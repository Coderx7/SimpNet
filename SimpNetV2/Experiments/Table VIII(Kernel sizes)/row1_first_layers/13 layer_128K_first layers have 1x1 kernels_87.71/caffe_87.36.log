
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0630 23:03:44.626240  7564 caffe.cpp:219] Using GPUs 0
I0630 23:03:44.807111  7564 caffe.cpp:224] GPU 0: GeForce GTX 1080
I0630 23:03:45.135123  7564 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0630 23:03:45.152135  7564 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 70000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 70000
snapshot_prefix: "examples/cifar10/128K"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 22000
stepvalue: 38000
stepvalue: 44000
stepvalue: 64000
type: "Nesterov"
I0630 23:03:45.152135  7564 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0630 23:03:45.153136  7564 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0630 23:03:45.153136  7564 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp4
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp5
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp6
I0630 23:03:45.153136  7564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0630 23:03:45.153136  7564 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_13_128k_first_1x1"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 21
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_12"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_12"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 37
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "conv4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp4"
  type: "Scale"
  bottom: "cccp4"
  top: "cccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 49
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp5"
  type: "Scale"
  bottom: "cccp5"
  top: "cccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "cccp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 50
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp6"
  type: "Scale"
  bottom: "cccp6"
  top: "cccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0630 23:03:45.154136  7564 layer_factory.cpp:58] Creating layer cifar
I0630 23:03:45.157140  7564 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I0630 23:03:45.157140  7564 net.cpp:84] Creating Layer cifar
I0630 23:03:45.157140  7564 net.cpp:380] cifar -> data
I0630 23:03:45.157140  7564 net.cpp:380] cifar -> label
I0630 23:03:45.157140  7564 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0630 23:03:45.158645  7564 data_layer.cpp:45] output data size: 100,3,32,32
I0630 23:03:45.164651  7564 net.cpp:122] Setting up cifar
I0630 23:03:45.164651  7564 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0630 23:03:45.164651  7564 net.cpp:129] Top shape: 100 (100)
I0630 23:03:45.164651  7564 net.cpp:137] Memory required for data: 1229200
I0630 23:03:45.164651  7564 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0630 23:03:45.165149  7564 net.cpp:84] Creating Layer label_cifar_1_split
I0630 23:03:45.165149  7564 net.cpp:406] label_cifar_1_split <- label
I0630 23:03:45.165149  7564 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0630 23:03:45.165149  7564 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0630 23:03:45.165149  7564 net.cpp:122] Setting up label_cifar_1_split
I0630 23:03:45.165149  7564 net.cpp:129] Top shape: 100 (100)
I0630 23:03:45.165149  7564 net.cpp:129] Top shape: 100 (100)
I0630 23:03:45.165149  7564 net.cpp:137] Memory required for data: 1230000
I0630 23:03:45.165149  7564 layer_factory.cpp:58] Creating layer conv1
I0630 23:03:45.165149  7564 net.cpp:84] Creating Layer conv1
I0630 23:03:45.165149  7564 net.cpp:406] conv1 <- data
I0630 23:03:45.165149  7564 net.cpp:380] conv1 -> conv1
I0630 23:03:45.165649  4252 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0630 23:03:45.412156  7564 net.cpp:122] Setting up conv1
I0630 23:03:45.412156  7564 net.cpp:129] Top shape: 100 21 32 32 (2150400)
I0630 23:03:45.412156  7564 net.cpp:137] Memory required for data: 9831600
I0630 23:03:45.412156  7564 layer_factory.cpp:58] Creating layer bn1
I0630 23:03:45.412156  7564 net.cpp:84] Creating Layer bn1
I0630 23:03:45.412156  7564 net.cpp:406] bn1 <- conv1
I0630 23:03:45.412156  7564 net.cpp:367] bn1 -> conv1 (in-place)
I0630 23:03:45.412156  7564 net.cpp:122] Setting up bn1
I0630 23:03:45.412156  7564 net.cpp:129] Top shape: 100 21 32 32 (2150400)
I0630 23:03:45.412156  7564 net.cpp:137] Memory required for data: 18433200
I0630 23:03:45.412156  7564 layer_factory.cpp:58] Creating layer scale1
I0630 23:03:45.412156  7564 net.cpp:84] Creating Layer scale1
I0630 23:03:45.412156  7564 net.cpp:406] scale1 <- conv1
I0630 23:03:45.412156  7564 net.cpp:367] scale1 -> conv1 (in-place)
I0630 23:03:45.412156  7564 layer_factory.cpp:58] Creating layer scale1
I0630 23:03:45.412156  7564 net.cpp:122] Setting up scale1
I0630 23:03:45.412156  7564 net.cpp:129] Top shape: 100 21 32 32 (2150400)
I0630 23:03:45.412156  7564 net.cpp:137] Memory required for data: 27034800
I0630 23:03:45.412156  7564 layer_factory.cpp:58] Creating layer relu1
I0630 23:03:45.412156  7564 net.cpp:84] Creating Layer relu1
I0630 23:03:45.412156  7564 net.cpp:406] relu1 <- conv1
I0630 23:03:45.412156  7564 net.cpp:367] relu1 -> conv1 (in-place)
I0630 23:03:45.412156  7564 net.cpp:122] Setting up relu1
I0630 23:03:45.412156  7564 net.cpp:129] Top shape: 100 21 32 32 (2150400)
I0630 23:03:45.412156  7564 net.cpp:137] Memory required for data: 35636400
I0630 23:03:45.412156  7564 layer_factory.cpp:58] Creating layer conv1_0
I0630 23:03:45.412156  7564 net.cpp:84] Creating Layer conv1_0
I0630 23:03:45.412156  7564 net.cpp:406] conv1_0 <- conv1
I0630 23:03:45.412156  7564 net.cpp:380] conv1_0 -> conv1_0
I0630 23:03:45.413157  7564 net.cpp:122] Setting up conv1_0
I0630 23:03:45.413157  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.413157  7564 net.cpp:137] Memory required for data: 48743600
I0630 23:03:45.413157  7564 layer_factory.cpp:58] Creating layer bn1_0
I0630 23:03:45.413157  7564 net.cpp:84] Creating Layer bn1_0
I0630 23:03:45.413157  7564 net.cpp:406] bn1_0 <- conv1_0
I0630 23:03:45.413157  7564 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0630 23:03:45.413157  7564 net.cpp:122] Setting up bn1_0
I0630 23:03:45.413157  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.413157  7564 net.cpp:137] Memory required for data: 61850800
I0630 23:03:45.413157  7564 layer_factory.cpp:58] Creating layer scale1_0
I0630 23:03:45.414158  7564 net.cpp:84] Creating Layer scale1_0
I0630 23:03:45.414158  7564 net.cpp:406] scale1_0 <- conv1_0
I0630 23:03:45.414158  7564 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0630 23:03:45.414158  7564 layer_factory.cpp:58] Creating layer scale1_0
I0630 23:03:45.414158  7564 net.cpp:122] Setting up scale1_0
I0630 23:03:45.414158  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.414158  7564 net.cpp:137] Memory required for data: 74958000
I0630 23:03:45.414158  7564 layer_factory.cpp:58] Creating layer relu1_0
I0630 23:03:45.414158  7564 net.cpp:84] Creating Layer relu1_0
I0630 23:03:45.414158  7564 net.cpp:406] relu1_0 <- conv1_0
I0630 23:03:45.414158  7564 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0630 23:03:45.414158  7564 net.cpp:122] Setting up relu1_0
I0630 23:03:45.414158  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.414158  7564 net.cpp:137] Memory required for data: 88065200
I0630 23:03:45.414158  7564 layer_factory.cpp:58] Creating layer conv2
I0630 23:03:45.414158  7564 net.cpp:84] Creating Layer conv2
I0630 23:03:45.414158  7564 net.cpp:406] conv2 <- conv1_0
I0630 23:03:45.414158  7564 net.cpp:380] conv2 -> conv2
I0630 23:03:45.415159  7564 net.cpp:122] Setting up conv2
I0630 23:03:45.415159  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.415159  7564 net.cpp:137] Memory required for data: 101172400
I0630 23:03:45.415159  7564 layer_factory.cpp:58] Creating layer bn2
I0630 23:03:45.415159  7564 net.cpp:84] Creating Layer bn2
I0630 23:03:45.415159  7564 net.cpp:406] bn2 <- conv2
I0630 23:03:45.415159  7564 net.cpp:367] bn2 -> conv2 (in-place)
I0630 23:03:45.415159  7564 net.cpp:122] Setting up bn2
I0630 23:03:45.415159  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.415159  7564 net.cpp:137] Memory required for data: 114279600
I0630 23:03:45.415159  7564 layer_factory.cpp:58] Creating layer scale2
I0630 23:03:45.415159  7564 net.cpp:84] Creating Layer scale2
I0630 23:03:45.415159  7564 net.cpp:406] scale2 <- conv2
I0630 23:03:45.415159  7564 net.cpp:367] scale2 -> conv2 (in-place)
I0630 23:03:45.415159  7564 layer_factory.cpp:58] Creating layer scale2
I0630 23:03:45.415159  7564 net.cpp:122] Setting up scale2
I0630 23:03:45.415159  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.415159  7564 net.cpp:137] Memory required for data: 127386800
I0630 23:03:45.415159  7564 layer_factory.cpp:58] Creating layer relu2
I0630 23:03:45.415159  7564 net.cpp:84] Creating Layer relu2
I0630 23:03:45.415159  7564 net.cpp:406] relu2 <- conv2
I0630 23:03:45.415159  7564 net.cpp:367] relu2 -> conv2 (in-place)
I0630 23:03:45.416159  7564 net.cpp:122] Setting up relu2
I0630 23:03:45.416159  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.416159  7564 net.cpp:137] Memory required for data: 140494000
I0630 23:03:45.416159  7564 layer_factory.cpp:58] Creating layer conv2_1
I0630 23:03:45.416159  7564 net.cpp:84] Creating Layer conv2_1
I0630 23:03:45.416159  7564 net.cpp:406] conv2_1 <- conv2
I0630 23:03:45.416159  7564 net.cpp:380] conv2_1 -> conv2_1
I0630 23:03:45.417160  7564 net.cpp:122] Setting up conv2_1
I0630 23:03:45.417160  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.417160  7564 net.cpp:137] Memory required for data: 153601200
I0630 23:03:45.417160  7564 layer_factory.cpp:58] Creating layer bn2_1
I0630 23:03:45.417160  7564 net.cpp:84] Creating Layer bn2_1
I0630 23:03:45.417160  7564 net.cpp:406] bn2_1 <- conv2_1
I0630 23:03:45.418161  7564 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0630 23:03:45.418161  7564 net.cpp:122] Setting up bn2_1
I0630 23:03:45.418161  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.418161  7564 net.cpp:137] Memory required for data: 166708400
I0630 23:03:45.418161  7564 layer_factory.cpp:58] Creating layer scale2_1
I0630 23:03:45.418161  7564 net.cpp:84] Creating Layer scale2_1
I0630 23:03:45.418161  7564 net.cpp:406] scale2_1 <- conv2_1
I0630 23:03:45.418161  7564 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0630 23:03:45.418161  7564 layer_factory.cpp:58] Creating layer scale2_1
I0630 23:03:45.418161  7564 net.cpp:122] Setting up scale2_1
I0630 23:03:45.418161  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.418161  7564 net.cpp:137] Memory required for data: 179815600
I0630 23:03:45.418161  7564 layer_factory.cpp:58] Creating layer relu2_1
I0630 23:03:45.418161  7564 net.cpp:84] Creating Layer relu2_1
I0630 23:03:45.418161  7564 net.cpp:406] relu2_1 <- conv2_1
I0630 23:03:45.418161  7564 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0630 23:03:45.418161  7564 net.cpp:122] Setting up relu2_1
I0630 23:03:45.418161  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.418161  7564 net.cpp:137] Memory required for data: 192922800
I0630 23:03:45.418161  7564 layer_factory.cpp:58] Creating layer conv2_2
I0630 23:03:45.418161  7564 net.cpp:84] Creating Layer conv2_2
I0630 23:03:45.418161  7564 net.cpp:406] conv2_2 <- conv2_1
I0630 23:03:45.418161  7564 net.cpp:380] conv2_2 -> conv2_2
I0630 23:03:45.419162  7564 net.cpp:122] Setting up conv2_2
I0630 23:03:45.419162  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.419162  7564 net.cpp:137] Memory required for data: 206030000
I0630 23:03:45.419162  7564 layer_factory.cpp:58] Creating layer bn2_2
I0630 23:03:45.419162  7564 net.cpp:84] Creating Layer bn2_2
I0630 23:03:45.419162  7564 net.cpp:406] bn2_2 <- conv2_2
I0630 23:03:45.419162  7564 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0630 23:03:45.419162  7564 net.cpp:122] Setting up bn2_2
I0630 23:03:45.419162  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.419162  7564 net.cpp:137] Memory required for data: 219137200
I0630 23:03:45.419162  7564 layer_factory.cpp:58] Creating layer scale2_2
I0630 23:03:45.419162  7564 net.cpp:84] Creating Layer scale2_2
I0630 23:03:45.419162  7564 net.cpp:406] scale2_2 <- conv2_2
I0630 23:03:45.419162  7564 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0630 23:03:45.419162  7564 layer_factory.cpp:58] Creating layer scale2_2
I0630 23:03:45.419162  7564 net.cpp:122] Setting up scale2_2
I0630 23:03:45.419162  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.420162  7564 net.cpp:137] Memory required for data: 232244400
I0630 23:03:45.420162  7564 layer_factory.cpp:58] Creating layer relu2_2
I0630 23:03:45.420162  7564 net.cpp:84] Creating Layer relu2_2
I0630 23:03:45.420162  7564 net.cpp:406] relu2_2 <- conv2_2
I0630 23:03:45.420162  7564 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0630 23:03:45.420162  7564 net.cpp:122] Setting up relu2_2
I0630 23:03:45.420162  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.420162  7564 net.cpp:137] Memory required for data: 245351600
I0630 23:03:45.420162  7564 layer_factory.cpp:58] Creating layer pool2_1
I0630 23:03:45.420162  7564 net.cpp:84] Creating Layer pool2_1
I0630 23:03:45.420162  7564 net.cpp:406] pool2_1 <- conv2_2
I0630 23:03:45.420162  7564 net.cpp:380] pool2_1 -> pool2_1
I0630 23:03:45.420162  7564 net.cpp:122] Setting up pool2_1
I0630 23:03:45.420162  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.420162  7564 net.cpp:137] Memory required for data: 248628400
I0630 23:03:45.420162  7564 layer_factory.cpp:58] Creating layer conv3
I0630 23:03:45.420162  7564 net.cpp:84] Creating Layer conv3
I0630 23:03:45.420162  7564 net.cpp:406] conv3 <- pool2_1
I0630 23:03:45.420162  7564 net.cpp:380] conv3 -> conv3
I0630 23:03:45.421162  7564 net.cpp:122] Setting up conv3
I0630 23:03:45.421162  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.421162  7564 net.cpp:137] Memory required for data: 251905200
I0630 23:03:45.421162  7564 layer_factory.cpp:58] Creating layer bn3
I0630 23:03:45.421162  7564 net.cpp:84] Creating Layer bn3
I0630 23:03:45.421162  7564 net.cpp:406] bn3 <- conv3
I0630 23:03:45.421162  7564 net.cpp:367] bn3 -> conv3 (in-place)
I0630 23:03:45.421162  7564 net.cpp:122] Setting up bn3
I0630 23:03:45.421162  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.421162  7564 net.cpp:137] Memory required for data: 255182000
I0630 23:03:45.421162  7564 layer_factory.cpp:58] Creating layer scale3
I0630 23:03:45.421162  7564 net.cpp:84] Creating Layer scale3
I0630 23:03:45.421162  7564 net.cpp:406] scale3 <- conv3
I0630 23:03:45.421162  7564 net.cpp:367] scale3 -> conv3 (in-place)
I0630 23:03:45.421162  7564 layer_factory.cpp:58] Creating layer scale3
I0630 23:03:45.421162  7564 net.cpp:122] Setting up scale3
I0630 23:03:45.421162  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.421162  7564 net.cpp:137] Memory required for data: 258458800
I0630 23:03:45.421162  7564 layer_factory.cpp:58] Creating layer relu3
I0630 23:03:45.421162  7564 net.cpp:84] Creating Layer relu3
I0630 23:03:45.421162  7564 net.cpp:406] relu3 <- conv3
I0630 23:03:45.421162  7564 net.cpp:367] relu3 -> conv3 (in-place)
I0630 23:03:45.421162  7564 net.cpp:122] Setting up relu3
I0630 23:03:45.421162  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.421162  7564 net.cpp:137] Memory required for data: 261735600
I0630 23:03:45.421162  7564 layer_factory.cpp:58] Creating layer conv4
I0630 23:03:45.421162  7564 net.cpp:84] Creating Layer conv4
I0630 23:03:45.421162  7564 net.cpp:406] conv4 <- conv3
I0630 23:03:45.421162  7564 net.cpp:380] conv4 -> conv4
I0630 23:03:45.422164  7564 net.cpp:122] Setting up conv4
I0630 23:03:45.422164  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.423164  7564 net.cpp:137] Memory required for data: 265012400
I0630 23:03:45.423164  7564 layer_factory.cpp:58] Creating layer bn4
I0630 23:03:45.423164  7564 net.cpp:84] Creating Layer bn4
I0630 23:03:45.423164  7564 net.cpp:406] bn4 <- conv4
I0630 23:03:45.423164  7564 net.cpp:367] bn4 -> conv4 (in-place)
I0630 23:03:45.423164  7564 net.cpp:122] Setting up bn4
I0630 23:03:45.423164  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.423164  7564 net.cpp:137] Memory required for data: 268289200
I0630 23:03:45.423164  7564 layer_factory.cpp:58] Creating layer scale4
I0630 23:03:45.423164  7564 net.cpp:84] Creating Layer scale4
I0630 23:03:45.423164  7564 net.cpp:406] scale4 <- conv4
I0630 23:03:45.423164  7564 net.cpp:367] scale4 -> conv4 (in-place)
I0630 23:03:45.423164  7564 layer_factory.cpp:58] Creating layer scale4
I0630 23:03:45.423164  7564 net.cpp:122] Setting up scale4
I0630 23:03:45.423164  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.423164  7564 net.cpp:137] Memory required for data: 271566000
I0630 23:03:45.423164  7564 layer_factory.cpp:58] Creating layer relu4
I0630 23:03:45.423164  7564 net.cpp:84] Creating Layer relu4
I0630 23:03:45.423164  7564 net.cpp:406] relu4 <- conv4
I0630 23:03:45.423164  7564 net.cpp:367] relu4 -> conv4 (in-place)
I0630 23:03:45.423164  7564 net.cpp:122] Setting up relu4
I0630 23:03:45.423164  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.423164  7564 net.cpp:137] Memory required for data: 274842800
I0630 23:03:45.423164  7564 layer_factory.cpp:58] Creating layer conv4_1
I0630 23:03:45.423164  7564 net.cpp:84] Creating Layer conv4_1
I0630 23:03:45.423164  7564 net.cpp:406] conv4_1 <- conv4
I0630 23:03:45.423164  7564 net.cpp:380] conv4_1 -> conv4_1
I0630 23:03:45.425165  7564 net.cpp:122] Setting up conv4_1
I0630 23:03:45.425165  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.425165  7564 net.cpp:137] Memory required for data: 278119600
I0630 23:03:45.425165  7564 layer_factory.cpp:58] Creating layer bn4_1
I0630 23:03:45.425165  7564 net.cpp:84] Creating Layer bn4_1
I0630 23:03:45.425165  7564 net.cpp:406] bn4_1 <- conv4_1
I0630 23:03:45.425165  7564 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0630 23:03:45.425165  7564 net.cpp:122] Setting up bn4_1
I0630 23:03:45.425165  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.425165  7564 net.cpp:137] Memory required for data: 281396400
I0630 23:03:45.425165  7564 layer_factory.cpp:58] Creating layer scale4_1
I0630 23:03:45.425165  7564 net.cpp:84] Creating Layer scale4_1
I0630 23:03:45.425165  7564 net.cpp:406] scale4_1 <- conv4_1
I0630 23:03:45.425165  7564 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0630 23:03:45.425165  7564 layer_factory.cpp:58] Creating layer scale4_1
I0630 23:03:45.425165  7564 net.cpp:122] Setting up scale4_1
I0630 23:03:45.425165  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.425165  7564 net.cpp:137] Memory required for data: 284673200
I0630 23:03:45.425165  7564 layer_factory.cpp:58] Creating layer relu4_1
I0630 23:03:45.425165  7564 net.cpp:84] Creating Layer relu4_1
I0630 23:03:45.425165  7564 net.cpp:406] relu4_1 <- conv4_1
I0630 23:03:45.425165  7564 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0630 23:03:45.426165  7564 net.cpp:122] Setting up relu4_1
I0630 23:03:45.426165  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.426165  7564 net.cpp:137] Memory required for data: 287950000
I0630 23:03:45.426165  7564 layer_factory.cpp:58] Creating layer conv4_2
I0630 23:03:45.426165  7564 net.cpp:84] Creating Layer conv4_2
I0630 23:03:45.426165  7564 net.cpp:406] conv4_2 <- conv4_1
I0630 23:03:45.426165  7564 net.cpp:380] conv4_2 -> conv4_2
I0630 23:03:45.427167  7564 net.cpp:122] Setting up conv4_2
I0630 23:03:45.427167  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.427167  7564 net.cpp:137] Memory required for data: 291226800
I0630 23:03:45.427167  7564 layer_factory.cpp:58] Creating layer bn4_2
I0630 23:03:45.427167  7564 net.cpp:84] Creating Layer bn4_2
I0630 23:03:45.427167  7564 net.cpp:406] bn4_2 <- conv4_2
I0630 23:03:45.427167  7564 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0630 23:03:45.427167  7564 net.cpp:122] Setting up bn4_2
I0630 23:03:45.427167  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.427167  7564 net.cpp:137] Memory required for data: 294503600
I0630 23:03:45.427167  7564 layer_factory.cpp:58] Creating layer scale4_2
I0630 23:03:45.427167  7564 net.cpp:84] Creating Layer scale4_2
I0630 23:03:45.427167  7564 net.cpp:406] scale4_2 <- conv4_2
I0630 23:03:45.427167  7564 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0630 23:03:45.427167  7564 layer_factory.cpp:58] Creating layer scale4_2
I0630 23:03:45.427167  7564 net.cpp:122] Setting up scale4_2
I0630 23:03:45.427167  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.427167  7564 net.cpp:137] Memory required for data: 297780400
I0630 23:03:45.427167  7564 layer_factory.cpp:58] Creating layer relu4_2
I0630 23:03:45.427167  7564 net.cpp:84] Creating Layer relu4_2
I0630 23:03:45.427167  7564 net.cpp:406] relu4_2 <- conv4_2
I0630 23:03:45.427167  7564 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0630 23:03:45.428174  7564 net.cpp:122] Setting up relu4_2
I0630 23:03:45.428174  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.428174  7564 net.cpp:137] Memory required for data: 301057200
I0630 23:03:45.428174  7564 layer_factory.cpp:58] Creating layer pool4_12
I0630 23:03:45.428174  7564 net.cpp:84] Creating Layer pool4_12
I0630 23:03:45.428174  7564 net.cpp:406] pool4_12 <- conv4_2
I0630 23:03:45.428174  7564 net.cpp:380] pool4_12 -> pool4_12
I0630 23:03:45.428174  7564 net.cpp:122] Setting up pool4_12
I0630 23:03:45.428174  7564 net.cpp:129] Top shape: 100 32 8 8 (204800)
I0630 23:03:45.428174  7564 net.cpp:137] Memory required for data: 301876400
I0630 23:03:45.428174  7564 layer_factory.cpp:58] Creating layer conv4_0
I0630 23:03:45.428174  7564 net.cpp:84] Creating Layer conv4_0
I0630 23:03:45.428174  7564 net.cpp:406] conv4_0 <- pool4_12
I0630 23:03:45.428174  7564 net.cpp:380] conv4_0 -> conv4_0
I0630 23:03:45.429180  7564 net.cpp:122] Setting up conv4_0
I0630 23:03:45.429180  7564 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 23:03:45.429180  7564 net.cpp:137] Memory required for data: 302823600
I0630 23:03:45.429180  7564 layer_factory.cpp:58] Creating layer bn4_0
I0630 23:03:45.429180  7564 net.cpp:84] Creating Layer bn4_0
I0630 23:03:45.429180  7564 net.cpp:406] bn4_0 <- conv4_0
I0630 23:03:45.429180  7564 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0630 23:03:45.429180  7564 net.cpp:122] Setting up bn4_0
I0630 23:03:45.429180  7564 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 23:03:45.429180  7564 net.cpp:137] Memory required for data: 303770800
I0630 23:03:45.429180  7564 layer_factory.cpp:58] Creating layer scale4_0
I0630 23:03:45.429180  7564 net.cpp:84] Creating Layer scale4_0
I0630 23:03:45.429180  7564 net.cpp:406] scale4_0 <- conv4_0
I0630 23:03:45.429180  7564 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0630 23:03:45.429180  7564 layer_factory.cpp:58] Creating layer scale4_0
I0630 23:03:45.429180  7564 net.cpp:122] Setting up scale4_0
I0630 23:03:45.429180  7564 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 23:03:45.429180  7564 net.cpp:137] Memory required for data: 304718000
I0630 23:03:45.429180  7564 layer_factory.cpp:58] Creating layer relu4_0
I0630 23:03:45.429180  7564 net.cpp:84] Creating Layer relu4_0
I0630 23:03:45.429180  7564 net.cpp:406] relu4_0 <- conv4_0
I0630 23:03:45.430169  7564 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0630 23:03:45.430169  7564 net.cpp:122] Setting up relu4_0
I0630 23:03:45.430169  7564 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 23:03:45.430169  7564 net.cpp:137] Memory required for data: 305665200
I0630 23:03:45.430169  7564 layer_factory.cpp:58] Creating layer cccp4
I0630 23:03:45.430169  7564 net.cpp:84] Creating Layer cccp4
I0630 23:03:45.430169  7564 net.cpp:406] cccp4 <- conv4_0
I0630 23:03:45.430169  7564 net.cpp:380] cccp4 -> cccp4
I0630 23:03:45.431185  7564 net.cpp:122] Setting up cccp4
I0630 23:03:45.431185  7564 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 23:03:45.431185  7564 net.cpp:137] Memory required for data: 306894000
I0630 23:03:45.431185  7564 layer_factory.cpp:58] Creating layer bn_cccp4
I0630 23:03:45.431185  7564 net.cpp:84] Creating Layer bn_cccp4
I0630 23:03:45.431185  7564 net.cpp:406] bn_cccp4 <- cccp4
I0630 23:03:45.431185  7564 net.cpp:367] bn_cccp4 -> cccp4 (in-place)
I0630 23:03:45.431185  7564 net.cpp:122] Setting up bn_cccp4
I0630 23:03:45.431185  7564 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 23:03:45.431185  7564 net.cpp:137] Memory required for data: 308122800
I0630 23:03:45.431185  7564 layer_factory.cpp:58] Creating layer scale_cccp4
I0630 23:03:45.431185  7564 net.cpp:84] Creating Layer scale_cccp4
I0630 23:03:45.431185  7564 net.cpp:406] scale_cccp4 <- cccp4
I0630 23:03:45.431185  7564 net.cpp:367] scale_cccp4 -> cccp4 (in-place)
I0630 23:03:45.431185  7564 layer_factory.cpp:58] Creating layer scale_cccp4
I0630 23:03:45.431185  7564 net.cpp:122] Setting up scale_cccp4
I0630 23:03:45.431185  7564 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 23:03:45.431185  7564 net.cpp:137] Memory required for data: 309351600
I0630 23:03:45.431185  7564 layer_factory.cpp:58] Creating layer relu_cccp4
I0630 23:03:45.431185  7564 net.cpp:84] Creating Layer relu_cccp4
I0630 23:03:45.431185  7564 net.cpp:406] relu_cccp4 <- cccp4
I0630 23:03:45.431185  7564 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0630 23:03:45.431185  7564 net.cpp:122] Setting up relu_cccp4
I0630 23:03:45.431185  7564 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 23:03:45.431185  7564 net.cpp:137] Memory required for data: 310580400
I0630 23:03:45.431185  7564 layer_factory.cpp:58] Creating layer cccp5
I0630 23:03:45.431185  7564 net.cpp:84] Creating Layer cccp5
I0630 23:03:45.431185  7564 net.cpp:406] cccp5 <- cccp4
I0630 23:03:45.431185  7564 net.cpp:380] cccp5 -> cccp5
I0630 23:03:45.433310  7564 net.cpp:122] Setting up cccp5
I0630 23:03:45.433310  7564 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 23:03:45.433310  7564 net.cpp:137] Memory required for data: 311834800
I0630 23:03:45.433310  7564 layer_factory.cpp:58] Creating layer bn_cccp5
I0630 23:03:45.433310  7564 net.cpp:84] Creating Layer bn_cccp5
I0630 23:03:45.433310  7564 net.cpp:406] bn_cccp5 <- cccp5
I0630 23:03:45.433310  7564 net.cpp:367] bn_cccp5 -> cccp5 (in-place)
I0630 23:03:45.433310  7564 net.cpp:122] Setting up bn_cccp5
I0630 23:03:45.433310  7564 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 23:03:45.433310  7564 net.cpp:137] Memory required for data: 313089200
I0630 23:03:45.433310  7564 layer_factory.cpp:58] Creating layer scale_cccp5
I0630 23:03:45.433310  7564 net.cpp:84] Creating Layer scale_cccp5
I0630 23:03:45.433310  7564 net.cpp:406] scale_cccp5 <- cccp5
I0630 23:03:45.433310  7564 net.cpp:367] scale_cccp5 -> cccp5 (in-place)
I0630 23:03:45.433310  7564 layer_factory.cpp:58] Creating layer scale_cccp5
I0630 23:03:45.433310  7564 net.cpp:122] Setting up scale_cccp5
I0630 23:03:45.433310  7564 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 23:03:45.433310  7564 net.cpp:137] Memory required for data: 314343600
I0630 23:03:45.433310  7564 layer_factory.cpp:58] Creating layer relu_cccp5
I0630 23:03:45.433310  7564 net.cpp:84] Creating Layer relu_cccp5
I0630 23:03:45.433310  7564 net.cpp:406] relu_cccp5 <- cccp5
I0630 23:03:45.433310  7564 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0630 23:03:45.434314  7564 net.cpp:122] Setting up relu_cccp5
I0630 23:03:45.434314  7564 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 23:03:45.434314  7564 net.cpp:137] Memory required for data: 315598000
I0630 23:03:45.434314  7564 layer_factory.cpp:58] Creating layer cccp6
I0630 23:03:45.434314  7564 net.cpp:84] Creating Layer cccp6
I0630 23:03:45.434314  7564 net.cpp:406] cccp6 <- cccp5
I0630 23:03:45.434314  7564 net.cpp:380] cccp6 -> cccp6
I0630 23:03:45.435313  7564 net.cpp:122] Setting up cccp6
I0630 23:03:45.435313  7564 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 23:03:45.435313  7564 net.cpp:137] Memory required for data: 316878000
I0630 23:03:45.435313  7564 layer_factory.cpp:58] Creating layer bn_cccp6
I0630 23:03:45.435313  7564 net.cpp:84] Creating Layer bn_cccp6
I0630 23:03:45.435313  7564 net.cpp:406] bn_cccp6 <- cccp6
I0630 23:03:45.435313  7564 net.cpp:367] bn_cccp6 -> cccp6 (in-place)
I0630 23:03:45.435313  7564 net.cpp:122] Setting up bn_cccp6
I0630 23:03:45.435313  7564 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 23:03:45.435313  7564 net.cpp:137] Memory required for data: 318158000
I0630 23:03:45.435313  7564 layer_factory.cpp:58] Creating layer scale_cccp6
I0630 23:03:45.435313  7564 net.cpp:84] Creating Layer scale_cccp6
I0630 23:03:45.435313  7564 net.cpp:406] scale_cccp6 <- cccp6
I0630 23:03:45.435313  7564 net.cpp:367] scale_cccp6 -> cccp6 (in-place)
I0630 23:03:45.435313  7564 layer_factory.cpp:58] Creating layer scale_cccp6
I0630 23:03:45.435313  7564 net.cpp:122] Setting up scale_cccp6
I0630 23:03:45.435313  7564 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 23:03:45.435313  7564 net.cpp:137] Memory required for data: 319438000
I0630 23:03:45.435313  7564 layer_factory.cpp:58] Creating layer relu_cccp6
I0630 23:03:45.435313  7564 net.cpp:84] Creating Layer relu_cccp6
I0630 23:03:45.435313  7564 net.cpp:406] relu_cccp6 <- cccp6
I0630 23:03:45.435313  7564 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0630 23:03:45.435313  7564 net.cpp:122] Setting up relu_cccp6
I0630 23:03:45.435313  7564 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 23:03:45.435313  7564 net.cpp:137] Memory required for data: 320718000
I0630 23:03:45.435313  7564 layer_factory.cpp:58] Creating layer poolcp6
I0630 23:03:45.435313  7564 net.cpp:84] Creating Layer poolcp6
I0630 23:03:45.435313  7564 net.cpp:406] poolcp6 <- cccp6
I0630 23:03:45.435313  7564 net.cpp:380] poolcp6 -> poolcp6
I0630 23:03:45.435313  7564 net.cpp:122] Setting up poolcp6
I0630 23:03:45.435313  7564 net.cpp:129] Top shape: 100 50 1 1 (5000)
I0630 23:03:45.435313  7564 net.cpp:137] Memory required for data: 320738000
I0630 23:03:45.435313  7564 layer_factory.cpp:58] Creating layer ip1
I0630 23:03:45.435313  7564 net.cpp:84] Creating Layer ip1
I0630 23:03:45.435313  7564 net.cpp:406] ip1 <- poolcp6
I0630 23:03:45.435313  7564 net.cpp:380] ip1 -> ip1
I0630 23:03:45.435313  7564 net.cpp:122] Setting up ip1
I0630 23:03:45.435313  7564 net.cpp:129] Top shape: 100 10 (1000)
I0630 23:03:45.435313  7564 net.cpp:137] Memory required for data: 320742000
I0630 23:03:45.435313  7564 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0630 23:03:45.435313  7564 net.cpp:84] Creating Layer ip1_ip1_0_split
I0630 23:03:45.435313  7564 net.cpp:406] ip1_ip1_0_split <- ip1
I0630 23:03:45.436314  7564 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0630 23:03:45.436314  7564 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0630 23:03:45.436314  7564 net.cpp:122] Setting up ip1_ip1_0_split
I0630 23:03:45.436314  7564 net.cpp:129] Top shape: 100 10 (1000)
I0630 23:03:45.436314  7564 net.cpp:129] Top shape: 100 10 (1000)
I0630 23:03:45.436314  7564 net.cpp:137] Memory required for data: 320750000
I0630 23:03:45.436314  7564 layer_factory.cpp:58] Creating layer accuracy_training
I0630 23:03:45.436314  7564 net.cpp:84] Creating Layer accuracy_training
I0630 23:03:45.436314  7564 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0630 23:03:45.436314  7564 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I0630 23:03:45.436314  7564 net.cpp:380] accuracy_training -> accuracy_training
I0630 23:03:45.436314  7564 net.cpp:122] Setting up accuracy_training
I0630 23:03:45.436314  7564 net.cpp:129] Top shape: (1)
I0630 23:03:45.436314  7564 net.cpp:137] Memory required for data: 320750004
I0630 23:03:45.436314  7564 layer_factory.cpp:58] Creating layer loss
I0630 23:03:45.436314  7564 net.cpp:84] Creating Layer loss
I0630 23:03:45.436314  7564 net.cpp:406] loss <- ip1_ip1_0_split_1
I0630 23:03:45.436314  7564 net.cpp:406] loss <- label_cifar_1_split_1
I0630 23:03:45.436314  7564 net.cpp:380] loss -> loss
I0630 23:03:45.436314  7564 layer_factory.cpp:58] Creating layer loss
I0630 23:03:45.436800  7564 net.cpp:122] Setting up loss
I0630 23:03:45.436800  7564 net.cpp:129] Top shape: (1)
I0630 23:03:45.436800  7564 net.cpp:132]     with loss weight 1
I0630 23:03:45.436800  7564 net.cpp:137] Memory required for data: 320750008
I0630 23:03:45.436800  7564 net.cpp:198] loss needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:200] accuracy_training does not need backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] ip1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] poolcp6 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu_cccp6 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale_cccp6 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn_cccp6 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] cccp6 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu_cccp5 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale_cccp5 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn_cccp5 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] cccp5 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu_cccp4 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale_cccp4 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn_cccp4 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] cccp4 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu4_0 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale4_0 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn4_0 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] conv4_0 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] pool4_12 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu4_2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale4_2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn4_2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] conv4_2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu4_1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale4_1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn4_1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] conv4_1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu4 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale4 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn4 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] conv4 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu3 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale3 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn3 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] conv3 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] pool2_1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu2_2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale2_2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn2_2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] conv2_2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu2_1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale2_1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn2_1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] conv2_1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] conv2 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu1_0 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale1_0 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn1_0 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] conv1_0 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] relu1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] scale1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] bn1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:198] conv1 needs backward computation.
I0630 23:03:45.436800  7564 net.cpp:200] label_cifar_1_split does not need backward computation.
I0630 23:03:45.436800  7564 net.cpp:200] cifar does not need backward computation.
I0630 23:03:45.436800  7564 net.cpp:242] This network produces output accuracy_training
I0630 23:03:45.436800  7564 net.cpp:242] This network produces output loss
I0630 23:03:45.436800  7564 net.cpp:255] Network initialization done.
I0630 23:03:45.437803  7564 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0630 23:03:45.437803  7564 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0630 23:03:45.437803  7564 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp4
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp5
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp6
I0630 23:03:45.437803  7564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0630 23:03:45.437803  7564 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_13_128k_first_1x1"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 21
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_12"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_12"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 37
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "conv4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp4"
  type: "Scale"
  bottom: "cccp4"
  top: "cccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 49
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp5"
  type: "Scale"
  bottom: "cccp5"
  top: "cccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "cccp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 50
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp6"
  type: "Scale"
  bottom: "cccp6"
  top: "cccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0630 23:03:45.438803  7564 layer_factory.cpp:58] Creating layer cifar
I0630 23:03:45.444809  7564 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I0630 23:03:45.444809  7564 net.cpp:84] Creating Layer cifar
I0630 23:03:45.444809  7564 net.cpp:380] cifar -> data
I0630 23:03:45.444809  7564 net.cpp:380] cifar -> label
I0630 23:03:45.444809  7564 data_layer.cpp:45] output data size: 100,3,32,32
I0630 23:03:45.450376  7564 net.cpp:122] Setting up cifar
I0630 23:03:45.450376  7564 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0630 23:03:45.450376  7564 net.cpp:129] Top shape: 100 (100)
I0630 23:03:45.450376  7564 net.cpp:137] Memory required for data: 1229200
I0630 23:03:45.450376  7564 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0630 23:03:45.450376  7564 net.cpp:84] Creating Layer label_cifar_1_split
I0630 23:03:45.450376  7564 net.cpp:406] label_cifar_1_split <- label
I0630 23:03:45.450376  7564 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0630 23:03:45.450376  7564 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0630 23:03:45.450376  7564 net.cpp:122] Setting up label_cifar_1_split
I0630 23:03:45.450376  7564 net.cpp:129] Top shape: 100 (100)
I0630 23:03:45.450376  7564 net.cpp:129] Top shape: 100 (100)
I0630 23:03:45.450376  7564 net.cpp:137] Memory required for data: 1230000
I0630 23:03:45.450376  7564 layer_factory.cpp:58] Creating layer conv1
I0630 23:03:45.450376  7564 net.cpp:84] Creating Layer conv1
I0630 23:03:45.450376  7564 net.cpp:406] conv1 <- data
I0630 23:03:45.450376  7564 net.cpp:380] conv1 -> conv1
I0630 23:03:45.451378  9248 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0630 23:03:45.451378  7564 net.cpp:122] Setting up conv1
I0630 23:03:45.451378  7564 net.cpp:129] Top shape: 100 21 32 32 (2150400)
I0630 23:03:45.451378  7564 net.cpp:137] Memory required for data: 9831600
I0630 23:03:45.451378  7564 layer_factory.cpp:58] Creating layer bn1
I0630 23:03:45.451378  7564 net.cpp:84] Creating Layer bn1
I0630 23:03:45.451378  7564 net.cpp:406] bn1 <- conv1
I0630 23:03:45.451378  7564 net.cpp:367] bn1 -> conv1 (in-place)
I0630 23:03:45.451378  7564 net.cpp:122] Setting up bn1
I0630 23:03:45.451378  7564 net.cpp:129] Top shape: 100 21 32 32 (2150400)
I0630 23:03:45.451378  7564 net.cpp:137] Memory required for data: 18433200
I0630 23:03:45.451378  7564 layer_factory.cpp:58] Creating layer scale1
I0630 23:03:45.451378  7564 net.cpp:84] Creating Layer scale1
I0630 23:03:45.451378  7564 net.cpp:406] scale1 <- conv1
I0630 23:03:45.451378  7564 net.cpp:367] scale1 -> conv1 (in-place)
I0630 23:03:45.451378  7564 layer_factory.cpp:58] Creating layer scale1
I0630 23:03:45.451378  7564 net.cpp:122] Setting up scale1
I0630 23:03:45.451378  7564 net.cpp:129] Top shape: 100 21 32 32 (2150400)
I0630 23:03:45.451378  7564 net.cpp:137] Memory required for data: 27034800
I0630 23:03:45.451378  7564 layer_factory.cpp:58] Creating layer relu1
I0630 23:03:45.451378  7564 net.cpp:84] Creating Layer relu1
I0630 23:03:45.451378  7564 net.cpp:406] relu1 <- conv1
I0630 23:03:45.451378  7564 net.cpp:367] relu1 -> conv1 (in-place)
I0630 23:03:45.452378  7564 net.cpp:122] Setting up relu1
I0630 23:03:45.452378  7564 net.cpp:129] Top shape: 100 21 32 32 (2150400)
I0630 23:03:45.452378  7564 net.cpp:137] Memory required for data: 35636400
I0630 23:03:45.452378  7564 layer_factory.cpp:58] Creating layer conv1_0
I0630 23:03:45.452378  7564 net.cpp:84] Creating Layer conv1_0
I0630 23:03:45.452378  7564 net.cpp:406] conv1_0 <- conv1
I0630 23:03:45.452378  7564 net.cpp:380] conv1_0 -> conv1_0
I0630 23:03:45.453379  7564 net.cpp:122] Setting up conv1_0
I0630 23:03:45.453379  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.453379  7564 net.cpp:137] Memory required for data: 48743600
I0630 23:03:45.453379  7564 layer_factory.cpp:58] Creating layer bn1_0
I0630 23:03:45.453379  7564 net.cpp:84] Creating Layer bn1_0
I0630 23:03:45.453379  7564 net.cpp:406] bn1_0 <- conv1_0
I0630 23:03:45.453379  7564 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0630 23:03:45.453379  7564 net.cpp:122] Setting up bn1_0
I0630 23:03:45.453379  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.453379  7564 net.cpp:137] Memory required for data: 61850800
I0630 23:03:45.453379  7564 layer_factory.cpp:58] Creating layer scale1_0
I0630 23:03:45.453379  7564 net.cpp:84] Creating Layer scale1_0
I0630 23:03:45.453379  7564 net.cpp:406] scale1_0 <- conv1_0
I0630 23:03:45.453379  7564 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0630 23:03:45.453379  7564 layer_factory.cpp:58] Creating layer scale1_0
I0630 23:03:45.454380  7564 net.cpp:122] Setting up scale1_0
I0630 23:03:45.454380  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.454380  7564 net.cpp:137] Memory required for data: 74958000
I0630 23:03:45.454380  7564 layer_factory.cpp:58] Creating layer relu1_0
I0630 23:03:45.454380  7564 net.cpp:84] Creating Layer relu1_0
I0630 23:03:45.454380  7564 net.cpp:406] relu1_0 <- conv1_0
I0630 23:03:45.454380  7564 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0630 23:03:45.454380  7564 net.cpp:122] Setting up relu1_0
I0630 23:03:45.454380  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.454380  7564 net.cpp:137] Memory required for data: 88065200
I0630 23:03:45.454380  7564 layer_factory.cpp:58] Creating layer conv2
I0630 23:03:45.454380  7564 net.cpp:84] Creating Layer conv2
I0630 23:03:45.454380  7564 net.cpp:406] conv2 <- conv1_0
I0630 23:03:45.454380  7564 net.cpp:380] conv2 -> conv2
I0630 23:03:45.455381  7564 net.cpp:122] Setting up conv2
I0630 23:03:45.455381  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.455381  7564 net.cpp:137] Memory required for data: 101172400
I0630 23:03:45.455381  7564 layer_factory.cpp:58] Creating layer bn2
I0630 23:03:45.455381  7564 net.cpp:84] Creating Layer bn2
I0630 23:03:45.455381  7564 net.cpp:406] bn2 <- conv2
I0630 23:03:45.455381  7564 net.cpp:367] bn2 -> conv2 (in-place)
I0630 23:03:45.456382  7564 net.cpp:122] Setting up bn2
I0630 23:03:45.456382  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.456382  7564 net.cpp:137] Memory required for data: 114279600
I0630 23:03:45.456382  7564 layer_factory.cpp:58] Creating layer scale2
I0630 23:03:45.456382  7564 net.cpp:84] Creating Layer scale2
I0630 23:03:45.456382  7564 net.cpp:406] scale2 <- conv2
I0630 23:03:45.456382  7564 net.cpp:367] scale2 -> conv2 (in-place)
I0630 23:03:45.456382  7564 layer_factory.cpp:58] Creating layer scale2
I0630 23:03:45.456382  7564 net.cpp:122] Setting up scale2
I0630 23:03:45.456382  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.456382  7564 net.cpp:137] Memory required for data: 127386800
I0630 23:03:45.456382  7564 layer_factory.cpp:58] Creating layer relu2
I0630 23:03:45.456382  7564 net.cpp:84] Creating Layer relu2
I0630 23:03:45.456382  7564 net.cpp:406] relu2 <- conv2
I0630 23:03:45.456382  7564 net.cpp:367] relu2 -> conv2 (in-place)
I0630 23:03:45.456382  7564 net.cpp:122] Setting up relu2
I0630 23:03:45.456382  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.456382  7564 net.cpp:137] Memory required for data: 140494000
I0630 23:03:45.456382  7564 layer_factory.cpp:58] Creating layer conv2_1
I0630 23:03:45.456382  7564 net.cpp:84] Creating Layer conv2_1
I0630 23:03:45.456382  7564 net.cpp:406] conv2_1 <- conv2
I0630 23:03:45.456382  7564 net.cpp:380] conv2_1 -> conv2_1
I0630 23:03:45.458384  7564 net.cpp:122] Setting up conv2_1
I0630 23:03:45.458384  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.458384  7564 net.cpp:137] Memory required for data: 153601200
I0630 23:03:45.458384  7564 layer_factory.cpp:58] Creating layer bn2_1
I0630 23:03:45.458384  7564 net.cpp:84] Creating Layer bn2_1
I0630 23:03:45.458384  7564 net.cpp:406] bn2_1 <- conv2_1
I0630 23:03:45.458384  7564 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0630 23:03:45.458887  7564 net.cpp:122] Setting up bn2_1
I0630 23:03:45.458887  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.458887  7564 net.cpp:137] Memory required for data: 166708400
I0630 23:03:45.458887  7564 layer_factory.cpp:58] Creating layer scale2_1
I0630 23:03:45.458887  7564 net.cpp:84] Creating Layer scale2_1
I0630 23:03:45.458887  7564 net.cpp:406] scale2_1 <- conv2_1
I0630 23:03:45.458887  7564 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0630 23:03:45.458887  7564 layer_factory.cpp:58] Creating layer scale2_1
I0630 23:03:45.459386  7564 net.cpp:122] Setting up scale2_1
I0630 23:03:45.459386  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.459386  7564 net.cpp:137] Memory required for data: 179815600
I0630 23:03:45.459386  7564 layer_factory.cpp:58] Creating layer relu2_1
I0630 23:03:45.459386  7564 net.cpp:84] Creating Layer relu2_1
I0630 23:03:45.459386  7564 net.cpp:406] relu2_1 <- conv2_1
I0630 23:03:45.459386  7564 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0630 23:03:45.459386  7564 net.cpp:122] Setting up relu2_1
I0630 23:03:45.459386  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.459386  7564 net.cpp:137] Memory required for data: 192922800
I0630 23:03:45.459386  7564 layer_factory.cpp:58] Creating layer conv2_2
I0630 23:03:45.459386  7564 net.cpp:84] Creating Layer conv2_2
I0630 23:03:45.459386  7564 net.cpp:406] conv2_2 <- conv2_1
I0630 23:03:45.459386  7564 net.cpp:380] conv2_2 -> conv2_2
I0630 23:03:45.461388  7564 net.cpp:122] Setting up conv2_2
I0630 23:03:45.461388  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.461388  7564 net.cpp:137] Memory required for data: 206030000
I0630 23:03:45.461388  7564 layer_factory.cpp:58] Creating layer bn2_2
I0630 23:03:45.461388  7564 net.cpp:84] Creating Layer bn2_2
I0630 23:03:45.461388  7564 net.cpp:406] bn2_2 <- conv2_2
I0630 23:03:45.461388  7564 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0630 23:03:45.461900  7564 net.cpp:122] Setting up bn2_2
I0630 23:03:45.461900  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.461900  7564 net.cpp:137] Memory required for data: 219137200
I0630 23:03:45.461900  7564 layer_factory.cpp:58] Creating layer scale2_2
I0630 23:03:45.461900  7564 net.cpp:84] Creating Layer scale2_2
I0630 23:03:45.461900  7564 net.cpp:406] scale2_2 <- conv2_2
I0630 23:03:45.461900  7564 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0630 23:03:45.461900  7564 layer_factory.cpp:58] Creating layer scale2_2
I0630 23:03:45.461900  7564 net.cpp:122] Setting up scale2_2
I0630 23:03:45.461900  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.461900  7564 net.cpp:137] Memory required for data: 232244400
I0630 23:03:45.461900  7564 layer_factory.cpp:58] Creating layer relu2_2
I0630 23:03:45.461900  7564 net.cpp:84] Creating Layer relu2_2
I0630 23:03:45.461900  7564 net.cpp:406] relu2_2 <- conv2_2
I0630 23:03:45.461900  7564 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0630 23:03:45.462656  7564 net.cpp:122] Setting up relu2_2
I0630 23:03:45.462656  7564 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 23:03:45.462656  7564 net.cpp:137] Memory required for data: 245351600
I0630 23:03:45.462656  7564 layer_factory.cpp:58] Creating layer pool2_1
I0630 23:03:45.462656  7564 net.cpp:84] Creating Layer pool2_1
I0630 23:03:45.462656  7564 net.cpp:406] pool2_1 <- conv2_2
I0630 23:03:45.462656  7564 net.cpp:380] pool2_1 -> pool2_1
I0630 23:03:45.462656  7564 net.cpp:122] Setting up pool2_1
I0630 23:03:45.462656  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.462656  7564 net.cpp:137] Memory required for data: 248628400
I0630 23:03:45.462656  7564 layer_factory.cpp:58] Creating layer conv3
I0630 23:03:45.462656  7564 net.cpp:84] Creating Layer conv3
I0630 23:03:45.462656  7564 net.cpp:406] conv3 <- pool2_1
I0630 23:03:45.462656  7564 net.cpp:380] conv3 -> conv3
I0630 23:03:45.463668  7564 net.cpp:122] Setting up conv3
I0630 23:03:45.463668  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.463668  7564 net.cpp:137] Memory required for data: 251905200
I0630 23:03:45.463668  7564 layer_factory.cpp:58] Creating layer bn3
I0630 23:03:45.463668  7564 net.cpp:84] Creating Layer bn3
I0630 23:03:45.463668  7564 net.cpp:406] bn3 <- conv3
I0630 23:03:45.463668  7564 net.cpp:367] bn3 -> conv3 (in-place)
I0630 23:03:45.464159  7564 net.cpp:122] Setting up bn3
I0630 23:03:45.464159  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.464159  7564 net.cpp:137] Memory required for data: 255182000
I0630 23:03:45.464159  7564 layer_factory.cpp:58] Creating layer scale3
I0630 23:03:45.464159  7564 net.cpp:84] Creating Layer scale3
I0630 23:03:45.464159  7564 net.cpp:406] scale3 <- conv3
I0630 23:03:45.464159  7564 net.cpp:367] scale3 -> conv3 (in-place)
I0630 23:03:45.464159  7564 layer_factory.cpp:58] Creating layer scale3
I0630 23:03:45.464159  7564 net.cpp:122] Setting up scale3
I0630 23:03:45.464159  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.464159  7564 net.cpp:137] Memory required for data: 258458800
I0630 23:03:45.464159  7564 layer_factory.cpp:58] Creating layer relu3
I0630 23:03:45.464159  7564 net.cpp:84] Creating Layer relu3
I0630 23:03:45.464159  7564 net.cpp:406] relu3 <- conv3
I0630 23:03:45.464159  7564 net.cpp:367] relu3 -> conv3 (in-place)
I0630 23:03:45.464674  7564 net.cpp:122] Setting up relu3
I0630 23:03:45.464674  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.464674  7564 net.cpp:137] Memory required for data: 261735600
I0630 23:03:45.464674  7564 layer_factory.cpp:58] Creating layer conv4
I0630 23:03:45.464674  7564 net.cpp:84] Creating Layer conv4
I0630 23:03:45.464674  7564 net.cpp:406] conv4 <- conv3
I0630 23:03:45.464674  7564 net.cpp:380] conv4 -> conv4
I0630 23:03:45.465989  7564 net.cpp:122] Setting up conv4
I0630 23:03:45.465989  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.465989  7564 net.cpp:137] Memory required for data: 265012400
I0630 23:03:45.465989  7564 layer_factory.cpp:58] Creating layer bn4
I0630 23:03:45.465989  7564 net.cpp:84] Creating Layer bn4
I0630 23:03:45.465989  7564 net.cpp:406] bn4 <- conv4
I0630 23:03:45.465989  7564 net.cpp:367] bn4 -> conv4 (in-place)
I0630 23:03:45.465989  7564 net.cpp:122] Setting up bn4
I0630 23:03:45.465989  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.465989  7564 net.cpp:137] Memory required for data: 268289200
I0630 23:03:45.465989  7564 layer_factory.cpp:58] Creating layer scale4
I0630 23:03:45.466491  7564 net.cpp:84] Creating Layer scale4
I0630 23:03:45.466491  7564 net.cpp:406] scale4 <- conv4
I0630 23:03:45.466491  7564 net.cpp:367] scale4 -> conv4 (in-place)
I0630 23:03:45.466491  7564 layer_factory.cpp:58] Creating layer scale4
I0630 23:03:45.466491  7564 net.cpp:122] Setting up scale4
I0630 23:03:45.466491  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.466491  7564 net.cpp:137] Memory required for data: 271566000
I0630 23:03:45.466491  7564 layer_factory.cpp:58] Creating layer relu4
I0630 23:03:45.466491  7564 net.cpp:84] Creating Layer relu4
I0630 23:03:45.466491  7564 net.cpp:406] relu4 <- conv4
I0630 23:03:45.466491  7564 net.cpp:367] relu4 -> conv4 (in-place)
I0630 23:03:45.466491  7564 net.cpp:122] Setting up relu4
I0630 23:03:45.466491  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.466491  7564 net.cpp:137] Memory required for data: 274842800
I0630 23:03:45.466491  7564 layer_factory.cpp:58] Creating layer conv4_1
I0630 23:03:45.466491  7564 net.cpp:84] Creating Layer conv4_1
I0630 23:03:45.466491  7564 net.cpp:406] conv4_1 <- conv4
I0630 23:03:45.466491  7564 net.cpp:380] conv4_1 -> conv4_1
I0630 23:03:45.468080  7564 net.cpp:122] Setting up conv4_1
I0630 23:03:45.468080  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.468080  7564 net.cpp:137] Memory required for data: 278119600
I0630 23:03:45.468080  7564 layer_factory.cpp:58] Creating layer bn4_1
I0630 23:03:45.468080  7564 net.cpp:84] Creating Layer bn4_1
I0630 23:03:45.468080  7564 net.cpp:406] bn4_1 <- conv4_1
I0630 23:03:45.468080  7564 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0630 23:03:45.468080  7564 net.cpp:122] Setting up bn4_1
I0630 23:03:45.468080  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.468080  7564 net.cpp:137] Memory required for data: 281396400
I0630 23:03:45.468080  7564 layer_factory.cpp:58] Creating layer scale4_1
I0630 23:03:45.468080  7564 net.cpp:84] Creating Layer scale4_1
I0630 23:03:45.468080  7564 net.cpp:406] scale4_1 <- conv4_1
I0630 23:03:45.468080  7564 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0630 23:03:45.468080  7564 layer_factory.cpp:58] Creating layer scale4_1
I0630 23:03:45.468080  7564 net.cpp:122] Setting up scale4_1
I0630 23:03:45.468080  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.468080  7564 net.cpp:137] Memory required for data: 284673200
I0630 23:03:45.468080  7564 layer_factory.cpp:58] Creating layer relu4_1
I0630 23:03:45.468080  7564 net.cpp:84] Creating Layer relu4_1
I0630 23:03:45.468080  7564 net.cpp:406] relu4_1 <- conv4_1
I0630 23:03:45.468080  7564 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0630 23:03:45.468581  7564 net.cpp:122] Setting up relu4_1
I0630 23:03:45.468581  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.468581  7564 net.cpp:137] Memory required for data: 287950000
I0630 23:03:45.468581  7564 layer_factory.cpp:58] Creating layer conv4_2
I0630 23:03:45.468581  7564 net.cpp:84] Creating Layer conv4_2
I0630 23:03:45.468581  7564 net.cpp:406] conv4_2 <- conv4_1
I0630 23:03:45.468581  7564 net.cpp:380] conv4_2 -> conv4_2
I0630 23:03:45.469383  7564 net.cpp:122] Setting up conv4_2
I0630 23:03:45.469383  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.469383  7564 net.cpp:137] Memory required for data: 291226800
I0630 23:03:45.469383  7564 layer_factory.cpp:58] Creating layer bn4_2
I0630 23:03:45.469383  7564 net.cpp:84] Creating Layer bn4_2
I0630 23:03:45.469383  7564 net.cpp:406] bn4_2 <- conv4_2
I0630 23:03:45.469383  7564 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0630 23:03:45.469885  7564 net.cpp:122] Setting up bn4_2
I0630 23:03:45.469885  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.469885  7564 net.cpp:137] Memory required for data: 294503600
I0630 23:03:45.469885  7564 layer_factory.cpp:58] Creating layer scale4_2
I0630 23:03:45.469885  7564 net.cpp:84] Creating Layer scale4_2
I0630 23:03:45.469885  7564 net.cpp:406] scale4_2 <- conv4_2
I0630 23:03:45.469885  7564 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0630 23:03:45.469885  7564 layer_factory.cpp:58] Creating layer scale4_2
I0630 23:03:45.469885  7564 net.cpp:122] Setting up scale4_2
I0630 23:03:45.469885  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.469885  7564 net.cpp:137] Memory required for data: 297780400
I0630 23:03:45.469885  7564 layer_factory.cpp:58] Creating layer relu4_2
I0630 23:03:45.469885  7564 net.cpp:84] Creating Layer relu4_2
I0630 23:03:45.469885  7564 net.cpp:406] relu4_2 <- conv4_2
I0630 23:03:45.469885  7564 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0630 23:03:45.469885  7564 net.cpp:122] Setting up relu4_2
I0630 23:03:45.469885  7564 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 23:03:45.469885  7564 net.cpp:137] Memory required for data: 301057200
I0630 23:03:45.469885  7564 layer_factory.cpp:58] Creating layer pool4_12
I0630 23:03:45.469885  7564 net.cpp:84] Creating Layer pool4_12
I0630 23:03:45.469885  7564 net.cpp:406] pool4_12 <- conv4_2
I0630 23:03:45.469885  7564 net.cpp:380] pool4_12 -> pool4_12
I0630 23:03:45.470386  7564 net.cpp:122] Setting up pool4_12
I0630 23:03:45.470386  7564 net.cpp:129] Top shape: 100 32 8 8 (204800)
I0630 23:03:45.470386  7564 net.cpp:137] Memory required for data: 301876400
I0630 23:03:45.470386  7564 layer_factory.cpp:58] Creating layer conv4_0
I0630 23:03:45.470386  7564 net.cpp:84] Creating Layer conv4_0
I0630 23:03:45.470386  7564 net.cpp:406] conv4_0 <- pool4_12
I0630 23:03:45.470386  7564 net.cpp:380] conv4_0 -> conv4_0
I0630 23:03:45.471386  7564 net.cpp:122] Setting up conv4_0
I0630 23:03:45.471386  7564 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 23:03:45.471386  7564 net.cpp:137] Memory required for data: 302823600
I0630 23:03:45.471386  7564 layer_factory.cpp:58] Creating layer bn4_0
I0630 23:03:45.471386  7564 net.cpp:84] Creating Layer bn4_0
I0630 23:03:45.471386  7564 net.cpp:406] bn4_0 <- conv4_0
I0630 23:03:45.471386  7564 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0630 23:03:45.471386  7564 net.cpp:122] Setting up bn4_0
I0630 23:03:45.471386  7564 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 23:03:45.471386  7564 net.cpp:137] Memory required for data: 303770800
I0630 23:03:45.471386  7564 layer_factory.cpp:58] Creating layer scale4_0
I0630 23:03:45.471386  7564 net.cpp:84] Creating Layer scale4_0
I0630 23:03:45.471386  7564 net.cpp:406] scale4_0 <- conv4_0
I0630 23:03:45.471386  7564 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0630 23:03:45.471386  7564 layer_factory.cpp:58] Creating layer scale4_0
I0630 23:03:45.471887  7564 net.cpp:122] Setting up scale4_0
I0630 23:03:45.471887  7564 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 23:03:45.471887  7564 net.cpp:137] Memory required for data: 304718000
I0630 23:03:45.471887  7564 layer_factory.cpp:58] Creating layer relu4_0
I0630 23:03:45.471887  7564 net.cpp:84] Creating Layer relu4_0
I0630 23:03:45.471887  7564 net.cpp:406] relu4_0 <- conv4_0
I0630 23:03:45.471887  7564 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0630 23:03:45.471887  7564 net.cpp:122] Setting up relu4_0
I0630 23:03:45.471887  7564 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 23:03:45.471887  7564 net.cpp:137] Memory required for data: 305665200
I0630 23:03:45.471887  7564 layer_factory.cpp:58] Creating layer cccp4
I0630 23:03:45.471887  7564 net.cpp:84] Creating Layer cccp4
I0630 23:03:45.471887  7564 net.cpp:406] cccp4 <- conv4_0
I0630 23:03:45.471887  7564 net.cpp:380] cccp4 -> cccp4
I0630 23:03:45.473392  7564 net.cpp:122] Setting up cccp4
I0630 23:03:45.473392  7564 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 23:03:45.473392  7564 net.cpp:137] Memory required for data: 306894000
I0630 23:03:45.473392  7564 layer_factory.cpp:58] Creating layer bn_cccp4
I0630 23:03:45.473392  7564 net.cpp:84] Creating Layer bn_cccp4
I0630 23:03:45.473392  7564 net.cpp:406] bn_cccp4 <- cccp4
I0630 23:03:45.473392  7564 net.cpp:367] bn_cccp4 -> cccp4 (in-place)
I0630 23:03:45.473392  7564 net.cpp:122] Setting up bn_cccp4
I0630 23:03:45.473392  7564 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 23:03:45.473392  7564 net.cpp:137] Memory required for data: 308122800
I0630 23:03:45.473392  7564 layer_factory.cpp:58] Creating layer scale_cccp4
I0630 23:03:45.473392  7564 net.cpp:84] Creating Layer scale_cccp4
I0630 23:03:45.473392  7564 net.cpp:406] scale_cccp4 <- cccp4
I0630 23:03:45.473392  7564 net.cpp:367] scale_cccp4 -> cccp4 (in-place)
I0630 23:03:45.473392  7564 layer_factory.cpp:58] Creating layer scale_cccp4
I0630 23:03:45.473888  7564 net.cpp:122] Setting up scale_cccp4
I0630 23:03:45.473888  7564 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 23:03:45.473888  7564 net.cpp:137] Memory required for data: 309351600
I0630 23:03:45.473888  7564 layer_factory.cpp:58] Creating layer relu_cccp4
I0630 23:03:45.473888  7564 net.cpp:84] Creating Layer relu_cccp4
I0630 23:03:45.473888  7564 net.cpp:406] relu_cccp4 <- cccp4
I0630 23:03:45.473888  7564 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0630 23:03:45.473888  7564 net.cpp:122] Setting up relu_cccp4
I0630 23:03:45.473888  7564 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 23:03:45.473888  7564 net.cpp:137] Memory required for data: 310580400
I0630 23:03:45.473888  7564 layer_factory.cpp:58] Creating layer cccp5
I0630 23:03:45.473888  7564 net.cpp:84] Creating Layer cccp5
I0630 23:03:45.473888  7564 net.cpp:406] cccp5 <- cccp4
I0630 23:03:45.473888  7564 net.cpp:380] cccp5 -> cccp5
I0630 23:03:45.475314  7564 net.cpp:122] Setting up cccp5
I0630 23:03:45.475314  7564 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 23:03:45.475314  7564 net.cpp:137] Memory required for data: 311834800
I0630 23:03:45.475314  7564 layer_factory.cpp:58] Creating layer bn_cccp5
I0630 23:03:45.475314  7564 net.cpp:84] Creating Layer bn_cccp5
I0630 23:03:45.475314  7564 net.cpp:406] bn_cccp5 <- cccp5
I0630 23:03:45.475314  7564 net.cpp:367] bn_cccp5 -> cccp5 (in-place)
I0630 23:03:45.475314  7564 net.cpp:122] Setting up bn_cccp5
I0630 23:03:45.475314  7564 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 23:03:45.475314  7564 net.cpp:137] Memory required for data: 313089200
I0630 23:03:45.475314  7564 layer_factory.cpp:58] Creating layer scale_cccp5
I0630 23:03:45.475314  7564 net.cpp:84] Creating Layer scale_cccp5
I0630 23:03:45.475314  7564 net.cpp:406] scale_cccp5 <- cccp5
I0630 23:03:45.475314  7564 net.cpp:367] scale_cccp5 -> cccp5 (in-place)
I0630 23:03:45.475314  7564 layer_factory.cpp:58] Creating layer scale_cccp5
I0630 23:03:45.475314  7564 net.cpp:122] Setting up scale_cccp5
I0630 23:03:45.475314  7564 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 23:03:45.475314  7564 net.cpp:137] Memory required for data: 314343600
I0630 23:03:45.475314  7564 layer_factory.cpp:58] Creating layer relu_cccp5
I0630 23:03:45.475314  7564 net.cpp:84] Creating Layer relu_cccp5
I0630 23:03:45.475314  7564 net.cpp:406] relu_cccp5 <- cccp5
I0630 23:03:45.475314  7564 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0630 23:03:45.476316  7564 net.cpp:122] Setting up relu_cccp5
I0630 23:03:45.476316  7564 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 23:03:45.476316  7564 net.cpp:137] Memory required for data: 315598000
I0630 23:03:45.476316  7564 layer_factory.cpp:58] Creating layer cccp6
I0630 23:03:45.476316  7564 net.cpp:84] Creating Layer cccp6
I0630 23:03:45.476316  7564 net.cpp:406] cccp6 <- cccp5
I0630 23:03:45.476316  7564 net.cpp:380] cccp6 -> cccp6
I0630 23:03:45.477316  7564 net.cpp:122] Setting up cccp6
I0630 23:03:45.477316  7564 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 23:03:45.477316  7564 net.cpp:137] Memory required for data: 316878000
I0630 23:03:45.477316  7564 layer_factory.cpp:58] Creating layer bn_cccp6
I0630 23:03:45.477316  7564 net.cpp:84] Creating Layer bn_cccp6
I0630 23:03:45.477316  7564 net.cpp:406] bn_cccp6 <- cccp6
I0630 23:03:45.477316  7564 net.cpp:367] bn_cccp6 -> cccp6 (in-place)
I0630 23:03:45.478317  7564 net.cpp:122] Setting up bn_cccp6
I0630 23:03:45.478317  7564 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 23:03:45.478317  7564 net.cpp:137] Memory required for data: 318158000
I0630 23:03:45.478317  7564 layer_factory.cpp:58] Creating layer scale_cccp6
I0630 23:03:45.478317  7564 net.cpp:84] Creating Layer scale_cccp6
I0630 23:03:45.478317  7564 net.cpp:406] scale_cccp6 <- cccp6
I0630 23:03:45.478317  7564 net.cpp:367] scale_cccp6 -> cccp6 (in-place)
I0630 23:03:45.478317  7564 layer_factory.cpp:58] Creating layer scale_cccp6
I0630 23:03:45.478317  7564 net.cpp:122] Setting up scale_cccp6
I0630 23:03:45.478317  7564 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 23:03:45.478317  7564 net.cpp:137] Memory required for data: 319438000
I0630 23:03:45.478317  7564 layer_factory.cpp:58] Creating layer relu_cccp6
I0630 23:03:45.478317  7564 net.cpp:84] Creating Layer relu_cccp6
I0630 23:03:45.478317  7564 net.cpp:406] relu_cccp6 <- cccp6
I0630 23:03:45.478317  7564 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0630 23:03:45.478317  7564 net.cpp:122] Setting up relu_cccp6
I0630 23:03:45.478317  7564 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 23:03:45.478317  7564 net.cpp:137] Memory required for data: 320718000
I0630 23:03:45.478317  7564 layer_factory.cpp:58] Creating layer poolcp6
I0630 23:03:45.478317  7564 net.cpp:84] Creating Layer poolcp6
I0630 23:03:45.478317  7564 net.cpp:406] poolcp6 <- cccp6
I0630 23:03:45.478317  7564 net.cpp:380] poolcp6 -> poolcp6
I0630 23:03:45.478317  7564 net.cpp:122] Setting up poolcp6
I0630 23:03:45.478317  7564 net.cpp:129] Top shape: 100 50 1 1 (5000)
I0630 23:03:45.478317  7564 net.cpp:137] Memory required for data: 320738000
I0630 23:03:45.478317  7564 layer_factory.cpp:58] Creating layer ip1
I0630 23:03:45.478317  7564 net.cpp:84] Creating Layer ip1
I0630 23:03:45.478317  7564 net.cpp:406] ip1 <- poolcp6
I0630 23:03:45.478317  7564 net.cpp:380] ip1 -> ip1
I0630 23:03:45.478317  7564 net.cpp:122] Setting up ip1
I0630 23:03:45.478317  7564 net.cpp:129] Top shape: 100 10 (1000)
I0630 23:03:45.478317  7564 net.cpp:137] Memory required for data: 320742000
I0630 23:03:45.478317  7564 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0630 23:03:45.478317  7564 net.cpp:84] Creating Layer ip1_ip1_0_split
I0630 23:03:45.478317  7564 net.cpp:406] ip1_ip1_0_split <- ip1
I0630 23:03:45.478317  7564 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0630 23:03:45.478317  7564 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0630 23:03:45.478317  7564 net.cpp:122] Setting up ip1_ip1_0_split
I0630 23:03:45.478317  7564 net.cpp:129] Top shape: 100 10 (1000)
I0630 23:03:45.478317  7564 net.cpp:129] Top shape: 100 10 (1000)
I0630 23:03:45.478317  7564 net.cpp:137] Memory required for data: 320750000
I0630 23:03:45.478317  7564 layer_factory.cpp:58] Creating layer accuracy
I0630 23:03:45.478317  7564 net.cpp:84] Creating Layer accuracy
I0630 23:03:45.478317  7564 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0630 23:03:45.478317  7564 net.cpp:406] accuracy <- label_cifar_1_split_0
I0630 23:03:45.478317  7564 net.cpp:380] accuracy -> accuracy
I0630 23:03:45.478317  7564 net.cpp:122] Setting up accuracy
I0630 23:03:45.478317  7564 net.cpp:129] Top shape: (1)
I0630 23:03:45.478317  7564 net.cpp:137] Memory required for data: 320750004
I0630 23:03:45.478317  7564 layer_factory.cpp:58] Creating layer loss
I0630 23:03:45.478317  7564 net.cpp:84] Creating Layer loss
I0630 23:03:45.478317  7564 net.cpp:406] loss <- ip1_ip1_0_split_1
I0630 23:03:45.478317  7564 net.cpp:406] loss <- label_cifar_1_split_1
I0630 23:03:45.478317  7564 net.cpp:380] loss -> loss
I0630 23:03:45.478317  7564 layer_factory.cpp:58] Creating layer loss
I0630 23:03:45.479318  7564 net.cpp:122] Setting up loss
I0630 23:03:45.479318  7564 net.cpp:129] Top shape: (1)
I0630 23:03:45.479318  7564 net.cpp:132]     with loss weight 1
I0630 23:03:45.479318  7564 net.cpp:137] Memory required for data: 320750008
I0630 23:03:45.479318  7564 net.cpp:198] loss needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:200] accuracy does not need backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] ip1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] poolcp6 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu_cccp6 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale_cccp6 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn_cccp6 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] cccp6 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu_cccp5 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale_cccp5 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn_cccp5 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] cccp5 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu_cccp4 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale_cccp4 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn_cccp4 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] cccp4 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu4_0 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale4_0 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn4_0 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] conv4_0 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] pool4_12 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu4_2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale4_2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn4_2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] conv4_2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu4_1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale4_1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn4_1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] conv4_1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu4 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale4 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn4 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] conv4 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu3 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale3 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn3 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] conv3 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] pool2_1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu2_2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale2_2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn2_2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] conv2_2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu2_1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale2_1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn2_1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] conv2_1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] conv2 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu1_0 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale1_0 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn1_0 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] conv1_0 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] relu1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] scale1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] bn1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:198] conv1 needs backward computation.
I0630 23:03:45.479318  7564 net.cpp:200] label_cifar_1_split does not need backward computation.
I0630 23:03:45.479318  7564 net.cpp:200] cifar does not need backward computation.
I0630 23:03:45.479318  7564 net.cpp:242] This network produces output accuracy
I0630 23:03:45.479318  7564 net.cpp:242] This network produces output loss
I0630 23:03:45.479318  7564 net.cpp:255] Network initialization done.
I0630 23:03:45.479318  7564 solver.cpp:56] Solver scaffolding done.
I0630 23:03:45.482321  7564 caffe.cpp:249] Starting Optimization
I0630 23:03:45.482321  7564 solver.cpp:272] Solving CIFAR10_SimpleNet_13_128k_first_1x1
I0630 23:03:45.482321  7564 solver.cpp:273] Learning Rate Policy: multistep
I0630 23:03:45.483332  7564 solver.cpp:330] Iteration 0, Testing net (#0)
I0630 23:03:45.485334  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:03:46.420964  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:03:46.454988  7564 solver.cpp:397]     Test net output #0: accuracy = 0.0965
I0630 23:03:46.454988  7564 solver.cpp:397]     Test net output #1: loss = 78.9086 (* 1 = 78.9086 loss)
I0630 23:03:46.552484  7564 solver.cpp:218] Iteration 0 (0 iter/s, 1.06879s/100 iters), loss = 3.99415
I0630 23:03:46.552484  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.07
I0630 23:03:46.552484  7564 solver.cpp:237]     Train net output #1: loss = 3.99415 (* 1 = 3.99415 loss)
I0630 23:03:46.552484  7564 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0630 23:03:50.375401  7564 solver.cpp:218] Iteration 100 (26.1587 iter/s, 3.82282s/100 iters), loss = 1.78789
I0630 23:03:50.375401  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I0630 23:03:50.375401  7564 solver.cpp:237]     Train net output #1: loss = 1.78789 (* 1 = 1.78789 loss)
I0630 23:03:50.375401  7564 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0630 23:03:54.264587  7564 solver.cpp:218] Iteration 200 (25.7174 iter/s, 3.88842s/100 iters), loss = 1.90021
I0630 23:03:54.264587  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I0630 23:03:54.264587  7564 solver.cpp:237]     Train net output #1: loss = 1.90021 (* 1 = 1.90021 loss)
I0630 23:03:54.264587  7564 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0630 23:03:58.094890  7564 solver.cpp:218] Iteration 300 (26.109 iter/s, 3.83009s/100 iters), loss = 1.46795
I0630 23:03:58.094890  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I0630 23:03:58.094890  7564 solver.cpp:237]     Train net output #1: loss = 1.46795 (* 1 = 1.46795 loss)
I0630 23:03:58.094890  7564 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0630 23:04:01.974148  7564 solver.cpp:218] Iteration 400 (25.7797 iter/s, 3.87902s/100 iters), loss = 1.43453
I0630 23:04:01.974148  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I0630 23:04:01.974148  7564 solver.cpp:237]     Train net output #1: loss = 1.43453 (* 1 = 1.43453 loss)
I0630 23:04:01.974148  7564 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0630 23:04:05.646605  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:04:05.795742  7564 solver.cpp:330] Iteration 500, Testing net (#0)
I0630 23:04:05.795742  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:04:06.674872  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:04:06.708905  7564 solver.cpp:397]     Test net output #0: accuracy = 0.474
I0630 23:04:06.708905  7564 solver.cpp:397]     Test net output #1: loss = 1.42902 (* 1 = 1.42902 loss)
I0630 23:04:06.746438  7564 solver.cpp:218] Iteration 500 (20.9563 iter/s, 4.77183s/100 iters), loss = 1.63026
I0630 23:04:06.746438  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I0630 23:04:06.746438  7564 solver.cpp:237]     Train net output #1: loss = 1.63026 (* 1 = 1.63026 loss)
I0630 23:04:06.746438  7564 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0630 23:04:10.625388  7564 solver.cpp:218] Iteration 600 (25.7821 iter/s, 3.87865s/100 iters), loss = 1.2676
I0630 23:04:10.625388  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I0630 23:04:10.625880  7564 solver.cpp:237]     Train net output #1: loss = 1.2676 (* 1 = 1.2676 loss)
I0630 23:04:10.625880  7564 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0630 23:04:14.445904  7564 solver.cpp:218] Iteration 700 (26.1789 iter/s, 3.81986s/100 iters), loss = 1.41312
I0630 23:04:14.445904  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I0630 23:04:14.445904  7564 solver.cpp:237]     Train net output #1: loss = 1.41312 (* 1 = 1.41312 loss)
I0630 23:04:14.445904  7564 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0630 23:04:18.270242  7564 solver.cpp:218] Iteration 800 (26.151 iter/s, 3.82395s/100 iters), loss = 1.18836
I0630 23:04:18.270242  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0630 23:04:18.270242  7564 solver.cpp:237]     Train net output #1: loss = 1.18836 (* 1 = 1.18836 loss)
I0630 23:04:18.270242  7564 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0630 23:04:22.110344  7564 solver.cpp:218] Iteration 900 (26.0398 iter/s, 3.84027s/100 iters), loss = 1.10773
I0630 23:04:22.110344  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I0630 23:04:22.110344  7564 solver.cpp:237]     Train net output #1: loss = 1.10773 (* 1 = 1.10773 loss)
I0630 23:04:22.110344  7564 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0630 23:04:25.747490  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:04:25.895669  7564 solver.cpp:330] Iteration 1000, Testing net (#0)
I0630 23:04:25.895669  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:04:26.768712  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:04:26.801744  7564 solver.cpp:397]     Test net output #0: accuracy = 0.5541
I0630 23:04:26.801744  7564 solver.cpp:397]     Test net output #1: loss = 1.23223 (* 1 = 1.23223 loss)
I0630 23:04:26.837769  7564 solver.cpp:218] Iteration 1000 (21.1579 iter/s, 4.72637s/100 iters), loss = 1.3283
I0630 23:04:26.837769  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I0630 23:04:26.837769  7564 solver.cpp:237]     Train net output #1: loss = 1.3283 (* 1 = 1.3283 loss)
I0630 23:04:26.837769  7564 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0630 23:04:30.714397  7564 solver.cpp:218] Iteration 1100 (25.7954 iter/s, 3.87666s/100 iters), loss = 1.06775
I0630 23:04:30.714397  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I0630 23:04:30.714397  7564 solver.cpp:237]     Train net output #1: loss = 1.06775 (* 1 = 1.06775 loss)
I0630 23:04:30.714397  7564 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0630 23:04:34.541647  7564 solver.cpp:218] Iteration 1200 (26.1279 iter/s, 3.82732s/100 iters), loss = 1.1744
I0630 23:04:34.541647  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I0630 23:04:34.541647  7564 solver.cpp:237]     Train net output #1: loss = 1.1744 (* 1 = 1.1744 loss)
I0630 23:04:34.541647  7564 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0630 23:04:38.355481  7564 solver.cpp:218] Iteration 1300 (26.2234 iter/s, 3.81339s/100 iters), loss = 1.07739
I0630 23:04:38.355481  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I0630 23:04:38.355481  7564 solver.cpp:237]     Train net output #1: loss = 1.07739 (* 1 = 1.07739 loss)
I0630 23:04:38.355481  7564 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0630 23:04:42.207908  7564 solver.cpp:218] Iteration 1400 (25.9627 iter/s, 3.85169s/100 iters), loss = 1.09712
I0630 23:04:42.208410  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I0630 23:04:42.208410  7564 solver.cpp:237]     Train net output #1: loss = 1.09712 (* 1 = 1.09712 loss)
I0630 23:04:42.208410  7564 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0630 23:04:45.880290  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:04:46.033433  7564 solver.cpp:330] Iteration 1500, Testing net (#0)
I0630 23:04:46.033433  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:04:46.904454  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:04:46.937479  7564 solver.cpp:397]     Test net output #0: accuracy = 0.6061
I0630 23:04:46.937479  7564 solver.cpp:397]     Test net output #1: loss = 1.10117 (* 1 = 1.10117 loss)
I0630 23:04:46.973503  7564 solver.cpp:218] Iteration 1500 (20.9847 iter/s, 4.76537s/100 iters), loss = 1.0986
I0630 23:04:46.973503  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I0630 23:04:46.973503  7564 solver.cpp:237]     Train net output #1: loss = 1.0986 (* 1 = 1.0986 loss)
I0630 23:04:46.973503  7564 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0630 23:04:50.803362  7564 solver.cpp:218] Iteration 1600 (26.1153 iter/s, 3.82917s/100 iters), loss = 0.908385
I0630 23:04:50.803362  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I0630 23:04:50.803362  7564 solver.cpp:237]     Train net output #1: loss = 0.908385 (* 1 = 0.908385 loss)
I0630 23:04:50.803362  7564 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0630 23:04:54.649965  7564 solver.cpp:218] Iteration 1700 (25.9992 iter/s, 3.84628s/100 iters), loss = 1.09377
I0630 23:04:54.649965  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I0630 23:04:54.649965  7564 solver.cpp:237]     Train net output #1: loss = 1.09377 (* 1 = 1.09377 loss)
I0630 23:04:54.649965  7564 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0630 23:04:58.505043  7564 solver.cpp:218] Iteration 1800 (25.9433 iter/s, 3.85455s/100 iters), loss = 0.880338
I0630 23:04:58.505043  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0630 23:04:58.505043  7564 solver.cpp:237]     Train net output #1: loss = 0.880338 (* 1 = 0.880338 loss)
I0630 23:04:58.505043  7564 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0630 23:05:02.387547  7564 solver.cpp:218] Iteration 1900 (25.7569 iter/s, 3.88246s/100 iters), loss = 0.896645
I0630 23:05:02.387547  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0630 23:05:02.387547  7564 solver.cpp:237]     Train net output #1: loss = 0.896645 (* 1 = 0.896645 loss)
I0630 23:05:02.387547  7564 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0630 23:05:06.034005  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:05:06.188261  7564 solver.cpp:330] Iteration 2000, Testing net (#0)
I0630 23:05:06.188261  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:05:07.071924  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:05:07.106458  7564 solver.cpp:397]     Test net output #0: accuracy = 0.6787
I0630 23:05:07.106458  7564 solver.cpp:397]     Test net output #1: loss = 0.903484 (* 1 = 0.903484 loss)
I0630 23:05:07.142953  7564 solver.cpp:218] Iteration 2000 (21.0294 iter/s, 4.75525s/100 iters), loss = 0.920598
I0630 23:05:07.142953  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0630 23:05:07.142953  7564 solver.cpp:237]     Train net output #1: loss = 0.920598 (* 1 = 0.920598 loss)
I0630 23:05:07.142953  7564 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0630 23:05:10.988754  7564 solver.cpp:218] Iteration 2100 (26.0061 iter/s, 3.84525s/100 iters), loss = 0.791061
I0630 23:05:10.988754  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0630 23:05:10.988754  7564 solver.cpp:237]     Train net output #1: loss = 0.791061 (* 1 = 0.791061 loss)
I0630 23:05:10.988754  7564 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0630 23:05:14.810261  7564 solver.cpp:218] Iteration 2200 (26.1728 iter/s, 3.82075s/100 iters), loss = 0.913272
I0630 23:05:14.810261  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0630 23:05:14.810261  7564 solver.cpp:237]     Train net output #1: loss = 0.913272 (* 1 = 0.913272 loss)
I0630 23:05:14.810261  7564 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0630 23:05:18.596086  7564 solver.cpp:218] Iteration 2300 (26.416 iter/s, 3.78559s/100 iters), loss = 0.742461
I0630 23:05:18.596086  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0630 23:05:18.596086  7564 solver.cpp:237]     Train net output #1: loss = 0.742461 (* 1 = 0.742461 loss)
I0630 23:05:18.596086  7564 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0630 23:05:22.388494  7564 solver.cpp:218] Iteration 2400 (26.3745 iter/s, 3.79155s/100 iters), loss = 0.70803
I0630 23:05:22.388494  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0630 23:05:22.388494  7564 solver.cpp:237]     Train net output #1: loss = 0.70803 (* 1 = 0.70803 loss)
I0630 23:05:22.388494  7564 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0630 23:05:26.001713  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:05:26.150880  7564 solver.cpp:330] Iteration 2500, Testing net (#0)
I0630 23:05:26.150880  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:05:27.016265  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:05:27.048808  7564 solver.cpp:397]     Test net output #0: accuracy = 0.6692
I0630 23:05:27.048808  7564 solver.cpp:397]     Test net output #1: loss = 0.97204 (* 1 = 0.97204 loss)
I0630 23:05:27.084831  7564 solver.cpp:218] Iteration 2500 (21.2917 iter/s, 4.69666s/100 iters), loss = 0.820393
I0630 23:05:27.084831  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I0630 23:05:27.084831  7564 solver.cpp:237]     Train net output #1: loss = 0.820393 (* 1 = 0.820393 loss)
I0630 23:05:27.084831  7564 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0630 23:05:30.872304  7564 solver.cpp:218] Iteration 2600 (26.4108 iter/s, 3.78632s/100 iters), loss = 0.773257
I0630 23:05:30.872304  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0630 23:05:30.872304  7564 solver.cpp:237]     Train net output #1: loss = 0.773257 (* 1 = 0.773257 loss)
I0630 23:05:30.872304  7564 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0630 23:05:34.664439  7564 solver.cpp:218] Iteration 2700 (26.3719 iter/s, 3.79192s/100 iters), loss = 0.863864
I0630 23:05:34.664439  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0630 23:05:34.664439  7564 solver.cpp:237]     Train net output #1: loss = 0.863864 (* 1 = 0.863864 loss)
I0630 23:05:34.664439  7564 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0630 23:05:38.463884  7564 solver.cpp:218] Iteration 2800 (26.3242 iter/s, 3.79879s/100 iters), loss = 0.767383
I0630 23:05:38.463884  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0630 23:05:38.463884  7564 solver.cpp:237]     Train net output #1: loss = 0.767383 (* 1 = 0.767383 loss)
I0630 23:05:38.463884  7564 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0630 23:05:42.295251  7564 solver.cpp:218] Iteration 2900 (26.1009 iter/s, 3.83129s/100 iters), loss = 0.661013
I0630 23:05:42.295251  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0630 23:05:42.295251  7564 solver.cpp:237]     Train net output #1: loss = 0.661013 (* 1 = 0.661013 loss)
I0630 23:05:42.295251  7564 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0630 23:05:45.913378  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:05:46.061501  7564 solver.cpp:330] Iteration 3000, Testing net (#0)
I0630 23:05:46.061501  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:05:46.930341  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:05:46.963409  7564 solver.cpp:397]     Test net output #0: accuracy = 0.723
I0630 23:05:46.963409  7564 solver.cpp:397]     Test net output #1: loss = 0.801386 (* 1 = 0.801386 loss)
I0630 23:05:46.999418  7564 solver.cpp:218] Iteration 3000 (21.2571 iter/s, 4.70432s/100 iters), loss = 0.739744
I0630 23:05:47.000429  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0630 23:05:47.000429  7564 solver.cpp:237]     Train net output #1: loss = 0.739744 (* 1 = 0.739744 loss)
I0630 23:05:47.000429  7564 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0630 23:05:50.809736  7564 solver.cpp:218] Iteration 3100 (26.2492 iter/s, 3.80964s/100 iters), loss = 0.581467
I0630 23:05:50.809736  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0630 23:05:50.809736  7564 solver.cpp:237]     Train net output #1: loss = 0.581467 (* 1 = 0.581467 loss)
I0630 23:05:50.809736  7564 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0630 23:05:54.603636  7564 solver.cpp:218] Iteration 3200 (26.3588 iter/s, 3.7938s/100 iters), loss = 0.790076
I0630 23:05:54.604637  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0630 23:05:54.604637  7564 solver.cpp:237]     Train net output #1: loss = 0.790076 (* 1 = 0.790076 loss)
I0630 23:05:54.604637  7564 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0630 23:05:58.415115  7564 solver.cpp:218] Iteration 3300 (26.2426 iter/s, 3.8106s/100 iters), loss = 0.692325
I0630 23:05:58.415115  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0630 23:05:58.415115  7564 solver.cpp:237]     Train net output #1: loss = 0.692325 (* 1 = 0.692325 loss)
I0630 23:05:58.415115  7564 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0630 23:06:02.226246  7564 solver.cpp:218] Iteration 3400 (26.2403 iter/s, 3.81094s/100 iters), loss = 0.651183
I0630 23:06:02.226246  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0630 23:06:02.226246  7564 solver.cpp:237]     Train net output #1: loss = 0.651183 (* 1 = 0.651183 loss)
I0630 23:06:02.226246  7564 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0630 23:06:05.876616  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:06:06.028734  7564 solver.cpp:330] Iteration 3500, Testing net (#0)
I0630 23:06:06.029734  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:06:06.913568  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:06:06.947582  7564 solver.cpp:397]     Test net output #0: accuracy = 0.7375
I0630 23:06:06.947582  7564 solver.cpp:397]     Test net output #1: loss = 0.750746 (* 1 = 0.750746 loss)
I0630 23:06:06.984629  7564 solver.cpp:218] Iteration 3500 (21.0173 iter/s, 4.75798s/100 iters), loss = 0.667598
I0630 23:06:06.984629  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 23:06:06.984629  7564 solver.cpp:237]     Train net output #1: loss = 0.667598 (* 1 = 0.667598 loss)
I0630 23:06:06.984629  7564 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0630 23:06:10.852895  7564 solver.cpp:218] Iteration 3600 (25.8543 iter/s, 3.86783s/100 iters), loss = 0.645885
I0630 23:06:10.852895  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0630 23:06:10.852895  7564 solver.cpp:237]     Train net output #1: loss = 0.645885 (* 1 = 0.645885 loss)
I0630 23:06:10.852895  7564 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0630 23:06:14.641980  7564 solver.cpp:218] Iteration 3700 (26.3925 iter/s, 3.78896s/100 iters), loss = 0.634893
I0630 23:06:14.641980  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 23:06:14.641980  7564 solver.cpp:237]     Train net output #1: loss = 0.634893 (* 1 = 0.634893 loss)
I0630 23:06:14.641980  7564 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0630 23:06:18.442457  7564 solver.cpp:218] Iteration 3800 (26.3158 iter/s, 3.8s/100 iters), loss = 0.628237
I0630 23:06:18.442457  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 23:06:18.442457  7564 solver.cpp:237]     Train net output #1: loss = 0.628237 (* 1 = 0.628237 loss)
I0630 23:06:18.442457  7564 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0630 23:06:22.245654  7564 solver.cpp:218] Iteration 3900 (26.2998 iter/s, 3.80231s/100 iters), loss = 0.588805
I0630 23:06:22.245654  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 23:06:22.245654  7564 solver.cpp:237]     Train net output #1: loss = 0.588805 (* 1 = 0.588805 loss)
I0630 23:06:22.245654  7564 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0630 23:06:25.855165  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:06:26.004319  7564 solver.cpp:330] Iteration 4000, Testing net (#0)
I0630 23:06:26.004319  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:06:26.878823  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:06:26.912495  7564 solver.cpp:397]     Test net output #0: accuracy = 0.7469
I0630 23:06:26.912495  7564 solver.cpp:397]     Test net output #1: loss = 0.742359 (* 1 = 0.742359 loss)
I0630 23:06:26.949532  7564 solver.cpp:218] Iteration 4000 (21.2587 iter/s, 4.70395s/100 iters), loss = 0.619478
I0630 23:06:26.949532  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0630 23:06:26.949532  7564 solver.cpp:237]     Train net output #1: loss = 0.619478 (* 1 = 0.619478 loss)
I0630 23:06:26.949532  7564 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0630 23:06:30.742619  7564 solver.cpp:218] Iteration 4100 (26.3669 iter/s, 3.79263s/100 iters), loss = 0.481824
I0630 23:06:30.742619  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 23:06:30.742619  7564 solver.cpp:237]     Train net output #1: loss = 0.481824 (* 1 = 0.481824 loss)
I0630 23:06:30.742619  7564 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0630 23:06:34.532060  7564 solver.cpp:218] Iteration 4200 (26.394 iter/s, 3.78874s/100 iters), loss = 0.625066
I0630 23:06:34.532060  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 23:06:34.532060  7564 solver.cpp:237]     Train net output #1: loss = 0.625066 (* 1 = 0.625066 loss)
I0630 23:06:34.532060  7564 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0630 23:06:38.314713  7564 solver.cpp:218] Iteration 4300 (26.4401 iter/s, 3.78214s/100 iters), loss = 0.578622
I0630 23:06:38.314713  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0630 23:06:38.314713  7564 solver.cpp:237]     Train net output #1: loss = 0.578622 (* 1 = 0.578622 loss)
I0630 23:06:38.314713  7564 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0630 23:06:42.102587  7564 solver.cpp:218] Iteration 4400 (26.4004 iter/s, 3.78783s/100 iters), loss = 0.518632
I0630 23:06:42.102587  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 23:06:42.103088  7564 solver.cpp:237]     Train net output #1: loss = 0.518632 (* 1 = 0.518632 loss)
I0630 23:06:42.103088  7564 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0630 23:06:45.707758  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:06:45.855382  7564 solver.cpp:330] Iteration 4500, Testing net (#0)
I0630 23:06:45.855382  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:06:46.723642  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:06:46.756662  7564 solver.cpp:397]     Test net output #0: accuracy = 0.7726
I0630 23:06:46.756662  7564 solver.cpp:397]     Test net output #1: loss = 0.653876 (* 1 = 0.653876 loss)
I0630 23:06:46.792693  7564 solver.cpp:218] Iteration 4500 (21.3225 iter/s, 4.68988s/100 iters), loss = 0.539026
I0630 23:06:46.792693  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0630 23:06:46.792693  7564 solver.cpp:237]     Train net output #1: loss = 0.539026 (* 1 = 0.539026 loss)
I0630 23:06:46.792693  7564 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0630 23:06:50.587405  7564 solver.cpp:218] Iteration 4600 (26.3571 iter/s, 3.79404s/100 iters), loss = 0.48855
I0630 23:06:50.587405  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 23:06:50.587405  7564 solver.cpp:237]     Train net output #1: loss = 0.48855 (* 1 = 0.48855 loss)
I0630 23:06:50.587405  7564 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0630 23:06:54.419657  7564 solver.cpp:218] Iteration 4700 (26.0995 iter/s, 3.83149s/100 iters), loss = 0.529905
I0630 23:06:54.419657  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0630 23:06:54.419657  7564 solver.cpp:237]     Train net output #1: loss = 0.529905 (* 1 = 0.529905 loss)
I0630 23:06:54.419657  7564 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0630 23:06:58.248649  7564 solver.cpp:218] Iteration 4800 (26.1148 iter/s, 3.82924s/100 iters), loss = 0.543895
I0630 23:06:58.248649  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:06:58.248649  7564 solver.cpp:237]     Train net output #1: loss = 0.543895 (* 1 = 0.543895 loss)
I0630 23:06:58.248649  7564 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0630 23:07:02.139128  7564 solver.cpp:218] Iteration 4900 (25.705 iter/s, 3.89029s/100 iters), loss = 0.442916
I0630 23:07:02.139128  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:07:02.139128  7564 solver.cpp:237]     Train net output #1: loss = 0.442916 (* 1 = 0.442916 loss)
I0630 23:07:02.139128  7564 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0630 23:07:05.766314  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:07:05.919916  7564 solver.cpp:330] Iteration 5000, Testing net (#0)
I0630 23:07:05.919916  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:07:06.802649  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:07:06.836668  7564 solver.cpp:397]     Test net output #0: accuracy = 0.7777
I0630 23:07:06.836668  7564 solver.cpp:397]     Test net output #1: loss = 0.642839 (* 1 = 0.642839 loss)
I0630 23:07:06.873720  7564 solver.cpp:218] Iteration 5000 (21.1257 iter/s, 4.73356s/100 iters), loss = 0.582352
I0630 23:07:06.873720  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0630 23:07:06.873720  7564 solver.cpp:237]     Train net output #1: loss = 0.582352 (* 1 = 0.582352 loss)
I0630 23:07:06.873720  7564 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0630 23:07:10.714640  7564 solver.cpp:218] Iteration 5100 (26.0356 iter/s, 3.84089s/100 iters), loss = 0.495411
I0630 23:07:10.714640  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 23:07:10.714640  7564 solver.cpp:237]     Train net output #1: loss = 0.495411 (* 1 = 0.495411 loss)
I0630 23:07:10.714640  7564 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0630 23:07:14.582839  7564 solver.cpp:218] Iteration 5200 (25.8515 iter/s, 3.86825s/100 iters), loss = 0.461711
I0630 23:07:14.583840  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:07:14.583840  7564 solver.cpp:237]     Train net output #1: loss = 0.461711 (* 1 = 0.461711 loss)
I0630 23:07:14.583840  7564 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0630 23:07:18.421432  7564 solver.cpp:218] Iteration 5300 (26.0603 iter/s, 3.83725s/100 iters), loss = 0.531652
I0630 23:07:18.421432  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 23:07:18.421432  7564 solver.cpp:237]     Train net output #1: loss = 0.531652 (* 1 = 0.531652 loss)
I0630 23:07:18.421432  7564 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0630 23:07:22.308809  7564 solver.cpp:218] Iteration 5400 (25.7255 iter/s, 3.8872s/100 iters), loss = 0.46889
I0630 23:07:22.308809  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0630 23:07:22.308809  7564 solver.cpp:237]     Train net output #1: loss = 0.46889 (* 1 = 0.46889 loss)
I0630 23:07:22.308809  7564 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0630 23:07:25.960472  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:07:26.114712  7564 solver.cpp:330] Iteration 5500, Testing net (#0)
I0630 23:07:26.114712  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:07:26.993182  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:07:27.026507  7564 solver.cpp:397]     Test net output #0: accuracy = 0.7873
I0630 23:07:27.026507  7564 solver.cpp:397]     Test net output #1: loss = 0.619591 (* 1 = 0.619591 loss)
I0630 23:07:27.064517  7564 solver.cpp:218] Iteration 5500 (21.0303 iter/s, 4.75505s/100 iters), loss = 0.427892
I0630 23:07:27.064517  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:07:27.064517  7564 solver.cpp:237]     Train net output #1: loss = 0.427892 (* 1 = 0.427892 loss)
I0630 23:07:27.064517  7564 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0630 23:07:30.932009  7564 solver.cpp:218] Iteration 5600 (25.8578 iter/s, 3.8673s/100 iters), loss = 0.459829
I0630 23:07:30.932009  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 23:07:30.932009  7564 solver.cpp:237]     Train net output #1: loss = 0.459829 (* 1 = 0.459829 loss)
I0630 23:07:30.932009  7564 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0630 23:07:34.773169  7564 solver.cpp:218] Iteration 5700 (26.0369 iter/s, 3.8407s/100 iters), loss = 0.559463
I0630 23:07:34.773169  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0630 23:07:34.773169  7564 solver.cpp:237]     Train net output #1: loss = 0.559463 (* 1 = 0.559463 loss)
I0630 23:07:34.773169  7564 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0630 23:07:38.548539  7564 solver.cpp:218] Iteration 5800 (26.4892 iter/s, 3.77512s/100 iters), loss = 0.531576
I0630 23:07:38.548539  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 23:07:38.548539  7564 solver.cpp:237]     Train net output #1: loss = 0.531576 (* 1 = 0.531576 loss)
I0630 23:07:38.548539  7564 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0630 23:07:42.334511  7564 solver.cpp:218] Iteration 5900 (26.4131 iter/s, 3.78601s/100 iters), loss = 0.589122
I0630 23:07:42.334511  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 23:07:42.334511  7564 solver.cpp:237]     Train net output #1: loss = 0.589122 (* 1 = 0.589122 loss)
I0630 23:07:42.334511  7564 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0630 23:07:45.947154  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:07:46.094804  7564 solver.cpp:330] Iteration 6000, Testing net (#0)
I0630 23:07:46.094804  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:07:46.960583  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:07:46.993612  7564 solver.cpp:397]     Test net output #0: accuracy = 0.7765
I0630 23:07:46.993612  7564 solver.cpp:397]     Test net output #1: loss = 0.66562 (* 1 = 0.66562 loss)
I0630 23:07:47.030151  7564 solver.cpp:218] Iteration 6000 (21.302 iter/s, 4.69439s/100 iters), loss = 0.417871
I0630 23:07:47.030151  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:07:47.030151  7564 solver.cpp:237]     Train net output #1: loss = 0.417871 (* 1 = 0.417871 loss)
I0630 23:07:47.030151  7564 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0630 23:07:50.817800  7564 solver.cpp:218] Iteration 6100 (26.4001 iter/s, 3.78786s/100 iters), loss = 0.373108
I0630 23:07:50.817800  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:07:50.817800  7564 solver.cpp:237]     Train net output #1: loss = 0.373108 (* 1 = 0.373108 loss)
I0630 23:07:50.817800  7564 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0630 23:07:54.606832  7564 solver.cpp:218] Iteration 6200 (26.3929 iter/s, 3.78889s/100 iters), loss = 0.472794
I0630 23:07:54.606832  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0630 23:07:54.607833  7564 solver.cpp:237]     Train net output #1: loss = 0.472794 (* 1 = 0.472794 loss)
I0630 23:07:54.607833  7564 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0630 23:07:58.423286  7564 solver.cpp:218] Iteration 6300 (26.207 iter/s, 3.81577s/100 iters), loss = 0.451921
I0630 23:07:58.423286  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:07:58.423286  7564 solver.cpp:237]     Train net output #1: loss = 0.451921 (* 1 = 0.451921 loss)
I0630 23:07:58.423286  7564 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0630 23:08:02.209884  7564 solver.cpp:218] Iteration 6400 (26.4126 iter/s, 3.78606s/100 iters), loss = 0.441274
I0630 23:08:02.209884  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0630 23:08:02.209884  7564 solver.cpp:237]     Train net output #1: loss = 0.441274 (* 1 = 0.441274 loss)
I0630 23:08:02.209884  7564 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0630 23:08:05.810590  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:08:05.959226  7564 solver.cpp:330] Iteration 6500, Testing net (#0)
I0630 23:08:05.959226  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:08:06.826164  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:08:06.859187  7564 solver.cpp:397]     Test net output #0: accuracy = 0.7926
I0630 23:08:06.859187  7564 solver.cpp:397]     Test net output #1: loss = 0.620901 (* 1 = 0.620901 loss)
I0630 23:08:06.895198  7564 solver.cpp:218] Iteration 6500 (21.3466 iter/s, 4.68458s/100 iters), loss = 0.336386
I0630 23:08:06.895198  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:08:06.895198  7564 solver.cpp:237]     Train net output #1: loss = 0.336386 (* 1 = 0.336386 loss)
I0630 23:08:06.895198  7564 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0630 23:08:10.677837  7564 solver.cpp:218] Iteration 6600 (26.4351 iter/s, 3.78285s/100 iters), loss = 0.51783
I0630 23:08:10.677837  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0630 23:08:10.677837  7564 solver.cpp:237]     Train net output #1: loss = 0.51783 (* 1 = 0.51783 loss)
I0630 23:08:10.677837  7564 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0630 23:08:14.461997  7564 solver.cpp:218] Iteration 6700 (26.433 iter/s, 3.78314s/100 iters), loss = 0.440078
I0630 23:08:14.461997  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:08:14.461997  7564 solver.cpp:237]     Train net output #1: loss = 0.440078 (* 1 = 0.440078 loss)
I0630 23:08:14.461997  7564 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0630 23:08:18.259510  7564 solver.cpp:218] Iteration 6800 (26.3352 iter/s, 3.79719s/100 iters), loss = 0.463593
I0630 23:08:18.259510  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 23:08:18.259510  7564 solver.cpp:237]     Train net output #1: loss = 0.463593 (* 1 = 0.463593 loss)
I0630 23:08:18.259510  7564 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0630 23:08:22.047426  7564 solver.cpp:218] Iteration 6900 (26.3979 iter/s, 3.78818s/100 iters), loss = 0.371453
I0630 23:08:22.047426  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:08:22.047426  7564 solver.cpp:237]     Train net output #1: loss = 0.371453 (* 1 = 0.371453 loss)
I0630 23:08:22.047426  7564 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0630 23:08:25.685597  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:08:25.833734  7564 solver.cpp:330] Iteration 7000, Testing net (#0)
I0630 23:08:25.833734  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:08:26.720437  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:08:26.752962  7564 solver.cpp:397]     Test net output #0: accuracy = 0.7973
I0630 23:08:26.752962  7564 solver.cpp:397]     Test net output #1: loss = 0.592124 (* 1 = 0.592124 loss)
I0630 23:08:26.788493  7564 solver.cpp:218] Iteration 7000 (21.0938 iter/s, 4.74074s/100 iters), loss = 0.427246
I0630 23:08:26.789489  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 23:08:26.789489  7564 solver.cpp:237]     Train net output #1: loss = 0.427246 (* 1 = 0.427246 loss)
I0630 23:08:26.789489  7564 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0630 23:08:30.692365  7564 solver.cpp:218] Iteration 7100 (25.6188 iter/s, 3.90339s/100 iters), loss = 0.361828
I0630 23:08:30.692365  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:08:30.692365  7564 solver.cpp:237]     Train net output #1: loss = 0.361828 (* 1 = 0.361828 loss)
I0630 23:08:30.692365  7564 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0630 23:08:34.587460  7564 solver.cpp:218] Iteration 7200 (25.6797 iter/s, 3.89413s/100 iters), loss = 0.435072
I0630 23:08:34.587460  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:08:34.587460  7564 solver.cpp:237]     Train net output #1: loss = 0.435072 (* 1 = 0.435072 loss)
I0630 23:08:34.587460  7564 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0630 23:08:38.454702  7564 solver.cpp:218] Iteration 7300 (25.8613 iter/s, 3.86679s/100 iters), loss = 0.508932
I0630 23:08:38.454702  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:08:38.454702  7564 solver.cpp:237]     Train net output #1: loss = 0.508932 (* 1 = 0.508932 loss)
I0630 23:08:38.454702  7564 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0630 23:08:42.310735  7564 solver.cpp:218] Iteration 7400 (25.9329 iter/s, 3.8561s/100 iters), loss = 0.387972
I0630 23:08:42.310735  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:08:42.310735  7564 solver.cpp:237]     Train net output #1: loss = 0.387972 (* 1 = 0.387972 loss)
I0630 23:08:42.310735  7564 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0630 23:08:45.972074  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:08:46.119817  7564 solver.cpp:330] Iteration 7500, Testing net (#0)
I0630 23:08:46.119817  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:08:46.984551  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:08:47.018610  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8025
I0630 23:08:47.018610  7564 solver.cpp:397]     Test net output #1: loss = 0.583226 (* 1 = 0.583226 loss)
I0630 23:08:47.054652  7564 solver.cpp:218] Iteration 7500 (21.0846 iter/s, 4.74279s/100 iters), loss = 0.351261
I0630 23:08:47.054652  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:08:47.054652  7564 solver.cpp:237]     Train net output #1: loss = 0.351261 (* 1 = 0.351261 loss)
I0630 23:08:47.054652  7564 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0630 23:08:50.845245  7564 solver.cpp:218] Iteration 7600 (26.3825 iter/s, 3.79038s/100 iters), loss = 0.343803
I0630 23:08:50.845245  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:08:50.845245  7564 solver.cpp:237]     Train net output #1: loss = 0.343803 (* 1 = 0.343803 loss)
I0630 23:08:50.845245  7564 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0630 23:08:54.637439  7564 solver.cpp:218] Iteration 7700 (26.3714 iter/s, 3.79199s/100 iters), loss = 0.454654
I0630 23:08:54.637439  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 23:08:54.637439  7564 solver.cpp:237]     Train net output #1: loss = 0.454654 (* 1 = 0.454654 loss)
I0630 23:08:54.637439  7564 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0630 23:08:58.436344  7564 solver.cpp:218] Iteration 7800 (26.3282 iter/s, 3.79821s/100 iters), loss = 0.420087
I0630 23:08:58.436344  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 23:08:58.436344  7564 solver.cpp:237]     Train net output #1: loss = 0.420087 (* 1 = 0.420087 loss)
I0630 23:08:58.436344  7564 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0630 23:09:02.236124  7564 solver.cpp:218] Iteration 7900 (26.317 iter/s, 3.79983s/100 iters), loss = 0.389735
I0630 23:09:02.236124  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:09:02.236124  7564 solver.cpp:237]     Train net output #1: loss = 0.389735 (* 1 = 0.389735 loss)
I0630 23:09:02.236124  7564 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0630 23:09:05.842723  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:09:05.990860  7564 solver.cpp:330] Iteration 8000, Testing net (#0)
I0630 23:09:05.991861  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:09:06.858698  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:09:06.891719  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8118
I0630 23:09:06.892720  7564 solver.cpp:397]     Test net output #1: loss = 0.557874 (* 1 = 0.557874 loss)
I0630 23:09:06.928757  7564 solver.cpp:218] Iteration 8000 (21.3133 iter/s, 4.69191s/100 iters), loss = 0.333365
I0630 23:09:06.928757  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:09:06.928757  7564 solver.cpp:237]     Train net output #1: loss = 0.333365 (* 1 = 0.333365 loss)
I0630 23:09:06.928757  7564 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0630 23:09:10.735810  7564 solver.cpp:218] Iteration 8100 (26.2699 iter/s, 3.80663s/100 iters), loss = 0.433424
I0630 23:09:10.735810  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 23:09:10.735810  7564 solver.cpp:237]     Train net output #1: loss = 0.433424 (* 1 = 0.433424 loss)
I0630 23:09:10.735810  7564 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0630 23:09:14.531888  7564 solver.cpp:218] Iteration 8200 (26.3464 iter/s, 3.79558s/100 iters), loss = 0.410742
I0630 23:09:14.531888  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:09:14.531888  7564 solver.cpp:237]     Train net output #1: loss = 0.410742 (* 1 = 0.410742 loss)
I0630 23:09:14.531888  7564 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0630 23:09:18.335672  7564 solver.cpp:218] Iteration 8300 (26.2912 iter/s, 3.80355s/100 iters), loss = 0.488214
I0630 23:09:18.335672  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 23:09:18.335672  7564 solver.cpp:237]     Train net output #1: loss = 0.488214 (* 1 = 0.488214 loss)
I0630 23:09:18.335672  7564 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0630 23:09:22.140110  7564 solver.cpp:218] Iteration 8400 (26.2877 iter/s, 3.80406s/100 iters), loss = 0.335364
I0630 23:09:22.140110  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:09:22.140110  7564 solver.cpp:237]     Train net output #1: loss = 0.335364 (* 1 = 0.335364 loss)
I0630 23:09:22.140110  7564 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0630 23:09:25.761225  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:09:25.910362  7564 solver.cpp:330] Iteration 8500, Testing net (#0)
I0630 23:09:25.910362  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:09:26.779139  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:09:26.812175  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8101
I0630 23:09:26.812175  7564 solver.cpp:397]     Test net output #1: loss = 0.556465 (* 1 = 0.556465 loss)
I0630 23:09:26.848209  7564 solver.cpp:218] Iteration 8500 (21.2414 iter/s, 4.70778s/100 iters), loss = 0.375298
I0630 23:09:26.848209  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:09:26.848209  7564 solver.cpp:237]     Train net output #1: loss = 0.375298 (* 1 = 0.375298 loss)
I0630 23:09:26.848209  7564 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0630 23:09:30.646000  7564 solver.cpp:218] Iteration 8600 (26.3342 iter/s, 3.79735s/100 iters), loss = 0.357073
I0630 23:09:30.646000  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:09:30.646000  7564 solver.cpp:237]     Train net output #1: loss = 0.357073 (* 1 = 0.357073 loss)
I0630 23:09:30.646000  7564 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0630 23:09:34.436986  7564 solver.cpp:218] Iteration 8700 (26.3777 iter/s, 3.79108s/100 iters), loss = 0.402059
I0630 23:09:34.436986  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 23:09:34.436986  7564 solver.cpp:237]     Train net output #1: loss = 0.402059 (* 1 = 0.402059 loss)
I0630 23:09:34.436986  7564 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0630 23:09:38.236750  7564 solver.cpp:218] Iteration 8800 (26.3212 iter/s, 3.79922s/100 iters), loss = 0.462563
I0630 23:09:38.236750  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 23:09:38.236750  7564 solver.cpp:237]     Train net output #1: loss = 0.462563 (* 1 = 0.462563 loss)
I0630 23:09:38.236750  7564 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0630 23:09:42.024628  7564 solver.cpp:218] Iteration 8900 (26.3997 iter/s, 3.78793s/100 iters), loss = 0.412536
I0630 23:09:42.025629  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:09:42.025629  7564 solver.cpp:237]     Train net output #1: loss = 0.412536 (* 1 = 0.412536 loss)
I0630 23:09:42.025629  7564 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0630 23:09:45.646158  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:09:45.795271  7564 solver.cpp:330] Iteration 9000, Testing net (#0)
I0630 23:09:45.795271  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:09:46.665989  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:09:46.698835  7564 solver.cpp:397]     Test net output #0: accuracy = 0.808
I0630 23:09:46.698835  7564 solver.cpp:397]     Test net output #1: loss = 0.566007 (* 1 = 0.566007 loss)
I0630 23:09:46.734856  7564 solver.cpp:218] Iteration 9000 (21.2343 iter/s, 4.70936s/100 iters), loss = 0.316005
I0630 23:09:46.734856  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:09:46.734856  7564 solver.cpp:237]     Train net output #1: loss = 0.316005 (* 1 = 0.316005 loss)
I0630 23:09:46.734856  7564 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0630 23:09:50.524737  7564 solver.cpp:218] Iteration 9100 (26.3893 iter/s, 3.78941s/100 iters), loss = 0.341775
I0630 23:09:50.524737  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:09:50.524737  7564 solver.cpp:237]     Train net output #1: loss = 0.341775 (* 1 = 0.341775 loss)
I0630 23:09:50.524737  7564 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0630 23:09:54.327752  7564 solver.cpp:218] Iteration 9200 (26.2968 iter/s, 3.80275s/100 iters), loss = 0.478657
I0630 23:09:54.327752  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 23:09:54.327752  7564 solver.cpp:237]     Train net output #1: loss = 0.478657 (* 1 = 0.478657 loss)
I0630 23:09:54.327752  7564 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0630 23:09:58.115178  7564 solver.cpp:218] Iteration 9300 (26.4024 iter/s, 3.78753s/100 iters), loss = 0.425914
I0630 23:09:58.115178  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:09:58.116179  7564 solver.cpp:237]     Train net output #1: loss = 0.425914 (* 1 = 0.425914 loss)
I0630 23:09:58.116179  7564 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0630 23:10:01.938092  7564 solver.cpp:218] Iteration 9400 (26.1673 iter/s, 3.82156s/100 iters), loss = 0.368401
I0630 23:10:01.938092  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:10:01.938092  7564 solver.cpp:237]     Train net output #1: loss = 0.368401 (* 1 = 0.368401 loss)
I0630 23:10:01.938092  7564 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0630 23:10:05.597633  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:10:05.746256  7564 solver.cpp:330] Iteration 9500, Testing net (#0)
I0630 23:10:05.747252  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:10:06.622388  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:10:06.654397  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8224
I0630 23:10:06.654397  7564 solver.cpp:397]     Test net output #1: loss = 0.529318 (* 1 = 0.529318 loss)
I0630 23:10:06.690433  7564 solver.cpp:218] Iteration 9500 (21.0412 iter/s, 4.75258s/100 iters), loss = 0.336582
I0630 23:10:06.690433  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:10:06.690433  7564 solver.cpp:237]     Train net output #1: loss = 0.336582 (* 1 = 0.336582 loss)
I0630 23:10:06.690433  7564 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0630 23:10:10.471262  7564 solver.cpp:218] Iteration 9600 (26.4535 iter/s, 3.78022s/100 iters), loss = 0.360252
I0630 23:10:10.471262  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:10:10.471262  7564 solver.cpp:237]     Train net output #1: loss = 0.360252 (* 1 = 0.360252 loss)
I0630 23:10:10.471262  7564 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0630 23:10:14.250717  7564 solver.cpp:218] Iteration 9700 (26.4571 iter/s, 3.77971s/100 iters), loss = 0.412741
I0630 23:10:14.250717  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:10:14.251718  7564 solver.cpp:237]     Train net output #1: loss = 0.412741 (* 1 = 0.412741 loss)
I0630 23:10:14.251718  7564 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0630 23:10:18.036799  7564 solver.cpp:218] Iteration 9800 (26.4194 iter/s, 3.7851s/100 iters), loss = 0.399977
I0630 23:10:18.036799  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:10:18.036799  7564 solver.cpp:237]     Train net output #1: loss = 0.399977 (* 1 = 0.399977 loss)
I0630 23:10:18.036799  7564 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0630 23:10:21.824651  7564 solver.cpp:218] Iteration 9900 (26.402 iter/s, 3.78759s/100 iters), loss = 0.419895
I0630 23:10:21.824651  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 23:10:21.824651  7564 solver.cpp:237]     Train net output #1: loss = 0.419895 (* 1 = 0.419895 loss)
I0630 23:10:21.824651  7564 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0630 23:10:25.420897  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:10:25.569038  7564 solver.cpp:330] Iteration 10000, Testing net (#0)
I0630 23:10:25.569038  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:10:26.437011  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:10:26.470029  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8092
I0630 23:10:26.470029  7564 solver.cpp:397]     Test net output #1: loss = 0.569352 (* 1 = 0.569352 loss)
I0630 23:10:26.506057  7564 solver.cpp:218] Iteration 10000 (21.3603 iter/s, 4.68158s/100 iters), loss = 0.379119
I0630 23:10:26.506057  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:10:26.506057  7564 solver.cpp:237]     Train net output #1: loss = 0.379119 (* 1 = 0.379119 loss)
I0630 23:10:26.506057  7564 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0630 23:10:30.284628  7564 solver.cpp:218] Iteration 10100 (26.4735 iter/s, 3.77736s/100 iters), loss = 0.299035
I0630 23:10:30.284628  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:10:30.284628  7564 solver.cpp:237]     Train net output #1: loss = 0.299035 (* 1 = 0.299035 loss)
I0630 23:10:30.284628  7564 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0630 23:10:34.075594  7564 solver.cpp:218] Iteration 10200 (26.3803 iter/s, 3.79071s/100 iters), loss = 0.4065
I0630 23:10:34.075594  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:10:34.075594  7564 solver.cpp:237]     Train net output #1: loss = 0.4065 (* 1 = 0.4065 loss)
I0630 23:10:34.075594  7564 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0630 23:10:37.888741  7564 solver.cpp:218] Iteration 10300 (26.2239 iter/s, 3.81332s/100 iters), loss = 0.433799
I0630 23:10:37.888741  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:10:37.888741  7564 solver.cpp:237]     Train net output #1: loss = 0.433799 (* 1 = 0.433799 loss)
I0630 23:10:37.888741  7564 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0630 23:10:41.677834  7564 solver.cpp:218] Iteration 10400 (26.4001 iter/s, 3.78787s/100 iters), loss = 0.352421
I0630 23:10:41.677834  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:10:41.677834  7564 solver.cpp:237]     Train net output #1: loss = 0.352421 (* 1 = 0.352421 loss)
I0630 23:10:41.677834  7564 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0630 23:10:45.283908  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:10:45.435554  7564 solver.cpp:330] Iteration 10500, Testing net (#0)
I0630 23:10:45.435554  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:10:46.299263  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:10:46.333277  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8089
I0630 23:10:46.333277  7564 solver.cpp:397]     Test net output #1: loss = 0.574296 (* 1 = 0.574296 loss)
I0630 23:10:46.368824  7564 solver.cpp:218] Iteration 10500 (21.3156 iter/s, 4.69139s/100 iters), loss = 0.330576
I0630 23:10:46.368824  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:10:46.368824  7564 solver.cpp:237]     Train net output #1: loss = 0.330576 (* 1 = 0.330576 loss)
I0630 23:10:46.368824  7564 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0630 23:10:50.146919  7564 solver.cpp:218] Iteration 10600 (26.4754 iter/s, 3.77709s/100 iters), loss = 0.34934
I0630 23:10:50.146919  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:10:50.146919  7564 solver.cpp:237]     Train net output #1: loss = 0.34934 (* 1 = 0.34934 loss)
I0630 23:10:50.146919  7564 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0630 23:10:53.942296  7564 solver.cpp:218] Iteration 10700 (26.3495 iter/s, 3.79514s/100 iters), loss = 0.349102
I0630 23:10:53.942296  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:10:53.942296  7564 solver.cpp:237]     Train net output #1: loss = 0.349102 (* 1 = 0.349102 loss)
I0630 23:10:53.942296  7564 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0630 23:10:57.779563  7564 solver.cpp:218] Iteration 10800 (26.0567 iter/s, 3.83779s/100 iters), loss = 0.333935
I0630 23:10:57.779563  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:10:57.779563  7564 solver.cpp:237]     Train net output #1: loss = 0.333936 (* 1 = 0.333936 loss)
I0630 23:10:57.780864  7564 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0630 23:11:01.568567  7564 solver.cpp:218] Iteration 10900 (26.4026 iter/s, 3.78751s/100 iters), loss = 0.327127
I0630 23:11:01.568567  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:11:01.568567  7564 solver.cpp:237]     Train net output #1: loss = 0.327127 (* 1 = 0.327127 loss)
I0630 23:11:01.568567  7564 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0630 23:11:05.168521  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:11:05.319716  7564 solver.cpp:330] Iteration 11000, Testing net (#0)
I0630 23:11:05.319716  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:11:06.186039  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:11:06.219130  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8182
I0630 23:11:06.219130  7564 solver.cpp:397]     Test net output #1: loss = 0.555947 (* 1 = 0.555947 loss)
I0630 23:11:06.255147  7564 solver.cpp:218] Iteration 11000 (21.3392 iter/s, 4.68622s/100 iters), loss = 0.366018
I0630 23:11:06.255147  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:11:06.255147  7564 solver.cpp:237]     Train net output #1: loss = 0.366018 (* 1 = 0.366018 loss)
I0630 23:11:06.255147  7564 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0630 23:11:10.033653  7564 solver.cpp:218] Iteration 11100 (26.466 iter/s, 3.77843s/100 iters), loss = 0.347786
I0630 23:11:10.033653  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:11:10.033653  7564 solver.cpp:237]     Train net output #1: loss = 0.347786 (* 1 = 0.347786 loss)
I0630 23:11:10.033653  7564 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0630 23:11:13.861251  7564 solver.cpp:218] Iteration 11200 (26.1295 iter/s, 3.82709s/100 iters), loss = 0.352071
I0630 23:11:13.861251  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:11:13.861251  7564 solver.cpp:237]     Train net output #1: loss = 0.352071 (* 1 = 0.352071 loss)
I0630 23:11:13.861251  7564 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0630 23:11:17.709687  7564 solver.cpp:218] Iteration 11300 (25.9888 iter/s, 3.84781s/100 iters), loss = 0.318356
I0630 23:11:17.709687  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:11:17.709687  7564 solver.cpp:237]     Train net output #1: loss = 0.318356 (* 1 = 0.318356 loss)
I0630 23:11:17.709687  7564 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0630 23:11:21.536550  7564 solver.cpp:218] Iteration 11400 (26.1326 iter/s, 3.82663s/100 iters), loss = 0.339751
I0630 23:11:21.536550  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:11:21.536550  7564 solver.cpp:237]     Train net output #1: loss = 0.339752 (* 1 = 0.339752 loss)
I0630 23:11:21.536550  7564 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0630 23:11:25.131101  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:11:25.279405  7564 solver.cpp:330] Iteration 11500, Testing net (#0)
I0630 23:11:25.279405  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:11:26.152194  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:11:26.186219  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8197
I0630 23:11:26.186219  7564 solver.cpp:397]     Test net output #1: loss = 0.55119 (* 1 = 0.55119 loss)
I0630 23:11:26.223014  7564 solver.cpp:218] Iteration 11500 (21.3389 iter/s, 4.68628s/100 iters), loss = 0.308409
I0630 23:11:26.223014  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:11:26.223014  7564 solver.cpp:237]     Train net output #1: loss = 0.308409 (* 1 = 0.308409 loss)
I0630 23:11:26.223014  7564 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0630 23:11:30.055613  7564 solver.cpp:218] Iteration 11600 (26.0927 iter/s, 3.8325s/100 iters), loss = 0.361323
I0630 23:11:30.055613  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:11:30.055613  7564 solver.cpp:237]     Train net output #1: loss = 0.361323 (* 1 = 0.361323 loss)
I0630 23:11:30.055613  7564 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0630 23:11:33.904155  7564 solver.cpp:218] Iteration 11700 (25.9899 iter/s, 3.84765s/100 iters), loss = 0.345402
I0630 23:11:33.904155  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:11:33.904155  7564 solver.cpp:237]     Train net output #1: loss = 0.345402 (* 1 = 0.345402 loss)
I0630 23:11:33.904155  7564 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0630 23:11:37.706280  7564 solver.cpp:218] Iteration 11800 (26.3046 iter/s, 3.80161s/100 iters), loss = 0.341103
I0630 23:11:37.706280  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:11:37.706280  7564 solver.cpp:237]     Train net output #1: loss = 0.341103 (* 1 = 0.341103 loss)
I0630 23:11:37.706280  7564 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0630 23:11:41.488135  7564 solver.cpp:218] Iteration 11900 (26.4405 iter/s, 3.78208s/100 iters), loss = 0.417935
I0630 23:11:41.488135  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:11:41.488135  7564 solver.cpp:237]     Train net output #1: loss = 0.417935 (* 1 = 0.417935 loss)
I0630 23:11:41.488135  7564 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0630 23:11:45.095233  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:11:45.243399  7564 solver.cpp:330] Iteration 12000, Testing net (#0)
I0630 23:11:45.243399  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:11:46.110512  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:11:46.144086  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8176
I0630 23:11:46.144086  7564 solver.cpp:397]     Test net output #1: loss = 0.554768 (* 1 = 0.554768 loss)
I0630 23:11:46.180245  7564 solver.cpp:218] Iteration 12000 (21.3168 iter/s, 4.69115s/100 iters), loss = 0.388705
I0630 23:11:46.180245  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 23:11:46.180245  7564 solver.cpp:237]     Train net output #1: loss = 0.388705 (* 1 = 0.388705 loss)
I0630 23:11:46.180245  7564 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0630 23:11:50.011186  7564 solver.cpp:218] Iteration 12100 (26.1014 iter/s, 3.83121s/100 iters), loss = 0.274771
I0630 23:11:50.011186  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:11:50.011186  7564 solver.cpp:237]     Train net output #1: loss = 0.274771 (* 1 = 0.274771 loss)
I0630 23:11:50.011186  7564 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0630 23:11:53.813444  7564 solver.cpp:218] Iteration 12200 (26.3076 iter/s, 3.80118s/100 iters), loss = 0.343461
I0630 23:11:53.813444  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:11:53.813444  7564 solver.cpp:237]     Train net output #1: loss = 0.343461 (* 1 = 0.343461 loss)
I0630 23:11:53.813444  7564 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0630 23:11:57.606268  7564 solver.cpp:218] Iteration 12300 (26.3626 iter/s, 3.79325s/100 iters), loss = 0.45865
I0630 23:11:57.607275  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 23:11:57.607275  7564 solver.cpp:237]     Train net output #1: loss = 0.45865 (* 1 = 0.45865 loss)
I0630 23:11:57.607275  7564 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0630 23:12:01.396327  7564 solver.cpp:218] Iteration 12400 (26.3923 iter/s, 3.78899s/100 iters), loss = 0.307756
I0630 23:12:01.396327  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:12:01.396327  7564 solver.cpp:237]     Train net output #1: loss = 0.307757 (* 1 = 0.307757 loss)
I0630 23:12:01.396327  7564 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0630 23:12:05.006439  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:12:05.155249  7564 solver.cpp:330] Iteration 12500, Testing net (#0)
I0630 23:12:05.155249  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:12:06.023160  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:12:06.056223  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8255
I0630 23:12:06.056223  7564 solver.cpp:397]     Test net output #1: loss = 0.52751 (* 1 = 0.52751 loss)
I0630 23:12:06.092258  7564 solver.cpp:218] Iteration 12500 (21.294 iter/s, 4.69616s/100 iters), loss = 0.280058
I0630 23:12:06.092258  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:12:06.093258  7564 solver.cpp:237]     Train net output #1: loss = 0.280058 (* 1 = 0.280058 loss)
I0630 23:12:06.093258  7564 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0630 23:12:09.887398  7564 solver.cpp:218] Iteration 12600 (26.3569 iter/s, 3.79408s/100 iters), loss = 0.308593
I0630 23:12:09.887398  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:12:09.887398  7564 solver.cpp:237]     Train net output #1: loss = 0.308593 (* 1 = 0.308593 loss)
I0630 23:12:09.887398  7564 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0630 23:12:13.685297  7564 solver.cpp:218] Iteration 12700 (26.3343 iter/s, 3.79733s/100 iters), loss = 0.339768
I0630 23:12:13.685297  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:12:13.685297  7564 solver.cpp:237]     Train net output #1: loss = 0.339768 (* 1 = 0.339768 loss)
I0630 23:12:13.685297  7564 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0630 23:12:17.472318  7564 solver.cpp:218] Iteration 12800 (26.4037 iter/s, 3.78734s/100 iters), loss = 0.381837
I0630 23:12:17.472318  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:12:17.472318  7564 solver.cpp:237]     Train net output #1: loss = 0.381837 (* 1 = 0.381837 loss)
I0630 23:12:17.472318  7564 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0630 23:12:21.266062  7564 solver.cpp:218] Iteration 12900 (26.3614 iter/s, 3.79342s/100 iters), loss = 0.422432
I0630 23:12:21.266062  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 23:12:21.266062  7564 solver.cpp:237]     Train net output #1: loss = 0.422432 (* 1 = 0.422432 loss)
I0630 23:12:21.266062  7564 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0630 23:12:24.885987  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:12:25.035114  7564 solver.cpp:330] Iteration 13000, Testing net (#0)
I0630 23:12:25.035114  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:12:25.908656  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:12:25.941682  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8188
I0630 23:12:25.941682  7564 solver.cpp:397]     Test net output #1: loss = 0.551013 (* 1 = 0.551013 loss)
I0630 23:12:25.977725  7564 solver.cpp:218] Iteration 13000 (21.2271 iter/s, 4.71095s/100 iters), loss = 0.306051
I0630 23:12:25.977725  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:12:25.977725  7564 solver.cpp:237]     Train net output #1: loss = 0.306051 (* 1 = 0.306051 loss)
I0630 23:12:25.977725  7564 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0630 23:12:29.823752  7564 solver.cpp:218] Iteration 13100 (26.0062 iter/s, 3.84524s/100 iters), loss = 0.298231
I0630 23:12:29.823752  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:12:29.823752  7564 solver.cpp:237]     Train net output #1: loss = 0.298231 (* 1 = 0.298231 loss)
I0630 23:12:29.823752  7564 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0630 23:12:33.644866  7564 solver.cpp:218] Iteration 13200 (26.1688 iter/s, 3.82135s/100 iters), loss = 0.432356
I0630 23:12:33.644866  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 23:12:33.644866  7564 solver.cpp:237]     Train net output #1: loss = 0.432356 (* 1 = 0.432356 loss)
I0630 23:12:33.644866  7564 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0630 23:12:37.454834  7564 solver.cpp:218] Iteration 13300 (26.2511 iter/s, 3.80937s/100 iters), loss = 0.367972
I0630 23:12:37.454834  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:12:37.454834  7564 solver.cpp:237]     Train net output #1: loss = 0.367972 (* 1 = 0.367972 loss)
I0630 23:12:37.454834  7564 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0630 23:12:41.281603  7564 solver.cpp:218] Iteration 13400 (26.1342 iter/s, 3.82641s/100 iters), loss = 0.333821
I0630 23:12:41.281603  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:12:41.281603  7564 solver.cpp:237]     Train net output #1: loss = 0.333821 (* 1 = 0.333821 loss)
I0630 23:12:41.281603  7564 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0630 23:12:44.921476  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:12:45.070891  7564 solver.cpp:330] Iteration 13500, Testing net (#0)
I0630 23:12:45.070891  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:12:45.935309  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:12:45.968854  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8362
I0630 23:12:45.968854  7564 solver.cpp:397]     Test net output #1: loss = 0.493169 (* 1 = 0.493169 loss)
I0630 23:12:46.004953  7564 solver.cpp:218] Iteration 13500 (21.1751 iter/s, 4.72252s/100 iters), loss = 0.313364
I0630 23:12:46.004953  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:12:46.004953  7564 solver.cpp:237]     Train net output #1: loss = 0.313364 (* 1 = 0.313364 loss)
I0630 23:12:46.004953  7564 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0630 23:12:49.835407  7564 solver.cpp:218] Iteration 13600 (26.1067 iter/s, 3.83043s/100 iters), loss = 0.348239
I0630 23:12:49.835407  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:12:49.835407  7564 solver.cpp:237]     Train net output #1: loss = 0.348239 (* 1 = 0.348239 loss)
I0630 23:12:49.835407  7564 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0630 23:12:53.668191  7564 solver.cpp:218] Iteration 13700 (26.0916 iter/s, 3.83266s/100 iters), loss = 0.319484
I0630 23:12:53.668191  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:12:53.668191  7564 solver.cpp:237]     Train net output #1: loss = 0.319484 (* 1 = 0.319484 loss)
I0630 23:12:53.668191  7564 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0630 23:12:57.466183  7564 solver.cpp:218] Iteration 13800 (26.3368 iter/s, 3.79697s/100 iters), loss = 0.395775
I0630 23:12:57.466183  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:12:57.466183  7564 solver.cpp:237]     Train net output #1: loss = 0.395775 (* 1 = 0.395775 loss)
I0630 23:12:57.466183  7564 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0630 23:13:01.266058  7564 solver.cpp:218] Iteration 13900 (26.3181 iter/s, 3.79966s/100 iters), loss = 0.36098
I0630 23:13:01.266058  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:13:01.266058  7564 solver.cpp:237]     Train net output #1: loss = 0.36098 (* 1 = 0.36098 loss)
I0630 23:13:01.266058  7564 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0630 23:13:04.889787  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:13:05.038522  7564 solver.cpp:330] Iteration 14000, Testing net (#0)
I0630 23:13:05.038522  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:13:05.906628  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:13:05.939673  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8282
I0630 23:13:05.939673  7564 solver.cpp:397]     Test net output #1: loss = 0.517024 (* 1 = 0.517024 loss)
I0630 23:13:05.975693  7564 solver.cpp:218] Iteration 14000 (21.2349 iter/s, 4.70923s/100 iters), loss = 0.222212
I0630 23:13:05.975693  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:13:05.975693  7564 solver.cpp:237]     Train net output #1: loss = 0.222212 (* 1 = 0.222212 loss)
I0630 23:13:05.975693  7564 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0630 23:13:09.779302  7564 solver.cpp:218] Iteration 14100 (26.2925 iter/s, 3.80337s/100 iters), loss = 0.277346
I0630 23:13:09.779302  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:13:09.779302  7564 solver.cpp:237]     Train net output #1: loss = 0.277346 (* 1 = 0.277346 loss)
I0630 23:13:09.779302  7564 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0630 23:13:13.579607  7564 solver.cpp:218] Iteration 14200 (26.3179 iter/s, 3.7997s/100 iters), loss = 0.232194
I0630 23:13:13.579607  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:13:13.579607  7564 solver.cpp:237]     Train net output #1: loss = 0.232194 (* 1 = 0.232194 loss)
I0630 23:13:13.579607  7564 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0630 23:13:17.393718  7564 solver.cpp:218] Iteration 14300 (26.2168 iter/s, 3.81435s/100 iters), loss = 0.293969
I0630 23:13:17.393718  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:13:17.393718  7564 solver.cpp:237]     Train net output #1: loss = 0.293969 (* 1 = 0.293969 loss)
I0630 23:13:17.393718  7564 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0630 23:13:21.258991  7564 solver.cpp:218] Iteration 14400 (25.8776 iter/s, 3.86435s/100 iters), loss = 0.351231
I0630 23:13:21.258991  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:13:21.258991  7564 solver.cpp:237]     Train net output #1: loss = 0.351231 (* 1 = 0.351231 loss)
I0630 23:13:21.258991  7564 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0630 23:13:24.879799  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:13:25.028697  7564 solver.cpp:330] Iteration 14500, Testing net (#0)
I0630 23:13:25.028697  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:13:25.900104  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:13:25.933656  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8159
I0630 23:13:25.933656  7564 solver.cpp:397]     Test net output #1: loss = 0.556025 (* 1 = 0.556025 loss)
I0630 23:13:25.968688  7564 solver.cpp:218] Iteration 14500 (21.232 iter/s, 4.70986s/100 iters), loss = 0.25733
I0630 23:13:25.968688  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:13:25.968688  7564 solver.cpp:237]     Train net output #1: loss = 0.25733 (* 1 = 0.25733 loss)
I0630 23:13:25.969689  7564 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0630 23:13:29.764235  7564 solver.cpp:218] Iteration 14600 (26.3555 iter/s, 3.79427s/100 iters), loss = 0.240233
I0630 23:13:29.764235  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:13:29.764235  7564 solver.cpp:237]     Train net output #1: loss = 0.240233 (* 1 = 0.240233 loss)
I0630 23:13:29.764235  7564 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0630 23:13:33.552675  7564 solver.cpp:218] Iteration 14700 (26.3977 iter/s, 3.78821s/100 iters), loss = 0.359061
I0630 23:13:33.552675  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 23:13:33.552675  7564 solver.cpp:237]     Train net output #1: loss = 0.359061 (* 1 = 0.359061 loss)
I0630 23:13:33.552675  7564 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0630 23:13:37.346767  7564 solver.cpp:218] Iteration 14800 (26.3596 iter/s, 3.79369s/100 iters), loss = 0.471043
I0630 23:13:37.346767  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 23:13:37.346767  7564 solver.cpp:237]     Train net output #1: loss = 0.471043 (* 1 = 0.471043 loss)
I0630 23:13:37.346767  7564 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0630 23:13:41.148294  7564 solver.cpp:218] Iteration 14900 (26.3076 iter/s, 3.80118s/100 iters), loss = 0.418142
I0630 23:13:41.148294  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:13:41.148294  7564 solver.cpp:237]     Train net output #1: loss = 0.418142 (* 1 = 0.418142 loss)
I0630 23:13:41.148294  7564 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0630 23:13:44.781685  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:13:44.931344  7564 solver.cpp:330] Iteration 15000, Testing net (#0)
I0630 23:13:44.931344  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:13:45.799038  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:13:45.833058  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8414
I0630 23:13:45.833058  7564 solver.cpp:397]     Test net output #1: loss = 0.483811 (* 1 = 0.483811 loss)
I0630 23:13:45.868669  7564 solver.cpp:218] Iteration 15000 (21.1858 iter/s, 4.72013s/100 iters), loss = 0.244205
I0630 23:13:45.868669  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:13:45.868669  7564 solver.cpp:237]     Train net output #1: loss = 0.244205 (* 1 = 0.244205 loss)
I0630 23:13:45.868669  7564 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0630 23:13:49.679838  7564 solver.cpp:218] Iteration 15100 (26.2392 iter/s, 3.81109s/100 iters), loss = 0.299104
I0630 23:13:49.679838  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:13:49.679838  7564 solver.cpp:237]     Train net output #1: loss = 0.299104 (* 1 = 0.299104 loss)
I0630 23:13:49.679838  7564 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0630 23:13:53.489688  7564 solver.cpp:218] Iteration 15200 (26.2512 iter/s, 3.80935s/100 iters), loss = 0.276735
I0630 23:13:53.489688  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:13:53.489688  7564 solver.cpp:237]     Train net output #1: loss = 0.276735 (* 1 = 0.276735 loss)
I0630 23:13:53.489688  7564 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0630 23:13:57.301901  7564 solver.cpp:218] Iteration 15300 (26.236 iter/s, 3.81156s/100 iters), loss = 0.319268
I0630 23:13:57.301901  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:13:57.301901  7564 solver.cpp:237]     Train net output #1: loss = 0.319268 (* 1 = 0.319268 loss)
I0630 23:13:57.301901  7564 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0630 23:14:01.102160  7564 solver.cpp:218] Iteration 15400 (26.3148 iter/s, 3.80014s/100 iters), loss = 0.349685
I0630 23:14:01.102160  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:14:01.102160  7564 solver.cpp:237]     Train net output #1: loss = 0.349685 (* 1 = 0.349685 loss)
I0630 23:14:01.102160  7564 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0630 23:14:04.714817  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:14:04.862828  7564 solver.cpp:330] Iteration 15500, Testing net (#0)
I0630 23:14:04.862828  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:14:05.736703  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:14:05.769754  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8311
I0630 23:14:05.769754  7564 solver.cpp:397]     Test net output #1: loss = 0.526166 (* 1 = 0.526166 loss)
I0630 23:14:05.805770  7564 solver.cpp:218] Iteration 15500 (21.2614 iter/s, 4.70335s/100 iters), loss = 0.259248
I0630 23:14:05.805770  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:14:05.805770  7564 solver.cpp:237]     Train net output #1: loss = 0.259248 (* 1 = 0.259248 loss)
I0630 23:14:05.805770  7564 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0630 23:14:09.638511  7564 solver.cpp:218] Iteration 15600 (26.0972 iter/s, 3.83183s/100 iters), loss = 0.275916
I0630 23:14:09.638511  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:14:09.638511  7564 solver.cpp:237]     Train net output #1: loss = 0.275916 (* 1 = 0.275916 loss)
I0630 23:14:09.638511  7564 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0630 23:14:13.493568  7564 solver.cpp:218] Iteration 15700 (25.9385 iter/s, 3.85527s/100 iters), loss = 0.321479
I0630 23:14:13.493568  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:14:13.493568  7564 solver.cpp:237]     Train net output #1: loss = 0.321479 (* 1 = 0.321479 loss)
I0630 23:14:13.493568  7564 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0630 23:14:17.287436  7564 solver.cpp:218] Iteration 15800 (26.3637 iter/s, 3.79309s/100 iters), loss = 0.353877
I0630 23:14:17.287436  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:14:17.287436  7564 solver.cpp:237]     Train net output #1: loss = 0.353877 (* 1 = 0.353877 loss)
I0630 23:14:17.287436  7564 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0630 23:14:21.081668  7564 solver.cpp:218] Iteration 15900 (26.3611 iter/s, 3.79347s/100 iters), loss = 0.301777
I0630 23:14:21.081668  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:14:21.081668  7564 solver.cpp:237]     Train net output #1: loss = 0.301777 (* 1 = 0.301777 loss)
I0630 23:14:21.081668  7564 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0630 23:14:24.696935  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:14:24.846084  7564 solver.cpp:330] Iteration 16000, Testing net (#0)
I0630 23:14:24.846084  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:14:25.714941  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:14:25.746976  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8322
I0630 23:14:25.746976  7564 solver.cpp:397]     Test net output #1: loss = 0.510323 (* 1 = 0.510323 loss)
I0630 23:14:25.782002  7564 solver.cpp:218] Iteration 16000 (21.2744 iter/s, 4.70048s/100 iters), loss = 0.276816
I0630 23:14:25.782002  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:14:25.782002  7564 solver.cpp:237]     Train net output #1: loss = 0.276816 (* 1 = 0.276816 loss)
I0630 23:14:25.782002  7564 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0630 23:14:29.589185  7564 solver.cpp:218] Iteration 16100 (26.2733 iter/s, 3.80615s/100 iters), loss = 0.336557
I0630 23:14:29.589185  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:14:29.589185  7564 solver.cpp:237]     Train net output #1: loss = 0.336557 (* 1 = 0.336557 loss)
I0630 23:14:29.589185  7564 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0630 23:14:33.385155  7564 solver.cpp:218] Iteration 16200 (26.3448 iter/s, 3.79581s/100 iters), loss = 0.271197
I0630 23:14:33.385155  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:14:33.385155  7564 solver.cpp:237]     Train net output #1: loss = 0.271197 (* 1 = 0.271197 loss)
I0630 23:14:33.385155  7564 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0630 23:14:37.179982  7564 solver.cpp:218] Iteration 16300 (26.3564 iter/s, 3.79414s/100 iters), loss = 0.316719
I0630 23:14:37.179982  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:14:37.179982  7564 solver.cpp:237]     Train net output #1: loss = 0.316719 (* 1 = 0.316719 loss)
I0630 23:14:37.179982  7564 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0630 23:14:40.979455  7564 solver.cpp:218] Iteration 16400 (26.3195 iter/s, 3.79946s/100 iters), loss = 0.290546
I0630 23:14:40.979455  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:14:40.979956  7564 solver.cpp:237]     Train net output #1: loss = 0.290546 (* 1 = 0.290546 loss)
I0630 23:14:40.979956  7564 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0630 23:14:44.603060  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:14:44.752197  7564 solver.cpp:330] Iteration 16500, Testing net (#0)
I0630 23:14:44.752197  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:14:45.618718  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:14:45.652741  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8389
I0630 23:14:45.652741  7564 solver.cpp:397]     Test net output #1: loss = 0.497425 (* 1 = 0.497425 loss)
I0630 23:14:45.688784  7564 solver.cpp:218] Iteration 16500 (21.2371 iter/s, 4.70874s/100 iters), loss = 0.250014
I0630 23:14:45.688784  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:14:45.688784  7564 solver.cpp:237]     Train net output #1: loss = 0.250015 (* 1 = 0.250015 loss)
I0630 23:14:45.688784  7564 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0630 23:14:49.486894  7564 solver.cpp:218] Iteration 16600 (26.3322 iter/s, 3.79762s/100 iters), loss = 0.284043
I0630 23:14:49.486894  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:14:49.486894  7564 solver.cpp:237]     Train net output #1: loss = 0.284043 (* 1 = 0.284043 loss)
I0630 23:14:49.486894  7564 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0630 23:14:53.294126  7564 solver.cpp:218] Iteration 16700 (26.2675 iter/s, 3.80698s/100 iters), loss = 0.321343
I0630 23:14:53.294126  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 23:14:53.294126  7564 solver.cpp:237]     Train net output #1: loss = 0.321343 (* 1 = 0.321343 loss)
I0630 23:14:53.294126  7564 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0630 23:14:57.090245  7564 solver.cpp:218] Iteration 16800 (26.3436 iter/s, 3.79599s/100 iters), loss = 0.395368
I0630 23:14:57.090245  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:14:57.090245  7564 solver.cpp:237]     Train net output #1: loss = 0.395368 (* 1 = 0.395368 loss)
I0630 23:14:57.090245  7564 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0630 23:15:00.899492  7564 solver.cpp:218] Iteration 16900 (26.2554 iter/s, 3.80874s/100 iters), loss = 0.228496
I0630 23:15:00.899492  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:15:00.899492  7564 solver.cpp:237]     Train net output #1: loss = 0.228496 (* 1 = 0.228496 loss)
I0630 23:15:00.899492  7564 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0630 23:15:04.514050  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:15:04.662389  7564 solver.cpp:330] Iteration 17000, Testing net (#0)
I0630 23:15:04.662389  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:15:05.531535  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:15:05.562572  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8274
I0630 23:15:05.563567  7564 solver.cpp:397]     Test net output #1: loss = 0.544424 (* 1 = 0.544424 loss)
I0630 23:15:05.598599  7564 solver.cpp:218] Iteration 17000 (21.2796 iter/s, 4.69934s/100 iters), loss = 0.228243
I0630 23:15:05.599601  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:15:05.599601  7564 solver.cpp:237]     Train net output #1: loss = 0.228243 (* 1 = 0.228243 loss)
I0630 23:15:05.599601  7564 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0630 23:15:09.409973  7564 solver.cpp:218] Iteration 17100 (26.2456 iter/s, 3.81016s/100 iters), loss = 0.252431
I0630 23:15:09.409973  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:15:09.409973  7564 solver.cpp:237]     Train net output #1: loss = 0.252431 (* 1 = 0.252431 loss)
I0630 23:15:09.409973  7564 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0630 23:15:13.206755  7564 solver.cpp:218] Iteration 17200 (26.3363 iter/s, 3.79704s/100 iters), loss = 0.313341
I0630 23:15:13.206755  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:15:13.206755  7564 solver.cpp:237]     Train net output #1: loss = 0.313341 (* 1 = 0.313341 loss)
I0630 23:15:13.206755  7564 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0630 23:15:17.002944  7564 solver.cpp:218] Iteration 17300 (26.3484 iter/s, 3.7953s/100 iters), loss = 0.320729
I0630 23:15:17.002944  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:15:17.002944  7564 solver.cpp:237]     Train net output #1: loss = 0.320729 (* 1 = 0.320729 loss)
I0630 23:15:17.002944  7564 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0630 23:15:20.810778  7564 solver.cpp:218] Iteration 17400 (26.2612 iter/s, 3.8079s/100 iters), loss = 0.241493
I0630 23:15:20.810778  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:15:20.810778  7564 solver.cpp:237]     Train net output #1: loss = 0.241493 (* 1 = 0.241493 loss)
I0630 23:15:20.810778  7564 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0630 23:15:24.417534  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:15:24.566051  7564 solver.cpp:330] Iteration 17500, Testing net (#0)
I0630 23:15:24.566051  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:15:25.436244  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:15:25.469282  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8338
I0630 23:15:25.469282  7564 solver.cpp:397]     Test net output #1: loss = 0.520553 (* 1 = 0.520553 loss)
I0630 23:15:25.505303  7564 solver.cpp:218] Iteration 17500 (21.3056 iter/s, 4.6936s/100 iters), loss = 0.206365
I0630 23:15:25.505303  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:15:25.505303  7564 solver.cpp:237]     Train net output #1: loss = 0.206365 (* 1 = 0.206365 loss)
I0630 23:15:25.505303  7564 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0630 23:15:29.311692  7564 solver.cpp:218] Iteration 17600 (26.2747 iter/s, 3.80595s/100 iters), loss = 0.188004
I0630 23:15:29.311692  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:15:29.311692  7564 solver.cpp:237]     Train net output #1: loss = 0.188004 (* 1 = 0.188004 loss)
I0630 23:15:29.311692  7564 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0630 23:15:33.098116  7564 solver.cpp:218] Iteration 17700 (26.4107 iter/s, 3.78634s/100 iters), loss = 0.280978
I0630 23:15:33.098116  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:15:33.098116  7564 solver.cpp:237]     Train net output #1: loss = 0.280978 (* 1 = 0.280978 loss)
I0630 23:15:33.098116  7564 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0630 23:15:36.885918  7564 solver.cpp:218] Iteration 17800 (26.4058 iter/s, 3.78704s/100 iters), loss = 0.27936
I0630 23:15:36.885918  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:15:36.885918  7564 solver.cpp:237]     Train net output #1: loss = 0.27936 (* 1 = 0.27936 loss)
I0630 23:15:36.885918  7564 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0630 23:15:40.674191  7564 solver.cpp:218] Iteration 17900 (26.401 iter/s, 3.78774s/100 iters), loss = 0.301849
I0630 23:15:40.674191  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:15:40.674191  7564 solver.cpp:237]     Train net output #1: loss = 0.301849 (* 1 = 0.301849 loss)
I0630 23:15:40.674191  7564 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0630 23:15:44.292080  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:15:44.441727  7564 solver.cpp:330] Iteration 18000, Testing net (#0)
I0630 23:15:44.441727  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:15:45.310997  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:15:45.343556  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8377
I0630 23:15:45.343556  7564 solver.cpp:397]     Test net output #1: loss = 0.493972 (* 1 = 0.493972 loss)
I0630 23:15:45.379678  7564 solver.cpp:218] Iteration 18000 (21.2518 iter/s, 4.70547s/100 iters), loss = 0.233515
I0630 23:15:45.379678  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:15:45.379678  7564 solver.cpp:237]     Train net output #1: loss = 0.233516 (* 1 = 0.233516 loss)
I0630 23:15:45.379678  7564 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0630 23:15:49.190973  7564 solver.cpp:218] Iteration 18100 (26.2378 iter/s, 3.8113s/100 iters), loss = 0.236663
I0630 23:15:49.190973  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:15:49.190973  7564 solver.cpp:237]     Train net output #1: loss = 0.236663 (* 1 = 0.236663 loss)
I0630 23:15:49.190973  7564 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0630 23:15:52.986801  7564 solver.cpp:218] Iteration 18200 (26.3478 iter/s, 3.79539s/100 iters), loss = 0.31781
I0630 23:15:52.986801  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:15:52.986801  7564 solver.cpp:237]     Train net output #1: loss = 0.31781 (* 1 = 0.31781 loss)
I0630 23:15:52.986801  7564 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0630 23:15:56.784613  7564 solver.cpp:218] Iteration 18300 (26.3356 iter/s, 3.79715s/100 iters), loss = 0.30061
I0630 23:15:56.784613  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:15:56.784613  7564 solver.cpp:237]     Train net output #1: loss = 0.30061 (* 1 = 0.30061 loss)
I0630 23:15:56.784613  7564 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0630 23:16:00.597229  7564 solver.cpp:218] Iteration 18400 (26.2288 iter/s, 3.81261s/100 iters), loss = 0.274419
I0630 23:16:00.597229  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:16:00.598225  7564 solver.cpp:237]     Train net output #1: loss = 0.274419 (* 1 = 0.274419 loss)
I0630 23:16:00.598225  7564 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0630 23:16:04.232861  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:16:04.383096  7564 solver.cpp:330] Iteration 18500, Testing net (#0)
I0630 23:16:04.383096  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:16:05.249395  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:16:05.282866  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8404
I0630 23:16:05.282866  7564 solver.cpp:397]     Test net output #1: loss = 0.500286 (* 1 = 0.500286 loss)
I0630 23:16:05.318902  7564 solver.cpp:218] Iteration 18500 (21.1848 iter/s, 4.72037s/100 iters), loss = 0.261194
I0630 23:16:05.318902  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:16:05.318902  7564 solver.cpp:237]     Train net output #1: loss = 0.261194 (* 1 = 0.261194 loss)
I0630 23:16:05.318902  7564 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0630 23:16:09.107651  7564 solver.cpp:218] Iteration 18600 (26.3909 iter/s, 3.78918s/100 iters), loss = 0.233419
I0630 23:16:09.107651  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:16:09.107651  7564 solver.cpp:237]     Train net output #1: loss = 0.233419 (* 1 = 0.233419 loss)
I0630 23:16:09.107651  7564 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0630 23:16:12.900038  7564 solver.cpp:218] Iteration 18700 (26.37 iter/s, 3.79218s/100 iters), loss = 0.358943
I0630 23:16:12.901039  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 23:16:12.901039  7564 solver.cpp:237]     Train net output #1: loss = 0.358943 (* 1 = 0.358943 loss)
I0630 23:16:12.901039  7564 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0630 23:16:16.688186  7564 solver.cpp:218] Iteration 18800 (26.4061 iter/s, 3.787s/100 iters), loss = 0.410474
I0630 23:16:16.688186  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 23:16:16.688186  7564 solver.cpp:237]     Train net output #1: loss = 0.410474 (* 1 = 0.410474 loss)
I0630 23:16:16.688186  7564 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0630 23:16:20.493371  7564 solver.cpp:218] Iteration 18900 (26.2838 iter/s, 3.80463s/100 iters), loss = 0.276784
I0630 23:16:20.493371  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:16:20.493371  7564 solver.cpp:237]     Train net output #1: loss = 0.276784 (* 1 = 0.276784 loss)
I0630 23:16:20.493371  7564 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0630 23:16:24.092027  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:16:24.240705  7564 solver.cpp:330] Iteration 19000, Testing net (#0)
I0630 23:16:24.240705  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:16:25.109119  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:16:25.143157  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8314
I0630 23:16:25.143157  7564 solver.cpp:397]     Test net output #1: loss = 0.516887 (* 1 = 0.516887 loss)
I0630 23:16:25.179168  7564 solver.cpp:218] Iteration 19000 (21.3424 iter/s, 4.68552s/100 iters), loss = 0.276365
I0630 23:16:25.179168  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:16:25.179168  7564 solver.cpp:237]     Train net output #1: loss = 0.276365 (* 1 = 0.276365 loss)
I0630 23:16:25.179168  7564 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0630 23:16:29.038398  7564 solver.cpp:218] Iteration 19100 (25.91 iter/s, 3.85952s/100 iters), loss = 0.256904
I0630 23:16:29.038398  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:16:29.038398  7564 solver.cpp:237]     Train net output #1: loss = 0.256904 (* 1 = 0.256904 loss)
I0630 23:16:29.038398  7564 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0630 23:16:32.851933  7564 solver.cpp:218] Iteration 19200 (26.2289 iter/s, 3.81259s/100 iters), loss = 0.291297
I0630 23:16:32.851933  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:16:32.851933  7564 solver.cpp:237]     Train net output #1: loss = 0.291297 (* 1 = 0.291297 loss)
I0630 23:16:32.851933  7564 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0630 23:16:36.676875  7564 solver.cpp:218] Iteration 19300 (26.1437 iter/s, 3.82501s/100 iters), loss = 0.364338
I0630 23:16:36.676875  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:16:36.676875  7564 solver.cpp:237]     Train net output #1: loss = 0.364338 (* 1 = 0.364338 loss)
I0630 23:16:36.676875  7564 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0630 23:16:40.541646  7564 solver.cpp:218] Iteration 19400 (25.8792 iter/s, 3.86411s/100 iters), loss = 0.222779
I0630 23:16:40.541646  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:16:40.541646  7564 solver.cpp:237]     Train net output #1: loss = 0.222779 (* 1 = 0.222779 loss)
I0630 23:16:40.541646  7564 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0630 23:16:44.214958  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:16:44.373502  7564 solver.cpp:330] Iteration 19500, Testing net (#0)
I0630 23:16:44.373502  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:16:45.246309  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:16:45.279315  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8286
I0630 23:16:45.279315  7564 solver.cpp:397]     Test net output #1: loss = 0.555789 (* 1 = 0.555789 loss)
I0630 23:16:45.316843  7564 solver.cpp:218] Iteration 19500 (20.9449 iter/s, 4.77444s/100 iters), loss = 0.224666
I0630 23:16:45.316843  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:16:45.316843  7564 solver.cpp:237]     Train net output #1: loss = 0.224666 (* 1 = 0.224666 loss)
I0630 23:16:45.316843  7564 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0630 23:16:49.109520  7564 solver.cpp:218] Iteration 19600 (26.3713 iter/s, 3.79201s/100 iters), loss = 0.158209
I0630 23:16:49.109520  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:16:49.109520  7564 solver.cpp:237]     Train net output #1: loss = 0.158209 (* 1 = 0.158209 loss)
I0630 23:16:49.109520  7564 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0630 23:16:52.921808  7564 solver.cpp:218] Iteration 19700 (26.2348 iter/s, 3.81173s/100 iters), loss = 0.309021
I0630 23:16:52.921808  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:16:52.921808  7564 solver.cpp:237]     Train net output #1: loss = 0.309021 (* 1 = 0.309021 loss)
I0630 23:16:52.921808  7564 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0630 23:16:56.730527  7564 solver.cpp:218] Iteration 19800 (26.2564 iter/s, 3.80859s/100 iters), loss = 0.279616
I0630 23:16:56.730527  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:16:56.730527  7564 solver.cpp:237]     Train net output #1: loss = 0.279616 (* 1 = 0.279616 loss)
I0630 23:16:56.730527  7564 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0630 23:17:00.550223  7564 solver.cpp:218] Iteration 19900 (26.1811 iter/s, 3.81955s/100 iters), loss = 0.284733
I0630 23:17:00.550223  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:17:00.550223  7564 solver.cpp:237]     Train net output #1: loss = 0.284733 (* 1 = 0.284733 loss)
I0630 23:17:00.550223  7564 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0630 23:17:04.180915  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:17:04.329248  7564 solver.cpp:330] Iteration 20000, Testing net (#0)
I0630 23:17:04.329248  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:17:05.190090  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:17:05.223117  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8286
I0630 23:17:05.223117  7564 solver.cpp:397]     Test net output #1: loss = 0.518818 (* 1 = 0.518818 loss)
I0630 23:17:05.258858  7564 solver.cpp:218] Iteration 20000 (21.2404 iter/s, 4.70801s/100 iters), loss = 0.196398
I0630 23:17:05.258858  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:17:05.258858  7564 solver.cpp:237]     Train net output #1: loss = 0.196398 (* 1 = 0.196398 loss)
I0630 23:17:05.258858  7564 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0630 23:17:09.030325  7564 solver.cpp:218] Iteration 20100 (26.5172 iter/s, 3.77114s/100 iters), loss = 0.213642
I0630 23:17:09.030325  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:17:09.030325  7564 solver.cpp:237]     Train net output #1: loss = 0.213642 (* 1 = 0.213642 loss)
I0630 23:17:09.030325  7564 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0630 23:17:12.803506  7564 solver.cpp:218] Iteration 20200 (26.5003 iter/s, 3.77354s/100 iters), loss = 0.315549
I0630 23:17:12.803506  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:17:12.804507  7564 solver.cpp:237]     Train net output #1: loss = 0.315549 (* 1 = 0.315549 loss)
I0630 23:17:12.804507  7564 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0630 23:17:16.574256  7564 solver.cpp:218] Iteration 20300 (26.524 iter/s, 3.77018s/100 iters), loss = 0.308138
I0630 23:17:16.574256  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 23:17:16.574256  7564 solver.cpp:237]     Train net output #1: loss = 0.308138 (* 1 = 0.308138 loss)
I0630 23:17:16.574256  7564 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0630 23:17:20.353456  7564 solver.cpp:218] Iteration 20400 (26.4639 iter/s, 3.77874s/100 iters), loss = 0.3157
I0630 23:17:20.353456  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:17:20.353456  7564 solver.cpp:237]     Train net output #1: loss = 0.3157 (* 1 = 0.3157 loss)
I0630 23:17:20.353456  7564 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0630 23:17:23.938000  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:17:24.085947  7564 solver.cpp:330] Iteration 20500, Testing net (#0)
I0630 23:17:24.085947  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:17:24.950417  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:17:24.982870  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8397
I0630 23:17:24.982870  7564 solver.cpp:397]     Test net output #1: loss = 0.494265 (* 1 = 0.494265 loss)
I0630 23:17:25.018898  7564 solver.cpp:218] Iteration 20500 (21.4367 iter/s, 4.66489s/100 iters), loss = 0.220294
I0630 23:17:25.018898  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:17:25.018898  7564 solver.cpp:237]     Train net output #1: loss = 0.220294 (* 1 = 0.220294 loss)
I0630 23:17:25.018898  7564 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0630 23:17:28.789813  7564 solver.cpp:218] Iteration 20600 (26.5223 iter/s, 3.77042s/100 iters), loss = 0.225115
I0630 23:17:28.789813  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:17:28.789813  7564 solver.cpp:237]     Train net output #1: loss = 0.225115 (* 1 = 0.225115 loss)
I0630 23:17:28.789813  7564 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0630 23:17:32.564425  7564 solver.cpp:218] Iteration 20700 (26.4945 iter/s, 3.77437s/100 iters), loss = 0.322105
I0630 23:17:32.564425  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:17:32.564425  7564 solver.cpp:237]     Train net output #1: loss = 0.322105 (* 1 = 0.322105 loss)
I0630 23:17:32.564425  7564 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0630 23:17:36.352090  7564 solver.cpp:218] Iteration 20800 (26.4062 iter/s, 3.78699s/100 iters), loss = 0.263417
I0630 23:17:36.352090  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:17:36.352090  7564 solver.cpp:237]     Train net output #1: loss = 0.263417 (* 1 = 0.263417 loss)
I0630 23:17:36.352090  7564 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0630 23:17:40.124909  7564 solver.cpp:218] Iteration 20900 (26.5025 iter/s, 3.77323s/100 iters), loss = 0.262432
I0630 23:17:40.124909  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:17:40.124909  7564 solver.cpp:237]     Train net output #1: loss = 0.262432 (* 1 = 0.262432 loss)
I0630 23:17:40.124909  7564 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0630 23:17:43.711719  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:17:43.860472  7564 solver.cpp:330] Iteration 21000, Testing net (#0)
I0630 23:17:43.860472  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:17:44.721230  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:17:44.754247  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8423
I0630 23:17:44.754247  7564 solver.cpp:397]     Test net output #1: loss = 0.496341 (* 1 = 0.496341 loss)
I0630 23:17:44.791771  7564 solver.cpp:218] Iteration 21000 (21.4312 iter/s, 4.66609s/100 iters), loss = 0.265124
I0630 23:17:44.791771  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:17:44.791771  7564 solver.cpp:237]     Train net output #1: loss = 0.265124 (* 1 = 0.265124 loss)
I0630 23:17:44.791771  7564 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0630 23:17:48.648699  7564 solver.cpp:218] Iteration 21100 (25.9302 iter/s, 3.85651s/100 iters), loss = 0.216209
I0630 23:17:48.648699  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:17:48.648699  7564 solver.cpp:237]     Train net output #1: loss = 0.216209 (* 1 = 0.216209 loss)
I0630 23:17:48.648699  7564 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0630 23:17:52.424410  7564 solver.cpp:218] Iteration 21200 (26.4901 iter/s, 3.775s/100 iters), loss = 0.311401
I0630 23:17:52.424410  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 23:17:52.424410  7564 solver.cpp:237]     Train net output #1: loss = 0.311401 (* 1 = 0.311401 loss)
I0630 23:17:52.424410  7564 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0630 23:17:56.195698  7564 solver.cpp:218] Iteration 21300 (26.5184 iter/s, 3.77097s/100 iters), loss = 0.270365
I0630 23:17:56.195698  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:17:56.195698  7564 solver.cpp:237]     Train net output #1: loss = 0.270365 (* 1 = 0.270365 loss)
I0630 23:17:56.195698  7564 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0630 23:17:59.969290  7564 solver.cpp:218] Iteration 21400 (26.5012 iter/s, 3.77342s/100 iters), loss = 0.242626
I0630 23:17:59.969290  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:17:59.969290  7564 solver.cpp:237]     Train net output #1: loss = 0.242626 (* 1 = 0.242626 loss)
I0630 23:17:59.969290  7564 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0630 23:18:03.559931  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:18:03.707933  7564 solver.cpp:330] Iteration 21500, Testing net (#0)
I0630 23:18:03.707933  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:18:04.569453  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:18:04.602645  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8481
I0630 23:18:04.602645  7564 solver.cpp:397]     Test net output #1: loss = 0.465703 (* 1 = 0.465703 loss)
I0630 23:18:04.638687  7564 solver.cpp:218] Iteration 21500 (21.4181 iter/s, 4.66895s/100 iters), loss = 0.227736
I0630 23:18:04.638687  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:18:04.638687  7564 solver.cpp:237]     Train net output #1: loss = 0.227736 (* 1 = 0.227736 loss)
I0630 23:18:04.638687  7564 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0630 23:18:08.411439  7564 solver.cpp:218] Iteration 21600 (26.5035 iter/s, 3.77309s/100 iters), loss = 0.149326
I0630 23:18:08.411439  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:18:08.411439  7564 solver.cpp:237]     Train net output #1: loss = 0.149326 (* 1 = 0.149326 loss)
I0630 23:18:08.411439  7564 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0630 23:18:12.184209  7564 solver.cpp:218] Iteration 21700 (26.5109 iter/s, 3.77203s/100 iters), loss = 0.273287
I0630 23:18:12.184715  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:18:12.184715  7564 solver.cpp:237]     Train net output #1: loss = 0.273287 (* 1 = 0.273287 loss)
I0630 23:18:12.184715  7564 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0630 23:18:15.961736  7564 solver.cpp:218] Iteration 21800 (26.4743 iter/s, 3.77725s/100 iters), loss = 0.282503
I0630 23:18:15.961736  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:18:15.961736  7564 solver.cpp:237]     Train net output #1: loss = 0.282503 (* 1 = 0.282503 loss)
I0630 23:18:15.961736  7564 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0630 23:18:19.733099  7564 solver.cpp:218] Iteration 21900 (26.52 iter/s, 3.77074s/100 iters), loss = 0.27876
I0630 23:18:19.733099  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:18:19.733099  7564 solver.cpp:237]     Train net output #1: loss = 0.27876 (* 1 = 0.27876 loss)
I0630 23:18:19.733099  7564 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0630 23:18:23.322016  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:18:23.470124  7564 solver.cpp:330] Iteration 22000, Testing net (#0)
I0630 23:18:23.470124  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:18:24.333705  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:18:24.365712  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8377
I0630 23:18:24.365712  7564 solver.cpp:397]     Test net output #1: loss = 0.511648 (* 1 = 0.511648 loss)
I0630 23:18:24.402266  7564 solver.cpp:218] Iteration 22000 (21.4197 iter/s, 4.66859s/100 iters), loss = 0.218001
I0630 23:18:24.402266  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:18:24.402266  7564 solver.cpp:237]     Train net output #1: loss = 0.218001 (* 1 = 0.218001 loss)
I0630 23:18:24.402266  7564 sgd_solver.cpp:46] MultiStep Status: Iteration 22000, step = 1
I0630 23:18:24.402266  7564 sgd_solver.cpp:105] Iteration 22000, lr = 0.001
I0630 23:18:28.178921  7564 solver.cpp:218] Iteration 22100 (26.4793 iter/s, 3.77653s/100 iters), loss = 0.222829
I0630 23:18:28.178921  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:18:28.178921  7564 solver.cpp:237]     Train net output #1: loss = 0.222829 (* 1 = 0.222829 loss)
I0630 23:18:28.178921  7564 sgd_solver.cpp:105] Iteration 22100, lr = 0.001
I0630 23:18:31.953550  7564 solver.cpp:218] Iteration 22200 (26.4945 iter/s, 3.77437s/100 iters), loss = 0.204425
I0630 23:18:31.953550  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:18:31.953550  7564 solver.cpp:237]     Train net output #1: loss = 0.204426 (* 1 = 0.204426 loss)
I0630 23:18:31.953550  7564 sgd_solver.cpp:105] Iteration 22200, lr = 0.001
I0630 23:18:35.725240  7564 solver.cpp:218] Iteration 22300 (26.5125 iter/s, 3.7718s/100 iters), loss = 0.209575
I0630 23:18:35.725240  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:18:35.725240  7564 solver.cpp:237]     Train net output #1: loss = 0.209575 (* 1 = 0.209575 loss)
I0630 23:18:35.725240  7564 sgd_solver.cpp:105] Iteration 22300, lr = 0.001
I0630 23:18:39.502692  7564 solver.cpp:218] Iteration 22400 (26.4761 iter/s, 3.77699s/100 iters), loss = 0.224298
I0630 23:18:39.502692  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:18:39.502692  7564 solver.cpp:237]     Train net output #1: loss = 0.224298 (* 1 = 0.224298 loss)
I0630 23:18:39.502692  7564 sgd_solver.cpp:105] Iteration 22400, lr = 0.001
I0630 23:18:43.094683  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:18:43.242894  7564 solver.cpp:330] Iteration 22500, Testing net (#0)
I0630 23:18:43.242894  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:18:44.104753  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:18:44.137243  7564 solver.cpp:397]     Test net output #0: accuracy = 0.865
I0630 23:18:44.137243  7564 solver.cpp:397]     Test net output #1: loss = 0.416692 (* 1 = 0.416692 loss)
I0630 23:18:44.173249  7564 solver.cpp:218] Iteration 22500 (21.4139 iter/s, 4.66987s/100 iters), loss = 0.195819
I0630 23:18:44.173249  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:18:44.173249  7564 solver.cpp:237]     Train net output #1: loss = 0.195819 (* 1 = 0.195819 loss)
I0630 23:18:44.173249  7564 sgd_solver.cpp:105] Iteration 22500, lr = 0.001
I0630 23:18:47.941751  7564 solver.cpp:218] Iteration 22600 (26.5398 iter/s, 3.76792s/100 iters), loss = 0.156154
I0630 23:18:47.941751  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:18:47.941751  7564 solver.cpp:237]     Train net output #1: loss = 0.156154 (* 1 = 0.156154 loss)
I0630 23:18:47.941751  7564 sgd_solver.cpp:105] Iteration 22600, lr = 0.001
I0630 23:18:51.715720  7564 solver.cpp:218] Iteration 22700 (26.4978 iter/s, 3.77389s/100 iters), loss = 0.187216
I0630 23:18:51.715720  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:18:51.715720  7564 solver.cpp:237]     Train net output #1: loss = 0.187216 (* 1 = 0.187216 loss)
I0630 23:18:51.715720  7564 sgd_solver.cpp:105] Iteration 22700, lr = 0.001
I0630 23:18:55.487381  7564 solver.cpp:218] Iteration 22800 (26.5161 iter/s, 3.77129s/100 iters), loss = 0.211001
I0630 23:18:55.487381  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:18:55.487381  7564 solver.cpp:237]     Train net output #1: loss = 0.211001 (* 1 = 0.211001 loss)
I0630 23:18:55.487381  7564 sgd_solver.cpp:105] Iteration 22800, lr = 0.001
I0630 23:18:59.255684  7564 solver.cpp:218] Iteration 22900 (26.5351 iter/s, 3.7686s/100 iters), loss = 0.218156
I0630 23:18:59.256685  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:18:59.256685  7564 solver.cpp:237]     Train net output #1: loss = 0.218156 (* 1 = 0.218156 loss)
I0630 23:18:59.256685  7564 sgd_solver.cpp:105] Iteration 22900, lr = 0.001
I0630 23:19:02.847220  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:19:02.994863  7564 solver.cpp:330] Iteration 23000, Testing net (#0)
I0630 23:19:02.994863  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:19:03.855546  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:19:03.888586  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8655
I0630 23:19:03.888586  7564 solver.cpp:397]     Test net output #1: loss = 0.412163 (* 1 = 0.412163 loss)
I0630 23:19:03.923610  7564 solver.cpp:218] Iteration 23000 (21.4247 iter/s, 4.66752s/100 iters), loss = 0.169574
I0630 23:19:03.923610  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:19:03.923610  7564 solver.cpp:237]     Train net output #1: loss = 0.169574 (* 1 = 0.169574 loss)
I0630 23:19:03.923610  7564 sgd_solver.cpp:105] Iteration 23000, lr = 0.001
I0630 23:19:07.695338  7564 solver.cpp:218] Iteration 23100 (26.5213 iter/s, 3.77056s/100 iters), loss = 0.122253
I0630 23:19:07.695338  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:19:07.695338  7564 solver.cpp:237]     Train net output #1: loss = 0.122253 (* 1 = 0.122253 loss)
I0630 23:19:07.695338  7564 sgd_solver.cpp:105] Iteration 23100, lr = 0.001
I0630 23:19:11.465443  7564 solver.cpp:218] Iteration 23200 (26.526 iter/s, 3.76988s/100 iters), loss = 0.199607
I0630 23:19:11.465443  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:19:11.465443  7564 solver.cpp:237]     Train net output #1: loss = 0.199607 (* 1 = 0.199607 loss)
I0630 23:19:11.465443  7564 sgd_solver.cpp:105] Iteration 23200, lr = 0.001
I0630 23:19:15.235395  7564 solver.cpp:218] Iteration 23300 (26.5237 iter/s, 3.77021s/100 iters), loss = 0.211817
I0630 23:19:15.235395  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:19:15.235395  7564 solver.cpp:237]     Train net output #1: loss = 0.211817 (* 1 = 0.211817 loss)
I0630 23:19:15.235395  7564 sgd_solver.cpp:105] Iteration 23300, lr = 0.001
I0630 23:19:19.006655  7564 solver.cpp:218] Iteration 23400 (26.5206 iter/s, 3.77066s/100 iters), loss = 0.250616
I0630 23:19:19.006655  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:19:19.006655  7564 solver.cpp:237]     Train net output #1: loss = 0.250616 (* 1 = 0.250616 loss)
I0630 23:19:19.006655  7564 sgd_solver.cpp:105] Iteration 23400, lr = 0.001
I0630 23:19:22.594442  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:19:22.742101  7564 solver.cpp:330] Iteration 23500, Testing net (#0)
I0630 23:19:22.742101  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:19:23.603826  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:19:23.635848  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8676
I0630 23:19:23.635848  7564 solver.cpp:397]     Test net output #1: loss = 0.413812 (* 1 = 0.413812 loss)
I0630 23:19:23.671864  7564 solver.cpp:218] Iteration 23500 (21.4367 iter/s, 4.6649s/100 iters), loss = 0.134617
I0630 23:19:23.671864  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:19:23.671864  7564 solver.cpp:237]     Train net output #1: loss = 0.134617 (* 1 = 0.134617 loss)
I0630 23:19:23.671864  7564 sgd_solver.cpp:105] Iteration 23500, lr = 0.001
I0630 23:19:27.439827  7564 solver.cpp:218] Iteration 23600 (26.5392 iter/s, 3.76801s/100 iters), loss = 0.125683
I0630 23:19:27.440829  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0630 23:19:27.440829  7564 solver.cpp:237]     Train net output #1: loss = 0.125683 (* 1 = 0.125683 loss)
I0630 23:19:27.440829  7564 sgd_solver.cpp:105] Iteration 23600, lr = 0.001
I0630 23:19:31.208802  7564 solver.cpp:218] Iteration 23700 (26.541 iter/s, 3.76776s/100 iters), loss = 0.14373
I0630 23:19:31.208802  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:19:31.208802  7564 solver.cpp:237]     Train net output #1: loss = 0.14373 (* 1 = 0.14373 loss)
I0630 23:19:31.208802  7564 sgd_solver.cpp:105] Iteration 23700, lr = 0.001
I0630 23:19:34.964140  7564 solver.cpp:218] Iteration 23800 (26.6293 iter/s, 3.75527s/100 iters), loss = 0.129414
I0630 23:19:34.964140  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:19:34.964140  7564 solver.cpp:237]     Train net output #1: loss = 0.129414 (* 1 = 0.129414 loss)
I0630 23:19:34.964140  7564 sgd_solver.cpp:105] Iteration 23800, lr = 0.001
I0630 23:19:38.718899  7564 solver.cpp:218] Iteration 23900 (26.6336 iter/s, 3.75466s/100 iters), loss = 0.204853
I0630 23:19:38.718899  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:19:38.718899  7564 solver.cpp:237]     Train net output #1: loss = 0.204853 (* 1 = 0.204853 loss)
I0630 23:19:38.718899  7564 sgd_solver.cpp:105] Iteration 23900, lr = 0.001
I0630 23:19:42.290076  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:19:42.438740  7564 solver.cpp:330] Iteration 24000, Testing net (#0)
I0630 23:19:42.438740  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:19:43.291025  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:19:43.324048  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8691
I0630 23:19:43.324048  7564 solver.cpp:397]     Test net output #1: loss = 0.41185 (* 1 = 0.41185 loss)
I0630 23:19:43.360072  7564 solver.cpp:218] Iteration 24000 (21.5498 iter/s, 4.64041s/100 iters), loss = 0.165282
I0630 23:19:43.360072  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:19:43.360072  7564 solver.cpp:237]     Train net output #1: loss = 0.165282 (* 1 = 0.165282 loss)
I0630 23:19:43.360072  7564 sgd_solver.cpp:105] Iteration 24000, lr = 0.001
I0630 23:19:47.121716  7564 solver.cpp:218] Iteration 24100 (26.5808 iter/s, 3.76212s/100 iters), loss = 0.225143
I0630 23:19:47.122717  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:19:47.122717  7564 solver.cpp:237]     Train net output #1: loss = 0.225143 (* 1 = 0.225143 loss)
I0630 23:19:47.122717  7564 sgd_solver.cpp:105] Iteration 24100, lr = 0.001
I0630 23:19:50.884042  7564 solver.cpp:218] Iteration 24200 (26.5876 iter/s, 3.76115s/100 iters), loss = 0.269641
I0630 23:19:50.884042  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:19:50.884042  7564 solver.cpp:237]     Train net output #1: loss = 0.269641 (* 1 = 0.269641 loss)
I0630 23:19:50.884042  7564 sgd_solver.cpp:105] Iteration 24200, lr = 0.001
I0630 23:19:54.645032  7564 solver.cpp:218] Iteration 24300 (26.5886 iter/s, 3.76101s/100 iters), loss = 0.210001
I0630 23:19:54.645032  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:19:54.645032  7564 solver.cpp:237]     Train net output #1: loss = 0.210001 (* 1 = 0.210001 loss)
I0630 23:19:54.645032  7564 sgd_solver.cpp:105] Iteration 24300, lr = 0.001
I0630 23:19:58.407454  7564 solver.cpp:218] Iteration 24400 (26.5798 iter/s, 3.76226s/100 iters), loss = 0.221662
I0630 23:19:58.407454  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:19:58.407454  7564 solver.cpp:237]     Train net output #1: loss = 0.221662 (* 1 = 0.221662 loss)
I0630 23:19:58.407454  7564 sgd_solver.cpp:105] Iteration 24400, lr = 0.001
I0630 23:20:02.065709  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:20:02.213174  7564 solver.cpp:330] Iteration 24500, Testing net (#0)
I0630 23:20:02.213174  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:20:03.066570  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:20:03.099097  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8697
I0630 23:20:03.099097  7564 solver.cpp:397]     Test net output #1: loss = 0.412712 (* 1 = 0.412712 loss)
I0630 23:20:03.134847  7564 solver.cpp:218] Iteration 24500 (21.1567 iter/s, 4.72664s/100 iters), loss = 0.146054
I0630 23:20:03.134847  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:20:03.134847  7564 solver.cpp:237]     Train net output #1: loss = 0.146054 (* 1 = 0.146054 loss)
I0630 23:20:03.134847  7564 sgd_solver.cpp:105] Iteration 24500, lr = 0.001
I0630 23:20:06.897927  7564 solver.cpp:218] Iteration 24600 (26.5778 iter/s, 3.76254s/100 iters), loss = 0.181442
I0630 23:20:06.897927  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:20:06.897927  7564 solver.cpp:237]     Train net output #1: loss = 0.181442 (* 1 = 0.181442 loss)
I0630 23:20:06.897927  7564 sgd_solver.cpp:105] Iteration 24600, lr = 0.001
I0630 23:20:10.673621  7564 solver.cpp:218] Iteration 24700 (26.4862 iter/s, 3.77555s/100 iters), loss = 0.175702
I0630 23:20:10.673621  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:20:10.673621  7564 solver.cpp:237]     Train net output #1: loss = 0.175702 (* 1 = 0.175702 loss)
I0630 23:20:10.673621  7564 sgd_solver.cpp:105] Iteration 24700, lr = 0.001
I0630 23:20:14.434137  7564 solver.cpp:218] Iteration 24800 (26.593 iter/s, 3.76039s/100 iters), loss = 0.129333
I0630 23:20:14.434137  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:20:14.434137  7564 solver.cpp:237]     Train net output #1: loss = 0.129333 (* 1 = 0.129333 loss)
I0630 23:20:14.434137  7564 sgd_solver.cpp:105] Iteration 24800, lr = 0.001
I0630 23:20:18.190822  7564 solver.cpp:218] Iteration 24900 (26.6196 iter/s, 3.75663s/100 iters), loss = 0.273858
I0630 23:20:18.190822  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:20:18.190822  7564 solver.cpp:237]     Train net output #1: loss = 0.273858 (* 1 = 0.273858 loss)
I0630 23:20:18.190822  7564 sgd_solver.cpp:105] Iteration 24900, lr = 0.001
I0630 23:20:21.764173  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:20:21.912927  7564 solver.cpp:330] Iteration 25000, Testing net (#0)
I0630 23:20:21.912927  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:20:22.768687  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:20:22.801710  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8698
I0630 23:20:22.801710  7564 solver.cpp:397]     Test net output #1: loss = 0.412897 (* 1 = 0.412897 loss)
I0630 23:20:22.838217  7564 solver.cpp:218] Iteration 25000 (21.5227 iter/s, 4.64625s/100 iters), loss = 0.156192
I0630 23:20:22.838217  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:20:22.838217  7564 solver.cpp:237]     Train net output #1: loss = 0.156192 (* 1 = 0.156192 loss)
I0630 23:20:22.838217  7564 sgd_solver.cpp:105] Iteration 25000, lr = 0.001
I0630 23:20:26.596266  7564 solver.cpp:218] Iteration 25100 (26.6123 iter/s, 3.75765s/100 iters), loss = 0.169093
I0630 23:20:26.596266  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:20:26.596266  7564 solver.cpp:237]     Train net output #1: loss = 0.169093 (* 1 = 0.169093 loss)
I0630 23:20:26.596266  7564 sgd_solver.cpp:105] Iteration 25100, lr = 0.001
I0630 23:20:30.356838  7564 solver.cpp:218] Iteration 25200 (26.5921 iter/s, 3.76052s/100 iters), loss = 0.157625
I0630 23:20:30.356838  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:20:30.356838  7564 solver.cpp:237]     Train net output #1: loss = 0.157625 (* 1 = 0.157625 loss)
I0630 23:20:30.356838  7564 sgd_solver.cpp:105] Iteration 25200, lr = 0.001
I0630 23:20:34.114580  7564 solver.cpp:218] Iteration 25300 (26.6121 iter/s, 3.75769s/100 iters), loss = 0.158984
I0630 23:20:34.114580  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:20:34.114580  7564 solver.cpp:237]     Train net output #1: loss = 0.158984 (* 1 = 0.158984 loss)
I0630 23:20:34.114580  7564 sgd_solver.cpp:105] Iteration 25300, lr = 0.001
I0630 23:20:37.878923  7564 solver.cpp:218] Iteration 25400 (26.5672 iter/s, 3.76405s/100 iters), loss = 0.271424
I0630 23:20:37.878923  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:20:37.878923  7564 solver.cpp:237]     Train net output #1: loss = 0.271424 (* 1 = 0.271424 loss)
I0630 23:20:37.878923  7564 sgd_solver.cpp:105] Iteration 25400, lr = 0.001
I0630 23:20:41.452697  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:20:41.599894  7564 solver.cpp:330] Iteration 25500, Testing net (#0)
I0630 23:20:41.599894  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:20:42.453637  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:20:42.485673  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8682
I0630 23:20:42.485673  7564 solver.cpp:397]     Test net output #1: loss = 0.414367 (* 1 = 0.414367 loss)
I0630 23:20:42.521685  7564 solver.cpp:218] Iteration 25500 (21.5389 iter/s, 4.64276s/100 iters), loss = 0.171157
I0630 23:20:42.522686  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:20:42.522686  7564 solver.cpp:237]     Train net output #1: loss = 0.171157 (* 1 = 0.171157 loss)
I0630 23:20:42.522686  7564 sgd_solver.cpp:105] Iteration 25500, lr = 0.001
I0630 23:20:46.287276  7564 solver.cpp:218] Iteration 25600 (26.5615 iter/s, 3.76485s/100 iters), loss = 0.194982
I0630 23:20:46.287276  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:20:46.287276  7564 solver.cpp:237]     Train net output #1: loss = 0.194982 (* 1 = 0.194982 loss)
I0630 23:20:46.287276  7564 sgd_solver.cpp:105] Iteration 25600, lr = 0.001
I0630 23:20:50.048593  7564 solver.cpp:218] Iteration 25700 (26.5913 iter/s, 3.76063s/100 iters), loss = 0.19245
I0630 23:20:50.048593  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:20:50.048593  7564 solver.cpp:237]     Train net output #1: loss = 0.19245 (* 1 = 0.19245 loss)
I0630 23:20:50.048593  7564 sgd_solver.cpp:105] Iteration 25700, lr = 0.001
I0630 23:20:53.814910  7564 solver.cpp:218] Iteration 25800 (26.5527 iter/s, 3.76609s/100 iters), loss = 0.178586
I0630 23:20:53.815412  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:20:53.815412  7564 solver.cpp:237]     Train net output #1: loss = 0.178586 (* 1 = 0.178586 loss)
I0630 23:20:53.815412  7564 sgd_solver.cpp:105] Iteration 25800, lr = 0.001
I0630 23:20:57.575511  7564 solver.cpp:218] Iteration 25900 (26.5954 iter/s, 3.76005s/100 iters), loss = 0.255968
I0630 23:20:57.575511  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:20:57.575511  7564 solver.cpp:237]     Train net output #1: loss = 0.255968 (* 1 = 0.255968 loss)
I0630 23:20:57.575511  7564 sgd_solver.cpp:105] Iteration 25900, lr = 0.001
I0630 23:21:01.151502  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:21:01.298594  7564 solver.cpp:330] Iteration 26000, Testing net (#0)
I0630 23:21:01.298594  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:21:02.154984  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:21:02.187007  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8698
I0630 23:21:02.187007  7564 solver.cpp:397]     Test net output #1: loss = 0.410822 (* 1 = 0.410822 loss)
I0630 23:21:02.223156  7564 solver.cpp:218] Iteration 26000 (21.5177 iter/s, 4.64734s/100 iters), loss = 0.195311
I0630 23:21:02.223156  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:21:02.223156  7564 solver.cpp:237]     Train net output #1: loss = 0.195311 (* 1 = 0.195311 loss)
I0630 23:21:02.223156  7564 sgd_solver.cpp:105] Iteration 26000, lr = 0.001
I0630 23:21:05.982436  7564 solver.cpp:218] Iteration 26100 (26.6009 iter/s, 3.75927s/100 iters), loss = 0.142919
I0630 23:21:05.982436  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:21:05.982436  7564 solver.cpp:237]     Train net output #1: loss = 0.142919 (* 1 = 0.142919 loss)
I0630 23:21:05.982436  7564 sgd_solver.cpp:105] Iteration 26100, lr = 0.001
I0630 23:21:09.740443  7564 solver.cpp:218] Iteration 26200 (26.6138 iter/s, 3.75745s/100 iters), loss = 0.168747
I0630 23:21:09.740443  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:21:09.740443  7564 solver.cpp:237]     Train net output #1: loss = 0.168747 (* 1 = 0.168747 loss)
I0630 23:21:09.740443  7564 sgd_solver.cpp:105] Iteration 26200, lr = 0.001
I0630 23:21:13.496470  7564 solver.cpp:218] Iteration 26300 (26.6274 iter/s, 3.75553s/100 iters), loss = 0.177855
I0630 23:21:13.496470  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:21:13.496470  7564 solver.cpp:237]     Train net output #1: loss = 0.177855 (* 1 = 0.177855 loss)
I0630 23:21:13.496470  7564 sgd_solver.cpp:105] Iteration 26300, lr = 0.001
I0630 23:21:17.251420  7564 solver.cpp:218] Iteration 26400 (26.6367 iter/s, 3.75422s/100 iters), loss = 0.180458
I0630 23:21:17.251420  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:21:17.251420  7564 solver.cpp:237]     Train net output #1: loss = 0.180458 (* 1 = 0.180458 loss)
I0630 23:21:17.251420  7564 sgd_solver.cpp:105] Iteration 26400, lr = 0.001
I0630 23:21:20.831174  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:21:20.977926  7564 solver.cpp:330] Iteration 26500, Testing net (#0)
I0630 23:21:20.977926  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:21:21.836537  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:21:21.869560  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8692
I0630 23:21:21.869560  7564 solver.cpp:397]     Test net output #1: loss = 0.4121 (* 1 = 0.4121 loss)
I0630 23:21:21.905586  7564 solver.cpp:218] Iteration 26500 (21.4861 iter/s, 4.65418s/100 iters), loss = 0.143652
I0630 23:21:21.905586  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:21:21.905586  7564 solver.cpp:237]     Train net output #1: loss = 0.143652 (* 1 = 0.143652 loss)
I0630 23:21:21.905586  7564 sgd_solver.cpp:105] Iteration 26500, lr = 0.001
I0630 23:21:25.667068  7564 solver.cpp:218] Iteration 26600 (26.5891 iter/s, 3.76093s/100 iters), loss = 0.151979
I0630 23:21:25.667068  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:21:25.667068  7564 solver.cpp:237]     Train net output #1: loss = 0.151979 (* 1 = 0.151979 loss)
I0630 23:21:25.667068  7564 sgd_solver.cpp:105] Iteration 26600, lr = 0.001
I0630 23:21:29.433828  7564 solver.cpp:218] Iteration 26700 (26.5514 iter/s, 3.76629s/100 iters), loss = 0.154184
I0630 23:21:29.433828  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:21:29.433828  7564 solver.cpp:237]     Train net output #1: loss = 0.154184 (* 1 = 0.154184 loss)
I0630 23:21:29.433828  7564 sgd_solver.cpp:105] Iteration 26700, lr = 0.001
I0630 23:21:33.186784  7564 solver.cpp:218] Iteration 26800 (26.6419 iter/s, 3.75349s/100 iters), loss = 0.186498
I0630 23:21:33.186784  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:21:33.186784  7564 solver.cpp:237]     Train net output #1: loss = 0.186498 (* 1 = 0.186498 loss)
I0630 23:21:33.187784  7564 sgd_solver.cpp:105] Iteration 26800, lr = 0.001
I0630 23:21:36.951673  7564 solver.cpp:218] Iteration 26900 (26.5676 iter/s, 3.76398s/100 iters), loss = 0.241687
I0630 23:21:36.951673  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:21:36.951673  7564 solver.cpp:237]     Train net output #1: loss = 0.241687 (* 1 = 0.241687 loss)
I0630 23:21:36.951673  7564 sgd_solver.cpp:105] Iteration 26900, lr = 0.001
I0630 23:21:40.530369  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:21:40.676605  7564 solver.cpp:330] Iteration 27000, Testing net (#0)
I0630 23:21:40.676605  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:21:41.532405  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:21:41.565598  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8709
I0630 23:21:41.565598  7564 solver.cpp:397]     Test net output #1: loss = 0.41372 (* 1 = 0.41372 loss)
I0630 23:21:41.601624  7564 solver.cpp:218] Iteration 27000 (21.5074 iter/s, 4.64956s/100 iters), loss = 0.123015
I0630 23:21:41.601624  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:21:41.601624  7564 solver.cpp:237]     Train net output #1: loss = 0.123015 (* 1 = 0.123015 loss)
I0630 23:21:41.601624  7564 sgd_solver.cpp:105] Iteration 27000, lr = 0.001
I0630 23:21:45.364110  7564 solver.cpp:218] Iteration 27100 (26.5798 iter/s, 3.76225s/100 iters), loss = 0.166479
I0630 23:21:45.364110  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:21:45.364110  7564 solver.cpp:237]     Train net output #1: loss = 0.166479 (* 1 = 0.166479 loss)
I0630 23:21:45.364110  7564 sgd_solver.cpp:105] Iteration 27100, lr = 0.001
I0630 23:21:49.122411  7564 solver.cpp:218] Iteration 27200 (26.6108 iter/s, 3.75787s/100 iters), loss = 0.128147
I0630 23:21:49.122411  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:21:49.122411  7564 solver.cpp:237]     Train net output #1: loss = 0.128147 (* 1 = 0.128147 loss)
I0630 23:21:49.122411  7564 sgd_solver.cpp:105] Iteration 27200, lr = 0.001
I0630 23:21:52.899852  7564 solver.cpp:218] Iteration 27300 (26.4723 iter/s, 3.77754s/100 iters), loss = 0.204621
I0630 23:21:52.899852  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:21:52.899852  7564 solver.cpp:237]     Train net output #1: loss = 0.204621 (* 1 = 0.204621 loss)
I0630 23:21:52.899852  7564 sgd_solver.cpp:105] Iteration 27300, lr = 0.001
I0630 23:21:56.663466  7564 solver.cpp:218] Iteration 27400 (26.5783 iter/s, 3.76246s/100 iters), loss = 0.163044
I0630 23:21:56.663466  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:21:56.663466  7564 solver.cpp:237]     Train net output #1: loss = 0.163044 (* 1 = 0.163044 loss)
I0630 23:21:56.663466  7564 sgd_solver.cpp:105] Iteration 27400, lr = 0.001
I0630 23:22:00.243072  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:22:00.392086  7564 solver.cpp:330] Iteration 27500, Testing net (#0)
I0630 23:22:00.392086  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:22:01.247115  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:22:01.279502  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8698
I0630 23:22:01.279502  7564 solver.cpp:397]     Test net output #1: loss = 0.417325 (* 1 = 0.417325 loss)
I0630 23:22:01.315528  7564 solver.cpp:218] Iteration 27500 (21.4955 iter/s, 4.65214s/100 iters), loss = 0.138449
I0630 23:22:01.315528  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:22:01.315528  7564 solver.cpp:237]     Train net output #1: loss = 0.138449 (* 1 = 0.138449 loss)
I0630 23:22:01.315528  7564 sgd_solver.cpp:105] Iteration 27500, lr = 0.001
I0630 23:22:05.083320  7564 solver.cpp:218] Iteration 27600 (26.5411 iter/s, 3.76774s/100 iters), loss = 0.167664
I0630 23:22:05.083320  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:22:05.083320  7564 solver.cpp:237]     Train net output #1: loss = 0.167664 (* 1 = 0.167664 loss)
I0630 23:22:05.083320  7564 sgd_solver.cpp:105] Iteration 27600, lr = 0.001
I0630 23:22:08.842574  7564 solver.cpp:218] Iteration 27700 (26.5974 iter/s, 3.75977s/100 iters), loss = 0.207615
I0630 23:22:08.842574  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:22:08.842574  7564 solver.cpp:237]     Train net output #1: loss = 0.207615 (* 1 = 0.207615 loss)
I0630 23:22:08.842574  7564 sgd_solver.cpp:105] Iteration 27700, lr = 0.001
I0630 23:22:12.600107  7564 solver.cpp:218] Iteration 27800 (26.6163 iter/s, 3.75709s/100 iters), loss = 0.235137
I0630 23:22:12.600107  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:22:12.600107  7564 solver.cpp:237]     Train net output #1: loss = 0.235137 (* 1 = 0.235137 loss)
I0630 23:22:12.600107  7564 sgd_solver.cpp:105] Iteration 27800, lr = 0.001
I0630 23:22:16.360551  7564 solver.cpp:218] Iteration 27900 (26.5967 iter/s, 3.75987s/100 iters), loss = 0.250274
I0630 23:22:16.360551  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:22:16.360551  7564 solver.cpp:237]     Train net output #1: loss = 0.250274 (* 1 = 0.250274 loss)
I0630 23:22:16.360551  7564 sgd_solver.cpp:105] Iteration 27900, lr = 0.001
I0630 23:22:19.935853  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:22:20.084655  7564 solver.cpp:330] Iteration 28000, Testing net (#0)
I0630 23:22:20.084655  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:22:20.942414  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:22:20.974444  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8707
I0630 23:22:20.974444  7564 solver.cpp:397]     Test net output #1: loss = 0.415135 (* 1 = 0.415135 loss)
I0630 23:22:21.011042  7564 solver.cpp:218] Iteration 28000 (21.5055 iter/s, 4.64998s/100 iters), loss = 0.141685
I0630 23:22:21.011042  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:22:21.011042  7564 solver.cpp:237]     Train net output #1: loss = 0.141685 (* 1 = 0.141685 loss)
I0630 23:22:21.011042  7564 sgd_solver.cpp:105] Iteration 28000, lr = 0.001
I0630 23:22:24.774507  7564 solver.cpp:218] Iteration 28100 (26.5716 iter/s, 3.76342s/100 iters), loss = 0.176942
I0630 23:22:24.774507  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:22:24.774507  7564 solver.cpp:237]     Train net output #1: loss = 0.176942 (* 1 = 0.176942 loss)
I0630 23:22:24.774507  7564 sgd_solver.cpp:105] Iteration 28100, lr = 0.001
I0630 23:22:28.536929  7564 solver.cpp:218] Iteration 28200 (26.5788 iter/s, 3.7624s/100 iters), loss = 0.157548
I0630 23:22:28.536929  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:22:28.536929  7564 solver.cpp:237]     Train net output #1: loss = 0.157548 (* 1 = 0.157548 loss)
I0630 23:22:28.536929  7564 sgd_solver.cpp:105] Iteration 28200, lr = 0.001
I0630 23:22:32.296447  7564 solver.cpp:218] Iteration 28300 (26.6058 iter/s, 3.75858s/100 iters), loss = 0.165523
I0630 23:22:32.296447  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:22:32.296447  7564 solver.cpp:237]     Train net output #1: loss = 0.165523 (* 1 = 0.165523 loss)
I0630 23:22:32.296447  7564 sgd_solver.cpp:105] Iteration 28300, lr = 0.001
I0630 23:22:36.066722  7564 solver.cpp:218] Iteration 28400 (26.5263 iter/s, 3.76984s/100 iters), loss = 0.173197
I0630 23:22:36.066722  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:22:36.066722  7564 solver.cpp:237]     Train net output #1: loss = 0.173197 (* 1 = 0.173197 loss)
I0630 23:22:36.066722  7564 sgd_solver.cpp:105] Iteration 28400, lr = 0.001
I0630 23:22:39.657248  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:22:39.805735  7564 solver.cpp:330] Iteration 28500, Testing net (#0)
I0630 23:22:39.806236  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:22:40.670470  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:22:40.703505  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8689
I0630 23:22:40.703505  7564 solver.cpp:397]     Test net output #1: loss = 0.415091 (* 1 = 0.415091 loss)
I0630 23:22:40.739143  7564 solver.cpp:218] Iteration 28500 (21.4021 iter/s, 4.67244s/100 iters), loss = 0.146973
I0630 23:22:40.739143  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:22:40.739143  7564 solver.cpp:237]     Train net output #1: loss = 0.146973 (* 1 = 0.146973 loss)
I0630 23:22:40.739143  7564 sgd_solver.cpp:105] Iteration 28500, lr = 0.001
I0630 23:22:44.512208  7564 solver.cpp:218] Iteration 28600 (26.5084 iter/s, 3.77239s/100 iters), loss = 0.133415
I0630 23:22:44.512208  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:22:44.512208  7564 solver.cpp:237]     Train net output #1: loss = 0.133415 (* 1 = 0.133415 loss)
I0630 23:22:44.512208  7564 sgd_solver.cpp:105] Iteration 28600, lr = 0.001
I0630 23:22:48.292282  7564 solver.cpp:218] Iteration 28700 (26.4572 iter/s, 3.77969s/100 iters), loss = 0.21012
I0630 23:22:48.292282  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:22:48.292282  7564 solver.cpp:237]     Train net output #1: loss = 0.21012 (* 1 = 0.21012 loss)
I0630 23:22:48.292282  7564 sgd_solver.cpp:105] Iteration 28700, lr = 0.001
I0630 23:22:52.066236  7564 solver.cpp:218] Iteration 28800 (26.499 iter/s, 3.77372s/100 iters), loss = 0.197758
I0630 23:22:52.066236  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:22:52.066236  7564 solver.cpp:237]     Train net output #1: loss = 0.197758 (* 1 = 0.197758 loss)
I0630 23:22:52.066236  7564 sgd_solver.cpp:105] Iteration 28800, lr = 0.001
I0630 23:22:55.844017  7564 solver.cpp:218] Iteration 28900 (26.4698 iter/s, 3.77788s/100 iters), loss = 0.257518
I0630 23:22:55.844017  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:22:55.844017  7564 solver.cpp:237]     Train net output #1: loss = 0.257518 (* 1 = 0.257518 loss)
I0630 23:22:55.844017  7564 sgd_solver.cpp:105] Iteration 28900, lr = 0.001
I0630 23:22:59.432853  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:22:59.580516  7564 solver.cpp:330] Iteration 29000, Testing net (#0)
I0630 23:22:59.580516  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:23:00.445225  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:23:00.478262  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8706
I0630 23:23:00.478262  7564 solver.cpp:397]     Test net output #1: loss = 0.416499 (* 1 = 0.416499 loss)
I0630 23:23:00.513268  7564 solver.cpp:218] Iteration 29000 (21.4191 iter/s, 4.66873s/100 iters), loss = 0.130585
I0630 23:23:00.513268  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:23:00.513268  7564 solver.cpp:237]     Train net output #1: loss = 0.130585 (* 1 = 0.130585 loss)
I0630 23:23:00.513268  7564 sgd_solver.cpp:105] Iteration 29000, lr = 0.001
I0630 23:23:04.287936  7564 solver.cpp:218] Iteration 29100 (26.4984 iter/s, 3.77381s/100 iters), loss = 0.165873
I0630 23:23:04.287936  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:23:04.287936  7564 solver.cpp:237]     Train net output #1: loss = 0.165873 (* 1 = 0.165873 loss)
I0630 23:23:04.287936  7564 sgd_solver.cpp:105] Iteration 29100, lr = 0.001
I0630 23:23:08.064748  7564 solver.cpp:218] Iteration 29200 (26.481 iter/s, 3.7763s/100 iters), loss = 0.208739
I0630 23:23:08.064748  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:23:08.064748  7564 solver.cpp:237]     Train net output #1: loss = 0.208739 (* 1 = 0.208739 loss)
I0630 23:23:08.064748  7564 sgd_solver.cpp:105] Iteration 29200, lr = 0.001
I0630 23:23:11.833375  7564 solver.cpp:218] Iteration 29300 (26.5362 iter/s, 3.76844s/100 iters), loss = 0.173007
I0630 23:23:11.833375  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:23:11.833375  7564 solver.cpp:237]     Train net output #1: loss = 0.173007 (* 1 = 0.173007 loss)
I0630 23:23:11.833375  7564 sgd_solver.cpp:105] Iteration 29300, lr = 0.001
I0630 23:23:15.613092  7564 solver.cpp:218] Iteration 29400 (26.4587 iter/s, 3.77948s/100 iters), loss = 0.226593
I0630 23:23:15.613092  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:23:15.613092  7564 solver.cpp:237]     Train net output #1: loss = 0.226593 (* 1 = 0.226593 loss)
I0630 23:23:15.613092  7564 sgd_solver.cpp:105] Iteration 29400, lr = 0.001
I0630 23:23:19.198467  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:23:19.348323  7564 solver.cpp:330] Iteration 29500, Testing net (#0)
I0630 23:23:19.348323  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:23:20.211386  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:23:20.244940  7564 solver.cpp:397]     Test net output #0: accuracy = 0.87
I0630 23:23:20.244940  7564 solver.cpp:397]     Test net output #1: loss = 0.417821 (* 1 = 0.417821 loss)
I0630 23:23:20.281234  7564 solver.cpp:218] Iteration 29500 (21.4258 iter/s, 4.66728s/100 iters), loss = 0.192028
I0630 23:23:20.281234  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:23:20.281234  7564 solver.cpp:237]     Train net output #1: loss = 0.192028 (* 1 = 0.192028 loss)
I0630 23:23:20.281234  7564 sgd_solver.cpp:105] Iteration 29500, lr = 0.001
I0630 23:23:24.058826  7564 solver.cpp:218] Iteration 29600 (26.4723 iter/s, 3.77753s/100 iters), loss = 0.143601
I0630 23:23:24.058826  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:23:24.058826  7564 solver.cpp:237]     Train net output #1: loss = 0.143601 (* 1 = 0.143601 loss)
I0630 23:23:24.058826  7564 sgd_solver.cpp:105] Iteration 29600, lr = 0.001
I0630 23:23:27.838503  7564 solver.cpp:218] Iteration 29700 (26.4613 iter/s, 3.7791s/100 iters), loss = 0.245517
I0630 23:23:27.838503  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:23:27.838503  7564 solver.cpp:237]     Train net output #1: loss = 0.245517 (* 1 = 0.245517 loss)
I0630 23:23:27.838503  7564 sgd_solver.cpp:105] Iteration 29700, lr = 0.001
I0630 23:23:31.614636  7564 solver.cpp:218] Iteration 29800 (26.4835 iter/s, 3.77594s/100 iters), loss = 0.129083
I0630 23:23:31.614636  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:23:31.614636  7564 solver.cpp:237]     Train net output #1: loss = 0.129083 (* 1 = 0.129083 loss)
I0630 23:23:31.614636  7564 sgd_solver.cpp:105] Iteration 29800, lr = 0.001
I0630 23:23:35.388806  7564 solver.cpp:218] Iteration 29900 (26.4996 iter/s, 3.77364s/100 iters), loss = 0.214753
I0630 23:23:35.388806  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:23:35.388806  7564 solver.cpp:237]     Train net output #1: loss = 0.214753 (* 1 = 0.214753 loss)
I0630 23:23:35.388806  7564 sgd_solver.cpp:105] Iteration 29900, lr = 0.001
I0630 23:23:39.074064  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:23:39.226179  7564 solver.cpp:330] Iteration 30000, Testing net (#0)
I0630 23:23:39.226179  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:23:40.092687  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:23:40.125221  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8703
I0630 23:23:40.125221  7564 solver.cpp:397]     Test net output #1: loss = 0.417354 (* 1 = 0.417354 loss)
I0630 23:23:40.161249  7564 solver.cpp:218] Iteration 30000 (20.9556 iter/s, 4.772s/100 iters), loss = 0.16007
I0630 23:23:40.161249  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:23:40.161249  7564 solver.cpp:237]     Train net output #1: loss = 0.16007 (* 1 = 0.16007 loss)
I0630 23:23:40.161249  7564 sgd_solver.cpp:105] Iteration 30000, lr = 0.001
I0630 23:23:43.945467  7564 solver.cpp:218] Iteration 30100 (26.4288 iter/s, 3.78375s/100 iters), loss = 0.18408
I0630 23:23:43.945467  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:23:43.945467  7564 solver.cpp:237]     Train net output #1: loss = 0.18408 (* 1 = 0.18408 loss)
I0630 23:23:43.945467  7564 sgd_solver.cpp:105] Iteration 30100, lr = 0.001
I0630 23:23:47.765733  7564 solver.cpp:218] Iteration 30200 (26.1727 iter/s, 3.82077s/100 iters), loss = 0.178491
I0630 23:23:47.765733  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:23:47.765733  7564 solver.cpp:237]     Train net output #1: loss = 0.178491 (* 1 = 0.178491 loss)
I0630 23:23:47.765733  7564 sgd_solver.cpp:105] Iteration 30200, lr = 0.001
I0630 23:23:51.693992  7564 solver.cpp:218] Iteration 30300 (25.4654 iter/s, 3.9269s/100 iters), loss = 0.200277
I0630 23:23:51.693992  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:23:51.693992  7564 solver.cpp:237]     Train net output #1: loss = 0.200277 (* 1 = 0.200277 loss)
I0630 23:23:51.693992  7564 sgd_solver.cpp:105] Iteration 30300, lr = 0.001
I0630 23:23:55.560055  7564 solver.cpp:218] Iteration 30400 (25.8634 iter/s, 3.86647s/100 iters), loss = 0.164336
I0630 23:23:55.560055  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:23:55.560055  7564 solver.cpp:237]     Train net output #1: loss = 0.164336 (* 1 = 0.164336 loss)
I0630 23:23:55.560055  7564 sgd_solver.cpp:105] Iteration 30400, lr = 0.001
I0630 23:23:59.172541  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:23:59.320178  7564 solver.cpp:330] Iteration 30500, Testing net (#0)
I0630 23:23:59.321179  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:24:00.182507  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:24:00.215525  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8723
I0630 23:24:00.215525  7564 solver.cpp:397]     Test net output #1: loss = 0.416524 (* 1 = 0.416524 loss)
I0630 23:24:00.251564  7564 solver.cpp:218] Iteration 30500 (21.3189 iter/s, 4.69068s/100 iters), loss = 0.201875
I0630 23:24:00.251564  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:24:00.251564  7564 solver.cpp:237]     Train net output #1: loss = 0.201875 (* 1 = 0.201875 loss)
I0630 23:24:00.251564  7564 sgd_solver.cpp:105] Iteration 30500, lr = 0.001
I0630 23:24:04.078102  7564 solver.cpp:218] Iteration 30600 (26.1367 iter/s, 3.82604s/100 iters), loss = 0.119603
I0630 23:24:04.078102  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:24:04.078102  7564 solver.cpp:237]     Train net output #1: loss = 0.119603 (* 1 = 0.119603 loss)
I0630 23:24:04.078102  7564 sgd_solver.cpp:105] Iteration 30600, lr = 0.001
I0630 23:24:07.872217  7564 solver.cpp:218] Iteration 30700 (26.3594 iter/s, 3.79371s/100 iters), loss = 0.181605
I0630 23:24:07.872217  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:24:07.872217  7564 solver.cpp:237]     Train net output #1: loss = 0.181605 (* 1 = 0.181605 loss)
I0630 23:24:07.872217  7564 sgd_solver.cpp:105] Iteration 30700, lr = 0.001
I0630 23:24:11.692788  7564 solver.cpp:218] Iteration 30800 (26.1762 iter/s, 3.82026s/100 iters), loss = 0.10875
I0630 23:24:11.692788  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:24:11.692788  7564 solver.cpp:237]     Train net output #1: loss = 0.10875 (* 1 = 0.10875 loss)
I0630 23:24:11.692788  7564 sgd_solver.cpp:105] Iteration 30800, lr = 0.001
I0630 23:24:15.536365  7564 solver.cpp:218] Iteration 30900 (26.017 iter/s, 3.84364s/100 iters), loss = 0.212907
I0630 23:24:15.536365  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:24:15.536365  7564 solver.cpp:237]     Train net output #1: loss = 0.212907 (* 1 = 0.212907 loss)
I0630 23:24:15.536365  7564 sgd_solver.cpp:105] Iteration 30900, lr = 0.001
I0630 23:24:19.152508  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:24:19.301158  7564 solver.cpp:330] Iteration 31000, Testing net (#0)
I0630 23:24:19.302152  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:24:20.168339  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:24:20.201357  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8715
I0630 23:24:20.201357  7564 solver.cpp:397]     Test net output #1: loss = 0.417427 (* 1 = 0.417427 loss)
I0630 23:24:20.237923  7564 solver.cpp:218] Iteration 31000 (21.2713 iter/s, 4.70118s/100 iters), loss = 0.168318
I0630 23:24:20.237923  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:24:20.237923  7564 solver.cpp:237]     Train net output #1: loss = 0.168318 (* 1 = 0.168318 loss)
I0630 23:24:20.237923  7564 sgd_solver.cpp:105] Iteration 31000, lr = 0.001
I0630 23:24:24.041481  7564 solver.cpp:218] Iteration 31100 (26.2947 iter/s, 3.80305s/100 iters), loss = 0.151956
I0630 23:24:24.041481  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:24:24.041481  7564 solver.cpp:237]     Train net output #1: loss = 0.151956 (* 1 = 0.151956 loss)
I0630 23:24:24.041481  7564 sgd_solver.cpp:105] Iteration 31100, lr = 0.001
I0630 23:24:27.901007  7564 solver.cpp:218] Iteration 31200 (25.9131 iter/s, 3.85905s/100 iters), loss = 0.195495
I0630 23:24:27.901007  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:24:27.901007  7564 solver.cpp:237]     Train net output #1: loss = 0.195495 (* 1 = 0.195495 loss)
I0630 23:24:27.901007  7564 sgd_solver.cpp:105] Iteration 31200, lr = 0.001
I0630 23:24:31.751546  7564 solver.cpp:218] Iteration 31300 (25.97 iter/s, 3.85059s/100 iters), loss = 0.191911
I0630 23:24:31.751546  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:24:31.751546  7564 solver.cpp:237]     Train net output #1: loss = 0.191911 (* 1 = 0.191911 loss)
I0630 23:24:31.752547  7564 sgd_solver.cpp:105] Iteration 31300, lr = 0.001
I0630 23:24:35.645922  7564 solver.cpp:218] Iteration 31400 (25.6838 iter/s, 3.89351s/100 iters), loss = 0.172118
I0630 23:24:35.646427  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:24:35.646427  7564 solver.cpp:237]     Train net output #1: loss = 0.172118 (* 1 = 0.172118 loss)
I0630 23:24:35.646427  7564 sgd_solver.cpp:105] Iteration 31400, lr = 0.001
I0630 23:24:39.259816  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:24:39.409464  7564 solver.cpp:330] Iteration 31500, Testing net (#0)
I0630 23:24:39.409464  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:24:40.279515  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:24:40.311563  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8699
I0630 23:24:40.312556  7564 solver.cpp:397]     Test net output #1: loss = 0.420051 (* 1 = 0.420051 loss)
I0630 23:24:40.348598  7564 solver.cpp:218] Iteration 31500 (21.2663 iter/s, 4.70228s/100 iters), loss = 0.12458
I0630 23:24:40.349097  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:24:40.349097  7564 solver.cpp:237]     Train net output #1: loss = 0.12458 (* 1 = 0.12458 loss)
I0630 23:24:40.349097  7564 sgd_solver.cpp:105] Iteration 31500, lr = 0.001
I0630 23:24:44.146931  7564 solver.cpp:218] Iteration 31600 (26.3323 iter/s, 3.79762s/100 iters), loss = 0.13928
I0630 23:24:44.146931  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:24:44.146931  7564 solver.cpp:237]     Train net output #1: loss = 0.13928 (* 1 = 0.13928 loss)
I0630 23:24:44.146931  7564 sgd_solver.cpp:105] Iteration 31600, lr = 0.001
I0630 23:24:47.946038  7564 solver.cpp:218] Iteration 31700 (26.3243 iter/s, 3.79877s/100 iters), loss = 0.184301
I0630 23:24:47.946038  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:24:47.946038  7564 solver.cpp:237]     Train net output #1: loss = 0.184301 (* 1 = 0.184301 loss)
I0630 23:24:47.946038  7564 sgd_solver.cpp:105] Iteration 31700, lr = 0.001
I0630 23:24:51.742965  7564 solver.cpp:218] Iteration 31800 (26.3381 iter/s, 3.79679s/100 iters), loss = 0.194561
I0630 23:24:51.742965  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:24:51.742965  7564 solver.cpp:237]     Train net output #1: loss = 0.194561 (* 1 = 0.194561 loss)
I0630 23:24:51.742965  7564 sgd_solver.cpp:105] Iteration 31800, lr = 0.001
I0630 23:24:55.536504  7564 solver.cpp:218] Iteration 31900 (26.3619 iter/s, 3.79335s/100 iters), loss = 0.163424
I0630 23:24:55.536504  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:24:55.536504  7564 solver.cpp:237]     Train net output #1: loss = 0.163424 (* 1 = 0.163424 loss)
I0630 23:24:55.536504  7564 sgd_solver.cpp:105] Iteration 31900, lr = 0.001
I0630 23:24:59.146260  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:24:59.293977  7564 solver.cpp:330] Iteration 32000, Testing net (#0)
I0630 23:24:59.293977  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:25:00.163023  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:25:00.196068  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8718
I0630 23:25:00.196068  7564 solver.cpp:397]     Test net output #1: loss = 0.419226 (* 1 = 0.419226 loss)
I0630 23:25:00.232086  7564 solver.cpp:218] Iteration 32000 (21.2998 iter/s, 4.69487s/100 iters), loss = 0.104178
I0630 23:25:00.232086  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:25:00.232086  7564 solver.cpp:237]     Train net output #1: loss = 0.104178 (* 1 = 0.104178 loss)
I0630 23:25:00.232086  7564 sgd_solver.cpp:105] Iteration 32000, lr = 0.001
I0630 23:25:04.026692  7564 solver.cpp:218] Iteration 32100 (26.3524 iter/s, 3.79472s/100 iters), loss = 0.187774
I0630 23:25:04.026692  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:25:04.026692  7564 solver.cpp:237]     Train net output #1: loss = 0.187774 (* 1 = 0.187774 loss)
I0630 23:25:04.026692  7564 sgd_solver.cpp:105] Iteration 32100, lr = 0.001
I0630 23:25:07.822085  7564 solver.cpp:218] Iteration 32200 (26.3538 iter/s, 3.79451s/100 iters), loss = 0.114615
I0630 23:25:07.822085  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:25:07.822085  7564 solver.cpp:237]     Train net output #1: loss = 0.114615 (* 1 = 0.114615 loss)
I0630 23:25:07.822085  7564 sgd_solver.cpp:105] Iteration 32200, lr = 0.001
I0630 23:25:11.621244  7564 solver.cpp:218] Iteration 32300 (26.3237 iter/s, 3.79885s/100 iters), loss = 0.158002
I0630 23:25:11.621244  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:25:11.621244  7564 solver.cpp:237]     Train net output #1: loss = 0.158002 (* 1 = 0.158002 loss)
I0630 23:25:11.621244  7564 sgd_solver.cpp:105] Iteration 32300, lr = 0.001
I0630 23:25:15.417855  7564 solver.cpp:218] Iteration 32400 (26.3425 iter/s, 3.79614s/100 iters), loss = 0.23204
I0630 23:25:15.417855  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:25:15.417855  7564 solver.cpp:237]     Train net output #1: loss = 0.23204 (* 1 = 0.23204 loss)
I0630 23:25:15.417855  7564 sgd_solver.cpp:105] Iteration 32400, lr = 0.001
I0630 23:25:19.025369  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:25:19.174278  7564 solver.cpp:330] Iteration 32500, Testing net (#0)
I0630 23:25:19.174278  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:25:20.043798  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:25:20.076858  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8718
I0630 23:25:20.076858  7564 solver.cpp:397]     Test net output #1: loss = 0.422305 (* 1 = 0.422305 loss)
I0630 23:25:20.113415  7564 solver.cpp:218] Iteration 32500 (21.2979 iter/s, 4.6953s/100 iters), loss = 0.173582
I0630 23:25:20.113415  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:25:20.113415  7564 solver.cpp:237]     Train net output #1: loss = 0.173582 (* 1 = 0.173582 loss)
I0630 23:25:20.113415  7564 sgd_solver.cpp:105] Iteration 32500, lr = 0.001
I0630 23:25:23.920394  7564 solver.cpp:218] Iteration 32600 (26.2684 iter/s, 3.80686s/100 iters), loss = 0.227629
I0630 23:25:23.920394  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:25:23.920394  7564 solver.cpp:237]     Train net output #1: loss = 0.227629 (* 1 = 0.227629 loss)
I0630 23:25:23.920394  7564 sgd_solver.cpp:105] Iteration 32600, lr = 0.001
I0630 23:25:27.726016  7564 solver.cpp:218] Iteration 32700 (26.2786 iter/s, 3.80537s/100 iters), loss = 0.139092
I0630 23:25:27.726016  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:25:27.726016  7564 solver.cpp:237]     Train net output #1: loss = 0.139092 (* 1 = 0.139092 loss)
I0630 23:25:27.726016  7564 sgd_solver.cpp:105] Iteration 32700, lr = 0.001
I0630 23:25:31.542668  7564 solver.cpp:218] Iteration 32800 (26.2063 iter/s, 3.81587s/100 iters), loss = 0.192313
I0630 23:25:31.542668  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:25:31.542668  7564 solver.cpp:237]     Train net output #1: loss = 0.192313 (* 1 = 0.192313 loss)
I0630 23:25:31.542668  7564 sgd_solver.cpp:105] Iteration 32800, lr = 0.001
I0630 23:25:35.356665  7564 solver.cpp:218] Iteration 32900 (26.2223 iter/s, 3.81355s/100 iters), loss = 0.178344
I0630 23:25:35.356665  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:25:35.356665  7564 solver.cpp:237]     Train net output #1: loss = 0.178344 (* 1 = 0.178344 loss)
I0630 23:25:35.356665  7564 sgd_solver.cpp:105] Iteration 32900, lr = 0.001
I0630 23:25:38.979854  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:25:39.129101  7564 solver.cpp:330] Iteration 33000, Testing net (#0)
I0630 23:25:39.129101  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:25:40.000306  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:25:40.033339  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8726
I0630 23:25:40.033339  7564 solver.cpp:397]     Test net output #1: loss = 0.421008 (* 1 = 0.421008 loss)
I0630 23:25:40.069362  7564 solver.cpp:218] Iteration 33000 (21.2216 iter/s, 4.71217s/100 iters), loss = 0.11383
I0630 23:25:40.069362  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:25:40.069362  7564 solver.cpp:237]     Train net output #1: loss = 0.11383 (* 1 = 0.11383 loss)
I0630 23:25:40.069362  7564 sgd_solver.cpp:105] Iteration 33000, lr = 0.001
I0630 23:25:43.875494  7564 solver.cpp:218] Iteration 33100 (26.276 iter/s, 3.80576s/100 iters), loss = 0.190774
I0630 23:25:43.875494  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:25:43.875494  7564 solver.cpp:237]     Train net output #1: loss = 0.190774 (* 1 = 0.190774 loss)
I0630 23:25:43.875494  7564 sgd_solver.cpp:105] Iteration 33100, lr = 0.001
I0630 23:25:47.685571  7564 solver.cpp:218] Iteration 33200 (26.2499 iter/s, 3.80954s/100 iters), loss = 0.195369
I0630 23:25:47.685571  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:25:47.685571  7564 solver.cpp:237]     Train net output #1: loss = 0.195369 (* 1 = 0.195369 loss)
I0630 23:25:47.685571  7564 sgd_solver.cpp:105] Iteration 33200, lr = 0.001
I0630 23:25:51.529721  7564 solver.cpp:218] Iteration 33300 (26.0139 iter/s, 3.8441s/100 iters), loss = 0.173797
I0630 23:25:51.529721  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:25:51.529721  7564 solver.cpp:237]     Train net output #1: loss = 0.173797 (* 1 = 0.173797 loss)
I0630 23:25:51.529721  7564 sgd_solver.cpp:105] Iteration 33300, lr = 0.001
I0630 23:25:55.344292  7564 solver.cpp:218] Iteration 33400 (26.2178 iter/s, 3.8142s/100 iters), loss = 0.146923
I0630 23:25:55.344292  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:25:55.344292  7564 solver.cpp:237]     Train net output #1: loss = 0.146923 (* 1 = 0.146923 loss)
I0630 23:25:55.344292  7564 sgd_solver.cpp:105] Iteration 33400, lr = 0.001
I0630 23:25:58.948616  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:25:59.097431  7564 solver.cpp:330] Iteration 33500, Testing net (#0)
I0630 23:25:59.097431  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:25:59.967674  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:26:00.001682  7564 solver.cpp:397]     Test net output #0: accuracy = 0.869
I0630 23:26:00.001682  7564 solver.cpp:397]     Test net output #1: loss = 0.426133 (* 1 = 0.426133 loss)
I0630 23:26:00.037221  7564 solver.cpp:218] Iteration 33500 (21.3107 iter/s, 4.69247s/100 iters), loss = 0.143065
I0630 23:26:00.037727  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:26:00.037727  7564 solver.cpp:237]     Train net output #1: loss = 0.143065 (* 1 = 0.143065 loss)
I0630 23:26:00.037727  7564 sgd_solver.cpp:105] Iteration 33500, lr = 0.001
I0630 23:26:03.865325  7564 solver.cpp:218] Iteration 33600 (26.126 iter/s, 3.82761s/100 iters), loss = 0.19107
I0630 23:26:03.865325  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:26:03.865325  7564 solver.cpp:237]     Train net output #1: loss = 0.19107 (* 1 = 0.19107 loss)
I0630 23:26:03.865325  7564 sgd_solver.cpp:105] Iteration 33600, lr = 0.001
I0630 23:26:07.679940  7564 solver.cpp:218] Iteration 33700 (26.2153 iter/s, 3.81456s/100 iters), loss = 0.131512
I0630 23:26:07.679940  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:26:07.679940  7564 solver.cpp:237]     Train net output #1: loss = 0.131512 (* 1 = 0.131512 loss)
I0630 23:26:07.679940  7564 sgd_solver.cpp:105] Iteration 33700, lr = 0.001
I0630 23:26:11.460732  7564 solver.cpp:218] Iteration 33800 (26.4547 iter/s, 3.78005s/100 iters), loss = 0.21981
I0630 23:26:11.460732  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:26:11.460732  7564 solver.cpp:237]     Train net output #1: loss = 0.21981 (* 1 = 0.21981 loss)
I0630 23:26:11.460732  7564 sgd_solver.cpp:105] Iteration 33800, lr = 0.001
I0630 23:26:15.242100  7564 solver.cpp:218] Iteration 33900 (26.45 iter/s, 3.78072s/100 iters), loss = 0.20382
I0630 23:26:15.242100  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:26:15.242100  7564 solver.cpp:237]     Train net output #1: loss = 0.20382 (* 1 = 0.20382 loss)
I0630 23:26:15.242100  7564 sgd_solver.cpp:105] Iteration 33900, lr = 0.001
I0630 23:26:18.851181  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:26:19.002090  7564 solver.cpp:330] Iteration 34000, Testing net (#0)
I0630 23:26:19.002090  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:26:19.868032  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:26:19.901070  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8709
I0630 23:26:19.901070  7564 solver.cpp:397]     Test net output #1: loss = 0.424544 (* 1 = 0.424544 loss)
I0630 23:26:19.937091  7564 solver.cpp:218] Iteration 34000 (21.2982 iter/s, 4.69523s/100 iters), loss = 0.11981
I0630 23:26:19.937091  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:26:19.937091  7564 solver.cpp:237]     Train net output #1: loss = 0.11981 (* 1 = 0.11981 loss)
I0630 23:26:19.937091  7564 sgd_solver.cpp:105] Iteration 34000, lr = 0.001
I0630 23:26:23.717545  7564 solver.cpp:218] Iteration 34100 (26.4536 iter/s, 3.7802s/100 iters), loss = 0.191352
I0630 23:26:23.717545  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:26:23.717545  7564 solver.cpp:237]     Train net output #1: loss = 0.191352 (* 1 = 0.191352 loss)
I0630 23:26:23.717545  7564 sgd_solver.cpp:105] Iteration 34100, lr = 0.001
I0630 23:26:27.491892  7564 solver.cpp:218] Iteration 34200 (26.4981 iter/s, 3.77385s/100 iters), loss = 0.141182
I0630 23:26:27.491892  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:26:27.491892  7564 solver.cpp:237]     Train net output #1: loss = 0.141182 (* 1 = 0.141182 loss)
I0630 23:26:27.491892  7564 sgd_solver.cpp:105] Iteration 34200, lr = 0.001
I0630 23:26:31.267989  7564 solver.cpp:218] Iteration 34300 (26.4878 iter/s, 3.77533s/100 iters), loss = 0.170318
I0630 23:26:31.267989  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:26:31.267989  7564 solver.cpp:237]     Train net output #1: loss = 0.170318 (* 1 = 0.170318 loss)
I0630 23:26:31.267989  7564 sgd_solver.cpp:105] Iteration 34300, lr = 0.001
I0630 23:26:35.059996  7564 solver.cpp:218] Iteration 34400 (26.3726 iter/s, 3.79181s/100 iters), loss = 0.191948
I0630 23:26:35.059996  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:26:35.060497  7564 solver.cpp:237]     Train net output #1: loss = 0.191948 (* 1 = 0.191948 loss)
I0630 23:26:35.060497  7564 sgd_solver.cpp:105] Iteration 34400, lr = 0.001
I0630 23:26:38.651073  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:26:38.798720  7564 solver.cpp:330] Iteration 34500, Testing net (#0)
I0630 23:26:38.798720  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:26:39.666280  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:26:39.699571  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8724
I0630 23:26:39.699571  7564 solver.cpp:397]     Test net output #1: loss = 0.423246 (* 1 = 0.423246 loss)
I0630 23:26:39.734592  7564 solver.cpp:218] Iteration 34500 (21.3915 iter/s, 4.67476s/100 iters), loss = 0.106794
I0630 23:26:39.735599  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:26:39.735599  7564 solver.cpp:237]     Train net output #1: loss = 0.106794 (* 1 = 0.106794 loss)
I0630 23:26:39.735599  7564 sgd_solver.cpp:105] Iteration 34500, lr = 0.001
I0630 23:26:43.532537  7564 solver.cpp:218] Iteration 34600 (26.3349 iter/s, 3.79724s/100 iters), loss = 0.0981858
I0630 23:26:43.532537  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:26:43.532537  7564 solver.cpp:237]     Train net output #1: loss = 0.0981859 (* 1 = 0.0981859 loss)
I0630 23:26:43.532537  7564 sgd_solver.cpp:105] Iteration 34600, lr = 0.001
I0630 23:26:47.314060  7564 solver.cpp:218] Iteration 34700 (26.4497 iter/s, 3.78076s/100 iters), loss = 0.164139
I0630 23:26:47.314060  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:26:47.314060  7564 solver.cpp:237]     Train net output #1: loss = 0.164139 (* 1 = 0.164139 loss)
I0630 23:26:47.314060  7564 sgd_solver.cpp:105] Iteration 34700, lr = 0.001
I0630 23:26:51.108330  7564 solver.cpp:218] Iteration 34800 (26.356 iter/s, 3.7942s/100 iters), loss = 0.132819
I0630 23:26:51.108330  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:26:51.108330  7564 solver.cpp:237]     Train net output #1: loss = 0.132819 (* 1 = 0.132819 loss)
I0630 23:26:51.108330  7564 sgd_solver.cpp:105] Iteration 34800, lr = 0.001
I0630 23:26:54.903576  7564 solver.cpp:218] Iteration 34900 (26.3526 iter/s, 3.79468s/100 iters), loss = 0.151174
I0630 23:26:54.903576  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:26:54.903576  7564 solver.cpp:237]     Train net output #1: loss = 0.151174 (* 1 = 0.151174 loss)
I0630 23:26:54.903576  7564 sgd_solver.cpp:105] Iteration 34900, lr = 0.001
I0630 23:26:58.529775  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:26:58.679903  7564 solver.cpp:330] Iteration 35000, Testing net (#0)
I0630 23:26:58.680903  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:26:59.548529  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:26:59.581537  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8736
I0630 23:26:59.581537  7564 solver.cpp:397]     Test net output #1: loss = 0.425843 (* 1 = 0.425843 loss)
I0630 23:26:59.618134  7564 solver.cpp:218] Iteration 35000 (21.2132 iter/s, 4.71405s/100 iters), loss = 0.0985547
I0630 23:26:59.618134  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0630 23:26:59.618134  7564 solver.cpp:237]     Train net output #1: loss = 0.0985547 (* 1 = 0.0985547 loss)
I0630 23:26:59.618134  7564 sgd_solver.cpp:105] Iteration 35000, lr = 0.001
I0630 23:27:03.427235  7564 solver.cpp:218] Iteration 35100 (26.2533 iter/s, 3.80905s/100 iters), loss = 0.162609
I0630 23:27:03.427235  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:27:03.427235  7564 solver.cpp:237]     Train net output #1: loss = 0.162609 (* 1 = 0.162609 loss)
I0630 23:27:03.427235  7564 sgd_solver.cpp:105] Iteration 35100, lr = 0.001
I0630 23:27:07.212098  7564 solver.cpp:218] Iteration 35200 (26.4195 iter/s, 3.78509s/100 iters), loss = 0.149497
I0630 23:27:07.213104  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:27:07.213104  7564 solver.cpp:237]     Train net output #1: loss = 0.149497 (* 1 = 0.149497 loss)
I0630 23:27:07.213104  7564 sgd_solver.cpp:105] Iteration 35200, lr = 0.001
I0630 23:27:11.002125  7564 solver.cpp:218] Iteration 35300 (26.3925 iter/s, 3.78895s/100 iters), loss = 0.197813
I0630 23:27:11.002125  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:27:11.002125  7564 solver.cpp:237]     Train net output #1: loss = 0.197813 (* 1 = 0.197813 loss)
I0630 23:27:11.002125  7564 sgd_solver.cpp:105] Iteration 35300, lr = 0.001
I0630 23:27:14.789857  7564 solver.cpp:218] Iteration 35400 (26.4045 iter/s, 3.78723s/100 iters), loss = 0.186556
I0630 23:27:14.789857  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:27:14.789857  7564 solver.cpp:237]     Train net output #1: loss = 0.186556 (* 1 = 0.186556 loss)
I0630 23:27:14.789857  7564 sgd_solver.cpp:105] Iteration 35400, lr = 0.001
I0630 23:27:18.400673  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:27:18.551276  7564 solver.cpp:330] Iteration 35500, Testing net (#0)
I0630 23:27:18.551276  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:27:19.425928  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:27:19.458951  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8712
I0630 23:27:19.458951  7564 solver.cpp:397]     Test net output #1: loss = 0.425443 (* 1 = 0.425443 loss)
I0630 23:27:19.494987  7564 solver.cpp:218] Iteration 35500 (21.2536 iter/s, 4.70508s/100 iters), loss = 0.141792
I0630 23:27:19.494987  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:27:19.494987  7564 solver.cpp:237]     Train net output #1: loss = 0.141792 (* 1 = 0.141792 loss)
I0630 23:27:19.494987  7564 sgd_solver.cpp:105] Iteration 35500, lr = 0.001
I0630 23:27:23.282335  7564 solver.cpp:218] Iteration 35600 (26.4069 iter/s, 3.7869s/100 iters), loss = 0.188446
I0630 23:27:23.282335  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:27:23.282335  7564 solver.cpp:237]     Train net output #1: loss = 0.188446 (* 1 = 0.188446 loss)
I0630 23:27:23.282335  7564 sgd_solver.cpp:105] Iteration 35600, lr = 0.001
I0630 23:27:27.108909  7564 solver.cpp:218] Iteration 35700 (26.1343 iter/s, 3.82639s/100 iters), loss = 0.173453
I0630 23:27:27.108909  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:27:27.108909  7564 solver.cpp:237]     Train net output #1: loss = 0.173453 (* 1 = 0.173453 loss)
I0630 23:27:27.108909  7564 sgd_solver.cpp:105] Iteration 35700, lr = 0.001
I0630 23:27:30.962486  7564 solver.cpp:218] Iteration 35800 (25.9555 iter/s, 3.85275s/100 iters), loss = 0.143383
I0630 23:27:30.962486  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:27:30.962486  7564 solver.cpp:237]     Train net output #1: loss = 0.143383 (* 1 = 0.143383 loss)
I0630 23:27:30.962486  7564 sgd_solver.cpp:105] Iteration 35800, lr = 0.001
I0630 23:27:34.780064  7564 solver.cpp:218] Iteration 35900 (26.1994 iter/s, 3.81688s/100 iters), loss = 0.263409
I0630 23:27:34.780064  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:27:34.780064  7564 solver.cpp:237]     Train net output #1: loss = 0.263409 (* 1 = 0.263409 loss)
I0630 23:27:34.780064  7564 sgd_solver.cpp:105] Iteration 35900, lr = 0.001
I0630 23:27:38.538794  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:27:38.692404  7564 solver.cpp:330] Iteration 36000, Testing net (#0)
I0630 23:27:38.692905  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:27:39.579020  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:27:39.613044  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8723
I0630 23:27:39.613044  7564 solver.cpp:397]     Test net output #1: loss = 0.430018 (* 1 = 0.430018 loss)
I0630 23:27:39.650084  7564 solver.cpp:218] Iteration 36000 (20.5349 iter/s, 4.86976s/100 iters), loss = 0.142661
I0630 23:27:39.650084  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:27:39.650084  7564 solver.cpp:237]     Train net output #1: loss = 0.142661 (* 1 = 0.142661 loss)
I0630 23:27:39.650084  7564 sgd_solver.cpp:105] Iteration 36000, lr = 0.001
I0630 23:27:43.728971  7564 solver.cpp:218] Iteration 36100 (24.5196 iter/s, 4.07837s/100 iters), loss = 0.160112
I0630 23:27:43.728971  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:27:43.728971  7564 solver.cpp:237]     Train net output #1: loss = 0.160112 (* 1 = 0.160112 loss)
I0630 23:27:43.728971  7564 sgd_solver.cpp:105] Iteration 36100, lr = 0.001
I0630 23:27:47.680171  7564 solver.cpp:218] Iteration 36200 (25.3092 iter/s, 3.95113s/100 iters), loss = 0.167776
I0630 23:27:47.680671  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:27:47.680671  7564 solver.cpp:237]     Train net output #1: loss = 0.167777 (* 1 = 0.167777 loss)
I0630 23:27:47.680671  7564 sgd_solver.cpp:105] Iteration 36200, lr = 0.001
I0630 23:27:51.648543  7564 solver.cpp:218] Iteration 36300 (25.202 iter/s, 3.96793s/100 iters), loss = 0.166894
I0630 23:27:51.649044  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:27:51.649044  7564 solver.cpp:237]     Train net output #1: loss = 0.166894 (* 1 = 0.166894 loss)
I0630 23:27:51.649044  7564 sgd_solver.cpp:105] Iteration 36300, lr = 0.001
I0630 23:27:55.635381  7564 solver.cpp:218] Iteration 36400 (25.0867 iter/s, 3.98617s/100 iters), loss = 0.177939
I0630 23:27:55.635381  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:27:55.635381  7564 solver.cpp:237]     Train net output #1: loss = 0.177939 (* 1 = 0.177939 loss)
I0630 23:27:55.635381  7564 sgd_solver.cpp:105] Iteration 36400, lr = 0.001
I0630 23:27:59.415901  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:27:59.571513  7564 solver.cpp:330] Iteration 36500, Testing net (#0)
I0630 23:27:59.571513  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:28:00.466166  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:28:00.500185  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8703
I0630 23:28:00.500185  7564 solver.cpp:397]     Test net output #1: loss = 0.428571 (* 1 = 0.428571 loss)
I0630 23:28:00.538202  7564 solver.cpp:218] Iteration 36500 (20.3984 iter/s, 4.90234s/100 iters), loss = 0.183674
I0630 23:28:00.538202  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:28:00.538202  7564 solver.cpp:237]     Train net output #1: loss = 0.183674 (* 1 = 0.183674 loss)
I0630 23:28:00.538202  7564 sgd_solver.cpp:105] Iteration 36500, lr = 0.001
I0630 23:28:04.519547  7564 solver.cpp:218] Iteration 36600 (25.1179 iter/s, 3.98122s/100 iters), loss = 0.118124
I0630 23:28:04.520051  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:28:04.520051  7564 solver.cpp:237]     Train net output #1: loss = 0.118124 (* 1 = 0.118124 loss)
I0630 23:28:04.520051  7564 sgd_solver.cpp:105] Iteration 36600, lr = 0.001
I0630 23:28:08.500368  7564 solver.cpp:218] Iteration 36700 (25.126 iter/s, 3.97993s/100 iters), loss = 0.14954
I0630 23:28:08.500368  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:28:08.500368  7564 solver.cpp:237]     Train net output #1: loss = 0.14954 (* 1 = 0.14954 loss)
I0630 23:28:08.500368  7564 sgd_solver.cpp:105] Iteration 36700, lr = 0.001
I0630 23:28:12.473731  7564 solver.cpp:218] Iteration 36800 (25.1681 iter/s, 3.97329s/100 iters), loss = 0.19356
I0630 23:28:12.473731  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 23:28:12.473731  7564 solver.cpp:237]     Train net output #1: loss = 0.19356 (* 1 = 0.19356 loss)
I0630 23:28:12.473731  7564 sgd_solver.cpp:105] Iteration 36800, lr = 0.001
I0630 23:28:16.452610  7564 solver.cpp:218] Iteration 36900 (25.1355 iter/s, 3.97844s/100 iters), loss = 0.124383
I0630 23:28:16.452610  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:28:16.452610  7564 solver.cpp:237]     Train net output #1: loss = 0.124383 (* 1 = 0.124383 loss)
I0630 23:28:16.452610  7564 sgd_solver.cpp:105] Iteration 36900, lr = 0.001
I0630 23:28:20.237285  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:28:20.394914  7564 solver.cpp:330] Iteration 37000, Testing net (#0)
I0630 23:28:20.394914  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:28:21.296541  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:28:21.329577  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:28:21.329577  7564 solver.cpp:397]     Test net output #1: loss = 0.431948 (* 1 = 0.431948 loss)
I0630 23:28:21.367590  7564 solver.cpp:218] Iteration 37000 (20.348 iter/s, 4.91449s/100 iters), loss = 0.141353
I0630 23:28:21.367590  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:28:21.367590  7564 solver.cpp:237]     Train net output #1: loss = 0.141353 (* 1 = 0.141353 loss)
I0630 23:28:21.367590  7564 sgd_solver.cpp:105] Iteration 37000, lr = 0.001
I0630 23:28:25.340917  7564 solver.cpp:218] Iteration 37100 (25.1704 iter/s, 3.97292s/100 iters), loss = 0.192861
I0630 23:28:25.340917  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:28:25.340917  7564 solver.cpp:237]     Train net output #1: loss = 0.192861 (* 1 = 0.192861 loss)
I0630 23:28:25.340917  7564 sgd_solver.cpp:105] Iteration 37100, lr = 0.001
I0630 23:28:29.312759  7564 solver.cpp:218] Iteration 37200 (25.1805 iter/s, 3.97133s/100 iters), loss = 0.170981
I0630 23:28:29.312759  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:28:29.312759  7564 solver.cpp:237]     Train net output #1: loss = 0.170981 (* 1 = 0.170981 loss)
I0630 23:28:29.312759  7564 sgd_solver.cpp:105] Iteration 37200, lr = 0.001
I0630 23:28:33.283567  7564 solver.cpp:218] Iteration 37300 (25.1841 iter/s, 3.97076s/100 iters), loss = 0.144101
I0630 23:28:33.284068  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:28:33.284068  7564 solver.cpp:237]     Train net output #1: loss = 0.144101 (* 1 = 0.144101 loss)
I0630 23:28:33.284068  7564 sgd_solver.cpp:105] Iteration 37300, lr = 0.001
I0630 23:28:37.263409  7564 solver.cpp:218] Iteration 37400 (25.1311 iter/s, 3.97913s/100 iters), loss = 0.249687
I0630 23:28:37.263409  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:28:37.263409  7564 solver.cpp:237]     Train net output #1: loss = 0.249687 (* 1 = 0.249687 loss)
I0630 23:28:37.263409  7564 sgd_solver.cpp:105] Iteration 37400, lr = 0.001
I0630 23:28:41.045161  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:28:41.200779  7564 solver.cpp:330] Iteration 37500, Testing net (#0)
I0630 23:28:41.200779  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:28:42.094424  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:28:42.128948  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8729
I0630 23:28:42.128948  7564 solver.cpp:397]     Test net output #1: loss = 0.43193 (* 1 = 0.43193 loss)
I0630 23:28:42.166977  7564 solver.cpp:218] Iteration 37500 (20.3957 iter/s, 4.90299s/100 iters), loss = 0.0922246
I0630 23:28:42.166977  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:28:42.166977  7564 solver.cpp:237]     Train net output #1: loss = 0.0922247 (* 1 = 0.0922247 loss)
I0630 23:28:42.166977  7564 sgd_solver.cpp:105] Iteration 37500, lr = 0.001
I0630 23:28:46.132432  7564 solver.cpp:218] Iteration 37600 (25.2194 iter/s, 3.96521s/100 iters), loss = 0.146377
I0630 23:28:46.132432  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:28:46.132432  7564 solver.cpp:237]     Train net output #1: loss = 0.146377 (* 1 = 0.146377 loss)
I0630 23:28:46.132432  7564 sgd_solver.cpp:105] Iteration 37600, lr = 0.001
I0630 23:28:50.103261  7564 solver.cpp:218] Iteration 37700 (25.1852 iter/s, 3.97058s/100 iters), loss = 0.13025
I0630 23:28:50.103762  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:28:50.103762  7564 solver.cpp:237]     Train net output #1: loss = 0.13025 (* 1 = 0.13025 loss)
I0630 23:28:50.103762  7564 sgd_solver.cpp:105] Iteration 37700, lr = 0.001
I0630 23:28:54.075099  7564 solver.cpp:218] Iteration 37800 (25.1828 iter/s, 3.97096s/100 iters), loss = 0.213861
I0630 23:28:54.075099  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:28:54.075099  7564 solver.cpp:237]     Train net output #1: loss = 0.213861 (* 1 = 0.213861 loss)
I0630 23:28:54.075099  7564 sgd_solver.cpp:105] Iteration 37800, lr = 0.001
I0630 23:28:58.046913  7564 solver.cpp:218] Iteration 37900 (25.1772 iter/s, 3.97185s/100 iters), loss = 0.136543
I0630 23:28:58.046913  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:28:58.046913  7564 solver.cpp:237]     Train net output #1: loss = 0.136543 (* 1 = 0.136543 loss)
I0630 23:28:58.046913  7564 sgd_solver.cpp:105] Iteration 37900, lr = 0.001
I0630 23:29:01.824864  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:29:01.980976  7564 solver.cpp:330] Iteration 38000, Testing net (#0)
I0630 23:29:01.980976  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:29:02.874111  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:29:02.908146  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8723
I0630 23:29:02.908146  7564 solver.cpp:397]     Test net output #1: loss = 0.434653 (* 1 = 0.434653 loss)
I0630 23:29:02.946163  7564 solver.cpp:218] Iteration 38000 (20.4135 iter/s, 4.89871s/100 iters), loss = 0.140663
I0630 23:29:02.946163  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:29:02.946163  7564 solver.cpp:237]     Train net output #1: loss = 0.140663 (* 1 = 0.140663 loss)
I0630 23:29:02.946163  7564 sgd_solver.cpp:46] MultiStep Status: Iteration 38000, step = 2
I0630 23:29:02.946163  7564 sgd_solver.cpp:105] Iteration 38000, lr = 0.0001
I0630 23:29:06.922006  7564 solver.cpp:218] Iteration 38100 (25.1551 iter/s, 3.97534s/100 iters), loss = 0.148184
I0630 23:29:06.922006  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:29:06.922006  7564 solver.cpp:237]     Train net output #1: loss = 0.148184 (* 1 = 0.148184 loss)
I0630 23:29:06.922006  7564 sgd_solver.cpp:105] Iteration 38100, lr = 0.0001
I0630 23:29:10.899451  7564 solver.cpp:218] Iteration 38200 (25.1431 iter/s, 3.97723s/100 iters), loss = 0.143048
I0630 23:29:10.899451  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:29:10.899451  7564 solver.cpp:237]     Train net output #1: loss = 0.143048 (* 1 = 0.143048 loss)
I0630 23:29:10.899451  7564 sgd_solver.cpp:105] Iteration 38200, lr = 0.0001
I0630 23:29:14.876314  7564 solver.cpp:218] Iteration 38300 (25.149 iter/s, 3.97631s/100 iters), loss = 0.164906
I0630 23:29:14.876314  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:29:14.876314  7564 solver.cpp:237]     Train net output #1: loss = 0.164906 (* 1 = 0.164906 loss)
I0630 23:29:14.876314  7564 sgd_solver.cpp:105] Iteration 38300, lr = 0.0001
I0630 23:29:18.851627  7564 solver.cpp:218] Iteration 38400 (25.1581 iter/s, 3.97487s/100 iters), loss = 0.157149
I0630 23:29:18.851627  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:29:18.851627  7564 solver.cpp:237]     Train net output #1: loss = 0.157149 (* 1 = 0.157149 loss)
I0630 23:29:18.851627  7564 sgd_solver.cpp:105] Iteration 38400, lr = 0.0001
I0630 23:29:22.632843  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:29:22.789471  7564 solver.cpp:330] Iteration 38500, Testing net (#0)
I0630 23:29:22.789471  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:29:23.684090  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:29:23.718627  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8723
I0630 23:29:23.718627  7564 solver.cpp:397]     Test net output #1: loss = 0.429731 (* 1 = 0.429731 loss)
I0630 23:29:23.756142  7564 solver.cpp:218] Iteration 38500 (20.3906 iter/s, 4.90423s/100 iters), loss = 0.144297
I0630 23:29:23.756142  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:29:23.756142  7564 solver.cpp:237]     Train net output #1: loss = 0.144297 (* 1 = 0.144297 loss)
I0630 23:29:23.756142  7564 sgd_solver.cpp:105] Iteration 38500, lr = 0.0001
I0630 23:29:27.729470  7564 solver.cpp:218] Iteration 38600 (25.1712 iter/s, 3.9728s/100 iters), loss = 0.153983
I0630 23:29:27.729470  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:29:27.729470  7564 solver.cpp:237]     Train net output #1: loss = 0.153983 (* 1 = 0.153983 loss)
I0630 23:29:27.729470  7564 sgd_solver.cpp:105] Iteration 38600, lr = 0.0001
I0630 23:29:31.697558  7564 solver.cpp:218] Iteration 38700 (25.2036 iter/s, 3.96768s/100 iters), loss = 0.156672
I0630 23:29:31.697558  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:29:31.697558  7564 solver.cpp:237]     Train net output #1: loss = 0.156672 (* 1 = 0.156672 loss)
I0630 23:29:31.697558  7564 sgd_solver.cpp:105] Iteration 38700, lr = 0.0001
I0630 23:29:35.671876  7564 solver.cpp:218] Iteration 38800 (25.1636 iter/s, 3.97399s/100 iters), loss = 0.125051
I0630 23:29:35.671876  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:29:35.671876  7564 solver.cpp:237]     Train net output #1: loss = 0.125051 (* 1 = 0.125051 loss)
I0630 23:29:35.671876  7564 sgd_solver.cpp:105] Iteration 38800, lr = 0.0001
I0630 23:29:39.640211  7564 solver.cpp:218] Iteration 38900 (25.1999 iter/s, 3.96827s/100 iters), loss = 0.235916
I0630 23:29:39.640712  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:29:39.640712  7564 solver.cpp:237]     Train net output #1: loss = 0.235916 (* 1 = 0.235916 loss)
I0630 23:29:39.640712  7564 sgd_solver.cpp:105] Iteration 38900, lr = 0.0001
I0630 23:29:43.414901  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:29:43.570010  7564 solver.cpp:330] Iteration 39000, Testing net (#0)
I0630 23:29:43.570510  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:29:44.462129  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:29:44.495654  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8716
I0630 23:29:44.495654  7564 solver.cpp:397]     Test net output #1: loss = 0.42931 (* 1 = 0.42931 loss)
I0630 23:29:44.533681  7564 solver.cpp:218] Iteration 39000 (20.4376 iter/s, 4.89294s/100 iters), loss = 0.130499
I0630 23:29:44.533681  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:29:44.534181  7564 solver.cpp:237]     Train net output #1: loss = 0.130499 (* 1 = 0.130499 loss)
I0630 23:29:44.534181  7564 sgd_solver.cpp:105] Iteration 39000, lr = 0.0001
I0630 23:29:48.510547  7564 solver.cpp:218] Iteration 39100 (25.1499 iter/s, 3.97616s/100 iters), loss = 0.121568
I0630 23:29:48.510547  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:29:48.510547  7564 solver.cpp:237]     Train net output #1: loss = 0.121568 (* 1 = 0.121568 loss)
I0630 23:29:48.510547  7564 sgd_solver.cpp:105] Iteration 39100, lr = 0.0001
I0630 23:29:52.482890  7564 solver.cpp:218] Iteration 39200 (25.1753 iter/s, 3.97214s/100 iters), loss = 0.147305
I0630 23:29:52.482890  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:29:52.482890  7564 solver.cpp:237]     Train net output #1: loss = 0.147305 (* 1 = 0.147305 loss)
I0630 23:29:52.482890  7564 sgd_solver.cpp:105] Iteration 39200, lr = 0.0001
I0630 23:29:56.450228  7564 solver.cpp:218] Iteration 39300 (25.2077 iter/s, 3.96704s/100 iters), loss = 0.169881
I0630 23:29:56.450228  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:29:56.450228  7564 solver.cpp:237]     Train net output #1: loss = 0.169881 (* 1 = 0.169881 loss)
I0630 23:29:56.450228  7564 sgd_solver.cpp:105] Iteration 39300, lr = 0.0001
I0630 23:30:00.435564  7564 solver.cpp:218] Iteration 39400 (25.0954 iter/s, 3.9848s/100 iters), loss = 0.18971
I0630 23:30:00.435564  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:30:00.435564  7564 solver.cpp:237]     Train net output #1: loss = 0.18971 (* 1 = 0.18971 loss)
I0630 23:30:00.435564  7564 sgd_solver.cpp:105] Iteration 39400, lr = 0.0001
I0630 23:30:04.230778  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:30:04.386875  7564 solver.cpp:330] Iteration 39500, Testing net (#0)
I0630 23:30:04.386875  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:30:05.283028  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:30:05.318051  7564 solver.cpp:397]     Test net output #0: accuracy = 0.873
I0630 23:30:05.318051  7564 solver.cpp:397]     Test net output #1: loss = 0.428512 (* 1 = 0.428512 loss)
I0630 23:30:05.356063  7564 solver.cpp:218] Iteration 39500 (20.3251 iter/s, 4.92001s/100 iters), loss = 0.104212
I0630 23:30:05.356063  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:30:05.356063  7564 solver.cpp:237]     Train net output #1: loss = 0.104211 (* 1 = 0.104211 loss)
I0630 23:30:05.356063  7564 sgd_solver.cpp:105] Iteration 39500, lr = 0.0001
I0630 23:30:09.330402  7564 solver.cpp:218] Iteration 39600 (25.1637 iter/s, 3.97398s/100 iters), loss = 0.117144
I0630 23:30:09.330402  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:30:09.330402  7564 solver.cpp:237]     Train net output #1: loss = 0.117144 (* 1 = 0.117144 loss)
I0630 23:30:09.330402  7564 sgd_solver.cpp:105] Iteration 39600, lr = 0.0001
I0630 23:30:13.302312  7564 solver.cpp:218] Iteration 39700 (25.18 iter/s, 3.97141s/100 iters), loss = 0.16343
I0630 23:30:13.302312  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:30:13.302312  7564 solver.cpp:237]     Train net output #1: loss = 0.16343 (* 1 = 0.16343 loss)
I0630 23:30:13.302312  7564 sgd_solver.cpp:105] Iteration 39700, lr = 0.0001
I0630 23:30:17.276631  7564 solver.cpp:218] Iteration 39800 (25.1633 iter/s, 3.97404s/100 iters), loss = 0.128669
I0630 23:30:17.276631  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:30:17.276631  7564 solver.cpp:237]     Train net output #1: loss = 0.128669 (* 1 = 0.128669 loss)
I0630 23:30:17.276631  7564 sgd_solver.cpp:105] Iteration 39800, lr = 0.0001
I0630 23:30:21.251476  7564 solver.cpp:218] Iteration 39900 (25.1625 iter/s, 3.97417s/100 iters), loss = 0.153756
I0630 23:30:21.251476  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:30:21.251476  7564 solver.cpp:237]     Train net output #1: loss = 0.153756 (* 1 = 0.153756 loss)
I0630 23:30:21.251476  7564 sgd_solver.cpp:105] Iteration 39900, lr = 0.0001
I0630 23:30:25.030697  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:30:25.186794  7564 solver.cpp:330] Iteration 40000, Testing net (#0)
I0630 23:30:25.187294  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:30:26.085933  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:30:26.120993  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I0630 23:30:26.120993  7564 solver.cpp:397]     Test net output #1: loss = 0.427872 (* 1 = 0.427872 loss)
I0630 23:30:26.158499  7564 solver.cpp:218] Iteration 40000 (20.3795 iter/s, 4.90689s/100 iters), loss = 0.0992007
I0630 23:30:26.158999  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:30:26.158999  7564 solver.cpp:237]     Train net output #1: loss = 0.0992006 (* 1 = 0.0992006 loss)
I0630 23:30:26.158999  7564 sgd_solver.cpp:105] Iteration 40000, lr = 0.0001
I0630 23:30:30.138829  7564 solver.cpp:218] Iteration 40100 (25.128 iter/s, 3.97962s/100 iters), loss = 0.128796
I0630 23:30:30.138829  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:30:30.138829  7564 solver.cpp:237]     Train net output #1: loss = 0.128796 (* 1 = 0.128796 loss)
I0630 23:30:30.138829  7564 sgd_solver.cpp:105] Iteration 40100, lr = 0.0001
I0630 23:30:34.164731  7564 solver.cpp:218] Iteration 40200 (24.8397 iter/s, 4.02581s/100 iters), loss = 0.195524
I0630 23:30:34.164731  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:30:34.164731  7564 solver.cpp:237]     Train net output #1: loss = 0.195524 (* 1 = 0.195524 loss)
I0630 23:30:34.164731  7564 sgd_solver.cpp:105] Iteration 40200, lr = 0.0001
I0630 23:30:38.182090  7564 solver.cpp:218] Iteration 40300 (24.8948 iter/s, 4.0169s/100 iters), loss = 0.152351
I0630 23:30:38.182090  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:30:38.182090  7564 solver.cpp:237]     Train net output #1: loss = 0.152351 (* 1 = 0.152351 loss)
I0630 23:30:38.182090  7564 sgd_solver.cpp:105] Iteration 40300, lr = 0.0001
I0630 23:30:42.220973  7564 solver.cpp:218] Iteration 40400 (24.7629 iter/s, 4.0383s/100 iters), loss = 0.141581
I0630 23:30:42.220973  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:30:42.220973  7564 solver.cpp:237]     Train net output #1: loss = 0.141581 (* 1 = 0.141581 loss)
I0630 23:30:42.220973  7564 sgd_solver.cpp:105] Iteration 40400, lr = 0.0001
I0630 23:30:46.047703  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:30:46.202813  7564 solver.cpp:330] Iteration 40500, Testing net (#0)
I0630 23:30:46.202813  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:30:47.092947  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:30:47.126971  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8723
I0630 23:30:47.126971  7564 solver.cpp:397]     Test net output #1: loss = 0.428684 (* 1 = 0.428684 loss)
I0630 23:30:47.165007  7564 solver.cpp:218] Iteration 40500 (20.2274 iter/s, 4.94379s/100 iters), loss = 0.12714
I0630 23:30:47.165007  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:30:47.165007  7564 solver.cpp:237]     Train net output #1: loss = 0.12714 (* 1 = 0.12714 loss)
I0630 23:30:47.165007  7564 sgd_solver.cpp:105] Iteration 40500, lr = 0.0001
I0630 23:30:51.128319  7564 solver.cpp:218] Iteration 40600 (25.2324 iter/s, 3.96316s/100 iters), loss = 0.111954
I0630 23:30:51.128818  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:30:51.128818  7564 solver.cpp:237]     Train net output #1: loss = 0.111954 (* 1 = 0.111954 loss)
I0630 23:30:51.128818  7564 sgd_solver.cpp:105] Iteration 40600, lr = 0.0001
I0630 23:30:55.101193  7564 solver.cpp:218] Iteration 40700 (25.1751 iter/s, 3.97219s/100 iters), loss = 0.11568
I0630 23:30:55.101193  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:30:55.101193  7564 solver.cpp:237]     Train net output #1: loss = 0.11568 (* 1 = 0.11568 loss)
I0630 23:30:55.101193  7564 sgd_solver.cpp:105] Iteration 40700, lr = 0.0001
I0630 23:30:59.063513  7564 solver.cpp:218] Iteration 40800 (25.2392 iter/s, 3.96209s/100 iters), loss = 0.203863
I0630 23:30:59.063513  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:30:59.063513  7564 solver.cpp:237]     Train net output #1: loss = 0.203863 (* 1 = 0.203863 loss)
I0630 23:30:59.063513  7564 sgd_solver.cpp:105] Iteration 40800, lr = 0.0001
I0630 23:31:03.028947  7564 solver.cpp:218] Iteration 40900 (25.2209 iter/s, 3.96496s/100 iters), loss = 0.12609
I0630 23:31:03.028947  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:31:03.028947  7564 solver.cpp:237]     Train net output #1: loss = 0.12609 (* 1 = 0.12609 loss)
I0630 23:31:03.028947  7564 sgd_solver.cpp:105] Iteration 40900, lr = 0.0001
I0630 23:31:06.805325  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:31:06.960935  7564 solver.cpp:330] Iteration 41000, Testing net (#0)
I0630 23:31:06.960935  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:31:07.854570  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:31:07.888094  7564 solver.cpp:397]     Test net output #0: accuracy = 0.873
I0630 23:31:07.888094  7564 solver.cpp:397]     Test net output #1: loss = 0.427831 (* 1 = 0.427831 loss)
I0630 23:31:07.925606  7564 solver.cpp:218] Iteration 41000 (20.4233 iter/s, 4.89637s/100 iters), loss = 0.129233
I0630 23:31:07.925606  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:31:07.925606  7564 solver.cpp:237]     Train net output #1: loss = 0.129233 (* 1 = 0.129233 loss)
I0630 23:31:07.925606  7564 sgd_solver.cpp:105] Iteration 41000, lr = 0.0001
I0630 23:31:11.901466  7564 solver.cpp:218] Iteration 41100 (25.1567 iter/s, 3.97509s/100 iters), loss = 0.152545
I0630 23:31:11.901466  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:31:11.901466  7564 solver.cpp:237]     Train net output #1: loss = 0.152544 (* 1 = 0.152544 loss)
I0630 23:31:11.901466  7564 sgd_solver.cpp:105] Iteration 41100, lr = 0.0001
I0630 23:31:15.876807  7564 solver.cpp:218] Iteration 41200 (25.1557 iter/s, 3.97523s/100 iters), loss = 0.176773
I0630 23:31:15.876807  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:31:15.876807  7564 solver.cpp:237]     Train net output #1: loss = 0.176772 (* 1 = 0.176772 loss)
I0630 23:31:15.876807  7564 sgd_solver.cpp:105] Iteration 41200, lr = 0.0001
I0630 23:31:19.851624  7564 solver.cpp:218] Iteration 41300 (25.1602 iter/s, 3.97453s/100 iters), loss = 0.125789
I0630 23:31:19.851624  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:31:19.851624  7564 solver.cpp:237]     Train net output #1: loss = 0.125789 (* 1 = 0.125789 loss)
I0630 23:31:19.851624  7564 sgd_solver.cpp:105] Iteration 41300, lr = 0.0001
I0630 23:31:23.827644  7564 solver.cpp:218] Iteration 41400 (25.1553 iter/s, 3.97531s/100 iters), loss = 0.129265
I0630 23:31:23.827644  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:31:23.827644  7564 solver.cpp:237]     Train net output #1: loss = 0.129265 (* 1 = 0.129265 loss)
I0630 23:31:23.827644  7564 sgd_solver.cpp:105] Iteration 41400, lr = 0.0001
I0630 23:31:27.606865  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:31:27.764493  7564 solver.cpp:330] Iteration 41500, Testing net (#0)
I0630 23:31:27.764993  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:31:28.658820  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:31:28.692844  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I0630 23:31:28.692844  7564 solver.cpp:397]     Test net output #1: loss = 0.427189 (* 1 = 0.427189 loss)
I0630 23:31:28.730856  7564 solver.cpp:218] Iteration 41500 (20.3953 iter/s, 4.90308s/100 iters), loss = 0.116151
I0630 23:31:28.731375  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:31:28.731375  7564 solver.cpp:237]     Train net output #1: loss = 0.116151 (* 1 = 0.116151 loss)
I0630 23:31:28.731375  7564 sgd_solver.cpp:105] Iteration 41500, lr = 0.0001
I0630 23:31:32.710688  7564 solver.cpp:218] Iteration 41600 (25.1301 iter/s, 3.97929s/100 iters), loss = 0.134412
I0630 23:31:32.710688  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:31:32.710688  7564 solver.cpp:237]     Train net output #1: loss = 0.134412 (* 1 = 0.134412 loss)
I0630 23:31:32.710688  7564 sgd_solver.cpp:105] Iteration 41600, lr = 0.0001
I0630 23:31:36.684554  7564 solver.cpp:218] Iteration 41700 (25.1674 iter/s, 3.97339s/100 iters), loss = 0.156197
I0630 23:31:36.684554  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:31:36.684554  7564 solver.cpp:237]     Train net output #1: loss = 0.156197 (* 1 = 0.156197 loss)
I0630 23:31:36.684554  7564 sgd_solver.cpp:105] Iteration 41700, lr = 0.0001
I0630 23:31:40.655881  7564 solver.cpp:218] Iteration 41800 (25.1844 iter/s, 3.97072s/100 iters), loss = 0.169083
I0630 23:31:40.655881  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:31:40.655881  7564 solver.cpp:237]     Train net output #1: loss = 0.169083 (* 1 = 0.169083 loss)
I0630 23:31:40.655881  7564 sgd_solver.cpp:105] Iteration 41800, lr = 0.0001
I0630 23:31:44.638784  7564 solver.cpp:218] Iteration 41900 (25.1103 iter/s, 3.98242s/100 iters), loss = 0.262475
I0630 23:31:44.638784  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:31:44.638784  7564 solver.cpp:237]     Train net output #1: loss = 0.262474 (* 1 = 0.262474 loss)
I0630 23:31:44.638784  7564 sgd_solver.cpp:105] Iteration 41900, lr = 0.0001
I0630 23:31:48.436040  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:31:48.592152  7564 solver.cpp:330] Iteration 42000, Testing net (#0)
I0630 23:31:48.592152  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:31:49.486107  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:31:49.520632  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8712
I0630 23:31:49.520632  7564 solver.cpp:397]     Test net output #1: loss = 0.42697 (* 1 = 0.42697 loss)
I0630 23:31:49.558645  7564 solver.cpp:218] Iteration 42000 (20.327 iter/s, 4.91956s/100 iters), loss = 0.183842
I0630 23:31:49.558645  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:31:49.558645  7564 solver.cpp:237]     Train net output #1: loss = 0.183842 (* 1 = 0.183842 loss)
I0630 23:31:49.558645  7564 sgd_solver.cpp:105] Iteration 42000, lr = 0.0001
I0630 23:31:53.532519  7564 solver.cpp:218] Iteration 42100 (25.1665 iter/s, 3.97354s/100 iters), loss = 0.120533
I0630 23:31:53.532519  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:31:53.532519  7564 solver.cpp:237]     Train net output #1: loss = 0.120533 (* 1 = 0.120533 loss)
I0630 23:31:53.532519  7564 sgd_solver.cpp:105] Iteration 42100, lr = 0.0001
I0630 23:31:57.507356  7564 solver.cpp:218] Iteration 42200 (25.1607 iter/s, 3.97445s/100 iters), loss = 0.171125
I0630 23:31:57.507856  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:31:57.507856  7564 solver.cpp:237]     Train net output #1: loss = 0.171124 (* 1 = 0.171124 loss)
I0630 23:31:57.507856  7564 sgd_solver.cpp:105] Iteration 42200, lr = 0.0001
I0630 23:32:01.475179  7564 solver.cpp:218] Iteration 42300 (25.2075 iter/s, 3.96708s/100 iters), loss = 0.110919
I0630 23:32:01.475179  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:32:01.475179  7564 solver.cpp:237]     Train net output #1: loss = 0.110919 (* 1 = 0.110919 loss)
I0630 23:32:01.475179  7564 sgd_solver.cpp:105] Iteration 42300, lr = 0.0001
I0630 23:32:05.442029  7564 solver.cpp:218] Iteration 42400 (25.2114 iter/s, 3.96645s/100 iters), loss = 0.118857
I0630 23:32:05.442029  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:32:05.442029  7564 solver.cpp:237]     Train net output #1: loss = 0.118857 (* 1 = 0.118857 loss)
I0630 23:32:05.442029  7564 sgd_solver.cpp:105] Iteration 42400, lr = 0.0001
I0630 23:32:09.216218  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:32:09.372331  7564 solver.cpp:330] Iteration 42500, Testing net (#0)
I0630 23:32:09.372331  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:32:10.267477  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:32:10.301506  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8711
I0630 23:32:10.301506  7564 solver.cpp:397]     Test net output #1: loss = 0.427081 (* 1 = 0.427081 loss)
I0630 23:32:10.339517  7564 solver.cpp:218] Iteration 42500 (20.4196 iter/s, 4.89725s/100 iters), loss = 0.138443
I0630 23:32:10.339517  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:32:10.339517  7564 solver.cpp:237]     Train net output #1: loss = 0.138443 (* 1 = 0.138443 loss)
I0630 23:32:10.339517  7564 sgd_solver.cpp:105] Iteration 42500, lr = 0.0001
I0630 23:32:14.309922  7564 solver.cpp:218] Iteration 42600 (25.1904 iter/s, 3.96977s/100 iters), loss = 0.137336
I0630 23:32:14.309922  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:32:14.309922  7564 solver.cpp:237]     Train net output #1: loss = 0.137336 (* 1 = 0.137336 loss)
I0630 23:32:14.309922  7564 sgd_solver.cpp:105] Iteration 42600, lr = 0.0001
I0630 23:32:18.281764  7564 solver.cpp:218] Iteration 42700 (25.1781 iter/s, 3.9717s/100 iters), loss = 0.134048
I0630 23:32:18.281764  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:32:18.281764  7564 solver.cpp:237]     Train net output #1: loss = 0.134048 (* 1 = 0.134048 loss)
I0630 23:32:18.281764  7564 sgd_solver.cpp:105] Iteration 42700, lr = 0.0001
I0630 23:32:22.256592  7564 solver.cpp:218] Iteration 42800 (25.1642 iter/s, 3.9739s/100 iters), loss = 0.170145
I0630 23:32:22.256592  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:32:22.256592  7564 solver.cpp:237]     Train net output #1: loss = 0.170145 (* 1 = 0.170145 loss)
I0630 23:32:22.256592  7564 sgd_solver.cpp:105] Iteration 42800, lr = 0.0001
I0630 23:32:26.223956  7564 solver.cpp:218] Iteration 42900 (25.2067 iter/s, 3.96721s/100 iters), loss = 0.194894
I0630 23:32:26.223956  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:32:26.223956  7564 solver.cpp:237]     Train net output #1: loss = 0.194894 (* 1 = 0.194894 loss)
I0630 23:32:26.223956  7564 sgd_solver.cpp:105] Iteration 42900, lr = 0.0001
I0630 23:32:30.001864  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:32:30.157477  7564 solver.cpp:330] Iteration 43000, Testing net (#0)
I0630 23:32:30.157477  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:32:31.051110  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:32:31.085646  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8721
I0630 23:32:31.085646  7564 solver.cpp:397]     Test net output #1: loss = 0.427195 (* 1 = 0.427195 loss)
I0630 23:32:31.123658  7564 solver.cpp:218] Iteration 43000 (20.4119 iter/s, 4.89911s/100 iters), loss = 0.161537
I0630 23:32:31.123658  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:32:31.123658  7564 solver.cpp:237]     Train net output #1: loss = 0.161537 (* 1 = 0.161537 loss)
I0630 23:32:31.123658  7564 sgd_solver.cpp:105] Iteration 43000, lr = 0.0001
I0630 23:32:35.100492  7564 solver.cpp:218] Iteration 43100 (25.1471 iter/s, 3.9766s/100 iters), loss = 0.0833228
I0630 23:32:35.100492  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:32:35.100492  7564 solver.cpp:237]     Train net output #1: loss = 0.0833227 (* 1 = 0.0833227 loss)
I0630 23:32:35.100492  7564 sgd_solver.cpp:105] Iteration 43100, lr = 0.0001
I0630 23:32:39.070328  7564 solver.cpp:218] Iteration 43200 (25.1919 iter/s, 3.96953s/100 iters), loss = 0.175419
I0630 23:32:39.070328  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:32:39.070328  7564 solver.cpp:237]     Train net output #1: loss = 0.175419 (* 1 = 0.175419 loss)
I0630 23:32:39.070328  7564 sgd_solver.cpp:105] Iteration 43200, lr = 0.0001
I0630 23:32:43.044155  7564 solver.cpp:218] Iteration 43300 (25.1679 iter/s, 3.97331s/100 iters), loss = 0.144669
I0630 23:32:43.044155  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:32:43.044155  7564 solver.cpp:237]     Train net output #1: loss = 0.144669 (* 1 = 0.144669 loss)
I0630 23:32:43.044155  7564 sgd_solver.cpp:105] Iteration 43300, lr = 0.0001
I0630 23:32:47.018483  7564 solver.cpp:218] Iteration 43400 (25.1627 iter/s, 3.97414s/100 iters), loss = 0.15166
I0630 23:32:47.018483  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:32:47.018483  7564 solver.cpp:237]     Train net output #1: loss = 0.15166 (* 1 = 0.15166 loss)
I0630 23:32:47.018483  7564 sgd_solver.cpp:105] Iteration 43400, lr = 0.0001
I0630 23:32:50.798171  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:32:50.954797  7564 solver.cpp:330] Iteration 43500, Testing net (#0)
I0630 23:32:50.954797  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:32:51.849934  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:32:51.883443  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8721
I0630 23:32:51.883443  7564 solver.cpp:397]     Test net output #1: loss = 0.426863 (* 1 = 0.426863 loss)
I0630 23:32:51.920984  7564 solver.cpp:218] Iteration 43500 (20.3986 iter/s, 4.9023s/100 iters), loss = 0.134268
I0630 23:32:51.921483  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:32:51.921483  7564 solver.cpp:237]     Train net output #1: loss = 0.134268 (* 1 = 0.134268 loss)
I0630 23:32:51.921483  7564 sgd_solver.cpp:105] Iteration 43500, lr = 0.0001
I0630 23:32:55.897801  7564 solver.cpp:218] Iteration 43600 (25.1494 iter/s, 3.97625s/100 iters), loss = 0.112482
I0630 23:32:55.897801  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:32:55.897801  7564 solver.cpp:237]     Train net output #1: loss = 0.112482 (* 1 = 0.112482 loss)
I0630 23:32:55.897801  7564 sgd_solver.cpp:105] Iteration 43600, lr = 0.0001
I0630 23:32:59.876631  7564 solver.cpp:218] Iteration 43700 (25.1365 iter/s, 3.97828s/100 iters), loss = 0.144188
I0630 23:32:59.876631  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:32:59.876631  7564 solver.cpp:237]     Train net output #1: loss = 0.144188 (* 1 = 0.144188 loss)
I0630 23:32:59.876631  7564 sgd_solver.cpp:105] Iteration 43700, lr = 0.0001
I0630 23:33:03.852473  7564 solver.cpp:218] Iteration 43800 (25.154 iter/s, 3.97552s/100 iters), loss = 0.135898
I0630 23:33:03.852473  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:33:03.852473  7564 solver.cpp:237]     Train net output #1: loss = 0.135898 (* 1 = 0.135898 loss)
I0630 23:33:03.852473  7564 sgd_solver.cpp:105] Iteration 43800, lr = 0.0001
I0630 23:33:07.831801  7564 solver.cpp:218] Iteration 43900 (25.1303 iter/s, 3.97926s/100 iters), loss = 0.217706
I0630 23:33:07.831801  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:33:07.832304  7564 solver.cpp:237]     Train net output #1: loss = 0.217706 (* 1 = 0.217706 loss)
I0630 23:33:07.832304  7564 sgd_solver.cpp:105] Iteration 43900, lr = 0.0001
I0630 23:33:11.614481  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:33:11.769593  7564 solver.cpp:330] Iteration 44000, Testing net (#0)
I0630 23:33:11.770093  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:33:12.664744  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:33:12.699754  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8721
I0630 23:33:12.699754  7564 solver.cpp:397]     Test net output #1: loss = 0.427421 (* 1 = 0.427421 loss)
I0630 23:33:12.737298  7564 solver.cpp:218] Iteration 44000 (20.3876 iter/s, 4.90495s/100 iters), loss = 0.134338
I0630 23:33:12.737298  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:33:12.737298  7564 solver.cpp:237]     Train net output #1: loss = 0.134338 (* 1 = 0.134338 loss)
I0630 23:33:12.737298  7564 sgd_solver.cpp:46] MultiStep Status: Iteration 44000, step = 3
I0630 23:33:12.737298  7564 sgd_solver.cpp:105] Iteration 44000, lr = 1e-05
I0630 23:33:16.708606  7564 solver.cpp:218] Iteration 44100 (25.1826 iter/s, 3.971s/100 iters), loss = 0.118753
I0630 23:33:16.708606  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:33:16.708606  7564 solver.cpp:237]     Train net output #1: loss = 0.118753 (* 1 = 0.118753 loss)
I0630 23:33:16.708606  7564 sgd_solver.cpp:105] Iteration 44100, lr = 1e-05
I0630 23:33:20.685475  7564 solver.cpp:218] Iteration 44200 (25.1473 iter/s, 3.97657s/100 iters), loss = 0.14973
I0630 23:33:20.685976  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:33:20.685976  7564 solver.cpp:237]     Train net output #1: loss = 0.14973 (* 1 = 0.14973 loss)
I0630 23:33:20.685976  7564 sgd_solver.cpp:105] Iteration 44200, lr = 1e-05
I0630 23:33:24.657291  7564 solver.cpp:218] Iteration 44300 (25.1804 iter/s, 3.97134s/100 iters), loss = 0.138511
I0630 23:33:24.657291  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:33:24.657291  7564 solver.cpp:237]     Train net output #1: loss = 0.138511 (* 1 = 0.138511 loss)
I0630 23:33:24.657291  7564 sgd_solver.cpp:105] Iteration 44300, lr = 1e-05
I0630 23:33:28.631160  7564 solver.cpp:218] Iteration 44400 (25.1677 iter/s, 3.97335s/100 iters), loss = 0.165658
I0630 23:33:28.631160  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:33:28.631160  7564 solver.cpp:237]     Train net output #1: loss = 0.165658 (* 1 = 0.165658 loss)
I0630 23:33:28.631160  7564 sgd_solver.cpp:105] Iteration 44400, lr = 1e-05
I0630 23:33:32.412389  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:33:32.568001  7564 solver.cpp:330] Iteration 44500, Testing net (#0)
I0630 23:33:32.568001  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:33:33.462653  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:33:33.496670  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I0630 23:33:33.496670  7564 solver.cpp:397]     Test net output #1: loss = 0.427557 (* 1 = 0.427557 loss)
I0630 23:33:33.534688  7564 solver.cpp:218] Iteration 44500 (20.396 iter/s, 4.90293s/100 iters), loss = 0.0784188
I0630 23:33:33.534688  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:33:33.534688  7564 solver.cpp:237]     Train net output #1: loss = 0.0784186 (* 1 = 0.0784186 loss)
I0630 23:33:33.534688  7564 sgd_solver.cpp:105] Iteration 44500, lr = 1e-05
I0630 23:33:37.503037  7564 solver.cpp:218] Iteration 44600 (25.2018 iter/s, 3.96797s/100 iters), loss = 0.154605
I0630 23:33:37.503037  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:33:37.503037  7564 solver.cpp:237]     Train net output #1: loss = 0.154604 (* 1 = 0.154604 loss)
I0630 23:33:37.503037  7564 sgd_solver.cpp:105] Iteration 44600, lr = 1e-05
I0630 23:33:41.471361  7564 solver.cpp:218] Iteration 44700 (25.2029 iter/s, 3.9678s/100 iters), loss = 0.178732
I0630 23:33:41.471361  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:33:41.471361  7564 solver.cpp:237]     Train net output #1: loss = 0.178732 (* 1 = 0.178732 loss)
I0630 23:33:41.471361  7564 sgd_solver.cpp:105] Iteration 44700, lr = 1e-05
I0630 23:33:45.444689  7564 solver.cpp:218] Iteration 44800 (25.1697 iter/s, 3.97304s/100 iters), loss = 0.14956
I0630 23:33:45.444689  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:33:45.444689  7564 solver.cpp:237]     Train net output #1: loss = 0.14956 (* 1 = 0.14956 loss)
I0630 23:33:45.444689  7564 sgd_solver.cpp:105] Iteration 44800, lr = 1e-05
I0630 23:33:49.434048  7564 solver.cpp:218] Iteration 44900 (25.07 iter/s, 3.98884s/100 iters), loss = 0.137911
I0630 23:33:49.434048  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:33:49.434048  7564 solver.cpp:237]     Train net output #1: loss = 0.137911 (* 1 = 0.137911 loss)
I0630 23:33:49.434048  7564 sgd_solver.cpp:105] Iteration 44900, lr = 1e-05
I0630 23:33:53.213330  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:33:53.369441  7564 solver.cpp:330] Iteration 45000, Testing net (#0)
I0630 23:33:53.369441  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:33:54.265589  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:33:54.300604  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:33:54.300604  7564 solver.cpp:397]     Test net output #1: loss = 0.427596 (* 1 = 0.427596 loss)
I0630 23:33:54.339148  7564 solver.cpp:218] Iteration 45000 (20.3885 iter/s, 4.90473s/100 iters), loss = 0.129709
I0630 23:33:54.339148  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:33:54.339148  7564 solver.cpp:237]     Train net output #1: loss = 0.129709 (* 1 = 0.129709 loss)
I0630 23:33:54.339148  7564 sgd_solver.cpp:105] Iteration 45000, lr = 1e-05
I0630 23:33:58.313925  7564 solver.cpp:218] Iteration 45100 (25.1598 iter/s, 3.9746s/100 iters), loss = 0.133987
I0630 23:33:58.313925  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:33:58.313925  7564 solver.cpp:237]     Train net output #1: loss = 0.133987 (* 1 = 0.133987 loss)
I0630 23:33:58.314410  7564 sgd_solver.cpp:105] Iteration 45100, lr = 1e-05
I0630 23:34:02.288748  7564 solver.cpp:218] Iteration 45200 (25.1634 iter/s, 3.97402s/100 iters), loss = 0.165496
I0630 23:34:02.288748  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:34:02.288748  7564 solver.cpp:237]     Train net output #1: loss = 0.165496 (* 1 = 0.165496 loss)
I0630 23:34:02.288748  7564 sgd_solver.cpp:105] Iteration 45200, lr = 1e-05
I0630 23:34:06.265066  7564 solver.cpp:218] Iteration 45300 (25.1516 iter/s, 3.97589s/100 iters), loss = 0.143448
I0630 23:34:06.265066  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:34:06.265066  7564 solver.cpp:237]     Train net output #1: loss = 0.143448 (* 1 = 0.143448 loss)
I0630 23:34:06.265066  7564 sgd_solver.cpp:105] Iteration 45300, lr = 1e-05
I0630 23:34:10.236408  7564 solver.cpp:218] Iteration 45400 (25.1826 iter/s, 3.97099s/100 iters), loss = 0.164377
I0630 23:34:10.236408  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:34:10.236408  7564 solver.cpp:237]     Train net output #1: loss = 0.164377 (* 1 = 0.164377 loss)
I0630 23:34:10.236408  7564 sgd_solver.cpp:105] Iteration 45400, lr = 1e-05
I0630 23:34:14.014622  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:34:14.171751  7564 solver.cpp:330] Iteration 45500, Testing net (#0)
I0630 23:34:14.171751  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:34:15.064368  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:34:15.098394  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8727
I0630 23:34:15.098394  7564 solver.cpp:397]     Test net output #1: loss = 0.426626 (* 1 = 0.426626 loss)
I0630 23:34:15.135932  7564 solver.cpp:218] Iteration 45500 (20.4105 iter/s, 4.89944s/100 iters), loss = 0.140508
I0630 23:34:15.136433  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:34:15.136433  7564 solver.cpp:237]     Train net output #1: loss = 0.140508 (* 1 = 0.140508 loss)
I0630 23:34:15.136433  7564 sgd_solver.cpp:105] Iteration 45500, lr = 1e-05
I0630 23:34:19.108247  7564 solver.cpp:218] Iteration 45600 (25.1797 iter/s, 3.97145s/100 iters), loss = 0.149157
I0630 23:34:19.108247  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:34:19.108247  7564 solver.cpp:237]     Train net output #1: loss = 0.149157 (* 1 = 0.149157 loss)
I0630 23:34:19.108247  7564 sgd_solver.cpp:105] Iteration 45600, lr = 1e-05
I0630 23:34:23.077070  7564 solver.cpp:218] Iteration 45700 (25.1984 iter/s, 3.9685s/100 iters), loss = 0.124164
I0630 23:34:23.077070  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:34:23.077070  7564 solver.cpp:237]     Train net output #1: loss = 0.124164 (* 1 = 0.124164 loss)
I0630 23:34:23.077070  7564 sgd_solver.cpp:105] Iteration 45700, lr = 1e-05
I0630 23:34:27.052856  7564 solver.cpp:218] Iteration 45800 (25.1548 iter/s, 3.97539s/100 iters), loss = 0.0985431
I0630 23:34:27.052856  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:34:27.052856  7564 solver.cpp:237]     Train net output #1: loss = 0.0985431 (* 1 = 0.0985431 loss)
I0630 23:34:27.052856  7564 sgd_solver.cpp:105] Iteration 45800, lr = 1e-05
I0630 23:34:31.022382  7564 solver.cpp:218] Iteration 45900 (25.1935 iter/s, 3.96929s/100 iters), loss = 0.163679
I0630 23:34:31.022382  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:34:31.022382  7564 solver.cpp:237]     Train net output #1: loss = 0.163679 (* 1 = 0.163679 loss)
I0630 23:34:31.022382  7564 sgd_solver.cpp:105] Iteration 45900, lr = 1e-05
I0630 23:34:34.799072  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:34:34.954185  7564 solver.cpp:330] Iteration 46000, Testing net (#0)
I0630 23:34:34.954185  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:34:35.849804  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:34:35.884335  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8717
I0630 23:34:35.884335  7564 solver.cpp:397]     Test net output #1: loss = 0.427416 (* 1 = 0.427416 loss)
I0630 23:34:35.923367  7564 solver.cpp:218] Iteration 46000 (20.4067 iter/s, 4.90036s/100 iters), loss = 0.118946
I0630 23:34:35.923367  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:34:35.923367  7564 solver.cpp:237]     Train net output #1: loss = 0.118946 (* 1 = 0.118946 loss)
I0630 23:34:35.923367  7564 sgd_solver.cpp:105] Iteration 46000, lr = 1e-05
I0630 23:34:39.900234  7564 solver.cpp:218] Iteration 46100 (25.1476 iter/s, 3.97652s/100 iters), loss = 0.149165
I0630 23:34:39.900234  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:34:39.900234  7564 solver.cpp:237]     Train net output #1: loss = 0.149165 (* 1 = 0.149165 loss)
I0630 23:34:39.900234  7564 sgd_solver.cpp:105] Iteration 46100, lr = 1e-05
I0630 23:34:43.878054  7564 solver.cpp:218] Iteration 46200 (25.141 iter/s, 3.97757s/100 iters), loss = 0.100338
I0630 23:34:43.878054  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:34:43.878054  7564 solver.cpp:237]     Train net output #1: loss = 0.100338 (* 1 = 0.100338 loss)
I0630 23:34:43.878054  7564 sgd_solver.cpp:105] Iteration 46200, lr = 1e-05
I0630 23:34:47.869905  7564 solver.cpp:218] Iteration 46300 (25.0549 iter/s, 3.99124s/100 iters), loss = 0.196693
I0630 23:34:47.869905  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:34:47.869905  7564 solver.cpp:237]     Train net output #1: loss = 0.196693 (* 1 = 0.196693 loss)
I0630 23:34:47.869905  7564 sgd_solver.cpp:105] Iteration 46300, lr = 1e-05
I0630 23:34:51.846784  7564 solver.cpp:218] Iteration 46400 (25.1494 iter/s, 3.97624s/100 iters), loss = 0.114689
I0630 23:34:51.846784  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:34:51.846784  7564 solver.cpp:237]     Train net output #1: loss = 0.114689 (* 1 = 0.114689 loss)
I0630 23:34:51.846784  7564 sgd_solver.cpp:105] Iteration 46400, lr = 1e-05
I0630 23:34:55.634629  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:34:55.790225  7564 solver.cpp:330] Iteration 46500, Testing net (#0)
I0630 23:34:55.790225  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:34:56.681859  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:34:56.715881  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I0630 23:34:56.715881  7564 solver.cpp:397]     Test net output #1: loss = 0.426913 (* 1 = 0.426913 loss)
I0630 23:34:56.753922  7564 solver.cpp:218] Iteration 46500 (20.3798 iter/s, 4.90681s/100 iters), loss = 0.141257
I0630 23:34:56.753922  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:34:56.753922  7564 solver.cpp:237]     Train net output #1: loss = 0.141257 (* 1 = 0.141257 loss)
I0630 23:34:56.753922  7564 sgd_solver.cpp:105] Iteration 46500, lr = 1e-05
I0630 23:35:00.726750  7564 solver.cpp:218] Iteration 46600 (25.1724 iter/s, 3.9726s/100 iters), loss = 0.0982398
I0630 23:35:00.726750  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:35:00.726750  7564 solver.cpp:237]     Train net output #1: loss = 0.0982398 (* 1 = 0.0982398 loss)
I0630 23:35:00.726750  7564 sgd_solver.cpp:105] Iteration 46600, lr = 1e-05
I0630 23:35:04.702064  7564 solver.cpp:218] Iteration 46700 (25.157 iter/s, 3.97504s/100 iters), loss = 0.125107
I0630 23:35:04.702064  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:35:04.702064  7564 solver.cpp:237]     Train net output #1: loss = 0.125107 (* 1 = 0.125107 loss)
I0630 23:35:04.702064  7564 sgd_solver.cpp:105] Iteration 46700, lr = 1e-05
I0630 23:35:08.684398  7564 solver.cpp:218] Iteration 46800 (25.1131 iter/s, 3.98198s/100 iters), loss = 0.154318
I0630 23:35:08.684398  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:35:08.684398  7564 solver.cpp:237]     Train net output #1: loss = 0.154318 (* 1 = 0.154318 loss)
I0630 23:35:08.684898  7564 sgd_solver.cpp:105] Iteration 46800, lr = 1e-05
I0630 23:35:12.661762  7564 solver.cpp:218] Iteration 46900 (25.1468 iter/s, 3.97664s/100 iters), loss = 0.200432
I0630 23:35:12.661762  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:35:12.661762  7564 solver.cpp:237]     Train net output #1: loss = 0.200432 (* 1 = 0.200432 loss)
I0630 23:35:12.661762  7564 sgd_solver.cpp:105] Iteration 46900, lr = 1e-05
I0630 23:35:16.437934  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:35:16.594547  7564 solver.cpp:330] Iteration 47000, Testing net (#0)
I0630 23:35:16.595046  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:35:17.495687  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:35:17.529711  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I0630 23:35:17.529711  7564 solver.cpp:397]     Test net output #1: loss = 0.427201 (* 1 = 0.427201 loss)
I0630 23:35:17.567239  7564 solver.cpp:218] Iteration 47000 (20.3852 iter/s, 4.90553s/100 iters), loss = 0.175075
I0630 23:35:17.567739  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:35:17.567739  7564 solver.cpp:237]     Train net output #1: loss = 0.175075 (* 1 = 0.175075 loss)
I0630 23:35:17.567739  7564 sgd_solver.cpp:105] Iteration 47000, lr = 1e-05
I0630 23:35:21.559590  7564 solver.cpp:218] Iteration 47100 (25.052 iter/s, 3.99169s/100 iters), loss = 0.11627
I0630 23:35:21.559590  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:35:21.559590  7564 solver.cpp:237]     Train net output #1: loss = 0.11627 (* 1 = 0.11627 loss)
I0630 23:35:21.559590  7564 sgd_solver.cpp:105] Iteration 47100, lr = 1e-05
I0630 23:35:25.536418  7564 solver.cpp:218] Iteration 47200 (25.1481 iter/s, 3.97645s/100 iters), loss = 0.138587
I0630 23:35:25.536418  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:35:25.536418  7564 solver.cpp:237]     Train net output #1: loss = 0.138587 (* 1 = 0.138587 loss)
I0630 23:35:25.536418  7564 sgd_solver.cpp:105] Iteration 47200, lr = 1e-05
I0630 23:35:29.516252  7564 solver.cpp:218] Iteration 47300 (25.1295 iter/s, 3.97939s/100 iters), loss = 0.175971
I0630 23:35:29.516252  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:35:29.516252  7564 solver.cpp:237]     Train net output #1: loss = 0.175971 (* 1 = 0.175971 loss)
I0630 23:35:29.516252  7564 sgd_solver.cpp:105] Iteration 47300, lr = 1e-05
I0630 23:35:33.492578  7564 solver.cpp:218] Iteration 47400 (25.1526 iter/s, 3.97573s/100 iters), loss = 0.164346
I0630 23:35:33.492578  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:35:33.492578  7564 solver.cpp:237]     Train net output #1: loss = 0.164346 (* 1 = 0.164346 loss)
I0630 23:35:33.492578  7564 sgd_solver.cpp:105] Iteration 47400, lr = 1e-05
I0630 23:35:37.282296  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:35:37.436916  7564 solver.cpp:330] Iteration 47500, Testing net (#0)
I0630 23:35:37.436916  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:35:38.332037  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:35:38.366065  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8723
I0630 23:35:38.366065  7564 solver.cpp:397]     Test net output #1: loss = 0.427499 (* 1 = 0.427499 loss)
I0630 23:35:38.404105  7564 solver.cpp:218] Iteration 47500 (20.3605 iter/s, 4.91147s/100 iters), loss = 0.152665
I0630 23:35:38.404606  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:35:38.404606  7564 solver.cpp:237]     Train net output #1: loss = 0.152665 (* 1 = 0.152665 loss)
I0630 23:35:38.404606  7564 sgd_solver.cpp:105] Iteration 47500, lr = 1e-05
I0630 23:35:42.385931  7564 solver.cpp:218] Iteration 47600 (25.1187 iter/s, 3.9811s/100 iters), loss = 0.130683
I0630 23:35:42.385931  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:35:42.385931  7564 solver.cpp:237]     Train net output #1: loss = 0.130683 (* 1 = 0.130683 loss)
I0630 23:35:42.385931  7564 sgd_solver.cpp:105] Iteration 47600, lr = 1e-05
I0630 23:35:46.361263  7564 solver.cpp:218] Iteration 47700 (25.1577 iter/s, 3.97492s/100 iters), loss = 0.124863
I0630 23:35:46.361263  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:35:46.361263  7564 solver.cpp:237]     Train net output #1: loss = 0.124863 (* 1 = 0.124863 loss)
I0630 23:35:46.361263  7564 sgd_solver.cpp:105] Iteration 47700, lr = 1e-05
I0630 23:35:50.339081  7564 solver.cpp:218] Iteration 47800 (25.1429 iter/s, 3.97726s/100 iters), loss = 0.160453
I0630 23:35:50.339081  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:35:50.339081  7564 solver.cpp:237]     Train net output #1: loss = 0.160453 (* 1 = 0.160453 loss)
I0630 23:35:50.339081  7564 sgd_solver.cpp:105] Iteration 47800, lr = 1e-05
I0630 23:35:54.319412  7564 solver.cpp:218] Iteration 47900 (25.1264 iter/s, 3.97988s/100 iters), loss = 0.229075
I0630 23:35:54.319412  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:35:54.319412  7564 solver.cpp:237]     Train net output #1: loss = 0.229075 (* 1 = 0.229075 loss)
I0630 23:35:54.319412  7564 sgd_solver.cpp:105] Iteration 47900, lr = 1e-05
I0630 23:35:58.105919  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:35:58.261541  7564 solver.cpp:330] Iteration 48000, Testing net (#0)
I0630 23:35:58.261541  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:35:59.156167  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:35:59.190706  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8726
I0630 23:35:59.190706  7564 solver.cpp:397]     Test net output #1: loss = 0.427311 (* 1 = 0.427311 loss)
I0630 23:35:59.227717  7564 solver.cpp:218] Iteration 48000 (20.3743 iter/s, 4.90815s/100 iters), loss = 0.12596
I0630 23:35:59.228217  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:35:59.228217  7564 solver.cpp:237]     Train net output #1: loss = 0.12596 (* 1 = 0.12596 loss)
I0630 23:35:59.228217  7564 sgd_solver.cpp:105] Iteration 48000, lr = 1e-05
I0630 23:36:03.203256  7564 solver.cpp:218] Iteration 48100 (25.1594 iter/s, 3.97466s/100 iters), loss = 0.194827
I0630 23:36:03.203256  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:36:03.203256  7564 solver.cpp:237]     Train net output #1: loss = 0.194827 (* 1 = 0.194827 loss)
I0630 23:36:03.203256  7564 sgd_solver.cpp:105] Iteration 48100, lr = 1e-05
I0630 23:36:07.179587  7564 solver.cpp:218] Iteration 48200 (25.1487 iter/s, 3.97635s/100 iters), loss = 0.0933001
I0630 23:36:07.180088  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:36:07.180088  7564 solver.cpp:237]     Train net output #1: loss = 0.0933 (* 1 = 0.0933 loss)
I0630 23:36:07.180088  7564 sgd_solver.cpp:105] Iteration 48200, lr = 1e-05
I0630 23:36:11.154031  7564 solver.cpp:218] Iteration 48300 (25.1651 iter/s, 3.97376s/100 iters), loss = 0.20757
I0630 23:36:11.154031  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:36:11.154031  7564 solver.cpp:237]     Train net output #1: loss = 0.20757 (* 1 = 0.20757 loss)
I0630 23:36:11.154031  7564 sgd_solver.cpp:105] Iteration 48300, lr = 1e-05
I0630 23:36:15.132365  7564 solver.cpp:218] Iteration 48400 (25.1387 iter/s, 3.97794s/100 iters), loss = 0.129353
I0630 23:36:15.132365  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:36:15.132365  7564 solver.cpp:237]     Train net output #1: loss = 0.129353 (* 1 = 0.129353 loss)
I0630 23:36:15.132365  7564 sgd_solver.cpp:105] Iteration 48400, lr = 1e-05
I0630 23:36:18.913556  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:36:19.070169  7564 solver.cpp:330] Iteration 48500, Testing net (#0)
I0630 23:36:19.070169  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:36:19.964789  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:36:19.998814  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8726
I0630 23:36:19.998814  7564 solver.cpp:397]     Test net output #1: loss = 0.42719 (* 1 = 0.42719 loss)
I0630 23:36:20.036351  7564 solver.cpp:218] Iteration 48500 (20.3928 iter/s, 4.9037s/100 iters), loss = 0.130043
I0630 23:36:20.036351  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:36:20.036351  7564 solver.cpp:237]     Train net output #1: loss = 0.130043 (* 1 = 0.130043 loss)
I0630 23:36:20.036351  7564 sgd_solver.cpp:105] Iteration 48500, lr = 1e-05
I0630 23:36:24.007180  7564 solver.cpp:218] Iteration 48600 (25.1859 iter/s, 3.97048s/100 iters), loss = 0.1221
I0630 23:36:24.007180  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:36:24.007180  7564 solver.cpp:237]     Train net output #1: loss = 0.1221 (* 1 = 0.1221 loss)
I0630 23:36:24.007180  7564 sgd_solver.cpp:105] Iteration 48600, lr = 1e-05
I0630 23:36:27.991510  7564 solver.cpp:218] Iteration 48700 (25.1019 iter/s, 3.98376s/100 iters), loss = 0.088266
I0630 23:36:27.991510  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:36:27.991510  7564 solver.cpp:237]     Train net output #1: loss = 0.088266 (* 1 = 0.088266 loss)
I0630 23:36:27.991510  7564 sgd_solver.cpp:105] Iteration 48700, lr = 1e-05
I0630 23:36:31.966840  7564 solver.cpp:218] Iteration 48800 (25.1565 iter/s, 3.97511s/100 iters), loss = 0.172184
I0630 23:36:31.966840  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:36:31.966840  7564 solver.cpp:237]     Train net output #1: loss = 0.172184 (* 1 = 0.172184 loss)
I0630 23:36:31.966840  7564 sgd_solver.cpp:105] Iteration 48800, lr = 1e-05
I0630 23:36:35.945202  7564 solver.cpp:218] Iteration 48900 (25.1382 iter/s, 3.978s/100 iters), loss = 0.192202
I0630 23:36:35.945202  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:36:35.945202  7564 solver.cpp:237]     Train net output #1: loss = 0.192202 (* 1 = 0.192202 loss)
I0630 23:36:35.945202  7564 sgd_solver.cpp:105] Iteration 48900, lr = 1e-05
I0630 23:36:39.725963  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:36:39.882060  7564 solver.cpp:330] Iteration 49000, Testing net (#0)
I0630 23:36:39.882060  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:36:40.780197  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:36:40.814223  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8729
I0630 23:36:40.814223  7564 solver.cpp:397]     Test net output #1: loss = 0.427096 (* 1 = 0.427096 loss)
I0630 23:36:40.851748  7564 solver.cpp:218] Iteration 49000 (20.3828 iter/s, 4.90609s/100 iters), loss = 0.132594
I0630 23:36:40.851748  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:36:40.851748  7564 solver.cpp:237]     Train net output #1: loss = 0.132594 (* 1 = 0.132594 loss)
I0630 23:36:40.851748  7564 sgd_solver.cpp:105] Iteration 49000, lr = 1e-05
I0630 23:36:44.833631  7564 solver.cpp:218] Iteration 49100 (25.1155 iter/s, 3.9816s/100 iters), loss = 0.160236
I0630 23:36:44.833631  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:36:44.833631  7564 solver.cpp:237]     Train net output #1: loss = 0.160236 (* 1 = 0.160236 loss)
I0630 23:36:44.833631  7564 sgd_solver.cpp:105] Iteration 49100, lr = 1e-05
I0630 23:36:48.810978  7564 solver.cpp:218] Iteration 49200 (25.1441 iter/s, 3.97707s/100 iters), loss = 0.120036
I0630 23:36:48.811478  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:36:48.811478  7564 solver.cpp:237]     Train net output #1: loss = 0.120036 (* 1 = 0.120036 loss)
I0630 23:36:48.811478  7564 sgd_solver.cpp:105] Iteration 49200, lr = 1e-05
I0630 23:36:52.788292  7564 solver.cpp:218] Iteration 49300 (25.1461 iter/s, 3.97675s/100 iters), loss = 0.123841
I0630 23:36:52.788292  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:36:52.788292  7564 solver.cpp:237]     Train net output #1: loss = 0.123841 (* 1 = 0.123841 loss)
I0630 23:36:52.788292  7564 sgd_solver.cpp:105] Iteration 49300, lr = 1e-05
I0630 23:36:56.765193  7564 solver.cpp:218] Iteration 49400 (25.1476 iter/s, 3.97652s/100 iters), loss = 0.194813
I0630 23:36:56.765193  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:36:56.765193  7564 solver.cpp:237]     Train net output #1: loss = 0.194813 (* 1 = 0.194813 loss)
I0630 23:36:56.765193  7564 sgd_solver.cpp:105] Iteration 49400, lr = 1e-05
I0630 23:37:00.551918  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:37:00.707530  7564 solver.cpp:330] Iteration 49500, Testing net (#0)
I0630 23:37:00.707530  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:37:01.604151  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:37:01.638176  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8728
I0630 23:37:01.638176  7564 solver.cpp:397]     Test net output #1: loss = 0.426705 (* 1 = 0.426705 loss)
I0630 23:37:01.676218  7564 solver.cpp:218] Iteration 49500 (20.3632 iter/s, 4.91082s/100 iters), loss = 0.0633416
I0630 23:37:01.676717  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:37:01.676717  7564 solver.cpp:237]     Train net output #1: loss = 0.0633416 (* 1 = 0.0633416 loss)
I0630 23:37:01.676717  7564 sgd_solver.cpp:105] Iteration 49500, lr = 1e-05
I0630 23:37:05.665089  7564 solver.cpp:218] Iteration 49600 (25.0734 iter/s, 3.98828s/100 iters), loss = 0.151212
I0630 23:37:05.665089  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:37:05.665089  7564 solver.cpp:237]     Train net output #1: loss = 0.151212 (* 1 = 0.151212 loss)
I0630 23:37:05.665089  7564 sgd_solver.cpp:105] Iteration 49600, lr = 1e-05
I0630 23:37:09.640070  7564 solver.cpp:218] Iteration 49700 (25.1585 iter/s, 3.9748s/100 iters), loss = 0.211143
I0630 23:37:09.640571  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:37:09.640571  7564 solver.cpp:237]     Train net output #1: loss = 0.211143 (* 1 = 0.211143 loss)
I0630 23:37:09.640571  7564 sgd_solver.cpp:105] Iteration 49700, lr = 1e-05
I0630 23:37:13.621901  7564 solver.cpp:218] Iteration 49800 (25.117 iter/s, 3.98136s/100 iters), loss = 0.164041
I0630 23:37:13.622397  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:37:13.622397  7564 solver.cpp:237]     Train net output #1: loss = 0.164041 (* 1 = 0.164041 loss)
I0630 23:37:13.622397  7564 sgd_solver.cpp:105] Iteration 49800, lr = 1e-05
I0630 23:37:17.596715  7564 solver.cpp:218] Iteration 49900 (25.161 iter/s, 3.9744s/100 iters), loss = 0.186226
I0630 23:37:17.596715  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:37:17.596715  7564 solver.cpp:237]     Train net output #1: loss = 0.186226 (* 1 = 0.186226 loss)
I0630 23:37:17.596715  7564 sgd_solver.cpp:105] Iteration 49900, lr = 1e-05
I0630 23:37:21.375903  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:37:21.531514  7564 solver.cpp:330] Iteration 50000, Testing net (#0)
I0630 23:37:21.531514  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:37:22.426164  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:37:22.460690  7564 solver.cpp:397]     Test net output #0: accuracy = 0.873
I0630 23:37:22.460690  7564 solver.cpp:397]     Test net output #1: loss = 0.426721 (* 1 = 0.426721 loss)
I0630 23:37:22.498203  7564 solver.cpp:218] Iteration 50000 (20.4045 iter/s, 4.90087s/100 iters), loss = 0.150162
I0630 23:37:22.498203  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:37:22.498203  7564 solver.cpp:237]     Train net output #1: loss = 0.150162 (* 1 = 0.150162 loss)
I0630 23:37:22.498203  7564 sgd_solver.cpp:105] Iteration 50000, lr = 1e-05
I0630 23:37:26.469955  7564 solver.cpp:218] Iteration 50100 (25.1808 iter/s, 3.97128s/100 iters), loss = 0.150744
I0630 23:37:26.469955  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:37:26.469955  7564 solver.cpp:237]     Train net output #1: loss = 0.150744 (* 1 = 0.150744 loss)
I0630 23:37:26.469955  7564 sgd_solver.cpp:105] Iteration 50100, lr = 1e-05
I0630 23:37:30.440801  7564 solver.cpp:218] Iteration 50200 (25.1861 iter/s, 3.97045s/100 iters), loss = 0.169148
I0630 23:37:30.440801  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:37:30.440801  7564 solver.cpp:237]     Train net output #1: loss = 0.169148 (* 1 = 0.169148 loss)
I0630 23:37:30.440801  7564 sgd_solver.cpp:105] Iteration 50200, lr = 1e-05
I0630 23:37:34.415709  7564 solver.cpp:218] Iteration 50300 (25.1616 iter/s, 3.97432s/100 iters), loss = 0.103303
I0630 23:37:34.415709  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:37:34.415709  7564 solver.cpp:237]     Train net output #1: loss = 0.103303 (* 1 = 0.103303 loss)
I0630 23:37:34.415709  7564 sgd_solver.cpp:105] Iteration 50300, lr = 1e-05
I0630 23:37:38.387523  7564 solver.cpp:218] Iteration 50400 (25.1789 iter/s, 3.97158s/100 iters), loss = 0.140973
I0630 23:37:38.387523  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:37:38.387523  7564 solver.cpp:237]     Train net output #1: loss = 0.140973 (* 1 = 0.140973 loss)
I0630 23:37:38.387523  7564 sgd_solver.cpp:105] Iteration 50400, lr = 1e-05
I0630 23:37:42.159745  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:37:42.316356  7564 solver.cpp:330] Iteration 50500, Testing net (#0)
I0630 23:37:42.316356  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:37:43.206490  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:37:43.241015  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8727
I0630 23:37:43.241015  7564 solver.cpp:397]     Test net output #1: loss = 0.427118 (* 1 = 0.427118 loss)
I0630 23:37:43.279042  7564 solver.cpp:218] Iteration 50500 (20.4457 iter/s, 4.89102s/100 iters), loss = 0.177143
I0630 23:37:43.279042  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:37:43.279042  7564 solver.cpp:237]     Train net output #1: loss = 0.177143 (* 1 = 0.177143 loss)
I0630 23:37:43.279042  7564 sgd_solver.cpp:105] Iteration 50500, lr = 1e-05
I0630 23:37:47.246446  7564 solver.cpp:218] Iteration 50600 (25.2073 iter/s, 3.9671s/100 iters), loss = 0.153345
I0630 23:37:47.246446  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:37:47.246446  7564 solver.cpp:237]     Train net output #1: loss = 0.153345 (* 1 = 0.153345 loss)
I0630 23:37:47.246446  7564 sgd_solver.cpp:105] Iteration 50600, lr = 1e-05
I0630 23:37:51.212769  7564 solver.cpp:218] Iteration 50700 (25.2142 iter/s, 3.96602s/100 iters), loss = 0.135575
I0630 23:37:51.212769  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:37:51.212769  7564 solver.cpp:237]     Train net output #1: loss = 0.135575 (* 1 = 0.135575 loss)
I0630 23:37:51.212769  7564 sgd_solver.cpp:105] Iteration 50700, lr = 1e-05
I0630 23:37:55.181092  7564 solver.cpp:218] Iteration 50800 (25.2017 iter/s, 3.96799s/100 iters), loss = 0.136674
I0630 23:37:55.181092  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:37:55.181092  7564 solver.cpp:237]     Train net output #1: loss = 0.136675 (* 1 = 0.136675 loss)
I0630 23:37:55.181092  7564 sgd_solver.cpp:105] Iteration 50800, lr = 1e-05
I0630 23:37:59.145444  7564 solver.cpp:218] Iteration 50900 (25.2274 iter/s, 3.96394s/100 iters), loss = 0.0940891
I0630 23:37:59.145444  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:37:59.145444  7564 solver.cpp:237]     Train net output #1: loss = 0.0940892 (* 1 = 0.0940892 loss)
I0630 23:37:59.145444  7564 sgd_solver.cpp:105] Iteration 50900, lr = 1e-05
I0630 23:38:02.920678  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:38:03.075789  7564 solver.cpp:330] Iteration 51000, Testing net (#0)
I0630 23:38:03.075789  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:38:03.966423  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:38:03.998945  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8724
I0630 23:38:03.998945  7564 solver.cpp:397]     Test net output #1: loss = 0.427046 (* 1 = 0.427046 loss)
I0630 23:38:04.036972  7564 solver.cpp:218] Iteration 51000 (20.446 iter/s, 4.89092s/100 iters), loss = 0.110874
I0630 23:38:04.036972  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:38:04.036972  7564 solver.cpp:237]     Train net output #1: loss = 0.110874 (* 1 = 0.110874 loss)
I0630 23:38:04.036972  7564 sgd_solver.cpp:105] Iteration 51000, lr = 1e-05
I0630 23:38:08.006798  7564 solver.cpp:218] Iteration 51100 (25.1925 iter/s, 3.96944s/100 iters), loss = 0.163312
I0630 23:38:08.006798  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:38:08.006798  7564 solver.cpp:237]     Train net output #1: loss = 0.163312 (* 1 = 0.163312 loss)
I0630 23:38:08.006798  7564 sgd_solver.cpp:105] Iteration 51100, lr = 1e-05
I0630 23:38:11.979123  7564 solver.cpp:218] Iteration 51200 (25.1765 iter/s, 3.97196s/100 iters), loss = 0.18064
I0630 23:38:11.979123  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:38:11.979123  7564 solver.cpp:237]     Train net output #1: loss = 0.18064 (* 1 = 0.18064 loss)
I0630 23:38:11.979123  7564 sgd_solver.cpp:105] Iteration 51200, lr = 1e-05
I0630 23:38:15.945444  7564 solver.cpp:218] Iteration 51300 (25.2161 iter/s, 3.96572s/100 iters), loss = 0.10052
I0630 23:38:15.945444  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:38:15.945444  7564 solver.cpp:237]     Train net output #1: loss = 0.10052 (* 1 = 0.10052 loss)
I0630 23:38:15.945444  7564 sgd_solver.cpp:105] Iteration 51300, lr = 1e-05
I0630 23:38:19.908766  7564 solver.cpp:218] Iteration 51400 (25.2313 iter/s, 3.96334s/100 iters), loss = 0.196396
I0630 23:38:19.909266  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:38:19.909266  7564 solver.cpp:237]     Train net output #1: loss = 0.196396 (* 1 = 0.196396 loss)
I0630 23:38:19.909266  7564 sgd_solver.cpp:105] Iteration 51400, lr = 1e-05
I0630 23:38:23.685951  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:38:23.843565  7564 solver.cpp:330] Iteration 51500, Testing net (#0)
I0630 23:38:23.843565  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:38:24.740731  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:38:24.774755  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8724
I0630 23:38:24.775255  7564 solver.cpp:397]     Test net output #1: loss = 0.427148 (* 1 = 0.427148 loss)
I0630 23:38:24.812283  7564 solver.cpp:218] Iteration 51500 (20.3967 iter/s, 4.90275s/100 iters), loss = 0.114844
I0630 23:38:24.812283  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:38:24.812283  7564 solver.cpp:237]     Train net output #1: loss = 0.114844 (* 1 = 0.114844 loss)
I0630 23:38:24.812283  7564 sgd_solver.cpp:105] Iteration 51500, lr = 1e-05
I0630 23:38:28.784917  7564 solver.cpp:218] Iteration 51600 (25.1732 iter/s, 3.97248s/100 iters), loss = 0.181088
I0630 23:38:28.784917  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:38:28.784917  7564 solver.cpp:237]     Train net output #1: loss = 0.181088 (* 1 = 0.181088 loss)
I0630 23:38:28.784917  7564 sgd_solver.cpp:105] Iteration 51600, lr = 1e-05
I0630 23:38:32.752565  7564 solver.cpp:218] Iteration 51700 (25.2062 iter/s, 3.96728s/100 iters), loss = 0.156226
I0630 23:38:32.752565  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:38:32.752565  7564 solver.cpp:237]     Train net output #1: loss = 0.156226 (* 1 = 0.156226 loss)
I0630 23:38:32.752565  7564 sgd_solver.cpp:105] Iteration 51700, lr = 1e-05
I0630 23:38:36.730396  7564 solver.cpp:218] Iteration 51800 (25.1418 iter/s, 3.97744s/100 iters), loss = 0.221554
I0630 23:38:36.730396  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:38:36.730396  7564 solver.cpp:237]     Train net output #1: loss = 0.221554 (* 1 = 0.221554 loss)
I0630 23:38:36.730396  7564 sgd_solver.cpp:105] Iteration 51800, lr = 1e-05
I0630 23:38:40.712229  7564 solver.cpp:218] Iteration 51900 (25.1191 iter/s, 3.98104s/100 iters), loss = 0.145504
I0630 23:38:40.712229  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:38:40.712229  7564 solver.cpp:237]     Train net output #1: loss = 0.145504 (* 1 = 0.145504 loss)
I0630 23:38:40.712229  7564 sgd_solver.cpp:105] Iteration 51900, lr = 1e-05
I0630 23:38:44.496956  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:38:44.654068  7564 solver.cpp:330] Iteration 52000, Testing net (#0)
I0630 23:38:44.654068  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:38:45.550706  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:38:45.584730  7564 solver.cpp:397]     Test net output #0: accuracy = 0.872
I0630 23:38:45.584730  7564 solver.cpp:397]     Test net output #1: loss = 0.427433 (* 1 = 0.427433 loss)
I0630 23:38:45.622256  7564 solver.cpp:218] Iteration 52000 (20.367 iter/s, 4.90991s/100 iters), loss = 0.118204
I0630 23:38:45.622256  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:38:45.622256  7564 solver.cpp:237]     Train net output #1: loss = 0.118205 (* 1 = 0.118205 loss)
I0630 23:38:45.622256  7564 sgd_solver.cpp:105] Iteration 52000, lr = 1e-05
I0630 23:38:49.600106  7564 solver.cpp:218] Iteration 52100 (25.1426 iter/s, 3.97732s/100 iters), loss = 0.122909
I0630 23:38:49.600106  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:38:49.600106  7564 solver.cpp:237]     Train net output #1: loss = 0.122909 (* 1 = 0.122909 loss)
I0630 23:38:49.600106  7564 sgd_solver.cpp:105] Iteration 52100, lr = 1e-05
I0630 23:38:53.581439  7564 solver.cpp:218] Iteration 52200 (25.1198 iter/s, 3.98093s/100 iters), loss = 0.140323
I0630 23:38:53.581439  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:38:53.581439  7564 solver.cpp:237]     Train net output #1: loss = 0.140323 (* 1 = 0.140323 loss)
I0630 23:38:53.581439  7564 sgd_solver.cpp:105] Iteration 52200, lr = 1e-05
I0630 23:38:57.564402  7564 solver.cpp:218] Iteration 52300 (25.1101 iter/s, 3.98246s/100 iters), loss = 0.166043
I0630 23:38:57.564402  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:38:57.564402  7564 solver.cpp:237]     Train net output #1: loss = 0.166043 (* 1 = 0.166043 loss)
I0630 23:38:57.564402  7564 sgd_solver.cpp:105] Iteration 52300, lr = 1e-05
I0630 23:39:01.538756  7564 solver.cpp:218] Iteration 52400 (25.1616 iter/s, 3.97431s/100 iters), loss = 0.155086
I0630 23:39:01.539258  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:39:01.539258  7564 solver.cpp:237]     Train net output #1: loss = 0.155086 (* 1 = 0.155086 loss)
I0630 23:39:01.539258  7564 sgd_solver.cpp:105] Iteration 52400, lr = 1e-05
I0630 23:39:05.319456  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:39:05.475077  7564 solver.cpp:330] Iteration 52500, Testing net (#0)
I0630 23:39:05.475077  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:39:06.372206  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:39:06.406731  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:39:06.406731  7564 solver.cpp:397]     Test net output #1: loss = 0.427116 (* 1 = 0.427116 loss)
I0630 23:39:06.444758  7564 solver.cpp:218] Iteration 52500 (20.3856 iter/s, 4.90542s/100 iters), loss = 0.131814
I0630 23:39:06.444758  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:39:06.444758  7564 solver.cpp:237]     Train net output #1: loss = 0.131815 (* 1 = 0.131815 loss)
I0630 23:39:06.444758  7564 sgd_solver.cpp:105] Iteration 52500, lr = 1e-05
I0630 23:39:10.416594  7564 solver.cpp:218] Iteration 52600 (25.18 iter/s, 3.9714s/100 iters), loss = 0.1513
I0630 23:39:10.416594  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:39:10.416594  7564 solver.cpp:237]     Train net output #1: loss = 0.1513 (* 1 = 0.1513 loss)
I0630 23:39:10.416594  7564 sgd_solver.cpp:105] Iteration 52600, lr = 1e-05
I0630 23:39:14.393430  7564 solver.cpp:218] Iteration 52700 (25.15 iter/s, 3.97614s/100 iters), loss = 0.158493
I0630 23:39:14.393430  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:39:14.393430  7564 solver.cpp:237]     Train net output #1: loss = 0.158493 (* 1 = 0.158493 loss)
I0630 23:39:14.393430  7564 sgd_solver.cpp:105] Iteration 52700, lr = 1e-05
I0630 23:39:18.370260  7564 solver.cpp:218] Iteration 52800 (25.1492 iter/s, 3.97628s/100 iters), loss = 0.194867
I0630 23:39:18.370260  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:39:18.370260  7564 solver.cpp:237]     Train net output #1: loss = 0.194867 (* 1 = 0.194867 loss)
I0630 23:39:18.370260  7564 sgd_solver.cpp:105] Iteration 52800, lr = 1e-05
I0630 23:39:22.344586  7564 solver.cpp:218] Iteration 52900 (25.1619 iter/s, 3.97426s/100 iters), loss = 0.16504
I0630 23:39:22.344586  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:39:22.344586  7564 solver.cpp:237]     Train net output #1: loss = 0.16504 (* 1 = 0.16504 loss)
I0630 23:39:22.344586  7564 sgd_solver.cpp:105] Iteration 52900, lr = 1e-05
I0630 23:39:26.128795  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:39:26.284889  7564 solver.cpp:330] Iteration 53000, Testing net (#0)
I0630 23:39:26.284889  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:39:27.179536  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:39:27.214061  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8719
I0630 23:39:27.214061  7564 solver.cpp:397]     Test net output #1: loss = 0.427485 (* 1 = 0.427485 loss)
I0630 23:39:27.251577  7564 solver.cpp:218] Iteration 53000 (20.3814 iter/s, 4.90642s/100 iters), loss = 0.0861928
I0630 23:39:27.251577  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:39:27.251577  7564 solver.cpp:237]     Train net output #1: loss = 0.086193 (* 1 = 0.086193 loss)
I0630 23:39:27.251577  7564 sgd_solver.cpp:105] Iteration 53000, lr = 1e-05
I0630 23:39:31.227406  7564 solver.cpp:218] Iteration 53100 (25.1548 iter/s, 3.97539s/100 iters), loss = 0.173515
I0630 23:39:31.227406  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:39:31.227406  7564 solver.cpp:237]     Train net output #1: loss = 0.173515 (* 1 = 0.173515 loss)
I0630 23:39:31.227406  7564 sgd_solver.cpp:105] Iteration 53100, lr = 1e-05
I0630 23:39:35.199743  7564 solver.cpp:218] Iteration 53200 (25.1772 iter/s, 3.97185s/100 iters), loss = 0.142862
I0630 23:39:35.199743  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:39:35.199743  7564 solver.cpp:237]     Train net output #1: loss = 0.142862 (* 1 = 0.142862 loss)
I0630 23:39:35.199743  7564 sgd_solver.cpp:105] Iteration 53200, lr = 1e-05
I0630 23:39:39.175295  7564 solver.cpp:218] Iteration 53300 (25.1567 iter/s, 3.97509s/100 iters), loss = 0.133596
I0630 23:39:39.175295  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:39:39.175295  7564 solver.cpp:237]     Train net output #1: loss = 0.133597 (* 1 = 0.133597 loss)
I0630 23:39:39.175295  7564 sgd_solver.cpp:105] Iteration 53300, lr = 1e-05
I0630 23:39:43.151641  7564 solver.cpp:218] Iteration 53400 (25.1493 iter/s, 3.97625s/100 iters), loss = 0.187931
I0630 23:39:43.151641  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:39:43.151641  7564 solver.cpp:237]     Train net output #1: loss = 0.187931 (* 1 = 0.187931 loss)
I0630 23:39:43.151641  7564 sgd_solver.cpp:105] Iteration 53400, lr = 1e-05
I0630 23:39:46.933496  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:39:47.089608  7564 solver.cpp:330] Iteration 53500, Testing net (#0)
I0630 23:39:47.089608  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:39:47.995767  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:39:48.030287  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:39:48.030287  7564 solver.cpp:397]     Test net output #1: loss = 0.427182 (* 1 = 0.427182 loss)
I0630 23:39:48.067804  7564 solver.cpp:218] Iteration 53500 (20.3423 iter/s, 4.91586s/100 iters), loss = 0.120634
I0630 23:39:48.068310  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:39:48.068310  7564 solver.cpp:237]     Train net output #1: loss = 0.120634 (* 1 = 0.120634 loss)
I0630 23:39:48.068310  7564 sgd_solver.cpp:105] Iteration 53500, lr = 1e-05
I0630 23:39:52.034626  7564 solver.cpp:218] Iteration 53600 (25.2144 iter/s, 3.96599s/100 iters), loss = 0.110138
I0630 23:39:52.034626  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:39:52.034626  7564 solver.cpp:237]     Train net output #1: loss = 0.110138 (* 1 = 0.110138 loss)
I0630 23:39:52.034626  7564 sgd_solver.cpp:105] Iteration 53600, lr = 1e-05
I0630 23:39:56.008642  7564 solver.cpp:218] Iteration 53700 (25.1636 iter/s, 3.97399s/100 iters), loss = 0.153698
I0630 23:39:56.008642  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:39:56.008642  7564 solver.cpp:237]     Train net output #1: loss = 0.153698 (* 1 = 0.153698 loss)
I0630 23:39:56.008642  7564 sgd_solver.cpp:105] Iteration 53700, lr = 1e-05
I0630 23:39:59.983983  7564 solver.cpp:218] Iteration 53800 (25.1582 iter/s, 3.97484s/100 iters), loss = 0.16422
I0630 23:39:59.983983  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:39:59.983983  7564 solver.cpp:237]     Train net output #1: loss = 0.164221 (* 1 = 0.164221 loss)
I0630 23:39:59.983983  7564 sgd_solver.cpp:105] Iteration 53800, lr = 1e-05
I0630 23:40:03.981892  7564 solver.cpp:218] Iteration 53900 (25.0141 iter/s, 3.99775s/100 iters), loss = 0.20086
I0630 23:40:03.981892  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:40:03.982393  7564 solver.cpp:237]     Train net output #1: loss = 0.200861 (* 1 = 0.200861 loss)
I0630 23:40:03.982393  7564 sgd_solver.cpp:105] Iteration 53900, lr = 1e-05
I0630 23:40:07.757077  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:40:07.912689  7564 solver.cpp:330] Iteration 54000, Testing net (#0)
I0630 23:40:07.912689  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:40:08.805344  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:40:08.839376  7564 solver.cpp:397]     Test net output #0: accuracy = 0.873
I0630 23:40:08.839376  7564 solver.cpp:397]     Test net output #1: loss = 0.426316 (* 1 = 0.426316 loss)
I0630 23:40:08.877380  7564 solver.cpp:218] Iteration 54000 (20.4288 iter/s, 4.89506s/100 iters), loss = 0.123107
I0630 23:40:08.877882  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:40:08.877882  7564 solver.cpp:237]     Train net output #1: loss = 0.123107 (* 1 = 0.123107 loss)
I0630 23:40:08.877882  7564 sgd_solver.cpp:105] Iteration 54000, lr = 1e-05
I0630 23:40:12.860234  7564 solver.cpp:218] Iteration 54100 (25.1122 iter/s, 3.98214s/100 iters), loss = 0.121049
I0630 23:40:12.860234  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:40:12.860234  7564 solver.cpp:237]     Train net output #1: loss = 0.121049 (* 1 = 0.121049 loss)
I0630 23:40:12.860234  7564 sgd_solver.cpp:105] Iteration 54100, lr = 1e-05
I0630 23:40:16.835602  7564 solver.cpp:218] Iteration 54200 (25.1588 iter/s, 3.97476s/100 iters), loss = 0.16279
I0630 23:40:16.835602  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:40:16.835602  7564 solver.cpp:237]     Train net output #1: loss = 0.16279 (* 1 = 0.16279 loss)
I0630 23:40:16.835602  7564 sgd_solver.cpp:105] Iteration 54200, lr = 1e-05
I0630 23:40:20.805938  7564 solver.cpp:218] Iteration 54300 (25.1875 iter/s, 3.97023s/100 iters), loss = 0.106976
I0630 23:40:20.805938  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:40:20.805938  7564 solver.cpp:237]     Train net output #1: loss = 0.106976 (* 1 = 0.106976 loss)
I0630 23:40:20.805938  7564 sgd_solver.cpp:105] Iteration 54300, lr = 1e-05
I0630 23:40:24.778756  7564 solver.cpp:218] Iteration 54400 (25.1754 iter/s, 3.97213s/100 iters), loss = 0.125994
I0630 23:40:24.778756  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:40:24.778756  7564 solver.cpp:237]     Train net output #1: loss = 0.125994 (* 1 = 0.125994 loss)
I0630 23:40:24.778756  7564 sgd_solver.cpp:105] Iteration 54400, lr = 1e-05
I0630 23:40:28.558460  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:40:28.714054  7564 solver.cpp:330] Iteration 54500, Testing net (#0)
I0630 23:40:28.714054  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:40:29.608204  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:40:29.642725  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8719
I0630 23:40:29.642725  7564 solver.cpp:397]     Test net output #1: loss = 0.427125 (* 1 = 0.427125 loss)
I0630 23:40:29.681252  7564 solver.cpp:218] Iteration 54500 (20.3997 iter/s, 4.90203s/100 iters), loss = 0.14128
I0630 23:40:29.681252  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:40:29.681252  7564 solver.cpp:237]     Train net output #1: loss = 0.14128 (* 1 = 0.14128 loss)
I0630 23:40:29.681252  7564 sgd_solver.cpp:105] Iteration 54500, lr = 1e-05
I0630 23:40:33.658625  7564 solver.cpp:218] Iteration 54600 (25.1424 iter/s, 3.97735s/100 iters), loss = 0.142842
I0630 23:40:33.658625  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:40:33.659126  7564 solver.cpp:237]     Train net output #1: loss = 0.142843 (* 1 = 0.142843 loss)
I0630 23:40:33.659126  7564 sgd_solver.cpp:105] Iteration 54600, lr = 1e-05
I0630 23:40:37.636945  7564 solver.cpp:218] Iteration 54700 (25.1411 iter/s, 3.97755s/100 iters), loss = 0.15462
I0630 23:40:37.636945  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:40:37.636945  7564 solver.cpp:237]     Train net output #1: loss = 0.154621 (* 1 = 0.154621 loss)
I0630 23:40:37.636945  7564 sgd_solver.cpp:105] Iteration 54700, lr = 1e-05
I0630 23:40:41.611274  7564 solver.cpp:218] Iteration 54800 (25.162 iter/s, 3.97424s/100 iters), loss = 0.190162
I0630 23:40:41.611274  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:40:41.611274  7564 solver.cpp:237]     Train net output #1: loss = 0.190162 (* 1 = 0.190162 loss)
I0630 23:40:41.611274  7564 sgd_solver.cpp:105] Iteration 54800, lr = 1e-05
I0630 23:40:45.584600  7564 solver.cpp:218] Iteration 54900 (25.17 iter/s, 3.97298s/100 iters), loss = 0.167863
I0630 23:40:45.584600  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:40:45.584600  7564 solver.cpp:237]     Train net output #1: loss = 0.167863 (* 1 = 0.167863 loss)
I0630 23:40:45.585100  7564 sgd_solver.cpp:105] Iteration 54900, lr = 1e-05
I0630 23:40:49.370808  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:40:49.524917  7564 solver.cpp:330] Iteration 55000, Testing net (#0)
I0630 23:40:49.524917  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:40:50.418555  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:40:50.452564  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8721
I0630 23:40:50.453074  7564 solver.cpp:397]     Test net output #1: loss = 0.426927 (* 1 = 0.426927 loss)
I0630 23:40:50.491091  7564 solver.cpp:218] Iteration 55000 (20.3832 iter/s, 4.90599s/100 iters), loss = 0.153103
I0630 23:40:50.491091  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:40:50.491091  7564 solver.cpp:237]     Train net output #1: loss = 0.153103 (* 1 = 0.153103 loss)
I0630 23:40:50.491091  7564 sgd_solver.cpp:105] Iteration 55000, lr = 1e-05
I0630 23:40:54.463946  7564 solver.cpp:218] Iteration 55100 (25.1721 iter/s, 3.97265s/100 iters), loss = 0.156631
I0630 23:40:54.464447  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:40:54.464447  7564 solver.cpp:237]     Train net output #1: loss = 0.156631 (* 1 = 0.156631 loss)
I0630 23:40:54.464447  7564 sgd_solver.cpp:105] Iteration 55100, lr = 1e-05
I0630 23:40:58.437871  7564 solver.cpp:218] Iteration 55200 (25.1663 iter/s, 3.97357s/100 iters), loss = 0.134183
I0630 23:40:58.438371  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:40:58.438371  7564 solver.cpp:237]     Train net output #1: loss = 0.134183 (* 1 = 0.134183 loss)
I0630 23:40:58.438371  7564 sgd_solver.cpp:105] Iteration 55200, lr = 1e-05
I0630 23:41:02.407696  7564 solver.cpp:218] Iteration 55300 (25.1933 iter/s, 3.96931s/100 iters), loss = 0.193854
I0630 23:41:02.407696  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:41:02.407696  7564 solver.cpp:237]     Train net output #1: loss = 0.193854 (* 1 = 0.193854 loss)
I0630 23:41:02.407696  7564 sgd_solver.cpp:105] Iteration 55300, lr = 1e-05
I0630 23:41:06.376046  7564 solver.cpp:218] Iteration 55400 (25.203 iter/s, 3.96778s/100 iters), loss = 0.176285
I0630 23:41:06.376046  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:41:06.376046  7564 solver.cpp:237]     Train net output #1: loss = 0.176286 (* 1 = 0.176286 loss)
I0630 23:41:06.376046  7564 sgd_solver.cpp:105] Iteration 55400, lr = 1e-05
I0630 23:41:10.153872  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:41:10.309983  7564 solver.cpp:330] Iteration 55500, Testing net (#0)
I0630 23:41:10.310483  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:41:11.204633  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:41:11.239645  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:41:11.239645  7564 solver.cpp:397]     Test net output #1: loss = 0.427369 (* 1 = 0.427369 loss)
I0630 23:41:11.276170  7564 solver.cpp:218] Iteration 55500 (20.4085 iter/s, 4.89992s/100 iters), loss = 0.137116
I0630 23:41:11.276170  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:41:11.276170  7564 solver.cpp:237]     Train net output #1: loss = 0.137116 (* 1 = 0.137116 loss)
I0630 23:41:11.276170  7564 sgd_solver.cpp:105] Iteration 55500, lr = 1e-05
I0630 23:41:15.252499  7564 solver.cpp:218] Iteration 55600 (25.1514 iter/s, 3.97591s/100 iters), loss = 0.168324
I0630 23:41:15.252499  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:41:15.252499  7564 solver.cpp:237]     Train net output #1: loss = 0.168325 (* 1 = 0.168325 loss)
I0630 23:41:15.252499  7564 sgd_solver.cpp:105] Iteration 55600, lr = 1e-05
I0630 23:41:19.227828  7564 solver.cpp:218] Iteration 55700 (25.1578 iter/s, 3.97491s/100 iters), loss = 0.154816
I0630 23:41:19.227828  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:41:19.227828  7564 solver.cpp:237]     Train net output #1: loss = 0.154816 (* 1 = 0.154816 loss)
I0630 23:41:19.227828  7564 sgd_solver.cpp:105] Iteration 55700, lr = 1e-05
I0630 23:41:23.202682  7564 solver.cpp:218] Iteration 55800 (25.1616 iter/s, 3.97431s/100 iters), loss = 0.131109
I0630 23:41:23.202682  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:41:23.202682  7564 solver.cpp:237]     Train net output #1: loss = 0.13111 (* 1 = 0.13111 loss)
I0630 23:41:23.202682  7564 sgd_solver.cpp:105] Iteration 55800, lr = 1e-05
I0630 23:41:27.177058  7564 solver.cpp:218] Iteration 55900 (25.1628 iter/s, 3.97413s/100 iters), loss = 0.229381
I0630 23:41:27.177058  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:41:27.177058  7564 solver.cpp:237]     Train net output #1: loss = 0.229382 (* 1 = 0.229382 loss)
I0630 23:41:27.177058  7564 sgd_solver.cpp:105] Iteration 55900, lr = 1e-05
I0630 23:41:30.961748  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:41:31.117861  7564 solver.cpp:330] Iteration 56000, Testing net (#0)
I0630 23:41:31.117861  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:41:32.013011  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:41:32.047035  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:41:32.047035  7564 solver.cpp:397]     Test net output #1: loss = 0.427488 (* 1 = 0.427488 loss)
I0630 23:41:32.085058  7564 solver.cpp:218] Iteration 56000 (20.3758 iter/s, 4.90779s/100 iters), loss = 0.204327
I0630 23:41:32.085563  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:41:32.085563  7564 solver.cpp:237]     Train net output #1: loss = 0.204327 (* 1 = 0.204327 loss)
I0630 23:41:32.085563  7564 sgd_solver.cpp:105] Iteration 56000, lr = 1e-05
I0630 23:41:36.063879  7564 solver.cpp:218] Iteration 56100 (25.1356 iter/s, 3.97843s/100 iters), loss = 0.135515
I0630 23:41:36.064379  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:41:36.064379  7564 solver.cpp:237]     Train net output #1: loss = 0.135516 (* 1 = 0.135516 loss)
I0630 23:41:36.064379  7564 sgd_solver.cpp:105] Iteration 56100, lr = 1e-05
I0630 23:41:40.036705  7564 solver.cpp:218] Iteration 56200 (25.1743 iter/s, 3.9723s/100 iters), loss = 0.170832
I0630 23:41:40.036705  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:41:40.036705  7564 solver.cpp:237]     Train net output #1: loss = 0.170833 (* 1 = 0.170833 loss)
I0630 23:41:40.036705  7564 sgd_solver.cpp:105] Iteration 56200, lr = 1e-05
I0630 23:41:44.011611  7564 solver.cpp:218] Iteration 56300 (25.1615 iter/s, 3.97432s/100 iters), loss = 0.121184
I0630 23:41:44.011611  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:41:44.011611  7564 solver.cpp:237]     Train net output #1: loss = 0.121184 (* 1 = 0.121184 loss)
I0630 23:41:44.011611  7564 sgd_solver.cpp:105] Iteration 56300, lr = 1e-05
I0630 23:41:47.991952  7564 solver.cpp:218] Iteration 56400 (25.1263 iter/s, 3.97989s/100 iters), loss = 0.190136
I0630 23:41:47.991952  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:41:47.991952  7564 solver.cpp:237]     Train net output #1: loss = 0.190136 (* 1 = 0.190136 loss)
I0630 23:41:47.991952  7564 sgd_solver.cpp:105] Iteration 56400, lr = 1e-05
I0630 23:41:51.772632  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:41:51.928758  7564 solver.cpp:330] Iteration 56500, Testing net (#0)
I0630 23:41:51.928758  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:41:52.822890  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:41:52.856420  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8724
I0630 23:41:52.856916  7564 solver.cpp:397]     Test net output #1: loss = 0.426856 (* 1 = 0.426856 loss)
I0630 23:41:52.894448  7564 solver.cpp:218] Iteration 56500 (20.3991 iter/s, 4.90217s/100 iters), loss = 0.0956362
I0630 23:41:52.894448  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:41:52.894448  7564 solver.cpp:237]     Train net output #1: loss = 0.0956366 (* 1 = 0.0956366 loss)
I0630 23:41:52.894448  7564 sgd_solver.cpp:105] Iteration 56500, lr = 1e-05
I0630 23:41:56.870301  7564 solver.cpp:218] Iteration 56600 (25.1546 iter/s, 3.97541s/100 iters), loss = 0.17835
I0630 23:41:56.870301  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:41:56.870301  7564 solver.cpp:237]     Train net output #1: loss = 0.17835 (* 1 = 0.17835 loss)
I0630 23:41:56.870301  7564 sgd_solver.cpp:105] Iteration 56600, lr = 1e-05
I0630 23:42:00.840075  7564 solver.cpp:218] Iteration 56700 (25.1915 iter/s, 3.96959s/100 iters), loss = 0.164372
I0630 23:42:00.840576  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:42:00.840576  7564 solver.cpp:237]     Train net output #1: loss = 0.164372 (* 1 = 0.164372 loss)
I0630 23:42:00.840576  7564 sgd_solver.cpp:105] Iteration 56700, lr = 1e-05
I0630 23:42:04.806423  7564 solver.cpp:218] Iteration 56800 (25.2188 iter/s, 3.9653s/100 iters), loss = 0.163687
I0630 23:42:04.806423  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:42:04.806423  7564 solver.cpp:237]     Train net output #1: loss = 0.163687 (* 1 = 0.163687 loss)
I0630 23:42:04.806423  7564 sgd_solver.cpp:105] Iteration 56800, lr = 1e-05
I0630 23:42:08.774745  7564 solver.cpp:218] Iteration 56900 (25.2017 iter/s, 3.96799s/100 iters), loss = 0.206514
I0630 23:42:08.774745  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:42:08.774745  7564 solver.cpp:237]     Train net output #1: loss = 0.206514 (* 1 = 0.206514 loss)
I0630 23:42:08.774745  7564 sgd_solver.cpp:105] Iteration 56900, lr = 1e-05
I0630 23:42:12.551712  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:42:12.706805  7564 solver.cpp:330] Iteration 57000, Testing net (#0)
I0630 23:42:12.706805  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:42:13.603443  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:42:13.637468  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:42:13.637468  7564 solver.cpp:397]     Test net output #1: loss = 0.427108 (* 1 = 0.427108 loss)
I0630 23:42:13.674494  7564 solver.cpp:218] Iteration 57000 (20.4101 iter/s, 4.89952s/100 iters), loss = 0.144795
I0630 23:42:13.674494  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:42:13.674494  7564 solver.cpp:237]     Train net output #1: loss = 0.144795 (* 1 = 0.144795 loss)
I0630 23:42:13.674494  7564 sgd_solver.cpp:105] Iteration 57000, lr = 1e-05
I0630 23:42:17.648821  7564 solver.cpp:218] Iteration 57100 (25.166 iter/s, 3.97362s/100 iters), loss = 0.159815
I0630 23:42:17.648821  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:42:17.648821  7564 solver.cpp:237]     Train net output #1: loss = 0.159815 (* 1 = 0.159815 loss)
I0630 23:42:17.648821  7564 sgd_solver.cpp:105] Iteration 57100, lr = 1e-05
I0630 23:42:21.627151  7564 solver.cpp:218] Iteration 57200 (25.1367 iter/s, 3.97825s/100 iters), loss = 0.142574
I0630 23:42:21.627151  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:42:21.627652  7564 solver.cpp:237]     Train net output #1: loss = 0.142575 (* 1 = 0.142575 loss)
I0630 23:42:21.627652  7564 sgd_solver.cpp:105] Iteration 57200, lr = 1e-05
I0630 23:42:25.604481  7564 solver.cpp:218] Iteration 57300 (25.1469 iter/s, 3.97663s/100 iters), loss = 0.139122
I0630 23:42:25.604481  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:42:25.604481  7564 solver.cpp:237]     Train net output #1: loss = 0.139123 (* 1 = 0.139123 loss)
I0630 23:42:25.604481  7564 sgd_solver.cpp:105] Iteration 57300, lr = 1e-05
I0630 23:42:29.586314  7564 solver.cpp:218] Iteration 57400 (25.1148 iter/s, 3.98171s/100 iters), loss = 0.163437
I0630 23:42:29.586314  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:42:29.586314  7564 solver.cpp:237]     Train net output #1: loss = 0.163437 (* 1 = 0.163437 loss)
I0630 23:42:29.586314  7564 sgd_solver.cpp:105] Iteration 57400, lr = 1e-05
I0630 23:42:33.368010  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:42:33.523115  7564 solver.cpp:330] Iteration 57500, Testing net (#0)
I0630 23:42:33.523115  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:42:34.417752  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:42:34.452277  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:42:34.452277  7564 solver.cpp:397]     Test net output #1: loss = 0.427059 (* 1 = 0.427059 loss)
I0630 23:42:34.490303  7564 solver.cpp:218] Iteration 57500 (20.3941 iter/s, 4.90339s/100 iters), loss = 0.121711
I0630 23:42:34.490303  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:42:34.490303  7564 solver.cpp:237]     Train net output #1: loss = 0.121712 (* 1 = 0.121712 loss)
I0630 23:42:34.490303  7564 sgd_solver.cpp:105] Iteration 57500, lr = 1e-05
I0630 23:42:38.470135  7564 solver.cpp:218] Iteration 57600 (25.1267 iter/s, 3.97983s/100 iters), loss = 0.109706
I0630 23:42:38.470635  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:42:38.470635  7564 solver.cpp:237]     Train net output #1: loss = 0.109706 (* 1 = 0.109706 loss)
I0630 23:42:38.470635  7564 sgd_solver.cpp:105] Iteration 57600, lr = 1e-05
I0630 23:42:42.468979  7564 solver.cpp:218] Iteration 57700 (25.0106 iter/s, 3.9983s/100 iters), loss = 0.180438
I0630 23:42:42.468979  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:42:42.469480  7564 solver.cpp:237]     Train net output #1: loss = 0.180438 (* 1 = 0.180438 loss)
I0630 23:42:42.469480  7564 sgd_solver.cpp:105] Iteration 57700, lr = 1e-05
I0630 23:42:46.463322  7564 solver.cpp:218] Iteration 57800 (25.038 iter/s, 3.99393s/100 iters), loss = 0.143484
I0630 23:42:46.463822  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:42:46.463822  7564 solver.cpp:237]     Train net output #1: loss = 0.143484 (* 1 = 0.143484 loss)
I0630 23:42:46.463822  7564 sgd_solver.cpp:105] Iteration 57800, lr = 1e-05
I0630 23:42:50.447212  7564 solver.cpp:218] Iteration 57900 (25.1045 iter/s, 3.98335s/100 iters), loss = 0.176002
I0630 23:42:50.447212  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:42:50.447212  7564 solver.cpp:237]     Train net output #1: loss = 0.176002 (* 1 = 0.176002 loss)
I0630 23:42:50.447212  7564 sgd_solver.cpp:105] Iteration 57900, lr = 1e-05
I0630 23:42:54.237409  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:42:54.393520  7564 solver.cpp:330] Iteration 58000, Testing net (#0)
I0630 23:42:54.394021  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:42:55.290158  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:42:55.323683  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8723
I0630 23:42:55.323683  7564 solver.cpp:397]     Test net output #1: loss = 0.42755 (* 1 = 0.42755 loss)
I0630 23:42:55.361711  7564 solver.cpp:218] Iteration 58000 (20.3503 iter/s, 4.91393s/100 iters), loss = 0.119359
I0630 23:42:55.361711  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:42:55.361711  7564 solver.cpp:237]     Train net output #1: loss = 0.119359 (* 1 = 0.119359 loss)
I0630 23:42:55.361711  7564 sgd_solver.cpp:105] Iteration 58000, lr = 1e-05
I0630 23:42:59.337538  7564 solver.cpp:218] Iteration 58100 (25.1562 iter/s, 3.97516s/100 iters), loss = 0.130615
I0630 23:42:59.337538  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:42:59.337538  7564 solver.cpp:237]     Train net output #1: loss = 0.130615 (* 1 = 0.130615 loss)
I0630 23:42:59.337538  7564 sgd_solver.cpp:105] Iteration 58100, lr = 1e-05
I0630 23:43:03.321373  7564 solver.cpp:218] Iteration 58200 (25.102 iter/s, 3.98374s/100 iters), loss = 0.145865
I0630 23:43:03.321373  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:43:03.321373  7564 solver.cpp:237]     Train net output #1: loss = 0.145865 (* 1 = 0.145865 loss)
I0630 23:43:03.321373  7564 sgd_solver.cpp:105] Iteration 58200, lr = 1e-05
I0630 23:43:07.301663  7564 solver.cpp:218] Iteration 58300 (25.1262 iter/s, 3.97991s/100 iters), loss = 0.154275
I0630 23:43:07.301663  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:43:07.301663  7564 solver.cpp:237]     Train net output #1: loss = 0.154276 (* 1 = 0.154276 loss)
I0630 23:43:07.301663  7564 sgd_solver.cpp:105] Iteration 58300, lr = 1e-05
I0630 23:43:11.286578  7564 solver.cpp:218] Iteration 58400 (25.0972 iter/s, 3.98451s/100 iters), loss = 0.198445
I0630 23:43:11.286578  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:43:11.286578  7564 solver.cpp:237]     Train net output #1: loss = 0.198445 (* 1 = 0.198445 loss)
I0630 23:43:11.287078  7564 sgd_solver.cpp:105] Iteration 58400, lr = 1e-05
I0630 23:43:15.066766  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:43:15.221879  7564 solver.cpp:330] Iteration 58500, Testing net (#0)
I0630 23:43:15.221879  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:43:16.115023  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:43:16.149538  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8726
I0630 23:43:16.149538  7564 solver.cpp:397]     Test net output #1: loss = 0.426486 (* 1 = 0.426486 loss)
I0630 23:43:16.187566  7564 solver.cpp:218] Iteration 58500 (20.4067 iter/s, 4.90036s/100 iters), loss = 0.112988
I0630 23:43:16.187566  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:43:16.187566  7564 solver.cpp:237]     Train net output #1: loss = 0.112988 (* 1 = 0.112988 loss)
I0630 23:43:16.187566  7564 sgd_solver.cpp:105] Iteration 58500, lr = 1e-05
I0630 23:43:20.157486  7564 solver.cpp:218] Iteration 58600 (25.1911 iter/s, 3.96966s/100 iters), loss = 0.14196
I0630 23:43:20.157486  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:43:20.157987  7564 solver.cpp:237]     Train net output #1: loss = 0.14196 (* 1 = 0.14196 loss)
I0630 23:43:20.157987  7564 sgd_solver.cpp:105] Iteration 58600, lr = 1e-05
I0630 23:43:24.132302  7564 solver.cpp:218] Iteration 58700 (25.164 iter/s, 3.97393s/100 iters), loss = 0.148131
I0630 23:43:24.132302  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:43:24.132302  7564 solver.cpp:237]     Train net output #1: loss = 0.148131 (* 1 = 0.148131 loss)
I0630 23:43:24.132302  7564 sgd_solver.cpp:105] Iteration 58700, lr = 1e-05
I0630 23:43:28.108167  7564 solver.cpp:218] Iteration 58800 (25.1532 iter/s, 3.97563s/100 iters), loss = 0.158654
I0630 23:43:28.108167  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:43:28.108167  7564 solver.cpp:237]     Train net output #1: loss = 0.158654 (* 1 = 0.158654 loss)
I0630 23:43:28.108167  7564 sgd_solver.cpp:105] Iteration 58800, lr = 1e-05
I0630 23:43:32.080483  7564 solver.cpp:218] Iteration 58900 (25.1777 iter/s, 3.97176s/100 iters), loss = 0.184828
I0630 23:43:32.080483  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:43:32.080483  7564 solver.cpp:237]     Train net output #1: loss = 0.184829 (* 1 = 0.184829 loss)
I0630 23:43:32.080483  7564 sgd_solver.cpp:105] Iteration 58900, lr = 1e-05
I0630 23:43:35.857669  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:43:36.012790  7564 solver.cpp:330] Iteration 59000, Testing net (#0)
I0630 23:43:36.012790  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:43:36.906918  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:43:36.941952  7564 solver.cpp:397]     Test net output #0: accuracy = 0.872
I0630 23:43:36.941952  7564 solver.cpp:397]     Test net output #1: loss = 0.427252 (* 1 = 0.427252 loss)
I0630 23:43:36.979480  7564 solver.cpp:218] Iteration 59000 (20.4127 iter/s, 4.89891s/100 iters), loss = 0.0926448
I0630 23:43:36.979981  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:43:36.979981  7564 solver.cpp:237]     Train net output #1: loss = 0.0926451 (* 1 = 0.0926451 loss)
I0630 23:43:36.979981  7564 sgd_solver.cpp:105] Iteration 59000, lr = 1e-05
I0630 23:43:40.953352  7564 solver.cpp:218] Iteration 59100 (25.1694 iter/s, 3.97309s/100 iters), loss = 0.184929
I0630 23:43:40.953352  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:43:40.953352  7564 solver.cpp:237]     Train net output #1: loss = 0.184929 (* 1 = 0.184929 loss)
I0630 23:43:40.953352  7564 sgd_solver.cpp:105] Iteration 59100, lr = 1e-05
I0630 23:43:44.926169  7564 solver.cpp:218] Iteration 59200 (25.1736 iter/s, 3.97241s/100 iters), loss = 0.169158
I0630 23:43:44.926169  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:43:44.926169  7564 solver.cpp:237]     Train net output #1: loss = 0.169158 (* 1 = 0.169158 loss)
I0630 23:43:44.926169  7564 sgd_solver.cpp:105] Iteration 59200, lr = 1e-05
I0630 23:43:48.900022  7564 solver.cpp:218] Iteration 59300 (25.1655 iter/s, 3.97369s/100 iters), loss = 0.120411
I0630 23:43:48.900022  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:43:48.900022  7564 solver.cpp:237]     Train net output #1: loss = 0.120411 (* 1 = 0.120411 loss)
I0630 23:43:48.900022  7564 sgd_solver.cpp:105] Iteration 59300, lr = 1e-05
I0630 23:43:52.872861  7564 solver.cpp:218] Iteration 59400 (25.1735 iter/s, 3.97242s/100 iters), loss = 0.187401
I0630 23:43:52.872861  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:43:52.872861  7564 solver.cpp:237]     Train net output #1: loss = 0.187401 (* 1 = 0.187401 loss)
I0630 23:43:52.872861  7564 sgd_solver.cpp:105] Iteration 59400, lr = 1e-05
I0630 23:43:56.652041  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:43:56.809154  7564 solver.cpp:330] Iteration 59500, Testing net (#0)
I0630 23:43:56.809154  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:43:57.705305  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:43:57.738831  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8721
I0630 23:43:57.738831  7564 solver.cpp:397]     Test net output #1: loss = 0.426669 (* 1 = 0.426669 loss)
I0630 23:43:57.776841  7564 solver.cpp:218] Iteration 59500 (20.3943 iter/s, 4.90334s/100 iters), loss = 0.148658
I0630 23:43:57.776841  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:43:57.776841  7564 solver.cpp:237]     Train net output #1: loss = 0.148658 (* 1 = 0.148658 loss)
I0630 23:43:57.776841  7564 sgd_solver.cpp:105] Iteration 59500, lr = 1e-05
I0630 23:44:01.747195  7564 solver.cpp:218] Iteration 59600 (25.1885 iter/s, 3.97006s/100 iters), loss = 0.127903
I0630 23:44:01.747195  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:44:01.747195  7564 solver.cpp:237]     Train net output #1: loss = 0.127903 (* 1 = 0.127903 loss)
I0630 23:44:01.747195  7564 sgd_solver.cpp:105] Iteration 59600, lr = 1e-05
I0630 23:44:05.714552  7564 solver.cpp:218] Iteration 59700 (25.2073 iter/s, 3.9671s/100 iters), loss = 0.182511
I0630 23:44:05.714552  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:44:05.714552  7564 solver.cpp:237]     Train net output #1: loss = 0.182511 (* 1 = 0.182511 loss)
I0630 23:44:05.714552  7564 sgd_solver.cpp:105] Iteration 59700, lr = 1e-05
I0630 23:44:09.682935  7564 solver.cpp:218] Iteration 59800 (25.2021 iter/s, 3.96792s/100 iters), loss = 0.0982529
I0630 23:44:09.682935  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:44:09.682935  7564 solver.cpp:237]     Train net output #1: loss = 0.0982531 (* 1 = 0.0982531 loss)
I0630 23:44:09.682935  7564 sgd_solver.cpp:105] Iteration 59800, lr = 1e-05
I0630 23:44:13.649747  7564 solver.cpp:218] Iteration 59900 (25.2127 iter/s, 3.96625s/100 iters), loss = 0.171367
I0630 23:44:13.649747  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:44:13.649747  7564 solver.cpp:237]     Train net output #1: loss = 0.171367 (* 1 = 0.171367 loss)
I0630 23:44:13.649747  7564 sgd_solver.cpp:105] Iteration 59900, lr = 1e-05
I0630 23:44:17.450503  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:44:17.606114  7564 solver.cpp:330] Iteration 60000, Testing net (#0)
I0630 23:44:17.606114  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:44:18.505755  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:44:18.539779  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8721
I0630 23:44:18.539779  7564 solver.cpp:397]     Test net output #1: loss = 0.427089 (* 1 = 0.427089 loss)
I0630 23:44:18.576807  7564 solver.cpp:218] Iteration 60000 (20.2988 iter/s, 4.92639s/100 iters), loss = 0.124429
I0630 23:44:18.576807  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:44:18.576807  7564 solver.cpp:237]     Train net output #1: loss = 0.124429 (* 1 = 0.124429 loss)
I0630 23:44:18.576807  7564 sgd_solver.cpp:105] Iteration 60000, lr = 1e-05
I0630 23:44:22.546754  7564 solver.cpp:218] Iteration 60100 (25.1921 iter/s, 3.9695s/100 iters), loss = 0.15082
I0630 23:44:22.546754  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:44:22.546754  7564 solver.cpp:237]     Train net output #1: loss = 0.15082 (* 1 = 0.15082 loss)
I0630 23:44:22.546754  7564 sgd_solver.cpp:105] Iteration 60100, lr = 1e-05
I0630 23:44:26.518153  7564 solver.cpp:218] Iteration 60200 (25.181 iter/s, 3.97125s/100 iters), loss = 0.0812995
I0630 23:44:26.518153  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:44:26.518153  7564 solver.cpp:237]     Train net output #1: loss = 0.0812998 (* 1 = 0.0812998 loss)
I0630 23:44:26.518153  7564 sgd_solver.cpp:105] Iteration 60200, lr = 1e-05
I0630 23:44:30.492480  7564 solver.cpp:218] Iteration 60300 (25.166 iter/s, 3.97362s/100 iters), loss = 0.118858
I0630 23:44:30.492480  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:44:30.492480  7564 solver.cpp:237]     Train net output #1: loss = 0.118858 (* 1 = 0.118858 loss)
I0630 23:44:30.492480  7564 sgd_solver.cpp:105] Iteration 60300, lr = 1e-05
I0630 23:44:34.466809  7564 solver.cpp:218] Iteration 60400 (25.1659 iter/s, 3.97363s/100 iters), loss = 0.16824
I0630 23:44:34.466809  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:44:34.466809  7564 solver.cpp:237]     Train net output #1: loss = 0.16824 (* 1 = 0.16824 loss)
I0630 23:44:34.466809  7564 sgd_solver.cpp:105] Iteration 60400, lr = 1e-05
I0630 23:44:38.246088  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:44:38.403713  7564 solver.cpp:330] Iteration 60500, Testing net (#0)
I0630 23:44:38.403713  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:44:39.298352  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:44:39.332887  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:44:39.332887  7564 solver.cpp:397]     Test net output #1: loss = 0.427481 (* 1 = 0.427481 loss)
I0630 23:44:39.370899  7564 solver.cpp:218] Iteration 60500 (20.3917 iter/s, 4.90397s/100 iters), loss = 0.129056
I0630 23:44:39.370899  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:44:39.370899  7564 solver.cpp:237]     Train net output #1: loss = 0.129057 (* 1 = 0.129057 loss)
I0630 23:44:39.370899  7564 sgd_solver.cpp:105] Iteration 60500, lr = 1e-05
I0630 23:44:43.344274  7564 solver.cpp:218] Iteration 60600 (25.1706 iter/s, 3.97289s/100 iters), loss = 0.148176
I0630 23:44:43.344274  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:44:43.344274  7564 solver.cpp:237]     Train net output #1: loss = 0.148176 (* 1 = 0.148176 loss)
I0630 23:44:43.344274  7564 sgd_solver.cpp:105] Iteration 60600, lr = 1e-05
I0630 23:44:47.321097  7564 solver.cpp:218] Iteration 60700 (25.1479 iter/s, 3.97647s/100 iters), loss = 0.120756
I0630 23:44:47.321097  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:44:47.321097  7564 solver.cpp:237]     Train net output #1: loss = 0.120756 (* 1 = 0.120756 loss)
I0630 23:44:47.321097  7564 sgd_solver.cpp:105] Iteration 60700, lr = 1e-05
I0630 23:44:51.298918  7564 solver.cpp:218] Iteration 60800 (25.1429 iter/s, 3.97727s/100 iters), loss = 0.178522
I0630 23:44:51.298918  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:44:51.298918  7564 solver.cpp:237]     Train net output #1: loss = 0.178523 (* 1 = 0.178523 loss)
I0630 23:44:51.298918  7564 sgd_solver.cpp:105] Iteration 60800, lr = 1e-05
I0630 23:44:55.276515  7564 solver.cpp:218] Iteration 60900 (25.144 iter/s, 3.97709s/100 iters), loss = 0.150083
I0630 23:44:55.276515  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:44:55.276515  7564 solver.cpp:237]     Train net output #1: loss = 0.150084 (* 1 = 0.150084 loss)
I0630 23:44:55.276515  7564 sgd_solver.cpp:105] Iteration 60900, lr = 1e-05
I0630 23:44:59.055205  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:44:59.210815  7564 solver.cpp:330] Iteration 61000, Testing net (#0)
I0630 23:44:59.210815  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:45:00.100950  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:45:00.134474  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I0630 23:45:00.134474  7564 solver.cpp:397]     Test net output #1: loss = 0.42782 (* 1 = 0.42782 loss)
I0630 23:45:00.172500  7564 solver.cpp:218] Iteration 61000 (20.4254 iter/s, 4.89586s/100 iters), loss = 0.152829
I0630 23:45:00.172500  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:45:00.172500  7564 solver.cpp:237]     Train net output #1: loss = 0.152829 (* 1 = 0.152829 loss)
I0630 23:45:00.172500  7564 sgd_solver.cpp:105] Iteration 61000, lr = 1e-05
I0630 23:45:04.135320  7564 solver.cpp:218] Iteration 61100 (25.2395 iter/s, 3.96204s/100 iters), loss = 0.147874
I0630 23:45:04.135320  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:45:04.135320  7564 solver.cpp:237]     Train net output #1: loss = 0.147874 (* 1 = 0.147874 loss)
I0630 23:45:04.135320  7564 sgd_solver.cpp:105] Iteration 61100, lr = 1e-05
I0630 23:45:08.100641  7564 solver.cpp:218] Iteration 61200 (25.2207 iter/s, 3.965s/100 iters), loss = 0.124958
I0630 23:45:08.100641  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:45:08.100641  7564 solver.cpp:237]     Train net output #1: loss = 0.124959 (* 1 = 0.124959 loss)
I0630 23:45:08.100641  7564 sgd_solver.cpp:105] Iteration 61200, lr = 1e-05
I0630 23:45:12.063486  7564 solver.cpp:218] Iteration 61300 (25.2359 iter/s, 3.96261s/100 iters), loss = 0.139687
I0630 23:45:12.063486  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:45:12.063486  7564 solver.cpp:237]     Train net output #1: loss = 0.139688 (* 1 = 0.139688 loss)
I0630 23:45:12.063486  7564 sgd_solver.cpp:105] Iteration 61300, lr = 1e-05
I0630 23:45:16.030360  7564 solver.cpp:218] Iteration 61400 (25.2123 iter/s, 3.96631s/100 iters), loss = 0.124275
I0630 23:45:16.030360  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:45:16.030360  7564 solver.cpp:237]     Train net output #1: loss = 0.124276 (* 1 = 0.124276 loss)
I0630 23:45:16.030360  7564 sgd_solver.cpp:105] Iteration 61400, lr = 1e-05
I0630 23:45:19.803544  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:45:19.959656  7564 solver.cpp:330] Iteration 61500, Testing net (#0)
I0630 23:45:19.959656  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:45:20.849789  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:45:20.883313  7564 solver.cpp:397]     Test net output #0: accuracy = 0.872
I0630 23:45:20.883313  7564 solver.cpp:397]     Test net output #1: loss = 0.427409 (* 1 = 0.427409 loss)
I0630 23:45:20.921340  7564 solver.cpp:218] Iteration 61500 (20.4463 iter/s, 4.89086s/100 iters), loss = 0.108912
I0630 23:45:20.921340  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:45:20.921340  7564 solver.cpp:237]     Train net output #1: loss = 0.108912 (* 1 = 0.108912 loss)
I0630 23:45:20.921340  7564 sgd_solver.cpp:105] Iteration 61500, lr = 1e-05
I0630 23:45:24.883184  7564 solver.cpp:218] Iteration 61600 (25.2436 iter/s, 3.9614s/100 iters), loss = 0.129446
I0630 23:45:24.883184  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:45:24.883184  7564 solver.cpp:237]     Train net output #1: loss = 0.129447 (* 1 = 0.129447 loss)
I0630 23:45:24.883184  7564 sgd_solver.cpp:105] Iteration 61600, lr = 1e-05
I0630 23:45:28.856093  7564 solver.cpp:218] Iteration 61700 (25.1726 iter/s, 3.97258s/100 iters), loss = 0.12726
I0630 23:45:28.856093  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:45:28.856093  7564 solver.cpp:237]     Train net output #1: loss = 0.12726 (* 1 = 0.12726 loss)
I0630 23:45:28.856093  7564 sgd_solver.cpp:105] Iteration 61700, lr = 1e-05
I0630 23:45:32.824460  7564 solver.cpp:218] Iteration 61800 (25.2018 iter/s, 3.96797s/100 iters), loss = 0.132264
I0630 23:45:32.824460  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:45:32.824460  7564 solver.cpp:237]     Train net output #1: loss = 0.132264 (* 1 = 0.132264 loss)
I0630 23:45:32.824460  7564 sgd_solver.cpp:105] Iteration 61800, lr = 1e-05
I0630 23:45:36.784765  7564 solver.cpp:218] Iteration 61900 (25.2535 iter/s, 3.95985s/100 iters), loss = 0.208808
I0630 23:45:36.784765  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:45:36.784765  7564 solver.cpp:237]     Train net output #1: loss = 0.208808 (* 1 = 0.208808 loss)
I0630 23:45:36.784765  7564 sgd_solver.cpp:105] Iteration 61900, lr = 1e-05
I0630 23:45:40.558964  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:45:40.713562  7564 solver.cpp:330] Iteration 62000, Testing net (#0)
I0630 23:45:40.713562  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:45:41.602193  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:45:41.635717  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I0630 23:45:41.635717  7564 solver.cpp:397]     Test net output #1: loss = 0.426989 (* 1 = 0.426989 loss)
I0630 23:45:41.673744  7564 solver.cpp:218] Iteration 62000 (20.4556 iter/s, 4.88864s/100 iters), loss = 0.0855805
I0630 23:45:41.673744  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:45:41.673744  7564 solver.cpp:237]     Train net output #1: loss = 0.0855807 (* 1 = 0.0855807 loss)
I0630 23:45:41.673744  7564 sgd_solver.cpp:105] Iteration 62000, lr = 1e-05
I0630 23:45:45.641567  7564 solver.cpp:218] Iteration 62100 (25.207 iter/s, 3.96715s/100 iters), loss = 0.136007
I0630 23:45:45.641567  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:45:45.641567  7564 solver.cpp:237]     Train net output #1: loss = 0.136007 (* 1 = 0.136007 loss)
I0630 23:45:45.641567  7564 sgd_solver.cpp:105] Iteration 62100, lr = 1e-05
I0630 23:45:49.608891  7564 solver.cpp:218] Iteration 62200 (25.2089 iter/s, 3.96686s/100 iters), loss = 0.13061
I0630 23:45:49.608891  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:45:49.608891  7564 solver.cpp:237]     Train net output #1: loss = 0.13061 (* 1 = 0.13061 loss)
I0630 23:45:49.608891  7564 sgd_solver.cpp:105] Iteration 62200, lr = 1e-05
I0630 23:45:53.581763  7564 solver.cpp:218] Iteration 62300 (25.171 iter/s, 3.97283s/100 iters), loss = 0.20033
I0630 23:45:53.581763  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:45:53.581763  7564 solver.cpp:237]     Train net output #1: loss = 0.20033 (* 1 = 0.20033 loss)
I0630 23:45:53.581763  7564 sgd_solver.cpp:105] Iteration 62300, lr = 1e-05
I0630 23:45:57.594617  7564 solver.cpp:218] Iteration 62400 (24.9239 iter/s, 4.01221s/100 iters), loss = 0.181774
I0630 23:45:57.594617  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:45:57.594617  7564 solver.cpp:237]     Train net output #1: loss = 0.181775 (* 1 = 0.181775 loss)
I0630 23:45:57.594617  7564 sgd_solver.cpp:105] Iteration 62400, lr = 1e-05
I0630 23:46:01.367302  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:46:01.523912  7564 solver.cpp:330] Iteration 62500, Testing net (#0)
I0630 23:46:01.523912  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:46:02.414546  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:46:02.448071  7564 solver.cpp:397]     Test net output #0: accuracy = 0.872
I0630 23:46:02.448571  7564 solver.cpp:397]     Test net output #1: loss = 0.426646 (* 1 = 0.426646 loss)
I0630 23:46:02.486098  7564 solver.cpp:218] Iteration 62500 (20.4448 iter/s, 4.89121s/100 iters), loss = 0.172363
I0630 23:46:02.486098  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:46:02.486098  7564 solver.cpp:237]     Train net output #1: loss = 0.172364 (* 1 = 0.172364 loss)
I0630 23:46:02.486098  7564 sgd_solver.cpp:105] Iteration 62500, lr = 1e-05
I0630 23:46:06.438992  7564 solver.cpp:218] Iteration 62600 (25.3013 iter/s, 3.95237s/100 iters), loss = 0.098491
I0630 23:46:06.438992  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:46:06.438992  7564 solver.cpp:237]     Train net output #1: loss = 0.0984912 (* 1 = 0.0984912 loss)
I0630 23:46:06.438992  7564 sgd_solver.cpp:105] Iteration 62600, lr = 1e-05
I0630 23:46:10.385354  7564 solver.cpp:218] Iteration 62700 (25.3425 iter/s, 3.94594s/100 iters), loss = 0.122067
I0630 23:46:10.385354  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:46:10.385354  7564 solver.cpp:237]     Train net output #1: loss = 0.122068 (* 1 = 0.122068 loss)
I0630 23:46:10.385354  7564 sgd_solver.cpp:105] Iteration 62700, lr = 1e-05
I0630 23:46:14.329649  7564 solver.cpp:218] Iteration 62800 (25.3529 iter/s, 3.94431s/100 iters), loss = 0.151058
I0630 23:46:14.330149  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:46:14.330149  7564 solver.cpp:237]     Train net output #1: loss = 0.151059 (* 1 = 0.151059 loss)
I0630 23:46:14.330149  7564 sgd_solver.cpp:105] Iteration 62800, lr = 1e-05
I0630 23:46:18.280288  7564 solver.cpp:218] Iteration 62900 (25.3149 iter/s, 3.95024s/100 iters), loss = 0.189372
I0630 23:46:18.280791  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:46:18.280791  7564 solver.cpp:237]     Train net output #1: loss = 0.189372 (* 1 = 0.189372 loss)
I0630 23:46:18.280791  7564 sgd_solver.cpp:105] Iteration 62900, lr = 1e-05
I0630 23:46:22.037742  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:46:22.191853  7564 solver.cpp:330] Iteration 63000, Testing net (#0)
I0630 23:46:22.191853  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:46:23.082494  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:46:23.115509  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:46:23.116009  7564 solver.cpp:397]     Test net output #1: loss = 0.427758 (* 1 = 0.427758 loss)
I0630 23:46:23.153035  7564 solver.cpp:218] Iteration 63000 (20.5246 iter/s, 4.87221s/100 iters), loss = 0.11617
I0630 23:46:23.153035  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:46:23.153035  7564 solver.cpp:237]     Train net output #1: loss = 0.11617 (* 1 = 0.11617 loss)
I0630 23:46:23.153035  7564 sgd_solver.cpp:105] Iteration 63000, lr = 1e-05
I0630 23:46:27.106091  7564 solver.cpp:218] Iteration 63100 (25.301 iter/s, 3.95241s/100 iters), loss = 0.103331
I0630 23:46:27.106091  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:46:27.106091  7564 solver.cpp:237]     Train net output #1: loss = 0.103331 (* 1 = 0.103331 loss)
I0630 23:46:27.106091  7564 sgd_solver.cpp:105] Iteration 63100, lr = 1e-05
I0630 23:46:31.057903  7564 solver.cpp:218] Iteration 63200 (25.3071 iter/s, 3.95145s/100 iters), loss = 0.115459
I0630 23:46:31.057903  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:46:31.057903  7564 solver.cpp:237]     Train net output #1: loss = 0.115459 (* 1 = 0.115459 loss)
I0630 23:46:31.057903  7564 sgd_solver.cpp:105] Iteration 63200, lr = 1e-05
I0630 23:46:35.013736  7564 solver.cpp:218] Iteration 63300 (25.2797 iter/s, 3.95575s/100 iters), loss = 0.192567
I0630 23:46:35.013736  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:46:35.013736  7564 solver.cpp:237]     Train net output #1: loss = 0.192568 (* 1 = 0.192568 loss)
I0630 23:46:35.013736  7564 sgd_solver.cpp:105] Iteration 63300, lr = 1e-05
I0630 23:46:38.965571  7564 solver.cpp:218] Iteration 63400 (25.3098 iter/s, 3.95104s/100 iters), loss = 0.178221
I0630 23:46:38.965571  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:46:38.965571  7564 solver.cpp:237]     Train net output #1: loss = 0.178222 (* 1 = 0.178222 loss)
I0630 23:46:38.965571  7564 sgd_solver.cpp:105] Iteration 63400, lr = 1e-05
I0630 23:46:42.728768  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:46:42.882378  7564 solver.cpp:330] Iteration 63500, Testing net (#0)
I0630 23:46:42.882378  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:46:43.773022  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:46:43.807536  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8728
I0630 23:46:43.807536  7564 solver.cpp:397]     Test net output #1: loss = 0.427077 (* 1 = 0.427077 loss)
I0630 23:46:43.844561  7564 solver.cpp:218] Iteration 63500 (20.4968 iter/s, 4.87882s/100 iters), loss = 0.138455
I0630 23:46:43.844561  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:46:43.844561  7564 solver.cpp:237]     Train net output #1: loss = 0.138456 (* 1 = 0.138456 loss)
I0630 23:46:43.844561  7564 sgd_solver.cpp:105] Iteration 63500, lr = 1e-05
I0630 23:46:47.803169  7564 solver.cpp:218] Iteration 63600 (25.2643 iter/s, 3.95816s/100 iters), loss = 0.12667
I0630 23:46:47.803169  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:46:47.803169  7564 solver.cpp:237]     Train net output #1: loss = 0.12667 (* 1 = 0.12667 loss)
I0630 23:46:47.803169  7564 sgd_solver.cpp:105] Iteration 63600, lr = 1e-05
I0630 23:46:51.758013  7564 solver.cpp:218] Iteration 63700 (25.2864 iter/s, 3.95469s/100 iters), loss = 0.117781
I0630 23:46:51.758013  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:46:51.758013  7564 solver.cpp:237]     Train net output #1: loss = 0.117781 (* 1 = 0.117781 loss)
I0630 23:46:51.758013  7564 sgd_solver.cpp:105] Iteration 63700, lr = 1e-05
I0630 23:46:55.713382  7564 solver.cpp:218] Iteration 63800 (25.2852 iter/s, 3.95488s/100 iters), loss = 0.132009
I0630 23:46:55.713382  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:46:55.713382  7564 solver.cpp:237]     Train net output #1: loss = 0.132009 (* 1 = 0.132009 loss)
I0630 23:46:55.713382  7564 sgd_solver.cpp:105] Iteration 63800, lr = 1e-05
I0630 23:46:59.665194  7564 solver.cpp:218] Iteration 63900 (25.3066 iter/s, 3.95154s/100 iters), loss = 0.164729
I0630 23:46:59.665194  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:46:59.665693  7564 solver.cpp:237]     Train net output #1: loss = 0.164729 (* 1 = 0.164729 loss)
I0630 23:46:59.665693  7564 sgd_solver.cpp:105] Iteration 63900, lr = 1e-05
I0630 23:47:03.422865  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:47:03.578987  7564 solver.cpp:330] Iteration 64000, Testing net (#0)
I0630 23:47:03.579488  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:47:04.468621  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:47:04.503149  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8727
I0630 23:47:04.503149  7564 solver.cpp:397]     Test net output #1: loss = 0.426738 (* 1 = 0.426738 loss)
I0630 23:47:04.541162  7564 solver.cpp:218] Iteration 64000 (20.5108 iter/s, 4.87547s/100 iters), loss = 0.115706
I0630 23:47:04.541162  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:47:04.541162  7564 solver.cpp:237]     Train net output #1: loss = 0.115706 (* 1 = 0.115706 loss)
I0630 23:47:04.541162  7564 sgd_solver.cpp:46] MultiStep Status: Iteration 64000, step = 4
I0630 23:47:04.541162  7564 sgd_solver.cpp:105] Iteration 64000, lr = 1e-06
I0630 23:47:08.497977  7564 solver.cpp:218] Iteration 64100 (25.2763 iter/s, 3.95628s/100 iters), loss = 0.131922
I0630 23:47:08.497977  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:47:08.497977  7564 solver.cpp:237]     Train net output #1: loss = 0.131922 (* 1 = 0.131922 loss)
I0630 23:47:08.497977  7564 sgd_solver.cpp:105] Iteration 64100, lr = 1e-06
I0630 23:47:12.450831  7564 solver.cpp:218] Iteration 64200 (25.2994 iter/s, 3.95266s/100 iters), loss = 0.179222
I0630 23:47:12.450831  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:47:12.450831  7564 solver.cpp:237]     Train net output #1: loss = 0.179222 (* 1 = 0.179222 loss)
I0630 23:47:12.450831  7564 sgd_solver.cpp:105] Iteration 64200, lr = 1e-06
I0630 23:47:16.401144  7564 solver.cpp:218] Iteration 64300 (25.3178 iter/s, 3.94979s/100 iters), loss = 0.175284
I0630 23:47:16.401144  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:47:16.401144  7564 solver.cpp:237]     Train net output #1: loss = 0.175284 (* 1 = 0.175284 loss)
I0630 23:47:16.401144  7564 sgd_solver.cpp:105] Iteration 64300, lr = 1e-06
I0630 23:47:20.356458  7564 solver.cpp:218] Iteration 64400 (25.2865 iter/s, 3.95468s/100 iters), loss = 0.125054
I0630 23:47:20.356458  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:47:20.356458  7564 solver.cpp:237]     Train net output #1: loss = 0.125054 (* 1 = 0.125054 loss)
I0630 23:47:20.356458  7564 sgd_solver.cpp:105] Iteration 64400, lr = 1e-06
I0630 23:47:24.116633  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:47:24.271244  7564 solver.cpp:330] Iteration 64500, Testing net (#0)
I0630 23:47:24.271244  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:47:25.164379  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:47:25.198413  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8724
I0630 23:47:25.198413  7564 solver.cpp:397]     Test net output #1: loss = 0.427188 (* 1 = 0.427188 loss)
I0630 23:47:25.235942  7564 solver.cpp:218] Iteration 64500 (20.4952 iter/s, 4.8792s/100 iters), loss = 0.118398
I0630 23:47:25.235942  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:47:25.235942  7564 solver.cpp:237]     Train net output #1: loss = 0.118398 (* 1 = 0.118398 loss)
I0630 23:47:25.235942  7564 sgd_solver.cpp:105] Iteration 64500, lr = 1e-06
I0630 23:47:29.185789  7564 solver.cpp:218] Iteration 64600 (25.3206 iter/s, 3.94935s/100 iters), loss = 0.0927356
I0630 23:47:29.185789  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:47:29.185789  7564 solver.cpp:237]     Train net output #1: loss = 0.0927357 (* 1 = 0.0927357 loss)
I0630 23:47:29.185789  7564 sgd_solver.cpp:105] Iteration 64600, lr = 1e-06
I0630 23:47:33.132587  7564 solver.cpp:218] Iteration 64700 (25.3394 iter/s, 3.94642s/100 iters), loss = 0.144464
I0630 23:47:33.132587  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:47:33.132587  7564 solver.cpp:237]     Train net output #1: loss = 0.144464 (* 1 = 0.144464 loss)
I0630 23:47:33.132587  7564 sgd_solver.cpp:105] Iteration 64700, lr = 1e-06
I0630 23:47:37.081907  7564 solver.cpp:218] Iteration 64800 (25.3224 iter/s, 3.94908s/100 iters), loss = 0.184842
I0630 23:47:37.081907  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 23:47:37.081907  7564 solver.cpp:237]     Train net output #1: loss = 0.184842 (* 1 = 0.184842 loss)
I0630 23:47:37.081907  7564 sgd_solver.cpp:105] Iteration 64800, lr = 1e-06
I0630 23:47:41.036211  7564 solver.cpp:218] Iteration 64900 (25.2917 iter/s, 3.95387s/100 iters), loss = 0.135962
I0630 23:47:41.036211  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:47:41.036211  7564 solver.cpp:237]     Train net output #1: loss = 0.135962 (* 1 = 0.135962 loss)
I0630 23:47:41.036211  7564 sgd_solver.cpp:105] Iteration 64900, lr = 1e-06
I0630 23:47:44.789927  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:47:44.945554  7564 solver.cpp:330] Iteration 65000, Testing net (#0)
I0630 23:47:44.945554  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:47:45.838686  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:47:45.873209  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8722
I0630 23:47:45.873209  7564 solver.cpp:397]     Test net output #1: loss = 0.427724 (* 1 = 0.427724 loss)
I0630 23:47:45.911224  7564 solver.cpp:218] Iteration 65000 (20.5147 iter/s, 4.87456s/100 iters), loss = 0.127703
I0630 23:47:45.911224  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:47:45.911224  7564 solver.cpp:237]     Train net output #1: loss = 0.127703 (* 1 = 0.127703 loss)
I0630 23:47:45.911224  7564 sgd_solver.cpp:105] Iteration 65000, lr = 1e-06
I0630 23:47:49.864547  7564 solver.cpp:218] Iteration 65100 (25.2985 iter/s, 3.9528s/100 iters), loss = 0.0867394
I0630 23:47:49.864547  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:47:49.864547  7564 solver.cpp:237]     Train net output #1: loss = 0.0867396 (* 1 = 0.0867396 loss)
I0630 23:47:49.864547  7564 sgd_solver.cpp:105] Iteration 65100, lr = 1e-06
I0630 23:47:53.818401  7564 solver.cpp:218] Iteration 65200 (25.293 iter/s, 3.95367s/100 iters), loss = 0.192566
I0630 23:47:53.818401  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:47:53.818902  7564 solver.cpp:237]     Train net output #1: loss = 0.192566 (* 1 = 0.192566 loss)
I0630 23:47:53.818902  7564 sgd_solver.cpp:105] Iteration 65200, lr = 1e-06
I0630 23:47:57.775703  7564 solver.cpp:218] Iteration 65300 (25.2749 iter/s, 3.9565s/100 iters), loss = 0.146576
I0630 23:47:57.775703  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:47:57.775703  7564 solver.cpp:237]     Train net output #1: loss = 0.146576 (* 1 = 0.146576 loss)
I0630 23:47:57.775703  7564 sgd_solver.cpp:105] Iteration 65300, lr = 1e-06
I0630 23:48:01.726012  7564 solver.cpp:218] Iteration 65400 (25.3144 iter/s, 3.95031s/100 iters), loss = 0.204612
I0630 23:48:01.726012  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:48:01.726012  7564 solver.cpp:237]     Train net output #1: loss = 0.204612 (* 1 = 0.204612 loss)
I0630 23:48:01.726513  7564 sgd_solver.cpp:105] Iteration 65400, lr = 1e-06
I0630 23:48:05.486213  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:48:05.642339  7564 solver.cpp:330] Iteration 65500, Testing net (#0)
I0630 23:48:05.642339  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:48:06.534974  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:48:06.568994  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I0630 23:48:06.568994  7564 solver.cpp:397]     Test net output #1: loss = 0.426547 (* 1 = 0.426547 loss)
I0630 23:48:06.606010  7564 solver.cpp:218] Iteration 65500 (20.4937 iter/s, 4.87954s/100 iters), loss = 0.120521
I0630 23:48:06.606010  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:48:06.606010  7564 solver.cpp:237]     Train net output #1: loss = 0.120521 (* 1 = 0.120521 loss)
I0630 23:48:06.606010  7564 sgd_solver.cpp:105] Iteration 65500, lr = 1e-06
I0630 23:48:10.555320  7564 solver.cpp:218] Iteration 65600 (25.3251 iter/s, 3.94866s/100 iters), loss = 0.126209
I0630 23:48:10.555320  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:48:10.555320  7564 solver.cpp:237]     Train net output #1: loss = 0.126209 (* 1 = 0.126209 loss)
I0630 23:48:10.555320  7564 sgd_solver.cpp:105] Iteration 65600, lr = 1e-06
I0630 23:48:14.504688  7564 solver.cpp:218] Iteration 65700 (25.3228 iter/s, 3.94902s/100 iters), loss = 0.155947
I0630 23:48:14.504688  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:48:14.504688  7564 solver.cpp:237]     Train net output #1: loss = 0.155947 (* 1 = 0.155947 loss)
I0630 23:48:14.504688  7564 sgd_solver.cpp:105] Iteration 65700, lr = 1e-06
I0630 23:48:18.463074  7564 solver.cpp:218] Iteration 65800 (25.2642 iter/s, 3.95817s/100 iters), loss = 0.159301
I0630 23:48:18.463574  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:48:18.463574  7564 solver.cpp:237]     Train net output #1: loss = 0.159301 (* 1 = 0.159301 loss)
I0630 23:48:18.463574  7564 sgd_solver.cpp:105] Iteration 65800, lr = 1e-06
I0630 23:48:22.415386  7564 solver.cpp:218] Iteration 65900 (25.306 iter/s, 3.95164s/100 iters), loss = 0.193949
I0630 23:48:22.415386  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:48:22.415386  7564 solver.cpp:237]     Train net output #1: loss = 0.193949 (* 1 = 0.193949 loss)
I0630 23:48:22.415386  7564 sgd_solver.cpp:105] Iteration 65900, lr = 1e-06
I0630 23:48:26.172562  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:48:26.328184  7564 solver.cpp:330] Iteration 66000, Testing net (#0)
I0630 23:48:26.328184  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:48:27.218824  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:48:27.252841  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I0630 23:48:27.252841  7564 solver.cpp:397]     Test net output #1: loss = 0.427325 (* 1 = 0.427325 loss)
I0630 23:48:27.290868  7564 solver.cpp:218] Iteration 66000 (20.5126 iter/s, 4.87504s/100 iters), loss = 0.164863
I0630 23:48:27.290868  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:48:27.290868  7564 solver.cpp:237]     Train net output #1: loss = 0.164863 (* 1 = 0.164863 loss)
I0630 23:48:27.290868  7564 sgd_solver.cpp:105] Iteration 66000, lr = 1e-06
I0630 23:48:31.250197  7564 solver.cpp:218] Iteration 66100 (25.2579 iter/s, 3.95917s/100 iters), loss = 0.177499
I0630 23:48:31.250197  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:48:31.250197  7564 solver.cpp:237]     Train net output #1: loss = 0.177499 (* 1 = 0.177499 loss)
I0630 23:48:31.250197  7564 sgd_solver.cpp:105] Iteration 66100, lr = 1e-06
I0630 23:48:35.212050  7564 solver.cpp:218] Iteration 66200 (25.2451 iter/s, 3.96116s/100 iters), loss = 0.189228
I0630 23:48:35.212050  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:48:35.212050  7564 solver.cpp:237]     Train net output #1: loss = 0.189228 (* 1 = 0.189228 loss)
I0630 23:48:35.212050  7564 sgd_solver.cpp:105] Iteration 66200, lr = 1e-06
I0630 23:48:39.165359  7564 solver.cpp:218] Iteration 66300 (25.2953 iter/s, 3.95331s/100 iters), loss = 0.152785
I0630 23:48:39.165859  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:48:39.165859  7564 solver.cpp:237]     Train net output #1: loss = 0.152785 (* 1 = 0.152785 loss)
I0630 23:48:39.165859  7564 sgd_solver.cpp:105] Iteration 66300, lr = 1e-06
I0630 23:48:43.119663  7564 solver.cpp:218] Iteration 66400 (25.2945 iter/s, 3.95343s/100 iters), loss = 0.177136
I0630 23:48:43.119663  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:48:43.119663  7564 solver.cpp:237]     Train net output #1: loss = 0.177136 (* 1 = 0.177136 loss)
I0630 23:48:43.119663  7564 sgd_solver.cpp:105] Iteration 66400, lr = 1e-06
I0630 23:48:46.878857  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:48:47.033468  7564 solver.cpp:330] Iteration 66500, Testing net (#0)
I0630 23:48:47.033968  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:48:47.924602  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:48:47.959141  7564 solver.cpp:397]     Test net output #0: accuracy = 0.872
I0630 23:48:47.959141  7564 solver.cpp:397]     Test net output #1: loss = 0.427485 (* 1 = 0.427485 loss)
I0630 23:48:47.996654  7564 solver.cpp:218] Iteration 66500 (20.5063 iter/s, 4.87654s/100 iters), loss = 0.113003
I0630 23:48:47.996654  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:48:47.996654  7564 solver.cpp:237]     Train net output #1: loss = 0.113003 (* 1 = 0.113003 loss)
I0630 23:48:47.996654  7564 sgd_solver.cpp:105] Iteration 66500, lr = 1e-06
I0630 23:48:51.950484  7564 solver.cpp:218] Iteration 66600 (25.2941 iter/s, 3.9535s/100 iters), loss = 0.131951
I0630 23:48:51.950484  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:48:51.950484  7564 solver.cpp:237]     Train net output #1: loss = 0.131951 (* 1 = 0.131951 loss)
I0630 23:48:51.950484  7564 sgd_solver.cpp:105] Iteration 66600, lr = 1e-06
I0630 23:48:55.904809  7564 solver.cpp:218] Iteration 66700 (25.2903 iter/s, 3.95409s/100 iters), loss = 0.170684
I0630 23:48:55.904809  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:48:55.904809  7564 solver.cpp:237]     Train net output #1: loss = 0.170684 (* 1 = 0.170684 loss)
I0630 23:48:55.904809  7564 sgd_solver.cpp:105] Iteration 66700, lr = 1e-06
I0630 23:48:59.856945  7564 solver.cpp:218] Iteration 66800 (25.3051 iter/s, 3.95178s/100 iters), loss = 0.11626
I0630 23:48:59.856945  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:48:59.856945  7564 solver.cpp:237]     Train net output #1: loss = 0.11626 (* 1 = 0.11626 loss)
I0630 23:48:59.856945  7564 sgd_solver.cpp:105] Iteration 66800, lr = 1e-06
I0630 23:49:03.803258  7564 solver.cpp:218] Iteration 66900 (25.3408 iter/s, 3.94621s/100 iters), loss = 0.137203
I0630 23:49:03.803776  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:49:03.803776  7564 solver.cpp:237]     Train net output #1: loss = 0.137203 (* 1 = 0.137203 loss)
I0630 23:49:03.803776  7564 sgd_solver.cpp:105] Iteration 66900, lr = 1e-06
I0630 23:49:07.557955  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:49:07.712066  7564 solver.cpp:330] Iteration 67000, Testing net (#0)
I0630 23:49:07.712066  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:49:08.602699  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:49:08.635233  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8718
I0630 23:49:08.635233  7564 solver.cpp:397]     Test net output #1: loss = 0.427112 (* 1 = 0.427112 loss)
I0630 23:49:08.672749  7564 solver.cpp:218] Iteration 67000 (20.5384 iter/s, 4.86892s/100 iters), loss = 0.089654
I0630 23:49:08.672749  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:49:08.672749  7564 solver.cpp:237]     Train net output #1: loss = 0.089654 (* 1 = 0.089654 loss)
I0630 23:49:08.672749  7564 sgd_solver.cpp:105] Iteration 67000, lr = 1e-06
I0630 23:49:12.625075  7564 solver.cpp:218] Iteration 67100 (25.3046 iter/s, 3.95185s/100 iters), loss = 0.170168
I0630 23:49:12.625075  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:49:12.625075  7564 solver.cpp:237]     Train net output #1: loss = 0.170168 (* 1 = 0.170168 loss)
I0630 23:49:12.625075  7564 sgd_solver.cpp:105] Iteration 67100, lr = 1e-06
I0630 23:49:16.580909  7564 solver.cpp:218] Iteration 67200 (25.2826 iter/s, 3.95529s/100 iters), loss = 0.127685
I0630 23:49:16.580909  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:49:16.580909  7564 solver.cpp:237]     Train net output #1: loss = 0.127685 (* 1 = 0.127685 loss)
I0630 23:49:16.580909  7564 sgd_solver.cpp:105] Iteration 67200, lr = 1e-06
I0630 23:49:20.536751  7564 solver.cpp:218] Iteration 67300 (25.2803 iter/s, 3.95565s/100 iters), loss = 0.187902
I0630 23:49:20.536751  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:49:20.536751  7564 solver.cpp:237]     Train net output #1: loss = 0.187902 (* 1 = 0.187902 loss)
I0630 23:49:20.536751  7564 sgd_solver.cpp:105] Iteration 67300, lr = 1e-06
I0630 23:49:24.490073  7564 solver.cpp:218] Iteration 67400 (25.2989 iter/s, 3.95274s/100 iters), loss = 0.159995
I0630 23:49:24.490073  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:49:24.490073  7564 solver.cpp:237]     Train net output #1: loss = 0.159995 (* 1 = 0.159995 loss)
I0630 23:49:24.490073  7564 sgd_solver.cpp:105] Iteration 67400, lr = 1e-06
I0630 23:49:28.249238  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:49:28.404348  7564 solver.cpp:330] Iteration 67500, Testing net (#0)
I0630 23:49:28.404348  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:49:29.294493  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:49:29.329507  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8721
I0630 23:49:29.329507  7564 solver.cpp:397]     Test net output #1: loss = 0.427242 (* 1 = 0.427242 loss)
I0630 23:49:29.366034  7564 solver.cpp:218] Iteration 67500 (20.5092 iter/s, 4.87586s/100 iters), loss = 0.120837
I0630 23:49:29.366533  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:49:29.366533  7564 solver.cpp:237]     Train net output #1: loss = 0.120837 (* 1 = 0.120837 loss)
I0630 23:49:29.366533  7564 sgd_solver.cpp:105] Iteration 67500, lr = 1e-06
I0630 23:49:33.314342  7564 solver.cpp:218] Iteration 67600 (25.331 iter/s, 3.94773s/100 iters), loss = 0.164603
I0630 23:49:33.314342  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:49:33.314342  7564 solver.cpp:237]     Train net output #1: loss = 0.164603 (* 1 = 0.164603 loss)
I0630 23:49:33.314342  7564 sgd_solver.cpp:105] Iteration 67600, lr = 1e-06
I0630 23:49:37.260665  7564 solver.cpp:218] Iteration 67700 (25.3419 iter/s, 3.94604s/100 iters), loss = 0.16747
I0630 23:49:37.260665  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:49:37.260665  7564 solver.cpp:237]     Train net output #1: loss = 0.16747 (* 1 = 0.16747 loss)
I0630 23:49:37.260665  7564 sgd_solver.cpp:105] Iteration 67700, lr = 1e-06
I0630 23:49:41.208515  7564 solver.cpp:218] Iteration 67800 (25.3331 iter/s, 3.9474s/100 iters), loss = 0.13839
I0630 23:49:41.208515  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:49:41.208515  7564 solver.cpp:237]     Train net output #1: loss = 0.13839 (* 1 = 0.13839 loss)
I0630 23:49:41.208515  7564 sgd_solver.cpp:105] Iteration 67800, lr = 1e-06
I0630 23:49:45.152348  7564 solver.cpp:218] Iteration 67900 (25.3603 iter/s, 3.94317s/100 iters), loss = 0.168343
I0630 23:49:45.152348  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:49:45.152348  7564 solver.cpp:237]     Train net output #1: loss = 0.168343 (* 1 = 0.168343 loss)
I0630 23:49:45.152348  7564 sgd_solver.cpp:105] Iteration 67900, lr = 1e-06
I0630 23:49:48.912511  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:49:49.066637  7564 solver.cpp:330] Iteration 68000, Testing net (#0)
I0630 23:49:49.066637  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:49:49.959771  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:49:49.993782  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I0630 23:49:49.993782  7564 solver.cpp:397]     Test net output #1: loss = 0.427258 (* 1 = 0.427258 loss)
I0630 23:49:50.031308  7564 solver.cpp:218] Iteration 68000 (20.4983 iter/s, 4.87845s/100 iters), loss = 0.137838
I0630 23:49:50.031308  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:49:50.031308  7564 solver.cpp:237]     Train net output #1: loss = 0.137838 (* 1 = 0.137838 loss)
I0630 23:49:50.031308  7564 sgd_solver.cpp:105] Iteration 68000, lr = 1e-06
I0630 23:49:53.985189  7564 solver.cpp:218] Iteration 68100 (25.2935 iter/s, 3.95359s/100 iters), loss = 0.0959268
I0630 23:49:53.985189  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:49:53.985189  7564 solver.cpp:237]     Train net output #1: loss = 0.0959268 (* 1 = 0.0959268 loss)
I0630 23:49:53.985189  7564 sgd_solver.cpp:105] Iteration 68100, lr = 1e-06
I0630 23:49:57.937516  7564 solver.cpp:218] Iteration 68200 (25.3031 iter/s, 3.95209s/100 iters), loss = 0.117876
I0630 23:49:57.937516  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:49:57.937516  7564 solver.cpp:237]     Train net output #1: loss = 0.117876 (* 1 = 0.117876 loss)
I0630 23:49:57.937516  7564 sgd_solver.cpp:105] Iteration 68200, lr = 1e-06
I0630 23:50:01.907343  7564 solver.cpp:218] Iteration 68300 (25.1914 iter/s, 3.96961s/100 iters), loss = 0.117991
I0630 23:50:01.907343  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:50:01.907343  7564 solver.cpp:237]     Train net output #1: loss = 0.117991 (* 1 = 0.117991 loss)
I0630 23:50:01.907343  7564 sgd_solver.cpp:105] Iteration 68300, lr = 1e-06
I0630 23:50:05.857156  7564 solver.cpp:218] Iteration 68400 (25.3196 iter/s, 3.94951s/100 iters), loss = 0.223747
I0630 23:50:05.857656  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:50:05.857656  7564 solver.cpp:237]     Train net output #1: loss = 0.223747 (* 1 = 0.223747 loss)
I0630 23:50:05.857656  7564 sgd_solver.cpp:105] Iteration 68400, lr = 1e-06
I0630 23:50:09.615381  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:50:09.770493  7564 solver.cpp:330] Iteration 68500, Testing net (#0)
I0630 23:50:09.770493  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:50:10.661640  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:50:10.695665  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8724
I0630 23:50:10.695665  7564 solver.cpp:397]     Test net output #1: loss = 0.42752 (* 1 = 0.42752 loss)
I0630 23:50:10.733677  7564 solver.cpp:218] Iteration 68500 (20.5093 iter/s, 4.87583s/100 iters), loss = 0.137486
I0630 23:50:10.733677  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:50:10.733677  7564 solver.cpp:237]     Train net output #1: loss = 0.137486 (* 1 = 0.137486 loss)
I0630 23:50:10.733677  7564 sgd_solver.cpp:105] Iteration 68500, lr = 1e-06
I0630 23:50:14.685042  7564 solver.cpp:218] Iteration 68600 (25.3108 iter/s, 3.95088s/100 iters), loss = 0.110287
I0630 23:50:14.685042  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:50:14.685042  7564 solver.cpp:237]     Train net output #1: loss = 0.110287 (* 1 = 0.110287 loss)
I0630 23:50:14.685042  7564 sgd_solver.cpp:105] Iteration 68600, lr = 1e-06
I0630 23:50:18.643462  7564 solver.cpp:218] Iteration 68700 (25.2641 iter/s, 3.95818s/100 iters), loss = 0.110698
I0630 23:50:18.643462  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:50:18.643462  7564 solver.cpp:237]     Train net output #1: loss = 0.110698 (* 1 = 0.110698 loss)
I0630 23:50:18.643462  7564 sgd_solver.cpp:105] Iteration 68700, lr = 1e-06
I0630 23:50:22.594274  7564 solver.cpp:218] Iteration 68800 (25.3133 iter/s, 3.95049s/100 iters), loss = 0.117962
I0630 23:50:22.594274  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 23:50:22.594274  7564 solver.cpp:237]     Train net output #1: loss = 0.117962 (* 1 = 0.117962 loss)
I0630 23:50:22.594274  7564 sgd_solver.cpp:105] Iteration 68800, lr = 1e-06
I0630 23:50:26.549927  7564 solver.cpp:218] Iteration 68900 (25.2836 iter/s, 3.95513s/100 iters), loss = 0.192184
I0630 23:50:26.549927  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:50:26.549927  7564 solver.cpp:237]     Train net output #1: loss = 0.192184 (* 1 = 0.192184 loss)
I0630 23:50:26.549927  7564 sgd_solver.cpp:105] Iteration 68900, lr = 1e-06
I0630 23:50:30.309651  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:50:30.464763  7564 solver.cpp:330] Iteration 69000, Testing net (#0)
I0630 23:50:30.464763  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:50:31.358408  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:50:31.393424  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8721
I0630 23:50:31.393424  7564 solver.cpp:397]     Test net output #1: loss = 0.427489 (* 1 = 0.427489 loss)
I0630 23:50:31.430459  7564 solver.cpp:218] Iteration 69000 (20.4915 iter/s, 4.88007s/100 iters), loss = 0.108142
I0630 23:50:31.430459  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:50:31.430459  7564 solver.cpp:237]     Train net output #1: loss = 0.108142 (* 1 = 0.108142 loss)
I0630 23:50:31.430459  7564 sgd_solver.cpp:105] Iteration 69000, lr = 1e-06
I0630 23:50:35.380270  7564 solver.cpp:218] Iteration 69100 (25.3197 iter/s, 3.9495s/100 iters), loss = 0.12985
I0630 23:50:35.380270  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:50:35.380270  7564 solver.cpp:237]     Train net output #1: loss = 0.12985 (* 1 = 0.12985 loss)
I0630 23:50:35.380270  7564 sgd_solver.cpp:105] Iteration 69100, lr = 1e-06
I0630 23:50:39.337821  7564 solver.cpp:218] Iteration 69200 (25.2705 iter/s, 3.95718s/100 iters), loss = 0.192889
I0630 23:50:39.337821  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 23:50:39.337821  7564 solver.cpp:237]     Train net output #1: loss = 0.192889 (* 1 = 0.192889 loss)
I0630 23:50:39.337821  7564 sgd_solver.cpp:105] Iteration 69200, lr = 1e-06
I0630 23:50:43.291617  7564 solver.cpp:218] Iteration 69300 (25.2963 iter/s, 3.95315s/100 iters), loss = 0.140742
I0630 23:50:43.291617  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:50:43.291617  7564 solver.cpp:237]     Train net output #1: loss = 0.140742 (* 1 = 0.140742 loss)
I0630 23:50:43.291617  7564 sgd_solver.cpp:105] Iteration 69300, lr = 1e-06
I0630 23:50:47.242486  7564 solver.cpp:218] Iteration 69400 (25.3119 iter/s, 3.95071s/100 iters), loss = 0.168381
I0630 23:50:47.242486  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 23:50:47.242486  7564 solver.cpp:237]     Train net output #1: loss = 0.168381 (* 1 = 0.168381 loss)
I0630 23:50:47.242486  7564 sgd_solver.cpp:105] Iteration 69400, lr = 1e-06
I0630 23:50:51.003679  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:50:51.158288  7564 solver.cpp:330] Iteration 69500, Testing net (#0)
I0630 23:50:51.158288  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:50:52.046941  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:50:52.080966  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8717
I0630 23:50:52.080966  7564 solver.cpp:397]     Test net output #1: loss = 0.427184 (* 1 = 0.427184 loss)
I0630 23:50:52.118002  7564 solver.cpp:218] Iteration 69500 (20.5131 iter/s, 4.87494s/100 iters), loss = 0.0949859
I0630 23:50:52.118002  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 23:50:52.118002  7564 solver.cpp:237]     Train net output #1: loss = 0.0949858 (* 1 = 0.0949858 loss)
I0630 23:50:52.118002  7564 sgd_solver.cpp:105] Iteration 69500, lr = 1e-06
I0630 23:50:56.070320  7564 solver.cpp:218] Iteration 69600 (25.3053 iter/s, 3.95175s/100 iters), loss = 0.131032
I0630 23:50:56.070320  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 23:50:56.070320  7564 solver.cpp:237]     Train net output #1: loss = 0.131032 (* 1 = 0.131032 loss)
I0630 23:50:56.070320  7564 sgd_solver.cpp:105] Iteration 69600, lr = 1e-06
I0630 23:51:00.029121  7564 solver.cpp:218] Iteration 69700 (25.2619 iter/s, 3.95853s/100 iters), loss = 0.127704
I0630 23:51:00.029121  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 23:51:00.029121  7564 solver.cpp:237]     Train net output #1: loss = 0.127704 (* 1 = 0.127704 loss)
I0630 23:51:00.029121  7564 sgd_solver.cpp:105] Iteration 69700, lr = 1e-06
I0630 23:51:03.986421  7564 solver.cpp:218] Iteration 69800 (25.2706 iter/s, 3.95716s/100 iters), loss = 0.127784
I0630 23:51:03.986421  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 23:51:03.986421  7564 solver.cpp:237]     Train net output #1: loss = 0.127784 (* 1 = 0.127784 loss)
I0630 23:51:03.986421  7564 sgd_solver.cpp:105] Iteration 69800, lr = 1e-06
I0630 23:51:07.937263  7564 solver.cpp:218] Iteration 69900 (25.3146 iter/s, 3.95029s/100 iters), loss = 0.22064
I0630 23:51:07.937263  7564 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 23:51:07.937263  7564 solver.cpp:237]     Train net output #1: loss = 0.22064 (* 1 = 0.22064 loss)
I0630 23:51:07.937263  7564 sgd_solver.cpp:105] Iteration 69900, lr = 1e-06
I0630 23:51:11.686430  4252 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:51:11.840538  7564 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/128K_iter_70000.caffemodel
I0630 23:51:11.872642  7564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/128K_iter_70000.solverstate
I0630 23:51:11.884150  7564 solver.cpp:310] Iteration 70000, loss = 0.109454
I0630 23:51:11.884150  7564 solver.cpp:330] Iteration 70000, Testing net (#0)
I0630 23:51:11.884650  7564 net.cpp:676] Ignoring source layer accuracy_training
I0630 23:51:12.773783  9248 data_layer.cpp:73] Restarting data prefetching from start.
I0630 23:51:12.807808  7564 solver.cpp:397]     Test net output #0: accuracy = 0.8729
I0630 23:51:12.807808  7564 solver.cpp:397]     Test net output #1: loss = 0.426867 (* 1 = 0.426867 loss)
I0630 23:51:12.807808  7564 solver.cpp:315] Optimization Done.
I0630 23:51:12.807808  7564 caffe.cpp:260] Optimization Done.
G:\Caffe>