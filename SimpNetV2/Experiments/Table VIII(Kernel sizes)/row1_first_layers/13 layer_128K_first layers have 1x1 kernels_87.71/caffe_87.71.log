
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0630 20:12:12.860105  4668 caffe.cpp:219] Using GPUs 0
I0630 20:12:13.040666  4668 caffe.cpp:224] GPU 0: GeForce GTX 1080
I0630 20:12:13.359079  4668 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0630 20:12:13.369079  4668 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 70000
snapshot_prefix: "examples/cifar10/128K"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 22000
stepvalue: 38000
stepvalue: 44000
stepvalue: 64000
type: "Nesterov"
I0630 20:12:13.369079  4668 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0630 20:12:13.369079  4668 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0630 20:12:13.369079  4668 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp4
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp5
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp6
I0630 20:12:13.369079  4668 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0630 20:12:13.369079  4668 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_13_128k_first_1x1"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 20
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_12"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_12"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 37
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "conv4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp4"
  type: "Scale"
  bottom: "cccp4"
  top: "cccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 49
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp5"
  type: "Scale"
  bottom: "cccp5"
  top: "cccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "cccp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 50
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp6"
  type: "Scale"
  bottom: "cccp6"
  top: "cccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0630 20:12:13.369079  4668 layer_factory.cpp:58] Creating layer cifar
I0630 20:12:13.401542  4668 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I0630 20:12:13.401542  4668 net.cpp:84] Creating Layer cifar
I0630 20:12:13.401542  4668 net.cpp:380] cifar -> data
I0630 20:12:13.401542  4668 net.cpp:380] cifar -> label
I0630 20:12:13.401542  4668 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0630 20:12:13.401542  4668 data_layer.cpp:45] output data size: 100,3,32,32
I0630 20:12:13.411571  4668 net.cpp:122] Setting up cifar
I0630 20:12:13.411571  4668 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0630 20:12:13.411571  4668 net.cpp:129] Top shape: 100 (100)
I0630 20:12:13.411571  4668 net.cpp:137] Memory required for data: 1229200
I0630 20:12:13.411571  4668 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0630 20:12:13.411571  4668 net.cpp:84] Creating Layer label_cifar_1_split
I0630 20:12:13.411571  4668 net.cpp:406] label_cifar_1_split <- label
I0630 20:12:13.411571  4668 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0630 20:12:13.411571  4668 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0630 20:12:13.411571  4668 net.cpp:122] Setting up label_cifar_1_split
I0630 20:12:13.411571  4668 net.cpp:129] Top shape: 100 (100)
I0630 20:12:13.411571  4668 net.cpp:129] Top shape: 100 (100)
I0630 20:12:13.411571  4668 net.cpp:137] Memory required for data: 1230000
I0630 20:12:13.411571  4668 layer_factory.cpp:58] Creating layer conv1
I0630 20:12:13.411571  4668 net.cpp:84] Creating Layer conv1
I0630 20:12:13.411571  4668 net.cpp:406] conv1 <- data
I0630 20:12:13.411571  4668 net.cpp:380] conv1 -> conv1
I0630 20:12:13.411571 16944 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0630 20:12:13.642262  4668 net.cpp:122] Setting up conv1
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 20 32 32 (2048000)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 9422000
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer bn1
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer bn1
I0630 20:12:13.642262  4668 net.cpp:406] bn1 <- conv1
I0630 20:12:13.642262  4668 net.cpp:367] bn1 -> conv1 (in-place)
I0630 20:12:13.642262  4668 net.cpp:122] Setting up bn1
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 20 32 32 (2048000)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 17614000
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer scale1
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer scale1
I0630 20:12:13.642262  4668 net.cpp:406] scale1 <- conv1
I0630 20:12:13.642262  4668 net.cpp:367] scale1 -> conv1 (in-place)
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer scale1
I0630 20:12:13.642262  4668 net.cpp:122] Setting up scale1
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 20 32 32 (2048000)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 25806000
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer relu1
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer relu1
I0630 20:12:13.642262  4668 net.cpp:406] relu1 <- conv1
I0630 20:12:13.642262  4668 net.cpp:367] relu1 -> conv1 (in-place)
I0630 20:12:13.642262  4668 net.cpp:122] Setting up relu1
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 20 32 32 (2048000)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 33998000
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer conv1_0
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer conv1_0
I0630 20:12:13.642262  4668 net.cpp:406] conv1_0 <- conv1
I0630 20:12:13.642262  4668 net.cpp:380] conv1_0 -> conv1_0
I0630 20:12:13.642262  4668 net.cpp:122] Setting up conv1_0
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 47105200
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer bn1_0
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer bn1_0
I0630 20:12:13.642262  4668 net.cpp:406] bn1_0 <- conv1_0
I0630 20:12:13.642262  4668 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0630 20:12:13.642262  4668 net.cpp:122] Setting up bn1_0
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 60212400
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer scale1_0
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer scale1_0
I0630 20:12:13.642262  4668 net.cpp:406] scale1_0 <- conv1_0
I0630 20:12:13.642262  4668 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer scale1_0
I0630 20:12:13.642262  4668 net.cpp:122] Setting up scale1_0
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 73319600
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer relu1_0
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer relu1_0
I0630 20:12:13.642262  4668 net.cpp:406] relu1_0 <- conv1_0
I0630 20:12:13.642262  4668 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0630 20:12:13.642262  4668 net.cpp:122] Setting up relu1_0
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 86426800
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer conv2
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer conv2
I0630 20:12:13.642262  4668 net.cpp:406] conv2 <- conv1_0
I0630 20:12:13.642262  4668 net.cpp:380] conv2 -> conv2
I0630 20:12:13.642262  4668 net.cpp:122] Setting up conv2
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 99534000
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer bn2
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer bn2
I0630 20:12:13.642262  4668 net.cpp:406] bn2 <- conv2
I0630 20:12:13.642262  4668 net.cpp:367] bn2 -> conv2 (in-place)
I0630 20:12:13.642262  4668 net.cpp:122] Setting up bn2
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 112641200
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer scale2
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer scale2
I0630 20:12:13.642262  4668 net.cpp:406] scale2 <- conv2
I0630 20:12:13.642262  4668 net.cpp:367] scale2 -> conv2 (in-place)
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer scale2
I0630 20:12:13.642262  4668 net.cpp:122] Setting up scale2
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 125748400
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer relu2
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer relu2
I0630 20:12:13.642262  4668 net.cpp:406] relu2 <- conv2
I0630 20:12:13.642262  4668 net.cpp:367] relu2 -> conv2 (in-place)
I0630 20:12:13.642262  4668 net.cpp:122] Setting up relu2
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 138855600
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer conv2_1
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer conv2_1
I0630 20:12:13.642262  4668 net.cpp:406] conv2_1 <- conv2
I0630 20:12:13.642262  4668 net.cpp:380] conv2_1 -> conv2_1
I0630 20:12:13.642262  4668 net.cpp:122] Setting up conv2_1
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 151962800
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer bn2_1
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer bn2_1
I0630 20:12:13.642262  4668 net.cpp:406] bn2_1 <- conv2_1
I0630 20:12:13.642262  4668 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0630 20:12:13.642262  4668 net.cpp:122] Setting up bn2_1
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 165070000
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer scale2_1
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer scale2_1
I0630 20:12:13.642262  4668 net.cpp:406] scale2_1 <- conv2_1
I0630 20:12:13.642262  4668 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer scale2_1
I0630 20:12:13.642262  4668 net.cpp:122] Setting up scale2_1
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 178177200
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer relu2_1
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer relu2_1
I0630 20:12:13.642262  4668 net.cpp:406] relu2_1 <- conv2_1
I0630 20:12:13.642262  4668 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0630 20:12:13.642262  4668 net.cpp:122] Setting up relu2_1
I0630 20:12:13.642262  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.642262  4668 net.cpp:137] Memory required for data: 191284400
I0630 20:12:13.642262  4668 layer_factory.cpp:58] Creating layer conv2_2
I0630 20:12:13.642262  4668 net.cpp:84] Creating Layer conv2_2
I0630 20:12:13.642262  4668 net.cpp:406] conv2_2 <- conv2_1
I0630 20:12:13.642262  4668 net.cpp:380] conv2_2 -> conv2_2
I0630 20:12:13.652281  4668 net.cpp:122] Setting up conv2_2
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 204391600
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer bn2_2
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer bn2_2
I0630 20:12:13.652281  4668 net.cpp:406] bn2_2 <- conv2_2
I0630 20:12:13.652281  4668 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up bn2_2
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 217498800
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale2_2
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer scale2_2
I0630 20:12:13.652281  4668 net.cpp:406] scale2_2 <- conv2_2
I0630 20:12:13.652281  4668 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale2_2
I0630 20:12:13.652281  4668 net.cpp:122] Setting up scale2_2
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 230606000
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer relu2_2
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer relu2_2
I0630 20:12:13.652281  4668 net.cpp:406] relu2_2 <- conv2_2
I0630 20:12:13.652281  4668 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up relu2_2
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 243713200
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer pool2_1
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer pool2_1
I0630 20:12:13.652281  4668 net.cpp:406] pool2_1 <- conv2_2
I0630 20:12:13.652281  4668 net.cpp:380] pool2_1 -> pool2_1
I0630 20:12:13.652281  4668 net.cpp:122] Setting up pool2_1
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 246990000
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer conv3
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer conv3
I0630 20:12:13.652281  4668 net.cpp:406] conv3 <- pool2_1
I0630 20:12:13.652281  4668 net.cpp:380] conv3 -> conv3
I0630 20:12:13.652281  4668 net.cpp:122] Setting up conv3
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 250266800
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer bn3
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer bn3
I0630 20:12:13.652281  4668 net.cpp:406] bn3 <- conv3
I0630 20:12:13.652281  4668 net.cpp:367] bn3 -> conv3 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up bn3
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 253543600
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale3
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer scale3
I0630 20:12:13.652281  4668 net.cpp:406] scale3 <- conv3
I0630 20:12:13.652281  4668 net.cpp:367] scale3 -> conv3 (in-place)
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale3
I0630 20:12:13.652281  4668 net.cpp:122] Setting up scale3
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 256820400
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer relu3
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer relu3
I0630 20:12:13.652281  4668 net.cpp:406] relu3 <- conv3
I0630 20:12:13.652281  4668 net.cpp:367] relu3 -> conv3 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up relu3
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 260097200
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer conv4
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer conv4
I0630 20:12:13.652281  4668 net.cpp:406] conv4 <- conv3
I0630 20:12:13.652281  4668 net.cpp:380] conv4 -> conv4
I0630 20:12:13.652281  4668 net.cpp:122] Setting up conv4
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 263374000
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer bn4
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer bn4
I0630 20:12:13.652281  4668 net.cpp:406] bn4 <- conv4
I0630 20:12:13.652281  4668 net.cpp:367] bn4 -> conv4 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up bn4
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 266650800
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale4
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer scale4
I0630 20:12:13.652281  4668 net.cpp:406] scale4 <- conv4
I0630 20:12:13.652281  4668 net.cpp:367] scale4 -> conv4 (in-place)
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale4
I0630 20:12:13.652281  4668 net.cpp:122] Setting up scale4
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 269927600
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer relu4
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer relu4
I0630 20:12:13.652281  4668 net.cpp:406] relu4 <- conv4
I0630 20:12:13.652281  4668 net.cpp:367] relu4 -> conv4 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up relu4
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 273204400
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer conv4_1
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer conv4_1
I0630 20:12:13.652281  4668 net.cpp:406] conv4_1 <- conv4
I0630 20:12:13.652281  4668 net.cpp:380] conv4_1 -> conv4_1
I0630 20:12:13.652281  4668 net.cpp:122] Setting up conv4_1
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 276481200
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer bn4_1
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer bn4_1
I0630 20:12:13.652281  4668 net.cpp:406] bn4_1 <- conv4_1
I0630 20:12:13.652281  4668 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up bn4_1
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 279758000
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale4_1
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer scale4_1
I0630 20:12:13.652281  4668 net.cpp:406] scale4_1 <- conv4_1
I0630 20:12:13.652281  4668 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale4_1
I0630 20:12:13.652281  4668 net.cpp:122] Setting up scale4_1
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 283034800
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer relu4_1
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer relu4_1
I0630 20:12:13.652281  4668 net.cpp:406] relu4_1 <- conv4_1
I0630 20:12:13.652281  4668 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up relu4_1
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 286311600
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer conv4_2
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer conv4_2
I0630 20:12:13.652281  4668 net.cpp:406] conv4_2 <- conv4_1
I0630 20:12:13.652281  4668 net.cpp:380] conv4_2 -> conv4_2
I0630 20:12:13.652281  4668 net.cpp:122] Setting up conv4_2
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 289588400
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer bn4_2
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer bn4_2
I0630 20:12:13.652281  4668 net.cpp:406] bn4_2 <- conv4_2
I0630 20:12:13.652281  4668 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up bn4_2
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 292865200
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale4_2
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer scale4_2
I0630 20:12:13.652281  4668 net.cpp:406] scale4_2 <- conv4_2
I0630 20:12:13.652281  4668 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale4_2
I0630 20:12:13.652281  4668 net.cpp:122] Setting up scale4_2
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 296142000
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer relu4_2
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer relu4_2
I0630 20:12:13.652281  4668 net.cpp:406] relu4_2 <- conv4_2
I0630 20:12:13.652281  4668 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up relu4_2
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 299418800
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer pool4_12
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer pool4_12
I0630 20:12:13.652281  4668 net.cpp:406] pool4_12 <- conv4_2
I0630 20:12:13.652281  4668 net.cpp:380] pool4_12 -> pool4_12
I0630 20:12:13.652281  4668 net.cpp:122] Setting up pool4_12
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 32 8 8 (204800)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 300238000
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer conv4_0
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer conv4_0
I0630 20:12:13.652281  4668 net.cpp:406] conv4_0 <- pool4_12
I0630 20:12:13.652281  4668 net.cpp:380] conv4_0 -> conv4_0
I0630 20:12:13.652281  4668 net.cpp:122] Setting up conv4_0
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 301185200
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer bn4_0
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer bn4_0
I0630 20:12:13.652281  4668 net.cpp:406] bn4_0 <- conv4_0
I0630 20:12:13.652281  4668 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up bn4_0
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 302132400
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale4_0
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer scale4_0
I0630 20:12:13.652281  4668 net.cpp:406] scale4_0 <- conv4_0
I0630 20:12:13.652281  4668 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer scale4_0
I0630 20:12:13.652281  4668 net.cpp:122] Setting up scale4_0
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 303079600
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer relu4_0
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer relu4_0
I0630 20:12:13.652281  4668 net.cpp:406] relu4_0 <- conv4_0
I0630 20:12:13.652281  4668 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0630 20:12:13.652281  4668 net.cpp:122] Setting up relu4_0
I0630 20:12:13.652281  4668 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 20:12:13.652281  4668 net.cpp:137] Memory required for data: 304026800
I0630 20:12:13.652281  4668 layer_factory.cpp:58] Creating layer cccp4
I0630 20:12:13.652281  4668 net.cpp:84] Creating Layer cccp4
I0630 20:12:13.652281  4668 net.cpp:406] cccp4 <- conv4_0
I0630 20:12:13.652281  4668 net.cpp:380] cccp4 -> cccp4
I0630 20:12:13.662263  4668 net.cpp:122] Setting up cccp4
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 305255600
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer bn_cccp4
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer bn_cccp4
I0630 20:12:13.662263  4668 net.cpp:406] bn_cccp4 <- cccp4
I0630 20:12:13.662263  4668 net.cpp:367] bn_cccp4 -> cccp4 (in-place)
I0630 20:12:13.662263  4668 net.cpp:122] Setting up bn_cccp4
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 306484400
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer scale_cccp4
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer scale_cccp4
I0630 20:12:13.662263  4668 net.cpp:406] scale_cccp4 <- cccp4
I0630 20:12:13.662263  4668 net.cpp:367] scale_cccp4 -> cccp4 (in-place)
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer scale_cccp4
I0630 20:12:13.662263  4668 net.cpp:122] Setting up scale_cccp4
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 307713200
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer relu_cccp4
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer relu_cccp4
I0630 20:12:13.662263  4668 net.cpp:406] relu_cccp4 <- cccp4
I0630 20:12:13.662263  4668 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0630 20:12:13.662263  4668 net.cpp:122] Setting up relu_cccp4
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 308942000
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer cccp5
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer cccp5
I0630 20:12:13.662263  4668 net.cpp:406] cccp5 <- cccp4
I0630 20:12:13.662263  4668 net.cpp:380] cccp5 -> cccp5
I0630 20:12:13.662263  4668 net.cpp:122] Setting up cccp5
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 310196400
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer bn_cccp5
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer bn_cccp5
I0630 20:12:13.662263  4668 net.cpp:406] bn_cccp5 <- cccp5
I0630 20:12:13.662263  4668 net.cpp:367] bn_cccp5 -> cccp5 (in-place)
I0630 20:12:13.662263  4668 net.cpp:122] Setting up bn_cccp5
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 311450800
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer scale_cccp5
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer scale_cccp5
I0630 20:12:13.662263  4668 net.cpp:406] scale_cccp5 <- cccp5
I0630 20:12:13.662263  4668 net.cpp:367] scale_cccp5 -> cccp5 (in-place)
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer scale_cccp5
I0630 20:12:13.662263  4668 net.cpp:122] Setting up scale_cccp5
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 312705200
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer relu_cccp5
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer relu_cccp5
I0630 20:12:13.662263  4668 net.cpp:406] relu_cccp5 <- cccp5
I0630 20:12:13.662263  4668 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0630 20:12:13.662263  4668 net.cpp:122] Setting up relu_cccp5
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 313959600
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer cccp6
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer cccp6
I0630 20:12:13.662263  4668 net.cpp:406] cccp6 <- cccp5
I0630 20:12:13.662263  4668 net.cpp:380] cccp6 -> cccp6
I0630 20:12:13.662263  4668 net.cpp:122] Setting up cccp6
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 315239600
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer bn_cccp6
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer bn_cccp6
I0630 20:12:13.662263  4668 net.cpp:406] bn_cccp6 <- cccp6
I0630 20:12:13.662263  4668 net.cpp:367] bn_cccp6 -> cccp6 (in-place)
I0630 20:12:13.662263  4668 net.cpp:122] Setting up bn_cccp6
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 316519600
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer scale_cccp6
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer scale_cccp6
I0630 20:12:13.662263  4668 net.cpp:406] scale_cccp6 <- cccp6
I0630 20:12:13.662263  4668 net.cpp:367] scale_cccp6 -> cccp6 (in-place)
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer scale_cccp6
I0630 20:12:13.662263  4668 net.cpp:122] Setting up scale_cccp6
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 317799600
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer relu_cccp6
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer relu_cccp6
I0630 20:12:13.662263  4668 net.cpp:406] relu_cccp6 <- cccp6
I0630 20:12:13.662263  4668 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0630 20:12:13.662263  4668 net.cpp:122] Setting up relu_cccp6
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 319079600
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer poolcp6
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer poolcp6
I0630 20:12:13.662263  4668 net.cpp:406] poolcp6 <- cccp6
I0630 20:12:13.662263  4668 net.cpp:380] poolcp6 -> poolcp6
I0630 20:12:13.662263  4668 net.cpp:122] Setting up poolcp6
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 50 1 1 (5000)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 319099600
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer ip1
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer ip1
I0630 20:12:13.662263  4668 net.cpp:406] ip1 <- poolcp6
I0630 20:12:13.662263  4668 net.cpp:380] ip1 -> ip1
I0630 20:12:13.662263  4668 net.cpp:122] Setting up ip1
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 10 (1000)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 319103600
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer ip1_ip1_0_split
I0630 20:12:13.662263  4668 net.cpp:406] ip1_ip1_0_split <- ip1
I0630 20:12:13.662263  4668 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0630 20:12:13.662263  4668 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0630 20:12:13.662263  4668 net.cpp:122] Setting up ip1_ip1_0_split
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 10 (1000)
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: 100 10 (1000)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 319111600
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer accuracy_training
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer accuracy_training
I0630 20:12:13.662263  4668 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0630 20:12:13.662263  4668 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I0630 20:12:13.662263  4668 net.cpp:380] accuracy_training -> accuracy_training
I0630 20:12:13.662263  4668 net.cpp:122] Setting up accuracy_training
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: (1)
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 319111604
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer loss
I0630 20:12:13.662263  4668 net.cpp:84] Creating Layer loss
I0630 20:12:13.662263  4668 net.cpp:406] loss <- ip1_ip1_0_split_1
I0630 20:12:13.662263  4668 net.cpp:406] loss <- label_cifar_1_split_1
I0630 20:12:13.662263  4668 net.cpp:380] loss -> loss
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer loss
I0630 20:12:13.662263  4668 net.cpp:122] Setting up loss
I0630 20:12:13.662263  4668 net.cpp:129] Top shape: (1)
I0630 20:12:13.662263  4668 net.cpp:132]     with loss weight 1
I0630 20:12:13.662263  4668 net.cpp:137] Memory required for data: 319111608
I0630 20:12:13.662263  4668 net.cpp:198] loss needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:200] accuracy_training does not need backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] ip1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] poolcp6 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu_cccp6 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale_cccp6 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn_cccp6 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] cccp6 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu_cccp5 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale_cccp5 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn_cccp5 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] cccp5 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu_cccp4 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale_cccp4 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn_cccp4 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] cccp4 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu4_0 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale4_0 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn4_0 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] conv4_0 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] pool4_12 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu4_2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale4_2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn4_2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] conv4_2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu4_1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale4_1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn4_1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] conv4_1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu4 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale4 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn4 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] conv4 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu3 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale3 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn3 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] conv3 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] pool2_1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu2_2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale2_2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn2_2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] conv2_2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu2_1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale2_1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn2_1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] conv2_1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] conv2 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu1_0 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale1_0 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn1_0 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] conv1_0 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] relu1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] scale1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] bn1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:198] conv1 needs backward computation.
I0630 20:12:13.662263  4668 net.cpp:200] label_cifar_1_split does not need backward computation.
I0630 20:12:13.662263  4668 net.cpp:200] cifar does not need backward computation.
I0630 20:12:13.662263  4668 net.cpp:242] This network produces output accuracy_training
I0630 20:12:13.662263  4668 net.cpp:242] This network produces output loss
I0630 20:12:13.662263  4668 net.cpp:255] Network initialization done.
I0630 20:12:13.662263  4668 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0630 20:12:13.662263  4668 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0630 20:12:13.662263  4668 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp4
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp5
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp6
I0630 20:12:13.662263  4668 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0630 20:12:13.662263  4668 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_13_128k_first_1x1"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 20
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_12"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_12"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 37
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "conv4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp4"
  type: "Scale"
  bottom: "cccp4"
  top: "cccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 49
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp5"
  type: "Scale"
  bottom: "cccp5"
  top: "cccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "cccp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 50
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp6"
  type: "Scale"
  bottom: "cccp6"
  top: "cccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0630 20:12:13.662263  4668 layer_factory.cpp:58] Creating layer cifar
I0630 20:12:13.672264  4668 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I0630 20:12:13.672264  4668 net.cpp:84] Creating Layer cifar
I0630 20:12:13.672264  4668 net.cpp:380] cifar -> data
I0630 20:12:13.672264  4668 net.cpp:380] cifar -> label
I0630 20:12:13.672264  4668 data_layer.cpp:45] output data size: 100,3,32,32
I0630 20:12:13.672264  4668 net.cpp:122] Setting up cifar
I0630 20:12:13.672264  4668 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0630 20:12:13.672264  4668 net.cpp:129] Top shape: 100 (100)
I0630 20:12:13.672264  4668 net.cpp:137] Memory required for data: 1229200
I0630 20:12:13.672264  4668 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0630 20:12:13.672264  4668 net.cpp:84] Creating Layer label_cifar_1_split
I0630 20:12:13.672264  4668 net.cpp:406] label_cifar_1_split <- label
I0630 20:12:13.672264  4668 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0630 20:12:13.672264  4668 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0630 20:12:13.672264  4668 net.cpp:122] Setting up label_cifar_1_split
I0630 20:12:13.672264  4668 net.cpp:129] Top shape: 100 (100)
I0630 20:12:13.672264  4668 net.cpp:129] Top shape: 100 (100)
I0630 20:12:13.672264  4668 net.cpp:137] Memory required for data: 1230000
I0630 20:12:13.672264  4668 layer_factory.cpp:58] Creating layer conv1
I0630 20:12:13.672264  4668 net.cpp:84] Creating Layer conv1
I0630 20:12:13.672264  4668 net.cpp:406] conv1 <- data
I0630 20:12:13.672264  4668 net.cpp:380] conv1 -> conv1
I0630 20:12:13.672264  9172 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0630 20:12:13.672264  4668 net.cpp:122] Setting up conv1
I0630 20:12:13.672264  4668 net.cpp:129] Top shape: 100 20 32 32 (2048000)
I0630 20:12:13.672264  4668 net.cpp:137] Memory required for data: 9422000
I0630 20:12:13.672264  4668 layer_factory.cpp:58] Creating layer bn1
I0630 20:12:13.672264  4668 net.cpp:84] Creating Layer bn1
I0630 20:12:13.672264  4668 net.cpp:406] bn1 <- conv1
I0630 20:12:13.672264  4668 net.cpp:367] bn1 -> conv1 (in-place)
I0630 20:12:13.672264  4668 net.cpp:122] Setting up bn1
I0630 20:12:13.672264  4668 net.cpp:129] Top shape: 100 20 32 32 (2048000)
I0630 20:12:13.672264  4668 net.cpp:137] Memory required for data: 17614000
I0630 20:12:13.672264  4668 layer_factory.cpp:58] Creating layer scale1
I0630 20:12:13.672264  4668 net.cpp:84] Creating Layer scale1
I0630 20:12:13.672264  4668 net.cpp:406] scale1 <- conv1
I0630 20:12:13.672264  4668 net.cpp:367] scale1 -> conv1 (in-place)
I0630 20:12:13.672264  4668 layer_factory.cpp:58] Creating layer scale1
I0630 20:12:13.672264  4668 net.cpp:122] Setting up scale1
I0630 20:12:13.672264  4668 net.cpp:129] Top shape: 100 20 32 32 (2048000)
I0630 20:12:13.672264  4668 net.cpp:137] Memory required for data: 25806000
I0630 20:12:13.672264  4668 layer_factory.cpp:58] Creating layer relu1
I0630 20:12:13.672264  4668 net.cpp:84] Creating Layer relu1
I0630 20:12:13.672264  4668 net.cpp:406] relu1 <- conv1
I0630 20:12:13.672264  4668 net.cpp:367] relu1 -> conv1 (in-place)
I0630 20:12:13.682446  4668 net.cpp:122] Setting up relu1
I0630 20:12:13.682446  4668 net.cpp:129] Top shape: 100 20 32 32 (2048000)
I0630 20:12:13.682446  4668 net.cpp:137] Memory required for data: 33998000
I0630 20:12:13.682446  4668 layer_factory.cpp:58] Creating layer conv1_0
I0630 20:12:13.682446  4668 net.cpp:84] Creating Layer conv1_0
I0630 20:12:13.682446  4668 net.cpp:406] conv1_0 <- conv1
I0630 20:12:13.682446  4668 net.cpp:380] conv1_0 -> conv1_0
I0630 20:12:13.684437  4668 net.cpp:122] Setting up conv1_0
I0630 20:12:13.684437  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.684437  4668 net.cpp:137] Memory required for data: 47105200
I0630 20:12:13.684437  4668 layer_factory.cpp:58] Creating layer bn1_0
I0630 20:12:13.684437  4668 net.cpp:84] Creating Layer bn1_0
I0630 20:12:13.684437  4668 net.cpp:406] bn1_0 <- conv1_0
I0630 20:12:13.684437  4668 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0630 20:12:13.684437  4668 net.cpp:122] Setting up bn1_0
I0630 20:12:13.684437  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.684437  4668 net.cpp:137] Memory required for data: 60212400
I0630 20:12:13.684437  4668 layer_factory.cpp:58] Creating layer scale1_0
I0630 20:12:13.684437  4668 net.cpp:84] Creating Layer scale1_0
I0630 20:12:13.684437  4668 net.cpp:406] scale1_0 <- conv1_0
I0630 20:12:13.684437  4668 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0630 20:12:13.684437  4668 layer_factory.cpp:58] Creating layer scale1_0
I0630 20:12:13.684437  4668 net.cpp:122] Setting up scale1_0
I0630 20:12:13.684437  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.684437  4668 net.cpp:137] Memory required for data: 73319600
I0630 20:12:13.684437  4668 layer_factory.cpp:58] Creating layer relu1_0
I0630 20:12:13.684437  4668 net.cpp:84] Creating Layer relu1_0
I0630 20:12:13.684437  4668 net.cpp:406] relu1_0 <- conv1_0
I0630 20:12:13.684437  4668 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0630 20:12:13.685437  4668 net.cpp:122] Setting up relu1_0
I0630 20:12:13.685437  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.685437  4668 net.cpp:137] Memory required for data: 86426800
I0630 20:12:13.685437  4668 layer_factory.cpp:58] Creating layer conv2
I0630 20:12:13.685437  4668 net.cpp:84] Creating Layer conv2
I0630 20:12:13.685437  4668 net.cpp:406] conv2 <- conv1_0
I0630 20:12:13.685437  4668 net.cpp:380] conv2 -> conv2
I0630 20:12:13.686944  4668 net.cpp:122] Setting up conv2
I0630 20:12:13.686944  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.686944  4668 net.cpp:137] Memory required for data: 99534000
I0630 20:12:13.686944  4668 layer_factory.cpp:58] Creating layer bn2
I0630 20:12:13.686944  4668 net.cpp:84] Creating Layer bn2
I0630 20:12:13.686944  4668 net.cpp:406] bn2 <- conv2
I0630 20:12:13.686944  4668 net.cpp:367] bn2 -> conv2 (in-place)
I0630 20:12:13.687444  4668 net.cpp:122] Setting up bn2
I0630 20:12:13.687444  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.687444  4668 net.cpp:137] Memory required for data: 112641200
I0630 20:12:13.687444  4668 layer_factory.cpp:58] Creating layer scale2
I0630 20:12:13.687444  4668 net.cpp:84] Creating Layer scale2
I0630 20:12:13.687444  4668 net.cpp:406] scale2 <- conv2
I0630 20:12:13.687444  4668 net.cpp:367] scale2 -> conv2 (in-place)
I0630 20:12:13.687444  4668 layer_factory.cpp:58] Creating layer scale2
I0630 20:12:13.687444  4668 net.cpp:122] Setting up scale2
I0630 20:12:13.687444  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.687444  4668 net.cpp:137] Memory required for data: 125748400
I0630 20:12:13.687444  4668 layer_factory.cpp:58] Creating layer relu2
I0630 20:12:13.687444  4668 net.cpp:84] Creating Layer relu2
I0630 20:12:13.687444  4668 net.cpp:406] relu2 <- conv2
I0630 20:12:13.687444  4668 net.cpp:367] relu2 -> conv2 (in-place)
I0630 20:12:13.687944  4668 net.cpp:122] Setting up relu2
I0630 20:12:13.687944  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.687944  4668 net.cpp:137] Memory required for data: 138855600
I0630 20:12:13.687944  4668 layer_factory.cpp:58] Creating layer conv2_1
I0630 20:12:13.687944  4668 net.cpp:84] Creating Layer conv2_1
I0630 20:12:13.687944  4668 net.cpp:406] conv2_1 <- conv2
I0630 20:12:13.687944  4668 net.cpp:380] conv2_1 -> conv2_1
I0630 20:12:13.689445  4668 net.cpp:122] Setting up conv2_1
I0630 20:12:13.689445  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.689445  4668 net.cpp:137] Memory required for data: 151962800
I0630 20:12:13.689445  4668 layer_factory.cpp:58] Creating layer bn2_1
I0630 20:12:13.689445  4668 net.cpp:84] Creating Layer bn2_1
I0630 20:12:13.689445  4668 net.cpp:406] bn2_1 <- conv2_1
I0630 20:12:13.689445  4668 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0630 20:12:13.689445  4668 net.cpp:122] Setting up bn2_1
I0630 20:12:13.689445  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.689445  4668 net.cpp:137] Memory required for data: 165070000
I0630 20:12:13.689945  4668 layer_factory.cpp:58] Creating layer scale2_1
I0630 20:12:13.689945  4668 net.cpp:84] Creating Layer scale2_1
I0630 20:12:13.689945  4668 net.cpp:406] scale2_1 <- conv2_1
I0630 20:12:13.689945  4668 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0630 20:12:13.689945  4668 layer_factory.cpp:58] Creating layer scale2_1
I0630 20:12:13.689945  4668 net.cpp:122] Setting up scale2_1
I0630 20:12:13.689945  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.689945  4668 net.cpp:137] Memory required for data: 178177200
I0630 20:12:13.689945  4668 layer_factory.cpp:58] Creating layer relu2_1
I0630 20:12:13.689945  4668 net.cpp:84] Creating Layer relu2_1
I0630 20:12:13.689945  4668 net.cpp:406] relu2_1 <- conv2_1
I0630 20:12:13.689945  4668 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0630 20:12:13.690446  4668 net.cpp:122] Setting up relu2_1
I0630 20:12:13.690446  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.690446  4668 net.cpp:137] Memory required for data: 191284400
I0630 20:12:13.690446  4668 layer_factory.cpp:58] Creating layer conv2_2
I0630 20:12:13.690446  4668 net.cpp:84] Creating Layer conv2_2
I0630 20:12:13.690446  4668 net.cpp:406] conv2_2 <- conv2_1
I0630 20:12:13.690446  4668 net.cpp:380] conv2_2 -> conv2_2
I0630 20:12:13.691947  4668 net.cpp:122] Setting up conv2_2
I0630 20:12:13.691947  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.691947  4668 net.cpp:137] Memory required for data: 204391600
I0630 20:12:13.691947  4668 layer_factory.cpp:58] Creating layer bn2_2
I0630 20:12:13.691947  4668 net.cpp:84] Creating Layer bn2_2
I0630 20:12:13.691947  4668 net.cpp:406] bn2_2 <- conv2_2
I0630 20:12:13.691947  4668 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0630 20:12:13.691947  4668 net.cpp:122] Setting up bn2_2
I0630 20:12:13.691947  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.691947  4668 net.cpp:137] Memory required for data: 217498800
I0630 20:12:13.691947  4668 layer_factory.cpp:58] Creating layer scale2_2
I0630 20:12:13.691947  4668 net.cpp:84] Creating Layer scale2_2
I0630 20:12:13.691947  4668 net.cpp:406] scale2_2 <- conv2_2
I0630 20:12:13.691947  4668 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0630 20:12:13.691947  4668 layer_factory.cpp:58] Creating layer scale2_2
I0630 20:12:13.691947  4668 net.cpp:122] Setting up scale2_2
I0630 20:12:13.691947  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.691947  4668 net.cpp:137] Memory required for data: 230606000
I0630 20:12:13.691947  4668 layer_factory.cpp:58] Creating layer relu2_2
I0630 20:12:13.691947  4668 net.cpp:84] Creating Layer relu2_2
I0630 20:12:13.691947  4668 net.cpp:406] relu2_2 <- conv2_2
I0630 20:12:13.691947  4668 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0630 20:12:13.692957  4668 net.cpp:122] Setting up relu2_2
I0630 20:12:13.692957  4668 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I0630 20:12:13.692957  4668 net.cpp:137] Memory required for data: 243713200
I0630 20:12:13.692957  4668 layer_factory.cpp:58] Creating layer pool2_1
I0630 20:12:13.692957  4668 net.cpp:84] Creating Layer pool2_1
I0630 20:12:13.692957  4668 net.cpp:406] pool2_1 <- conv2_2
I0630 20:12:13.692957  4668 net.cpp:380] pool2_1 -> pool2_1
I0630 20:12:13.692957  4668 net.cpp:122] Setting up pool2_1
I0630 20:12:13.692957  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.692957  4668 net.cpp:137] Memory required for data: 246990000
I0630 20:12:13.692957  4668 layer_factory.cpp:58] Creating layer conv3
I0630 20:12:13.692957  4668 net.cpp:84] Creating Layer conv3
I0630 20:12:13.692957  4668 net.cpp:406] conv3 <- pool2_1
I0630 20:12:13.692957  4668 net.cpp:380] conv3 -> conv3
I0630 20:12:13.694448  4668 net.cpp:122] Setting up conv3
I0630 20:12:13.694448  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.694448  4668 net.cpp:137] Memory required for data: 250266800
I0630 20:12:13.694448  4668 layer_factory.cpp:58] Creating layer bn3
I0630 20:12:13.694448  4668 net.cpp:84] Creating Layer bn3
I0630 20:12:13.694448  4668 net.cpp:406] bn3 <- conv3
I0630 20:12:13.694448  4668 net.cpp:367] bn3 -> conv3 (in-place)
I0630 20:12:13.694448  4668 net.cpp:122] Setting up bn3
I0630 20:12:13.694448  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.694448  4668 net.cpp:137] Memory required for data: 253543600
I0630 20:12:13.694448  4668 layer_factory.cpp:58] Creating layer scale3
I0630 20:12:13.694448  4668 net.cpp:84] Creating Layer scale3
I0630 20:12:13.694448  4668 net.cpp:406] scale3 <- conv3
I0630 20:12:13.694448  4668 net.cpp:367] scale3 -> conv3 (in-place)
I0630 20:12:13.694448  4668 layer_factory.cpp:58] Creating layer scale3
I0630 20:12:13.694448  4668 net.cpp:122] Setting up scale3
I0630 20:12:13.694448  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.694448  4668 net.cpp:137] Memory required for data: 256820400
I0630 20:12:13.694948  4668 layer_factory.cpp:58] Creating layer relu3
I0630 20:12:13.694948  4668 net.cpp:84] Creating Layer relu3
I0630 20:12:13.694948  4668 net.cpp:406] relu3 <- conv3
I0630 20:12:13.694948  4668 net.cpp:367] relu3 -> conv3 (in-place)
I0630 20:12:13.695449  4668 net.cpp:122] Setting up relu3
I0630 20:12:13.695449  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.695449  4668 net.cpp:137] Memory required for data: 260097200
I0630 20:12:13.695449  4668 layer_factory.cpp:58] Creating layer conv4
I0630 20:12:13.695449  4668 net.cpp:84] Creating Layer conv4
I0630 20:12:13.695449  4668 net.cpp:406] conv4 <- conv3
I0630 20:12:13.695449  4668 net.cpp:380] conv4 -> conv4
I0630 20:12:13.696450  4668 net.cpp:122] Setting up conv4
I0630 20:12:13.696450  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.696950  4668 net.cpp:137] Memory required for data: 263374000
I0630 20:12:13.696950  4668 layer_factory.cpp:58] Creating layer bn4
I0630 20:12:13.696950  4668 net.cpp:84] Creating Layer bn4
I0630 20:12:13.696950  4668 net.cpp:406] bn4 <- conv4
I0630 20:12:13.696950  4668 net.cpp:367] bn4 -> conv4 (in-place)
I0630 20:12:13.696950  4668 net.cpp:122] Setting up bn4
I0630 20:12:13.696950  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.696950  4668 net.cpp:137] Memory required for data: 266650800
I0630 20:12:13.696950  4668 layer_factory.cpp:58] Creating layer scale4
I0630 20:12:13.696950  4668 net.cpp:84] Creating Layer scale4
I0630 20:12:13.696950  4668 net.cpp:406] scale4 <- conv4
I0630 20:12:13.696950  4668 net.cpp:367] scale4 -> conv4 (in-place)
I0630 20:12:13.696950  4668 layer_factory.cpp:58] Creating layer scale4
I0630 20:12:13.696950  4668 net.cpp:122] Setting up scale4
I0630 20:12:13.696950  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.696950  4668 net.cpp:137] Memory required for data: 269927600
I0630 20:12:13.696950  4668 layer_factory.cpp:58] Creating layer relu4
I0630 20:12:13.696950  4668 net.cpp:84] Creating Layer relu4
I0630 20:12:13.696950  4668 net.cpp:406] relu4 <- conv4
I0630 20:12:13.696950  4668 net.cpp:367] relu4 -> conv4 (in-place)
I0630 20:12:13.697536  4668 net.cpp:122] Setting up relu4
I0630 20:12:13.697536  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.697536  4668 net.cpp:137] Memory required for data: 273204400
I0630 20:12:13.697536  4668 layer_factory.cpp:58] Creating layer conv4_1
I0630 20:12:13.697536  4668 net.cpp:84] Creating Layer conv4_1
I0630 20:12:13.697536  4668 net.cpp:406] conv4_1 <- conv4
I0630 20:12:13.697536  4668 net.cpp:380] conv4_1 -> conv4_1
I0630 20:12:13.698951  4668 net.cpp:122] Setting up conv4_1
I0630 20:12:13.698951  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.698951  4668 net.cpp:137] Memory required for data: 276481200
I0630 20:12:13.698951  4668 layer_factory.cpp:58] Creating layer bn4_1
I0630 20:12:13.698951  4668 net.cpp:84] Creating Layer bn4_1
I0630 20:12:13.698951  4668 net.cpp:406] bn4_1 <- conv4_1
I0630 20:12:13.698951  4668 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0630 20:12:13.698951  4668 net.cpp:122] Setting up bn4_1
I0630 20:12:13.698951  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.698951  4668 net.cpp:137] Memory required for data: 279758000
I0630 20:12:13.698951  4668 layer_factory.cpp:58] Creating layer scale4_1
I0630 20:12:13.698951  4668 net.cpp:84] Creating Layer scale4_1
I0630 20:12:13.698951  4668 net.cpp:406] scale4_1 <- conv4_1
I0630 20:12:13.698951  4668 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0630 20:12:13.698951  4668 layer_factory.cpp:58] Creating layer scale4_1
I0630 20:12:13.698951  4668 net.cpp:122] Setting up scale4_1
I0630 20:12:13.698951  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.698951  4668 net.cpp:137] Memory required for data: 283034800
I0630 20:12:13.698951  4668 layer_factory.cpp:58] Creating layer relu4_1
I0630 20:12:13.698951  4668 net.cpp:84] Creating Layer relu4_1
I0630 20:12:13.698951  4668 net.cpp:406] relu4_1 <- conv4_1
I0630 20:12:13.698951  4668 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0630 20:12:13.699452  4668 net.cpp:122] Setting up relu4_1
I0630 20:12:13.699452  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.699452  4668 net.cpp:137] Memory required for data: 286311600
I0630 20:12:13.699452  4668 layer_factory.cpp:58] Creating layer conv4_2
I0630 20:12:13.699452  4668 net.cpp:84] Creating Layer conv4_2
I0630 20:12:13.699452  4668 net.cpp:406] conv4_2 <- conv4_1
I0630 20:12:13.699452  4668 net.cpp:380] conv4_2 -> conv4_2
I0630 20:12:13.700470  4668 net.cpp:122] Setting up conv4_2
I0630 20:12:13.700470  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.700470  4668 net.cpp:137] Memory required for data: 289588400
I0630 20:12:13.700470  4668 layer_factory.cpp:58] Creating layer bn4_2
I0630 20:12:13.700470  4668 net.cpp:84] Creating Layer bn4_2
I0630 20:12:13.700470  4668 net.cpp:406] bn4_2 <- conv4_2
I0630 20:12:13.700470  4668 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0630 20:12:13.700970  4668 net.cpp:122] Setting up bn4_2
I0630 20:12:13.700970  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.700970  4668 net.cpp:137] Memory required for data: 292865200
I0630 20:12:13.700970  4668 layer_factory.cpp:58] Creating layer scale4_2
I0630 20:12:13.700970  4668 net.cpp:84] Creating Layer scale4_2
I0630 20:12:13.700970  4668 net.cpp:406] scale4_2 <- conv4_2
I0630 20:12:13.700970  4668 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0630 20:12:13.700970  4668 layer_factory.cpp:58] Creating layer scale4_2
I0630 20:12:13.700970  4668 net.cpp:122] Setting up scale4_2
I0630 20:12:13.700970  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.700970  4668 net.cpp:137] Memory required for data: 296142000
I0630 20:12:13.700970  4668 layer_factory.cpp:58] Creating layer relu4_2
I0630 20:12:13.700970  4668 net.cpp:84] Creating Layer relu4_2
I0630 20:12:13.700970  4668 net.cpp:406] relu4_2 <- conv4_2
I0630 20:12:13.700970  4668 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0630 20:12:13.700970  4668 net.cpp:122] Setting up relu4_2
I0630 20:12:13.700970  4668 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0630 20:12:13.700970  4668 net.cpp:137] Memory required for data: 299418800
I0630 20:12:13.700970  4668 layer_factory.cpp:58] Creating layer pool4_12
I0630 20:12:13.700970  4668 net.cpp:84] Creating Layer pool4_12
I0630 20:12:13.700970  4668 net.cpp:406] pool4_12 <- conv4_2
I0630 20:12:13.700970  4668 net.cpp:380] pool4_12 -> pool4_12
I0630 20:12:13.701472  4668 net.cpp:122] Setting up pool4_12
I0630 20:12:13.701472  4668 net.cpp:129] Top shape: 100 32 8 8 (204800)
I0630 20:12:13.701472  4668 net.cpp:137] Memory required for data: 300238000
I0630 20:12:13.701472  4668 layer_factory.cpp:58] Creating layer conv4_0
I0630 20:12:13.701472  4668 net.cpp:84] Creating Layer conv4_0
I0630 20:12:13.701472  4668 net.cpp:406] conv4_0 <- pool4_12
I0630 20:12:13.701472  4668 net.cpp:380] conv4_0 -> conv4_0
I0630 20:12:13.702472  4668 net.cpp:122] Setting up conv4_0
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 301185200
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer bn4_0
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer bn4_0
I0630 20:12:13.702472  4668 net.cpp:406] bn4_0 <- conv4_0
I0630 20:12:13.702472  4668 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0630 20:12:13.702472  4668 net.cpp:122] Setting up bn4_0
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 302132400
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer scale4_0
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer scale4_0
I0630 20:12:13.702472  4668 net.cpp:406] scale4_0 <- conv4_0
I0630 20:12:13.702472  4668 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer scale4_0
I0630 20:12:13.702472  4668 net.cpp:122] Setting up scale4_0
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 303079600
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer relu4_0
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer relu4_0
I0630 20:12:13.702472  4668 net.cpp:406] relu4_0 <- conv4_0
I0630 20:12:13.702472  4668 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0630 20:12:13.702472  4668 net.cpp:122] Setting up relu4_0
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 37 8 8 (236800)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 304026800
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer cccp4
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer cccp4
I0630 20:12:13.702472  4668 net.cpp:406] cccp4 <- conv4_0
I0630 20:12:13.702472  4668 net.cpp:380] cccp4 -> cccp4
I0630 20:12:13.702472  4668 net.cpp:122] Setting up cccp4
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 305255600
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer bn_cccp4
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer bn_cccp4
I0630 20:12:13.702472  4668 net.cpp:406] bn_cccp4 <- cccp4
I0630 20:12:13.702472  4668 net.cpp:367] bn_cccp4 -> cccp4 (in-place)
I0630 20:12:13.702472  4668 net.cpp:122] Setting up bn_cccp4
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 306484400
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer scale_cccp4
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer scale_cccp4
I0630 20:12:13.702472  4668 net.cpp:406] scale_cccp4 <- cccp4
I0630 20:12:13.702472  4668 net.cpp:367] scale_cccp4 -> cccp4 (in-place)
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer scale_cccp4
I0630 20:12:13.702472  4668 net.cpp:122] Setting up scale_cccp4
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 307713200
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer relu_cccp4
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer relu_cccp4
I0630 20:12:13.702472  4668 net.cpp:406] relu_cccp4 <- cccp4
I0630 20:12:13.702472  4668 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0630 20:12:13.702472  4668 net.cpp:122] Setting up relu_cccp4
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 48 8 8 (307200)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 308942000
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer cccp5
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer cccp5
I0630 20:12:13.702472  4668 net.cpp:406] cccp5 <- cccp4
I0630 20:12:13.702472  4668 net.cpp:380] cccp5 -> cccp5
I0630 20:12:13.702472  4668 net.cpp:122] Setting up cccp5
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 310196400
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer bn_cccp5
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer bn_cccp5
I0630 20:12:13.702472  4668 net.cpp:406] bn_cccp5 <- cccp5
I0630 20:12:13.702472  4668 net.cpp:367] bn_cccp5 -> cccp5 (in-place)
I0630 20:12:13.702472  4668 net.cpp:122] Setting up bn_cccp5
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 311450800
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer scale_cccp5
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer scale_cccp5
I0630 20:12:13.702472  4668 net.cpp:406] scale_cccp5 <- cccp5
I0630 20:12:13.702472  4668 net.cpp:367] scale_cccp5 -> cccp5 (in-place)
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer scale_cccp5
I0630 20:12:13.702472  4668 net.cpp:122] Setting up scale_cccp5
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 312705200
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer relu_cccp5
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer relu_cccp5
I0630 20:12:13.702472  4668 net.cpp:406] relu_cccp5 <- cccp5
I0630 20:12:13.702472  4668 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0630 20:12:13.702472  4668 net.cpp:122] Setting up relu_cccp5
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 49 8 8 (313600)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 313959600
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer cccp6
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer cccp6
I0630 20:12:13.702472  4668 net.cpp:406] cccp6 <- cccp5
I0630 20:12:13.702472  4668 net.cpp:380] cccp6 -> cccp6
I0630 20:12:13.702472  4668 net.cpp:122] Setting up cccp6
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 315239600
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer bn_cccp6
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer bn_cccp6
I0630 20:12:13.702472  4668 net.cpp:406] bn_cccp6 <- cccp6
I0630 20:12:13.702472  4668 net.cpp:367] bn_cccp6 -> cccp6 (in-place)
I0630 20:12:13.702472  4668 net.cpp:122] Setting up bn_cccp6
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 316519600
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer scale_cccp6
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer scale_cccp6
I0630 20:12:13.702472  4668 net.cpp:406] scale_cccp6 <- cccp6
I0630 20:12:13.702472  4668 net.cpp:367] scale_cccp6 -> cccp6 (in-place)
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer scale_cccp6
I0630 20:12:13.702472  4668 net.cpp:122] Setting up scale_cccp6
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 317799600
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer relu_cccp6
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer relu_cccp6
I0630 20:12:13.702472  4668 net.cpp:406] relu_cccp6 <- cccp6
I0630 20:12:13.702472  4668 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0630 20:12:13.702472  4668 net.cpp:122] Setting up relu_cccp6
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 319079600
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer poolcp6
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer poolcp6
I0630 20:12:13.702472  4668 net.cpp:406] poolcp6 <- cccp6
I0630 20:12:13.702472  4668 net.cpp:380] poolcp6 -> poolcp6
I0630 20:12:13.702472  4668 net.cpp:122] Setting up poolcp6
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 50 1 1 (5000)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 319099600
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer ip1
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer ip1
I0630 20:12:13.702472  4668 net.cpp:406] ip1 <- poolcp6
I0630 20:12:13.702472  4668 net.cpp:380] ip1 -> ip1
I0630 20:12:13.702472  4668 net.cpp:122] Setting up ip1
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 10 (1000)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 319103600
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer ip1_ip1_0_split
I0630 20:12:13.702472  4668 net.cpp:406] ip1_ip1_0_split <- ip1
I0630 20:12:13.702472  4668 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0630 20:12:13.702472  4668 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0630 20:12:13.702472  4668 net.cpp:122] Setting up ip1_ip1_0_split
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 10 (1000)
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: 100 10 (1000)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 319111600
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer accuracy
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer accuracy
I0630 20:12:13.702472  4668 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0630 20:12:13.702472  4668 net.cpp:406] accuracy <- label_cifar_1_split_0
I0630 20:12:13.702472  4668 net.cpp:380] accuracy -> accuracy
I0630 20:12:13.702472  4668 net.cpp:122] Setting up accuracy
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: (1)
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 319111604
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer loss
I0630 20:12:13.702472  4668 net.cpp:84] Creating Layer loss
I0630 20:12:13.702472  4668 net.cpp:406] loss <- ip1_ip1_0_split_1
I0630 20:12:13.702472  4668 net.cpp:406] loss <- label_cifar_1_split_1
I0630 20:12:13.702472  4668 net.cpp:380] loss -> loss
I0630 20:12:13.702472  4668 layer_factory.cpp:58] Creating layer loss
I0630 20:12:13.702472  4668 net.cpp:122] Setting up loss
I0630 20:12:13.702472  4668 net.cpp:129] Top shape: (1)
I0630 20:12:13.702472  4668 net.cpp:132]     with loss weight 1
I0630 20:12:13.702472  4668 net.cpp:137] Memory required for data: 319111608
I0630 20:12:13.702472  4668 net.cpp:198] loss needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:200] accuracy does not need backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] ip1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] poolcp6 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu_cccp6 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale_cccp6 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn_cccp6 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] cccp6 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu_cccp5 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale_cccp5 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn_cccp5 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] cccp5 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu_cccp4 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale_cccp4 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn_cccp4 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] cccp4 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu4_0 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale4_0 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn4_0 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] conv4_0 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] pool4_12 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu4_2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale4_2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn4_2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] conv4_2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu4_1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale4_1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn4_1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] conv4_1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu4 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale4 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn4 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] conv4 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu3 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale3 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn3 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] conv3 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] pool2_1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu2_2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale2_2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn2_2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] conv2_2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu2_1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale2_1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn2_1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] conv2_1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] conv2 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu1_0 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale1_0 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn1_0 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] conv1_0 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] relu1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] scale1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] bn1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:198] conv1 needs backward computation.
I0630 20:12:13.702472  4668 net.cpp:200] label_cifar_1_split does not need backward computation.
I0630 20:12:13.702472  4668 net.cpp:200] cifar does not need backward computation.
I0630 20:12:13.702472  4668 net.cpp:242] This network produces output accuracy
I0630 20:12:13.702472  4668 net.cpp:242] This network produces output loss
I0630 20:12:13.702472  4668 net.cpp:255] Network initialization done.
I0630 20:12:13.702472  4668 solver.cpp:56] Solver scaffolding done.
I0630 20:12:13.712476  4668 caffe.cpp:249] Starting Optimization
I0630 20:12:13.712476  4668 solver.cpp:272] Solving CIFAR10_SimpleNet_13_128k_first_1x1
I0630 20:12:13.712476  4668 solver.cpp:273] Learning Rate Policy: multistep
I0630 20:12:13.712476  4668 solver.cpp:330] Iteration 0, Testing net (#0)
I0630 20:12:13.712476  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:12:14.589221  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:12:14.613749  4668 solver.cpp:397]     Test net output #0: accuracy = 0.1001
I0630 20:12:14.613749  4668 solver.cpp:397]     Test net output #1: loss = 78.5941 (* 1 = 78.5941 loss)
I0630 20:12:14.683743  4668 solver.cpp:218] Iteration 0 (-nan iter/s, 0.976331s/100 iters), loss = 3.36262
I0630 20:12:14.683743  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.05
I0630 20:12:14.683743  4668 solver.cpp:237]     Train net output #1: loss = 3.36262 (* 1 = 3.36262 loss)
I0630 20:12:14.683743  4668 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0630 20:12:18.337949  4668 solver.cpp:218] Iteration 100 (27.3633 iter/s, 3.65453s/100 iters), loss = 1.72031
I0630 20:12:18.337949  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I0630 20:12:18.337949  4668 solver.cpp:237]     Train net output #1: loss = 1.72031 (* 1 = 1.72031 loss)
I0630 20:12:18.337949  4668 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0630 20:12:21.970139  4668 solver.cpp:218] Iteration 200 (27.5773 iter/s, 3.62617s/100 iters), loss = 1.73276
I0630 20:12:21.970139  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I0630 20:12:21.970139  4668 solver.cpp:237]     Train net output #1: loss = 1.73276 (* 1 = 1.73276 loss)
I0630 20:12:21.970139  4668 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0630 20:12:25.590384  4668 solver.cpp:218] Iteration 300 (27.5769 iter/s, 3.62622s/100 iters), loss = 1.52992
I0630 20:12:25.590384  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I0630 20:12:25.590384  4668 solver.cpp:237]     Train net output #1: loss = 1.52992 (* 1 = 1.52992 loss)
I0630 20:12:25.590384  4668 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0630 20:12:29.216328  4668 solver.cpp:218] Iteration 400 (27.6286 iter/s, 3.61943s/100 iters), loss = 1.37601
I0630 20:12:29.216328  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I0630 20:12:29.216328  4668 solver.cpp:237]     Train net output #1: loss = 1.37601 (* 1 = 1.37601 loss)
I0630 20:12:29.216328  4668 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0630 20:12:32.662735 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:12:32.797837  4668 solver.cpp:330] Iteration 500, Testing net (#0)
I0630 20:12:32.797837  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:12:33.626531  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:12:33.658571  4668 solver.cpp:397]     Test net output #0: accuracy = 0.4779
I0630 20:12:33.658571  4668 solver.cpp:397]     Test net output #1: loss = 1.46455 (* 1 = 1.46455 loss)
I0630 20:12:33.689661  4668 solver.cpp:218] Iteration 500 (22.3515 iter/s, 4.47397s/100 iters), loss = 1.52012
I0630 20:12:33.689661  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I0630 20:12:33.689661  4668 solver.cpp:237]     Train net output #1: loss = 1.52012 (* 1 = 1.52012 loss)
I0630 20:12:33.689661  4668 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0630 20:12:37.320241  4668 solver.cpp:218] Iteration 600 (27.5238 iter/s, 3.63322s/100 iters), loss = 1.35356
I0630 20:12:37.320241  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I0630 20:12:37.320241  4668 solver.cpp:237]     Train net output #1: loss = 1.35356 (* 1 = 1.35356 loss)
I0630 20:12:37.320241  4668 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0630 20:12:40.930596  4668 solver.cpp:218] Iteration 700 (27.7389 iter/s, 3.60504s/100 iters), loss = 1.49675
I0630 20:12:40.930596  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I0630 20:12:40.930596  4668 solver.cpp:237]     Train net output #1: loss = 1.49675 (* 1 = 1.49675 loss)
I0630 20:12:40.930596  4668 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0630 20:12:44.532996  4668 solver.cpp:218] Iteration 800 (27.7665 iter/s, 3.60146s/100 iters), loss = 1.29325
I0630 20:12:44.532996  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I0630 20:12:44.532996  4668 solver.cpp:237]     Train net output #1: loss = 1.29325 (* 1 = 1.29325 loss)
I0630 20:12:44.532996  4668 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0630 20:12:48.135617  4668 solver.cpp:218] Iteration 900 (27.7418 iter/s, 3.60467s/100 iters), loss = 1.12398
I0630 20:12:48.135617  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I0630 20:12:48.135617  4668 solver.cpp:237]     Train net output #1: loss = 1.12398 (* 1 = 1.12398 loss)
I0630 20:12:48.135617  4668 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0630 20:12:51.584015 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:12:51.724925  4668 solver.cpp:330] Iteration 1000, Testing net (#0)
I0630 20:12:51.724925  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:12:52.538920  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:12:52.578158  4668 solver.cpp:397]     Test net output #0: accuracy = 0.5482
I0630 20:12:52.578158  4668 solver.cpp:397]     Test net output #1: loss = 1.2658 (* 1 = 1.2658 loss)
I0630 20:12:52.611503  4668 solver.cpp:218] Iteration 1000 (22.3541 iter/s, 4.47346s/100 iters), loss = 1.36632
I0630 20:12:52.611503  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I0630 20:12:52.611503  4668 solver.cpp:237]     Train net output #1: loss = 1.36632 (* 1 = 1.36632 loss)
I0630 20:12:52.611503  4668 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0630 20:12:56.229840  4668 solver.cpp:218] Iteration 1100 (27.648 iter/s, 3.6169s/100 iters), loss = 0.995782
I0630 20:12:56.229840  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0630 20:12:56.229840  4668 solver.cpp:237]     Train net output #1: loss = 0.995782 (* 1 = 0.995782 loss)
I0630 20:12:56.229840  4668 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0630 20:12:59.847839  4668 solver.cpp:218] Iteration 1200 (27.6416 iter/s, 3.61774s/100 iters), loss = 1.24535
I0630 20:12:59.847839  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I0630 20:12:59.847839  4668 solver.cpp:237]     Train net output #1: loss = 1.24535 (* 1 = 1.24535 loss)
I0630 20:12:59.847839  4668 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0630 20:13:03.464552  4668 solver.cpp:218] Iteration 1300 (27.6548 iter/s, 3.61601s/100 iters), loss = 1.04029
I0630 20:13:03.464552  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0630 20:13:03.464552  4668 solver.cpp:237]     Train net output #1: loss = 1.04029 (* 1 = 1.04029 loss)
I0630 20:13:03.464552  4668 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0630 20:13:07.081012  4668 solver.cpp:218] Iteration 1400 (27.6513 iter/s, 3.61647s/100 iters), loss = 1.03309
I0630 20:13:07.081514  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0630 20:13:07.081514  4668 solver.cpp:237]     Train net output #1: loss = 1.03309 (* 1 = 1.03309 loss)
I0630 20:13:07.081514  4668 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0630 20:13:10.521605 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:13:10.663223  4668 solver.cpp:330] Iteration 1500, Testing net (#0)
I0630 20:13:10.663223  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:13:11.481039  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:13:11.510767  4668 solver.cpp:397]     Test net output #0: accuracy = 0.6227
I0630 20:13:11.510767  4668 solver.cpp:397]     Test net output #1: loss = 1.06503 (* 1 = 1.06503 loss)
I0630 20:13:11.550770  4668 solver.cpp:218] Iteration 1500 (22.357 iter/s, 4.47288s/100 iters), loss = 1.10959
I0630 20:13:11.550770  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I0630 20:13:11.550770  4668 solver.cpp:237]     Train net output #1: loss = 1.10959 (* 1 = 1.10959 loss)
I0630 20:13:11.550770  4668 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0630 20:13:15.174557  4668 solver.cpp:218] Iteration 1600 (27.6237 iter/s, 3.62008s/100 iters), loss = 0.842877
I0630 20:13:15.174557  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0630 20:13:15.174557  4668 solver.cpp:237]     Train net output #1: loss = 0.842877 (* 1 = 0.842877 loss)
I0630 20:13:15.174557  4668 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0630 20:13:18.789248  4668 solver.cpp:218] Iteration 1700 (27.6579 iter/s, 3.6156s/100 iters), loss = 1.12131
I0630 20:13:18.789248  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I0630 20:13:18.789248  4668 solver.cpp:237]     Train net output #1: loss = 1.12131 (* 1 = 1.12131 loss)
I0630 20:13:18.789248  4668 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0630 20:13:22.407752  4668 solver.cpp:218] Iteration 1800 (27.6415 iter/s, 3.61775s/100 iters), loss = 0.915892
I0630 20:13:22.407752  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0630 20:13:22.407752  4668 solver.cpp:237]     Train net output #1: loss = 0.915892 (* 1 = 0.915892 loss)
I0630 20:13:22.407752  4668 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0630 20:13:26.021883  4668 solver.cpp:218] Iteration 1900 (27.6415 iter/s, 3.61775s/100 iters), loss = 0.79871
I0630 20:13:26.021883  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0630 20:13:26.021883  4668 solver.cpp:237]     Train net output #1: loss = 0.79871 (* 1 = 0.79871 loss)
I0630 20:13:26.021883  4668 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0630 20:13:29.464243 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:13:29.604434  4668 solver.cpp:330] Iteration 2000, Testing net (#0)
I0630 20:13:29.604434  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:13:30.434288  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:13:30.465620  4668 solver.cpp:397]     Test net output #0: accuracy = 0.6756
I0630 20:13:30.465620  4668 solver.cpp:397]     Test net output #1: loss = 0.917298 (* 1 = 0.917298 loss)
I0630 20:13:30.499632  4668 solver.cpp:218] Iteration 2000 (22.3591 iter/s, 4.47245s/100 iters), loss = 0.923424
I0630 20:13:30.500138  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0630 20:13:30.500138  4668 solver.cpp:237]     Train net output #1: loss = 0.923424 (* 1 = 0.923424 loss)
I0630 20:13:30.500138  4668 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0630 20:13:34.107950  4668 solver.cpp:218] Iteration 2100 (27.6447 iter/s, 3.61733s/100 iters), loss = 0.747048
I0630 20:13:34.107950  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0630 20:13:34.107950  4668 solver.cpp:237]     Train net output #1: loss = 0.747048 (* 1 = 0.747048 loss)
I0630 20:13:34.107950  4668 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0630 20:13:37.729761  4668 solver.cpp:218] Iteration 2200 (27.6232 iter/s, 3.62015s/100 iters), loss = 0.957594
I0630 20:13:37.729761  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0630 20:13:37.729761  4668 solver.cpp:237]     Train net output #1: loss = 0.957594 (* 1 = 0.957594 loss)
I0630 20:13:37.729761  4668 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0630 20:13:41.353768  4668 solver.cpp:218] Iteration 2300 (27.6403 iter/s, 3.61791s/100 iters), loss = 0.794716
I0630 20:13:41.353768  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0630 20:13:41.353768  4668 solver.cpp:237]     Train net output #1: loss = 0.794716 (* 1 = 0.794716 loss)
I0630 20:13:41.353768  4668 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0630 20:13:44.970768  4668 solver.cpp:218] Iteration 2400 (27.6701 iter/s, 3.61401s/100 iters), loss = 0.832092
I0630 20:13:44.970768  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0630 20:13:44.970768  4668 solver.cpp:237]     Train net output #1: loss = 0.832092 (* 1 = 0.832092 loss)
I0630 20:13:44.970768  4668 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0630 20:13:48.412930 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:13:48.545662  4668 solver.cpp:330] Iteration 2500, Testing net (#0)
I0630 20:13:48.555666  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:13:49.378259  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:13:49.410779  4668 solver.cpp:397]     Test net output #0: accuracy = 0.6997
I0630 20:13:49.410779  4668 solver.cpp:397]     Test net output #1: loss = 0.858048 (* 1 = 0.858048 loss)
I0630 20:13:49.436293  4668 solver.cpp:218] Iteration 2500 (22.3499 iter/s, 4.47429s/100 iters), loss = 0.87623
I0630 20:13:49.436293  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0630 20:13:49.436293  4668 solver.cpp:237]     Train net output #1: loss = 0.87623 (* 1 = 0.87623 loss)
I0630 20:13:49.436293  4668 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0630 20:13:53.064041  4668 solver.cpp:218] Iteration 2600 (27.6371 iter/s, 3.61833s/100 iters), loss = 0.72562
I0630 20:13:53.064041  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0630 20:13:53.064041  4668 solver.cpp:237]     Train net output #1: loss = 0.72562 (* 1 = 0.72562 loss)
I0630 20:13:53.064041  4668 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0630 20:13:56.681179  4668 solver.cpp:218] Iteration 2700 (27.605 iter/s, 3.62254s/100 iters), loss = 0.851401
I0630 20:13:56.681179  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0630 20:13:56.681179  4668 solver.cpp:237]     Train net output #1: loss = 0.851401 (* 1 = 0.851401 loss)
I0630 20:13:56.681179  4668 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0630 20:14:00.304733  4668 solver.cpp:218] Iteration 2800 (27.6398 iter/s, 3.61798s/100 iters), loss = 0.689528
I0630 20:14:00.304733  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0630 20:14:00.304733  4668 solver.cpp:237]     Train net output #1: loss = 0.689528 (* 1 = 0.689528 loss)
I0630 20:14:00.304733  4668 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0630 20:14:03.925212  4668 solver.cpp:218] Iteration 2900 (27.6284 iter/s, 3.61946s/100 iters), loss = 0.714599
I0630 20:14:03.925212  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0630 20:14:03.925212  4668 solver.cpp:237]     Train net output #1: loss = 0.714599 (* 1 = 0.714599 loss)
I0630 20:14:03.925212  4668 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0630 20:14:07.367202 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:14:07.512125  4668 solver.cpp:330] Iteration 3000, Testing net (#0)
I0630 20:14:07.512125  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:14:08.327800  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:14:08.357801  4668 solver.cpp:397]     Test net output #0: accuracy = 0.7138
I0630 20:14:08.357801  4668 solver.cpp:397]     Test net output #1: loss = 0.836752 (* 1 = 0.836752 loss)
I0630 20:14:08.397799  4668 solver.cpp:218] Iteration 3000 (22.3408 iter/s, 4.47612s/100 iters), loss = 0.742775
I0630 20:14:08.397799  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0630 20:14:08.397799  4668 solver.cpp:237]     Train net output #1: loss = 0.742775 (* 1 = 0.742775 loss)
I0630 20:14:08.397799  4668 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0630 20:14:12.029021  4668 solver.cpp:218] Iteration 3100 (27.5351 iter/s, 3.63173s/100 iters), loss = 0.665721
I0630 20:14:12.029021  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0630 20:14:12.029021  4668 solver.cpp:237]     Train net output #1: loss = 0.665721 (* 1 = 0.665721 loss)
I0630 20:14:12.029021  4668 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0630 20:14:15.660542  4668 solver.cpp:218] Iteration 3200 (27.5421 iter/s, 3.6308s/100 iters), loss = 0.737841
I0630 20:14:15.660542  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0630 20:14:15.660542  4668 solver.cpp:237]     Train net output #1: loss = 0.737841 (* 1 = 0.737841 loss)
I0630 20:14:15.660542  4668 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0630 20:14:19.285101  4668 solver.cpp:218] Iteration 3300 (27.5776 iter/s, 3.62613s/100 iters), loss = 0.619657
I0630 20:14:19.285101  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0630 20:14:19.285101  4668 solver.cpp:237]     Train net output #1: loss = 0.619657 (* 1 = 0.619657 loss)
I0630 20:14:19.285101  4668 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0630 20:14:22.918562  4668 solver.cpp:218] Iteration 3400 (27.5058 iter/s, 3.63559s/100 iters), loss = 0.549415
I0630 20:14:22.918562  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0630 20:14:22.918562  4668 solver.cpp:237]     Train net output #1: loss = 0.549415 (* 1 = 0.549415 loss)
I0630 20:14:22.918562  4668 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0630 20:14:26.371243 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:14:26.521420  4668 solver.cpp:330] Iteration 3500, Testing net (#0)
I0630 20:14:26.521420  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:14:27.338701  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:14:27.368705  4668 solver.cpp:397]     Test net output #0: accuracy = 0.7438
I0630 20:14:27.368705  4668 solver.cpp:397]     Test net output #1: loss = 0.735608 (* 1 = 0.735608 loss)
I0630 20:14:27.411381  4668 solver.cpp:218] Iteration 3500 (22.2954 iter/s, 4.48524s/100 iters), loss = 0.691416
I0630 20:14:27.411381  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0630 20:14:27.411381  4668 solver.cpp:237]     Train net output #1: loss = 0.691416 (* 1 = 0.691416 loss)
I0630 20:14:27.411381  4668 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0630 20:14:31.034504  4668 solver.cpp:218] Iteration 3600 (27.5704 iter/s, 3.62708s/100 iters), loss = 0.544499
I0630 20:14:31.034504  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0630 20:14:31.034504  4668 solver.cpp:237]     Train net output #1: loss = 0.544499 (* 1 = 0.544499 loss)
I0630 20:14:31.034504  4668 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0630 20:14:34.677366  4668 solver.cpp:218] Iteration 3700 (27.4543 iter/s, 3.64242s/100 iters), loss = 0.70821
I0630 20:14:34.677366  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0630 20:14:34.677366  4668 solver.cpp:237]     Train net output #1: loss = 0.70821 (* 1 = 0.70821 loss)
I0630 20:14:34.677366  4668 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0630 20:14:38.305359  4668 solver.cpp:218] Iteration 3800 (27.6069 iter/s, 3.62229s/100 iters), loss = 0.690718
I0630 20:14:38.305359  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 20:14:38.305359  4668 solver.cpp:237]     Train net output #1: loss = 0.690718 (* 1 = 0.690718 loss)
I0630 20:14:38.305359  4668 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0630 20:14:41.929404  4668 solver.cpp:218] Iteration 3900 (27.5956 iter/s, 3.62376s/100 iters), loss = 0.55439
I0630 20:14:41.929404  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0630 20:14:41.929404  4668 solver.cpp:237]     Train net output #1: loss = 0.55439 (* 1 = 0.55439 loss)
I0630 20:14:41.929404  4668 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0630 20:14:45.366943 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:14:45.515138  4668 solver.cpp:330] Iteration 4000, Testing net (#0)
I0630 20:14:45.515138  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:14:46.336369  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:14:46.366389  4668 solver.cpp:397]     Test net output #0: accuracy = 0.7636
I0630 20:14:46.366389  4668 solver.cpp:397]     Test net output #1: loss = 0.684283 (* 1 = 0.684283 loss)
I0630 20:14:46.405413  4668 solver.cpp:218] Iteration 4000 (22.3256 iter/s, 4.47916s/100 iters), loss = 0.674075
I0630 20:14:46.405413  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0630 20:14:46.405413  4668 solver.cpp:237]     Train net output #1: loss = 0.674075 (* 1 = 0.674075 loss)
I0630 20:14:46.405413  4668 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0630 20:14:50.027452  4668 solver.cpp:218] Iteration 4100 (27.6165 iter/s, 3.62102s/100 iters), loss = 0.5273
I0630 20:14:50.027452  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 20:14:50.027452  4668 solver.cpp:237]     Train net output #1: loss = 0.5273 (* 1 = 0.5273 loss)
I0630 20:14:50.027452  4668 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0630 20:14:53.650095  4668 solver.cpp:218] Iteration 4200 (27.6052 iter/s, 3.6225s/100 iters), loss = 0.620121
I0630 20:14:53.650095  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 20:14:53.650095  4668 solver.cpp:237]     Train net output #1: loss = 0.620121 (* 1 = 0.620121 loss)
I0630 20:14:53.650095  4668 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0630 20:14:57.274155  4668 solver.cpp:218] Iteration 4300 (27.6188 iter/s, 3.62072s/100 iters), loss = 0.598839
I0630 20:14:57.274155  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0630 20:14:57.274155  4668 solver.cpp:237]     Train net output #1: loss = 0.598839 (* 1 = 0.598839 loss)
I0630 20:14:57.274155  4668 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0630 20:15:00.893139  4668 solver.cpp:218] Iteration 4400 (27.5803 iter/s, 3.62578s/100 iters), loss = 0.552418
I0630 20:15:00.893139  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0630 20:15:00.893139  4668 solver.cpp:237]     Train net output #1: loss = 0.552418 (* 1 = 0.552418 loss)
I0630 20:15:00.893139  4668 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0630 20:15:04.335594 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:15:04.484804  4668 solver.cpp:330] Iteration 4500, Testing net (#0)
I0630 20:15:04.484804  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:15:05.309159  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:15:05.336297  4668 solver.cpp:397]     Test net output #0: accuracy = 0.7631
I0630 20:15:05.336297  4668 solver.cpp:397]     Test net output #1: loss = 0.697046 (* 1 = 0.697046 loss)
I0630 20:15:05.365792  4668 solver.cpp:218] Iteration 4500 (22.3517 iter/s, 4.47393s/100 iters), loss = 0.617476
I0630 20:15:05.365792  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0630 20:15:05.365792  4668 solver.cpp:237]     Train net output #1: loss = 0.617476 (* 1 = 0.617476 loss)
I0630 20:15:05.365792  4668 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0630 20:15:08.988715  4668 solver.cpp:218] Iteration 4600 (27.6008 iter/s, 3.62308s/100 iters), loss = 0.560584
I0630 20:15:08.988715  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 20:15:08.988715  4668 solver.cpp:237]     Train net output #1: loss = 0.560584 (* 1 = 0.560584 loss)
I0630 20:15:08.988715  4668 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0630 20:15:12.621454  4668 solver.cpp:218] Iteration 4700 (27.6007 iter/s, 3.6231s/100 iters), loss = 0.560827
I0630 20:15:12.621454  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 20:15:12.621454  4668 solver.cpp:237]     Train net output #1: loss = 0.560827 (* 1 = 0.560827 loss)
I0630 20:15:12.621454  4668 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0630 20:15:16.233858  4668 solver.cpp:218] Iteration 4800 (27.619 iter/s, 3.6207s/100 iters), loss = 0.597215
I0630 20:15:16.233858  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0630 20:15:16.233858  4668 solver.cpp:237]     Train net output #1: loss = 0.597215 (* 1 = 0.597215 loss)
I0630 20:15:16.233858  4668 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0630 20:15:19.865065  4668 solver.cpp:218] Iteration 4900 (27.5926 iter/s, 3.62416s/100 iters), loss = 0.523342
I0630 20:15:19.865065  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0630 20:15:19.865065  4668 solver.cpp:237]     Train net output #1: loss = 0.523342 (* 1 = 0.523342 loss)
I0630 20:15:19.865065  4668 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0630 20:15:23.309752 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:15:23.454351  4668 solver.cpp:330] Iteration 5000, Testing net (#0)
I0630 20:15:23.454351  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:15:24.268895  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:15:24.310034  4668 solver.cpp:397]     Test net output #0: accuracy = 0.7724
I0630 20:15:24.310034  4668 solver.cpp:397]     Test net output #1: loss = 0.661011 (* 1 = 0.661011 loss)
I0630 20:15:24.344136  4668 solver.cpp:218] Iteration 5000 (22.3368 iter/s, 4.47692s/100 iters), loss = 0.765781
I0630 20:15:24.344665  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0630 20:15:24.344665  4668 solver.cpp:237]     Train net output #1: loss = 0.765781 (* 1 = 0.765781 loss)
I0630 20:15:24.344665  4668 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0630 20:15:27.971554  4668 solver.cpp:218] Iteration 5100 (27.5583 iter/s, 3.62867s/100 iters), loss = 0.450777
I0630 20:15:27.971554  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 20:15:27.971554  4668 solver.cpp:237]     Train net output #1: loss = 0.450777 (* 1 = 0.450777 loss)
I0630 20:15:27.971554  4668 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0630 20:15:31.590600  4668 solver.cpp:218] Iteration 5200 (27.5852 iter/s, 3.62513s/100 iters), loss = 0.490113
I0630 20:15:31.590600  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:15:31.590600  4668 solver.cpp:237]     Train net output #1: loss = 0.490113 (* 1 = 0.490113 loss)
I0630 20:15:31.590600  4668 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0630 20:15:35.218677  4668 solver.cpp:218] Iteration 5300 (27.5834 iter/s, 3.62537s/100 iters), loss = 0.498188
I0630 20:15:35.218677  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0630 20:15:35.218677  4668 solver.cpp:237]     Train net output #1: loss = 0.498188 (* 1 = 0.498188 loss)
I0630 20:15:35.218677  4668 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0630 20:15:38.839337  4668 solver.cpp:218] Iteration 5400 (27.598 iter/s, 3.62345s/100 iters), loss = 0.471923
I0630 20:15:38.839337  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 20:15:38.839337  4668 solver.cpp:237]     Train net output #1: loss = 0.471923 (* 1 = 0.471923 loss)
I0630 20:15:38.839337  4668 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0630 20:15:42.294180 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:15:42.434623  4668 solver.cpp:330] Iteration 5500, Testing net (#0)
I0630 20:15:42.434623  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:15:43.253712  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:15:43.292646  4668 solver.cpp:397]     Test net output #0: accuracy = 0.7757
I0630 20:15:43.292646  4668 solver.cpp:397]     Test net output #1: loss = 0.659005 (* 1 = 0.659005 loss)
I0630 20:15:43.326748  4668 solver.cpp:218] Iteration 5500 (22.329 iter/s, 4.47849s/100 iters), loss = 0.491076
I0630 20:15:43.326748  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 20:15:43.326748  4668 solver.cpp:237]     Train net output #1: loss = 0.491076 (* 1 = 0.491076 loss)
I0630 20:15:43.326748  4668 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0630 20:15:46.947175  4668 solver.cpp:218] Iteration 5600 (27.6079 iter/s, 3.62215s/100 iters), loss = 0.403864
I0630 20:15:46.947175  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:15:46.947175  4668 solver.cpp:237]     Train net output #1: loss = 0.403864 (* 1 = 0.403864 loss)
I0630 20:15:46.947175  4668 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0630 20:15:50.572902  4668 solver.cpp:218] Iteration 5700 (27.5996 iter/s, 3.62324s/100 iters), loss = 0.538429
I0630 20:15:50.572902  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0630 20:15:50.572902  4668 solver.cpp:237]     Train net output #1: loss = 0.538429 (* 1 = 0.538429 loss)
I0630 20:15:50.572902  4668 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0630 20:15:54.192189  4668 solver.cpp:218] Iteration 5800 (27.5999 iter/s, 3.62321s/100 iters), loss = 0.471494
I0630 20:15:54.192189  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 20:15:54.192189  4668 solver.cpp:237]     Train net output #1: loss = 0.471494 (* 1 = 0.471494 loss)
I0630 20:15:54.192189  4668 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0630 20:15:57.825492  4668 solver.cpp:218] Iteration 5900 (27.5341 iter/s, 3.63187s/100 iters), loss = 0.430467
I0630 20:15:57.825492  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 20:15:57.825492  4668 solver.cpp:237]     Train net output #1: loss = 0.430467 (* 1 = 0.430467 loss)
I0630 20:15:57.825492  4668 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0630 20:16:01.287837 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:16:01.428820  4668 solver.cpp:330] Iteration 6000, Testing net (#0)
I0630 20:16:01.428820  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:16:02.261308  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:16:02.293839  4668 solver.cpp:397]     Test net output #0: accuracy = 0.7866
I0630 20:16:02.293839  4668 solver.cpp:397]     Test net output #1: loss = 0.621893 (* 1 = 0.621893 loss)
I0630 20:16:02.320358  4668 solver.cpp:218] Iteration 6000 (22.2285 iter/s, 4.49873s/100 iters), loss = 0.559534
I0630 20:16:02.320358  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 20:16:02.320358  4668 solver.cpp:237]     Train net output #1: loss = 0.559534 (* 1 = 0.559534 loss)
I0630 20:16:02.320358  4668 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0630 20:16:05.982751  4668 solver.cpp:218] Iteration 6100 (27.3136 iter/s, 3.66118s/100 iters), loss = 0.382791
I0630 20:16:05.982751  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:16:05.982751  4668 solver.cpp:237]     Train net output #1: loss = 0.382791 (* 1 = 0.382791 loss)
I0630 20:16:05.982751  4668 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0630 20:16:09.645103  4668 solver.cpp:218] Iteration 6200 (27.2974 iter/s, 3.66335s/100 iters), loss = 0.575341
I0630 20:16:09.645103  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0630 20:16:09.645103  4668 solver.cpp:237]     Train net output #1: loss = 0.575341 (* 1 = 0.575341 loss)
I0630 20:16:09.645103  4668 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0630 20:16:13.277626  4668 solver.cpp:218] Iteration 6300 (27.5784 iter/s, 3.62602s/100 iters), loss = 0.464653
I0630 20:16:13.277626  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 20:16:13.277626  4668 solver.cpp:237]     Train net output #1: loss = 0.464653 (* 1 = 0.464653 loss)
I0630 20:16:13.277626  4668 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0630 20:16:16.930176  4668 solver.cpp:218] Iteration 6400 (27.3967 iter/s, 3.65007s/100 iters), loss = 0.373393
I0630 20:16:16.930176  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:16:16.930176  4668 solver.cpp:237]     Train net output #1: loss = 0.373393 (* 1 = 0.373393 loss)
I0630 20:16:16.930176  4668 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0630 20:16:20.404095 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:16:20.543967  4668 solver.cpp:330] Iteration 6500, Testing net (#0)
I0630 20:16:20.543967  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:16:21.374413  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:16:21.404413  4668 solver.cpp:397]     Test net output #0: accuracy = 0.7929
I0630 20:16:21.404413  4668 solver.cpp:397]     Test net output #1: loss = 0.603006 (* 1 = 0.603006 loss)
I0630 20:16:21.434456  4668 solver.cpp:218] Iteration 6500 (22.1756 iter/s, 4.50945s/100 iters), loss = 0.432908
I0630 20:16:21.434456  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0630 20:16:21.434456  4668 solver.cpp:237]     Train net output #1: loss = 0.432908 (* 1 = 0.432908 loss)
I0630 20:16:21.434456  4668 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0630 20:16:25.071084  4668 solver.cpp:218] Iteration 6600 (27.5423 iter/s, 3.63078s/100 iters), loss = 0.429655
I0630 20:16:25.071084  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:16:25.071084  4668 solver.cpp:237]     Train net output #1: loss = 0.429655 (* 1 = 0.429655 loss)
I0630 20:16:25.071084  4668 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0630 20:16:28.711743  4668 solver.cpp:218] Iteration 6700 (27.4345 iter/s, 3.64504s/100 iters), loss = 0.479175
I0630 20:16:28.711743  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:16:28.711743  4668 solver.cpp:237]     Train net output #1: loss = 0.479175 (* 1 = 0.479175 loss)
I0630 20:16:28.711743  4668 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0630 20:16:32.350561  4668 solver.cpp:218] Iteration 6800 (27.4953 iter/s, 3.63699s/100 iters), loss = 0.401703
I0630 20:16:32.350561  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:16:32.350561  4668 solver.cpp:237]     Train net output #1: loss = 0.401703 (* 1 = 0.401703 loss)
I0630 20:16:32.350561  4668 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0630 20:16:36.002338  4668 solver.cpp:218] Iteration 6900 (27.3673 iter/s, 3.654s/100 iters), loss = 0.531449
I0630 20:16:36.002338  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0630 20:16:36.002338  4668 solver.cpp:237]     Train net output #1: loss = 0.531449 (* 1 = 0.531449 loss)
I0630 20:16:36.002338  4668 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0630 20:16:39.464964 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:16:39.611907  4668 solver.cpp:330] Iteration 7000, Testing net (#0)
I0630 20:16:39.611907  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:16:40.440627  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:16:40.465251  4668 solver.cpp:397]     Test net output #0: accuracy = 0.7843
I0630 20:16:40.465251  4668 solver.cpp:397]     Test net output #1: loss = 0.628562 (* 1 = 0.628562 loss)
I0630 20:16:40.506361  4668 solver.cpp:218] Iteration 7000 (22.2329 iter/s, 4.49784s/100 iters), loss = 0.535966
I0630 20:16:40.506361  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0630 20:16:40.506361  4668 solver.cpp:237]     Train net output #1: loss = 0.535966 (* 1 = 0.535966 loss)
I0630 20:16:40.506361  4668 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0630 20:16:44.147070  4668 solver.cpp:218] Iteration 7100 (27.4536 iter/s, 3.64251s/100 iters), loss = 0.379812
I0630 20:16:44.147070  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:16:44.147070  4668 solver.cpp:237]     Train net output #1: loss = 0.379812 (* 1 = 0.379812 loss)
I0630 20:16:44.147070  4668 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0630 20:16:47.778913  4668 solver.cpp:218] Iteration 7200 (27.5389 iter/s, 3.63123s/100 iters), loss = 0.430912
I0630 20:16:47.778913  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:16:47.778913  4668 solver.cpp:237]     Train net output #1: loss = 0.430912 (* 1 = 0.430912 loss)
I0630 20:16:47.778913  4668 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0630 20:16:51.413003  4668 solver.cpp:218] Iteration 7300 (27.5118 iter/s, 3.63481s/100 iters), loss = 0.44123
I0630 20:16:51.413003  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:16:51.413003  4668 solver.cpp:237]     Train net output #1: loss = 0.44123 (* 1 = 0.44123 loss)
I0630 20:16:51.413003  4668 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0630 20:16:55.053072  4668 solver.cpp:218] Iteration 7400 (27.4791 iter/s, 3.63913s/100 iters), loss = 0.457928
I0630 20:16:55.053072  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0630 20:16:55.053072  4668 solver.cpp:237]     Train net output #1: loss = 0.457928 (* 1 = 0.457928 loss)
I0630 20:16:55.053072  4668 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0630 20:16:58.497382 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:16:58.644367  4668 solver.cpp:330] Iteration 7500, Testing net (#0)
I0630 20:16:58.644367  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:16:59.476459  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:16:59.507416  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8022
I0630 20:16:59.507416  4668 solver.cpp:397]     Test net output #1: loss = 0.575538 (* 1 = 0.575538 loss)
I0630 20:16:59.537434  4668 solver.cpp:218] Iteration 7500 (22.2723 iter/s, 4.48988s/100 iters), loss = 0.451804
I0630 20:16:59.537434  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:16:59.537434  4668 solver.cpp:237]     Train net output #1: loss = 0.451804 (* 1 = 0.451804 loss)
I0630 20:16:59.537434  4668 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0630 20:17:03.197787  4668 solver.cpp:218] Iteration 7600 (27.3466 iter/s, 3.65676s/100 iters), loss = 0.343313
I0630 20:17:03.197787  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:17:03.197787  4668 solver.cpp:237]     Train net output #1: loss = 0.343313 (* 1 = 0.343313 loss)
I0630 20:17:03.197787  4668 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0630 20:17:06.859936  4668 solver.cpp:218] Iteration 7700 (27.3354 iter/s, 3.65826s/100 iters), loss = 0.350797
I0630 20:17:06.859936  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:17:06.859936  4668 solver.cpp:237]     Train net output #1: loss = 0.350797 (* 1 = 0.350797 loss)
I0630 20:17:06.859936  4668 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0630 20:17:10.512359  4668 solver.cpp:218] Iteration 7800 (27.3934 iter/s, 3.65051s/100 iters), loss = 0.41246
I0630 20:17:10.512359  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:17:10.512359  4668 solver.cpp:237]     Train net output #1: loss = 0.41246 (* 1 = 0.41246 loss)
I0630 20:17:10.512359  4668 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0630 20:17:14.164435  4668 solver.cpp:218] Iteration 7900 (27.3447 iter/s, 3.65702s/100 iters), loss = 0.329524
I0630 20:17:14.164435  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:17:14.164435  4668 solver.cpp:237]     Train net output #1: loss = 0.329524 (* 1 = 0.329524 loss)
I0630 20:17:14.164435  4668 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0630 20:17:17.611310 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:17:17.748839  4668 solver.cpp:330] Iteration 8000, Testing net (#0)
I0630 20:17:17.748839  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:17:18.577585  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:17:18.608784  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8012
I0630 20:17:18.608784  4668 solver.cpp:397]     Test net output #1: loss = 0.590918 (* 1 = 0.590918 loss)
I0630 20:17:18.642853  4668 solver.cpp:218] Iteration 8000 (22.3546 iter/s, 4.47335s/100 iters), loss = 0.489763
I0630 20:17:18.642853  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 20:17:18.642853  4668 solver.cpp:237]     Train net output #1: loss = 0.489763 (* 1 = 0.489763 loss)
I0630 20:17:18.642853  4668 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0630 20:17:22.277251  4668 solver.cpp:218] Iteration 8100 (27.5227 iter/s, 3.63336s/100 iters), loss = 0.369235
I0630 20:17:22.277251  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:17:22.277251  4668 solver.cpp:237]     Train net output #1: loss = 0.369235 (* 1 = 0.369235 loss)
I0630 20:17:22.277251  4668 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0630 20:17:25.925021  4668 solver.cpp:218] Iteration 8200 (27.3951 iter/s, 3.65029s/100 iters), loss = 0.412799
I0630 20:17:25.925021  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:17:25.925021  4668 solver.cpp:237]     Train net output #1: loss = 0.412799 (* 1 = 0.412799 loss)
I0630 20:17:25.925021  4668 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0630 20:17:29.557212  4668 solver.cpp:218] Iteration 8300 (27.4836 iter/s, 3.63853s/100 iters), loss = 0.427126
I0630 20:17:29.557212  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:17:29.557212  4668 solver.cpp:237]     Train net output #1: loss = 0.427126 (* 1 = 0.427126 loss)
I0630 20:17:29.557212  4668 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0630 20:17:33.208776  4668 solver.cpp:218] Iteration 8400 (27.3934 iter/s, 3.65052s/100 iters), loss = 0.361423
I0630 20:17:33.208776  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:17:33.208776  4668 solver.cpp:237]     Train net output #1: loss = 0.361423 (* 1 = 0.361423 loss)
I0630 20:17:33.208776  4668 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0630 20:17:36.670716 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:17:36.812204  4668 solver.cpp:330] Iteration 8500, Testing net (#0)
I0630 20:17:36.812204  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:17:37.641639  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:17:37.671646  4668 solver.cpp:397]     Test net output #0: accuracy = 0.798
I0630 20:17:37.671646  4668 solver.cpp:397]     Test net output #1: loss = 0.591913 (* 1 = 0.591913 loss)
I0630 20:17:37.711633  4668 solver.cpp:218] Iteration 8500 (22.2492 iter/s, 4.49455s/100 iters), loss = 0.469028
I0630 20:17:37.711633  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0630 20:17:37.711633  4668 solver.cpp:237]     Train net output #1: loss = 0.469028 (* 1 = 0.469028 loss)
I0630 20:17:37.711633  4668 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0630 20:17:41.345880  4668 solver.cpp:218] Iteration 8600 (27.5026 iter/s, 3.63602s/100 iters), loss = 0.370234
I0630 20:17:41.345880  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:17:41.345880  4668 solver.cpp:237]     Train net output #1: loss = 0.370234 (* 1 = 0.370234 loss)
I0630 20:17:41.345880  4668 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0630 20:17:44.985134  4668 solver.cpp:218] Iteration 8700 (27.4825 iter/s, 3.63868s/100 iters), loss = 0.46975
I0630 20:17:44.985134  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0630 20:17:44.985134  4668 solver.cpp:237]     Train net output #1: loss = 0.46975 (* 1 = 0.46975 loss)
I0630 20:17:44.985134  4668 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0630 20:17:48.638331  4668 solver.cpp:218] Iteration 8800 (27.3575 iter/s, 3.6553s/100 iters), loss = 0.439097
I0630 20:17:48.638331  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0630 20:17:48.638331  4668 solver.cpp:237]     Train net output #1: loss = 0.439097 (* 1 = 0.439097 loss)
I0630 20:17:48.638331  4668 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0630 20:17:52.299206  4668 solver.cpp:218] Iteration 8900 (27.3438 iter/s, 3.65714s/100 iters), loss = 0.323204
I0630 20:17:52.299206  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:17:52.299206  4668 solver.cpp:237]     Train net output #1: loss = 0.323204 (* 1 = 0.323204 loss)
I0630 20:17:52.299206  4668 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0630 20:17:55.743129 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:17:55.883671  4668 solver.cpp:330] Iteration 9000, Testing net (#0)
I0630 20:17:55.883671  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:17:56.714373  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:17:56.744909  4668 solver.cpp:397]     Test net output #0: accuracy = 0.799
I0630 20:17:56.744909  4668 solver.cpp:397]     Test net output #1: loss = 0.603052 (* 1 = 0.603052 loss)
I0630 20:17:56.784922  4668 solver.cpp:218] Iteration 9000 (22.3038 iter/s, 4.48354s/100 iters), loss = 0.34528
I0630 20:17:56.784922  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:17:56.784922  4668 solver.cpp:237]     Train net output #1: loss = 0.34528 (* 1 = 0.34528 loss)
I0630 20:17:56.784922  4668 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0630 20:18:00.428912  4668 solver.cpp:218] Iteration 9100 (27.4456 iter/s, 3.64357s/100 iters), loss = 0.378165
I0630 20:18:00.428912  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:18:00.428912  4668 solver.cpp:237]     Train net output #1: loss = 0.378165 (* 1 = 0.378165 loss)
I0630 20:18:00.428912  4668 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0630 20:18:04.059037  4668 solver.cpp:218] Iteration 9200 (27.4831 iter/s, 3.6386s/100 iters), loss = 0.397271
I0630 20:18:04.059037  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:18:04.059037  4668 solver.cpp:237]     Train net output #1: loss = 0.397271 (* 1 = 0.397271 loss)
I0630 20:18:04.059037  4668 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0630 20:18:07.711771  4668 solver.cpp:218] Iteration 9300 (27.4185 iter/s, 3.64717s/100 iters), loss = 0.3885
I0630 20:18:07.711771  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:18:07.711771  4668 solver.cpp:237]     Train net output #1: loss = 0.3885 (* 1 = 0.3885 loss)
I0630 20:18:07.711771  4668 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0630 20:18:11.328043  4668 solver.cpp:218] Iteration 9400 (27.6453 iter/s, 3.61725s/100 iters), loss = 0.330584
I0630 20:18:11.328043  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:18:11.328043  4668 solver.cpp:237]     Train net output #1: loss = 0.330584 (* 1 = 0.330584 loss)
I0630 20:18:11.328043  4668 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0630 20:18:14.818444 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:18:14.958456  4668 solver.cpp:330] Iteration 9500, Testing net (#0)
I0630 20:18:14.958456  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:18:15.779331  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:18:15.809339  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8046
I0630 20:18:15.809339  4668 solver.cpp:397]     Test net output #1: loss = 0.566228 (* 1 = 0.566228 loss)
I0630 20:18:15.849346  4668 solver.cpp:218] Iteration 9500 (22.1317 iter/s, 4.5184s/100 iters), loss = 0.367884
I0630 20:18:15.849346  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:18:15.849346  4668 solver.cpp:237]     Train net output #1: loss = 0.367884 (* 1 = 0.367884 loss)
I0630 20:18:15.849346  4668 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0630 20:18:19.511867  4668 solver.cpp:218] Iteration 9600 (27.2901 iter/s, 3.66434s/100 iters), loss = 0.35779
I0630 20:18:19.511867  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:18:19.511867  4668 solver.cpp:237]     Train net output #1: loss = 0.35779 (* 1 = 0.35779 loss)
I0630 20:18:19.511867  4668 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0630 20:18:23.154278  4668 solver.cpp:218] Iteration 9700 (27.4889 iter/s, 3.63783s/100 iters), loss = 0.351913
I0630 20:18:23.154784  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:18:23.154784  4668 solver.cpp:237]     Train net output #1: loss = 0.351913 (* 1 = 0.351913 loss)
I0630 20:18:23.154784  4668 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0630 20:18:26.796497  4668 solver.cpp:218] Iteration 9800 (27.4601 iter/s, 3.64164s/100 iters), loss = 0.37131
I0630 20:18:26.796497  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 20:18:26.796497  4668 solver.cpp:237]     Train net output #1: loss = 0.37131 (* 1 = 0.37131 loss)
I0630 20:18:26.796497  4668 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0630 20:18:30.430110  4668 solver.cpp:218] Iteration 9900 (27.514 iter/s, 3.63451s/100 iters), loss = 0.351074
I0630 20:18:30.430110  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:18:30.430110  4668 solver.cpp:237]     Train net output #1: loss = 0.351074 (* 1 = 0.351074 loss)
I0630 20:18:30.430110  4668 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0630 20:18:33.872134 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:18:34.021795  4668 solver.cpp:330] Iteration 10000, Testing net (#0)
I0630 20:18:34.021795  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:18:34.844275  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:18:34.872912  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8173
I0630 20:18:34.872912  4668 solver.cpp:397]     Test net output #1: loss = 0.543075 (* 1 = 0.543075 loss)
I0630 20:18:34.912932  4668 solver.cpp:218] Iteration 10000 (22.2902 iter/s, 4.48627s/100 iters), loss = 0.390317
I0630 20:18:34.912932  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:18:34.912932  4668 solver.cpp:237]     Train net output #1: loss = 0.390317 (* 1 = 0.390317 loss)
I0630 20:18:34.912932  4668 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0630 20:18:38.545114  4668 solver.cpp:218] Iteration 10100 (27.508 iter/s, 3.63531s/100 iters), loss = 0.483105
I0630 20:18:38.545114  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:18:38.545114  4668 solver.cpp:237]     Train net output #1: loss = 0.483105 (* 1 = 0.483105 loss)
I0630 20:18:38.545114  4668 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0630 20:18:42.187055  4668 solver.cpp:218] Iteration 10200 (27.492 iter/s, 3.63742s/100 iters), loss = 0.399418
I0630 20:18:42.187055  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:18:42.187055  4668 solver.cpp:237]     Train net output #1: loss = 0.399418 (* 1 = 0.399418 loss)
I0630 20:18:42.187055  4668 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0630 20:18:45.818137  4668 solver.cpp:218] Iteration 10300 (27.537 iter/s, 3.63147s/100 iters), loss = 0.389099
I0630 20:18:45.818137  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:18:45.818137  4668 solver.cpp:237]     Train net output #1: loss = 0.389099 (* 1 = 0.389099 loss)
I0630 20:18:45.818137  4668 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0630 20:18:49.450625  4668 solver.cpp:218] Iteration 10400 (27.511 iter/s, 3.63491s/100 iters), loss = 0.286216
I0630 20:18:49.450625  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:18:49.450625  4668 solver.cpp:237]     Train net output #1: loss = 0.286216 (* 1 = 0.286216 loss)
I0630 20:18:49.450625  4668 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0630 20:18:52.913134 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:18:53.053352  4668 solver.cpp:330] Iteration 10500, Testing net (#0)
I0630 20:18:53.053352  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:18:53.874264  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:18:53.904284  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8018
I0630 20:18:53.904284  4668 solver.cpp:397]     Test net output #1: loss = 0.6103 (* 1 = 0.6103 loss)
I0630 20:18:53.945124  4668 solver.cpp:218] Iteration 10500 (22.2887 iter/s, 4.48657s/100 iters), loss = 0.436618
I0630 20:18:53.945124  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0630 20:18:53.945124  4668 solver.cpp:237]     Train net output #1: loss = 0.436618 (* 1 = 0.436618 loss)
I0630 20:18:53.945124  4668 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0630 20:18:57.565217  4668 solver.cpp:218] Iteration 10600 (27.6312 iter/s, 3.61909s/100 iters), loss = 0.451859
I0630 20:18:57.565217  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:18:57.565217  4668 solver.cpp:237]     Train net output #1: loss = 0.45186 (* 1 = 0.45186 loss)
I0630 20:18:57.565217  4668 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0630 20:19:01.180357  4668 solver.cpp:218] Iteration 10700 (27.6417 iter/s, 3.61772s/100 iters), loss = 0.419185
I0630 20:19:01.180357  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:19:01.180357  4668 solver.cpp:237]     Train net output #1: loss = 0.419185 (* 1 = 0.419185 loss)
I0630 20:19:01.180357  4668 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0630 20:19:04.801944  4668 solver.cpp:218] Iteration 10800 (27.63 iter/s, 3.61925s/100 iters), loss = 0.365357
I0630 20:19:04.801944  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:19:04.801944  4668 solver.cpp:237]     Train net output #1: loss = 0.365357 (* 1 = 0.365357 loss)
I0630 20:19:04.801944  4668 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0630 20:19:08.414820  4668 solver.cpp:218] Iteration 10900 (27.6212 iter/s, 3.6204s/100 iters), loss = 0.339707
I0630 20:19:08.414820  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:19:08.414820  4668 solver.cpp:237]     Train net output #1: loss = 0.339707 (* 1 = 0.339707 loss)
I0630 20:19:08.414820  4668 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0630 20:19:11.857275 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:19:12.007246  4668 solver.cpp:330] Iteration 11000, Testing net (#0)
I0630 20:19:12.007246  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:19:12.827560  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:19:12.857568  4668 solver.cpp:397]     Test net output #0: accuracy = 0.7962
I0630 20:19:12.857568  4668 solver.cpp:397]     Test net output #1: loss = 0.629967 (* 1 = 0.629967 loss)
I0630 20:19:12.887567  4668 solver.cpp:218] Iteration 11000 (22.3543 iter/s, 4.47342s/100 iters), loss = 0.47483
I0630 20:19:12.887567  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:19:12.887567  4668 solver.cpp:237]     Train net output #1: loss = 0.47483 (* 1 = 0.47483 loss)
I0630 20:19:12.887567  4668 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0630 20:19:16.520604  4668 solver.cpp:218] Iteration 11100 (27.5499 iter/s, 3.62978s/100 iters), loss = 0.381209
I0630 20:19:16.520604  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:19:16.520604  4668 solver.cpp:237]     Train net output #1: loss = 0.381209 (* 1 = 0.381209 loss)
I0630 20:19:16.520604  4668 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0630 20:19:20.154693  4668 solver.cpp:218] Iteration 11200 (27.5027 iter/s, 3.63601s/100 iters), loss = 0.343909
I0630 20:19:20.154693  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 20:19:20.154693  4668 solver.cpp:237]     Train net output #1: loss = 0.34391 (* 1 = 0.34391 loss)
I0630 20:19:20.154693  4668 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0630 20:19:23.807931  4668 solver.cpp:218] Iteration 11300 (27.3786 iter/s, 3.65248s/100 iters), loss = 0.325438
I0630 20:19:23.807931  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:19:23.807931  4668 solver.cpp:237]     Train net output #1: loss = 0.325438 (* 1 = 0.325438 loss)
I0630 20:19:23.807931  4668 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0630 20:19:27.442296  4668 solver.cpp:218] Iteration 11400 (27.5248 iter/s, 3.63308s/100 iters), loss = 0.267397
I0630 20:19:27.442296  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:19:27.442296  4668 solver.cpp:237]     Train net output #1: loss = 0.267397 (* 1 = 0.267397 loss)
I0630 20:19:27.442296  4668 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0630 20:19:30.905045 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:19:31.044747  4668 solver.cpp:330] Iteration 11500, Testing net (#0)
I0630 20:19:31.044747  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:19:31.875670  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:19:31.905702  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8114
I0630 20:19:31.905702  4668 solver.cpp:397]     Test net output #1: loss = 0.570741 (* 1 = 0.570741 loss)
I0630 20:19:31.935814  4668 solver.cpp:218] Iteration 11500 (22.2534 iter/s, 4.49369s/100 iters), loss = 0.309264
I0630 20:19:31.935814  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:19:31.935814  4668 solver.cpp:237]     Train net output #1: loss = 0.309264 (* 1 = 0.309264 loss)
I0630 20:19:31.935814  4668 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0630 20:19:35.583706  4668 solver.cpp:218] Iteration 11600 (27.4775 iter/s, 3.63934s/100 iters), loss = 0.36719
I0630 20:19:35.583706  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 20:19:35.583706  4668 solver.cpp:237]     Train net output #1: loss = 0.36719 (* 1 = 0.36719 loss)
I0630 20:19:35.583706  4668 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0630 20:19:39.209017  4668 solver.cpp:218] Iteration 11700 (27.5717 iter/s, 3.6269s/100 iters), loss = 0.44854
I0630 20:19:39.209017  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 20:19:39.209017  4668 solver.cpp:237]     Train net output #1: loss = 0.44854 (* 1 = 0.44854 loss)
I0630 20:19:39.209017  4668 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0630 20:19:42.852762  4668 solver.cpp:218] Iteration 11800 (27.4468 iter/s, 3.64341s/100 iters), loss = 0.359149
I0630 20:19:42.852762  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:19:42.852762  4668 solver.cpp:237]     Train net output #1: loss = 0.359149 (* 1 = 0.359149 loss)
I0630 20:19:42.852762  4668 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0630 20:19:46.474316  4668 solver.cpp:218] Iteration 11900 (27.5574 iter/s, 3.62879s/100 iters), loss = 0.294684
I0630 20:19:46.474316  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:19:46.474316  4668 solver.cpp:237]     Train net output #1: loss = 0.294684 (* 1 = 0.294684 loss)
I0630 20:19:46.474316  4668 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0630 20:19:49.936403 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:19:50.081643  4668 solver.cpp:330] Iteration 12000, Testing net (#0)
I0630 20:19:50.081643  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:19:50.899073  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:19:50.928122  4668 solver.cpp:397]     Test net output #0: accuracy = 0.807
I0630 20:19:50.928122  4668 solver.cpp:397]     Test net output #1: loss = 0.574033 (* 1 = 0.574033 loss)
I0630 20:19:50.968113  4668 solver.cpp:218] Iteration 12000 (22.2824 iter/s, 4.48784s/100 iters), loss = 0.427634
I0630 20:19:50.968113  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:19:50.968113  4668 solver.cpp:237]     Train net output #1: loss = 0.427634 (* 1 = 0.427634 loss)
I0630 20:19:50.968113  4668 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0630 20:19:54.613862  4668 solver.cpp:218] Iteration 12100 (27.4597 iter/s, 3.6417s/100 iters), loss = 0.384161
I0630 20:19:54.613862  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:19:54.614363  4668 solver.cpp:237]     Train net output #1: loss = 0.384161 (* 1 = 0.384161 loss)
I0630 20:19:54.614363  4668 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0630 20:19:58.365254  4668 solver.cpp:218] Iteration 12200 (26.6123 iter/s, 3.75766s/100 iters), loss = 0.26781
I0630 20:19:58.365254  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:19:58.365254  4668 solver.cpp:237]     Train net output #1: loss = 0.26781 (* 1 = 0.26781 loss)
I0630 20:19:58.365254  4668 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0630 20:20:02.127223  4668 solver.cpp:218] Iteration 12300 (26.6321 iter/s, 3.75487s/100 iters), loss = 0.340535
I0630 20:20:02.127223  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:20:02.127223  4668 solver.cpp:237]     Train net output #1: loss = 0.340535 (* 1 = 0.340535 loss)
I0630 20:20:02.127223  4668 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0630 20:20:05.798246  4668 solver.cpp:218] Iteration 12400 (27.2197 iter/s, 3.67381s/100 iters), loss = 0.293229
I0630 20:20:05.798246  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:20:05.798246  4668 solver.cpp:237]     Train net output #1: loss = 0.293229 (* 1 = 0.293229 loss)
I0630 20:20:05.798246  4668 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0630 20:20:09.270352 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:20:09.421826  4668 solver.cpp:330] Iteration 12500, Testing net (#0)
I0630 20:20:09.421826  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:20:10.245611  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:20:10.275630  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8177
I0630 20:20:10.275630  4668 solver.cpp:397]     Test net output #1: loss = 0.547935 (* 1 = 0.547935 loss)
I0630 20:20:10.307258  4668 solver.cpp:218] Iteration 12500 (22.1744 iter/s, 4.5097s/100 iters), loss = 0.31572
I0630 20:20:10.307258  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:20:10.307258  4668 solver.cpp:237]     Train net output #1: loss = 0.31572 (* 1 = 0.31572 loss)
I0630 20:20:10.307258  4668 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0630 20:20:13.931673  4668 solver.cpp:218] Iteration 12600 (27.6266 iter/s, 3.6197s/100 iters), loss = 0.295244
I0630 20:20:13.931673  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:20:13.931673  4668 solver.cpp:237]     Train net output #1: loss = 0.295244 (* 1 = 0.295244 loss)
I0630 20:20:13.931673  4668 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0630 20:20:17.605149  4668 solver.cpp:218] Iteration 12700 (27.2253 iter/s, 3.67306s/100 iters), loss = 0.400732
I0630 20:20:17.605149  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:20:17.605149  4668 solver.cpp:237]     Train net output #1: loss = 0.400732 (* 1 = 0.400732 loss)
I0630 20:20:17.605149  4668 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0630 20:20:21.322329  4668 solver.cpp:218] Iteration 12800 (26.8647 iter/s, 3.72236s/100 iters), loss = 0.359215
I0630 20:20:21.322329  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:20:21.322329  4668 solver.cpp:237]     Train net output #1: loss = 0.359215 (* 1 = 0.359215 loss)
I0630 20:20:21.322329  4668 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0630 20:20:24.954880  4668 solver.cpp:218] Iteration 12900 (27.5178 iter/s, 3.63402s/100 iters), loss = 0.195355
I0630 20:20:24.954880  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:20:24.954880  4668 solver.cpp:237]     Train net output #1: loss = 0.195355 (* 1 = 0.195355 loss)
I0630 20:20:24.954880  4668 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0630 20:20:28.440834 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:20:28.582031  4668 solver.cpp:330] Iteration 13000, Testing net (#0)
I0630 20:20:28.582031  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:20:29.406085  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:20:29.440099  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8195
I0630 20:20:29.440593  4668 solver.cpp:397]     Test net output #1: loss = 0.546571 (* 1 = 0.546571 loss)
I0630 20:20:29.474740  4668 solver.cpp:218] Iteration 13000 (22.1609 iter/s, 4.51245s/100 iters), loss = 0.318286
I0630 20:20:29.474740  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:20:29.474740  4668 solver.cpp:237]     Train net output #1: loss = 0.318286 (* 1 = 0.318286 loss)
I0630 20:20:29.474740  4668 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0630 20:20:33.180284  4668 solver.cpp:218] Iteration 13100 (26.9925 iter/s, 3.70473s/100 iters), loss = 0.33854
I0630 20:20:33.180284  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:20:33.180284  4668 solver.cpp:237]     Train net output #1: loss = 0.33854 (* 1 = 0.33854 loss)
I0630 20:20:33.180284  4668 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0630 20:20:36.808454  4668 solver.cpp:218] Iteration 13200 (27.5163 iter/s, 3.63421s/100 iters), loss = 0.343354
I0630 20:20:36.808454  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:20:36.808454  4668 solver.cpp:237]     Train net output #1: loss = 0.343354 (* 1 = 0.343354 loss)
I0630 20:20:36.808454  4668 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0630 20:20:40.487257  4668 solver.cpp:218] Iteration 13300 (27.2337 iter/s, 3.67192s/100 iters), loss = 0.31276
I0630 20:20:40.487257  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:20:40.487257  4668 solver.cpp:237]     Train net output #1: loss = 0.31276 (* 1 = 0.31276 loss)
I0630 20:20:40.487257  4668 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0630 20:20:44.138702  4668 solver.cpp:218] Iteration 13400 (27.3182 iter/s, 3.66057s/100 iters), loss = 0.294223
I0630 20:20:44.138702  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:20:44.138702  4668 solver.cpp:237]     Train net output #1: loss = 0.294223 (* 1 = 0.294223 loss)
I0630 20:20:44.138702  4668 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0630 20:20:47.595600 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:20:47.732676  4668 solver.cpp:330] Iteration 13500, Testing net (#0)
I0630 20:20:47.732676  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:20:48.553069  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:20:48.592727  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8301
I0630 20:20:48.592727  4668 solver.cpp:397]     Test net output #1: loss = 0.511454 (* 1 = 0.511454 loss)
I0630 20:20:48.622772  4668 solver.cpp:218] Iteration 13500 (22.3268 iter/s, 4.47891s/100 iters), loss = 0.373018
I0630 20:20:48.622772  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:20:48.622772  4668 solver.cpp:237]     Train net output #1: loss = 0.373018 (* 1 = 0.373018 loss)
I0630 20:20:48.622772  4668 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0630 20:20:52.267228  4668 solver.cpp:218] Iteration 13600 (27.4714 iter/s, 3.64015s/100 iters), loss = 0.319863
I0630 20:20:52.267228  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:20:52.267228  4668 solver.cpp:237]     Train net output #1: loss = 0.319863 (* 1 = 0.319863 loss)
I0630 20:20:52.267228  4668 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0630 20:20:55.908263  4668 solver.cpp:218] Iteration 13700 (27.473 iter/s, 3.63994s/100 iters), loss = 0.351985
I0630 20:20:55.908263  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:20:55.908263  4668 solver.cpp:237]     Train net output #1: loss = 0.351985 (* 1 = 0.351985 loss)
I0630 20:20:55.908263  4668 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0630 20:20:59.549424  4668 solver.cpp:218] Iteration 13800 (27.404 iter/s, 3.64911s/100 iters), loss = 0.268211
I0630 20:20:59.549424  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:20:59.549424  4668 solver.cpp:237]     Train net output #1: loss = 0.268211 (* 1 = 0.268211 loss)
I0630 20:20:59.549424  4668 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0630 20:21:03.191691  4668 solver.cpp:218] Iteration 13900 (27.473 iter/s, 3.63993s/100 iters), loss = 0.306453
I0630 20:21:03.191691  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:21:03.191691  4668 solver.cpp:237]     Train net output #1: loss = 0.306453 (* 1 = 0.306453 loss)
I0630 20:21:03.191691  4668 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0630 20:21:06.653162 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:21:06.793180  4668 solver.cpp:330] Iteration 14000, Testing net (#0)
I0630 20:21:06.793180  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:21:07.623461  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:21:07.653463  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8383
I0630 20:21:07.653463  4668 solver.cpp:397]     Test net output #1: loss = 0.482379 (* 1 = 0.482379 loss)
I0630 20:21:07.683465  4668 solver.cpp:218] Iteration 14000 (22.2604 iter/s, 4.49227s/100 iters), loss = 0.274903
I0630 20:21:07.683465  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:21:07.683465  4668 solver.cpp:237]     Train net output #1: loss = 0.274904 (* 1 = 0.274904 loss)
I0630 20:21:07.683465  4668 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0630 20:21:11.344926  4668 solver.cpp:218] Iteration 14100 (27.3664 iter/s, 3.65411s/100 iters), loss = 0.404013
I0630 20:21:11.344926  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:21:11.344926  4668 solver.cpp:237]     Train net output #1: loss = 0.404014 (* 1 = 0.404014 loss)
I0630 20:21:11.344926  4668 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0630 20:21:15.018250  4668 solver.cpp:218] Iteration 14200 (27.1629 iter/s, 3.6815s/100 iters), loss = 0.392842
I0630 20:21:15.018250  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:21:15.018250  4668 solver.cpp:237]     Train net output #1: loss = 0.392842 (* 1 = 0.392842 loss)
I0630 20:21:15.018250  4668 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0630 20:21:18.739060  4668 solver.cpp:218] Iteration 14300 (26.9045 iter/s, 3.71685s/100 iters), loss = 0.329159
I0630 20:21:18.739060  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:21:18.739060  4668 solver.cpp:237]     Train net output #1: loss = 0.329159 (* 1 = 0.329159 loss)
I0630 20:21:18.739060  4668 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0630 20:21:22.389832  4668 solver.cpp:218] Iteration 14400 (27.4151 iter/s, 3.64762s/100 iters), loss = 0.301421
I0630 20:21:22.389832  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:21:22.389832  4668 solver.cpp:237]     Train net output #1: loss = 0.301421 (* 1 = 0.301421 loss)
I0630 20:21:22.389832  4668 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0630 20:21:25.850169 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:21:25.990191  4668 solver.cpp:330] Iteration 14500, Testing net (#0)
I0630 20:21:25.990191  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:21:26.822726  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:21:26.850239  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8243
I0630 20:21:26.850239  4668 solver.cpp:397]     Test net output #1: loss = 0.533745 (* 1 = 0.533745 loss)
I0630 20:21:26.880240  4668 solver.cpp:218] Iteration 14500 (22.2355 iter/s, 4.4973s/100 iters), loss = 0.293911
I0630 20:21:26.880240  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:21:26.880240  4668 solver.cpp:237]     Train net output #1: loss = 0.293911 (* 1 = 0.293911 loss)
I0630 20:21:26.880240  4668 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0630 20:21:30.521054  4668 solver.cpp:218] Iteration 14600 (27.5216 iter/s, 3.63351s/100 iters), loss = 0.363624
I0630 20:21:30.521054  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:21:30.521054  4668 solver.cpp:237]     Train net output #1: loss = 0.363624 (* 1 = 0.363624 loss)
I0630 20:21:30.521054  4668 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0630 20:21:34.151880  4668 solver.cpp:218] Iteration 14700 (27.5515 iter/s, 3.62957s/100 iters), loss = 0.322531
I0630 20:21:34.151880  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:21:34.151880  4668 solver.cpp:237]     Train net output #1: loss = 0.322531 (* 1 = 0.322531 loss)
I0630 20:21:34.151880  4668 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0630 20:21:37.783295  4668 solver.cpp:218] Iteration 14800 (27.5528 iter/s, 3.6294s/100 iters), loss = 0.34037
I0630 20:21:37.783295  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:21:37.783295  4668 solver.cpp:237]     Train net output #1: loss = 0.34037 (* 1 = 0.34037 loss)
I0630 20:21:37.783295  4668 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0630 20:21:41.415251  4668 solver.cpp:218] Iteration 14900 (27.4845 iter/s, 3.63841s/100 iters), loss = 0.237719
I0630 20:21:41.415251  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:21:41.415251  4668 solver.cpp:237]     Train net output #1: loss = 0.237719 (* 1 = 0.237719 loss)
I0630 20:21:41.415251  4668 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0630 20:21:44.875545 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:21:45.025575  4668 solver.cpp:330] Iteration 15000, Testing net (#0)
I0630 20:21:45.025575  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:21:45.846271  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:21:45.876274  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8326
I0630 20:21:45.876274  4668 solver.cpp:397]     Test net output #1: loss = 0.512457 (* 1 = 0.512457 loss)
I0630 20:21:45.920414  4668 solver.cpp:218] Iteration 15000 (22.2326 iter/s, 4.4979s/100 iters), loss = 0.305158
I0630 20:21:45.920414  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:21:45.920414  4668 solver.cpp:237]     Train net output #1: loss = 0.305158 (* 1 = 0.305158 loss)
I0630 20:21:45.920414  4668 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0630 20:21:49.572242  4668 solver.cpp:218] Iteration 15100 (27.3868 iter/s, 3.65139s/100 iters), loss = 0.265725
I0630 20:21:49.572242  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:21:49.572242  4668 solver.cpp:237]     Train net output #1: loss = 0.265725 (* 1 = 0.265725 loss)
I0630 20:21:49.572242  4668 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0630 20:21:53.300532  4668 solver.cpp:218] Iteration 15200 (26.8212 iter/s, 3.7284s/100 iters), loss = 0.298699
I0630 20:21:53.300532  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:21:53.301532  4668 solver.cpp:237]     Train net output #1: loss = 0.298699 (* 1 = 0.298699 loss)
I0630 20:21:53.301532  4668 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0630 20:21:56.945039  4668 solver.cpp:218] Iteration 15300 (27.4473 iter/s, 3.64335s/100 iters), loss = 0.327323
I0630 20:21:56.945039  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:21:56.945039  4668 solver.cpp:237]     Train net output #1: loss = 0.327323 (* 1 = 0.327323 loss)
I0630 20:21:56.945039  4668 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0630 20:22:00.654299  4668 solver.cpp:218] Iteration 15400 (26.9266 iter/s, 3.7138s/100 iters), loss = 0.279309
I0630 20:22:00.654299  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:22:00.654299  4668 solver.cpp:237]     Train net output #1: loss = 0.279309 (* 1 = 0.279309 loss)
I0630 20:22:00.654299  4668 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0630 20:22:04.156339 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:22:04.304023  4668 solver.cpp:330] Iteration 15500, Testing net (#0)
I0630 20:22:04.304023  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:22:05.126786  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:22:05.156788  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8223
I0630 20:22:05.156788  4668 solver.cpp:397]     Test net output #1: loss = 0.549487 (* 1 = 0.549487 loss)
I0630 20:22:05.197882  4668 solver.cpp:218] Iteration 15500 (22.035 iter/s, 4.53824s/100 iters), loss = 0.390639
I0630 20:22:05.197882  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:22:05.197882  4668 solver.cpp:237]     Train net output #1: loss = 0.39064 (* 1 = 0.39064 loss)
I0630 20:22:05.197882  4668 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0630 20:22:08.839138  4668 solver.cpp:218] Iteration 15600 (27.4551 iter/s, 3.6423s/100 iters), loss = 0.328447
I0630 20:22:08.839138  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:22:08.839138  4668 solver.cpp:237]     Train net output #1: loss = 0.328447 (* 1 = 0.328447 loss)
I0630 20:22:08.839138  4668 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0630 20:22:12.463959  4668 solver.cpp:218] Iteration 15700 (27.5413 iter/s, 3.6309s/100 iters), loss = 0.324207
I0630 20:22:12.463959  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0630 20:22:12.463959  4668 solver.cpp:237]     Train net output #1: loss = 0.324207 (* 1 = 0.324207 loss)
I0630 20:22:12.463959  4668 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0630 20:22:16.113543  4668 solver.cpp:218] Iteration 15800 (27.4599 iter/s, 3.64167s/100 iters), loss = 0.347967
I0630 20:22:16.113543  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:22:16.113543  4668 solver.cpp:237]     Train net output #1: loss = 0.347967 (* 1 = 0.347967 loss)
I0630 20:22:16.113543  4668 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0630 20:22:19.743963  4668 solver.cpp:218] Iteration 15900 (27.5479 iter/s, 3.63003s/100 iters), loss = 0.265565
I0630 20:22:19.743963  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:22:19.743963  4668 solver.cpp:237]     Train net output #1: loss = 0.265566 (* 1 = 0.265566 loss)
I0630 20:22:19.743963  4668 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0630 20:22:23.214732 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:22:23.356094  4668 solver.cpp:330] Iteration 16000, Testing net (#0)
I0630 20:22:23.356094  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:22:24.186399  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:22:24.215420  4668 solver.cpp:397]     Test net output #0: accuracy = 0.835
I0630 20:22:24.215420  4668 solver.cpp:397]     Test net output #1: loss = 0.497732 (* 1 = 0.497732 loss)
I0630 20:22:24.245422  4668 solver.cpp:218] Iteration 16000 (22.1798 iter/s, 4.50862s/100 iters), loss = 0.2832
I0630 20:22:24.245422  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:22:24.245422  4668 solver.cpp:237]     Train net output #1: loss = 0.2832 (* 1 = 0.2832 loss)
I0630 20:22:24.245422  4668 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0630 20:22:27.876421  4668 solver.cpp:218] Iteration 16100 (27.5634 iter/s, 3.628s/100 iters), loss = 0.295378
I0630 20:22:27.876421  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:22:27.876421  4668 solver.cpp:237]     Train net output #1: loss = 0.295378 (* 1 = 0.295378 loss)
I0630 20:22:27.876421  4668 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0630 20:22:31.592110  4668 solver.cpp:218] Iteration 16200 (26.9121 iter/s, 3.7158s/100 iters), loss = 0.308986
I0630 20:22:31.592110  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:22:31.592110  4668 solver.cpp:237]     Train net output #1: loss = 0.308986 (* 1 = 0.308986 loss)
I0630 20:22:31.592110  4668 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0630 20:22:35.281975  4668 solver.cpp:218] Iteration 16300 (27.1446 iter/s, 3.68397s/100 iters), loss = 0.287552
I0630 20:22:35.281975  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:22:35.281975  4668 solver.cpp:237]     Train net output #1: loss = 0.287552 (* 1 = 0.287552 loss)
I0630 20:22:35.281975  4668 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0630 20:22:38.991281  4668 solver.cpp:218] Iteration 16400 (26.9088 iter/s, 3.71626s/100 iters), loss = 0.313464
I0630 20:22:38.991281  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:22:38.991281  4668 solver.cpp:237]     Train net output #1: loss = 0.313464 (* 1 = 0.313464 loss)
I0630 20:22:38.991281  4668 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0630 20:22:42.454020 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:22:42.601954  4668 solver.cpp:330] Iteration 16500, Testing net (#0)
I0630 20:22:42.601954  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:22:43.431347  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:22:43.461350  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8352
I0630 20:22:43.461350  4668 solver.cpp:397]     Test net output #1: loss = 0.511135 (* 1 = 0.511135 loss)
I0630 20:22:43.501353  4668 solver.cpp:218] Iteration 16500 (22.2014 iter/s, 4.50423s/100 iters), loss = 0.397224
I0630 20:22:43.501353  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:22:43.501353  4668 solver.cpp:237]     Train net output #1: loss = 0.397224 (* 1 = 0.397224 loss)
I0630 20:22:43.501353  4668 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0630 20:22:47.132284  4668 solver.cpp:218] Iteration 16600 (27.5035 iter/s, 3.6359s/100 iters), loss = 0.33652
I0630 20:22:47.132284  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:22:47.132284  4668 solver.cpp:237]     Train net output #1: loss = 0.33652 (* 1 = 0.33652 loss)
I0630 20:22:47.132284  4668 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0630 20:22:50.784114  4668 solver.cpp:218] Iteration 16700 (27.4137 iter/s, 3.6478s/100 iters), loss = 0.28387
I0630 20:22:50.784114  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:22:50.784114  4668 solver.cpp:237]     Train net output #1: loss = 0.283871 (* 1 = 0.283871 loss)
I0630 20:22:50.784114  4668 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0630 20:22:54.525988  4668 solver.cpp:218] Iteration 16800 (26.7407 iter/s, 3.73961s/100 iters), loss = 0.335155
I0630 20:22:54.525988  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:22:54.525988  4668 solver.cpp:237]     Train net output #1: loss = 0.335155 (* 1 = 0.335155 loss)
I0630 20:22:54.525988  4668 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0630 20:22:58.267376  4668 solver.cpp:218] Iteration 16900 (26.731 iter/s, 3.74097s/100 iters), loss = 0.263658
I0630 20:22:58.267376  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:22:58.267376  4668 solver.cpp:237]     Train net output #1: loss = 0.263658 (* 1 = 0.263658 loss)
I0630 20:22:58.267376  4668 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0630 20:23:01.823750 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:23:01.958921  4668 solver.cpp:330] Iteration 17000, Testing net (#0)
I0630 20:23:01.958921  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:23:02.799268  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:23:02.829278  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8405
I0630 20:23:02.829278  4668 solver.cpp:397]     Test net output #1: loss = 0.495048 (* 1 = 0.495048 loss)
I0630 20:23:02.859282  4668 solver.cpp:218] Iteration 17000 (21.7575 iter/s, 4.59612s/100 iters), loss = 0.249274
I0630 20:23:02.859282  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:23:02.859282  4668 solver.cpp:237]     Train net output #1: loss = 0.249274 (* 1 = 0.249274 loss)
I0630 20:23:02.859282  4668 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0630 20:23:06.524462  4668 solver.cpp:218] Iteration 17100 (27.3313 iter/s, 3.65881s/100 iters), loss = 0.291906
I0630 20:23:06.524462  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:23:06.524462  4668 solver.cpp:237]     Train net output #1: loss = 0.291907 (* 1 = 0.291907 loss)
I0630 20:23:06.524462  4668 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0630 20:23:10.162884  4668 solver.cpp:218] Iteration 17200 (27.4816 iter/s, 3.6388s/100 iters), loss = 0.336285
I0630 20:23:10.162884  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:23:10.162884  4668 solver.cpp:237]     Train net output #1: loss = 0.336285 (* 1 = 0.336285 loss)
I0630 20:23:10.162884  4668 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0630 20:23:13.784790  4668 solver.cpp:218] Iteration 17300 (27.5803 iter/s, 3.62577s/100 iters), loss = 0.219627
I0630 20:23:13.784790  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:23:13.784790  4668 solver.cpp:237]     Train net output #1: loss = 0.219627 (* 1 = 0.219627 loss)
I0630 20:23:13.784790  4668 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0630 20:23:17.406492  4668 solver.cpp:218] Iteration 17400 (27.5959 iter/s, 3.62373s/100 iters), loss = 0.286926
I0630 20:23:17.406492  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:23:17.406492  4668 solver.cpp:237]     Train net output #1: loss = 0.286926 (* 1 = 0.286926 loss)
I0630 20:23:17.406492  4668 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0630 20:23:20.877259 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:23:21.017279  4668 solver.cpp:330] Iteration 17500, Testing net (#0)
I0630 20:23:21.017279  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:23:21.847474  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:23:21.877486  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8344
I0630 20:23:21.877486  4668 solver.cpp:397]     Test net output #1: loss = 0.517365 (* 1 = 0.517365 loss)
I0630 20:23:21.917479  4668 solver.cpp:218] Iteration 17500 (22.1918 iter/s, 4.50617s/100 iters), loss = 0.257818
I0630 20:23:21.917479  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:23:21.917479  4668 solver.cpp:237]     Train net output #1: loss = 0.257819 (* 1 = 0.257819 loss)
I0630 20:23:21.917479  4668 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0630 20:23:25.571039  4668 solver.cpp:218] Iteration 17600 (27.3907 iter/s, 3.65088s/100 iters), loss = 0.289542
I0630 20:23:25.571039  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:23:25.571039  4668 solver.cpp:237]     Train net output #1: loss = 0.289543 (* 1 = 0.289543 loss)
I0630 20:23:25.571039  4668 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0630 20:23:29.222534  4668 solver.cpp:218] Iteration 17700 (27.3742 iter/s, 3.65307s/100 iters), loss = 0.233879
I0630 20:23:29.222534  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:23:29.222534  4668 solver.cpp:237]     Train net output #1: loss = 0.233879 (* 1 = 0.233879 loss)
I0630 20:23:29.222534  4668 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0630 20:23:32.872905  4668 solver.cpp:218] Iteration 17800 (27.4087 iter/s, 3.64847s/100 iters), loss = 0.317226
I0630 20:23:32.872905  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:23:32.872905  4668 solver.cpp:237]     Train net output #1: loss = 0.317226 (* 1 = 0.317226 loss)
I0630 20:23:32.872905  4668 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0630 20:23:36.612313  4668 solver.cpp:218] Iteration 17900 (26.7283 iter/s, 3.74135s/100 iters), loss = 0.275361
I0630 20:23:36.612313  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:23:36.612313  4668 solver.cpp:237]     Train net output #1: loss = 0.275362 (* 1 = 0.275362 loss)
I0630 20:23:36.612313  4668 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0630 20:23:40.078063 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:23:40.216434  4668 solver.cpp:330] Iteration 18000, Testing net (#0)
I0630 20:23:40.216434  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:23:41.056169  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:23:41.090193  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8243
I0630 20:23:41.090193  4668 solver.cpp:397]     Test net output #1: loss = 0.557554 (* 1 = 0.557554 loss)
I0630 20:23:41.121465  4668 solver.cpp:218] Iteration 18000 (22.1772 iter/s, 4.50914s/100 iters), loss = 0.3298
I0630 20:23:41.121465  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:23:41.121465  4668 solver.cpp:237]     Train net output #1: loss = 0.3298 (* 1 = 0.3298 loss)
I0630 20:23:41.121465  4668 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0630 20:23:44.858333  4668 solver.cpp:218] Iteration 18100 (26.7348 iter/s, 3.74044s/100 iters), loss = 0.359996
I0630 20:23:44.858333  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:23:44.858333  4668 solver.cpp:237]     Train net output #1: loss = 0.359996 (* 1 = 0.359996 loss)
I0630 20:23:44.858333  4668 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0630 20:23:48.505533  4668 solver.cpp:218] Iteration 18200 (27.4549 iter/s, 3.64234s/100 iters), loss = 0.306185
I0630 20:23:48.505533  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0630 20:23:48.505533  4668 solver.cpp:237]     Train net output #1: loss = 0.306185 (* 1 = 0.306185 loss)
I0630 20:23:48.505533  4668 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0630 20:23:52.134156  4668 solver.cpp:218] Iteration 18300 (27.5589 iter/s, 3.62859s/100 iters), loss = 0.257052
I0630 20:23:52.134156  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:23:52.134156  4668 solver.cpp:237]     Train net output #1: loss = 0.257052 (* 1 = 0.257052 loss)
I0630 20:23:52.134156  4668 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0630 20:23:55.775475  4668 solver.cpp:218] Iteration 18400 (27.4847 iter/s, 3.63839s/100 iters), loss = 0.317245
I0630 20:23:55.775475  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:23:55.775475  4668 solver.cpp:237]     Train net output #1: loss = 0.317245 (* 1 = 0.317245 loss)
I0630 20:23:55.775475  4668 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0630 20:23:59.238287 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:23:59.378175  4668 solver.cpp:330] Iteration 18500, Testing net (#0)
I0630 20:23:59.378175  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:24:00.208689  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:24:00.248695  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8456
I0630 20:24:00.248695  4668 solver.cpp:397]     Test net output #1: loss = 0.483777 (* 1 = 0.483777 loss)
I0630 20:24:00.283040  4668 solver.cpp:218] Iteration 18500 (22.1903 iter/s, 4.50646s/100 iters), loss = 0.232804
I0630 20:24:00.283040  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:24:00.283040  4668 solver.cpp:237]     Train net output #1: loss = 0.232804 (* 1 = 0.232804 loss)
I0630 20:24:00.283040  4668 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0630 20:24:03.941535  4668 solver.cpp:218] Iteration 18600 (27.3229 iter/s, 3.65993s/100 iters), loss = 0.253605
I0630 20:24:03.941535  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:24:03.941535  4668 solver.cpp:237]     Train net output #1: loss = 0.253605 (* 1 = 0.253605 loss)
I0630 20:24:03.941535  4668 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0630 20:24:07.591794  4668 solver.cpp:218] Iteration 18700 (27.3591 iter/s, 3.6551s/100 iters), loss = 0.269789
I0630 20:24:07.591794  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:24:07.591794  4668 solver.cpp:237]     Train net output #1: loss = 0.26979 (* 1 = 0.26979 loss)
I0630 20:24:07.591794  4668 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0630 20:24:11.245054  4668 solver.cpp:218] Iteration 18800 (27.4185 iter/s, 3.64717s/100 iters), loss = 0.264335
I0630 20:24:11.245054  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:24:11.245054  4668 solver.cpp:237]     Train net output #1: loss = 0.264335 (* 1 = 0.264335 loss)
I0630 20:24:11.245054  4668 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0630 20:24:14.938124  4668 solver.cpp:218] Iteration 18900 (27.0637 iter/s, 3.69499s/100 iters), loss = 0.256905
I0630 20:24:14.938124  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:24:14.938124  4668 solver.cpp:237]     Train net output #1: loss = 0.256905 (* 1 = 0.256905 loss)
I0630 20:24:14.938124  4668 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0630 20:24:18.439170 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:24:18.589314  4668 solver.cpp:330] Iteration 19000, Testing net (#0)
I0630 20:24:18.589314  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:24:19.413120  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:24:19.440129  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8337
I0630 20:24:19.440129  4668 solver.cpp:397]     Test net output #1: loss = 0.509182 (* 1 = 0.509182 loss)
I0630 20:24:19.470131  4668 solver.cpp:218] Iteration 19000 (22.0434 iter/s, 4.5365s/100 iters), loss = 0.230247
I0630 20:24:19.470131  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:24:19.470131  4668 solver.cpp:237]     Train net output #1: loss = 0.230247 (* 1 = 0.230247 loss)
I0630 20:24:19.470131  4668 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0630 20:24:23.141108  4668 solver.cpp:218] Iteration 19100 (27.3007 iter/s, 3.66291s/100 iters), loss = 0.258068
I0630 20:24:23.141108  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:24:23.141108  4668 solver.cpp:237]     Train net output #1: loss = 0.258068 (* 1 = 0.258068 loss)
I0630 20:24:23.141108  4668 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0630 20:24:26.820663  4668 solver.cpp:218] Iteration 19200 (27.144 iter/s, 3.68406s/100 iters), loss = 0.305001
I0630 20:24:26.820663  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:24:26.820663  4668 solver.cpp:237]     Train net output #1: loss = 0.305001 (* 1 = 0.305001 loss)
I0630 20:24:26.820663  4668 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0630 20:24:30.592121  4668 solver.cpp:218] Iteration 19300 (26.5062 iter/s, 3.77271s/100 iters), loss = 0.302693
I0630 20:24:30.592121  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:24:30.592121  4668 solver.cpp:237]     Train net output #1: loss = 0.302694 (* 1 = 0.302694 loss)
I0630 20:24:30.592121  4668 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0630 20:24:34.284435  4668 solver.cpp:218] Iteration 19400 (27.1378 iter/s, 3.6849s/100 iters), loss = 0.298255
I0630 20:24:34.284435  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:24:34.284435  4668 solver.cpp:237]     Train net output #1: loss = 0.298255 (* 1 = 0.298255 loss)
I0630 20:24:34.284435  4668 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0630 20:24:37.763433 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:24:37.903452  4668 solver.cpp:330] Iteration 19500, Testing net (#0)
I0630 20:24:37.903452  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:24:38.733734  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:24:38.763736  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8405
I0630 20:24:38.763736  4668 solver.cpp:397]     Test net output #1: loss = 0.485372 (* 1 = 0.485372 loss)
I0630 20:24:38.793737  4668 solver.cpp:218] Iteration 19500 (22.1478 iter/s, 4.51513s/100 iters), loss = 0.249439
I0630 20:24:38.793737  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:24:38.793737  4668 solver.cpp:237]     Train net output #1: loss = 0.24944 (* 1 = 0.24944 loss)
I0630 20:24:38.793737  4668 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0630 20:24:42.447582  4668 solver.cpp:218] Iteration 19600 (27.3665 iter/s, 3.6541s/100 iters), loss = 0.309083
I0630 20:24:42.447582  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:24:42.447582  4668 solver.cpp:237]     Train net output #1: loss = 0.309083 (* 1 = 0.309083 loss)
I0630 20:24:42.447582  4668 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0630 20:24:46.101660  4668 solver.cpp:218] Iteration 19700 (27.3938 iter/s, 3.65046s/100 iters), loss = 0.32819
I0630 20:24:46.101660  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:24:46.101660  4668 solver.cpp:237]     Train net output #1: loss = 0.32819 (* 1 = 0.32819 loss)
I0630 20:24:46.101660  4668 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0630 20:24:49.738890  4668 solver.cpp:218] Iteration 19800 (27.4755 iter/s, 3.63961s/100 iters), loss = 0.232062
I0630 20:24:49.738890  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:24:49.738890  4668 solver.cpp:237]     Train net output #1: loss = 0.232063 (* 1 = 0.232063 loss)
I0630 20:24:49.738890  4668 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0630 20:24:53.371615  4668 solver.cpp:218] Iteration 19900 (27.522 iter/s, 3.63346s/100 iters), loss = 0.229638
I0630 20:24:53.371615  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:24:53.371615  4668 solver.cpp:237]     Train net output #1: loss = 0.229639 (* 1 = 0.229639 loss)
I0630 20:24:53.371615  4668 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0630 20:24:56.833035 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:24:56.973577  4668 solver.cpp:330] Iteration 20000, Testing net (#0)
I0630 20:24:56.973577  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:24:57.804219  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:24:57.834230  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8445
I0630 20:24:57.834230  4668 solver.cpp:397]     Test net output #1: loss = 0.485721 (* 1 = 0.485721 loss)
I0630 20:24:57.865393  4668 solver.cpp:218] Iteration 20000 (22.2592 iter/s, 4.49252s/100 iters), loss = 0.226322
I0630 20:24:57.865393  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:24:57.865393  4668 solver.cpp:237]     Train net output #1: loss = 0.226322 (* 1 = 0.226322 loss)
I0630 20:24:57.865393  4668 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0630 20:25:01.506148  4668 solver.cpp:218] Iteration 20100 (27.4711 iter/s, 3.64019s/100 iters), loss = 0.25594
I0630 20:25:01.506148  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:25:01.506148  4668 solver.cpp:237]     Train net output #1: loss = 0.25594 (* 1 = 0.25594 loss)
I0630 20:25:01.506148  4668 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0630 20:25:05.137548  4668 solver.cpp:218] Iteration 20200 (27.5311 iter/s, 3.63226s/100 iters), loss = 0.25537
I0630 20:25:05.137548  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:25:05.137548  4668 solver.cpp:237]     Train net output #1: loss = 0.25537 (* 1 = 0.25537 loss)
I0630 20:25:05.137548  4668 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0630 20:25:08.778692  4668 solver.cpp:218] Iteration 20300 (27.4681 iter/s, 3.64058s/100 iters), loss = 0.253058
I0630 20:25:08.778692  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:25:08.778692  4668 solver.cpp:237]     Train net output #1: loss = 0.253059 (* 1 = 0.253059 loss)
I0630 20:25:08.778692  4668 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0630 20:25:12.421044  4668 solver.cpp:218] Iteration 20400 (27.4816 iter/s, 3.6388s/100 iters), loss = 0.272023
I0630 20:25:12.421044  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:25:12.421044  4668 solver.cpp:237]     Train net output #1: loss = 0.272023 (* 1 = 0.272023 loss)
I0630 20:25:12.421044  4668 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0630 20:25:15.879909 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:25:16.019929  4668 solver.cpp:330] Iteration 20500, Testing net (#0)
I0630 20:25:16.019929  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:25:16.854019  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:25:16.884021  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8472
I0630 20:25:16.884021  4668 solver.cpp:397]     Test net output #1: loss = 0.475966 (* 1 = 0.475966 loss)
I0630 20:25:16.914022  4668 solver.cpp:218] Iteration 20500 (22.2421 iter/s, 4.49597s/100 iters), loss = 0.269929
I0630 20:25:16.914022  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:25:16.914022  4668 solver.cpp:237]     Train net output #1: loss = 0.26993 (* 1 = 0.26993 loss)
I0630 20:25:16.914022  4668 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0630 20:25:20.612632  4668 solver.cpp:218] Iteration 20600 (27.0548 iter/s, 3.6962s/100 iters), loss = 0.386742
I0630 20:25:20.612632  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0630 20:25:20.612632  4668 solver.cpp:237]     Train net output #1: loss = 0.386742 (* 1 = 0.386742 loss)
I0630 20:25:20.612632  4668 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0630 20:25:24.301367  4668 solver.cpp:218] Iteration 20700 (27.087 iter/s, 3.69181s/100 iters), loss = 0.292045
I0630 20:25:24.301367  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:25:24.301367  4668 solver.cpp:237]     Train net output #1: loss = 0.292045 (* 1 = 0.292045 loss)
I0630 20:25:24.301367  4668 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0630 20:25:27.953253  4668 solver.cpp:218] Iteration 20800 (27.4046 iter/s, 3.64902s/100 iters), loss = 0.293273
I0630 20:25:27.953253  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:25:27.953253  4668 solver.cpp:237]     Train net output #1: loss = 0.293273 (* 1 = 0.293273 loss)
I0630 20:25:27.953253  4668 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0630 20:25:31.592821  4668 solver.cpp:218] Iteration 20900 (27.4801 iter/s, 3.63899s/100 iters), loss = 0.232561
I0630 20:25:31.592821  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:25:31.592821  4668 solver.cpp:237]     Train net output #1: loss = 0.232561 (* 1 = 0.232561 loss)
I0630 20:25:31.592821  4668 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0630 20:25:35.055719 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:25:35.204924  4668 solver.cpp:330] Iteration 21000, Testing net (#0)
I0630 20:25:35.204924  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:25:36.045708  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:25:36.078830  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8413
I0630 20:25:36.078830  4668 solver.cpp:397]     Test net output #1: loss = 0.485775 (* 1 = 0.485775 loss)
I0630 20:25:36.113168  4668 solver.cpp:218] Iteration 21000 (22.1501 iter/s, 4.51465s/100 iters), loss = 0.225766
I0630 20:25:36.113168  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:25:36.113168  4668 solver.cpp:237]     Train net output #1: loss = 0.225766 (* 1 = 0.225766 loss)
I0630 20:25:36.113168  4668 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0630 20:25:39.843344  4668 solver.cpp:218] Iteration 21100 (26.819 iter/s, 3.7287s/100 iters), loss = 0.319709
I0630 20:25:39.843845  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:25:39.843845  4668 solver.cpp:237]     Train net output #1: loss = 0.319709 (* 1 = 0.319709 loss)
I0630 20:25:39.843845  4668 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0630 20:25:43.488865  4668 solver.cpp:218] Iteration 21200 (27.3939 iter/s, 3.65045s/100 iters), loss = 0.270355
I0630 20:25:43.488865  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:25:43.488865  4668 solver.cpp:237]     Train net output #1: loss = 0.270355 (* 1 = 0.270355 loss)
I0630 20:25:43.488865  4668 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0630 20:25:47.130690  4668 solver.cpp:218] Iteration 21300 (27.4488 iter/s, 3.64314s/100 iters), loss = 0.29187
I0630 20:25:47.130690  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:25:47.130690  4668 solver.cpp:237]     Train net output #1: loss = 0.29187 (* 1 = 0.29187 loss)
I0630 20:25:47.130690  4668 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0630 20:25:50.793731  4668 solver.cpp:218] Iteration 21400 (27.3015 iter/s, 3.66281s/100 iters), loss = 0.240296
I0630 20:25:50.793731  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:25:50.793731  4668 solver.cpp:237]     Train net output #1: loss = 0.240296 (* 1 = 0.240296 loss)
I0630 20:25:50.793731  4668 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0630 20:25:54.256503 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:25:54.407816  4668 solver.cpp:330] Iteration 21500, Testing net (#0)
I0630 20:25:54.407816  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:25:55.230639  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:25:55.255755  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8168
I0630 20:25:55.255755  4668 solver.cpp:397]     Test net output #1: loss = 0.594231 (* 1 = 0.594231 loss)
I0630 20:25:55.297704  4668 solver.cpp:218] Iteration 21500 (22.2403 iter/s, 4.49634s/100 iters), loss = 0.181988
I0630 20:25:55.297704  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:25:55.297704  4668 solver.cpp:237]     Train net output #1: loss = 0.181988 (* 1 = 0.181988 loss)
I0630 20:25:55.297704  4668 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0630 20:25:59.013249  4668 solver.cpp:218] Iteration 21600 (26.9167 iter/s, 3.71516s/100 iters), loss = 0.24989
I0630 20:25:59.013249  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:25:59.013249  4668 solver.cpp:237]     Train net output #1: loss = 0.24989 (* 1 = 0.24989 loss)
I0630 20:25:59.013249  4668 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0630 20:26:02.671438  4668 solver.cpp:218] Iteration 21700 (27.3115 iter/s, 3.66146s/100 iters), loss = 0.346836
I0630 20:26:02.671438  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0630 20:26:02.671438  4668 solver.cpp:237]     Train net output #1: loss = 0.346836 (* 1 = 0.346836 loss)
I0630 20:26:02.671438  4668 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0630 20:26:06.352243  4668 solver.cpp:218] Iteration 21800 (27.1369 iter/s, 3.68502s/100 iters), loss = 0.200985
I0630 20:26:06.352243  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:26:06.352243  4668 solver.cpp:237]     Train net output #1: loss = 0.200986 (* 1 = 0.200986 loss)
I0630 20:26:06.352243  4668 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0630 20:26:10.042994  4668 solver.cpp:218] Iteration 21900 (27.0899 iter/s, 3.69141s/100 iters), loss = 0.269768
I0630 20:26:10.042994  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:26:10.042994  4668 solver.cpp:237]     Train net output #1: loss = 0.269769 (* 1 = 0.269769 loss)
I0630 20:26:10.042994  4668 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0630 20:26:13.523725 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:26:13.663586  4668 solver.cpp:330] Iteration 22000, Testing net (#0)
I0630 20:26:13.663586  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:26:14.483896  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:26:14.523906  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8418
I0630 20:26:14.523906  4668 solver.cpp:397]     Test net output #1: loss = 0.486911 (* 1 = 0.486911 loss)
I0630 20:26:14.553910  4668 solver.cpp:218] Iteration 22000 (22.1914 iter/s, 4.50626s/100 iters), loss = 0.212002
I0630 20:26:14.553910  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:26:14.553910  4668 solver.cpp:237]     Train net output #1: loss = 0.212002 (* 1 = 0.212002 loss)
I0630 20:26:14.553910  4668 sgd_solver.cpp:46] MultiStep Status: Iteration 22000, step = 1
I0630 20:26:14.553910  4668 sgd_solver.cpp:105] Iteration 22000, lr = 0.001
I0630 20:26:18.364532  4668 solver.cpp:218] Iteration 22100 (26.2134 iter/s, 3.81484s/100 iters), loss = 0.230256
I0630 20:26:18.364532  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:26:18.364532  4668 solver.cpp:237]     Train net output #1: loss = 0.230256 (* 1 = 0.230256 loss)
I0630 20:26:18.364532  4668 sgd_solver.cpp:105] Iteration 22100, lr = 0.001
I0630 20:26:22.007117  4668 solver.cpp:218] Iteration 22200 (27.4817 iter/s, 3.63879s/100 iters), loss = 0.226811
I0630 20:26:22.007117  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:26:22.007117  4668 solver.cpp:237]     Train net output #1: loss = 0.226811 (* 1 = 0.226811 loss)
I0630 20:26:22.007117  4668 sgd_solver.cpp:105] Iteration 22200, lr = 0.001
I0630 20:26:25.648018  4668 solver.cpp:218] Iteration 22300 (27.475 iter/s, 3.63967s/100 iters), loss = 0.214169
I0630 20:26:25.648018  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:26:25.648018  4668 solver.cpp:237]     Train net output #1: loss = 0.214169 (* 1 = 0.214169 loss)
I0630 20:26:25.648018  4668 sgd_solver.cpp:105] Iteration 22300, lr = 0.001
I0630 20:26:29.291398  4668 solver.cpp:218] Iteration 22400 (27.4887 iter/s, 3.63785s/100 iters), loss = 0.169735
I0630 20:26:29.291398  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:26:29.291398  4668 solver.cpp:237]     Train net output #1: loss = 0.169735 (* 1 = 0.169735 loss)
I0630 20:26:29.291398  4668 sgd_solver.cpp:105] Iteration 22400, lr = 0.001
I0630 20:26:32.941218 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:26:33.092233  4668 solver.cpp:330] Iteration 22500, Testing net (#0)
I0630 20:26:33.092233  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:26:33.941323  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:26:33.971325  4668 solver.cpp:397]     Test net output #0: accuracy = 0.87
I0630 20:26:33.971325  4668 solver.cpp:397]     Test net output #1: loss = 0.406319 (* 1 = 0.406319 loss)
I0630 20:26:34.001325  4668 solver.cpp:218] Iteration 22500 (21.2016 iter/s, 4.71663s/100 iters), loss = 0.174989
I0630 20:26:34.001325  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:26:34.001325  4668 solver.cpp:237]     Train net output #1: loss = 0.17499 (* 1 = 0.17499 loss)
I0630 20:26:34.001325  4668 sgd_solver.cpp:105] Iteration 22500, lr = 0.001
I0630 20:26:37.782338  4668 solver.cpp:218] Iteration 22600 (26.4917 iter/s, 3.77477s/100 iters), loss = 0.268595
I0630 20:26:37.782338  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:26:37.782338  4668 solver.cpp:237]     Train net output #1: loss = 0.268595 (* 1 = 0.268595 loss)
I0630 20:26:37.782338  4668 sgd_solver.cpp:105] Iteration 22600, lr = 0.001
I0630 20:26:41.413339  4668 solver.cpp:218] Iteration 22700 (27.5426 iter/s, 3.63073s/100 iters), loss = 0.234984
I0630 20:26:41.413339  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:26:41.413339  4668 solver.cpp:237]     Train net output #1: loss = 0.234984 (* 1 = 0.234984 loss)
I0630 20:26:41.413339  4668 sgd_solver.cpp:105] Iteration 22700, lr = 0.001
I0630 20:26:45.055183  4668 solver.cpp:218] Iteration 22800 (27.4603 iter/s, 3.64162s/100 iters), loss = 0.135553
I0630 20:26:45.055183  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:26:45.055183  4668 solver.cpp:237]     Train net output #1: loss = 0.135553 (* 1 = 0.135553 loss)
I0630 20:26:45.055183  4668 sgd_solver.cpp:105] Iteration 22800, lr = 0.001
I0630 20:26:48.691442  4668 solver.cpp:218] Iteration 22900 (27.4825 iter/s, 3.63868s/100 iters), loss = 0.260774
I0630 20:26:48.691442  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:26:48.691442  4668 solver.cpp:237]     Train net output #1: loss = 0.260774 (* 1 = 0.260774 loss)
I0630 20:26:48.691442  4668 sgd_solver.cpp:105] Iteration 22900, lr = 0.001
I0630 20:26:52.158427 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:26:52.307595  4668 solver.cpp:330] Iteration 23000, Testing net (#0)
I0630 20:26:52.307595  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:26:53.122444  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:26:53.158956  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8714
I0630 20:26:53.158956  4668 solver.cpp:397]     Test net output #1: loss = 0.403806 (* 1 = 0.403806 loss)
I0630 20:26:53.196166  4668 solver.cpp:218] Iteration 23000 (22.2224 iter/s, 4.49996s/100 iters), loss = 0.231705
I0630 20:26:53.196166  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:26:53.196166  4668 solver.cpp:237]     Train net output #1: loss = 0.231705 (* 1 = 0.231705 loss)
I0630 20:26:53.196166  4668 sgd_solver.cpp:105] Iteration 23000, lr = 0.001
I0630 20:26:56.834695  4668 solver.cpp:218] Iteration 23100 (27.4859 iter/s, 3.63823s/100 iters), loss = 0.233013
I0630 20:26:56.834695  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:26:56.834695  4668 solver.cpp:237]     Train net output #1: loss = 0.233013 (* 1 = 0.233013 loss)
I0630 20:26:56.834695  4668 sgd_solver.cpp:105] Iteration 23100, lr = 0.001
I0630 20:27:00.472322  4668 solver.cpp:218] Iteration 23200 (27.4548 iter/s, 3.64236s/100 iters), loss = 0.164543
I0630 20:27:00.472322  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:27:00.472322  4668 solver.cpp:237]     Train net output #1: loss = 0.164543 (* 1 = 0.164543 loss)
I0630 20:27:00.472322  4668 sgd_solver.cpp:105] Iteration 23200, lr = 0.001
I0630 20:27:04.163065  4668 solver.cpp:218] Iteration 23300 (27.0758 iter/s, 3.69334s/100 iters), loss = 0.155084
I0630 20:27:04.163065  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:27:04.163065  4668 solver.cpp:237]     Train net output #1: loss = 0.155084 (* 1 = 0.155084 loss)
I0630 20:27:04.163065  4668 sgd_solver.cpp:105] Iteration 23300, lr = 0.001
I0630 20:27:07.819196  4668 solver.cpp:218] Iteration 23400 (27.3522 iter/s, 3.65602s/100 iters), loss = 0.218071
I0630 20:27:07.819196  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:27:07.819196  4668 solver.cpp:237]     Train net output #1: loss = 0.218072 (* 1 = 0.218072 loss)
I0630 20:27:07.819196  4668 sgd_solver.cpp:105] Iteration 23400, lr = 0.001
I0630 20:27:11.300863 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:27:11.442770  4668 solver.cpp:330] Iteration 23500, Testing net (#0)
I0630 20:27:11.442770  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:27:12.269737  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:27:12.302357  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8713
I0630 20:27:12.302357  4668 solver.cpp:397]     Test net output #1: loss = 0.399503 (* 1 = 0.399503 loss)
I0630 20:27:12.337975  4668 solver.cpp:218] Iteration 23500 (22.1732 iter/s, 4.50996s/100 iters), loss = 0.208578
I0630 20:27:12.337975  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:27:12.337975  4668 solver.cpp:237]     Train net output #1: loss = 0.208578 (* 1 = 0.208578 loss)
I0630 20:27:12.337975  4668 sgd_solver.cpp:105] Iteration 23500, lr = 0.001
I0630 20:27:15.999413  4668 solver.cpp:218] Iteration 23600 (27.2888 iter/s, 3.6645s/100 iters), loss = 0.256083
I0630 20:27:15.999413  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:27:15.999413  4668 solver.cpp:237]     Train net output #1: loss = 0.256084 (* 1 = 0.256084 loss)
I0630 20:27:15.999413  4668 sgd_solver.cpp:105] Iteration 23600, lr = 0.001
I0630 20:27:19.623100  4668 solver.cpp:218] Iteration 23700 (27.5536 iter/s, 3.6293s/100 iters), loss = 0.211899
I0630 20:27:19.623100  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:27:19.623100  4668 solver.cpp:237]     Train net output #1: loss = 0.211899 (* 1 = 0.211899 loss)
I0630 20:27:19.623100  4668 sgd_solver.cpp:105] Iteration 23700, lr = 0.001
I0630 20:27:23.272085  4668 solver.cpp:218] Iteration 23800 (27.4624 iter/s, 3.64135s/100 iters), loss = 0.203395
I0630 20:27:23.272085  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:27:23.272085  4668 solver.cpp:237]     Train net output #1: loss = 0.203395 (* 1 = 0.203395 loss)
I0630 20:27:23.272085  4668 sgd_solver.cpp:105] Iteration 23800, lr = 0.001
I0630 20:27:26.984753  4668 solver.cpp:218] Iteration 23900 (26.8844 iter/s, 3.71963s/100 iters), loss = 0.176936
I0630 20:27:26.984753  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:27:26.984753  4668 solver.cpp:237]     Train net output #1: loss = 0.176937 (* 1 = 0.176937 loss)
I0630 20:27:26.984753  4668 sgd_solver.cpp:105] Iteration 23900, lr = 0.001
I0630 20:27:30.496701 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:27:30.633679  4668 solver.cpp:330] Iteration 24000, Testing net (#0)
I0630 20:27:30.633679  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:27:31.475517  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:27:31.505524  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8718
I0630 20:27:31.505524  4668 solver.cpp:397]     Test net output #1: loss = 0.400134 (* 1 = 0.400134 loss)
I0630 20:27:31.546541  4668 solver.cpp:218] Iteration 24000 (21.9663 iter/s, 4.55242s/100 iters), loss = 0.16482
I0630 20:27:31.546541  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:27:31.546541  4668 solver.cpp:237]     Train net output #1: loss = 0.16482 (* 1 = 0.16482 loss)
I0630 20:27:31.546541  4668 sgd_solver.cpp:105] Iteration 24000, lr = 0.001
I0630 20:27:35.218276  4668 solver.cpp:218] Iteration 24100 (27.2338 iter/s, 3.67191s/100 iters), loss = 0.291331
I0630 20:27:35.218276  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:27:35.218276  4668 solver.cpp:237]     Train net output #1: loss = 0.291331 (* 1 = 0.291331 loss)
I0630 20:27:35.218276  4668 sgd_solver.cpp:105] Iteration 24100, lr = 0.001
I0630 20:27:38.860535  4668 solver.cpp:218] Iteration 24200 (27.4382 iter/s, 3.64455s/100 iters), loss = 0.279603
I0630 20:27:38.860535  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:27:38.860535  4668 solver.cpp:237]     Train net output #1: loss = 0.279604 (* 1 = 0.279604 loss)
I0630 20:27:38.860535  4668 sgd_solver.cpp:105] Iteration 24200, lr = 0.001
I0630 20:27:42.513020  4668 solver.cpp:218] Iteration 24300 (27.4041 iter/s, 3.64908s/100 iters), loss = 0.14912
I0630 20:27:42.513020  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:27:42.513020  4668 solver.cpp:237]     Train net output #1: loss = 0.14912 (* 1 = 0.14912 loss)
I0630 20:27:42.513020  4668 sgd_solver.cpp:105] Iteration 24300, lr = 0.001
I0630 20:27:46.161180  4668 solver.cpp:218] Iteration 24400 (27.4158 iter/s, 3.64753s/100 iters), loss = 0.154357
I0630 20:27:46.161180  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:27:46.161180  4668 solver.cpp:237]     Train net output #1: loss = 0.154357 (* 1 = 0.154357 loss)
I0630 20:27:46.161180  4668 sgd_solver.cpp:105] Iteration 24400, lr = 0.001
I0630 20:27:49.621850 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:27:49.766409  4668 solver.cpp:330] Iteration 24500, Testing net (#0)
I0630 20:27:49.766409  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:27:50.598568  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:27:50.622714  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8701
I0630 20:27:50.622714  4668 solver.cpp:397]     Test net output #1: loss = 0.40285 (* 1 = 0.40285 loss)
I0630 20:27:50.665227  4668 solver.cpp:218] Iteration 24500 (22.2052 iter/s, 4.50344s/100 iters), loss = 0.218676
I0630 20:27:50.665227  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:27:50.665227  4668 solver.cpp:237]     Train net output #1: loss = 0.218676 (* 1 = 0.218676 loss)
I0630 20:27:50.665227  4668 sgd_solver.cpp:105] Iteration 24500, lr = 0.001
I0630 20:27:54.303079  4668 solver.cpp:218] Iteration 24600 (27.4176 iter/s, 3.64729s/100 iters), loss = 0.169967
I0630 20:27:54.303079  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:27:54.303079  4668 solver.cpp:237]     Train net output #1: loss = 0.169968 (* 1 = 0.169968 loss)
I0630 20:27:54.303079  4668 sgd_solver.cpp:105] Iteration 24600, lr = 0.001
I0630 20:27:57.953119  4668 solver.cpp:218] Iteration 24700 (27.4269 iter/s, 3.64606s/100 iters), loss = 0.239097
I0630 20:27:57.953119  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:27:57.953119  4668 solver.cpp:237]     Train net output #1: loss = 0.239097 (* 1 = 0.239097 loss)
I0630 20:27:57.953119  4668 sgd_solver.cpp:105] Iteration 24700, lr = 0.001
I0630 20:28:01.593637  4668 solver.cpp:218] Iteration 24800 (27.514 iter/s, 3.63451s/100 iters), loss = 0.168928
I0630 20:28:01.593637  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:28:01.593637  4668 solver.cpp:237]     Train net output #1: loss = 0.168929 (* 1 = 0.168929 loss)
I0630 20:28:01.593637  4668 sgd_solver.cpp:105] Iteration 24800, lr = 0.001
I0630 20:28:05.245704  4668 solver.cpp:218] Iteration 24900 (27.3877 iter/s, 3.65128s/100 iters), loss = 0.214244
I0630 20:28:05.245873  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:28:05.245873  4668 solver.cpp:237]     Train net output #1: loss = 0.214244 (* 1 = 0.214244 loss)
I0630 20:28:05.245873  4668 sgd_solver.cpp:105] Iteration 24900, lr = 0.001
I0630 20:28:08.700196 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:28:08.841481  4668 solver.cpp:330] Iteration 25000, Testing net (#0)
I0630 20:28:08.841481  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:28:09.677008  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:28:09.701531  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8735
I0630 20:28:09.701531  4668 solver.cpp:397]     Test net output #1: loss = 0.402533 (* 1 = 0.402533 loss)
I0630 20:28:09.741533  4668 solver.cpp:218] Iteration 25000 (22.237 iter/s, 4.497s/100 iters), loss = 0.174969
I0630 20:28:09.741533  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:28:09.741533  4668 solver.cpp:237]     Train net output #1: loss = 0.17497 (* 1 = 0.17497 loss)
I0630 20:28:09.741533  4668 sgd_solver.cpp:105] Iteration 25000, lr = 0.001
I0630 20:28:13.377050  4668 solver.cpp:218] Iteration 25100 (27.5218 iter/s, 3.63349s/100 iters), loss = 0.15505
I0630 20:28:13.377050  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:28:13.377050  4668 solver.cpp:237]     Train net output #1: loss = 0.15505 (* 1 = 0.15505 loss)
I0630 20:28:13.377050  4668 sgd_solver.cpp:105] Iteration 25100, lr = 0.001
I0630 20:28:17.021262  4668 solver.cpp:218] Iteration 25200 (27.4418 iter/s, 3.64408s/100 iters), loss = 0.178738
I0630 20:28:17.021262  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:28:17.021262  4668 solver.cpp:237]     Train net output #1: loss = 0.178739 (* 1 = 0.178739 loss)
I0630 20:28:17.021262  4668 sgd_solver.cpp:105] Iteration 25200, lr = 0.001
I0630 20:28:20.670146  4668 solver.cpp:218] Iteration 25300 (27.3899 iter/s, 3.65099s/100 iters), loss = 0.18843
I0630 20:28:20.670146  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:28:20.670146  4668 solver.cpp:237]     Train net output #1: loss = 0.18843 (* 1 = 0.18843 loss)
I0630 20:28:20.670146  4668 sgd_solver.cpp:105] Iteration 25300, lr = 0.001
I0630 20:28:24.334373  4668 solver.cpp:218] Iteration 25400 (27.3098 iter/s, 3.66168s/100 iters), loss = 0.14706
I0630 20:28:24.334373  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:28:24.334373  4668 solver.cpp:237]     Train net output #1: loss = 0.147061 (* 1 = 0.147061 loss)
I0630 20:28:24.334373  4668 sgd_solver.cpp:105] Iteration 25400, lr = 0.001
I0630 20:28:27.805265 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:28:27.952836  4668 solver.cpp:330] Iteration 25500, Testing net (#0)
I0630 20:28:27.952836  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:28:28.776378  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:28:28.805909  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8734
I0630 20:28:28.805909  4668 solver.cpp:397]     Test net output #1: loss = 0.400025 (* 1 = 0.400025 loss)
I0630 20:28:28.845968  4668 solver.cpp:218] Iteration 25500 (22.1586 iter/s, 4.51293s/100 iters), loss = 0.136565
I0630 20:28:28.845968  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:28:28.845968  4668 solver.cpp:237]     Train net output #1: loss = 0.136565 (* 1 = 0.136565 loss)
I0630 20:28:28.845968  4668 sgd_solver.cpp:105] Iteration 25500, lr = 0.001
I0630 20:28:32.480573  4668 solver.cpp:218] Iteration 25600 (27.5041 iter/s, 3.63583s/100 iters), loss = 0.283814
I0630 20:28:32.480573  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:28:32.480573  4668 solver.cpp:237]     Train net output #1: loss = 0.283814 (* 1 = 0.283814 loss)
I0630 20:28:32.480573  4668 sgd_solver.cpp:105] Iteration 25600, lr = 0.001
I0630 20:28:36.110566  4668 solver.cpp:218] Iteration 25700 (27.5342 iter/s, 3.63184s/100 iters), loss = 0.241535
I0630 20:28:36.110566  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:28:36.110566  4668 solver.cpp:237]     Train net output #1: loss = 0.241536 (* 1 = 0.241536 loss)
I0630 20:28:36.110566  4668 sgd_solver.cpp:105] Iteration 25700, lr = 0.001
I0630 20:28:39.742633  4668 solver.cpp:218] Iteration 25800 (27.537 iter/s, 3.63147s/100 iters), loss = 0.140573
I0630 20:28:39.742633  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:28:39.742633  4668 solver.cpp:237]     Train net output #1: loss = 0.140574 (* 1 = 0.140574 loss)
I0630 20:28:39.742633  4668 sgd_solver.cpp:105] Iteration 25800, lr = 0.001
I0630 20:28:43.387107  4668 solver.cpp:218] Iteration 25900 (27.4438 iter/s, 3.64381s/100 iters), loss = 0.202799
I0630 20:28:43.387107  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:28:43.387107  4668 solver.cpp:237]     Train net output #1: loss = 0.202799 (* 1 = 0.202799 loss)
I0630 20:28:43.387107  4668 sgd_solver.cpp:105] Iteration 25900, lr = 0.001
I0630 20:28:46.846132 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:28:46.987076  4668 solver.cpp:330] Iteration 26000, Testing net (#0)
I0630 20:28:46.987076  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:28:47.816982  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:28:47.846995  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8733
I0630 20:28:47.846995  4668 solver.cpp:397]     Test net output #1: loss = 0.400569 (* 1 = 0.400569 loss)
I0630 20:28:47.876997  4668 solver.cpp:218] Iteration 26000 (22.2635 iter/s, 4.49166s/100 iters), loss = 0.152012
I0630 20:28:47.876997  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:28:47.876997  4668 solver.cpp:237]     Train net output #1: loss = 0.152013 (* 1 = 0.152013 loss)
I0630 20:28:47.876997  4668 sgd_solver.cpp:105] Iteration 26000, lr = 0.001
I0630 20:28:51.518970  4668 solver.cpp:218] Iteration 26100 (27.4892 iter/s, 3.6378s/100 iters), loss = 0.242527
I0630 20:28:51.518970  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:28:51.518970  4668 solver.cpp:237]     Train net output #1: loss = 0.242528 (* 1 = 0.242528 loss)
I0630 20:28:51.518970  4668 sgd_solver.cpp:105] Iteration 26100, lr = 0.001
I0630 20:28:55.160524  4668 solver.cpp:218] Iteration 26200 (27.4453 iter/s, 3.6436s/100 iters), loss = 0.20785
I0630 20:28:55.160524  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:28:55.160524  4668 solver.cpp:237]     Train net output #1: loss = 0.20785 (* 1 = 0.20785 loss)
I0630 20:28:55.160524  4668 sgd_solver.cpp:105] Iteration 26200, lr = 0.001
I0630 20:28:58.793635  4668 solver.cpp:218] Iteration 26300 (27.503 iter/s, 3.63596s/100 iters), loss = 0.184745
I0630 20:28:58.793635  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:28:58.793635  4668 solver.cpp:237]     Train net output #1: loss = 0.184745 (* 1 = 0.184745 loss)
I0630 20:28:58.793635  4668 sgd_solver.cpp:105] Iteration 26300, lr = 0.001
I0630 20:29:02.425107  4668 solver.cpp:218] Iteration 26400 (27.5346 iter/s, 3.6318s/100 iters), loss = 0.153735
I0630 20:29:02.425107  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:29:02.425107  4668 solver.cpp:237]     Train net output #1: loss = 0.153735 (* 1 = 0.153735 loss)
I0630 20:29:02.425107  4668 sgd_solver.cpp:105] Iteration 26400, lr = 0.001
I0630 20:29:05.885830 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:29:06.029899  4668 solver.cpp:330] Iteration 26500, Testing net (#0)
I0630 20:29:06.029899  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:29:06.849480  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:29:06.886523  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8739
I0630 20:29:06.886523  4668 solver.cpp:397]     Test net output #1: loss = 0.402499 (* 1 = 0.402499 loss)
I0630 20:29:06.916525  4668 solver.cpp:218] Iteration 26500 (22.2725 iter/s, 4.48983s/100 iters), loss = 0.220982
I0630 20:29:06.916525  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:29:06.916525  4668 solver.cpp:237]     Train net output #1: loss = 0.220982 (* 1 = 0.220982 loss)
I0630 20:29:06.916525  4668 sgd_solver.cpp:105] Iteration 26500, lr = 0.001
I0630 20:29:10.583240  4668 solver.cpp:218] Iteration 26600 (27.334 iter/s, 3.65845s/100 iters), loss = 0.184299
I0630 20:29:10.583240  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:29:10.583240  4668 solver.cpp:237]     Train net output #1: loss = 0.184299 (* 1 = 0.184299 loss)
I0630 20:29:10.583240  4668 sgd_solver.cpp:105] Iteration 26600, lr = 0.001
I0630 20:29:14.351181  4668 solver.cpp:218] Iteration 26700 (26.4836 iter/s, 3.77592s/100 iters), loss = 0.217632
I0630 20:29:14.351181  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:29:14.351181  4668 solver.cpp:237]     Train net output #1: loss = 0.217632 (* 1 = 0.217632 loss)
I0630 20:29:14.351181  4668 sgd_solver.cpp:105] Iteration 26700, lr = 0.001
I0630 20:29:18.034176  4668 solver.cpp:218] Iteration 26800 (27.1615 iter/s, 3.68168s/100 iters), loss = 0.172532
I0630 20:29:18.034176  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:29:18.034176  4668 solver.cpp:237]     Train net output #1: loss = 0.172532 (* 1 = 0.172532 loss)
I0630 20:29:18.034176  4668 sgd_solver.cpp:105] Iteration 26800, lr = 0.001
I0630 20:29:21.670325  4668 solver.cpp:218] Iteration 26900 (27.5171 iter/s, 3.63411s/100 iters), loss = 0.165989
I0630 20:29:21.670325  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:29:21.670325  4668 solver.cpp:237]     Train net output #1: loss = 0.16599 (* 1 = 0.16599 loss)
I0630 20:29:21.670325  4668 sgd_solver.cpp:105] Iteration 26900, lr = 0.001
I0630 20:29:25.141937 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:29:25.290997  4668 solver.cpp:330] Iteration 27000, Testing net (#0)
I0630 20:29:25.290997  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:29:26.114055  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:29:26.144057  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8744
I0630 20:29:26.144057  4668 solver.cpp:397]     Test net output #1: loss = 0.404165 (* 1 = 0.404165 loss)
I0630 20:29:26.184061  4668 solver.cpp:218] Iteration 27000 (22.1868 iter/s, 4.50718s/100 iters), loss = 0.186645
I0630 20:29:26.184061  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:29:26.184061  4668 solver.cpp:237]     Train net output #1: loss = 0.186645 (* 1 = 0.186645 loss)
I0630 20:29:26.184061  4668 sgd_solver.cpp:105] Iteration 27000, lr = 0.001
I0630 20:29:29.796957  4668 solver.cpp:218] Iteration 27100 (27.6364 iter/s, 3.61842s/100 iters), loss = 0.240005
I0630 20:29:29.796957  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:29:29.796957  4668 solver.cpp:237]     Train net output #1: loss = 0.240005 (* 1 = 0.240005 loss)
I0630 20:29:29.796957  4668 sgd_solver.cpp:105] Iteration 27100, lr = 0.001
I0630 20:29:33.450129  4668 solver.cpp:218] Iteration 27200 (27.4132 iter/s, 3.64787s/100 iters), loss = 0.241432
I0630 20:29:33.450129  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:29:33.450129  4668 solver.cpp:237]     Train net output #1: loss = 0.241432 (* 1 = 0.241432 loss)
I0630 20:29:33.450129  4668 sgd_solver.cpp:105] Iteration 27200, lr = 0.001
I0630 20:29:37.072199  4668 solver.cpp:218] Iteration 27300 (27.6177 iter/s, 3.62087s/100 iters), loss = 0.167279
I0630 20:29:37.072199  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:29:37.072199  4668 solver.cpp:237]     Train net output #1: loss = 0.167279 (* 1 = 0.167279 loss)
I0630 20:29:37.072199  4668 sgd_solver.cpp:105] Iteration 27300, lr = 0.001
I0630 20:29:40.684978  4668 solver.cpp:218] Iteration 27400 (27.6412 iter/s, 3.61779s/100 iters), loss = 0.140525
I0630 20:29:40.684978  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:29:40.684978  4668 solver.cpp:237]     Train net output #1: loss = 0.140525 (* 1 = 0.140525 loss)
I0630 20:29:40.684978  4668 sgd_solver.cpp:105] Iteration 27400, lr = 0.001
I0630 20:29:44.132671 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:29:44.268224  4668 solver.cpp:330] Iteration 27500, Testing net (#0)
I0630 20:29:44.268224  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:29:45.099910  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:29:45.124995  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8746
I0630 20:29:45.124995  4668 solver.cpp:397]     Test net output #1: loss = 0.399747 (* 1 = 0.399747 loss)
I0630 20:29:45.165002  4668 solver.cpp:218] Iteration 27500 (22.3492 iter/s, 4.47443s/100 iters), loss = 0.134656
I0630 20:29:45.165002  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:29:45.165002  4668 solver.cpp:237]     Train net output #1: loss = 0.134657 (* 1 = 0.134657 loss)
I0630 20:29:45.165002  4668 sgd_solver.cpp:105] Iteration 27500, lr = 0.001
I0630 20:29:48.812436  4668 solver.cpp:218] Iteration 27600 (27.3665 iter/s, 3.6541s/100 iters), loss = 0.166157
I0630 20:29:48.812436  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:29:48.812436  4668 solver.cpp:237]     Train net output #1: loss = 0.166157 (* 1 = 0.166157 loss)
I0630 20:29:48.812436  4668 sgd_solver.cpp:105] Iteration 27600, lr = 0.001
I0630 20:29:52.446486  4668 solver.cpp:218] Iteration 27700 (27.5427 iter/s, 3.63072s/100 iters), loss = 0.197179
I0630 20:29:52.446486  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:29:52.446486  4668 solver.cpp:237]     Train net output #1: loss = 0.19718 (* 1 = 0.19718 loss)
I0630 20:29:52.446486  4668 sgd_solver.cpp:105] Iteration 27700, lr = 0.001
I0630 20:29:56.092206  4668 solver.cpp:218] Iteration 27800 (27.4372 iter/s, 3.64468s/100 iters), loss = 0.228297
I0630 20:29:56.092206  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:29:56.092206  4668 solver.cpp:237]     Train net output #1: loss = 0.228298 (* 1 = 0.228298 loss)
I0630 20:29:56.092206  4668 sgd_solver.cpp:105] Iteration 27800, lr = 0.001
I0630 20:29:59.747187  4668 solver.cpp:218] Iteration 27900 (27.3474 iter/s, 3.65665s/100 iters), loss = 0.186926
I0630 20:29:59.747187  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:29:59.747187  4668 solver.cpp:237]     Train net output #1: loss = 0.186926 (* 1 = 0.186926 loss)
I0630 20:29:59.747187  4668 sgd_solver.cpp:105] Iteration 27900, lr = 0.001
I0630 20:30:03.271384 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:30:03.408505  4668 solver.cpp:330] Iteration 28000, Testing net (#0)
I0630 20:30:03.408505  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:30:04.238451  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:30:04.272742  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8731
I0630 20:30:04.272742  4668 solver.cpp:397]     Test net output #1: loss = 0.406342 (* 1 = 0.406342 loss)
I0630 20:30:04.307754  4668 solver.cpp:218] Iteration 28000 (21.9543 iter/s, 4.55492s/100 iters), loss = 0.142734
I0630 20:30:04.307754  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:30:04.307754  4668 solver.cpp:237]     Train net output #1: loss = 0.142735 (* 1 = 0.142735 loss)
I0630 20:30:04.307754  4668 sgd_solver.cpp:105] Iteration 28000, lr = 0.001
I0630 20:30:07.930147  4668 solver.cpp:218] Iteration 28100 (27.5398 iter/s, 3.63111s/100 iters), loss = 0.178914
I0630 20:30:07.930147  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:30:07.930147  4668 solver.cpp:237]     Train net output #1: loss = 0.178914 (* 1 = 0.178914 loss)
I0630 20:30:07.930147  4668 sgd_solver.cpp:105] Iteration 28100, lr = 0.001
I0630 20:30:11.613050  4668 solver.cpp:218] Iteration 28200 (27.2176 iter/s, 3.6741s/100 iters), loss = 0.206145
I0630 20:30:11.613050  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:30:11.613050  4668 solver.cpp:237]     Train net output #1: loss = 0.206145 (* 1 = 0.206145 loss)
I0630 20:30:11.613050  4668 sgd_solver.cpp:105] Iteration 28200, lr = 0.001
I0630 20:30:15.303768  4668 solver.cpp:218] Iteration 28300 (27.0905 iter/s, 3.69133s/100 iters), loss = 0.132392
I0630 20:30:15.303768  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:30:15.303768  4668 solver.cpp:237]     Train net output #1: loss = 0.132392 (* 1 = 0.132392 loss)
I0630 20:30:15.303768  4668 sgd_solver.cpp:105] Iteration 28300, lr = 0.001
I0630 20:30:18.944303  4668 solver.cpp:218] Iteration 28400 (27.4388 iter/s, 3.64447s/100 iters), loss = 0.188443
I0630 20:30:18.944303  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:30:18.944303  4668 solver.cpp:237]     Train net output #1: loss = 0.188443 (* 1 = 0.188443 loss)
I0630 20:30:18.944303  4668 sgd_solver.cpp:105] Iteration 28400, lr = 0.001
I0630 20:30:22.448377 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:30:22.591485  4668 solver.cpp:330] Iteration 28500, Testing net (#0)
I0630 20:30:22.591485  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:30:23.418758  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:30:23.448770  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8739
I0630 20:30:23.448770  4668 solver.cpp:397]     Test net output #1: loss = 0.404198 (* 1 = 0.404198 loss)
I0630 20:30:23.478493  4668 solver.cpp:218] Iteration 28500 (22.0491 iter/s, 4.53533s/100 iters), loss = 0.172641
I0630 20:30:23.478493  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:30:23.478493  4668 solver.cpp:237]     Train net output #1: loss = 0.172641 (* 1 = 0.172641 loss)
I0630 20:30:23.478493  4668 sgd_solver.cpp:105] Iteration 28500, lr = 0.001
I0630 20:30:27.122376  4668 solver.cpp:218] Iteration 28600 (27.4841 iter/s, 3.63846s/100 iters), loss = 0.267623
I0630 20:30:27.122376  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:30:27.122376  4668 solver.cpp:237]     Train net output #1: loss = 0.267623 (* 1 = 0.267623 loss)
I0630 20:30:27.122376  4668 sgd_solver.cpp:105] Iteration 28600, lr = 0.001
I0630 20:30:30.761422  4668 solver.cpp:218] Iteration 28700 (27.5036 iter/s, 3.63589s/100 iters), loss = 0.225161
I0630 20:30:30.761422  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:30:30.761906  4668 solver.cpp:237]     Train net output #1: loss = 0.225162 (* 1 = 0.225162 loss)
I0630 20:30:30.761906  4668 sgd_solver.cpp:105] Iteration 28700, lr = 0.001
I0630 20:30:34.416085  4668 solver.cpp:218] Iteration 28800 (27.3664 iter/s, 3.65412s/100 iters), loss = 0.178816
I0630 20:30:34.416085  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:30:34.416085  4668 solver.cpp:237]     Train net output #1: loss = 0.178816 (* 1 = 0.178816 loss)
I0630 20:30:34.416085  4668 sgd_solver.cpp:105] Iteration 28800, lr = 0.001
I0630 20:30:38.056841  4668 solver.cpp:218] Iteration 28900 (27.4226 iter/s, 3.64663s/100 iters), loss = 0.182691
I0630 20:30:38.056841  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:30:38.056841  4668 solver.cpp:237]     Train net output #1: loss = 0.182691 (* 1 = 0.182691 loss)
I0630 20:30:38.056841  4668 sgd_solver.cpp:105] Iteration 28900, lr = 0.001
I0630 20:30:41.516610 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:30:41.662514  4668 solver.cpp:330] Iteration 29000, Testing net (#0)
I0630 20:30:41.662514  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:30:42.476943  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:30:42.516947  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:30:42.516947  4668 solver.cpp:397]     Test net output #1: loss = 0.403827 (* 1 = 0.403827 loss)
I0630 20:30:42.546962  4668 solver.cpp:218] Iteration 29000 (22.2689 iter/s, 4.49058s/100 iters), loss = 0.170939
I0630 20:30:42.546962  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:30:42.546962  4668 solver.cpp:237]     Train net output #1: loss = 0.170939 (* 1 = 0.170939 loss)
I0630 20:30:42.546962  4668 sgd_solver.cpp:105] Iteration 29000, lr = 0.001
I0630 20:30:46.275243  4668 solver.cpp:218] Iteration 29100 (26.8757 iter/s, 3.72083s/100 iters), loss = 0.192974
I0630 20:30:46.275243  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:30:46.275243  4668 solver.cpp:237]     Train net output #1: loss = 0.192974 (* 1 = 0.192974 loss)
I0630 20:30:46.275243  4668 sgd_solver.cpp:105] Iteration 29100, lr = 0.001
I0630 20:30:49.920161  4668 solver.cpp:218] Iteration 29200 (27.3664 iter/s, 3.65411s/100 iters), loss = 0.272852
I0630 20:30:49.920161  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0630 20:30:49.920161  4668 solver.cpp:237]     Train net output #1: loss = 0.272852 (* 1 = 0.272852 loss)
I0630 20:30:49.920161  4668 sgd_solver.cpp:105] Iteration 29200, lr = 0.001
I0630 20:30:53.595157  4668 solver.cpp:218] Iteration 29300 (27.2846 iter/s, 3.66507s/100 iters), loss = 0.17247
I0630 20:30:53.595157  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:30:53.595157  4668 solver.cpp:237]     Train net output #1: loss = 0.17247 (* 1 = 0.17247 loss)
I0630 20:30:53.595157  4668 sgd_solver.cpp:105] Iteration 29300, lr = 0.001
I0630 20:30:57.273074  4668 solver.cpp:218] Iteration 29400 (27.1886 iter/s, 3.67801s/100 iters), loss = 0.186775
I0630 20:30:57.273074  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:30:57.273074  4668 solver.cpp:237]     Train net output #1: loss = 0.186776 (* 1 = 0.186776 loss)
I0630 20:30:57.273074  4668 sgd_solver.cpp:105] Iteration 29400, lr = 0.001
I0630 20:31:00.790377 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:31:00.930558  4668 solver.cpp:330] Iteration 29500, Testing net (#0)
I0630 20:31:00.930558  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:31:01.772559  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:31:01.810575  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8739
I0630 20:31:01.811074  4668 solver.cpp:397]     Test net output #1: loss = 0.406224 (* 1 = 0.406224 loss)
I0630 20:31:01.841500  4668 solver.cpp:218] Iteration 29500 (21.8758 iter/s, 4.57126s/100 iters), loss = 0.157481
I0630 20:31:01.841500  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:31:01.841500  4668 solver.cpp:237]     Train net output #1: loss = 0.157481 (* 1 = 0.157481 loss)
I0630 20:31:01.841500  4668 sgd_solver.cpp:105] Iteration 29500, lr = 0.001
I0630 20:31:05.484899  4668 solver.cpp:218] Iteration 29600 (27.4408 iter/s, 3.6442s/100 iters), loss = 0.231066
I0630 20:31:05.484899  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:31:05.484899  4668 solver.cpp:237]     Train net output #1: loss = 0.231066 (* 1 = 0.231066 loss)
I0630 20:31:05.484899  4668 sgd_solver.cpp:105] Iteration 29600, lr = 0.001
I0630 20:31:09.146118  4668 solver.cpp:218] Iteration 29700 (27.3413 iter/s, 3.65747s/100 iters), loss = 0.153607
I0630 20:31:09.146118  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:31:09.146118  4668 solver.cpp:237]     Train net output #1: loss = 0.153608 (* 1 = 0.153608 loss)
I0630 20:31:09.146118  4668 sgd_solver.cpp:105] Iteration 29700, lr = 0.001
I0630 20:31:12.888713  4668 solver.cpp:218] Iteration 29800 (26.7313 iter/s, 3.74094s/100 iters), loss = 0.162364
I0630 20:31:12.888713  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:31:12.888713  4668 solver.cpp:237]     Train net output #1: loss = 0.162364 (* 1 = 0.162364 loss)
I0630 20:31:12.888713  4668 sgd_solver.cpp:105] Iteration 29800, lr = 0.001
I0630 20:31:16.541060  4668 solver.cpp:218] Iteration 29900 (27.3723 iter/s, 3.65332s/100 iters), loss = 0.14327
I0630 20:31:16.541060  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:31:16.541060  4668 solver.cpp:237]     Train net output #1: loss = 0.14327 (* 1 = 0.14327 loss)
I0630 20:31:16.541060  4668 sgd_solver.cpp:105] Iteration 29900, lr = 0.001
I0630 20:31:20.019534 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:31:20.153704  4668 solver.cpp:330] Iteration 30000, Testing net (#0)
I0630 20:31:20.153704  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:31:20.983964  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:31:21.017459  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8747
I0630 20:31:21.017459  4668 solver.cpp:397]     Test net output #1: loss = 0.402959 (* 1 = 0.402959 loss)
I0630 20:31:21.044487  4668 solver.cpp:218] Iteration 30000 (22.1759 iter/s, 4.50941s/100 iters), loss = 0.141748
I0630 20:31:21.044487  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:31:21.044487  4668 solver.cpp:237]     Train net output #1: loss = 0.141749 (* 1 = 0.141749 loss)
I0630 20:31:21.044487  4668 sgd_solver.cpp:105] Iteration 30000, lr = 0.001
I0630 20:31:24.694885  4668 solver.cpp:218] Iteration 30100 (27.3887 iter/s, 3.65114s/100 iters), loss = 0.256984
I0630 20:31:24.694885  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:31:24.694885  4668 solver.cpp:237]     Train net output #1: loss = 0.256984 (* 1 = 0.256984 loss)
I0630 20:31:24.694885  4668 sgd_solver.cpp:105] Iteration 30100, lr = 0.001
I0630 20:31:28.338325  4668 solver.cpp:218] Iteration 30200 (27.4687 iter/s, 3.64051s/100 iters), loss = 0.169431
I0630 20:31:28.338325  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:31:28.338325  4668 solver.cpp:237]     Train net output #1: loss = 0.169431 (* 1 = 0.169431 loss)
I0630 20:31:28.338325  4668 sgd_solver.cpp:105] Iteration 30200, lr = 0.001
I0630 20:31:32.040084  4668 solver.cpp:218] Iteration 30300 (27.0161 iter/s, 3.70149s/100 iters), loss = 0.172044
I0630 20:31:32.040084  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:31:32.040084  4668 solver.cpp:237]     Train net output #1: loss = 0.172044 (* 1 = 0.172044 loss)
I0630 20:31:32.040084  4668 sgd_solver.cpp:105] Iteration 30300, lr = 0.001
I0630 20:31:35.726864  4668 solver.cpp:218] Iteration 30400 (27.1731 iter/s, 3.68011s/100 iters), loss = 0.170452
I0630 20:31:35.726864  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:31:35.726864  4668 solver.cpp:237]     Train net output #1: loss = 0.170452 (* 1 = 0.170452 loss)
I0630 20:31:35.726864  4668 sgd_solver.cpp:105] Iteration 30400, lr = 0.001
I0630 20:31:39.234717 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:31:39.380619  4668 solver.cpp:330] Iteration 30500, Testing net (#0)
I0630 20:31:39.380619  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:31:40.215673  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:31:40.245481  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8746
I0630 20:31:40.245481  4668 solver.cpp:397]     Test net output #1: loss = 0.407955 (* 1 = 0.407955 loss)
I0630 20:31:40.285481  4668 solver.cpp:218] Iteration 30500 (21.9377 iter/s, 4.55837s/100 iters), loss = 0.146779
I0630 20:31:40.285481  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:31:40.285481  4668 solver.cpp:237]     Train net output #1: loss = 0.14678 (* 1 = 0.14678 loss)
I0630 20:31:40.285481  4668 sgd_solver.cpp:105] Iteration 30500, lr = 0.001
I0630 20:31:43.907797  4668 solver.cpp:218] Iteration 30600 (27.5556 iter/s, 3.62902s/100 iters), loss = 0.250799
I0630 20:31:43.907797  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:31:43.907797  4668 solver.cpp:237]     Train net output #1: loss = 0.250799 (* 1 = 0.250799 loss)
I0630 20:31:43.907797  4668 sgd_solver.cpp:105] Iteration 30600, lr = 0.001
I0630 20:31:47.577219  4668 solver.cpp:218] Iteration 30700 (27.3067 iter/s, 3.6621s/100 iters), loss = 0.236831
I0630 20:31:47.577219  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:31:47.577219  4668 solver.cpp:237]     Train net output #1: loss = 0.236831 (* 1 = 0.236831 loss)
I0630 20:31:47.577219  4668 sgd_solver.cpp:105] Iteration 30700, lr = 0.001
I0630 20:31:51.243896  4668 solver.cpp:218] Iteration 30800 (27.2629 iter/s, 3.66799s/100 iters), loss = 0.140271
I0630 20:31:51.243896  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:31:51.243896  4668 solver.cpp:237]     Train net output #1: loss = 0.140272 (* 1 = 0.140272 loss)
I0630 20:31:51.243896  4668 sgd_solver.cpp:105] Iteration 30800, lr = 0.001
I0630 20:31:54.885493  4668 solver.cpp:218] Iteration 30900 (27.4506 iter/s, 3.64291s/100 iters), loss = 0.13259
I0630 20:31:54.885493  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:31:54.885493  4668 solver.cpp:237]     Train net output #1: loss = 0.132591 (* 1 = 0.132591 loss)
I0630 20:31:54.885493  4668 sgd_solver.cpp:105] Iteration 30900, lr = 0.001
I0630 20:31:58.336360 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:31:58.478937  4668 solver.cpp:330] Iteration 31000, Testing net (#0)
I0630 20:31:58.478937  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:31:59.310570  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:31:59.337690  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8735
I0630 20:31:59.337690  4668 solver.cpp:397]     Test net output #1: loss = 0.405482 (* 1 = 0.405482 loss)
I0630 20:31:59.367694  4668 solver.cpp:218] Iteration 31000 (22.2853 iter/s, 4.48727s/100 iters), loss = 0.168781
I0630 20:31:59.367694  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:31:59.367694  4668 solver.cpp:237]     Train net output #1: loss = 0.168781 (* 1 = 0.168781 loss)
I0630 20:31:59.367694  4668 sgd_solver.cpp:105] Iteration 31000, lr = 0.001
I0630 20:32:03.086501  4668 solver.cpp:218] Iteration 31100 (26.9573 iter/s, 3.70957s/100 iters), loss = 0.155565
I0630 20:32:03.086501  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:32:03.086501  4668 solver.cpp:237]     Train net output #1: loss = 0.155565 (* 1 = 0.155565 loss)
I0630 20:32:03.086501  4668 sgd_solver.cpp:105] Iteration 31100, lr = 0.001
I0630 20:32:06.755089  4668 solver.cpp:218] Iteration 31200 (27.2234 iter/s, 3.67331s/100 iters), loss = 0.231982
I0630 20:32:06.755089  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:32:06.755089  4668 solver.cpp:237]     Train net output #1: loss = 0.231983 (* 1 = 0.231983 loss)
I0630 20:32:06.755089  4668 sgd_solver.cpp:105] Iteration 31200, lr = 0.001
I0630 20:32:10.510793  4668 solver.cpp:218] Iteration 31300 (26.6696 iter/s, 3.74959s/100 iters), loss = 0.210936
I0630 20:32:10.510793  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:32:10.510793  4668 solver.cpp:237]     Train net output #1: loss = 0.210937 (* 1 = 0.210937 loss)
I0630 20:32:10.510793  4668 sgd_solver.cpp:105] Iteration 31300, lr = 0.001
I0630 20:32:14.194255  4668 solver.cpp:218] Iteration 31400 (27.0957 iter/s, 3.69063s/100 iters), loss = 0.23226
I0630 20:32:14.194255  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:32:14.194255  4668 solver.cpp:237]     Train net output #1: loss = 0.232261 (* 1 = 0.232261 loss)
I0630 20:32:14.194255  4668 sgd_solver.cpp:105] Iteration 31400, lr = 0.001
I0630 20:32:17.642520 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:32:17.792758  4668 solver.cpp:330] Iteration 31500, Testing net (#0)
I0630 20:32:17.792758  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:32:18.618561  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:32:18.644567  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8744
I0630 20:32:18.644567  4668 solver.cpp:397]     Test net output #1: loss = 0.408174 (* 1 = 0.408174 loss)
I0630 20:32:18.684581  4668 solver.cpp:218] Iteration 31500 (22.3071 iter/s, 4.48287s/100 iters), loss = 0.214764
I0630 20:32:18.684581  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:32:18.684581  4668 solver.cpp:237]     Train net output #1: loss = 0.214765 (* 1 = 0.214765 loss)
I0630 20:32:18.684581  4668 sgd_solver.cpp:105] Iteration 31500, lr = 0.001
I0630 20:32:22.327368  4668 solver.cpp:218] Iteration 31600 (27.4096 iter/s, 3.64836s/100 iters), loss = 0.187676
I0630 20:32:22.327368  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:32:22.327368  4668 solver.cpp:237]     Train net output #1: loss = 0.187676 (* 1 = 0.187676 loss)
I0630 20:32:22.327368  4668 sgd_solver.cpp:105] Iteration 31600, lr = 0.001
I0630 20:32:25.980080  4668 solver.cpp:218] Iteration 31700 (27.3893 iter/s, 3.65107s/100 iters), loss = 0.155264
I0630 20:32:25.980080  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:32:25.980080  4668 solver.cpp:237]     Train net output #1: loss = 0.155265 (* 1 = 0.155265 loss)
I0630 20:32:25.980080  4668 sgd_solver.cpp:105] Iteration 31700, lr = 0.001
I0630 20:32:29.632464  4668 solver.cpp:218] Iteration 31800 (27.3996 iter/s, 3.64969s/100 iters), loss = 0.130329
I0630 20:32:29.632464  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:32:29.632464  4668 solver.cpp:237]     Train net output #1: loss = 0.13033 (* 1 = 0.13033 loss)
I0630 20:32:29.632464  4668 sgd_solver.cpp:105] Iteration 31800, lr = 0.001
I0630 20:32:33.260565  4668 solver.cpp:218] Iteration 31900 (27.5218 iter/s, 3.63348s/100 iters), loss = 0.14725
I0630 20:32:33.260565  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:32:33.260565  4668 solver.cpp:237]     Train net output #1: loss = 0.147251 (* 1 = 0.147251 loss)
I0630 20:32:33.260565  4668 sgd_solver.cpp:105] Iteration 31900, lr = 0.001
I0630 20:32:36.758543 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:32:36.911773  4668 solver.cpp:330] Iteration 32000, Testing net (#0)
I0630 20:32:36.911773  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:32:37.768806  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:32:37.798800  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8759
I0630 20:32:37.798800  4668 solver.cpp:397]     Test net output #1: loss = 0.40981 (* 1 = 0.40981 loss)
I0630 20:32:37.838811  4668 solver.cpp:218] Iteration 32000 (21.8715 iter/s, 4.57216s/100 iters), loss = 0.107358
I0630 20:32:37.838811  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:32:37.838811  4668 solver.cpp:237]     Train net output #1: loss = 0.107358 (* 1 = 0.107358 loss)
I0630 20:32:37.838811  4668 sgd_solver.cpp:105] Iteration 32000, lr = 0.001
I0630 20:32:41.501317  4668 solver.cpp:218] Iteration 32100 (27.2678 iter/s, 3.66733s/100 iters), loss = 0.215499
I0630 20:32:41.501317  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:32:41.501317  4668 solver.cpp:237]     Train net output #1: loss = 0.2155 (* 1 = 0.2155 loss)
I0630 20:32:41.501317  4668 sgd_solver.cpp:105] Iteration 32100, lr = 0.001
I0630 20:32:45.223032  4668 solver.cpp:218] Iteration 32200 (26.9235 iter/s, 3.71423s/100 iters), loss = 0.188444
I0630 20:32:45.223032  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:32:45.223032  4668 solver.cpp:237]     Train net output #1: loss = 0.188445 (* 1 = 0.188445 loss)
I0630 20:32:45.223032  4668 sgd_solver.cpp:105] Iteration 32200, lr = 0.001
I0630 20:32:49.006525  4668 solver.cpp:218] Iteration 32300 (26.4247 iter/s, 3.78433s/100 iters), loss = 0.104859
I0630 20:32:49.006525  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:32:49.006525  4668 solver.cpp:237]     Train net output #1: loss = 0.10486 (* 1 = 0.10486 loss)
I0630 20:32:49.006525  4668 sgd_solver.cpp:105] Iteration 32300, lr = 0.001
I0630 20:32:52.737975  4668 solver.cpp:218] Iteration 32400 (26.8071 iter/s, 3.73036s/100 iters), loss = 0.115872
I0630 20:32:52.737975  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:32:52.737975  4668 solver.cpp:237]     Train net output #1: loss = 0.115873 (* 1 = 0.115873 loss)
I0630 20:32:52.737975  4668 sgd_solver.cpp:105] Iteration 32400, lr = 0.001
I0630 20:32:56.200490 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:32:56.334719  4668 solver.cpp:330] Iteration 32500, Testing net (#0)
I0630 20:32:56.334719  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:32:57.167274  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:32:57.198310  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8732
I0630 20:32:57.198310  4668 solver.cpp:397]     Test net output #1: loss = 0.41355 (* 1 = 0.41355 loss)
I0630 20:32:57.232440  4668 solver.cpp:218] Iteration 32500 (22.2543 iter/s, 4.49351s/100 iters), loss = 0.148664
I0630 20:32:57.232440  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:32:57.232440  4668 solver.cpp:237]     Train net output #1: loss = 0.148664 (* 1 = 0.148664 loss)
I0630 20:32:57.232440  4668 sgd_solver.cpp:105] Iteration 32500, lr = 0.001
I0630 20:33:00.854990  4668 solver.cpp:218] Iteration 32600 (27.6105 iter/s, 3.62182s/100 iters), loss = 0.260973
I0630 20:33:00.854990  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:33:00.855490  4668 solver.cpp:237]     Train net output #1: loss = 0.260973 (* 1 = 0.260973 loss)
I0630 20:33:00.855490  4668 sgd_solver.cpp:105] Iteration 32600, lr = 0.001
I0630 20:33:04.495153  4668 solver.cpp:218] Iteration 32700 (27.4272 iter/s, 3.64602s/100 iters), loss = 0.255095
I0630 20:33:04.495153  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 20:33:04.495153  4668 solver.cpp:237]     Train net output #1: loss = 0.255095 (* 1 = 0.255095 loss)
I0630 20:33:04.495153  4668 sgd_solver.cpp:105] Iteration 32700, lr = 0.001
I0630 20:33:08.133044  4668 solver.cpp:218] Iteration 32800 (27.5368 iter/s, 3.6315s/100 iters), loss = 0.15168
I0630 20:33:08.133044  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:33:08.133044  4668 solver.cpp:237]     Train net output #1: loss = 0.151681 (* 1 = 0.151681 loss)
I0630 20:33:08.133044  4668 sgd_solver.cpp:105] Iteration 32800, lr = 0.001
I0630 20:33:11.749632  4668 solver.cpp:218] Iteration 32900 (27.6075 iter/s, 3.62221s/100 iters), loss = 0.173275
I0630 20:33:11.749632  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:33:11.749632  4668 solver.cpp:237]     Train net output #1: loss = 0.173275 (* 1 = 0.173275 loss)
I0630 20:33:11.749632  4668 sgd_solver.cpp:105] Iteration 32900, lr = 0.001
I0630 20:33:15.212903 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:33:15.356570  4668 solver.cpp:330] Iteration 33000, Testing net (#0)
I0630 20:33:15.356570  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:33:16.188915  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:33:16.214493  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8767
I0630 20:33:16.214493  4668 solver.cpp:397]     Test net output #1: loss = 0.409948 (* 1 = 0.409948 loss)
I0630 20:33:16.254493  4668 solver.cpp:218] Iteration 33000 (22.227 iter/s, 4.49903s/100 iters), loss = 0.217338
I0630 20:33:16.254493  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:33:16.254493  4668 solver.cpp:237]     Train net output #1: loss = 0.217339 (* 1 = 0.217339 loss)
I0630 20:33:16.254493  4668 sgd_solver.cpp:105] Iteration 33000, lr = 0.001
I0630 20:33:19.893024  4668 solver.cpp:218] Iteration 33100 (27.4923 iter/s, 3.63738s/100 iters), loss = 0.260111
I0630 20:33:19.893024  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:33:19.893024  4668 solver.cpp:237]     Train net output #1: loss = 0.260112 (* 1 = 0.260112 loss)
I0630 20:33:19.893024  4668 sgd_solver.cpp:105] Iteration 33100, lr = 0.001
I0630 20:33:23.623375  4668 solver.cpp:218] Iteration 33200 (26.7802 iter/s, 3.7341s/100 iters), loss = 0.175143
I0630 20:33:23.623375  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:33:23.623375  4668 solver.cpp:237]     Train net output #1: loss = 0.175144 (* 1 = 0.175144 loss)
I0630 20:33:23.623375  4668 sgd_solver.cpp:105] Iteration 33200, lr = 0.001
I0630 20:33:27.267035  4668 solver.cpp:218] Iteration 33300 (27.4784 iter/s, 3.63922s/100 iters), loss = 0.213068
I0630 20:33:27.267035  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:33:27.267035  4668 solver.cpp:237]     Train net output #1: loss = 0.213069 (* 1 = 0.213069 loss)
I0630 20:33:27.267035  4668 sgd_solver.cpp:105] Iteration 33300, lr = 0.001
I0630 20:33:30.932857  4668 solver.cpp:218] Iteration 33400 (27.2831 iter/s, 3.66527s/100 iters), loss = 0.171704
I0630 20:33:30.932857  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:33:30.932857  4668 solver.cpp:237]     Train net output #1: loss = 0.171704 (* 1 = 0.171704 loss)
I0630 20:33:30.932857  4668 sgd_solver.cpp:105] Iteration 33400, lr = 0.001
I0630 20:33:34.486389 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:33:34.622689  4668 solver.cpp:330] Iteration 33500, Testing net (#0)
I0630 20:33:34.622689  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:33:35.458341  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:33:35.487865  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8743
I0630 20:33:35.487865  4668 solver.cpp:397]     Test net output #1: loss = 0.41509 (* 1 = 0.41509 loss)
I0630 20:33:35.527899  4668 solver.cpp:218] Iteration 33500 (21.7267 iter/s, 4.60263s/100 iters), loss = 0.0971341
I0630 20:33:35.527899  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:33:35.527899  4668 solver.cpp:237]     Train net output #1: loss = 0.0971344 (* 1 = 0.0971344 loss)
I0630 20:33:35.527899  4668 sgd_solver.cpp:105] Iteration 33500, lr = 0.001
I0630 20:33:39.221851  4668 solver.cpp:218] Iteration 33600 (27.1097 iter/s, 3.68871s/100 iters), loss = 0.188263
I0630 20:33:39.221851  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:33:39.221851  4668 solver.cpp:237]     Train net output #1: loss = 0.188264 (* 1 = 0.188264 loss)
I0630 20:33:39.221851  4668 sgd_solver.cpp:105] Iteration 33600, lr = 0.001
I0630 20:33:42.865808  4668 solver.cpp:218] Iteration 33700 (27.4349 iter/s, 3.64499s/100 iters), loss = 0.242895
I0630 20:33:42.865808  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:33:42.865808  4668 solver.cpp:237]     Train net output #1: loss = 0.242895 (* 1 = 0.242895 loss)
I0630 20:33:42.865808  4668 sgd_solver.cpp:105] Iteration 33700, lr = 0.001
I0630 20:33:46.499219  4668 solver.cpp:218] Iteration 33800 (27.4949 iter/s, 3.63704s/100 iters), loss = 0.179827
I0630 20:33:46.499219  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:33:46.499219  4668 solver.cpp:237]     Train net output #1: loss = 0.179827 (* 1 = 0.179827 loss)
I0630 20:33:46.499219  4668 sgd_solver.cpp:105] Iteration 33800, lr = 0.001
I0630 20:33:50.151921  4668 solver.cpp:218] Iteration 33900 (27.4065 iter/s, 3.64877s/100 iters), loss = 0.186367
I0630 20:33:50.151921  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:33:50.151921  4668 solver.cpp:237]     Train net output #1: loss = 0.186367 (* 1 = 0.186367 loss)
I0630 20:33:50.151921  4668 sgd_solver.cpp:105] Iteration 33900, lr = 0.001
I0630 20:33:53.615065 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:33:53.754588  4668 solver.cpp:330] Iteration 34000, Testing net (#0)
I0630 20:33:53.754588  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:33:54.595692  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:33:54.625717  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8732
I0630 20:33:54.625717  4668 solver.cpp:397]     Test net output #1: loss = 0.416025 (* 1 = 0.416025 loss)
I0630 20:33:54.661089  4668 solver.cpp:218] Iteration 34000 (22.2026 iter/s, 4.50397s/100 iters), loss = 0.12846
I0630 20:33:54.661089  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:33:54.661089  4668 solver.cpp:237]     Train net output #1: loss = 0.12846 (* 1 = 0.12846 loss)
I0630 20:33:54.661089  4668 sgd_solver.cpp:105] Iteration 34000, lr = 0.001
I0630 20:33:58.306820  4668 solver.cpp:218] Iteration 34100 (27.4326 iter/s, 3.6453s/100 iters), loss = 0.195782
I0630 20:33:58.306820  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:33:58.306820  4668 solver.cpp:237]     Train net output #1: loss = 0.195782 (* 1 = 0.195782 loss)
I0630 20:33:58.306820  4668 sgd_solver.cpp:105] Iteration 34100, lr = 0.001
I0630 20:34:02.021963  4668 solver.cpp:218] Iteration 34200 (26.8535 iter/s, 3.72391s/100 iters), loss = 0.181516
I0630 20:34:02.021963  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:34:02.021963  4668 solver.cpp:237]     Train net output #1: loss = 0.181516 (* 1 = 0.181516 loss)
I0630 20:34:02.021963  4668 sgd_solver.cpp:105] Iteration 34200, lr = 0.001
I0630 20:34:05.673705  4668 solver.cpp:218] Iteration 34300 (27.4361 iter/s, 3.64483s/100 iters), loss = 0.12159
I0630 20:34:05.673705  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:34:05.673705  4668 solver.cpp:237]     Train net output #1: loss = 0.12159 (* 1 = 0.12159 loss)
I0630 20:34:05.673705  4668 sgd_solver.cpp:105] Iteration 34300, lr = 0.001
I0630 20:34:09.314532  4668 solver.cpp:218] Iteration 34400 (27.4876 iter/s, 3.63801s/100 iters), loss = 0.174292
I0630 20:34:09.314532  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:34:09.314532  4668 solver.cpp:237]     Train net output #1: loss = 0.174292 (* 1 = 0.174292 loss)
I0630 20:34:09.314532  4668 sgd_solver.cpp:105] Iteration 34400, lr = 0.001
I0630 20:34:12.820046 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:34:12.966308  4668 solver.cpp:330] Iteration 34500, Testing net (#0)
I0630 20:34:12.966308  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:34:13.827138  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:34:13.864564  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8739
I0630 20:34:13.864564  4668 solver.cpp:397]     Test net output #1: loss = 0.41608 (* 1 = 0.41608 loss)
I0630 20:34:13.901150  4668 solver.cpp:218] Iteration 34500 (21.804 iter/s, 4.58632s/100 iters), loss = 0.172893
I0630 20:34:13.901150  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:34:13.901150  4668 solver.cpp:237]     Train net output #1: loss = 0.172893 (* 1 = 0.172893 loss)
I0630 20:34:13.901150  4668 sgd_solver.cpp:105] Iteration 34500, lr = 0.001
I0630 20:34:17.539559  4668 solver.cpp:218] Iteration 34600 (27.4241 iter/s, 3.64643s/100 iters), loss = 0.205054
I0630 20:34:17.539559  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:34:17.539559  4668 solver.cpp:237]     Train net output #1: loss = 0.205054 (* 1 = 0.205054 loss)
I0630 20:34:17.539559  4668 sgd_solver.cpp:105] Iteration 34600, lr = 0.001
I0630 20:34:21.181994  4668 solver.cpp:218] Iteration 34700 (27.4789 iter/s, 3.63916s/100 iters), loss = 0.244343
I0630 20:34:21.181994  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:34:21.181994  4668 solver.cpp:237]     Train net output #1: loss = 0.244343 (* 1 = 0.244343 loss)
I0630 20:34:21.181994  4668 sgd_solver.cpp:105] Iteration 34700, lr = 0.001
I0630 20:34:24.823761  4668 solver.cpp:218] Iteration 34800 (27.4386 iter/s, 3.6445s/100 iters), loss = 0.0936947
I0630 20:34:24.823761  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:34:24.823761  4668 solver.cpp:237]     Train net output #1: loss = 0.093695 (* 1 = 0.093695 loss)
I0630 20:34:24.823761  4668 sgd_solver.cpp:105] Iteration 34800, lr = 0.001
I0630 20:34:28.552642  4668 solver.cpp:218] Iteration 34900 (26.8633 iter/s, 3.72254s/100 iters), loss = 0.169889
I0630 20:34:28.552642  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:34:28.552642  4668 solver.cpp:237]     Train net output #1: loss = 0.169889 (* 1 = 0.169889 loss)
I0630 20:34:28.552642  4668 sgd_solver.cpp:105] Iteration 34900, lr = 0.001
I0630 20:34:32.009368 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:34:32.149034  4668 solver.cpp:330] Iteration 35000, Testing net (#0)
I0630 20:34:32.149034  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:34:32.981012  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:34:33.010597  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8771
I0630 20:34:33.010597  4668 solver.cpp:397]     Test net output #1: loss = 0.414209 (* 1 = 0.414209 loss)
I0630 20:34:33.040599  4668 solver.cpp:218] Iteration 35000 (22.255 iter/s, 4.49338s/100 iters), loss = 0.178923
I0630 20:34:33.040599  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:34:33.040599  4668 solver.cpp:237]     Train net output #1: loss = 0.178923 (* 1 = 0.178923 loss)
I0630 20:34:33.040599  4668 sgd_solver.cpp:105] Iteration 35000, lr = 0.001
I0630 20:34:36.753036  4668 solver.cpp:218] Iteration 35100 (26.9952 iter/s, 3.70436s/100 iters), loss = 0.193921
I0630 20:34:36.753036  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:34:36.753036  4668 solver.cpp:237]     Train net output #1: loss = 0.193921 (* 1 = 0.193921 loss)
I0630 20:34:36.753036  4668 sgd_solver.cpp:105] Iteration 35100, lr = 0.001
I0630 20:34:40.406749  4668 solver.cpp:218] Iteration 35200 (27.346 iter/s, 3.65684s/100 iters), loss = 0.135145
I0630 20:34:40.406749  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:34:40.406749  4668 solver.cpp:237]     Train net output #1: loss = 0.135145 (* 1 = 0.135145 loss)
I0630 20:34:40.406749  4668 sgd_solver.cpp:105] Iteration 35200, lr = 0.001
I0630 20:34:44.132697  4668 solver.cpp:218] Iteration 35300 (26.8186 iter/s, 3.72876s/100 iters), loss = 0.152501
I0630 20:34:44.132697  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:34:44.132697  4668 solver.cpp:237]     Train net output #1: loss = 0.152501 (* 1 = 0.152501 loss)
I0630 20:34:44.132697  4668 sgd_solver.cpp:105] Iteration 35300, lr = 0.001
I0630 20:34:47.822496  4668 solver.cpp:218] Iteration 35400 (27.0882 iter/s, 3.69165s/100 iters), loss = 0.131527
I0630 20:34:47.822496  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:34:47.822496  4668 solver.cpp:237]     Train net output #1: loss = 0.131527 (* 1 = 0.131527 loss)
I0630 20:34:47.822496  4668 sgd_solver.cpp:105] Iteration 35400, lr = 0.001
I0630 20:34:51.305085 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:34:51.445188  4668 solver.cpp:330] Iteration 35500, Testing net (#0)
I0630 20:34:51.445188  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:34:52.273416  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:34:52.304940  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:34:52.304940  4668 solver.cpp:397]     Test net output #1: loss = 0.415133 (* 1 = 0.415133 loss)
I0630 20:34:52.333652  4668 solver.cpp:218] Iteration 35500 (22.1874 iter/s, 4.50707s/100 iters), loss = 0.110191
I0630 20:34:52.333652  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:34:52.333652  4668 solver.cpp:237]     Train net output #1: loss = 0.110191 (* 1 = 0.110191 loss)
I0630 20:34:52.333652  4668 sgd_solver.cpp:105] Iteration 35500, lr = 0.001
I0630 20:34:55.968565  4668 solver.cpp:218] Iteration 35600 (27.5273 iter/s, 3.63276s/100 iters), loss = 0.156058
I0630 20:34:55.968565  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:34:55.968565  4668 solver.cpp:237]     Train net output #1: loss = 0.156058 (* 1 = 0.156058 loss)
I0630 20:34:55.968565  4668 sgd_solver.cpp:105] Iteration 35600, lr = 0.001
I0630 20:34:59.660925  4668 solver.cpp:218] Iteration 35700 (27.0868 iter/s, 3.69183s/100 iters), loss = 0.278621
I0630 20:34:59.660925  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:34:59.660925  4668 solver.cpp:237]     Train net output #1: loss = 0.278621 (* 1 = 0.278621 loss)
I0630 20:34:59.660925  4668 sgd_solver.cpp:105] Iteration 35700, lr = 0.001
I0630 20:35:03.358774  4668 solver.cpp:218] Iteration 35800 (27.0729 iter/s, 3.69374s/100 iters), loss = 0.174711
I0630 20:35:03.358774  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:35:03.359275  4668 solver.cpp:237]     Train net output #1: loss = 0.174711 (* 1 = 0.174711 loss)
I0630 20:35:03.359275  4668 sgd_solver.cpp:105] Iteration 35800, lr = 0.001
I0630 20:35:07.005323  4668 solver.cpp:218] Iteration 35900 (27.4124 iter/s, 3.64799s/100 iters), loss = 0.109041
I0630 20:35:07.005323  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:35:07.005323  4668 solver.cpp:237]     Train net output #1: loss = 0.109042 (* 1 = 0.109042 loss)
I0630 20:35:07.005323  4668 sgd_solver.cpp:105] Iteration 35900, lr = 0.001
I0630 20:35:10.483626 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:35:10.623070  4668 solver.cpp:330] Iteration 36000, Testing net (#0)
I0630 20:35:10.623070  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:35:11.476863  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:35:11.506865  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8762
I0630 20:35:11.506865  4668 solver.cpp:397]     Test net output #1: loss = 0.415649 (* 1 = 0.415649 loss)
I0630 20:35:11.553876  4668 solver.cpp:218] Iteration 36000 (21.9973 iter/s, 4.546s/100 iters), loss = 0.158574
I0630 20:35:11.553876  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:35:11.553876  4668 solver.cpp:237]     Train net output #1: loss = 0.158575 (* 1 = 0.158575 loss)
I0630 20:35:11.553876  4668 sgd_solver.cpp:105] Iteration 36000, lr = 0.001
I0630 20:35:15.249325  4668 solver.cpp:218] Iteration 36100 (27.0609 iter/s, 3.69537s/100 iters), loss = 0.225517
I0630 20:35:15.249325  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:35:15.249325  4668 solver.cpp:237]     Train net output #1: loss = 0.225517 (* 1 = 0.225517 loss)
I0630 20:35:15.249325  4668 sgd_solver.cpp:105] Iteration 36100, lr = 0.001
I0630 20:35:18.880417  4668 solver.cpp:218] Iteration 36200 (27.4959 iter/s, 3.6369s/100 iters), loss = 0.13704
I0630 20:35:18.880417  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:35:18.880417  4668 solver.cpp:237]     Train net output #1: loss = 0.13704 (* 1 = 0.13704 loss)
I0630 20:35:18.880417  4668 sgd_solver.cpp:105] Iteration 36200, lr = 0.001
I0630 20:35:22.613243  4668 solver.cpp:218] Iteration 36300 (26.7916 iter/s, 3.73252s/100 iters), loss = 0.162748
I0630 20:35:22.613243  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:35:22.613243  4668 solver.cpp:237]     Train net output #1: loss = 0.162749 (* 1 = 0.162749 loss)
I0630 20:35:22.613243  4668 sgd_solver.cpp:105] Iteration 36300, lr = 0.001
I0630 20:35:26.270817  4668 solver.cpp:218] Iteration 36400 (27.3913 iter/s, 3.65079s/100 iters), loss = 0.108375
I0630 20:35:26.270817  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:35:26.270817  4668 solver.cpp:237]     Train net output #1: loss = 0.108375 (* 1 = 0.108375 loss)
I0630 20:35:26.270817  4668 sgd_solver.cpp:105] Iteration 36400, lr = 0.001
I0630 20:35:29.726198 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:35:29.865216  4668 solver.cpp:330] Iteration 36500, Testing net (#0)
I0630 20:35:29.865216  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:35:30.695281  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:35:30.725284  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8744
I0630 20:35:30.725284  4668 solver.cpp:397]     Test net output #1: loss = 0.420265 (* 1 = 0.420265 loss)
I0630 20:35:30.760622  4668 solver.cpp:218] Iteration 36500 (22.2712 iter/s, 4.4901s/100 iters), loss = 0.231339
I0630 20:35:30.760622  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:35:30.760622  4668 solver.cpp:237]     Train net output #1: loss = 0.231339 (* 1 = 0.231339 loss)
I0630 20:35:30.760622  4668 sgd_solver.cpp:105] Iteration 36500, lr = 0.001
I0630 20:35:34.406661  4668 solver.cpp:218] Iteration 36600 (27.3681 iter/s, 3.65389s/100 iters), loss = 0.0977167
I0630 20:35:34.406661  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:35:34.406661  4668 solver.cpp:237]     Train net output #1: loss = 0.0977169 (* 1 = 0.0977169 loss)
I0630 20:35:34.406661  4668 sgd_solver.cpp:105] Iteration 36600, lr = 0.001
I0630 20:35:38.059041  4668 solver.cpp:218] Iteration 36700 (27.3971 iter/s, 3.65002s/100 iters), loss = 0.170155
I0630 20:35:38.059041  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:35:38.059041  4668 solver.cpp:237]     Train net output #1: loss = 0.170156 (* 1 = 0.170156 loss)
I0630 20:35:38.059041  4668 sgd_solver.cpp:105] Iteration 36700, lr = 0.001
I0630 20:35:41.701385  4668 solver.cpp:218] Iteration 36800 (27.4729 iter/s, 3.63995s/100 iters), loss = 0.164827
I0630 20:35:41.701385  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:35:41.701385  4668 solver.cpp:237]     Train net output #1: loss = 0.164827 (* 1 = 0.164827 loss)
I0630 20:35:41.701385  4668 sgd_solver.cpp:105] Iteration 36800, lr = 0.001
I0630 20:35:45.441519  4668 solver.cpp:218] Iteration 36900 (26.7598 iter/s, 3.73695s/100 iters), loss = 0.188178
I0630 20:35:45.441519  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:35:45.441519  4668 solver.cpp:237]     Train net output #1: loss = 0.188178 (* 1 = 0.188178 loss)
I0630 20:35:45.441519  4668 sgd_solver.cpp:105] Iteration 36900, lr = 0.001
I0630 20:35:48.902568 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:35:49.036710  4668 solver.cpp:330] Iteration 37000, Testing net (#0)
I0630 20:35:49.036710  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:35:49.877712  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:35:49.907724  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8734
I0630 20:35:49.907724  4668 solver.cpp:397]     Test net output #1: loss = 0.418153 (* 1 = 0.418153 loss)
I0630 20:35:49.947729  4668 solver.cpp:218] Iteration 37000 (22.1957 iter/s, 4.50537s/100 iters), loss = 0.159481
I0630 20:35:49.947729  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:35:49.947729  4668 solver.cpp:237]     Train net output #1: loss = 0.159481 (* 1 = 0.159481 loss)
I0630 20:35:49.947729  4668 sgd_solver.cpp:105] Iteration 37000, lr = 0.001
I0630 20:35:53.599056  4668 solver.cpp:218] Iteration 37100 (27.4026 iter/s, 3.64929s/100 iters), loss = 0.219907
I0630 20:35:53.599056  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:35:53.599056  4668 solver.cpp:237]     Train net output #1: loss = 0.219907 (* 1 = 0.219907 loss)
I0630 20:35:53.599056  4668 sgd_solver.cpp:105] Iteration 37100, lr = 0.001
I0630 20:35:57.285852  4668 solver.cpp:218] Iteration 37200 (27.1047 iter/s, 3.6894s/100 iters), loss = 0.174397
I0630 20:35:57.285852  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:35:57.285852  4668 solver.cpp:237]     Train net output #1: loss = 0.174397 (* 1 = 0.174397 loss)
I0630 20:35:57.285852  4668 sgd_solver.cpp:105] Iteration 37200, lr = 0.001
I0630 20:36:00.922848  4668 solver.cpp:218] Iteration 37300 (27.5101 iter/s, 3.63503s/100 iters), loss = 0.155021
I0630 20:36:00.922848  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:36:00.922848  4668 solver.cpp:237]     Train net output #1: loss = 0.155021 (* 1 = 0.155021 loss)
I0630 20:36:00.922848  4668 sgd_solver.cpp:105] Iteration 37300, lr = 0.001
I0630 20:36:04.554575  4668 solver.cpp:218] Iteration 37400 (27.4977 iter/s, 3.63667s/100 iters), loss = 0.128083
I0630 20:36:04.554575  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:36:04.554575  4668 solver.cpp:237]     Train net output #1: loss = 0.128083 (* 1 = 0.128083 loss)
I0630 20:36:04.554575  4668 sgd_solver.cpp:105] Iteration 37400, lr = 0.001
I0630 20:36:08.015202 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:36:08.164832  4668 solver.cpp:330] Iteration 37500, Testing net (#0)
I0630 20:36:08.164832  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:36:08.995460  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:36:09.025475  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8742
I0630 20:36:09.025475  4668 solver.cpp:397]     Test net output #1: loss = 0.41838 (* 1 = 0.41838 loss)
I0630 20:36:09.065476  4668 solver.cpp:218] Iteration 37500 (22.1935 iter/s, 4.50583s/100 iters), loss = 0.133014
I0630 20:36:09.065476  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:36:09.065476  4668 solver.cpp:237]     Train net output #1: loss = 0.133014 (* 1 = 0.133014 loss)
I0630 20:36:09.065476  4668 sgd_solver.cpp:105] Iteration 37500, lr = 0.001
I0630 20:36:12.786572  4668 solver.cpp:218] Iteration 37600 (26.8379 iter/s, 3.72607s/100 iters), loss = 0.190927
I0630 20:36:12.786572  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:36:12.786572  4668 solver.cpp:237]     Train net output #1: loss = 0.190927 (* 1 = 0.190927 loss)
I0630 20:36:12.786572  4668 sgd_solver.cpp:105] Iteration 37600, lr = 0.001
I0630 20:36:16.427377  4668 solver.cpp:218] Iteration 37700 (27.4523 iter/s, 3.64268s/100 iters), loss = 0.15252
I0630 20:36:16.427377  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:36:16.427377  4668 solver.cpp:237]     Train net output #1: loss = 0.15252 (* 1 = 0.15252 loss)
I0630 20:36:16.427377  4668 sgd_solver.cpp:105] Iteration 37700, lr = 0.001
I0630 20:36:20.238776  4668 solver.cpp:218] Iteration 37800 (26.2439 iter/s, 3.81041s/100 iters), loss = 0.156856
I0630 20:36:20.238776  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:36:20.238776  4668 solver.cpp:237]     Train net output #1: loss = 0.156856 (* 1 = 0.156856 loss)
I0630 20:36:20.238776  4668 sgd_solver.cpp:105] Iteration 37800, lr = 0.001
I0630 20:36:23.970542  4668 solver.cpp:218] Iteration 37900 (26.8613 iter/s, 3.72283s/100 iters), loss = 0.111071
I0630 20:36:23.970542  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:36:23.970542  4668 solver.cpp:237]     Train net output #1: loss = 0.111071 (* 1 = 0.111071 loss)
I0630 20:36:23.970542  4668 sgd_solver.cpp:105] Iteration 37900, lr = 0.001
I0630 20:36:27.503921 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:36:27.653717  4668 solver.cpp:330] Iteration 38000, Testing net (#0)
I0630 20:36:27.653717  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:36:28.474174  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:36:28.504175  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8738
I0630 20:36:28.504175  4668 solver.cpp:397]     Test net output #1: loss = 0.416538 (* 1 = 0.416538 loss)
I0630 20:36:28.544188  4668 solver.cpp:218] Iteration 38000 (21.85 iter/s, 4.57666s/100 iters), loss = 0.167151
I0630 20:36:28.544188  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:36:28.544188  4668 solver.cpp:237]     Train net output #1: loss = 0.167152 (* 1 = 0.167152 loss)
I0630 20:36:28.544188  4668 sgd_solver.cpp:46] MultiStep Status: Iteration 38000, step = 2
I0630 20:36:28.544188  4668 sgd_solver.cpp:105] Iteration 38000, lr = 0.0001
I0630 20:36:32.184973  4668 solver.cpp:218] Iteration 38100 (27.465 iter/s, 3.641s/100 iters), loss = 0.184925
I0630 20:36:32.184973  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:36:32.184973  4668 solver.cpp:237]     Train net output #1: loss = 0.184925 (* 1 = 0.184925 loss)
I0630 20:36:32.184973  4668 sgd_solver.cpp:105] Iteration 38100, lr = 0.0001
I0630 20:36:35.924732  4668 solver.cpp:218] Iteration 38200 (26.7705 iter/s, 3.73546s/100 iters), loss = 0.212499
I0630 20:36:35.924732  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:36:35.924732  4668 solver.cpp:237]     Train net output #1: loss = 0.212499 (* 1 = 0.212499 loss)
I0630 20:36:35.925232  4668 sgd_solver.cpp:105] Iteration 38200, lr = 0.0001
I0630 20:36:39.558311  4668 solver.cpp:218] Iteration 38300 (27.4676 iter/s, 3.64065s/100 iters), loss = 0.136814
I0630 20:36:39.558311  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:36:39.558311  4668 solver.cpp:237]     Train net output #1: loss = 0.136815 (* 1 = 0.136815 loss)
I0630 20:36:39.558311  4668 sgd_solver.cpp:105] Iteration 38300, lr = 0.0001
I0630 20:36:43.191633  4668 solver.cpp:218] Iteration 38400 (27.534 iter/s, 3.63187s/100 iters), loss = 0.0901286
I0630 20:36:43.191633  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:36:43.191633  4668 solver.cpp:237]     Train net output #1: loss = 0.0901288 (* 1 = 0.0901288 loss)
I0630 20:36:43.191633  4668 sgd_solver.cpp:105] Iteration 38400, lr = 0.0001
I0630 20:36:46.779119 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:36:46.927258  4668 solver.cpp:330] Iteration 38500, Testing net (#0)
I0630 20:36:46.927258  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:36:47.761910  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:36:47.801913  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I0630 20:36:47.801913  4668 solver.cpp:397]     Test net output #1: loss = 0.415081 (* 1 = 0.415081 loss)
I0630 20:36:47.834425  4668 solver.cpp:218] Iteration 38500 (21.5395 iter/s, 4.64263s/100 iters), loss = 0.130255
I0630 20:36:47.834425  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:36:47.834425  4668 solver.cpp:237]     Train net output #1: loss = 0.130255 (* 1 = 0.130255 loss)
I0630 20:36:47.834425  4668 sgd_solver.cpp:105] Iteration 38500, lr = 0.0001
I0630 20:36:51.532099  4668 solver.cpp:218] Iteration 38600 (27.0945 iter/s, 3.69079s/100 iters), loss = 0.157525
I0630 20:36:51.532099  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:36:51.532099  4668 solver.cpp:237]     Train net output #1: loss = 0.157526 (* 1 = 0.157526 loss)
I0630 20:36:51.532099  4668 sgd_solver.cpp:105] Iteration 38600, lr = 0.0001
I0630 20:36:55.185775  4668 solver.cpp:218] Iteration 38700 (27.3134 iter/s, 3.6612s/100 iters), loss = 0.202423
I0630 20:36:55.185775  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:36:55.185775  4668 solver.cpp:237]     Train net output #1: loss = 0.202423 (* 1 = 0.202423 loss)
I0630 20:36:55.185775  4668 sgd_solver.cpp:105] Iteration 38700, lr = 0.0001
I0630 20:36:58.907999  4668 solver.cpp:218] Iteration 38800 (26.8827 iter/s, 3.71986s/100 iters), loss = 0.1163
I0630 20:36:58.907999  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:36:58.907999  4668 solver.cpp:237]     Train net output #1: loss = 0.116301 (* 1 = 0.116301 loss)
I0630 20:36:58.907999  4668 sgd_solver.cpp:105] Iteration 38800, lr = 0.0001
I0630 20:37:02.558734  4668 solver.cpp:218] Iteration 38900 (27.4136 iter/s, 3.64783s/100 iters), loss = 0.131217
I0630 20:37:02.558734  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:37:02.558734  4668 solver.cpp:237]     Train net output #1: loss = 0.131217 (* 1 = 0.131217 loss)
I0630 20:37:02.558734  4668 sgd_solver.cpp:105] Iteration 38900, lr = 0.0001
I0630 20:37:06.059861 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:37:06.209283  4668 solver.cpp:330] Iteration 39000, Testing net (#0)
I0630 20:37:06.209283  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:37:07.079787  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:37:07.112941  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8755
I0630 20:37:07.112941  4668 solver.cpp:397]     Test net output #1: loss = 0.41648 (* 1 = 0.41648 loss)
I0630 20:37:07.142945  4668 solver.cpp:218] Iteration 39000 (21.8036 iter/s, 4.58641s/100 iters), loss = 0.185026
I0630 20:37:07.142945  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:37:07.142945  4668 solver.cpp:237]     Train net output #1: loss = 0.185027 (* 1 = 0.185027 loss)
I0630 20:37:07.142945  4668 sgd_solver.cpp:105] Iteration 39000, lr = 0.0001
I0630 20:37:10.813835  4668 solver.cpp:218] Iteration 39100 (27.2926 iter/s, 3.664s/100 iters), loss = 0.137715
I0630 20:37:10.813835  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:37:10.813835  4668 solver.cpp:237]     Train net output #1: loss = 0.137715 (* 1 = 0.137715 loss)
I0630 20:37:10.813835  4668 sgd_solver.cpp:105] Iteration 39100, lr = 0.0001
I0630 20:37:14.452877  4668 solver.cpp:218] Iteration 39200 (27.4604 iter/s, 3.6416s/100 iters), loss = 0.271178
I0630 20:37:14.452877  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:37:14.452877  4668 solver.cpp:237]     Train net output #1: loss = 0.271178 (* 1 = 0.271178 loss)
I0630 20:37:14.452877  4668 sgd_solver.cpp:105] Iteration 39200, lr = 0.0001
I0630 20:37:18.192670  4668 solver.cpp:218] Iteration 39300 (26.7609 iter/s, 3.7368s/100 iters), loss = 0.130359
I0630 20:37:18.192670  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:37:18.192670  4668 solver.cpp:237]     Train net output #1: loss = 0.130359 (* 1 = 0.130359 loss)
I0630 20:37:18.192670  4668 sgd_solver.cpp:105] Iteration 39300, lr = 0.0001
I0630 20:37:21.806944  4668 solver.cpp:218] Iteration 39400 (27.6276 iter/s, 3.61957s/100 iters), loss = 0.0852039
I0630 20:37:21.806944  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:37:21.806944  4668 solver.cpp:237]     Train net output #1: loss = 0.0852042 (* 1 = 0.0852042 loss)
I0630 20:37:21.806944  4668 sgd_solver.cpp:105] Iteration 39400, lr = 0.0001
I0630 20:37:25.269218 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:37:25.409477  4668 solver.cpp:330] Iteration 39500, Testing net (#0)
I0630 20:37:25.409477  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:37:26.241603  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:37:26.269836  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8769
I0630 20:37:26.269836  4668 solver.cpp:397]     Test net output #1: loss = 0.414744 (* 1 = 0.414744 loss)
I0630 20:37:26.308908  4668 solver.cpp:218] Iteration 39500 (22.244 iter/s, 4.49559s/100 iters), loss = 0.234949
I0630 20:37:26.308908  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:37:26.308908  4668 solver.cpp:237]     Train net output #1: loss = 0.234949 (* 1 = 0.234949 loss)
I0630 20:37:26.308908  4668 sgd_solver.cpp:105] Iteration 39500, lr = 0.0001
I0630 20:37:29.952787  4668 solver.cpp:218] Iteration 39600 (27.3973 iter/s, 3.64999s/100 iters), loss = 0.124451
I0630 20:37:29.952787  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:37:29.952787  4668 solver.cpp:237]     Train net output #1: loss = 0.124451 (* 1 = 0.124451 loss)
I0630 20:37:29.952787  4668 sgd_solver.cpp:105] Iteration 39600, lr = 0.0001
I0630 20:37:33.604666  4668 solver.cpp:218] Iteration 39700 (27.4143 iter/s, 3.64773s/100 iters), loss = 0.176777
I0630 20:37:33.604666  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:37:33.604666  4668 solver.cpp:237]     Train net output #1: loss = 0.176777 (* 1 = 0.176777 loss)
I0630 20:37:33.604666  4668 sgd_solver.cpp:105] Iteration 39700, lr = 0.0001
I0630 20:37:37.236412  4668 solver.cpp:218] Iteration 39800 (27.5013 iter/s, 3.63619s/100 iters), loss = 0.148213
I0630 20:37:37.236412  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:37:37.236412  4668 solver.cpp:237]     Train net output #1: loss = 0.148213 (* 1 = 0.148213 loss)
I0630 20:37:37.236412  4668 sgd_solver.cpp:105] Iteration 39800, lr = 0.0001
I0630 20:37:40.879372  4668 solver.cpp:218] Iteration 39900 (27.4405 iter/s, 3.64425s/100 iters), loss = 0.0992928
I0630 20:37:40.879372  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:37:40.879372  4668 solver.cpp:237]     Train net output #1: loss = 0.0992931 (* 1 = 0.0992931 loss)
I0630 20:37:40.879372  4668 sgd_solver.cpp:105] Iteration 39900, lr = 0.0001
I0630 20:37:44.440641 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:37:44.591534  4668 solver.cpp:330] Iteration 40000, Testing net (#0)
I0630 20:37:44.591534  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:37:45.411170  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:37:45.441172  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8745
I0630 20:37:45.441172  4668 solver.cpp:397]     Test net output #1: loss = 0.416281 (* 1 = 0.416281 loss)
I0630 20:37:45.471174  4668 solver.cpp:218] Iteration 40000 (21.7786 iter/s, 4.59167s/100 iters), loss = 0.210247
I0630 20:37:45.471174  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:37:45.471174  4668 solver.cpp:237]     Train net output #1: loss = 0.210248 (* 1 = 0.210248 loss)
I0630 20:37:45.471174  4668 sgd_solver.cpp:105] Iteration 40000, lr = 0.0001
I0630 20:37:49.163022  4668 solver.cpp:218] Iteration 40100 (27.0945 iter/s, 3.69079s/100 iters), loss = 0.223922
I0630 20:37:49.163022  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:37:49.163022  4668 solver.cpp:237]     Train net output #1: loss = 0.223922 (* 1 = 0.223922 loss)
I0630 20:37:49.163022  4668 sgd_solver.cpp:105] Iteration 40100, lr = 0.0001
I0630 20:37:52.818488  4668 solver.cpp:218] Iteration 40200 (27.4146 iter/s, 3.64769s/100 iters), loss = 0.224246
I0630 20:37:52.818488  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:37:52.818488  4668 solver.cpp:237]     Train net output #1: loss = 0.224247 (* 1 = 0.224247 loss)
I0630 20:37:52.818488  4668 sgd_solver.cpp:105] Iteration 40200, lr = 0.0001
I0630 20:37:56.521697  4668 solver.cpp:218] Iteration 40300 (26.9733 iter/s, 3.70737s/100 iters), loss = 0.112453
I0630 20:37:56.521697  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:37:56.521697  4668 solver.cpp:237]     Train net output #1: loss = 0.112453 (* 1 = 0.112453 loss)
I0630 20:37:56.521697  4668 sgd_solver.cpp:105] Iteration 40300, lr = 0.0001
I0630 20:38:00.197645  4668 solver.cpp:218] Iteration 40400 (27.2468 iter/s, 3.67015s/100 iters), loss = 0.156082
I0630 20:38:00.197645  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:38:00.197645  4668 solver.cpp:237]     Train net output #1: loss = 0.156082 (* 1 = 0.156082 loss)
I0630 20:38:00.197645  4668 sgd_solver.cpp:105] Iteration 40400, lr = 0.0001
I0630 20:38:03.668339 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:38:03.806365  4668 solver.cpp:330] Iteration 40500, Testing net (#0)
I0630 20:38:03.806365  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:38:04.637186  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:38:04.667187  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8755
I0630 20:38:04.667187  4668 solver.cpp:397]     Test net output #1: loss = 0.416226 (* 1 = 0.416226 loss)
I0630 20:38:04.707203  4668 solver.cpp:218] Iteration 40500 (22.1676 iter/s, 4.51109s/100 iters), loss = 0.150084
I0630 20:38:04.707203  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:38:04.707203  4668 solver.cpp:237]     Train net output #1: loss = 0.150084 (* 1 = 0.150084 loss)
I0630 20:38:04.707203  4668 sgd_solver.cpp:105] Iteration 40500, lr = 0.0001
I0630 20:38:08.347347  4668 solver.cpp:218] Iteration 40600 (27.4666 iter/s, 3.64078s/100 iters), loss = 0.206055
I0630 20:38:08.347347  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:38:08.347347  4668 solver.cpp:237]     Train net output #1: loss = 0.206055 (* 1 = 0.206055 loss)
I0630 20:38:08.347347  4668 sgd_solver.cpp:105] Iteration 40600, lr = 0.0001
I0630 20:38:12.021396  4668 solver.cpp:218] Iteration 40700 (27.215 iter/s, 3.67445s/100 iters), loss = 0.149311
I0630 20:38:12.021396  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:38:12.021396  4668 solver.cpp:237]     Train net output #1: loss = 0.149312 (* 1 = 0.149312 loss)
I0630 20:38:12.021396  4668 sgd_solver.cpp:105] Iteration 40700, lr = 0.0001
I0630 20:38:15.772545  4668 solver.cpp:218] Iteration 40800 (26.6808 iter/s, 3.74801s/100 iters), loss = 0.138825
I0630 20:38:15.772545  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:38:15.772545  4668 solver.cpp:237]     Train net output #1: loss = 0.138826 (* 1 = 0.138826 loss)
I0630 20:38:15.772545  4668 sgd_solver.cpp:105] Iteration 40800, lr = 0.0001
I0630 20:38:19.446983  4668 solver.cpp:218] Iteration 40900 (27.1547 iter/s, 3.6826s/100 iters), loss = 0.140774
I0630 20:38:19.446983  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:38:19.446983  4668 solver.cpp:237]     Train net output #1: loss = 0.140774 (* 1 = 0.140774 loss)
I0630 20:38:19.446983  4668 sgd_solver.cpp:105] Iteration 40900, lr = 0.0001
I0630 20:38:22.911463 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:38:23.047987  4668 solver.cpp:330] Iteration 41000, Testing net (#0)
I0630 20:38:23.047987  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:38:23.875891  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:38:23.912401  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8755
I0630 20:38:23.912401  4668 solver.cpp:397]     Test net output #1: loss = 0.416908 (* 1 = 0.416908 loss)
I0630 20:38:23.947187  4668 solver.cpp:218] Iteration 41000 (22.2712 iter/s, 4.4901s/100 iters), loss = 0.160887
I0630 20:38:23.947187  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:38:23.947187  4668 solver.cpp:237]     Train net output #1: loss = 0.160887 (* 1 = 0.160887 loss)
I0630 20:38:23.947187  4668 sgd_solver.cpp:105] Iteration 41000, lr = 0.0001
I0630 20:38:27.593327  4668 solver.cpp:218] Iteration 41100 (27.394 iter/s, 3.65044s/100 iters), loss = 0.22652
I0630 20:38:27.593327  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:38:27.593327  4668 solver.cpp:237]     Train net output #1: loss = 0.226521 (* 1 = 0.226521 loss)
I0630 20:38:27.593327  4668 sgd_solver.cpp:105] Iteration 41100, lr = 0.0001
I0630 20:38:31.257792  4668 solver.cpp:218] Iteration 41200 (27.2733 iter/s, 3.66658s/100 iters), loss = 0.219843
I0630 20:38:31.257792  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:38:31.257792  4668 solver.cpp:237]     Train net output #1: loss = 0.219843 (* 1 = 0.219843 loss)
I0630 20:38:31.257792  4668 sgd_solver.cpp:105] Iteration 41200, lr = 0.0001
I0630 20:38:34.928613  4668 solver.cpp:218] Iteration 41300 (27.26 iter/s, 3.66838s/100 iters), loss = 0.0863537
I0630 20:38:34.928613  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:38:34.928613  4668 solver.cpp:237]     Train net output #1: loss = 0.086354 (* 1 = 0.086354 loss)
I0630 20:38:34.928613  4668 sgd_solver.cpp:105] Iteration 41300, lr = 0.0001
I0630 20:38:38.560209  4668 solver.cpp:218] Iteration 41400 (27.5368 iter/s, 3.63151s/100 iters), loss = 0.11842
I0630 20:38:38.560209  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:38:38.560209  4668 solver.cpp:237]     Train net output #1: loss = 0.118421 (* 1 = 0.118421 loss)
I0630 20:38:38.560209  4668 sgd_solver.cpp:105] Iteration 41400, lr = 0.0001
I0630 20:38:42.032268 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:38:42.172510  4668 solver.cpp:330] Iteration 41500, Testing net (#0)
I0630 20:38:42.172510  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:38:43.015425  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:38:43.043505  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:38:43.043505  4668 solver.cpp:397]     Test net output #1: loss = 0.417071 (* 1 = 0.417071 loss)
I0630 20:38:43.081944  4668 solver.cpp:218] Iteration 41500 (22.1438 iter/s, 4.51594s/100 iters), loss = 0.170243
I0630 20:38:43.081944  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:38:43.081944  4668 solver.cpp:237]     Train net output #1: loss = 0.170244 (* 1 = 0.170244 loss)
I0630 20:38:43.081944  4668 sgd_solver.cpp:105] Iteration 41500, lr = 0.0001
I0630 20:38:46.765202  4668 solver.cpp:218] Iteration 41600 (27.0959 iter/s, 3.69059s/100 iters), loss = 0.0559825
I0630 20:38:46.765202  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0630 20:38:46.765202  4668 solver.cpp:237]     Train net output #1: loss = 0.0559828 (* 1 = 0.0559828 loss)
I0630 20:38:46.765202  4668 sgd_solver.cpp:105] Iteration 41600, lr = 0.0001
I0630 20:38:50.424196  4668 solver.cpp:218] Iteration 41700 (27.391 iter/s, 3.65084s/100 iters), loss = 0.229038
I0630 20:38:50.424196  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:38:50.424196  4668 solver.cpp:237]     Train net output #1: loss = 0.229038 (* 1 = 0.229038 loss)
I0630 20:38:50.424196  4668 sgd_solver.cpp:105] Iteration 41700, lr = 0.0001
I0630 20:38:54.079874  4668 solver.cpp:218] Iteration 41800 (27.3545 iter/s, 3.6557s/100 iters), loss = 0.166045
I0630 20:38:54.079874  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:38:54.079874  4668 solver.cpp:237]     Train net output #1: loss = 0.166046 (* 1 = 0.166046 loss)
I0630 20:38:54.079874  4668 sgd_solver.cpp:105] Iteration 41800, lr = 0.0001
I0630 20:38:57.749924  4668 solver.cpp:218] Iteration 41900 (27.1877 iter/s, 3.67813s/100 iters), loss = 0.15592
I0630 20:38:57.749924  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:38:57.749924  4668 solver.cpp:237]     Train net output #1: loss = 0.15592 (* 1 = 0.15592 loss)
I0630 20:38:57.749924  4668 sgd_solver.cpp:105] Iteration 41900, lr = 0.0001
I0630 20:39:01.241482 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:39:01.386518  4668 solver.cpp:330] Iteration 42000, Testing net (#0)
I0630 20:39:01.386518  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:39:02.201920  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:39:02.242537  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8759
I0630 20:39:02.242537  4668 solver.cpp:397]     Test net output #1: loss = 0.415987 (* 1 = 0.415987 loss)
I0630 20:39:02.276561  4668 solver.cpp:218] Iteration 42000 (22.1329 iter/s, 4.51816s/100 iters), loss = 0.144688
I0630 20:39:02.276561  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:39:02.276561  4668 solver.cpp:237]     Train net output #1: loss = 0.144688 (* 1 = 0.144688 loss)
I0630 20:39:02.276561  4668 sgd_solver.cpp:105] Iteration 42000, lr = 0.0001
I0630 20:39:05.893440  4668 solver.cpp:218] Iteration 42100 (27.6341 iter/s, 3.61872s/100 iters), loss = 0.157698
I0630 20:39:05.893440  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:39:05.893440  4668 solver.cpp:237]     Train net output #1: loss = 0.157698 (* 1 = 0.157698 loss)
I0630 20:39:05.893440  4668 sgd_solver.cpp:105] Iteration 42100, lr = 0.0001
I0630 20:39:09.534438  4668 solver.cpp:218] Iteration 42200 (27.4881 iter/s, 3.63794s/100 iters), loss = 0.208906
I0630 20:39:09.534438  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:39:09.534438  4668 solver.cpp:237]     Train net output #1: loss = 0.208906 (* 1 = 0.208906 loss)
I0630 20:39:09.534438  4668 sgd_solver.cpp:105] Iteration 42200, lr = 0.0001
I0630 20:39:13.185732  4668 solver.cpp:218] Iteration 42300 (27.387 iter/s, 3.65136s/100 iters), loss = 0.131787
I0630 20:39:13.185732  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:39:13.185732  4668 solver.cpp:237]     Train net output #1: loss = 0.131788 (* 1 = 0.131788 loss)
I0630 20:39:13.185732  4668 sgd_solver.cpp:105] Iteration 42300, lr = 0.0001
I0630 20:39:16.832576  4668 solver.cpp:218] Iteration 42400 (27.4247 iter/s, 3.64634s/100 iters), loss = 0.10815
I0630 20:39:16.832576  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:39:16.832576  4668 solver.cpp:237]     Train net output #1: loss = 0.10815 (* 1 = 0.10815 loss)
I0630 20:39:16.832576  4668 sgd_solver.cpp:105] Iteration 42400, lr = 0.0001
I0630 20:39:20.310780 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:39:20.463701  4668 solver.cpp:330] Iteration 42500, Testing net (#0)
I0630 20:39:20.463701  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:39:21.316701  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:39:21.348949  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8755
I0630 20:39:21.348949  4668 solver.cpp:397]     Test net output #1: loss = 0.416411 (* 1 = 0.416411 loss)
I0630 20:39:21.388952  4668 solver.cpp:218] Iteration 42500 (21.9503 iter/s, 4.55574s/100 iters), loss = 0.1632
I0630 20:39:21.388952  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:39:21.388952  4668 solver.cpp:237]     Train net output #1: loss = 0.1632 (* 1 = 0.1632 loss)
I0630 20:39:21.388952  4668 sgd_solver.cpp:105] Iteration 42500, lr = 0.0001
I0630 20:39:25.018100  4668 solver.cpp:218] Iteration 42600 (27.5548 iter/s, 3.62914s/100 iters), loss = 0.195304
I0630 20:39:25.018100  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:39:25.018100  4668 solver.cpp:237]     Train net output #1: loss = 0.195304 (* 1 = 0.195304 loss)
I0630 20:39:25.018100  4668 sgd_solver.cpp:105] Iteration 42600, lr = 0.0001
I0630 20:39:28.644613  4668 solver.cpp:218] Iteration 42700 (27.5795 iter/s, 3.62588s/100 iters), loss = 0.146885
I0630 20:39:28.644613  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:39:28.644613  4668 solver.cpp:237]     Train net output #1: loss = 0.146885 (* 1 = 0.146885 loss)
I0630 20:39:28.644613  4668 sgd_solver.cpp:105] Iteration 42700, lr = 0.0001
I0630 20:39:32.265377  4668 solver.cpp:218] Iteration 42800 (27.6172 iter/s, 3.62093s/100 iters), loss = 0.0709402
I0630 20:39:32.265377  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0630 20:39:32.266382  4668 solver.cpp:237]     Train net output #1: loss = 0.0709404 (* 1 = 0.0709404 loss)
I0630 20:39:32.266382  4668 sgd_solver.cpp:105] Iteration 42800, lr = 0.0001
I0630 20:39:35.883096  4668 solver.cpp:218] Iteration 42900 (27.5833 iter/s, 3.62538s/100 iters), loss = 0.129055
I0630 20:39:35.883096  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:39:35.883096  4668 solver.cpp:237]     Train net output #1: loss = 0.129055 (* 1 = 0.129055 loss)
I0630 20:39:35.883096  4668 sgd_solver.cpp:105] Iteration 42900, lr = 0.0001
I0630 20:39:39.332233 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:39:39.482292  4668 solver.cpp:330] Iteration 43000, Testing net (#0)
I0630 20:39:39.482292  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:39:40.307538  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:39:40.333632  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8756
I0630 20:39:40.333632  4668 solver.cpp:397]     Test net output #1: loss = 0.415733 (* 1 = 0.415733 loss)
I0630 20:39:40.372803  4668 solver.cpp:218] Iteration 43000 (22.3141 iter/s, 4.48147s/100 iters), loss = 0.0859312
I0630 20:39:40.372803  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:39:40.372803  4668 solver.cpp:237]     Train net output #1: loss = 0.0859314 (* 1 = 0.0859314 loss)
I0630 20:39:40.372803  4668 sgd_solver.cpp:105] Iteration 43000, lr = 0.0001
I0630 20:39:43.986280  4668 solver.cpp:218] Iteration 43100 (27.6224 iter/s, 3.62025s/100 iters), loss = 0.105599
I0630 20:39:43.986280  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:39:43.986280  4668 solver.cpp:237]     Train net output #1: loss = 0.1056 (* 1 = 0.1056 loss)
I0630 20:39:43.986280  4668 sgd_solver.cpp:105] Iteration 43100, lr = 0.0001
I0630 20:39:47.613454  4668 solver.cpp:218] Iteration 43200 (27.6059 iter/s, 3.62241s/100 iters), loss = 0.159063
I0630 20:39:47.613454  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:39:47.613454  4668 solver.cpp:237]     Train net output #1: loss = 0.159064 (* 1 = 0.159064 loss)
I0630 20:39:47.613454  4668 sgd_solver.cpp:105] Iteration 43200, lr = 0.0001
I0630 20:39:51.233018  4668 solver.cpp:218] Iteration 43300 (27.6418 iter/s, 3.61771s/100 iters), loss = 0.126087
I0630 20:39:51.233018  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:39:51.233018  4668 solver.cpp:237]     Train net output #1: loss = 0.126088 (* 1 = 0.126088 loss)
I0630 20:39:51.233018  4668 sgd_solver.cpp:105] Iteration 43300, lr = 0.0001
I0630 20:39:54.845624  4668 solver.cpp:218] Iteration 43400 (27.6249 iter/s, 3.61992s/100 iters), loss = 0.148851
I0630 20:39:54.845624  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:39:54.845624  4668 solver.cpp:237]     Train net output #1: loss = 0.148852 (* 1 = 0.148852 loss)
I0630 20:39:54.845624  4668 sgd_solver.cpp:105] Iteration 43400, lr = 0.0001
I0630 20:39:58.303858 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:39:58.446323  4668 solver.cpp:330] Iteration 43500, Testing net (#0)
I0630 20:39:58.446323  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:39:59.271580  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:39:59.299281  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8755
I0630 20:39:59.299281  4668 solver.cpp:397]     Test net output #1: loss = 0.416067 (* 1 = 0.416067 loss)
I0630 20:39:59.329278  4668 solver.cpp:218] Iteration 43500 (22.3118 iter/s, 4.48193s/100 iters), loss = 0.117217
I0630 20:39:59.329278  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:39:59.329278  4668 solver.cpp:237]     Train net output #1: loss = 0.117217 (* 1 = 0.117217 loss)
I0630 20:39:59.329278  4668 sgd_solver.cpp:105] Iteration 43500, lr = 0.0001
I0630 20:40:03.023001  4668 solver.cpp:218] Iteration 43600 (27.1128 iter/s, 3.6883s/100 iters), loss = 0.138878
I0630 20:40:03.023001  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:40:03.023001  4668 solver.cpp:237]     Train net output #1: loss = 0.138878 (* 1 = 0.138878 loss)
I0630 20:40:03.023001  4668 sgd_solver.cpp:105] Iteration 43600, lr = 0.0001
I0630 20:40:06.643352  4668 solver.cpp:218] Iteration 43700 (27.6156 iter/s, 3.62115s/100 iters), loss = 0.200096
I0630 20:40:06.643352  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:40:06.643352  4668 solver.cpp:237]     Train net output #1: loss = 0.200097 (* 1 = 0.200097 loss)
I0630 20:40:06.643352  4668 sgd_solver.cpp:105] Iteration 43700, lr = 0.0001
I0630 20:40:10.267854  4668 solver.cpp:218] Iteration 43800 (27.6183 iter/s, 3.62078s/100 iters), loss = 0.10488
I0630 20:40:10.267854  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:40:10.267854  4668 solver.cpp:237]     Train net output #1: loss = 0.104881 (* 1 = 0.104881 loss)
I0630 20:40:10.267854  4668 sgd_solver.cpp:105] Iteration 43800, lr = 0.0001
I0630 20:40:13.889452  4668 solver.cpp:218] Iteration 43900 (27.6073 iter/s, 3.62223s/100 iters), loss = 0.200666
I0630 20:40:13.889452  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:40:13.889452  4668 solver.cpp:237]     Train net output #1: loss = 0.200667 (* 1 = 0.200667 loss)
I0630 20:40:13.889452  4668 sgd_solver.cpp:105] Iteration 43900, lr = 0.0001
I0630 20:40:17.329574 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:40:17.474797  4668 solver.cpp:330] Iteration 44000, Testing net (#0)
I0630 20:40:17.474797  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:40:18.296773  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:40:18.326792  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:40:18.326792  4668 solver.cpp:397]     Test net output #1: loss = 0.415766 (* 1 = 0.415766 loss)
I0630 20:40:18.366794  4668 solver.cpp:218] Iteration 44000 (22.3377 iter/s, 4.47674s/100 iters), loss = 0.156986
I0630 20:40:18.366794  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:40:18.366794  4668 solver.cpp:237]     Train net output #1: loss = 0.156986 (* 1 = 0.156986 loss)
I0630 20:40:18.366794  4668 sgd_solver.cpp:46] MultiStep Status: Iteration 44000, step = 3
I0630 20:40:18.366794  4668 sgd_solver.cpp:105] Iteration 44000, lr = 1e-05
I0630 20:40:21.986984  4668 solver.cpp:218] Iteration 44100 (27.6191 iter/s, 3.62068s/100 iters), loss = 0.165109
I0630 20:40:21.986984  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:40:21.986984  4668 solver.cpp:237]     Train net output #1: loss = 0.165109 (* 1 = 0.165109 loss)
I0630 20:40:21.986984  4668 sgd_solver.cpp:105] Iteration 44100, lr = 1e-05
I0630 20:40:25.603613  4668 solver.cpp:218] Iteration 44200 (27.6045 iter/s, 3.6226s/100 iters), loss = 0.134177
I0630 20:40:25.603613  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:40:25.603613  4668 solver.cpp:237]     Train net output #1: loss = 0.134177 (* 1 = 0.134177 loss)
I0630 20:40:25.603613  4668 sgd_solver.cpp:105] Iteration 44200, lr = 1e-05
I0630 20:40:29.240072  4668 solver.cpp:218] Iteration 44300 (27.5693 iter/s, 3.62722s/100 iters), loss = 0.131082
I0630 20:40:29.240072  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:40:29.240072  4668 solver.cpp:237]     Train net output #1: loss = 0.131082 (* 1 = 0.131082 loss)
I0630 20:40:29.240072  4668 sgd_solver.cpp:105] Iteration 44300, lr = 1e-05
I0630 20:40:32.863454  4668 solver.cpp:218] Iteration 44400 (27.583 iter/s, 3.62542s/100 iters), loss = 0.137645
I0630 20:40:32.863454  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:40:32.863454  4668 solver.cpp:237]     Train net output #1: loss = 0.137645 (* 1 = 0.137645 loss)
I0630 20:40:32.863454  4668 sgd_solver.cpp:105] Iteration 44400, lr = 1e-05
I0630 20:40:36.315451 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:40:36.458386  4668 solver.cpp:330] Iteration 44500, Testing net (#0)
I0630 20:40:36.458386  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:40:37.278267  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:40:37.308359  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 20:40:37.308359  4668 solver.cpp:397]     Test net output #1: loss = 0.41571 (* 1 = 0.41571 loss)
I0630 20:40:37.337373  4668 solver.cpp:218] Iteration 44500 (22.3273 iter/s, 4.47882s/100 iters), loss = 0.178785
I0630 20:40:37.337373  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:40:37.337373  4668 solver.cpp:237]     Train net output #1: loss = 0.178785 (* 1 = 0.178785 loss)
I0630 20:40:37.337373  4668 sgd_solver.cpp:105] Iteration 44500, lr = 1e-05
I0630 20:40:40.959682  4668 solver.cpp:218] Iteration 44600 (27.6033 iter/s, 3.62275s/100 iters), loss = 0.128774
I0630 20:40:40.959682  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:40:40.959682  4668 solver.cpp:237]     Train net output #1: loss = 0.128774 (* 1 = 0.128774 loss)
I0630 20:40:40.959682  4668 sgd_solver.cpp:105] Iteration 44600, lr = 1e-05
I0630 20:40:44.591162  4668 solver.cpp:218] Iteration 44700 (27.6069 iter/s, 3.62228s/100 iters), loss = 0.186224
I0630 20:40:44.591162  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:40:44.591162  4668 solver.cpp:237]     Train net output #1: loss = 0.186224 (* 1 = 0.186224 loss)
I0630 20:40:44.591162  4668 sgd_solver.cpp:105] Iteration 44700, lr = 1e-05
I0630 20:40:48.205814  4668 solver.cpp:218] Iteration 44800 (27.615 iter/s, 3.62123s/100 iters), loss = 0.113571
I0630 20:40:48.205814  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:40:48.205814  4668 solver.cpp:237]     Train net output #1: loss = 0.113571 (* 1 = 0.113571 loss)
I0630 20:40:48.205814  4668 sgd_solver.cpp:105] Iteration 44800, lr = 1e-05
I0630 20:40:51.836221  4668 solver.cpp:218] Iteration 44900 (27.601 iter/s, 3.62306s/100 iters), loss = 0.149922
I0630 20:40:51.836221  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:40:51.836221  4668 solver.cpp:237]     Train net output #1: loss = 0.149922 (* 1 = 0.149922 loss)
I0630 20:40:51.836221  4668 sgd_solver.cpp:105] Iteration 44900, lr = 1e-05
I0630 20:40:55.279322 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:40:55.421356  4668 solver.cpp:330] Iteration 45000, Testing net (#0)
I0630 20:40:55.421356  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:40:56.236907  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:40:56.276909  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:40:56.276909  4668 solver.cpp:397]     Test net output #1: loss = 0.416336 (* 1 = 0.416336 loss)
I0630 20:40:56.311900  4668 solver.cpp:218] Iteration 45000 (22.3449 iter/s, 4.4753s/100 iters), loss = 0.156968
I0630 20:40:56.311900  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:40:56.311900  4668 solver.cpp:237]     Train net output #1: loss = 0.156968 (* 1 = 0.156968 loss)
I0630 20:40:56.311900  4668 sgd_solver.cpp:105] Iteration 45000, lr = 1e-05
I0630 20:40:59.929512  4668 solver.cpp:218] Iteration 45100 (27.5919 iter/s, 3.62426s/100 iters), loss = 0.207801
I0630 20:40:59.929512  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:40:59.929512  4668 solver.cpp:237]     Train net output #1: loss = 0.207801 (* 1 = 0.207801 loss)
I0630 20:40:59.929512  4668 sgd_solver.cpp:105] Iteration 45100, lr = 1e-05
I0630 20:41:03.552057  4668 solver.cpp:218] Iteration 45200 (27.6144 iter/s, 3.6213s/100 iters), loss = 0.114058
I0630 20:41:03.552057  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:41:03.552057  4668 solver.cpp:237]     Train net output #1: loss = 0.114058 (* 1 = 0.114058 loss)
I0630 20:41:03.552057  4668 sgd_solver.cpp:105] Iteration 45200, lr = 1e-05
I0630 20:41:07.174963  4668 solver.cpp:218] Iteration 45300 (27.605 iter/s, 3.62253s/100 iters), loss = 0.136056
I0630 20:41:07.174963  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:41:07.174963  4668 solver.cpp:237]     Train net output #1: loss = 0.136056 (* 1 = 0.136056 loss)
I0630 20:41:07.174963  4668 sgd_solver.cpp:105] Iteration 45300, lr = 1e-05
I0630 20:41:10.797622  4668 solver.cpp:218] Iteration 45400 (27.615 iter/s, 3.62122s/100 iters), loss = 0.0998699
I0630 20:41:10.797622  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:41:10.797622  4668 solver.cpp:237]     Train net output #1: loss = 0.0998701 (* 1 = 0.0998701 loss)
I0630 20:41:10.797622  4668 sgd_solver.cpp:105] Iteration 45400, lr = 1e-05
I0630 20:41:14.240522 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:41:14.390205  4668 solver.cpp:330] Iteration 45500, Testing net (#0)
I0630 20:41:14.390205  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:41:15.210449  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:41:15.240496  4668 solver.cpp:397]     Test net output #0: accuracy = 0.875899
I0630 20:41:15.240496  4668 solver.cpp:397]     Test net output #1: loss = 0.415796 (* 1 = 0.415796 loss)
I0630 20:41:15.273651  4668 solver.cpp:218] Iteration 45500 (22.3326 iter/s, 4.47776s/100 iters), loss = 0.138009
I0630 20:41:15.273651  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:41:15.273651  4668 solver.cpp:237]     Train net output #1: loss = 0.13801 (* 1 = 0.13801 loss)
I0630 20:41:15.273651  4668 sgd_solver.cpp:105] Iteration 45500, lr = 1e-05
I0630 20:41:18.904080  4668 solver.cpp:218] Iteration 45600 (27.6002 iter/s, 3.62316s/100 iters), loss = 0.17035
I0630 20:41:18.904080  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:41:18.904080  4668 solver.cpp:237]     Train net output #1: loss = 0.17035 (* 1 = 0.17035 loss)
I0630 20:41:18.904080  4668 sgd_solver.cpp:105] Iteration 45600, lr = 1e-05
I0630 20:41:22.516734  4668 solver.cpp:218] Iteration 45700 (27.6168 iter/s, 3.62098s/100 iters), loss = 0.201189
I0630 20:41:22.516734  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:41:22.516734  4668 solver.cpp:237]     Train net output #1: loss = 0.201189 (* 1 = 0.201189 loss)
I0630 20:41:22.516734  4668 sgd_solver.cpp:105] Iteration 45700, lr = 1e-05
I0630 20:41:26.140516  4668 solver.cpp:218] Iteration 45800 (27.6078 iter/s, 3.62217s/100 iters), loss = 0.112099
I0630 20:41:26.140516  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:41:26.140516  4668 solver.cpp:237]     Train net output #1: loss = 0.1121 (* 1 = 0.1121 loss)
I0630 20:41:26.140516  4668 sgd_solver.cpp:105] Iteration 45800, lr = 1e-05
I0630 20:41:29.761837  4668 solver.cpp:218] Iteration 45900 (27.6099 iter/s, 3.62189s/100 iters), loss = 0.076528
I0630 20:41:29.761837  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:41:29.761837  4668 solver.cpp:237]     Train net output #1: loss = 0.0765282 (* 1 = 0.0765282 loss)
I0630 20:41:29.761837  4668 sgd_solver.cpp:105] Iteration 45900, lr = 1e-05
I0630 20:41:33.214524 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:41:33.354743  4668 solver.cpp:330] Iteration 46000, Testing net (#0)
I0630 20:41:33.354743  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:41:34.183531  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:41:34.213529  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:41:34.213529  4668 solver.cpp:397]     Test net output #1: loss = 0.416053 (* 1 = 0.416053 loss)
I0630 20:41:34.246029  4668 solver.cpp:218] Iteration 46000 (22.3152 iter/s, 4.48126s/100 iters), loss = 0.14809
I0630 20:41:34.246029  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:41:34.246029  4668 solver.cpp:237]     Train net output #1: loss = 0.148091 (* 1 = 0.148091 loss)
I0630 20:41:34.246029  4668 sgd_solver.cpp:105] Iteration 46000, lr = 1e-05
I0630 20:41:37.869046  4668 solver.cpp:218] Iteration 46100 (27.609 iter/s, 3.622s/100 iters), loss = 0.143266
I0630 20:41:37.869046  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:41:37.869046  4668 solver.cpp:237]     Train net output #1: loss = 0.143267 (* 1 = 0.143267 loss)
I0630 20:41:37.869046  4668 sgd_solver.cpp:105] Iteration 46100, lr = 1e-05
I0630 20:41:41.490599  4668 solver.cpp:218] Iteration 46200 (27.633 iter/s, 3.61887s/100 iters), loss = 0.233795
I0630 20:41:41.490599  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:41:41.490599  4668 solver.cpp:237]     Train net output #1: loss = 0.233796 (* 1 = 0.233796 loss)
I0630 20:41:41.490599  4668 sgd_solver.cpp:105] Iteration 46200, lr = 1e-05
I0630 20:41:45.112964  4668 solver.cpp:218] Iteration 46300 (27.6192 iter/s, 3.62067s/100 iters), loss = 0.138025
I0630 20:41:45.112964  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:41:45.112964  4668 solver.cpp:237]     Train net output #1: loss = 0.138025 (* 1 = 0.138025 loss)
I0630 20:41:45.112964  4668 sgd_solver.cpp:105] Iteration 46300, lr = 1e-05
I0630 20:41:48.736925  4668 solver.cpp:218] Iteration 46400 (27.6031 iter/s, 3.62279s/100 iters), loss = 0.104339
I0630 20:41:48.736925  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:41:48.736925  4668 solver.cpp:237]     Train net output #1: loss = 0.10434 (* 1 = 0.10434 loss)
I0630 20:41:48.736925  4668 sgd_solver.cpp:105] Iteration 46400, lr = 1e-05
I0630 20:41:52.180141 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:41:52.326344  4668 solver.cpp:330] Iteration 46500, Testing net (#0)
I0630 20:41:52.326344  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:41:53.140702  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:41:53.180686  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:41:53.180686  4668 solver.cpp:397]     Test net output #1: loss = 0.416038 (* 1 = 0.416038 loss)
I0630 20:41:53.210698  4668 solver.cpp:218] Iteration 46500 (22.3277 iter/s, 4.47875s/100 iters), loss = 0.14615
I0630 20:41:53.210698  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:41:53.210698  4668 solver.cpp:237]     Train net output #1: loss = 0.14615 (* 1 = 0.14615 loss)
I0630 20:41:53.210698  4668 sgd_solver.cpp:105] Iteration 46500, lr = 1e-05
I0630 20:41:56.832978  4668 solver.cpp:218] Iteration 46600 (27.6145 iter/s, 3.62129s/100 iters), loss = 0.161335
I0630 20:41:56.832978  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:41:56.832978  4668 solver.cpp:237]     Train net output #1: loss = 0.161335 (* 1 = 0.161335 loss)
I0630 20:41:56.832978  4668 sgd_solver.cpp:105] Iteration 46600, lr = 1e-05
I0630 20:42:00.457420  4668 solver.cpp:218] Iteration 46700 (27.6154 iter/s, 3.62117s/100 iters), loss = 0.187596
I0630 20:42:00.457420  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:42:00.457420  4668 solver.cpp:237]     Train net output #1: loss = 0.187596 (* 1 = 0.187596 loss)
I0630 20:42:00.457420  4668 sgd_solver.cpp:105] Iteration 46700, lr = 1e-05
I0630 20:42:04.079984  4668 solver.cpp:218] Iteration 46800 (27.6201 iter/s, 3.62056s/100 iters), loss = 0.103562
I0630 20:42:04.079984  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:42:04.079984  4668 solver.cpp:237]     Train net output #1: loss = 0.103563 (* 1 = 0.103563 loss)
I0630 20:42:04.079984  4668 sgd_solver.cpp:105] Iteration 46800, lr = 1e-05
I0630 20:42:07.701666  4668 solver.cpp:218] Iteration 46900 (27.597 iter/s, 3.62358s/100 iters), loss = 0.120413
I0630 20:42:07.701666  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:42:07.701666  4668 solver.cpp:237]     Train net output #1: loss = 0.120413 (* 1 = 0.120413 loss)
I0630 20:42:07.701666  4668 sgd_solver.cpp:105] Iteration 46900, lr = 1e-05
I0630 20:42:11.142633 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:42:11.291268  4668 solver.cpp:330] Iteration 47000, Testing net (#0)
I0630 20:42:11.291268  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:42:12.117153  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:42:12.143366  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:42:12.143366  4668 solver.cpp:397]     Test net output #1: loss = 0.416184 (* 1 = 0.416184 loss)
I0630 20:42:12.173368  4668 solver.cpp:218] Iteration 47000 (22.332 iter/s, 4.47787s/100 iters), loss = 0.227207
I0630 20:42:12.173368  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:42:12.173368  4668 solver.cpp:237]     Train net output #1: loss = 0.227208 (* 1 = 0.227208 loss)
I0630 20:42:12.173368  4668 sgd_solver.cpp:105] Iteration 47000, lr = 1e-05
I0630 20:42:15.797423  4668 solver.cpp:218] Iteration 47100 (27.5935 iter/s, 3.62404s/100 iters), loss = 0.172268
I0630 20:42:15.807430  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:42:15.807430  4668 solver.cpp:237]     Train net output #1: loss = 0.172268 (* 1 = 0.172268 loss)
I0630 20:42:15.807430  4668 sgd_solver.cpp:105] Iteration 47100, lr = 1e-05
I0630 20:42:19.429368  4668 solver.cpp:218] Iteration 47200 (27.5545 iter/s, 3.62918s/100 iters), loss = 0.199243
I0630 20:42:19.429368  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:42:19.429368  4668 solver.cpp:237]     Train net output #1: loss = 0.199243 (* 1 = 0.199243 loss)
I0630 20:42:19.429368  4668 sgd_solver.cpp:105] Iteration 47200, lr = 1e-05
I0630 20:42:23.053438  4668 solver.cpp:218] Iteration 47300 (27.5979 iter/s, 3.62346s/100 iters), loss = 0.155348
I0630 20:42:23.053438  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:42:23.053438  4668 solver.cpp:237]     Train net output #1: loss = 0.155348 (* 1 = 0.155348 loss)
I0630 20:42:23.053438  4668 sgd_solver.cpp:105] Iteration 47300, lr = 1e-05
I0630 20:42:26.684459  4668 solver.cpp:218] Iteration 47400 (27.5937 iter/s, 3.62402s/100 iters), loss = 0.0905632
I0630 20:42:26.684459  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:42:26.684459  4668 solver.cpp:237]     Train net output #1: loss = 0.0905634 (* 1 = 0.0905634 loss)
I0630 20:42:26.684459  4668 sgd_solver.cpp:105] Iteration 47400, lr = 1e-05
I0630 20:42:30.137632 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:42:30.280270  4668 solver.cpp:330] Iteration 47500, Testing net (#0)
I0630 20:42:30.280270  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:42:31.104804  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:42:31.136301  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:42:31.136801  4668 solver.cpp:397]     Test net output #1: loss = 0.416247 (* 1 = 0.416247 loss)
I0630 20:42:31.169716  4668 solver.cpp:218] Iteration 47500 (22.2936 iter/s, 4.48558s/100 iters), loss = 0.182583
I0630 20:42:31.169716  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:42:31.169716  4668 solver.cpp:237]     Train net output #1: loss = 0.182584 (* 1 = 0.182584 loss)
I0630 20:42:31.169716  4668 sgd_solver.cpp:105] Iteration 47500, lr = 1e-05
I0630 20:42:34.792369  4668 solver.cpp:218] Iteration 47600 (27.5888 iter/s, 3.62467s/100 iters), loss = 0.200065
I0630 20:42:34.792369  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:42:34.792369  4668 solver.cpp:237]     Train net output #1: loss = 0.200065 (* 1 = 0.200065 loss)
I0630 20:42:34.792369  4668 sgd_solver.cpp:105] Iteration 47600, lr = 1e-05
I0630 20:42:38.413892  4668 solver.cpp:218] Iteration 47700 (27.6171 iter/s, 3.62094s/100 iters), loss = 0.115789
I0630 20:42:38.413892  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:42:38.413892  4668 solver.cpp:237]     Train net output #1: loss = 0.11579 (* 1 = 0.11579 loss)
I0630 20:42:38.413892  4668 sgd_solver.cpp:105] Iteration 47700, lr = 1e-05
I0630 20:42:42.040594  4668 solver.cpp:218] Iteration 47800 (27.6005 iter/s, 3.62312s/100 iters), loss = 0.128628
I0630 20:42:42.040594  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:42:42.040594  4668 solver.cpp:237]     Train net output #1: loss = 0.128628 (* 1 = 0.128628 loss)
I0630 20:42:42.040594  4668 sgd_solver.cpp:105] Iteration 47800, lr = 1e-05
I0630 20:42:45.658601  4668 solver.cpp:218] Iteration 47900 (27.5965 iter/s, 3.62364s/100 iters), loss = 0.131447
I0630 20:42:45.658601  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:42:45.658601  4668 solver.cpp:237]     Train net output #1: loss = 0.131447 (* 1 = 0.131447 loss)
I0630 20:42:45.658601  4668 sgd_solver.cpp:105] Iteration 47900, lr = 1e-05
I0630 20:42:49.103564 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:42:49.251109  4668 solver.cpp:330] Iteration 48000, Testing net (#0)
I0630 20:42:49.251109  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:42:50.079249  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:42:50.111255  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:42:50.111255  4668 solver.cpp:397]     Test net output #1: loss = 0.41572 (* 1 = 0.41572 loss)
I0630 20:42:50.146406  4668 solver.cpp:218] Iteration 48000 (22.3155 iter/s, 4.48118s/100 iters), loss = 0.110181
I0630 20:42:50.146406  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:42:50.146406  4668 solver.cpp:237]     Train net output #1: loss = 0.110181 (* 1 = 0.110181 loss)
I0630 20:42:50.146406  4668 sgd_solver.cpp:105] Iteration 48000, lr = 1e-05
I0630 20:42:53.764760  4668 solver.cpp:218] Iteration 48100 (27.5906 iter/s, 3.62442s/100 iters), loss = 0.163919
I0630 20:42:53.764760  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:42:53.764760  4668 solver.cpp:237]     Train net output #1: loss = 0.163919 (* 1 = 0.163919 loss)
I0630 20:42:53.764760  4668 sgd_solver.cpp:105] Iteration 48100, lr = 1e-05
I0630 20:42:57.386857  4668 solver.cpp:218] Iteration 48200 (27.591 iter/s, 3.62437s/100 iters), loss = 0.124647
I0630 20:42:57.386857  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:42:57.386857  4668 solver.cpp:237]     Train net output #1: loss = 0.124647 (* 1 = 0.124647 loss)
I0630 20:42:57.386857  4668 sgd_solver.cpp:105] Iteration 48200, lr = 1e-05
I0630 20:43:01.022799  4668 solver.cpp:218] Iteration 48300 (27.5741 iter/s, 3.62659s/100 iters), loss = 0.141403
I0630 20:43:01.022799  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:43:01.022799  4668 solver.cpp:237]     Train net output #1: loss = 0.141403 (* 1 = 0.141403 loss)
I0630 20:43:01.022799  4668 sgd_solver.cpp:105] Iteration 48300, lr = 1e-05
I0630 20:43:04.644237  4668 solver.cpp:218] Iteration 48400 (27.5757 iter/s, 3.62638s/100 iters), loss = 0.117741
I0630 20:43:04.644237  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:43:04.644237  4668 solver.cpp:237]     Train net output #1: loss = 0.117741 (* 1 = 0.117741 loss)
I0630 20:43:04.644237  4668 sgd_solver.cpp:105] Iteration 48400, lr = 1e-05
I0630 20:43:08.097841 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:43:08.234535  4668 solver.cpp:330] Iteration 48500, Testing net (#0)
I0630 20:43:08.234535  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:43:09.073810  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:43:09.105754  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8758
I0630 20:43:09.105754  4668 solver.cpp:397]     Test net output #1: loss = 0.416164 (* 1 = 0.416164 loss)
I0630 20:43:09.139993  4668 solver.cpp:218] Iteration 48500 (22.2702 iter/s, 4.4903s/100 iters), loss = 0.115463
I0630 20:43:09.139993  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:43:09.139993  4668 solver.cpp:237]     Train net output #1: loss = 0.115463 (* 1 = 0.115463 loss)
I0630 20:43:09.139993  4668 sgd_solver.cpp:105] Iteration 48500, lr = 1e-05
I0630 20:43:12.776793  4668 solver.cpp:218] Iteration 48600 (27.4863 iter/s, 3.63817s/100 iters), loss = 0.173158
I0630 20:43:12.776793  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:43:12.776793  4668 solver.cpp:237]     Train net output #1: loss = 0.173158 (* 1 = 0.173158 loss)
I0630 20:43:12.776793  4668 sgd_solver.cpp:105] Iteration 48600, lr = 1e-05
I0630 20:43:16.400501  4668 solver.cpp:218] Iteration 48700 (27.6106 iter/s, 3.6218s/100 iters), loss = 0.20554
I0630 20:43:16.401026  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:43:16.401026  4668 solver.cpp:237]     Train net output #1: loss = 0.20554 (* 1 = 0.20554 loss)
I0630 20:43:16.401026  4668 sgd_solver.cpp:105] Iteration 48700, lr = 1e-05
I0630 20:43:20.022811  4668 solver.cpp:218] Iteration 48800 (27.5997 iter/s, 3.62323s/100 iters), loss = 0.121653
I0630 20:43:20.022811  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:43:20.022811  4668 solver.cpp:237]     Train net output #1: loss = 0.121653 (* 1 = 0.121653 loss)
I0630 20:43:20.022811  4668 sgd_solver.cpp:105] Iteration 48800, lr = 1e-05
I0630 20:43:23.645588  4668 solver.cpp:218] Iteration 48900 (27.5588 iter/s, 3.6286s/100 iters), loss = 0.106826
I0630 20:43:23.645588  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:43:23.645588  4668 solver.cpp:237]     Train net output #1: loss = 0.106826 (* 1 = 0.106826 loss)
I0630 20:43:23.645588  4668 sgd_solver.cpp:105] Iteration 48900, lr = 1e-05
I0630 20:43:27.094964 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:43:27.246207  4668 solver.cpp:330] Iteration 49000, Testing net (#0)
I0630 20:43:27.246207  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:43:28.068521  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:43:28.093969  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8759
I0630 20:43:28.093969  4668 solver.cpp:397]     Test net output #1: loss = 0.416006 (* 1 = 0.416006 loss)
I0630 20:43:28.128307  4668 solver.cpp:218] Iteration 49000 (22.3102 iter/s, 4.48226s/100 iters), loss = 0.202091
I0630 20:43:28.128307  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:43:28.128307  4668 solver.cpp:237]     Train net output #1: loss = 0.202091 (* 1 = 0.202091 loss)
I0630 20:43:28.128307  4668 sgd_solver.cpp:105] Iteration 49000, lr = 1e-05
I0630 20:43:31.752571  4668 solver.cpp:218] Iteration 49100 (27.6114 iter/s, 3.6217s/100 iters), loss = 0.203423
I0630 20:43:31.752571  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:43:31.752571  4668 solver.cpp:237]     Train net output #1: loss = 0.203423 (* 1 = 0.203423 loss)
I0630 20:43:31.752571  4668 sgd_solver.cpp:105] Iteration 49100, lr = 1e-05
I0630 20:43:35.371121  4668 solver.cpp:218] Iteration 49200 (27.606 iter/s, 3.6224s/100 iters), loss = 0.171791
I0630 20:43:35.371121  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:43:35.371121  4668 solver.cpp:237]     Train net output #1: loss = 0.171791 (* 1 = 0.171791 loss)
I0630 20:43:35.371121  4668 sgd_solver.cpp:105] Iteration 49200, lr = 1e-05
I0630 20:43:39.003595  4668 solver.cpp:218] Iteration 49300 (27.5565 iter/s, 3.62891s/100 iters), loss = 0.15418
I0630 20:43:39.003595  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:43:39.003595  4668 solver.cpp:237]     Train net output #1: loss = 0.15418 (* 1 = 0.15418 loss)
I0630 20:43:39.003595  4668 sgd_solver.cpp:105] Iteration 49300, lr = 1e-05
I0630 20:43:42.635898  4668 solver.cpp:218] Iteration 49400 (27.5775 iter/s, 3.62615s/100 iters), loss = 0.0769615
I0630 20:43:42.635898  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0630 20:43:42.635898  4668 solver.cpp:237]     Train net output #1: loss = 0.0769618 (* 1 = 0.0769618 loss)
I0630 20:43:42.635898  4668 sgd_solver.cpp:105] Iteration 49400, lr = 1e-05
I0630 20:43:46.082347 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:43:46.218927  4668 solver.cpp:330] Iteration 49500, Testing net (#0)
I0630 20:43:46.218927  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:43:47.049690  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:43:47.080983  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:43:47.080983  4668 solver.cpp:397]     Test net output #1: loss = 0.416227 (* 1 = 0.416227 loss)
I0630 20:43:47.109814  4668 solver.cpp:218] Iteration 49500 (22.3258 iter/s, 4.47911s/100 iters), loss = 0.0913641
I0630 20:43:47.109814  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:43:47.109814  4668 solver.cpp:237]     Train net output #1: loss = 0.0913644 (* 1 = 0.0913644 loss)
I0630 20:43:47.109814  4668 sgd_solver.cpp:105] Iteration 49500, lr = 1e-05
I0630 20:43:50.731704  4668 solver.cpp:218] Iteration 49600 (27.603 iter/s, 3.62279s/100 iters), loss = 0.0913424
I0630 20:43:50.731704  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:43:50.731704  4668 solver.cpp:237]     Train net output #1: loss = 0.0913426 (* 1 = 0.0913426 loss)
I0630 20:43:50.731704  4668 sgd_solver.cpp:105] Iteration 49600, lr = 1e-05
I0630 20:43:54.364401  4668 solver.cpp:218] Iteration 49700 (27.5588 iter/s, 3.6286s/100 iters), loss = 0.285406
I0630 20:43:54.364401  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:43:54.364401  4668 solver.cpp:237]     Train net output #1: loss = 0.285406 (* 1 = 0.285406 loss)
I0630 20:43:54.364401  4668 sgd_solver.cpp:105] Iteration 49700, lr = 1e-05
I0630 20:43:57.977624  4668 solver.cpp:218] Iteration 49800 (27.6364 iter/s, 3.61842s/100 iters), loss = 0.129336
I0630 20:43:57.977624  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:43:57.977624  4668 solver.cpp:237]     Train net output #1: loss = 0.129337 (* 1 = 0.129337 loss)
I0630 20:43:57.977624  4668 sgd_solver.cpp:105] Iteration 49800, lr = 1e-05
I0630 20:44:01.609565  4668 solver.cpp:218] Iteration 49900 (27.6049 iter/s, 3.62254s/100 iters), loss = 0.159153
I0630 20:44:01.609565  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:44:01.609565  4668 solver.cpp:237]     Train net output #1: loss = 0.159153 (* 1 = 0.159153 loss)
I0630 20:44:01.609565  4668 sgd_solver.cpp:105] Iteration 49900, lr = 1e-05
I0630 20:44:05.053987 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:44:05.194128  4668 solver.cpp:330] Iteration 50000, Testing net (#0)
I0630 20:44:05.194128  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:44:06.015260  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:44:06.054546  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8762
I0630 20:44:06.054546  4668 solver.cpp:397]     Test net output #1: loss = 0.416412 (* 1 = 0.416412 loss)
I0630 20:44:06.088554  4668 solver.cpp:218] Iteration 50000 (22.3262 iter/s, 4.47904s/100 iters), loss = 0.188175
I0630 20:44:06.088554  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:44:06.088554  4668 solver.cpp:237]     Train net output #1: loss = 0.188176 (* 1 = 0.188176 loss)
I0630 20:44:06.088554  4668 sgd_solver.cpp:105] Iteration 50000, lr = 1e-05
I0630 20:44:09.708245  4668 solver.cpp:218] Iteration 50100 (27.5762 iter/s, 3.62632s/100 iters), loss = 0.203885
I0630 20:44:09.708245  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:44:09.708245  4668 solver.cpp:237]     Train net output #1: loss = 0.203885 (* 1 = 0.203885 loss)
I0630 20:44:09.708245  4668 sgd_solver.cpp:105] Iteration 50100, lr = 1e-05
I0630 20:44:13.332120  4668 solver.cpp:218] Iteration 50200 (27.5931 iter/s, 3.6241s/100 iters), loss = 0.202282
I0630 20:44:13.332120  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:44:13.332120  4668 solver.cpp:237]     Train net output #1: loss = 0.202282 (* 1 = 0.202282 loss)
I0630 20:44:13.332120  4668 sgd_solver.cpp:105] Iteration 50200, lr = 1e-05
I0630 20:44:16.962908  4668 solver.cpp:218] Iteration 50300 (27.6028 iter/s, 3.62282s/100 iters), loss = 0.173175
I0630 20:44:16.962908  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:44:16.962908  4668 solver.cpp:237]     Train net output #1: loss = 0.173175 (* 1 = 0.173175 loss)
I0630 20:44:16.962908  4668 sgd_solver.cpp:105] Iteration 50300, lr = 1e-05
I0630 20:44:20.585538  4668 solver.cpp:218] Iteration 50400 (27.61 iter/s, 3.62188s/100 iters), loss = 0.13639
I0630 20:44:20.585538  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:44:20.585538  4668 solver.cpp:237]     Train net output #1: loss = 0.13639 (* 1 = 0.13639 loss)
I0630 20:44:20.585538  4668 sgd_solver.cpp:105] Iteration 50400, lr = 1e-05
I0630 20:44:24.027707 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:44:24.178148  4668 solver.cpp:330] Iteration 50500, Testing net (#0)
I0630 20:44:24.178148  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:44:24.999115  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:44:25.029134  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8762
I0630 20:44:25.029134  4668 solver.cpp:397]     Test net output #1: loss = 0.416307 (* 1 = 0.416307 loss)
I0630 20:44:25.069146  4668 solver.cpp:218] Iteration 50500 (22.3056 iter/s, 4.48317s/100 iters), loss = 0.134239
I0630 20:44:25.069146  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:44:25.069146  4668 solver.cpp:237]     Train net output #1: loss = 0.13424 (* 1 = 0.13424 loss)
I0630 20:44:25.069146  4668 sgd_solver.cpp:105] Iteration 50500, lr = 1e-05
I0630 20:44:28.690297  4668 solver.cpp:218] Iteration 50600 (27.5869 iter/s, 3.62491s/100 iters), loss = 0.17217
I0630 20:44:28.690297  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:44:28.690297  4668 solver.cpp:237]     Train net output #1: loss = 0.17217 (* 1 = 0.17217 loss)
I0630 20:44:28.690297  4668 sgd_solver.cpp:105] Iteration 50600, lr = 1e-05
I0630 20:44:32.314026  4668 solver.cpp:218] Iteration 50700 (27.586 iter/s, 3.62502s/100 iters), loss = 0.158739
I0630 20:44:32.314026  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:44:32.314026  4668 solver.cpp:237]     Train net output #1: loss = 0.158739 (* 1 = 0.158739 loss)
I0630 20:44:32.314026  4668 sgd_solver.cpp:105] Iteration 50700, lr = 1e-05
I0630 20:44:35.938828  4668 solver.cpp:218] Iteration 50800 (27.606 iter/s, 3.6224s/100 iters), loss = 0.126938
I0630 20:44:35.938828  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:44:35.938828  4668 solver.cpp:237]     Train net output #1: loss = 0.126938 (* 1 = 0.126938 loss)
I0630 20:44:35.938828  4668 sgd_solver.cpp:105] Iteration 50800, lr = 1e-05
I0630 20:44:39.562803  4668 solver.cpp:218] Iteration 50900 (27.6221 iter/s, 3.62029s/100 iters), loss = 0.180216
I0630 20:44:39.563309  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:44:39.563309  4668 solver.cpp:237]     Train net output #1: loss = 0.180216 (* 1 = 0.180216 loss)
I0630 20:44:39.563309  4668 sgd_solver.cpp:105] Iteration 50900, lr = 1e-05
I0630 20:44:43.001086 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:44:43.141752  4668 solver.cpp:330] Iteration 51000, Testing net (#0)
I0630 20:44:43.141752  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:44:43.971568  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:44:44.001539  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8762
I0630 20:44:44.001539  4668 solver.cpp:397]     Test net output #1: loss = 0.416392 (* 1 = 0.416392 loss)
I0630 20:44:44.032078  4668 solver.cpp:218] Iteration 51000 (22.34 iter/s, 4.47628s/100 iters), loss = 0.180503
I0630 20:44:44.032078  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:44:44.032078  4668 solver.cpp:237]     Train net output #1: loss = 0.180503 (* 1 = 0.180503 loss)
I0630 20:44:44.032078  4668 sgd_solver.cpp:105] Iteration 51000, lr = 1e-05
I0630 20:44:47.654090  4668 solver.cpp:218] Iteration 51100 (27.6058 iter/s, 3.62243s/100 iters), loss = 0.123152
I0630 20:44:47.654090  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:44:47.654090  4668 solver.cpp:237]     Train net output #1: loss = 0.123153 (* 1 = 0.123153 loss)
I0630 20:44:47.654090  4668 sgd_solver.cpp:105] Iteration 51100, lr = 1e-05
I0630 20:44:51.277086  4668 solver.cpp:218] Iteration 51200 (27.5945 iter/s, 3.6239s/100 iters), loss = 0.163826
I0630 20:44:51.277086  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:44:51.277086  4668 solver.cpp:237]     Train net output #1: loss = 0.163826 (* 1 = 0.163826 loss)
I0630 20:44:51.277086  4668 sgd_solver.cpp:105] Iteration 51200, lr = 1e-05
I0630 20:44:54.911675  4668 solver.cpp:218] Iteration 51300 (27.5877 iter/s, 3.6248s/100 iters), loss = 0.126119
I0630 20:44:54.911675  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:44:54.911675  4668 solver.cpp:237]     Train net output #1: loss = 0.12612 (* 1 = 0.12612 loss)
I0630 20:44:54.911675  4668 sgd_solver.cpp:105] Iteration 51300, lr = 1e-05
I0630 20:44:58.524626  4668 solver.cpp:218] Iteration 51400 (27.6146 iter/s, 3.62128s/100 iters), loss = 0.16057
I0630 20:44:58.524626  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:44:58.524626  4668 solver.cpp:237]     Train net output #1: loss = 0.16057 (* 1 = 0.16057 loss)
I0630 20:44:58.524626  4668 sgd_solver.cpp:105] Iteration 51400, lr = 1e-05
I0630 20:45:01.977622 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:45:02.117918  4668 solver.cpp:330] Iteration 51500, Testing net (#0)
I0630 20:45:02.117918  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:45:02.937746  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:45:02.973968  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8756
I0630 20:45:02.973968  4668 solver.cpp:397]     Test net output #1: loss = 0.416261 (* 1 = 0.416261 loss)
I0630 20:45:03.007481  4668 solver.cpp:218] Iteration 51500 (22.3247 iter/s, 4.47935s/100 iters), loss = 0.149662
I0630 20:45:03.007481  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:45:03.007481  4668 solver.cpp:237]     Train net output #1: loss = 0.149662 (* 1 = 0.149662 loss)
I0630 20:45:03.007481  4668 sgd_solver.cpp:105] Iteration 51500, lr = 1e-05
I0630 20:45:06.635272  4668 solver.cpp:218] Iteration 51600 (27.6005 iter/s, 3.62312s/100 iters), loss = 0.206632
I0630 20:45:06.635272  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:45:06.635272  4668 solver.cpp:237]     Train net output #1: loss = 0.206632 (* 1 = 0.206632 loss)
I0630 20:45:06.635272  4668 sgd_solver.cpp:105] Iteration 51600, lr = 1e-05
I0630 20:45:10.261585  4668 solver.cpp:218] Iteration 51700 (27.5839 iter/s, 3.6253s/100 iters), loss = 0.172587
I0630 20:45:10.261585  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:45:10.261585  4668 solver.cpp:237]     Train net output #1: loss = 0.172587 (* 1 = 0.172587 loss)
I0630 20:45:10.261585  4668 sgd_solver.cpp:105] Iteration 51700, lr = 1e-05
I0630 20:45:13.877704  4668 solver.cpp:218] Iteration 51800 (27.5992 iter/s, 3.62329s/100 iters), loss = 0.128688
I0630 20:45:13.877704  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:45:13.877704  4668 solver.cpp:237]     Train net output #1: loss = 0.128688 (* 1 = 0.128688 loss)
I0630 20:45:13.877704  4668 sgd_solver.cpp:105] Iteration 51800, lr = 1e-05
I0630 20:45:17.513344  4668 solver.cpp:218] Iteration 51900 (27.5691 iter/s, 3.62725s/100 iters), loss = 0.120177
I0630 20:45:17.513344  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:45:17.513344  4668 solver.cpp:237]     Train net output #1: loss = 0.120177 (* 1 = 0.120177 loss)
I0630 20:45:17.513344  4668 sgd_solver.cpp:105] Iteration 51900, lr = 1e-05
I0630 20:45:20.962098 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:45:21.106382  4668 solver.cpp:330] Iteration 52000, Testing net (#0)
I0630 20:45:21.106382  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:45:21.923202  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:45:21.953203  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:45:21.953203  4668 solver.cpp:397]     Test net output #1: loss = 0.416402 (* 1 = 0.416402 loss)
I0630 20:45:21.993206  4668 solver.cpp:218] Iteration 52000 (22.3095 iter/s, 4.4824s/100 iters), loss = 0.149179
I0630 20:45:21.993206  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:45:21.993206  4668 solver.cpp:237]     Train net output #1: loss = 0.149179 (* 1 = 0.149179 loss)
I0630 20:45:21.993206  4668 sgd_solver.cpp:105] Iteration 52000, lr = 1e-05
I0630 20:45:25.614807  4668 solver.cpp:218] Iteration 52100 (27.6032 iter/s, 3.62277s/100 iters), loss = 0.19127
I0630 20:45:25.614807  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:45:25.614807  4668 solver.cpp:237]     Train net output #1: loss = 0.191271 (* 1 = 0.191271 loss)
I0630 20:45:25.614807  4668 sgd_solver.cpp:105] Iteration 52100, lr = 1e-05
I0630 20:45:29.237300  4668 solver.cpp:218] Iteration 52200 (27.6122 iter/s, 3.62158s/100 iters), loss = 0.221219
I0630 20:45:29.237300  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:45:29.237300  4668 solver.cpp:237]     Train net output #1: loss = 0.221219 (* 1 = 0.221219 loss)
I0630 20:45:29.237300  4668 sgd_solver.cpp:105] Iteration 52200, lr = 1e-05
I0630 20:45:32.863561  4668 solver.cpp:218] Iteration 52300 (27.6071 iter/s, 3.62226s/100 iters), loss = 0.126279
I0630 20:45:32.863561  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:45:32.863561  4668 solver.cpp:237]     Train net output #1: loss = 0.126279 (* 1 = 0.126279 loss)
I0630 20:45:32.863561  4668 sgd_solver.cpp:105] Iteration 52300, lr = 1e-05
I0630 20:45:36.481387  4668 solver.cpp:218] Iteration 52400 (27.6032 iter/s, 3.62277s/100 iters), loss = 0.107356
I0630 20:45:36.481387  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:45:36.481387  4668 solver.cpp:237]     Train net output #1: loss = 0.107357 (* 1 = 0.107357 loss)
I0630 20:45:36.481387  4668 sgd_solver.cpp:105] Iteration 52400, lr = 1e-05
I0630 20:45:39.931222 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:45:40.073194  4668 solver.cpp:330] Iteration 52500, Testing net (#0)
I0630 20:45:40.073194  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:45:40.898911  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:45:40.930454  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:45:40.930454  4668 solver.cpp:397]     Test net output #1: loss = 0.416479 (* 1 = 0.416479 loss)
I0630 20:45:40.965096  4668 solver.cpp:218] Iteration 52500 (22.3342 iter/s, 4.47744s/100 iters), loss = 0.164114
I0630 20:45:40.965096  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:45:40.965096  4668 solver.cpp:237]     Train net output #1: loss = 0.164114 (* 1 = 0.164114 loss)
I0630 20:45:40.965096  4668 sgd_solver.cpp:105] Iteration 52500, lr = 1e-05
I0630 20:45:44.584120  4668 solver.cpp:218] Iteration 52600 (27.6342 iter/s, 3.6187s/100 iters), loss = 0.204925
I0630 20:45:44.584120  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:45:44.584120  4668 solver.cpp:237]     Train net output #1: loss = 0.204926 (* 1 = 0.204926 loss)
I0630 20:45:44.584120  4668 sgd_solver.cpp:105] Iteration 52600, lr = 1e-05
I0630 20:45:48.197335  4668 solver.cpp:218] Iteration 52700 (27.6418 iter/s, 3.61771s/100 iters), loss = 0.142507
I0630 20:45:48.197335  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:45:48.197335  4668 solver.cpp:237]     Train net output #1: loss = 0.142508 (* 1 = 0.142508 loss)
I0630 20:45:48.197335  4668 sgd_solver.cpp:105] Iteration 52700, lr = 1e-05
I0630 20:45:51.818390  4668 solver.cpp:218] Iteration 52800 (27.6096 iter/s, 3.62193s/100 iters), loss = 0.159922
I0630 20:45:51.818390  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:45:51.818390  4668 solver.cpp:237]     Train net output #1: loss = 0.159922 (* 1 = 0.159922 loss)
I0630 20:45:51.818390  4668 sgd_solver.cpp:105] Iteration 52800, lr = 1e-05
I0630 20:45:55.447711  4668 solver.cpp:218] Iteration 52900 (27.6018 iter/s, 3.62295s/100 iters), loss = 0.171094
I0630 20:45:55.447711  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:45:55.447711  4668 solver.cpp:237]     Train net output #1: loss = 0.171094 (* 1 = 0.171094 loss)
I0630 20:45:55.447711  4668 sgd_solver.cpp:105] Iteration 52900, lr = 1e-05
I0630 20:45:58.882009 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:45:59.022187  4668 solver.cpp:330] Iteration 53000, Testing net (#0)
I0630 20:45:59.022187  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:45:59.853083  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:45:59.879384  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:45:59.879384  4668 solver.cpp:397]     Test net output #1: loss = 0.416266 (* 1 = 0.416266 loss)
I0630 20:45:59.921584  4668 solver.cpp:218] Iteration 53000 (22.3472 iter/s, 4.47484s/100 iters), loss = 0.1249
I0630 20:45:59.921584  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:45:59.921584  4668 solver.cpp:237]     Train net output #1: loss = 0.1249 (* 1 = 0.1249 loss)
I0630 20:45:59.921584  4668 sgd_solver.cpp:105] Iteration 53000, lr = 1e-05
I0630 20:46:03.547405  4668 solver.cpp:218] Iteration 53100 (27.5925 iter/s, 3.62417s/100 iters), loss = 0.12864
I0630 20:46:03.547405  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:46:03.547405  4668 solver.cpp:237]     Train net output #1: loss = 0.12864 (* 1 = 0.12864 loss)
I0630 20:46:03.547405  4668 sgd_solver.cpp:105] Iteration 53100, lr = 1e-05
I0630 20:46:07.174352  4668 solver.cpp:218] Iteration 53200 (27.5743 iter/s, 3.62656s/100 iters), loss = 0.1504
I0630 20:46:07.174352  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:46:07.174352  4668 solver.cpp:237]     Train net output #1: loss = 0.150401 (* 1 = 0.150401 loss)
I0630 20:46:07.174352  4668 sgd_solver.cpp:105] Iteration 53200, lr = 1e-05
I0630 20:46:10.791298  4668 solver.cpp:218] Iteration 53300 (27.6015 iter/s, 3.62299s/100 iters), loss = 0.0945123
I0630 20:46:10.791298  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:46:10.791298  4668 solver.cpp:237]     Train net output #1: loss = 0.0945126 (* 1 = 0.0945126 loss)
I0630 20:46:10.791298  4668 sgd_solver.cpp:105] Iteration 53300, lr = 1e-05
I0630 20:46:14.413259  4668 solver.cpp:218] Iteration 53400 (27.5973 iter/s, 3.62355s/100 iters), loss = 0.128258
I0630 20:46:14.413259  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:46:14.413259  4668 solver.cpp:237]     Train net output #1: loss = 0.128259 (* 1 = 0.128259 loss)
I0630 20:46:14.413259  4668 sgd_solver.cpp:105] Iteration 53400, lr = 1e-05
I0630 20:46:17.865617 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:46:18.005043  4668 solver.cpp:330] Iteration 53500, Testing net (#0)
I0630 20:46:18.005043  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:46:18.825438  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:46:18.865424  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:46:18.865424  4668 solver.cpp:397]     Test net output #1: loss = 0.416185 (* 1 = 0.416185 loss)
I0630 20:46:18.895038  4668 solver.cpp:218] Iteration 53500 (22.3267 iter/s, 4.47893s/100 iters), loss = 0.168031
I0630 20:46:18.895038  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:46:18.895038  4668 solver.cpp:237]     Train net output #1: loss = 0.168032 (* 1 = 0.168032 loss)
I0630 20:46:18.895038  4668 sgd_solver.cpp:105] Iteration 53500, lr = 1e-05
I0630 20:46:22.518280  4668 solver.cpp:218] Iteration 53600 (27.5834 iter/s, 3.62537s/100 iters), loss = 0.149969
I0630 20:46:22.518280  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:46:22.518280  4668 solver.cpp:237]     Train net output #1: loss = 0.14997 (* 1 = 0.14997 loss)
I0630 20:46:22.518280  4668 sgd_solver.cpp:105] Iteration 53600, lr = 1e-05
I0630 20:46:26.149315  4668 solver.cpp:218] Iteration 53700 (27.5883 iter/s, 3.62473s/100 iters), loss = 0.164855
I0630 20:46:26.149315  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:46:26.149315  4668 solver.cpp:237]     Train net output #1: loss = 0.164855 (* 1 = 0.164855 loss)
I0630 20:46:26.149315  4668 sgd_solver.cpp:105] Iteration 53700, lr = 1e-05
I0630 20:46:29.765079  4668 solver.cpp:218] Iteration 53800 (27.6292 iter/s, 3.61936s/100 iters), loss = 0.137663
I0630 20:46:29.765079  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:46:29.765079  4668 solver.cpp:237]     Train net output #1: loss = 0.137663 (* 1 = 0.137663 loss)
I0630 20:46:29.765079  4668 sgd_solver.cpp:105] Iteration 53800, lr = 1e-05
I0630 20:46:33.396356  4668 solver.cpp:218] Iteration 53900 (27.588 iter/s, 3.62477s/100 iters), loss = 0.12165
I0630 20:46:33.396356  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:46:33.396356  4668 solver.cpp:237]     Train net output #1: loss = 0.12165 (* 1 = 0.12165 loss)
I0630 20:46:33.396356  4668 sgd_solver.cpp:105] Iteration 53900, lr = 1e-05
I0630 20:46:36.828668 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:46:36.978247  4668 solver.cpp:330] Iteration 54000, Testing net (#0)
I0630 20:46:36.978247  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:46:37.799373  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:46:37.829514  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:46:37.829514  4668 solver.cpp:397]     Test net output #1: loss = 0.415997 (* 1 = 0.415997 loss)
I0630 20:46:37.869532  4668 solver.cpp:218] Iteration 54000 (22.3571 iter/s, 4.47285s/100 iters), loss = 0.116089
I0630 20:46:37.869532  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:46:37.869532  4668 solver.cpp:237]     Train net output #1: loss = 0.116089 (* 1 = 0.116089 loss)
I0630 20:46:37.869532  4668 sgd_solver.cpp:105] Iteration 54000, lr = 1e-05
I0630 20:46:41.483822  4668 solver.cpp:218] Iteration 54100 (27.6218 iter/s, 3.62032s/100 iters), loss = 0.191029
I0630 20:46:41.483822  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:46:41.483822  4668 solver.cpp:237]     Train net output #1: loss = 0.19103 (* 1 = 0.19103 loss)
I0630 20:46:41.483822  4668 sgd_solver.cpp:105] Iteration 54100, lr = 1e-05
I0630 20:46:45.104882  4668 solver.cpp:218] Iteration 54200 (27.6248 iter/s, 3.61993s/100 iters), loss = 0.128163
I0630 20:46:45.104882  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:46:45.104882  4668 solver.cpp:237]     Train net output #1: loss = 0.128163 (* 1 = 0.128163 loss)
I0630 20:46:45.104882  4668 sgd_solver.cpp:105] Iteration 54200, lr = 1e-05
I0630 20:46:48.728083  4668 solver.cpp:218] Iteration 54300 (27.6136 iter/s, 3.6214s/100 iters), loss = 0.219668
I0630 20:46:48.728083  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:46:48.728083  4668 solver.cpp:237]     Train net output #1: loss = 0.219668 (* 1 = 0.219668 loss)
I0630 20:46:48.728083  4668 sgd_solver.cpp:105] Iteration 54300, lr = 1e-05
I0630 20:46:52.351266  4668 solver.cpp:218] Iteration 54400 (27.5968 iter/s, 3.62361s/100 iters), loss = 0.106469
I0630 20:46:52.351266  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:46:52.351266  4668 solver.cpp:237]     Train net output #1: loss = 0.106469 (* 1 = 0.106469 loss)
I0630 20:46:52.351266  4668 sgd_solver.cpp:105] Iteration 54400, lr = 1e-05
I0630 20:46:55.792438 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:46:55.933928  4668 solver.cpp:330] Iteration 54500, Testing net (#0)
I0630 20:46:55.933928  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:46:56.765004  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:46:56.795001  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8767
I0630 20:46:56.795001  4668 solver.cpp:397]     Test net output #1: loss = 0.415761 (* 1 = 0.415761 loss)
I0630 20:46:56.824643  4668 solver.cpp:218] Iteration 54500 (22.3404 iter/s, 4.4762s/100 iters), loss = 0.155997
I0630 20:46:56.824643  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:46:56.824643  4668 solver.cpp:237]     Train net output #1: loss = 0.155997 (* 1 = 0.155997 loss)
I0630 20:46:56.824643  4668 sgd_solver.cpp:105] Iteration 54500, lr = 1e-05
I0630 20:47:00.447095  4668 solver.cpp:218] Iteration 54600 (27.6127 iter/s, 3.62152s/100 iters), loss = 0.191893
I0630 20:47:00.447095  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:47:00.447095  4668 solver.cpp:237]     Train net output #1: loss = 0.191894 (* 1 = 0.191894 loss)
I0630 20:47:00.447095  4668 sgd_solver.cpp:105] Iteration 54600, lr = 1e-05
I0630 20:47:04.070657  4668 solver.cpp:218] Iteration 54700 (27.6105 iter/s, 3.62182s/100 iters), loss = 0.177246
I0630 20:47:04.070657  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:47:04.070657  4668 solver.cpp:237]     Train net output #1: loss = 0.177246 (* 1 = 0.177246 loss)
I0630 20:47:04.070657  4668 sgd_solver.cpp:105] Iteration 54700, lr = 1e-05
I0630 20:47:07.694245  4668 solver.cpp:218] Iteration 54800 (27.5894 iter/s, 3.62458s/100 iters), loss = 0.119251
I0630 20:47:07.694245  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:47:07.694245  4668 solver.cpp:237]     Train net output #1: loss = 0.119251 (* 1 = 0.119251 loss)
I0630 20:47:07.694245  4668 sgd_solver.cpp:105] Iteration 54800, lr = 1e-05
I0630 20:47:11.326771  4668 solver.cpp:218] Iteration 54900 (27.5597 iter/s, 3.62849s/100 iters), loss = 0.128316
I0630 20:47:11.326771  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:47:11.326771  4668 solver.cpp:237]     Train net output #1: loss = 0.128316 (* 1 = 0.128316 loss)
I0630 20:47:11.326771  4668 sgd_solver.cpp:105] Iteration 54900, lr = 1e-05
I0630 20:47:14.779024 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:47:14.920626  4668 solver.cpp:330] Iteration 55000, Testing net (#0)
I0630 20:47:14.920626  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:47:15.739385  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:47:15.777658  4668 solver.cpp:397]     Test net output #0: accuracy = 0.877
I0630 20:47:15.777658  4668 solver.cpp:397]     Test net output #1: loss = 0.416185 (* 1 = 0.416185 loss)
I0630 20:47:15.807972  4668 solver.cpp:218] Iteration 55000 (22.3124 iter/s, 4.48181s/100 iters), loss = 0.154309
I0630 20:47:15.807972  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:47:15.807972  4668 solver.cpp:237]     Train net output #1: loss = 0.154309 (* 1 = 0.154309 loss)
I0630 20:47:15.807972  4668 sgd_solver.cpp:105] Iteration 55000, lr = 1e-05
I0630 20:47:19.440237  4668 solver.cpp:218] Iteration 55100 (27.5664 iter/s, 3.6276s/100 iters), loss = 0.178391
I0630 20:47:19.440237  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:47:19.440237  4668 solver.cpp:237]     Train net output #1: loss = 0.178391 (* 1 = 0.178391 loss)
I0630 20:47:19.440237  4668 sgd_solver.cpp:105] Iteration 55100, lr = 1e-05
I0630 20:47:23.065696  4668 solver.cpp:218] Iteration 55200 (27.5814 iter/s, 3.62563s/100 iters), loss = 0.169202
I0630 20:47:23.065696  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:47:23.066696  4668 solver.cpp:237]     Train net output #1: loss = 0.169202 (* 1 = 0.169202 loss)
I0630 20:47:23.066696  4668 sgd_solver.cpp:105] Iteration 55200, lr = 1e-05
I0630 20:47:26.686110  4668 solver.cpp:218] Iteration 55300 (27.5894 iter/s, 3.62458s/100 iters), loss = 0.070157
I0630 20:47:26.686110  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0630 20:47:26.686110  4668 solver.cpp:237]     Train net output #1: loss = 0.0701573 (* 1 = 0.0701573 loss)
I0630 20:47:26.686110  4668 sgd_solver.cpp:105] Iteration 55300, lr = 1e-05
I0630 20:47:30.313084  4668 solver.cpp:218] Iteration 55400 (27.5783 iter/s, 3.62605s/100 iters), loss = 0.144047
I0630 20:47:30.313084  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:47:30.313084  4668 solver.cpp:237]     Train net output #1: loss = 0.144048 (* 1 = 0.144048 loss)
I0630 20:47:30.313084  4668 sgd_solver.cpp:105] Iteration 55400, lr = 1e-05
I0630 20:47:33.767812 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:47:33.909829  4668 solver.cpp:330] Iteration 55500, Testing net (#0)
I0630 20:47:33.909829  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:47:34.730734  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:47:34.765770  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8767
I0630 20:47:34.765770  4668 solver.cpp:397]     Test net output #1: loss = 0.416068 (* 1 = 0.416068 loss)
I0630 20:47:34.791273  4668 solver.cpp:218] Iteration 55500 (22.3114 iter/s, 4.48202s/100 iters), loss = 0.0760569
I0630 20:47:34.791273  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0630 20:47:34.791273  4668 solver.cpp:237]     Train net output #1: loss = 0.0760572 (* 1 = 0.0760572 loss)
I0630 20:47:34.791273  4668 sgd_solver.cpp:105] Iteration 55500, lr = 1e-05
I0630 20:47:38.413592  4668 solver.cpp:218] Iteration 55600 (27.6656 iter/s, 3.61459s/100 iters), loss = 0.198759
I0630 20:47:38.413592  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:47:38.413592  4668 solver.cpp:237]     Train net output #1: loss = 0.198759 (* 1 = 0.198759 loss)
I0630 20:47:38.413592  4668 sgd_solver.cpp:105] Iteration 55600, lr = 1e-05
I0630 20:47:42.025732  4668 solver.cpp:218] Iteration 55700 (27.649 iter/s, 3.61677s/100 iters), loss = 0.193771
I0630 20:47:42.025732  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:47:42.025732  4668 solver.cpp:237]     Train net output #1: loss = 0.193771 (* 1 = 0.193771 loss)
I0630 20:47:42.025732  4668 sgd_solver.cpp:105] Iteration 55700, lr = 1e-05
I0630 20:47:45.646596  4668 solver.cpp:218] Iteration 55800 (27.6354 iter/s, 3.61854s/100 iters), loss = 0.10983
I0630 20:47:45.646596  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:47:45.646596  4668 solver.cpp:237]     Train net output #1: loss = 0.10983 (* 1 = 0.10983 loss)
I0630 20:47:45.646596  4668 sgd_solver.cpp:105] Iteration 55800, lr = 1e-05
I0630 20:47:49.268853  4668 solver.cpp:218] Iteration 55900 (27.6205 iter/s, 3.6205s/100 iters), loss = 0.152762
I0630 20:47:49.268853  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:47:49.268853  4668 solver.cpp:237]     Train net output #1: loss = 0.152762 (* 1 = 0.152762 loss)
I0630 20:47:49.268853  4668 sgd_solver.cpp:105] Iteration 55900, lr = 1e-05
I0630 20:47:52.711529 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:47:52.852064  4668 solver.cpp:330] Iteration 56000, Testing net (#0)
I0630 20:47:52.852064  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:47:53.683110  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:47:53.713111  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8762
I0630 20:47:53.713111  4668 solver.cpp:397]     Test net output #1: loss = 0.416513 (* 1 = 0.416513 loss)
I0630 20:47:53.742656  4668 solver.cpp:218] Iteration 56000 (22.3317 iter/s, 4.47795s/100 iters), loss = 0.152016
I0630 20:47:53.742656  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:47:53.742656  4668 solver.cpp:237]     Train net output #1: loss = 0.152016 (* 1 = 0.152016 loss)
I0630 20:47:53.742656  4668 sgd_solver.cpp:105] Iteration 56000, lr = 1e-05
I0630 20:47:57.374626  4668 solver.cpp:218] Iteration 56100 (27.589 iter/s, 3.62464s/100 iters), loss = 0.205557
I0630 20:47:57.374626  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:47:57.374626  4668 solver.cpp:237]     Train net output #1: loss = 0.205557 (* 1 = 0.205557 loss)
I0630 20:47:57.374626  4668 sgd_solver.cpp:105] Iteration 56100, lr = 1e-05
I0630 20:48:00.996734  4668 solver.cpp:218] Iteration 56200 (27.6076 iter/s, 3.62219s/100 iters), loss = 0.155736
I0630 20:48:00.996734  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:48:00.996734  4668 solver.cpp:237]     Train net output #1: loss = 0.155737 (* 1 = 0.155737 loss)
I0630 20:48:00.996734  4668 sgd_solver.cpp:105] Iteration 56200, lr = 1e-05
I0630 20:48:04.616547  4668 solver.cpp:218] Iteration 56300 (27.585 iter/s, 3.62515s/100 iters), loss = 0.100441
I0630 20:48:04.616547  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:48:04.616547  4668 solver.cpp:237]     Train net output #1: loss = 0.100441 (* 1 = 0.100441 loss)
I0630 20:48:04.616547  4668 sgd_solver.cpp:105] Iteration 56300, lr = 1e-05
I0630 20:48:08.242677  4668 solver.cpp:218] Iteration 56400 (27.6161 iter/s, 3.62107s/100 iters), loss = 0.169082
I0630 20:48:08.242677  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:48:08.242677  4668 solver.cpp:237]     Train net output #1: loss = 0.169083 (* 1 = 0.169083 loss)
I0630 20:48:08.242677  4668 sgd_solver.cpp:105] Iteration 56400, lr = 1e-05
I0630 20:48:11.692620 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:48:11.834478  4668 solver.cpp:330] Iteration 56500, Testing net (#0)
I0630 20:48:11.834478  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:48:12.654863  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:48:12.684897  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:48:12.684897  4668 solver.cpp:397]     Test net output #1: loss = 0.415901 (* 1 = 0.415901 loss)
I0630 20:48:12.724916  4668 solver.cpp:218] Iteration 56500 (22.3195 iter/s, 4.48039s/100 iters), loss = 0.115241
I0630 20:48:12.724916  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:48:12.724916  4668 solver.cpp:237]     Train net output #1: loss = 0.115241 (* 1 = 0.115241 loss)
I0630 20:48:12.724916  4668 sgd_solver.cpp:105] Iteration 56500, lr = 1e-05
I0630 20:48:16.341856  4668 solver.cpp:218] Iteration 56600 (27.6181 iter/s, 3.62081s/100 iters), loss = 0.135747
I0630 20:48:16.341856  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:48:16.341856  4668 solver.cpp:237]     Train net output #1: loss = 0.135747 (* 1 = 0.135747 loss)
I0630 20:48:16.341856  4668 sgd_solver.cpp:105] Iteration 56600, lr = 1e-05
I0630 20:48:19.959730  4668 solver.cpp:218] Iteration 56700 (27.6135 iter/s, 3.62142s/100 iters), loss = 0.194473
I0630 20:48:19.959730  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:48:19.959730  4668 solver.cpp:237]     Train net output #1: loss = 0.194474 (* 1 = 0.194474 loss)
I0630 20:48:19.959730  4668 sgd_solver.cpp:105] Iteration 56700, lr = 1e-05
I0630 20:48:23.593602  4668 solver.cpp:218] Iteration 56800 (27.5854 iter/s, 3.62511s/100 iters), loss = 0.107688
I0630 20:48:23.593602  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:48:23.593602  4668 solver.cpp:237]     Train net output #1: loss = 0.107688 (* 1 = 0.107688 loss)
I0630 20:48:23.593602  4668 sgd_solver.cpp:105] Iteration 56800, lr = 1e-05
I0630 20:48:27.217886  4668 solver.cpp:218] Iteration 56900 (27.5935 iter/s, 3.62404s/100 iters), loss = 0.184481
I0630 20:48:27.217886  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:48:27.217886  4668 solver.cpp:237]     Train net output #1: loss = 0.184481 (* 1 = 0.184481 loss)
I0630 20:48:27.217886  4668 sgd_solver.cpp:105] Iteration 56900, lr = 1e-05
I0630 20:48:30.659642 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:48:30.797312  4668 solver.cpp:330] Iteration 57000, Testing net (#0)
I0630 20:48:30.797312  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:48:31.628039  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:48:31.658344  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 20:48:31.658344  4668 solver.cpp:397]     Test net output #1: loss = 0.416139 (* 1 = 0.416139 loss)
I0630 20:48:31.688344  4668 solver.cpp:218] Iteration 57000 (22.3386 iter/s, 4.47655s/100 iters), loss = 0.116499
I0630 20:48:31.688344  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:48:31.688344  4668 solver.cpp:237]     Train net output #1: loss = 0.116499 (* 1 = 0.116499 loss)
I0630 20:48:31.688344  4668 sgd_solver.cpp:105] Iteration 57000, lr = 1e-05
I0630 20:48:35.307741  4668 solver.cpp:218] Iteration 57100 (27.6128 iter/s, 3.62151s/100 iters), loss = 0.202279
I0630 20:48:35.307741  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:48:35.307741  4668 solver.cpp:237]     Train net output #1: loss = 0.20228 (* 1 = 0.20228 loss)
I0630 20:48:35.307741  4668 sgd_solver.cpp:105] Iteration 57100, lr = 1e-05
I0630 20:48:38.934660  4668 solver.cpp:218] Iteration 57200 (27.5828 iter/s, 3.62544s/100 iters), loss = 0.198435
I0630 20:48:38.934660  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:48:38.934660  4668 solver.cpp:237]     Train net output #1: loss = 0.198435 (* 1 = 0.198435 loss)
I0630 20:48:38.934660  4668 sgd_solver.cpp:105] Iteration 57200, lr = 1e-05
I0630 20:48:42.560904  4668 solver.cpp:218] Iteration 57300 (27.6244 iter/s, 3.61999s/100 iters), loss = 0.140312
I0630 20:48:42.560904  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:48:42.560904  4668 solver.cpp:237]     Train net output #1: loss = 0.140312 (* 1 = 0.140312 loss)
I0630 20:48:42.560904  4668 sgd_solver.cpp:105] Iteration 57300, lr = 1e-05
I0630 20:48:46.180768  4668 solver.cpp:218] Iteration 57400 (27.5907 iter/s, 3.62441s/100 iters), loss = 0.145324
I0630 20:48:46.180768  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:48:46.180768  4668 solver.cpp:237]     Train net output #1: loss = 0.145324 (* 1 = 0.145324 loss)
I0630 20:48:46.180768  4668 sgd_solver.cpp:105] Iteration 57400, lr = 1e-05
I0630 20:48:49.633790 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:48:49.773838  4668 solver.cpp:330] Iteration 57500, Testing net (#0)
I0630 20:48:49.773838  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:48:50.599876  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:48:50.623993  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:48:50.623993  4668 solver.cpp:397]     Test net output #1: loss = 0.416415 (* 1 = 0.416415 loss)
I0630 20:48:50.663995  4668 solver.cpp:218] Iteration 57500 (22.3323 iter/s, 4.47781s/100 iters), loss = 0.135446
I0630 20:48:50.663995  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:48:50.663995  4668 solver.cpp:237]     Train net output #1: loss = 0.135446 (* 1 = 0.135446 loss)
I0630 20:48:50.663995  4668 sgd_solver.cpp:105] Iteration 57500, lr = 1e-05
I0630 20:48:54.290544  4668 solver.cpp:218] Iteration 57600 (27.5901 iter/s, 3.62449s/100 iters), loss = 0.193887
I0630 20:48:54.290544  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:48:54.290544  4668 solver.cpp:237]     Train net output #1: loss = 0.193887 (* 1 = 0.193887 loss)
I0630 20:48:54.290544  4668 sgd_solver.cpp:105] Iteration 57600, lr = 1e-05
I0630 20:48:57.910151  4668 solver.cpp:218] Iteration 57700 (27.6154 iter/s, 3.62116s/100 iters), loss = 0.210414
I0630 20:48:57.910151  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:48:57.910151  4668 solver.cpp:237]     Train net output #1: loss = 0.210414 (* 1 = 0.210414 loss)
I0630 20:48:57.910151  4668 sgd_solver.cpp:105] Iteration 57700, lr = 1e-05
I0630 20:49:01.534440  4668 solver.cpp:218] Iteration 57800 (27.5884 iter/s, 3.62471s/100 iters), loss = 0.0925443
I0630 20:49:01.534440  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:49:01.534440  4668 solver.cpp:237]     Train net output #1: loss = 0.0925448 (* 1 = 0.0925448 loss)
I0630 20:49:01.534440  4668 sgd_solver.cpp:105] Iteration 57800, lr = 1e-05
I0630 20:49:05.160874  4668 solver.cpp:218] Iteration 57900 (27.5985 iter/s, 3.62338s/100 iters), loss = 0.115653
I0630 20:49:05.160874  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:49:05.160874  4668 solver.cpp:237]     Train net output #1: loss = 0.115653 (* 1 = 0.115653 loss)
I0630 20:49:05.160874  4668 sgd_solver.cpp:105] Iteration 57900, lr = 1e-05
I0630 20:49:08.604897 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:49:08.747720  4668 solver.cpp:330] Iteration 58000, Testing net (#0)
I0630 20:49:08.747720  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:49:09.566349  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:49:09.604933  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8765
I0630 20:49:09.604933  4668 solver.cpp:397]     Test net output #1: loss = 0.416046 (* 1 = 0.416046 loss)
I0630 20:49:09.634934  4668 solver.cpp:218] Iteration 58000 (22.3204 iter/s, 4.4802s/100 iters), loss = 0.174347
I0630 20:49:09.634934  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:49:09.634934  4668 solver.cpp:237]     Train net output #1: loss = 0.174348 (* 1 = 0.174348 loss)
I0630 20:49:09.634934  4668 sgd_solver.cpp:105] Iteration 58000, lr = 1e-05
I0630 20:49:13.266575  4668 solver.cpp:218] Iteration 58100 (27.5871 iter/s, 3.62488s/100 iters), loss = 0.167602
I0630 20:49:13.266575  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:49:13.266575  4668 solver.cpp:237]     Train net output #1: loss = 0.167603 (* 1 = 0.167603 loss)
I0630 20:49:13.266575  4668 sgd_solver.cpp:105] Iteration 58100, lr = 1e-05
I0630 20:49:16.889390  4668 solver.cpp:218] Iteration 58200 (27.602 iter/s, 3.62293s/100 iters), loss = 0.134434
I0630 20:49:16.889390  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:49:16.889390  4668 solver.cpp:237]     Train net output #1: loss = 0.134435 (* 1 = 0.134435 loss)
I0630 20:49:16.889390  4668 sgd_solver.cpp:105] Iteration 58200, lr = 1e-05
I0630 20:49:20.512920  4668 solver.cpp:218] Iteration 58300 (27.5961 iter/s, 3.6237s/100 iters), loss = 0.140886
I0630 20:49:20.512920  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:49:20.512920  4668 solver.cpp:237]     Train net output #1: loss = 0.140886 (* 1 = 0.140886 loss)
I0630 20:49:20.512920  4668 sgd_solver.cpp:105] Iteration 58300, lr = 1e-05
I0630 20:49:24.135291  4668 solver.cpp:218] Iteration 58400 (27.6061 iter/s, 3.62239s/100 iters), loss = 0.146798
I0630 20:49:24.135291  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:49:24.135291  4668 solver.cpp:237]     Train net output #1: loss = 0.146799 (* 1 = 0.146799 loss)
I0630 20:49:24.135291  4668 sgd_solver.cpp:105] Iteration 58400, lr = 1e-05
I0630 20:49:27.585345 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:49:27.727993  4668 solver.cpp:330] Iteration 58500, Testing net (#0)
I0630 20:49:27.727993  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:49:28.546891  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:49:28.584043  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I0630 20:49:28.584043  4668 solver.cpp:397]     Test net output #1: loss = 0.415928 (* 1 = 0.415928 loss)
I0630 20:49:28.615291  4668 solver.cpp:218] Iteration 58500 (22.3127 iter/s, 4.48174s/100 iters), loss = 0.152491
I0630 20:49:28.615291  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:49:28.615291  4668 solver.cpp:237]     Train net output #1: loss = 0.152491 (* 1 = 0.152491 loss)
I0630 20:49:28.615291  4668 sgd_solver.cpp:105] Iteration 58500, lr = 1e-05
I0630 20:49:32.238811  4668 solver.cpp:218] Iteration 58600 (27.6272 iter/s, 3.61963s/100 iters), loss = 0.158877
I0630 20:49:32.238811  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:49:32.238811  4668 solver.cpp:237]     Train net output #1: loss = 0.158878 (* 1 = 0.158878 loss)
I0630 20:49:32.238811  4668 sgd_solver.cpp:105] Iteration 58600, lr = 1e-05
I0630 20:49:35.850806  4668 solver.cpp:218] Iteration 58700 (27.6427 iter/s, 3.6176s/100 iters), loss = 0.144157
I0630 20:49:35.850806  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:49:35.850806  4668 solver.cpp:237]     Train net output #1: loss = 0.144157 (* 1 = 0.144157 loss)
I0630 20:49:35.850806  4668 sgd_solver.cpp:105] Iteration 58700, lr = 1e-05
I0630 20:49:39.476580  4668 solver.cpp:218] Iteration 58800 (27.629 iter/s, 3.61938s/100 iters), loss = 0.100419
I0630 20:49:39.476580  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:49:39.476580  4668 solver.cpp:237]     Train net output #1: loss = 0.100419 (* 1 = 0.100419 loss)
I0630 20:49:39.476580  4668 sgd_solver.cpp:105] Iteration 58800, lr = 1e-05
I0630 20:49:43.092063  4668 solver.cpp:218] Iteration 58900 (27.6586 iter/s, 3.61551s/100 iters), loss = 0.113864
I0630 20:49:43.092063  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:49:43.092562  4668 solver.cpp:237]     Train net output #1: loss = 0.113864 (* 1 = 0.113864 loss)
I0630 20:49:43.092562  4668 sgd_solver.cpp:105] Iteration 58900, lr = 1e-05
I0630 20:49:46.527905 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:49:46.668066  4668 solver.cpp:330] Iteration 59000, Testing net (#0)
I0630 20:49:46.668066  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:49:47.500471  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:49:47.528213  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:49:47.528213  4668 solver.cpp:397]     Test net output #1: loss = 0.416457 (* 1 = 0.416457 loss)
I0630 20:49:47.566004  4668 solver.cpp:218] Iteration 59000 (22.3524 iter/s, 4.47379s/100 iters), loss = 0.160794
I0630 20:49:47.566004  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:49:47.566004  4668 solver.cpp:237]     Train net output #1: loss = 0.160795 (* 1 = 0.160795 loss)
I0630 20:49:47.566004  4668 sgd_solver.cpp:105] Iteration 59000, lr = 1e-05
I0630 20:49:51.190045  4668 solver.cpp:218] Iteration 59100 (27.6006 iter/s, 3.6231s/100 iters), loss = 0.225202
I0630 20:49:51.190045  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:49:51.190045  4668 solver.cpp:237]     Train net output #1: loss = 0.225203 (* 1 = 0.225203 loss)
I0630 20:49:51.190045  4668 sgd_solver.cpp:105] Iteration 59100, lr = 1e-05
I0630 20:49:54.810588  4668 solver.cpp:218] Iteration 59200 (27.6208 iter/s, 3.62046s/100 iters), loss = 0.184643
I0630 20:49:54.810588  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:49:54.810588  4668 solver.cpp:237]     Train net output #1: loss = 0.184644 (* 1 = 0.184644 loss)
I0630 20:49:54.810588  4668 sgd_solver.cpp:105] Iteration 59200, lr = 1e-05
I0630 20:49:58.435173  4668 solver.cpp:218] Iteration 59300 (27.5787 iter/s, 3.62598s/100 iters), loss = 0.137337
I0630 20:49:58.435173  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:49:58.435173  4668 solver.cpp:237]     Train net output #1: loss = 0.137338 (* 1 = 0.137338 loss)
I0630 20:49:58.435173  4668 sgd_solver.cpp:105] Iteration 59300, lr = 1e-05
I0630 20:50:02.125141  4668 solver.cpp:218] Iteration 59400 (27.1169 iter/s, 3.68773s/100 iters), loss = 0.119315
I0630 20:50:02.125141  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:50:02.125141  4668 solver.cpp:237]     Train net output #1: loss = 0.119315 (* 1 = 0.119315 loss)
I0630 20:50:02.125141  4668 sgd_solver.cpp:105] Iteration 59400, lr = 1e-05
I0630 20:50:05.563364 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:50:05.713418  4668 solver.cpp:330] Iteration 59500, Testing net (#0)
I0630 20:50:05.713418  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:50:06.533789  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:50:06.563796  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I0630 20:50:06.563796  4668 solver.cpp:397]     Test net output #1: loss = 0.415927 (* 1 = 0.415927 loss)
I0630 20:50:06.605173  4668 solver.cpp:218] Iteration 59500 (22.3224 iter/s, 4.47981s/100 iters), loss = 0.117972
I0630 20:50:06.605173  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:50:06.605173  4668 solver.cpp:237]     Train net output #1: loss = 0.117972 (* 1 = 0.117972 loss)
I0630 20:50:06.605173  4668 sgd_solver.cpp:105] Iteration 59500, lr = 1e-05
I0630 20:50:10.225148  4668 solver.cpp:218] Iteration 59600 (27.606 iter/s, 3.6224s/100 iters), loss = 0.170597
I0630 20:50:10.225148  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:50:10.225148  4668 solver.cpp:237]     Train net output #1: loss = 0.170598 (* 1 = 0.170598 loss)
I0630 20:50:10.225148  4668 sgd_solver.cpp:105] Iteration 59600, lr = 1e-05
I0630 20:50:13.847916  4668 solver.cpp:218] Iteration 59700 (27.5984 iter/s, 3.6234s/100 iters), loss = 0.202496
I0630 20:50:13.847916  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:50:13.847916  4668 solver.cpp:237]     Train net output #1: loss = 0.202497 (* 1 = 0.202497 loss)
I0630 20:50:13.847916  4668 sgd_solver.cpp:105] Iteration 59700, lr = 1e-05
I0630 20:50:17.471381  4668 solver.cpp:218] Iteration 59800 (27.5997 iter/s, 3.62322s/100 iters), loss = 0.135204
I0630 20:50:17.471381  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:50:17.471381  4668 solver.cpp:237]     Train net output #1: loss = 0.135205 (* 1 = 0.135205 loss)
I0630 20:50:17.471381  4668 sgd_solver.cpp:105] Iteration 59800, lr = 1e-05
I0630 20:50:21.094394  4668 solver.cpp:218] Iteration 59900 (27.6202 iter/s, 3.62054s/100 iters), loss = 0.119801
I0630 20:50:21.094394  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:50:21.094394  4668 solver.cpp:237]     Train net output #1: loss = 0.119801 (* 1 = 0.119801 loss)
I0630 20:50:21.094394  4668 sgd_solver.cpp:105] Iteration 59900, lr = 1e-05
I0630 20:50:24.535874 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:50:24.685941  4668 solver.cpp:330] Iteration 60000, Testing net (#0)
I0630 20:50:24.685941  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:50:25.506335  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:50:25.536342  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8762
I0630 20:50:25.536342  4668 solver.cpp:397]     Test net output #1: loss = 0.416188 (* 1 = 0.416188 loss)
I0630 20:50:25.576431  4668 solver.cpp:218] Iteration 60000 (22.3235 iter/s, 4.47959s/100 iters), loss = 0.162959
I0630 20:50:25.576431  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:50:25.576431  4668 solver.cpp:237]     Train net output #1: loss = 0.162959 (* 1 = 0.162959 loss)
I0630 20:50:25.576431  4668 sgd_solver.cpp:105] Iteration 60000, lr = 1e-05
I0630 20:50:29.199249  4668 solver.cpp:218] Iteration 60100 (27.5784 iter/s, 3.62602s/100 iters), loss = 0.136405
I0630 20:50:29.199249  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:50:29.199249  4668 solver.cpp:237]     Train net output #1: loss = 0.136405 (* 1 = 0.136405 loss)
I0630 20:50:29.199249  4668 sgd_solver.cpp:105] Iteration 60100, lr = 1e-05
I0630 20:50:32.822340  4668 solver.cpp:218] Iteration 60200 (27.5844 iter/s, 3.62524s/100 iters), loss = 0.163781
I0630 20:50:32.822340  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:50:32.822340  4668 solver.cpp:237]     Train net output #1: loss = 0.163782 (* 1 = 0.163782 loss)
I0630 20:50:32.822340  4668 sgd_solver.cpp:105] Iteration 60200, lr = 1e-05
I0630 20:50:36.444752  4668 solver.cpp:218] Iteration 60300 (27.5948 iter/s, 3.62387s/100 iters), loss = 0.149087
I0630 20:50:36.444752  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:50:36.444752  4668 solver.cpp:237]     Train net output #1: loss = 0.149087 (* 1 = 0.149087 loss)
I0630 20:50:36.444752  4668 sgd_solver.cpp:105] Iteration 60300, lr = 1e-05
I0630 20:50:40.067420  4668 solver.cpp:218] Iteration 60400 (27.5998 iter/s, 3.62321s/100 iters), loss = 0.141649
I0630 20:50:40.067420  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:50:40.067420  4668 solver.cpp:237]     Train net output #1: loss = 0.141649 (* 1 = 0.141649 loss)
I0630 20:50:40.067420  4668 sgd_solver.cpp:105] Iteration 60400, lr = 1e-05
I0630 20:50:43.519107 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:50:43.660254  4668 solver.cpp:330] Iteration 60500, Testing net (#0)
I0630 20:50:43.660254  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:50:44.492036  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:50:44.520130  4668 solver.cpp:397]     Test net output #0: accuracy = 0.877
I0630 20:50:44.520130  4668 solver.cpp:397]     Test net output #1: loss = 0.415865 (* 1 = 0.415865 loss)
I0630 20:50:44.550144  4668 solver.cpp:218] Iteration 60500 (22.3112 iter/s, 4.48205s/100 iters), loss = 0.139953
I0630 20:50:44.550144  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:50:44.550144  4668 solver.cpp:237]     Train net output #1: loss = 0.139954 (* 1 = 0.139954 loss)
I0630 20:50:44.550144  4668 sgd_solver.cpp:105] Iteration 60500, lr = 1e-05
I0630 20:50:48.175846  4668 solver.cpp:218] Iteration 60600 (27.5933 iter/s, 3.62407s/100 iters), loss = 0.0954323
I0630 20:50:48.175846  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:50:48.175846  4668 solver.cpp:237]     Train net output #1: loss = 0.0954329 (* 1 = 0.0954329 loss)
I0630 20:50:48.175846  4668 sgd_solver.cpp:105] Iteration 60600, lr = 1e-05
I0630 20:50:51.797564  4668 solver.cpp:218] Iteration 60700 (27.6093 iter/s, 3.62197s/100 iters), loss = 0.237857
I0630 20:50:51.797564  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:50:51.797564  4668 solver.cpp:237]     Train net output #1: loss = 0.237857 (* 1 = 0.237857 loss)
I0630 20:50:51.797564  4668 sgd_solver.cpp:105] Iteration 60700, lr = 1e-05
I0630 20:50:55.421957  4668 solver.cpp:218] Iteration 60800 (27.5946 iter/s, 3.6239s/100 iters), loss = 0.108416
I0630 20:50:55.421957  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:50:55.421957  4668 solver.cpp:237]     Train net output #1: loss = 0.108417 (* 1 = 0.108417 loss)
I0630 20:50:55.421957  4668 sgd_solver.cpp:105] Iteration 60800, lr = 1e-05
I0630 20:50:59.045061  4668 solver.cpp:218] Iteration 60900 (27.6195 iter/s, 3.62063s/100 iters), loss = 0.234044
I0630 20:50:59.045061  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:50:59.045061  4668 solver.cpp:237]     Train net output #1: loss = 0.234044 (* 1 = 0.234044 loss)
I0630 20:50:59.045061  4668 sgd_solver.cpp:105] Iteration 60900, lr = 1e-05
I0630 20:51:02.497592 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:51:02.636636  4668 solver.cpp:330] Iteration 61000, Testing net (#0)
I0630 20:51:02.636636  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:51:03.465976  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:51:03.488477  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 20:51:03.488477  4668 solver.cpp:397]     Test net output #1: loss = 0.416001 (* 1 = 0.416001 loss)
I0630 20:51:03.528496  4668 solver.cpp:218] Iteration 61000 (22.3145 iter/s, 4.4814s/100 iters), loss = 0.114268
I0630 20:51:03.528496  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:51:03.528496  4668 solver.cpp:237]     Train net output #1: loss = 0.114268 (* 1 = 0.114268 loss)
I0630 20:51:03.528496  4668 sgd_solver.cpp:105] Iteration 61000, lr = 1e-05
I0630 20:51:07.145282  4668 solver.cpp:218] Iteration 61100 (27.6097 iter/s, 3.62191s/100 iters), loss = 0.199998
I0630 20:51:07.145282  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:51:07.145282  4668 solver.cpp:237]     Train net output #1: loss = 0.199999 (* 1 = 0.199999 loss)
I0630 20:51:07.145282  4668 sgd_solver.cpp:105] Iteration 61100, lr = 1e-05
I0630 20:51:10.773052  4668 solver.cpp:218] Iteration 61200 (27.6201 iter/s, 3.62055s/100 iters), loss = 0.185033
I0630 20:51:10.773052  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:51:10.773052  4668 solver.cpp:237]     Train net output #1: loss = 0.185033 (* 1 = 0.185033 loss)
I0630 20:51:10.773052  4668 sgd_solver.cpp:105] Iteration 61200, lr = 1e-05
I0630 20:51:14.394811  4668 solver.cpp:218] Iteration 61300 (27.5797 iter/s, 3.62586s/100 iters), loss = 0.141754
I0630 20:51:14.394811  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:51:14.394811  4668 solver.cpp:237]     Train net output #1: loss = 0.141755 (* 1 = 0.141755 loss)
I0630 20:51:14.394811  4668 sgd_solver.cpp:105] Iteration 61300, lr = 1e-05
I0630 20:51:18.018523  4668 solver.cpp:218] Iteration 61400 (27.5923 iter/s, 3.6242s/100 iters), loss = 0.117843
I0630 20:51:18.018523  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:51:18.018523  4668 solver.cpp:237]     Train net output #1: loss = 0.117843 (* 1 = 0.117843 loss)
I0630 20:51:18.018523  4668 sgd_solver.cpp:105] Iteration 61400, lr = 1e-05
I0630 20:51:21.476559 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:51:21.619153  4668 solver.cpp:330] Iteration 61500, Testing net (#0)
I0630 20:51:21.619153  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:51:22.438536  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:51:22.468885  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8767
I0630 20:51:22.468885  4668 solver.cpp:397]     Test net output #1: loss = 0.415902 (* 1 = 0.415902 loss)
I0630 20:51:22.508883  4668 solver.cpp:218] Iteration 61500 (22.3076 iter/s, 4.48277s/100 iters), loss = 0.1581
I0630 20:51:22.508883  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:51:22.508883  4668 solver.cpp:237]     Train net output #1: loss = 0.158101 (* 1 = 0.158101 loss)
I0630 20:51:22.508883  4668 sgd_solver.cpp:105] Iteration 61500, lr = 1e-05
I0630 20:51:26.126807  4668 solver.cpp:218] Iteration 61600 (27.6426 iter/s, 3.61761s/100 iters), loss = 0.193045
I0630 20:51:26.126807  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:51:26.126807  4668 solver.cpp:237]     Train net output #1: loss = 0.193046 (* 1 = 0.193046 loss)
I0630 20:51:26.126807  4668 sgd_solver.cpp:105] Iteration 61600, lr = 1e-05
I0630 20:51:29.747723  4668 solver.cpp:218] Iteration 61700 (27.6211 iter/s, 3.62042s/100 iters), loss = 0.218522
I0630 20:51:29.747723  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:51:29.747723  4668 solver.cpp:237]     Train net output #1: loss = 0.218523 (* 1 = 0.218523 loss)
I0630 20:51:29.747723  4668 sgd_solver.cpp:105] Iteration 61700, lr = 1e-05
I0630 20:51:33.364424  4668 solver.cpp:218] Iteration 61800 (27.6223 iter/s, 3.62027s/100 iters), loss = 0.0889987
I0630 20:51:33.364424  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:51:33.364424  4668 solver.cpp:237]     Train net output #1: loss = 0.0889992 (* 1 = 0.0889992 loss)
I0630 20:51:33.364424  4668 sgd_solver.cpp:105] Iteration 61800, lr = 1e-05
I0630 20:51:36.988641  4668 solver.cpp:218] Iteration 61900 (27.6257 iter/s, 3.61981s/100 iters), loss = 0.0762264
I0630 20:51:36.988641  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:51:36.988641  4668 solver.cpp:237]     Train net output #1: loss = 0.0762269 (* 1 = 0.0762269 loss)
I0630 20:51:36.988641  4668 sgd_solver.cpp:105] Iteration 61900, lr = 1e-05
I0630 20:51:40.431516 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:51:40.574374  4668 solver.cpp:330] Iteration 62000, Testing net (#0)
I0630 20:51:40.574374  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:51:41.392488  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:51:41.432510  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8767
I0630 20:51:41.432510  4668 solver.cpp:397]     Test net output #1: loss = 0.415956 (* 1 = 0.415956 loss)
I0630 20:51:41.462646  4668 solver.cpp:218] Iteration 62000 (22.33 iter/s, 4.47828s/100 iters), loss = 0.164036
I0630 20:51:41.462646  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:51:41.462646  4668 solver.cpp:237]     Train net output #1: loss = 0.164037 (* 1 = 0.164037 loss)
I0630 20:51:41.462646  4668 sgd_solver.cpp:105] Iteration 62000, lr = 1e-05
I0630 20:51:45.095340  4668 solver.cpp:218] Iteration 62100 (27.5555 iter/s, 3.62903s/100 iters), loss = 0.204984
I0630 20:51:45.095340  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:51:45.095340  4668 solver.cpp:237]     Train net output #1: loss = 0.204984 (* 1 = 0.204984 loss)
I0630 20:51:45.095340  4668 sgd_solver.cpp:105] Iteration 62100, lr = 1e-05
I0630 20:51:48.722494  4668 solver.cpp:218] Iteration 62200 (27.5824 iter/s, 3.6255s/100 iters), loss = 0.156005
I0630 20:51:48.722494  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:51:48.722494  4668 solver.cpp:237]     Train net output #1: loss = 0.156006 (* 1 = 0.156006 loss)
I0630 20:51:48.722494  4668 sgd_solver.cpp:105] Iteration 62200, lr = 1e-05
I0630 20:51:52.338495  4668 solver.cpp:218] Iteration 62300 (27.5843 iter/s, 3.62526s/100 iters), loss = 0.135256
I0630 20:51:52.338495  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:51:52.338495  4668 solver.cpp:237]     Train net output #1: loss = 0.135257 (* 1 = 0.135257 loss)
I0630 20:51:52.338495  4668 sgd_solver.cpp:105] Iteration 62300, lr = 1e-05
I0630 20:51:55.972862  4668 solver.cpp:218] Iteration 62400 (27.5913 iter/s, 3.62433s/100 iters), loss = 0.175029
I0630 20:51:55.972862  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:51:55.972862  4668 solver.cpp:237]     Train net output #1: loss = 0.17503 (* 1 = 0.17503 loss)
I0630 20:51:55.972862  4668 sgd_solver.cpp:105] Iteration 62400, lr = 1e-05
I0630 20:51:59.416622 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:51:59.551561  4668 solver.cpp:330] Iteration 62500, Testing net (#0)
I0630 20:51:59.551561  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:52:00.382421  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:52:00.412418  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8766
I0630 20:52:00.412418  4668 solver.cpp:397]     Test net output #1: loss = 0.416009 (* 1 = 0.416009 loss)
I0630 20:52:00.442417  4668 solver.cpp:218] Iteration 62500 (22.3341 iter/s, 4.47747s/100 iters), loss = 0.220373
I0630 20:52:00.442417  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0630 20:52:00.442417  4668 solver.cpp:237]     Train net output #1: loss = 0.220374 (* 1 = 0.220374 loss)
I0630 20:52:00.442417  4668 sgd_solver.cpp:105] Iteration 62500, lr = 1e-05
I0630 20:52:04.064867  4668 solver.cpp:218] Iteration 62600 (27.6118 iter/s, 3.62164s/100 iters), loss = 0.125403
I0630 20:52:04.064867  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:52:04.064867  4668 solver.cpp:237]     Train net output #1: loss = 0.125403 (* 1 = 0.125403 loss)
I0630 20:52:04.064867  4668 sgd_solver.cpp:105] Iteration 62600, lr = 1e-05
I0630 20:52:07.688122  4668 solver.cpp:218] Iteration 62700 (27.6342 iter/s, 3.6187s/100 iters), loss = 0.205022
I0630 20:52:07.688122  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:52:07.688122  4668 solver.cpp:237]     Train net output #1: loss = 0.205022 (* 1 = 0.205022 loss)
I0630 20:52:07.688122  4668 sgd_solver.cpp:105] Iteration 62700, lr = 1e-05
I0630 20:52:11.314038  4668 solver.cpp:218] Iteration 62800 (27.6071 iter/s, 3.62226s/100 iters), loss = 0.159223
I0630 20:52:11.314038  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:52:11.314038  4668 solver.cpp:237]     Train net output #1: loss = 0.159224 (* 1 = 0.159224 loss)
I0630 20:52:11.314038  4668 sgd_solver.cpp:105] Iteration 62800, lr = 1e-05
I0630 20:52:14.935351  4668 solver.cpp:218] Iteration 62900 (27.6028 iter/s, 3.62282s/100 iters), loss = 0.07302
I0630 20:52:14.935351  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:52:14.935351  4668 solver.cpp:237]     Train net output #1: loss = 0.0730206 (* 1 = 0.0730206 loss)
I0630 20:52:14.935351  4668 sgd_solver.cpp:105] Iteration 62900, lr = 1e-05
I0630 20:52:18.378552 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:52:18.524830  4668 solver.cpp:330] Iteration 63000, Testing net (#0)
I0630 20:52:18.524830  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:52:19.344058  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:52:19.374047  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I0630 20:52:19.374047  4668 solver.cpp:397]     Test net output #1: loss = 0.415983 (* 1 = 0.415983 loss)
I0630 20:52:19.408823  4668 solver.cpp:218] Iteration 63000 (22.3359 iter/s, 4.4771s/100 iters), loss = 0.146423
I0630 20:52:19.408823  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:52:19.408823  4668 solver.cpp:237]     Train net output #1: loss = 0.146423 (* 1 = 0.146423 loss)
I0630 20:52:19.408823  4668 sgd_solver.cpp:105] Iteration 63000, lr = 1e-05
I0630 20:52:23.034358  4668 solver.cpp:218] Iteration 63100 (27.6071 iter/s, 3.62226s/100 iters), loss = 0.204361
I0630 20:52:23.034358  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:52:23.034358  4668 solver.cpp:237]     Train net output #1: loss = 0.204362 (* 1 = 0.204362 loss)
I0630 20:52:23.034358  4668 sgd_solver.cpp:105] Iteration 63100, lr = 1e-05
I0630 20:52:26.654618  4668 solver.cpp:218] Iteration 63200 (27.6279 iter/s, 3.61952s/100 iters), loss = 0.230213
I0630 20:52:26.654618  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:52:26.654618  4668 solver.cpp:237]     Train net output #1: loss = 0.230214 (* 1 = 0.230214 loss)
I0630 20:52:26.654618  4668 sgd_solver.cpp:105] Iteration 63200, lr = 1e-05
I0630 20:52:30.275827  4668 solver.cpp:218] Iteration 63300 (27.6323 iter/s, 3.61895s/100 iters), loss = 0.104968
I0630 20:52:30.275827  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:52:30.275827  4668 solver.cpp:237]     Train net output #1: loss = 0.104968 (* 1 = 0.104968 loss)
I0630 20:52:30.275827  4668 sgd_solver.cpp:105] Iteration 63300, lr = 1e-05
I0630 20:52:33.890053  4668 solver.cpp:218] Iteration 63400 (27.6314 iter/s, 3.61907s/100 iters), loss = 0.147637
I0630 20:52:33.890053  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:52:33.890053  4668 solver.cpp:237]     Train net output #1: loss = 0.147638 (* 1 = 0.147638 loss)
I0630 20:52:33.890053  4668 sgd_solver.cpp:105] Iteration 63400, lr = 1e-05
I0630 20:52:37.342787 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:52:37.482571  4668 solver.cpp:330] Iteration 63500, Testing net (#0)
I0630 20:52:37.482571  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:52:38.313668  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:52:38.342202  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 20:52:38.342202  4668 solver.cpp:397]     Test net output #1: loss = 0.416248 (* 1 = 0.416248 loss)
I0630 20:52:38.372490  4668 solver.cpp:218] Iteration 63500 (22.3061 iter/s, 4.48307s/100 iters), loss = 0.160686
I0630 20:52:38.372490  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:52:38.372490  4668 solver.cpp:237]     Train net output #1: loss = 0.160687 (* 1 = 0.160687 loss)
I0630 20:52:38.372490  4668 sgd_solver.cpp:105] Iteration 63500, lr = 1e-05
I0630 20:52:41.993945  4668 solver.cpp:218] Iteration 63600 (27.5991 iter/s, 3.6233s/100 iters), loss = 0.137146
I0630 20:52:41.993945  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:52:41.993945  4668 solver.cpp:237]     Train net output #1: loss = 0.137147 (* 1 = 0.137147 loss)
I0630 20:52:41.993945  4668 sgd_solver.cpp:105] Iteration 63600, lr = 1e-05
I0630 20:52:45.626262  4668 solver.cpp:218] Iteration 63700 (27.5819 iter/s, 3.62556s/100 iters), loss = 0.14122
I0630 20:52:45.626262  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:52:45.626262  4668 solver.cpp:237]     Train net output #1: loss = 0.141221 (* 1 = 0.141221 loss)
I0630 20:52:45.626262  4668 sgd_solver.cpp:105] Iteration 63700, lr = 1e-05
I0630 20:52:49.250475  4668 solver.cpp:218] Iteration 63800 (27.5945 iter/s, 3.62391s/100 iters), loss = 0.0843983
I0630 20:52:49.250475  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0630 20:52:49.250475  4668 solver.cpp:237]     Train net output #1: loss = 0.084399 (* 1 = 0.084399 loss)
I0630 20:52:49.250475  4668 sgd_solver.cpp:105] Iteration 63800, lr = 1e-05
I0630 20:52:52.873939  4668 solver.cpp:218] Iteration 63900 (27.5927 iter/s, 3.62414s/100 iters), loss = 0.0850064
I0630 20:52:52.873939  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:52:52.873939  4668 solver.cpp:237]     Train net output #1: loss = 0.0850071 (* 1 = 0.0850071 loss)
I0630 20:52:52.873939  4668 sgd_solver.cpp:105] Iteration 63900, lr = 1e-05
I0630 20:52:56.316689 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:52:56.465138  4668 solver.cpp:330] Iteration 64000, Testing net (#0)
I0630 20:52:56.465138  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:52:57.290138  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:52:57.321233  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8767
I0630 20:52:57.321233  4668 solver.cpp:397]     Test net output #1: loss = 0.415885 (* 1 = 0.415885 loss)
I0630 20:52:57.354745  4668 solver.cpp:218] Iteration 64000 (22.3291 iter/s, 4.47846s/100 iters), loss = 0.146437
I0630 20:52:57.354745  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:52:57.354745  4668 solver.cpp:237]     Train net output #1: loss = 0.146438 (* 1 = 0.146438 loss)
I0630 20:52:57.354745  4668 sgd_solver.cpp:46] MultiStep Status: Iteration 64000, step = 4
I0630 20:52:57.354745  4668 sgd_solver.cpp:105] Iteration 64000, lr = 1e-06
I0630 20:53:00.978036  4668 solver.cpp:218] Iteration 64100 (27.6091 iter/s, 3.622s/100 iters), loss = 0.227
I0630 20:53:00.978036  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:53:00.978036  4668 solver.cpp:237]     Train net output #1: loss = 0.227 (* 1 = 0.227 loss)
I0630 20:53:00.978036  4668 sgd_solver.cpp:105] Iteration 64100, lr = 1e-06
I0630 20:53:04.594696  4668 solver.cpp:218] Iteration 64200 (27.6235 iter/s, 3.62011s/100 iters), loss = 0.170797
I0630 20:53:04.594696  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:53:04.594696  4668 solver.cpp:237]     Train net output #1: loss = 0.170797 (* 1 = 0.170797 loss)
I0630 20:53:04.594696  4668 sgd_solver.cpp:105] Iteration 64200, lr = 1e-06
I0630 20:53:08.222854  4668 solver.cpp:218] Iteration 64300 (27.5994 iter/s, 3.62327s/100 iters), loss = 0.19355
I0630 20:53:08.222854  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:53:08.222854  4668 solver.cpp:237]     Train net output #1: loss = 0.193551 (* 1 = 0.193551 loss)
I0630 20:53:08.222854  4668 sgd_solver.cpp:105] Iteration 64300, lr = 1e-06
I0630 20:53:11.845266  4668 solver.cpp:218] Iteration 64400 (27.5884 iter/s, 3.62471s/100 iters), loss = 0.0933439
I0630 20:53:11.845266  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:53:11.845266  4668 solver.cpp:237]     Train net output #1: loss = 0.0933446 (* 1 = 0.0933446 loss)
I0630 20:53:11.845266  4668 sgd_solver.cpp:105] Iteration 64400, lr = 1e-06
I0630 20:53:15.293565 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:53:15.428282  4668 solver.cpp:330] Iteration 64500, Testing net (#0)
I0630 20:53:15.428282  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:53:16.260125  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:53:16.290797  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8767
I0630 20:53:16.291786  4668 solver.cpp:397]     Test net output #1: loss = 0.416132 (* 1 = 0.416132 loss)
I0630 20:53:16.320847  4668 solver.cpp:218] Iteration 64500 (22.333 iter/s, 4.47767s/100 iters), loss = 0.14745
I0630 20:53:16.320847  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:53:16.320847  4668 solver.cpp:237]     Train net output #1: loss = 0.147451 (* 1 = 0.147451 loss)
I0630 20:53:16.320847  4668 sgd_solver.cpp:105] Iteration 64500, lr = 1e-06
I0630 20:53:19.943038  4668 solver.cpp:218] Iteration 64600 (27.6354 iter/s, 3.61855s/100 iters), loss = 0.210009
I0630 20:53:19.943038  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:53:19.943038  4668 solver.cpp:237]     Train net output #1: loss = 0.210009 (* 1 = 0.210009 loss)
I0630 20:53:19.943038  4668 sgd_solver.cpp:105] Iteration 64600, lr = 1e-06
I0630 20:53:23.568303  4668 solver.cpp:218] Iteration 64700 (27.5988 iter/s, 3.62335s/100 iters), loss = 0.161704
I0630 20:53:23.568303  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:53:23.568303  4668 solver.cpp:237]     Train net output #1: loss = 0.161705 (* 1 = 0.161705 loss)
I0630 20:53:23.568303  4668 sgd_solver.cpp:105] Iteration 64700, lr = 1e-06
I0630 20:53:27.184775  4668 solver.cpp:218] Iteration 64800 (27.6274 iter/s, 3.6196s/100 iters), loss = 0.186164
I0630 20:53:27.184775  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:53:27.184775  4668 solver.cpp:237]     Train net output #1: loss = 0.186165 (* 1 = 0.186165 loss)
I0630 20:53:27.184775  4668 sgd_solver.cpp:105] Iteration 64800, lr = 1e-06
I0630 20:53:30.806020  4668 solver.cpp:218] Iteration 64900 (27.6112 iter/s, 3.62171s/100 iters), loss = 0.0859731
I0630 20:53:30.806020  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:53:30.806020  4668 solver.cpp:237]     Train net output #1: loss = 0.0859739 (* 1 = 0.0859739 loss)
I0630 20:53:30.806020  4668 sgd_solver.cpp:105] Iteration 64900, lr = 1e-06
I0630 20:53:34.248191 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:53:34.388167  4668 solver.cpp:330] Iteration 65000, Testing net (#0)
I0630 20:53:34.388167  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:53:35.222297  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:53:35.250370  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8766
I0630 20:53:35.250370  4668 solver.cpp:397]     Test net output #1: loss = 0.416575 (* 1 = 0.416575 loss)
I0630 20:53:35.290544  4668 solver.cpp:218] Iteration 65000 (22.3193 iter/s, 4.48043s/100 iters), loss = 0.184242
I0630 20:53:35.291544  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:53:35.291544  4668 solver.cpp:237]     Train net output #1: loss = 0.184242 (* 1 = 0.184242 loss)
I0630 20:53:35.291544  4668 sgd_solver.cpp:105] Iteration 65000, lr = 1e-06
I0630 20:53:38.911010  4668 solver.cpp:218] Iteration 65100 (27.5896 iter/s, 3.62455s/100 iters), loss = 0.247548
I0630 20:53:38.911010  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:53:38.911010  4668 solver.cpp:237]     Train net output #1: loss = 0.247549 (* 1 = 0.247549 loss)
I0630 20:53:38.911010  4668 sgd_solver.cpp:105] Iteration 65100, lr = 1e-06
I0630 20:53:42.533761  4668 solver.cpp:218] Iteration 65200 (27.5882 iter/s, 3.62474s/100 iters), loss = 0.160592
I0630 20:53:42.533761  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:53:42.533761  4668 solver.cpp:237]     Train net output #1: loss = 0.160593 (* 1 = 0.160593 loss)
I0630 20:53:42.533761  4668 sgd_solver.cpp:105] Iteration 65200, lr = 1e-06
I0630 20:53:46.155192  4668 solver.cpp:218] Iteration 65300 (27.6046 iter/s, 3.62259s/100 iters), loss = 0.164432
I0630 20:53:46.155192  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:53:46.155192  4668 solver.cpp:237]     Train net output #1: loss = 0.164433 (* 1 = 0.164433 loss)
I0630 20:53:46.155192  4668 sgd_solver.cpp:105] Iteration 65300, lr = 1e-06
I0630 20:53:49.781229  4668 solver.cpp:218] Iteration 65400 (27.5829 iter/s, 3.62543s/100 iters), loss = 0.140646
I0630 20:53:49.781229  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:53:49.781229  4668 solver.cpp:237]     Train net output #1: loss = 0.140647 (* 1 = 0.140647 loss)
I0630 20:53:49.781229  4668 sgd_solver.cpp:105] Iteration 65400, lr = 1e-06
I0630 20:53:53.225432 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:53:53.376668  4668 solver.cpp:330] Iteration 65500, Testing net (#0)
I0630 20:53:53.376668  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:53:54.198587  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:53:54.225648  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:53:54.225648  4668 solver.cpp:397]     Test net output #1: loss = 0.415897 (* 1 = 0.415897 loss)
I0630 20:53:54.255651  4668 solver.cpp:218] Iteration 65500 (22.3513 iter/s, 4.47401s/100 iters), loss = 0.134395
I0630 20:53:54.255651  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:53:54.255651  4668 solver.cpp:237]     Train net output #1: loss = 0.134396 (* 1 = 0.134396 loss)
I0630 20:53:54.255651  4668 sgd_solver.cpp:105] Iteration 65500, lr = 1e-06
I0630 20:53:57.878655  4668 solver.cpp:218] Iteration 65600 (27.6093 iter/s, 3.62197s/100 iters), loss = 0.115145
I0630 20:53:57.878655  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:53:57.878655  4668 solver.cpp:237]     Train net output #1: loss = 0.115145 (* 1 = 0.115145 loss)
I0630 20:53:57.878655  4668 sgd_solver.cpp:105] Iteration 65600, lr = 1e-06
I0630 20:54:01.508213  4668 solver.cpp:218] Iteration 65700 (27.6137 iter/s, 3.62139s/100 iters), loss = 0.12471
I0630 20:54:01.508716  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:54:01.508716  4668 solver.cpp:237]     Train net output #1: loss = 0.124711 (* 1 = 0.124711 loss)
I0630 20:54:01.508716  4668 sgd_solver.cpp:105] Iteration 65700, lr = 1e-06
I0630 20:54:05.122191  4668 solver.cpp:218] Iteration 65800 (27.6087 iter/s, 3.62205s/100 iters), loss = 0.154091
I0630 20:54:05.122191  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:54:05.122191  4668 solver.cpp:237]     Train net output #1: loss = 0.154092 (* 1 = 0.154092 loss)
I0630 20:54:05.122191  4668 sgd_solver.cpp:105] Iteration 65800, lr = 1e-06
I0630 20:54:08.744889  4668 solver.cpp:218] Iteration 65900 (27.6136 iter/s, 3.6214s/100 iters), loss = 0.0815424
I0630 20:54:08.744889  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:54:08.744889  4668 solver.cpp:237]     Train net output #1: loss = 0.0815432 (* 1 = 0.0815432 loss)
I0630 20:54:08.744889  4668 sgd_solver.cpp:105] Iteration 65900, lr = 1e-06
I0630 20:54:12.196645 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:54:12.338835  4668 solver.cpp:330] Iteration 66000, Testing net (#0)
I0630 20:54:12.338835  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:54:13.158646  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:54:13.194186  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8765
I0630 20:54:13.194186  4668 solver.cpp:397]     Test net output #1: loss = 0.415726 (* 1 = 0.415726 loss)
I0630 20:54:13.228698  4668 solver.cpp:218] Iteration 66000 (22.341 iter/s, 4.47608s/100 iters), loss = 0.115063
I0630 20:54:13.228698  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:54:13.228698  4668 solver.cpp:237]     Train net output #1: loss = 0.115064 (* 1 = 0.115064 loss)
I0630 20:54:13.228698  4668 sgd_solver.cpp:105] Iteration 66000, lr = 1e-06
I0630 20:54:16.848806  4668 solver.cpp:218] Iteration 66100 (27.6235 iter/s, 3.62011s/100 iters), loss = 0.117141
I0630 20:54:16.848806  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:54:16.848806  4668 solver.cpp:237]     Train net output #1: loss = 0.117142 (* 1 = 0.117142 loss)
I0630 20:54:16.848806  4668 sgd_solver.cpp:105] Iteration 66100, lr = 1e-06
I0630 20:54:20.513614  4668 solver.cpp:218] Iteration 66200 (27.2251 iter/s, 3.67309s/100 iters), loss = 0.13819
I0630 20:54:20.513614  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:54:20.513614  4668 solver.cpp:237]     Train net output #1: loss = 0.138191 (* 1 = 0.138191 loss)
I0630 20:54:20.513614  4668 sgd_solver.cpp:105] Iteration 66200, lr = 1e-06
I0630 20:54:24.136306  4668 solver.cpp:218] Iteration 66300 (27.6642 iter/s, 3.61478s/100 iters), loss = 0.127144
I0630 20:54:24.136306  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:54:24.136306  4668 solver.cpp:237]     Train net output #1: loss = 0.127145 (* 1 = 0.127145 loss)
I0630 20:54:24.136306  4668 sgd_solver.cpp:105] Iteration 66300, lr = 1e-06
I0630 20:54:27.745156  4668 solver.cpp:218] Iteration 66400 (27.7065 iter/s, 3.60926s/100 iters), loss = 0.139095
I0630 20:54:27.745156  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:54:27.745156  4668 solver.cpp:237]     Train net output #1: loss = 0.139096 (* 1 = 0.139096 loss)
I0630 20:54:27.745156  4668 sgd_solver.cpp:105] Iteration 66400, lr = 1e-06
I0630 20:54:31.171370 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:54:31.317026  4668 solver.cpp:330] Iteration 66500, Testing net (#0)
I0630 20:54:31.317026  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:54:32.135443  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:54:32.172467  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 20:54:32.172467  4668 solver.cpp:397]     Test net output #1: loss = 0.415788 (* 1 = 0.415788 loss)
I0630 20:54:32.202469  4668 solver.cpp:218] Iteration 66500 (22.4153 iter/s, 4.46125s/100 iters), loss = 0.146731
I0630 20:54:32.202469  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:54:32.202469  4668 solver.cpp:237]     Train net output #1: loss = 0.146732 (* 1 = 0.146732 loss)
I0630 20:54:32.202469  4668 sgd_solver.cpp:105] Iteration 66500, lr = 1e-06
I0630 20:54:35.814504  4668 solver.cpp:218] Iteration 66600 (27.7014 iter/s, 3.60992s/100 iters), loss = 0.192597
I0630 20:54:35.814504  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:54:35.814504  4668 solver.cpp:237]     Train net output #1: loss = 0.192597 (* 1 = 0.192597 loss)
I0630 20:54:35.814504  4668 sgd_solver.cpp:105] Iteration 66600, lr = 1e-06
I0630 20:54:39.427512  4668 solver.cpp:218] Iteration 66700 (27.6848 iter/s, 3.61209s/100 iters), loss = 0.173635
I0630 20:54:39.427512  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:54:39.427512  4668 solver.cpp:237]     Train net output #1: loss = 0.173636 (* 1 = 0.173636 loss)
I0630 20:54:39.427512  4668 sgd_solver.cpp:105] Iteration 66700, lr = 1e-06
I0630 20:54:43.040834  4668 solver.cpp:218] Iteration 66800 (27.7018 iter/s, 3.60987s/100 iters), loss = 0.162011
I0630 20:54:43.040834  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:54:43.040834  4668 solver.cpp:237]     Train net output #1: loss = 0.162012 (* 1 = 0.162012 loss)
I0630 20:54:43.040834  4668 sgd_solver.cpp:105] Iteration 66800, lr = 1e-06
I0630 20:54:46.655550  4668 solver.cpp:218] Iteration 66900 (27.6722 iter/s, 3.61374s/100 iters), loss = 0.161681
I0630 20:54:46.655550  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:54:46.655550  4668 solver.cpp:237]     Train net output #1: loss = 0.161682 (* 1 = 0.161682 loss)
I0630 20:54:46.655550  4668 sgd_solver.cpp:105] Iteration 66900, lr = 1e-06
I0630 20:54:50.093936 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:54:50.236289  4668 solver.cpp:330] Iteration 67000, Testing net (#0)
I0630 20:54:50.236289  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:54:51.057073  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:54:51.088166  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 20:54:51.088166  4668 solver.cpp:397]     Test net output #1: loss = 0.416189 (* 1 = 0.416189 loss)
I0630 20:54:51.122615  4668 solver.cpp:218] Iteration 67000 (22.3882 iter/s, 4.46664s/100 iters), loss = 0.19861
I0630 20:54:51.122615  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:54:51.122615  4668 solver.cpp:237]     Train net output #1: loss = 0.198611 (* 1 = 0.198611 loss)
I0630 20:54:51.122615  4668 sgd_solver.cpp:105] Iteration 67000, lr = 1e-06
I0630 20:54:54.729962  4668 solver.cpp:218] Iteration 67100 (27.6831 iter/s, 3.61231s/100 iters), loss = 0.147205
I0630 20:54:54.729962  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:54:54.729962  4668 solver.cpp:237]     Train net output #1: loss = 0.147205 (* 1 = 0.147205 loss)
I0630 20:54:54.729962  4668 sgd_solver.cpp:105] Iteration 67100, lr = 1e-06
I0630 20:54:58.335265  4668 solver.cpp:218] Iteration 67200 (27.7164 iter/s, 3.60797s/100 iters), loss = 0.16657
I0630 20:54:58.335265  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:54:58.335265  4668 solver.cpp:237]     Train net output #1: loss = 0.166571 (* 1 = 0.166571 loss)
I0630 20:54:58.335265  4668 sgd_solver.cpp:105] Iteration 67200, lr = 1e-06
I0630 20:55:01.953807  4668 solver.cpp:218] Iteration 67300 (27.7057 iter/s, 3.60937s/100 iters), loss = 0.090193
I0630 20:55:01.953807  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:55:01.953807  4668 solver.cpp:237]     Train net output #1: loss = 0.0901937 (* 1 = 0.0901937 loss)
I0630 20:55:01.953807  4668 sgd_solver.cpp:105] Iteration 67300, lr = 1e-06
I0630 20:55:05.565577  4668 solver.cpp:218] Iteration 67400 (27.6872 iter/s, 3.61178s/100 iters), loss = 0.147654
I0630 20:55:05.565577  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:55:05.565577  4668 solver.cpp:237]     Train net output #1: loss = 0.147655 (* 1 = 0.147655 loss)
I0630 20:55:05.565577  4668 sgd_solver.cpp:105] Iteration 67400, lr = 1e-06
I0630 20:55:08.995483 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:55:09.143146  4668 solver.cpp:330] Iteration 67500, Testing net (#0)
I0630 20:55:09.143146  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:55:09.954699  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:55:09.994688  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 20:55:09.994688  4668 solver.cpp:397]     Test net output #1: loss = 0.416159 (* 1 = 0.416159 loss)
I0630 20:55:10.024565  4668 solver.cpp:218] Iteration 67500 (22.4057 iter/s, 4.46316s/100 iters), loss = 0.106866
I0630 20:55:10.024565  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:55:10.024565  4668 solver.cpp:237]     Train net output #1: loss = 0.106867 (* 1 = 0.106867 loss)
I0630 20:55:10.024565  4668 sgd_solver.cpp:105] Iteration 67500, lr = 1e-06
I0630 20:55:13.635416  4668 solver.cpp:218] Iteration 67600 (27.6838 iter/s, 3.61222s/100 iters), loss = 0.165177
I0630 20:55:13.635416  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:55:13.635416  4668 solver.cpp:237]     Train net output #1: loss = 0.165178 (* 1 = 0.165178 loss)
I0630 20:55:13.635416  4668 sgd_solver.cpp:105] Iteration 67600, lr = 1e-06
I0630 20:55:17.248073  4668 solver.cpp:218] Iteration 67700 (27.6986 iter/s, 3.61029s/100 iters), loss = 0.203606
I0630 20:55:17.248073  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:55:17.248073  4668 solver.cpp:237]     Train net output #1: loss = 0.203607 (* 1 = 0.203607 loss)
I0630 20:55:17.248073  4668 sgd_solver.cpp:105] Iteration 67700, lr = 1e-06
I0630 20:55:20.863983  4668 solver.cpp:218] Iteration 67800 (27.6929 iter/s, 3.61104s/100 iters), loss = 0.10622
I0630 20:55:20.863983  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:55:20.863983  4668 solver.cpp:237]     Train net output #1: loss = 0.10622 (* 1 = 0.10622 loss)
I0630 20:55:20.863983  4668 sgd_solver.cpp:105] Iteration 67800, lr = 1e-06
I0630 20:55:24.473444  4668 solver.cpp:218] Iteration 67900 (27.6798 iter/s, 3.61274s/100 iters), loss = 0.147205
I0630 20:55:24.473444  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:55:24.473444  4668 solver.cpp:237]     Train net output #1: loss = 0.147206 (* 1 = 0.147206 loss)
I0630 20:55:24.473444  4668 sgd_solver.cpp:105] Iteration 67900, lr = 1e-06
I0630 20:55:27.905493 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:55:28.045562  4668 solver.cpp:330] Iteration 68000, Testing net (#0)
I0630 20:55:28.055550  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:55:28.876126  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:55:28.906113  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8765
I0630 20:55:28.906113  4668 solver.cpp:397]     Test net output #1: loss = 0.415862 (* 1 = 0.415862 loss)
I0630 20:55:28.936889  4668 solver.cpp:218] Iteration 68000 (22.3983 iter/s, 4.46462s/100 iters), loss = 0.14691
I0630 20:55:28.936889  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:55:28.936889  4668 solver.cpp:237]     Train net output #1: loss = 0.14691 (* 1 = 0.14691 loss)
I0630 20:55:28.936889  4668 sgd_solver.cpp:105] Iteration 68000, lr = 1e-06
I0630 20:55:32.557973  4668 solver.cpp:218] Iteration 68100 (27.6567 iter/s, 3.61577s/100 iters), loss = 0.243948
I0630 20:55:32.557973  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:55:32.557973  4668 solver.cpp:237]     Train net output #1: loss = 0.243949 (* 1 = 0.243949 loss)
I0630 20:55:32.557973  4668 sgd_solver.cpp:105] Iteration 68100, lr = 1e-06
I0630 20:55:36.167629  4668 solver.cpp:218] Iteration 68200 (27.7064 iter/s, 3.60928s/100 iters), loss = 0.114083
I0630 20:55:36.167629  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:55:36.167629  4668 solver.cpp:237]     Train net output #1: loss = 0.114083 (* 1 = 0.114083 loss)
I0630 20:55:36.167629  4668 sgd_solver.cpp:105] Iteration 68200, lr = 1e-06
I0630 20:55:39.771869  4668 solver.cpp:218] Iteration 68300 (27.736 iter/s, 3.60542s/100 iters), loss = 0.148728
I0630 20:55:39.771869  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:55:39.771869  4668 solver.cpp:237]     Train net output #1: loss = 0.148729 (* 1 = 0.148729 loss)
I0630 20:55:39.771869  4668 sgd_solver.cpp:105] Iteration 68300, lr = 1e-06
I0630 20:55:43.375733  4668 solver.cpp:218] Iteration 68400 (27.6892 iter/s, 3.61152s/100 iters), loss = 0.148813
I0630 20:55:43.375733  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:55:43.375733  4668 solver.cpp:237]     Train net output #1: loss = 0.148814 (* 1 = 0.148814 loss)
I0630 20:55:43.375733  4668 sgd_solver.cpp:105] Iteration 68400, lr = 1e-06
I0630 20:55:46.821775 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:55:46.962894  4668 solver.cpp:330] Iteration 68500, Testing net (#0)
I0630 20:55:46.963395  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:55:47.778995  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:55:47.808982  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 20:55:47.808982  4668 solver.cpp:397]     Test net output #1: loss = 0.416017 (* 1 = 0.416017 loss)
I0630 20:55:47.848796  4668 solver.cpp:218] Iteration 68500 (22.4007 iter/s, 4.46414s/100 iters), loss = 0.125539
I0630 20:55:47.848796  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:55:47.848796  4668 solver.cpp:237]     Train net output #1: loss = 0.125539 (* 1 = 0.125539 loss)
I0630 20:55:47.848796  4668 sgd_solver.cpp:105] Iteration 68500, lr = 1e-06
I0630 20:55:51.458911  4668 solver.cpp:218] Iteration 68600 (27.6446 iter/s, 3.61734s/100 iters), loss = 0.166251
I0630 20:55:51.458911  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:55:51.458911  4668 solver.cpp:237]     Train net output #1: loss = 0.166251 (* 1 = 0.166251 loss)
I0630 20:55:51.458911  4668 sgd_solver.cpp:105] Iteration 68600, lr = 1e-06
I0630 20:55:55.083289  4668 solver.cpp:218] Iteration 68700 (27.6553 iter/s, 3.61594s/100 iters), loss = 0.137496
I0630 20:55:55.083289  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:55:55.083289  4668 solver.cpp:237]     Train net output #1: loss = 0.137496 (* 1 = 0.137496 loss)
I0630 20:55:55.083289  4668 sgd_solver.cpp:105] Iteration 68700, lr = 1e-06
I0630 20:55:58.697911  4668 solver.cpp:218] Iteration 68800 (27.6729 iter/s, 3.61365s/100 iters), loss = 0.113345
I0630 20:55:58.697911  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:55:58.697911  4668 solver.cpp:237]     Train net output #1: loss = 0.113346 (* 1 = 0.113346 loss)
I0630 20:55:58.697911  4668 sgd_solver.cpp:105] Iteration 68800, lr = 1e-06
I0630 20:56:02.309139  4668 solver.cpp:218] Iteration 68900 (27.6818 iter/s, 3.61248s/100 iters), loss = 0.158865
I0630 20:56:02.309139  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:56:02.309139  4668 solver.cpp:237]     Train net output #1: loss = 0.158866 (* 1 = 0.158866 loss)
I0630 20:56:02.309139  4668 sgd_solver.cpp:105] Iteration 68900, lr = 1e-06
I0630 20:56:05.742938 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:56:05.883041  4668 solver.cpp:330] Iteration 69000, Testing net (#0)
I0630 20:56:05.883041  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:56:06.710469  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:56:06.742101  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:56:06.742101  4668 solver.cpp:397]     Test net output #1: loss = 0.416138 (* 1 = 0.416138 loss)
I0630 20:56:06.774122  4668 solver.cpp:218] Iteration 69000 (22.3941 iter/s, 4.46547s/100 iters), loss = 0.13041
I0630 20:56:06.774122  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:56:06.774122  4668 solver.cpp:237]     Train net output #1: loss = 0.130411 (* 1 = 0.130411 loss)
I0630 20:56:06.774122  4668 sgd_solver.cpp:105] Iteration 69000, lr = 1e-06
I0630 20:56:10.385740  4668 solver.cpp:218] Iteration 69100 (27.7059 iter/s, 3.60933s/100 iters), loss = 0.199313
I0630 20:56:10.385740  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:56:10.385740  4668 solver.cpp:237]     Train net output #1: loss = 0.199314 (* 1 = 0.199314 loss)
I0630 20:56:10.385740  4668 sgd_solver.cpp:105] Iteration 69100, lr = 1e-06
I0630 20:56:13.988549  4668 solver.cpp:218] Iteration 69200 (27.7093 iter/s, 3.60889s/100 iters), loss = 0.175453
I0630 20:56:13.988549  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:56:13.988549  4668 solver.cpp:237]     Train net output #1: loss = 0.175453 (* 1 = 0.175453 loss)
I0630 20:56:13.988549  4668 sgd_solver.cpp:105] Iteration 69200, lr = 1e-06
I0630 20:56:17.595204  4668 solver.cpp:218] Iteration 69300 (27.7085 iter/s, 3.609s/100 iters), loss = 0.158327
I0630 20:56:17.595204  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:56:17.595204  4668 solver.cpp:237]     Train net output #1: loss = 0.158327 (* 1 = 0.158327 loss)
I0630 20:56:17.595204  4668 sgd_solver.cpp:105] Iteration 69300, lr = 1e-06
I0630 20:56:21.212996  4668 solver.cpp:218] Iteration 69400 (27.6954 iter/s, 3.6107s/100 iters), loss = 0.11953
I0630 20:56:21.212996  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:56:21.212996  4668 solver.cpp:237]     Train net output #1: loss = 0.119531 (* 1 = 0.119531 loss)
I0630 20:56:21.212996  4668 sgd_solver.cpp:105] Iteration 69400, lr = 1e-06
I0630 20:56:24.645153 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:56:24.785245  4668 solver.cpp:330] Iteration 69500, Testing net (#0)
I0630 20:56:24.785245  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:56:25.605703  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:56:25.635715  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8769
I0630 20:56:25.635715  4668 solver.cpp:397]     Test net output #1: loss = 0.416616 (* 1 = 0.416616 loss)
I0630 20:56:25.675740  4668 solver.cpp:218] Iteration 69500 (22.424 iter/s, 4.45951s/100 iters), loss = 0.176607
I0630 20:56:25.675740  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:56:25.675740  4668 solver.cpp:237]     Train net output #1: loss = 0.176607 (* 1 = 0.176607 loss)
I0630 20:56:25.675740  4668 sgd_solver.cpp:105] Iteration 69500, lr = 1e-06
I0630 20:56:29.287474  4668 solver.cpp:218] Iteration 69600 (27.684 iter/s, 3.61219s/100 iters), loss = 0.15829
I0630 20:56:29.287474  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:56:29.287474  4668 solver.cpp:237]     Train net output #1: loss = 0.15829 (* 1 = 0.15829 loss)
I0630 20:56:29.287474  4668 sgd_solver.cpp:105] Iteration 69600, lr = 1e-06
I0630 20:56:32.891239  4668 solver.cpp:218] Iteration 69700 (27.6976 iter/s, 3.61042s/100 iters), loss = 0.195232
I0630 20:56:32.891239  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:56:32.891239  4668 solver.cpp:237]     Train net output #1: loss = 0.195232 (* 1 = 0.195232 loss)
I0630 20:56:32.891239  4668 sgd_solver.cpp:105] Iteration 69700, lr = 1e-06
I0630 20:56:36.503998  4668 solver.cpp:218] Iteration 69800 (27.715 iter/s, 3.60816s/100 iters), loss = 0.13627
I0630 20:56:36.503998  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:56:36.503998  4668 solver.cpp:237]     Train net output #1: loss = 0.136271 (* 1 = 0.136271 loss)
I0630 20:56:36.503998  4668 sgd_solver.cpp:105] Iteration 69800, lr = 1e-06
I0630 20:56:40.115665  4668 solver.cpp:218] Iteration 69900 (27.6915 iter/s, 3.61122s/100 iters), loss = 0.0947228
I0630 20:56:40.115665  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:56:40.115665  4668 solver.cpp:237]     Train net output #1: loss = 0.0947233 (* 1 = 0.0947233 loss)
I0630 20:56:40.115665  4668 sgd_solver.cpp:105] Iteration 69900, lr = 1e-06
I0630 20:56:43.547013 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:56:43.687770  4668 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/128K_iter_70000.caffemodel
I0630 20:56:43.727813  4668 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/128K_iter_70000.solverstate
I0630 20:56:43.727813  4668 solver.cpp:330] Iteration 70000, Testing net (#0)
I0630 20:56:43.727813  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:56:44.548429  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:56:44.583142  4668 solver.cpp:397]     Test net output #0: accuracy = 0.876
I0630 20:56:44.583142  4668 solver.cpp:397]     Test net output #1: loss = 0.415682 (* 1 = 0.415682 loss)
I0630 20:56:44.608223  4668 solver.cpp:218] Iteration 70000 (22.2315 iter/s, 4.49811s/100 iters), loss = 0.153754
I0630 20:56:44.608223  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:56:44.608223  4668 solver.cpp:237]     Train net output #1: loss = 0.153755 (* 1 = 0.153755 loss)
I0630 20:56:44.608223  4668 sgd_solver.cpp:105] Iteration 70000, lr = 1e-06
I0630 20:56:48.220633  4668 solver.cpp:218] Iteration 70100 (27.6862 iter/s, 3.61191s/100 iters), loss = 0.171956
I0630 20:56:48.220633  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:56:48.220633  4668 solver.cpp:237]     Train net output #1: loss = 0.171956 (* 1 = 0.171956 loss)
I0630 20:56:48.220633  4668 sgd_solver.cpp:105] Iteration 70100, lr = 1e-06
I0630 20:56:51.842636  4668 solver.cpp:218] Iteration 70200 (27.6695 iter/s, 3.61409s/100 iters), loss = 0.210532
I0630 20:56:51.842636  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:56:51.842636  4668 solver.cpp:237]     Train net output #1: loss = 0.210532 (* 1 = 0.210532 loss)
I0630 20:56:51.842636  4668 sgd_solver.cpp:105] Iteration 70200, lr = 1e-06
I0630 20:56:55.455770  4668 solver.cpp:218] Iteration 70300 (27.6823 iter/s, 3.61241s/100 iters), loss = 0.128906
I0630 20:56:55.455770  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:56:55.455770  4668 solver.cpp:237]     Train net output #1: loss = 0.128906 (* 1 = 0.128906 loss)
I0630 20:56:55.455770  4668 sgd_solver.cpp:105] Iteration 70300, lr = 1e-06
I0630 20:56:59.058624  4668 solver.cpp:218] Iteration 70400 (27.707 iter/s, 3.6092s/100 iters), loss = 0.115638
I0630 20:56:59.058624  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:56:59.058624  4668 solver.cpp:237]     Train net output #1: loss = 0.115639 (* 1 = 0.115639 loss)
I0630 20:56:59.058624  4668 sgd_solver.cpp:105] Iteration 70400, lr = 1e-06
I0630 20:57:02.490905 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:57:02.635819  4668 solver.cpp:330] Iteration 70500, Testing net (#0)
I0630 20:57:02.635819  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:57:03.461232  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:57:03.491269  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8762
I0630 20:57:03.491269  4668 solver.cpp:397]     Test net output #1: loss = 0.416306 (* 1 = 0.416306 loss)
I0630 20:57:03.521273  4668 solver.cpp:218] Iteration 70500 (22.4125 iter/s, 4.46181s/100 iters), loss = 0.124896
I0630 20:57:03.521273  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:57:03.521273  4668 solver.cpp:237]     Train net output #1: loss = 0.124897 (* 1 = 0.124897 loss)
I0630 20:57:03.521273  4668 sgd_solver.cpp:105] Iteration 70500, lr = 1e-06
I0630 20:57:07.135059  4668 solver.cpp:218] Iteration 70600 (27.7118 iter/s, 3.60857s/100 iters), loss = 0.158299
I0630 20:57:07.135059  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:57:07.135059  4668 solver.cpp:237]     Train net output #1: loss = 0.158299 (* 1 = 0.158299 loss)
I0630 20:57:07.135059  4668 sgd_solver.cpp:105] Iteration 70600, lr = 1e-06
I0630 20:57:10.746556  4668 solver.cpp:218] Iteration 70700 (27.7075 iter/s, 3.60912s/100 iters), loss = 0.190228
I0630 20:57:10.746556  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:57:10.746556  4668 solver.cpp:237]     Train net output #1: loss = 0.190228 (* 1 = 0.190228 loss)
I0630 20:57:10.746556  4668 sgd_solver.cpp:105] Iteration 70700, lr = 1e-06
I0630 20:57:14.351845  4668 solver.cpp:218] Iteration 70800 (27.6768 iter/s, 3.61314s/100 iters), loss = 0.119551
I0630 20:57:14.351845  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:57:14.351845  4668 solver.cpp:237]     Train net output #1: loss = 0.119552 (* 1 = 0.119552 loss)
I0630 20:57:14.351845  4668 sgd_solver.cpp:105] Iteration 70800, lr = 1e-06
I0630 20:57:17.963724  4668 solver.cpp:218] Iteration 70900 (27.7293 iter/s, 3.60629s/100 iters), loss = 0.103929
I0630 20:57:17.963724  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:57:17.963724  4668 solver.cpp:237]     Train net output #1: loss = 0.10393 (* 1 = 0.10393 loss)
I0630 20:57:17.963724  4668 sgd_solver.cpp:105] Iteration 70900, lr = 1e-06
I0630 20:57:21.400480 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:57:21.536275  4668 solver.cpp:330] Iteration 71000, Testing net (#0)
I0630 20:57:21.536275  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:57:22.355449  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:57:22.385442  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8766
I0630 20:57:22.385442  4668 solver.cpp:397]     Test net output #1: loss = 0.416015 (* 1 = 0.416015 loss)
I0630 20:57:22.427220  4668 solver.cpp:218] Iteration 71000 (22.4224 iter/s, 4.45983s/100 iters), loss = 0.146051
I0630 20:57:22.427220  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:57:22.427220  4668 solver.cpp:237]     Train net output #1: loss = 0.146051 (* 1 = 0.146051 loss)
I0630 20:57:22.427220  4668 sgd_solver.cpp:105] Iteration 71000, lr = 1e-06
I0630 20:57:26.029604  4668 solver.cpp:218] Iteration 71100 (27.7158 iter/s, 3.60805s/100 iters), loss = 0.188673
I0630 20:57:26.029604  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:57:26.029604  4668 solver.cpp:237]     Train net output #1: loss = 0.188673 (* 1 = 0.188673 loss)
I0630 20:57:26.029604  4668 sgd_solver.cpp:105] Iteration 71100, lr = 1e-06
I0630 20:57:29.642796  4668 solver.cpp:218] Iteration 71200 (27.7192 iter/s, 3.6076s/100 iters), loss = 0.137139
I0630 20:57:29.642796  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:57:29.642796  4668 solver.cpp:237]     Train net output #1: loss = 0.13714 (* 1 = 0.13714 loss)
I0630 20:57:29.642796  4668 sgd_solver.cpp:105] Iteration 71200, lr = 1e-06
I0630 20:57:33.246759  4668 solver.cpp:218] Iteration 71300 (27.723 iter/s, 3.60711s/100 iters), loss = 0.0962332
I0630 20:57:33.246759  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:57:33.246759  4668 solver.cpp:237]     Train net output #1: loss = 0.0962336 (* 1 = 0.0962336 loss)
I0630 20:57:33.246759  4668 sgd_solver.cpp:105] Iteration 71300, lr = 1e-06
I0630 20:57:36.851068  4668 solver.cpp:218] Iteration 71400 (27.735 iter/s, 3.60555s/100 iters), loss = 0.104874
I0630 20:57:36.851068  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 20:57:36.851068  4668 solver.cpp:237]     Train net output #1: loss = 0.104874 (* 1 = 0.104874 loss)
I0630 20:57:36.851068  4668 sgd_solver.cpp:105] Iteration 71400, lr = 1e-06
I0630 20:57:40.288609 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:57:40.422973  4668 solver.cpp:330] Iteration 71500, Testing net (#0)
I0630 20:57:40.422973  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:57:41.244282  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:57:41.274279  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8765
I0630 20:57:41.274279  4668 solver.cpp:397]     Test net output #1: loss = 0.415969 (* 1 = 0.415969 loss)
I0630 20:57:41.315452  4668 solver.cpp:218] Iteration 71500 (22.4299 iter/s, 4.45834s/100 iters), loss = 0.186194
I0630 20:57:41.315452  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:57:41.315452  4668 solver.cpp:237]     Train net output #1: loss = 0.186194 (* 1 = 0.186194 loss)
I0630 20:57:41.315452  4668 sgd_solver.cpp:105] Iteration 71500, lr = 1e-06
I0630 20:57:44.927709  4668 solver.cpp:218] Iteration 71600 (27.6705 iter/s, 3.61396s/100 iters), loss = 0.15077
I0630 20:57:44.927709  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:57:44.927709  4668 solver.cpp:237]     Train net output #1: loss = 0.150771 (* 1 = 0.150771 loss)
I0630 20:57:44.927709  4668 sgd_solver.cpp:105] Iteration 71600, lr = 1e-06
I0630 20:57:48.542470  4668 solver.cpp:218] Iteration 71700 (27.6771 iter/s, 3.6131s/100 iters), loss = 0.204817
I0630 20:57:48.542470  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:57:48.542470  4668 solver.cpp:237]     Train net output #1: loss = 0.204817 (* 1 = 0.204817 loss)
I0630 20:57:48.542470  4668 sgd_solver.cpp:105] Iteration 71700, lr = 1e-06
I0630 20:57:52.152446  4668 solver.cpp:218] Iteration 71800 (27.6922 iter/s, 3.61113s/100 iters), loss = 0.0867529
I0630 20:57:52.152446  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:57:52.152446  4668 solver.cpp:237]     Train net output #1: loss = 0.0867532 (* 1 = 0.0867532 loss)
I0630 20:57:52.152446  4668 sgd_solver.cpp:105] Iteration 71800, lr = 1e-06
I0630 20:57:55.755478  4668 solver.cpp:218] Iteration 71900 (27.7111 iter/s, 3.60866s/100 iters), loss = 0.14921
I0630 20:57:55.755478  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:57:55.755478  4668 solver.cpp:237]     Train net output #1: loss = 0.14921 (* 1 = 0.14921 loss)
I0630 20:57:55.755478  4668 sgd_solver.cpp:105] Iteration 71900, lr = 1e-06
I0630 20:57:59.189652 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:57:59.337870  4668 solver.cpp:330] Iteration 72000, Testing net (#0)
I0630 20:57:59.337870  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:58:00.148300  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:58:00.188302  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8766
I0630 20:58:00.188302  4668 solver.cpp:397]     Test net output #1: loss = 0.416211 (* 1 = 0.416211 loss)
I0630 20:58:00.218312  4668 solver.cpp:218] Iteration 72000 (22.4273 iter/s, 4.45885s/100 iters), loss = 0.124228
I0630 20:58:00.218312  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:58:00.218312  4668 solver.cpp:237]     Train net output #1: loss = 0.124228 (* 1 = 0.124228 loss)
I0630 20:58:00.218312  4668 sgd_solver.cpp:105] Iteration 72000, lr = 1e-06
I0630 20:58:03.830090  4668 solver.cpp:218] Iteration 72100 (27.6881 iter/s, 3.61166s/100 iters), loss = 0.177167
I0630 20:58:03.830090  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:58:03.830090  4668 solver.cpp:237]     Train net output #1: loss = 0.177168 (* 1 = 0.177168 loss)
I0630 20:58:03.830090  4668 sgd_solver.cpp:105] Iteration 72100, lr = 1e-06
I0630 20:58:07.443269  4668 solver.cpp:218] Iteration 72200 (27.6844 iter/s, 3.61215s/100 iters), loss = 0.145273
I0630 20:58:07.443269  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:58:07.443269  4668 solver.cpp:237]     Train net output #1: loss = 0.145273 (* 1 = 0.145273 loss)
I0630 20:58:07.443269  4668 sgd_solver.cpp:105] Iteration 72200, lr = 1e-06
I0630 20:58:11.054157  4668 solver.cpp:218] Iteration 72300 (27.6665 iter/s, 3.61448s/100 iters), loss = 0.131488
I0630 20:58:11.054157  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:58:11.054157  4668 solver.cpp:237]     Train net output #1: loss = 0.131489 (* 1 = 0.131489 loss)
I0630 20:58:11.054157  4668 sgd_solver.cpp:105] Iteration 72300, lr = 1e-06
I0630 20:58:14.665431  4668 solver.cpp:218] Iteration 72400 (27.6864 iter/s, 3.61188s/100 iters), loss = 0.125208
I0630 20:58:14.665431  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:58:14.665431  4668 solver.cpp:237]     Train net output #1: loss = 0.125208 (* 1 = 0.125208 loss)
I0630 20:58:14.665431  4668 sgd_solver.cpp:105] Iteration 72400, lr = 1e-06
I0630 20:58:18.108191 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:58:18.249832  4668 solver.cpp:330] Iteration 72500, Testing net (#0)
I0630 20:58:18.249832  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:58:19.070255  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:58:19.095258  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 20:58:19.095258  4668 solver.cpp:397]     Test net output #1: loss = 0.416106 (* 1 = 0.416106 loss)
I0630 20:58:19.135278  4668 solver.cpp:218] Iteration 72500 (22.4054 iter/s, 4.46322s/100 iters), loss = 0.140492
I0630 20:58:19.135278  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:58:19.135278  4668 solver.cpp:237]     Train net output #1: loss = 0.140492 (* 1 = 0.140492 loss)
I0630 20:58:19.135278  4668 sgd_solver.cpp:105] Iteration 72500, lr = 1e-06
I0630 20:58:22.743937  4668 solver.cpp:218] Iteration 72600 (27.6903 iter/s, 3.61137s/100 iters), loss = 0.160353
I0630 20:58:22.743937  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:58:22.743937  4668 solver.cpp:237]     Train net output #1: loss = 0.160353 (* 1 = 0.160353 loss)
I0630 20:58:22.743937  4668 sgd_solver.cpp:105] Iteration 72600, lr = 1e-06
I0630 20:58:26.359642  4668 solver.cpp:218] Iteration 72700 (27.7047 iter/s, 3.60949s/100 iters), loss = 0.194779
I0630 20:58:26.359642  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:58:26.359642  4668 solver.cpp:237]     Train net output #1: loss = 0.19478 (* 1 = 0.19478 loss)
I0630 20:58:26.359642  4668 sgd_solver.cpp:105] Iteration 72700, lr = 1e-06
I0630 20:58:29.961177  4668 solver.cpp:218] Iteration 72800 (27.7096 iter/s, 3.60885s/100 iters), loss = 0.171325
I0630 20:58:29.961177  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:58:29.961177  4668 solver.cpp:237]     Train net output #1: loss = 0.171325 (* 1 = 0.171325 loss)
I0630 20:58:29.961177  4668 sgd_solver.cpp:105] Iteration 72800, lr = 1e-06
I0630 20:58:33.577612  4668 solver.cpp:218] Iteration 72900 (27.7073 iter/s, 3.60916s/100 iters), loss = 0.135515
I0630 20:58:33.578624  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:58:33.578624  4668 solver.cpp:237]     Train net output #1: loss = 0.135515 (* 1 = 0.135515 loss)
I0630 20:58:33.578624  4668 sgd_solver.cpp:105] Iteration 72900, lr = 1e-06
I0630 20:58:36.996249 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:58:37.137671  4668 solver.cpp:330] Iteration 73000, Testing net (#0)
I0630 20:58:37.137671  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:58:37.966635  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:58:37.996642  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8767
I0630 20:58:37.996642  4668 solver.cpp:397]     Test net output #1: loss = 0.416398 (* 1 = 0.416398 loss)
I0630 20:58:38.026985  4668 solver.cpp:218] Iteration 73000 (22.446 iter/s, 4.45513s/100 iters), loss = 0.146167
I0630 20:58:38.026985  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:58:38.026985  4668 solver.cpp:237]     Train net output #1: loss = 0.146167 (* 1 = 0.146167 loss)
I0630 20:58:38.026985  4668 sgd_solver.cpp:105] Iteration 73000, lr = 1e-06
I0630 20:58:41.638949  4668 solver.cpp:218] Iteration 73100 (27.6733 iter/s, 3.61359s/100 iters), loss = 0.221007
I0630 20:58:41.638949  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:58:41.638949  4668 solver.cpp:237]     Train net output #1: loss = 0.221007 (* 1 = 0.221007 loss)
I0630 20:58:41.638949  4668 sgd_solver.cpp:105] Iteration 73100, lr = 1e-06
I0630 20:58:45.251262  4668 solver.cpp:218] Iteration 73200 (27.6933 iter/s, 3.61098s/100 iters), loss = 0.150814
I0630 20:58:45.251262  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:58:45.251262  4668 solver.cpp:237]     Train net output #1: loss = 0.150814 (* 1 = 0.150814 loss)
I0630 20:58:45.251262  4668 sgd_solver.cpp:105] Iteration 73200, lr = 1e-06
I0630 20:58:48.864130  4668 solver.cpp:218] Iteration 73300 (27.6943 iter/s, 3.61085s/100 iters), loss = 0.146622
I0630 20:58:48.864130  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:58:48.864130  4668 solver.cpp:237]     Train net output #1: loss = 0.146623 (* 1 = 0.146623 loss)
I0630 20:58:48.864130  4668 sgd_solver.cpp:105] Iteration 73300, lr = 1e-06
I0630 20:58:52.476184  4668 solver.cpp:218] Iteration 73400 (27.6906 iter/s, 3.61133s/100 iters), loss = 0.129154
I0630 20:58:52.476184  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:58:52.476184  4668 solver.cpp:237]     Train net output #1: loss = 0.129154 (* 1 = 0.129154 loss)
I0630 20:58:52.476184  4668 sgd_solver.cpp:105] Iteration 73400, lr = 1e-06
I0630 20:58:55.919100 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:58:56.060600  4668 solver.cpp:330] Iteration 73500, Testing net (#0)
I0630 20:58:56.060600  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:58:56.879089  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:58:56.909102  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 20:58:56.909102  4668 solver.cpp:397]     Test net output #1: loss = 0.41635 (* 1 = 0.41635 loss)
I0630 20:58:56.939143  4668 solver.cpp:218] Iteration 73500 (22.3932 iter/s, 4.46563s/100 iters), loss = 0.137895
I0630 20:58:56.939143  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 20:58:56.939143  4668 solver.cpp:237]     Train net output #1: loss = 0.137895 (* 1 = 0.137895 loss)
I0630 20:58:56.939143  4668 sgd_solver.cpp:105] Iteration 73500, lr = 1e-06
I0630 20:59:00.552032  4668 solver.cpp:218] Iteration 73600 (27.6961 iter/s, 3.61062s/100 iters), loss = 0.0974596
I0630 20:59:00.552032  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:59:00.552032  4668 solver.cpp:237]     Train net output #1: loss = 0.0974599 (* 1 = 0.0974599 loss)
I0630 20:59:00.552032  4668 sgd_solver.cpp:105] Iteration 73600, lr = 1e-06
I0630 20:59:04.164976  4668 solver.cpp:218] Iteration 73700 (27.701 iter/s, 3.60997s/100 iters), loss = 0.147148
I0630 20:59:04.164976  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:59:04.164976  4668 solver.cpp:237]     Train net output #1: loss = 0.147148 (* 1 = 0.147148 loss)
I0630 20:59:04.164976  4668 sgd_solver.cpp:105] Iteration 73700, lr = 1e-06
I0630 20:59:07.778502  4668 solver.cpp:218] Iteration 73800 (27.7071 iter/s, 3.60918s/100 iters), loss = 0.16254
I0630 20:59:07.778502  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 20:59:07.778502  4668 solver.cpp:237]     Train net output #1: loss = 0.16254 (* 1 = 0.16254 loss)
I0630 20:59:07.778502  4668 sgd_solver.cpp:105] Iteration 73800, lr = 1e-06
I0630 20:59:11.389623  4668 solver.cpp:218] Iteration 73900 (27.6884 iter/s, 3.61161s/100 iters), loss = 0.11833
I0630 20:59:11.389623  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:59:11.389623  4668 solver.cpp:237]     Train net output #1: loss = 0.11833 (* 1 = 0.11833 loss)
I0630 20:59:11.389623  4668 sgd_solver.cpp:105] Iteration 73900, lr = 1e-06
I0630 20:59:14.823086 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:59:14.962940  4668 solver.cpp:330] Iteration 74000, Testing net (#0)
I0630 20:59:14.962940  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:59:15.779961  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:59:15.809953  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8766
I0630 20:59:15.809953  4668 solver.cpp:397]     Test net output #1: loss = 0.415731 (* 1 = 0.415731 loss)
I0630 20:59:15.843969  4668 solver.cpp:218] Iteration 74000 (22.4239 iter/s, 4.45952s/100 iters), loss = 0.11798
I0630 20:59:15.843969  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 20:59:15.843969  4668 solver.cpp:237]     Train net output #1: loss = 0.11798 (* 1 = 0.11798 loss)
I0630 20:59:15.843969  4668 sgd_solver.cpp:105] Iteration 74000, lr = 1e-06
I0630 20:59:19.455731  4668 solver.cpp:218] Iteration 74100 (27.7023 iter/s, 3.60981s/100 iters), loss = 0.177906
I0630 20:59:19.455731  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:59:19.455731  4668 solver.cpp:237]     Train net output #1: loss = 0.177906 (* 1 = 0.177906 loss)
I0630 20:59:19.455731  4668 sgd_solver.cpp:105] Iteration 74100, lr = 1e-06
I0630 20:59:23.068051  4668 solver.cpp:218] Iteration 74200 (27.7256 iter/s, 3.60678s/100 iters), loss = 0.199584
I0630 20:59:23.068051  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:59:23.068051  4668 solver.cpp:237]     Train net output #1: loss = 0.199585 (* 1 = 0.199585 loss)
I0630 20:59:23.068051  4668 sgd_solver.cpp:105] Iteration 74200, lr = 1e-06
I0630 20:59:26.669456  4668 solver.cpp:218] Iteration 74300 (27.7125 iter/s, 3.60848s/100 iters), loss = 0.135282
I0630 20:59:26.669456  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:59:26.669456  4668 solver.cpp:237]     Train net output #1: loss = 0.135283 (* 1 = 0.135283 loss)
I0630 20:59:26.669456  4668 sgd_solver.cpp:105] Iteration 74300, lr = 1e-06
I0630 20:59:30.283890  4668 solver.cpp:218] Iteration 74400 (27.7243 iter/s, 3.60695s/100 iters), loss = 0.145235
I0630 20:59:30.283890  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:59:30.283890  4668 solver.cpp:237]     Train net output #1: loss = 0.145235 (* 1 = 0.145235 loss)
I0630 20:59:30.283890  4668 sgd_solver.cpp:105] Iteration 74400, lr = 1e-06
I0630 20:59:33.713345 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:59:33.853890  4668 solver.cpp:330] Iteration 74500, Testing net (#0)
I0630 20:59:33.853890  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:59:34.673998  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:59:34.704000  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I0630 20:59:34.704000  4668 solver.cpp:397]     Test net output #1: loss = 0.416174 (* 1 = 0.416174 loss)
I0630 20:59:34.743993  4668 solver.cpp:218] Iteration 74500 (22.4262 iter/s, 4.45908s/100 iters), loss = 0.180926
I0630 20:59:34.743993  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 20:59:34.743993  4668 solver.cpp:237]     Train net output #1: loss = 0.180926 (* 1 = 0.180926 loss)
I0630 20:59:34.743993  4668 sgd_solver.cpp:105] Iteration 74500, lr = 1e-06
I0630 20:59:38.354045  4668 solver.cpp:218] Iteration 74600 (27.6999 iter/s, 3.61013s/100 iters), loss = 0.145211
I0630 20:59:38.354045  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:59:38.354045  4668 solver.cpp:237]     Train net output #1: loss = 0.145211 (* 1 = 0.145211 loss)
I0630 20:59:38.354045  4668 sgd_solver.cpp:105] Iteration 74600, lr = 1e-06
I0630 20:59:41.958632  4668 solver.cpp:218] Iteration 74700 (27.7049 iter/s, 3.60947s/100 iters), loss = 0.222203
I0630 20:59:41.958632  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:59:41.958632  4668 solver.cpp:237]     Train net output #1: loss = 0.222203 (* 1 = 0.222203 loss)
I0630 20:59:41.958632  4668 sgd_solver.cpp:105] Iteration 74700, lr = 1e-06
I0630 20:59:45.571774  4668 solver.cpp:218] Iteration 74800 (27.7083 iter/s, 3.60902s/100 iters), loss = 0.213947
I0630 20:59:45.571774  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 20:59:45.571774  4668 solver.cpp:237]     Train net output #1: loss = 0.213947 (* 1 = 0.213947 loss)
I0630 20:59:45.571774  4668 sgd_solver.cpp:105] Iteration 74800, lr = 1e-06
I0630 20:59:49.184155  4668 solver.cpp:218] Iteration 74900 (27.6939 iter/s, 3.6109s/100 iters), loss = 0.150267
I0630 20:59:49.184155  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:59:49.184155  4668 solver.cpp:237]     Train net output #1: loss = 0.150267 (* 1 = 0.150267 loss)
I0630 20:59:49.184155  4668 sgd_solver.cpp:105] Iteration 74900, lr = 1e-06
I0630 20:59:52.615721 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:59:52.760754  4668 solver.cpp:330] Iteration 75000, Testing net (#0)
I0630 20:59:52.761255  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 20:59:53.581560  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 20:59:53.606919  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I0630 20:59:53.606919  4668 solver.cpp:397]     Test net output #1: loss = 0.416295 (* 1 = 0.416295 loss)
I0630 20:59:53.646919  4668 solver.cpp:218] Iteration 75000 (22.4104 iter/s, 4.46221s/100 iters), loss = 0.129155
I0630 20:59:53.646919  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 20:59:53.646919  4668 solver.cpp:237]     Train net output #1: loss = 0.129155 (* 1 = 0.129155 loss)
I0630 20:59:53.646919  4668 sgd_solver.cpp:105] Iteration 75000, lr = 1e-06
I0630 20:59:57.259944  4668 solver.cpp:218] Iteration 75100 (27.6812 iter/s, 3.61257s/100 iters), loss = 0.17251
I0630 20:59:57.259944  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 20:59:57.259944  4668 solver.cpp:237]     Train net output #1: loss = 0.172511 (* 1 = 0.172511 loss)
I0630 20:59:57.259944  4668 sgd_solver.cpp:105] Iteration 75100, lr = 1e-06
I0630 21:00:00.872179  4668 solver.cpp:218] Iteration 75200 (27.6867 iter/s, 3.61184s/100 iters), loss = 0.207351
I0630 21:00:00.872179  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:00:00.872179  4668 solver.cpp:237]     Train net output #1: loss = 0.207351 (* 1 = 0.207351 loss)
I0630 21:00:00.872179  4668 sgd_solver.cpp:105] Iteration 75200, lr = 1e-06
I0630 21:00:04.475589  4668 solver.cpp:218] Iteration 75300 (27.7161 iter/s, 3.60801s/100 iters), loss = 0.134315
I0630 21:00:04.475589  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:00:04.475589  4668 solver.cpp:237]     Train net output #1: loss = 0.134315 (* 1 = 0.134315 loss)
I0630 21:00:04.475589  4668 sgd_solver.cpp:105] Iteration 75300, lr = 1e-06
I0630 21:00:08.092823  4668 solver.cpp:218] Iteration 75400 (27.683 iter/s, 3.61232s/100 iters), loss = 0.091928
I0630 21:00:08.092823  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 21:00:08.092823  4668 solver.cpp:237]     Train net output #1: loss = 0.0919282 (* 1 = 0.0919282 loss)
I0630 21:00:08.092823  4668 sgd_solver.cpp:105] Iteration 75400, lr = 1e-06
I0630 21:00:11.529458 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:00:11.673391  4668 solver.cpp:330] Iteration 75500, Testing net (#0)
I0630 21:00:11.673890  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 21:00:12.490037  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:00:12.520043  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 21:00:12.520043  4668 solver.cpp:397]     Test net output #1: loss = 0.415726 (* 1 = 0.415726 loss)
I0630 21:00:12.560048  4668 solver.cpp:218] Iteration 75500 (22.3894 iter/s, 4.4664s/100 iters), loss = 0.0912014
I0630 21:00:12.560048  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:00:12.560048  4668 solver.cpp:237]     Train net output #1: loss = 0.0912016 (* 1 = 0.0912016 loss)
I0630 21:00:12.560048  4668 sgd_solver.cpp:105] Iteration 75500, lr = 1e-06
I0630 21:00:16.170439  4668 solver.cpp:218] Iteration 75600 (27.6985 iter/s, 3.61031s/100 iters), loss = 0.157991
I0630 21:00:16.170439  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:00:16.170439  4668 solver.cpp:237]     Train net output #1: loss = 0.157991 (* 1 = 0.157991 loss)
I0630 21:00:16.170439  4668 sgd_solver.cpp:105] Iteration 75600, lr = 1e-06
I0630 21:00:19.777997  4668 solver.cpp:218] Iteration 75700 (27.71 iter/s, 3.60881s/100 iters), loss = 0.140039
I0630 21:00:19.777997  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:00:19.777997  4668 solver.cpp:237]     Train net output #1: loss = 0.140039 (* 1 = 0.140039 loss)
I0630 21:00:19.777997  4668 sgd_solver.cpp:105] Iteration 75700, lr = 1e-06
I0630 21:00:23.376999  4668 solver.cpp:218] Iteration 75800 (27.7347 iter/s, 3.6056s/100 iters), loss = 0.126503
I0630 21:00:23.376999  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 21:00:23.376999  4668 solver.cpp:237]     Train net output #1: loss = 0.126503 (* 1 = 0.126503 loss)
I0630 21:00:23.376999  4668 sgd_solver.cpp:105] Iteration 75800, lr = 1e-06
I0630 21:00:26.990286  4668 solver.cpp:218] Iteration 75900 (27.715 iter/s, 3.60816s/100 iters), loss = 0.10554
I0630 21:00:26.990286  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 21:00:26.990286  4668 solver.cpp:237]     Train net output #1: loss = 0.10554 (* 1 = 0.10554 loss)
I0630 21:00:26.990286  4668 sgd_solver.cpp:105] Iteration 75900, lr = 1e-06
I0630 21:00:30.423887 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:00:30.564045  4668 solver.cpp:330] Iteration 76000, Testing net (#0)
I0630 21:00:30.564045  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 21:00:31.385277  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:00:31.415290  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I0630 21:00:31.415290  4668 solver.cpp:397]     Test net output #1: loss = 0.416521 (* 1 = 0.416521 loss)
I0630 21:00:31.454833  4668 solver.cpp:218] Iteration 76000 (22.4201 iter/s, 4.46028s/100 iters), loss = 0.109177
I0630 21:00:31.454833  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 21:00:31.454833  4668 solver.cpp:237]     Train net output #1: loss = 0.109178 (* 1 = 0.109178 loss)
I0630 21:00:31.454833  4668 sgd_solver.cpp:105] Iteration 76000, lr = 1e-06
I0630 21:00:35.064991  4668 solver.cpp:218] Iteration 76100 (27.6979 iter/s, 3.61038s/100 iters), loss = 0.220189
I0630 21:00:35.064991  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 21:00:35.064991  4668 solver.cpp:237]     Train net output #1: loss = 0.220189 (* 1 = 0.220189 loss)
I0630 21:00:35.064991  4668 sgd_solver.cpp:105] Iteration 76100, lr = 1e-06
I0630 21:00:38.667789  4668 solver.cpp:218] Iteration 76200 (27.7064 iter/s, 3.60928s/100 iters), loss = 0.152247
I0630 21:00:38.667789  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:00:38.667789  4668 solver.cpp:237]     Train net output #1: loss = 0.152248 (* 1 = 0.152248 loss)
I0630 21:00:38.667789  4668 sgd_solver.cpp:105] Iteration 76200, lr = 1e-06
I0630 21:00:42.285884  4668 solver.cpp:218] Iteration 76300 (27.6941 iter/s, 3.61088s/100 iters), loss = 0.115782
I0630 21:00:42.285884  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 21:00:42.285884  4668 solver.cpp:237]     Train net output #1: loss = 0.115783 (* 1 = 0.115783 loss)
I0630 21:00:42.285884  4668 sgd_solver.cpp:105] Iteration 76300, lr = 1e-06
I0630 21:00:45.883785  4668 solver.cpp:218] Iteration 76400 (27.7452 iter/s, 3.60423s/100 iters), loss = 0.171449
I0630 21:00:45.883785  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0630 21:00:45.883785  4668 solver.cpp:237]     Train net output #1: loss = 0.171449 (* 1 = 0.171449 loss)
I0630 21:00:45.883785  4668 sgd_solver.cpp:105] Iteration 76400, lr = 1e-06
I0630 21:00:49.317466 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:00:49.457496  4668 solver.cpp:330] Iteration 76500, Testing net (#0)
I0630 21:00:49.457496  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 21:00:50.281888  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:00:50.311033  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8757
I0630 21:00:50.311033  4668 solver.cpp:397]     Test net output #1: loss = 0.416371 (* 1 = 0.416371 loss)
I0630 21:00:50.341058  4668 solver.cpp:218] Iteration 76500 (22.4422 iter/s, 4.45589s/100 iters), loss = 0.0878004
I0630 21:00:50.341058  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 21:00:50.341058  4668 solver.cpp:237]     Train net output #1: loss = 0.0878006 (* 1 = 0.0878006 loss)
I0630 21:00:50.341058  4668 sgd_solver.cpp:105] Iteration 76500, lr = 1e-06
I0630 21:00:53.950232  4668 solver.cpp:218] Iteration 76600 (27.7062 iter/s, 3.6093s/100 iters), loss = 0.163099
I0630 21:00:53.950232  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:00:53.950232  4668 solver.cpp:237]     Train net output #1: loss = 0.163099 (* 1 = 0.163099 loss)
I0630 21:00:53.950232  4668 sgd_solver.cpp:105] Iteration 76600, lr = 1e-06
I0630 21:00:57.562180  4668 solver.cpp:218] Iteration 76700 (27.6855 iter/s, 3.612s/100 iters), loss = 0.175347
I0630 21:00:57.562180  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:00:57.562180  4668 solver.cpp:237]     Train net output #1: loss = 0.175347 (* 1 = 0.175347 loss)
I0630 21:00:57.562180  4668 sgd_solver.cpp:105] Iteration 76700, lr = 1e-06
I0630 21:01:01.176414  4668 solver.cpp:218] Iteration 76800 (27.6887 iter/s, 3.61158s/100 iters), loss = 0.103935
I0630 21:01:01.176414  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 21:01:01.176414  4668 solver.cpp:237]     Train net output #1: loss = 0.103935 (* 1 = 0.103935 loss)
I0630 21:01:01.176414  4668 sgd_solver.cpp:105] Iteration 76800, lr = 1e-06
I0630 21:01:04.795115  4668 solver.cpp:218] Iteration 76900 (27.6757 iter/s, 3.61327s/100 iters), loss = 0.155513
I0630 21:01:04.795115  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:01:04.795115  4668 solver.cpp:237]     Train net output #1: loss = 0.155513 (* 1 = 0.155513 loss)
I0630 21:01:04.795115  4668 sgd_solver.cpp:105] Iteration 76900, lr = 1e-06
I0630 21:01:08.231710 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:01:08.372110  4668 solver.cpp:330] Iteration 77000, Testing net (#0)
I0630 21:01:08.372110  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 21:01:09.195317  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:01:09.222321  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8765
I0630 21:01:09.222321  4668 solver.cpp:397]     Test net output #1: loss = 0.416457 (* 1 = 0.416457 loss)
I0630 21:01:09.252326  4668 solver.cpp:218] Iteration 77000 (22.3927 iter/s, 4.46574s/100 iters), loss = 0.180495
I0630 21:01:09.252326  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0630 21:01:09.252326  4668 solver.cpp:237]     Train net output #1: loss = 0.180495 (* 1 = 0.180495 loss)
I0630 21:01:09.252326  4668 sgd_solver.cpp:105] Iteration 77000, lr = 1e-06
I0630 21:01:12.868700  4668 solver.cpp:218] Iteration 77100 (27.7037 iter/s, 3.60963s/100 iters), loss = 0.183129
I0630 21:01:12.868700  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:01:12.868700  4668 solver.cpp:237]     Train net output #1: loss = 0.183129 (* 1 = 0.183129 loss)
I0630 21:01:12.868700  4668 sgd_solver.cpp:105] Iteration 77100, lr = 1e-06
I0630 21:01:16.475930  4668 solver.cpp:218] Iteration 77200 (27.7026 iter/s, 3.60977s/100 iters), loss = 0.151785
I0630 21:01:16.475930  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:01:16.475930  4668 solver.cpp:237]     Train net output #1: loss = 0.151785 (* 1 = 0.151785 loss)
I0630 21:01:16.475930  4668 sgd_solver.cpp:105] Iteration 77200, lr = 1e-06
I0630 21:01:20.090039  4668 solver.cpp:218] Iteration 77300 (27.7069 iter/s, 3.60921s/100 iters), loss = 0.0829864
I0630 21:01:20.090039  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 21:01:20.090039  4668 solver.cpp:237]     Train net output #1: loss = 0.0829865 (* 1 = 0.0829865 loss)
I0630 21:01:20.090039  4668 sgd_solver.cpp:105] Iteration 77300, lr = 1e-06
I0630 21:01:23.703138  4668 solver.cpp:218] Iteration 77400 (27.682 iter/s, 3.61246s/100 iters), loss = 0.178449
I0630 21:01:23.703138  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:01:23.703138  4668 solver.cpp:237]     Train net output #1: loss = 0.178449 (* 1 = 0.178449 loss)
I0630 21:01:23.703138  4668 sgd_solver.cpp:105] Iteration 77400, lr = 1e-06
I0630 21:01:27.133867 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:01:27.278646  4668 solver.cpp:330] Iteration 77500, Testing net (#0)
I0630 21:01:27.278646  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 21:01:28.096431  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:01:28.130448  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I0630 21:01:28.130949  4668 solver.cpp:397]     Test net output #1: loss = 0.416176 (* 1 = 0.416176 loss)
I0630 21:01:28.155447  4668 solver.cpp:218] Iteration 77500 (22.415 iter/s, 4.46131s/100 iters), loss = 0.135222
I0630 21:01:28.155447  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 21:01:28.155447  4668 solver.cpp:237]     Train net output #1: loss = 0.135222 (* 1 = 0.135222 loss)
I0630 21:01:28.155447  4668 sgd_solver.cpp:105] Iteration 77500, lr = 1e-06
I0630 21:01:31.770023  4668 solver.cpp:218] Iteration 77600 (27.6788 iter/s, 3.61288s/100 iters), loss = 0.121984
I0630 21:01:31.770023  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:01:31.770023  4668 solver.cpp:237]     Train net output #1: loss = 0.121984 (* 1 = 0.121984 loss)
I0630 21:01:31.770023  4668 sgd_solver.cpp:105] Iteration 77600, lr = 1e-06
I0630 21:01:35.381397  4668 solver.cpp:218] Iteration 77700 (27.728 iter/s, 3.60646s/100 iters), loss = 0.302213
I0630 21:01:35.381397  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0630 21:01:35.381397  4668 solver.cpp:237]     Train net output #1: loss = 0.302213 (* 1 = 0.302213 loss)
I0630 21:01:35.381397  4668 sgd_solver.cpp:105] Iteration 77700, lr = 1e-06
I0630 21:01:38.996434  4668 solver.cpp:218] Iteration 77800 (27.694 iter/s, 3.61089s/100 iters), loss = 0.117436
I0630 21:01:38.996434  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 21:01:38.996434  4668 solver.cpp:237]     Train net output #1: loss = 0.117436 (* 1 = 0.117436 loss)
I0630 21:01:38.996434  4668 sgd_solver.cpp:105] Iteration 77800, lr = 1e-06
I0630 21:01:42.605525  4668 solver.cpp:218] Iteration 77900 (27.6627 iter/s, 3.61498s/100 iters), loss = 0.118572
I0630 21:01:42.605525  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 21:01:42.605525  4668 solver.cpp:237]     Train net output #1: loss = 0.118572 (* 1 = 0.118572 loss)
I0630 21:01:42.605525  4668 sgd_solver.cpp:105] Iteration 77900, lr = 1e-06
I0630 21:01:46.036813 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:01:46.187635  4668 solver.cpp:330] Iteration 78000, Testing net (#0)
I0630 21:01:46.187635  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 21:01:46.998554  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:01:47.038565  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8769
I0630 21:01:47.038565  4668 solver.cpp:397]     Test net output #1: loss = 0.416311 (* 1 = 0.416311 loss)
I0630 21:01:47.068249  4668 solver.cpp:218] Iteration 78000 (22.4122 iter/s, 4.46185s/100 iters), loss = 0.0966957
I0630 21:01:47.068249  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 21:01:47.068249  4668 solver.cpp:237]     Train net output #1: loss = 0.0966958 (* 1 = 0.0966958 loss)
I0630 21:01:47.068249  4668 sgd_solver.cpp:105] Iteration 78000, lr = 1e-06
I0630 21:01:50.679991  4668 solver.cpp:218] Iteration 78100 (27.7073 iter/s, 3.60916s/100 iters), loss = 0.176597
I0630 21:01:50.679991  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:01:50.679991  4668 solver.cpp:237]     Train net output #1: loss = 0.176597 (* 1 = 0.176597 loss)
I0630 21:01:50.679991  4668 sgd_solver.cpp:105] Iteration 78100, lr = 1e-06
I0630 21:01:54.291366  4668 solver.cpp:218] Iteration 78200 (27.7155 iter/s, 3.60809s/100 iters), loss = 0.218898
I0630 21:01:54.291366  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:01:54.291366  4668 solver.cpp:237]     Train net output #1: loss = 0.218898 (* 1 = 0.218898 loss)
I0630 21:01:54.291366  4668 sgd_solver.cpp:105] Iteration 78200, lr = 1e-06
I0630 21:01:57.894208  4668 solver.cpp:218] Iteration 78300 (27.6976 iter/s, 3.61043s/100 iters), loss = 0.114807
I0630 21:01:57.894208  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 21:01:57.894208  4668 solver.cpp:237]     Train net output #1: loss = 0.114808 (* 1 = 0.114808 loss)
I0630 21:01:57.894208  4668 sgd_solver.cpp:105] Iteration 78300, lr = 1e-06
I0630 21:02:01.506283  4668 solver.cpp:218] Iteration 78400 (27.6862 iter/s, 3.61191s/100 iters), loss = 0.168194
I0630 21:02:01.506283  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:02:01.506283  4668 solver.cpp:237]     Train net output #1: loss = 0.168194 (* 1 = 0.168194 loss)
I0630 21:02:01.506283  4668 sgd_solver.cpp:105] Iteration 78400, lr = 1e-06
I0630 21:02:04.948911 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:02:05.091766  4668 solver.cpp:330] Iteration 78500, Testing net (#0)
I0630 21:02:05.091766  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 21:02:05.909323  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:02:05.939321  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I0630 21:02:05.939321  4668 solver.cpp:397]     Test net output #1: loss = 0.415971 (* 1 = 0.415971 loss)
I0630 21:02:05.969323  4668 solver.cpp:218] Iteration 78500 (22.4035 iter/s, 4.46359s/100 iters), loss = 0.110236
I0630 21:02:05.969323  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:02:05.969323  4668 solver.cpp:237]     Train net output #1: loss = 0.110236 (* 1 = 0.110236 loss)
I0630 21:02:05.969323  4668 sgd_solver.cpp:105] Iteration 78500, lr = 1e-06
I0630 21:02:09.589897  4668 solver.cpp:218] Iteration 78600 (27.6949 iter/s, 3.61077s/100 iters), loss = 0.172998
I0630 21:02:09.589897  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:02:09.589897  4668 solver.cpp:237]     Train net output #1: loss = 0.172998 (* 1 = 0.172998 loss)
I0630 21:02:09.589897  4668 sgd_solver.cpp:105] Iteration 78600, lr = 1e-06
I0630 21:02:13.195937  4668 solver.cpp:218] Iteration 78700 (27.7174 iter/s, 3.60785s/100 iters), loss = 0.128206
I0630 21:02:13.195937  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0630 21:02:13.195937  4668 solver.cpp:237]     Train net output #1: loss = 0.128206 (* 1 = 0.128206 loss)
I0630 21:02:13.195937  4668 sgd_solver.cpp:105] Iteration 78700, lr = 1e-06
I0630 21:02:16.797497  4668 solver.cpp:218] Iteration 78800 (27.7291 iter/s, 3.60632s/100 iters), loss = 0.123206
I0630 21:02:16.797497  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:02:16.797497  4668 solver.cpp:237]     Train net output #1: loss = 0.123206 (* 1 = 0.123206 loss)
I0630 21:02:16.797497  4668 sgd_solver.cpp:105] Iteration 78800, lr = 1e-06
I0630 21:02:20.410110  4668 solver.cpp:218] Iteration 78900 (27.7132 iter/s, 3.60839s/100 iters), loss = 0.113813
I0630 21:02:20.410110  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:02:20.410110  4668 solver.cpp:237]     Train net output #1: loss = 0.113814 (* 1 = 0.113814 loss)
I0630 21:02:20.410110  4668 sgd_solver.cpp:105] Iteration 78900, lr = 1e-06
I0630 21:02:23.842658 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:02:23.986577  4668 solver.cpp:330] Iteration 79000, Testing net (#0)
I0630 21:02:23.986577  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 21:02:24.806586  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:02:24.832216  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8768
I0630 21:02:24.832216  4668 solver.cpp:397]     Test net output #1: loss = 0.416225 (* 1 = 0.416225 loss)
I0630 21:02:24.872215  4668 solver.cpp:218] Iteration 79000 (22.4294 iter/s, 4.45843s/100 iters), loss = 0.162564
I0630 21:02:24.872215  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0630 21:02:24.872215  4668 solver.cpp:237]     Train net output #1: loss = 0.162564 (* 1 = 0.162564 loss)
I0630 21:02:24.872215  4668 sgd_solver.cpp:105] Iteration 79000, lr = 1e-06
I0630 21:02:28.474258  4668 solver.cpp:218] Iteration 79100 (27.6918 iter/s, 3.61118s/100 iters), loss = 0.237437
I0630 21:02:28.474258  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:02:28.474258  4668 solver.cpp:237]     Train net output #1: loss = 0.237437 (* 1 = 0.237437 loss)
I0630 21:02:28.474258  4668 sgd_solver.cpp:105] Iteration 79100, lr = 1e-06
I0630 21:02:32.095515  4668 solver.cpp:218] Iteration 79200 (27.6868 iter/s, 3.61182s/100 iters), loss = 0.197019
I0630 21:02:32.095515  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:02:32.095515  4668 solver.cpp:237]     Train net output #1: loss = 0.197019 (* 1 = 0.197019 loss)
I0630 21:02:32.095515  4668 sgd_solver.cpp:105] Iteration 79200, lr = 1e-06
I0630 21:02:35.699272  4668 solver.cpp:218] Iteration 79300 (27.6961 iter/s, 3.61062s/100 iters), loss = 0.0746783
I0630 21:02:35.699272  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 21:02:35.699272  4668 solver.cpp:237]     Train net output #1: loss = 0.0746783 (* 1 = 0.0746783 loss)
I0630 21:02:35.699272  4668 sgd_solver.cpp:105] Iteration 79300, lr = 1e-06
I0630 21:02:39.319561  4668 solver.cpp:218] Iteration 79400 (27.6837 iter/s, 3.61223s/100 iters), loss = 0.100006
I0630 21:02:39.319561  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0630 21:02:39.319561  4668 solver.cpp:237]     Train net output #1: loss = 0.100006 (* 1 = 0.100006 loss)
I0630 21:02:39.319561  4668 sgd_solver.cpp:105] Iteration 79400, lr = 1e-06
I0630 21:02:42.745332 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:02:42.885414  4668 solver.cpp:330] Iteration 79500, Testing net (#0)
I0630 21:02:42.885414  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 21:02:43.706157  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:02:43.736165  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I0630 21:02:43.736165  4668 solver.cpp:397]     Test net output #1: loss = 0.416161 (* 1 = 0.416161 loss)
I0630 21:02:43.776177  4668 solver.cpp:218] Iteration 79500 (22.4298 iter/s, 4.45836s/100 iters), loss = 0.0876392
I0630 21:02:43.776177  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0630 21:02:43.776177  4668 solver.cpp:237]     Train net output #1: loss = 0.0876392 (* 1 = 0.0876392 loss)
I0630 21:02:43.776177  4668 sgd_solver.cpp:105] Iteration 79500, lr = 1e-06
I0630 21:02:47.379567  4668 solver.cpp:218] Iteration 79600 (27.7008 iter/s, 3.61s/100 iters), loss = 0.252813
I0630 21:02:47.379567  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 21:02:47.379567  4668 solver.cpp:237]     Train net output #1: loss = 0.252813 (* 1 = 0.252813 loss)
I0630 21:02:47.379567  4668 sgd_solver.cpp:105] Iteration 79600, lr = 1e-06
I0630 21:02:50.993356  4668 solver.cpp:218] Iteration 79700 (27.6856 iter/s, 3.61199s/100 iters), loss = 0.189846
I0630 21:02:50.993356  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0630 21:02:50.993356  4668 solver.cpp:237]     Train net output #1: loss = 0.189846 (* 1 = 0.189846 loss)
I0630 21:02:50.993356  4668 sgd_solver.cpp:105] Iteration 79700, lr = 1e-06
I0630 21:02:54.606009  4668 solver.cpp:218] Iteration 79800 (27.6861 iter/s, 3.61193s/100 iters), loss = 0.16541
I0630 21:02:54.606009  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:02:54.606009  4668 solver.cpp:237]     Train net output #1: loss = 0.16541 (* 1 = 0.16541 loss)
I0630 21:02:54.606009  4668 sgd_solver.cpp:105] Iteration 79800, lr = 1e-06
I0630 21:02:58.218760  4668 solver.cpp:218] Iteration 79900 (27.6966 iter/s, 3.61055s/100 iters), loss = 0.139378
I0630 21:02:58.218760  4668 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0630 21:02:58.218760  4668 solver.cpp:237]     Train net output #1: loss = 0.139378 (* 1 = 0.139378 loss)
I0630 21:02:58.218760  4668 sgd_solver.cpp:105] Iteration 79900, lr = 1e-06
I0630 21:03:01.658651 16944 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:03:01.802737  4668 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/128K_iter_80000.caffemodel
I0630 21:03:01.812724  4668 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/128K_iter_80000.solverstate
I0630 21:03:01.822737  4668 solver.cpp:310] Iteration 80000, loss = 0.148301
I0630 21:03:01.822737  4668 solver.cpp:330] Iteration 80000, Testing net (#0)
I0630 21:03:01.822737  4668 net.cpp:676] Ignoring source layer accuracy_training
I0630 21:03:02.644980  9172 data_layer.cpp:73] Restarting data prefetching from start.
I0630 21:03:02.668634  4668 solver.cpp:397]     Test net output #0: accuracy = 0.8763
I0630 21:03:02.668634  4668 solver.cpp:397]     Test net output #1: loss = 0.415869 (* 1 = 0.415869 loss)
I0630 21:03:02.668634  4668 solver.cpp:315] Optimization Done.
I0630 21:03:02.668634  4668 caffe.cpp:260] Optimization Done.
G:\Caffe>