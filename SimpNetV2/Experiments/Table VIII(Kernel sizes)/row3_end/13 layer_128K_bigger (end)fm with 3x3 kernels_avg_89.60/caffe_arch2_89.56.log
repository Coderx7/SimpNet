
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0629 10:53:44.338567  2332 caffe.cpp:219] Using GPUs 0
I0629 10:53:44.532941  2332 caffe.cpp:224] GPU 0: GeForce GTX 1080
I0629 10:53:44.869794  2332 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0629 10:53:44.884804  2332 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 80000
snapshot_prefix: "examples/cifar10/128K"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 32000
stepvalue: 48000
stepvalue: 54000
stepvalue: 74000
type: "Nesterov"
I0629 10:53:44.884804  2332 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0629 10:53:44.885805  2332 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0629 10:53:44.885805  2332 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I0629 10:53:44.885805  2332 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0629 10:53:44.885805  2332 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_128K_t2"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 26
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 51
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 51
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 51
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 52
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0629 10:53:44.886806  2332 layer_factory.cpp:58] Creating layer cifar
I0629 10:53:44.891810  2332 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I0629 10:53:44.891810  2332 net.cpp:84] Creating Layer cifar
I0629 10:53:44.891810  2332 net.cpp:380] cifar -> data
I0629 10:53:44.891810  2332 net.cpp:380] cifar -> label
I0629 10:53:44.892809  2332 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0629 10:53:44.892809  2332 data_layer.cpp:45] output data size: 100,3,32,32
I0629 10:53:44.898483  2332 net.cpp:122] Setting up cifar
I0629 10:53:44.898483  2332 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0629 10:53:44.898483  2332 net.cpp:129] Top shape: 100 (100)
I0629 10:53:44.898483  2332 net.cpp:137] Memory required for data: 1229200
I0629 10:53:44.898483  2332 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0629 10:53:44.898483  2332 net.cpp:84] Creating Layer label_cifar_1_split
I0629 10:53:44.898483  2332 net.cpp:406] label_cifar_1_split <- label
I0629 10:53:44.898483  2332 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0629 10:53:44.898483  2332 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0629 10:53:44.898483  2332 net.cpp:122] Setting up label_cifar_1_split
I0629 10:53:44.898483  2332 net.cpp:129] Top shape: 100 (100)
I0629 10:53:44.898483  2332 net.cpp:129] Top shape: 100 (100)
I0629 10:53:44.898483  2332 net.cpp:137] Memory required for data: 1230000
I0629 10:53:44.898483  2332 layer_factory.cpp:58] Creating layer conv1
I0629 10:53:44.898483  2332 net.cpp:84] Creating Layer conv1
I0629 10:53:44.898483  2332 net.cpp:406] conv1 <- data
I0629 10:53:44.898483  2332 net.cpp:380] conv1 -> conv1
I0629 10:53:44.898986  2892 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0629 10:53:45.140465  2332 net.cpp:122] Setting up conv1
I0629 10:53:45.140465  2332 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0629 10:53:45.140465  2332 net.cpp:137] Memory required for data: 9012400
I0629 10:53:45.140465  2332 layer_factory.cpp:58] Creating layer bn1
I0629 10:53:45.140465  2332 net.cpp:84] Creating Layer bn1
I0629 10:53:45.140465  2332 net.cpp:406] bn1 <- conv1
I0629 10:53:45.140465  2332 net.cpp:367] bn1 -> conv1 (in-place)
I0629 10:53:45.140465  2332 net.cpp:122] Setting up bn1
I0629 10:53:45.140465  2332 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0629 10:53:45.140465  2332 net.cpp:137] Memory required for data: 16794800
I0629 10:53:45.140465  2332 layer_factory.cpp:58] Creating layer scale1
I0629 10:53:45.140465  2332 net.cpp:84] Creating Layer scale1
I0629 10:53:45.140465  2332 net.cpp:406] scale1 <- conv1
I0629 10:53:45.140465  2332 net.cpp:367] scale1 -> conv1 (in-place)
I0629 10:53:45.140465  2332 layer_factory.cpp:58] Creating layer scale1
I0629 10:53:45.140465  2332 net.cpp:122] Setting up scale1
I0629 10:53:45.140465  2332 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0629 10:53:45.140465  2332 net.cpp:137] Memory required for data: 24577200
I0629 10:53:45.140465  2332 layer_factory.cpp:58] Creating layer relu1
I0629 10:53:45.140465  2332 net.cpp:84] Creating Layer relu1
I0629 10:53:45.140465  2332 net.cpp:406] relu1 <- conv1
I0629 10:53:45.140465  2332 net.cpp:367] relu1 -> conv1 (in-place)
I0629 10:53:45.140465  2332 net.cpp:122] Setting up relu1
I0629 10:53:45.140465  2332 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0629 10:53:45.140465  2332 net.cpp:137] Memory required for data: 32359600
I0629 10:53:45.140465  2332 layer_factory.cpp:58] Creating layer conv1_0
I0629 10:53:45.140465  2332 net.cpp:84] Creating Layer conv1_0
I0629 10:53:45.140465  2332 net.cpp:406] conv1_0 <- conv1
I0629 10:53:45.141465  2332 net.cpp:380] conv1_0 -> conv1_0
I0629 10:53:45.142467  2332 net.cpp:122] Setting up conv1_0
I0629 10:53:45.142467  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.142467  2332 net.cpp:137] Memory required for data: 42599600
I0629 10:53:45.142467  2332 layer_factory.cpp:58] Creating layer bn1_0
I0629 10:53:45.142467  2332 net.cpp:84] Creating Layer bn1_0
I0629 10:53:45.142467  2332 net.cpp:406] bn1_0 <- conv1_0
I0629 10:53:45.142467  2332 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0629 10:53:45.143467  2332 net.cpp:122] Setting up bn1_0
I0629 10:53:45.143467  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.143467  2332 net.cpp:137] Memory required for data: 52839600
I0629 10:53:45.143467  2332 layer_factory.cpp:58] Creating layer scale1_0
I0629 10:53:45.143467  2332 net.cpp:84] Creating Layer scale1_0
I0629 10:53:45.143467  2332 net.cpp:406] scale1_0 <- conv1_0
I0629 10:53:45.143467  2332 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0629 10:53:45.143467  2332 layer_factory.cpp:58] Creating layer scale1_0
I0629 10:53:45.143467  2332 net.cpp:122] Setting up scale1_0
I0629 10:53:45.143467  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.143467  2332 net.cpp:137] Memory required for data: 63079600
I0629 10:53:45.143467  2332 layer_factory.cpp:58] Creating layer relu1_0
I0629 10:53:45.143467  2332 net.cpp:84] Creating Layer relu1_0
I0629 10:53:45.143467  2332 net.cpp:406] relu1_0 <- conv1_0
I0629 10:53:45.143467  2332 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0629 10:53:45.143467  2332 net.cpp:122] Setting up relu1_0
I0629 10:53:45.143467  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.143467  2332 net.cpp:137] Memory required for data: 73319600
I0629 10:53:45.144469  2332 layer_factory.cpp:58] Creating layer conv2
I0629 10:53:45.144469  2332 net.cpp:84] Creating Layer conv2
I0629 10:53:45.144469  2332 net.cpp:406] conv2 <- conv1_0
I0629 10:53:45.144469  2332 net.cpp:380] conv2 -> conv2
I0629 10:53:45.144469  2332 net.cpp:122] Setting up conv2
I0629 10:53:45.144469  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.144469  2332 net.cpp:137] Memory required for data: 83559600
I0629 10:53:45.144469  2332 layer_factory.cpp:58] Creating layer bn2
I0629 10:53:45.144469  2332 net.cpp:84] Creating Layer bn2
I0629 10:53:45.144469  2332 net.cpp:406] bn2 <- conv2
I0629 10:53:45.144469  2332 net.cpp:367] bn2 -> conv2 (in-place)
I0629 10:53:45.144469  2332 net.cpp:122] Setting up bn2
I0629 10:53:45.144469  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.144469  2332 net.cpp:137] Memory required for data: 93799600
I0629 10:53:45.144469  2332 layer_factory.cpp:58] Creating layer scale2
I0629 10:53:45.144469  2332 net.cpp:84] Creating Layer scale2
I0629 10:53:45.145468  2332 net.cpp:406] scale2 <- conv2
I0629 10:53:45.145468  2332 net.cpp:367] scale2 -> conv2 (in-place)
I0629 10:53:45.145468  2332 layer_factory.cpp:58] Creating layer scale2
I0629 10:53:45.145468  2332 net.cpp:122] Setting up scale2
I0629 10:53:45.145468  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.145468  2332 net.cpp:137] Memory required for data: 104039600
I0629 10:53:45.145468  2332 layer_factory.cpp:58] Creating layer relu2
I0629 10:53:45.145468  2332 net.cpp:84] Creating Layer relu2
I0629 10:53:45.145468  2332 net.cpp:406] relu2 <- conv2
I0629 10:53:45.145468  2332 net.cpp:367] relu2 -> conv2 (in-place)
I0629 10:53:45.145468  2332 net.cpp:122] Setting up relu2
I0629 10:53:45.145468  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.145468  2332 net.cpp:137] Memory required for data: 114279600
I0629 10:53:45.145468  2332 layer_factory.cpp:58] Creating layer conv2_1
I0629 10:53:45.145468  2332 net.cpp:84] Creating Layer conv2_1
I0629 10:53:45.145468  2332 net.cpp:406] conv2_1 <- conv2
I0629 10:53:45.145468  2332 net.cpp:380] conv2_1 -> conv2_1
I0629 10:53:45.146469  2332 net.cpp:122] Setting up conv2_1
I0629 10:53:45.146469  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.146469  2332 net.cpp:137] Memory required for data: 124519600
I0629 10:53:45.146469  2332 layer_factory.cpp:58] Creating layer bn2_1
I0629 10:53:45.146469  2332 net.cpp:84] Creating Layer bn2_1
I0629 10:53:45.146469  2332 net.cpp:406] bn2_1 <- conv2_1
I0629 10:53:45.146469  2332 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0629 10:53:45.146469  2332 net.cpp:122] Setting up bn2_1
I0629 10:53:45.146469  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.146469  2332 net.cpp:137] Memory required for data: 134759600
I0629 10:53:45.146469  2332 layer_factory.cpp:58] Creating layer scale2_1
I0629 10:53:45.146469  2332 net.cpp:84] Creating Layer scale2_1
I0629 10:53:45.146469  2332 net.cpp:406] scale2_1 <- conv2_1
I0629 10:53:45.146469  2332 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0629 10:53:45.146469  2332 layer_factory.cpp:58] Creating layer scale2_1
I0629 10:53:45.147469  2332 net.cpp:122] Setting up scale2_1
I0629 10:53:45.147469  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.147469  2332 net.cpp:137] Memory required for data: 144999600
I0629 10:53:45.147469  2332 layer_factory.cpp:58] Creating layer relu2_1
I0629 10:53:45.147469  2332 net.cpp:84] Creating Layer relu2_1
I0629 10:53:45.147469  2332 net.cpp:406] relu2_1 <- conv2_1
I0629 10:53:45.147469  2332 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0629 10:53:45.147469  2332 net.cpp:122] Setting up relu2_1
I0629 10:53:45.147469  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.147469  2332 net.cpp:137] Memory required for data: 155239600
I0629 10:53:45.147469  2332 layer_factory.cpp:58] Creating layer conv2_2
I0629 10:53:45.147469  2332 net.cpp:84] Creating Layer conv2_2
I0629 10:53:45.147469  2332 net.cpp:406] conv2_2 <- conv2_1
I0629 10:53:45.147469  2332 net.cpp:380] conv2_2 -> conv2_2
I0629 10:53:45.148469  2332 net.cpp:122] Setting up conv2_2
I0629 10:53:45.148469  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.148469  2332 net.cpp:137] Memory required for data: 165479600
I0629 10:53:45.148469  2332 layer_factory.cpp:58] Creating layer bn2_2
I0629 10:53:45.148469  2332 net.cpp:84] Creating Layer bn2_2
I0629 10:53:45.148469  2332 net.cpp:406] bn2_2 <- conv2_2
I0629 10:53:45.148469  2332 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0629 10:53:45.148469  2332 net.cpp:122] Setting up bn2_2
I0629 10:53:45.148469  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.148469  2332 net.cpp:137] Memory required for data: 175719600
I0629 10:53:45.148469  2332 layer_factory.cpp:58] Creating layer scale2_2
I0629 10:53:45.148469  2332 net.cpp:84] Creating Layer scale2_2
I0629 10:53:45.148469  2332 net.cpp:406] scale2_2 <- conv2_2
I0629 10:53:45.148469  2332 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0629 10:53:45.148469  2332 layer_factory.cpp:58] Creating layer scale2_2
I0629 10:53:45.148469  2332 net.cpp:122] Setting up scale2_2
I0629 10:53:45.148469  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.148469  2332 net.cpp:137] Memory required for data: 185959600
I0629 10:53:45.148469  2332 layer_factory.cpp:58] Creating layer relu2_2
I0629 10:53:45.148469  2332 net.cpp:84] Creating Layer relu2_2
I0629 10:53:45.148469  2332 net.cpp:406] relu2_2 <- conv2_2
I0629 10:53:45.148469  2332 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0629 10:53:45.149488  2332 net.cpp:122] Setting up relu2_2
I0629 10:53:45.149488  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.149488  2332 net.cpp:137] Memory required for data: 196199600
I0629 10:53:45.149488  2332 layer_factory.cpp:58] Creating layer pool2_1
I0629 10:53:45.149488  2332 net.cpp:84] Creating Layer pool2_1
I0629 10:53:45.149488  2332 net.cpp:406] pool2_1 <- conv2_2
I0629 10:53:45.149488  2332 net.cpp:380] pool2_1 -> pool2_1
I0629 10:53:45.149488  2332 net.cpp:122] Setting up pool2_1
I0629 10:53:45.149488  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.149488  2332 net.cpp:137] Memory required for data: 198759600
I0629 10:53:45.149488  2332 layer_factory.cpp:58] Creating layer conv3
I0629 10:53:45.149488  2332 net.cpp:84] Creating Layer conv3
I0629 10:53:45.149488  2332 net.cpp:406] conv3 <- pool2_1
I0629 10:53:45.149488  2332 net.cpp:380] conv3 -> conv3
I0629 10:53:45.150488  2332 net.cpp:122] Setting up conv3
I0629 10:53:45.150488  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.150488  2332 net.cpp:137] Memory required for data: 201319600
I0629 10:53:45.150488  2332 layer_factory.cpp:58] Creating layer bn3
I0629 10:53:45.150488  2332 net.cpp:84] Creating Layer bn3
I0629 10:53:45.150488  2332 net.cpp:406] bn3 <- conv3
I0629 10:53:45.150488  2332 net.cpp:367] bn3 -> conv3 (in-place)
I0629 10:53:45.150488  2332 net.cpp:122] Setting up bn3
I0629 10:53:45.150488  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.150488  2332 net.cpp:137] Memory required for data: 203879600
I0629 10:53:45.150488  2332 layer_factory.cpp:58] Creating layer scale3
I0629 10:53:45.150488  2332 net.cpp:84] Creating Layer scale3
I0629 10:53:45.150488  2332 net.cpp:406] scale3 <- conv3
I0629 10:53:45.150488  2332 net.cpp:367] scale3 -> conv3 (in-place)
I0629 10:53:45.150488  2332 layer_factory.cpp:58] Creating layer scale3
I0629 10:53:45.150488  2332 net.cpp:122] Setting up scale3
I0629 10:53:45.150488  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.150488  2332 net.cpp:137] Memory required for data: 206439600
I0629 10:53:45.150488  2332 layer_factory.cpp:58] Creating layer relu3
I0629 10:53:45.150488  2332 net.cpp:84] Creating Layer relu3
I0629 10:53:45.150488  2332 net.cpp:406] relu3 <- conv3
I0629 10:53:45.150488  2332 net.cpp:367] relu3 -> conv3 (in-place)
I0629 10:53:45.150488  2332 net.cpp:122] Setting up relu3
I0629 10:53:45.150488  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.150488  2332 net.cpp:137] Memory required for data: 208999600
I0629 10:53:45.150488  2332 layer_factory.cpp:58] Creating layer conv3_1
I0629 10:53:45.151489  2332 net.cpp:84] Creating Layer conv3_1
I0629 10:53:45.151489  2332 net.cpp:406] conv3_1 <- conv3
I0629 10:53:45.151489  2332 net.cpp:380] conv3_1 -> conv3_1
I0629 10:53:45.152473  2332 net.cpp:122] Setting up conv3_1
I0629 10:53:45.152473  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.152473  2332 net.cpp:137] Memory required for data: 211559600
I0629 10:53:45.152473  2332 layer_factory.cpp:58] Creating layer bn3_1
I0629 10:53:45.152473  2332 net.cpp:84] Creating Layer bn3_1
I0629 10:53:45.152473  2332 net.cpp:406] bn3_1 <- conv3_1
I0629 10:53:45.152473  2332 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I0629 10:53:45.152473  2332 net.cpp:122] Setting up bn3_1
I0629 10:53:45.152473  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.152473  2332 net.cpp:137] Memory required for data: 214119600
I0629 10:53:45.152473  2332 layer_factory.cpp:58] Creating layer scale3_1
I0629 10:53:45.152473  2332 net.cpp:84] Creating Layer scale3_1
I0629 10:53:45.152473  2332 net.cpp:406] scale3_1 <- conv3_1
I0629 10:53:45.152473  2332 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I0629 10:53:45.152473  2332 layer_factory.cpp:58] Creating layer scale3_1
I0629 10:53:45.152473  2332 net.cpp:122] Setting up scale3_1
I0629 10:53:45.152473  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.152473  2332 net.cpp:137] Memory required for data: 216679600
I0629 10:53:45.152473  2332 layer_factory.cpp:58] Creating layer relu3_1
I0629 10:53:45.152473  2332 net.cpp:84] Creating Layer relu3_1
I0629 10:53:45.152473  2332 net.cpp:406] relu3_1 <- conv3_1
I0629 10:53:45.152473  2332 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0629 10:53:45.152473  2332 net.cpp:122] Setting up relu3_1
I0629 10:53:45.152473  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.152473  2332 net.cpp:137] Memory required for data: 219239600
I0629 10:53:45.152473  2332 layer_factory.cpp:58] Creating layer conv4
I0629 10:53:45.152473  2332 net.cpp:84] Creating Layer conv4
I0629 10:53:45.152473  2332 net.cpp:406] conv4 <- conv3_1
I0629 10:53:45.152473  2332 net.cpp:380] conv4 -> conv4
I0629 10:53:45.153491  2332 net.cpp:122] Setting up conv4
I0629 10:53:45.153491  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.153491  2332 net.cpp:137] Memory required for data: 221799600
I0629 10:53:45.153491  2332 layer_factory.cpp:58] Creating layer bn4
I0629 10:53:45.153491  2332 net.cpp:84] Creating Layer bn4
I0629 10:53:45.153491  2332 net.cpp:406] bn4 <- conv4
I0629 10:53:45.153491  2332 net.cpp:367] bn4 -> conv4 (in-place)
I0629 10:53:45.154491  2332 net.cpp:122] Setting up bn4
I0629 10:53:45.154491  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.154491  2332 net.cpp:137] Memory required for data: 224359600
I0629 10:53:45.154491  2332 layer_factory.cpp:58] Creating layer scale4
I0629 10:53:45.154491  2332 net.cpp:84] Creating Layer scale4
I0629 10:53:45.154491  2332 net.cpp:406] scale4 <- conv4
I0629 10:53:45.154491  2332 net.cpp:367] scale4 -> conv4 (in-place)
I0629 10:53:45.154491  2332 layer_factory.cpp:58] Creating layer scale4
I0629 10:53:45.154491  2332 net.cpp:122] Setting up scale4
I0629 10:53:45.154491  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.154491  2332 net.cpp:137] Memory required for data: 226919600
I0629 10:53:45.154491  2332 layer_factory.cpp:58] Creating layer relu4
I0629 10:53:45.154491  2332 net.cpp:84] Creating Layer relu4
I0629 10:53:45.154491  2332 net.cpp:406] relu4 <- conv4
I0629 10:53:45.154491  2332 net.cpp:367] relu4 -> conv4 (in-place)
I0629 10:53:45.154491  2332 net.cpp:122] Setting up relu4
I0629 10:53:45.154491  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.154491  2332 net.cpp:137] Memory required for data: 229479600
I0629 10:53:45.154491  2332 layer_factory.cpp:58] Creating layer conv4_1
I0629 10:53:45.154491  2332 net.cpp:84] Creating Layer conv4_1
I0629 10:53:45.154491  2332 net.cpp:406] conv4_1 <- conv4
I0629 10:53:45.154491  2332 net.cpp:380] conv4_1 -> conv4_1
I0629 10:53:45.155493  2332 net.cpp:122] Setting up conv4_1
I0629 10:53:45.155493  2332 net.cpp:129] Top shape: 100 26 16 16 (665600)
I0629 10:53:45.155493  2332 net.cpp:137] Memory required for data: 232142000
I0629 10:53:45.155493  2332 layer_factory.cpp:58] Creating layer bn4_1
I0629 10:53:45.155493  2332 net.cpp:84] Creating Layer bn4_1
I0629 10:53:45.155493  2332 net.cpp:406] bn4_1 <- conv4_1
I0629 10:53:45.155493  2332 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0629 10:53:45.155493  2332 net.cpp:122] Setting up bn4_1
I0629 10:53:45.155493  2332 net.cpp:129] Top shape: 100 26 16 16 (665600)
I0629 10:53:45.155493  2332 net.cpp:137] Memory required for data: 234804400
I0629 10:53:45.155493  2332 layer_factory.cpp:58] Creating layer scale4_1
I0629 10:53:45.155493  2332 net.cpp:84] Creating Layer scale4_1
I0629 10:53:45.155493  2332 net.cpp:406] scale4_1 <- conv4_1
I0629 10:53:45.155493  2332 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0629 10:53:45.155493  2332 layer_factory.cpp:58] Creating layer scale4_1
I0629 10:53:45.156493  2332 net.cpp:122] Setting up scale4_1
I0629 10:53:45.156493  2332 net.cpp:129] Top shape: 100 26 16 16 (665600)
I0629 10:53:45.156493  2332 net.cpp:137] Memory required for data: 237466800
I0629 10:53:45.156493  2332 layer_factory.cpp:58] Creating layer relu4_1
I0629 10:53:45.156493  2332 net.cpp:84] Creating Layer relu4_1
I0629 10:53:45.156493  2332 net.cpp:406] relu4_1 <- conv4_1
I0629 10:53:45.156493  2332 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0629 10:53:45.156493  2332 net.cpp:122] Setting up relu4_1
I0629 10:53:45.156493  2332 net.cpp:129] Top shape: 100 26 16 16 (665600)
I0629 10:53:45.156493  2332 net.cpp:137] Memory required for data: 240129200
I0629 10:53:45.156493  2332 layer_factory.cpp:58] Creating layer conv4_2
I0629 10:53:45.156493  2332 net.cpp:84] Creating Layer conv4_2
I0629 10:53:45.156493  2332 net.cpp:406] conv4_2 <- conv4_1
I0629 10:53:45.156493  2332 net.cpp:380] conv4_2 -> conv4_2
I0629 10:53:45.157493  2332 net.cpp:122] Setting up conv4_2
I0629 10:53:45.157493  2332 net.cpp:129] Top shape: 100 51 16 16 (1305600)
I0629 10:53:45.157493  2332 net.cpp:137] Memory required for data: 245351600
I0629 10:53:45.157493  2332 layer_factory.cpp:58] Creating layer bn4_2
I0629 10:53:45.157493  2332 net.cpp:84] Creating Layer bn4_2
I0629 10:53:45.157493  2332 net.cpp:406] bn4_2 <- conv4_2
I0629 10:53:45.157493  2332 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0629 10:53:45.158494  2332 net.cpp:122] Setting up bn4_2
I0629 10:53:45.158494  2332 net.cpp:129] Top shape: 100 51 16 16 (1305600)
I0629 10:53:45.158494  2332 net.cpp:137] Memory required for data: 250574000
I0629 10:53:45.158494  2332 layer_factory.cpp:58] Creating layer scale4_2
I0629 10:53:45.158494  2332 net.cpp:84] Creating Layer scale4_2
I0629 10:53:45.158494  2332 net.cpp:406] scale4_2 <- conv4_2
I0629 10:53:45.158494  2332 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0629 10:53:45.158494  2332 layer_factory.cpp:58] Creating layer scale4_2
I0629 10:53:45.158494  2332 net.cpp:122] Setting up scale4_2
I0629 10:53:45.158494  2332 net.cpp:129] Top shape: 100 51 16 16 (1305600)
I0629 10:53:45.158494  2332 net.cpp:137] Memory required for data: 255796400
I0629 10:53:45.158494  2332 layer_factory.cpp:58] Creating layer relu4_2
I0629 10:53:45.158494  2332 net.cpp:84] Creating Layer relu4_2
I0629 10:53:45.158494  2332 net.cpp:406] relu4_2 <- conv4_2
I0629 10:53:45.158494  2332 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0629 10:53:45.158494  2332 net.cpp:122] Setting up relu4_2
I0629 10:53:45.158494  2332 net.cpp:129] Top shape: 100 51 16 16 (1305600)
I0629 10:53:45.158494  2332 net.cpp:137] Memory required for data: 261018800
I0629 10:53:45.158494  2332 layer_factory.cpp:58] Creating layer pool4_2
I0629 10:53:45.158494  2332 net.cpp:84] Creating Layer pool4_2
I0629 10:53:45.158494  2332 net.cpp:406] pool4_2 <- conv4_2
I0629 10:53:45.158494  2332 net.cpp:380] pool4_2 -> pool4_2
I0629 10:53:45.159479  2332 net.cpp:122] Setting up pool4_2
I0629 10:53:45.159479  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.159479  2332 net.cpp:137] Memory required for data: 262324400
I0629 10:53:45.159479  2332 layer_factory.cpp:58] Creating layer conv4_0
I0629 10:53:45.159479  2332 net.cpp:84] Creating Layer conv4_0
I0629 10:53:45.159479  2332 net.cpp:406] conv4_0 <- pool4_2
I0629 10:53:45.159479  2332 net.cpp:380] conv4_0 -> conv4_0
I0629 10:53:45.161481  2332 net.cpp:122] Setting up conv4_0
I0629 10:53:45.161481  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.161481  2332 net.cpp:137] Memory required for data: 263630000
I0629 10:53:45.161481  2332 layer_factory.cpp:58] Creating layer bn4_0
I0629 10:53:45.161481  2332 net.cpp:84] Creating Layer bn4_0
I0629 10:53:45.161481  2332 net.cpp:406] bn4_0 <- conv4_0
I0629 10:53:45.161481  2332 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0629 10:53:45.161481  2332 net.cpp:122] Setting up bn4_0
I0629 10:53:45.161481  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.161481  2332 net.cpp:137] Memory required for data: 264935600
I0629 10:53:45.161481  2332 layer_factory.cpp:58] Creating layer scale4_0
I0629 10:53:45.161481  2332 net.cpp:84] Creating Layer scale4_0
I0629 10:53:45.161481  2332 net.cpp:406] scale4_0 <- conv4_0
I0629 10:53:45.161481  2332 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0629 10:53:45.161481  2332 layer_factory.cpp:58] Creating layer scale4_0
I0629 10:53:45.161481  2332 net.cpp:122] Setting up scale4_0
I0629 10:53:45.161481  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.161481  2332 net.cpp:137] Memory required for data: 266241200
I0629 10:53:45.161481  2332 layer_factory.cpp:58] Creating layer relu4_0
I0629 10:53:45.161481  2332 net.cpp:84] Creating Layer relu4_0
I0629 10:53:45.161481  2332 net.cpp:406] relu4_0 <- conv4_0
I0629 10:53:45.161481  2332 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0629 10:53:45.161481  2332 net.cpp:122] Setting up relu4_0
I0629 10:53:45.161481  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.161481  2332 net.cpp:137] Memory required for data: 267546800
I0629 10:53:45.161481  2332 layer_factory.cpp:58] Creating layer conv11
I0629 10:53:45.161481  2332 net.cpp:84] Creating Layer conv11
I0629 10:53:45.161481  2332 net.cpp:406] conv11 <- conv4_0
I0629 10:53:45.161481  2332 net.cpp:380] conv11 -> conv11
I0629 10:53:45.163496  2332 net.cpp:122] Setting up conv11
I0629 10:53:45.163496  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.163496  2332 net.cpp:137] Memory required for data: 268852400
I0629 10:53:45.163496  2332 layer_factory.cpp:58] Creating layer bn_conv11
I0629 10:53:45.163496  2332 net.cpp:84] Creating Layer bn_conv11
I0629 10:53:45.163496  2332 net.cpp:406] bn_conv11 <- conv11
I0629 10:53:45.163496  2332 net.cpp:367] bn_conv11 -> conv11 (in-place)
I0629 10:53:45.163496  2332 net.cpp:122] Setting up bn_conv11
I0629 10:53:45.163496  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.163496  2332 net.cpp:137] Memory required for data: 270158000
I0629 10:53:45.163496  2332 layer_factory.cpp:58] Creating layer scale_conv11
I0629 10:53:45.163496  2332 net.cpp:84] Creating Layer scale_conv11
I0629 10:53:45.163496  2332 net.cpp:406] scale_conv11 <- conv11
I0629 10:53:45.163496  2332 net.cpp:367] scale_conv11 -> conv11 (in-place)
I0629 10:53:45.163496  2332 layer_factory.cpp:58] Creating layer scale_conv11
I0629 10:53:45.163496  2332 net.cpp:122] Setting up scale_conv11
I0629 10:53:45.163496  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.163496  2332 net.cpp:137] Memory required for data: 271463600
I0629 10:53:45.163496  2332 layer_factory.cpp:58] Creating layer relu_conv11
I0629 10:53:45.163496  2332 net.cpp:84] Creating Layer relu_conv11
I0629 10:53:45.163496  2332 net.cpp:406] relu_conv11 <- conv11
I0629 10:53:45.163496  2332 net.cpp:367] relu_conv11 -> conv11 (in-place)
I0629 10:53:45.163496  2332 net.cpp:122] Setting up relu_conv11
I0629 10:53:45.163496  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.163496  2332 net.cpp:137] Memory required for data: 272769200
I0629 10:53:45.163496  2332 layer_factory.cpp:58] Creating layer conv12
I0629 10:53:45.163496  2332 net.cpp:84] Creating Layer conv12
I0629 10:53:45.163496  2332 net.cpp:406] conv12 <- conv11
I0629 10:53:45.163496  2332 net.cpp:380] conv12 -> conv12
I0629 10:53:45.166482  2332 net.cpp:122] Setting up conv12
I0629 10:53:45.166482  2332 net.cpp:129] Top shape: 100 52 8 8 (332800)
I0629 10:53:45.166482  2332 net.cpp:137] Memory required for data: 274100400
I0629 10:53:45.166482  2332 layer_factory.cpp:58] Creating layer bn_conv12
I0629 10:53:45.166482  2332 net.cpp:84] Creating Layer bn_conv12
I0629 10:53:45.166482  2332 net.cpp:406] bn_conv12 <- conv12
I0629 10:53:45.166482  2332 net.cpp:367] bn_conv12 -> conv12 (in-place)
I0629 10:53:45.166482  2332 net.cpp:122] Setting up bn_conv12
I0629 10:53:45.166482  2332 net.cpp:129] Top shape: 100 52 8 8 (332800)
I0629 10:53:45.166482  2332 net.cpp:137] Memory required for data: 275431600
I0629 10:53:45.166482  2332 layer_factory.cpp:58] Creating layer scale_conv12
I0629 10:53:45.166482  2332 net.cpp:84] Creating Layer scale_conv12
I0629 10:53:45.166482  2332 net.cpp:406] scale_conv12 <- conv12
I0629 10:53:45.166482  2332 net.cpp:367] scale_conv12 -> conv12 (in-place)
I0629 10:53:45.166482  2332 layer_factory.cpp:58] Creating layer scale_conv12
I0629 10:53:45.167485  2332 net.cpp:122] Setting up scale_conv12
I0629 10:53:45.167485  2332 net.cpp:129] Top shape: 100 52 8 8 (332800)
I0629 10:53:45.167485  2332 net.cpp:137] Memory required for data: 276762800
I0629 10:53:45.167485  2332 layer_factory.cpp:58] Creating layer relu_conv12
I0629 10:53:45.167485  2332 net.cpp:84] Creating Layer relu_conv12
I0629 10:53:45.167485  2332 net.cpp:406] relu_conv12 <- conv12
I0629 10:53:45.167485  2332 net.cpp:367] relu_conv12 -> conv12 (in-place)
I0629 10:53:45.167485  2332 net.cpp:122] Setting up relu_conv12
I0629 10:53:45.167485  2332 net.cpp:129] Top shape: 100 52 8 8 (332800)
I0629 10:53:45.167485  2332 net.cpp:137] Memory required for data: 278094000
I0629 10:53:45.167485  2332 layer_factory.cpp:58] Creating layer poolcp6
I0629 10:53:45.167485  2332 net.cpp:84] Creating Layer poolcp6
I0629 10:53:45.167485  2332 net.cpp:406] poolcp6 <- conv12
I0629 10:53:45.167485  2332 net.cpp:380] poolcp6 -> poolcp6
I0629 10:53:45.167485  2332 net.cpp:122] Setting up poolcp6
I0629 10:53:45.167485  2332 net.cpp:129] Top shape: 100 52 1 1 (5200)
I0629 10:53:45.167485  2332 net.cpp:137] Memory required for data: 278114800
I0629 10:53:45.167485  2332 layer_factory.cpp:58] Creating layer ip1
I0629 10:53:45.167485  2332 net.cpp:84] Creating Layer ip1
I0629 10:53:45.167485  2332 net.cpp:406] ip1 <- poolcp6
I0629 10:53:45.167485  2332 net.cpp:380] ip1 -> ip1
I0629 10:53:45.168483  2332 net.cpp:122] Setting up ip1
I0629 10:53:45.168483  2332 net.cpp:129] Top shape: 100 10 (1000)
I0629 10:53:45.168483  2332 net.cpp:137] Memory required for data: 278118800
I0629 10:53:45.168483  2332 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0629 10:53:45.168483  2332 net.cpp:84] Creating Layer ip1_ip1_0_split
I0629 10:53:45.168483  2332 net.cpp:406] ip1_ip1_0_split <- ip1
I0629 10:53:45.168483  2332 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0629 10:53:45.168483  2332 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0629 10:53:45.168483  2332 net.cpp:122] Setting up ip1_ip1_0_split
I0629 10:53:45.168483  2332 net.cpp:129] Top shape: 100 10 (1000)
I0629 10:53:45.168483  2332 net.cpp:129] Top shape: 100 10 (1000)
I0629 10:53:45.168483  2332 net.cpp:137] Memory required for data: 278126800
I0629 10:53:45.168483  2332 layer_factory.cpp:58] Creating layer accuracy_training
I0629 10:53:45.168483  2332 net.cpp:84] Creating Layer accuracy_training
I0629 10:53:45.168483  2332 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0629 10:53:45.168483  2332 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I0629 10:53:45.168483  2332 net.cpp:380] accuracy_training -> accuracy_training
I0629 10:53:45.168483  2332 net.cpp:122] Setting up accuracy_training
I0629 10:53:45.168483  2332 net.cpp:129] Top shape: (1)
I0629 10:53:45.168483  2332 net.cpp:137] Memory required for data: 278126804
I0629 10:53:45.168483  2332 layer_factory.cpp:58] Creating layer loss
I0629 10:53:45.168483  2332 net.cpp:84] Creating Layer loss
I0629 10:53:45.168483  2332 net.cpp:406] loss <- ip1_ip1_0_split_1
I0629 10:53:45.168483  2332 net.cpp:406] loss <- label_cifar_1_split_1
I0629 10:53:45.168483  2332 net.cpp:380] loss -> loss
I0629 10:53:45.168483  2332 layer_factory.cpp:58] Creating layer loss
I0629 10:53:45.169486  2332 net.cpp:122] Setting up loss
I0629 10:53:45.169486  2332 net.cpp:129] Top shape: (1)
I0629 10:53:45.169486  2332 net.cpp:132]     with loss weight 1
I0629 10:53:45.169486  2332 net.cpp:137] Memory required for data: 278126808
I0629 10:53:45.169486  2332 net.cpp:198] loss needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:200] accuracy_training does not need backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] ip1 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] poolcp6 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] relu_conv12 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] scale_conv12 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] bn_conv12 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] conv12 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] relu_conv11 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] scale_conv11 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] bn_conv11 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] conv11 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] relu4_0 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] scale4_0 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] bn4_0 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] conv4_0 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] pool4_2 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] relu4_2 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] scale4_2 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] bn4_2 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] conv4_2 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] relu4_1 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] scale4_1 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] bn4_1 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] conv4_1 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] relu4 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] scale4 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] bn4 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] conv4 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] relu3_1 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] scale3_1 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] bn3_1 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] conv3_1 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] relu3 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] scale3 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] bn3 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] conv3 needs backward computation.
I0629 10:53:45.169486  2332 net.cpp:198] pool2_1 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] relu2_2 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] scale2_2 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] bn2_2 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] conv2_2 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] relu2_1 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] scale2_1 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] bn2_1 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] conv2_1 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] relu2 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] scale2 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] bn2 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] conv2 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] relu1_0 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] scale1_0 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] bn1_0 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] conv1_0 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] relu1 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] scale1 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] bn1 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:198] conv1 needs backward computation.
I0629 10:53:45.170487  2332 net.cpp:200] label_cifar_1_split does not need backward computation.
I0629 10:53:45.170487  2332 net.cpp:200] cifar does not need backward computation.
I0629 10:53:45.170487  2332 net.cpp:242] This network produces output accuracy_training
I0629 10:53:45.170487  2332 net.cpp:242] This network produces output loss
I0629 10:53:45.170487  2332 net.cpp:255] Network initialization done.
I0629 10:53:45.171489  2332 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0629 10:53:45.171489  2332 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0629 10:53:45.171489  2332 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I0629 10:53:45.171489  2332 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0629 10:53:45.171489  2332 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_128K_t2"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 26
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 51
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 51
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 51
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 52
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0629 10:53:45.172504  2332 layer_factory.cpp:58] Creating layer cifar
I0629 10:53:45.174494  2332 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I0629 10:53:45.175508  2332 net.cpp:84] Creating Layer cifar
I0629 10:53:45.175508  2332 net.cpp:380] cifar -> data
I0629 10:53:45.175508  2332 net.cpp:380] cifar -> label
I0629 10:53:45.175508  2332 data_layer.cpp:45] output data size: 100,3,32,32
I0629 10:53:45.180493  2332 net.cpp:122] Setting up cifar
I0629 10:53:45.181494  2332 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0629 10:53:45.181494  2332 net.cpp:129] Top shape: 100 (100)
I0629 10:53:45.181494  2332 net.cpp:137] Memory required for data: 1229200
I0629 10:53:45.181494  2332 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0629 10:53:45.181494  2332 net.cpp:84] Creating Layer label_cifar_1_split
I0629 10:53:45.181494  2332 net.cpp:406] label_cifar_1_split <- label
I0629 10:53:45.181494  2332 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0629 10:53:45.181494  2332 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0629 10:53:45.181494  2332 net.cpp:122] Setting up label_cifar_1_split
I0629 10:53:45.181494  2332 net.cpp:129] Top shape: 100 (100)
I0629 10:53:45.181494  2332 net.cpp:129] Top shape: 100 (100)
I0629 10:53:45.181494  2332 net.cpp:137] Memory required for data: 1230000
I0629 10:53:45.181494  2332 layer_factory.cpp:58] Creating layer conv1
I0629 10:53:45.181494  2332 net.cpp:84] Creating Layer conv1
I0629 10:53:45.181494  2332 net.cpp:406] conv1 <- data
I0629 10:53:45.181494  2332 net.cpp:380] conv1 -> conv1
I0629 10:53:45.182495  8116 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0629 10:53:45.182495  2332 net.cpp:122] Setting up conv1
I0629 10:53:45.182495  2332 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0629 10:53:45.182495  2332 net.cpp:137] Memory required for data: 9012400
I0629 10:53:45.182495  2332 layer_factory.cpp:58] Creating layer bn1
I0629 10:53:45.182495  2332 net.cpp:84] Creating Layer bn1
I0629 10:53:45.182495  2332 net.cpp:406] bn1 <- conv1
I0629 10:53:45.182495  2332 net.cpp:367] bn1 -> conv1 (in-place)
I0629 10:53:45.182495  2332 net.cpp:122] Setting up bn1
I0629 10:53:45.182495  2332 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0629 10:53:45.182495  2332 net.cpp:137] Memory required for data: 16794800
I0629 10:53:45.182495  2332 layer_factory.cpp:58] Creating layer scale1
I0629 10:53:45.182495  2332 net.cpp:84] Creating Layer scale1
I0629 10:53:45.182495  2332 net.cpp:406] scale1 <- conv1
I0629 10:53:45.182495  2332 net.cpp:367] scale1 -> conv1 (in-place)
I0629 10:53:45.182495  2332 layer_factory.cpp:58] Creating layer scale1
I0629 10:53:45.183511  2332 net.cpp:122] Setting up scale1
I0629 10:53:45.183511  2332 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0629 10:53:45.183511  2332 net.cpp:137] Memory required for data: 24577200
I0629 10:53:45.183511  2332 layer_factory.cpp:58] Creating layer relu1
I0629 10:53:45.183511  2332 net.cpp:84] Creating Layer relu1
I0629 10:53:45.183511  2332 net.cpp:406] relu1 <- conv1
I0629 10:53:45.183511  2332 net.cpp:367] relu1 -> conv1 (in-place)
I0629 10:53:45.183511  2332 net.cpp:122] Setting up relu1
I0629 10:53:45.183511  2332 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0629 10:53:45.183511  2332 net.cpp:137] Memory required for data: 32359600
I0629 10:53:45.183511  2332 layer_factory.cpp:58] Creating layer conv1_0
I0629 10:53:45.183511  2332 net.cpp:84] Creating Layer conv1_0
I0629 10:53:45.183511  2332 net.cpp:406] conv1_0 <- conv1
I0629 10:53:45.183511  2332 net.cpp:380] conv1_0 -> conv1_0
I0629 10:53:45.184495  2332 net.cpp:122] Setting up conv1_0
I0629 10:53:45.184495  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.184495  2332 net.cpp:137] Memory required for data: 42599600
I0629 10:53:45.184495  2332 layer_factory.cpp:58] Creating layer bn1_0
I0629 10:53:45.184495  2332 net.cpp:84] Creating Layer bn1_0
I0629 10:53:45.184495  2332 net.cpp:406] bn1_0 <- conv1_0
I0629 10:53:45.184495  2332 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0629 10:53:45.184495  2332 net.cpp:122] Setting up bn1_0
I0629 10:53:45.184495  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.184495  2332 net.cpp:137] Memory required for data: 52839600
I0629 10:53:45.184495  2332 layer_factory.cpp:58] Creating layer scale1_0
I0629 10:53:45.184495  2332 net.cpp:84] Creating Layer scale1_0
I0629 10:53:45.184495  2332 net.cpp:406] scale1_0 <- conv1_0
I0629 10:53:45.184495  2332 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0629 10:53:45.184495  2332 layer_factory.cpp:58] Creating layer scale1_0
I0629 10:53:45.184495  2332 net.cpp:122] Setting up scale1_0
I0629 10:53:45.184495  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.184495  2332 net.cpp:137] Memory required for data: 63079600
I0629 10:53:45.184495  2332 layer_factory.cpp:58] Creating layer relu1_0
I0629 10:53:45.184495  2332 net.cpp:84] Creating Layer relu1_0
I0629 10:53:45.184495  2332 net.cpp:406] relu1_0 <- conv1_0
I0629 10:53:45.184495  2332 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0629 10:53:45.185513  2332 net.cpp:122] Setting up relu1_0
I0629 10:53:45.185513  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.185513  2332 net.cpp:137] Memory required for data: 73319600
I0629 10:53:45.185513  2332 layer_factory.cpp:58] Creating layer conv2
I0629 10:53:45.185513  2332 net.cpp:84] Creating Layer conv2
I0629 10:53:45.185513  2332 net.cpp:406] conv2 <- conv1_0
I0629 10:53:45.185513  2332 net.cpp:380] conv2 -> conv2
I0629 10:53:45.186498  2332 net.cpp:122] Setting up conv2
I0629 10:53:45.186498  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.186498  2332 net.cpp:137] Memory required for data: 83559600
I0629 10:53:45.186498  2332 layer_factory.cpp:58] Creating layer bn2
I0629 10:53:45.186498  2332 net.cpp:84] Creating Layer bn2
I0629 10:53:45.186498  2332 net.cpp:406] bn2 <- conv2
I0629 10:53:45.186498  2332 net.cpp:367] bn2 -> conv2 (in-place)
I0629 10:53:45.187515  2332 net.cpp:122] Setting up bn2
I0629 10:53:45.187515  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.187515  2332 net.cpp:137] Memory required for data: 93799600
I0629 10:53:45.187515  2332 layer_factory.cpp:58] Creating layer scale2
I0629 10:53:45.187515  2332 net.cpp:84] Creating Layer scale2
I0629 10:53:45.187515  2332 net.cpp:406] scale2 <- conv2
I0629 10:53:45.187515  2332 net.cpp:367] scale2 -> conv2 (in-place)
I0629 10:53:45.187515  2332 layer_factory.cpp:58] Creating layer scale2
I0629 10:53:45.187515  2332 net.cpp:122] Setting up scale2
I0629 10:53:45.187515  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.187515  2332 net.cpp:137] Memory required for data: 104039600
I0629 10:53:45.187515  2332 layer_factory.cpp:58] Creating layer relu2
I0629 10:53:45.187515  2332 net.cpp:84] Creating Layer relu2
I0629 10:53:45.187515  2332 net.cpp:406] relu2 <- conv2
I0629 10:53:45.187515  2332 net.cpp:367] relu2 -> conv2 (in-place)
I0629 10:53:45.187515  2332 net.cpp:122] Setting up relu2
I0629 10:53:45.187515  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.187515  2332 net.cpp:137] Memory required for data: 114279600
I0629 10:53:45.187515  2332 layer_factory.cpp:58] Creating layer conv2_1
I0629 10:53:45.187515  2332 net.cpp:84] Creating Layer conv2_1
I0629 10:53:45.187515  2332 net.cpp:406] conv2_1 <- conv2
I0629 10:53:45.187515  2332 net.cpp:380] conv2_1 -> conv2_1
I0629 10:53:45.188498  2332 net.cpp:122] Setting up conv2_1
I0629 10:53:45.188498  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.188498  2332 net.cpp:137] Memory required for data: 124519600
I0629 10:53:45.188498  2332 layer_factory.cpp:58] Creating layer bn2_1
I0629 10:53:45.188498  2332 net.cpp:84] Creating Layer bn2_1
I0629 10:53:45.188498  2332 net.cpp:406] bn2_1 <- conv2_1
I0629 10:53:45.188498  2332 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0629 10:53:45.188498  2332 net.cpp:122] Setting up bn2_1
I0629 10:53:45.188498  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.188498  2332 net.cpp:137] Memory required for data: 134759600
I0629 10:53:45.188498  2332 layer_factory.cpp:58] Creating layer scale2_1
I0629 10:53:45.188498  2332 net.cpp:84] Creating Layer scale2_1
I0629 10:53:45.188498  2332 net.cpp:406] scale2_1 <- conv2_1
I0629 10:53:45.188498  2332 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0629 10:53:45.188498  2332 layer_factory.cpp:58] Creating layer scale2_1
I0629 10:53:45.189517  2332 net.cpp:122] Setting up scale2_1
I0629 10:53:45.189517  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.189517  2332 net.cpp:137] Memory required for data: 144999600
I0629 10:53:45.189517  2332 layer_factory.cpp:58] Creating layer relu2_1
I0629 10:53:45.189517  2332 net.cpp:84] Creating Layer relu2_1
I0629 10:53:45.189517  2332 net.cpp:406] relu2_1 <- conv2_1
I0629 10:53:45.189517  2332 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0629 10:53:45.189517  2332 net.cpp:122] Setting up relu2_1
I0629 10:53:45.189517  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.189517  2332 net.cpp:137] Memory required for data: 155239600
I0629 10:53:45.189517  2332 layer_factory.cpp:58] Creating layer conv2_2
I0629 10:53:45.189517  2332 net.cpp:84] Creating Layer conv2_2
I0629 10:53:45.189517  2332 net.cpp:406] conv2_2 <- conv2_1
I0629 10:53:45.189517  2332 net.cpp:380] conv2_2 -> conv2_2
I0629 10:53:45.190517  2332 net.cpp:122] Setting up conv2_2
I0629 10:53:45.190517  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.190517  2332 net.cpp:137] Memory required for data: 165479600
I0629 10:53:45.190517  2332 layer_factory.cpp:58] Creating layer bn2_2
I0629 10:53:45.190517  2332 net.cpp:84] Creating Layer bn2_2
I0629 10:53:45.190517  2332 net.cpp:406] bn2_2 <- conv2_2
I0629 10:53:45.190517  2332 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0629 10:53:45.190517  2332 net.cpp:122] Setting up bn2_2
I0629 10:53:45.190517  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.190517  2332 net.cpp:137] Memory required for data: 175719600
I0629 10:53:45.190517  2332 layer_factory.cpp:58] Creating layer scale2_2
I0629 10:53:45.190517  2332 net.cpp:84] Creating Layer scale2_2
I0629 10:53:45.190517  2332 net.cpp:406] scale2_2 <- conv2_2
I0629 10:53:45.190517  2332 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0629 10:53:45.190517  2332 layer_factory.cpp:58] Creating layer scale2_2
I0629 10:53:45.190517  2332 net.cpp:122] Setting up scale2_2
I0629 10:53:45.190517  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.190517  2332 net.cpp:137] Memory required for data: 185959600
I0629 10:53:45.190517  2332 layer_factory.cpp:58] Creating layer relu2_2
I0629 10:53:45.190517  2332 net.cpp:84] Creating Layer relu2_2
I0629 10:53:45.190517  2332 net.cpp:406] relu2_2 <- conv2_2
I0629 10:53:45.190517  2332 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0629 10:53:45.191517  2332 net.cpp:122] Setting up relu2_2
I0629 10:53:45.191517  2332 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0629 10:53:45.191517  2332 net.cpp:137] Memory required for data: 196199600
I0629 10:53:45.191517  2332 layer_factory.cpp:58] Creating layer pool2_1
I0629 10:53:45.191517  2332 net.cpp:84] Creating Layer pool2_1
I0629 10:53:45.191517  2332 net.cpp:406] pool2_1 <- conv2_2
I0629 10:53:45.191517  2332 net.cpp:380] pool2_1 -> pool2_1
I0629 10:53:45.191517  2332 net.cpp:122] Setting up pool2_1
I0629 10:53:45.191517  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.191517  2332 net.cpp:137] Memory required for data: 198759600
I0629 10:53:45.191517  2332 layer_factory.cpp:58] Creating layer conv3
I0629 10:53:45.191517  2332 net.cpp:84] Creating Layer conv3
I0629 10:53:45.191517  2332 net.cpp:406] conv3 <- pool2_1
I0629 10:53:45.191517  2332 net.cpp:380] conv3 -> conv3
I0629 10:53:45.192502  2332 net.cpp:122] Setting up conv3
I0629 10:53:45.192502  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.192502  2332 net.cpp:137] Memory required for data: 201319600
I0629 10:53:45.192502  2332 layer_factory.cpp:58] Creating layer bn3
I0629 10:53:45.192502  2332 net.cpp:84] Creating Layer bn3
I0629 10:53:45.192502  2332 net.cpp:406] bn3 <- conv3
I0629 10:53:45.192502  2332 net.cpp:367] bn3 -> conv3 (in-place)
I0629 10:53:45.193519  2332 net.cpp:122] Setting up bn3
I0629 10:53:45.193519  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.193519  2332 net.cpp:137] Memory required for data: 203879600
I0629 10:53:45.193519  2332 layer_factory.cpp:58] Creating layer scale3
I0629 10:53:45.193519  2332 net.cpp:84] Creating Layer scale3
I0629 10:53:45.193519  2332 net.cpp:406] scale3 <- conv3
I0629 10:53:45.193519  2332 net.cpp:367] scale3 -> conv3 (in-place)
I0629 10:53:45.193519  2332 layer_factory.cpp:58] Creating layer scale3
I0629 10:53:45.193519  2332 net.cpp:122] Setting up scale3
I0629 10:53:45.193519  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.193519  2332 net.cpp:137] Memory required for data: 206439600
I0629 10:53:45.193519  2332 layer_factory.cpp:58] Creating layer relu3
I0629 10:53:45.193519  2332 net.cpp:84] Creating Layer relu3
I0629 10:53:45.193519  2332 net.cpp:406] relu3 <- conv3
I0629 10:53:45.193519  2332 net.cpp:367] relu3 -> conv3 (in-place)
I0629 10:53:45.193519  2332 net.cpp:122] Setting up relu3
I0629 10:53:45.193519  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.193519  2332 net.cpp:137] Memory required for data: 208999600
I0629 10:53:45.193519  2332 layer_factory.cpp:58] Creating layer conv3_1
I0629 10:53:45.193519  2332 net.cpp:84] Creating Layer conv3_1
I0629 10:53:45.193519  2332 net.cpp:406] conv3_1 <- conv3
I0629 10:53:45.193519  2332 net.cpp:380] conv3_1 -> conv3_1
I0629 10:53:45.195541  2332 net.cpp:122] Setting up conv3_1
I0629 10:53:45.195541  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.195541  2332 net.cpp:137] Memory required for data: 211559600
I0629 10:53:45.195541  2332 layer_factory.cpp:58] Creating layer bn3_1
I0629 10:53:45.195541  2332 net.cpp:84] Creating Layer bn3_1
I0629 10:53:45.195541  2332 net.cpp:406] bn3_1 <- conv3_1
I0629 10:53:45.195541  2332 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I0629 10:53:45.196041  2332 net.cpp:122] Setting up bn3_1
I0629 10:53:45.196041  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.196041  2332 net.cpp:137] Memory required for data: 214119600
I0629 10:53:45.196041  2332 layer_factory.cpp:58] Creating layer scale3_1
I0629 10:53:45.196041  2332 net.cpp:84] Creating Layer scale3_1
I0629 10:53:45.196041  2332 net.cpp:406] scale3_1 <- conv3_1
I0629 10:53:45.196041  2332 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I0629 10:53:45.196041  2332 layer_factory.cpp:58] Creating layer scale3_1
I0629 10:53:45.196041  2332 net.cpp:122] Setting up scale3_1
I0629 10:53:45.196041  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.196041  2332 net.cpp:137] Memory required for data: 216679600
I0629 10:53:45.196041  2332 layer_factory.cpp:58] Creating layer relu3_1
I0629 10:53:45.196041  2332 net.cpp:84] Creating Layer relu3_1
I0629 10:53:45.196041  2332 net.cpp:406] relu3_1 <- conv3_1
I0629 10:53:45.196041  2332 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0629 10:53:45.196526  2332 net.cpp:122] Setting up relu3_1
I0629 10:53:45.196526  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.196526  2332 net.cpp:137] Memory required for data: 219239600
I0629 10:53:45.196526  2332 layer_factory.cpp:58] Creating layer conv4
I0629 10:53:45.196526  2332 net.cpp:84] Creating Layer conv4
I0629 10:53:45.196526  2332 net.cpp:406] conv4 <- conv3_1
I0629 10:53:45.196526  2332 net.cpp:380] conv4 -> conv4
I0629 10:53:45.197535  2332 net.cpp:122] Setting up conv4
I0629 10:53:45.197535  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.197535  2332 net.cpp:137] Memory required for data: 221799600
I0629 10:53:45.197535  2332 layer_factory.cpp:58] Creating layer bn4
I0629 10:53:45.197535  2332 net.cpp:84] Creating Layer bn4
I0629 10:53:45.197535  2332 net.cpp:406] bn4 <- conv4
I0629 10:53:45.197535  2332 net.cpp:367] bn4 -> conv4 (in-place)
I0629 10:53:45.198037  2332 net.cpp:122] Setting up bn4
I0629 10:53:45.198037  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.198037  2332 net.cpp:137] Memory required for data: 224359600
I0629 10:53:45.198037  2332 layer_factory.cpp:58] Creating layer scale4
I0629 10:53:45.198037  2332 net.cpp:84] Creating Layer scale4
I0629 10:53:45.198037  2332 net.cpp:406] scale4 <- conv4
I0629 10:53:45.198037  2332 net.cpp:367] scale4 -> conv4 (in-place)
I0629 10:53:45.198037  2332 layer_factory.cpp:58] Creating layer scale4
I0629 10:53:45.198037  2332 net.cpp:122] Setting up scale4
I0629 10:53:45.198037  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.198037  2332 net.cpp:137] Memory required for data: 226919600
I0629 10:53:45.198037  2332 layer_factory.cpp:58] Creating layer relu4
I0629 10:53:45.198037  2332 net.cpp:84] Creating Layer relu4
I0629 10:53:45.198037  2332 net.cpp:406] relu4 <- conv4
I0629 10:53:45.198037  2332 net.cpp:367] relu4 -> conv4 (in-place)
I0629 10:53:45.198037  2332 net.cpp:122] Setting up relu4
I0629 10:53:45.198537  2332 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0629 10:53:45.198537  2332 net.cpp:137] Memory required for data: 229479600
I0629 10:53:45.198537  2332 layer_factory.cpp:58] Creating layer conv4_1
I0629 10:53:45.198537  2332 net.cpp:84] Creating Layer conv4_1
I0629 10:53:45.198537  2332 net.cpp:406] conv4_1 <- conv4
I0629 10:53:45.198537  2332 net.cpp:380] conv4_1 -> conv4_1
I0629 10:53:45.199220  2332 net.cpp:122] Setting up conv4_1
I0629 10:53:45.199220  2332 net.cpp:129] Top shape: 100 26 16 16 (665600)
I0629 10:53:45.199220  2332 net.cpp:137] Memory required for data: 232142000
I0629 10:53:45.199220  2332 layer_factory.cpp:58] Creating layer bn4_1
I0629 10:53:45.199220  2332 net.cpp:84] Creating Layer bn4_1
I0629 10:53:45.199220  2332 net.cpp:406] bn4_1 <- conv4_1
I0629 10:53:45.199220  2332 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0629 10:53:45.199723  2332 net.cpp:122] Setting up bn4_1
I0629 10:53:45.199723  2332 net.cpp:129] Top shape: 100 26 16 16 (665600)
I0629 10:53:45.199723  2332 net.cpp:137] Memory required for data: 234804400
I0629 10:53:45.199723  2332 layer_factory.cpp:58] Creating layer scale4_1
I0629 10:53:45.199723  2332 net.cpp:84] Creating Layer scale4_1
I0629 10:53:45.199723  2332 net.cpp:406] scale4_1 <- conv4_1
I0629 10:53:45.199723  2332 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0629 10:53:45.199723  2332 layer_factory.cpp:58] Creating layer scale4_1
I0629 10:53:45.199723  2332 net.cpp:122] Setting up scale4_1
I0629 10:53:45.199723  2332 net.cpp:129] Top shape: 100 26 16 16 (665600)
I0629 10:53:45.199723  2332 net.cpp:137] Memory required for data: 237466800
I0629 10:53:45.199723  2332 layer_factory.cpp:58] Creating layer relu4_1
I0629 10:53:45.199723  2332 net.cpp:84] Creating Layer relu4_1
I0629 10:53:45.199723  2332 net.cpp:406] relu4_1 <- conv4_1
I0629 10:53:45.199723  2332 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0629 10:53:45.200222  2332 net.cpp:122] Setting up relu4_1
I0629 10:53:45.200222  2332 net.cpp:129] Top shape: 100 26 16 16 (665600)
I0629 10:53:45.200222  2332 net.cpp:137] Memory required for data: 240129200
I0629 10:53:45.200222  2332 layer_factory.cpp:58] Creating layer conv4_2
I0629 10:53:45.200222  2332 net.cpp:84] Creating Layer conv4_2
I0629 10:53:45.200222  2332 net.cpp:406] conv4_2 <- conv4_1
I0629 10:53:45.200222  2332 net.cpp:380] conv4_2 -> conv4_2
I0629 10:53:45.200915  2332 net.cpp:122] Setting up conv4_2
I0629 10:53:45.200915  2332 net.cpp:129] Top shape: 100 51 16 16 (1305600)
I0629 10:53:45.200915  2332 net.cpp:137] Memory required for data: 245351600
I0629 10:53:45.200915  2332 layer_factory.cpp:58] Creating layer bn4_2
I0629 10:53:45.200915  2332 net.cpp:84] Creating Layer bn4_2
I0629 10:53:45.201417  2332 net.cpp:406] bn4_2 <- conv4_2
I0629 10:53:45.201417  2332 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0629 10:53:45.201417  2332 net.cpp:122] Setting up bn4_2
I0629 10:53:45.201417  2332 net.cpp:129] Top shape: 100 51 16 16 (1305600)
I0629 10:53:45.201417  2332 net.cpp:137] Memory required for data: 250574000
I0629 10:53:45.201417  2332 layer_factory.cpp:58] Creating layer scale4_2
I0629 10:53:45.201417  2332 net.cpp:84] Creating Layer scale4_2
I0629 10:53:45.201417  2332 net.cpp:406] scale4_2 <- conv4_2
I0629 10:53:45.201417  2332 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0629 10:53:45.201417  2332 layer_factory.cpp:58] Creating layer scale4_2
I0629 10:53:45.201417  2332 net.cpp:122] Setting up scale4_2
I0629 10:53:45.201417  2332 net.cpp:129] Top shape: 100 51 16 16 (1305600)
I0629 10:53:45.201417  2332 net.cpp:137] Memory required for data: 255796400
I0629 10:53:45.201417  2332 layer_factory.cpp:58] Creating layer relu4_2
I0629 10:53:45.201417  2332 net.cpp:84] Creating Layer relu4_2
I0629 10:53:45.201417  2332 net.cpp:406] relu4_2 <- conv4_2
I0629 10:53:45.201417  2332 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0629 10:53:45.201917  2332 net.cpp:122] Setting up relu4_2
I0629 10:53:45.201917  2332 net.cpp:129] Top shape: 100 51 16 16 (1305600)
I0629 10:53:45.201917  2332 net.cpp:137] Memory required for data: 261018800
I0629 10:53:45.201917  2332 layer_factory.cpp:58] Creating layer pool4_2
I0629 10:53:45.201917  2332 net.cpp:84] Creating Layer pool4_2
I0629 10:53:45.201917  2332 net.cpp:406] pool4_2 <- conv4_2
I0629 10:53:45.201917  2332 net.cpp:380] pool4_2 -> pool4_2
I0629 10:53:45.201917  2332 net.cpp:122] Setting up pool4_2
I0629 10:53:45.201917  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.201917  2332 net.cpp:137] Memory required for data: 262324400
I0629 10:53:45.201917  2332 layer_factory.cpp:58] Creating layer conv4_0
I0629 10:53:45.201917  2332 net.cpp:84] Creating Layer conv4_0
I0629 10:53:45.201917  2332 net.cpp:406] conv4_0 <- pool4_2
I0629 10:53:45.201917  2332 net.cpp:380] conv4_0 -> conv4_0
I0629 10:53:45.202919  2332 net.cpp:122] Setting up conv4_0
I0629 10:53:45.202919  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.202919  2332 net.cpp:137] Memory required for data: 263630000
I0629 10:53:45.202919  2332 layer_factory.cpp:58] Creating layer bn4_0
I0629 10:53:45.202919  2332 net.cpp:84] Creating Layer bn4_0
I0629 10:53:45.202919  2332 net.cpp:406] bn4_0 <- conv4_0
I0629 10:53:45.202919  2332 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0629 10:53:45.203418  2332 net.cpp:122] Setting up bn4_0
I0629 10:53:45.203418  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.203418  2332 net.cpp:137] Memory required for data: 264935600
I0629 10:53:45.203418  2332 layer_factory.cpp:58] Creating layer scale4_0
I0629 10:53:45.203418  2332 net.cpp:84] Creating Layer scale4_0
I0629 10:53:45.203418  2332 net.cpp:406] scale4_0 <- conv4_0
I0629 10:53:45.203418  2332 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0629 10:53:45.203418  2332 layer_factory.cpp:58] Creating layer scale4_0
I0629 10:53:45.203418  2332 net.cpp:122] Setting up scale4_0
I0629 10:53:45.203418  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.203418  2332 net.cpp:137] Memory required for data: 266241200
I0629 10:53:45.203418  2332 layer_factory.cpp:58] Creating layer relu4_0
I0629 10:53:45.203418  2332 net.cpp:84] Creating Layer relu4_0
I0629 10:53:45.203418  2332 net.cpp:406] relu4_0 <- conv4_0
I0629 10:53:45.203418  2332 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0629 10:53:45.204056  2332 net.cpp:122] Setting up relu4_0
I0629 10:53:45.204056  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.204056  2332 net.cpp:137] Memory required for data: 267546800
I0629 10:53:45.204056  2332 layer_factory.cpp:58] Creating layer conv11
I0629 10:53:45.204056  2332 net.cpp:84] Creating Layer conv11
I0629 10:53:45.204056  2332 net.cpp:406] conv11 <- conv4_0
I0629 10:53:45.204056  2332 net.cpp:380] conv11 -> conv11
I0629 10:53:45.204557  2332 net.cpp:122] Setting up conv11
I0629 10:53:45.204557  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.204557  2332 net.cpp:137] Memory required for data: 268852400
I0629 10:53:45.204557  2332 layer_factory.cpp:58] Creating layer bn_conv11
I0629 10:53:45.205057  2332 net.cpp:84] Creating Layer bn_conv11
I0629 10:53:45.205057  2332 net.cpp:406] bn_conv11 <- conv11
I0629 10:53:45.205057  2332 net.cpp:367] bn_conv11 -> conv11 (in-place)
I0629 10:53:45.205057  2332 net.cpp:122] Setting up bn_conv11
I0629 10:53:45.205057  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.205057  2332 net.cpp:137] Memory required for data: 270158000
I0629 10:53:45.205057  2332 layer_factory.cpp:58] Creating layer scale_conv11
I0629 10:53:45.205057  2332 net.cpp:84] Creating Layer scale_conv11
I0629 10:53:45.205057  2332 net.cpp:406] scale_conv11 <- conv11
I0629 10:53:45.205057  2332 net.cpp:367] scale_conv11 -> conv11 (in-place)
I0629 10:53:45.205057  2332 layer_factory.cpp:58] Creating layer scale_conv11
I0629 10:53:45.205057  2332 net.cpp:122] Setting up scale_conv11
I0629 10:53:45.205057  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.205057  2332 net.cpp:137] Memory required for data: 271463600
I0629 10:53:45.205057  2332 layer_factory.cpp:58] Creating layer relu_conv11
I0629 10:53:45.205057  2332 net.cpp:84] Creating Layer relu_conv11
I0629 10:53:45.205057  2332 net.cpp:406] relu_conv11 <- conv11
I0629 10:53:45.205057  2332 net.cpp:367] relu_conv11 -> conv11 (in-place)
I0629 10:53:45.205557  2332 net.cpp:122] Setting up relu_conv11
I0629 10:53:45.205557  2332 net.cpp:129] Top shape: 100 51 8 8 (326400)
I0629 10:53:45.205557  2332 net.cpp:137] Memory required for data: 272769200
I0629 10:53:45.205557  2332 layer_factory.cpp:58] Creating layer conv12
I0629 10:53:45.205557  2332 net.cpp:84] Creating Layer conv12
I0629 10:53:45.205557  2332 net.cpp:406] conv12 <- conv11
I0629 10:53:45.205557  2332 net.cpp:380] conv12 -> conv12
I0629 10:53:45.207059  2332 net.cpp:122] Setting up conv12
I0629 10:53:45.207059  2332 net.cpp:129] Top shape: 100 52 8 8 (332800)
I0629 10:53:45.207059  2332 net.cpp:137] Memory required for data: 274100400
I0629 10:53:45.207059  2332 layer_factory.cpp:58] Creating layer bn_conv12
I0629 10:53:45.207059  2332 net.cpp:84] Creating Layer bn_conv12
I0629 10:53:45.207059  2332 net.cpp:406] bn_conv12 <- conv12
I0629 10:53:45.207059  2332 net.cpp:367] bn_conv12 -> conv12 (in-place)
I0629 10:53:45.207059  2332 net.cpp:122] Setting up bn_conv12
I0629 10:53:45.207059  2332 net.cpp:129] Top shape: 100 52 8 8 (332800)
I0629 10:53:45.207059  2332 net.cpp:137] Memory required for data: 275431600
I0629 10:53:45.207059  2332 layer_factory.cpp:58] Creating layer scale_conv12
I0629 10:53:45.207059  2332 net.cpp:84] Creating Layer scale_conv12
I0629 10:53:45.207059  2332 net.cpp:406] scale_conv12 <- conv12
I0629 10:53:45.207059  2332 net.cpp:367] scale_conv12 -> conv12 (in-place)
I0629 10:53:45.207059  2332 layer_factory.cpp:58] Creating layer scale_conv12
I0629 10:53:45.207559  2332 net.cpp:122] Setting up scale_conv12
I0629 10:53:45.207559  2332 net.cpp:129] Top shape: 100 52 8 8 (332800)
I0629 10:53:45.207559  2332 net.cpp:137] Memory required for data: 276762800
I0629 10:53:45.207559  2332 layer_factory.cpp:58] Creating layer relu_conv12
I0629 10:53:45.207559  2332 net.cpp:84] Creating Layer relu_conv12
I0629 10:53:45.207559  2332 net.cpp:406] relu_conv12 <- conv12
I0629 10:53:45.207559  2332 net.cpp:367] relu_conv12 -> conv12 (in-place)
I0629 10:53:45.207559  2332 net.cpp:122] Setting up relu_conv12
I0629 10:53:45.207559  2332 net.cpp:129] Top shape: 100 52 8 8 (332800)
I0629 10:53:45.207559  2332 net.cpp:137] Memory required for data: 278094000
I0629 10:53:45.207559  2332 layer_factory.cpp:58] Creating layer poolcp6
I0629 10:53:45.207559  2332 net.cpp:84] Creating Layer poolcp6
I0629 10:53:45.207559  2332 net.cpp:406] poolcp6 <- conv12
I0629 10:53:45.207559  2332 net.cpp:380] poolcp6 -> poolcp6
I0629 10:53:45.207559  2332 net.cpp:122] Setting up poolcp6
I0629 10:53:45.207559  2332 net.cpp:129] Top shape: 100 52 1 1 (5200)
I0629 10:53:45.207559  2332 net.cpp:137] Memory required for data: 278114800
I0629 10:53:45.207559  2332 layer_factory.cpp:58] Creating layer ip1
I0629 10:53:45.207559  2332 net.cpp:84] Creating Layer ip1
I0629 10:53:45.207559  2332 net.cpp:406] ip1 <- poolcp6
I0629 10:53:45.207559  2332 net.cpp:380] ip1 -> ip1
I0629 10:53:45.207559  2332 net.cpp:122] Setting up ip1
I0629 10:53:45.208060  2332 net.cpp:129] Top shape: 100 10 (1000)
I0629 10:53:45.208060  2332 net.cpp:137] Memory required for data: 278118800
I0629 10:53:45.208060  2332 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0629 10:53:45.208060  2332 net.cpp:84] Creating Layer ip1_ip1_0_split
I0629 10:53:45.208060  2332 net.cpp:406] ip1_ip1_0_split <- ip1
I0629 10:53:45.208060  2332 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0629 10:53:45.208060  2332 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0629 10:53:45.208060  2332 net.cpp:122] Setting up ip1_ip1_0_split
I0629 10:53:45.208060  2332 net.cpp:129] Top shape: 100 10 (1000)
I0629 10:53:45.208060  2332 net.cpp:129] Top shape: 100 10 (1000)
I0629 10:53:45.208060  2332 net.cpp:137] Memory required for data: 278126800
I0629 10:53:45.208060  2332 layer_factory.cpp:58] Creating layer accuracy
I0629 10:53:45.208060  2332 net.cpp:84] Creating Layer accuracy
I0629 10:53:45.208060  2332 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0629 10:53:45.208060  2332 net.cpp:406] accuracy <- label_cifar_1_split_0
I0629 10:53:45.208060  2332 net.cpp:380] accuracy -> accuracy
I0629 10:53:45.208060  2332 net.cpp:122] Setting up accuracy
I0629 10:53:45.208060  2332 net.cpp:129] Top shape: (1)
I0629 10:53:45.208060  2332 net.cpp:137] Memory required for data: 278126804
I0629 10:53:45.208060  2332 layer_factory.cpp:58] Creating layer loss
I0629 10:53:45.208060  2332 net.cpp:84] Creating Layer loss
I0629 10:53:45.208060  2332 net.cpp:406] loss <- ip1_ip1_0_split_1
I0629 10:53:45.208060  2332 net.cpp:406] loss <- label_cifar_1_split_1
I0629 10:53:45.208060  2332 net.cpp:380] loss -> loss
I0629 10:53:45.208060  2332 layer_factory.cpp:58] Creating layer loss
I0629 10:53:45.208564  2332 net.cpp:122] Setting up loss
I0629 10:53:45.208564  2332 net.cpp:129] Top shape: (1)
I0629 10:53:45.208564  2332 net.cpp:132]     with loss weight 1
I0629 10:53:45.208564  2332 net.cpp:137] Memory required for data: 278126808
I0629 10:53:45.208564  2332 net.cpp:198] loss needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:200] accuracy does not need backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] ip1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] poolcp6 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu_conv12 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale_conv12 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn_conv12 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv12 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu_conv11 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale_conv11 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn_conv11 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv11 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu4_0 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale4_0 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn4_0 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv4_0 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] pool4_2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu4_2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale4_2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn4_2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv4_2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu4_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale4_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn4_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv4_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu4 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale4 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn4 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv4 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu3_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale3_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn3_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv3_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu3 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale3 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn3 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv3 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] pool2_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu2_2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale2_2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn2_2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv2_2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu2_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale2_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn2_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv2_1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv2 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu1_0 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale1_0 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn1_0 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv1_0 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] relu1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] scale1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] bn1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:198] conv1 needs backward computation.
I0629 10:53:45.208564  2332 net.cpp:200] label_cifar_1_split does not need backward computation.
I0629 10:53:45.208564  2332 net.cpp:200] cifar does not need backward computation.
I0629 10:53:45.209060  2332 net.cpp:242] This network produces output accuracy
I0629 10:53:45.209060  2332 net.cpp:242] This network produces output loss
I0629 10:53:45.209060  2332 net.cpp:255] Network initialization done.
I0629 10:53:45.209060  2332 solver.cpp:56] Solver scaffolding done.
I0629 10:53:45.211678  2332 caffe.cpp:249] Starting Optimization
I0629 10:53:45.211678  2332 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_128K_t2
I0629 10:53:45.211678  2332 solver.cpp:273] Learning Rate Policy: multistep
I0629 10:53:45.213678  2332 solver.cpp:330] Iteration 0, Testing net (#0)
I0629 10:53:45.214679  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:53:46.086781  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:53:46.122381  2332 solver.cpp:397]     Test net output #0: accuracy = 0.0948
I0629 10:53:46.122381  2332 solver.cpp:397]     Test net output #1: loss = 79.057 (* 1 = 79.057 loss)
I0629 10:53:46.195557  2332 solver.cpp:218] Iteration 0 (0 iter/s, 0.982457s/100 iters), loss = 4.23293
I0629 10:53:46.195557  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.07
I0629 10:53:46.195557  2332 solver.cpp:237]     Train net output #1: loss = 4.23293 (* 1 = 4.23293 loss)
I0629 10:53:46.196058  2332 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0629 10:53:49.966238  2332 solver.cpp:218] Iteration 100 (26.5208 iter/s, 3.77062s/100 iters), loss = 1.75063
I0629 10:53:49.966238  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I0629 10:53:49.966238  2332 solver.cpp:237]     Train net output #1: loss = 1.75063 (* 1 = 1.75063 loss)
I0629 10:53:49.966238  2332 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0629 10:53:53.734856  2332 solver.cpp:218] Iteration 200 (26.5355 iter/s, 3.76854s/100 iters), loss = 1.77647
I0629 10:53:53.735857  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I0629 10:53:53.735857  2332 solver.cpp:237]     Train net output #1: loss = 1.77647 (* 1 = 1.77647 loss)
I0629 10:53:53.735857  2332 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0629 10:53:57.485177  2332 solver.cpp:218] Iteration 300 (26.6733 iter/s, 3.74907s/100 iters), loss = 1.46624
I0629 10:53:57.485177  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I0629 10:53:57.485177  2332 solver.cpp:237]     Train net output #1: loss = 1.46624 (* 1 = 1.46624 loss)
I0629 10:53:57.485177  2332 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0629 10:54:01.233517  2332 solver.cpp:218] Iteration 400 (26.6796 iter/s, 3.74819s/100 iters), loss = 1.34488
I0629 10:54:01.233517  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I0629 10:54:01.233517  2332 solver.cpp:237]     Train net output #1: loss = 1.34488 (* 1 = 1.34488 loss)
I0629 10:54:01.233517  2332 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0629 10:54:04.802309  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:54:04.951933  2332 solver.cpp:330] Iteration 500, Testing net (#0)
I0629 10:54:04.951933  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:54:05.801743  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:54:05.833397  2332 solver.cpp:397]     Test net output #0: accuracy = 0.4979
I0629 10:54:05.833397  2332 solver.cpp:397]     Test net output #1: loss = 1.37614 (* 1 = 1.37614 loss)
I0629 10:54:05.869428  2332 solver.cpp:218] Iteration 500 (21.5707 iter/s, 4.63592s/100 iters), loss = 1.52428
I0629 10:54:05.869428  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I0629 10:54:05.869428  2332 solver.cpp:237]     Train net output #1: loss = 1.52428 (* 1 = 1.52428 loss)
I0629 10:54:05.869428  2332 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0629 10:54:09.703631  2332 solver.cpp:218] Iteration 600 (26.088 iter/s, 3.83318s/100 iters), loss = 1.21144
I0629 10:54:09.703631  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I0629 10:54:09.703631  2332 solver.cpp:237]     Train net output #1: loss = 1.21144 (* 1 = 1.21144 loss)
I0629 10:54:09.703631  2332 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0629 10:54:13.598739  2332 solver.cpp:218] Iteration 700 (25.6742 iter/s, 3.89496s/100 iters), loss = 1.32071
I0629 10:54:13.598739  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I0629 10:54:13.598739  2332 solver.cpp:237]     Train net output #1: loss = 1.32071 (* 1 = 1.32071 loss)
I0629 10:54:13.598739  2332 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0629 10:54:17.247484  2332 solver.cpp:218] Iteration 800 (27.4079 iter/s, 3.64859s/100 iters), loss = 1.14926
I0629 10:54:17.247484  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I0629 10:54:17.247484  2332 solver.cpp:237]     Train net output #1: loss = 1.14926 (* 1 = 1.14926 loss)
I0629 10:54:17.247484  2332 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0629 10:54:20.979338  2332 solver.cpp:218] Iteration 900 (26.8016 iter/s, 3.73112s/100 iters), loss = 1.13955
I0629 10:54:20.979338  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I0629 10:54:20.979338  2332 solver.cpp:237]     Train net output #1: loss = 1.13955 (* 1 = 1.13955 loss)
I0629 10:54:20.979338  2332 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0629 10:54:24.586019  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:54:24.727623  2332 solver.cpp:330] Iteration 1000, Testing net (#0)
I0629 10:54:24.727623  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:54:25.558104  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:54:25.588125  2332 solver.cpp:397]     Test net output #0: accuracy = 0.575
I0629 10:54:25.588125  2332 solver.cpp:397]     Test net output #1: loss = 1.20731 (* 1 = 1.20731 loss)
I0629 10:54:25.623149  2332 solver.cpp:218] Iteration 1000 (21.5342 iter/s, 4.64378s/100 iters), loss = 1.0544
I0629 10:54:25.623149  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I0629 10:54:25.623149  2332 solver.cpp:237]     Train net output #1: loss = 1.0544 (* 1 = 1.0544 loss)
I0629 10:54:25.623149  2332 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0629 10:54:29.304960  2332 solver.cpp:218] Iteration 1100 (27.16 iter/s, 3.68188s/100 iters), loss = 0.968195
I0629 10:54:29.305960  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0629 10:54:29.305960  2332 solver.cpp:237]     Train net output #1: loss = 0.968195 (* 1 = 0.968195 loss)
I0629 10:54:29.305960  2332 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0629 10:54:32.970335  2332 solver.cpp:218] Iteration 1200 (27.2869 iter/s, 3.66476s/100 iters), loss = 1.11502
I0629 10:54:32.970335  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I0629 10:54:32.970335  2332 solver.cpp:237]     Train net output #1: loss = 1.11502 (* 1 = 1.11502 loss)
I0629 10:54:32.970335  2332 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0629 10:54:36.604401  2332 solver.cpp:218] Iteration 1300 (27.5256 iter/s, 3.63299s/100 iters), loss = 0.975402
I0629 10:54:36.604401  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0629 10:54:36.604401  2332 solver.cpp:237]     Train net output #1: loss = 0.975402 (* 1 = 0.975402 loss)
I0629 10:54:36.604401  2332 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0629 10:54:40.215302  2332 solver.cpp:218] Iteration 1400 (27.6927 iter/s, 3.61106s/100 iters), loss = 0.987174
I0629 10:54:40.215302  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I0629 10:54:40.215302  2332 solver.cpp:237]     Train net output #1: loss = 0.987174 (* 1 = 0.987174 loss)
I0629 10:54:40.215302  2332 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0629 10:54:43.635957  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:54:43.778285  2332 solver.cpp:330] Iteration 1500, Testing net (#0)
I0629 10:54:43.778285  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:54:44.597087  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:54:44.627306  2332 solver.cpp:397]     Test net output #0: accuracy = 0.6478
I0629 10:54:44.627306  2332 solver.cpp:397]     Test net output #1: loss = 0.982507 (* 1 = 0.982507 loss)
I0629 10:54:44.662334  2332 solver.cpp:218] Iteration 1500 (22.4917 iter/s, 4.44609s/100 iters), loss = 1.01426
I0629 10:54:44.662334  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0629 10:54:44.662334  2332 solver.cpp:237]     Train net output #1: loss = 1.01426 (* 1 = 1.01426 loss)
I0629 10:54:44.662334  2332 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0629 10:54:48.270560  2332 solver.cpp:218] Iteration 1600 (27.7129 iter/s, 3.60843s/100 iters), loss = 0.910425
I0629 10:54:48.270560  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I0629 10:54:48.270560  2332 solver.cpp:237]     Train net output #1: loss = 0.910425 (* 1 = 0.910425 loss)
I0629 10:54:48.270560  2332 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0629 10:54:51.904513  2332 solver.cpp:218] Iteration 1700 (27.5203 iter/s, 3.63368s/100 iters), loss = 0.991751
I0629 10:54:51.904513  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I0629 10:54:51.904513  2332 solver.cpp:237]     Train net output #1: loss = 0.991751 (* 1 = 0.991751 loss)
I0629 10:54:51.904513  2332 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0629 10:54:55.536867  2332 solver.cpp:218] Iteration 1800 (27.5361 iter/s, 3.6316s/100 iters), loss = 0.863888
I0629 10:54:55.536867  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I0629 10:54:55.536867  2332 solver.cpp:237]     Train net output #1: loss = 0.863888 (* 1 = 0.863888 loss)
I0629 10:54:55.536867  2332 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0629 10:54:59.168614  2332 solver.cpp:218] Iteration 1900 (27.5367 iter/s, 3.63152s/100 iters), loss = 0.836876
I0629 10:54:59.168614  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0629 10:54:59.168614  2332 solver.cpp:237]     Train net output #1: loss = 0.836876 (* 1 = 0.836876 loss)
I0629 10:54:59.168614  2332 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0629 10:55:02.614213  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:55:02.756321  2332 solver.cpp:330] Iteration 2000, Testing net (#0)
I0629 10:55:02.756822  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:55:03.577950  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:55:03.608971  2332 solver.cpp:397]     Test net output #0: accuracy = 0.6865
I0629 10:55:03.608971  2332 solver.cpp:397]     Test net output #1: loss = 0.898379 (* 1 = 0.898379 loss)
I0629 10:55:03.643497  2332 solver.cpp:218] Iteration 2000 (22.349 iter/s, 4.47448s/100 iters), loss = 0.823706
I0629 10:55:03.643497  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I0629 10:55:03.643497  2332 solver.cpp:237]     Train net output #1: loss = 0.823706 (* 1 = 0.823706 loss)
I0629 10:55:03.643497  2332 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0629 10:55:07.271680  2332 solver.cpp:218] Iteration 2100 (27.5651 iter/s, 3.62777s/100 iters), loss = 0.685614
I0629 10:55:07.271680  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0629 10:55:07.271680  2332 solver.cpp:237]     Train net output #1: loss = 0.685614 (* 1 = 0.685614 loss)
I0629 10:55:07.271680  2332 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0629 10:55:10.896404  2332 solver.cpp:218] Iteration 2200 (27.5906 iter/s, 3.62442s/100 iters), loss = 0.960721
I0629 10:55:10.896404  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0629 10:55:10.896404  2332 solver.cpp:237]     Train net output #1: loss = 0.960721 (* 1 = 0.960721 loss)
I0629 10:55:10.896404  2332 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0629 10:55:14.517102  2332 solver.cpp:218] Iteration 2300 (27.6165 iter/s, 3.62102s/100 iters), loss = 0.764269
I0629 10:55:14.517102  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0629 10:55:14.517102  2332 solver.cpp:237]     Train net output #1: loss = 0.764269 (* 1 = 0.764269 loss)
I0629 10:55:14.517102  2332 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0629 10:55:18.142840  2332 solver.cpp:218] Iteration 2400 (27.5847 iter/s, 3.62519s/100 iters), loss = 0.768725
I0629 10:55:18.142840  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0629 10:55:18.142840  2332 solver.cpp:237]     Train net output #1: loss = 0.768725 (* 1 = 0.768725 loss)
I0629 10:55:18.142840  2332 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0629 10:55:21.594435  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:55:21.735538  2332 solver.cpp:330] Iteration 2500, Testing net (#0)
I0629 10:55:21.735538  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:55:22.562260  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:55:22.593284  2332 solver.cpp:397]     Test net output #0: accuracy = 0.6665
I0629 10:55:22.593284  2332 solver.cpp:397]     Test net output #1: loss = 0.955781 (* 1 = 0.955781 loss)
I0629 10:55:22.627307  2332 solver.cpp:218] Iteration 2500 (22.3025 iter/s, 4.48381s/100 iters), loss = 0.773871
I0629 10:55:22.627307  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0629 10:55:22.627307  2332 solver.cpp:237]     Train net output #1: loss = 0.773871 (* 1 = 0.773871 loss)
I0629 10:55:22.627307  2332 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0629 10:55:26.249003  2332 solver.cpp:218] Iteration 2600 (27.6092 iter/s, 3.62199s/100 iters), loss = 0.657552
I0629 10:55:26.249003  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0629 10:55:26.250005  2332 solver.cpp:237]     Train net output #1: loss = 0.657552 (* 1 = 0.657552 loss)
I0629 10:55:26.250005  2332 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0629 10:55:29.877287  2332 solver.cpp:218] Iteration 2700 (27.5695 iter/s, 3.6272s/100 iters), loss = 0.822073
I0629 10:55:29.877287  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0629 10:55:29.877287  2332 solver.cpp:237]     Train net output #1: loss = 0.822073 (* 1 = 0.822073 loss)
I0629 10:55:29.877287  2332 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0629 10:55:33.502516  2332 solver.cpp:218] Iteration 2800 (27.5875 iter/s, 3.62483s/100 iters), loss = 0.728705
I0629 10:55:33.502516  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0629 10:55:33.502516  2332 solver.cpp:237]     Train net output #1: loss = 0.728705 (* 1 = 0.728705 loss)
I0629 10:55:33.502516  2332 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0629 10:55:37.130334  2332 solver.cpp:218] Iteration 2900 (27.5675 iter/s, 3.62747s/100 iters), loss = 0.723327
I0629 10:55:37.130334  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0629 10:55:37.130334  2332 solver.cpp:237]     Train net output #1: loss = 0.723327 (* 1 = 0.723327 loss)
I0629 10:55:37.130334  2332 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0629 10:55:40.589714  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:55:40.730816  2332 solver.cpp:330] Iteration 3000, Testing net (#0)
I0629 10:55:40.730816  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:55:41.548547  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:55:41.580063  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7189
I0629 10:55:41.580063  2332 solver.cpp:397]     Test net output #1: loss = 0.795767 (* 1 = 0.795767 loss)
I0629 10:55:41.613589  2332 solver.cpp:218] Iteration 3000 (22.303 iter/s, 4.4837s/100 iters), loss = 0.768846
I0629 10:55:41.614589  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0629 10:55:41.614589  2332 solver.cpp:237]     Train net output #1: loss = 0.768846 (* 1 = 0.768846 loss)
I0629 10:55:41.614589  2332 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0629 10:55:45.247292  2332 solver.cpp:218] Iteration 3100 (27.5283 iter/s, 3.63263s/100 iters), loss = 0.597131
I0629 10:55:45.247292  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0629 10:55:45.247292  2332 solver.cpp:237]     Train net output #1: loss = 0.597131 (* 1 = 0.597131 loss)
I0629 10:55:45.247292  2332 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0629 10:55:48.863210  2332 solver.cpp:218] Iteration 3200 (27.6555 iter/s, 3.61591s/100 iters), loss = 0.740046
I0629 10:55:48.863210  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0629 10:55:48.863210  2332 solver.cpp:237]     Train net output #1: loss = 0.740046 (* 1 = 0.740046 loss)
I0629 10:55:48.863210  2332 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0629 10:55:52.494498  2332 solver.cpp:218] Iteration 3300 (27.5432 iter/s, 3.63065s/100 iters), loss = 0.619855
I0629 10:55:52.494498  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0629 10:55:52.494498  2332 solver.cpp:237]     Train net output #1: loss = 0.619855 (* 1 = 0.619855 loss)
I0629 10:55:52.494498  2332 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0629 10:55:56.129066  2332 solver.cpp:218] Iteration 3400 (27.5175 iter/s, 3.63404s/100 iters), loss = 0.723367
I0629 10:55:56.129066  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0629 10:55:56.129066  2332 solver.cpp:237]     Train net output #1: loss = 0.723367 (* 1 = 0.723367 loss)
I0629 10:55:56.129066  2332 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0629 10:55:59.578672  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:55:59.720798  2332 solver.cpp:330] Iteration 3500, Testing net (#0)
I0629 10:55:59.720798  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:56:00.539389  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:56:00.570411  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7209
I0629 10:56:00.570411  2332 solver.cpp:397]     Test net output #1: loss = 0.791204 (* 1 = 0.791204 loss)
I0629 10:56:00.604936  2332 solver.cpp:218] Iteration 3500 (22.3432 iter/s, 4.47563s/100 iters), loss = 0.702867
I0629 10:56:00.604936  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0629 10:56:00.604936  2332 solver.cpp:237]     Train net output #1: loss = 0.702867 (* 1 = 0.702867 loss)
I0629 10:56:00.604936  2332 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0629 10:56:04.230201  2332 solver.cpp:218] Iteration 3600 (27.588 iter/s, 3.62477s/100 iters), loss = 0.562272
I0629 10:56:04.230201  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 10:56:04.230201  2332 solver.cpp:237]     Train net output #1: loss = 0.562272 (* 1 = 0.562272 loss)
I0629 10:56:04.230201  2332 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0629 10:56:07.858978  2332 solver.cpp:218] Iteration 3700 (27.5599 iter/s, 3.62846s/100 iters), loss = 0.640798
I0629 10:56:07.858978  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0629 10:56:07.858978  2332 solver.cpp:237]     Train net output #1: loss = 0.640798 (* 1 = 0.640798 loss)
I0629 10:56:07.858978  2332 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0629 10:56:11.477773  2332 solver.cpp:218] Iteration 3800 (27.6308 iter/s, 3.61915s/100 iters), loss = 0.603472
I0629 10:56:11.477773  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0629 10:56:11.477773  2332 solver.cpp:237]     Train net output #1: loss = 0.603472 (* 1 = 0.603472 loss)
I0629 10:56:11.477773  2332 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0629 10:56:15.114882  2332 solver.cpp:218] Iteration 3900 (27.5026 iter/s, 3.63603s/100 iters), loss = 0.632647
I0629 10:56:15.114882  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0629 10:56:15.114882  2332 solver.cpp:237]     Train net output #1: loss = 0.632647 (* 1 = 0.632647 loss)
I0629 10:56:15.114882  2332 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0629 10:56:18.565255  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:56:18.707875  2332 solver.cpp:330] Iteration 4000, Testing net (#0)
I0629 10:56:18.707875  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:56:19.524452  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:56:19.555481  2332 solver.cpp:397]     Test net output #0: accuracy = 0.6958
I0629 10:56:19.555481  2332 solver.cpp:397]     Test net output #1: loss = 0.908649 (* 1 = 0.908649 loss)
I0629 10:56:19.589510  2332 solver.cpp:218] Iteration 4000 (22.3488 iter/s, 4.47451s/100 iters), loss = 0.571892
I0629 10:56:19.589510  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0629 10:56:19.589510  2332 solver.cpp:237]     Train net output #1: loss = 0.571892 (* 1 = 0.571892 loss)
I0629 10:56:19.589510  2332 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0629 10:56:23.209118  2332 solver.cpp:218] Iteration 4100 (27.6292 iter/s, 3.61936s/100 iters), loss = 0.508048
I0629 10:56:23.209621  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0629 10:56:23.209621  2332 solver.cpp:237]     Train net output #1: loss = 0.508048 (* 1 = 0.508048 loss)
I0629 10:56:23.209621  2332 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0629 10:56:26.825356  2332 solver.cpp:218] Iteration 4200 (27.6558 iter/s, 3.61588s/100 iters), loss = 0.553294
I0629 10:56:26.825844  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0629 10:56:26.825844  2332 solver.cpp:237]     Train net output #1: loss = 0.553294 (* 1 = 0.553294 loss)
I0629 10:56:26.825844  2332 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0629 10:56:30.454530  2332 solver.cpp:218] Iteration 4300 (27.5556 iter/s, 3.62903s/100 iters), loss = 0.56428
I0629 10:56:30.454530  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0629 10:56:30.454530  2332 solver.cpp:237]     Train net output #1: loss = 0.56428 (* 1 = 0.56428 loss)
I0629 10:56:30.454530  2332 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0629 10:56:34.072201  2332 solver.cpp:218] Iteration 4400 (27.6443 iter/s, 3.61739s/100 iters), loss = 0.511287
I0629 10:56:34.072201  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0629 10:56:34.072201  2332 solver.cpp:237]     Train net output #1: loss = 0.511287 (* 1 = 0.511287 loss)
I0629 10:56:34.072201  2332 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0629 10:56:37.527945  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:56:37.668972  2332 solver.cpp:330] Iteration 4500, Testing net (#0)
I0629 10:56:37.668972  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:56:38.486227  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:56:38.517258  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7378
I0629 10:56:38.517258  2332 solver.cpp:397]     Test net output #1: loss = 0.792385 (* 1 = 0.792385 loss)
I0629 10:56:38.552290  2332 solver.cpp:218] Iteration 4500 (22.3257 iter/s, 4.47915s/100 iters), loss = 0.600648
I0629 10:56:38.552290  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0629 10:56:38.552290  2332 solver.cpp:237]     Train net output #1: loss = 0.600648 (* 1 = 0.600648 loss)
I0629 10:56:38.552290  2332 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0629 10:56:42.170356  2332 solver.cpp:218] Iteration 4600 (27.6367 iter/s, 3.61838s/100 iters), loss = 0.507997
I0629 10:56:42.170356  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0629 10:56:42.170356  2332 solver.cpp:237]     Train net output #1: loss = 0.507997 (* 1 = 0.507997 loss)
I0629 10:56:42.170356  2332 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0629 10:56:45.790462  2332 solver.cpp:218] Iteration 4700 (27.6248 iter/s, 3.61993s/100 iters), loss = 0.634671
I0629 10:56:45.790462  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0629 10:56:45.790462  2332 solver.cpp:237]     Train net output #1: loss = 0.634671 (* 1 = 0.634671 loss)
I0629 10:56:45.790462  2332 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0629 10:56:49.411270  2332 solver.cpp:218] Iteration 4800 (27.6204 iter/s, 3.62051s/100 iters), loss = 0.562947
I0629 10:56:49.412271  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 10:56:49.412271  2332 solver.cpp:237]     Train net output #1: loss = 0.562947 (* 1 = 0.562947 loss)
I0629 10:56:49.412271  2332 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0629 10:56:53.034677  2332 solver.cpp:218] Iteration 4900 (27.6023 iter/s, 3.62289s/100 iters), loss = 0.485818
I0629 10:56:53.034677  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0629 10:56:53.034677  2332 solver.cpp:237]     Train net output #1: loss = 0.485818 (* 1 = 0.485818 loss)
I0629 10:56:53.034677  2332 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0629 10:56:56.476125  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:56:56.616819  2332 solver.cpp:330] Iteration 5000, Testing net (#0)
I0629 10:56:56.616819  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:56:57.432914  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:56:57.464073  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7772
I0629 10:56:57.464073  2332 solver.cpp:397]     Test net output #1: loss = 0.632312 (* 1 = 0.632312 loss)
I0629 10:56:57.498108  2332 solver.cpp:218] Iteration 5000 (22.4091 iter/s, 4.46248s/100 iters), loss = 0.52753
I0629 10:56:57.498108  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0629 10:56:57.498108  2332 solver.cpp:237]     Train net output #1: loss = 0.52753 (* 1 = 0.52753 loss)
I0629 10:56:57.498108  2332 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0629 10:57:01.140607  2332 solver.cpp:218] Iteration 5100 (27.4564 iter/s, 3.64213s/100 iters), loss = 0.436179
I0629 10:57:01.140607  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 10:57:01.140607  2332 solver.cpp:237]     Train net output #1: loss = 0.436179 (* 1 = 0.436179 loss)
I0629 10:57:01.140607  2332 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0629 10:57:04.756755  2332 solver.cpp:218] Iteration 5200 (27.6562 iter/s, 3.61583s/100 iters), loss = 0.501572
I0629 10:57:04.756755  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0629 10:57:04.756755  2332 solver.cpp:237]     Train net output #1: loss = 0.501572 (* 1 = 0.501572 loss)
I0629 10:57:04.756755  2332 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0629 10:57:08.399020  2332 solver.cpp:218] Iteration 5300 (27.4578 iter/s, 3.64195s/100 iters), loss = 0.491203
I0629 10:57:08.399020  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 10:57:08.399020  2332 solver.cpp:237]     Train net output #1: loss = 0.491203 (* 1 = 0.491203 loss)
I0629 10:57:08.399020  2332 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0629 10:57:12.019484  2332 solver.cpp:218] Iteration 5400 (27.6191 iter/s, 3.62069s/100 iters), loss = 0.503698
I0629 10:57:12.019484  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0629 10:57:12.019484  2332 solver.cpp:237]     Train net output #1: loss = 0.503698 (* 1 = 0.503698 loss)
I0629 10:57:12.019484  2332 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0629 10:57:15.464213  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:57:15.607317  2332 solver.cpp:330] Iteration 5500, Testing net (#0)
I0629 10:57:15.607317  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:57:16.430933  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:57:16.461958  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7517
I0629 10:57:16.461958  2332 solver.cpp:397]     Test net output #1: loss = 0.731304 (* 1 = 0.731304 loss)
I0629 10:57:16.495982  2332 solver.cpp:218] Iteration 5500 (22.3404 iter/s, 4.47619s/100 iters), loss = 0.526761
I0629 10:57:16.495982  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0629 10:57:16.495982  2332 solver.cpp:237]     Train net output #1: loss = 0.526761 (* 1 = 0.526761 loss)
I0629 10:57:16.495982  2332 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0629 10:57:20.116055  2332 solver.cpp:218] Iteration 5600 (27.6312 iter/s, 3.6191s/100 iters), loss = 0.46762
I0629 10:57:20.116055  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0629 10:57:20.116055  2332 solver.cpp:237]     Train net output #1: loss = 0.46762 (* 1 = 0.46762 loss)
I0629 10:57:20.116055  2332 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0629 10:57:23.735993  2332 solver.cpp:218] Iteration 5700 (27.6236 iter/s, 3.62009s/100 iters), loss = 0.548726
I0629 10:57:23.735993  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0629 10:57:23.735993  2332 solver.cpp:237]     Train net output #1: loss = 0.548726 (* 1 = 0.548726 loss)
I0629 10:57:23.735993  2332 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0629 10:57:27.364239  2332 solver.cpp:218] Iteration 5800 (27.5666 iter/s, 3.62758s/100 iters), loss = 0.54416
I0629 10:57:27.364739  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 10:57:27.364739  2332 solver.cpp:237]     Train net output #1: loss = 0.54416 (* 1 = 0.54416 loss)
I0629 10:57:27.364739  2332 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0629 10:57:30.978765  2332 solver.cpp:218] Iteration 5900 (27.6662 iter/s, 3.61452s/100 iters), loss = 0.45521
I0629 10:57:30.978765  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0629 10:57:30.978765  2332 solver.cpp:237]     Train net output #1: loss = 0.45521 (* 1 = 0.45521 loss)
I0629 10:57:30.978765  2332 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0629 10:57:34.426667  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:57:34.567383  2332 solver.cpp:330] Iteration 6000, Testing net (#0)
I0629 10:57:34.567383  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:57:35.382628  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:57:35.413638  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7749
I0629 10:57:35.413638  2332 solver.cpp:397]     Test net output #1: loss = 0.668783 (* 1 = 0.668783 loss)
I0629 10:57:35.447672  2332 solver.cpp:218] Iteration 6000 (22.3796 iter/s, 4.46836s/100 iters), loss = 0.42333
I0629 10:57:35.447672  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 10:57:35.447672  2332 solver.cpp:237]     Train net output #1: loss = 0.42333 (* 1 = 0.42333 loss)
I0629 10:57:35.447672  2332 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0629 10:57:39.070233  2332 solver.cpp:218] Iteration 6100 (27.6109 iter/s, 3.62176s/100 iters), loss = 0.438493
I0629 10:57:39.070233  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 10:57:39.070233  2332 solver.cpp:237]     Train net output #1: loss = 0.438493 (* 1 = 0.438493 loss)
I0629 10:57:39.070233  2332 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0629 10:57:42.682791  2332 solver.cpp:218] Iteration 6200 (27.6844 iter/s, 3.61214s/100 iters), loss = 0.503978
I0629 10:57:42.682791  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 10:57:42.682791  2332 solver.cpp:237]     Train net output #1: loss = 0.503978 (* 1 = 0.503978 loss)
I0629 10:57:42.682791  2332 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0629 10:57:46.299952  2332 solver.cpp:218] Iteration 6300 (27.6461 iter/s, 3.61715s/100 iters), loss = 0.50347
I0629 10:57:46.299952  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0629 10:57:46.299952  2332 solver.cpp:237]     Train net output #1: loss = 0.50347 (* 1 = 0.50347 loss)
I0629 10:57:46.299952  2332 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0629 10:57:49.912369  2332 solver.cpp:218] Iteration 6400 (27.6824 iter/s, 3.6124s/100 iters), loss = 0.400912
I0629 10:57:49.912369  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 10:57:49.912369  2332 solver.cpp:237]     Train net output #1: loss = 0.400912 (* 1 = 0.400912 loss)
I0629 10:57:49.912369  2332 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0629 10:57:53.353582  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:57:53.494755  2332 solver.cpp:330] Iteration 6500, Testing net (#0)
I0629 10:57:53.494755  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:57:54.311322  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:57:54.342331  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7911
I0629 10:57:54.342331  2332 solver.cpp:397]     Test net output #1: loss = 0.608869 (* 1 = 0.608869 loss)
I0629 10:57:54.376366  2332 solver.cpp:218] Iteration 6500 (22.4037 iter/s, 4.46355s/100 iters), loss = 0.455509
I0629 10:57:54.376366  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0629 10:57:54.376366  2332 solver.cpp:237]     Train net output #1: loss = 0.455509 (* 1 = 0.455509 loss)
I0629 10:57:54.376366  2332 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0629 10:57:57.993790  2332 solver.cpp:218] Iteration 6600 (27.6499 iter/s, 3.61665s/100 iters), loss = 0.348471
I0629 10:57:57.993790  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 10:57:57.993790  2332 solver.cpp:237]     Train net output #1: loss = 0.348471 (* 1 = 0.348471 loss)
I0629 10:57:57.993790  2332 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0629 10:58:01.609302  2332 solver.cpp:218] Iteration 6700 (27.659 iter/s, 3.61546s/100 iters), loss = 0.46703
I0629 10:58:01.609302  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 10:58:01.609302  2332 solver.cpp:237]     Train net output #1: loss = 0.46703 (* 1 = 0.46703 loss)
I0629 10:58:01.609302  2332 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0629 10:58:05.224824  2332 solver.cpp:218] Iteration 6800 (27.6571 iter/s, 3.61571s/100 iters), loss = 0.530083
I0629 10:58:05.225826  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0629 10:58:05.225826  2332 solver.cpp:237]     Train net output #1: loss = 0.530083 (* 1 = 0.530083 loss)
I0629 10:58:05.225826  2332 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0629 10:58:08.855510  2332 solver.cpp:218] Iteration 6900 (27.5502 iter/s, 3.62973s/100 iters), loss = 0.418218
I0629 10:58:08.855510  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 10:58:08.855510  2332 solver.cpp:237]     Train net output #1: loss = 0.418218 (* 1 = 0.418218 loss)
I0629 10:58:08.855510  2332 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0629 10:58:12.299605  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:58:12.441220  2332 solver.cpp:330] Iteration 7000, Testing net (#0)
I0629 10:58:12.441220  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:58:13.258433  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:58:13.289459  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7794
I0629 10:58:13.289459  2332 solver.cpp:397]     Test net output #1: loss = 0.648827 (* 1 = 0.648827 loss)
I0629 10:58:13.323479  2332 solver.cpp:218] Iteration 7000 (22.382 iter/s, 4.46789s/100 iters), loss = 0.518505
I0629 10:58:13.323479  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0629 10:58:13.323479  2332 solver.cpp:237]     Train net output #1: loss = 0.518505 (* 1 = 0.518505 loss)
I0629 10:58:13.323479  2332 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0629 10:58:16.971684  2332 solver.cpp:218] Iteration 7100 (27.4123 iter/s, 3.64799s/100 iters), loss = 0.417686
I0629 10:58:16.971684  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0629 10:58:16.971684  2332 solver.cpp:237]     Train net output #1: loss = 0.417686 (* 1 = 0.417686 loss)
I0629 10:58:16.971684  2332 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0629 10:58:20.598525  2332 solver.cpp:218] Iteration 7200 (27.5804 iter/s, 3.62576s/100 iters), loss = 0.389169
I0629 10:58:20.598525  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0629 10:58:20.598525  2332 solver.cpp:237]     Train net output #1: loss = 0.389169 (* 1 = 0.389169 loss)
I0629 10:58:20.598525  2332 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0629 10:58:24.223243  2332 solver.cpp:218] Iteration 7300 (27.5867 iter/s, 3.62494s/100 iters), loss = 0.480977
I0629 10:58:24.223243  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 10:58:24.223243  2332 solver.cpp:237]     Train net output #1: loss = 0.480977 (* 1 = 0.480977 loss)
I0629 10:58:24.223243  2332 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0629 10:58:27.846951  2332 solver.cpp:218] Iteration 7400 (27.5994 iter/s, 3.62326s/100 iters), loss = 0.409666
I0629 10:58:27.846951  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 10:58:27.846951  2332 solver.cpp:237]     Train net output #1: loss = 0.409666 (* 1 = 0.409666 loss)
I0629 10:58:27.846951  2332 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0629 10:58:31.289702  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:58:31.430806  2332 solver.cpp:330] Iteration 7500, Testing net (#0)
I0629 10:58:31.430806  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:58:32.249011  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:58:32.279533  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7918
I0629 10:58:32.279533  2332 solver.cpp:397]     Test net output #1: loss = 0.598988 (* 1 = 0.598988 loss)
I0629 10:58:32.314558  2332 solver.cpp:218] Iteration 7500 (22.3864 iter/s, 4.467s/100 iters), loss = 0.477283
I0629 10:58:32.314558  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 10:58:32.314558  2332 solver.cpp:237]     Train net output #1: loss = 0.477283 (* 1 = 0.477283 loss)
I0629 10:58:32.314558  2332 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0629 10:58:35.978552  2332 solver.cpp:218] Iteration 7600 (27.2916 iter/s, 3.66413s/100 iters), loss = 0.368677
I0629 10:58:35.978552  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 10:58:35.978552  2332 solver.cpp:237]     Train net output #1: loss = 0.368677 (* 1 = 0.368677 loss)
I0629 10:58:35.978552  2332 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0629 10:58:39.628268  2332 solver.cpp:218] Iteration 7700 (27.4005 iter/s, 3.64956s/100 iters), loss = 0.482406
I0629 10:58:39.628268  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0629 10:58:39.628268  2332 solver.cpp:237]     Train net output #1: loss = 0.482406 (* 1 = 0.482406 loss)
I0629 10:58:39.628268  2332 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0629 10:58:43.257719  2332 solver.cpp:218] Iteration 7800 (27.5607 iter/s, 3.62836s/100 iters), loss = 0.546465
I0629 10:58:43.257719  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0629 10:58:43.257719  2332 solver.cpp:237]     Train net output #1: loss = 0.546465 (* 1 = 0.546465 loss)
I0629 10:58:43.257719  2332 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0629 10:58:46.893237  2332 solver.cpp:218] Iteration 7900 (27.5049 iter/s, 3.63572s/100 iters), loss = 0.405483
I0629 10:58:46.893237  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 10:58:46.893237  2332 solver.cpp:237]     Train net output #1: loss = 0.405483 (* 1 = 0.405483 loss)
I0629 10:58:46.893237  2332 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0629 10:58:50.353359  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:58:50.495465  2332 solver.cpp:330] Iteration 8000, Testing net (#0)
I0629 10:58:50.495465  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:58:51.318078  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:58:51.349105  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7984
I0629 10:58:51.349105  2332 solver.cpp:397]     Test net output #1: loss = 0.600361 (* 1 = 0.600361 loss)
I0629 10:58:51.383127  2332 solver.cpp:218] Iteration 8000 (22.2732 iter/s, 4.4897s/100 iters), loss = 0.451552
I0629 10:58:51.383127  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 10:58:51.383127  2332 solver.cpp:237]     Train net output #1: loss = 0.451552 (* 1 = 0.451552 loss)
I0629 10:58:51.383127  2332 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0629 10:58:55.010844  2332 solver.cpp:218] Iteration 8100 (27.5727 iter/s, 3.62678s/100 iters), loss = 0.398528
I0629 10:58:55.010844  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 10:58:55.010844  2332 solver.cpp:237]     Train net output #1: loss = 0.398528 (* 1 = 0.398528 loss)
I0629 10:58:55.010844  2332 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0629 10:58:58.648569  2332 solver.cpp:218] Iteration 8200 (27.4891 iter/s, 3.6378s/100 iters), loss = 0.474513
I0629 10:58:58.648569  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 10:58:58.648569  2332 solver.cpp:237]     Train net output #1: loss = 0.474513 (* 1 = 0.474513 loss)
I0629 10:58:58.648569  2332 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0629 10:59:02.285090  2332 solver.cpp:218] Iteration 8300 (27.5005 iter/s, 3.6363s/100 iters), loss = 0.419285
I0629 10:59:02.285090  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0629 10:59:02.285090  2332 solver.cpp:237]     Train net output #1: loss = 0.419285 (* 1 = 0.419285 loss)
I0629 10:59:02.285090  2332 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0629 10:59:05.915319  2332 solver.cpp:218] Iteration 8400 (27.5538 iter/s, 3.62927s/100 iters), loss = 0.323864
I0629 10:59:05.915319  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 10:59:05.915319  2332 solver.cpp:237]     Train net output #1: loss = 0.323864 (* 1 = 0.323864 loss)
I0629 10:59:05.915319  2332 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0629 10:59:09.368566  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:59:09.510679  2332 solver.cpp:330] Iteration 8500, Testing net (#0)
I0629 10:59:09.510679  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:59:10.329896  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:59:10.360920  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8124
I0629 10:59:10.360920  2332 solver.cpp:397]     Test net output #1: loss = 0.561998 (* 1 = 0.561998 loss)
I0629 10:59:10.394944  2332 solver.cpp:218] Iteration 8500 (22.3237 iter/s, 4.47955s/100 iters), loss = 0.407209
I0629 10:59:10.394944  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 10:59:10.394944  2332 solver.cpp:237]     Train net output #1: loss = 0.407209 (* 1 = 0.407209 loss)
I0629 10:59:10.394944  2332 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0629 10:59:14.028256  2332 solver.cpp:218] Iteration 8600 (27.5256 iter/s, 3.63298s/100 iters), loss = 0.329847
I0629 10:59:14.028256  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 10:59:14.028256  2332 solver.cpp:237]     Train net output #1: loss = 0.329847 (* 1 = 0.329847 loss)
I0629 10:59:14.028756  2332 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0629 10:59:17.661743  2332 solver.cpp:218] Iteration 8700 (27.5225 iter/s, 3.63339s/100 iters), loss = 0.375045
I0629 10:59:17.661743  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 10:59:17.661743  2332 solver.cpp:237]     Train net output #1: loss = 0.375045 (* 1 = 0.375045 loss)
I0629 10:59:17.661743  2332 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0629 10:59:21.295462  2332 solver.cpp:218] Iteration 8800 (27.524 iter/s, 3.6332s/100 iters), loss = 0.44682
I0629 10:59:21.295462  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 10:59:21.295462  2332 solver.cpp:237]     Train net output #1: loss = 0.44682 (* 1 = 0.44682 loss)
I0629 10:59:21.295462  2332 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0629 10:59:24.928220  2332 solver.cpp:218] Iteration 8900 (27.5335 iter/s, 3.63194s/100 iters), loss = 0.421207
I0629 10:59:24.928220  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0629 10:59:24.928220  2332 solver.cpp:237]     Train net output #1: loss = 0.421207 (* 1 = 0.421207 loss)
I0629 10:59:24.928220  2332 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0629 10:59:28.385838  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:59:28.527942  2332 solver.cpp:330] Iteration 9000, Testing net (#0)
I0629 10:59:28.527942  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:59:29.350626  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:59:29.381649  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8117
I0629 10:59:29.381649  2332 solver.cpp:397]     Test net output #1: loss = 0.55366 (* 1 = 0.55366 loss)
I0629 10:59:29.415673  2332 solver.cpp:218] Iteration 9000 (22.2822 iter/s, 4.48789s/100 iters), loss = 0.395924
I0629 10:59:29.415673  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0629 10:59:29.415673  2332 solver.cpp:237]     Train net output #1: loss = 0.395924 (* 1 = 0.395924 loss)
I0629 10:59:29.415673  2332 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0629 10:59:33.051445  2332 solver.cpp:218] Iteration 9100 (27.5077 iter/s, 3.63534s/100 iters), loss = 0.342563
I0629 10:59:33.051445  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 10:59:33.051445  2332 solver.cpp:237]     Train net output #1: loss = 0.342563 (* 1 = 0.342563 loss)
I0629 10:59:33.051445  2332 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0629 10:59:36.721245  2332 solver.cpp:218] Iteration 9200 (27.2514 iter/s, 3.66954s/100 iters), loss = 0.440498
I0629 10:59:36.721245  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 10:59:36.721245  2332 solver.cpp:237]     Train net output #1: loss = 0.440498 (* 1 = 0.440498 loss)
I0629 10:59:36.721245  2332 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0629 10:59:40.365924  2332 solver.cpp:218] Iteration 9300 (27.4407 iter/s, 3.64423s/100 iters), loss = 0.396457
I0629 10:59:40.365924  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 10:59:40.365924  2332 solver.cpp:237]     Train net output #1: loss = 0.396457 (* 1 = 0.396457 loss)
I0629 10:59:40.365924  2332 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0629 10:59:43.992633  2332 solver.cpp:218] Iteration 9400 (27.578 iter/s, 3.62608s/100 iters), loss = 0.410729
I0629 10:59:43.992633  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0629 10:59:43.992633  2332 solver.cpp:237]     Train net output #1: loss = 0.410729 (* 1 = 0.410729 loss)
I0629 10:59:43.992633  2332 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0629 10:59:47.451802  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:59:47.594408  2332 solver.cpp:330] Iteration 9500, Testing net (#0)
I0629 10:59:47.594408  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 10:59:48.413028  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 10:59:48.444051  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8091
I0629 10:59:48.444051  2332 solver.cpp:397]     Test net output #1: loss = 0.553721 (* 1 = 0.553721 loss)
I0629 10:59:48.478078  2332 solver.cpp:218] Iteration 9500 (22.2961 iter/s, 4.48509s/100 iters), loss = 0.433768
I0629 10:59:48.478078  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 10:59:48.478078  2332 solver.cpp:237]     Train net output #1: loss = 0.433768 (* 1 = 0.433768 loss)
I0629 10:59:48.478078  2332 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0629 10:59:52.115587  2332 solver.cpp:218] Iteration 9600 (27.4957 iter/s, 3.63693s/100 iters), loss = 0.369676
I0629 10:59:52.115587  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 10:59:52.115587  2332 solver.cpp:237]     Train net output #1: loss = 0.369676 (* 1 = 0.369676 loss)
I0629 10:59:52.115587  2332 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0629 10:59:55.756039  2332 solver.cpp:218] Iteration 9700 (27.4715 iter/s, 3.64014s/100 iters), loss = 0.358059
I0629 10:59:55.756039  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 10:59:55.756039  2332 solver.cpp:237]     Train net output #1: loss = 0.35806 (* 1 = 0.35806 loss)
I0629 10:59:55.756039  2332 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0629 10:59:59.386240  2332 solver.cpp:218] Iteration 9800 (27.5478 iter/s, 3.63006s/100 iters), loss = 0.391547
I0629 10:59:59.386240  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0629 10:59:59.386240  2332 solver.cpp:237]     Train net output #1: loss = 0.391547 (* 1 = 0.391547 loss)
I0629 10:59:59.386240  2332 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0629 11:00:03.044100  2332 solver.cpp:218] Iteration 9900 (27.3377 iter/s, 3.65795s/100 iters), loss = 0.283667
I0629 11:00:03.044100  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:00:03.044100  2332 solver.cpp:237]     Train net output #1: loss = 0.283667 (* 1 = 0.283667 loss)
I0629 11:00:03.044100  2332 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0629 11:00:06.510694  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:00:06.651798  2332 solver.cpp:330] Iteration 10000, Testing net (#0)
I0629 11:00:06.651798  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:00:07.474423  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:00:07.505448  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8135
I0629 11:00:07.505448  2332 solver.cpp:397]     Test net output #1: loss = 0.553719 (* 1 = 0.553719 loss)
I0629 11:00:07.539480  2332 solver.cpp:218] Iteration 10000 (22.2468 iter/s, 4.49504s/100 iters), loss = 0.354071
I0629 11:00:07.539480  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:00:07.539480  2332 solver.cpp:237]     Train net output #1: loss = 0.354071 (* 1 = 0.354071 loss)
I0629 11:00:07.539480  2332 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0629 11:00:11.169196  2332 solver.cpp:218] Iteration 10100 (27.5571 iter/s, 3.62883s/100 iters), loss = 0.321337
I0629 11:00:11.169196  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:00:11.169196  2332 solver.cpp:237]     Train net output #1: loss = 0.321337 (* 1 = 0.321337 loss)
I0629 11:00:11.169196  2332 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0629 11:00:14.805793  2332 solver.cpp:218] Iteration 10200 (27.5015 iter/s, 3.63617s/100 iters), loss = 0.31773
I0629 11:00:14.805793  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:00:14.805793  2332 solver.cpp:237]     Train net output #1: loss = 0.31773 (* 1 = 0.31773 loss)
I0629 11:00:14.805793  2332 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0629 11:00:18.453037  2332 solver.cpp:218] Iteration 10300 (27.4156 iter/s, 3.64755s/100 iters), loss = 0.388785
I0629 11:00:18.453037  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:00:18.453037  2332 solver.cpp:237]     Train net output #1: loss = 0.388785 (* 1 = 0.388785 loss)
I0629 11:00:18.453037  2332 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0629 11:00:22.091778  2332 solver.cpp:218] Iteration 10400 (27.4873 iter/s, 3.63804s/100 iters), loss = 0.312428
I0629 11:00:22.091778  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:00:22.091778  2332 solver.cpp:237]     Train net output #1: loss = 0.312428 (* 1 = 0.312428 loss)
I0629 11:00:22.091778  2332 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0629 11:00:25.549857  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:00:25.692023  2332 solver.cpp:330] Iteration 10500, Testing net (#0)
I0629 11:00:25.692023  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:00:26.515244  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:00:26.545871  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8154
I0629 11:00:26.545871  2332 solver.cpp:397]     Test net output #1: loss = 0.547997 (* 1 = 0.547997 loss)
I0629 11:00:26.579897  2332 solver.cpp:218] Iteration 10500 (22.281 iter/s, 4.48812s/100 iters), loss = 0.39749
I0629 11:00:26.579897  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:00:26.579897  2332 solver.cpp:237]     Train net output #1: loss = 0.39749 (* 1 = 0.39749 loss)
I0629 11:00:26.579897  2332 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0629 11:00:30.201917  2332 solver.cpp:218] Iteration 10600 (27.6122 iter/s, 3.62159s/100 iters), loss = 0.294972
I0629 11:00:30.201917  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:00:30.201917  2332 solver.cpp:237]     Train net output #1: loss = 0.294973 (* 1 = 0.294973 loss)
I0629 11:00:30.201917  2332 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0629 11:00:33.818747  2332 solver.cpp:218] Iteration 10700 (27.6508 iter/s, 3.61653s/100 iters), loss = 0.395056
I0629 11:00:33.818747  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:00:33.818747  2332 solver.cpp:237]     Train net output #1: loss = 0.395056 (* 1 = 0.395056 loss)
I0629 11:00:33.818747  2332 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0629 11:00:37.440840  2332 solver.cpp:218] Iteration 10800 (27.6164 iter/s, 3.62104s/100 iters), loss = 0.452891
I0629 11:00:37.440840  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 11:00:37.440840  2332 solver.cpp:237]     Train net output #1: loss = 0.452891 (* 1 = 0.452891 loss)
I0629 11:00:37.440840  2332 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0629 11:00:41.059459  2332 solver.cpp:218] Iteration 10900 (27.6377 iter/s, 3.61825s/100 iters), loss = 0.317058
I0629 11:00:41.059459  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:00:41.059459  2332 solver.cpp:237]     Train net output #1: loss = 0.317058 (* 1 = 0.317058 loss)
I0629 11:00:41.059459  2332 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0629 11:00:44.518932  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:00:44.661033  2332 solver.cpp:330] Iteration 11000, Testing net (#0)
I0629 11:00:44.661535  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:00:45.479110  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:00:45.510131  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8319
I0629 11:00:45.510131  2332 solver.cpp:397]     Test net output #1: loss = 0.500101 (* 1 = 0.500101 loss)
I0629 11:00:45.545159  2332 solver.cpp:218] Iteration 11000 (22.2928 iter/s, 4.48575s/100 iters), loss = 0.402485
I0629 11:00:45.545159  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:00:45.545159  2332 solver.cpp:237]     Train net output #1: loss = 0.402485 (* 1 = 0.402485 loss)
I0629 11:00:45.545159  2332 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0629 11:00:49.196038  2332 solver.cpp:218] Iteration 11100 (27.3925 iter/s, 3.65064s/100 iters), loss = 0.368345
I0629 11:00:49.196038  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:00:49.196038  2332 solver.cpp:237]     Train net output #1: loss = 0.368345 (* 1 = 0.368345 loss)
I0629 11:00:49.196038  2332 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0629 11:00:52.840315  2332 solver.cpp:218] Iteration 11200 (27.4464 iter/s, 3.64346s/100 iters), loss = 0.328234
I0629 11:00:52.840315  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:00:52.840315  2332 solver.cpp:237]     Train net output #1: loss = 0.328234 (* 1 = 0.328234 loss)
I0629 11:00:52.840315  2332 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0629 11:00:56.486091  2332 solver.cpp:218] Iteration 11300 (27.4296 iter/s, 3.6457s/100 iters), loss = 0.399153
I0629 11:00:56.486091  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:00:56.486091  2332 solver.cpp:237]     Train net output #1: loss = 0.399153 (* 1 = 0.399153 loss)
I0629 11:00:56.486091  2332 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0629 11:01:00.123910  2332 solver.cpp:218] Iteration 11400 (27.493 iter/s, 3.63729s/100 iters), loss = 0.317541
I0629 11:01:00.123910  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:01:00.123910  2332 solver.cpp:237]     Train net output #1: loss = 0.317542 (* 1 = 0.317542 loss)
I0629 11:01:00.123910  2332 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0629 11:01:03.578508  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:01:03.719614  2332 solver.cpp:330] Iteration 11500, Testing net (#0)
I0629 11:01:03.720614  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:01:04.539227  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:01:04.570248  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8113
I0629 11:01:04.570248  2332 solver.cpp:397]     Test net output #1: loss = 0.568808 (* 1 = 0.568808 loss)
I0629 11:01:04.604275  2332 solver.cpp:218] Iteration 11500 (22.3182 iter/s, 4.48064s/100 iters), loss = 0.361419
I0629 11:01:04.604275  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:01:04.604275  2332 solver.cpp:237]     Train net output #1: loss = 0.361419 (* 1 = 0.361419 loss)
I0629 11:01:04.604275  2332 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0629 11:01:08.243882  2332 solver.cpp:218] Iteration 11600 (27.4798 iter/s, 3.63904s/100 iters), loss = 0.365967
I0629 11:01:08.243882  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:01:08.243882  2332 solver.cpp:237]     Train net output #1: loss = 0.365967 (* 1 = 0.365967 loss)
I0629 11:01:08.243882  2332 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0629 11:01:11.875604  2332 solver.cpp:218] Iteration 11700 (27.5421 iter/s, 3.63081s/100 iters), loss = 0.358155
I0629 11:01:11.875604  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:01:11.875604  2332 solver.cpp:237]     Train net output #1: loss = 0.358155 (* 1 = 0.358155 loss)
I0629 11:01:11.875604  2332 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0629 11:01:15.501293  2332 solver.cpp:218] Iteration 11800 (27.5815 iter/s, 3.62562s/100 iters), loss = 0.379623
I0629 11:01:15.501293  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:01:15.501293  2332 solver.cpp:237]     Train net output #1: loss = 0.379623 (* 1 = 0.379623 loss)
I0629 11:01:15.501293  2332 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0629 11:01:19.131803  2332 solver.cpp:218] Iteration 11900 (27.5493 iter/s, 3.62986s/100 iters), loss = 0.307575
I0629 11:01:19.131803  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:01:19.131803  2332 solver.cpp:237]     Train net output #1: loss = 0.307575 (* 1 = 0.307575 loss)
I0629 11:01:19.131803  2332 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0629 11:01:22.595407  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:01:22.737512  2332 solver.cpp:330] Iteration 12000, Testing net (#0)
I0629 11:01:22.737512  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:01:23.559253  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:01:23.590786  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8354
I0629 11:01:23.590786  2332 solver.cpp:397]     Test net output #1: loss = 0.484184 (* 1 = 0.484184 loss)
I0629 11:01:23.624311  2332 solver.cpp:218] Iteration 12000 (22.2587 iter/s, 4.49263s/100 iters), loss = 0.302679
I0629 11:01:23.624311  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:01:23.624311  2332 solver.cpp:237]     Train net output #1: loss = 0.30268 (* 1 = 0.30268 loss)
I0629 11:01:23.624311  2332 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0629 11:01:27.257145  2332 solver.cpp:218] Iteration 12100 (27.535 iter/s, 3.63175s/100 iters), loss = 0.343508
I0629 11:01:27.257145  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:01:27.257145  2332 solver.cpp:237]     Train net output #1: loss = 0.343508 (* 1 = 0.343508 loss)
I0629 11:01:27.257145  2332 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0629 11:01:30.889642  2332 solver.cpp:218] Iteration 12200 (27.5318 iter/s, 3.63216s/100 iters), loss = 0.389117
I0629 11:01:30.889642  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:01:30.889642  2332 solver.cpp:237]     Train net output #1: loss = 0.389118 (* 1 = 0.389118 loss)
I0629 11:01:30.889642  2332 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0629 11:01:34.518378  2332 solver.cpp:218] Iteration 12300 (27.5602 iter/s, 3.62842s/100 iters), loss = 0.36689
I0629 11:01:34.518378  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:01:34.518378  2332 solver.cpp:237]     Train net output #1: loss = 0.36689 (* 1 = 0.36689 loss)
I0629 11:01:34.518378  2332 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0629 11:01:38.146093  2332 solver.cpp:218] Iteration 12400 (27.5621 iter/s, 3.62816s/100 iters), loss = 0.325083
I0629 11:01:38.146093  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:01:38.146093  2332 solver.cpp:237]     Train net output #1: loss = 0.325083 (* 1 = 0.325083 loss)
I0629 11:01:38.146093  2332 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0629 11:01:41.601610  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:01:41.743715  2332 solver.cpp:330] Iteration 12500, Testing net (#0)
I0629 11:01:41.743715  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:01:42.565394  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:01:42.596429  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8356
I0629 11:01:42.596429  2332 solver.cpp:397]     Test net output #1: loss = 0.490965 (* 1 = 0.490965 loss)
I0629 11:01:42.630453  2332 solver.cpp:218] Iteration 12500 (22.3021 iter/s, 4.48389s/100 iters), loss = 0.400151
I0629 11:01:42.630453  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0629 11:01:42.630453  2332 solver.cpp:237]     Train net output #1: loss = 0.400151 (* 1 = 0.400151 loss)
I0629 11:01:42.630453  2332 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0629 11:01:46.256184  2332 solver.cpp:218] Iteration 12600 (27.5883 iter/s, 3.62473s/100 iters), loss = 0.268134
I0629 11:01:46.256184  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:01:46.256184  2332 solver.cpp:237]     Train net output #1: loss = 0.268134 (* 1 = 0.268134 loss)
I0629 11:01:46.256184  2332 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0629 11:01:49.886466  2332 solver.cpp:218] Iteration 12700 (27.5484 iter/s, 3.62997s/100 iters), loss = 0.299807
I0629 11:01:49.886466  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:01:49.886466  2332 solver.cpp:237]     Train net output #1: loss = 0.299807 (* 1 = 0.299807 loss)
I0629 11:01:49.886466  2332 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0629 11:01:53.513173  2332 solver.cpp:218] Iteration 12800 (27.5764 iter/s, 3.62628s/100 iters), loss = 0.38676
I0629 11:01:53.513173  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:01:53.513173  2332 solver.cpp:237]     Train net output #1: loss = 0.38676 (* 1 = 0.38676 loss)
I0629 11:01:53.513173  2332 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0629 11:01:57.150653  2332 solver.cpp:218] Iteration 12900 (27.4874 iter/s, 3.63804s/100 iters), loss = 0.363319
I0629 11:01:57.150653  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:01:57.151654  2332 solver.cpp:237]     Train net output #1: loss = 0.363319 (* 1 = 0.363319 loss)
I0629 11:01:57.151654  2332 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0629 11:02:00.602246  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:02:00.744349  2332 solver.cpp:330] Iteration 13000, Testing net (#0)
I0629 11:02:00.744349  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:02:01.568992  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:02:01.599016  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8264
I0629 11:02:01.600018  2332 solver.cpp:397]     Test net output #1: loss = 0.518097 (* 1 = 0.518097 loss)
I0629 11:02:01.634042  2332 solver.cpp:218] Iteration 13000 (22.3095 iter/s, 4.48239s/100 iters), loss = 0.296777
I0629 11:02:01.634042  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:02:01.634042  2332 solver.cpp:237]     Train net output #1: loss = 0.296777 (* 1 = 0.296777 loss)
I0629 11:02:01.634042  2332 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0629 11:02:05.257807  2332 solver.cpp:218] Iteration 13100 (27.5939 iter/s, 3.62399s/100 iters), loss = 0.366535
I0629 11:02:05.257807  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:02:05.257807  2332 solver.cpp:237]     Train net output #1: loss = 0.366535 (* 1 = 0.366535 loss)
I0629 11:02:05.257807  2332 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0629 11:02:08.880738  2332 solver.cpp:218] Iteration 13200 (27.6084 iter/s, 3.62208s/100 iters), loss = 0.365091
I0629 11:02:08.880738  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:02:08.880738  2332 solver.cpp:237]     Train net output #1: loss = 0.365091 (* 1 = 0.365091 loss)
I0629 11:02:08.880738  2332 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0629 11:02:12.509546  2332 solver.cpp:218] Iteration 13300 (27.5592 iter/s, 3.62856s/100 iters), loss = 0.34607
I0629 11:02:12.509546  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:02:12.509546  2332 solver.cpp:237]     Train net output #1: loss = 0.34607 (* 1 = 0.34607 loss)
I0629 11:02:12.509546  2332 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0629 11:02:16.146821  2332 solver.cpp:218] Iteration 13400 (27.4967 iter/s, 3.6368s/100 iters), loss = 0.3121
I0629 11:02:16.146821  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:02:16.146821  2332 solver.cpp:237]     Train net output #1: loss = 0.3121 (* 1 = 0.3121 loss)
I0629 11:02:16.146821  2332 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0629 11:02:19.605924  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:02:19.748028  2332 solver.cpp:330] Iteration 13500, Testing net (#0)
I0629 11:02:19.748028  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:02:20.576544  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:02:20.599563  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8122
I0629 11:02:20.599563  2332 solver.cpp:397]     Test net output #1: loss = 0.546691 (* 1 = 0.546691 loss)
I0629 11:02:20.634588  2332 solver.cpp:218] Iteration 13500 (22.2863 iter/s, 4.48707s/100 iters), loss = 0.312147
I0629 11:02:20.634588  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:02:20.634588  2332 solver.cpp:237]     Train net output #1: loss = 0.312147 (* 1 = 0.312147 loss)
I0629 11:02:20.634588  2332 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0629 11:02:24.261518  2332 solver.cpp:218] Iteration 13600 (27.5725 iter/s, 3.6268s/100 iters), loss = 0.222538
I0629 11:02:24.261518  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:02:24.261518  2332 solver.cpp:237]     Train net output #1: loss = 0.222538 (* 1 = 0.222538 loss)
I0629 11:02:24.261518  2332 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0629 11:02:27.886013  2332 solver.cpp:218] Iteration 13700 (27.5876 iter/s, 3.62482s/100 iters), loss = 0.360812
I0629 11:02:27.886013  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:02:27.886013  2332 solver.cpp:237]     Train net output #1: loss = 0.360812 (* 1 = 0.360812 loss)
I0629 11:02:27.886013  2332 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0629 11:02:31.527706  2332 solver.cpp:218] Iteration 13800 (27.4681 iter/s, 3.64058s/100 iters), loss = 0.47359
I0629 11:02:31.527706  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 11:02:31.527706  2332 solver.cpp:237]     Train net output #1: loss = 0.473591 (* 1 = 0.473591 loss)
I0629 11:02:31.527706  2332 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0629 11:02:35.158540  2332 solver.cpp:218] Iteration 13900 (27.5411 iter/s, 3.63093s/100 iters), loss = 0.352472
I0629 11:02:35.158540  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0629 11:02:35.158540  2332 solver.cpp:237]     Train net output #1: loss = 0.352473 (* 1 = 0.352473 loss)
I0629 11:02:35.158540  2332 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0629 11:02:38.618137  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:02:38.761241  2332 solver.cpp:330] Iteration 14000, Testing net (#0)
I0629 11:02:38.761241  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:02:39.579851  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:02:39.611378  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8281
I0629 11:02:39.611876  2332 solver.cpp:397]     Test net output #1: loss = 0.505929 (* 1 = 0.505929 loss)
I0629 11:02:39.645902  2332 solver.cpp:218] Iteration 14000 (22.287 iter/s, 4.48692s/100 iters), loss = 0.393451
I0629 11:02:39.645902  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0629 11:02:39.645902  2332 solver.cpp:237]     Train net output #1: loss = 0.393451 (* 1 = 0.393451 loss)
I0629 11:02:39.645902  2332 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0629 11:02:43.281505  2332 solver.cpp:218] Iteration 14100 (27.5057 iter/s, 3.63561s/100 iters), loss = 0.239064
I0629 11:02:43.281505  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:02:43.281505  2332 solver.cpp:237]     Train net output #1: loss = 0.239064 (* 1 = 0.239064 loss)
I0629 11:02:43.281505  2332 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0629 11:02:46.917232  2332 solver.cpp:218] Iteration 14200 (27.5122 iter/s, 3.63475s/100 iters), loss = 0.294516
I0629 11:02:46.917232  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:02:46.917232  2332 solver.cpp:237]     Train net output #1: loss = 0.294516 (* 1 = 0.294516 loss)
I0629 11:02:46.917232  2332 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0629 11:02:50.572558  2332 solver.cpp:218] Iteration 14300 (27.3546 iter/s, 3.65569s/100 iters), loss = 0.334092
I0629 11:02:50.572558  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:02:50.572558  2332 solver.cpp:237]     Train net output #1: loss = 0.334092 (* 1 = 0.334092 loss)
I0629 11:02:50.572558  2332 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0629 11:02:54.214149  2332 solver.cpp:218] Iteration 14400 (27.4674 iter/s, 3.64068s/100 iters), loss = 0.333461
I0629 11:02:54.214149  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:02:54.214149  2332 solver.cpp:237]     Train net output #1: loss = 0.333461 (* 1 = 0.333461 loss)
I0629 11:02:54.214149  2332 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0629 11:02:57.662703  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:02:57.803805  2332 solver.cpp:330] Iteration 14500, Testing net (#0)
I0629 11:02:57.804806  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:02:58.623036  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:02:58.653559  2332 solver.cpp:397]     Test net output #0: accuracy = 0.811
I0629 11:02:58.654559  2332 solver.cpp:397]     Test net output #1: loss = 0.568291 (* 1 = 0.568291 loss)
I0629 11:02:58.688583  2332 solver.cpp:218] Iteration 14500 (22.3483 iter/s, 4.47461s/100 iters), loss = 0.430201
I0629 11:02:58.688583  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0629 11:02:58.688583  2332 solver.cpp:237]     Train net output #1: loss = 0.430201 (* 1 = 0.430201 loss)
I0629 11:02:58.688583  2332 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0629 11:03:02.337008  2332 solver.cpp:218] Iteration 14600 (27.4138 iter/s, 3.6478s/100 iters), loss = 0.25931
I0629 11:03:02.337008  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:03:02.337008  2332 solver.cpp:237]     Train net output #1: loss = 0.25931 (* 1 = 0.25931 loss)
I0629 11:03:02.337008  2332 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0629 11:03:05.962757  2332 solver.cpp:218] Iteration 14700 (27.5848 iter/s, 3.62518s/100 iters), loss = 0.394828
I0629 11:03:05.962757  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:03:05.962757  2332 solver.cpp:237]     Train net output #1: loss = 0.394828 (* 1 = 0.394828 loss)
I0629 11:03:05.962757  2332 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0629 11:03:09.593430  2332 solver.cpp:218] Iteration 14800 (27.5411 iter/s, 3.63094s/100 iters), loss = 0.473023
I0629 11:03:09.593430  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:03:09.593430  2332 solver.cpp:237]     Train net output #1: loss = 0.473023 (* 1 = 0.473023 loss)
I0629 11:03:09.593430  2332 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0629 11:03:13.223202  2332 solver.cpp:218] Iteration 14900 (27.5556 iter/s, 3.62902s/100 iters), loss = 0.336133
I0629 11:03:13.223702  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:03:13.223702  2332 solver.cpp:237]     Train net output #1: loss = 0.336133 (* 1 = 0.336133 loss)
I0629 11:03:13.223702  2332 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0629 11:03:16.679463  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:03:16.821566  2332 solver.cpp:330] Iteration 15000, Testing net (#0)
I0629 11:03:16.822568  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:03:17.640311  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:03:17.671334  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8229
I0629 11:03:17.671334  2332 solver.cpp:397]     Test net output #1: loss = 0.519847 (* 1 = 0.519847 loss)
I0629 11:03:17.705358  2332 solver.cpp:218] Iteration 15000 (22.312 iter/s, 4.48189s/100 iters), loss = 0.291295
I0629 11:03:17.705358  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:03:17.705358  2332 solver.cpp:237]     Train net output #1: loss = 0.291295 (* 1 = 0.291295 loss)
I0629 11:03:17.705358  2332 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0629 11:03:21.340652  2332 solver.cpp:218] Iteration 15100 (27.5128 iter/s, 3.63468s/100 iters), loss = 0.269947
I0629 11:03:21.340652  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:03:21.340652  2332 solver.cpp:237]     Train net output #1: loss = 0.269947 (* 1 = 0.269947 loss)
I0629 11:03:21.340652  2332 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0629 11:03:24.964774  2332 solver.cpp:218] Iteration 15200 (27.5947 iter/s, 3.62389s/100 iters), loss = 0.32691
I0629 11:03:24.964774  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:03:24.964774  2332 solver.cpp:237]     Train net output #1: loss = 0.326911 (* 1 = 0.326911 loss)
I0629 11:03:24.964774  2332 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0629 11:03:28.595506  2332 solver.cpp:218] Iteration 15300 (27.5468 iter/s, 3.63019s/100 iters), loss = 0.340327
I0629 11:03:28.595506  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:03:28.595506  2332 solver.cpp:237]     Train net output #1: loss = 0.340327 (* 1 = 0.340327 loss)
I0629 11:03:28.595506  2332 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0629 11:03:32.224246  2332 solver.cpp:218] Iteration 15400 (27.5592 iter/s, 3.62855s/100 iters), loss = 0.240671
I0629 11:03:32.224246  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:03:32.224246  2332 solver.cpp:237]     Train net output #1: loss = 0.240671 (* 1 = 0.240671 loss)
I0629 11:03:32.224246  2332 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0629 11:03:35.677227  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:03:35.819375  2332 solver.cpp:330] Iteration 15500, Testing net (#0)
I0629 11:03:35.819375  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:03:36.638283  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:03:36.669309  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8316
I0629 11:03:36.669309  2332 solver.cpp:397]     Test net output #1: loss = 0.496898 (* 1 = 0.496898 loss)
I0629 11:03:36.703346  2332 solver.cpp:218] Iteration 15500 (22.326 iter/s, 4.47909s/100 iters), loss = 0.321134
I0629 11:03:36.703346  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:03:36.703346  2332 solver.cpp:237]     Train net output #1: loss = 0.321134 (* 1 = 0.321134 loss)
I0629 11:03:36.703346  2332 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0629 11:03:40.333277  2332 solver.cpp:218] Iteration 15600 (27.5548 iter/s, 3.62913s/100 iters), loss = 0.273687
I0629 11:03:40.333277  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:03:40.333277  2332 solver.cpp:237]     Train net output #1: loss = 0.273687 (* 1 = 0.273687 loss)
I0629 11:03:40.333277  2332 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0629 11:03:43.954048  2332 solver.cpp:218] Iteration 15700 (27.6194 iter/s, 3.62065s/100 iters), loss = 0.389119
I0629 11:03:43.954048  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:03:43.954048  2332 solver.cpp:237]     Train net output #1: loss = 0.389119 (* 1 = 0.389119 loss)
I0629 11:03:43.954048  2332 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0629 11:03:47.576463  2332 solver.cpp:218] Iteration 15800 (27.6041 iter/s, 3.62265s/100 iters), loss = 0.40091
I0629 11:03:47.576463  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:03:47.577463  2332 solver.cpp:237]     Train net output #1: loss = 0.40091 (* 1 = 0.40091 loss)
I0629 11:03:47.577463  2332 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0629 11:03:51.202837  2332 solver.cpp:218] Iteration 15900 (27.5791 iter/s, 3.62593s/100 iters), loss = 0.269048
I0629 11:03:51.202837  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:03:51.202837  2332 solver.cpp:237]     Train net output #1: loss = 0.269048 (* 1 = 0.269048 loss)
I0629 11:03:51.202837  2332 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0629 11:03:54.650831  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:03:54.792100  2332 solver.cpp:330] Iteration 16000, Testing net (#0)
I0629 11:03:54.792100  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:03:55.609007  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:03:55.640015  2332 solver.cpp:397]     Test net output #0: accuracy = 0.829
I0629 11:03:55.640015  2332 solver.cpp:397]     Test net output #1: loss = 0.517286 (* 1 = 0.517286 loss)
I0629 11:03:55.674062  2332 solver.cpp:218] Iteration 16000 (22.3673 iter/s, 4.4708s/100 iters), loss = 0.359688
I0629 11:03:55.674062  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:03:55.674062  2332 solver.cpp:237]     Train net output #1: loss = 0.359688 (* 1 = 0.359688 loss)
I0629 11:03:55.674062  2332 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0629 11:03:59.306188  2332 solver.cpp:218] Iteration 16100 (27.5383 iter/s, 3.63131s/100 iters), loss = 0.227402
I0629 11:03:59.306188  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:03:59.306188  2332 solver.cpp:237]     Train net output #1: loss = 0.227402 (* 1 = 0.227402 loss)
I0629 11:03:59.306188  2332 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0629 11:04:02.941608  2332 solver.cpp:218] Iteration 16200 (27.51 iter/s, 3.63504s/100 iters), loss = 0.367273
I0629 11:04:02.941608  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:04:02.941608  2332 solver.cpp:237]     Train net output #1: loss = 0.367273 (* 1 = 0.367273 loss)
I0629 11:04:02.941608  2332 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0629 11:04:06.567206  2332 solver.cpp:218] Iteration 16300 (27.5788 iter/s, 3.62598s/100 iters), loss = 0.311971
I0629 11:04:06.567206  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:04:06.567206  2332 solver.cpp:237]     Train net output #1: loss = 0.311971 (* 1 = 0.311971 loss)
I0629 11:04:06.567206  2332 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0629 11:04:10.206667  2332 solver.cpp:218] Iteration 16400 (27.481 iter/s, 3.63887s/100 iters), loss = 0.229214
I0629 11:04:10.206667  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:04:10.206667  2332 solver.cpp:237]     Train net output #1: loss = 0.229214 (* 1 = 0.229214 loss)
I0629 11:04:10.206667  2332 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0629 11:04:13.660567  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:04:13.802634  2332 solver.cpp:330] Iteration 16500, Testing net (#0)
I0629 11:04:13.802634  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:04:14.621027  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:04:14.653036  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8342
I0629 11:04:14.653036  2332 solver.cpp:397]     Test net output #1: loss = 0.506456 (* 1 = 0.506456 loss)
I0629 11:04:14.687072  2332 solver.cpp:218] Iteration 16500 (22.3228 iter/s, 4.47973s/100 iters), loss = 0.231905
I0629 11:04:14.687072  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:04:14.687072  2332 solver.cpp:237]     Train net output #1: loss = 0.231905 (* 1 = 0.231905 loss)
I0629 11:04:14.687072  2332 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0629 11:04:18.320708  2332 solver.cpp:218] Iteration 16600 (27.5192 iter/s, 3.63383s/100 iters), loss = 0.267128
I0629 11:04:18.320708  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:04:18.320708  2332 solver.cpp:237]     Train net output #1: loss = 0.267128 (* 1 = 0.267128 loss)
I0629 11:04:18.320708  2332 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0629 11:04:21.940824  2332 solver.cpp:218] Iteration 16700 (27.6292 iter/s, 3.61935s/100 iters), loss = 0.32996
I0629 11:04:21.940824  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:04:21.940824  2332 solver.cpp:237]     Train net output #1: loss = 0.329961 (* 1 = 0.329961 loss)
I0629 11:04:21.940824  2332 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0629 11:04:25.562948  2332 solver.cpp:218] Iteration 16800 (27.6075 iter/s, 3.62221s/100 iters), loss = 0.409894
I0629 11:04:25.562948  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0629 11:04:25.562948  2332 solver.cpp:237]     Train net output #1: loss = 0.409894 (* 1 = 0.409894 loss)
I0629 11:04:25.562948  2332 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0629 11:04:29.189671  2332 solver.cpp:218] Iteration 16900 (27.5803 iter/s, 3.62578s/100 iters), loss = 0.270963
I0629 11:04:29.189671  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:04:29.189671  2332 solver.cpp:237]     Train net output #1: loss = 0.270963 (* 1 = 0.270963 loss)
I0629 11:04:29.189671  2332 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0629 11:04:32.643726  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:04:32.786568  2332 solver.cpp:330] Iteration 17000, Testing net (#0)
I0629 11:04:32.786568  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:04:33.604372  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:04:33.634889  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8309
I0629 11:04:33.634889  2332 solver.cpp:397]     Test net output #1: loss = 0.512514 (* 1 = 0.512514 loss)
I0629 11:04:33.669927  2332 solver.cpp:218] Iteration 17000 (22.3226 iter/s, 4.47976s/100 iters), loss = 0.343138
I0629 11:04:33.669927  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:04:33.669927  2332 solver.cpp:237]     Train net output #1: loss = 0.343138 (* 1 = 0.343138 loss)
I0629 11:04:33.669927  2332 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0629 11:04:37.294780  2332 solver.cpp:218] Iteration 17100 (27.5909 iter/s, 3.62438s/100 iters), loss = 0.295327
I0629 11:04:37.294780  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:04:37.294780  2332 solver.cpp:237]     Train net output #1: loss = 0.295327 (* 1 = 0.295327 loss)
I0629 11:04:37.294780  2332 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0629 11:04:40.922508  2332 solver.cpp:218] Iteration 17200 (27.5658 iter/s, 3.62768s/100 iters), loss = 0.298783
I0629 11:04:40.922508  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:04:40.922508  2332 solver.cpp:237]     Train net output #1: loss = 0.298783 (* 1 = 0.298783 loss)
I0629 11:04:40.922508  2332 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0629 11:04:44.560241  2332 solver.cpp:218] Iteration 17300 (27.4885 iter/s, 3.63788s/100 iters), loss = 0.365869
I0629 11:04:44.560241  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:04:44.560241  2332 solver.cpp:237]     Train net output #1: loss = 0.365869 (* 1 = 0.365869 loss)
I0629 11:04:44.560241  2332 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0629 11:04:48.179416  2332 solver.cpp:218] Iteration 17400 (27.6354 iter/s, 3.61855s/100 iters), loss = 0.276032
I0629 11:04:48.179918  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:04:48.179918  2332 solver.cpp:237]     Train net output #1: loss = 0.276032 (* 1 = 0.276032 loss)
I0629 11:04:48.179918  2332 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0629 11:04:51.631865  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:04:51.773969  2332 solver.cpp:330] Iteration 17500, Testing net (#0)
I0629 11:04:51.773969  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:04:52.593186  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:04:52.624495  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8245
I0629 11:04:52.624495  2332 solver.cpp:397]     Test net output #1: loss = 0.556003 (* 1 = 0.556003 loss)
I0629 11:04:52.658531  2332 solver.cpp:218] Iteration 17500 (22.3269 iter/s, 4.47889s/100 iters), loss = 0.311308
I0629 11:04:52.658531  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:04:52.658531  2332 solver.cpp:237]     Train net output #1: loss = 0.311308 (* 1 = 0.311308 loss)
I0629 11:04:52.658531  2332 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0629 11:04:56.277014  2332 solver.cpp:218] Iteration 17600 (27.6396 iter/s, 3.618s/100 iters), loss = 0.213023
I0629 11:04:56.277014  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:04:56.277014  2332 solver.cpp:237]     Train net output #1: loss = 0.213024 (* 1 = 0.213024 loss)
I0629 11:04:56.277014  2332 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0629 11:04:59.898298  2332 solver.cpp:218] Iteration 17700 (27.6183 iter/s, 3.62079s/100 iters), loss = 0.269745
I0629 11:04:59.898298  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:04:59.898298  2332 solver.cpp:237]     Train net output #1: loss = 0.269746 (* 1 = 0.269746 loss)
I0629 11:04:59.898298  2332 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0629 11:05:03.523591  2332 solver.cpp:218] Iteration 17800 (27.5811 iter/s, 3.62567s/100 iters), loss = 0.36627
I0629 11:05:03.524579  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:05:03.524579  2332 solver.cpp:237]     Train net output #1: loss = 0.36627 (* 1 = 0.36627 loss)
I0629 11:05:03.524579  2332 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0629 11:05:07.148712  2332 solver.cpp:218] Iteration 17900 (27.5945 iter/s, 3.62392s/100 iters), loss = 0.317867
I0629 11:05:07.148712  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:05:07.148712  2332 solver.cpp:237]     Train net output #1: loss = 0.317867 (* 1 = 0.317867 loss)
I0629 11:05:07.148712  2332 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0629 11:05:10.593266  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:05:10.734870  2332 solver.cpp:330] Iteration 18000, Testing net (#0)
I0629 11:05:10.734870  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:05:11.554414  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:05:11.585429  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8371
I0629 11:05:11.585429  2332 solver.cpp:397]     Test net output #1: loss = 0.498784 (* 1 = 0.498784 loss)
I0629 11:05:11.619510  2332 solver.cpp:218] Iteration 18000 (22.3675 iter/s, 4.47077s/100 iters), loss = 0.319512
I0629 11:05:11.619510  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:05:11.619510  2332 solver.cpp:237]     Train net output #1: loss = 0.319512 (* 1 = 0.319512 loss)
I0629 11:05:11.619510  2332 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0629 11:05:15.255641  2332 solver.cpp:218] Iteration 18100 (27.5068 iter/s, 3.63547s/100 iters), loss = 0.299948
I0629 11:05:15.255641  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:05:15.255641  2332 solver.cpp:237]     Train net output #1: loss = 0.299948 (* 1 = 0.299948 loss)
I0629 11:05:15.255641  2332 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0629 11:05:18.903162  2332 solver.cpp:218] Iteration 18200 (27.419 iter/s, 3.64711s/100 iters), loss = 0.378026
I0629 11:05:18.903162  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:05:18.903162  2332 solver.cpp:237]     Train net output #1: loss = 0.378027 (* 1 = 0.378027 loss)
I0629 11:05:18.903162  2332 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0629 11:05:22.528036  2332 solver.cpp:218] Iteration 18300 (27.5827 iter/s, 3.62546s/100 iters), loss = 0.388859
I0629 11:05:22.529026  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:05:22.529026  2332 solver.cpp:237]     Train net output #1: loss = 0.388859 (* 1 = 0.388859 loss)
I0629 11:05:22.529026  2332 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0629 11:05:26.153844  2332 solver.cpp:218] Iteration 18400 (27.59 iter/s, 3.6245s/100 iters), loss = 0.329357
I0629 11:05:26.153844  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:05:26.153844  2332 solver.cpp:237]     Train net output #1: loss = 0.329357 (* 1 = 0.329357 loss)
I0629 11:05:26.153844  2332 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0629 11:05:29.618062  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:05:29.759279  2332 solver.cpp:330] Iteration 18500, Testing net (#0)
I0629 11:05:29.759279  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:05:30.578464  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:05:30.609422  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8323
I0629 11:05:30.609422  2332 solver.cpp:397]     Test net output #1: loss = 0.496534 (* 1 = 0.496534 loss)
I0629 11:05:30.643460  2332 solver.cpp:218] Iteration 18500 (22.2712 iter/s, 4.4901s/100 iters), loss = 0.268483
I0629 11:05:30.643460  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:05:30.643460  2332 solver.cpp:237]     Train net output #1: loss = 0.268483 (* 1 = 0.268483 loss)
I0629 11:05:30.644448  2332 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0629 11:05:34.264209  2332 solver.cpp:218] Iteration 18600 (27.6283 iter/s, 3.61948s/100 iters), loss = 0.242476
I0629 11:05:34.264209  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:05:34.264209  2332 solver.cpp:237]     Train net output #1: loss = 0.242476 (* 1 = 0.242476 loss)
I0629 11:05:34.264209  2332 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0629 11:05:37.892133  2332 solver.cpp:218] Iteration 18700 (27.5616 iter/s, 3.62824s/100 iters), loss = 0.31118
I0629 11:05:37.892133  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:05:37.892133  2332 solver.cpp:237]     Train net output #1: loss = 0.311181 (* 1 = 0.311181 loss)
I0629 11:05:37.892133  2332 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0629 11:05:41.521749  2332 solver.cpp:218] Iteration 18800 (27.5572 iter/s, 3.62882s/100 iters), loss = 0.373065
I0629 11:05:41.521749  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:05:41.521749  2332 solver.cpp:237]     Train net output #1: loss = 0.373066 (* 1 = 0.373066 loss)
I0629 11:05:41.521749  2332 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0629 11:05:45.151113  2332 solver.cpp:218] Iteration 18900 (27.5531 iter/s, 3.62936s/100 iters), loss = 0.308342
I0629 11:05:45.151113  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:05:45.151113  2332 solver.cpp:237]     Train net output #1: loss = 0.308342 (* 1 = 0.308342 loss)
I0629 11:05:45.151113  2332 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0629 11:05:48.611126  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:05:48.754230  2332 solver.cpp:330] Iteration 19000, Testing net (#0)
I0629 11:05:48.754230  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:05:49.581852  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:05:49.612875  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8489
I0629 11:05:49.612875  2332 solver.cpp:397]     Test net output #1: loss = 0.449228 (* 1 = 0.449228 loss)
I0629 11:05:49.646911  2332 solver.cpp:218] Iteration 19000 (22.2446 iter/s, 4.49548s/100 iters), loss = 0.282522
I0629 11:05:49.646911  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:05:49.646911  2332 solver.cpp:237]     Train net output #1: loss = 0.282522 (* 1 = 0.282522 loss)
I0629 11:05:49.646911  2332 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0629 11:05:53.281682  2332 solver.cpp:218] Iteration 19100 (27.5143 iter/s, 3.63448s/100 iters), loss = 0.313957
I0629 11:05:53.281682  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:05:53.281682  2332 solver.cpp:237]     Train net output #1: loss = 0.313957 (* 1 = 0.313957 loss)
I0629 11:05:53.281682  2332 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0629 11:05:56.909423  2332 solver.cpp:218] Iteration 19200 (27.5668 iter/s, 3.62755s/100 iters), loss = 0.316566
I0629 11:05:56.909423  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:05:56.909423  2332 solver.cpp:237]     Train net output #1: loss = 0.316566 (* 1 = 0.316566 loss)
I0629 11:05:56.909423  2332 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0629 11:06:00.541189  2332 solver.cpp:218] Iteration 19300 (27.5401 iter/s, 3.63107s/100 iters), loss = 0.338155
I0629 11:06:00.541189  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:06:00.541189  2332 solver.cpp:237]     Train net output #1: loss = 0.338156 (* 1 = 0.338156 loss)
I0629 11:06:00.541189  2332 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0629 11:06:04.176057  2332 solver.cpp:218] Iteration 19400 (27.515 iter/s, 3.63438s/100 iters), loss = 0.390234
I0629 11:06:04.176057  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:06:04.176057  2332 solver.cpp:237]     Train net output #1: loss = 0.390234 (* 1 = 0.390234 loss)
I0629 11:06:04.176057  2332 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0629 11:06:07.626077  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:06:07.768182  2332 solver.cpp:330] Iteration 19500, Testing net (#0)
I0629 11:06:07.768182  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:06:08.587575  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:06:08.618597  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8098
I0629 11:06:08.618597  2332 solver.cpp:397]     Test net output #1: loss = 0.564306 (* 1 = 0.564306 loss)
I0629 11:06:08.652621  2332 solver.cpp:218] Iteration 19500 (22.3389 iter/s, 4.47649s/100 iters), loss = 0.209546
I0629 11:06:08.652621  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:06:08.652621  2332 solver.cpp:237]     Train net output #1: loss = 0.209546 (* 1 = 0.209546 loss)
I0629 11:06:08.652621  2332 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0629 11:06:12.287349  2332 solver.cpp:218] Iteration 19600 (27.5134 iter/s, 3.63459s/100 iters), loss = 0.296673
I0629 11:06:12.287349  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:06:12.287349  2332 solver.cpp:237]     Train net output #1: loss = 0.296673 (* 1 = 0.296673 loss)
I0629 11:06:12.287349  2332 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0629 11:06:15.925411  2332 solver.cpp:218] Iteration 19700 (27.4899 iter/s, 3.6377s/100 iters), loss = 0.265166
I0629 11:06:15.925411  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:06:15.925411  2332 solver.cpp:237]     Train net output #1: loss = 0.265166 (* 1 = 0.265166 loss)
I0629 11:06:15.925411  2332 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0629 11:06:19.564332  2332 solver.cpp:218] Iteration 19800 (27.484 iter/s, 3.63848s/100 iters), loss = 0.372934
I0629 11:06:19.564332  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:06:19.564332  2332 solver.cpp:237]     Train net output #1: loss = 0.372935 (* 1 = 0.372935 loss)
I0629 11:06:19.564332  2332 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0629 11:06:23.215214  2332 solver.cpp:218] Iteration 19900 (27.398 iter/s, 3.64991s/100 iters), loss = 0.319949
I0629 11:06:23.215214  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:06:23.215214  2332 solver.cpp:237]     Train net output #1: loss = 0.319949 (* 1 = 0.319949 loss)
I0629 11:06:23.215214  2332 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0629 11:06:26.660363  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:06:26.802608  2332 solver.cpp:330] Iteration 20000, Testing net (#0)
I0629 11:06:26.802608  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:06:27.624905  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:06:27.655927  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8303
I0629 11:06:27.655927  2332 solver.cpp:397]     Test net output #1: loss = 0.509504 (* 1 = 0.509504 loss)
I0629 11:06:27.690466  2332 solver.cpp:218] Iteration 20000 (22.3466 iter/s, 4.47496s/100 iters), loss = 0.297267
I0629 11:06:27.690466  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:06:27.690466  2332 solver.cpp:237]     Train net output #1: loss = 0.297267 (* 1 = 0.297267 loss)
I0629 11:06:27.690466  2332 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0629 11:06:31.309018  2332 solver.cpp:218] Iteration 20100 (27.6355 iter/s, 3.61854s/100 iters), loss = 0.182975
I0629 11:06:31.309018  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:06:31.309018  2332 solver.cpp:237]     Train net output #1: loss = 0.182975 (* 1 = 0.182975 loss)
I0629 11:06:31.309018  2332 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0629 11:06:34.925552  2332 solver.cpp:218] Iteration 20200 (27.6519 iter/s, 3.61639s/100 iters), loss = 0.412066
I0629 11:06:34.925552  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:06:34.925552  2332 solver.cpp:237]     Train net output #1: loss = 0.412066 (* 1 = 0.412066 loss)
I0629 11:06:34.925552  2332 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0629 11:06:38.551349  2332 solver.cpp:218] Iteration 20300 (27.5874 iter/s, 3.62485s/100 iters), loss = 0.32501
I0629 11:06:38.551349  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:06:38.551349  2332 solver.cpp:237]     Train net output #1: loss = 0.325011 (* 1 = 0.325011 loss)
I0629 11:06:38.551349  2332 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0629 11:06:42.181460  2332 solver.cpp:218] Iteration 20400 (27.5474 iter/s, 3.6301s/100 iters), loss = 0.33179
I0629 11:06:42.181460  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:06:42.181460  2332 solver.cpp:237]     Train net output #1: loss = 0.33179 (* 1 = 0.33179 loss)
I0629 11:06:42.181460  2332 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0629 11:06:45.639859  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:06:45.781965  2332 solver.cpp:330] Iteration 20500, Testing net (#0)
I0629 11:06:45.781965  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:06:46.601681  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:06:46.631999  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8305
I0629 11:06:46.631999  2332 solver.cpp:397]     Test net output #1: loss = 0.5039 (* 1 = 0.5039 loss)
I0629 11:06:46.667021  2332 solver.cpp:218] Iteration 20500 (22.2992 iter/s, 4.48446s/100 iters), loss = 0.261805
I0629 11:06:46.667021  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:06:46.667021  2332 solver.cpp:237]     Train net output #1: loss = 0.261805 (* 1 = 0.261805 loss)
I0629 11:06:46.667021  2332 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0629 11:06:50.294137  2332 solver.cpp:218] Iteration 20600 (27.5685 iter/s, 3.62732s/100 iters), loss = 0.230819
I0629 11:06:50.294137  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:06:50.294137  2332 solver.cpp:237]     Train net output #1: loss = 0.23082 (* 1 = 0.23082 loss)
I0629 11:06:50.294137  2332 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0629 11:06:53.923791  2332 solver.cpp:218] Iteration 20700 (27.5559 iter/s, 3.62899s/100 iters), loss = 0.297414
I0629 11:06:53.923791  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:06:53.923791  2332 solver.cpp:237]     Train net output #1: loss = 0.297414 (* 1 = 0.297414 loss)
I0629 11:06:53.923791  2332 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0629 11:06:57.555853  2332 solver.cpp:218] Iteration 20800 (27.5341 iter/s, 3.63186s/100 iters), loss = 0.219249
I0629 11:06:57.555853  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:06:57.555853  2332 solver.cpp:237]     Train net output #1: loss = 0.219249 (* 1 = 0.219249 loss)
I0629 11:06:57.555853  2332 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0629 11:07:01.188987  2332 solver.cpp:218] Iteration 20900 (27.53 iter/s, 3.6324s/100 iters), loss = 0.324421
I0629 11:07:01.188987  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:07:01.188987  2332 solver.cpp:237]     Train net output #1: loss = 0.324421 (* 1 = 0.324421 loss)
I0629 11:07:01.188987  2332 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0629 11:07:04.645722  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:07:04.787384  2332 solver.cpp:330] Iteration 21000, Testing net (#0)
I0629 11:07:04.787384  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:07:05.612082  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:07:05.646090  2332 solver.cpp:397]     Test net output #0: accuracy = 0.835
I0629 11:07:05.646090  2332 solver.cpp:397]     Test net output #1: loss = 0.482483 (* 1 = 0.482483 loss)
I0629 11:07:05.680131  2332 solver.cpp:218] Iteration 21000 (22.2635 iter/s, 4.49166s/100 iters), loss = 0.297105
I0629 11:07:05.681115  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:07:05.681115  2332 solver.cpp:237]     Train net output #1: loss = 0.297105 (* 1 = 0.297105 loss)
I0629 11:07:05.681115  2332 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0629 11:07:09.312597  2332 solver.cpp:218] Iteration 21100 (27.5393 iter/s, 3.63118s/100 iters), loss = 0.273544
I0629 11:07:09.312597  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:07:09.312597  2332 solver.cpp:237]     Train net output #1: loss = 0.273544 (* 1 = 0.273544 loss)
I0629 11:07:09.312597  2332 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0629 11:07:12.938745  2332 solver.cpp:218] Iteration 21200 (27.5768 iter/s, 3.62623s/100 iters), loss = 0.305994
I0629 11:07:12.938745  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:07:12.938745  2332 solver.cpp:237]     Train net output #1: loss = 0.305994 (* 1 = 0.305994 loss)
I0629 11:07:12.938745  2332 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0629 11:07:16.561556  2332 solver.cpp:218] Iteration 21300 (27.6032 iter/s, 3.62277s/100 iters), loss = 0.282455
I0629 11:07:16.561556  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:07:16.561556  2332 solver.cpp:237]     Train net output #1: loss = 0.282455 (* 1 = 0.282455 loss)
I0629 11:07:16.561556  2332 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0629 11:07:20.189586  2332 solver.cpp:218] Iteration 21400 (27.5683 iter/s, 3.62735s/100 iters), loss = 0.290414
I0629 11:07:20.189586  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:07:20.189586  2332 solver.cpp:237]     Train net output #1: loss = 0.290414 (* 1 = 0.290414 loss)
I0629 11:07:20.189586  2332 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0629 11:07:23.636714  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:07:23.779064  2332 solver.cpp:330] Iteration 21500, Testing net (#0)
I0629 11:07:23.779064  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:07:24.599730  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:07:24.630741  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8417
I0629 11:07:24.630741  2332 solver.cpp:397]     Test net output #1: loss = 0.487231 (* 1 = 0.487231 loss)
I0629 11:07:24.664775  2332 solver.cpp:218] Iteration 21500 (22.3468 iter/s, 4.47492s/100 iters), loss = 0.242463
I0629 11:07:24.665264  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:07:24.665264  2332 solver.cpp:237]     Train net output #1: loss = 0.242463 (* 1 = 0.242463 loss)
I0629 11:07:24.665264  2332 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0629 11:07:28.289278  2332 solver.cpp:218] Iteration 21600 (27.593 iter/s, 3.62411s/100 iters), loss = 0.255709
I0629 11:07:28.289278  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:07:28.289278  2332 solver.cpp:237]     Train net output #1: loss = 0.255709 (* 1 = 0.255709 loss)
I0629 11:07:28.289278  2332 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0629 11:07:31.916267  2332 solver.cpp:218] Iteration 21700 (27.5753 iter/s, 3.62643s/100 iters), loss = 0.355408
I0629 11:07:31.916267  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:07:31.916267  2332 solver.cpp:237]     Train net output #1: loss = 0.355408 (* 1 = 0.355408 loss)
I0629 11:07:31.916267  2332 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0629 11:07:35.545651  2332 solver.cpp:218] Iteration 21800 (27.554 iter/s, 3.62924s/100 iters), loss = 0.30931
I0629 11:07:35.545651  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:07:35.545651  2332 solver.cpp:237]     Train net output #1: loss = 0.30931 (* 1 = 0.30931 loss)
I0629 11:07:35.545651  2332 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0629 11:07:39.203501  2332 solver.cpp:218] Iteration 21900 (27.3434 iter/s, 3.65719s/100 iters), loss = 0.290323
I0629 11:07:39.203501  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:07:39.203501  2332 solver.cpp:237]     Train net output #1: loss = 0.290323 (* 1 = 0.290323 loss)
I0629 11:07:39.203501  2332 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0629 11:07:42.647682  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:07:42.789800  2332 solver.cpp:330] Iteration 22000, Testing net (#0)
I0629 11:07:42.789800  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:07:43.609978  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:07:43.641000  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8239
I0629 11:07:43.641000  2332 solver.cpp:397]     Test net output #1: loss = 0.543503 (* 1 = 0.543503 loss)
I0629 11:07:43.674628  2332 solver.cpp:218] Iteration 22000 (22.3643 iter/s, 4.47142s/100 iters), loss = 0.27685
I0629 11:07:43.674628  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:07:43.674628  2332 solver.cpp:237]     Train net output #1: loss = 0.27685 (* 1 = 0.27685 loss)
I0629 11:07:43.674628  2332 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0629 11:07:47.301513  2332 solver.cpp:218] Iteration 22100 (27.577 iter/s, 3.62621s/100 iters), loss = 0.282804
I0629 11:07:47.301513  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:07:47.301513  2332 solver.cpp:237]     Train net output #1: loss = 0.282805 (* 1 = 0.282805 loss)
I0629 11:07:47.301513  2332 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0629 11:07:50.951746  2332 solver.cpp:218] Iteration 22200 (27.3985 iter/s, 3.64983s/100 iters), loss = 0.278559
I0629 11:07:50.952247  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:07:50.952247  2332 solver.cpp:237]     Train net output #1: loss = 0.27856 (* 1 = 0.27856 loss)
I0629 11:07:50.952247  2332 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0629 11:07:54.583988  2332 solver.cpp:218] Iteration 22300 (27.5316 iter/s, 3.63219s/100 iters), loss = 0.350929
I0629 11:07:54.583988  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:07:54.583988  2332 solver.cpp:237]     Train net output #1: loss = 0.350929 (* 1 = 0.350929 loss)
I0629 11:07:54.583988  2332 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0629 11:07:58.213892  2332 solver.cpp:218] Iteration 22400 (27.5564 iter/s, 3.62893s/100 iters), loss = 0.250863
I0629 11:07:58.213892  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:07:58.213892  2332 solver.cpp:237]     Train net output #1: loss = 0.250863 (* 1 = 0.250863 loss)
I0629 11:07:58.213892  2332 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0629 11:08:01.676684  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:08:01.818789  2332 solver.cpp:330] Iteration 22500, Testing net (#0)
I0629 11:08:01.818789  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:08:02.644417  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:08:02.675940  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8208
I0629 11:08:02.675940  2332 solver.cpp:397]     Test net output #1: loss = 0.550594 (* 1 = 0.550594 loss)
I0629 11:08:02.709466  2332 solver.cpp:218] Iteration 22500 (22.2423 iter/s, 4.49595s/100 iters), loss = 0.269915
I0629 11:08:02.709466  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:08:02.709466  2332 solver.cpp:237]     Train net output #1: loss = 0.269915 (* 1 = 0.269915 loss)
I0629 11:08:02.709466  2332 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0629 11:08:06.345970  2332 solver.cpp:218] Iteration 22600 (27.5076 iter/s, 3.63535s/100 iters), loss = 0.286
I0629 11:08:06.345970  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:08:06.345970  2332 solver.cpp:237]     Train net output #1: loss = 0.286 (* 1 = 0.286 loss)
I0629 11:08:06.345970  2332 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0629 11:08:09.980897  2332 solver.cpp:218] Iteration 22700 (27.5126 iter/s, 3.6347s/100 iters), loss = 0.367867
I0629 11:08:09.980897  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:08:09.980897  2332 solver.cpp:237]     Train net output #1: loss = 0.367868 (* 1 = 0.367868 loss)
I0629 11:08:09.980897  2332 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0629 11:08:13.607614  2332 solver.cpp:218] Iteration 22800 (27.5709 iter/s, 3.62702s/100 iters), loss = 0.305078
I0629 11:08:13.607614  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:08:13.607614  2332 solver.cpp:237]     Train net output #1: loss = 0.305079 (* 1 = 0.305079 loss)
I0629 11:08:13.607614  2332 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0629 11:08:17.239462  2332 solver.cpp:218] Iteration 22900 (27.5398 iter/s, 3.63111s/100 iters), loss = 0.258691
I0629 11:08:17.239462  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:08:17.239462  2332 solver.cpp:237]     Train net output #1: loss = 0.258691 (* 1 = 0.258691 loss)
I0629 11:08:17.239462  2332 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0629 11:08:20.689579  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:08:20.831184  2332 solver.cpp:330] Iteration 23000, Testing net (#0)
I0629 11:08:20.831184  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:08:21.652812  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:08:21.684337  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8311
I0629 11:08:21.684837  2332 solver.cpp:397]     Test net output #1: loss = 0.515432 (* 1 = 0.515432 loss)
I0629 11:08:21.718863  2332 solver.cpp:218] Iteration 23000 (22.3252 iter/s, 4.47925s/100 iters), loss = 0.266179
I0629 11:08:21.718863  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:08:21.718863  2332 solver.cpp:237]     Train net output #1: loss = 0.26618 (* 1 = 0.26618 loss)
I0629 11:08:21.718863  2332 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0629 11:08:25.360590  2332 solver.cpp:218] Iteration 23100 (27.4593 iter/s, 3.64176s/100 iters), loss = 0.255084
I0629 11:08:25.361591  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:08:25.361591  2332 solver.cpp:237]     Train net output #1: loss = 0.255084 (* 1 = 0.255084 loss)
I0629 11:08:25.361591  2332 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0629 11:08:28.999359  2332 solver.cpp:218] Iteration 23200 (27.4879 iter/s, 3.63796s/100 iters), loss = 0.245337
I0629 11:08:28.999359  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:08:28.999359  2332 solver.cpp:237]     Train net output #1: loss = 0.245338 (* 1 = 0.245338 loss)
I0629 11:08:28.999359  2332 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0629 11:08:32.632103  2332 solver.cpp:218] Iteration 23300 (27.5298 iter/s, 3.63243s/100 iters), loss = 0.381468
I0629 11:08:32.632103  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:08:32.632103  2332 solver.cpp:237]     Train net output #1: loss = 0.381468 (* 1 = 0.381468 loss)
I0629 11:08:32.632103  2332 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0629 11:08:36.269829  2332 solver.cpp:218] Iteration 23400 (27.4925 iter/s, 3.63735s/100 iters), loss = 0.280942
I0629 11:08:36.269829  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:08:36.269829  2332 solver.cpp:237]     Train net output #1: loss = 0.280942 (* 1 = 0.280942 loss)
I0629 11:08:36.269829  2332 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0629 11:08:39.730578  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:08:39.873183  2332 solver.cpp:330] Iteration 23500, Testing net (#0)
I0629 11:08:39.873183  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:08:40.693434  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:08:40.724457  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8563
I0629 11:08:40.724457  2332 solver.cpp:397]     Test net output #1: loss = 0.438733 (* 1 = 0.438733 loss)
I0629 11:08:40.758481  2332 solver.cpp:218] Iteration 23500 (22.2811 iter/s, 4.48811s/100 iters), loss = 0.23886
I0629 11:08:40.758481  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:08:40.758481  2332 solver.cpp:237]     Train net output #1: loss = 0.23886 (* 1 = 0.23886 loss)
I0629 11:08:40.758481  2332 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0629 11:08:44.392155  2332 solver.cpp:218] Iteration 23600 (27.5246 iter/s, 3.63311s/100 iters), loss = 0.420712
I0629 11:08:44.392155  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0629 11:08:44.392155  2332 solver.cpp:237]     Train net output #1: loss = 0.420712 (* 1 = 0.420712 loss)
I0629 11:08:44.392155  2332 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0629 11:08:48.023733  2332 solver.cpp:218] Iteration 23700 (27.5335 iter/s, 3.63194s/100 iters), loss = 0.264535
I0629 11:08:48.023733  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:08:48.023733  2332 solver.cpp:237]     Train net output #1: loss = 0.264535 (* 1 = 0.264535 loss)
I0629 11:08:48.023733  2332 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0629 11:08:51.655658  2332 solver.cpp:218] Iteration 23800 (27.5406 iter/s, 3.631s/100 iters), loss = 0.272955
I0629 11:08:51.655658  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:08:51.655658  2332 solver.cpp:237]     Train net output #1: loss = 0.272955 (* 1 = 0.272955 loss)
I0629 11:08:51.655658  2332 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0629 11:08:55.290539  2332 solver.cpp:218] Iteration 23900 (27.5128 iter/s, 3.63468s/100 iters), loss = 0.23581
I0629 11:08:55.290539  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:08:55.290539  2332 solver.cpp:237]     Train net output #1: loss = 0.235811 (* 1 = 0.235811 loss)
I0629 11:08:55.290539  2332 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0629 11:08:58.740062  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:08:58.882166  2332 solver.cpp:330] Iteration 24000, Testing net (#0)
I0629 11:08:58.882166  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:08:59.701086  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:08:59.731611  2332 solver.cpp:397]     Test net output #0: accuracy = 0.797
I0629 11:08:59.731611  2332 solver.cpp:397]     Test net output #1: loss = 0.612453 (* 1 = 0.612453 loss)
I0629 11:08:59.765632  2332 solver.cpp:218] Iteration 24000 (22.3447 iter/s, 4.47533s/100 iters), loss = 0.272173
I0629 11:08:59.765632  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:08:59.766633  2332 solver.cpp:237]     Train net output #1: loss = 0.272173 (* 1 = 0.272173 loss)
I0629 11:08:59.766633  2332 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0629 11:09:03.398850  2332 solver.cpp:218] Iteration 24100 (27.5303 iter/s, 3.63236s/100 iters), loss = 0.26018
I0629 11:09:03.398850  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:09:03.398850  2332 solver.cpp:237]     Train net output #1: loss = 0.260181 (* 1 = 0.260181 loss)
I0629 11:09:03.399351  2332 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0629 11:09:07.041184  2332 solver.cpp:218] Iteration 24200 (27.4595 iter/s, 3.64173s/100 iters), loss = 0.31506
I0629 11:09:07.041184  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:09:07.041184  2332 solver.cpp:237]     Train net output #1: loss = 0.31506 (* 1 = 0.31506 loss)
I0629 11:09:07.041184  2332 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0629 11:09:10.676986  2332 solver.cpp:218] Iteration 24300 (27.5041 iter/s, 3.63582s/100 iters), loss = 0.235219
I0629 11:09:10.676986  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:09:10.676986  2332 solver.cpp:237]     Train net output #1: loss = 0.235219 (* 1 = 0.235219 loss)
I0629 11:09:10.676986  2332 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0629 11:09:14.311074  2332 solver.cpp:218] Iteration 24400 (27.5229 iter/s, 3.63333s/100 iters), loss = 0.28581
I0629 11:09:14.311074  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:09:14.311074  2332 solver.cpp:237]     Train net output #1: loss = 0.28581 (* 1 = 0.28581 loss)
I0629 11:09:14.311074  2332 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0629 11:09:17.761364  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:09:17.902468  2332 solver.cpp:330] Iteration 24500, Testing net (#0)
I0629 11:09:17.902969  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:09:18.721982  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:09:18.753003  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8557
I0629 11:09:18.753003  2332 solver.cpp:397]     Test net output #1: loss = 0.438561 (* 1 = 0.438561 loss)
I0629 11:09:18.788028  2332 solver.cpp:218] Iteration 24500 (22.3378 iter/s, 4.47671s/100 iters), loss = 0.258796
I0629 11:09:18.788028  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:09:18.788028  2332 solver.cpp:237]     Train net output #1: loss = 0.258796 (* 1 = 0.258796 loss)
I0629 11:09:18.788028  2332 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0629 11:09:22.413456  2332 solver.cpp:218] Iteration 24600 (27.5842 iter/s, 3.62527s/100 iters), loss = 0.275906
I0629 11:09:22.413957  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:09:22.413957  2332 solver.cpp:237]     Train net output #1: loss = 0.275906 (* 1 = 0.275906 loss)
I0629 11:09:22.413957  2332 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0629 11:09:26.038442  2332 solver.cpp:218] Iteration 24700 (27.5898 iter/s, 3.62453s/100 iters), loss = 0.289602
I0629 11:09:26.038442  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:09:26.038442  2332 solver.cpp:237]     Train net output #1: loss = 0.289602 (* 1 = 0.289602 loss)
I0629 11:09:26.038442  2332 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0629 11:09:29.747386  2332 solver.cpp:218] Iteration 24800 (26.9637 iter/s, 3.70868s/100 iters), loss = 0.295473
I0629 11:09:29.747386  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:09:29.747386  2332 solver.cpp:237]     Train net output #1: loss = 0.295473 (* 1 = 0.295473 loss)
I0629 11:09:29.747386  2332 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0629 11:09:33.366264  2332 solver.cpp:218] Iteration 24900 (27.6324 iter/s, 3.61894s/100 iters), loss = 0.308409
I0629 11:09:33.366264  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:09:33.366264  2332 solver.cpp:237]     Train net output #1: loss = 0.308409 (* 1 = 0.308409 loss)
I0629 11:09:33.366264  2332 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0629 11:09:36.810145  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:09:36.952291  2332 solver.cpp:330] Iteration 25000, Testing net (#0)
I0629 11:09:36.952291  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:09:37.779206  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:09:37.810232  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8306
I0629 11:09:37.810232  2332 solver.cpp:397]     Test net output #1: loss = 0.511364 (* 1 = 0.511364 loss)
I0629 11:09:37.845273  2332 solver.cpp:218] Iteration 25000 (22.3321 iter/s, 4.47786s/100 iters), loss = 0.264762
I0629 11:09:37.845273  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:09:37.845273  2332 solver.cpp:237]     Train net output #1: loss = 0.264762 (* 1 = 0.264762 loss)
I0629 11:09:37.845273  2332 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0629 11:09:41.472383  2332 solver.cpp:218] Iteration 25100 (27.5661 iter/s, 3.62765s/100 iters), loss = 0.228181
I0629 11:09:41.472383  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:09:41.473383  2332 solver.cpp:237]     Train net output #1: loss = 0.228181 (* 1 = 0.228181 loss)
I0629 11:09:41.473383  2332 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0629 11:09:45.095319  2332 solver.cpp:218] Iteration 25200 (27.61 iter/s, 3.62188s/100 iters), loss = 0.233373
I0629 11:09:45.095319  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:09:45.095319  2332 solver.cpp:237]     Train net output #1: loss = 0.233374 (* 1 = 0.233374 loss)
I0629 11:09:45.095319  2332 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0629 11:09:48.724990  2332 solver.cpp:218] Iteration 25300 (27.551 iter/s, 3.62963s/100 iters), loss = 0.405327
I0629 11:09:48.725507  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:09:48.725507  2332 solver.cpp:237]     Train net output #1: loss = 0.405327 (* 1 = 0.405327 loss)
I0629 11:09:48.725507  2332 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0629 11:09:52.352252  2332 solver.cpp:218] Iteration 25400 (27.5688 iter/s, 3.62729s/100 iters), loss = 0.240202
I0629 11:09:52.352252  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:09:52.352252  2332 solver.cpp:237]     Train net output #1: loss = 0.240202 (* 1 = 0.240202 loss)
I0629 11:09:52.352252  2332 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0629 11:09:55.806453  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:09:55.948068  2332 solver.cpp:330] Iteration 25500, Testing net (#0)
I0629 11:09:55.948068  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:09:56.766108  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:09:56.797113  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8343
I0629 11:09:56.797113  2332 solver.cpp:397]     Test net output #1: loss = 0.487544 (* 1 = 0.487544 loss)
I0629 11:09:56.832154  2332 solver.cpp:218] Iteration 25500 (22.3275 iter/s, 4.47878s/100 iters), loss = 0.257704
I0629 11:09:56.832154  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:09:56.832154  2332 solver.cpp:237]     Train net output #1: loss = 0.257705 (* 1 = 0.257705 loss)
I0629 11:09:56.832154  2332 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0629 11:10:00.451606  2332 solver.cpp:218] Iteration 25600 (27.6252 iter/s, 3.61989s/100 iters), loss = 0.279603
I0629 11:10:00.451606  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:10:00.451606  2332 solver.cpp:237]     Train net output #1: loss = 0.279603 (* 1 = 0.279603 loss)
I0629 11:10:00.451606  2332 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0629 11:10:04.094137  2332 solver.cpp:218] Iteration 25700 (27.4559 iter/s, 3.6422s/100 iters), loss = 0.213848
I0629 11:10:04.094137  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:10:04.094137  2332 solver.cpp:237]     Train net output #1: loss = 0.213848 (* 1 = 0.213848 loss)
I0629 11:10:04.094137  2332 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0629 11:10:07.725600  2332 solver.cpp:218] Iteration 25800 (27.5437 iter/s, 3.63059s/100 iters), loss = 0.257431
I0629 11:10:07.725600  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:10:07.725600  2332 solver.cpp:237]     Train net output #1: loss = 0.257431 (* 1 = 0.257431 loss)
I0629 11:10:07.725600  2332 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0629 11:10:11.349827  2332 solver.cpp:218] Iteration 25900 (27.5957 iter/s, 3.62375s/100 iters), loss = 0.271555
I0629 11:10:11.349827  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:10:11.349827  2332 solver.cpp:237]     Train net output #1: loss = 0.271555 (* 1 = 0.271555 loss)
I0629 11:10:11.349827  2332 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0629 11:10:14.803452  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:10:14.946055  2332 solver.cpp:330] Iteration 26000, Testing net (#0)
I0629 11:10:14.946055  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:10:15.763792  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:10:15.794876  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8491
I0629 11:10:15.794876  2332 solver.cpp:397]     Test net output #1: loss = 0.454814 (* 1 = 0.454814 loss)
I0629 11:10:15.828896  2332 solver.cpp:218] Iteration 26000 (22.3255 iter/s, 4.47917s/100 iters), loss = 0.312432
I0629 11:10:15.828896  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:10:15.828896  2332 solver.cpp:237]     Train net output #1: loss = 0.312432 (* 1 = 0.312432 loss)
I0629 11:10:15.828896  2332 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0629 11:10:19.454807  2332 solver.cpp:218] Iteration 26100 (27.5814 iter/s, 3.62564s/100 iters), loss = 0.36252
I0629 11:10:19.454807  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:10:19.454807  2332 solver.cpp:237]     Train net output #1: loss = 0.36252 (* 1 = 0.36252 loss)
I0629 11:10:19.454807  2332 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0629 11:10:23.075074  2332 solver.cpp:218] Iteration 26200 (27.6283 iter/s, 3.61948s/100 iters), loss = 0.236324
I0629 11:10:23.075074  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:10:23.075074  2332 solver.cpp:237]     Train net output #1: loss = 0.236324 (* 1 = 0.236324 loss)
I0629 11:10:23.075074  2332 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0629 11:10:26.696051  2332 solver.cpp:218] Iteration 26300 (27.615 iter/s, 3.62122s/100 iters), loss = 0.334773
I0629 11:10:26.696051  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:10:26.696051  2332 solver.cpp:237]     Train net output #1: loss = 0.334773 (* 1 = 0.334773 loss)
I0629 11:10:26.696051  2332 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0629 11:10:30.322325  2332 solver.cpp:218] Iteration 26400 (27.5798 iter/s, 3.62584s/100 iters), loss = 0.248612
I0629 11:10:30.322325  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:10:30.322325  2332 solver.cpp:237]     Train net output #1: loss = 0.248613 (* 1 = 0.248613 loss)
I0629 11:10:30.322325  2332 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0629 11:10:33.767690  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:10:33.909431  2332 solver.cpp:330] Iteration 26500, Testing net (#0)
I0629 11:10:33.909431  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:10:34.728298  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:10:34.759306  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8465
I0629 11:10:34.759306  2332 solver.cpp:397]     Test net output #1: loss = 0.472707 (* 1 = 0.472707 loss)
I0629 11:10:34.793858  2332 solver.cpp:218] Iteration 26500 (22.3683 iter/s, 4.47061s/100 iters), loss = 0.196408
I0629 11:10:34.793858  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:10:34.793858  2332 solver.cpp:237]     Train net output #1: loss = 0.196408 (* 1 = 0.196408 loss)
I0629 11:10:34.793858  2332 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0629 11:10:38.411481  2332 solver.cpp:218] Iteration 26600 (27.646 iter/s, 3.61716s/100 iters), loss = 0.218537
I0629 11:10:38.411481  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:10:38.411481  2332 solver.cpp:237]     Train net output #1: loss = 0.218538 (* 1 = 0.218538 loss)
I0629 11:10:38.411481  2332 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0629 11:10:42.039271  2332 solver.cpp:218] Iteration 26700 (27.5625 iter/s, 3.62812s/100 iters), loss = 0.259129
I0629 11:10:42.039271  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:10:42.039271  2332 solver.cpp:237]     Train net output #1: loss = 0.259129 (* 1 = 0.259129 loss)
I0629 11:10:42.039271  2332 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0629 11:10:45.674883  2332 solver.cpp:218] Iteration 26800 (27.5118 iter/s, 3.63481s/100 iters), loss = 0.368859
I0629 11:10:45.674883  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0629 11:10:45.674883  2332 solver.cpp:237]     Train net output #1: loss = 0.368859 (* 1 = 0.368859 loss)
I0629 11:10:45.674883  2332 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0629 11:10:49.288517  2332 solver.cpp:218] Iteration 26900 (27.6758 iter/s, 3.61327s/100 iters), loss = 0.272582
I0629 11:10:49.288517  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:10:49.288517  2332 solver.cpp:237]     Train net output #1: loss = 0.272582 (* 1 = 0.272582 loss)
I0629 11:10:49.288517  2332 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0629 11:10:52.738612  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:10:52.880468  2332 solver.cpp:330] Iteration 27000, Testing net (#0)
I0629 11:10:52.880468  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:10:53.704421  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:10:53.734962  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8375
I0629 11:10:53.734962  2332 solver.cpp:397]     Test net output #1: loss = 0.493971 (* 1 = 0.493971 loss)
I0629 11:10:53.768980  2332 solver.cpp:218] Iteration 27000 (22.3182 iter/s, 4.48065s/100 iters), loss = 0.184578
I0629 11:10:53.768980  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:10:53.768980  2332 solver.cpp:237]     Train net output #1: loss = 0.184578 (* 1 = 0.184578 loss)
I0629 11:10:53.768980  2332 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0629 11:10:57.396507  2332 solver.cpp:218] Iteration 27100 (27.5707 iter/s, 3.62703s/100 iters), loss = 0.316505
I0629 11:10:57.396507  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:10:57.396507  2332 solver.cpp:237]     Train net output #1: loss = 0.316505 (* 1 = 0.316505 loss)
I0629 11:10:57.396507  2332 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0629 11:11:01.016523  2332 solver.cpp:218] Iteration 27200 (27.6262 iter/s, 3.61975s/100 iters), loss = 0.314025
I0629 11:11:01.016523  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:11:01.016523  2332 solver.cpp:237]     Train net output #1: loss = 0.314025 (* 1 = 0.314025 loss)
I0629 11:11:01.016523  2332 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0629 11:11:04.646606  2332 solver.cpp:218] Iteration 27300 (27.5508 iter/s, 3.62966s/100 iters), loss = 0.386151
I0629 11:11:04.646606  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:11:04.646606  2332 solver.cpp:237]     Train net output #1: loss = 0.386152 (* 1 = 0.386152 loss)
I0629 11:11:04.646606  2332 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0629 11:11:08.276254  2332 solver.cpp:218] Iteration 27400 (27.5564 iter/s, 3.62893s/100 iters), loss = 0.244488
I0629 11:11:08.276254  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:11:08.276254  2332 solver.cpp:237]     Train net output #1: loss = 0.244489 (* 1 = 0.244489 loss)
I0629 11:11:08.276254  2332 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0629 11:11:11.716255  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:11:11.857949  2332 solver.cpp:330] Iteration 27500, Testing net (#0)
I0629 11:11:11.857949  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:11:12.672562  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:11:12.703109  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8399
I0629 11:11:12.703109  2332 solver.cpp:397]     Test net output #1: loss = 0.485821 (* 1 = 0.485821 loss)
I0629 11:11:12.737144  2332 solver.cpp:218] Iteration 27500 (22.4148 iter/s, 4.46134s/100 iters), loss = 0.28293
I0629 11:11:12.738134  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:11:12.738134  2332 solver.cpp:237]     Train net output #1: loss = 0.282931 (* 1 = 0.282931 loss)
I0629 11:11:12.738134  2332 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0629 11:11:16.369807  2332 solver.cpp:218] Iteration 27600 (27.5333 iter/s, 3.63196s/100 iters), loss = 0.242984
I0629 11:11:16.369807  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:11:16.369807  2332 solver.cpp:237]     Train net output #1: loss = 0.242984 (* 1 = 0.242984 loss)
I0629 11:11:16.369807  2332 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0629 11:11:19.995590  2332 solver.cpp:218] Iteration 27700 (27.586 iter/s, 3.62502s/100 iters), loss = 0.302844
I0629 11:11:19.995590  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:11:19.995590  2332 solver.cpp:237]     Train net output #1: loss = 0.302844 (* 1 = 0.302844 loss)
I0629 11:11:19.995590  2332 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0629 11:11:23.629353  2332 solver.cpp:218] Iteration 27800 (27.5203 iter/s, 3.63368s/100 iters), loss = 0.287631
I0629 11:11:23.629353  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:11:23.629353  2332 solver.cpp:237]     Train net output #1: loss = 0.287631 (* 1 = 0.287631 loss)
I0629 11:11:23.629353  2332 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0629 11:11:27.240342  2332 solver.cpp:218] Iteration 27900 (27.6945 iter/s, 3.61082s/100 iters), loss = 0.209032
I0629 11:11:27.240342  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:11:27.240342  2332 solver.cpp:237]     Train net output #1: loss = 0.209033 (* 1 = 0.209033 loss)
I0629 11:11:27.240342  2332 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0629 11:11:30.688359  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:11:30.830122  2332 solver.cpp:330] Iteration 28000, Testing net (#0)
I0629 11:11:30.830122  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:11:31.646597  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:11:31.677623  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8351
I0629 11:11:31.677623  2332 solver.cpp:397]     Test net output #1: loss = 0.508469 (* 1 = 0.508469 loss)
I0629 11:11:31.711230  2332 solver.cpp:218] Iteration 28000 (22.3663 iter/s, 4.47101s/100 iters), loss = 0.21579
I0629 11:11:31.712230  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:11:31.712230  2332 solver.cpp:237]     Train net output #1: loss = 0.215791 (* 1 = 0.215791 loss)
I0629 11:11:31.712230  2332 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0629 11:11:35.332418  2332 solver.cpp:218] Iteration 28100 (27.6202 iter/s, 3.62054s/100 iters), loss = 0.230536
I0629 11:11:35.332418  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:11:35.332418  2332 solver.cpp:237]     Train net output #1: loss = 0.230536 (* 1 = 0.230536 loss)
I0629 11:11:35.332418  2332 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0629 11:11:38.965055  2332 solver.cpp:218] Iteration 28200 (27.5315 iter/s, 3.63221s/100 iters), loss = 0.331518
I0629 11:11:38.965055  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:11:38.965055  2332 solver.cpp:237]     Train net output #1: loss = 0.331518 (* 1 = 0.331518 loss)
I0629 11:11:38.965055  2332 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0629 11:11:42.591482  2332 solver.cpp:218] Iteration 28300 (27.582 iter/s, 3.62556s/100 iters), loss = 0.260072
I0629 11:11:42.591482  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:11:42.591482  2332 solver.cpp:237]     Train net output #1: loss = 0.260072 (* 1 = 0.260072 loss)
I0629 11:11:42.591482  2332 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0629 11:11:46.216230  2332 solver.cpp:218] Iteration 28400 (27.587 iter/s, 3.62489s/100 iters), loss = 0.16365
I0629 11:11:46.216230  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:11:46.216230  2332 solver.cpp:237]     Train net output #1: loss = 0.16365 (* 1 = 0.16365 loss)
I0629 11:11:46.216230  2332 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0629 11:11:49.682852  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:11:49.826961  2332 solver.cpp:330] Iteration 28500, Testing net (#0)
I0629 11:11:49.826961  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:11:50.646577  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:11:50.677599  2332 solver.cpp:397]     Test net output #0: accuracy = 0.843
I0629 11:11:50.677599  2332 solver.cpp:397]     Test net output #1: loss = 0.488452 (* 1 = 0.488452 loss)
I0629 11:11:50.711627  2332 solver.cpp:218] Iteration 28500 (22.247 iter/s, 4.49498s/100 iters), loss = 0.265488
I0629 11:11:50.711627  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:11:50.711627  2332 solver.cpp:237]     Train net output #1: loss = 0.265488 (* 1 = 0.265488 loss)
I0629 11:11:50.711627  2332 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0629 11:11:54.343344  2332 solver.cpp:218] Iteration 28600 (27.5355 iter/s, 3.63168s/100 iters), loss = 0.21133
I0629 11:11:54.343344  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:11:54.343344  2332 solver.cpp:237]     Train net output #1: loss = 0.21133 (* 1 = 0.21133 loss)
I0629 11:11:54.343344  2332 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0629 11:11:57.968947  2332 solver.cpp:218] Iteration 28700 (27.5869 iter/s, 3.62491s/100 iters), loss = 0.24423
I0629 11:11:57.968947  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:11:57.968947  2332 solver.cpp:237]     Train net output #1: loss = 0.24423 (* 1 = 0.24423 loss)
I0629 11:11:57.968947  2332 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I0629 11:12:01.599725  2332 solver.cpp:218] Iteration 28800 (27.5479 iter/s, 3.63003s/100 iters), loss = 0.278359
I0629 11:12:01.599725  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:12:01.599725  2332 solver.cpp:237]     Train net output #1: loss = 0.278359 (* 1 = 0.278359 loss)
I0629 11:12:01.599725  2332 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I0629 11:12:05.228250  2332 solver.cpp:218] Iteration 28900 (27.5619 iter/s, 3.6282s/100 iters), loss = 0.189733
I0629 11:12:05.228250  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:12:05.228250  2332 solver.cpp:237]     Train net output #1: loss = 0.189733 (* 1 = 0.189733 loss)
I0629 11:12:05.228250  2332 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I0629 11:12:08.684049  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:12:08.826156  2332 solver.cpp:330] Iteration 29000, Testing net (#0)
I0629 11:12:08.826156  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:12:09.647770  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:12:09.678792  2332 solver.cpp:397]     Test net output #0: accuracy = 0.7984
I0629 11:12:09.678792  2332 solver.cpp:397]     Test net output #1: loss = 0.645921 (* 1 = 0.645921 loss)
I0629 11:12:09.713331  2332 solver.cpp:218] Iteration 29000 (22.2979 iter/s, 4.48473s/100 iters), loss = 0.227438
I0629 11:12:09.713331  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:12:09.713331  2332 solver.cpp:237]     Train net output #1: loss = 0.227438 (* 1 = 0.227438 loss)
I0629 11:12:09.713331  2332 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I0629 11:12:13.341615  2332 solver.cpp:218] Iteration 29100 (27.5637 iter/s, 3.62797s/100 iters), loss = 0.266682
I0629 11:12:13.341615  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:12:13.341615  2332 solver.cpp:237]     Train net output #1: loss = 0.266682 (* 1 = 0.266682 loss)
I0629 11:12:13.341615  2332 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I0629 11:12:16.967206  2332 solver.cpp:218] Iteration 29200 (27.5834 iter/s, 3.62537s/100 iters), loss = 0.295885
I0629 11:12:16.967206  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:12:16.967206  2332 solver.cpp:237]     Train net output #1: loss = 0.295886 (* 1 = 0.295886 loss)
I0629 11:12:16.967206  2332 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I0629 11:12:20.593120  2332 solver.cpp:218] Iteration 29300 (27.581 iter/s, 3.62568s/100 iters), loss = 0.311698
I0629 11:12:20.593120  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:12:20.593120  2332 solver.cpp:237]     Train net output #1: loss = 0.311698 (* 1 = 0.311698 loss)
I0629 11:12:20.593120  2332 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I0629 11:12:24.241180  2332 solver.cpp:218] Iteration 29400 (27.4144 iter/s, 3.64772s/100 iters), loss = 0.198119
I0629 11:12:24.241180  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:12:24.241180  2332 solver.cpp:237]     Train net output #1: loss = 0.198119 (* 1 = 0.198119 loss)
I0629 11:12:24.241180  2332 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I0629 11:12:27.687772  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:12:27.830377  2332 solver.cpp:330] Iteration 29500, Testing net (#0)
I0629 11:12:27.830377  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:12:28.652514  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:12:28.683542  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8344
I0629 11:12:28.683542  2332 solver.cpp:397]     Test net output #1: loss = 0.507764 (* 1 = 0.507764 loss)
I0629 11:12:28.717561  2332 solver.cpp:218] Iteration 29500 (22.3394 iter/s, 4.47641s/100 iters), loss = 0.255752
I0629 11:12:28.717561  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:12:28.717561  2332 solver.cpp:237]     Train net output #1: loss = 0.255752 (* 1 = 0.255752 loss)
I0629 11:12:28.717561  2332 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I0629 11:12:32.337342  2332 solver.cpp:218] Iteration 29600 (27.6301 iter/s, 3.61924s/100 iters), loss = 0.234232
I0629 11:12:32.337342  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:12:32.337842  2332 solver.cpp:237]     Train net output #1: loss = 0.234232 (* 1 = 0.234232 loss)
I0629 11:12:32.337842  2332 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I0629 11:12:35.972074  2332 solver.cpp:218] Iteration 29700 (27.5178 iter/s, 3.63401s/100 iters), loss = 0.249955
I0629 11:12:35.972074  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:12:35.972074  2332 solver.cpp:237]     Train net output #1: loss = 0.249955 (* 1 = 0.249955 loss)
I0629 11:12:35.972074  2332 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I0629 11:12:39.594841  2332 solver.cpp:218] Iteration 29800 (27.6044 iter/s, 3.62261s/100 iters), loss = 0.317983
I0629 11:12:39.594841  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0629 11:12:39.594841  2332 solver.cpp:237]     Train net output #1: loss = 0.317983 (* 1 = 0.317983 loss)
I0629 11:12:39.594841  2332 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I0629 11:12:43.222699  2332 solver.cpp:218] Iteration 29900 (27.5672 iter/s, 3.6275s/100 iters), loss = 0.30499
I0629 11:12:43.222699  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:12:43.222699  2332 solver.cpp:237]     Train net output #1: loss = 0.30499 (* 1 = 0.30499 loss)
I0629 11:12:43.222699  2332 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I0629 11:12:46.673307  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:12:46.815414  2332 solver.cpp:330] Iteration 30000, Testing net (#0)
I0629 11:12:46.815414  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:12:47.633024  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:12:47.664050  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8511
I0629 11:12:47.664050  2332 solver.cpp:397]     Test net output #1: loss = 0.444945 (* 1 = 0.444945 loss)
I0629 11:12:47.698074  2332 solver.cpp:218] Iteration 30000 (22.3431 iter/s, 4.47566s/100 iters), loss = 0.203175
I0629 11:12:47.698074  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:12:47.698074  2332 solver.cpp:237]     Train net output #1: loss = 0.203175 (* 1 = 0.203175 loss)
I0629 11:12:47.698074  2332 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I0629 11:12:51.322708  2332 solver.cpp:218] Iteration 30100 (27.5956 iter/s, 3.62376s/100 iters), loss = 0.268933
I0629 11:12:51.322708  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:12:51.322708  2332 solver.cpp:237]     Train net output #1: loss = 0.268933 (* 1 = 0.268933 loss)
I0629 11:12:51.322708  2332 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I0629 11:12:54.960467  2332 solver.cpp:218] Iteration 30200 (27.4922 iter/s, 3.6374s/100 iters), loss = 0.22015
I0629 11:12:54.960467  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:12:54.960467  2332 solver.cpp:237]     Train net output #1: loss = 0.22015 (* 1 = 0.22015 loss)
I0629 11:12:54.960467  2332 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I0629 11:12:58.590219  2332 solver.cpp:218] Iteration 30300 (27.554 iter/s, 3.62923s/100 iters), loss = 0.245075
I0629 11:12:58.590219  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:12:58.590219  2332 solver.cpp:237]     Train net output #1: loss = 0.245076 (* 1 = 0.245076 loss)
I0629 11:12:58.590219  2332 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I0629 11:13:02.216760  2332 solver.cpp:218] Iteration 30400 (27.5715 iter/s, 3.62693s/100 iters), loss = 0.202278
I0629 11:13:02.216760  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:13:02.216760  2332 solver.cpp:237]     Train net output #1: loss = 0.202279 (* 1 = 0.202279 loss)
I0629 11:13:02.216760  2332 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I0629 11:13:05.671773  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:13:05.813874  2332 solver.cpp:330] Iteration 30500, Testing net (#0)
I0629 11:13:05.813874  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:13:06.643564  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:13:06.666585  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8308
I0629 11:13:06.666585  2332 solver.cpp:397]     Test net output #1: loss = 0.550447 (* 1 = 0.550447 loss)
I0629 11:13:06.700604  2332 solver.cpp:218] Iteration 30500 (22.3043 iter/s, 4.48344s/100 iters), loss = 0.287138
I0629 11:13:06.700604  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:13:06.700604  2332 solver.cpp:237]     Train net output #1: loss = 0.287138 (* 1 = 0.287138 loss)
I0629 11:13:06.700604  2332 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I0629 11:13:10.327981  2332 solver.cpp:218] Iteration 30600 (27.5742 iter/s, 3.62658s/100 iters), loss = 0.200366
I0629 11:13:10.327981  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:13:10.327981  2332 solver.cpp:237]     Train net output #1: loss = 0.200366 (* 1 = 0.200366 loss)
I0629 11:13:10.327981  2332 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I0629 11:13:13.950997  2332 solver.cpp:218] Iteration 30700 (27.6019 iter/s, 3.62294s/100 iters), loss = 0.315399
I0629 11:13:13.950997  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0629 11:13:13.950997  2332 solver.cpp:237]     Train net output #1: loss = 0.315399 (* 1 = 0.315399 loss)
I0629 11:13:13.950997  2332 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I0629 11:13:17.578738  2332 solver.cpp:218] Iteration 30800 (27.5668 iter/s, 3.62755s/100 iters), loss = 0.24032
I0629 11:13:17.578738  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:13:17.578738  2332 solver.cpp:237]     Train net output #1: loss = 0.24032 (* 1 = 0.24032 loss)
I0629 11:13:17.578738  2332 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I0629 11:13:21.207461  2332 solver.cpp:218] Iteration 30900 (27.5583 iter/s, 3.62867s/100 iters), loss = 0.232323
I0629 11:13:21.208467  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:13:21.208467  2332 solver.cpp:237]     Train net output #1: loss = 0.232323 (* 1 = 0.232323 loss)
I0629 11:13:21.208467  2332 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I0629 11:13:24.659970  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:13:24.803601  2332 solver.cpp:330] Iteration 31000, Testing net (#0)
I0629 11:13:24.803601  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:13:25.620438  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:13:25.651965  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8446
I0629 11:13:25.651965  2332 solver.cpp:397]     Test net output #1: loss = 0.474082 (* 1 = 0.474082 loss)
I0629 11:13:25.686517  2332 solver.cpp:218] Iteration 31000 (22.3325 iter/s, 4.47778s/100 iters), loss = 0.256082
I0629 11:13:25.686517  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:13:25.686517  2332 solver.cpp:237]     Train net output #1: loss = 0.256083 (* 1 = 0.256083 loss)
I0629 11:13:25.686517  2332 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I0629 11:13:29.320063  2332 solver.cpp:218] Iteration 31100 (27.5231 iter/s, 3.63332s/100 iters), loss = 0.313284
I0629 11:13:29.320063  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:13:29.320063  2332 solver.cpp:237]     Train net output #1: loss = 0.313285 (* 1 = 0.313285 loss)
I0629 11:13:29.320063  2332 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I0629 11:13:32.953490  2332 solver.cpp:218] Iteration 31200 (27.524 iter/s, 3.63319s/100 iters), loss = 0.245148
I0629 11:13:32.953490  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:13:32.953490  2332 solver.cpp:237]     Train net output #1: loss = 0.245148 (* 1 = 0.245148 loss)
I0629 11:13:32.953490  2332 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I0629 11:13:36.589954  2332 solver.cpp:218] Iteration 31300 (27.5026 iter/s, 3.63602s/100 iters), loss = 0.216232
I0629 11:13:36.589954  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:13:36.589954  2332 solver.cpp:237]     Train net output #1: loss = 0.216232 (* 1 = 0.216232 loss)
I0629 11:13:36.589954  2332 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I0629 11:13:40.226321  2332 solver.cpp:218] Iteration 31400 (27.5013 iter/s, 3.63619s/100 iters), loss = 0.267484
I0629 11:13:40.226321  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:13:40.226321  2332 solver.cpp:237]     Train net output #1: loss = 0.267484 (* 1 = 0.267484 loss)
I0629 11:13:40.226321  2332 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I0629 11:13:43.677646  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:13:43.819253  2332 solver.cpp:330] Iteration 31500, Testing net (#0)
I0629 11:13:43.819253  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:13:44.634711  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:13:44.665732  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8301
I0629 11:13:44.665732  2332 solver.cpp:397]     Test net output #1: loss = 0.524639 (* 1 = 0.524639 loss)
I0629 11:13:44.699757  2332 solver.cpp:218] Iteration 31500 (22.3534 iter/s, 4.4736s/100 iters), loss = 0.250168
I0629 11:13:44.699757  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:13:44.699757  2332 solver.cpp:237]     Train net output #1: loss = 0.250168 (* 1 = 0.250168 loss)
I0629 11:13:44.699757  2332 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I0629 11:13:48.328480  2332 solver.cpp:218] Iteration 31600 (27.5647 iter/s, 3.62783s/100 iters), loss = 0.231741
I0629 11:13:48.328480  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:13:48.328480  2332 solver.cpp:237]     Train net output #1: loss = 0.231741 (* 1 = 0.231741 loss)
I0629 11:13:48.328480  2332 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I0629 11:13:51.949168  2332 solver.cpp:218] Iteration 31700 (27.6181 iter/s, 3.62081s/100 iters), loss = 0.233237
I0629 11:13:51.949168  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:13:51.949168  2332 solver.cpp:237]     Train net output #1: loss = 0.233237 (* 1 = 0.233237 loss)
I0629 11:13:51.949168  2332 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I0629 11:13:55.579018  2332 solver.cpp:218] Iteration 31800 (27.5575 iter/s, 3.62878s/100 iters), loss = 0.269781
I0629 11:13:55.579018  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:13:55.579018  2332 solver.cpp:237]     Train net output #1: loss = 0.269781 (* 1 = 0.269781 loss)
I0629 11:13:55.579018  2332 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I0629 11:13:59.195982  2332 solver.cpp:218] Iteration 31900 (27.6472 iter/s, 3.617s/100 iters), loss = 0.208905
I0629 11:13:59.196482  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:13:59.196482  2332 solver.cpp:237]     Train net output #1: loss = 0.208905 (* 1 = 0.208905 loss)
I0629 11:13:59.196482  2332 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I0629 11:14:02.650183  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:14:02.792286  2332 solver.cpp:330] Iteration 32000, Testing net (#0)
I0629 11:14:02.792286  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:14:03.608194  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:14:03.638726  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8331
I0629 11:14:03.638726  2332 solver.cpp:397]     Test net output #1: loss = 0.541258 (* 1 = 0.541258 loss)
I0629 11:14:03.673750  2332 solver.cpp:218] Iteration 32000 (22.3347 iter/s, 4.47735s/100 iters), loss = 0.310566
I0629 11:14:03.673750  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0629 11:14:03.673750  2332 solver.cpp:237]     Train net output #1: loss = 0.310566 (* 1 = 0.310566 loss)
I0629 11:14:03.673750  2332 sgd_solver.cpp:46] MultiStep Status: Iteration 32000, step = 1
I0629 11:14:03.673750  2332 sgd_solver.cpp:105] Iteration 32000, lr = 0.001
I0629 11:14:07.299571  2332 solver.cpp:218] Iteration 32100 (27.5798 iter/s, 3.62584s/100 iters), loss = 0.242135
I0629 11:14:07.299571  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:14:07.299571  2332 solver.cpp:237]     Train net output #1: loss = 0.242135 (* 1 = 0.242135 loss)
I0629 11:14:07.299571  2332 sgd_solver.cpp:105] Iteration 32100, lr = 0.001
I0629 11:14:10.922317  2332 solver.cpp:218] Iteration 32200 (27.6109 iter/s, 3.62175s/100 iters), loss = 0.258342
I0629 11:14:10.922317  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:14:10.922317  2332 solver.cpp:237]     Train net output #1: loss = 0.258342 (* 1 = 0.258342 loss)
I0629 11:14:10.922317  2332 sgd_solver.cpp:105] Iteration 32200, lr = 0.001
I0629 11:14:14.548105  2332 solver.cpp:218] Iteration 32300 (27.5777 iter/s, 3.62612s/100 iters), loss = 0.211832
I0629 11:14:14.548105  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:14:14.548105  2332 solver.cpp:237]     Train net output #1: loss = 0.211832 (* 1 = 0.211832 loss)
I0629 11:14:14.548105  2332 sgd_solver.cpp:105] Iteration 32300, lr = 0.001
I0629 11:14:18.177981  2332 solver.cpp:218] Iteration 32400 (27.557 iter/s, 3.62884s/100 iters), loss = 0.223364
I0629 11:14:18.177981  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0629 11:14:18.177981  2332 solver.cpp:237]     Train net output #1: loss = 0.223364 (* 1 = 0.223364 loss)
I0629 11:14:18.177981  2332 sgd_solver.cpp:105] Iteration 32400, lr = 0.001
I0629 11:14:21.631314  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:14:21.772416  2332 solver.cpp:330] Iteration 32500, Testing net (#0)
I0629 11:14:21.773417  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:14:22.593099  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:14:22.624624  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8872
I0629 11:14:22.624624  2332 solver.cpp:397]     Test net output #1: loss = 0.345328 (* 1 = 0.345328 loss)
I0629 11:14:22.659149  2332 solver.cpp:218] Iteration 32500 (22.3167 iter/s, 4.48095s/100 iters), loss = 0.149992
I0629 11:14:22.659149  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:14:22.659149  2332 solver.cpp:237]     Train net output #1: loss = 0.149992 (* 1 = 0.149992 loss)
I0629 11:14:22.659149  2332 sgd_solver.cpp:105] Iteration 32500, lr = 0.001
I0629 11:14:26.279294  2332 solver.cpp:218] Iteration 32600 (27.6246 iter/s, 3.61996s/100 iters), loss = 0.227458
I0629 11:14:26.279294  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:14:26.279294  2332 solver.cpp:237]     Train net output #1: loss = 0.227458 (* 1 = 0.227458 loss)
I0629 11:14:26.279294  2332 sgd_solver.cpp:105] Iteration 32600, lr = 0.001
I0629 11:14:29.905302  2332 solver.cpp:218] Iteration 32700 (27.5788 iter/s, 3.62598s/100 iters), loss = 0.183602
I0629 11:14:29.905302  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:14:29.905302  2332 solver.cpp:237]     Train net output #1: loss = 0.183602 (* 1 = 0.183602 loss)
I0629 11:14:29.905302  2332 sgd_solver.cpp:105] Iteration 32700, lr = 0.001
I0629 11:14:33.525205  2332 solver.cpp:218] Iteration 32800 (27.6291 iter/s, 3.61937s/100 iters), loss = 0.16311
I0629 11:14:33.525205  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:14:33.525205  2332 solver.cpp:237]     Train net output #1: loss = 0.16311 (* 1 = 0.16311 loss)
I0629 11:14:33.525205  2332 sgd_solver.cpp:105] Iteration 32800, lr = 0.001
I0629 11:14:37.153540  2332 solver.cpp:218] Iteration 32900 (27.5658 iter/s, 3.62768s/100 iters), loss = 0.175675
I0629 11:14:37.153540  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:14:37.153540  2332 solver.cpp:237]     Train net output #1: loss = 0.175675 (* 1 = 0.175675 loss)
I0629 11:14:37.153540  2332 sgd_solver.cpp:105] Iteration 32900, lr = 0.001
I0629 11:14:40.596155  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:14:40.737634  2332 solver.cpp:330] Iteration 33000, Testing net (#0)
I0629 11:14:40.737634  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:14:41.555609  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:14:41.586618  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8886
I0629 11:14:41.586618  2332 solver.cpp:397]     Test net output #1: loss = 0.338098 (* 1 = 0.338098 loss)
I0629 11:14:41.620652  2332 solver.cpp:218] Iteration 33000 (22.3842 iter/s, 4.46744s/100 iters), loss = 0.212205
I0629 11:14:41.620652  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:14:41.620652  2332 solver.cpp:237]     Train net output #1: loss = 0.212205 (* 1 = 0.212205 loss)
I0629 11:14:41.620652  2332 sgd_solver.cpp:105] Iteration 33000, lr = 0.001
I0629 11:14:45.242761  2332 solver.cpp:218] Iteration 33100 (27.6146 iter/s, 3.62127s/100 iters), loss = 0.187688
I0629 11:14:45.242761  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:14:45.242761  2332 solver.cpp:237]     Train net output #1: loss = 0.187688 (* 1 = 0.187688 loss)
I0629 11:14:45.242761  2332 sgd_solver.cpp:105] Iteration 33100, lr = 0.001
I0629 11:14:48.860327  2332 solver.cpp:218] Iteration 33200 (27.6418 iter/s, 3.61771s/100 iters), loss = 0.135665
I0629 11:14:48.860327  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:14:48.860327  2332 solver.cpp:237]     Train net output #1: loss = 0.135666 (* 1 = 0.135666 loss)
I0629 11:14:48.860327  2332 sgd_solver.cpp:105] Iteration 33200, lr = 0.001
I0629 11:14:52.476243  2332 solver.cpp:218] Iteration 33300 (27.6617 iter/s, 3.61511s/100 iters), loss = 0.197772
I0629 11:14:52.476243  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:14:52.476742  2332 solver.cpp:237]     Train net output #1: loss = 0.197772 (* 1 = 0.197772 loss)
I0629 11:14:52.476742  2332 sgd_solver.cpp:105] Iteration 33300, lr = 0.001
I0629 11:14:56.099333  2332 solver.cpp:218] Iteration 33400 (27.606 iter/s, 3.6224s/100 iters), loss = 0.147337
I0629 11:14:56.099333  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:14:56.099333  2332 solver.cpp:237]     Train net output #1: loss = 0.147337 (* 1 = 0.147337 loss)
I0629 11:14:56.099333  2332 sgd_solver.cpp:105] Iteration 33400, lr = 0.001
I0629 11:14:59.540772  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:14:59.681388  2332 solver.cpp:330] Iteration 33500, Testing net (#0)
I0629 11:14:59.681388  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:15:00.497022  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:15:00.528048  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8888
I0629 11:15:00.528048  2332 solver.cpp:397]     Test net output #1: loss = 0.33642 (* 1 = 0.33642 loss)
I0629 11:15:00.562595  2332 solver.cpp:218] Iteration 33500 (22.4051 iter/s, 4.46326s/100 iters), loss = 0.170859
I0629 11:15:00.562595  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0629 11:15:00.562595  2332 solver.cpp:237]     Train net output #1: loss = 0.170859 (* 1 = 0.170859 loss)
I0629 11:15:00.562595  2332 sgd_solver.cpp:105] Iteration 33500, lr = 0.001
I0629 11:15:04.195374  2332 solver.cpp:218] Iteration 33600 (27.5255 iter/s, 3.633s/100 iters), loss = 0.217462
I0629 11:15:04.196357  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:15:04.196357  2332 solver.cpp:237]     Train net output #1: loss = 0.217462 (* 1 = 0.217462 loss)
I0629 11:15:04.196357  2332 sgd_solver.cpp:105] Iteration 33600, lr = 0.001
I0629 11:15:07.817363  2332 solver.cpp:218] Iteration 33700 (27.6124 iter/s, 3.62157s/100 iters), loss = 0.20339
I0629 11:15:07.817363  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:15:07.817363  2332 solver.cpp:237]     Train net output #1: loss = 0.20339 (* 1 = 0.20339 loss)
I0629 11:15:07.817363  2332 sgd_solver.cpp:105] Iteration 33700, lr = 0.001
I0629 11:15:11.437654  2332 solver.cpp:218] Iteration 33800 (27.6306 iter/s, 3.61918s/100 iters), loss = 0.121459
I0629 11:15:11.437654  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:15:11.437654  2332 solver.cpp:237]     Train net output #1: loss = 0.121459 (* 1 = 0.121459 loss)
I0629 11:15:11.437654  2332 sgd_solver.cpp:105] Iteration 33800, lr = 0.001
I0629 11:15:15.053810  2332 solver.cpp:218] Iteration 33900 (27.6524 iter/s, 3.61632s/100 iters), loss = 0.226374
I0629 11:15:15.053810  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:15:15.053810  2332 solver.cpp:237]     Train net output #1: loss = 0.226375 (* 1 = 0.226375 loss)
I0629 11:15:15.053810  2332 sgd_solver.cpp:105] Iteration 33900, lr = 0.001
I0629 11:15:18.490780  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:15:18.631911  2332 solver.cpp:330] Iteration 34000, Testing net (#0)
I0629 11:15:18.632412  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:15:19.447337  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:15:19.478361  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8875
I0629 11:15:19.478361  2332 solver.cpp:397]     Test net output #1: loss = 0.342765 (* 1 = 0.342765 loss)
I0629 11:15:19.512397  2332 solver.cpp:218] Iteration 34000 (22.43 iter/s, 4.45831s/100 iters), loss = 0.141674
I0629 11:15:19.512397  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:15:19.512397  2332 solver.cpp:237]     Train net output #1: loss = 0.141674 (* 1 = 0.141674 loss)
I0629 11:15:19.512397  2332 sgd_solver.cpp:105] Iteration 34000, lr = 0.001
I0629 11:15:23.138190  2332 solver.cpp:218] Iteration 34100 (27.5867 iter/s, 3.62494s/100 iters), loss = 0.189697
I0629 11:15:23.138190  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:15:23.138190  2332 solver.cpp:237]     Train net output #1: loss = 0.189697 (* 1 = 0.189697 loss)
I0629 11:15:23.138190  2332 sgd_solver.cpp:105] Iteration 34100, lr = 0.001
I0629 11:15:26.766304  2332 solver.cpp:218] Iteration 34200 (27.5665 iter/s, 3.62759s/100 iters), loss = 0.163917
I0629 11:15:26.766304  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:15:26.766304  2332 solver.cpp:237]     Train net output #1: loss = 0.163917 (* 1 = 0.163917 loss)
I0629 11:15:26.766304  2332 sgd_solver.cpp:105] Iteration 34200, lr = 0.001
I0629 11:15:30.392000  2332 solver.cpp:218] Iteration 34300 (27.5818 iter/s, 3.62558s/100 iters), loss = 0.181412
I0629 11:15:30.392000  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:15:30.392000  2332 solver.cpp:237]     Train net output #1: loss = 0.181412 (* 1 = 0.181412 loss)
I0629 11:15:30.392000  2332 sgd_solver.cpp:105] Iteration 34300, lr = 0.001
I0629 11:15:34.017580  2332 solver.cpp:218] Iteration 34400 (27.5859 iter/s, 3.62504s/100 iters), loss = 0.139383
I0629 11:15:34.017580  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:15:34.017580  2332 solver.cpp:237]     Train net output #1: loss = 0.139383 (* 1 = 0.139383 loss)
I0629 11:15:34.017580  2332 sgd_solver.cpp:105] Iteration 34400, lr = 0.001
I0629 11:15:37.468421  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:15:37.609524  2332 solver.cpp:330] Iteration 34500, Testing net (#0)
I0629 11:15:37.610524  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:15:38.430145  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:15:38.461165  2332 solver.cpp:397]     Test net output #0: accuracy = 0.891
I0629 11:15:38.461165  2332 solver.cpp:397]     Test net output #1: loss = 0.3391 (* 1 = 0.3391 loss)
I0629 11:15:38.494820  2332 solver.cpp:218] Iteration 34500 (22.333 iter/s, 4.47768s/100 iters), loss = 0.110227
I0629 11:15:38.494820  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:15:38.494820  2332 solver.cpp:237]     Train net output #1: loss = 0.110227 (* 1 = 0.110227 loss)
I0629 11:15:38.494820  2332 sgd_solver.cpp:105] Iteration 34500, lr = 0.001
I0629 11:15:42.125713  2332 solver.cpp:218] Iteration 34600 (27.5471 iter/s, 3.63015s/100 iters), loss = 0.180254
I0629 11:15:42.125713  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:15:42.125713  2332 solver.cpp:237]     Train net output #1: loss = 0.180254 (* 1 = 0.180254 loss)
I0629 11:15:42.125713  2332 sgd_solver.cpp:105] Iteration 34600, lr = 0.001
I0629 11:15:45.744824  2332 solver.cpp:218] Iteration 34700 (27.6357 iter/s, 3.61851s/100 iters), loss = 0.144763
I0629 11:15:45.744824  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:15:45.744824  2332 solver.cpp:237]     Train net output #1: loss = 0.144763 (* 1 = 0.144763 loss)
I0629 11:15:45.744824  2332 sgd_solver.cpp:105] Iteration 34700, lr = 0.001
I0629 11:15:49.379066  2332 solver.cpp:218] Iteration 34800 (27.5152 iter/s, 3.63436s/100 iters), loss = 0.178467
I0629 11:15:49.379066  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:15:49.379066  2332 solver.cpp:237]     Train net output #1: loss = 0.178467 (* 1 = 0.178467 loss)
I0629 11:15:49.379066  2332 sgd_solver.cpp:105] Iteration 34800, lr = 0.001
I0629 11:15:53.005559  2332 solver.cpp:218] Iteration 34900 (27.5764 iter/s, 3.62629s/100 iters), loss = 0.151497
I0629 11:15:53.005559  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:15:53.005559  2332 solver.cpp:237]     Train net output #1: loss = 0.151497 (* 1 = 0.151497 loss)
I0629 11:15:53.005559  2332 sgd_solver.cpp:105] Iteration 34900, lr = 0.001
I0629 11:15:56.449126  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:15:56.591233  2332 solver.cpp:330] Iteration 35000, Testing net (#0)
I0629 11:15:56.591233  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:15:57.408288  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:15:57.439309  2332 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0629 11:15:57.439309  2332 solver.cpp:397]     Test net output #1: loss = 0.3336 (* 1 = 0.3336 loss)
I0629 11:15:57.473835  2332 solver.cpp:218] Iteration 35000 (22.3834 iter/s, 4.46759s/100 iters), loss = 0.105323
I0629 11:15:57.474336  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:15:57.474336  2332 solver.cpp:237]     Train net output #1: loss = 0.105323 (* 1 = 0.105323 loss)
I0629 11:15:57.474336  2332 sgd_solver.cpp:105] Iteration 35000, lr = 0.001
I0629 11:16:01.102293  2332 solver.cpp:218] Iteration 35100 (27.5588 iter/s, 3.6286s/100 iters), loss = 0.166719
I0629 11:16:01.102293  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:16:01.103294  2332 solver.cpp:237]     Train net output #1: loss = 0.166719 (* 1 = 0.166719 loss)
I0629 11:16:01.103294  2332 sgd_solver.cpp:105] Iteration 35100, lr = 0.001
I0629 11:16:04.738070  2332 solver.cpp:218] Iteration 35200 (27.5097 iter/s, 3.63509s/100 iters), loss = 0.122092
I0629 11:16:04.738070  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:16:04.738070  2332 solver.cpp:237]     Train net output #1: loss = 0.122092 (* 1 = 0.122092 loss)
I0629 11:16:04.738070  2332 sgd_solver.cpp:105] Iteration 35200, lr = 0.001
I0629 11:16:08.371487  2332 solver.cpp:218] Iteration 35300 (27.5258 iter/s, 3.63296s/100 iters), loss = 0.172672
I0629 11:16:08.371487  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:16:08.371989  2332 solver.cpp:237]     Train net output #1: loss = 0.172672 (* 1 = 0.172672 loss)
I0629 11:16:08.371989  2332 sgd_solver.cpp:105] Iteration 35300, lr = 0.001
I0629 11:16:12.000727  2332 solver.cpp:218] Iteration 35400 (27.5597 iter/s, 3.62848s/100 iters), loss = 0.148119
I0629 11:16:12.000727  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:16:12.000727  2332 solver.cpp:237]     Train net output #1: loss = 0.148119 (* 1 = 0.148119 loss)
I0629 11:16:12.000727  2332 sgd_solver.cpp:105] Iteration 35400, lr = 0.001
I0629 11:16:15.457180  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:16:15.599488  2332 solver.cpp:330] Iteration 35500, Testing net (#0)
I0629 11:16:15.599488  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:16:16.417101  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:16:16.448123  2332 solver.cpp:397]     Test net output #0: accuracy = 0.893
I0629 11:16:16.448123  2332 solver.cpp:397]     Test net output #1: loss = 0.334824 (* 1 = 0.334824 loss)
I0629 11:16:16.482650  2332 solver.cpp:218] Iteration 35500 (22.3127 iter/s, 4.48176s/100 iters), loss = 0.120773
I0629 11:16:16.482650  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:16:16.482650  2332 solver.cpp:237]     Train net output #1: loss = 0.120773 (* 1 = 0.120773 loss)
I0629 11:16:16.482650  2332 sgd_solver.cpp:105] Iteration 35500, lr = 0.001
I0629 11:16:20.107020  2332 solver.cpp:218] Iteration 35600 (27.5886 iter/s, 3.62469s/100 iters), loss = 0.144256
I0629 11:16:20.107020  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:16:20.107020  2332 solver.cpp:237]     Train net output #1: loss = 0.144256 (* 1 = 0.144256 loss)
I0629 11:16:20.107020  2332 sgd_solver.cpp:105] Iteration 35600, lr = 0.001
I0629 11:16:23.739195  2332 solver.cpp:218] Iteration 35700 (27.5394 iter/s, 3.63116s/100 iters), loss = 0.208624
I0629 11:16:23.739195  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:16:23.739195  2332 solver.cpp:237]     Train net output #1: loss = 0.208624 (* 1 = 0.208624 loss)
I0629 11:16:23.739195  2332 sgd_solver.cpp:105] Iteration 35700, lr = 0.001
I0629 11:16:27.373968  2332 solver.cpp:218] Iteration 35800 (27.5141 iter/s, 3.6345s/100 iters), loss = 0.173178
I0629 11:16:27.373968  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:16:27.373968  2332 solver.cpp:237]     Train net output #1: loss = 0.173178 (* 1 = 0.173178 loss)
I0629 11:16:27.373968  2332 sgd_solver.cpp:105] Iteration 35800, lr = 0.001
I0629 11:16:31.007707  2332 solver.cpp:218] Iteration 35900 (27.5211 iter/s, 3.63358s/100 iters), loss = 0.113919
I0629 11:16:31.007707  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:16:31.007707  2332 solver.cpp:237]     Train net output #1: loss = 0.113919 (* 1 = 0.113919 loss)
I0629 11:16:31.007707  2332 sgd_solver.cpp:105] Iteration 35900, lr = 0.001
I0629 11:16:34.454352  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:16:34.596457  2332 solver.cpp:330] Iteration 36000, Testing net (#0)
I0629 11:16:34.596457  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:16:35.413065  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:16:35.444089  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8907
I0629 11:16:35.444089  2332 solver.cpp:397]     Test net output #1: loss = 0.338578 (* 1 = 0.338578 loss)
I0629 11:16:35.478113  2332 solver.cpp:218] Iteration 36000 (22.3704 iter/s, 4.4702s/100 iters), loss = 0.178243
I0629 11:16:35.478113  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:16:35.478113  2332 solver.cpp:237]     Train net output #1: loss = 0.178243 (* 1 = 0.178243 loss)
I0629 11:16:35.478113  2332 sgd_solver.cpp:105] Iteration 36000, lr = 0.001
I0629 11:16:39.102804  2332 solver.cpp:218] Iteration 36100 (27.5896 iter/s, 3.62456s/100 iters), loss = 0.170804
I0629 11:16:39.102804  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:16:39.102804  2332 solver.cpp:237]     Train net output #1: loss = 0.170804 (* 1 = 0.170804 loss)
I0629 11:16:39.102804  2332 sgd_solver.cpp:105] Iteration 36100, lr = 0.001
I0629 11:16:42.723300  2332 solver.cpp:218] Iteration 36200 (27.6211 iter/s, 3.62042s/100 iters), loss = 0.140272
I0629 11:16:42.724301  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:16:42.724301  2332 solver.cpp:237]     Train net output #1: loss = 0.140272 (* 1 = 0.140272 loss)
I0629 11:16:42.724301  2332 sgd_solver.cpp:105] Iteration 36200, lr = 0.001
I0629 11:16:46.360553  2332 solver.cpp:218] Iteration 36300 (27.496 iter/s, 3.63689s/100 iters), loss = 0.156792
I0629 11:16:46.361554  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:16:46.361554  2332 solver.cpp:237]     Train net output #1: loss = 0.156792 (* 1 = 0.156792 loss)
I0629 11:16:46.361554  2332 sgd_solver.cpp:105] Iteration 36300, lr = 0.001
I0629 11:16:49.987270  2332 solver.cpp:218] Iteration 36400 (27.5797 iter/s, 3.62586s/100 iters), loss = 0.125389
I0629 11:16:49.987270  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:16:49.987270  2332 solver.cpp:237]     Train net output #1: loss = 0.125389 (* 1 = 0.125389 loss)
I0629 11:16:49.987270  2332 sgd_solver.cpp:105] Iteration 36400, lr = 0.001
I0629 11:16:53.441908  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:16:53.583014  2332 solver.cpp:330] Iteration 36500, Testing net (#0)
I0629 11:16:53.583014  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:16:54.409654  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:16:54.440676  2332 solver.cpp:397]     Test net output #0: accuracy = 0.893
I0629 11:16:54.440676  2332 solver.cpp:397]     Test net output #1: loss = 0.340698 (* 1 = 0.340698 loss)
I0629 11:16:54.474704  2332 solver.cpp:218] Iteration 36500 (22.2837 iter/s, 4.48758s/100 iters), loss = 0.124793
I0629 11:16:54.474704  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:16:54.474704  2332 solver.cpp:237]     Train net output #1: loss = 0.124793 (* 1 = 0.124793 loss)
I0629 11:16:54.474704  2332 sgd_solver.cpp:105] Iteration 36500, lr = 0.001
I0629 11:16:58.100427  2332 solver.cpp:218] Iteration 36600 (27.5853 iter/s, 3.62512s/100 iters), loss = 0.145331
I0629 11:16:58.100427  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:16:58.100427  2332 solver.cpp:237]     Train net output #1: loss = 0.145331 (* 1 = 0.145331 loss)
I0629 11:16:58.100427  2332 sgd_solver.cpp:105] Iteration 36600, lr = 0.001
I0629 11:17:01.729171  2332 solver.cpp:218] Iteration 36700 (27.5652 iter/s, 3.62776s/100 iters), loss = 0.0952416
I0629 11:17:01.729171  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:17:01.729171  2332 solver.cpp:237]     Train net output #1: loss = 0.0952418 (* 1 = 0.0952418 loss)
I0629 11:17:01.729171  2332 sgd_solver.cpp:105] Iteration 36700, lr = 0.001
I0629 11:17:05.348263  2332 solver.cpp:218] Iteration 36800 (27.6326 iter/s, 3.61891s/100 iters), loss = 0.158796
I0629 11:17:05.348263  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:17:05.348263  2332 solver.cpp:237]     Train net output #1: loss = 0.158796 (* 1 = 0.158796 loss)
I0629 11:17:05.348263  2332 sgd_solver.cpp:105] Iteration 36800, lr = 0.001
I0629 11:17:08.968452  2332 solver.cpp:218] Iteration 36900 (27.6265 iter/s, 3.61971s/100 iters), loss = 0.139037
I0629 11:17:08.968452  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:17:08.968452  2332 solver.cpp:237]     Train net output #1: loss = 0.139037 (* 1 = 0.139037 loss)
I0629 11:17:08.968452  2332 sgd_solver.cpp:105] Iteration 36900, lr = 0.001
I0629 11:17:12.420348  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:17:12.562463  2332 solver.cpp:330] Iteration 37000, Testing net (#0)
I0629 11:17:12.562463  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:17:13.379114  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:17:13.410137  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8916
I0629 11:17:13.410137  2332 solver.cpp:397]     Test net output #1: loss = 0.342539 (* 1 = 0.342539 loss)
I0629 11:17:13.445161  2332 solver.cpp:218] Iteration 37000 (22.3383 iter/s, 4.47662s/100 iters), loss = 0.146366
I0629 11:17:13.445161  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:17:13.445161  2332 solver.cpp:237]     Train net output #1: loss = 0.146366 (* 1 = 0.146366 loss)
I0629 11:17:13.445161  2332 sgd_solver.cpp:105] Iteration 37000, lr = 0.001
I0629 11:17:17.080730  2332 solver.cpp:218] Iteration 37100 (27.5049 iter/s, 3.63571s/100 iters), loss = 0.161278
I0629 11:17:17.080730  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:17:17.080730  2332 solver.cpp:237]     Train net output #1: loss = 0.161279 (* 1 = 0.161279 loss)
I0629 11:17:17.080730  2332 sgd_solver.cpp:105] Iteration 37100, lr = 0.001
I0629 11:17:20.720345  2332 solver.cpp:218] Iteration 37200 (27.4819 iter/s, 3.63876s/100 iters), loss = 0.157147
I0629 11:17:20.720345  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:17:20.720345  2332 solver.cpp:237]     Train net output #1: loss = 0.157147 (* 1 = 0.157147 loss)
I0629 11:17:20.720345  2332 sgd_solver.cpp:105] Iteration 37200, lr = 0.001
I0629 11:17:24.349297  2332 solver.cpp:218] Iteration 37300 (27.5591 iter/s, 3.62857s/100 iters), loss = 0.167153
I0629 11:17:24.349297  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:17:24.349297  2332 solver.cpp:237]     Train net output #1: loss = 0.167153 (* 1 = 0.167153 loss)
I0629 11:17:24.349297  2332 sgd_solver.cpp:105] Iteration 37300, lr = 0.001
I0629 11:17:27.970548  2332 solver.cpp:218] Iteration 37400 (27.6178 iter/s, 3.62086s/100 iters), loss = 0.125593
I0629 11:17:27.970548  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:17:27.970548  2332 solver.cpp:237]     Train net output #1: loss = 0.125593 (* 1 = 0.125593 loss)
I0629 11:17:27.970548  2332 sgd_solver.cpp:105] Iteration 37400, lr = 0.001
I0629 11:17:31.426378  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:17:31.567992  2332 solver.cpp:330] Iteration 37500, Testing net (#0)
I0629 11:17:31.567992  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:17:32.386045  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:17:32.417069  2332 solver.cpp:397]     Test net output #0: accuracy = 0.895
I0629 11:17:32.417069  2332 solver.cpp:397]     Test net output #1: loss = 0.341087 (* 1 = 0.341087 loss)
I0629 11:17:32.451092  2332 solver.cpp:218] Iteration 37500 (22.3181 iter/s, 4.48067s/100 iters), loss = 0.10331
I0629 11:17:32.451092  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:17:32.451092  2332 solver.cpp:237]     Train net output #1: loss = 0.103311 (* 1 = 0.103311 loss)
I0629 11:17:32.451092  2332 sgd_solver.cpp:105] Iteration 37500, lr = 0.001
I0629 11:17:36.086177  2332 solver.cpp:218] Iteration 37600 (27.5157 iter/s, 3.63429s/100 iters), loss = 0.153173
I0629 11:17:36.086177  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:17:36.086177  2332 solver.cpp:237]     Train net output #1: loss = 0.153173 (* 1 = 0.153173 loss)
I0629 11:17:36.086177  2332 sgd_solver.cpp:105] Iteration 37600, lr = 0.001
I0629 11:17:39.713017  2332 solver.cpp:218] Iteration 37700 (27.5713 iter/s, 3.62696s/100 iters), loss = 0.133112
I0629 11:17:39.713017  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:17:39.713017  2332 solver.cpp:237]     Train net output #1: loss = 0.133113 (* 1 = 0.133113 loss)
I0629 11:17:39.713017  2332 sgd_solver.cpp:105] Iteration 37700, lr = 0.001
I0629 11:17:43.334729  2332 solver.cpp:218] Iteration 37800 (27.6177 iter/s, 3.62086s/100 iters), loss = 0.151988
I0629 11:17:43.334729  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:17:43.334729  2332 solver.cpp:237]     Train net output #1: loss = 0.151988 (* 1 = 0.151988 loss)
I0629 11:17:43.334729  2332 sgd_solver.cpp:105] Iteration 37800, lr = 0.001
I0629 11:17:46.957531  2332 solver.cpp:218] Iteration 37900 (27.6005 iter/s, 3.62312s/100 iters), loss = 0.146996
I0629 11:17:46.957531  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:17:46.957531  2332 solver.cpp:237]     Train net output #1: loss = 0.146996 (* 1 = 0.146996 loss)
I0629 11:17:46.957531  2332 sgd_solver.cpp:105] Iteration 37900, lr = 0.001
I0629 11:17:50.416307  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:17:50.558413  2332 solver.cpp:330] Iteration 38000, Testing net (#0)
I0629 11:17:50.558413  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:17:51.376199  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:17:51.407220  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8929
I0629 11:17:51.407220  2332 solver.cpp:397]     Test net output #1: loss = 0.344994 (* 1 = 0.344994 loss)
I0629 11:17:51.441745  2332 solver.cpp:218] Iteration 38000 (22.3043 iter/s, 4.48343s/100 iters), loss = 0.133027
I0629 11:17:51.441745  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:17:51.441745  2332 solver.cpp:237]     Train net output #1: loss = 0.133027 (* 1 = 0.133027 loss)
I0629 11:17:51.441745  2332 sgd_solver.cpp:105] Iteration 38000, lr = 0.001
I0629 11:17:55.060812  2332 solver.cpp:218] Iteration 38100 (27.631 iter/s, 3.61913s/100 iters), loss = 0.117145
I0629 11:17:55.060812  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:17:55.060812  2332 solver.cpp:237]     Train net output #1: loss = 0.117146 (* 1 = 0.117146 loss)
I0629 11:17:55.060812  2332 sgd_solver.cpp:105] Iteration 38100, lr = 0.001
I0629 11:17:58.706539  2332 solver.cpp:218] Iteration 38200 (27.435 iter/s, 3.64498s/100 iters), loss = 0.157529
I0629 11:17:58.706539  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:17:58.706539  2332 solver.cpp:237]     Train net output #1: loss = 0.157529 (* 1 = 0.157529 loss)
I0629 11:17:58.706539  2332 sgd_solver.cpp:105] Iteration 38200, lr = 0.001
I0629 11:18:02.351764  2332 solver.cpp:218] Iteration 38300 (27.4354 iter/s, 3.64493s/100 iters), loss = 0.150422
I0629 11:18:02.351764  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:18:02.352264  2332 solver.cpp:237]     Train net output #1: loss = 0.150422 (* 1 = 0.150422 loss)
I0629 11:18:02.352264  2332 sgd_solver.cpp:105] Iteration 38300, lr = 0.001
I0629 11:18:05.978130  2332 solver.cpp:218] Iteration 38400 (27.5773 iter/s, 3.62617s/100 iters), loss = 0.118809
I0629 11:18:05.978130  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:18:05.978130  2332 solver.cpp:237]     Train net output #1: loss = 0.118809 (* 1 = 0.118809 loss)
I0629 11:18:05.978130  2332 sgd_solver.cpp:105] Iteration 38400, lr = 0.001
I0629 11:18:09.426983  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:18:09.573098  2332 solver.cpp:330] Iteration 38500, Testing net (#0)
I0629 11:18:09.573098  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:18:10.391726  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:18:10.422744  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8936
I0629 11:18:10.422744  2332 solver.cpp:397]     Test net output #1: loss = 0.347215 (* 1 = 0.347215 loss)
I0629 11:18:10.457769  2332 solver.cpp:218] Iteration 38500 (22.3269 iter/s, 4.47891s/100 iters), loss = 0.0923084
I0629 11:18:10.457769  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:18:10.457769  2332 solver.cpp:237]     Train net output #1: loss = 0.0923086 (* 1 = 0.0923086 loss)
I0629 11:18:10.457769  2332 sgd_solver.cpp:105] Iteration 38500, lr = 0.001
I0629 11:18:14.080457  2332 solver.cpp:218] Iteration 38600 (27.6016 iter/s, 3.62298s/100 iters), loss = 0.166892
I0629 11:18:14.080457  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:18:14.080457  2332 solver.cpp:237]     Train net output #1: loss = 0.166892 (* 1 = 0.166892 loss)
I0629 11:18:14.080457  2332 sgd_solver.cpp:105] Iteration 38600, lr = 0.001
I0629 11:18:17.713407  2332 solver.cpp:218] Iteration 38700 (27.5331 iter/s, 3.632s/100 iters), loss = 0.13032
I0629 11:18:17.713407  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:18:17.713407  2332 solver.cpp:237]     Train net output #1: loss = 0.13032 (* 1 = 0.13032 loss)
I0629 11:18:17.713407  2332 sgd_solver.cpp:105] Iteration 38700, lr = 0.001
I0629 11:18:21.340121  2332 solver.cpp:218] Iteration 38800 (27.5731 iter/s, 3.62672s/100 iters), loss = 0.14841
I0629 11:18:21.340121  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:18:21.340121  2332 solver.cpp:237]     Train net output #1: loss = 0.14841 (* 1 = 0.14841 loss)
I0629 11:18:21.340121  2332 sgd_solver.cpp:105] Iteration 38800, lr = 0.001
I0629 11:18:24.969794  2332 solver.cpp:218] Iteration 38900 (27.5552 iter/s, 3.62908s/100 iters), loss = 0.126866
I0629 11:18:24.969794  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:18:24.969794  2332 solver.cpp:237]     Train net output #1: loss = 0.126866 (* 1 = 0.126866 loss)
I0629 11:18:24.969794  2332 sgd_solver.cpp:105] Iteration 38900, lr = 0.001
I0629 11:18:28.415475  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:18:28.558579  2332 solver.cpp:330] Iteration 39000, Testing net (#0)
I0629 11:18:28.558579  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:18:29.378324  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:18:29.409346  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0629 11:18:29.409346  2332 solver.cpp:397]     Test net output #1: loss = 0.345658 (* 1 = 0.345658 loss)
I0629 11:18:29.444371  2332 solver.cpp:218] Iteration 39000 (22.3513 iter/s, 4.47401s/100 iters), loss = 0.12256
I0629 11:18:29.444371  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:18:29.444371  2332 solver.cpp:237]     Train net output #1: loss = 0.122561 (* 1 = 0.122561 loss)
I0629 11:18:29.444371  2332 sgd_solver.cpp:105] Iteration 39000, lr = 0.001
I0629 11:18:33.073083  2332 solver.cpp:218] Iteration 39100 (27.5582 iter/s, 3.62868s/100 iters), loss = 0.164496
I0629 11:18:33.073083  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:18:33.073083  2332 solver.cpp:237]     Train net output #1: loss = 0.164496 (* 1 = 0.164496 loss)
I0629 11:18:33.073083  2332 sgd_solver.cpp:105] Iteration 39100, lr = 0.001
I0629 11:18:36.711951  2332 solver.cpp:218] Iteration 39200 (27.4837 iter/s, 3.63852s/100 iters), loss = 0.10202
I0629 11:18:36.711951  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:18:36.711951  2332 solver.cpp:237]     Train net output #1: loss = 0.10202 (* 1 = 0.10202 loss)
I0629 11:18:36.711951  2332 sgd_solver.cpp:105] Iteration 39200, lr = 0.001
I0629 11:18:40.341650  2332 solver.cpp:218] Iteration 39300 (27.5548 iter/s, 3.62913s/100 iters), loss = 0.176747
I0629 11:18:40.341650  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:18:40.341650  2332 solver.cpp:237]     Train net output #1: loss = 0.176747 (* 1 = 0.176747 loss)
I0629 11:18:40.341650  2332 sgd_solver.cpp:105] Iteration 39300, lr = 0.001
I0629 11:18:43.960420  2332 solver.cpp:218] Iteration 39400 (27.6344 iter/s, 3.61868s/100 iters), loss = 0.111545
I0629 11:18:43.960420  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:18:43.960420  2332 solver.cpp:237]     Train net output #1: loss = 0.111545 (* 1 = 0.111545 loss)
I0629 11:18:43.960420  2332 sgd_solver.cpp:105] Iteration 39400, lr = 0.001
I0629 11:18:47.404979  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:18:47.546082  2332 solver.cpp:330] Iteration 39500, Testing net (#0)
I0629 11:18:47.547083  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:18:48.362787  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:18:48.393812  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8929
I0629 11:18:48.393812  2332 solver.cpp:397]     Test net output #1: loss = 0.345614 (* 1 = 0.345614 loss)
I0629 11:18:48.427835  2332 solver.cpp:218] Iteration 39500 (22.3862 iter/s, 4.46704s/100 iters), loss = 0.12163
I0629 11:18:48.427835  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:18:48.427835  2332 solver.cpp:237]     Train net output #1: loss = 0.12163 (* 1 = 0.12163 loss)
I0629 11:18:48.427835  2332 sgd_solver.cpp:105] Iteration 39500, lr = 0.001
I0629 11:18:52.051291  2332 solver.cpp:218] Iteration 39600 (27.5961 iter/s, 3.6237s/100 iters), loss = 0.194201
I0629 11:18:52.051291  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:18:52.051291  2332 solver.cpp:237]     Train net output #1: loss = 0.194201 (* 1 = 0.194201 loss)
I0629 11:18:52.051291  2332 sgd_solver.cpp:105] Iteration 39600, lr = 0.001
I0629 11:18:55.680584  2332 solver.cpp:218] Iteration 39700 (27.5608 iter/s, 3.62835s/100 iters), loss = 0.177265
I0629 11:18:55.680584  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:18:55.680584  2332 solver.cpp:237]     Train net output #1: loss = 0.177265 (* 1 = 0.177265 loss)
I0629 11:18:55.680584  2332 sgd_solver.cpp:105] Iteration 39700, lr = 0.001
I0629 11:18:59.309592  2332 solver.cpp:218] Iteration 39800 (27.5542 iter/s, 3.62921s/100 iters), loss = 0.0873462
I0629 11:18:59.309592  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:18:59.309592  2332 solver.cpp:237]     Train net output #1: loss = 0.0873462 (* 1 = 0.0873462 loss)
I0629 11:18:59.309592  2332 sgd_solver.cpp:105] Iteration 39800, lr = 0.001
I0629 11:19:02.951128  2332 solver.cpp:218] Iteration 39900 (27.4697 iter/s, 3.64037s/100 iters), loss = 0.123636
I0629 11:19:02.951128  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:19:02.951128  2332 solver.cpp:237]     Train net output #1: loss = 0.123636 (* 1 = 0.123636 loss)
I0629 11:19:02.951128  2332 sgd_solver.cpp:105] Iteration 39900, lr = 0.001
I0629 11:19:06.404886  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:19:06.546993  2332 solver.cpp:330] Iteration 40000, Testing net (#0)
I0629 11:19:06.546993  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:19:07.380892  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:19:07.403914  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8921
I0629 11:19:07.403914  2332 solver.cpp:397]     Test net output #1: loss = 0.349706 (* 1 = 0.349706 loss)
I0629 11:19:07.437932  2332 solver.cpp:218] Iteration 40000 (22.2881 iter/s, 4.4867s/100 iters), loss = 0.148583
I0629 11:19:07.437932  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:19:07.437932  2332 solver.cpp:237]     Train net output #1: loss = 0.148583 (* 1 = 0.148583 loss)
I0629 11:19:07.437932  2332 sgd_solver.cpp:105] Iteration 40000, lr = 0.001
I0629 11:19:11.059520  2332 solver.cpp:218] Iteration 40100 (27.6118 iter/s, 3.62164s/100 iters), loss = 0.131959
I0629 11:19:11.059520  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:19:11.059520  2332 solver.cpp:237]     Train net output #1: loss = 0.131959 (* 1 = 0.131959 loss)
I0629 11:19:11.059520  2332 sgd_solver.cpp:105] Iteration 40100, lr = 0.001
I0629 11:19:14.692564  2332 solver.cpp:218] Iteration 40200 (27.5271 iter/s, 3.63279s/100 iters), loss = 0.188248
I0629 11:19:14.692564  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:19:14.692564  2332 solver.cpp:237]     Train net output #1: loss = 0.188248 (* 1 = 0.188248 loss)
I0629 11:19:14.692564  2332 sgd_solver.cpp:105] Iteration 40200, lr = 0.001
I0629 11:19:18.326582  2332 solver.cpp:218] Iteration 40300 (27.5186 iter/s, 3.6339s/100 iters), loss = 0.141477
I0629 11:19:18.327600  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:19:18.327600  2332 solver.cpp:237]     Train net output #1: loss = 0.141477 (* 1 = 0.141477 loss)
I0629 11:19:18.327600  2332 sgd_solver.cpp:105] Iteration 40300, lr = 0.001
I0629 11:19:21.956632  2332 solver.cpp:218] Iteration 40400 (27.5567 iter/s, 3.62888s/100 iters), loss = 0.125223
I0629 11:19:21.956632  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:19:21.956632  2332 solver.cpp:237]     Train net output #1: loss = 0.125223 (* 1 = 0.125223 loss)
I0629 11:19:21.956632  2332 sgd_solver.cpp:105] Iteration 40400, lr = 0.001
I0629 11:19:25.400537  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:19:25.542245  2332 solver.cpp:330] Iteration 40500, Testing net (#0)
I0629 11:19:25.542245  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:19:26.361001  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:19:26.392040  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8929
I0629 11:19:26.392040  2332 solver.cpp:397]     Test net output #1: loss = 0.350499 (* 1 = 0.350499 loss)
I0629 11:19:26.426062  2332 solver.cpp:218] Iteration 40500 (22.3723 iter/s, 4.46981s/100 iters), loss = 0.0922468
I0629 11:19:26.426062  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:19:26.427073  2332 solver.cpp:237]     Train net output #1: loss = 0.0922467 (* 1 = 0.0922467 loss)
I0629 11:19:26.427073  2332 sgd_solver.cpp:105] Iteration 40500, lr = 0.001
I0629 11:19:30.050266  2332 solver.cpp:218] Iteration 40600 (27.5961 iter/s, 3.6237s/100 iters), loss = 0.145639
I0629 11:19:30.050266  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:19:30.050266  2332 solver.cpp:237]     Train net output #1: loss = 0.145639 (* 1 = 0.145639 loss)
I0629 11:19:30.050266  2332 sgd_solver.cpp:105] Iteration 40600, lr = 0.001
I0629 11:19:33.677003  2332 solver.cpp:218] Iteration 40700 (27.5783 iter/s, 3.62604s/100 iters), loss = 0.192136
I0629 11:19:33.677003  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:19:33.677003  2332 solver.cpp:237]     Train net output #1: loss = 0.192136 (* 1 = 0.192136 loss)
I0629 11:19:33.677003  2332 sgd_solver.cpp:105] Iteration 40700, lr = 0.001
I0629 11:19:37.296680  2332 solver.cpp:218] Iteration 40800 (27.6272 iter/s, 3.61963s/100 iters), loss = 0.099806
I0629 11:19:37.296680  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:19:37.296680  2332 solver.cpp:237]     Train net output #1: loss = 0.099806 (* 1 = 0.099806 loss)
I0629 11:19:37.296680  2332 sgd_solver.cpp:105] Iteration 40800, lr = 0.001
I0629 11:19:40.928294  2332 solver.cpp:218] Iteration 40900 (27.5427 iter/s, 3.63072s/100 iters), loss = 0.164128
I0629 11:19:40.928294  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:19:40.928294  2332 solver.cpp:237]     Train net output #1: loss = 0.164128 (* 1 = 0.164128 loss)
I0629 11:19:40.928294  2332 sgd_solver.cpp:105] Iteration 40900, lr = 0.001
I0629 11:19:44.385891  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:19:44.527997  2332 solver.cpp:330] Iteration 41000, Testing net (#0)
I0629 11:19:44.528498  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:19:45.343616  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:19:45.374639  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8916
I0629 11:19:45.374639  2332 solver.cpp:397]     Test net output #1: loss = 0.350025 (* 1 = 0.350025 loss)
I0629 11:19:45.408663  2332 solver.cpp:218] Iteration 41000 (22.3207 iter/s, 4.48016s/100 iters), loss = 0.101747
I0629 11:19:45.408663  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:19:45.408663  2332 solver.cpp:237]     Train net output #1: loss = 0.101747 (* 1 = 0.101747 loss)
I0629 11:19:45.408663  2332 sgd_solver.cpp:105] Iteration 41000, lr = 0.001
I0629 11:19:49.036869  2332 solver.cpp:218] Iteration 41100 (27.5634 iter/s, 3.62801s/100 iters), loss = 0.1495
I0629 11:19:49.036869  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:19:49.036869  2332 solver.cpp:237]     Train net output #1: loss = 0.1495 (* 1 = 0.1495 loss)
I0629 11:19:49.037369  2332 sgd_solver.cpp:105] Iteration 41100, lr = 0.001
I0629 11:19:52.663290  2332 solver.cpp:218] Iteration 41200 (27.5804 iter/s, 3.62576s/100 iters), loss = 0.100813
I0629 11:19:52.663290  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:19:52.663290  2332 solver.cpp:237]     Train net output #1: loss = 0.100812 (* 1 = 0.100812 loss)
I0629 11:19:52.663290  2332 sgd_solver.cpp:105] Iteration 41200, lr = 0.001
I0629 11:19:56.279067  2332 solver.cpp:218] Iteration 41300 (27.6536 iter/s, 3.61616s/100 iters), loss = 0.111663
I0629 11:19:56.279067  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:19:56.279067  2332 solver.cpp:237]     Train net output #1: loss = 0.111662 (* 1 = 0.111662 loss)
I0629 11:19:56.279067  2332 sgd_solver.cpp:105] Iteration 41300, lr = 0.001
I0629 11:19:59.902274  2332 solver.cpp:218] Iteration 41400 (27.6038 iter/s, 3.62269s/100 iters), loss = 0.132069
I0629 11:19:59.902274  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:19:59.902274  2332 solver.cpp:237]     Train net output #1: loss = 0.132069 (* 1 = 0.132069 loss)
I0629 11:19:59.902274  2332 sgd_solver.cpp:105] Iteration 41400, lr = 0.001
I0629 11:20:03.363440  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:20:03.504544  2332 solver.cpp:330] Iteration 41500, Testing net (#0)
I0629 11:20:03.504544  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:20:04.322168  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:20:04.353694  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I0629 11:20:04.353694  2332 solver.cpp:397]     Test net output #1: loss = 0.351244 (* 1 = 0.351244 loss)
I0629 11:20:04.388221  2332 solver.cpp:218] Iteration 41500 (22.2936 iter/s, 4.48559s/100 iters), loss = 0.136099
I0629 11:20:04.388221  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:20:04.388221  2332 solver.cpp:237]     Train net output #1: loss = 0.136099 (* 1 = 0.136099 loss)
I0629 11:20:04.388221  2332 sgd_solver.cpp:105] Iteration 41500, lr = 0.001
I0629 11:20:08.017081  2332 solver.cpp:218] Iteration 41600 (27.5589 iter/s, 3.62859s/100 iters), loss = 0.139332
I0629 11:20:08.017081  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:20:08.017081  2332 solver.cpp:237]     Train net output #1: loss = 0.139332 (* 1 = 0.139332 loss)
I0629 11:20:08.017081  2332 sgd_solver.cpp:105] Iteration 41600, lr = 0.001
I0629 11:20:11.655361  2332 solver.cpp:218] Iteration 41700 (27.4932 iter/s, 3.63726s/100 iters), loss = 0.106044
I0629 11:20:11.655361  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:20:11.655361  2332 solver.cpp:237]     Train net output #1: loss = 0.106044 (* 1 = 0.106044 loss)
I0629 11:20:11.655361  2332 sgd_solver.cpp:105] Iteration 41700, lr = 0.001
I0629 11:20:15.286165  2332 solver.cpp:218] Iteration 41800 (27.542 iter/s, 3.63081s/100 iters), loss = 0.17358
I0629 11:20:15.286165  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:20:15.286165  2332 solver.cpp:237]     Train net output #1: loss = 0.173579 (* 1 = 0.173579 loss)
I0629 11:20:15.286165  2332 sgd_solver.cpp:105] Iteration 41800, lr = 0.001
I0629 11:20:18.920086  2332 solver.cpp:218] Iteration 41900 (27.5238 iter/s, 3.63322s/100 iters), loss = 0.0926553
I0629 11:20:18.920086  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:20:18.920086  2332 solver.cpp:237]     Train net output #1: loss = 0.0926551 (* 1 = 0.0926551 loss)
I0629 11:20:18.920086  2332 sgd_solver.cpp:105] Iteration 41900, lr = 0.001
I0629 11:20:22.382640  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:20:22.527400  2332 solver.cpp:330] Iteration 42000, Testing net (#0)
I0629 11:20:22.527400  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:20:23.348639  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:20:23.379709  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8932
I0629 11:20:23.379709  2332 solver.cpp:397]     Test net output #1: loss = 0.35252 (* 1 = 0.35252 loss)
I0629 11:20:23.413733  2332 solver.cpp:218] Iteration 42000 (22.2508 iter/s, 4.49422s/100 iters), loss = 0.106435
I0629 11:20:23.413733  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:20:23.413733  2332 solver.cpp:237]     Train net output #1: loss = 0.106435 (* 1 = 0.106435 loss)
I0629 11:20:23.414733  2332 sgd_solver.cpp:105] Iteration 42000, lr = 0.001
I0629 11:20:27.047695  2332 solver.cpp:218] Iteration 42100 (27.525 iter/s, 3.63306s/100 iters), loss = 0.178196
I0629 11:20:27.047695  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:20:27.047695  2332 solver.cpp:237]     Train net output #1: loss = 0.178196 (* 1 = 0.178196 loss)
I0629 11:20:27.047695  2332 sgd_solver.cpp:105] Iteration 42100, lr = 0.001
I0629 11:20:30.680943  2332 solver.cpp:218] Iteration 42200 (27.5228 iter/s, 3.63336s/100 iters), loss = 0.186486
I0629 11:20:30.680943  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:20:30.680943  2332 solver.cpp:237]     Train net output #1: loss = 0.186486 (* 1 = 0.186486 loss)
I0629 11:20:30.680943  2332 sgd_solver.cpp:105] Iteration 42200, lr = 0.001
I0629 11:20:34.318902  2332 solver.cpp:218] Iteration 42300 (27.4957 iter/s, 3.63693s/100 iters), loss = 0.136006
I0629 11:20:34.318902  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:20:34.318902  2332 solver.cpp:237]     Train net output #1: loss = 0.136006 (* 1 = 0.136006 loss)
I0629 11:20:34.318902  2332 sgd_solver.cpp:105] Iteration 42300, lr = 0.001
I0629 11:20:37.968961  2332 solver.cpp:218] Iteration 42400 (27.3989 iter/s, 3.64978s/100 iters), loss = 0.0919912
I0629 11:20:37.968961  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:20:37.968961  2332 solver.cpp:237]     Train net output #1: loss = 0.0919909 (* 1 = 0.0919909 loss)
I0629 11:20:37.968961  2332 sgd_solver.cpp:105] Iteration 42400, lr = 0.001
I0629 11:20:41.433989  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:20:41.576637  2332 solver.cpp:330] Iteration 42500, Testing net (#0)
I0629 11:20:41.576637  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:20:42.392046  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:20:42.423583  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8915
I0629 11:20:42.423583  2332 solver.cpp:397]     Test net output #1: loss = 0.350949 (* 1 = 0.350949 loss)
I0629 11:20:42.457638  2332 solver.cpp:218] Iteration 42500 (22.2785 iter/s, 4.48864s/100 iters), loss = 0.104803
I0629 11:20:42.457638  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:20:42.457638  2332 solver.cpp:237]     Train net output #1: loss = 0.104802 (* 1 = 0.104802 loss)
I0629 11:20:42.457638  2332 sgd_solver.cpp:105] Iteration 42500, lr = 0.001
I0629 11:20:46.090497  2332 solver.cpp:218] Iteration 42600 (27.5291 iter/s, 3.63252s/100 iters), loss = 0.13015
I0629 11:20:46.090497  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:20:46.090497  2332 solver.cpp:237]     Train net output #1: loss = 0.13015 (* 1 = 0.13015 loss)
I0629 11:20:46.090497  2332 sgd_solver.cpp:105] Iteration 42600, lr = 0.001
I0629 11:20:49.722725  2332 solver.cpp:218] Iteration 42700 (27.5317 iter/s, 3.63218s/100 iters), loss = 0.0843415
I0629 11:20:49.722725  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:20:49.722725  2332 solver.cpp:237]     Train net output #1: loss = 0.0843412 (* 1 = 0.0843412 loss)
I0629 11:20:49.722725  2332 sgd_solver.cpp:105] Iteration 42700, lr = 0.001
I0629 11:20:53.352259  2332 solver.cpp:218] Iteration 42800 (27.5572 iter/s, 3.62882s/100 iters), loss = 0.100608
I0629 11:20:53.352259  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:20:53.352259  2332 solver.cpp:237]     Train net output #1: loss = 0.100608 (* 1 = 0.100608 loss)
I0629 11:20:53.352259  2332 sgd_solver.cpp:105] Iteration 42800, lr = 0.001
I0629 11:20:56.981268  2332 solver.cpp:218] Iteration 42900 (27.5556 iter/s, 3.62902s/100 iters), loss = 0.118908
I0629 11:20:56.981268  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:20:56.981268  2332 solver.cpp:237]     Train net output #1: loss = 0.118908 (* 1 = 0.118908 loss)
I0629 11:20:56.981268  2332 sgd_solver.cpp:105] Iteration 42900, lr = 0.001
I0629 11:21:00.440697  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:21:00.582819  2332 solver.cpp:330] Iteration 43000, Testing net (#0)
I0629 11:21:00.582819  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:21:01.406761  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:21:01.437818  2332 solver.cpp:397]     Test net output #0: accuracy = 0.893
I0629 11:21:01.437818  2332 solver.cpp:397]     Test net output #1: loss = 0.353189 (* 1 = 0.353189 loss)
I0629 11:21:01.471837  2332 solver.cpp:218] Iteration 43000 (22.2697 iter/s, 4.49041s/100 iters), loss = 0.122386
I0629 11:21:01.472841  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:21:01.472841  2332 solver.cpp:237]     Train net output #1: loss = 0.122386 (* 1 = 0.122386 loss)
I0629 11:21:01.472841  2332 sgd_solver.cpp:105] Iteration 43000, lr = 0.001
I0629 11:21:05.117777  2332 solver.cpp:218] Iteration 43100 (27.4342 iter/s, 3.64508s/100 iters), loss = 0.163117
I0629 11:21:05.117777  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:21:05.117777  2332 solver.cpp:237]     Train net output #1: loss = 0.163117 (* 1 = 0.163117 loss)
I0629 11:21:05.117777  2332 sgd_solver.cpp:105] Iteration 43100, lr = 0.001
I0629 11:21:08.751981  2332 solver.cpp:218] Iteration 43200 (27.5197 iter/s, 3.63375s/100 iters), loss = 0.094436
I0629 11:21:08.751981  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:21:08.751981  2332 solver.cpp:237]     Train net output #1: loss = 0.0944357 (* 1 = 0.0944357 loss)
I0629 11:21:08.751981  2332 sgd_solver.cpp:105] Iteration 43200, lr = 0.001
I0629 11:21:12.380267  2332 solver.cpp:218] Iteration 43300 (27.5606 iter/s, 3.62837s/100 iters), loss = 0.133276
I0629 11:21:12.380267  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:21:12.380267  2332 solver.cpp:237]     Train net output #1: loss = 0.133275 (* 1 = 0.133275 loss)
I0629 11:21:12.381268  2332 sgd_solver.cpp:105] Iteration 43300, lr = 0.001
I0629 11:21:16.021849  2332 solver.cpp:218] Iteration 43400 (27.467 iter/s, 3.64074s/100 iters), loss = 0.083643
I0629 11:21:16.021849  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:21:16.021849  2332 solver.cpp:237]     Train net output #1: loss = 0.0836428 (* 1 = 0.0836428 loss)
I0629 11:21:16.021849  2332 sgd_solver.cpp:105] Iteration 43400, lr = 0.001
I0629 11:21:19.490324  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:21:19.638934  2332 solver.cpp:330] Iteration 43500, Testing net (#0)
I0629 11:21:19.638934  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:21:20.455618  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:21:20.486640  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0629 11:21:20.486640  2332 solver.cpp:397]     Test net output #1: loss = 0.356544 (* 1 = 0.356544 loss)
I0629 11:21:20.520665  2332 solver.cpp:218] Iteration 43500 (22.228 iter/s, 4.49884s/100 iters), loss = 0.117783
I0629 11:21:20.520665  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:21:20.520665  2332 solver.cpp:237]     Train net output #1: loss = 0.117783 (* 1 = 0.117783 loss)
I0629 11:21:20.520665  2332 sgd_solver.cpp:105] Iteration 43500, lr = 0.001
I0629 11:21:24.158619  2332 solver.cpp:218] Iteration 43600 (27.4965 iter/s, 3.63683s/100 iters), loss = 0.125063
I0629 11:21:24.158619  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:21:24.158619  2332 solver.cpp:237]     Train net output #1: loss = 0.125062 (* 1 = 0.125062 loss)
I0629 11:21:24.158619  2332 sgd_solver.cpp:105] Iteration 43600, lr = 0.001
I0629 11:21:27.779322  2332 solver.cpp:218] Iteration 43700 (27.6208 iter/s, 3.62045s/100 iters), loss = 0.121336
I0629 11:21:27.779322  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:21:27.779322  2332 solver.cpp:237]     Train net output #1: loss = 0.121336 (* 1 = 0.121336 loss)
I0629 11:21:27.779322  2332 sgd_solver.cpp:105] Iteration 43700, lr = 0.001
I0629 11:21:31.403048  2332 solver.cpp:218] Iteration 43800 (27.5925 iter/s, 3.62417s/100 iters), loss = 0.133993
I0629 11:21:31.403048  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:21:31.403048  2332 solver.cpp:237]     Train net output #1: loss = 0.133992 (* 1 = 0.133992 loss)
I0629 11:21:31.404049  2332 sgd_solver.cpp:105] Iteration 43800, lr = 0.001
I0629 11:21:35.027875  2332 solver.cpp:218] Iteration 43900 (27.59 iter/s, 3.6245s/100 iters), loss = 0.102771
I0629 11:21:35.027875  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:21:35.028877  2332 solver.cpp:237]     Train net output #1: loss = 0.10277 (* 1 = 0.10277 loss)
I0629 11:21:35.028877  2332 sgd_solver.cpp:105] Iteration 43900, lr = 0.001
I0629 11:21:38.477717  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:21:38.619822  2332 solver.cpp:330] Iteration 44000, Testing net (#0)
I0629 11:21:38.619822  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:21:39.438442  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:21:39.468477  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8927
I0629 11:21:39.468477  2332 solver.cpp:397]     Test net output #1: loss = 0.360011 (* 1 = 0.360011 loss)
I0629 11:21:39.503502  2332 solver.cpp:218] Iteration 44000 (22.3479 iter/s, 4.47469s/100 iters), loss = 0.124762
I0629 11:21:39.503502  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:21:39.503502  2332 solver.cpp:237]     Train net output #1: loss = 0.124762 (* 1 = 0.124762 loss)
I0629 11:21:39.503502  2332 sgd_solver.cpp:105] Iteration 44000, lr = 0.001
I0629 11:21:43.130275  2332 solver.cpp:218] Iteration 44100 (27.5767 iter/s, 3.62625s/100 iters), loss = 0.202046
I0629 11:21:43.130275  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:21:43.130275  2332 solver.cpp:237]     Train net output #1: loss = 0.202045 (* 1 = 0.202045 loss)
I0629 11:21:43.130275  2332 sgd_solver.cpp:105] Iteration 44100, lr = 0.001
I0629 11:21:46.759958  2332 solver.cpp:218] Iteration 44200 (27.5544 iter/s, 3.62918s/100 iters), loss = 0.100108
I0629 11:21:46.759958  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:21:46.759958  2332 solver.cpp:237]     Train net output #1: loss = 0.100108 (* 1 = 0.100108 loss)
I0629 11:21:46.759958  2332 sgd_solver.cpp:105] Iteration 44200, lr = 0.001
I0629 11:21:50.390657  2332 solver.cpp:218] Iteration 44300 (27.5442 iter/s, 3.63053s/100 iters), loss = 0.106501
I0629 11:21:50.390657  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:21:50.390657  2332 solver.cpp:237]     Train net output #1: loss = 0.1065 (* 1 = 0.1065 loss)
I0629 11:21:50.390657  2332 sgd_solver.cpp:105] Iteration 44300, lr = 0.001
I0629 11:21:54.013440  2332 solver.cpp:218] Iteration 44400 (27.6052 iter/s, 3.62251s/100 iters), loss = 0.0929988
I0629 11:21:54.013440  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:21:54.013440  2332 solver.cpp:237]     Train net output #1: loss = 0.0929986 (* 1 = 0.0929986 loss)
I0629 11:21:54.013440  2332 sgd_solver.cpp:105] Iteration 44400, lr = 0.001
I0629 11:21:57.462262  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:21:57.603368  2332 solver.cpp:330] Iteration 44500, Testing net (#0)
I0629 11:21:57.603368  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:21:58.420979  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:21:58.452000  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8901
I0629 11:21:58.452000  2332 solver.cpp:397]     Test net output #1: loss = 0.361842 (* 1 = 0.361842 loss)
I0629 11:21:58.486028  2332 solver.cpp:218] Iteration 44500 (22.3579 iter/s, 4.4727s/100 iters), loss = 0.0728747
I0629 11:21:58.487028  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:21:58.487028  2332 solver.cpp:237]     Train net output #1: loss = 0.0728744 (* 1 = 0.0728744 loss)
I0629 11:21:58.487028  2332 sgd_solver.cpp:105] Iteration 44500, lr = 0.001
I0629 11:22:02.106730  2332 solver.cpp:218] Iteration 44600 (27.6282 iter/s, 3.61949s/100 iters), loss = 0.159351
I0629 11:22:02.106730  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:22:02.106730  2332 solver.cpp:237]     Train net output #1: loss = 0.159351 (* 1 = 0.159351 loss)
I0629 11:22:02.106730  2332 sgd_solver.cpp:105] Iteration 44600, lr = 0.001
I0629 11:22:05.723691  2332 solver.cpp:218] Iteration 44700 (27.644 iter/s, 3.61742s/100 iters), loss = 0.104799
I0629 11:22:05.723691  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:22:05.723691  2332 solver.cpp:237]     Train net output #1: loss = 0.104799 (* 1 = 0.104799 loss)
I0629 11:22:05.723691  2332 sgd_solver.cpp:105] Iteration 44700, lr = 0.001
I0629 11:22:09.348629  2332 solver.cpp:218] Iteration 44800 (27.5924 iter/s, 3.62419s/100 iters), loss = 0.127122
I0629 11:22:09.348629  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:22:09.348629  2332 solver.cpp:237]     Train net output #1: loss = 0.127122 (* 1 = 0.127122 loss)
I0629 11:22:09.348629  2332 sgd_solver.cpp:105] Iteration 44800, lr = 0.001
I0629 11:22:12.977349  2332 solver.cpp:218] Iteration 44900 (27.558 iter/s, 3.62871s/100 iters), loss = 0.103155
I0629 11:22:12.977349  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:22:12.977349  2332 solver.cpp:237]     Train net output #1: loss = 0.103155 (* 1 = 0.103155 loss)
I0629 11:22:12.977349  2332 sgd_solver.cpp:105] Iteration 44900, lr = 0.001
I0629 11:22:16.441838  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:22:16.583943  2332 solver.cpp:330] Iteration 45000, Testing net (#0)
I0629 11:22:16.583943  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:22:17.404563  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:22:17.435587  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0629 11:22:17.435587  2332 solver.cpp:397]     Test net output #1: loss = 0.361129 (* 1 = 0.361129 loss)
I0629 11:22:17.469612  2332 solver.cpp:218] Iteration 45000 (22.2631 iter/s, 4.49174s/100 iters), loss = 0.0611582
I0629 11:22:17.469612  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:22:17.469612  2332 solver.cpp:237]     Train net output #1: loss = 0.0611581 (* 1 = 0.0611581 loss)
I0629 11:22:17.469612  2332 sgd_solver.cpp:105] Iteration 45000, lr = 0.001
I0629 11:22:21.091203  2332 solver.cpp:218] Iteration 45100 (27.6179 iter/s, 3.62084s/100 iters), loss = 0.112834
I0629 11:22:21.091203  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:22:21.091203  2332 solver.cpp:237]     Train net output #1: loss = 0.112834 (* 1 = 0.112834 loss)
I0629 11:22:21.091203  2332 sgd_solver.cpp:105] Iteration 45100, lr = 0.001
I0629 11:22:24.721094  2332 solver.cpp:218] Iteration 45200 (27.552 iter/s, 3.6295s/100 iters), loss = 0.104754
I0629 11:22:24.721094  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:22:24.721094  2332 solver.cpp:237]     Train net output #1: loss = 0.104754 (* 1 = 0.104754 loss)
I0629 11:22:24.721094  2332 sgd_solver.cpp:105] Iteration 45200, lr = 0.001
I0629 11:22:28.346529  2332 solver.cpp:218] Iteration 45300 (27.5869 iter/s, 3.62492s/100 iters), loss = 0.106729
I0629 11:22:28.346529  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:22:28.346529  2332 solver.cpp:237]     Train net output #1: loss = 0.106729 (* 1 = 0.106729 loss)
I0629 11:22:28.346529  2332 sgd_solver.cpp:105] Iteration 45300, lr = 0.001
I0629 11:22:31.972836  2332 solver.cpp:218] Iteration 45400 (27.5762 iter/s, 3.62631s/100 iters), loss = 0.135463
I0629 11:22:31.972836  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:22:31.972836  2332 solver.cpp:237]     Train net output #1: loss = 0.135463 (* 1 = 0.135463 loss)
I0629 11:22:31.972836  2332 sgd_solver.cpp:105] Iteration 45400, lr = 0.001
I0629 11:22:35.419612  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:22:35.560219  2332 solver.cpp:330] Iteration 45500, Testing net (#0)
I0629 11:22:35.560219  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:22:36.380496  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:22:36.411519  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8904
I0629 11:22:36.411519  2332 solver.cpp:397]     Test net output #1: loss = 0.365505 (* 1 = 0.365505 loss)
I0629 11:22:36.446044  2332 solver.cpp:218] Iteration 45500 (22.3569 iter/s, 4.47289s/100 iters), loss = 0.0872827
I0629 11:22:36.446044  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:22:36.446044  2332 solver.cpp:237]     Train net output #1: loss = 0.0872824 (* 1 = 0.0872824 loss)
I0629 11:22:36.446044  2332 sgd_solver.cpp:105] Iteration 45500, lr = 0.001
I0629 11:22:40.078512  2332 solver.cpp:218] Iteration 45600 (27.5297 iter/s, 3.63244s/100 iters), loss = 0.133217
I0629 11:22:40.078512  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:22:40.078512  2332 solver.cpp:237]     Train net output #1: loss = 0.133216 (* 1 = 0.133216 loss)
I0629 11:22:40.078512  2332 sgd_solver.cpp:105] Iteration 45600, lr = 0.001
I0629 11:22:43.704427  2332 solver.cpp:218] Iteration 45700 (27.5832 iter/s, 3.6254s/100 iters), loss = 0.0984761
I0629 11:22:43.704427  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:22:43.704427  2332 solver.cpp:237]     Train net output #1: loss = 0.0984759 (* 1 = 0.0984759 loss)
I0629 11:22:43.704427  2332 sgd_solver.cpp:105] Iteration 45700, lr = 0.001
I0629 11:22:47.339134  2332 solver.cpp:218] Iteration 45800 (27.5175 iter/s, 3.63405s/100 iters), loss = 0.101632
I0629 11:22:47.339134  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:22:47.339134  2332 solver.cpp:237]     Train net output #1: loss = 0.101632 (* 1 = 0.101632 loss)
I0629 11:22:47.339134  2332 sgd_solver.cpp:105] Iteration 45800, lr = 0.001
I0629 11:22:50.956094  2332 solver.cpp:218] Iteration 45900 (27.6449 iter/s, 3.6173s/100 iters), loss = 0.134779
I0629 11:22:50.957095  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:22:50.957095  2332 solver.cpp:237]     Train net output #1: loss = 0.134779 (* 1 = 0.134779 loss)
I0629 11:22:50.957095  2332 sgd_solver.cpp:105] Iteration 45900, lr = 0.001
I0629 11:22:54.405354  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:22:54.547457  2332 solver.cpp:330] Iteration 46000, Testing net (#0)
I0629 11:22:54.547457  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:22:55.366574  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:22:55.397096  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8919
I0629 11:22:55.397096  2332 solver.cpp:397]     Test net output #1: loss = 0.367455 (* 1 = 0.367455 loss)
I0629 11:22:55.431120  2332 solver.cpp:218] Iteration 46000 (22.3481 iter/s, 4.47466s/100 iters), loss = 0.117652
I0629 11:22:55.431120  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:22:55.432121  2332 solver.cpp:237]     Train net output #1: loss = 0.117652 (* 1 = 0.117652 loss)
I0629 11:22:55.432121  2332 sgd_solver.cpp:105] Iteration 46000, lr = 0.001
I0629 11:22:59.058810  2332 solver.cpp:218] Iteration 46100 (27.5725 iter/s, 3.6268s/100 iters), loss = 0.181197
I0629 11:22:59.058810  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:22:59.058810  2332 solver.cpp:237]     Train net output #1: loss = 0.181197 (* 1 = 0.181197 loss)
I0629 11:22:59.058810  2332 sgd_solver.cpp:105] Iteration 46100, lr = 0.001
I0629 11:23:02.688014  2332 solver.cpp:218] Iteration 46200 (27.5573 iter/s, 3.6288s/100 iters), loss = 0.0810359
I0629 11:23:02.688014  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:23:02.688014  2332 solver.cpp:237]     Train net output #1: loss = 0.0810356 (* 1 = 0.0810356 loss)
I0629 11:23:02.688014  2332 sgd_solver.cpp:105] Iteration 46200, lr = 0.001
I0629 11:23:06.310703  2332 solver.cpp:218] Iteration 46300 (27.6046 iter/s, 3.62259s/100 iters), loss = 0.0937369
I0629 11:23:06.310703  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:23:06.310703  2332 solver.cpp:237]     Train net output #1: loss = 0.0937366 (* 1 = 0.0937366 loss)
I0629 11:23:06.310703  2332 sgd_solver.cpp:105] Iteration 46300, lr = 0.001
I0629 11:23:09.938433  2332 solver.cpp:218] Iteration 46400 (27.5686 iter/s, 3.62732s/100 iters), loss = 0.148112
I0629 11:23:09.938433  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:23:09.938433  2332 solver.cpp:237]     Train net output #1: loss = 0.148111 (* 1 = 0.148111 loss)
I0629 11:23:09.938433  2332 sgd_solver.cpp:105] Iteration 46400, lr = 0.001
I0629 11:23:13.393024  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:23:13.534128  2332 solver.cpp:330] Iteration 46500, Testing net (#0)
I0629 11:23:13.534128  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:23:14.352803  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:23:14.384328  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0629 11:23:14.384328  2332 solver.cpp:397]     Test net output #1: loss = 0.364626 (* 1 = 0.364626 loss)
I0629 11:23:14.418853  2332 solver.cpp:218] Iteration 46500 (22.3233 iter/s, 4.47962s/100 iters), loss = 0.0767676
I0629 11:23:14.418853  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:23:14.418853  2332 solver.cpp:237]     Train net output #1: loss = 0.0767673 (* 1 = 0.0767673 loss)
I0629 11:23:14.418853  2332 sgd_solver.cpp:105] Iteration 46500, lr = 0.001
I0629 11:23:18.053831  2332 solver.cpp:218] Iteration 46600 (27.509 iter/s, 3.63518s/100 iters), loss = 0.138493
I0629 11:23:18.053831  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:23:18.053831  2332 solver.cpp:237]     Train net output #1: loss = 0.138493 (* 1 = 0.138493 loss)
I0629 11:23:18.053831  2332 sgd_solver.cpp:105] Iteration 46600, lr = 0.001
I0629 11:23:21.680460  2332 solver.cpp:218] Iteration 46700 (27.5802 iter/s, 3.62579s/100 iters), loss = 0.123159
I0629 11:23:21.680460  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:23:21.680460  2332 solver.cpp:237]     Train net output #1: loss = 0.123158 (* 1 = 0.123158 loss)
I0629 11:23:21.680460  2332 sgd_solver.cpp:105] Iteration 46700, lr = 0.001
I0629 11:23:25.315935  2332 solver.cpp:218] Iteration 46800 (27.5028 iter/s, 3.63599s/100 iters), loss = 0.183559
I0629 11:23:25.315935  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:23:25.315935  2332 solver.cpp:237]     Train net output #1: loss = 0.183559 (* 1 = 0.183559 loss)
I0629 11:23:25.315935  2332 sgd_solver.cpp:105] Iteration 46800, lr = 0.001
I0629 11:23:28.951654  2332 solver.cpp:218] Iteration 46900 (27.5135 iter/s, 3.63458s/100 iters), loss = 0.133051
I0629 11:23:28.951654  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:23:28.951654  2332 solver.cpp:237]     Train net output #1: loss = 0.133051 (* 1 = 0.133051 loss)
I0629 11:23:28.951654  2332 sgd_solver.cpp:105] Iteration 46900, lr = 0.001
I0629 11:23:32.409380  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:23:32.551484  2332 solver.cpp:330] Iteration 47000, Testing net (#0)
I0629 11:23:32.551484  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:23:33.369117  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:23:33.400146  2332 solver.cpp:397]     Test net output #0: accuracy = 0.893
I0629 11:23:33.400146  2332 solver.cpp:397]     Test net output #1: loss = 0.362556 (* 1 = 0.362556 loss)
I0629 11:23:33.435166  2332 solver.cpp:218] Iteration 47000 (22.3056 iter/s, 4.48317s/100 iters), loss = 0.096611
I0629 11:23:33.435166  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:23:33.435166  2332 solver.cpp:237]     Train net output #1: loss = 0.0966107 (* 1 = 0.0966107 loss)
I0629 11:23:33.435166  2332 sgd_solver.cpp:105] Iteration 47000, lr = 0.001
I0629 11:23:37.067092  2332 solver.cpp:218] Iteration 47100 (27.5338 iter/s, 3.6319s/100 iters), loss = 0.120694
I0629 11:23:37.067092  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:23:37.067092  2332 solver.cpp:237]     Train net output #1: loss = 0.120694 (* 1 = 0.120694 loss)
I0629 11:23:37.067092  2332 sgd_solver.cpp:105] Iteration 47100, lr = 0.001
I0629 11:23:40.707322  2332 solver.cpp:218] Iteration 47200 (27.4731 iter/s, 3.63992s/100 iters), loss = 0.0810167
I0629 11:23:40.707322  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:23:40.707322  2332 solver.cpp:237]     Train net output #1: loss = 0.0810165 (* 1 = 0.0810165 loss)
I0629 11:23:40.707322  2332 sgd_solver.cpp:105] Iteration 47200, lr = 0.001
I0629 11:23:44.329110  2332 solver.cpp:218] Iteration 47300 (27.6131 iter/s, 3.62146s/100 iters), loss = 0.137729
I0629 11:23:44.329610  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:23:44.329610  2332 solver.cpp:237]     Train net output #1: loss = 0.137729 (* 1 = 0.137729 loss)
I0629 11:23:44.329610  2332 sgd_solver.cpp:105] Iteration 47300, lr = 0.001
I0629 11:23:47.953810  2332 solver.cpp:218] Iteration 47400 (27.5901 iter/s, 3.62449s/100 iters), loss = 0.127145
I0629 11:23:47.953810  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:23:47.953810  2332 solver.cpp:237]     Train net output #1: loss = 0.127145 (* 1 = 0.127145 loss)
I0629 11:23:47.953810  2332 sgd_solver.cpp:105] Iteration 47400, lr = 0.001
I0629 11:23:51.402631  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:23:51.549094  2332 solver.cpp:330] Iteration 47500, Testing net (#0)
I0629 11:23:51.549094  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:23:52.371067  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:23:52.402088  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8915
I0629 11:23:52.402088  2332 solver.cpp:397]     Test net output #1: loss = 0.370676 (* 1 = 0.370676 loss)
I0629 11:23:52.436110  2332 solver.cpp:218] Iteration 47500 (22.3128 iter/s, 4.48173s/100 iters), loss = 0.0854362
I0629 11:23:52.436625  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:23:52.436625  2332 solver.cpp:237]     Train net output #1: loss = 0.085436 (* 1 = 0.085436 loss)
I0629 11:23:52.436625  2332 sgd_solver.cpp:105] Iteration 47500, lr = 0.001
I0629 11:23:56.053408  2332 solver.cpp:218] Iteration 47600 (27.6447 iter/s, 3.61734s/100 iters), loss = 0.169027
I0629 11:23:56.053408  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:23:56.053408  2332 solver.cpp:237]     Train net output #1: loss = 0.169027 (* 1 = 0.169027 loss)
I0629 11:23:56.053408  2332 sgd_solver.cpp:105] Iteration 47600, lr = 0.001
I0629 11:23:59.678709  2332 solver.cpp:218] Iteration 47700 (27.5909 iter/s, 3.62438s/100 iters), loss = 0.0840581
I0629 11:23:59.678709  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:23:59.678709  2332 solver.cpp:237]     Train net output #1: loss = 0.0840578 (* 1 = 0.0840578 loss)
I0629 11:23:59.678709  2332 sgd_solver.cpp:105] Iteration 47700, lr = 0.001
I0629 11:24:03.309154  2332 solver.cpp:218] Iteration 47800 (27.547 iter/s, 3.63016s/100 iters), loss = 0.100354
I0629 11:24:03.309154  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:24:03.309154  2332 solver.cpp:237]     Train net output #1: loss = 0.100353 (* 1 = 0.100353 loss)
I0629 11:24:03.309154  2332 sgd_solver.cpp:105] Iteration 47800, lr = 0.001
I0629 11:24:06.929245  2332 solver.cpp:218] Iteration 47900 (27.6289 iter/s, 3.61939s/100 iters), loss = 0.0790725
I0629 11:24:06.929245  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:24:06.929245  2332 solver.cpp:237]     Train net output #1: loss = 0.0790723 (* 1 = 0.0790723 loss)
I0629 11:24:06.929245  2332 sgd_solver.cpp:105] Iteration 47900, lr = 0.001
I0629 11:24:10.381836  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:24:10.523939  2332 solver.cpp:330] Iteration 48000, Testing net (#0)
I0629 11:24:10.523939  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:24:11.340566  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:24:11.371603  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8931
I0629 11:24:11.371603  2332 solver.cpp:397]     Test net output #1: loss = 0.367284 (* 1 = 0.367284 loss)
I0629 11:24:11.405628  2332 solver.cpp:218] Iteration 48000 (22.338 iter/s, 4.47667s/100 iters), loss = 0.117376
I0629 11:24:11.405628  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:24:11.405628  2332 solver.cpp:237]     Train net output #1: loss = 0.117375 (* 1 = 0.117375 loss)
I0629 11:24:11.405628  2332 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0629 11:24:11.405628  2332 sgd_solver.cpp:105] Iteration 48000, lr = 0.0001
I0629 11:24:15.039358  2332 solver.cpp:218] Iteration 48100 (27.5206 iter/s, 3.63365s/100 iters), loss = 0.127081
I0629 11:24:15.039358  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:24:15.040359  2332 solver.cpp:237]     Train net output #1: loss = 0.127081 (* 1 = 0.127081 loss)
I0629 11:24:15.040359  2332 sgd_solver.cpp:105] Iteration 48100, lr = 0.0001
I0629 11:24:18.667961  2332 solver.cpp:218] Iteration 48200 (27.5683 iter/s, 3.62735s/100 iters), loss = 0.0994225
I0629 11:24:18.667961  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:24:18.667961  2332 solver.cpp:237]     Train net output #1: loss = 0.0994223 (* 1 = 0.0994223 loss)
I0629 11:24:18.667961  2332 sgd_solver.cpp:105] Iteration 48200, lr = 0.0001
I0629 11:24:22.304705  2332 solver.cpp:218] Iteration 48300 (27.4938 iter/s, 3.63718s/100 iters), loss = 0.104726
I0629 11:24:22.304705  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:24:22.304705  2332 solver.cpp:237]     Train net output #1: loss = 0.104725 (* 1 = 0.104725 loss)
I0629 11:24:22.304705  2332 sgd_solver.cpp:105] Iteration 48300, lr = 0.0001
I0629 11:24:25.941114  2332 solver.cpp:218] Iteration 48400 (27.5066 iter/s, 3.63549s/100 iters), loss = 0.116077
I0629 11:24:25.941114  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:24:25.941114  2332 solver.cpp:237]     Train net output #1: loss = 0.116077 (* 1 = 0.116077 loss)
I0629 11:24:25.941114  2332 sgd_solver.cpp:105] Iteration 48400, lr = 0.0001
I0629 11:24:29.389513  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:24:29.531615  2332 solver.cpp:330] Iteration 48500, Testing net (#0)
I0629 11:24:29.531615  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:24:30.353688  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:24:30.384712  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8956
I0629 11:24:30.384712  2332 solver.cpp:397]     Test net output #1: loss = 0.35816 (* 1 = 0.35816 loss)
I0629 11:24:30.419737  2332 solver.cpp:218] Iteration 48500 (22.3301 iter/s, 4.47826s/100 iters), loss = 0.0732282
I0629 11:24:30.419737  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:24:30.419737  2332 solver.cpp:237]     Train net output #1: loss = 0.0732279 (* 1 = 0.0732279 loss)
I0629 11:24:30.419737  2332 sgd_solver.cpp:105] Iteration 48500, lr = 0.0001
I0629 11:24:34.040086  2332 solver.cpp:218] Iteration 48600 (27.623 iter/s, 3.62017s/100 iters), loss = 0.130736
I0629 11:24:34.040086  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:24:34.040086  2332 solver.cpp:237]     Train net output #1: loss = 0.130735 (* 1 = 0.130735 loss)
I0629 11:24:34.040086  2332 sgd_solver.cpp:105] Iteration 48600, lr = 0.0001
I0629 11:24:37.667399  2332 solver.cpp:218] Iteration 48700 (27.57 iter/s, 3.62713s/100 iters), loss = 0.0646736
I0629 11:24:37.667399  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:24:37.667399  2332 solver.cpp:237]     Train net output #1: loss = 0.0646733 (* 1 = 0.0646733 loss)
I0629 11:24:37.667399  2332 sgd_solver.cpp:105] Iteration 48700, lr = 0.0001
I0629 11:24:41.296108  2332 solver.cpp:218] Iteration 48800 (27.5595 iter/s, 3.62852s/100 iters), loss = 0.0966481
I0629 11:24:41.296108  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:24:41.296108  2332 solver.cpp:237]     Train net output #1: loss = 0.0966478 (* 1 = 0.0966478 loss)
I0629 11:24:41.296108  2332 sgd_solver.cpp:105] Iteration 48800, lr = 0.0001
I0629 11:24:44.922984  2332 solver.cpp:218] Iteration 48900 (27.5768 iter/s, 3.62623s/100 iters), loss = 0.068228
I0629 11:24:44.922984  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:24:44.922984  2332 solver.cpp:237]     Train net output #1: loss = 0.0682277 (* 1 = 0.0682277 loss)
I0629 11:24:44.922984  2332 sgd_solver.cpp:105] Iteration 48900, lr = 0.0001
I0629 11:24:48.375622  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:24:48.517726  2332 solver.cpp:330] Iteration 49000, Testing net (#0)
I0629 11:24:48.517726  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:24:49.339503  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:24:49.370524  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I0629 11:24:49.370524  2332 solver.cpp:397]     Test net output #1: loss = 0.356867 (* 1 = 0.356867 loss)
I0629 11:24:49.404548  2332 solver.cpp:218] Iteration 49000 (22.3148 iter/s, 4.48134s/100 iters), loss = 0.0971044
I0629 11:24:49.404548  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:24:49.404548  2332 solver.cpp:237]     Train net output #1: loss = 0.0971041 (* 1 = 0.0971041 loss)
I0629 11:24:49.404548  2332 sgd_solver.cpp:105] Iteration 49000, lr = 0.0001
I0629 11:24:53.032903  2332 solver.cpp:218] Iteration 49100 (27.5643 iter/s, 3.62788s/100 iters), loss = 0.152582
I0629 11:24:53.032903  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:24:53.032903  2332 solver.cpp:237]     Train net output #1: loss = 0.152582 (* 1 = 0.152582 loss)
I0629 11:24:53.032903  2332 sgd_solver.cpp:105] Iteration 49100, lr = 0.0001
I0629 11:24:56.657275  2332 solver.cpp:218] Iteration 49200 (27.5907 iter/s, 3.62441s/100 iters), loss = 0.182383
I0629 11:24:56.657275  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:24:56.657275  2332 solver.cpp:237]     Train net output #1: loss = 0.182382 (* 1 = 0.182382 loss)
I0629 11:24:56.657275  2332 sgd_solver.cpp:105] Iteration 49200, lr = 0.0001
I0629 11:25:00.296130  2332 solver.cpp:218] Iteration 49300 (27.4834 iter/s, 3.63856s/100 iters), loss = 0.0732961
I0629 11:25:00.296130  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:25:00.296130  2332 solver.cpp:237]     Train net output #1: loss = 0.0732958 (* 1 = 0.0732958 loss)
I0629 11:25:00.296130  2332 sgd_solver.cpp:105] Iteration 49300, lr = 0.0001
I0629 11:25:03.921831  2332 solver.cpp:218] Iteration 49400 (27.5891 iter/s, 3.62462s/100 iters), loss = 0.0616558
I0629 11:25:03.921831  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:25:03.921831  2332 solver.cpp:237]     Train net output #1: loss = 0.0616555 (* 1 = 0.0616555 loss)
I0629 11:25:03.921831  2332 sgd_solver.cpp:105] Iteration 49400, lr = 0.0001
I0629 11:25:07.370573  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:25:07.512678  2332 solver.cpp:330] Iteration 49500, Testing net (#0)
I0629 11:25:07.512678  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:25:08.331017  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:25:08.362542  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8944
I0629 11:25:08.362542  2332 solver.cpp:397]     Test net output #1: loss = 0.356048 (* 1 = 0.356048 loss)
I0629 11:25:08.396566  2332 solver.cpp:218] Iteration 49500 (22.3452 iter/s, 4.47524s/100 iters), loss = 0.112542
I0629 11:25:08.396566  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:25:08.396566  2332 solver.cpp:237]     Train net output #1: loss = 0.112541 (* 1 = 0.112541 loss)
I0629 11:25:08.396566  2332 sgd_solver.cpp:105] Iteration 49500, lr = 0.0001
I0629 11:25:12.011679  2332 solver.cpp:218] Iteration 49600 (27.6643 iter/s, 3.61477s/100 iters), loss = 0.128161
I0629 11:25:12.011679  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:25:12.011679  2332 solver.cpp:237]     Train net output #1: loss = 0.128161 (* 1 = 0.128161 loss)
I0629 11:25:12.011679  2332 sgd_solver.cpp:105] Iteration 49600, lr = 0.0001
I0629 11:25:15.629170  2332 solver.cpp:218] Iteration 49700 (27.6472 iter/s, 3.617s/100 iters), loss = 0.137723
I0629 11:25:15.629170  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:25:15.629170  2332 solver.cpp:237]     Train net output #1: loss = 0.137723 (* 1 = 0.137723 loss)
I0629 11:25:15.629170  2332 sgd_solver.cpp:105] Iteration 49700, lr = 0.0001
I0629 11:25:19.244942  2332 solver.cpp:218] Iteration 49800 (27.6643 iter/s, 3.61476s/100 iters), loss = 0.0834548
I0629 11:25:19.244942  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:25:19.244942  2332 solver.cpp:237]     Train net output #1: loss = 0.0834545 (* 1 = 0.0834545 loss)
I0629 11:25:19.244942  2332 sgd_solver.cpp:105] Iteration 49800, lr = 0.0001
I0629 11:25:22.862077  2332 solver.cpp:218] Iteration 49900 (27.6467 iter/s, 3.61707s/100 iters), loss = 0.131556
I0629 11:25:22.862077  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:25:22.862077  2332 solver.cpp:237]     Train net output #1: loss = 0.131556 (* 1 = 0.131556 loss)
I0629 11:25:22.862077  2332 sgd_solver.cpp:105] Iteration 49900, lr = 0.0001
I0629 11:25:26.296847  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:25:26.437988  2332 solver.cpp:330] Iteration 50000, Testing net (#0)
I0629 11:25:26.438989  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:25:27.258148  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:25:27.289191  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8947
I0629 11:25:27.289191  2332 solver.cpp:397]     Test net output #1: loss = 0.355587 (* 1 = 0.355587 loss)
I0629 11:25:27.323225  2332 solver.cpp:218] Iteration 50000 (22.4175 iter/s, 4.4608s/100 iters), loss = 0.11503
I0629 11:25:27.323225  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:25:27.323225  2332 solver.cpp:237]     Train net output #1: loss = 0.11503 (* 1 = 0.11503 loss)
I0629 11:25:27.323225  2332 sgd_solver.cpp:105] Iteration 50000, lr = 0.0001
I0629 11:25:30.960412  2332 solver.cpp:218] Iteration 50100 (27.4984 iter/s, 3.63658s/100 iters), loss = 0.137441
I0629 11:25:30.960412  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:25:30.960412  2332 solver.cpp:237]     Train net output #1: loss = 0.13744 (* 1 = 0.13744 loss)
I0629 11:25:30.960412  2332 sgd_solver.cpp:105] Iteration 50100, lr = 0.0001
I0629 11:25:34.579715  2332 solver.cpp:218] Iteration 50200 (27.6323 iter/s, 3.61896s/100 iters), loss = 0.105972
I0629 11:25:34.579715  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:25:34.579715  2332 solver.cpp:237]     Train net output #1: loss = 0.105972 (* 1 = 0.105972 loss)
I0629 11:25:34.579715  2332 sgd_solver.cpp:105] Iteration 50200, lr = 0.0001
I0629 11:25:38.207502  2332 solver.cpp:218] Iteration 50300 (27.5628 iter/s, 3.62808s/100 iters), loss = 0.130462
I0629 11:25:38.207502  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:25:38.207502  2332 solver.cpp:237]     Train net output #1: loss = 0.130462 (* 1 = 0.130462 loss)
I0629 11:25:38.207502  2332 sgd_solver.cpp:105] Iteration 50300, lr = 0.0001
I0629 11:25:41.836210  2332 solver.cpp:218] Iteration 50400 (27.5654 iter/s, 3.62773s/100 iters), loss = 0.0973871
I0629 11:25:41.836210  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:25:41.836210  2332 solver.cpp:237]     Train net output #1: loss = 0.0973869 (* 1 = 0.0973869 loss)
I0629 11:25:41.836210  2332 sgd_solver.cpp:105] Iteration 50400, lr = 0.0001
I0629 11:25:45.293910  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:25:45.436014  2332 solver.cpp:330] Iteration 50500, Testing net (#0)
I0629 11:25:45.437016  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:25:46.254637  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:25:46.286151  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8949
I0629 11:25:46.286151  2332 solver.cpp:397]     Test net output #1: loss = 0.355603 (* 1 = 0.355603 loss)
I0629 11:25:46.320677  2332 solver.cpp:218] Iteration 50500 (22.3005 iter/s, 4.48421s/100 iters), loss = 0.0768153
I0629 11:25:46.320677  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:25:46.320677  2332 solver.cpp:237]     Train net output #1: loss = 0.076815 (* 1 = 0.076815 loss)
I0629 11:25:46.320677  2332 sgd_solver.cpp:105] Iteration 50500, lr = 0.0001
I0629 11:25:49.939558  2332 solver.cpp:218] Iteration 50600 (27.6315 iter/s, 3.61905s/100 iters), loss = 0.129633
I0629 11:25:49.939558  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:25:49.939558  2332 solver.cpp:237]     Train net output #1: loss = 0.129633 (* 1 = 0.129633 loss)
I0629 11:25:49.939558  2332 sgd_solver.cpp:105] Iteration 50600, lr = 0.0001
I0629 11:25:53.578464  2332 solver.cpp:218] Iteration 50700 (27.4871 iter/s, 3.63807s/100 iters), loss = 0.097247
I0629 11:25:53.578464  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:25:53.578464  2332 solver.cpp:237]     Train net output #1: loss = 0.0972468 (* 1 = 0.0972468 loss)
I0629 11:25:53.578464  2332 sgd_solver.cpp:105] Iteration 50700, lr = 0.0001
I0629 11:25:57.200703  2332 solver.cpp:218] Iteration 50800 (27.6106 iter/s, 3.6218s/100 iters), loss = 0.0815544
I0629 11:25:57.200703  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:25:57.200703  2332 solver.cpp:237]     Train net output #1: loss = 0.0815541 (* 1 = 0.0815541 loss)
I0629 11:25:57.200703  2332 sgd_solver.cpp:105] Iteration 50800, lr = 0.0001
I0629 11:26:00.812407  2332 solver.cpp:218] Iteration 50900 (27.6901 iter/s, 3.61139s/100 iters), loss = 0.0851449
I0629 11:26:00.812407  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:26:00.812407  2332 solver.cpp:237]     Train net output #1: loss = 0.0851446 (* 1 = 0.0851446 loss)
I0629 11:26:00.812407  2332 sgd_solver.cpp:105] Iteration 50900, lr = 0.0001
I0629 11:26:04.257282  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:26:04.400511  2332 solver.cpp:330] Iteration 51000, Testing net (#0)
I0629 11:26:04.400511  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:26:05.221338  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:26:05.251857  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0629 11:26:05.251857  2332 solver.cpp:397]     Test net output #1: loss = 0.356148 (* 1 = 0.356148 loss)
I0629 11:26:05.285893  2332 solver.cpp:218] Iteration 51000 (22.353 iter/s, 4.47366s/100 iters), loss = 0.0927164
I0629 11:26:05.285893  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:26:05.285893  2332 solver.cpp:237]     Train net output #1: loss = 0.0927162 (* 1 = 0.0927162 loss)
I0629 11:26:05.285893  2332 sgd_solver.cpp:105] Iteration 51000, lr = 0.0001
I0629 11:26:08.903944  2332 solver.cpp:218] Iteration 51100 (27.6406 iter/s, 3.61787s/100 iters), loss = 0.114907
I0629 11:26:08.903944  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:26:08.903944  2332 solver.cpp:237]     Train net output #1: loss = 0.114907 (* 1 = 0.114907 loss)
I0629 11:26:08.903944  2332 sgd_solver.cpp:105] Iteration 51100, lr = 0.0001
I0629 11:26:12.528096  2332 solver.cpp:218] Iteration 51200 (27.5982 iter/s, 3.62343s/100 iters), loss = 0.120446
I0629 11:26:12.528096  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:26:12.528096  2332 solver.cpp:237]     Train net output #1: loss = 0.120446 (* 1 = 0.120446 loss)
I0629 11:26:12.528096  2332 sgd_solver.cpp:105] Iteration 51200, lr = 0.0001
I0629 11:26:16.161382  2332 solver.cpp:218] Iteration 51300 (27.5245 iter/s, 3.63312s/100 iters), loss = 0.0500887
I0629 11:26:16.161382  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:26:16.161382  2332 solver.cpp:237]     Train net output #1: loss = 0.0500885 (* 1 = 0.0500885 loss)
I0629 11:26:16.161382  2332 sgd_solver.cpp:105] Iteration 51300, lr = 0.0001
I0629 11:26:19.778445  2332 solver.cpp:218] Iteration 51400 (27.65 iter/s, 3.61663s/100 iters), loss = 0.073044
I0629 11:26:19.778445  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:26:19.778445  2332 solver.cpp:237]     Train net output #1: loss = 0.0730438 (* 1 = 0.0730438 loss)
I0629 11:26:19.778445  2332 sgd_solver.cpp:105] Iteration 51400, lr = 0.0001
I0629 11:26:23.227515  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:26:23.368891  2332 solver.cpp:330] Iteration 51500, Testing net (#0)
I0629 11:26:23.368891  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:26:24.191663  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:26:24.222672  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8944
I0629 11:26:24.222672  2332 solver.cpp:397]     Test net output #1: loss = 0.355917 (* 1 = 0.355917 loss)
I0629 11:26:24.261234  2332 solver.cpp:218] Iteration 51500 (22.3113 iter/s, 4.48204s/100 iters), loss = 0.0585459
I0629 11:26:24.261234  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:26:24.261234  2332 solver.cpp:237]     Train net output #1: loss = 0.0585457 (* 1 = 0.0585457 loss)
I0629 11:26:24.261234  2332 sgd_solver.cpp:105] Iteration 51500, lr = 0.0001
I0629 11:26:27.881548  2332 solver.cpp:218] Iteration 51600 (27.6215 iter/s, 3.62037s/100 iters), loss = 0.121827
I0629 11:26:27.881548  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:26:27.881548  2332 solver.cpp:237]     Train net output #1: loss = 0.121827 (* 1 = 0.121827 loss)
I0629 11:26:27.881548  2332 sgd_solver.cpp:105] Iteration 51600, lr = 0.0001
I0629 11:26:31.500349  2332 solver.cpp:218] Iteration 51700 (27.6333 iter/s, 3.61882s/100 iters), loss = 0.0954158
I0629 11:26:31.501333  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:26:31.501333  2332 solver.cpp:237]     Train net output #1: loss = 0.0954157 (* 1 = 0.0954157 loss)
I0629 11:26:31.501333  2332 sgd_solver.cpp:105] Iteration 51700, lr = 0.0001
I0629 11:26:35.118285  2332 solver.cpp:218] Iteration 51800 (27.6476 iter/s, 3.61695s/100 iters), loss = 0.0729589
I0629 11:26:35.118285  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:26:35.118285  2332 solver.cpp:237]     Train net output #1: loss = 0.0729587 (* 1 = 0.0729587 loss)
I0629 11:26:35.118285  2332 sgd_solver.cpp:105] Iteration 51800, lr = 0.0001
I0629 11:26:38.753896  2332 solver.cpp:218] Iteration 51900 (27.5113 iter/s, 3.63488s/100 iters), loss = 0.0868127
I0629 11:26:38.753896  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:26:38.753896  2332 solver.cpp:237]     Train net output #1: loss = 0.0868126 (* 1 = 0.0868126 loss)
I0629 11:26:38.753896  2332 sgd_solver.cpp:105] Iteration 51900, lr = 0.0001
I0629 11:26:42.205636  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:26:42.347743  2332 solver.cpp:330] Iteration 52000, Testing net (#0)
I0629 11:26:42.347743  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:26:43.168356  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:26:43.199378  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8945
I0629 11:26:43.199378  2332 solver.cpp:397]     Test net output #1: loss = 0.356039 (* 1 = 0.356039 loss)
I0629 11:26:43.233904  2332 solver.cpp:218] Iteration 52000 (22.3219 iter/s, 4.4799s/100 iters), loss = 0.0930833
I0629 11:26:43.233904  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:26:43.233904  2332 solver.cpp:237]     Train net output #1: loss = 0.0930832 (* 1 = 0.0930832 loss)
I0629 11:26:43.233904  2332 sgd_solver.cpp:105] Iteration 52000, lr = 0.0001
I0629 11:26:46.865387  2332 solver.cpp:218] Iteration 52100 (27.5347 iter/s, 3.63178s/100 iters), loss = 0.137553
I0629 11:26:46.865387  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:26:46.865387  2332 solver.cpp:237]     Train net output #1: loss = 0.137553 (* 1 = 0.137553 loss)
I0629 11:26:46.865387  2332 sgd_solver.cpp:105] Iteration 52100, lr = 0.0001
I0629 11:26:50.485069  2332 solver.cpp:218] Iteration 52200 (27.6358 iter/s, 3.6185s/100 iters), loss = 0.0845398
I0629 11:26:50.485069  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:26:50.485069  2332 solver.cpp:237]     Train net output #1: loss = 0.0845397 (* 1 = 0.0845397 loss)
I0629 11:26:50.485069  2332 sgd_solver.cpp:105] Iteration 52200, lr = 0.0001
I0629 11:26:54.102761  2332 solver.cpp:218] Iteration 52300 (27.6409 iter/s, 3.61782s/100 iters), loss = 0.0552851
I0629 11:26:54.102761  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:26:54.102761  2332 solver.cpp:237]     Train net output #1: loss = 0.055285 (* 1 = 0.055285 loss)
I0629 11:26:54.102761  2332 sgd_solver.cpp:105] Iteration 52300, lr = 0.0001
I0629 11:26:57.727381  2332 solver.cpp:218] Iteration 52400 (27.5935 iter/s, 3.62404s/100 iters), loss = 0.0686727
I0629 11:26:57.727381  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:26:57.727381  2332 solver.cpp:237]     Train net output #1: loss = 0.0686726 (* 1 = 0.0686726 loss)
I0629 11:26:57.727381  2332 sgd_solver.cpp:105] Iteration 52400, lr = 0.0001
I0629 11:27:01.179708  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:27:01.321813  2332 solver.cpp:330] Iteration 52500, Testing net (#0)
I0629 11:27:01.321813  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:27:02.141432  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:27:02.173454  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8945
I0629 11:27:02.173454  2332 solver.cpp:397]     Test net output #1: loss = 0.35516 (* 1 = 0.35516 loss)
I0629 11:27:02.207481  2332 solver.cpp:218] Iteration 52500 (22.3229 iter/s, 4.47971s/100 iters), loss = 0.0859438
I0629 11:27:02.207481  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:27:02.207481  2332 solver.cpp:237]     Train net output #1: loss = 0.0859437 (* 1 = 0.0859437 loss)
I0629 11:27:02.207481  2332 sgd_solver.cpp:105] Iteration 52500, lr = 0.0001
I0629 11:27:05.829255  2332 solver.cpp:218] Iteration 52600 (27.6093 iter/s, 3.62197s/100 iters), loss = 0.15793
I0629 11:27:05.829255  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:27:05.829255  2332 solver.cpp:237]     Train net output #1: loss = 0.157929 (* 1 = 0.157929 loss)
I0629 11:27:05.829255  2332 sgd_solver.cpp:105] Iteration 52600, lr = 0.0001
I0629 11:27:09.455023  2332 solver.cpp:218] Iteration 52700 (27.588 iter/s, 3.62476s/100 iters), loss = 0.137266
I0629 11:27:09.455023  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:27:09.455023  2332 solver.cpp:237]     Train net output #1: loss = 0.137266 (* 1 = 0.137266 loss)
I0629 11:27:09.455023  2332 sgd_solver.cpp:105] Iteration 52700, lr = 0.0001
I0629 11:27:13.081748  2332 solver.cpp:218] Iteration 52800 (27.574 iter/s, 3.62661s/100 iters), loss = 0.0959674
I0629 11:27:13.081748  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:27:13.081748  2332 solver.cpp:237]     Train net output #1: loss = 0.0959673 (* 1 = 0.0959673 loss)
I0629 11:27:13.081748  2332 sgd_solver.cpp:105] Iteration 52800, lr = 0.0001
I0629 11:27:16.705549  2332 solver.cpp:218] Iteration 52900 (27.5979 iter/s, 3.62347s/100 iters), loss = 0.131827
I0629 11:27:16.705549  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:27:16.705549  2332 solver.cpp:237]     Train net output #1: loss = 0.131827 (* 1 = 0.131827 loss)
I0629 11:27:16.705549  2332 sgd_solver.cpp:105] Iteration 52900, lr = 0.0001
I0629 11:27:20.161289  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:27:20.303400  2332 solver.cpp:330] Iteration 53000, Testing net (#0)
I0629 11:27:20.303400  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:27:21.122867  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:27:21.152886  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8954
I0629 11:27:21.152886  2332 solver.cpp:397]     Test net output #1: loss = 0.35534 (* 1 = 0.35534 loss)
I0629 11:27:21.187912  2332 solver.cpp:218] Iteration 53000 (22.3109 iter/s, 4.48211s/100 iters), loss = 0.0897646
I0629 11:27:21.187912  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:27:21.187912  2332 solver.cpp:237]     Train net output #1: loss = 0.0897645 (* 1 = 0.0897645 loss)
I0629 11:27:21.187912  2332 sgd_solver.cpp:105] Iteration 53000, lr = 0.0001
I0629 11:27:24.822739  2332 solver.cpp:218] Iteration 53100 (27.5101 iter/s, 3.63503s/100 iters), loss = 0.108855
I0629 11:27:24.823740  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:27:24.823740  2332 solver.cpp:237]     Train net output #1: loss = 0.108854 (* 1 = 0.108854 loss)
I0629 11:27:24.823740  2332 sgd_solver.cpp:105] Iteration 53100, lr = 0.0001
I0629 11:27:28.450513  2332 solver.cpp:218] Iteration 53200 (27.5704 iter/s, 3.62708s/100 iters), loss = 0.0712638
I0629 11:27:28.450513  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:27:28.450513  2332 solver.cpp:237]     Train net output #1: loss = 0.0712636 (* 1 = 0.0712636 loss)
I0629 11:27:28.450513  2332 sgd_solver.cpp:105] Iteration 53200, lr = 0.0001
I0629 11:27:32.075362  2332 solver.cpp:218] Iteration 53300 (27.5942 iter/s, 3.62395s/100 iters), loss = 0.0766718
I0629 11:27:32.075362  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:27:32.075362  2332 solver.cpp:237]     Train net output #1: loss = 0.0766716 (* 1 = 0.0766716 loss)
I0629 11:27:32.075362  2332 sgd_solver.cpp:105] Iteration 53300, lr = 0.0001
I0629 11:27:35.700152  2332 solver.cpp:218] Iteration 53400 (27.5899 iter/s, 3.62452s/100 iters), loss = 0.10437
I0629 11:27:35.700152  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:27:35.700152  2332 solver.cpp:237]     Train net output #1: loss = 0.10437 (* 1 = 0.10437 loss)
I0629 11:27:35.700152  2332 sgd_solver.cpp:105] Iteration 53400, lr = 0.0001
I0629 11:27:39.143785  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:27:39.285892  2332 solver.cpp:330] Iteration 53500, Testing net (#0)
I0629 11:27:39.285892  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:27:40.101516  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:27:40.133544  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8952
I0629 11:27:40.133544  2332 solver.cpp:397]     Test net output #1: loss = 0.35609 (* 1 = 0.35609 loss)
I0629 11:27:40.167567  2332 solver.cpp:218] Iteration 53500 (22.3833 iter/s, 4.46762s/100 iters), loss = 0.0887724
I0629 11:27:40.167567  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:27:40.167567  2332 solver.cpp:237]     Train net output #1: loss = 0.0887723 (* 1 = 0.0887723 loss)
I0629 11:27:40.167567  2332 sgd_solver.cpp:105] Iteration 53500, lr = 0.0001
I0629 11:27:43.792564  2332 solver.cpp:218] Iteration 53600 (27.5926 iter/s, 3.62416s/100 iters), loss = 0.160459
I0629 11:27:43.792564  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:27:43.792564  2332 solver.cpp:237]     Train net output #1: loss = 0.160459 (* 1 = 0.160459 loss)
I0629 11:27:43.792564  2332 sgd_solver.cpp:105] Iteration 53600, lr = 0.0001
I0629 11:27:47.414412  2332 solver.cpp:218] Iteration 53700 (27.6142 iter/s, 3.62133s/100 iters), loss = 0.14344
I0629 11:27:47.414412  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:27:47.414412  2332 solver.cpp:237]     Train net output #1: loss = 0.143439 (* 1 = 0.143439 loss)
I0629 11:27:47.414412  2332 sgd_solver.cpp:105] Iteration 53700, lr = 0.0001
I0629 11:27:51.039212  2332 solver.cpp:218] Iteration 53800 (27.5902 iter/s, 3.62448s/100 iters), loss = 0.139167
I0629 11:27:51.039212  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:27:51.039212  2332 solver.cpp:237]     Train net output #1: loss = 0.139166 (* 1 = 0.139166 loss)
I0629 11:27:51.039212  2332 sgd_solver.cpp:105] Iteration 53800, lr = 0.0001
I0629 11:27:54.668436  2332 solver.cpp:218] Iteration 53900 (27.5536 iter/s, 3.62929s/100 iters), loss = 0.0899221
I0629 11:27:54.668936  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:27:54.668936  2332 solver.cpp:237]     Train net output #1: loss = 0.0899219 (* 1 = 0.0899219 loss)
I0629 11:27:54.668936  2332 sgd_solver.cpp:105] Iteration 53900, lr = 0.0001
I0629 11:27:58.114518  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:27:58.256634  2332 solver.cpp:330] Iteration 54000, Testing net (#0)
I0629 11:27:58.256634  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:27:59.072237  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:27:59.103265  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0629 11:27:59.103265  2332 solver.cpp:397]     Test net output #1: loss = 0.356505 (* 1 = 0.356505 loss)
I0629 11:27:59.138288  2332 solver.cpp:218] Iteration 54000 (22.3748 iter/s, 4.46931s/100 iters), loss = 0.0929561
I0629 11:27:59.138288  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:27:59.138288  2332 solver.cpp:237]     Train net output #1: loss = 0.0929559 (* 1 = 0.0929559 loss)
I0629 11:27:59.138288  2332 sgd_solver.cpp:46] MultiStep Status: Iteration 54000, step = 3
I0629 11:27:59.138288  2332 sgd_solver.cpp:105] Iteration 54000, lr = 1e-05
I0629 11:28:02.764170  2332 solver.cpp:218] Iteration 54100 (27.5847 iter/s, 3.6252s/100 iters), loss = 0.138101
I0629 11:28:02.764170  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:28:02.764170  2332 solver.cpp:237]     Train net output #1: loss = 0.1381 (* 1 = 0.1381 loss)
I0629 11:28:02.764170  2332 sgd_solver.cpp:105] Iteration 54100, lr = 1e-05
I0629 11:28:06.399583  2332 solver.cpp:218] Iteration 54200 (27.5084 iter/s, 3.63525s/100 iters), loss = 0.0544545
I0629 11:28:06.399583  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:28:06.399583  2332 solver.cpp:237]     Train net output #1: loss = 0.0544542 (* 1 = 0.0544542 loss)
I0629 11:28:06.399583  2332 sgd_solver.cpp:105] Iteration 54200, lr = 1e-05
I0629 11:28:10.026971  2332 solver.cpp:218] Iteration 54300 (27.5681 iter/s, 3.62738s/100 iters), loss = 0.0584971
I0629 11:28:10.026971  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:28:10.026971  2332 solver.cpp:237]     Train net output #1: loss = 0.0584968 (* 1 = 0.0584968 loss)
I0629 11:28:10.026971  2332 sgd_solver.cpp:105] Iteration 54300, lr = 1e-05
I0629 11:28:13.655707  2332 solver.cpp:218] Iteration 54400 (27.5633 iter/s, 3.62801s/100 iters), loss = 0.0966095
I0629 11:28:13.655707  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:28:13.655707  2332 solver.cpp:237]     Train net output #1: loss = 0.0966093 (* 1 = 0.0966093 loss)
I0629 11:28:13.655707  2332 sgd_solver.cpp:105] Iteration 54400, lr = 1e-05
I0629 11:28:17.106709  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:28:17.252318  2332 solver.cpp:330] Iteration 54500, Testing net (#0)
I0629 11:28:17.252318  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:28:18.068931  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:28:18.099953  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I0629 11:28:18.099953  2332 solver.cpp:397]     Test net output #1: loss = 0.355546 (* 1 = 0.355546 loss)
I0629 11:28:18.133996  2332 solver.cpp:218] Iteration 54500 (22.3286 iter/s, 4.47855s/100 iters), loss = 0.072451
I0629 11:28:18.133996  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:28:18.133996  2332 solver.cpp:237]     Train net output #1: loss = 0.0724508 (* 1 = 0.0724508 loss)
I0629 11:28:18.133996  2332 sgd_solver.cpp:105] Iteration 54500, lr = 1e-05
I0629 11:28:21.765691  2332 solver.cpp:218] Iteration 54600 (27.5394 iter/s, 3.63117s/100 iters), loss = 0.122159
I0629 11:28:21.765691  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:28:21.765691  2332 solver.cpp:237]     Train net output #1: loss = 0.122158 (* 1 = 0.122158 loss)
I0629 11:28:21.765691  2332 sgd_solver.cpp:105] Iteration 54600, lr = 1e-05
I0629 11:28:25.399286  2332 solver.cpp:218] Iteration 54700 (27.5231 iter/s, 3.63331s/100 iters), loss = 0.127756
I0629 11:28:25.400286  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:28:25.400286  2332 solver.cpp:237]     Train net output #1: loss = 0.127756 (* 1 = 0.127756 loss)
I0629 11:28:25.400286  2332 sgd_solver.cpp:105] Iteration 54700, lr = 1e-05
I0629 11:28:29.023928  2332 solver.cpp:218] Iteration 54800 (27.5959 iter/s, 3.62373s/100 iters), loss = 0.0903841
I0629 11:28:29.023928  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:28:29.023928  2332 solver.cpp:237]     Train net output #1: loss = 0.0903839 (* 1 = 0.0903839 loss)
I0629 11:28:29.024430  2332 sgd_solver.cpp:105] Iteration 54800, lr = 1e-05
I0629 11:28:32.650727  2332 solver.cpp:218] Iteration 54900 (27.5746 iter/s, 3.62653s/100 iters), loss = 0.138745
I0629 11:28:32.650727  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:28:32.650727  2332 solver.cpp:237]     Train net output #1: loss = 0.138745 (* 1 = 0.138745 loss)
I0629 11:28:32.650727  2332 sgd_solver.cpp:105] Iteration 54900, lr = 1e-05
I0629 11:28:36.092320  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:28:36.236430  2332 solver.cpp:330] Iteration 55000, Testing net (#0)
I0629 11:28:36.236430  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:28:37.053164  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:28:37.084190  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8947
I0629 11:28:37.084190  2332 solver.cpp:397]     Test net output #1: loss = 0.355562 (* 1 = 0.355562 loss)
I0629 11:28:37.118712  2332 solver.cpp:218] Iteration 55000 (22.3834 iter/s, 4.46759s/100 iters), loss = 0.0822288
I0629 11:28:37.119213  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:28:37.119213  2332 solver.cpp:237]     Train net output #1: loss = 0.0822285 (* 1 = 0.0822285 loss)
I0629 11:28:37.119213  2332 sgd_solver.cpp:105] Iteration 55000, lr = 1e-05
I0629 11:28:40.753141  2332 solver.cpp:218] Iteration 55100 (27.5203 iter/s, 3.63368s/100 iters), loss = 0.113218
I0629 11:28:40.753141  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:28:40.753141  2332 solver.cpp:237]     Train net output #1: loss = 0.113218 (* 1 = 0.113218 loss)
I0629 11:28:40.753141  2332 sgd_solver.cpp:105] Iteration 55100, lr = 1e-05
I0629 11:28:44.382686  2332 solver.cpp:218] Iteration 55200 (27.5541 iter/s, 3.62922s/100 iters), loss = 0.0985052
I0629 11:28:44.382686  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:28:44.382686  2332 solver.cpp:237]     Train net output #1: loss = 0.098505 (* 1 = 0.098505 loss)
I0629 11:28:44.382686  2332 sgd_solver.cpp:105] Iteration 55200, lr = 1e-05
I0629 11:28:48.010473  2332 solver.cpp:218] Iteration 55300 (27.564 iter/s, 3.62793s/100 iters), loss = 0.0539285
I0629 11:28:48.010473  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:28:48.010473  2332 solver.cpp:237]     Train net output #1: loss = 0.0539283 (* 1 = 0.0539283 loss)
I0629 11:28:48.010473  2332 sgd_solver.cpp:105] Iteration 55300, lr = 1e-05
I0629 11:28:51.636356  2332 solver.cpp:218] Iteration 55400 (27.5855 iter/s, 3.62509s/100 iters), loss = 0.0621732
I0629 11:28:51.636356  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:28:51.636356  2332 solver.cpp:237]     Train net output #1: loss = 0.062173 (* 1 = 0.062173 loss)
I0629 11:28:51.636356  2332 sgd_solver.cpp:105] Iteration 55400, lr = 1e-05
I0629 11:28:55.098170  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:28:55.240279  2332 solver.cpp:330] Iteration 55500, Testing net (#0)
I0629 11:28:55.240279  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:28:56.056994  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:28:56.088019  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0629 11:28:56.088019  2332 solver.cpp:397]     Test net output #1: loss = 0.355692 (* 1 = 0.355692 loss)
I0629 11:28:56.122043  2332 solver.cpp:218] Iteration 55500 (22.2921 iter/s, 4.4859s/100 iters), loss = 0.111504
I0629 11:28:56.122043  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:28:56.122043  2332 solver.cpp:237]     Train net output #1: loss = 0.111504 (* 1 = 0.111504 loss)
I0629 11:28:56.122043  2332 sgd_solver.cpp:105] Iteration 55500, lr = 1e-05
I0629 11:28:59.744806  2332 solver.cpp:218] Iteration 55600 (27.6131 iter/s, 3.62148s/100 iters), loss = 0.0880716
I0629 11:28:59.744806  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:28:59.744806  2332 solver.cpp:237]     Train net output #1: loss = 0.0880714 (* 1 = 0.0880714 loss)
I0629 11:28:59.744806  2332 sgd_solver.cpp:105] Iteration 55600, lr = 1e-05
I0629 11:29:03.373677  2332 solver.cpp:218] Iteration 55700 (27.5588 iter/s, 3.6286s/100 iters), loss = 0.123074
I0629 11:29:03.373677  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:29:03.373677  2332 solver.cpp:237]     Train net output #1: loss = 0.123074 (* 1 = 0.123074 loss)
I0629 11:29:03.373677  2332 sgd_solver.cpp:105] Iteration 55700, lr = 1e-05
I0629 11:29:06.994527  2332 solver.cpp:218] Iteration 55800 (27.6184 iter/s, 3.62078s/100 iters), loss = 0.0895489
I0629 11:29:06.994527  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:29:06.994527  2332 solver.cpp:237]     Train net output #1: loss = 0.0895487 (* 1 = 0.0895487 loss)
I0629 11:29:06.994527  2332 sgd_solver.cpp:105] Iteration 55800, lr = 1e-05
I0629 11:29:10.616299  2332 solver.cpp:218] Iteration 55900 (27.6133 iter/s, 3.62145s/100 iters), loss = 0.0296157
I0629 11:29:10.616299  2332 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0629 11:29:10.616299  2332 solver.cpp:237]     Train net output #1: loss = 0.0296155 (* 1 = 0.0296155 loss)
I0629 11:29:10.616299  2332 sgd_solver.cpp:105] Iteration 55900, lr = 1e-05
I0629 11:29:14.067032  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:29:14.209138  2332 solver.cpp:330] Iteration 56000, Testing net (#0)
I0629 11:29:14.209138  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:29:15.025755  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:29:15.056777  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I0629 11:29:15.056777  2332 solver.cpp:397]     Test net output #1: loss = 0.355452 (* 1 = 0.355452 loss)
I0629 11:29:15.090802  2332 solver.cpp:218] Iteration 56000 (22.352 iter/s, 4.47388s/100 iters), loss = 0.0744203
I0629 11:29:15.090802  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:29:15.090802  2332 solver.cpp:237]     Train net output #1: loss = 0.0744201 (* 1 = 0.0744201 loss)
I0629 11:29:15.090802  2332 sgd_solver.cpp:105] Iteration 56000, lr = 1e-05
I0629 11:29:18.715525  2332 solver.cpp:218] Iteration 56100 (27.5848 iter/s, 3.62519s/100 iters), loss = 0.11969
I0629 11:29:18.716526  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:29:18.716526  2332 solver.cpp:237]     Train net output #1: loss = 0.11969 (* 1 = 0.11969 loss)
I0629 11:29:18.716526  2332 sgd_solver.cpp:105] Iteration 56100, lr = 1e-05
I0629 11:29:22.338289  2332 solver.cpp:218] Iteration 56200 (27.6092 iter/s, 3.62198s/100 iters), loss = 0.066921
I0629 11:29:22.338289  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:29:22.338289  2332 solver.cpp:237]     Train net output #1: loss = 0.0669208 (* 1 = 0.0669208 loss)
I0629 11:29:22.338289  2332 sgd_solver.cpp:105] Iteration 56200, lr = 1e-05
I0629 11:29:25.969182  2332 solver.cpp:218] Iteration 56300 (27.5417 iter/s, 3.63086s/100 iters), loss = 0.0786181
I0629 11:29:25.969182  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:29:25.969182  2332 solver.cpp:237]     Train net output #1: loss = 0.0786179 (* 1 = 0.0786179 loss)
I0629 11:29:25.969182  2332 sgd_solver.cpp:105] Iteration 56300, lr = 1e-05
I0629 11:29:29.595633  2332 solver.cpp:218] Iteration 56400 (27.584 iter/s, 3.6253s/100 iters), loss = 0.0837583
I0629 11:29:29.595633  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:29:29.595633  2332 solver.cpp:237]     Train net output #1: loss = 0.0837581 (* 1 = 0.0837581 loss)
I0629 11:29:29.595633  2332 sgd_solver.cpp:105] Iteration 56400, lr = 1e-05
I0629 11:29:33.044709  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:29:33.186815  2332 solver.cpp:330] Iteration 56500, Testing net (#0)
I0629 11:29:33.186815  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:29:34.003214  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:29:34.033737  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I0629 11:29:34.033737  2332 solver.cpp:397]     Test net output #1: loss = 0.355842 (* 1 = 0.355842 loss)
I0629 11:29:34.068763  2332 solver.cpp:218] Iteration 56500 (22.355 iter/s, 4.47328s/100 iters), loss = 0.0821275
I0629 11:29:34.068763  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:29:34.068763  2332 solver.cpp:237]     Train net output #1: loss = 0.0821273 (* 1 = 0.0821273 loss)
I0629 11:29:34.068763  2332 sgd_solver.cpp:105] Iteration 56500, lr = 1e-05
I0629 11:29:37.689291  2332 solver.cpp:218] Iteration 56600 (27.627 iter/s, 3.61965s/100 iters), loss = 0.164832
I0629 11:29:37.689291  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:29:37.689291  2332 solver.cpp:237]     Train net output #1: loss = 0.164832 (* 1 = 0.164832 loss)
I0629 11:29:37.689291  2332 sgd_solver.cpp:105] Iteration 56600, lr = 1e-05
I0629 11:29:41.305660  2332 solver.cpp:218] Iteration 56700 (27.6526 iter/s, 3.6163s/100 iters), loss = 0.0793711
I0629 11:29:41.305660  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:29:41.305660  2332 solver.cpp:237]     Train net output #1: loss = 0.079371 (* 1 = 0.079371 loss)
I0629 11:29:41.305660  2332 sgd_solver.cpp:105] Iteration 56700, lr = 1e-05
I0629 11:29:44.923007  2332 solver.cpp:218] Iteration 56800 (27.6445 iter/s, 3.61735s/100 iters), loss = 0.0652234
I0629 11:29:44.923007  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:29:44.923007  2332 solver.cpp:237]     Train net output #1: loss = 0.0652232 (* 1 = 0.0652232 loss)
I0629 11:29:44.923007  2332 sgd_solver.cpp:105] Iteration 56800, lr = 1e-05
I0629 11:29:48.542731  2332 solver.cpp:218] Iteration 56900 (27.6308 iter/s, 3.61915s/100 iters), loss = 0.127855
I0629 11:29:48.542731  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:29:48.542731  2332 solver.cpp:237]     Train net output #1: loss = 0.127855 (* 1 = 0.127855 loss)
I0629 11:29:48.542731  2332 sgd_solver.cpp:105] Iteration 56900, lr = 1e-05
I0629 11:29:51.988250  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:29:52.130357  2332 solver.cpp:330] Iteration 57000, Testing net (#0)
I0629 11:29:52.130357  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:29:52.946998  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:29:52.978021  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8952
I0629 11:29:52.978021  2332 solver.cpp:397]     Test net output #1: loss = 0.355127 (* 1 = 0.355127 loss)
I0629 11:29:53.012048  2332 solver.cpp:218] Iteration 57000 (22.3745 iter/s, 4.46937s/100 iters), loss = 0.0583142
I0629 11:29:53.012048  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:29:53.013049  2332 solver.cpp:237]     Train net output #1: loss = 0.058314 (* 1 = 0.058314 loss)
I0629 11:29:53.013049  2332 sgd_solver.cpp:105] Iteration 57000, lr = 1e-05
I0629 11:29:56.635766  2332 solver.cpp:218] Iteration 57100 (27.605 iter/s, 3.62254s/100 iters), loss = 0.156557
I0629 11:29:56.635766  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:29:56.635766  2332 solver.cpp:237]     Train net output #1: loss = 0.156557 (* 1 = 0.156557 loss)
I0629 11:29:56.635766  2332 sgd_solver.cpp:105] Iteration 57100, lr = 1e-05
I0629 11:30:00.266535  2332 solver.cpp:218] Iteration 57200 (27.5437 iter/s, 3.63059s/100 iters), loss = 0.144085
I0629 11:30:00.266535  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:30:00.266535  2332 solver.cpp:237]     Train net output #1: loss = 0.144085 (* 1 = 0.144085 loss)
I0629 11:30:00.266535  2332 sgd_solver.cpp:105] Iteration 57200, lr = 1e-05
I0629 11:30:03.890326  2332 solver.cpp:218] Iteration 57300 (27.5951 iter/s, 3.62384s/100 iters), loss = 0.109503
I0629 11:30:03.890326  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:30:03.890326  2332 solver.cpp:237]     Train net output #1: loss = 0.109503 (* 1 = 0.109503 loss)
I0629 11:30:03.890326  2332 sgd_solver.cpp:105] Iteration 57300, lr = 1e-05
I0629 11:30:07.525189  2332 solver.cpp:218] Iteration 57400 (27.5183 iter/s, 3.63395s/100 iters), loss = 0.0793602
I0629 11:30:07.525189  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:30:07.525189  2332 solver.cpp:237]     Train net output #1: loss = 0.0793601 (* 1 = 0.0793601 loss)
I0629 11:30:07.525189  2332 sgd_solver.cpp:105] Iteration 57400, lr = 1e-05
I0629 11:30:10.977926  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:30:11.120534  2332 solver.cpp:330] Iteration 57500, Testing net (#0)
I0629 11:30:11.120534  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:30:11.936672  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:30:11.967694  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8952
I0629 11:30:11.967694  2332 solver.cpp:397]     Test net output #1: loss = 0.355395 (* 1 = 0.355395 loss)
I0629 11:30:12.001718  2332 solver.cpp:218] Iteration 57500 (22.337 iter/s, 4.47688s/100 iters), loss = 0.087083
I0629 11:30:12.001718  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:30:12.001718  2332 solver.cpp:237]     Train net output #1: loss = 0.0870829 (* 1 = 0.0870829 loss)
I0629 11:30:12.001718  2332 sgd_solver.cpp:105] Iteration 57500, lr = 1e-05
I0629 11:30:15.627338  2332 solver.cpp:218] Iteration 57600 (27.5841 iter/s, 3.62527s/100 iters), loss = 0.125484
I0629 11:30:15.627338  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:30:15.627338  2332 solver.cpp:237]     Train net output #1: loss = 0.125484 (* 1 = 0.125484 loss)
I0629 11:30:15.627338  2332 sgd_solver.cpp:105] Iteration 57600, lr = 1e-05
I0629 11:30:19.254091  2332 solver.cpp:218] Iteration 57700 (27.581 iter/s, 3.62569s/100 iters), loss = 0.074164
I0629 11:30:19.254091  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:30:19.254091  2332 solver.cpp:237]     Train net output #1: loss = 0.0741638 (* 1 = 0.0741638 loss)
I0629 11:30:19.254091  2332 sgd_solver.cpp:105] Iteration 57700, lr = 1e-05
I0629 11:30:22.879895  2332 solver.cpp:218] Iteration 57800 (27.5815 iter/s, 3.62562s/100 iters), loss = 0.152191
I0629 11:30:22.879895  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:30:22.879895  2332 solver.cpp:237]     Train net output #1: loss = 0.152191 (* 1 = 0.152191 loss)
I0629 11:30:22.879895  2332 sgd_solver.cpp:105] Iteration 57800, lr = 1e-05
I0629 11:30:26.507691  2332 solver.cpp:218] Iteration 57900 (27.5626 iter/s, 3.62811s/100 iters), loss = 0.0828831
I0629 11:30:26.507691  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:30:26.507691  2332 solver.cpp:237]     Train net output #1: loss = 0.0828829 (* 1 = 0.0828829 loss)
I0629 11:30:26.507691  2332 sgd_solver.cpp:105] Iteration 57900, lr = 1e-05
I0629 11:30:29.961411  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:30:30.102516  2332 solver.cpp:330] Iteration 58000, Testing net (#0)
I0629 11:30:30.102516  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:30:30.920162  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:30:30.951202  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8953
I0629 11:30:30.951202  2332 solver.cpp:397]     Test net output #1: loss = 0.355149 (* 1 = 0.355149 loss)
I0629 11:30:30.985216  2332 solver.cpp:218] Iteration 58000 (22.3368 iter/s, 4.47691s/100 iters), loss = 0.0841256
I0629 11:30:30.985216  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:30:30.985216  2332 solver.cpp:237]     Train net output #1: loss = 0.0841255 (* 1 = 0.0841255 loss)
I0629 11:30:30.985216  2332 sgd_solver.cpp:105] Iteration 58000, lr = 1e-05
I0629 11:30:34.618000  2332 solver.cpp:218] Iteration 58100 (27.5291 iter/s, 3.63252s/100 iters), loss = 0.121145
I0629 11:30:34.618000  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:30:34.618000  2332 solver.cpp:237]     Train net output #1: loss = 0.121145 (* 1 = 0.121145 loss)
I0629 11:30:34.618000  2332 sgd_solver.cpp:105] Iteration 58100, lr = 1e-05
I0629 11:30:38.249804  2332 solver.cpp:218] Iteration 58200 (27.5345 iter/s, 3.63181s/100 iters), loss = 0.100864
I0629 11:30:38.250804  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:30:38.250804  2332 solver.cpp:237]     Train net output #1: loss = 0.100864 (* 1 = 0.100864 loss)
I0629 11:30:38.250804  2332 sgd_solver.cpp:105] Iteration 58200, lr = 1e-05
I0629 11:30:41.886663  2332 solver.cpp:218] Iteration 58300 (27.4997 iter/s, 3.63641s/100 iters), loss = 0.0667048
I0629 11:30:41.887665  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:30:41.887665  2332 solver.cpp:237]     Train net output #1: loss = 0.0667047 (* 1 = 0.0667047 loss)
I0629 11:30:41.887665  2332 sgd_solver.cpp:105] Iteration 58300, lr = 1e-05
I0629 11:30:45.506474  2332 solver.cpp:218] Iteration 58400 (27.6337 iter/s, 3.61878s/100 iters), loss = 0.0812957
I0629 11:30:45.506474  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:30:45.506474  2332 solver.cpp:237]     Train net output #1: loss = 0.0812956 (* 1 = 0.0812956 loss)
I0629 11:30:45.506474  2332 sgd_solver.cpp:105] Iteration 58400, lr = 1e-05
I0629 11:30:48.953228  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:30:49.096328  2332 solver.cpp:330] Iteration 58500, Testing net (#0)
I0629 11:30:49.096328  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:30:49.915966  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:30:49.947491  2332 solver.cpp:397]     Test net output #0: accuracy = 0.895
I0629 11:30:49.947491  2332 solver.cpp:397]     Test net output #1: loss = 0.354981 (* 1 = 0.354981 loss)
I0629 11:30:49.982017  2332 solver.cpp:218] Iteration 58500 (22.3453 iter/s, 4.47521s/100 iters), loss = 0.0946869
I0629 11:30:49.982017  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:30:49.982017  2332 solver.cpp:237]     Train net output #1: loss = 0.0946867 (* 1 = 0.0946867 loss)
I0629 11:30:49.982017  2332 sgd_solver.cpp:105] Iteration 58500, lr = 1e-05
I0629 11:30:53.601796  2332 solver.cpp:218] Iteration 58600 (27.6254 iter/s, 3.61986s/100 iters), loss = 0.146002
I0629 11:30:53.601796  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:30:53.601796  2332 solver.cpp:237]     Train net output #1: loss = 0.146002 (* 1 = 0.146002 loss)
I0629 11:30:53.601796  2332 sgd_solver.cpp:105] Iteration 58600, lr = 1e-05
I0629 11:30:57.222604  2332 solver.cpp:218] Iteration 58700 (27.6205 iter/s, 3.6205s/100 iters), loss = 0.112429
I0629 11:30:57.222604  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:30:57.222604  2332 solver.cpp:237]     Train net output #1: loss = 0.112429 (* 1 = 0.112429 loss)
I0629 11:30:57.222604  2332 sgd_solver.cpp:105] Iteration 58700, lr = 1e-05
I0629 11:31:00.843390  2332 solver.cpp:218] Iteration 58800 (27.6227 iter/s, 3.62022s/100 iters), loss = 0.0870193
I0629 11:31:00.843390  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:31:00.843390  2332 solver.cpp:237]     Train net output #1: loss = 0.0870192 (* 1 = 0.0870192 loss)
I0629 11:31:00.843390  2332 sgd_solver.cpp:105] Iteration 58800, lr = 1e-05
I0629 11:31:04.471204  2332 solver.cpp:218] Iteration 58900 (27.5709 iter/s, 3.62702s/100 iters), loss = 0.0691224
I0629 11:31:04.471204  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:31:04.471204  2332 solver.cpp:237]     Train net output #1: loss = 0.0691222 (* 1 = 0.0691222 loss)
I0629 11:31:04.471204  2332 sgd_solver.cpp:105] Iteration 58900, lr = 1e-05
I0629 11:31:07.917927  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:31:08.060537  2332 solver.cpp:330] Iteration 59000, Testing net (#0)
I0629 11:31:08.060537  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:31:08.876663  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:31:08.907685  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8952
I0629 11:31:08.907685  2332 solver.cpp:397]     Test net output #1: loss = 0.355126 (* 1 = 0.355126 loss)
I0629 11:31:08.941709  2332 solver.cpp:218] Iteration 59000 (22.3675 iter/s, 4.47077s/100 iters), loss = 0.134062
I0629 11:31:08.941709  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:31:08.941709  2332 solver.cpp:237]     Train net output #1: loss = 0.134062 (* 1 = 0.134062 loss)
I0629 11:31:08.941709  2332 sgd_solver.cpp:105] Iteration 59000, lr = 1e-05
I0629 11:31:12.578552  2332 solver.cpp:218] Iteration 59100 (27.4969 iter/s, 3.63677s/100 iters), loss = 0.127499
I0629 11:31:12.579553  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:31:12.579553  2332 solver.cpp:237]     Train net output #1: loss = 0.127499 (* 1 = 0.127499 loss)
I0629 11:31:12.579553  2332 sgd_solver.cpp:105] Iteration 59100, lr = 1e-05
I0629 11:31:16.209355  2332 solver.cpp:218] Iteration 59200 (27.5513 iter/s, 3.6296s/100 iters), loss = 0.0866431
I0629 11:31:16.209355  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:31:16.209355  2332 solver.cpp:237]     Train net output #1: loss = 0.0866429 (* 1 = 0.0866429 loss)
I0629 11:31:16.209355  2332 sgd_solver.cpp:105] Iteration 59200, lr = 1e-05
I0629 11:31:19.830143  2332 solver.cpp:218] Iteration 59300 (27.6168 iter/s, 3.62098s/100 iters), loss = 0.0844528
I0629 11:31:19.830143  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:31:19.830143  2332 solver.cpp:237]     Train net output #1: loss = 0.0844526 (* 1 = 0.0844526 loss)
I0629 11:31:19.830143  2332 sgd_solver.cpp:105] Iteration 59300, lr = 1e-05
I0629 11:31:23.460978  2332 solver.cpp:218] Iteration 59400 (27.5436 iter/s, 3.63061s/100 iters), loss = 0.067202
I0629 11:31:23.460978  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:31:23.460978  2332 solver.cpp:237]     Train net output #1: loss = 0.0672018 (* 1 = 0.0672018 loss)
I0629 11:31:23.460978  2332 sgd_solver.cpp:105] Iteration 59400, lr = 1e-05
I0629 11:31:26.904630  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:31:27.046736  2332 solver.cpp:330] Iteration 59500, Testing net (#0)
I0629 11:31:27.046736  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:31:27.863371  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:31:27.894403  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8948
I0629 11:31:27.894403  2332 solver.cpp:397]     Test net output #1: loss = 0.355274 (* 1 = 0.355274 loss)
I0629 11:31:27.929424  2332 solver.cpp:218] Iteration 59500 (22.3844 iter/s, 4.4674s/100 iters), loss = 0.0624366
I0629 11:31:27.929424  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:31:27.929424  2332 solver.cpp:237]     Train net output #1: loss = 0.0624364 (* 1 = 0.0624364 loss)
I0629 11:31:27.929424  2332 sgd_solver.cpp:105] Iteration 59500, lr = 1e-05
I0629 11:31:31.562227  2332 solver.cpp:218] Iteration 59600 (27.5299 iter/s, 3.63242s/100 iters), loss = 0.109443
I0629 11:31:31.562227  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:31:31.562227  2332 solver.cpp:237]     Train net output #1: loss = 0.109443 (* 1 = 0.109443 loss)
I0629 11:31:31.562227  2332 sgd_solver.cpp:105] Iteration 59600, lr = 1e-05
I0629 11:31:35.180016  2332 solver.cpp:218] Iteration 59700 (27.6414 iter/s, 3.61776s/100 iters), loss = 0.123908
I0629 11:31:35.180016  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:31:35.180016  2332 solver.cpp:237]     Train net output #1: loss = 0.123908 (* 1 = 0.123908 loss)
I0629 11:31:35.180016  2332 sgd_solver.cpp:105] Iteration 59700, lr = 1e-05
I0629 11:31:38.808784  2332 solver.cpp:218] Iteration 59800 (27.5604 iter/s, 3.62839s/100 iters), loss = 0.0731621
I0629 11:31:38.808784  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:31:38.808784  2332 solver.cpp:237]     Train net output #1: loss = 0.0731619 (* 1 = 0.0731619 loss)
I0629 11:31:38.808784  2332 sgd_solver.cpp:105] Iteration 59800, lr = 1e-05
I0629 11:31:42.434545  2332 solver.cpp:218] Iteration 59900 (27.5816 iter/s, 3.6256s/100 iters), loss = 0.0842791
I0629 11:31:42.434545  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:31:42.434545  2332 solver.cpp:237]     Train net output #1: loss = 0.084279 (* 1 = 0.084279 loss)
I0629 11:31:42.434545  2332 sgd_solver.cpp:105] Iteration 59900, lr = 1e-05
I0629 11:31:45.889631  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:31:46.031236  2332 solver.cpp:330] Iteration 60000, Testing net (#0)
I0629 11:31:46.031236  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:31:46.848886  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:31:46.879907  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8948
I0629 11:31:46.879907  2332 solver.cpp:397]     Test net output #1: loss = 0.355538 (* 1 = 0.355538 loss)
I0629 11:31:46.913936  2332 solver.cpp:218] Iteration 60000 (22.324 iter/s, 4.47948s/100 iters), loss = 0.0812759
I0629 11:31:46.913936  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:31:46.913936  2332 solver.cpp:237]     Train net output #1: loss = 0.0812758 (* 1 = 0.0812758 loss)
I0629 11:31:46.913936  2332 sgd_solver.cpp:105] Iteration 60000, lr = 1e-05
I0629 11:31:50.535826  2332 solver.cpp:218] Iteration 60100 (27.6174 iter/s, 3.6209s/100 iters), loss = 0.123684
I0629 11:31:50.535826  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:31:50.535826  2332 solver.cpp:237]     Train net output #1: loss = 0.123684 (* 1 = 0.123684 loss)
I0629 11:31:50.535826  2332 sgd_solver.cpp:105] Iteration 60100, lr = 1e-05
I0629 11:31:54.153373  2332 solver.cpp:218] Iteration 60200 (27.6478 iter/s, 3.61692s/100 iters), loss = 0.14419
I0629 11:31:54.153373  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:31:54.153373  2332 solver.cpp:237]     Train net output #1: loss = 0.144189 (* 1 = 0.144189 loss)
I0629 11:31:54.153373  2332 sgd_solver.cpp:105] Iteration 60200, lr = 1e-05
I0629 11:31:57.776070  2332 solver.cpp:218] Iteration 60300 (27.6041 iter/s, 3.62265s/100 iters), loss = 0.134494
I0629 11:31:57.776070  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:31:57.776070  2332 solver.cpp:237]     Train net output #1: loss = 0.134494 (* 1 = 0.134494 loss)
I0629 11:31:57.776070  2332 sgd_solver.cpp:105] Iteration 60300, lr = 1e-05
I0629 11:32:01.398332  2332 solver.cpp:218] Iteration 60400 (27.6093 iter/s, 3.62196s/100 iters), loss = 0.0950221
I0629 11:32:01.398332  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:32:01.398332  2332 solver.cpp:237]     Train net output #1: loss = 0.095022 (* 1 = 0.095022 loss)
I0629 11:32:01.398332  2332 sgd_solver.cpp:105] Iteration 60400, lr = 1e-05
I0629 11:32:04.844385  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:32:04.986490  2332 solver.cpp:330] Iteration 60500, Testing net (#0)
I0629 11:32:04.986490  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:32:05.803632  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:32:05.834156  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8951
I0629 11:32:05.835156  2332 solver.cpp:397]     Test net output #1: loss = 0.355796 (* 1 = 0.355796 loss)
I0629 11:32:05.869179  2332 solver.cpp:218] Iteration 60500 (22.3687 iter/s, 4.47054s/100 iters), loss = 0.069329
I0629 11:32:05.869179  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:32:05.869179  2332 solver.cpp:237]     Train net output #1: loss = 0.0693288 (* 1 = 0.0693288 loss)
I0629 11:32:05.869179  2332 sgd_solver.cpp:105] Iteration 60500, lr = 1e-05
I0629 11:32:09.489089  2332 solver.cpp:218] Iteration 60600 (27.6246 iter/s, 3.61996s/100 iters), loss = 0.17402
I0629 11:32:09.489089  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:32:09.489089  2332 solver.cpp:237]     Train net output #1: loss = 0.17402 (* 1 = 0.17402 loss)
I0629 11:32:09.489089  2332 sgd_solver.cpp:105] Iteration 60600, lr = 1e-05
I0629 11:32:13.115579  2332 solver.cpp:218] Iteration 60700 (27.5808 iter/s, 3.62571s/100 iters), loss = 0.174895
I0629 11:32:13.115579  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:32:13.115579  2332 solver.cpp:237]     Train net output #1: loss = 0.174894 (* 1 = 0.174894 loss)
I0629 11:32:13.115579  2332 sgd_solver.cpp:105] Iteration 60700, lr = 1e-05
I0629 11:32:16.738278  2332 solver.cpp:218] Iteration 60800 (27.6064 iter/s, 3.62235s/100 iters), loss = 0.083364
I0629 11:32:16.738278  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:32:16.738278  2332 solver.cpp:237]     Train net output #1: loss = 0.0833639 (* 1 = 0.0833639 loss)
I0629 11:32:16.738278  2332 sgd_solver.cpp:105] Iteration 60800, lr = 1e-05
I0629 11:32:20.365028  2332 solver.cpp:218] Iteration 60900 (27.5731 iter/s, 3.62672s/100 iters), loss = 0.0467829
I0629 11:32:20.365028  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:32:20.365028  2332 solver.cpp:237]     Train net output #1: loss = 0.0467828 (* 1 = 0.0467828 loss)
I0629 11:32:20.365028  2332 sgd_solver.cpp:105] Iteration 60900, lr = 1e-05
I0629 11:32:23.826494  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:32:23.967600  2332 solver.cpp:330] Iteration 61000, Testing net (#0)
I0629 11:32:23.967600  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:32:24.785356  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:32:24.816880  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8951
I0629 11:32:24.816880  2332 solver.cpp:397]     Test net output #1: loss = 0.355241 (* 1 = 0.355241 loss)
I0629 11:32:24.855409  2332 solver.cpp:218] Iteration 61000 (22.2755 iter/s, 4.48924s/100 iters), loss = 0.0619523
I0629 11:32:24.855409  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:32:24.855409  2332 solver.cpp:237]     Train net output #1: loss = 0.0619522 (* 1 = 0.0619522 loss)
I0629 11:32:24.855409  2332 sgd_solver.cpp:105] Iteration 61000, lr = 1e-05
I0629 11:32:28.486142  2332 solver.cpp:218] Iteration 61100 (27.5413 iter/s, 3.63091s/100 iters), loss = 0.0960851
I0629 11:32:28.486142  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:32:28.486142  2332 solver.cpp:237]     Train net output #1: loss = 0.0960851 (* 1 = 0.0960851 loss)
I0629 11:32:28.486142  2332 sgd_solver.cpp:105] Iteration 61100, lr = 1e-05
I0629 11:32:32.119446  2332 solver.cpp:218] Iteration 61200 (27.5296 iter/s, 3.63245s/100 iters), loss = 0.121121
I0629 11:32:32.119446  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:32:32.119446  2332 solver.cpp:237]     Train net output #1: loss = 0.121121 (* 1 = 0.121121 loss)
I0629 11:32:32.119446  2332 sgd_solver.cpp:105] Iteration 61200, lr = 1e-05
I0629 11:32:35.745482  2332 solver.cpp:218] Iteration 61300 (27.5753 iter/s, 3.62643s/100 iters), loss = 0.10718
I0629 11:32:35.745482  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:32:35.745482  2332 solver.cpp:237]     Train net output #1: loss = 0.10718 (* 1 = 0.10718 loss)
I0629 11:32:35.745482  2332 sgd_solver.cpp:105] Iteration 61300, lr = 1e-05
I0629 11:32:39.388347  2332 solver.cpp:218] Iteration 61400 (27.4583 iter/s, 3.64189s/100 iters), loss = 0.0666731
I0629 11:32:39.388347  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:32:39.388347  2332 solver.cpp:237]     Train net output #1: loss = 0.066673 (* 1 = 0.066673 loss)
I0629 11:32:39.388347  2332 sgd_solver.cpp:105] Iteration 61400, lr = 1e-05
I0629 11:32:42.841806  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:32:42.982909  2332 solver.cpp:330] Iteration 61500, Testing net (#0)
I0629 11:32:42.982909  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:32:43.807428  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:32:43.838454  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8944
I0629 11:32:43.838454  2332 solver.cpp:397]     Test net output #1: loss = 0.355568 (* 1 = 0.355568 loss)
I0629 11:32:43.872134  2332 solver.cpp:218] Iteration 61500 (22.302 iter/s, 4.48391s/100 iters), loss = 0.132625
I0629 11:32:43.872134  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:32:43.872134  2332 solver.cpp:237]     Train net output #1: loss = 0.132625 (* 1 = 0.132625 loss)
I0629 11:32:43.872134  2332 sgd_solver.cpp:105] Iteration 61500, lr = 1e-05
I0629 11:32:47.503343  2332 solver.cpp:218] Iteration 61600 (27.5455 iter/s, 3.63036s/100 iters), loss = 0.113424
I0629 11:32:47.503343  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:32:47.503343  2332 solver.cpp:237]     Train net output #1: loss = 0.113424 (* 1 = 0.113424 loss)
I0629 11:32:47.503343  2332 sgd_solver.cpp:105] Iteration 61600, lr = 1e-05
I0629 11:32:51.123697  2332 solver.cpp:218] Iteration 61700 (27.6205 iter/s, 3.6205s/100 iters), loss = 0.131394
I0629 11:32:51.123697  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:32:51.123697  2332 solver.cpp:237]     Train net output #1: loss = 0.131394 (* 1 = 0.131394 loss)
I0629 11:32:51.123697  2332 sgd_solver.cpp:105] Iteration 61700, lr = 1e-05
I0629 11:32:54.747465  2332 solver.cpp:218] Iteration 61800 (27.603 iter/s, 3.6228s/100 iters), loss = 0.073203
I0629 11:32:54.747465  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:32:54.747465  2332 solver.cpp:237]     Train net output #1: loss = 0.073203 (* 1 = 0.073203 loss)
I0629 11:32:54.747465  2332 sgd_solver.cpp:105] Iteration 61800, lr = 1e-05
I0629 11:32:58.368268  2332 solver.cpp:218] Iteration 61900 (27.6189 iter/s, 3.62071s/100 iters), loss = 0.0926019
I0629 11:32:58.368268  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:32:58.368268  2332 solver.cpp:237]     Train net output #1: loss = 0.0926019 (* 1 = 0.0926019 loss)
I0629 11:32:58.368268  2332 sgd_solver.cpp:105] Iteration 61900, lr = 1e-05
I0629 11:33:01.820751  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:33:01.961865  2332 solver.cpp:330] Iteration 62000, Testing net (#0)
I0629 11:33:01.961865  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:33:02.778517  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:33:02.809538  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8947
I0629 11:33:02.809538  2332 solver.cpp:397]     Test net output #1: loss = 0.355725 (* 1 = 0.355725 loss)
I0629 11:33:02.844564  2332 solver.cpp:218] Iteration 62000 (22.3423 iter/s, 4.47582s/100 iters), loss = 0.0795879
I0629 11:33:02.844564  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:33:02.844564  2332 solver.cpp:237]     Train net output #1: loss = 0.0795879 (* 1 = 0.0795879 loss)
I0629 11:33:02.844564  2332 sgd_solver.cpp:105] Iteration 62000, lr = 1e-05
I0629 11:33:06.474283  2332 solver.cpp:218] Iteration 62100 (27.5549 iter/s, 3.62912s/100 iters), loss = 0.0887938
I0629 11:33:06.474283  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:33:06.474283  2332 solver.cpp:237]     Train net output #1: loss = 0.0887937 (* 1 = 0.0887937 loss)
I0629 11:33:06.474283  2332 sgd_solver.cpp:105] Iteration 62100, lr = 1e-05
I0629 11:33:10.094713  2332 solver.cpp:218] Iteration 62200 (27.6165 iter/s, 3.62102s/100 iters), loss = 0.0818827
I0629 11:33:10.094713  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:33:10.094713  2332 solver.cpp:237]     Train net output #1: loss = 0.0818826 (* 1 = 0.0818826 loss)
I0629 11:33:10.095715  2332 sgd_solver.cpp:105] Iteration 62200, lr = 1e-05
I0629 11:33:13.723824  2332 solver.cpp:218] Iteration 62300 (27.5613 iter/s, 3.62827s/100 iters), loss = 0.095658
I0629 11:33:13.723824  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:33:13.723824  2332 solver.cpp:237]     Train net output #1: loss = 0.0956579 (* 1 = 0.0956579 loss)
I0629 11:33:13.723824  2332 sgd_solver.cpp:105] Iteration 62300, lr = 1e-05
I0629 11:33:17.355141  2332 solver.cpp:218] Iteration 62400 (27.5414 iter/s, 3.6309s/100 iters), loss = 0.121041
I0629 11:33:17.355141  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:33:17.355141  2332 solver.cpp:237]     Train net output #1: loss = 0.121041 (* 1 = 0.121041 loss)
I0629 11:33:17.355141  2332 sgd_solver.cpp:105] Iteration 62400, lr = 1e-05
I0629 11:33:20.817951  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:33:20.961115  2332 solver.cpp:330] Iteration 62500, Testing net (#0)
I0629 11:33:20.961115  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:33:21.780747  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:33:21.811770  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8943
I0629 11:33:21.811770  2332 solver.cpp:397]     Test net output #1: loss = 0.355301 (* 1 = 0.355301 loss)
I0629 11:33:21.846822  2332 solver.cpp:218] Iteration 62500 (22.2662 iter/s, 4.49112s/100 iters), loss = 0.110509
I0629 11:33:21.846822  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:33:21.846822  2332 solver.cpp:237]     Train net output #1: loss = 0.110509 (* 1 = 0.110509 loss)
I0629 11:33:21.846822  2332 sgd_solver.cpp:105] Iteration 62500, lr = 1e-05
I0629 11:33:25.486114  2332 solver.cpp:218] Iteration 62600 (27.4769 iter/s, 3.63943s/100 iters), loss = 0.163523
I0629 11:33:25.486114  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:33:25.486114  2332 solver.cpp:237]     Train net output #1: loss = 0.163523 (* 1 = 0.163523 loss)
I0629 11:33:25.486114  2332 sgd_solver.cpp:105] Iteration 62600, lr = 1e-05
I0629 11:33:29.125212  2332 solver.cpp:218] Iteration 62700 (27.4835 iter/s, 3.63854s/100 iters), loss = 0.0889612
I0629 11:33:29.125212  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:33:29.125212  2332 solver.cpp:237]     Train net output #1: loss = 0.0889612 (* 1 = 0.0889612 loss)
I0629 11:33:29.125212  2332 sgd_solver.cpp:105] Iteration 62700, lr = 1e-05
I0629 11:33:32.761373  2332 solver.cpp:218] Iteration 62800 (27.5002 iter/s, 3.63634s/100 iters), loss = 0.0964626
I0629 11:33:32.761373  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:33:32.761373  2332 solver.cpp:237]     Train net output #1: loss = 0.0964626 (* 1 = 0.0964626 loss)
I0629 11:33:32.761373  2332 sgd_solver.cpp:105] Iteration 62800, lr = 1e-05
I0629 11:33:36.398855  2332 solver.cpp:218] Iteration 62900 (27.4995 iter/s, 3.63643s/100 iters), loss = 0.0997442
I0629 11:33:36.398855  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:33:36.398855  2332 solver.cpp:237]     Train net output #1: loss = 0.0997442 (* 1 = 0.0997442 loss)
I0629 11:33:36.398855  2332 sgd_solver.cpp:105] Iteration 62900, lr = 1e-05
I0629 11:33:39.853448  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:33:39.994051  2332 solver.cpp:330] Iteration 63000, Testing net (#0)
I0629 11:33:39.994051  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:33:40.810492  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:33:40.841521  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8945
I0629 11:33:40.841521  2332 solver.cpp:397]     Test net output #1: loss = 0.355799 (* 1 = 0.355799 loss)
I0629 11:33:40.875193  2332 solver.cpp:218] Iteration 63000 (22.3382 iter/s, 4.47663s/100 iters), loss = 0.0912981
I0629 11:33:40.875193  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:33:40.875193  2332 solver.cpp:237]     Train net output #1: loss = 0.0912981 (* 1 = 0.0912981 loss)
I0629 11:33:40.875193  2332 sgd_solver.cpp:105] Iteration 63000, lr = 1e-05
I0629 11:33:44.499500  2332 solver.cpp:218] Iteration 63100 (27.5939 iter/s, 3.62398s/100 iters), loss = 0.136513
I0629 11:33:44.499500  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:33:44.499500  2332 solver.cpp:237]     Train net output #1: loss = 0.136513 (* 1 = 0.136513 loss)
I0629 11:33:44.499500  2332 sgd_solver.cpp:105] Iteration 63100, lr = 1e-05
I0629 11:33:48.114892  2332 solver.cpp:218] Iteration 63200 (27.6613 iter/s, 3.61516s/100 iters), loss = 0.0908733
I0629 11:33:48.115878  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:33:48.115878  2332 solver.cpp:237]     Train net output #1: loss = 0.0908733 (* 1 = 0.0908733 loss)
I0629 11:33:48.115878  2332 sgd_solver.cpp:105] Iteration 63200, lr = 1e-05
I0629 11:33:51.745872  2332 solver.cpp:218] Iteration 63300 (27.5508 iter/s, 3.62966s/100 iters), loss = 0.0852444
I0629 11:33:51.745872  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:33:51.745872  2332 solver.cpp:237]     Train net output #1: loss = 0.0852445 (* 1 = 0.0852445 loss)
I0629 11:33:51.745872  2332 sgd_solver.cpp:105] Iteration 63300, lr = 1e-05
I0629 11:33:55.382882  2332 solver.cpp:218] Iteration 63400 (27.4935 iter/s, 3.63722s/100 iters), loss = 0.0769807
I0629 11:33:55.382882  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:33:55.382882  2332 solver.cpp:237]     Train net output #1: loss = 0.0769806 (* 1 = 0.0769806 loss)
I0629 11:33:55.382882  2332 sgd_solver.cpp:105] Iteration 63400, lr = 1e-05
I0629 11:33:58.830687  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:33:58.971875  2332 solver.cpp:330] Iteration 63500, Testing net (#0)
I0629 11:33:58.971875  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:33:59.799029  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:33:59.822044  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8955
I0629 11:33:59.822044  2332 solver.cpp:397]     Test net output #1: loss = 0.3554 (* 1 = 0.3554 loss)
I0629 11:33:59.857098  2332 solver.cpp:218] Iteration 63500 (22.3549 iter/s, 4.4733s/100 iters), loss = 0.0705457
I0629 11:33:59.857098  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:33:59.857098  2332 solver.cpp:237]     Train net output #1: loss = 0.0705457 (* 1 = 0.0705457 loss)
I0629 11:33:59.857098  2332 sgd_solver.cpp:105] Iteration 63500, lr = 1e-05
I0629 11:34:03.501394  2332 solver.cpp:218] Iteration 63600 (27.443 iter/s, 3.64392s/100 iters), loss = 0.154369
I0629 11:34:03.501394  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:34:03.501394  2332 solver.cpp:237]     Train net output #1: loss = 0.154369 (* 1 = 0.154369 loss)
I0629 11:34:03.501394  2332 sgd_solver.cpp:105] Iteration 63600, lr = 1e-05
I0629 11:34:07.132918  2332 solver.cpp:218] Iteration 63700 (27.5346 iter/s, 3.6318s/100 iters), loss = 0.10709
I0629 11:34:07.132918  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:34:07.132918  2332 solver.cpp:237]     Train net output #1: loss = 0.10709 (* 1 = 0.10709 loss)
I0629 11:34:07.132918  2332 sgd_solver.cpp:105] Iteration 63700, lr = 1e-05
I0629 11:34:10.775773  2332 solver.cpp:218] Iteration 63800 (27.4585 iter/s, 3.64186s/100 iters), loss = 0.0889629
I0629 11:34:10.775773  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:34:10.775773  2332 solver.cpp:237]     Train net output #1: loss = 0.0889629 (* 1 = 0.0889629 loss)
I0629 11:34:10.775773  2332 sgd_solver.cpp:105] Iteration 63800, lr = 1e-05
I0629 11:34:14.415530  2332 solver.cpp:218] Iteration 63900 (27.4772 iter/s, 3.63939s/100 iters), loss = 0.091956
I0629 11:34:14.415530  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:34:14.415530  2332 solver.cpp:237]     Train net output #1: loss = 0.091956 (* 1 = 0.091956 loss)
I0629 11:34:14.415530  2332 sgd_solver.cpp:105] Iteration 63900, lr = 1e-05
I0629 11:34:17.867219  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:34:18.008325  2332 solver.cpp:330] Iteration 64000, Testing net (#0)
I0629 11:34:18.008325  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:34:18.828076  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:34:18.858101  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8954
I0629 11:34:18.858101  2332 solver.cpp:397]     Test net output #1: loss = 0.355729 (* 1 = 0.355729 loss)
I0629 11:34:18.893126  2332 solver.cpp:218] Iteration 64000 (22.3335 iter/s, 4.47759s/100 iters), loss = 0.0802304
I0629 11:34:18.893126  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:34:18.893126  2332 solver.cpp:237]     Train net output #1: loss = 0.0802304 (* 1 = 0.0802304 loss)
I0629 11:34:18.893126  2332 sgd_solver.cpp:105] Iteration 64000, lr = 1e-05
I0629 11:34:22.518893  2332 solver.cpp:218] Iteration 64100 (27.58 iter/s, 3.62582s/100 iters), loss = 0.148733
I0629 11:34:22.518893  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:34:22.518893  2332 solver.cpp:237]     Train net output #1: loss = 0.148733 (* 1 = 0.148733 loss)
I0629 11:34:22.518893  2332 sgd_solver.cpp:105] Iteration 64100, lr = 1e-05
I0629 11:34:26.148967  2332 solver.cpp:218] Iteration 64200 (27.555 iter/s, 3.62911s/100 iters), loss = 0.101735
I0629 11:34:26.148967  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:34:26.148967  2332 solver.cpp:237]     Train net output #1: loss = 0.101735 (* 1 = 0.101735 loss)
I0629 11:34:26.148967  2332 sgd_solver.cpp:105] Iteration 64200, lr = 1e-05
I0629 11:34:29.771689  2332 solver.cpp:218] Iteration 64300 (27.6054 iter/s, 3.62249s/100 iters), loss = 0.112117
I0629 11:34:29.771689  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:34:29.771689  2332 solver.cpp:237]     Train net output #1: loss = 0.112117 (* 1 = 0.112117 loss)
I0629 11:34:29.771689  2332 sgd_solver.cpp:105] Iteration 64300, lr = 1e-05
I0629 11:34:33.402477  2332 solver.cpp:218] Iteration 64400 (27.5436 iter/s, 3.63061s/100 iters), loss = 0.066186
I0629 11:34:33.402477  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:34:33.402477  2332 solver.cpp:237]     Train net output #1: loss = 0.0661861 (* 1 = 0.0661861 loss)
I0629 11:34:33.402477  2332 sgd_solver.cpp:105] Iteration 64400, lr = 1e-05
I0629 11:34:36.851245  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:34:36.991350  2332 solver.cpp:330] Iteration 64500, Testing net (#0)
I0629 11:34:36.992352  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:34:37.812067  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:34:37.843089  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8955
I0629 11:34:37.843089  2332 solver.cpp:397]     Test net output #1: loss = 0.355891 (* 1 = 0.355891 loss)
I0629 11:34:37.877116  2332 solver.cpp:218] Iteration 64500 (22.349 iter/s, 4.47448s/100 iters), loss = 0.102104
I0629 11:34:37.877116  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:34:37.877116  2332 solver.cpp:237]     Train net output #1: loss = 0.102104 (* 1 = 0.102104 loss)
I0629 11:34:37.877116  2332 sgd_solver.cpp:105] Iteration 64500, lr = 1e-05
I0629 11:34:41.501852  2332 solver.cpp:218] Iteration 64600 (27.5889 iter/s, 3.62465s/100 iters), loss = 0.154067
I0629 11:34:41.501852  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:34:41.501852  2332 solver.cpp:237]     Train net output #1: loss = 0.154067 (* 1 = 0.154067 loss)
I0629 11:34:41.501852  2332 sgd_solver.cpp:105] Iteration 64600, lr = 1e-05
I0629 11:34:45.123551  2332 solver.cpp:218] Iteration 64700 (27.6161 iter/s, 3.62108s/100 iters), loss = 0.142215
I0629 11:34:45.123551  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:34:45.123551  2332 solver.cpp:237]     Train net output #1: loss = 0.142215 (* 1 = 0.142215 loss)
I0629 11:34:45.123551  2332 sgd_solver.cpp:105] Iteration 64700, lr = 1e-05
I0629 11:34:48.747283  2332 solver.cpp:218] Iteration 64800 (27.5979 iter/s, 3.62347s/100 iters), loss = 0.117941
I0629 11:34:48.747283  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:34:48.747283  2332 solver.cpp:237]     Train net output #1: loss = 0.117941 (* 1 = 0.117941 loss)
I0629 11:34:48.747283  2332 sgd_solver.cpp:105] Iteration 64800, lr = 1e-05
I0629 11:34:52.366662  2332 solver.cpp:218] Iteration 64900 (27.6357 iter/s, 3.61851s/100 iters), loss = 0.0624227
I0629 11:34:52.366662  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:34:52.366662  2332 solver.cpp:237]     Train net output #1: loss = 0.0624226 (* 1 = 0.0624226 loss)
I0629 11:34:52.366662  2332 sgd_solver.cpp:105] Iteration 64900, lr = 1e-05
I0629 11:34:55.818572  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:34:55.959676  2332 solver.cpp:330] Iteration 65000, Testing net (#0)
I0629 11:34:55.959676  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:34:56.781805  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:34:56.812327  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8953
I0629 11:34:56.812327  2332 solver.cpp:397]     Test net output #1: loss = 0.35578 (* 1 = 0.35578 loss)
I0629 11:34:56.846351  2332 solver.cpp:218] Iteration 65000 (22.322 iter/s, 4.47988s/100 iters), loss = 0.0948361
I0629 11:34:56.846351  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:34:56.846351  2332 solver.cpp:237]     Train net output #1: loss = 0.094836 (* 1 = 0.094836 loss)
I0629 11:34:56.846351  2332 sgd_solver.cpp:105] Iteration 65000, lr = 1e-05
I0629 11:35:00.468993  2332 solver.cpp:218] Iteration 65100 (27.6097 iter/s, 3.62191s/100 iters), loss = 0.19718
I0629 11:35:00.468993  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:35:00.468993  2332 solver.cpp:237]     Train net output #1: loss = 0.19718 (* 1 = 0.19718 loss)
I0629 11:35:00.468993  2332 sgd_solver.cpp:105] Iteration 65100, lr = 1e-05
I0629 11:35:04.094805  2332 solver.cpp:218] Iteration 65200 (27.5824 iter/s, 3.6255s/100 iters), loss = 0.0888702
I0629 11:35:04.094805  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:35:04.094805  2332 solver.cpp:237]     Train net output #1: loss = 0.0888702 (* 1 = 0.0888702 loss)
I0629 11:35:04.094805  2332 sgd_solver.cpp:105] Iteration 65200, lr = 1e-05
I0629 11:35:07.709071  2332 solver.cpp:218] Iteration 65300 (27.6743 iter/s, 3.61346s/100 iters), loss = 0.0957963
I0629 11:35:07.709071  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:35:07.709071  2332 solver.cpp:237]     Train net output #1: loss = 0.0957963 (* 1 = 0.0957963 loss)
I0629 11:35:07.709071  2332 sgd_solver.cpp:105] Iteration 65300, lr = 1e-05
I0629 11:35:11.326901  2332 solver.cpp:218] Iteration 65400 (27.639 iter/s, 3.61808s/100 iters), loss = 0.0863326
I0629 11:35:11.326901  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:35:11.326901  2332 solver.cpp:237]     Train net output #1: loss = 0.0863326 (* 1 = 0.0863326 loss)
I0629 11:35:11.326901  2332 sgd_solver.cpp:105] Iteration 65400, lr = 1e-05
I0629 11:35:14.771634  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:35:14.914316  2332 solver.cpp:330] Iteration 65500, Testing net (#0)
I0629 11:35:14.914316  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:35:15.730427  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:35:15.761461  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8949
I0629 11:35:15.761461  2332 solver.cpp:397]     Test net output #1: loss = 0.356059 (* 1 = 0.356059 loss)
I0629 11:35:15.799489  2332 solver.cpp:218] Iteration 65500 (22.3587 iter/s, 4.47253s/100 iters), loss = 0.040243
I0629 11:35:15.799489  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:35:15.799489  2332 solver.cpp:237]     Train net output #1: loss = 0.040243 (* 1 = 0.040243 loss)
I0629 11:35:15.799489  2332 sgd_solver.cpp:105] Iteration 65500, lr = 1e-05
I0629 11:35:19.411301  2332 solver.cpp:218] Iteration 65600 (27.6951 iter/s, 3.61074s/100 iters), loss = 0.187978
I0629 11:35:19.411301  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:35:19.411301  2332 solver.cpp:237]     Train net output #1: loss = 0.187977 (* 1 = 0.187977 loss)
I0629 11:35:19.411301  2332 sgd_solver.cpp:105] Iteration 65600, lr = 1e-05
I0629 11:35:23.042955  2332 solver.cpp:218] Iteration 65700 (27.5327 iter/s, 3.63204s/100 iters), loss = 0.0830089
I0629 11:35:23.043944  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:35:23.043944  2332 solver.cpp:237]     Train net output #1: loss = 0.0830089 (* 1 = 0.0830089 loss)
I0629 11:35:23.043944  2332 sgd_solver.cpp:105] Iteration 65700, lr = 1e-05
I0629 11:35:26.662135  2332 solver.cpp:218] Iteration 65800 (27.6329 iter/s, 3.61887s/100 iters), loss = 0.0879957
I0629 11:35:26.663126  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:35:26.663126  2332 solver.cpp:237]     Train net output #1: loss = 0.0879956 (* 1 = 0.0879956 loss)
I0629 11:35:26.663126  2332 sgd_solver.cpp:105] Iteration 65800, lr = 1e-05
I0629 11:35:30.287925  2332 solver.cpp:218] Iteration 65900 (27.5844 iter/s, 3.62523s/100 iters), loss = 0.0894503
I0629 11:35:30.287925  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:35:30.287925  2332 solver.cpp:237]     Train net output #1: loss = 0.0894502 (* 1 = 0.0894502 loss)
I0629 11:35:30.287925  2332 sgd_solver.cpp:105] Iteration 65900, lr = 1e-05
I0629 11:35:33.729773  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:35:33.871881  2332 solver.cpp:330] Iteration 66000, Testing net (#0)
I0629 11:35:33.871881  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:35:34.688494  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:35:34.719524  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8936
I0629 11:35:34.719524  2332 solver.cpp:397]     Test net output #1: loss = 0.35557 (* 1 = 0.35557 loss)
I0629 11:35:34.753545  2332 solver.cpp:218] Iteration 66000 (22.3953 iter/s, 4.46523s/100 iters), loss = 0.0932508
I0629 11:35:34.753545  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:35:34.753545  2332 solver.cpp:237]     Train net output #1: loss = 0.0932507 (* 1 = 0.0932507 loss)
I0629 11:35:34.753545  2332 sgd_solver.cpp:105] Iteration 66000, lr = 1e-05
I0629 11:35:38.386410  2332 solver.cpp:218] Iteration 66100 (27.5345 iter/s, 3.63181s/100 iters), loss = 0.106266
I0629 11:35:38.386410  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:35:38.386410  2332 solver.cpp:237]     Train net output #1: loss = 0.106266 (* 1 = 0.106266 loss)
I0629 11:35:38.386410  2332 sgd_solver.cpp:105] Iteration 66100, lr = 1e-05
I0629 11:35:42.006913  2332 solver.cpp:218] Iteration 66200 (27.6215 iter/s, 3.62037s/100 iters), loss = 0.0586557
I0629 11:35:42.006913  2332 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0629 11:35:42.006913  2332 solver.cpp:237]     Train net output #1: loss = 0.0586556 (* 1 = 0.0586556 loss)
I0629 11:35:42.006913  2332 sgd_solver.cpp:105] Iteration 66200, lr = 1e-05
I0629 11:35:45.631705  2332 solver.cpp:218] Iteration 66300 (27.5897 iter/s, 3.62454s/100 iters), loss = 0.0539956
I0629 11:35:45.631705  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:35:45.631705  2332 solver.cpp:237]     Train net output #1: loss = 0.0539955 (* 1 = 0.0539955 loss)
I0629 11:35:45.631705  2332 sgd_solver.cpp:105] Iteration 66300, lr = 1e-05
I0629 11:35:49.258896  2332 solver.cpp:218] Iteration 66400 (27.5698 iter/s, 3.62715s/100 iters), loss = 0.106181
I0629 11:35:49.258896  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:35:49.258896  2332 solver.cpp:237]     Train net output #1: loss = 0.106181 (* 1 = 0.106181 loss)
I0629 11:35:49.258896  2332 sgd_solver.cpp:105] Iteration 66400, lr = 1e-05
I0629 11:35:52.709458  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:35:52.852064  2332 solver.cpp:330] Iteration 66500, Testing net (#0)
I0629 11:35:52.852064  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:35:53.673388  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:35:53.704411  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8937
I0629 11:35:53.704411  2332 solver.cpp:397]     Test net output #1: loss = 0.355393 (* 1 = 0.355393 loss)
I0629 11:35:53.739436  2332 solver.cpp:218] Iteration 66500 (22.3236 iter/s, 4.47957s/100 iters), loss = 0.0530238
I0629 11:35:53.739436  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:35:53.739436  2332 solver.cpp:237]     Train net output #1: loss = 0.0530238 (* 1 = 0.0530238 loss)
I0629 11:35:53.739436  2332 sgd_solver.cpp:105] Iteration 66500, lr = 1e-05
I0629 11:35:57.349273  2332 solver.cpp:218] Iteration 66600 (27.7034 iter/s, 3.60966s/100 iters), loss = 0.146373
I0629 11:35:57.349273  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:35:57.349273  2332 solver.cpp:237]     Train net output #1: loss = 0.146373 (* 1 = 0.146373 loss)
I0629 11:35:57.349273  2332 sgd_solver.cpp:105] Iteration 66600, lr = 1e-05
I0629 11:36:00.964987  2332 solver.cpp:218] Iteration 66700 (27.6575 iter/s, 3.61566s/100 iters), loss = 0.0886049
I0629 11:36:00.964987  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:36:00.964987  2332 solver.cpp:237]     Train net output #1: loss = 0.0886048 (* 1 = 0.0886048 loss)
I0629 11:36:00.964987  2332 sgd_solver.cpp:105] Iteration 66700, lr = 1e-05
I0629 11:36:04.594669  2332 solver.cpp:218] Iteration 66800 (27.5499 iter/s, 3.62978s/100 iters), loss = 0.111125
I0629 11:36:04.595655  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:36:04.595655  2332 solver.cpp:237]     Train net output #1: loss = 0.111125 (* 1 = 0.111125 loss)
I0629 11:36:04.595655  2332 sgd_solver.cpp:105] Iteration 66800, lr = 1e-05
I0629 11:36:08.232225  2332 solver.cpp:218] Iteration 66900 (27.5008 iter/s, 3.63626s/100 iters), loss = 0.100902
I0629 11:36:08.232225  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:36:08.232225  2332 solver.cpp:237]     Train net output #1: loss = 0.100902 (* 1 = 0.100902 loss)
I0629 11:36:08.232225  2332 sgd_solver.cpp:105] Iteration 66900, lr = 1e-05
I0629 11:36:11.673296  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:36:11.816401  2332 solver.cpp:330] Iteration 67000, Testing net (#0)
I0629 11:36:11.816401  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:36:12.642168  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:36:12.673192  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0629 11:36:12.673192  2332 solver.cpp:397]     Test net output #1: loss = 0.355414 (* 1 = 0.355414 loss)
I0629 11:36:12.707216  2332 solver.cpp:218] Iteration 67000 (22.3452 iter/s, 4.47523s/100 iters), loss = 0.0599125
I0629 11:36:12.707216  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:36:12.707216  2332 solver.cpp:237]     Train net output #1: loss = 0.0599125 (* 1 = 0.0599125 loss)
I0629 11:36:12.707216  2332 sgd_solver.cpp:105] Iteration 67000, lr = 1e-05
I0629 11:36:16.329959  2332 solver.cpp:218] Iteration 67100 (27.6029 iter/s, 3.6228s/100 iters), loss = 0.18393
I0629 11:36:16.330960  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:36:16.330960  2332 solver.cpp:237]     Train net output #1: loss = 0.18393 (* 1 = 0.18393 loss)
I0629 11:36:16.330960  2332 sgd_solver.cpp:105] Iteration 67100, lr = 1e-05
I0629 11:36:19.957183  2332 solver.cpp:218] Iteration 67200 (27.5784 iter/s, 3.62603s/100 iters), loss = 0.183509
I0629 11:36:19.957183  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:36:19.957183  2332 solver.cpp:237]     Train net output #1: loss = 0.183509 (* 1 = 0.183509 loss)
I0629 11:36:19.957183  2332 sgd_solver.cpp:105] Iteration 67200, lr = 1e-05
I0629 11:36:23.595063  2332 solver.cpp:218] Iteration 67300 (27.4865 iter/s, 3.63815s/100 iters), loss = 0.101754
I0629 11:36:23.595063  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:36:23.595063  2332 solver.cpp:237]     Train net output #1: loss = 0.101754 (* 1 = 0.101754 loss)
I0629 11:36:23.595063  2332 sgd_solver.cpp:105] Iteration 67300, lr = 1e-05
I0629 11:36:27.215922  2332 solver.cpp:218] Iteration 67400 (27.6224 iter/s, 3.62025s/100 iters), loss = 0.0557054
I0629 11:36:27.215922  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:36:27.215922  2332 solver.cpp:237]     Train net output #1: loss = 0.0557054 (* 1 = 0.0557054 loss)
I0629 11:36:27.215922  2332 sgd_solver.cpp:105] Iteration 67400, lr = 1e-05
I0629 11:36:30.663642  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:36:30.804747  2332 solver.cpp:330] Iteration 67500, Testing net (#0)
I0629 11:36:30.804747  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:36:31.629379  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:36:31.660907  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0629 11:36:31.660907  2332 solver.cpp:397]     Test net output #1: loss = 0.355945 (* 1 = 0.355945 loss)
I0629 11:36:31.695432  2332 solver.cpp:218] Iteration 67500 (22.3261 iter/s, 4.47907s/100 iters), loss = 0.071075
I0629 11:36:31.695432  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:36:31.695432  2332 solver.cpp:237]     Train net output #1: loss = 0.0710751 (* 1 = 0.0710751 loss)
I0629 11:36:31.695432  2332 sgd_solver.cpp:105] Iteration 67500, lr = 1e-05
I0629 11:36:35.325167  2332 solver.cpp:218] Iteration 67600 (27.5513 iter/s, 3.62959s/100 iters), loss = 0.170409
I0629 11:36:35.325167  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:36:35.325167  2332 solver.cpp:237]     Train net output #1: loss = 0.170409 (* 1 = 0.170409 loss)
I0629 11:36:35.325167  2332 sgd_solver.cpp:105] Iteration 67600, lr = 1e-05
I0629 11:36:38.953899  2332 solver.cpp:218] Iteration 67700 (27.5587 iter/s, 3.62862s/100 iters), loss = 0.115399
I0629 11:36:38.953899  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:36:38.953899  2332 solver.cpp:237]     Train net output #1: loss = 0.115399 (* 1 = 0.115399 loss)
I0629 11:36:38.953899  2332 sgd_solver.cpp:105] Iteration 67700, lr = 1e-05
I0629 11:36:42.582433  2332 solver.cpp:218] Iteration 67800 (27.5639 iter/s, 3.62794s/100 iters), loss = 0.126593
I0629 11:36:42.582433  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:36:42.582433  2332 solver.cpp:237]     Train net output #1: loss = 0.126593 (* 1 = 0.126593 loss)
I0629 11:36:42.582433  2332 sgd_solver.cpp:105] Iteration 67800, lr = 1e-05
I0629 11:36:46.227376  2332 solver.cpp:218] Iteration 67900 (27.4365 iter/s, 3.64478s/100 iters), loss = 0.0647318
I0629 11:36:46.227376  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:36:46.227376  2332 solver.cpp:237]     Train net output #1: loss = 0.0647318 (* 1 = 0.0647318 loss)
I0629 11:36:46.227376  2332 sgd_solver.cpp:105] Iteration 67900, lr = 1e-05
I0629 11:36:49.674005  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:36:49.816112  2332 solver.cpp:330] Iteration 68000, Testing net (#0)
I0629 11:36:49.816112  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:36:50.636721  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:36:50.667742  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8947
I0629 11:36:50.667742  2332 solver.cpp:397]     Test net output #1: loss = 0.355538 (* 1 = 0.355538 loss)
I0629 11:36:50.702317  2332 solver.cpp:218] Iteration 68000 (22.3476 iter/s, 4.47475s/100 iters), loss = 0.0358664
I0629 11:36:50.702317  2332 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0629 11:36:50.702317  2332 solver.cpp:237]     Train net output #1: loss = 0.0358664 (* 1 = 0.0358664 loss)
I0629 11:36:50.702317  2332 sgd_solver.cpp:105] Iteration 68000, lr = 1e-05
I0629 11:36:54.337749  2332 solver.cpp:218] Iteration 68100 (27.5094 iter/s, 3.63512s/100 iters), loss = 0.113865
I0629 11:36:54.337749  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:36:54.337749  2332 solver.cpp:237]     Train net output #1: loss = 0.113865 (* 1 = 0.113865 loss)
I0629 11:36:54.337749  2332 sgd_solver.cpp:105] Iteration 68100, lr = 1e-05
I0629 11:36:57.962529  2332 solver.cpp:218] Iteration 68200 (27.5964 iter/s, 3.62366s/100 iters), loss = 0.0781707
I0629 11:36:57.962529  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:36:57.962529  2332 solver.cpp:237]     Train net output #1: loss = 0.0781707 (* 1 = 0.0781707 loss)
I0629 11:36:57.962529  2332 sgd_solver.cpp:105] Iteration 68200, lr = 1e-05
I0629 11:37:01.584064  2332 solver.cpp:218] Iteration 68300 (27.6125 iter/s, 3.62155s/100 iters), loss = 0.0816114
I0629 11:37:01.584064  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:37:01.584564  2332 solver.cpp:237]     Train net output #1: loss = 0.0816114 (* 1 = 0.0816114 loss)
I0629 11:37:01.584564  2332 sgd_solver.cpp:105] Iteration 68300, lr = 1e-05
I0629 11:37:05.201439  2332 solver.cpp:218] Iteration 68400 (27.65 iter/s, 3.61664s/100 iters), loss = 0.051797
I0629 11:37:05.201439  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:37:05.201439  2332 solver.cpp:237]     Train net output #1: loss = 0.051797 (* 1 = 0.051797 loss)
I0629 11:37:05.201439  2332 sgd_solver.cpp:105] Iteration 68400, lr = 1e-05
I0629 11:37:08.645586  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:37:08.787369  2332 solver.cpp:330] Iteration 68500, Testing net (#0)
I0629 11:37:08.787369  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:37:09.604315  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:37:09.635336  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8953
I0629 11:37:09.635336  2332 solver.cpp:397]     Test net output #1: loss = 0.355695 (* 1 = 0.355695 loss)
I0629 11:37:09.669373  2332 solver.cpp:218] Iteration 68500 (22.3834 iter/s, 4.4676s/100 iters), loss = 0.121028
I0629 11:37:09.669373  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:37:09.669373  2332 solver.cpp:237]     Train net output #1: loss = 0.121028 (* 1 = 0.121028 loss)
I0629 11:37:09.669373  2332 sgd_solver.cpp:105] Iteration 68500, lr = 1e-05
I0629 11:37:13.280692  2332 solver.cpp:218] Iteration 68600 (27.6858 iter/s, 3.61196s/100 iters), loss = 0.124305
I0629 11:37:13.281692  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:37:13.281692  2332 solver.cpp:237]     Train net output #1: loss = 0.124305 (* 1 = 0.124305 loss)
I0629 11:37:13.281692  2332 sgd_solver.cpp:105] Iteration 68600, lr = 1e-05
I0629 11:37:16.894176  2332 solver.cpp:218] Iteration 68700 (27.6781 iter/s, 3.61296s/100 iters), loss = 0.101266
I0629 11:37:16.894176  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:37:16.894176  2332 solver.cpp:237]     Train net output #1: loss = 0.101266 (* 1 = 0.101266 loss)
I0629 11:37:16.894176  2332 sgd_solver.cpp:105] Iteration 68700, lr = 1e-05
I0629 11:37:20.508190  2332 solver.cpp:218] Iteration 68800 (27.6734 iter/s, 3.61358s/100 iters), loss = 0.0639812
I0629 11:37:20.508190  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:37:20.508190  2332 solver.cpp:237]     Train net output #1: loss = 0.0639811 (* 1 = 0.0639811 loss)
I0629 11:37:20.508190  2332 sgd_solver.cpp:105] Iteration 68800, lr = 1e-05
I0629 11:37:24.130368  2332 solver.cpp:218] Iteration 68900 (27.6137 iter/s, 3.62139s/100 iters), loss = 0.0519612
I0629 11:37:24.130368  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:37:24.130368  2332 solver.cpp:237]     Train net output #1: loss = 0.0519612 (* 1 = 0.0519612 loss)
I0629 11:37:24.130368  2332 sgd_solver.cpp:105] Iteration 68900, lr = 1e-05
I0629 11:37:27.571569  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:37:27.713606  2332 solver.cpp:330] Iteration 69000, Testing net (#0)
I0629 11:37:27.713606  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:37:28.530254  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:37:28.561266  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8954
I0629 11:37:28.561266  2332 solver.cpp:397]     Test net output #1: loss = 0.355755 (* 1 = 0.355755 loss)
I0629 11:37:28.595789  2332 solver.cpp:218] Iteration 69000 (22.3951 iter/s, 4.46527s/100 iters), loss = 0.0825552
I0629 11:37:28.595789  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:37:28.595789  2332 solver.cpp:237]     Train net output #1: loss = 0.0825552 (* 1 = 0.0825552 loss)
I0629 11:37:28.595789  2332 sgd_solver.cpp:105] Iteration 69000, lr = 1e-05
I0629 11:37:32.219666  2332 solver.cpp:218] Iteration 69100 (27.595 iter/s, 3.62385s/100 iters), loss = 0.123261
I0629 11:37:32.219666  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:37:32.219666  2332 solver.cpp:237]     Train net output #1: loss = 0.123261 (* 1 = 0.123261 loss)
I0629 11:37:32.219666  2332 sgd_solver.cpp:105] Iteration 69100, lr = 1e-05
I0629 11:37:35.837787  2332 solver.cpp:218] Iteration 69200 (27.6458 iter/s, 3.61718s/100 iters), loss = 0.123649
I0629 11:37:35.837787  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:37:35.837787  2332 solver.cpp:237]     Train net output #1: loss = 0.123649 (* 1 = 0.123649 loss)
I0629 11:37:35.837787  2332 sgd_solver.cpp:105] Iteration 69200, lr = 1e-05
I0629 11:37:39.471539  2332 solver.cpp:218] Iteration 69300 (27.5177 iter/s, 3.63403s/100 iters), loss = 0.0798632
I0629 11:37:39.471539  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:37:39.471539  2332 solver.cpp:237]     Train net output #1: loss = 0.0798632 (* 1 = 0.0798632 loss)
I0629 11:37:39.471539  2332 sgd_solver.cpp:105] Iteration 69300, lr = 1e-05
I0629 11:37:43.095386  2332 solver.cpp:218] Iteration 69400 (27.6003 iter/s, 3.62315s/100 iters), loss = 0.0941083
I0629 11:37:43.095386  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:37:43.095386  2332 solver.cpp:237]     Train net output #1: loss = 0.0941084 (* 1 = 0.0941084 loss)
I0629 11:37:43.095386  2332 sgd_solver.cpp:105] Iteration 69400, lr = 1e-05
I0629 11:37:46.546005  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:37:46.688113  2332 solver.cpp:330] Iteration 69500, Testing net (#0)
I0629 11:37:46.688113  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:37:47.505487  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:37:47.536519  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0629 11:37:47.536519  2332 solver.cpp:397]     Test net output #1: loss = 0.356219 (* 1 = 0.356219 loss)
I0629 11:37:47.570535  2332 solver.cpp:218] Iteration 69500 (22.3453 iter/s, 4.47521s/100 iters), loss = 0.0783899
I0629 11:37:47.570535  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:37:47.570535  2332 solver.cpp:237]     Train net output #1: loss = 0.07839 (* 1 = 0.07839 loss)
I0629 11:37:47.570535  2332 sgd_solver.cpp:105] Iteration 69500, lr = 1e-05
I0629 11:37:51.201344  2332 solver.cpp:218] Iteration 69600 (27.5475 iter/s, 3.6301s/100 iters), loss = 0.0894114
I0629 11:37:51.201344  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:37:51.201344  2332 solver.cpp:237]     Train net output #1: loss = 0.0894114 (* 1 = 0.0894114 loss)
I0629 11:37:51.201344  2332 sgd_solver.cpp:105] Iteration 69600, lr = 1e-05
I0629 11:37:54.835151  2332 solver.cpp:218] Iteration 69700 (27.5241 iter/s, 3.63317s/100 iters), loss = 0.13061
I0629 11:37:54.835151  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:37:54.835151  2332 solver.cpp:237]     Train net output #1: loss = 0.13061 (* 1 = 0.13061 loss)
I0629 11:37:54.835151  2332 sgd_solver.cpp:105] Iteration 69700, lr = 1e-05
I0629 11:37:58.454936  2332 solver.cpp:218] Iteration 69800 (27.6276 iter/s, 3.61957s/100 iters), loss = 0.0849646
I0629 11:37:58.454936  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:37:58.454936  2332 solver.cpp:237]     Train net output #1: loss = 0.0849646 (* 1 = 0.0849646 loss)
I0629 11:37:58.454936  2332 sgd_solver.cpp:105] Iteration 69800, lr = 1e-05
I0629 11:38:02.088881  2332 solver.cpp:218] Iteration 69900 (27.5165 iter/s, 3.63419s/100 iters), loss = 0.0733083
I0629 11:38:02.088881  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:38:02.088881  2332 solver.cpp:237]     Train net output #1: loss = 0.0733083 (* 1 = 0.0733083 loss)
I0629 11:38:02.088881  2332 sgd_solver.cpp:105] Iteration 69900, lr = 1e-05
I0629 11:38:05.539625  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:38:05.681731  2332 solver.cpp:330] Iteration 70000, Testing net (#0)
I0629 11:38:05.681731  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:38:06.498386  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:38:06.529408  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I0629 11:38:06.529408  2332 solver.cpp:397]     Test net output #1: loss = 0.355781 (* 1 = 0.355781 loss)
I0629 11:38:06.563432  2332 solver.cpp:218] Iteration 70000 (22.351 iter/s, 4.47408s/100 iters), loss = 0.0951739
I0629 11:38:06.563432  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:38:06.563432  2332 solver.cpp:237]     Train net output #1: loss = 0.0951739 (* 1 = 0.0951739 loss)
I0629 11:38:06.563432  2332 sgd_solver.cpp:105] Iteration 70000, lr = 1e-05
I0629 11:38:10.189249  2332 solver.cpp:218] Iteration 70100 (27.5874 iter/s, 3.62484s/100 iters), loss = 0.114672
I0629 11:38:10.189249  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:38:10.189249  2332 solver.cpp:237]     Train net output #1: loss = 0.114672 (* 1 = 0.114672 loss)
I0629 11:38:10.189249  2332 sgd_solver.cpp:105] Iteration 70100, lr = 1e-05
I0629 11:38:13.810870  2332 solver.cpp:218] Iteration 70200 (27.6113 iter/s, 3.6217s/100 iters), loss = 0.0912341
I0629 11:38:13.810870  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:38:13.810870  2332 solver.cpp:237]     Train net output #1: loss = 0.0912341 (* 1 = 0.0912341 loss)
I0629 11:38:13.810870  2332 sgd_solver.cpp:105] Iteration 70200, lr = 1e-05
I0629 11:38:17.447412  2332 solver.cpp:218] Iteration 70300 (27.5014 iter/s, 3.63617s/100 iters), loss = 0.11703
I0629 11:38:17.447412  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:38:17.447412  2332 solver.cpp:237]     Train net output #1: loss = 0.11703 (* 1 = 0.11703 loss)
I0629 11:38:17.447412  2332 sgd_solver.cpp:105] Iteration 70300, lr = 1e-05
I0629 11:38:21.064805  2332 solver.cpp:218] Iteration 70400 (27.6484 iter/s, 3.61684s/100 iters), loss = 0.0677423
I0629 11:38:21.064805  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:38:21.064805  2332 solver.cpp:237]     Train net output #1: loss = 0.0677423 (* 1 = 0.0677423 loss)
I0629 11:38:21.064805  2332 sgd_solver.cpp:105] Iteration 70400, lr = 1e-05
I0629 11:38:24.524391  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:38:24.671499  2332 solver.cpp:330] Iteration 70500, Testing net (#0)
I0629 11:38:24.671499  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:38:25.499996  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:38:25.531018  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8956
I0629 11:38:25.531018  2332 solver.cpp:397]     Test net output #1: loss = 0.355931 (* 1 = 0.355931 loss)
I0629 11:38:25.566043  2332 solver.cpp:218] Iteration 70500 (22.2191 iter/s, 4.50063s/100 iters), loss = 0.0507119
I0629 11:38:25.566043  2332 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0629 11:38:25.566043  2332 solver.cpp:237]     Train net output #1: loss = 0.0507119 (* 1 = 0.0507119 loss)
I0629 11:38:25.566043  2332 sgd_solver.cpp:105] Iteration 70500, lr = 1e-05
I0629 11:38:29.182677  2332 solver.cpp:218] Iteration 70600 (27.6496 iter/s, 3.61669s/100 iters), loss = 0.100457
I0629 11:38:29.182677  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:38:29.182677  2332 solver.cpp:237]     Train net output #1: loss = 0.100457 (* 1 = 0.100457 loss)
I0629 11:38:29.182677  2332 sgd_solver.cpp:105] Iteration 70600, lr = 1e-05
I0629 11:38:32.804100  2332 solver.cpp:218] Iteration 70700 (27.6191 iter/s, 3.62069s/100 iters), loss = 0.0797822
I0629 11:38:32.804100  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:38:32.804100  2332 solver.cpp:237]     Train net output #1: loss = 0.0797821 (* 1 = 0.0797821 loss)
I0629 11:38:32.804100  2332 sgd_solver.cpp:105] Iteration 70700, lr = 1e-05
I0629 11:38:36.430829  2332 solver.cpp:218] Iteration 70800 (27.5748 iter/s, 3.6265s/100 iters), loss = 0.135459
I0629 11:38:36.430829  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:38:36.430829  2332 solver.cpp:237]     Train net output #1: loss = 0.135459 (* 1 = 0.135459 loss)
I0629 11:38:36.430829  2332 sgd_solver.cpp:105] Iteration 70800, lr = 1e-05
I0629 11:38:40.064843  2332 solver.cpp:218] Iteration 70900 (27.5141 iter/s, 3.6345s/100 iters), loss = 0.0872197
I0629 11:38:40.065845  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:38:40.065845  2332 solver.cpp:237]     Train net output #1: loss = 0.0872197 (* 1 = 0.0872197 loss)
I0629 11:38:40.065845  2332 sgd_solver.cpp:105] Iteration 70900, lr = 1e-05
I0629 11:38:43.510418  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:38:43.652524  2332 solver.cpp:330] Iteration 71000, Testing net (#0)
I0629 11:38:43.652524  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:38:44.467917  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:38:44.498939  2332 solver.cpp:397]     Test net output #0: accuracy = 0.895
I0629 11:38:44.498939  2332 solver.cpp:397]     Test net output #1: loss = 0.355732 (* 1 = 0.355732 loss)
I0629 11:38:44.533965  2332 solver.cpp:218] Iteration 71000 (22.3811 iter/s, 4.46806s/100 iters), loss = 0.0974565
I0629 11:38:44.533965  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:38:44.533965  2332 solver.cpp:237]     Train net output #1: loss = 0.0974565 (* 1 = 0.0974565 loss)
I0629 11:38:44.533965  2332 sgd_solver.cpp:105] Iteration 71000, lr = 1e-05
I0629 11:38:48.164712  2332 solver.cpp:218] Iteration 71100 (27.5402 iter/s, 3.63106s/100 iters), loss = 0.131062
I0629 11:38:48.165714  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:38:48.165714  2332 solver.cpp:237]     Train net output #1: loss = 0.131062 (* 1 = 0.131062 loss)
I0629 11:38:48.165714  2332 sgd_solver.cpp:105] Iteration 71100, lr = 1e-05
I0629 11:38:51.787710  2332 solver.cpp:218] Iteration 71200 (27.6046 iter/s, 3.62258s/100 iters), loss = 0.0969514
I0629 11:38:51.787710  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:38:51.788710  2332 solver.cpp:237]     Train net output #1: loss = 0.0969514 (* 1 = 0.0969514 loss)
I0629 11:38:51.788710  2332 sgd_solver.cpp:105] Iteration 71200, lr = 1e-05
I0629 11:38:55.407169  2332 solver.cpp:218] Iteration 71300 (27.638 iter/s, 3.61821s/100 iters), loss = 0.0944891
I0629 11:38:55.407169  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:38:55.407169  2332 solver.cpp:237]     Train net output #1: loss = 0.0944891 (* 1 = 0.0944891 loss)
I0629 11:38:55.407169  2332 sgd_solver.cpp:105] Iteration 71300, lr = 1e-05
I0629 11:38:59.023756  2332 solver.cpp:218] Iteration 71400 (27.6527 iter/s, 3.61629s/100 iters), loss = 0.126809
I0629 11:38:59.023756  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:38:59.023756  2332 solver.cpp:237]     Train net output #1: loss = 0.126809 (* 1 = 0.126809 loss)
I0629 11:38:59.023756  2332 sgd_solver.cpp:105] Iteration 71400, lr = 1e-05
I0629 11:39:02.488652  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:39:02.629775  2332 solver.cpp:330] Iteration 71500, Testing net (#0)
I0629 11:39:02.629775  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:39:03.451885  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:39:03.482533  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8945
I0629 11:39:03.482533  2332 solver.cpp:397]     Test net output #1: loss = 0.356357 (* 1 = 0.356357 loss)
I0629 11:39:03.516556  2332 solver.cpp:218] Iteration 71500 (22.2565 iter/s, 4.49308s/100 iters), loss = 0.0906543
I0629 11:39:03.516556  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:39:03.516556  2332 solver.cpp:237]     Train net output #1: loss = 0.0906543 (* 1 = 0.0906543 loss)
I0629 11:39:03.516556  2332 sgd_solver.cpp:105] Iteration 71500, lr = 1e-05
I0629 11:39:07.156461  2332 solver.cpp:218] Iteration 71600 (27.4806 iter/s, 3.63892s/100 iters), loss = 0.163123
I0629 11:39:07.156461  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:39:07.156461  2332 solver.cpp:237]     Train net output #1: loss = 0.163123 (* 1 = 0.163123 loss)
I0629 11:39:07.156461  2332 sgd_solver.cpp:105] Iteration 71600, lr = 1e-05
I0629 11:39:10.784121  2332 solver.cpp:218] Iteration 71700 (27.5638 iter/s, 3.62795s/100 iters), loss = 0.111923
I0629 11:39:10.784121  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:39:10.784121  2332 solver.cpp:237]     Train net output #1: loss = 0.111923 (* 1 = 0.111923 loss)
I0629 11:39:10.784121  2332 sgd_solver.cpp:105] Iteration 71700, lr = 1e-05
I0629 11:39:14.407443  2332 solver.cpp:218] Iteration 71800 (27.6025 iter/s, 3.62286s/100 iters), loss = 0.100977
I0629 11:39:14.407443  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:39:14.407443  2332 solver.cpp:237]     Train net output #1: loss = 0.100977 (* 1 = 0.100977 loss)
I0629 11:39:14.407443  2332 sgd_solver.cpp:105] Iteration 71800, lr = 1e-05
I0629 11:39:18.025799  2332 solver.cpp:218] Iteration 71900 (27.6451 iter/s, 3.61728s/100 iters), loss = 0.0631621
I0629 11:39:18.025799  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:39:18.025799  2332 solver.cpp:237]     Train net output #1: loss = 0.0631621 (* 1 = 0.0631621 loss)
I0629 11:39:18.025799  2332 sgd_solver.cpp:105] Iteration 71900, lr = 1e-05
I0629 11:39:21.479751  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:39:21.621202  2332 solver.cpp:330] Iteration 72000, Testing net (#0)
I0629 11:39:21.621202  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:39:22.447402  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:39:22.478937  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8948
I0629 11:39:22.478937  2332 solver.cpp:397]     Test net output #1: loss = 0.355966 (* 1 = 0.355966 loss)
I0629 11:39:22.512464  2332 solver.cpp:218] Iteration 72000 (22.2863 iter/s, 4.48707s/100 iters), loss = 0.0965901
I0629 11:39:22.512464  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:39:22.512464  2332 solver.cpp:237]     Train net output #1: loss = 0.09659 (* 1 = 0.09659 loss)
I0629 11:39:22.512464  2332 sgd_solver.cpp:105] Iteration 72000, lr = 1e-05
I0629 11:39:26.153301  2332 solver.cpp:218] Iteration 72100 (27.4709 iter/s, 3.64022s/100 iters), loss = 0.116349
I0629 11:39:26.153301  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:39:26.153301  2332 solver.cpp:237]     Train net output #1: loss = 0.11635 (* 1 = 0.11635 loss)
I0629 11:39:26.153301  2332 sgd_solver.cpp:105] Iteration 72100, lr = 1e-05
I0629 11:39:29.769639  2332 solver.cpp:218] Iteration 72200 (27.6539 iter/s, 3.61613s/100 iters), loss = 0.109009
I0629 11:39:29.769639  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:39:29.769639  2332 solver.cpp:237]     Train net output #1: loss = 0.109009 (* 1 = 0.109009 loss)
I0629 11:39:29.769639  2332 sgd_solver.cpp:105] Iteration 72200, lr = 1e-05
I0629 11:39:33.393762  2332 solver.cpp:218] Iteration 72300 (27.5993 iter/s, 3.62328s/100 iters), loss = 0.0815148
I0629 11:39:33.393762  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:39:33.393762  2332 solver.cpp:237]     Train net output #1: loss = 0.0815149 (* 1 = 0.0815149 loss)
I0629 11:39:33.393762  2332 sgd_solver.cpp:105] Iteration 72300, lr = 1e-05
I0629 11:39:37.011452  2332 solver.cpp:218] Iteration 72400 (27.6418 iter/s, 3.61771s/100 iters), loss = 0.122731
I0629 11:39:37.011452  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:39:37.011452  2332 solver.cpp:237]     Train net output #1: loss = 0.122731 (* 1 = 0.122731 loss)
I0629 11:39:37.011452  2332 sgd_solver.cpp:105] Iteration 72400, lr = 1e-05
I0629 11:39:40.455633  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:39:40.596824  2332 solver.cpp:330] Iteration 72500, Testing net (#0)
I0629 11:39:40.596824  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:39:41.413941  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:39:41.444958  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8944
I0629 11:39:41.445963  2332 solver.cpp:397]     Test net output #1: loss = 0.355959 (* 1 = 0.355959 loss)
I0629 11:39:41.479982  2332 solver.cpp:218] Iteration 72500 (22.3822 iter/s, 4.46784s/100 iters), loss = 0.0585289
I0629 11:39:41.479982  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:39:41.479982  2332 solver.cpp:237]     Train net output #1: loss = 0.0585289 (* 1 = 0.0585289 loss)
I0629 11:39:41.479982  2332 sgd_solver.cpp:105] Iteration 72500, lr = 1e-05
I0629 11:39:45.096456  2332 solver.cpp:218] Iteration 72600 (27.6525 iter/s, 3.61631s/100 iters), loss = 0.154228
I0629 11:39:45.096456  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:39:45.096456  2332 solver.cpp:237]     Train net output #1: loss = 0.154228 (* 1 = 0.154228 loss)
I0629 11:39:45.096456  2332 sgd_solver.cpp:105] Iteration 72600, lr = 1e-05
I0629 11:39:48.721889  2332 solver.cpp:218] Iteration 72700 (27.5815 iter/s, 3.62562s/100 iters), loss = 0.0730707
I0629 11:39:48.721889  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:39:48.721889  2332 solver.cpp:237]     Train net output #1: loss = 0.0730707 (* 1 = 0.0730707 loss)
I0629 11:39:48.721889  2332 sgd_solver.cpp:105] Iteration 72700, lr = 1e-05
I0629 11:39:52.345633  2332 solver.cpp:218] Iteration 72800 (27.6015 iter/s, 3.62299s/100 iters), loss = 0.0796784
I0629 11:39:52.345633  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:39:52.345633  2332 solver.cpp:237]     Train net output #1: loss = 0.0796784 (* 1 = 0.0796784 loss)
I0629 11:39:52.345633  2332 sgd_solver.cpp:105] Iteration 72800, lr = 1e-05
I0629 11:39:55.977768  2332 solver.cpp:218] Iteration 72900 (27.5328 iter/s, 3.63203s/100 iters), loss = 0.126138
I0629 11:39:55.977768  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:39:55.977768  2332 solver.cpp:237]     Train net output #1: loss = 0.126138 (* 1 = 0.126138 loss)
I0629 11:39:55.977768  2332 sgd_solver.cpp:105] Iteration 72900, lr = 1e-05
I0629 11:39:59.427695  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:39:59.570552  2332 solver.cpp:330] Iteration 73000, Testing net (#0)
I0629 11:39:59.570552  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:40:00.389683  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:40:00.421224  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0629 11:40:00.421224  2332 solver.cpp:397]     Test net output #1: loss = 0.355643 (* 1 = 0.355643 loss)
I0629 11:40:00.458243  2332 solver.cpp:218] Iteration 73000 (22.3241 iter/s, 4.47946s/100 iters), loss = 0.0639253
I0629 11:40:00.458243  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:40:00.458243  2332 solver.cpp:237]     Train net output #1: loss = 0.0639253 (* 1 = 0.0639253 loss)
I0629 11:40:00.458243  2332 sgd_solver.cpp:105] Iteration 73000, lr = 1e-05
I0629 11:40:04.092890  2332 solver.cpp:218] Iteration 73100 (27.5097 iter/s, 3.63508s/100 iters), loss = 0.143595
I0629 11:40:04.092890  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:40:04.092890  2332 solver.cpp:237]     Train net output #1: loss = 0.143595 (* 1 = 0.143595 loss)
I0629 11:40:04.092890  2332 sgd_solver.cpp:105] Iteration 73100, lr = 1e-05
I0629 11:40:07.730324  2332 solver.cpp:218] Iteration 73200 (27.4954 iter/s, 3.63698s/100 iters), loss = 0.127009
I0629 11:40:07.730324  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:40:07.730324  2332 solver.cpp:237]     Train net output #1: loss = 0.127009 (* 1 = 0.127009 loss)
I0629 11:40:07.730324  2332 sgd_solver.cpp:105] Iteration 73200, lr = 1e-05
I0629 11:40:11.353093  2332 solver.cpp:218] Iteration 73300 (27.6041 iter/s, 3.62264s/100 iters), loss = 0.0627047
I0629 11:40:11.354095  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:40:11.354095  2332 solver.cpp:237]     Train net output #1: loss = 0.0627047 (* 1 = 0.0627047 loss)
I0629 11:40:11.354095  2332 sgd_solver.cpp:105] Iteration 73300, lr = 1e-05
I0629 11:40:14.976478  2332 solver.cpp:218] Iteration 73400 (27.6053 iter/s, 3.6225s/100 iters), loss = 0.0848325
I0629 11:40:14.976478  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:40:14.976478  2332 solver.cpp:237]     Train net output #1: loss = 0.0848326 (* 1 = 0.0848326 loss)
I0629 11:40:14.976478  2332 sgd_solver.cpp:105] Iteration 73400, lr = 1e-05
I0629 11:40:18.427206  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:40:18.568269  2332 solver.cpp:330] Iteration 73500, Testing net (#0)
I0629 11:40:18.568269  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:40:19.387861  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:40:19.418884  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8941
I0629 11:40:19.418884  2332 solver.cpp:397]     Test net output #1: loss = 0.355947 (* 1 = 0.355947 loss)
I0629 11:40:19.452515  2332 solver.cpp:218] Iteration 73500 (22.3418 iter/s, 4.47591s/100 iters), loss = 0.0557968
I0629 11:40:19.452515  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:40:19.452515  2332 solver.cpp:237]     Train net output #1: loss = 0.0557968 (* 1 = 0.0557968 loss)
I0629 11:40:19.452515  2332 sgd_solver.cpp:105] Iteration 73500, lr = 1e-05
I0629 11:40:23.086103  2332 solver.cpp:218] Iteration 73600 (27.5265 iter/s, 3.63286s/100 iters), loss = 0.151612
I0629 11:40:23.086103  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:40:23.086103  2332 solver.cpp:237]     Train net output #1: loss = 0.151612 (* 1 = 0.151612 loss)
I0629 11:40:23.086103  2332 sgd_solver.cpp:105] Iteration 73600, lr = 1e-05
I0629 11:40:26.709805  2332 solver.cpp:218] Iteration 73700 (27.5964 iter/s, 3.62366s/100 iters), loss = 0.0879809
I0629 11:40:26.709805  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:40:26.709805  2332 solver.cpp:237]     Train net output #1: loss = 0.0879809 (* 1 = 0.0879809 loss)
I0629 11:40:26.709805  2332 sgd_solver.cpp:105] Iteration 73700, lr = 1e-05
I0629 11:40:30.335016  2332 solver.cpp:218] Iteration 73800 (27.5906 iter/s, 3.62442s/100 iters), loss = 0.0862648
I0629 11:40:30.335016  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:40:30.335016  2332 solver.cpp:237]     Train net output #1: loss = 0.0862648 (* 1 = 0.0862648 loss)
I0629 11:40:30.335016  2332 sgd_solver.cpp:105] Iteration 73800, lr = 1e-05
I0629 11:40:33.968098  2332 solver.cpp:218] Iteration 73900 (27.5233 iter/s, 3.63329s/100 iters), loss = 0.120511
I0629 11:40:33.968098  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:40:33.968098  2332 solver.cpp:237]     Train net output #1: loss = 0.120511 (* 1 = 0.120511 loss)
I0629 11:40:33.968098  2332 sgd_solver.cpp:105] Iteration 73900, lr = 1e-05
I0629 11:40:37.423588  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:40:37.564695  2332 solver.cpp:330] Iteration 74000, Testing net (#0)
I0629 11:40:37.564695  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:40:38.385505  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:40:38.415526  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I0629 11:40:38.415526  2332 solver.cpp:397]     Test net output #1: loss = 0.355954 (* 1 = 0.355954 loss)
I0629 11:40:38.450552  2332 solver.cpp:218] Iteration 74000 (22.3139 iter/s, 4.48151s/100 iters), loss = 0.0614208
I0629 11:40:38.450552  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:40:38.450552  2332 solver.cpp:237]     Train net output #1: loss = 0.0614208 (* 1 = 0.0614208 loss)
I0629 11:40:38.450552  2332 sgd_solver.cpp:46] MultiStep Status: Iteration 74000, step = 4
I0629 11:40:38.450552  2332 sgd_solver.cpp:105] Iteration 74000, lr = 1e-06
I0629 11:40:42.074398  2332 solver.cpp:218] Iteration 74100 (27.5955 iter/s, 3.62378s/100 iters), loss = 0.0927811
I0629 11:40:42.074398  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:40:42.074398  2332 solver.cpp:237]     Train net output #1: loss = 0.0927811 (* 1 = 0.0927811 loss)
I0629 11:40:42.074398  2332 sgd_solver.cpp:105] Iteration 74100, lr = 1e-06
I0629 11:40:45.698118  2332 solver.cpp:218] Iteration 74200 (27.5965 iter/s, 3.62364s/100 iters), loss = 0.116322
I0629 11:40:45.698118  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:40:45.698118  2332 solver.cpp:237]     Train net output #1: loss = 0.116322 (* 1 = 0.116322 loss)
I0629 11:40:45.698118  2332 sgd_solver.cpp:105] Iteration 74200, lr = 1e-06
I0629 11:40:49.321946  2332 solver.cpp:218] Iteration 74300 (27.6001 iter/s, 3.62318s/100 iters), loss = 0.0786388
I0629 11:40:49.321946  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:40:49.321946  2332 solver.cpp:237]     Train net output #1: loss = 0.0786387 (* 1 = 0.0786387 loss)
I0629 11:40:49.321946  2332 sgd_solver.cpp:105] Iteration 74300, lr = 1e-06
I0629 11:40:52.952186  2332 solver.cpp:218] Iteration 74400 (27.5502 iter/s, 3.62974s/100 iters), loss = 0.06844
I0629 11:40:52.952186  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:40:52.952186  2332 solver.cpp:237]     Train net output #1: loss = 0.0684399 (* 1 = 0.0684399 loss)
I0629 11:40:52.952186  2332 sgd_solver.cpp:105] Iteration 74400, lr = 1e-06
I0629 11:40:56.400352  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:40:56.542456  2332 solver.cpp:330] Iteration 74500, Testing net (#0)
I0629 11:40:56.542456  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:40:57.360568  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:40:57.391090  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8937
I0629 11:40:57.391090  2332 solver.cpp:397]     Test net output #1: loss = 0.35606 (* 1 = 0.35606 loss)
I0629 11:40:57.425114  2332 solver.cpp:218] Iteration 74500 (22.3557 iter/s, 4.47314s/100 iters), loss = 0.0858531
I0629 11:40:57.425114  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:40:57.425114  2332 solver.cpp:237]     Train net output #1: loss = 0.0858531 (* 1 = 0.0858531 loss)
I0629 11:40:57.425114  2332 sgd_solver.cpp:105] Iteration 74500, lr = 1e-06
I0629 11:41:01.057926  2332 solver.cpp:218] Iteration 74600 (27.5318 iter/s, 3.63217s/100 iters), loss = 0.104965
I0629 11:41:01.058429  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:41:01.058429  2332 solver.cpp:237]     Train net output #1: loss = 0.104965 (* 1 = 0.104965 loss)
I0629 11:41:01.058429  2332 sgd_solver.cpp:105] Iteration 74600, lr = 1e-06
I0629 11:41:04.683923  2332 solver.cpp:218] Iteration 74700 (27.5827 iter/s, 3.62546s/100 iters), loss = 0.182074
I0629 11:41:04.683923  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0629 11:41:04.683923  2332 solver.cpp:237]     Train net output #1: loss = 0.182074 (* 1 = 0.182074 loss)
I0629 11:41:04.683923  2332 sgd_solver.cpp:105] Iteration 74700, lr = 1e-06
I0629 11:41:08.312170  2332 solver.cpp:218] Iteration 74800 (27.5611 iter/s, 3.6283s/100 iters), loss = 0.0983573
I0629 11:41:08.312170  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:41:08.312170  2332 solver.cpp:237]     Train net output #1: loss = 0.0983573 (* 1 = 0.0983573 loss)
I0629 11:41:08.312170  2332 sgd_solver.cpp:105] Iteration 74800, lr = 1e-06
I0629 11:41:11.931372  2332 solver.cpp:218] Iteration 74900 (27.6319 iter/s, 3.619s/100 iters), loss = 0.0789
I0629 11:41:11.931372  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:41:11.931372  2332 solver.cpp:237]     Train net output #1: loss = 0.0789 (* 1 = 0.0789 loss)
I0629 11:41:11.931372  2332 sgd_solver.cpp:105] Iteration 74900, lr = 1e-06
I0629 11:41:15.382655  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:41:15.524260  2332 solver.cpp:330] Iteration 75000, Testing net (#0)
I0629 11:41:15.524260  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:41:16.345012  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:41:16.376538  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0629 11:41:16.376538  2332 solver.cpp:397]     Test net output #1: loss = 0.356133 (* 1 = 0.356133 loss)
I0629 11:41:16.410063  2332 solver.cpp:218] Iteration 75000 (22.3289 iter/s, 4.47851s/100 iters), loss = 0.0850983
I0629 11:41:16.410063  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:41:16.410063  2332 solver.cpp:237]     Train net output #1: loss = 0.0850983 (* 1 = 0.0850983 loss)
I0629 11:41:16.410063  2332 sgd_solver.cpp:105] Iteration 75000, lr = 1e-06
I0629 11:41:20.047682  2332 solver.cpp:218] Iteration 75100 (27.4986 iter/s, 3.63654s/100 iters), loss = 0.124649
I0629 11:41:20.047682  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:41:20.047682  2332 solver.cpp:237]     Train net output #1: loss = 0.124649 (* 1 = 0.124649 loss)
I0629 11:41:20.047682  2332 sgd_solver.cpp:105] Iteration 75100, lr = 1e-06
I0629 11:41:23.679890  2332 solver.cpp:218] Iteration 75200 (27.5347 iter/s, 3.63178s/100 iters), loss = 0.138992
I0629 11:41:23.679890  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:41:23.679890  2332 solver.cpp:237]     Train net output #1: loss = 0.138992 (* 1 = 0.138992 loss)
I0629 11:41:23.679890  2332 sgd_solver.cpp:105] Iteration 75200, lr = 1e-06
I0629 11:41:27.303309  2332 solver.cpp:218] Iteration 75300 (27.595 iter/s, 3.62385s/100 iters), loss = 0.0775712
I0629 11:41:27.303309  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:41:27.303309  2332 solver.cpp:237]     Train net output #1: loss = 0.0775712 (* 1 = 0.0775712 loss)
I0629 11:41:27.303309  2332 sgd_solver.cpp:105] Iteration 75300, lr = 1e-06
I0629 11:41:30.924609  2332 solver.cpp:218] Iteration 75400 (27.6233 iter/s, 3.62013s/100 iters), loss = 0.108883
I0629 11:41:30.924609  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:41:30.924609  2332 solver.cpp:237]     Train net output #1: loss = 0.108883 (* 1 = 0.108883 loss)
I0629 11:41:30.924609  2332 sgd_solver.cpp:105] Iteration 75400, lr = 1e-06
I0629 11:41:34.374811  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:41:34.515566  2332 solver.cpp:330] Iteration 75500, Testing net (#0)
I0629 11:41:34.515566  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:41:35.337550  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:41:35.368568  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8937
I0629 11:41:35.368568  2332 solver.cpp:397]     Test net output #1: loss = 0.35611 (* 1 = 0.35611 loss)
I0629 11:41:35.403084  2332 solver.cpp:218] Iteration 75500 (22.3287 iter/s, 4.47855s/100 iters), loss = 0.0592418
I0629 11:41:35.403084  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:41:35.403084  2332 solver.cpp:237]     Train net output #1: loss = 0.0592418 (* 1 = 0.0592418 loss)
I0629 11:41:35.403084  2332 sgd_solver.cpp:105] Iteration 75500, lr = 1e-06
I0629 11:41:39.037842  2332 solver.cpp:218] Iteration 75600 (27.5123 iter/s, 3.63473s/100 iters), loss = 0.133007
I0629 11:41:39.037842  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0629 11:41:39.037842  2332 solver.cpp:237]     Train net output #1: loss = 0.133007 (* 1 = 0.133007 loss)
I0629 11:41:39.037842  2332 sgd_solver.cpp:105] Iteration 75600, lr = 1e-06
I0629 11:41:42.661312  2332 solver.cpp:218] Iteration 75700 (27.6015 iter/s, 3.62299s/100 iters), loss = 0.108661
I0629 11:41:42.661312  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:41:42.661312  2332 solver.cpp:237]     Train net output #1: loss = 0.108661 (* 1 = 0.108661 loss)
I0629 11:41:42.661312  2332 sgd_solver.cpp:105] Iteration 75700, lr = 1e-06
I0629 11:41:46.294348  2332 solver.cpp:218] Iteration 75800 (27.5267 iter/s, 3.63284s/100 iters), loss = 0.123412
I0629 11:41:46.294348  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:41:46.294348  2332 solver.cpp:237]     Train net output #1: loss = 0.123412 (* 1 = 0.123412 loss)
I0629 11:41:46.294348  2332 sgd_solver.cpp:105] Iteration 75800, lr = 1e-06
I0629 11:41:49.909689  2332 solver.cpp:218] Iteration 75900 (27.6653 iter/s, 3.61464s/100 iters), loss = 0.0958041
I0629 11:41:49.909689  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:41:49.909689  2332 solver.cpp:237]     Train net output #1: loss = 0.0958042 (* 1 = 0.0958042 loss)
I0629 11:41:49.909689  2332 sgd_solver.cpp:105] Iteration 75900, lr = 1e-06
I0629 11:41:53.363276  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:41:53.504978  2332 solver.cpp:330] Iteration 76000, Testing net (#0)
I0629 11:41:53.504978  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:41:54.324069  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:41:54.355082  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8941
I0629 11:41:54.355082  2332 solver.cpp:397]     Test net output #1: loss = 0.356006 (* 1 = 0.356006 loss)
I0629 11:41:54.390107  2332 solver.cpp:218] Iteration 76000 (22.3221 iter/s, 4.47986s/100 iters), loss = 0.0763711
I0629 11:41:54.390107  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:41:54.390107  2332 solver.cpp:237]     Train net output #1: loss = 0.0763712 (* 1 = 0.0763712 loss)
I0629 11:41:54.390107  2332 sgd_solver.cpp:105] Iteration 76000, lr = 1e-06
I0629 11:41:58.014005  2332 solver.cpp:218] Iteration 76100 (27.5984 iter/s, 3.6234s/100 iters), loss = 0.0788417
I0629 11:41:58.014005  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:41:58.014005  2332 solver.cpp:237]     Train net output #1: loss = 0.0788418 (* 1 = 0.0788418 loss)
I0629 11:41:58.014005  2332 sgd_solver.cpp:105] Iteration 76100, lr = 1e-06
I0629 11:42:01.640036  2332 solver.cpp:218] Iteration 76200 (27.5742 iter/s, 3.62657s/100 iters), loss = 0.106905
I0629 11:42:01.640036  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:42:01.640036  2332 solver.cpp:237]     Train net output #1: loss = 0.106905 (* 1 = 0.106905 loss)
I0629 11:42:01.641037  2332 sgd_solver.cpp:105] Iteration 76200, lr = 1e-06
I0629 11:42:05.274750  2332 solver.cpp:218] Iteration 76300 (27.5193 iter/s, 3.63381s/100 iters), loss = 0.0507023
I0629 11:42:05.274750  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:42:05.274750  2332 solver.cpp:237]     Train net output #1: loss = 0.0507024 (* 1 = 0.0507024 loss)
I0629 11:42:05.274750  2332 sgd_solver.cpp:105] Iteration 76300, lr = 1e-06
I0629 11:42:08.897470  2332 solver.cpp:218] Iteration 76400 (27.6039 iter/s, 3.62267s/100 iters), loss = 0.120867
I0629 11:42:08.897470  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:42:08.897470  2332 solver.cpp:237]     Train net output #1: loss = 0.120867 (* 1 = 0.120867 loss)
I0629 11:42:08.897470  2332 sgd_solver.cpp:105] Iteration 76400, lr = 1e-06
I0629 11:42:12.354590  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:42:12.496191  2332 solver.cpp:330] Iteration 76500, Testing net (#0)
I0629 11:42:12.496191  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:42:13.323613  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:42:13.355648  2332 solver.cpp:397]     Test net output #0: accuracy = 0.894
I0629 11:42:13.355648  2332 solver.cpp:397]     Test net output #1: loss = 0.355951 (* 1 = 0.355951 loss)
I0629 11:42:13.389675  2332 solver.cpp:218] Iteration 76500 (22.2631 iter/s, 4.49174s/100 iters), loss = 0.0663451
I0629 11:42:13.389675  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:42:13.389675  2332 solver.cpp:237]     Train net output #1: loss = 0.0663451 (* 1 = 0.0663451 loss)
I0629 11:42:13.389675  2332 sgd_solver.cpp:105] Iteration 76500, lr = 1e-06
I0629 11:42:17.012250  2332 solver.cpp:218] Iteration 76600 (27.607 iter/s, 3.62227s/100 iters), loss = 0.124669
I0629 11:42:17.012250  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:42:17.012250  2332 solver.cpp:237]     Train net output #1: loss = 0.124669 (* 1 = 0.124669 loss)
I0629 11:42:17.012250  2332 sgd_solver.cpp:105] Iteration 76600, lr = 1e-06
I0629 11:42:20.633517  2332 solver.cpp:218] Iteration 76700 (27.6167 iter/s, 3.62099s/100 iters), loss = 0.109733
I0629 11:42:20.633517  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:42:20.633517  2332 solver.cpp:237]     Train net output #1: loss = 0.109733 (* 1 = 0.109733 loss)
I0629 11:42:20.633517  2332 sgd_solver.cpp:105] Iteration 76700, lr = 1e-06
I0629 11:42:24.264271  2332 solver.cpp:218] Iteration 76800 (27.5467 iter/s, 3.6302s/100 iters), loss = 0.112514
I0629 11:42:24.264271  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:42:24.264271  2332 solver.cpp:237]     Train net output #1: loss = 0.112514 (* 1 = 0.112514 loss)
I0629 11:42:24.264271  2332 sgd_solver.cpp:105] Iteration 76800, lr = 1e-06
I0629 11:42:27.885231  2332 solver.cpp:218] Iteration 76900 (27.6205 iter/s, 3.6205s/100 iters), loss = 0.0834216
I0629 11:42:27.885231  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:42:27.885231  2332 solver.cpp:237]     Train net output #1: loss = 0.0834216 (* 1 = 0.0834216 loss)
I0629 11:42:27.885231  2332 sgd_solver.cpp:105] Iteration 76900, lr = 1e-06
I0629 11:42:31.331017  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:42:31.472124  2332 solver.cpp:330] Iteration 77000, Testing net (#0)
I0629 11:42:31.472124  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:42:32.289734  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:42:32.320756  2332 solver.cpp:397]     Test net output #0: accuracy = 0.894
I0629 11:42:32.320756  2332 solver.cpp:397]     Test net output #1: loss = 0.355972 (* 1 = 0.355972 loss)
I0629 11:42:32.355790  2332 solver.cpp:218] Iteration 77000 (22.3718 iter/s, 4.46991s/100 iters), loss = 0.107518
I0629 11:42:32.355790  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:42:32.355790  2332 solver.cpp:237]     Train net output #1: loss = 0.107518 (* 1 = 0.107518 loss)
I0629 11:42:32.355790  2332 sgd_solver.cpp:105] Iteration 77000, lr = 1e-06
I0629 11:42:35.971482  2332 solver.cpp:218] Iteration 77100 (27.6542 iter/s, 3.61609s/100 iters), loss = 0.122628
I0629 11:42:35.971482  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:42:35.971482  2332 solver.cpp:237]     Train net output #1: loss = 0.122628 (* 1 = 0.122628 loss)
I0629 11:42:35.971482  2332 sgd_solver.cpp:105] Iteration 77100, lr = 1e-06
I0629 11:42:39.599442  2332 solver.cpp:218] Iteration 77200 (27.5701 iter/s, 3.62712s/100 iters), loss = 0.0955276
I0629 11:42:39.599442  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:42:39.599442  2332 solver.cpp:237]     Train net output #1: loss = 0.0955276 (* 1 = 0.0955276 loss)
I0629 11:42:39.599442  2332 sgd_solver.cpp:105] Iteration 77200, lr = 1e-06
I0629 11:42:43.219851  2332 solver.cpp:218] Iteration 77300 (27.6219 iter/s, 3.62031s/100 iters), loss = 0.107732
I0629 11:42:43.220352  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:42:43.220352  2332 solver.cpp:237]     Train net output #1: loss = 0.107732 (* 1 = 0.107732 loss)
I0629 11:42:43.220352  2332 sgd_solver.cpp:105] Iteration 77300, lr = 1e-06
I0629 11:42:46.850062  2332 solver.cpp:218] Iteration 77400 (27.5482 iter/s, 3.63001s/100 iters), loss = 0.0445483
I0629 11:42:46.850062  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:42:46.850062  2332 solver.cpp:237]     Train net output #1: loss = 0.0445483 (* 1 = 0.0445483 loss)
I0629 11:42:46.850062  2332 sgd_solver.cpp:105] Iteration 77400, lr = 1e-06
I0629 11:42:50.303936  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:42:50.445042  2332 solver.cpp:330] Iteration 77500, Testing net (#0)
I0629 11:42:50.445042  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:42:51.262655  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:42:51.293676  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0629 11:42:51.293676  2332 solver.cpp:397]     Test net output #1: loss = 0.356141 (* 1 = 0.356141 loss)
I0629 11:42:51.329203  2332 solver.cpp:218] Iteration 77500 (22.3292 iter/s, 4.47845s/100 iters), loss = 0.101568
I0629 11:42:51.329203  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:42:51.329203  2332 solver.cpp:237]     Train net output #1: loss = 0.101568 (* 1 = 0.101568 loss)
I0629 11:42:51.329203  2332 sgd_solver.cpp:105] Iteration 77500, lr = 1e-06
I0629 11:42:54.956857  2332 solver.cpp:218] Iteration 77600 (27.5644 iter/s, 3.62787s/100 iters), loss = 0.118507
I0629 11:42:54.956857  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0629 11:42:54.956857  2332 solver.cpp:237]     Train net output #1: loss = 0.118507 (* 1 = 0.118507 loss)
I0629 11:42:54.956857  2332 sgd_solver.cpp:105] Iteration 77600, lr = 1e-06
I0629 11:42:58.579372  2332 solver.cpp:218] Iteration 77700 (27.6083 iter/s, 3.62209s/100 iters), loss = 0.0608673
I0629 11:42:58.579372  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:42:58.579372  2332 solver.cpp:237]     Train net output #1: loss = 0.0608673 (* 1 = 0.0608673 loss)
I0629 11:42:58.579372  2332 sgd_solver.cpp:105] Iteration 77700, lr = 1e-06
I0629 11:43:02.208087  2332 solver.cpp:218] Iteration 77800 (27.562 iter/s, 3.62818s/100 iters), loss = 0.0744812
I0629 11:43:02.208087  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:43:02.208087  2332 solver.cpp:237]     Train net output #1: loss = 0.0744812 (* 1 = 0.0744812 loss)
I0629 11:43:02.208087  2332 sgd_solver.cpp:105] Iteration 77800, lr = 1e-06
I0629 11:43:05.829815  2332 solver.cpp:218] Iteration 77900 (27.6158 iter/s, 3.62112s/100 iters), loss = 0.0704994
I0629 11:43:05.829815  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:43:05.829815  2332 solver.cpp:237]     Train net output #1: loss = 0.0704994 (* 1 = 0.0704994 loss)
I0629 11:43:05.829815  2332 sgd_solver.cpp:105] Iteration 77900, lr = 1e-06
I0629 11:43:09.283610  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:43:09.425714  2332 solver.cpp:330] Iteration 78000, Testing net (#0)
I0629 11:43:09.425714  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:43:10.246876  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:43:10.277398  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0629 11:43:10.277398  2332 solver.cpp:397]     Test net output #1: loss = 0.356355 (* 1 = 0.356355 loss)
I0629 11:43:10.311422  2332 solver.cpp:218] Iteration 78000 (22.3126 iter/s, 4.48178s/100 iters), loss = 0.0617521
I0629 11:43:10.311422  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:43:10.311422  2332 solver.cpp:237]     Train net output #1: loss = 0.061752 (* 1 = 0.061752 loss)
I0629 11:43:10.311422  2332 sgd_solver.cpp:105] Iteration 78000, lr = 1e-06
I0629 11:43:13.941581  2332 solver.cpp:218] Iteration 78100 (27.5535 iter/s, 3.62931s/100 iters), loss = 0.151064
I0629 11:43:13.941581  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:43:13.941581  2332 solver.cpp:237]     Train net output #1: loss = 0.151063 (* 1 = 0.151063 loss)
I0629 11:43:13.941581  2332 sgd_solver.cpp:105] Iteration 78100, lr = 1e-06
I0629 11:43:17.572249  2332 solver.cpp:218] Iteration 78200 (27.547 iter/s, 3.63016s/100 iters), loss = 0.0996876
I0629 11:43:17.572249  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:43:17.572249  2332 solver.cpp:237]     Train net output #1: loss = 0.0996875 (* 1 = 0.0996875 loss)
I0629 11:43:17.572249  2332 sgd_solver.cpp:105] Iteration 78200, lr = 1e-06
I0629 11:43:21.208544  2332 solver.cpp:218] Iteration 78300 (27.4981 iter/s, 3.63662s/100 iters), loss = 0.0966791
I0629 11:43:21.208544  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:43:21.208544  2332 solver.cpp:237]     Train net output #1: loss = 0.0966791 (* 1 = 0.0966791 loss)
I0629 11:43:21.208544  2332 sgd_solver.cpp:105] Iteration 78300, lr = 1e-06
I0629 11:43:24.843941  2332 solver.cpp:218] Iteration 78400 (27.5099 iter/s, 3.63505s/100 iters), loss = 0.0827131
I0629 11:43:24.843941  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:43:24.843941  2332 solver.cpp:237]     Train net output #1: loss = 0.082713 (* 1 = 0.082713 loss)
I0629 11:43:24.843941  2332 sgd_solver.cpp:105] Iteration 78400, lr = 1e-06
I0629 11:43:28.299342  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:43:28.441493  2332 solver.cpp:330] Iteration 78500, Testing net (#0)
I0629 11:43:28.441493  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:43:29.259163  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:43:29.289698  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8941
I0629 11:43:29.289698  2332 solver.cpp:397]     Test net output #1: loss = 0.356041 (* 1 = 0.356041 loss)
I0629 11:43:29.324739  2332 solver.cpp:218] Iteration 78500 (22.3213 iter/s, 4.48004s/100 iters), loss = 0.083195
I0629 11:43:29.324739  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:43:29.324739  2332 solver.cpp:237]     Train net output #1: loss = 0.0831949 (* 1 = 0.0831949 loss)
I0629 11:43:29.324739  2332 sgd_solver.cpp:105] Iteration 78500, lr = 1e-06
I0629 11:43:32.955325  2332 solver.cpp:218] Iteration 78600 (27.5427 iter/s, 3.63072s/100 iters), loss = 0.122291
I0629 11:43:32.955325  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:43:32.955325  2332 solver.cpp:237]     Train net output #1: loss = 0.122291 (* 1 = 0.122291 loss)
I0629 11:43:32.955325  2332 sgd_solver.cpp:105] Iteration 78600, lr = 1e-06
I0629 11:43:36.579795  2332 solver.cpp:218] Iteration 78700 (27.5955 iter/s, 3.62377s/100 iters), loss = 0.105264
I0629 11:43:36.579795  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:43:36.579795  2332 solver.cpp:237]     Train net output #1: loss = 0.105264 (* 1 = 0.105264 loss)
I0629 11:43:36.579795  2332 sgd_solver.cpp:105] Iteration 78700, lr = 1e-06
I0629 11:43:40.215513  2332 solver.cpp:218] Iteration 78800 (27.5053 iter/s, 3.63566s/100 iters), loss = 0.0684675
I0629 11:43:40.215513  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:43:40.215513  2332 solver.cpp:237]     Train net output #1: loss = 0.0684674 (* 1 = 0.0684674 loss)
I0629 11:43:40.215513  2332 sgd_solver.cpp:105] Iteration 78800, lr = 1e-06
I0629 11:43:43.845080  2332 solver.cpp:218] Iteration 78900 (27.5522 iter/s, 3.62948s/100 iters), loss = 0.0941417
I0629 11:43:43.846089  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:43:43.846089  2332 solver.cpp:237]     Train net output #1: loss = 0.0941416 (* 1 = 0.0941416 loss)
I0629 11:43:43.846089  2332 sgd_solver.cpp:105] Iteration 78900, lr = 1e-06
I0629 11:43:47.295239  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:43:47.438402  2332 solver.cpp:330] Iteration 79000, Testing net (#0)
I0629 11:43:47.438402  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:43:48.255136  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:43:48.286661  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8945
I0629 11:43:48.286661  2332 solver.cpp:397]     Test net output #1: loss = 0.356399 (* 1 = 0.356399 loss)
I0629 11:43:48.320214  2332 solver.cpp:218] Iteration 79000 (22.3485 iter/s, 4.47457s/100 iters), loss = 0.0902858
I0629 11:43:48.320214  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:43:48.320214  2332 solver.cpp:237]     Train net output #1: loss = 0.0902857 (* 1 = 0.0902857 loss)
I0629 11:43:48.320214  2332 sgd_solver.cpp:105] Iteration 79000, lr = 1e-06
I0629 11:43:51.955850  2332 solver.cpp:218] Iteration 79100 (27.5083 iter/s, 3.63527s/100 iters), loss = 0.149944
I0629 11:43:51.955850  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:43:51.955850  2332 solver.cpp:237]     Train net output #1: loss = 0.149944 (* 1 = 0.149944 loss)
I0629 11:43:51.955850  2332 sgd_solver.cpp:105] Iteration 79100, lr = 1e-06
I0629 11:43:55.589010  2332 solver.cpp:218] Iteration 79200 (27.5252 iter/s, 3.63303s/100 iters), loss = 0.106998
I0629 11:43:55.589010  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:43:55.590011  2332 solver.cpp:237]     Train net output #1: loss = 0.106998 (* 1 = 0.106998 loss)
I0629 11:43:55.590011  2332 sgd_solver.cpp:105] Iteration 79200, lr = 1e-06
I0629 11:43:59.224510  2332 solver.cpp:218] Iteration 79300 (27.5134 iter/s, 3.63459s/100 iters), loss = 0.0895451
I0629 11:43:59.224510  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0629 11:43:59.224510  2332 solver.cpp:237]     Train net output #1: loss = 0.089545 (* 1 = 0.089545 loss)
I0629 11:43:59.224510  2332 sgd_solver.cpp:105] Iteration 79300, lr = 1e-06
I0629 11:44:02.855566  2332 solver.cpp:218] Iteration 79400 (27.5439 iter/s, 3.63056s/100 iters), loss = 0.0507214
I0629 11:44:02.855566  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0629 11:44:02.855566  2332 solver.cpp:237]     Train net output #1: loss = 0.0507213 (* 1 = 0.0507213 loss)
I0629 11:44:02.855566  2332 sgd_solver.cpp:105] Iteration 79400, lr = 1e-06
I0629 11:44:06.307909  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:44:06.450053  2332 solver.cpp:330] Iteration 79500, Testing net (#0)
I0629 11:44:06.450053  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:44:07.275413  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:44:07.306448  2332 solver.cpp:397]     Test net output #0: accuracy = 0.894
I0629 11:44:07.306448  2332 solver.cpp:397]     Test net output #1: loss = 0.355999 (* 1 = 0.355999 loss)
I0629 11:44:07.341472  2332 solver.cpp:218] Iteration 79500 (22.2945 iter/s, 4.48542s/100 iters), loss = 0.0609008
I0629 11:44:07.341472  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:44:07.341472  2332 solver.cpp:237]     Train net output #1: loss = 0.0609007 (* 1 = 0.0609007 loss)
I0629 11:44:07.341472  2332 sgd_solver.cpp:105] Iteration 79500, lr = 1e-06
I0629 11:44:10.983114  2332 solver.cpp:218] Iteration 79600 (27.4634 iter/s, 3.64121s/100 iters), loss = 0.0988994
I0629 11:44:10.983114  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0629 11:44:10.983114  2332 solver.cpp:237]     Train net output #1: loss = 0.0988993 (* 1 = 0.0988993 loss)
I0629 11:44:10.983114  2332 sgd_solver.cpp:105] Iteration 79600, lr = 1e-06
I0629 11:44:14.620000  2332 solver.cpp:218] Iteration 79700 (27.4927 iter/s, 3.63732s/100 iters), loss = 0.108144
I0629 11:44:14.620000  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:44:14.620000  2332 solver.cpp:237]     Train net output #1: loss = 0.108144 (* 1 = 0.108144 loss)
I0629 11:44:14.620000  2332 sgd_solver.cpp:105] Iteration 79700, lr = 1e-06
I0629 11:44:18.260629  2332 solver.cpp:218] Iteration 79800 (27.4746 iter/s, 3.63972s/100 iters), loss = 0.0628663
I0629 11:44:18.260629  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0629 11:44:18.260629  2332 solver.cpp:237]     Train net output #1: loss = 0.0628662 (* 1 = 0.0628662 loss)
I0629 11:44:18.260629  2332 sgd_solver.cpp:105] Iteration 79800, lr = 1e-06
I0629 11:44:21.899278  2332 solver.cpp:218] Iteration 79900 (27.4821 iter/s, 3.63873s/100 iters), loss = 0.0592246
I0629 11:44:21.899278  2332 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0629 11:44:21.899278  2332 solver.cpp:237]     Train net output #1: loss = 0.0592245 (* 1 = 0.0592245 loss)
I0629 11:44:21.899278  2332 sgd_solver.cpp:105] Iteration 79900, lr = 1e-06
I0629 11:44:25.360105  2892 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:44:25.501245  2332 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/128K_iter_80000.caffemodel
I0629 11:44:25.510772  2332 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/128K_iter_80000.solverstate
I0629 11:44:25.521775  2332 solver.cpp:310] Iteration 80000, loss = 0.0799586
I0629 11:44:25.521775  2332 solver.cpp:330] Iteration 80000, Testing net (#0)
I0629 11:44:25.521775  2332 net.cpp:676] Ignoring source layer accuracy_training
I0629 11:44:26.342692  8116 data_layer.cpp:73] Restarting data prefetching from start.
I0629 11:44:26.373728  2332 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0629 11:44:26.373728  2332 solver.cpp:397]     Test net output #1: loss = 0.355969 (* 1 = 0.355969 loss)
I0629 11:44:26.373728  2332 solver.cpp:315] Optimization Done.
I0629 11:44:26.373728  2332 caffe.cpp:260] Optimization Done.
G:\Caffe>