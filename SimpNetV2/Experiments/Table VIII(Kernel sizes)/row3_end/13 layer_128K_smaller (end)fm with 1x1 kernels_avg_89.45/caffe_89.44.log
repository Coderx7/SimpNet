
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0628 21:42:12.126710 17220 caffe.cpp:219] Using GPUs 0
I0628 21:42:12.316447 17220 caffe.cpp:224] GPU 0: GeForce GTX 1080
I0628 21:42:12.655261 17220 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 21:42:12.670272 17220 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 80000
snapshot_prefix: "examples/cifar10/128K"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 32000
stepvalue: 48000
stepvalue: 54000
stepvalue: 74000
type: "Nesterov"
I0628 21:42:12.670773 17220 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 21:42:12.671272 17220 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 21:42:12.671272 17220 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0628 21:42:12.671272 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0628 21:42:12.671272 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp4
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp5
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp6
I0628 21:42:12.671773 17220 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0628 21:42:12.671773 17220 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_13_128k_end1x1"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_12"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_12"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 53
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "conv4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 53
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp4"
  type: "Scale"
  bottom: "cccp4"
  top: "cccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "cccp4"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "pool4_2"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp5"
  type: "Scale"
  bottom: "cccp5"
  top: "cccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp6"
  type: "Scale"
  bottom: "cccp6"
  top: "cccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0628 21:42:12.672274 17220 layer_factory.cpp:58] Creating layer cifar
I0628 21:42:12.674775 17220 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I0628 21:42:12.675276 17220 net.cpp:84] Creating Layer cifar
I0628 21:42:12.675276 17220 net.cpp:380] cifar -> data
I0628 21:42:12.675276 17220 net.cpp:380] cifar -> label
I0628 21:42:12.675276 17220 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 21:42:12.676276 17220 data_layer.cpp:45] output data size: 100,3,32,32
I0628 21:42:12.682780 17220 net.cpp:122] Setting up cifar
I0628 21:42:12.682780 17220 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0628 21:42:12.682780 17220 net.cpp:129] Top shape: 100 (100)
I0628 21:42:12.682780 17220 net.cpp:137] Memory required for data: 1229200
I0628 21:42:12.682780 17220 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0628 21:42:12.682780 17220 net.cpp:84] Creating Layer label_cifar_1_split
I0628 21:42:12.682780 17220 net.cpp:406] label_cifar_1_split <- label
I0628 21:42:12.682780 17220 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0628 21:42:12.682780 17220 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0628 21:42:12.682780 17220 net.cpp:122] Setting up label_cifar_1_split
I0628 21:42:12.682780 17220 net.cpp:129] Top shape: 100 (100)
I0628 21:42:12.682780 17220 net.cpp:129] Top shape: 100 (100)
I0628 21:42:12.682780 17220 net.cpp:137] Memory required for data: 1230000
I0628 21:42:12.682780 17220 layer_factory.cpp:58] Creating layer conv1
I0628 21:42:12.682780 17220 net.cpp:84] Creating Layer conv1
I0628 21:42:12.683295 17220 net.cpp:406] conv1 <- data
I0628 21:42:12.683295 17220 net.cpp:380] conv1 -> conv1
I0628 21:42:12.683791  9296 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 21:42:12.913945 17220 net.cpp:122] Setting up conv1
I0628 21:42:12.913945 17220 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 21:42:12.913945 17220 net.cpp:137] Memory required for data: 9012400
I0628 21:42:12.913945 17220 layer_factory.cpp:58] Creating layer bn1
I0628 21:42:12.913945 17220 net.cpp:84] Creating Layer bn1
I0628 21:42:12.913945 17220 net.cpp:406] bn1 <- conv1
I0628 21:42:12.913945 17220 net.cpp:367] bn1 -> conv1 (in-place)
I0628 21:42:12.913945 17220 net.cpp:122] Setting up bn1
I0628 21:42:12.913945 17220 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 21:42:12.913945 17220 net.cpp:137] Memory required for data: 16794800
I0628 21:42:12.913945 17220 layer_factory.cpp:58] Creating layer scale1
I0628 21:42:12.913945 17220 net.cpp:84] Creating Layer scale1
I0628 21:42:12.913945 17220 net.cpp:406] scale1 <- conv1
I0628 21:42:12.913945 17220 net.cpp:367] scale1 -> conv1 (in-place)
I0628 21:42:12.914446 17220 layer_factory.cpp:58] Creating layer scale1
I0628 21:42:12.914446 17220 net.cpp:122] Setting up scale1
I0628 21:42:12.914446 17220 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 21:42:12.914446 17220 net.cpp:137] Memory required for data: 24577200
I0628 21:42:12.914446 17220 layer_factory.cpp:58] Creating layer relu1
I0628 21:42:12.914446 17220 net.cpp:84] Creating Layer relu1
I0628 21:42:12.914446 17220 net.cpp:406] relu1 <- conv1
I0628 21:42:12.914446 17220 net.cpp:367] relu1 -> conv1 (in-place)
I0628 21:42:12.914446 17220 net.cpp:122] Setting up relu1
I0628 21:42:12.914446 17220 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 21:42:12.914446 17220 net.cpp:137] Memory required for data: 32359600
I0628 21:42:12.914446 17220 layer_factory.cpp:58] Creating layer conv1_0
I0628 21:42:12.914446 17220 net.cpp:84] Creating Layer conv1_0
I0628 21:42:12.914446 17220 net.cpp:406] conv1_0 <- conv1
I0628 21:42:12.914446 17220 net.cpp:380] conv1_0 -> conv1_0
I0628 21:42:12.916448 17220 net.cpp:122] Setting up conv1_0
I0628 21:42:12.916448 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.916448 17220 net.cpp:137] Memory required for data: 42599600
I0628 21:42:12.916448 17220 layer_factory.cpp:58] Creating layer bn1_0
I0628 21:42:12.916448 17220 net.cpp:84] Creating Layer bn1_0
I0628 21:42:12.916448 17220 net.cpp:406] bn1_0 <- conv1_0
I0628 21:42:12.916448 17220 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0628 21:42:12.916448 17220 net.cpp:122] Setting up bn1_0
I0628 21:42:12.916448 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.916448 17220 net.cpp:137] Memory required for data: 52839600
I0628 21:42:12.916448 17220 layer_factory.cpp:58] Creating layer scale1_0
I0628 21:42:12.916448 17220 net.cpp:84] Creating Layer scale1_0
I0628 21:42:12.916448 17220 net.cpp:406] scale1_0 <- conv1_0
I0628 21:42:12.916448 17220 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0628 21:42:12.916448 17220 layer_factory.cpp:58] Creating layer scale1_0
I0628 21:42:12.916448 17220 net.cpp:122] Setting up scale1_0
I0628 21:42:12.916448 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.916448 17220 net.cpp:137] Memory required for data: 63079600
I0628 21:42:12.916448 17220 layer_factory.cpp:58] Creating layer relu1_0
I0628 21:42:12.916448 17220 net.cpp:84] Creating Layer relu1_0
I0628 21:42:12.916448 17220 net.cpp:406] relu1_0 <- conv1_0
I0628 21:42:12.916448 17220 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0628 21:42:12.916947 17220 net.cpp:122] Setting up relu1_0
I0628 21:42:12.916947 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.916947 17220 net.cpp:137] Memory required for data: 73319600
I0628 21:42:12.916947 17220 layer_factory.cpp:58] Creating layer conv2
I0628 21:42:12.916947 17220 net.cpp:84] Creating Layer conv2
I0628 21:42:12.916947 17220 net.cpp:406] conv2 <- conv1_0
I0628 21:42:12.916947 17220 net.cpp:380] conv2 -> conv2
I0628 21:42:12.917948 17220 net.cpp:122] Setting up conv2
I0628 21:42:12.917948 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.917948 17220 net.cpp:137] Memory required for data: 83559600
I0628 21:42:12.917948 17220 layer_factory.cpp:58] Creating layer bn2
I0628 21:42:12.917948 17220 net.cpp:84] Creating Layer bn2
I0628 21:42:12.917948 17220 net.cpp:406] bn2 <- conv2
I0628 21:42:12.917948 17220 net.cpp:367] bn2 -> conv2 (in-place)
I0628 21:42:12.917948 17220 net.cpp:122] Setting up bn2
I0628 21:42:12.917948 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.917948 17220 net.cpp:137] Memory required for data: 93799600
I0628 21:42:12.917948 17220 layer_factory.cpp:58] Creating layer scale2
I0628 21:42:12.918448 17220 net.cpp:84] Creating Layer scale2
I0628 21:42:12.918448 17220 net.cpp:406] scale2 <- conv2
I0628 21:42:12.918448 17220 net.cpp:367] scale2 -> conv2 (in-place)
I0628 21:42:12.918448 17220 layer_factory.cpp:58] Creating layer scale2
I0628 21:42:12.918448 17220 net.cpp:122] Setting up scale2
I0628 21:42:12.918448 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.918448 17220 net.cpp:137] Memory required for data: 104039600
I0628 21:42:12.918448 17220 layer_factory.cpp:58] Creating layer relu2
I0628 21:42:12.918448 17220 net.cpp:84] Creating Layer relu2
I0628 21:42:12.918448 17220 net.cpp:406] relu2 <- conv2
I0628 21:42:12.918448 17220 net.cpp:367] relu2 -> conv2 (in-place)
I0628 21:42:12.918949 17220 net.cpp:122] Setting up relu2
I0628 21:42:12.918949 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.918949 17220 net.cpp:137] Memory required for data: 114279600
I0628 21:42:12.918949 17220 layer_factory.cpp:58] Creating layer conv2_1
I0628 21:42:12.918949 17220 net.cpp:84] Creating Layer conv2_1
I0628 21:42:12.918949 17220 net.cpp:406] conv2_1 <- conv2
I0628 21:42:12.918949 17220 net.cpp:380] conv2_1 -> conv2_1
I0628 21:42:12.919950 17220 net.cpp:122] Setting up conv2_1
I0628 21:42:12.919950 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.919950 17220 net.cpp:137] Memory required for data: 124519600
I0628 21:42:12.919950 17220 layer_factory.cpp:58] Creating layer bn2_1
I0628 21:42:12.919950 17220 net.cpp:84] Creating Layer bn2_1
I0628 21:42:12.919950 17220 net.cpp:406] bn2_1 <- conv2_1
I0628 21:42:12.919950 17220 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0628 21:42:12.919950 17220 net.cpp:122] Setting up bn2_1
I0628 21:42:12.919950 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.919950 17220 net.cpp:137] Memory required for data: 134759600
I0628 21:42:12.919950 17220 layer_factory.cpp:58] Creating layer scale2_1
I0628 21:42:12.919950 17220 net.cpp:84] Creating Layer scale2_1
I0628 21:42:12.919950 17220 net.cpp:406] scale2_1 <- conv2_1
I0628 21:42:12.919950 17220 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0628 21:42:12.919950 17220 layer_factory.cpp:58] Creating layer scale2_1
I0628 21:42:12.919950 17220 net.cpp:122] Setting up scale2_1
I0628 21:42:12.920450 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.920450 17220 net.cpp:137] Memory required for data: 144999600
I0628 21:42:12.920450 17220 layer_factory.cpp:58] Creating layer relu2_1
I0628 21:42:12.920450 17220 net.cpp:84] Creating Layer relu2_1
I0628 21:42:12.920450 17220 net.cpp:406] relu2_1 <- conv2_1
I0628 21:42:12.920450 17220 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0628 21:42:12.920450 17220 net.cpp:122] Setting up relu2_1
I0628 21:42:12.920450 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.920450 17220 net.cpp:137] Memory required for data: 155239600
I0628 21:42:12.920450 17220 layer_factory.cpp:58] Creating layer conv2_2
I0628 21:42:12.920450 17220 net.cpp:84] Creating Layer conv2_2
I0628 21:42:12.920450 17220 net.cpp:406] conv2_2 <- conv2_1
I0628 21:42:12.920450 17220 net.cpp:380] conv2_2 -> conv2_2
I0628 21:42:12.921450 17220 net.cpp:122] Setting up conv2_2
I0628 21:42:12.921450 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.921450 17220 net.cpp:137] Memory required for data: 165479600
I0628 21:42:12.921450 17220 layer_factory.cpp:58] Creating layer bn2_2
I0628 21:42:12.921450 17220 net.cpp:84] Creating Layer bn2_2
I0628 21:42:12.921450 17220 net.cpp:406] bn2_2 <- conv2_2
I0628 21:42:12.921450 17220 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0628 21:42:12.921450 17220 net.cpp:122] Setting up bn2_2
I0628 21:42:12.921450 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.921450 17220 net.cpp:137] Memory required for data: 175719600
I0628 21:42:12.921450 17220 layer_factory.cpp:58] Creating layer scale2_2
I0628 21:42:12.921450 17220 net.cpp:84] Creating Layer scale2_2
I0628 21:42:12.921450 17220 net.cpp:406] scale2_2 <- conv2_2
I0628 21:42:12.921450 17220 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0628 21:42:12.921952 17220 layer_factory.cpp:58] Creating layer scale2_2
I0628 21:42:12.921952 17220 net.cpp:122] Setting up scale2_2
I0628 21:42:12.921952 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.921952 17220 net.cpp:137] Memory required for data: 185959600
I0628 21:42:12.921952 17220 layer_factory.cpp:58] Creating layer relu2_2
I0628 21:42:12.921952 17220 net.cpp:84] Creating Layer relu2_2
I0628 21:42:12.921952 17220 net.cpp:406] relu2_2 <- conv2_2
I0628 21:42:12.921952 17220 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0628 21:42:12.921952 17220 net.cpp:122] Setting up relu2_2
I0628 21:42:12.921952 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.921952 17220 net.cpp:137] Memory required for data: 196199600
I0628 21:42:12.921952 17220 layer_factory.cpp:58] Creating layer pool2_1
I0628 21:42:12.921952 17220 net.cpp:84] Creating Layer pool2_1
I0628 21:42:12.921952 17220 net.cpp:406] pool2_1 <- conv2_2
I0628 21:42:12.921952 17220 net.cpp:380] pool2_1 -> pool2_1
I0628 21:42:12.921952 17220 net.cpp:122] Setting up pool2_1
I0628 21:42:12.921952 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.921952 17220 net.cpp:137] Memory required for data: 198759600
I0628 21:42:12.921952 17220 layer_factory.cpp:58] Creating layer conv3
I0628 21:42:12.921952 17220 net.cpp:84] Creating Layer conv3
I0628 21:42:12.921952 17220 net.cpp:406] conv3 <- pool2_1
I0628 21:42:12.921952 17220 net.cpp:380] conv3 -> conv3
I0628 21:42:12.923452 17220 net.cpp:122] Setting up conv3
I0628 21:42:12.923452 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.923452 17220 net.cpp:137] Memory required for data: 201319600
I0628 21:42:12.923452 17220 layer_factory.cpp:58] Creating layer bn3
I0628 21:42:12.923452 17220 net.cpp:84] Creating Layer bn3
I0628 21:42:12.923452 17220 net.cpp:406] bn3 <- conv3
I0628 21:42:12.923452 17220 net.cpp:367] bn3 -> conv3 (in-place)
I0628 21:42:12.923452 17220 net.cpp:122] Setting up bn3
I0628 21:42:12.923452 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.923452 17220 net.cpp:137] Memory required for data: 203879600
I0628 21:42:12.923452 17220 layer_factory.cpp:58] Creating layer scale3
I0628 21:42:12.923452 17220 net.cpp:84] Creating Layer scale3
I0628 21:42:12.923452 17220 net.cpp:406] scale3 <- conv3
I0628 21:42:12.923452 17220 net.cpp:367] scale3 -> conv3 (in-place)
I0628 21:42:12.923452 17220 layer_factory.cpp:58] Creating layer scale3
I0628 21:42:12.923452 17220 net.cpp:122] Setting up scale3
I0628 21:42:12.923452 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.923452 17220 net.cpp:137] Memory required for data: 206439600
I0628 21:42:12.923452 17220 layer_factory.cpp:58] Creating layer relu3
I0628 21:42:12.923452 17220 net.cpp:84] Creating Layer relu3
I0628 21:42:12.923452 17220 net.cpp:406] relu3 <- conv3
I0628 21:42:12.923452 17220 net.cpp:367] relu3 -> conv3 (in-place)
I0628 21:42:12.923952 17220 net.cpp:122] Setting up relu3
I0628 21:42:12.923952 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.923952 17220 net.cpp:137] Memory required for data: 208999600
I0628 21:42:12.923952 17220 layer_factory.cpp:58] Creating layer conv4
I0628 21:42:12.923952 17220 net.cpp:84] Creating Layer conv4
I0628 21:42:12.923952 17220 net.cpp:406] conv4 <- conv3
I0628 21:42:12.923952 17220 net.cpp:380] conv4 -> conv4
I0628 21:42:12.924953 17220 net.cpp:122] Setting up conv4
I0628 21:42:12.924953 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.924953 17220 net.cpp:137] Memory required for data: 211559600
I0628 21:42:12.924953 17220 layer_factory.cpp:58] Creating layer bn4
I0628 21:42:12.924953 17220 net.cpp:84] Creating Layer bn4
I0628 21:42:12.924953 17220 net.cpp:406] bn4 <- conv4
I0628 21:42:12.924953 17220 net.cpp:367] bn4 -> conv4 (in-place)
I0628 21:42:12.925453 17220 net.cpp:122] Setting up bn4
I0628 21:42:12.925453 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.925453 17220 net.cpp:137] Memory required for data: 214119600
I0628 21:42:12.925453 17220 layer_factory.cpp:58] Creating layer scale4
I0628 21:42:12.925453 17220 net.cpp:84] Creating Layer scale4
I0628 21:42:12.925453 17220 net.cpp:406] scale4 <- conv4
I0628 21:42:12.925453 17220 net.cpp:367] scale4 -> conv4 (in-place)
I0628 21:42:12.925453 17220 layer_factory.cpp:58] Creating layer scale4
I0628 21:42:12.925453 17220 net.cpp:122] Setting up scale4
I0628 21:42:12.925453 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.925453 17220 net.cpp:137] Memory required for data: 216679600
I0628 21:42:12.925453 17220 layer_factory.cpp:58] Creating layer relu4
I0628 21:42:12.925453 17220 net.cpp:84] Creating Layer relu4
I0628 21:42:12.925453 17220 net.cpp:406] relu4 <- conv4
I0628 21:42:12.925453 17220 net.cpp:367] relu4 -> conv4 (in-place)
I0628 21:42:12.925453 17220 net.cpp:122] Setting up relu4
I0628 21:42:12.925453 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.925453 17220 net.cpp:137] Memory required for data: 219239600
I0628 21:42:12.925453 17220 layer_factory.cpp:58] Creating layer conv4_1
I0628 21:42:12.925453 17220 net.cpp:84] Creating Layer conv4_1
I0628 21:42:12.925453 17220 net.cpp:406] conv4_1 <- conv4
I0628 21:42:12.925453 17220 net.cpp:380] conv4_1 -> conv4_1
I0628 21:42:12.926453 17220 net.cpp:122] Setting up conv4_1
I0628 21:42:12.926955 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.926955 17220 net.cpp:137] Memory required for data: 221799600
I0628 21:42:12.926955 17220 layer_factory.cpp:58] Creating layer bn4_1
I0628 21:42:12.926955 17220 net.cpp:84] Creating Layer bn4_1
I0628 21:42:12.926955 17220 net.cpp:406] bn4_1 <- conv4_1
I0628 21:42:12.926955 17220 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0628 21:42:12.926955 17220 net.cpp:122] Setting up bn4_1
I0628 21:42:12.926955 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.926955 17220 net.cpp:137] Memory required for data: 224359600
I0628 21:42:12.926955 17220 layer_factory.cpp:58] Creating layer scale4_1
I0628 21:42:12.926955 17220 net.cpp:84] Creating Layer scale4_1
I0628 21:42:12.926955 17220 net.cpp:406] scale4_1 <- conv4_1
I0628 21:42:12.926955 17220 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0628 21:42:12.926955 17220 layer_factory.cpp:58] Creating layer scale4_1
I0628 21:42:12.927455 17220 net.cpp:122] Setting up scale4_1
I0628 21:42:12.927455 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.927455 17220 net.cpp:137] Memory required for data: 226919600
I0628 21:42:12.927455 17220 layer_factory.cpp:58] Creating layer relu4_1
I0628 21:42:12.927455 17220 net.cpp:84] Creating Layer relu4_1
I0628 21:42:12.927455 17220 net.cpp:406] relu4_1 <- conv4_1
I0628 21:42:12.927455 17220 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0628 21:42:12.927955 17220 net.cpp:122] Setting up relu4_1
I0628 21:42:12.927955 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.927955 17220 net.cpp:137] Memory required for data: 229479600
I0628 21:42:12.927955 17220 layer_factory.cpp:58] Creating layer conv4_2
I0628 21:42:12.927955 17220 net.cpp:84] Creating Layer conv4_2
I0628 21:42:12.927955 17220 net.cpp:406] conv4_2 <- conv4_1
I0628 21:42:12.927955 17220 net.cpp:380] conv4_2 -> conv4_2
I0628 21:42:12.928455 17220 net.cpp:122] Setting up conv4_2
I0628 21:42:12.928455 17220 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 21:42:12.928455 17220 net.cpp:137] Memory required for data: 236033200
I0628 21:42:12.928455 17220 layer_factory.cpp:58] Creating layer bn4_2
I0628 21:42:12.928455 17220 net.cpp:84] Creating Layer bn4_2
I0628 21:42:12.928455 17220 net.cpp:406] bn4_2 <- conv4_2
I0628 21:42:12.928455 17220 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0628 21:42:12.928956 17220 net.cpp:122] Setting up bn4_2
I0628 21:42:12.928956 17220 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 21:42:12.928956 17220 net.cpp:137] Memory required for data: 242586800
I0628 21:42:12.928956 17220 layer_factory.cpp:58] Creating layer scale4_2
I0628 21:42:12.928956 17220 net.cpp:84] Creating Layer scale4_2
I0628 21:42:12.928956 17220 net.cpp:406] scale4_2 <- conv4_2
I0628 21:42:12.928956 17220 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0628 21:42:12.928956 17220 layer_factory.cpp:58] Creating layer scale4_2
I0628 21:42:12.928956 17220 net.cpp:122] Setting up scale4_2
I0628 21:42:12.928956 17220 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 21:42:12.928956 17220 net.cpp:137] Memory required for data: 249140400
I0628 21:42:12.928956 17220 layer_factory.cpp:58] Creating layer relu4_2
I0628 21:42:12.928956 17220 net.cpp:84] Creating Layer relu4_2
I0628 21:42:12.928956 17220 net.cpp:406] relu4_2 <- conv4_2
I0628 21:42:12.928956 17220 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0628 21:42:12.929427 17220 net.cpp:122] Setting up relu4_2
I0628 21:42:12.929427 17220 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 21:42:12.929427 17220 net.cpp:137] Memory required for data: 255694000
I0628 21:42:12.929427 17220 layer_factory.cpp:58] Creating layer pool4_12
I0628 21:42:12.929427 17220 net.cpp:84] Creating Layer pool4_12
I0628 21:42:12.929427 17220 net.cpp:406] pool4_12 <- conv4_2
I0628 21:42:12.929427 17220 net.cpp:380] pool4_12 -> pool4_12
I0628 21:42:12.929427 17220 net.cpp:122] Setting up pool4_12
I0628 21:42:12.929427 17220 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0628 21:42:12.929427 17220 net.cpp:137] Memory required for data: 257332400
I0628 21:42:12.929427 17220 layer_factory.cpp:58] Creating layer conv4_0
I0628 21:42:12.929427 17220 net.cpp:84] Creating Layer conv4_0
I0628 21:42:12.929427 17220 net.cpp:406] conv4_0 <- pool4_12
I0628 21:42:12.929427 17220 net.cpp:380] conv4_0 -> conv4_0
I0628 21:42:12.931430 17220 net.cpp:122] Setting up conv4_0
I0628 21:42:12.931430 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.931430 17220 net.cpp:137] Memory required for data: 258689200
I0628 21:42:12.931430 17220 layer_factory.cpp:58] Creating layer bn4_0
I0628 21:42:12.931430 17220 net.cpp:84] Creating Layer bn4_0
I0628 21:42:12.931430 17220 net.cpp:406] bn4_0 <- conv4_0
I0628 21:42:12.931430 17220 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0628 21:42:12.931430 17220 net.cpp:122] Setting up bn4_0
I0628 21:42:12.931430 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.931430 17220 net.cpp:137] Memory required for data: 260046000
I0628 21:42:12.931430 17220 layer_factory.cpp:58] Creating layer scale4_0
I0628 21:42:12.931430 17220 net.cpp:84] Creating Layer scale4_0
I0628 21:42:12.931430 17220 net.cpp:406] scale4_0 <- conv4_0
I0628 21:42:12.931430 17220 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0628 21:42:12.931430 17220 layer_factory.cpp:58] Creating layer scale4_0
I0628 21:42:12.931931 17220 net.cpp:122] Setting up scale4_0
I0628 21:42:12.931931 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.931931 17220 net.cpp:137] Memory required for data: 261402800
I0628 21:42:12.931931 17220 layer_factory.cpp:58] Creating layer relu4_0
I0628 21:42:12.931931 17220 net.cpp:84] Creating Layer relu4_0
I0628 21:42:12.931931 17220 net.cpp:406] relu4_0 <- conv4_0
I0628 21:42:12.931931 17220 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0628 21:42:12.931931 17220 net.cpp:122] Setting up relu4_0
I0628 21:42:12.931931 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.931931 17220 net.cpp:137] Memory required for data: 262759600
I0628 21:42:12.931931 17220 layer_factory.cpp:58] Creating layer cccp4
I0628 21:42:12.931931 17220 net.cpp:84] Creating Layer cccp4
I0628 21:42:12.931931 17220 net.cpp:406] cccp4 <- conv4_0
I0628 21:42:12.931931 17220 net.cpp:380] cccp4 -> cccp4
I0628 21:42:12.933431 17220 net.cpp:122] Setting up cccp4
I0628 21:42:12.933431 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.933431 17220 net.cpp:137] Memory required for data: 264116400
I0628 21:42:12.933431 17220 layer_factory.cpp:58] Creating layer bn_cccp4
I0628 21:42:12.933431 17220 net.cpp:84] Creating Layer bn_cccp4
I0628 21:42:12.933431 17220 net.cpp:406] bn_cccp4 <- cccp4
I0628 21:42:12.933431 17220 net.cpp:367] bn_cccp4 -> cccp4 (in-place)
I0628 21:42:12.933431 17220 net.cpp:122] Setting up bn_cccp4
I0628 21:42:12.933431 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.933431 17220 net.cpp:137] Memory required for data: 265473200
I0628 21:42:12.933431 17220 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 21:42:12.933431 17220 net.cpp:84] Creating Layer scale_cccp4
I0628 21:42:12.933431 17220 net.cpp:406] scale_cccp4 <- cccp4
I0628 21:42:12.933431 17220 net.cpp:367] scale_cccp4 -> cccp4 (in-place)
I0628 21:42:12.933431 17220 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 21:42:12.933933 17220 net.cpp:122] Setting up scale_cccp4
I0628 21:42:12.933933 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.933933 17220 net.cpp:137] Memory required for data: 266830000
I0628 21:42:12.933933 17220 layer_factory.cpp:58] Creating layer relu_cccp4
I0628 21:42:12.933933 17220 net.cpp:84] Creating Layer relu_cccp4
I0628 21:42:12.933933 17220 net.cpp:406] relu_cccp4 <- cccp4
I0628 21:42:12.933933 17220 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0628 21:42:12.933933 17220 net.cpp:122] Setting up relu_cccp4
I0628 21:42:12.933933 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.933933 17220 net.cpp:137] Memory required for data: 268186800
I0628 21:42:12.933933 17220 layer_factory.cpp:58] Creating layer pool4_2
I0628 21:42:12.933933 17220 net.cpp:84] Creating Layer pool4_2
I0628 21:42:12.933933 17220 net.cpp:406] pool4_2 <- cccp4
I0628 21:42:12.933933 17220 net.cpp:380] pool4_2 -> pool4_2
I0628 21:42:12.933933 17220 net.cpp:122] Setting up pool4_2
I0628 21:42:12.933933 17220 net.cpp:129] Top shape: 100 53 4 4 (84800)
I0628 21:42:12.933933 17220 net.cpp:137] Memory required for data: 268526000
I0628 21:42:12.933933 17220 layer_factory.cpp:58] Creating layer cccp5
I0628 21:42:12.933933 17220 net.cpp:84] Creating Layer cccp5
I0628 21:42:12.933933 17220 net.cpp:406] cccp5 <- pool4_2
I0628 21:42:12.933933 17220 net.cpp:380] cccp5 -> cccp5
I0628 21:42:12.935436 17220 net.cpp:122] Setting up cccp5
I0628 21:42:12.935436 17220 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 21:42:12.935436 17220 net.cpp:137] Memory required for data: 270081200
I0628 21:42:12.935436 17220 layer_factory.cpp:58] Creating layer bn_cccp5
I0628 21:42:12.935436 17220 net.cpp:84] Creating Layer bn_cccp5
I0628 21:42:12.935436 17220 net.cpp:406] bn_cccp5 <- cccp5
I0628 21:42:12.935436 17220 net.cpp:367] bn_cccp5 -> cccp5 (in-place)
I0628 21:42:12.935436 17220 net.cpp:122] Setting up bn_cccp5
I0628 21:42:12.935436 17220 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 21:42:12.935436 17220 net.cpp:137] Memory required for data: 271636400
I0628 21:42:12.935436 17220 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 21:42:12.935436 17220 net.cpp:84] Creating Layer scale_cccp5
I0628 21:42:12.935436 17220 net.cpp:406] scale_cccp5 <- cccp5
I0628 21:42:12.935436 17220 net.cpp:367] scale_cccp5 -> cccp5 (in-place)
I0628 21:42:12.935436 17220 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 21:42:12.935935 17220 net.cpp:122] Setting up scale_cccp5
I0628 21:42:12.935935 17220 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 21:42:12.935935 17220 net.cpp:137] Memory required for data: 273191600
I0628 21:42:12.935935 17220 layer_factory.cpp:58] Creating layer relu_cccp5
I0628 21:42:12.935935 17220 net.cpp:84] Creating Layer relu_cccp5
I0628 21:42:12.935935 17220 net.cpp:406] relu_cccp5 <- cccp5
I0628 21:42:12.935935 17220 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0628 21:42:12.935935 17220 net.cpp:122] Setting up relu_cccp5
I0628 21:42:12.935935 17220 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 21:42:12.935935 17220 net.cpp:137] Memory required for data: 274746800
I0628 21:42:12.935935 17220 layer_factory.cpp:58] Creating layer poolcp5
I0628 21:42:12.935935 17220 net.cpp:84] Creating Layer poolcp5
I0628 21:42:12.935935 17220 net.cpp:406] poolcp5 <- cccp5
I0628 21:42:12.935935 17220 net.cpp:380] poolcp5 -> poolcp5
I0628 21:42:12.935935 17220 net.cpp:122] Setting up poolcp5
I0628 21:42:12.935935 17220 net.cpp:129] Top shape: 100 108 3 3 (97200)
I0628 21:42:12.935935 17220 net.cpp:137] Memory required for data: 275135600
I0628 21:42:12.935935 17220 layer_factory.cpp:58] Creating layer cccp6
I0628 21:42:12.935935 17220 net.cpp:84] Creating Layer cccp6
I0628 21:42:12.935935 17220 net.cpp:406] cccp6 <- poolcp5
I0628 21:42:12.935935 17220 net.cpp:380] cccp6 -> cccp6
I0628 21:42:12.937434 17220 net.cpp:122] Setting up cccp6
I0628 21:42:12.937434 17220 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 21:42:12.937434 17220 net.cpp:137] Memory required for data: 276215600
I0628 21:42:12.937434 17220 layer_factory.cpp:58] Creating layer bn_cccp6
I0628 21:42:12.937434 17220 net.cpp:84] Creating Layer bn_cccp6
I0628 21:42:12.937434 17220 net.cpp:406] bn_cccp6 <- cccp6
I0628 21:42:12.937434 17220 net.cpp:367] bn_cccp6 -> cccp6 (in-place)
I0628 21:42:12.937949 17220 net.cpp:122] Setting up bn_cccp6
I0628 21:42:12.937949 17220 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 21:42:12.937949 17220 net.cpp:137] Memory required for data: 277295600
I0628 21:42:12.937949 17220 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 21:42:12.937949 17220 net.cpp:84] Creating Layer scale_cccp6
I0628 21:42:12.937949 17220 net.cpp:406] scale_cccp6 <- cccp6
I0628 21:42:12.937949 17220 net.cpp:367] scale_cccp6 -> cccp6 (in-place)
I0628 21:42:12.937949 17220 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 21:42:12.937949 17220 net.cpp:122] Setting up scale_cccp6
I0628 21:42:12.937949 17220 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 21:42:12.937949 17220 net.cpp:137] Memory required for data: 278375600
I0628 21:42:12.937949 17220 layer_factory.cpp:58] Creating layer relu_cccp6
I0628 21:42:12.937949 17220 net.cpp:84] Creating Layer relu_cccp6
I0628 21:42:12.937949 17220 net.cpp:406] relu_cccp6 <- cccp6
I0628 21:42:12.937949 17220 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0628 21:42:12.937949 17220 net.cpp:122] Setting up relu_cccp6
I0628 21:42:12.937949 17220 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 21:42:12.937949 17220 net.cpp:137] Memory required for data: 279455600
I0628 21:42:12.937949 17220 layer_factory.cpp:58] Creating layer poolcp6
I0628 21:42:12.937949 17220 net.cpp:84] Creating Layer poolcp6
I0628 21:42:12.937949 17220 net.cpp:406] poolcp6 <- cccp6
I0628 21:42:12.937949 17220 net.cpp:380] poolcp6 -> poolcp6
I0628 21:42:12.938437 17220 net.cpp:122] Setting up poolcp6
I0628 21:42:12.938437 17220 net.cpp:129] Top shape: 100 108 1 1 (10800)
I0628 21:42:12.938437 17220 net.cpp:137] Memory required for data: 279498800
I0628 21:42:12.938437 17220 layer_factory.cpp:58] Creating layer ip1
I0628 21:42:12.938437 17220 net.cpp:84] Creating Layer ip1
I0628 21:42:12.938437 17220 net.cpp:406] ip1 <- poolcp6
I0628 21:42:12.938437 17220 net.cpp:380] ip1 -> ip1
I0628 21:42:12.938935 17220 net.cpp:122] Setting up ip1
I0628 21:42:12.938935 17220 net.cpp:129] Top shape: 100 10 (1000)
I0628 21:42:12.938935 17220 net.cpp:137] Memory required for data: 279502800
I0628 21:42:12.938935 17220 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0628 21:42:12.939451 17220 net.cpp:84] Creating Layer ip1_ip1_0_split
I0628 21:42:12.939451 17220 net.cpp:406] ip1_ip1_0_split <- ip1
I0628 21:42:12.939451 17220 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0628 21:42:12.939451 17220 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0628 21:42:12.939451 17220 net.cpp:122] Setting up ip1_ip1_0_split
I0628 21:42:12.939451 17220 net.cpp:129] Top shape: 100 10 (1000)
I0628 21:42:12.939451 17220 net.cpp:129] Top shape: 100 10 (1000)
I0628 21:42:12.939451 17220 net.cpp:137] Memory required for data: 279510800
I0628 21:42:12.939451 17220 layer_factory.cpp:58] Creating layer accuracy_training
I0628 21:42:12.939451 17220 net.cpp:84] Creating Layer accuracy_training
I0628 21:42:12.939451 17220 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0628 21:42:12.939451 17220 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I0628 21:42:12.939451 17220 net.cpp:380] accuracy_training -> accuracy_training
I0628 21:42:12.939451 17220 net.cpp:122] Setting up accuracy_training
I0628 21:42:12.939451 17220 net.cpp:129] Top shape: (1)
I0628 21:42:12.939451 17220 net.cpp:137] Memory required for data: 279510804
I0628 21:42:12.939451 17220 layer_factory.cpp:58] Creating layer loss
I0628 21:42:12.939451 17220 net.cpp:84] Creating Layer loss
I0628 21:42:12.939451 17220 net.cpp:406] loss <- ip1_ip1_0_split_1
I0628 21:42:12.939451 17220 net.cpp:406] loss <- label_cifar_1_split_1
I0628 21:42:12.939451 17220 net.cpp:380] loss -> loss
I0628 21:42:12.939451 17220 layer_factory.cpp:58] Creating layer loss
I0628 21:42:12.939936 17220 net.cpp:122] Setting up loss
I0628 21:42:12.939936 17220 net.cpp:129] Top shape: (1)
I0628 21:42:12.939936 17220 net.cpp:132]     with loss weight 1
I0628 21:42:12.939936 17220 net.cpp:137] Memory required for data: 279510808
I0628 21:42:12.939936 17220 net.cpp:198] loss needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:200] accuracy_training does not need backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] ip1 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] poolcp6 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] relu_cccp6 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] scale_cccp6 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] bn_cccp6 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] cccp6 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] poolcp5 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] relu_cccp5 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] scale_cccp5 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] bn_cccp5 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] cccp5 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] pool4_2 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] relu_cccp4 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] scale_cccp4 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] bn_cccp4 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] cccp4 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] relu4_0 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] scale4_0 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] bn4_0 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] conv4_0 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] pool4_12 needs backward computation.
I0628 21:42:12.939936 17220 net.cpp:198] relu4_2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] scale4_2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] bn4_2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] conv4_2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] relu4_1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] scale4_1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] bn4_1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] conv4_1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] relu4 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] scale4 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] bn4 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] conv4 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] relu3 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] scale3 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] bn3 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] conv3 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] pool2_1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] relu2_2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] scale2_2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] bn2_2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] conv2_2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] relu2_1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] scale2_1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] bn2_1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] conv2_1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] relu2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] scale2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] bn2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] conv2 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] relu1_0 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] scale1_0 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] bn1_0 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] conv1_0 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] relu1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] scale1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] bn1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:198] conv1 needs backward computation.
I0628 21:42:12.940451 17220 net.cpp:200] label_cifar_1_split does not need backward computation.
I0628 21:42:12.940451 17220 net.cpp:200] cifar does not need backward computation.
I0628 21:42:12.940451 17220 net.cpp:242] This network produces output accuracy_training
I0628 21:42:12.940451 17220 net.cpp:242] This network produces output loss
I0628 21:42:12.940451 17220 net.cpp:255] Network initialization done.
I0628 21:42:12.941452 17220 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 21:42:12.941452 17220 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0628 21:42:12.941452 17220 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp4
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp5
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp6
I0628 21:42:12.941452 17220 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0628 21:42:12.941952 17220 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_13_128k_end1x1"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_12"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_12"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 53
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "conv4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 53
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp4"
  type: "Scale"
  bottom: "cccp4"
  top: "cccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "cccp4"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "pool4_2"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp5"
  type: "Scale"
  bottom: "cccp5"
  top: "cccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp6"
  type: "Scale"
  bottom: "cccp6"
  top: "cccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0628 21:42:12.941952 17220 layer_factory.cpp:58] Creating layer cifar
I0628 21:42:12.946943 17220 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I0628 21:42:12.947443 17220 net.cpp:84] Creating Layer cifar
I0628 21:42:12.947443 17220 net.cpp:380] cifar -> data
I0628 21:42:12.947443 17220 net.cpp:380] cifar -> label
I0628 21:42:12.947443 17220 data_layer.cpp:45] output data size: 100,3,32,32
I0628 21:42:12.952864 17220 net.cpp:122] Setting up cifar
I0628 21:42:12.952864 17220 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0628 21:42:12.952864 17220 net.cpp:129] Top shape: 100 (100)
I0628 21:42:12.952864 17220 net.cpp:137] Memory required for data: 1229200
I0628 21:42:12.952864 17220 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0628 21:42:12.952864 17220 net.cpp:84] Creating Layer label_cifar_1_split
I0628 21:42:12.952864 17220 net.cpp:406] label_cifar_1_split <- label
I0628 21:42:12.952864 17220 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0628 21:42:12.952864 17220 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0628 21:42:12.952864 17220 net.cpp:122] Setting up label_cifar_1_split
I0628 21:42:12.952864 17220 net.cpp:129] Top shape: 100 (100)
I0628 21:42:12.952864 17220 net.cpp:129] Top shape: 100 (100)
I0628 21:42:12.952864 17220 net.cpp:137] Memory required for data: 1230000
I0628 21:42:12.952864 17220 layer_factory.cpp:58] Creating layer conv1
I0628 21:42:12.952864 17220 net.cpp:84] Creating Layer conv1
I0628 21:42:12.952864 17220 net.cpp:406] conv1 <- data
I0628 21:42:12.952864 17220 net.cpp:380] conv1 -> conv1
I0628 21:42:12.953865 10900 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 21:42:12.954051 17220 net.cpp:122] Setting up conv1
I0628 21:42:12.954051 17220 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 21:42:12.954051 17220 net.cpp:137] Memory required for data: 9012400
I0628 21:42:12.954551 17220 layer_factory.cpp:58] Creating layer bn1
I0628 21:42:12.954551 17220 net.cpp:84] Creating Layer bn1
I0628 21:42:12.954551 17220 net.cpp:406] bn1 <- conv1
I0628 21:42:12.954551 17220 net.cpp:367] bn1 -> conv1 (in-place)
I0628 21:42:12.954551 17220 net.cpp:122] Setting up bn1
I0628 21:42:12.954551 17220 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 21:42:12.954551 17220 net.cpp:137] Memory required for data: 16794800
I0628 21:42:12.954551 17220 layer_factory.cpp:58] Creating layer scale1
I0628 21:42:12.954551 17220 net.cpp:84] Creating Layer scale1
I0628 21:42:12.954551 17220 net.cpp:406] scale1 <- conv1
I0628 21:42:12.954551 17220 net.cpp:367] scale1 -> conv1 (in-place)
I0628 21:42:12.954551 17220 layer_factory.cpp:58] Creating layer scale1
I0628 21:42:12.955052 17220 net.cpp:122] Setting up scale1
I0628 21:42:12.955052 17220 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 21:42:12.955052 17220 net.cpp:137] Memory required for data: 24577200
I0628 21:42:12.955052 17220 layer_factory.cpp:58] Creating layer relu1
I0628 21:42:12.955052 17220 net.cpp:84] Creating Layer relu1
I0628 21:42:12.955052 17220 net.cpp:406] relu1 <- conv1
I0628 21:42:12.955052 17220 net.cpp:367] relu1 -> conv1 (in-place)
I0628 21:42:12.955052 17220 net.cpp:122] Setting up relu1
I0628 21:42:12.955052 17220 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 21:42:12.955052 17220 net.cpp:137] Memory required for data: 32359600
I0628 21:42:12.955052 17220 layer_factory.cpp:58] Creating layer conv1_0
I0628 21:42:12.955052 17220 net.cpp:84] Creating Layer conv1_0
I0628 21:42:12.955052 17220 net.cpp:406] conv1_0 <- conv1
I0628 21:42:12.955052 17220 net.cpp:380] conv1_0 -> conv1_0
I0628 21:42:12.956553 17220 net.cpp:122] Setting up conv1_0
I0628 21:42:12.956553 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.956553 17220 net.cpp:137] Memory required for data: 42599600
I0628 21:42:12.956553 17220 layer_factory.cpp:58] Creating layer bn1_0
I0628 21:42:12.956553 17220 net.cpp:84] Creating Layer bn1_0
I0628 21:42:12.956553 17220 net.cpp:406] bn1_0 <- conv1_0
I0628 21:42:12.956553 17220 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0628 21:42:12.956553 17220 net.cpp:122] Setting up bn1_0
I0628 21:42:12.956553 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.956553 17220 net.cpp:137] Memory required for data: 52839600
I0628 21:42:12.956553 17220 layer_factory.cpp:58] Creating layer scale1_0
I0628 21:42:12.956553 17220 net.cpp:84] Creating Layer scale1_0
I0628 21:42:12.956553 17220 net.cpp:406] scale1_0 <- conv1_0
I0628 21:42:12.956553 17220 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0628 21:42:12.956553 17220 layer_factory.cpp:58] Creating layer scale1_0
I0628 21:42:12.956553 17220 net.cpp:122] Setting up scale1_0
I0628 21:42:12.956553 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.956553 17220 net.cpp:137] Memory required for data: 63079600
I0628 21:42:12.956553 17220 layer_factory.cpp:58] Creating layer relu1_0
I0628 21:42:12.956553 17220 net.cpp:84] Creating Layer relu1_0
I0628 21:42:12.956553 17220 net.cpp:406] relu1_0 <- conv1_0
I0628 21:42:12.956553 17220 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0628 21:42:12.957053 17220 net.cpp:122] Setting up relu1_0
I0628 21:42:12.957053 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.957053 17220 net.cpp:137] Memory required for data: 73319600
I0628 21:42:12.957053 17220 layer_factory.cpp:58] Creating layer conv2
I0628 21:42:12.957053 17220 net.cpp:84] Creating Layer conv2
I0628 21:42:12.957053 17220 net.cpp:406] conv2 <- conv1_0
I0628 21:42:12.957053 17220 net.cpp:380] conv2 -> conv2
I0628 21:42:12.958479 17220 net.cpp:122] Setting up conv2
I0628 21:42:12.958479 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.958479 17220 net.cpp:137] Memory required for data: 83559600
I0628 21:42:12.958479 17220 layer_factory.cpp:58] Creating layer bn2
I0628 21:42:12.958479 17220 net.cpp:84] Creating Layer bn2
I0628 21:42:12.958479 17220 net.cpp:406] bn2 <- conv2
I0628 21:42:12.958479 17220 net.cpp:367] bn2 -> conv2 (in-place)
I0628 21:42:12.958981 17220 net.cpp:122] Setting up bn2
I0628 21:42:12.958981 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.958981 17220 net.cpp:137] Memory required for data: 93799600
I0628 21:42:12.958981 17220 layer_factory.cpp:58] Creating layer scale2
I0628 21:42:12.958981 17220 net.cpp:84] Creating Layer scale2
I0628 21:42:12.958981 17220 net.cpp:406] scale2 <- conv2
I0628 21:42:12.958981 17220 net.cpp:367] scale2 -> conv2 (in-place)
I0628 21:42:12.958981 17220 layer_factory.cpp:58] Creating layer scale2
I0628 21:42:12.959481 17220 net.cpp:122] Setting up scale2
I0628 21:42:12.959481 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.959481 17220 net.cpp:137] Memory required for data: 104039600
I0628 21:42:12.959481 17220 layer_factory.cpp:58] Creating layer relu2
I0628 21:42:12.959481 17220 net.cpp:84] Creating Layer relu2
I0628 21:42:12.959481 17220 net.cpp:406] relu2 <- conv2
I0628 21:42:12.959481 17220 net.cpp:367] relu2 -> conv2 (in-place)
I0628 21:42:12.959481 17220 net.cpp:122] Setting up relu2
I0628 21:42:12.959481 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.959481 17220 net.cpp:137] Memory required for data: 114279600
I0628 21:42:12.959481 17220 layer_factory.cpp:58] Creating layer conv2_1
I0628 21:42:12.959481 17220 net.cpp:84] Creating Layer conv2_1
I0628 21:42:12.959481 17220 net.cpp:406] conv2_1 <- conv2
I0628 21:42:12.959481 17220 net.cpp:380] conv2_1 -> conv2_1
I0628 21:42:12.961483 17220 net.cpp:122] Setting up conv2_1
I0628 21:42:12.961483 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.961483 17220 net.cpp:137] Memory required for data: 124519600
I0628 21:42:12.961483 17220 layer_factory.cpp:58] Creating layer bn2_1
I0628 21:42:12.961483 17220 net.cpp:84] Creating Layer bn2_1
I0628 21:42:12.961483 17220 net.cpp:406] bn2_1 <- conv2_1
I0628 21:42:12.961483 17220 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0628 21:42:12.961982 17220 net.cpp:122] Setting up bn2_1
I0628 21:42:12.961982 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.961982 17220 net.cpp:137] Memory required for data: 134759600
I0628 21:42:12.961982 17220 layer_factory.cpp:58] Creating layer scale2_1
I0628 21:42:12.961982 17220 net.cpp:84] Creating Layer scale2_1
I0628 21:42:12.961982 17220 net.cpp:406] scale2_1 <- conv2_1
I0628 21:42:12.961982 17220 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0628 21:42:12.961982 17220 layer_factory.cpp:58] Creating layer scale2_1
I0628 21:42:12.961982 17220 net.cpp:122] Setting up scale2_1
I0628 21:42:12.961982 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.961982 17220 net.cpp:137] Memory required for data: 144999600
I0628 21:42:12.961982 17220 layer_factory.cpp:58] Creating layer relu2_1
I0628 21:42:12.961982 17220 net.cpp:84] Creating Layer relu2_1
I0628 21:42:12.961982 17220 net.cpp:406] relu2_1 <- conv2_1
I0628 21:42:12.961982 17220 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0628 21:42:12.962482 17220 net.cpp:122] Setting up relu2_1
I0628 21:42:12.962482 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.962482 17220 net.cpp:137] Memory required for data: 155239600
I0628 21:42:12.962482 17220 layer_factory.cpp:58] Creating layer conv2_2
I0628 21:42:12.962482 17220 net.cpp:84] Creating Layer conv2_2
I0628 21:42:12.962482 17220 net.cpp:406] conv2_2 <- conv2_1
I0628 21:42:12.962482 17220 net.cpp:380] conv2_2 -> conv2_2
I0628 21:42:12.963984 17220 net.cpp:122] Setting up conv2_2
I0628 21:42:12.963984 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.963984 17220 net.cpp:137] Memory required for data: 165479600
I0628 21:42:12.963984 17220 layer_factory.cpp:58] Creating layer bn2_2
I0628 21:42:12.963984 17220 net.cpp:84] Creating Layer bn2_2
I0628 21:42:12.963984 17220 net.cpp:406] bn2_2 <- conv2_2
I0628 21:42:12.963984 17220 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0628 21:42:12.963984 17220 net.cpp:122] Setting up bn2_2
I0628 21:42:12.963984 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.963984 17220 net.cpp:137] Memory required for data: 175719600
I0628 21:42:12.963984 17220 layer_factory.cpp:58] Creating layer scale2_2
I0628 21:42:12.963984 17220 net.cpp:84] Creating Layer scale2_2
I0628 21:42:12.963984 17220 net.cpp:406] scale2_2 <- conv2_2
I0628 21:42:12.963984 17220 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0628 21:42:12.964484 17220 layer_factory.cpp:58] Creating layer scale2_2
I0628 21:42:12.964484 17220 net.cpp:122] Setting up scale2_2
I0628 21:42:12.964484 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.964484 17220 net.cpp:137] Memory required for data: 185959600
I0628 21:42:12.964484 17220 layer_factory.cpp:58] Creating layer relu2_2
I0628 21:42:12.964484 17220 net.cpp:84] Creating Layer relu2_2
I0628 21:42:12.964484 17220 net.cpp:406] relu2_2 <- conv2_2
I0628 21:42:12.964484 17220 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0628 21:42:12.964984 17220 net.cpp:122] Setting up relu2_2
I0628 21:42:12.964984 17220 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 21:42:12.964984 17220 net.cpp:137] Memory required for data: 196199600
I0628 21:42:12.964984 17220 layer_factory.cpp:58] Creating layer pool2_1
I0628 21:42:12.964984 17220 net.cpp:84] Creating Layer pool2_1
I0628 21:42:12.964984 17220 net.cpp:406] pool2_1 <- conv2_2
I0628 21:42:12.964984 17220 net.cpp:380] pool2_1 -> pool2_1
I0628 21:42:12.964984 17220 net.cpp:122] Setting up pool2_1
I0628 21:42:12.964984 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.964984 17220 net.cpp:137] Memory required for data: 198759600
I0628 21:42:12.964984 17220 layer_factory.cpp:58] Creating layer conv3
I0628 21:42:12.964984 17220 net.cpp:84] Creating Layer conv3
I0628 21:42:12.964984 17220 net.cpp:406] conv3 <- pool2_1
I0628 21:42:12.964984 17220 net.cpp:380] conv3 -> conv3
I0628 21:42:12.965986 17220 net.cpp:122] Setting up conv3
I0628 21:42:12.965986 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.965986 17220 net.cpp:137] Memory required for data: 201319600
I0628 21:42:12.965986 17220 layer_factory.cpp:58] Creating layer bn3
I0628 21:42:12.965986 17220 net.cpp:84] Creating Layer bn3
I0628 21:42:12.965986 17220 net.cpp:406] bn3 <- conv3
I0628 21:42:12.965986 17220 net.cpp:367] bn3 -> conv3 (in-place)
I0628 21:42:12.966485 17220 net.cpp:122] Setting up bn3
I0628 21:42:12.966485 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.966485 17220 net.cpp:137] Memory required for data: 203879600
I0628 21:42:12.966485 17220 layer_factory.cpp:58] Creating layer scale3
I0628 21:42:12.966485 17220 net.cpp:84] Creating Layer scale3
I0628 21:42:12.966485 17220 net.cpp:406] scale3 <- conv3
I0628 21:42:12.966485 17220 net.cpp:367] scale3 -> conv3 (in-place)
I0628 21:42:12.966485 17220 layer_factory.cpp:58] Creating layer scale3
I0628 21:42:12.966485 17220 net.cpp:122] Setting up scale3
I0628 21:42:12.966485 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.966485 17220 net.cpp:137] Memory required for data: 206439600
I0628 21:42:12.966485 17220 layer_factory.cpp:58] Creating layer relu3
I0628 21:42:12.966485 17220 net.cpp:84] Creating Layer relu3
I0628 21:42:12.966485 17220 net.cpp:406] relu3 <- conv3
I0628 21:42:12.966485 17220 net.cpp:367] relu3 -> conv3 (in-place)
I0628 21:42:12.967486 17220 net.cpp:122] Setting up relu3
I0628 21:42:12.967486 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.967486 17220 net.cpp:137] Memory required for data: 208999600
I0628 21:42:12.967486 17220 layer_factory.cpp:58] Creating layer conv4
I0628 21:42:12.967486 17220 net.cpp:84] Creating Layer conv4
I0628 21:42:12.967486 17220 net.cpp:406] conv4 <- conv3
I0628 21:42:12.967486 17220 net.cpp:380] conv4 -> conv4
I0628 21:42:12.968487 17220 net.cpp:122] Setting up conv4
I0628 21:42:12.968487 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.968487 17220 net.cpp:137] Memory required for data: 211559600
I0628 21:42:12.968487 17220 layer_factory.cpp:58] Creating layer bn4
I0628 21:42:12.968487 17220 net.cpp:84] Creating Layer bn4
I0628 21:42:12.968487 17220 net.cpp:406] bn4 <- conv4
I0628 21:42:12.968487 17220 net.cpp:367] bn4 -> conv4 (in-place)
I0628 21:42:12.968987 17220 net.cpp:122] Setting up bn4
I0628 21:42:12.968987 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.968987 17220 net.cpp:137] Memory required for data: 214119600
I0628 21:42:12.968987 17220 layer_factory.cpp:58] Creating layer scale4
I0628 21:42:12.968987 17220 net.cpp:84] Creating Layer scale4
I0628 21:42:12.968987 17220 net.cpp:406] scale4 <- conv4
I0628 21:42:12.968987 17220 net.cpp:367] scale4 -> conv4 (in-place)
I0628 21:42:12.968987 17220 layer_factory.cpp:58] Creating layer scale4
I0628 21:42:12.968987 17220 net.cpp:122] Setting up scale4
I0628 21:42:12.968987 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.968987 17220 net.cpp:137] Memory required for data: 216679600
I0628 21:42:12.968987 17220 layer_factory.cpp:58] Creating layer relu4
I0628 21:42:12.968987 17220 net.cpp:84] Creating Layer relu4
I0628 21:42:12.969487 17220 net.cpp:406] relu4 <- conv4
I0628 21:42:12.969487 17220 net.cpp:367] relu4 -> conv4 (in-place)
I0628 21:42:12.969487 17220 net.cpp:122] Setting up relu4
I0628 21:42:12.969487 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.969487 17220 net.cpp:137] Memory required for data: 219239600
I0628 21:42:12.969487 17220 layer_factory.cpp:58] Creating layer conv4_1
I0628 21:42:12.969487 17220 net.cpp:84] Creating Layer conv4_1
I0628 21:42:12.969487 17220 net.cpp:406] conv4_1 <- conv4
I0628 21:42:12.969487 17220 net.cpp:380] conv4_1 -> conv4_1
I0628 21:42:12.970998 17220 net.cpp:122] Setting up conv4_1
I0628 21:42:12.970998 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.970998 17220 net.cpp:137] Memory required for data: 221799600
I0628 21:42:12.970998 17220 layer_factory.cpp:58] Creating layer bn4_1
I0628 21:42:12.970998 17220 net.cpp:84] Creating Layer bn4_1
I0628 21:42:12.970998 17220 net.cpp:406] bn4_1 <- conv4_1
I0628 21:42:12.970998 17220 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0628 21:42:12.970998 17220 net.cpp:122] Setting up bn4_1
I0628 21:42:12.970998 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.970998 17220 net.cpp:137] Memory required for data: 224359600
I0628 21:42:12.970998 17220 layer_factory.cpp:58] Creating layer scale4_1
I0628 21:42:12.970998 17220 net.cpp:84] Creating Layer scale4_1
I0628 21:42:12.970998 17220 net.cpp:406] scale4_1 <- conv4_1
I0628 21:42:12.970998 17220 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0628 21:42:12.971501 17220 layer_factory.cpp:58] Creating layer scale4_1
I0628 21:42:12.971501 17220 net.cpp:122] Setting up scale4_1
I0628 21:42:12.971501 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.971501 17220 net.cpp:137] Memory required for data: 226919600
I0628 21:42:12.971501 17220 layer_factory.cpp:58] Creating layer relu4_1
I0628 21:42:12.971501 17220 net.cpp:84] Creating Layer relu4_1
I0628 21:42:12.971501 17220 net.cpp:406] relu4_1 <- conv4_1
I0628 21:42:12.971501 17220 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0628 21:42:12.971501 17220 net.cpp:122] Setting up relu4_1
I0628 21:42:12.971501 17220 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 21:42:12.971501 17220 net.cpp:137] Memory required for data: 229479600
I0628 21:42:12.971501 17220 layer_factory.cpp:58] Creating layer conv4_2
I0628 21:42:12.971501 17220 net.cpp:84] Creating Layer conv4_2
I0628 21:42:12.971501 17220 net.cpp:406] conv4_2 <- conv4_1
I0628 21:42:12.971501 17220 net.cpp:380] conv4_2 -> conv4_2
I0628 21:42:12.972491 17220 net.cpp:122] Setting up conv4_2
I0628 21:42:12.972491 17220 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 21:42:12.972491 17220 net.cpp:137] Memory required for data: 236033200
I0628 21:42:12.972491 17220 layer_factory.cpp:58] Creating layer bn4_2
I0628 21:42:12.972491 17220 net.cpp:84] Creating Layer bn4_2
I0628 21:42:12.973002 17220 net.cpp:406] bn4_2 <- conv4_2
I0628 21:42:12.973002 17220 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0628 21:42:12.973002 17220 net.cpp:122] Setting up bn4_2
I0628 21:42:12.973002 17220 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 21:42:12.973002 17220 net.cpp:137] Memory required for data: 242586800
I0628 21:42:12.973002 17220 layer_factory.cpp:58] Creating layer scale4_2
I0628 21:42:12.973002 17220 net.cpp:84] Creating Layer scale4_2
I0628 21:42:12.973002 17220 net.cpp:406] scale4_2 <- conv4_2
I0628 21:42:12.973002 17220 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0628 21:42:12.973002 17220 layer_factory.cpp:58] Creating layer scale4_2
I0628 21:42:12.973002 17220 net.cpp:122] Setting up scale4_2
I0628 21:42:12.973002 17220 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 21:42:12.973002 17220 net.cpp:137] Memory required for data: 249140400
I0628 21:42:12.973002 17220 layer_factory.cpp:58] Creating layer relu4_2
I0628 21:42:12.973002 17220 net.cpp:84] Creating Layer relu4_2
I0628 21:42:12.973002 17220 net.cpp:406] relu4_2 <- conv4_2
I0628 21:42:12.973002 17220 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0628 21:42:12.973503 17220 net.cpp:122] Setting up relu4_2
I0628 21:42:12.973503 17220 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 21:42:12.973503 17220 net.cpp:137] Memory required for data: 255694000
I0628 21:42:12.973503 17220 layer_factory.cpp:58] Creating layer pool4_12
I0628 21:42:12.973503 17220 net.cpp:84] Creating Layer pool4_12
I0628 21:42:12.973503 17220 net.cpp:406] pool4_12 <- conv4_2
I0628 21:42:12.973503 17220 net.cpp:380] pool4_12 -> pool4_12
I0628 21:42:12.973503 17220 net.cpp:122] Setting up pool4_12
I0628 21:42:12.973503 17220 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0628 21:42:12.973503 17220 net.cpp:137] Memory required for data: 257332400
I0628 21:42:12.973503 17220 layer_factory.cpp:58] Creating layer conv4_0
I0628 21:42:12.973503 17220 net.cpp:84] Creating Layer conv4_0
I0628 21:42:12.973503 17220 net.cpp:406] conv4_0 <- pool4_12
I0628 21:42:12.973503 17220 net.cpp:380] conv4_0 -> conv4_0
I0628 21:42:12.974493 17220 net.cpp:122] Setting up conv4_0
I0628 21:42:12.974493 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.974493 17220 net.cpp:137] Memory required for data: 258689200
I0628 21:42:12.974493 17220 layer_factory.cpp:58] Creating layer bn4_0
I0628 21:42:12.974493 17220 net.cpp:84] Creating Layer bn4_0
I0628 21:42:12.974493 17220 net.cpp:406] bn4_0 <- conv4_0
I0628 21:42:12.974493 17220 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0628 21:42:12.975002 17220 net.cpp:122] Setting up bn4_0
I0628 21:42:12.975002 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.975002 17220 net.cpp:137] Memory required for data: 260046000
I0628 21:42:12.975002 17220 layer_factory.cpp:58] Creating layer scale4_0
I0628 21:42:12.975002 17220 net.cpp:84] Creating Layer scale4_0
I0628 21:42:12.975002 17220 net.cpp:406] scale4_0 <- conv4_0
I0628 21:42:12.975002 17220 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0628 21:42:12.975002 17220 layer_factory.cpp:58] Creating layer scale4_0
I0628 21:42:12.975002 17220 net.cpp:122] Setting up scale4_0
I0628 21:42:12.975002 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.975002 17220 net.cpp:137] Memory required for data: 261402800
I0628 21:42:12.975002 17220 layer_factory.cpp:58] Creating layer relu4_0
I0628 21:42:12.975002 17220 net.cpp:84] Creating Layer relu4_0
I0628 21:42:12.975002 17220 net.cpp:406] relu4_0 <- conv4_0
I0628 21:42:12.975002 17220 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0628 21:42:12.975502 17220 net.cpp:122] Setting up relu4_0
I0628 21:42:12.975502 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.975502 17220 net.cpp:137] Memory required for data: 262759600
I0628 21:42:12.975502 17220 layer_factory.cpp:58] Creating layer cccp4
I0628 21:42:12.975502 17220 net.cpp:84] Creating Layer cccp4
I0628 21:42:12.975502 17220 net.cpp:406] cccp4 <- conv4_0
I0628 21:42:12.975502 17220 net.cpp:380] cccp4 -> cccp4
I0628 21:42:12.976493 17220 net.cpp:122] Setting up cccp4
I0628 21:42:12.976493 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.976493 17220 net.cpp:137] Memory required for data: 264116400
I0628 21:42:12.976493 17220 layer_factory.cpp:58] Creating layer bn_cccp4
I0628 21:42:12.976493 17220 net.cpp:84] Creating Layer bn_cccp4
I0628 21:42:12.976493 17220 net.cpp:406] bn_cccp4 <- cccp4
I0628 21:42:12.976493 17220 net.cpp:367] bn_cccp4 -> cccp4 (in-place)
I0628 21:42:12.976994 17220 net.cpp:122] Setting up bn_cccp4
I0628 21:42:12.976994 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.976994 17220 net.cpp:137] Memory required for data: 265473200
I0628 21:42:12.976994 17220 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 21:42:12.976994 17220 net.cpp:84] Creating Layer scale_cccp4
I0628 21:42:12.976994 17220 net.cpp:406] scale_cccp4 <- cccp4
I0628 21:42:12.976994 17220 net.cpp:367] scale_cccp4 -> cccp4 (in-place)
I0628 21:42:12.976994 17220 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 21:42:12.976994 17220 net.cpp:122] Setting up scale_cccp4
I0628 21:42:12.976994 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.976994 17220 net.cpp:137] Memory required for data: 266830000
I0628 21:42:12.976994 17220 layer_factory.cpp:58] Creating layer relu_cccp4
I0628 21:42:12.976994 17220 net.cpp:84] Creating Layer relu_cccp4
I0628 21:42:12.976994 17220 net.cpp:406] relu_cccp4 <- cccp4
I0628 21:42:12.976994 17220 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0628 21:42:12.977495 17220 net.cpp:122] Setting up relu_cccp4
I0628 21:42:12.977495 17220 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 21:42:12.977495 17220 net.cpp:137] Memory required for data: 268186800
I0628 21:42:12.977495 17220 layer_factory.cpp:58] Creating layer pool4_2
I0628 21:42:12.977495 17220 net.cpp:84] Creating Layer pool4_2
I0628 21:42:12.977495 17220 net.cpp:406] pool4_2 <- cccp4
I0628 21:42:12.977495 17220 net.cpp:380] pool4_2 -> pool4_2
I0628 21:42:12.977495 17220 net.cpp:122] Setting up pool4_2
I0628 21:42:12.977495 17220 net.cpp:129] Top shape: 100 53 4 4 (84800)
I0628 21:42:12.977495 17220 net.cpp:137] Memory required for data: 268526000
I0628 21:42:12.977495 17220 layer_factory.cpp:58] Creating layer cccp5
I0628 21:42:12.977495 17220 net.cpp:84] Creating Layer cccp5
I0628 21:42:12.977495 17220 net.cpp:406] cccp5 <- pool4_2
I0628 21:42:12.977495 17220 net.cpp:380] cccp5 -> cccp5
I0628 21:42:12.978495 17220 net.cpp:122] Setting up cccp5
I0628 21:42:12.978495 17220 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 21:42:12.978495 17220 net.cpp:137] Memory required for data: 270081200
I0628 21:42:12.978495 17220 layer_factory.cpp:58] Creating layer bn_cccp5
I0628 21:42:12.978495 17220 net.cpp:84] Creating Layer bn_cccp5
I0628 21:42:12.978495 17220 net.cpp:406] bn_cccp5 <- cccp5
I0628 21:42:12.978495 17220 net.cpp:367] bn_cccp5 -> cccp5 (in-place)
I0628 21:42:12.978495 17220 net.cpp:122] Setting up bn_cccp5
I0628 21:42:12.978495 17220 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 21:42:12.978495 17220 net.cpp:137] Memory required for data: 271636400
I0628 21:42:12.978495 17220 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 21:42:12.978495 17220 net.cpp:84] Creating Layer scale_cccp5
I0628 21:42:12.978495 17220 net.cpp:406] scale_cccp5 <- cccp5
I0628 21:42:12.978495 17220 net.cpp:367] scale_cccp5 -> cccp5 (in-place)
I0628 21:42:12.978495 17220 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 21:42:12.978996 17220 net.cpp:122] Setting up scale_cccp5
I0628 21:42:12.978996 17220 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 21:42:12.978996 17220 net.cpp:137] Memory required for data: 273191600
I0628 21:42:12.978996 17220 layer_factory.cpp:58] Creating layer relu_cccp5
I0628 21:42:12.978996 17220 net.cpp:84] Creating Layer relu_cccp5
I0628 21:42:12.978996 17220 net.cpp:406] relu_cccp5 <- cccp5
I0628 21:42:12.978996 17220 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0628 21:42:12.979303 17220 net.cpp:122] Setting up relu_cccp5
I0628 21:42:12.979303 17220 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 21:42:12.979303 17220 net.cpp:137] Memory required for data: 274746800
I0628 21:42:12.979303 17220 layer_factory.cpp:58] Creating layer poolcp5
I0628 21:42:12.979303 17220 net.cpp:84] Creating Layer poolcp5
I0628 21:42:12.979303 17220 net.cpp:406] poolcp5 <- cccp5
I0628 21:42:12.979303 17220 net.cpp:380] poolcp5 -> poolcp5
I0628 21:42:12.979303 17220 net.cpp:122] Setting up poolcp5
I0628 21:42:12.979303 17220 net.cpp:129] Top shape: 100 108 3 3 (97200)
I0628 21:42:12.979303 17220 net.cpp:137] Memory required for data: 275135600
I0628 21:42:12.979303 17220 layer_factory.cpp:58] Creating layer cccp6
I0628 21:42:12.979303 17220 net.cpp:84] Creating Layer cccp6
I0628 21:42:12.979303 17220 net.cpp:406] cccp6 <- poolcp5
I0628 21:42:12.979303 17220 net.cpp:380] cccp6 -> cccp6
I0628 21:42:12.980306 17220 net.cpp:122] Setting up cccp6
I0628 21:42:12.980306 17220 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 21:42:12.980306 17220 net.cpp:137] Memory required for data: 276215600
I0628 21:42:12.980306 17220 layer_factory.cpp:58] Creating layer bn_cccp6
I0628 21:42:12.980806 17220 net.cpp:84] Creating Layer bn_cccp6
I0628 21:42:12.980806 17220 net.cpp:406] bn_cccp6 <- cccp6
I0628 21:42:12.980806 17220 net.cpp:367] bn_cccp6 -> cccp6 (in-place)
I0628 21:42:12.980806 17220 net.cpp:122] Setting up bn_cccp6
I0628 21:42:12.980806 17220 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 21:42:12.980806 17220 net.cpp:137] Memory required for data: 277295600
I0628 21:42:12.980806 17220 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 21:42:12.980806 17220 net.cpp:84] Creating Layer scale_cccp6
I0628 21:42:12.980806 17220 net.cpp:406] scale_cccp6 <- cccp6
I0628 21:42:12.980806 17220 net.cpp:367] scale_cccp6 -> cccp6 (in-place)
I0628 21:42:12.980806 17220 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 21:42:12.980806 17220 net.cpp:122] Setting up scale_cccp6
I0628 21:42:12.980806 17220 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 21:42:12.980806 17220 net.cpp:137] Memory required for data: 278375600
I0628 21:42:12.980806 17220 layer_factory.cpp:58] Creating layer relu_cccp6
I0628 21:42:12.980806 17220 net.cpp:84] Creating Layer relu_cccp6
I0628 21:42:12.980806 17220 net.cpp:406] relu_cccp6 <- cccp6
I0628 21:42:12.980806 17220 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0628 21:42:12.981307 17220 net.cpp:122] Setting up relu_cccp6
I0628 21:42:12.981307 17220 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 21:42:12.981307 17220 net.cpp:137] Memory required for data: 279455600
I0628 21:42:12.981307 17220 layer_factory.cpp:58] Creating layer poolcp6
I0628 21:42:12.981307 17220 net.cpp:84] Creating Layer poolcp6
I0628 21:42:12.981307 17220 net.cpp:406] poolcp6 <- cccp6
I0628 21:42:12.981307 17220 net.cpp:380] poolcp6 -> poolcp6
I0628 21:42:12.981307 17220 net.cpp:122] Setting up poolcp6
I0628 21:42:12.981307 17220 net.cpp:129] Top shape: 100 108 1 1 (10800)
I0628 21:42:12.981307 17220 net.cpp:137] Memory required for data: 279498800
I0628 21:42:12.981307 17220 layer_factory.cpp:58] Creating layer ip1
I0628 21:42:12.981307 17220 net.cpp:84] Creating Layer ip1
I0628 21:42:12.981307 17220 net.cpp:406] ip1 <- poolcp6
I0628 21:42:12.981307 17220 net.cpp:380] ip1 -> ip1
I0628 21:42:12.981307 17220 net.cpp:122] Setting up ip1
I0628 21:42:12.981307 17220 net.cpp:129] Top shape: 100 10 (1000)
I0628 21:42:12.981307 17220 net.cpp:137] Memory required for data: 279502800
I0628 21:42:12.981307 17220 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0628 21:42:12.981307 17220 net.cpp:84] Creating Layer ip1_ip1_0_split
I0628 21:42:12.981307 17220 net.cpp:406] ip1_ip1_0_split <- ip1
I0628 21:42:12.981307 17220 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0628 21:42:12.981307 17220 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0628 21:42:12.981307 17220 net.cpp:122] Setting up ip1_ip1_0_split
I0628 21:42:12.981307 17220 net.cpp:129] Top shape: 100 10 (1000)
I0628 21:42:12.981307 17220 net.cpp:129] Top shape: 100 10 (1000)
I0628 21:42:12.981307 17220 net.cpp:137] Memory required for data: 279510800
I0628 21:42:12.981307 17220 layer_factory.cpp:58] Creating layer accuracy
I0628 21:42:12.981307 17220 net.cpp:84] Creating Layer accuracy
I0628 21:42:12.981307 17220 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0628 21:42:12.981307 17220 net.cpp:406] accuracy <- label_cifar_1_split_0
I0628 21:42:12.981307 17220 net.cpp:380] accuracy -> accuracy
I0628 21:42:12.981307 17220 net.cpp:122] Setting up accuracy
I0628 21:42:12.981307 17220 net.cpp:129] Top shape: (1)
I0628 21:42:12.981307 17220 net.cpp:137] Memory required for data: 279510804
I0628 21:42:12.981307 17220 layer_factory.cpp:58] Creating layer loss
I0628 21:42:12.981307 17220 net.cpp:84] Creating Layer loss
I0628 21:42:12.981307 17220 net.cpp:406] loss <- ip1_ip1_0_split_1
I0628 21:42:12.981307 17220 net.cpp:406] loss <- label_cifar_1_split_1
I0628 21:42:12.981307 17220 net.cpp:380] loss -> loss
I0628 21:42:12.981807 17220 layer_factory.cpp:58] Creating layer loss
I0628 21:42:12.981807 17220 net.cpp:122] Setting up loss
I0628 21:42:12.981807 17220 net.cpp:129] Top shape: (1)
I0628 21:42:12.981807 17220 net.cpp:132]     with loss weight 1
I0628 21:42:12.981807 17220 net.cpp:137] Memory required for data: 279510808
I0628 21:42:12.981807 17220 net.cpp:198] loss needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:200] accuracy does not need backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] ip1 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] poolcp6 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] relu_cccp6 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] scale_cccp6 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] bn_cccp6 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] cccp6 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] poolcp5 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] relu_cccp5 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] scale_cccp5 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] bn_cccp5 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] cccp5 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] pool4_2 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] relu_cccp4 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] scale_cccp4 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] bn_cccp4 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] cccp4 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] relu4_0 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] scale4_0 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] bn4_0 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] conv4_0 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] pool4_12 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] relu4_2 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] scale4_2 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] bn4_2 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] conv4_2 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] relu4_1 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] scale4_1 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] bn4_1 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] conv4_1 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] relu4 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] scale4 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] bn4 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] conv4 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] relu3 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] scale3 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] bn3 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] conv3 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] pool2_1 needs backward computation.
I0628 21:42:12.981807 17220 net.cpp:198] relu2_2 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] scale2_2 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] bn2_2 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] conv2_2 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] relu2_1 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] scale2_1 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] bn2_1 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] conv2_1 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] relu2 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] scale2 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] bn2 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] conv2 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] relu1_0 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] scale1_0 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] bn1_0 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] conv1_0 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] relu1 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] scale1 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] bn1 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:198] conv1 needs backward computation.
I0628 21:42:12.982308 17220 net.cpp:200] label_cifar_1_split does not need backward computation.
I0628 21:42:12.982308 17220 net.cpp:200] cifar does not need backward computation.
I0628 21:42:12.982308 17220 net.cpp:242] This network produces output accuracy
I0628 21:42:12.982308 17220 net.cpp:242] This network produces output loss
I0628 21:42:12.982308 17220 net.cpp:255] Network initialization done.
I0628 21:42:12.982308 17220 solver.cpp:56] Solver scaffolding done.
I0628 21:42:12.985309 17220 caffe.cpp:249] Starting Optimization
I0628 21:42:12.985309 17220 solver.cpp:272] Solving CIFAR10_SimpleNet_13_128k_end1x1
I0628 21:42:12.985309 17220 solver.cpp:273] Learning Rate Policy: multistep
I0628 21:42:12.986702 17220 solver.cpp:330] Iteration 0, Testing net (#0)
I0628 21:42:12.988204 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:42:13.865938 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:42:13.896961 17220 solver.cpp:397]     Test net output #0: accuracy = 0.1004
I0628 21:42:13.896961 17220 solver.cpp:397]     Test net output #1: loss = 78.5679 (* 1 = 78.5679 loss)
I0628 21:42:13.969283 17220 solver.cpp:218] Iteration 0 (0 iter/s, 0.98276s/100 iters), loss = 4.46954
I0628 21:42:13.969283 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I0628 21:42:13.969283 17220 solver.cpp:237]     Train net output #1: loss = 4.46954 (* 1 = 4.46954 loss)
I0628 21:42:13.969283 17220 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0628 21:42:17.570477 17220 solver.cpp:218] Iteration 100 (27.7706 iter/s, 3.60093s/100 iters), loss = 1.71615
I0628 21:42:17.570477 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I0628 21:42:17.570477 17220 solver.cpp:237]     Train net output #1: loss = 1.71615 (* 1 = 1.71615 loss)
I0628 21:42:17.570477 17220 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0628 21:42:21.187888 17220 solver.cpp:218] Iteration 200 (27.647 iter/s, 3.61703s/100 iters), loss = 1.60024
I0628 21:42:21.187888 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I0628 21:42:21.187888 17220 solver.cpp:237]     Train net output #1: loss = 1.60024 (* 1 = 1.60024 loss)
I0628 21:42:21.187888 17220 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0628 21:42:24.809465 17220 solver.cpp:218] Iteration 300 (27.6117 iter/s, 3.62165s/100 iters), loss = 1.61663
I0628 21:42:24.809967 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I0628 21:42:24.809967 17220 solver.cpp:237]     Train net output #1: loss = 1.61663 (* 1 = 1.61663 loss)
I0628 21:42:24.809967 17220 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0628 21:42:28.425071 17220 solver.cpp:218] Iteration 400 (27.6632 iter/s, 3.61492s/100 iters), loss = 1.35135
I0628 21:42:28.425071 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I0628 21:42:28.425071 17220 solver.cpp:237]     Train net output #1: loss = 1.35135 (* 1 = 1.35135 loss)
I0628 21:42:28.425071 17220 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0628 21:42:31.856106  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:42:31.997221 17220 solver.cpp:330] Iteration 500, Testing net (#0)
I0628 21:42:31.997721 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:42:32.815301 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:42:32.845809 17220 solver.cpp:397]     Test net output #0: accuracy = 0.4655
I0628 21:42:32.845809 17220 solver.cpp:397]     Test net output #1: loss = 1.43416 (* 1 = 1.43416 loss)
I0628 21:42:32.880347 17220 solver.cpp:218] Iteration 500 (22.4472 iter/s, 4.4549s/100 iters), loss = 1.50225
I0628 21:42:32.880347 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I0628 21:42:32.880347 17220 solver.cpp:237]     Train net output #1: loss = 1.50225 (* 1 = 1.50225 loss)
I0628 21:42:32.880347 17220 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0628 21:42:36.493540 17220 solver.cpp:218] Iteration 600 (27.6794 iter/s, 3.61279s/100 iters), loss = 1.28534
I0628 21:42:36.493540 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I0628 21:42:36.493540 17220 solver.cpp:237]     Train net output #1: loss = 1.28534 (* 1 = 1.28534 loss)
I0628 21:42:36.493540 17220 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0628 21:42:40.102105 17220 solver.cpp:218] Iteration 700 (27.7125 iter/s, 3.60848s/100 iters), loss = 1.47424
I0628 21:42:40.102105 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I0628 21:42:40.102105 17220 solver.cpp:237]     Train net output #1: loss = 1.47424 (* 1 = 1.47424 loss)
I0628 21:42:40.102105 17220 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0628 21:42:43.748757 17220 solver.cpp:218] Iteration 800 (27.4253 iter/s, 3.64627s/100 iters), loss = 1.35547
I0628 21:42:43.748757 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I0628 21:42:43.748757 17220 solver.cpp:237]     Train net output #1: loss = 1.35547 (* 1 = 1.35547 loss)
I0628 21:42:43.748757 17220 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0628 21:42:47.384284 17220 solver.cpp:218] Iteration 900 (27.5097 iter/s, 3.63508s/100 iters), loss = 1.1512
I0628 21:42:47.384284 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I0628 21:42:47.384284 17220 solver.cpp:237]     Train net output #1: loss = 1.1512 (* 1 = 1.1512 loss)
I0628 21:42:47.384284 17220 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0628 21:42:50.846748  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:42:50.989351 17220 solver.cpp:330] Iteration 1000, Testing net (#0)
I0628 21:42:50.989351 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:42:51.809434 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:42:51.840456 17220 solver.cpp:397]     Test net output #0: accuracy = 0.5548
I0628 21:42:51.840456 17220 solver.cpp:397]     Test net output #1: loss = 1.22174 (* 1 = 1.22174 loss)
I0628 21:42:51.874979 17220 solver.cpp:218] Iteration 1000 (22.2694 iter/s, 4.49046s/100 iters), loss = 1.3729
I0628 21:42:51.874979 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I0628 21:42:51.874979 17220 solver.cpp:237]     Train net output #1: loss = 1.3729 (* 1 = 1.3729 loss)
I0628 21:42:51.874979 17220 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0628 21:42:55.505098 17220 solver.cpp:218] Iteration 1100 (27.5523 iter/s, 3.62945s/100 iters), loss = 1.11326
I0628 21:42:55.505098 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I0628 21:42:55.505098 17220 solver.cpp:237]     Train net output #1: loss = 1.11326 (* 1 = 1.11326 loss)
I0628 21:42:55.505098 17220 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0628 21:42:59.127676 17220 solver.cpp:218] Iteration 1200 (27.6039 iter/s, 3.62268s/100 iters), loss = 1.24188
I0628 21:42:59.128177 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I0628 21:42:59.128177 17220 solver.cpp:237]     Train net output #1: loss = 1.24188 (* 1 = 1.24188 loss)
I0628 21:42:59.128177 17220 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0628 21:43:02.748752 17220 solver.cpp:218] Iteration 1300 (27.6205 iter/s, 3.6205s/100 iters), loss = 1.13337
I0628 21:43:02.748752 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0628 21:43:02.748752 17220 solver.cpp:237]     Train net output #1: loss = 1.13337 (* 1 = 1.13337 loss)
I0628 21:43:02.748752 17220 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0628 21:43:06.377130 17220 solver.cpp:218] Iteration 1400 (27.5632 iter/s, 3.62803s/100 iters), loss = 1.00438
I0628 21:43:06.377130 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I0628 21:43:06.377130 17220 solver.cpp:237]     Train net output #1: loss = 1.00438 (* 1 = 1.00438 loss)
I0628 21:43:06.377130 17220 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0628 21:43:09.833114  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:43:09.974236 17220 solver.cpp:330] Iteration 1500, Testing net (#0)
I0628 21:43:09.974730 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:43:10.796820 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:43:10.826841 17220 solver.cpp:397]     Test net output #0: accuracy = 0.6182
I0628 21:43:10.826841 17220 solver.cpp:397]     Test net output #1: loss = 1.04559 (* 1 = 1.04559 loss)
I0628 21:43:10.861361 17220 solver.cpp:218] Iteration 1500 (22.3031 iter/s, 4.48369s/100 iters), loss = 1.03151
I0628 21:43:10.861361 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0628 21:43:10.861361 17220 solver.cpp:237]     Train net output #1: loss = 1.03151 (* 1 = 1.03151 loss)
I0628 21:43:10.861361 17220 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0628 21:43:14.477582 17220 solver.cpp:218] Iteration 1600 (27.6544 iter/s, 3.61606s/100 iters), loss = 1.11004
I0628 21:43:14.477582 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I0628 21:43:14.477582 17220 solver.cpp:237]     Train net output #1: loss = 1.11004 (* 1 = 1.11004 loss)
I0628 21:43:14.477582 17220 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0628 21:43:18.111661 17220 solver.cpp:218] Iteration 1700 (27.5196 iter/s, 3.63377s/100 iters), loss = 1.00461
I0628 21:43:18.111661 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0628 21:43:18.111661 17220 solver.cpp:237]     Train net output #1: loss = 1.00461 (* 1 = 1.00461 loss)
I0628 21:43:18.111661 17220 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0628 21:43:21.760773 17220 solver.cpp:218] Iteration 1800 (27.4067 iter/s, 3.64874s/100 iters), loss = 1.07844
I0628 21:43:21.760773 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0628 21:43:21.760773 17220 solver.cpp:237]     Train net output #1: loss = 1.07844 (* 1 = 1.07844 loss)
I0628 21:43:21.760773 17220 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0628 21:43:25.391417 17220 solver.cpp:218] Iteration 1900 (27.547 iter/s, 3.63016s/100 iters), loss = 0.815253
I0628 21:43:25.391417 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0628 21:43:25.391417 17220 solver.cpp:237]     Train net output #1: loss = 0.815253 (* 1 = 0.815253 loss)
I0628 21:43:25.391417 17220 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0628 21:43:28.841935  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:43:28.984022 17220 solver.cpp:330] Iteration 2000, Testing net (#0)
I0628 21:43:28.984539 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:43:29.810616 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:43:29.841146 17220 solver.cpp:397]     Test net output #0: accuracy = 0.653
I0628 21:43:29.841146 17220 solver.cpp:397]     Test net output #1: loss = 0.957961 (* 1 = 0.957961 loss)
I0628 21:43:29.875655 17220 solver.cpp:218] Iteration 2000 (22.3025 iter/s, 4.48381s/100 iters), loss = 0.98358
I0628 21:43:29.875655 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I0628 21:43:29.875655 17220 solver.cpp:237]     Train net output #1: loss = 0.98358 (* 1 = 0.98358 loss)
I0628 21:43:29.875655 17220 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0628 21:43:33.495908 17220 solver.cpp:218] Iteration 2100 (27.6234 iter/s, 3.62012s/100 iters), loss = 0.899087
I0628 21:43:33.495908 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0628 21:43:33.496408 17220 solver.cpp:237]     Train net output #1: loss = 0.899087 (* 1 = 0.899087 loss)
I0628 21:43:33.496408 17220 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0628 21:43:37.117095 17220 solver.cpp:218] Iteration 2200 (27.6175 iter/s, 3.62089s/100 iters), loss = 0.953804
I0628 21:43:37.117595 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0628 21:43:37.117595 17220 solver.cpp:237]     Train net output #1: loss = 0.953804 (* 1 = 0.953804 loss)
I0628 21:43:37.117595 17220 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0628 21:43:40.741184 17220 solver.cpp:218] Iteration 2300 (27.596 iter/s, 3.62372s/100 iters), loss = 0.967456
I0628 21:43:40.741684 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0628 21:43:40.741684 17220 solver.cpp:237]     Train net output #1: loss = 0.967456 (* 1 = 0.967456 loss)
I0628 21:43:40.741684 17220 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0628 21:43:44.374299 17220 solver.cpp:218] Iteration 2400 (27.5304 iter/s, 3.63235s/100 iters), loss = 0.72383
I0628 21:43:44.374299 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0628 21:43:44.374299 17220 solver.cpp:237]     Train net output #1: loss = 0.72383 (* 1 = 0.72383 loss)
I0628 21:43:44.374299 17220 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0628 21:43:47.842296  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:43:47.984382 17220 solver.cpp:330] Iteration 2500, Testing net (#0)
I0628 21:43:47.984382 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:43:48.812988 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:43:48.844509 17220 solver.cpp:397]     Test net output #0: accuracy = 0.702
I0628 21:43:48.844509 17220 solver.cpp:397]     Test net output #1: loss = 0.841376 (* 1 = 0.841376 loss)
I0628 21:43:48.879020 17220 solver.cpp:218] Iteration 2500 (22.1997 iter/s, 4.50457s/100 iters), loss = 0.811217
I0628 21:43:48.879020 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0628 21:43:48.879020 17220 solver.cpp:237]     Train net output #1: loss = 0.811217 (* 1 = 0.811217 loss)
I0628 21:43:48.879020 17220 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0628 21:43:52.526150 17220 solver.cpp:218] Iteration 2600 (27.4225 iter/s, 3.64665s/100 iters), loss = 0.807039
I0628 21:43:52.526150 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0628 21:43:52.526150 17220 solver.cpp:237]     Train net output #1: loss = 0.807039 (* 1 = 0.807039 loss)
I0628 21:43:52.526150 17220 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0628 21:43:56.161249 17220 solver.cpp:218] Iteration 2700 (27.5097 iter/s, 3.63508s/100 iters), loss = 0.862334
I0628 21:43:56.161249 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0628 21:43:56.161749 17220 solver.cpp:237]     Train net output #1: loss = 0.862334 (* 1 = 0.862334 loss)
I0628 21:43:56.161749 17220 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0628 21:43:59.793864 17220 solver.cpp:218] Iteration 2800 (27.5323 iter/s, 3.6321s/100 iters), loss = 0.86955
I0628 21:43:59.793864 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0628 21:43:59.793864 17220 solver.cpp:237]     Train net output #1: loss = 0.86955 (* 1 = 0.86955 loss)
I0628 21:43:59.793864 17220 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0628 21:44:03.424970 17220 solver.cpp:218] Iteration 2900 (27.5431 iter/s, 3.63067s/100 iters), loss = 0.707014
I0628 21:44:03.424970 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0628 21:44:03.424970 17220 solver.cpp:237]     Train net output #1: loss = 0.707014 (* 1 = 0.707014 loss)
I0628 21:44:03.424970 17220 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0628 21:44:06.871912  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:44:07.013027 17220 solver.cpp:330] Iteration 3000, Testing net (#0)
I0628 21:44:07.013027 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:44:07.839601 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:44:07.870623 17220 solver.cpp:397]     Test net output #0: accuracy = 0.715
I0628 21:44:07.870623 17220 solver.cpp:397]     Test net output #1: loss = 0.82652 (* 1 = 0.82652 loss)
I0628 21:44:07.905148 17220 solver.cpp:218] Iteration 3000 (22.3222 iter/s, 4.47985s/100 iters), loss = 0.873055
I0628 21:44:07.905148 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0628 21:44:07.905148 17220 solver.cpp:237]     Train net output #1: loss = 0.873055 (* 1 = 0.873055 loss)
I0628 21:44:07.905148 17220 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0628 21:44:11.539705 17220 solver.cpp:218] Iteration 3100 (27.5163 iter/s, 3.6342s/100 iters), loss = 0.749276
I0628 21:44:11.539705 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 21:44:11.539705 17220 solver.cpp:237]     Train net output #1: loss = 0.749276 (* 1 = 0.749276 loss)
I0628 21:44:11.539705 17220 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0628 21:44:15.174437 17220 solver.cpp:218] Iteration 3200 (27.5142 iter/s, 3.63449s/100 iters), loss = 0.88342
I0628 21:44:15.174437 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0628 21:44:15.174437 17220 solver.cpp:237]     Train net output #1: loss = 0.88342 (* 1 = 0.88342 loss)
I0628 21:44:15.174437 17220 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0628 21:44:18.789017 17220 solver.cpp:218] Iteration 3300 (27.6698 iter/s, 3.61405s/100 iters), loss = 0.736158
I0628 21:44:18.789017 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0628 21:44:18.789017 17220 solver.cpp:237]     Train net output #1: loss = 0.736158 (* 1 = 0.736158 loss)
I0628 21:44:18.789017 17220 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0628 21:44:22.391156 17220 solver.cpp:218] Iteration 3400 (27.7657 iter/s, 3.60157s/100 iters), loss = 0.66241
I0628 21:44:22.391156 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0628 21:44:22.391156 17220 solver.cpp:237]     Train net output #1: loss = 0.66241 (* 1 = 0.66241 loss)
I0628 21:44:22.391156 17220 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0628 21:44:25.807111  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:44:25.948211 17220 solver.cpp:330] Iteration 3500, Testing net (#0)
I0628 21:44:25.948211 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:44:26.770797 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:44:26.801319 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7124
I0628 21:44:26.801820 17220 solver.cpp:397]     Test net output #1: loss = 0.820227 (* 1 = 0.820227 loss)
I0628 21:44:26.835844 17220 solver.cpp:218] Iteration 3500 (22.4998 iter/s, 4.44449s/100 iters), loss = 0.821627
I0628 21:44:26.835844 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0628 21:44:26.835844 17220 solver.cpp:237]     Train net output #1: loss = 0.821627 (* 1 = 0.821627 loss)
I0628 21:44:26.835844 17220 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0628 21:44:30.431946 17220 solver.cpp:218] Iteration 3600 (27.8118 iter/s, 3.59559s/100 iters), loss = 0.689007
I0628 21:44:30.431946 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 21:44:30.431946 17220 solver.cpp:237]     Train net output #1: loss = 0.689007 (* 1 = 0.689007 loss)
I0628 21:44:30.431946 17220 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0628 21:44:34.047044 17220 solver.cpp:218] Iteration 3700 (27.6616 iter/s, 3.61512s/100 iters), loss = 0.645716
I0628 21:44:34.047044 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 21:44:34.047544 17220 solver.cpp:237]     Train net output #1: loss = 0.645716 (* 1 = 0.645716 loss)
I0628 21:44:34.047544 17220 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0628 21:44:37.655619 17220 solver.cpp:218] Iteration 3800 (27.7171 iter/s, 3.60788s/100 iters), loss = 0.691689
I0628 21:44:37.655619 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0628 21:44:37.655619 17220 solver.cpp:237]     Train net output #1: loss = 0.691689 (* 1 = 0.691689 loss)
I0628 21:44:37.655619 17220 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0628 21:44:41.264214 17220 solver.cpp:218] Iteration 3900 (27.7129 iter/s, 3.60843s/100 iters), loss = 0.608806
I0628 21:44:41.264214 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0628 21:44:41.264214 17220 solver.cpp:237]     Train net output #1: loss = 0.608806 (* 1 = 0.608806 loss)
I0628 21:44:41.264214 17220 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0628 21:44:44.689750  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:44:44.829851 17220 solver.cpp:330] Iteration 4000, Testing net (#0)
I0628 21:44:44.829851 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:44:45.649933 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:44:45.680455 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7284
I0628 21:44:45.680455 17220 solver.cpp:397]     Test net output #1: loss = 0.764181 (* 1 = 0.764181 loss)
I0628 21:44:45.714480 17220 solver.cpp:218] Iteration 4000 (22.4715 iter/s, 4.45008s/100 iters), loss = 0.741913
I0628 21:44:45.714480 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0628 21:44:45.714480 17220 solver.cpp:237]     Train net output #1: loss = 0.741913 (* 1 = 0.741913 loss)
I0628 21:44:45.714480 17220 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0628 21:44:49.321135 17220 solver.cpp:218] Iteration 4100 (27.7287 iter/s, 3.60637s/100 iters), loss = 0.524068
I0628 21:44:49.321636 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:44:49.321636 17220 solver.cpp:237]     Train net output #1: loss = 0.524068 (* 1 = 0.524068 loss)
I0628 21:44:49.321636 17220 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0628 21:44:52.966728 17220 solver.cpp:218] Iteration 4200 (27.4355 iter/s, 3.64491s/100 iters), loss = 0.744685
I0628 21:44:52.966728 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 21:44:52.966728 17220 solver.cpp:237]     Train net output #1: loss = 0.744685 (* 1 = 0.744685 loss)
I0628 21:44:52.966728 17220 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0628 21:44:56.603816 17220 solver.cpp:218] Iteration 4300 (27.4953 iter/s, 3.63698s/100 iters), loss = 0.668632
I0628 21:44:56.603816 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 21:44:56.603816 17220 solver.cpp:237]     Train net output #1: loss = 0.668632 (* 1 = 0.668632 loss)
I0628 21:44:56.603816 17220 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0628 21:45:00.252987 17220 solver.cpp:218] Iteration 4400 (27.4059 iter/s, 3.64885s/100 iters), loss = 0.562921
I0628 21:45:00.252987 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 21:45:00.253487 17220 solver.cpp:237]     Train net output #1: loss = 0.562921 (* 1 = 0.562921 loss)
I0628 21:45:00.253487 17220 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0628 21:45:03.705466  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:45:03.846567 17220 solver.cpp:330] Iteration 4500, Testing net (#0)
I0628 21:45:03.846567 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:45:04.673156 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:45:04.704177 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7366
I0628 21:45:04.704177 17220 solver.cpp:397]     Test net output #1: loss = 0.761831 (* 1 = 0.761831 loss)
I0628 21:45:04.738203 17220 solver.cpp:218] Iteration 4500 (22.2974 iter/s, 4.48482s/100 iters), loss = 0.715237
I0628 21:45:04.738203 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0628 21:45:04.738703 17220 solver.cpp:237]     Train net output #1: loss = 0.715237 (* 1 = 0.715237 loss)
I0628 21:45:04.738703 17220 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0628 21:45:08.370332 17220 solver.cpp:218] Iteration 4600 (27.5357 iter/s, 3.63164s/100 iters), loss = 0.653996
I0628 21:45:08.370332 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0628 21:45:08.370332 17220 solver.cpp:237]     Train net output #1: loss = 0.653996 (* 1 = 0.653996 loss)
I0628 21:45:08.370332 17220 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0628 21:45:12.007920 17220 solver.cpp:218] Iteration 4700 (27.4947 iter/s, 3.63706s/100 iters), loss = 0.639954
I0628 21:45:12.007920 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 21:45:12.007920 17220 solver.cpp:237]     Train net output #1: loss = 0.639954 (* 1 = 0.639954 loss)
I0628 21:45:12.007920 17220 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0628 21:45:15.641029 17220 solver.cpp:218] Iteration 4800 (27.527 iter/s, 3.6328s/100 iters), loss = 0.689654
I0628 21:45:15.641029 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 21:45:15.641029 17220 solver.cpp:237]     Train net output #1: loss = 0.689654 (* 1 = 0.689654 loss)
I0628 21:45:15.641029 17220 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0628 21:45:19.279606 17220 solver.cpp:218] Iteration 4900 (27.4839 iter/s, 3.63849s/100 iters), loss = 0.5238
I0628 21:45:19.280107 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 21:45:19.280107 17220 solver.cpp:237]     Train net output #1: loss = 0.5238 (* 1 = 0.5238 loss)
I0628 21:45:19.280107 17220 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0628 21:45:22.733562  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:45:22.875164 17220 solver.cpp:330] Iteration 5000, Testing net (#0)
I0628 21:45:22.875664 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:45:23.698750 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:45:23.729271 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7471
I0628 21:45:23.729271 17220 solver.cpp:397]     Test net output #1: loss = 0.742326 (* 1 = 0.742326 loss)
I0628 21:45:23.763795 17220 solver.cpp:218] Iteration 5000 (22.3035 iter/s, 4.4836s/100 iters), loss = 0.663566
I0628 21:45:23.763795 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 21:45:23.763795 17220 solver.cpp:237]     Train net output #1: loss = 0.663566 (* 1 = 0.663566 loss)
I0628 21:45:23.763795 17220 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0628 21:45:27.396380 17220 solver.cpp:218] Iteration 5100 (27.532 iter/s, 3.63214s/100 iters), loss = 0.492993
I0628 21:45:27.396380 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:45:27.396380 17220 solver.cpp:237]     Train net output #1: loss = 0.492993 (* 1 = 0.492993 loss)
I0628 21:45:27.396380 17220 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0628 21:45:31.036970 17220 solver.cpp:218] Iteration 5200 (27.4714 iter/s, 3.64015s/100 iters), loss = 0.598445
I0628 21:45:31.036970 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 21:45:31.036970 17220 solver.cpp:237]     Train net output #1: loss = 0.598445 (* 1 = 0.598445 loss)
I0628 21:45:31.036970 17220 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0628 21:45:34.661548 17220 solver.cpp:218] Iteration 5300 (27.5933 iter/s, 3.62407s/100 iters), loss = 0.564163
I0628 21:45:34.661548 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:45:34.661548 17220 solver.cpp:237]     Train net output #1: loss = 0.564163 (* 1 = 0.564163 loss)
I0628 21:45:34.661548 17220 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0628 21:45:38.288183 17220 solver.cpp:218] Iteration 5400 (27.5755 iter/s, 3.62641s/100 iters), loss = 0.5144
I0628 21:45:38.288183 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:45:38.288183 17220 solver.cpp:237]     Train net output #1: loss = 0.5144 (* 1 = 0.5144 loss)
I0628 21:45:38.288183 17220 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0628 21:45:41.748145  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:45:41.891758 17220 solver.cpp:330] Iteration 5500, Testing net (#0)
I0628 21:45:41.891758 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:45:42.715844 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:45:42.746366 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7577
I0628 21:45:42.746366 17220 solver.cpp:397]     Test net output #1: loss = 0.703157 (* 1 = 0.703157 loss)
I0628 21:45:42.780891 17220 solver.cpp:218] Iteration 5500 (22.2601 iter/s, 4.49234s/100 iters), loss = 0.782239
I0628 21:45:42.780891 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0628 21:45:42.780891 17220 solver.cpp:237]     Train net output #1: loss = 0.782239 (* 1 = 0.782239 loss)
I0628 21:45:42.780891 17220 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0628 21:45:46.398069 17220 solver.cpp:218] Iteration 5600 (27.6469 iter/s, 3.61704s/100 iters), loss = 0.561371
I0628 21:45:46.398569 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:45:46.398569 17220 solver.cpp:237]     Train net output #1: loss = 0.561371 (* 1 = 0.561371 loss)
I0628 21:45:46.398569 17220 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0628 21:45:50.029654 17220 solver.cpp:218] Iteration 5700 (27.5402 iter/s, 3.63105s/100 iters), loss = 0.546678
I0628 21:45:50.029654 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 21:45:50.029654 17220 solver.cpp:237]     Train net output #1: loss = 0.546678 (* 1 = 0.546678 loss)
I0628 21:45:50.029654 17220 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0628 21:45:53.653231 17220 solver.cpp:218] Iteration 5800 (27.5988 iter/s, 3.62334s/100 iters), loss = 0.537705
I0628 21:45:53.653731 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 21:45:53.653731 17220 solver.cpp:237]     Train net output #1: loss = 0.537705 (* 1 = 0.537705 loss)
I0628 21:45:53.653731 17220 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0628 21:45:57.284816 17220 solver.cpp:218] Iteration 5900 (27.5407 iter/s, 3.63099s/100 iters), loss = 0.496565
I0628 21:45:57.284816 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 21:45:57.284816 17220 solver.cpp:237]     Train net output #1: loss = 0.496565 (* 1 = 0.496565 loss)
I0628 21:45:57.284816 17220 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0628 21:46:00.740774  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:46:00.882375 17220 solver.cpp:330] Iteration 6000, Testing net (#0)
I0628 21:46:00.882875 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:46:01.710464 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:46:01.741487 17220 solver.cpp:397]     Test net output #0: accuracy = 0.742
I0628 21:46:01.741487 17220 solver.cpp:397]     Test net output #1: loss = 0.762685 (* 1 = 0.762685 loss)
I0628 21:46:01.776510 17220 solver.cpp:218] Iteration 6000 (22.2665 iter/s, 4.49106s/100 iters), loss = 0.523278
I0628 21:46:01.776510 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 21:46:01.776510 17220 solver.cpp:237]     Train net output #1: loss = 0.523278 (* 1 = 0.523278 loss)
I0628 21:46:01.776510 17220 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0628 21:46:05.427112 17220 solver.cpp:218] Iteration 6100 (27.3921 iter/s, 3.65069s/100 iters), loss = 0.48452
I0628 21:46:05.427112 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:46:05.427112 17220 solver.cpp:237]     Train net output #1: loss = 0.48452 (* 1 = 0.48452 loss)
I0628 21:46:05.427613 17220 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0628 21:46:09.066701 17220 solver.cpp:218] Iteration 6200 (27.479 iter/s, 3.63914s/100 iters), loss = 0.561389
I0628 21:46:09.067212 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:46:09.067212 17220 solver.cpp:237]     Train net output #1: loss = 0.561389 (* 1 = 0.561389 loss)
I0628 21:46:09.067212 17220 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0628 21:46:12.734311 17220 solver.cpp:218] Iteration 6300 (27.2726 iter/s, 3.66668s/100 iters), loss = 0.558864
I0628 21:46:12.734311 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:46:12.734311 17220 solver.cpp:237]     Train net output #1: loss = 0.558864 (* 1 = 0.558864 loss)
I0628 21:46:12.734311 17220 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0628 21:46:16.363394 17220 solver.cpp:218] Iteration 6400 (27.5559 iter/s, 3.62898s/100 iters), loss = 0.493048
I0628 21:46:16.363394 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 21:46:16.363394 17220 solver.cpp:237]     Train net output #1: loss = 0.493048 (* 1 = 0.493048 loss)
I0628 21:46:16.363394 17220 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0628 21:46:19.808372  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:46:19.950973 17220 solver.cpp:330] Iteration 6500, Testing net (#0)
I0628 21:46:19.950973 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:46:20.776561 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:46:20.808583 17220 solver.cpp:397]     Test net output #0: accuracy = 0.738
I0628 21:46:20.808583 17220 solver.cpp:397]     Test net output #1: loss = 0.774531 (* 1 = 0.774531 loss)
I0628 21:46:20.843108 17220 solver.cpp:218] Iteration 6500 (22.3258 iter/s, 4.47912s/100 iters), loss = 0.505615
I0628 21:46:20.843108 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:46:20.843108 17220 solver.cpp:237]     Train net output #1: loss = 0.505615 (* 1 = 0.505615 loss)
I0628 21:46:20.843108 17220 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0628 21:46:24.475193 17220 solver.cpp:218] Iteration 6600 (27.5336 iter/s, 3.63192s/100 iters), loss = 0.528759
I0628 21:46:24.475193 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 21:46:24.475193 17220 solver.cpp:237]     Train net output #1: loss = 0.528759 (* 1 = 0.528759 loss)
I0628 21:46:24.475193 17220 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0628 21:46:28.105274 17220 solver.cpp:218] Iteration 6700 (27.5522 iter/s, 3.62948s/100 iters), loss = 0.61533
I0628 21:46:28.105274 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0628 21:46:28.105274 17220 solver.cpp:237]     Train net output #1: loss = 0.61533 (* 1 = 0.61533 loss)
I0628 21:46:28.105274 17220 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0628 21:46:31.731371 17220 solver.cpp:218] Iteration 6800 (27.5771 iter/s, 3.6262s/100 iters), loss = 0.561186
I0628 21:46:31.731871 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:46:31.731871 17220 solver.cpp:237]     Train net output #1: loss = 0.561186 (* 1 = 0.561186 loss)
I0628 21:46:31.731871 17220 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0628 21:46:35.351925 17220 solver.cpp:218] Iteration 6900 (27.6234 iter/s, 3.62012s/100 iters), loss = 0.445695
I0628 21:46:35.351925 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:46:35.351925 17220 solver.cpp:237]     Train net output #1: loss = 0.445695 (* 1 = 0.445695 loss)
I0628 21:46:35.351925 17220 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0628 21:46:38.807193  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:46:38.948793 17220 solver.cpp:330] Iteration 7000, Testing net (#0)
I0628 21:46:38.948793 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:46:39.770879 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:46:39.802402 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7596
I0628 21:46:39.802402 17220 solver.cpp:397]     Test net output #1: loss = 0.732696 (* 1 = 0.732696 loss)
I0628 21:46:39.836424 17220 solver.cpp:218] Iteration 7000 (22.3018 iter/s, 4.48394s/100 iters), loss = 0.549583
I0628 21:46:39.836424 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 21:46:39.836424 17220 solver.cpp:237]     Train net output #1: loss = 0.549583 (* 1 = 0.549583 loss)
I0628 21:46:39.836424 17220 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0628 21:46:43.477025 17220 solver.cpp:218] Iteration 7100 (27.4698 iter/s, 3.64036s/100 iters), loss = 0.434483
I0628 21:46:43.477025 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:46:43.477025 17220 solver.cpp:237]     Train net output #1: loss = 0.434483 (* 1 = 0.434483 loss)
I0628 21:46:43.477025 17220 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0628 21:46:47.100103 17220 solver.cpp:218] Iteration 7200 (27.6031 iter/s, 3.62278s/100 iters), loss = 0.579851
I0628 21:46:47.100103 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:46:47.100103 17220 solver.cpp:237]     Train net output #1: loss = 0.579851 (* 1 = 0.579851 loss)
I0628 21:46:47.100103 17220 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0628 21:46:50.737690 17220 solver.cpp:218] Iteration 7300 (27.4958 iter/s, 3.63692s/100 iters), loss = 0.540668
I0628 21:46:50.737690 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 21:46:50.737690 17220 solver.cpp:237]     Train net output #1: loss = 0.540668 (* 1 = 0.540668 loss)
I0628 21:46:50.737690 17220 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0628 21:46:54.378818 17220 solver.cpp:218] Iteration 7400 (27.4666 iter/s, 3.64078s/100 iters), loss = 0.447139
I0628 21:46:54.378818 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:46:54.378818 17220 solver.cpp:237]     Train net output #1: loss = 0.447139 (* 1 = 0.447139 loss)
I0628 21:46:54.378818 17220 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0628 21:46:57.839807  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:46:57.982408 17220 solver.cpp:330] Iteration 7500, Testing net (#0)
I0628 21:46:57.982408 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:46:58.809496 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:46:58.840518 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7755
I0628 21:46:58.840518 17220 solver.cpp:397]     Test net output #1: loss = 0.662276 (* 1 = 0.662276 loss)
I0628 21:46:58.875042 17220 solver.cpp:218] Iteration 7500 (22.2411 iter/s, 4.49617s/100 iters), loss = 0.515816
I0628 21:46:58.875042 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:46:58.875042 17220 solver.cpp:237]     Train net output #1: loss = 0.515816 (* 1 = 0.515816 loss)
I0628 21:46:58.875042 17220 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0628 21:47:02.505158 17220 solver.cpp:218] Iteration 7600 (27.5526 iter/s, 3.62942s/100 iters), loss = 0.435535
I0628 21:47:02.505158 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:47:02.505158 17220 solver.cpp:237]     Train net output #1: loss = 0.435535 (* 1 = 0.435535 loss)
I0628 21:47:02.505158 17220 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0628 21:47:06.127745 17220 solver.cpp:218] Iteration 7700 (27.6069 iter/s, 3.62228s/100 iters), loss = 0.481527
I0628 21:47:06.127745 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:47:06.127745 17220 solver.cpp:237]     Train net output #1: loss = 0.481527 (* 1 = 0.481527 loss)
I0628 21:47:06.127745 17220 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0628 21:47:09.763327 17220 solver.cpp:218] Iteration 7800 (27.5087 iter/s, 3.63521s/100 iters), loss = 0.590327
I0628 21:47:09.763327 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:47:09.763327 17220 solver.cpp:237]     Train net output #1: loss = 0.590327 (* 1 = 0.590327 loss)
I0628 21:47:09.763327 17220 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0628 21:47:13.387955 17220 solver.cpp:218] Iteration 7900 (27.5883 iter/s, 3.62472s/100 iters), loss = 0.464567
I0628 21:47:13.388456 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 21:47:13.388456 17220 solver.cpp:237]     Train net output #1: loss = 0.464567 (* 1 = 0.464567 loss)
I0628 21:47:13.388456 17220 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0628 21:47:16.843941  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:47:16.986543 17220 solver.cpp:330] Iteration 8000, Testing net (#0)
I0628 21:47:16.987043 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:47:17.808629 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:47:17.839149 17220 solver.cpp:397]     Test net output #0: accuracy = 0.763
I0628 21:47:17.839149 17220 solver.cpp:397]     Test net output #1: loss = 0.718507 (* 1 = 0.718507 loss)
I0628 21:47:17.874174 17220 solver.cpp:218] Iteration 8000 (22.2947 iter/s, 4.48537s/100 iters), loss = 0.56943
I0628 21:47:17.874174 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0628 21:47:17.874174 17220 solver.cpp:237]     Train net output #1: loss = 0.56943 (* 1 = 0.56943 loss)
I0628 21:47:17.874174 17220 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0628 21:47:21.496680 17220 solver.cpp:218] Iteration 8100 (27.6051 iter/s, 3.62252s/100 iters), loss = 0.396626
I0628 21:47:21.496680 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:47:21.496680 17220 solver.cpp:237]     Train net output #1: loss = 0.396626 (* 1 = 0.396626 loss)
I0628 21:47:21.497179 17220 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0628 21:47:25.122149 17220 solver.cpp:218] Iteration 8200 (27.5882 iter/s, 3.62474s/100 iters), loss = 0.563442
I0628 21:47:25.122149 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 21:47:25.122149 17220 solver.cpp:237]     Train net output #1: loss = 0.563442 (* 1 = 0.563442 loss)
I0628 21:47:25.122149 17220 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0628 21:47:28.749160 17220 solver.cpp:218] Iteration 8300 (27.5734 iter/s, 3.62669s/100 iters), loss = 0.471438
I0628 21:47:28.749160 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 21:47:28.749160 17220 solver.cpp:237]     Train net output #1: loss = 0.471438 (* 1 = 0.471438 loss)
I0628 21:47:28.749160 17220 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0628 21:47:32.379323 17220 solver.cpp:218] Iteration 8400 (27.5475 iter/s, 3.63009s/100 iters), loss = 0.418959
I0628 21:47:32.379323 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:47:32.379323 17220 solver.cpp:237]     Train net output #1: loss = 0.418959 (* 1 = 0.418959 loss)
I0628 21:47:32.379323 17220 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0628 21:47:35.833343  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:47:35.976444 17220 solver.cpp:330] Iteration 8500, Testing net (#0)
I0628 21:47:35.976444 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:47:36.798538 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:47:36.829067 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7863
I0628 21:47:36.829067 17220 solver.cpp:397]     Test net output #1: loss = 0.638739 (* 1 = 0.638739 loss)
I0628 21:47:36.863587 17220 solver.cpp:218] Iteration 8500 (22.302 iter/s, 4.48391s/100 iters), loss = 0.591232
I0628 21:47:36.863587 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 21:47:36.863587 17220 solver.cpp:237]     Train net output #1: loss = 0.591232 (* 1 = 0.591232 loss)
I0628 21:47:36.863587 17220 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0628 21:47:40.486693 17220 solver.cpp:218] Iteration 8600 (27.6029 iter/s, 3.62281s/100 iters), loss = 0.35179
I0628 21:47:40.486693 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:47:40.486693 17220 solver.cpp:237]     Train net output #1: loss = 0.35179 (* 1 = 0.35179 loss)
I0628 21:47:40.486693 17220 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0628 21:47:44.111770 17220 solver.cpp:218] Iteration 8700 (27.5887 iter/s, 3.62468s/100 iters), loss = 0.457449
I0628 21:47:44.111770 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 21:47:44.111770 17220 solver.cpp:237]     Train net output #1: loss = 0.457449 (* 1 = 0.457449 loss)
I0628 21:47:44.111770 17220 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0628 21:47:47.732976 17220 solver.cpp:218] Iteration 8800 (27.6189 iter/s, 3.6207s/100 iters), loss = 0.560663
I0628 21:47:47.732976 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:47:47.732976 17220 solver.cpp:237]     Train net output #1: loss = 0.560663 (* 1 = 0.560663 loss)
I0628 21:47:47.732976 17220 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0628 21:47:51.361045 17220 solver.cpp:218] Iteration 8900 (27.5669 iter/s, 3.62754s/100 iters), loss = 0.493654
I0628 21:47:51.361045 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 21:47:51.361045 17220 solver.cpp:237]     Train net output #1: loss = 0.493654 (* 1 = 0.493654 loss)
I0628 21:47:51.361045 17220 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0628 21:47:54.814502  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:47:54.956120 17220 solver.cpp:330] Iteration 9000, Testing net (#0)
I0628 21:47:54.956120 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:47:55.783709 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:47:55.814714 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7929
I0628 21:47:55.814714 17220 solver.cpp:397]     Test net output #1: loss = 0.620185 (* 1 = 0.620185 loss)
I0628 21:47:55.848738 17220 solver.cpp:218] Iteration 9000 (22.2832 iter/s, 4.48769s/100 iters), loss = 0.465211
I0628 21:47:55.848738 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 21:47:55.848738 17220 solver.cpp:237]     Train net output #1: loss = 0.465211 (* 1 = 0.465211 loss)
I0628 21:47:55.848738 17220 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0628 21:47:59.478363 17220 solver.cpp:218] Iteration 9100 (27.5551 iter/s, 3.62909s/100 iters), loss = 0.418575
I0628 21:47:59.478363 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:47:59.478363 17220 solver.cpp:237]     Train net output #1: loss = 0.418575 (* 1 = 0.418575 loss)
I0628 21:47:59.478363 17220 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0628 21:48:03.104979 17220 solver.cpp:218] Iteration 9200 (27.5779 iter/s, 3.6261s/100 iters), loss = 0.482926
I0628 21:48:03.104979 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0628 21:48:03.104979 17220 solver.cpp:237]     Train net output #1: loss = 0.482926 (* 1 = 0.482926 loss)
I0628 21:48:03.104979 17220 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0628 21:48:06.730921 17220 solver.cpp:218] Iteration 9300 (27.5787 iter/s, 3.62599s/100 iters), loss = 0.484295
I0628 21:48:06.731426 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:48:06.731426 17220 solver.cpp:237]     Train net output #1: loss = 0.484295 (* 1 = 0.484295 loss)
I0628 21:48:06.731426 17220 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0628 21:48:10.373525 17220 solver.cpp:218] Iteration 9400 (27.4557 iter/s, 3.64224s/100 iters), loss = 0.396067
I0628 21:48:10.373525 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:48:10.374027 17220 solver.cpp:237]     Train net output #1: loss = 0.396067 (* 1 = 0.396067 loss)
I0628 21:48:10.374027 17220 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0628 21:48:13.839061  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:48:13.981678 17220 solver.cpp:330] Iteration 9500, Testing net (#0)
I0628 21:48:13.981678 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:48:14.811303 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:48:14.842329 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7749
I0628 21:48:14.842329 17220 solver.cpp:397]     Test net output #1: loss = 0.668256 (* 1 = 0.668256 loss)
I0628 21:48:14.877348 17220 solver.cpp:218] Iteration 9500 (22.2053 iter/s, 4.50342s/100 iters), loss = 0.394354
I0628 21:48:14.877348 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:48:14.877848 17220 solver.cpp:237]     Train net output #1: loss = 0.394354 (* 1 = 0.394354 loss)
I0628 21:48:14.877848 17220 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0628 21:48:18.502426 17220 solver.cpp:218] Iteration 9600 (27.5896 iter/s, 3.62455s/100 iters), loss = 0.471017
I0628 21:48:18.502426 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:48:18.502426 17220 solver.cpp:237]     Train net output #1: loss = 0.471017 (* 1 = 0.471017 loss)
I0628 21:48:18.502426 17220 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0628 21:48:22.138119 17220 solver.cpp:218] Iteration 9700 (27.5093 iter/s, 3.63513s/100 iters), loss = 0.461529
I0628 21:48:22.138119 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 21:48:22.138119 17220 solver.cpp:237]     Train net output #1: loss = 0.461529 (* 1 = 0.461529 loss)
I0628 21:48:22.138119 17220 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0628 21:48:25.763293 17220 solver.cpp:218] Iteration 9800 (27.5857 iter/s, 3.62506s/100 iters), loss = 0.414267
I0628 21:48:25.763797 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:48:25.763797 17220 solver.cpp:237]     Train net output #1: loss = 0.414267 (* 1 = 0.414267 loss)
I0628 21:48:25.763797 17220 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0628 21:48:29.386358 17220 solver.cpp:218] Iteration 9900 (27.6064 iter/s, 3.62235s/100 iters), loss = 0.37266
I0628 21:48:29.386358 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:48:29.386358 17220 solver.cpp:237]     Train net output #1: loss = 0.37266 (* 1 = 0.37266 loss)
I0628 21:48:29.386358 17220 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0628 21:48:32.837815  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:48:32.979930 17220 solver.cpp:330] Iteration 10000, Testing net (#0)
I0628 21:48:32.979930 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:48:33.801515 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:48:33.832532 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8055
I0628 21:48:33.832532 17220 solver.cpp:397]     Test net output #1: loss = 0.570379 (* 1 = 0.570379 loss)
I0628 21:48:33.867059 17220 solver.cpp:218] Iteration 10000 (22.3197 iter/s, 4.48035s/100 iters), loss = 0.428846
I0628 21:48:33.867059 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:48:33.867059 17220 solver.cpp:237]     Train net output #1: loss = 0.428846 (* 1 = 0.428846 loss)
I0628 21:48:33.867059 17220 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0628 21:48:37.496656 17220 solver.cpp:218] Iteration 10100 (27.5519 iter/s, 3.62951s/100 iters), loss = 0.480497
I0628 21:48:37.496656 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:48:37.496656 17220 solver.cpp:237]     Train net output #1: loss = 0.480497 (* 1 = 0.480497 loss)
I0628 21:48:37.496656 17220 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0628 21:48:41.117743 17220 solver.cpp:218] Iteration 10200 (27.6206 iter/s, 3.62049s/100 iters), loss = 0.44879
I0628 21:48:41.117743 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:48:41.117743 17220 solver.cpp:237]     Train net output #1: loss = 0.44879 (* 1 = 0.44879 loss)
I0628 21:48:41.117743 17220 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0628 21:48:44.749316 17220 solver.cpp:218] Iteration 10300 (27.5396 iter/s, 3.63113s/100 iters), loss = 0.465744
I0628 21:48:44.749316 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:48:44.749316 17220 solver.cpp:237]     Train net output #1: loss = 0.465744 (* 1 = 0.465744 loss)
I0628 21:48:44.749316 17220 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0628 21:48:48.381979 17220 solver.cpp:218] Iteration 10400 (27.5288 iter/s, 3.63255s/100 iters), loss = 0.35787
I0628 21:48:48.381979 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:48:48.381979 17220 solver.cpp:237]     Train net output #1: loss = 0.35787 (* 1 = 0.35787 loss)
I0628 21:48:48.381979 17220 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0628 21:48:51.834017  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:48:51.976114 17220 solver.cpp:330] Iteration 10500, Testing net (#0)
I0628 21:48:51.976114 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:48:52.800191 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:48:52.831228 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8063
I0628 21:48:52.831228 17220 solver.cpp:397]     Test net output #1: loss = 0.571966 (* 1 = 0.571966 loss)
I0628 21:48:52.865236 17220 solver.cpp:218] Iteration 10500 (22.3066 iter/s, 4.48298s/100 iters), loss = 0.438857
I0628 21:48:52.865236 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:48:52.865236 17220 solver.cpp:237]     Train net output #1: loss = 0.438857 (* 1 = 0.438857 loss)
I0628 21:48:52.865236 17220 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0628 21:48:56.500746 17220 solver.cpp:218] Iteration 10600 (27.5092 iter/s, 3.63515s/100 iters), loss = 0.403866
I0628 21:48:56.500746 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:48:56.500746 17220 solver.cpp:237]     Train net output #1: loss = 0.403866 (* 1 = 0.403866 loss)
I0628 21:48:56.500746 17220 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0628 21:49:00.146185 17220 solver.cpp:218] Iteration 10700 (27.4353 iter/s, 3.64494s/100 iters), loss = 0.424809
I0628 21:49:00.146185 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:49:00.146185 17220 solver.cpp:237]     Train net output #1: loss = 0.424809 (* 1 = 0.424809 loss)
I0628 21:49:00.146185 17220 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0628 21:49:03.787778 17220 solver.cpp:218] Iteration 10800 (27.4625 iter/s, 3.64133s/100 iters), loss = 0.553384
I0628 21:49:03.787778 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:49:03.787778 17220 solver.cpp:237]     Train net output #1: loss = 0.553384 (* 1 = 0.553384 loss)
I0628 21:49:03.787778 17220 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0628 21:49:07.426355 17220 solver.cpp:218] Iteration 10900 (27.4861 iter/s, 3.6382s/100 iters), loss = 0.377376
I0628 21:49:07.426355 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:49:07.426355 17220 solver.cpp:237]     Train net output #1: loss = 0.377376 (* 1 = 0.377376 loss)
I0628 21:49:07.426355 17220 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0628 21:49:10.887877  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:49:11.030477 17220 solver.cpp:330] Iteration 11000, Testing net (#0)
I0628 21:49:11.030477 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:49:11.852078 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:49:11.883117 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8043
I0628 21:49:11.883117 17220 solver.cpp:397]     Test net output #1: loss = 0.574144 (* 1 = 0.574144 loss)
I0628 21:49:11.917623 17220 solver.cpp:218] Iteration 11000 (22.2694 iter/s, 4.49047s/100 iters), loss = 0.385688
I0628 21:49:11.917623 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:49:11.917623 17220 solver.cpp:237]     Train net output #1: loss = 0.385688 (* 1 = 0.385688 loss)
I0628 21:49:11.917623 17220 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0628 21:49:15.551230 17220 solver.cpp:218] Iteration 11100 (27.5208 iter/s, 3.63361s/100 iters), loss = 0.415376
I0628 21:49:15.551230 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:49:15.551230 17220 solver.cpp:237]     Train net output #1: loss = 0.415376 (* 1 = 0.415376 loss)
I0628 21:49:15.551230 17220 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0628 21:49:19.173882 17220 solver.cpp:218] Iteration 11200 (27.6066 iter/s, 3.62232s/100 iters), loss = 0.412625
I0628 21:49:19.173882 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:49:19.173882 17220 solver.cpp:237]     Train net output #1: loss = 0.412625 (* 1 = 0.412625 loss)
I0628 21:49:19.173882 17220 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0628 21:49:22.799962 17220 solver.cpp:218] Iteration 11300 (27.5822 iter/s, 3.62552s/100 iters), loss = 0.470589
I0628 21:49:22.799962 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:49:22.799962 17220 solver.cpp:237]     Train net output #1: loss = 0.470589 (* 1 = 0.470589 loss)
I0628 21:49:22.799962 17220 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0628 21:49:26.418560 17220 solver.cpp:218] Iteration 11400 (27.6353 iter/s, 3.61856s/100 iters), loss = 0.311226
I0628 21:49:26.419064 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:49:26.419064 17220 solver.cpp:237]     Train net output #1: loss = 0.311226 (* 1 = 0.311226 loss)
I0628 21:49:26.419064 17220 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0628 21:49:29.864519  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:49:30.006603 17220 solver.cpp:330] Iteration 11500, Testing net (#0)
I0628 21:49:30.006603 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:49:30.829203 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:49:30.859724 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8067
I0628 21:49:30.859724 17220 solver.cpp:397]     Test net output #1: loss = 0.598046 (* 1 = 0.598046 loss)
I0628 21:49:30.894246 17220 solver.cpp:218] Iteration 11500 (22.3469 iter/s, 4.47488s/100 iters), loss = 0.367104
I0628 21:49:30.894246 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:49:30.894246 17220 solver.cpp:237]     Train net output #1: loss = 0.367104 (* 1 = 0.367104 loss)
I0628 21:49:30.894246 17220 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0628 21:49:34.524364 17220 solver.cpp:218] Iteration 11600 (27.5474 iter/s, 3.63011s/100 iters), loss = 0.457161
I0628 21:49:34.524364 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:49:34.524364 17220 solver.cpp:237]     Train net output #1: loss = 0.457161 (* 1 = 0.457161 loss)
I0628 21:49:34.524364 17220 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0628 21:49:38.141449 17220 solver.cpp:218] Iteration 11700 (27.6508 iter/s, 3.61653s/100 iters), loss = 0.417571
I0628 21:49:38.141449 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:49:38.141449 17220 solver.cpp:237]     Train net output #1: loss = 0.417571 (* 1 = 0.417571 loss)
I0628 21:49:38.141449 17220 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0628 21:49:41.776906 17220 solver.cpp:218] Iteration 11800 (27.5082 iter/s, 3.63528s/100 iters), loss = 0.369441
I0628 21:49:41.776906 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:49:41.776906 17220 solver.cpp:237]     Train net output #1: loss = 0.369441 (* 1 = 0.369441 loss)
I0628 21:49:41.776906 17220 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0628 21:49:45.413493 17220 solver.cpp:218] Iteration 11900 (27.5002 iter/s, 3.63634s/100 iters), loss = 0.38522
I0628 21:49:45.413995 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:49:45.413995 17220 solver.cpp:237]     Train net output #1: loss = 0.38522 (* 1 = 0.38522 loss)
I0628 21:49:45.413995 17220 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0628 21:49:48.862016  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:49:49.004618 17220 solver.cpp:330] Iteration 12000, Testing net (#0)
I0628 21:49:49.004618 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:49:49.826202 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:49:49.857225 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7951
I0628 21:49:49.857225 17220 solver.cpp:397]     Test net output #1: loss = 0.618494 (* 1 = 0.618494 loss)
I0628 21:49:49.891249 17220 solver.cpp:218] Iteration 12000 (22.3349 iter/s, 4.47729s/100 iters), loss = 0.428529
I0628 21:49:49.891249 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:49:49.891249 17220 solver.cpp:237]     Train net output #1: loss = 0.428529 (* 1 = 0.428529 loss)
I0628 21:49:49.891249 17220 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0628 21:49:53.529837 17220 solver.cpp:218] Iteration 12100 (27.4862 iter/s, 3.63819s/100 iters), loss = 0.382889
I0628 21:49:53.529837 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:49:53.529837 17220 solver.cpp:237]     Train net output #1: loss = 0.382889 (* 1 = 0.382889 loss)
I0628 21:49:53.529837 17220 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0628 21:49:57.183938 17220 solver.cpp:218] Iteration 12200 (27.3711 iter/s, 3.65349s/100 iters), loss = 0.345175
I0628 21:49:57.183938 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:49:57.183938 17220 solver.cpp:237]     Train net output #1: loss = 0.345175 (* 1 = 0.345175 loss)
I0628 21:49:57.183938 17220 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0628 21:50:00.826313 17220 solver.cpp:218] Iteration 12300 (27.4566 iter/s, 3.64211s/100 iters), loss = 0.494279
I0628 21:50:00.826313 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:50:00.826313 17220 solver.cpp:237]     Train net output #1: loss = 0.494279 (* 1 = 0.494279 loss)
I0628 21:50:00.826313 17220 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0628 21:50:04.461930 17220 solver.cpp:218] Iteration 12400 (27.5092 iter/s, 3.63515s/100 iters), loss = 0.334015
I0628 21:50:04.461930 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:50:04.461930 17220 solver.cpp:237]     Train net output #1: loss = 0.334015 (* 1 = 0.334015 loss)
I0628 21:50:04.461930 17220 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0628 21:50:07.916899  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:50:08.059500 17220 solver.cpp:330] Iteration 12500, Testing net (#0)
I0628 21:50:08.059500 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:50:08.882586 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:50:08.913609 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8118
I0628 21:50:08.913609 17220 solver.cpp:397]     Test net output #1: loss = 0.559826 (* 1 = 0.559826 loss)
I0628 21:50:08.947633 17220 solver.cpp:218] Iteration 12500 (22.2933 iter/s, 4.48565s/100 iters), loss = 0.458284
I0628 21:50:08.947633 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:50:08.947633 17220 solver.cpp:237]     Train net output #1: loss = 0.458284 (* 1 = 0.458284 loss)
I0628 21:50:08.948132 17220 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0628 21:50:12.575713 17220 solver.cpp:218] Iteration 12600 (27.5682 iter/s, 3.62736s/100 iters), loss = 0.382062
I0628 21:50:12.575713 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:50:12.575713 17220 solver.cpp:237]     Train net output #1: loss = 0.382062 (* 1 = 0.382062 loss)
I0628 21:50:12.575713 17220 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0628 21:50:16.207324 17220 solver.cpp:218] Iteration 12700 (27.5352 iter/s, 3.63172s/100 iters), loss = 0.353531
I0628 21:50:16.207825 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:50:16.207825 17220 solver.cpp:237]     Train net output #1: loss = 0.353531 (* 1 = 0.353531 loss)
I0628 21:50:16.207825 17220 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0628 21:50:19.833905 17220 solver.cpp:218] Iteration 12800 (27.5805 iter/s, 3.62575s/100 iters), loss = 0.456354
I0628 21:50:19.833905 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:50:19.833905 17220 solver.cpp:237]     Train net output #1: loss = 0.456354 (* 1 = 0.456354 loss)
I0628 21:50:19.833905 17220 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0628 21:50:23.463987 17220 solver.cpp:218] Iteration 12900 (27.5473 iter/s, 3.63013s/100 iters), loss = 0.237725
I0628 21:50:23.463987 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:50:23.463987 17220 solver.cpp:237]     Train net output #1: loss = 0.237725 (* 1 = 0.237725 loss)
I0628 21:50:23.463987 17220 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0628 21:50:26.917444  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:50:27.060046 17220 solver.cpp:330] Iteration 13000, Testing net (#0)
I0628 21:50:27.060046 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:50:27.884632 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:50:27.915654 17220 solver.cpp:397]     Test net output #0: accuracy = 0.818
I0628 21:50:27.915654 17220 solver.cpp:397]     Test net output #1: loss = 0.550503 (* 1 = 0.550503 loss)
I0628 21:50:27.949679 17220 solver.cpp:218] Iteration 13000 (22.2949 iter/s, 4.48534s/100 iters), loss = 0.442028
I0628 21:50:27.949679 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:50:27.949679 17220 solver.cpp:237]     Train net output #1: loss = 0.442028 (* 1 = 0.442028 loss)
I0628 21:50:27.949679 17220 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0628 21:50:31.573757 17220 solver.cpp:218] Iteration 13100 (27.5979 iter/s, 3.62346s/100 iters), loss = 0.405184
I0628 21:50:31.573757 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:50:31.573757 17220 solver.cpp:237]     Train net output #1: loss = 0.405184 (* 1 = 0.405184 loss)
I0628 21:50:31.573757 17220 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0628 21:50:35.213367 17220 solver.cpp:218] Iteration 13200 (27.4769 iter/s, 3.63942s/100 iters), loss = 0.36929
I0628 21:50:35.213367 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:50:35.213367 17220 solver.cpp:237]     Train net output #1: loss = 0.36929 (* 1 = 0.36929 loss)
I0628 21:50:35.213367 17220 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0628 21:50:38.843449 17220 solver.cpp:218] Iteration 13300 (27.5522 iter/s, 3.62947s/100 iters), loss = 0.378356
I0628 21:50:38.843449 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:50:38.843449 17220 solver.cpp:237]     Train net output #1: loss = 0.378356 (* 1 = 0.378356 loss)
I0628 21:50:38.843449 17220 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0628 21:50:42.481061 17220 solver.cpp:218] Iteration 13400 (27.4904 iter/s, 3.63763s/100 iters), loss = 0.340924
I0628 21:50:42.481061 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:50:42.481061 17220 solver.cpp:237]     Train net output #1: loss = 0.340924 (* 1 = 0.340924 loss)
I0628 21:50:42.481061 17220 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0628 21:50:45.938596  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:50:46.081198 17220 solver.cpp:330] Iteration 13500, Testing net (#0)
I0628 21:50:46.081198 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:50:46.902329 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:50:46.933351 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8329
I0628 21:50:46.933351 17220 solver.cpp:397]     Test net output #1: loss = 0.499492 (* 1 = 0.499492 loss)
I0628 21:50:46.967876 17220 solver.cpp:218] Iteration 13500 (22.29 iter/s, 4.48631s/100 iters), loss = 0.33253
I0628 21:50:46.967876 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:50:46.967876 17220 solver.cpp:237]     Train net output #1: loss = 0.33253 (* 1 = 0.33253 loss)
I0628 21:50:46.967876 17220 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0628 21:50:50.603322 17220 solver.cpp:218] Iteration 13600 (27.5099 iter/s, 3.63506s/100 iters), loss = 0.439447
I0628 21:50:50.603322 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:50:50.603322 17220 solver.cpp:237]     Train net output #1: loss = 0.439447 (* 1 = 0.439447 loss)
I0628 21:50:50.603322 17220 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0628 21:50:54.225163 17220 solver.cpp:218] Iteration 13700 (27.6112 iter/s, 3.62172s/100 iters), loss = 0.440408
I0628 21:50:54.225664 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:50:54.225664 17220 solver.cpp:237]     Train net output #1: loss = 0.440408 (* 1 = 0.440408 loss)
I0628 21:50:54.225664 17220 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0628 21:50:57.853245 17220 solver.cpp:218] Iteration 13800 (27.5668 iter/s, 3.62755s/100 iters), loss = 0.489095
I0628 21:50:57.853245 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:50:57.853245 17220 solver.cpp:237]     Train net output #1: loss = 0.489095 (* 1 = 0.489095 loss)
I0628 21:50:57.853245 17220 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0628 21:51:01.493849 17220 solver.cpp:218] Iteration 13900 (27.4714 iter/s, 3.64015s/100 iters), loss = 0.206127
I0628 21:51:01.493849 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:51:01.493849 17220 solver.cpp:237]     Train net output #1: loss = 0.206126 (* 1 = 0.206126 loss)
I0628 21:51:01.493849 17220 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0628 21:51:04.947823  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:51:05.090407 17220 solver.cpp:330] Iteration 14000, Testing net (#0)
I0628 21:51:05.090407 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:51:05.912492 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:51:05.943014 17220 solver.cpp:397]     Test net output #0: accuracy = 0.7688
I0628 21:51:05.943514 17220 solver.cpp:397]     Test net output #1: loss = 0.738343 (* 1 = 0.738343 loss)
I0628 21:51:05.977538 17220 solver.cpp:218] Iteration 14000 (22.3053 iter/s, 4.48324s/100 iters), loss = 0.384525
I0628 21:51:05.977538 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:51:05.977538 17220 solver.cpp:237]     Train net output #1: loss = 0.384524 (* 1 = 0.384524 loss)
I0628 21:51:05.977538 17220 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0628 21:51:09.612143 17220 solver.cpp:218] Iteration 14100 (27.5134 iter/s, 3.6346s/100 iters), loss = 0.429296
I0628 21:51:09.612143 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:51:09.612644 17220 solver.cpp:237]     Train net output #1: loss = 0.429295 (* 1 = 0.429295 loss)
I0628 21:51:09.612644 17220 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0628 21:51:13.254235 17220 solver.cpp:218] Iteration 14200 (27.4593 iter/s, 3.64175s/100 iters), loss = 0.316112
I0628 21:51:13.254735 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:51:13.254735 17220 solver.cpp:237]     Train net output #1: loss = 0.316112 (* 1 = 0.316112 loss)
I0628 21:51:13.254735 17220 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0628 21:51:16.887820 17220 solver.cpp:218] Iteration 14300 (27.5238 iter/s, 3.63322s/100 iters), loss = 0.297597
I0628 21:51:16.888321 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:51:16.888321 17220 solver.cpp:237]     Train net output #1: loss = 0.297596 (* 1 = 0.297596 loss)
I0628 21:51:16.888321 17220 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0628 21:51:20.514914 17220 solver.cpp:218] Iteration 14400 (27.5729 iter/s, 3.62675s/100 iters), loss = 0.364963
I0628 21:51:20.515414 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:51:20.515414 17220 solver.cpp:237]     Train net output #1: loss = 0.364963 (* 1 = 0.364963 loss)
I0628 21:51:20.515414 17220 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0628 21:51:23.975782  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:51:24.118883 17220 solver.cpp:330] Iteration 14500, Testing net (#0)
I0628 21:51:24.118883 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:51:24.940131 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:51:24.971170 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8344
I0628 21:51:24.971170 17220 solver.cpp:397]     Test net output #1: loss = 0.495441 (* 1 = 0.495441 loss)
I0628 21:51:25.005687 17220 solver.cpp:218] Iteration 14500 (22.2708 iter/s, 4.49018s/100 iters), loss = 0.421142
I0628 21:51:25.005687 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:51:25.005687 17220 solver.cpp:237]     Train net output #1: loss = 0.421142 (* 1 = 0.421142 loss)
I0628 21:51:25.005687 17220 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0628 21:51:28.637771 17220 solver.cpp:218] Iteration 14600 (27.5334 iter/s, 3.63195s/100 iters), loss = 0.360315
I0628 21:51:28.637771 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:51:28.638273 17220 solver.cpp:237]     Train net output #1: loss = 0.360315 (* 1 = 0.360315 loss)
I0628 21:51:28.638273 17220 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0628 21:51:32.265943 17220 solver.cpp:218] Iteration 14700 (27.5676 iter/s, 3.62744s/100 iters), loss = 0.320138
I0628 21:51:32.265943 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:51:32.265943 17220 solver.cpp:237]     Train net output #1: loss = 0.320138 (* 1 = 0.320138 loss)
I0628 21:51:32.265943 17220 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0628 21:51:35.893656 17220 solver.cpp:218] Iteration 14800 (27.5673 iter/s, 3.62749s/100 iters), loss = 0.476701
I0628 21:51:35.893656 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 21:51:35.893656 17220 solver.cpp:237]     Train net output #1: loss = 0.476701 (* 1 = 0.476701 loss)
I0628 21:51:35.893656 17220 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0628 21:51:39.520725 17220 solver.cpp:218] Iteration 14900 (27.5743 iter/s, 3.62656s/100 iters), loss = 0.247632
I0628 21:51:39.520725 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:51:39.520725 17220 solver.cpp:237]     Train net output #1: loss = 0.247632 (* 1 = 0.247632 loss)
I0628 21:51:39.520725 17220 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0628 21:51:42.965750  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:51:43.107836 17220 solver.cpp:330] Iteration 15000, Testing net (#0)
I0628 21:51:43.108336 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:51:43.930935 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:51:43.961956 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8236
I0628 21:51:43.962455 17220 solver.cpp:397]     Test net output #1: loss = 0.545083 (* 1 = 0.545083 loss)
I0628 21:51:43.996469 17220 solver.cpp:218] Iteration 15000 (22.3424 iter/s, 4.47579s/100 iters), loss = 0.437676
I0628 21:51:43.996469 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:51:43.996469 17220 solver.cpp:237]     Train net output #1: loss = 0.437676 (* 1 = 0.437676 loss)
I0628 21:51:43.996970 17220 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0628 21:51:47.631450 17220 solver.cpp:218] Iteration 15100 (27.5155 iter/s, 3.63432s/100 iters), loss = 0.313765
I0628 21:51:47.631450 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:51:47.631450 17220 solver.cpp:237]     Train net output #1: loss = 0.313764 (* 1 = 0.313764 loss)
I0628 21:51:47.631450 17220 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0628 21:51:51.233561 17220 solver.cpp:218] Iteration 15200 (27.7649 iter/s, 3.60167s/100 iters), loss = 0.388943
I0628 21:51:51.233561 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:51:51.233561 17220 solver.cpp:237]     Train net output #1: loss = 0.388943 (* 1 = 0.388943 loss)
I0628 21:51:51.233561 17220 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0628 21:51:54.847406 17220 solver.cpp:218] Iteration 15300 (27.6738 iter/s, 3.61353s/100 iters), loss = 0.383938
I0628 21:51:54.847406 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:51:54.847406 17220 solver.cpp:237]     Train net output #1: loss = 0.383938 (* 1 = 0.383938 loss)
I0628 21:51:54.847406 17220 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0628 21:51:58.463953 17220 solver.cpp:218] Iteration 15400 (27.6511 iter/s, 3.61649s/100 iters), loss = 0.249998
I0628 21:51:58.464460 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:51:58.464460 17220 solver.cpp:237]     Train net output #1: loss = 0.249997 (* 1 = 0.249997 loss)
I0628 21:51:58.464460 17220 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0628 21:52:01.919441  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:52:02.062042 17220 solver.cpp:330] Iteration 15500, Testing net (#0)
I0628 21:52:02.062042 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:52:02.884127 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:52:02.915149 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8342
I0628 21:52:02.915149 17220 solver.cpp:397]     Test net output #1: loss = 0.499216 (* 1 = 0.499216 loss)
I0628 21:52:02.949173 17220 solver.cpp:218] Iteration 15500 (22.2984 iter/s, 4.48463s/100 iters), loss = 0.311712
I0628 21:52:02.949173 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:52:02.949173 17220 solver.cpp:237]     Train net output #1: loss = 0.311712 (* 1 = 0.311712 loss)
I0628 21:52:02.949173 17220 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0628 21:52:06.590575 17220 solver.cpp:218] Iteration 15600 (27.4644 iter/s, 3.64107s/100 iters), loss = 0.418575
I0628 21:52:06.590575 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:52:06.590575 17220 solver.cpp:237]     Train net output #1: loss = 0.418575 (* 1 = 0.418575 loss)
I0628 21:52:06.591075 17220 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0628 21:52:10.220145 17220 solver.cpp:218] Iteration 15700 (27.5568 iter/s, 3.62887s/100 iters), loss = 0.27914
I0628 21:52:10.220145 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:52:10.220145 17220 solver.cpp:237]     Train net output #1: loss = 0.27914 (* 1 = 0.27914 loss)
I0628 21:52:10.220145 17220 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0628 21:52:13.856732 17220 solver.cpp:218] Iteration 15800 (27.4991 iter/s, 3.63648s/100 iters), loss = 0.408753
I0628 21:52:13.856732 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:52:13.856732 17220 solver.cpp:237]     Train net output #1: loss = 0.408753 (* 1 = 0.408753 loss)
I0628 21:52:13.856732 17220 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0628 21:52:17.488441 17220 solver.cpp:218] Iteration 15900 (27.5396 iter/s, 3.63114s/100 iters), loss = 0.333161
I0628 21:52:17.488441 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:52:17.488441 17220 solver.cpp:237]     Train net output #1: loss = 0.333161 (* 1 = 0.333161 loss)
I0628 21:52:17.488441 17220 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0628 21:52:20.943384  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:52:21.086001 17220 solver.cpp:330] Iteration 16000, Testing net (#0)
I0628 21:52:21.086001 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:52:21.910145 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:52:21.940662 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8284
I0628 21:52:21.941165 17220 solver.cpp:397]     Test net output #1: loss = 0.501447 (* 1 = 0.501447 loss)
I0628 21:52:21.975178 17220 solver.cpp:218] Iteration 16000 (22.2895 iter/s, 4.48641s/100 iters), loss = 0.367117
I0628 21:52:21.975178 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:52:21.975178 17220 solver.cpp:237]     Train net output #1: loss = 0.367117 (* 1 = 0.367117 loss)
I0628 21:52:21.975178 17220 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0628 21:52:25.616267 17220 solver.cpp:218] Iteration 16100 (27.4665 iter/s, 3.6408s/100 iters), loss = 0.366467
I0628 21:52:25.616267 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:52:25.616267 17220 solver.cpp:237]     Train net output #1: loss = 0.366467 (* 1 = 0.366467 loss)
I0628 21:52:25.616267 17220 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0628 21:52:29.286540 17220 solver.cpp:218] Iteration 16200 (27.2509 iter/s, 3.6696s/100 iters), loss = 0.423814
I0628 21:52:29.286540 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 21:52:29.286540 17220 solver.cpp:237]     Train net output #1: loss = 0.423814 (* 1 = 0.423814 loss)
I0628 21:52:29.286540 17220 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0628 21:52:33.029172 17220 solver.cpp:218] Iteration 16300 (26.7214 iter/s, 3.74232s/100 iters), loss = 0.336511
I0628 21:52:33.029172 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:52:33.029172 17220 solver.cpp:237]     Train net output #1: loss = 0.336511 (* 1 = 0.336511 loss)
I0628 21:52:33.029172 17220 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0628 21:52:36.828377 17220 solver.cpp:218] Iteration 16400 (26.3238 iter/s, 3.79884s/100 iters), loss = 0.242418
I0628 21:52:36.828377 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:52:36.828377 17220 solver.cpp:237]     Train net output #1: loss = 0.242418 (* 1 = 0.242418 loss)
I0628 21:52:36.828377 17220 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0628 21:52:40.374899  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:52:40.519502 17220 solver.cpp:330] Iteration 16500, Testing net (#0)
I0628 21:52:40.519502 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:52:41.361101 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:52:41.394124 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8127
I0628 21:52:41.394124 17220 solver.cpp:397]     Test net output #1: loss = 0.572402 (* 1 = 0.572402 loss)
I0628 21:52:41.430663 17220 solver.cpp:218] Iteration 16500 (21.7292 iter/s, 4.6021s/100 iters), loss = 0.321541
I0628 21:52:41.430663 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:52:41.430663 17220 solver.cpp:237]     Train net output #1: loss = 0.321541 (* 1 = 0.321541 loss)
I0628 21:52:41.430663 17220 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0628 21:52:45.208838 17220 solver.cpp:218] Iteration 16600 (26.4704 iter/s, 3.7778s/100 iters), loss = 0.347611
I0628 21:52:45.208838 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:52:45.208838 17220 solver.cpp:237]     Train net output #1: loss = 0.347611 (* 1 = 0.347611 loss)
I0628 21:52:45.208838 17220 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0628 21:52:48.955003 17220 solver.cpp:218] Iteration 16700 (26.6991 iter/s, 3.74545s/100 iters), loss = 0.31255
I0628 21:52:48.955003 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:52:48.955003 17220 solver.cpp:237]     Train net output #1: loss = 0.31255 (* 1 = 0.31255 loss)
I0628 21:52:48.955003 17220 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0628 21:52:52.648888 17220 solver.cpp:218] Iteration 16800 (27.0749 iter/s, 3.69346s/100 iters), loss = 0.447007
I0628 21:52:52.648888 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:52:52.648888 17220 solver.cpp:237]     Train net output #1: loss = 0.447007 (* 1 = 0.447007 loss)
I0628 21:52:52.648888 17220 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0628 21:52:56.282536 17220 solver.cpp:218] Iteration 16900 (27.5221 iter/s, 3.63345s/100 iters), loss = 0.243799
I0628 21:52:56.282536 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:52:56.282536 17220 solver.cpp:237]     Train net output #1: loss = 0.243798 (* 1 = 0.243798 loss)
I0628 21:52:56.282536 17220 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0628 21:52:59.730515  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:52:59.873132 17220 solver.cpp:330] Iteration 17000, Testing net (#0)
I0628 21:52:59.873631 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:53:00.694701 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:53:00.725739 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8269
I0628 21:53:00.725739 17220 solver.cpp:397]     Test net output #1: loss = 0.522489 (* 1 = 0.522489 loss)
I0628 21:53:00.760247 17220 solver.cpp:218] Iteration 17000 (22.3355 iter/s, 4.47717s/100 iters), loss = 0.305613
I0628 21:53:00.760247 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:53:00.760247 17220 solver.cpp:237]     Train net output #1: loss = 0.305613 (* 1 = 0.305613 loss)
I0628 21:53:00.760247 17220 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0628 21:53:04.406354 17220 solver.cpp:218] Iteration 17100 (27.4286 iter/s, 3.64583s/100 iters), loss = 0.360197
I0628 21:53:04.406354 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:53:04.406354 17220 solver.cpp:237]     Train net output #1: loss = 0.360197 (* 1 = 0.360197 loss)
I0628 21:53:04.406354 17220 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0628 21:53:08.056447 17220 solver.cpp:218] Iteration 17200 (27.3998 iter/s, 3.64966s/100 iters), loss = 0.341621
I0628 21:53:08.056447 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:53:08.056447 17220 solver.cpp:237]     Train net output #1: loss = 0.341621 (* 1 = 0.341621 loss)
I0628 21:53:08.056447 17220 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0628 21:53:11.712100 17220 solver.cpp:218] Iteration 17300 (27.3556 iter/s, 3.65556s/100 iters), loss = 0.353927
I0628 21:53:11.712600 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:53:11.712600 17220 solver.cpp:237]     Train net output #1: loss = 0.353927 (* 1 = 0.353927 loss)
I0628 21:53:11.712600 17220 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0628 21:53:15.352706 17220 solver.cpp:218] Iteration 17400 (27.4742 iter/s, 3.63978s/100 iters), loss = 0.326598
I0628 21:53:15.352706 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:53:15.352706 17220 solver.cpp:237]     Train net output #1: loss = 0.326598 (* 1 = 0.326598 loss)
I0628 21:53:15.352706 17220 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0628 21:53:18.809648  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:53:18.950762 17220 solver.cpp:330] Iteration 17500, Testing net (#0)
I0628 21:53:18.950762 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:53:19.779867 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:53:19.810863 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8078
I0628 21:53:19.810863 17220 solver.cpp:397]     Test net output #1: loss = 0.573706 (* 1 = 0.573706 loss)
I0628 21:53:19.844898 17220 solver.cpp:218] Iteration 17500 (22.2617 iter/s, 4.49203s/100 iters), loss = 0.382299
I0628 21:53:19.844898 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:53:19.844898 17220 solver.cpp:237]     Train net output #1: loss = 0.382299 (* 1 = 0.382299 loss)
I0628 21:53:19.844898 17220 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0628 21:53:23.465003 17220 solver.cpp:218] Iteration 17600 (27.6266 iter/s, 3.6197s/100 iters), loss = 0.305087
I0628 21:53:23.465003 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:53:23.465003 17220 solver.cpp:237]     Train net output #1: loss = 0.305087 (* 1 = 0.305087 loss)
I0628 21:53:23.465003 17220 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0628 21:53:27.093626 17220 solver.cpp:218] Iteration 17700 (27.5624 iter/s, 3.62813s/100 iters), loss = 0.284898
I0628 21:53:27.093626 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:53:27.093626 17220 solver.cpp:237]     Train net output #1: loss = 0.284898 (* 1 = 0.284898 loss)
I0628 21:53:27.093626 17220 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0628 21:53:30.730247 17220 solver.cpp:218] Iteration 17800 (27.4989 iter/s, 3.63651s/100 iters), loss = 0.438331
I0628 21:53:30.730247 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:53:30.730247 17220 solver.cpp:237]     Train net output #1: loss = 0.438331 (* 1 = 0.438331 loss)
I0628 21:53:30.730247 17220 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0628 21:53:34.397155 17220 solver.cpp:218] Iteration 17900 (27.2759 iter/s, 3.66624s/100 iters), loss = 0.260368
I0628 21:53:34.397155 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:53:34.397155 17220 solver.cpp:237]     Train net output #1: loss = 0.260368 (* 1 = 0.260368 loss)
I0628 21:53:34.397155 17220 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0628 21:53:37.865164  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:53:38.007263 17220 solver.cpp:330] Iteration 18000, Testing net (#0)
I0628 21:53:38.007263 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:53:38.830348 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:53:38.861380 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8153
I0628 21:53:38.861380 17220 solver.cpp:397]     Test net output #1: loss = 0.564567 (* 1 = 0.564567 loss)
I0628 21:53:38.895407 17220 solver.cpp:218] Iteration 18000 (22.2322 iter/s, 4.49797s/100 iters), loss = 0.404434
I0628 21:53:38.895407 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:53:38.895407 17220 solver.cpp:237]     Train net output #1: loss = 0.404434 (* 1 = 0.404434 loss)
I0628 21:53:38.895407 17220 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0628 21:53:42.568424 17220 solver.cpp:218] Iteration 18100 (27.2268 iter/s, 3.67285s/100 iters), loss = 0.204162
I0628 21:53:42.568424 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:53:42.568424 17220 solver.cpp:237]     Train net output #1: loss = 0.204162 (* 1 = 0.204162 loss)
I0628 21:53:42.568925 17220 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0628 21:53:46.232533 17220 solver.cpp:218] Iteration 18200 (27.2951 iter/s, 3.66367s/100 iters), loss = 0.329847
I0628 21:53:46.232533 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:53:46.232533 17220 solver.cpp:237]     Train net output #1: loss = 0.329847 (* 1 = 0.329847 loss)
I0628 21:53:46.232533 17220 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0628 21:53:49.884717 17220 solver.cpp:218] Iteration 18300 (27.3863 iter/s, 3.65146s/100 iters), loss = 0.402716
I0628 21:53:49.884717 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:53:49.884717 17220 solver.cpp:237]     Train net output #1: loss = 0.402716 (* 1 = 0.402716 loss)
I0628 21:53:49.884717 17220 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0628 21:53:53.524433 17220 solver.cpp:218] Iteration 18400 (27.4748 iter/s, 3.6397s/100 iters), loss = 0.250307
I0628 21:53:53.524433 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:53:53.524433 17220 solver.cpp:237]     Train net output #1: loss = 0.250307 (* 1 = 0.250307 loss)
I0628 21:53:53.524433 17220 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0628 21:53:56.958978  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:53:57.100105 17220 solver.cpp:330] Iteration 18500, Testing net (#0)
I0628 21:53:57.100105 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:53:57.921720 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:53:57.952741 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8373
I0628 21:53:57.952741 17220 solver.cpp:397]     Test net output #1: loss = 0.493067 (* 1 = 0.493067 loss)
I0628 21:53:57.986765 17220 solver.cpp:218] Iteration 18500 (22.4117 iter/s, 4.46195s/100 iters), loss = 0.37055
I0628 21:53:57.986765 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:53:57.986765 17220 solver.cpp:237]     Train net output #1: loss = 0.37055 (* 1 = 0.37055 loss)
I0628 21:53:57.986765 17220 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0628 21:54:01.617529 17220 solver.cpp:218] Iteration 18600 (27.5448 iter/s, 3.63046s/100 iters), loss = 0.354689
I0628 21:54:01.617529 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:54:01.617529 17220 solver.cpp:237]     Train net output #1: loss = 0.354689 (* 1 = 0.354689 loss)
I0628 21:54:01.618031 17220 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0628 21:54:05.240665 17220 solver.cpp:218] Iteration 18700 (27.6049 iter/s, 3.62254s/100 iters), loss = 0.315265
I0628 21:54:05.240665 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:54:05.240665 17220 solver.cpp:237]     Train net output #1: loss = 0.315265 (* 1 = 0.315265 loss)
I0628 21:54:05.240665 17220 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0628 21:54:08.850379 17220 solver.cpp:218] Iteration 18800 (27.7054 iter/s, 3.6094s/100 iters), loss = 0.330609
I0628 21:54:08.850379 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:54:08.850379 17220 solver.cpp:237]     Train net output #1: loss = 0.330609 (* 1 = 0.330609 loss)
I0628 21:54:08.850379 17220 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0628 21:54:12.520005 17220 solver.cpp:218] Iteration 18900 (27.2528 iter/s, 3.66935s/100 iters), loss = 0.301849
I0628 21:54:12.520005 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:54:12.520504 17220 solver.cpp:237]     Train net output #1: loss = 0.301849 (* 1 = 0.301849 loss)
I0628 21:54:12.520504 17220 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0628 21:54:15.991528  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:54:16.137620 17220 solver.cpp:330] Iteration 19000, Testing net (#0)
I0628 21:54:16.137620 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:54:16.978718 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:54:17.010752 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8363
I0628 21:54:17.010752 17220 solver.cpp:397]     Test net output #1: loss = 0.490754 (* 1 = 0.490754 loss)
I0628 21:54:17.046284 17220 solver.cpp:218] Iteration 19000 (22.0964 iter/s, 4.52563s/100 iters), loss = 0.289562
I0628 21:54:17.046284 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:54:17.046284 17220 solver.cpp:237]     Train net output #1: loss = 0.289562 (* 1 = 0.289562 loss)
I0628 21:54:17.046284 17220 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0628 21:54:20.708438 17220 solver.cpp:218] Iteration 19100 (27.3104 iter/s, 3.6616s/100 iters), loss = 0.411768
I0628 21:54:20.708438 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:54:20.708438 17220 solver.cpp:237]     Train net output #1: loss = 0.411768 (* 1 = 0.411768 loss)
I0628 21:54:20.708438 17220 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0628 21:54:24.357573 17220 solver.cpp:218] Iteration 19200 (27.4061 iter/s, 3.64883s/100 iters), loss = 0.318589
I0628 21:54:24.357573 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:54:24.357573 17220 solver.cpp:237]     Train net output #1: loss = 0.318589 (* 1 = 0.318589 loss)
I0628 21:54:24.357573 17220 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0628 21:54:27.986665 17220 solver.cpp:218] Iteration 19300 (27.5584 iter/s, 3.62866s/100 iters), loss = 0.428414
I0628 21:54:27.986665 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 21:54:27.986665 17220 solver.cpp:237]     Train net output #1: loss = 0.428414 (* 1 = 0.428414 loss)
I0628 21:54:27.986665 17220 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0628 21:54:31.611266 17220 solver.cpp:218] Iteration 19400 (27.5918 iter/s, 3.62426s/100 iters), loss = 0.27971
I0628 21:54:31.611266 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:54:31.611266 17220 solver.cpp:237]     Train net output #1: loss = 0.27971 (* 1 = 0.27971 loss)
I0628 21:54:31.611266 17220 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0628 21:54:35.061301  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:54:35.203404 17220 solver.cpp:330] Iteration 19500, Testing net (#0)
I0628 21:54:35.203404 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:54:36.026437 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:54:36.056944 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8275
I0628 21:54:36.056944 17220 solver.cpp:397]     Test net output #1: loss = 0.517643 (* 1 = 0.517643 loss)
I0628 21:54:36.091982 17220 solver.cpp:218] Iteration 19500 (22.3195 iter/s, 4.4804s/100 iters), loss = 0.340193
I0628 21:54:36.091982 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:54:36.091982 17220 solver.cpp:237]     Train net output #1: loss = 0.340193 (* 1 = 0.340193 loss)
I0628 21:54:36.091982 17220 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0628 21:54:39.728610 17220 solver.cpp:218] Iteration 19600 (27.4983 iter/s, 3.63658s/100 iters), loss = 0.389865
I0628 21:54:39.728610 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:54:39.728610 17220 solver.cpp:237]     Train net output #1: loss = 0.389865 (* 1 = 0.389865 loss)
I0628 21:54:39.729122 17220 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0628 21:54:43.359231 17220 solver.cpp:218] Iteration 19700 (27.546 iter/s, 3.63029s/100 iters), loss = 0.251835
I0628 21:54:43.359735 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:54:43.359735 17220 solver.cpp:237]     Train net output #1: loss = 0.251835 (* 1 = 0.251835 loss)
I0628 21:54:43.359735 17220 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0628 21:54:47.081867 17220 solver.cpp:218] Iteration 19800 (26.8689 iter/s, 3.72178s/100 iters), loss = 0.436
I0628 21:54:47.081867 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 21:54:47.081867 17220 solver.cpp:237]     Train net output #1: loss = 0.436 (* 1 = 0.436 loss)
I0628 21:54:47.081867 17220 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0628 21:54:50.873126 17220 solver.cpp:218] Iteration 19900 (26.377 iter/s, 3.79118s/100 iters), loss = 0.229671
I0628 21:54:50.873126 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:54:50.873126 17220 solver.cpp:237]     Train net output #1: loss = 0.229671 (* 1 = 0.229671 loss)
I0628 21:54:50.873126 17220 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0628 21:54:54.328076  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:54:54.470196 17220 solver.cpp:330] Iteration 20000, Testing net (#0)
I0628 21:54:54.470196 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:54:55.291255 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:54:55.322293 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8255
I0628 21:54:55.322293 17220 solver.cpp:397]     Test net output #1: loss = 0.542091 (* 1 = 0.542091 loss)
I0628 21:54:55.357312 17220 solver.cpp:218] Iteration 20000 (22.3041 iter/s, 4.48347s/100 iters), loss = 0.215274
I0628 21:54:55.357312 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:54:55.357312 17220 solver.cpp:237]     Train net output #1: loss = 0.215274 (* 1 = 0.215274 loss)
I0628 21:54:55.357312 17220 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0628 21:54:59.061517 17220 solver.cpp:218] Iteration 20100 (26.996 iter/s, 3.70426s/100 iters), loss = 0.376194
I0628 21:54:59.061517 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:54:59.062016 17220 solver.cpp:237]     Train net output #1: loss = 0.376194 (* 1 = 0.376194 loss)
I0628 21:54:59.062016 17220 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0628 21:55:02.762490 17220 solver.cpp:218] Iteration 20200 (27.0224 iter/s, 3.70063s/100 iters), loss = 0.339589
I0628 21:55:02.762980 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:55:02.762980 17220 solver.cpp:237]     Train net output #1: loss = 0.339589 (* 1 = 0.339589 loss)
I0628 21:55:02.762980 17220 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0628 21:55:06.437094 17220 solver.cpp:218] Iteration 20300 (27.2196 iter/s, 3.67382s/100 iters), loss = 0.373422
I0628 21:55:06.437094 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:55:06.437094 17220 solver.cpp:237]     Train net output #1: loss = 0.373422 (* 1 = 0.373422 loss)
I0628 21:55:06.437094 17220 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0628 21:55:10.144315 17220 solver.cpp:218] Iteration 20400 (26.9756 iter/s, 3.70706s/100 iters), loss = 0.289717
I0628 21:55:10.144315 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:55:10.144315 17220 solver.cpp:237]     Train net output #1: loss = 0.289717 (* 1 = 0.289717 loss)
I0628 21:55:10.144315 17220 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0628 21:55:13.697810  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:55:13.851939 17220 solver.cpp:330] Iteration 20500, Testing net (#0)
I0628 21:55:13.852439 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:55:14.694538 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:55:14.726061 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8407
I0628 21:55:14.726061 17220 solver.cpp:397]     Test net output #1: loss = 0.486963 (* 1 = 0.486963 loss)
I0628 21:55:14.760586 17220 solver.cpp:218] Iteration 20500 (21.6643 iter/s, 4.61588s/100 iters), loss = 0.292672
I0628 21:55:14.760586 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:55:14.760586 17220 solver.cpp:237]     Train net output #1: loss = 0.292672 (* 1 = 0.292672 loss)
I0628 21:55:14.760586 17220 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0628 21:55:18.435700 17220 solver.cpp:218] Iteration 20600 (27.2144 iter/s, 3.67453s/100 iters), loss = 0.275591
I0628 21:55:18.435700 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:55:18.435700 17220 solver.cpp:237]     Train net output #1: loss = 0.275591 (* 1 = 0.275591 loss)
I0628 21:55:18.435700 17220 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0628 21:55:22.144451 17220 solver.cpp:218] Iteration 20700 (26.9647 iter/s, 3.70855s/100 iters), loss = 0.280565
I0628 21:55:22.144451 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:55:22.144951 17220 solver.cpp:237]     Train net output #1: loss = 0.280565 (* 1 = 0.280565 loss)
I0628 21:55:22.144951 17220 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0628 21:55:25.830584 17220 solver.cpp:218] Iteration 20800 (27.1334 iter/s, 3.6855s/100 iters), loss = 0.411936
I0628 21:55:25.830584 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:55:25.830584 17220 solver.cpp:237]     Train net output #1: loss = 0.411936 (* 1 = 0.411936 loss)
I0628 21:55:25.830584 17220 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0628 21:55:29.534708 17220 solver.cpp:218] Iteration 20900 (26.9987 iter/s, 3.70388s/100 iters), loss = 0.233313
I0628 21:55:29.534708 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:55:29.534708 17220 solver.cpp:237]     Train net output #1: loss = 0.233313 (* 1 = 0.233313 loss)
I0628 21:55:29.534708 17220 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0628 21:55:33.080231  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:55:33.225349 17220 solver.cpp:330] Iteration 21000, Testing net (#0)
I0628 21:55:33.225349 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:55:34.060930 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:55:34.092962 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8264
I0628 21:55:34.092962 17220 solver.cpp:397]     Test net output #1: loss = 0.528297 (* 1 = 0.528297 loss)
I0628 21:55:34.127986 17220 solver.cpp:218] Iteration 21000 (21.7725 iter/s, 4.59294s/100 iters), loss = 0.2083
I0628 21:55:34.127986 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:55:34.127986 17220 solver.cpp:237]     Train net output #1: loss = 0.208299 (* 1 = 0.208299 loss)
I0628 21:55:34.127986 17220 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0628 21:55:37.832132 17220 solver.cpp:218] Iteration 21100 (26.9993 iter/s, 3.7038s/100 iters), loss = 0.322915
I0628 21:55:37.832132 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:55:37.832132 17220 solver.cpp:237]     Train net output #1: loss = 0.322915 (* 1 = 0.322915 loss)
I0628 21:55:37.832633 17220 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0628 21:55:41.536383 17220 solver.cpp:218] Iteration 21200 (27.0015 iter/s, 3.70349s/100 iters), loss = 0.371043
I0628 21:55:41.536383 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:55:41.536383 17220 solver.cpp:237]     Train net output #1: loss = 0.371043 (* 1 = 0.371043 loss)
I0628 21:55:41.536383 17220 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0628 21:55:45.192313 17220 solver.cpp:218] Iteration 21300 (27.357 iter/s, 3.65537s/100 iters), loss = 0.338876
I0628 21:55:45.192313 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:55:45.192313 17220 solver.cpp:237]     Train net output #1: loss = 0.338876 (* 1 = 0.338876 loss)
I0628 21:55:45.192313 17220 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0628 21:55:48.842025 17220 solver.cpp:218] Iteration 21400 (27.4022 iter/s, 3.64934s/100 iters), loss = 0.24656
I0628 21:55:48.842025 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:55:48.842025 17220 solver.cpp:237]     Train net output #1: loss = 0.24656 (* 1 = 0.24656 loss)
I0628 21:55:48.842025 17220 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0628 21:55:52.326118  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:55:52.467720 17220 solver.cpp:330] Iteration 21500, Testing net (#0)
I0628 21:55:52.467720 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:55:53.291805 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:55:53.322827 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8169
I0628 21:55:53.322827 17220 solver.cpp:397]     Test net output #1: loss = 0.583543 (* 1 = 0.583543 loss)
I0628 21:55:53.357352 17220 solver.cpp:218] Iteration 21500 (22.1483 iter/s, 4.51503s/100 iters), loss = 0.349506
I0628 21:55:53.357352 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:55:53.357352 17220 solver.cpp:237]     Train net output #1: loss = 0.349506 (* 1 = 0.349506 loss)
I0628 21:55:53.357352 17220 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0628 21:55:56.987934 17220 solver.cpp:218] Iteration 21600 (27.5462 iter/s, 3.63027s/100 iters), loss = 0.287163
I0628 21:55:56.987934 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:55:56.987934 17220 solver.cpp:237]     Train net output #1: loss = 0.287163 (* 1 = 0.287163 loss)
I0628 21:55:56.987934 17220 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0628 21:56:00.614527 17220 solver.cpp:218] Iteration 21700 (27.5751 iter/s, 3.62646s/100 iters), loss = 0.295924
I0628 21:56:00.615028 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:56:00.615028 17220 solver.cpp:237]     Train net output #1: loss = 0.295924 (* 1 = 0.295924 loss)
I0628 21:56:00.615028 17220 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0628 21:56:04.274631 17220 solver.cpp:218] Iteration 21800 (27.3249 iter/s, 3.65967s/100 iters), loss = 0.440493
I0628 21:56:04.274631 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:56:04.274631 17220 solver.cpp:237]     Train net output #1: loss = 0.440493 (* 1 = 0.440493 loss)
I0628 21:56:04.274631 17220 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0628 21:56:07.979809 17220 solver.cpp:218] Iteration 21900 (26.9917 iter/s, 3.70485s/100 iters), loss = 0.239509
I0628 21:56:07.979809 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:56:07.979809 17220 solver.cpp:237]     Train net output #1: loss = 0.239509 (* 1 = 0.239509 loss)
I0628 21:56:07.979809 17220 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0628 21:56:11.568363  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:56:11.713466 17220 solver.cpp:330] Iteration 22000, Testing net (#0)
I0628 21:56:11.713466 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:56:12.549561 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:56:12.581084 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8068
I0628 21:56:12.581084 17220 solver.cpp:397]     Test net output #1: loss = 0.620515 (* 1 = 0.620515 loss)
I0628 21:56:12.615608 17220 solver.cpp:218] Iteration 22000 (21.5735 iter/s, 4.63532s/100 iters), loss = 0.189171
I0628 21:56:12.615608 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:56:12.615608 17220 solver.cpp:237]     Train net output #1: loss = 0.189171 (* 1 = 0.189171 loss)
I0628 21:56:12.615608 17220 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0628 21:56:16.271275 17220 solver.cpp:218] Iteration 22100 (27.3575 iter/s, 3.6553s/100 iters), loss = 0.389141
I0628 21:56:16.271275 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 21:56:16.271275 17220 solver.cpp:237]     Train net output #1: loss = 0.389141 (* 1 = 0.389141 loss)
I0628 21:56:16.271275 17220 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0628 21:56:19.961191 17220 solver.cpp:218] Iteration 22200 (27.1031 iter/s, 3.68962s/100 iters), loss = 0.242196
I0628 21:56:19.961693 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:56:19.961693 17220 solver.cpp:237]     Train net output #1: loss = 0.242196 (* 1 = 0.242196 loss)
I0628 21:56:19.961693 17220 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0628 21:56:23.607786 17220 solver.cpp:218] Iteration 22300 (27.4257 iter/s, 3.64621s/100 iters), loss = 0.355419
I0628 21:56:23.608288 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:56:23.608288 17220 solver.cpp:237]     Train net output #1: loss = 0.355419 (* 1 = 0.355419 loss)
I0628 21:56:23.608288 17220 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0628 21:56:27.255059 17220 solver.cpp:218] Iteration 22400 (27.4218 iter/s, 3.64673s/100 iters), loss = 0.250373
I0628 21:56:27.255059 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:56:27.255059 17220 solver.cpp:237]     Train net output #1: loss = 0.250373 (* 1 = 0.250373 loss)
I0628 21:56:27.255059 17220 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0628 21:56:30.713520  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:56:30.855620 17220 solver.cpp:330] Iteration 22500, Testing net (#0)
I0628 21:56:30.855620 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:56:31.689272 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:56:31.719794 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8012
I0628 21:56:31.719794 17220 solver.cpp:397]     Test net output #1: loss = 0.609242 (* 1 = 0.609242 loss)
I0628 21:56:31.753818 17220 solver.cpp:218] Iteration 22500 (22.2308 iter/s, 4.49826s/100 iters), loss = 0.221962
I0628 21:56:31.753818 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:56:31.753818 17220 solver.cpp:237]     Train net output #1: loss = 0.221962 (* 1 = 0.221962 loss)
I0628 21:56:31.753818 17220 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0628 21:56:35.424449 17220 solver.cpp:218] Iteration 22600 (27.2443 iter/s, 3.67049s/100 iters), loss = 0.408356
I0628 21:56:35.424449 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:56:35.424449 17220 solver.cpp:237]     Train net output #1: loss = 0.408356 (* 1 = 0.408356 loss)
I0628 21:56:35.424950 17220 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0628 21:56:39.074546 17220 solver.cpp:218] Iteration 22700 (27.4007 iter/s, 3.64954s/100 iters), loss = 0.294806
I0628 21:56:39.074546 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:56:39.074546 17220 solver.cpp:237]     Train net output #1: loss = 0.294806 (* 1 = 0.294806 loss)
I0628 21:56:39.074546 17220 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0628 21:56:42.708632 17220 solver.cpp:218] Iteration 22800 (27.5217 iter/s, 3.63349s/100 iters), loss = 0.389717
I0628 21:56:42.708632 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:56:42.708632 17220 solver.cpp:237]     Train net output #1: loss = 0.389717 (* 1 = 0.389717 loss)
I0628 21:56:42.708632 17220 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0628 21:56:46.354727 17220 solver.cpp:218] Iteration 22900 (27.4277 iter/s, 3.64595s/100 iters), loss = 0.267399
I0628 21:56:46.355226 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:56:46.355226 17220 solver.cpp:237]     Train net output #1: loss = 0.267399 (* 1 = 0.267399 loss)
I0628 21:56:46.355226 17220 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0628 21:56:49.878237  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:56:50.019837 17220 solver.cpp:330] Iteration 23000, Testing net (#0)
I0628 21:56:50.019837 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:56:50.852471 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:56:50.883494 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8394
I0628 21:56:50.883494 17220 solver.cpp:397]     Test net output #1: loss = 0.497934 (* 1 = 0.497934 loss)
I0628 21:56:50.918519 17220 solver.cpp:218] Iteration 23000 (21.9145 iter/s, 4.56319s/100 iters), loss = 0.281545
I0628 21:56:50.918519 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:56:50.918519 17220 solver.cpp:237]     Train net output #1: loss = 0.281545 (* 1 = 0.281545 loss)
I0628 21:56:50.918519 17220 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0628 21:56:54.562682 17220 solver.cpp:218] Iteration 23100 (27.4452 iter/s, 3.64362s/100 iters), loss = 0.322719
I0628 21:56:54.562682 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:56:54.562682 17220 solver.cpp:237]     Train net output #1: loss = 0.322719 (* 1 = 0.322719 loss)
I0628 21:56:54.562682 17220 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0628 21:56:58.228791 17220 solver.cpp:218] Iteration 23200 (27.2775 iter/s, 3.66602s/100 iters), loss = 0.399048
I0628 21:56:58.229292 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:56:58.229292 17220 solver.cpp:237]     Train net output #1: loss = 0.399048 (* 1 = 0.399048 loss)
I0628 21:56:58.229292 17220 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0628 21:57:01.934949 17220 solver.cpp:218] Iteration 23300 (26.9864 iter/s, 3.70557s/100 iters), loss = 0.397314
I0628 21:57:01.934949 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 21:57:01.934949 17220 solver.cpp:237]     Train net output #1: loss = 0.397314 (* 1 = 0.397314 loss)
I0628 21:57:01.934949 17220 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0628 21:57:05.682113 17220 solver.cpp:218] Iteration 23400 (26.691 iter/s, 3.74658s/100 iters), loss = 0.310551
I0628 21:57:05.682113 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:57:05.682113 17220 solver.cpp:237]     Train net output #1: loss = 0.310551 (* 1 = 0.310551 loss)
I0628 21:57:05.682113 17220 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0628 21:57:09.144603  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:57:09.286203 17220 solver.cpp:330] Iteration 23500, Testing net (#0)
I0628 21:57:09.286203 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:57:10.112829 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:57:10.144353 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8291
I0628 21:57:10.144353 17220 solver.cpp:397]     Test net output #1: loss = 0.516998 (* 1 = 0.516998 loss)
I0628 21:57:10.181879 17220 solver.cpp:218] Iteration 23500 (22.2254 iter/s, 4.49936s/100 iters), loss = 0.337664
I0628 21:57:10.181879 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:57:10.181879 17220 solver.cpp:237]     Train net output #1: loss = 0.337664 (* 1 = 0.337664 loss)
I0628 21:57:10.181879 17220 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0628 21:57:13.843484 17220 solver.cpp:218] Iteration 23600 (27.3131 iter/s, 3.66125s/100 iters), loss = 0.365348
I0628 21:57:13.843484 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:57:13.866407 17220 solver.cpp:237]     Train net output #1: loss = 0.365348 (* 1 = 0.365348 loss)
I0628 21:57:13.866407 17220 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0628 21:57:17.532938 17220 solver.cpp:218] Iteration 23700 (27.2766 iter/s, 3.66615s/100 iters), loss = 0.322484
I0628 21:57:17.532938 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:57:17.532938 17220 solver.cpp:237]     Train net output #1: loss = 0.322483 (* 1 = 0.322483 loss)
I0628 21:57:17.532938 17220 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0628 21:57:21.175146 17220 solver.cpp:218] Iteration 23800 (27.4574 iter/s, 3.64201s/100 iters), loss = 0.422534
I0628 21:57:21.175146 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 21:57:21.175146 17220 solver.cpp:237]     Train net output #1: loss = 0.422534 (* 1 = 0.422534 loss)
I0628 21:57:21.175647 17220 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0628 21:57:24.797250 17220 solver.cpp:218] Iteration 23900 (27.612 iter/s, 3.62161s/100 iters), loss = 0.215833
I0628 21:57:24.797250 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:57:24.797250 17220 solver.cpp:237]     Train net output #1: loss = 0.215833 (* 1 = 0.215833 loss)
I0628 21:57:24.797250 17220 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0628 21:57:28.234868  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:57:28.377470 17220 solver.cpp:330] Iteration 24000, Testing net (#0)
I0628 21:57:28.377470 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:57:29.199054 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:57:29.230077 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8432
I0628 21:57:29.230077 17220 solver.cpp:397]     Test net output #1: loss = 0.484046 (* 1 = 0.484046 loss)
I0628 21:57:29.264600 17220 solver.cpp:218] Iteration 24000 (22.3879 iter/s, 4.46669s/100 iters), loss = 0.342996
I0628 21:57:29.264600 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:57:29.264600 17220 solver.cpp:237]     Train net output #1: loss = 0.342996 (* 1 = 0.342996 loss)
I0628 21:57:29.264600 17220 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0628 21:57:32.890738 17220 solver.cpp:218] Iteration 24100 (27.5791 iter/s, 3.62593s/100 iters), loss = 0.341347
I0628 21:57:32.890738 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:57:32.890738 17220 solver.cpp:237]     Train net output #1: loss = 0.341347 (* 1 = 0.341347 loss)
I0628 21:57:32.890738 17220 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0628 21:57:36.530930 17220 solver.cpp:218] Iteration 24200 (27.4718 iter/s, 3.64009s/100 iters), loss = 0.276104
I0628 21:57:36.531431 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:57:36.531431 17220 solver.cpp:237]     Train net output #1: loss = 0.276104 (* 1 = 0.276104 loss)
I0628 21:57:36.531431 17220 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0628 21:57:40.175530 17220 solver.cpp:218] Iteration 24300 (27.4432 iter/s, 3.64389s/100 iters), loss = 0.493762
I0628 21:57:40.175530 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:57:40.175530 17220 solver.cpp:237]     Train net output #1: loss = 0.493761 (* 1 = 0.493761 loss)
I0628 21:57:40.175530 17220 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0628 21:57:43.842530 17220 solver.cpp:218] Iteration 24400 (27.2726 iter/s, 3.66668s/100 iters), loss = 0.268532
I0628 21:57:43.842530 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:57:43.842530 17220 solver.cpp:237]     Train net output #1: loss = 0.268532 (* 1 = 0.268532 loss)
I0628 21:57:43.842530 17220 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0628 21:57:47.313016  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:57:47.457620 17220 solver.cpp:330] Iteration 24500, Testing net (#0)
I0628 21:57:47.457620 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:57:48.281708 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:57:48.312227 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8154
I0628 21:57:48.312227 17220 solver.cpp:397]     Test net output #1: loss = 0.569132 (* 1 = 0.569132 loss)
I0628 21:57:48.346750 17220 solver.cpp:218] Iteration 24500 (22.2033 iter/s, 4.50384s/100 iters), loss = 0.25513
I0628 21:57:48.346750 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:57:48.346750 17220 solver.cpp:237]     Train net output #1: loss = 0.25513 (* 1 = 0.25513 loss)
I0628 21:57:48.346750 17220 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0628 21:57:52.011854 17220 solver.cpp:218] Iteration 24600 (27.2878 iter/s, 3.66463s/100 iters), loss = 0.331346
I0628 21:57:52.011854 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:57:52.011854 17220 solver.cpp:237]     Train net output #1: loss = 0.331346 (* 1 = 0.331346 loss)
I0628 21:57:52.011854 17220 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0628 21:57:55.663010 17220 solver.cpp:218] Iteration 24700 (27.3912 iter/s, 3.65081s/100 iters), loss = 0.430624
I0628 21:57:55.663010 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 21:57:55.663010 17220 solver.cpp:237]     Train net output #1: loss = 0.430624 (* 1 = 0.430624 loss)
I0628 21:57:55.663010 17220 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0628 21:57:59.315603 17220 solver.cpp:218] Iteration 24800 (27.3779 iter/s, 3.65258s/100 iters), loss = 0.432065
I0628 21:57:59.315603 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:57:59.315603 17220 solver.cpp:237]     Train net output #1: loss = 0.432065 (* 1 = 0.432065 loss)
I0628 21:57:59.315603 17220 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0628 21:58:02.964198 17220 solver.cpp:218] Iteration 24900 (27.4132 iter/s, 3.64788s/100 iters), loss = 0.271042
I0628 21:58:02.964198 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:58:02.964198 17220 solver.cpp:237]     Train net output #1: loss = 0.271042 (* 1 = 0.271042 loss)
I0628 21:58:02.964198 17220 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0628 21:58:06.454886  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:58:06.598989 17220 solver.cpp:330] Iteration 25000, Testing net (#0)
I0628 21:58:06.598989 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:58:07.430408 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:58:07.461429 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8381
I0628 21:58:07.461429 17220 solver.cpp:397]     Test net output #1: loss = 0.499896 (* 1 = 0.499896 loss)
I0628 21:58:07.495954 17220 solver.cpp:218] Iteration 25000 (22.0667 iter/s, 4.53172s/100 iters), loss = 0.341551
I0628 21:58:07.495954 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:58:07.495954 17220 solver.cpp:237]     Train net output #1: loss = 0.341551 (* 1 = 0.341551 loss)
I0628 21:58:07.495954 17220 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0628 21:58:11.168567 17220 solver.cpp:218] Iteration 25100 (27.2339 iter/s, 3.6719s/100 iters), loss = 0.270068
I0628 21:58:11.168567 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:58:11.168567 17220 solver.cpp:237]     Train net output #1: loss = 0.270068 (* 1 = 0.270068 loss)
I0628 21:58:11.168567 17220 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0628 21:58:14.825670 17220 solver.cpp:218] Iteration 25200 (27.3444 iter/s, 3.65705s/100 iters), loss = 0.373025
I0628 21:58:14.825670 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:58:14.825670 17220 solver.cpp:237]     Train net output #1: loss = 0.373025 (* 1 = 0.373025 loss)
I0628 21:58:14.825670 17220 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0628 21:58:18.463258 17220 solver.cpp:218] Iteration 25300 (27.4956 iter/s, 3.63694s/100 iters), loss = 0.370921
I0628 21:58:18.463258 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:58:18.463258 17220 solver.cpp:237]     Train net output #1: loss = 0.370921 (* 1 = 0.370921 loss)
I0628 21:58:18.463258 17220 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0628 21:58:22.115419 17220 solver.cpp:218] Iteration 25400 (27.3823 iter/s, 3.65199s/100 iters), loss = 0.222772
I0628 21:58:22.115419 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:58:22.115419 17220 solver.cpp:237]     Train net output #1: loss = 0.222772 (* 1 = 0.222772 loss)
I0628 21:58:22.115419 17220 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0628 21:58:25.591392  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:58:25.736496 17220 solver.cpp:330] Iteration 25500, Testing net (#0)
I0628 21:58:25.736496 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:58:26.565085 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:58:26.596107 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8402
I0628 21:58:26.596107 17220 solver.cpp:397]     Test net output #1: loss = 0.499184 (* 1 = 0.499184 loss)
I0628 21:58:26.630632 17220 solver.cpp:218] Iteration 25500 (22.1502 iter/s, 4.51463s/100 iters), loss = 0.348813
I0628 21:58:26.630632 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:58:26.630632 17220 solver.cpp:237]     Train net output #1: loss = 0.348813 (* 1 = 0.348813 loss)
I0628 21:58:26.630632 17220 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0628 21:58:30.260699 17220 solver.cpp:218] Iteration 25600 (27.5472 iter/s, 3.63013s/100 iters), loss = 0.283271
I0628 21:58:30.260699 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:58:30.260699 17220 solver.cpp:237]     Train net output #1: loss = 0.283271 (* 1 = 0.283271 loss)
I0628 21:58:30.260699 17220 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0628 21:58:33.920091 17220 solver.cpp:218] Iteration 25700 (27.3328 iter/s, 3.6586s/100 iters), loss = 0.304594
I0628 21:58:33.920091 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:58:33.920091 17220 solver.cpp:237]     Train net output #1: loss = 0.304594 (* 1 = 0.304594 loss)
I0628 21:58:33.920091 17220 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0628 21:58:37.571259 17220 solver.cpp:218] Iteration 25800 (27.3899 iter/s, 3.65098s/100 iters), loss = 0.342835
I0628 21:58:37.571259 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:58:37.571259 17220 solver.cpp:237]     Train net output #1: loss = 0.342835 (* 1 = 0.342835 loss)
I0628 21:58:37.571259 17220 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0628 21:58:41.189833 17220 solver.cpp:218] Iteration 25900 (27.6369 iter/s, 3.61836s/100 iters), loss = 0.270315
I0628 21:58:41.189833 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:58:41.189833 17220 solver.cpp:237]     Train net output #1: loss = 0.270315 (* 1 = 0.270315 loss)
I0628 21:58:41.189833 17220 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0628 21:58:44.626083  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:58:44.765683 17220 solver.cpp:330] Iteration 26000, Testing net (#0)
I0628 21:58:44.765683 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:58:45.586266 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:58:45.617290 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8279
I0628 21:58:45.617290 17220 solver.cpp:397]     Test net output #1: loss = 0.519265 (* 1 = 0.519265 loss)
I0628 21:58:45.652814 17220 solver.cpp:218] Iteration 26000 (22.4097 iter/s, 4.46235s/100 iters), loss = 0.286901
I0628 21:58:45.652814 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:58:45.652814 17220 solver.cpp:237]     Train net output #1: loss = 0.286901 (* 1 = 0.286901 loss)
I0628 21:58:45.652814 17220 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0628 21:58:49.302001 17220 solver.cpp:218] Iteration 26100 (27.4049 iter/s, 3.64898s/100 iters), loss = 0.332966
I0628 21:58:49.302001 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:58:49.302001 17220 solver.cpp:237]     Train net output #1: loss = 0.332966 (* 1 = 0.332966 loss)
I0628 21:58:49.302001 17220 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0628 21:58:52.937671 17220 solver.cpp:218] Iteration 26200 (27.5097 iter/s, 3.63508s/100 iters), loss = 0.348538
I0628 21:58:52.937671 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:58:52.937671 17220 solver.cpp:237]     Train net output #1: loss = 0.348538 (* 1 = 0.348538 loss)
I0628 21:58:52.937671 17220 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0628 21:58:56.574859 17220 solver.cpp:218] Iteration 26300 (27.4937 iter/s, 3.63719s/100 iters), loss = 0.361602
I0628 21:58:56.574859 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 21:58:56.575359 17220 solver.cpp:237]     Train net output #1: loss = 0.361602 (* 1 = 0.361602 loss)
I0628 21:58:56.575359 17220 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0628 21:59:00.246937 17220 solver.cpp:218] Iteration 26400 (27.2379 iter/s, 3.67136s/100 iters), loss = 0.257184
I0628 21:59:00.246937 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:59:00.246937 17220 solver.cpp:237]     Train net output #1: loss = 0.257184 (* 1 = 0.257184 loss)
I0628 21:59:00.246937 17220 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0628 21:59:03.695458  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:59:03.837059 17220 solver.cpp:330] Iteration 26500, Testing net (#0)
I0628 21:59:03.837059 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:59:04.666414 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:59:04.697437 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8183
I0628 21:59:04.697437 17220 solver.cpp:397]     Test net output #1: loss = 0.594772 (* 1 = 0.594772 loss)
I0628 21:59:04.731459 17220 solver.cpp:218] Iteration 26500 (22.3003 iter/s, 4.48425s/100 iters), loss = 0.258538
I0628 21:59:04.731459 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 21:59:04.731459 17220 solver.cpp:237]     Train net output #1: loss = 0.258538 (* 1 = 0.258538 loss)
I0628 21:59:04.731459 17220 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0628 21:59:08.389564 17220 solver.cpp:218] Iteration 26600 (27.3382 iter/s, 3.65788s/100 iters), loss = 0.263555
I0628 21:59:08.389564 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:59:08.389564 17220 solver.cpp:237]     Train net output #1: loss = 0.263555 (* 1 = 0.263555 loss)
I0628 21:59:08.390064 17220 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0628 21:59:12.092197 17220 solver.cpp:218] Iteration 26700 (27.0101 iter/s, 3.70231s/100 iters), loss = 0.254921
I0628 21:59:12.092197 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:59:12.092699 17220 solver.cpp:237]     Train net output #1: loss = 0.254921 (* 1 = 0.254921 loss)
I0628 21:59:12.092699 17220 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0628 21:59:15.752810 17220 solver.cpp:218] Iteration 26800 (27.3238 iter/s, 3.65982s/100 iters), loss = 0.384212
I0628 21:59:15.752810 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:59:15.752810 17220 solver.cpp:237]     Train net output #1: loss = 0.384212 (* 1 = 0.384212 loss)
I0628 21:59:15.752810 17220 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0628 21:59:19.388406 17220 solver.cpp:218] Iteration 26900 (27.506 iter/s, 3.63557s/100 iters), loss = 0.176331
I0628 21:59:19.388406 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:59:19.388406 17220 solver.cpp:237]     Train net output #1: loss = 0.176331 (* 1 = 0.176331 loss)
I0628 21:59:19.388406 17220 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0628 21:59:22.855916  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:59:22.996516 17220 solver.cpp:330] Iteration 27000, Testing net (#0)
I0628 21:59:22.996516 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:59:23.821102 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:59:23.851624 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8515
I0628 21:59:23.851624 17220 solver.cpp:397]     Test net output #1: loss = 0.460561 (* 1 = 0.460561 loss)
I0628 21:59:23.886149 17220 solver.cpp:218] Iteration 27000 (22.2356 iter/s, 4.4973s/100 iters), loss = 0.312883
I0628 21:59:23.886149 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:59:23.886149 17220 solver.cpp:237]     Train net output #1: loss = 0.312883 (* 1 = 0.312883 loss)
I0628 21:59:23.886149 17220 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0628 21:59:27.512327 17220 solver.cpp:218] Iteration 27100 (27.579 iter/s, 3.62594s/100 iters), loss = 0.403097
I0628 21:59:27.512327 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 21:59:27.512327 17220 solver.cpp:237]     Train net output #1: loss = 0.403097 (* 1 = 0.403097 loss)
I0628 21:59:27.512327 17220 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0628 21:59:31.152417 17220 solver.cpp:218] Iteration 27200 (27.4754 iter/s, 3.63961s/100 iters), loss = 0.271281
I0628 21:59:31.152417 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:59:31.152417 17220 solver.cpp:237]     Train net output #1: loss = 0.271281 (* 1 = 0.271281 loss)
I0628 21:59:31.152417 17220 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0628 21:59:34.859635 17220 solver.cpp:218] Iteration 27300 (26.9774 iter/s, 3.70681s/100 iters), loss = 0.346714
I0628 21:59:34.859635 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 21:59:34.859635 17220 solver.cpp:237]     Train net output #1: loss = 0.346714 (* 1 = 0.346714 loss)
I0628 21:59:34.859635 17220 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0628 21:59:38.503844 17220 solver.cpp:218] Iteration 27400 (27.4425 iter/s, 3.64398s/100 iters), loss = 0.243763
I0628 21:59:38.504345 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:59:38.504345 17220 solver.cpp:237]     Train net output #1: loss = 0.243763 (* 1 = 0.243763 loss)
I0628 21:59:38.504345 17220 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0628 21:59:41.975314  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:59:42.119928 17220 solver.cpp:330] Iteration 27500, Testing net (#0)
I0628 21:59:42.119928 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:59:42.953011 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:59:42.984041 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8249
I0628 21:59:42.984041 17220 solver.cpp:397]     Test net output #1: loss = 0.535796 (* 1 = 0.535796 loss)
I0628 21:59:43.018065 17220 solver.cpp:218] Iteration 27500 (22.1545 iter/s, 4.51375s/100 iters), loss = 0.289598
I0628 21:59:43.018065 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:59:43.018065 17220 solver.cpp:237]     Train net output #1: loss = 0.289598 (* 1 = 0.289598 loss)
I0628 21:59:43.018065 17220 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0628 21:59:46.653753 17220 solver.cpp:218] Iteration 27600 (27.5085 iter/s, 3.63524s/100 iters), loss = 0.318124
I0628 21:59:46.653753 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:59:46.653753 17220 solver.cpp:237]     Train net output #1: loss = 0.318124 (* 1 = 0.318124 loss)
I0628 21:59:46.653753 17220 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0628 21:59:50.290328 17220 solver.cpp:218] Iteration 27700 (27.4995 iter/s, 3.63643s/100 iters), loss = 0.297607
I0628 21:59:50.290828 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:59:50.290828 17220 solver.cpp:237]     Train net output #1: loss = 0.297607 (* 1 = 0.297607 loss)
I0628 21:59:50.290828 17220 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0628 21:59:53.922425 17220 solver.cpp:218] Iteration 27800 (27.5363 iter/s, 3.63157s/100 iters), loss = 0.332584
I0628 21:59:53.922425 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:59:53.922425 17220 solver.cpp:237]     Train net output #1: loss = 0.332584 (* 1 = 0.332584 loss)
I0628 21:59:53.922425 17220 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0628 21:59:57.578095 17220 solver.cpp:218] Iteration 27900 (27.3594 iter/s, 3.65505s/100 iters), loss = 0.190421
I0628 21:59:57.578095 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:59:57.578095 17220 solver.cpp:237]     Train net output #1: loss = 0.190421 (* 1 = 0.190421 loss)
I0628 21:59:57.578095 17220 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0628 22:00:01.046077  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:00:01.191180 17220 solver.cpp:330] Iteration 28000, Testing net (#0)
I0628 22:00:01.191180 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:00:02.024289 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:00:02.055809 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8365
I0628 22:00:02.055809 17220 solver.cpp:397]     Test net output #1: loss = 0.504778 (* 1 = 0.504778 loss)
I0628 22:00:02.090345 17220 solver.cpp:218] Iteration 28000 (22.1638 iter/s, 4.51187s/100 iters), loss = 0.242981
I0628 22:00:02.090345 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 22:00:02.090345 17220 solver.cpp:237]     Train net output #1: loss = 0.242982 (* 1 = 0.242982 loss)
I0628 22:00:02.090345 17220 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0628 22:00:05.707005 17220 solver.cpp:218] Iteration 28100 (27.6509 iter/s, 3.61652s/100 iters), loss = 0.289818
I0628 22:00:05.707005 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:00:05.707005 17220 solver.cpp:237]     Train net output #1: loss = 0.289818 (* 1 = 0.289818 loss)
I0628 22:00:05.707005 17220 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0628 22:00:09.332145 17220 solver.cpp:218] Iteration 28200 (27.587 iter/s, 3.6249s/100 iters), loss = 0.289783
I0628 22:00:09.332145 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 22:00:09.332145 17220 solver.cpp:237]     Train net output #1: loss = 0.289783 (* 1 = 0.289783 loss)
I0628 22:00:09.332145 17220 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0628 22:00:12.944576 17220 solver.cpp:218] Iteration 28300 (27.6869 iter/s, 3.61182s/100 iters), loss = 0.299751
I0628 22:00:12.944576 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:00:12.944576 17220 solver.cpp:237]     Train net output #1: loss = 0.299751 (* 1 = 0.299751 loss)
I0628 22:00:12.944576 17220 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0628 22:00:16.552251 17220 solver.cpp:218] Iteration 28400 (27.7219 iter/s, 3.60726s/100 iters), loss = 0.275896
I0628 22:00:16.552251 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:00:16.552251 17220 solver.cpp:237]     Train net output #1: loss = 0.275896 (* 1 = 0.275896 loss)
I0628 22:00:16.552251 17220 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0628 22:00:19.982136  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:00:20.123736 17220 solver.cpp:330] Iteration 28500, Testing net (#0)
I0628 22:00:20.123736 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:00:20.946321 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:00:20.977344 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8323
I0628 22:00:20.977344 17220 solver.cpp:397]     Test net output #1: loss = 0.520696 (* 1 = 0.520696 loss)
I0628 22:00:21.011368 17220 solver.cpp:218] Iteration 28500 (22.428 iter/s, 4.45871s/100 iters), loss = 0.294957
I0628 22:00:21.011368 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 22:00:21.011368 17220 solver.cpp:237]     Train net output #1: loss = 0.294957 (* 1 = 0.294957 loss)
I0628 22:00:21.011368 17220 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0628 22:00:24.666505 17220 solver.cpp:218] Iteration 28600 (27.3605 iter/s, 3.65491s/100 iters), loss = 0.299362
I0628 22:00:24.666505 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:00:24.666505 17220 solver.cpp:237]     Train net output #1: loss = 0.299362 (* 1 = 0.299362 loss)
I0628 22:00:24.666505 17220 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0628 22:00:28.318104 17220 solver.cpp:218] Iteration 28700 (27.3877 iter/s, 3.65127s/100 iters), loss = 0.362191
I0628 22:00:28.318104 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 22:00:28.318104 17220 solver.cpp:237]     Train net output #1: loss = 0.362191 (* 1 = 0.362191 loss)
I0628 22:00:28.318104 17220 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I0628 22:00:31.972203 17220 solver.cpp:218] Iteration 28800 (27.3667 iter/s, 3.65408s/100 iters), loss = 0.321341
I0628 22:00:31.972703 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 22:00:31.972703 17220 solver.cpp:237]     Train net output #1: loss = 0.321342 (* 1 = 0.321342 loss)
I0628 22:00:31.972703 17220 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I0628 22:00:35.622800 17220 solver.cpp:218] Iteration 28900 (27.3988 iter/s, 3.6498s/100 iters), loss = 0.235561
I0628 22:00:35.622800 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:00:35.622800 17220 solver.cpp:237]     Train net output #1: loss = 0.235561 (* 1 = 0.235561 loss)
I0628 22:00:35.622800 17220 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I0628 22:00:39.080899  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:00:39.221498 17220 solver.cpp:330] Iteration 29000, Testing net (#0)
I0628 22:00:39.221498 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:00:40.046084 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:00:40.077106 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8524
I0628 22:00:40.077106 17220 solver.cpp:397]     Test net output #1: loss = 0.457934 (* 1 = 0.457934 loss)
I0628 22:00:40.111644 17220 solver.cpp:218] Iteration 29000 (22.279 iter/s, 4.48854s/100 iters), loss = 0.257137
I0628 22:00:40.111644 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:00:40.111644 17220 solver.cpp:237]     Train net output #1: loss = 0.257137 (* 1 = 0.257137 loss)
I0628 22:00:40.111644 17220 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I0628 22:00:43.728955 17220 solver.cpp:218] Iteration 29100 (27.6482 iter/s, 3.61687s/100 iters), loss = 0.310975
I0628 22:00:43.728955 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 22:00:43.728955 17220 solver.cpp:237]     Train net output #1: loss = 0.310975 (* 1 = 0.310975 loss)
I0628 22:00:43.728955 17220 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I0628 22:00:47.359617 17220 solver.cpp:218] Iteration 29200 (27.5444 iter/s, 3.6305s/100 iters), loss = 0.238275
I0628 22:00:47.359617 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:00:47.359617 17220 solver.cpp:237]     Train net output #1: loss = 0.238275 (* 1 = 0.238275 loss)
I0628 22:00:47.359617 17220 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I0628 22:00:51.003286 17220 solver.cpp:218] Iteration 29300 (27.4458 iter/s, 3.64355s/100 iters), loss = 0.326199
I0628 22:00:51.003787 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 22:00:51.003787 17220 solver.cpp:237]     Train net output #1: loss = 0.326199 (* 1 = 0.326199 loss)
I0628 22:00:51.003787 17220 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I0628 22:00:54.631422 17220 solver.cpp:218] Iteration 29400 (27.5665 iter/s, 3.62759s/100 iters), loss = 0.15113
I0628 22:00:54.631422 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:00:54.631422 17220 solver.cpp:237]     Train net output #1: loss = 0.15113 (* 1 = 0.15113 loss)
I0628 22:00:54.631422 17220 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I0628 22:00:58.061058  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:00:58.203161 17220 solver.cpp:330] Iteration 29500, Testing net (#0)
I0628 22:00:58.203161 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:00:59.017966 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:00:59.047991 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8347
I0628 22:00:59.048991 17220 solver.cpp:397]     Test net output #1: loss = 0.532888 (* 1 = 0.532888 loss)
I0628 22:00:59.086017 17220 solver.cpp:218] Iteration 29500 (22.4482 iter/s, 4.4547s/100 iters), loss = 0.370041
I0628 22:00:59.086017 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 22:00:59.086017 17220 solver.cpp:237]     Train net output #1: loss = 0.370041 (* 1 = 0.370041 loss)
I0628 22:00:59.086017 17220 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I0628 22:01:02.737694 17220 solver.cpp:218] Iteration 29600 (27.4109 iter/s, 3.64818s/100 iters), loss = 0.376055
I0628 22:01:02.738194 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 22:01:02.738194 17220 solver.cpp:237]     Train net output #1: loss = 0.376055 (* 1 = 0.376055 loss)
I0628 22:01:02.738194 17220 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I0628 22:01:06.358681 17220 solver.cpp:218] Iteration 29700 (27.6195 iter/s, 3.62063s/100 iters), loss = 0.383992
I0628 22:01:06.358681 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 22:01:06.358681 17220 solver.cpp:237]     Train net output #1: loss = 0.383992 (* 1 = 0.383992 loss)
I0628 22:01:06.359181 17220 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I0628 22:01:09.981760 17220 solver.cpp:218] Iteration 29800 (27.6041 iter/s, 3.62266s/100 iters), loss = 0.292652
I0628 22:01:09.981760 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:01:09.981760 17220 solver.cpp:237]     Train net output #1: loss = 0.292652 (* 1 = 0.292652 loss)
I0628 22:01:09.981760 17220 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I0628 22:01:13.606838 17220 solver.cpp:218] Iteration 29900 (27.5891 iter/s, 3.62462s/100 iters), loss = 0.235442
I0628 22:01:13.606838 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:01:13.606838 17220 solver.cpp:237]     Train net output #1: loss = 0.235442 (* 1 = 0.235442 loss)
I0628 22:01:13.606838 17220 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I0628 22:01:17.091817  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:01:17.236922 17220 solver.cpp:330] Iteration 30000, Testing net (#0)
I0628 22:01:17.237421 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:01:18.064509 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:01:18.095532 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8457
I0628 22:01:18.095532 17220 solver.cpp:397]     Test net output #1: loss = 0.48492 (* 1 = 0.48492 loss)
I0628 22:01:18.130056 17220 solver.cpp:218] Iteration 30000 (22.1105 iter/s, 4.52274s/100 iters), loss = 0.286187
I0628 22:01:18.130056 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 22:01:18.130056 17220 solver.cpp:237]     Train net output #1: loss = 0.286187 (* 1 = 0.286187 loss)
I0628 22:01:18.130056 17220 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I0628 22:01:21.767143 17220 solver.cpp:218] Iteration 30100 (27.4953 iter/s, 3.63699s/100 iters), loss = 0.349493
I0628 22:01:21.767143 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:01:21.767143 17220 solver.cpp:237]     Train net output #1: loss = 0.349493 (* 1 = 0.349493 loss)
I0628 22:01:21.767143 17220 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I0628 22:01:25.392724 17220 solver.cpp:218] Iteration 30200 (27.5864 iter/s, 3.62498s/100 iters), loss = 0.407925
I0628 22:01:25.392724 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 22:01:25.392724 17220 solver.cpp:237]     Train net output #1: loss = 0.407925 (* 1 = 0.407925 loss)
I0628 22:01:25.392724 17220 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I0628 22:01:29.032130 17220 solver.cpp:218] Iteration 30300 (27.4781 iter/s, 3.63926s/100 iters), loss = 0.230454
I0628 22:01:29.032130 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:01:29.032130 17220 solver.cpp:237]     Train net output #1: loss = 0.230455 (* 1 = 0.230455 loss)
I0628 22:01:29.032130 17220 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I0628 22:01:32.650372 17220 solver.cpp:218] Iteration 30400 (27.6421 iter/s, 3.61767s/100 iters), loss = 0.273578
I0628 22:01:32.650372 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:01:32.650372 17220 solver.cpp:237]     Train net output #1: loss = 0.273578 (* 1 = 0.273578 loss)
I0628 22:01:32.650372 17220 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I0628 22:01:36.109308  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:01:36.250907 17220 solver.cpp:330] Iteration 30500, Testing net (#0)
I0628 22:01:36.250907 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:01:37.072993 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:01:37.104015 17220 solver.cpp:397]     Test net output #0: accuracy = 0.844
I0628 22:01:37.104015 17220 solver.cpp:397]     Test net output #1: loss = 0.487043 (* 1 = 0.487043 loss)
I0628 22:01:37.138038 17220 solver.cpp:218] Iteration 30500 (22.2834 iter/s, 4.48764s/100 iters), loss = 0.355332
I0628 22:01:37.138038 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 22:01:37.138038 17220 solver.cpp:237]     Train net output #1: loss = 0.355332 (* 1 = 0.355332 loss)
I0628 22:01:37.138540 17220 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I0628 22:01:40.763118 17220 solver.cpp:218] Iteration 30600 (27.5899 iter/s, 3.62452s/100 iters), loss = 0.350985
I0628 22:01:40.763118 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 22:01:40.763118 17220 solver.cpp:237]     Train net output #1: loss = 0.350985 (* 1 = 0.350985 loss)
I0628 22:01:40.763118 17220 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I0628 22:01:44.401724 17220 solver.cpp:218] Iteration 30700 (27.4863 iter/s, 3.63818s/100 iters), loss = 0.253755
I0628 22:01:44.401724 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:01:44.401724 17220 solver.cpp:237]     Train net output #1: loss = 0.253755 (* 1 = 0.253755 loss)
I0628 22:01:44.401724 17220 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I0628 22:01:48.026831 17220 solver.cpp:218] Iteration 30800 (27.5875 iter/s, 3.62484s/100 iters), loss = 0.270741
I0628 22:01:48.026831 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:01:48.026831 17220 solver.cpp:237]     Train net output #1: loss = 0.270741 (* 1 = 0.270741 loss)
I0628 22:01:48.026831 17220 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I0628 22:01:51.678737 17220 solver.cpp:218] Iteration 30900 (27.385 iter/s, 3.65164s/100 iters), loss = 0.257032
I0628 22:01:51.678737 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:01:51.678737 17220 solver.cpp:237]     Train net output #1: loss = 0.257032 (* 1 = 0.257032 loss)
I0628 22:01:51.678737 17220 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I0628 22:01:55.148205  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:01:55.289808 17220 solver.cpp:330] Iteration 31000, Testing net (#0)
I0628 22:01:55.290307 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:01:56.114893 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:01:56.145925 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8272
I0628 22:01:56.145925 17220 solver.cpp:397]     Test net output #1: loss = 0.546511 (* 1 = 0.546511 loss)
I0628 22:01:56.180452 17220 solver.cpp:218] Iteration 31000 (22.2155 iter/s, 4.50137s/100 iters), loss = 0.205699
I0628 22:01:56.180956 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 22:01:56.180956 17220 solver.cpp:237]     Train net output #1: loss = 0.205699 (* 1 = 0.205699 loss)
I0628 22:01:56.180956 17220 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I0628 22:01:59.819840 17220 solver.cpp:218] Iteration 31100 (27.4827 iter/s, 3.63866s/100 iters), loss = 0.294764
I0628 22:01:59.819840 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:01:59.819840 17220 solver.cpp:237]     Train net output #1: loss = 0.294764 (* 1 = 0.294764 loss)
I0628 22:01:59.819840 17220 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I0628 22:02:03.462432 17220 solver.cpp:218] Iteration 31200 (27.4573 iter/s, 3.64202s/100 iters), loss = 0.28223
I0628 22:02:03.462432 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 22:02:03.462432 17220 solver.cpp:237]     Train net output #1: loss = 0.28223 (* 1 = 0.28223 loss)
I0628 22:02:03.462432 17220 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I0628 22:02:07.087959 17220 solver.cpp:218] Iteration 31300 (27.5836 iter/s, 3.62534s/100 iters), loss = 0.326241
I0628 22:02:07.087959 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:02:07.087959 17220 solver.cpp:237]     Train net output #1: loss = 0.326241 (* 1 = 0.326241 loss)
I0628 22:02:07.087959 17220 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I0628 22:02:10.717129 17220 solver.cpp:218] Iteration 31400 (27.556 iter/s, 3.62897s/100 iters), loss = 0.149552
I0628 22:02:10.717129 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:02:10.717129 17220 solver.cpp:237]     Train net output #1: loss = 0.149552 (* 1 = 0.149552 loss)
I0628 22:02:10.717129 17220 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I0628 22:02:14.188285  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:02:14.329386 17220 solver.cpp:330] Iteration 31500, Testing net (#0)
I0628 22:02:14.329386 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:02:15.154090 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:02:15.184612 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8359
I0628 22:02:15.184612 17220 solver.cpp:397]     Test net output #1: loss = 0.526951 (* 1 = 0.526951 loss)
I0628 22:02:15.219136 17220 solver.cpp:218] Iteration 31500 (22.2157 iter/s, 4.50132s/100 iters), loss = 0.279237
I0628 22:02:15.219136 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 22:02:15.219136 17220 solver.cpp:237]     Train net output #1: loss = 0.279237 (* 1 = 0.279237 loss)
I0628 22:02:15.219136 17220 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I0628 22:02:18.844344 17220 solver.cpp:218] Iteration 31600 (27.587 iter/s, 3.6249s/100 iters), loss = 0.342549
I0628 22:02:18.844344 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:02:18.844344 17220 solver.cpp:237]     Train net output #1: loss = 0.342549 (* 1 = 0.342549 loss)
I0628 22:02:18.844344 17220 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I0628 22:02:22.489450 17220 solver.cpp:218] Iteration 31700 (27.4364 iter/s, 3.64479s/100 iters), loss = 0.309286
I0628 22:02:22.489450 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:02:22.489450 17220 solver.cpp:237]     Train net output #1: loss = 0.309286 (* 1 = 0.309286 loss)
I0628 22:02:22.489450 17220 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I0628 22:02:26.141108 17220 solver.cpp:218] Iteration 31800 (27.3876 iter/s, 3.65129s/100 iters), loss = 0.319056
I0628 22:02:26.141108 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 22:02:26.141108 17220 solver.cpp:237]     Train net output #1: loss = 0.319056 (* 1 = 0.319056 loss)
I0628 22:02:26.141108 17220 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I0628 22:02:29.777236 17220 solver.cpp:218] Iteration 31900 (27.5025 iter/s, 3.63603s/100 iters), loss = 0.184663
I0628 22:02:29.777236 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:02:29.777236 17220 solver.cpp:237]     Train net output #1: loss = 0.184663 (* 1 = 0.184663 loss)
I0628 22:02:29.777236 17220 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I0628 22:02:33.238973  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:02:33.381574 17220 solver.cpp:330] Iteration 32000, Testing net (#0)
I0628 22:02:33.381574 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:02:34.202158 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:02:34.233180 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8322
I0628 22:02:34.233180 17220 solver.cpp:397]     Test net output #1: loss = 0.533517 (* 1 = 0.533517 loss)
I0628 22:02:34.268205 17220 solver.cpp:218] Iteration 32000 (22.2682 iter/s, 4.4907s/100 iters), loss = 0.211704
I0628 22:02:34.268205 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:02:34.268705 17220 solver.cpp:237]     Train net output #1: loss = 0.211704 (* 1 = 0.211704 loss)
I0628 22:02:34.268705 17220 sgd_solver.cpp:46] MultiStep Status: Iteration 32000, step = 1
I0628 22:02:34.268705 17220 sgd_solver.cpp:105] Iteration 32000, lr = 0.001
I0628 22:02:37.903893 17220 solver.cpp:218] Iteration 32100 (27.508 iter/s, 3.6353s/100 iters), loss = 0.242582
I0628 22:02:37.903893 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:02:37.903893 17220 solver.cpp:237]     Train net output #1: loss = 0.242582 (* 1 = 0.242582 loss)
I0628 22:02:37.903893 17220 sgd_solver.cpp:105] Iteration 32100, lr = 0.001
I0628 22:02:41.592034 17220 solver.cpp:218] Iteration 32200 (27.1176 iter/s, 3.68764s/100 iters), loss = 0.22325
I0628 22:02:41.592034 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:02:41.592034 17220 solver.cpp:237]     Train net output #1: loss = 0.223251 (* 1 = 0.223251 loss)
I0628 22:02:41.592034 17220 sgd_solver.cpp:105] Iteration 32200, lr = 0.001
I0628 22:02:45.230208 17220 solver.cpp:218] Iteration 32300 (27.4908 iter/s, 3.63758s/100 iters), loss = 0.137322
I0628 22:02:45.230208 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:02:45.230208 17220 solver.cpp:237]     Train net output #1: loss = 0.137322 (* 1 = 0.137322 loss)
I0628 22:02:45.230208 17220 sgd_solver.cpp:105] Iteration 32300, lr = 0.001
I0628 22:02:48.943019 17220 solver.cpp:218] Iteration 32400 (26.936 iter/s, 3.71251s/100 iters), loss = 0.233606
I0628 22:02:48.943019 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:02:48.943019 17220 solver.cpp:237]     Train net output #1: loss = 0.233606 (* 1 = 0.233606 loss)
I0628 22:02:48.943019 17220 sgd_solver.cpp:105] Iteration 32400, lr = 0.001
I0628 22:02:52.440068  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:02:52.584671 17220 solver.cpp:330] Iteration 32500, Testing net (#0)
I0628 22:02:52.584671 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:02:53.424768 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:02:53.456291 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8859
I0628 22:02:53.456291 17220 solver.cpp:397]     Test net output #1: loss = 0.352475 (* 1 = 0.352475 loss)
I0628 22:02:53.491317 17220 solver.cpp:218] Iteration 32500 (21.9862 iter/s, 4.5483s/100 iters), loss = 0.289794
I0628 22:02:53.491317 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 22:02:53.491317 17220 solver.cpp:237]     Train net output #1: loss = 0.289794 (* 1 = 0.289794 loss)
I0628 22:02:53.491317 17220 sgd_solver.cpp:105] Iteration 32500, lr = 0.001
I0628 22:02:57.177039 17220 solver.cpp:218] Iteration 32600 (27.1349 iter/s, 3.68528s/100 iters), loss = 0.297996
I0628 22:02:57.177039 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:02:57.177039 17220 solver.cpp:237]     Train net output #1: loss = 0.297996 (* 1 = 0.297996 loss)
I0628 22:02:57.177039 17220 sgd_solver.cpp:105] Iteration 32600, lr = 0.001
I0628 22:03:00.859694 17220 solver.cpp:218] Iteration 32700 (27.1587 iter/s, 3.68206s/100 iters), loss = 0.180012
I0628 22:03:00.859694 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:03:00.859694 17220 solver.cpp:237]     Train net output #1: loss = 0.180012 (* 1 = 0.180012 loss)
I0628 22:03:00.859694 17220 sgd_solver.cpp:105] Iteration 32700, lr = 0.001
I0628 22:03:04.539798 17220 solver.cpp:218] Iteration 32800 (27.1734 iter/s, 3.68007s/100 iters), loss = 0.226385
I0628 22:03:04.540297 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:03:04.540297 17220 solver.cpp:237]     Train net output #1: loss = 0.226385 (* 1 = 0.226385 loss)
I0628 22:03:04.540297 17220 sgd_solver.cpp:105] Iteration 32800, lr = 0.001
I0628 22:03:08.209930 17220 solver.cpp:218] Iteration 32900 (27.2518 iter/s, 3.66948s/100 iters), loss = 0.125188
I0628 22:03:08.209930 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:03:08.209930 17220 solver.cpp:237]     Train net output #1: loss = 0.125188 (* 1 = 0.125188 loss)
I0628 22:03:08.209930 17220 sgd_solver.cpp:105] Iteration 32900, lr = 0.001
I0628 22:03:11.707219  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:03:11.850821 17220 solver.cpp:330] Iteration 33000, Testing net (#0)
I0628 22:03:11.850821 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:03:12.687438 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:03:12.718940 17220 solver.cpp:397]     Test net output #0: accuracy = 0.888
I0628 22:03:12.718940 17220 solver.cpp:397]     Test net output #1: loss = 0.348255 (* 1 = 0.348255 loss)
I0628 22:03:12.753964 17220 solver.cpp:218] Iteration 33000 (22.0087 iter/s, 4.54366s/100 iters), loss = 0.210376
I0628 22:03:12.753964 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:03:12.753964 17220 solver.cpp:237]     Train net output #1: loss = 0.210376 (* 1 = 0.210376 loss)
I0628 22:03:12.753964 17220 sgd_solver.cpp:105] Iteration 33000, lr = 0.001
I0628 22:03:16.444180 17220 solver.cpp:218] Iteration 33100 (27.1019 iter/s, 3.68977s/100 iters), loss = 0.247097
I0628 22:03:16.444180 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:03:16.444180 17220 solver.cpp:237]     Train net output #1: loss = 0.247097 (* 1 = 0.247097 loss)
I0628 22:03:16.444180 17220 sgd_solver.cpp:105] Iteration 33100, lr = 0.001
I0628 22:03:20.127895 17220 solver.cpp:218] Iteration 33200 (27.1495 iter/s, 3.6833s/100 iters), loss = 0.175043
I0628 22:03:20.127895 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:03:20.127895 17220 solver.cpp:237]     Train net output #1: loss = 0.175044 (* 1 = 0.175044 loss)
I0628 22:03:20.127895 17220 sgd_solver.cpp:105] Iteration 33200, lr = 0.001
I0628 22:03:23.817019 17220 solver.cpp:218] Iteration 33300 (27.1084 iter/s, 3.6889s/100 iters), loss = 0.185749
I0628 22:03:23.817019 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:03:23.817019 17220 solver.cpp:237]     Train net output #1: loss = 0.185749 (* 1 = 0.185749 loss)
I0628 22:03:23.817019 17220 sgd_solver.cpp:105] Iteration 33300, lr = 0.001
I0628 22:03:27.496729 17220 solver.cpp:218] Iteration 33400 (27.1782 iter/s, 3.67942s/100 iters), loss = 0.142092
I0628 22:03:27.496729 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:03:27.496729 17220 solver.cpp:237]     Train net output #1: loss = 0.142092 (* 1 = 0.142092 loss)
I0628 22:03:27.496729 17220 sgd_solver.cpp:105] Iteration 33400, lr = 0.001
I0628 22:03:31.001860  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:03:31.145462 17220 solver.cpp:330] Iteration 33500, Testing net (#0)
I0628 22:03:31.145962 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:03:31.981556 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:03:32.013079 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8865
I0628 22:03:32.013079 17220 solver.cpp:397]     Test net output #1: loss = 0.350561 (* 1 = 0.350561 loss)
I0628 22:03:32.047605 17220 solver.cpp:218] Iteration 33500 (21.9757 iter/s, 4.55048s/100 iters), loss = 0.132429
I0628 22:03:32.047605 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:03:32.047605 17220 solver.cpp:237]     Train net output #1: loss = 0.132429 (* 1 = 0.132429 loss)
I0628 22:03:32.047605 17220 sgd_solver.cpp:105] Iteration 33500, lr = 0.001
I0628 22:03:35.738809 17220 solver.cpp:218] Iteration 33600 (27.0929 iter/s, 3.691s/100 iters), loss = 0.220673
I0628 22:03:35.739310 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:03:35.739310 17220 solver.cpp:237]     Train net output #1: loss = 0.220673 (* 1 = 0.220673 loss)
I0628 22:03:35.739310 17220 sgd_solver.cpp:105] Iteration 33600, lr = 0.001
I0628 22:03:39.454458 17220 solver.cpp:218] Iteration 33700 (26.9189 iter/s, 3.71487s/100 iters), loss = 0.162419
I0628 22:03:39.454458 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:03:39.454458 17220 solver.cpp:237]     Train net output #1: loss = 0.162419 (* 1 = 0.162419 loss)
I0628 22:03:39.454458 17220 sgd_solver.cpp:105] Iteration 33700, lr = 0.001
I0628 22:03:43.158594 17220 solver.cpp:218] Iteration 33800 (26.9994 iter/s, 3.70379s/100 iters), loss = 0.17372
I0628 22:03:43.158594 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:03:43.158594 17220 solver.cpp:237]     Train net output #1: loss = 0.17372 (* 1 = 0.17372 loss)
I0628 22:03:43.158594 17220 sgd_solver.cpp:105] Iteration 33800, lr = 0.001
I0628 22:03:46.859227 17220 solver.cpp:218] Iteration 33900 (27.0224 iter/s, 3.70063s/100 iters), loss = 0.218226
I0628 22:03:46.859227 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:03:46.859727 17220 solver.cpp:237]     Train net output #1: loss = 0.218226 (* 1 = 0.218226 loss)
I0628 22:03:46.859727 17220 sgd_solver.cpp:105] Iteration 33900, lr = 0.001
I0628 22:03:50.394243  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:03:50.538846 17220 solver.cpp:330] Iteration 34000, Testing net (#0)
I0628 22:03:50.538846 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:03:51.377943 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:03:51.409965 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8896
I0628 22:03:51.409965 17220 solver.cpp:397]     Test net output #1: loss = 0.349126 (* 1 = 0.349126 loss)
I0628 22:03:51.445489 17220 solver.cpp:218] Iteration 34000 (21.8079 iter/s, 4.58549s/100 iters), loss = 0.156469
I0628 22:03:51.445489 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:03:51.445489 17220 solver.cpp:237]     Train net output #1: loss = 0.15647 (* 1 = 0.15647 loss)
I0628 22:03:51.445489 17220 sgd_solver.cpp:105] Iteration 34000, lr = 0.001
I0628 22:03:55.150626 17220 solver.cpp:218] Iteration 34100 (26.9917 iter/s, 3.70484s/100 iters), loss = 0.211179
I0628 22:03:55.150626 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:03:55.150626 17220 solver.cpp:237]     Train net output #1: loss = 0.211179 (* 1 = 0.211179 loss)
I0628 22:03:55.150626 17220 sgd_solver.cpp:105] Iteration 34100, lr = 0.001
I0628 22:03:58.853097 17220 solver.cpp:218] Iteration 34200 (27.012 iter/s, 3.70206s/100 iters), loss = 0.144299
I0628 22:03:58.853097 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:03:58.853097 17220 solver.cpp:237]     Train net output #1: loss = 0.1443 (* 1 = 0.1443 loss)
I0628 22:03:58.853097 17220 sgd_solver.cpp:105] Iteration 34200, lr = 0.001
I0628 22:04:02.541749 17220 solver.cpp:218] Iteration 34300 (27.1132 iter/s, 3.68825s/100 iters), loss = 0.156899
I0628 22:04:02.541749 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:04:02.541749 17220 solver.cpp:237]     Train net output #1: loss = 0.156899 (* 1 = 0.156899 loss)
I0628 22:04:02.541749 17220 sgd_solver.cpp:105] Iteration 34300, lr = 0.001
I0628 22:04:06.237377 17220 solver.cpp:218] Iteration 34400 (27.0626 iter/s, 3.69514s/100 iters), loss = 0.144951
I0628 22:04:06.237377 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:04:06.237377 17220 solver.cpp:237]     Train net output #1: loss = 0.144951 (* 1 = 0.144951 loss)
I0628 22:04:06.237377 17220 sgd_solver.cpp:105] Iteration 34400, lr = 0.001
I0628 22:04:09.738003  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:04:09.882105 17220 solver.cpp:330] Iteration 34500, Testing net (#0)
I0628 22:04:09.882105 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:04:10.717699 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:04:10.748720 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8897
I0628 22:04:10.748720 17220 solver.cpp:397]     Test net output #1: loss = 0.349758 (* 1 = 0.349758 loss)
I0628 22:04:10.783754 17220 solver.cpp:218] Iteration 34500 (21.9978 iter/s, 4.54591s/100 iters), loss = 0.112184
I0628 22:04:10.783754 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:04:10.783754 17220 solver.cpp:237]     Train net output #1: loss = 0.112184 (* 1 = 0.112184 loss)
I0628 22:04:10.783754 17220 sgd_solver.cpp:105] Iteration 34500, lr = 0.001
I0628 22:04:14.480751 17220 solver.cpp:218] Iteration 34600 (27.0509 iter/s, 3.69673s/100 iters), loss = 0.244718
I0628 22:04:14.480751 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:04:14.480751 17220 solver.cpp:237]     Train net output #1: loss = 0.244718 (* 1 = 0.244718 loss)
I0628 22:04:14.480751 17220 sgd_solver.cpp:105] Iteration 34600, lr = 0.001
I0628 22:04:18.176882 17220 solver.cpp:218] Iteration 34700 (27.0589 iter/s, 3.69564s/100 iters), loss = 0.171102
I0628 22:04:18.176882 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:04:18.176882 17220 solver.cpp:237]     Train net output #1: loss = 0.171102 (* 1 = 0.171102 loss)
I0628 22:04:18.176882 17220 sgd_solver.cpp:105] Iteration 34700, lr = 0.001
I0628 22:04:21.876533 17220 solver.cpp:218] Iteration 34800 (27.0318 iter/s, 3.69935s/100 iters), loss = 0.257071
I0628 22:04:21.876533 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:04:21.876533 17220 solver.cpp:237]     Train net output #1: loss = 0.257071 (* 1 = 0.257071 loss)
I0628 22:04:21.876533 17220 sgd_solver.cpp:105] Iteration 34800, lr = 0.001
I0628 22:04:25.569188 17220 solver.cpp:218] Iteration 34900 (27.0821 iter/s, 3.69247s/100 iters), loss = 0.12929
I0628 22:04:25.569188 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:04:25.569687 17220 solver.cpp:237]     Train net output #1: loss = 0.12929 (* 1 = 0.12929 loss)
I0628 22:04:25.569687 17220 sgd_solver.cpp:105] Iteration 34900, lr = 0.001
I0628 22:04:29.092196  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:04:29.236284 17220 solver.cpp:330] Iteration 35000, Testing net (#0)
I0628 22:04:29.236284 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:04:30.072895 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:04:30.104409 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8903
I0628 22:04:30.104409 17220 solver.cpp:397]     Test net output #1: loss = 0.354284 (* 1 = 0.354284 loss)
I0628 22:04:30.139940 17220 solver.cpp:218] Iteration 35000 (21.8819 iter/s, 4.56998s/100 iters), loss = 0.159372
I0628 22:04:30.139940 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:04:30.139940 17220 solver.cpp:237]     Train net output #1: loss = 0.159373 (* 1 = 0.159373 loss)
I0628 22:04:30.139940 17220 sgd_solver.cpp:105] Iteration 35000, lr = 0.001
I0628 22:04:33.843523 17220 solver.cpp:218] Iteration 35100 (27.0007 iter/s, 3.70361s/100 iters), loss = 0.240684
I0628 22:04:33.843523 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:04:33.844015 17220 solver.cpp:237]     Train net output #1: loss = 0.240684 (* 1 = 0.240684 loss)
I0628 22:04:33.844015 17220 sgd_solver.cpp:105] Iteration 35100, lr = 0.001
I0628 22:04:37.537423 17220 solver.cpp:218] Iteration 35200 (27.0758 iter/s, 3.69334s/100 iters), loss = 0.119085
I0628 22:04:37.537423 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:04:37.537423 17220 solver.cpp:237]     Train net output #1: loss = 0.119086 (* 1 = 0.119086 loss)
I0628 22:04:37.537423 17220 sgd_solver.cpp:105] Iteration 35200, lr = 0.001
I0628 22:04:41.237591 17220 solver.cpp:218] Iteration 35300 (27.0314 iter/s, 3.69941s/100 iters), loss = 0.230435
I0628 22:04:41.237591 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:04:41.237591 17220 solver.cpp:237]     Train net output #1: loss = 0.230436 (* 1 = 0.230436 loss)
I0628 22:04:41.237591 17220 sgd_solver.cpp:105] Iteration 35300, lr = 0.001
I0628 22:04:44.936790 17220 solver.cpp:218] Iteration 35400 (27.0324 iter/s, 3.69927s/100 iters), loss = 0.101755
I0628 22:04:44.937291 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:04:44.937291 17220 solver.cpp:237]     Train net output #1: loss = 0.101756 (* 1 = 0.101756 loss)
I0628 22:04:44.937291 17220 sgd_solver.cpp:105] Iteration 35400, lr = 0.001
I0628 22:04:48.465801  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:04:48.610405 17220 solver.cpp:330] Iteration 35500, Testing net (#0)
I0628 22:04:48.610405 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:04:49.458513 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:04:49.491544 17220 solver.cpp:397]     Test net output #0: accuracy = 0.891
I0628 22:04:49.491544 17220 solver.cpp:397]     Test net output #1: loss = 0.352353 (* 1 = 0.352353 loss)
I0628 22:04:49.528576 17220 solver.cpp:218] Iteration 35500 (21.7805 iter/s, 4.59127s/100 iters), loss = 0.119072
I0628 22:04:49.528576 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:04:49.528576 17220 solver.cpp:237]     Train net output #1: loss = 0.119072 (* 1 = 0.119072 loss)
I0628 22:04:49.528576 17220 sgd_solver.cpp:105] Iteration 35500, lr = 0.001
I0628 22:04:53.213819 17220 solver.cpp:218] Iteration 35600 (27.1397 iter/s, 3.68463s/100 iters), loss = 0.160581
I0628 22:04:53.213819 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:04:53.213819 17220 solver.cpp:237]     Train net output #1: loss = 0.160581 (* 1 = 0.160581 loss)
I0628 22:04:53.213819 17220 sgd_solver.cpp:105] Iteration 35600, lr = 0.001
I0628 22:04:56.861913 17220 solver.cpp:218] Iteration 35700 (27.4141 iter/s, 3.64776s/100 iters), loss = 0.152165
I0628 22:04:56.861913 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:04:56.861913 17220 solver.cpp:237]     Train net output #1: loss = 0.152165 (* 1 = 0.152165 loss)
I0628 22:04:56.861913 17220 sgd_solver.cpp:105] Iteration 35700, lr = 0.001
I0628 22:05:00.516515 17220 solver.cpp:218] Iteration 35800 (27.3648 iter/s, 3.65433s/100 iters), loss = 0.141437
I0628 22:05:00.516515 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:05:00.516515 17220 solver.cpp:237]     Train net output #1: loss = 0.141437 (* 1 = 0.141437 loss)
I0628 22:05:00.516515 17220 sgd_solver.cpp:105] Iteration 35800, lr = 0.001
I0628 22:05:04.282243 17220 solver.cpp:218] Iteration 35900 (26.5571 iter/s, 3.76547s/100 iters), loss = 0.134795
I0628 22:05:04.282744 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:05:04.282744 17220 solver.cpp:237]     Train net output #1: loss = 0.134796 (* 1 = 0.134796 loss)
I0628 22:05:04.282744 17220 sgd_solver.cpp:105] Iteration 35900, lr = 0.001
I0628 22:05:07.808251  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:05:07.953855 17220 solver.cpp:330] Iteration 36000, Testing net (#0)
I0628 22:05:07.953855 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:05:08.793952 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:05:08.825475 17220 solver.cpp:397]     Test net output #0: accuracy = 0.89
I0628 22:05:08.825975 17220 solver.cpp:397]     Test net output #1: loss = 0.350981 (* 1 = 0.350981 loss)
I0628 22:05:08.860499 17220 solver.cpp:218] Iteration 36000 (21.8458 iter/s, 4.57753s/100 iters), loss = 0.1727
I0628 22:05:08.860499 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:05:08.860499 17220 solver.cpp:237]     Train net output #1: loss = 0.172701 (* 1 = 0.172701 loss)
I0628 22:05:08.860499 17220 sgd_solver.cpp:105] Iteration 36000, lr = 0.001
I0628 22:05:12.551625 17220 solver.cpp:218] Iteration 36100 (27.0939 iter/s, 3.69087s/100 iters), loss = 0.206695
I0628 22:05:12.551625 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:05:12.551625 17220 solver.cpp:237]     Train net output #1: loss = 0.206696 (* 1 = 0.206696 loss)
I0628 22:05:12.551625 17220 sgd_solver.cpp:105] Iteration 36100, lr = 0.001
I0628 22:05:16.248756 17220 solver.cpp:218] Iteration 36200 (27.0516 iter/s, 3.69664s/100 iters), loss = 0.165952
I0628 22:05:16.248756 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:05:16.248756 17220 solver.cpp:237]     Train net output #1: loss = 0.165953 (* 1 = 0.165953 loss)
I0628 22:05:16.248756 17220 sgd_solver.cpp:105] Iteration 36200, lr = 0.001
I0628 22:05:19.948889 17220 solver.cpp:218] Iteration 36300 (27.0292 iter/s, 3.6997s/100 iters), loss = 0.173392
I0628 22:05:19.948889 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:05:19.948889 17220 solver.cpp:237]     Train net output #1: loss = 0.173393 (* 1 = 0.173393 loss)
I0628 22:05:19.948889 17220 sgd_solver.cpp:105] Iteration 36300, lr = 0.001
I0628 22:05:23.705561 17220 solver.cpp:218] Iteration 36400 (26.6203 iter/s, 3.75653s/100 iters), loss = 0.119302
I0628 22:05:23.705561 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:05:23.705561 17220 solver.cpp:237]     Train net output #1: loss = 0.119302 (* 1 = 0.119302 loss)
I0628 22:05:23.705561 17220 sgd_solver.cpp:105] Iteration 36400, lr = 0.001
I0628 22:05:27.237574  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:05:27.387681 17220 solver.cpp:330] Iteration 36500, Testing net (#0)
I0628 22:05:27.387681 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:05:28.228305 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:05:28.259829 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8895
I0628 22:05:28.259829 17220 solver.cpp:397]     Test net output #1: loss = 0.352722 (* 1 = 0.352722 loss)
I0628 22:05:28.294853 17220 solver.cpp:218] Iteration 36500 (21.7922 iter/s, 4.58879s/100 iters), loss = 0.125023
I0628 22:05:28.294853 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:05:28.294853 17220 solver.cpp:237]     Train net output #1: loss = 0.125023 (* 1 = 0.125023 loss)
I0628 22:05:28.294853 17220 sgd_solver.cpp:105] Iteration 36500, lr = 0.001
I0628 22:05:31.989981 17220 solver.cpp:218] Iteration 36600 (27.0653 iter/s, 3.69477s/100 iters), loss = 0.214045
I0628 22:05:31.989981 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:05:31.989981 17220 solver.cpp:237]     Train net output #1: loss = 0.214045 (* 1 = 0.214045 loss)
I0628 22:05:31.989981 17220 sgd_solver.cpp:105] Iteration 36600, lr = 0.001
I0628 22:05:35.670882 17220 solver.cpp:218] Iteration 36700 (27.1697 iter/s, 3.68057s/100 iters), loss = 0.160908
I0628 22:05:35.670882 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:05:35.671382 17220 solver.cpp:237]     Train net output #1: loss = 0.160908 (* 1 = 0.160908 loss)
I0628 22:05:35.671382 17220 sgd_solver.cpp:105] Iteration 36700, lr = 0.001
I0628 22:05:39.296963 17220 solver.cpp:218] Iteration 36800 (27.583 iter/s, 3.62542s/100 iters), loss = 0.143522
I0628 22:05:39.296963 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:05:39.296963 17220 solver.cpp:237]     Train net output #1: loss = 0.143522 (* 1 = 0.143522 loss)
I0628 22:05:39.296963 17220 sgd_solver.cpp:105] Iteration 36800, lr = 0.001
I0628 22:05:42.933578 17220 solver.cpp:218] Iteration 36900 (27.4987 iter/s, 3.63653s/100 iters), loss = 0.1109
I0628 22:05:42.934078 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:05:42.934078 17220 solver.cpp:237]     Train net output #1: loss = 0.1109 (* 1 = 0.1109 loss)
I0628 22:05:42.934078 17220 sgd_solver.cpp:105] Iteration 36900, lr = 0.001
I0628 22:05:46.400044  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:05:46.542645 17220 solver.cpp:330] Iteration 37000, Testing net (#0)
I0628 22:05:46.542645 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:05:47.364229 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:05:47.395752 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8887
I0628 22:05:47.395752 17220 solver.cpp:397]     Test net output #1: loss = 0.353313 (* 1 = 0.353313 loss)
I0628 22:05:47.429776 17220 solver.cpp:218] Iteration 37000 (22.2442 iter/s, 4.49556s/100 iters), loss = 0.129995
I0628 22:05:47.429776 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:05:47.429776 17220 solver.cpp:237]     Train net output #1: loss = 0.129996 (* 1 = 0.129996 loss)
I0628 22:05:47.429776 17220 sgd_solver.cpp:105] Iteration 37000, lr = 0.001
I0628 22:05:51.062861 17220 solver.cpp:218] Iteration 37100 (27.5276 iter/s, 3.63271s/100 iters), loss = 0.230876
I0628 22:05:51.062861 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:05:51.062861 17220 solver.cpp:237]     Train net output #1: loss = 0.230877 (* 1 = 0.230877 loss)
I0628 22:05:51.062861 17220 sgd_solver.cpp:105] Iteration 37100, lr = 0.001
I0628 22:05:54.711457 17220 solver.cpp:218] Iteration 37200 (27.4119 iter/s, 3.64805s/100 iters), loss = 0.227454
I0628 22:05:54.711457 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:05:54.711457 17220 solver.cpp:237]     Train net output #1: loss = 0.227454 (* 1 = 0.227454 loss)
I0628 22:05:54.711457 17220 sgd_solver.cpp:105] Iteration 37200, lr = 0.001
I0628 22:05:58.359076 17220 solver.cpp:218] Iteration 37300 (27.4176 iter/s, 3.64729s/100 iters), loss = 0.180374
I0628 22:05:58.359076 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:05:58.359076 17220 solver.cpp:237]     Train net output #1: loss = 0.180374 (* 1 = 0.180374 loss)
I0628 22:05:58.359076 17220 sgd_solver.cpp:105] Iteration 37300, lr = 0.001
I0628 22:06:01.993661 17220 solver.cpp:218] Iteration 37400 (27.5164 iter/s, 3.6342s/100 iters), loss = 0.0570505
I0628 22:06:01.993661 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:06:01.993661 17220 solver.cpp:237]     Train net output #1: loss = 0.0570509 (* 1 = 0.0570509 loss)
I0628 22:06:01.993661 17220 sgd_solver.cpp:105] Iteration 37400, lr = 0.001
I0628 22:06:05.451122  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:06:05.593724 17220 solver.cpp:330] Iteration 37500, Testing net (#0)
I0628 22:06:05.593724 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:06:06.415307 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:06:06.445837 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8911
I0628 22:06:06.445837 17220 solver.cpp:397]     Test net output #1: loss = 0.353622 (* 1 = 0.353622 loss)
I0628 22:06:06.480355 17220 solver.cpp:218] Iteration 37500 (22.2893 iter/s, 4.48646s/100 iters), loss = 0.123242
I0628 22:06:06.480355 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:06:06.480355 17220 solver.cpp:237]     Train net output #1: loss = 0.123242 (* 1 = 0.123242 loss)
I0628 22:06:06.480355 17220 sgd_solver.cpp:105] Iteration 37500, lr = 0.001
I0628 22:06:10.106433 17220 solver.cpp:218] Iteration 37600 (27.5796 iter/s, 3.62587s/100 iters), loss = 0.236101
I0628 22:06:10.106433 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:06:10.106433 17220 solver.cpp:237]     Train net output #1: loss = 0.236102 (* 1 = 0.236102 loss)
I0628 22:06:10.106935 17220 sgd_solver.cpp:105] Iteration 37600, lr = 0.001
I0628 22:06:13.765048 17220 solver.cpp:218] Iteration 37700 (27.3379 iter/s, 3.65793s/100 iters), loss = 0.135765
I0628 22:06:13.765048 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:06:13.765048 17220 solver.cpp:237]     Train net output #1: loss = 0.135765 (* 1 = 0.135765 loss)
I0628 22:06:13.765048 17220 sgd_solver.cpp:105] Iteration 37700, lr = 0.001
I0628 22:06:17.388625 17220 solver.cpp:218] Iteration 37800 (27.5974 iter/s, 3.62353s/100 iters), loss = 0.170693
I0628 22:06:17.388625 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:06:17.388625 17220 solver.cpp:237]     Train net output #1: loss = 0.170694 (* 1 = 0.170694 loss)
I0628 22:06:17.389127 17220 sgd_solver.cpp:105] Iteration 37800, lr = 0.001
I0628 22:06:21.036284 17220 solver.cpp:218] Iteration 37900 (27.4205 iter/s, 3.64691s/100 iters), loss = 0.11936
I0628 22:06:21.036284 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:06:21.036284 17220 solver.cpp:237]     Train net output #1: loss = 0.11936 (* 1 = 0.11936 loss)
I0628 22:06:21.036284 17220 sgd_solver.cpp:105] Iteration 37900, lr = 0.001
I0628 22:06:24.494242  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:06:24.636844 17220 solver.cpp:330] Iteration 38000, Testing net (#0)
I0628 22:06:24.636844 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:06:25.465934 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:06:25.496955 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8881
I0628 22:06:25.496955 17220 solver.cpp:397]     Test net output #1: loss = 0.359321 (* 1 = 0.359321 loss)
I0628 22:06:25.531479 17220 solver.cpp:218] Iteration 38000 (22.2468 iter/s, 4.49504s/100 iters), loss = 0.0919617
I0628 22:06:25.531479 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:06:25.531479 17220 solver.cpp:237]     Train net output #1: loss = 0.0919621 (* 1 = 0.0919621 loss)
I0628 22:06:25.531479 17220 sgd_solver.cpp:105] Iteration 38000, lr = 0.001
I0628 22:06:29.176074 17220 solver.cpp:218] Iteration 38100 (27.4407 iter/s, 3.64422s/100 iters), loss = 0.159958
I0628 22:06:29.176074 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:06:29.176074 17220 solver.cpp:237]     Train net output #1: loss = 0.159959 (* 1 = 0.159959 loss)
I0628 22:06:29.176074 17220 sgd_solver.cpp:105] Iteration 38100, lr = 0.001
I0628 22:06:32.805155 17220 solver.cpp:218] Iteration 38200 (27.558 iter/s, 3.62871s/100 iters), loss = 0.131928
I0628 22:06:32.805155 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:06:32.805155 17220 solver.cpp:237]     Train net output #1: loss = 0.131928 (* 1 = 0.131928 loss)
I0628 22:06:32.805155 17220 sgd_solver.cpp:105] Iteration 38200, lr = 0.001
I0628 22:06:36.428733 17220 solver.cpp:218] Iteration 38300 (27.5981 iter/s, 3.62343s/100 iters), loss = 0.176881
I0628 22:06:36.428733 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:06:36.428733 17220 solver.cpp:237]     Train net output #1: loss = 0.176881 (* 1 = 0.176881 loss)
I0628 22:06:36.428733 17220 sgd_solver.cpp:105] Iteration 38300, lr = 0.001
I0628 22:06:40.051280 17220 solver.cpp:218] Iteration 38400 (27.6083 iter/s, 3.62209s/100 iters), loss = 0.132957
I0628 22:06:40.051280 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:06:40.051280 17220 solver.cpp:237]     Train net output #1: loss = 0.132957 (* 1 = 0.132957 loss)
I0628 22:06:40.051280 17220 sgd_solver.cpp:105] Iteration 38400, lr = 0.001
I0628 22:06:43.500485  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:06:43.641587 17220 solver.cpp:330] Iteration 38500, Testing net (#0)
I0628 22:06:43.641587 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:06:44.470690 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:06:44.501713 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8905
I0628 22:06:44.501713 17220 solver.cpp:397]     Test net output #1: loss = 0.361538 (* 1 = 0.361538 loss)
I0628 22:06:44.535785 17220 solver.cpp:218] Iteration 38500 (22.3023 iter/s, 4.48384s/100 iters), loss = 0.0973371
I0628 22:06:44.535785 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:06:44.535785 17220 solver.cpp:237]     Train net output #1: loss = 0.0973374 (* 1 = 0.0973374 loss)
I0628 22:06:44.535785 17220 sgd_solver.cpp:105] Iteration 38500, lr = 0.001
I0628 22:06:48.174909 17220 solver.cpp:218] Iteration 38600 (27.4793 iter/s, 3.6391s/100 iters), loss = 0.254932
I0628 22:06:48.174909 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:06:48.174909 17220 solver.cpp:237]     Train net output #1: loss = 0.254932 (* 1 = 0.254932 loss)
I0628 22:06:48.174909 17220 sgd_solver.cpp:105] Iteration 38600, lr = 0.001
I0628 22:06:51.796553 17220 solver.cpp:218] Iteration 38700 (27.616 iter/s, 3.62109s/100 iters), loss = 0.194253
I0628 22:06:51.796553 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:06:51.796553 17220 solver.cpp:237]     Train net output #1: loss = 0.194254 (* 1 = 0.194254 loss)
I0628 22:06:51.796553 17220 sgd_solver.cpp:105] Iteration 38700, lr = 0.001
I0628 22:06:55.429723 17220 solver.cpp:218] Iteration 38800 (27.5271 iter/s, 3.63278s/100 iters), loss = 0.108575
I0628 22:06:55.429723 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:06:55.429723 17220 solver.cpp:237]     Train net output #1: loss = 0.108575 (* 1 = 0.108575 loss)
I0628 22:06:55.429723 17220 sgd_solver.cpp:105] Iteration 38800, lr = 0.001
I0628 22:06:59.063835 17220 solver.cpp:218] Iteration 38900 (27.5181 iter/s, 3.63397s/100 iters), loss = 0.0880035
I0628 22:06:59.063835 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:06:59.063835 17220 solver.cpp:237]     Train net output #1: loss = 0.0880038 (* 1 = 0.0880038 loss)
I0628 22:06:59.063835 17220 sgd_solver.cpp:105] Iteration 38900, lr = 0.001
I0628 22:07:02.516393  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:07:02.657508 17220 solver.cpp:330] Iteration 39000, Testing net (#0)
I0628 22:07:02.657508 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:07:03.482095 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:07:03.513113 17220 solver.cpp:397]     Test net output #0: accuracy = 0.89
I0628 22:07:03.513113 17220 solver.cpp:397]     Test net output #1: loss = 0.364002 (* 1 = 0.364002 loss)
I0628 22:07:03.547626 17220 solver.cpp:218] Iteration 39000 (22.306 iter/s, 4.48311s/100 iters), loss = 0.156722
I0628 22:07:03.547626 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:07:03.547626 17220 solver.cpp:237]     Train net output #1: loss = 0.156723 (* 1 = 0.156723 loss)
I0628 22:07:03.547626 17220 sgd_solver.cpp:105] Iteration 39000, lr = 0.001
I0628 22:07:07.191682 17220 solver.cpp:218] Iteration 39100 (27.4422 iter/s, 3.64402s/100 iters), loss = 0.174514
I0628 22:07:07.191682 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:07:07.191682 17220 solver.cpp:237]     Train net output #1: loss = 0.174514 (* 1 = 0.174514 loss)
I0628 22:07:07.191682 17220 sgd_solver.cpp:105] Iteration 39100, lr = 0.001
I0628 22:07:10.816761 17220 solver.cpp:218] Iteration 39200 (27.5879 iter/s, 3.62478s/100 iters), loss = 0.134282
I0628 22:07:10.816761 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:07:10.816761 17220 solver.cpp:237]     Train net output #1: loss = 0.134283 (* 1 = 0.134283 loss)
I0628 22:07:10.816761 17220 sgd_solver.cpp:105] Iteration 39200, lr = 0.001
I0628 22:07:14.443842 17220 solver.cpp:218] Iteration 39300 (27.574 iter/s, 3.62661s/100 iters), loss = 0.122322
I0628 22:07:14.443842 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:07:14.443842 17220 solver.cpp:237]     Train net output #1: loss = 0.122322 (* 1 = 0.122322 loss)
I0628 22:07:14.443842 17220 sgd_solver.cpp:105] Iteration 39300, lr = 0.001
I0628 22:07:18.068420 17220 solver.cpp:218] Iteration 39400 (27.5948 iter/s, 3.62387s/100 iters), loss = 0.163841
I0628 22:07:18.068420 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:07:18.068420 17220 solver.cpp:237]     Train net output #1: loss = 0.163841 (* 1 = 0.163841 loss)
I0628 22:07:18.068420 17220 sgd_solver.cpp:105] Iteration 39400, lr = 0.001
I0628 22:07:21.519876  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:07:21.661478 17220 solver.cpp:330] Iteration 39500, Testing net (#0)
I0628 22:07:21.661478 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:07:22.482565 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:07:22.513083 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8879
I0628 22:07:22.513083 17220 solver.cpp:397]     Test net output #1: loss = 0.358462 (* 1 = 0.358462 loss)
I0628 22:07:22.548120 17220 solver.cpp:218] Iteration 39500 (22.324 iter/s, 4.47948s/100 iters), loss = 0.100224
I0628 22:07:22.548120 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:07:22.548120 17220 solver.cpp:237]     Train net output #1: loss = 0.100225 (* 1 = 0.100225 loss)
I0628 22:07:22.548120 17220 sgd_solver.cpp:105] Iteration 39500, lr = 0.001
I0628 22:07:26.168845 17220 solver.cpp:218] Iteration 39600 (27.6218 iter/s, 3.62033s/100 iters), loss = 0.213767
I0628 22:07:26.168845 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:07:26.168845 17220 solver.cpp:237]     Train net output #1: loss = 0.213767 (* 1 = 0.213767 loss)
I0628 22:07:26.168845 17220 sgd_solver.cpp:105] Iteration 39600, lr = 0.001
I0628 22:07:29.795498 17220 solver.cpp:218] Iteration 39700 (27.5744 iter/s, 3.62656s/100 iters), loss = 0.160973
I0628 22:07:29.796000 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:07:29.796000 17220 solver.cpp:237]     Train net output #1: loss = 0.160973 (* 1 = 0.160973 loss)
I0628 22:07:29.796000 17220 sgd_solver.cpp:105] Iteration 39700, lr = 0.001
I0628 22:07:33.433584 17220 solver.cpp:218] Iteration 39800 (27.4909 iter/s, 3.63757s/100 iters), loss = 0.179065
I0628 22:07:33.433584 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:07:33.433584 17220 solver.cpp:237]     Train net output #1: loss = 0.179065 (* 1 = 0.179065 loss)
I0628 22:07:33.433584 17220 sgd_solver.cpp:105] Iteration 39800, lr = 0.001
I0628 22:07:37.059659 17220 solver.cpp:218] Iteration 39900 (27.583 iter/s, 3.62542s/100 iters), loss = 0.0843667
I0628 22:07:37.059659 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:07:37.059659 17220 solver.cpp:237]     Train net output #1: loss = 0.0843671 (* 1 = 0.0843671 loss)
I0628 22:07:37.059659 17220 sgd_solver.cpp:105] Iteration 39900, lr = 0.001
I0628 22:07:40.534883  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:07:40.685494 17220 solver.cpp:330] Iteration 40000, Testing net (#0)
I0628 22:07:40.685494 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:07:41.506575 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:07:41.537596 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8909
I0628 22:07:41.537596 17220 solver.cpp:397]     Test net output #1: loss = 0.360016 (* 1 = 0.360016 loss)
I0628 22:07:41.572120 17220 solver.cpp:218] Iteration 40000 (22.1618 iter/s, 4.51226s/100 iters), loss = 0.117523
I0628 22:07:41.572120 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:07:41.572120 17220 solver.cpp:237]     Train net output #1: loss = 0.117524 (* 1 = 0.117524 loss)
I0628 22:07:41.572120 17220 sgd_solver.cpp:105] Iteration 40000, lr = 0.001
I0628 22:07:45.177685 17220 solver.cpp:218] Iteration 40100 (27.7373 iter/s, 3.60525s/100 iters), loss = 0.158873
I0628 22:07:45.177685 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:07:45.177685 17220 solver.cpp:237]     Train net output #1: loss = 0.158873 (* 1 = 0.158873 loss)
I0628 22:07:45.177685 17220 sgd_solver.cpp:105] Iteration 40100, lr = 0.001
I0628 22:07:48.805366 17220 solver.cpp:218] Iteration 40200 (27.5692 iter/s, 3.62724s/100 iters), loss = 0.159094
I0628 22:07:48.805366 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:07:48.805366 17220 solver.cpp:237]     Train net output #1: loss = 0.159094 (* 1 = 0.159094 loss)
I0628 22:07:48.805366 17220 sgd_solver.cpp:105] Iteration 40200, lr = 0.001
I0628 22:07:52.422930 17220 solver.cpp:218] Iteration 40300 (27.6443 iter/s, 3.61738s/100 iters), loss = 0.18876
I0628 22:07:52.423430 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:07:52.423430 17220 solver.cpp:237]     Train net output #1: loss = 0.188761 (* 1 = 0.188761 loss)
I0628 22:07:52.423430 17220 sgd_solver.cpp:105] Iteration 40300, lr = 0.001
I0628 22:07:56.031018 17220 solver.cpp:218] Iteration 40400 (27.7215 iter/s, 3.60731s/100 iters), loss = 0.0825927
I0628 22:07:56.031018 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:07:56.031018 17220 solver.cpp:237]     Train net output #1: loss = 0.0825931 (* 1 = 0.0825931 loss)
I0628 22:07:56.031018 17220 sgd_solver.cpp:105] Iteration 40400, lr = 0.001
I0628 22:07:59.464478  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:07:59.606580 17220 solver.cpp:330] Iteration 40500, Testing net (#0)
I0628 22:07:59.606580 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:08:00.427165 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:08:00.458189 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8901
I0628 22:08:00.458189 17220 solver.cpp:397]     Test net output #1: loss = 0.363863 (* 1 = 0.363863 loss)
I0628 22:08:00.492712 17220 solver.cpp:218] Iteration 40500 (22.4146 iter/s, 4.46139s/100 iters), loss = 0.13864
I0628 22:08:00.492712 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:08:00.492712 17220 solver.cpp:237]     Train net output #1: loss = 0.138641 (* 1 = 0.138641 loss)
I0628 22:08:00.492712 17220 sgd_solver.cpp:105] Iteration 40500, lr = 0.001
I0628 22:08:04.111783 17220 solver.cpp:218] Iteration 40600 (27.634 iter/s, 3.61873s/100 iters), loss = 0.129637
I0628 22:08:04.111783 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:08:04.111783 17220 solver.cpp:237]     Train net output #1: loss = 0.129637 (* 1 = 0.129637 loss)
I0628 22:08:04.111783 17220 sgd_solver.cpp:105] Iteration 40600, lr = 0.001
I0628 22:08:07.753376 17220 solver.cpp:218] Iteration 40700 (27.4631 iter/s, 3.64125s/100 iters), loss = 0.171567
I0628 22:08:07.753376 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:08:07.753376 17220 solver.cpp:237]     Train net output #1: loss = 0.171567 (* 1 = 0.171567 loss)
I0628 22:08:07.753376 17220 sgd_solver.cpp:105] Iteration 40700, lr = 0.001
I0628 22:08:11.386960 17220 solver.cpp:218] Iteration 40800 (27.5221 iter/s, 3.63345s/100 iters), loss = 0.140741
I0628 22:08:11.386960 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:08:11.386960 17220 solver.cpp:237]     Train net output #1: loss = 0.140741 (* 1 = 0.140741 loss)
I0628 22:08:11.386960 17220 sgd_solver.cpp:105] Iteration 40800, lr = 0.001
I0628 22:08:15.013540 17220 solver.cpp:218] Iteration 40900 (27.5784 iter/s, 3.62602s/100 iters), loss = 0.0776881
I0628 22:08:15.013540 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:08:15.013540 17220 solver.cpp:237]     Train net output #1: loss = 0.0776885 (* 1 = 0.0776885 loss)
I0628 22:08:15.013540 17220 sgd_solver.cpp:105] Iteration 40900, lr = 0.001
I0628 22:08:18.480506  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:08:18.621107 17220 solver.cpp:330] Iteration 41000, Testing net (#0)
I0628 22:08:18.621608 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:08:19.444692 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:08:19.475715 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8901
I0628 22:08:19.475715 17220 solver.cpp:397]     Test net output #1: loss = 0.363651 (* 1 = 0.363651 loss)
I0628 22:08:19.510239 17220 solver.cpp:218] Iteration 41000 (22.2403 iter/s, 4.49634s/100 iters), loss = 0.145922
I0628 22:08:19.510239 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:08:19.510239 17220 solver.cpp:237]     Train net output #1: loss = 0.145922 (* 1 = 0.145922 loss)
I0628 22:08:19.510239 17220 sgd_solver.cpp:105] Iteration 41000, lr = 0.001
I0628 22:08:23.148243 17220 solver.cpp:218] Iteration 41100 (27.4896 iter/s, 3.63773s/100 iters), loss = 0.195342
I0628 22:08:23.148243 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:08:23.148243 17220 solver.cpp:237]     Train net output #1: loss = 0.195343 (* 1 = 0.195343 loss)
I0628 22:08:23.148243 17220 sgd_solver.cpp:105] Iteration 41100, lr = 0.001
I0628 22:08:26.756904 17220 solver.cpp:218] Iteration 41200 (27.7138 iter/s, 3.60831s/100 iters), loss = 0.137262
I0628 22:08:26.756904 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:08:26.756904 17220 solver.cpp:237]     Train net output #1: loss = 0.137262 (* 1 = 0.137262 loss)
I0628 22:08:26.756904 17220 sgd_solver.cpp:105] Iteration 41200, lr = 0.001
I0628 22:08:30.360055 17220 solver.cpp:218] Iteration 41300 (27.7561 iter/s, 3.60281s/100 iters), loss = 0.162088
I0628 22:08:30.360055 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:08:30.360055 17220 solver.cpp:237]     Train net output #1: loss = 0.162088 (* 1 = 0.162088 loss)
I0628 22:08:30.360055 17220 sgd_solver.cpp:105] Iteration 41300, lr = 0.001
I0628 22:08:33.983435 17220 solver.cpp:218] Iteration 41400 (27.5995 iter/s, 3.62326s/100 iters), loss = 0.0911563
I0628 22:08:33.983937 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:08:33.983937 17220 solver.cpp:237]     Train net output #1: loss = 0.0911567 (* 1 = 0.0911567 loss)
I0628 22:08:33.983937 17220 sgd_solver.cpp:105] Iteration 41400, lr = 0.001
I0628 22:08:37.421324  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:08:37.566910 17220 solver.cpp:330] Iteration 41500, Testing net (#0)
I0628 22:08:37.566910 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:08:38.394001 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:08:38.425035 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8915
I0628 22:08:38.425035 17220 solver.cpp:397]     Test net output #1: loss = 0.364554 (* 1 = 0.364554 loss)
I0628 22:08:38.459544 17220 solver.cpp:218] Iteration 41500 (22.3438 iter/s, 4.4755s/100 iters), loss = 0.135499
I0628 22:08:38.459544 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:08:38.459544 17220 solver.cpp:237]     Train net output #1: loss = 0.135499 (* 1 = 0.135499 loss)
I0628 22:08:38.459544 17220 sgd_solver.cpp:105] Iteration 41500, lr = 0.001
I0628 22:08:42.086670 17220 solver.cpp:218] Iteration 41600 (27.5716 iter/s, 3.62692s/100 iters), loss = 0.169399
I0628 22:08:42.086670 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:08:42.086670 17220 solver.cpp:237]     Train net output #1: loss = 0.169399 (* 1 = 0.169399 loss)
I0628 22:08:42.086670 17220 sgd_solver.cpp:105] Iteration 41600, lr = 0.001
I0628 22:08:45.712772 17220 solver.cpp:218] Iteration 41700 (27.583 iter/s, 3.62541s/100 iters), loss = 0.158191
I0628 22:08:45.712772 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:08:45.712772 17220 solver.cpp:237]     Train net output #1: loss = 0.158192 (* 1 = 0.158192 loss)
I0628 22:08:45.712772 17220 sgd_solver.cpp:105] Iteration 41700, lr = 0.001
I0628 22:08:49.322340 17220 solver.cpp:218] Iteration 41800 (27.7072 iter/s, 3.60917s/100 iters), loss = 0.171553
I0628 22:08:49.322340 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:08:49.322340 17220 solver.cpp:237]     Train net output #1: loss = 0.171553 (* 1 = 0.171553 loss)
I0628 22:08:49.322340 17220 sgd_solver.cpp:105] Iteration 41800, lr = 0.001
I0628 22:08:52.947564 17220 solver.cpp:218] Iteration 41900 (27.586 iter/s, 3.62503s/100 iters), loss = 0.0778795
I0628 22:08:52.947564 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:08:52.947564 17220 solver.cpp:237]     Train net output #1: loss = 0.0778799 (* 1 = 0.0778799 loss)
I0628 22:08:52.947564 17220 sgd_solver.cpp:105] Iteration 41900, lr = 0.001
I0628 22:08:56.383903  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:08:56.525517 17220 solver.cpp:330] Iteration 42000, Testing net (#0)
I0628 22:08:56.525517 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:08:57.347102 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:08:57.378110 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8924
I0628 22:08:57.378110 17220 solver.cpp:397]     Test net output #1: loss = 0.368712 (* 1 = 0.368712 loss)
I0628 22:08:57.413136 17220 solver.cpp:218] Iteration 42000 (22.3961 iter/s, 4.46507s/100 iters), loss = 0.136925
I0628 22:08:57.413136 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:08:57.413136 17220 solver.cpp:237]     Train net output #1: loss = 0.136925 (* 1 = 0.136925 loss)
I0628 22:08:57.413136 17220 sgd_solver.cpp:105] Iteration 42000, lr = 0.001
I0628 22:09:01.041726 17220 solver.cpp:218] Iteration 42100 (27.5603 iter/s, 3.6284s/100 iters), loss = 0.165961
I0628 22:09:01.041726 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:09:01.041726 17220 solver.cpp:237]     Train net output #1: loss = 0.165962 (* 1 = 0.165962 loss)
I0628 22:09:01.041726 17220 sgd_solver.cpp:105] Iteration 42100, lr = 0.001
I0628 22:09:04.668807 17220 solver.cpp:218] Iteration 42200 (27.5746 iter/s, 3.62652s/100 iters), loss = 0.203326
I0628 22:09:04.668807 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:09:04.668807 17220 solver.cpp:237]     Train net output #1: loss = 0.203327 (* 1 = 0.203327 loss)
I0628 22:09:04.668807 17220 sgd_solver.cpp:105] Iteration 42200, lr = 0.001
I0628 22:09:08.290385 17220 solver.cpp:218] Iteration 42300 (27.6133 iter/s, 3.62144s/100 iters), loss = 0.182277
I0628 22:09:08.290385 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:09:08.290385 17220 solver.cpp:237]     Train net output #1: loss = 0.182278 (* 1 = 0.182278 loss)
I0628 22:09:08.290385 17220 sgd_solver.cpp:105] Iteration 42300, lr = 0.001
I0628 22:09:11.923976 17220 solver.cpp:218] Iteration 42400 (27.5253 iter/s, 3.63302s/100 iters), loss = 0.0968176
I0628 22:09:11.923976 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:09:11.923976 17220 solver.cpp:237]     Train net output #1: loss = 0.0968179 (* 1 = 0.0968179 loss)
I0628 22:09:11.923976 17220 sgd_solver.cpp:105] Iteration 42400, lr = 0.001
I0628 22:09:15.376953  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:09:15.518555 17220 solver.cpp:330] Iteration 42500, Testing net (#0)
I0628 22:09:15.518555 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:09:16.340138 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:09:16.371161 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8895
I0628 22:09:16.371161 17220 solver.cpp:397]     Test net output #1: loss = 0.368577 (* 1 = 0.368577 loss)
I0628 22:09:16.406697 17220 solver.cpp:218] Iteration 42500 (22.3091 iter/s, 4.48248s/100 iters), loss = 0.0911161
I0628 22:09:16.406697 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:09:16.406697 17220 solver.cpp:237]     Train net output #1: loss = 0.0911165 (* 1 = 0.0911165 loss)
I0628 22:09:16.406697 17220 sgd_solver.cpp:105] Iteration 42500, lr = 0.001
I0628 22:09:20.052289 17220 solver.cpp:218] Iteration 42600 (27.4334 iter/s, 3.64519s/100 iters), loss = 0.148552
I0628 22:09:20.052289 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:09:20.052289 17220 solver.cpp:237]     Train net output #1: loss = 0.148552 (* 1 = 0.148552 loss)
I0628 22:09:20.052289 17220 sgd_solver.cpp:105] Iteration 42600, lr = 0.001
I0628 22:09:23.693924 17220 solver.cpp:218] Iteration 42700 (27.4616 iter/s, 3.64145s/100 iters), loss = 0.141599
I0628 22:09:23.694422 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:09:23.694422 17220 solver.cpp:237]     Train net output #1: loss = 0.141599 (* 1 = 0.141599 loss)
I0628 22:09:23.694422 17220 sgd_solver.cpp:105] Iteration 42700, lr = 0.001
I0628 22:09:27.314870 17220 solver.cpp:218] Iteration 42800 (27.6203 iter/s, 3.62052s/100 iters), loss = 0.167394
I0628 22:09:27.314870 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:09:27.314870 17220 solver.cpp:237]     Train net output #1: loss = 0.167394 (* 1 = 0.167394 loss)
I0628 22:09:27.314870 17220 sgd_solver.cpp:105] Iteration 42800, lr = 0.001
I0628 22:09:30.946938 17220 solver.cpp:218] Iteration 42900 (27.538 iter/s, 3.63134s/100 iters), loss = 0.126532
I0628 22:09:30.946938 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:09:30.946938 17220 solver.cpp:237]     Train net output #1: loss = 0.126532 (* 1 = 0.126532 loss)
I0628 22:09:30.946938 17220 sgd_solver.cpp:105] Iteration 42900, lr = 0.001
I0628 22:09:34.392890  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:09:34.533990 17220 solver.cpp:330] Iteration 43000, Testing net (#0)
I0628 22:09:34.533990 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:09:35.359591 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:09:35.391099 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8917
I0628 22:09:35.391099 17220 solver.cpp:397]     Test net output #1: loss = 0.36217 (* 1 = 0.36217 loss)
I0628 22:09:35.425633 17220 solver.cpp:218] Iteration 43000 (22.3282 iter/s, 4.47864s/100 iters), loss = 0.143228
I0628 22:09:35.425633 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:09:35.425633 17220 solver.cpp:237]     Train net output #1: loss = 0.143228 (* 1 = 0.143228 loss)
I0628 22:09:35.425633 17220 sgd_solver.cpp:105] Iteration 43000, lr = 0.001
I0628 22:09:39.045127 17220 solver.cpp:218] Iteration 43100 (27.6328 iter/s, 3.61889s/100 iters), loss = 0.164503
I0628 22:09:39.045127 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:09:39.045127 17220 solver.cpp:237]     Train net output #1: loss = 0.164503 (* 1 = 0.164503 loss)
I0628 22:09:39.045127 17220 sgd_solver.cpp:105] Iteration 43100, lr = 0.001
I0628 22:09:42.673709 17220 solver.cpp:218] Iteration 43200 (27.56 iter/s, 3.62844s/100 iters), loss = 0.135279
I0628 22:09:42.673709 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:09:42.674197 17220 solver.cpp:237]     Train net output #1: loss = 0.13528 (* 1 = 0.13528 loss)
I0628 22:09:42.674197 17220 sgd_solver.cpp:105] Iteration 43200, lr = 0.001
I0628 22:09:46.292819 17220 solver.cpp:218] Iteration 43300 (27.6339 iter/s, 3.61874s/100 iters), loss = 0.159266
I0628 22:09:46.293319 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:09:46.293319 17220 solver.cpp:237]     Train net output #1: loss = 0.159266 (* 1 = 0.159266 loss)
I0628 22:09:46.293319 17220 sgd_solver.cpp:105] Iteration 43300, lr = 0.001
I0628 22:09:49.910421 17220 solver.cpp:218] Iteration 43400 (27.6471 iter/s, 3.61702s/100 iters), loss = 0.0551346
I0628 22:09:49.910421 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:09:49.910421 17220 solver.cpp:237]     Train net output #1: loss = 0.0551349 (* 1 = 0.0551349 loss)
I0628 22:09:49.910421 17220 sgd_solver.cpp:105] Iteration 43400, lr = 0.001
I0628 22:09:53.349895  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:09:53.491508 17220 solver.cpp:330] Iteration 43500, Testing net (#0)
I0628 22:09:53.491508 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:09:54.313094 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:09:54.344111 17220 solver.cpp:397]     Test net output #0: accuracy = 0.89
I0628 22:09:54.344616 17220 solver.cpp:397]     Test net output #1: loss = 0.367164 (* 1 = 0.367164 loss)
I0628 22:09:54.378638 17220 solver.cpp:218] Iteration 43500 (22.382 iter/s, 4.46787s/100 iters), loss = 0.101462
I0628 22:09:54.378638 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:09:54.378638 17220 solver.cpp:237]     Train net output #1: loss = 0.101462 (* 1 = 0.101462 loss)
I0628 22:09:54.378638 17220 sgd_solver.cpp:105] Iteration 43500, lr = 0.001
I0628 22:09:57.998287 17220 solver.cpp:218] Iteration 43600 (27.6315 iter/s, 3.61905s/100 iters), loss = 0.135754
I0628 22:09:57.998287 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:09:57.998287 17220 solver.cpp:237]     Train net output #1: loss = 0.135755 (* 1 = 0.135755 loss)
I0628 22:09:57.998287 17220 sgd_solver.cpp:105] Iteration 43600, lr = 0.001
I0628 22:10:01.641973 17220 solver.cpp:218] Iteration 43700 (27.4454 iter/s, 3.6436s/100 iters), loss = 0.0930431
I0628 22:10:01.641973 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:10:01.641973 17220 solver.cpp:237]     Train net output #1: loss = 0.0930434 (* 1 = 0.0930434 loss)
I0628 22:10:01.641973 17220 sgd_solver.cpp:105] Iteration 43700, lr = 0.001
I0628 22:10:05.266084 17220 solver.cpp:218] Iteration 43800 (27.596 iter/s, 3.62372s/100 iters), loss = 0.181688
I0628 22:10:05.266084 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:10:05.266084 17220 solver.cpp:237]     Train net output #1: loss = 0.181688 (* 1 = 0.181688 loss)
I0628 22:10:05.266084 17220 sgd_solver.cpp:105] Iteration 43800, lr = 0.001
I0628 22:10:08.915122 17220 solver.cpp:218] Iteration 43900 (27.4091 iter/s, 3.64843s/100 iters), loss = 0.134162
I0628 22:10:08.915122 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:10:08.915122 17220 solver.cpp:237]     Train net output #1: loss = 0.134162 (* 1 = 0.134162 loss)
I0628 22:10:08.915122 17220 sgd_solver.cpp:105] Iteration 43900, lr = 0.001
I0628 22:10:12.386633  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:10:12.528234 17220 solver.cpp:330] Iteration 44000, Testing net (#0)
I0628 22:10:12.528234 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:10:13.349318 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:10:13.380839 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I0628 22:10:13.380839 17220 solver.cpp:397]     Test net output #1: loss = 0.366191 (* 1 = 0.366191 loss)
I0628 22:10:13.415364 17220 solver.cpp:218] Iteration 44000 (22.2227 iter/s, 4.49991s/100 iters), loss = 0.133123
I0628 22:10:13.415364 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:10:13.415364 17220 solver.cpp:237]     Train net output #1: loss = 0.133123 (* 1 = 0.133123 loss)
I0628 22:10:13.415364 17220 sgd_solver.cpp:105] Iteration 44000, lr = 0.001
I0628 22:10:17.048949 17220 solver.cpp:218] Iteration 44100 (27.5241 iter/s, 3.63317s/100 iters), loss = 0.1729
I0628 22:10:17.048949 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:10:17.048949 17220 solver.cpp:237]     Train net output #1: loss = 0.1729 (* 1 = 0.1729 loss)
I0628 22:10:17.048949 17220 sgd_solver.cpp:105] Iteration 44100, lr = 0.001
I0628 22:10:20.676684 17220 solver.cpp:218] Iteration 44200 (27.5666 iter/s, 3.62758s/100 iters), loss = 0.164637
I0628 22:10:20.676684 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:10:20.676684 17220 solver.cpp:237]     Train net output #1: loss = 0.164637 (* 1 = 0.164637 loss)
I0628 22:10:20.676684 17220 sgd_solver.cpp:105] Iteration 44200, lr = 0.001
I0628 22:10:24.278967 17220 solver.cpp:218] Iteration 44300 (27.7648 iter/s, 3.60168s/100 iters), loss = 0.158507
I0628 22:10:24.278967 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:10:24.278967 17220 solver.cpp:237]     Train net output #1: loss = 0.158508 (* 1 = 0.158508 loss)
I0628 22:10:24.278967 17220 sgd_solver.cpp:105] Iteration 44300, lr = 0.001
I0628 22:10:27.892576 17220 solver.cpp:218] Iteration 44400 (27.6775 iter/s, 3.61304s/100 iters), loss = 0.112228
I0628 22:10:27.892576 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:10:27.892576 17220 solver.cpp:237]     Train net output #1: loss = 0.112228 (* 1 = 0.112228 loss)
I0628 22:10:27.892576 17220 sgd_solver.cpp:105] Iteration 44400, lr = 0.001
I0628 22:10:31.320588  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:10:31.462190 17220 solver.cpp:330] Iteration 44500, Testing net (#0)
I0628 22:10:31.462190 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:10:32.285775 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:10:32.316298 17220 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0628 22:10:32.316298 17220 solver.cpp:397]     Test net output #1: loss = 0.372687 (* 1 = 0.372687 loss)
I0628 22:10:32.350822 17220 solver.cpp:218] Iteration 44500 (22.4315 iter/s, 4.45801s/100 iters), loss = 0.0646387
I0628 22:10:32.350822 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:10:32.350822 17220 solver.cpp:237]     Train net output #1: loss = 0.064639 (* 1 = 0.064639 loss)
I0628 22:10:32.350822 17220 sgd_solver.cpp:105] Iteration 44500, lr = 0.001
I0628 22:10:35.962522 17220 solver.cpp:218] Iteration 44600 (27.6906 iter/s, 3.61134s/100 iters), loss = 0.17286
I0628 22:10:35.962522 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:10:35.962522 17220 solver.cpp:237]     Train net output #1: loss = 0.17286 (* 1 = 0.17286 loss)
I0628 22:10:35.962522 17220 sgd_solver.cpp:105] Iteration 44600, lr = 0.001
I0628 22:10:39.554734 17220 solver.cpp:218] Iteration 44700 (27.8385 iter/s, 3.59215s/100 iters), loss = 0.160599
I0628 22:10:39.554734 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:10:39.554734 17220 solver.cpp:237]     Train net output #1: loss = 0.160599 (* 1 = 0.160599 loss)
I0628 22:10:39.554734 17220 sgd_solver.cpp:105] Iteration 44700, lr = 0.001
I0628 22:10:43.163413 17220 solver.cpp:218] Iteration 44800 (27.7157 iter/s, 3.60806s/100 iters), loss = 0.185575
I0628 22:10:43.163413 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:10:43.163413 17220 solver.cpp:237]     Train net output #1: loss = 0.185575 (* 1 = 0.185575 loss)
I0628 22:10:43.163413 17220 sgd_solver.cpp:105] Iteration 44800, lr = 0.001
I0628 22:10:46.768600 17220 solver.cpp:218] Iteration 44900 (27.7381 iter/s, 3.60515s/100 iters), loss = 0.0877017
I0628 22:10:46.769086 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:10:46.769086 17220 solver.cpp:237]     Train net output #1: loss = 0.087702 (* 1 = 0.087702 loss)
I0628 22:10:46.769086 17220 sgd_solver.cpp:105] Iteration 44900, lr = 0.001
I0628 22:10:50.213183  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:10:50.355784 17220 solver.cpp:330] Iteration 45000, Testing net (#0)
I0628 22:10:50.355784 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:10:51.177369 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:10:51.208395 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8897
I0628 22:10:51.208395 17220 solver.cpp:397]     Test net output #1: loss = 0.373032 (* 1 = 0.373032 loss)
I0628 22:10:51.242915 17220 solver.cpp:218] Iteration 45000 (22.3522 iter/s, 4.47382s/100 iters), loss = 0.0853817
I0628 22:10:51.242915 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:10:51.242915 17220 solver.cpp:237]     Train net output #1: loss = 0.085382 (* 1 = 0.085382 loss)
I0628 22:10:51.242915 17220 sgd_solver.cpp:105] Iteration 45000, lr = 0.001
I0628 22:10:54.862663 17220 solver.cpp:218] Iteration 45100 (27.629 iter/s, 3.61938s/100 iters), loss = 0.166986
I0628 22:10:54.862663 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:10:54.862663 17220 solver.cpp:237]     Train net output #1: loss = 0.166986 (* 1 = 0.166986 loss)
I0628 22:10:54.862663 17220 sgd_solver.cpp:105] Iteration 45100, lr = 0.001
I0628 22:10:58.465323 17220 solver.cpp:218] Iteration 45200 (27.7602 iter/s, 3.60227s/100 iters), loss = 0.1309
I0628 22:10:58.465323 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:10:58.465323 17220 solver.cpp:237]     Train net output #1: loss = 0.1309 (* 1 = 0.1309 loss)
I0628 22:10:58.465323 17220 sgd_solver.cpp:105] Iteration 45200, lr = 0.001
I0628 22:11:02.072474 17220 solver.cpp:218] Iteration 45300 (27.7258 iter/s, 3.60675s/100 iters), loss = 0.129782
I0628 22:11:02.072474 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:11:02.072474 17220 solver.cpp:237]     Train net output #1: loss = 0.129783 (* 1 = 0.129783 loss)
I0628 22:11:02.072474 17220 sgd_solver.cpp:105] Iteration 45300, lr = 0.001
I0628 22:11:05.673074 17220 solver.cpp:218] Iteration 45400 (27.7763 iter/s, 3.60019s/100 iters), loss = 0.0964791
I0628 22:11:05.673074 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:11:05.673074 17220 solver.cpp:237]     Train net output #1: loss = 0.0964794 (* 1 = 0.0964794 loss)
I0628 22:11:05.673074 17220 sgd_solver.cpp:105] Iteration 45400, lr = 0.001
I0628 22:11:09.109691  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:11:09.250293 17220 solver.cpp:330] Iteration 45500, Testing net (#0)
I0628 22:11:09.250792 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:11:10.071403 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:11:10.102424 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8902
I0628 22:11:10.102424 17220 solver.cpp:397]     Test net output #1: loss = 0.376965 (* 1 = 0.376965 loss)
I0628 22:11:10.136459 17220 solver.cpp:218] Iteration 45500 (22.4051 iter/s, 4.46328s/100 iters), loss = 0.130232
I0628 22:11:10.136950 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:11:10.136950 17220 solver.cpp:237]     Train net output #1: loss = 0.130233 (* 1 = 0.130233 loss)
I0628 22:11:10.136950 17220 sgd_solver.cpp:105] Iteration 45500, lr = 0.001
I0628 22:11:13.740854 17220 solver.cpp:218] Iteration 45600 (27.7472 iter/s, 3.60396s/100 iters), loss = 0.16225
I0628 22:11:13.740854 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:11:13.741354 17220 solver.cpp:237]     Train net output #1: loss = 0.16225 (* 1 = 0.16225 loss)
I0628 22:11:13.741354 17220 sgd_solver.cpp:105] Iteration 45600, lr = 0.001
I0628 22:11:17.342059 17220 solver.cpp:218] Iteration 45700 (27.7731 iter/s, 3.6006s/100 iters), loss = 0.162366
I0628 22:11:17.342059 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:11:17.342059 17220 solver.cpp:237]     Train net output #1: loss = 0.162367 (* 1 = 0.162367 loss)
I0628 22:11:17.342059 17220 sgd_solver.cpp:105] Iteration 45700, lr = 0.001
I0628 22:11:20.953655 17220 solver.cpp:218] Iteration 45800 (27.6906 iter/s, 3.61134s/100 iters), loss = 0.176827
I0628 22:11:20.953655 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 22:11:20.953655 17220 solver.cpp:237]     Train net output #1: loss = 0.176827 (* 1 = 0.176827 loss)
I0628 22:11:20.953655 17220 sgd_solver.cpp:105] Iteration 45800, lr = 0.001
I0628 22:11:24.557718 17220 solver.cpp:218] Iteration 45900 (27.7475 iter/s, 3.60393s/100 iters), loss = 0.144847
I0628 22:11:24.558218 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:11:24.558218 17220 solver.cpp:237]     Train net output #1: loss = 0.144847 (* 1 = 0.144847 loss)
I0628 22:11:24.558218 17220 sgd_solver.cpp:105] Iteration 45900, lr = 0.001
I0628 22:11:27.995081  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:11:28.136682 17220 solver.cpp:330] Iteration 46000, Testing net (#0)
I0628 22:11:28.136682 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:11:28.957765 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:11:28.989289 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8877
I0628 22:11:28.989289 17220 solver.cpp:397]     Test net output #1: loss = 0.373962 (* 1 = 0.373962 loss)
I0628 22:11:29.023313 17220 solver.cpp:218] Iteration 46000 (22.3965 iter/s, 4.46498s/100 iters), loss = 0.118365
I0628 22:11:29.023313 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:11:29.023313 17220 solver.cpp:237]     Train net output #1: loss = 0.118365 (* 1 = 0.118365 loss)
I0628 22:11:29.023313 17220 sgd_solver.cpp:105] Iteration 46000, lr = 0.001
I0628 22:11:32.654422 17220 solver.cpp:218] Iteration 46100 (27.5431 iter/s, 3.63067s/100 iters), loss = 0.15737
I0628 22:11:32.654422 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:11:32.654422 17220 solver.cpp:237]     Train net output #1: loss = 0.15737 (* 1 = 0.15737 loss)
I0628 22:11:32.654422 17220 sgd_solver.cpp:105] Iteration 46100, lr = 0.001
I0628 22:11:36.289010 17220 solver.cpp:218] Iteration 46200 (27.5137 iter/s, 3.63455s/100 iters), loss = 0.108502
I0628 22:11:36.289010 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:11:36.289010 17220 solver.cpp:237]     Train net output #1: loss = 0.108502 (* 1 = 0.108502 loss)
I0628 22:11:36.289010 17220 sgd_solver.cpp:105] Iteration 46200, lr = 0.001
I0628 22:11:39.929098 17220 solver.cpp:218] Iteration 46300 (27.477 iter/s, 3.63941s/100 iters), loss = 0.162207
I0628 22:11:39.929098 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:11:39.929098 17220 solver.cpp:237]     Train net output #1: loss = 0.162207 (* 1 = 0.162207 loss)
I0628 22:11:39.929098 17220 sgd_solver.cpp:105] Iteration 46300, lr = 0.001
I0628 22:11:43.563057 17220 solver.cpp:218] Iteration 46400 (27.5186 iter/s, 3.63391s/100 iters), loss = 0.0830459
I0628 22:11:43.563057 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:11:43.563057 17220 solver.cpp:237]     Train net output #1: loss = 0.0830463 (* 1 = 0.0830463 loss)
I0628 22:11:43.563057 17220 sgd_solver.cpp:105] Iteration 46400, lr = 0.001
I0628 22:11:47.067919  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:11:47.210019 17220 solver.cpp:330] Iteration 46500, Testing net (#0)
I0628 22:11:47.210019 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:11:48.051630 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:11:48.084141 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8895
I0628 22:11:48.084141 17220 solver.cpp:397]     Test net output #1: loss = 0.376416 (* 1 = 0.376416 loss)
I0628 22:11:48.120167 17220 solver.cpp:218] Iteration 46500 (21.9468 iter/s, 4.55647s/100 iters), loss = 0.115334
I0628 22:11:48.120167 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:11:48.120167 17220 solver.cpp:237]     Train net output #1: loss = 0.115334 (* 1 = 0.115334 loss)
I0628 22:11:48.120167 17220 sgd_solver.cpp:105] Iteration 46500, lr = 0.001
I0628 22:11:51.791829 17220 solver.cpp:218] Iteration 46600 (27.2386 iter/s, 3.67126s/100 iters), loss = 0.178019
I0628 22:11:51.791829 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:11:51.791829 17220 solver.cpp:237]     Train net output #1: loss = 0.178019 (* 1 = 0.178019 loss)
I0628 22:11:51.791829 17220 sgd_solver.cpp:105] Iteration 46600, lr = 0.001
I0628 22:11:55.438112 17220 solver.cpp:218] Iteration 46700 (27.4268 iter/s, 3.64606s/100 iters), loss = 0.145708
I0628 22:11:55.438112 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:11:55.438112 17220 solver.cpp:237]     Train net output #1: loss = 0.145708 (* 1 = 0.145708 loss)
I0628 22:11:55.438112 17220 sgd_solver.cpp:105] Iteration 46700, lr = 0.001
I0628 22:11:59.067195 17220 solver.cpp:218] Iteration 46800 (27.561 iter/s, 3.62831s/100 iters), loss = 0.118971
I0628 22:11:59.067195 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:11:59.067195 17220 solver.cpp:237]     Train net output #1: loss = 0.118971 (* 1 = 0.118971 loss)
I0628 22:11:59.067195 17220 sgd_solver.cpp:105] Iteration 46800, lr = 0.001
I0628 22:12:02.786355 17220 solver.cpp:218] Iteration 46900 (26.8908 iter/s, 3.71874s/100 iters), loss = 0.0879013
I0628 22:12:02.786355 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:12:02.786355 17220 solver.cpp:237]     Train net output #1: loss = 0.0879017 (* 1 = 0.0879017 loss)
I0628 22:12:02.786355 17220 sgd_solver.cpp:105] Iteration 46900, lr = 0.001
I0628 22:12:06.232877  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:12:06.372977 17220 solver.cpp:330] Iteration 47000, Testing net (#0)
I0628 22:12:06.372977 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:12:07.196024 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:12:07.227039 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8898
I0628 22:12:07.227039 17220 solver.cpp:397]     Test net output #1: loss = 0.374248 (* 1 = 0.374248 loss)
I0628 22:12:07.260560 17220 solver.cpp:218] Iteration 47000 (22.3504 iter/s, 4.47419s/100 iters), loss = 0.103748
I0628 22:12:07.260560 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:12:07.260560 17220 solver.cpp:237]     Train net output #1: loss = 0.103749 (* 1 = 0.103749 loss)
I0628 22:12:07.260560 17220 sgd_solver.cpp:105] Iteration 47000, lr = 0.001
I0628 22:12:10.908671 17220 solver.cpp:218] Iteration 47100 (27.4153 iter/s, 3.6476s/100 iters), loss = 0.17546
I0628 22:12:10.908671 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:12:10.908671 17220 solver.cpp:237]     Train net output #1: loss = 0.17546 (* 1 = 0.17546 loss)
I0628 22:12:10.908671 17220 sgd_solver.cpp:105] Iteration 47100, lr = 0.001
I0628 22:12:14.602797 17220 solver.cpp:218] Iteration 47200 (27.0714 iter/s, 3.69394s/100 iters), loss = 0.0715505
I0628 22:12:14.602797 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:12:14.603296 17220 solver.cpp:237]     Train net output #1: loss = 0.0715509 (* 1 = 0.0715509 loss)
I0628 22:12:14.603296 17220 sgd_solver.cpp:105] Iteration 47200, lr = 0.001
I0628 22:12:18.248512 17220 solver.cpp:218] Iteration 47300 (27.4327 iter/s, 3.64528s/100 iters), loss = 0.144025
I0628 22:12:18.248512 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:12:18.248512 17220 solver.cpp:237]     Train net output #1: loss = 0.144025 (* 1 = 0.144025 loss)
I0628 22:12:18.248512 17220 sgd_solver.cpp:105] Iteration 47300, lr = 0.001
I0628 22:12:21.857681 17220 solver.cpp:218] Iteration 47400 (27.7088 iter/s, 3.60896s/100 iters), loss = 0.0916795
I0628 22:12:21.857681 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:12:21.858182 17220 solver.cpp:237]     Train net output #1: loss = 0.0916799 (* 1 = 0.0916799 loss)
I0628 22:12:21.858182 17220 sgd_solver.cpp:105] Iteration 47400, lr = 0.001
I0628 22:12:25.305635  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:12:25.447736 17220 solver.cpp:330] Iteration 47500, Testing net (#0)
I0628 22:12:25.447736 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:12:26.269820 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:12:26.300341 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8919
I0628 22:12:26.300341 17220 solver.cpp:397]     Test net output #1: loss = 0.375117 (* 1 = 0.375117 loss)
I0628 22:12:26.334867 17220 solver.cpp:218] Iteration 47500 (22.3383 iter/s, 4.47662s/100 iters), loss = 0.114145
I0628 22:12:26.334867 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:12:26.334867 17220 solver.cpp:237]     Train net output #1: loss = 0.114145 (* 1 = 0.114145 loss)
I0628 22:12:26.334867 17220 sgd_solver.cpp:105] Iteration 47500, lr = 0.001
I0628 22:12:29.940750 17220 solver.cpp:218] Iteration 47600 (27.7349 iter/s, 3.60557s/100 iters), loss = 0.131056
I0628 22:12:29.940750 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:12:29.940750 17220 solver.cpp:237]     Train net output #1: loss = 0.131057 (* 1 = 0.131057 loss)
I0628 22:12:29.940750 17220 sgd_solver.cpp:105] Iteration 47600, lr = 0.001
I0628 22:12:33.544342 17220 solver.cpp:218] Iteration 47700 (27.7516 iter/s, 3.60339s/100 iters), loss = 0.126817
I0628 22:12:33.544842 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:12:33.544842 17220 solver.cpp:237]     Train net output #1: loss = 0.126818 (* 1 = 0.126818 loss)
I0628 22:12:33.544842 17220 sgd_solver.cpp:105] Iteration 47700, lr = 0.001
I0628 22:12:37.179263 17220 solver.cpp:218] Iteration 47800 (27.5166 iter/s, 3.63417s/100 iters), loss = 0.198342
I0628 22:12:37.179263 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:12:37.179263 17220 solver.cpp:237]     Train net output #1: loss = 0.198342 (* 1 = 0.198342 loss)
I0628 22:12:37.179263 17220 sgd_solver.cpp:105] Iteration 47800, lr = 0.001
I0628 22:12:40.940826 17220 solver.cpp:218] Iteration 47900 (26.5871 iter/s, 3.76122s/100 iters), loss = 0.120013
I0628 22:12:40.940826 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:12:40.940826 17220 solver.cpp:237]     Train net output #1: loss = 0.120014 (* 1 = 0.120014 loss)
I0628 22:12:40.940826 17220 sgd_solver.cpp:105] Iteration 47900, lr = 0.001
I0628 22:12:44.456773  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:12:44.600666 17220 solver.cpp:330] Iteration 48000, Testing net (#0)
I0628 22:12:44.600666 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:12:45.425768 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:12:45.456790 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8901
I0628 22:12:45.456790 17220 solver.cpp:397]     Test net output #1: loss = 0.377856 (* 1 = 0.377856 loss)
I0628 22:12:45.491801 17220 solver.cpp:218] Iteration 48000 (21.9753 iter/s, 4.55056s/100 iters), loss = 0.119827
I0628 22:12:45.491801 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:12:45.491801 17220 solver.cpp:237]     Train net output #1: loss = 0.119827 (* 1 = 0.119827 loss)
I0628 22:12:45.491801 17220 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0628 22:12:45.491801 17220 sgd_solver.cpp:105] Iteration 48000, lr = 0.0001
I0628 22:12:49.127446 17220 solver.cpp:218] Iteration 48100 (27.5084 iter/s, 3.63525s/100 iters), loss = 0.125572
I0628 22:12:49.127446 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:12:49.127446 17220 solver.cpp:237]     Train net output #1: loss = 0.125573 (* 1 = 0.125573 loss)
I0628 22:12:49.127446 17220 sgd_solver.cpp:105] Iteration 48100, lr = 0.0001
I0628 22:12:52.754662 17220 solver.cpp:218] Iteration 48200 (27.5712 iter/s, 3.62698s/100 iters), loss = 0.110128
I0628 22:12:52.754662 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:12:52.754662 17220 solver.cpp:237]     Train net output #1: loss = 0.110128 (* 1 = 0.110128 loss)
I0628 22:12:52.754662 17220 sgd_solver.cpp:105] Iteration 48200, lr = 0.0001
I0628 22:12:56.417647 17220 solver.cpp:218] Iteration 48300 (27.3044 iter/s, 3.66241s/100 iters), loss = 0.154387
I0628 22:12:56.417647 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:12:56.417647 17220 solver.cpp:237]     Train net output #1: loss = 0.154388 (* 1 = 0.154388 loss)
I0628 22:12:56.417647 17220 sgd_solver.cpp:105] Iteration 48300, lr = 0.0001
I0628 22:13:00.036038 17220 solver.cpp:218] Iteration 48400 (27.6362 iter/s, 3.61844s/100 iters), loss = 0.0886074
I0628 22:13:00.036538 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:13:00.036538 17220 solver.cpp:237]     Train net output #1: loss = 0.0886079 (* 1 = 0.0886079 loss)
I0628 22:13:00.036538 17220 sgd_solver.cpp:105] Iteration 48400, lr = 0.0001
I0628 22:13:03.479132  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:13:03.620234 17220 solver.cpp:330] Iteration 48500, Testing net (#0)
I0628 22:13:03.620234 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:13:04.447372 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:13:04.478381 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I0628 22:13:04.478381 17220 solver.cpp:397]     Test net output #1: loss = 0.370514 (* 1 = 0.370514 loss)
I0628 22:13:04.512414 17220 solver.cpp:218] Iteration 48500 (22.3431 iter/s, 4.47565s/100 iters), loss = 0.126893
I0628 22:13:04.512414 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:13:04.512414 17220 solver.cpp:237]     Train net output #1: loss = 0.126893 (* 1 = 0.126893 loss)
I0628 22:13:04.512414 17220 sgd_solver.cpp:105] Iteration 48500, lr = 0.0001
I0628 22:13:08.163158 17220 solver.cpp:218] Iteration 48600 (27.3917 iter/s, 3.65074s/100 iters), loss = 0.146101
I0628 22:13:08.163658 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:13:08.163658 17220 solver.cpp:237]     Train net output #1: loss = 0.146102 (* 1 = 0.146102 loss)
I0628 22:13:08.163658 17220 sgd_solver.cpp:105] Iteration 48600, lr = 0.0001
I0628 22:13:11.819259 17220 solver.cpp:218] Iteration 48700 (27.356 iter/s, 3.65551s/100 iters), loss = 0.178633
I0628 22:13:11.819259 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:13:11.819259 17220 solver.cpp:237]     Train net output #1: loss = 0.178634 (* 1 = 0.178634 loss)
I0628 22:13:11.819259 17220 sgd_solver.cpp:105] Iteration 48700, lr = 0.0001
I0628 22:13:15.446998 17220 solver.cpp:218] Iteration 48800 (27.5666 iter/s, 3.62758s/100 iters), loss = 0.107978
I0628 22:13:15.446998 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:13:15.446998 17220 solver.cpp:237]     Train net output #1: loss = 0.107979 (* 1 = 0.107979 loss)
I0628 22:13:15.446998 17220 sgd_solver.cpp:105] Iteration 48800, lr = 0.0001
I0628 22:13:19.050583 17220 solver.cpp:218] Iteration 48900 (27.7561 iter/s, 3.60281s/100 iters), loss = 0.0531169
I0628 22:13:19.050583 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:13:19.050583 17220 solver.cpp:237]     Train net output #1: loss = 0.0531174 (* 1 = 0.0531174 loss)
I0628 22:13:19.050583 17220 sgd_solver.cpp:105] Iteration 48900, lr = 0.0001
I0628 22:13:22.483304  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:13:22.624905 17220 solver.cpp:330] Iteration 49000, Testing net (#0)
I0628 22:13:22.624905 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:13:23.447489 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:13:23.478515 17220 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0628 22:13:23.478515 17220 solver.cpp:397]     Test net output #1: loss = 0.370529 (* 1 = 0.370529 loss)
I0628 22:13:23.512537 17220 solver.cpp:218] Iteration 49000 (22.411 iter/s, 4.46209s/100 iters), loss = 0.1254
I0628 22:13:23.513037 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:13:23.513037 17220 solver.cpp:237]     Train net output #1: loss = 0.125401 (* 1 = 0.125401 loss)
I0628 22:13:23.513037 17220 sgd_solver.cpp:105] Iteration 49000, lr = 0.0001
I0628 22:13:27.136219 17220 solver.cpp:218] Iteration 49100 (27.6004 iter/s, 3.62314s/100 iters), loss = 0.150205
I0628 22:13:27.136219 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:13:27.136219 17220 solver.cpp:237]     Train net output #1: loss = 0.150206 (* 1 = 0.150206 loss)
I0628 22:13:27.136219 17220 sgd_solver.cpp:105] Iteration 49100, lr = 0.0001
I0628 22:13:30.736526 17220 solver.cpp:218] Iteration 49200 (27.7795 iter/s, 3.59977s/100 iters), loss = 0.147616
I0628 22:13:30.736526 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:13:30.736526 17220 solver.cpp:237]     Train net output #1: loss = 0.147617 (* 1 = 0.147617 loss)
I0628 22:13:30.736526 17220 sgd_solver.cpp:105] Iteration 49200, lr = 0.0001
I0628 22:13:34.333118 17220 solver.cpp:218] Iteration 49300 (27.8058 iter/s, 3.59637s/100 iters), loss = 0.0845076
I0628 22:13:34.333118 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:13:34.333118 17220 solver.cpp:237]     Train net output #1: loss = 0.0845082 (* 1 = 0.0845082 loss)
I0628 22:13:34.333118 17220 sgd_solver.cpp:105] Iteration 49300, lr = 0.0001
I0628 22:13:37.932723 17220 solver.cpp:218] Iteration 49400 (27.7817 iter/s, 3.59949s/100 iters), loss = 0.0788259
I0628 22:13:37.933223 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:13:37.933223 17220 solver.cpp:237]     Train net output #1: loss = 0.0788265 (* 1 = 0.0788265 loss)
I0628 22:13:37.933223 17220 sgd_solver.cpp:105] Iteration 49400, lr = 0.0001
I0628 22:13:41.355211  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:13:41.497813 17220 solver.cpp:330] Iteration 49500, Testing net (#0)
I0628 22:13:41.497813 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:13:42.318397 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:13:42.349419 17220 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0628 22:13:42.349419 17220 solver.cpp:397]     Test net output #1: loss = 0.371 (* 1 = 0.371 loss)
I0628 22:13:42.383443 17220 solver.cpp:218] Iteration 49500 (22.4711 iter/s, 4.45017s/100 iters), loss = 0.1335
I0628 22:13:42.383443 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:13:42.383443 17220 solver.cpp:237]     Train net output #1: loss = 0.1335 (* 1 = 0.1335 loss)
I0628 22:13:42.383443 17220 sgd_solver.cpp:105] Iteration 49500, lr = 0.0001
I0628 22:13:45.990600 17220 solver.cpp:218] Iteration 49600 (27.7251 iter/s, 3.60684s/100 iters), loss = 0.185041
I0628 22:13:45.990600 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:13:45.990600 17220 solver.cpp:237]     Train net output #1: loss = 0.185041 (* 1 = 0.185041 loss)
I0628 22:13:45.990600 17220 sgd_solver.cpp:105] Iteration 49600, lr = 0.0001
I0628 22:13:49.596664 17220 solver.cpp:218] Iteration 49700 (27.7353 iter/s, 3.60551s/100 iters), loss = 0.166713
I0628 22:13:49.596664 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:13:49.596664 17220 solver.cpp:237]     Train net output #1: loss = 0.166714 (* 1 = 0.166714 loss)
I0628 22:13:49.596664 17220 sgd_solver.cpp:105] Iteration 49700, lr = 0.0001
I0628 22:13:53.223269 17220 solver.cpp:218] Iteration 49800 (27.575 iter/s, 3.62648s/100 iters), loss = 0.119115
I0628 22:13:53.223269 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:13:53.223269 17220 solver.cpp:237]     Train net output #1: loss = 0.119116 (* 1 = 0.119116 loss)
I0628 22:13:53.223269 17220 sgd_solver.cpp:105] Iteration 49800, lr = 0.0001
I0628 22:13:56.859272 17220 solver.cpp:218] Iteration 49900 (27.5063 iter/s, 3.63553s/100 iters), loss = 0.096522
I0628 22:13:56.859272 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:13:56.859272 17220 solver.cpp:237]     Train net output #1: loss = 0.0965227 (* 1 = 0.0965227 loss)
I0628 22:13:56.859272 17220 sgd_solver.cpp:105] Iteration 49900, lr = 0.0001
I0628 22:14:00.316763  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:14:00.459378 17220 solver.cpp:330] Iteration 50000, Testing net (#0)
I0628 22:14:00.459378 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:14:01.281951 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:14:01.314471 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8931
I0628 22:14:01.314471 17220 solver.cpp:397]     Test net output #1: loss = 0.370467 (* 1 = 0.370467 loss)
I0628 22:14:01.349508 17220 solver.cpp:218] Iteration 50000 (22.272 iter/s, 4.48995s/100 iters), loss = 0.106024
I0628 22:14:01.349508 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:14:01.349508 17220 solver.cpp:237]     Train net output #1: loss = 0.106024 (* 1 = 0.106024 loss)
I0628 22:14:01.349508 17220 sgd_solver.cpp:105] Iteration 50000, lr = 0.0001
I0628 22:14:05.005229 17220 solver.cpp:218] Iteration 50100 (27.3556 iter/s, 3.65556s/100 iters), loss = 0.134862
I0628 22:14:05.005731 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:14:05.005731 17220 solver.cpp:237]     Train net output #1: loss = 0.134862 (* 1 = 0.134862 loss)
I0628 22:14:05.005731 17220 sgd_solver.cpp:105] Iteration 50100, lr = 0.0001
I0628 22:14:08.671836 17220 solver.cpp:218] Iteration 50200 (27.2756 iter/s, 3.66628s/100 iters), loss = 0.122121
I0628 22:14:08.672343 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:14:08.672343 17220 solver.cpp:237]     Train net output #1: loss = 0.122121 (* 1 = 0.122121 loss)
I0628 22:14:08.672343 17220 sgd_solver.cpp:105] Iteration 50200, lr = 0.0001
I0628 22:14:12.344444 17220 solver.cpp:218] Iteration 50300 (27.2352 iter/s, 3.67172s/100 iters), loss = 0.102496
I0628 22:14:12.344444 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:14:12.344444 17220 solver.cpp:237]     Train net output #1: loss = 0.102497 (* 1 = 0.102497 loss)
I0628 22:14:12.344444 17220 sgd_solver.cpp:105] Iteration 50300, lr = 0.0001
I0628 22:14:16.008083 17220 solver.cpp:218] Iteration 50400 (27.2951 iter/s, 3.66366s/100 iters), loss = 0.073568
I0628 22:14:16.008584 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:14:16.008584 17220 solver.cpp:237]     Train net output #1: loss = 0.0735686 (* 1 = 0.0735686 loss)
I0628 22:14:16.008584 17220 sgd_solver.cpp:105] Iteration 50400, lr = 0.0001
I0628 22:14:19.524225  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:14:19.666826 17220 solver.cpp:330] Iteration 50500, Testing net (#0)
I0628 22:14:19.666826 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:14:20.488427 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:14:20.518934 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8934
I0628 22:14:20.518934 17220 solver.cpp:397]     Test net output #1: loss = 0.370249 (* 1 = 0.370249 loss)
I0628 22:14:20.552958 17220 solver.cpp:218] Iteration 50500 (22.0061 iter/s, 4.5442s/100 iters), loss = 0.0983654
I0628 22:14:20.552958 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:14:20.552958 17220 solver.cpp:237]     Train net output #1: loss = 0.098366 (* 1 = 0.098366 loss)
I0628 22:14:20.552958 17220 sgd_solver.cpp:105] Iteration 50500, lr = 0.0001
I0628 22:14:24.147516 17220 solver.cpp:218] Iteration 50600 (27.821 iter/s, 3.59441s/100 iters), loss = 0.120089
I0628 22:14:24.147516 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:14:24.147516 17220 solver.cpp:237]     Train net output #1: loss = 0.120089 (* 1 = 0.120089 loss)
I0628 22:14:24.147516 17220 sgd_solver.cpp:105] Iteration 50600, lr = 0.0001
I0628 22:14:27.789611 17220 solver.cpp:218] Iteration 50700 (27.4587 iter/s, 3.64183s/100 iters), loss = 0.130907
I0628 22:14:27.789611 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:14:27.789611 17220 solver.cpp:237]     Train net output #1: loss = 0.130907 (* 1 = 0.130907 loss)
I0628 22:14:27.789611 17220 sgd_solver.cpp:105] Iteration 50700, lr = 0.0001
I0628 22:14:31.434722 17220 solver.cpp:218] Iteration 50800 (27.437 iter/s, 3.64471s/100 iters), loss = 0.13414
I0628 22:14:31.434722 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:14:31.434722 17220 solver.cpp:237]     Train net output #1: loss = 0.134141 (* 1 = 0.134141 loss)
I0628 22:14:31.434722 17220 sgd_solver.cpp:105] Iteration 50800, lr = 0.0001
I0628 22:14:35.078547 17220 solver.cpp:218] Iteration 50900 (27.449 iter/s, 3.64312s/100 iters), loss = 0.0971076
I0628 22:14:35.078547 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:14:35.078547 17220 solver.cpp:237]     Train net output #1: loss = 0.0971082 (* 1 = 0.0971082 loss)
I0628 22:14:35.078547 17220 sgd_solver.cpp:105] Iteration 50900, lr = 0.0001
I0628 22:14:38.525064  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:14:38.667665 17220 solver.cpp:330] Iteration 51000, Testing net (#0)
I0628 22:14:38.667665 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:14:39.490802 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:14:39.521824 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8921
I0628 22:14:39.521824 17220 solver.cpp:397]     Test net output #1: loss = 0.369993 (* 1 = 0.369993 loss)
I0628 22:14:39.555857 17220 solver.cpp:218] Iteration 51000 (22.3359 iter/s, 4.47709s/100 iters), loss = 0.0966107
I0628 22:14:39.555857 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:14:39.555857 17220 solver.cpp:237]     Train net output #1: loss = 0.0966113 (* 1 = 0.0966113 loss)
I0628 22:14:39.555857 17220 sgd_solver.cpp:105] Iteration 51000, lr = 0.0001
I0628 22:14:43.156554 17220 solver.cpp:218] Iteration 51100 (27.7774 iter/s, 3.60005s/100 iters), loss = 0.202909
I0628 22:14:43.156554 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:14:43.156554 17220 solver.cpp:237]     Train net output #1: loss = 0.202909 (* 1 = 0.202909 loss)
I0628 22:14:43.156554 17220 sgd_solver.cpp:105] Iteration 51100, lr = 0.0001
I0628 22:14:46.768664 17220 solver.cpp:218] Iteration 51200 (27.6862 iter/s, 3.6119s/100 iters), loss = 0.156557
I0628 22:14:46.768664 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:14:46.768664 17220 solver.cpp:237]     Train net output #1: loss = 0.156558 (* 1 = 0.156558 loss)
I0628 22:14:46.768664 17220 sgd_solver.cpp:105] Iteration 51200, lr = 0.0001
I0628 22:14:50.394186 17220 solver.cpp:218] Iteration 51300 (27.5863 iter/s, 3.62499s/100 iters), loss = 0.114459
I0628 22:14:50.394186 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:14:50.394186 17220 solver.cpp:237]     Train net output #1: loss = 0.114459 (* 1 = 0.114459 loss)
I0628 22:14:50.394186 17220 sgd_solver.cpp:105] Iteration 51300, lr = 0.0001
I0628 22:14:54.045707 17220 solver.cpp:218] Iteration 51400 (27.3858 iter/s, 3.65153s/100 iters), loss = 0.111674
I0628 22:14:54.046208 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:14:54.046208 17220 solver.cpp:237]     Train net output #1: loss = 0.111675 (* 1 = 0.111675 loss)
I0628 22:14:54.046208 17220 sgd_solver.cpp:105] Iteration 51400, lr = 0.0001
I0628 22:14:57.501166  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:14:57.643267 17220 solver.cpp:330] Iteration 51500, Testing net (#0)
I0628 22:14:57.643267 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:14:58.464851 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:14:58.495873 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8924
I0628 22:14:58.495873 17220 solver.cpp:397]     Test net output #1: loss = 0.370592 (* 1 = 0.370592 loss)
I0628 22:14:58.530398 17220 solver.cpp:218] Iteration 51500 (22.3005 iter/s, 4.4842s/100 iters), loss = 0.119948
I0628 22:14:58.530398 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:14:58.530398 17220 solver.cpp:237]     Train net output #1: loss = 0.119948 (* 1 = 0.119948 loss)
I0628 22:14:58.530398 17220 sgd_solver.cpp:105] Iteration 51500, lr = 0.0001
I0628 22:15:02.162482 17220 solver.cpp:218] Iteration 51600 (27.5366 iter/s, 3.63154s/100 iters), loss = 0.182341
I0628 22:15:02.162482 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:15:02.162482 17220 solver.cpp:237]     Train net output #1: loss = 0.182342 (* 1 = 0.182342 loss)
I0628 22:15:02.162482 17220 sgd_solver.cpp:105] Iteration 51600, lr = 0.0001
I0628 22:15:05.815081 17220 solver.cpp:218] Iteration 51700 (27.3806 iter/s, 3.65223s/100 iters), loss = 0.121943
I0628 22:15:05.815081 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:15:05.815081 17220 solver.cpp:237]     Train net output #1: loss = 0.121944 (* 1 = 0.121944 loss)
I0628 22:15:05.815081 17220 sgd_solver.cpp:105] Iteration 51700, lr = 0.0001
I0628 22:15:09.457706 17220 solver.cpp:218] Iteration 51800 (27.457 iter/s, 3.64206s/100 iters), loss = 0.114666
I0628 22:15:09.457706 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:15:09.457706 17220 solver.cpp:237]     Train net output #1: loss = 0.114666 (* 1 = 0.114666 loss)
I0628 22:15:09.457706 17220 sgd_solver.cpp:105] Iteration 51800, lr = 0.0001
I0628 22:15:13.089282 17220 solver.cpp:218] Iteration 51900 (27.5365 iter/s, 3.63155s/100 iters), loss = 0.101787
I0628 22:15:13.089282 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:15:13.089282 17220 solver.cpp:237]     Train net output #1: loss = 0.101788 (* 1 = 0.101788 loss)
I0628 22:15:13.089282 17220 sgd_solver.cpp:105] Iteration 51900, lr = 0.0001
I0628 22:15:16.531731  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:15:16.673832 17220 solver.cpp:330] Iteration 52000, Testing net (#0)
I0628 22:15:16.674338 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:15:17.502923 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:15:17.533944 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8931
I0628 22:15:17.533944 17220 solver.cpp:397]     Test net output #1: loss = 0.370368 (* 1 = 0.370368 loss)
I0628 22:15:17.568469 17220 solver.cpp:218] Iteration 52000 (22.3285 iter/s, 4.47858s/100 iters), loss = 0.0912758
I0628 22:15:17.568469 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:15:17.568469 17220 solver.cpp:237]     Train net output #1: loss = 0.0912765 (* 1 = 0.0912765 loss)
I0628 22:15:17.568469 17220 sgd_solver.cpp:105] Iteration 52000, lr = 0.0001
I0628 22:15:21.195549 17220 solver.cpp:218] Iteration 52100 (27.5731 iter/s, 3.62673s/100 iters), loss = 0.123024
I0628 22:15:21.195549 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:15:21.195549 17220 solver.cpp:237]     Train net output #1: loss = 0.123024 (* 1 = 0.123024 loss)
I0628 22:15:21.195549 17220 sgd_solver.cpp:105] Iteration 52100, lr = 0.0001
I0628 22:15:24.831032 17220 solver.cpp:218] Iteration 52200 (27.5064 iter/s, 3.63551s/100 iters), loss = 0.113158
I0628 22:15:24.831032 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:15:24.831532 17220 solver.cpp:237]     Train net output #1: loss = 0.113158 (* 1 = 0.113158 loss)
I0628 22:15:24.831532 17220 sgd_solver.cpp:105] Iteration 52200, lr = 0.0001
I0628 22:15:28.452196 17220 solver.cpp:218] Iteration 52300 (27.6185 iter/s, 3.62077s/100 iters), loss = 0.167334
I0628 22:15:28.452196 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:15:28.452196 17220 solver.cpp:237]     Train net output #1: loss = 0.167335 (* 1 = 0.167335 loss)
I0628 22:15:28.452196 17220 sgd_solver.cpp:105] Iteration 52300, lr = 0.0001
I0628 22:15:32.053788 17220 solver.cpp:218] Iteration 52400 (27.7704 iter/s, 3.60096s/100 iters), loss = 0.100376
I0628 22:15:32.053788 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:15:32.053788 17220 solver.cpp:237]     Train net output #1: loss = 0.100377 (* 1 = 0.100377 loss)
I0628 22:15:32.053788 17220 sgd_solver.cpp:105] Iteration 52400, lr = 0.0001
I0628 22:15:35.498298  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:15:35.639396 17220 solver.cpp:330] Iteration 52500, Testing net (#0)
I0628 22:15:35.639896 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:15:36.469471 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:15:36.500519 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0628 22:15:36.500519 17220 solver.cpp:397]     Test net output #1: loss = 0.370276 (* 1 = 0.370276 loss)
I0628 22:15:36.534535 17220 solver.cpp:218] Iteration 52500 (22.3183 iter/s, 4.48063s/100 iters), loss = 0.0591394
I0628 22:15:36.534535 17220 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0628 22:15:36.534535 17220 solver.cpp:237]     Train net output #1: loss = 0.0591401 (* 1 = 0.0591401 loss)
I0628 22:15:36.534535 17220 sgd_solver.cpp:105] Iteration 52500, lr = 0.0001
I0628 22:15:40.165628 17220 solver.cpp:218] Iteration 52600 (27.5426 iter/s, 3.63074s/100 iters), loss = 0.122478
I0628 22:15:40.165628 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:15:40.165628 17220 solver.cpp:237]     Train net output #1: loss = 0.122479 (* 1 = 0.122479 loss)
I0628 22:15:40.165628 17220 sgd_solver.cpp:105] Iteration 52600, lr = 0.0001
I0628 22:15:43.809245 17220 solver.cpp:218] Iteration 52700 (27.4506 iter/s, 3.64291s/100 iters), loss = 0.0862785
I0628 22:15:43.809245 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:15:43.809245 17220 solver.cpp:237]     Train net output #1: loss = 0.0862792 (* 1 = 0.0862792 loss)
I0628 22:15:43.809245 17220 sgd_solver.cpp:105] Iteration 52700, lr = 0.0001
I0628 22:15:47.450767 17220 solver.cpp:218] Iteration 52800 (27.461 iter/s, 3.64153s/100 iters), loss = 0.126605
I0628 22:15:47.450767 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:15:47.450767 17220 solver.cpp:237]     Train net output #1: loss = 0.126605 (* 1 = 0.126605 loss)
I0628 22:15:47.450767 17220 sgd_solver.cpp:105] Iteration 52800, lr = 0.0001
I0628 22:15:51.080114 17220 solver.cpp:218] Iteration 52900 (27.5554 iter/s, 3.62905s/100 iters), loss = 0.121024
I0628 22:15:51.080615 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:15:51.080615 17220 solver.cpp:237]     Train net output #1: loss = 0.121025 (* 1 = 0.121025 loss)
I0628 22:15:51.080615 17220 sgd_solver.cpp:105] Iteration 52900, lr = 0.0001
I0628 22:15:54.511613  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:15:54.651212 17220 solver.cpp:330] Iteration 53000, Testing net (#0)
I0628 22:15:54.651212 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:15:55.475798 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:15:55.506320 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0628 22:15:55.506320 17220 solver.cpp:397]     Test net output #1: loss = 0.371548 (* 1 = 0.371548 loss)
I0628 22:15:55.540345 17220 solver.cpp:218] Iteration 53000 (22.4238 iter/s, 4.45954s/100 iters), loss = 0.0870877
I0628 22:15:55.540345 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:15:55.540345 17220 solver.cpp:237]     Train net output #1: loss = 0.0870884 (* 1 = 0.0870884 loss)
I0628 22:15:55.540345 17220 sgd_solver.cpp:105] Iteration 53000, lr = 0.0001
I0628 22:15:59.159410 17220 solver.cpp:218] Iteration 53100 (27.6342 iter/s, 3.6187s/100 iters), loss = 0.0995304
I0628 22:15:59.159410 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:15:59.159410 17220 solver.cpp:237]     Train net output #1: loss = 0.0995312 (* 1 = 0.0995312 loss)
I0628 22:15:59.159410 17220 sgd_solver.cpp:105] Iteration 53100, lr = 0.0001
I0628 22:16:02.763949 17220 solver.cpp:218] Iteration 53200 (27.7439 iter/s, 3.6044s/100 iters), loss = 0.146441
I0628 22:16:02.763949 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:16:02.763949 17220 solver.cpp:237]     Train net output #1: loss = 0.146442 (* 1 = 0.146442 loss)
I0628 22:16:02.763949 17220 sgd_solver.cpp:105] Iteration 53200, lr = 0.0001
I0628 22:16:06.383093 17220 solver.cpp:218] Iteration 53300 (27.6353 iter/s, 3.61857s/100 iters), loss = 0.090292
I0628 22:16:06.383093 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:16:06.383093 17220 solver.cpp:237]     Train net output #1: loss = 0.0902927 (* 1 = 0.0902927 loss)
I0628 22:16:06.383093 17220 sgd_solver.cpp:105] Iteration 53300, lr = 0.0001
I0628 22:16:10.005295 17220 solver.cpp:218] Iteration 53400 (27.6092 iter/s, 3.62198s/100 iters), loss = 0.104626
I0628 22:16:10.005295 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:16:10.005295 17220 solver.cpp:237]     Train net output #1: loss = 0.104627 (* 1 = 0.104627 loss)
I0628 22:16:10.005295 17220 sgd_solver.cpp:105] Iteration 53400, lr = 0.0001
I0628 22:16:13.470793  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:16:13.611910 17220 solver.cpp:330] Iteration 53500, Testing net (#0)
I0628 22:16:13.611910 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:16:14.432492 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:16:14.463510 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0628 22:16:14.463510 17220 solver.cpp:397]     Test net output #1: loss = 0.37192 (* 1 = 0.37192 loss)
I0628 22:16:14.498023 17220 solver.cpp:218] Iteration 53500 (22.2607 iter/s, 4.49223s/100 iters), loss = 0.0760208
I0628 22:16:14.498023 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:16:14.498023 17220 solver.cpp:237]     Train net output #1: loss = 0.0760215 (* 1 = 0.0760215 loss)
I0628 22:16:14.498023 17220 sgd_solver.cpp:105] Iteration 53500, lr = 0.0001
I0628 22:16:18.134618 17220 solver.cpp:218] Iteration 53600 (27.5017 iter/s, 3.63614s/100 iters), loss = 0.212043
I0628 22:16:18.134618 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:16:18.134618 17220 solver.cpp:237]     Train net output #1: loss = 0.212044 (* 1 = 0.212044 loss)
I0628 22:16:18.134618 17220 sgd_solver.cpp:105] Iteration 53600, lr = 0.0001
I0628 22:16:21.768707 17220 solver.cpp:218] Iteration 53700 (27.5178 iter/s, 3.63402s/100 iters), loss = 0.0987072
I0628 22:16:21.768707 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:16:21.768707 17220 solver.cpp:237]     Train net output #1: loss = 0.098708 (* 1 = 0.098708 loss)
I0628 22:16:21.769197 17220 sgd_solver.cpp:105] Iteration 53700, lr = 0.0001
I0628 22:16:25.389850 17220 solver.cpp:218] Iteration 53800 (27.6193 iter/s, 3.62065s/100 iters), loss = 0.122117
I0628 22:16:25.389850 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:16:25.389850 17220 solver.cpp:237]     Train net output #1: loss = 0.122118 (* 1 = 0.122118 loss)
I0628 22:16:25.389850 17220 sgd_solver.cpp:105] Iteration 53800, lr = 0.0001
I0628 22:16:29.014434 17220 solver.cpp:218] Iteration 53900 (27.5908 iter/s, 3.6244s/100 iters), loss = 0.0648057
I0628 22:16:29.014943 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:16:29.014943 17220 solver.cpp:237]     Train net output #1: loss = 0.0648065 (* 1 = 0.0648065 loss)
I0628 22:16:29.014943 17220 sgd_solver.cpp:105] Iteration 53900, lr = 0.0001
I0628 22:16:32.460887  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:16:32.605991 17220 solver.cpp:330] Iteration 54000, Testing net (#0)
I0628 22:16:32.605991 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:16:33.430577 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:16:33.461599 17220 solver.cpp:397]     Test net output #0: accuracy = 0.893199
I0628 22:16:33.461599 17220 solver.cpp:397]     Test net output #1: loss = 0.372095 (* 1 = 0.372095 loss)
I0628 22:16:33.496124 17220 solver.cpp:218] Iteration 54000 (22.3165 iter/s, 4.48099s/100 iters), loss = 0.0937276
I0628 22:16:33.496124 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:16:33.496124 17220 solver.cpp:237]     Train net output #1: loss = 0.0937284 (* 1 = 0.0937284 loss)
I0628 22:16:33.496124 17220 sgd_solver.cpp:46] MultiStep Status: Iteration 54000, step = 3
I0628 22:16:33.496124 17220 sgd_solver.cpp:105] Iteration 54000, lr = 1e-05
I0628 22:16:37.119201 17220 solver.cpp:218] Iteration 54100 (27.6012 iter/s, 3.62303s/100 iters), loss = 0.164979
I0628 22:16:37.119701 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:16:37.119701 17220 solver.cpp:237]     Train net output #1: loss = 0.16498 (* 1 = 0.16498 loss)
I0628 22:16:37.119701 17220 sgd_solver.cpp:105] Iteration 54100, lr = 1e-05
I0628 22:16:40.741278 17220 solver.cpp:218] Iteration 54200 (27.614 iter/s, 3.62135s/100 iters), loss = 0.115305
I0628 22:16:40.741278 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:16:40.741278 17220 solver.cpp:237]     Train net output #1: loss = 0.115305 (* 1 = 0.115305 loss)
I0628 22:16:40.741278 17220 sgd_solver.cpp:105] Iteration 54200, lr = 1e-05
I0628 22:16:44.369870 17220 solver.cpp:218] Iteration 54300 (27.5611 iter/s, 3.6283s/100 iters), loss = 0.140797
I0628 22:16:44.369870 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:16:44.369870 17220 solver.cpp:237]     Train net output #1: loss = 0.140798 (* 1 = 0.140798 loss)
I0628 22:16:44.369870 17220 sgd_solver.cpp:105] Iteration 54300, lr = 1e-05
I0628 22:16:47.997440 17220 solver.cpp:218] Iteration 54400 (27.5683 iter/s, 3.62735s/100 iters), loss = 0.0828476
I0628 22:16:47.997440 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:16:47.997440 17220 solver.cpp:237]     Train net output #1: loss = 0.0828484 (* 1 = 0.0828484 loss)
I0628 22:16:47.997440 17220 sgd_solver.cpp:105] Iteration 54400, lr = 1e-05
I0628 22:16:51.458904  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:16:51.601505 17220 solver.cpp:330] Iteration 54500, Testing net (#0)
I0628 22:16:51.601505 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:16:52.424590 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:16:52.455621 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8935
I0628 22:16:52.455621 17220 solver.cpp:397]     Test net output #1: loss = 0.372723 (* 1 = 0.372723 loss)
I0628 22:16:52.490137 17220 solver.cpp:218] Iteration 54500 (22.2614 iter/s, 4.49208s/100 iters), loss = 0.0761921
I0628 22:16:52.490137 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:16:52.490137 17220 solver.cpp:237]     Train net output #1: loss = 0.0761929 (* 1 = 0.0761929 loss)
I0628 22:16:52.490137 17220 sgd_solver.cpp:105] Iteration 54500, lr = 1e-05
I0628 22:16:56.131728 17220 solver.cpp:218] Iteration 54600 (27.4616 iter/s, 3.64145s/100 iters), loss = 0.134512
I0628 22:16:56.131728 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:16:56.131728 17220 solver.cpp:237]     Train net output #1: loss = 0.134513 (* 1 = 0.134513 loss)
I0628 22:16:56.131728 17220 sgd_solver.cpp:105] Iteration 54600, lr = 1e-05
I0628 22:16:59.761310 17220 solver.cpp:218] Iteration 54700 (27.5542 iter/s, 3.62921s/100 iters), loss = 0.212141
I0628 22:16:59.761310 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:16:59.761310 17220 solver.cpp:237]     Train net output #1: loss = 0.212142 (* 1 = 0.212142 loss)
I0628 22:16:59.761310 17220 sgd_solver.cpp:105] Iteration 54700, lr = 1e-05
I0628 22:17:03.384888 17220 solver.cpp:218] Iteration 54800 (27.6014 iter/s, 3.623s/100 iters), loss = 0.104359
I0628 22:17:03.384888 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:17:03.384888 17220 solver.cpp:237]     Train net output #1: loss = 0.10436 (* 1 = 0.10436 loss)
I0628 22:17:03.384888 17220 sgd_solver.cpp:105] Iteration 54800, lr = 1e-05
I0628 22:17:07.026351 17220 solver.cpp:218] Iteration 54900 (27.4636 iter/s, 3.64118s/100 iters), loss = 0.046422
I0628 22:17:07.026351 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:17:07.026351 17220 solver.cpp:237]     Train net output #1: loss = 0.0464227 (* 1 = 0.0464227 loss)
I0628 22:17:07.026351 17220 sgd_solver.cpp:105] Iteration 54900, lr = 1e-05
I0628 22:17:10.479308  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:17:10.620909 17220 solver.cpp:330] Iteration 55000, Testing net (#0)
I0628 22:17:10.620909 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:17:11.441493 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:17:11.472514 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8934
I0628 22:17:11.472514 17220 solver.cpp:397]     Test net output #1: loss = 0.371455 (* 1 = 0.371455 loss)
I0628 22:17:11.506538 17220 solver.cpp:218] Iteration 55000 (22.3215 iter/s, 4.47999s/100 iters), loss = 0.106285
I0628 22:17:11.506538 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:17:11.506538 17220 solver.cpp:237]     Train net output #1: loss = 0.106285 (* 1 = 0.106285 loss)
I0628 22:17:11.506538 17220 sgd_solver.cpp:105] Iteration 55000, lr = 1e-05
I0628 22:17:15.131618 17220 solver.cpp:218] Iteration 55100 (27.5874 iter/s, 3.62484s/100 iters), loss = 0.186144
I0628 22:17:15.131618 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:17:15.132118 17220 solver.cpp:237]     Train net output #1: loss = 0.186144 (* 1 = 0.186144 loss)
I0628 22:17:15.132118 17220 sgd_solver.cpp:105] Iteration 55100, lr = 1e-05
I0628 22:17:18.757197 17220 solver.cpp:218] Iteration 55200 (27.5848 iter/s, 3.62518s/100 iters), loss = 0.120598
I0628 22:17:18.757197 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:17:18.757197 17220 solver.cpp:237]     Train net output #1: loss = 0.120598 (* 1 = 0.120598 loss)
I0628 22:17:18.757197 17220 sgd_solver.cpp:105] Iteration 55200, lr = 1e-05
I0628 22:17:22.392784 17220 solver.cpp:218] Iteration 55300 (27.5091 iter/s, 3.63516s/100 iters), loss = 0.0805976
I0628 22:17:22.392784 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:17:22.392784 17220 solver.cpp:237]     Train net output #1: loss = 0.0805984 (* 1 = 0.0805984 loss)
I0628 22:17:22.392784 17220 sgd_solver.cpp:105] Iteration 55300, lr = 1e-05
I0628 22:17:26.017854 17220 solver.cpp:218] Iteration 55400 (27.5882 iter/s, 3.62474s/100 iters), loss = 0.126693
I0628 22:17:26.017854 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:17:26.017854 17220 solver.cpp:237]     Train net output #1: loss = 0.126693 (* 1 = 0.126693 loss)
I0628 22:17:26.017854 17220 sgd_solver.cpp:105] Iteration 55400, lr = 1e-05
I0628 22:17:29.453824  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:17:29.594425 17220 solver.cpp:330] Iteration 55500, Testing net (#0)
I0628 22:17:29.594425 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:17:30.416508 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:17:30.447031 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8936
I0628 22:17:30.447031 17220 solver.cpp:397]     Test net output #1: loss = 0.371423 (* 1 = 0.371423 loss)
I0628 22:17:30.481555 17220 solver.cpp:218] Iteration 55500 (22.4043 iter/s, 4.46342s/100 iters), loss = 0.0600506
I0628 22:17:30.481555 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:17:30.481555 17220 solver.cpp:237]     Train net output #1: loss = 0.0600514 (* 1 = 0.0600514 loss)
I0628 22:17:30.481555 17220 sgd_solver.cpp:105] Iteration 55500, lr = 1e-05
I0628 22:17:34.083698 17220 solver.cpp:218] Iteration 55600 (27.7675 iter/s, 3.60134s/100 iters), loss = 0.125347
I0628 22:17:34.083698 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:17:34.083698 17220 solver.cpp:237]     Train net output #1: loss = 0.125348 (* 1 = 0.125348 loss)
I0628 22:17:34.083698 17220 sgd_solver.cpp:105] Iteration 55600, lr = 1e-05
I0628 22:17:37.695688 17220 solver.cpp:218] Iteration 55700 (27.6852 iter/s, 3.61203s/100 iters), loss = 0.112977
I0628 22:17:37.695688 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:17:37.695688 17220 solver.cpp:237]     Train net output #1: loss = 0.112978 (* 1 = 0.112978 loss)
I0628 22:17:37.695688 17220 sgd_solver.cpp:105] Iteration 55700, lr = 1e-05
I0628 22:17:41.293843 17220 solver.cpp:218] Iteration 55800 (27.7956 iter/s, 3.5977s/100 iters), loss = 0.161042
I0628 22:17:41.293843 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:17:41.293843 17220 solver.cpp:237]     Train net output #1: loss = 0.161043 (* 1 = 0.161043 loss)
I0628 22:17:41.293843 17220 sgd_solver.cpp:105] Iteration 55800, lr = 1e-05
I0628 22:17:44.903959 17220 solver.cpp:218] Iteration 55900 (27.7047 iter/s, 3.60949s/100 iters), loss = 0.0776202
I0628 22:17:44.903959 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:17:44.903959 17220 solver.cpp:237]     Train net output #1: loss = 0.077621 (* 1 = 0.077621 loss)
I0628 22:17:44.903959 17220 sgd_solver.cpp:105] Iteration 55900, lr = 1e-05
I0628 22:17:48.352447  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:17:48.495048 17220 solver.cpp:330] Iteration 56000, Testing net (#0)
I0628 22:17:48.495048 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:17:49.321149 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:17:49.352157 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0628 22:17:49.352157 17220 solver.cpp:397]     Test net output #1: loss = 0.371298 (* 1 = 0.371298 loss)
I0628 22:17:49.387193 17220 solver.cpp:218] Iteration 56000 (22.3071 iter/s, 4.48287s/100 iters), loss = 0.0666662
I0628 22:17:49.387193 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:17:49.387193 17220 solver.cpp:237]     Train net output #1: loss = 0.066667 (* 1 = 0.066667 loss)
I0628 22:17:49.387193 17220 sgd_solver.cpp:105] Iteration 56000, lr = 1e-05
I0628 22:17:53.001268 17220 solver.cpp:218] Iteration 56100 (27.6717 iter/s, 3.61379s/100 iters), loss = 0.180115
I0628 22:17:53.001778 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:17:53.001778 17220 solver.cpp:237]     Train net output #1: loss = 0.180115 (* 1 = 0.180115 loss)
I0628 22:17:53.001778 17220 sgd_solver.cpp:105] Iteration 56100, lr = 1e-05
I0628 22:17:56.628931 17220 solver.cpp:218] Iteration 56200 (27.5728 iter/s, 3.62676s/100 iters), loss = 0.153112
I0628 22:17:56.628931 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:17:56.628931 17220 solver.cpp:237]     Train net output #1: loss = 0.153113 (* 1 = 0.153113 loss)
I0628 22:17:56.628931 17220 sgd_solver.cpp:105] Iteration 56200, lr = 1e-05
I0628 22:18:00.260143 17220 solver.cpp:218] Iteration 56300 (27.5392 iter/s, 3.63119s/100 iters), loss = 0.104758
I0628 22:18:00.260143 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:18:00.260143 17220 solver.cpp:237]     Train net output #1: loss = 0.104759 (* 1 = 0.104759 loss)
I0628 22:18:00.260143 17220 sgd_solver.cpp:105] Iteration 56300, lr = 1e-05
I0628 22:18:03.890727 17220 solver.cpp:218] Iteration 56400 (27.5462 iter/s, 3.63027s/100 iters), loss = 0.130378
I0628 22:18:03.890727 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:18:03.890727 17220 solver.cpp:237]     Train net output #1: loss = 0.130378 (* 1 = 0.130378 loss)
I0628 22:18:03.890727 17220 sgd_solver.cpp:105] Iteration 56400, lr = 1e-05
I0628 22:18:07.353893  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:18:07.495995 17220 solver.cpp:330] Iteration 56500, Testing net (#0)
I0628 22:18:07.495995 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:18:08.316578 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:18:08.347600 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0628 22:18:08.347600 17220 solver.cpp:397]     Test net output #1: loss = 0.371264 (* 1 = 0.371264 loss)
I0628 22:18:08.382625 17220 solver.cpp:218] Iteration 56500 (22.2653 iter/s, 4.49129s/100 iters), loss = 0.113273
I0628 22:18:08.382625 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:18:08.382625 17220 solver.cpp:237]     Train net output #1: loss = 0.113274 (* 1 = 0.113274 loss)
I0628 22:18:08.382625 17220 sgd_solver.cpp:105] Iteration 56500, lr = 1e-05
I0628 22:18:12.012250 17220 solver.cpp:218] Iteration 56600 (27.5523 iter/s, 3.62947s/100 iters), loss = 0.111813
I0628 22:18:12.012250 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:18:12.012250 17220 solver.cpp:237]     Train net output #1: loss = 0.111814 (* 1 = 0.111814 loss)
I0628 22:18:12.012250 17220 sgd_solver.cpp:105] Iteration 56600, lr = 1e-05
I0628 22:18:15.646270 17220 solver.cpp:218] Iteration 56700 (27.5205 iter/s, 3.63365s/100 iters), loss = 0.117469
I0628 22:18:15.646270 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:18:15.646270 17220 solver.cpp:237]     Train net output #1: loss = 0.11747 (* 1 = 0.11747 loss)
I0628 22:18:15.646270 17220 sgd_solver.cpp:105] Iteration 56700, lr = 1e-05
I0628 22:18:19.268836 17220 solver.cpp:218] Iteration 56800 (27.6084 iter/s, 3.62208s/100 iters), loss = 0.116361
I0628 22:18:19.268836 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:18:19.268836 17220 solver.cpp:237]     Train net output #1: loss = 0.116362 (* 1 = 0.116362 loss)
I0628 22:18:19.268836 17220 sgd_solver.cpp:105] Iteration 56800, lr = 1e-05
I0628 22:18:22.906893 17220 solver.cpp:218] Iteration 56900 (27.4888 iter/s, 3.63784s/100 iters), loss = 0.0606124
I0628 22:18:22.906893 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:18:22.906893 17220 solver.cpp:237]     Train net output #1: loss = 0.0606132 (* 1 = 0.0606132 loss)
I0628 22:18:22.906893 17220 sgd_solver.cpp:105] Iteration 56900, lr = 1e-05
I0628 22:18:26.442409  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:18:26.588512 17220 solver.cpp:330] Iteration 57000, Testing net (#0)
I0628 22:18:26.588512 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:18:27.477645 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:18:27.509670 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8936
I0628 22:18:27.509670 17220 solver.cpp:397]     Test net output #1: loss = 0.371059 (* 1 = 0.371059 loss)
I0628 22:18:27.548696 17220 solver.cpp:218] Iteration 57000 (21.5456 iter/s, 4.64131s/100 iters), loss = 0.0984094
I0628 22:18:27.548696 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:18:27.548696 17220 solver.cpp:237]     Train net output #1: loss = 0.0984103 (* 1 = 0.0984103 loss)
I0628 22:18:27.548696 17220 sgd_solver.cpp:105] Iteration 57000, lr = 1e-05
I0628 22:18:31.272845 17220 solver.cpp:218] Iteration 57100 (26.8563 iter/s, 3.72353s/100 iters), loss = 0.139395
I0628 22:18:31.272845 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:18:31.272845 17220 solver.cpp:237]     Train net output #1: loss = 0.139396 (* 1 = 0.139396 loss)
I0628 22:18:31.272845 17220 sgd_solver.cpp:105] Iteration 57100, lr = 1e-05
I0628 22:18:34.934450 17220 solver.cpp:218] Iteration 57200 (27.3112 iter/s, 3.66151s/100 iters), loss = 0.137738
I0628 22:18:34.934450 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:18:34.934450 17220 solver.cpp:237]     Train net output #1: loss = 0.137739 (* 1 = 0.137739 loss)
I0628 22:18:34.934450 17220 sgd_solver.cpp:105] Iteration 57200, lr = 1e-05
I0628 22:18:38.676656 17220 solver.cpp:218] Iteration 57300 (26.726 iter/s, 3.74168s/100 iters), loss = 0.0860128
I0628 22:18:38.676656 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:18:38.676656 17220 solver.cpp:237]     Train net output #1: loss = 0.0860136 (* 1 = 0.0860136 loss)
I0628 22:18:38.676656 17220 sgd_solver.cpp:105] Iteration 57300, lr = 1e-05
I0628 22:18:42.393164 17220 solver.cpp:218] Iteration 57400 (26.9115 iter/s, 3.71589s/100 iters), loss = 0.086131
I0628 22:18:42.393164 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:18:42.393164 17220 solver.cpp:237]     Train net output #1: loss = 0.0861319 (* 1 = 0.0861319 loss)
I0628 22:18:42.393164 17220 sgd_solver.cpp:105] Iteration 57400, lr = 1e-05
I0628 22:18:45.829674  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:18:45.969774 17220 solver.cpp:330] Iteration 57500, Testing net (#0)
I0628 22:18:45.969774 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:18:46.790855 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:18:46.822379 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8937
I0628 22:18:46.822379 17220 solver.cpp:397]     Test net output #1: loss = 0.371564 (* 1 = 0.371564 loss)
I0628 22:18:46.856403 17220 solver.cpp:218] Iteration 57500 (22.4051 iter/s, 4.46327s/100 iters), loss = 0.0959075
I0628 22:18:46.856902 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:18:46.856902 17220 solver.cpp:237]     Train net output #1: loss = 0.0959084 (* 1 = 0.0959084 loss)
I0628 22:18:46.856902 17220 sgd_solver.cpp:105] Iteration 57500, lr = 1e-05
I0628 22:18:50.505058 17220 solver.cpp:218] Iteration 57600 (27.4119 iter/s, 3.64805s/100 iters), loss = 0.167611
I0628 22:18:50.505058 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:18:50.505058 17220 solver.cpp:237]     Train net output #1: loss = 0.167612 (* 1 = 0.167612 loss)
I0628 22:18:50.505058 17220 sgd_solver.cpp:105] Iteration 57600, lr = 1e-05
I0628 22:18:54.170176 17220 solver.cpp:218] Iteration 57700 (27.2872 iter/s, 3.66472s/100 iters), loss = 0.0994989
I0628 22:18:54.170176 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:18:54.170176 17220 solver.cpp:237]     Train net output #1: loss = 0.0994998 (* 1 = 0.0994998 loss)
I0628 22:18:54.170176 17220 sgd_solver.cpp:105] Iteration 57700, lr = 1e-05
I0628 22:18:57.830363 17220 solver.cpp:218] Iteration 57800 (27.3247 iter/s, 3.65969s/100 iters), loss = 0.12971
I0628 22:18:57.830363 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:18:57.830363 17220 solver.cpp:237]     Train net output #1: loss = 0.12971 (* 1 = 0.12971 loss)
I0628 22:18:57.830363 17220 sgd_solver.cpp:105] Iteration 57800, lr = 1e-05
I0628 22:19:01.579059 17220 solver.cpp:218] Iteration 57900 (26.6762 iter/s, 3.74865s/100 iters), loss = 0.100076
I0628 22:19:01.579059 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:19:01.579059 17220 solver.cpp:237]     Train net output #1: loss = 0.100077 (* 1 = 0.100077 loss)
I0628 22:19:01.579059 17220 sgd_solver.cpp:105] Iteration 57900, lr = 1e-05
I0628 22:19:05.043386  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:19:05.183986 17220 solver.cpp:330] Iteration 58000, Testing net (#0)
I0628 22:19:05.183986 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:19:06.002568 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:19:06.033089 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8943
I0628 22:19:06.033089 17220 solver.cpp:397]     Test net output #1: loss = 0.371358 (* 1 = 0.371358 loss)
I0628 22:19:06.067615 17220 solver.cpp:218] Iteration 58000 (22.281 iter/s, 4.48814s/100 iters), loss = 0.116728
I0628 22:19:06.067615 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:19:06.067615 17220 solver.cpp:237]     Train net output #1: loss = 0.116728 (* 1 = 0.116728 loss)
I0628 22:19:06.067615 17220 sgd_solver.cpp:105] Iteration 58000, lr = 1e-05
I0628 22:19:09.686189 17220 solver.cpp:218] Iteration 58100 (27.6379 iter/s, 3.61822s/100 iters), loss = 0.117336
I0628 22:19:09.686189 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:19:09.686189 17220 solver.cpp:237]     Train net output #1: loss = 0.117337 (* 1 = 0.117337 loss)
I0628 22:19:09.686189 17220 sgd_solver.cpp:105] Iteration 58100, lr = 1e-05
I0628 22:19:13.297273 17220 solver.cpp:218] Iteration 58200 (27.6958 iter/s, 3.61065s/100 iters), loss = 0.0939537
I0628 22:19:13.297273 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:19:13.297273 17220 solver.cpp:237]     Train net output #1: loss = 0.0939545 (* 1 = 0.0939545 loss)
I0628 22:19:13.297273 17220 sgd_solver.cpp:105] Iteration 58200, lr = 1e-05
I0628 22:19:16.914098 17220 solver.cpp:218] Iteration 58300 (27.6508 iter/s, 3.61654s/100 iters), loss = 0.0907379
I0628 22:19:16.914598 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:19:16.914598 17220 solver.cpp:237]     Train net output #1: loss = 0.0907388 (* 1 = 0.0907388 loss)
I0628 22:19:16.914598 17220 sgd_solver.cpp:105] Iteration 58300, lr = 1e-05
I0628 22:19:20.616289 17220 solver.cpp:218] Iteration 58400 (27.0149 iter/s, 3.70166s/100 iters), loss = 0.137232
I0628 22:19:20.616289 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:19:20.616289 17220 solver.cpp:237]     Train net output #1: loss = 0.137233 (* 1 = 0.137233 loss)
I0628 22:19:20.616289 17220 sgd_solver.cpp:105] Iteration 58400, lr = 1e-05
I0628 22:19:24.155241  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:19:24.301345 17220 solver.cpp:330] Iteration 58500, Testing net (#0)
I0628 22:19:24.301345 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:19:25.132448 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:19:25.163470 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8937
I0628 22:19:25.163967 17220 solver.cpp:397]     Test net output #1: loss = 0.37174 (* 1 = 0.37174 loss)
I0628 22:19:25.198983 17220 solver.cpp:218] Iteration 58500 (21.8245 iter/s, 4.58201s/100 iters), loss = 0.0694626
I0628 22:19:25.198983 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:19:25.198983 17220 solver.cpp:237]     Train net output #1: loss = 0.0694635 (* 1 = 0.0694635 loss)
I0628 22:19:25.198983 17220 sgd_solver.cpp:105] Iteration 58500, lr = 1e-05
I0628 22:19:28.858597 17220 solver.cpp:218] Iteration 58600 (27.3256 iter/s, 3.65957s/100 iters), loss = 0.140596
I0628 22:19:28.858597 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:19:28.859097 17220 solver.cpp:237]     Train net output #1: loss = 0.140597 (* 1 = 0.140597 loss)
I0628 22:19:28.859097 17220 sgd_solver.cpp:105] Iteration 58600, lr = 1e-05
I0628 22:19:32.510263 17220 solver.cpp:218] Iteration 58700 (27.3896 iter/s, 3.65102s/100 iters), loss = 0.142231
I0628 22:19:32.510263 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:19:32.510263 17220 solver.cpp:237]     Train net output #1: loss = 0.142232 (* 1 = 0.142232 loss)
I0628 22:19:32.510263 17220 sgd_solver.cpp:105] Iteration 58700, lr = 1e-05
I0628 22:19:36.151981 17220 solver.cpp:218] Iteration 58800 (27.4621 iter/s, 3.64138s/100 iters), loss = 0.111572
I0628 22:19:36.151981 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:19:36.151981 17220 solver.cpp:237]     Train net output #1: loss = 0.111573 (* 1 = 0.111573 loss)
I0628 22:19:36.151981 17220 sgd_solver.cpp:105] Iteration 58800, lr = 1e-05
I0628 22:19:39.782078 17220 solver.cpp:218] Iteration 58900 (27.5494 iter/s, 3.62984s/100 iters), loss = 0.0824675
I0628 22:19:39.782078 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:19:39.782078 17220 solver.cpp:237]     Train net output #1: loss = 0.0824683 (* 1 = 0.0824683 loss)
I0628 22:19:39.782078 17220 sgd_solver.cpp:105] Iteration 58900, lr = 1e-05
I0628 22:19:43.346948  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:19:43.488050 17220 solver.cpp:330] Iteration 59000, Testing net (#0)
I0628 22:19:43.488050 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:19:44.308634 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:19:44.339655 17220 solver.cpp:397]     Test net output #0: accuracy = 0.894
I0628 22:19:44.339655 17220 solver.cpp:397]     Test net output #1: loss = 0.371081 (* 1 = 0.371081 loss)
I0628 22:19:44.374183 17220 solver.cpp:218] Iteration 59000 (21.7785 iter/s, 4.59169s/100 iters), loss = 0.112618
I0628 22:19:44.374183 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:19:44.374183 17220 solver.cpp:237]     Train net output #1: loss = 0.112619 (* 1 = 0.112619 loss)
I0628 22:19:44.374183 17220 sgd_solver.cpp:105] Iteration 59000, lr = 1e-05
I0628 22:19:48.040793 17220 solver.cpp:218] Iteration 59100 (27.2778 iter/s, 3.66599s/100 iters), loss = 0.166682
I0628 22:19:48.040793 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:19:48.040793 17220 solver.cpp:237]     Train net output #1: loss = 0.166683 (* 1 = 0.166683 loss)
I0628 22:19:48.040793 17220 sgd_solver.cpp:105] Iteration 59100, lr = 1e-05
I0628 22:19:51.689427 17220 solver.cpp:218] Iteration 59200 (27.4078 iter/s, 3.64859s/100 iters), loss = 0.169153
I0628 22:19:51.689929 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:19:51.689929 17220 solver.cpp:237]     Train net output #1: loss = 0.169154 (* 1 = 0.169154 loss)
I0628 22:19:51.689929 17220 sgd_solver.cpp:105] Iteration 59200, lr = 1e-05
I0628 22:19:55.362577 17220 solver.cpp:218] Iteration 59300 (27.2285 iter/s, 3.67263s/100 iters), loss = 0.0836734
I0628 22:19:55.362577 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:19:55.362577 17220 solver.cpp:237]     Train net output #1: loss = 0.0836742 (* 1 = 0.0836742 loss)
I0628 22:19:55.362577 17220 sgd_solver.cpp:105] Iteration 59300, lr = 1e-05
I0628 22:19:58.983259 17220 solver.cpp:218] Iteration 59400 (27.6243 iter/s, 3.62s/100 iters), loss = 0.0462963
I0628 22:19:58.983259 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:19:58.983259 17220 solver.cpp:237]     Train net output #1: loss = 0.0462971 (* 1 = 0.0462971 loss)
I0628 22:19:58.983259 17220 sgd_solver.cpp:105] Iteration 59400, lr = 1e-05
I0628 22:20:02.471319  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:20:02.619426 17220 solver.cpp:330] Iteration 59500, Testing net (#0)
I0628 22:20:02.619426 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:20:03.444512 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:20:03.475534 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0628 22:20:03.475534 17220 solver.cpp:397]     Test net output #1: loss = 0.371165 (* 1 = 0.371165 loss)
I0628 22:20:03.510058 17220 solver.cpp:218] Iteration 59500 (22.0916 iter/s, 4.5266s/100 iters), loss = 0.0742043
I0628 22:20:03.510058 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:20:03.510058 17220 solver.cpp:237]     Train net output #1: loss = 0.0742051 (* 1 = 0.0742051 loss)
I0628 22:20:03.510058 17220 sgd_solver.cpp:105] Iteration 59500, lr = 1e-05
I0628 22:20:07.153515 17220 solver.cpp:218] Iteration 59600 (27.4501 iter/s, 3.64298s/100 iters), loss = 0.110968
I0628 22:20:07.153515 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:20:07.153515 17220 solver.cpp:237]     Train net output #1: loss = 0.110968 (* 1 = 0.110968 loss)
I0628 22:20:07.153515 17220 sgd_solver.cpp:105] Iteration 59600, lr = 1e-05
I0628 22:20:10.775151 17220 solver.cpp:218] Iteration 59700 (27.6122 iter/s, 3.62159s/100 iters), loss = 0.152972
I0628 22:20:10.775151 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:20:10.775151 17220 solver.cpp:237]     Train net output #1: loss = 0.152973 (* 1 = 0.152973 loss)
I0628 22:20:10.775151 17220 sgd_solver.cpp:105] Iteration 59700, lr = 1e-05
I0628 22:20:14.402837 17220 solver.cpp:218] Iteration 59800 (27.57 iter/s, 3.62713s/100 iters), loss = 0.15325
I0628 22:20:14.402837 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:20:14.402837 17220 solver.cpp:237]     Train net output #1: loss = 0.15325 (* 1 = 0.15325 loss)
I0628 22:20:14.402837 17220 sgd_solver.cpp:105] Iteration 59800, lr = 1e-05
I0628 22:20:18.085783 17220 solver.cpp:218] Iteration 59900 (27.1527 iter/s, 3.68288s/100 iters), loss = 0.0998702
I0628 22:20:18.086283 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:20:18.086283 17220 solver.cpp:237]     Train net output #1: loss = 0.0998711 (* 1 = 0.0998711 loss)
I0628 22:20:18.086283 17220 sgd_solver.cpp:105] Iteration 59900, lr = 1e-05
I0628 22:20:21.638176  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:20:21.779778 17220 solver.cpp:330] Iteration 60000, Testing net (#0)
I0628 22:20:21.779778 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:20:22.601861 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:20:22.633385 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8935
I0628 22:20:22.633385 17220 solver.cpp:397]     Test net output #1: loss = 0.371564 (* 1 = 0.371564 loss)
I0628 22:20:22.667408 17220 solver.cpp:218] Iteration 60000 (21.8296 iter/s, 4.58095s/100 iters), loss = 0.0846329
I0628 22:20:22.667408 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:20:22.667408 17220 solver.cpp:237]     Train net output #1: loss = 0.0846337 (* 1 = 0.0846337 loss)
I0628 22:20:22.667408 17220 sgd_solver.cpp:105] Iteration 60000, lr = 1e-05
I0628 22:20:26.300493 17220 solver.cpp:218] Iteration 60100 (27.527 iter/s, 3.6328s/100 iters), loss = 0.167383
I0628 22:20:26.300493 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:20:26.300493 17220 solver.cpp:237]     Train net output #1: loss = 0.167383 (* 1 = 0.167383 loss)
I0628 22:20:26.300493 17220 sgd_solver.cpp:105] Iteration 60100, lr = 1e-05
I0628 22:20:30.161052 17220 solver.cpp:218] Iteration 60200 (25.9044 iter/s, 3.86035s/100 iters), loss = 0.123614
I0628 22:20:30.161052 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:20:30.161052 17220 solver.cpp:237]     Train net output #1: loss = 0.123614 (* 1 = 0.123614 loss)
I0628 22:20:30.161052 17220 sgd_solver.cpp:105] Iteration 60200, lr = 1e-05
I0628 22:20:33.896219 17220 solver.cpp:218] Iteration 60300 (26.7751 iter/s, 3.73482s/100 iters), loss = 0.11303
I0628 22:20:33.896219 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:20:33.896720 17220 solver.cpp:237]     Train net output #1: loss = 0.113031 (* 1 = 0.113031 loss)
I0628 22:20:33.896720 17220 sgd_solver.cpp:105] Iteration 60300, lr = 1e-05
I0628 22:20:37.622112 17220 solver.cpp:218] Iteration 60400 (26.8442 iter/s, 3.7252s/100 iters), loss = 0.083625
I0628 22:20:37.622112 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:20:37.622112 17220 solver.cpp:237]     Train net output #1: loss = 0.0836258 (* 1 = 0.0836258 loss)
I0628 22:20:37.622112 17220 sgd_solver.cpp:105] Iteration 60400, lr = 1e-05
I0628 22:20:41.186755  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:20:41.327837 17220 solver.cpp:330] Iteration 60500, Testing net (#0)
I0628 22:20:41.327837 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:20:42.161340 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:20:42.192863 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8937
I0628 22:20:42.192863 17220 solver.cpp:397]     Test net output #1: loss = 0.370994 (* 1 = 0.370994 loss)
I0628 22:20:42.227387 17220 solver.cpp:218] Iteration 60500 (21.7167 iter/s, 4.60475s/100 iters), loss = 0.114224
I0628 22:20:42.227387 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:20:42.227387 17220 solver.cpp:237]     Train net output #1: loss = 0.114225 (* 1 = 0.114225 loss)
I0628 22:20:42.227387 17220 sgd_solver.cpp:105] Iteration 60500, lr = 1e-05
I0628 22:20:45.944057 17220 solver.cpp:218] Iteration 60600 (26.9088 iter/s, 3.71625s/100 iters), loss = 0.189166
I0628 22:20:45.944057 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:20:45.944057 17220 solver.cpp:237]     Train net output #1: loss = 0.189167 (* 1 = 0.189167 loss)
I0628 22:20:45.944057 17220 sgd_solver.cpp:105] Iteration 60600, lr = 1e-05
I0628 22:20:49.685719 17220 solver.cpp:218] Iteration 60700 (26.727 iter/s, 3.74154s/100 iters), loss = 0.090929
I0628 22:20:49.685719 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:20:49.685719 17220 solver.cpp:237]     Train net output #1: loss = 0.0909298 (* 1 = 0.0909298 loss)
I0628 22:20:49.685719 17220 sgd_solver.cpp:105] Iteration 60700, lr = 1e-05
I0628 22:20:53.495699 17220 solver.cpp:218] Iteration 60800 (26.2521 iter/s, 3.80921s/100 iters), loss = 0.137615
I0628 22:20:53.495699 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:20:53.495699 17220 solver.cpp:237]     Train net output #1: loss = 0.137615 (* 1 = 0.137615 loss)
I0628 22:20:53.495699 17220 sgd_solver.cpp:105] Iteration 60800, lr = 1e-05
I0628 22:20:57.315417 17220 solver.cpp:218] Iteration 60900 (26.182 iter/s, 3.81942s/100 iters), loss = 0.0774719
I0628 22:20:57.315417 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:20:57.315417 17220 solver.cpp:237]     Train net output #1: loss = 0.0774726 (* 1 = 0.0774726 loss)
I0628 22:20:57.315417 17220 sgd_solver.cpp:105] Iteration 60900, lr = 1e-05
I0628 22:21:00.878950  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:21:01.036563 17220 solver.cpp:330] Iteration 61000, Testing net (#0)
I0628 22:21:01.036563 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:21:01.930219 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:21:01.961737 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8943
I0628 22:21:01.961737 17220 solver.cpp:397]     Test net output #1: loss = 0.371771 (* 1 = 0.371771 loss)
I0628 22:21:01.996762 17220 solver.cpp:218] Iteration 61000 (21.3638 iter/s, 4.68081s/100 iters), loss = 0.0746404
I0628 22:21:01.996762 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:21:01.996762 17220 solver.cpp:237]     Train net output #1: loss = 0.0746412 (* 1 = 0.0746412 loss)
I0628 22:21:01.996762 17220 sgd_solver.cpp:105] Iteration 61000, lr = 1e-05
I0628 22:21:05.721411 17220 solver.cpp:218] Iteration 61100 (26.8514 iter/s, 3.7242s/100 iters), loss = 0.104331
I0628 22:21:05.721411 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:21:05.721411 17220 solver.cpp:237]     Train net output #1: loss = 0.104332 (* 1 = 0.104332 loss)
I0628 22:21:05.721411 17220 sgd_solver.cpp:105] Iteration 61100, lr = 1e-05
I0628 22:21:09.493407 17220 solver.cpp:218] Iteration 61200 (26.5137 iter/s, 3.77164s/100 iters), loss = 0.147221
I0628 22:21:09.493407 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:21:09.493407 17220 solver.cpp:237]     Train net output #1: loss = 0.147222 (* 1 = 0.147222 loss)
I0628 22:21:09.493407 17220 sgd_solver.cpp:105] Iteration 61200, lr = 1e-05
I0628 22:21:13.122930 17220 solver.cpp:218] Iteration 61300 (27.5555 iter/s, 3.62905s/100 iters), loss = 0.107962
I0628 22:21:13.122930 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:21:13.122930 17220 solver.cpp:237]     Train net output #1: loss = 0.107962 (* 1 = 0.107962 loss)
I0628 22:21:13.122930 17220 sgd_solver.cpp:105] Iteration 61300, lr = 1e-05
I0628 22:21:16.781554 17220 solver.cpp:218] Iteration 61400 (27.3337 iter/s, 3.65849s/100 iters), loss = 0.0863856
I0628 22:21:16.781554 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:21:16.781554 17220 solver.cpp:237]     Train net output #1: loss = 0.0863864 (* 1 = 0.0863864 loss)
I0628 22:21:16.781554 17220 sgd_solver.cpp:105] Iteration 61400, lr = 1e-05
I0628 22:21:20.336571  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:21:20.482674 17220 solver.cpp:330] Iteration 61500, Testing net (#0)
I0628 22:21:20.482674 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:21:21.314267 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:21:21.344789 17220 solver.cpp:397]     Test net output #0: accuracy = 0.894
I0628 22:21:21.344789 17220 solver.cpp:397]     Test net output #1: loss = 0.371789 (* 1 = 0.371789 loss)
I0628 22:21:21.379312 17220 solver.cpp:218] Iteration 61500 (21.7528 iter/s, 4.59711s/100 iters), loss = 0.0937036
I0628 22:21:21.379312 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:21:21.379312 17220 solver.cpp:237]     Train net output #1: loss = 0.0937043 (* 1 = 0.0937043 loss)
I0628 22:21:21.379312 17220 sgd_solver.cpp:105] Iteration 61500, lr = 1e-05
I0628 22:21:25.067272 17220 solver.cpp:218] Iteration 61600 (27.1187 iter/s, 3.68749s/100 iters), loss = 0.154887
I0628 22:21:25.067272 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:21:25.067272 17220 solver.cpp:237]     Train net output #1: loss = 0.154888 (* 1 = 0.154888 loss)
I0628 22:21:25.067272 17220 sgd_solver.cpp:105] Iteration 61600, lr = 1e-05
I0628 22:21:28.727372 17220 solver.cpp:218] Iteration 61700 (27.3226 iter/s, 3.65997s/100 iters), loss = 0.0874265
I0628 22:21:28.727372 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:21:28.727372 17220 solver.cpp:237]     Train net output #1: loss = 0.0874272 (* 1 = 0.0874272 loss)
I0628 22:21:28.727372 17220 sgd_solver.cpp:105] Iteration 61700, lr = 1e-05
I0628 22:21:32.362447 17220 solver.cpp:218] Iteration 61800 (27.5123 iter/s, 3.63473s/100 iters), loss = 0.0832401
I0628 22:21:32.362447 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:21:32.362447 17220 solver.cpp:237]     Train net output #1: loss = 0.0832409 (* 1 = 0.0832409 loss)
I0628 22:21:32.362447 17220 sgd_solver.cpp:105] Iteration 61800, lr = 1e-05
I0628 22:21:35.998585 17220 solver.cpp:218] Iteration 61900 (27.5034 iter/s, 3.63591s/100 iters), loss = 0.069882
I0628 22:21:35.999086 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:21:35.999086 17220 solver.cpp:237]     Train net output #1: loss = 0.0698828 (* 1 = 0.0698828 loss)
I0628 22:21:35.999086 17220 sgd_solver.cpp:105] Iteration 61900, lr = 1e-05
I0628 22:21:39.503620  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:21:39.645220 17220 solver.cpp:330] Iteration 62000, Testing net (#0)
I0628 22:21:39.645220 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:21:40.474810 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:21:40.505832 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8937
I0628 22:21:40.505832 17220 solver.cpp:397]     Test net output #1: loss = 0.371761 (* 1 = 0.371761 loss)
I0628 22:21:40.541358 17220 solver.cpp:218] Iteration 62000 (22.0151 iter/s, 4.54234s/100 iters), loss = 0.134346
I0628 22:21:40.541859 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:21:40.541859 17220 solver.cpp:237]     Train net output #1: loss = 0.134346 (* 1 = 0.134346 loss)
I0628 22:21:40.541859 17220 sgd_solver.cpp:105] Iteration 62000, lr = 1e-05
I0628 22:21:44.203485 17220 solver.cpp:218] Iteration 62100 (27.31 iter/s, 3.66166s/100 iters), loss = 0.160348
I0628 22:21:44.203485 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:21:44.203485 17220 solver.cpp:237]     Train net output #1: loss = 0.160349 (* 1 = 0.160349 loss)
I0628 22:21:44.203485 17220 sgd_solver.cpp:105] Iteration 62100, lr = 1e-05
I0628 22:21:47.834663 17220 solver.cpp:218] Iteration 62200 (27.5437 iter/s, 3.6306s/100 iters), loss = 0.135794
I0628 22:21:47.834663 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:21:47.834663 17220 solver.cpp:237]     Train net output #1: loss = 0.135795 (* 1 = 0.135795 loss)
I0628 22:21:47.834663 17220 sgd_solver.cpp:105] Iteration 62200, lr = 1e-05
I0628 22:21:51.472395 17220 solver.cpp:218] Iteration 62300 (27.493 iter/s, 3.63729s/100 iters), loss = 0.090223
I0628 22:21:51.472395 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:21:51.472395 17220 solver.cpp:237]     Train net output #1: loss = 0.0902237 (* 1 = 0.0902237 loss)
I0628 22:21:51.472395 17220 sgd_solver.cpp:105] Iteration 62300, lr = 1e-05
I0628 22:21:55.120491 17220 solver.cpp:218] Iteration 62400 (27.4138 iter/s, 3.6478s/100 iters), loss = 0.0977269
I0628 22:21:55.120491 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:21:55.120491 17220 solver.cpp:237]     Train net output #1: loss = 0.0977276 (* 1 = 0.0977276 loss)
I0628 22:21:55.120491 17220 sgd_solver.cpp:105] Iteration 62400, lr = 1e-05
I0628 22:21:58.578941  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:21:58.720556 17220 solver.cpp:330] Iteration 62500, Testing net (#0)
I0628 22:21:58.720556 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:21:59.540627 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:21:59.571660 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0628 22:21:59.571660 17220 solver.cpp:397]     Test net output #1: loss = 0.37147 (* 1 = 0.37147 loss)
I0628 22:21:59.605671 17220 solver.cpp:218] Iteration 62500 (22.2963 iter/s, 4.48506s/100 iters), loss = 0.14512
I0628 22:21:59.606184 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:21:59.606184 17220 solver.cpp:237]     Train net output #1: loss = 0.145121 (* 1 = 0.145121 loss)
I0628 22:21:59.606184 17220 sgd_solver.cpp:105] Iteration 62500, lr = 1e-05
I0628 22:22:03.263506 17220 solver.cpp:218] Iteration 62600 (27.3426 iter/s, 3.6573s/100 iters), loss = 0.144617
I0628 22:22:03.263506 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:22:03.263506 17220 solver.cpp:237]     Train net output #1: loss = 0.144618 (* 1 = 0.144618 loss)
I0628 22:22:03.263506 17220 sgd_solver.cpp:105] Iteration 62600, lr = 1e-05
I0628 22:22:06.947376 17220 solver.cpp:218] Iteration 62700 (27.1494 iter/s, 3.68333s/100 iters), loss = 0.105218
I0628 22:22:06.947376 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:22:06.947376 17220 solver.cpp:237]     Train net output #1: loss = 0.105219 (* 1 = 0.105219 loss)
I0628 22:22:06.947376 17220 sgd_solver.cpp:105] Iteration 62700, lr = 1e-05
I0628 22:22:10.596472 17220 solver.cpp:218] Iteration 62800 (27.4038 iter/s, 3.64913s/100 iters), loss = 0.15701
I0628 22:22:10.596973 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:22:10.596973 17220 solver.cpp:237]     Train net output #1: loss = 0.157011 (* 1 = 0.157011 loss)
I0628 22:22:10.596973 17220 sgd_solver.cpp:105] Iteration 62800, lr = 1e-05
I0628 22:22:14.220064 17220 solver.cpp:218] Iteration 62900 (27.6019 iter/s, 3.62293s/100 iters), loss = 0.13744
I0628 22:22:14.220064 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:22:14.220064 17220 solver.cpp:237]     Train net output #1: loss = 0.137441 (* 1 = 0.137441 loss)
I0628 22:22:14.220064 17220 sgd_solver.cpp:105] Iteration 62900, lr = 1e-05
I0628 22:22:17.659931  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:22:17.801533 17220 solver.cpp:330] Iteration 63000, Testing net (#0)
I0628 22:22:17.801533 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:22:18.629120 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:22:18.660143 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8937
I0628 22:22:18.660143 17220 solver.cpp:397]     Test net output #1: loss = 0.37228 (* 1 = 0.37228 loss)
I0628 22:22:18.693676 17220 solver.cpp:218] Iteration 63000 (22.3544 iter/s, 4.47339s/100 iters), loss = 0.0754273
I0628 22:22:18.693676 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:22:18.693676 17220 solver.cpp:237]     Train net output #1: loss = 0.0754281 (* 1 = 0.0754281 loss)
I0628 22:22:18.693676 17220 sgd_solver.cpp:105] Iteration 63000, lr = 1e-05
I0628 22:22:22.326292 17220 solver.cpp:218] Iteration 63100 (27.5324 iter/s, 3.63208s/100 iters), loss = 0.124371
I0628 22:22:22.326292 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:22:22.326292 17220 solver.cpp:237]     Train net output #1: loss = 0.124372 (* 1 = 0.124372 loss)
I0628 22:22:22.326292 17220 sgd_solver.cpp:105] Iteration 63100, lr = 1e-05
I0628 22:22:26.013968 17220 solver.cpp:218] Iteration 63200 (27.1194 iter/s, 3.6874s/100 iters), loss = 0.108103
I0628 22:22:26.013968 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:22:26.013968 17220 solver.cpp:237]     Train net output #1: loss = 0.108103 (* 1 = 0.108103 loss)
I0628 22:22:26.013968 17220 sgd_solver.cpp:105] Iteration 63200, lr = 1e-05
I0628 22:22:29.702078 17220 solver.cpp:218] Iteration 63300 (27.1173 iter/s, 3.68768s/100 iters), loss = 0.143204
I0628 22:22:29.702078 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:22:29.702078 17220 solver.cpp:237]     Train net output #1: loss = 0.143205 (* 1 = 0.143205 loss)
I0628 22:22:29.702078 17220 sgd_solver.cpp:105] Iteration 63300, lr = 1e-05
I0628 22:22:33.432813 17220 solver.cpp:218] Iteration 63400 (26.808 iter/s, 3.73023s/100 iters), loss = 0.0967445
I0628 22:22:33.432813 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:22:33.432813 17220 solver.cpp:237]     Train net output #1: loss = 0.0967453 (* 1 = 0.0967453 loss)
I0628 22:22:33.432813 17220 sgd_solver.cpp:105] Iteration 63400, lr = 1e-05
I0628 22:22:36.958111  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:22:37.099211 17220 solver.cpp:330] Iteration 63500, Testing net (#0)
I0628 22:22:37.099710 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:22:37.932302 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:22:37.963825 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0628 22:22:37.963825 17220 solver.cpp:397]     Test net output #1: loss = 0.372419 (* 1 = 0.372419 loss)
I0628 22:22:37.997850 17220 solver.cpp:218] Iteration 63500 (21.9069 iter/s, 4.56476s/100 iters), loss = 0.0947791
I0628 22:22:37.997850 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:22:37.997850 17220 solver.cpp:237]     Train net output #1: loss = 0.0947798 (* 1 = 0.0947798 loss)
I0628 22:22:37.997850 17220 sgd_solver.cpp:105] Iteration 63500, lr = 1e-05
I0628 22:22:41.663751 17220 solver.cpp:218] Iteration 63600 (27.283 iter/s, 3.66529s/100 iters), loss = 0.187016
I0628 22:22:41.663751 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:22:41.663751 17220 solver.cpp:237]     Train net output #1: loss = 0.187017 (* 1 = 0.187017 loss)
I0628 22:22:41.663751 17220 sgd_solver.cpp:105] Iteration 63600, lr = 1e-05
I0628 22:22:45.313843 17220 solver.cpp:218] Iteration 63700 (27.3985 iter/s, 3.64983s/100 iters), loss = 0.134546
I0628 22:22:45.313843 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:22:45.313843 17220 solver.cpp:237]     Train net output #1: loss = 0.134547 (* 1 = 0.134547 loss)
I0628 22:22:45.313843 17220 sgd_solver.cpp:105] Iteration 63700, lr = 1e-05
I0628 22:22:48.940549 17220 solver.cpp:218] Iteration 63800 (27.5749 iter/s, 3.62649s/100 iters), loss = 0.0979717
I0628 22:22:48.940549 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:22:48.940549 17220 solver.cpp:237]     Train net output #1: loss = 0.0979725 (* 1 = 0.0979725 loss)
I0628 22:22:48.940549 17220 sgd_solver.cpp:105] Iteration 63800, lr = 1e-05
I0628 22:22:52.582183 17220 solver.cpp:218] Iteration 63900 (27.4642 iter/s, 3.6411s/100 iters), loss = 0.0763208
I0628 22:22:52.582183 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:22:52.582183 17220 solver.cpp:237]     Train net output #1: loss = 0.0763215 (* 1 = 0.0763215 loss)
I0628 22:22:52.582183 17220 sgd_solver.cpp:105] Iteration 63900, lr = 1e-05
I0628 22:22:56.055672  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:22:56.198271 17220 solver.cpp:330] Iteration 64000, Testing net (#0)
I0628 22:22:56.198271 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:22:57.032364 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:22:57.063372 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8936
I0628 22:22:57.063372 17220 solver.cpp:397]     Test net output #1: loss = 0.37172 (* 1 = 0.37172 loss)
I0628 22:22:57.097906 17220 solver.cpp:218] Iteration 64000 (22.1474 iter/s, 4.51521s/100 iters), loss = 0.133353
I0628 22:22:57.097906 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:22:57.097906 17220 solver.cpp:237]     Train net output #1: loss = 0.133354 (* 1 = 0.133354 loss)
I0628 22:22:57.097906 17220 sgd_solver.cpp:105] Iteration 64000, lr = 1e-05
I0628 22:23:00.731992 17220 solver.cpp:218] Iteration 64100 (27.518 iter/s, 3.63399s/100 iters), loss = 0.139102
I0628 22:23:00.731992 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 22:23:00.731992 17220 solver.cpp:237]     Train net output #1: loss = 0.139103 (* 1 = 0.139103 loss)
I0628 22:23:00.731992 17220 sgd_solver.cpp:105] Iteration 64100, lr = 1e-05
I0628 22:23:04.392597 17220 solver.cpp:218] Iteration 64200 (27.3223 iter/s, 3.66002s/100 iters), loss = 0.0745038
I0628 22:23:04.392597 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:23:04.392597 17220 solver.cpp:237]     Train net output #1: loss = 0.0745046 (* 1 = 0.0745046 loss)
I0628 22:23:04.392597 17220 sgd_solver.cpp:105] Iteration 64200, lr = 1e-05
I0628 22:23:08.015676 17220 solver.cpp:218] Iteration 64300 (27.6036 iter/s, 3.62272s/100 iters), loss = 0.137097
I0628 22:23:08.015676 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:23:08.015676 17220 solver.cpp:237]     Train net output #1: loss = 0.137098 (* 1 = 0.137098 loss)
I0628 22:23:08.015676 17220 sgd_solver.cpp:105] Iteration 64300, lr = 1e-05
I0628 22:23:11.660976 17220 solver.cpp:218] Iteration 64400 (27.4334 iter/s, 3.6452s/100 iters), loss = 0.0660007
I0628 22:23:11.660976 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:23:11.660976 17220 solver.cpp:237]     Train net output #1: loss = 0.0660015 (* 1 = 0.0660015 loss)
I0628 22:23:11.660976 17220 sgd_solver.cpp:105] Iteration 64400, lr = 1e-05
I0628 22:23:15.113703  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:23:15.254786 17220 solver.cpp:330] Iteration 64500, Testing net (#0)
I0628 22:23:15.255287 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:23:16.080374 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:23:16.111397 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8935
I0628 22:23:16.111896 17220 solver.cpp:397]     Test net output #1: loss = 0.37158 (* 1 = 0.37158 loss)
I0628 22:23:16.145920 17220 solver.cpp:218] Iteration 64500 (22.2999 iter/s, 4.48433s/100 iters), loss = 0.0824026
I0628 22:23:16.145920 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:23:16.145920 17220 solver.cpp:237]     Train net output #1: loss = 0.0824034 (* 1 = 0.0824034 loss)
I0628 22:23:16.145920 17220 sgd_solver.cpp:105] Iteration 64500, lr = 1e-05
I0628 22:23:19.763530 17220 solver.cpp:218] Iteration 64600 (27.6438 iter/s, 3.61744s/100 iters), loss = 0.110888
I0628 22:23:19.763530 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:23:19.763530 17220 solver.cpp:237]     Train net output #1: loss = 0.110889 (* 1 = 0.110889 loss)
I0628 22:23:19.763530 17220 sgd_solver.cpp:105] Iteration 64600, lr = 1e-05
I0628 22:23:23.387157 17220 solver.cpp:218] Iteration 64700 (27.5989 iter/s, 3.62334s/100 iters), loss = 0.136525
I0628 22:23:23.387657 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:23:23.387657 17220 solver.cpp:237]     Train net output #1: loss = 0.136526 (* 1 = 0.136526 loss)
I0628 22:23:23.387657 17220 sgd_solver.cpp:105] Iteration 64700, lr = 1e-05
I0628 22:23:27.037649 17220 solver.cpp:218] Iteration 64800 (27.3991 iter/s, 3.64975s/100 iters), loss = 0.0904421
I0628 22:23:27.037649 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:23:27.037649 17220 solver.cpp:237]     Train net output #1: loss = 0.0904428 (* 1 = 0.0904428 loss)
I0628 22:23:27.037649 17220 sgd_solver.cpp:105] Iteration 64800, lr = 1e-05
I0628 22:23:30.747733 17220 solver.cpp:218] Iteration 64900 (26.9557 iter/s, 3.70979s/100 iters), loss = 0.0661114
I0628 22:23:30.747733 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:23:30.747733 17220 solver.cpp:237]     Train net output #1: loss = 0.0661121 (* 1 = 0.0661121 loss)
I0628 22:23:30.747733 17220 sgd_solver.cpp:105] Iteration 64900, lr = 1e-05
I0628 22:23:34.262265  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:23:34.406868 17220 solver.cpp:330] Iteration 65000, Testing net (#0)
I0628 22:23:34.406868 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:23:35.246465 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:23:35.269484 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0628 22:23:35.269484 17220 solver.cpp:397]     Test net output #1: loss = 0.372265 (* 1 = 0.372265 loss)
I0628 22:23:35.304507 17220 solver.cpp:218] Iteration 65000 (21.9473 iter/s, 4.55638s/100 iters), loss = 0.13153
I0628 22:23:35.304507 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:23:35.304507 17220 solver.cpp:237]     Train net output #1: loss = 0.131531 (* 1 = 0.131531 loss)
I0628 22:23:35.305007 17220 sgd_solver.cpp:105] Iteration 65000, lr = 1e-05
I0628 22:23:38.970158 17220 solver.cpp:218] Iteration 65100 (27.2835 iter/s, 3.66522s/100 iters), loss = 0.1047
I0628 22:23:38.970158 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:23:38.970158 17220 solver.cpp:237]     Train net output #1: loss = 0.104701 (* 1 = 0.104701 loss)
I0628 22:23:38.970158 17220 sgd_solver.cpp:105] Iteration 65100, lr = 1e-05
I0628 22:23:42.617594 17220 solver.cpp:218] Iteration 65200 (27.4184 iter/s, 3.64718s/100 iters), loss = 0.150353
I0628 22:23:42.618093 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:23:42.618093 17220 solver.cpp:237]     Train net output #1: loss = 0.150354 (* 1 = 0.150354 loss)
I0628 22:23:42.618093 17220 sgd_solver.cpp:105] Iteration 65200, lr = 1e-05
I0628 22:23:46.300714 17220 solver.cpp:218] Iteration 65300 (27.1556 iter/s, 3.68248s/100 iters), loss = 0.0900311
I0628 22:23:46.300714 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:23:46.300714 17220 solver.cpp:237]     Train net output #1: loss = 0.0900318 (* 1 = 0.0900318 loss)
I0628 22:23:46.300714 17220 sgd_solver.cpp:105] Iteration 65300, lr = 1e-05
I0628 22:23:49.950310 17220 solver.cpp:218] Iteration 65400 (27.4023 iter/s, 3.64933s/100 iters), loss = 0.0962329
I0628 22:23:49.950310 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:23:49.950310 17220 solver.cpp:237]     Train net output #1: loss = 0.0962336 (* 1 = 0.0962336 loss)
I0628 22:23:49.950310 17220 sgd_solver.cpp:105] Iteration 65400, lr = 1e-05
I0628 22:23:53.471176  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:23:53.620782 17220 solver.cpp:330] Iteration 65500, Testing net (#0)
I0628 22:23:53.620782 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:23:54.446384 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:23:54.476902 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8934
I0628 22:23:54.476902 17220 solver.cpp:397]     Test net output #1: loss = 0.372432 (* 1 = 0.372432 loss)
I0628 22:23:54.511425 17220 solver.cpp:218] Iteration 65500 (21.927 iter/s, 4.56059s/100 iters), loss = 0.0903177
I0628 22:23:54.511425 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:23:54.511425 17220 solver.cpp:237]     Train net output #1: loss = 0.0903184 (* 1 = 0.0903184 loss)
I0628 22:23:54.511425 17220 sgd_solver.cpp:105] Iteration 65500, lr = 1e-05
I0628 22:23:58.148003 17220 solver.cpp:218] Iteration 65600 (27.5019 iter/s, 3.63612s/100 iters), loss = 0.160037
I0628 22:23:58.148003 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:23:58.148003 17220 solver.cpp:237]     Train net output #1: loss = 0.160038 (* 1 = 0.160038 loss)
I0628 22:23:58.148003 17220 sgd_solver.cpp:105] Iteration 65600, lr = 1e-05
I0628 22:24:01.779134 17220 solver.cpp:218] Iteration 65700 (27.5408 iter/s, 3.63097s/100 iters), loss = 0.111258
I0628 22:24:01.779134 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:24:01.779134 17220 solver.cpp:237]     Train net output #1: loss = 0.111258 (* 1 = 0.111258 loss)
I0628 22:24:01.779134 17220 sgd_solver.cpp:105] Iteration 65700, lr = 1e-05
I0628 22:24:05.417156 17220 solver.cpp:218] Iteration 65800 (27.4891 iter/s, 3.63781s/100 iters), loss = 0.126103
I0628 22:24:05.417656 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:24:05.417656 17220 solver.cpp:237]     Train net output #1: loss = 0.126104 (* 1 = 0.126104 loss)
I0628 22:24:05.417656 17220 sgd_solver.cpp:105] Iteration 65800, lr = 1e-05
I0628 22:24:09.029251 17220 solver.cpp:218] Iteration 65900 (27.688 iter/s, 3.61167s/100 iters), loss = 0.088716
I0628 22:24:09.029251 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:24:09.029251 17220 solver.cpp:237]     Train net output #1: loss = 0.0887167 (* 1 = 0.0887167 loss)
I0628 22:24:09.029251 17220 sgd_solver.cpp:105] Iteration 65900, lr = 1e-05
I0628 22:24:12.471402  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:24:12.612502 17220 solver.cpp:330] Iteration 66000, Testing net (#0)
I0628 22:24:12.612502 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:24:13.442594 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:24:13.473120 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0628 22:24:13.473615 17220 solver.cpp:397]     Test net output #1: loss = 0.372185 (* 1 = 0.372185 loss)
I0628 22:24:13.507639 17220 solver.cpp:218] Iteration 66000 (22.3316 iter/s, 4.47795s/100 iters), loss = 0.0980725
I0628 22:24:13.507639 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:24:13.507639 17220 solver.cpp:237]     Train net output #1: loss = 0.0980733 (* 1 = 0.0980733 loss)
I0628 22:24:13.507639 17220 sgd_solver.cpp:105] Iteration 66000, lr = 1e-05
I0628 22:24:17.158736 17220 solver.cpp:218] Iteration 66100 (27.3909 iter/s, 3.65085s/100 iters), loss = 0.138463
I0628 22:24:17.158736 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:24:17.158736 17220 solver.cpp:237]     Train net output #1: loss = 0.138463 (* 1 = 0.138463 loss)
I0628 22:24:17.159237 17220 sgd_solver.cpp:105] Iteration 66100, lr = 1e-05
I0628 22:24:20.828848 17220 solver.cpp:218] Iteration 66200 (27.2506 iter/s, 3.66965s/100 iters), loss = 0.100202
I0628 22:24:20.828848 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:24:20.828848 17220 solver.cpp:237]     Train net output #1: loss = 0.100203 (* 1 = 0.100203 loss)
I0628 22:24:20.828848 17220 sgd_solver.cpp:105] Iteration 66200, lr = 1e-05
I0628 22:24:24.532024 17220 solver.cpp:218] Iteration 66300 (27.0069 iter/s, 3.70275s/100 iters), loss = 0.114957
I0628 22:24:24.532024 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:24:24.532024 17220 solver.cpp:237]     Train net output #1: loss = 0.114957 (* 1 = 0.114957 loss)
I0628 22:24:24.532024 17220 sgd_solver.cpp:105] Iteration 66300, lr = 1e-05
I0628 22:24:28.187125 17220 solver.cpp:218] Iteration 66400 (27.3629 iter/s, 3.65459s/100 iters), loss = 0.10182
I0628 22:24:28.187125 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:24:28.187125 17220 solver.cpp:237]     Train net output #1: loss = 0.10182 (* 1 = 0.10182 loss)
I0628 22:24:28.187125 17220 sgd_solver.cpp:105] Iteration 66400, lr = 1e-05
I0628 22:24:31.672106  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:24:31.813705 17220 solver.cpp:330] Iteration 66500, Testing net (#0)
I0628 22:24:31.813705 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:24:32.639793 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:24:32.670815 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0628 22:24:32.670815 17220 solver.cpp:397]     Test net output #1: loss = 0.371267 (* 1 = 0.371267 loss)
I0628 22:24:32.705339 17220 solver.cpp:218] Iteration 66500 (22.1344 iter/s, 4.51785s/100 iters), loss = 0.071815
I0628 22:24:32.705339 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:24:32.705339 17220 solver.cpp:237]     Train net output #1: loss = 0.0718158 (* 1 = 0.0718158 loss)
I0628 22:24:32.705339 17220 sgd_solver.cpp:105] Iteration 66500, lr = 1e-05
I0628 22:24:36.330919 17220 solver.cpp:218] Iteration 66600 (27.5825 iter/s, 3.62548s/100 iters), loss = 0.0677104
I0628 22:24:36.330919 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:24:36.331420 17220 solver.cpp:237]     Train net output #1: loss = 0.0677111 (* 1 = 0.0677111 loss)
I0628 22:24:36.331420 17220 sgd_solver.cpp:105] Iteration 66600, lr = 1e-05
I0628 22:24:39.949856 17220 solver.cpp:218] Iteration 66700 (27.6375 iter/s, 3.61828s/100 iters), loss = 0.144768
I0628 22:24:39.949856 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:24:39.949856 17220 solver.cpp:237]     Train net output #1: loss = 0.144769 (* 1 = 0.144769 loss)
I0628 22:24:39.949856 17220 sgd_solver.cpp:105] Iteration 66700, lr = 1e-05
I0628 22:24:43.552922 17220 solver.cpp:218] Iteration 66800 (27.758 iter/s, 3.60256s/100 iters), loss = 0.0959732
I0628 22:24:43.552922 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:24:43.552922 17220 solver.cpp:237]     Train net output #1: loss = 0.095974 (* 1 = 0.095974 loss)
I0628 22:24:43.552922 17220 sgd_solver.cpp:105] Iteration 66800, lr = 1e-05
I0628 22:24:47.148468 17220 solver.cpp:218] Iteration 66900 (27.8143 iter/s, 3.59528s/100 iters), loss = 0.0910559
I0628 22:24:47.148468 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:24:47.148468 17220 solver.cpp:237]     Train net output #1: loss = 0.0910567 (* 1 = 0.0910567 loss)
I0628 22:24:47.148468 17220 sgd_solver.cpp:105] Iteration 66900, lr = 1e-05
I0628 22:24:50.584940  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:24:50.725538 17220 solver.cpp:330] Iteration 67000, Testing net (#0)
I0628 22:24:50.725538 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:24:51.548624 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:24:51.579646 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8934
I0628 22:24:51.579646 17220 solver.cpp:397]     Test net output #1: loss = 0.371379 (* 1 = 0.371379 loss)
I0628 22:24:51.613682 17220 solver.cpp:218] Iteration 67000 (22.397 iter/s, 4.46487s/100 iters), loss = 0.0932688
I0628 22:24:51.613682 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:24:51.613682 17220 solver.cpp:237]     Train net output #1: loss = 0.0932696 (* 1 = 0.0932696 loss)
I0628 22:24:51.613682 17220 sgd_solver.cpp:105] Iteration 67000, lr = 1e-05
I0628 22:24:55.284337 17220 solver.cpp:218] Iteration 67100 (27.2433 iter/s, 3.67062s/100 iters), loss = 0.198287
I0628 22:24:55.284837 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:24:55.284837 17220 solver.cpp:237]     Train net output #1: loss = 0.198288 (* 1 = 0.198288 loss)
I0628 22:24:55.284837 17220 sgd_solver.cpp:105] Iteration 67100, lr = 1e-05
I0628 22:24:58.917381 17220 solver.cpp:218] Iteration 67200 (27.5313 iter/s, 3.63222s/100 iters), loss = 0.0953967
I0628 22:24:58.917381 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:24:58.917381 17220 solver.cpp:237]     Train net output #1: loss = 0.0953975 (* 1 = 0.0953975 loss)
I0628 22:24:58.917381 17220 sgd_solver.cpp:105] Iteration 67200, lr = 1e-05
I0628 22:25:02.555249 17220 solver.cpp:218] Iteration 67300 (27.4884 iter/s, 3.6379s/100 iters), loss = 0.123306
I0628 22:25:02.555750 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:25:02.555750 17220 solver.cpp:237]     Train net output #1: loss = 0.123307 (* 1 = 0.123307 loss)
I0628 22:25:02.555750 17220 sgd_solver.cpp:105] Iteration 67300, lr = 1e-05
I0628 22:25:06.196341 17220 solver.cpp:218] Iteration 67400 (27.4668 iter/s, 3.64076s/100 iters), loss = 0.0760008
I0628 22:25:06.196341 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:25:06.196341 17220 solver.cpp:237]     Train net output #1: loss = 0.0760015 (* 1 = 0.0760015 loss)
I0628 22:25:06.196341 17220 sgd_solver.cpp:105] Iteration 67400, lr = 1e-05
I0628 22:25:09.683775  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:25:09.827877 17220 solver.cpp:330] Iteration 67500, Testing net (#0)
I0628 22:25:09.827877 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:25:10.651964 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:25:10.682996 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0628 22:25:10.682996 17220 solver.cpp:397]     Test net output #1: loss = 0.37193 (* 1 = 0.37193 loss)
I0628 22:25:10.717010 17220 solver.cpp:218] Iteration 67500 (22.1244 iter/s, 4.51989s/100 iters), loss = 0.139636
I0628 22:25:10.717010 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:25:10.717010 17220 solver.cpp:237]     Train net output #1: loss = 0.139637 (* 1 = 0.139637 loss)
I0628 22:25:10.717010 17220 sgd_solver.cpp:105] Iteration 67500, lr = 1e-05
I0628 22:25:14.361104 17220 solver.cpp:218] Iteration 67600 (27.4442 iter/s, 3.64376s/100 iters), loss = 0.123935
I0628 22:25:14.361104 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:25:14.361104 17220 solver.cpp:237]     Train net output #1: loss = 0.123935 (* 1 = 0.123935 loss)
I0628 22:25:14.361104 17220 sgd_solver.cpp:105] Iteration 67600, lr = 1e-05
I0628 22:25:17.983219 17220 solver.cpp:218] Iteration 67700 (27.6134 iter/s, 3.62143s/100 iters), loss = 0.146076
I0628 22:25:17.983219 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:25:17.983219 17220 solver.cpp:237]     Train net output #1: loss = 0.146077 (* 1 = 0.146077 loss)
I0628 22:25:17.983219 17220 sgd_solver.cpp:105] Iteration 67700, lr = 1e-05
I0628 22:25:21.642088 17220 solver.cpp:218] Iteration 67800 (27.3331 iter/s, 3.65857s/100 iters), loss = 0.0816382
I0628 22:25:21.642088 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:25:21.642088 17220 solver.cpp:237]     Train net output #1: loss = 0.081639 (* 1 = 0.081639 loss)
I0628 22:25:21.642088 17220 sgd_solver.cpp:105] Iteration 67800, lr = 1e-05
I0628 22:25:25.267277 17220 solver.cpp:218] Iteration 67900 (27.5881 iter/s, 3.62475s/100 iters), loss = 0.0854654
I0628 22:25:25.267277 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:25:25.267277 17220 solver.cpp:237]     Train net output #1: loss = 0.0854662 (* 1 = 0.0854662 loss)
I0628 22:25:25.267277 17220 sgd_solver.cpp:105] Iteration 67900, lr = 1e-05
I0628 22:25:28.717944  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:25:28.860046 17220 solver.cpp:330] Iteration 68000, Testing net (#0)
I0628 22:25:28.860046 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:25:29.682631 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:25:29.713654 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8936
I0628 22:25:29.713654 17220 solver.cpp:397]     Test net output #1: loss = 0.371723 (* 1 = 0.371723 loss)
I0628 22:25:29.748178 17220 solver.cpp:218] Iteration 68000 (22.3186 iter/s, 4.48056s/100 iters), loss = 0.103141
I0628 22:25:29.748178 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:25:29.748178 17220 solver.cpp:237]     Train net output #1: loss = 0.103142 (* 1 = 0.103142 loss)
I0628 22:25:29.748178 17220 sgd_solver.cpp:105] Iteration 68000, lr = 1e-05
I0628 22:25:33.386791 17220 solver.cpp:218] Iteration 68100 (27.4835 iter/s, 3.63854s/100 iters), loss = 0.0800904
I0628 22:25:33.386791 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:25:33.386791 17220 solver.cpp:237]     Train net output #1: loss = 0.0800912 (* 1 = 0.0800912 loss)
I0628 22:25:33.386791 17220 sgd_solver.cpp:105] Iteration 68100, lr = 1e-05
I0628 22:25:37.029062 17220 solver.cpp:218] Iteration 68200 (27.4586 iter/s, 3.64185s/100 iters), loss = 0.110833
I0628 22:25:37.029062 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:25:37.029062 17220 solver.cpp:237]     Train net output #1: loss = 0.110834 (* 1 = 0.110834 loss)
I0628 22:25:37.029062 17220 sgd_solver.cpp:105] Iteration 68200, lr = 1e-05
I0628 22:25:40.648653 17220 solver.cpp:218] Iteration 68300 (27.6317 iter/s, 3.61903s/100 iters), loss = 0.159346
I0628 22:25:40.648653 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:25:40.648653 17220 solver.cpp:237]     Train net output #1: loss = 0.159347 (* 1 = 0.159347 loss)
I0628 22:25:40.648653 17220 sgd_solver.cpp:105] Iteration 68300, lr = 1e-05
I0628 22:25:44.286242 17220 solver.cpp:218] Iteration 68400 (27.4944 iter/s, 3.6371s/100 iters), loss = 0.0813042
I0628 22:25:44.286242 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:25:44.286242 17220 solver.cpp:237]     Train net output #1: loss = 0.0813049 (* 1 = 0.0813049 loss)
I0628 22:25:44.286242 17220 sgd_solver.cpp:105] Iteration 68400, lr = 1e-05
I0628 22:25:47.744760  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:25:47.886862 17220 solver.cpp:330] Iteration 68500, Testing net (#0)
I0628 22:25:47.886862 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:25:48.710948 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:25:48.742470 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0628 22:25:48.742470 17220 solver.cpp:397]     Test net output #1: loss = 0.371797 (* 1 = 0.371797 loss)
I0628 22:25:48.776494 17220 solver.cpp:218] Iteration 68500 (22.2725 iter/s, 4.48985s/100 iters), loss = 0.0724877
I0628 22:25:48.776494 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:25:48.776494 17220 solver.cpp:237]     Train net output #1: loss = 0.0724884 (* 1 = 0.0724884 loss)
I0628 22:25:48.776494 17220 sgd_solver.cpp:105] Iteration 68500, lr = 1e-05
I0628 22:25:52.424154 17220 solver.cpp:218] Iteration 68600 (27.416 iter/s, 3.6475s/100 iters), loss = 0.134361
I0628 22:25:52.424154 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:25:52.424154 17220 solver.cpp:237]     Train net output #1: loss = 0.134362 (* 1 = 0.134362 loss)
I0628 22:25:52.424154 17220 sgd_solver.cpp:105] Iteration 68600, lr = 1e-05
I0628 22:25:56.078270 17220 solver.cpp:218] Iteration 68700 (27.3726 iter/s, 3.65329s/100 iters), loss = 0.0490415
I0628 22:25:56.078270 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:25:56.078270 17220 solver.cpp:237]     Train net output #1: loss = 0.0490422 (* 1 = 0.0490422 loss)
I0628 22:25:56.078270 17220 sgd_solver.cpp:105] Iteration 68700, lr = 1e-05
I0628 22:25:59.744968 17220 solver.cpp:218] Iteration 68800 (27.2741 iter/s, 3.66649s/100 iters), loss = 0.075066
I0628 22:25:59.744968 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:25:59.744968 17220 solver.cpp:237]     Train net output #1: loss = 0.0750667 (* 1 = 0.0750667 loss)
I0628 22:25:59.744968 17220 sgd_solver.cpp:105] Iteration 68800, lr = 1e-05
I0628 22:26:03.371069 17220 solver.cpp:218] Iteration 68900 (27.5793 iter/s, 3.62591s/100 iters), loss = 0.0707037
I0628 22:26:03.371069 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:26:03.371570 17220 solver.cpp:237]     Train net output #1: loss = 0.0707043 (* 1 = 0.0707043 loss)
I0628 22:26:03.371570 17220 sgd_solver.cpp:105] Iteration 68900, lr = 1e-05
I0628 22:26:06.837579  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:26:06.978688 17220 solver.cpp:330] Iteration 69000, Testing net (#0)
I0628 22:26:06.978688 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:26:07.802819 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:26:07.833838 17220 solver.cpp:397]     Test net output #0: accuracy = 0.894
I0628 22:26:07.833838 17220 solver.cpp:397]     Test net output #1: loss = 0.371755 (* 1 = 0.371755 loss)
I0628 22:26:07.868363 17220 solver.cpp:218] Iteration 69000 (22.2394 iter/s, 4.49652s/100 iters), loss = 0.107308
I0628 22:26:07.868363 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:26:07.868363 17220 solver.cpp:237]     Train net output #1: loss = 0.107308 (* 1 = 0.107308 loss)
I0628 22:26:07.868363 17220 sgd_solver.cpp:105] Iteration 69000, lr = 1e-05
I0628 22:26:11.490429 17220 solver.cpp:218] Iteration 69100 (27.6097 iter/s, 3.62192s/100 iters), loss = 0.18429
I0628 22:26:11.490429 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:26:11.490429 17220 solver.cpp:237]     Train net output #1: loss = 0.18429 (* 1 = 0.18429 loss)
I0628 22:26:11.490429 17220 sgd_solver.cpp:105] Iteration 69100, lr = 1e-05
I0628 22:26:15.089092 17220 solver.cpp:218] Iteration 69200 (27.7899 iter/s, 3.59843s/100 iters), loss = 0.149864
I0628 22:26:15.089092 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:26:15.089092 17220 solver.cpp:237]     Train net output #1: loss = 0.149864 (* 1 = 0.149864 loss)
I0628 22:26:15.089092 17220 sgd_solver.cpp:105] Iteration 69200, lr = 1e-05
I0628 22:26:18.685693 17220 solver.cpp:218] Iteration 69300 (27.8092 iter/s, 3.59593s/100 iters), loss = 0.113714
I0628 22:26:18.685693 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:26:18.685693 17220 solver.cpp:237]     Train net output #1: loss = 0.113715 (* 1 = 0.113715 loss)
I0628 22:26:18.685693 17220 sgd_solver.cpp:105] Iteration 69300, lr = 1e-05
I0628 22:26:22.309386 17220 solver.cpp:218] Iteration 69400 (27.5984 iter/s, 3.6234s/100 iters), loss = 0.10504
I0628 22:26:22.309386 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:26:22.309386 17220 solver.cpp:237]     Train net output #1: loss = 0.105041 (* 1 = 0.105041 loss)
I0628 22:26:22.309386 17220 sgd_solver.cpp:105] Iteration 69400, lr = 1e-05
I0628 22:26:25.735373  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:26:25.875974 17220 solver.cpp:330] Iteration 69500, Testing net (#0)
I0628 22:26:25.875974 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:26:26.703562 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:26:26.734083 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0628 22:26:26.734585 17220 solver.cpp:397]     Test net output #1: loss = 0.371485 (* 1 = 0.371485 loss)
I0628 22:26:26.768609 17220 solver.cpp:218] Iteration 69500 (22.4263 iter/s, 4.45904s/100 iters), loss = 0.091489
I0628 22:26:26.768609 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:26:26.768609 17220 solver.cpp:237]     Train net output #1: loss = 0.0914897 (* 1 = 0.0914897 loss)
I0628 22:26:26.768609 17220 sgd_solver.cpp:105] Iteration 69500, lr = 1e-05
I0628 22:26:30.388185 17220 solver.cpp:218] Iteration 69600 (27.6303 iter/s, 3.61922s/100 iters), loss = 0.131977
I0628 22:26:30.388185 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:26:30.388185 17220 solver.cpp:237]     Train net output #1: loss = 0.131978 (* 1 = 0.131978 loss)
I0628 22:26:30.388185 17220 sgd_solver.cpp:105] Iteration 69600, lr = 1e-05
I0628 22:26:33.999860 17220 solver.cpp:218] Iteration 69700 (27.6903 iter/s, 3.61138s/100 iters), loss = 0.0933782
I0628 22:26:33.999860 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:26:33.999860 17220 solver.cpp:237]     Train net output #1: loss = 0.0933789 (* 1 = 0.0933789 loss)
I0628 22:26:33.999860 17220 sgd_solver.cpp:105] Iteration 69700, lr = 1e-05
I0628 22:26:37.637363 17220 solver.cpp:218] Iteration 69800 (27.4936 iter/s, 3.63721s/100 iters), loss = 0.126637
I0628 22:26:37.637363 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:26:37.637363 17220 solver.cpp:237]     Train net output #1: loss = 0.126638 (* 1 = 0.126638 loss)
I0628 22:26:37.637363 17220 sgd_solver.cpp:105] Iteration 69800, lr = 1e-05
I0628 22:26:41.270493 17220 solver.cpp:218] Iteration 69900 (27.5276 iter/s, 3.63272s/100 iters), loss = 0.0730291
I0628 22:26:41.270493 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:26:41.270493 17220 solver.cpp:237]     Train net output #1: loss = 0.0730298 (* 1 = 0.0730298 loss)
I0628 22:26:41.270493 17220 sgd_solver.cpp:105] Iteration 69900, lr = 1e-05
I0628 22:26:44.721449  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:26:44.864053 17220 solver.cpp:330] Iteration 70000, Testing net (#0)
I0628 22:26:44.864053 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:26:45.686136 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:26:45.716657 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0628 22:26:45.716657 17220 solver.cpp:397]     Test net output #1: loss = 0.371416 (* 1 = 0.371416 loss)
I0628 22:26:45.751181 17220 solver.cpp:218] Iteration 70000 (22.3193 iter/s, 4.48043s/100 iters), loss = 0.0886691
I0628 22:26:45.751682 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:26:45.751682 17220 solver.cpp:237]     Train net output #1: loss = 0.0886698 (* 1 = 0.0886698 loss)
I0628 22:26:45.751682 17220 sgd_solver.cpp:105] Iteration 70000, lr = 1e-05
I0628 22:26:49.375260 17220 solver.cpp:218] Iteration 70100 (27.5978 iter/s, 3.62347s/100 iters), loss = 0.189284
I0628 22:26:49.375260 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:26:49.375260 17220 solver.cpp:237]     Train net output #1: loss = 0.189285 (* 1 = 0.189285 loss)
I0628 22:26:49.375260 17220 sgd_solver.cpp:105] Iteration 70100, lr = 1e-05
I0628 22:26:53.005342 17220 solver.cpp:218] Iteration 70200 (27.5488 iter/s, 3.62993s/100 iters), loss = 0.128738
I0628 22:26:53.005342 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:26:53.005342 17220 solver.cpp:237]     Train net output #1: loss = 0.128738 (* 1 = 0.128738 loss)
I0628 22:26:53.005342 17220 sgd_solver.cpp:105] Iteration 70200, lr = 1e-05
I0628 22:26:56.640929 17220 solver.cpp:218] Iteration 70300 (27.5114 iter/s, 3.63486s/100 iters), loss = 0.0798754
I0628 22:26:56.640929 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:26:56.640929 17220 solver.cpp:237]     Train net output #1: loss = 0.0798761 (* 1 = 0.0798761 loss)
I0628 22:26:56.640929 17220 sgd_solver.cpp:105] Iteration 70300, lr = 1e-05
I0628 22:27:00.276020 17220 solver.cpp:218] Iteration 70400 (27.5122 iter/s, 3.63475s/100 iters), loss = 0.0880181
I0628 22:27:00.276020 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:27:00.276020 17220 solver.cpp:237]     Train net output #1: loss = 0.0880188 (* 1 = 0.0880188 loss)
I0628 22:27:00.276020 17220 sgd_solver.cpp:105] Iteration 70400, lr = 1e-05
I0628 22:27:03.732480  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:27:03.874580 17220 solver.cpp:330] Iteration 70500, Testing net (#0)
I0628 22:27:03.874580 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:27:04.696166 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:27:04.728688 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0628 22:27:04.728688 17220 solver.cpp:397]     Test net output #1: loss = 0.372112 (* 1 = 0.372112 loss)
I0628 22:27:04.763212 17220 solver.cpp:218] Iteration 70500 (22.287 iter/s, 4.48692s/100 iters), loss = 0.0823134
I0628 22:27:04.763212 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:27:04.763212 17220 solver.cpp:237]     Train net output #1: loss = 0.0823141 (* 1 = 0.0823141 loss)
I0628 22:27:04.763212 17220 sgd_solver.cpp:105] Iteration 70500, lr = 1e-05
I0628 22:27:08.388792 17220 solver.cpp:218] Iteration 70600 (27.5841 iter/s, 3.62528s/100 iters), loss = 0.210045
I0628 22:27:08.388792 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:27:08.388792 17220 solver.cpp:237]     Train net output #1: loss = 0.210046 (* 1 = 0.210046 loss)
I0628 22:27:08.388792 17220 sgd_solver.cpp:105] Iteration 70600, lr = 1e-05
I0628 22:27:12.020375 17220 solver.cpp:218] Iteration 70700 (27.5389 iter/s, 3.63123s/100 iters), loss = 0.180209
I0628 22:27:12.020375 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:27:12.020375 17220 solver.cpp:237]     Train net output #1: loss = 0.18021 (* 1 = 0.18021 loss)
I0628 22:27:12.020375 17220 sgd_solver.cpp:105] Iteration 70700, lr = 1e-05
I0628 22:27:15.641451 17220 solver.cpp:218] Iteration 70800 (27.6192 iter/s, 3.62068s/100 iters), loss = 0.149081
I0628 22:27:15.641451 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:27:15.641451 17220 solver.cpp:237]     Train net output #1: loss = 0.149081 (* 1 = 0.149081 loss)
I0628 22:27:15.641952 17220 sgd_solver.cpp:105] Iteration 70800, lr = 1e-05
I0628 22:27:19.272034 17220 solver.cpp:218] Iteration 70900 (27.5471 iter/s, 3.63015s/100 iters), loss = 0.0879736
I0628 22:27:19.272034 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:27:19.272034 17220 solver.cpp:237]     Train net output #1: loss = 0.0879743 (* 1 = 0.0879743 loss)
I0628 22:27:19.272034 17220 sgd_solver.cpp:105] Iteration 70900, lr = 1e-05
I0628 22:27:22.722990  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:27:22.864090 17220 solver.cpp:330] Iteration 71000, Testing net (#0)
I0628 22:27:22.864090 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:27:23.686175 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:27:23.716706 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0628 22:27:23.716706 17220 solver.cpp:397]     Test net output #1: loss = 0.37221 (* 1 = 0.37221 loss)
I0628 22:27:23.751221 17220 solver.cpp:218] Iteration 71000 (22.3286 iter/s, 4.47857s/100 iters), loss = 0.0904011
I0628 22:27:23.751221 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:27:23.751221 17220 solver.cpp:237]     Train net output #1: loss = 0.0904018 (* 1 = 0.0904018 loss)
I0628 22:27:23.751221 17220 sgd_solver.cpp:105] Iteration 71000, lr = 1e-05
I0628 22:27:27.381304 17220 solver.cpp:218] Iteration 71100 (27.5491 iter/s, 3.62988s/100 iters), loss = 0.181313
I0628 22:27:27.381304 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:27:27.381304 17220 solver.cpp:237]     Train net output #1: loss = 0.181313 (* 1 = 0.181313 loss)
I0628 22:27:27.381304 17220 sgd_solver.cpp:105] Iteration 71100, lr = 1e-05
I0628 22:27:31.010886 17220 solver.cpp:218] Iteration 71200 (27.5548 iter/s, 3.62913s/100 iters), loss = 0.090305
I0628 22:27:31.010886 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:27:31.010886 17220 solver.cpp:237]     Train net output #1: loss = 0.0903057 (* 1 = 0.0903057 loss)
I0628 22:27:31.010886 17220 sgd_solver.cpp:105] Iteration 71200, lr = 1e-05
I0628 22:27:34.635704 17220 solver.cpp:218] Iteration 71300 (27.5898 iter/s, 3.62453s/100 iters), loss = 0.0871567
I0628 22:27:34.635704 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:27:34.635704 17220 solver.cpp:237]     Train net output #1: loss = 0.0871574 (* 1 = 0.0871574 loss)
I0628 22:27:34.635704 17220 sgd_solver.cpp:105] Iteration 71300, lr = 1e-05
I0628 22:27:38.252774 17220 solver.cpp:218] Iteration 71400 (27.6518 iter/s, 3.61641s/100 iters), loss = 0.12397
I0628 22:27:38.252774 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:27:38.252774 17220 solver.cpp:237]     Train net output #1: loss = 0.123971 (* 1 = 0.123971 loss)
I0628 22:27:38.252774 17220 sgd_solver.cpp:105] Iteration 71400, lr = 1e-05
I0628 22:27:41.694922  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:27:41.836524 17220 solver.cpp:330] Iteration 71500, Testing net (#0)
I0628 22:27:41.836524 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:27:42.659108 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:27:42.690131 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0628 22:27:42.690131 17220 solver.cpp:397]     Test net output #1: loss = 0.372065 (* 1 = 0.372065 loss)
I0628 22:27:42.724154 17220 solver.cpp:218] Iteration 71500 (22.3651 iter/s, 4.47125s/100 iters), loss = 0.159938
I0628 22:27:42.724154 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:27:42.724154 17220 solver.cpp:237]     Train net output #1: loss = 0.159939 (* 1 = 0.159939 loss)
I0628 22:27:42.724154 17220 sgd_solver.cpp:105] Iteration 71500, lr = 1e-05
I0628 22:27:46.352706 17220 solver.cpp:218] Iteration 71600 (27.5622 iter/s, 3.62815s/100 iters), loss = 0.17825
I0628 22:27:46.352706 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:27:46.352706 17220 solver.cpp:237]     Train net output #1: loss = 0.178251 (* 1 = 0.178251 loss)
I0628 22:27:46.352706 17220 sgd_solver.cpp:105] Iteration 71600, lr = 1e-05
I0628 22:27:49.976784 17220 solver.cpp:218] Iteration 71700 (27.5965 iter/s, 3.62365s/100 iters), loss = 0.0947166
I0628 22:27:49.976784 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:27:49.976784 17220 solver.cpp:237]     Train net output #1: loss = 0.0947174 (* 1 = 0.0947174 loss)
I0628 22:27:49.976784 17220 sgd_solver.cpp:105] Iteration 71700, lr = 1e-05
I0628 22:27:53.610383 17220 solver.cpp:218] Iteration 71800 (27.5234 iter/s, 3.63327s/100 iters), loss = 0.0797095
I0628 22:27:53.610383 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:27:53.610383 17220 solver.cpp:237]     Train net output #1: loss = 0.0797103 (* 1 = 0.0797103 loss)
I0628 22:27:53.610383 17220 sgd_solver.cpp:105] Iteration 71800, lr = 1e-05
I0628 22:27:57.237643 17220 solver.cpp:218] Iteration 71900 (27.5702 iter/s, 3.6271s/100 iters), loss = 0.0943295
I0628 22:27:57.237643 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:27:57.237643 17220 solver.cpp:237]     Train net output #1: loss = 0.0943304 (* 1 = 0.0943304 loss)
I0628 22:27:57.237643 17220 sgd_solver.cpp:105] Iteration 71900, lr = 1e-05
I0628 22:28:00.695143  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:28:00.836256 17220 solver.cpp:330] Iteration 72000, Testing net (#0)
I0628 22:28:00.836256 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:28:01.658336 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:28:01.689358 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0628 22:28:01.689358 17220 solver.cpp:397]     Test net output #1: loss = 0.371507 (* 1 = 0.371507 loss)
I0628 22:28:01.723884 17220 solver.cpp:218] Iteration 72000 (22.2937 iter/s, 4.48557s/100 iters), loss = 0.14267
I0628 22:28:01.723884 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:28:01.723884 17220 solver.cpp:237]     Train net output #1: loss = 0.142671 (* 1 = 0.142671 loss)
I0628 22:28:01.723884 17220 sgd_solver.cpp:105] Iteration 72000, lr = 1e-05
I0628 22:28:05.353674 17220 solver.cpp:218] Iteration 72100 (27.5495 iter/s, 3.62983s/100 iters), loss = 0.247853
I0628 22:28:05.353674 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:28:05.353674 17220 solver.cpp:237]     Train net output #1: loss = 0.247853 (* 1 = 0.247853 loss)
I0628 22:28:05.353674 17220 sgd_solver.cpp:105] Iteration 72100, lr = 1e-05
I0628 22:28:08.982795 17220 solver.cpp:218] Iteration 72200 (27.5572 iter/s, 3.62882s/100 iters), loss = 0.155726
I0628 22:28:08.983301 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:28:08.983301 17220 solver.cpp:237]     Train net output #1: loss = 0.155726 (* 1 = 0.155726 loss)
I0628 22:28:08.983301 17220 sgd_solver.cpp:105] Iteration 72200, lr = 1e-05
I0628 22:28:12.612380 17220 solver.cpp:218] Iteration 72300 (27.556 iter/s, 3.62897s/100 iters), loss = 0.0423051
I0628 22:28:12.612380 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:28:12.612380 17220 solver.cpp:237]     Train net output #1: loss = 0.042306 (* 1 = 0.042306 loss)
I0628 22:28:12.612380 17220 sgd_solver.cpp:105] Iteration 72300, lr = 1e-05
I0628 22:28:16.233844 17220 solver.cpp:218] Iteration 72400 (27.6158 iter/s, 3.62111s/100 iters), loss = 0.0939374
I0628 22:28:16.233844 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:28:16.233844 17220 solver.cpp:237]     Train net output #1: loss = 0.0939383 (* 1 = 0.0939383 loss)
I0628 22:28:16.233844 17220 sgd_solver.cpp:105] Iteration 72400, lr = 1e-05
I0628 22:28:19.678896  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:28:19.818998 17220 solver.cpp:330] Iteration 72500, Testing net (#0)
I0628 22:28:19.818998 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:28:20.640223 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:28:20.671245 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0628 22:28:20.671245 17220 solver.cpp:397]     Test net output #1: loss = 0.371548 (* 1 = 0.371548 loss)
I0628 22:28:20.704771 17220 solver.cpp:218] Iteration 72500 (22.3685 iter/s, 4.47058s/100 iters), loss = 0.0755195
I0628 22:28:20.704771 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:28:20.704771 17220 solver.cpp:237]     Train net output #1: loss = 0.0755204 (* 1 = 0.0755204 loss)
I0628 22:28:20.704771 17220 sgd_solver.cpp:105] Iteration 72500, lr = 1e-05
I0628 22:28:24.324885 17220 solver.cpp:218] Iteration 72600 (27.6269 iter/s, 3.61966s/100 iters), loss = 0.172577
I0628 22:28:24.324885 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:28:24.324885 17220 solver.cpp:237]     Train net output #1: loss = 0.172578 (* 1 = 0.172578 loss)
I0628 22:28:24.324885 17220 sgd_solver.cpp:105] Iteration 72600, lr = 1e-05
I0628 22:28:27.940027 17220 solver.cpp:218] Iteration 72700 (27.665 iter/s, 3.61467s/100 iters), loss = 0.148731
I0628 22:28:27.940027 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:28:27.940027 17220 solver.cpp:237]     Train net output #1: loss = 0.148732 (* 1 = 0.148732 loss)
I0628 22:28:27.940027 17220 sgd_solver.cpp:105] Iteration 72700, lr = 1e-05
I0628 22:28:31.546147 17220 solver.cpp:218] Iteration 72800 (27.7324 iter/s, 3.60589s/100 iters), loss = 0.0806438
I0628 22:28:31.546147 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:28:31.546147 17220 solver.cpp:237]     Train net output #1: loss = 0.0806447 (* 1 = 0.0806447 loss)
I0628 22:28:31.546147 17220 sgd_solver.cpp:105] Iteration 72800, lr = 1e-05
I0628 22:28:35.162744 17220 solver.cpp:218] Iteration 72900 (27.6543 iter/s, 3.61607s/100 iters), loss = 0.0989934
I0628 22:28:35.162744 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:28:35.162744 17220 solver.cpp:237]     Train net output #1: loss = 0.0989943 (* 1 = 0.0989943 loss)
I0628 22:28:35.162744 17220 sgd_solver.cpp:105] Iteration 72900, lr = 1e-05
I0628 22:28:38.609287  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:28:38.749387 17220 solver.cpp:330] Iteration 73000, Testing net (#0)
I0628 22:28:38.749387 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:28:39.568478 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:28:39.599496 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8937
I0628 22:28:39.599496 17220 solver.cpp:397]     Test net output #1: loss = 0.371361 (* 1 = 0.371361 loss)
I0628 22:28:39.634516 17220 solver.cpp:218] Iteration 73000 (22.3643 iter/s, 4.4714s/100 iters), loss = 0.0671373
I0628 22:28:39.634516 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:28:39.634516 17220 solver.cpp:237]     Train net output #1: loss = 0.0671382 (* 1 = 0.0671382 loss)
I0628 22:28:39.634516 17220 sgd_solver.cpp:105] Iteration 73000, lr = 1e-05
I0628 22:28:43.252112 17220 solver.cpp:218] Iteration 73100 (27.6443 iter/s, 3.61738s/100 iters), loss = 0.193939
I0628 22:28:43.252112 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:28:43.252112 17220 solver.cpp:237]     Train net output #1: loss = 0.19394 (* 1 = 0.19394 loss)
I0628 22:28:43.252112 17220 sgd_solver.cpp:105] Iteration 73100, lr = 1e-05
I0628 22:28:46.868311 17220 solver.cpp:218] Iteration 73200 (27.6555 iter/s, 3.61592s/100 iters), loss = 0.130849
I0628 22:28:46.868311 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:28:46.868311 17220 solver.cpp:237]     Train net output #1: loss = 0.13085 (* 1 = 0.13085 loss)
I0628 22:28:46.868311 17220 sgd_solver.cpp:105] Iteration 73200, lr = 1e-05
I0628 22:28:50.500943 17220 solver.cpp:218] Iteration 73300 (27.5295 iter/s, 3.63246s/100 iters), loss = 0.113031
I0628 22:28:50.500943 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:28:50.500943 17220 solver.cpp:237]     Train net output #1: loss = 0.113032 (* 1 = 0.113032 loss)
I0628 22:28:50.501443 17220 sgd_solver.cpp:105] Iteration 73300, lr = 1e-05
I0628 22:28:54.110024 17220 solver.cpp:218] Iteration 73400 (27.7141 iter/s, 3.60827s/100 iters), loss = 0.0908165
I0628 22:28:54.110024 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:28:54.110024 17220 solver.cpp:237]     Train net output #1: loss = 0.0908175 (* 1 = 0.0908175 loss)
I0628 22:28:54.110024 17220 sgd_solver.cpp:105] Iteration 73400, lr = 1e-05
I0628 22:28:57.575032  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:28:57.715132 17220 solver.cpp:330] Iteration 73500, Testing net (#0)
I0628 22:28:57.715632 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:28:58.537216 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:28:58.568238 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8944
I0628 22:28:58.568238 17220 solver.cpp:397]     Test net output #1: loss = 0.37188 (* 1 = 0.37188 loss)
I0628 22:28:58.605767 17220 solver.cpp:218] Iteration 73500 (22.2435 iter/s, 4.49571s/100 iters), loss = 0.113486
I0628 22:28:58.605767 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:28:58.605767 17220 solver.cpp:237]     Train net output #1: loss = 0.113487 (* 1 = 0.113487 loss)
I0628 22:28:58.605767 17220 sgd_solver.cpp:105] Iteration 73500, lr = 1e-05
I0628 22:29:02.229949 17220 solver.cpp:218] Iteration 73600 (27.596 iter/s, 3.62372s/100 iters), loss = 0.19557
I0628 22:29:02.229949 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 22:29:02.229949 17220 solver.cpp:237]     Train net output #1: loss = 0.195571 (* 1 = 0.195571 loss)
I0628 22:29:02.229949 17220 sgd_solver.cpp:105] Iteration 73600, lr = 1e-05
I0628 22:29:05.833523 17220 solver.cpp:218] Iteration 73700 (27.7525 iter/s, 3.60328s/100 iters), loss = 0.166459
I0628 22:29:05.833523 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:29:05.833523 17220 solver.cpp:237]     Train net output #1: loss = 0.16646 (* 1 = 0.16646 loss)
I0628 22:29:05.833523 17220 sgd_solver.cpp:105] Iteration 73700, lr = 1e-05
I0628 22:29:09.460139 17220 solver.cpp:218] Iteration 73800 (27.5764 iter/s, 3.62629s/100 iters), loss = 0.0933943
I0628 22:29:09.460139 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:29:09.460139 17220 solver.cpp:237]     Train net output #1: loss = 0.0933953 (* 1 = 0.0933953 loss)
I0628 22:29:09.460139 17220 sgd_solver.cpp:105] Iteration 73800, lr = 1e-05
I0628 22:29:13.092660 17220 solver.cpp:218] Iteration 73900 (27.5332 iter/s, 3.63198s/100 iters), loss = 0.0578226
I0628 22:29:13.092660 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:29:13.092660 17220 solver.cpp:237]     Train net output #1: loss = 0.0578236 (* 1 = 0.0578236 loss)
I0628 22:29:13.092660 17220 sgd_solver.cpp:105] Iteration 73900, lr = 1e-05
I0628 22:29:16.539153  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:29:16.681270 17220 solver.cpp:330] Iteration 74000, Testing net (#0)
I0628 22:29:16.681771 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:29:17.507844 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:29:17.538878 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8941
I0628 22:29:17.538878 17220 solver.cpp:397]     Test net output #1: loss = 0.37212 (* 1 = 0.37212 loss)
I0628 22:29:17.572890 17220 solver.cpp:218] Iteration 74000 (22.3224 iter/s, 4.4798s/100 iters), loss = 0.108998
I0628 22:29:17.572890 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:29:17.572890 17220 solver.cpp:237]     Train net output #1: loss = 0.108999 (* 1 = 0.108999 loss)
I0628 22:29:17.572890 17220 sgd_solver.cpp:46] MultiStep Status: Iteration 74000, step = 4
I0628 22:29:17.572890 17220 sgd_solver.cpp:105] Iteration 74000, lr = 1e-06
I0628 22:29:21.201972 17220 solver.cpp:218] Iteration 74100 (27.5584 iter/s, 3.62866s/100 iters), loss = 0.11553
I0628 22:29:21.201972 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:29:21.201972 17220 solver.cpp:237]     Train net output #1: loss = 0.115531 (* 1 = 0.115531 loss)
I0628 22:29:21.201972 17220 sgd_solver.cpp:105] Iteration 74100, lr = 1e-06
I0628 22:29:24.837570 17220 solver.cpp:218] Iteration 74200 (27.5086 iter/s, 3.63522s/100 iters), loss = 0.104356
I0628 22:29:24.837570 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:29:24.837570 17220 solver.cpp:237]     Train net output #1: loss = 0.104357 (* 1 = 0.104357 loss)
I0628 22:29:24.837570 17220 sgd_solver.cpp:105] Iteration 74200, lr = 1e-06
I0628 22:29:28.473655 17220 solver.cpp:218] Iteration 74300 (27.504 iter/s, 3.63584s/100 iters), loss = 0.088715
I0628 22:29:28.473655 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:29:28.473655 17220 solver.cpp:237]     Train net output #1: loss = 0.0887159 (* 1 = 0.0887159 loss)
I0628 22:29:28.473655 17220 sgd_solver.cpp:105] Iteration 74300, lr = 1e-06
I0628 22:29:32.103229 17220 solver.cpp:218] Iteration 74400 (27.552 iter/s, 3.62949s/100 iters), loss = 0.0989389
I0628 22:29:32.103229 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:29:32.103229 17220 solver.cpp:237]     Train net output #1: loss = 0.0989398 (* 1 = 0.0989398 loss)
I0628 22:29:32.103229 17220 sgd_solver.cpp:105] Iteration 74400, lr = 1e-06
I0628 22:29:35.552898  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:29:35.693998 17220 solver.cpp:330] Iteration 74500, Testing net (#0)
I0628 22:29:35.693998 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:29:36.522588 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:29:36.553120 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0628 22:29:36.553120 17220 solver.cpp:397]     Test net output #1: loss = 0.372106 (* 1 = 0.372106 loss)
I0628 22:29:36.588135 17220 solver.cpp:218] Iteration 74500 (22.3004 iter/s, 4.48423s/100 iters), loss = 0.0911806
I0628 22:29:36.588135 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:29:36.588135 17220 solver.cpp:237]     Train net output #1: loss = 0.0911816 (* 1 = 0.0911816 loss)
I0628 22:29:36.588135 17220 sgd_solver.cpp:105] Iteration 74500, lr = 1e-06
I0628 22:29:40.196238 17220 solver.cpp:218] Iteration 74600 (27.7196 iter/s, 3.60755s/100 iters), loss = 0.14649
I0628 22:29:40.196238 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:29:40.196238 17220 solver.cpp:237]     Train net output #1: loss = 0.146491 (* 1 = 0.146491 loss)
I0628 22:29:40.196238 17220 sgd_solver.cpp:105] Iteration 74600, lr = 1e-06
I0628 22:29:43.807838 17220 solver.cpp:218] Iteration 74700 (27.6894 iter/s, 3.61149s/100 iters), loss = 0.11358
I0628 22:29:43.807838 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:29:43.807838 17220 solver.cpp:237]     Train net output #1: loss = 0.113581 (* 1 = 0.113581 loss)
I0628 22:29:43.807838 17220 sgd_solver.cpp:105] Iteration 74700, lr = 1e-06
I0628 22:29:47.412499 17220 solver.cpp:218] Iteration 74800 (27.7464 iter/s, 3.60407s/100 iters), loss = 0.128852
I0628 22:29:47.412499 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:29:47.412499 17220 solver.cpp:237]     Train net output #1: loss = 0.128853 (* 1 = 0.128853 loss)
I0628 22:29:47.412499 17220 sgd_solver.cpp:105] Iteration 74800, lr = 1e-06
I0628 22:29:51.030073 17220 solver.cpp:218] Iteration 74900 (27.6438 iter/s, 3.61744s/100 iters), loss = 0.0996213
I0628 22:29:51.030073 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:29:51.030073 17220 solver.cpp:237]     Train net output #1: loss = 0.0996223 (* 1 = 0.0996223 loss)
I0628 22:29:51.030073 17220 sgd_solver.cpp:105] Iteration 74900, lr = 1e-06
I0628 22:29:54.466972  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:29:54.607071 17220 solver.cpp:330] Iteration 75000, Testing net (#0)
I0628 22:29:54.607071 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:29:55.430193 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:29:55.461716 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8941
I0628 22:29:55.461716 17220 solver.cpp:397]     Test net output #1: loss = 0.372243 (* 1 = 0.372243 loss)
I0628 22:29:55.496242 17220 solver.cpp:218] Iteration 75000 (22.3934 iter/s, 4.46559s/100 iters), loss = 0.0747311
I0628 22:29:55.496242 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:29:55.496242 17220 solver.cpp:237]     Train net output #1: loss = 0.074732 (* 1 = 0.074732 loss)
I0628 22:29:55.496242 17220 sgd_solver.cpp:105] Iteration 75000, lr = 1e-06
I0628 22:29:59.108310 17220 solver.cpp:218] Iteration 75100 (27.6863 iter/s, 3.6119s/100 iters), loss = 0.14437
I0628 22:29:59.108310 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:29:59.108310 17220 solver.cpp:237]     Train net output #1: loss = 0.144371 (* 1 = 0.144371 loss)
I0628 22:29:59.108310 17220 sgd_solver.cpp:105] Iteration 75100, lr = 1e-06
I0628 22:30:02.751962 17220 solver.cpp:218] Iteration 75200 (27.4463 iter/s, 3.64347s/100 iters), loss = 0.13968
I0628 22:30:02.752462 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:30:02.752462 17220 solver.cpp:237]     Train net output #1: loss = 0.139681 (* 1 = 0.139681 loss)
I0628 22:30:02.752462 17220 sgd_solver.cpp:105] Iteration 75200, lr = 1e-06
I0628 22:30:06.381122 17220 solver.cpp:218] Iteration 75300 (27.5596 iter/s, 3.62851s/100 iters), loss = 0.135465
I0628 22:30:06.381122 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:30:06.381122 17220 solver.cpp:237]     Train net output #1: loss = 0.135466 (* 1 = 0.135466 loss)
I0628 22:30:06.381122 17220 sgd_solver.cpp:105] Iteration 75300, lr = 1e-06
I0628 22:30:10.016413 17220 solver.cpp:218] Iteration 75400 (27.5116 iter/s, 3.63483s/100 iters), loss = 0.0989002
I0628 22:30:10.016413 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:30:10.016413 17220 solver.cpp:237]     Train net output #1: loss = 0.0989012 (* 1 = 0.0989012 loss)
I0628 22:30:10.016413 17220 sgd_solver.cpp:105] Iteration 75400, lr = 1e-06
I0628 22:30:13.478878  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:30:13.620978 17220 solver.cpp:330] Iteration 75500, Testing net (#0)
I0628 22:30:13.620978 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:30:14.446565 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:30:14.477087 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0628 22:30:14.477087 17220 solver.cpp:397]     Test net output #1: loss = 0.372599 (* 1 = 0.372599 loss)
I0628 22:30:14.511611 17220 solver.cpp:218] Iteration 75500 (22.2482 iter/s, 4.49474s/100 iters), loss = 0.0700406
I0628 22:30:14.511611 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:30:14.511611 17220 solver.cpp:237]     Train net output #1: loss = 0.0700415 (* 1 = 0.0700415 loss)
I0628 22:30:14.511611 17220 sgd_solver.cpp:105] Iteration 75500, lr = 1e-06
I0628 22:30:18.150200 17220 solver.cpp:218] Iteration 75600 (27.4865 iter/s, 3.63814s/100 iters), loss = 0.187696
I0628 22:30:18.150200 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:30:18.150200 17220 solver.cpp:237]     Train net output #1: loss = 0.187697 (* 1 = 0.187697 loss)
I0628 22:30:18.150200 17220 sgd_solver.cpp:105] Iteration 75600, lr = 1e-06
I0628 22:30:21.790357 17220 solver.cpp:218] Iteration 75700 (27.4716 iter/s, 3.64013s/100 iters), loss = 0.0947181
I0628 22:30:21.790357 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:30:21.790357 17220 solver.cpp:237]     Train net output #1: loss = 0.0947191 (* 1 = 0.0947191 loss)
I0628 22:30:21.790357 17220 sgd_solver.cpp:105] Iteration 75700, lr = 1e-06
I0628 22:30:25.420450 17220 solver.cpp:218] Iteration 75800 (27.5527 iter/s, 3.62941s/100 iters), loss = 0.133394
I0628 22:30:25.420450 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:30:25.420450 17220 solver.cpp:237]     Train net output #1: loss = 0.133395 (* 1 = 0.133395 loss)
I0628 22:30:25.420450 17220 sgd_solver.cpp:105] Iteration 75800, lr = 1e-06
I0628 22:30:29.054025 17220 solver.cpp:218] Iteration 75900 (27.5225 iter/s, 3.63339s/100 iters), loss = 0.0848998
I0628 22:30:29.054025 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:30:29.054025 17220 solver.cpp:237]     Train net output #1: loss = 0.0849008 (* 1 = 0.0849008 loss)
I0628 22:30:29.054025 17220 sgd_solver.cpp:105] Iteration 75900, lr = 1e-06
I0628 22:30:32.508985  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:30:32.654099 17220 solver.cpp:330] Iteration 76000, Testing net (#0)
I0628 22:30:32.654099 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:30:33.477226 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:30:33.508235 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8934
I0628 22:30:33.508235 17220 solver.cpp:397]     Test net output #1: loss = 0.372156 (* 1 = 0.372156 loss)
I0628 22:30:33.542258 17220 solver.cpp:218] Iteration 76000 (22.2822 iter/s, 4.48788s/100 iters), loss = 0.10952
I0628 22:30:33.542258 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:30:33.542258 17220 solver.cpp:237]     Train net output #1: loss = 0.109521 (* 1 = 0.109521 loss)
I0628 22:30:33.542258 17220 sgd_solver.cpp:105] Iteration 76000, lr = 1e-06
I0628 22:30:37.181602 17220 solver.cpp:218] Iteration 76100 (27.4804 iter/s, 3.63896s/100 iters), loss = 0.157989
I0628 22:30:37.181602 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:30:37.181602 17220 solver.cpp:237]     Train net output #1: loss = 0.15799 (* 1 = 0.15799 loss)
I0628 22:30:37.181602 17220 sgd_solver.cpp:105] Iteration 76100, lr = 1e-06
I0628 22:30:40.810184 17220 solver.cpp:218] Iteration 76200 (27.5602 iter/s, 3.62842s/100 iters), loss = 0.146739
I0628 22:30:40.810684 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:30:40.810684 17220 solver.cpp:237]     Train net output #1: loss = 0.14674 (* 1 = 0.14674 loss)
I0628 22:30:40.810684 17220 sgd_solver.cpp:105] Iteration 76200, lr = 1e-06
I0628 22:30:44.434274 17220 solver.cpp:218] Iteration 76300 (27.5979 iter/s, 3.62346s/100 iters), loss = 0.119809
I0628 22:30:44.434274 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:30:44.434274 17220 solver.cpp:237]     Train net output #1: loss = 0.11981 (* 1 = 0.11981 loss)
I0628 22:30:44.434274 17220 sgd_solver.cpp:105] Iteration 76300, lr = 1e-06
I0628 22:30:48.057340 17220 solver.cpp:218] Iteration 76400 (27.6037 iter/s, 3.62271s/100 iters), loss = 0.0541855
I0628 22:30:48.057340 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:30:48.057340 17220 solver.cpp:237]     Train net output #1: loss = 0.0541865 (* 1 = 0.0541865 loss)
I0628 22:30:48.057340 17220 sgd_solver.cpp:105] Iteration 76400, lr = 1e-06
I0628 22:30:51.498289  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:30:51.639405 17220 solver.cpp:330] Iteration 76500, Testing net (#0)
I0628 22:30:51.639405 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:30:52.460472 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:30:52.491519 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0628 22:30:52.491519 17220 solver.cpp:397]     Test net output #1: loss = 0.37261 (* 1 = 0.37261 loss)
I0628 22:30:52.526029 17220 solver.cpp:218] Iteration 76500 (22.3805 iter/s, 4.46817s/100 iters), loss = 0.110693
I0628 22:30:52.526029 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:30:52.526029 17220 solver.cpp:237]     Train net output #1: loss = 0.110694 (* 1 = 0.110694 loss)
I0628 22:30:52.526029 17220 sgd_solver.cpp:105] Iteration 76500, lr = 1e-06
I0628 22:30:56.146632 17220 solver.cpp:218] Iteration 76600 (27.622 iter/s, 3.6203s/100 iters), loss = 0.207855
I0628 22:30:56.146632 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:30:56.146632 17220 solver.cpp:237]     Train net output #1: loss = 0.207856 (* 1 = 0.207856 loss)
I0628 22:30:56.146632 17220 sgd_solver.cpp:105] Iteration 76600, lr = 1e-06
I0628 22:30:59.770200 17220 solver.cpp:218] Iteration 76700 (27.5996 iter/s, 3.62324s/100 iters), loss = 0.123573
I0628 22:30:59.770200 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:30:59.770200 17220 solver.cpp:237]     Train net output #1: loss = 0.123574 (* 1 = 0.123574 loss)
I0628 22:30:59.770200 17220 sgd_solver.cpp:105] Iteration 76700, lr = 1e-06
I0628 22:31:03.400795 17220 solver.cpp:218] Iteration 76800 (27.5465 iter/s, 3.63023s/100 iters), loss = 0.130799
I0628 22:31:03.400795 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:31:03.400795 17220 solver.cpp:237]     Train net output #1: loss = 0.1308 (* 1 = 0.1308 loss)
I0628 22:31:03.400795 17220 sgd_solver.cpp:105] Iteration 76800, lr = 1e-06
I0628 22:31:07.032378 17220 solver.cpp:218] Iteration 76900 (27.5389 iter/s, 3.63123s/100 iters), loss = 0.0813301
I0628 22:31:07.032378 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:31:07.032378 17220 solver.cpp:237]     Train net output #1: loss = 0.081331 (* 1 = 0.081331 loss)
I0628 22:31:07.032378 17220 sgd_solver.cpp:105] Iteration 76900, lr = 1e-06
I0628 22:31:10.486825  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:31:10.628442 17220 solver.cpp:330] Iteration 77000, Testing net (#0)
I0628 22:31:10.628442 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:31:11.448508 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:31:11.479532 17220 solver.cpp:397]     Test net output #0: accuracy = 0.894
I0628 22:31:11.479532 17220 solver.cpp:397]     Test net output #1: loss = 0.371968 (* 1 = 0.371968 loss)
I0628 22:31:11.513068 17220 solver.cpp:218] Iteration 77000 (22.3187 iter/s, 4.48055s/100 iters), loss = 0.0703046
I0628 22:31:11.513068 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:31:11.513068 17220 solver.cpp:237]     Train net output #1: loss = 0.0703056 (* 1 = 0.0703056 loss)
I0628 22:31:11.513068 17220 sgd_solver.cpp:105] Iteration 77000, lr = 1e-06
I0628 22:31:15.134671 17220 solver.cpp:218] Iteration 77100 (27.6168 iter/s, 3.62099s/100 iters), loss = 0.215713
I0628 22:31:15.134671 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:31:15.134671 17220 solver.cpp:237]     Train net output #1: loss = 0.215714 (* 1 = 0.215714 loss)
I0628 22:31:15.134671 17220 sgd_solver.cpp:105] Iteration 77100, lr = 1e-06
I0628 22:31:18.756770 17220 solver.cpp:218] Iteration 77200 (27.608 iter/s, 3.62213s/100 iters), loss = 0.130705
I0628 22:31:18.757278 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:31:18.757278 17220 solver.cpp:237]     Train net output #1: loss = 0.130706 (* 1 = 0.130706 loss)
I0628 22:31:18.757278 17220 sgd_solver.cpp:105] Iteration 77200, lr = 1e-06
I0628 22:31:22.383430 17220 solver.cpp:218] Iteration 77300 (27.5773 iter/s, 3.62617s/100 iters), loss = 0.111387
I0628 22:31:22.383430 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:31:22.383931 17220 solver.cpp:237]     Train net output #1: loss = 0.111388 (* 1 = 0.111388 loss)
I0628 22:31:22.383931 17220 sgd_solver.cpp:105] Iteration 77300, lr = 1e-06
I0628 22:31:26.008021 17220 solver.cpp:218] Iteration 77400 (27.5936 iter/s, 3.62403s/100 iters), loss = 0.106867
I0628 22:31:26.008021 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:31:26.008021 17220 solver.cpp:237]     Train net output #1: loss = 0.106868 (* 1 = 0.106868 loss)
I0628 22:31:26.008021 17220 sgd_solver.cpp:105] Iteration 77400, lr = 1e-06
I0628 22:31:29.454962  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:31:29.596063 17220 solver.cpp:330] Iteration 77500, Testing net (#0)
I0628 22:31:29.596563 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:31:30.419662 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:31:30.450670 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8941
I0628 22:31:30.450670 17220 solver.cpp:397]     Test net output #1: loss = 0.37141 (* 1 = 0.37141 loss)
I0628 22:31:30.485195 17220 solver.cpp:218] Iteration 77500 (22.3386 iter/s, 4.47656s/100 iters), loss = 0.0881239
I0628 22:31:30.485195 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:31:30.485195 17220 solver.cpp:237]     Train net output #1: loss = 0.0881249 (* 1 = 0.0881249 loss)
I0628 22:31:30.485195 17220 sgd_solver.cpp:105] Iteration 77500, lr = 1e-06
I0628 22:31:34.110848 17220 solver.cpp:218] Iteration 77600 (27.5817 iter/s, 3.62559s/100 iters), loss = 0.199016
I0628 22:31:34.110848 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:31:34.110848 17220 solver.cpp:237]     Train net output #1: loss = 0.199017 (* 1 = 0.199017 loss)
I0628 22:31:34.110848 17220 sgd_solver.cpp:105] Iteration 77600, lr = 1e-06
I0628 22:31:37.732964 17220 solver.cpp:218] Iteration 77700 (27.6124 iter/s, 3.62156s/100 iters), loss = 0.120049
I0628 22:31:37.732964 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:31:37.732964 17220 solver.cpp:237]     Train net output #1: loss = 0.12005 (* 1 = 0.12005 loss)
I0628 22:31:37.732964 17220 sgd_solver.cpp:105] Iteration 77700, lr = 1e-06
I0628 22:31:41.357041 17220 solver.cpp:218] Iteration 77800 (27.5946 iter/s, 3.6239s/100 iters), loss = 0.0815834
I0628 22:31:41.357041 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:31:41.357041 17220 solver.cpp:237]     Train net output #1: loss = 0.0815844 (* 1 = 0.0815844 loss)
I0628 22:31:41.357041 17220 sgd_solver.cpp:105] Iteration 77800, lr = 1e-06
I0628 22:31:44.997196 17220 solver.cpp:218] Iteration 77900 (27.4772 iter/s, 3.63938s/100 iters), loss = 0.0697013
I0628 22:31:44.997196 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:31:44.997196 17220 solver.cpp:237]     Train net output #1: loss = 0.0697022 (* 1 = 0.0697022 loss)
I0628 22:31:44.997196 17220 sgd_solver.cpp:105] Iteration 77900, lr = 1e-06
I0628 22:31:48.453660  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:31:48.594761 17220 solver.cpp:330] Iteration 78000, Testing net (#0)
I0628 22:31:48.594761 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:31:49.423863 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:31:49.454871 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8941
I0628 22:31:49.454871 17220 solver.cpp:397]     Test net output #1: loss = 0.371851 (* 1 = 0.371851 loss)
I0628 22:31:49.489395 17220 solver.cpp:218] Iteration 78000 (22.2618 iter/s, 4.492s/100 iters), loss = 0.099345
I0628 22:31:49.489395 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:31:49.489395 17220 solver.cpp:237]     Train net output #1: loss = 0.099346 (* 1 = 0.099346 loss)
I0628 22:31:49.489395 17220 sgd_solver.cpp:105] Iteration 78000, lr = 1e-06
I0628 22:31:53.109472 17220 solver.cpp:218] Iteration 78100 (27.6266 iter/s, 3.6197s/100 iters), loss = 0.155358
I0628 22:31:53.109472 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 22:31:53.109472 17220 solver.cpp:237]     Train net output #1: loss = 0.155359 (* 1 = 0.155359 loss)
I0628 22:31:53.109472 17220 sgd_solver.cpp:105] Iteration 78100, lr = 1e-06
I0628 22:31:56.748692 17220 solver.cpp:218] Iteration 78200 (27.481 iter/s, 3.63887s/100 iters), loss = 0.096321
I0628 22:31:56.748692 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:31:56.748692 17220 solver.cpp:237]     Train net output #1: loss = 0.096322 (* 1 = 0.096322 loss)
I0628 22:31:56.748692 17220 sgd_solver.cpp:105] Iteration 78200, lr = 1e-06
I0628 22:32:00.366278 17220 solver.cpp:218] Iteration 78300 (27.646 iter/s, 3.61716s/100 iters), loss = 0.119053
I0628 22:32:00.366278 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:32:00.366278 17220 solver.cpp:237]     Train net output #1: loss = 0.119054 (* 1 = 0.119054 loss)
I0628 22:32:00.366278 17220 sgd_solver.cpp:105] Iteration 78300, lr = 1e-06
I0628 22:32:03.988205 17220 solver.cpp:218] Iteration 78400 (27.6122 iter/s, 3.62159s/100 iters), loss = 0.0802362
I0628 22:32:03.988205 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:32:03.988205 17220 solver.cpp:237]     Train net output #1: loss = 0.0802372 (* 1 = 0.0802372 loss)
I0628 22:32:03.988205 17220 sgd_solver.cpp:105] Iteration 78400, lr = 1e-06
I0628 22:32:07.452462  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:32:07.594105 17220 solver.cpp:330] Iteration 78500, Testing net (#0)
I0628 22:32:07.594105 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:32:08.414188 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:32:08.445210 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0628 22:32:08.445210 17220 solver.cpp:397]     Test net output #1: loss = 0.372414 (* 1 = 0.372414 loss)
I0628 22:32:08.479735 17220 solver.cpp:218] Iteration 78500 (22.266 iter/s, 4.49115s/100 iters), loss = 0.087575
I0628 22:32:08.479735 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:32:08.479735 17220 solver.cpp:237]     Train net output #1: loss = 0.087576 (* 1 = 0.087576 loss)
I0628 22:32:08.479735 17220 sgd_solver.cpp:105] Iteration 78500, lr = 1e-06
I0628 22:32:12.086418 17220 solver.cpp:218] Iteration 78600 (27.7293 iter/s, 3.6063s/100 iters), loss = 0.122052
I0628 22:32:12.086418 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:32:12.086418 17220 solver.cpp:237]     Train net output #1: loss = 0.122053 (* 1 = 0.122053 loss)
I0628 22:32:12.086418 17220 sgd_solver.cpp:105] Iteration 78600, lr = 1e-06
I0628 22:32:15.693298 17220 solver.cpp:218] Iteration 78700 (27.7247 iter/s, 3.6069s/100 iters), loss = 0.1238
I0628 22:32:15.693799 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:32:15.693799 17220 solver.cpp:237]     Train net output #1: loss = 0.123801 (* 1 = 0.123801 loss)
I0628 22:32:15.693799 17220 sgd_solver.cpp:105] Iteration 78700, lr = 1e-06
I0628 22:32:19.315348 17220 solver.cpp:218] Iteration 78800 (27.6123 iter/s, 3.62157s/100 iters), loss = 0.0959224
I0628 22:32:19.315348 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:32:19.315348 17220 solver.cpp:237]     Train net output #1: loss = 0.0959234 (* 1 = 0.0959234 loss)
I0628 22:32:19.315348 17220 sgd_solver.cpp:105] Iteration 78800, lr = 1e-06
I0628 22:32:22.947588 17220 solver.cpp:218] Iteration 78900 (27.5336 iter/s, 3.63193s/100 iters), loss = 0.0688888
I0628 22:32:22.948091 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 22:32:22.948091 17220 solver.cpp:237]     Train net output #1: loss = 0.0688898 (* 1 = 0.0688898 loss)
I0628 22:32:22.948091 17220 sgd_solver.cpp:105] Iteration 78900, lr = 1e-06
I0628 22:32:26.406038  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:32:26.548154 17220 solver.cpp:330] Iteration 79000, Testing net (#0)
I0628 22:32:26.548154 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:32:27.372740 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:32:27.404263 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0628 22:32:27.404263 17220 solver.cpp:397]     Test net output #1: loss = 0.371816 (* 1 = 0.371816 loss)
I0628 22:32:27.438783 17220 solver.cpp:218] Iteration 79000 (22.2682 iter/s, 4.49071s/100 iters), loss = 0.0816588
I0628 22:32:27.438783 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:32:27.438783 17220 solver.cpp:237]     Train net output #1: loss = 0.0816598 (* 1 = 0.0816598 loss)
I0628 22:32:27.438783 17220 sgd_solver.cpp:105] Iteration 79000, lr = 1e-06
I0628 22:32:31.075362 17220 solver.cpp:218] Iteration 79100 (27.5006 iter/s, 3.63628s/100 iters), loss = 0.143156
I0628 22:32:31.075362 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:32:31.075362 17220 solver.cpp:237]     Train net output #1: loss = 0.143157 (* 1 = 0.143157 loss)
I0628 22:32:31.075362 17220 sgd_solver.cpp:105] Iteration 79100, lr = 1e-06
I0628 22:32:34.704352 17220 solver.cpp:218] Iteration 79200 (27.5611 iter/s, 3.6283s/100 iters), loss = 0.137389
I0628 22:32:34.704352 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:32:34.704352 17220 solver.cpp:237]     Train net output #1: loss = 0.13739 (* 1 = 0.13739 loss)
I0628 22:32:34.704352 17220 sgd_solver.cpp:105] Iteration 79200, lr = 1e-06
I0628 22:32:38.343498 17220 solver.cpp:218] Iteration 79300 (27.4817 iter/s, 3.63879s/100 iters), loss = 0.0806677
I0628 22:32:38.343498 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 22:32:38.343498 17220 solver.cpp:237]     Train net output #1: loss = 0.0806687 (* 1 = 0.0806687 loss)
I0628 22:32:38.343498 17220 sgd_solver.cpp:105] Iteration 79300, lr = 1e-06
I0628 22:32:41.979053 17220 solver.cpp:218] Iteration 79400 (27.5067 iter/s, 3.63547s/100 iters), loss = 0.078751
I0628 22:32:41.979053 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:32:41.979053 17220 solver.cpp:237]     Train net output #1: loss = 0.078752 (* 1 = 0.078752 loss)
I0628 22:32:41.979053 17220 sgd_solver.cpp:105] Iteration 79400, lr = 1e-06
I0628 22:32:45.439515  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:32:45.581116 17220 solver.cpp:330] Iteration 79500, Testing net (#0)
I0628 22:32:45.581116 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:32:46.403201 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:32:46.433724 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0628 22:32:46.433724 17220 solver.cpp:397]     Test net output #1: loss = 0.371681 (* 1 = 0.371681 loss)
I0628 22:32:46.468247 17220 solver.cpp:218] Iteration 79500 (22.279 iter/s, 4.48854s/100 iters), loss = 0.109025
I0628 22:32:46.468247 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 22:32:46.468247 17220 solver.cpp:237]     Train net output #1: loss = 0.109026 (* 1 = 0.109026 loss)
I0628 22:32:46.468247 17220 sgd_solver.cpp:105] Iteration 79500, lr = 1e-06
I0628 22:32:50.096328 17220 solver.cpp:218] Iteration 79600 (27.5659 iter/s, 3.62767s/100 iters), loss = 0.128592
I0628 22:32:50.096328 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:32:50.096328 17220 solver.cpp:237]     Train net output #1: loss = 0.128593 (* 1 = 0.128593 loss)
I0628 22:32:50.096328 17220 sgd_solver.cpp:105] Iteration 79600, lr = 1e-06
I0628 22:32:53.726411 17220 solver.cpp:218] Iteration 79700 (27.5504 iter/s, 3.62971s/100 iters), loss = 0.111459
I0628 22:32:53.726411 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 22:32:53.726411 17220 solver.cpp:237]     Train net output #1: loss = 0.11146 (* 1 = 0.11146 loss)
I0628 22:32:53.726411 17220 sgd_solver.cpp:105] Iteration 79700, lr = 1e-06
I0628 22:32:57.346500 17220 solver.cpp:218] Iteration 79800 (27.6243 iter/s, 3.62s/100 iters), loss = 0.130516
I0628 22:32:57.346500 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 22:32:57.346500 17220 solver.cpp:237]     Train net output #1: loss = 0.130517 (* 1 = 0.130517 loss)
I0628 22:32:57.346500 17220 sgd_solver.cpp:105] Iteration 79800, lr = 1e-06
I0628 22:33:00.977679 17220 solver.cpp:218] Iteration 79900 (27.5442 iter/s, 3.63053s/100 iters), loss = 0.128366
I0628 22:33:00.977679 17220 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 22:33:00.977679 17220 solver.cpp:237]     Train net output #1: loss = 0.128367 (* 1 = 0.128367 loss)
I0628 22:33:00.977679 17220 sgd_solver.cpp:105] Iteration 79900, lr = 1e-06
I0628 22:33:04.428623  9296 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:33:04.569223 17220 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/128K_iter_80000.caffemodel
I0628 22:33:04.579231 17220 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/128K_iter_80000.solverstate
I0628 22:33:04.590239 17220 solver.cpp:310] Iteration 80000, loss = 0.0631905
I0628 22:33:04.590239 17220 solver.cpp:330] Iteration 80000, Testing net (#0)
I0628 22:33:04.590239 17220 net.cpp:676] Ignoring source layer accuracy_training
I0628 22:33:05.411823 10900 data_layer.cpp:73] Restarting data prefetching from start.
I0628 22:33:05.442845 17220 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0628 22:33:05.442845 17220 solver.cpp:397]     Test net output #1: loss = 0.371596 (* 1 = 0.371596 loss)
I0628 22:33:05.442845 17220 solver.cpp:315] Optimization Done.
I0628 22:33:05.442845 17220 caffe.cpp:260] Optimization Done.
G:\Caffe>