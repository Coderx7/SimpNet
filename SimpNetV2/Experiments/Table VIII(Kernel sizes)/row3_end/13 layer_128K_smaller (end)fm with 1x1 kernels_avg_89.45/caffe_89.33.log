
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0628 20:36:55.252830  6212 caffe.cpp:219] Using GPUs 0
I0628 20:36:55.443409  6212 caffe.cpp:224] GPU 0: GeForce GTX 1080
I0628 20:36:55.777170  6212 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 20:36:55.791206  6212 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 80000
snapshot_prefix: "examples/cifar10/128K"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 32000
stepvalue: 48000
stepvalue: 54000
stepvalue: 74000
type: "Nesterov"
I0628 20:36:55.792207  6212 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 20:36:55.793207  6212 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 20:36:55.793207  6212 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp4
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp5
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp6
I0628 20:36:55.793207  6212 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0628 20:36:55.793207  6212 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_13_128k_end1x1"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_12"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_12"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 53
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "conv4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 53
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp4"
  type: "Scale"
  bottom: "cccp4"
  top: "cccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "cccp4"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "pool4_2"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp5"
  type: "Scale"
  bottom: "cccp5"
  top: "cccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp6"
  type: "Scale"
  bottom: "cccp6"
  top: "cccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0628 20:36:55.794209  6212 layer_factory.cpp:58] Creating layer cifar
I0628 20:36:55.799206  6212 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I0628 20:36:55.800200  6212 net.cpp:84] Creating Layer cifar
I0628 20:36:55.800200  6212 net.cpp:380] cifar -> data
I0628 20:36:55.800200  6212 net.cpp:380] cifar -> label
I0628 20:36:55.800200  6212 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 20:36:55.800200  6212 data_layer.cpp:45] output data size: 100,3,32,32
I0628 20:36:55.806213  6212 net.cpp:122] Setting up cifar
I0628 20:36:55.806213  6212 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0628 20:36:55.806213  6212 net.cpp:129] Top shape: 100 (100)
I0628 20:36:55.806213  6212 net.cpp:137] Memory required for data: 1229200
I0628 20:36:55.806213  6212 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0628 20:36:55.806213  6212 net.cpp:84] Creating Layer label_cifar_1_split
I0628 20:36:55.806213  6212 net.cpp:406] label_cifar_1_split <- label
I0628 20:36:55.806213  6212 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0628 20:36:55.806213  6212 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0628 20:36:55.806213  6212 net.cpp:122] Setting up label_cifar_1_split
I0628 20:36:55.806213  6212 net.cpp:129] Top shape: 100 (100)
I0628 20:36:55.806213  6212 net.cpp:129] Top shape: 100 (100)
I0628 20:36:55.806213  6212 net.cpp:137] Memory required for data: 1230000
I0628 20:36:55.806213  6212 layer_factory.cpp:58] Creating layer conv1
I0628 20:36:55.806213  6212 net.cpp:84] Creating Layer conv1
I0628 20:36:55.806213  6212 net.cpp:406] conv1 <- data
I0628 20:36:55.806213  6212 net.cpp:380] conv1 -> conv1
I0628 20:36:55.806213 15016 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 20:36:56.039170  6212 net.cpp:122] Setting up conv1
I0628 20:36:56.039170  6212 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 20:36:56.039170  6212 net.cpp:137] Memory required for data: 9012400
I0628 20:36:56.039170  6212 layer_factory.cpp:58] Creating layer bn1
I0628 20:36:56.039170  6212 net.cpp:84] Creating Layer bn1
I0628 20:36:56.039170  6212 net.cpp:406] bn1 <- conv1
I0628 20:36:56.039170  6212 net.cpp:367] bn1 -> conv1 (in-place)
I0628 20:36:56.040174  6212 net.cpp:122] Setting up bn1
I0628 20:36:56.040174  6212 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 20:36:56.040174  6212 net.cpp:137] Memory required for data: 16794800
I0628 20:36:56.040174  6212 layer_factory.cpp:58] Creating layer scale1
I0628 20:36:56.040174  6212 net.cpp:84] Creating Layer scale1
I0628 20:36:56.040174  6212 net.cpp:406] scale1 <- conv1
I0628 20:36:56.040174  6212 net.cpp:367] scale1 -> conv1 (in-place)
I0628 20:36:56.040174  6212 layer_factory.cpp:58] Creating layer scale1
I0628 20:36:56.040174  6212 net.cpp:122] Setting up scale1
I0628 20:36:56.040174  6212 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 20:36:56.040174  6212 net.cpp:137] Memory required for data: 24577200
I0628 20:36:56.040174  6212 layer_factory.cpp:58] Creating layer relu1
I0628 20:36:56.040174  6212 net.cpp:84] Creating Layer relu1
I0628 20:36:56.040174  6212 net.cpp:406] relu1 <- conv1
I0628 20:36:56.040174  6212 net.cpp:367] relu1 -> conv1 (in-place)
I0628 20:36:56.040174  6212 net.cpp:122] Setting up relu1
I0628 20:36:56.040174  6212 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 20:36:56.040174  6212 net.cpp:137] Memory required for data: 32359600
I0628 20:36:56.040174  6212 layer_factory.cpp:58] Creating layer conv1_0
I0628 20:36:56.040174  6212 net.cpp:84] Creating Layer conv1_0
I0628 20:36:56.040174  6212 net.cpp:406] conv1_0 <- conv1
I0628 20:36:56.040174  6212 net.cpp:380] conv1_0 -> conv1_0
I0628 20:36:56.041612  6212 net.cpp:122] Setting up conv1_0
I0628 20:36:56.041612  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.041612  6212 net.cpp:137] Memory required for data: 42599600
I0628 20:36:56.041612  6212 layer_factory.cpp:58] Creating layer bn1_0
I0628 20:36:56.041612  6212 net.cpp:84] Creating Layer bn1_0
I0628 20:36:56.041612  6212 net.cpp:406] bn1_0 <- conv1_0
I0628 20:36:56.041612  6212 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0628 20:36:56.041612  6212 net.cpp:122] Setting up bn1_0
I0628 20:36:56.041612  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.041612  6212 net.cpp:137] Memory required for data: 52839600
I0628 20:36:56.041612  6212 layer_factory.cpp:58] Creating layer scale1_0
I0628 20:36:56.041612  6212 net.cpp:84] Creating Layer scale1_0
I0628 20:36:56.041612  6212 net.cpp:406] scale1_0 <- conv1_0
I0628 20:36:56.041612  6212 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0628 20:36:56.041612  6212 layer_factory.cpp:58] Creating layer scale1_0
I0628 20:36:56.041612  6212 net.cpp:122] Setting up scale1_0
I0628 20:36:56.041612  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.041612  6212 net.cpp:137] Memory required for data: 63079600
I0628 20:36:56.041612  6212 layer_factory.cpp:58] Creating layer relu1_0
I0628 20:36:56.042615  6212 net.cpp:84] Creating Layer relu1_0
I0628 20:36:56.042615  6212 net.cpp:406] relu1_0 <- conv1_0
I0628 20:36:56.042615  6212 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0628 20:36:56.042615  6212 net.cpp:122] Setting up relu1_0
I0628 20:36:56.042615  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.042615  6212 net.cpp:137] Memory required for data: 73319600
I0628 20:36:56.042615  6212 layer_factory.cpp:58] Creating layer conv2
I0628 20:36:56.042615  6212 net.cpp:84] Creating Layer conv2
I0628 20:36:56.042615  6212 net.cpp:406] conv2 <- conv1_0
I0628 20:36:56.042615  6212 net.cpp:380] conv2 -> conv2
I0628 20:36:56.043617  6212 net.cpp:122] Setting up conv2
I0628 20:36:56.043617  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.043617  6212 net.cpp:137] Memory required for data: 83559600
I0628 20:36:56.043617  6212 layer_factory.cpp:58] Creating layer bn2
I0628 20:36:56.043617  6212 net.cpp:84] Creating Layer bn2
I0628 20:36:56.043617  6212 net.cpp:406] bn2 <- conv2
I0628 20:36:56.043617  6212 net.cpp:367] bn2 -> conv2 (in-place)
I0628 20:36:56.043617  6212 net.cpp:122] Setting up bn2
I0628 20:36:56.043617  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.043617  6212 net.cpp:137] Memory required for data: 93799600
I0628 20:36:56.043617  6212 layer_factory.cpp:58] Creating layer scale2
I0628 20:36:56.043617  6212 net.cpp:84] Creating Layer scale2
I0628 20:36:56.043617  6212 net.cpp:406] scale2 <- conv2
I0628 20:36:56.043617  6212 net.cpp:367] scale2 -> conv2 (in-place)
I0628 20:36:56.043617  6212 layer_factory.cpp:58] Creating layer scale2
I0628 20:36:56.043617  6212 net.cpp:122] Setting up scale2
I0628 20:36:56.043617  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.043617  6212 net.cpp:137] Memory required for data: 104039600
I0628 20:36:56.043617  6212 layer_factory.cpp:58] Creating layer relu2
I0628 20:36:56.043617  6212 net.cpp:84] Creating Layer relu2
I0628 20:36:56.043617  6212 net.cpp:406] relu2 <- conv2
I0628 20:36:56.043617  6212 net.cpp:367] relu2 -> conv2 (in-place)
I0628 20:36:56.043617  6212 net.cpp:122] Setting up relu2
I0628 20:36:56.043617  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.043617  6212 net.cpp:137] Memory required for data: 114279600
I0628 20:36:56.043617  6212 layer_factory.cpp:58] Creating layer conv2_1
I0628 20:36:56.043617  6212 net.cpp:84] Creating Layer conv2_1
I0628 20:36:56.044616  6212 net.cpp:406] conv2_1 <- conv2
I0628 20:36:56.044616  6212 net.cpp:380] conv2_1 -> conv2_1
I0628 20:36:56.044616  6212 net.cpp:122] Setting up conv2_1
I0628 20:36:56.044616  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.045617  6212 net.cpp:137] Memory required for data: 124519600
I0628 20:36:56.045617  6212 layer_factory.cpp:58] Creating layer bn2_1
I0628 20:36:56.045617  6212 net.cpp:84] Creating Layer bn2_1
I0628 20:36:56.045617  6212 net.cpp:406] bn2_1 <- conv2_1
I0628 20:36:56.045617  6212 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0628 20:36:56.045617  6212 net.cpp:122] Setting up bn2_1
I0628 20:36:56.045617  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.045617  6212 net.cpp:137] Memory required for data: 134759600
I0628 20:36:56.045617  6212 layer_factory.cpp:58] Creating layer scale2_1
I0628 20:36:56.045617  6212 net.cpp:84] Creating Layer scale2_1
I0628 20:36:56.045617  6212 net.cpp:406] scale2_1 <- conv2_1
I0628 20:36:56.045617  6212 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0628 20:36:56.045617  6212 layer_factory.cpp:58] Creating layer scale2_1
I0628 20:36:56.045617  6212 net.cpp:122] Setting up scale2_1
I0628 20:36:56.045617  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.045617  6212 net.cpp:137] Memory required for data: 144999600
I0628 20:36:56.045617  6212 layer_factory.cpp:58] Creating layer relu2_1
I0628 20:36:56.045617  6212 net.cpp:84] Creating Layer relu2_1
I0628 20:36:56.045617  6212 net.cpp:406] relu2_1 <- conv2_1
I0628 20:36:56.045617  6212 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0628 20:36:56.045617  6212 net.cpp:122] Setting up relu2_1
I0628 20:36:56.045617  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.045617  6212 net.cpp:137] Memory required for data: 155239600
I0628 20:36:56.045617  6212 layer_factory.cpp:58] Creating layer conv2_2
I0628 20:36:56.045617  6212 net.cpp:84] Creating Layer conv2_2
I0628 20:36:56.045617  6212 net.cpp:406] conv2_2 <- conv2_1
I0628 20:36:56.045617  6212 net.cpp:380] conv2_2 -> conv2_2
I0628 20:36:56.046618  6212 net.cpp:122] Setting up conv2_2
I0628 20:36:56.046618  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.046618  6212 net.cpp:137] Memory required for data: 165479600
I0628 20:36:56.046618  6212 layer_factory.cpp:58] Creating layer bn2_2
I0628 20:36:56.046618  6212 net.cpp:84] Creating Layer bn2_2
I0628 20:36:56.046618  6212 net.cpp:406] bn2_2 <- conv2_2
I0628 20:36:56.046618  6212 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0628 20:36:56.046618  6212 net.cpp:122] Setting up bn2_2
I0628 20:36:56.046618  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.046618  6212 net.cpp:137] Memory required for data: 175719600
I0628 20:36:56.046618  6212 layer_factory.cpp:58] Creating layer scale2_2
I0628 20:36:56.046618  6212 net.cpp:84] Creating Layer scale2_2
I0628 20:36:56.046618  6212 net.cpp:406] scale2_2 <- conv2_2
I0628 20:36:56.046618  6212 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0628 20:36:56.046618  6212 layer_factory.cpp:58] Creating layer scale2_2
I0628 20:36:56.046618  6212 net.cpp:122] Setting up scale2_2
I0628 20:36:56.046618  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.046618  6212 net.cpp:137] Memory required for data: 185959600
I0628 20:36:56.046618  6212 layer_factory.cpp:58] Creating layer relu2_2
I0628 20:36:56.047618  6212 net.cpp:84] Creating Layer relu2_2
I0628 20:36:56.047618  6212 net.cpp:406] relu2_2 <- conv2_2
I0628 20:36:56.047618  6212 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0628 20:36:56.047618  6212 net.cpp:122] Setting up relu2_2
I0628 20:36:56.047618  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.047618  6212 net.cpp:137] Memory required for data: 196199600
I0628 20:36:56.047618  6212 layer_factory.cpp:58] Creating layer pool2_1
I0628 20:36:56.047618  6212 net.cpp:84] Creating Layer pool2_1
I0628 20:36:56.047618  6212 net.cpp:406] pool2_1 <- conv2_2
I0628 20:36:56.047618  6212 net.cpp:380] pool2_1 -> pool2_1
I0628 20:36:56.047618  6212 net.cpp:122] Setting up pool2_1
I0628 20:36:56.047618  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.047618  6212 net.cpp:137] Memory required for data: 198759600
I0628 20:36:56.047618  6212 layer_factory.cpp:58] Creating layer conv3
I0628 20:36:56.047618  6212 net.cpp:84] Creating Layer conv3
I0628 20:36:56.047618  6212 net.cpp:406] conv3 <- pool2_1
I0628 20:36:56.047618  6212 net.cpp:380] conv3 -> conv3
I0628 20:36:56.048619  6212 net.cpp:122] Setting up conv3
I0628 20:36:56.048619  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.048619  6212 net.cpp:137] Memory required for data: 201319600
I0628 20:36:56.048619  6212 layer_factory.cpp:58] Creating layer bn3
I0628 20:36:56.048619  6212 net.cpp:84] Creating Layer bn3
I0628 20:36:56.048619  6212 net.cpp:406] bn3 <- conv3
I0628 20:36:56.048619  6212 net.cpp:367] bn3 -> conv3 (in-place)
I0628 20:36:56.048619  6212 net.cpp:122] Setting up bn3
I0628 20:36:56.048619  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.048619  6212 net.cpp:137] Memory required for data: 203879600
I0628 20:36:56.048619  6212 layer_factory.cpp:58] Creating layer scale3
I0628 20:36:56.048619  6212 net.cpp:84] Creating Layer scale3
I0628 20:36:56.048619  6212 net.cpp:406] scale3 <- conv3
I0628 20:36:56.048619  6212 net.cpp:367] scale3 -> conv3 (in-place)
I0628 20:36:56.048619  6212 layer_factory.cpp:58] Creating layer scale3
I0628 20:36:56.048619  6212 net.cpp:122] Setting up scale3
I0628 20:36:56.048619  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.048619  6212 net.cpp:137] Memory required for data: 206439600
I0628 20:36:56.048619  6212 layer_factory.cpp:58] Creating layer relu3
I0628 20:36:56.048619  6212 net.cpp:84] Creating Layer relu3
I0628 20:36:56.048619  6212 net.cpp:406] relu3 <- conv3
I0628 20:36:56.048619  6212 net.cpp:367] relu3 -> conv3 (in-place)
I0628 20:36:56.049620  6212 net.cpp:122] Setting up relu3
I0628 20:36:56.049620  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.049620  6212 net.cpp:137] Memory required for data: 208999600
I0628 20:36:56.049620  6212 layer_factory.cpp:58] Creating layer conv4
I0628 20:36:56.049620  6212 net.cpp:84] Creating Layer conv4
I0628 20:36:56.049620  6212 net.cpp:406] conv4 <- conv3
I0628 20:36:56.049620  6212 net.cpp:380] conv4 -> conv4
I0628 20:36:56.050220  6212 net.cpp:122] Setting up conv4
I0628 20:36:56.050220  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.050220  6212 net.cpp:137] Memory required for data: 211559600
I0628 20:36:56.050220  6212 layer_factory.cpp:58] Creating layer bn4
I0628 20:36:56.050220  6212 net.cpp:84] Creating Layer bn4
I0628 20:36:56.050220  6212 net.cpp:406] bn4 <- conv4
I0628 20:36:56.050220  6212 net.cpp:367] bn4 -> conv4 (in-place)
I0628 20:36:56.050220  6212 net.cpp:122] Setting up bn4
I0628 20:36:56.050220  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.050220  6212 net.cpp:137] Memory required for data: 214119600
I0628 20:36:56.050220  6212 layer_factory.cpp:58] Creating layer scale4
I0628 20:36:56.050220  6212 net.cpp:84] Creating Layer scale4
I0628 20:36:56.050220  6212 net.cpp:406] scale4 <- conv4
I0628 20:36:56.050220  6212 net.cpp:367] scale4 -> conv4 (in-place)
I0628 20:36:56.050220  6212 layer_factory.cpp:58] Creating layer scale4
I0628 20:36:56.050220  6212 net.cpp:122] Setting up scale4
I0628 20:36:56.050220  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.050220  6212 net.cpp:137] Memory required for data: 216679600
I0628 20:36:56.050220  6212 layer_factory.cpp:58] Creating layer relu4
I0628 20:36:56.050220  6212 net.cpp:84] Creating Layer relu4
I0628 20:36:56.050220  6212 net.cpp:406] relu4 <- conv4
I0628 20:36:56.050220  6212 net.cpp:367] relu4 -> conv4 (in-place)
I0628 20:36:56.050220  6212 net.cpp:122] Setting up relu4
I0628 20:36:56.051221  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.051221  6212 net.cpp:137] Memory required for data: 219239600
I0628 20:36:56.051221  6212 layer_factory.cpp:58] Creating layer conv4_1
I0628 20:36:56.051221  6212 net.cpp:84] Creating Layer conv4_1
I0628 20:36:56.051221  6212 net.cpp:406] conv4_1 <- conv4
I0628 20:36:56.051221  6212 net.cpp:380] conv4_1 -> conv4_1
I0628 20:36:56.051221  6212 net.cpp:122] Setting up conv4_1
I0628 20:36:56.051221  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.051221  6212 net.cpp:137] Memory required for data: 221799600
I0628 20:36:56.051221  6212 layer_factory.cpp:58] Creating layer bn4_1
I0628 20:36:56.051221  6212 net.cpp:84] Creating Layer bn4_1
I0628 20:36:56.051221  6212 net.cpp:406] bn4_1 <- conv4_1
I0628 20:36:56.051221  6212 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0628 20:36:56.052222  6212 net.cpp:122] Setting up bn4_1
I0628 20:36:56.052222  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.052222  6212 net.cpp:137] Memory required for data: 224359600
I0628 20:36:56.052222  6212 layer_factory.cpp:58] Creating layer scale4_1
I0628 20:36:56.052222  6212 net.cpp:84] Creating Layer scale4_1
I0628 20:36:56.052222  6212 net.cpp:406] scale4_1 <- conv4_1
I0628 20:36:56.052222  6212 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0628 20:36:56.052222  6212 layer_factory.cpp:58] Creating layer scale4_1
I0628 20:36:56.052222  6212 net.cpp:122] Setting up scale4_1
I0628 20:36:56.052222  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.052222  6212 net.cpp:137] Memory required for data: 226919600
I0628 20:36:56.052222  6212 layer_factory.cpp:58] Creating layer relu4_1
I0628 20:36:56.052222  6212 net.cpp:84] Creating Layer relu4_1
I0628 20:36:56.052222  6212 net.cpp:406] relu4_1 <- conv4_1
I0628 20:36:56.052222  6212 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0628 20:36:56.052222  6212 net.cpp:122] Setting up relu4_1
I0628 20:36:56.052222  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.052222  6212 net.cpp:137] Memory required for data: 229479600
I0628 20:36:56.052222  6212 layer_factory.cpp:58] Creating layer conv4_2
I0628 20:36:56.052222  6212 net.cpp:84] Creating Layer conv4_2
I0628 20:36:56.052222  6212 net.cpp:406] conv4_2 <- conv4_1
I0628 20:36:56.052222  6212 net.cpp:380] conv4_2 -> conv4_2
I0628 20:36:56.053223  6212 net.cpp:122] Setting up conv4_2
I0628 20:36:56.053223  6212 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 20:36:56.053223  6212 net.cpp:137] Memory required for data: 236033200
I0628 20:36:56.053223  6212 layer_factory.cpp:58] Creating layer bn4_2
I0628 20:36:56.053223  6212 net.cpp:84] Creating Layer bn4_2
I0628 20:36:56.053223  6212 net.cpp:406] bn4_2 <- conv4_2
I0628 20:36:56.053223  6212 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0628 20:36:56.053223  6212 net.cpp:122] Setting up bn4_2
I0628 20:36:56.053223  6212 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 20:36:56.053223  6212 net.cpp:137] Memory required for data: 242586800
I0628 20:36:56.053223  6212 layer_factory.cpp:58] Creating layer scale4_2
I0628 20:36:56.053223  6212 net.cpp:84] Creating Layer scale4_2
I0628 20:36:56.053223  6212 net.cpp:406] scale4_2 <- conv4_2
I0628 20:36:56.053223  6212 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0628 20:36:56.053223  6212 layer_factory.cpp:58] Creating layer scale4_2
I0628 20:36:56.054224  6212 net.cpp:122] Setting up scale4_2
I0628 20:36:56.054224  6212 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 20:36:56.054224  6212 net.cpp:137] Memory required for data: 249140400
I0628 20:36:56.054224  6212 layer_factory.cpp:58] Creating layer relu4_2
I0628 20:36:56.054224  6212 net.cpp:84] Creating Layer relu4_2
I0628 20:36:56.054224  6212 net.cpp:406] relu4_2 <- conv4_2
I0628 20:36:56.054224  6212 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0628 20:36:56.054224  6212 net.cpp:122] Setting up relu4_2
I0628 20:36:56.054224  6212 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 20:36:56.054224  6212 net.cpp:137] Memory required for data: 255694000
I0628 20:36:56.054224  6212 layer_factory.cpp:58] Creating layer pool4_12
I0628 20:36:56.054224  6212 net.cpp:84] Creating Layer pool4_12
I0628 20:36:56.054224  6212 net.cpp:406] pool4_12 <- conv4_2
I0628 20:36:56.054224  6212 net.cpp:380] pool4_12 -> pool4_12
I0628 20:36:56.054224  6212 net.cpp:122] Setting up pool4_12
I0628 20:36:56.054224  6212 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0628 20:36:56.054224  6212 net.cpp:137] Memory required for data: 257332400
I0628 20:36:56.054224  6212 layer_factory.cpp:58] Creating layer conv4_0
I0628 20:36:56.054224  6212 net.cpp:84] Creating Layer conv4_0
I0628 20:36:56.054224  6212 net.cpp:406] conv4_0 <- pool4_12
I0628 20:36:56.054224  6212 net.cpp:380] conv4_0 -> conv4_0
I0628 20:36:56.056226  6212 net.cpp:122] Setting up conv4_0
I0628 20:36:56.056226  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.056226  6212 net.cpp:137] Memory required for data: 258689200
I0628 20:36:56.056226  6212 layer_factory.cpp:58] Creating layer bn4_0
I0628 20:36:56.056226  6212 net.cpp:84] Creating Layer bn4_0
I0628 20:36:56.056226  6212 net.cpp:406] bn4_0 <- conv4_0
I0628 20:36:56.056226  6212 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0628 20:36:56.056226  6212 net.cpp:122] Setting up bn4_0
I0628 20:36:56.056226  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.056226  6212 net.cpp:137] Memory required for data: 260046000
I0628 20:36:56.056226  6212 layer_factory.cpp:58] Creating layer scale4_0
I0628 20:36:56.056226  6212 net.cpp:84] Creating Layer scale4_0
I0628 20:36:56.056226  6212 net.cpp:406] scale4_0 <- conv4_0
I0628 20:36:56.056226  6212 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0628 20:36:56.056226  6212 layer_factory.cpp:58] Creating layer scale4_0
I0628 20:36:56.056226  6212 net.cpp:122] Setting up scale4_0
I0628 20:36:56.056226  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.056226  6212 net.cpp:137] Memory required for data: 261402800
I0628 20:36:56.056226  6212 layer_factory.cpp:58] Creating layer relu4_0
I0628 20:36:56.056226  6212 net.cpp:84] Creating Layer relu4_0
I0628 20:36:56.056226  6212 net.cpp:406] relu4_0 <- conv4_0
I0628 20:36:56.056226  6212 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0628 20:36:56.057226  6212 net.cpp:122] Setting up relu4_0
I0628 20:36:56.057226  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.057226  6212 net.cpp:137] Memory required for data: 262759600
I0628 20:36:56.057226  6212 layer_factory.cpp:58] Creating layer cccp4
I0628 20:36:56.057226  6212 net.cpp:84] Creating Layer cccp4
I0628 20:36:56.057226  6212 net.cpp:406] cccp4 <- conv4_0
I0628 20:36:56.057226  6212 net.cpp:380] cccp4 -> cccp4
I0628 20:36:56.058226  6212 net.cpp:122] Setting up cccp4
I0628 20:36:56.058226  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.058226  6212 net.cpp:137] Memory required for data: 264116400
I0628 20:36:56.058226  6212 layer_factory.cpp:58] Creating layer bn_cccp4
I0628 20:36:56.058226  6212 net.cpp:84] Creating Layer bn_cccp4
I0628 20:36:56.058226  6212 net.cpp:406] bn_cccp4 <- cccp4
I0628 20:36:56.058226  6212 net.cpp:367] bn_cccp4 -> cccp4 (in-place)
I0628 20:36:56.058226  6212 net.cpp:122] Setting up bn_cccp4
I0628 20:36:56.058226  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.058226  6212 net.cpp:137] Memory required for data: 265473200
I0628 20:36:56.058226  6212 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 20:36:56.058226  6212 net.cpp:84] Creating Layer scale_cccp4
I0628 20:36:56.058226  6212 net.cpp:406] scale_cccp4 <- cccp4
I0628 20:36:56.058226  6212 net.cpp:367] scale_cccp4 -> cccp4 (in-place)
I0628 20:36:56.058226  6212 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 20:36:56.058226  6212 net.cpp:122] Setting up scale_cccp4
I0628 20:36:56.058226  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.058226  6212 net.cpp:137] Memory required for data: 266830000
I0628 20:36:56.058226  6212 layer_factory.cpp:58] Creating layer relu_cccp4
I0628 20:36:56.058226  6212 net.cpp:84] Creating Layer relu_cccp4
I0628 20:36:56.058226  6212 net.cpp:406] relu_cccp4 <- cccp4
I0628 20:36:56.058226  6212 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0628 20:36:56.058226  6212 net.cpp:122] Setting up relu_cccp4
I0628 20:36:56.058226  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.058226  6212 net.cpp:137] Memory required for data: 268186800
I0628 20:36:56.058226  6212 layer_factory.cpp:58] Creating layer pool4_2
I0628 20:36:56.058226  6212 net.cpp:84] Creating Layer pool4_2
I0628 20:36:56.058226  6212 net.cpp:406] pool4_2 <- cccp4
I0628 20:36:56.058226  6212 net.cpp:380] pool4_2 -> pool4_2
I0628 20:36:56.058226  6212 net.cpp:122] Setting up pool4_2
I0628 20:36:56.058226  6212 net.cpp:129] Top shape: 100 53 4 4 (84800)
I0628 20:36:56.058226  6212 net.cpp:137] Memory required for data: 268526000
I0628 20:36:56.058226  6212 layer_factory.cpp:58] Creating layer cccp5
I0628 20:36:56.058226  6212 net.cpp:84] Creating Layer cccp5
I0628 20:36:56.058226  6212 net.cpp:406] cccp5 <- pool4_2
I0628 20:36:56.058226  6212 net.cpp:380] cccp5 -> cccp5
I0628 20:36:56.059671  6212 net.cpp:122] Setting up cccp5
I0628 20:36:56.059671  6212 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 20:36:56.059671  6212 net.cpp:137] Memory required for data: 270081200
I0628 20:36:56.059671  6212 layer_factory.cpp:58] Creating layer bn_cccp5
I0628 20:36:56.059671  6212 net.cpp:84] Creating Layer bn_cccp5
I0628 20:36:56.059671  6212 net.cpp:406] bn_cccp5 <- cccp5
I0628 20:36:56.059671  6212 net.cpp:367] bn_cccp5 -> cccp5 (in-place)
I0628 20:36:56.059671  6212 net.cpp:122] Setting up bn_cccp5
I0628 20:36:56.059671  6212 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 20:36:56.059671  6212 net.cpp:137] Memory required for data: 271636400
I0628 20:36:56.059671  6212 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 20:36:56.059671  6212 net.cpp:84] Creating Layer scale_cccp5
I0628 20:36:56.059671  6212 net.cpp:406] scale_cccp5 <- cccp5
I0628 20:36:56.059671  6212 net.cpp:367] scale_cccp5 -> cccp5 (in-place)
I0628 20:36:56.059671  6212 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 20:36:56.059671  6212 net.cpp:122] Setting up scale_cccp5
I0628 20:36:56.059671  6212 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 20:36:56.059671  6212 net.cpp:137] Memory required for data: 273191600
I0628 20:36:56.059671  6212 layer_factory.cpp:58] Creating layer relu_cccp5
I0628 20:36:56.059671  6212 net.cpp:84] Creating Layer relu_cccp5
I0628 20:36:56.059671  6212 net.cpp:406] relu_cccp5 <- cccp5
I0628 20:36:56.059671  6212 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0628 20:36:56.059671  6212 net.cpp:122] Setting up relu_cccp5
I0628 20:36:56.059671  6212 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 20:36:56.059671  6212 net.cpp:137] Memory required for data: 274746800
I0628 20:36:56.059671  6212 layer_factory.cpp:58] Creating layer poolcp5
I0628 20:36:56.059671  6212 net.cpp:84] Creating Layer poolcp5
I0628 20:36:56.059671  6212 net.cpp:406] poolcp5 <- cccp5
I0628 20:36:56.059671  6212 net.cpp:380] poolcp5 -> poolcp5
I0628 20:36:56.060674  6212 net.cpp:122] Setting up poolcp5
I0628 20:36:56.060674  6212 net.cpp:129] Top shape: 100 108 3 3 (97200)
I0628 20:36:56.060674  6212 net.cpp:137] Memory required for data: 275135600
I0628 20:36:56.060674  6212 layer_factory.cpp:58] Creating layer cccp6
I0628 20:36:56.060674  6212 net.cpp:84] Creating Layer cccp6
I0628 20:36:56.060674  6212 net.cpp:406] cccp6 <- poolcp5
I0628 20:36:56.060674  6212 net.cpp:380] cccp6 -> cccp6
I0628 20:36:56.061275  6212 net.cpp:122] Setting up cccp6
I0628 20:36:56.061275  6212 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 20:36:56.061275  6212 net.cpp:137] Memory required for data: 276215600
I0628 20:36:56.061275  6212 layer_factory.cpp:58] Creating layer bn_cccp6
I0628 20:36:56.061275  6212 net.cpp:84] Creating Layer bn_cccp6
I0628 20:36:56.061275  6212 net.cpp:406] bn_cccp6 <- cccp6
I0628 20:36:56.061275  6212 net.cpp:367] bn_cccp6 -> cccp6 (in-place)
I0628 20:36:56.061275  6212 net.cpp:122] Setting up bn_cccp6
I0628 20:36:56.061275  6212 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 20:36:56.061275  6212 net.cpp:137] Memory required for data: 277295600
I0628 20:36:56.061275  6212 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 20:36:56.061275  6212 net.cpp:84] Creating Layer scale_cccp6
I0628 20:36:56.061275  6212 net.cpp:406] scale_cccp6 <- cccp6
I0628 20:36:56.061275  6212 net.cpp:367] scale_cccp6 -> cccp6 (in-place)
I0628 20:36:56.061275  6212 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 20:36:56.061275  6212 net.cpp:122] Setting up scale_cccp6
I0628 20:36:56.061275  6212 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 20:36:56.061275  6212 net.cpp:137] Memory required for data: 278375600
I0628 20:36:56.061275  6212 layer_factory.cpp:58] Creating layer relu_cccp6
I0628 20:36:56.061275  6212 net.cpp:84] Creating Layer relu_cccp6
I0628 20:36:56.061275  6212 net.cpp:406] relu_cccp6 <- cccp6
I0628 20:36:56.061275  6212 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0628 20:36:56.062278  6212 net.cpp:122] Setting up relu_cccp6
I0628 20:36:56.062278  6212 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 20:36:56.062278  6212 net.cpp:137] Memory required for data: 279455600
I0628 20:36:56.062278  6212 layer_factory.cpp:58] Creating layer poolcp6
I0628 20:36:56.062278  6212 net.cpp:84] Creating Layer poolcp6
I0628 20:36:56.062278  6212 net.cpp:406] poolcp6 <- cccp6
I0628 20:36:56.062278  6212 net.cpp:380] poolcp6 -> poolcp6
I0628 20:36:56.062278  6212 net.cpp:122] Setting up poolcp6
I0628 20:36:56.062278  6212 net.cpp:129] Top shape: 100 108 1 1 (10800)
I0628 20:36:56.062278  6212 net.cpp:137] Memory required for data: 279498800
I0628 20:36:56.062278  6212 layer_factory.cpp:58] Creating layer ip1
I0628 20:36:56.062278  6212 net.cpp:84] Creating Layer ip1
I0628 20:36:56.062278  6212 net.cpp:406] ip1 <- poolcp6
I0628 20:36:56.062278  6212 net.cpp:380] ip1 -> ip1
I0628 20:36:56.062278  6212 net.cpp:122] Setting up ip1
I0628 20:36:56.062278  6212 net.cpp:129] Top shape: 100 10 (1000)
I0628 20:36:56.062278  6212 net.cpp:137] Memory required for data: 279502800
I0628 20:36:56.062278  6212 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0628 20:36:56.062278  6212 net.cpp:84] Creating Layer ip1_ip1_0_split
I0628 20:36:56.062278  6212 net.cpp:406] ip1_ip1_0_split <- ip1
I0628 20:36:56.062278  6212 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0628 20:36:56.062278  6212 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0628 20:36:56.062278  6212 net.cpp:122] Setting up ip1_ip1_0_split
I0628 20:36:56.062278  6212 net.cpp:129] Top shape: 100 10 (1000)
I0628 20:36:56.062278  6212 net.cpp:129] Top shape: 100 10 (1000)
I0628 20:36:56.062278  6212 net.cpp:137] Memory required for data: 279510800
I0628 20:36:56.062278  6212 layer_factory.cpp:58] Creating layer accuracy_training
I0628 20:36:56.062278  6212 net.cpp:84] Creating Layer accuracy_training
I0628 20:36:56.062278  6212 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0628 20:36:56.062278  6212 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I0628 20:36:56.062278  6212 net.cpp:380] accuracy_training -> accuracy_training
I0628 20:36:56.062278  6212 net.cpp:122] Setting up accuracy_training
I0628 20:36:56.063279  6212 net.cpp:129] Top shape: (1)
I0628 20:36:56.063279  6212 net.cpp:137] Memory required for data: 279510804
I0628 20:36:56.063279  6212 layer_factory.cpp:58] Creating layer loss
I0628 20:36:56.063279  6212 net.cpp:84] Creating Layer loss
I0628 20:36:56.063279  6212 net.cpp:406] loss <- ip1_ip1_0_split_1
I0628 20:36:56.063279  6212 net.cpp:406] loss <- label_cifar_1_split_1
I0628 20:36:56.063279  6212 net.cpp:380] loss -> loss
I0628 20:36:56.063279  6212 layer_factory.cpp:58] Creating layer loss
I0628 20:36:56.063566  6212 net.cpp:122] Setting up loss
I0628 20:36:56.063566  6212 net.cpp:129] Top shape: (1)
I0628 20:36:56.063566  6212 net.cpp:132]     with loss weight 1
I0628 20:36:56.063566  6212 net.cpp:137] Memory required for data: 279510808
I0628 20:36:56.063566  6212 net.cpp:198] loss needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:200] accuracy_training does not need backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] ip1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] poolcp6 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu_cccp6 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale_cccp6 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn_cccp6 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] cccp6 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] poolcp5 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu_cccp5 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale_cccp5 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn_cccp5 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] cccp5 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] pool4_2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu_cccp4 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale_cccp4 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn_cccp4 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] cccp4 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu4_0 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale4_0 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn4_0 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] conv4_0 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] pool4_12 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu4_2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale4_2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn4_2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] conv4_2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu4_1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale4_1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn4_1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] conv4_1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu4 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale4 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn4 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] conv4 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu3 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale3 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn3 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] conv3 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] pool2_1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu2_2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale2_2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn2_2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] conv2_2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu2_1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale2_1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn2_1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] conv2_1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] conv2 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu1_0 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale1_0 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn1_0 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] conv1_0 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] relu1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] scale1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] bn1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:198] conv1 needs backward computation.
I0628 20:36:56.063566  6212 net.cpp:200] label_cifar_1_split does not need backward computation.
I0628 20:36:56.063566  6212 net.cpp:200] cifar does not need backward computation.
I0628 20:36:56.063566  6212 net.cpp:242] This network produces output accuracy_training
I0628 20:36:56.063566  6212 net.cpp:242] This network produces output loss
I0628 20:36:56.063566  6212 net.cpp:255] Network initialization done.
I0628 20:36:56.064568  6212 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 20:36:56.064568  6212 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0628 20:36:56.064568  6212 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp4
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp5
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp6
I0628 20:36:56.064568  6212 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0628 20:36:56.064568  6212 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_13_128k_end1x1"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_12"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_12"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 53
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "conv4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 53
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp4"
  type: "Scale"
  bottom: "cccp4"
  top: "cccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "cccp4"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "pool4_2"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp5"
  type: "Scale"
  bottom: "cccp5"
  top: "cccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp6"
  type: "Scale"
  bottom: "cccp6"
  top: "cccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0628 20:36:56.065568  6212 layer_factory.cpp:58] Creating layer cifar
I0628 20:36:56.067571  6212 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I0628 20:36:56.067571  6212 net.cpp:84] Creating Layer cifar
I0628 20:36:56.067571  6212 net.cpp:380] cifar -> data
I0628 20:36:56.067571  6212 net.cpp:380] cifar -> label
I0628 20:36:56.067571  6212 data_layer.cpp:45] output data size: 100,3,32,32
I0628 20:36:56.073906  6212 net.cpp:122] Setting up cifar
I0628 20:36:56.073906  6212 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0628 20:36:56.073906  6212 net.cpp:129] Top shape: 100 (100)
I0628 20:36:56.073906  6212 net.cpp:137] Memory required for data: 1229200
I0628 20:36:56.073906  6212 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0628 20:36:56.073906  6212 net.cpp:84] Creating Layer label_cifar_1_split
I0628 20:36:56.073906  6212 net.cpp:406] label_cifar_1_split <- label
I0628 20:36:56.073906  6212 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0628 20:36:56.073906  6212 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0628 20:36:56.073906  6212 net.cpp:122] Setting up label_cifar_1_split
I0628 20:36:56.073906  6212 net.cpp:129] Top shape: 100 (100)
I0628 20:36:56.073906  6212 net.cpp:129] Top shape: 100 (100)
I0628 20:36:56.073906  6212 net.cpp:137] Memory required for data: 1230000
I0628 20:36:56.073906  6212 layer_factory.cpp:58] Creating layer conv1
I0628 20:36:56.073906  6212 net.cpp:84] Creating Layer conv1
I0628 20:36:56.073906  6212 net.cpp:406] conv1 <- data
I0628 20:36:56.073906  6212 net.cpp:380] conv1 -> conv1
I0628 20:36:56.074923  1380 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 20:36:56.075424  6212 net.cpp:122] Setting up conv1
I0628 20:36:56.075424  6212 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 20:36:56.075424  6212 net.cpp:137] Memory required for data: 9012400
I0628 20:36:56.075424  6212 layer_factory.cpp:58] Creating layer bn1
I0628 20:36:56.075424  6212 net.cpp:84] Creating Layer bn1
I0628 20:36:56.075424  6212 net.cpp:406] bn1 <- conv1
I0628 20:36:56.075424  6212 net.cpp:367] bn1 -> conv1 (in-place)
I0628 20:36:56.075924  6212 net.cpp:122] Setting up bn1
I0628 20:36:56.075924  6212 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 20:36:56.075924  6212 net.cpp:137] Memory required for data: 16794800
I0628 20:36:56.075924  6212 layer_factory.cpp:58] Creating layer scale1
I0628 20:36:56.075924  6212 net.cpp:84] Creating Layer scale1
I0628 20:36:56.075924  6212 net.cpp:406] scale1 <- conv1
I0628 20:36:56.075924  6212 net.cpp:367] scale1 -> conv1 (in-place)
I0628 20:36:56.075924  6212 layer_factory.cpp:58] Creating layer scale1
I0628 20:36:56.075924  6212 net.cpp:122] Setting up scale1
I0628 20:36:56.075924  6212 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 20:36:56.075924  6212 net.cpp:137] Memory required for data: 24577200
I0628 20:36:56.075924  6212 layer_factory.cpp:58] Creating layer relu1
I0628 20:36:56.075924  6212 net.cpp:84] Creating Layer relu1
I0628 20:36:56.075924  6212 net.cpp:406] relu1 <- conv1
I0628 20:36:56.075924  6212 net.cpp:367] relu1 -> conv1 (in-place)
I0628 20:36:56.075924  6212 net.cpp:122] Setting up relu1
I0628 20:36:56.075924  6212 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 20:36:56.075924  6212 net.cpp:137] Memory required for data: 32359600
I0628 20:36:56.076424  6212 layer_factory.cpp:58] Creating layer conv1_0
I0628 20:36:56.076424  6212 net.cpp:84] Creating Layer conv1_0
I0628 20:36:56.076424  6212 net.cpp:406] conv1_0 <- conv1
I0628 20:36:56.076424  6212 net.cpp:380] conv1_0 -> conv1_0
I0628 20:36:56.077425  6212 net.cpp:122] Setting up conv1_0
I0628 20:36:56.077425  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.077425  6212 net.cpp:137] Memory required for data: 42599600
I0628 20:36:56.077425  6212 layer_factory.cpp:58] Creating layer bn1_0
I0628 20:36:56.077425  6212 net.cpp:84] Creating Layer bn1_0
I0628 20:36:56.077425  6212 net.cpp:406] bn1_0 <- conv1_0
I0628 20:36:56.077425  6212 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0628 20:36:56.077425  6212 net.cpp:122] Setting up bn1_0
I0628 20:36:56.077425  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.077425  6212 net.cpp:137] Memory required for data: 52839600
I0628 20:36:56.077425  6212 layer_factory.cpp:58] Creating layer scale1_0
I0628 20:36:56.077425  6212 net.cpp:84] Creating Layer scale1_0
I0628 20:36:56.077425  6212 net.cpp:406] scale1_0 <- conv1_0
I0628 20:36:56.077425  6212 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0628 20:36:56.077425  6212 layer_factory.cpp:58] Creating layer scale1_0
I0628 20:36:56.077925  6212 net.cpp:122] Setting up scale1_0
I0628 20:36:56.077925  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.077925  6212 net.cpp:137] Memory required for data: 63079600
I0628 20:36:56.077925  6212 layer_factory.cpp:58] Creating layer relu1_0
I0628 20:36:56.077925  6212 net.cpp:84] Creating Layer relu1_0
I0628 20:36:56.077925  6212 net.cpp:406] relu1_0 <- conv1_0
I0628 20:36:56.077925  6212 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0628 20:36:56.077925  6212 net.cpp:122] Setting up relu1_0
I0628 20:36:56.077925  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.077925  6212 net.cpp:137] Memory required for data: 73319600
I0628 20:36:56.077925  6212 layer_factory.cpp:58] Creating layer conv2
I0628 20:36:56.077925  6212 net.cpp:84] Creating Layer conv2
I0628 20:36:56.077925  6212 net.cpp:406] conv2 <- conv1_0
I0628 20:36:56.077925  6212 net.cpp:380] conv2 -> conv2
I0628 20:36:56.079622  6212 net.cpp:122] Setting up conv2
I0628 20:36:56.079622  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.079622  6212 net.cpp:137] Memory required for data: 83559600
I0628 20:36:56.079622  6212 layer_factory.cpp:58] Creating layer bn2
I0628 20:36:56.079622  6212 net.cpp:84] Creating Layer bn2
I0628 20:36:56.079622  6212 net.cpp:406] bn2 <- conv2
I0628 20:36:56.079622  6212 net.cpp:367] bn2 -> conv2 (in-place)
I0628 20:36:56.079622  6212 net.cpp:122] Setting up bn2
I0628 20:36:56.079622  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.079622  6212 net.cpp:137] Memory required for data: 93799600
I0628 20:36:56.079622  6212 layer_factory.cpp:58] Creating layer scale2
I0628 20:36:56.079622  6212 net.cpp:84] Creating Layer scale2
I0628 20:36:56.079622  6212 net.cpp:406] scale2 <- conv2
I0628 20:36:56.079622  6212 net.cpp:367] scale2 -> conv2 (in-place)
I0628 20:36:56.079622  6212 layer_factory.cpp:58] Creating layer scale2
I0628 20:36:56.080122  6212 net.cpp:122] Setting up scale2
I0628 20:36:56.080122  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.080122  6212 net.cpp:137] Memory required for data: 104039600
I0628 20:36:56.080122  6212 layer_factory.cpp:58] Creating layer relu2
I0628 20:36:56.080122  6212 net.cpp:84] Creating Layer relu2
I0628 20:36:56.080122  6212 net.cpp:406] relu2 <- conv2
I0628 20:36:56.080122  6212 net.cpp:367] relu2 -> conv2 (in-place)
I0628 20:36:56.080122  6212 net.cpp:122] Setting up relu2
I0628 20:36:56.080122  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.080122  6212 net.cpp:137] Memory required for data: 114279600
I0628 20:36:56.080122  6212 layer_factory.cpp:58] Creating layer conv2_1
I0628 20:36:56.080122  6212 net.cpp:84] Creating Layer conv2_1
I0628 20:36:56.080122  6212 net.cpp:406] conv2_1 <- conv2
I0628 20:36:56.080122  6212 net.cpp:380] conv2_1 -> conv2_1
I0628 20:36:56.081624  6212 net.cpp:122] Setting up conv2_1
I0628 20:36:56.081624  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.081624  6212 net.cpp:137] Memory required for data: 124519600
I0628 20:36:56.081624  6212 layer_factory.cpp:58] Creating layer bn2_1
I0628 20:36:56.081624  6212 net.cpp:84] Creating Layer bn2_1
I0628 20:36:56.081624  6212 net.cpp:406] bn2_1 <- conv2_1
I0628 20:36:56.081624  6212 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0628 20:36:56.081624  6212 net.cpp:122] Setting up bn2_1
I0628 20:36:56.081624  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.081624  6212 net.cpp:137] Memory required for data: 134759600
I0628 20:36:56.081624  6212 layer_factory.cpp:58] Creating layer scale2_1
I0628 20:36:56.081624  6212 net.cpp:84] Creating Layer scale2_1
I0628 20:36:56.081624  6212 net.cpp:406] scale2_1 <- conv2_1
I0628 20:36:56.081624  6212 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0628 20:36:56.081624  6212 layer_factory.cpp:58] Creating layer scale2_1
I0628 20:36:56.082124  6212 net.cpp:122] Setting up scale2_1
I0628 20:36:56.082124  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.082124  6212 net.cpp:137] Memory required for data: 144999600
I0628 20:36:56.082124  6212 layer_factory.cpp:58] Creating layer relu2_1
I0628 20:36:56.082124  6212 net.cpp:84] Creating Layer relu2_1
I0628 20:36:56.082124  6212 net.cpp:406] relu2_1 <- conv2_1
I0628 20:36:56.082124  6212 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0628 20:36:56.082124  6212 net.cpp:122] Setting up relu2_1
I0628 20:36:56.082124  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.082124  6212 net.cpp:137] Memory required for data: 155239600
I0628 20:36:56.082124  6212 layer_factory.cpp:58] Creating layer conv2_2
I0628 20:36:56.082124  6212 net.cpp:84] Creating Layer conv2_2
I0628 20:36:56.082124  6212 net.cpp:406] conv2_2 <- conv2_1
I0628 20:36:56.082124  6212 net.cpp:380] conv2_2 -> conv2_2
I0628 20:36:56.083536  6212 net.cpp:122] Setting up conv2_2
I0628 20:36:56.083536  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.083536  6212 net.cpp:137] Memory required for data: 165479600
I0628 20:36:56.083536  6212 layer_factory.cpp:58] Creating layer bn2_2
I0628 20:36:56.083536  6212 net.cpp:84] Creating Layer bn2_2
I0628 20:36:56.083536  6212 net.cpp:406] bn2_2 <- conv2_2
I0628 20:36:56.083536  6212 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0628 20:36:56.083536  6212 net.cpp:122] Setting up bn2_2
I0628 20:36:56.083536  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.083536  6212 net.cpp:137] Memory required for data: 175719600
I0628 20:36:56.083536  6212 layer_factory.cpp:58] Creating layer scale2_2
I0628 20:36:56.083536  6212 net.cpp:84] Creating Layer scale2_2
I0628 20:36:56.083536  6212 net.cpp:406] scale2_2 <- conv2_2
I0628 20:36:56.084038  6212 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0628 20:36:56.084038  6212 layer_factory.cpp:58] Creating layer scale2_2
I0628 20:36:56.084038  6212 net.cpp:122] Setting up scale2_2
I0628 20:36:56.084038  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.084038  6212 net.cpp:137] Memory required for data: 185959600
I0628 20:36:56.084038  6212 layer_factory.cpp:58] Creating layer relu2_2
I0628 20:36:56.084038  6212 net.cpp:84] Creating Layer relu2_2
I0628 20:36:56.084038  6212 net.cpp:406] relu2_2 <- conv2_2
I0628 20:36:56.084038  6212 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0628 20:36:56.084537  6212 net.cpp:122] Setting up relu2_2
I0628 20:36:56.084537  6212 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 20:36:56.084537  6212 net.cpp:137] Memory required for data: 196199600
I0628 20:36:56.084537  6212 layer_factory.cpp:58] Creating layer pool2_1
I0628 20:36:56.084537  6212 net.cpp:84] Creating Layer pool2_1
I0628 20:36:56.084537  6212 net.cpp:406] pool2_1 <- conv2_2
I0628 20:36:56.084537  6212 net.cpp:380] pool2_1 -> pool2_1
I0628 20:36:56.084537  6212 net.cpp:122] Setting up pool2_1
I0628 20:36:56.084537  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.084537  6212 net.cpp:137] Memory required for data: 198759600
I0628 20:36:56.084537  6212 layer_factory.cpp:58] Creating layer conv3
I0628 20:36:56.084537  6212 net.cpp:84] Creating Layer conv3
I0628 20:36:56.084537  6212 net.cpp:406] conv3 <- pool2_1
I0628 20:36:56.084537  6212 net.cpp:380] conv3 -> conv3
I0628 20:36:56.085538  6212 net.cpp:122] Setting up conv3
I0628 20:36:56.085538  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.085538  6212 net.cpp:137] Memory required for data: 201319600
I0628 20:36:56.085538  6212 layer_factory.cpp:58] Creating layer bn3
I0628 20:36:56.085538  6212 net.cpp:84] Creating Layer bn3
I0628 20:36:56.085538  6212 net.cpp:406] bn3 <- conv3
I0628 20:36:56.085538  6212 net.cpp:367] bn3 -> conv3 (in-place)
I0628 20:36:56.085538  6212 net.cpp:122] Setting up bn3
I0628 20:36:56.085538  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.085538  6212 net.cpp:137] Memory required for data: 203879600
I0628 20:36:56.085538  6212 layer_factory.cpp:58] Creating layer scale3
I0628 20:36:56.085538  6212 net.cpp:84] Creating Layer scale3
I0628 20:36:56.085538  6212 net.cpp:406] scale3 <- conv3
I0628 20:36:56.085538  6212 net.cpp:367] scale3 -> conv3 (in-place)
I0628 20:36:56.085538  6212 layer_factory.cpp:58] Creating layer scale3
I0628 20:36:56.085538  6212 net.cpp:122] Setting up scale3
I0628 20:36:56.085538  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.085538  6212 net.cpp:137] Memory required for data: 206439600
I0628 20:36:56.085538  6212 layer_factory.cpp:58] Creating layer relu3
I0628 20:36:56.086038  6212 net.cpp:84] Creating Layer relu3
I0628 20:36:56.086038  6212 net.cpp:406] relu3 <- conv3
I0628 20:36:56.086038  6212 net.cpp:367] relu3 -> conv3 (in-place)
I0628 20:36:56.086364  6212 net.cpp:122] Setting up relu3
I0628 20:36:56.086364  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.086364  6212 net.cpp:137] Memory required for data: 208999600
I0628 20:36:56.086364  6212 layer_factory.cpp:58] Creating layer conv4
I0628 20:36:56.086364  6212 net.cpp:84] Creating Layer conv4
I0628 20:36:56.086364  6212 net.cpp:406] conv4 <- conv3
I0628 20:36:56.086364  6212 net.cpp:380] conv4 -> conv4
I0628 20:36:56.087368  6212 net.cpp:122] Setting up conv4
I0628 20:36:56.087867  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.087867  6212 net.cpp:137] Memory required for data: 211559600
I0628 20:36:56.087867  6212 layer_factory.cpp:58] Creating layer bn4
I0628 20:36:56.087867  6212 net.cpp:84] Creating Layer bn4
I0628 20:36:56.087867  6212 net.cpp:406] bn4 <- conv4
I0628 20:36:56.087867  6212 net.cpp:367] bn4 -> conv4 (in-place)
I0628 20:36:56.087867  6212 net.cpp:122] Setting up bn4
I0628 20:36:56.087867  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.087867  6212 net.cpp:137] Memory required for data: 214119600
I0628 20:36:56.087867  6212 layer_factory.cpp:58] Creating layer scale4
I0628 20:36:56.087867  6212 net.cpp:84] Creating Layer scale4
I0628 20:36:56.087867  6212 net.cpp:406] scale4 <- conv4
I0628 20:36:56.087867  6212 net.cpp:367] scale4 -> conv4 (in-place)
I0628 20:36:56.087867  6212 layer_factory.cpp:58] Creating layer scale4
I0628 20:36:56.087867  6212 net.cpp:122] Setting up scale4
I0628 20:36:56.087867  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.087867  6212 net.cpp:137] Memory required for data: 216679600
I0628 20:36:56.087867  6212 layer_factory.cpp:58] Creating layer relu4
I0628 20:36:56.087867  6212 net.cpp:84] Creating Layer relu4
I0628 20:36:56.087867  6212 net.cpp:406] relu4 <- conv4
I0628 20:36:56.087867  6212 net.cpp:367] relu4 -> conv4 (in-place)
I0628 20:36:56.088368  6212 net.cpp:122] Setting up relu4
I0628 20:36:56.088368  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.088368  6212 net.cpp:137] Memory required for data: 219239600
I0628 20:36:56.088368  6212 layer_factory.cpp:58] Creating layer conv4_1
I0628 20:36:56.088368  6212 net.cpp:84] Creating Layer conv4_1
I0628 20:36:56.088368  6212 net.cpp:406] conv4_1 <- conv4
I0628 20:36:56.088368  6212 net.cpp:380] conv4_1 -> conv4_1
I0628 20:36:56.089382  6212 net.cpp:122] Setting up conv4_1
I0628 20:36:56.089382  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.089382  6212 net.cpp:137] Memory required for data: 221799600
I0628 20:36:56.089382  6212 layer_factory.cpp:58] Creating layer bn4_1
I0628 20:36:56.089382  6212 net.cpp:84] Creating Layer bn4_1
I0628 20:36:56.089382  6212 net.cpp:406] bn4_1 <- conv4_1
I0628 20:36:56.089382  6212 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0628 20:36:56.089382  6212 net.cpp:122] Setting up bn4_1
I0628 20:36:56.089382  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.089382  6212 net.cpp:137] Memory required for data: 224359600
I0628 20:36:56.089382  6212 layer_factory.cpp:58] Creating layer scale4_1
I0628 20:36:56.089382  6212 net.cpp:84] Creating Layer scale4_1
I0628 20:36:56.089382  6212 net.cpp:406] scale4_1 <- conv4_1
I0628 20:36:56.089382  6212 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0628 20:36:56.089382  6212 layer_factory.cpp:58] Creating layer scale4_1
I0628 20:36:56.089382  6212 net.cpp:122] Setting up scale4_1
I0628 20:36:56.089382  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.089382  6212 net.cpp:137] Memory required for data: 226919600
I0628 20:36:56.089382  6212 layer_factory.cpp:58] Creating layer relu4_1
I0628 20:36:56.089382  6212 net.cpp:84] Creating Layer relu4_1
I0628 20:36:56.089382  6212 net.cpp:406] relu4_1 <- conv4_1
I0628 20:36:56.089382  6212 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0628 20:36:56.089382  6212 net.cpp:122] Setting up relu4_1
I0628 20:36:56.089382  6212 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 20:36:56.089382  6212 net.cpp:137] Memory required for data: 229479600
I0628 20:36:56.089382  6212 layer_factory.cpp:58] Creating layer conv4_2
I0628 20:36:56.089382  6212 net.cpp:84] Creating Layer conv4_2
I0628 20:36:56.089382  6212 net.cpp:406] conv4_2 <- conv4_1
I0628 20:36:56.089382  6212 net.cpp:380] conv4_2 -> conv4_2
I0628 20:36:56.090984  6212 net.cpp:122] Setting up conv4_2
I0628 20:36:56.090984  6212 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 20:36:56.090984  6212 net.cpp:137] Memory required for data: 236033200
I0628 20:36:56.090984  6212 layer_factory.cpp:58] Creating layer bn4_2
I0628 20:36:56.090984  6212 net.cpp:84] Creating Layer bn4_2
I0628 20:36:56.090984  6212 net.cpp:406] bn4_2 <- conv4_2
I0628 20:36:56.090984  6212 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0628 20:36:56.090984  6212 net.cpp:122] Setting up bn4_2
I0628 20:36:56.090984  6212 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 20:36:56.090984  6212 net.cpp:137] Memory required for data: 242586800
I0628 20:36:56.090984  6212 layer_factory.cpp:58] Creating layer scale4_2
I0628 20:36:56.090984  6212 net.cpp:84] Creating Layer scale4_2
I0628 20:36:56.090984  6212 net.cpp:406] scale4_2 <- conv4_2
I0628 20:36:56.090984  6212 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0628 20:36:56.090984  6212 layer_factory.cpp:58] Creating layer scale4_2
I0628 20:36:56.090984  6212 net.cpp:122] Setting up scale4_2
I0628 20:36:56.090984  6212 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 20:36:56.090984  6212 net.cpp:137] Memory required for data: 249140400
I0628 20:36:56.090984  6212 layer_factory.cpp:58] Creating layer relu4_2
I0628 20:36:56.090984  6212 net.cpp:84] Creating Layer relu4_2
I0628 20:36:56.090984  6212 net.cpp:406] relu4_2 <- conv4_2
I0628 20:36:56.090984  6212 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0628 20:36:56.090984  6212 net.cpp:122] Setting up relu4_2
I0628 20:36:56.090984  6212 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 20:36:56.090984  6212 net.cpp:137] Memory required for data: 255694000
I0628 20:36:56.090984  6212 layer_factory.cpp:58] Creating layer pool4_12
I0628 20:36:56.090984  6212 net.cpp:84] Creating Layer pool4_12
I0628 20:36:56.091986  6212 net.cpp:406] pool4_12 <- conv4_2
I0628 20:36:56.091986  6212 net.cpp:380] pool4_12 -> pool4_12
I0628 20:36:56.091986  6212 net.cpp:122] Setting up pool4_12
I0628 20:36:56.091986  6212 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0628 20:36:56.091986  6212 net.cpp:137] Memory required for data: 257332400
I0628 20:36:56.091986  6212 layer_factory.cpp:58] Creating layer conv4_0
I0628 20:36:56.091986  6212 net.cpp:84] Creating Layer conv4_0
I0628 20:36:56.091986  6212 net.cpp:406] conv4_0 <- pool4_12
I0628 20:36:56.091986  6212 net.cpp:380] conv4_0 -> conv4_0
I0628 20:36:56.092988  6212 net.cpp:122] Setting up conv4_0
I0628 20:36:56.092988  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.092988  6212 net.cpp:137] Memory required for data: 258689200
I0628 20:36:56.092988  6212 layer_factory.cpp:58] Creating layer bn4_0
I0628 20:36:56.092988  6212 net.cpp:84] Creating Layer bn4_0
I0628 20:36:56.092988  6212 net.cpp:406] bn4_0 <- conv4_0
I0628 20:36:56.092988  6212 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0628 20:36:56.092988  6212 net.cpp:122] Setting up bn4_0
I0628 20:36:56.092988  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.092988  6212 net.cpp:137] Memory required for data: 260046000
I0628 20:36:56.092988  6212 layer_factory.cpp:58] Creating layer scale4_0
I0628 20:36:56.092988  6212 net.cpp:84] Creating Layer scale4_0
I0628 20:36:56.092988  6212 net.cpp:406] scale4_0 <- conv4_0
I0628 20:36:56.092988  6212 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0628 20:36:56.092988  6212 layer_factory.cpp:58] Creating layer scale4_0
I0628 20:36:56.092988  6212 net.cpp:122] Setting up scale4_0
I0628 20:36:56.092988  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.092988  6212 net.cpp:137] Memory required for data: 261402800
I0628 20:36:56.092988  6212 layer_factory.cpp:58] Creating layer relu4_0
I0628 20:36:56.092988  6212 net.cpp:84] Creating Layer relu4_0
I0628 20:36:56.092988  6212 net.cpp:406] relu4_0 <- conv4_0
I0628 20:36:56.092988  6212 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0628 20:36:56.092988  6212 net.cpp:122] Setting up relu4_0
I0628 20:36:56.092988  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.092988  6212 net.cpp:137] Memory required for data: 262759600
I0628 20:36:56.092988  6212 layer_factory.cpp:58] Creating layer cccp4
I0628 20:36:56.092988  6212 net.cpp:84] Creating Layer cccp4
I0628 20:36:56.092988  6212 net.cpp:406] cccp4 <- conv4_0
I0628 20:36:56.092988  6212 net.cpp:380] cccp4 -> cccp4
I0628 20:36:56.094332  6212 net.cpp:122] Setting up cccp4
I0628 20:36:56.094332  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.094332  6212 net.cpp:137] Memory required for data: 264116400
I0628 20:36:56.094332  6212 layer_factory.cpp:58] Creating layer bn_cccp4
I0628 20:36:56.094332  6212 net.cpp:84] Creating Layer bn_cccp4
I0628 20:36:56.094332  6212 net.cpp:406] bn_cccp4 <- cccp4
I0628 20:36:56.094332  6212 net.cpp:367] bn_cccp4 -> cccp4 (in-place)
I0628 20:36:56.094332  6212 net.cpp:122] Setting up bn_cccp4
I0628 20:36:56.094332  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.094332  6212 net.cpp:137] Memory required for data: 265473200
I0628 20:36:56.094332  6212 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 20:36:56.094332  6212 net.cpp:84] Creating Layer scale_cccp4
I0628 20:36:56.094332  6212 net.cpp:406] scale_cccp4 <- cccp4
I0628 20:36:56.094332  6212 net.cpp:367] scale_cccp4 -> cccp4 (in-place)
I0628 20:36:56.094332  6212 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 20:36:56.094332  6212 net.cpp:122] Setting up scale_cccp4
I0628 20:36:56.094332  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.094332  6212 net.cpp:137] Memory required for data: 266830000
I0628 20:36:56.094332  6212 layer_factory.cpp:58] Creating layer relu_cccp4
I0628 20:36:56.094332  6212 net.cpp:84] Creating Layer relu_cccp4
I0628 20:36:56.094332  6212 net.cpp:406] relu_cccp4 <- cccp4
I0628 20:36:56.094332  6212 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0628 20:36:56.095335  6212 net.cpp:122] Setting up relu_cccp4
I0628 20:36:56.095335  6212 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 20:36:56.095335  6212 net.cpp:137] Memory required for data: 268186800
I0628 20:36:56.095335  6212 layer_factory.cpp:58] Creating layer pool4_2
I0628 20:36:56.095335  6212 net.cpp:84] Creating Layer pool4_2
I0628 20:36:56.095335  6212 net.cpp:406] pool4_2 <- cccp4
I0628 20:36:56.095335  6212 net.cpp:380] pool4_2 -> pool4_2
I0628 20:36:56.095335  6212 net.cpp:122] Setting up pool4_2
I0628 20:36:56.095335  6212 net.cpp:129] Top shape: 100 53 4 4 (84800)
I0628 20:36:56.095335  6212 net.cpp:137] Memory required for data: 268526000
I0628 20:36:56.095335  6212 layer_factory.cpp:58] Creating layer cccp5
I0628 20:36:56.095335  6212 net.cpp:84] Creating Layer cccp5
I0628 20:36:56.095335  6212 net.cpp:406] cccp5 <- pool4_2
I0628 20:36:56.095335  6212 net.cpp:380] cccp5 -> cccp5
I0628 20:36:56.096335  6212 net.cpp:122] Setting up cccp5
I0628 20:36:56.096335  6212 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 20:36:56.096335  6212 net.cpp:137] Memory required for data: 270081200
I0628 20:36:56.096335  6212 layer_factory.cpp:58] Creating layer bn_cccp5
I0628 20:36:56.096335  6212 net.cpp:84] Creating Layer bn_cccp5
I0628 20:36:56.096335  6212 net.cpp:406] bn_cccp5 <- cccp5
I0628 20:36:56.096335  6212 net.cpp:367] bn_cccp5 -> cccp5 (in-place)
I0628 20:36:56.096335  6212 net.cpp:122] Setting up bn_cccp5
I0628 20:36:56.096335  6212 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 20:36:56.096335  6212 net.cpp:137] Memory required for data: 271636400
I0628 20:36:56.096335  6212 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 20:36:56.096335  6212 net.cpp:84] Creating Layer scale_cccp5
I0628 20:36:56.096335  6212 net.cpp:406] scale_cccp5 <- cccp5
I0628 20:36:56.096335  6212 net.cpp:367] scale_cccp5 -> cccp5 (in-place)
I0628 20:36:56.096335  6212 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 20:36:56.096335  6212 net.cpp:122] Setting up scale_cccp5
I0628 20:36:56.096335  6212 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 20:36:56.096335  6212 net.cpp:137] Memory required for data: 273191600
I0628 20:36:56.096335  6212 layer_factory.cpp:58] Creating layer relu_cccp5
I0628 20:36:56.096335  6212 net.cpp:84] Creating Layer relu_cccp5
I0628 20:36:56.096335  6212 net.cpp:406] relu_cccp5 <- cccp5
I0628 20:36:56.096335  6212 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0628 20:36:56.097337  6212 net.cpp:122] Setting up relu_cccp5
I0628 20:36:56.097337  6212 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 20:36:56.097337  6212 net.cpp:137] Memory required for data: 274746800
I0628 20:36:56.097337  6212 layer_factory.cpp:58] Creating layer poolcp5
I0628 20:36:56.097337  6212 net.cpp:84] Creating Layer poolcp5
I0628 20:36:56.097337  6212 net.cpp:406] poolcp5 <- cccp5
I0628 20:36:56.097337  6212 net.cpp:380] poolcp5 -> poolcp5
I0628 20:36:56.097337  6212 net.cpp:122] Setting up poolcp5
I0628 20:36:56.097337  6212 net.cpp:129] Top shape: 100 108 3 3 (97200)
I0628 20:36:56.097337  6212 net.cpp:137] Memory required for data: 275135600
I0628 20:36:56.097337  6212 layer_factory.cpp:58] Creating layer cccp6
I0628 20:36:56.097337  6212 net.cpp:84] Creating Layer cccp6
I0628 20:36:56.097337  6212 net.cpp:406] cccp6 <- poolcp5
I0628 20:36:56.097337  6212 net.cpp:380] cccp6 -> cccp6
I0628 20:36:56.098336  6212 net.cpp:122] Setting up cccp6
I0628 20:36:56.098336  6212 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 20:36:56.098336  6212 net.cpp:137] Memory required for data: 276215600
I0628 20:36:56.098336  6212 layer_factory.cpp:58] Creating layer bn_cccp6
I0628 20:36:56.098336  6212 net.cpp:84] Creating Layer bn_cccp6
I0628 20:36:56.098336  6212 net.cpp:406] bn_cccp6 <- cccp6
I0628 20:36:56.098336  6212 net.cpp:367] bn_cccp6 -> cccp6 (in-place)
I0628 20:36:56.098336  6212 net.cpp:122] Setting up bn_cccp6
I0628 20:36:56.098336  6212 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 20:36:56.098336  6212 net.cpp:137] Memory required for data: 277295600
I0628 20:36:56.098336  6212 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 20:36:56.098336  6212 net.cpp:84] Creating Layer scale_cccp6
I0628 20:36:56.098336  6212 net.cpp:406] scale_cccp6 <- cccp6
I0628 20:36:56.098336  6212 net.cpp:367] scale_cccp6 -> cccp6 (in-place)
I0628 20:36:56.098336  6212 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 20:36:56.098336  6212 net.cpp:122] Setting up scale_cccp6
I0628 20:36:56.098336  6212 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 20:36:56.098336  6212 net.cpp:137] Memory required for data: 278375600
I0628 20:36:56.098336  6212 layer_factory.cpp:58] Creating layer relu_cccp6
I0628 20:36:56.098336  6212 net.cpp:84] Creating Layer relu_cccp6
I0628 20:36:56.098336  6212 net.cpp:406] relu_cccp6 <- cccp6
I0628 20:36:56.098336  6212 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0628 20:36:56.099337  6212 net.cpp:122] Setting up relu_cccp6
I0628 20:36:56.099337  6212 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 20:36:56.099337  6212 net.cpp:137] Memory required for data: 279455600
I0628 20:36:56.099337  6212 layer_factory.cpp:58] Creating layer poolcp6
I0628 20:36:56.099337  6212 net.cpp:84] Creating Layer poolcp6
I0628 20:36:56.099337  6212 net.cpp:406] poolcp6 <- cccp6
I0628 20:36:56.099337  6212 net.cpp:380] poolcp6 -> poolcp6
I0628 20:36:56.099337  6212 net.cpp:122] Setting up poolcp6
I0628 20:36:56.099337  6212 net.cpp:129] Top shape: 100 108 1 1 (10800)
I0628 20:36:56.099337  6212 net.cpp:137] Memory required for data: 279498800
I0628 20:36:56.099337  6212 layer_factory.cpp:58] Creating layer ip1
I0628 20:36:56.099337  6212 net.cpp:84] Creating Layer ip1
I0628 20:36:56.099337  6212 net.cpp:406] ip1 <- poolcp6
I0628 20:36:56.099337  6212 net.cpp:380] ip1 -> ip1
I0628 20:36:56.099337  6212 net.cpp:122] Setting up ip1
I0628 20:36:56.099337  6212 net.cpp:129] Top shape: 100 10 (1000)
I0628 20:36:56.099337  6212 net.cpp:137] Memory required for data: 279502800
I0628 20:36:56.099337  6212 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0628 20:36:56.099337  6212 net.cpp:84] Creating Layer ip1_ip1_0_split
I0628 20:36:56.099337  6212 net.cpp:406] ip1_ip1_0_split <- ip1
I0628 20:36:56.099337  6212 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0628 20:36:56.099337  6212 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0628 20:36:56.099337  6212 net.cpp:122] Setting up ip1_ip1_0_split
I0628 20:36:56.099337  6212 net.cpp:129] Top shape: 100 10 (1000)
I0628 20:36:56.099337  6212 net.cpp:129] Top shape: 100 10 (1000)
I0628 20:36:56.099337  6212 net.cpp:137] Memory required for data: 279510800
I0628 20:36:56.099337  6212 layer_factory.cpp:58] Creating layer accuracy
I0628 20:36:56.099337  6212 net.cpp:84] Creating Layer accuracy
I0628 20:36:56.099337  6212 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0628 20:36:56.099337  6212 net.cpp:406] accuracy <- label_cifar_1_split_0
I0628 20:36:56.099337  6212 net.cpp:380] accuracy -> accuracy
I0628 20:36:56.099337  6212 net.cpp:122] Setting up accuracy
I0628 20:36:56.099337  6212 net.cpp:129] Top shape: (1)
I0628 20:36:56.099337  6212 net.cpp:137] Memory required for data: 279510804
I0628 20:36:56.099337  6212 layer_factory.cpp:58] Creating layer loss
I0628 20:36:56.099337  6212 net.cpp:84] Creating Layer loss
I0628 20:36:56.099337  6212 net.cpp:406] loss <- ip1_ip1_0_split_1
I0628 20:36:56.099337  6212 net.cpp:406] loss <- label_cifar_1_split_1
I0628 20:36:56.099337  6212 net.cpp:380] loss -> loss
I0628 20:36:56.099337  6212 layer_factory.cpp:58] Creating layer loss
I0628 20:36:56.099337  6212 net.cpp:122] Setting up loss
I0628 20:36:56.099337  6212 net.cpp:129] Top shape: (1)
I0628 20:36:56.099337  6212 net.cpp:132]     with loss weight 1
I0628 20:36:56.099337  6212 net.cpp:137] Memory required for data: 279510808
I0628 20:36:56.099337  6212 net.cpp:198] loss needs backward computation.
I0628 20:36:56.099337  6212 net.cpp:200] accuracy does not need backward computation.
I0628 20:36:56.099337  6212 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0628 20:36:56.099337  6212 net.cpp:198] ip1 needs backward computation.
I0628 20:36:56.099337  6212 net.cpp:198] poolcp6 needs backward computation.
I0628 20:36:56.099337  6212 net.cpp:198] relu_cccp6 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale_cccp6 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn_cccp6 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] cccp6 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] poolcp5 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu_cccp5 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale_cccp5 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn_cccp5 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] cccp5 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] pool4_2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu_cccp4 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale_cccp4 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn_cccp4 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] cccp4 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu4_0 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale4_0 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn4_0 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] conv4_0 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] pool4_12 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu4_2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale4_2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn4_2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] conv4_2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu4_1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale4_1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn4_1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] conv4_1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu4 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale4 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn4 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] conv4 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu3 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale3 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn3 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] conv3 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] pool2_1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu2_2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale2_2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn2_2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] conv2_2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu2_1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale2_1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn2_1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] conv2_1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] conv2 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu1_0 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale1_0 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn1_0 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] conv1_0 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] relu1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] scale1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] bn1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:198] conv1 needs backward computation.
I0628 20:36:56.100350  6212 net.cpp:200] label_cifar_1_split does not need backward computation.
I0628 20:36:56.100350  6212 net.cpp:200] cifar does not need backward computation.
I0628 20:36:56.100350  6212 net.cpp:242] This network produces output accuracy
I0628 20:36:56.100350  6212 net.cpp:242] This network produces output loss
I0628 20:36:56.100350  6212 net.cpp:255] Network initialization done.
I0628 20:36:56.100350  6212 solver.cpp:56] Solver scaffolding done.
I0628 20:36:56.103353  6212 caffe.cpp:249] Starting Optimization
I0628 20:36:56.103353  6212 solver.cpp:272] Solving CIFAR10_SimpleNet_13_128k_end1x1
I0628 20:36:56.103353  6212 solver.cpp:273] Learning Rate Policy: multistep
I0628 20:36:56.105083  6212 solver.cpp:330] Iteration 0, Testing net (#0)
I0628 20:36:56.106084  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:36:56.968773  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:36:56.999061  6212 solver.cpp:397]     Test net output #0: accuracy = 0.0998
I0628 20:36:56.999061  6212 solver.cpp:397]     Test net output #1: loss = 78.6204 (* 1 = 78.6204 loss)
I0628 20:36:57.070240  6212 solver.cpp:218] Iteration 0 (-nan iter/s, 0.965916s/100 iters), loss = 3.82823
I0628 20:36:57.070240  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I0628 20:36:57.070240  6212 solver.cpp:237]     Train net output #1: loss = 3.82823 (* 1 = 3.82823 loss)
I0628 20:36:57.070240  6212 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0628 20:37:00.725316  6212 solver.cpp:218] Iteration 100 (27.3581 iter/s, 3.65523s/100 iters), loss = 1.71527
I0628 20:37:00.725316  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I0628 20:37:00.725316  6212 solver.cpp:237]     Train net output #1: loss = 1.71527 (* 1 = 1.71527 loss)
I0628 20:37:00.725316  6212 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0628 20:37:04.375358  6212 solver.cpp:218] Iteration 200 (27.4058 iter/s, 3.64886s/100 iters), loss = 1.68744
I0628 20:37:04.375358  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I0628 20:37:04.375358  6212 solver.cpp:237]     Train net output #1: loss = 1.68744 (* 1 = 1.68744 loss)
I0628 20:37:04.375358  6212 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0628 20:37:07.958341  6212 solver.cpp:218] Iteration 300 (27.908 iter/s, 3.5832s/100 iters), loss = 1.51211
I0628 20:37:07.958341  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I0628 20:37:07.958341  6212 solver.cpp:237]     Train net output #1: loss = 1.51211 (* 1 = 1.51211 loss)
I0628 20:37:07.958341  6212 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0628 20:37:11.544512  6212 solver.cpp:218] Iteration 400 (27.8875 iter/s, 3.58584s/100 iters), loss = 1.3066
I0628 20:37:11.544512  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I0628 20:37:11.544512  6212 solver.cpp:237]     Train net output #1: loss = 1.3066 (* 1 = 1.3066 loss)
I0628 20:37:11.544512  6212 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0628 20:37:14.955309 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:37:15.095479  6212 solver.cpp:330] Iteration 500, Testing net (#0)
I0628 20:37:15.095980  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:37:15.908987  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:37:15.940009  6212 solver.cpp:397]     Test net output #0: accuracy = 0.4721
I0628 20:37:15.940009  6212 solver.cpp:397]     Test net output #1: loss = 1.43217 (* 1 = 1.43217 loss)
I0628 20:37:15.974047  6212 solver.cpp:218] Iteration 500 (22.579 iter/s, 4.42889s/100 iters), loss = 1.56658
I0628 20:37:15.974047  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I0628 20:37:15.974047  6212 solver.cpp:237]     Train net output #1: loss = 1.56658 (* 1 = 1.56658 loss)
I0628 20:37:15.974047  6212 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0628 20:37:19.575814  6212 solver.cpp:218] Iteration 600 (27.7666 iter/s, 3.60145s/100 iters), loss = 1.3868
I0628 20:37:19.575814  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I0628 20:37:19.575814  6212 solver.cpp:237]     Train net output #1: loss = 1.3868 (* 1 = 1.3868 loss)
I0628 20:37:19.575814  6212 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0628 20:37:23.176800  6212 solver.cpp:218] Iteration 700 (27.7745 iter/s, 3.60042s/100 iters), loss = 1.37175
I0628 20:37:23.176800  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I0628 20:37:23.176800  6212 solver.cpp:237]     Train net output #1: loss = 1.37175 (* 1 = 1.37175 loss)
I0628 20:37:23.176800  6212 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0628 20:37:26.765699  6212 solver.cpp:218] Iteration 800 (27.8676 iter/s, 3.5884s/100 iters), loss = 1.26461
I0628 20:37:26.765699  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I0628 20:37:26.765699  6212 solver.cpp:237]     Train net output #1: loss = 1.26461 (* 1 = 1.26461 loss)
I0628 20:37:26.765699  6212 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0628 20:37:30.355671  6212 solver.cpp:218] Iteration 900 (27.8571 iter/s, 3.58975s/100 iters), loss = 1.19558
I0628 20:37:30.355671  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I0628 20:37:30.355671  6212 solver.cpp:237]     Train net output #1: loss = 1.19558 (* 1 = 1.19558 loss)
I0628 20:37:30.355671  6212 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0628 20:37:33.769667 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:37:33.910831  6212 solver.cpp:330] Iteration 1000, Testing net (#0)
I0628 20:37:33.910831  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:37:34.723065  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:37:34.754091  6212 solver.cpp:397]     Test net output #0: accuracy = 0.5724
I0628 20:37:34.754091  6212 solver.cpp:397]     Test net output #1: loss = 1.1956 (* 1 = 1.1956 loss)
I0628 20:37:34.788112  6212 solver.cpp:218] Iteration 1000 (22.5616 iter/s, 4.43231s/100 iters), loss = 1.30375
I0628 20:37:34.788112  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I0628 20:37:34.788112  6212 solver.cpp:237]     Train net output #1: loss = 1.30375 (* 1 = 1.30375 loss)
I0628 20:37:34.788112  6212 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0628 20:37:38.374799  6212 solver.cpp:218] Iteration 1100 (27.8831 iter/s, 3.5864s/100 iters), loss = 1.1538
I0628 20:37:38.374799  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I0628 20:37:38.374799  6212 solver.cpp:237]     Train net output #1: loss = 1.1538 (* 1 = 1.1538 loss)
I0628 20:37:38.374799  6212 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0628 20:37:41.968819  6212 solver.cpp:218] Iteration 1200 (27.8267 iter/s, 3.59367s/100 iters), loss = 1.15296
I0628 20:37:41.968819  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I0628 20:37:41.968819  6212 solver.cpp:237]     Train net output #1: loss = 1.15296 (* 1 = 1.15296 loss)
I0628 20:37:41.968819  6212 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0628 20:37:45.560736  6212 solver.cpp:218] Iteration 1300 (27.8455 iter/s, 3.59125s/100 iters), loss = 1.03696
I0628 20:37:45.560736  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0628 20:37:45.560736  6212 solver.cpp:237]     Train net output #1: loss = 1.03696 (* 1 = 1.03696 loss)
I0628 20:37:45.560736  6212 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0628 20:37:49.144289  6212 solver.cpp:218] Iteration 1400 (27.9064 iter/s, 3.58341s/100 iters), loss = 0.882934
I0628 20:37:49.144289  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0628 20:37:49.144289  6212 solver.cpp:237]     Train net output #1: loss = 0.882934 (* 1 = 0.882934 loss)
I0628 20:37:49.144289  6212 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0628 20:37:52.594156 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:37:52.735260  6212 solver.cpp:330] Iteration 1500, Testing net (#0)
I0628 20:37:52.735260  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:37:53.551733  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:37:53.582756  6212 solver.cpp:397]     Test net output #0: accuracy = 0.6384
I0628 20:37:53.582756  6212 solver.cpp:397]     Test net output #1: loss = 1.00899 (* 1 = 1.00899 loss)
I0628 20:37:53.616782  6212 solver.cpp:218] Iteration 1500 (22.3613 iter/s, 4.472s/100 iters), loss = 1.02735
I0628 20:37:53.616782  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I0628 20:37:53.616782  6212 solver.cpp:237]     Train net output #1: loss = 1.02735 (* 1 = 1.02735 loss)
I0628 20:37:53.616782  6212 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0628 20:37:57.224649  6212 solver.cpp:218] Iteration 1600 (27.7141 iter/s, 3.60828s/100 iters), loss = 0.989773
I0628 20:37:57.225651  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0628 20:37:57.225651  6212 solver.cpp:237]     Train net output #1: loss = 0.989773 (* 1 = 0.989773 loss)
I0628 20:37:57.225651  6212 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0628 20:38:00.827384  6212 solver.cpp:218] Iteration 1700 (27.7641 iter/s, 3.60177s/100 iters), loss = 0.948427
I0628 20:38:00.827384  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0628 20:38:00.827384  6212 solver.cpp:237]     Train net output #1: loss = 0.948427 (* 1 = 0.948427 loss)
I0628 20:38:00.827384  6212 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0628 20:38:04.429059  6212 solver.cpp:218] Iteration 1800 (27.7687 iter/s, 3.60118s/100 iters), loss = 0.935563
I0628 20:38:04.429059  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I0628 20:38:04.429059  6212 solver.cpp:237]     Train net output #1: loss = 0.935563 (* 1 = 0.935563 loss)
I0628 20:38:04.429059  6212 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0628 20:38:08.032526  6212 solver.cpp:218] Iteration 1900 (27.7539 iter/s, 3.60309s/100 iters), loss = 1.00597
I0628 20:38:08.032526  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0628 20:38:08.032526  6212 solver.cpp:237]     Train net output #1: loss = 1.00597 (* 1 = 1.00597 loss)
I0628 20:38:08.032526  6212 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0628 20:38:11.462086 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:38:11.603693  6212 solver.cpp:330] Iteration 2000, Testing net (#0)
I0628 20:38:11.603693  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:38:12.416627  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:38:12.447649  6212 solver.cpp:397]     Test net output #0: accuracy = 0.6698
I0628 20:38:12.448650  6212 solver.cpp:397]     Test net output #1: loss = 0.923961 (* 1 = 0.923961 loss)
I0628 20:38:12.481673  6212 solver.cpp:218] Iteration 2000 (22.4739 iter/s, 4.4496s/100 iters), loss = 0.90493
I0628 20:38:12.481673  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0628 20:38:12.481673  6212 solver.cpp:237]     Train net output #1: loss = 0.90493 (* 1 = 0.90493 loss)
I0628 20:38:12.481673  6212 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0628 20:38:16.096369  6212 solver.cpp:218] Iteration 2100 (27.6721 iter/s, 3.61375s/100 iters), loss = 0.779272
I0628 20:38:16.096369  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I0628 20:38:16.096369  6212 solver.cpp:237]     Train net output #1: loss = 0.779272 (* 1 = 0.779272 loss)
I0628 20:38:16.096369  6212 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0628 20:38:19.702282  6212 solver.cpp:218] Iteration 2200 (27.7341 iter/s, 3.60567s/100 iters), loss = 0.837708
I0628 20:38:19.702282  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0628 20:38:19.702282  6212 solver.cpp:237]     Train net output #1: loss = 0.837708 (* 1 = 0.837708 loss)
I0628 20:38:19.702282  6212 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0628 20:38:23.316838  6212 solver.cpp:218] Iteration 2300 (27.6692 iter/s, 3.61413s/100 iters), loss = 0.990416
I0628 20:38:23.316838  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0628 20:38:23.316838  6212 solver.cpp:237]     Train net output #1: loss = 0.990416 (* 1 = 0.990416 loss)
I0628 20:38:23.316838  6212 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0628 20:38:26.924180  6212 solver.cpp:218] Iteration 2400 (27.7258 iter/s, 3.60675s/100 iters), loss = 0.788146
I0628 20:38:26.924180  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0628 20:38:26.924180  6212 solver.cpp:237]     Train net output #1: loss = 0.788146 (* 1 = 0.788146 loss)
I0628 20:38:26.924180  6212 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0628 20:38:30.359853 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:38:30.500604  6212 solver.cpp:330] Iteration 2500, Testing net (#0)
I0628 20:38:30.500604  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:38:31.318531  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:38:31.350067  6212 solver.cpp:397]     Test net output #0: accuracy = 0.633
I0628 20:38:31.350067  6212 solver.cpp:397]     Test net output #1: loss = 1.05547 (* 1 = 1.05547 loss)
I0628 20:38:31.385107  6212 solver.cpp:218] Iteration 2500 (22.4188 iter/s, 4.46054s/100 iters), loss = 0.838045
I0628 20:38:31.385107  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0628 20:38:31.385107  6212 solver.cpp:237]     Train net output #1: loss = 0.838045 (* 1 = 0.838045 loss)
I0628 20:38:31.385107  6212 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0628 20:38:34.991843  6212 solver.cpp:218] Iteration 2600 (27.7246 iter/s, 3.6069s/100 iters), loss = 0.642754
I0628 20:38:34.991843  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 20:38:34.991843  6212 solver.cpp:237]     Train net output #1: loss = 0.642754 (* 1 = 0.642754 loss)
I0628 20:38:34.991843  6212 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0628 20:38:38.613932  6212 solver.cpp:218] Iteration 2700 (27.6087 iter/s, 3.62204s/100 iters), loss = 0.816565
I0628 20:38:38.613932  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0628 20:38:38.613932  6212 solver.cpp:237]     Train net output #1: loss = 0.816565 (* 1 = 0.816565 loss)
I0628 20:38:38.613932  6212 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0628 20:38:42.215894  6212 solver.cpp:218] Iteration 2800 (27.77 iter/s, 3.601s/100 iters), loss = 0.741961
I0628 20:38:42.215894  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0628 20:38:42.215894  6212 solver.cpp:237]     Train net output #1: loss = 0.741961 (* 1 = 0.741961 loss)
I0628 20:38:42.215894  6212 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0628 20:38:45.822069  6212 solver.cpp:218] Iteration 2900 (27.7277 iter/s, 3.6065s/100 iters), loss = 0.766149
I0628 20:38:45.822069  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0628 20:38:45.822069  6212 solver.cpp:237]     Train net output #1: loss = 0.766149 (* 1 = 0.766149 loss)
I0628 20:38:45.822069  6212 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0628 20:38:49.255689 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:38:49.396294  6212 solver.cpp:330] Iteration 3000, Testing net (#0)
I0628 20:38:49.396294  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:38:50.210006  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:38:50.241533  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7129
I0628 20:38:50.241533  6212 solver.cpp:397]     Test net output #1: loss = 0.829067 (* 1 = 0.829067 loss)
I0628 20:38:50.275671  6212 solver.cpp:218] Iteration 3000 (22.4598 iter/s, 4.45239s/100 iters), loss = 0.787932
I0628 20:38:50.275671  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 20:38:50.275671  6212 solver.cpp:237]     Train net output #1: loss = 0.787932 (* 1 = 0.787932 loss)
I0628 20:38:50.275671  6212 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0628 20:38:53.902489  6212 solver.cpp:218] Iteration 3100 (27.568 iter/s, 3.62739s/100 iters), loss = 0.700269
I0628 20:38:53.903494  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 20:38:53.903494  6212 solver.cpp:237]     Train net output #1: loss = 0.700269 (* 1 = 0.700269 loss)
I0628 20:38:53.903494  6212 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0628 20:38:57.514623  6212 solver.cpp:218] Iteration 3200 (27.6891 iter/s, 3.61153s/100 iters), loss = 0.786703
I0628 20:38:57.514623  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0628 20:38:57.514623  6212 solver.cpp:237]     Train net output #1: loss = 0.786703 (* 1 = 0.786703 loss)
I0628 20:38:57.514623  6212 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0628 20:39:01.139004  6212 solver.cpp:218] Iteration 3300 (27.5922 iter/s, 3.62421s/100 iters), loss = 0.744457
I0628 20:39:01.139004  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0628 20:39:01.139004  6212 solver.cpp:237]     Train net output #1: loss = 0.744457 (* 1 = 0.744457 loss)
I0628 20:39:01.140005  6212 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0628 20:39:04.749614  6212 solver.cpp:218] Iteration 3400 (27.7028 iter/s, 3.60974s/100 iters), loss = 0.701986
I0628 20:39:04.749614  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0628 20:39:04.749614  6212 solver.cpp:237]     Train net output #1: loss = 0.701986 (* 1 = 0.701986 loss)
I0628 20:39:04.749614  6212 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0628 20:39:08.183060 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:39:08.324697  6212 solver.cpp:330] Iteration 3500, Testing net (#0)
I0628 20:39:08.324697  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:39:09.148569  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:39:09.171104  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7256
I0628 20:39:09.171605  6212 solver.cpp:397]     Test net output #1: loss = 0.783056 (* 1 = 0.783056 loss)
I0628 20:39:09.204645  6212 solver.cpp:218] Iteration 3500 (22.446 iter/s, 4.45513s/100 iters), loss = 0.679644
I0628 20:39:09.204645  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 20:39:09.204645  6212 solver.cpp:237]     Train net output #1: loss = 0.679644 (* 1 = 0.679644 loss)
I0628 20:39:09.204645  6212 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0628 20:39:12.815704  6212 solver.cpp:218] Iteration 3600 (27.6986 iter/s, 3.6103s/100 iters), loss = 0.619754
I0628 20:39:12.815704  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 20:39:12.815704  6212 solver.cpp:237]     Train net output #1: loss = 0.619754 (* 1 = 0.619754 loss)
I0628 20:39:12.815704  6212 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0628 20:39:16.430652  6212 solver.cpp:218] Iteration 3700 (27.6688 iter/s, 3.61418s/100 iters), loss = 0.705281
I0628 20:39:16.430652  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0628 20:39:16.430652  6212 solver.cpp:237]     Train net output #1: loss = 0.705281 (* 1 = 0.705281 loss)
I0628 20:39:16.430652  6212 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0628 20:39:20.039562  6212 solver.cpp:218] Iteration 3800 (27.7075 iter/s, 3.60913s/100 iters), loss = 0.703652
I0628 20:39:20.039562  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0628 20:39:20.039562  6212 solver.cpp:237]     Train net output #1: loss = 0.703652 (* 1 = 0.703652 loss)
I0628 20:39:20.039562  6212 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0628 20:39:23.661756  6212 solver.cpp:218] Iteration 3900 (27.6086 iter/s, 3.62206s/100 iters), loss = 0.594312
I0628 20:39:23.661756  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0628 20:39:23.661756  6212 solver.cpp:237]     Train net output #1: loss = 0.594312 (* 1 = 0.594312 loss)
I0628 20:39:23.661756  6212 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0628 20:39:27.104225 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:39:27.245363  6212 solver.cpp:330] Iteration 4000, Testing net (#0)
I0628 20:39:27.245363  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:39:28.062909  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:39:28.094458  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7315
I0628 20:39:28.094458  6212 solver.cpp:397]     Test net output #1: loss = 0.777282 (* 1 = 0.777282 loss)
I0628 20:39:28.128476  6212 solver.cpp:218] Iteration 4000 (22.3896 iter/s, 4.46636s/100 iters), loss = 0.706002
I0628 20:39:28.128476  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0628 20:39:28.128476  6212 solver.cpp:237]     Train net output #1: loss = 0.706002 (* 1 = 0.706002 loss)
I0628 20:39:28.128476  6212 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0628 20:39:31.743760  6212 solver.cpp:218] Iteration 4100 (27.6673 iter/s, 3.61438s/100 iters), loss = 0.587112
I0628 20:39:31.743760  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 20:39:31.743760  6212 solver.cpp:237]     Train net output #1: loss = 0.587112 (* 1 = 0.587112 loss)
I0628 20:39:31.743760  6212 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0628 20:39:35.360638  6212 solver.cpp:218] Iteration 4200 (27.6493 iter/s, 3.61673s/100 iters), loss = 0.606488
I0628 20:39:35.360638  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 20:39:35.360638  6212 solver.cpp:237]     Train net output #1: loss = 0.606488 (* 1 = 0.606488 loss)
I0628 20:39:35.360638  6212 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0628 20:39:38.979955  6212 solver.cpp:218] Iteration 4300 (27.6348 iter/s, 3.61862s/100 iters), loss = 0.711093
I0628 20:39:38.979955  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 20:39:38.979955  6212 solver.cpp:237]     Train net output #1: loss = 0.711093 (* 1 = 0.711093 loss)
I0628 20:39:38.979955  6212 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0628 20:39:42.586971  6212 solver.cpp:218] Iteration 4400 (27.7223 iter/s, 3.60721s/100 iters), loss = 0.552356
I0628 20:39:42.586971  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 20:39:42.586971  6212 solver.cpp:237]     Train net output #1: loss = 0.552356 (* 1 = 0.552356 loss)
I0628 20:39:42.586971  6212 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0628 20:39:46.025966 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:39:46.168093  6212 solver.cpp:330] Iteration 4500, Testing net (#0)
I0628 20:39:46.168093  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:39:46.984519  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:39:47.016556  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7402
I0628 20:39:47.016556  6212 solver.cpp:397]     Test net output #1: loss = 0.789385 (* 1 = 0.789385 loss)
I0628 20:39:47.050590  6212 solver.cpp:218] Iteration 4500 (22.4052 iter/s, 4.46326s/100 iters), loss = 0.643057
I0628 20:39:47.050590  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0628 20:39:47.050590  6212 solver.cpp:237]     Train net output #1: loss = 0.643057 (* 1 = 0.643057 loss)
I0628 20:39:47.050590  6212 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0628 20:39:50.664294  6212 solver.cpp:218] Iteration 4600 (27.6797 iter/s, 3.61275s/100 iters), loss = 0.439539
I0628 20:39:50.664294  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:39:50.664294  6212 solver.cpp:237]     Train net output #1: loss = 0.439539 (* 1 = 0.439539 loss)
I0628 20:39:50.664294  6212 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0628 20:39:54.284485  6212 solver.cpp:218] Iteration 4700 (27.6259 iter/s, 3.6198s/100 iters), loss = 0.672157
I0628 20:39:54.284485  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0628 20:39:54.284485  6212 solver.cpp:237]     Train net output #1: loss = 0.672157 (* 1 = 0.672157 loss)
I0628 20:39:54.284485  6212 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0628 20:39:57.898386  6212 solver.cpp:218] Iteration 4800 (27.6685 iter/s, 3.61422s/100 iters), loss = 0.6856
I0628 20:39:57.898386  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 20:39:57.898386  6212 solver.cpp:237]     Train net output #1: loss = 0.6856 (* 1 = 0.6856 loss)
I0628 20:39:57.898386  6212 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0628 20:40:01.512755  6212 solver.cpp:218] Iteration 4900 (27.6726 iter/s, 3.61369s/100 iters), loss = 0.542788
I0628 20:40:01.512755  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:40:01.512755  6212 solver.cpp:237]     Train net output #1: loss = 0.542788 (* 1 = 0.542788 loss)
I0628 20:40:01.512755  6212 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0628 20:40:04.948810 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:40:05.089912  6212 solver.cpp:330] Iteration 5000, Testing net (#0)
I0628 20:40:05.089912  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:40:05.918027  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:40:05.940546  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7569
I0628 20:40:05.940546  6212 solver.cpp:397]     Test net output #1: loss = 0.695758 (* 1 = 0.695758 loss)
I0628 20:40:05.974570  6212 solver.cpp:218] Iteration 5000 (22.4112 iter/s, 4.46205s/100 iters), loss = 0.58401
I0628 20:40:05.975575  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 20:40:05.975575  6212 solver.cpp:237]     Train net output #1: loss = 0.58401 (* 1 = 0.58401 loss)
I0628 20:40:05.975575  6212 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0628 20:40:09.603467  6212 solver.cpp:218] Iteration 5100 (27.5648 iter/s, 3.62781s/100 iters), loss = 0.557242
I0628 20:40:09.603467  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 20:40:09.603467  6212 solver.cpp:237]     Train net output #1: loss = 0.557242 (* 1 = 0.557242 loss)
I0628 20:40:09.603467  6212 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0628 20:40:13.207345  6212 solver.cpp:218] Iteration 5200 (27.7494 iter/s, 3.60368s/100 iters), loss = 0.619878
I0628 20:40:13.207345  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 20:40:13.207345  6212 solver.cpp:237]     Train net output #1: loss = 0.619878 (* 1 = 0.619878 loss)
I0628 20:40:13.207345  6212 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0628 20:40:16.818842  6212 solver.cpp:218] Iteration 5300 (27.6918 iter/s, 3.61117s/100 iters), loss = 0.587037
I0628 20:40:16.818842  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 20:40:16.818842  6212 solver.cpp:237]     Train net output #1: loss = 0.587037 (* 1 = 0.587037 loss)
I0628 20:40:16.818842  6212 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0628 20:40:20.435235  6212 solver.cpp:218] Iteration 5400 (27.6558 iter/s, 3.61587s/100 iters), loss = 0.625267
I0628 20:40:20.435235  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0628 20:40:20.435235  6212 solver.cpp:237]     Train net output #1: loss = 0.625267 (* 1 = 0.625267 loss)
I0628 20:40:20.435235  6212 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0628 20:40:23.874368 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:40:24.016472  6212 solver.cpp:330] Iteration 5500, Testing net (#0)
I0628 20:40:24.016472  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:40:24.831091  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:40:24.862114  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7568
I0628 20:40:24.862114  6212 solver.cpp:397]     Test net output #1: loss = 0.688764 (* 1 = 0.688764 loss)
I0628 20:40:24.896138  6212 solver.cpp:218] Iteration 5500 (22.4162 iter/s, 4.46107s/100 iters), loss = 0.478176
I0628 20:40:24.896138  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:40:24.896138  6212 solver.cpp:237]     Train net output #1: loss = 0.478176 (* 1 = 0.478176 loss)
I0628 20:40:24.896138  6212 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0628 20:40:28.513178  6212 solver.cpp:218] Iteration 5600 (27.6488 iter/s, 3.61679s/100 iters), loss = 0.478524
I0628 20:40:28.513178  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:40:28.513178  6212 solver.cpp:237]     Train net output #1: loss = 0.478524 (* 1 = 0.478524 loss)
I0628 20:40:28.514179  6212 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0628 20:40:32.129025  6212 solver.cpp:218] Iteration 5700 (27.6603 iter/s, 3.61529s/100 iters), loss = 0.608339
I0628 20:40:32.129025  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 20:40:32.129025  6212 solver.cpp:237]     Train net output #1: loss = 0.608339 (* 1 = 0.608339 loss)
I0628 20:40:32.129025  6212 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0628 20:40:35.738389  6212 solver.cpp:218] Iteration 5800 (27.7109 iter/s, 3.60869s/100 iters), loss = 0.60253
I0628 20:40:35.738389  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:40:35.738389  6212 solver.cpp:237]     Train net output #1: loss = 0.60253 (* 1 = 0.60253 loss)
I0628 20:40:35.738389  6212 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0628 20:40:39.364140  6212 solver.cpp:218] Iteration 5900 (27.5838 iter/s, 3.62532s/100 iters), loss = 0.503797
I0628 20:40:39.364140  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:40:39.364140  6212 solver.cpp:237]     Train net output #1: loss = 0.503797 (* 1 = 0.503797 loss)
I0628 20:40:39.364140  6212 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0628 20:40:42.796041 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:40:42.937160  6212 solver.cpp:330] Iteration 6000, Testing net (#0)
I0628 20:40:42.937160  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:40:43.751965  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:40:43.783718  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7529
I0628 20:40:43.783718  6212 solver.cpp:397]     Test net output #1: loss = 0.725073 (* 1 = 0.725073 loss)
I0628 20:40:43.817752  6212 solver.cpp:218] Iteration 6000 (22.4562 iter/s, 4.45311s/100 iters), loss = 0.538413
I0628 20:40:43.817752  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 20:40:43.817752  6212 solver.cpp:237]     Train net output #1: loss = 0.538413 (* 1 = 0.538413 loss)
I0628 20:40:43.817752  6212 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0628 20:40:47.415606  6212 solver.cpp:218] Iteration 6100 (27.7962 iter/s, 3.59761s/100 iters), loss = 0.492715
I0628 20:40:47.415606  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:40:47.415606  6212 solver.cpp:237]     Train net output #1: loss = 0.492715 (* 1 = 0.492715 loss)
I0628 20:40:47.415606  6212 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0628 20:40:51.019769  6212 solver.cpp:218] Iteration 6200 (27.7435 iter/s, 3.60444s/100 iters), loss = 0.45326
I0628 20:40:51.019769  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:40:51.020781  6212 solver.cpp:237]     Train net output #1: loss = 0.45326 (* 1 = 0.45326 loss)
I0628 20:40:51.020781  6212 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0628 20:40:54.634093  6212 solver.cpp:218] Iteration 6300 (27.6778 iter/s, 3.61301s/100 iters), loss = 0.537765
I0628 20:40:54.634093  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:40:54.634093  6212 solver.cpp:237]     Train net output #1: loss = 0.537765 (* 1 = 0.537765 loss)
I0628 20:40:54.634093  6212 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0628 20:40:58.243190  6212 solver.cpp:218] Iteration 6400 (27.7084 iter/s, 3.60902s/100 iters), loss = 0.46549
I0628 20:40:58.243190  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:40:58.243190  6212 solver.cpp:237]     Train net output #1: loss = 0.46549 (* 1 = 0.46549 loss)
I0628 20:40:58.243190  6212 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0628 20:41:01.680295 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:41:01.820910  6212 solver.cpp:330] Iteration 6500, Testing net (#0)
I0628 20:41:01.821912  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:41:02.636529  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:41:02.667553  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7407
I0628 20:41:02.667553  6212 solver.cpp:397]     Test net output #1: loss = 0.763755 (* 1 = 0.763755 loss)
I0628 20:41:02.701580  6212 solver.cpp:218] Iteration 6500 (22.4303 iter/s, 4.45826s/100 iters), loss = 0.507774
I0628 20:41:02.701580  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0628 20:41:02.701580  6212 solver.cpp:237]     Train net output #1: loss = 0.507774 (* 1 = 0.507774 loss)
I0628 20:41:02.701580  6212 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0628 20:41:06.320319  6212 solver.cpp:218] Iteration 6600 (27.6396 iter/s, 3.618s/100 iters), loss = 0.391808
I0628 20:41:06.320319  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:41:06.320319  6212 solver.cpp:237]     Train net output #1: loss = 0.391808 (* 1 = 0.391808 loss)
I0628 20:41:06.320319  6212 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0628 20:41:09.930126  6212 solver.cpp:218] Iteration 6700 (27.7042 iter/s, 3.60956s/100 iters), loss = 0.503199
I0628 20:41:09.930126  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:41:09.930126  6212 solver.cpp:237]     Train net output #1: loss = 0.503199 (* 1 = 0.503199 loss)
I0628 20:41:09.930126  6212 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0628 20:41:13.539455  6212 solver.cpp:218] Iteration 6800 (27.7049 iter/s, 3.60947s/100 iters), loss = 0.567094
I0628 20:41:13.539455  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 20:41:13.539455  6212 solver.cpp:237]     Train net output #1: loss = 0.567094 (* 1 = 0.567094 loss)
I0628 20:41:13.539455  6212 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0628 20:41:17.148648  6212 solver.cpp:218] Iteration 6900 (27.7102 iter/s, 3.60879s/100 iters), loss = 0.457894
I0628 20:41:17.148648  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:41:17.148648  6212 solver.cpp:237]     Train net output #1: loss = 0.457894 (* 1 = 0.457894 loss)
I0628 20:41:17.148648  6212 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0628 20:41:20.582235 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:41:20.724339  6212 solver.cpp:330] Iteration 7000, Testing net (#0)
I0628 20:41:20.724339  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:41:21.542040  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:41:21.573062  6212 solver.cpp:397]     Test net output #0: accuracy = 0.79
I0628 20:41:21.573062  6212 solver.cpp:397]     Test net output #1: loss = 0.626777 (* 1 = 0.626777 loss)
I0628 20:41:21.608090  6212 solver.cpp:218] Iteration 7000 (22.4289 iter/s, 4.45853s/100 iters), loss = 0.509334
I0628 20:41:21.608090  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:41:21.608090  6212 solver.cpp:237]     Train net output #1: loss = 0.509334 (* 1 = 0.509334 loss)
I0628 20:41:21.608090  6212 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0628 20:41:25.225946  6212 solver.cpp:218] Iteration 7100 (27.6399 iter/s, 3.61796s/100 iters), loss = 0.491382
I0628 20:41:25.225946  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:41:25.225946  6212 solver.cpp:237]     Train net output #1: loss = 0.491382 (* 1 = 0.491382 loss)
I0628 20:41:25.225946  6212 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0628 20:41:28.842650  6212 solver.cpp:218] Iteration 7200 (27.6541 iter/s, 3.6161s/100 iters), loss = 0.532243
I0628 20:41:28.842650  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:41:28.842650  6212 solver.cpp:237]     Train net output #1: loss = 0.532243 (* 1 = 0.532243 loss)
I0628 20:41:28.842650  6212 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0628 20:41:32.461381  6212 solver.cpp:218] Iteration 7300 (27.6374 iter/s, 3.61829s/100 iters), loss = 0.473951
I0628 20:41:32.461381  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:41:32.461381  6212 solver.cpp:237]     Train net output #1: loss = 0.473951 (* 1 = 0.473951 loss)
I0628 20:41:32.461381  6212 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0628 20:41:36.071066  6212 solver.cpp:218] Iteration 7400 (27.7002 iter/s, 3.61008s/100 iters), loss = 0.475522
I0628 20:41:36.071066  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:41:36.071066  6212 solver.cpp:237]     Train net output #1: loss = 0.475522 (* 1 = 0.475522 loss)
I0628 20:41:36.071066  6212 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0628 20:41:39.508304 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:41:39.649408  6212 solver.cpp:330] Iteration 7500, Testing net (#0)
I0628 20:41:39.649408  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:41:40.467103  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:41:40.498642  6212 solver.cpp:397]     Test net output #0: accuracy = 0.775
I0628 20:41:40.498642  6212 solver.cpp:397]     Test net output #1: loss = 0.641842 (* 1 = 0.641842 loss)
I0628 20:41:40.533167  6212 solver.cpp:218] Iteration 7500 (22.4173 iter/s, 4.46084s/100 iters), loss = 0.528196
I0628 20:41:40.533167  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 20:41:40.533167  6212 solver.cpp:237]     Train net output #1: loss = 0.528196 (* 1 = 0.528196 loss)
I0628 20:41:40.533167  6212 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0628 20:41:44.147475  6212 solver.cpp:218] Iteration 7600 (27.6695 iter/s, 3.61409s/100 iters), loss = 0.455832
I0628 20:41:44.147475  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:41:44.147475  6212 solver.cpp:237]     Train net output #1: loss = 0.455832 (* 1 = 0.455832 loss)
I0628 20:41:44.147475  6212 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0628 20:41:47.764665  6212 solver.cpp:218] Iteration 7700 (27.6443 iter/s, 3.61738s/100 iters), loss = 0.591168
I0628 20:41:47.764665  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 20:41:47.764665  6212 solver.cpp:237]     Train net output #1: loss = 0.591168 (* 1 = 0.591168 loss)
I0628 20:41:47.764665  6212 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0628 20:41:51.367709  6212 solver.cpp:218] Iteration 7800 (27.7603 iter/s, 3.60226s/100 iters), loss = 0.537307
I0628 20:41:51.367709  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0628 20:41:51.367709  6212 solver.cpp:237]     Train net output #1: loss = 0.537307 (* 1 = 0.537307 loss)
I0628 20:41:51.367709  6212 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0628 20:41:54.972620  6212 solver.cpp:218] Iteration 7900 (27.7396 iter/s, 3.60495s/100 iters), loss = 0.434125
I0628 20:41:54.972620  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:41:54.972620  6212 solver.cpp:237]     Train net output #1: loss = 0.434125 (* 1 = 0.434125 loss)
I0628 20:41:54.972620  6212 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0628 20:41:58.402283 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:41:58.543386  6212 solver.cpp:330] Iteration 8000, Testing net (#0)
I0628 20:41:58.543386  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:41:59.358956  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:41:59.389981  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7457
I0628 20:41:59.389981  6212 solver.cpp:397]     Test net output #1: loss = 0.758554 (* 1 = 0.758554 loss)
I0628 20:41:59.424005  6212 solver.cpp:218] Iteration 8000 (22.4695 iter/s, 4.45047s/100 iters), loss = 0.565934
I0628 20:41:59.424005  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0628 20:41:59.424005  6212 solver.cpp:237]     Train net output #1: loss = 0.565934 (* 1 = 0.565934 loss)
I0628 20:41:59.424005  6212 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0628 20:42:03.030696  6212 solver.cpp:218] Iteration 8100 (27.7278 iter/s, 3.60649s/100 iters), loss = 0.405844
I0628 20:42:03.030696  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:42:03.030696  6212 solver.cpp:237]     Train net output #1: loss = 0.405844 (* 1 = 0.405844 loss)
I0628 20:42:03.030696  6212 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0628 20:42:06.637387  6212 solver.cpp:218] Iteration 8200 (27.7299 iter/s, 3.60622s/100 iters), loss = 0.512788
I0628 20:42:06.637387  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 20:42:06.637387  6212 solver.cpp:237]     Train net output #1: loss = 0.512788 (* 1 = 0.512788 loss)
I0628 20:42:06.637387  6212 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0628 20:42:10.254076  6212 solver.cpp:218] Iteration 8300 (27.6457 iter/s, 3.6172s/100 iters), loss = 0.503442
I0628 20:42:10.255076  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:42:10.255076  6212 solver.cpp:237]     Train net output #1: loss = 0.503442 (* 1 = 0.503442 loss)
I0628 20:42:10.255076  6212 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0628 20:42:13.865746  6212 solver.cpp:218] Iteration 8400 (27.6957 iter/s, 3.61068s/100 iters), loss = 0.384445
I0628 20:42:13.865746  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:42:13.865746  6212 solver.cpp:237]     Train net output #1: loss = 0.384445 (* 1 = 0.384445 loss)
I0628 20:42:13.865746  6212 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0628 20:42:17.308684 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:42:17.453892  6212 solver.cpp:330] Iteration 8500, Testing net (#0)
I0628 20:42:17.453892  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:42:18.274294  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:42:18.306325  6212 solver.cpp:397]     Test net output #0: accuracy = 0.804
I0628 20:42:18.306325  6212 solver.cpp:397]     Test net output #1: loss = 0.574278 (* 1 = 0.574278 loss)
I0628 20:42:18.340360  6212 solver.cpp:218] Iteration 8500 (22.349 iter/s, 4.47447s/100 iters), loss = 0.517301
I0628 20:42:18.340360  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:42:18.340360  6212 solver.cpp:237]     Train net output #1: loss = 0.517301 (* 1 = 0.517301 loss)
I0628 20:42:18.340360  6212 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0628 20:42:21.944412  6212 solver.cpp:218] Iteration 8600 (27.7488 iter/s, 3.60376s/100 iters), loss = 0.430108
I0628 20:42:21.944412  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:42:21.944412  6212 solver.cpp:237]     Train net output #1: loss = 0.430108 (* 1 = 0.430108 loss)
I0628 20:42:21.944412  6212 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0628 20:42:25.553961  6212 solver.cpp:218] Iteration 8700 (27.7055 iter/s, 3.60939s/100 iters), loss = 0.468053
I0628 20:42:25.553961  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:42:25.553961  6212 solver.cpp:237]     Train net output #1: loss = 0.468053 (* 1 = 0.468053 loss)
I0628 20:42:25.553961  6212 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0628 20:42:29.155674  6212 solver.cpp:218] Iteration 8800 (27.7679 iter/s, 3.60128s/100 iters), loss = 0.520081
I0628 20:42:29.155674  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:42:29.155674  6212 solver.cpp:237]     Train net output #1: loss = 0.520081 (* 1 = 0.520081 loss)
I0628 20:42:29.155674  6212 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0628 20:42:32.760439  6212 solver.cpp:218] Iteration 8900 (27.7447 iter/s, 3.6043s/100 iters), loss = 0.457379
I0628 20:42:32.760439  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:42:32.760439  6212 solver.cpp:237]     Train net output #1: loss = 0.457379 (* 1 = 0.457379 loss)
I0628 20:42:32.760439  6212 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0628 20:42:36.195355 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:42:36.336495  6212 solver.cpp:330] Iteration 9000, Testing net (#0)
I0628 20:42:36.336495  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:42:37.150329  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:42:37.181362  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7853
I0628 20:42:37.181362  6212 solver.cpp:397]     Test net output #1: loss = 0.632186 (* 1 = 0.632186 loss)
I0628 20:42:37.216063  6212 solver.cpp:218] Iteration 9000 (22.4474 iter/s, 4.45485s/100 iters), loss = 0.429916
I0628 20:42:37.216063  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:42:37.216063  6212 solver.cpp:237]     Train net output #1: loss = 0.429916 (* 1 = 0.429916 loss)
I0628 20:42:37.216063  6212 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0628 20:42:40.821190  6212 solver.cpp:218] Iteration 9100 (27.7352 iter/s, 3.60552s/100 iters), loss = 0.520903
I0628 20:42:40.821190  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 20:42:40.821190  6212 solver.cpp:237]     Train net output #1: loss = 0.520903 (* 1 = 0.520903 loss)
I0628 20:42:40.821190  6212 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0628 20:42:44.438124  6212 solver.cpp:218] Iteration 9200 (27.6537 iter/s, 3.61615s/100 iters), loss = 0.508932
I0628 20:42:44.438124  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:42:44.438124  6212 solver.cpp:237]     Train net output #1: loss = 0.508932 (* 1 = 0.508932 loss)
I0628 20:42:44.438124  6212 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0628 20:42:48.042438  6212 solver.cpp:218] Iteration 9300 (27.7423 iter/s, 3.6046s/100 iters), loss = 0.554381
I0628 20:42:48.043442  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:42:48.043442  6212 solver.cpp:237]     Train net output #1: loss = 0.554381 (* 1 = 0.554381 loss)
I0628 20:42:48.043442  6212 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0628 20:42:51.658632  6212 solver.cpp:218] Iteration 9400 (27.6604 iter/s, 3.61528s/100 iters), loss = 0.368548
I0628 20:42:51.658632  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:42:51.658632  6212 solver.cpp:237]     Train net output #1: loss = 0.368548 (* 1 = 0.368548 loss)
I0628 20:42:51.658632  6212 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0628 20:42:55.084036 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:42:55.225278  6212 solver.cpp:330] Iteration 9500, Testing net (#0)
I0628 20:42:55.225278  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:42:56.038182  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:42:56.069216  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7852
I0628 20:42:56.069216  6212 solver.cpp:397]     Test net output #1: loss = 0.651077 (* 1 = 0.651077 loss)
I0628 20:42:56.103238  6212 solver.cpp:218] Iteration 9500 (22.499 iter/s, 4.44464s/100 iters), loss = 0.394043
I0628 20:42:56.103238  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:42:56.103238  6212 solver.cpp:237]     Train net output #1: loss = 0.394043 (* 1 = 0.394043 loss)
I0628 20:42:56.103238  6212 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0628 20:42:59.710052  6212 solver.cpp:218] Iteration 9600 (27.7312 iter/s, 3.60605s/100 iters), loss = 0.407608
I0628 20:42:59.710551  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:42:59.710551  6212 solver.cpp:237]     Train net output #1: loss = 0.407608 (* 1 = 0.407608 loss)
I0628 20:42:59.710551  6212 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0628 20:43:03.311883  6212 solver.cpp:218] Iteration 9700 (27.765 iter/s, 3.60166s/100 iters), loss = 0.467362
I0628 20:43:03.311883  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:43:03.311883  6212 solver.cpp:237]     Train net output #1: loss = 0.467362 (* 1 = 0.467362 loss)
I0628 20:43:03.311883  6212 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0628 20:43:06.911504  6212 solver.cpp:218] Iteration 9800 (27.7815 iter/s, 3.59952s/100 iters), loss = 0.519871
I0628 20:43:06.911504  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:43:06.911504  6212 solver.cpp:237]     Train net output #1: loss = 0.519871 (* 1 = 0.519871 loss)
I0628 20:43:06.911504  6212 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0628 20:43:10.513710  6212 solver.cpp:218] Iteration 9900 (27.7665 iter/s, 3.60146s/100 iters), loss = 0.379171
I0628 20:43:10.513710  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:43:10.513710  6212 solver.cpp:237]     Train net output #1: loss = 0.379171 (* 1 = 0.379171 loss)
I0628 20:43:10.513710  6212 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0628 20:43:13.941133 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:43:14.082485  6212 solver.cpp:330] Iteration 10000, Testing net (#0)
I0628 20:43:14.082485  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:43:14.899930  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:43:14.930953  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7823
I0628 20:43:14.930953  6212 solver.cpp:397]     Test net output #1: loss = 0.644064 (* 1 = 0.644064 loss)
I0628 20:43:14.964975  6212 solver.cpp:218] Iteration 10000 (22.4679 iter/s, 4.45079s/100 iters), loss = 0.426072
I0628 20:43:14.964975  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:43:14.964975  6212 solver.cpp:237]     Train net output #1: loss = 0.426072 (* 1 = 0.426072 loss)
I0628 20:43:14.964975  6212 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0628 20:43:18.576066  6212 solver.cpp:218] Iteration 10100 (27.6929 iter/s, 3.61103s/100 iters), loss = 0.443472
I0628 20:43:18.576066  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:43:18.576066  6212 solver.cpp:237]     Train net output #1: loss = 0.443472 (* 1 = 0.443472 loss)
I0628 20:43:18.576066  6212 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0628 20:43:22.177772  6212 solver.cpp:218] Iteration 10200 (27.766 iter/s, 3.60152s/100 iters), loss = 0.486646
I0628 20:43:22.177772  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:43:22.177772  6212 solver.cpp:237]     Train net output #1: loss = 0.486646 (* 1 = 0.486646 loss)
I0628 20:43:22.177772  6212 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0628 20:43:25.782492  6212 solver.cpp:218] Iteration 10300 (27.7448 iter/s, 3.60429s/100 iters), loss = 0.444929
I0628 20:43:25.782492  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:43:25.782492  6212 solver.cpp:237]     Train net output #1: loss = 0.444929 (* 1 = 0.444929 loss)
I0628 20:43:25.782492  6212 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0628 20:43:29.388170  6212 solver.cpp:218] Iteration 10400 (27.7388 iter/s, 3.60506s/100 iters), loss = 0.347963
I0628 20:43:29.388170  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:43:29.388170  6212 solver.cpp:237]     Train net output #1: loss = 0.347963 (* 1 = 0.347963 loss)
I0628 20:43:29.388170  6212 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0628 20:43:32.816223 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:43:32.955832  6212 solver.cpp:330] Iteration 10500, Testing net (#0)
I0628 20:43:32.955832  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:43:33.773453  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:43:33.803474  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8035
I0628 20:43:33.803474  6212 solver.cpp:397]     Test net output #1: loss = 0.592182 (* 1 = 0.592182 loss)
I0628 20:43:33.838501  6212 solver.cpp:218] Iteration 10500 (22.474 iter/s, 4.44959s/100 iters), loss = 0.492649
I0628 20:43:33.838501  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:43:33.838501  6212 solver.cpp:237]     Train net output #1: loss = 0.492649 (* 1 = 0.492649 loss)
I0628 20:43:33.838501  6212 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0628 20:43:37.445257  6212 solver.cpp:218] Iteration 10600 (27.7242 iter/s, 3.60696s/100 iters), loss = 0.381832
I0628 20:43:37.445257  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:43:37.445257  6212 solver.cpp:237]     Train net output #1: loss = 0.381832 (* 1 = 0.381832 loss)
I0628 20:43:37.445257  6212 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0628 20:43:41.046552  6212 solver.cpp:218] Iteration 10700 (27.7692 iter/s, 3.60112s/100 iters), loss = 0.542047
I0628 20:43:41.046552  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:43:41.046552  6212 solver.cpp:237]     Train net output #1: loss = 0.542047 (* 1 = 0.542047 loss)
I0628 20:43:41.046552  6212 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0628 20:43:44.650818  6212 solver.cpp:218] Iteration 10800 (27.7473 iter/s, 3.60395s/100 iters), loss = 0.46038
I0628 20:43:44.650818  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:43:44.650818  6212 solver.cpp:237]     Train net output #1: loss = 0.46038 (* 1 = 0.46038 loss)
I0628 20:43:44.650818  6212 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0628 20:43:48.254274  6212 solver.cpp:218] Iteration 10900 (27.7606 iter/s, 3.60222s/100 iters), loss = 0.397849
I0628 20:43:48.254274  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:43:48.254274  6212 solver.cpp:237]     Train net output #1: loss = 0.397849 (* 1 = 0.397849 loss)
I0628 20:43:48.254274  6212 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0628 20:43:51.679601 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:43:51.820220  6212 solver.cpp:330] Iteration 11000, Testing net (#0)
I0628 20:43:51.820220  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:43:52.636102  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:43:52.669139  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8208
I0628 20:43:52.669139  6212 solver.cpp:397]     Test net output #1: loss = 0.536755 (* 1 = 0.536755 loss)
I0628 20:43:52.703174  6212 solver.cpp:218] Iteration 11000 (22.4781 iter/s, 4.44877s/100 iters), loss = 0.416011
I0628 20:43:52.703174  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:43:52.703174  6212 solver.cpp:237]     Train net output #1: loss = 0.416011 (* 1 = 0.416011 loss)
I0628 20:43:52.703174  6212 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0628 20:43:56.305814  6212 solver.cpp:218] Iteration 11100 (27.7599 iter/s, 3.60232s/100 iters), loss = 0.344713
I0628 20:43:56.305814  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:43:56.305814  6212 solver.cpp:237]     Train net output #1: loss = 0.344713 (* 1 = 0.344713 loss)
I0628 20:43:56.305814  6212 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0628 20:43:59.906632  6212 solver.cpp:218] Iteration 11200 (27.7754 iter/s, 3.60031s/100 iters), loss = 0.511307
I0628 20:43:59.906632  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 20:43:59.906632  6212 solver.cpp:237]     Train net output #1: loss = 0.511307 (* 1 = 0.511307 loss)
I0628 20:43:59.906632  6212 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0628 20:44:03.510766  6212 solver.cpp:218] Iteration 11300 (27.7464 iter/s, 3.60407s/100 iters), loss = 0.374036
I0628 20:44:03.510766  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:44:03.510766  6212 solver.cpp:237]     Train net output #1: loss = 0.374036 (* 1 = 0.374036 loss)
I0628 20:44:03.510766  6212 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0628 20:44:07.102455  6212 solver.cpp:218] Iteration 11400 (27.8419 iter/s, 3.59171s/100 iters), loss = 0.36939
I0628 20:44:07.102455  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:44:07.102455  6212 solver.cpp:237]     Train net output #1: loss = 0.36939 (* 1 = 0.36939 loss)
I0628 20:44:07.102455  6212 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0628 20:44:10.528892 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:44:10.669023  6212 solver.cpp:330] Iteration 11500, Testing net (#0)
I0628 20:44:10.669023  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:44:11.483647  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:44:11.514654  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8072
I0628 20:44:11.514654  6212 solver.cpp:397]     Test net output #1: loss = 0.572036 (* 1 = 0.572036 loss)
I0628 20:44:11.548691  6212 solver.cpp:218] Iteration 11500 (22.4959 iter/s, 4.44526s/100 iters), loss = 0.414037
I0628 20:44:11.548691  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:44:11.548691  6212 solver.cpp:237]     Train net output #1: loss = 0.414037 (* 1 = 0.414037 loss)
I0628 20:44:11.548691  6212 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0628 20:44:15.149906  6212 solver.cpp:218] Iteration 11600 (27.7656 iter/s, 3.60157s/100 iters), loss = 0.423473
I0628 20:44:15.149906  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:44:15.149906  6212 solver.cpp:237]     Train net output #1: loss = 0.423473 (* 1 = 0.423473 loss)
I0628 20:44:15.149906  6212 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0628 20:44:18.747658  6212 solver.cpp:218] Iteration 11700 (27.8016 iter/s, 3.59691s/100 iters), loss = 0.392468
I0628 20:44:18.747658  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:44:18.747658  6212 solver.cpp:237]     Train net output #1: loss = 0.392468 (* 1 = 0.392468 loss)
I0628 20:44:18.747658  6212 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0628 20:44:22.351668  6212 solver.cpp:218] Iteration 11800 (27.7449 iter/s, 3.60427s/100 iters), loss = 0.410422
I0628 20:44:22.351668  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:44:22.351668  6212 solver.cpp:237]     Train net output #1: loss = 0.410422 (* 1 = 0.410422 loss)
I0628 20:44:22.351668  6212 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0628 20:44:25.943189  6212 solver.cpp:218] Iteration 11900 (27.8515 iter/s, 3.59047s/100 iters), loss = 0.400765
I0628 20:44:25.943189  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:44:25.943189  6212 solver.cpp:237]     Train net output #1: loss = 0.400766 (* 1 = 0.400766 loss)
I0628 20:44:25.943189  6212 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0628 20:44:29.372794 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:44:29.513300  6212 solver.cpp:330] Iteration 12000, Testing net (#0)
I0628 20:44:29.513300  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:44:30.329864  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:44:30.360889  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8136
I0628 20:44:30.360889  6212 solver.cpp:397]     Test net output #1: loss = 0.543973 (* 1 = 0.543973 loss)
I0628 20:44:30.395087  6212 solver.cpp:218] Iteration 12000 (22.4632 iter/s, 4.45173s/100 iters), loss = 0.403162
I0628 20:44:30.395087  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:44:30.395087  6212 solver.cpp:237]     Train net output #1: loss = 0.403162 (* 1 = 0.403162 loss)
I0628 20:44:30.395087  6212 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0628 20:44:34.002640  6212 solver.cpp:218] Iteration 12100 (27.725 iter/s, 3.60685s/100 iters), loss = 0.429189
I0628 20:44:34.002640  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:44:34.002640  6212 solver.cpp:237]     Train net output #1: loss = 0.429189 (* 1 = 0.429189 loss)
I0628 20:44:34.002640  6212 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0628 20:44:37.606009  6212 solver.cpp:218] Iteration 12200 (27.7514 iter/s, 3.60342s/100 iters), loss = 0.411615
I0628 20:44:37.606009  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:44:37.606009  6212 solver.cpp:237]     Train net output #1: loss = 0.411615 (* 1 = 0.411615 loss)
I0628 20:44:37.606009  6212 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0628 20:44:41.212929  6212 solver.cpp:218] Iteration 12300 (27.7252 iter/s, 3.60683s/100 iters), loss = 0.391566
I0628 20:44:41.212929  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:44:41.212929  6212 solver.cpp:237]     Train net output #1: loss = 0.391566 (* 1 = 0.391566 loss)
I0628 20:44:41.212929  6212 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0628 20:44:44.819952  6212 solver.cpp:218] Iteration 12400 (27.7281 iter/s, 3.60645s/100 iters), loss = 0.42912
I0628 20:44:44.819952  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:44:44.819952  6212 solver.cpp:237]     Train net output #1: loss = 0.42912 (* 1 = 0.42912 loss)
I0628 20:44:44.819952  6212 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0628 20:44:48.244664 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:44:48.387787  6212 solver.cpp:330] Iteration 12500, Testing net (#0)
I0628 20:44:48.387787  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:44:49.200445  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:44:49.230690  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7961
I0628 20:44:49.230690  6212 solver.cpp:397]     Test net output #1: loss = 0.624417 (* 1 = 0.624417 loss)
I0628 20:44:49.265717  6212 solver.cpp:218] Iteration 12500 (22.4964 iter/s, 4.44516s/100 iters), loss = 0.356368
I0628 20:44:49.265717  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:44:49.265717  6212 solver.cpp:237]     Train net output #1: loss = 0.356368 (* 1 = 0.356368 loss)
I0628 20:44:49.265717  6212 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0628 20:44:52.861812  6212 solver.cpp:218] Iteration 12600 (27.8092 iter/s, 3.59593s/100 iters), loss = 0.333064
I0628 20:44:52.861812  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:44:52.861812  6212 solver.cpp:237]     Train net output #1: loss = 0.333064 (* 1 = 0.333064 loss)
I0628 20:44:52.861812  6212 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0628 20:44:56.464284  6212 solver.cpp:218] Iteration 12700 (27.7577 iter/s, 3.60261s/100 iters), loss = 0.370685
I0628 20:44:56.464284  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:44:56.464284  6212 solver.cpp:237]     Train net output #1: loss = 0.370685 (* 1 = 0.370685 loss)
I0628 20:44:56.464284  6212 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0628 20:45:00.062491  6212 solver.cpp:218] Iteration 12800 (27.7941 iter/s, 3.59788s/100 iters), loss = 0.465932
I0628 20:45:00.062491  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:45:00.062491  6212 solver.cpp:237]     Train net output #1: loss = 0.465932 (* 1 = 0.465932 loss)
I0628 20:45:00.062491  6212 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0628 20:45:03.676939  6212 solver.cpp:218] Iteration 12900 (27.67 iter/s, 3.61402s/100 iters), loss = 0.43009
I0628 20:45:03.676939  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:45:03.676939  6212 solver.cpp:237]     Train net output #1: loss = 0.43009 (* 1 = 0.43009 loss)
I0628 20:45:03.676939  6212 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0628 20:45:07.104496 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:45:07.245101  6212 solver.cpp:330] Iteration 13000, Testing net (#0)
I0628 20:45:07.245101  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:45:08.063959  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:45:08.093981  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7864
I0628 20:45:08.093981  6212 solver.cpp:397]     Test net output #1: loss = 0.654744 (* 1 = 0.654744 loss)
I0628 20:45:08.128005  6212 solver.cpp:218] Iteration 13000 (22.467 iter/s, 4.45096s/100 iters), loss = 0.373781
I0628 20:45:08.129005  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:45:08.129005  6212 solver.cpp:237]     Train net output #1: loss = 0.373781 (* 1 = 0.373781 loss)
I0628 20:45:08.129005  6212 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0628 20:45:11.732499  6212 solver.cpp:218] Iteration 13100 (27.7476 iter/s, 3.60392s/100 iters), loss = 0.323926
I0628 20:45:11.732499  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:45:11.732499  6212 solver.cpp:237]     Train net output #1: loss = 0.323926 (* 1 = 0.323926 loss)
I0628 20:45:11.732499  6212 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0628 20:45:15.337239  6212 solver.cpp:218] Iteration 13200 (27.7421 iter/s, 3.60463s/100 iters), loss = 0.405805
I0628 20:45:15.337239  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:45:15.337239  6212 solver.cpp:237]     Train net output #1: loss = 0.405805 (* 1 = 0.405805 loss)
I0628 20:45:15.337239  6212 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0628 20:45:18.942924  6212 solver.cpp:218] Iteration 13300 (27.7383 iter/s, 3.60512s/100 iters), loss = 0.379242
I0628 20:45:18.942924  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:45:18.942924  6212 solver.cpp:237]     Train net output #1: loss = 0.379242 (* 1 = 0.379242 loss)
I0628 20:45:18.942924  6212 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0628 20:45:22.549450  6212 solver.cpp:218] Iteration 13400 (27.7353 iter/s, 3.60551s/100 iters), loss = 0.382123
I0628 20:45:22.549450  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:45:22.549450  6212 solver.cpp:237]     Train net output #1: loss = 0.382123 (* 1 = 0.382123 loss)
I0628 20:45:22.549450  6212 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0628 20:45:25.992182 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:45:26.134285  6212 solver.cpp:330] Iteration 13500, Testing net (#0)
I0628 20:45:26.134285  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:45:26.952898  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:45:26.983654  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8068
I0628 20:45:26.983654  6212 solver.cpp:397]     Test net output #1: loss = 0.575376 (* 1 = 0.575376 loss)
I0628 20:45:27.017669  6212 solver.cpp:218] Iteration 13500 (22.3791 iter/s, 4.46846s/100 iters), loss = 0.311236
I0628 20:45:27.017669  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:45:27.017669  6212 solver.cpp:237]     Train net output #1: loss = 0.311236 (* 1 = 0.311236 loss)
I0628 20:45:27.017669  6212 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0628 20:45:30.626871  6212 solver.cpp:218] Iteration 13600 (27.7123 iter/s, 3.6085s/100 iters), loss = 0.393888
I0628 20:45:30.626871  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:45:30.626871  6212 solver.cpp:237]     Train net output #1: loss = 0.393888 (* 1 = 0.393888 loss)
I0628 20:45:30.626871  6212 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0628 20:45:34.243505  6212 solver.cpp:218] Iteration 13700 (27.652 iter/s, 3.61637s/100 iters), loss = 0.551663
I0628 20:45:34.243505  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:45:34.243505  6212 solver.cpp:237]     Train net output #1: loss = 0.551663 (* 1 = 0.551663 loss)
I0628 20:45:34.243505  6212 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0628 20:45:37.847203  6212 solver.cpp:218] Iteration 13800 (27.7537 iter/s, 3.60312s/100 iters), loss = 0.329772
I0628 20:45:37.847203  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:45:37.847203  6212 solver.cpp:237]     Train net output #1: loss = 0.329772 (* 1 = 0.329772 loss)
I0628 20:45:37.847203  6212 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0628 20:45:41.452893  6212 solver.cpp:218] Iteration 13900 (27.7316 iter/s, 3.606s/100 iters), loss = 0.336403
I0628 20:45:41.452893  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:45:41.452893  6212 solver.cpp:237]     Train net output #1: loss = 0.336403 (* 1 = 0.336403 loss)
I0628 20:45:41.452893  6212 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0628 20:45:44.889670 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:45:45.030776  6212 solver.cpp:330] Iteration 14000, Testing net (#0)
I0628 20:45:45.030776  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:45:45.845383  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:45:45.875404  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8104
I0628 20:45:45.875404  6212 solver.cpp:397]     Test net output #1: loss = 0.569756 (* 1 = 0.569756 loss)
I0628 20:45:45.909432  6212 solver.cpp:218] Iteration 14000 (22.4399 iter/s, 4.45636s/100 iters), loss = 0.356851
I0628 20:45:45.909432  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:45:45.909432  6212 solver.cpp:237]     Train net output #1: loss = 0.356851 (* 1 = 0.356851 loss)
I0628 20:45:45.909432  6212 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0628 20:45:49.516353  6212 solver.cpp:218] Iteration 14100 (27.7266 iter/s, 3.60664s/100 iters), loss = 0.341648
I0628 20:45:49.517354  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:45:49.517354  6212 solver.cpp:237]     Train net output #1: loss = 0.341648 (* 1 = 0.341648 loss)
I0628 20:45:49.517354  6212 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0628 20:45:53.122071  6212 solver.cpp:218] Iteration 14200 (27.7405 iter/s, 3.60483s/100 iters), loss = 0.402518
I0628 20:45:53.122071  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:45:53.122071  6212 solver.cpp:237]     Train net output #1: loss = 0.402518 (* 1 = 0.402518 loss)
I0628 20:45:53.122071  6212 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0628 20:45:56.727800  6212 solver.cpp:218] Iteration 14300 (27.7391 iter/s, 3.60502s/100 iters), loss = 0.483964
I0628 20:45:56.727800  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 20:45:56.727800  6212 solver.cpp:237]     Train net output #1: loss = 0.483964 (* 1 = 0.483964 loss)
I0628 20:45:56.727800  6212 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0628 20:46:00.349457  6212 solver.cpp:218] Iteration 14400 (27.6099 iter/s, 3.62188s/100 iters), loss = 0.30257
I0628 20:46:00.349457  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:46:00.349457  6212 solver.cpp:237]     Train net output #1: loss = 0.30257 (* 1 = 0.30257 loss)
I0628 20:46:00.349457  6212 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0628 20:46:03.780524 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:46:03.921629  6212 solver.cpp:330] Iteration 14500, Testing net (#0)
I0628 20:46:03.921629  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:46:04.751260  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:46:04.783283  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8064
I0628 20:46:04.783283  6212 solver.cpp:397]     Test net output #1: loss = 0.575586 (* 1 = 0.575586 loss)
I0628 20:46:04.817307  6212 solver.cpp:218] Iteration 14500 (22.3864 iter/s, 4.467s/100 iters), loss = 0.288345
I0628 20:46:04.817307  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:46:04.817307  6212 solver.cpp:237]     Train net output #1: loss = 0.288345 (* 1 = 0.288345 loss)
I0628 20:46:04.817307  6212 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0628 20:46:08.429250  6212 solver.cpp:218] Iteration 14600 (27.6868 iter/s, 3.61183s/100 iters), loss = 0.373055
I0628 20:46:08.429250  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:46:08.429250  6212 solver.cpp:237]     Train net output #1: loss = 0.373055 (* 1 = 0.373055 loss)
I0628 20:46:08.429250  6212 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0628 20:46:12.036964  6212 solver.cpp:218] Iteration 14700 (27.721 iter/s, 3.60737s/100 iters), loss = 0.336356
I0628 20:46:12.036964  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:46:12.036964  6212 solver.cpp:237]     Train net output #1: loss = 0.336356 (* 1 = 0.336356 loss)
I0628 20:46:12.036964  6212 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0628 20:46:15.643646  6212 solver.cpp:218] Iteration 14800 (27.729 iter/s, 3.60633s/100 iters), loss = 0.451178
I0628 20:46:15.643646  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:46:15.643646  6212 solver.cpp:237]     Train net output #1: loss = 0.451178 (* 1 = 0.451178 loss)
I0628 20:46:15.643646  6212 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0628 20:46:19.254341  6212 solver.cpp:218] Iteration 14900 (27.6942 iter/s, 3.61086s/100 iters), loss = 0.323854
I0628 20:46:19.254341  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:46:19.254341  6212 solver.cpp:237]     Train net output #1: loss = 0.323854 (* 1 = 0.323854 loss)
I0628 20:46:19.254341  6212 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0628 20:46:22.686920 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:46:22.829032  6212 solver.cpp:330] Iteration 15000, Testing net (#0)
I0628 20:46:22.829032  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:46:23.644955  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:46:23.675977  6212 solver.cpp:397]     Test net output #0: accuracy = 0.813
I0628 20:46:23.675977  6212 solver.cpp:397]     Test net output #1: loss = 0.548634 (* 1 = 0.548634 loss)
I0628 20:46:23.710003  6212 solver.cpp:218] Iteration 15000 (22.4483 iter/s, 4.45469s/100 iters), loss = 0.352028
I0628 20:46:23.710003  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:46:23.710003  6212 solver.cpp:237]     Train net output #1: loss = 0.352028 (* 1 = 0.352028 loss)
I0628 20:46:23.710003  6212 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0628 20:46:27.313674  6212 solver.cpp:218] Iteration 15100 (27.7457 iter/s, 3.60416s/100 iters), loss = 0.332298
I0628 20:46:27.314676  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:46:27.314676  6212 solver.cpp:237]     Train net output #1: loss = 0.332298 (* 1 = 0.332298 loss)
I0628 20:46:27.314676  6212 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0628 20:46:30.913372  6212 solver.cpp:218] Iteration 15200 (27.7887 iter/s, 3.59858s/100 iters), loss = 0.403229
I0628 20:46:30.913372  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:46:30.913372  6212 solver.cpp:237]     Train net output #1: loss = 0.403229 (* 1 = 0.403229 loss)
I0628 20:46:30.913372  6212 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0628 20:46:34.538067  6212 solver.cpp:218] Iteration 15300 (27.5859 iter/s, 3.62504s/100 iters), loss = 0.521772
I0628 20:46:34.538067  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:46:34.538067  6212 solver.cpp:237]     Train net output #1: loss = 0.521772 (* 1 = 0.521772 loss)
I0628 20:46:34.538067  6212 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0628 20:46:38.141332  6212 solver.cpp:218] Iteration 15400 (27.7598 iter/s, 3.60233s/100 iters), loss = 0.271793
I0628 20:46:38.141332  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:46:38.141332  6212 solver.cpp:237]     Train net output #1: loss = 0.271793 (* 1 = 0.271793 loss)
I0628 20:46:38.141332  6212 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0628 20:46:41.576946 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:46:41.718053  6212 solver.cpp:330] Iteration 15500, Testing net (#0)
I0628 20:46:41.718053  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:46:42.531476  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:46:42.562497  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8234
I0628 20:46:42.562497  6212 solver.cpp:397]     Test net output #1: loss = 0.526103 (* 1 = 0.526103 loss)
I0628 20:46:42.596524  6212 solver.cpp:218] Iteration 15500 (22.4488 iter/s, 4.45458s/100 iters), loss = 0.416871
I0628 20:46:42.596524  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:46:42.596524  6212 solver.cpp:237]     Train net output #1: loss = 0.416871 (* 1 = 0.416871 loss)
I0628 20:46:42.596524  6212 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0628 20:46:46.200750  6212 solver.cpp:218] Iteration 15600 (27.7484 iter/s, 3.60381s/100 iters), loss = 0.39395
I0628 20:46:46.200750  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:46:46.200750  6212 solver.cpp:237]     Train net output #1: loss = 0.39395 (* 1 = 0.39395 loss)
I0628 20:46:46.200750  6212 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0628 20:46:49.805826  6212 solver.cpp:218] Iteration 15700 (27.7372 iter/s, 3.60527s/100 iters), loss = 0.384487
I0628 20:46:49.805826  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:46:49.805826  6212 solver.cpp:237]     Train net output #1: loss = 0.384487 (* 1 = 0.384487 loss)
I0628 20:46:49.805826  6212 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0628 20:46:53.408541  6212 solver.cpp:218] Iteration 15800 (27.7558 iter/s, 3.60285s/100 iters), loss = 0.45504
I0628 20:46:53.409543  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:46:53.409543  6212 solver.cpp:237]     Train net output #1: loss = 0.45504 (* 1 = 0.45504 loss)
I0628 20:46:53.409543  6212 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0628 20:46:57.009423  6212 solver.cpp:218] Iteration 15900 (27.7755 iter/s, 3.6003s/100 iters), loss = 0.318477
I0628 20:46:57.009423  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:46:57.009423  6212 solver.cpp:237]     Train net output #1: loss = 0.318477 (* 1 = 0.318477 loss)
I0628 20:46:57.009423  6212 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0628 20:47:00.435853 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:47:00.577957  6212 solver.cpp:330] Iteration 16000, Testing net (#0)
I0628 20:47:00.577957  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:47:01.395478  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:47:01.426503  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7978
I0628 20:47:01.426503  6212 solver.cpp:397]     Test net output #1: loss = 0.623831 (* 1 = 0.623831 loss)
I0628 20:47:01.460527  6212 solver.cpp:218] Iteration 16000 (22.4676 iter/s, 4.45085s/100 iters), loss = 0.356069
I0628 20:47:01.460527  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:47:01.460527  6212 solver.cpp:237]     Train net output #1: loss = 0.356069 (* 1 = 0.356069 loss)
I0628 20:47:01.460527  6212 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0628 20:47:05.073257  6212 solver.cpp:218] Iteration 16100 (27.6828 iter/s, 3.61236s/100 iters), loss = 0.265093
I0628 20:47:05.073257  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:47:05.073257  6212 solver.cpp:237]     Train net output #1: loss = 0.265093 (* 1 = 0.265093 loss)
I0628 20:47:05.073257  6212 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0628 20:47:08.681845  6212 solver.cpp:218] Iteration 16200 (27.7143 iter/s, 3.60825s/100 iters), loss = 0.31219
I0628 20:47:08.681845  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:47:08.681845  6212 solver.cpp:237]     Train net output #1: loss = 0.31219 (* 1 = 0.31219 loss)
I0628 20:47:08.681845  6212 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0628 20:47:12.296540  6212 solver.cpp:218] Iteration 16300 (27.6682 iter/s, 3.61425s/100 iters), loss = 0.392278
I0628 20:47:12.296540  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:47:12.296540  6212 solver.cpp:237]     Train net output #1: loss = 0.392278 (* 1 = 0.392278 loss)
I0628 20:47:12.296540  6212 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0628 20:47:15.911236  6212 solver.cpp:218] Iteration 16400 (27.6724 iter/s, 3.61371s/100 iters), loss = 0.229568
I0628 20:47:15.911236  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:47:15.911236  6212 solver.cpp:237]     Train net output #1: loss = 0.229568 (* 1 = 0.229568 loss)
I0628 20:47:15.911736  6212 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0628 20:47:19.346704 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:47:19.488808  6212 solver.cpp:330] Iteration 16500, Testing net (#0)
I0628 20:47:19.488808  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:47:20.305441  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:47:20.336468  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8055
I0628 20:47:20.336468  6212 solver.cpp:397]     Test net output #1: loss = 0.589648 (* 1 = 0.589648 loss)
I0628 20:47:20.370492  6212 solver.cpp:218] Iteration 16500 (22.4281 iter/s, 4.45868s/100 iters), loss = 0.373596
I0628 20:47:20.370492  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:47:20.370492  6212 solver.cpp:237]     Train net output #1: loss = 0.373596 (* 1 = 0.373596 loss)
I0628 20:47:20.370492  6212 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0628 20:47:23.976302  6212 solver.cpp:218] Iteration 16600 (27.7322 iter/s, 3.60592s/100 iters), loss = 0.386509
I0628 20:47:23.976302  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:47:23.976302  6212 solver.cpp:237]     Train net output #1: loss = 0.386509 (* 1 = 0.386509 loss)
I0628 20:47:23.976302  6212 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0628 20:47:27.590989  6212 solver.cpp:218] Iteration 16700 (27.67 iter/s, 3.61402s/100 iters), loss = 0.306802
I0628 20:47:27.590989  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:47:27.590989  6212 solver.cpp:237]     Train net output #1: loss = 0.306802 (* 1 = 0.306802 loss)
I0628 20:47:27.590989  6212 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0628 20:47:31.194700  6212 solver.cpp:218] Iteration 16800 (27.7545 iter/s, 3.60302s/100 iters), loss = 0.412595
I0628 20:47:31.194700  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:47:31.194700  6212 solver.cpp:237]     Train net output #1: loss = 0.412595 (* 1 = 0.412595 loss)
I0628 20:47:31.194700  6212 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0628 20:47:34.799407  6212 solver.cpp:218] Iteration 16900 (27.7443 iter/s, 3.60435s/100 iters), loss = 0.326571
I0628 20:47:34.799407  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:47:34.799407  6212 solver.cpp:237]     Train net output #1: loss = 0.326571 (* 1 = 0.326571 loss)
I0628 20:47:34.799407  6212 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0628 20:47:38.235445 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:47:38.376049  6212 solver.cpp:330] Iteration 17000, Testing net (#0)
I0628 20:47:38.376049  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:47:39.191656  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:47:39.222679  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8248
I0628 20:47:39.222679  6212 solver.cpp:397]     Test net output #1: loss = 0.528005 (* 1 = 0.528005 loss)
I0628 20:47:39.256705  6212 solver.cpp:218] Iteration 17000 (22.4354 iter/s, 4.45723s/100 iters), loss = 0.34722
I0628 20:47:39.256705  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:47:39.256705  6212 solver.cpp:237]     Train net output #1: loss = 0.34722 (* 1 = 0.34722 loss)
I0628 20:47:39.256705  6212 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0628 20:47:42.872553  6212 solver.cpp:218] Iteration 17100 (27.6548 iter/s, 3.616s/100 iters), loss = 0.226797
I0628 20:47:42.872553  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:47:42.872553  6212 solver.cpp:237]     Train net output #1: loss = 0.226797 (* 1 = 0.226797 loss)
I0628 20:47:42.872553  6212 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0628 20:47:46.479076  6212 solver.cpp:218] Iteration 17200 (27.7354 iter/s, 3.6055s/100 iters), loss = 0.355414
I0628 20:47:46.479076  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:47:46.479076  6212 solver.cpp:237]     Train net output #1: loss = 0.355414 (* 1 = 0.355414 loss)
I0628 20:47:46.479076  6212 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0628 20:47:50.083868  6212 solver.cpp:218] Iteration 17300 (27.7368 iter/s, 3.60531s/100 iters), loss = 0.389954
I0628 20:47:50.084869  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:47:50.084869  6212 solver.cpp:237]     Train net output #1: loss = 0.389954 (* 1 = 0.389954 loss)
I0628 20:47:50.084869  6212 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0628 20:47:53.686599  6212 solver.cpp:218] Iteration 17400 (27.7649 iter/s, 3.60167s/100 iters), loss = 0.284293
I0628 20:47:53.686599  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:47:53.686599  6212 solver.cpp:237]     Train net output #1: loss = 0.284293 (* 1 = 0.284293 loss)
I0628 20:47:53.686599  6212 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0628 20:47:57.119542 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:47:57.260648  6212 solver.cpp:330] Iteration 17500, Testing net (#0)
I0628 20:47:57.260648  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:47:58.074400  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:47:58.105422  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7856
I0628 20:47:58.105422  6212 solver.cpp:397]     Test net output #1: loss = 0.660518 (* 1 = 0.660518 loss)
I0628 20:47:58.140449  6212 solver.cpp:218] Iteration 17500 (22.4548 iter/s, 4.45339s/100 iters), loss = 0.380015
I0628 20:47:58.140449  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:47:58.140449  6212 solver.cpp:237]     Train net output #1: loss = 0.380015 (* 1 = 0.380015 loss)
I0628 20:47:58.140449  6212 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0628 20:48:01.751629  6212 solver.cpp:218] Iteration 17600 (27.693 iter/s, 3.61102s/100 iters), loss = 0.386584
I0628 20:48:01.751629  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:48:01.751629  6212 solver.cpp:237]     Train net output #1: loss = 0.386584 (* 1 = 0.386584 loss)
I0628 20:48:01.751629  6212 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0628 20:48:05.367102  6212 solver.cpp:218] Iteration 17700 (27.6577 iter/s, 3.61563s/100 iters), loss = 0.332103
I0628 20:48:05.367102  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:48:05.367102  6212 solver.cpp:237]     Train net output #1: loss = 0.332102 (* 1 = 0.332102 loss)
I0628 20:48:05.367102  6212 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0628 20:48:08.985085  6212 solver.cpp:218] Iteration 17800 (27.6412 iter/s, 3.61779s/100 iters), loss = 0.366263
I0628 20:48:08.985085  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:48:08.985085  6212 solver.cpp:237]     Train net output #1: loss = 0.366263 (* 1 = 0.366263 loss)
I0628 20:48:08.985085  6212 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0628 20:48:12.589658  6212 solver.cpp:218] Iteration 17900 (27.7501 iter/s, 3.60359s/100 iters), loss = 0.263152
I0628 20:48:12.589658  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:48:12.589658  6212 solver.cpp:237]     Train net output #1: loss = 0.263152 (* 1 = 0.263152 loss)
I0628 20:48:12.589658  6212 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0628 20:48:16.019773 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:48:16.160984  6212 solver.cpp:330] Iteration 18000, Testing net (#0)
I0628 20:48:16.160984  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:48:16.981549  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:48:17.012588  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8125
I0628 20:48:17.012588  6212 solver.cpp:397]     Test net output #1: loss = 0.555117 (* 1 = 0.555117 loss)
I0628 20:48:17.046638  6212 solver.cpp:218] Iteration 18000 (22.4378 iter/s, 4.45677s/100 iters), loss = 0.375158
I0628 20:48:17.046638  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:48:17.046638  6212 solver.cpp:237]     Train net output #1: loss = 0.375158 (* 1 = 0.375158 loss)
I0628 20:48:17.046638  6212 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0628 20:48:20.663430  6212 solver.cpp:218] Iteration 18100 (27.6535 iter/s, 3.61618s/100 iters), loss = 0.382418
I0628 20:48:20.663430  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:48:20.663430  6212 solver.cpp:237]     Train net output #1: loss = 0.382418 (* 1 = 0.382418 loss)
I0628 20:48:20.663430  6212 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0628 20:48:24.289155  6212 solver.cpp:218] Iteration 18200 (27.5781 iter/s, 3.62606s/100 iters), loss = 0.307103
I0628 20:48:24.289155  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:48:24.289155  6212 solver.cpp:237]     Train net output #1: loss = 0.307103 (* 1 = 0.307103 loss)
I0628 20:48:24.289155  6212 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0628 20:48:27.897833  6212 solver.cpp:218] Iteration 18300 (27.7154 iter/s, 3.60811s/100 iters), loss = 0.401364
I0628 20:48:27.897833  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:48:27.897833  6212 solver.cpp:237]     Train net output #1: loss = 0.401364 (* 1 = 0.401364 loss)
I0628 20:48:27.897833  6212 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0628 20:48:31.507602  6212 solver.cpp:218] Iteration 18400 (27.7083 iter/s, 3.60903s/100 iters), loss = 0.276525
I0628 20:48:31.507602  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:48:31.507602  6212 solver.cpp:237]     Train net output #1: loss = 0.276525 (* 1 = 0.276525 loss)
I0628 20:48:31.507602  6212 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0628 20:48:34.938213 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:48:35.078317  6212 solver.cpp:330] Iteration 18500, Testing net (#0)
I0628 20:48:35.078317  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:48:35.894955  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:48:35.925478  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8091
I0628 20:48:35.925978  6212 solver.cpp:397]     Test net output #1: loss = 0.586149 (* 1 = 0.586149 loss)
I0628 20:48:35.960005  6212 solver.cpp:218] Iteration 18500 (22.4627 iter/s, 4.45182s/100 iters), loss = 0.321176
I0628 20:48:35.960005  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:48:35.960005  6212 solver.cpp:237]     Train net output #1: loss = 0.321176 (* 1 = 0.321176 loss)
I0628 20:48:35.960005  6212 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0628 20:48:39.569702  6212 solver.cpp:218] Iteration 18600 (27.7051 iter/s, 3.60944s/100 iters), loss = 0.350565
I0628 20:48:39.569702  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:48:39.569702  6212 solver.cpp:237]     Train net output #1: loss = 0.350565 (* 1 = 0.350565 loss)
I0628 20:48:39.569702  6212 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0628 20:48:43.180390  6212 solver.cpp:218] Iteration 18700 (27.6963 iter/s, 3.61059s/100 iters), loss = 0.436816
I0628 20:48:43.180390  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 20:48:43.180390  6212 solver.cpp:237]     Train net output #1: loss = 0.436816 (* 1 = 0.436816 loss)
I0628 20:48:43.180390  6212 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0628 20:48:46.792920  6212 solver.cpp:218] Iteration 18800 (27.6832 iter/s, 3.6123s/100 iters), loss = 0.43608
I0628 20:48:46.792920  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:48:46.792920  6212 solver.cpp:237]     Train net output #1: loss = 0.43608 (* 1 = 0.43608 loss)
I0628 20:48:46.792920  6212 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0628 20:48:50.399600  6212 solver.cpp:218] Iteration 18900 (27.7305 iter/s, 3.60613s/100 iters), loss = 0.261701
I0628 20:48:50.399600  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:48:50.399600  6212 solver.cpp:237]     Train net output #1: loss = 0.261701 (* 1 = 0.261701 loss)
I0628 20:48:50.399600  6212 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0628 20:48:53.829115 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:48:53.969225  6212 solver.cpp:330] Iteration 19000, Testing net (#0)
I0628 20:48:53.969225  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:48:54.782953  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:48:54.813977  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8056
I0628 20:48:54.813977  6212 solver.cpp:397]     Test net output #1: loss = 0.575783 (* 1 = 0.575783 loss)
I0628 20:48:54.848501  6212 solver.cpp:218] Iteration 19000 (22.4785 iter/s, 4.4487s/100 iters), loss = 0.361736
I0628 20:48:54.848501  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:48:54.848501  6212 solver.cpp:237]     Train net output #1: loss = 0.361736 (* 1 = 0.361736 loss)
I0628 20:48:54.848501  6212 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0628 20:48:58.451125  6212 solver.cpp:218] Iteration 19100 (27.7614 iter/s, 3.60213s/100 iters), loss = 0.293542
I0628 20:48:58.451125  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:48:58.451125  6212 solver.cpp:237]     Train net output #1: loss = 0.293541 (* 1 = 0.293541 loss)
I0628 20:48:58.451125  6212 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0628 20:49:02.064504  6212 solver.cpp:218] Iteration 19200 (27.6792 iter/s, 3.61282s/100 iters), loss = 0.354144
I0628 20:49:02.064504  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:49:02.064504  6212 solver.cpp:237]     Train net output #1: loss = 0.354144 (* 1 = 0.354144 loss)
I0628 20:49:02.064504  6212 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0628 20:49:05.669324  6212 solver.cpp:218] Iteration 19300 (27.7435 iter/s, 3.60445s/100 iters), loss = 0.398899
I0628 20:49:05.669324  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:49:05.669324  6212 solver.cpp:237]     Train net output #1: loss = 0.398899 (* 1 = 0.398899 loss)
I0628 20:49:05.669324  6212 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0628 20:49:09.276902  6212 solver.cpp:218] Iteration 19400 (27.7162 iter/s, 3.608s/100 iters), loss = 0.429851
I0628 20:49:09.276902  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:49:09.276902  6212 solver.cpp:237]     Train net output #1: loss = 0.429851 (* 1 = 0.429851 loss)
I0628 20:49:09.276902  6212 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0628 20:49:12.706472 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:49:12.848577  6212 solver.cpp:330] Iteration 19500, Testing net (#0)
I0628 20:49:12.848577  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:49:13.665555  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:49:13.696578  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8197
I0628 20:49:13.696578  6212 solver.cpp:397]     Test net output #1: loss = 0.543555 (* 1 = 0.543555 loss)
I0628 20:49:13.730602  6212 solver.cpp:218] Iteration 19500 (22.4567 iter/s, 4.45301s/100 iters), loss = 0.335723
I0628 20:49:13.730602  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:49:13.730602  6212 solver.cpp:237]     Train net output #1: loss = 0.335723 (* 1 = 0.335723 loss)
I0628 20:49:13.730602  6212 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0628 20:49:17.327278  6212 solver.cpp:218] Iteration 19600 (27.8081 iter/s, 3.59608s/100 iters), loss = 0.325729
I0628 20:49:17.327278  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:49:17.327278  6212 solver.cpp:237]     Train net output #1: loss = 0.325729 (* 1 = 0.325729 loss)
I0628 20:49:17.327278  6212 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0628 20:49:20.934973  6212 solver.cpp:218] Iteration 19700 (27.7209 iter/s, 3.60739s/100 iters), loss = 0.368948
I0628 20:49:20.934973  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:49:20.934973  6212 solver.cpp:237]     Train net output #1: loss = 0.368948 (* 1 = 0.368948 loss)
I0628 20:49:20.934973  6212 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0628 20:49:24.542925  6212 solver.cpp:218] Iteration 19800 (27.7151 iter/s, 3.60814s/100 iters), loss = 0.269701
I0628 20:49:24.542925  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:49:24.542925  6212 solver.cpp:237]     Train net output #1: loss = 0.269701 (* 1 = 0.269701 loss)
I0628 20:49:24.542925  6212 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0628 20:49:28.142768  6212 solver.cpp:218] Iteration 19900 (27.7863 iter/s, 3.59889s/100 iters), loss = 0.263786
I0628 20:49:28.142768  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:49:28.142768  6212 solver.cpp:237]     Train net output #1: loss = 0.263786 (* 1 = 0.263786 loss)
I0628 20:49:28.142768  6212 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0628 20:49:31.566716 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:49:31.707641  6212 solver.cpp:330] Iteration 20000, Testing net (#0)
I0628 20:49:31.707641  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:49:32.528107  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:49:32.559140  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8202
I0628 20:49:32.559140  6212 solver.cpp:397]     Test net output #1: loss = 0.530726 (* 1 = 0.530726 loss)
I0628 20:49:32.593184  6212 solver.cpp:218] Iteration 20000 (22.4718 iter/s, 4.45001s/100 iters), loss = 0.294076
I0628 20:49:32.593184  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:49:32.593184  6212 solver.cpp:237]     Train net output #1: loss = 0.294076 (* 1 = 0.294076 loss)
I0628 20:49:32.593184  6212 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0628 20:49:36.214783  6212 solver.cpp:218] Iteration 20100 (27.613 iter/s, 3.62148s/100 iters), loss = 0.308558
I0628 20:49:36.214783  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:49:36.214783  6212 solver.cpp:237]     Train net output #1: loss = 0.308558 (* 1 = 0.308558 loss)
I0628 20:49:36.214783  6212 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0628 20:49:39.819875  6212 solver.cpp:218] Iteration 20200 (27.7416 iter/s, 3.60469s/100 iters), loss = 0.32822
I0628 20:49:39.819875  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:49:39.819875  6212 solver.cpp:237]     Train net output #1: loss = 0.32822 (* 1 = 0.32822 loss)
I0628 20:49:39.819875  6212 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0628 20:49:43.432099  6212 solver.cpp:218] Iteration 20300 (27.687 iter/s, 3.6118s/100 iters), loss = 0.457798
I0628 20:49:43.432099  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:49:43.432099  6212 solver.cpp:237]     Train net output #1: loss = 0.457798 (* 1 = 0.457798 loss)
I0628 20:49:43.432099  6212 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0628 20:49:47.046103  6212 solver.cpp:218] Iteration 20400 (27.6729 iter/s, 3.61365s/100 iters), loss = 0.320482
I0628 20:49:47.046103  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:49:47.046103  6212 solver.cpp:237]     Train net output #1: loss = 0.320482 (* 1 = 0.320482 loss)
I0628 20:49:47.046103  6212 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0628 20:49:50.473868 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:49:50.615075  6212 solver.cpp:330] Iteration 20500, Testing net (#0)
I0628 20:49:50.615075  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:49:51.430884  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:49:51.461441  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8296
I0628 20:49:51.461441  6212 solver.cpp:397]     Test net output #1: loss = 0.506181 (* 1 = 0.506181 loss)
I0628 20:49:51.495471  6212 solver.cpp:218] Iteration 20500 (22.4751 iter/s, 4.44937s/100 iters), loss = 0.328329
I0628 20:49:51.495471  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:49:51.495471  6212 solver.cpp:237]     Train net output #1: loss = 0.328329 (* 1 = 0.328329 loss)
I0628 20:49:51.495471  6212 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0628 20:49:55.093355  6212 solver.cpp:218] Iteration 20600 (27.7945 iter/s, 3.59784s/100 iters), loss = 0.354338
I0628 20:49:55.094344  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:49:55.094344  6212 solver.cpp:237]     Train net output #1: loss = 0.354338 (* 1 = 0.354338 loss)
I0628 20:49:55.094344  6212 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0628 20:49:58.699189  6212 solver.cpp:218] Iteration 20700 (27.7374 iter/s, 3.60524s/100 iters), loss = 0.342206
I0628 20:49:58.699189  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:49:58.699189  6212 solver.cpp:237]     Train net output #1: loss = 0.342206 (* 1 = 0.342206 loss)
I0628 20:49:58.699189  6212 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0628 20:50:02.295614  6212 solver.cpp:218] Iteration 20800 (27.8125 iter/s, 3.59551s/100 iters), loss = 0.366319
I0628 20:50:02.295614  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:50:02.295614  6212 solver.cpp:237]     Train net output #1: loss = 0.366319 (* 1 = 0.366319 loss)
I0628 20:50:02.295614  6212 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0628 20:50:05.902495  6212 solver.cpp:218] Iteration 20900 (27.7231 iter/s, 3.60711s/100 iters), loss = 0.225397
I0628 20:50:05.902495  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:50:05.902495  6212 solver.cpp:237]     Train net output #1: loss = 0.225397 (* 1 = 0.225397 loss)
I0628 20:50:05.902495  6212 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0628 20:50:09.331682 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:50:09.472292  6212 solver.cpp:330] Iteration 21000, Testing net (#0)
I0628 20:50:09.472292  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:50:10.287467  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:50:10.317340  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8169
I0628 20:50:10.317340  6212 solver.cpp:397]     Test net output #1: loss = 0.555512 (* 1 = 0.555512 loss)
I0628 20:50:10.351359  6212 solver.cpp:218] Iteration 21000 (22.4804 iter/s, 4.44833s/100 iters), loss = 0.380762
I0628 20:50:10.351359  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:50:10.351359  6212 solver.cpp:237]     Train net output #1: loss = 0.380762 (* 1 = 0.380762 loss)
I0628 20:50:10.351359  6212 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0628 20:50:13.955231  6212 solver.cpp:218] Iteration 21100 (27.7547 iter/s, 3.60299s/100 iters), loss = 0.22453
I0628 20:50:13.955231  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:50:13.955231  6212 solver.cpp:237]     Train net output #1: loss = 0.22453 (* 1 = 0.22453 loss)
I0628 20:50:13.955231  6212 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0628 20:50:17.550952  6212 solver.cpp:218] Iteration 21200 (27.8111 iter/s, 3.59569s/100 iters), loss = 0.343033
I0628 20:50:17.550952  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:50:17.550952  6212 solver.cpp:237]     Train net output #1: loss = 0.343033 (* 1 = 0.343033 loss)
I0628 20:50:17.550952  6212 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0628 20:50:21.155483  6212 solver.cpp:218] Iteration 21300 (27.7411 iter/s, 3.60475s/100 iters), loss = 0.366007
I0628 20:50:21.156471  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:50:21.156471  6212 solver.cpp:237]     Train net output #1: loss = 0.366007 (* 1 = 0.366007 loss)
I0628 20:50:21.156471  6212 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0628 20:50:24.747797  6212 solver.cpp:218] Iteration 21400 (27.8474 iter/s, 3.591s/100 iters), loss = 0.251172
I0628 20:50:24.747797  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:50:24.747797  6212 solver.cpp:237]     Train net output #1: loss = 0.251171 (* 1 = 0.251171 loss)
I0628 20:50:24.747797  6212 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0628 20:50:28.164191 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:50:28.307366  6212 solver.cpp:330] Iteration 21500, Testing net (#0)
I0628 20:50:28.307366  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:50:29.129339  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:50:29.159356  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7835
I0628 20:50:29.159356  6212 solver.cpp:397]     Test net output #1: loss = 0.677507 (* 1 = 0.677507 loss)
I0628 20:50:29.193888  6212 solver.cpp:218] Iteration 21500 (22.4924 iter/s, 4.44594s/100 iters), loss = 0.238285
I0628 20:50:29.193888  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:50:29.193888  6212 solver.cpp:237]     Train net output #1: loss = 0.238285 (* 1 = 0.238285 loss)
I0628 20:50:29.193888  6212 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0628 20:50:32.808733  6212 solver.cpp:218] Iteration 21600 (27.6659 iter/s, 3.61455s/100 iters), loss = 0.327276
I0628 20:50:32.808733  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:50:32.808733  6212 solver.cpp:237]     Train net output #1: loss = 0.327276 (* 1 = 0.327276 loss)
I0628 20:50:32.808733  6212 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0628 20:50:36.424000  6212 solver.cpp:218] Iteration 21700 (27.665 iter/s, 3.61468s/100 iters), loss = 0.345349
I0628 20:50:36.424000  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:50:36.424000  6212 solver.cpp:237]     Train net output #1: loss = 0.345349 (* 1 = 0.345349 loss)
I0628 20:50:36.424000  6212 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0628 20:50:40.028164  6212 solver.cpp:218] Iteration 21800 (27.7473 iter/s, 3.60395s/100 iters), loss = 0.330549
I0628 20:50:40.028164  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:50:40.028164  6212 solver.cpp:237]     Train net output #1: loss = 0.330549 (* 1 = 0.330549 loss)
I0628 20:50:40.028164  6212 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0628 20:50:43.627018  6212 solver.cpp:218] Iteration 21900 (27.7861 iter/s, 3.59893s/100 iters), loss = 0.250831
I0628 20:50:43.627018  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:50:43.627018  6212 solver.cpp:237]     Train net output #1: loss = 0.250831 (* 1 = 0.250831 loss)
I0628 20:50:43.627018  6212 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0628 20:50:47.047785 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:50:47.188194  6212 solver.cpp:330] Iteration 22000, Testing net (#0)
I0628 20:50:47.188194  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:50:48.000066  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:50:48.030680  6212 solver.cpp:397]     Test net output #0: accuracy = 0.836
I0628 20:50:48.030680  6212 solver.cpp:397]     Test net output #1: loss = 0.500837 (* 1 = 0.500837 loss)
I0628 20:50:48.064710  6212 solver.cpp:218] Iteration 22000 (22.536 iter/s, 4.43735s/100 iters), loss = 0.312307
I0628 20:50:48.064710  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:50:48.064710  6212 solver.cpp:237]     Train net output #1: loss = 0.312307 (* 1 = 0.312307 loss)
I0628 20:50:48.064710  6212 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0628 20:50:51.671423  6212 solver.cpp:218] Iteration 22100 (27.726 iter/s, 3.60672s/100 iters), loss = 0.331865
I0628 20:50:51.671423  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:50:51.671423  6212 solver.cpp:237]     Train net output #1: loss = 0.331865 (* 1 = 0.331865 loss)
I0628 20:50:51.671423  6212 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0628 20:50:55.279156  6212 solver.cpp:218] Iteration 22200 (27.7276 iter/s, 3.60652s/100 iters), loss = 0.301833
I0628 20:50:55.279156  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:50:55.279156  6212 solver.cpp:237]     Train net output #1: loss = 0.301833 (* 1 = 0.301833 loss)
I0628 20:50:55.279156  6212 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0628 20:50:58.876621  6212 solver.cpp:218] Iteration 22300 (27.8003 iter/s, 3.59708s/100 iters), loss = 0.392035
I0628 20:50:58.876621  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:50:58.876621  6212 solver.cpp:237]     Train net output #1: loss = 0.392035 (* 1 = 0.392035 loss)
I0628 20:50:58.876621  6212 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0628 20:51:02.483321  6212 solver.cpp:218] Iteration 22400 (27.7268 iter/s, 3.60662s/100 iters), loss = 0.258041
I0628 20:51:02.483321  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:51:02.483321  6212 solver.cpp:237]     Train net output #1: loss = 0.258041 (* 1 = 0.258041 loss)
I0628 20:51:02.483321  6212 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0628 20:51:05.918287 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:51:06.059402  6212 solver.cpp:330] Iteration 22500, Testing net (#0)
I0628 20:51:06.059402  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:51:06.870401  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:51:06.901408  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8301
I0628 20:51:06.901408  6212 solver.cpp:397]     Test net output #1: loss = 0.511841 (* 1 = 0.511841 loss)
I0628 20:51:06.936446  6212 solver.cpp:218] Iteration 22500 (22.4588 iter/s, 4.45259s/100 iters), loss = 0.251684
I0628 20:51:06.936446  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:51:06.936446  6212 solver.cpp:237]     Train net output #1: loss = 0.251684 (* 1 = 0.251684 loss)
I0628 20:51:06.936446  6212 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0628 20:51:10.546794  6212 solver.cpp:218] Iteration 22600 (27.7022 iter/s, 3.60982s/100 iters), loss = 0.29131
I0628 20:51:10.546794  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:51:10.546794  6212 solver.cpp:237]     Train net output #1: loss = 0.29131 (* 1 = 0.29131 loss)
I0628 20:51:10.546794  6212 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0628 20:51:14.143561  6212 solver.cpp:218] Iteration 22700 (27.8022 iter/s, 3.59683s/100 iters), loss = 0.390713
I0628 20:51:14.143561  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:51:14.143561  6212 solver.cpp:237]     Train net output #1: loss = 0.390713 (* 1 = 0.390713 loss)
I0628 20:51:14.143561  6212 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0628 20:51:17.742689  6212 solver.cpp:218] Iteration 22800 (27.7882 iter/s, 3.59865s/100 iters), loss = 0.307304
I0628 20:51:17.742689  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:51:17.742689  6212 solver.cpp:237]     Train net output #1: loss = 0.307304 (* 1 = 0.307304 loss)
I0628 20:51:17.742689  6212 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0628 20:51:21.349696  6212 solver.cpp:218] Iteration 22900 (27.7261 iter/s, 3.60671s/100 iters), loss = 0.237513
I0628 20:51:21.349696  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:51:21.349696  6212 solver.cpp:237]     Train net output #1: loss = 0.237513 (* 1 = 0.237513 loss)
I0628 20:51:21.349696  6212 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0628 20:51:24.791769 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:51:24.932873  6212 solver.cpp:330] Iteration 23000, Testing net (#0)
I0628 20:51:24.932873  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:51:25.752543  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:51:25.783566  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8073
I0628 20:51:25.783566  6212 solver.cpp:397]     Test net output #1: loss = 0.589937 (* 1 = 0.589937 loss)
I0628 20:51:25.817590  6212 solver.cpp:218] Iteration 23000 (22.3836 iter/s, 4.46755s/100 iters), loss = 0.331745
I0628 20:51:25.817590  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:51:25.817590  6212 solver.cpp:237]     Train net output #1: loss = 0.331745 (* 1 = 0.331745 loss)
I0628 20:51:25.817590  6212 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0628 20:51:29.422420  6212 solver.cpp:218] Iteration 23100 (27.7439 iter/s, 3.60439s/100 iters), loss = 0.215816
I0628 20:51:29.422420  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:51:29.422420  6212 solver.cpp:237]     Train net output #1: loss = 0.215816 (* 1 = 0.215816 loss)
I0628 20:51:29.422420  6212 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0628 20:51:33.026870  6212 solver.cpp:218] Iteration 23200 (27.7441 iter/s, 3.60437s/100 iters), loss = 0.345717
I0628 20:51:33.026870  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:51:33.026870  6212 solver.cpp:237]     Train net output #1: loss = 0.345718 (* 1 = 0.345718 loss)
I0628 20:51:33.026870  6212 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0628 20:51:36.643584  6212 solver.cpp:218] Iteration 23300 (27.6492 iter/s, 3.61674s/100 iters), loss = 0.402506
I0628 20:51:36.643584  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:51:36.643584  6212 solver.cpp:237]     Train net output #1: loss = 0.402506 (* 1 = 0.402506 loss)
I0628 20:51:36.643584  6212 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0628 20:51:40.258347  6212 solver.cpp:218] Iteration 23400 (27.6706 iter/s, 3.61394s/100 iters), loss = 0.264776
I0628 20:51:40.258347  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:51:40.258347  6212 solver.cpp:237]     Train net output #1: loss = 0.264776 (* 1 = 0.264776 loss)
I0628 20:51:40.258347  6212 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0628 20:51:43.688426 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:51:43.830530  6212 solver.cpp:330] Iteration 23500, Testing net (#0)
I0628 20:51:43.830530  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:51:44.645900  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:51:44.676924  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8268
I0628 20:51:44.676924  6212 solver.cpp:397]     Test net output #1: loss = 0.513511 (* 1 = 0.513511 loss)
I0628 20:51:44.711951  6212 solver.cpp:218] Iteration 23500 (22.4565 iter/s, 4.45305s/100 iters), loss = 0.315508
I0628 20:51:44.711951  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:51:44.711951  6212 solver.cpp:237]     Train net output #1: loss = 0.315508 (* 1 = 0.315508 loss)
I0628 20:51:44.711951  6212 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0628 20:51:48.316658  6212 solver.cpp:218] Iteration 23600 (27.744 iter/s, 3.60439s/100 iters), loss = 0.244774
I0628 20:51:48.316658  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:51:48.316658  6212 solver.cpp:237]     Train net output #1: loss = 0.244774 (* 1 = 0.244774 loss)
I0628 20:51:48.316658  6212 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0628 20:51:51.921485  6212 solver.cpp:218] Iteration 23700 (27.7437 iter/s, 3.60442s/100 iters), loss = 0.384377
I0628 20:51:51.921485  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:51:51.921485  6212 solver.cpp:237]     Train net output #1: loss = 0.384377 (* 1 = 0.384377 loss)
I0628 20:51:51.921485  6212 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0628 20:51:55.536173  6212 solver.cpp:218] Iteration 23800 (27.6631 iter/s, 3.61493s/100 iters), loss = 0.279973
I0628 20:51:55.536173  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:51:55.536173  6212 solver.cpp:237]     Train net output #1: loss = 0.279972 (* 1 = 0.279972 loss)
I0628 20:51:55.536173  6212 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0628 20:51:59.140012  6212 solver.cpp:218] Iteration 23900 (27.7525 iter/s, 3.60328s/100 iters), loss = 0.276166
I0628 20:51:59.140012  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:51:59.140012  6212 solver.cpp:237]     Train net output #1: loss = 0.276166 (* 1 = 0.276166 loss)
I0628 20:51:59.140012  6212 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0628 20:52:02.630358 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:52:02.769590  6212 solver.cpp:330] Iteration 24000, Testing net (#0)
I0628 20:52:02.770589  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:52:03.581261  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:52:03.611897  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8169
I0628 20:52:03.611897  6212 solver.cpp:397]     Test net output #1: loss = 0.569556 (* 1 = 0.569556 loss)
I0628 20:52:03.645933  6212 solver.cpp:218] Iteration 24000 (22.1963 iter/s, 4.50525s/100 iters), loss = 0.316333
I0628 20:52:03.645933  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:52:03.645933  6212 solver.cpp:237]     Train net output #1: loss = 0.316333 (* 1 = 0.316333 loss)
I0628 20:52:03.645933  6212 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0628 20:52:07.251354  6212 solver.cpp:218] Iteration 24100 (27.74 iter/s, 3.60491s/100 iters), loss = 0.27718
I0628 20:52:07.251354  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:52:07.251354  6212 solver.cpp:237]     Train net output #1: loss = 0.27718 (* 1 = 0.27718 loss)
I0628 20:52:07.251354  6212 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0628 20:52:10.859640  6212 solver.cpp:218] Iteration 24200 (27.7113 iter/s, 3.60863s/100 iters), loss = 0.228858
I0628 20:52:10.859640  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:52:10.859640  6212 solver.cpp:237]     Train net output #1: loss = 0.228858 (* 1 = 0.228858 loss)
I0628 20:52:10.859640  6212 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0628 20:52:14.454339  6212 solver.cpp:218] Iteration 24300 (27.824 iter/s, 3.59402s/100 iters), loss = 0.360411
I0628 20:52:14.454339  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:52:14.454339  6212 solver.cpp:237]     Train net output #1: loss = 0.360411 (* 1 = 0.360411 loss)
I0628 20:52:14.454339  6212 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0628 20:52:18.052203  6212 solver.cpp:218] Iteration 24400 (27.7927 iter/s, 3.59806s/100 iters), loss = 0.256185
I0628 20:52:18.053205  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:52:18.053205  6212 solver.cpp:237]     Train net output #1: loss = 0.256184 (* 1 = 0.256184 loss)
I0628 20:52:18.053205  6212 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0628 20:52:21.478273 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:52:21.619379  6212 solver.cpp:330] Iteration 24500, Testing net (#0)
I0628 20:52:21.619379  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:52:22.433111  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:52:22.463132  6212 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0628 20:52:22.463132  6212 solver.cpp:397]     Test net output #1: loss = 0.551677 (* 1 = 0.551677 loss)
I0628 20:52:22.497658  6212 solver.cpp:218] Iteration 24500 (22.499 iter/s, 4.44464s/100 iters), loss = 0.254434
I0628 20:52:22.498159  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:52:22.498159  6212 solver.cpp:237]     Train net output #1: loss = 0.254434 (* 1 = 0.254434 loss)
I0628 20:52:22.498159  6212 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0628 20:52:26.094830  6212 solver.cpp:218] Iteration 24600 (27.8016 iter/s, 3.59692s/100 iters), loss = 0.265492
I0628 20:52:26.094830  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:52:26.094830  6212 solver.cpp:237]     Train net output #1: loss = 0.265492 (* 1 = 0.265492 loss)
I0628 20:52:26.094830  6212 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0628 20:52:29.696527  6212 solver.cpp:218] Iteration 24700 (27.7693 iter/s, 3.6011s/100 iters), loss = 0.331472
I0628 20:52:29.696527  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:52:29.696527  6212 solver.cpp:237]     Train net output #1: loss = 0.331472 (* 1 = 0.331472 loss)
I0628 20:52:29.696527  6212 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0628 20:52:33.290043  6212 solver.cpp:218] Iteration 24800 (27.8293 iter/s, 3.59334s/100 iters), loss = 0.395631
I0628 20:52:33.290043  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:52:33.290043  6212 solver.cpp:237]     Train net output #1: loss = 0.395631 (* 1 = 0.395631 loss)
I0628 20:52:33.290043  6212 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0628 20:52:36.885813  6212 solver.cpp:218] Iteration 24900 (27.812 iter/s, 3.59557s/100 iters), loss = 0.278809
I0628 20:52:36.885813  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:52:36.885813  6212 solver.cpp:237]     Train net output #1: loss = 0.278809 (* 1 = 0.278809 loss)
I0628 20:52:36.885813  6212 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0628 20:52:40.309870 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:52:40.449477  6212 solver.cpp:330] Iteration 25000, Testing net (#0)
I0628 20:52:40.449477  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:52:41.270193  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:52:41.293205  6212 solver.cpp:397]     Test net output #0: accuracy = 0.839
I0628 20:52:41.294206  6212 solver.cpp:397]     Test net output #1: loss = 0.479135 (* 1 = 0.479135 loss)
I0628 20:52:41.327232  6212 solver.cpp:218] Iteration 25000 (22.516 iter/s, 4.44128s/100 iters), loss = 0.22482
I0628 20:52:41.327232  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:52:41.327232  6212 solver.cpp:237]     Train net output #1: loss = 0.22482 (* 1 = 0.22482 loss)
I0628 20:52:41.327232  6212 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0628 20:52:44.938942  6212 solver.cpp:218] Iteration 25100 (27.6938 iter/s, 3.61091s/100 iters), loss = 0.325576
I0628 20:52:44.938942  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:52:44.938942  6212 solver.cpp:237]     Train net output #1: loss = 0.325576 (* 1 = 0.325576 loss)
I0628 20:52:44.938942  6212 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0628 20:52:48.544555  6212 solver.cpp:218] Iteration 25200 (27.7372 iter/s, 3.60526s/100 iters), loss = 0.408552
I0628 20:52:48.544555  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:52:48.544555  6212 solver.cpp:237]     Train net output #1: loss = 0.408552 (* 1 = 0.408552 loss)
I0628 20:52:48.544555  6212 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0628 20:52:52.145186  6212 solver.cpp:218] Iteration 25300 (27.7774 iter/s, 3.60005s/100 iters), loss = 0.283287
I0628 20:52:52.145186  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:52:52.145186  6212 solver.cpp:237]     Train net output #1: loss = 0.283287 (* 1 = 0.283287 loss)
I0628 20:52:52.145186  6212 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0628 20:52:55.751386  6212 solver.cpp:218] Iteration 25400 (27.7336 iter/s, 3.60573s/100 iters), loss = 0.26065
I0628 20:52:55.751386  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:52:55.751386  6212 solver.cpp:237]     Train net output #1: loss = 0.260649 (* 1 = 0.260649 loss)
I0628 20:52:55.751386  6212 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0628 20:52:59.180464 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:52:59.322567  6212 solver.cpp:330] Iteration 25500, Testing net (#0)
I0628 20:52:59.322567  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:53:00.133302  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:53:00.164326  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7937
I0628 20:53:00.164826  6212 solver.cpp:397]     Test net output #1: loss = 0.642892 (* 1 = 0.642892 loss)
I0628 20:53:00.198351  6212 solver.cpp:218] Iteration 25500 (22.4871 iter/s, 4.44699s/100 iters), loss = 0.392411
I0628 20:53:00.198351  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:53:00.198351  6212 solver.cpp:237]     Train net output #1: loss = 0.392411 (* 1 = 0.392411 loss)
I0628 20:53:00.198351  6212 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0628 20:53:03.808053  6212 solver.cpp:218] Iteration 25600 (27.706 iter/s, 3.60932s/100 iters), loss = 0.240413
I0628 20:53:03.808053  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:53:03.808053  6212 solver.cpp:237]     Train net output #1: loss = 0.240413 (* 1 = 0.240413 loss)
I0628 20:53:03.808053  6212 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0628 20:53:07.417893  6212 solver.cpp:218] Iteration 25700 (27.7004 iter/s, 3.61006s/100 iters), loss = 0.461679
I0628 20:53:07.418895  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 20:53:07.418895  6212 solver.cpp:237]     Train net output #1: loss = 0.461679 (* 1 = 0.461679 loss)
I0628 20:53:07.418895  6212 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0628 20:53:11.016654  6212 solver.cpp:218] Iteration 25800 (27.7918 iter/s, 3.59818s/100 iters), loss = 0.320822
I0628 20:53:11.016654  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:53:11.016654  6212 solver.cpp:237]     Train net output #1: loss = 0.320822 (* 1 = 0.320822 loss)
I0628 20:53:11.016654  6212 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0628 20:53:14.618794  6212 solver.cpp:218] Iteration 25900 (27.7692 iter/s, 3.60111s/100 iters), loss = 0.227736
I0628 20:53:14.618794  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:53:14.618794  6212 solver.cpp:237]     Train net output #1: loss = 0.227736 (* 1 = 0.227736 loss)
I0628 20:53:14.618794  6212 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0628 20:53:18.050350 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:53:18.190455  6212 solver.cpp:330] Iteration 26000, Testing net (#0)
I0628 20:53:18.191457  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:53:19.002068  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:53:19.033089  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8052
I0628 20:53:19.033089  6212 solver.cpp:397]     Test net output #1: loss = 0.609984 (* 1 = 0.609984 loss)
I0628 20:53:19.067113  6212 solver.cpp:218] Iteration 26000 (22.479 iter/s, 4.4486s/100 iters), loss = 0.31654
I0628 20:53:19.067113  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:53:19.067113  6212 solver.cpp:237]     Train net output #1: loss = 0.31654 (* 1 = 0.31654 loss)
I0628 20:53:19.067113  6212 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0628 20:53:22.673318  6212 solver.cpp:218] Iteration 26100 (27.7367 iter/s, 3.60533s/100 iters), loss = 0.254121
I0628 20:53:22.673318  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:53:22.673318  6212 solver.cpp:237]     Train net output #1: loss = 0.254121 (* 1 = 0.254121 loss)
I0628 20:53:22.673318  6212 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0628 20:53:26.268576  6212 solver.cpp:218] Iteration 26200 (27.8125 iter/s, 3.59551s/100 iters), loss = 0.316709
I0628 20:53:26.268576  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:53:26.268576  6212 solver.cpp:237]     Train net output #1: loss = 0.316709 (* 1 = 0.316709 loss)
I0628 20:53:26.268576  6212 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0628 20:53:29.872714  6212 solver.cpp:218] Iteration 26300 (27.7531 iter/s, 3.6032s/100 iters), loss = 0.39298
I0628 20:53:29.872714  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:53:29.872714  6212 solver.cpp:237]     Train net output #1: loss = 0.39298 (* 1 = 0.39298 loss)
I0628 20:53:29.872714  6212 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0628 20:53:33.467775  6212 solver.cpp:218] Iteration 26400 (27.8118 iter/s, 3.59559s/100 iters), loss = 0.306756
I0628 20:53:33.468776  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:53:33.468776  6212 solver.cpp:237]     Train net output #1: loss = 0.306756 (* 1 = 0.306756 loss)
I0628 20:53:33.468776  6212 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0628 20:53:36.900152 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:53:37.041259  6212 solver.cpp:330] Iteration 26500, Testing net (#0)
I0628 20:53:37.041259  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:53:37.854862  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:53:37.885885  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8144
I0628 20:53:37.885885  6212 solver.cpp:397]     Test net output #1: loss = 0.572391 (* 1 = 0.572391 loss)
I0628 20:53:37.919909  6212 solver.cpp:218] Iteration 26500 (22.467 iter/s, 4.45097s/100 iters), loss = 0.318936
I0628 20:53:37.919909  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:53:37.919909  6212 solver.cpp:237]     Train net output #1: loss = 0.318936 (* 1 = 0.318936 loss)
I0628 20:53:37.919909  6212 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0628 20:53:41.523636  6212 solver.cpp:218] Iteration 26600 (27.7514 iter/s, 3.60343s/100 iters), loss = 0.25499
I0628 20:53:41.523636  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:53:41.523636  6212 solver.cpp:237]     Train net output #1: loss = 0.25499 (* 1 = 0.25499 loss)
I0628 20:53:41.523636  6212 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0628 20:53:45.119415  6212 solver.cpp:218] Iteration 26700 (27.8076 iter/s, 3.59614s/100 iters), loss = 0.40498
I0628 20:53:45.119415  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:53:45.119415  6212 solver.cpp:237]     Train net output #1: loss = 0.40498 (* 1 = 0.40498 loss)
I0628 20:53:45.119415  6212 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0628 20:53:48.739243  6212 solver.cpp:218] Iteration 26800 (27.6293 iter/s, 3.61935s/100 iters), loss = 0.359514
I0628 20:53:48.739243  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:53:48.739243  6212 solver.cpp:237]     Train net output #1: loss = 0.359514 (* 1 = 0.359514 loss)
I0628 20:53:48.739243  6212 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0628 20:53:52.341722  6212 solver.cpp:218] Iteration 26900 (27.7605 iter/s, 3.60224s/100 iters), loss = 0.239214
I0628 20:53:52.341722  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:53:52.341722  6212 solver.cpp:237]     Train net output #1: loss = 0.239213 (* 1 = 0.239213 loss)
I0628 20:53:52.341722  6212 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0628 20:53:55.767961 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:53:55.909373  6212 solver.cpp:330] Iteration 27000, Testing net (#0)
I0628 20:53:55.909373  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:53:56.723147  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:53:56.753674  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8132
I0628 20:53:56.753674  6212 solver.cpp:397]     Test net output #1: loss = 0.579535 (* 1 = 0.579535 loss)
I0628 20:53:56.788224  6212 solver.cpp:218] Iteration 27000 (22.4956 iter/s, 4.44531s/100 iters), loss = 0.284178
I0628 20:53:56.788224  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:53:56.788224  6212 solver.cpp:237]     Train net output #1: loss = 0.284178 (* 1 = 0.284178 loss)
I0628 20:53:56.788224  6212 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0628 20:54:00.382772  6212 solver.cpp:218] Iteration 27100 (27.8178 iter/s, 3.59482s/100 iters), loss = 0.238697
I0628 20:54:00.382772  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:54:00.382772  6212 solver.cpp:237]     Train net output #1: loss = 0.238697 (* 1 = 0.238697 loss)
I0628 20:54:00.382772  6212 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0628 20:54:03.983451  6212 solver.cpp:218] Iteration 27200 (27.7766 iter/s, 3.60015s/100 iters), loss = 0.339386
I0628 20:54:03.983451  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:54:03.983451  6212 solver.cpp:237]     Train net output #1: loss = 0.339386 (* 1 = 0.339386 loss)
I0628 20:54:03.983451  6212 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0628 20:54:07.587553  6212 solver.cpp:218] Iteration 27300 (27.7446 iter/s, 3.6043s/100 iters), loss = 0.313873
I0628 20:54:07.588558  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:54:07.588558  6212 solver.cpp:237]     Train net output #1: loss = 0.313873 (* 1 = 0.313873 loss)
I0628 20:54:07.588558  6212 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0628 20:54:11.190137  6212 solver.cpp:218] Iteration 27400 (27.765 iter/s, 3.60166s/100 iters), loss = 0.194448
I0628 20:54:11.190137  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:54:11.190137  6212 solver.cpp:237]     Train net output #1: loss = 0.194448 (* 1 = 0.194448 loss)
I0628 20:54:11.190137  6212 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0628 20:54:14.609302 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:54:14.750015  6212 solver.cpp:330] Iteration 27500, Testing net (#0)
I0628 20:54:14.750015  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:54:15.563365  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:54:15.594343  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8001
I0628 20:54:15.594343  6212 solver.cpp:397]     Test net output #1: loss = 0.620636 (* 1 = 0.620636 loss)
I0628 20:54:15.628360  6212 solver.cpp:218] Iteration 27500 (22.5307 iter/s, 4.43838s/100 iters), loss = 0.2496
I0628 20:54:15.628360  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:54:15.628360  6212 solver.cpp:237]     Train net output #1: loss = 0.2496 (* 1 = 0.2496 loss)
I0628 20:54:15.628360  6212 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0628 20:54:19.222810  6212 solver.cpp:218] Iteration 27600 (27.8261 iter/s, 3.59375s/100 iters), loss = 0.335395
I0628 20:54:19.222810  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:54:19.222810  6212 solver.cpp:237]     Train net output #1: loss = 0.335395 (* 1 = 0.335395 loss)
I0628 20:54:19.222810  6212 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0628 20:54:22.844727  6212 solver.cpp:218] Iteration 27700 (27.6121 iter/s, 3.6216s/100 iters), loss = 0.311039
I0628 20:54:22.844727  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:54:22.844727  6212 solver.cpp:237]     Train net output #1: loss = 0.311039 (* 1 = 0.311039 loss)
I0628 20:54:22.844727  6212 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0628 20:54:26.445413  6212 solver.cpp:218] Iteration 27800 (27.7772 iter/s, 3.60007s/100 iters), loss = 0.341868
I0628 20:54:26.445413  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:54:26.445413  6212 solver.cpp:237]     Train net output #1: loss = 0.341868 (* 1 = 0.341868 loss)
I0628 20:54:26.445413  6212 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0628 20:54:30.039608  6212 solver.cpp:218] Iteration 27900 (27.825 iter/s, 3.59389s/100 iters), loss = 0.256237
I0628 20:54:30.039608  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:54:30.039608  6212 solver.cpp:237]     Train net output #1: loss = 0.256237 (* 1 = 0.256237 loss)
I0628 20:54:30.039608  6212 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0628 20:54:33.465571 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:54:33.606681  6212 solver.cpp:330] Iteration 28000, Testing net (#0)
I0628 20:54:33.606681  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:54:34.420295  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:54:34.451315  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8348
I0628 20:54:34.451315  6212 solver.cpp:397]     Test net output #1: loss = 0.49957 (* 1 = 0.49957 loss)
I0628 20:54:34.485340  6212 solver.cpp:218] Iteration 28000 (22.4921 iter/s, 4.446s/100 iters), loss = 0.310446
I0628 20:54:34.485340  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:54:34.485340  6212 solver.cpp:237]     Train net output #1: loss = 0.310446 (* 1 = 0.310446 loss)
I0628 20:54:34.485340  6212 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0628 20:54:38.086040  6212 solver.cpp:218] Iteration 28100 (27.7795 iter/s, 3.59978s/100 iters), loss = 0.271006
I0628 20:54:38.086040  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:54:38.086040  6212 solver.cpp:237]     Train net output #1: loss = 0.271006 (* 1 = 0.271006 loss)
I0628 20:54:38.086040  6212 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0628 20:54:41.684715  6212 solver.cpp:218] Iteration 28200 (27.7865 iter/s, 3.59888s/100 iters), loss = 0.340059
I0628 20:54:41.684715  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:54:41.684715  6212 solver.cpp:237]     Train net output #1: loss = 0.340059 (* 1 = 0.340059 loss)
I0628 20:54:41.684715  6212 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0628 20:54:45.287408  6212 solver.cpp:218] Iteration 28300 (27.7633 iter/s, 3.60188s/100 iters), loss = 0.402307
I0628 20:54:45.287408  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:54:45.287408  6212 solver.cpp:237]     Train net output #1: loss = 0.402307 (* 1 = 0.402307 loss)
I0628 20:54:45.287408  6212 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0628 20:54:48.887444  6212 solver.cpp:218] Iteration 28400 (27.7829 iter/s, 3.59934s/100 iters), loss = 0.299282
I0628 20:54:48.887444  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:54:48.887444  6212 solver.cpp:237]     Train net output #1: loss = 0.299282 (* 1 = 0.299282 loss)
I0628 20:54:48.887444  6212 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0628 20:54:52.320996 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:54:52.463099  6212 solver.cpp:330] Iteration 28500, Testing net (#0)
I0628 20:54:52.463099  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:54:53.274855  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:54:53.306380  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8367
I0628 20:54:53.306380  6212 solver.cpp:397]     Test net output #1: loss = 0.498298 (* 1 = 0.498298 loss)
I0628 20:54:53.339905  6212 solver.cpp:218] Iteration 28500 (22.458 iter/s, 4.45276s/100 iters), loss = 0.304562
I0628 20:54:53.339905  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:54:53.339905  6212 solver.cpp:237]     Train net output #1: loss = 0.304562 (* 1 = 0.304562 loss)
I0628 20:54:53.339905  6212 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0628 20:54:56.936653  6212 solver.cpp:218] Iteration 28600 (27.8091 iter/s, 3.59595s/100 iters), loss = 0.26205
I0628 20:54:56.936653  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:54:56.936653  6212 solver.cpp:237]     Train net output #1: loss = 0.26205 (* 1 = 0.26205 loss)
I0628 20:54:56.936653  6212 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0628 20:55:00.529690  6212 solver.cpp:218] Iteration 28700 (27.8325 iter/s, 3.59292s/100 iters), loss = 0.342804
I0628 20:55:00.529690  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:55:00.529690  6212 solver.cpp:237]     Train net output #1: loss = 0.342804 (* 1 = 0.342804 loss)
I0628 20:55:00.529690  6212 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I0628 20:55:04.127349  6212 solver.cpp:218] Iteration 28800 (27.7987 iter/s, 3.59729s/100 iters), loss = 0.34562
I0628 20:55:04.127349  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:55:04.127349  6212 solver.cpp:237]     Train net output #1: loss = 0.34562 (* 1 = 0.34562 loss)
I0628 20:55:04.127349  6212 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I0628 20:55:07.723204  6212 solver.cpp:218] Iteration 28900 (27.8111 iter/s, 3.59568s/100 iters), loss = 0.301766
I0628 20:55:07.723204  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:55:07.723204  6212 solver.cpp:237]     Train net output #1: loss = 0.301766 (* 1 = 0.301766 loss)
I0628 20:55:07.723204  6212 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I0628 20:55:11.146757 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:55:11.288861  6212 solver.cpp:330] Iteration 29000, Testing net (#0)
I0628 20:55:11.288861  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:55:12.100980  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:55:12.131502  6212 solver.cpp:397]     Test net output #0: accuracy = 0.7773
I0628 20:55:12.131502  6212 solver.cpp:397]     Test net output #1: loss = 0.736285 (* 1 = 0.736285 loss)
I0628 20:55:12.165526  6212 solver.cpp:218] Iteration 29000 (22.5121 iter/s, 4.44205s/100 iters), loss = 0.294305
I0628 20:55:12.165526  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:55:12.165526  6212 solver.cpp:237]     Train net output #1: loss = 0.294305 (* 1 = 0.294305 loss)
I0628 20:55:12.165526  6212 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I0628 20:55:15.768201  6212 solver.cpp:218] Iteration 29100 (27.7602 iter/s, 3.60228s/100 iters), loss = 0.23525
I0628 20:55:15.768201  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:55:15.768201  6212 solver.cpp:237]     Train net output #1: loss = 0.23525 (* 1 = 0.23525 loss)
I0628 20:55:15.768201  6212 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I0628 20:55:19.373281  6212 solver.cpp:218] Iteration 29200 (27.7405 iter/s, 3.60483s/100 iters), loss = 0.334953
I0628 20:55:19.374284  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:55:19.374284  6212 solver.cpp:237]     Train net output #1: loss = 0.334953 (* 1 = 0.334953 loss)
I0628 20:55:19.374284  6212 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I0628 20:55:22.972957  6212 solver.cpp:218] Iteration 29300 (27.7907 iter/s, 3.59832s/100 iters), loss = 0.279036
I0628 20:55:22.972957  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:55:22.972957  6212 solver.cpp:237]     Train net output #1: loss = 0.279036 (* 1 = 0.279036 loss)
I0628 20:55:22.972957  6212 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I0628 20:55:26.571655  6212 solver.cpp:218] Iteration 29400 (27.7905 iter/s, 3.59835s/100 iters), loss = 0.238897
I0628 20:55:26.571655  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:55:26.571655  6212 solver.cpp:237]     Train net output #1: loss = 0.238898 (* 1 = 0.238898 loss)
I0628 20:55:26.571655  6212 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I0628 20:55:29.990206 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:55:30.130311  6212 solver.cpp:330] Iteration 29500, Testing net (#0)
I0628 20:55:30.130311  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:55:30.948932  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:55:30.979954  6212 solver.cpp:397]     Test net output #0: accuracy = 0.821
I0628 20:55:30.979954  6212 solver.cpp:397]     Test net output #1: loss = 0.551153 (* 1 = 0.551153 loss)
I0628 20:55:31.014480  6212 solver.cpp:218] Iteration 29500 (22.5099 iter/s, 4.4425s/100 iters), loss = 0.299754
I0628 20:55:31.014480  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:55:31.014480  6212 solver.cpp:237]     Train net output #1: loss = 0.299755 (* 1 = 0.299755 loss)
I0628 20:55:31.014480  6212 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I0628 20:55:34.621784  6212 solver.cpp:218] Iteration 29600 (27.7251 iter/s, 3.60684s/100 iters), loss = 0.251248
I0628 20:55:34.621784  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:55:34.621784  6212 solver.cpp:237]     Train net output #1: loss = 0.251248 (* 1 = 0.251248 loss)
I0628 20:55:34.621784  6212 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I0628 20:55:38.221675  6212 solver.cpp:218] Iteration 29700 (27.7803 iter/s, 3.59967s/100 iters), loss = 0.280451
I0628 20:55:38.221675  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:55:38.221675  6212 solver.cpp:237]     Train net output #1: loss = 0.280451 (* 1 = 0.280451 loss)
I0628 20:55:38.221675  6212 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I0628 20:55:41.823843  6212 solver.cpp:218] Iteration 29800 (27.7604 iter/s, 3.60226s/100 iters), loss = 0.338484
I0628 20:55:41.823843  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:55:41.823843  6212 solver.cpp:237]     Train net output #1: loss = 0.338484 (* 1 = 0.338484 loss)
I0628 20:55:41.823843  6212 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I0628 20:55:45.416517  6212 solver.cpp:218] Iteration 29900 (27.8343 iter/s, 3.59268s/100 iters), loss = 0.297024
I0628 20:55:45.416517  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:55:45.417518  6212 solver.cpp:237]     Train net output #1: loss = 0.297024 (* 1 = 0.297024 loss)
I0628 20:55:45.417518  6212 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I0628 20:55:48.852917 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:55:48.993093  6212 solver.cpp:330] Iteration 30000, Testing net (#0)
I0628 20:55:48.993093  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:55:49.809780  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:55:49.840803  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8198
I0628 20:55:49.840803  6212 solver.cpp:397]     Test net output #1: loss = 0.568402 (* 1 = 0.568402 loss)
I0628 20:55:49.874842  6212 solver.cpp:218] Iteration 30000 (22.4328 iter/s, 4.45776s/100 iters), loss = 0.343039
I0628 20:55:49.874842  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:55:49.874842  6212 solver.cpp:237]     Train net output #1: loss = 0.343039 (* 1 = 0.343039 loss)
I0628 20:55:49.874842  6212 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I0628 20:55:53.469017  6212 solver.cpp:218] Iteration 30100 (27.8243 iter/s, 3.59398s/100 iters), loss = 0.256971
I0628 20:55:53.469017  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:55:53.469017  6212 solver.cpp:237]     Train net output #1: loss = 0.256971 (* 1 = 0.256971 loss)
I0628 20:55:53.469017  6212 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I0628 20:55:57.070535  6212 solver.cpp:218] Iteration 30200 (27.7732 iter/s, 3.60059s/100 iters), loss = 0.268373
I0628 20:55:57.070535  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:55:57.070535  6212 solver.cpp:237]     Train net output #1: loss = 0.268374 (* 1 = 0.268374 loss)
I0628 20:55:57.070535  6212 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I0628 20:56:00.678866  6212 solver.cpp:218] Iteration 30300 (27.7107 iter/s, 3.60871s/100 iters), loss = 0.288738
I0628 20:56:00.679867  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:56:00.679867  6212 solver.cpp:237]     Train net output #1: loss = 0.288738 (* 1 = 0.288738 loss)
I0628 20:56:00.679867  6212 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I0628 20:56:04.277534  6212 solver.cpp:218] Iteration 30400 (27.7978 iter/s, 3.59741s/100 iters), loss = 0.226361
I0628 20:56:04.277534  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:56:04.277534  6212 solver.cpp:237]     Train net output #1: loss = 0.226361 (* 1 = 0.226361 loss)
I0628 20:56:04.277534  6212 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I0628 20:56:07.707119 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:56:07.848726  6212 solver.cpp:330] Iteration 30500, Testing net (#0)
I0628 20:56:07.848726  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:56:08.660547  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:56:08.690568  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8247
I0628 20:56:08.690568  6212 solver.cpp:397]     Test net output #1: loss = 0.547916 (* 1 = 0.547916 loss)
I0628 20:56:08.728598  6212 solver.cpp:218] Iteration 30500 (22.4654 iter/s, 4.45129s/100 iters), loss = 0.273355
I0628 20:56:08.728598  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:56:08.728598  6212 solver.cpp:237]     Train net output #1: loss = 0.273355 (* 1 = 0.273355 loss)
I0628 20:56:08.728598  6212 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I0628 20:56:12.331297  6212 solver.cpp:218] Iteration 30600 (27.7615 iter/s, 3.60211s/100 iters), loss = 0.222687
I0628 20:56:12.331297  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:56:12.331297  6212 solver.cpp:237]     Train net output #1: loss = 0.222687 (* 1 = 0.222687 loss)
I0628 20:56:12.331297  6212 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I0628 20:56:15.929998  6212 solver.cpp:218] Iteration 30700 (27.7931 iter/s, 3.59802s/100 iters), loss = 0.371498
I0628 20:56:15.929998  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:56:15.929998  6212 solver.cpp:237]     Train net output #1: loss = 0.371498 (* 1 = 0.371498 loss)
I0628 20:56:15.929998  6212 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I0628 20:56:19.529722  6212 solver.cpp:218] Iteration 30800 (27.7784 iter/s, 3.59992s/100 iters), loss = 0.326459
I0628 20:56:19.529722  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:56:19.529722  6212 solver.cpp:237]     Train net output #1: loss = 0.32646 (* 1 = 0.32646 loss)
I0628 20:56:19.529722  6212 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I0628 20:56:23.125301  6212 solver.cpp:218] Iteration 30900 (27.8146 iter/s, 3.59523s/100 iters), loss = 0.276742
I0628 20:56:23.125301  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:56:23.125301  6212 solver.cpp:237]     Train net output #1: loss = 0.276743 (* 1 = 0.276743 loss)
I0628 20:56:23.125301  6212 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I0628 20:56:26.550845 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:56:26.690948  6212 solver.cpp:330] Iteration 31000, Testing net (#0)
I0628 20:56:26.690948  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:56:27.509570  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:56:27.540597  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8408
I0628 20:56:27.540597  6212 solver.cpp:397]     Test net output #1: loss = 0.47878 (* 1 = 0.47878 loss)
I0628 20:56:27.574620  6212 solver.cpp:218] Iteration 31000 (22.4792 iter/s, 4.44855s/100 iters), loss = 0.341745
I0628 20:56:27.574620  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:56:27.574620  6212 solver.cpp:237]     Train net output #1: loss = 0.341745 (* 1 = 0.341745 loss)
I0628 20:56:27.574620  6212 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I0628 20:56:31.180802  6212 solver.cpp:218] Iteration 31100 (27.7331 iter/s, 3.60581s/100 iters), loss = 0.270466
I0628 20:56:31.180802  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:56:31.180802  6212 solver.cpp:237]     Train net output #1: loss = 0.270466 (* 1 = 0.270466 loss)
I0628 20:56:31.180802  6212 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I0628 20:56:34.784358  6212 solver.cpp:218] Iteration 31200 (27.754 iter/s, 3.60308s/100 iters), loss = 0.288103
I0628 20:56:34.784358  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:56:34.784358  6212 solver.cpp:237]     Train net output #1: loss = 0.288103 (* 1 = 0.288103 loss)
I0628 20:56:34.784358  6212 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I0628 20:56:38.381572  6212 solver.cpp:218] Iteration 31300 (27.8 iter/s, 3.59713s/100 iters), loss = 0.284116
I0628 20:56:38.381572  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:56:38.381572  6212 solver.cpp:237]     Train net output #1: loss = 0.284116 (* 1 = 0.284116 loss)
I0628 20:56:38.381572  6212 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I0628 20:56:41.981343  6212 solver.cpp:218] Iteration 31400 (27.7833 iter/s, 3.59929s/100 iters), loss = 0.272649
I0628 20:56:41.981343  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:56:41.981343  6212 solver.cpp:237]     Train net output #1: loss = 0.272649 (* 1 = 0.272649 loss)
I0628 20:56:41.981343  6212 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I0628 20:56:45.426391 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:56:45.566491  6212 solver.cpp:330] Iteration 31500, Testing net (#0)
I0628 20:56:45.566992  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:56:46.378870  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:56:46.409394  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8108
I0628 20:56:46.409394  6212 solver.cpp:397]     Test net output #1: loss = 0.617548 (* 1 = 0.617548 loss)
I0628 20:56:46.443418  6212 solver.cpp:218] Iteration 31500 (22.4103 iter/s, 4.46224s/100 iters), loss = 0.286733
I0628 20:56:46.443418  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:56:46.443418  6212 solver.cpp:237]     Train net output #1: loss = 0.286733 (* 1 = 0.286733 loss)
I0628 20:56:46.443418  6212 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I0628 20:56:50.048123  6212 solver.cpp:218] Iteration 31600 (27.7443 iter/s, 3.60435s/100 iters), loss = 0.256453
I0628 20:56:50.048123  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:56:50.048123  6212 solver.cpp:237]     Train net output #1: loss = 0.256453 (* 1 = 0.256453 loss)
I0628 20:56:50.048123  6212 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I0628 20:56:53.642006  6212 solver.cpp:218] Iteration 31700 (27.8315 iter/s, 3.59305s/100 iters), loss = 0.257256
I0628 20:56:53.642006  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:56:53.642006  6212 solver.cpp:237]     Train net output #1: loss = 0.257257 (* 1 = 0.257257 loss)
I0628 20:56:53.642006  6212 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I0628 20:56:57.244577  6212 solver.cpp:218] Iteration 31800 (27.758 iter/s, 3.60256s/100 iters), loss = 0.255996
I0628 20:56:57.244577  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:56:57.244577  6212 solver.cpp:237]     Train net output #1: loss = 0.255996 (* 1 = 0.255996 loss)
I0628 20:56:57.244577  6212 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I0628 20:57:00.840353  6212 solver.cpp:218] Iteration 31900 (27.814 iter/s, 3.59531s/100 iters), loss = 0.180912
I0628 20:57:00.840353  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:57:00.840353  6212 solver.cpp:237]     Train net output #1: loss = 0.180912 (* 1 = 0.180912 loss)
I0628 20:57:00.840353  6212 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I0628 20:57:04.270408 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:57:04.414564  6212 solver.cpp:330] Iteration 32000, Testing net (#0)
I0628 20:57:04.414564  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:57:05.226122  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:57:05.257156  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8196
I0628 20:57:05.257156  6212 solver.cpp:397]     Test net output #1: loss = 0.577377 (* 1 = 0.577377 loss)
I0628 20:57:05.291174  6212 solver.cpp:218] Iteration 32000 (22.4681 iter/s, 4.45075s/100 iters), loss = 0.248453
I0628 20:57:05.291174  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:57:05.291174  6212 solver.cpp:237]     Train net output #1: loss = 0.248453 (* 1 = 0.248453 loss)
I0628 20:57:05.291174  6212 sgd_solver.cpp:46] MultiStep Status: Iteration 32000, step = 1
I0628 20:57:05.291174  6212 sgd_solver.cpp:105] Iteration 32000, lr = 0.001
I0628 20:57:08.922562  6212 solver.cpp:218] Iteration 32100 (27.5425 iter/s, 3.63075s/100 iters), loss = 0.210361
I0628 20:57:08.922562  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:57:08.922562  6212 solver.cpp:237]     Train net output #1: loss = 0.210361 (* 1 = 0.210361 loss)
I0628 20:57:08.922562  6212 sgd_solver.cpp:105] Iteration 32100, lr = 0.001
I0628 20:57:12.531185  6212 solver.cpp:218] Iteration 32200 (27.7139 iter/s, 3.6083s/100 iters), loss = 0.285416
I0628 20:57:12.531185  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:57:12.531185  6212 solver.cpp:237]     Train net output #1: loss = 0.285416 (* 1 = 0.285416 loss)
I0628 20:57:12.531185  6212 sgd_solver.cpp:105] Iteration 32200, lr = 0.001
I0628 20:57:16.121830  6212 solver.cpp:218] Iteration 32300 (27.8542 iter/s, 3.59013s/100 iters), loss = 0.246109
I0628 20:57:16.121830  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:57:16.121830  6212 solver.cpp:237]     Train net output #1: loss = 0.246109 (* 1 = 0.246109 loss)
I0628 20:57:16.121830  6212 sgd_solver.cpp:105] Iteration 32300, lr = 0.001
I0628 20:57:19.715685  6212 solver.cpp:218] Iteration 32400 (27.831 iter/s, 3.59312s/100 iters), loss = 0.12951
I0628 20:57:19.715685  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:57:19.715685  6212 solver.cpp:237]     Train net output #1: loss = 0.129511 (* 1 = 0.129511 loss)
I0628 20:57:19.715685  6212 sgd_solver.cpp:105] Iteration 32400, lr = 0.001
I0628 20:57:23.144269 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:57:23.285373  6212 solver.cpp:330] Iteration 32500, Testing net (#0)
I0628 20:57:23.285373  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:57:24.100980  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:57:24.131002  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8839
I0628 20:57:24.132004  6212 solver.cpp:397]     Test net output #1: loss = 0.347999 (* 1 = 0.347999 loss)
I0628 20:57:24.166028  6212 solver.cpp:218] Iteration 32500 (22.4718 iter/s, 4.45002s/100 iters), loss = 0.164638
I0628 20:57:24.166028  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:57:24.166028  6212 solver.cpp:237]     Train net output #1: loss = 0.164638 (* 1 = 0.164638 loss)
I0628 20:57:24.166028  6212 sgd_solver.cpp:105] Iteration 32500, lr = 0.001
I0628 20:57:27.771906  6212 solver.cpp:218] Iteration 32600 (27.7286 iter/s, 3.60639s/100 iters), loss = 0.166449
I0628 20:57:27.771906  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:57:27.771906  6212 solver.cpp:237]     Train net output #1: loss = 0.166449 (* 1 = 0.166449 loss)
I0628 20:57:27.771906  6212 sgd_solver.cpp:105] Iteration 32600, lr = 0.001
I0628 20:57:31.369717  6212 solver.cpp:218] Iteration 32700 (27.7975 iter/s, 3.59745s/100 iters), loss = 0.261647
I0628 20:57:31.369717  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:57:31.369717  6212 solver.cpp:237]     Train net output #1: loss = 0.261648 (* 1 = 0.261648 loss)
I0628 20:57:31.369717  6212 sgd_solver.cpp:105] Iteration 32700, lr = 0.001
I0628 20:57:34.975461  6212 solver.cpp:218] Iteration 32800 (27.739 iter/s, 3.60503s/100 iters), loss = 0.277509
I0628 20:57:34.975961  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:57:34.975961  6212 solver.cpp:237]     Train net output #1: loss = 0.277509 (* 1 = 0.277509 loss)
I0628 20:57:34.975961  6212 sgd_solver.cpp:105] Iteration 32800, lr = 0.001
I0628 20:57:38.582036  6212 solver.cpp:218] Iteration 32900 (27.7311 iter/s, 3.60606s/100 iters), loss = 0.179934
I0628 20:57:38.582036  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:57:38.582036  6212 solver.cpp:237]     Train net output #1: loss = 0.179934 (* 1 = 0.179934 loss)
I0628 20:57:38.582036  6212 sgd_solver.cpp:105] Iteration 32900, lr = 0.001
I0628 20:57:42.006569 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:57:42.147673  6212 solver.cpp:330] Iteration 33000, Testing net (#0)
I0628 20:57:42.147673  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:57:42.958951  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:57:42.990486  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8881
I0628 20:57:42.990486  6212 solver.cpp:397]     Test net output #1: loss = 0.34248 (* 1 = 0.34248 loss)
I0628 20:57:43.024511  6212 solver.cpp:218] Iteration 33000 (22.5127 iter/s, 4.44193s/100 iters), loss = 0.17255
I0628 20:57:43.024511  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:57:43.024511  6212 solver.cpp:237]     Train net output #1: loss = 0.17255 (* 1 = 0.17255 loss)
I0628 20:57:43.024511  6212 sgd_solver.cpp:105] Iteration 33000, lr = 0.001
I0628 20:57:46.624694  6212 solver.cpp:218] Iteration 33100 (27.7769 iter/s, 3.60011s/100 iters), loss = 0.226956
I0628 20:57:46.624694  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:57:46.624694  6212 solver.cpp:237]     Train net output #1: loss = 0.226956 (* 1 = 0.226956 loss)
I0628 20:57:46.624694  6212 sgd_solver.cpp:105] Iteration 33100, lr = 0.001
I0628 20:57:50.225469  6212 solver.cpp:218] Iteration 33200 (27.7758 iter/s, 3.60025s/100 iters), loss = 0.259193
I0628 20:57:50.225469  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:57:50.225469  6212 solver.cpp:237]     Train net output #1: loss = 0.259193 (* 1 = 0.259193 loss)
I0628 20:57:50.225469  6212 sgd_solver.cpp:105] Iteration 33200, lr = 0.001
I0628 20:57:53.833977  6212 solver.cpp:218] Iteration 33300 (27.7142 iter/s, 3.60826s/100 iters), loss = 0.194509
I0628 20:57:53.833977  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:57:53.833977  6212 solver.cpp:237]     Train net output #1: loss = 0.194509 (* 1 = 0.194509 loss)
I0628 20:57:53.833977  6212 sgd_solver.cpp:105] Iteration 33300, lr = 0.001
I0628 20:57:57.442683  6212 solver.cpp:218] Iteration 33400 (27.7149 iter/s, 3.60817s/100 iters), loss = 0.185556
I0628 20:57:57.442683  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:57:57.442683  6212 solver.cpp:237]     Train net output #1: loss = 0.185556 (* 1 = 0.185556 loss)
I0628 20:57:57.442683  6212 sgd_solver.cpp:105] Iteration 33400, lr = 0.001
I0628 20:58:00.870270 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:58:01.011385  6212 solver.cpp:330] Iteration 33500, Testing net (#0)
I0628 20:58:01.011385  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:58:01.826958  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:58:01.857980  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8885
I0628 20:58:01.857980  6212 solver.cpp:397]     Test net output #1: loss = 0.339637 (* 1 = 0.339637 loss)
I0628 20:58:01.892505  6212 solver.cpp:218] Iteration 33500 (22.4734 iter/s, 4.4497s/100 iters), loss = 0.127793
I0628 20:58:01.892505  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:58:01.892505  6212 solver.cpp:237]     Train net output #1: loss = 0.127793 (* 1 = 0.127793 loss)
I0628 20:58:01.892505  6212 sgd_solver.cpp:105] Iteration 33500, lr = 0.001
I0628 20:58:05.496696  6212 solver.cpp:218] Iteration 33600 (27.7489 iter/s, 3.60375s/100 iters), loss = 0.19364
I0628 20:58:05.496696  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:58:05.496696  6212 solver.cpp:237]     Train net output #1: loss = 0.19364 (* 1 = 0.19364 loss)
I0628 20:58:05.496696  6212 sgd_solver.cpp:105] Iteration 33600, lr = 0.001
I0628 20:58:09.104893  6212 solver.cpp:218] Iteration 33700 (27.7185 iter/s, 3.6077s/100 iters), loss = 0.16159
I0628 20:58:09.104893  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:58:09.104893  6212 solver.cpp:237]     Train net output #1: loss = 0.16159 (* 1 = 0.16159 loss)
I0628 20:58:09.104893  6212 sgd_solver.cpp:105] Iteration 33700, lr = 0.001
I0628 20:58:12.706923  6212 solver.cpp:218] Iteration 33800 (27.7624 iter/s, 3.60199s/100 iters), loss = 0.179208
I0628 20:58:12.706923  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:58:12.706923  6212 solver.cpp:237]     Train net output #1: loss = 0.179208 (* 1 = 0.179208 loss)
I0628 20:58:12.706923  6212 sgd_solver.cpp:105] Iteration 33800, lr = 0.001
I0628 20:58:16.293421  6212 solver.cpp:218] Iteration 33900 (27.8865 iter/s, 3.58596s/100 iters), loss = 0.211282
I0628 20:58:16.293421  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:58:16.293421  6212 solver.cpp:237]     Train net output #1: loss = 0.211282 (* 1 = 0.211282 loss)
I0628 20:58:16.293421  6212 sgd_solver.cpp:105] Iteration 33900, lr = 0.001
I0628 20:58:19.714150 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:58:19.855300  6212 solver.cpp:330] Iteration 34000, Testing net (#0)
I0628 20:58:19.855300  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:58:20.675503  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:58:20.706037  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8865
I0628 20:58:20.706037  6212 solver.cpp:397]     Test net output #1: loss = 0.33881 (* 1 = 0.33881 loss)
I0628 20:58:20.739665  6212 solver.cpp:218] Iteration 34000 (22.4917 iter/s, 4.44609s/100 iters), loss = 0.127828
I0628 20:58:20.739665  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:58:20.739665  6212 solver.cpp:237]     Train net output #1: loss = 0.127828 (* 1 = 0.127828 loss)
I0628 20:58:20.739665  6212 sgd_solver.cpp:105] Iteration 34000, lr = 0.001
I0628 20:58:24.343905  6212 solver.cpp:218] Iteration 34100 (27.751 iter/s, 3.60348s/100 iters), loss = 0.132002
I0628 20:58:24.343905  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:58:24.343905  6212 solver.cpp:237]     Train net output #1: loss = 0.132003 (* 1 = 0.132003 loss)
I0628 20:58:24.343905  6212 sgd_solver.cpp:105] Iteration 34100, lr = 0.001
I0628 20:58:27.938102  6212 solver.cpp:218] Iteration 34200 (27.8253 iter/s, 3.59385s/100 iters), loss = 0.188138
I0628 20:58:27.938102  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:58:27.938102  6212 solver.cpp:237]     Train net output #1: loss = 0.188138 (* 1 = 0.188138 loss)
I0628 20:58:27.938102  6212 sgd_solver.cpp:105] Iteration 34200, lr = 0.001
I0628 20:58:31.530889  6212 solver.cpp:218] Iteration 34300 (27.8352 iter/s, 3.59257s/100 iters), loss = 0.152202
I0628 20:58:31.530889  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:58:31.530889  6212 solver.cpp:237]     Train net output #1: loss = 0.152202 (* 1 = 0.152202 loss)
I0628 20:58:31.530889  6212 sgd_solver.cpp:105] Iteration 34300, lr = 0.001
I0628 20:58:35.133571  6212 solver.cpp:218] Iteration 34400 (27.7587 iter/s, 3.60248s/100 iters), loss = 0.132865
I0628 20:58:35.133571  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:58:35.133571  6212 solver.cpp:237]     Train net output #1: loss = 0.132865 (* 1 = 0.132865 loss)
I0628 20:58:35.134071  6212 sgd_solver.cpp:105] Iteration 34400, lr = 0.001
I0628 20:58:38.557124 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:58:38.699234  6212 solver.cpp:330] Iteration 34500, Testing net (#0)
I0628 20:58:38.699234  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:58:39.511838  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:58:39.542863  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8909
I0628 20:58:39.542863  6212 solver.cpp:397]     Test net output #1: loss = 0.336371 (* 1 = 0.336371 loss)
I0628 20:58:39.576887  6212 solver.cpp:218] Iteration 34500 (22.5072 iter/s, 4.44302s/100 iters), loss = 0.154925
I0628 20:58:39.576887  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:58:39.576887  6212 solver.cpp:237]     Train net output #1: loss = 0.154926 (* 1 = 0.154926 loss)
I0628 20:58:39.576887  6212 sgd_solver.cpp:105] Iteration 34500, lr = 0.001
I0628 20:58:43.177649  6212 solver.cpp:218] Iteration 34600 (27.7734 iter/s, 3.60057s/100 iters), loss = 0.151515
I0628 20:58:43.177649  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:58:43.177649  6212 solver.cpp:237]     Train net output #1: loss = 0.151516 (* 1 = 0.151516 loss)
I0628 20:58:43.177649  6212 sgd_solver.cpp:105] Iteration 34600, lr = 0.001
I0628 20:58:46.772351  6212 solver.cpp:218] Iteration 34700 (27.82 iter/s, 3.59453s/100 iters), loss = 0.180037
I0628 20:58:46.772351  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:58:46.772351  6212 solver.cpp:237]     Train net output #1: loss = 0.180038 (* 1 = 0.180038 loss)
I0628 20:58:46.772351  6212 sgd_solver.cpp:105] Iteration 34700, lr = 0.001
I0628 20:58:50.366044  6212 solver.cpp:218] Iteration 34800 (27.8302 iter/s, 3.59323s/100 iters), loss = 0.172174
I0628 20:58:50.366044  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:58:50.366044  6212 solver.cpp:237]     Train net output #1: loss = 0.172174 (* 1 = 0.172174 loss)
I0628 20:58:50.366044  6212 sgd_solver.cpp:105] Iteration 34800, lr = 0.001
I0628 20:58:53.969871  6212 solver.cpp:218] Iteration 34900 (27.7496 iter/s, 3.60365s/100 iters), loss = 0.227849
I0628 20:58:53.969871  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:58:53.970872  6212 solver.cpp:237]     Train net output #1: loss = 0.227849 (* 1 = 0.227849 loss)
I0628 20:58:53.970872  6212 sgd_solver.cpp:105] Iteration 34900, lr = 0.001
I0628 20:58:57.396950 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:58:57.538553  6212 solver.cpp:330] Iteration 35000, Testing net (#0)
I0628 20:58:57.538553  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:58:58.350536  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:58:58.381059  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8903
I0628 20:58:58.381059  6212 solver.cpp:397]     Test net output #1: loss = 0.337265 (* 1 = 0.337265 loss)
I0628 20:58:58.415083  6212 solver.cpp:218] Iteration 35000 (22.5022 iter/s, 4.44401s/100 iters), loss = 0.165745
I0628 20:58:58.415083  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:58:58.415083  6212 solver.cpp:237]     Train net output #1: loss = 0.165746 (* 1 = 0.165746 loss)
I0628 20:58:58.415083  6212 sgd_solver.cpp:105] Iteration 35000, lr = 0.001
I0628 20:59:02.018784  6212 solver.cpp:218] Iteration 35100 (27.7455 iter/s, 3.60419s/100 iters), loss = 0.136762
I0628 20:59:02.018784  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:59:02.018784  6212 solver.cpp:237]     Train net output #1: loss = 0.136762 (* 1 = 0.136762 loss)
I0628 20:59:02.018784  6212 sgd_solver.cpp:105] Iteration 35100, lr = 0.001
I0628 20:59:05.632474  6212 solver.cpp:218] Iteration 35200 (27.6757 iter/s, 3.61327s/100 iters), loss = 0.141072
I0628 20:59:05.632474  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:59:05.632474  6212 solver.cpp:237]     Train net output #1: loss = 0.141072 (* 1 = 0.141072 loss)
I0628 20:59:05.632474  6212 sgd_solver.cpp:105] Iteration 35200, lr = 0.001
I0628 20:59:09.251996  6212 solver.cpp:218] Iteration 35300 (27.6358 iter/s, 3.6185s/100 iters), loss = 0.162798
I0628 20:59:09.251996  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:59:09.251996  6212 solver.cpp:237]     Train net output #1: loss = 0.162798 (* 1 = 0.162798 loss)
I0628 20:59:09.251996  6212 sgd_solver.cpp:105] Iteration 35300, lr = 0.001
I0628 20:59:12.854638  6212 solver.cpp:218] Iteration 35400 (27.7585 iter/s, 3.60249s/100 iters), loss = 0.119855
I0628 20:59:12.854638  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:59:12.854638  6212 solver.cpp:237]     Train net output #1: loss = 0.119855 (* 1 = 0.119855 loss)
I0628 20:59:12.854638  6212 sgd_solver.cpp:105] Iteration 35400, lr = 0.001
I0628 20:59:16.289206 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:59:16.436316  6212 solver.cpp:330] Iteration 35500, Testing net (#0)
I0628 20:59:16.436316  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:59:17.253928  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:59:17.284541  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8864
I0628 20:59:17.284541  6212 solver.cpp:397]     Test net output #1: loss = 0.343318 (* 1 = 0.343318 loss)
I0628 20:59:17.318565  6212 solver.cpp:218] Iteration 35500 (22.404 iter/s, 4.46349s/100 iters), loss = 0.0807093
I0628 20:59:17.318565  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:59:17.318565  6212 solver.cpp:237]     Train net output #1: loss = 0.0807095 (* 1 = 0.0807095 loss)
I0628 20:59:17.318565  6212 sgd_solver.cpp:105] Iteration 35500, lr = 0.001
I0628 20:59:20.919739  6212 solver.cpp:218] Iteration 35600 (27.7673 iter/s, 3.60136s/100 iters), loss = 0.12808
I0628 20:59:20.919739  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:59:20.919739  6212 solver.cpp:237]     Train net output #1: loss = 0.12808 (* 1 = 0.12808 loss)
I0628 20:59:20.919739  6212 sgd_solver.cpp:105] Iteration 35600, lr = 0.001
I0628 20:59:24.522645  6212 solver.cpp:218] Iteration 35700 (27.7619 iter/s, 3.60206s/100 iters), loss = 0.164679
I0628 20:59:24.522645  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:59:24.522645  6212 solver.cpp:237]     Train net output #1: loss = 0.164679 (* 1 = 0.164679 loss)
I0628 20:59:24.522645  6212 sgd_solver.cpp:105] Iteration 35700, lr = 0.001
I0628 20:59:28.123309  6212 solver.cpp:218] Iteration 35800 (27.7755 iter/s, 3.60029s/100 iters), loss = 0.196738
I0628 20:59:28.123309  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:59:28.123309  6212 solver.cpp:237]     Train net output #1: loss = 0.196738 (* 1 = 0.196738 loss)
I0628 20:59:28.123309  6212 sgd_solver.cpp:105] Iteration 35800, lr = 0.001
I0628 20:59:31.716825  6212 solver.cpp:218] Iteration 35900 (27.8314 iter/s, 3.59306s/100 iters), loss = 0.144628
I0628 20:59:31.716825  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:59:31.716825  6212 solver.cpp:237]     Train net output #1: loss = 0.144628 (* 1 = 0.144628 loss)
I0628 20:59:31.716825  6212 sgd_solver.cpp:105] Iteration 35900, lr = 0.001
I0628 20:59:35.384452 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:59:35.524555  6212 solver.cpp:330] Iteration 36000, Testing net (#0)
I0628 20:59:35.524555  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:59:36.350486  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:59:36.374011  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8878
I0628 20:59:36.374011  6212 solver.cpp:397]     Test net output #1: loss = 0.343377 (* 1 = 0.343377 loss)
I0628 20:59:36.408097  6212 solver.cpp:218] Iteration 36000 (21.3147 iter/s, 4.6916s/100 iters), loss = 0.161287
I0628 20:59:36.408097  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:59:36.408097  6212 solver.cpp:237]     Train net output #1: loss = 0.161287 (* 1 = 0.161287 loss)
I0628 20:59:36.408097  6212 sgd_solver.cpp:105] Iteration 36000, lr = 0.001
I0628 20:59:40.002643  6212 solver.cpp:218] Iteration 36100 (27.8232 iter/s, 3.59413s/100 iters), loss = 0.198978
I0628 20:59:40.002643  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:59:40.002643  6212 solver.cpp:237]     Train net output #1: loss = 0.198978 (* 1 = 0.198978 loss)
I0628 20:59:40.002643  6212 sgd_solver.cpp:105] Iteration 36100, lr = 0.001
I0628 20:59:43.602836  6212 solver.cpp:218] Iteration 36200 (27.7766 iter/s, 3.60015s/100 iters), loss = 0.111185
I0628 20:59:43.603826  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:59:43.603826  6212 solver.cpp:237]     Train net output #1: loss = 0.111185 (* 1 = 0.111185 loss)
I0628 20:59:43.603826  6212 sgd_solver.cpp:105] Iteration 36200, lr = 0.001
I0628 20:59:47.207258  6212 solver.cpp:218] Iteration 36300 (27.7527 iter/s, 3.60325s/100 iters), loss = 0.162153
I0628 20:59:47.207258  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:59:47.207258  6212 solver.cpp:237]     Train net output #1: loss = 0.162154 (* 1 = 0.162154 loss)
I0628 20:59:47.207258  6212 sgd_solver.cpp:105] Iteration 36300, lr = 0.001
I0628 20:59:50.809381  6212 solver.cpp:218] Iteration 36400 (27.7626 iter/s, 3.60197s/100 iters), loss = 0.139774
I0628 20:59:50.809381  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:59:50.809381  6212 solver.cpp:237]     Train net output #1: loss = 0.139774 (* 1 = 0.139774 loss)
I0628 20:59:50.809381  6212 sgd_solver.cpp:105] Iteration 36400, lr = 0.001
I0628 20:59:54.235237 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:59:54.376368  6212 solver.cpp:330] Iteration 36500, Testing net (#0)
I0628 20:59:54.376368  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:59:55.186704  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:59:55.216832  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8887
I0628 20:59:55.217823  6212 solver.cpp:397]     Test net output #1: loss = 0.344528 (* 1 = 0.344528 loss)
I0628 20:59:55.251863  6212 solver.cpp:218] Iteration 36500 (22.5119 iter/s, 4.44209s/100 iters), loss = 0.218029
I0628 20:59:55.251863  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:59:55.251863  6212 solver.cpp:237]     Train net output #1: loss = 0.218029 (* 1 = 0.218029 loss)
I0628 20:59:55.251863  6212 sgd_solver.cpp:105] Iteration 36500, lr = 0.001
I0628 20:59:58.845706  6212 solver.cpp:218] Iteration 36600 (27.8278 iter/s, 3.59353s/100 iters), loss = 0.18592
I0628 20:59:58.845706  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:59:58.845706  6212 solver.cpp:237]     Train net output #1: loss = 0.18592 (* 1 = 0.18592 loss)
I0628 20:59:58.845706  6212 sgd_solver.cpp:105] Iteration 36600, lr = 0.001
I0628 21:00:02.450814  6212 solver.cpp:218] Iteration 36700 (27.736 iter/s, 3.60542s/100 iters), loss = 0.120126
I0628 21:00:02.451803  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:00:02.451803  6212 solver.cpp:237]     Train net output #1: loss = 0.120127 (* 1 = 0.120127 loss)
I0628 21:00:02.451803  6212 sgd_solver.cpp:105] Iteration 36700, lr = 0.001
I0628 21:00:06.073436  6212 solver.cpp:218] Iteration 36800 (27.6069 iter/s, 3.62228s/100 iters), loss = 0.195671
I0628 21:00:06.074426  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:00:06.074426  6212 solver.cpp:237]     Train net output #1: loss = 0.195672 (* 1 = 0.195672 loss)
I0628 21:00:06.074426  6212 sgd_solver.cpp:105] Iteration 36800, lr = 0.001
I0628 21:00:09.725898  6212 solver.cpp:218] Iteration 36900 (27.3829 iter/s, 3.65192s/100 iters), loss = 0.146487
I0628 21:00:09.725898  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:00:09.725898  6212 solver.cpp:237]     Train net output #1: loss = 0.146488 (* 1 = 0.146488 loss)
I0628 21:00:09.725898  6212 sgd_solver.cpp:105] Iteration 36900, lr = 0.001
I0628 21:00:13.197396 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:00:13.346710  6212 solver.cpp:330] Iteration 37000, Testing net (#0)
I0628 21:00:13.347710  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:00:14.163875  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:00:14.194907  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8879
I0628 21:00:14.194907  6212 solver.cpp:397]     Test net output #1: loss = 0.347733 (* 1 = 0.347733 loss)
I0628 21:00:14.229938  6212 solver.cpp:218] Iteration 37000 (22.2075 iter/s, 4.50298s/100 iters), loss = 0.105277
I0628 21:00:14.229938  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:00:14.229938  6212 solver.cpp:237]     Train net output #1: loss = 0.105277 (* 1 = 0.105277 loss)
I0628 21:00:14.229938  6212 sgd_solver.cpp:105] Iteration 37000, lr = 0.001
I0628 21:00:17.852221  6212 solver.cpp:218] Iteration 37100 (27.6043 iter/s, 3.62263s/100 iters), loss = 0.155141
I0628 21:00:17.852221  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:00:17.852221  6212 solver.cpp:237]     Train net output #1: loss = 0.155142 (* 1 = 0.155142 loss)
I0628 21:00:17.852221  6212 sgd_solver.cpp:105] Iteration 37100, lr = 0.001
I0628 21:00:21.550014  6212 solver.cpp:218] Iteration 37200 (27.0488 iter/s, 3.69703s/100 iters), loss = 0.157349
I0628 21:00:21.550014  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:00:21.550014  6212 solver.cpp:237]     Train net output #1: loss = 0.157349 (* 1 = 0.157349 loss)
I0628 21:00:21.550014  6212 sgd_solver.cpp:105] Iteration 37200, lr = 0.001
I0628 21:00:25.217409  6212 solver.cpp:218] Iteration 37300 (27.2707 iter/s, 3.66694s/100 iters), loss = 0.15835
I0628 21:00:25.217409  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:00:25.217409  6212 solver.cpp:237]     Train net output #1: loss = 0.158351 (* 1 = 0.158351 loss)
I0628 21:00:25.217409  6212 sgd_solver.cpp:105] Iteration 37300, lr = 0.001
I0628 21:00:28.843065  6212 solver.cpp:218] Iteration 37400 (27.5833 iter/s, 3.62538s/100 iters), loss = 0.111045
I0628 21:00:28.843065  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:00:28.843065  6212 solver.cpp:237]     Train net output #1: loss = 0.111045 (* 1 = 0.111045 loss)
I0628 21:00:28.843065  6212 sgd_solver.cpp:105] Iteration 37400, lr = 0.001
I0628 21:00:32.283620 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:00:32.426228  6212 solver.cpp:330] Iteration 37500, Testing net (#0)
I0628 21:00:32.427227  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:00:33.241677  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:00:33.272706  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8901
I0628 21:00:33.272706  6212 solver.cpp:397]     Test net output #1: loss = 0.3424 (* 1 = 0.3424 loss)
I0628 21:00:33.307732  6212 solver.cpp:218] Iteration 37500 (22.4003 iter/s, 4.46422s/100 iters), loss = 0.116797
I0628 21:00:33.307732  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:00:33.307732  6212 solver.cpp:237]     Train net output #1: loss = 0.116797 (* 1 = 0.116797 loss)
I0628 21:00:33.307732  6212 sgd_solver.cpp:105] Iteration 37500, lr = 0.001
I0628 21:00:36.975517  6212 solver.cpp:218] Iteration 37600 (27.2624 iter/s, 3.66805s/100 iters), loss = 0.142352
I0628 21:00:36.975517  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:00:36.975517  6212 solver.cpp:237]     Train net output #1: loss = 0.142352 (* 1 = 0.142352 loss)
I0628 21:00:36.975517  6212 sgd_solver.cpp:105] Iteration 37600, lr = 0.001
I0628 21:00:40.591935  6212 solver.cpp:218] Iteration 37700 (27.6589 iter/s, 3.61547s/100 iters), loss = 0.147111
I0628 21:00:40.591935  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:00:40.591935  6212 solver.cpp:237]     Train net output #1: loss = 0.147111 (* 1 = 0.147111 loss)
I0628 21:00:40.591935  6212 sgd_solver.cpp:105] Iteration 37700, lr = 0.001
I0628 21:00:44.194422  6212 solver.cpp:218] Iteration 37800 (27.7627 iter/s, 3.60195s/100 iters), loss = 0.185104
I0628 21:00:44.194422  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:00:44.194422  6212 solver.cpp:237]     Train net output #1: loss = 0.185104 (* 1 = 0.185104 loss)
I0628 21:00:44.194422  6212 sgd_solver.cpp:105] Iteration 37800, lr = 0.001
I0628 21:00:47.817132  6212 solver.cpp:218] Iteration 37900 (27.5997 iter/s, 3.62323s/100 iters), loss = 0.115024
I0628 21:00:47.817132  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:00:47.817132  6212 solver.cpp:237]     Train net output #1: loss = 0.115024 (* 1 = 0.115024 loss)
I0628 21:00:47.817132  6212 sgd_solver.cpp:105] Iteration 37900, lr = 0.001
I0628 21:00:51.248739 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:00:51.390844  6212 solver.cpp:330] Iteration 38000, Testing net (#0)
I0628 21:00:51.390844  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:00:52.204965  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:00:52.235488  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8881
I0628 21:00:52.235488  6212 solver.cpp:397]     Test net output #1: loss = 0.349513 (* 1 = 0.349513 loss)
I0628 21:00:52.269512  6212 solver.cpp:218] Iteration 38000 (22.4642 iter/s, 4.45152s/100 iters), loss = 0.165594
I0628 21:00:52.269512  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:00:52.269512  6212 solver.cpp:237]     Train net output #1: loss = 0.165594 (* 1 = 0.165594 loss)
I0628 21:00:52.269512  6212 sgd_solver.cpp:105] Iteration 38000, lr = 0.001
I0628 21:00:55.883236  6212 solver.cpp:218] Iteration 38100 (27.6747 iter/s, 3.61341s/100 iters), loss = 0.132942
I0628 21:00:55.883236  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:00:55.883236  6212 solver.cpp:237]     Train net output #1: loss = 0.132943 (* 1 = 0.132943 loss)
I0628 21:00:55.883236  6212 sgd_solver.cpp:105] Iteration 38100, lr = 0.001
I0628 21:00:59.485882  6212 solver.cpp:218] Iteration 38200 (27.762 iter/s, 3.60205s/100 iters), loss = 0.146141
I0628 21:00:59.485882  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:00:59.485882  6212 solver.cpp:237]     Train net output #1: loss = 0.146141 (* 1 = 0.146141 loss)
I0628 21:00:59.485882  6212 sgd_solver.cpp:105] Iteration 38200, lr = 0.001
I0628 21:01:03.097750  6212 solver.cpp:218] Iteration 38300 (27.6857 iter/s, 3.61197s/100 iters), loss = 0.197437
I0628 21:01:03.097750  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 21:01:03.097750  6212 solver.cpp:237]     Train net output #1: loss = 0.197438 (* 1 = 0.197438 loss)
I0628 21:01:03.097750  6212 sgd_solver.cpp:105] Iteration 38300, lr = 0.001
I0628 21:01:06.713954  6212 solver.cpp:218] Iteration 38400 (27.6593 iter/s, 3.61543s/100 iters), loss = 0.112406
I0628 21:01:06.713954  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:01:06.713954  6212 solver.cpp:237]     Train net output #1: loss = 0.112406 (* 1 = 0.112406 loss)
I0628 21:01:06.713954  6212 sgd_solver.cpp:105] Iteration 38400, lr = 0.001
I0628 21:01:10.159175 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:01:10.305284  6212 solver.cpp:330] Iteration 38500, Testing net (#0)
I0628 21:01:10.305284  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:01:11.125326  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:01:11.155858  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8874
I0628 21:01:11.155858  6212 solver.cpp:397]     Test net output #1: loss = 0.348511 (* 1 = 0.348511 loss)
I0628 21:01:11.190873  6212 solver.cpp:218] Iteration 38500 (22.3393 iter/s, 4.47641s/100 iters), loss = 0.128913
I0628 21:01:11.190873  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:01:11.190873  6212 solver.cpp:237]     Train net output #1: loss = 0.128913 (* 1 = 0.128913 loss)
I0628 21:01:11.190873  6212 sgd_solver.cpp:105] Iteration 38500, lr = 0.001
I0628 21:01:14.824589  6212 solver.cpp:218] Iteration 38600 (27.5205 iter/s, 3.63366s/100 iters), loss = 0.132293
I0628 21:01:14.824589  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:01:14.824589  6212 solver.cpp:237]     Train net output #1: loss = 0.132293 (* 1 = 0.132293 loss)
I0628 21:01:14.824589  6212 sgd_solver.cpp:105] Iteration 38600, lr = 0.001
I0628 21:01:18.616674  6212 solver.cpp:218] Iteration 38700 (26.3737 iter/s, 3.79165s/100 iters), loss = 0.193758
I0628 21:01:18.616674  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:01:18.616674  6212 solver.cpp:237]     Train net output #1: loss = 0.193758 (* 1 = 0.193758 loss)
I0628 21:01:18.616674  6212 sgd_solver.cpp:105] Iteration 38700, lr = 0.001
I0628 21:01:22.631737  6212 solver.cpp:218] Iteration 38800 (24.9072 iter/s, 4.01491s/100 iters), loss = 0.133042
I0628 21:01:22.632238  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:01:22.632238  6212 solver.cpp:237]     Train net output #1: loss = 0.133042 (* 1 = 0.133042 loss)
I0628 21:01:22.632238  6212 sgd_solver.cpp:105] Iteration 38800, lr = 0.001
I0628 21:01:26.267427  6212 solver.cpp:218] Iteration 38900 (27.5069 iter/s, 3.63545s/100 iters), loss = 0.124134
I0628 21:01:26.267427  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:01:26.267427  6212 solver.cpp:237]     Train net output #1: loss = 0.124134 (* 1 = 0.124134 loss)
I0628 21:01:26.267427  6212 sgd_solver.cpp:105] Iteration 38900, lr = 0.001
I0628 21:01:29.801800 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:01:29.947913  6212 solver.cpp:330] Iteration 39000, Testing net (#0)
I0628 21:01:29.947913  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:01:30.779575  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:01:30.811599  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8897
I0628 21:01:30.811599  6212 solver.cpp:397]     Test net output #1: loss = 0.34678 (* 1 = 0.34678 loss)
I0628 21:01:30.846627  6212 solver.cpp:218] Iteration 39000 (21.8416 iter/s, 4.57842s/100 iters), loss = 0.172668
I0628 21:01:30.846627  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:01:30.846627  6212 solver.cpp:237]     Train net output #1: loss = 0.172668 (* 1 = 0.172668 loss)
I0628 21:01:30.846627  6212 sgd_solver.cpp:105] Iteration 39000, lr = 0.001
I0628 21:01:34.592540  6212 solver.cpp:218] Iteration 39100 (26.6963 iter/s, 3.74584s/100 iters), loss = 0.108745
I0628 21:01:34.592540  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:01:34.592540  6212 solver.cpp:237]     Train net output #1: loss = 0.108745 (* 1 = 0.108745 loss)
I0628 21:01:34.592540  6212 sgd_solver.cpp:105] Iteration 39100, lr = 0.001
I0628 21:01:38.630714  6212 solver.cpp:218] Iteration 39200 (24.7637 iter/s, 4.03817s/100 iters), loss = 0.179239
I0628 21:01:38.631716  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:01:38.631716  6212 solver.cpp:237]     Train net output #1: loss = 0.179239 (* 1 = 0.179239 loss)
I0628 21:01:38.631716  6212 sgd_solver.cpp:105] Iteration 39200, lr = 0.001
I0628 21:01:42.347228  6212 solver.cpp:218] Iteration 39300 (26.9134 iter/s, 3.71562s/100 iters), loss = 0.143968
I0628 21:01:42.347228  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:01:42.347228  6212 solver.cpp:237]     Train net output #1: loss = 0.143968 (* 1 = 0.143968 loss)
I0628 21:01:42.347228  6212 sgd_solver.cpp:105] Iteration 39300, lr = 0.001
I0628 21:01:46.015503  6212 solver.cpp:218] Iteration 39400 (27.2617 iter/s, 3.66815s/100 iters), loss = 0.132204
I0628 21:01:46.015503  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:01:46.015503  6212 solver.cpp:237]     Train net output #1: loss = 0.132204 (* 1 = 0.132204 loss)
I0628 21:01:46.015503  6212 sgd_solver.cpp:105] Iteration 39400, lr = 0.001
I0628 21:01:49.519609 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:01:49.663216  6212 solver.cpp:330] Iteration 39500, Testing net (#0)
I0628 21:01:49.663216  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:01:50.476759  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:01:50.507783  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8845
I0628 21:01:50.507783  6212 solver.cpp:397]     Test net output #1: loss = 0.3522 (* 1 = 0.3522 loss)
I0628 21:01:50.541332  6212 solver.cpp:218] Iteration 39500 (22.097 iter/s, 4.52551s/100 iters), loss = 0.144644
I0628 21:01:50.541332  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:01:50.541332  6212 solver.cpp:237]     Train net output #1: loss = 0.144644 (* 1 = 0.144644 loss)
I0628 21:01:50.541332  6212 sgd_solver.cpp:105] Iteration 39500, lr = 0.001
I0628 21:01:54.237361  6212 solver.cpp:218] Iteration 39600 (27.0632 iter/s, 3.69506s/100 iters), loss = 0.101255
I0628 21:01:54.237361  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:01:54.237361  6212 solver.cpp:237]     Train net output #1: loss = 0.101255 (* 1 = 0.101255 loss)
I0628 21:01:54.237361  6212 sgd_solver.cpp:105] Iteration 39600, lr = 0.001
I0628 21:01:57.962852  6212 solver.cpp:218] Iteration 39700 (26.845 iter/s, 3.72509s/100 iters), loss = 0.169677
I0628 21:01:57.962852  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:01:57.962852  6212 solver.cpp:237]     Train net output #1: loss = 0.169677 (* 1 = 0.169677 loss)
I0628 21:01:57.962852  6212 sgd_solver.cpp:105] Iteration 39700, lr = 0.001
I0628 21:02:01.628237  6212 solver.cpp:218] Iteration 39800 (27.2837 iter/s, 3.66519s/100 iters), loss = 0.172731
I0628 21:02:01.628237  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:02:01.628237  6212 solver.cpp:237]     Train net output #1: loss = 0.172731 (* 1 = 0.172731 loss)
I0628 21:02:01.628237  6212 sgd_solver.cpp:105] Iteration 39800, lr = 0.001
I0628 21:02:05.329728  6212 solver.cpp:218] Iteration 39900 (27.0195 iter/s, 3.70103s/100 iters), loss = 0.158297
I0628 21:02:05.329728  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:02:05.329728  6212 solver.cpp:237]     Train net output #1: loss = 0.158297 (* 1 = 0.158297 loss)
I0628 21:02:05.329728  6212 sgd_solver.cpp:105] Iteration 39900, lr = 0.001
I0628 21:02:08.831475 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:02:08.975605  6212 solver.cpp:330] Iteration 40000, Testing net (#0)
I0628 21:02:08.975605  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:02:09.794492  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:02:09.826016  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8844
I0628 21:02:09.826016  6212 solver.cpp:397]     Test net output #1: loss = 0.357468 (* 1 = 0.357468 loss)
I0628 21:02:09.860198  6212 solver.cpp:218] Iteration 40000 (22.0742 iter/s, 4.53017s/100 iters), loss = 0.132002
I0628 21:02:09.860198  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:02:09.860198  6212 solver.cpp:237]     Train net output #1: loss = 0.132003 (* 1 = 0.132003 loss)
I0628 21:02:09.860198  6212 sgd_solver.cpp:105] Iteration 40000, lr = 0.001
I0628 21:02:13.476382  6212 solver.cpp:218] Iteration 40100 (27.6529 iter/s, 3.61626s/100 iters), loss = 0.174012
I0628 21:02:13.476382  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:02:13.476382  6212 solver.cpp:237]     Train net output #1: loss = 0.174012 (* 1 = 0.174012 loss)
I0628 21:02:13.476382  6212 sgd_solver.cpp:105] Iteration 40100, lr = 0.001
I0628 21:02:17.093636  6212 solver.cpp:218] Iteration 40200 (27.6527 iter/s, 3.61628s/100 iters), loss = 0.141189
I0628 21:02:17.093636  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:02:17.093636  6212 solver.cpp:237]     Train net output #1: loss = 0.141189 (* 1 = 0.141189 loss)
I0628 21:02:17.093636  6212 sgd_solver.cpp:105] Iteration 40200, lr = 0.001
I0628 21:02:20.728317  6212 solver.cpp:218] Iteration 40300 (27.5112 iter/s, 3.63488s/100 iters), loss = 0.149027
I0628 21:02:20.728317  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:02:20.728317  6212 solver.cpp:237]     Train net output #1: loss = 0.149027 (* 1 = 0.149027 loss)
I0628 21:02:20.728317  6212 sgd_solver.cpp:105] Iteration 40300, lr = 0.001
I0628 21:02:24.369027  6212 solver.cpp:218] Iteration 40400 (27.4676 iter/s, 3.64066s/100 iters), loss = 0.14633
I0628 21:02:24.370028  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:02:24.370028  6212 solver.cpp:237]     Train net output #1: loss = 0.146331 (* 1 = 0.146331 loss)
I0628 21:02:24.370028  6212 sgd_solver.cpp:105] Iteration 40400, lr = 0.001
I0628 21:02:27.841163 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:02:27.981767  6212 solver.cpp:330] Iteration 40500, Testing net (#0)
I0628 21:02:27.981767  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:02:28.797468  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:02:28.828491  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8869
I0628 21:02:28.828491  6212 solver.cpp:397]     Test net output #1: loss = 0.351166 (* 1 = 0.351166 loss)
I0628 21:02:28.862517  6212 solver.cpp:218] Iteration 40500 (22.2585 iter/s, 4.49267s/100 iters), loss = 0.150378
I0628 21:02:28.862517  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:02:28.862517  6212 solver.cpp:237]     Train net output #1: loss = 0.150378 (* 1 = 0.150378 loss)
I0628 21:02:28.862517  6212 sgd_solver.cpp:105] Iteration 40500, lr = 0.001
I0628 21:02:32.489251  6212 solver.cpp:218] Iteration 40600 (27.5725 iter/s, 3.6268s/100 iters), loss = 0.165959
I0628 21:02:32.490252  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:02:32.490252  6212 solver.cpp:237]     Train net output #1: loss = 0.165959 (* 1 = 0.165959 loss)
I0628 21:02:32.490252  6212 sgd_solver.cpp:105] Iteration 40600, lr = 0.001
I0628 21:02:36.120172  6212 solver.cpp:218] Iteration 40700 (27.5477 iter/s, 3.63007s/100 iters), loss = 0.126313
I0628 21:02:36.120172  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:02:36.120172  6212 solver.cpp:237]     Train net output #1: loss = 0.126313 (* 1 = 0.126313 loss)
I0628 21:02:36.120172  6212 sgd_solver.cpp:105] Iteration 40700, lr = 0.001
I0628 21:02:39.753939  6212 solver.cpp:218] Iteration 40800 (27.5238 iter/s, 3.63322s/100 iters), loss = 0.116284
I0628 21:02:39.753939  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:02:39.753939  6212 solver.cpp:237]     Train net output #1: loss = 0.116284 (* 1 = 0.116284 loss)
I0628 21:02:39.753939  6212 sgd_solver.cpp:105] Iteration 40800, lr = 0.001
I0628 21:02:43.388707  6212 solver.cpp:218] Iteration 40900 (27.5126 iter/s, 3.6347s/100 iters), loss = 0.136672
I0628 21:02:43.388707  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:02:43.388707  6212 solver.cpp:237]     Train net output #1: loss = 0.136672 (* 1 = 0.136672 loss)
I0628 21:02:43.388707  6212 sgd_solver.cpp:105] Iteration 40900, lr = 0.001
I0628 21:02:46.832520 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:02:46.975518  6212 solver.cpp:330] Iteration 41000, Testing net (#0)
I0628 21:02:46.975518  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:02:47.797139  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:02:47.828161  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8864
I0628 21:02:47.828161  6212 solver.cpp:397]     Test net output #1: loss = 0.353279 (* 1 = 0.353279 loss)
I0628 21:02:47.862687  6212 solver.cpp:218] Iteration 41000 (22.3537 iter/s, 4.47353s/100 iters), loss = 0.0994425
I0628 21:02:47.862687  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:02:47.862687  6212 solver.cpp:237]     Train net output #1: loss = 0.0994426 (* 1 = 0.0994426 loss)
I0628 21:02:47.862687  6212 sgd_solver.cpp:105] Iteration 41000, lr = 0.001
I0628 21:02:51.499908  6212 solver.cpp:218] Iteration 41100 (27.4982 iter/s, 3.6366s/100 iters), loss = 0.122734
I0628 21:02:51.499908  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:02:51.499908  6212 solver.cpp:237]     Train net output #1: loss = 0.122734 (* 1 = 0.122734 loss)
I0628 21:02:51.499908  6212 sgd_solver.cpp:105] Iteration 41100, lr = 0.001
I0628 21:02:55.134618  6212 solver.cpp:218] Iteration 41200 (27.5093 iter/s, 3.63514s/100 iters), loss = 0.127268
I0628 21:02:55.134618  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:02:55.134618  6212 solver.cpp:237]     Train net output #1: loss = 0.127268 (* 1 = 0.127268 loss)
I0628 21:02:55.134618  6212 sgd_solver.cpp:105] Iteration 41200, lr = 0.001
I0628 21:02:58.773452  6212 solver.cpp:218] Iteration 41300 (27.4882 iter/s, 3.63793s/100 iters), loss = 0.21312
I0628 21:02:58.773452  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:02:58.773452  6212 solver.cpp:237]     Train net output #1: loss = 0.21312 (* 1 = 0.21312 loss)
I0628 21:02:58.773452  6212 sgd_solver.cpp:105] Iteration 41300, lr = 0.001
I0628 21:03:02.389971  6212 solver.cpp:218] Iteration 41400 (27.649 iter/s, 3.61677s/100 iters), loss = 0.177743
I0628 21:03:02.390971  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:03:02.390971  6212 solver.cpp:237]     Train net output #1: loss = 0.177743 (* 1 = 0.177743 loss)
I0628 21:03:02.390971  6212 sgd_solver.cpp:105] Iteration 41400, lr = 0.001
I0628 21:03:05.843437 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:03:05.985543  6212 solver.cpp:330] Iteration 41500, Testing net (#0)
I0628 21:03:05.985543  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:03:06.814664  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:03:06.837183  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8895
I0628 21:03:06.837183  6212 solver.cpp:397]     Test net output #1: loss = 0.35105 (* 1 = 0.35105 loss)
I0628 21:03:06.870708  6212 solver.cpp:218] Iteration 41500 (22.3211 iter/s, 4.48006s/100 iters), loss = 0.178041
I0628 21:03:06.870708  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:03:06.870708  6212 solver.cpp:237]     Train net output #1: loss = 0.178041 (* 1 = 0.178041 loss)
I0628 21:03:06.870708  6212 sgd_solver.cpp:105] Iteration 41500, lr = 0.001
I0628 21:03:10.498291  6212 solver.cpp:218] Iteration 41600 (27.5709 iter/s, 3.62701s/100 iters), loss = 0.184471
I0628 21:03:10.498291  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:03:10.498291  6212 solver.cpp:237]     Train net output #1: loss = 0.184472 (* 1 = 0.184472 loss)
I0628 21:03:10.498291  6212 sgd_solver.cpp:105] Iteration 41600, lr = 0.001
I0628 21:03:14.143028  6212 solver.cpp:218] Iteration 41700 (27.4425 iter/s, 3.64399s/100 iters), loss = 0.166248
I0628 21:03:14.143028  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:03:14.143028  6212 solver.cpp:237]     Train net output #1: loss = 0.166248 (* 1 = 0.166248 loss)
I0628 21:03:14.143028  6212 sgd_solver.cpp:105] Iteration 41700, lr = 0.001
I0628 21:03:17.809767  6212 solver.cpp:218] Iteration 41800 (27.2696 iter/s, 3.66709s/100 iters), loss = 0.13504
I0628 21:03:17.809767  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:03:17.809767  6212 solver.cpp:237]     Train net output #1: loss = 0.13504 (* 1 = 0.13504 loss)
I0628 21:03:17.809767  6212 sgd_solver.cpp:105] Iteration 41800, lr = 0.001
I0628 21:03:21.498056  6212 solver.cpp:218] Iteration 41900 (27.1177 iter/s, 3.68762s/100 iters), loss = 0.102537
I0628 21:03:21.498056  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:03:21.498056  6212 solver.cpp:237]     Train net output #1: loss = 0.102537 (* 1 = 0.102537 loss)
I0628 21:03:21.498056  6212 sgd_solver.cpp:105] Iteration 41900, lr = 0.001
I0628 21:03:25.109508 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:03:25.257642  6212 solver.cpp:330] Iteration 42000, Testing net (#0)
I0628 21:03:25.257642  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:03:26.104250  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:03:26.136262  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8881
I0628 21:03:26.136262  6212 solver.cpp:397]     Test net output #1: loss = 0.354979 (* 1 = 0.354979 loss)
I0628 21:03:26.172300  6212 solver.cpp:218] Iteration 42000 (21.3986 iter/s, 4.6732s/100 iters), loss = 0.17592
I0628 21:03:26.172300  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:03:26.172300  6212 solver.cpp:237]     Train net output #1: loss = 0.17592 (* 1 = 0.17592 loss)
I0628 21:03:26.172300  6212 sgd_solver.cpp:105] Iteration 42000, lr = 0.001
I0628 21:03:29.957803  6212 solver.cpp:218] Iteration 42100 (26.418 iter/s, 3.7853s/100 iters), loss = 0.164331
I0628 21:03:29.957803  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:03:29.957803  6212 solver.cpp:237]     Train net output #1: loss = 0.164331 (* 1 = 0.164331 loss)
I0628 21:03:29.957803  6212 sgd_solver.cpp:105] Iteration 42100, lr = 0.001
I0628 21:03:33.786480  6212 solver.cpp:218] Iteration 42200 (26.1252 iter/s, 3.82772s/100 iters), loss = 0.165823
I0628 21:03:33.786480  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:03:33.786480  6212 solver.cpp:237]     Train net output #1: loss = 0.165823 (* 1 = 0.165823 loss)
I0628 21:03:33.786480  6212 sgd_solver.cpp:105] Iteration 42200, lr = 0.001
I0628 21:03:37.573891  6212 solver.cpp:218] Iteration 42300 (26.4048 iter/s, 3.78719s/100 iters), loss = 0.153457
I0628 21:03:37.573891  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:03:37.573891  6212 solver.cpp:237]     Train net output #1: loss = 0.153458 (* 1 = 0.153458 loss)
I0628 21:03:37.573891  6212 sgd_solver.cpp:105] Iteration 42300, lr = 0.001
I0628 21:03:41.338634  6212 solver.cpp:218] Iteration 42400 (26.5649 iter/s, 3.76437s/100 iters), loss = 0.155972
I0628 21:03:41.338634  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:03:41.338634  6212 solver.cpp:237]     Train net output #1: loss = 0.155972 (* 1 = 0.155972 loss)
I0628 21:03:41.338634  6212 sgd_solver.cpp:105] Iteration 42400, lr = 0.001
I0628 21:03:44.898563 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:03:45.047404  6212 solver.cpp:330] Iteration 42500, Testing net (#0)
I0628 21:03:45.047404  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:03:45.881775  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:03:45.912818  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8888
I0628 21:03:45.912818  6212 solver.cpp:397]     Test net output #1: loss = 0.360374 (* 1 = 0.360374 loss)
I0628 21:03:45.946861  6212 solver.cpp:218] Iteration 42500 (21.7001 iter/s, 4.60826s/100 iters), loss = 0.152913
I0628 21:03:45.946861  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:03:45.946861  6212 solver.cpp:237]     Train net output #1: loss = 0.152913 (* 1 = 0.152913 loss)
I0628 21:03:45.946861  6212 sgd_solver.cpp:105] Iteration 42500, lr = 0.001
I0628 21:03:49.710914  6212 solver.cpp:218] Iteration 42600 (26.5724 iter/s, 3.76331s/100 iters), loss = 0.15568
I0628 21:03:49.710914  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:03:49.710914  6212 solver.cpp:237]     Train net output #1: loss = 0.15568 (* 1 = 0.15568 loss)
I0628 21:03:49.710914  6212 sgd_solver.cpp:105] Iteration 42600, lr = 0.001
I0628 21:03:53.362586  6212 solver.cpp:218] Iteration 42700 (27.3884 iter/s, 3.65118s/100 iters), loss = 0.194183
I0628 21:03:53.362586  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:03:53.362586  6212 solver.cpp:237]     Train net output #1: loss = 0.194183 (* 1 = 0.194183 loss)
I0628 21:03:53.362586  6212 sgd_solver.cpp:105] Iteration 42700, lr = 0.001
I0628 21:03:57.027405  6212 solver.cpp:218] Iteration 42800 (27.2886 iter/s, 3.66453s/100 iters), loss = 0.149723
I0628 21:03:57.027405  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:03:57.027405  6212 solver.cpp:237]     Train net output #1: loss = 0.149723 (* 1 = 0.149723 loss)
I0628 21:03:57.027405  6212 sgd_solver.cpp:105] Iteration 42800, lr = 0.001
I0628 21:04:00.656432  6212 solver.cpp:218] Iteration 42900 (27.5574 iter/s, 3.62879s/100 iters), loss = 0.0873045
I0628 21:04:00.656432  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:04:00.656432  6212 solver.cpp:237]     Train net output #1: loss = 0.0873046 (* 1 = 0.0873046 loss)
I0628 21:04:00.656432  6212 sgd_solver.cpp:105] Iteration 42900, lr = 0.001
I0628 21:04:04.121831 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:04:04.266083  6212 solver.cpp:330] Iteration 43000, Testing net (#0)
I0628 21:04:04.266083  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:04:05.110620  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:04:05.141675  6212 solver.cpp:397]     Test net output #0: accuracy = 0.889
I0628 21:04:05.141675  6212 solver.cpp:397]     Test net output #1: loss = 0.359193 (* 1 = 0.359193 loss)
I0628 21:04:05.175699  6212 solver.cpp:218] Iteration 43000 (22.1291 iter/s, 4.51894s/100 iters), loss = 0.128118
I0628 21:04:05.175699  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:04:05.175699  6212 solver.cpp:237]     Train net output #1: loss = 0.128118 (* 1 = 0.128118 loss)
I0628 21:04:05.175699  6212 sgd_solver.cpp:105] Iteration 43000, lr = 0.001
I0628 21:04:08.830286  6212 solver.cpp:218] Iteration 43100 (27.3638 iter/s, 3.65447s/100 iters), loss = 0.151288
I0628 21:04:08.830286  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:04:08.830286  6212 solver.cpp:237]     Train net output #1: loss = 0.151288 (* 1 = 0.151288 loss)
I0628 21:04:08.830286  6212 sgd_solver.cpp:105] Iteration 43100, lr = 0.001
I0628 21:04:12.469755  6212 solver.cpp:218] Iteration 43200 (27.4818 iter/s, 3.63877s/100 iters), loss = 0.139618
I0628 21:04:12.469755  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:04:12.470255  6212 solver.cpp:237]     Train net output #1: loss = 0.139619 (* 1 = 0.139619 loss)
I0628 21:04:12.470255  6212 sgd_solver.cpp:105] Iteration 43200, lr = 0.001
I0628 21:04:16.223464  6212 solver.cpp:218] Iteration 43300 (26.644 iter/s, 3.7532s/100 iters), loss = 0.182795
I0628 21:04:16.223464  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:04:16.223464  6212 solver.cpp:237]     Train net output #1: loss = 0.182795 (* 1 = 0.182795 loss)
I0628 21:04:16.223464  6212 sgd_solver.cpp:105] Iteration 43300, lr = 0.001
I0628 21:04:19.970242  6212 solver.cpp:218] Iteration 43400 (26.6921 iter/s, 3.74642s/100 iters), loss = 0.096504
I0628 21:04:19.970242  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:04:19.970242  6212 solver.cpp:237]     Train net output #1: loss = 0.0965041 (* 1 = 0.0965041 loss)
I0628 21:04:19.970242  6212 sgd_solver.cpp:105] Iteration 43400, lr = 0.001
I0628 21:04:23.525032 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:04:23.671140  6212 solver.cpp:330] Iteration 43500, Testing net (#0)
I0628 21:04:23.671140  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:04:24.504489  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:04:24.537521  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8877
I0628 21:04:24.537521  6212 solver.cpp:397]     Test net output #1: loss = 0.355373 (* 1 = 0.355373 loss)
I0628 21:04:24.572544  6212 solver.cpp:218] Iteration 43500 (21.7296 iter/s, 4.60202s/100 iters), loss = 0.141922
I0628 21:04:24.572544  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:04:24.572544  6212 solver.cpp:237]     Train net output #1: loss = 0.141922 (* 1 = 0.141922 loss)
I0628 21:04:24.572544  6212 sgd_solver.cpp:105] Iteration 43500, lr = 0.001
I0628 21:04:28.260846  6212 solver.cpp:218] Iteration 43600 (27.1151 iter/s, 3.68799s/100 iters), loss = 0.163475
I0628 21:04:28.260846  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:04:28.260846  6212 solver.cpp:237]     Train net output #1: loss = 0.163475 (* 1 = 0.163475 loss)
I0628 21:04:28.260846  6212 sgd_solver.cpp:105] Iteration 43600, lr = 0.001
I0628 21:04:31.928534  6212 solver.cpp:218] Iteration 43700 (27.2653 iter/s, 3.66767s/100 iters), loss = 0.179152
I0628 21:04:31.928534  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:04:31.928534  6212 solver.cpp:237]     Train net output #1: loss = 0.179152 (* 1 = 0.179152 loss)
I0628 21:04:31.928534  6212 sgd_solver.cpp:105] Iteration 43700, lr = 0.001
I0628 21:04:35.599807  6212 solver.cpp:218] Iteration 43800 (27.2454 iter/s, 3.67035s/100 iters), loss = 0.160416
I0628 21:04:35.599807  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:04:35.599807  6212 solver.cpp:237]     Train net output #1: loss = 0.160416 (* 1 = 0.160416 loss)
I0628 21:04:35.599807  6212 sgd_solver.cpp:105] Iteration 43800, lr = 0.001
I0628 21:04:39.262966  6212 solver.cpp:218] Iteration 43900 (27.2993 iter/s, 3.6631s/100 iters), loss = 0.178771
I0628 21:04:39.262966  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:04:39.262966  6212 solver.cpp:237]     Train net output #1: loss = 0.178771 (* 1 = 0.178771 loss)
I0628 21:04:39.262966  6212 sgd_solver.cpp:105] Iteration 43900, lr = 0.001
I0628 21:04:42.742621 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:04:42.885382  6212 solver.cpp:330] Iteration 44000, Testing net (#0)
I0628 21:04:42.885382  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:04:43.715484  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:04:43.738518  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8893
I0628 21:04:43.738518  6212 solver.cpp:397]     Test net output #1: loss = 0.354918 (* 1 = 0.354918 loss)
I0628 21:04:43.772536  6212 solver.cpp:218] Iteration 44000 (22.1765 iter/s, 4.50928s/100 iters), loss = 0.0978675
I0628 21:04:43.772536  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:04:43.772536  6212 solver.cpp:237]     Train net output #1: loss = 0.0978676 (* 1 = 0.0978676 loss)
I0628 21:04:43.772536  6212 sgd_solver.cpp:105] Iteration 44000, lr = 0.001
I0628 21:04:47.434829  6212 solver.cpp:218] Iteration 44100 (27.3127 iter/s, 3.66131s/100 iters), loss = 0.165642
I0628 21:04:47.434829  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:04:47.434829  6212 solver.cpp:237]     Train net output #1: loss = 0.165642 (* 1 = 0.165642 loss)
I0628 21:04:47.434829  6212 sgd_solver.cpp:105] Iteration 44100, lr = 0.001
I0628 21:04:51.098110  6212 solver.cpp:218] Iteration 44200 (27.2959 iter/s, 3.66355s/100 iters), loss = 0.106319
I0628 21:04:51.098110  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:04:51.098110  6212 solver.cpp:237]     Train net output #1: loss = 0.106319 (* 1 = 0.106319 loss)
I0628 21:04:51.098110  6212 sgd_solver.cpp:105] Iteration 44200, lr = 0.001
I0628 21:04:54.754598  6212 solver.cpp:218] Iteration 44300 (27.3543 iter/s, 3.65574s/100 iters), loss = 0.137065
I0628 21:04:54.754598  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:04:54.754598  6212 solver.cpp:237]     Train net output #1: loss = 0.137065 (* 1 = 0.137065 loss)
I0628 21:04:54.754598  6212 sgd_solver.cpp:105] Iteration 44300, lr = 0.001
I0628 21:04:58.430375  6212 solver.cpp:218] Iteration 44400 (27.2091 iter/s, 3.67524s/100 iters), loss = 0.143422
I0628 21:04:58.430375  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:04:58.430375  6212 solver.cpp:237]     Train net output #1: loss = 0.143422 (* 1 = 0.143422 loss)
I0628 21:04:58.430375  6212 sgd_solver.cpp:105] Iteration 44400, lr = 0.001
I0628 21:05:01.910542 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:05:02.053709  6212 solver.cpp:330] Iteration 44500, Testing net (#0)
I0628 21:05:02.053709  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:05:02.874578  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:05:02.905585  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8883
I0628 21:05:02.906596  6212 solver.cpp:397]     Test net output #1: loss = 0.359325 (* 1 = 0.359325 loss)
I0628 21:05:02.940481  6212 solver.cpp:218] Iteration 44500 (22.1735 iter/s, 4.50989s/100 iters), loss = 0.151599
I0628 21:05:02.940481  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:05:02.940481  6212 solver.cpp:237]     Train net output #1: loss = 0.151599 (* 1 = 0.151599 loss)
I0628 21:05:02.940481  6212 sgd_solver.cpp:105] Iteration 44500, lr = 0.001
I0628 21:05:06.605603  6212 solver.cpp:218] Iteration 44600 (27.2849 iter/s, 3.66503s/100 iters), loss = 0.090824
I0628 21:05:06.605603  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:05:06.605603  6212 solver.cpp:237]     Train net output #1: loss = 0.0908241 (* 1 = 0.0908241 loss)
I0628 21:05:06.605603  6212 sgd_solver.cpp:105] Iteration 44600, lr = 0.001
I0628 21:05:10.262094  6212 solver.cpp:218] Iteration 44700 (27.3557 iter/s, 3.65555s/100 iters), loss = 0.140628
I0628 21:05:10.262094  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:05:10.262094  6212 solver.cpp:237]     Train net output #1: loss = 0.140628 (* 1 = 0.140628 loss)
I0628 21:05:10.262094  6212 sgd_solver.cpp:105] Iteration 44700, lr = 0.001
I0628 21:05:13.921924  6212 solver.cpp:218] Iteration 44800 (27.3288 iter/s, 3.65914s/100 iters), loss = 0.166926
I0628 21:05:13.921924  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:05:13.921924  6212 solver.cpp:237]     Train net output #1: loss = 0.166926 (* 1 = 0.166926 loss)
I0628 21:05:13.921924  6212 sgd_solver.cpp:105] Iteration 44800, lr = 0.001
I0628 21:05:17.571122  6212 solver.cpp:218] Iteration 44900 (27.4014 iter/s, 3.64945s/100 iters), loss = 0.133345
I0628 21:05:17.571122  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:05:17.571122  6212 solver.cpp:237]     Train net output #1: loss = 0.133345 (* 1 = 0.133345 loss)
I0628 21:05:17.571122  6212 sgd_solver.cpp:105] Iteration 44900, lr = 0.001
I0628 21:05:21.043072 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:05:21.186822  6212 solver.cpp:330] Iteration 45000, Testing net (#0)
I0628 21:05:21.186822  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:05:22.008227  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:05:22.039252  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8864
I0628 21:05:22.039252  6212 solver.cpp:397]     Test net output #1: loss = 0.364273 (* 1 = 0.364273 loss)
I0628 21:05:22.073287  6212 solver.cpp:218] Iteration 45000 (22.2134 iter/s, 4.50178s/100 iters), loss = 0.115009
I0628 21:05:22.073287  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:05:22.073287  6212 solver.cpp:237]     Train net output #1: loss = 0.11501 (* 1 = 0.11501 loss)
I0628 21:05:22.073287  6212 sgd_solver.cpp:105] Iteration 45000, lr = 0.001
I0628 21:05:25.730197  6212 solver.cpp:218] Iteration 45100 (27.3485 iter/s, 3.65651s/100 iters), loss = 0.152144
I0628 21:05:25.730197  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:05:25.730197  6212 solver.cpp:237]     Train net output #1: loss = 0.152144 (* 1 = 0.152144 loss)
I0628 21:05:25.730197  6212 sgd_solver.cpp:105] Iteration 45100, lr = 0.001
I0628 21:05:29.381053  6212 solver.cpp:218] Iteration 45200 (27.3927 iter/s, 3.65061s/100 iters), loss = 0.177103
I0628 21:05:29.381053  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:05:29.381053  6212 solver.cpp:237]     Train net output #1: loss = 0.177104 (* 1 = 0.177104 loss)
I0628 21:05:29.381053  6212 sgd_solver.cpp:105] Iteration 45200, lr = 0.001
I0628 21:05:33.009812  6212 solver.cpp:218] Iteration 45300 (27.5666 iter/s, 3.62758s/100 iters), loss = 0.119839
I0628 21:05:33.009812  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:05:33.009812  6212 solver.cpp:237]     Train net output #1: loss = 0.119839 (* 1 = 0.119839 loss)
I0628 21:05:33.009812  6212 sgd_solver.cpp:105] Iteration 45300, lr = 0.001
I0628 21:05:36.648558  6212 solver.cpp:218] Iteration 45400 (27.4845 iter/s, 3.63841s/100 iters), loss = 0.151649
I0628 21:05:36.648558  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:05:36.648558  6212 solver.cpp:237]     Train net output #1: loss = 0.151649 (* 1 = 0.151649 loss)
I0628 21:05:36.648558  6212 sgd_solver.cpp:105] Iteration 45400, lr = 0.001
I0628 21:05:40.089015 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:05:40.230309  6212 solver.cpp:330] Iteration 45500, Testing net (#0)
I0628 21:05:40.230309  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:05:41.050338  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:05:41.081393  6212 solver.cpp:397]     Test net output #0: accuracy = 0.887
I0628 21:05:41.081393  6212 solver.cpp:397]     Test net output #1: loss = 0.359828 (* 1 = 0.359828 loss)
I0628 21:05:41.115409  6212 solver.cpp:218] Iteration 45500 (22.3853 iter/s, 4.46721s/100 iters), loss = 0.0895975
I0628 21:05:41.115409  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:05:41.115409  6212 solver.cpp:237]     Train net output #1: loss = 0.0895977 (* 1 = 0.0895977 loss)
I0628 21:05:41.115409  6212 sgd_solver.cpp:105] Iteration 45500, lr = 0.001
I0628 21:05:44.737496  6212 solver.cpp:218] Iteration 45600 (27.6164 iter/s, 3.62104s/100 iters), loss = 0.158774
I0628 21:05:44.737496  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:05:44.737496  6212 solver.cpp:237]     Train net output #1: loss = 0.158774 (* 1 = 0.158774 loss)
I0628 21:05:44.737496  6212 sgd_solver.cpp:105] Iteration 45600, lr = 0.001
I0628 21:05:48.360743  6212 solver.cpp:218] Iteration 45700 (27.6024 iter/s, 3.62287s/100 iters), loss = 0.185406
I0628 21:05:48.360743  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:05:48.360743  6212 solver.cpp:237]     Train net output #1: loss = 0.185406 (* 1 = 0.185406 loss)
I0628 21:05:48.360743  6212 sgd_solver.cpp:105] Iteration 45700, lr = 0.001
I0628 21:05:51.983712  6212 solver.cpp:218] Iteration 45800 (27.6045 iter/s, 3.6226s/100 iters), loss = 0.15259
I0628 21:05:51.983712  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:05:51.983712  6212 solver.cpp:237]     Train net output #1: loss = 0.15259 (* 1 = 0.15259 loss)
I0628 21:05:51.983712  6212 sgd_solver.cpp:105] Iteration 45800, lr = 0.001
I0628 21:05:55.604115  6212 solver.cpp:218] Iteration 45900 (27.6228 iter/s, 3.6202s/100 iters), loss = 0.0817394
I0628 21:05:55.604115  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:05:55.604115  6212 solver.cpp:237]     Train net output #1: loss = 0.0817396 (* 1 = 0.0817396 loss)
I0628 21:05:55.604115  6212 sgd_solver.cpp:105] Iteration 45900, lr = 0.001
I0628 21:05:59.048110 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:05:59.189750  6212 solver.cpp:330] Iteration 46000, Testing net (#0)
I0628 21:05:59.190738  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:06:00.006489  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:06:00.037544  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8863
I0628 21:06:00.037544  6212 solver.cpp:397]     Test net output #1: loss = 0.363683 (* 1 = 0.363683 loss)
I0628 21:06:00.071566  6212 solver.cpp:218] Iteration 46000 (22.3821 iter/s, 4.46785s/100 iters), loss = 0.14542
I0628 21:06:00.071566  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:06:00.071566  6212 solver.cpp:237]     Train net output #1: loss = 0.14542 (* 1 = 0.14542 loss)
I0628 21:06:00.072568  6212 sgd_solver.cpp:105] Iteration 46000, lr = 0.001
I0628 21:06:03.702435  6212 solver.cpp:218] Iteration 46100 (27.5449 iter/s, 3.63044s/100 iters), loss = 0.124654
I0628 21:06:03.702435  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:06:03.702435  6212 solver.cpp:237]     Train net output #1: loss = 0.124654 (* 1 = 0.124654 loss)
I0628 21:06:03.702435  6212 sgd_solver.cpp:105] Iteration 46100, lr = 0.001
I0628 21:06:07.327613  6212 solver.cpp:218] Iteration 46200 (27.5878 iter/s, 3.62479s/100 iters), loss = 0.129473
I0628 21:06:07.327613  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:06:07.327613  6212 solver.cpp:237]     Train net output #1: loss = 0.129473 (* 1 = 0.129473 loss)
I0628 21:06:07.327613  6212 sgd_solver.cpp:105] Iteration 46200, lr = 0.001
I0628 21:06:10.982914  6212 solver.cpp:218] Iteration 46300 (27.3597 iter/s, 3.65501s/100 iters), loss = 0.156968
I0628 21:06:10.983932  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:06:10.983932  6212 solver.cpp:237]     Train net output #1: loss = 0.156969 (* 1 = 0.156969 loss)
I0628 21:06:10.983932  6212 sgd_solver.cpp:105] Iteration 46300, lr = 0.001
I0628 21:06:14.630610  6212 solver.cpp:218] Iteration 46400 (27.4215 iter/s, 3.64678s/100 iters), loss = 0.0927865
I0628 21:06:14.630610  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:06:14.630610  6212 solver.cpp:237]     Train net output #1: loss = 0.0927867 (* 1 = 0.0927867 loss)
I0628 21:06:14.630610  6212 sgd_solver.cpp:105] Iteration 46400, lr = 0.001
I0628 21:06:18.092509 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:06:18.233611  6212 solver.cpp:330] Iteration 46500, Testing net (#0)
I0628 21:06:18.233611  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:06:19.060240  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:06:19.091269  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8855
I0628 21:06:19.091269  6212 solver.cpp:397]     Test net output #1: loss = 0.364596 (* 1 = 0.364596 loss)
I0628 21:06:19.125293  6212 solver.cpp:218] Iteration 46500 (22.2482 iter/s, 4.49475s/100 iters), loss = 0.17139
I0628 21:06:19.126293  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:06:19.126293  6212 solver.cpp:237]     Train net output #1: loss = 0.171391 (* 1 = 0.171391 loss)
I0628 21:06:19.126293  6212 sgd_solver.cpp:105] Iteration 46500, lr = 0.001
I0628 21:06:22.769471  6212 solver.cpp:218] Iteration 46600 (27.4485 iter/s, 3.64319s/100 iters), loss = 0.144322
I0628 21:06:22.769471  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:06:22.769471  6212 solver.cpp:237]     Train net output #1: loss = 0.144323 (* 1 = 0.144323 loss)
I0628 21:06:22.769471  6212 sgd_solver.cpp:105] Iteration 46600, lr = 0.001
I0628 21:06:26.420691  6212 solver.cpp:218] Iteration 46700 (27.3936 iter/s, 3.65049s/100 iters), loss = 0.153085
I0628 21:06:26.420691  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:06:26.420691  6212 solver.cpp:237]     Train net output #1: loss = 0.153085 (* 1 = 0.153085 loss)
I0628 21:06:26.420691  6212 sgd_solver.cpp:105] Iteration 46700, lr = 0.001
I0628 21:06:30.063432  6212 solver.cpp:218] Iteration 46800 (27.4534 iter/s, 3.64253s/100 iters), loss = 0.176285
I0628 21:06:30.063432  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:06:30.063432  6212 solver.cpp:237]     Train net output #1: loss = 0.176285 (* 1 = 0.176285 loss)
I0628 21:06:30.063432  6212 sgd_solver.cpp:105] Iteration 46800, lr = 0.001
I0628 21:06:33.694012  6212 solver.cpp:218] Iteration 46900 (27.5459 iter/s, 3.63031s/100 iters), loss = 0.182128
I0628 21:06:33.694012  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:06:33.694012  6212 solver.cpp:237]     Train net output #1: loss = 0.182128 (* 1 = 0.182128 loss)
I0628 21:06:33.694012  6212 sgd_solver.cpp:105] Iteration 46900, lr = 0.001
I0628 21:06:37.140586 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:06:37.284696  6212 solver.cpp:330] Iteration 47000, Testing net (#0)
I0628 21:06:37.284696  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:06:38.104336  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:06:38.135361  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8845
I0628 21:06:38.135361  6212 solver.cpp:397]     Test net output #1: loss = 0.365699 (* 1 = 0.365699 loss)
I0628 21:06:38.170383  6212 solver.cpp:218] Iteration 47000 (22.3407 iter/s, 4.47614s/100 iters), loss = 0.129974
I0628 21:06:38.170383  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:06:38.170383  6212 solver.cpp:237]     Train net output #1: loss = 0.129974 (* 1 = 0.129974 loss)
I0628 21:06:38.170383  6212 sgd_solver.cpp:105] Iteration 47000, lr = 0.001
I0628 21:06:41.794163  6212 solver.cpp:218] Iteration 47100 (27.5981 iter/s, 3.62343s/100 iters), loss = 0.0908799
I0628 21:06:41.794163  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:06:41.794163  6212 solver.cpp:237]     Train net output #1: loss = 0.0908801 (* 1 = 0.0908801 loss)
I0628 21:06:41.794163  6212 sgd_solver.cpp:105] Iteration 47100, lr = 0.001
I0628 21:06:45.436982  6212 solver.cpp:218] Iteration 47200 (27.4519 iter/s, 3.64274s/100 iters), loss = 0.194357
I0628 21:06:45.436982  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:06:45.436982  6212 solver.cpp:237]     Train net output #1: loss = 0.194357 (* 1 = 0.194357 loss)
I0628 21:06:45.436982  6212 sgd_solver.cpp:105] Iteration 47200, lr = 0.001
I0628 21:06:49.068847  6212 solver.cpp:218] Iteration 47300 (27.5401 iter/s, 3.63106s/100 iters), loss = 0.12011
I0628 21:06:49.068847  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:06:49.068847  6212 solver.cpp:237]     Train net output #1: loss = 0.12011 (* 1 = 0.12011 loss)
I0628 21:06:49.068847  6212 sgd_solver.cpp:105] Iteration 47300, lr = 0.001
I0628 21:06:52.712599  6212 solver.cpp:218] Iteration 47400 (27.4437 iter/s, 3.64383s/100 iters), loss = 0.0871399
I0628 21:06:52.712599  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:06:52.712599  6212 solver.cpp:237]     Train net output #1: loss = 0.08714 (* 1 = 0.08714 loss)
I0628 21:06:52.712599  6212 sgd_solver.cpp:105] Iteration 47400, lr = 0.001
I0628 21:06:56.165123 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:06:56.308230  6212 solver.cpp:330] Iteration 47500, Testing net (#0)
I0628 21:06:56.308230  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:06:57.125938  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:06:57.156960  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8842
I0628 21:06:57.156960  6212 solver.cpp:397]     Test net output #1: loss = 0.368936 (* 1 = 0.368936 loss)
I0628 21:06:57.190984  6212 solver.cpp:218] Iteration 47500 (22.3326 iter/s, 4.47777s/100 iters), loss = 0.150496
I0628 21:06:57.190984  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:06:57.190984  6212 solver.cpp:237]     Train net output #1: loss = 0.150496 (* 1 = 0.150496 loss)
I0628 21:06:57.190984  6212 sgd_solver.cpp:105] Iteration 47500, lr = 0.001
I0628 21:07:00.823513  6212 solver.cpp:218] Iteration 47600 (27.5313 iter/s, 3.63223s/100 iters), loss = 0.0983961
I0628 21:07:00.823513  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:07:00.823513  6212 solver.cpp:237]     Train net output #1: loss = 0.0983963 (* 1 = 0.0983963 loss)
I0628 21:07:00.823513  6212 sgd_solver.cpp:105] Iteration 47600, lr = 0.001
I0628 21:07:04.453126  6212 solver.cpp:218] Iteration 47700 (27.5551 iter/s, 3.62909s/100 iters), loss = 0.129972
I0628 21:07:04.453126  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:07:04.453126  6212 solver.cpp:237]     Train net output #1: loss = 0.129973 (* 1 = 0.129973 loss)
I0628 21:07:04.453126  6212 sgd_solver.cpp:105] Iteration 47700, lr = 0.001
I0628 21:07:08.163178  6212 solver.cpp:218] Iteration 47800 (26.9594 iter/s, 3.70928s/100 iters), loss = 0.139099
I0628 21:07:08.163178  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:07:08.163178  6212 solver.cpp:237]     Train net output #1: loss = 0.139099 (* 1 = 0.139099 loss)
I0628 21:07:08.163178  6212 sgd_solver.cpp:105] Iteration 47800, lr = 0.001
I0628 21:07:11.955837  6212 solver.cpp:218] Iteration 47900 (26.3676 iter/s, 3.79253s/100 iters), loss = 0.113093
I0628 21:07:11.955837  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:07:11.955837  6212 solver.cpp:237]     Train net output #1: loss = 0.113093 (* 1 = 0.113093 loss)
I0628 21:07:11.955837  6212 sgd_solver.cpp:105] Iteration 47900, lr = 0.001
I0628 21:07:15.541541 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:07:15.688648  6212 solver.cpp:330] Iteration 48000, Testing net (#0)
I0628 21:07:15.688648  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:07:16.529279  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:07:16.560300  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8895
I0628 21:07:16.560300  6212 solver.cpp:397]     Test net output #1: loss = 0.362583 (* 1 = 0.362583 loss)
I0628 21:07:16.596326  6212 solver.cpp:218] Iteration 48000 (21.5527 iter/s, 4.63979s/100 iters), loss = 0.201049
I0628 21:07:16.596326  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:07:16.596326  6212 solver.cpp:237]     Train net output #1: loss = 0.201049 (* 1 = 0.201049 loss)
I0628 21:07:16.596326  6212 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0628 21:07:16.596326  6212 sgd_solver.cpp:105] Iteration 48000, lr = 0.0001
I0628 21:07:20.361981  6212 solver.cpp:218] Iteration 48100 (26.558 iter/s, 3.76534s/100 iters), loss = 0.094256
I0628 21:07:20.361981  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:07:20.361981  6212 solver.cpp:237]     Train net output #1: loss = 0.0942562 (* 1 = 0.0942562 loss)
I0628 21:07:20.361981  6212 sgd_solver.cpp:105] Iteration 48100, lr = 0.0001
I0628 21:07:24.112397  6212 solver.cpp:218] Iteration 48200 (26.6675 iter/s, 3.74988s/100 iters), loss = 0.132447
I0628 21:07:24.112397  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:07:24.112397  6212 solver.cpp:237]     Train net output #1: loss = 0.132448 (* 1 = 0.132448 loss)
I0628 21:07:24.112397  6212 sgd_solver.cpp:105] Iteration 48200, lr = 0.0001
I0628 21:07:27.879900  6212 solver.cpp:218] Iteration 48300 (26.5436 iter/s, 3.76739s/100 iters), loss = 0.115836
I0628 21:07:27.879900  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:07:27.879900  6212 solver.cpp:237]     Train net output #1: loss = 0.115836 (* 1 = 0.115836 loss)
I0628 21:07:27.879900  6212 sgd_solver.cpp:105] Iteration 48300, lr = 0.0001
I0628 21:07:31.650553  6212 solver.cpp:218] Iteration 48400 (26.5276 iter/s, 3.76966s/100 iters), loss = 0.093499
I0628 21:07:31.650553  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:07:31.650553  6212 solver.cpp:237]     Train net output #1: loss = 0.0934991 (* 1 = 0.0934991 loss)
I0628 21:07:31.650553  6212 sgd_solver.cpp:105] Iteration 48400, lr = 0.0001
I0628 21:07:35.236297 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:07:35.382405  6212 solver.cpp:330] Iteration 48500, Testing net (#0)
I0628 21:07:35.382405  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:07:36.218037  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:07:36.250064  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0628 21:07:36.250064  6212 solver.cpp:397]     Test net output #1: loss = 0.351768 (* 1 = 0.351768 loss)
I0628 21:07:36.285089  6212 solver.cpp:218] Iteration 48500 (21.5777 iter/s, 4.63441s/100 iters), loss = 0.117206
I0628 21:07:36.285089  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:07:36.285089  6212 solver.cpp:237]     Train net output #1: loss = 0.117206 (* 1 = 0.117206 loss)
I0628 21:07:36.285089  6212 sgd_solver.cpp:105] Iteration 48500, lr = 0.0001
I0628 21:07:40.029402  6212 solver.cpp:218] Iteration 48600 (26.7116 iter/s, 3.74369s/100 iters), loss = 0.142552
I0628 21:07:40.029402  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:07:40.029402  6212 solver.cpp:237]     Train net output #1: loss = 0.142552 (* 1 = 0.142552 loss)
I0628 21:07:40.029402  6212 sgd_solver.cpp:105] Iteration 48600, lr = 0.0001
I0628 21:07:43.777917  6212 solver.cpp:218] Iteration 48700 (26.6753 iter/s, 3.74879s/100 iters), loss = 0.147343
I0628 21:07:43.777917  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:07:43.777917  6212 solver.cpp:237]     Train net output #1: loss = 0.147343 (* 1 = 0.147343 loss)
I0628 21:07:43.778919  6212 sgd_solver.cpp:105] Iteration 48700, lr = 0.0001
I0628 21:07:47.508903  6212 solver.cpp:218] Iteration 48800 (26.806 iter/s, 3.73051s/100 iters), loss = 0.148647
I0628 21:07:47.508903  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:07:47.508903  6212 solver.cpp:237]     Train net output #1: loss = 0.148647 (* 1 = 0.148647 loss)
I0628 21:07:47.508903  6212 sgd_solver.cpp:105] Iteration 48800, lr = 0.0001
I0628 21:07:51.184646  6212 solver.cpp:218] Iteration 48900 (27.208 iter/s, 3.6754s/100 iters), loss = 0.0833955
I0628 21:07:51.184646  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:07:51.184646  6212 solver.cpp:237]     Train net output #1: loss = 0.0833956 (* 1 = 0.0833956 loss)
I0628 21:07:51.184646  6212 sgd_solver.cpp:105] Iteration 48900, lr = 0.0001
I0628 21:07:54.673272 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:07:54.817379  6212 solver.cpp:330] Iteration 49000, Testing net (#0)
I0628 21:07:54.817379  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:07:55.639472  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:07:55.669993  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0628 21:07:55.669993  6212 solver.cpp:397]     Test net output #1: loss = 0.350724 (* 1 = 0.350724 loss)
I0628 21:07:55.705031  6212 solver.cpp:218] Iteration 49000 (22.1266 iter/s, 4.51944s/100 iters), loss = 0.122164
I0628 21:07:55.705031  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:07:55.705031  6212 solver.cpp:237]     Train net output #1: loss = 0.122164 (* 1 = 0.122164 loss)
I0628 21:07:55.705031  6212 sgd_solver.cpp:105] Iteration 49000, lr = 0.0001
I0628 21:07:59.368217  6212 solver.cpp:218] Iteration 49100 (27.2973 iter/s, 3.66336s/100 iters), loss = 0.159259
I0628 21:07:59.368217  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:07:59.369218  6212 solver.cpp:237]     Train net output #1: loss = 0.15926 (* 1 = 0.15926 loss)
I0628 21:07:59.369218  6212 sgd_solver.cpp:105] Iteration 49100, lr = 0.0001
I0628 21:08:03.013555  6212 solver.cpp:218] Iteration 49200 (27.4388 iter/s, 3.64447s/100 iters), loss = 0.135321
I0628 21:08:03.013555  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:08:03.013555  6212 solver.cpp:237]     Train net output #1: loss = 0.135321 (* 1 = 0.135321 loss)
I0628 21:08:03.013555  6212 sgd_solver.cpp:105] Iteration 49200, lr = 0.0001
I0628 21:08:06.664824  6212 solver.cpp:218] Iteration 49300 (27.3925 iter/s, 3.65063s/100 iters), loss = 0.182488
I0628 21:08:06.664824  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:08:06.664824  6212 solver.cpp:237]     Train net output #1: loss = 0.182488 (* 1 = 0.182488 loss)
I0628 21:08:06.664824  6212 sgd_solver.cpp:105] Iteration 49300, lr = 0.0001
I0628 21:08:10.313701  6212 solver.cpp:218] Iteration 49400 (27.4076 iter/s, 3.64862s/100 iters), loss = 0.147486
I0628 21:08:10.313701  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:08:10.313701  6212 solver.cpp:237]     Train net output #1: loss = 0.147486 (* 1 = 0.147486 loss)
I0628 21:08:10.313701  6212 sgd_solver.cpp:105] Iteration 49400, lr = 0.0001
I0628 21:08:13.788853 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:08:13.930485  6212 solver.cpp:330] Iteration 49500, Testing net (#0)
I0628 21:08:13.930485  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:08:14.751955  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:08:14.784009  6212 solver.cpp:397]     Test net output #0: accuracy = 0.893
I0628 21:08:14.784009  6212 solver.cpp:397]     Test net output #1: loss = 0.351262 (* 1 = 0.351262 loss)
I0628 21:08:14.818033  6212 solver.cpp:218] Iteration 49500 (22.2011 iter/s, 4.50428s/100 iters), loss = 0.124207
I0628 21:08:14.818033  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:08:14.818033  6212 solver.cpp:237]     Train net output #1: loss = 0.124207 (* 1 = 0.124207 loss)
I0628 21:08:14.818033  6212 sgd_solver.cpp:105] Iteration 49500, lr = 0.0001
I0628 21:08:18.463752  6212 solver.cpp:218] Iteration 49600 (27.4365 iter/s, 3.64478s/100 iters), loss = 0.131593
I0628 21:08:18.463752  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:08:18.463752  6212 solver.cpp:237]     Train net output #1: loss = 0.131593 (* 1 = 0.131593 loss)
I0628 21:08:18.463752  6212 sgd_solver.cpp:105] Iteration 49600, lr = 0.0001
I0628 21:08:22.123363  6212 solver.cpp:218] Iteration 49700 (27.3242 iter/s, 3.65976s/100 iters), loss = 0.129115
I0628 21:08:22.123363  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:08:22.123363  6212 solver.cpp:237]     Train net output #1: loss = 0.129116 (* 1 = 0.129116 loss)
I0628 21:08:22.123363  6212 sgd_solver.cpp:105] Iteration 49700, lr = 0.0001
I0628 21:08:25.779256  6212 solver.cpp:218] Iteration 49800 (27.3603 iter/s, 3.65493s/100 iters), loss = 0.166622
I0628 21:08:25.779256  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:08:25.779256  6212 solver.cpp:237]     Train net output #1: loss = 0.166622 (* 1 = 0.166622 loss)
I0628 21:08:25.779256  6212 sgd_solver.cpp:105] Iteration 49800, lr = 0.0001
I0628 21:08:29.442888  6212 solver.cpp:218] Iteration 49900 (27.2943 iter/s, 3.66377s/100 iters), loss = 0.0867147
I0628 21:08:29.442888  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:08:29.442888  6212 solver.cpp:237]     Train net output #1: loss = 0.0867148 (* 1 = 0.0867148 loss)
I0628 21:08:29.442888  6212 sgd_solver.cpp:105] Iteration 49900, lr = 0.0001
I0628 21:08:32.937819 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:08:33.079923  6212 solver.cpp:330] Iteration 50000, Testing net (#0)
I0628 21:08:33.080425  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:08:33.915560  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:08:33.946578  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8921
I0628 21:08:33.946578  6212 solver.cpp:397]     Test net output #1: loss = 0.350889 (* 1 = 0.350889 loss)
I0628 21:08:33.982105  6212 solver.cpp:218] Iteration 50000 (22.0326 iter/s, 4.53873s/100 iters), loss = 0.0841144
I0628 21:08:33.982606  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:08:33.982606  6212 solver.cpp:237]     Train net output #1: loss = 0.0841146 (* 1 = 0.0841146 loss)
I0628 21:08:33.982606  6212 sgd_solver.cpp:105] Iteration 50000, lr = 0.0001
I0628 21:08:37.776820  6212 solver.cpp:218] Iteration 50100 (26.3587 iter/s, 3.79382s/100 iters), loss = 0.163021
I0628 21:08:37.776820  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:08:37.776820  6212 solver.cpp:237]     Train net output #1: loss = 0.163021 (* 1 = 0.163021 loss)
I0628 21:08:37.776820  6212 sgd_solver.cpp:105] Iteration 50100, lr = 0.0001
I0628 21:08:41.515455  6212 solver.cpp:218] Iteration 50200 (26.7512 iter/s, 3.73815s/100 iters), loss = 0.10441
I0628 21:08:41.515455  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:08:41.515455  6212 solver.cpp:237]     Train net output #1: loss = 0.10441 (* 1 = 0.10441 loss)
I0628 21:08:41.515455  6212 sgd_solver.cpp:105] Iteration 50200, lr = 0.0001
I0628 21:08:45.257371  6212 solver.cpp:218] Iteration 50300 (26.7266 iter/s, 3.7416s/100 iters), loss = 0.106127
I0628 21:08:45.257371  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:08:45.257371  6212 solver.cpp:237]     Train net output #1: loss = 0.106127 (* 1 = 0.106127 loss)
I0628 21:08:45.257371  6212 sgd_solver.cpp:105] Iteration 50300, lr = 0.0001
I0628 21:08:48.993474  6212 solver.cpp:218] Iteration 50400 (26.7662 iter/s, 3.73606s/100 iters), loss = 0.0754992
I0628 21:08:48.993474  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:08:48.993474  6212 solver.cpp:237]     Train net output #1: loss = 0.0754993 (* 1 = 0.0754993 loss)
I0628 21:08:48.993474  6212 sgd_solver.cpp:105] Iteration 50400, lr = 0.0001
I0628 21:08:52.539155 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:08:52.684546  6212 solver.cpp:330] Iteration 50500, Testing net (#0)
I0628 21:08:52.684546  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:08:53.515745  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:08:53.547269  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8917
I0628 21:08:53.547269  6212 solver.cpp:397]     Test net output #1: loss = 0.352485 (* 1 = 0.352485 loss)
I0628 21:08:53.582294  6212 solver.cpp:218] Iteration 50500 (21.7952 iter/s, 4.58816s/100 iters), loss = 0.092591
I0628 21:08:53.582294  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:08:53.582294  6212 solver.cpp:237]     Train net output #1: loss = 0.0925912 (* 1 = 0.0925912 loss)
I0628 21:08:53.582294  6212 sgd_solver.cpp:105] Iteration 50500, lr = 0.0001
I0628 21:08:57.307536  6212 solver.cpp:218] Iteration 50600 (26.8483 iter/s, 3.72464s/100 iters), loss = 0.113627
I0628 21:08:57.307536  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:08:57.307536  6212 solver.cpp:237]     Train net output #1: loss = 0.113627 (* 1 = 0.113627 loss)
I0628 21:08:57.307536  6212 sgd_solver.cpp:105] Iteration 50600, lr = 0.0001
I0628 21:09:01.038782  6212 solver.cpp:218] Iteration 50700 (26.8011 iter/s, 3.73119s/100 iters), loss = 0.156016
I0628 21:09:01.038782  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:09:01.038782  6212 solver.cpp:237]     Train net output #1: loss = 0.156016 (* 1 = 0.156016 loss)
I0628 21:09:01.038782  6212 sgd_solver.cpp:105] Iteration 50700, lr = 0.0001
I0628 21:09:04.792425  6212 solver.cpp:218] Iteration 50800 (26.6461 iter/s, 3.75289s/100 iters), loss = 0.10988
I0628 21:09:04.792425  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:09:04.792425  6212 solver.cpp:237]     Train net output #1: loss = 0.10988 (* 1 = 0.10988 loss)
I0628 21:09:04.792425  6212 sgd_solver.cpp:105] Iteration 50800, lr = 0.0001
I0628 21:09:08.530704  6212 solver.cpp:218] Iteration 50900 (26.7491 iter/s, 3.73844s/100 iters), loss = 0.0906971
I0628 21:09:08.530704  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:09:08.530704  6212 solver.cpp:237]     Train net output #1: loss = 0.0906973 (* 1 = 0.0906973 loss)
I0628 21:09:08.530704  6212 sgd_solver.cpp:105] Iteration 50900, lr = 0.0001
I0628 21:09:12.013448 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:09:12.157140  6212 solver.cpp:330] Iteration 51000, Testing net (#0)
I0628 21:09:12.157140  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:09:12.979039  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:09:13.010061  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8917
I0628 21:09:13.010061  6212 solver.cpp:397]     Test net output #1: loss = 0.352892 (* 1 = 0.352892 loss)
I0628 21:09:13.044682  6212 solver.cpp:218] Iteration 51000 (22.1552 iter/s, 4.51361s/100 iters), loss = 0.0988623
I0628 21:09:13.044682  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:09:13.044682  6212 solver.cpp:237]     Train net output #1: loss = 0.0988624 (* 1 = 0.0988624 loss)
I0628 21:09:13.044682  6212 sgd_solver.cpp:105] Iteration 51000, lr = 0.0001
I0628 21:09:16.704728  6212 solver.cpp:218] Iteration 51100 (27.3274 iter/s, 3.65933s/100 iters), loss = 0.106323
I0628 21:09:16.704728  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:09:16.704728  6212 solver.cpp:237]     Train net output #1: loss = 0.106323 (* 1 = 0.106323 loss)
I0628 21:09:16.704728  6212 sgd_solver.cpp:105] Iteration 51100, lr = 0.0001
I0628 21:09:20.358456  6212 solver.cpp:218] Iteration 51200 (27.3687 iter/s, 3.65381s/100 iters), loss = 0.113537
I0628 21:09:20.358456  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:09:20.358456  6212 solver.cpp:237]     Train net output #1: loss = 0.113537 (* 1 = 0.113537 loss)
I0628 21:09:20.358456  6212 sgd_solver.cpp:105] Iteration 51200, lr = 0.0001
I0628 21:09:24.015147  6212 solver.cpp:218] Iteration 51300 (27.3485 iter/s, 3.65651s/100 iters), loss = 0.148244
I0628 21:09:24.016149  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:09:24.016149  6212 solver.cpp:237]     Train net output #1: loss = 0.148244 (* 1 = 0.148244 loss)
I0628 21:09:24.016149  6212 sgd_solver.cpp:105] Iteration 51300, lr = 0.0001
I0628 21:09:27.678203  6212 solver.cpp:218] Iteration 51400 (27.3037 iter/s, 3.6625s/100 iters), loss = 0.0889838
I0628 21:09:27.678203  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:09:27.678203  6212 solver.cpp:237]     Train net output #1: loss = 0.0889839 (* 1 = 0.0889839 loss)
I0628 21:09:27.678203  6212 sgd_solver.cpp:105] Iteration 51400, lr = 0.0001
I0628 21:09:31.125879 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:09:31.267984  6212 solver.cpp:330] Iteration 51500, Testing net (#0)
I0628 21:09:31.267984  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:09:32.092676  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:09:32.123697  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I0628 21:09:32.123697  6212 solver.cpp:397]     Test net output #1: loss = 0.352215 (* 1 = 0.352215 loss)
I0628 21:09:32.158725  6212 solver.cpp:218] Iteration 51500 (22.3247 iter/s, 4.47933s/100 iters), loss = 0.110229
I0628 21:09:32.158725  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:09:32.158725  6212 solver.cpp:237]     Train net output #1: loss = 0.110229 (* 1 = 0.110229 loss)
I0628 21:09:32.158725  6212 sgd_solver.cpp:105] Iteration 51500, lr = 0.0001
I0628 21:09:35.787488  6212 solver.cpp:218] Iteration 51600 (27.5581 iter/s, 3.62869s/100 iters), loss = 0.160857
I0628 21:09:35.787488  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:09:35.787488  6212 solver.cpp:237]     Train net output #1: loss = 0.160857 (* 1 = 0.160857 loss)
I0628 21:09:35.787488  6212 sgd_solver.cpp:105] Iteration 51600, lr = 0.0001
I0628 21:09:39.414361  6212 solver.cpp:218] Iteration 51700 (27.5751 iter/s, 3.62646s/100 iters), loss = 0.0806281
I0628 21:09:39.414361  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:09:39.414361  6212 solver.cpp:237]     Train net output #1: loss = 0.0806282 (* 1 = 0.0806282 loss)
I0628 21:09:39.414361  6212 sgd_solver.cpp:105] Iteration 51700, lr = 0.0001
I0628 21:09:43.036234  6212 solver.cpp:218] Iteration 51800 (27.6102 iter/s, 3.62185s/100 iters), loss = 0.128451
I0628 21:09:43.036234  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:09:43.036234  6212 solver.cpp:237]     Train net output #1: loss = 0.128451 (* 1 = 0.128451 loss)
I0628 21:09:43.036234  6212 sgd_solver.cpp:105] Iteration 51800, lr = 0.0001
I0628 21:09:46.674355  6212 solver.cpp:218] Iteration 51900 (27.4889 iter/s, 3.63784s/100 iters), loss = 0.0904854
I0628 21:09:46.674355  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:09:46.674355  6212 solver.cpp:237]     Train net output #1: loss = 0.0904856 (* 1 = 0.0904856 loss)
I0628 21:09:46.674355  6212 sgd_solver.cpp:105] Iteration 51900, lr = 0.0001
I0628 21:09:50.122534 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:09:50.264636  6212 solver.cpp:330] Iteration 52000, Testing net (#0)
I0628 21:09:50.264636  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:09:51.081302  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:09:51.112324  6212 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0628 21:09:51.112324  6212 solver.cpp:397]     Test net output #1: loss = 0.352947 (* 1 = 0.352947 loss)
I0628 21:09:51.146348  6212 solver.cpp:218] Iteration 52000 (22.3646 iter/s, 4.47136s/100 iters), loss = 0.0838147
I0628 21:09:51.146348  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:09:51.146348  6212 solver.cpp:237]     Train net output #1: loss = 0.0838149 (* 1 = 0.0838149 loss)
I0628 21:09:51.146348  6212 sgd_solver.cpp:105] Iteration 52000, lr = 0.0001
I0628 21:09:54.777685  6212 solver.cpp:218] Iteration 52100 (27.5435 iter/s, 3.63063s/100 iters), loss = 0.145958
I0628 21:09:54.777685  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:09:54.777685  6212 solver.cpp:237]     Train net output #1: loss = 0.145958 (* 1 = 0.145958 loss)
I0628 21:09:54.777685  6212 sgd_solver.cpp:105] Iteration 52100, lr = 0.0001
I0628 21:09:58.414496  6212 solver.cpp:218] Iteration 52200 (27.4966 iter/s, 3.63681s/100 iters), loss = 0.182231
I0628 21:09:58.414496  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:09:58.414496  6212 solver.cpp:237]     Train net output #1: loss = 0.182231 (* 1 = 0.182231 loss)
I0628 21:09:58.414496  6212 sgd_solver.cpp:105] Iteration 52200, lr = 0.0001
I0628 21:10:02.064515  6212 solver.cpp:218] Iteration 52300 (27.3974 iter/s, 3.64999s/100 iters), loss = 0.127263
I0628 21:10:02.064515  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:10:02.064515  6212 solver.cpp:237]     Train net output #1: loss = 0.127263 (* 1 = 0.127263 loss)
I0628 21:10:02.064515  6212 sgd_solver.cpp:105] Iteration 52300, lr = 0.0001
I0628 21:10:05.698729  6212 solver.cpp:218] Iteration 52400 (27.5217 iter/s, 3.6335s/100 iters), loss = 0.048178
I0628 21:10:05.698729  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 21:10:05.698729  6212 solver.cpp:237]     Train net output #1: loss = 0.0481781 (* 1 = 0.0481781 loss)
I0628 21:10:05.698729  6212 sgd_solver.cpp:105] Iteration 52400, lr = 0.0001
I0628 21:10:09.153076 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:10:09.295181  6212 solver.cpp:330] Iteration 52500, Testing net (#0)
I0628 21:10:09.295181  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:10:10.118798  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:10:10.149821  6212 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0628 21:10:10.149821  6212 solver.cpp:397]     Test net output #1: loss = 0.353408 (* 1 = 0.353408 loss)
I0628 21:10:10.183845  6212 solver.cpp:218] Iteration 52500 (22.2979 iter/s, 4.48473s/100 iters), loss = 0.0942966
I0628 21:10:10.183845  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:10:10.183845  6212 solver.cpp:237]     Train net output #1: loss = 0.0942968 (* 1 = 0.0942968 loss)
I0628 21:10:10.183845  6212 sgd_solver.cpp:105] Iteration 52500, lr = 0.0001
I0628 21:10:13.826565  6212 solver.cpp:218] Iteration 52600 (27.4534 iter/s, 3.64253s/100 iters), loss = 0.133657
I0628 21:10:13.826565  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:10:13.826565  6212 solver.cpp:237]     Train net output #1: loss = 0.133657 (* 1 = 0.133657 loss)
I0628 21:10:13.826565  6212 sgd_solver.cpp:105] Iteration 52600, lr = 0.0001
I0628 21:10:17.462322  6212 solver.cpp:218] Iteration 52700 (27.505 iter/s, 3.63571s/100 iters), loss = 0.159336
I0628 21:10:17.462322  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:10:17.462322  6212 solver.cpp:237]     Train net output #1: loss = 0.159337 (* 1 = 0.159337 loss)
I0628 21:10:17.462322  6212 sgd_solver.cpp:105] Iteration 52700, lr = 0.0001
I0628 21:10:21.085743  6212 solver.cpp:218] Iteration 52800 (27.6031 iter/s, 3.62278s/100 iters), loss = 0.140668
I0628 21:10:21.085743  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:10:21.085743  6212 solver.cpp:237]     Train net output #1: loss = 0.140668 (* 1 = 0.140668 loss)
I0628 21:10:21.085743  6212 sgd_solver.cpp:105] Iteration 52800, lr = 0.0001
I0628 21:10:24.724455  6212 solver.cpp:218] Iteration 52900 (27.4858 iter/s, 3.63824s/100 iters), loss = 0.10174
I0628 21:10:24.724956  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:10:24.724956  6212 solver.cpp:237]     Train net output #1: loss = 0.10174 (* 1 = 0.10174 loss)
I0628 21:10:24.724956  6212 sgd_solver.cpp:105] Iteration 52900, lr = 0.0001
I0628 21:10:28.170073 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:10:28.313685  6212 solver.cpp:330] Iteration 53000, Testing net (#0)
I0628 21:10:28.313685  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:10:29.132105  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:10:29.163131  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8917
I0628 21:10:29.163131  6212 solver.cpp:397]     Test net output #1: loss = 0.353274 (* 1 = 0.353274 loss)
I0628 21:10:29.198153  6212 solver.cpp:218] Iteration 53000 (22.3572 iter/s, 4.47284s/100 iters), loss = 0.122617
I0628 21:10:29.198153  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:10:29.198153  6212 solver.cpp:237]     Train net output #1: loss = 0.122617 (* 1 = 0.122617 loss)
I0628 21:10:29.198153  6212 sgd_solver.cpp:105] Iteration 53000, lr = 0.0001
I0628 21:10:32.854305  6212 solver.cpp:218] Iteration 53100 (27.3504 iter/s, 3.65625s/100 iters), loss = 0.16192
I0628 21:10:32.854305  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:10:32.854305  6212 solver.cpp:237]     Train net output #1: loss = 0.16192 (* 1 = 0.16192 loss)
I0628 21:10:32.854305  6212 sgd_solver.cpp:105] Iteration 53100, lr = 0.0001
I0628 21:10:36.561383  6212 solver.cpp:218] Iteration 53200 (26.9792 iter/s, 3.70656s/100 iters), loss = 0.0773743
I0628 21:10:36.561383  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:10:36.561383  6212 solver.cpp:237]     Train net output #1: loss = 0.0773744 (* 1 = 0.0773744 loss)
I0628 21:10:36.561383  6212 sgd_solver.cpp:105] Iteration 53200, lr = 0.0001
I0628 21:10:40.258332  6212 solver.cpp:218] Iteration 53300 (27.048 iter/s, 3.69713s/100 iters), loss = 0.108164
I0628 21:10:40.258332  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:10:40.258332  6212 solver.cpp:237]     Train net output #1: loss = 0.108164 (* 1 = 0.108164 loss)
I0628 21:10:40.258332  6212 sgd_solver.cpp:105] Iteration 53300, lr = 0.0001
I0628 21:10:43.910940  6212 solver.cpp:218] Iteration 53400 (27.3842 iter/s, 3.65174s/100 iters), loss = 0.0795468
I0628 21:10:43.910940  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:10:43.910940  6212 solver.cpp:237]     Train net output #1: loss = 0.079547 (* 1 = 0.079547 loss)
I0628 21:10:43.910940  6212 sgd_solver.cpp:105] Iteration 53400, lr = 0.0001
I0628 21:10:47.370555 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:10:47.511658  6212 solver.cpp:330] Iteration 53500, Testing net (#0)
I0628 21:10:47.511658  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:10:48.343564  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:10:48.376088  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8927
I0628 21:10:48.376088  6212 solver.cpp:397]     Test net output #1: loss = 0.35356 (* 1 = 0.35356 loss)
I0628 21:10:48.411113  6212 solver.cpp:218] Iteration 53500 (22.2235 iter/s, 4.49974s/100 iters), loss = 0.0952352
I0628 21:10:48.411113  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:10:48.411113  6212 solver.cpp:237]     Train net output #1: loss = 0.0952352 (* 1 = 0.0952352 loss)
I0628 21:10:48.411113  6212 sgd_solver.cpp:105] Iteration 53500, lr = 0.0001
I0628 21:10:52.074868  6212 solver.cpp:218] Iteration 53600 (27.2944 iter/s, 3.66376s/100 iters), loss = 0.142517
I0628 21:10:52.075870  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:10:52.075870  6212 solver.cpp:237]     Train net output #1: loss = 0.142517 (* 1 = 0.142517 loss)
I0628 21:10:52.075870  6212 sgd_solver.cpp:105] Iteration 53600, lr = 0.0001
I0628 21:10:55.745729  6212 solver.cpp:218] Iteration 53700 (27.25 iter/s, 3.66973s/100 iters), loss = 0.102496
I0628 21:10:55.745729  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:10:55.745729  6212 solver.cpp:237]     Train net output #1: loss = 0.102496 (* 1 = 0.102496 loss)
I0628 21:10:55.745729  6212 sgd_solver.cpp:105] Iteration 53700, lr = 0.0001
I0628 21:10:59.376468  6212 solver.cpp:218] Iteration 53800 (27.5439 iter/s, 3.63056s/100 iters), loss = 0.122964
I0628 21:10:59.376468  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:10:59.376468  6212 solver.cpp:237]     Train net output #1: loss = 0.122964 (* 1 = 0.122964 loss)
I0628 21:10:59.376468  6212 sgd_solver.cpp:105] Iteration 53800, lr = 0.0001
I0628 21:11:03.037546  6212 solver.cpp:218] Iteration 53900 (27.3154 iter/s, 3.66094s/100 iters), loss = 0.121008
I0628 21:11:03.037546  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:11:03.037546  6212 solver.cpp:237]     Train net output #1: loss = 0.121008 (* 1 = 0.121008 loss)
I0628 21:11:03.037546  6212 sgd_solver.cpp:105] Iteration 53900, lr = 0.0001
I0628 21:11:06.476155 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:11:06.617257  6212 solver.cpp:330] Iteration 54000, Testing net (#0)
I0628 21:11:06.618258  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:11:07.437891  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:11:07.469415  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8924
I0628 21:11:07.469415  6212 solver.cpp:397]     Test net output #1: loss = 0.354142 (* 1 = 0.354142 loss)
I0628 21:11:07.502941  6212 solver.cpp:218] Iteration 54000 (22.3958 iter/s, 4.46512s/100 iters), loss = 0.150811
I0628 21:11:07.502941  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:11:07.502941  6212 solver.cpp:237]     Train net output #1: loss = 0.150811 (* 1 = 0.150811 loss)
I0628 21:11:07.502941  6212 sgd_solver.cpp:46] MultiStep Status: Iteration 54000, step = 3
I0628 21:11:07.502941  6212 sgd_solver.cpp:105] Iteration 54000, lr = 1e-05
I0628 21:11:11.136471  6212 solver.cpp:218] Iteration 54100 (27.5236 iter/s, 3.63325s/100 iters), loss = 0.125642
I0628 21:11:11.136471  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:11:11.136471  6212 solver.cpp:237]     Train net output #1: loss = 0.125642 (* 1 = 0.125642 loss)
I0628 21:11:11.136471  6212 sgd_solver.cpp:105] Iteration 54100, lr = 1e-05
I0628 21:11:14.803061  6212 solver.cpp:218] Iteration 54200 (27.2791 iter/s, 3.66581s/100 iters), loss = 0.101224
I0628 21:11:14.803061  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:11:14.803061  6212 solver.cpp:237]     Train net output #1: loss = 0.101224 (* 1 = 0.101224 loss)
I0628 21:11:14.803061  6212 sgd_solver.cpp:105] Iteration 54200, lr = 1e-05
I0628 21:11:18.533335  6212 solver.cpp:218] Iteration 54300 (26.8114 iter/s, 3.72976s/100 iters), loss = 0.127892
I0628 21:11:18.533335  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:11:18.533335  6212 solver.cpp:237]     Train net output #1: loss = 0.127892 (* 1 = 0.127892 loss)
I0628 21:11:18.533335  6212 sgd_solver.cpp:105] Iteration 54300, lr = 1e-05
I0628 21:11:22.224555  6212 solver.cpp:218] Iteration 54400 (27.0919 iter/s, 3.69113s/100 iters), loss = 0.104118
I0628 21:11:22.224555  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:11:22.224555  6212 solver.cpp:237]     Train net output #1: loss = 0.104118 (* 1 = 0.104118 loss)
I0628 21:11:22.224555  6212 sgd_solver.cpp:105] Iteration 54400, lr = 1e-05
I0628 21:11:25.767194 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:11:25.918123  6212 solver.cpp:330] Iteration 54500, Testing net (#0)
I0628 21:11:25.918123  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:11:26.750762  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:11:26.776310  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8917
I0628 21:11:26.776310  6212 solver.cpp:397]     Test net output #1: loss = 0.354033 (* 1 = 0.354033 loss)
I0628 21:11:26.813328  6212 solver.cpp:218] Iteration 54500 (21.795 iter/s, 4.5882s/100 iters), loss = 0.127706
I0628 21:11:26.813328  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:11:26.813328  6212 solver.cpp:237]     Train net output #1: loss = 0.127706 (* 1 = 0.127706 loss)
I0628 21:11:26.813328  6212 sgd_solver.cpp:105] Iteration 54500, lr = 1e-05
I0628 21:11:30.551903  6212 solver.cpp:218] Iteration 54600 (26.7523 iter/s, 3.73799s/100 iters), loss = 0.179584
I0628 21:11:30.551903  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:11:30.551903  6212 solver.cpp:237]     Train net output #1: loss = 0.179584 (* 1 = 0.179584 loss)
I0628 21:11:30.551903  6212 sgd_solver.cpp:105] Iteration 54600, lr = 1e-05
I0628 21:11:34.185469  6212 solver.cpp:218] Iteration 54700 (27.5192 iter/s, 3.63383s/100 iters), loss = 0.140208
I0628 21:11:34.185469  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:11:34.185469  6212 solver.cpp:237]     Train net output #1: loss = 0.140208 (* 1 = 0.140208 loss)
I0628 21:11:34.185469  6212 sgd_solver.cpp:105] Iteration 54700, lr = 1e-05
I0628 21:11:37.810375  6212 solver.cpp:218] Iteration 54800 (27.5896 iter/s, 3.62455s/100 iters), loss = 0.114437
I0628 21:11:37.810375  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:11:37.810375  6212 solver.cpp:237]     Train net output #1: loss = 0.114437 (* 1 = 0.114437 loss)
I0628 21:11:37.810375  6212 sgd_solver.cpp:105] Iteration 54800, lr = 1e-05
I0628 21:11:41.463924  6212 solver.cpp:218] Iteration 54900 (27.3761 iter/s, 3.65282s/100 iters), loss = 0.113841
I0628 21:11:41.463924  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:11:41.463924  6212 solver.cpp:237]     Train net output #1: loss = 0.113841 (* 1 = 0.113841 loss)
I0628 21:11:41.463924  6212 sgd_solver.cpp:105] Iteration 54900, lr = 1e-05
I0628 21:11:44.963001 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:11:45.104192  6212 solver.cpp:330] Iteration 55000, Testing net (#0)
I0628 21:11:45.104192  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:11:45.920677  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:11:45.951704  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8919
I0628 21:11:45.951704  6212 solver.cpp:397]     Test net output #1: loss = 0.353637 (* 1 = 0.353637 loss)
I0628 21:11:45.986722  6212 solver.cpp:218] Iteration 55000 (22.113 iter/s, 4.52223s/100 iters), loss = 0.0994276
I0628 21:11:45.986722  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:11:45.986722  6212 solver.cpp:237]     Train net output #1: loss = 0.0994277 (* 1 = 0.0994277 loss)
I0628 21:11:45.986722  6212 sgd_solver.cpp:105] Iteration 55000, lr = 1e-05
I0628 21:11:49.606537  6212 solver.cpp:218] Iteration 55100 (27.6298 iter/s, 3.61929s/100 iters), loss = 0.168563
I0628 21:11:49.606537  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:11:49.606537  6212 solver.cpp:237]     Train net output #1: loss = 0.168563 (* 1 = 0.168563 loss)
I0628 21:11:49.606537  6212 sgd_solver.cpp:105] Iteration 55100, lr = 1e-05
I0628 21:11:53.234602  6212 solver.cpp:218] Iteration 55200 (27.5636 iter/s, 3.62798s/100 iters), loss = 0.111191
I0628 21:11:53.234602  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:11:53.234602  6212 solver.cpp:237]     Train net output #1: loss = 0.111191 (* 1 = 0.111191 loss)
I0628 21:11:53.234602  6212 sgd_solver.cpp:105] Iteration 55200, lr = 1e-05
I0628 21:11:56.906785  6212 solver.cpp:218] Iteration 55300 (27.2357 iter/s, 3.67165s/100 iters), loss = 0.16093
I0628 21:11:56.906785  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:11:56.906785  6212 solver.cpp:237]     Train net output #1: loss = 0.16093 (* 1 = 0.16093 loss)
I0628 21:11:56.906785  6212 sgd_solver.cpp:105] Iteration 55300, lr = 1e-05
I0628 21:12:00.824183  6212 solver.cpp:218] Iteration 55400 (25.5288 iter/s, 3.91714s/100 iters), loss = 0.115419
I0628 21:12:00.824183  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:12:00.824183  6212 solver.cpp:237]     Train net output #1: loss = 0.115419 (* 1 = 0.115419 loss)
I0628 21:12:00.824183  6212 sgd_solver.cpp:105] Iteration 55400, lr = 1e-05
I0628 21:12:04.284267 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:12:04.427556  6212 solver.cpp:330] Iteration 55500, Testing net (#0)
I0628 21:12:04.427556  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:12:05.262042  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:12:05.293063  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I0628 21:12:05.293063  6212 solver.cpp:397]     Test net output #1: loss = 0.353979 (* 1 = 0.353979 loss)
I0628 21:12:05.327601  6212 solver.cpp:218] Iteration 55500 (22.2039 iter/s, 4.50372s/100 iters), loss = 0.172546
I0628 21:12:05.327601  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:12:05.327601  6212 solver.cpp:237]     Train net output #1: loss = 0.172546 (* 1 = 0.172546 loss)
I0628 21:12:05.327601  6212 sgd_solver.cpp:105] Iteration 55500, lr = 1e-05
I0628 21:12:09.302247  6212 solver.cpp:218] Iteration 55600 (25.1681 iter/s, 3.97329s/100 iters), loss = 0.124276
I0628 21:12:09.302247  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:12:09.302247  6212 solver.cpp:237]     Train net output #1: loss = 0.124276 (* 1 = 0.124276 loss)
I0628 21:12:09.302247  6212 sgd_solver.cpp:105] Iteration 55600, lr = 1e-05
I0628 21:12:12.963495  6212 solver.cpp:218] Iteration 55700 (27.3123 iter/s, 3.66136s/100 iters), loss = 0.102313
I0628 21:12:12.964013  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:12:12.964013  6212 solver.cpp:237]     Train net output #1: loss = 0.102313 (* 1 = 0.102313 loss)
I0628 21:12:12.964013  6212 sgd_solver.cpp:105] Iteration 55700, lr = 1e-05
I0628 21:12:16.587621  6212 solver.cpp:218] Iteration 55800 (27.5961 iter/s, 3.62371s/100 iters), loss = 0.151212
I0628 21:12:16.587621  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:12:16.587621  6212 solver.cpp:237]     Train net output #1: loss = 0.151212 (* 1 = 0.151212 loss)
I0628 21:12:16.587621  6212 sgd_solver.cpp:105] Iteration 55800, lr = 1e-05
I0628 21:12:20.225847  6212 solver.cpp:218] Iteration 55900 (27.4873 iter/s, 3.63804s/100 iters), loss = 0.119519
I0628 21:12:20.225847  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:12:20.225847  6212 solver.cpp:237]     Train net output #1: loss = 0.119519 (* 1 = 0.119519 loss)
I0628 21:12:20.225847  6212 sgd_solver.cpp:105] Iteration 55900, lr = 1e-05
I0628 21:12:23.688760 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:12:23.830409  6212 solver.cpp:330] Iteration 56000, Testing net (#0)
I0628 21:12:23.830409  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:12:24.648720  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:12:24.679735  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 21:12:24.679735  6212 solver.cpp:397]     Test net output #1: loss = 0.354288 (* 1 = 0.354288 loss)
I0628 21:12:24.714334  6212 solver.cpp:218] Iteration 56000 (22.2823 iter/s, 4.48787s/100 iters), loss = 0.108619
I0628 21:12:24.714334  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:12:24.714334  6212 solver.cpp:237]     Train net output #1: loss = 0.108619 (* 1 = 0.108619 loss)
I0628 21:12:24.714334  6212 sgd_solver.cpp:105] Iteration 56000, lr = 1e-05
I0628 21:12:28.355871  6212 solver.cpp:218] Iteration 56100 (27.4664 iter/s, 3.64082s/100 iters), loss = 0.0986524
I0628 21:12:28.355871  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:12:28.355871  6212 solver.cpp:237]     Train net output #1: loss = 0.0986524 (* 1 = 0.0986524 loss)
I0628 21:12:28.355871  6212 sgd_solver.cpp:105] Iteration 56100, lr = 1e-05
I0628 21:12:31.975881  6212 solver.cpp:218] Iteration 56200 (27.6201 iter/s, 3.62055s/100 iters), loss = 0.115061
I0628 21:12:31.976887  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:12:31.976887  6212 solver.cpp:237]     Train net output #1: loss = 0.115061 (* 1 = 0.115061 loss)
I0628 21:12:31.976887  6212 sgd_solver.cpp:105] Iteration 56200, lr = 1e-05
I0628 21:12:35.604715  6212 solver.cpp:218] Iteration 56300 (27.5628 iter/s, 3.62808s/100 iters), loss = 0.152624
I0628 21:12:35.604715  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:12:35.604715  6212 solver.cpp:237]     Train net output #1: loss = 0.152624 (* 1 = 0.152624 loss)
I0628 21:12:35.604715  6212 sgd_solver.cpp:105] Iteration 56300, lr = 1e-05
I0628 21:12:39.221642  6212 solver.cpp:218] Iteration 56400 (27.6472 iter/s, 3.617s/100 iters), loss = 0.0776669
I0628 21:12:39.222651  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:12:39.222651  6212 solver.cpp:237]     Train net output #1: loss = 0.0776669 (* 1 = 0.0776669 loss)
I0628 21:12:39.222651  6212 sgd_solver.cpp:105] Iteration 56400, lr = 1e-05
I0628 21:12:42.670183 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:12:42.811929  6212 solver.cpp:330] Iteration 56500, Testing net (#0)
I0628 21:12:42.811929  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:12:43.630121  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:12:43.661144  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8924
I0628 21:12:43.661144  6212 solver.cpp:397]     Test net output #1: loss = 0.353646 (* 1 = 0.353646 loss)
I0628 21:12:43.695179  6212 solver.cpp:218] Iteration 56500 (22.3575 iter/s, 4.47277s/100 iters), loss = 0.0745317
I0628 21:12:43.695179  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:12:43.695179  6212 solver.cpp:237]     Train net output #1: loss = 0.0745316 (* 1 = 0.0745316 loss)
I0628 21:12:43.695179  6212 sgd_solver.cpp:105] Iteration 56500, lr = 1e-05
I0628 21:12:47.310425  6212 solver.cpp:218] Iteration 56600 (27.662 iter/s, 3.61507s/100 iters), loss = 0.118083
I0628 21:12:47.310425  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:12:47.310425  6212 solver.cpp:237]     Train net output #1: loss = 0.118083 (* 1 = 0.118083 loss)
I0628 21:12:47.310425  6212 sgd_solver.cpp:105] Iteration 56600, lr = 1e-05
I0628 21:12:50.926288  6212 solver.cpp:218] Iteration 56700 (27.6572 iter/s, 3.6157s/100 iters), loss = 0.115312
I0628 21:12:50.926288  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:12:50.926288  6212 solver.cpp:237]     Train net output #1: loss = 0.115312 (* 1 = 0.115312 loss)
I0628 21:12:50.926288  6212 sgd_solver.cpp:105] Iteration 56700, lr = 1e-05
I0628 21:12:54.557956  6212 solver.cpp:218] Iteration 56800 (27.5434 iter/s, 3.63063s/100 iters), loss = 0.124683
I0628 21:12:54.557956  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:12:54.557956  6212 solver.cpp:237]     Train net output #1: loss = 0.124683 (* 1 = 0.124683 loss)
I0628 21:12:54.557956  6212 sgd_solver.cpp:105] Iteration 56800, lr = 1e-05
I0628 21:12:58.182638  6212 solver.cpp:218] Iteration 56900 (27.5865 iter/s, 3.62497s/100 iters), loss = 0.0847252
I0628 21:12:58.182638  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:12:58.182638  6212 solver.cpp:237]     Train net output #1: loss = 0.0847251 (* 1 = 0.0847251 loss)
I0628 21:12:58.182638  6212 sgd_solver.cpp:105] Iteration 56900, lr = 1e-05
I0628 21:13:01.622223 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:13:01.763327  6212 solver.cpp:330] Iteration 57000, Testing net (#0)
I0628 21:13:01.763327  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:13:02.579006  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:13:02.610033  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8917
I0628 21:13:02.610033  6212 solver.cpp:397]     Test net output #1: loss = 0.354264 (* 1 = 0.354264 loss)
I0628 21:13:02.644057  6212 solver.cpp:218] Iteration 57000 (22.4165 iter/s, 4.46099s/100 iters), loss = 0.102703
I0628 21:13:02.644057  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:13:02.644057  6212 solver.cpp:237]     Train net output #1: loss = 0.102703 (* 1 = 0.102703 loss)
I0628 21:13:02.644057  6212 sgd_solver.cpp:105] Iteration 57000, lr = 1e-05
I0628 21:13:06.263984  6212 solver.cpp:218] Iteration 57100 (27.6297 iter/s, 3.6193s/100 iters), loss = 0.138391
I0628 21:13:06.263984  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:13:06.263984  6212 solver.cpp:237]     Train net output #1: loss = 0.138391 (* 1 = 0.138391 loss)
I0628 21:13:06.263984  6212 sgd_solver.cpp:105] Iteration 57100, lr = 1e-05
I0628 21:13:09.881692  6212 solver.cpp:218] Iteration 57200 (27.6445 iter/s, 3.61735s/100 iters), loss = 0.106611
I0628 21:13:09.881692  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:13:09.881692  6212 solver.cpp:237]     Train net output #1: loss = 0.10661 (* 1 = 0.10661 loss)
I0628 21:13:09.881692  6212 sgd_solver.cpp:105] Iteration 57200, lr = 1e-05
I0628 21:13:13.489259  6212 solver.cpp:218] Iteration 57300 (27.7184 iter/s, 3.60772s/100 iters), loss = 0.102958
I0628 21:13:13.490260  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:13:13.490260  6212 solver.cpp:237]     Train net output #1: loss = 0.102958 (* 1 = 0.102958 loss)
I0628 21:13:13.490260  6212 sgd_solver.cpp:105] Iteration 57300, lr = 1e-05
I0628 21:13:17.114467  6212 solver.cpp:218] Iteration 57400 (27.5912 iter/s, 3.62434s/100 iters), loss = 0.0940306
I0628 21:13:17.114969  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:13:17.114969  6212 solver.cpp:237]     Train net output #1: loss = 0.0940305 (* 1 = 0.0940305 loss)
I0628 21:13:17.114969  6212 sgd_solver.cpp:105] Iteration 57400, lr = 1e-05
I0628 21:13:20.566802 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:13:20.707407  6212 solver.cpp:330] Iteration 57500, Testing net (#0)
I0628 21:13:20.707407  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:13:21.526396  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:13:21.557418  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8917
I0628 21:13:21.557418  6212 solver.cpp:397]     Test net output #1: loss = 0.35383 (* 1 = 0.35383 loss)
I0628 21:13:21.591442  6212 solver.cpp:218] Iteration 57500 (22.3365 iter/s, 4.47699s/100 iters), loss = 0.117874
I0628 21:13:21.591442  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:13:21.591442  6212 solver.cpp:237]     Train net output #1: loss = 0.117874 (* 1 = 0.117874 loss)
I0628 21:13:21.591442  6212 sgd_solver.cpp:105] Iteration 57500, lr = 1e-05
I0628 21:13:25.212596  6212 solver.cpp:218] Iteration 57600 (27.622 iter/s, 3.6203s/100 iters), loss = 0.0954663
I0628 21:13:25.212596  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:13:25.212596  6212 solver.cpp:237]     Train net output #1: loss = 0.0954663 (* 1 = 0.0954663 loss)
I0628 21:13:25.212596  6212 sgd_solver.cpp:105] Iteration 57600, lr = 1e-05
I0628 21:13:28.827682  6212 solver.cpp:218] Iteration 57700 (27.6616 iter/s, 3.61512s/100 iters), loss = 0.133575
I0628 21:13:28.827682  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:13:28.827682  6212 solver.cpp:237]     Train net output #1: loss = 0.133575 (* 1 = 0.133575 loss)
I0628 21:13:28.827682  6212 sgd_solver.cpp:105] Iteration 57700, lr = 1e-05
I0628 21:13:32.452271  6212 solver.cpp:218] Iteration 57800 (27.5972 iter/s, 3.62355s/100 iters), loss = 0.138047
I0628 21:13:32.452271  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:13:32.452271  6212 solver.cpp:237]     Train net output #1: loss = 0.138047 (* 1 = 0.138047 loss)
I0628 21:13:32.452271  6212 sgd_solver.cpp:105] Iteration 57800, lr = 1e-05
I0628 21:13:36.069866  6212 solver.cpp:218] Iteration 57900 (27.6434 iter/s, 3.6175s/100 iters), loss = 0.0579088
I0628 21:13:36.069866  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:13:36.069866  6212 solver.cpp:237]     Train net output #1: loss = 0.0579087 (* 1 = 0.0579087 loss)
I0628 21:13:36.069866  6212 sgd_solver.cpp:105] Iteration 57900, lr = 1e-05
I0628 21:13:39.509420 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:13:39.650527  6212 solver.cpp:330] Iteration 58000, Testing net (#0)
I0628 21:13:39.650527  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:13:40.470146  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:13:40.501168  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8919
I0628 21:13:40.501168  6212 solver.cpp:397]     Test net output #1: loss = 0.35354 (* 1 = 0.35354 loss)
I0628 21:13:40.535195  6212 solver.cpp:218] Iteration 58000 (22.3934 iter/s, 4.4656s/100 iters), loss = 0.0979202
I0628 21:13:40.536196  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:13:40.536196  6212 solver.cpp:237]     Train net output #1: loss = 0.0979202 (* 1 = 0.0979202 loss)
I0628 21:13:40.536196  6212 sgd_solver.cpp:105] Iteration 58000, lr = 1e-05
I0628 21:13:44.152377  6212 solver.cpp:218] Iteration 58100 (27.6495 iter/s, 3.6167s/100 iters), loss = 0.147452
I0628 21:13:44.152377  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:13:44.152377  6212 solver.cpp:237]     Train net output #1: loss = 0.147452 (* 1 = 0.147452 loss)
I0628 21:13:44.152377  6212 sgd_solver.cpp:105] Iteration 58100, lr = 1e-05
I0628 21:13:47.772161  6212 solver.cpp:218] Iteration 58200 (27.6322 iter/s, 3.61897s/100 iters), loss = 0.102302
I0628 21:13:47.772161  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:13:47.772161  6212 solver.cpp:237]     Train net output #1: loss = 0.102302 (* 1 = 0.102302 loss)
I0628 21:13:47.772161  6212 sgd_solver.cpp:105] Iteration 58200, lr = 1e-05
I0628 21:13:51.384198  6212 solver.cpp:218] Iteration 58300 (27.6893 iter/s, 3.61151s/100 iters), loss = 0.124819
I0628 21:13:51.384198  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:13:51.384198  6212 solver.cpp:237]     Train net output #1: loss = 0.124819 (* 1 = 0.124819 loss)
I0628 21:13:51.384198  6212 sgd_solver.cpp:105] Iteration 58300, lr = 1e-05
I0628 21:13:55.002146  6212 solver.cpp:218] Iteration 58400 (27.6441 iter/s, 3.61741s/100 iters), loss = 0.10339
I0628 21:13:55.002146  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:13:55.002146  6212 solver.cpp:237]     Train net output #1: loss = 0.10339 (* 1 = 0.10339 loss)
I0628 21:13:55.002146  6212 sgd_solver.cpp:105] Iteration 58400, lr = 1e-05
I0628 21:13:58.458396 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:13:58.602502  6212 solver.cpp:330] Iteration 58500, Testing net (#0)
I0628 21:13:58.602502  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:13:59.423269  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:13:59.454291  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8928
I0628 21:13:59.454291  6212 solver.cpp:397]     Test net output #1: loss = 0.353215 (* 1 = 0.353215 loss)
I0628 21:13:59.488314  6212 solver.cpp:218] Iteration 58500 (22.2877 iter/s, 4.48677s/100 iters), loss = 0.123512
I0628 21:13:59.489315  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:13:59.489315  6212 solver.cpp:237]     Train net output #1: loss = 0.123512 (* 1 = 0.123512 loss)
I0628 21:13:59.489315  6212 sgd_solver.cpp:105] Iteration 58500, lr = 1e-05
I0628 21:14:03.112308  6212 solver.cpp:218] Iteration 58600 (27.602 iter/s, 3.62293s/100 iters), loss = 0.0778378
I0628 21:14:03.112308  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:14:03.112308  6212 solver.cpp:237]     Train net output #1: loss = 0.0778378 (* 1 = 0.0778378 loss)
I0628 21:14:03.112308  6212 sgd_solver.cpp:105] Iteration 58600, lr = 1e-05
I0628 21:14:06.720881  6212 solver.cpp:218] Iteration 58700 (27.7114 iter/s, 3.60862s/100 iters), loss = 0.121379
I0628 21:14:06.720881  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:14:06.720881  6212 solver.cpp:237]     Train net output #1: loss = 0.121379 (* 1 = 0.121379 loss)
I0628 21:14:06.720881  6212 sgd_solver.cpp:105] Iteration 58700, lr = 1e-05
I0628 21:14:10.369643  6212 solver.cpp:218] Iteration 58800 (27.4093 iter/s, 3.64839s/100 iters), loss = 0.135151
I0628 21:14:10.369643  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:14:10.369643  6212 solver.cpp:237]     Train net output #1: loss = 0.135151 (* 1 = 0.135151 loss)
I0628 21:14:10.369643  6212 sgd_solver.cpp:105] Iteration 58800, lr = 1e-05
I0628 21:14:14.020370  6212 solver.cpp:218] Iteration 58900 (27.3993 iter/s, 3.64972s/100 iters), loss = 0.171751
I0628 21:14:14.020370  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:14:14.020370  6212 solver.cpp:237]     Train net output #1: loss = 0.171751 (* 1 = 0.171751 loss)
I0628 21:14:14.020370  6212 sgd_solver.cpp:105] Iteration 58900, lr = 1e-05
I0628 21:14:17.479028 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:14:17.620635  6212 solver.cpp:330] Iteration 59000, Testing net (#0)
I0628 21:14:17.620635  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:14:18.444761  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:14:18.475781  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8914
I0628 21:14:18.475781  6212 solver.cpp:397]     Test net output #1: loss = 0.353292 (* 1 = 0.353292 loss)
I0628 21:14:18.510807  6212 solver.cpp:218] Iteration 59000 (22.2705 iter/s, 4.49025s/100 iters), loss = 0.0962612
I0628 21:14:18.510807  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:14:18.510807  6212 solver.cpp:237]     Train net output #1: loss = 0.0962612 (* 1 = 0.0962612 loss)
I0628 21:14:18.510807  6212 sgd_solver.cpp:105] Iteration 59000, lr = 1e-05
I0628 21:14:22.136301  6212 solver.cpp:218] Iteration 59100 (27.581 iter/s, 3.62568s/100 iters), loss = 0.167485
I0628 21:14:22.136301  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:14:22.136301  6212 solver.cpp:237]     Train net output #1: loss = 0.167485 (* 1 = 0.167485 loss)
I0628 21:14:22.136301  6212 sgd_solver.cpp:105] Iteration 59100, lr = 1e-05
I0628 21:14:25.754998  6212 solver.cpp:218] Iteration 59200 (27.6408 iter/s, 3.61784s/100 iters), loss = 0.156743
I0628 21:14:25.754998  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:14:25.754998  6212 solver.cpp:237]     Train net output #1: loss = 0.156743 (* 1 = 0.156743 loss)
I0628 21:14:25.754998  6212 sgd_solver.cpp:105] Iteration 59200, lr = 1e-05
I0628 21:14:29.381726  6212 solver.cpp:218] Iteration 59300 (27.572 iter/s, 3.62687s/100 iters), loss = 0.0999171
I0628 21:14:29.381726  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:14:29.381726  6212 solver.cpp:237]     Train net output #1: loss = 0.099917 (* 1 = 0.099917 loss)
I0628 21:14:29.381726  6212 sgd_solver.cpp:105] Iteration 59300, lr = 1e-05
I0628 21:14:32.996413  6212 solver.cpp:218] Iteration 59400 (27.6721 iter/s, 3.61375s/100 iters), loss = 0.113416
I0628 21:14:32.996413  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:14:32.996413  6212 solver.cpp:237]     Train net output #1: loss = 0.113416 (* 1 = 0.113416 loss)
I0628 21:14:32.996413  6212 sgd_solver.cpp:105] Iteration 59400, lr = 1e-05
I0628 21:14:36.442181 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:14:36.583287  6212 solver.cpp:330] Iteration 59500, Testing net (#0)
I0628 21:14:36.583287  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:14:37.402098  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:14:37.433123  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 21:14:37.433123  6212 solver.cpp:397]     Test net output #1: loss = 0.353404 (* 1 = 0.353404 loss)
I0628 21:14:37.467149  6212 solver.cpp:218] Iteration 59500 (22.3701 iter/s, 4.47026s/100 iters), loss = 0.1222
I0628 21:14:37.467149  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:14:37.467149  6212 solver.cpp:237]     Train net output #1: loss = 0.1222 (* 1 = 0.1222 loss)
I0628 21:14:37.467149  6212 sgd_solver.cpp:105] Iteration 59500, lr = 1e-05
I0628 21:14:41.085875  6212 solver.cpp:218] Iteration 59600 (27.6327 iter/s, 3.61889s/100 iters), loss = 0.167433
I0628 21:14:41.085875  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:14:41.085875  6212 solver.cpp:237]     Train net output #1: loss = 0.167433 (* 1 = 0.167433 loss)
I0628 21:14:41.085875  6212 sgd_solver.cpp:105] Iteration 59600, lr = 1e-05
I0628 21:14:44.703570  6212 solver.cpp:218] Iteration 59700 (27.6485 iter/s, 3.61683s/100 iters), loss = 0.141388
I0628 21:14:44.703570  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:14:44.703570  6212 solver.cpp:237]     Train net output #1: loss = 0.141387 (* 1 = 0.141387 loss)
I0628 21:14:44.703570  6212 sgd_solver.cpp:105] Iteration 59700, lr = 1e-05
I0628 21:14:48.342197  6212 solver.cpp:218] Iteration 59800 (27.4834 iter/s, 3.63856s/100 iters), loss = 0.140158
I0628 21:14:48.342197  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:14:48.342197  6212 solver.cpp:237]     Train net output #1: loss = 0.140158 (* 1 = 0.140158 loss)
I0628 21:14:48.342197  6212 sgd_solver.cpp:105] Iteration 59800, lr = 1e-05
I0628 21:14:52.012372  6212 solver.cpp:218] Iteration 59900 (27.2488 iter/s, 3.66988s/100 iters), loss = 0.115931
I0628 21:14:52.012372  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:14:52.012872  6212 solver.cpp:237]     Train net output #1: loss = 0.115931 (* 1 = 0.115931 loss)
I0628 21:14:52.012872  6212 sgd_solver.cpp:105] Iteration 59900, lr = 1e-05
I0628 21:14:55.501626 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:14:55.644727  6212 solver.cpp:330] Iteration 60000, Testing net (#0)
I0628 21:14:55.644727  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:14:56.464810  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:14:56.495332  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 21:14:56.495332  6212 solver.cpp:397]     Test net output #1: loss = 0.354077 (* 1 = 0.354077 loss)
I0628 21:14:56.529857  6212 solver.cpp:218] Iteration 60000 (22.1396 iter/s, 4.51679s/100 iters), loss = 0.0560478
I0628 21:14:56.529857  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:14:56.529857  6212 solver.cpp:237]     Train net output #1: loss = 0.0560478 (* 1 = 0.0560478 loss)
I0628 21:14:56.529857  6212 sgd_solver.cpp:105] Iteration 60000, lr = 1e-05
I0628 21:15:00.167573  6212 solver.cpp:218] Iteration 60100 (27.492 iter/s, 3.63743s/100 iters), loss = 0.183964
I0628 21:15:00.167573  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:15:00.167573  6212 solver.cpp:237]     Train net output #1: loss = 0.183964 (* 1 = 0.183964 loss)
I0628 21:15:00.167573  6212 sgd_solver.cpp:105] Iteration 60100, lr = 1e-05
I0628 21:15:03.811655  6212 solver.cpp:218] Iteration 60200 (27.4445 iter/s, 3.64372s/100 iters), loss = 0.108987
I0628 21:15:03.811655  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:15:03.811655  6212 solver.cpp:237]     Train net output #1: loss = 0.108987 (* 1 = 0.108987 loss)
I0628 21:15:03.811655  6212 sgd_solver.cpp:105] Iteration 60200, lr = 1e-05
I0628 21:15:07.454582  6212 solver.cpp:218] Iteration 60300 (27.4529 iter/s, 3.6426s/100 iters), loss = 0.156993
I0628 21:15:07.454582  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:15:07.454582  6212 solver.cpp:237]     Train net output #1: loss = 0.156993 (* 1 = 0.156993 loss)
I0628 21:15:07.454582  6212 sgd_solver.cpp:105] Iteration 60300, lr = 1e-05
I0628 21:15:11.103178  6212 solver.cpp:218] Iteration 60400 (27.4101 iter/s, 3.64828s/100 iters), loss = 0.0698164
I0628 21:15:11.103178  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:15:11.103178  6212 solver.cpp:237]     Train net output #1: loss = 0.0698165 (* 1 = 0.0698165 loss)
I0628 21:15:11.103178  6212 sgd_solver.cpp:105] Iteration 60400, lr = 1e-05
I0628 21:15:14.562680 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:15:14.704278  6212 solver.cpp:330] Iteration 60500, Testing net (#0)
I0628 21:15:14.704278  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:15:15.512354  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:15:15.543377  6212 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0628 21:15:15.543377  6212 solver.cpp:397]     Test net output #1: loss = 0.353698 (* 1 = 0.353698 loss)
I0628 21:15:15.577401  6212 solver.cpp:218] Iteration 60500 (22.3523 iter/s, 4.47381s/100 iters), loss = 0.0897166
I0628 21:15:15.577401  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:15:15.577401  6212 solver.cpp:237]     Train net output #1: loss = 0.0897166 (* 1 = 0.0897166 loss)
I0628 21:15:15.577401  6212 sgd_solver.cpp:105] Iteration 60500, lr = 1e-05
I0628 21:15:19.223964  6212 solver.cpp:218] Iteration 60600 (27.4245 iter/s, 3.64637s/100 iters), loss = 0.166196
I0628 21:15:19.223964  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:15:19.223964  6212 solver.cpp:237]     Train net output #1: loss = 0.166196 (* 1 = 0.166196 loss)
I0628 21:15:19.223964  6212 sgd_solver.cpp:105] Iteration 60600, lr = 1e-05
I0628 21:15:22.911502  6212 solver.cpp:218] Iteration 60700 (27.1206 iter/s, 3.68724s/100 iters), loss = 0.125023
I0628 21:15:22.911502  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:15:22.911502  6212 solver.cpp:237]     Train net output #1: loss = 0.125024 (* 1 = 0.125024 loss)
I0628 21:15:22.912003  6212 sgd_solver.cpp:105] Iteration 60700, lr = 1e-05
I0628 21:15:26.550114  6212 solver.cpp:218] Iteration 60800 (27.4869 iter/s, 3.6381s/100 iters), loss = 0.165961
I0628 21:15:26.550114  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:15:26.550114  6212 solver.cpp:237]     Train net output #1: loss = 0.165962 (* 1 = 0.165962 loss)
I0628 21:15:26.550114  6212 sgd_solver.cpp:105] Iteration 60800, lr = 1e-05
I0628 21:15:30.182304  6212 solver.cpp:218] Iteration 60900 (27.5365 iter/s, 3.63154s/100 iters), loss = 0.0936333
I0628 21:15:30.182304  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:15:30.182304  6212 solver.cpp:237]     Train net output #1: loss = 0.0936334 (* 1 = 0.0936334 loss)
I0628 21:15:30.182304  6212 sgd_solver.cpp:105] Iteration 60900, lr = 1e-05
I0628 21:15:33.672304 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:15:33.815917  6212 solver.cpp:330] Iteration 61000, Testing net (#0)
I0628 21:15:33.815917  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:15:34.636492  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:15:34.667529  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8919
I0628 21:15:34.667529  6212 solver.cpp:397]     Test net output #1: loss = 0.353718 (* 1 = 0.353718 loss)
I0628 21:15:34.701550  6212 solver.cpp:218] Iteration 61000 (22.1292 iter/s, 4.51892s/100 iters), loss = 0.0681368
I0628 21:15:34.701550  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 21:15:34.701550  6212 solver.cpp:237]     Train net output #1: loss = 0.0681369 (* 1 = 0.0681369 loss)
I0628 21:15:34.701550  6212 sgd_solver.cpp:105] Iteration 61000, lr = 1e-05
I0628 21:15:38.361336  6212 solver.cpp:218] Iteration 61100 (27.3252 iter/s, 3.65963s/100 iters), loss = 0.0826823
I0628 21:15:38.361336  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:15:38.361336  6212 solver.cpp:237]     Train net output #1: loss = 0.0826823 (* 1 = 0.0826823 loss)
I0628 21:15:38.361336  6212 sgd_solver.cpp:105] Iteration 61100, lr = 1e-05
I0628 21:15:42.034934  6212 solver.cpp:218] Iteration 61200 (27.2265 iter/s, 3.6729s/100 iters), loss = 0.094201
I0628 21:15:42.034934  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:15:42.034934  6212 solver.cpp:237]     Train net output #1: loss = 0.0942011 (* 1 = 0.0942011 loss)
I0628 21:15:42.034934  6212 sgd_solver.cpp:105] Iteration 61200, lr = 1e-05
I0628 21:15:45.686533  6212 solver.cpp:218] Iteration 61300 (27.3847 iter/s, 3.65168s/100 iters), loss = 0.136791
I0628 21:15:45.687034  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:15:45.687034  6212 solver.cpp:237]     Train net output #1: loss = 0.136791 (* 1 = 0.136791 loss)
I0628 21:15:45.687034  6212 sgd_solver.cpp:105] Iteration 61300, lr = 1e-05
I0628 21:15:49.376164  6212 solver.cpp:218] Iteration 61400 (27.1076 iter/s, 3.689s/100 iters), loss = 0.112283
I0628 21:15:49.376164  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:15:49.376164  6212 solver.cpp:237]     Train net output #1: loss = 0.112283 (* 1 = 0.112283 loss)
I0628 21:15:49.376164  6212 sgd_solver.cpp:105] Iteration 61400, lr = 1e-05
I0628 21:15:52.829622 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:15:52.972223  6212 solver.cpp:330] Iteration 61500, Testing net (#0)
I0628 21:15:52.972223  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:15:53.793807  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:15:53.824831  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 21:15:53.824831  6212 solver.cpp:397]     Test net output #1: loss = 0.35387 (* 1 = 0.35387 loss)
I0628 21:15:53.859354  6212 solver.cpp:218] Iteration 61500 (22.3079 iter/s, 4.48271s/100 iters), loss = 0.0797262
I0628 21:15:53.859354  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:15:53.859354  6212 solver.cpp:237]     Train net output #1: loss = 0.0797263 (* 1 = 0.0797263 loss)
I0628 21:15:53.859354  6212 sgd_solver.cpp:105] Iteration 61500, lr = 1e-05
I0628 21:15:57.495942  6212 solver.cpp:218] Iteration 61600 (27.5031 iter/s, 3.63596s/100 iters), loss = 0.118461
I0628 21:15:57.495942  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:15:57.495942  6212 solver.cpp:237]     Train net output #1: loss = 0.118462 (* 1 = 0.118462 loss)
I0628 21:15:57.495942  6212 sgd_solver.cpp:105] Iteration 61600, lr = 1e-05
I0628 21:16:01.124023  6212 solver.cpp:218] Iteration 61700 (27.5643 iter/s, 3.62788s/100 iters), loss = 0.11733
I0628 21:16:01.124023  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:16:01.124023  6212 solver.cpp:237]     Train net output #1: loss = 0.11733 (* 1 = 0.11733 loss)
I0628 21:16:01.124023  6212 sgd_solver.cpp:105] Iteration 61700, lr = 1e-05
I0628 21:16:04.778638  6212 solver.cpp:218] Iteration 61800 (27.3674 iter/s, 3.65398s/100 iters), loss = 0.145185
I0628 21:16:04.778638  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:16:04.778638  6212 solver.cpp:237]     Train net output #1: loss = 0.145185 (* 1 = 0.145185 loss)
I0628 21:16:04.778638  6212 sgd_solver.cpp:105] Iteration 61800, lr = 1e-05
I0628 21:16:08.418228  6212 solver.cpp:218] Iteration 61900 (27.475 iter/s, 3.63967s/100 iters), loss = 0.0688112
I0628 21:16:08.418228  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:16:08.418728  6212 solver.cpp:237]     Train net output #1: loss = 0.0688113 (* 1 = 0.0688113 loss)
I0628 21:16:08.418728  6212 sgd_solver.cpp:105] Iteration 61900, lr = 1e-05
I0628 21:16:11.864030 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:16:12.005631  6212 solver.cpp:330] Iteration 62000, Testing net (#0)
I0628 21:16:12.006130  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:16:12.817767  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:16:12.848275  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8924
I0628 21:16:12.848275  6212 solver.cpp:397]     Test net output #1: loss = 0.35299 (* 1 = 0.35299 loss)
I0628 21:16:12.881798  6212 solver.cpp:218] Iteration 62000 (22.4065 iter/s, 4.46298s/100 iters), loss = 0.105352
I0628 21:16:12.881798  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:16:12.881798  6212 solver.cpp:237]     Train net output #1: loss = 0.105352 (* 1 = 0.105352 loss)
I0628 21:16:12.881798  6212 sgd_solver.cpp:105] Iteration 62000, lr = 1e-05
I0628 21:16:16.499016  6212 solver.cpp:218] Iteration 62100 (27.6465 iter/s, 3.6171s/100 iters), loss = 0.166339
I0628 21:16:16.499016  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:16:16.499016  6212 solver.cpp:237]     Train net output #1: loss = 0.166339 (* 1 = 0.166339 loss)
I0628 21:16:16.499016  6212 sgd_solver.cpp:105] Iteration 62100, lr = 1e-05
I0628 21:16:20.112412  6212 solver.cpp:218] Iteration 62200 (27.6791 iter/s, 3.61284s/100 iters), loss = 0.0922931
I0628 21:16:20.112412  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:16:20.112412  6212 solver.cpp:237]     Train net output #1: loss = 0.0922932 (* 1 = 0.0922932 loss)
I0628 21:16:20.112412  6212 sgd_solver.cpp:105] Iteration 62200, lr = 1e-05
I0628 21:16:23.730474  6212 solver.cpp:218] Iteration 62300 (27.6424 iter/s, 3.61764s/100 iters), loss = 0.109328
I0628 21:16:23.730474  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:16:23.730474  6212 solver.cpp:237]     Train net output #1: loss = 0.109328 (* 1 = 0.109328 loss)
I0628 21:16:23.730474  6212 sgd_solver.cpp:105] Iteration 62300, lr = 1e-05
I0628 21:16:27.344676  6212 solver.cpp:218] Iteration 62400 (27.6687 iter/s, 3.61419s/100 iters), loss = 0.116282
I0628 21:16:27.345176  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:16:27.345176  6212 solver.cpp:237]     Train net output #1: loss = 0.116282 (* 1 = 0.116282 loss)
I0628 21:16:27.345176  6212 sgd_solver.cpp:105] Iteration 62400, lr = 1e-05
I0628 21:16:30.775688 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:16:30.916790  6212 solver.cpp:330] Iteration 62500, Testing net (#0)
I0628 21:16:30.916790  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:16:31.730406  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:16:31.761430  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 21:16:31.761430  6212 solver.cpp:397]     Test net output #1: loss = 0.353199 (* 1 = 0.353199 loss)
I0628 21:16:31.796454  6212 solver.cpp:218] Iteration 62500 (22.4667 iter/s, 4.45103s/100 iters), loss = 0.123553
I0628 21:16:31.796454  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:16:31.796454  6212 solver.cpp:237]     Train net output #1: loss = 0.123553 (* 1 = 0.123553 loss)
I0628 21:16:31.796454  6212 sgd_solver.cpp:105] Iteration 62500, lr = 1e-05
I0628 21:16:35.425056  6212 solver.cpp:218] Iteration 62600 (27.56 iter/s, 3.62845s/100 iters), loss = 0.125107
I0628 21:16:35.425056  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:16:35.425056  6212 solver.cpp:237]     Train net output #1: loss = 0.125107 (* 1 = 0.125107 loss)
I0628 21:16:35.425056  6212 sgd_solver.cpp:105] Iteration 62600, lr = 1e-05
I0628 21:16:39.033000  6212 solver.cpp:218] Iteration 62700 (27.7213 iter/s, 3.60734s/100 iters), loss = 0.096498
I0628 21:16:39.033000  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:16:39.033000  6212 solver.cpp:237]     Train net output #1: loss = 0.0964981 (* 1 = 0.0964981 loss)
I0628 21:16:39.033000  6212 sgd_solver.cpp:105] Iteration 62700, lr = 1e-05
I0628 21:16:42.654165  6212 solver.cpp:218] Iteration 62800 (27.6162 iter/s, 3.62107s/100 iters), loss = 0.0940113
I0628 21:16:42.654165  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:16:42.654165  6212 solver.cpp:237]     Train net output #1: loss = 0.0940114 (* 1 = 0.0940114 loss)
I0628 21:16:42.654165  6212 sgd_solver.cpp:105] Iteration 62800, lr = 1e-05
I0628 21:16:46.283629  6212 solver.cpp:218] Iteration 62900 (27.5567 iter/s, 3.62888s/100 iters), loss = 0.0913725
I0628 21:16:46.283629  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:16:46.283629  6212 solver.cpp:237]     Train net output #1: loss = 0.0913726 (* 1 = 0.0913726 loss)
I0628 21:16:46.283629  6212 sgd_solver.cpp:105] Iteration 62900, lr = 1e-05
I0628 21:16:49.751138 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:16:49.892740  6212 solver.cpp:330] Iteration 63000, Testing net (#0)
I0628 21:16:49.892740  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:16:50.708834  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:16:50.731336  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8927
I0628 21:16:50.731336  6212 solver.cpp:397]     Test net output #1: loss = 0.353715 (* 1 = 0.353715 loss)
I0628 21:16:50.765887  6212 solver.cpp:218] Iteration 63000 (22.3109 iter/s, 4.48212s/100 iters), loss = 0.0852778
I0628 21:16:50.765887  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:16:50.765887  6212 solver.cpp:237]     Train net output #1: loss = 0.0852779 (* 1 = 0.0852779 loss)
I0628 21:16:50.765887  6212 sgd_solver.cpp:105] Iteration 63000, lr = 1e-05
I0628 21:16:54.401311  6212 solver.cpp:218] Iteration 63100 (27.5097 iter/s, 3.63508s/100 iters), loss = 0.132758
I0628 21:16:54.401311  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:16:54.401311  6212 solver.cpp:237]     Train net output #1: loss = 0.132758 (* 1 = 0.132758 loss)
I0628 21:16:54.401311  6212 sgd_solver.cpp:105] Iteration 63100, lr = 1e-05
I0628 21:16:58.034420  6212 solver.cpp:218] Iteration 63200 (27.5269 iter/s, 3.63281s/100 iters), loss = 0.123352
I0628 21:16:58.034920  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:16:58.034920  6212 solver.cpp:237]     Train net output #1: loss = 0.123352 (* 1 = 0.123352 loss)
I0628 21:16:58.034920  6212 sgd_solver.cpp:105] Iteration 63200, lr = 1e-05
I0628 21:17:01.663501  6212 solver.cpp:218] Iteration 63300 (27.5585 iter/s, 3.62865s/100 iters), loss = 0.145811
I0628 21:17:01.664002  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:17:01.664002  6212 solver.cpp:237]     Train net output #1: loss = 0.145811 (* 1 = 0.145811 loss)
I0628 21:17:01.664002  6212 sgd_solver.cpp:105] Iteration 63300, lr = 1e-05
I0628 21:17:05.298588  6212 solver.cpp:218] Iteration 63400 (27.5146 iter/s, 3.63444s/100 iters), loss = 0.0652653
I0628 21:17:05.298588  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:17:05.298588  6212 solver.cpp:237]     Train net output #1: loss = 0.0652654 (* 1 = 0.0652654 loss)
I0628 21:17:05.298588  6212 sgd_solver.cpp:105] Iteration 63400, lr = 1e-05
I0628 21:17:08.760578 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:17:08.902724  6212 solver.cpp:330] Iteration 63500, Testing net (#0)
I0628 21:17:08.903224  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:17:09.718804  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:17:09.749825  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 21:17:09.750326  6212 solver.cpp:397]     Test net output #1: loss = 0.353412 (* 1 = 0.353412 loss)
I0628 21:17:09.784852  6212 solver.cpp:218] Iteration 63500 (22.2929 iter/s, 4.48573s/100 iters), loss = 0.0865891
I0628 21:17:09.784852  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:17:09.784852  6212 solver.cpp:237]     Train net output #1: loss = 0.0865892 (* 1 = 0.0865892 loss)
I0628 21:17:09.784852  6212 sgd_solver.cpp:105] Iteration 63500, lr = 1e-05
I0628 21:17:13.417935  6212 solver.cpp:218] Iteration 63600 (27.5251 iter/s, 3.63304s/100 iters), loss = 0.090501
I0628 21:17:13.417935  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:17:13.417935  6212 solver.cpp:237]     Train net output #1: loss = 0.0905011 (* 1 = 0.0905011 loss)
I0628 21:17:13.417935  6212 sgd_solver.cpp:105] Iteration 63600, lr = 1e-05
I0628 21:17:17.055023  6212 solver.cpp:218] Iteration 63700 (27.4989 iter/s, 3.63651s/100 iters), loss = 0.162012
I0628 21:17:17.055023  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:17:17.055023  6212 solver.cpp:237]     Train net output #1: loss = 0.162012 (* 1 = 0.162012 loss)
I0628 21:17:17.055023  6212 sgd_solver.cpp:105] Iteration 63700, lr = 1e-05
I0628 21:17:20.699116  6212 solver.cpp:218] Iteration 63800 (27.4446 iter/s, 3.6437s/100 iters), loss = 0.106226
I0628 21:17:20.699116  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:17:20.699116  6212 solver.cpp:237]     Train net output #1: loss = 0.106227 (* 1 = 0.106227 loss)
I0628 21:17:20.699116  6212 sgd_solver.cpp:105] Iteration 63800, lr = 1e-05
I0628 21:17:24.329699  6212 solver.cpp:218] Iteration 63900 (27.5461 iter/s, 3.63027s/100 iters), loss = 0.0979346
I0628 21:17:24.329699  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:17:24.329699  6212 solver.cpp:237]     Train net output #1: loss = 0.0979347 (* 1 = 0.0979347 loss)
I0628 21:17:24.329699  6212 sgd_solver.cpp:105] Iteration 63900, lr = 1e-05
I0628 21:17:27.800014 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:17:27.942128  6212 solver.cpp:330] Iteration 64000, Testing net (#0)
I0628 21:17:27.942128  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:17:28.761714  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:17:28.792239  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I0628 21:17:28.792239  6212 solver.cpp:397]     Test net output #1: loss = 0.354122 (* 1 = 0.354122 loss)
I0628 21:17:28.826743  6212 solver.cpp:218] Iteration 64000 (22.2377 iter/s, 4.49688s/100 iters), loss = 0.134817
I0628 21:17:28.827244  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:17:28.827244  6212 solver.cpp:237]     Train net output #1: loss = 0.134818 (* 1 = 0.134818 loss)
I0628 21:17:28.827244  6212 sgd_solver.cpp:105] Iteration 64000, lr = 1e-05
I0628 21:17:32.460891  6212 solver.cpp:218] Iteration 64100 (27.5208 iter/s, 3.63362s/100 iters), loss = 0.138088
I0628 21:17:32.460891  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:17:32.461390  6212 solver.cpp:237]     Train net output #1: loss = 0.138088 (* 1 = 0.138088 loss)
I0628 21:17:32.461390  6212 sgd_solver.cpp:105] Iteration 64100, lr = 1e-05
I0628 21:17:36.096838  6212 solver.cpp:218] Iteration 64200 (27.5061 iter/s, 3.63556s/100 iters), loss = 0.128875
I0628 21:17:36.097338  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:17:36.097338  6212 solver.cpp:237]     Train net output #1: loss = 0.128875 (* 1 = 0.128875 loss)
I0628 21:17:36.097338  6212 sgd_solver.cpp:105] Iteration 64200, lr = 1e-05
I0628 21:17:39.709494  6212 solver.cpp:218] Iteration 64300 (27.6859 iter/s, 3.61195s/100 iters), loss = 0.113847
I0628 21:17:39.709494  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:17:39.709494  6212 solver.cpp:237]     Train net output #1: loss = 0.113848 (* 1 = 0.113848 loss)
I0628 21:17:39.709494  6212 sgd_solver.cpp:105] Iteration 64300, lr = 1e-05
I0628 21:17:43.317785  6212 solver.cpp:218] Iteration 64400 (27.717 iter/s, 3.60789s/100 iters), loss = 0.0298571
I0628 21:17:43.317785  6212 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0628 21:17:43.317785  6212 solver.cpp:237]     Train net output #1: loss = 0.0298573 (* 1 = 0.0298573 loss)
I0628 21:17:43.317785  6212 sgd_solver.cpp:105] Iteration 64400, lr = 1e-05
I0628 21:17:46.750823 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:17:46.891923  6212 solver.cpp:330] Iteration 64500, Testing net (#0)
I0628 21:17:46.892423  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:17:47.702528  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:17:47.733047  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8924
I0628 21:17:47.733047  6212 solver.cpp:397]     Test net output #1: loss = 0.35361 (* 1 = 0.35361 loss)
I0628 21:17:47.767571  6212 solver.cpp:218] Iteration 64500 (22.4731 iter/s, 4.44977s/100 iters), loss = 0.122525
I0628 21:17:47.767571  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:17:47.767571  6212 solver.cpp:237]     Train net output #1: loss = 0.122525 (* 1 = 0.122525 loss)
I0628 21:17:47.767571  6212 sgd_solver.cpp:105] Iteration 64500, lr = 1e-05
I0628 21:17:51.387774  6212 solver.cpp:218] Iteration 64600 (27.628 iter/s, 3.61952s/100 iters), loss = 0.123875
I0628 21:17:51.387774  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:17:51.387774  6212 solver.cpp:237]     Train net output #1: loss = 0.123876 (* 1 = 0.123876 loss)
I0628 21:17:51.387774  6212 sgd_solver.cpp:105] Iteration 64600, lr = 1e-05
I0628 21:17:55.030903  6212 solver.cpp:218] Iteration 64700 (27.4491 iter/s, 3.6431s/100 iters), loss = 0.111709
I0628 21:17:55.030903  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:17:55.030903  6212 solver.cpp:237]     Train net output #1: loss = 0.111709 (* 1 = 0.111709 loss)
I0628 21:17:55.030903  6212 sgd_solver.cpp:105] Iteration 64700, lr = 1e-05
I0628 21:17:58.661003  6212 solver.cpp:218] Iteration 64800 (27.551 iter/s, 3.62964s/100 iters), loss = 0.111271
I0628 21:17:58.661003  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:17:58.661003  6212 solver.cpp:237]     Train net output #1: loss = 0.111271 (* 1 = 0.111271 loss)
I0628 21:17:58.661003  6212 sgd_solver.cpp:105] Iteration 64800, lr = 1e-05
I0628 21:18:02.293596  6212 solver.cpp:218] Iteration 64900 (27.5316 iter/s, 3.63219s/100 iters), loss = 0.0841765
I0628 21:18:02.293596  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:18:02.293596  6212 solver.cpp:237]     Train net output #1: loss = 0.0841766 (* 1 = 0.0841766 loss)
I0628 21:18:02.293596  6212 sgd_solver.cpp:105] Iteration 64900, lr = 1e-05
I0628 21:18:05.753562 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:18:05.895150  6212 solver.cpp:330] Iteration 65000, Testing net (#0)
I0628 21:18:05.895150  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:18:06.713246  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:18:06.744263  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 21:18:06.744263  6212 solver.cpp:397]     Test net output #1: loss = 0.353499 (* 1 = 0.353499 loss)
I0628 21:18:06.778290  6212 solver.cpp:218] Iteration 65000 (22.3003 iter/s, 4.48424s/100 iters), loss = 0.110392
I0628 21:18:06.778290  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:18:06.778290  6212 solver.cpp:237]     Train net output #1: loss = 0.110392 (* 1 = 0.110392 loss)
I0628 21:18:06.778290  6212 sgd_solver.cpp:105] Iteration 65000, lr = 1e-05
I0628 21:18:10.430434  6212 solver.cpp:218] Iteration 65100 (27.3852 iter/s, 3.6516s/100 iters), loss = 0.11913
I0628 21:18:10.430434  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:18:10.430434  6212 solver.cpp:237]     Train net output #1: loss = 0.11913 (* 1 = 0.11913 loss)
I0628 21:18:10.430434  6212 sgd_solver.cpp:105] Iteration 65100, lr = 1e-05
I0628 21:18:14.079030  6212 solver.cpp:218] Iteration 65200 (27.4088 iter/s, 3.64847s/100 iters), loss = 0.0967191
I0628 21:18:14.079030  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:18:14.079030  6212 solver.cpp:237]     Train net output #1: loss = 0.0967192 (* 1 = 0.0967192 loss)
I0628 21:18:14.079530  6212 sgd_solver.cpp:105] Iteration 65200, lr = 1e-05
I0628 21:18:17.718042  6212 solver.cpp:218] Iteration 65300 (27.4827 iter/s, 3.63866s/100 iters), loss = 0.118728
I0628 21:18:17.718542  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:18:17.718542  6212 solver.cpp:237]     Train net output #1: loss = 0.118729 (* 1 = 0.118729 loss)
I0628 21:18:17.718542  6212 sgd_solver.cpp:105] Iteration 65300, lr = 1e-05
I0628 21:18:21.350198  6212 solver.cpp:218] Iteration 65400 (27.5378 iter/s, 3.63137s/100 iters), loss = 0.087144
I0628 21:18:21.350198  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:18:21.350198  6212 solver.cpp:237]     Train net output #1: loss = 0.0871441 (* 1 = 0.0871441 loss)
I0628 21:18:21.350198  6212 sgd_solver.cpp:105] Iteration 65400, lr = 1e-05
I0628 21:18:24.810178 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:18:24.951778  6212 solver.cpp:330] Iteration 65500, Testing net (#0)
I0628 21:18:24.952280  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:18:25.776365  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:18:25.807399  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8928
I0628 21:18:25.807399  6212 solver.cpp:397]     Test net output #1: loss = 0.353346 (* 1 = 0.353346 loss)
I0628 21:18:25.841411  6212 solver.cpp:218] Iteration 65500 (22.2659 iter/s, 4.49117s/100 iters), loss = 0.121216
I0628 21:18:25.841411  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:18:25.841411  6212 solver.cpp:237]     Train net output #1: loss = 0.121216 (* 1 = 0.121216 loss)
I0628 21:18:25.841411  6212 sgd_solver.cpp:105] Iteration 65500, lr = 1e-05
I0628 21:18:29.487005  6212 solver.cpp:218] Iteration 65600 (27.435 iter/s, 3.64498s/100 iters), loss = 0.123488
I0628 21:18:29.487005  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:18:29.487005  6212 solver.cpp:237]     Train net output #1: loss = 0.123488 (* 1 = 0.123488 loss)
I0628 21:18:29.487005  6212 sgd_solver.cpp:105] Iteration 65600, lr = 1e-05
I0628 21:18:33.134171  6212 solver.cpp:218] Iteration 65700 (27.4213 iter/s, 3.6468s/100 iters), loss = 0.153758
I0628 21:18:33.134171  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:18:33.134171  6212 solver.cpp:237]     Train net output #1: loss = 0.153758 (* 1 = 0.153758 loss)
I0628 21:18:33.134171  6212 sgd_solver.cpp:105] Iteration 65700, lr = 1e-05
I0628 21:18:36.777782  6212 solver.cpp:218] Iteration 65800 (27.447 iter/s, 3.64338s/100 iters), loss = 0.16499
I0628 21:18:36.777782  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:18:36.777782  6212 solver.cpp:237]     Train net output #1: loss = 0.16499 (* 1 = 0.16499 loss)
I0628 21:18:36.777782  6212 sgd_solver.cpp:105] Iteration 65800, lr = 1e-05
I0628 21:18:40.420917  6212 solver.cpp:218] Iteration 65900 (27.452 iter/s, 3.64272s/100 iters), loss = 0.0582887
I0628 21:18:40.420917  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 21:18:40.420917  6212 solver.cpp:237]     Train net output #1: loss = 0.0582889 (* 1 = 0.0582889 loss)
I0628 21:18:40.420917  6212 sgd_solver.cpp:105] Iteration 65900, lr = 1e-05
I0628 21:18:43.870991 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:18:44.015588  6212 solver.cpp:330] Iteration 66000, Testing net (#0)
I0628 21:18:44.015588  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:18:44.835165  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:18:44.865694  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 21:18:44.866197  6212 solver.cpp:397]     Test net output #1: loss = 0.353802 (* 1 = 0.353802 loss)
I0628 21:18:44.900722  6212 solver.cpp:218] Iteration 66000 (22.3235 iter/s, 4.47957s/100 iters), loss = 0.0625221
I0628 21:18:44.900722  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 21:18:44.900722  6212 solver.cpp:237]     Train net output #1: loss = 0.0625223 (* 1 = 0.0625223 loss)
I0628 21:18:44.900722  6212 sgd_solver.cpp:105] Iteration 66000, lr = 1e-05
I0628 21:18:48.547806  6212 solver.cpp:218] Iteration 66100 (27.4214 iter/s, 3.64678s/100 iters), loss = 0.169611
I0628 21:18:48.548317  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:18:48.548317  6212 solver.cpp:237]     Train net output #1: loss = 0.169611 (* 1 = 0.169611 loss)
I0628 21:18:48.548317  6212 sgd_solver.cpp:105] Iteration 66100, lr = 1e-05
I0628 21:18:52.188452  6212 solver.cpp:218] Iteration 66200 (27.4719 iter/s, 3.64008s/100 iters), loss = 0.124649
I0628 21:18:52.188452  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:18:52.188452  6212 solver.cpp:237]     Train net output #1: loss = 0.124649 (* 1 = 0.124649 loss)
I0628 21:18:52.188452  6212 sgd_solver.cpp:105] Iteration 66200, lr = 1e-05
I0628 21:18:55.841575  6212 solver.cpp:218] Iteration 66300 (27.3761 iter/s, 3.65282s/100 iters), loss = 0.0881455
I0628 21:18:55.841575  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:18:55.841575  6212 solver.cpp:237]     Train net output #1: loss = 0.0881456 (* 1 = 0.0881456 loss)
I0628 21:18:55.841575  6212 sgd_solver.cpp:105] Iteration 66300, lr = 1e-05
I0628 21:18:59.464912  6212 solver.cpp:218] Iteration 66400 (27.6025 iter/s, 3.62285s/100 iters), loss = 0.0490175
I0628 21:18:59.464912  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:18:59.464912  6212 solver.cpp:237]     Train net output #1: loss = 0.0490176 (* 1 = 0.0490176 loss)
I0628 21:18:59.464912  6212 sgd_solver.cpp:105] Iteration 66400, lr = 1e-05
I0628 21:19:02.934367 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:19:03.079473  6212 solver.cpp:330] Iteration 66500, Testing net (#0)
I0628 21:19:03.079473  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:19:03.907074  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:19:03.938092  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 21:19:03.938092  6212 solver.cpp:397]     Test net output #1: loss = 0.353387 (* 1 = 0.353387 loss)
I0628 21:19:03.972616  6212 solver.cpp:218] Iteration 66500 (22.1857 iter/s, 4.50742s/100 iters), loss = 0.127617
I0628 21:19:03.972616  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:19:03.972616  6212 solver.cpp:237]     Train net output #1: loss = 0.127617 (* 1 = 0.127617 loss)
I0628 21:19:03.972616  6212 sgd_solver.cpp:105] Iteration 66500, lr = 1e-05
I0628 21:19:07.623214  6212 solver.cpp:218] Iteration 66600 (27.3981 iter/s, 3.64989s/100 iters), loss = 0.139265
I0628 21:19:07.623214  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:19:07.623214  6212 solver.cpp:237]     Train net output #1: loss = 0.139265 (* 1 = 0.139265 loss)
I0628 21:19:07.623214  6212 sgd_solver.cpp:105] Iteration 66600, lr = 1e-05
I0628 21:19:11.258302  6212 solver.cpp:218] Iteration 66700 (27.5125 iter/s, 3.63471s/100 iters), loss = 0.0838089
I0628 21:19:11.258302  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:19:11.258302  6212 solver.cpp:237]     Train net output #1: loss = 0.083809 (* 1 = 0.083809 loss)
I0628 21:19:11.258302  6212 sgd_solver.cpp:105] Iteration 66700, lr = 1e-05
I0628 21:19:14.894925  6212 solver.cpp:218] Iteration 66800 (27.4979 iter/s, 3.63664s/100 iters), loss = 0.123983
I0628 21:19:14.895426  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:19:14.895426  6212 solver.cpp:237]     Train net output #1: loss = 0.123983 (* 1 = 0.123983 loss)
I0628 21:19:14.895426  6212 sgd_solver.cpp:105] Iteration 66800, lr = 1e-05
I0628 21:19:18.529062  6212 solver.cpp:218] Iteration 66900 (27.5197 iter/s, 3.63376s/100 iters), loss = 0.127405
I0628 21:19:18.529567  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:19:18.529567  6212 solver.cpp:237]     Train net output #1: loss = 0.127406 (* 1 = 0.127406 loss)
I0628 21:19:18.529567  6212 sgd_solver.cpp:105] Iteration 66900, lr = 1e-05
I0628 21:19:21.983007 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:19:22.126124  6212 solver.cpp:330] Iteration 67000, Testing net (#0)
I0628 21:19:22.126124  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:19:22.944207  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:19:22.975219  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 21:19:22.975219  6212 solver.cpp:397]     Test net output #1: loss = 0.353354 (* 1 = 0.353354 loss)
I0628 21:19:23.009753  6212 solver.cpp:218] Iteration 67000 (22.3199 iter/s, 4.4803s/100 iters), loss = 0.118326
I0628 21:19:23.010253  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:19:23.010253  6212 solver.cpp:237]     Train net output #1: loss = 0.118326 (* 1 = 0.118326 loss)
I0628 21:19:23.010253  6212 sgd_solver.cpp:105] Iteration 67000, lr = 1e-05
I0628 21:19:26.640831  6212 solver.cpp:218] Iteration 67100 (27.5439 iter/s, 3.63057s/100 iters), loss = 0.129337
I0628 21:19:26.640831  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:19:26.640831  6212 solver.cpp:237]     Train net output #1: loss = 0.129337 (* 1 = 0.129337 loss)
I0628 21:19:26.640831  6212 sgd_solver.cpp:105] Iteration 67100, lr = 1e-05
I0628 21:19:30.280958  6212 solver.cpp:218] Iteration 67200 (27.4764 iter/s, 3.63949s/100 iters), loss = 0.0980183
I0628 21:19:30.280958  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:19:30.280958  6212 solver.cpp:237]     Train net output #1: loss = 0.0980184 (* 1 = 0.0980184 loss)
I0628 21:19:30.280958  6212 sgd_solver.cpp:105] Iteration 67200, lr = 1e-05
I0628 21:19:33.926893  6212 solver.cpp:218] Iteration 67300 (27.4306 iter/s, 3.64556s/100 iters), loss = 0.105492
I0628 21:19:33.926893  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:19:33.926893  6212 solver.cpp:237]     Train net output #1: loss = 0.105492 (* 1 = 0.105492 loss)
I0628 21:19:33.926893  6212 sgd_solver.cpp:105] Iteration 67300, lr = 1e-05
I0628 21:19:37.569985  6212 solver.cpp:218] Iteration 67400 (27.4534 iter/s, 3.64254s/100 iters), loss = 0.0856996
I0628 21:19:37.569985  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:19:37.569985  6212 solver.cpp:237]     Train net output #1: loss = 0.0856997 (* 1 = 0.0856997 loss)
I0628 21:19:37.569985  6212 sgd_solver.cpp:105] Iteration 67400, lr = 1e-05
I0628 21:19:41.021442 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:19:41.163043  6212 solver.cpp:330] Iteration 67500, Testing net (#0)
I0628 21:19:41.163043  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:19:41.984127  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:19:42.015655  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I0628 21:19:42.015655  6212 solver.cpp:397]     Test net output #1: loss = 0.353782 (* 1 = 0.353782 loss)
I0628 21:19:42.049674  6212 solver.cpp:218] Iteration 67500 (22.3246 iter/s, 4.47937s/100 iters), loss = 0.13265
I0628 21:19:42.049674  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:19:42.049674  6212 solver.cpp:237]     Train net output #1: loss = 0.13265 (* 1 = 0.13265 loss)
I0628 21:19:42.049674  6212 sgd_solver.cpp:105] Iteration 67500, lr = 1e-05
I0628 21:19:45.686760  6212 solver.cpp:218] Iteration 67600 (27.4944 iter/s, 3.6371s/100 iters), loss = 0.148421
I0628 21:19:45.687261  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:19:45.687261  6212 solver.cpp:237]     Train net output #1: loss = 0.148421 (* 1 = 0.148421 loss)
I0628 21:19:45.687261  6212 sgd_solver.cpp:105] Iteration 67600, lr = 1e-05
I0628 21:19:49.335373  6212 solver.cpp:218] Iteration 67700 (27.4126 iter/s, 3.64796s/100 iters), loss = 0.100407
I0628 21:19:49.335373  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:19:49.335373  6212 solver.cpp:237]     Train net output #1: loss = 0.100407 (* 1 = 0.100407 loss)
I0628 21:19:49.335373  6212 sgd_solver.cpp:105] Iteration 67700, lr = 1e-05
I0628 21:19:52.986454  6212 solver.cpp:218] Iteration 67800 (27.3902 iter/s, 3.65095s/100 iters), loss = 0.123621
I0628 21:19:52.986454  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:19:52.986954  6212 solver.cpp:237]     Train net output #1: loss = 0.123621 (* 1 = 0.123621 loss)
I0628 21:19:52.986954  6212 sgd_solver.cpp:105] Iteration 67800, lr = 1e-05
I0628 21:19:56.636551  6212 solver.cpp:218] Iteration 67900 (27.4003 iter/s, 3.64959s/100 iters), loss = 0.0614758
I0628 21:19:56.636551  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 21:19:56.636551  6212 solver.cpp:237]     Train net output #1: loss = 0.061476 (* 1 = 0.061476 loss)
I0628 21:19:56.636551  6212 sgd_solver.cpp:105] Iteration 67900, lr = 1e-05
I0628 21:20:00.111523 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:20:00.269651  6212 solver.cpp:330] Iteration 68000, Testing net (#0)
I0628 21:20:00.269651  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:20:01.114238  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:20:01.136754  6212 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0628 21:20:01.136754  6212 solver.cpp:397]     Test net output #1: loss = 0.353011 (* 1 = 0.353011 loss)
I0628 21:20:01.171778  6212 solver.cpp:218] Iteration 68000 (22.0521 iter/s, 4.53471s/100 iters), loss = 0.113422
I0628 21:20:01.171778  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:20:01.171778  6212 solver.cpp:237]     Train net output #1: loss = 0.113422 (* 1 = 0.113422 loss)
I0628 21:20:01.171778  6212 sgd_solver.cpp:105] Iteration 68000, lr = 1e-05
I0628 21:20:04.815871  6212 solver.cpp:218] Iteration 68100 (27.4427 iter/s, 3.64396s/100 iters), loss = 0.194128
I0628 21:20:04.816371  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:20:04.816371  6212 solver.cpp:237]     Train net output #1: loss = 0.194129 (* 1 = 0.194129 loss)
I0628 21:20:04.816371  6212 sgd_solver.cpp:105] Iteration 68100, lr = 1e-05
I0628 21:20:08.461464  6212 solver.cpp:218] Iteration 68200 (27.4352 iter/s, 3.64495s/100 iters), loss = 0.0827249
I0628 21:20:08.461464  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:20:08.461464  6212 solver.cpp:237]     Train net output #1: loss = 0.0827252 (* 1 = 0.0827252 loss)
I0628 21:20:08.461464  6212 sgd_solver.cpp:105] Iteration 68200, lr = 1e-05
I0628 21:20:12.097139  6212 solver.cpp:218] Iteration 68300 (27.5096 iter/s, 3.63509s/100 iters), loss = 0.143623
I0628 21:20:12.097139  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:20:12.097139  6212 solver.cpp:237]     Train net output #1: loss = 0.143623 (* 1 = 0.143623 loss)
I0628 21:20:12.097139  6212 sgd_solver.cpp:105] Iteration 68300, lr = 1e-05
I0628 21:20:15.733240  6212 solver.cpp:218] Iteration 68400 (27.5036 iter/s, 3.63589s/100 iters), loss = 0.122669
I0628 21:20:15.733240  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:20:15.733240  6212 solver.cpp:237]     Train net output #1: loss = 0.122669 (* 1 = 0.122669 loss)
I0628 21:20:15.733240  6212 sgd_solver.cpp:105] Iteration 68400, lr = 1e-05
I0628 21:20:19.185711 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:20:19.331830  6212 solver.cpp:330] Iteration 68500, Testing net (#0)
I0628 21:20:19.331830  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:20:20.153399  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:20:20.184442  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I0628 21:20:20.184928  6212 solver.cpp:397]     Test net output #1: loss = 0.353572 (* 1 = 0.353572 loss)
I0628 21:20:20.219458  6212 solver.cpp:218] Iteration 68500 (22.2915 iter/s, 4.48602s/100 iters), loss = 0.0934295
I0628 21:20:20.219458  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:20:20.219458  6212 solver.cpp:237]     Train net output #1: loss = 0.0934298 (* 1 = 0.0934298 loss)
I0628 21:20:20.219458  6212 sgd_solver.cpp:105] Iteration 68500, lr = 1e-05
I0628 21:20:23.859040  6212 solver.cpp:218] Iteration 68600 (27.4815 iter/s, 3.63881s/100 iters), loss = 0.18518
I0628 21:20:23.859040  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:20:23.859040  6212 solver.cpp:237]     Train net output #1: loss = 0.18518 (* 1 = 0.18518 loss)
I0628 21:20:23.859040  6212 sgd_solver.cpp:105] Iteration 68600, lr = 1e-05
I0628 21:20:27.548164  6212 solver.cpp:218] Iteration 68700 (27.106 iter/s, 3.68923s/100 iters), loss = 0.0707055
I0628 21:20:27.548665  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:20:27.548665  6212 solver.cpp:237]     Train net output #1: loss = 0.0707058 (* 1 = 0.0707058 loss)
I0628 21:20:27.548665  6212 sgd_solver.cpp:105] Iteration 68700, lr = 1e-05
I0628 21:20:31.192759  6212 solver.cpp:218] Iteration 68800 (27.443 iter/s, 3.64392s/100 iters), loss = 0.113816
I0628 21:20:31.192759  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:20:31.192759  6212 solver.cpp:237]     Train net output #1: loss = 0.113816 (* 1 = 0.113816 loss)
I0628 21:20:31.192759  6212 sgd_solver.cpp:105] Iteration 68800, lr = 1e-05
I0628 21:20:34.862869  6212 solver.cpp:218] Iteration 68900 (27.2498 iter/s, 3.66976s/100 iters), loss = 0.0588701
I0628 21:20:34.862869  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 21:20:34.862869  6212 solver.cpp:237]     Train net output #1: loss = 0.0588704 (* 1 = 0.0588704 loss)
I0628 21:20:34.862869  6212 sgd_solver.cpp:105] Iteration 68900, lr = 1e-05
I0628 21:20:38.330837 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:20:38.472939  6212 solver.cpp:330] Iteration 69000, Testing net (#0)
I0628 21:20:38.472939  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:20:39.292019  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:20:39.325045  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I0628 21:20:39.325045  6212 solver.cpp:397]     Test net output #1: loss = 0.353875 (* 1 = 0.353875 loss)
I0628 21:20:39.359068  6212 solver.cpp:218] Iteration 69000 (22.2413 iter/s, 4.49613s/100 iters), loss = 0.0644747
I0628 21:20:39.359570  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:20:39.359570  6212 solver.cpp:237]     Train net output #1: loss = 0.064475 (* 1 = 0.064475 loss)
I0628 21:20:39.359570  6212 sgd_solver.cpp:105] Iteration 69000, lr = 1e-05
I0628 21:20:42.995156  6212 solver.cpp:218] Iteration 69100 (27.5048 iter/s, 3.63573s/100 iters), loss = 0.126086
I0628 21:20:42.995657  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:20:42.995657  6212 solver.cpp:237]     Train net output #1: loss = 0.126086 (* 1 = 0.126086 loss)
I0628 21:20:42.995657  6212 sgd_solver.cpp:105] Iteration 69100, lr = 1e-05
I0628 21:20:46.632243  6212 solver.cpp:218] Iteration 69200 (27.5013 iter/s, 3.63619s/100 iters), loss = 0.118297
I0628 21:20:46.632243  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:20:46.632243  6212 solver.cpp:237]     Train net output #1: loss = 0.118298 (* 1 = 0.118298 loss)
I0628 21:20:46.632243  6212 sgd_solver.cpp:105] Iteration 69200, lr = 1e-05
I0628 21:20:50.267329  6212 solver.cpp:218] Iteration 69300 (27.5089 iter/s, 3.63519s/100 iters), loss = 0.177402
I0628 21:20:50.267830  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:20:50.267830  6212 solver.cpp:237]     Train net output #1: loss = 0.177402 (* 1 = 0.177402 loss)
I0628 21:20:50.267830  6212 sgd_solver.cpp:105] Iteration 69300, lr = 1e-05
I0628 21:20:53.909420  6212 solver.cpp:218] Iteration 69400 (27.4624 iter/s, 3.64134s/100 iters), loss = 0.136324
I0628 21:20:53.909420  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:20:53.909420  6212 solver.cpp:237]     Train net output #1: loss = 0.136325 (* 1 = 0.136325 loss)
I0628 21:20:53.909420  6212 sgd_solver.cpp:105] Iteration 69400, lr = 1e-05
I0628 21:20:57.364379 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:20:57.505980  6212 solver.cpp:330] Iteration 69500, Testing net (#0)
I0628 21:20:57.506480  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:20:58.327564  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:20:58.358587  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I0628 21:20:58.358587  6212 solver.cpp:397]     Test net output #1: loss = 0.353782 (* 1 = 0.353782 loss)
I0628 21:20:58.393110  6212 solver.cpp:218] Iteration 69500 (22.305 iter/s, 4.4833s/100 iters), loss = 0.109042
I0628 21:20:58.393110  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:20:58.393110  6212 solver.cpp:237]     Train net output #1: loss = 0.109043 (* 1 = 0.109043 loss)
I0628 21:20:58.393110  6212 sgd_solver.cpp:105] Iteration 69500, lr = 1e-05
I0628 21:21:02.027196  6212 solver.cpp:218] Iteration 69600 (27.5175 iter/s, 3.63405s/100 iters), loss = 0.114746
I0628 21:21:02.027196  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:21:02.027196  6212 solver.cpp:237]     Train net output #1: loss = 0.114746 (* 1 = 0.114746 loss)
I0628 21:21:02.027196  6212 sgd_solver.cpp:105] Iteration 69600, lr = 1e-05
I0628 21:21:05.674875  6212 solver.cpp:218] Iteration 69700 (27.4167 iter/s, 3.64741s/100 iters), loss = 0.16143
I0628 21:21:05.675375  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:21:05.675375  6212 solver.cpp:237]     Train net output #1: loss = 0.161431 (* 1 = 0.161431 loss)
I0628 21:21:05.675375  6212 sgd_solver.cpp:105] Iteration 69700, lr = 1e-05
I0628 21:21:09.340482  6212 solver.cpp:218] Iteration 69800 (27.2838 iter/s, 3.66517s/100 iters), loss = 0.144397
I0628 21:21:09.340482  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:21:09.340482  6212 solver.cpp:237]     Train net output #1: loss = 0.144397 (* 1 = 0.144397 loss)
I0628 21:21:09.340482  6212 sgd_solver.cpp:105] Iteration 69800, lr = 1e-05
I0628 21:21:12.980072  6212 solver.cpp:218] Iteration 69900 (27.4811 iter/s, 3.63886s/100 iters), loss = 0.0753115
I0628 21:21:12.980072  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:21:12.980072  6212 solver.cpp:237]     Train net output #1: loss = 0.0753118 (* 1 = 0.0753118 loss)
I0628 21:21:12.980072  6212 sgd_solver.cpp:105] Iteration 69900, lr = 1e-05
I0628 21:21:16.450042 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:21:16.593143  6212 solver.cpp:330] Iteration 70000, Testing net (#0)
I0628 21:21:16.593143  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:21:17.413727  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:21:17.445256  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8927
I0628 21:21:17.445256  6212 solver.cpp:397]     Test net output #1: loss = 0.354003 (* 1 = 0.354003 loss)
I0628 21:21:17.479773  6212 solver.cpp:218] Iteration 70000 (22.2258 iter/s, 4.49928s/100 iters), loss = 0.120739
I0628 21:21:17.479773  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:21:17.479773  6212 solver.cpp:237]     Train net output #1: loss = 0.120739 (* 1 = 0.120739 loss)
I0628 21:21:17.479773  6212 sgd_solver.cpp:105] Iteration 70000, lr = 1e-05
I0628 21:21:21.130339  6212 solver.cpp:218] Iteration 70100 (27.395 iter/s, 3.6503s/100 iters), loss = 0.132407
I0628 21:21:21.130339  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:21:21.130339  6212 solver.cpp:237]     Train net output #1: loss = 0.132407 (* 1 = 0.132407 loss)
I0628 21:21:21.130339  6212 sgd_solver.cpp:105] Iteration 70100, lr = 1e-05
I0628 21:21:24.772447  6212 solver.cpp:218] Iteration 70200 (27.4573 iter/s, 3.64202s/100 iters), loss = 0.148836
I0628 21:21:24.772948  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:21:24.772948  6212 solver.cpp:237]     Train net output #1: loss = 0.148836 (* 1 = 0.148836 loss)
I0628 21:21:24.772948  6212 sgd_solver.cpp:105] Iteration 70200, lr = 1e-05
I0628 21:21:28.409642  6212 solver.cpp:218] Iteration 70300 (27.4984 iter/s, 3.63658s/100 iters), loss = 0.136092
I0628 21:21:28.409642  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:21:28.409642  6212 solver.cpp:237]     Train net output #1: loss = 0.136092 (* 1 = 0.136092 loss)
I0628 21:21:28.409642  6212 sgd_solver.cpp:105] Iteration 70300, lr = 1e-05
I0628 21:21:32.060739  6212 solver.cpp:218] Iteration 70400 (27.3926 iter/s, 3.65062s/100 iters), loss = 0.0943302
I0628 21:21:32.060739  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:21:32.060739  6212 solver.cpp:237]     Train net output #1: loss = 0.0943306 (* 1 = 0.0943306 loss)
I0628 21:21:32.060739  6212 sgd_solver.cpp:105] Iteration 70400, lr = 1e-05
I0628 21:21:35.529724 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:21:35.672327  6212 solver.cpp:330] Iteration 70500, Testing net (#0)
I0628 21:21:35.672327  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:21:36.492409  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:21:36.522931  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8921
I0628 21:21:36.523432  6212 solver.cpp:397]     Test net output #1: loss = 0.354317 (* 1 = 0.354317 loss)
I0628 21:21:36.557456  6212 solver.cpp:218] Iteration 70500 (22.2401 iter/s, 4.49639s/100 iters), loss = 0.132526
I0628 21:21:36.557456  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:21:36.557456  6212 solver.cpp:237]     Train net output #1: loss = 0.132526 (* 1 = 0.132526 loss)
I0628 21:21:36.557456  6212 sgd_solver.cpp:105] Iteration 70500, lr = 1e-05
I0628 21:21:40.212556  6212 solver.cpp:218] Iteration 70600 (27.3611 iter/s, 3.65482s/100 iters), loss = 0.113092
I0628 21:21:40.212556  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:21:40.212556  6212 solver.cpp:237]     Train net output #1: loss = 0.113092 (* 1 = 0.113092 loss)
I0628 21:21:40.212556  6212 sgd_solver.cpp:105] Iteration 70600, lr = 1e-05
I0628 21:21:43.844139  6212 solver.cpp:218] Iteration 70700 (27.5407 iter/s, 3.63099s/100 iters), loss = 0.0956828
I0628 21:21:43.844139  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:21:43.844139  6212 solver.cpp:237]     Train net output #1: loss = 0.0956832 (* 1 = 0.0956832 loss)
I0628 21:21:43.844139  6212 sgd_solver.cpp:105] Iteration 70700, lr = 1e-05
I0628 21:21:47.512249  6212 solver.cpp:218] Iteration 70800 (27.2629 iter/s, 3.66799s/100 iters), loss = 0.133888
I0628 21:21:47.512750  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:21:47.512750  6212 solver.cpp:237]     Train net output #1: loss = 0.133888 (* 1 = 0.133888 loss)
I0628 21:21:47.512750  6212 sgd_solver.cpp:105] Iteration 70800, lr = 1e-05
I0628 21:21:51.180027  6212 solver.cpp:218] Iteration 70900 (27.2697 iter/s, 3.66708s/100 iters), loss = 0.07008
I0628 21:21:51.180027  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:21:51.180027  6212 solver.cpp:237]     Train net output #1: loss = 0.0700804 (* 1 = 0.0700804 loss)
I0628 21:21:51.180027  6212 sgd_solver.cpp:105] Iteration 70900, lr = 1e-05
I0628 21:21:54.643477 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:21:54.790081  6212 solver.cpp:330] Iteration 71000, Testing net (#0)
I0628 21:21:54.790581  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:21:55.619173  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:21:55.642189  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 21:21:55.642189  6212 solver.cpp:397]     Test net output #1: loss = 0.354353 (* 1 = 0.354353 loss)
I0628 21:21:55.677212  6212 solver.cpp:218] Iteration 71000 (22.2381 iter/s, 4.49679s/100 iters), loss = 0.116004
I0628 21:21:55.677212  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:21:55.677212  6212 solver.cpp:237]     Train net output #1: loss = 0.116004 (* 1 = 0.116004 loss)
I0628 21:21:55.677212  6212 sgd_solver.cpp:105] Iteration 71000, lr = 1e-05
I0628 21:21:59.321882  6212 solver.cpp:218] Iteration 71100 (27.4387 iter/s, 3.64448s/100 iters), loss = 0.103854
I0628 21:21:59.322383  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:21:59.322383  6212 solver.cpp:237]     Train net output #1: loss = 0.103855 (* 1 = 0.103855 loss)
I0628 21:21:59.322383  6212 sgd_solver.cpp:105] Iteration 71100, lr = 1e-05
I0628 21:22:02.966214  6212 solver.cpp:218] Iteration 71200 (27.4463 iter/s, 3.64348s/100 iters), loss = 0.0986393
I0628 21:22:02.966214  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:22:02.966214  6212 solver.cpp:237]     Train net output #1: loss = 0.0986397 (* 1 = 0.0986397 loss)
I0628 21:22:02.966214  6212 sgd_solver.cpp:105] Iteration 71200, lr = 1e-05
I0628 21:22:06.610894  6212 solver.cpp:218] Iteration 71300 (27.4402 iter/s, 3.64429s/100 iters), loss = 0.0933923
I0628 21:22:06.610894  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:22:06.610894  6212 solver.cpp:237]     Train net output #1: loss = 0.0933927 (* 1 = 0.0933927 loss)
I0628 21:22:06.610894  6212 sgd_solver.cpp:105] Iteration 71300, lr = 1e-05
I0628 21:22:10.260989  6212 solver.cpp:218] Iteration 71400 (27.4004 iter/s, 3.64958s/100 iters), loss = 0.0658577
I0628 21:22:10.260989  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:22:10.260989  6212 solver.cpp:237]     Train net output #1: loss = 0.0658581 (* 1 = 0.0658581 loss)
I0628 21:22:10.260989  6212 sgd_solver.cpp:105] Iteration 71400, lr = 1e-05
I0628 21:22:13.779323 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:22:13.926445  6212 solver.cpp:330] Iteration 71500, Testing net (#0)
I0628 21:22:13.926445  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:22:14.826570  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:22:14.866098  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 21:22:14.866098  6212 solver.cpp:397]     Test net output #1: loss = 0.354297 (* 1 = 0.354297 loss)
I0628 21:22:14.900629  6212 solver.cpp:218] Iteration 71500 (21.5543 iter/s, 4.63945s/100 iters), loss = 0.062981
I0628 21:22:14.900629  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 21:22:14.900629  6212 solver.cpp:237]     Train net output #1: loss = 0.0629813 (* 1 = 0.0629813 loss)
I0628 21:22:14.900629  6212 sgd_solver.cpp:105] Iteration 71500, lr = 1e-05
I0628 21:22:19.217337  6212 solver.cpp:218] Iteration 71600 (23.1686 iter/s, 4.31618s/100 iters), loss = 0.173313
I0628 21:22:19.217337  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:22:19.217337  6212 solver.cpp:237]     Train net output #1: loss = 0.173314 (* 1 = 0.173314 loss)
I0628 21:22:19.217337  6212 sgd_solver.cpp:105] Iteration 71600, lr = 1e-05
I0628 21:22:22.979338  6212 solver.cpp:218] Iteration 71700 (26.5858 iter/s, 3.76141s/100 iters), loss = 0.130362
I0628 21:22:22.979338  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:22:22.979338  6212 solver.cpp:237]     Train net output #1: loss = 0.130362 (* 1 = 0.130362 loss)
I0628 21:22:22.979338  6212 sgd_solver.cpp:105] Iteration 71700, lr = 1e-05
I0628 21:22:26.640650  6212 solver.cpp:218] Iteration 71800 (27.315 iter/s, 3.661s/100 iters), loss = 0.0887202
I0628 21:22:26.640650  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:22:26.640650  6212 solver.cpp:237]     Train net output #1: loss = 0.0887206 (* 1 = 0.0887206 loss)
I0628 21:22:26.640650  6212 sgd_solver.cpp:105] Iteration 71800, lr = 1e-05
I0628 21:22:30.287772  6212 solver.cpp:218] Iteration 71900 (27.4225 iter/s, 3.64664s/100 iters), loss = 0.105615
I0628 21:22:30.287772  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:22:30.287772  6212 solver.cpp:237]     Train net output #1: loss = 0.105615 (* 1 = 0.105615 loss)
I0628 21:22:30.287772  6212 sgd_solver.cpp:105] Iteration 71900, lr = 1e-05
I0628 21:22:33.729465 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:22:33.871567  6212 solver.cpp:330] Iteration 72000, Testing net (#0)
I0628 21:22:33.871567  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:22:34.690647  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:22:34.713663  6212 solver.cpp:397]     Test net output #0: accuracy = 0.893
I0628 21:22:34.713663  6212 solver.cpp:397]     Test net output #1: loss = 0.354417 (* 1 = 0.354417 loss)
I0628 21:22:34.748188  6212 solver.cpp:218] Iteration 72000 (22.4225 iter/s, 4.4598s/100 iters), loss = 0.0997628
I0628 21:22:34.748188  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:22:34.748188  6212 solver.cpp:237]     Train net output #1: loss = 0.0997632 (* 1 = 0.0997632 loss)
I0628 21:22:34.748188  6212 sgd_solver.cpp:105] Iteration 72000, lr = 1e-05
I0628 21:22:38.397876  6212 solver.cpp:218] Iteration 72100 (27.3998 iter/s, 3.64966s/100 iters), loss = 0.107063
I0628 21:22:38.397876  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:22:38.397876  6212 solver.cpp:237]     Train net output #1: loss = 0.107063 (* 1 = 0.107063 loss)
I0628 21:22:38.397876  6212 sgd_solver.cpp:105] Iteration 72100, lr = 1e-05
I0628 21:22:42.047473  6212 solver.cpp:218] Iteration 72200 (27.4048 iter/s, 3.64899s/100 iters), loss = 0.149865
I0628 21:22:42.047473  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:22:42.047473  6212 solver.cpp:237]     Train net output #1: loss = 0.149865 (* 1 = 0.149865 loss)
I0628 21:22:42.047473  6212 sgd_solver.cpp:105] Iteration 72200, lr = 1e-05
I0628 21:22:45.817930  6212 solver.cpp:218] Iteration 72300 (26.5229 iter/s, 3.77033s/100 iters), loss = 0.157344
I0628 21:22:45.817930  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:22:45.817930  6212 solver.cpp:237]     Train net output #1: loss = 0.157344 (* 1 = 0.157344 loss)
I0628 21:22:45.817930  6212 sgd_solver.cpp:105] Iteration 72300, lr = 1e-05
I0628 21:22:49.538702  6212 solver.cpp:218] Iteration 72400 (26.8799 iter/s, 3.72025s/100 iters), loss = 0.131687
I0628 21:22:49.538702  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:22:49.538702  6212 solver.cpp:237]     Train net output #1: loss = 0.131687 (* 1 = 0.131687 loss)
I0628 21:22:49.538702  6212 sgd_solver.cpp:105] Iteration 72400, lr = 1e-05
I0628 21:22:52.985644 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:22:53.129263  6212 solver.cpp:330] Iteration 72500, Testing net (#0)
I0628 21:22:53.129263  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:22:53.958338  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:22:53.989361  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8919
I0628 21:22:53.989361  6212 solver.cpp:397]     Test net output #1: loss = 0.354477 (* 1 = 0.354477 loss)
I0628 21:22:54.023893  6212 solver.cpp:218] Iteration 72500 (22.298 iter/s, 4.48472s/100 iters), loss = 0.136894
I0628 21:22:54.023893  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:22:54.023893  6212 solver.cpp:237]     Train net output #1: loss = 0.136894 (* 1 = 0.136894 loss)
I0628 21:22:54.023893  6212 sgd_solver.cpp:105] Iteration 72500, lr = 1e-05
I0628 21:22:57.658008  6212 solver.cpp:218] Iteration 72600 (27.5195 iter/s, 3.63379s/100 iters), loss = 0.13357
I0628 21:22:57.658008  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:22:57.658008  6212 solver.cpp:237]     Train net output #1: loss = 0.133571 (* 1 = 0.133571 loss)
I0628 21:22:57.658008  6212 sgd_solver.cpp:105] Iteration 72600, lr = 1e-05
I0628 21:23:01.295138  6212 solver.cpp:218] Iteration 72700 (27.498 iter/s, 3.63663s/100 iters), loss = 0.126463
I0628 21:23:01.295138  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:23:01.295138  6212 solver.cpp:237]     Train net output #1: loss = 0.126463 (* 1 = 0.126463 loss)
I0628 21:23:01.295138  6212 sgd_solver.cpp:105] Iteration 72700, lr = 1e-05
I0628 21:23:04.948009  6212 solver.cpp:218] Iteration 72800 (27.3795 iter/s, 3.65236s/100 iters), loss = 0.077197
I0628 21:23:04.948009  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:23:04.948009  6212 solver.cpp:237]     Train net output #1: loss = 0.0771973 (* 1 = 0.0771973 loss)
I0628 21:23:04.948009  6212 sgd_solver.cpp:105] Iteration 72800, lr = 1e-05
I0628 21:23:08.592401  6212 solver.cpp:218] Iteration 72900 (27.4414 iter/s, 3.64413s/100 iters), loss = 0.0944907
I0628 21:23:08.592401  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:23:08.592401  6212 solver.cpp:237]     Train net output #1: loss = 0.094491 (* 1 = 0.094491 loss)
I0628 21:23:08.592401  6212 sgd_solver.cpp:105] Iteration 72900, lr = 1e-05
I0628 21:23:12.054369 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:23:12.196472  6212 solver.cpp:330] Iteration 73000, Testing net (#0)
I0628 21:23:12.196472  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:23:13.016053  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:23:13.046576  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I0628 21:23:13.047076  6212 solver.cpp:397]     Test net output #1: loss = 0.354597 (* 1 = 0.354597 loss)
I0628 21:23:13.081099  6212 solver.cpp:218] Iteration 73000 (22.2791 iter/s, 4.4885s/100 iters), loss = 0.113752
I0628 21:23:13.081099  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:23:13.081099  6212 solver.cpp:237]     Train net output #1: loss = 0.113753 (* 1 = 0.113753 loss)
I0628 21:23:13.081099  6212 sgd_solver.cpp:105] Iteration 73000, lr = 1e-05
I0628 21:23:16.729197  6212 solver.cpp:218] Iteration 73100 (27.4157 iter/s, 3.64755s/100 iters), loss = 0.148528
I0628 21:23:16.729197  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:23:16.729197  6212 solver.cpp:237]     Train net output #1: loss = 0.148528 (* 1 = 0.148528 loss)
I0628 21:23:16.729197  6212 sgd_solver.cpp:105] Iteration 73100, lr = 1e-05
I0628 21:23:20.373788  6212 solver.cpp:218] Iteration 73200 (27.4421 iter/s, 3.64404s/100 iters), loss = 0.152596
I0628 21:23:20.373788  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:23:20.373788  6212 solver.cpp:237]     Train net output #1: loss = 0.152596 (* 1 = 0.152596 loss)
I0628 21:23:20.373788  6212 sgd_solver.cpp:105] Iteration 73200, lr = 1e-05
I0628 21:23:24.015538  6212 solver.cpp:218] Iteration 73300 (27.4596 iter/s, 3.64171s/100 iters), loss = 0.114678
I0628 21:23:24.015538  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:23:24.015538  6212 solver.cpp:237]     Train net output #1: loss = 0.114678 (* 1 = 0.114678 loss)
I0628 21:23:24.015538  6212 sgd_solver.cpp:105] Iteration 73300, lr = 1e-05
I0628 21:23:27.655148  6212 solver.cpp:218] Iteration 73400 (27.478 iter/s, 3.63927s/100 iters), loss = 0.131163
I0628 21:23:27.655148  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:23:27.655148  6212 solver.cpp:237]     Train net output #1: loss = 0.131163 (* 1 = 0.131163 loss)
I0628 21:23:27.655642  6212 sgd_solver.cpp:105] Iteration 73400, lr = 1e-05
I0628 21:23:31.116605 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:23:31.258205  6212 solver.cpp:330] Iteration 73500, Testing net (#0)
I0628 21:23:31.258205  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:23:32.085794  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:23:32.116315  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8927
I0628 21:23:32.116315  6212 solver.cpp:397]     Test net output #1: loss = 0.35405 (* 1 = 0.35405 loss)
I0628 21:23:32.151340  6212 solver.cpp:218] Iteration 73500 (22.2451 iter/s, 4.49537s/100 iters), loss = 0.0811405
I0628 21:23:32.151340  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:23:32.151340  6212 solver.cpp:237]     Train net output #1: loss = 0.0811408 (* 1 = 0.0811408 loss)
I0628 21:23:32.151340  6212 sgd_solver.cpp:105] Iteration 73500, lr = 1e-05
I0628 21:23:35.811445  6212 solver.cpp:218] Iteration 73600 (27.3226 iter/s, 3.65998s/100 iters), loss = 0.123665
I0628 21:23:35.811445  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:23:35.811445  6212 solver.cpp:237]     Train net output #1: loss = 0.123665 (* 1 = 0.123665 loss)
I0628 21:23:35.811445  6212 sgd_solver.cpp:105] Iteration 73600, lr = 1e-05
I0628 21:23:39.441540  6212 solver.cpp:218] Iteration 73700 (27.5501 iter/s, 3.62975s/100 iters), loss = 0.128838
I0628 21:23:39.441540  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:23:39.441540  6212 solver.cpp:237]     Train net output #1: loss = 0.128838 (* 1 = 0.128838 loss)
I0628 21:23:39.441540  6212 sgd_solver.cpp:105] Iteration 73700, lr = 1e-05
I0628 21:23:43.090000  6212 solver.cpp:218] Iteration 73800 (27.412 iter/s, 3.64804s/100 iters), loss = 0.135103
I0628 21:23:43.090000  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:23:43.090000  6212 solver.cpp:237]     Train net output #1: loss = 0.135104 (* 1 = 0.135104 loss)
I0628 21:23:43.090000  6212 sgd_solver.cpp:105] Iteration 73800, lr = 1e-05
I0628 21:23:46.733599  6212 solver.cpp:218] Iteration 73900 (27.4481 iter/s, 3.64324s/100 iters), loss = 0.12923
I0628 21:23:46.733599  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:23:46.733599  6212 solver.cpp:237]     Train net output #1: loss = 0.12923 (* 1 = 0.12923 loss)
I0628 21:23:46.733599  6212 sgd_solver.cpp:105] Iteration 73900, lr = 1e-05
I0628 21:23:50.240505 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:23:50.382606  6212 solver.cpp:330] Iteration 74000, Testing net (#0)
I0628 21:23:50.383106  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:23:51.219753  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:23:51.251276  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8924
I0628 21:23:51.251276  6212 solver.cpp:397]     Test net output #1: loss = 0.35448 (* 1 = 0.35448 loss)
I0628 21:23:51.285809  6212 solver.cpp:218] Iteration 74000 (21.9698 iter/s, 4.55171s/100 iters), loss = 0.0927231
I0628 21:23:51.285809  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:23:51.285809  6212 solver.cpp:237]     Train net output #1: loss = 0.0927235 (* 1 = 0.0927235 loss)
I0628 21:23:51.285809  6212 sgd_solver.cpp:46] MultiStep Status: Iteration 74000, step = 4
I0628 21:23:51.285809  6212 sgd_solver.cpp:105] Iteration 74000, lr = 1e-06
I0628 21:23:54.925890  6212 solver.cpp:218] Iteration 74100 (27.4732 iter/s, 3.63992s/100 iters), loss = 0.166461
I0628 21:23:54.925890  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 21:23:54.925890  6212 solver.cpp:237]     Train net output #1: loss = 0.166461 (* 1 = 0.166461 loss)
I0628 21:23:54.925890  6212 sgd_solver.cpp:105] Iteration 74100, lr = 1e-06
I0628 21:23:58.570483  6212 solver.cpp:218] Iteration 74200 (27.4432 iter/s, 3.64389s/100 iters), loss = 0.0843934
I0628 21:23:58.570483  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:23:58.570483  6212 solver.cpp:237]     Train net output #1: loss = 0.0843938 (* 1 = 0.0843938 loss)
I0628 21:23:58.570483  6212 sgd_solver.cpp:105] Iteration 74200, lr = 1e-06
I0628 21:24:02.200711  6212 solver.cpp:218] Iteration 74300 (27.5464 iter/s, 3.63024s/100 iters), loss = 0.110902
I0628 21:24:02.200711  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:24:02.200711  6212 solver.cpp:237]     Train net output #1: loss = 0.110902 (* 1 = 0.110902 loss)
I0628 21:24:02.200711  6212 sgd_solver.cpp:105] Iteration 74300, lr = 1e-06
I0628 21:24:05.826107  6212 solver.cpp:218] Iteration 74400 (27.585 iter/s, 3.62516s/100 iters), loss = 0.102173
I0628 21:24:05.826607  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:24:05.826607  6212 solver.cpp:237]     Train net output #1: loss = 0.102174 (* 1 = 0.102174 loss)
I0628 21:24:05.826607  6212 sgd_solver.cpp:105] Iteration 74400, lr = 1e-06
I0628 21:24:09.267055 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:24:09.408155  6212 solver.cpp:330] Iteration 74500, Testing net (#0)
I0628 21:24:09.408155  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:24:10.222735  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:24:10.253258  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 21:24:10.253757  6212 solver.cpp:397]     Test net output #1: loss = 0.354564 (* 1 = 0.354564 loss)
I0628 21:24:10.287781  6212 solver.cpp:218] Iteration 74500 (22.4162 iter/s, 4.46107s/100 iters), loss = 0.0818903
I0628 21:24:10.287781  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:24:10.287781  6212 solver.cpp:237]     Train net output #1: loss = 0.0818907 (* 1 = 0.0818907 loss)
I0628 21:24:10.287781  6212 sgd_solver.cpp:105] Iteration 74500, lr = 1e-06
I0628 21:24:13.904414  6212 solver.cpp:218] Iteration 74600 (27.6542 iter/s, 3.61609s/100 iters), loss = 0.139608
I0628 21:24:13.904414  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:24:13.904414  6212 solver.cpp:237]     Train net output #1: loss = 0.139608 (* 1 = 0.139608 loss)
I0628 21:24:13.904414  6212 sgd_solver.cpp:105] Iteration 74600, lr = 1e-06
I0628 21:24:17.538990  6212 solver.cpp:218] Iteration 74700 (27.5155 iter/s, 3.63432s/100 iters), loss = 0.0864044
I0628 21:24:17.538990  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:24:17.538990  6212 solver.cpp:237]     Train net output #1: loss = 0.0864048 (* 1 = 0.0864048 loss)
I0628 21:24:17.538990  6212 sgd_solver.cpp:105] Iteration 74700, lr = 1e-06
I0628 21:24:21.186573  6212 solver.cpp:218] Iteration 74800 (27.4207 iter/s, 3.64688s/100 iters), loss = 0.160879
I0628 21:24:21.186573  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:24:21.186573  6212 solver.cpp:237]     Train net output #1: loss = 0.160879 (* 1 = 0.160879 loss)
I0628 21:24:21.186573  6212 sgd_solver.cpp:105] Iteration 74800, lr = 1e-06
I0628 21:24:24.811904  6212 solver.cpp:218] Iteration 74900 (27.5837 iter/s, 3.62533s/100 iters), loss = 0.0989802
I0628 21:24:24.811904  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:24:24.811904  6212 solver.cpp:237]     Train net output #1: loss = 0.0989805 (* 1 = 0.0989805 loss)
I0628 21:24:24.811904  6212 sgd_solver.cpp:105] Iteration 74900, lr = 1e-06
I0628 21:24:28.265863 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:24:28.407963  6212 solver.cpp:330] Iteration 75000, Testing net (#0)
I0628 21:24:28.407963  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:24:29.230562  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:24:29.261571  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 21:24:29.261571  6212 solver.cpp:397]     Test net output #1: loss = 0.354575 (* 1 = 0.354575 loss)
I0628 21:24:29.295604  6212 solver.cpp:218] Iteration 75000 (22.3047 iter/s, 4.48335s/100 iters), loss = 0.0763388
I0628 21:24:29.295604  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:24:29.295604  6212 solver.cpp:237]     Train net output #1: loss = 0.0763392 (* 1 = 0.0763392 loss)
I0628 21:24:29.296104  6212 sgd_solver.cpp:105] Iteration 75000, lr = 1e-06
I0628 21:24:32.940747  6212 solver.cpp:218] Iteration 75100 (27.4387 iter/s, 3.64448s/100 iters), loss = 0.125697
I0628 21:24:32.940747  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:24:32.940747  6212 solver.cpp:237]     Train net output #1: loss = 0.125698 (* 1 = 0.125698 loss)
I0628 21:24:32.940747  6212 sgd_solver.cpp:105] Iteration 75100, lr = 1e-06
I0628 21:24:36.597972  6212 solver.cpp:218] Iteration 75200 (27.3447 iter/s, 3.65702s/100 iters), loss = 0.10289
I0628 21:24:36.597972  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:24:36.597972  6212 solver.cpp:237]     Train net output #1: loss = 0.10289 (* 1 = 0.10289 loss)
I0628 21:24:36.597972  6212 sgd_solver.cpp:105] Iteration 75200, lr = 1e-06
I0628 21:24:40.232058  6212 solver.cpp:218] Iteration 75300 (27.5191 iter/s, 3.63384s/100 iters), loss = 0.190048
I0628 21:24:40.232558  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:24:40.232558  6212 solver.cpp:237]     Train net output #1: loss = 0.190048 (* 1 = 0.190048 loss)
I0628 21:24:40.232558  6212 sgd_solver.cpp:105] Iteration 75300, lr = 1e-06
I0628 21:24:43.875149  6212 solver.cpp:218] Iteration 75400 (27.4534 iter/s, 3.64254s/100 iters), loss = 0.114818
I0628 21:24:43.875149  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:24:43.875149  6212 solver.cpp:237]     Train net output #1: loss = 0.114818 (* 1 = 0.114818 loss)
I0628 21:24:43.875149  6212 sgd_solver.cpp:105] Iteration 75400, lr = 1e-06
I0628 21:24:47.337113 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:24:47.478214  6212 solver.cpp:330] Iteration 75500, Testing net (#0)
I0628 21:24:47.478214  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:24:48.302799  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:24:48.333822  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I0628 21:24:48.333822  6212 solver.cpp:397]     Test net output #1: loss = 0.354265 (* 1 = 0.354265 loss)
I0628 21:24:48.367846  6212 solver.cpp:218] Iteration 75500 (22.2596 iter/s, 4.49245s/100 iters), loss = 0.0978369
I0628 21:24:48.367846  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:24:48.367846  6212 solver.cpp:237]     Train net output #1: loss = 0.0978373 (* 1 = 0.0978373 loss)
I0628 21:24:48.367846  6212 sgd_solver.cpp:105] Iteration 75500, lr = 1e-06
I0628 21:24:52.007436  6212 solver.cpp:218] Iteration 75600 (27.4801 iter/s, 3.639s/100 iters), loss = 0.190974
I0628 21:24:52.007436  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:24:52.007436  6212 solver.cpp:237]     Train net output #1: loss = 0.190975 (* 1 = 0.190975 loss)
I0628 21:24:52.007436  6212 sgd_solver.cpp:105] Iteration 75600, lr = 1e-06
I0628 21:24:55.627554  6212 solver.cpp:218] Iteration 75700 (27.6264 iter/s, 3.61973s/100 iters), loss = 0.116122
I0628 21:24:55.627554  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:24:55.627554  6212 solver.cpp:237]     Train net output #1: loss = 0.116122 (* 1 = 0.116122 loss)
I0628 21:24:55.627554  6212 sgd_solver.cpp:105] Iteration 75700, lr = 1e-06
I0628 21:24:59.239399  6212 solver.cpp:218] Iteration 75800 (27.6874 iter/s, 3.61175s/100 iters), loss = 0.130843
I0628 21:24:59.239399  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:24:59.239399  6212 solver.cpp:237]     Train net output #1: loss = 0.130844 (* 1 = 0.130844 loss)
I0628 21:24:59.239399  6212 sgd_solver.cpp:105] Iteration 75800, lr = 1e-06
I0628 21:25:02.862577  6212 solver.cpp:218] Iteration 75900 (27.6017 iter/s, 3.62296s/100 iters), loss = 0.118184
I0628 21:25:02.863077  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:25:02.863077  6212 solver.cpp:237]     Train net output #1: loss = 0.118184 (* 1 = 0.118184 loss)
I0628 21:25:02.863077  6212 sgd_solver.cpp:105] Iteration 75900, lr = 1e-06
I0628 21:25:06.316305 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:25:06.460409  6212 solver.cpp:330] Iteration 76000, Testing net (#0)
I0628 21:25:06.460409  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:25:07.268483  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:25:07.300006  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 21:25:07.300006  6212 solver.cpp:397]     Test net output #1: loss = 0.35474 (* 1 = 0.35474 loss)
I0628 21:25:07.334028  6212 solver.cpp:218] Iteration 76000 (22.3673 iter/s, 4.47081s/100 iters), loss = 0.0850678
I0628 21:25:07.334028  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:25:07.334028  6212 solver.cpp:237]     Train net output #1: loss = 0.0850682 (* 1 = 0.0850682 loss)
I0628 21:25:07.334028  6212 sgd_solver.cpp:105] Iteration 76000, lr = 1e-06
I0628 21:25:10.963505  6212 solver.cpp:218] Iteration 76100 (27.5555 iter/s, 3.62904s/100 iters), loss = 0.232746
I0628 21:25:10.963505  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 21:25:10.963505  6212 solver.cpp:237]     Train net output #1: loss = 0.232746 (* 1 = 0.232746 loss)
I0628 21:25:10.964004  6212 sgd_solver.cpp:105] Iteration 76100, lr = 1e-06
I0628 21:25:14.601178  6212 solver.cpp:218] Iteration 76200 (27.4922 iter/s, 3.63739s/100 iters), loss = 0.117549
I0628 21:25:14.601680  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:25:14.601680  6212 solver.cpp:237]     Train net output #1: loss = 0.117549 (* 1 = 0.117549 loss)
I0628 21:25:14.601680  6212 sgd_solver.cpp:105] Iteration 76200, lr = 1e-06
I0628 21:25:18.227298  6212 solver.cpp:218] Iteration 76300 (27.5843 iter/s, 3.62526s/100 iters), loss = 0.117532
I0628 21:25:18.227298  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:25:18.227298  6212 solver.cpp:237]     Train net output #1: loss = 0.117533 (* 1 = 0.117533 loss)
I0628 21:25:18.227298  6212 sgd_solver.cpp:105] Iteration 76300, lr = 1e-06
I0628 21:25:21.848912  6212 solver.cpp:218] Iteration 76400 (27.612 iter/s, 3.62162s/100 iters), loss = 0.103182
I0628 21:25:21.848912  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:25:21.848912  6212 solver.cpp:237]     Train net output #1: loss = 0.103182 (* 1 = 0.103182 loss)
I0628 21:25:21.848912  6212 sgd_solver.cpp:105] Iteration 76400, lr = 1e-06
I0628 21:25:25.301625 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:25:25.444216  6212 solver.cpp:330] Iteration 76500, Testing net (#0)
I0628 21:25:25.444716  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:25:26.254793  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:25:26.286315  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 21:25:26.286315  6212 solver.cpp:397]     Test net output #1: loss = 0.354163 (* 1 = 0.354163 loss)
I0628 21:25:26.320339  6212 solver.cpp:218] Iteration 76500 (22.3658 iter/s, 4.47111s/100 iters), loss = 0.109281
I0628 21:25:26.320840  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:25:26.320840  6212 solver.cpp:237]     Train net output #1: loss = 0.109282 (* 1 = 0.109282 loss)
I0628 21:25:26.320840  6212 sgd_solver.cpp:105] Iteration 76500, lr = 1e-06
I0628 21:25:29.933745  6212 solver.cpp:218] Iteration 76600 (27.6802 iter/s, 3.61269s/100 iters), loss = 0.153055
I0628 21:25:29.933745  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:25:29.933745  6212 solver.cpp:237]     Train net output #1: loss = 0.153055 (* 1 = 0.153055 loss)
I0628 21:25:29.933745  6212 sgd_solver.cpp:105] Iteration 76600, lr = 1e-06
I0628 21:25:33.587483  6212 solver.cpp:218] Iteration 76700 (27.3713 iter/s, 3.65347s/100 iters), loss = 0.0783854
I0628 21:25:33.587483  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:25:33.587483  6212 solver.cpp:237]     Train net output #1: loss = 0.0783858 (* 1 = 0.0783858 loss)
I0628 21:25:33.587483  6212 sgd_solver.cpp:105] Iteration 76700, lr = 1e-06
I0628 21:25:37.208169  6212 solver.cpp:218] Iteration 76800 (27.6195 iter/s, 3.62063s/100 iters), loss = 0.147296
I0628 21:25:37.208670  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:25:37.208670  6212 solver.cpp:237]     Train net output #1: loss = 0.147297 (* 1 = 0.147297 loss)
I0628 21:25:37.208670  6212 sgd_solver.cpp:105] Iteration 76800, lr = 1e-06
I0628 21:25:40.841125  6212 solver.cpp:218] Iteration 76900 (27.5302 iter/s, 3.63237s/100 iters), loss = 0.0729908
I0628 21:25:40.841125  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:25:40.841125  6212 solver.cpp:237]     Train net output #1: loss = 0.0729913 (* 1 = 0.0729913 loss)
I0628 21:25:40.841125  6212 sgd_solver.cpp:105] Iteration 76900, lr = 1e-06
I0628 21:25:44.319646 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:25:44.461261  6212 solver.cpp:330] Iteration 77000, Testing net (#0)
I0628 21:25:44.461762  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:25:45.277830  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:25:45.309360  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8921
I0628 21:25:45.309360  6212 solver.cpp:397]     Test net output #1: loss = 0.354192 (* 1 = 0.354192 loss)
I0628 21:25:45.343884  6212 solver.cpp:218] Iteration 77000 (22.2099 iter/s, 4.50249s/100 iters), loss = 0.0871087
I0628 21:25:45.343884  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:25:45.343884  6212 solver.cpp:237]     Train net output #1: loss = 0.0871091 (* 1 = 0.0871091 loss)
I0628 21:25:45.343884  6212 sgd_solver.cpp:105] Iteration 77000, lr = 1e-06
I0628 21:25:49.003039  6212 solver.cpp:218] Iteration 77100 (27.3335 iter/s, 3.65851s/100 iters), loss = 0.169535
I0628 21:25:49.003039  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 21:25:49.003039  6212 solver.cpp:237]     Train net output #1: loss = 0.169535 (* 1 = 0.169535 loss)
I0628 21:25:49.003039  6212 sgd_solver.cpp:105] Iteration 77100, lr = 1e-06
I0628 21:25:52.617161  6212 solver.cpp:218] Iteration 77200 (27.6704 iter/s, 3.61397s/100 iters), loss = 0.146905
I0628 21:25:52.617161  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:25:52.617161  6212 solver.cpp:237]     Train net output #1: loss = 0.146906 (* 1 = 0.146906 loss)
I0628 21:25:52.617161  6212 sgd_solver.cpp:105] Iteration 77200, lr = 1e-06
I0628 21:25:56.266794  6212 solver.cpp:218] Iteration 77300 (27.4018 iter/s, 3.64939s/100 iters), loss = 0.118914
I0628 21:25:56.266794  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:25:56.266794  6212 solver.cpp:237]     Train net output #1: loss = 0.118914 (* 1 = 0.118914 loss)
I0628 21:25:56.267294  6212 sgd_solver.cpp:105] Iteration 77300, lr = 1e-06
I0628 21:25:59.886368  6212 solver.cpp:218] Iteration 77400 (27.6334 iter/s, 3.61881s/100 iters), loss = 0.0868575
I0628 21:25:59.886368  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:25:59.886368  6212 solver.cpp:237]     Train net output #1: loss = 0.086858 (* 1 = 0.086858 loss)
I0628 21:25:59.886368  6212 sgd_solver.cpp:105] Iteration 77400, lr = 1e-06
I0628 21:26:03.336261 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:26:03.480865  6212 solver.cpp:330] Iteration 77500, Testing net (#0)
I0628 21:26:03.480865  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:26:04.303951  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:26:04.334972  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 21:26:04.334972  6212 solver.cpp:397]     Test net output #1: loss = 0.354367 (* 1 = 0.354367 loss)
I0628 21:26:04.369496  6212 solver.cpp:218] Iteration 77500 (22.307 iter/s, 4.48289s/100 iters), loss = 0.103902
I0628 21:26:04.369496  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:26:04.369496  6212 solver.cpp:237]     Train net output #1: loss = 0.103903 (* 1 = 0.103903 loss)
I0628 21:26:04.369496  6212 sgd_solver.cpp:105] Iteration 77500, lr = 1e-06
I0628 21:26:08.017091  6212 solver.cpp:218] Iteration 77600 (27.4157 iter/s, 3.64755s/100 iters), loss = 0.12186
I0628 21:26:08.017091  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:26:08.017091  6212 solver.cpp:237]     Train net output #1: loss = 0.121861 (* 1 = 0.121861 loss)
I0628 21:26:08.017091  6212 sgd_solver.cpp:105] Iteration 77600, lr = 1e-06
I0628 21:26:11.660183  6212 solver.cpp:218] Iteration 77700 (27.4533 iter/s, 3.64255s/100 iters), loss = 0.152136
I0628 21:26:11.660183  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:26:11.660183  6212 solver.cpp:237]     Train net output #1: loss = 0.152137 (* 1 = 0.152137 loss)
I0628 21:26:11.660183  6212 sgd_solver.cpp:105] Iteration 77700, lr = 1e-06
I0628 21:26:15.307278  6212 solver.cpp:218] Iteration 77800 (27.4198 iter/s, 3.647s/100 iters), loss = 0.111478
I0628 21:26:15.307278  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:26:15.307278  6212 solver.cpp:237]     Train net output #1: loss = 0.111479 (* 1 = 0.111479 loss)
I0628 21:26:15.307778  6212 sgd_solver.cpp:105] Iteration 77800, lr = 1e-06
I0628 21:26:18.966895  6212 solver.cpp:218] Iteration 77900 (27.3296 iter/s, 3.65904s/100 iters), loss = 0.0901921
I0628 21:26:18.966895  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:26:18.966895  6212 solver.cpp:237]     Train net output #1: loss = 0.0901927 (* 1 = 0.0901927 loss)
I0628 21:26:18.966895  6212 sgd_solver.cpp:105] Iteration 77900, lr = 1e-06
I0628 21:26:22.450222 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:26:22.591809  6212 solver.cpp:330] Iteration 78000, Testing net (#0)
I0628 21:26:22.591809  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:26:23.409904  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:26:23.440943  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I0628 21:26:23.440943  6212 solver.cpp:397]     Test net output #1: loss = 0.354261 (* 1 = 0.354261 loss)
I0628 21:26:23.475452  6212 solver.cpp:218] Iteration 78000 (22.1806 iter/s, 4.50845s/100 iters), loss = 0.111411
I0628 21:26:23.475952  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 21:26:23.475952  6212 solver.cpp:237]     Train net output #1: loss = 0.111412 (* 1 = 0.111412 loss)
I0628 21:26:23.475952  6212 sgd_solver.cpp:105] Iteration 78000, lr = 1e-06
I0628 21:26:27.124044  6212 solver.cpp:218] Iteration 78100 (27.4141 iter/s, 3.64776s/100 iters), loss = 0.114454
I0628 21:26:27.124044  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:26:27.124044  6212 solver.cpp:237]     Train net output #1: loss = 0.114454 (* 1 = 0.114454 loss)
I0628 21:26:27.124044  6212 sgd_solver.cpp:105] Iteration 78100, lr = 1e-06
I0628 21:26:30.765175  6212 solver.cpp:218] Iteration 78200 (27.4648 iter/s, 3.64103s/100 iters), loss = 0.109473
I0628 21:26:30.765175  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:26:30.765175  6212 solver.cpp:237]     Train net output #1: loss = 0.109474 (* 1 = 0.109474 loss)
I0628 21:26:30.765175  6212 sgd_solver.cpp:105] Iteration 78200, lr = 1e-06
I0628 21:26:34.414288  6212 solver.cpp:218] Iteration 78300 (27.4058 iter/s, 3.64886s/100 iters), loss = 0.0970551
I0628 21:26:34.414288  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 21:26:34.414288  6212 solver.cpp:237]     Train net output #1: loss = 0.0970556 (* 1 = 0.0970556 loss)
I0628 21:26:34.414788  6212 sgd_solver.cpp:105] Iteration 78300, lr = 1e-06
I0628 21:26:38.059383  6212 solver.cpp:218] Iteration 78400 (27.4363 iter/s, 3.64481s/100 iters), loss = 0.136371
I0628 21:26:38.059887  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:26:38.059887  6212 solver.cpp:237]     Train net output #1: loss = 0.136371 (* 1 = 0.136371 loss)
I0628 21:26:38.059887  6212 sgd_solver.cpp:105] Iteration 78400, lr = 1e-06
I0628 21:26:41.521538 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:26:41.664126  6212 solver.cpp:330] Iteration 78500, Testing net (#0)
I0628 21:26:41.664126  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:26:42.482266  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:26:42.513284  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I0628 21:26:42.513284  6212 solver.cpp:397]     Test net output #1: loss = 0.354487 (* 1 = 0.354487 loss)
I0628 21:26:42.547816  6212 solver.cpp:218] Iteration 78500 (22.2826 iter/s, 4.48781s/100 iters), loss = 0.0885021
I0628 21:26:42.547816  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:26:42.547816  6212 solver.cpp:237]     Train net output #1: loss = 0.0885027 (* 1 = 0.0885027 loss)
I0628 21:26:42.547816  6212 sgd_solver.cpp:105] Iteration 78500, lr = 1e-06
I0628 21:26:46.188946  6212 solver.cpp:218] Iteration 78600 (27.4687 iter/s, 3.64051s/100 iters), loss = 0.14316
I0628 21:26:46.188946  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:26:46.188946  6212 solver.cpp:237]     Train net output #1: loss = 0.14316 (* 1 = 0.14316 loss)
I0628 21:26:46.188946  6212 sgd_solver.cpp:105] Iteration 78600, lr = 1e-06
I0628 21:26:49.831087  6212 solver.cpp:218] Iteration 78700 (27.4584 iter/s, 3.64187s/100 iters), loss = 0.0954114
I0628 21:26:49.831087  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:26:49.831087  6212 solver.cpp:237]     Train net output #1: loss = 0.0954121 (* 1 = 0.0954121 loss)
I0628 21:26:49.831087  6212 sgd_solver.cpp:105] Iteration 78700, lr = 1e-06
I0628 21:26:53.486174  6212 solver.cpp:218] Iteration 78800 (27.3614 iter/s, 3.65479s/100 iters), loss = 0.0901714
I0628 21:26:53.486174  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:26:53.486174  6212 solver.cpp:237]     Train net output #1: loss = 0.0901721 (* 1 = 0.0901721 loss)
I0628 21:26:53.486174  6212 sgd_solver.cpp:105] Iteration 78800, lr = 1e-06
I0628 21:26:57.146333  6212 solver.cpp:218] Iteration 78900 (27.3238 iter/s, 3.65981s/100 iters), loss = 0.0741971
I0628 21:26:57.146333  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 21:26:57.146333  6212 solver.cpp:237]     Train net output #1: loss = 0.0741977 (* 1 = 0.0741977 loss)
I0628 21:26:57.146333  6212 sgd_solver.cpp:105] Iteration 78900, lr = 1e-06
I0628 21:27:00.611299 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:27:00.752899  6212 solver.cpp:330] Iteration 79000, Testing net (#0)
I0628 21:27:00.752899  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:27:01.575984  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:27:01.607007  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I0628 21:27:01.607007  6212 solver.cpp:397]     Test net output #1: loss = 0.354567 (* 1 = 0.354567 loss)
I0628 21:27:01.641031  6212 solver.cpp:218] Iteration 79000 (22.25 iter/s, 4.49438s/100 iters), loss = 0.0905057
I0628 21:27:01.641031  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:27:01.641031  6212 solver.cpp:237]     Train net output #1: loss = 0.0905062 (* 1 = 0.0905062 loss)
I0628 21:27:01.641031  6212 sgd_solver.cpp:105] Iteration 79000, lr = 1e-06
I0628 21:27:05.282716  6212 solver.cpp:218] Iteration 79100 (27.4654 iter/s, 3.64094s/100 iters), loss = 0.0888875
I0628 21:27:05.282716  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 21:27:05.282716  6212 solver.cpp:237]     Train net output #1: loss = 0.0888881 (* 1 = 0.0888881 loss)
I0628 21:27:05.282716  6212 sgd_solver.cpp:105] Iteration 79100, lr = 1e-06
I0628 21:27:08.920410  6212 solver.cpp:218] Iteration 79200 (27.4924 iter/s, 3.63737s/100 iters), loss = 0.157486
I0628 21:27:08.920410  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:27:08.920410  6212 solver.cpp:237]     Train net output #1: loss = 0.157487 (* 1 = 0.157487 loss)
I0628 21:27:08.920410  6212 sgd_solver.cpp:105] Iteration 79200, lr = 1e-06
I0628 21:27:12.579000  6212 solver.cpp:218] Iteration 79300 (27.3361 iter/s, 3.65817s/100 iters), loss = 0.150337
I0628 21:27:12.579000  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 21:27:12.579000  6212 solver.cpp:237]     Train net output #1: loss = 0.150338 (* 1 = 0.150338 loss)
I0628 21:27:12.579000  6212 sgd_solver.cpp:105] Iteration 79300, lr = 1e-06
I0628 21:27:16.211144  6212 solver.cpp:218] Iteration 79400 (27.5351 iter/s, 3.63172s/100 iters), loss = 0.0483194
I0628 21:27:16.211144  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:27:16.211144  6212 solver.cpp:237]     Train net output #1: loss = 0.04832 (* 1 = 0.04832 loss)
I0628 21:27:16.211144  6212 sgd_solver.cpp:105] Iteration 79400, lr = 1e-06
I0628 21:27:19.664082 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:27:19.805681  6212 solver.cpp:330] Iteration 79500, Testing net (#0)
I0628 21:27:19.806182  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:27:20.628265  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:27:20.658802  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I0628 21:27:20.659301  6212 solver.cpp:397]     Test net output #1: loss = 0.354405 (* 1 = 0.354405 loss)
I0628 21:27:20.693822  6212 solver.cpp:218] Iteration 79500 (22.3089 iter/s, 4.48251s/100 iters), loss = 0.133709
I0628 21:27:20.693822  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:27:20.693822  6212 solver.cpp:237]     Train net output #1: loss = 0.13371 (* 1 = 0.13371 loss)
I0628 21:27:20.693822  6212 sgd_solver.cpp:105] Iteration 79500, lr = 1e-06
I0628 21:27:24.326396  6212 solver.cpp:218] Iteration 79600 (27.5311 iter/s, 3.63225s/100 iters), loss = 0.137572
I0628 21:27:24.326396  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 21:27:24.326396  6212 solver.cpp:237]     Train net output #1: loss = 0.137573 (* 1 = 0.137573 loss)
I0628 21:27:24.326396  6212 sgd_solver.cpp:105] Iteration 79600, lr = 1e-06
I0628 21:27:27.960492  6212 solver.cpp:218] Iteration 79700 (27.5207 iter/s, 3.63363s/100 iters), loss = 0.0878628
I0628 21:27:27.960492  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:27:27.960996  6212 solver.cpp:237]     Train net output #1: loss = 0.0878634 (* 1 = 0.0878634 loss)
I0628 21:27:27.960996  6212 sgd_solver.cpp:105] Iteration 79700, lr = 1e-06
I0628 21:27:31.588563  6212 solver.cpp:218] Iteration 79800 (27.567 iter/s, 3.62752s/100 iters), loss = 0.0925996
I0628 21:27:31.588563  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:27:31.588563  6212 solver.cpp:237]     Train net output #1: loss = 0.0926002 (* 1 = 0.0926002 loss)
I0628 21:27:31.588563  6212 sgd_solver.cpp:105] Iteration 79800, lr = 1e-06
I0628 21:27:35.219187  6212 solver.cpp:218] Iteration 79900 (27.5481 iter/s, 3.63001s/100 iters), loss = 0.0555803
I0628 21:27:35.219187  6212 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 21:27:35.219187  6212 solver.cpp:237]     Train net output #1: loss = 0.0555809 (* 1 = 0.0555809 loss)
I0628 21:27:35.219187  6212 sgd_solver.cpp:105] Iteration 79900, lr = 1e-06
I0628 21:27:38.679939 15016 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:27:38.821555  6212 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/128K_iter_80000.caffemodel
I0628 21:27:38.831055  6212 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/128K_iter_80000.solverstate
I0628 21:27:38.868645  6212 solver.cpp:310] Iteration 80000, loss = 0.0946758
I0628 21:27:38.868645  6212 solver.cpp:330] Iteration 80000, Testing net (#0)
I0628 21:27:38.869154  6212 net.cpp:676] Ignoring source layer accuracy_training
I0628 21:27:39.681723  1380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 21:27:39.712245  6212 solver.cpp:397]     Test net output #0: accuracy = 0.8921
I0628 21:27:39.712245  6212 solver.cpp:397]     Test net output #1: loss = 0.354504 (* 1 = 0.354504 loss)
I0628 21:27:39.712245  6212 solver.cpp:315] Optimization Done.
I0628 21:27:39.712245  6212 caffe.cpp:260] Optimization Done.
G:\Caffe>