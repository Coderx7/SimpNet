
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0628 19:42:53.854567  1232 caffe.cpp:219] Using GPUs 0
I0628 19:42:54.039916  1232 caffe.cpp:224] GPU 0: GeForce GTX 1080
I0628 19:42:54.379942  1232 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 19:42:54.394953  1232 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 80000
snapshot_prefix: "examples/cifar10/128K"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 32000
stepvalue: 48000
stepvalue: 54000
stepvalue: 74000
type: "Nesterov"
I0628 19:42:54.395954  1232 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 19:42:54.395954  1232 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 19:42:54.395954  1232 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp4
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp5
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp6
I0628 19:42:54.396955  1232 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0628 19:42:54.396955  1232 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_13_128k_end1x1"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_12"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_12"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 53
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "conv4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 53
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp4"
  type: "Scale"
  bottom: "cccp4"
  top: "cccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "cccp4"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "pool4_2"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp5"
  type: "Scale"
  bottom: "cccp5"
  top: "cccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp6"
  type: "Scale"
  bottom: "cccp6"
  top: "cccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0628 19:42:54.397471  1232 layer_factory.cpp:58] Creating layer cifar
I0628 19:42:54.400476  1232 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I0628 19:42:54.400476  1232 net.cpp:84] Creating Layer cifar
I0628 19:42:54.400476  1232 net.cpp:380] cifar -> data
I0628 19:42:54.400476  1232 net.cpp:380] cifar -> label
I0628 19:42:54.400476  1232 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 19:42:54.401477  1232 data_layer.cpp:45] output data size: 100,3,32,32
I0628 19:42:54.406481  1232 net.cpp:122] Setting up cifar
I0628 19:42:54.406481  1232 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0628 19:42:54.407480  1232 net.cpp:129] Top shape: 100 (100)
I0628 19:42:54.407480  1232 net.cpp:137] Memory required for data: 1229200
I0628 19:42:54.407480  1232 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0628 19:42:54.407480  1232 net.cpp:84] Creating Layer label_cifar_1_split
I0628 19:42:54.407480  1232 net.cpp:406] label_cifar_1_split <- label
I0628 19:42:54.407480  1232 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0628 19:42:54.407480  1232 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0628 19:42:54.407480  1232 net.cpp:122] Setting up label_cifar_1_split
I0628 19:42:54.407480  1232 net.cpp:129] Top shape: 100 (100)
I0628 19:42:54.407480  1232 net.cpp:129] Top shape: 100 (100)
I0628 19:42:54.407480  1232 net.cpp:137] Memory required for data: 1230000
I0628 19:42:54.407480  1232 layer_factory.cpp:58] Creating layer conv1
I0628 19:42:54.407480  1232 net.cpp:84] Creating Layer conv1
I0628 19:42:54.407480  1232 net.cpp:406] conv1 <- data
I0628 19:42:54.407480  1232 net.cpp:380] conv1 -> conv1
I0628 19:42:54.407480 13656 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 19:42:54.639011  1232 net.cpp:122] Setting up conv1
I0628 19:42:54.639011  1232 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 19:42:54.639011  1232 net.cpp:137] Memory required for data: 9012400
I0628 19:42:54.639011  1232 layer_factory.cpp:58] Creating layer bn1
I0628 19:42:54.639011  1232 net.cpp:84] Creating Layer bn1
I0628 19:42:54.639011  1232 net.cpp:406] bn1 <- conv1
I0628 19:42:54.639011  1232 net.cpp:367] bn1 -> conv1 (in-place)
I0628 19:42:54.639011  1232 net.cpp:122] Setting up bn1
I0628 19:42:54.639011  1232 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 19:42:54.639011  1232 net.cpp:137] Memory required for data: 16794800
I0628 19:42:54.639011  1232 layer_factory.cpp:58] Creating layer scale1
I0628 19:42:54.639011  1232 net.cpp:84] Creating Layer scale1
I0628 19:42:54.639011  1232 net.cpp:406] scale1 <- conv1
I0628 19:42:54.639011  1232 net.cpp:367] scale1 -> conv1 (in-place)
I0628 19:42:54.639011  1232 layer_factory.cpp:58] Creating layer scale1
I0628 19:42:54.639011  1232 net.cpp:122] Setting up scale1
I0628 19:42:54.639011  1232 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 19:42:54.639011  1232 net.cpp:137] Memory required for data: 24577200
I0628 19:42:54.639011  1232 layer_factory.cpp:58] Creating layer relu1
I0628 19:42:54.639011  1232 net.cpp:84] Creating Layer relu1
I0628 19:42:54.639011  1232 net.cpp:406] relu1 <- conv1
I0628 19:42:54.639011  1232 net.cpp:367] relu1 -> conv1 (in-place)
I0628 19:42:54.639011  1232 net.cpp:122] Setting up relu1
I0628 19:42:54.639011  1232 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 19:42:54.639011  1232 net.cpp:137] Memory required for data: 32359600
I0628 19:42:54.639011  1232 layer_factory.cpp:58] Creating layer conv1_0
I0628 19:42:54.639011  1232 net.cpp:84] Creating Layer conv1_0
I0628 19:42:54.639011  1232 net.cpp:406] conv1_0 <- conv1
I0628 19:42:54.639011  1232 net.cpp:380] conv1_0 -> conv1_0
I0628 19:42:54.641014  1232 net.cpp:122] Setting up conv1_0
I0628 19:42:54.641014  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.641014  1232 net.cpp:137] Memory required for data: 42599600
I0628 19:42:54.641014  1232 layer_factory.cpp:58] Creating layer bn1_0
I0628 19:42:54.641014  1232 net.cpp:84] Creating Layer bn1_0
I0628 19:42:54.641014  1232 net.cpp:406] bn1_0 <- conv1_0
I0628 19:42:54.641014  1232 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0628 19:42:54.641014  1232 net.cpp:122] Setting up bn1_0
I0628 19:42:54.641014  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.641014  1232 net.cpp:137] Memory required for data: 52839600
I0628 19:42:54.641014  1232 layer_factory.cpp:58] Creating layer scale1_0
I0628 19:42:54.641014  1232 net.cpp:84] Creating Layer scale1_0
I0628 19:42:54.641014  1232 net.cpp:406] scale1_0 <- conv1_0
I0628 19:42:54.641014  1232 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0628 19:42:54.641014  1232 layer_factory.cpp:58] Creating layer scale1_0
I0628 19:42:54.641014  1232 net.cpp:122] Setting up scale1_0
I0628 19:42:54.641014  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.641014  1232 net.cpp:137] Memory required for data: 63079600
I0628 19:42:54.641014  1232 layer_factory.cpp:58] Creating layer relu1_0
I0628 19:42:54.641014  1232 net.cpp:84] Creating Layer relu1_0
I0628 19:42:54.641014  1232 net.cpp:406] relu1_0 <- conv1_0
I0628 19:42:54.641014  1232 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0628 19:42:54.642288  1232 net.cpp:122] Setting up relu1_0
I0628 19:42:54.642288  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.642288  1232 net.cpp:137] Memory required for data: 73319600
I0628 19:42:54.642288  1232 layer_factory.cpp:58] Creating layer conv2
I0628 19:42:54.642288  1232 net.cpp:84] Creating Layer conv2
I0628 19:42:54.642288  1232 net.cpp:406] conv2 <- conv1_0
I0628 19:42:54.642288  1232 net.cpp:380] conv2 -> conv2
I0628 19:42:54.642288  1232 net.cpp:122] Setting up conv2
I0628 19:42:54.642288  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.642288  1232 net.cpp:137] Memory required for data: 83559600
I0628 19:42:54.642288  1232 layer_factory.cpp:58] Creating layer bn2
I0628 19:42:54.642288  1232 net.cpp:84] Creating Layer bn2
I0628 19:42:54.642288  1232 net.cpp:406] bn2 <- conv2
I0628 19:42:54.642288  1232 net.cpp:367] bn2 -> conv2 (in-place)
I0628 19:42:54.643291  1232 net.cpp:122] Setting up bn2
I0628 19:42:54.643291  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.643291  1232 net.cpp:137] Memory required for data: 93799600
I0628 19:42:54.643291  1232 layer_factory.cpp:58] Creating layer scale2
I0628 19:42:54.643291  1232 net.cpp:84] Creating Layer scale2
I0628 19:42:54.643291  1232 net.cpp:406] scale2 <- conv2
I0628 19:42:54.643291  1232 net.cpp:367] scale2 -> conv2 (in-place)
I0628 19:42:54.643291  1232 layer_factory.cpp:58] Creating layer scale2
I0628 19:42:54.643291  1232 net.cpp:122] Setting up scale2
I0628 19:42:54.643291  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.643291  1232 net.cpp:137] Memory required for data: 104039600
I0628 19:42:54.643291  1232 layer_factory.cpp:58] Creating layer relu2
I0628 19:42:54.643291  1232 net.cpp:84] Creating Layer relu2
I0628 19:42:54.643291  1232 net.cpp:406] relu2 <- conv2
I0628 19:42:54.643291  1232 net.cpp:367] relu2 -> conv2 (in-place)
I0628 19:42:54.643838  1232 net.cpp:122] Setting up relu2
I0628 19:42:54.643838  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.643838  1232 net.cpp:137] Memory required for data: 114279600
I0628 19:42:54.643838  1232 layer_factory.cpp:58] Creating layer conv2_1
I0628 19:42:54.643838  1232 net.cpp:84] Creating Layer conv2_1
I0628 19:42:54.643838  1232 net.cpp:406] conv2_1 <- conv2
I0628 19:42:54.643838  1232 net.cpp:380] conv2_1 -> conv2_1
I0628 19:42:54.645014  1232 net.cpp:122] Setting up conv2_1
I0628 19:42:54.645014  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.645014  1232 net.cpp:137] Memory required for data: 124519600
I0628 19:42:54.645014  1232 layer_factory.cpp:58] Creating layer bn2_1
I0628 19:42:54.645014  1232 net.cpp:84] Creating Layer bn2_1
I0628 19:42:54.645014  1232 net.cpp:406] bn2_1 <- conv2_1
I0628 19:42:54.645014  1232 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0628 19:42:54.645014  1232 net.cpp:122] Setting up bn2_1
I0628 19:42:54.645014  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.645014  1232 net.cpp:137] Memory required for data: 134759600
I0628 19:42:54.645014  1232 layer_factory.cpp:58] Creating layer scale2_1
I0628 19:42:54.645014  1232 net.cpp:84] Creating Layer scale2_1
I0628 19:42:54.645014  1232 net.cpp:406] scale2_1 <- conv2_1
I0628 19:42:54.645014  1232 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0628 19:42:54.645014  1232 layer_factory.cpp:58] Creating layer scale2_1
I0628 19:42:54.645014  1232 net.cpp:122] Setting up scale2_1
I0628 19:42:54.645014  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.645014  1232 net.cpp:137] Memory required for data: 144999600
I0628 19:42:54.645014  1232 layer_factory.cpp:58] Creating layer relu2_1
I0628 19:42:54.645014  1232 net.cpp:84] Creating Layer relu2_1
I0628 19:42:54.645014  1232 net.cpp:406] relu2_1 <- conv2_1
I0628 19:42:54.645014  1232 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0628 19:42:54.645014  1232 net.cpp:122] Setting up relu2_1
I0628 19:42:54.645014  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.645014  1232 net.cpp:137] Memory required for data: 155239600
I0628 19:42:54.645014  1232 layer_factory.cpp:58] Creating layer conv2_2
I0628 19:42:54.645014  1232 net.cpp:84] Creating Layer conv2_2
I0628 19:42:54.645014  1232 net.cpp:406] conv2_2 <- conv2_1
I0628 19:42:54.645014  1232 net.cpp:380] conv2_2 -> conv2_2
I0628 19:42:54.647033  1232 net.cpp:122] Setting up conv2_2
I0628 19:42:54.647033  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.647033  1232 net.cpp:137] Memory required for data: 165479600
I0628 19:42:54.647033  1232 layer_factory.cpp:58] Creating layer bn2_2
I0628 19:42:54.647033  1232 net.cpp:84] Creating Layer bn2_2
I0628 19:42:54.647033  1232 net.cpp:406] bn2_2 <- conv2_2
I0628 19:42:54.647033  1232 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0628 19:42:54.647033  1232 net.cpp:122] Setting up bn2_2
I0628 19:42:54.647033  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.647033  1232 net.cpp:137] Memory required for data: 175719600
I0628 19:42:54.647033  1232 layer_factory.cpp:58] Creating layer scale2_2
I0628 19:42:54.647033  1232 net.cpp:84] Creating Layer scale2_2
I0628 19:42:54.647033  1232 net.cpp:406] scale2_2 <- conv2_2
I0628 19:42:54.647033  1232 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0628 19:42:54.647033  1232 layer_factory.cpp:58] Creating layer scale2_2
I0628 19:42:54.647033  1232 net.cpp:122] Setting up scale2_2
I0628 19:42:54.647033  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.647033  1232 net.cpp:137] Memory required for data: 185959600
I0628 19:42:54.647033  1232 layer_factory.cpp:58] Creating layer relu2_2
I0628 19:42:54.647033  1232 net.cpp:84] Creating Layer relu2_2
I0628 19:42:54.647033  1232 net.cpp:406] relu2_2 <- conv2_2
I0628 19:42:54.647033  1232 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0628 19:42:54.647033  1232 net.cpp:122] Setting up relu2_2
I0628 19:42:54.647033  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.647033  1232 net.cpp:137] Memory required for data: 196199600
I0628 19:42:54.647033  1232 layer_factory.cpp:58] Creating layer pool2_1
I0628 19:42:54.647033  1232 net.cpp:84] Creating Layer pool2_1
I0628 19:42:54.647033  1232 net.cpp:406] pool2_1 <- conv2_2
I0628 19:42:54.647033  1232 net.cpp:380] pool2_1 -> pool2_1
I0628 19:42:54.647033  1232 net.cpp:122] Setting up pool2_1
I0628 19:42:54.647033  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.647033  1232 net.cpp:137] Memory required for data: 198759600
I0628 19:42:54.647033  1232 layer_factory.cpp:58] Creating layer conv3
I0628 19:42:54.647033  1232 net.cpp:84] Creating Layer conv3
I0628 19:42:54.647033  1232 net.cpp:406] conv3 <- pool2_1
I0628 19:42:54.647033  1232 net.cpp:380] conv3 -> conv3
I0628 19:42:54.648365  1232 net.cpp:122] Setting up conv3
I0628 19:42:54.648365  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.648365  1232 net.cpp:137] Memory required for data: 201319600
I0628 19:42:54.648365  1232 layer_factory.cpp:58] Creating layer bn3
I0628 19:42:54.648365  1232 net.cpp:84] Creating Layer bn3
I0628 19:42:54.648365  1232 net.cpp:406] bn3 <- conv3
I0628 19:42:54.648365  1232 net.cpp:367] bn3 -> conv3 (in-place)
I0628 19:42:54.648365  1232 net.cpp:122] Setting up bn3
I0628 19:42:54.648365  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.648365  1232 net.cpp:137] Memory required for data: 203879600
I0628 19:42:54.648365  1232 layer_factory.cpp:58] Creating layer scale3
I0628 19:42:54.648365  1232 net.cpp:84] Creating Layer scale3
I0628 19:42:54.648365  1232 net.cpp:406] scale3 <- conv3
I0628 19:42:54.648365  1232 net.cpp:367] scale3 -> conv3 (in-place)
I0628 19:42:54.648365  1232 layer_factory.cpp:58] Creating layer scale3
I0628 19:42:54.648365  1232 net.cpp:122] Setting up scale3
I0628 19:42:54.648365  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.648365  1232 net.cpp:137] Memory required for data: 206439600
I0628 19:42:54.648365  1232 layer_factory.cpp:58] Creating layer relu3
I0628 19:42:54.648365  1232 net.cpp:84] Creating Layer relu3
I0628 19:42:54.648365  1232 net.cpp:406] relu3 <- conv3
I0628 19:42:54.648365  1232 net.cpp:367] relu3 -> conv3 (in-place)
I0628 19:42:54.649369  1232 net.cpp:122] Setting up relu3
I0628 19:42:54.649369  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.649369  1232 net.cpp:137] Memory required for data: 208999600
I0628 19:42:54.649369  1232 layer_factory.cpp:58] Creating layer conv4
I0628 19:42:54.649369  1232 net.cpp:84] Creating Layer conv4
I0628 19:42:54.649369  1232 net.cpp:406] conv4 <- conv3
I0628 19:42:54.649369  1232 net.cpp:380] conv4 -> conv4
I0628 19:42:54.650368  1232 net.cpp:122] Setting up conv4
I0628 19:42:54.650368  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.650368  1232 net.cpp:137] Memory required for data: 211559600
I0628 19:42:54.650368  1232 layer_factory.cpp:58] Creating layer bn4
I0628 19:42:54.650368  1232 net.cpp:84] Creating Layer bn4
I0628 19:42:54.650368  1232 net.cpp:406] bn4 <- conv4
I0628 19:42:54.650368  1232 net.cpp:367] bn4 -> conv4 (in-place)
I0628 19:42:54.650368  1232 net.cpp:122] Setting up bn4
I0628 19:42:54.650368  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.650368  1232 net.cpp:137] Memory required for data: 214119600
I0628 19:42:54.650368  1232 layer_factory.cpp:58] Creating layer scale4
I0628 19:42:54.650368  1232 net.cpp:84] Creating Layer scale4
I0628 19:42:54.650368  1232 net.cpp:406] scale4 <- conv4
I0628 19:42:54.650368  1232 net.cpp:367] scale4 -> conv4 (in-place)
I0628 19:42:54.650368  1232 layer_factory.cpp:58] Creating layer scale4
I0628 19:42:54.650368  1232 net.cpp:122] Setting up scale4
I0628 19:42:54.650368  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.650368  1232 net.cpp:137] Memory required for data: 216679600
I0628 19:42:54.650368  1232 layer_factory.cpp:58] Creating layer relu4
I0628 19:42:54.650368  1232 net.cpp:84] Creating Layer relu4
I0628 19:42:54.650368  1232 net.cpp:406] relu4 <- conv4
I0628 19:42:54.650368  1232 net.cpp:367] relu4 -> conv4 (in-place)
I0628 19:42:54.650368  1232 net.cpp:122] Setting up relu4
I0628 19:42:54.650368  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.650368  1232 net.cpp:137] Memory required for data: 219239600
I0628 19:42:54.650368  1232 layer_factory.cpp:58] Creating layer conv4_1
I0628 19:42:54.650368  1232 net.cpp:84] Creating Layer conv4_1
I0628 19:42:54.650368  1232 net.cpp:406] conv4_1 <- conv4
I0628 19:42:54.650368  1232 net.cpp:380] conv4_1 -> conv4_1
I0628 19:42:54.651370  1232 net.cpp:122] Setting up conv4_1
I0628 19:42:54.651370  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.651370  1232 net.cpp:137] Memory required for data: 221799600
I0628 19:42:54.651370  1232 layer_factory.cpp:58] Creating layer bn4_1
I0628 19:42:54.651370  1232 net.cpp:84] Creating Layer bn4_1
I0628 19:42:54.651370  1232 net.cpp:406] bn4_1 <- conv4_1
I0628 19:42:54.651370  1232 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0628 19:42:54.652370  1232 net.cpp:122] Setting up bn4_1
I0628 19:42:54.652370  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.652370  1232 net.cpp:137] Memory required for data: 224359600
I0628 19:42:54.652370  1232 layer_factory.cpp:58] Creating layer scale4_1
I0628 19:42:54.652370  1232 net.cpp:84] Creating Layer scale4_1
I0628 19:42:54.652370  1232 net.cpp:406] scale4_1 <- conv4_1
I0628 19:42:54.652370  1232 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0628 19:42:54.652370  1232 layer_factory.cpp:58] Creating layer scale4_1
I0628 19:42:54.652370  1232 net.cpp:122] Setting up scale4_1
I0628 19:42:54.652370  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.652370  1232 net.cpp:137] Memory required for data: 226919600
I0628 19:42:54.652370  1232 layer_factory.cpp:58] Creating layer relu4_1
I0628 19:42:54.652370  1232 net.cpp:84] Creating Layer relu4_1
I0628 19:42:54.652370  1232 net.cpp:406] relu4_1 <- conv4_1
I0628 19:42:54.652370  1232 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0628 19:42:54.653062  1232 net.cpp:122] Setting up relu4_1
I0628 19:42:54.653062  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.653062  1232 net.cpp:137] Memory required for data: 229479600
I0628 19:42:54.653062  1232 layer_factory.cpp:58] Creating layer conv4_2
I0628 19:42:54.653062  1232 net.cpp:84] Creating Layer conv4_2
I0628 19:42:54.653062  1232 net.cpp:406] conv4_2 <- conv4_1
I0628 19:42:54.653062  1232 net.cpp:380] conv4_2 -> conv4_2
I0628 19:42:54.654065  1232 net.cpp:122] Setting up conv4_2
I0628 19:42:54.654065  1232 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 19:42:54.654065  1232 net.cpp:137] Memory required for data: 236033200
I0628 19:42:54.654065  1232 layer_factory.cpp:58] Creating layer bn4_2
I0628 19:42:54.654065  1232 net.cpp:84] Creating Layer bn4_2
I0628 19:42:54.654065  1232 net.cpp:406] bn4_2 <- conv4_2
I0628 19:42:54.654065  1232 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0628 19:42:54.654065  1232 net.cpp:122] Setting up bn4_2
I0628 19:42:54.654065  1232 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 19:42:54.654065  1232 net.cpp:137] Memory required for data: 242586800
I0628 19:42:54.654065  1232 layer_factory.cpp:58] Creating layer scale4_2
I0628 19:42:54.654065  1232 net.cpp:84] Creating Layer scale4_2
I0628 19:42:54.654065  1232 net.cpp:406] scale4_2 <- conv4_2
I0628 19:42:54.654065  1232 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0628 19:42:54.654065  1232 layer_factory.cpp:58] Creating layer scale4_2
I0628 19:42:54.654065  1232 net.cpp:122] Setting up scale4_2
I0628 19:42:54.654065  1232 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 19:42:54.654065  1232 net.cpp:137] Memory required for data: 249140400
I0628 19:42:54.654065  1232 layer_factory.cpp:58] Creating layer relu4_2
I0628 19:42:54.654065  1232 net.cpp:84] Creating Layer relu4_2
I0628 19:42:54.654065  1232 net.cpp:406] relu4_2 <- conv4_2
I0628 19:42:54.654065  1232 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0628 19:42:54.654726  1232 net.cpp:122] Setting up relu4_2
I0628 19:42:54.654726  1232 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 19:42:54.654726  1232 net.cpp:137] Memory required for data: 255694000
I0628 19:42:54.654726  1232 layer_factory.cpp:58] Creating layer pool4_12
I0628 19:42:54.654726  1232 net.cpp:84] Creating Layer pool4_12
I0628 19:42:54.654726  1232 net.cpp:406] pool4_12 <- conv4_2
I0628 19:42:54.654726  1232 net.cpp:380] pool4_12 -> pool4_12
I0628 19:42:54.654726  1232 net.cpp:122] Setting up pool4_12
I0628 19:42:54.654726  1232 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0628 19:42:54.654726  1232 net.cpp:137] Memory required for data: 257332400
I0628 19:42:54.654726  1232 layer_factory.cpp:58] Creating layer conv4_0
I0628 19:42:54.654726  1232 net.cpp:84] Creating Layer conv4_0
I0628 19:42:54.654726  1232 net.cpp:406] conv4_0 <- pool4_12
I0628 19:42:54.654726  1232 net.cpp:380] conv4_0 -> conv4_0
I0628 19:42:54.656730  1232 net.cpp:122] Setting up conv4_0
I0628 19:42:54.656730  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.656730  1232 net.cpp:137] Memory required for data: 258689200
I0628 19:42:54.656730  1232 layer_factory.cpp:58] Creating layer bn4_0
I0628 19:42:54.656730  1232 net.cpp:84] Creating Layer bn4_0
I0628 19:42:54.656730  1232 net.cpp:406] bn4_0 <- conv4_0
I0628 19:42:54.656730  1232 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0628 19:42:54.656730  1232 net.cpp:122] Setting up bn4_0
I0628 19:42:54.656730  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.656730  1232 net.cpp:137] Memory required for data: 260046000
I0628 19:42:54.656730  1232 layer_factory.cpp:58] Creating layer scale4_0
I0628 19:42:54.656730  1232 net.cpp:84] Creating Layer scale4_0
I0628 19:42:54.656730  1232 net.cpp:406] scale4_0 <- conv4_0
I0628 19:42:54.656730  1232 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0628 19:42:54.656730  1232 layer_factory.cpp:58] Creating layer scale4_0
I0628 19:42:54.656730  1232 net.cpp:122] Setting up scale4_0
I0628 19:42:54.656730  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.656730  1232 net.cpp:137] Memory required for data: 261402800
I0628 19:42:54.656730  1232 layer_factory.cpp:58] Creating layer relu4_0
I0628 19:42:54.656730  1232 net.cpp:84] Creating Layer relu4_0
I0628 19:42:54.656730  1232 net.cpp:406] relu4_0 <- conv4_0
I0628 19:42:54.656730  1232 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0628 19:42:54.656730  1232 net.cpp:122] Setting up relu4_0
I0628 19:42:54.656730  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.656730  1232 net.cpp:137] Memory required for data: 262759600
I0628 19:42:54.656730  1232 layer_factory.cpp:58] Creating layer cccp4
I0628 19:42:54.656730  1232 net.cpp:84] Creating Layer cccp4
I0628 19:42:54.656730  1232 net.cpp:406] cccp4 <- conv4_0
I0628 19:42:54.656730  1232 net.cpp:380] cccp4 -> cccp4
I0628 19:42:54.657732  1232 net.cpp:122] Setting up cccp4
I0628 19:42:54.657732  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.657732  1232 net.cpp:137] Memory required for data: 264116400
I0628 19:42:54.657732  1232 layer_factory.cpp:58] Creating layer bn_cccp4
I0628 19:42:54.657732  1232 net.cpp:84] Creating Layer bn_cccp4
I0628 19:42:54.657732  1232 net.cpp:406] bn_cccp4 <- cccp4
I0628 19:42:54.657732  1232 net.cpp:367] bn_cccp4 -> cccp4 (in-place)
I0628 19:42:54.658730  1232 net.cpp:122] Setting up bn_cccp4
I0628 19:42:54.658730  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.658730  1232 net.cpp:137] Memory required for data: 265473200
I0628 19:42:54.658730  1232 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 19:42:54.658730  1232 net.cpp:84] Creating Layer scale_cccp4
I0628 19:42:54.658730  1232 net.cpp:406] scale_cccp4 <- cccp4
I0628 19:42:54.658730  1232 net.cpp:367] scale_cccp4 -> cccp4 (in-place)
I0628 19:42:54.658730  1232 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 19:42:54.658730  1232 net.cpp:122] Setting up scale_cccp4
I0628 19:42:54.658730  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.658730  1232 net.cpp:137] Memory required for data: 266830000
I0628 19:42:54.658730  1232 layer_factory.cpp:58] Creating layer relu_cccp4
I0628 19:42:54.658730  1232 net.cpp:84] Creating Layer relu_cccp4
I0628 19:42:54.658730  1232 net.cpp:406] relu_cccp4 <- cccp4
I0628 19:42:54.658730  1232 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0628 19:42:54.658730  1232 net.cpp:122] Setting up relu_cccp4
I0628 19:42:54.658730  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.658730  1232 net.cpp:137] Memory required for data: 268186800
I0628 19:42:54.658730  1232 layer_factory.cpp:58] Creating layer pool4_2
I0628 19:42:54.658730  1232 net.cpp:84] Creating Layer pool4_2
I0628 19:42:54.658730  1232 net.cpp:406] pool4_2 <- cccp4
I0628 19:42:54.658730  1232 net.cpp:380] pool4_2 -> pool4_2
I0628 19:42:54.658730  1232 net.cpp:122] Setting up pool4_2
I0628 19:42:54.658730  1232 net.cpp:129] Top shape: 100 53 4 4 (84800)
I0628 19:42:54.658730  1232 net.cpp:137] Memory required for data: 268526000
I0628 19:42:54.658730  1232 layer_factory.cpp:58] Creating layer cccp5
I0628 19:42:54.658730  1232 net.cpp:84] Creating Layer cccp5
I0628 19:42:54.658730  1232 net.cpp:406] cccp5 <- pool4_2
I0628 19:42:54.658730  1232 net.cpp:380] cccp5 -> cccp5
I0628 19:42:54.660084  1232 net.cpp:122] Setting up cccp5
I0628 19:42:54.660084  1232 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 19:42:54.660084  1232 net.cpp:137] Memory required for data: 270081200
I0628 19:42:54.660084  1232 layer_factory.cpp:58] Creating layer bn_cccp5
I0628 19:42:54.660084  1232 net.cpp:84] Creating Layer bn_cccp5
I0628 19:42:54.660084  1232 net.cpp:406] bn_cccp5 <- cccp5
I0628 19:42:54.660084  1232 net.cpp:367] bn_cccp5 -> cccp5 (in-place)
I0628 19:42:54.660084  1232 net.cpp:122] Setting up bn_cccp5
I0628 19:42:54.660084  1232 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 19:42:54.660084  1232 net.cpp:137] Memory required for data: 271636400
I0628 19:42:54.660084  1232 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 19:42:54.660084  1232 net.cpp:84] Creating Layer scale_cccp5
I0628 19:42:54.660084  1232 net.cpp:406] scale_cccp5 <- cccp5
I0628 19:42:54.660084  1232 net.cpp:367] scale_cccp5 -> cccp5 (in-place)
I0628 19:42:54.660084  1232 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 19:42:54.661087  1232 net.cpp:122] Setting up scale_cccp5
I0628 19:42:54.661087  1232 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 19:42:54.661087  1232 net.cpp:137] Memory required for data: 273191600
I0628 19:42:54.661087  1232 layer_factory.cpp:58] Creating layer relu_cccp5
I0628 19:42:54.661087  1232 net.cpp:84] Creating Layer relu_cccp5
I0628 19:42:54.661087  1232 net.cpp:406] relu_cccp5 <- cccp5
I0628 19:42:54.661087  1232 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0628 19:42:54.661087  1232 net.cpp:122] Setting up relu_cccp5
I0628 19:42:54.661087  1232 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 19:42:54.661087  1232 net.cpp:137] Memory required for data: 274746800
I0628 19:42:54.661087  1232 layer_factory.cpp:58] Creating layer poolcp5
I0628 19:42:54.661087  1232 net.cpp:84] Creating Layer poolcp5
I0628 19:42:54.661087  1232 net.cpp:406] poolcp5 <- cccp5
I0628 19:42:54.661087  1232 net.cpp:380] poolcp5 -> poolcp5
I0628 19:42:54.661087  1232 net.cpp:122] Setting up poolcp5
I0628 19:42:54.661087  1232 net.cpp:129] Top shape: 100 108 3 3 (97200)
I0628 19:42:54.661087  1232 net.cpp:137] Memory required for data: 275135600
I0628 19:42:54.661087  1232 layer_factory.cpp:58] Creating layer cccp6
I0628 19:42:54.661087  1232 net.cpp:84] Creating Layer cccp6
I0628 19:42:54.661087  1232 net.cpp:406] cccp6 <- poolcp5
I0628 19:42:54.661087  1232 net.cpp:380] cccp6 -> cccp6
I0628 19:42:54.661923  1232 net.cpp:122] Setting up cccp6
I0628 19:42:54.661923  1232 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 19:42:54.661923  1232 net.cpp:137] Memory required for data: 276215600
I0628 19:42:54.661923  1232 layer_factory.cpp:58] Creating layer bn_cccp6
I0628 19:42:54.661923  1232 net.cpp:84] Creating Layer bn_cccp6
I0628 19:42:54.661923  1232 net.cpp:406] bn_cccp6 <- cccp6
I0628 19:42:54.661923  1232 net.cpp:367] bn_cccp6 -> cccp6 (in-place)
I0628 19:42:54.661923  1232 net.cpp:122] Setting up bn_cccp6
I0628 19:42:54.661923  1232 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 19:42:54.661923  1232 net.cpp:137] Memory required for data: 277295600
I0628 19:42:54.661923  1232 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 19:42:54.661923  1232 net.cpp:84] Creating Layer scale_cccp6
I0628 19:42:54.661923  1232 net.cpp:406] scale_cccp6 <- cccp6
I0628 19:42:54.661923  1232 net.cpp:367] scale_cccp6 -> cccp6 (in-place)
I0628 19:42:54.661923  1232 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 19:42:54.661923  1232 net.cpp:122] Setting up scale_cccp6
I0628 19:42:54.661923  1232 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 19:42:54.661923  1232 net.cpp:137] Memory required for data: 278375600
I0628 19:42:54.661923  1232 layer_factory.cpp:58] Creating layer relu_cccp6
I0628 19:42:54.661923  1232 net.cpp:84] Creating Layer relu_cccp6
I0628 19:42:54.661923  1232 net.cpp:406] relu_cccp6 <- cccp6
I0628 19:42:54.661923  1232 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0628 19:42:54.662927  1232 net.cpp:122] Setting up relu_cccp6
I0628 19:42:54.662927  1232 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 19:42:54.662927  1232 net.cpp:137] Memory required for data: 279455600
I0628 19:42:54.662927  1232 layer_factory.cpp:58] Creating layer poolcp6
I0628 19:42:54.662927  1232 net.cpp:84] Creating Layer poolcp6
I0628 19:42:54.662927  1232 net.cpp:406] poolcp6 <- cccp6
I0628 19:42:54.662927  1232 net.cpp:380] poolcp6 -> poolcp6
I0628 19:42:54.662927  1232 net.cpp:122] Setting up poolcp6
I0628 19:42:54.662927  1232 net.cpp:129] Top shape: 100 108 1 1 (10800)
I0628 19:42:54.662927  1232 net.cpp:137] Memory required for data: 279498800
I0628 19:42:54.662927  1232 layer_factory.cpp:58] Creating layer ip1
I0628 19:42:54.662927  1232 net.cpp:84] Creating Layer ip1
I0628 19:42:54.662927  1232 net.cpp:406] ip1 <- poolcp6
I0628 19:42:54.662927  1232 net.cpp:380] ip1 -> ip1
I0628 19:42:54.663928  1232 net.cpp:122] Setting up ip1
I0628 19:42:54.663928  1232 net.cpp:129] Top shape: 100 10 (1000)
I0628 19:42:54.663928  1232 net.cpp:137] Memory required for data: 279502800
I0628 19:42:54.663928  1232 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0628 19:42:54.663928  1232 net.cpp:84] Creating Layer ip1_ip1_0_split
I0628 19:42:54.663928  1232 net.cpp:406] ip1_ip1_0_split <- ip1
I0628 19:42:54.663928  1232 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0628 19:42:54.663928  1232 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0628 19:42:54.663928  1232 net.cpp:122] Setting up ip1_ip1_0_split
I0628 19:42:54.663928  1232 net.cpp:129] Top shape: 100 10 (1000)
I0628 19:42:54.663928  1232 net.cpp:129] Top shape: 100 10 (1000)
I0628 19:42:54.663928  1232 net.cpp:137] Memory required for data: 279510800
I0628 19:42:54.663928  1232 layer_factory.cpp:58] Creating layer accuracy_training
I0628 19:42:54.663928  1232 net.cpp:84] Creating Layer accuracy_training
I0628 19:42:54.663928  1232 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0628 19:42:54.663928  1232 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I0628 19:42:54.663928  1232 net.cpp:380] accuracy_training -> accuracy_training
I0628 19:42:54.663928  1232 net.cpp:122] Setting up accuracy_training
I0628 19:42:54.663928  1232 net.cpp:129] Top shape: (1)
I0628 19:42:54.663928  1232 net.cpp:137] Memory required for data: 279510804
I0628 19:42:54.663928  1232 layer_factory.cpp:58] Creating layer loss
I0628 19:42:54.663928  1232 net.cpp:84] Creating Layer loss
I0628 19:42:54.663928  1232 net.cpp:406] loss <- ip1_ip1_0_split_1
I0628 19:42:54.663928  1232 net.cpp:406] loss <- label_cifar_1_split_1
I0628 19:42:54.663928  1232 net.cpp:380] loss -> loss
I0628 19:42:54.663928  1232 layer_factory.cpp:58] Creating layer loss
I0628 19:42:54.664417  1232 net.cpp:122] Setting up loss
I0628 19:42:54.664417  1232 net.cpp:129] Top shape: (1)
I0628 19:42:54.664417  1232 net.cpp:132]     with loss weight 1
I0628 19:42:54.664417  1232 net.cpp:137] Memory required for data: 279510808
I0628 19:42:54.664417  1232 net.cpp:198] loss needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:200] accuracy_training does not need backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] ip1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] poolcp6 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu_cccp6 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale_cccp6 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn_cccp6 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] cccp6 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] poolcp5 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu_cccp5 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale_cccp5 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn_cccp5 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] cccp5 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] pool4_2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu_cccp4 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale_cccp4 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn_cccp4 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] cccp4 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu4_0 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale4_0 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn4_0 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] conv4_0 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] pool4_12 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu4_2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale4_2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn4_2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] conv4_2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu4_1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale4_1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn4_1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] conv4_1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu4 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale4 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn4 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] conv4 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu3 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale3 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn3 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] conv3 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] pool2_1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu2_2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale2_2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn2_2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] conv2_2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu2_1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale2_1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn2_1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] conv2_1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] conv2 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu1_0 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale1_0 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn1_0 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] conv1_0 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] relu1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] scale1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] bn1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:198] conv1 needs backward computation.
I0628 19:42:54.664417  1232 net.cpp:200] label_cifar_1_split does not need backward computation.
I0628 19:42:54.664417  1232 net.cpp:200] cifar does not need backward computation.
I0628 19:42:54.664417  1232 net.cpp:242] This network produces output accuracy_training
I0628 19:42:54.664417  1232 net.cpp:242] This network produces output loss
I0628 19:42:54.664417  1232 net.cpp:255] Network initialization done.
I0628 19:42:54.665421  1232 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 19:42:54.665421  1232 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0628 19:42:54.665421  1232 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp4
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp5
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp6
I0628 19:42:54.665421  1232 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0628 19:42:54.665421  1232 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_13_128k_end1x1"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 25
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_12"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_12"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 53
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "conv4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 53
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp4"
  type: "Scale"
  bottom: "cccp4"
  top: "cccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "cccp4"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "pool4_2"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp5"
  type: "Scale"
  bottom: "cccp5"
  top: "cccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 108
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_cccp6"
  type: "Scale"
  bottom: "cccp6"
  top: "cccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0628 19:42:54.666421  1232 layer_factory.cpp:58] Creating layer cifar
I0628 19:42:54.671424  1232 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I0628 19:42:54.671424  1232 net.cpp:84] Creating Layer cifar
I0628 19:42:54.671424  1232 net.cpp:380] cifar -> data
I0628 19:42:54.671424  1232 net.cpp:380] cifar -> label
I0628 19:42:54.671424  1232 data_layer.cpp:45] output data size: 100,3,32,32
I0628 19:42:54.677433  1232 net.cpp:122] Setting up cifar
I0628 19:42:54.677433  1232 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0628 19:42:54.677433  1232 net.cpp:129] Top shape: 100 (100)
I0628 19:42:54.677433  1232 net.cpp:137] Memory required for data: 1229200
I0628 19:42:54.677433  1232 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0628 19:42:54.677433  1232 net.cpp:84] Creating Layer label_cifar_1_split
I0628 19:42:54.677433  1232 net.cpp:406] label_cifar_1_split <- label
I0628 19:42:54.677433  1232 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0628 19:42:54.677433  1232 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0628 19:42:54.677433  1232 net.cpp:122] Setting up label_cifar_1_split
I0628 19:42:54.677433  1232 net.cpp:129] Top shape: 100 (100)
I0628 19:42:54.677433  1232 net.cpp:129] Top shape: 100 (100)
I0628 19:42:54.677433  1232 net.cpp:137] Memory required for data: 1230000
I0628 19:42:54.677433  1232 layer_factory.cpp:58] Creating layer conv1
I0628 19:42:54.677433  1232 net.cpp:84] Creating Layer conv1
I0628 19:42:54.677433  1232 net.cpp:406] conv1 <- data
I0628 19:42:54.677433  1232 net.cpp:380] conv1 -> conv1
I0628 19:42:54.678429 13380 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0628 19:42:54.678429  1232 net.cpp:122] Setting up conv1
I0628 19:42:54.678429  1232 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 19:42:54.678429  1232 net.cpp:137] Memory required for data: 9012400
I0628 19:42:54.678429  1232 layer_factory.cpp:58] Creating layer bn1
I0628 19:42:54.678429  1232 net.cpp:84] Creating Layer bn1
I0628 19:42:54.678429  1232 net.cpp:406] bn1 <- conv1
I0628 19:42:54.678429  1232 net.cpp:367] bn1 -> conv1 (in-place)
I0628 19:42:54.679430  1232 net.cpp:122] Setting up bn1
I0628 19:42:54.679430  1232 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 19:42:54.679430  1232 net.cpp:137] Memory required for data: 16794800
I0628 19:42:54.679430  1232 layer_factory.cpp:58] Creating layer scale1
I0628 19:42:54.679430  1232 net.cpp:84] Creating Layer scale1
I0628 19:42:54.679430  1232 net.cpp:406] scale1 <- conv1
I0628 19:42:54.679430  1232 net.cpp:367] scale1 -> conv1 (in-place)
I0628 19:42:54.679430  1232 layer_factory.cpp:58] Creating layer scale1
I0628 19:42:54.679430  1232 net.cpp:122] Setting up scale1
I0628 19:42:54.679430  1232 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 19:42:54.679430  1232 net.cpp:137] Memory required for data: 24577200
I0628 19:42:54.679430  1232 layer_factory.cpp:58] Creating layer relu1
I0628 19:42:54.679430  1232 net.cpp:84] Creating Layer relu1
I0628 19:42:54.679430  1232 net.cpp:406] relu1 <- conv1
I0628 19:42:54.679430  1232 net.cpp:367] relu1 -> conv1 (in-place)
I0628 19:42:54.679430  1232 net.cpp:122] Setting up relu1
I0628 19:42:54.679430  1232 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0628 19:42:54.679430  1232 net.cpp:137] Memory required for data: 32359600
I0628 19:42:54.679430  1232 layer_factory.cpp:58] Creating layer conv1_0
I0628 19:42:54.679430  1232 net.cpp:84] Creating Layer conv1_0
I0628 19:42:54.679430  1232 net.cpp:406] conv1_0 <- conv1
I0628 19:42:54.679430  1232 net.cpp:380] conv1_0 -> conv1_0
I0628 19:42:54.680430  1232 net.cpp:122] Setting up conv1_0
I0628 19:42:54.680430  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.680430  1232 net.cpp:137] Memory required for data: 42599600
I0628 19:42:54.680430  1232 layer_factory.cpp:58] Creating layer bn1_0
I0628 19:42:54.680430  1232 net.cpp:84] Creating Layer bn1_0
I0628 19:42:54.680430  1232 net.cpp:406] bn1_0 <- conv1_0
I0628 19:42:54.680430  1232 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0628 19:42:54.680430  1232 net.cpp:122] Setting up bn1_0
I0628 19:42:54.680430  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.680430  1232 net.cpp:137] Memory required for data: 52839600
I0628 19:42:54.680430  1232 layer_factory.cpp:58] Creating layer scale1_0
I0628 19:42:54.680430  1232 net.cpp:84] Creating Layer scale1_0
I0628 19:42:54.680430  1232 net.cpp:406] scale1_0 <- conv1_0
I0628 19:42:54.681432  1232 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0628 19:42:54.681432  1232 layer_factory.cpp:58] Creating layer scale1_0
I0628 19:42:54.681432  1232 net.cpp:122] Setting up scale1_0
I0628 19:42:54.681432  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.681432  1232 net.cpp:137] Memory required for data: 63079600
I0628 19:42:54.681432  1232 layer_factory.cpp:58] Creating layer relu1_0
I0628 19:42:54.681432  1232 net.cpp:84] Creating Layer relu1_0
I0628 19:42:54.681432  1232 net.cpp:406] relu1_0 <- conv1_0
I0628 19:42:54.681432  1232 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0628 19:42:54.681432  1232 net.cpp:122] Setting up relu1_0
I0628 19:42:54.681432  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.681432  1232 net.cpp:137] Memory required for data: 73319600
I0628 19:42:54.681432  1232 layer_factory.cpp:58] Creating layer conv2
I0628 19:42:54.681432  1232 net.cpp:84] Creating Layer conv2
I0628 19:42:54.681432  1232 net.cpp:406] conv2 <- conv1_0
I0628 19:42:54.681432  1232 net.cpp:380] conv2 -> conv2
I0628 19:42:54.682803  1232 net.cpp:122] Setting up conv2
I0628 19:42:54.682803  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.682803  1232 net.cpp:137] Memory required for data: 83559600
I0628 19:42:54.682803  1232 layer_factory.cpp:58] Creating layer bn2
I0628 19:42:54.682803  1232 net.cpp:84] Creating Layer bn2
I0628 19:42:54.682803  1232 net.cpp:406] bn2 <- conv2
I0628 19:42:54.682803  1232 net.cpp:367] bn2 -> conv2 (in-place)
I0628 19:42:54.682803  1232 net.cpp:122] Setting up bn2
I0628 19:42:54.682803  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.682803  1232 net.cpp:137] Memory required for data: 93799600
I0628 19:42:54.682803  1232 layer_factory.cpp:58] Creating layer scale2
I0628 19:42:54.682803  1232 net.cpp:84] Creating Layer scale2
I0628 19:42:54.682803  1232 net.cpp:406] scale2 <- conv2
I0628 19:42:54.682803  1232 net.cpp:367] scale2 -> conv2 (in-place)
I0628 19:42:54.682803  1232 layer_factory.cpp:58] Creating layer scale2
I0628 19:42:54.683806  1232 net.cpp:122] Setting up scale2
I0628 19:42:54.683806  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.683806  1232 net.cpp:137] Memory required for data: 104039600
I0628 19:42:54.683806  1232 layer_factory.cpp:58] Creating layer relu2
I0628 19:42:54.683806  1232 net.cpp:84] Creating Layer relu2
I0628 19:42:54.683806  1232 net.cpp:406] relu2 <- conv2
I0628 19:42:54.683806  1232 net.cpp:367] relu2 -> conv2 (in-place)
I0628 19:42:54.683806  1232 net.cpp:122] Setting up relu2
I0628 19:42:54.683806  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.683806  1232 net.cpp:137] Memory required for data: 114279600
I0628 19:42:54.683806  1232 layer_factory.cpp:58] Creating layer conv2_1
I0628 19:42:54.683806  1232 net.cpp:84] Creating Layer conv2_1
I0628 19:42:54.683806  1232 net.cpp:406] conv2_1 <- conv2
I0628 19:42:54.683806  1232 net.cpp:380] conv2_1 -> conv2_1
I0628 19:42:54.684808  1232 net.cpp:122] Setting up conv2_1
I0628 19:42:54.685807  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.685807  1232 net.cpp:137] Memory required for data: 124519600
I0628 19:42:54.685807  1232 layer_factory.cpp:58] Creating layer bn2_1
I0628 19:42:54.685807  1232 net.cpp:84] Creating Layer bn2_1
I0628 19:42:54.685807  1232 net.cpp:406] bn2_1 <- conv2_1
I0628 19:42:54.685807  1232 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0628 19:42:54.685807  1232 net.cpp:122] Setting up bn2_1
I0628 19:42:54.685807  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.685807  1232 net.cpp:137] Memory required for data: 134759600
I0628 19:42:54.685807  1232 layer_factory.cpp:58] Creating layer scale2_1
I0628 19:42:54.685807  1232 net.cpp:84] Creating Layer scale2_1
I0628 19:42:54.685807  1232 net.cpp:406] scale2_1 <- conv2_1
I0628 19:42:54.685807  1232 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0628 19:42:54.685807  1232 layer_factory.cpp:58] Creating layer scale2_1
I0628 19:42:54.685807  1232 net.cpp:122] Setting up scale2_1
I0628 19:42:54.685807  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.685807  1232 net.cpp:137] Memory required for data: 144999600
I0628 19:42:54.685807  1232 layer_factory.cpp:58] Creating layer relu2_1
I0628 19:42:54.685807  1232 net.cpp:84] Creating Layer relu2_1
I0628 19:42:54.685807  1232 net.cpp:406] relu2_1 <- conv2_1
I0628 19:42:54.685807  1232 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0628 19:42:54.685807  1232 net.cpp:122] Setting up relu2_1
I0628 19:42:54.685807  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.685807  1232 net.cpp:137] Memory required for data: 155239600
I0628 19:42:54.685807  1232 layer_factory.cpp:58] Creating layer conv2_2
I0628 19:42:54.685807  1232 net.cpp:84] Creating Layer conv2_2
I0628 19:42:54.685807  1232 net.cpp:406] conv2_2 <- conv2_1
I0628 19:42:54.685807  1232 net.cpp:380] conv2_2 -> conv2_2
I0628 19:42:54.687809  1232 net.cpp:122] Setting up conv2_2
I0628 19:42:54.687809  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.687809  1232 net.cpp:137] Memory required for data: 165479600
I0628 19:42:54.687809  1232 layer_factory.cpp:58] Creating layer bn2_2
I0628 19:42:54.687809  1232 net.cpp:84] Creating Layer bn2_2
I0628 19:42:54.687809  1232 net.cpp:406] bn2_2 <- conv2_2
I0628 19:42:54.687809  1232 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0628 19:42:54.687809  1232 net.cpp:122] Setting up bn2_2
I0628 19:42:54.687809  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.687809  1232 net.cpp:137] Memory required for data: 175719600
I0628 19:42:54.687809  1232 layer_factory.cpp:58] Creating layer scale2_2
I0628 19:42:54.687809  1232 net.cpp:84] Creating Layer scale2_2
I0628 19:42:54.687809  1232 net.cpp:406] scale2_2 <- conv2_2
I0628 19:42:54.687809  1232 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0628 19:42:54.687809  1232 layer_factory.cpp:58] Creating layer scale2_2
I0628 19:42:54.687809  1232 net.cpp:122] Setting up scale2_2
I0628 19:42:54.687809  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.687809  1232 net.cpp:137] Memory required for data: 185959600
I0628 19:42:54.687809  1232 layer_factory.cpp:58] Creating layer relu2_2
I0628 19:42:54.687809  1232 net.cpp:84] Creating Layer relu2_2
I0628 19:42:54.687809  1232 net.cpp:406] relu2_2 <- conv2_2
I0628 19:42:54.687809  1232 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0628 19:42:54.688810  1232 net.cpp:122] Setting up relu2_2
I0628 19:42:54.688810  1232 net.cpp:129] Top shape: 100 25 32 32 (2560000)
I0628 19:42:54.688810  1232 net.cpp:137] Memory required for data: 196199600
I0628 19:42:54.688810  1232 layer_factory.cpp:58] Creating layer pool2_1
I0628 19:42:54.688810  1232 net.cpp:84] Creating Layer pool2_1
I0628 19:42:54.688810  1232 net.cpp:406] pool2_1 <- conv2_2
I0628 19:42:54.688810  1232 net.cpp:380] pool2_1 -> pool2_1
I0628 19:42:54.688810  1232 net.cpp:122] Setting up pool2_1
I0628 19:42:54.688810  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.688810  1232 net.cpp:137] Memory required for data: 198759600
I0628 19:42:54.688810  1232 layer_factory.cpp:58] Creating layer conv3
I0628 19:42:54.688810  1232 net.cpp:84] Creating Layer conv3
I0628 19:42:54.688810  1232 net.cpp:406] conv3 <- pool2_1
I0628 19:42:54.688810  1232 net.cpp:380] conv3 -> conv3
I0628 19:42:54.689810  1232 net.cpp:122] Setting up conv3
I0628 19:42:54.689810  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.689810  1232 net.cpp:137] Memory required for data: 201319600
I0628 19:42:54.689810  1232 layer_factory.cpp:58] Creating layer bn3
I0628 19:42:54.689810  1232 net.cpp:84] Creating Layer bn3
I0628 19:42:54.689810  1232 net.cpp:406] bn3 <- conv3
I0628 19:42:54.689810  1232 net.cpp:367] bn3 -> conv3 (in-place)
I0628 19:42:54.689810  1232 net.cpp:122] Setting up bn3
I0628 19:42:54.689810  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.689810  1232 net.cpp:137] Memory required for data: 203879600
I0628 19:42:54.689810  1232 layer_factory.cpp:58] Creating layer scale3
I0628 19:42:54.689810  1232 net.cpp:84] Creating Layer scale3
I0628 19:42:54.689810  1232 net.cpp:406] scale3 <- conv3
I0628 19:42:54.689810  1232 net.cpp:367] scale3 -> conv3 (in-place)
I0628 19:42:54.689810  1232 layer_factory.cpp:58] Creating layer scale3
I0628 19:42:54.689810  1232 net.cpp:122] Setting up scale3
I0628 19:42:54.689810  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.689810  1232 net.cpp:137] Memory required for data: 206439600
I0628 19:42:54.689810  1232 layer_factory.cpp:58] Creating layer relu3
I0628 19:42:54.689810  1232 net.cpp:84] Creating Layer relu3
I0628 19:42:54.689810  1232 net.cpp:406] relu3 <- conv3
I0628 19:42:54.689810  1232 net.cpp:367] relu3 -> conv3 (in-place)
I0628 19:42:54.690814  1232 net.cpp:122] Setting up relu3
I0628 19:42:54.690814  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.690814  1232 net.cpp:137] Memory required for data: 208999600
I0628 19:42:54.690814  1232 layer_factory.cpp:58] Creating layer conv4
I0628 19:42:54.690814  1232 net.cpp:84] Creating Layer conv4
I0628 19:42:54.690814  1232 net.cpp:406] conv4 <- conv3
I0628 19:42:54.690814  1232 net.cpp:380] conv4 -> conv4
I0628 19:42:54.691810  1232 net.cpp:122] Setting up conv4
I0628 19:42:54.691810  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.691810  1232 net.cpp:137] Memory required for data: 211559600
I0628 19:42:54.691810  1232 layer_factory.cpp:58] Creating layer bn4
I0628 19:42:54.691810  1232 net.cpp:84] Creating Layer bn4
I0628 19:42:54.691810  1232 net.cpp:406] bn4 <- conv4
I0628 19:42:54.691810  1232 net.cpp:367] bn4 -> conv4 (in-place)
I0628 19:42:54.691810  1232 net.cpp:122] Setting up bn4
I0628 19:42:54.691810  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.691810  1232 net.cpp:137] Memory required for data: 214119600
I0628 19:42:54.692813  1232 layer_factory.cpp:58] Creating layer scale4
I0628 19:42:54.692813  1232 net.cpp:84] Creating Layer scale4
I0628 19:42:54.692813  1232 net.cpp:406] scale4 <- conv4
I0628 19:42:54.692813  1232 net.cpp:367] scale4 -> conv4 (in-place)
I0628 19:42:54.692813  1232 layer_factory.cpp:58] Creating layer scale4
I0628 19:42:54.692813  1232 net.cpp:122] Setting up scale4
I0628 19:42:54.692813  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.692813  1232 net.cpp:137] Memory required for data: 216679600
I0628 19:42:54.692813  1232 layer_factory.cpp:58] Creating layer relu4
I0628 19:42:54.692813  1232 net.cpp:84] Creating Layer relu4
I0628 19:42:54.692813  1232 net.cpp:406] relu4 <- conv4
I0628 19:42:54.692813  1232 net.cpp:367] relu4 -> conv4 (in-place)
I0628 19:42:54.692813  1232 net.cpp:122] Setting up relu4
I0628 19:42:54.692813  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.692813  1232 net.cpp:137] Memory required for data: 219239600
I0628 19:42:54.692813  1232 layer_factory.cpp:58] Creating layer conv4_1
I0628 19:42:54.692813  1232 net.cpp:84] Creating Layer conv4_1
I0628 19:42:54.692813  1232 net.cpp:406] conv4_1 <- conv4
I0628 19:42:54.692813  1232 net.cpp:380] conv4_1 -> conv4_1
I0628 19:42:54.694097  1232 net.cpp:122] Setting up conv4_1
I0628 19:42:54.694097  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.694097  1232 net.cpp:137] Memory required for data: 221799600
I0628 19:42:54.694097  1232 layer_factory.cpp:58] Creating layer bn4_1
I0628 19:42:54.694097  1232 net.cpp:84] Creating Layer bn4_1
I0628 19:42:54.694097  1232 net.cpp:406] bn4_1 <- conv4_1
I0628 19:42:54.694097  1232 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0628 19:42:54.694097  1232 net.cpp:122] Setting up bn4_1
I0628 19:42:54.694097  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.694097  1232 net.cpp:137] Memory required for data: 224359600
I0628 19:42:54.694097  1232 layer_factory.cpp:58] Creating layer scale4_1
I0628 19:42:54.694097  1232 net.cpp:84] Creating Layer scale4_1
I0628 19:42:54.694097  1232 net.cpp:406] scale4_1 <- conv4_1
I0628 19:42:54.694097  1232 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0628 19:42:54.694097  1232 layer_factory.cpp:58] Creating layer scale4_1
I0628 19:42:54.694097  1232 net.cpp:122] Setting up scale4_1
I0628 19:42:54.694097  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.694097  1232 net.cpp:137] Memory required for data: 226919600
I0628 19:42:54.694097  1232 layer_factory.cpp:58] Creating layer relu4_1
I0628 19:42:54.694097  1232 net.cpp:84] Creating Layer relu4_1
I0628 19:42:54.694097  1232 net.cpp:406] relu4_1 <- conv4_1
I0628 19:42:54.694097  1232 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0628 19:42:54.694097  1232 net.cpp:122] Setting up relu4_1
I0628 19:42:54.694097  1232 net.cpp:129] Top shape: 100 25 16 16 (640000)
I0628 19:42:54.694097  1232 net.cpp:137] Memory required for data: 229479600
I0628 19:42:54.694097  1232 layer_factory.cpp:58] Creating layer conv4_2
I0628 19:42:54.694097  1232 net.cpp:84] Creating Layer conv4_2
I0628 19:42:54.694097  1232 net.cpp:406] conv4_2 <- conv4_1
I0628 19:42:54.694097  1232 net.cpp:380] conv4_2 -> conv4_2
I0628 19:42:54.696101  1232 net.cpp:122] Setting up conv4_2
I0628 19:42:54.696101  1232 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 19:42:54.696101  1232 net.cpp:137] Memory required for data: 236033200
I0628 19:42:54.696101  1232 layer_factory.cpp:58] Creating layer bn4_2
I0628 19:42:54.696101  1232 net.cpp:84] Creating Layer bn4_2
I0628 19:42:54.696101  1232 net.cpp:406] bn4_2 <- conv4_2
I0628 19:42:54.696101  1232 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0628 19:42:54.696101  1232 net.cpp:122] Setting up bn4_2
I0628 19:42:54.696101  1232 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 19:42:54.696101  1232 net.cpp:137] Memory required for data: 242586800
I0628 19:42:54.696101  1232 layer_factory.cpp:58] Creating layer scale4_2
I0628 19:42:54.696101  1232 net.cpp:84] Creating Layer scale4_2
I0628 19:42:54.696101  1232 net.cpp:406] scale4_2 <- conv4_2
I0628 19:42:54.696101  1232 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0628 19:42:54.696101  1232 layer_factory.cpp:58] Creating layer scale4_2
I0628 19:42:54.696101  1232 net.cpp:122] Setting up scale4_2
I0628 19:42:54.696101  1232 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 19:42:54.696101  1232 net.cpp:137] Memory required for data: 249140400
I0628 19:42:54.696101  1232 layer_factory.cpp:58] Creating layer relu4_2
I0628 19:42:54.696101  1232 net.cpp:84] Creating Layer relu4_2
I0628 19:42:54.696101  1232 net.cpp:406] relu4_2 <- conv4_2
I0628 19:42:54.696101  1232 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0628 19:42:54.696101  1232 net.cpp:122] Setting up relu4_2
I0628 19:42:54.696101  1232 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0628 19:42:54.696101  1232 net.cpp:137] Memory required for data: 255694000
I0628 19:42:54.696101  1232 layer_factory.cpp:58] Creating layer pool4_12
I0628 19:42:54.696101  1232 net.cpp:84] Creating Layer pool4_12
I0628 19:42:54.696101  1232 net.cpp:406] pool4_12 <- conv4_2
I0628 19:42:54.696101  1232 net.cpp:380] pool4_12 -> pool4_12
I0628 19:42:54.696101  1232 net.cpp:122] Setting up pool4_12
I0628 19:42:54.696101  1232 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0628 19:42:54.696101  1232 net.cpp:137] Memory required for data: 257332400
I0628 19:42:54.696101  1232 layer_factory.cpp:58] Creating layer conv4_0
I0628 19:42:54.696101  1232 net.cpp:84] Creating Layer conv4_0
I0628 19:42:54.696101  1232 net.cpp:406] conv4_0 <- pool4_12
I0628 19:42:54.696101  1232 net.cpp:380] conv4_0 -> conv4_0
I0628 19:42:54.697103  1232 net.cpp:122] Setting up conv4_0
I0628 19:42:54.697103  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.697103  1232 net.cpp:137] Memory required for data: 258689200
I0628 19:42:54.697103  1232 layer_factory.cpp:58] Creating layer bn4_0
I0628 19:42:54.697103  1232 net.cpp:84] Creating Layer bn4_0
I0628 19:42:54.697103  1232 net.cpp:406] bn4_0 <- conv4_0
I0628 19:42:54.697103  1232 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0628 19:42:54.698103  1232 net.cpp:122] Setting up bn4_0
I0628 19:42:54.698103  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.698103  1232 net.cpp:137] Memory required for data: 260046000
I0628 19:42:54.698103  1232 layer_factory.cpp:58] Creating layer scale4_0
I0628 19:42:54.698103  1232 net.cpp:84] Creating Layer scale4_0
I0628 19:42:54.698103  1232 net.cpp:406] scale4_0 <- conv4_0
I0628 19:42:54.698103  1232 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0628 19:42:54.698103  1232 layer_factory.cpp:58] Creating layer scale4_0
I0628 19:42:54.698103  1232 net.cpp:122] Setting up scale4_0
I0628 19:42:54.698103  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.698103  1232 net.cpp:137] Memory required for data: 261402800
I0628 19:42:54.698103  1232 layer_factory.cpp:58] Creating layer relu4_0
I0628 19:42:54.698103  1232 net.cpp:84] Creating Layer relu4_0
I0628 19:42:54.698103  1232 net.cpp:406] relu4_0 <- conv4_0
I0628 19:42:54.698103  1232 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0628 19:42:54.698103  1232 net.cpp:122] Setting up relu4_0
I0628 19:42:54.698103  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.698103  1232 net.cpp:137] Memory required for data: 262759600
I0628 19:42:54.698103  1232 layer_factory.cpp:58] Creating layer cccp4
I0628 19:42:54.698103  1232 net.cpp:84] Creating Layer cccp4
I0628 19:42:54.698103  1232 net.cpp:406] cccp4 <- conv4_0
I0628 19:42:54.698103  1232 net.cpp:380] cccp4 -> cccp4
I0628 19:42:54.699103  1232 net.cpp:122] Setting up cccp4
I0628 19:42:54.699103  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.699103  1232 net.cpp:137] Memory required for data: 264116400
I0628 19:42:54.699103  1232 layer_factory.cpp:58] Creating layer bn_cccp4
I0628 19:42:54.699103  1232 net.cpp:84] Creating Layer bn_cccp4
I0628 19:42:54.699103  1232 net.cpp:406] bn_cccp4 <- cccp4
I0628 19:42:54.699103  1232 net.cpp:367] bn_cccp4 -> cccp4 (in-place)
I0628 19:42:54.699103  1232 net.cpp:122] Setting up bn_cccp4
I0628 19:42:54.699103  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.699103  1232 net.cpp:137] Memory required for data: 265473200
I0628 19:42:54.699103  1232 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 19:42:54.699103  1232 net.cpp:84] Creating Layer scale_cccp4
I0628 19:42:54.699103  1232 net.cpp:406] scale_cccp4 <- cccp4
I0628 19:42:54.699103  1232 net.cpp:367] scale_cccp4 -> cccp4 (in-place)
I0628 19:42:54.699103  1232 layer_factory.cpp:58] Creating layer scale_cccp4
I0628 19:42:54.700104  1232 net.cpp:122] Setting up scale_cccp4
I0628 19:42:54.700104  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.700104  1232 net.cpp:137] Memory required for data: 266830000
I0628 19:42:54.700104  1232 layer_factory.cpp:58] Creating layer relu_cccp4
I0628 19:42:54.700104  1232 net.cpp:84] Creating Layer relu_cccp4
I0628 19:42:54.700104  1232 net.cpp:406] relu_cccp4 <- cccp4
I0628 19:42:54.700104  1232 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0628 19:42:54.700104  1232 net.cpp:122] Setting up relu_cccp4
I0628 19:42:54.700104  1232 net.cpp:129] Top shape: 100 53 8 8 (339200)
I0628 19:42:54.700104  1232 net.cpp:137] Memory required for data: 268186800
I0628 19:42:54.700104  1232 layer_factory.cpp:58] Creating layer pool4_2
I0628 19:42:54.700104  1232 net.cpp:84] Creating Layer pool4_2
I0628 19:42:54.700104  1232 net.cpp:406] pool4_2 <- cccp4
I0628 19:42:54.700104  1232 net.cpp:380] pool4_2 -> pool4_2
I0628 19:42:54.700104  1232 net.cpp:122] Setting up pool4_2
I0628 19:42:54.700104  1232 net.cpp:129] Top shape: 100 53 4 4 (84800)
I0628 19:42:54.700104  1232 net.cpp:137] Memory required for data: 268526000
I0628 19:42:54.700104  1232 layer_factory.cpp:58] Creating layer cccp5
I0628 19:42:54.700104  1232 net.cpp:84] Creating Layer cccp5
I0628 19:42:54.700104  1232 net.cpp:406] cccp5 <- pool4_2
I0628 19:42:54.700104  1232 net.cpp:380] cccp5 -> cccp5
I0628 19:42:54.701105  1232 net.cpp:122] Setting up cccp5
I0628 19:42:54.701105  1232 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 19:42:54.701105  1232 net.cpp:137] Memory required for data: 270081200
I0628 19:42:54.701105  1232 layer_factory.cpp:58] Creating layer bn_cccp5
I0628 19:42:54.701105  1232 net.cpp:84] Creating Layer bn_cccp5
I0628 19:42:54.701105  1232 net.cpp:406] bn_cccp5 <- cccp5
I0628 19:42:54.701105  1232 net.cpp:367] bn_cccp5 -> cccp5 (in-place)
I0628 19:42:54.701105  1232 net.cpp:122] Setting up bn_cccp5
I0628 19:42:54.701105  1232 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 19:42:54.701105  1232 net.cpp:137] Memory required for data: 271636400
I0628 19:42:54.701105  1232 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 19:42:54.701105  1232 net.cpp:84] Creating Layer scale_cccp5
I0628 19:42:54.701105  1232 net.cpp:406] scale_cccp5 <- cccp5
I0628 19:42:54.701105  1232 net.cpp:367] scale_cccp5 -> cccp5 (in-place)
I0628 19:42:54.701105  1232 layer_factory.cpp:58] Creating layer scale_cccp5
I0628 19:42:54.701105  1232 net.cpp:122] Setting up scale_cccp5
I0628 19:42:54.701105  1232 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 19:42:54.702105  1232 net.cpp:137] Memory required for data: 273191600
I0628 19:42:54.702105  1232 layer_factory.cpp:58] Creating layer relu_cccp5
I0628 19:42:54.702105  1232 net.cpp:84] Creating Layer relu_cccp5
I0628 19:42:54.702105  1232 net.cpp:406] relu_cccp5 <- cccp5
I0628 19:42:54.702105  1232 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0628 19:42:54.702105  1232 net.cpp:122] Setting up relu_cccp5
I0628 19:42:54.702105  1232 net.cpp:129] Top shape: 100 108 6 6 (388800)
I0628 19:42:54.702105  1232 net.cpp:137] Memory required for data: 274746800
I0628 19:42:54.702105  1232 layer_factory.cpp:58] Creating layer poolcp5
I0628 19:42:54.702105  1232 net.cpp:84] Creating Layer poolcp5
I0628 19:42:54.702105  1232 net.cpp:406] poolcp5 <- cccp5
I0628 19:42:54.702105  1232 net.cpp:380] poolcp5 -> poolcp5
I0628 19:42:54.702105  1232 net.cpp:122] Setting up poolcp5
I0628 19:42:54.702105  1232 net.cpp:129] Top shape: 100 108 3 3 (97200)
I0628 19:42:54.702105  1232 net.cpp:137] Memory required for data: 275135600
I0628 19:42:54.702105  1232 layer_factory.cpp:58] Creating layer cccp6
I0628 19:42:54.702105  1232 net.cpp:84] Creating Layer cccp6
I0628 19:42:54.702105  1232 net.cpp:406] cccp6 <- poolcp5
I0628 19:42:54.702105  1232 net.cpp:380] cccp6 -> cccp6
I0628 19:42:54.703106  1232 net.cpp:122] Setting up cccp6
I0628 19:42:54.703106  1232 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 19:42:54.703106  1232 net.cpp:137] Memory required for data: 276215600
I0628 19:42:54.703106  1232 layer_factory.cpp:58] Creating layer bn_cccp6
I0628 19:42:54.703106  1232 net.cpp:84] Creating Layer bn_cccp6
I0628 19:42:54.703106  1232 net.cpp:406] bn_cccp6 <- cccp6
I0628 19:42:54.703106  1232 net.cpp:367] bn_cccp6 -> cccp6 (in-place)
I0628 19:42:54.703106  1232 net.cpp:122] Setting up bn_cccp6
I0628 19:42:54.703106  1232 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 19:42:54.703106  1232 net.cpp:137] Memory required for data: 277295600
I0628 19:42:54.703106  1232 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 19:42:54.703106  1232 net.cpp:84] Creating Layer scale_cccp6
I0628 19:42:54.703106  1232 net.cpp:406] scale_cccp6 <- cccp6
I0628 19:42:54.703106  1232 net.cpp:367] scale_cccp6 -> cccp6 (in-place)
I0628 19:42:54.704107  1232 layer_factory.cpp:58] Creating layer scale_cccp6
I0628 19:42:54.704107  1232 net.cpp:122] Setting up scale_cccp6
I0628 19:42:54.704107  1232 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 19:42:54.704107  1232 net.cpp:137] Memory required for data: 278375600
I0628 19:42:54.704107  1232 layer_factory.cpp:58] Creating layer relu_cccp6
I0628 19:42:54.704107  1232 net.cpp:84] Creating Layer relu_cccp6
I0628 19:42:54.704107  1232 net.cpp:406] relu_cccp6 <- cccp6
I0628 19:42:54.704107  1232 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0628 19:42:54.704107  1232 net.cpp:122] Setting up relu_cccp6
I0628 19:42:54.704107  1232 net.cpp:129] Top shape: 100 108 5 5 (270000)
I0628 19:42:54.704107  1232 net.cpp:137] Memory required for data: 279455600
I0628 19:42:54.704107  1232 layer_factory.cpp:58] Creating layer poolcp6
I0628 19:42:54.704107  1232 net.cpp:84] Creating Layer poolcp6
I0628 19:42:54.704107  1232 net.cpp:406] poolcp6 <- cccp6
I0628 19:42:54.704107  1232 net.cpp:380] poolcp6 -> poolcp6
I0628 19:42:54.704107  1232 net.cpp:122] Setting up poolcp6
I0628 19:42:54.704107  1232 net.cpp:129] Top shape: 100 108 1 1 (10800)
I0628 19:42:54.704107  1232 net.cpp:137] Memory required for data: 279498800
I0628 19:42:54.704107  1232 layer_factory.cpp:58] Creating layer ip1
I0628 19:42:54.704107  1232 net.cpp:84] Creating Layer ip1
I0628 19:42:54.704107  1232 net.cpp:406] ip1 <- poolcp6
I0628 19:42:54.704107  1232 net.cpp:380] ip1 -> ip1
I0628 19:42:54.704107  1232 net.cpp:122] Setting up ip1
I0628 19:42:54.704107  1232 net.cpp:129] Top shape: 100 10 (1000)
I0628 19:42:54.704107  1232 net.cpp:137] Memory required for data: 279502800
I0628 19:42:54.704107  1232 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0628 19:42:54.704107  1232 net.cpp:84] Creating Layer ip1_ip1_0_split
I0628 19:42:54.704107  1232 net.cpp:406] ip1_ip1_0_split <- ip1
I0628 19:42:54.704107  1232 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0628 19:42:54.704107  1232 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0628 19:42:54.704107  1232 net.cpp:122] Setting up ip1_ip1_0_split
I0628 19:42:54.704107  1232 net.cpp:129] Top shape: 100 10 (1000)
I0628 19:42:54.704107  1232 net.cpp:129] Top shape: 100 10 (1000)
I0628 19:42:54.704107  1232 net.cpp:137] Memory required for data: 279510800
I0628 19:42:54.704107  1232 layer_factory.cpp:58] Creating layer accuracy
I0628 19:42:54.704107  1232 net.cpp:84] Creating Layer accuracy
I0628 19:42:54.704107  1232 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0628 19:42:54.704107  1232 net.cpp:406] accuracy <- label_cifar_1_split_0
I0628 19:42:54.704107  1232 net.cpp:380] accuracy -> accuracy
I0628 19:42:54.704107  1232 net.cpp:122] Setting up accuracy
I0628 19:42:54.704107  1232 net.cpp:129] Top shape: (1)
I0628 19:42:54.704107  1232 net.cpp:137] Memory required for data: 279510804
I0628 19:42:54.704107  1232 layer_factory.cpp:58] Creating layer loss
I0628 19:42:54.704107  1232 net.cpp:84] Creating Layer loss
I0628 19:42:54.704107  1232 net.cpp:406] loss <- ip1_ip1_0_split_1
I0628 19:42:54.704107  1232 net.cpp:406] loss <- label_cifar_1_split_1
I0628 19:42:54.704107  1232 net.cpp:380] loss -> loss
I0628 19:42:54.704107  1232 layer_factory.cpp:58] Creating layer loss
I0628 19:42:54.705108  1232 net.cpp:122] Setting up loss
I0628 19:42:54.705108  1232 net.cpp:129] Top shape: (1)
I0628 19:42:54.705108  1232 net.cpp:132]     with loss weight 1
I0628 19:42:54.705108  1232 net.cpp:137] Memory required for data: 279510808
I0628 19:42:54.705108  1232 net.cpp:198] loss needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:200] accuracy does not need backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] ip1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] poolcp6 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu_cccp6 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale_cccp6 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn_cccp6 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] cccp6 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] poolcp5 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu_cccp5 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale_cccp5 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn_cccp5 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] cccp5 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] pool4_2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu_cccp4 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale_cccp4 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn_cccp4 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] cccp4 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu4_0 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale4_0 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn4_0 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] conv4_0 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] pool4_12 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu4_2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale4_2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn4_2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] conv4_2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu4_1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale4_1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn4_1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] conv4_1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu4 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale4 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn4 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] conv4 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu3 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale3 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn3 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] conv3 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] pool2_1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu2_2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale2_2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn2_2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] conv2_2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu2_1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale2_1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn2_1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] conv2_1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] conv2 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu1_0 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale1_0 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn1_0 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] conv1_0 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] relu1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] scale1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] bn1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:198] conv1 needs backward computation.
I0628 19:42:54.705108  1232 net.cpp:200] label_cifar_1_split does not need backward computation.
I0628 19:42:54.705108  1232 net.cpp:200] cifar does not need backward computation.
I0628 19:42:54.705108  1232 net.cpp:242] This network produces output accuracy
I0628 19:42:54.705108  1232 net.cpp:242] This network produces output loss
I0628 19:42:54.705108  1232 net.cpp:255] Network initialization done.
I0628 19:42:54.705108  1232 solver.cpp:56] Solver scaffolding done.
I0628 19:42:54.708109  1232 caffe.cpp:249] Starting Optimization
I0628 19:42:54.708109  1232 solver.cpp:272] Solving CIFAR10_SimpleNet_13_128k_end1x1
I0628 19:42:54.708109  1232 solver.cpp:273] Learning Rate Policy: multistep
I0628 19:42:54.710111  1232 solver.cpp:330] Iteration 0, Testing net (#0)
I0628 19:42:54.711112  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:42:55.577736 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:42:55.608758  1232 solver.cpp:397]     Test net output #0: accuracy = 0.1038
I0628 19:42:55.608758  1232 solver.cpp:397]     Test net output #1: loss = 78.271 (* 1 = 78.271 loss)
I0628 19:42:55.682335  1232 solver.cpp:218] Iteration 0 (0 iter/s, 0.972992s/100 iters), loss = 3.89368
I0628 19:42:55.682335  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.1
I0628 19:42:55.682335  1232 solver.cpp:237]     Train net output #1: loss = 3.89368 (* 1 = 3.89368 loss)
I0628 19:42:55.682335  1232 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0628 19:42:59.361564  1232 solver.cpp:218] Iteration 100 (27.1786 iter/s, 3.67936s/100 iters), loss = 1.71478
I0628 19:42:59.361564  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I0628 19:42:59.361564  1232 solver.cpp:237]     Train net output #1: loss = 1.71478 (* 1 = 1.71478 loss)
I0628 19:42:59.361564  1232 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0628 19:43:03.105669  1232 solver.cpp:218] Iteration 200 (26.7103 iter/s, 3.74387s/100 iters), loss = 1.66942
I0628 19:43:03.106670  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I0628 19:43:03.106670  1232 solver.cpp:237]     Train net output #1: loss = 1.66942 (* 1 = 1.66942 loss)
I0628 19:43:03.106670  1232 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0628 19:43:06.941174  1232 solver.cpp:218] Iteration 300 (26.0791 iter/s, 3.83449s/100 iters), loss = 1.59393
I0628 19:43:06.941174  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I0628 19:43:06.941174  1232 solver.cpp:237]     Train net output #1: loss = 1.59393 (* 1 = 1.59393 loss)
I0628 19:43:06.941174  1232 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0628 19:43:10.591234  1232 solver.cpp:218] Iteration 400 (27.4012 iter/s, 3.64948s/100 iters), loss = 1.26703
I0628 19:43:10.591234  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I0628 19:43:10.591234  1232 solver.cpp:237]     Train net output #1: loss = 1.26703 (* 1 = 1.26703 loss)
I0628 19:43:10.591234  1232 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0628 19:43:14.024224 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:43:14.165330  1232 solver.cpp:330] Iteration 500, Testing net (#0)
I0628 19:43:14.165330  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:43:15.000955 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:43:15.032979  1232 solver.cpp:397]     Test net output #0: accuracy = 0.4889
I0628 19:43:15.032979  1232 solver.cpp:397]     Test net output #1: loss = 1.39937 (* 1 = 1.39937 loss)
I0628 19:43:15.068006  1232 solver.cpp:218] Iteration 500 (22.3386 iter/s, 4.47656s/100 iters), loss = 1.54878
I0628 19:43:15.068006  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I0628 19:43:15.068006  1232 solver.cpp:237]     Train net output #1: loss = 1.54878 (* 1 = 1.54878 loss)
I0628 19:43:15.068006  1232 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0628 19:43:18.904105  1232 solver.cpp:218] Iteration 600 (26.0707 iter/s, 3.83573s/100 iters), loss = 1.29225
I0628 19:43:18.904105  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I0628 19:43:18.904105  1232 solver.cpp:237]     Train net output #1: loss = 1.29225 (* 1 = 1.29225 loss)
I0628 19:43:18.904105  1232 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0628 19:43:22.572062  1232 solver.cpp:218] Iteration 700 (27.2669 iter/s, 3.66745s/100 iters), loss = 1.41251
I0628 19:43:22.572062  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I0628 19:43:22.572062  1232 solver.cpp:237]     Train net output #1: loss = 1.41251 (* 1 = 1.41251 loss)
I0628 19:43:22.572062  1232 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0628 19:43:26.255451  1232 solver.cpp:218] Iteration 800 (27.1495 iter/s, 3.68331s/100 iters), loss = 1.28861
I0628 19:43:26.255451  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I0628 19:43:26.255451  1232 solver.cpp:237]     Train net output #1: loss = 1.28861 (* 1 = 1.28861 loss)
I0628 19:43:26.255451  1232 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0628 19:43:30.017344  1232 solver.cpp:218] Iteration 900 (26.5861 iter/s, 3.76136s/100 iters), loss = 1.00672
I0628 19:43:30.017344  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I0628 19:43:30.017344  1232 solver.cpp:237]     Train net output #1: loss = 1.00672 (* 1 = 1.00672 loss)
I0628 19:43:30.017344  1232 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0628 19:43:33.558092 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:43:33.704284  1232 solver.cpp:330] Iteration 1000, Testing net (#0)
I0628 19:43:33.704284  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:43:34.539680 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:43:34.571712  1232 solver.cpp:397]     Test net output #0: accuracy = 0.5157
I0628 19:43:34.571712  1232 solver.cpp:397]     Test net output #1: loss = 1.34555 (* 1 = 1.34555 loss)
I0628 19:43:34.606250  1232 solver.cpp:218] Iteration 1000 (21.7939 iter/s, 4.58844s/100 iters), loss = 1.26097
I0628 19:43:34.606250  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I0628 19:43:34.606250  1232 solver.cpp:237]     Train net output #1: loss = 1.26097 (* 1 = 1.26097 loss)
I0628 19:43:34.606250  1232 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0628 19:43:38.271252  1232 solver.cpp:218] Iteration 1100 (27.2885 iter/s, 3.66454s/100 iters), loss = 1.10489
I0628 19:43:38.271252  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I0628 19:43:38.271252  1232 solver.cpp:237]     Train net output #1: loss = 1.10489 (* 1 = 1.10489 loss)
I0628 19:43:38.271252  1232 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0628 19:43:41.985046  1232 solver.cpp:218] Iteration 1200 (26.9267 iter/s, 3.71378s/100 iters), loss = 1.16917
I0628 19:43:41.985046  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I0628 19:43:41.985046  1232 solver.cpp:237]     Train net output #1: loss = 1.16917 (* 1 = 1.16917 loss)
I0628 19:43:41.985046  1232 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0628 19:43:45.729163  1232 solver.cpp:218] Iteration 1300 (26.7099 iter/s, 3.74393s/100 iters), loss = 1.16623
I0628 19:43:45.729163  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0628 19:43:45.729163  1232 solver.cpp:237]     Train net output #1: loss = 1.16623 (* 1 = 1.16623 loss)
I0628 19:43:45.729163  1232 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0628 19:43:49.451354  1232 solver.cpp:218] Iteration 1400 (26.8703 iter/s, 3.72158s/100 iters), loss = 0.955339
I0628 19:43:49.451354  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0628 19:43:49.451354  1232 solver.cpp:237]     Train net output #1: loss = 0.955339 (* 1 = 0.955339 loss)
I0628 19:43:49.451354  1232 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0628 19:43:52.968287 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:43:53.118441  1232 solver.cpp:330] Iteration 1500, Testing net (#0)
I0628 19:43:53.118441  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:43:53.958207 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:43:53.982239  1232 solver.cpp:397]     Test net output #0: accuracy = 0.5836
I0628 19:43:53.982239  1232 solver.cpp:397]     Test net output #1: loss = 1.16695 (* 1 = 1.16695 loss)
I0628 19:43:54.016275  1232 solver.cpp:218] Iteration 1500 (21.9096 iter/s, 4.5642s/100 iters), loss = 1.18457
I0628 19:43:54.016275  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I0628 19:43:54.016275  1232 solver.cpp:237]     Train net output #1: loss = 1.18457 (* 1 = 1.18457 loss)
I0628 19:43:54.016275  1232 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0628 19:43:57.679905  1232 solver.cpp:218] Iteration 1600 (27.2922 iter/s, 3.66405s/100 iters), loss = 0.99602
I0628 19:43:57.679905  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0628 19:43:57.680903  1232 solver.cpp:237]     Train net output #1: loss = 0.99602 (* 1 = 0.99602 loss)
I0628 19:43:57.680903  1232 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0628 19:44:01.330862  1232 solver.cpp:218] Iteration 1700 (27.3982 iter/s, 3.64987s/100 iters), loss = 0.955535
I0628 19:44:01.330862  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I0628 19:44:01.330862  1232 solver.cpp:237]     Train net output #1: loss = 0.955535 (* 1 = 0.955535 loss)
I0628 19:44:01.330862  1232 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0628 19:44:04.961915  1232 solver.cpp:218] Iteration 1800 (27.5428 iter/s, 3.63071s/100 iters), loss = 0.925731
I0628 19:44:04.961915  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0628 19:44:04.961915  1232 solver.cpp:237]     Train net output #1: loss = 0.925731 (* 1 = 0.925731 loss)
I0628 19:44:04.961915  1232 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0628 19:44:08.644960  1232 solver.cpp:218] Iteration 1900 (27.1523 iter/s, 3.68293s/100 iters), loss = 0.979336
I0628 19:44:08.645460  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0628 19:44:08.645460  1232 solver.cpp:237]     Train net output #1: loss = 0.979336 (* 1 = 0.979336 loss)
I0628 19:44:08.645460  1232 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0628 19:44:12.109063 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:44:12.251168  1232 solver.cpp:330] Iteration 2000, Testing net (#0)
I0628 19:44:12.251168  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:44:13.074012 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:44:13.105034  1232 solver.cpp:397]     Test net output #0: accuracy = 0.6656
I0628 19:44:13.105034  1232 solver.cpp:397]     Test net output #1: loss = 0.941626 (* 1 = 0.941626 loss)
I0628 19:44:13.139058  1232 solver.cpp:218] Iteration 2000 (22.252 iter/s, 4.49399s/100 iters), loss = 0.914808
I0628 19:44:13.139058  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0628 19:44:13.139058  1232 solver.cpp:237]     Train net output #1: loss = 0.914808 (* 1 = 0.914808 loss)
I0628 19:44:13.139058  1232 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0628 19:44:16.799625  1232 solver.cpp:218] Iteration 2100 (27.3235 iter/s, 3.65985s/100 iters), loss = 0.75253
I0628 19:44:16.799625  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0628 19:44:16.799625  1232 solver.cpp:237]     Train net output #1: loss = 0.75253 (* 1 = 0.75253 loss)
I0628 19:44:16.799625  1232 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0628 19:44:20.449669  1232 solver.cpp:218] Iteration 2200 (27.3957 iter/s, 3.65021s/100 iters), loss = 0.871833
I0628 19:44:20.449669  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0628 19:44:20.449669  1232 solver.cpp:237]     Train net output #1: loss = 0.871833 (* 1 = 0.871833 loss)
I0628 19:44:20.449669  1232 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0628 19:44:24.065973  1232 solver.cpp:218] Iteration 2300 (27.6612 iter/s, 3.61517s/100 iters), loss = 0.877301
I0628 19:44:24.065973  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0628 19:44:24.065973  1232 solver.cpp:237]     Train net output #1: loss = 0.877301 (* 1 = 0.877301 loss)
I0628 19:44:24.065973  1232 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0628 19:44:27.704918  1232 solver.cpp:218] Iteration 2400 (27.4762 iter/s, 3.63952s/100 iters), loss = 0.850992
I0628 19:44:27.705919  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0628 19:44:27.705919  1232 solver.cpp:237]     Train net output #1: loss = 0.850992 (* 1 = 0.850992 loss)
I0628 19:44:27.705919  1232 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0628 19:44:31.160642 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:44:31.304754  1232 solver.cpp:330] Iteration 2500, Testing net (#0)
I0628 19:44:31.304754  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:44:32.128382 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:44:32.160404  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7067
I0628 19:44:32.160404  1232 solver.cpp:397]     Test net output #1: loss = 0.828632 (* 1 = 0.828632 loss)
I0628 19:44:32.195433  1232 solver.cpp:218] Iteration 2500 (22.2737 iter/s, 4.4896s/100 iters), loss = 0.851243
I0628 19:44:32.195433  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0628 19:44:32.195433  1232 solver.cpp:237]     Train net output #1: loss = 0.851243 (* 1 = 0.851243 loss)
I0628 19:44:32.195433  1232 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0628 19:44:35.852339  1232 solver.cpp:218] Iteration 2600 (27.3492 iter/s, 3.65641s/100 iters), loss = 0.735218
I0628 19:44:35.852339  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 19:44:35.852339  1232 solver.cpp:237]     Train net output #1: loss = 0.735218 (* 1 = 0.735218 loss)
I0628 19:44:35.852339  1232 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0628 19:44:39.483960  1232 solver.cpp:218] Iteration 2700 (27.539 iter/s, 3.63121s/100 iters), loss = 0.81651
I0628 19:44:39.483960  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0628 19:44:39.483960  1232 solver.cpp:237]     Train net output #1: loss = 0.81651 (* 1 = 0.81651 loss)
I0628 19:44:39.483960  1232 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0628 19:44:43.104848  1232 solver.cpp:218] Iteration 2800 (27.6156 iter/s, 3.62114s/100 iters), loss = 0.792199
I0628 19:44:43.104848  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0628 19:44:43.104848  1232 solver.cpp:237]     Train net output #1: loss = 0.792199 (* 1 = 0.792199 loss)
I0628 19:44:43.104848  1232 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0628 19:44:46.734872  1232 solver.cpp:218] Iteration 2900 (27.5507 iter/s, 3.62967s/100 iters), loss = 0.921137
I0628 19:44:46.734872  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0628 19:44:46.734872  1232 solver.cpp:237]     Train net output #1: loss = 0.921137 (* 1 = 0.921137 loss)
I0628 19:44:46.734872  1232 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0628 19:44:50.221642 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:44:50.362736  1232 solver.cpp:330] Iteration 3000, Testing net (#0)
I0628 19:44:50.362736  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:44:51.179440 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:44:51.209501  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7016
I0628 19:44:51.210501  1232 solver.cpp:397]     Test net output #1: loss = 0.835491 (* 1 = 0.835491 loss)
I0628 19:44:51.243530  1232 solver.cpp:218] Iteration 3000 (22.1815 iter/s, 4.50826s/100 iters), loss = 0.760452
I0628 19:44:51.244530  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0628 19:44:51.244530  1232 solver.cpp:237]     Train net output #1: loss = 0.760452 (* 1 = 0.760452 loss)
I0628 19:44:51.244530  1232 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0628 19:44:54.877559  1232 solver.cpp:218] Iteration 3100 (27.5232 iter/s, 3.63329s/100 iters), loss = 0.798725
I0628 19:44:54.877559  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0628 19:44:54.877559  1232 solver.cpp:237]     Train net output #1: loss = 0.798725 (* 1 = 0.798725 loss)
I0628 19:44:54.877559  1232 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0628 19:44:58.507786  1232 solver.cpp:218] Iteration 3200 (27.5521 iter/s, 3.62948s/100 iters), loss = 0.699175
I0628 19:44:58.507786  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0628 19:44:58.507786  1232 solver.cpp:237]     Train net output #1: loss = 0.699175 (* 1 = 0.699175 loss)
I0628 19:44:58.507786  1232 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0628 19:45:02.135458  1232 solver.cpp:218] Iteration 3300 (27.5645 iter/s, 3.62785s/100 iters), loss = 0.692804
I0628 19:45:02.135458  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0628 19:45:02.135458  1232 solver.cpp:237]     Train net output #1: loss = 0.692804 (* 1 = 0.692804 loss)
I0628 19:45:02.135458  1232 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0628 19:45:05.769001  1232 solver.cpp:218] Iteration 3400 (27.5245 iter/s, 3.63313s/100 iters), loss = 0.756455
I0628 19:45:05.769001  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0628 19:45:05.769001  1232 solver.cpp:237]     Train net output #1: loss = 0.756455 (* 1 = 0.756455 loss)
I0628 19:45:05.769001  1232 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0628 19:45:09.216512 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:45:09.360651  1232 solver.cpp:330] Iteration 3500, Testing net (#0)
I0628 19:45:09.361652  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:45:10.178586 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:45:10.210119  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7047
I0628 19:45:10.210119  1232 solver.cpp:397]     Test net output #1: loss = 0.831733 (* 1 = 0.831733 loss)
I0628 19:45:10.244666  1232 solver.cpp:218] Iteration 3500 (22.3465 iter/s, 4.47497s/100 iters), loss = 0.790419
I0628 19:45:10.244666  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0628 19:45:10.244666  1232 solver.cpp:237]     Train net output #1: loss = 0.790419 (* 1 = 0.790419 loss)
I0628 19:45:10.244666  1232 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0628 19:45:13.869323  1232 solver.cpp:218] Iteration 3600 (27.591 iter/s, 3.62437s/100 iters), loss = 0.577509
I0628 19:45:13.869323  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 19:45:13.869323  1232 solver.cpp:237]     Train net output #1: loss = 0.577509 (* 1 = 0.577509 loss)
I0628 19:45:13.869323  1232 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0628 19:45:17.505913  1232 solver.cpp:218] Iteration 3700 (27.5046 iter/s, 3.63576s/100 iters), loss = 0.796349
I0628 19:45:17.505913  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0628 19:45:17.505913  1232 solver.cpp:237]     Train net output #1: loss = 0.796349 (* 1 = 0.796349 loss)
I0628 19:45:17.505913  1232 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0628 19:45:21.182862  1232 solver.cpp:218] Iteration 3800 (27.1926 iter/s, 3.67747s/100 iters), loss = 0.660117
I0628 19:45:21.183863  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 19:45:21.183863  1232 solver.cpp:237]     Train net output #1: loss = 0.660117 (* 1 = 0.660117 loss)
I0628 19:45:21.183863  1232 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0628 19:45:24.885303  1232 solver.cpp:218] Iteration 3900 (27.0154 iter/s, 3.70159s/100 iters), loss = 0.723406
I0628 19:45:24.885303  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0628 19:45:24.885303  1232 solver.cpp:237]     Train net output #1: loss = 0.723406 (* 1 = 0.723406 loss)
I0628 19:45:24.885303  1232 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0628 19:45:28.343302 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:45:28.484452  1232 solver.cpp:330] Iteration 4000, Testing net (#0)
I0628 19:45:28.484452  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:45:29.310256 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:45:29.341280  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7335
I0628 19:45:29.341280  1232 solver.cpp:397]     Test net output #1: loss = 0.768897 (* 1 = 0.768897 loss)
I0628 19:45:29.376307  1232 solver.cpp:218] Iteration 4000 (22.27 iter/s, 4.49035s/100 iters), loss = 0.669
I0628 19:45:29.376307  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 19:45:29.376307  1232 solver.cpp:237]     Train net output #1: loss = 0.669 (* 1 = 0.669 loss)
I0628 19:45:29.376307  1232 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0628 19:45:32.993155  1232 solver.cpp:218] Iteration 4100 (27.6501 iter/s, 3.61662s/100 iters), loss = 0.683568
I0628 19:45:32.993155  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 19:45:32.993155  1232 solver.cpp:237]     Train net output #1: loss = 0.683568 (* 1 = 0.683568 loss)
I0628 19:45:32.993155  1232 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0628 19:45:36.615000  1232 solver.cpp:218] Iteration 4200 (27.6135 iter/s, 3.62141s/100 iters), loss = 0.648047
I0628 19:45:36.615000  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0628 19:45:36.615000  1232 solver.cpp:237]     Train net output #1: loss = 0.648047 (* 1 = 0.648047 loss)
I0628 19:45:36.615000  1232 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0628 19:45:40.241237  1232 solver.cpp:218] Iteration 4300 (27.5745 iter/s, 3.62654s/100 iters), loss = 0.572054
I0628 19:45:40.241237  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 19:45:40.241237  1232 solver.cpp:237]     Train net output #1: loss = 0.572054 (* 1 = 0.572054 loss)
I0628 19:45:40.241237  1232 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0628 19:45:43.954367  1232 solver.cpp:218] Iteration 4400 (26.9395 iter/s, 3.71202s/100 iters), loss = 0.732771
I0628 19:45:43.954367  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I0628 19:45:43.954367  1232 solver.cpp:237]     Train net output #1: loss = 0.732771 (* 1 = 0.732771 loss)
I0628 19:45:43.954367  1232 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0628 19:45:47.400018 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:45:47.540683  1232 solver.cpp:330] Iteration 4500, Testing net (#0)
I0628 19:45:47.540683  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:45:48.362221 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:45:48.393225  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7328
I0628 19:45:48.393225  1232 solver.cpp:397]     Test net output #1: loss = 0.777266 (* 1 = 0.777266 loss)
I0628 19:45:48.428251  1232 solver.cpp:218] Iteration 4500 (22.3524 iter/s, 4.47378s/100 iters), loss = 0.590092
I0628 19:45:48.428251  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 19:45:48.428751  1232 solver.cpp:237]     Train net output #1: loss = 0.590092 (* 1 = 0.590092 loss)
I0628 19:45:48.428751  1232 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0628 19:45:52.053925  1232 solver.cpp:218] Iteration 4600 (27.5847 iter/s, 3.6252s/100 iters), loss = 0.531914
I0628 19:45:52.053925  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 19:45:52.053925  1232 solver.cpp:237]     Train net output #1: loss = 0.531914 (* 1 = 0.531914 loss)
I0628 19:45:52.053925  1232 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0628 19:45:55.695507  1232 solver.cpp:218] Iteration 4700 (27.4626 iter/s, 3.64131s/100 iters), loss = 0.612144
I0628 19:45:55.695507  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 19:45:55.695507  1232 solver.cpp:237]     Train net output #1: loss = 0.612144 (* 1 = 0.612144 loss)
I0628 19:45:55.695507  1232 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0628 19:45:59.325659  1232 solver.cpp:218] Iteration 4800 (27.5451 iter/s, 3.63041s/100 iters), loss = 0.649059
I0628 19:45:59.326660  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0628 19:45:59.326660  1232 solver.cpp:237]     Train net output #1: loss = 0.649059 (* 1 = 0.649059 loss)
I0628 19:45:59.326660  1232 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0628 19:46:02.959313  1232 solver.cpp:218] Iteration 4900 (27.5258 iter/s, 3.63295s/100 iters), loss = 0.681318
I0628 19:46:02.959313  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0628 19:46:02.959313  1232 solver.cpp:237]     Train net output #1: loss = 0.681318 (* 1 = 0.681318 loss)
I0628 19:46:02.959313  1232 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0628 19:46:06.429702 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:46:06.570992  1232 solver.cpp:330] Iteration 5000, Testing net (#0)
I0628 19:46:06.570992  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:46:07.398638 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:46:07.429659  1232 solver.cpp:397]     Test net output #0: accuracy = 0.751
I0628 19:46:07.429659  1232 solver.cpp:397]     Test net output #1: loss = 0.731911 (* 1 = 0.731911 loss)
I0628 19:46:07.464700  1232 solver.cpp:218] Iteration 5000 (22.2004 iter/s, 4.50442s/100 iters), loss = 0.636216
I0628 19:46:07.464700  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 19:46:07.464700  1232 solver.cpp:237]     Train net output #1: loss = 0.636216 (* 1 = 0.636216 loss)
I0628 19:46:07.464700  1232 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0628 19:46:11.110671  1232 solver.cpp:218] Iteration 5100 (27.4308 iter/s, 3.64554s/100 iters), loss = 0.419448
I0628 19:46:11.110671  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:46:11.110671  1232 solver.cpp:237]     Train net output #1: loss = 0.419448 (* 1 = 0.419448 loss)
I0628 19:46:11.110671  1232 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0628 19:46:14.735021  1232 solver.cpp:218] Iteration 5200 (27.5884 iter/s, 3.62472s/100 iters), loss = 0.692507
I0628 19:46:14.735021  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0628 19:46:14.735021  1232 solver.cpp:237]     Train net output #1: loss = 0.692507 (* 1 = 0.692507 loss)
I0628 19:46:14.735021  1232 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0628 19:46:18.361450  1232 solver.cpp:218] Iteration 5300 (27.5809 iter/s, 3.6257s/100 iters), loss = 0.574048
I0628 19:46:18.361450  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 19:46:18.361450  1232 solver.cpp:237]     Train net output #1: loss = 0.574048 (* 1 = 0.574048 loss)
I0628 19:46:18.361450  1232 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0628 19:46:21.995133  1232 solver.cpp:218] Iteration 5400 (27.5236 iter/s, 3.63324s/100 iters), loss = 0.556143
I0628 19:46:21.995133  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0628 19:46:21.995133  1232 solver.cpp:237]     Train net output #1: loss = 0.556143 (* 1 = 0.556143 loss)
I0628 19:46:21.995133  1232 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0628 19:46:25.438158 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:46:25.579771  1232 solver.cpp:330] Iteration 5500, Testing net (#0)
I0628 19:46:25.579771  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:46:26.403364 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:46:26.434386  1232 solver.cpp:397]     Test net output #0: accuracy = 0.766
I0628 19:46:26.434386  1232 solver.cpp:397]     Test net output #1: loss = 0.688973 (* 1 = 0.688973 loss)
I0628 19:46:26.468914  1232 solver.cpp:218] Iteration 5500 (22.3534 iter/s, 4.47359s/100 iters), loss = 0.527989
I0628 19:46:26.468914  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 19:46:26.469414  1232 solver.cpp:237]     Train net output #1: loss = 0.527989 (* 1 = 0.527989 loss)
I0628 19:46:26.469414  1232 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0628 19:46:30.087970  1232 solver.cpp:218] Iteration 5600 (27.6319 iter/s, 3.619s/100 iters), loss = 0.476827
I0628 19:46:30.087970  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:46:30.087970  1232 solver.cpp:237]     Train net output #1: loss = 0.476827 (* 1 = 0.476827 loss)
I0628 19:46:30.087970  1232 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0628 19:46:33.721065  1232 solver.cpp:218] Iteration 5700 (27.533 iter/s, 3.632s/100 iters), loss = 0.636972
I0628 19:46:33.721065  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 19:46:33.721065  1232 solver.cpp:237]     Train net output #1: loss = 0.636972 (* 1 = 0.636972 loss)
I0628 19:46:33.721065  1232 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0628 19:46:37.355751  1232 solver.cpp:218] Iteration 5800 (27.5138 iter/s, 3.63454s/100 iters), loss = 0.536462
I0628 19:46:37.355751  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:46:37.355751  1232 solver.cpp:237]     Train net output #1: loss = 0.536462 (* 1 = 0.536462 loss)
I0628 19:46:37.355751  1232 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0628 19:46:40.984800  1232 solver.cpp:218] Iteration 5900 (27.5578 iter/s, 3.62873s/100 iters), loss = 0.542017
I0628 19:46:40.984800  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 19:46:40.984800  1232 solver.cpp:237]     Train net output #1: loss = 0.542017 (* 1 = 0.542017 loss)
I0628 19:46:40.984800  1232 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0628 19:46:44.431315 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:46:44.572418  1232 solver.cpp:330] Iteration 6000, Testing net (#0)
I0628 19:46:44.573421  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:46:45.395086 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:46:45.426609  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7663
I0628 19:46:45.426609  1232 solver.cpp:397]     Test net output #1: loss = 0.683432 (* 1 = 0.683432 loss)
I0628 19:46:45.460633  1232 solver.cpp:218] Iteration 6000 (22.3436 iter/s, 4.47555s/100 iters), loss = 0.473991
I0628 19:46:45.460633  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 19:46:45.460633  1232 solver.cpp:237]     Train net output #1: loss = 0.473991 (* 1 = 0.473991 loss)
I0628 19:46:45.460633  1232 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0628 19:46:49.102264  1232 solver.cpp:218] Iteration 6100 (27.4627 iter/s, 3.64131s/100 iters), loss = 0.47423
I0628 19:46:49.102264  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:46:49.102264  1232 solver.cpp:237]     Train net output #1: loss = 0.47423 (* 1 = 0.47423 loss)
I0628 19:46:49.102264  1232 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0628 19:46:52.718747  1232 solver.cpp:218] Iteration 6200 (27.6518 iter/s, 3.6164s/100 iters), loss = 0.589248
I0628 19:46:52.718747  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 19:46:52.718747  1232 solver.cpp:237]     Train net output #1: loss = 0.589248 (* 1 = 0.589248 loss)
I0628 19:46:52.718747  1232 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0628 19:46:56.388418  1232 solver.cpp:218] Iteration 6300 (27.2534 iter/s, 3.66927s/100 iters), loss = 0.516854
I0628 19:46:56.388418  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 19:46:56.388418  1232 solver.cpp:237]     Train net output #1: loss = 0.516854 (* 1 = 0.516854 loss)
I0628 19:46:56.388418  1232 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0628 19:47:00.117491  1232 solver.cpp:218] Iteration 6400 (26.8203 iter/s, 3.72852s/100 iters), loss = 0.480347
I0628 19:47:00.117491  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:47:00.117491  1232 solver.cpp:237]     Train net output #1: loss = 0.480347 (* 1 = 0.480347 loss)
I0628 19:47:00.117491  1232 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0628 19:47:03.634363 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:47:03.779999  1232 solver.cpp:330] Iteration 6500, Testing net (#0)
I0628 19:47:03.779999  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:47:04.632405 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:47:04.664394  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7764
I0628 19:47:04.664394  1232 solver.cpp:397]     Test net output #1: loss = 0.663247 (* 1 = 0.663247 loss)
I0628 19:47:04.700438  1232 solver.cpp:218] Iteration 6500 (21.8235 iter/s, 4.58222s/100 iters), loss = 0.525852
I0628 19:47:04.700937  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 19:47:04.700937  1232 solver.cpp:237]     Train net output #1: loss = 0.525852 (* 1 = 0.525852 loss)
I0628 19:47:04.700937  1232 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0628 19:47:08.527086  1232 solver.cpp:218] Iteration 6600 (26.1381 iter/s, 3.82584s/100 iters), loss = 0.484244
I0628 19:47:08.527086  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:47:08.527086  1232 solver.cpp:237]     Train net output #1: loss = 0.484244 (* 1 = 0.484244 loss)
I0628 19:47:08.527086  1232 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0628 19:47:12.213140  1232 solver.cpp:218] Iteration 6700 (27.1303 iter/s, 3.68592s/100 iters), loss = 0.487647
I0628 19:47:12.213140  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 19:47:12.213140  1232 solver.cpp:237]     Train net output #1: loss = 0.487647 (* 1 = 0.487647 loss)
I0628 19:47:12.213140  1232 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0628 19:47:16.005046  1232 solver.cpp:218] Iteration 6800 (26.3743 iter/s, 3.79157s/100 iters), loss = 0.530892
I0628 19:47:16.005046  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 19:47:16.005046  1232 solver.cpp:237]     Train net output #1: loss = 0.530892 (* 1 = 0.530892 loss)
I0628 19:47:16.005046  1232 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0628 19:47:19.886946  1232 solver.cpp:218] Iteration 6900 (25.7646 iter/s, 3.8813s/100 iters), loss = 0.554695
I0628 19:47:19.886946  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0628 19:47:19.886946  1232 solver.cpp:237]     Train net output #1: loss = 0.554695 (* 1 = 0.554695 loss)
I0628 19:47:19.886946  1232 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0628 19:47:23.375526 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:47:23.517657  1232 solver.cpp:330] Iteration 7000, Testing net (#0)
I0628 19:47:23.517657  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:47:24.346398 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:47:24.377452  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7803
I0628 19:47:24.377452  1232 solver.cpp:397]     Test net output #1: loss = 0.635317 (* 1 = 0.635317 loss)
I0628 19:47:24.411468  1232 solver.cpp:218] Iteration 7000 (22.102 iter/s, 4.52447s/100 iters), loss = 0.432337
I0628 19:47:24.411468  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 19:47:24.411468  1232 solver.cpp:237]     Train net output #1: loss = 0.432337 (* 1 = 0.432337 loss)
I0628 19:47:24.411468  1232 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0628 19:47:28.041725  1232 solver.cpp:218] Iteration 7100 (27.554 iter/s, 3.62923s/100 iters), loss = 0.458028
I0628 19:47:28.041725  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:47:28.041725  1232 solver.cpp:237]     Train net output #1: loss = 0.458028 (* 1 = 0.458028 loss)
I0628 19:47:28.041725  1232 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0628 19:47:31.643802  1232 solver.cpp:218] Iteration 7200 (27.7605 iter/s, 3.60224s/100 iters), loss = 0.531415
I0628 19:47:31.644302  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 19:47:31.644302  1232 solver.cpp:237]     Train net output #1: loss = 0.531415 (* 1 = 0.531415 loss)
I0628 19:47:31.644302  1232 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0628 19:47:35.245817  1232 solver.cpp:218] Iteration 7300 (27.7683 iter/s, 3.60123s/100 iters), loss = 0.53952
I0628 19:47:35.245817  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 19:47:35.245817  1232 solver.cpp:237]     Train net output #1: loss = 0.53952 (* 1 = 0.53952 loss)
I0628 19:47:35.245817  1232 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0628 19:47:38.852597  1232 solver.cpp:218] Iteration 7400 (27.7279 iter/s, 3.60648s/100 iters), loss = 0.405584
I0628 19:47:38.852597  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:47:38.852597  1232 solver.cpp:237]     Train net output #1: loss = 0.405584 (* 1 = 0.405584 loss)
I0628 19:47:38.852597  1232 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0628 19:47:42.281210 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:47:42.423317  1232 solver.cpp:330] Iteration 7500, Testing net (#0)
I0628 19:47:42.423317  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:47:43.238060 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:47:43.269104  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7899
I0628 19:47:43.270123  1232 solver.cpp:397]     Test net output #1: loss = 0.616093 (* 1 = 0.616093 loss)
I0628 19:47:43.304144  1232 solver.cpp:218] Iteration 7500 (22.4627 iter/s, 4.45183s/100 iters), loss = 0.400277
I0628 19:47:43.304144  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:47:43.305145  1232 solver.cpp:237]     Train net output #1: loss = 0.400277 (* 1 = 0.400277 loss)
I0628 19:47:43.305145  1232 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0628 19:47:46.903771  1232 solver.cpp:218] Iteration 7600 (27.7856 iter/s, 3.59899s/100 iters), loss = 0.441208
I0628 19:47:46.903771  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:47:46.903771  1232 solver.cpp:237]     Train net output #1: loss = 0.441208 (* 1 = 0.441208 loss)
I0628 19:47:46.903771  1232 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0628 19:47:50.506283  1232 solver.cpp:218] Iteration 7700 (27.7589 iter/s, 3.60245s/100 iters), loss = 0.543695
I0628 19:47:50.507282  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 19:47:50.507282  1232 solver.cpp:237]     Train net output #1: loss = 0.543695 (* 1 = 0.543695 loss)
I0628 19:47:50.507282  1232 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0628 19:47:54.102851  1232 solver.cpp:218] Iteration 7800 (27.8108 iter/s, 3.59572s/100 iters), loss = 0.48639
I0628 19:47:54.102851  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 19:47:54.102851  1232 solver.cpp:237]     Train net output #1: loss = 0.48639 (* 1 = 0.48639 loss)
I0628 19:47:54.102851  1232 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0628 19:47:57.702440  1232 solver.cpp:218] Iteration 7900 (27.7865 iter/s, 3.59887s/100 iters), loss = 0.435507
I0628 19:47:57.702440  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:47:57.702440  1232 solver.cpp:237]     Train net output #1: loss = 0.435507 (* 1 = 0.435507 loss)
I0628 19:47:57.702440  1232 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0628 19:48:01.145701 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:48:01.287865  1232 solver.cpp:330] Iteration 8000, Testing net (#0)
I0628 19:48:01.287865  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:48:02.101567 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:48:02.132588  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7995
I0628 19:48:02.132588  1232 solver.cpp:397]     Test net output #1: loss = 0.592951 (* 1 = 0.592951 loss)
I0628 19:48:02.167132  1232 solver.cpp:218] Iteration 8000 (22.3996 iter/s, 4.46436s/100 iters), loss = 0.419525
I0628 19:48:02.167132  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:48:02.167132  1232 solver.cpp:237]     Train net output #1: loss = 0.419525 (* 1 = 0.419525 loss)
I0628 19:48:02.167132  1232 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0628 19:48:05.766736  1232 solver.cpp:218] Iteration 8100 (27.7815 iter/s, 3.59952s/100 iters), loss = 0.496443
I0628 19:48:05.766736  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:48:05.766736  1232 solver.cpp:237]     Train net output #1: loss = 0.496443 (* 1 = 0.496443 loss)
I0628 19:48:05.766736  1232 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0628 19:48:09.365156  1232 solver.cpp:218] Iteration 8200 (27.7897 iter/s, 3.59846s/100 iters), loss = 0.516604
I0628 19:48:09.365156  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:48:09.365156  1232 solver.cpp:237]     Train net output #1: loss = 0.516604 (* 1 = 0.516604 loss)
I0628 19:48:09.365156  1232 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0628 19:48:12.965116  1232 solver.cpp:218] Iteration 8300 (27.7858 iter/s, 3.59896s/100 iters), loss = 0.525332
I0628 19:48:12.965116  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 19:48:12.965116  1232 solver.cpp:237]     Train net output #1: loss = 0.525332 (* 1 = 0.525332 loss)
I0628 19:48:12.965116  1232 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0628 19:48:16.560567  1232 solver.cpp:218] Iteration 8400 (27.8159 iter/s, 3.59507s/100 iters), loss = 0.46006
I0628 19:48:16.560567  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:48:16.560567  1232 solver.cpp:237]     Train net output #1: loss = 0.46006 (* 1 = 0.46006 loss)
I0628 19:48:16.560567  1232 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0628 19:48:19.976673 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:48:20.117810  1232 solver.cpp:330] Iteration 8500, Testing net (#0)
I0628 19:48:20.117810  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:48:20.938626 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:48:20.968657  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7918
I0628 19:48:20.969658  1232 solver.cpp:397]     Test net output #1: loss = 0.614243 (* 1 = 0.614243 loss)
I0628 19:48:21.003715  1232 solver.cpp:218] Iteration 8500 (22.508 iter/s, 4.44286s/100 iters), loss = 0.499226
I0628 19:48:21.003715  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 19:48:21.003715  1232 solver.cpp:237]     Train net output #1: loss = 0.499226 (* 1 = 0.499226 loss)
I0628 19:48:21.003715  1232 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0628 19:48:24.609083  1232 solver.cpp:218] Iteration 8600 (27.7323 iter/s, 3.6059s/100 iters), loss = 0.498514
I0628 19:48:24.610085  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:48:24.610085  1232 solver.cpp:237]     Train net output #1: loss = 0.498514 (* 1 = 0.498514 loss)
I0628 19:48:24.610085  1232 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0628 19:48:28.213030  1232 solver.cpp:218] Iteration 8700 (27.7555 iter/s, 3.60289s/100 iters), loss = 0.439762
I0628 19:48:28.213030  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:48:28.213030  1232 solver.cpp:237]     Train net output #1: loss = 0.439762 (* 1 = 0.439762 loss)
I0628 19:48:28.213030  1232 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0628 19:48:31.801964  1232 solver.cpp:218] Iteration 8800 (27.8653 iter/s, 3.58869s/100 iters), loss = 0.423513
I0628 19:48:31.801964  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:48:31.801964  1232 solver.cpp:237]     Train net output #1: loss = 0.423513 (* 1 = 0.423513 loss)
I0628 19:48:31.801964  1232 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0628 19:48:35.403527  1232 solver.cpp:218] Iteration 8900 (27.7681 iter/s, 3.60126s/100 iters), loss = 0.388583
I0628 19:48:35.404026  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:48:35.404026  1232 solver.cpp:237]     Train net output #1: loss = 0.388583 (* 1 = 0.388583 loss)
I0628 19:48:35.404026  1232 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0628 19:48:38.833019 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:48:38.973668  1232 solver.cpp:330] Iteration 9000, Testing net (#0)
I0628 19:48:38.973668  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:48:39.791417 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:48:39.821472  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7989
I0628 19:48:39.821472  1232 solver.cpp:397]     Test net output #1: loss = 0.589552 (* 1 = 0.589552 loss)
I0628 19:48:39.855496  1232 solver.cpp:218] Iteration 9000 (22.4624 iter/s, 4.45188s/100 iters), loss = 0.39298
I0628 19:48:39.855496  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:48:39.855496  1232 solver.cpp:237]     Train net output #1: loss = 0.39298 (* 1 = 0.39298 loss)
I0628 19:48:39.855496  1232 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0628 19:48:43.443755  1232 solver.cpp:218] Iteration 9100 (27.8763 iter/s, 3.58728s/100 iters), loss = 0.353362
I0628 19:48:43.443755  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:48:43.443755  1232 solver.cpp:237]     Train net output #1: loss = 0.353362 (* 1 = 0.353362 loss)
I0628 19:48:43.443755  1232 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0628 19:48:47.036247  1232 solver.cpp:218] Iteration 9200 (27.8384 iter/s, 3.59216s/100 iters), loss = 0.414199
I0628 19:48:47.036247  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 19:48:47.036247  1232 solver.cpp:237]     Train net output #1: loss = 0.414199 (* 1 = 0.414199 loss)
I0628 19:48:47.036247  1232 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0628 19:48:50.633532  1232 solver.cpp:218] Iteration 9300 (27.801 iter/s, 3.59699s/100 iters), loss = 0.431388
I0628 19:48:50.633532  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:48:50.633532  1232 solver.cpp:237]     Train net output #1: loss = 0.431388 (* 1 = 0.431388 loss)
I0628 19:48:50.633532  1232 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0628 19:48:54.226339  1232 solver.cpp:218] Iteration 9400 (27.8338 iter/s, 3.59276s/100 iters), loss = 0.492363
I0628 19:48:54.226339  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 19:48:54.226339  1232 solver.cpp:237]     Train net output #1: loss = 0.492363 (* 1 = 0.492363 loss)
I0628 19:48:54.226339  1232 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0628 19:48:57.639093 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:48:57.781217  1232 solver.cpp:330] Iteration 9500, Testing net (#0)
I0628 19:48:57.781217  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:48:58.593132 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:48:58.624666  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8022
I0628 19:48:58.624666  1232 solver.cpp:397]     Test net output #1: loss = 0.596824 (* 1 = 0.596824 loss)
I0628 19:48:58.657852  1232 solver.cpp:218] Iteration 9500 (22.5644 iter/s, 4.43177s/100 iters), loss = 0.397983
I0628 19:48:58.658852  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:48:58.658852  1232 solver.cpp:237]     Train net output #1: loss = 0.397983 (* 1 = 0.397983 loss)
I0628 19:48:58.658852  1232 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0628 19:49:02.270311  1232 solver.cpp:218] Iteration 9600 (27.692 iter/s, 3.61116s/100 iters), loss = 0.400069
I0628 19:49:02.270311  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:49:02.270311  1232 solver.cpp:237]     Train net output #1: loss = 0.400069 (* 1 = 0.400069 loss)
I0628 19:49:02.270311  1232 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0628 19:49:05.882915  1232 solver.cpp:218] Iteration 9700 (27.6822 iter/s, 3.61244s/100 iters), loss = 0.438677
I0628 19:49:05.882915  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:49:05.882915  1232 solver.cpp:237]     Train net output #1: loss = 0.438677 (* 1 = 0.438677 loss)
I0628 19:49:05.882915  1232 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0628 19:49:09.484436  1232 solver.cpp:218] Iteration 9800 (27.7631 iter/s, 3.6019s/100 iters), loss = 0.487669
I0628 19:49:09.484436  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0628 19:49:09.484436  1232 solver.cpp:237]     Train net output #1: loss = 0.487669 (* 1 = 0.487669 loss)
I0628 19:49:09.485433  1232 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0628 19:49:13.079474  1232 solver.cpp:218] Iteration 9900 (27.8255 iter/s, 3.59383s/100 iters), loss = 0.413723
I0628 19:49:13.079474  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:49:13.079474  1232 solver.cpp:237]     Train net output #1: loss = 0.413723 (* 1 = 0.413723 loss)
I0628 19:49:13.079474  1232 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0628 19:49:16.492260 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:49:16.632364  1232 solver.cpp:330] Iteration 10000, Testing net (#0)
I0628 19:49:16.632364  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:49:17.446768 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:49:17.477793  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8136
I0628 19:49:17.477793  1232 solver.cpp:397]     Test net output #1: loss = 0.564635 (* 1 = 0.564635 loss)
I0628 19:49:17.511817  1232 solver.cpp:218] Iteration 10000 (22.5618 iter/s, 4.43226s/100 iters), loss = 0.373207
I0628 19:49:17.511817  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:49:17.511817  1232 solver.cpp:237]     Train net output #1: loss = 0.373207 (* 1 = 0.373207 loss)
I0628 19:49:17.511817  1232 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0628 19:49:21.093286  1232 solver.cpp:218] Iteration 10100 (27.9203 iter/s, 3.58162s/100 iters), loss = 0.483282
I0628 19:49:21.093286  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:49:21.093286  1232 solver.cpp:237]     Train net output #1: loss = 0.483282 (* 1 = 0.483282 loss)
I0628 19:49:21.093286  1232 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0628 19:49:24.675168  1232 solver.cpp:218] Iteration 10200 (27.9211 iter/s, 3.58152s/100 iters), loss = 0.38513
I0628 19:49:24.675168  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:49:24.675168  1232 solver.cpp:237]     Train net output #1: loss = 0.38513 (* 1 = 0.38513 loss)
I0628 19:49:24.675168  1232 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0628 19:49:28.260262  1232 solver.cpp:218] Iteration 10300 (27.9004 iter/s, 3.58417s/100 iters), loss = 0.399196
I0628 19:49:28.260262  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:49:28.260262  1232 solver.cpp:237]     Train net output #1: loss = 0.399196 (* 1 = 0.399196 loss)
I0628 19:49:28.260262  1232 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0628 19:49:31.846284  1232 solver.cpp:218] Iteration 10400 (27.8849 iter/s, 3.58617s/100 iters), loss = 0.410857
I0628 19:49:31.846284  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:49:31.846284  1232 solver.cpp:237]     Train net output #1: loss = 0.410857 (* 1 = 0.410857 loss)
I0628 19:49:31.846284  1232 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0628 19:49:35.256479 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:49:35.399085  1232 solver.cpp:330] Iteration 10500, Testing net (#0)
I0628 19:49:35.399085  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:49:36.211278 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:49:36.242300  1232 solver.cpp:397]     Test net output #0: accuracy = 0.795
I0628 19:49:36.242300  1232 solver.cpp:397]     Test net output #1: loss = 0.613101 (* 1 = 0.613101 loss)
I0628 19:49:36.276829  1232 solver.cpp:218] Iteration 10500 (22.5756 iter/s, 4.42957s/100 iters), loss = 0.513101
I0628 19:49:36.276829  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0628 19:49:36.276829  1232 solver.cpp:237]     Train net output #1: loss = 0.513101 (* 1 = 0.513101 loss)
I0628 19:49:36.276829  1232 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0628 19:49:39.880621  1232 solver.cpp:218] Iteration 10600 (27.7509 iter/s, 3.60349s/100 iters), loss = 0.369473
I0628 19:49:39.880621  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:49:39.880621  1232 solver.cpp:237]     Train net output #1: loss = 0.369473 (* 1 = 0.369473 loss)
I0628 19:49:39.880621  1232 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0628 19:49:43.478077  1232 solver.cpp:218] Iteration 10700 (27.7979 iter/s, 3.5974s/100 iters), loss = 0.431047
I0628 19:49:43.478077  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:49:43.478077  1232 solver.cpp:237]     Train net output #1: loss = 0.431047 (* 1 = 0.431047 loss)
I0628 19:49:43.478077  1232 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0628 19:49:47.071856  1232 solver.cpp:218] Iteration 10800 (27.828 iter/s, 3.5935s/100 iters), loss = 0.495156
I0628 19:49:47.071856  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:49:47.071856  1232 solver.cpp:237]     Train net output #1: loss = 0.495156 (* 1 = 0.495156 loss)
I0628 19:49:47.071856  1232 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0628 19:49:50.662577  1232 solver.cpp:218] Iteration 10900 (27.8511 iter/s, 3.59052s/100 iters), loss = 0.451378
I0628 19:49:50.662577  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 19:49:50.662577  1232 solver.cpp:237]     Train net output #1: loss = 0.451378 (* 1 = 0.451378 loss)
I0628 19:49:50.662577  1232 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0628 19:49:54.073328 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:49:54.213990  1232 solver.cpp:330] Iteration 11000, Testing net (#0)
I0628 19:49:54.213990  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:49:55.031335 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:49:55.061352  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7959
I0628 19:49:55.061352  1232 solver.cpp:397]     Test net output #1: loss = 0.60605 (* 1 = 0.60605 loss)
I0628 19:49:55.095408  1232 solver.cpp:218] Iteration 11000 (22.5596 iter/s, 4.43271s/100 iters), loss = 0.387889
I0628 19:49:55.095408  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:49:55.095408  1232 solver.cpp:237]     Train net output #1: loss = 0.387889 (* 1 = 0.387889 loss)
I0628 19:49:55.095408  1232 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0628 19:49:58.681326  1232 solver.cpp:218] Iteration 11100 (27.8932 iter/s, 3.58511s/100 iters), loss = 0.388562
I0628 19:49:58.681326  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:49:58.681326  1232 solver.cpp:237]     Train net output #1: loss = 0.388562 (* 1 = 0.388562 loss)
I0628 19:49:58.681326  1232 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0628 19:50:02.308745  1232 solver.cpp:218] Iteration 11200 (27.5705 iter/s, 3.62707s/100 iters), loss = 0.415054
I0628 19:50:02.308745  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:50:02.308745  1232 solver.cpp:237]     Train net output #1: loss = 0.415054 (* 1 = 0.415054 loss)
I0628 19:50:02.308745  1232 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0628 19:50:05.906668  1232 solver.cpp:218] Iteration 11300 (27.796 iter/s, 3.59764s/100 iters), loss = 0.49543
I0628 19:50:05.906668  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0628 19:50:05.906668  1232 solver.cpp:237]     Train net output #1: loss = 0.49543 (* 1 = 0.49543 loss)
I0628 19:50:05.906668  1232 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0628 19:50:09.495713  1232 solver.cpp:218] Iteration 11400 (27.8681 iter/s, 3.58834s/100 iters), loss = 0.424279
I0628 19:50:09.495713  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 19:50:09.495713  1232 solver.cpp:237]     Train net output #1: loss = 0.424279 (* 1 = 0.424279 loss)
I0628 19:50:09.495713  1232 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0628 19:50:12.920428 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:50:13.060529  1232 solver.cpp:330] Iteration 11500, Testing net (#0)
I0628 19:50:13.060529  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:50:13.877148 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:50:13.908179  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8185
I0628 19:50:13.908179  1232 solver.cpp:397]     Test net output #1: loss = 0.547888 (* 1 = 0.547888 loss)
I0628 19:50:13.942198  1232 solver.cpp:218] Iteration 11500 (22.4887 iter/s, 4.44668s/100 iters), loss = 0.358436
I0628 19:50:13.942198  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:50:13.942198  1232 solver.cpp:237]     Train net output #1: loss = 0.358436 (* 1 = 0.358436 loss)
I0628 19:50:13.942198  1232 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0628 19:50:17.530815  1232 solver.cpp:218] Iteration 11600 (27.8706 iter/s, 3.58801s/100 iters), loss = 0.39704
I0628 19:50:17.530815  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:50:17.530815  1232 solver.cpp:237]     Train net output #1: loss = 0.39704 (* 1 = 0.39704 loss)
I0628 19:50:17.530815  1232 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0628 19:50:21.109727  1232 solver.cpp:218] Iteration 11700 (27.9453 iter/s, 3.57842s/100 iters), loss = 0.394462
I0628 19:50:21.109727  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:50:21.109727  1232 solver.cpp:237]     Train net output #1: loss = 0.394462 (* 1 = 0.394462 loss)
I0628 19:50:21.109727  1232 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0628 19:50:24.689508  1232 solver.cpp:218] Iteration 11800 (27.9366 iter/s, 3.57953s/100 iters), loss = 0.432898
I0628 19:50:24.689508  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:50:24.689508  1232 solver.cpp:237]     Train net output #1: loss = 0.432898 (* 1 = 0.432898 loss)
I0628 19:50:24.689508  1232 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0628 19:50:28.276381  1232 solver.cpp:218] Iteration 11900 (27.8764 iter/s, 3.58726s/100 iters), loss = 0.403735
I0628 19:50:28.277382  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:50:28.277382  1232 solver.cpp:237]     Train net output #1: loss = 0.403735 (* 1 = 0.403735 loss)
I0628 19:50:28.277382  1232 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0628 19:50:31.685914 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:50:31.827024  1232 solver.cpp:330] Iteration 12000, Testing net (#0)
I0628 19:50:31.827024  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:50:32.645426 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:50:32.675447  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8112
I0628 19:50:32.675447  1232 solver.cpp:397]     Test net output #1: loss = 0.562153 (* 1 = 0.562153 loss)
I0628 19:50:32.710474  1232 solver.cpp:218] Iteration 12000 (22.5596 iter/s, 4.43269s/100 iters), loss = 0.328393
I0628 19:50:32.710474  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:50:32.710474  1232 solver.cpp:237]     Train net output #1: loss = 0.328393 (* 1 = 0.328393 loss)
I0628 19:50:32.710474  1232 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0628 19:50:36.296340  1232 solver.cpp:218] Iteration 12100 (27.8839 iter/s, 3.5863s/100 iters), loss = 0.398192
I0628 19:50:36.296340  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:50:36.296340  1232 solver.cpp:237]     Train net output #1: loss = 0.398192 (* 1 = 0.398192 loss)
I0628 19:50:36.296340  1232 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0628 19:50:39.891734  1232 solver.cpp:218] Iteration 12200 (27.821 iter/s, 3.59441s/100 iters), loss = 0.342178
I0628 19:50:39.891734  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:50:39.891734  1232 solver.cpp:237]     Train net output #1: loss = 0.342178 (* 1 = 0.342178 loss)
I0628 19:50:39.891734  1232 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0628 19:50:43.483790  1232 solver.cpp:218] Iteration 12300 (27.8422 iter/s, 3.59166s/100 iters), loss = 0.391251
I0628 19:50:43.483790  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:50:43.483790  1232 solver.cpp:237]     Train net output #1: loss = 0.391251 (* 1 = 0.391251 loss)
I0628 19:50:43.483790  1232 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0628 19:50:47.076480  1232 solver.cpp:218] Iteration 12400 (27.8376 iter/s, 3.59226s/100 iters), loss = 0.389144
I0628 19:50:47.076480  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:50:47.076480  1232 solver.cpp:237]     Train net output #1: loss = 0.389145 (* 1 = 0.389145 loss)
I0628 19:50:47.076480  1232 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0628 19:50:50.506032 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:50:50.646136  1232 solver.cpp:330] Iteration 12500, Testing net (#0)
I0628 19:50:50.646136  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:50:51.461386 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:50:51.491909  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8091
I0628 19:50:51.491909  1232 solver.cpp:397]     Test net output #1: loss = 0.569834 (* 1 = 0.569834 loss)
I0628 19:50:51.525933  1232 solver.cpp:218] Iteration 12500 (22.4744 iter/s, 4.4495s/100 iters), loss = 0.396035
I0628 19:50:51.525933  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:50:51.525933  1232 solver.cpp:237]     Train net output #1: loss = 0.396036 (* 1 = 0.396036 loss)
I0628 19:50:51.525933  1232 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0628 19:50:55.111709  1232 solver.cpp:218] Iteration 12600 (27.8875 iter/s, 3.58583s/100 iters), loss = 0.413963
I0628 19:50:55.111709  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:50:55.111709  1232 solver.cpp:237]     Train net output #1: loss = 0.413963 (* 1 = 0.413963 loss)
I0628 19:50:55.111709  1232 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0628 19:50:58.699393  1232 solver.cpp:218] Iteration 12700 (27.883 iter/s, 3.58642s/100 iters), loss = 0.338114
I0628 19:50:58.699393  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:50:58.699393  1232 solver.cpp:237]     Train net output #1: loss = 0.338114 (* 1 = 0.338114 loss)
I0628 19:50:58.699393  1232 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0628 19:51:02.286577  1232 solver.cpp:218] Iteration 12800 (27.8792 iter/s, 3.58691s/100 iters), loss = 0.397865
I0628 19:51:02.286577  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:51:02.286577  1232 solver.cpp:237]     Train net output #1: loss = 0.397865 (* 1 = 0.397865 loss)
I0628 19:51:02.286577  1232 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0628 19:51:05.870751  1232 solver.cpp:218] Iteration 12900 (27.8994 iter/s, 3.5843s/100 iters), loss = 0.380033
I0628 19:51:05.870751  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:51:05.870751  1232 solver.cpp:237]     Train net output #1: loss = 0.380033 (* 1 = 0.380033 loss)
I0628 19:51:05.870751  1232 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0628 19:51:09.291570 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:51:09.431169  1232 solver.cpp:330] Iteration 13000, Testing net (#0)
I0628 19:51:09.431169  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:51:10.243275 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:51:10.274307  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8098
I0628 19:51:10.274307  1232 solver.cpp:397]     Test net output #1: loss = 0.577125 (* 1 = 0.577125 loss)
I0628 19:51:10.309324  1232 solver.cpp:218] Iteration 13000 (22.5343 iter/s, 4.43767s/100 iters), loss = 0.368042
I0628 19:51:10.309324  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:51:10.309324  1232 solver.cpp:237]     Train net output #1: loss = 0.368042 (* 1 = 0.368042 loss)
I0628 19:51:10.309324  1232 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0628 19:51:13.888984  1232 solver.cpp:218] Iteration 13100 (27.9357 iter/s, 3.57964s/100 iters), loss = 0.346231
I0628 19:51:13.888984  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:51:13.888984  1232 solver.cpp:237]     Train net output #1: loss = 0.346231 (* 1 = 0.346231 loss)
I0628 19:51:13.888984  1232 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0628 19:51:17.475669  1232 solver.cpp:218] Iteration 13200 (27.8805 iter/s, 3.58674s/100 iters), loss = 0.390258
I0628 19:51:17.475669  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:51:17.476670  1232 solver.cpp:237]     Train net output #1: loss = 0.390258 (* 1 = 0.390258 loss)
I0628 19:51:17.476670  1232 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0628 19:51:21.075347  1232 solver.cpp:218] Iteration 13300 (27.7884 iter/s, 3.59862s/100 iters), loss = 0.338098
I0628 19:51:21.075347  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:51:21.075347  1232 solver.cpp:237]     Train net output #1: loss = 0.338098 (* 1 = 0.338098 loss)
I0628 19:51:21.075347  1232 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0628 19:51:24.658380  1232 solver.cpp:218] Iteration 13400 (27.9095 iter/s, 3.583s/100 iters), loss = 0.329153
I0628 19:51:24.658380  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:51:24.658380  1232 solver.cpp:237]     Train net output #1: loss = 0.329153 (* 1 = 0.329153 loss)
I0628 19:51:24.658380  1232 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0628 19:51:28.088800 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:51:28.228008  1232 solver.cpp:330] Iteration 13500, Testing net (#0)
I0628 19:51:28.228008  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:51:29.040091 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:51:29.070670  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8242
I0628 19:51:29.071671  1232 solver.cpp:397]     Test net output #1: loss = 0.521574 (* 1 = 0.521574 loss)
I0628 19:51:29.105695  1232 solver.cpp:218] Iteration 13500 (22.4898 iter/s, 4.44646s/100 iters), loss = 0.359399
I0628 19:51:29.105695  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:51:29.105695  1232 solver.cpp:237]     Train net output #1: loss = 0.359399 (* 1 = 0.359399 loss)
I0628 19:51:29.105695  1232 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0628 19:51:32.688354  1232 solver.cpp:218] Iteration 13600 (27.9146 iter/s, 3.58235s/100 iters), loss = 0.443432
I0628 19:51:32.688354  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:51:32.688354  1232 solver.cpp:237]     Train net output #1: loss = 0.443433 (* 1 = 0.443433 loss)
I0628 19:51:32.688354  1232 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0628 19:51:36.279188  1232 solver.cpp:218] Iteration 13700 (27.8491 iter/s, 3.59078s/100 iters), loss = 0.381258
I0628 19:51:36.279188  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:51:36.279688  1232 solver.cpp:237]     Train net output #1: loss = 0.381259 (* 1 = 0.381259 loss)
I0628 19:51:36.279688  1232 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0628 19:51:39.866375  1232 solver.cpp:218] Iteration 13800 (27.8774 iter/s, 3.58714s/100 iters), loss = 0.359735
I0628 19:51:39.866375  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:51:39.866375  1232 solver.cpp:237]     Train net output #1: loss = 0.359735 (* 1 = 0.359735 loss)
I0628 19:51:39.866375  1232 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0628 19:51:43.462126  1232 solver.cpp:218] Iteration 13900 (27.8177 iter/s, 3.59483s/100 iters), loss = 0.312109
I0628 19:51:43.462126  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:51:43.462126  1232 solver.cpp:237]     Train net output #1: loss = 0.312109 (* 1 = 0.312109 loss)
I0628 19:51:43.462126  1232 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0628 19:51:46.876588 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:51:47.016695  1232 solver.cpp:330] Iteration 14000, Testing net (#0)
I0628 19:51:47.016695  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:51:47.834448 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:51:47.865470  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8264
I0628 19:51:47.865470  1232 solver.cpp:397]     Test net output #1: loss = 0.54068 (* 1 = 0.54068 loss)
I0628 19:51:47.899497  1232 solver.cpp:218] Iteration 14000 (22.5378 iter/s, 4.43698s/100 iters), loss = 0.296746
I0628 19:51:47.899497  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:51:47.899497  1232 solver.cpp:237]     Train net output #1: loss = 0.296746 (* 1 = 0.296746 loss)
I0628 19:51:47.899497  1232 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0628 19:51:51.493116  1232 solver.cpp:218] Iteration 14100 (27.8313 iter/s, 3.59308s/100 iters), loss = 0.375762
I0628 19:51:51.493116  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:51:51.493116  1232 solver.cpp:237]     Train net output #1: loss = 0.375762 (* 1 = 0.375762 loss)
I0628 19:51:51.493116  1232 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0628 19:51:55.084799  1232 solver.cpp:218] Iteration 14200 (27.8432 iter/s, 3.59154s/100 iters), loss = 0.333956
I0628 19:51:55.084799  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:51:55.084799  1232 solver.cpp:237]     Train net output #1: loss = 0.333956 (* 1 = 0.333956 loss)
I0628 19:51:55.084799  1232 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0628 19:51:58.663486  1232 solver.cpp:218] Iteration 14300 (27.9474 iter/s, 3.57815s/100 iters), loss = 0.314201
I0628 19:51:58.663486  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:51:58.663486  1232 solver.cpp:237]     Train net output #1: loss = 0.314202 (* 1 = 0.314202 loss)
I0628 19:51:58.663486  1232 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0628 19:52:02.251132  1232 solver.cpp:218] Iteration 14400 (27.8694 iter/s, 3.58817s/100 iters), loss = 0.32211
I0628 19:52:02.251132  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:52:02.251132  1232 solver.cpp:237]     Train net output #1: loss = 0.32211 (* 1 = 0.32211 loss)
I0628 19:52:02.251132  1232 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0628 19:52:05.676625 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:52:05.816730  1232 solver.cpp:330] Iteration 14500, Testing net (#0)
I0628 19:52:05.816730  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:52:06.633342 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:52:06.664364  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8207
I0628 19:52:06.664364  1232 solver.cpp:397]     Test net output #1: loss = 0.555192 (* 1 = 0.555192 loss)
I0628 19:52:06.698390  1232 solver.cpp:218] Iteration 14500 (22.4912 iter/s, 4.44618s/100 iters), loss = 0.387317
I0628 19:52:06.698390  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:52:06.698390  1232 solver.cpp:237]     Train net output #1: loss = 0.387317 (* 1 = 0.387317 loss)
I0628 19:52:06.698390  1232 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0628 19:52:10.290061  1232 solver.cpp:218] Iteration 14600 (27.8388 iter/s, 3.59212s/100 iters), loss = 0.431301
I0628 19:52:10.291062  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:52:10.291062  1232 solver.cpp:237]     Train net output #1: loss = 0.431301 (* 1 = 0.431301 loss)
I0628 19:52:10.291062  1232 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0628 19:52:13.875738  1232 solver.cpp:218] Iteration 14700 (27.8995 iter/s, 3.5843s/100 iters), loss = 0.419094
I0628 19:52:13.875738  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:52:13.875738  1232 solver.cpp:237]     Train net output #1: loss = 0.419095 (* 1 = 0.419095 loss)
I0628 19:52:13.875738  1232 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0628 19:52:17.457700  1232 solver.cpp:218] Iteration 14800 (27.9133 iter/s, 3.58252s/100 iters), loss = 0.373883
I0628 19:52:17.458701  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:52:17.458701  1232 solver.cpp:237]     Train net output #1: loss = 0.373883 (* 1 = 0.373883 loss)
I0628 19:52:17.458701  1232 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0628 19:52:21.045367  1232 solver.cpp:218] Iteration 14900 (27.8788 iter/s, 3.58696s/100 iters), loss = 0.287841
I0628 19:52:21.045367  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:52:21.045367  1232 solver.cpp:237]     Train net output #1: loss = 0.287841 (* 1 = 0.287841 loss)
I0628 19:52:21.045367  1232 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0628 19:52:24.464843 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:52:24.604944  1232 solver.cpp:330] Iteration 15000, Testing net (#0)
I0628 19:52:24.604944  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:52:25.418983 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:52:25.449506  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7892
I0628 19:52:25.449506  1232 solver.cpp:397]     Test net output #1: loss = 0.672565 (* 1 = 0.672565 loss)
I0628 19:52:25.482529  1232 solver.cpp:218] Iteration 15000 (22.5374 iter/s, 4.43707s/100 iters), loss = 0.252674
I0628 19:52:25.482529  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:52:25.482529  1232 solver.cpp:237]     Train net output #1: loss = 0.252675 (* 1 = 0.252675 loss)
I0628 19:52:25.482529  1232 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0628 19:52:29.081984  1232 solver.cpp:218] Iteration 15100 (27.7904 iter/s, 3.59837s/100 iters), loss = 0.350551
I0628 19:52:29.081984  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:52:29.081984  1232 solver.cpp:237]     Train net output #1: loss = 0.350551 (* 1 = 0.350551 loss)
I0628 19:52:29.081984  1232 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0628 19:52:32.657655  1232 solver.cpp:218] Iteration 15200 (27.9624 iter/s, 3.57623s/100 iters), loss = 0.431117
I0628 19:52:32.658656  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:52:32.658656  1232 solver.cpp:237]     Train net output #1: loss = 0.431117 (* 1 = 0.431117 loss)
I0628 19:52:32.658656  1232 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0628 19:52:36.244333  1232 solver.cpp:218] Iteration 15300 (27.8901 iter/s, 3.5855s/100 iters), loss = 0.375781
I0628 19:52:36.244333  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:52:36.244333  1232 solver.cpp:237]     Train net output #1: loss = 0.375781 (* 1 = 0.375781 loss)
I0628 19:52:36.244333  1232 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0628 19:52:39.827011  1232 solver.cpp:218] Iteration 15400 (27.9151 iter/s, 3.58229s/100 iters), loss = 0.288826
I0628 19:52:39.827011  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:52:39.827011  1232 solver.cpp:237]     Train net output #1: loss = 0.288827 (* 1 = 0.288827 loss)
I0628 19:52:39.827011  1232 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0628 19:52:43.229039 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:52:43.369426  1232 solver.cpp:330] Iteration 15500, Testing net (#0)
I0628 19:52:43.369426  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:52:44.185350 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:52:44.216369  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8287
I0628 19:52:44.216369  1232 solver.cpp:397]     Test net output #1: loss = 0.528499 (* 1 = 0.528499 loss)
I0628 19:52:44.250413  1232 solver.cpp:218] Iteration 15500 (22.6085 iter/s, 4.42312s/100 iters), loss = 0.248312
I0628 19:52:44.250413  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 19:52:44.250413  1232 solver.cpp:237]     Train net output #1: loss = 0.248312 (* 1 = 0.248312 loss)
I0628 19:52:44.250413  1232 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0628 19:52:47.839089  1232 solver.cpp:218] Iteration 15600 (27.8663 iter/s, 3.58856s/100 iters), loss = 0.340954
I0628 19:52:47.839089  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:52:47.839089  1232 solver.cpp:237]     Train net output #1: loss = 0.340954 (* 1 = 0.340954 loss)
I0628 19:52:47.839089  1232 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0628 19:52:51.439370  1232 solver.cpp:218] Iteration 15700 (27.7809 iter/s, 3.5996s/100 iters), loss = 0.413625
I0628 19:52:51.439370  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:52:51.439370  1232 solver.cpp:237]     Train net output #1: loss = 0.413625 (* 1 = 0.413625 loss)
I0628 19:52:51.439370  1232 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0628 19:52:55.031819  1232 solver.cpp:218] Iteration 15800 (27.8371 iter/s, 3.59233s/100 iters), loss = 0.395928
I0628 19:52:55.031819  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:52:55.031819  1232 solver.cpp:237]     Train net output #1: loss = 0.395928 (* 1 = 0.395928 loss)
I0628 19:52:55.031819  1232 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0628 19:52:58.625021  1232 solver.cpp:218] Iteration 15900 (27.8273 iter/s, 3.59359s/100 iters), loss = 0.266892
I0628 19:52:58.625021  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:52:58.625021  1232 solver.cpp:237]     Train net output #1: loss = 0.266892 (* 1 = 0.266892 loss)
I0628 19:52:58.626022  1232 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0628 19:53:02.031726 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:53:02.171833  1232 solver.cpp:330] Iteration 16000, Testing net (#0)
I0628 19:53:02.171833  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:53:02.984421 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:53:03.014441  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8211
I0628 19:53:03.014441  1232 solver.cpp:397]     Test net output #1: loss = 0.553686 (* 1 = 0.553686 loss)
I0628 19:53:03.048974  1232 solver.cpp:218] Iteration 16000 (22.6083 iter/s, 4.42315s/100 iters), loss = 0.322369
I0628 19:53:03.049474  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:53:03.049474  1232 solver.cpp:237]     Train net output #1: loss = 0.322369 (* 1 = 0.322369 loss)
I0628 19:53:03.049474  1232 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0628 19:53:06.637802  1232 solver.cpp:218] Iteration 16100 (27.8684 iter/s, 3.58829s/100 iters), loss = 0.389625
I0628 19:53:06.637802  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:53:06.637802  1232 solver.cpp:237]     Train net output #1: loss = 0.389625 (* 1 = 0.389625 loss)
I0628 19:53:06.637802  1232 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0628 19:53:10.228986  1232 solver.cpp:218] Iteration 16200 (27.8454 iter/s, 3.59126s/100 iters), loss = 0.382842
I0628 19:53:10.228986  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:53:10.228986  1232 solver.cpp:237]     Train net output #1: loss = 0.382842 (* 1 = 0.382842 loss)
I0628 19:53:10.228986  1232 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0628 19:53:13.817472  1232 solver.cpp:218] Iteration 16300 (27.8749 iter/s, 3.58745s/100 iters), loss = 0.410321
I0628 19:53:13.817472  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:53:13.817472  1232 solver.cpp:237]     Train net output #1: loss = 0.410321 (* 1 = 0.410321 loss)
I0628 19:53:13.817472  1232 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0628 19:53:17.413511  1232 solver.cpp:218] Iteration 16400 (27.8104 iter/s, 3.59578s/100 iters), loss = 0.297358
I0628 19:53:17.413511  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:53:17.413511  1232 solver.cpp:237]     Train net output #1: loss = 0.297358 (* 1 = 0.297358 loss)
I0628 19:53:17.413511  1232 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0628 19:53:20.830942 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:53:20.972127  1232 solver.cpp:330] Iteration 16500, Testing net (#0)
I0628 19:53:20.972127  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:53:21.786937 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:53:21.817955  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8184
I0628 19:53:21.817955  1232 solver.cpp:397]     Test net output #1: loss = 0.547674 (* 1 = 0.547674 loss)
I0628 19:53:21.852979  1232 solver.cpp:218] Iteration 16500 (22.5266 iter/s, 4.4392s/100 iters), loss = 0.436865
I0628 19:53:21.852979  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:53:21.852979  1232 solver.cpp:237]     Train net output #1: loss = 0.436865 (* 1 = 0.436865 loss)
I0628 19:53:21.852979  1232 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0628 19:53:25.441689  1232 solver.cpp:218] Iteration 16600 (27.8658 iter/s, 3.58862s/100 iters), loss = 0.328904
I0628 19:53:25.441689  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:53:25.441689  1232 solver.cpp:237]     Train net output #1: loss = 0.328904 (* 1 = 0.328904 loss)
I0628 19:53:25.441689  1232 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0628 19:53:29.031162  1232 solver.cpp:218] Iteration 16700 (27.859 iter/s, 3.58951s/100 iters), loss = 0.343659
I0628 19:53:29.031162  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:53:29.031162  1232 solver.cpp:237]     Train net output #1: loss = 0.343659 (* 1 = 0.343659 loss)
I0628 19:53:29.031162  1232 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0628 19:53:32.620131  1232 solver.cpp:218] Iteration 16800 (27.8683 iter/s, 3.5883s/100 iters), loss = 0.389777
I0628 19:53:32.620131  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:53:32.620131  1232 solver.cpp:237]     Train net output #1: loss = 0.389777 (* 1 = 0.389777 loss)
I0628 19:53:32.620131  1232 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0628 19:53:36.200354  1232 solver.cpp:218] Iteration 16900 (27.931 iter/s, 3.58025s/100 iters), loss = 0.365486
I0628 19:53:36.200354  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:53:36.200354  1232 solver.cpp:237]     Train net output #1: loss = 0.365487 (* 1 = 0.365487 loss)
I0628 19:53:36.200354  1232 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0628 19:53:39.634277 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:53:39.776324  1232 solver.cpp:330] Iteration 17000, Testing net (#0)
I0628 19:53:39.776324  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:53:40.588477 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:53:40.618458  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8182
I0628 19:53:40.618458  1232 solver.cpp:397]     Test net output #1: loss = 0.5331 (* 1 = 0.5331 loss)
I0628 19:53:40.652482  1232 solver.cpp:218] Iteration 17000 (22.4631 iter/s, 4.45174s/100 iters), loss = 0.266783
I0628 19:53:40.652482  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:53:40.652482  1232 solver.cpp:237]     Train net output #1: loss = 0.266783 (* 1 = 0.266783 loss)
I0628 19:53:40.652482  1232 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0628 19:53:44.237897  1232 solver.cpp:218] Iteration 17100 (27.8999 iter/s, 3.58424s/100 iters), loss = 0.399117
I0628 19:53:44.237897  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:53:44.237897  1232 solver.cpp:237]     Train net output #1: loss = 0.399117 (* 1 = 0.399117 loss)
I0628 19:53:44.237897  1232 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0628 19:53:47.823906  1232 solver.cpp:218] Iteration 17200 (27.8847 iter/s, 3.5862s/100 iters), loss = 0.374777
I0628 19:53:47.823906  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:53:47.823906  1232 solver.cpp:237]     Train net output #1: loss = 0.374778 (* 1 = 0.374778 loss)
I0628 19:53:47.823906  1232 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0628 19:53:51.404992  1232 solver.cpp:218] Iteration 17300 (27.9253 iter/s, 3.58098s/100 iters), loss = 0.388296
I0628 19:53:51.404992  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:53:51.404992  1232 solver.cpp:237]     Train net output #1: loss = 0.388296 (* 1 = 0.388296 loss)
I0628 19:53:51.404992  1232 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0628 19:53:54.983769  1232 solver.cpp:218] Iteration 17400 (27.9483 iter/s, 3.57803s/100 iters), loss = 0.263391
I0628 19:53:54.983769  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:53:54.983769  1232 solver.cpp:237]     Train net output #1: loss = 0.263392 (* 1 = 0.263392 loss)
I0628 19:53:54.983769  1232 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0628 19:53:58.393028 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:53:58.533730  1232 solver.cpp:330] Iteration 17500, Testing net (#0)
I0628 19:53:58.533730  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:53:59.346299 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:53:59.377321  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8315
I0628 19:53:59.377321  1232 solver.cpp:397]     Test net output #1: loss = 0.499538 (* 1 = 0.499538 loss)
I0628 19:53:59.411345  1232 solver.cpp:218] Iteration 17500 (22.5876 iter/s, 4.4272s/100 iters), loss = 0.301299
I0628 19:53:59.411345  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:53:59.411345  1232 solver.cpp:237]     Train net output #1: loss = 0.301299 (* 1 = 0.301299 loss)
I0628 19:53:59.411345  1232 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0628 19:54:03.019793  1232 solver.cpp:218] Iteration 17600 (27.7135 iter/s, 3.60835s/100 iters), loss = 0.333637
I0628 19:54:03.019793  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:54:03.019793  1232 solver.cpp:237]     Train net output #1: loss = 0.333637 (* 1 = 0.333637 loss)
I0628 19:54:03.019793  1232 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0628 19:54:06.603657  1232 solver.cpp:218] Iteration 17700 (27.9087 iter/s, 3.58311s/100 iters), loss = 0.251575
I0628 19:54:06.603657  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 19:54:06.603657  1232 solver.cpp:237]     Train net output #1: loss = 0.251575 (* 1 = 0.251575 loss)
I0628 19:54:06.603657  1232 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0628 19:54:10.193187  1232 solver.cpp:218] Iteration 17800 (27.856 iter/s, 3.5899s/100 iters), loss = 0.295128
I0628 19:54:10.193187  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:54:10.193187  1232 solver.cpp:237]     Train net output #1: loss = 0.295128 (* 1 = 0.295128 loss)
I0628 19:54:10.193187  1232 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0628 19:54:13.778941  1232 solver.cpp:218] Iteration 17900 (27.8972 iter/s, 3.5846s/100 iters), loss = 0.310194
I0628 19:54:13.778941  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:54:13.778941  1232 solver.cpp:237]     Train net output #1: loss = 0.310195 (* 1 = 0.310195 loss)
I0628 19:54:13.778941  1232 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0628 19:54:17.186478 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:54:17.327586  1232 solver.cpp:330] Iteration 18000, Testing net (#0)
I0628 19:54:17.327586  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:54:18.148104 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:54:18.171121  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8311
I0628 19:54:18.171121  1232 solver.cpp:397]     Test net output #1: loss = 0.510878 (* 1 = 0.510878 loss)
I0628 19:54:18.205145  1232 solver.cpp:218] Iteration 18000 (22.5936 iter/s, 4.42603s/100 iters), loss = 0.287344
I0628 19:54:18.205145  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:54:18.205145  1232 solver.cpp:237]     Train net output #1: loss = 0.287344 (* 1 = 0.287344 loss)
I0628 19:54:18.205145  1232 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0628 19:54:21.796129  1232 solver.cpp:218] Iteration 18100 (27.8458 iter/s, 3.5912s/100 iters), loss = 0.327926
I0628 19:54:21.796129  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:54:21.796129  1232 solver.cpp:237]     Train net output #1: loss = 0.327926 (* 1 = 0.327926 loss)
I0628 19:54:21.796129  1232 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0628 19:54:25.392151  1232 solver.cpp:218] Iteration 18200 (27.8142 iter/s, 3.59529s/100 iters), loss = 0.473035
I0628 19:54:25.392151  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0628 19:54:25.392151  1232 solver.cpp:237]     Train net output #1: loss = 0.473035 (* 1 = 0.473035 loss)
I0628 19:54:25.392151  1232 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0628 19:54:28.975929  1232 solver.cpp:218] Iteration 18300 (27.9057 iter/s, 3.58349s/100 iters), loss = 0.305374
I0628 19:54:28.975929  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:54:28.975929  1232 solver.cpp:237]     Train net output #1: loss = 0.305375 (* 1 = 0.305375 loss)
I0628 19:54:28.975929  1232 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0628 19:54:32.571934  1232 solver.cpp:218] Iteration 18400 (27.8106 iter/s, 3.59575s/100 iters), loss = 0.295807
I0628 19:54:32.571934  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:54:32.571934  1232 solver.cpp:237]     Train net output #1: loss = 0.295807 (* 1 = 0.295807 loss)
I0628 19:54:32.571934  1232 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0628 19:54:35.989781 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:54:36.130887  1232 solver.cpp:330] Iteration 18500, Testing net (#0)
I0628 19:54:36.131387  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:54:36.943462 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:54:36.974484  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8235
I0628 19:54:36.974484  1232 solver.cpp:397]     Test net output #1: loss = 0.540042 (* 1 = 0.540042 loss)
I0628 19:54:37.008508  1232 solver.cpp:218] Iteration 18500 (22.542 iter/s, 4.43616s/100 iters), loss = 0.336791
I0628 19:54:37.008508  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:54:37.008508  1232 solver.cpp:237]     Train net output #1: loss = 0.336791 (* 1 = 0.336791 loss)
I0628 19:54:37.008508  1232 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0628 19:54:40.592180  1232 solver.cpp:218] Iteration 18600 (27.9097 iter/s, 3.58299s/100 iters), loss = 0.296143
I0628 19:54:40.592180  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:54:40.592180  1232 solver.cpp:237]     Train net output #1: loss = 0.296143 (* 1 = 0.296143 loss)
I0628 19:54:40.592180  1232 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0628 19:54:44.198521  1232 solver.cpp:218] Iteration 18700 (27.7332 iter/s, 3.60579s/100 iters), loss = 0.386798
I0628 19:54:44.198521  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:54:44.198521  1232 solver.cpp:237]     Train net output #1: loss = 0.386798 (* 1 = 0.386798 loss)
I0628 19:54:44.198521  1232 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0628 19:54:47.782063  1232 solver.cpp:218] Iteration 18800 (27.9066 iter/s, 3.58338s/100 iters), loss = 0.492081
I0628 19:54:47.782063  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:54:47.782063  1232 solver.cpp:237]     Train net output #1: loss = 0.492081 (* 1 = 0.492081 loss)
I0628 19:54:47.782063  1232 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0628 19:54:51.361732  1232 solver.cpp:218] Iteration 18900 (27.9343 iter/s, 3.57983s/100 iters), loss = 0.316609
I0628 19:54:51.361732  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:54:51.361732  1232 solver.cpp:237]     Train net output #1: loss = 0.316609 (* 1 = 0.316609 loss)
I0628 19:54:51.361732  1232 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0628 19:54:54.771441 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:54:54.912549  1232 solver.cpp:330] Iteration 19000, Testing net (#0)
I0628 19:54:54.912549  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:54:55.726153 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:54:55.756175  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8073
I0628 19:54:55.756175  1232 solver.cpp:397]     Test net output #1: loss = 0.590737 (* 1 = 0.590737 loss)
I0628 19:54:55.790700  1232 solver.cpp:218] Iteration 19000 (22.5822 iter/s, 4.42827s/100 iters), loss = 0.339471
I0628 19:54:55.790700  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:54:55.790700  1232 solver.cpp:237]     Train net output #1: loss = 0.339471 (* 1 = 0.339471 loss)
I0628 19:54:55.790700  1232 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0628 19:54:59.365031  1232 solver.cpp:218] Iteration 19100 (27.9758 iter/s, 3.57452s/100 iters), loss = 0.3803
I0628 19:54:59.366032  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:54:59.366032  1232 solver.cpp:237]     Train net output #1: loss = 0.3803 (* 1 = 0.3803 loss)
I0628 19:54:59.366032  1232 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0628 19:55:02.948524  1232 solver.cpp:218] Iteration 19200 (27.9099 iter/s, 3.58295s/100 iters), loss = 0.357129
I0628 19:55:02.948524  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:55:02.948524  1232 solver.cpp:237]     Train net output #1: loss = 0.357129 (* 1 = 0.357129 loss)
I0628 19:55:02.948524  1232 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0628 19:55:06.542687  1232 solver.cpp:218] Iteration 19300 (27.8254 iter/s, 3.59384s/100 iters), loss = 0.366688
I0628 19:55:06.542687  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:55:06.542687  1232 solver.cpp:237]     Train net output #1: loss = 0.366688 (* 1 = 0.366688 loss)
I0628 19:55:06.542687  1232 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0628 19:55:10.140794  1232 solver.cpp:218] Iteration 19400 (27.7982 iter/s, 3.59736s/100 iters), loss = 0.319056
I0628 19:55:10.140794  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:55:10.140794  1232 solver.cpp:237]     Train net output #1: loss = 0.319056 (* 1 = 0.319056 loss)
I0628 19:55:10.140794  1232 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0628 19:55:13.557286 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:55:13.697937  1232 solver.cpp:330] Iteration 19500, Testing net (#0)
I0628 19:55:13.697937  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:55:14.514144 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:55:14.545162  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8274
I0628 19:55:14.545162  1232 solver.cpp:397]     Test net output #1: loss = 0.519217 (* 1 = 0.519217 loss)
I0628 19:55:14.579186  1232 solver.cpp:218] Iteration 19500 (22.5325 iter/s, 4.43804s/100 iters), loss = 0.394023
I0628 19:55:14.579186  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:55:14.579186  1232 solver.cpp:237]     Train net output #1: loss = 0.394023 (* 1 = 0.394023 loss)
I0628 19:55:14.579186  1232 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0628 19:55:18.171368  1232 solver.cpp:218] Iteration 19600 (27.8388 iter/s, 3.59211s/100 iters), loss = 0.32895
I0628 19:55:18.171368  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:55:18.171368  1232 solver.cpp:237]     Train net output #1: loss = 0.328951 (* 1 = 0.328951 loss)
I0628 19:55:18.171368  1232 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0628 19:55:21.766850  1232 solver.cpp:218] Iteration 19700 (27.8187 iter/s, 3.59471s/100 iters), loss = 0.440169
I0628 19:55:21.766850  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:55:21.766850  1232 solver.cpp:237]     Train net output #1: loss = 0.440169 (* 1 = 0.440169 loss)
I0628 19:55:21.766850  1232 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0628 19:55:25.363008  1232 solver.cpp:218] Iteration 19800 (27.8111 iter/s, 3.59569s/100 iters), loss = 0.406028
I0628 19:55:25.363008  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:55:25.363008  1232 solver.cpp:237]     Train net output #1: loss = 0.406028 (* 1 = 0.406028 loss)
I0628 19:55:25.363008  1232 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0628 19:55:28.968171  1232 solver.cpp:218] Iteration 19900 (27.7409 iter/s, 3.60479s/100 iters), loss = 0.3066
I0628 19:55:28.968171  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:55:28.968171  1232 solver.cpp:237]     Train net output #1: loss = 0.3066 (* 1 = 0.3066 loss)
I0628 19:55:28.968171  1232 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0628 19:55:32.395193 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:55:32.535349  1232 solver.cpp:330] Iteration 20000, Testing net (#0)
I0628 19:55:32.535349  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:55:33.351177 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:55:33.382191  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8405
I0628 19:55:33.382191  1232 solver.cpp:397]     Test net output #1: loss = 0.493375 (* 1 = 0.493375 loss)
I0628 19:55:33.416229  1232 solver.cpp:218] Iteration 20000 (22.4818 iter/s, 4.44804s/100 iters), loss = 0.246552
I0628 19:55:33.416229  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:55:33.416229  1232 solver.cpp:237]     Train net output #1: loss = 0.246552 (* 1 = 0.246552 loss)
I0628 19:55:33.416229  1232 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0628 19:55:37.009167  1232 solver.cpp:218] Iteration 20100 (27.8361 iter/s, 3.59246s/100 iters), loss = 0.363139
I0628 19:55:37.009167  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:55:37.009167  1232 solver.cpp:237]     Train net output #1: loss = 0.363139 (* 1 = 0.363139 loss)
I0628 19:55:37.009167  1232 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0628 19:55:40.615900  1232 solver.cpp:218] Iteration 20200 (27.7298 iter/s, 3.60622s/100 iters), loss = 0.401286
I0628 19:55:40.615900  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:55:40.615900  1232 solver.cpp:237]     Train net output #1: loss = 0.401286 (* 1 = 0.401286 loss)
I0628 19:55:40.615900  1232 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0628 19:55:44.216122  1232 solver.cpp:218] Iteration 20300 (27.7778 iter/s, 3.6s/100 iters), loss = 0.354424
I0628 19:55:44.216122  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:55:44.216122  1232 solver.cpp:237]     Train net output #1: loss = 0.354425 (* 1 = 0.354425 loss)
I0628 19:55:44.216122  1232 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0628 19:55:47.806706  1232 solver.cpp:218] Iteration 20400 (27.8554 iter/s, 3.58996s/100 iters), loss = 0.331715
I0628 19:55:47.806706  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:55:47.806706  1232 solver.cpp:237]     Train net output #1: loss = 0.331715 (* 1 = 0.331715 loss)
I0628 19:55:47.806706  1232 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0628 19:55:51.232394 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:55:51.377535  1232 solver.cpp:330] Iteration 20500, Testing net (#0)
I0628 19:55:51.377535  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:55:52.195385 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:55:52.226403  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8486
I0628 19:55:52.226403  1232 solver.cpp:397]     Test net output #1: loss = 0.460921 (* 1 = 0.460921 loss)
I0628 19:55:52.261451  1232 solver.cpp:218] Iteration 20500 (22.4498 iter/s, 4.45437s/100 iters), loss = 0.252164
I0628 19:55:52.261451  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 19:55:52.261451  1232 solver.cpp:237]     Train net output #1: loss = 0.252164 (* 1 = 0.252164 loss)
I0628 19:55:52.261451  1232 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0628 19:55:55.865875  1232 solver.cpp:218] Iteration 20600 (27.7411 iter/s, 3.60476s/100 iters), loss = 0.314892
I0628 19:55:55.865875  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:55:55.865875  1232 solver.cpp:237]     Train net output #1: loss = 0.314892 (* 1 = 0.314892 loss)
I0628 19:55:55.865875  1232 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0628 19:55:59.459563  1232 solver.cpp:218] Iteration 20700 (27.8333 iter/s, 3.59282s/100 iters), loss = 0.438532
I0628 19:55:59.459563  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:55:59.459563  1232 solver.cpp:237]     Train net output #1: loss = 0.438533 (* 1 = 0.438533 loss)
I0628 19:55:59.459563  1232 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0628 19:56:03.049775  1232 solver.cpp:218] Iteration 20800 (27.8555 iter/s, 3.58996s/100 iters), loss = 0.329054
I0628 19:56:03.049775  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:56:03.049775  1232 solver.cpp:237]     Train net output #1: loss = 0.329054 (* 1 = 0.329054 loss)
I0628 19:56:03.049775  1232 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0628 19:56:06.645511  1232 solver.cpp:218] Iteration 20900 (27.8151 iter/s, 3.59517s/100 iters), loss = 0.246057
I0628 19:56:06.645511  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 19:56:06.645511  1232 solver.cpp:237]     Train net output #1: loss = 0.246058 (* 1 = 0.246058 loss)
I0628 19:56:06.645511  1232 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0628 19:56:10.067493 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:56:10.207630  1232 solver.cpp:330] Iteration 21000, Testing net (#0)
I0628 19:56:10.208632  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:56:11.022310 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:56:11.053354  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8415
I0628 19:56:11.053354  1232 solver.cpp:397]     Test net output #1: loss = 0.482898 (* 1 = 0.482898 loss)
I0628 19:56:11.087085  1232 solver.cpp:218] Iteration 21000 (22.5124 iter/s, 4.442s/100 iters), loss = 0.239669
I0628 19:56:11.087085  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:56:11.087085  1232 solver.cpp:237]     Train net output #1: loss = 0.239669 (* 1 = 0.239669 loss)
I0628 19:56:11.087085  1232 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0628 19:56:14.690834  1232 solver.cpp:218] Iteration 21100 (27.7562 iter/s, 3.6028s/100 iters), loss = 0.34532
I0628 19:56:14.690834  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:56:14.690834  1232 solver.cpp:237]     Train net output #1: loss = 0.34532 (* 1 = 0.34532 loss)
I0628 19:56:14.690834  1232 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0628 19:56:18.293006  1232 solver.cpp:218] Iteration 21200 (27.7637 iter/s, 3.60183s/100 iters), loss = 0.310813
I0628 19:56:18.293006  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:56:18.293006  1232 solver.cpp:237]     Train net output #1: loss = 0.310813 (* 1 = 0.310813 loss)
I0628 19:56:18.293006  1232 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0628 19:56:21.899848  1232 solver.cpp:218] Iteration 21300 (27.7237 iter/s, 3.60702s/100 iters), loss = 0.333803
I0628 19:56:21.899848  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:56:21.899848  1232 solver.cpp:237]     Train net output #1: loss = 0.333803 (* 1 = 0.333803 loss)
I0628 19:56:21.899848  1232 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0628 19:56:25.499125  1232 solver.cpp:218] Iteration 21400 (27.7908 iter/s, 3.59831s/100 iters), loss = 0.229276
I0628 19:56:25.499125  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:56:25.499125  1232 solver.cpp:237]     Train net output #1: loss = 0.229276 (* 1 = 0.229276 loss)
I0628 19:56:25.499125  1232 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0628 19:56:28.913110 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:56:29.053742  1232 solver.cpp:330] Iteration 21500, Testing net (#0)
I0628 19:56:29.053742  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:56:29.874516 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:56:29.905575  1232 solver.cpp:397]     Test net output #0: accuracy = 0.7986
I0628 19:56:29.905575  1232 solver.cpp:397]     Test net output #1: loss = 0.616241 (* 1 = 0.616241 loss)
I0628 19:56:29.939584  1232 solver.cpp:218] Iteration 21500 (22.5196 iter/s, 4.44058s/100 iters), loss = 0.256786
I0628 19:56:29.939584  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:56:29.939584  1232 solver.cpp:237]     Train net output #1: loss = 0.256786 (* 1 = 0.256786 loss)
I0628 19:56:29.939584  1232 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0628 19:56:33.529619  1232 solver.cpp:218] Iteration 21600 (27.8585 iter/s, 3.58957s/100 iters), loss = 0.308019
I0628 19:56:33.529619  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:56:33.529619  1232 solver.cpp:237]     Train net output #1: loss = 0.308019 (* 1 = 0.308019 loss)
I0628 19:56:33.529619  1232 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0628 19:56:37.117799  1232 solver.cpp:218] Iteration 21700 (27.8707 iter/s, 3.588s/100 iters), loss = 0.336575
I0628 19:56:37.117799  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:56:37.117799  1232 solver.cpp:237]     Train net output #1: loss = 0.336575 (* 1 = 0.336575 loss)
I0628 19:56:37.117799  1232 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0628 19:56:40.712831  1232 solver.cpp:218] Iteration 21800 (27.8225 iter/s, 3.59421s/100 iters), loss = 0.317988
I0628 19:56:40.712831  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:56:40.712831  1232 solver.cpp:237]     Train net output #1: loss = 0.317988 (* 1 = 0.317988 loss)
I0628 19:56:40.712831  1232 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0628 19:56:44.296120  1232 solver.cpp:218] Iteration 21900 (27.9084 iter/s, 3.58316s/100 iters), loss = 0.27952
I0628 19:56:44.296120  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:56:44.296120  1232 solver.cpp:237]     Train net output #1: loss = 0.27952 (* 1 = 0.27952 loss)
I0628 19:56:44.296120  1232 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0628 19:56:47.719498 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:56:47.858660  1232 solver.cpp:330] Iteration 22000, Testing net (#0)
I0628 19:56:47.858660  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:56:48.679314 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:56:48.710347  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8204
I0628 19:56:48.710347  1232 solver.cpp:397]     Test net output #1: loss = 0.553065 (* 1 = 0.553065 loss)
I0628 19:56:48.743388  1232 solver.cpp:218] Iteration 22000 (22.4857 iter/s, 4.44727s/100 iters), loss = 0.306391
I0628 19:56:48.743388  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:56:48.743388  1232 solver.cpp:237]     Train net output #1: loss = 0.306391 (* 1 = 0.306391 loss)
I0628 19:56:48.743388  1232 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0628 19:56:52.334841  1232 solver.cpp:218] Iteration 22100 (27.8475 iter/s, 3.59098s/100 iters), loss = 0.437106
I0628 19:56:52.334841  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:56:52.334841  1232 solver.cpp:237]     Train net output #1: loss = 0.437106 (* 1 = 0.437106 loss)
I0628 19:56:52.334841  1232 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0628 19:56:55.930450  1232 solver.cpp:218] Iteration 22200 (27.8163 iter/s, 3.59502s/100 iters), loss = 0.317598
I0628 19:56:55.930450  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:56:55.930450  1232 solver.cpp:237]     Train net output #1: loss = 0.317598 (* 1 = 0.317598 loss)
I0628 19:56:55.930450  1232 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0628 19:56:59.524401  1232 solver.cpp:218] Iteration 22300 (27.8289 iter/s, 3.59338s/100 iters), loss = 0.269708
I0628 19:56:59.524401  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 19:56:59.524401  1232 solver.cpp:237]     Train net output #1: loss = 0.269708 (* 1 = 0.269708 loss)
I0628 19:56:59.524401  1232 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0628 19:57:03.117194  1232 solver.cpp:218] Iteration 22400 (27.8388 iter/s, 3.59212s/100 iters), loss = 0.254546
I0628 19:57:03.117194  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:57:03.117194  1232 solver.cpp:237]     Train net output #1: loss = 0.254547 (* 1 = 0.254547 loss)
I0628 19:57:03.117194  1232 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0628 19:57:06.532786 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:57:06.673964  1232 solver.cpp:330] Iteration 22500, Testing net (#0)
I0628 19:57:06.673964  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:57:07.488807 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:57:07.519832  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8425
I0628 19:57:07.519832  1232 solver.cpp:397]     Test net output #1: loss = 0.487641 (* 1 = 0.487641 loss)
I0628 19:57:07.553866  1232 solver.cpp:218] Iteration 22500 (22.5396 iter/s, 4.43664s/100 iters), loss = 0.26765
I0628 19:57:07.553866  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:57:07.553866  1232 solver.cpp:237]     Train net output #1: loss = 0.26765 (* 1 = 0.26765 loss)
I0628 19:57:07.553866  1232 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0628 19:57:11.141517  1232 solver.cpp:218] Iteration 22600 (27.8778 iter/s, 3.58708s/100 iters), loss = 0.303058
I0628 19:57:11.141517  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:57:11.141517  1232 solver.cpp:237]     Train net output #1: loss = 0.303058 (* 1 = 0.303058 loss)
I0628 19:57:11.141517  1232 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0628 19:57:14.727610  1232 solver.cpp:218] Iteration 22700 (27.8873 iter/s, 3.58586s/100 iters), loss = 0.333163
I0628 19:57:14.727610  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0628 19:57:14.727610  1232 solver.cpp:237]     Train net output #1: loss = 0.333163 (* 1 = 0.333163 loss)
I0628 19:57:14.727610  1232 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0628 19:57:18.325104  1232 solver.cpp:218] Iteration 22800 (27.7938 iter/s, 3.59793s/100 iters), loss = 0.294439
I0628 19:57:18.326105  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:57:18.326105  1232 solver.cpp:237]     Train net output #1: loss = 0.294439 (* 1 = 0.294439 loss)
I0628 19:57:18.326105  1232 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0628 19:57:21.926614  1232 solver.cpp:218] Iteration 22900 (27.7735 iter/s, 3.60056s/100 iters), loss = 0.240429
I0628 19:57:21.926614  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:57:21.926614  1232 solver.cpp:237]     Train net output #1: loss = 0.240429 (* 1 = 0.240429 loss)
I0628 19:57:21.926614  1232 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0628 19:57:25.336323 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:57:25.475926  1232 solver.cpp:330] Iteration 23000, Testing net (#0)
I0628 19:57:25.476428  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:57:26.302335 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:57:26.325350  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8279
I0628 19:57:26.325350  1232 solver.cpp:397]     Test net output #1: loss = 0.524004 (* 1 = 0.524004 loss)
I0628 19:57:26.360374  1232 solver.cpp:218] Iteration 23000 (22.5578 iter/s, 4.43305s/100 iters), loss = 0.300607
I0628 19:57:26.360374  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:57:26.360374  1232 solver.cpp:237]     Train net output #1: loss = 0.300607 (* 1 = 0.300607 loss)
I0628 19:57:26.360374  1232 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0628 19:57:29.941217  1232 solver.cpp:218] Iteration 23100 (27.9286 iter/s, 3.58056s/100 iters), loss = 0.314884
I0628 19:57:29.941217  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:57:29.941217  1232 solver.cpp:237]     Train net output #1: loss = 0.314884 (* 1 = 0.314884 loss)
I0628 19:57:29.941217  1232 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0628 19:57:33.521733  1232 solver.cpp:218] Iteration 23200 (27.9253 iter/s, 3.58098s/100 iters), loss = 0.291737
I0628 19:57:33.521733  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:57:33.522734  1232 solver.cpp:237]     Train net output #1: loss = 0.291737 (* 1 = 0.291737 loss)
I0628 19:57:33.522734  1232 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0628 19:57:37.113229  1232 solver.cpp:218] Iteration 23300 (27.8515 iter/s, 3.59047s/100 iters), loss = 0.379688
I0628 19:57:37.113229  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 19:57:37.113229  1232 solver.cpp:237]     Train net output #1: loss = 0.379688 (* 1 = 0.379688 loss)
I0628 19:57:37.113229  1232 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0628 19:57:40.724858  1232 solver.cpp:218] Iteration 23400 (27.6917 iter/s, 3.61119s/100 iters), loss = 0.332229
I0628 19:57:40.724858  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:57:40.724858  1232 solver.cpp:237]     Train net output #1: loss = 0.332229 (* 1 = 0.332229 loss)
I0628 19:57:40.724858  1232 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0628 19:57:44.130370 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:57:44.271476  1232 solver.cpp:330] Iteration 23500, Testing net (#0)
I0628 19:57:44.271476  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:57:45.089236 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:57:45.120276  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8444
I0628 19:57:45.120276  1232 solver.cpp:397]     Test net output #1: loss = 0.468016 (* 1 = 0.468016 loss)
I0628 19:57:45.154284  1232 solver.cpp:218] Iteration 23500 (22.5773 iter/s, 4.42922s/100 iters), loss = 0.175274
I0628 19:57:45.154284  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 19:57:45.154284  1232 solver.cpp:237]     Train net output #1: loss = 0.175274 (* 1 = 0.175274 loss)
I0628 19:57:45.154284  1232 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0628 19:57:48.751292  1232 solver.cpp:218] Iteration 23600 (27.8039 iter/s, 3.59662s/100 iters), loss = 0.345336
I0628 19:57:48.751292  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 19:57:48.751292  1232 solver.cpp:237]     Train net output #1: loss = 0.345336 (* 1 = 0.345336 loss)
I0628 19:57:48.751292  1232 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0628 19:57:52.337466  1232 solver.cpp:218] Iteration 23700 (27.886 iter/s, 3.58603s/100 iters), loss = 0.442574
I0628 19:57:52.337466  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:57:52.337466  1232 solver.cpp:237]     Train net output #1: loss = 0.442574 (* 1 = 0.442574 loss)
I0628 19:57:52.337466  1232 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0628 19:57:55.932978  1232 solver.cpp:218] Iteration 23800 (27.8165 iter/s, 3.59499s/100 iters), loss = 0.271688
I0628 19:57:55.932978  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:57:55.932978  1232 solver.cpp:237]     Train net output #1: loss = 0.271688 (* 1 = 0.271688 loss)
I0628 19:57:55.932978  1232 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0628 19:57:59.511767  1232 solver.cpp:218] Iteration 23900 (27.9422 iter/s, 3.57881s/100 iters), loss = 0.277324
I0628 19:57:59.511767  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:57:59.511767  1232 solver.cpp:237]     Train net output #1: loss = 0.277324 (* 1 = 0.277324 loss)
I0628 19:57:59.511767  1232 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0628 19:58:02.924304 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:58:03.064409  1232 solver.cpp:330] Iteration 24000, Testing net (#0)
I0628 19:58:03.064909  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:58:03.881018 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:58:03.911039  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8455
I0628 19:58:03.912040  1232 solver.cpp:397]     Test net output #1: loss = 0.482602 (* 1 = 0.482602 loss)
I0628 19:58:03.946064  1232 solver.cpp:218] Iteration 24000 (22.5559 iter/s, 4.43343s/100 iters), loss = 0.216505
I0628 19:58:03.946064  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 19:58:03.946064  1232 solver.cpp:237]     Train net output #1: loss = 0.216505 (* 1 = 0.216505 loss)
I0628 19:58:03.946064  1232 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0628 19:58:07.537731  1232 solver.cpp:218] Iteration 24100 (27.8391 iter/s, 3.59206s/100 iters), loss = 0.366808
I0628 19:58:07.537731  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:58:07.537731  1232 solver.cpp:237]     Train net output #1: loss = 0.366808 (* 1 = 0.366808 loss)
I0628 19:58:07.537731  1232 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0628 19:58:11.123240  1232 solver.cpp:218] Iteration 24200 (27.8992 iter/s, 3.58433s/100 iters), loss = 0.220316
I0628 19:58:11.123240  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 19:58:11.123240  1232 solver.cpp:237]     Train net output #1: loss = 0.220316 (* 1 = 0.220316 loss)
I0628 19:58:11.123240  1232 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0628 19:58:14.709918  1232 solver.cpp:218] Iteration 24300 (27.8833 iter/s, 3.58637s/100 iters), loss = 0.338547
I0628 19:58:14.709918  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:58:14.709918  1232 solver.cpp:237]     Train net output #1: loss = 0.338547 (* 1 = 0.338547 loss)
I0628 19:58:14.709918  1232 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0628 19:58:18.296175  1232 solver.cpp:218] Iteration 24400 (27.8854 iter/s, 3.5861s/100 iters), loss = 0.267835
I0628 19:58:18.296175  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:58:18.296175  1232 solver.cpp:237]     Train net output #1: loss = 0.267835 (* 1 = 0.267835 loss)
I0628 19:58:18.296175  1232 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0628 19:58:21.715976 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:58:21.856078  1232 solver.cpp:330] Iteration 24500, Testing net (#0)
I0628 19:58:21.857079  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:58:22.668303 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:58:22.699340  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8463
I0628 19:58:22.699340  1232 solver.cpp:397]     Test net output #1: loss = 0.468754 (* 1 = 0.468754 loss)
I0628 19:58:22.732854  1232 solver.cpp:218] Iteration 24500 (22.5391 iter/s, 4.43673s/100 iters), loss = 0.213622
I0628 19:58:22.732854  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 19:58:22.732854  1232 solver.cpp:237]     Train net output #1: loss = 0.213622 (* 1 = 0.213622 loss)
I0628 19:58:22.732854  1232 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0628 19:58:26.323508  1232 solver.cpp:218] Iteration 24600 (27.8566 iter/s, 3.58981s/100 iters), loss = 0.320056
I0628 19:58:26.323508  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 19:58:26.323508  1232 solver.cpp:237]     Train net output #1: loss = 0.320056 (* 1 = 0.320056 loss)
I0628 19:58:26.323508  1232 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0628 19:58:29.922986  1232 solver.cpp:218] Iteration 24700 (27.7836 iter/s, 3.59925s/100 iters), loss = 0.285843
I0628 19:58:29.922986  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:58:29.922986  1232 solver.cpp:237]     Train net output #1: loss = 0.285843 (* 1 = 0.285843 loss)
I0628 19:58:29.922986  1232 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0628 19:58:33.518673  1232 solver.cpp:218] Iteration 24800 (27.8127 iter/s, 3.59548s/100 iters), loss = 0.300992
I0628 19:58:33.518673  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:58:33.518673  1232 solver.cpp:237]     Train net output #1: loss = 0.300992 (* 1 = 0.300992 loss)
I0628 19:58:33.518673  1232 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0628 19:58:37.112433  1232 solver.cpp:218] Iteration 24900 (27.8296 iter/s, 3.59329s/100 iters), loss = 0.279451
I0628 19:58:37.112933  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:58:37.112933  1232 solver.cpp:237]     Train net output #1: loss = 0.279451 (* 1 = 0.279451 loss)
I0628 19:58:37.112933  1232 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0628 19:58:40.526814 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:58:40.666916  1232 solver.cpp:330] Iteration 25000, Testing net (#0)
I0628 19:58:40.666916  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:58:41.486547 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:58:41.517571  1232 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0628 19:58:41.517571  1232 solver.cpp:397]     Test net output #1: loss = 0.560708 (* 1 = 0.560708 loss)
I0628 19:58:41.551596  1232 solver.cpp:218] Iteration 25000 (22.5292 iter/s, 4.43868s/100 iters), loss = 0.275876
I0628 19:58:41.551596  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 19:58:41.551596  1232 solver.cpp:237]     Train net output #1: loss = 0.275876 (* 1 = 0.275876 loss)
I0628 19:58:41.551596  1232 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0628 19:58:45.136453  1232 solver.cpp:218] Iteration 25100 (27.8982 iter/s, 3.58447s/100 iters), loss = 0.347054
I0628 19:58:45.136453  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 19:58:45.136453  1232 solver.cpp:237]     Train net output #1: loss = 0.347054 (* 1 = 0.347054 loss)
I0628 19:58:45.136453  1232 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0628 19:58:48.731878  1232 solver.cpp:218] Iteration 25200 (27.8126 iter/s, 3.5955s/100 iters), loss = 0.256533
I0628 19:58:48.731878  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 19:58:48.731878  1232 solver.cpp:237]     Train net output #1: loss = 0.256534 (* 1 = 0.256534 loss)
I0628 19:58:48.731878  1232 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0628 19:58:52.337050  1232 solver.cpp:218] Iteration 25300 (27.7392 iter/s, 3.605s/100 iters), loss = 0.413574
I0628 19:58:52.337050  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:58:52.338052  1232 solver.cpp:237]     Train net output #1: loss = 0.413575 (* 1 = 0.413575 loss)
I0628 19:58:52.338052  1232 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0628 19:58:55.939517  1232 solver.cpp:218] Iteration 25400 (27.7638 iter/s, 3.60181s/100 iters), loss = 0.26872
I0628 19:58:55.939517  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:58:55.939517  1232 solver.cpp:237]     Train net output #1: loss = 0.26872 (* 1 = 0.26872 loss)
I0628 19:58:55.939517  1232 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0628 19:58:59.359056 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:58:59.499158  1232 solver.cpp:330] Iteration 25500, Testing net (#0)
I0628 19:58:59.499158  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:59:00.312791 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:59:00.343818  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8295
I0628 19:59:00.343818  1232 solver.cpp:397]     Test net output #1: loss = 0.527877 (* 1 = 0.527877 loss)
I0628 19:59:00.377841  1232 solver.cpp:218] Iteration 25500 (22.5347 iter/s, 4.43759s/100 iters), loss = 0.236875
I0628 19:59:00.377841  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 19:59:00.377841  1232 solver.cpp:237]     Train net output #1: loss = 0.236875 (* 1 = 0.236875 loss)
I0628 19:59:00.377841  1232 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0628 19:59:03.971541  1232 solver.cpp:218] Iteration 25600 (27.8308 iter/s, 3.59315s/100 iters), loss = 0.295803
I0628 19:59:03.971541  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:59:03.971541  1232 solver.cpp:237]     Train net output #1: loss = 0.295804 (* 1 = 0.295804 loss)
I0628 19:59:03.971541  1232 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0628 19:59:07.563650  1232 solver.cpp:218] Iteration 25700 (27.8391 iter/s, 3.59208s/100 iters), loss = 0.264163
I0628 19:59:07.563650  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 19:59:07.563650  1232 solver.cpp:237]     Train net output #1: loss = 0.264163 (* 1 = 0.264163 loss)
I0628 19:59:07.563650  1232 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0628 19:59:11.160418  1232 solver.cpp:218] Iteration 25800 (27.8041 iter/s, 3.59659s/100 iters), loss = 0.409504
I0628 19:59:11.160418  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0628 19:59:11.160418  1232 solver.cpp:237]     Train net output #1: loss = 0.409504 (* 1 = 0.409504 loss)
I0628 19:59:11.160418  1232 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0628 19:59:14.747681  1232 solver.cpp:218] Iteration 25900 (27.8812 iter/s, 3.58664s/100 iters), loss = 0.261201
I0628 19:59:14.747681  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:59:14.747681  1232 solver.cpp:237]     Train net output #1: loss = 0.261201 (* 1 = 0.261201 loss)
I0628 19:59:14.747681  1232 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0628 19:59:18.159318 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:59:18.299448  1232 solver.cpp:330] Iteration 26000, Testing net (#0)
I0628 19:59:18.299953  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:59:19.114888 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:59:19.145428  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8408
I0628 19:59:19.145428  1232 solver.cpp:397]     Test net output #1: loss = 0.493183 (* 1 = 0.493183 loss)
I0628 19:59:19.179442  1232 solver.cpp:218] Iteration 26000 (22.5649 iter/s, 4.43166s/100 iters), loss = 0.218744
I0628 19:59:19.179442  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 19:59:19.179442  1232 solver.cpp:237]     Train net output #1: loss = 0.218744 (* 1 = 0.218744 loss)
I0628 19:59:19.179442  1232 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0628 19:59:22.784368  1232 solver.cpp:218] Iteration 26100 (27.7457 iter/s, 3.60416s/100 iters), loss = 0.311984
I0628 19:59:22.784368  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:59:22.784368  1232 solver.cpp:237]     Train net output #1: loss = 0.311984 (* 1 = 0.311984 loss)
I0628 19:59:22.784368  1232 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0628 19:59:26.379009  1232 solver.cpp:218] Iteration 26200 (27.8192 iter/s, 3.59463s/100 iters), loss = 0.346536
I0628 19:59:26.379009  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:59:26.379009  1232 solver.cpp:237]     Train net output #1: loss = 0.346536 (* 1 = 0.346536 loss)
I0628 19:59:26.379009  1232 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0628 19:59:29.982980  1232 solver.cpp:218] Iteration 26300 (27.7472 iter/s, 3.60397s/100 iters), loss = 0.285944
I0628 19:59:29.982980  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:59:29.982980  1232 solver.cpp:237]     Train net output #1: loss = 0.285945 (* 1 = 0.285945 loss)
I0628 19:59:29.982980  1232 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0628 19:59:33.579803  1232 solver.cpp:218] Iteration 26400 (27.8056 iter/s, 3.59639s/100 iters), loss = 0.194552
I0628 19:59:33.579803  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 19:59:33.579803  1232 solver.cpp:237]     Train net output #1: loss = 0.194552 (* 1 = 0.194552 loss)
I0628 19:59:33.579803  1232 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0628 19:59:36.999357 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:59:37.139464  1232 solver.cpp:330] Iteration 26500, Testing net (#0)
I0628 19:59:37.139464  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:59:37.962077 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:59:37.992099  1232 solver.cpp:397]     Test net output #0: accuracy = 0.834
I0628 19:59:37.993100  1232 solver.cpp:397]     Test net output #1: loss = 0.504941 (* 1 = 0.504941 loss)
I0628 19:59:38.027125  1232 solver.cpp:218] Iteration 26500 (22.4909 iter/s, 4.44623s/100 iters), loss = 0.30697
I0628 19:59:38.027125  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:59:38.027125  1232 solver.cpp:237]     Train net output #1: loss = 0.30697 (* 1 = 0.30697 loss)
I0628 19:59:38.027125  1232 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0628 19:59:41.620800  1232 solver.cpp:218] Iteration 26600 (27.8291 iter/s, 3.59336s/100 iters), loss = 0.364136
I0628 19:59:41.620800  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:59:41.620800  1232 solver.cpp:237]     Train net output #1: loss = 0.364136 (* 1 = 0.364136 loss)
I0628 19:59:41.620800  1232 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0628 19:59:45.202802  1232 solver.cpp:218] Iteration 26700 (27.9141 iter/s, 3.58243s/100 iters), loss = 0.321579
I0628 19:59:45.202802  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 19:59:45.202802  1232 solver.cpp:237]     Train net output #1: loss = 0.32158 (* 1 = 0.32158 loss)
I0628 19:59:45.202802  1232 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0628 19:59:48.786540  1232 solver.cpp:218] Iteration 26800 (27.9067 iter/s, 3.58337s/100 iters), loss = 0.295823
I0628 19:59:48.786540  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 19:59:48.786540  1232 solver.cpp:237]     Train net output #1: loss = 0.295823 (* 1 = 0.295823 loss)
I0628 19:59:48.786540  1232 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0628 19:59:52.370235  1232 solver.cpp:218] Iteration 26900 (27.9119 iter/s, 3.5827s/100 iters), loss = 0.221107
I0628 19:59:52.370235  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 19:59:52.370235  1232 solver.cpp:237]     Train net output #1: loss = 0.221107 (* 1 = 0.221107 loss)
I0628 19:59:52.370235  1232 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0628 19:59:55.773658 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:59:55.914759  1232 solver.cpp:330] Iteration 27000, Testing net (#0)
I0628 19:59:55.914759  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 19:59:56.729369 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 19:59:56.760395  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8509
I0628 19:59:56.760395  1232 solver.cpp:397]     Test net output #1: loss = 0.457276 (* 1 = 0.457276 loss)
I0628 19:59:56.794419  1232 solver.cpp:218] Iteration 27000 (22.6019 iter/s, 4.42441s/100 iters), loss = 0.209566
I0628 19:59:56.794419  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 19:59:56.794419  1232 solver.cpp:237]     Train net output #1: loss = 0.209566 (* 1 = 0.209566 loss)
I0628 19:59:56.794419  1232 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0628 20:00:00.401625  1232 solver.cpp:218] Iteration 27100 (27.7294 iter/s, 3.60628s/100 iters), loss = 0.29446
I0628 20:00:00.401625  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:00:00.401625  1232 solver.cpp:237]     Train net output #1: loss = 0.29446 (* 1 = 0.29446 loss)
I0628 20:00:00.401625  1232 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0628 20:00:04.019915  1232 solver.cpp:218] Iteration 27200 (27.6405 iter/s, 3.61788s/100 iters), loss = 0.376714
I0628 20:00:04.019915  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:00:04.019915  1232 solver.cpp:237]     Train net output #1: loss = 0.376714 (* 1 = 0.376714 loss)
I0628 20:00:04.019915  1232 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0628 20:00:07.611488  1232 solver.cpp:218] Iteration 27300 (27.8474 iter/s, 3.591s/100 iters), loss = 0.319776
I0628 20:00:07.611488  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:00:07.611488  1232 solver.cpp:237]     Train net output #1: loss = 0.319777 (* 1 = 0.319777 loss)
I0628 20:00:07.611488  1232 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0628 20:00:11.195101  1232 solver.cpp:218] Iteration 27400 (27.9064 iter/s, 3.58341s/100 iters), loss = 0.253316
I0628 20:00:11.195101  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:00:11.195101  1232 solver.cpp:237]     Train net output #1: loss = 0.253316 (* 1 = 0.253316 loss)
I0628 20:00:11.195101  1232 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0628 20:00:14.608395 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:00:14.748502  1232 solver.cpp:330] Iteration 27500, Testing net (#0)
I0628 20:00:14.748502  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:00:15.563001 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:00:15.594525  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8274
I0628 20:00:15.594525  1232 solver.cpp:397]     Test net output #1: loss = 0.538596 (* 1 = 0.538596 loss)
I0628 20:00:15.628549  1232 solver.cpp:218] Iteration 27500 (22.5578 iter/s, 4.43305s/100 iters), loss = 0.189845
I0628 20:00:15.628549  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:00:15.628549  1232 solver.cpp:237]     Train net output #1: loss = 0.189846 (* 1 = 0.189846 loss)
I0628 20:00:15.628549  1232 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0628 20:00:19.219363  1232 solver.cpp:218] Iteration 27600 (27.8487 iter/s, 3.59083s/100 iters), loss = 0.210508
I0628 20:00:19.219363  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:00:19.219363  1232 solver.cpp:237]     Train net output #1: loss = 0.210508 (* 1 = 0.210508 loss)
I0628 20:00:19.219363  1232 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0628 20:00:22.806079  1232 solver.cpp:218] Iteration 27700 (27.8855 iter/s, 3.58609s/100 iters), loss = 0.2641
I0628 20:00:22.806079  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:00:22.806079  1232 solver.cpp:237]     Train net output #1: loss = 0.2641 (* 1 = 0.2641 loss)
I0628 20:00:22.806079  1232 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0628 20:00:26.407614  1232 solver.cpp:218] Iteration 27800 (27.7683 iter/s, 3.60122s/100 iters), loss = 0.281372
I0628 20:00:26.407614  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:00:26.407614  1232 solver.cpp:237]     Train net output #1: loss = 0.281373 (* 1 = 0.281373 loss)
I0628 20:00:26.407614  1232 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0628 20:00:29.993778  1232 solver.cpp:218] Iteration 27900 (27.8893 iter/s, 3.5856s/100 iters), loss = 0.261821
I0628 20:00:29.993778  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:00:29.993778  1232 solver.cpp:237]     Train net output #1: loss = 0.261822 (* 1 = 0.261822 loss)
I0628 20:00:29.993778  1232 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0628 20:00:33.419123 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:00:33.560061  1232 solver.cpp:330] Iteration 28000, Testing net (#0)
I0628 20:00:33.560061  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:00:34.374617 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:00:34.404680  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8284
I0628 20:00:34.405681  1232 solver.cpp:397]     Test net output #1: loss = 0.549937 (* 1 = 0.549937 loss)
I0628 20:00:34.441707  1232 solver.cpp:218] Iteration 28000 (22.4838 iter/s, 4.44766s/100 iters), loss = 0.209072
I0628 20:00:34.441707  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:00:34.441707  1232 solver.cpp:237]     Train net output #1: loss = 0.209072 (* 1 = 0.209072 loss)
I0628 20:00:34.441707  1232 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0628 20:00:38.037067  1232 solver.cpp:218] Iteration 28100 (27.8114 iter/s, 3.59564s/100 iters), loss = 0.242624
I0628 20:00:38.037067  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:00:38.037067  1232 solver.cpp:237]     Train net output #1: loss = 0.242624 (* 1 = 0.242624 loss)
I0628 20:00:38.037067  1232 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0628 20:00:41.629751  1232 solver.cpp:218] Iteration 28200 (27.8387 iter/s, 3.59212s/100 iters), loss = 0.379432
I0628 20:00:41.629751  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:00:41.629751  1232 solver.cpp:237]     Train net output #1: loss = 0.379433 (* 1 = 0.379433 loss)
I0628 20:00:41.629751  1232 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0628 20:00:45.223603  1232 solver.cpp:218] Iteration 28300 (27.8297 iter/s, 3.59328s/100 iters), loss = 0.350353
I0628 20:00:45.223603  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:00:45.223603  1232 solver.cpp:237]     Train net output #1: loss = 0.350353 (* 1 = 0.350353 loss)
I0628 20:00:45.223603  1232 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0628 20:00:48.815199  1232 solver.cpp:218] Iteration 28400 (27.8441 iter/s, 3.59142s/100 iters), loss = 0.278424
I0628 20:00:48.815199  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:00:48.815199  1232 solver.cpp:237]     Train net output #1: loss = 0.278425 (* 1 = 0.278425 loss)
I0628 20:00:48.815199  1232 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0628 20:00:52.231756 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:00:52.372586  1232 solver.cpp:330] Iteration 28500, Testing net (#0)
I0628 20:00:52.372586  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:00:53.183713 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:00:53.214738  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8365
I0628 20:00:53.214738  1232 solver.cpp:397]     Test net output #1: loss = 0.500982 (* 1 = 0.500982 loss)
I0628 20:00:53.248762  1232 solver.cpp:218] Iteration 28500 (22.5574 iter/s, 4.43314s/100 iters), loss = 0.315348
I0628 20:00:53.248762  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:00:53.248762  1232 solver.cpp:237]     Train net output #1: loss = 0.315349 (* 1 = 0.315349 loss)
I0628 20:00:53.248762  1232 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0628 20:00:56.839072  1232 solver.cpp:218] Iteration 28600 (27.8578 iter/s, 3.58966s/100 iters), loss = 0.350789
I0628 20:00:56.839072  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0628 20:00:56.839072  1232 solver.cpp:237]     Train net output #1: loss = 0.350789 (* 1 = 0.350789 loss)
I0628 20:00:56.839072  1232 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0628 20:01:00.432390  1232 solver.cpp:218] Iteration 28700 (27.8319 iter/s, 3.593s/100 iters), loss = 0.377223
I0628 20:01:00.432390  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:01:00.432390  1232 solver.cpp:237]     Train net output #1: loss = 0.377224 (* 1 = 0.377224 loss)
I0628 20:01:00.432390  1232 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I0628 20:01:04.015352  1232 solver.cpp:218] Iteration 28800 (27.9106 iter/s, 3.58287s/100 iters), loss = 0.317127
I0628 20:01:04.015352  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:01:04.015352  1232 solver.cpp:237]     Train net output #1: loss = 0.317127 (* 1 = 0.317127 loss)
I0628 20:01:04.015352  1232 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I0628 20:01:07.604352  1232 solver.cpp:218] Iteration 28900 (27.8674 iter/s, 3.58842s/100 iters), loss = 0.228048
I0628 20:01:07.604352  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:01:07.604352  1232 solver.cpp:237]     Train net output #1: loss = 0.228048 (* 1 = 0.228048 loss)
I0628 20:01:07.604352  1232 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I0628 20:01:11.019515 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:01:11.159617  1232 solver.cpp:330] Iteration 29000, Testing net (#0)
I0628 20:01:11.159617  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:01:11.979228 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:01:12.002748  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8306
I0628 20:01:12.002748  1232 solver.cpp:397]     Test net output #1: loss = 0.515368 (* 1 = 0.515368 loss)
I0628 20:01:12.036273  1232 solver.cpp:218] Iteration 29000 (22.5611 iter/s, 4.43241s/100 iters), loss = 0.237977
I0628 20:01:12.037273  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:01:12.037273  1232 solver.cpp:237]     Train net output #1: loss = 0.237977 (* 1 = 0.237977 loss)
I0628 20:01:12.037273  1232 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I0628 20:01:15.615942  1232 solver.cpp:218] Iteration 29100 (27.942 iter/s, 3.57884s/100 iters), loss = 0.300028
I0628 20:01:15.616442  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:01:15.616442  1232 solver.cpp:237]     Train net output #1: loss = 0.300029 (* 1 = 0.300029 loss)
I0628 20:01:15.616442  1232 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I0628 20:01:19.194602  1232 solver.cpp:218] Iteration 29200 (27.9464 iter/s, 3.57828s/100 iters), loss = 0.293698
I0628 20:01:19.194602  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:01:19.194602  1232 solver.cpp:237]     Train net output #1: loss = 0.293699 (* 1 = 0.293699 loss)
I0628 20:01:19.194602  1232 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I0628 20:01:22.789495  1232 solver.cpp:218] Iteration 29300 (27.8174 iter/s, 3.59487s/100 iters), loss = 0.297008
I0628 20:01:22.789495  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:01:22.789495  1232 solver.cpp:237]     Train net output #1: loss = 0.297009 (* 1 = 0.297009 loss)
I0628 20:01:22.789495  1232 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I0628 20:01:26.375177  1232 solver.cpp:218] Iteration 29400 (27.896 iter/s, 3.58475s/100 iters), loss = 0.26932
I0628 20:01:26.375177  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:01:26.375177  1232 solver.cpp:237]     Train net output #1: loss = 0.26932 (* 1 = 0.26932 loss)
I0628 20:01:26.375177  1232 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I0628 20:01:29.784593 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:01:29.925709  1232 solver.cpp:330] Iteration 29500, Testing net (#0)
I0628 20:01:29.925709  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:01:30.741487 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:01:30.771508  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8379
I0628 20:01:30.772509  1232 solver.cpp:397]     Test net output #1: loss = 0.507409 (* 1 = 0.507409 loss)
I0628 20:01:30.806533  1232 solver.cpp:218] Iteration 29500 (22.5677 iter/s, 4.43112s/100 iters), loss = 0.231712
I0628 20:01:30.806533  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:01:30.806533  1232 solver.cpp:237]     Train net output #1: loss = 0.231712 (* 1 = 0.231712 loss)
I0628 20:01:30.806533  1232 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I0628 20:01:34.388196  1232 solver.cpp:218] Iteration 29600 (27.9237 iter/s, 3.58119s/100 iters), loss = 0.344996
I0628 20:01:34.388196  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:01:34.388196  1232 solver.cpp:237]     Train net output #1: loss = 0.344996 (* 1 = 0.344996 loss)
I0628 20:01:34.388196  1232 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I0628 20:01:37.973096  1232 solver.cpp:218] Iteration 29700 (27.8944 iter/s, 3.58495s/100 iters), loss = 0.3325
I0628 20:01:37.973096  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:01:37.973096  1232 solver.cpp:237]     Train net output #1: loss = 0.332501 (* 1 = 0.332501 loss)
I0628 20:01:37.973096  1232 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I0628 20:01:41.574681  1232 solver.cpp:218] Iteration 29800 (27.7718 iter/s, 3.60078s/100 iters), loss = 0.292757
I0628 20:01:41.574681  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:01:41.574681  1232 solver.cpp:237]     Train net output #1: loss = 0.292757 (* 1 = 0.292757 loss)
I0628 20:01:41.574681  1232 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I0628 20:01:45.162209  1232 solver.cpp:218] Iteration 29900 (27.8731 iter/s, 3.58768s/100 iters), loss = 0.300689
I0628 20:01:45.162209  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:01:45.162209  1232 solver.cpp:237]     Train net output #1: loss = 0.30069 (* 1 = 0.30069 loss)
I0628 20:01:45.162209  1232 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I0628 20:01:48.574335 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:01:48.713973  1232 solver.cpp:330] Iteration 30000, Testing net (#0)
I0628 20:01:48.713973  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:01:49.530292 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:01:49.561034  1232 solver.cpp:397]     Test net output #0: accuracy = 0.812
I0628 20:01:49.561034  1232 solver.cpp:397]     Test net output #1: loss = 0.605655 (* 1 = 0.605655 loss)
I0628 20:01:49.595048  1232 solver.cpp:218] Iteration 30000 (22.5591 iter/s, 4.43281s/100 iters), loss = 0.204862
I0628 20:01:49.595048  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:01:49.595048  1232 solver.cpp:237]     Train net output #1: loss = 0.204862 (* 1 = 0.204862 loss)
I0628 20:01:49.595048  1232 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I0628 20:01:53.185664  1232 solver.cpp:218] Iteration 30100 (27.8557 iter/s, 3.58993s/100 iters), loss = 0.280947
I0628 20:01:53.185664  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:01:53.185664  1232 solver.cpp:237]     Train net output #1: loss = 0.280948 (* 1 = 0.280948 loss)
I0628 20:01:53.185664  1232 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I0628 20:01:56.780150  1232 solver.cpp:218] Iteration 30200 (27.8197 iter/s, 3.59457s/100 iters), loss = 0.307992
I0628 20:01:56.780150  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:01:56.781152  1232 solver.cpp:237]     Train net output #1: loss = 0.307992 (* 1 = 0.307992 loss)
I0628 20:01:56.781152  1232 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I0628 20:02:00.366953  1232 solver.cpp:218] Iteration 30300 (27.8888 iter/s, 3.58567s/100 iters), loss = 0.34175
I0628 20:02:00.366953  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:02:00.366953  1232 solver.cpp:237]     Train net output #1: loss = 0.34175 (* 1 = 0.34175 loss)
I0628 20:02:00.366953  1232 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I0628 20:02:03.948150  1232 solver.cpp:218] Iteration 30400 (27.9271 iter/s, 3.58075s/100 iters), loss = 0.226582
I0628 20:02:03.948150  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:02:03.948150  1232 solver.cpp:237]     Train net output #1: loss = 0.226582 (* 1 = 0.226582 loss)
I0628 20:02:03.948150  1232 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I0628 20:02:07.353098 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:02:07.493371  1232 solver.cpp:330] Iteration 30500, Testing net (#0)
I0628 20:02:07.493371  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:02:08.309284 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:02:08.341334  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8526
I0628 20:02:08.341334  1232 solver.cpp:397]     Test net output #1: loss = 0.457164 (* 1 = 0.457164 loss)
I0628 20:02:08.375464  1232 solver.cpp:218] Iteration 30500 (22.5854 iter/s, 4.42765s/100 iters), loss = 0.289742
I0628 20:02:08.375464  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:02:08.375464  1232 solver.cpp:237]     Train net output #1: loss = 0.289743 (* 1 = 0.289743 loss)
I0628 20:02:08.375464  1232 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I0628 20:02:11.968197  1232 solver.cpp:218] Iteration 30600 (27.8408 iter/s, 3.59186s/100 iters), loss = 0.291528
I0628 20:02:11.968197  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:02:11.968197  1232 solver.cpp:237]     Train net output #1: loss = 0.291528 (* 1 = 0.291528 loss)
I0628 20:02:11.968197  1232 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I0628 20:02:15.562320  1232 solver.cpp:218] Iteration 30700 (27.8256 iter/s, 3.59382s/100 iters), loss = 0.339236
I0628 20:02:15.562320  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0628 20:02:15.562320  1232 solver.cpp:237]     Train net output #1: loss = 0.339237 (* 1 = 0.339237 loss)
I0628 20:02:15.562320  1232 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I0628 20:02:19.152595  1232 solver.cpp:218] Iteration 30800 (27.8557 iter/s, 3.58993s/100 iters), loss = 0.300234
I0628 20:02:19.152595  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:02:19.152595  1232 solver.cpp:237]     Train net output #1: loss = 0.300234 (* 1 = 0.300234 loss)
I0628 20:02:19.152595  1232 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I0628 20:02:22.802500  1232 solver.cpp:218] Iteration 30900 (27.4015 iter/s, 3.64943s/100 iters), loss = 0.288631
I0628 20:02:22.802500  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:02:22.802500  1232 solver.cpp:237]     Train net output #1: loss = 0.288632 (* 1 = 0.288632 loss)
I0628 20:02:22.802500  1232 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I0628 20:02:26.195036 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:02:26.336141  1232 solver.cpp:330] Iteration 31000, Testing net (#0)
I0628 20:02:26.336141  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:02:27.146878 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:02:27.178169  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8417
I0628 20:02:27.178169  1232 solver.cpp:397]     Test net output #1: loss = 0.49235 (* 1 = 0.49235 loss)
I0628 20:02:27.213692  1232 solver.cpp:218] Iteration 31000 (22.6726 iter/s, 4.4106s/100 iters), loss = 0.253072
I0628 20:02:27.213692  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:02:27.213692  1232 solver.cpp:237]     Train net output #1: loss = 0.253072 (* 1 = 0.253072 loss)
I0628 20:02:27.213692  1232 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I0628 20:02:30.793180  1232 solver.cpp:218] Iteration 31100 (27.9357 iter/s, 3.57964s/100 iters), loss = 0.2819
I0628 20:02:30.793180  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0628 20:02:30.793180  1232 solver.cpp:237]     Train net output #1: loss = 0.2819 (* 1 = 0.2819 loss)
I0628 20:02:30.793180  1232 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I0628 20:02:34.365236  1232 solver.cpp:218] Iteration 31200 (28.0009 iter/s, 3.57131s/100 iters), loss = 0.366332
I0628 20:02:34.365236  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0628 20:02:34.365236  1232 solver.cpp:237]     Train net output #1: loss = 0.366333 (* 1 = 0.366333 loss)
I0628 20:02:34.365236  1232 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I0628 20:02:37.954593  1232 solver.cpp:218] Iteration 31300 (27.8639 iter/s, 3.58888s/100 iters), loss = 0.257718
I0628 20:02:37.954593  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:02:37.954593  1232 solver.cpp:237]     Train net output #1: loss = 0.257719 (* 1 = 0.257719 loss)
I0628 20:02:37.954593  1232 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I0628 20:02:41.540626  1232 solver.cpp:218] Iteration 31400 (27.8823 iter/s, 3.5865s/100 iters), loss = 0.23824
I0628 20:02:41.540626  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:02:41.541626  1232 solver.cpp:237]     Train net output #1: loss = 0.238241 (* 1 = 0.238241 loss)
I0628 20:02:41.541626  1232 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I0628 20:02:44.946048 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:02:45.086189  1232 solver.cpp:330] Iteration 31500, Testing net (#0)
I0628 20:02:45.086189  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:02:45.909155 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:02:45.940178  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8232
I0628 20:02:45.940178  1232 solver.cpp:397]     Test net output #1: loss = 0.571904 (* 1 = 0.571904 loss)
I0628 20:02:45.974205  1232 solver.cpp:218] Iteration 31500 (22.5615 iter/s, 4.43233s/100 iters), loss = 0.223081
I0628 20:02:45.974205  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:02:45.974205  1232 solver.cpp:237]     Train net output #1: loss = 0.223081 (* 1 = 0.223081 loss)
I0628 20:02:45.974205  1232 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I0628 20:02:49.544287  1232 solver.cpp:218] Iteration 31600 (28.0119 iter/s, 3.56991s/100 iters), loss = 0.350905
I0628 20:02:49.544287  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:02:49.544287  1232 solver.cpp:237]     Train net output #1: loss = 0.350905 (* 1 = 0.350905 loss)
I0628 20:02:49.544287  1232 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I0628 20:02:53.117321  1232 solver.cpp:218] Iteration 31700 (27.9862 iter/s, 3.57319s/100 iters), loss = 0.246307
I0628 20:02:53.117321  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:02:53.117321  1232 solver.cpp:237]     Train net output #1: loss = 0.246308 (* 1 = 0.246308 loss)
I0628 20:02:53.117321  1232 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I0628 20:02:56.687309  1232 solver.cpp:218] Iteration 31800 (28.0162 iter/s, 3.56936s/100 iters), loss = 0.28674
I0628 20:02:56.687309  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:02:56.687309  1232 solver.cpp:237]     Train net output #1: loss = 0.286741 (* 1 = 0.286741 loss)
I0628 20:02:56.687309  1232 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I0628 20:03:00.261142  1232 solver.cpp:218] Iteration 31900 (27.9828 iter/s, 3.57363s/100 iters), loss = 0.28914
I0628 20:03:00.261142  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0628 20:03:00.261142  1232 solver.cpp:237]     Train net output #1: loss = 0.289141 (* 1 = 0.289141 loss)
I0628 20:03:00.261142  1232 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I0628 20:03:03.661828 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:03:03.802999  1232 solver.cpp:330] Iteration 32000, Testing net (#0)
I0628 20:03:03.802999  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:03:04.614015 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:03:04.644037  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8451
I0628 20:03:04.644037  1232 solver.cpp:397]     Test net output #1: loss = 0.483834 (* 1 = 0.483834 loss)
I0628 20:03:04.678061  1232 solver.cpp:218] Iteration 32000 (22.6422 iter/s, 4.41653s/100 iters), loss = 0.204489
I0628 20:03:04.678061  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:03:04.678061  1232 solver.cpp:237]     Train net output #1: loss = 0.204489 (* 1 = 0.204489 loss)
I0628 20:03:04.678061  1232 sgd_solver.cpp:46] MultiStep Status: Iteration 32000, step = 1
I0628 20:03:04.678061  1232 sgd_solver.cpp:105] Iteration 32000, lr = 0.001
I0628 20:03:08.242380  1232 solver.cpp:218] Iteration 32100 (28.0589 iter/s, 3.56393s/100 iters), loss = 0.265393
I0628 20:03:08.242380  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:03:08.242380  1232 solver.cpp:237]     Train net output #1: loss = 0.265394 (* 1 = 0.265394 loss)
I0628 20:03:08.242380  1232 sgd_solver.cpp:105] Iteration 32100, lr = 0.001
I0628 20:03:11.808324  1232 solver.cpp:218] Iteration 32200 (28.0458 iter/s, 3.5656s/100 iters), loss = 0.238729
I0628 20:03:11.808825  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:03:11.808825  1232 solver.cpp:237]     Train net output #1: loss = 0.23873 (* 1 = 0.23873 loss)
I0628 20:03:11.808825  1232 sgd_solver.cpp:105] Iteration 32200, lr = 0.001
I0628 20:03:15.376623  1232 solver.cpp:218] Iteration 32300 (28.0257 iter/s, 3.56815s/100 iters), loss = 0.240319
I0628 20:03:15.376623  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:03:15.376623  1232 solver.cpp:237]     Train net output #1: loss = 0.24032 (* 1 = 0.24032 loss)
I0628 20:03:15.376623  1232 sgd_solver.cpp:105] Iteration 32300, lr = 0.001
I0628 20:03:18.944324  1232 solver.cpp:218] Iteration 32400 (28.0346 iter/s, 3.56702s/100 iters), loss = 0.173147
I0628 20:03:18.944324  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:03:18.944324  1232 solver.cpp:237]     Train net output #1: loss = 0.173147 (* 1 = 0.173147 loss)
I0628 20:03:18.944324  1232 sgd_solver.cpp:105] Iteration 32400, lr = 0.001
I0628 20:03:22.333377 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:03:22.472481  1232 solver.cpp:330] Iteration 32500, Testing net (#0)
I0628 20:03:22.472481  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:03:23.281371 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:03:23.312906  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8858
I0628 20:03:23.312906  1232 solver.cpp:397]     Test net output #1: loss = 0.3506 (* 1 = 0.3506 loss)
I0628 20:03:23.346422  1232 solver.cpp:218] Iteration 32500 (22.7165 iter/s, 4.40208s/100 iters), loss = 0.116607
I0628 20:03:23.346422  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:03:23.346422  1232 solver.cpp:237]     Train net output #1: loss = 0.116607 (* 1 = 0.116607 loss)
I0628 20:03:23.346422  1232 sgd_solver.cpp:105] Iteration 32500, lr = 0.001
I0628 20:03:26.928577  1232 solver.cpp:218] Iteration 32600 (27.9209 iter/s, 3.58154s/100 iters), loss = 0.266762
I0628 20:03:26.928577  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:03:26.928577  1232 solver.cpp:237]     Train net output #1: loss = 0.266762 (* 1 = 0.266762 loss)
I0628 20:03:26.929078  1232 sgd_solver.cpp:105] Iteration 32600, lr = 0.001
I0628 20:03:30.499256  1232 solver.cpp:218] Iteration 32700 (28.007 iter/s, 3.57053s/100 iters), loss = 0.263343
I0628 20:03:30.499256  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:03:30.499256  1232 solver.cpp:237]     Train net output #1: loss = 0.263344 (* 1 = 0.263344 loss)
I0628 20:03:30.499256  1232 sgd_solver.cpp:105] Iteration 32700, lr = 0.001
I0628 20:03:34.072912  1232 solver.cpp:218] Iteration 32800 (27.9895 iter/s, 3.57277s/100 iters), loss = 0.22236
I0628 20:03:34.072912  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:03:34.072912  1232 solver.cpp:237]     Train net output #1: loss = 0.222361 (* 1 = 0.222361 loss)
I0628 20:03:34.072912  1232 sgd_solver.cpp:105] Iteration 32800, lr = 0.001
I0628 20:03:37.644547  1232 solver.cpp:218] Iteration 32900 (27.9973 iter/s, 3.57177s/100 iters), loss = 0.134001
I0628 20:03:37.644547  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:03:37.644547  1232 solver.cpp:237]     Train net output #1: loss = 0.134001 (* 1 = 0.134001 loss)
I0628 20:03:37.644547  1232 sgd_solver.cpp:105] Iteration 32900, lr = 0.001
I0628 20:03:41.048681 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:03:41.188783  1232 solver.cpp:330] Iteration 33000, Testing net (#0)
I0628 20:03:41.188783  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:03:41.998385 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:03:42.029412  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8907
I0628 20:03:42.029412  1232 solver.cpp:397]     Test net output #1: loss = 0.341065 (* 1 = 0.341065 loss)
I0628 20:03:42.063434  1232 solver.cpp:218] Iteration 33000 (22.6345 iter/s, 4.41804s/100 iters), loss = 0.172658
I0628 20:03:42.063434  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:03:42.063434  1232 solver.cpp:237]     Train net output #1: loss = 0.172658 (* 1 = 0.172658 loss)
I0628 20:03:42.063434  1232 sgd_solver.cpp:105] Iteration 33000, lr = 0.001
I0628 20:03:45.644109  1232 solver.cpp:218] Iteration 33100 (27.9257 iter/s, 3.58092s/100 iters), loss = 0.162603
I0628 20:03:45.644109  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:03:45.644109  1232 solver.cpp:237]     Train net output #1: loss = 0.162604 (* 1 = 0.162604 loss)
I0628 20:03:45.644109  1232 sgd_solver.cpp:105] Iteration 33100, lr = 0.001
I0628 20:03:49.220687  1232 solver.cpp:218] Iteration 33200 (27.9626 iter/s, 3.57621s/100 iters), loss = 0.163866
I0628 20:03:49.220687  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:03:49.220687  1232 solver.cpp:237]     Train net output #1: loss = 0.163867 (* 1 = 0.163867 loss)
I0628 20:03:49.220687  1232 sgd_solver.cpp:105] Iteration 33200, lr = 0.001
I0628 20:03:52.820816  1232 solver.cpp:218] Iteration 33300 (27.7836 iter/s, 3.59925s/100 iters), loss = 0.174303
I0628 20:03:52.820816  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:03:52.820816  1232 solver.cpp:237]     Train net output #1: loss = 0.174303 (* 1 = 0.174303 loss)
I0628 20:03:52.820816  1232 sgd_solver.cpp:105] Iteration 33300, lr = 0.001
I0628 20:03:56.398362  1232 solver.cpp:218] Iteration 33400 (27.9518 iter/s, 3.57759s/100 iters), loss = 0.132841
I0628 20:03:56.398862  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:03:56.398862  1232 solver.cpp:237]     Train net output #1: loss = 0.132842 (* 1 = 0.132842 loss)
I0628 20:03:56.398862  1232 sgd_solver.cpp:105] Iteration 33400, lr = 0.001
I0628 20:03:59.799366 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:03:59.938469  1232 solver.cpp:330] Iteration 33500, Testing net (#0)
I0628 20:03:59.938469  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:04:00.749712 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:04:00.780743  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8908
I0628 20:04:00.780743  1232 solver.cpp:397]     Test net output #1: loss = 0.341683 (* 1 = 0.341683 loss)
I0628 20:04:00.814260  1232 solver.cpp:218] Iteration 33500 (22.6448 iter/s, 4.41603s/100 iters), loss = 0.138452
I0628 20:04:00.814260  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:04:00.815261  1232 solver.cpp:237]     Train net output #1: loss = 0.138453 (* 1 = 0.138453 loss)
I0628 20:04:00.815261  1232 sgd_solver.cpp:105] Iteration 33500, lr = 0.001
I0628 20:04:04.390919  1232 solver.cpp:218] Iteration 33600 (27.9667 iter/s, 3.57569s/100 iters), loss = 0.214423
I0628 20:04:04.390919  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:04:04.390919  1232 solver.cpp:237]     Train net output #1: loss = 0.214424 (* 1 = 0.214424 loss)
I0628 20:04:04.390919  1232 sgd_solver.cpp:105] Iteration 33600, lr = 0.001
I0628 20:04:07.994737  1232 solver.cpp:218] Iteration 33700 (27.7476 iter/s, 3.60392s/100 iters), loss = 0.201889
I0628 20:04:07.994737  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:04:07.994737  1232 solver.cpp:237]     Train net output #1: loss = 0.201889 (* 1 = 0.201889 loss)
I0628 20:04:07.994737  1232 sgd_solver.cpp:105] Iteration 33700, lr = 0.001
I0628 20:04:11.584345  1232 solver.cpp:218] Iteration 33800 (27.864 iter/s, 3.58887s/100 iters), loss = 0.204933
I0628 20:04:11.584345  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:04:11.584345  1232 solver.cpp:237]     Train net output #1: loss = 0.204933 (* 1 = 0.204933 loss)
I0628 20:04:11.584345  1232 sgd_solver.cpp:105] Iteration 33800, lr = 0.001
I0628 20:04:15.160082  1232 solver.cpp:218] Iteration 33900 (27.9717 iter/s, 3.57504s/100 iters), loss = 0.117818
I0628 20:04:15.160082  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:04:15.160082  1232 solver.cpp:237]     Train net output #1: loss = 0.117819 (* 1 = 0.117819 loss)
I0628 20:04:15.160082  1232 sgd_solver.cpp:105] Iteration 33900, lr = 0.001
I0628 20:04:18.559381 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:04:18.698078  1232 solver.cpp:330] Iteration 34000, Testing net (#0)
I0628 20:04:18.698078  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:04:19.510246 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:04:19.540776  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 20:04:19.540776  1232 solver.cpp:397]     Test net output #1: loss = 0.344151 (* 1 = 0.344151 loss)
I0628 20:04:19.574923  1232 solver.cpp:218] Iteration 34000 (22.6524 iter/s, 4.41454s/100 iters), loss = 0.233538
I0628 20:04:19.574923  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:04:19.574923  1232 solver.cpp:237]     Train net output #1: loss = 0.233539 (* 1 = 0.233539 loss)
I0628 20:04:19.574923  1232 sgd_solver.cpp:105] Iteration 34000, lr = 0.001
I0628 20:04:23.140846  1232 solver.cpp:218] Iteration 34100 (28.0453 iter/s, 3.56566s/100 iters), loss = 0.201534
I0628 20:04:23.140846  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:04:23.140846  1232 solver.cpp:237]     Train net output #1: loss = 0.201535 (* 1 = 0.201535 loss)
I0628 20:04:23.140846  1232 sgd_solver.cpp:105] Iteration 34100, lr = 0.001
I0628 20:04:26.724766  1232 solver.cpp:218] Iteration 34200 (27.9004 iter/s, 3.58418s/100 iters), loss = 0.172695
I0628 20:04:26.724766  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:04:26.724766  1232 solver.cpp:237]     Train net output #1: loss = 0.172695 (* 1 = 0.172695 loss)
I0628 20:04:26.724766  1232 sgd_solver.cpp:105] Iteration 34200, lr = 0.001
I0628 20:04:30.292918  1232 solver.cpp:218] Iteration 34300 (28.0281 iter/s, 3.56785s/100 iters), loss = 0.190671
I0628 20:04:30.292918  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:04:30.292918  1232 solver.cpp:237]     Train net output #1: loss = 0.190671 (* 1 = 0.190671 loss)
I0628 20:04:30.292918  1232 sgd_solver.cpp:105] Iteration 34300, lr = 0.001
I0628 20:04:33.864380  1232 solver.cpp:218] Iteration 34400 (28.0029 iter/s, 3.57106s/100 iters), loss = 0.133254
I0628 20:04:33.864380  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:04:33.864380  1232 solver.cpp:237]     Train net output #1: loss = 0.133255 (* 1 = 0.133255 loss)
I0628 20:04:33.864380  1232 sgd_solver.cpp:105] Iteration 34400, lr = 0.001
I0628 20:04:37.259421 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:04:37.403028  1232 solver.cpp:330] Iteration 34500, Testing net (#0)
I0628 20:04:37.403028  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:04:38.211685 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:04:38.242707  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0628 20:04:38.242707  1232 solver.cpp:397]     Test net output #1: loss = 0.342031 (* 1 = 0.342031 loss)
I0628 20:04:38.276733  1232 solver.cpp:218] Iteration 34500 (22.6695 iter/s, 4.41122s/100 iters), loss = 0.139763
I0628 20:04:38.276733  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:04:38.276733  1232 solver.cpp:237]     Train net output #1: loss = 0.139763 (* 1 = 0.139763 loss)
I0628 20:04:38.276733  1232 sgd_solver.cpp:105] Iteration 34500, lr = 0.001
I0628 20:04:41.853278  1232 solver.cpp:218] Iteration 34600 (27.9595 iter/s, 3.5766s/100 iters), loss = 0.213017
I0628 20:04:41.853778  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:04:41.853778  1232 solver.cpp:237]     Train net output #1: loss = 0.213017 (* 1 = 0.213017 loss)
I0628 20:04:41.853778  1232 sgd_solver.cpp:105] Iteration 34600, lr = 0.001
I0628 20:04:45.424942  1232 solver.cpp:218] Iteration 34700 (28.0015 iter/s, 3.57123s/100 iters), loss = 0.21663
I0628 20:04:45.424942  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:04:45.424942  1232 solver.cpp:237]     Train net output #1: loss = 0.216631 (* 1 = 0.216631 loss)
I0628 20:04:45.424942  1232 sgd_solver.cpp:105] Iteration 34700, lr = 0.001
I0628 20:04:49.011780  1232 solver.cpp:218] Iteration 34800 (27.8804 iter/s, 3.58674s/100 iters), loss = 0.18312
I0628 20:04:49.011780  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:04:49.011780  1232 solver.cpp:237]     Train net output #1: loss = 0.183121 (* 1 = 0.183121 loss)
I0628 20:04:49.011780  1232 sgd_solver.cpp:105] Iteration 34800, lr = 0.001
I0628 20:04:52.589722  1232 solver.cpp:218] Iteration 34900 (27.9526 iter/s, 3.57748s/100 iters), loss = 0.0891949
I0628 20:04:52.589722  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:04:52.589722  1232 solver.cpp:237]     Train net output #1: loss = 0.0891955 (* 1 = 0.0891955 loss)
I0628 20:04:52.589722  1232 sgd_solver.cpp:105] Iteration 34900, lr = 0.001
I0628 20:04:55.994168 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:04:56.134292  1232 solver.cpp:330] Iteration 35000, Testing net (#0)
I0628 20:04:56.134292  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:04:56.947631 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:04:56.978685  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8916
I0628 20:04:56.978685  1232 solver.cpp:397]     Test net output #1: loss = 0.34344 (* 1 = 0.34344 loss)
I0628 20:04:57.012722  1232 solver.cpp:218] Iteration 35000 (22.6136 iter/s, 4.42211s/100 iters), loss = 0.106344
I0628 20:04:57.012722  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:04:57.012722  1232 solver.cpp:237]     Train net output #1: loss = 0.106345 (* 1 = 0.106345 loss)
I0628 20:04:57.012722  1232 sgd_solver.cpp:105] Iteration 35000, lr = 0.001
I0628 20:05:00.595425  1232 solver.cpp:218] Iteration 35100 (27.9139 iter/s, 3.58244s/100 iters), loss = 0.174619
I0628 20:05:00.595425  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:05:00.595425  1232 solver.cpp:237]     Train net output #1: loss = 0.17462 (* 1 = 0.17462 loss)
I0628 20:05:00.595425  1232 sgd_solver.cpp:105] Iteration 35100, lr = 0.001
I0628 20:05:04.175055  1232 solver.cpp:218] Iteration 35200 (27.9365 iter/s, 3.57955s/100 iters), loss = 0.212837
I0628 20:05:04.175055  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:05:04.175055  1232 solver.cpp:237]     Train net output #1: loss = 0.212837 (* 1 = 0.212837 loss)
I0628 20:05:04.175055  1232 sgd_solver.cpp:105] Iteration 35200, lr = 0.001
I0628 20:05:07.751528  1232 solver.cpp:218] Iteration 35300 (27.9615 iter/s, 3.57635s/100 iters), loss = 0.207893
I0628 20:05:07.751528  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:05:07.751528  1232 solver.cpp:237]     Train net output #1: loss = 0.207893 (* 1 = 0.207893 loss)
I0628 20:05:07.751528  1232 sgd_solver.cpp:105] Iteration 35300, lr = 0.001
I0628 20:05:11.326318  1232 solver.cpp:218] Iteration 35400 (27.9787 iter/s, 3.57414s/100 iters), loss = 0.095889
I0628 20:05:11.326318  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:05:11.326318  1232 solver.cpp:237]     Train net output #1: loss = 0.0958897 (* 1 = 0.0958897 loss)
I0628 20:05:11.326318  1232 sgd_solver.cpp:105] Iteration 35400, lr = 0.001
I0628 20:05:14.726287 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:05:14.866940  1232 solver.cpp:330] Iteration 35500, Testing net (#0)
I0628 20:05:14.866940  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:05:15.684592 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:05:15.714653  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 20:05:15.714653  1232 solver.cpp:397]     Test net output #1: loss = 0.343414 (* 1 = 0.343414 loss)
I0628 20:05:15.749680  1232 solver.cpp:218] Iteration 35500 (22.6101 iter/s, 4.4228s/100 iters), loss = 0.150075
I0628 20:05:15.749680  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:05:15.749680  1232 solver.cpp:237]     Train net output #1: loss = 0.150076 (* 1 = 0.150076 loss)
I0628 20:05:15.749680  1232 sgd_solver.cpp:105] Iteration 35500, lr = 0.001
I0628 20:05:19.341858  1232 solver.cpp:218] Iteration 35600 (27.8392 iter/s, 3.59206s/100 iters), loss = 0.235737
I0628 20:05:19.341858  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:05:19.341858  1232 solver.cpp:237]     Train net output #1: loss = 0.235738 (* 1 = 0.235738 loss)
I0628 20:05:19.341858  1232 sgd_solver.cpp:105] Iteration 35600, lr = 0.001
I0628 20:05:22.915619  1232 solver.cpp:218] Iteration 35700 (27.9867 iter/s, 3.57313s/100 iters), loss = 0.19855
I0628 20:05:22.915619  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:05:22.915619  1232 solver.cpp:237]     Train net output #1: loss = 0.198551 (* 1 = 0.198551 loss)
I0628 20:05:22.915619  1232 sgd_solver.cpp:105] Iteration 35700, lr = 0.001
I0628 20:05:26.495260  1232 solver.cpp:218] Iteration 35800 (27.938 iter/s, 3.57935s/100 iters), loss = 0.184167
I0628 20:05:26.495260  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:05:26.495260  1232 solver.cpp:237]     Train net output #1: loss = 0.184168 (* 1 = 0.184168 loss)
I0628 20:05:26.495260  1232 sgd_solver.cpp:105] Iteration 35800, lr = 0.001
I0628 20:05:30.093924  1232 solver.cpp:218] Iteration 35900 (27.7908 iter/s, 3.59831s/100 iters), loss = 0.120204
I0628 20:05:30.093924  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:05:30.093924  1232 solver.cpp:237]     Train net output #1: loss = 0.120205 (* 1 = 0.120205 loss)
I0628 20:05:30.093924  1232 sgd_solver.cpp:105] Iteration 35900, lr = 0.001
I0628 20:05:33.508559 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:05:33.649159  1232 solver.cpp:330] Iteration 36000, Testing net (#0)
I0628 20:05:33.649159  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:05:34.465765 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:05:34.492285  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8913
I0628 20:05:34.493286  1232 solver.cpp:397]     Test net output #1: loss = 0.347761 (* 1 = 0.347761 loss)
I0628 20:05:34.526309  1232 solver.cpp:218] Iteration 36000 (22.5589 iter/s, 4.43284s/100 iters), loss = 0.146605
I0628 20:05:34.526309  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:05:34.526309  1232 solver.cpp:237]     Train net output #1: loss = 0.146606 (* 1 = 0.146606 loss)
I0628 20:05:34.526309  1232 sgd_solver.cpp:105] Iteration 36000, lr = 0.001
I0628 20:05:38.110677  1232 solver.cpp:218] Iteration 36100 (27.903 iter/s, 3.58385s/100 iters), loss = 0.194402
I0628 20:05:38.110677  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:05:38.110677  1232 solver.cpp:237]     Train net output #1: loss = 0.194402 (* 1 = 0.194402 loss)
I0628 20:05:38.110677  1232 sgd_solver.cpp:105] Iteration 36100, lr = 0.001
I0628 20:05:41.688336  1232 solver.cpp:218] Iteration 36200 (27.9518 iter/s, 3.57759s/100 iters), loss = 0.21394
I0628 20:05:41.689337  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:05:41.689337  1232 solver.cpp:237]     Train net output #1: loss = 0.213941 (* 1 = 0.213941 loss)
I0628 20:05:41.689337  1232 sgd_solver.cpp:105] Iteration 36200, lr = 0.001
I0628 20:05:45.270998  1232 solver.cpp:218] Iteration 36300 (27.9224 iter/s, 3.58135s/100 iters), loss = 0.149719
I0628 20:05:45.270998  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:05:45.270998  1232 solver.cpp:237]     Train net output #1: loss = 0.14972 (* 1 = 0.14972 loss)
I0628 20:05:45.270998  1232 sgd_solver.cpp:105] Iteration 36300, lr = 0.001
I0628 20:05:48.851683  1232 solver.cpp:218] Iteration 36400 (27.9273 iter/s, 3.58072s/100 iters), loss = 0.119802
I0628 20:05:48.851683  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:05:48.851683  1232 solver.cpp:237]     Train net output #1: loss = 0.119802 (* 1 = 0.119802 loss)
I0628 20:05:48.851683  1232 sgd_solver.cpp:105] Iteration 36400, lr = 0.001
I0628 20:05:52.255323 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:05:52.395429  1232 solver.cpp:330] Iteration 36500, Testing net (#0)
I0628 20:05:52.395429  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:05:53.204924 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:05:53.235946  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8916
I0628 20:05:53.235946  1232 solver.cpp:397]     Test net output #1: loss = 0.349417 (* 1 = 0.349417 loss)
I0628 20:05:53.269971  1232 solver.cpp:218] Iteration 36500 (22.6351 iter/s, 4.41791s/100 iters), loss = 0.112473
I0628 20:05:53.269971  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:05:53.269971  1232 solver.cpp:237]     Train net output #1: loss = 0.112473 (* 1 = 0.112473 loss)
I0628 20:05:53.269971  1232 sgd_solver.cpp:105] Iteration 36500, lr = 0.001
I0628 20:05:56.854205  1232 solver.cpp:218] Iteration 36600 (27.9002 iter/s, 3.58421s/100 iters), loss = 0.14262
I0628 20:05:56.854205  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:05:56.854205  1232 solver.cpp:237]     Train net output #1: loss = 0.142621 (* 1 = 0.142621 loss)
I0628 20:05:56.854205  1232 sgd_solver.cpp:105] Iteration 36600, lr = 0.001
I0628 20:06:00.431375  1232 solver.cpp:218] Iteration 36700 (27.9583 iter/s, 3.57675s/100 iters), loss = 0.166292
I0628 20:06:00.431375  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:06:00.431375  1232 solver.cpp:237]     Train net output #1: loss = 0.166292 (* 1 = 0.166292 loss)
I0628 20:06:00.431375  1232 sgd_solver.cpp:105] Iteration 36700, lr = 0.001
I0628 20:06:04.029060  1232 solver.cpp:218] Iteration 36800 (27.7982 iter/s, 3.59736s/100 iters), loss = 0.111164
I0628 20:06:04.029060  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:06:04.029060  1232 solver.cpp:237]     Train net output #1: loss = 0.111165 (* 1 = 0.111165 loss)
I0628 20:06:04.029060  1232 sgd_solver.cpp:105] Iteration 36800, lr = 0.001
I0628 20:06:07.615824  1232 solver.cpp:218] Iteration 36900 (27.8829 iter/s, 3.58643s/100 iters), loss = 0.0807334
I0628 20:06:07.615824  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:06:07.615824  1232 solver.cpp:237]     Train net output #1: loss = 0.0807342 (* 1 = 0.0807342 loss)
I0628 20:06:07.615824  1232 sgd_solver.cpp:105] Iteration 36900, lr = 0.001
I0628 20:06:11.024390 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:06:11.163491  1232 solver.cpp:330] Iteration 37000, Testing net (#0)
I0628 20:06:11.163491  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:06:11.977125 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:06:12.008150  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 20:06:12.008150  1232 solver.cpp:397]     Test net output #1: loss = 0.348403 (* 1 = 0.348403 loss)
I0628 20:06:12.043175  1232 solver.cpp:218] Iteration 37000 (22.5915 iter/s, 4.42645s/100 iters), loss = 0.124789
I0628 20:06:12.043175  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:06:12.043175  1232 solver.cpp:237]     Train net output #1: loss = 0.124789 (* 1 = 0.124789 loss)
I0628 20:06:12.043175  1232 sgd_solver.cpp:105] Iteration 37000, lr = 0.001
I0628 20:06:15.614835  1232 solver.cpp:218] Iteration 37100 (27.9946 iter/s, 3.57212s/100 iters), loss = 0.182715
I0628 20:06:15.614835  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:06:15.614835  1232 solver.cpp:237]     Train net output #1: loss = 0.182716 (* 1 = 0.182716 loss)
I0628 20:06:15.614835  1232 sgd_solver.cpp:105] Iteration 37100, lr = 0.001
I0628 20:06:19.193827  1232 solver.cpp:218] Iteration 37200 (27.9505 iter/s, 3.57775s/100 iters), loss = 0.163975
I0628 20:06:19.193827  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:06:19.193827  1232 solver.cpp:237]     Train net output #1: loss = 0.163976 (* 1 = 0.163976 loss)
I0628 20:06:19.193827  1232 sgd_solver.cpp:105] Iteration 37200, lr = 0.001
I0628 20:06:22.777846  1232 solver.cpp:218] Iteration 37300 (27.9037 iter/s, 3.58376s/100 iters), loss = 0.18209
I0628 20:06:22.777846  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:06:22.777846  1232 solver.cpp:237]     Train net output #1: loss = 0.182091 (* 1 = 0.182091 loss)
I0628 20:06:22.777846  1232 sgd_solver.cpp:105] Iteration 37300, lr = 0.001
I0628 20:06:26.359516  1232 solver.cpp:218] Iteration 37400 (27.9205 iter/s, 3.5816s/100 iters), loss = 0.129112
I0628 20:06:26.359516  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:06:26.359516  1232 solver.cpp:237]     Train net output #1: loss = 0.129113 (* 1 = 0.129113 loss)
I0628 20:06:26.359516  1232 sgd_solver.cpp:105] Iteration 37400, lr = 0.001
I0628 20:06:29.757046 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:06:29.896648  1232 solver.cpp:330] Iteration 37500, Testing net (#0)
I0628 20:06:29.896648  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:06:30.706817 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:06:30.737840  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8928
I0628 20:06:30.737840  1232 solver.cpp:397]     Test net output #1: loss = 0.34826 (* 1 = 0.34826 loss)
I0628 20:06:30.770864  1232 solver.cpp:218] Iteration 37500 (22.6708 iter/s, 4.41097s/100 iters), loss = 0.153188
I0628 20:06:30.770864  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:06:30.770864  1232 solver.cpp:237]     Train net output #1: loss = 0.153189 (* 1 = 0.153189 loss)
I0628 20:06:30.770864  1232 sgd_solver.cpp:105] Iteration 37500, lr = 0.001
I0628 20:06:34.351544  1232 solver.cpp:218] Iteration 37600 (27.9291 iter/s, 3.58049s/100 iters), loss = 0.237011
I0628 20:06:34.351544  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:06:34.351544  1232 solver.cpp:237]     Train net output #1: loss = 0.237012 (* 1 = 0.237012 loss)
I0628 20:06:34.351544  1232 sgd_solver.cpp:105] Iteration 37600, lr = 0.001
I0628 20:06:37.931084  1232 solver.cpp:218] Iteration 37700 (27.9385 iter/s, 3.57928s/100 iters), loss = 0.229491
I0628 20:06:37.932085  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:06:37.932085  1232 solver.cpp:237]     Train net output #1: loss = 0.229492 (* 1 = 0.229492 loss)
I0628 20:06:37.932085  1232 sgd_solver.cpp:105] Iteration 37700, lr = 0.001
I0628 20:06:41.509255  1232 solver.cpp:218] Iteration 37800 (27.954 iter/s, 3.5773s/100 iters), loss = 0.135475
I0628 20:06:41.509757  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:06:41.509757  1232 solver.cpp:237]     Train net output #1: loss = 0.135476 (* 1 = 0.135476 loss)
I0628 20:06:41.509757  1232 sgd_solver.cpp:105] Iteration 37800, lr = 0.001
I0628 20:06:45.089625  1232 solver.cpp:218] Iteration 37900 (27.9294 iter/s, 3.58046s/100 iters), loss = 0.0582111
I0628 20:06:45.089625  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:06:45.089625  1232 solver.cpp:237]     Train net output #1: loss = 0.0582118 (* 1 = 0.0582118 loss)
I0628 20:06:45.089625  1232 sgd_solver.cpp:105] Iteration 37900, lr = 0.001
I0628 20:06:48.495172 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:06:48.635275  1232 solver.cpp:330] Iteration 38000, Testing net (#0)
I0628 20:06:48.635776  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:06:49.446135 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:06:49.476658  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8916
I0628 20:06:49.476658  1232 solver.cpp:397]     Test net output #1: loss = 0.34762 (* 1 = 0.34762 loss)
I0628 20:06:49.510682  1232 solver.cpp:218] Iteration 38000 (22.624 iter/s, 4.42008s/100 iters), loss = 0.102164
I0628 20:06:49.510682  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:06:49.510682  1232 solver.cpp:237]     Train net output #1: loss = 0.102165 (* 1 = 0.102165 loss)
I0628 20:06:49.510682  1232 sgd_solver.cpp:105] Iteration 38000, lr = 0.001
I0628 20:06:53.079334  1232 solver.cpp:218] Iteration 38100 (28.0191 iter/s, 3.569s/100 iters), loss = 0.226828
I0628 20:06:53.079334  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:06:53.079334  1232 solver.cpp:237]     Train net output #1: loss = 0.226829 (* 1 = 0.226829 loss)
I0628 20:06:53.079334  1232 sgd_solver.cpp:105] Iteration 38100, lr = 0.001
I0628 20:06:56.658574  1232 solver.cpp:218] Iteration 38200 (27.9464 iter/s, 3.57828s/100 iters), loss = 0.136556
I0628 20:06:56.658574  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:06:56.658574  1232 solver.cpp:237]     Train net output #1: loss = 0.136557 (* 1 = 0.136557 loss)
I0628 20:06:56.658574  1232 sgd_solver.cpp:105] Iteration 38200, lr = 0.001
I0628 20:07:00.230761  1232 solver.cpp:218] Iteration 38300 (27.9949 iter/s, 3.57208s/100 iters), loss = 0.139185
I0628 20:07:00.230761  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:07:00.230761  1232 solver.cpp:237]     Train net output #1: loss = 0.139186 (* 1 = 0.139186 loss)
I0628 20:07:00.230761  1232 sgd_solver.cpp:105] Iteration 38300, lr = 0.001
I0628 20:07:03.801424  1232 solver.cpp:218] Iteration 38400 (28.0104 iter/s, 3.5701s/100 iters), loss = 0.0880903
I0628 20:07:03.801424  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:07:03.801424  1232 solver.cpp:237]     Train net output #1: loss = 0.088091 (* 1 = 0.088091 loss)
I0628 20:07:03.801424  1232 sgd_solver.cpp:105] Iteration 38400, lr = 0.001
I0628 20:07:07.200949 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:07:07.342052  1232 solver.cpp:330] Iteration 38500, Testing net (#0)
I0628 20:07:07.342052  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:07:08.154474 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:07:08.185022  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8889
I0628 20:07:08.185022  1232 solver.cpp:397]     Test net output #1: loss = 0.353389 (* 1 = 0.353389 loss)
I0628 20:07:08.219048  1232 solver.cpp:218] Iteration 38500 (22.6361 iter/s, 4.41773s/100 iters), loss = 0.144571
I0628 20:07:08.219048  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:07:08.219048  1232 solver.cpp:237]     Train net output #1: loss = 0.144572 (* 1 = 0.144572 loss)
I0628 20:07:08.219048  1232 sgd_solver.cpp:105] Iteration 38500, lr = 0.001
I0628 20:07:11.793300  1232 solver.cpp:218] Iteration 38600 (27.9851 iter/s, 3.57333s/100 iters), loss = 0.219565
I0628 20:07:11.793300  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:07:11.793300  1232 solver.cpp:237]     Train net output #1: loss = 0.219566 (* 1 = 0.219566 loss)
I0628 20:07:11.793300  1232 sgd_solver.cpp:105] Iteration 38600, lr = 0.001
I0628 20:07:15.365952  1232 solver.cpp:218] Iteration 38700 (27.9913 iter/s, 3.57254s/100 iters), loss = 0.198213
I0628 20:07:15.365952  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:07:15.365952  1232 solver.cpp:237]     Train net output #1: loss = 0.198214 (* 1 = 0.198214 loss)
I0628 20:07:15.365952  1232 sgd_solver.cpp:105] Iteration 38700, lr = 0.001
I0628 20:07:18.933439  1232 solver.cpp:218] Iteration 38800 (28.0351 iter/s, 3.56695s/100 iters), loss = 0.11909
I0628 20:07:18.933439  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:07:18.933439  1232 solver.cpp:237]     Train net output #1: loss = 0.119091 (* 1 = 0.119091 loss)
I0628 20:07:18.933439  1232 sgd_solver.cpp:105] Iteration 38800, lr = 0.001
I0628 20:07:22.507089  1232 solver.cpp:218] Iteration 38900 (27.9805 iter/s, 3.57391s/100 iters), loss = 0.10207
I0628 20:07:22.507089  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:07:22.507089  1232 solver.cpp:237]     Train net output #1: loss = 0.102071 (* 1 = 0.102071 loss)
I0628 20:07:22.507089  1232 sgd_solver.cpp:105] Iteration 38900, lr = 0.001
I0628 20:07:25.904865 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:07:26.045013  1232 solver.cpp:330] Iteration 39000, Testing net (#0)
I0628 20:07:26.045013  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:07:26.861937 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:07:26.892990  1232 solver.cpp:397]     Test net output #0: accuracy = 0.889
I0628 20:07:26.892990  1232 solver.cpp:397]     Test net output #1: loss = 0.358591 (* 1 = 0.358591 loss)
I0628 20:07:26.926009  1232 solver.cpp:218] Iteration 39000 (22.6313 iter/s, 4.41865s/100 iters), loss = 0.156293
I0628 20:07:26.926009  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:07:26.926009  1232 solver.cpp:237]     Train net output #1: loss = 0.156294 (* 1 = 0.156294 loss)
I0628 20:07:26.926009  1232 sgd_solver.cpp:105] Iteration 39000, lr = 0.001
I0628 20:07:30.503947  1232 solver.cpp:218] Iteration 39100 (27.9521 iter/s, 3.57755s/100 iters), loss = 0.240493
I0628 20:07:30.503947  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:07:30.503947  1232 solver.cpp:237]     Train net output #1: loss = 0.240494 (* 1 = 0.240494 loss)
I0628 20:07:30.503947  1232 sgd_solver.cpp:105] Iteration 39100, lr = 0.001
I0628 20:07:34.087278  1232 solver.cpp:218] Iteration 39200 (27.9143 iter/s, 3.58239s/100 iters), loss = 0.20222
I0628 20:07:34.087278  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:07:34.087278  1232 solver.cpp:237]     Train net output #1: loss = 0.202221 (* 1 = 0.202221 loss)
I0628 20:07:34.087278  1232 sgd_solver.cpp:105] Iteration 39200, lr = 0.001
I0628 20:07:37.661710  1232 solver.cpp:218] Iteration 39300 (27.9749 iter/s, 3.57463s/100 iters), loss = 0.195873
I0628 20:07:37.661710  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:07:37.661710  1232 solver.cpp:237]     Train net output #1: loss = 0.195874 (* 1 = 0.195874 loss)
I0628 20:07:37.661710  1232 sgd_solver.cpp:105] Iteration 39300, lr = 0.001
I0628 20:07:41.251648  1232 solver.cpp:218] Iteration 39400 (27.8613 iter/s, 3.58921s/100 iters), loss = 0.107509
I0628 20:07:41.251648  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:07:41.251648  1232 solver.cpp:237]     Train net output #1: loss = 0.10751 (* 1 = 0.10751 loss)
I0628 20:07:41.251648  1232 sgd_solver.cpp:105] Iteration 39400, lr = 0.001
I0628 20:07:44.660120 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:07:44.800282  1232 solver.cpp:330] Iteration 39500, Testing net (#0)
I0628 20:07:44.800282  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:07:45.612476 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:07:45.643496  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8921
I0628 20:07:45.643496  1232 solver.cpp:397]     Test net output #1: loss = 0.35547 (* 1 = 0.35547 loss)
I0628 20:07:45.677552  1232 solver.cpp:218] Iteration 39500 (22.5938 iter/s, 4.426s/100 iters), loss = 0.112205
I0628 20:07:45.677552  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:07:45.677552  1232 solver.cpp:237]     Train net output #1: loss = 0.112206 (* 1 = 0.112206 loss)
I0628 20:07:45.677552  1232 sgd_solver.cpp:105] Iteration 39500, lr = 0.001
I0628 20:07:49.258813  1232 solver.cpp:218] Iteration 39600 (27.9306 iter/s, 3.5803s/100 iters), loss = 0.169343
I0628 20:07:49.258813  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:07:49.258813  1232 solver.cpp:237]     Train net output #1: loss = 0.169344 (* 1 = 0.169344 loss)
I0628 20:07:49.258813  1232 sgd_solver.cpp:105] Iteration 39600, lr = 0.001
I0628 20:07:52.844255  1232 solver.cpp:218] Iteration 39700 (27.8872 iter/s, 3.58588s/100 iters), loss = 0.179849
I0628 20:07:52.845257  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:07:52.845257  1232 solver.cpp:237]     Train net output #1: loss = 0.179849 (* 1 = 0.179849 loss)
I0628 20:07:52.845257  1232 sgd_solver.cpp:105] Iteration 39700, lr = 0.001
I0628 20:07:56.432492  1232 solver.cpp:218] Iteration 39800 (27.8724 iter/s, 3.58778s/100 iters), loss = 0.19233
I0628 20:07:56.432492  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:07:56.432492  1232 solver.cpp:237]     Train net output #1: loss = 0.192331 (* 1 = 0.192331 loss)
I0628 20:07:56.432492  1232 sgd_solver.cpp:105] Iteration 39800, lr = 0.001
I0628 20:08:00.002341  1232 solver.cpp:218] Iteration 39900 (28.0151 iter/s, 3.5695s/100 iters), loss = 0.0969247
I0628 20:08:00.002341  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:08:00.002341  1232 solver.cpp:237]     Train net output #1: loss = 0.0969255 (* 1 = 0.0969255 loss)
I0628 20:08:00.002341  1232 sgd_solver.cpp:105] Iteration 39900, lr = 0.001
I0628 20:08:03.399701 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:08:03.539804  1232 solver.cpp:330] Iteration 40000, Testing net (#0)
I0628 20:08:03.539804  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:08:04.351416 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:08:04.382957  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8935
I0628 20:08:04.382957  1232 solver.cpp:397]     Test net output #1: loss = 0.353058 (* 1 = 0.353058 loss)
I0628 20:08:04.416487  1232 solver.cpp:218] Iteration 40000 (22.6594 iter/s, 4.41319s/100 iters), loss = 0.0849546
I0628 20:08:04.416487  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:08:04.416487  1232 solver.cpp:237]     Train net output #1: loss = 0.0849554 (* 1 = 0.0849554 loss)
I0628 20:08:04.416487  1232 sgd_solver.cpp:105] Iteration 40000, lr = 0.001
I0628 20:08:08.001302  1232 solver.cpp:218] Iteration 40100 (27.8944 iter/s, 3.58495s/100 iters), loss = 0.175805
I0628 20:08:08.001302  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:08:08.001302  1232 solver.cpp:237]     Train net output #1: loss = 0.175806 (* 1 = 0.175806 loss)
I0628 20:08:08.001302  1232 sgd_solver.cpp:105] Iteration 40100, lr = 0.001
I0628 20:08:11.586392  1232 solver.cpp:218] Iteration 40200 (27.9007 iter/s, 3.58413s/100 iters), loss = 0.179818
I0628 20:08:11.586392  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:08:11.586392  1232 solver.cpp:237]     Train net output #1: loss = 0.179819 (* 1 = 0.179819 loss)
I0628 20:08:11.586392  1232 sgd_solver.cpp:105] Iteration 40200, lr = 0.001
I0628 20:08:15.168326  1232 solver.cpp:218] Iteration 40300 (27.9136 iter/s, 3.58249s/100 iters), loss = 0.147993
I0628 20:08:15.169327  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:08:15.169327  1232 solver.cpp:237]     Train net output #1: loss = 0.147994 (* 1 = 0.147994 loss)
I0628 20:08:15.169327  1232 sgd_solver.cpp:105] Iteration 40300, lr = 0.001
I0628 20:08:18.752892  1232 solver.cpp:218] Iteration 40400 (27.9041 iter/s, 3.5837s/100 iters), loss = 0.115416
I0628 20:08:18.752892  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:08:18.752892  1232 solver.cpp:237]     Train net output #1: loss = 0.115417 (* 1 = 0.115417 loss)
I0628 20:08:18.752892  1232 sgd_solver.cpp:105] Iteration 40400, lr = 0.001
I0628 20:08:22.168814 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:08:22.309934  1232 solver.cpp:330] Iteration 40500, Testing net (#0)
I0628 20:08:22.309934  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:08:23.124795 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:08:23.155819  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8911
I0628 20:08:23.155819  1232 solver.cpp:397]     Test net output #1: loss = 0.354962 (* 1 = 0.354962 loss)
I0628 20:08:23.189841  1232 solver.cpp:218] Iteration 40500 (22.5399 iter/s, 4.43657s/100 iters), loss = 0.062929
I0628 20:08:23.189841  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:08:23.189841  1232 solver.cpp:237]     Train net output #1: loss = 0.0629299 (* 1 = 0.0629299 loss)
I0628 20:08:23.189841  1232 sgd_solver.cpp:105] Iteration 40500, lr = 0.001
I0628 20:08:26.769151  1232 solver.cpp:218] Iteration 40600 (27.938 iter/s, 3.57935s/100 iters), loss = 0.179991
I0628 20:08:26.769151  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:08:26.769151  1232 solver.cpp:237]     Train net output #1: loss = 0.179991 (* 1 = 0.179991 loss)
I0628 20:08:26.769151  1232 sgd_solver.cpp:105] Iteration 40600, lr = 0.001
I0628 20:08:30.361615  1232 solver.cpp:218] Iteration 40700 (27.8386 iter/s, 3.59213s/100 iters), loss = 0.174514
I0628 20:08:30.361615  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:08:30.361615  1232 solver.cpp:237]     Train net output #1: loss = 0.174515 (* 1 = 0.174515 loss)
I0628 20:08:30.361615  1232 sgd_solver.cpp:105] Iteration 40700, lr = 0.001
I0628 20:08:33.943648  1232 solver.cpp:218] Iteration 40800 (27.9217 iter/s, 3.58145s/100 iters), loss = 0.177183
I0628 20:08:33.943648  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:08:33.943648  1232 solver.cpp:237]     Train net output #1: loss = 0.177184 (* 1 = 0.177184 loss)
I0628 20:08:33.943648  1232 sgd_solver.cpp:105] Iteration 40800, lr = 0.001
I0628 20:08:37.525385  1232 solver.cpp:218] Iteration 40900 (27.9194 iter/s, 3.58174s/100 iters), loss = 0.127827
I0628 20:08:37.525385  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:08:37.525385  1232 solver.cpp:237]     Train net output #1: loss = 0.127827 (* 1 = 0.127827 loss)
I0628 20:08:37.525385  1232 sgd_solver.cpp:105] Iteration 40900, lr = 0.001
I0628 20:08:40.939934 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:08:41.080047  1232 solver.cpp:330] Iteration 41000, Testing net (#0)
I0628 20:08:41.080047  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:08:41.893647 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:08:41.924674  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I0628 20:08:41.924674  1232 solver.cpp:397]     Test net output #1: loss = 0.354919 (* 1 = 0.354919 loss)
I0628 20:08:41.958726  1232 solver.cpp:218] Iteration 41000 (22.5603 iter/s, 4.43256s/100 iters), loss = 0.101588
I0628 20:08:41.958726  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:08:41.958726  1232 solver.cpp:237]     Train net output #1: loss = 0.101589 (* 1 = 0.101589 loss)
I0628 20:08:41.958726  1232 sgd_solver.cpp:105] Iteration 41000, lr = 0.001
I0628 20:08:45.542258  1232 solver.cpp:218] Iteration 41100 (27.9106 iter/s, 3.58287s/100 iters), loss = 0.110508
I0628 20:08:45.542258  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:08:45.542258  1232 solver.cpp:237]     Train net output #1: loss = 0.110509 (* 1 = 0.110509 loss)
I0628 20:08:45.542258  1232 sgd_solver.cpp:105] Iteration 41100, lr = 0.001
I0628 20:08:49.122736  1232 solver.cpp:218] Iteration 41200 (27.932 iter/s, 3.58013s/100 iters), loss = 0.199817
I0628 20:08:49.122736  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:08:49.122736  1232 solver.cpp:237]     Train net output #1: loss = 0.199818 (* 1 = 0.199818 loss)
I0628 20:08:49.122736  1232 sgd_solver.cpp:105] Iteration 41200, lr = 0.001
I0628 20:08:52.746193  1232 solver.cpp:218] Iteration 41300 (27.5953 iter/s, 3.62381s/100 iters), loss = 0.177552
I0628 20:08:52.746193  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:08:52.746193  1232 solver.cpp:237]     Train net output #1: loss = 0.177553 (* 1 = 0.177553 loss)
I0628 20:08:52.746193  1232 sgd_solver.cpp:105] Iteration 41300, lr = 0.001
I0628 20:08:56.316030  1232 solver.cpp:218] Iteration 41400 (28.0164 iter/s, 3.56933s/100 iters), loss = 0.16306
I0628 20:08:56.316030  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:08:56.316030  1232 solver.cpp:237]     Train net output #1: loss = 0.163061 (* 1 = 0.163061 loss)
I0628 20:08:56.316030  1232 sgd_solver.cpp:105] Iteration 41400, lr = 0.001
I0628 20:08:59.719791 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:08:59.859897  1232 solver.cpp:330] Iteration 41500, Testing net (#0)
I0628 20:08:59.859897  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:09:00.674500 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:09:00.705523  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8924
I0628 20:09:00.705523  1232 solver.cpp:397]     Test net output #1: loss = 0.355518 (* 1 = 0.355518 loss)
I0628 20:09:00.739548  1232 solver.cpp:218] Iteration 41500 (22.6107 iter/s, 4.42268s/100 iters), loss = 0.107688
I0628 20:09:00.739548  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:09:00.739548  1232 solver.cpp:237]     Train net output #1: loss = 0.107689 (* 1 = 0.107689 loss)
I0628 20:09:00.739548  1232 sgd_solver.cpp:105] Iteration 41500, lr = 0.001
I0628 20:09:04.322948  1232 solver.cpp:218] Iteration 41600 (27.9049 iter/s, 3.5836s/100 iters), loss = 0.166442
I0628 20:09:04.322948  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:09:04.322948  1232 solver.cpp:237]     Train net output #1: loss = 0.166443 (* 1 = 0.166443 loss)
I0628 20:09:04.322948  1232 sgd_solver.cpp:105] Iteration 41600, lr = 0.001
I0628 20:09:07.895609  1232 solver.cpp:218] Iteration 41700 (27.9908 iter/s, 3.5726s/100 iters), loss = 0.150481
I0628 20:09:07.896610  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:09:07.896610  1232 solver.cpp:237]     Train net output #1: loss = 0.150482 (* 1 = 0.150482 loss)
I0628 20:09:07.896610  1232 sgd_solver.cpp:105] Iteration 41700, lr = 0.001
I0628 20:09:11.468430  1232 solver.cpp:218] Iteration 41800 (27.9974 iter/s, 3.57176s/100 iters), loss = 0.131275
I0628 20:09:11.468430  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:09:11.468430  1232 solver.cpp:237]     Train net output #1: loss = 0.131276 (* 1 = 0.131276 loss)
I0628 20:09:11.468430  1232 sgd_solver.cpp:105] Iteration 41800, lr = 0.001
I0628 20:09:15.057328  1232 solver.cpp:218] Iteration 41900 (27.8613 iter/s, 3.58921s/100 iters), loss = 0.0674084
I0628 20:09:15.057328  1232 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0628 20:09:15.057328  1232 solver.cpp:237]     Train net output #1: loss = 0.0674093 (* 1 = 0.0674093 loss)
I0628 20:09:15.057328  1232 sgd_solver.cpp:105] Iteration 41900, lr = 0.001
I0628 20:09:18.465625 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:09:18.605726  1232 solver.cpp:330] Iteration 42000, Testing net (#0)
I0628 20:09:18.605726  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:09:19.424160 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:09:19.447681  1232 solver.cpp:397]     Test net output #0: accuracy = 0.893
I0628 20:09:19.447681  1232 solver.cpp:397]     Test net output #1: loss = 0.356878 (* 1 = 0.356878 loss)
I0628 20:09:19.481204  1232 solver.cpp:218] Iteration 42000 (22.6074 iter/s, 4.42332s/100 iters), loss = 0.11055
I0628 20:09:19.481204  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:09:19.481204  1232 solver.cpp:237]     Train net output #1: loss = 0.110551 (* 1 = 0.110551 loss)
I0628 20:09:19.481204  1232 sgd_solver.cpp:105] Iteration 42000, lr = 0.001
I0628 20:09:23.070045  1232 solver.cpp:218] Iteration 42100 (27.8691 iter/s, 3.5882s/100 iters), loss = 0.227342
I0628 20:09:23.070045  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:09:23.070045  1232 solver.cpp:237]     Train net output #1: loss = 0.227343 (* 1 = 0.227343 loss)
I0628 20:09:23.070045  1232 sgd_solver.cpp:105] Iteration 42100, lr = 0.001
I0628 20:09:26.652272  1232 solver.cpp:218] Iteration 42200 (27.9191 iter/s, 3.58178s/100 iters), loss = 0.192508
I0628 20:09:26.652272  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:09:26.652272  1232 solver.cpp:237]     Train net output #1: loss = 0.192509 (* 1 = 0.192509 loss)
I0628 20:09:26.652272  1232 sgd_solver.cpp:105] Iteration 42200, lr = 0.001
I0628 20:09:30.231528  1232 solver.cpp:218] Iteration 42300 (27.942 iter/s, 3.57885s/100 iters), loss = 0.132742
I0628 20:09:30.231528  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:09:30.231528  1232 solver.cpp:237]     Train net output #1: loss = 0.132743 (* 1 = 0.132743 loss)
I0628 20:09:30.231528  1232 sgd_solver.cpp:105] Iteration 42300, lr = 0.001
I0628 20:09:33.808678  1232 solver.cpp:218] Iteration 42400 (27.9566 iter/s, 3.57697s/100 iters), loss = 0.0902018
I0628 20:09:33.808678  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:09:33.808678  1232 solver.cpp:237]     Train net output #1: loss = 0.0902026 (* 1 = 0.0902026 loss)
I0628 20:09:33.808678  1232 sgd_solver.cpp:105] Iteration 42400, lr = 0.001
I0628 20:09:37.206220 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:09:37.347326  1232 solver.cpp:330] Iteration 42500, Testing net (#0)
I0628 20:09:37.347326  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:09:38.162941 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:09:38.192965  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8927
I0628 20:09:38.192965  1232 solver.cpp:397]     Test net output #1: loss = 0.357131 (* 1 = 0.357131 loss)
I0628 20:09:38.226989  1232 solver.cpp:218] Iteration 42500 (22.6343 iter/s, 4.41807s/100 iters), loss = 0.13686
I0628 20:09:38.226989  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:09:38.226989  1232 solver.cpp:237]     Train net output #1: loss = 0.136861 (* 1 = 0.136861 loss)
I0628 20:09:38.226989  1232 sgd_solver.cpp:105] Iteration 42500, lr = 0.001
I0628 20:09:41.806664  1232 solver.cpp:218] Iteration 42600 (27.9402 iter/s, 3.57907s/100 iters), loss = 0.239465
I0628 20:09:41.806664  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:09:41.806664  1232 solver.cpp:237]     Train net output #1: loss = 0.239466 (* 1 = 0.239466 loss)
I0628 20:09:41.806664  1232 sgd_solver.cpp:105] Iteration 42600, lr = 0.001
I0628 20:09:45.396879  1232 solver.cpp:218] Iteration 42700 (27.8563 iter/s, 3.58985s/100 iters), loss = 0.110343
I0628 20:09:45.396879  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:09:45.396879  1232 solver.cpp:237]     Train net output #1: loss = 0.110344 (* 1 = 0.110344 loss)
I0628 20:09:45.396879  1232 sgd_solver.cpp:105] Iteration 42700, lr = 0.001
I0628 20:09:48.972276  1232 solver.cpp:218] Iteration 42800 (27.9676 iter/s, 3.57556s/100 iters), loss = 0.158807
I0628 20:09:48.972276  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:09:48.972276  1232 solver.cpp:237]     Train net output #1: loss = 0.158808 (* 1 = 0.158808 loss)
I0628 20:09:48.972276  1232 sgd_solver.cpp:105] Iteration 42800, lr = 0.001
I0628 20:09:52.767074  1232 solver.cpp:218] Iteration 42900 (26.3583 iter/s, 3.79387s/100 iters), loss = 0.0727755
I0628 20:09:52.767074  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:09:52.767074  1232 solver.cpp:237]     Train net output #1: loss = 0.0727763 (* 1 = 0.0727763 loss)
I0628 20:09:52.767074  1232 sgd_solver.cpp:105] Iteration 42900, lr = 0.001
I0628 20:09:56.196822 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:09:56.338243  1232 solver.cpp:330] Iteration 43000, Testing net (#0)
I0628 20:09:56.338243  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:09:57.162775 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:09:57.193791  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I0628 20:09:57.193791  1232 solver.cpp:397]     Test net output #1: loss = 0.362626 (* 1 = 0.362626 loss)
I0628 20:09:57.228842  1232 solver.cpp:218] Iteration 43000 (22.415 iter/s, 4.46129s/100 iters), loss = 0.0975376
I0628 20:09:57.228842  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:09:57.228842  1232 solver.cpp:237]     Train net output #1: loss = 0.0975384 (* 1 = 0.0975384 loss)
I0628 20:09:57.228842  1232 sgd_solver.cpp:105] Iteration 43000, lr = 0.001
I0628 20:10:00.877097  1232 solver.cpp:218] Iteration 43100 (27.4136 iter/s, 3.64782s/100 iters), loss = 0.135941
I0628 20:10:00.877097  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:10:00.877097  1232 solver.cpp:237]     Train net output #1: loss = 0.135942 (* 1 = 0.135942 loss)
I0628 20:10:00.877097  1232 sgd_solver.cpp:105] Iteration 43100, lr = 0.001
I0628 20:10:04.468873  1232 solver.cpp:218] Iteration 43200 (27.8381 iter/s, 3.5922s/100 iters), loss = 0.118636
I0628 20:10:04.468873  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:10:04.468873  1232 solver.cpp:237]     Train net output #1: loss = 0.118637 (* 1 = 0.118637 loss)
I0628 20:10:04.468873  1232 sgd_solver.cpp:105] Iteration 43200, lr = 0.001
I0628 20:10:08.049374  1232 solver.cpp:218] Iteration 43300 (27.936 iter/s, 3.57962s/100 iters), loss = 0.120509
I0628 20:10:08.049374  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:10:08.049374  1232 solver.cpp:237]     Train net output #1: loss = 0.12051 (* 1 = 0.12051 loss)
I0628 20:10:08.049374  1232 sgd_solver.cpp:105] Iteration 43300, lr = 0.001
I0628 20:10:11.653087  1232 solver.cpp:218] Iteration 43400 (27.7536 iter/s, 3.60314s/100 iters), loss = 0.0913648
I0628 20:10:11.653087  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:10:11.653087  1232 solver.cpp:237]     Train net output #1: loss = 0.0913656 (* 1 = 0.0913656 loss)
I0628 20:10:11.653087  1232 sgd_solver.cpp:105] Iteration 43400, lr = 0.001
I0628 20:10:15.176069 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:10:15.321681  1232 solver.cpp:330] Iteration 43500, Testing net (#0)
I0628 20:10:15.321681  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:10:16.170578 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:10:16.201602  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I0628 20:10:16.201602  1232 solver.cpp:397]     Test net output #1: loss = 0.361647 (* 1 = 0.361647 loss)
I0628 20:10:16.237643  1232 solver.cpp:218] Iteration 43500 (21.8135 iter/s, 4.58431s/100 iters), loss = 0.0888313
I0628 20:10:16.237643  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:10:16.237643  1232 solver.cpp:237]     Train net output #1: loss = 0.088832 (* 1 = 0.088832 loss)
I0628 20:10:16.237643  1232 sgd_solver.cpp:105] Iteration 43500, lr = 0.001
I0628 20:10:19.903569  1232 solver.cpp:218] Iteration 43600 (27.2788 iter/s, 3.66585s/100 iters), loss = 0.150901
I0628 20:10:19.903569  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:10:19.903569  1232 solver.cpp:237]     Train net output #1: loss = 0.150901 (* 1 = 0.150901 loss)
I0628 20:10:19.903569  1232 sgd_solver.cpp:105] Iteration 43600, lr = 0.001
I0628 20:10:23.592137  1232 solver.cpp:218] Iteration 43700 (27.1166 iter/s, 3.68777s/100 iters), loss = 0.172802
I0628 20:10:23.592137  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:10:23.592137  1232 solver.cpp:237]     Train net output #1: loss = 0.172803 (* 1 = 0.172803 loss)
I0628 20:10:23.592137  1232 sgd_solver.cpp:105] Iteration 43700, lr = 0.001
I0628 20:10:27.271929  1232 solver.cpp:218] Iteration 43800 (27.1757 iter/s, 3.67976s/100 iters), loss = 0.152526
I0628 20:10:27.271929  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:10:27.271929  1232 solver.cpp:237]     Train net output #1: loss = 0.152527 (* 1 = 0.152527 loss)
I0628 20:10:27.271929  1232 sgd_solver.cpp:105] Iteration 43800, lr = 0.001
I0628 20:10:30.960496  1232 solver.cpp:218] Iteration 43900 (27.1121 iter/s, 3.68839s/100 iters), loss = 0.139761
I0628 20:10:30.960496  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:10:30.960496  1232 solver.cpp:237]     Train net output #1: loss = 0.139762 (* 1 = 0.139762 loss)
I0628 20:10:30.960496  1232 sgd_solver.cpp:105] Iteration 43900, lr = 0.001
I0628 20:10:34.523169 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:10:34.668336  1232 solver.cpp:330] Iteration 44000, Testing net (#0)
I0628 20:10:34.668336  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:10:35.555033 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:10:35.585852  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8901
I0628 20:10:35.585852  1232 solver.cpp:397]     Test net output #1: loss = 0.366374 (* 1 = 0.366374 loss)
I0628 20:10:35.619889  1232 solver.cpp:218] Iteration 44000 (21.4655 iter/s, 4.65863s/100 iters), loss = 0.0941867
I0628 20:10:35.619889  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:10:35.619889  1232 solver.cpp:237]     Train net output #1: loss = 0.0941874 (* 1 = 0.0941874 loss)
I0628 20:10:35.619889  1232 sgd_solver.cpp:105] Iteration 44000, lr = 0.001
I0628 20:10:39.227345  1232 solver.cpp:218] Iteration 44100 (27.7211 iter/s, 3.60736s/100 iters), loss = 0.152135
I0628 20:10:39.227345  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:10:39.227345  1232 solver.cpp:237]     Train net output #1: loss = 0.152136 (* 1 = 0.152136 loss)
I0628 20:10:39.227345  1232 sgd_solver.cpp:105] Iteration 44100, lr = 0.001
I0628 20:10:42.830315  1232 solver.cpp:218] Iteration 44200 (27.7611 iter/s, 3.60216s/100 iters), loss = 0.164506
I0628 20:10:42.830315  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:10:42.830315  1232 solver.cpp:237]     Train net output #1: loss = 0.164506 (* 1 = 0.164506 loss)
I0628 20:10:42.830315  1232 sgd_solver.cpp:105] Iteration 44200, lr = 0.001
I0628 20:10:46.544358  1232 solver.cpp:218] Iteration 44300 (26.9226 iter/s, 3.71435s/100 iters), loss = 0.137812
I0628 20:10:46.544358  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:10:46.544358  1232 solver.cpp:237]     Train net output #1: loss = 0.137812 (* 1 = 0.137812 loss)
I0628 20:10:46.544358  1232 sgd_solver.cpp:105] Iteration 44300, lr = 0.001
I0628 20:10:50.217516  1232 solver.cpp:218] Iteration 44400 (27.2272 iter/s, 3.6728s/100 iters), loss = 0.0711689
I0628 20:10:50.217516  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:10:50.217516  1232 solver.cpp:237]     Train net output #1: loss = 0.0711696 (* 1 = 0.0711696 loss)
I0628 20:10:50.217516  1232 sgd_solver.cpp:105] Iteration 44400, lr = 0.001
I0628 20:10:53.655618 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:10:53.812242  1232 solver.cpp:330] Iteration 44500, Testing net (#0)
I0628 20:10:53.812242  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:10:54.636814 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:10:54.668372  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8924
I0628 20:10:54.668372  1232 solver.cpp:397]     Test net output #1: loss = 0.36532 (* 1 = 0.36532 loss)
I0628 20:10:54.703125  1232 solver.cpp:218] Iteration 44500 (22.2986 iter/s, 4.48459s/100 iters), loss = 0.0933689
I0628 20:10:54.703125  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:10:54.703125  1232 solver.cpp:237]     Train net output #1: loss = 0.0933696 (* 1 = 0.0933696 loss)
I0628 20:10:54.703125  1232 sgd_solver.cpp:105] Iteration 44500, lr = 0.001
I0628 20:10:58.622148  1232 solver.cpp:218] Iteration 44600 (25.5147 iter/s, 3.91931s/100 iters), loss = 0.20327
I0628 20:10:58.622148  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:10:58.622148  1232 solver.cpp:237]     Train net output #1: loss = 0.203271 (* 1 = 0.203271 loss)
I0628 20:10:58.622148  1232 sgd_solver.cpp:105] Iteration 44600, lr = 0.001
I0628 20:11:02.373605  1232 solver.cpp:218] Iteration 44700 (26.6626 iter/s, 3.75057s/100 iters), loss = 0.158155
I0628 20:11:02.373605  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:11:02.373605  1232 solver.cpp:237]     Train net output #1: loss = 0.158156 (* 1 = 0.158156 loss)
I0628 20:11:02.373605  1232 sgd_solver.cpp:105] Iteration 44700, lr = 0.001
I0628 20:11:06.143360  1232 solver.cpp:218] Iteration 44800 (26.5317 iter/s, 3.76908s/100 iters), loss = 0.102078
I0628 20:11:06.143360  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:11:06.143360  1232 solver.cpp:237]     Train net output #1: loss = 0.102079 (* 1 = 0.102079 loss)
I0628 20:11:06.143360  1232 sgd_solver.cpp:105] Iteration 44800, lr = 0.001
I0628 20:11:09.822391  1232 solver.cpp:218] Iteration 44900 (27.1825 iter/s, 3.67884s/100 iters), loss = 0.105779
I0628 20:11:09.822391  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:11:09.822391  1232 solver.cpp:237]     Train net output #1: loss = 0.105779 (* 1 = 0.105779 loss)
I0628 20:11:09.822391  1232 sgd_solver.cpp:105] Iteration 44900, lr = 0.001
I0628 20:11:13.272217 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:11:13.437340  1232 solver.cpp:330] Iteration 45000, Testing net (#0)
I0628 20:11:13.437340  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:11:14.307535 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:11:14.339059  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8915
I0628 20:11:14.339059  1232 solver.cpp:397]     Test net output #1: loss = 0.368951 (* 1 = 0.368951 loss)
I0628 20:11:14.373082  1232 solver.cpp:218] Iteration 45000 (21.9741 iter/s, 4.55081s/100 iters), loss = 0.0686459
I0628 20:11:14.373082  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:11:14.373082  1232 solver.cpp:237]     Train net output #1: loss = 0.0686467 (* 1 = 0.0686467 loss)
I0628 20:11:14.373082  1232 sgd_solver.cpp:105] Iteration 45000, lr = 0.001
I0628 20:11:18.024760  1232 solver.cpp:218] Iteration 45100 (27.3882 iter/s, 3.65121s/100 iters), loss = 0.171409
I0628 20:11:18.024760  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:11:18.024760  1232 solver.cpp:237]     Train net output #1: loss = 0.171409 (* 1 = 0.171409 loss)
I0628 20:11:18.024760  1232 sgd_solver.cpp:105] Iteration 45100, lr = 0.001
I0628 20:11:21.654522  1232 solver.cpp:218] Iteration 45200 (27.5524 iter/s, 3.62945s/100 iters), loss = 0.165712
I0628 20:11:21.654522  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:11:21.654522  1232 solver.cpp:237]     Train net output #1: loss = 0.165713 (* 1 = 0.165713 loss)
I0628 20:11:21.654522  1232 sgd_solver.cpp:105] Iteration 45200, lr = 0.001
I0628 20:11:25.296996  1232 solver.cpp:218] Iteration 45300 (27.4548 iter/s, 3.64235s/100 iters), loss = 0.167163
I0628 20:11:25.296996  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:11:25.296996  1232 solver.cpp:237]     Train net output #1: loss = 0.167164 (* 1 = 0.167164 loss)
I0628 20:11:25.297996  1232 sgd_solver.cpp:105] Iteration 45300, lr = 0.001
I0628 20:11:28.909588  1232 solver.cpp:218] Iteration 45400 (27.6904 iter/s, 3.61136s/100 iters), loss = 0.0980104
I0628 20:11:28.909588  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:11:28.909588  1232 solver.cpp:237]     Train net output #1: loss = 0.0980112 (* 1 = 0.0980112 loss)
I0628 20:11:28.909588  1232 sgd_solver.cpp:105] Iteration 45400, lr = 0.001
I0628 20:11:32.338002 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:11:32.482156  1232 solver.cpp:330] Iteration 45500, Testing net (#0)
I0628 20:11:32.482156  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:11:33.295888 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:11:33.327944  1232 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0628 20:11:33.327944  1232 solver.cpp:397]     Test net output #1: loss = 0.357981 (* 1 = 0.357981 loss)
I0628 20:11:33.361966  1232 solver.cpp:218] Iteration 45500 (22.4599 iter/s, 4.45238s/100 iters), loss = 0.122727
I0628 20:11:33.361966  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:11:33.361966  1232 solver.cpp:237]     Train net output #1: loss = 0.122727 (* 1 = 0.122727 loss)
I0628 20:11:33.361966  1232 sgd_solver.cpp:105] Iteration 45500, lr = 0.001
I0628 20:11:37.032143  1232 solver.cpp:218] Iteration 45600 (27.2501 iter/s, 3.66971s/100 iters), loss = 0.130082
I0628 20:11:37.032644  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:11:37.032644  1232 solver.cpp:237]     Train net output #1: loss = 0.130082 (* 1 = 0.130082 loss)
I0628 20:11:37.032644  1232 sgd_solver.cpp:105] Iteration 45600, lr = 0.001
I0628 20:11:40.660223  1232 solver.cpp:218] Iteration 45700 (27.5686 iter/s, 3.62731s/100 iters), loss = 0.204778
I0628 20:11:40.660223  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:11:40.660223  1232 solver.cpp:237]     Train net output #1: loss = 0.204779 (* 1 = 0.204779 loss)
I0628 20:11:40.660223  1232 sgd_solver.cpp:105] Iteration 45700, lr = 0.001
I0628 20:11:44.272094  1232 solver.cpp:218] Iteration 45800 (27.6843 iter/s, 3.61216s/100 iters), loss = 0.121389
I0628 20:11:44.272094  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:11:44.272094  1232 solver.cpp:237]     Train net output #1: loss = 0.12139 (* 1 = 0.12139 loss)
I0628 20:11:44.272094  1232 sgd_solver.cpp:105] Iteration 45800, lr = 0.001
I0628 20:11:47.907821  1232 solver.cpp:218] Iteration 45900 (27.5109 iter/s, 3.63493s/100 iters), loss = 0.151446
I0628 20:11:47.907821  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:11:47.907821  1232 solver.cpp:237]     Train net output #1: loss = 0.151447 (* 1 = 0.151447 loss)
I0628 20:11:47.907821  1232 sgd_solver.cpp:105] Iteration 45900, lr = 0.001
I0628 20:11:51.322480 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:11:51.462581  1232 solver.cpp:330] Iteration 46000, Testing net (#0)
I0628 20:11:51.462581  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:11:52.295317 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:11:52.317332  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I0628 20:11:52.318333  1232 solver.cpp:397]     Test net output #1: loss = 0.362095 (* 1 = 0.362095 loss)
I0628 20:11:52.352360  1232 solver.cpp:218] Iteration 46000 (22.502 iter/s, 4.44404s/100 iters), loss = 0.0987587
I0628 20:11:52.352360  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:11:52.352360  1232 solver.cpp:237]     Train net output #1: loss = 0.0987595 (* 1 = 0.0987595 loss)
I0628 20:11:52.352360  1232 sgd_solver.cpp:105] Iteration 46000, lr = 0.001
I0628 20:11:55.946832  1232 solver.cpp:218] Iteration 46100 (27.8217 iter/s, 3.59431s/100 iters), loss = 0.30106
I0628 20:11:55.946832  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:11:55.946832  1232 solver.cpp:237]     Train net output #1: loss = 0.301061 (* 1 = 0.301061 loss)
I0628 20:11:55.946832  1232 sgd_solver.cpp:105] Iteration 46100, lr = 0.001
I0628 20:11:59.578830  1232 solver.cpp:218] Iteration 46200 (27.5324 iter/s, 3.63209s/100 iters), loss = 0.165943
I0628 20:11:59.578830  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:11:59.578830  1232 solver.cpp:237]     Train net output #1: loss = 0.165943 (* 1 = 0.165943 loss)
I0628 20:11:59.578830  1232 sgd_solver.cpp:105] Iteration 46200, lr = 0.001
I0628 20:12:03.181282  1232 solver.cpp:218] Iteration 46300 (27.7602 iter/s, 3.60228s/100 iters), loss = 0.159657
I0628 20:12:03.181282  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:12:03.181282  1232 solver.cpp:237]     Train net output #1: loss = 0.159658 (* 1 = 0.159658 loss)
I0628 20:12:03.181282  1232 sgd_solver.cpp:105] Iteration 46300, lr = 0.001
I0628 20:12:06.785917  1232 solver.cpp:218] Iteration 46400 (27.7471 iter/s, 3.60398s/100 iters), loss = 0.149841
I0628 20:12:06.785917  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:12:06.785917  1232 solver.cpp:237]     Train net output #1: loss = 0.149842 (* 1 = 0.149842 loss)
I0628 20:12:06.785917  1232 sgd_solver.cpp:105] Iteration 46400, lr = 0.001
I0628 20:12:10.240222 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:12:10.380358  1232 solver.cpp:330] Iteration 46500, Testing net (#0)
I0628 20:12:10.381359  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:12:11.203346 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:12:11.226373  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0628 20:12:11.226373  1232 solver.cpp:397]     Test net output #1: loss = 0.360509 (* 1 = 0.360509 loss)
I0628 20:12:11.260397  1232 solver.cpp:218] Iteration 46500 (22.3512 iter/s, 4.47403s/100 iters), loss = 0.129113
I0628 20:12:11.260397  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:12:11.260397  1232 solver.cpp:237]     Train net output #1: loss = 0.129114 (* 1 = 0.129114 loss)
I0628 20:12:11.260397  1232 sgd_solver.cpp:105] Iteration 46500, lr = 0.001
I0628 20:12:14.857735  1232 solver.cpp:218] Iteration 46600 (27.8013 iter/s, 3.59695s/100 iters), loss = 0.197801
I0628 20:12:14.857735  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:12:14.857735  1232 solver.cpp:237]     Train net output #1: loss = 0.197802 (* 1 = 0.197802 loss)
I0628 20:12:14.857735  1232 sgd_solver.cpp:105] Iteration 46600, lr = 0.001
I0628 20:12:18.471462  1232 solver.cpp:218] Iteration 46700 (27.6715 iter/s, 3.61382s/100 iters), loss = 0.122629
I0628 20:12:18.471462  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:12:18.471462  1232 solver.cpp:237]     Train net output #1: loss = 0.12263 (* 1 = 0.12263 loss)
I0628 20:12:18.471462  1232 sgd_solver.cpp:105] Iteration 46700, lr = 0.001
I0628 20:12:22.092475  1232 solver.cpp:218] Iteration 46800 (27.6226 iter/s, 3.62023s/100 iters), loss = 0.148842
I0628 20:12:22.092475  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:12:22.092475  1232 solver.cpp:237]     Train net output #1: loss = 0.148843 (* 1 = 0.148843 loss)
I0628 20:12:22.092975  1232 sgd_solver.cpp:105] Iteration 46800, lr = 0.001
I0628 20:12:25.700963  1232 solver.cpp:218] Iteration 46900 (27.7154 iter/s, 3.6081s/100 iters), loss = 0.109706
I0628 20:12:25.700963  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:12:25.700963  1232 solver.cpp:237]     Train net output #1: loss = 0.109707 (* 1 = 0.109707 loss)
I0628 20:12:25.700963  1232 sgd_solver.cpp:105] Iteration 46900, lr = 0.001
I0628 20:12:29.140205 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:12:29.291817  1232 solver.cpp:330] Iteration 47000, Testing net (#0)
I0628 20:12:29.291817  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:12:30.106494 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:12:30.137017  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0628 20:12:30.137017  1232 solver.cpp:397]     Test net output #1: loss = 0.367204 (* 1 = 0.367204 loss)
I0628 20:12:30.171041  1232 solver.cpp:218] Iteration 47000 (22.3726 iter/s, 4.46976s/100 iters), loss = 0.0554653
I0628 20:12:30.171041  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:12:30.171041  1232 solver.cpp:237]     Train net output #1: loss = 0.055466 (* 1 = 0.055466 loss)
I0628 20:12:30.171041  1232 sgd_solver.cpp:105] Iteration 47000, lr = 0.001
I0628 20:12:33.768756  1232 solver.cpp:218] Iteration 47100 (27.7981 iter/s, 3.59737s/100 iters), loss = 0.1871
I0628 20:12:33.768756  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:12:33.768756  1232 solver.cpp:237]     Train net output #1: loss = 0.1871 (* 1 = 0.1871 loss)
I0628 20:12:33.768756  1232 sgd_solver.cpp:105] Iteration 47100, lr = 0.001
I0628 20:12:37.366430  1232 solver.cpp:218] Iteration 47200 (27.7995 iter/s, 3.59718s/100 iters), loss = 0.118681
I0628 20:12:37.366430  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:12:37.366430  1232 solver.cpp:237]     Train net output #1: loss = 0.118682 (* 1 = 0.118682 loss)
I0628 20:12:37.366430  1232 sgd_solver.cpp:105] Iteration 47200, lr = 0.001
I0628 20:12:40.981307  1232 solver.cpp:218] Iteration 47300 (27.6628 iter/s, 3.61497s/100 iters), loss = 0.101487
I0628 20:12:40.981307  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:12:40.981307  1232 solver.cpp:237]     Train net output #1: loss = 0.101488 (* 1 = 0.101488 loss)
I0628 20:12:40.981307  1232 sgd_solver.cpp:105] Iteration 47300, lr = 0.001
I0628 20:12:44.569202  1232 solver.cpp:218] Iteration 47400 (27.8778 iter/s, 3.58708s/100 iters), loss = 0.0769401
I0628 20:12:44.569202  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:12:44.569202  1232 solver.cpp:237]     Train net output #1: loss = 0.0769408 (* 1 = 0.0769408 loss)
I0628 20:12:44.569202  1232 sgd_solver.cpp:105] Iteration 47400, lr = 0.001
I0628 20:12:48.010069 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:12:48.152222  1232 solver.cpp:330] Iteration 47500, Testing net (#0)
I0628 20:12:48.152222  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:12:48.969224 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:12:48.999264  1232 solver.cpp:397]     Test net output #0: accuracy = 0.89
I0628 20:12:48.999264  1232 solver.cpp:397]     Test net output #1: loss = 0.368771 (* 1 = 0.368771 loss)
I0628 20:12:49.033294  1232 solver.cpp:218] Iteration 47500 (22.4006 iter/s, 4.46416s/100 iters), loss = 0.103543
I0628 20:12:49.033294  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:12:49.033294  1232 solver.cpp:237]     Train net output #1: loss = 0.103544 (* 1 = 0.103544 loss)
I0628 20:12:49.033294  1232 sgd_solver.cpp:105] Iteration 47500, lr = 0.001
I0628 20:12:52.643045  1232 solver.cpp:218] Iteration 47600 (27.7087 iter/s, 3.60897s/100 iters), loss = 0.12082
I0628 20:12:52.643045  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:12:52.643045  1232 solver.cpp:237]     Train net output #1: loss = 0.120821 (* 1 = 0.120821 loss)
I0628 20:12:52.643045  1232 sgd_solver.cpp:105] Iteration 47600, lr = 0.001
I0628 20:12:56.229300  1232 solver.cpp:218] Iteration 47700 (27.8853 iter/s, 3.58611s/100 iters), loss = 0.188152
I0628 20:12:56.229800  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:12:56.229800  1232 solver.cpp:237]     Train net output #1: loss = 0.188153 (* 1 = 0.188153 loss)
I0628 20:12:56.229800  1232 sgd_solver.cpp:105] Iteration 47700, lr = 0.001
I0628 20:12:59.855671  1232 solver.cpp:218] Iteration 47800 (27.5798 iter/s, 3.62584s/100 iters), loss = 0.143938
I0628 20:12:59.855671  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:12:59.855671  1232 solver.cpp:237]     Train net output #1: loss = 0.143939 (* 1 = 0.143939 loss)
I0628 20:12:59.855671  1232 sgd_solver.cpp:105] Iteration 47800, lr = 0.001
I0628 20:13:03.450011  1232 solver.cpp:218] Iteration 47900 (27.8255 iter/s, 3.59383s/100 iters), loss = 0.0852186
I0628 20:13:03.450011  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:13:03.450011  1232 solver.cpp:237]     Train net output #1: loss = 0.0852194 (* 1 = 0.0852194 loss)
I0628 20:13:03.450011  1232 sgd_solver.cpp:105] Iteration 47900, lr = 0.001
I0628 20:13:06.882539 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:13:07.022394  1232 solver.cpp:330] Iteration 48000, Testing net (#0)
I0628 20:13:07.022394  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:13:07.834188 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:13:07.865211  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8908
I0628 20:13:07.865211  1232 solver.cpp:397]     Test net output #1: loss = 0.375132 (* 1 = 0.375132 loss)
I0628 20:13:07.899262  1232 solver.cpp:218] Iteration 48000 (22.4752 iter/s, 4.44936s/100 iters), loss = 0.0827098
I0628 20:13:07.899262  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:13:07.899262  1232 solver.cpp:237]     Train net output #1: loss = 0.0827105 (* 1 = 0.0827105 loss)
I0628 20:13:07.899262  1232 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0628 20:13:07.899262  1232 sgd_solver.cpp:105] Iteration 48000, lr = 0.0001
I0628 20:13:11.506639  1232 solver.cpp:218] Iteration 48100 (27.726 iter/s, 3.60672s/100 iters), loss = 0.17345
I0628 20:13:11.506639  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:13:11.506639  1232 solver.cpp:237]     Train net output #1: loss = 0.173451 (* 1 = 0.173451 loss)
I0628 20:13:11.506639  1232 sgd_solver.cpp:105] Iteration 48100, lr = 0.0001
I0628 20:13:15.107870  1232 solver.cpp:218] Iteration 48200 (27.77 iter/s, 3.60101s/100 iters), loss = 0.158765
I0628 20:13:15.107870  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:13:15.107870  1232 solver.cpp:237]     Train net output #1: loss = 0.158765 (* 1 = 0.158765 loss)
I0628 20:13:15.107870  1232 sgd_solver.cpp:105] Iteration 48200, lr = 0.0001
I0628 20:13:18.715081  1232 solver.cpp:218] Iteration 48300 (27.7211 iter/s, 3.60736s/100 iters), loss = 0.135812
I0628 20:13:18.715081  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:13:18.715081  1232 solver.cpp:237]     Train net output #1: loss = 0.135812 (* 1 = 0.135812 loss)
I0628 20:13:18.716083  1232 sgd_solver.cpp:105] Iteration 48300, lr = 0.0001
I0628 20:13:22.322957  1232 solver.cpp:218] Iteration 48400 (27.7267 iter/s, 3.60664s/100 iters), loss = 0.0552719
I0628 20:13:22.322957  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:13:22.322957  1232 solver.cpp:237]     Train net output #1: loss = 0.0552726 (* 1 = 0.0552726 loss)
I0628 20:13:22.322957  1232 sgd_solver.cpp:105] Iteration 48400, lr = 0.0001
I0628 20:13:25.777797 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:13:25.920980  1232 solver.cpp:330] Iteration 48500, Testing net (#0)
I0628 20:13:25.920980  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:13:26.738677 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:13:26.769700  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8945
I0628 20:13:26.769700  1232 solver.cpp:397]     Test net output #1: loss = 0.36713 (* 1 = 0.36713 loss)
I0628 20:13:26.804255  1232 solver.cpp:218] Iteration 48500 (22.3165 iter/s, 4.48098s/100 iters), loss = 0.0665237
I0628 20:13:26.804255  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:13:26.804255  1232 solver.cpp:237]     Train net output #1: loss = 0.0665243 (* 1 = 0.0665243 loss)
I0628 20:13:26.804255  1232 sgd_solver.cpp:105] Iteration 48500, lr = 0.0001
I0628 20:13:30.447051  1232 solver.cpp:218] Iteration 48600 (27.4477 iter/s, 3.64329s/100 iters), loss = 0.157274
I0628 20:13:30.447051  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:13:30.448051  1232 solver.cpp:237]     Train net output #1: loss = 0.157275 (* 1 = 0.157275 loss)
I0628 20:13:30.448051  1232 sgd_solver.cpp:105] Iteration 48600, lr = 0.0001
I0628 20:13:34.066623  1232 solver.cpp:218] Iteration 48700 (27.6348 iter/s, 3.61863s/100 iters), loss = 0.0819661
I0628 20:13:34.066623  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:13:34.066623  1232 solver.cpp:237]     Train net output #1: loss = 0.0819668 (* 1 = 0.0819668 loss)
I0628 20:13:34.066623  1232 sgd_solver.cpp:105] Iteration 48700, lr = 0.0001
I0628 20:13:37.754118  1232 solver.cpp:218] Iteration 48800 (27.1194 iter/s, 3.6874s/100 iters), loss = 0.119436
I0628 20:13:37.754118  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:13:37.754118  1232 solver.cpp:237]     Train net output #1: loss = 0.119436 (* 1 = 0.119436 loss)
I0628 20:13:37.754118  1232 sgd_solver.cpp:105] Iteration 48800, lr = 0.0001
I0628 20:13:41.410101  1232 solver.cpp:218] Iteration 48900 (27.3605 iter/s, 3.65491s/100 iters), loss = 0.101858
I0628 20:13:41.410101  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:13:41.410101  1232 solver.cpp:237]     Train net output #1: loss = 0.101859 (* 1 = 0.101859 loss)
I0628 20:13:41.410101  1232 sgd_solver.cpp:105] Iteration 48900, lr = 0.0001
I0628 20:13:44.945631 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:13:45.087307  1232 solver.cpp:330] Iteration 49000, Testing net (#0)
I0628 20:13:45.087307  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:13:45.916143 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:13:45.946687  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0628 20:13:45.946687  1232 solver.cpp:397]     Test net output #1: loss = 0.366849 (* 1 = 0.366849 loss)
I0628 20:13:45.981711  1232 solver.cpp:218] Iteration 49000 (21.874 iter/s, 4.57165s/100 iters), loss = 0.073106
I0628 20:13:45.981711  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:13:45.981711  1232 solver.cpp:237]     Train net output #1: loss = 0.0731066 (* 1 = 0.0731066 loss)
I0628 20:13:45.981711  1232 sgd_solver.cpp:105] Iteration 49000, lr = 0.0001
I0628 20:13:49.633661  1232 solver.cpp:218] Iteration 49100 (27.3842 iter/s, 3.65174s/100 iters), loss = 0.160944
I0628 20:13:49.633661  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:13:49.633661  1232 solver.cpp:237]     Train net output #1: loss = 0.160945 (* 1 = 0.160945 loss)
I0628 20:13:49.633661  1232 sgd_solver.cpp:105] Iteration 49100, lr = 0.0001
I0628 20:13:53.456749  1232 solver.cpp:218] Iteration 49200 (26.1585 iter/s, 3.82284s/100 iters), loss = 0.104877
I0628 20:13:53.456749  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:13:53.456749  1232 solver.cpp:237]     Train net output #1: loss = 0.104877 (* 1 = 0.104877 loss)
I0628 20:13:53.456749  1232 sgd_solver.cpp:105] Iteration 49200, lr = 0.0001
I0628 20:13:57.194733  1232 solver.cpp:218] Iteration 49300 (26.755 iter/s, 3.73762s/100 iters), loss = 0.165019
I0628 20:13:57.194733  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:13:57.195734  1232 solver.cpp:237]     Train net output #1: loss = 0.165019 (* 1 = 0.165019 loss)
I0628 20:13:57.195734  1232 sgd_solver.cpp:105] Iteration 49300, lr = 0.0001
I0628 20:14:00.844172  1232 solver.cpp:218] Iteration 49400 (27.4078 iter/s, 3.64859s/100 iters), loss = 0.104207
I0628 20:14:00.844672  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:14:00.844672  1232 solver.cpp:237]     Train net output #1: loss = 0.104208 (* 1 = 0.104208 loss)
I0628 20:14:00.844672  1232 sgd_solver.cpp:105] Iteration 49400, lr = 0.0001
I0628 20:14:04.323740 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:14:04.462923  1232 solver.cpp:330] Iteration 49500, Testing net (#0)
I0628 20:14:04.462923  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:14:05.292500 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:14:05.321535  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8938
I0628 20:14:05.321535  1232 solver.cpp:397]     Test net output #1: loss = 0.364401 (* 1 = 0.364401 loss)
I0628 20:14:05.356556  1232 solver.cpp:218] Iteration 49500 (22.1637 iter/s, 4.51189s/100 iters), loss = 0.0741023
I0628 20:14:05.356556  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:14:05.356556  1232 solver.cpp:237]     Train net output #1: loss = 0.074103 (* 1 = 0.074103 loss)
I0628 20:14:05.356556  1232 sgd_solver.cpp:105] Iteration 49500, lr = 0.0001
I0628 20:14:09.077679  1232 solver.cpp:218] Iteration 49600 (26.8758 iter/s, 3.72082s/100 iters), loss = 0.128048
I0628 20:14:09.077679  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:14:09.077679  1232 solver.cpp:237]     Train net output #1: loss = 0.128049 (* 1 = 0.128049 loss)
I0628 20:14:09.077679  1232 sgd_solver.cpp:105] Iteration 49600, lr = 0.0001
I0628 20:14:12.733052  1232 solver.cpp:218] Iteration 49700 (27.3577 iter/s, 3.65528s/100 iters), loss = 0.126158
I0628 20:14:12.733052  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:14:12.733052  1232 solver.cpp:237]     Train net output #1: loss = 0.126159 (* 1 = 0.126159 loss)
I0628 20:14:12.733052  1232 sgd_solver.cpp:105] Iteration 49700, lr = 0.0001
I0628 20:14:16.359107  1232 solver.cpp:218] Iteration 49800 (27.5834 iter/s, 3.62537s/100 iters), loss = 0.086013
I0628 20:14:16.359107  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:14:16.359107  1232 solver.cpp:237]     Train net output #1: loss = 0.0860137 (* 1 = 0.0860137 loss)
I0628 20:14:16.359107  1232 sgd_solver.cpp:105] Iteration 49800, lr = 0.0001
I0628 20:14:20.025921  1232 solver.cpp:218] Iteration 49900 (27.2726 iter/s, 3.66668s/100 iters), loss = 0.0551042
I0628 20:14:20.025921  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:14:20.025921  1232 solver.cpp:237]     Train net output #1: loss = 0.0551049 (* 1 = 0.0551049 loss)
I0628 20:14:20.025921  1232 sgd_solver.cpp:105] Iteration 49900, lr = 0.0001
I0628 20:14:23.527539 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:14:23.674649  1232 solver.cpp:330] Iteration 50000, Testing net (#0)
I0628 20:14:23.674649  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:14:24.531188 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:14:24.563213  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8935
I0628 20:14:24.563213  1232 solver.cpp:397]     Test net output #1: loss = 0.365727 (* 1 = 0.365727 loss)
I0628 20:14:24.599239  1232 solver.cpp:218] Iteration 50000 (21.8698 iter/s, 4.57251s/100 iters), loss = 0.0667267
I0628 20:14:24.599239  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:14:24.599239  1232 solver.cpp:237]     Train net output #1: loss = 0.0667274 (* 1 = 0.0667274 loss)
I0628 20:14:24.599239  1232 sgd_solver.cpp:105] Iteration 50000, lr = 0.0001
I0628 20:14:28.273962  1232 solver.cpp:218] Iteration 50100 (27.217 iter/s, 3.67417s/100 iters), loss = 0.138407
I0628 20:14:28.273962  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:14:28.273962  1232 solver.cpp:237]     Train net output #1: loss = 0.138408 (* 1 = 0.138408 loss)
I0628 20:14:28.273962  1232 sgd_solver.cpp:105] Iteration 50100, lr = 0.0001
I0628 20:14:31.975919  1232 solver.cpp:218] Iteration 50200 (27.0145 iter/s, 3.70171s/100 iters), loss = 0.100624
I0628 20:14:31.975919  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:14:31.975919  1232 solver.cpp:237]     Train net output #1: loss = 0.100625 (* 1 = 0.100625 loss)
I0628 20:14:31.975919  1232 sgd_solver.cpp:105] Iteration 50200, lr = 0.0001
I0628 20:14:35.614318  1232 solver.cpp:218] Iteration 50300 (27.4819 iter/s, 3.63876s/100 iters), loss = 0.150852
I0628 20:14:35.615317  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:14:35.615317  1232 solver.cpp:237]     Train net output #1: loss = 0.150852 (* 1 = 0.150852 loss)
I0628 20:14:35.615317  1232 sgd_solver.cpp:105] Iteration 50300, lr = 0.0001
I0628 20:14:39.273576  1232 solver.cpp:218] Iteration 50400 (27.3404 iter/s, 3.65759s/100 iters), loss = 0.0690032
I0628 20:14:39.273576  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:14:39.273576  1232 solver.cpp:237]     Train net output #1: loss = 0.0690039 (* 1 = 0.0690039 loss)
I0628 20:14:39.273576  1232 sgd_solver.cpp:105] Iteration 50400, lr = 0.0001
I0628 20:14:42.778956 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:14:42.928618  1232 solver.cpp:330] Iteration 50500, Testing net (#0)
I0628 20:14:42.928618  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:14:43.770797 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:14:43.801805  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I0628 20:14:43.801805  1232 solver.cpp:397]     Test net output #1: loss = 0.363502 (* 1 = 0.363502 loss)
I0628 20:14:43.836859  1232 solver.cpp:218] Iteration 50500 (21.916 iter/s, 4.56288s/100 iters), loss = 0.077493
I0628 20:14:43.836859  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:14:43.836859  1232 solver.cpp:237]     Train net output #1: loss = 0.0774937 (* 1 = 0.0774937 loss)
I0628 20:14:43.836859  1232 sgd_solver.cpp:105] Iteration 50500, lr = 0.0001
I0628 20:14:47.534324  1232 solver.cpp:218] Iteration 50600 (27.0465 iter/s, 3.69734s/100 iters), loss = 0.194527
I0628 20:14:47.534324  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:14:47.534324  1232 solver.cpp:237]     Train net output #1: loss = 0.194527 (* 1 = 0.194527 loss)
I0628 20:14:47.534324  1232 sgd_solver.cpp:105] Iteration 50600, lr = 0.0001
I0628 20:14:51.342944  1232 solver.cpp:218] Iteration 50700 (26.2599 iter/s, 3.80809s/100 iters), loss = 0.105166
I0628 20:14:51.342944  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:14:51.342944  1232 solver.cpp:237]     Train net output #1: loss = 0.105167 (* 1 = 0.105167 loss)
I0628 20:14:51.342944  1232 sgd_solver.cpp:105] Iteration 50700, lr = 0.0001
I0628 20:14:55.099674  1232 solver.cpp:218] Iteration 50800 (26.6186 iter/s, 3.75678s/100 iters), loss = 0.173687
I0628 20:14:55.099674  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:14:55.099674  1232 solver.cpp:237]     Train net output #1: loss = 0.173687 (* 1 = 0.173687 loss)
I0628 20:14:55.099674  1232 sgd_solver.cpp:105] Iteration 50800, lr = 0.0001
I0628 20:14:58.927459  1232 solver.cpp:218] Iteration 50900 (26.1295 iter/s, 3.82709s/100 iters), loss = 0.0613066
I0628 20:14:58.927459  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:14:58.927459  1232 solver.cpp:237]     Train net output #1: loss = 0.0613074 (* 1 = 0.0613074 loss)
I0628 20:14:58.927459  1232 sgd_solver.cpp:105] Iteration 50900, lr = 0.0001
I0628 20:15:02.446789 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:15:02.587996  1232 solver.cpp:330] Iteration 51000, Testing net (#0)
I0628 20:15:02.587996  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:15:03.419855 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:15:03.450398  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8942
I0628 20:15:03.450398  1232 solver.cpp:397]     Test net output #1: loss = 0.364659 (* 1 = 0.364659 loss)
I0628 20:15:03.483934  1232 solver.cpp:218] Iteration 51000 (21.9462 iter/s, 4.55659s/100 iters), loss = 0.097377
I0628 20:15:03.483934  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:15:03.483934  1232 solver.cpp:237]     Train net output #1: loss = 0.0973778 (* 1 = 0.0973778 loss)
I0628 20:15:03.483934  1232 sgd_solver.cpp:105] Iteration 51000, lr = 0.0001
I0628 20:15:07.152412  1232 solver.cpp:218] Iteration 51100 (27.2686 iter/s, 3.66723s/100 iters), loss = 0.101006
I0628 20:15:07.152412  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:15:07.152412  1232 solver.cpp:237]     Train net output #1: loss = 0.101007 (* 1 = 0.101007 loss)
I0628 20:15:07.152412  1232 sgd_solver.cpp:105] Iteration 51100, lr = 0.0001
I0628 20:15:10.797224  1232 solver.cpp:218] Iteration 51200 (27.4383 iter/s, 3.64454s/100 iters), loss = 0.130312
I0628 20:15:10.797224  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:15:10.797224  1232 solver.cpp:237]     Train net output #1: loss = 0.130312 (* 1 = 0.130312 loss)
I0628 20:15:10.797224  1232 sgd_solver.cpp:105] Iteration 51200, lr = 0.0001
I0628 20:15:14.426939  1232 solver.cpp:218] Iteration 51300 (27.549 iter/s, 3.62989s/100 iters), loss = 0.132756
I0628 20:15:14.426939  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:15:14.426939  1232 solver.cpp:237]     Train net output #1: loss = 0.132757 (* 1 = 0.132757 loss)
I0628 20:15:14.426939  1232 sgd_solver.cpp:105] Iteration 51300, lr = 0.0001
I0628 20:15:18.162195  1232 solver.cpp:218] Iteration 51400 (26.7787 iter/s, 3.73432s/100 iters), loss = 0.064527
I0628 20:15:18.162195  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:15:18.162195  1232 solver.cpp:237]     Train net output #1: loss = 0.0645278 (* 1 = 0.0645278 loss)
I0628 20:15:18.162195  1232 sgd_solver.cpp:105] Iteration 51400, lr = 0.0001
I0628 20:15:21.711064 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:15:21.856181  1232 solver.cpp:330] Iteration 51500, Testing net (#0)
I0628 20:15:21.856181  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:15:22.713518 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:15:22.744542  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0628 20:15:22.744542  1232 solver.cpp:397]     Test net output #1: loss = 0.365675 (* 1 = 0.365675 loss)
I0628 20:15:22.779070  1232 solver.cpp:218] Iteration 51500 (21.6604 iter/s, 4.61673s/100 iters), loss = 0.0984189
I0628 20:15:22.779570  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:15:22.779570  1232 solver.cpp:237]     Train net output #1: loss = 0.0984197 (* 1 = 0.0984197 loss)
I0628 20:15:22.779570  1232 sgd_solver.cpp:105] Iteration 51500, lr = 0.0001
I0628 20:15:26.484769  1232 solver.cpp:218] Iteration 51600 (26.9913 iter/s, 3.70489s/100 iters), loss = 0.196769
I0628 20:15:26.484769  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:15:26.484769  1232 solver.cpp:237]     Train net output #1: loss = 0.19677 (* 1 = 0.19677 loss)
I0628 20:15:26.484769  1232 sgd_solver.cpp:105] Iteration 51600, lr = 0.0001
I0628 20:15:30.183447  1232 solver.cpp:218] Iteration 51700 (27.0382 iter/s, 3.69846s/100 iters), loss = 0.136541
I0628 20:15:30.183447  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:15:30.183447  1232 solver.cpp:237]     Train net output #1: loss = 0.136542 (* 1 = 0.136542 loss)
I0628 20:15:30.183447  1232 sgd_solver.cpp:105] Iteration 51700, lr = 0.0001
I0628 20:15:33.819648  1232 solver.cpp:218] Iteration 51800 (27.5012 iter/s, 3.63621s/100 iters), loss = 0.128299
I0628 20:15:33.819648  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:15:33.819648  1232 solver.cpp:237]     Train net output #1: loss = 0.1283 (* 1 = 0.1283 loss)
I0628 20:15:33.819648  1232 sgd_solver.cpp:105] Iteration 51800, lr = 0.0001
I0628 20:15:37.547502  1232 solver.cpp:218] Iteration 51900 (26.8296 iter/s, 3.72722s/100 iters), loss = 0.0538146
I0628 20:15:37.548002  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:15:37.548002  1232 solver.cpp:237]     Train net output #1: loss = 0.0538154 (* 1 = 0.0538154 loss)
I0628 20:15:37.548002  1232 sgd_solver.cpp:105] Iteration 51900, lr = 0.0001
I0628 20:15:41.075677 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:15:41.222384  1232 solver.cpp:330] Iteration 52000, Testing net (#0)
I0628 20:15:41.222384  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:15:42.056133 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:15:42.087671  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8947
I0628 20:15:42.087671  1232 solver.cpp:397]     Test net output #1: loss = 0.364132 (* 1 = 0.364132 loss)
I0628 20:15:42.121695  1232 solver.cpp:218] Iteration 52000 (21.8647 iter/s, 4.57359s/100 iters), loss = 0.121576
I0628 20:15:42.121695  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:15:42.121695  1232 solver.cpp:237]     Train net output #1: loss = 0.121577 (* 1 = 0.121577 loss)
I0628 20:15:42.121695  1232 sgd_solver.cpp:105] Iteration 52000, lr = 0.0001
I0628 20:15:45.754211  1232 solver.cpp:218] Iteration 52100 (27.5264 iter/s, 3.63288s/100 iters), loss = 0.159861
I0628 20:15:45.755213  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:15:45.755213  1232 solver.cpp:237]     Train net output #1: loss = 0.159862 (* 1 = 0.159862 loss)
I0628 20:15:45.755213  1232 sgd_solver.cpp:105] Iteration 52100, lr = 0.0001
I0628 20:15:49.445910  1232 solver.cpp:218] Iteration 52200 (27.0906 iter/s, 3.69132s/100 iters), loss = 0.120811
I0628 20:15:49.446910  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:15:49.446910  1232 solver.cpp:237]     Train net output #1: loss = 0.120812 (* 1 = 0.120812 loss)
I0628 20:15:49.446910  1232 sgd_solver.cpp:105] Iteration 52200, lr = 0.0001
I0628 20:15:53.066777  1232 solver.cpp:218] Iteration 52300 (27.6244 iter/s, 3.61999s/100 iters), loss = 0.114741
I0628 20:15:53.067278  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:15:53.067278  1232 solver.cpp:237]     Train net output #1: loss = 0.114742 (* 1 = 0.114742 loss)
I0628 20:15:53.067278  1232 sgd_solver.cpp:105] Iteration 52300, lr = 0.0001
I0628 20:15:56.704790  1232 solver.cpp:218] Iteration 52400 (27.4933 iter/s, 3.63726s/100 iters), loss = 0.0973405
I0628 20:15:56.704790  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:15:56.704790  1232 solver.cpp:237]     Train net output #1: loss = 0.0973413 (* 1 = 0.0973413 loss)
I0628 20:15:56.704790  1232 sgd_solver.cpp:105] Iteration 52400, lr = 0.0001
I0628 20:16:00.175532 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:16:00.316498  1232 solver.cpp:330] Iteration 52500, Testing net (#0)
I0628 20:16:00.316498  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:16:01.131623 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:16:01.162649  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8944
I0628 20:16:01.162649  1232 solver.cpp:397]     Test net output #1: loss = 0.36445 (* 1 = 0.36445 loss)
I0628 20:16:01.196185  1232 solver.cpp:218] Iteration 52500 (22.2622 iter/s, 4.49192s/100 iters), loss = 0.095957
I0628 20:16:01.196185  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:16:01.196185  1232 solver.cpp:237]     Train net output #1: loss = 0.0959578 (* 1 = 0.0959578 loss)
I0628 20:16:01.196185  1232 sgd_solver.cpp:105] Iteration 52500, lr = 0.0001
I0628 20:16:04.804925  1232 solver.cpp:218] Iteration 52600 (27.7157 iter/s, 3.60807s/100 iters), loss = 0.173929
I0628 20:16:04.804925  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:16:04.804925  1232 solver.cpp:237]     Train net output #1: loss = 0.17393 (* 1 = 0.17393 loss)
I0628 20:16:04.804925  1232 sgd_solver.cpp:105] Iteration 52600, lr = 0.0001
I0628 20:16:08.428707  1232 solver.cpp:218] Iteration 52700 (27.6001 iter/s, 3.62317s/100 iters), loss = 0.0972705
I0628 20:16:08.428707  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:16:08.428707  1232 solver.cpp:237]     Train net output #1: loss = 0.0972713 (* 1 = 0.0972713 loss)
I0628 20:16:08.428707  1232 sgd_solver.cpp:105] Iteration 52700, lr = 0.0001
I0628 20:16:12.101925  1232 solver.cpp:218] Iteration 52800 (27.2244 iter/s, 3.67317s/100 iters), loss = 0.130612
I0628 20:16:12.101925  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:16:12.101925  1232 solver.cpp:237]     Train net output #1: loss = 0.130613 (* 1 = 0.130613 loss)
I0628 20:16:12.101925  1232 sgd_solver.cpp:105] Iteration 52800, lr = 0.0001
I0628 20:16:15.759851  1232 solver.cpp:218] Iteration 52900 (27.3396 iter/s, 3.65769s/100 iters), loss = 0.0726154
I0628 20:16:15.760852  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:16:15.760852  1232 solver.cpp:237]     Train net output #1: loss = 0.0726162 (* 1 = 0.0726162 loss)
I0628 20:16:15.760852  1232 sgd_solver.cpp:105] Iteration 52900, lr = 0.0001
I0628 20:16:19.220604 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:16:19.366715  1232 solver.cpp:330] Iteration 53000, Testing net (#0)
I0628 20:16:19.366715  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:16:20.211182 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:16:20.242188  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8944
I0628 20:16:20.242188  1232 solver.cpp:397]     Test net output #1: loss = 0.365065 (* 1 = 0.365065 loss)
I0628 20:16:20.277215  1232 solver.cpp:218] Iteration 53000 (22.1392 iter/s, 4.51687s/100 iters), loss = 0.0763662
I0628 20:16:20.277215  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:16:20.277215  1232 solver.cpp:237]     Train net output #1: loss = 0.076367 (* 1 = 0.076367 loss)
I0628 20:16:20.277215  1232 sgd_solver.cpp:105] Iteration 53000, lr = 0.0001
I0628 20:16:23.964745  1232 solver.cpp:218] Iteration 53100 (27.1257 iter/s, 3.68655s/100 iters), loss = 0.101861
I0628 20:16:23.964745  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:16:23.964745  1232 solver.cpp:237]     Train net output #1: loss = 0.101862 (* 1 = 0.101862 loss)
I0628 20:16:23.964745  1232 sgd_solver.cpp:105] Iteration 53100, lr = 0.0001
I0628 20:16:27.579464  1232 solver.cpp:218] Iteration 53200 (27.6662 iter/s, 3.61452s/100 iters), loss = 0.129678
I0628 20:16:27.579464  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:16:27.579464  1232 solver.cpp:237]     Train net output #1: loss = 0.129679 (* 1 = 0.129679 loss)
I0628 20:16:27.579464  1232 sgd_solver.cpp:105] Iteration 53200, lr = 0.0001
I0628 20:16:31.262143  1232 solver.cpp:218] Iteration 53300 (27.1575 iter/s, 3.68222s/100 iters), loss = 0.094202
I0628 20:16:31.262143  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:16:31.262143  1232 solver.cpp:237]     Train net output #1: loss = 0.0942028 (* 1 = 0.0942028 loss)
I0628 20:16:31.262143  1232 sgd_solver.cpp:105] Iteration 53300, lr = 0.0001
I0628 20:16:34.898849  1232 solver.cpp:218] Iteration 53400 (27.4962 iter/s, 3.63687s/100 iters), loss = 0.045264
I0628 20:16:34.898849  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:16:34.898849  1232 solver.cpp:237]     Train net output #1: loss = 0.0452649 (* 1 = 0.0452649 loss)
I0628 20:16:34.898849  1232 sgd_solver.cpp:105] Iteration 53400, lr = 0.0001
I0628 20:16:38.320142 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:16:38.459765  1232 solver.cpp:330] Iteration 53500, Testing net (#0)
I0628 20:16:38.459765  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:16:39.283320 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:16:39.315343  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8948
I0628 20:16:39.315343  1232 solver.cpp:397]     Test net output #1: loss = 0.362611 (* 1 = 0.362611 loss)
I0628 20:16:39.350400  1232 solver.cpp:218] Iteration 53500 (22.467 iter/s, 4.45098s/100 iters), loss = 0.0694284
I0628 20:16:39.350400  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:16:39.350400  1232 solver.cpp:237]     Train net output #1: loss = 0.0694292 (* 1 = 0.0694292 loss)
I0628 20:16:39.350400  1232 sgd_solver.cpp:105] Iteration 53500, lr = 0.0001
I0628 20:16:42.966708  1232 solver.cpp:218] Iteration 53600 (27.6602 iter/s, 3.61531s/100 iters), loss = 0.150747
I0628 20:16:42.966708  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:16:42.966708  1232 solver.cpp:237]     Train net output #1: loss = 0.150748 (* 1 = 0.150748 loss)
I0628 20:16:42.966708  1232 sgd_solver.cpp:105] Iteration 53600, lr = 0.0001
I0628 20:16:46.572409  1232 solver.cpp:218] Iteration 53700 (27.7361 iter/s, 3.60541s/100 iters), loss = 0.130044
I0628 20:16:46.572409  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:16:46.572409  1232 solver.cpp:237]     Train net output #1: loss = 0.130045 (* 1 = 0.130045 loss)
I0628 20:16:46.572409  1232 sgd_solver.cpp:105] Iteration 53700, lr = 0.0001
I0628 20:16:50.271637  1232 solver.cpp:218] Iteration 53800 (27.0363 iter/s, 3.69873s/100 iters), loss = 0.116641
I0628 20:16:50.271637  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:16:50.271637  1232 solver.cpp:237]     Train net output #1: loss = 0.116641 (* 1 = 0.116641 loss)
I0628 20:16:50.271637  1232 sgd_solver.cpp:105] Iteration 53800, lr = 0.0001
I0628 20:16:53.984419  1232 solver.cpp:218] Iteration 53900 (26.9304 iter/s, 3.71327s/100 iters), loss = 0.060427
I0628 20:16:53.984419  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:16:53.984419  1232 solver.cpp:237]     Train net output #1: loss = 0.0604279 (* 1 = 0.0604279 loss)
I0628 20:16:53.984419  1232 sgd_solver.cpp:105] Iteration 53900, lr = 0.0001
I0628 20:16:57.500691 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:16:57.640782  1232 solver.cpp:330] Iteration 54000, Testing net (#0)
I0628 20:16:57.640782  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:16:58.468439 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:16:58.499694  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I0628 20:16:58.499694  1232 solver.cpp:397]     Test net output #1: loss = 0.36453 (* 1 = 0.36453 loss)
I0628 20:16:58.533716  1232 solver.cpp:218] Iteration 54000 (21.9867 iter/s, 4.54821s/100 iters), loss = 0.0703642
I0628 20:16:58.533716  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:16:58.533716  1232 solver.cpp:237]     Train net output #1: loss = 0.0703651 (* 1 = 0.0703651 loss)
I0628 20:16:58.533716  1232 sgd_solver.cpp:46] MultiStep Status: Iteration 54000, step = 3
I0628 20:16:58.533716  1232 sgd_solver.cpp:105] Iteration 54000, lr = 1e-05
I0628 20:17:02.184623  1232 solver.cpp:218] Iteration 54100 (27.3883 iter/s, 3.65119s/100 iters), loss = 0.143136
I0628 20:17:02.184623  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:17:02.184623  1232 solver.cpp:237]     Train net output #1: loss = 0.143137 (* 1 = 0.143137 loss)
I0628 20:17:02.184623  1232 sgd_solver.cpp:105] Iteration 54100, lr = 1e-05
I0628 20:17:05.898383  1232 solver.cpp:218] Iteration 54200 (26.9325 iter/s, 3.71299s/100 iters), loss = 0.119713
I0628 20:17:05.898383  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:17:05.898383  1232 solver.cpp:237]     Train net output #1: loss = 0.119714 (* 1 = 0.119714 loss)
I0628 20:17:05.898383  1232 sgd_solver.cpp:105] Iteration 54200, lr = 1e-05
I0628 20:17:09.541406  1232 solver.cpp:218] Iteration 54300 (27.4499 iter/s, 3.643s/100 iters), loss = 0.0889312
I0628 20:17:09.541406  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:17:09.541406  1232 solver.cpp:237]     Train net output #1: loss = 0.0889321 (* 1 = 0.0889321 loss)
I0628 20:17:09.541406  1232 sgd_solver.cpp:105] Iteration 54300, lr = 1e-05
I0628 20:17:13.179499  1232 solver.cpp:218] Iteration 54400 (27.4931 iter/s, 3.63727s/100 iters), loss = 0.0882905
I0628 20:17:13.179499  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:17:13.179499  1232 solver.cpp:237]     Train net output #1: loss = 0.0882914 (* 1 = 0.0882914 loss)
I0628 20:17:13.179499  1232 sgd_solver.cpp:105] Iteration 54400, lr = 1e-05
I0628 20:17:16.665928 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:17:16.808080  1232 solver.cpp:330] Iteration 54500, Testing net (#0)
I0628 20:17:16.808080  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:17:17.639561 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:17:17.670579  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8941
I0628 20:17:17.670579  1232 solver.cpp:397]     Test net output #1: loss = 0.363966 (* 1 = 0.363966 loss)
I0628 20:17:17.704787  1232 solver.cpp:218] Iteration 54500 (22.0968 iter/s, 4.52554s/100 iters), loss = 0.0523539
I0628 20:17:17.704787  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:17:17.704787  1232 solver.cpp:237]     Train net output #1: loss = 0.0523547 (* 1 = 0.0523547 loss)
I0628 20:17:17.704787  1232 sgd_solver.cpp:105] Iteration 54500, lr = 1e-05
I0628 20:17:21.349345  1232 solver.cpp:218] Iteration 54600 (27.4457 iter/s, 3.64356s/100 iters), loss = 0.141195
I0628 20:17:21.349345  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:17:21.349345  1232 solver.cpp:237]     Train net output #1: loss = 0.141196 (* 1 = 0.141196 loss)
I0628 20:17:21.349345  1232 sgd_solver.cpp:105] Iteration 54600, lr = 1e-05
I0628 20:17:25.087766  1232 solver.cpp:218] Iteration 54700 (26.7531 iter/s, 3.73789s/100 iters), loss = 0.148785
I0628 20:17:25.087766  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:17:25.087766  1232 solver.cpp:237]     Train net output #1: loss = 0.148786 (* 1 = 0.148786 loss)
I0628 20:17:25.087766  1232 sgd_solver.cpp:105] Iteration 54700, lr = 1e-05
I0628 20:17:28.787889  1232 solver.cpp:218] Iteration 54800 (27.0297 iter/s, 3.69964s/100 iters), loss = 0.0990402
I0628 20:17:28.787889  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:17:28.787889  1232 solver.cpp:237]     Train net output #1: loss = 0.0990411 (* 1 = 0.0990411 loss)
I0628 20:17:28.787889  1232 sgd_solver.cpp:105] Iteration 54800, lr = 1e-05
I0628 20:17:32.418478  1232 solver.cpp:218] Iteration 54900 (27.5409 iter/s, 3.63097s/100 iters), loss = 0.0520375
I0628 20:17:32.418478  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:17:32.418478  1232 solver.cpp:237]     Train net output #1: loss = 0.0520384 (* 1 = 0.0520384 loss)
I0628 20:17:32.418478  1232 sgd_solver.cpp:105] Iteration 54900, lr = 1e-05
I0628 20:17:35.888442 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:17:36.033924  1232 solver.cpp:330] Iteration 55000, Testing net (#0)
I0628 20:17:36.033924  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:17:36.873324 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:17:36.904862  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I0628 20:17:36.904862  1232 solver.cpp:397]     Test net output #1: loss = 0.364046 (* 1 = 0.364046 loss)
I0628 20:17:36.938491  1232 solver.cpp:218] Iteration 55000 (22.1269 iter/s, 4.51938s/100 iters), loss = 0.123026
I0628 20:17:36.938491  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:17:36.938491  1232 solver.cpp:237]     Train net output #1: loss = 0.123027 (* 1 = 0.123027 loss)
I0628 20:17:36.938491  1232 sgd_solver.cpp:105] Iteration 55000, lr = 1e-05
I0628 20:17:40.540555  1232 solver.cpp:218] Iteration 55100 (27.7646 iter/s, 3.60171s/100 iters), loss = 0.185188
I0628 20:17:40.540555  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:17:40.540555  1232 solver.cpp:237]     Train net output #1: loss = 0.185188 (* 1 = 0.185188 loss)
I0628 20:17:40.540555  1232 sgd_solver.cpp:105] Iteration 55100, lr = 1e-05
I0628 20:17:44.157652  1232 solver.cpp:218] Iteration 55200 (27.6493 iter/s, 3.61673s/100 iters), loss = 0.133851
I0628 20:17:44.157652  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:17:44.157652  1232 solver.cpp:237]     Train net output #1: loss = 0.133852 (* 1 = 0.133852 loss)
I0628 20:17:44.157652  1232 sgd_solver.cpp:105] Iteration 55200, lr = 1e-05
I0628 20:17:47.750334  1232 solver.cpp:218] Iteration 55300 (27.8396 iter/s, 3.59201s/100 iters), loss = 0.115797
I0628 20:17:47.750334  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:17:47.750334  1232 solver.cpp:237]     Train net output #1: loss = 0.115798 (* 1 = 0.115798 loss)
I0628 20:17:47.750334  1232 sgd_solver.cpp:105] Iteration 55300, lr = 1e-05
I0628 20:17:51.431105  1232 solver.cpp:218] Iteration 55400 (27.1673 iter/s, 3.68089s/100 iters), loss = 0.0975575
I0628 20:17:51.431105  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:17:51.431105  1232 solver.cpp:237]     Train net output #1: loss = 0.0975585 (* 1 = 0.0975585 loss)
I0628 20:17:51.431105  1232 sgd_solver.cpp:105] Iteration 55400, lr = 1e-05
I0628 20:17:54.932768 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:17:55.072871  1232 solver.cpp:330] Iteration 55500, Testing net (#0)
I0628 20:17:55.072871  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:17:55.899240 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:17:55.930781  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8949
I0628 20:17:55.930781  1232 solver.cpp:397]     Test net output #1: loss = 0.36365 (* 1 = 0.36365 loss)
I0628 20:17:55.965804  1232 solver.cpp:218] Iteration 55500 (22.0539 iter/s, 4.53434s/100 iters), loss = 0.0947821
I0628 20:17:55.965804  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:17:55.965804  1232 solver.cpp:237]     Train net output #1: loss = 0.0947831 (* 1 = 0.0947831 loss)
I0628 20:17:55.965804  1232 sgd_solver.cpp:105] Iteration 55500, lr = 1e-05
I0628 20:17:59.602385  1232 solver.cpp:218] Iteration 55600 (27.5006 iter/s, 3.63628s/100 iters), loss = 0.131442
I0628 20:17:59.602385  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:17:59.602385  1232 solver.cpp:237]     Train net output #1: loss = 0.131443 (* 1 = 0.131443 loss)
I0628 20:17:59.602385  1232 sgd_solver.cpp:105] Iteration 55600, lr = 1e-05
I0628 20:18:03.207059  1232 solver.cpp:218] Iteration 55700 (27.7502 iter/s, 3.60357s/100 iters), loss = 0.142346
I0628 20:18:03.207059  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:18:03.207059  1232 solver.cpp:237]     Train net output #1: loss = 0.142347 (* 1 = 0.142347 loss)
I0628 20:18:03.207059  1232 sgd_solver.cpp:105] Iteration 55700, lr = 1e-05
I0628 20:18:06.796717  1232 solver.cpp:218] Iteration 55800 (27.8555 iter/s, 3.58995s/100 iters), loss = 0.0966916
I0628 20:18:06.796717  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:18:06.796717  1232 solver.cpp:237]     Train net output #1: loss = 0.0966924 (* 1 = 0.0966924 loss)
I0628 20:18:06.796717  1232 sgd_solver.cpp:105] Iteration 55800, lr = 1e-05
I0628 20:18:10.407606  1232 solver.cpp:218] Iteration 55900 (27.6951 iter/s, 3.61075s/100 iters), loss = 0.117943
I0628 20:18:10.408607  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:18:10.408607  1232 solver.cpp:237]     Train net output #1: loss = 0.117944 (* 1 = 0.117944 loss)
I0628 20:18:10.408607  1232 sgd_solver.cpp:105] Iteration 55900, lr = 1e-05
I0628 20:18:13.833279 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:18:13.974400  1232 solver.cpp:330] Iteration 56000, Testing net (#0)
I0628 20:18:13.974400  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:18:14.795205 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:18:14.825726  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8954
I0628 20:18:14.825726  1232 solver.cpp:397]     Test net output #1: loss = 0.364145 (* 1 = 0.364145 loss)
I0628 20:18:14.859760  1232 solver.cpp:218] Iteration 56000 (22.463 iter/s, 4.45177s/100 iters), loss = 0.0608242
I0628 20:18:14.859760  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:18:14.860760  1232 solver.cpp:237]     Train net output #1: loss = 0.0608251 (* 1 = 0.0608251 loss)
I0628 20:18:14.860760  1232 sgd_solver.cpp:105] Iteration 56000, lr = 1e-05
I0628 20:18:18.459064  1232 solver.cpp:218] Iteration 56100 (27.7912 iter/s, 3.59826s/100 iters), loss = 0.16568
I0628 20:18:18.459064  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:18:18.459064  1232 solver.cpp:237]     Train net output #1: loss = 0.165681 (* 1 = 0.165681 loss)
I0628 20:18:18.459064  1232 sgd_solver.cpp:105] Iteration 56100, lr = 1e-05
I0628 20:18:22.062263  1232 solver.cpp:218] Iteration 56200 (27.7523 iter/s, 3.60331s/100 iters), loss = 0.152464
I0628 20:18:22.062263  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:18:22.062263  1232 solver.cpp:237]     Train net output #1: loss = 0.152465 (* 1 = 0.152465 loss)
I0628 20:18:22.062263  1232 sgd_solver.cpp:105] Iteration 56200, lr = 1e-05
I0628 20:18:25.658675  1232 solver.cpp:218] Iteration 56300 (27.8064 iter/s, 3.59629s/100 iters), loss = 0.208783
I0628 20:18:25.658675  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:18:25.659677  1232 solver.cpp:237]     Train net output #1: loss = 0.208784 (* 1 = 0.208784 loss)
I0628 20:18:25.659677  1232 sgd_solver.cpp:105] Iteration 56300, lr = 1e-05
I0628 20:18:29.268712  1232 solver.cpp:218] Iteration 56400 (27.7078 iter/s, 3.60909s/100 iters), loss = 0.0566205
I0628 20:18:29.268712  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:18:29.268712  1232 solver.cpp:237]     Train net output #1: loss = 0.0566212 (* 1 = 0.0566212 loss)
I0628 20:18:29.268712  1232 sgd_solver.cpp:105] Iteration 56400, lr = 1e-05
I0628 20:18:32.700110 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:18:32.845718  1232 solver.cpp:330] Iteration 56500, Testing net (#0)
I0628 20:18:32.845718  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:18:33.661608 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:18:33.691630  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8953
I0628 20:18:33.692631  1232 solver.cpp:397]     Test net output #1: loss = 0.363926 (* 1 = 0.363926 loss)
I0628 20:18:33.726655  1232 solver.cpp:218] Iteration 56500 (22.435 iter/s, 4.45733s/100 iters), loss = 0.0741627
I0628 20:18:33.726655  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:18:33.726655  1232 solver.cpp:237]     Train net output #1: loss = 0.0741635 (* 1 = 0.0741635 loss)
I0628 20:18:33.726655  1232 sgd_solver.cpp:105] Iteration 56500, lr = 1e-05
I0628 20:18:37.321557  1232 solver.cpp:218] Iteration 56600 (27.8148 iter/s, 3.59521s/100 iters), loss = 0.159419
I0628 20:18:37.321557  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:18:37.321557  1232 solver.cpp:237]     Train net output #1: loss = 0.159419 (* 1 = 0.159419 loss)
I0628 20:18:37.321557  1232 sgd_solver.cpp:105] Iteration 56600, lr = 1e-05
I0628 20:18:40.910192  1232 solver.cpp:218] Iteration 56700 (27.8672 iter/s, 3.58845s/100 iters), loss = 0.0732771
I0628 20:18:40.911193  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:18:40.911193  1232 solver.cpp:237]     Train net output #1: loss = 0.0732779 (* 1 = 0.0732779 loss)
I0628 20:18:40.911193  1232 sgd_solver.cpp:105] Iteration 56700, lr = 1e-05
I0628 20:18:44.499863  1232 solver.cpp:218] Iteration 56800 (27.8682 iter/s, 3.58832s/100 iters), loss = 0.0979009
I0628 20:18:44.499863  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:18:44.499863  1232 solver.cpp:237]     Train net output #1: loss = 0.0979016 (* 1 = 0.0979016 loss)
I0628 20:18:44.499863  1232 sgd_solver.cpp:105] Iteration 56800, lr = 1e-05
I0628 20:18:48.094769  1232 solver.cpp:218] Iteration 56900 (27.8169 iter/s, 3.59494s/100 iters), loss = 0.0558991
I0628 20:18:48.094769  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:18:48.094769  1232 solver.cpp:237]     Train net output #1: loss = 0.0558998 (* 1 = 0.0558998 loss)
I0628 20:18:48.094769  1232 sgd_solver.cpp:105] Iteration 56900, lr = 1e-05
I0628 20:18:51.519049 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:18:51.659700  1232 solver.cpp:330] Iteration 57000, Testing net (#0)
I0628 20:18:51.659700  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:18:52.476030 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:18:52.507066  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I0628 20:18:52.507066  1232 solver.cpp:397]     Test net output #1: loss = 0.364085 (* 1 = 0.364085 loss)
I0628 20:18:52.541090  1232 solver.cpp:218] Iteration 57000 (22.4922 iter/s, 4.44599s/100 iters), loss = 0.0810484
I0628 20:18:52.541090  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:18:52.541090  1232 solver.cpp:237]     Train net output #1: loss = 0.0810491 (* 1 = 0.0810491 loss)
I0628 20:18:52.541090  1232 sgd_solver.cpp:105] Iteration 57000, lr = 1e-05
I0628 20:18:56.148254  1232 solver.cpp:218] Iteration 57100 (27.7209 iter/s, 3.60739s/100 iters), loss = 0.148392
I0628 20:18:56.149255  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:18:56.149255  1232 solver.cpp:237]     Train net output #1: loss = 0.148392 (* 1 = 0.148392 loss)
I0628 20:18:56.149255  1232 sgd_solver.cpp:105] Iteration 57100, lr = 1e-05
I0628 20:18:59.758970  1232 solver.cpp:218] Iteration 57200 (27.6994 iter/s, 3.61019s/100 iters), loss = 0.101248
I0628 20:18:59.758970  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:18:59.758970  1232 solver.cpp:237]     Train net output #1: loss = 0.101248 (* 1 = 0.101248 loss)
I0628 20:18:59.758970  1232 sgd_solver.cpp:105] Iteration 57200, lr = 1e-05
I0628 20:19:03.362303  1232 solver.cpp:218] Iteration 57300 (27.7576 iter/s, 3.60261s/100 iters), loss = 0.117491
I0628 20:19:03.362303  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:19:03.362303  1232 solver.cpp:237]     Train net output #1: loss = 0.117492 (* 1 = 0.117492 loss)
I0628 20:19:03.362303  1232 sgd_solver.cpp:105] Iteration 57300, lr = 1e-05
I0628 20:19:06.964892  1232 solver.cpp:218] Iteration 57400 (27.7621 iter/s, 3.60204s/100 iters), loss = 0.102941
I0628 20:19:06.964892  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:19:06.964892  1232 solver.cpp:237]     Train net output #1: loss = 0.102942 (* 1 = 0.102942 loss)
I0628 20:19:06.964892  1232 sgd_solver.cpp:105] Iteration 57400, lr = 1e-05
I0628 20:19:10.401247 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:19:10.542362  1232 solver.cpp:330] Iteration 57500, Testing net (#0)
I0628 20:19:10.542362  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:19:11.355173 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:19:11.386212  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8947
I0628 20:19:11.386212  1232 solver.cpp:397]     Test net output #1: loss = 0.363442 (* 1 = 0.363442 loss)
I0628 20:19:11.419261  1232 solver.cpp:218] Iteration 57500 (22.4483 iter/s, 4.45468s/100 iters), loss = 0.0644232
I0628 20:19:11.419261  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:19:11.419261  1232 solver.cpp:237]     Train net output #1: loss = 0.0644239 (* 1 = 0.0644239 loss)
I0628 20:19:11.419261  1232 sgd_solver.cpp:105] Iteration 57500, lr = 1e-05
I0628 20:19:15.023308  1232 solver.cpp:218] Iteration 57600 (27.7501 iter/s, 3.6036s/100 iters), loss = 0.130351
I0628 20:19:15.023308  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:19:15.023308  1232 solver.cpp:237]     Train net output #1: loss = 0.130351 (* 1 = 0.130351 loss)
I0628 20:19:15.023308  1232 sgd_solver.cpp:105] Iteration 57600, lr = 1e-05
I0628 20:19:18.632694  1232 solver.cpp:218] Iteration 57700 (27.7121 iter/s, 3.60854s/100 iters), loss = 0.140809
I0628 20:19:18.632694  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:19:18.632694  1232 solver.cpp:237]     Train net output #1: loss = 0.14081 (* 1 = 0.14081 loss)
I0628 20:19:18.632694  1232 sgd_solver.cpp:105] Iteration 57700, lr = 1e-05
I0628 20:19:22.244680  1232 solver.cpp:218] Iteration 57800 (27.6898 iter/s, 3.61143s/100 iters), loss = 0.14134
I0628 20:19:22.244680  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:19:22.244680  1232 solver.cpp:237]     Train net output #1: loss = 0.141341 (* 1 = 0.141341 loss)
I0628 20:19:22.244680  1232 sgd_solver.cpp:105] Iteration 57800, lr = 1e-05
I0628 20:19:25.863010  1232 solver.cpp:218] Iteration 57900 (27.6403 iter/s, 3.61791s/100 iters), loss = 0.0674231
I0628 20:19:25.863010  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:19:25.863010  1232 solver.cpp:237]     Train net output #1: loss = 0.0674238 (* 1 = 0.0674238 loss)
I0628 20:19:25.863010  1232 sgd_solver.cpp:105] Iteration 57900, lr = 1e-05
I0628 20:19:29.279898 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:19:29.421617  1232 solver.cpp:330] Iteration 58000, Testing net (#0)
I0628 20:19:29.421617  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:19:30.237591 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:19:30.268616  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8948
I0628 20:19:30.268616  1232 solver.cpp:397]     Test net output #1: loss = 0.363587 (* 1 = 0.363587 loss)
I0628 20:19:30.303169  1232 solver.cpp:218] Iteration 58000 (22.5214 iter/s, 4.44023s/100 iters), loss = 0.0565282
I0628 20:19:30.303670  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:19:30.303670  1232 solver.cpp:237]     Train net output #1: loss = 0.0565289 (* 1 = 0.0565289 loss)
I0628 20:19:30.303670  1232 sgd_solver.cpp:105] Iteration 58000, lr = 1e-05
I0628 20:19:33.903748  1232 solver.cpp:218] Iteration 58100 (27.778 iter/s, 3.59997s/100 iters), loss = 0.142784
I0628 20:19:33.903748  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:19:33.903748  1232 solver.cpp:237]     Train net output #1: loss = 0.142785 (* 1 = 0.142785 loss)
I0628 20:19:33.903748  1232 sgd_solver.cpp:105] Iteration 58100, lr = 1e-05
I0628 20:19:37.491431  1232 solver.cpp:218] Iteration 58200 (27.8721 iter/s, 3.58781s/100 iters), loss = 0.10223
I0628 20:19:37.491431  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:19:37.491431  1232 solver.cpp:237]     Train net output #1: loss = 0.102231 (* 1 = 0.102231 loss)
I0628 20:19:37.491431  1232 sgd_solver.cpp:105] Iteration 58200, lr = 1e-05
I0628 20:19:41.084166  1232 solver.cpp:218] Iteration 58300 (27.8366 iter/s, 3.5924s/100 iters), loss = 0.119309
I0628 20:19:41.084166  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:19:41.084166  1232 solver.cpp:237]     Train net output #1: loss = 0.11931 (* 1 = 0.11931 loss)
I0628 20:19:41.084166  1232 sgd_solver.cpp:105] Iteration 58300, lr = 1e-05
I0628 20:19:44.676792  1232 solver.cpp:218] Iteration 58400 (27.8383 iter/s, 3.59218s/100 iters), loss = 0.123663
I0628 20:19:44.676792  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:19:44.676792  1232 solver.cpp:237]     Train net output #1: loss = 0.123664 (* 1 = 0.123664 loss)
I0628 20:19:44.676792  1232 sgd_solver.cpp:105] Iteration 58400, lr = 1e-05
I0628 20:19:48.094391 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:19:48.234498  1232 solver.cpp:330] Iteration 58500, Testing net (#0)
I0628 20:19:48.234498  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:19:49.049105 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:19:49.080127  1232 solver.cpp:397]     Test net output #0: accuracy = 0.895
I0628 20:19:49.080127  1232 solver.cpp:397]     Test net output #1: loss = 0.364377 (* 1 = 0.364377 loss)
I0628 20:19:49.114653  1232 solver.cpp:218] Iteration 58500 (22.5374 iter/s, 4.43707s/100 iters), loss = 0.0740004
I0628 20:19:49.114653  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:19:49.114653  1232 solver.cpp:237]     Train net output #1: loss = 0.074001 (* 1 = 0.074001 loss)
I0628 20:19:49.114653  1232 sgd_solver.cpp:105] Iteration 58500, lr = 1e-05
I0628 20:19:52.717507  1232 solver.cpp:218] Iteration 58600 (27.7567 iter/s, 3.60274s/100 iters), loss = 0.142305
I0628 20:19:52.717507  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:19:52.717507  1232 solver.cpp:237]     Train net output #1: loss = 0.142306 (* 1 = 0.142306 loss)
I0628 20:19:52.717507  1232 sgd_solver.cpp:105] Iteration 58600, lr = 1e-05
I0628 20:19:56.318014  1232 solver.cpp:218] Iteration 58700 (27.7732 iter/s, 3.60059s/100 iters), loss = 0.119658
I0628 20:19:56.318014  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:19:56.318014  1232 solver.cpp:237]     Train net output #1: loss = 0.119659 (* 1 = 0.119659 loss)
I0628 20:19:56.318014  1232 sgd_solver.cpp:105] Iteration 58700, lr = 1e-05
I0628 20:19:59.916900  1232 solver.cpp:218] Iteration 58800 (27.7911 iter/s, 3.59827s/100 iters), loss = 0.161829
I0628 20:19:59.916900  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:19:59.916900  1232 solver.cpp:237]     Train net output #1: loss = 0.161829 (* 1 = 0.161829 loss)
I0628 20:19:59.916900  1232 sgd_solver.cpp:105] Iteration 58800, lr = 1e-05
I0628 20:20:03.522034  1232 solver.cpp:218] Iteration 58900 (27.7398 iter/s, 3.60493s/100 iters), loss = 0.093019
I0628 20:20:03.522034  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:20:03.522034  1232 solver.cpp:237]     Train net output #1: loss = 0.0930196 (* 1 = 0.0930196 loss)
I0628 20:20:03.522034  1232 sgd_solver.cpp:105] Iteration 58900, lr = 1e-05
I0628 20:20:06.944145 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:20:07.084264  1232 solver.cpp:330] Iteration 59000, Testing net (#0)
I0628 20:20:07.084264  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:20:07.903700 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:20:07.933717  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8954
I0628 20:20:07.933717  1232 solver.cpp:397]     Test net output #1: loss = 0.363842 (* 1 = 0.363842 loss)
I0628 20:20:07.968758  1232 solver.cpp:218] Iteration 59000 (22.4923 iter/s, 4.44596s/100 iters), loss = 0.0762748
I0628 20:20:07.968758  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:20:07.968758  1232 solver.cpp:237]     Train net output #1: loss = 0.0762754 (* 1 = 0.0762754 loss)
I0628 20:20:07.968758  1232 sgd_solver.cpp:105] Iteration 59000, lr = 1e-05
I0628 20:20:11.555603  1232 solver.cpp:218] Iteration 59100 (27.8812 iter/s, 3.58665s/100 iters), loss = 0.148675
I0628 20:20:11.555603  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:20:11.555603  1232 solver.cpp:237]     Train net output #1: loss = 0.148676 (* 1 = 0.148676 loss)
I0628 20:20:11.555603  1232 sgd_solver.cpp:105] Iteration 59100, lr = 1e-05
I0628 20:20:15.148052  1232 solver.cpp:218] Iteration 59200 (27.8405 iter/s, 3.5919s/100 iters), loss = 0.141459
I0628 20:20:15.148052  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:20:15.148052  1232 solver.cpp:237]     Train net output #1: loss = 0.141459 (* 1 = 0.141459 loss)
I0628 20:20:15.148052  1232 sgd_solver.cpp:105] Iteration 59200, lr = 1e-05
I0628 20:20:18.735805  1232 solver.cpp:218] Iteration 59300 (27.8725 iter/s, 3.58777s/100 iters), loss = 0.134657
I0628 20:20:18.735805  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:20:18.735805  1232 solver.cpp:237]     Train net output #1: loss = 0.134658 (* 1 = 0.134658 loss)
I0628 20:20:18.735805  1232 sgd_solver.cpp:105] Iteration 59300, lr = 1e-05
I0628 20:20:22.329486  1232 solver.cpp:218] Iteration 59400 (27.8315 iter/s, 3.59306s/100 iters), loss = 0.125542
I0628 20:20:22.329486  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:20:22.329486  1232 solver.cpp:237]     Train net output #1: loss = 0.125543 (* 1 = 0.125543 loss)
I0628 20:20:22.329486  1232 sgd_solver.cpp:105] Iteration 59400, lr = 1e-05
I0628 20:20:25.739971 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:20:25.879854  1232 solver.cpp:330] Iteration 59500, Testing net (#0)
I0628 20:20:25.879854  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:20:26.693490 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:20:26.724022  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8951
I0628 20:20:26.724022  1232 solver.cpp:397]     Test net output #1: loss = 0.363881 (* 1 = 0.363881 loss)
I0628 20:20:26.758049  1232 solver.cpp:218] Iteration 59500 (22.5809 iter/s, 4.42851s/100 iters), loss = 0.0816021
I0628 20:20:26.758049  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:20:26.758049  1232 solver.cpp:237]     Train net output #1: loss = 0.0816027 (* 1 = 0.0816027 loss)
I0628 20:20:26.758049  1232 sgd_solver.cpp:105] Iteration 59500, lr = 1e-05
I0628 20:20:30.355294  1232 solver.cpp:218] Iteration 59600 (27.8031 iter/s, 3.59672s/100 iters), loss = 0.134198
I0628 20:20:30.355294  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:20:30.355294  1232 solver.cpp:237]     Train net output #1: loss = 0.134199 (* 1 = 0.134199 loss)
I0628 20:20:30.355294  1232 sgd_solver.cpp:105] Iteration 59600, lr = 1e-05
I0628 20:20:33.955384  1232 solver.cpp:218] Iteration 59700 (27.7809 iter/s, 3.5996s/100 iters), loss = 0.109852
I0628 20:20:33.955384  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:20:33.955384  1232 solver.cpp:237]     Train net output #1: loss = 0.109853 (* 1 = 0.109853 loss)
I0628 20:20:33.955384  1232 sgd_solver.cpp:105] Iteration 59700, lr = 1e-05
I0628 20:20:37.561653  1232 solver.cpp:218] Iteration 59800 (27.7334 iter/s, 3.60576s/100 iters), loss = 0.120767
I0628 20:20:37.561653  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:20:37.561653  1232 solver.cpp:237]     Train net output #1: loss = 0.120768 (* 1 = 0.120768 loss)
I0628 20:20:37.561653  1232 sgd_solver.cpp:105] Iteration 59800, lr = 1e-05
I0628 20:20:41.159394  1232 solver.cpp:218] Iteration 59900 (27.7964 iter/s, 3.59759s/100 iters), loss = 0.16156
I0628 20:20:41.159394  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:20:41.159394  1232 solver.cpp:237]     Train net output #1: loss = 0.161561 (* 1 = 0.161561 loss)
I0628 20:20:41.159394  1232 sgd_solver.cpp:105] Iteration 59900, lr = 1e-05
I0628 20:20:44.576812 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:20:44.717012  1232 solver.cpp:330] Iteration 60000, Testing net (#0)
I0628 20:20:44.717012  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:20:45.531041 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:20:45.562064  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8947
I0628 20:20:45.562064  1232 solver.cpp:397]     Test net output #1: loss = 0.364396 (* 1 = 0.364396 loss)
I0628 20:20:45.596119  1232 solver.cpp:218] Iteration 60000 (22.5405 iter/s, 4.43645s/100 iters), loss = 0.0787823
I0628 20:20:45.596119  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:20:45.596119  1232 solver.cpp:237]     Train net output #1: loss = 0.078783 (* 1 = 0.078783 loss)
I0628 20:20:45.596119  1232 sgd_solver.cpp:105] Iteration 60000, lr = 1e-05
I0628 20:20:49.178675  1232 solver.cpp:218] Iteration 60100 (27.9117 iter/s, 3.58272s/100 iters), loss = 0.204498
I0628 20:20:49.179677  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0628 20:20:49.179677  1232 solver.cpp:237]     Train net output #1: loss = 0.204499 (* 1 = 0.204499 loss)
I0628 20:20:49.179677  1232 sgd_solver.cpp:105] Iteration 60100, lr = 1e-05
I0628 20:20:52.776324  1232 solver.cpp:218] Iteration 60200 (27.7992 iter/s, 3.59723s/100 iters), loss = 0.184379
I0628 20:20:52.776324  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:20:52.776324  1232 solver.cpp:237]     Train net output #1: loss = 0.18438 (* 1 = 0.18438 loss)
I0628 20:20:52.776324  1232 sgd_solver.cpp:105] Iteration 60200, lr = 1e-05
I0628 20:20:56.366763  1232 solver.cpp:218] Iteration 60300 (27.8609 iter/s, 3.58926s/100 iters), loss = 0.131139
I0628 20:20:56.366763  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:20:56.366763  1232 solver.cpp:237]     Train net output #1: loss = 0.13114 (* 1 = 0.13114 loss)
I0628 20:20:56.366763  1232 sgd_solver.cpp:105] Iteration 60300, lr = 1e-05
I0628 20:20:59.951488  1232 solver.cpp:218] Iteration 60400 (27.895 iter/s, 3.58488s/100 iters), loss = 0.0770515
I0628 20:20:59.951488  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:20:59.951488  1232 solver.cpp:237]     Train net output #1: loss = 0.0770522 (* 1 = 0.0770522 loss)
I0628 20:20:59.951488  1232 sgd_solver.cpp:105] Iteration 60400, lr = 1e-05
I0628 20:21:03.368894 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:21:03.510010  1232 solver.cpp:330] Iteration 60500, Testing net (#0)
I0628 20:21:03.510010  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:21:04.332181 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:21:04.354706  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8951
I0628 20:21:04.354706  1232 solver.cpp:397]     Test net output #1: loss = 0.363665 (* 1 = 0.363665 loss)
I0628 20:21:04.389731  1232 solver.cpp:218] Iteration 60500 (22.5348 iter/s, 4.43759s/100 iters), loss = 0.1144
I0628 20:21:04.389731  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:21:04.389731  1232 solver.cpp:237]     Train net output #1: loss = 0.114401 (* 1 = 0.114401 loss)
I0628 20:21:04.389731  1232 sgd_solver.cpp:105] Iteration 60500, lr = 1e-05
I0628 20:21:07.972446  1232 solver.cpp:218] Iteration 60600 (27.9141 iter/s, 3.58242s/100 iters), loss = 0.174219
I0628 20:21:07.972446  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:21:07.972446  1232 solver.cpp:237]     Train net output #1: loss = 0.17422 (* 1 = 0.17422 loss)
I0628 20:21:07.972446  1232 sgd_solver.cpp:105] Iteration 60600, lr = 1e-05
I0628 20:21:11.553172  1232 solver.cpp:218] Iteration 60700 (27.9291 iter/s, 3.5805s/100 iters), loss = 0.0811253
I0628 20:21:11.553172  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:21:11.553172  1232 solver.cpp:237]     Train net output #1: loss = 0.081126 (* 1 = 0.081126 loss)
I0628 20:21:11.553172  1232 sgd_solver.cpp:105] Iteration 60700, lr = 1e-05
I0628 20:21:15.136582  1232 solver.cpp:218] Iteration 60800 (27.9083 iter/s, 3.58316s/100 iters), loss = 0.114733
I0628 20:21:15.136582  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:21:15.136582  1232 solver.cpp:237]     Train net output #1: loss = 0.114734 (* 1 = 0.114734 loss)
I0628 20:21:15.136582  1232 sgd_solver.cpp:105] Iteration 60800, lr = 1e-05
I0628 20:21:18.720191  1232 solver.cpp:218] Iteration 60900 (27.9096 iter/s, 3.583s/100 iters), loss = 0.0455703
I0628 20:21:18.720191  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:21:18.720191  1232 solver.cpp:237]     Train net output #1: loss = 0.045571 (* 1 = 0.045571 loss)
I0628 20:21:18.720191  1232 sgd_solver.cpp:105] Iteration 60900, lr = 1e-05
I0628 20:21:22.131495 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:21:22.271811  1232 solver.cpp:330] Iteration 61000, Testing net (#0)
I0628 20:21:22.271811  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:21:23.083112 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:21:23.114123  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8952
I0628 20:21:23.114123  1232 solver.cpp:397]     Test net output #1: loss = 0.363961 (* 1 = 0.363961 loss)
I0628 20:21:23.148207  1232 solver.cpp:218] Iteration 61000 (22.5847 iter/s, 4.42778s/100 iters), loss = 0.166179
I0628 20:21:23.148207  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:21:23.148207  1232 solver.cpp:237]     Train net output #1: loss = 0.16618 (* 1 = 0.16618 loss)
I0628 20:21:23.148207  1232 sgd_solver.cpp:105] Iteration 61000, lr = 1e-05
I0628 20:21:26.735572  1232 solver.cpp:218] Iteration 61100 (27.8778 iter/s, 3.58708s/100 iters), loss = 0.134327
I0628 20:21:26.735572  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:21:26.735572  1232 solver.cpp:237]     Train net output #1: loss = 0.134328 (* 1 = 0.134328 loss)
I0628 20:21:26.735572  1232 sgd_solver.cpp:105] Iteration 61100, lr = 1e-05
I0628 20:21:30.313391  1232 solver.cpp:218] Iteration 61200 (27.9524 iter/s, 3.57751s/100 iters), loss = 0.1114
I0628 20:21:30.313391  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:21:30.313391  1232 solver.cpp:237]     Train net output #1: loss = 0.111401 (* 1 = 0.111401 loss)
I0628 20:21:30.313391  1232 sgd_solver.cpp:105] Iteration 61200, lr = 1e-05
I0628 20:21:33.897984  1232 solver.cpp:218] Iteration 61300 (27.9006 iter/s, 3.58415s/100 iters), loss = 0.104096
I0628 20:21:33.897984  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:21:33.897984  1232 solver.cpp:237]     Train net output #1: loss = 0.104096 (* 1 = 0.104096 loss)
I0628 20:21:33.897984  1232 sgd_solver.cpp:105] Iteration 61300, lr = 1e-05
I0628 20:21:37.484030  1232 solver.cpp:218] Iteration 61400 (27.8833 iter/s, 3.58637s/100 iters), loss = 0.0669327
I0628 20:21:37.484030  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:21:37.484030  1232 solver.cpp:237]     Train net output #1: loss = 0.0669333 (* 1 = 0.0669333 loss)
I0628 20:21:37.484030  1232 sgd_solver.cpp:105] Iteration 61400, lr = 1e-05
I0628 20:21:40.893823 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:21:41.033740  1232 solver.cpp:330] Iteration 61500, Testing net (#0)
I0628 20:21:41.033740  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:21:41.853600 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:21:41.883615  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8949
I0628 20:21:41.883615  1232 solver.cpp:397]     Test net output #1: loss = 0.363974 (* 1 = 0.363974 loss)
I0628 20:21:41.917215  1232 solver.cpp:218] Iteration 61500 (22.5584 iter/s, 4.43293s/100 iters), loss = 0.139651
I0628 20:21:41.918216  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:21:41.918216  1232 solver.cpp:237]     Train net output #1: loss = 0.139651 (* 1 = 0.139651 loss)
I0628 20:21:41.918216  1232 sgd_solver.cpp:105] Iteration 61500, lr = 1e-05
I0628 20:21:45.507597  1232 solver.cpp:218] Iteration 61600 (27.8879 iter/s, 3.58578s/100 iters), loss = 0.137052
I0628 20:21:45.507597  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:21:45.507597  1232 solver.cpp:237]     Train net output #1: loss = 0.137053 (* 1 = 0.137053 loss)
I0628 20:21:45.507597  1232 sgd_solver.cpp:105] Iteration 61600, lr = 1e-05
I0628 20:21:49.098738  1232 solver.cpp:218] Iteration 61700 (27.8514 iter/s, 3.59048s/100 iters), loss = 0.151487
I0628 20:21:49.098738  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:21:49.098738  1232 solver.cpp:237]     Train net output #1: loss = 0.151487 (* 1 = 0.151487 loss)
I0628 20:21:49.098738  1232 sgd_solver.cpp:105] Iteration 61700, lr = 1e-05
I0628 20:21:52.688520  1232 solver.cpp:218] Iteration 61800 (27.8551 iter/s, 3.59001s/100 iters), loss = 0.131999
I0628 20:21:52.688520  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:21:52.688520  1232 solver.cpp:237]     Train net output #1: loss = 0.132 (* 1 = 0.132 loss)
I0628 20:21:52.688520  1232 sgd_solver.cpp:105] Iteration 61800, lr = 1e-05
I0628 20:21:56.288859  1232 solver.cpp:218] Iteration 61900 (27.7813 iter/s, 3.59954s/100 iters), loss = 0.0562232
I0628 20:21:56.288859  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:21:56.288859  1232 solver.cpp:237]     Train net output #1: loss = 0.0562238 (* 1 = 0.0562238 loss)
I0628 20:21:56.288859  1232 sgd_solver.cpp:105] Iteration 61900, lr = 1e-05
I0628 20:21:59.714654 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:21:59.855072  1232 solver.cpp:330] Iteration 62000, Testing net (#0)
I0628 20:21:59.855072  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:22:00.667845 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:22:00.698863  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8945
I0628 20:22:00.698863  1232 solver.cpp:397]     Test net output #1: loss = 0.363957 (* 1 = 0.363957 loss)
I0628 20:22:00.732908  1232 solver.cpp:218] Iteration 62000 (22.502 iter/s, 4.44405s/100 iters), loss = 0.10337
I0628 20:22:00.732908  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:22:00.732908  1232 solver.cpp:237]     Train net output #1: loss = 0.10337 (* 1 = 0.10337 loss)
I0628 20:22:00.732908  1232 sgd_solver.cpp:105] Iteration 62000, lr = 1e-05
I0628 20:22:04.343214  1232 solver.cpp:218] Iteration 62100 (27.7018 iter/s, 3.60988s/100 iters), loss = 0.166865
I0628 20:22:04.343214  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:22:04.343214  1232 solver.cpp:237]     Train net output #1: loss = 0.166865 (* 1 = 0.166865 loss)
I0628 20:22:04.343214  1232 sgd_solver.cpp:105] Iteration 62100, lr = 1e-05
I0628 20:22:07.948818  1232 solver.cpp:218] Iteration 62200 (27.7419 iter/s, 3.60466s/100 iters), loss = 0.121905
I0628 20:22:07.948818  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:22:07.948818  1232 solver.cpp:237]     Train net output #1: loss = 0.121906 (* 1 = 0.121906 loss)
I0628 20:22:07.948818  1232 sgd_solver.cpp:105] Iteration 62200, lr = 1e-05
I0628 20:22:11.538558  1232 solver.cpp:218] Iteration 62300 (27.8567 iter/s, 3.5898s/100 iters), loss = 0.109218
I0628 20:22:11.538558  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:22:11.538558  1232 solver.cpp:237]     Train net output #1: loss = 0.109219 (* 1 = 0.109219 loss)
I0628 20:22:11.538558  1232 sgd_solver.cpp:105] Iteration 62300, lr = 1e-05
I0628 20:22:15.123363  1232 solver.cpp:218] Iteration 62400 (27.901 iter/s, 3.5841s/100 iters), loss = 0.0659237
I0628 20:22:15.123363  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:22:15.123363  1232 solver.cpp:237]     Train net output #1: loss = 0.0659244 (* 1 = 0.0659244 loss)
I0628 20:22:15.123363  1232 sgd_solver.cpp:105] Iteration 62400, lr = 1e-05
I0628 20:22:18.540803 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:22:18.680970  1232 solver.cpp:330] Iteration 62500, Testing net (#0)
I0628 20:22:18.680970  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:22:19.495529 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:22:19.526558  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8949
I0628 20:22:19.526558  1232 solver.cpp:397]     Test net output #1: loss = 0.364078 (* 1 = 0.364078 loss)
I0628 20:22:19.561103  1232 solver.cpp:218] Iteration 62500 (22.5348 iter/s, 4.43758s/100 iters), loss = 0.0612185
I0628 20:22:19.561103  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:22:19.561103  1232 solver.cpp:237]     Train net output #1: loss = 0.0612192 (* 1 = 0.0612192 loss)
I0628 20:22:19.561103  1232 sgd_solver.cpp:105] Iteration 62500, lr = 1e-05
I0628 20:22:23.148501  1232 solver.cpp:218] Iteration 62600 (27.88 iter/s, 3.5868s/100 iters), loss = 0.110234
I0628 20:22:23.148501  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:22:23.148501  1232 solver.cpp:237]     Train net output #1: loss = 0.110235 (* 1 = 0.110235 loss)
I0628 20:22:23.148501  1232 sgd_solver.cpp:105] Iteration 62600, lr = 1e-05
I0628 20:22:26.738951  1232 solver.cpp:218] Iteration 62700 (27.8474 iter/s, 3.59099s/100 iters), loss = 0.124281
I0628 20:22:26.738951  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:22:26.738951  1232 solver.cpp:237]     Train net output #1: loss = 0.124281 (* 1 = 0.124281 loss)
I0628 20:22:26.738951  1232 sgd_solver.cpp:105] Iteration 62700, lr = 1e-05
I0628 20:22:30.324892  1232 solver.cpp:218] Iteration 62800 (27.8956 iter/s, 3.58479s/100 iters), loss = 0.0953108
I0628 20:22:30.324892  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:22:30.324892  1232 solver.cpp:237]     Train net output #1: loss = 0.0953115 (* 1 = 0.0953115 loss)
I0628 20:22:30.324892  1232 sgd_solver.cpp:105] Iteration 62800, lr = 1e-05
I0628 20:22:33.914595  1232 solver.cpp:218] Iteration 62900 (27.855 iter/s, 3.59002s/100 iters), loss = 0.081597
I0628 20:22:33.915596  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:22:33.915596  1232 solver.cpp:237]     Train net output #1: loss = 0.0815977 (* 1 = 0.0815977 loss)
I0628 20:22:33.915596  1232 sgd_solver.cpp:105] Iteration 62900, lr = 1e-05
I0628 20:22:37.330209 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:22:37.471009  1232 solver.cpp:330] Iteration 63000, Testing net (#0)
I0628 20:22:37.471009  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:22:38.284085 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:22:38.314091  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8948
I0628 20:22:38.315091  1232 solver.cpp:397]     Test net output #1: loss = 0.364285 (* 1 = 0.364285 loss)
I0628 20:22:38.349133  1232 solver.cpp:218] Iteration 63000 (22.5536 iter/s, 4.43389s/100 iters), loss = 0.0624354
I0628 20:22:38.349133  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:22:38.349133  1232 solver.cpp:237]     Train net output #1: loss = 0.062436 (* 1 = 0.062436 loss)
I0628 20:22:38.349133  1232 sgd_solver.cpp:105] Iteration 63000, lr = 1e-05
I0628 20:22:41.931092  1232 solver.cpp:218] Iteration 63100 (27.9184 iter/s, 3.58187s/100 iters), loss = 0.199808
I0628 20:22:41.931092  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:22:41.931092  1232 solver.cpp:237]     Train net output #1: loss = 0.199809 (* 1 = 0.199809 loss)
I0628 20:22:41.931092  1232 sgd_solver.cpp:105] Iteration 63100, lr = 1e-05
I0628 20:22:45.519817  1232 solver.cpp:218] Iteration 63200 (27.8703 iter/s, 3.58805s/100 iters), loss = 0.142213
I0628 20:22:45.519817  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:22:45.519817  1232 solver.cpp:237]     Train net output #1: loss = 0.142214 (* 1 = 0.142214 loss)
I0628 20:22:45.519817  1232 sgd_solver.cpp:105] Iteration 63200, lr = 1e-05
I0628 20:22:49.115183  1232 solver.cpp:218] Iteration 63300 (27.8201 iter/s, 3.59452s/100 iters), loss = 0.121122
I0628 20:22:49.115183  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:22:49.115183  1232 solver.cpp:237]     Train net output #1: loss = 0.121123 (* 1 = 0.121123 loss)
I0628 20:22:49.115183  1232 sgd_solver.cpp:105] Iteration 63300, lr = 1e-05
I0628 20:22:52.708667  1232 solver.cpp:218] Iteration 63400 (27.8241 iter/s, 3.59401s/100 iters), loss = 0.0753009
I0628 20:22:52.709667  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:22:52.709667  1232 solver.cpp:237]     Train net output #1: loss = 0.0753016 (* 1 = 0.0753016 loss)
I0628 20:22:52.709667  1232 sgd_solver.cpp:105] Iteration 63400, lr = 1e-05
I0628 20:22:56.124019 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:22:56.264155  1232 solver.cpp:330] Iteration 63500, Testing net (#0)
I0628 20:22:56.264155  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:22:57.077038 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:22:57.107656  1232 solver.cpp:397]     Test net output #0: accuracy = 0.895
I0628 20:22:57.107656  1232 solver.cpp:397]     Test net output #1: loss = 0.363815 (* 1 = 0.363815 loss)
I0628 20:22:57.141692  1232 solver.cpp:218] Iteration 63500 (22.5641 iter/s, 4.43182s/100 iters), loss = 0.0989522
I0628 20:22:57.141692  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:22:57.141692  1232 solver.cpp:237]     Train net output #1: loss = 0.0989529 (* 1 = 0.0989529 loss)
I0628 20:22:57.141692  1232 sgd_solver.cpp:105] Iteration 63500, lr = 1e-05
I0628 20:23:00.731268  1232 solver.cpp:218] Iteration 63600 (27.8615 iter/s, 3.58918s/100 iters), loss = 0.0920321
I0628 20:23:00.731268  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:23:00.731268  1232 solver.cpp:237]     Train net output #1: loss = 0.0920328 (* 1 = 0.0920328 loss)
I0628 20:23:00.731268  1232 sgd_solver.cpp:105] Iteration 63600, lr = 1e-05
I0628 20:23:04.325348  1232 solver.cpp:218] Iteration 63700 (27.8261 iter/s, 3.59374s/100 iters), loss = 0.140755
I0628 20:23:04.325348  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:23:04.325348  1232 solver.cpp:237]     Train net output #1: loss = 0.140756 (* 1 = 0.140756 loss)
I0628 20:23:04.325348  1232 sgd_solver.cpp:105] Iteration 63700, lr = 1e-05
I0628 20:23:07.906137  1232 solver.cpp:218] Iteration 63800 (27.9241 iter/s, 3.58113s/100 iters), loss = 0.0940534
I0628 20:23:07.906137  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:23:07.906137  1232 solver.cpp:237]     Train net output #1: loss = 0.0940541 (* 1 = 0.0940541 loss)
I0628 20:23:07.906137  1232 sgd_solver.cpp:105] Iteration 63800, lr = 1e-05
I0628 20:23:11.493775  1232 solver.cpp:218] Iteration 63900 (27.8796 iter/s, 3.58685s/100 iters), loss = 0.115656
I0628 20:23:11.493775  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:23:11.493775  1232 solver.cpp:237]     Train net output #1: loss = 0.115657 (* 1 = 0.115657 loss)
I0628 20:23:11.494277  1232 sgd_solver.cpp:105] Iteration 63900, lr = 1e-05
I0628 20:23:14.912569 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:23:15.053709  1232 solver.cpp:330] Iteration 64000, Testing net (#0)
I0628 20:23:15.053709  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:23:15.872818 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:23:15.903856  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8951
I0628 20:23:15.903856  1232 solver.cpp:397]     Test net output #1: loss = 0.364632 (* 1 = 0.364632 loss)
I0628 20:23:15.936969  1232 solver.cpp:218] Iteration 64000 (22.5055 iter/s, 4.44335s/100 iters), loss = 0.0739437
I0628 20:23:15.936969  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:23:15.937970  1232 solver.cpp:237]     Train net output #1: loss = 0.0739444 (* 1 = 0.0739444 loss)
I0628 20:23:15.937970  1232 sgd_solver.cpp:105] Iteration 64000, lr = 1e-05
I0628 20:23:19.531898  1232 solver.cpp:218] Iteration 64100 (27.8202 iter/s, 3.59451s/100 iters), loss = 0.122496
I0628 20:23:19.531898  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:23:19.531898  1232 solver.cpp:237]     Train net output #1: loss = 0.122497 (* 1 = 0.122497 loss)
I0628 20:23:19.531898  1232 sgd_solver.cpp:105] Iteration 64100, lr = 1e-05
I0628 20:23:23.126790  1232 solver.cpp:218] Iteration 64200 (27.8202 iter/s, 3.5945s/100 iters), loss = 0.108832
I0628 20:23:23.126790  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:23:23.126790  1232 solver.cpp:237]     Train net output #1: loss = 0.108832 (* 1 = 0.108832 loss)
I0628 20:23:23.126790  1232 sgd_solver.cpp:105] Iteration 64200, lr = 1e-05
I0628 20:23:26.723506  1232 solver.cpp:218] Iteration 64300 (27.8091 iter/s, 3.59595s/100 iters), loss = 0.169443
I0628 20:23:26.723506  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:23:26.724007  1232 solver.cpp:237]     Train net output #1: loss = 0.169443 (* 1 = 0.169443 loss)
I0628 20:23:26.724007  1232 sgd_solver.cpp:105] Iteration 64300, lr = 1e-05
I0628 20:23:30.315973  1232 solver.cpp:218] Iteration 64400 (27.8396 iter/s, 3.59201s/100 iters), loss = 0.0553532
I0628 20:23:30.315973  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:23:30.315973  1232 solver.cpp:237]     Train net output #1: loss = 0.0553539 (* 1 = 0.0553539 loss)
I0628 20:23:30.315973  1232 sgd_solver.cpp:105] Iteration 64400, lr = 1e-05
I0628 20:23:33.734815 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:23:33.875946  1232 solver.cpp:330] Iteration 64500, Testing net (#0)
I0628 20:23:33.875946  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:23:34.694702 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:23:34.725720  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I0628 20:23:34.725720  1232 solver.cpp:397]     Test net output #1: loss = 0.363773 (* 1 = 0.363773 loss)
I0628 20:23:34.759745  1232 solver.cpp:218] Iteration 64500 (22.5023 iter/s, 4.44398s/100 iters), loss = 0.0831299
I0628 20:23:34.759745  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:23:34.759745  1232 solver.cpp:237]     Train net output #1: loss = 0.0831307 (* 1 = 0.0831307 loss)
I0628 20:23:34.759745  1232 sgd_solver.cpp:105] Iteration 64500, lr = 1e-05
I0628 20:23:38.361243  1232 solver.cpp:218] Iteration 64600 (27.7754 iter/s, 3.60031s/100 iters), loss = 0.188392
I0628 20:23:38.361243  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:23:38.361243  1232 solver.cpp:237]     Train net output #1: loss = 0.188393 (* 1 = 0.188393 loss)
I0628 20:23:38.361243  1232 sgd_solver.cpp:105] Iteration 64600, lr = 1e-05
I0628 20:23:41.956517  1232 solver.cpp:218] Iteration 64700 (27.8108 iter/s, 3.59573s/100 iters), loss = 0.135729
I0628 20:23:41.956517  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:23:41.956517  1232 solver.cpp:237]     Train net output #1: loss = 0.13573 (* 1 = 0.13573 loss)
I0628 20:23:41.956517  1232 sgd_solver.cpp:105] Iteration 64700, lr = 1e-05
I0628 20:23:45.551091  1232 solver.cpp:218] Iteration 64800 (27.8222 iter/s, 3.59426s/100 iters), loss = 0.135943
I0628 20:23:45.551091  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:23:45.551091  1232 solver.cpp:237]     Train net output #1: loss = 0.135944 (* 1 = 0.135944 loss)
I0628 20:23:45.551091  1232 sgd_solver.cpp:105] Iteration 64800, lr = 1e-05
I0628 20:23:49.142936  1232 solver.cpp:218] Iteration 64900 (27.849 iter/s, 3.59079s/100 iters), loss = 0.0910065
I0628 20:23:49.142936  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:23:49.142936  1232 solver.cpp:237]     Train net output #1: loss = 0.0910073 (* 1 = 0.0910073 loss)
I0628 20:23:49.142936  1232 sgd_solver.cpp:105] Iteration 64900, lr = 1e-05
I0628 20:23:52.556140 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:23:52.697655  1232 solver.cpp:330] Iteration 65000, Testing net (#0)
I0628 20:23:52.697655  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:23:53.515137 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:23:53.546145  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8947
I0628 20:23:53.546145  1232 solver.cpp:397]     Test net output #1: loss = 0.363545 (* 1 = 0.363545 loss)
I0628 20:23:53.580180  1232 solver.cpp:218] Iteration 65000 (22.5389 iter/s, 4.43677s/100 iters), loss = 0.0893175
I0628 20:23:53.580180  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:23:53.580180  1232 solver.cpp:237]     Train net output #1: loss = 0.0893183 (* 1 = 0.0893183 loss)
I0628 20:23:53.580180  1232 sgd_solver.cpp:105] Iteration 65000, lr = 1e-05
I0628 20:23:57.175318  1232 solver.cpp:218] Iteration 65100 (27.8106 iter/s, 3.59575s/100 iters), loss = 0.106233
I0628 20:23:57.176319  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:23:57.176319  1232 solver.cpp:237]     Train net output #1: loss = 0.106234 (* 1 = 0.106234 loss)
I0628 20:23:57.176319  1232 sgd_solver.cpp:105] Iteration 65100, lr = 1e-05
I0628 20:24:00.763198  1232 solver.cpp:218] Iteration 65200 (27.8802 iter/s, 3.58678s/100 iters), loss = 0.147044
I0628 20:24:00.763198  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:24:00.763198  1232 solver.cpp:237]     Train net output #1: loss = 0.147045 (* 1 = 0.147045 loss)
I0628 20:24:00.763198  1232 sgd_solver.cpp:105] Iteration 65200, lr = 1e-05
I0628 20:24:04.354177  1232 solver.cpp:218] Iteration 65300 (27.8466 iter/s, 3.59111s/100 iters), loss = 0.1186
I0628 20:24:04.354177  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:24:04.354177  1232 solver.cpp:237]     Train net output #1: loss = 0.118601 (* 1 = 0.118601 loss)
I0628 20:24:04.354177  1232 sgd_solver.cpp:105] Iteration 65300, lr = 1e-05
I0628 20:24:07.968868  1232 solver.cpp:218] Iteration 65400 (27.6718 iter/s, 3.61378s/100 iters), loss = 0.0661273
I0628 20:24:07.968868  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:24:07.968868  1232 solver.cpp:237]     Train net output #1: loss = 0.0661281 (* 1 = 0.0661281 loss)
I0628 20:24:07.968868  1232 sgd_solver.cpp:105] Iteration 65400, lr = 1e-05
I0628 20:24:11.424911 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:24:11.565014  1232 solver.cpp:330] Iteration 65500, Testing net (#0)
I0628 20:24:11.565014  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:24:12.388149 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:24:12.418676  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8947
I0628 20:24:12.418676  1232 solver.cpp:397]     Test net output #1: loss = 0.363768 (* 1 = 0.363768 loss)
I0628 20:24:12.456703  1232 solver.cpp:218] Iteration 65500 (22.2812 iter/s, 4.4881s/100 iters), loss = 0.0489746
I0628 20:24:12.456703  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:24:12.456703  1232 solver.cpp:237]     Train net output #1: loss = 0.0489754 (* 1 = 0.0489754 loss)
I0628 20:24:12.456703  1232 sgd_solver.cpp:105] Iteration 65500, lr = 1e-05
I0628 20:24:16.081501  1232 solver.cpp:218] Iteration 65600 (27.5942 iter/s, 3.62395s/100 iters), loss = 0.153102
I0628 20:24:16.081501  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:24:16.081501  1232 solver.cpp:237]     Train net output #1: loss = 0.153103 (* 1 = 0.153103 loss)
I0628 20:24:16.081501  1232 sgd_solver.cpp:105] Iteration 65600, lr = 1e-05
I0628 20:24:19.690312  1232 solver.cpp:218] Iteration 65700 (27.7151 iter/s, 3.60814s/100 iters), loss = 0.146242
I0628 20:24:19.690312  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:24:19.690312  1232 solver.cpp:237]     Train net output #1: loss = 0.146243 (* 1 = 0.146243 loss)
I0628 20:24:19.690312  1232 sgd_solver.cpp:105] Iteration 65700, lr = 1e-05
I0628 20:24:23.304180  1232 solver.cpp:218] Iteration 65800 (27.6717 iter/s, 3.61379s/100 iters), loss = 0.115288
I0628 20:24:23.304180  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:24:23.304180  1232 solver.cpp:237]     Train net output #1: loss = 0.115288 (* 1 = 0.115288 loss)
I0628 20:24:23.304180  1232 sgd_solver.cpp:105] Iteration 65800, lr = 1e-05
I0628 20:24:26.918629  1232 solver.cpp:218] Iteration 65900 (27.6692 iter/s, 3.61413s/100 iters), loss = 0.088009
I0628 20:24:26.918629  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:24:26.918629  1232 solver.cpp:237]     Train net output #1: loss = 0.0880098 (* 1 = 0.0880098 loss)
I0628 20:24:26.918629  1232 sgd_solver.cpp:105] Iteration 65900, lr = 1e-05
I0628 20:24:30.365867 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:24:30.507971  1232 solver.cpp:330] Iteration 66000, Testing net (#0)
I0628 20:24:30.507971  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:24:31.327481 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:24:31.358521  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8953
I0628 20:24:31.358521  1232 solver.cpp:397]     Test net output #1: loss = 0.363767 (* 1 = 0.363767 loss)
I0628 20:24:31.392544  1232 solver.cpp:218] Iteration 66000 (22.3519 iter/s, 4.4739s/100 iters), loss = 0.0762147
I0628 20:24:31.392544  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:24:31.392544  1232 solver.cpp:237]     Train net output #1: loss = 0.0762155 (* 1 = 0.0762155 loss)
I0628 20:24:31.392544  1232 sgd_solver.cpp:105] Iteration 66000, lr = 1e-05
I0628 20:24:35.010457  1232 solver.cpp:218] Iteration 66100 (27.6431 iter/s, 3.61754s/100 iters), loss = 0.10856
I0628 20:24:35.010457  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:24:35.010457  1232 solver.cpp:237]     Train net output #1: loss = 0.108561 (* 1 = 0.108561 loss)
I0628 20:24:35.010457  1232 sgd_solver.cpp:105] Iteration 66100, lr = 1e-05
I0628 20:24:38.617048  1232 solver.cpp:218] Iteration 66200 (27.7331 iter/s, 3.60581s/100 iters), loss = 0.108968
I0628 20:24:38.617048  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:24:38.617048  1232 solver.cpp:237]     Train net output #1: loss = 0.108969 (* 1 = 0.108969 loss)
I0628 20:24:38.617048  1232 sgd_solver.cpp:105] Iteration 66200, lr = 1e-05
I0628 20:24:42.201815  1232 solver.cpp:218] Iteration 66300 (27.8934 iter/s, 3.58507s/100 iters), loss = 0.131928
I0628 20:24:42.201815  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:24:42.201815  1232 solver.cpp:237]     Train net output #1: loss = 0.131929 (* 1 = 0.131929 loss)
I0628 20:24:42.201815  1232 sgd_solver.cpp:105] Iteration 66300, lr = 1e-05
I0628 20:24:45.813715  1232 solver.cpp:218] Iteration 66400 (27.6926 iter/s, 3.61107s/100 iters), loss = 0.103778
I0628 20:24:45.813715  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:24:45.813715  1232 solver.cpp:237]     Train net output #1: loss = 0.103778 (* 1 = 0.103778 loss)
I0628 20:24:45.813715  1232 sgd_solver.cpp:105] Iteration 66400, lr = 1e-05
I0628 20:24:49.241070 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:24:49.382758  1232 solver.cpp:330] Iteration 66500, Testing net (#0)
I0628 20:24:49.382758  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:24:50.196975 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:24:50.227998  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8943
I0628 20:24:50.227998  1232 solver.cpp:397]     Test net output #1: loss = 0.363686 (* 1 = 0.363686 loss)
I0628 20:24:50.262025  1232 solver.cpp:218] Iteration 66500 (22.4815 iter/s, 4.4481s/100 iters), loss = 0.0684373
I0628 20:24:50.262025  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:24:50.262025  1232 solver.cpp:237]     Train net output #1: loss = 0.0684381 (* 1 = 0.0684381 loss)
I0628 20:24:50.262025  1232 sgd_solver.cpp:105] Iteration 66500, lr = 1e-05
I0628 20:24:53.861263  1232 solver.cpp:218] Iteration 66600 (27.7892 iter/s, 3.59852s/100 iters), loss = 0.154631
I0628 20:24:53.861263  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:24:53.861263  1232 solver.cpp:237]     Train net output #1: loss = 0.154631 (* 1 = 0.154631 loss)
I0628 20:24:53.861263  1232 sgd_solver.cpp:105] Iteration 66600, lr = 1e-05
I0628 20:24:57.465322  1232 solver.cpp:218] Iteration 66700 (27.7476 iter/s, 3.60391s/100 iters), loss = 0.149571
I0628 20:24:57.465322  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:24:57.465322  1232 solver.cpp:237]     Train net output #1: loss = 0.149572 (* 1 = 0.149572 loss)
I0628 20:24:57.465322  1232 sgd_solver.cpp:105] Iteration 66700, lr = 1e-05
I0628 20:25:01.062110  1232 solver.cpp:218] Iteration 66800 (27.8066 iter/s, 3.59626s/100 iters), loss = 0.136955
I0628 20:25:01.062110  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:25:01.062110  1232 solver.cpp:237]     Train net output #1: loss = 0.136956 (* 1 = 0.136956 loss)
I0628 20:25:01.062110  1232 sgd_solver.cpp:105] Iteration 66800, lr = 1e-05
I0628 20:25:04.654923  1232 solver.cpp:218] Iteration 66900 (27.8347 iter/s, 3.59264s/100 iters), loss = 0.0682558
I0628 20:25:04.654923  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:25:04.654923  1232 solver.cpp:237]     Train net output #1: loss = 0.0682566 (* 1 = 0.0682566 loss)
I0628 20:25:04.654923  1232 sgd_solver.cpp:105] Iteration 66900, lr = 1e-05
I0628 20:25:08.190588 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:25:08.332193  1232 solver.cpp:330] Iteration 67000, Testing net (#0)
I0628 20:25:08.332193  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:25:09.150560 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:25:09.180593  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8953
I0628 20:25:09.181593  1232 solver.cpp:397]     Test net output #1: loss = 0.363455 (* 1 = 0.363455 loss)
I0628 20:25:09.214614  1232 solver.cpp:218] Iteration 67000 (21.9302 iter/s, 4.55993s/100 iters), loss = 0.0841583
I0628 20:25:09.214614  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:25:09.214614  1232 solver.cpp:237]     Train net output #1: loss = 0.0841591 (* 1 = 0.0841591 loss)
I0628 20:25:09.214614  1232 sgd_solver.cpp:105] Iteration 67000, lr = 1e-05
I0628 20:25:12.817157  1232 solver.cpp:218] Iteration 67100 (27.7604 iter/s, 3.60225s/100 iters), loss = 0.259126
I0628 20:25:12.817157  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:25:12.817157  1232 solver.cpp:237]     Train net output #1: loss = 0.259127 (* 1 = 0.259127 loss)
I0628 20:25:12.817157  1232 sgd_solver.cpp:105] Iteration 67100, lr = 1e-05
I0628 20:25:16.415340  1232 solver.cpp:218] Iteration 67200 (27.798 iter/s, 3.59738s/100 iters), loss = 0.140271
I0628 20:25:16.415340  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:25:16.415340  1232 solver.cpp:237]     Train net output #1: loss = 0.140272 (* 1 = 0.140272 loss)
I0628 20:25:16.415340  1232 sgd_solver.cpp:105] Iteration 67200, lr = 1e-05
I0628 20:25:19.999317  1232 solver.cpp:218] Iteration 67300 (27.905 iter/s, 3.58358s/100 iters), loss = 0.0984772
I0628 20:25:19.999317  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:25:19.999317  1232 solver.cpp:237]     Train net output #1: loss = 0.098478 (* 1 = 0.098478 loss)
I0628 20:25:19.999317  1232 sgd_solver.cpp:105] Iteration 67300, lr = 1e-05
I0628 20:25:23.582487  1232 solver.cpp:218] Iteration 67400 (27.9107 iter/s, 3.58285s/100 iters), loss = 0.0539405
I0628 20:25:23.582487  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:25:23.582487  1232 solver.cpp:237]     Train net output #1: loss = 0.0539413 (* 1 = 0.0539413 loss)
I0628 20:25:23.582487  1232 sgd_solver.cpp:105] Iteration 67400, lr = 1e-05
I0628 20:25:26.991006 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:25:27.132112  1232 solver.cpp:330] Iteration 67500, Testing net (#0)
I0628 20:25:27.132112  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:25:27.944721 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:25:27.975744  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8959
I0628 20:25:27.975744  1232 solver.cpp:397]     Test net output #1: loss = 0.364044 (* 1 = 0.364044 loss)
I0628 20:25:28.010272  1232 solver.cpp:218] Iteration 67500 (22.5867 iter/s, 4.42739s/100 iters), loss = 0.0843035
I0628 20:25:28.010272  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:25:28.010272  1232 solver.cpp:237]     Train net output #1: loss = 0.0843043 (* 1 = 0.0843043 loss)
I0628 20:25:28.010272  1232 sgd_solver.cpp:105] Iteration 67500, lr = 1e-05
I0628 20:25:31.608467  1232 solver.cpp:218] Iteration 67600 (27.7963 iter/s, 3.5976s/100 iters), loss = 0.162682
I0628 20:25:31.608467  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:25:31.608467  1232 solver.cpp:237]     Train net output #1: loss = 0.162683 (* 1 = 0.162683 loss)
I0628 20:25:31.608467  1232 sgd_solver.cpp:105] Iteration 67600, lr = 1e-05
I0628 20:25:35.209481  1232 solver.cpp:218] Iteration 67700 (27.768 iter/s, 3.60127s/100 iters), loss = 0.15541
I0628 20:25:35.209481  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:25:35.209481  1232 solver.cpp:237]     Train net output #1: loss = 0.15541 (* 1 = 0.15541 loss)
I0628 20:25:35.209481  1232 sgd_solver.cpp:105] Iteration 67700, lr = 1e-05
I0628 20:25:38.793398  1232 solver.cpp:218] Iteration 67800 (27.9052 iter/s, 3.58357s/100 iters), loss = 0.119699
I0628 20:25:38.793398  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:25:38.793398  1232 solver.cpp:237]     Train net output #1: loss = 0.1197 (* 1 = 0.1197 loss)
I0628 20:25:38.793398  1232 sgd_solver.cpp:105] Iteration 67800, lr = 1e-05
I0628 20:25:42.376055  1232 solver.cpp:218] Iteration 67900 (27.9185 iter/s, 3.58185s/100 iters), loss = 0.142445
I0628 20:25:42.376055  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:25:42.376055  1232 solver.cpp:237]     Train net output #1: loss = 0.142446 (* 1 = 0.142446 loss)
I0628 20:25:42.376055  1232 sgd_solver.cpp:105] Iteration 67900, lr = 1e-05
I0628 20:25:45.784585 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:25:45.924690  1232 solver.cpp:330] Iteration 68000, Testing net (#0)
I0628 20:25:45.924690  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:25:46.741482 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:25:46.771502  1232 solver.cpp:397]     Test net output #0: accuracy = 0.895
I0628 20:25:46.771502  1232 solver.cpp:397]     Test net output #1: loss = 0.364173 (* 1 = 0.364173 loss)
I0628 20:25:46.805529  1232 solver.cpp:218] Iteration 68000 (22.5753 iter/s, 4.42962s/100 iters), loss = 0.0861556
I0628 20:25:46.805529  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:25:46.805529  1232 solver.cpp:237]     Train net output #1: loss = 0.0861564 (* 1 = 0.0861564 loss)
I0628 20:25:46.805529  1232 sgd_solver.cpp:105] Iteration 68000, lr = 1e-05
I0628 20:25:50.391981  1232 solver.cpp:218] Iteration 68100 (27.8878 iter/s, 3.5858s/100 iters), loss = 0.0916817
I0628 20:25:50.392482  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:25:50.392482  1232 solver.cpp:237]     Train net output #1: loss = 0.0916825 (* 1 = 0.0916825 loss)
I0628 20:25:50.392482  1232 sgd_solver.cpp:105] Iteration 68100, lr = 1e-05
I0628 20:25:53.973830  1232 solver.cpp:218] Iteration 68200 (27.9185 iter/s, 3.58185s/100 iters), loss = 0.0696394
I0628 20:25:53.973830  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:25:53.973830  1232 solver.cpp:237]     Train net output #1: loss = 0.0696402 (* 1 = 0.0696402 loss)
I0628 20:25:53.973830  1232 sgd_solver.cpp:105] Iteration 68200, lr = 1e-05
I0628 20:25:57.560747  1232 solver.cpp:218] Iteration 68300 (27.8806 iter/s, 3.58673s/100 iters), loss = 0.133944
I0628 20:25:57.561748  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:25:57.561748  1232 solver.cpp:237]     Train net output #1: loss = 0.133945 (* 1 = 0.133945 loss)
I0628 20:25:57.561748  1232 sgd_solver.cpp:105] Iteration 68300, lr = 1e-05
I0628 20:26:01.137140  1232 solver.cpp:218] Iteration 68400 (27.965 iter/s, 3.57589s/100 iters), loss = 0.0516365
I0628 20:26:01.137140  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:26:01.137140  1232 solver.cpp:237]     Train net output #1: loss = 0.0516373 (* 1 = 0.0516373 loss)
I0628 20:26:01.137140  1232 sgd_solver.cpp:105] Iteration 68400, lr = 1e-05
I0628 20:26:04.548187 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:26:04.688289  1232 solver.cpp:330] Iteration 68500, Testing net (#0)
I0628 20:26:04.688289  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:26:05.502951 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:26:05.532974  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8953
I0628 20:26:05.532974  1232 solver.cpp:397]     Test net output #1: loss = 0.363821 (* 1 = 0.363821 loss)
I0628 20:26:05.566998  1232 solver.cpp:218] Iteration 68500 (22.5764 iter/s, 4.42941s/100 iters), loss = 0.116963
I0628 20:26:05.566998  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:26:05.566998  1232 solver.cpp:237]     Train net output #1: loss = 0.116964 (* 1 = 0.116964 loss)
I0628 20:26:05.566998  1232 sgd_solver.cpp:105] Iteration 68500, lr = 1e-05
I0628 20:26:09.167917  1232 solver.cpp:218] Iteration 68600 (27.7768 iter/s, 3.60013s/100 iters), loss = 0.181576
I0628 20:26:09.167917  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:26:09.167917  1232 solver.cpp:237]     Train net output #1: loss = 0.181577 (* 1 = 0.181577 loss)
I0628 20:26:09.167917  1232 sgd_solver.cpp:105] Iteration 68600, lr = 1e-05
I0628 20:26:12.768607  1232 solver.cpp:218] Iteration 68700 (27.775 iter/s, 3.60036s/100 iters), loss = 0.168048
I0628 20:26:12.768607  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:26:12.768607  1232 solver.cpp:237]     Train net output #1: loss = 0.168049 (* 1 = 0.168049 loss)
I0628 20:26:12.768607  1232 sgd_solver.cpp:105] Iteration 68700, lr = 1e-05
I0628 20:26:16.344735  1232 solver.cpp:218] Iteration 68800 (27.9646 iter/s, 3.57595s/100 iters), loss = 0.11662
I0628 20:26:16.344735  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:26:16.344735  1232 solver.cpp:237]     Train net output #1: loss = 0.116621 (* 1 = 0.116621 loss)
I0628 20:26:16.344735  1232 sgd_solver.cpp:105] Iteration 68800, lr = 1e-05
I0628 20:26:19.947955  1232 solver.cpp:218] Iteration 68900 (27.7552 iter/s, 3.60293s/100 iters), loss = 0.0640639
I0628 20:26:19.947955  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:26:19.947955  1232 solver.cpp:237]     Train net output #1: loss = 0.0640647 (* 1 = 0.0640647 loss)
I0628 20:26:19.947955  1232 sgd_solver.cpp:105] Iteration 68900, lr = 1e-05
I0628 20:26:23.372316 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:26:23.512483  1232 solver.cpp:330] Iteration 69000, Testing net (#0)
I0628 20:26:23.512483  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:26:24.328126 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:26:24.359131  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8954
I0628 20:26:24.359131  1232 solver.cpp:397]     Test net output #1: loss = 0.3641 (* 1 = 0.3641 loss)
I0628 20:26:24.393182  1232 solver.cpp:218] Iteration 69000 (22.4987 iter/s, 4.44471s/100 iters), loss = 0.0885021
I0628 20:26:24.393182  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:26:24.393182  1232 solver.cpp:237]     Train net output #1: loss = 0.0885029 (* 1 = 0.0885029 loss)
I0628 20:26:24.393182  1232 sgd_solver.cpp:105] Iteration 69000, lr = 1e-05
I0628 20:26:27.989390  1232 solver.cpp:218] Iteration 69100 (27.8047 iter/s, 3.59651s/100 iters), loss = 0.192855
I0628 20:26:27.990391  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:26:27.990391  1232 solver.cpp:237]     Train net output #1: loss = 0.192856 (* 1 = 0.192856 loss)
I0628 20:26:27.990391  1232 sgd_solver.cpp:105] Iteration 69100, lr = 1e-05
I0628 20:26:31.585521  1232 solver.cpp:218] Iteration 69200 (27.8164 iter/s, 3.595s/100 iters), loss = 0.114245
I0628 20:26:31.585521  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:26:31.585521  1232 solver.cpp:237]     Train net output #1: loss = 0.114246 (* 1 = 0.114246 loss)
I0628 20:26:31.585521  1232 sgd_solver.cpp:105] Iteration 69200, lr = 1e-05
I0628 20:26:35.185137  1232 solver.cpp:218] Iteration 69300 (27.7818 iter/s, 3.59948s/100 iters), loss = 0.122563
I0628 20:26:35.185637  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:26:35.185637  1232 solver.cpp:237]     Train net output #1: loss = 0.122564 (* 1 = 0.122564 loss)
I0628 20:26:35.185637  1232 sgd_solver.cpp:105] Iteration 69300, lr = 1e-05
I0628 20:26:38.786644  1232 solver.cpp:218] Iteration 69400 (27.7689 iter/s, 3.60115s/100 iters), loss = 0.0929309
I0628 20:26:38.787144  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:26:38.787144  1232 solver.cpp:237]     Train net output #1: loss = 0.0929317 (* 1 = 0.0929317 loss)
I0628 20:26:38.787144  1232 sgd_solver.cpp:105] Iteration 69400, lr = 1e-05
I0628 20:26:42.214171 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:26:42.355320  1232 solver.cpp:330] Iteration 69500, Testing net (#0)
I0628 20:26:42.355320  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:26:43.174422 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:26:43.205588  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8956
I0628 20:26:43.205588  1232 solver.cpp:397]     Test net output #1: loss = 0.363325 (* 1 = 0.363325 loss)
I0628 20:26:43.239608  1232 solver.cpp:218] Iteration 69500 (22.4587 iter/s, 4.45261s/100 iters), loss = 0.0926438
I0628 20:26:43.239608  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:26:43.239608  1232 solver.cpp:237]     Train net output #1: loss = 0.0926446 (* 1 = 0.0926446 loss)
I0628 20:26:43.239608  1232 sgd_solver.cpp:105] Iteration 69500, lr = 1e-05
I0628 20:26:46.831615  1232 solver.cpp:218] Iteration 69600 (27.8403 iter/s, 3.59192s/100 iters), loss = 0.183651
I0628 20:26:46.831615  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:26:46.831615  1232 solver.cpp:237]     Train net output #1: loss = 0.183652 (* 1 = 0.183652 loss)
I0628 20:26:46.831615  1232 sgd_solver.cpp:105] Iteration 69600, lr = 1e-05
I0628 20:26:50.409785  1232 solver.cpp:218] Iteration 69700 (27.9528 iter/s, 3.57745s/100 iters), loss = 0.0960282
I0628 20:26:50.409785  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:26:50.409785  1232 solver.cpp:237]     Train net output #1: loss = 0.096029 (* 1 = 0.096029 loss)
I0628 20:26:50.409785  1232 sgd_solver.cpp:105] Iteration 69700, lr = 1e-05
I0628 20:26:54.009974  1232 solver.cpp:218] Iteration 69800 (27.7814 iter/s, 3.59953s/100 iters), loss = 0.165216
I0628 20:26:54.009974  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:26:54.009974  1232 solver.cpp:237]     Train net output #1: loss = 0.165216 (* 1 = 0.165216 loss)
I0628 20:26:54.009974  1232 sgd_solver.cpp:105] Iteration 69800, lr = 1e-05
I0628 20:26:57.594799  1232 solver.cpp:218] Iteration 69900 (27.898 iter/s, 3.58448s/100 iters), loss = 0.0521687
I0628 20:26:57.594799  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:26:57.594799  1232 solver.cpp:237]     Train net output #1: loss = 0.0521696 (* 1 = 0.0521696 loss)
I0628 20:26:57.594799  1232 sgd_solver.cpp:105] Iteration 69900, lr = 1e-05
I0628 20:27:01.003854 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:27:01.146461  1232 solver.cpp:330] Iteration 70000, Testing net (#0)
I0628 20:27:01.146461  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:27:01.966295 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:27:01.997316  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8954
I0628 20:27:01.997316  1232 solver.cpp:397]     Test net output #1: loss = 0.363898 (* 1 = 0.363898 loss)
I0628 20:27:02.031343  1232 solver.cpp:218] Iteration 70000 (22.5387 iter/s, 4.43681s/100 iters), loss = 0.0678714
I0628 20:27:02.031343  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:27:02.031343  1232 solver.cpp:237]     Train net output #1: loss = 0.0678723 (* 1 = 0.0678723 loss)
I0628 20:27:02.031343  1232 sgd_solver.cpp:105] Iteration 70000, lr = 1e-05
I0628 20:27:05.613991  1232 solver.cpp:218] Iteration 70100 (27.9197 iter/s, 3.5817s/100 iters), loss = 0.191435
I0628 20:27:05.613991  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:27:05.613991  1232 solver.cpp:237]     Train net output #1: loss = 0.191435 (* 1 = 0.191435 loss)
I0628 20:27:05.613991  1232 sgd_solver.cpp:105] Iteration 70100, lr = 1e-05
I0628 20:27:09.194975  1232 solver.cpp:218] Iteration 70200 (27.9227 iter/s, 3.58131s/100 iters), loss = 0.131641
I0628 20:27:09.194975  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:27:09.194975  1232 solver.cpp:237]     Train net output #1: loss = 0.131641 (* 1 = 0.131641 loss)
I0628 20:27:09.194975  1232 sgd_solver.cpp:105] Iteration 70200, lr = 1e-05
I0628 20:27:12.788185  1232 solver.cpp:218] Iteration 70300 (27.8346 iter/s, 3.59265s/100 iters), loss = 0.113819
I0628 20:27:12.788185  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:27:12.788185  1232 solver.cpp:237]     Train net output #1: loss = 0.11382 (* 1 = 0.11382 loss)
I0628 20:27:12.788185  1232 sgd_solver.cpp:105] Iteration 70300, lr = 1e-05
I0628 20:27:16.392627  1232 solver.cpp:218] Iteration 70400 (27.7476 iter/s, 3.60391s/100 iters), loss = 0.0623171
I0628 20:27:16.392627  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:27:16.392627  1232 solver.cpp:237]     Train net output #1: loss = 0.062318 (* 1 = 0.062318 loss)
I0628 20:27:16.392627  1232 sgd_solver.cpp:105] Iteration 70400, lr = 1e-05
I0628 20:27:19.807849 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:27:19.948514  1232 solver.cpp:330] Iteration 70500, Testing net (#0)
I0628 20:27:19.948514  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:27:20.769613 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:27:20.800628  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8957
I0628 20:27:20.800628  1232 solver.cpp:397]     Test net output #1: loss = 0.363809 (* 1 = 0.363809 loss)
I0628 20:27:20.834687  1232 solver.cpp:218] Iteration 70500 (22.5139 iter/s, 4.4417s/100 iters), loss = 0.0703971
I0628 20:27:20.834687  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:27:20.834687  1232 solver.cpp:237]     Train net output #1: loss = 0.070398 (* 1 = 0.070398 loss)
I0628 20:27:20.834687  1232 sgd_solver.cpp:105] Iteration 70500, lr = 1e-05
I0628 20:27:24.436991  1232 solver.cpp:218] Iteration 70600 (27.7631 iter/s, 3.60191s/100 iters), loss = 0.138722
I0628 20:27:24.436991  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:27:24.436991  1232 solver.cpp:237]     Train net output #1: loss = 0.138723 (* 1 = 0.138723 loss)
I0628 20:27:24.436991  1232 sgd_solver.cpp:105] Iteration 70600, lr = 1e-05
I0628 20:27:28.038641  1232 solver.cpp:218] Iteration 70700 (27.7688 iter/s, 3.60116s/100 iters), loss = 0.0855328
I0628 20:27:28.038641  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:27:28.038641  1232 solver.cpp:237]     Train net output #1: loss = 0.0855337 (* 1 = 0.0855337 loss)
I0628 20:27:28.038641  1232 sgd_solver.cpp:105] Iteration 70700, lr = 1e-05
I0628 20:27:31.633327  1232 solver.cpp:218] Iteration 70800 (27.8197 iter/s, 3.59457s/100 iters), loss = 0.135118
I0628 20:27:31.633327  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:27:31.633327  1232 solver.cpp:237]     Train net output #1: loss = 0.135118 (* 1 = 0.135118 loss)
I0628 20:27:31.633327  1232 sgd_solver.cpp:105] Iteration 70800, lr = 1e-05
I0628 20:27:35.228351  1232 solver.cpp:218] Iteration 70900 (27.8168 iter/s, 3.59495s/100 iters), loss = 0.0788258
I0628 20:27:35.228351  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:27:35.228351  1232 solver.cpp:237]     Train net output #1: loss = 0.0788267 (* 1 = 0.0788267 loss)
I0628 20:27:35.228351  1232 sgd_solver.cpp:105] Iteration 70900, lr = 1e-05
I0628 20:27:38.654216 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:27:38.794515  1232 solver.cpp:330] Iteration 71000, Testing net (#0)
I0628 20:27:38.794515  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:27:39.608454 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:27:39.639489  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8954
I0628 20:27:39.639489  1232 solver.cpp:397]     Test net output #1: loss = 0.363597 (* 1 = 0.363597 loss)
I0628 20:27:39.673526  1232 solver.cpp:218] Iteration 71000 (22.4976 iter/s, 4.44491s/100 iters), loss = 0.0766696
I0628 20:27:39.673526  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:27:39.673526  1232 solver.cpp:237]     Train net output #1: loss = 0.0766704 (* 1 = 0.0766704 loss)
I0628 20:27:39.673526  1232 sgd_solver.cpp:105] Iteration 71000, lr = 1e-05
I0628 20:27:43.271877  1232 solver.cpp:218] Iteration 71100 (27.7989 iter/s, 3.59727s/100 iters), loss = 0.14884
I0628 20:27:43.271877  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:27:43.271877  1232 solver.cpp:237]     Train net output #1: loss = 0.148841 (* 1 = 0.148841 loss)
I0628 20:27:43.271877  1232 sgd_solver.cpp:105] Iteration 71100, lr = 1e-05
I0628 20:27:46.872431  1232 solver.cpp:218] Iteration 71200 (27.7754 iter/s, 3.60031s/100 iters), loss = 0.0987244
I0628 20:27:46.872431  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:27:46.872431  1232 solver.cpp:237]     Train net output #1: loss = 0.0987252 (* 1 = 0.0987252 loss)
I0628 20:27:46.872431  1232 sgd_solver.cpp:105] Iteration 71200, lr = 1e-05
I0628 20:27:50.472432  1232 solver.cpp:218] Iteration 71300 (27.7785 iter/s, 3.59991s/100 iters), loss = 0.121942
I0628 20:27:50.472432  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:27:50.472432  1232 solver.cpp:237]     Train net output #1: loss = 0.121943 (* 1 = 0.121943 loss)
I0628 20:27:50.472432  1232 sgd_solver.cpp:105] Iteration 71300, lr = 1e-05
I0628 20:27:54.074928  1232 solver.cpp:218] Iteration 71400 (27.7632 iter/s, 3.60189s/100 iters), loss = 0.0913194
I0628 20:27:54.074928  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:27:54.074928  1232 solver.cpp:237]     Train net output #1: loss = 0.0913203 (* 1 = 0.0913203 loss)
I0628 20:27:54.074928  1232 sgd_solver.cpp:105] Iteration 71400, lr = 1e-05
I0628 20:27:57.507762 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:27:57.648869  1232 solver.cpp:330] Iteration 71500, Testing net (#0)
I0628 20:27:57.648869  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:27:58.463487 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:27:58.494509  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8958
I0628 20:27:58.494509  1232 solver.cpp:397]     Test net output #1: loss = 0.364 (* 1 = 0.364 loss)
I0628 20:27:58.528533  1232 solver.cpp:218] Iteration 71500 (22.4557 iter/s, 4.45321s/100 iters), loss = 0.0714576
I0628 20:27:58.528533  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:27:58.528533  1232 solver.cpp:237]     Train net output #1: loss = 0.0714585 (* 1 = 0.0714585 loss)
I0628 20:27:58.528533  1232 sgd_solver.cpp:105] Iteration 71500, lr = 1e-05
I0628 20:28:02.122148  1232 solver.cpp:218] Iteration 71600 (27.8224 iter/s, 3.59423s/100 iters), loss = 0.160895
I0628 20:28:02.123148  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:28:02.123148  1232 solver.cpp:237]     Train net output #1: loss = 0.160896 (* 1 = 0.160896 loss)
I0628 20:28:02.123148  1232 sgd_solver.cpp:105] Iteration 71600, lr = 1e-05
I0628 20:28:05.708808  1232 solver.cpp:218] Iteration 71700 (27.8847 iter/s, 3.5862s/100 iters), loss = 0.15614
I0628 20:28:05.708808  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:28:05.708808  1232 solver.cpp:237]     Train net output #1: loss = 0.156141 (* 1 = 0.156141 loss)
I0628 20:28:05.708808  1232 sgd_solver.cpp:105] Iteration 71700, lr = 1e-05
I0628 20:28:09.302455  1232 solver.cpp:218] Iteration 71800 (27.832 iter/s, 3.59299s/100 iters), loss = 0.146536
I0628 20:28:09.302455  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:28:09.302455  1232 solver.cpp:237]     Train net output #1: loss = 0.146537 (* 1 = 0.146537 loss)
I0628 20:28:09.302455  1232 sgd_solver.cpp:105] Iteration 71800, lr = 1e-05
I0628 20:28:12.895166  1232 solver.cpp:218] Iteration 71900 (27.8394 iter/s, 3.59203s/100 iters), loss = 0.0664725
I0628 20:28:12.895166  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:28:12.895166  1232 solver.cpp:237]     Train net output #1: loss = 0.0664734 (* 1 = 0.0664734 loss)
I0628 20:28:12.895166  1232 sgd_solver.cpp:105] Iteration 71900, lr = 1e-05
I0628 20:28:16.304702 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:28:16.444806  1232 solver.cpp:330] Iteration 72000, Testing net (#0)
I0628 20:28:16.444806  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:28:17.257179 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:28:17.288203  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8958
I0628 20:28:17.288203  1232 solver.cpp:397]     Test net output #1: loss = 0.364073 (* 1 = 0.364073 loss)
I0628 20:28:17.323227  1232 solver.cpp:218] Iteration 72000 (22.5843 iter/s, 4.42785s/100 iters), loss = 0.111465
I0628 20:28:17.323227  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:28:17.323227  1232 solver.cpp:237]     Train net output #1: loss = 0.111466 (* 1 = 0.111466 loss)
I0628 20:28:17.323227  1232 sgd_solver.cpp:105] Iteration 72000, lr = 1e-05
I0628 20:28:20.915895  1232 solver.cpp:218] Iteration 72100 (27.8359 iter/s, 3.59248s/100 iters), loss = 0.105011
I0628 20:28:20.915895  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:28:20.915895  1232 solver.cpp:237]     Train net output #1: loss = 0.105012 (* 1 = 0.105012 loss)
I0628 20:28:20.915895  1232 sgd_solver.cpp:105] Iteration 72100, lr = 1e-05
I0628 20:28:24.498630  1232 solver.cpp:218] Iteration 72200 (27.9145 iter/s, 3.58237s/100 iters), loss = 0.0989728
I0628 20:28:24.498630  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:28:24.498630  1232 solver.cpp:237]     Train net output #1: loss = 0.0989737 (* 1 = 0.0989737 loss)
I0628 20:28:24.498630  1232 sgd_solver.cpp:105] Iteration 72200, lr = 1e-05
I0628 20:28:28.080287  1232 solver.cpp:218] Iteration 72300 (27.9259 iter/s, 3.58091s/100 iters), loss = 0.161115
I0628 20:28:28.080287  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:28:28.080287  1232 solver.cpp:237]     Train net output #1: loss = 0.161116 (* 1 = 0.161116 loss)
I0628 20:28:28.080287  1232 sgd_solver.cpp:105] Iteration 72300, lr = 1e-05
I0628 20:28:31.671964  1232 solver.cpp:218] Iteration 72400 (27.8383 iter/s, 3.59217s/100 iters), loss = 0.0608595
I0628 20:28:31.672966  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:28:31.672966  1232 solver.cpp:237]     Train net output #1: loss = 0.0608605 (* 1 = 0.0608605 loss)
I0628 20:28:31.672966  1232 sgd_solver.cpp:105] Iteration 72400, lr = 1e-05
I0628 20:28:35.089751 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:28:35.229853  1232 solver.cpp:330] Iteration 72500, Testing net (#0)
I0628 20:28:35.229853  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:28:36.047610 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:28:36.078675  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8954
I0628 20:28:36.078675  1232 solver.cpp:397]     Test net output #1: loss = 0.363805 (* 1 = 0.363805 loss)
I0628 20:28:36.112697  1232 solver.cpp:218] Iteration 72500 (22.5254 iter/s, 4.43944s/100 iters), loss = 0.0507964
I0628 20:28:36.112697  1232 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0628 20:28:36.112697  1232 solver.cpp:237]     Train net output #1: loss = 0.0507974 (* 1 = 0.0507974 loss)
I0628 20:28:36.112697  1232 sgd_solver.cpp:105] Iteration 72500, lr = 1e-05
I0628 20:28:39.704344  1232 solver.cpp:218] Iteration 72600 (27.8408 iter/s, 3.59185s/100 iters), loss = 0.136946
I0628 20:28:39.704344  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:28:39.704344  1232 solver.cpp:237]     Train net output #1: loss = 0.136947 (* 1 = 0.136947 loss)
I0628 20:28:39.704344  1232 sgd_solver.cpp:105] Iteration 72600, lr = 1e-05
I0628 20:28:43.302011  1232 solver.cpp:218] Iteration 72700 (27.7988 iter/s, 3.59728s/100 iters), loss = 0.139311
I0628 20:28:43.302011  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:28:43.302011  1232 solver.cpp:237]     Train net output #1: loss = 0.139312 (* 1 = 0.139312 loss)
I0628 20:28:43.302011  1232 sgd_solver.cpp:105] Iteration 72700, lr = 1e-05
I0628 20:28:46.900770  1232 solver.cpp:218] Iteration 72800 (27.795 iter/s, 3.59777s/100 iters), loss = 0.127233
I0628 20:28:46.900770  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:28:46.900770  1232 solver.cpp:237]     Train net output #1: loss = 0.127234 (* 1 = 0.127234 loss)
I0628 20:28:46.900770  1232 sgd_solver.cpp:105] Iteration 72800, lr = 1e-05
I0628 20:28:50.493333  1232 solver.cpp:218] Iteration 72900 (27.8314 iter/s, 3.59307s/100 iters), loss = 0.0859625
I0628 20:28:50.493333  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:28:50.493333  1232 solver.cpp:237]     Train net output #1: loss = 0.0859635 (* 1 = 0.0859635 loss)
I0628 20:28:50.493333  1232 sgd_solver.cpp:105] Iteration 72900, lr = 1e-05
I0628 20:28:53.915215 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:28:54.056361  1232 solver.cpp:330] Iteration 73000, Testing net (#0)
I0628 20:28:54.056361  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:28:54.872040 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:28:54.903092  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8957
I0628 20:28:54.903092  1232 solver.cpp:397]     Test net output #1: loss = 0.364033 (* 1 = 0.364033 loss)
I0628 20:28:54.937124  1232 solver.cpp:218] Iteration 73000 (22.5052 iter/s, 4.44342s/100 iters), loss = 0.0467543
I0628 20:28:54.937124  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:28:54.937124  1232 solver.cpp:237]     Train net output #1: loss = 0.0467552 (* 1 = 0.0467552 loss)
I0628 20:28:54.937124  1232 sgd_solver.cpp:105] Iteration 73000, lr = 1e-05
I0628 20:28:58.526690  1232 solver.cpp:218] Iteration 73100 (27.867 iter/s, 3.58848s/100 iters), loss = 0.226363
I0628 20:28:58.526690  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:28:58.526690  1232 solver.cpp:237]     Train net output #1: loss = 0.226364 (* 1 = 0.226364 loss)
I0628 20:28:58.526690  1232 sgd_solver.cpp:105] Iteration 73100, lr = 1e-05
I0628 20:29:02.116844  1232 solver.cpp:218] Iteration 73200 (27.8523 iter/s, 3.59036s/100 iters), loss = 0.0920388
I0628 20:29:02.116844  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:29:02.116844  1232 solver.cpp:237]     Train net output #1: loss = 0.0920396 (* 1 = 0.0920396 loss)
I0628 20:29:02.116844  1232 sgd_solver.cpp:105] Iteration 73200, lr = 1e-05
I0628 20:29:05.718935  1232 solver.cpp:218] Iteration 73300 (27.7668 iter/s, 3.60143s/100 iters), loss = 0.14933
I0628 20:29:05.718935  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:29:05.718935  1232 solver.cpp:237]     Train net output #1: loss = 0.149331 (* 1 = 0.149331 loss)
I0628 20:29:05.718935  1232 sgd_solver.cpp:105] Iteration 73300, lr = 1e-05
I0628 20:29:09.309285  1232 solver.cpp:218] Iteration 73400 (27.8508 iter/s, 3.59056s/100 iters), loss = 0.0566062
I0628 20:29:09.309285  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:29:09.309285  1232 solver.cpp:237]     Train net output #1: loss = 0.0566071 (* 1 = 0.0566071 loss)
I0628 20:29:09.309285  1232 sgd_solver.cpp:105] Iteration 73400, lr = 1e-05
I0628 20:29:12.731631 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:29:12.872735  1232 solver.cpp:330] Iteration 73500, Testing net (#0)
I0628 20:29:12.872735  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:29:13.687441 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:29:13.718466  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8957
I0628 20:29:13.718466  1232 solver.cpp:397]     Test net output #1: loss = 0.363865 (* 1 = 0.363865 loss)
I0628 20:29:13.752490  1232 solver.cpp:218] Iteration 73500 (22.5091 iter/s, 4.44265s/100 iters), loss = 0.0927669
I0628 20:29:13.752490  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:29:13.752490  1232 solver.cpp:237]     Train net output #1: loss = 0.0927677 (* 1 = 0.0927677 loss)
I0628 20:29:13.752490  1232 sgd_solver.cpp:105] Iteration 73500, lr = 1e-05
I0628 20:29:17.339627  1232 solver.cpp:218] Iteration 73600 (27.8797 iter/s, 3.58684s/100 iters), loss = 0.182112
I0628 20:29:17.339627  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:29:17.339627  1232 solver.cpp:237]     Train net output #1: loss = 0.182113 (* 1 = 0.182113 loss)
I0628 20:29:17.339627  1232 sgd_solver.cpp:105] Iteration 73600, lr = 1e-05
I0628 20:29:20.931087  1232 solver.cpp:218] Iteration 73700 (27.8523 iter/s, 3.59037s/100 iters), loss = 0.0841578
I0628 20:29:20.931087  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:29:20.931087  1232 solver.cpp:237]     Train net output #1: loss = 0.0841587 (* 1 = 0.0841587 loss)
I0628 20:29:20.931087  1232 sgd_solver.cpp:105] Iteration 73700, lr = 1e-05
I0628 20:29:24.514346  1232 solver.cpp:218] Iteration 73800 (27.9088 iter/s, 3.5831s/100 iters), loss = 0.120297
I0628 20:29:24.514346  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:29:24.514346  1232 solver.cpp:237]     Train net output #1: loss = 0.120298 (* 1 = 0.120298 loss)
I0628 20:29:24.514346  1232 sgd_solver.cpp:105] Iteration 73800, lr = 1e-05
I0628 20:29:28.118619  1232 solver.cpp:218] Iteration 73900 (27.7468 iter/s, 3.60402s/100 iters), loss = 0.0820889
I0628 20:29:28.118619  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:29:28.118619  1232 solver.cpp:237]     Train net output #1: loss = 0.0820897 (* 1 = 0.0820897 loss)
I0628 20:29:28.118619  1232 sgd_solver.cpp:105] Iteration 73900, lr = 1e-05
I0628 20:29:31.539207 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:29:31.680339  1232 solver.cpp:330] Iteration 74000, Testing net (#0)
I0628 20:29:31.680339  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:29:32.497885 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:29:32.528950  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8957
I0628 20:29:32.528950  1232 solver.cpp:397]     Test net output #1: loss = 0.364374 (* 1 = 0.364374 loss)
I0628 20:29:32.563971  1232 solver.cpp:218] Iteration 74000 (22.4986 iter/s, 4.44471s/100 iters), loss = 0.0910634
I0628 20:29:32.563971  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:29:32.563971  1232 solver.cpp:237]     Train net output #1: loss = 0.0910643 (* 1 = 0.0910643 loss)
I0628 20:29:32.563971  1232 sgd_solver.cpp:46] MultiStep Status: Iteration 74000, step = 4
I0628 20:29:32.563971  1232 sgd_solver.cpp:105] Iteration 74000, lr = 1e-06
I0628 20:29:36.161275  1232 solver.cpp:218] Iteration 74100 (27.7944 iter/s, 3.59785s/100 iters), loss = 0.201998
I0628 20:29:36.161275  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0628 20:29:36.161275  1232 solver.cpp:237]     Train net output #1: loss = 0.201999 (* 1 = 0.201999 loss)
I0628 20:29:36.161275  1232 sgd_solver.cpp:105] Iteration 74100, lr = 1e-06
I0628 20:29:39.763717  1232 solver.cpp:218] Iteration 74200 (27.7678 iter/s, 3.60129s/100 iters), loss = 0.171887
I0628 20:29:39.763717  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:29:39.763717  1232 solver.cpp:237]     Train net output #1: loss = 0.171888 (* 1 = 0.171888 loss)
I0628 20:29:39.763717  1232 sgd_solver.cpp:105] Iteration 74200, lr = 1e-06
I0628 20:29:43.365417  1232 solver.cpp:218] Iteration 74300 (27.7608 iter/s, 3.6022s/100 iters), loss = 0.161349
I0628 20:29:43.365417  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:29:43.365417  1232 solver.cpp:237]     Train net output #1: loss = 0.16135 (* 1 = 0.16135 loss)
I0628 20:29:43.366418  1232 sgd_solver.cpp:105] Iteration 74300, lr = 1e-06
I0628 20:29:46.952595  1232 solver.cpp:218] Iteration 74400 (27.8834 iter/s, 3.58637s/100 iters), loss = 0.0526769
I0628 20:29:46.952595  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:29:46.952595  1232 solver.cpp:237]     Train net output #1: loss = 0.0526779 (* 1 = 0.0526779 loss)
I0628 20:29:46.952595  1232 sgd_solver.cpp:105] Iteration 74400, lr = 1e-06
I0628 20:29:50.369814 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:29:50.510936  1232 solver.cpp:330] Iteration 74500, Testing net (#0)
I0628 20:29:50.510936  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:29:51.328296 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:29:51.358853  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8956
I0628 20:29:51.358853  1232 solver.cpp:397]     Test net output #1: loss = 0.364026 (* 1 = 0.364026 loss)
I0628 20:29:51.392850  1232 solver.cpp:218] Iteration 74500 (22.5232 iter/s, 4.43986s/100 iters), loss = 0.0813663
I0628 20:29:51.392850  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:29:51.392850  1232 solver.cpp:237]     Train net output #1: loss = 0.0813672 (* 1 = 0.0813672 loss)
I0628 20:29:51.392850  1232 sgd_solver.cpp:105] Iteration 74500, lr = 1e-06
I0628 20:29:54.991322  1232 solver.cpp:218] Iteration 74600 (27.7935 iter/s, 3.59796s/100 iters), loss = 0.229835
I0628 20:29:54.991322  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:29:54.991322  1232 solver.cpp:237]     Train net output #1: loss = 0.229836 (* 1 = 0.229836 loss)
I0628 20:29:54.991322  1232 sgd_solver.cpp:105] Iteration 74600, lr = 1e-06
I0628 20:29:58.584794  1232 solver.cpp:218] Iteration 74700 (27.8304 iter/s, 3.59319s/100 iters), loss = 0.120792
I0628 20:29:58.584794  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:29:58.584794  1232 solver.cpp:237]     Train net output #1: loss = 0.120792 (* 1 = 0.120792 loss)
I0628 20:29:58.584794  1232 sgd_solver.cpp:105] Iteration 74700, lr = 1e-06
I0628 20:30:02.176226  1232 solver.cpp:218] Iteration 74800 (27.8428 iter/s, 3.5916s/100 iters), loss = 0.115289
I0628 20:30:02.176226  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:30:02.176226  1232 solver.cpp:237]     Train net output #1: loss = 0.11529 (* 1 = 0.11529 loss)
I0628 20:30:02.176226  1232 sgd_solver.cpp:105] Iteration 74800, lr = 1e-06
I0628 20:30:05.770712  1232 solver.cpp:218] Iteration 74900 (27.8218 iter/s, 3.5943s/100 iters), loss = 0.0709358
I0628 20:30:05.770712  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:30:05.770712  1232 solver.cpp:237]     Train net output #1: loss = 0.0709366 (* 1 = 0.0709366 loss)
I0628 20:30:05.770712  1232 sgd_solver.cpp:105] Iteration 74900, lr = 1e-06
I0628 20:30:09.182958 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:30:09.325070  1232 solver.cpp:330] Iteration 75000, Testing net (#0)
I0628 20:30:09.325070  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:30:10.150370 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:30:10.172888  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8958
I0628 20:30:10.172888  1232 solver.cpp:397]     Test net output #1: loss = 0.364227 (* 1 = 0.364227 loss)
I0628 20:30:10.206928  1232 solver.cpp:218] Iteration 75000 (22.5454 iter/s, 4.43549s/100 iters), loss = 0.0455096
I0628 20:30:10.206928  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:30:10.206928  1232 solver.cpp:237]     Train net output #1: loss = 0.0455105 (* 1 = 0.0455105 loss)
I0628 20:30:10.206928  1232 sgd_solver.cpp:105] Iteration 75000, lr = 1e-06
I0628 20:30:13.801462  1232 solver.cpp:218] Iteration 75100 (27.8194 iter/s, 3.59461s/100 iters), loss = 0.198637
I0628 20:30:13.802464  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:30:13.802464  1232 solver.cpp:237]     Train net output #1: loss = 0.198638 (* 1 = 0.198638 loss)
I0628 20:30:13.802464  1232 sgd_solver.cpp:105] Iteration 75100, lr = 1e-06
I0628 20:30:17.403950  1232 solver.cpp:218] Iteration 75200 (27.7644 iter/s, 3.60174s/100 iters), loss = 0.106368
I0628 20:30:17.403950  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:30:17.403950  1232 solver.cpp:237]     Train net output #1: loss = 0.106369 (* 1 = 0.106369 loss)
I0628 20:30:17.403950  1232 sgd_solver.cpp:105] Iteration 75200, lr = 1e-06
I0628 20:30:20.993072  1232 solver.cpp:218] Iteration 75300 (27.8634 iter/s, 3.58894s/100 iters), loss = 0.126567
I0628 20:30:20.993072  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:30:20.993072  1232 solver.cpp:237]     Train net output #1: loss = 0.126568 (* 1 = 0.126568 loss)
I0628 20:30:20.993072  1232 sgd_solver.cpp:105] Iteration 75300, lr = 1e-06
I0628 20:30:24.576887  1232 solver.cpp:218] Iteration 75400 (27.9076 iter/s, 3.58325s/100 iters), loss = 0.0530353
I0628 20:30:24.576887  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:30:24.576887  1232 solver.cpp:237]     Train net output #1: loss = 0.0530362 (* 1 = 0.0530362 loss)
I0628 20:30:24.576887  1232 sgd_solver.cpp:105] Iteration 75400, lr = 1e-06
I0628 20:30:27.990423 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:30:28.130527  1232 solver.cpp:330] Iteration 75500, Testing net (#0)
I0628 20:30:28.130527  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:30:28.951838 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:30:28.974356  1232 solver.cpp:397]     Test net output #0: accuracy = 0.896
I0628 20:30:28.974356  1232 solver.cpp:397]     Test net output #1: loss = 0.363417 (* 1 = 0.363417 loss)
I0628 20:30:29.008383  1232 solver.cpp:218] Iteration 75500 (22.5669 iter/s, 4.43127s/100 iters), loss = 0.0841509
I0628 20:30:29.008383  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:30:29.008383  1232 solver.cpp:237]     Train net output #1: loss = 0.0841517 (* 1 = 0.0841517 loss)
I0628 20:30:29.008383  1232 sgd_solver.cpp:105] Iteration 75500, lr = 1e-06
I0628 20:30:32.606060  1232 solver.cpp:218] Iteration 75600 (27.7967 iter/s, 3.59755s/100 iters), loss = 0.195055
I0628 20:30:32.606060  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:30:32.606060  1232 solver.cpp:237]     Train net output #1: loss = 0.195056 (* 1 = 0.195056 loss)
I0628 20:30:32.606060  1232 sgd_solver.cpp:105] Iteration 75600, lr = 1e-06
I0628 20:30:36.193727  1232 solver.cpp:218] Iteration 75700 (27.8805 iter/s, 3.58674s/100 iters), loss = 0.164532
I0628 20:30:36.193727  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:30:36.193727  1232 solver.cpp:237]     Train net output #1: loss = 0.164533 (* 1 = 0.164533 loss)
I0628 20:30:36.193727  1232 sgd_solver.cpp:105] Iteration 75700, lr = 1e-06
I0628 20:30:39.782085  1232 solver.cpp:218] Iteration 75800 (27.8684 iter/s, 3.58829s/100 iters), loss = 0.0852236
I0628 20:30:39.782585  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:30:39.782585  1232 solver.cpp:237]     Train net output #1: loss = 0.0852245 (* 1 = 0.0852245 loss)
I0628 20:30:39.782585  1232 sgd_solver.cpp:105] Iteration 75800, lr = 1e-06
I0628 20:30:43.361301  1232 solver.cpp:218] Iteration 75900 (27.9394 iter/s, 3.57917s/100 iters), loss = 0.0765623
I0628 20:30:43.361301  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:30:43.361301  1232 solver.cpp:237]     Train net output #1: loss = 0.0765632 (* 1 = 0.0765632 loss)
I0628 20:30:43.361301  1232 sgd_solver.cpp:105] Iteration 75900, lr = 1e-06
I0628 20:30:46.774358 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:30:46.913960  1232 solver.cpp:330] Iteration 76000, Testing net (#0)
I0628 20:30:46.913960  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:30:47.733618 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:30:47.764644  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8953
I0628 20:30:47.764644  1232 solver.cpp:397]     Test net output #1: loss = 0.363817 (* 1 = 0.363817 loss)
I0628 20:30:47.799238  1232 solver.cpp:218] Iteration 76000 (22.5377 iter/s, 4.43701s/100 iters), loss = 0.0492077
I0628 20:30:47.799238  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:30:47.799238  1232 solver.cpp:237]     Train net output #1: loss = 0.0492086 (* 1 = 0.0492086 loss)
I0628 20:30:47.799238  1232 sgd_solver.cpp:105] Iteration 76000, lr = 1e-06
I0628 20:30:51.391628  1232 solver.cpp:218] Iteration 76100 (27.8393 iter/s, 3.59205s/100 iters), loss = 0.215626
I0628 20:30:51.391628  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:30:51.391628  1232 solver.cpp:237]     Train net output #1: loss = 0.215627 (* 1 = 0.215627 loss)
I0628 20:30:51.391628  1232 sgd_solver.cpp:105] Iteration 76100, lr = 1e-06
I0628 20:30:54.984442  1232 solver.cpp:218] Iteration 76200 (27.8358 iter/s, 3.59249s/100 iters), loss = 0.0992881
I0628 20:30:54.984442  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:30:54.984442  1232 solver.cpp:237]     Train net output #1: loss = 0.0992889 (* 1 = 0.0992889 loss)
I0628 20:30:54.984442  1232 sgd_solver.cpp:105] Iteration 76200, lr = 1e-06
I0628 20:30:58.585127  1232 solver.cpp:218] Iteration 76300 (27.7751 iter/s, 3.60035s/100 iters), loss = 0.104726
I0628 20:30:58.585127  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:30:58.585127  1232 solver.cpp:237]     Train net output #1: loss = 0.104727 (* 1 = 0.104727 loss)
I0628 20:30:58.585127  1232 sgd_solver.cpp:105] Iteration 76300, lr = 1e-06
I0628 20:31:02.181733  1232 solver.cpp:218] Iteration 76400 (27.8044 iter/s, 3.59655s/100 iters), loss = 0.0502545
I0628 20:31:02.181733  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:31:02.181733  1232 solver.cpp:237]     Train net output #1: loss = 0.0502553 (* 1 = 0.0502553 loss)
I0628 20:31:02.181733  1232 sgd_solver.cpp:105] Iteration 76400, lr = 1e-06
I0628 20:31:05.605270 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:31:05.745415  1232 solver.cpp:330] Iteration 76500, Testing net (#0)
I0628 20:31:05.745415  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:31:06.558228 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:31:06.589251  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8957
I0628 20:31:06.590251  1232 solver.cpp:397]     Test net output #1: loss = 0.363967 (* 1 = 0.363967 loss)
I0628 20:31:06.624307  1232 solver.cpp:218] Iteration 76500 (22.5131 iter/s, 4.44186s/100 iters), loss = 0.059891
I0628 20:31:06.624307  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:31:06.624307  1232 solver.cpp:237]     Train net output #1: loss = 0.0598917 (* 1 = 0.0598917 loss)
I0628 20:31:06.624307  1232 sgd_solver.cpp:105] Iteration 76500, lr = 1e-06
I0628 20:31:10.211861  1232 solver.cpp:218] Iteration 76600 (27.8705 iter/s, 3.58802s/100 iters), loss = 0.117108
I0628 20:31:10.211861  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:31:10.211861  1232 solver.cpp:237]     Train net output #1: loss = 0.117109 (* 1 = 0.117109 loss)
I0628 20:31:10.211861  1232 sgd_solver.cpp:105] Iteration 76600, lr = 1e-06
I0628 20:31:13.805241  1232 solver.cpp:218] Iteration 76700 (27.8388 iter/s, 3.59211s/100 iters), loss = 0.125719
I0628 20:31:13.805241  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:31:13.805241  1232 solver.cpp:237]     Train net output #1: loss = 0.12572 (* 1 = 0.12572 loss)
I0628 20:31:13.805241  1232 sgd_solver.cpp:105] Iteration 76700, lr = 1e-06
I0628 20:31:17.396525  1232 solver.cpp:218] Iteration 76800 (27.8439 iter/s, 3.59144s/100 iters), loss = 0.150081
I0628 20:31:17.396525  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:31:17.396525  1232 solver.cpp:237]     Train net output #1: loss = 0.150082 (* 1 = 0.150082 loss)
I0628 20:31:17.396525  1232 sgd_solver.cpp:105] Iteration 76800, lr = 1e-06
I0628 20:31:21.001348  1232 solver.cpp:218] Iteration 76900 (27.7443 iter/s, 3.60434s/100 iters), loss = 0.0804431
I0628 20:31:21.001348  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:31:21.001348  1232 solver.cpp:237]     Train net output #1: loss = 0.0804438 (* 1 = 0.0804438 loss)
I0628 20:31:21.001848  1232 sgd_solver.cpp:105] Iteration 76900, lr = 1e-06
I0628 20:31:24.436384 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:31:24.576534  1232 solver.cpp:330] Iteration 77000, Testing net (#0)
I0628 20:31:24.577533  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:31:25.392244 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:31:25.423801  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8955
I0628 20:31:25.423801  1232 solver.cpp:397]     Test net output #1: loss = 0.364049 (* 1 = 0.364049 loss)
I0628 20:31:25.457340  1232 solver.cpp:218] Iteration 77000 (22.4414 iter/s, 4.45605s/100 iters), loss = 0.0671039
I0628 20:31:25.457340  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:31:25.457340  1232 solver.cpp:237]     Train net output #1: loss = 0.0671047 (* 1 = 0.0671047 loss)
I0628 20:31:25.457340  1232 sgd_solver.cpp:105] Iteration 77000, lr = 1e-06
I0628 20:31:29.047857  1232 solver.cpp:218] Iteration 77100 (27.8561 iter/s, 3.58988s/100 iters), loss = 0.215196
I0628 20:31:29.047857  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:31:29.047857  1232 solver.cpp:237]     Train net output #1: loss = 0.215197 (* 1 = 0.215197 loss)
I0628 20:31:29.047857  1232 sgd_solver.cpp:105] Iteration 77100, lr = 1e-06
I0628 20:31:32.642375  1232 solver.cpp:218] Iteration 77200 (27.8223 iter/s, 3.59424s/100 iters), loss = 0.106972
I0628 20:31:32.642375  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:31:32.642375  1232 solver.cpp:237]     Train net output #1: loss = 0.106973 (* 1 = 0.106973 loss)
I0628 20:31:32.642375  1232 sgd_solver.cpp:105] Iteration 77200, lr = 1e-06
I0628 20:31:36.241466  1232 solver.cpp:218] Iteration 77300 (27.7915 iter/s, 3.59822s/100 iters), loss = 0.101821
I0628 20:31:36.241466  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:31:36.241466  1232 solver.cpp:237]     Train net output #1: loss = 0.101822 (* 1 = 0.101822 loss)
I0628 20:31:36.241466  1232 sgd_solver.cpp:105] Iteration 77300, lr = 1e-06
I0628 20:31:39.838316  1232 solver.cpp:218] Iteration 77400 (27.8052 iter/s, 3.59645s/100 iters), loss = 0.06578
I0628 20:31:39.838316  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:31:39.838316  1232 solver.cpp:237]     Train net output #1: loss = 0.0657808 (* 1 = 0.0657808 loss)
I0628 20:31:39.838316  1232 sgd_solver.cpp:105] Iteration 77400, lr = 1e-06
I0628 20:31:43.255959 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:31:43.398092  1232 solver.cpp:330] Iteration 77500, Testing net (#0)
I0628 20:31:43.398092  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:31:44.216799 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:31:44.247855  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8957
I0628 20:31:44.247855  1232 solver.cpp:397]     Test net output #1: loss = 0.364257 (* 1 = 0.364257 loss)
I0628 20:31:44.281888  1232 solver.cpp:218] Iteration 77500 (22.5048 iter/s, 4.44349s/100 iters), loss = 0.0773152
I0628 20:31:44.281888  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:31:44.281888  1232 solver.cpp:237]     Train net output #1: loss = 0.077316 (* 1 = 0.077316 loss)
I0628 20:31:44.281888  1232 sgd_solver.cpp:105] Iteration 77500, lr = 1e-06
I0628 20:31:47.886188  1232 solver.cpp:218] Iteration 77600 (27.7425 iter/s, 3.60458s/100 iters), loss = 0.180216
I0628 20:31:47.887188  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:31:47.887188  1232 solver.cpp:237]     Train net output #1: loss = 0.180217 (* 1 = 0.180217 loss)
I0628 20:31:47.887188  1232 sgd_solver.cpp:105] Iteration 77600, lr = 1e-06
I0628 20:31:51.489153  1232 solver.cpp:218] Iteration 77700 (27.7599 iter/s, 3.60232s/100 iters), loss = 0.16171
I0628 20:31:51.489153  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0628 20:31:51.489153  1232 solver.cpp:237]     Train net output #1: loss = 0.161711 (* 1 = 0.161711 loss)
I0628 20:31:51.489153  1232 sgd_solver.cpp:105] Iteration 77700, lr = 1e-06
I0628 20:31:55.096580  1232 solver.cpp:218] Iteration 77800 (27.7227 iter/s, 3.60715s/100 iters), loss = 0.145051
I0628 20:31:55.096580  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0628 20:31:55.096580  1232 solver.cpp:237]     Train net output #1: loss = 0.145051 (* 1 = 0.145051 loss)
I0628 20:31:55.096580  1232 sgd_solver.cpp:105] Iteration 77800, lr = 1e-06
I0628 20:31:58.693106  1232 solver.cpp:218] Iteration 77900 (27.8076 iter/s, 3.59614s/100 iters), loss = 0.0532802
I0628 20:31:58.693106  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:31:58.693106  1232 solver.cpp:237]     Train net output #1: loss = 0.053281 (* 1 = 0.053281 loss)
I0628 20:31:58.693106  1232 sgd_solver.cpp:105] Iteration 77900, lr = 1e-06
I0628 20:32:02.126421 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:32:02.266435  1232 solver.cpp:330] Iteration 78000, Testing net (#0)
I0628 20:32:02.266435  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:32:03.079383 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:32:03.109423  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8959
I0628 20:32:03.109423  1232 solver.cpp:397]     Test net output #1: loss = 0.363879 (* 1 = 0.363879 loss)
I0628 20:32:03.143932  1232 solver.cpp:218] Iteration 78000 (22.4715 iter/s, 4.45008s/100 iters), loss = 0.0816464
I0628 20:32:03.143932  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:32:03.143932  1232 solver.cpp:237]     Train net output #1: loss = 0.0816472 (* 1 = 0.0816472 loss)
I0628 20:32:03.143932  1232 sgd_solver.cpp:105] Iteration 78000, lr = 1e-06
I0628 20:32:06.740851  1232 solver.cpp:218] Iteration 78100 (27.8055 iter/s, 3.59641s/100 iters), loss = 0.233595
I0628 20:32:06.740851  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0628 20:32:06.740851  1232 solver.cpp:237]     Train net output #1: loss = 0.233595 (* 1 = 0.233595 loss)
I0628 20:32:06.740851  1232 sgd_solver.cpp:105] Iteration 78100, lr = 1e-06
I0628 20:32:10.345474  1232 solver.cpp:218] Iteration 78200 (27.7422 iter/s, 3.60462s/100 iters), loss = 0.107757
I0628 20:32:10.345974  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:32:10.345974  1232 solver.cpp:237]     Train net output #1: loss = 0.107758 (* 1 = 0.107758 loss)
I0628 20:32:10.345974  1232 sgd_solver.cpp:105] Iteration 78200, lr = 1e-06
I0628 20:32:13.937376  1232 solver.cpp:218] Iteration 78300 (27.8459 iter/s, 3.5912s/100 iters), loss = 0.100606
I0628 20:32:13.937376  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:32:13.937376  1232 solver.cpp:237]     Train net output #1: loss = 0.100607 (* 1 = 0.100607 loss)
I0628 20:32:13.937376  1232 sgd_solver.cpp:105] Iteration 78300, lr = 1e-06
I0628 20:32:17.530323  1232 solver.cpp:218] Iteration 78400 (27.8355 iter/s, 3.59254s/100 iters), loss = 0.0606484
I0628 20:32:17.530323  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0628 20:32:17.530323  1232 solver.cpp:237]     Train net output #1: loss = 0.0606491 (* 1 = 0.0606491 loss)
I0628 20:32:17.530323  1232 sgd_solver.cpp:105] Iteration 78400, lr = 1e-06
I0628 20:32:20.957588 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:32:21.097754  1232 solver.cpp:330] Iteration 78500, Testing net (#0)
I0628 20:32:21.097754  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:32:21.914427 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:32:21.945453  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8955
I0628 20:32:21.945453  1232 solver.cpp:397]     Test net output #1: loss = 0.363643 (* 1 = 0.363643 loss)
I0628 20:32:21.979377  1232 solver.cpp:218] Iteration 78500 (22.4752 iter/s, 4.44934s/100 iters), loss = 0.0897563
I0628 20:32:21.979377  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:32:21.979377  1232 solver.cpp:237]     Train net output #1: loss = 0.089757 (* 1 = 0.089757 loss)
I0628 20:32:21.979377  1232 sgd_solver.cpp:105] Iteration 78500, lr = 1e-06
I0628 20:32:25.569255  1232 solver.cpp:218] Iteration 78600 (27.858 iter/s, 3.58963s/100 iters), loss = 0.108497
I0628 20:32:25.569255  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:32:25.569255  1232 solver.cpp:237]     Train net output #1: loss = 0.108497 (* 1 = 0.108497 loss)
I0628 20:32:25.569255  1232 sgd_solver.cpp:105] Iteration 78600, lr = 1e-06
I0628 20:32:29.163429  1232 solver.cpp:218] Iteration 78700 (27.8287 iter/s, 3.59341s/100 iters), loss = 0.148593
I0628 20:32:29.163429  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:32:29.163429  1232 solver.cpp:237]     Train net output #1: loss = 0.148594 (* 1 = 0.148594 loss)
I0628 20:32:29.163429  1232 sgd_solver.cpp:105] Iteration 78700, lr = 1e-06
I0628 20:32:32.754413  1232 solver.cpp:218] Iteration 78800 (27.8461 iter/s, 3.59117s/100 iters), loss = 0.118335
I0628 20:32:32.754413  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:32:32.754413  1232 solver.cpp:237]     Train net output #1: loss = 0.118335 (* 1 = 0.118335 loss)
I0628 20:32:32.754413  1232 sgd_solver.cpp:105] Iteration 78800, lr = 1e-06
I0628 20:32:36.344619  1232 solver.cpp:218] Iteration 78900 (27.8565 iter/s, 3.58983s/100 iters), loss = 0.0523711
I0628 20:32:36.344619  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:32:36.344619  1232 solver.cpp:237]     Train net output #1: loss = 0.0523718 (* 1 = 0.0523718 loss)
I0628 20:32:36.344619  1232 sgd_solver.cpp:105] Iteration 78900, lr = 1e-06
I0628 20:32:39.775532 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:32:39.919664  1232 solver.cpp:330] Iteration 79000, Testing net (#0)
I0628 20:32:39.919664  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:32:40.733346 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:32:40.763888  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8956
I0628 20:32:40.763888  1232 solver.cpp:397]     Test net output #1: loss = 0.364562 (* 1 = 0.364562 loss)
I0628 20:32:40.798912  1232 solver.cpp:218] Iteration 79000 (22.4552 iter/s, 4.45331s/100 iters), loss = 0.0919814
I0628 20:32:40.798912  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:32:40.798912  1232 solver.cpp:237]     Train net output #1: loss = 0.0919822 (* 1 = 0.0919822 loss)
I0628 20:32:40.798912  1232 sgd_solver.cpp:105] Iteration 79000, lr = 1e-06
I0628 20:32:44.390537  1232 solver.cpp:218] Iteration 79100 (27.84 iter/s, 3.59195s/100 iters), loss = 0.122902
I0628 20:32:44.390537  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:32:44.390537  1232 solver.cpp:237]     Train net output #1: loss = 0.122903 (* 1 = 0.122903 loss)
I0628 20:32:44.390537  1232 sgd_solver.cpp:105] Iteration 79100, lr = 1e-06
I0628 20:32:47.985987  1232 solver.cpp:218] Iteration 79200 (27.815 iter/s, 3.59519s/100 iters), loss = 0.176788
I0628 20:32:47.985987  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:32:47.985987  1232 solver.cpp:237]     Train net output #1: loss = 0.176789 (* 1 = 0.176789 loss)
I0628 20:32:47.985987  1232 sgd_solver.cpp:105] Iteration 79200, lr = 1e-06
I0628 20:32:51.586096  1232 solver.cpp:218] Iteration 79300 (27.7796 iter/s, 3.59976s/100 iters), loss = 0.117019
I0628 20:32:51.586096  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:32:51.586096  1232 solver.cpp:237]     Train net output #1: loss = 0.117019 (* 1 = 0.117019 loss)
I0628 20:32:51.586096  1232 sgd_solver.cpp:105] Iteration 79300, lr = 1e-06
I0628 20:32:55.245192  1232 solver.cpp:218] Iteration 79400 (27.3381 iter/s, 3.6579s/100 iters), loss = 0.0869692
I0628 20:32:55.245192  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:32:55.245192  1232 solver.cpp:237]     Train net output #1: loss = 0.0869699 (* 1 = 0.0869699 loss)
I0628 20:32:55.245192  1232 sgd_solver.cpp:105] Iteration 79400, lr = 1e-06
I0628 20:32:58.684816 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:32:58.824923  1232 solver.cpp:330] Iteration 79500, Testing net (#0)
I0628 20:32:58.824923  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:32:59.637688 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:32:59.669445  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8953
I0628 20:32:59.669445  1232 solver.cpp:397]     Test net output #1: loss = 0.364419 (* 1 = 0.364419 loss)
I0628 20:32:59.703454  1232 solver.cpp:218] Iteration 79500 (22.4321 iter/s, 4.45791s/100 iters), loss = 0.087886
I0628 20:32:59.703454  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0628 20:32:59.703454  1232 solver.cpp:237]     Train net output #1: loss = 0.0878867 (* 1 = 0.0878867 loss)
I0628 20:32:59.703454  1232 sgd_solver.cpp:105] Iteration 79500, lr = 1e-06
I0628 20:33:03.295847  1232 solver.cpp:218] Iteration 79600 (27.8347 iter/s, 3.59264s/100 iters), loss = 0.166853
I0628 20:33:03.295847  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0628 20:33:03.295847  1232 solver.cpp:237]     Train net output #1: loss = 0.166854 (* 1 = 0.166854 loss)
I0628 20:33:03.295847  1232 sgd_solver.cpp:105] Iteration 79600, lr = 1e-06
I0628 20:33:06.888047  1232 solver.cpp:218] Iteration 79700 (27.8417 iter/s, 3.59174s/100 iters), loss = 0.139217
I0628 20:33:06.888047  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:33:06.888047  1232 solver.cpp:237]     Train net output #1: loss = 0.139218 (* 1 = 0.139218 loss)
I0628 20:33:06.888047  1232 sgd_solver.cpp:105] Iteration 79700, lr = 1e-06
I0628 20:33:10.489241  1232 solver.cpp:218] Iteration 79800 (27.7715 iter/s, 3.60082s/100 iters), loss = 0.172335
I0628 20:33:10.489241  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0628 20:33:10.489241  1232 solver.cpp:237]     Train net output #1: loss = 0.172336 (* 1 = 0.172336 loss)
I0628 20:33:10.489241  1232 sgd_solver.cpp:105] Iteration 79800, lr = 1e-06
I0628 20:33:14.071813  1232 solver.cpp:218] Iteration 79900 (27.916 iter/s, 3.58217s/100 iters), loss = 0.105628
I0628 20:33:14.071813  1232 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0628 20:33:14.071813  1232 solver.cpp:237]     Train net output #1: loss = 0.105628 (* 1 = 0.105628 loss)
I0628 20:33:14.071813  1232 sgd_solver.cpp:105] Iteration 79900, lr = 1e-06
I0628 20:33:17.544890 13656 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:33:17.684993  1232 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/128K_iter_80000.caffemodel
I0628 20:33:17.695003  1232 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/128K_iter_80000.solverstate
I0628 20:33:17.706007  1232 solver.cpp:310] Iteration 80000, loss = 0.0658344
I0628 20:33:17.706007  1232 solver.cpp:330] Iteration 80000, Testing net (#0)
I0628 20:33:17.706007  1232 net.cpp:676] Ignoring source layer accuracy_training
I0628 20:33:18.533628 13380 data_layer.cpp:73] Restarting data prefetching from start.
I0628 20:33:18.556645  1232 solver.cpp:397]     Test net output #0: accuracy = 0.8948
I0628 20:33:18.556645  1232 solver.cpp:397]     Test net output #1: loss = 0.364415 (* 1 = 0.364415 loss)
I0628 20:33:18.556645  1232 solver.cpp:315] Optimization Done.
I0628 20:33:18.556645  1232 caffe.cpp:260] Optimization Done.
G:\Caffe>