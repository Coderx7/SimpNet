
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I1004 21:25:20.613692  3812 caffe.cpp:219] Using GPUs 0
I1004 21:25:20.798684  3812 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1004 21:25:21.150681  3812 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 21:25:21.167680  3812 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 25000
snapshot_prefix: "examples/cifar10/slimnet_simpnet_P3"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 25000
type: "Nesterov"
I1004 21:25:21.220681  3812 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 21:25:21.221681  3812 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 21:25:21.221681  3812 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1004 21:25:21.221681  3812 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1004 21:25:21.222681  3812 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P3__"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1004 21:25:21.270076  3812 layer_factory.cpp:58] Creating layer cifar
I1004 21:25:21.412672  3812 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I1004 21:25:21.412672  3812 net.cpp:84] Creating Layer cifar
I1004 21:25:21.413668  3812 net.cpp:380] cifar -> data
I1004 21:25:21.413668  3812 net.cpp:380] cifar -> label
I1004 21:25:21.413668  3812 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1004 21:25:21.415669  3812 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 21:25:21.415669  3812 data_layer.cpp:45] output data size: 100,3,32,32
I1004 21:25:21.423657  3812 net.cpp:122] Setting up cifar
I1004 21:25:21.423657  3812 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1004 21:25:21.423657  3812 net.cpp:129] Top shape: 100 (100)
I1004 21:25:21.423657  3812 net.cpp:137] Memory required for data: 1229200
I1004 21:25:21.423657  3812 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1004 21:25:21.423657  3812 net.cpp:84] Creating Layer label_cifar_1_split
I1004 21:25:21.423657  3812 net.cpp:406] label_cifar_1_split <- label
I1004 21:25:21.423657  3812 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1004 21:25:21.423657  3812 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1004 21:25:21.423657  3812 net.cpp:122] Setting up label_cifar_1_split
I1004 21:25:21.423657  3812 net.cpp:129] Top shape: 100 (100)
I1004 21:25:21.423657  3812 net.cpp:129] Top shape: 100 (100)
I1004 21:25:21.423657  3812 net.cpp:137] Memory required for data: 1230000
I1004 21:25:21.423657  3812 layer_factory.cpp:58] Creating layer conv1
I1004 21:25:21.423657  3812 net.cpp:84] Creating Layer conv1
I1004 21:25:21.423657  3812 net.cpp:406] conv1 <- data
I1004 21:25:21.423657  3812 net.cpp:380] conv1 -> conv1
I1004 21:25:21.424655 16840 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 21:25:21.674654  3812 net.cpp:122] Setting up conv1
I1004 21:25:21.675653  3812 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:25:21.675653  3812 net.cpp:137] Memory required for data: 3687600
I1004 21:25:21.675653  3812 layer_factory.cpp:58] Creating layer bn1
I1004 21:25:21.675653  3812 net.cpp:84] Creating Layer bn1
I1004 21:25:21.675653  3812 net.cpp:406] bn1 <- conv1
I1004 21:25:21.675653  3812 net.cpp:367] bn1 -> conv1 (in-place)
I1004 21:25:21.675653  3812 net.cpp:122] Setting up bn1
I1004 21:25:21.675653  3812 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:25:21.675653  3812 net.cpp:137] Memory required for data: 6145200
I1004 21:25:21.675653  3812 layer_factory.cpp:58] Creating layer scale1
I1004 21:25:21.675653  3812 net.cpp:84] Creating Layer scale1
I1004 21:25:21.675653  3812 net.cpp:406] scale1 <- conv1
I1004 21:25:21.675653  3812 net.cpp:367] scale1 -> conv1 (in-place)
I1004 21:25:21.675653  3812 layer_factory.cpp:58] Creating layer scale1
I1004 21:25:21.675653  3812 net.cpp:122] Setting up scale1
I1004 21:25:21.675653  3812 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:25:21.675653  3812 net.cpp:137] Memory required for data: 8602800
I1004 21:25:21.675653  3812 layer_factory.cpp:58] Creating layer relu1
I1004 21:25:21.675653  3812 net.cpp:84] Creating Layer relu1
I1004 21:25:21.675653  3812 net.cpp:406] relu1 <- conv1
I1004 21:25:21.675653  3812 net.cpp:367] relu1 -> conv1 (in-place)
I1004 21:25:21.675653  3812 net.cpp:122] Setting up relu1
I1004 21:25:21.675653  3812 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:25:21.675653  3812 net.cpp:137] Memory required for data: 11060400
I1004 21:25:21.675653  3812 layer_factory.cpp:58] Creating layer conv1_0
I1004 21:25:21.675653  3812 net.cpp:84] Creating Layer conv1_0
I1004 21:25:21.675653  3812 net.cpp:406] conv1_0 <- conv1
I1004 21:25:21.675653  3812 net.cpp:380] conv1_0 -> conv1_0
I1004 21:25:21.677651  3812 net.cpp:122] Setting up conv1_0
I1004 21:25:21.677651  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.677651  3812 net.cpp:137] Memory required for data: 15975600
I1004 21:25:21.677651  3812 layer_factory.cpp:58] Creating layer bn1_0
I1004 21:25:21.677651  3812 net.cpp:84] Creating Layer bn1_0
I1004 21:25:21.677651  3812 net.cpp:406] bn1_0 <- conv1_0
I1004 21:25:21.677651  3812 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1004 21:25:21.677651  3812 net.cpp:122] Setting up bn1_0
I1004 21:25:21.677651  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.677651  3812 net.cpp:137] Memory required for data: 20890800
I1004 21:25:21.677651  3812 layer_factory.cpp:58] Creating layer scale1_0
I1004 21:25:21.677651  3812 net.cpp:84] Creating Layer scale1_0
I1004 21:25:21.677651  3812 net.cpp:406] scale1_0 <- conv1_0
I1004 21:25:21.677651  3812 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1004 21:25:21.677651  3812 layer_factory.cpp:58] Creating layer scale1_0
I1004 21:25:21.677651  3812 net.cpp:122] Setting up scale1_0
I1004 21:25:21.677651  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.677651  3812 net.cpp:137] Memory required for data: 25806000
I1004 21:25:21.677651  3812 layer_factory.cpp:58] Creating layer relu1_0
I1004 21:25:21.677651  3812 net.cpp:84] Creating Layer relu1_0
I1004 21:25:21.677651  3812 net.cpp:406] relu1_0 <- conv1_0
I1004 21:25:21.677651  3812 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1004 21:25:21.678653  3812 net.cpp:122] Setting up relu1_0
I1004 21:25:21.678653  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.678653  3812 net.cpp:137] Memory required for data: 30721200
I1004 21:25:21.678653  3812 layer_factory.cpp:58] Creating layer conv2
I1004 21:25:21.678653  3812 net.cpp:84] Creating Layer conv2
I1004 21:25:21.678653  3812 net.cpp:406] conv2 <- conv1_0
I1004 21:25:21.678653  3812 net.cpp:380] conv2 -> conv2
I1004 21:25:21.678653  3812 net.cpp:122] Setting up conv2
I1004 21:25:21.678653  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.678653  3812 net.cpp:137] Memory required for data: 35636400
I1004 21:25:21.678653  3812 layer_factory.cpp:58] Creating layer bn2
I1004 21:25:21.678653  3812 net.cpp:84] Creating Layer bn2
I1004 21:25:21.678653  3812 net.cpp:406] bn2 <- conv2
I1004 21:25:21.678653  3812 net.cpp:367] bn2 -> conv2 (in-place)
I1004 21:25:21.679653  3812 net.cpp:122] Setting up bn2
I1004 21:25:21.679653  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.679653  3812 net.cpp:137] Memory required for data: 40551600
I1004 21:25:21.679653  3812 layer_factory.cpp:58] Creating layer scale2
I1004 21:25:21.679653  3812 net.cpp:84] Creating Layer scale2
I1004 21:25:21.679653  3812 net.cpp:406] scale2 <- conv2
I1004 21:25:21.679653  3812 net.cpp:367] scale2 -> conv2 (in-place)
I1004 21:25:21.679653  3812 layer_factory.cpp:58] Creating layer scale2
I1004 21:25:21.679653  3812 net.cpp:122] Setting up scale2
I1004 21:25:21.679653  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.679653  3812 net.cpp:137] Memory required for data: 45466800
I1004 21:25:21.679653  3812 layer_factory.cpp:58] Creating layer relu2
I1004 21:25:21.679653  3812 net.cpp:84] Creating Layer relu2
I1004 21:25:21.679653  3812 net.cpp:406] relu2 <- conv2
I1004 21:25:21.679653  3812 net.cpp:367] relu2 -> conv2 (in-place)
I1004 21:25:21.679653  3812 net.cpp:122] Setting up relu2
I1004 21:25:21.679653  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.679653  3812 net.cpp:137] Memory required for data: 50382000
I1004 21:25:21.679653  3812 layer_factory.cpp:58] Creating layer pool2_1
I1004 21:25:21.679653  3812 net.cpp:84] Creating Layer pool2_1
I1004 21:25:21.679653  3812 net.cpp:406] pool2_1 <- conv2
I1004 21:25:21.679653  3812 net.cpp:380] pool2_1 -> pool2_1
I1004 21:25:21.679653  3812 net.cpp:122] Setting up pool2_1
I1004 21:25:21.679653  3812 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:25:21.679653  3812 net.cpp:137] Memory required for data: 51610800
I1004 21:25:21.679653  3812 layer_factory.cpp:58] Creating layer conv2_1
I1004 21:25:21.679653  3812 net.cpp:84] Creating Layer conv2_1
I1004 21:25:21.679653  3812 net.cpp:406] conv2_1 <- pool2_1
I1004 21:25:21.679653  3812 net.cpp:380] conv2_1 -> conv2_1
I1004 21:25:21.680654  3812 net.cpp:122] Setting up conv2_1
I1004 21:25:21.680654  3812 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:25:21.680654  3812 net.cpp:137] Memory required for data: 52839600
I1004 21:25:21.680654  3812 layer_factory.cpp:58] Creating layer bn2_1
I1004 21:25:21.680654  3812 net.cpp:84] Creating Layer bn2_1
I1004 21:25:21.680654  3812 net.cpp:406] bn2_1 <- conv2_1
I1004 21:25:21.680654  3812 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1004 21:25:21.681653  3812 net.cpp:122] Setting up bn2_1
I1004 21:25:21.681653  3812 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:25:21.681653  3812 net.cpp:137] Memory required for data: 54068400
I1004 21:25:21.681653  3812 layer_factory.cpp:58] Creating layer scale2_1
I1004 21:25:21.681653  3812 net.cpp:84] Creating Layer scale2_1
I1004 21:25:21.681653  3812 net.cpp:406] scale2_1 <- conv2_1
I1004 21:25:21.681653  3812 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1004 21:25:21.681653  3812 layer_factory.cpp:58] Creating layer scale2_1
I1004 21:25:21.681653  3812 net.cpp:122] Setting up scale2_1
I1004 21:25:21.681653  3812 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:25:21.681653  3812 net.cpp:137] Memory required for data: 55297200
I1004 21:25:21.681653  3812 layer_factory.cpp:58] Creating layer relu2_1
I1004 21:25:21.681653  3812 net.cpp:84] Creating Layer relu2_1
I1004 21:25:21.681653  3812 net.cpp:406] relu2_1 <- conv2_1
I1004 21:25:21.681653  3812 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1004 21:25:21.681653  3812 net.cpp:122] Setting up relu2_1
I1004 21:25:21.681653  3812 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:25:21.681653  3812 net.cpp:137] Memory required for data: 56526000
I1004 21:25:21.681653  3812 layer_factory.cpp:58] Creating layer conv2_2
I1004 21:25:21.681653  3812 net.cpp:84] Creating Layer conv2_2
I1004 21:25:21.681653  3812 net.cpp:406] conv2_2 <- conv2_1
I1004 21:25:21.681653  3812 net.cpp:380] conv2_2 -> conv2_2
I1004 21:25:21.682652  3812 net.cpp:122] Setting up conv2_2
I1004 21:25:21.682652  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.682652  3812 net.cpp:137] Memory required for data: 58471600
I1004 21:25:21.682652  3812 layer_factory.cpp:58] Creating layer bn2_2
I1004 21:25:21.682652  3812 net.cpp:84] Creating Layer bn2_2
I1004 21:25:21.682652  3812 net.cpp:406] bn2_2 <- conv2_2
I1004 21:25:21.682652  3812 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1004 21:25:21.682652  3812 net.cpp:122] Setting up bn2_2
I1004 21:25:21.682652  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.682652  3812 net.cpp:137] Memory required for data: 60417200
I1004 21:25:21.682652  3812 layer_factory.cpp:58] Creating layer scale2_2
I1004 21:25:21.682652  3812 net.cpp:84] Creating Layer scale2_2
I1004 21:25:21.682652  3812 net.cpp:406] scale2_2 <- conv2_2
I1004 21:25:21.682652  3812 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1004 21:25:21.682652  3812 layer_factory.cpp:58] Creating layer scale2_2
I1004 21:25:21.682652  3812 net.cpp:122] Setting up scale2_2
I1004 21:25:21.682652  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.682652  3812 net.cpp:137] Memory required for data: 62362800
I1004 21:25:21.682652  3812 layer_factory.cpp:58] Creating layer relu2_2
I1004 21:25:21.682652  3812 net.cpp:84] Creating Layer relu2_2
I1004 21:25:21.682652  3812 net.cpp:406] relu2_2 <- conv2_2
I1004 21:25:21.682652  3812 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1004 21:25:21.683653  3812 net.cpp:122] Setting up relu2_2
I1004 21:25:21.683653  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.683653  3812 net.cpp:137] Memory required for data: 64308400
I1004 21:25:21.683653  3812 layer_factory.cpp:58] Creating layer conv3
I1004 21:25:21.683653  3812 net.cpp:84] Creating Layer conv3
I1004 21:25:21.683653  3812 net.cpp:406] conv3 <- conv2_2
I1004 21:25:21.683653  3812 net.cpp:380] conv3 -> conv3
I1004 21:25:21.684653  3812 net.cpp:122] Setting up conv3
I1004 21:25:21.684653  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.684653  3812 net.cpp:137] Memory required for data: 66254000
I1004 21:25:21.684653  3812 layer_factory.cpp:58] Creating layer bn3
I1004 21:25:21.684653  3812 net.cpp:84] Creating Layer bn3
I1004 21:25:21.684653  3812 net.cpp:406] bn3 <- conv3
I1004 21:25:21.684653  3812 net.cpp:367] bn3 -> conv3 (in-place)
I1004 21:25:21.684653  3812 net.cpp:122] Setting up bn3
I1004 21:25:21.684653  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.684653  3812 net.cpp:137] Memory required for data: 68199600
I1004 21:25:21.684653  3812 layer_factory.cpp:58] Creating layer scale3
I1004 21:25:21.684653  3812 net.cpp:84] Creating Layer scale3
I1004 21:25:21.684653  3812 net.cpp:406] scale3 <- conv3
I1004 21:25:21.684653  3812 net.cpp:367] scale3 -> conv3 (in-place)
I1004 21:25:21.684653  3812 layer_factory.cpp:58] Creating layer scale3
I1004 21:25:21.684653  3812 net.cpp:122] Setting up scale3
I1004 21:25:21.684653  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.684653  3812 net.cpp:137] Memory required for data: 70145200
I1004 21:25:21.684653  3812 layer_factory.cpp:58] Creating layer relu3
I1004 21:25:21.684653  3812 net.cpp:84] Creating Layer relu3
I1004 21:25:21.684653  3812 net.cpp:406] relu3 <- conv3
I1004 21:25:21.684653  3812 net.cpp:367] relu3 -> conv3 (in-place)
I1004 21:25:21.684653  3812 net.cpp:122] Setting up relu3
I1004 21:25:21.684653  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.684653  3812 net.cpp:137] Memory required for data: 72090800
I1004 21:25:21.684653  3812 layer_factory.cpp:58] Creating layer conv3_1
I1004 21:25:21.684653  3812 net.cpp:84] Creating Layer conv3_1
I1004 21:25:21.684653  3812 net.cpp:406] conv3_1 <- conv3
I1004 21:25:21.684653  3812 net.cpp:380] conv3_1 -> conv3_1
I1004 21:25:21.685653  3812 net.cpp:122] Setting up conv3_1
I1004 21:25:21.685653  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.685653  3812 net.cpp:137] Memory required for data: 74036400
I1004 21:25:21.685653  3812 layer_factory.cpp:58] Creating layer bn3_1
I1004 21:25:21.685653  3812 net.cpp:84] Creating Layer bn3_1
I1004 21:25:21.685653  3812 net.cpp:406] bn3_1 <- conv3_1
I1004 21:25:21.685653  3812 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1004 21:25:21.685653  3812 net.cpp:122] Setting up bn3_1
I1004 21:25:21.686653  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.686653  3812 net.cpp:137] Memory required for data: 75982000
I1004 21:25:21.686653  3812 layer_factory.cpp:58] Creating layer scale3_1
I1004 21:25:21.686653  3812 net.cpp:84] Creating Layer scale3_1
I1004 21:25:21.686653  3812 net.cpp:406] scale3_1 <- conv3_1
I1004 21:25:21.686653  3812 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1004 21:25:21.686653  3812 layer_factory.cpp:58] Creating layer scale3_1
I1004 21:25:21.686653  3812 net.cpp:122] Setting up scale3_1
I1004 21:25:21.686653  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.686653  3812 net.cpp:137] Memory required for data: 77927600
I1004 21:25:21.686653  3812 layer_factory.cpp:58] Creating layer relu3_1
I1004 21:25:21.686653  3812 net.cpp:84] Creating Layer relu3_1
I1004 21:25:21.686653  3812 net.cpp:406] relu3_1 <- conv3_1
I1004 21:25:21.686653  3812 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1004 21:25:21.686653  3812 net.cpp:122] Setting up relu3_1
I1004 21:25:21.686653  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.686653  3812 net.cpp:137] Memory required for data: 79873200
I1004 21:25:21.686653  3812 layer_factory.cpp:58] Creating layer conv4
I1004 21:25:21.686653  3812 net.cpp:84] Creating Layer conv4
I1004 21:25:21.686653  3812 net.cpp:406] conv4 <- conv3_1
I1004 21:25:21.686653  3812 net.cpp:380] conv4 -> conv4
I1004 21:25:21.687654  3812 net.cpp:122] Setting up conv4
I1004 21:25:21.687654  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.687654  3812 net.cpp:137] Memory required for data: 81818800
I1004 21:25:21.687654  3812 layer_factory.cpp:58] Creating layer bn4
I1004 21:25:21.687654  3812 net.cpp:84] Creating Layer bn4
I1004 21:25:21.687654  3812 net.cpp:406] bn4 <- conv4
I1004 21:25:21.687654  3812 net.cpp:367] bn4 -> conv4 (in-place)
I1004 21:25:21.687654  3812 net.cpp:122] Setting up bn4
I1004 21:25:21.687654  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.687654  3812 net.cpp:137] Memory required for data: 83764400
I1004 21:25:21.687654  3812 layer_factory.cpp:58] Creating layer scale4
I1004 21:25:21.687654  3812 net.cpp:84] Creating Layer scale4
I1004 21:25:21.687654  3812 net.cpp:406] scale4 <- conv4
I1004 21:25:21.687654  3812 net.cpp:367] scale4 -> conv4 (in-place)
I1004 21:25:21.687654  3812 layer_factory.cpp:58] Creating layer scale4
I1004 21:25:21.687654  3812 net.cpp:122] Setting up scale4
I1004 21:25:21.687654  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.687654  3812 net.cpp:137] Memory required for data: 85710000
I1004 21:25:21.687654  3812 layer_factory.cpp:58] Creating layer relu4
I1004 21:25:21.687654  3812 net.cpp:84] Creating Layer relu4
I1004 21:25:21.687654  3812 net.cpp:406] relu4 <- conv4
I1004 21:25:21.687654  3812 net.cpp:367] relu4 -> conv4 (in-place)
I1004 21:25:21.688652  3812 net.cpp:122] Setting up relu4
I1004 21:25:21.688652  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.688652  3812 net.cpp:137] Memory required for data: 87655600
I1004 21:25:21.688652  3812 layer_factory.cpp:58] Creating layer conv4_1
I1004 21:25:21.688652  3812 net.cpp:84] Creating Layer conv4_1
I1004 21:25:21.688652  3812 net.cpp:406] conv4_1 <- conv4
I1004 21:25:21.688652  3812 net.cpp:380] conv4_1 -> conv4_1
I1004 21:25:21.689652  3812 net.cpp:122] Setting up conv4_1
I1004 21:25:21.689652  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.689652  3812 net.cpp:137] Memory required for data: 89601200
I1004 21:25:21.689652  3812 layer_factory.cpp:58] Creating layer bn4_1
I1004 21:25:21.689652  3812 net.cpp:84] Creating Layer bn4_1
I1004 21:25:21.689652  3812 net.cpp:406] bn4_1 <- conv4_1
I1004 21:25:21.689652  3812 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1004 21:25:21.689652  3812 net.cpp:122] Setting up bn4_1
I1004 21:25:21.689652  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.689652  3812 net.cpp:137] Memory required for data: 91546800
I1004 21:25:21.689652  3812 layer_factory.cpp:58] Creating layer scale4_1
I1004 21:25:21.689652  3812 net.cpp:84] Creating Layer scale4_1
I1004 21:25:21.689652  3812 net.cpp:406] scale4_1 <- conv4_1
I1004 21:25:21.689652  3812 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1004 21:25:21.689652  3812 layer_factory.cpp:58] Creating layer scale4_1
I1004 21:25:21.689652  3812 net.cpp:122] Setting up scale4_1
I1004 21:25:21.689652  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.689652  3812 net.cpp:137] Memory required for data: 93492400
I1004 21:25:21.689652  3812 layer_factory.cpp:58] Creating layer relu4_1
I1004 21:25:21.689652  3812 net.cpp:84] Creating Layer relu4_1
I1004 21:25:21.689652  3812 net.cpp:406] relu4_1 <- conv4_1
I1004 21:25:21.689652  3812 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1004 21:25:21.690654  3812 net.cpp:122] Setting up relu4_1
I1004 21:25:21.690654  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.690654  3812 net.cpp:137] Memory required for data: 95438000
I1004 21:25:21.690654  3812 layer_factory.cpp:58] Creating layer conv4_2
I1004 21:25:21.690654  3812 net.cpp:84] Creating Layer conv4_2
I1004 21:25:21.690654  3812 net.cpp:406] conv4_2 <- conv4_1
I1004 21:25:21.690654  3812 net.cpp:380] conv4_2 -> conv4_2
I1004 21:25:21.691653  3812 net.cpp:122] Setting up conv4_2
I1004 21:25:21.691653  3812 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:25:21.691653  3812 net.cpp:137] Memory required for data: 98305200
I1004 21:25:21.691653  3812 layer_factory.cpp:58] Creating layer bn4_2
I1004 21:25:21.691653  3812 net.cpp:84] Creating Layer bn4_2
I1004 21:25:21.691653  3812 net.cpp:406] bn4_2 <- conv4_2
I1004 21:25:21.691653  3812 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1004 21:25:21.691653  3812 net.cpp:122] Setting up bn4_2
I1004 21:25:21.691653  3812 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:25:21.691653  3812 net.cpp:137] Memory required for data: 101172400
I1004 21:25:21.691653  3812 layer_factory.cpp:58] Creating layer scale4_2
I1004 21:25:21.691653  3812 net.cpp:84] Creating Layer scale4_2
I1004 21:25:21.691653  3812 net.cpp:406] scale4_2 <- conv4_2
I1004 21:25:21.691653  3812 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1004 21:25:21.692653  3812 layer_factory.cpp:58] Creating layer scale4_2
I1004 21:25:21.692653  3812 net.cpp:122] Setting up scale4_2
I1004 21:25:21.692653  3812 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:25:21.692653  3812 net.cpp:137] Memory required for data: 104039600
I1004 21:25:21.692653  3812 layer_factory.cpp:58] Creating layer relu4_2
I1004 21:25:21.692653  3812 net.cpp:84] Creating Layer relu4_2
I1004 21:25:21.692653  3812 net.cpp:406] relu4_2 <- conv4_2
I1004 21:25:21.692653  3812 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1004 21:25:21.692653  3812 net.cpp:122] Setting up relu4_2
I1004 21:25:21.692653  3812 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:25:21.692653  3812 net.cpp:137] Memory required for data: 106906800
I1004 21:25:21.692653  3812 layer_factory.cpp:58] Creating layer pool4_2
I1004 21:25:21.692653  3812 net.cpp:84] Creating Layer pool4_2
I1004 21:25:21.692653  3812 net.cpp:406] pool4_2 <- conv4_2
I1004 21:25:21.692653  3812 net.cpp:380] pool4_2 -> pool4_2
I1004 21:25:21.692653  3812 net.cpp:122] Setting up pool4_2
I1004 21:25:21.692653  3812 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:25:21.692653  3812 net.cpp:137] Memory required for data: 107623600
I1004 21:25:21.692653  3812 layer_factory.cpp:58] Creating layer conv4_0
I1004 21:25:21.692653  3812 net.cpp:84] Creating Layer conv4_0
I1004 21:25:21.692653  3812 net.cpp:406] conv4_0 <- pool4_2
I1004 21:25:21.692653  3812 net.cpp:380] conv4_0 -> conv4_0
I1004 21:25:21.693652  3812 net.cpp:122] Setting up conv4_0
I1004 21:25:21.693652  3812 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:25:21.693652  3812 net.cpp:137] Memory required for data: 108340400
I1004 21:25:21.693652  3812 layer_factory.cpp:58] Creating layer bn4_0
I1004 21:25:21.694654  3812 net.cpp:84] Creating Layer bn4_0
I1004 21:25:21.694654  3812 net.cpp:406] bn4_0 <- conv4_0
I1004 21:25:21.694654  3812 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1004 21:25:21.694654  3812 net.cpp:122] Setting up bn4_0
I1004 21:25:21.694654  3812 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:25:21.694654  3812 net.cpp:137] Memory required for data: 109057200
I1004 21:25:21.694654  3812 layer_factory.cpp:58] Creating layer scale4_0
I1004 21:25:21.694654  3812 net.cpp:84] Creating Layer scale4_0
I1004 21:25:21.694654  3812 net.cpp:406] scale4_0 <- conv4_0
I1004 21:25:21.694654  3812 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1004 21:25:21.694654  3812 layer_factory.cpp:58] Creating layer scale4_0
I1004 21:25:21.694654  3812 net.cpp:122] Setting up scale4_0
I1004 21:25:21.694654  3812 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:25:21.694654  3812 net.cpp:137] Memory required for data: 109774000
I1004 21:25:21.694654  3812 layer_factory.cpp:58] Creating layer relu4_0
I1004 21:25:21.694654  3812 net.cpp:84] Creating Layer relu4_0
I1004 21:25:21.694654  3812 net.cpp:406] relu4_0 <- conv4_0
I1004 21:25:21.694654  3812 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1004 21:25:21.694654  3812 net.cpp:122] Setting up relu4_0
I1004 21:25:21.694654  3812 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:25:21.694654  3812 net.cpp:137] Memory required for data: 110490800
I1004 21:25:21.694654  3812 layer_factory.cpp:58] Creating layer conv11
I1004 21:25:21.694654  3812 net.cpp:84] Creating Layer conv11
I1004 21:25:21.694654  3812 net.cpp:406] conv11 <- conv4_0
I1004 21:25:21.694654  3812 net.cpp:380] conv11 -> conv11
I1004 21:25:21.695653  3812 net.cpp:122] Setting up conv11
I1004 21:25:21.695653  3812 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:25:21.695653  3812 net.cpp:137] Memory required for data: 111386800
I1004 21:25:21.695653  3812 layer_factory.cpp:58] Creating layer bn_conv11
I1004 21:25:21.695653  3812 net.cpp:84] Creating Layer bn_conv11
I1004 21:25:21.695653  3812 net.cpp:406] bn_conv11 <- conv11
I1004 21:25:21.695653  3812 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1004 21:25:21.696652  3812 net.cpp:122] Setting up bn_conv11
I1004 21:25:21.696652  3812 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:25:21.696652  3812 net.cpp:137] Memory required for data: 112282800
I1004 21:25:21.696652  3812 layer_factory.cpp:58] Creating layer scale_conv11
I1004 21:25:21.696652  3812 net.cpp:84] Creating Layer scale_conv11
I1004 21:25:21.696652  3812 net.cpp:406] scale_conv11 <- conv11
I1004 21:25:21.696652  3812 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1004 21:25:21.696652  3812 layer_factory.cpp:58] Creating layer scale_conv11
I1004 21:25:21.696652  3812 net.cpp:122] Setting up scale_conv11
I1004 21:25:21.696652  3812 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:25:21.696652  3812 net.cpp:137] Memory required for data: 113178800
I1004 21:25:21.696652  3812 layer_factory.cpp:58] Creating layer relu_conv11
I1004 21:25:21.696652  3812 net.cpp:84] Creating Layer relu_conv11
I1004 21:25:21.696652  3812 net.cpp:406] relu_conv11 <- conv11
I1004 21:25:21.696652  3812 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1004 21:25:21.696652  3812 net.cpp:122] Setting up relu_conv11
I1004 21:25:21.696652  3812 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:25:21.696652  3812 net.cpp:137] Memory required for data: 114074800
I1004 21:25:21.696652  3812 layer_factory.cpp:58] Creating layer conv12
I1004 21:25:21.696652  3812 net.cpp:84] Creating Layer conv12
I1004 21:25:21.696652  3812 net.cpp:406] conv12 <- conv11
I1004 21:25:21.696652  3812 net.cpp:380] conv12 -> conv12
I1004 21:25:21.697654  3812 net.cpp:122] Setting up conv12
I1004 21:25:21.697654  3812 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:25:21.697654  3812 net.cpp:137] Memory required for data: 115175600
I1004 21:25:21.697654  3812 layer_factory.cpp:58] Creating layer bn_conv12
I1004 21:25:21.697654  3812 net.cpp:84] Creating Layer bn_conv12
I1004 21:25:21.697654  3812 net.cpp:406] bn_conv12 <- conv12
I1004 21:25:21.697654  3812 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1004 21:25:21.697654  3812 net.cpp:122] Setting up bn_conv12
I1004 21:25:21.697654  3812 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:25:21.697654  3812 net.cpp:137] Memory required for data: 116276400
I1004 21:25:21.697654  3812 layer_factory.cpp:58] Creating layer scale_conv12
I1004 21:25:21.697654  3812 net.cpp:84] Creating Layer scale_conv12
I1004 21:25:21.697654  3812 net.cpp:406] scale_conv12 <- conv12
I1004 21:25:21.697654  3812 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1004 21:25:21.697654  3812 layer_factory.cpp:58] Creating layer scale_conv12
I1004 21:25:21.698652  3812 net.cpp:122] Setting up scale_conv12
I1004 21:25:21.698652  3812 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:25:21.698652  3812 net.cpp:137] Memory required for data: 117377200
I1004 21:25:21.698652  3812 layer_factory.cpp:58] Creating layer relu_conv12
I1004 21:25:21.698652  3812 net.cpp:84] Creating Layer relu_conv12
I1004 21:25:21.698652  3812 net.cpp:406] relu_conv12 <- conv12
I1004 21:25:21.698652  3812 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1004 21:25:21.698652  3812 net.cpp:122] Setting up relu_conv12
I1004 21:25:21.698652  3812 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:25:21.698652  3812 net.cpp:137] Memory required for data: 118478000
I1004 21:25:21.698652  3812 layer_factory.cpp:58] Creating layer poolcp6
I1004 21:25:21.698652  3812 net.cpp:84] Creating Layer poolcp6
I1004 21:25:21.698652  3812 net.cpp:406] poolcp6 <- conv12
I1004 21:25:21.698652  3812 net.cpp:380] poolcp6 -> poolcp6
I1004 21:25:21.698652  3812 net.cpp:122] Setting up poolcp6
I1004 21:25:21.698652  3812 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1004 21:25:21.698652  3812 net.cpp:137] Memory required for data: 118495200
I1004 21:25:21.698652  3812 layer_factory.cpp:58] Creating layer ip1
I1004 21:25:21.698652  3812 net.cpp:84] Creating Layer ip1
I1004 21:25:21.698652  3812 net.cpp:406] ip1 <- poolcp6
I1004 21:25:21.698652  3812 net.cpp:380] ip1 -> ip1
I1004 21:25:21.698652  3812 net.cpp:122] Setting up ip1
I1004 21:25:21.698652  3812 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:25:21.698652  3812 net.cpp:137] Memory required for data: 118499200
I1004 21:25:21.698652  3812 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1004 21:25:21.698652  3812 net.cpp:84] Creating Layer ip1_ip1_0_split
I1004 21:25:21.698652  3812 net.cpp:406] ip1_ip1_0_split <- ip1
I1004 21:25:21.698652  3812 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1004 21:25:21.698652  3812 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1004 21:25:21.698652  3812 net.cpp:122] Setting up ip1_ip1_0_split
I1004 21:25:21.698652  3812 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:25:21.698652  3812 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:25:21.698652  3812 net.cpp:137] Memory required for data: 118507200
I1004 21:25:21.698652  3812 layer_factory.cpp:58] Creating layer accuracy_training
I1004 21:25:21.698652  3812 net.cpp:84] Creating Layer accuracy_training
I1004 21:25:21.698652  3812 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1004 21:25:21.698652  3812 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1004 21:25:21.698652  3812 net.cpp:380] accuracy_training -> accuracy_training
I1004 21:25:21.698652  3812 net.cpp:122] Setting up accuracy_training
I1004 21:25:21.698652  3812 net.cpp:129] Top shape: (1)
I1004 21:25:21.698652  3812 net.cpp:137] Memory required for data: 118507204
I1004 21:25:21.698652  3812 layer_factory.cpp:58] Creating layer loss
I1004 21:25:21.698652  3812 net.cpp:84] Creating Layer loss
I1004 21:25:21.698652  3812 net.cpp:406] loss <- ip1_ip1_0_split_1
I1004 21:25:21.698652  3812 net.cpp:406] loss <- label_cifar_1_split_1
I1004 21:25:21.698652  3812 net.cpp:380] loss -> loss
I1004 21:25:21.698652  3812 layer_factory.cpp:58] Creating layer loss
I1004 21:25:21.699654  3812 net.cpp:122] Setting up loss
I1004 21:25:21.699654  3812 net.cpp:129] Top shape: (1)
I1004 21:25:21.699654  3812 net.cpp:132]     with loss weight 1
I1004 21:25:21.699654  3812 net.cpp:137] Memory required for data: 118507208
I1004 21:25:21.699654  3812 net.cpp:198] loss needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:200] accuracy_training does not need backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] ip1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] poolcp6 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu_conv12 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale_conv12 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn_conv12 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv12 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu_conv11 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale_conv11 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn_conv11 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv11 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu4_0 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale4_0 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn4_0 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv4_0 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] pool4_2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu4_2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale4_2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn4_2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv4_2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu4_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale4_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn4_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv4_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu4 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale4 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn4 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv4 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu3_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale3_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn3_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv3_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu3 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale3 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn3 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv3 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu2_2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale2_2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn2_2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv2_2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu2_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale2_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn2_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv2_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] pool2_1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv2 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu1_0 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale1_0 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn1_0 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv1_0 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] relu1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] scale1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] bn1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:198] conv1 needs backward computation.
I1004 21:25:21.699654  3812 net.cpp:200] label_cifar_1_split does not need backward computation.
I1004 21:25:21.699654  3812 net.cpp:200] cifar does not need backward computation.
I1004 21:25:21.699654  3812 net.cpp:242] This network produces output accuracy_training
I1004 21:25:21.699654  3812 net.cpp:242] This network produces output loss
I1004 21:25:21.699654  3812 net.cpp:255] Network initialization done.
I1004 21:25:21.700652  3812 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 21:25:21.700652  3812 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1004 21:25:21.700652  3812 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1004 21:25:21.700652  3812 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1004 21:25:21.701652  3812 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P3__"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1004 21:25:21.701652  3812 layer_factory.cpp:58] Creating layer cifar
I1004 21:25:21.870450  3812 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I1004 21:25:21.894678  3812 net.cpp:84] Creating Layer cifar
I1004 21:25:21.894678  3812 net.cpp:380] cifar -> data
I1004 21:25:21.894678  3812 net.cpp:380] cifar -> label
I1004 21:25:21.894678  3812 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1004 21:25:21.894678  3812 data_layer.cpp:45] output data size: 100,3,32,32
I1004 21:25:21.900367  3812 net.cpp:122] Setting up cifar
I1004 21:25:21.900367  3812 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1004 21:25:21.900367  3812 net.cpp:129] Top shape: 100 (100)
I1004 21:25:21.900367  3812 net.cpp:137] Memory required for data: 1229200
I1004 21:25:21.900367  3812 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1004 21:25:21.900367  3812 net.cpp:84] Creating Layer label_cifar_1_split
I1004 21:25:21.900367  3812 net.cpp:406] label_cifar_1_split <- label
I1004 21:25:21.900367  3812 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1004 21:25:21.900367  3812 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1004 21:25:21.901373  3812 net.cpp:122] Setting up label_cifar_1_split
I1004 21:25:21.901373  3812 net.cpp:129] Top shape: 100 (100)
I1004 21:25:21.901373  3812 net.cpp:129] Top shape: 100 (100)
I1004 21:25:21.901373  3812 net.cpp:137] Memory required for data: 1230000
I1004 21:25:21.901373  3812 layer_factory.cpp:58] Creating layer conv1
I1004 21:25:21.901373  3812 net.cpp:84] Creating Layer conv1
I1004 21:25:21.901373  3812 net.cpp:406] conv1 <- data
I1004 21:25:21.901373  3812 net.cpp:380] conv1 -> conv1
I1004 21:25:21.901373 17180 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 21:25:21.902374  3812 net.cpp:122] Setting up conv1
I1004 21:25:21.902374  3812 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:25:21.902374  3812 net.cpp:137] Memory required for data: 3687600
I1004 21:25:21.902374  3812 layer_factory.cpp:58] Creating layer bn1
I1004 21:25:21.902374  3812 net.cpp:84] Creating Layer bn1
I1004 21:25:21.902374  3812 net.cpp:406] bn1 <- conv1
I1004 21:25:21.902374  3812 net.cpp:367] bn1 -> conv1 (in-place)
I1004 21:25:21.903388  3812 net.cpp:122] Setting up bn1
I1004 21:25:21.903388  3812 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:25:21.903388  3812 net.cpp:137] Memory required for data: 6145200
I1004 21:25:21.903388  3812 layer_factory.cpp:58] Creating layer scale1
I1004 21:25:21.903388  3812 net.cpp:84] Creating Layer scale1
I1004 21:25:21.903388  3812 net.cpp:406] scale1 <- conv1
I1004 21:25:21.903388  3812 net.cpp:367] scale1 -> conv1 (in-place)
I1004 21:25:21.903388  3812 layer_factory.cpp:58] Creating layer scale1
I1004 21:25:21.903388  3812 net.cpp:122] Setting up scale1
I1004 21:25:21.903388  3812 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:25:21.903388  3812 net.cpp:137] Memory required for data: 8602800
I1004 21:25:21.903388  3812 layer_factory.cpp:58] Creating layer relu1
I1004 21:25:21.903388  3812 net.cpp:84] Creating Layer relu1
I1004 21:25:21.903388  3812 net.cpp:406] relu1 <- conv1
I1004 21:25:21.903388  3812 net.cpp:367] relu1 -> conv1 (in-place)
I1004 21:25:21.903388  3812 net.cpp:122] Setting up relu1
I1004 21:25:21.903388  3812 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:25:21.903388  3812 net.cpp:137] Memory required for data: 11060400
I1004 21:25:21.903388  3812 layer_factory.cpp:58] Creating layer conv1_0
I1004 21:25:21.903388  3812 net.cpp:84] Creating Layer conv1_0
I1004 21:25:21.903388  3812 net.cpp:406] conv1_0 <- conv1
I1004 21:25:21.903388  3812 net.cpp:380] conv1_0 -> conv1_0
I1004 21:25:21.904695  3812 net.cpp:122] Setting up conv1_0
I1004 21:25:21.904695  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.904695  3812 net.cpp:137] Memory required for data: 15975600
I1004 21:25:21.904695  3812 layer_factory.cpp:58] Creating layer bn1_0
I1004 21:25:21.904695  3812 net.cpp:84] Creating Layer bn1_0
I1004 21:25:21.904695  3812 net.cpp:406] bn1_0 <- conv1_0
I1004 21:25:21.904695  3812 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1004 21:25:21.904695  3812 net.cpp:122] Setting up bn1_0
I1004 21:25:21.904695  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.904695  3812 net.cpp:137] Memory required for data: 20890800
I1004 21:25:21.904695  3812 layer_factory.cpp:58] Creating layer scale1_0
I1004 21:25:21.904695  3812 net.cpp:84] Creating Layer scale1_0
I1004 21:25:21.904695  3812 net.cpp:406] scale1_0 <- conv1_0
I1004 21:25:21.904695  3812 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1004 21:25:21.904695  3812 layer_factory.cpp:58] Creating layer scale1_0
I1004 21:25:21.905714  3812 net.cpp:122] Setting up scale1_0
I1004 21:25:21.905714  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.905714  3812 net.cpp:137] Memory required for data: 25806000
I1004 21:25:21.905714  3812 layer_factory.cpp:58] Creating layer relu1_0
I1004 21:25:21.905714  3812 net.cpp:84] Creating Layer relu1_0
I1004 21:25:21.905714  3812 net.cpp:406] relu1_0 <- conv1_0
I1004 21:25:21.905714  3812 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1004 21:25:21.905714  3812 net.cpp:122] Setting up relu1_0
I1004 21:25:21.905714  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.905714  3812 net.cpp:137] Memory required for data: 30721200
I1004 21:25:21.905714  3812 layer_factory.cpp:58] Creating layer conv2
I1004 21:25:21.905714  3812 net.cpp:84] Creating Layer conv2
I1004 21:25:21.905714  3812 net.cpp:406] conv2 <- conv1_0
I1004 21:25:21.905714  3812 net.cpp:380] conv2 -> conv2
I1004 21:25:21.906713  3812 net.cpp:122] Setting up conv2
I1004 21:25:21.906713  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.906713  3812 net.cpp:137] Memory required for data: 35636400
I1004 21:25:21.906713  3812 layer_factory.cpp:58] Creating layer bn2
I1004 21:25:21.906713  3812 net.cpp:84] Creating Layer bn2
I1004 21:25:21.906713  3812 net.cpp:406] bn2 <- conv2
I1004 21:25:21.906713  3812 net.cpp:367] bn2 -> conv2 (in-place)
I1004 21:25:21.906713  3812 net.cpp:122] Setting up bn2
I1004 21:25:21.906713  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.906713  3812 net.cpp:137] Memory required for data: 40551600
I1004 21:25:21.906713  3812 layer_factory.cpp:58] Creating layer scale2
I1004 21:25:21.906713  3812 net.cpp:84] Creating Layer scale2
I1004 21:25:21.906713  3812 net.cpp:406] scale2 <- conv2
I1004 21:25:21.906713  3812 net.cpp:367] scale2 -> conv2 (in-place)
I1004 21:25:21.906713  3812 layer_factory.cpp:58] Creating layer scale2
I1004 21:25:21.906713  3812 net.cpp:122] Setting up scale2
I1004 21:25:21.906713  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.906713  3812 net.cpp:137] Memory required for data: 45466800
I1004 21:25:21.906713  3812 layer_factory.cpp:58] Creating layer relu2
I1004 21:25:21.906713  3812 net.cpp:84] Creating Layer relu2
I1004 21:25:21.906713  3812 net.cpp:406] relu2 <- conv2
I1004 21:25:21.906713  3812 net.cpp:367] relu2 -> conv2 (in-place)
I1004 21:25:21.907712  3812 net.cpp:122] Setting up relu2
I1004 21:25:21.907712  3812 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:25:21.907712  3812 net.cpp:137] Memory required for data: 50382000
I1004 21:25:21.907712  3812 layer_factory.cpp:58] Creating layer pool2_1
I1004 21:25:21.907712  3812 net.cpp:84] Creating Layer pool2_1
I1004 21:25:21.907712  3812 net.cpp:406] pool2_1 <- conv2
I1004 21:25:21.907712  3812 net.cpp:380] pool2_1 -> pool2_1
I1004 21:25:21.907712  3812 net.cpp:122] Setting up pool2_1
I1004 21:25:21.907712  3812 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:25:21.907712  3812 net.cpp:137] Memory required for data: 51610800
I1004 21:25:21.907712  3812 layer_factory.cpp:58] Creating layer conv2_1
I1004 21:25:21.907712  3812 net.cpp:84] Creating Layer conv2_1
I1004 21:25:21.907712  3812 net.cpp:406] conv2_1 <- pool2_1
I1004 21:25:21.907712  3812 net.cpp:380] conv2_1 -> conv2_1
I1004 21:25:21.908713  3812 net.cpp:122] Setting up conv2_1
I1004 21:25:21.908713  3812 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:25:21.908713  3812 net.cpp:137] Memory required for data: 52839600
I1004 21:25:21.908713  3812 layer_factory.cpp:58] Creating layer bn2_1
I1004 21:25:21.908713  3812 net.cpp:84] Creating Layer bn2_1
I1004 21:25:21.908713  3812 net.cpp:406] bn2_1 <- conv2_1
I1004 21:25:21.908713  3812 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1004 21:25:21.908713  3812 net.cpp:122] Setting up bn2_1
I1004 21:25:21.908713  3812 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:25:21.908713  3812 net.cpp:137] Memory required for data: 54068400
I1004 21:25:21.908713  3812 layer_factory.cpp:58] Creating layer scale2_1
I1004 21:25:21.908713  3812 net.cpp:84] Creating Layer scale2_1
I1004 21:25:21.908713  3812 net.cpp:406] scale2_1 <- conv2_1
I1004 21:25:21.908713  3812 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1004 21:25:21.908713  3812 layer_factory.cpp:58] Creating layer scale2_1
I1004 21:25:21.908713  3812 net.cpp:122] Setting up scale2_1
I1004 21:25:21.908713  3812 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:25:21.908713  3812 net.cpp:137] Memory required for data: 55297200
I1004 21:25:21.908713  3812 layer_factory.cpp:58] Creating layer relu2_1
I1004 21:25:21.909713  3812 net.cpp:84] Creating Layer relu2_1
I1004 21:25:21.909713  3812 net.cpp:406] relu2_1 <- conv2_1
I1004 21:25:21.909713  3812 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1004 21:25:21.909713  3812 net.cpp:122] Setting up relu2_1
I1004 21:25:21.909713  3812 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:25:21.909713  3812 net.cpp:137] Memory required for data: 56526000
I1004 21:25:21.909713  3812 layer_factory.cpp:58] Creating layer conv2_2
I1004 21:25:21.909713  3812 net.cpp:84] Creating Layer conv2_2
I1004 21:25:21.909713  3812 net.cpp:406] conv2_2 <- conv2_1
I1004 21:25:21.909713  3812 net.cpp:380] conv2_2 -> conv2_2
I1004 21:25:21.910712  3812 net.cpp:122] Setting up conv2_2
I1004 21:25:21.910712  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.910712  3812 net.cpp:137] Memory required for data: 58471600
I1004 21:25:21.910712  3812 layer_factory.cpp:58] Creating layer bn2_2
I1004 21:25:21.910712  3812 net.cpp:84] Creating Layer bn2_2
I1004 21:25:21.910712  3812 net.cpp:406] bn2_2 <- conv2_2
I1004 21:25:21.910712  3812 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1004 21:25:21.911712  3812 net.cpp:122] Setting up bn2_2
I1004 21:25:21.911712  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.911712  3812 net.cpp:137] Memory required for data: 60417200
I1004 21:25:21.911712  3812 layer_factory.cpp:58] Creating layer scale2_2
I1004 21:25:21.911712  3812 net.cpp:84] Creating Layer scale2_2
I1004 21:25:21.911712  3812 net.cpp:406] scale2_2 <- conv2_2
I1004 21:25:21.911712  3812 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1004 21:25:21.911712  3812 layer_factory.cpp:58] Creating layer scale2_2
I1004 21:25:21.911712  3812 net.cpp:122] Setting up scale2_2
I1004 21:25:21.911712  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.911712  3812 net.cpp:137] Memory required for data: 62362800
I1004 21:25:21.911712  3812 layer_factory.cpp:58] Creating layer relu2_2
I1004 21:25:21.911712  3812 net.cpp:84] Creating Layer relu2_2
I1004 21:25:21.911712  3812 net.cpp:406] relu2_2 <- conv2_2
I1004 21:25:21.911712  3812 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1004 21:25:21.911712  3812 net.cpp:122] Setting up relu2_2
I1004 21:25:21.911712  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.911712  3812 net.cpp:137] Memory required for data: 64308400
I1004 21:25:21.911712  3812 layer_factory.cpp:58] Creating layer conv3
I1004 21:25:21.911712  3812 net.cpp:84] Creating Layer conv3
I1004 21:25:21.911712  3812 net.cpp:406] conv3 <- conv2_2
I1004 21:25:21.911712  3812 net.cpp:380] conv3 -> conv3
I1004 21:25:21.912726  3812 net.cpp:122] Setting up conv3
I1004 21:25:21.912726  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.912726  3812 net.cpp:137] Memory required for data: 66254000
I1004 21:25:21.912726  3812 layer_factory.cpp:58] Creating layer bn3
I1004 21:25:21.912726  3812 net.cpp:84] Creating Layer bn3
I1004 21:25:21.912726  3812 net.cpp:406] bn3 <- conv3
I1004 21:25:21.912726  3812 net.cpp:367] bn3 -> conv3 (in-place)
I1004 21:25:21.913727  3812 net.cpp:122] Setting up bn3
I1004 21:25:21.913727  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.913727  3812 net.cpp:137] Memory required for data: 68199600
I1004 21:25:21.913727  3812 layer_factory.cpp:58] Creating layer scale3
I1004 21:25:21.913727  3812 net.cpp:84] Creating Layer scale3
I1004 21:25:21.913727  3812 net.cpp:406] scale3 <- conv3
I1004 21:25:21.913727  3812 net.cpp:367] scale3 -> conv3 (in-place)
I1004 21:25:21.913727  3812 layer_factory.cpp:58] Creating layer scale3
I1004 21:25:21.913727  3812 net.cpp:122] Setting up scale3
I1004 21:25:21.913727  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.913727  3812 net.cpp:137] Memory required for data: 70145200
I1004 21:25:21.913727  3812 layer_factory.cpp:58] Creating layer relu3
I1004 21:25:21.913727  3812 net.cpp:84] Creating Layer relu3
I1004 21:25:21.913727  3812 net.cpp:406] relu3 <- conv3
I1004 21:25:21.913727  3812 net.cpp:367] relu3 -> conv3 (in-place)
I1004 21:25:21.913727  3812 net.cpp:122] Setting up relu3
I1004 21:25:21.913727  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.913727  3812 net.cpp:137] Memory required for data: 72090800
I1004 21:25:21.913727  3812 layer_factory.cpp:58] Creating layer conv3_1
I1004 21:25:21.913727  3812 net.cpp:84] Creating Layer conv3_1
I1004 21:25:21.913727  3812 net.cpp:406] conv3_1 <- conv3
I1004 21:25:21.913727  3812 net.cpp:380] conv3_1 -> conv3_1
I1004 21:25:21.915727  3812 net.cpp:122] Setting up conv3_1
I1004 21:25:21.915727  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.915727  3812 net.cpp:137] Memory required for data: 74036400
I1004 21:25:21.915727  3812 layer_factory.cpp:58] Creating layer bn3_1
I1004 21:25:21.915727  3812 net.cpp:84] Creating Layer bn3_1
I1004 21:25:21.915727  3812 net.cpp:406] bn3_1 <- conv3_1
I1004 21:25:21.915727  3812 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1004 21:25:21.915727  3812 net.cpp:122] Setting up bn3_1
I1004 21:25:21.915727  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.915727  3812 net.cpp:137] Memory required for data: 75982000
I1004 21:25:21.915727  3812 layer_factory.cpp:58] Creating layer scale3_1
I1004 21:25:21.915727  3812 net.cpp:84] Creating Layer scale3_1
I1004 21:25:21.915727  3812 net.cpp:406] scale3_1 <- conv3_1
I1004 21:25:21.915727  3812 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1004 21:25:21.915727  3812 layer_factory.cpp:58] Creating layer scale3_1
I1004 21:25:21.915727  3812 net.cpp:122] Setting up scale3_1
I1004 21:25:21.915727  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.915727  3812 net.cpp:137] Memory required for data: 77927600
I1004 21:25:21.915727  3812 layer_factory.cpp:58] Creating layer relu3_1
I1004 21:25:21.915727  3812 net.cpp:84] Creating Layer relu3_1
I1004 21:25:21.915727  3812 net.cpp:406] relu3_1 <- conv3_1
I1004 21:25:21.915727  3812 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1004 21:25:21.916726  3812 net.cpp:122] Setting up relu3_1
I1004 21:25:21.916726  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.916726  3812 net.cpp:137] Memory required for data: 79873200
I1004 21:25:21.916726  3812 layer_factory.cpp:58] Creating layer conv4
I1004 21:25:21.916726  3812 net.cpp:84] Creating Layer conv4
I1004 21:25:21.916726  3812 net.cpp:406] conv4 <- conv3_1
I1004 21:25:21.916726  3812 net.cpp:380] conv4 -> conv4
I1004 21:25:21.917714  3812 net.cpp:122] Setting up conv4
I1004 21:25:21.917714  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.917714  3812 net.cpp:137] Memory required for data: 81818800
I1004 21:25:21.917714  3812 layer_factory.cpp:58] Creating layer bn4
I1004 21:25:21.917714  3812 net.cpp:84] Creating Layer bn4
I1004 21:25:21.917714  3812 net.cpp:406] bn4 <- conv4
I1004 21:25:21.917714  3812 net.cpp:367] bn4 -> conv4 (in-place)
I1004 21:25:21.917714  3812 net.cpp:122] Setting up bn4
I1004 21:25:21.917714  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.917714  3812 net.cpp:137] Memory required for data: 83764400
I1004 21:25:21.917714  3812 layer_factory.cpp:58] Creating layer scale4
I1004 21:25:21.917714  3812 net.cpp:84] Creating Layer scale4
I1004 21:25:21.917714  3812 net.cpp:406] scale4 <- conv4
I1004 21:25:21.917714  3812 net.cpp:367] scale4 -> conv4 (in-place)
I1004 21:25:21.917714  3812 layer_factory.cpp:58] Creating layer scale4
I1004 21:25:21.917714  3812 net.cpp:122] Setting up scale4
I1004 21:25:21.917714  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.917714  3812 net.cpp:137] Memory required for data: 85710000
I1004 21:25:21.917714  3812 layer_factory.cpp:58] Creating layer relu4
I1004 21:25:21.917714  3812 net.cpp:84] Creating Layer relu4
I1004 21:25:21.917714  3812 net.cpp:406] relu4 <- conv4
I1004 21:25:21.917714  3812 net.cpp:367] relu4 -> conv4 (in-place)
I1004 21:25:21.918736  3812 net.cpp:122] Setting up relu4
I1004 21:25:21.918736  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.918736  3812 net.cpp:137] Memory required for data: 87655600
I1004 21:25:21.918736  3812 layer_factory.cpp:58] Creating layer conv4_1
I1004 21:25:21.918736  3812 net.cpp:84] Creating Layer conv4_1
I1004 21:25:21.918736  3812 net.cpp:406] conv4_1 <- conv4
I1004 21:25:21.918736  3812 net.cpp:380] conv4_1 -> conv4_1
I1004 21:25:21.919728  3812 net.cpp:122] Setting up conv4_1
I1004 21:25:21.919728  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.919728  3812 net.cpp:137] Memory required for data: 89601200
I1004 21:25:21.919728  3812 layer_factory.cpp:58] Creating layer bn4_1
I1004 21:25:21.919728  3812 net.cpp:84] Creating Layer bn4_1
I1004 21:25:21.919728  3812 net.cpp:406] bn4_1 <- conv4_1
I1004 21:25:21.919728  3812 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1004 21:25:21.919728  3812 net.cpp:122] Setting up bn4_1
I1004 21:25:21.919728  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.919728  3812 net.cpp:137] Memory required for data: 91546800
I1004 21:25:21.919728  3812 layer_factory.cpp:58] Creating layer scale4_1
I1004 21:25:21.919728  3812 net.cpp:84] Creating Layer scale4_1
I1004 21:25:21.919728  3812 net.cpp:406] scale4_1 <- conv4_1
I1004 21:25:21.919728  3812 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1004 21:25:21.919728  3812 layer_factory.cpp:58] Creating layer scale4_1
I1004 21:25:21.919728  3812 net.cpp:122] Setting up scale4_1
I1004 21:25:21.919728  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.919728  3812 net.cpp:137] Memory required for data: 93492400
I1004 21:25:21.919728  3812 layer_factory.cpp:58] Creating layer relu4_1
I1004 21:25:21.919728  3812 net.cpp:84] Creating Layer relu4_1
I1004 21:25:21.919728  3812 net.cpp:406] relu4_1 <- conv4_1
I1004 21:25:21.919728  3812 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1004 21:25:21.919728  3812 net.cpp:122] Setting up relu4_1
I1004 21:25:21.919728  3812 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:25:21.919728  3812 net.cpp:137] Memory required for data: 95438000
I1004 21:25:21.919728  3812 layer_factory.cpp:58] Creating layer conv4_2
I1004 21:25:21.919728  3812 net.cpp:84] Creating Layer conv4_2
I1004 21:25:21.919728  3812 net.cpp:406] conv4_2 <- conv4_1
I1004 21:25:21.919728  3812 net.cpp:380] conv4_2 -> conv4_2
I1004 21:25:21.921161  3812 net.cpp:122] Setting up conv4_2
I1004 21:25:21.921161  3812 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:25:21.921161  3812 net.cpp:137] Memory required for data: 98305200
I1004 21:25:21.921161  3812 layer_factory.cpp:58] Creating layer bn4_2
I1004 21:25:21.921161  3812 net.cpp:84] Creating Layer bn4_2
I1004 21:25:21.921161  3812 net.cpp:406] bn4_2 <- conv4_2
I1004 21:25:21.921161  3812 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1004 21:25:21.921161  3812 net.cpp:122] Setting up bn4_2
I1004 21:25:21.921161  3812 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:25:21.921161  3812 net.cpp:137] Memory required for data: 101172400
I1004 21:25:21.921161  3812 layer_factory.cpp:58] Creating layer scale4_2
I1004 21:25:21.921161  3812 net.cpp:84] Creating Layer scale4_2
I1004 21:25:21.921161  3812 net.cpp:406] scale4_2 <- conv4_2
I1004 21:25:21.921161  3812 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1004 21:25:21.921161  3812 layer_factory.cpp:58] Creating layer scale4_2
I1004 21:25:21.921161  3812 net.cpp:122] Setting up scale4_2
I1004 21:25:21.921161  3812 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:25:21.921161  3812 net.cpp:137] Memory required for data: 104039600
I1004 21:25:21.921161  3812 layer_factory.cpp:58] Creating layer relu4_2
I1004 21:25:21.921161  3812 net.cpp:84] Creating Layer relu4_2
I1004 21:25:21.921161  3812 net.cpp:406] relu4_2 <- conv4_2
I1004 21:25:21.921161  3812 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1004 21:25:21.922193  3812 net.cpp:122] Setting up relu4_2
I1004 21:25:21.922193  3812 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:25:21.922193  3812 net.cpp:137] Memory required for data: 106906800
I1004 21:25:21.922193  3812 layer_factory.cpp:58] Creating layer pool4_2
I1004 21:25:21.922193  3812 net.cpp:84] Creating Layer pool4_2
I1004 21:25:21.922193  3812 net.cpp:406] pool4_2 <- conv4_2
I1004 21:25:21.922193  3812 net.cpp:380] pool4_2 -> pool4_2
I1004 21:25:21.922193  3812 net.cpp:122] Setting up pool4_2
I1004 21:25:21.922193  3812 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:25:21.922193  3812 net.cpp:137] Memory required for data: 107623600
I1004 21:25:21.922193  3812 layer_factory.cpp:58] Creating layer conv4_0
I1004 21:25:21.922193  3812 net.cpp:84] Creating Layer conv4_0
I1004 21:25:21.922193  3812 net.cpp:406] conv4_0 <- pool4_2
I1004 21:25:21.922193  3812 net.cpp:380] conv4_0 -> conv4_0
I1004 21:25:21.923192  3812 net.cpp:122] Setting up conv4_0
I1004 21:25:21.923192  3812 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:25:21.923192  3812 net.cpp:137] Memory required for data: 108340400
I1004 21:25:21.923192  3812 layer_factory.cpp:58] Creating layer bn4_0
I1004 21:25:21.923192  3812 net.cpp:84] Creating Layer bn4_0
I1004 21:25:21.923192  3812 net.cpp:406] bn4_0 <- conv4_0
I1004 21:25:21.923192  3812 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1004 21:25:21.923192  3812 net.cpp:122] Setting up bn4_0
I1004 21:25:21.923192  3812 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:25:21.923192  3812 net.cpp:137] Memory required for data: 109057200
I1004 21:25:21.923192  3812 layer_factory.cpp:58] Creating layer scale4_0
I1004 21:25:21.923192  3812 net.cpp:84] Creating Layer scale4_0
I1004 21:25:21.923192  3812 net.cpp:406] scale4_0 <- conv4_0
I1004 21:25:21.923192  3812 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1004 21:25:21.923192  3812 layer_factory.cpp:58] Creating layer scale4_0
I1004 21:25:21.923192  3812 net.cpp:122] Setting up scale4_0
I1004 21:25:21.923192  3812 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:25:21.923192  3812 net.cpp:137] Memory required for data: 109774000
I1004 21:25:21.923192  3812 layer_factory.cpp:58] Creating layer relu4_0
I1004 21:25:21.923192  3812 net.cpp:84] Creating Layer relu4_0
I1004 21:25:21.923192  3812 net.cpp:406] relu4_0 <- conv4_0
I1004 21:25:21.923192  3812 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1004 21:25:21.924181  3812 net.cpp:122] Setting up relu4_0
I1004 21:25:21.924181  3812 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:25:21.924181  3812 net.cpp:137] Memory required for data: 110490800
I1004 21:25:21.924181  3812 layer_factory.cpp:58] Creating layer conv11
I1004 21:25:21.924181  3812 net.cpp:84] Creating Layer conv11
I1004 21:25:21.924181  3812 net.cpp:406] conv11 <- conv4_0
I1004 21:25:21.924181  3812 net.cpp:380] conv11 -> conv11
I1004 21:25:21.925196  3812 net.cpp:122] Setting up conv11
I1004 21:25:21.925196  3812 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:25:21.925196  3812 net.cpp:137] Memory required for data: 111386800
I1004 21:25:21.925196  3812 layer_factory.cpp:58] Creating layer bn_conv11
I1004 21:25:21.925196  3812 net.cpp:84] Creating Layer bn_conv11
I1004 21:25:21.925196  3812 net.cpp:406] bn_conv11 <- conv11
I1004 21:25:21.925196  3812 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1004 21:25:21.925196  3812 net.cpp:122] Setting up bn_conv11
I1004 21:25:21.925196  3812 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:25:21.925196  3812 net.cpp:137] Memory required for data: 112282800
I1004 21:25:21.925196  3812 layer_factory.cpp:58] Creating layer scale_conv11
I1004 21:25:21.925196  3812 net.cpp:84] Creating Layer scale_conv11
I1004 21:25:21.925196  3812 net.cpp:406] scale_conv11 <- conv11
I1004 21:25:21.925196  3812 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1004 21:25:21.925196  3812 layer_factory.cpp:58] Creating layer scale_conv11
I1004 21:25:21.925196  3812 net.cpp:122] Setting up scale_conv11
I1004 21:25:21.925196  3812 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:25:21.925196  3812 net.cpp:137] Memory required for data: 113178800
I1004 21:25:21.925196  3812 layer_factory.cpp:58] Creating layer relu_conv11
I1004 21:25:21.925196  3812 net.cpp:84] Creating Layer relu_conv11
I1004 21:25:21.925196  3812 net.cpp:406] relu_conv11 <- conv11
I1004 21:25:21.925196  3812 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1004 21:25:21.926183  3812 net.cpp:122] Setting up relu_conv11
I1004 21:25:21.926183  3812 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:25:21.926183  3812 net.cpp:137] Memory required for data: 114074800
I1004 21:25:21.926183  3812 layer_factory.cpp:58] Creating layer conv12
I1004 21:25:21.926183  3812 net.cpp:84] Creating Layer conv12
I1004 21:25:21.926183  3812 net.cpp:406] conv12 <- conv11
I1004 21:25:21.926183  3812 net.cpp:380] conv12 -> conv12
I1004 21:25:21.928189  3812 net.cpp:122] Setting up conv12
I1004 21:25:21.928189  3812 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:25:21.928189  3812 net.cpp:137] Memory required for data: 115175600
I1004 21:25:21.928189  3812 layer_factory.cpp:58] Creating layer bn_conv12
I1004 21:25:21.928189  3812 net.cpp:84] Creating Layer bn_conv12
I1004 21:25:21.928189  3812 net.cpp:406] bn_conv12 <- conv12
I1004 21:25:21.928189  3812 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1004 21:25:21.928189  3812 net.cpp:122] Setting up bn_conv12
I1004 21:25:21.928189  3812 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:25:21.928189  3812 net.cpp:137] Memory required for data: 116276400
I1004 21:25:21.928189  3812 layer_factory.cpp:58] Creating layer scale_conv12
I1004 21:25:21.928189  3812 net.cpp:84] Creating Layer scale_conv12
I1004 21:25:21.928189  3812 net.cpp:406] scale_conv12 <- conv12
I1004 21:25:21.928189  3812 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1004 21:25:21.928189  3812 layer_factory.cpp:58] Creating layer scale_conv12
I1004 21:25:21.928189  3812 net.cpp:122] Setting up scale_conv12
I1004 21:25:21.928189  3812 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:25:21.928189  3812 net.cpp:137] Memory required for data: 117377200
I1004 21:25:21.928189  3812 layer_factory.cpp:58] Creating layer relu_conv12
I1004 21:25:21.929183  3812 net.cpp:84] Creating Layer relu_conv12
I1004 21:25:21.929183  3812 net.cpp:406] relu_conv12 <- conv12
I1004 21:25:21.929183  3812 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1004 21:25:21.929183  3812 net.cpp:122] Setting up relu_conv12
I1004 21:25:21.929183  3812 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:25:21.929183  3812 net.cpp:137] Memory required for data: 118478000
I1004 21:25:21.929183  3812 layer_factory.cpp:58] Creating layer poolcp6
I1004 21:25:21.929183  3812 net.cpp:84] Creating Layer poolcp6
I1004 21:25:21.929183  3812 net.cpp:406] poolcp6 <- conv12
I1004 21:25:21.929183  3812 net.cpp:380] poolcp6 -> poolcp6
I1004 21:25:21.929183  3812 net.cpp:122] Setting up poolcp6
I1004 21:25:21.929183  3812 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1004 21:25:21.929183  3812 net.cpp:137] Memory required for data: 118495200
I1004 21:25:21.929183  3812 layer_factory.cpp:58] Creating layer ip1
I1004 21:25:21.929183  3812 net.cpp:84] Creating Layer ip1
I1004 21:25:21.929183  3812 net.cpp:406] ip1 <- poolcp6
I1004 21:25:21.929183  3812 net.cpp:380] ip1 -> ip1
I1004 21:25:21.929183  3812 net.cpp:122] Setting up ip1
I1004 21:25:21.929183  3812 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:25:21.929183  3812 net.cpp:137] Memory required for data: 118499200
I1004 21:25:21.929183  3812 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1004 21:25:21.929183  3812 net.cpp:84] Creating Layer ip1_ip1_0_split
I1004 21:25:21.929183  3812 net.cpp:406] ip1_ip1_0_split <- ip1
I1004 21:25:21.929183  3812 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1004 21:25:21.929183  3812 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1004 21:25:21.929183  3812 net.cpp:122] Setting up ip1_ip1_0_split
I1004 21:25:21.929183  3812 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:25:21.930179  3812 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:25:21.930179  3812 net.cpp:137] Memory required for data: 118507200
I1004 21:25:21.930179  3812 layer_factory.cpp:58] Creating layer accuracy
I1004 21:25:21.930179  3812 net.cpp:84] Creating Layer accuracy
I1004 21:25:21.930179  3812 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1004 21:25:21.930179  3812 net.cpp:406] accuracy <- label_cifar_1_split_0
I1004 21:25:21.930179  3812 net.cpp:380] accuracy -> accuracy
I1004 21:25:21.930179  3812 net.cpp:122] Setting up accuracy
I1004 21:25:21.930179  3812 net.cpp:129] Top shape: (1)
I1004 21:25:21.930179  3812 net.cpp:137] Memory required for data: 118507204
I1004 21:25:21.930179  3812 layer_factory.cpp:58] Creating layer loss
I1004 21:25:21.930179  3812 net.cpp:84] Creating Layer loss
I1004 21:25:21.930179  3812 net.cpp:406] loss <- ip1_ip1_0_split_1
I1004 21:25:21.930179  3812 net.cpp:406] loss <- label_cifar_1_split_1
I1004 21:25:21.930179  3812 net.cpp:380] loss -> loss
I1004 21:25:21.930179  3812 layer_factory.cpp:58] Creating layer loss
I1004 21:25:21.930179  3812 net.cpp:122] Setting up loss
I1004 21:25:21.930179  3812 net.cpp:129] Top shape: (1)
I1004 21:25:21.930179  3812 net.cpp:132]     with loss weight 1
I1004 21:25:21.930179  3812 net.cpp:137] Memory required for data: 118507208
I1004 21:25:21.930179  3812 net.cpp:198] loss needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:200] accuracy does not need backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] ip1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] poolcp6 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu_conv12 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale_conv12 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn_conv12 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv12 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu_conv11 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale_conv11 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn_conv11 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv11 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu4_0 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale4_0 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn4_0 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv4_0 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] pool4_2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu4_2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale4_2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn4_2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv4_2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu4_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale4_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn4_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv4_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu4 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale4 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn4 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv4 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu3_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale3_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn3_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv3_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu3 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale3 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn3 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv3 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu2_2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale2_2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn2_2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv2_2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu2_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale2_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn2_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv2_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] pool2_1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv2 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu1_0 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale1_0 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn1_0 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv1_0 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] relu1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] scale1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] bn1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:198] conv1 needs backward computation.
I1004 21:25:21.930179  3812 net.cpp:200] label_cifar_1_split does not need backward computation.
I1004 21:25:21.930179  3812 net.cpp:200] cifar does not need backward computation.
I1004 21:25:21.930179  3812 net.cpp:242] This network produces output accuracy
I1004 21:25:21.930179  3812 net.cpp:242] This network produces output loss
I1004 21:25:21.930179  3812 net.cpp:255] Network initialization done.
I1004 21:25:21.931188  3812 solver.cpp:56] Solver scaffolding done.
I1004 21:25:21.934188  3812 caffe.cpp:249] Starting Optimization
I1004 21:25:21.934188  3812 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_drpall_Simple_P3__
I1004 21:25:21.934188  3812 solver.cpp:273] Learning Rate Policy: multistep
I1004 21:25:21.935178  3812 solver.cpp:330] Iteration 0, Testing net (#0)
I1004 21:25:21.937188  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:25:21.963416  3812 blocking_queue.cpp:49] Waiting for data
I1004 21:25:22.978058 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:25:22.994057  3812 solver.cpp:397]     Test net output #0: accuracy = 0.1132
I1004 21:25:22.994057  3812 solver.cpp:397]     Test net output #1: loss = 77.45 (* 1 = 77.45 loss)
I1004 21:25:23.041059  3812 solver.cpp:218] Iteration 0 (-6.69036e-41 iter/s, 1.10589s/100 iters), loss = 3.90316
I1004 21:25:23.041059  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.06
I1004 21:25:23.041059  3812 solver.cpp:237]     Train net output #1: loss = 3.90316 (* 1 = 3.90316 loss)
I1004 21:25:23.042060  3812 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1004 21:25:25.466917  3812 solver.cpp:218] Iteration 100 (41.231 iter/s, 2.42536s/100 iters), loss = 1.8097
I1004 21:25:25.466917  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1004 21:25:25.466917  3812 solver.cpp:237]     Train net output #1: loss = 1.8097 (* 1 = 1.8097 loss)
I1004 21:25:25.466917  3812 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1004 21:25:27.822078  3812 solver.cpp:218] Iteration 200 (42.3307 iter/s, 2.36235s/100 iters), loss = 1.97259
I1004 21:25:27.822078  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1004 21:25:27.822078  3812 solver.cpp:237]     Train net output #1: loss = 1.97259 (* 1 = 1.97259 loss)
I1004 21:25:27.822078  3812 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1004 21:25:30.148552  3812 solver.cpp:218] Iteration 300 (43.1378 iter/s, 2.31815s/100 iters), loss = 1.60003
I1004 21:25:30.148552  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1004 21:25:30.148552  3812 solver.cpp:237]     Train net output #1: loss = 1.60003 (* 1 = 1.60003 loss)
I1004 21:25:30.148552  3812 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1004 21:25:32.428552  3812 solver.cpp:218] Iteration 400 (43.8616 iter/s, 2.2799s/100 iters), loss = 1.44743
I1004 21:25:32.428552  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1004 21:25:32.428552  3812 solver.cpp:237]     Train net output #1: loss = 1.44743 (* 1 = 1.44743 loss)
I1004 21:25:32.428552  3812 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1004 21:25:34.594552 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:25:34.704552  3812 solver.cpp:218] Iteration 500 (43.9455 iter/s, 2.27555s/100 iters), loss = 1.60483
I1004 21:25:34.704552  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1004 21:25:34.704552  3812 solver.cpp:237]     Train net output #1: loss = 1.60483 (* 1 = 1.60483 loss)
I1004 21:25:34.704552  3812 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1004 21:25:36.959553  3812 solver.cpp:218] Iteration 600 (44.3494 iter/s, 2.25482s/100 iters), loss = 1.39769
I1004 21:25:36.959553  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1004 21:25:36.959553  3812 solver.cpp:237]     Train net output #1: loss = 1.39769 (* 1 = 1.39769 loss)
I1004 21:25:36.959553  3812 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1004 21:25:39.203552  3812 solver.cpp:218] Iteration 700 (44.5592 iter/s, 2.24421s/100 iters), loss = 1.55228
I1004 21:25:39.203552  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1004 21:25:39.203552  3812 solver.cpp:237]     Train net output #1: loss = 1.55228 (* 1 = 1.55228 loss)
I1004 21:25:39.204552  3812 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1004 21:25:41.478370  3812 solver.cpp:218] Iteration 800 (43.9795 iter/s, 2.27379s/100 iters), loss = 1.33927
I1004 21:25:41.478370  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1004 21:25:41.478370  3812 solver.cpp:237]     Train net output #1: loss = 1.33927 (* 1 = 1.33927 loss)
I1004 21:25:41.478370  3812 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1004 21:25:43.742928  3812 solver.cpp:218] Iteration 900 (43.8701 iter/s, 2.27946s/100 iters), loss = 1.27415
I1004 21:25:43.742928  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1004 21:25:43.742928  3812 solver.cpp:237]     Train net output #1: loss = 1.27415 (* 1 = 1.27415 loss)
I1004 21:25:43.742928  3812 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1004 21:25:45.908082 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:25:45.996080  3812 solver.cpp:330] Iteration 1000, Testing net (#0)
I1004 21:25:45.996080  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:25:46.429082 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:25:46.446089  3812 solver.cpp:397]     Test net output #0: accuracy = 0.5296
I1004 21:25:46.446089  3812 solver.cpp:397]     Test net output #1: loss = 1.29408 (* 1 = 1.29408 loss)
I1004 21:25:46.467082  3812 solver.cpp:218] Iteration 1000 (36.9195 iter/s, 2.70859s/100 iters), loss = 1.32674
I1004 21:25:46.467082  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1004 21:25:46.467082  3812 solver.cpp:237]     Train net output #1: loss = 1.32674 (* 1 = 1.32674 loss)
I1004 21:25:46.467082  3812 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1004 21:25:48.707332  3812 solver.cpp:218] Iteration 1100 (44.6362 iter/s, 2.24033s/100 iters), loss = 1.25722
I1004 21:25:48.707332  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1004 21:25:48.707332  3812 solver.cpp:237]     Train net output #1: loss = 1.25722 (* 1 = 1.25722 loss)
I1004 21:25:48.707332  3812 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1004 21:25:50.990311  3812 solver.cpp:218] Iteration 1200 (43.7751 iter/s, 2.2844s/100 iters), loss = 1.34954
I1004 21:25:50.990311  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1004 21:25:50.990311  3812 solver.cpp:237]     Train net output #1: loss = 1.34954 (* 1 = 1.34954 loss)
I1004 21:25:50.990311  3812 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1004 21:25:53.228833  3812 solver.cpp:218] Iteration 1300 (44.4896 iter/s, 2.24772s/100 iters), loss = 1.16426
I1004 21:25:53.228833  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1004 21:25:53.228833  3812 solver.cpp:237]     Train net output #1: loss = 1.16426 (* 1 = 1.16426 loss)
I1004 21:25:53.228833  3812 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1004 21:25:55.517774  3812 solver.cpp:218] Iteration 1400 (43.9045 iter/s, 2.27767s/100 iters), loss = 1.08994
I1004 21:25:55.517774  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1004 21:25:55.517774  3812 solver.cpp:237]     Train net output #1: loss = 1.08994 (* 1 = 1.08994 loss)
I1004 21:25:55.517774  3812 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1004 21:25:57.663812 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:25:57.773188  3812 solver.cpp:218] Iteration 1500 (44.2789 iter/s, 2.25841s/100 iters), loss = 1.14425
I1004 21:25:57.773188  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1004 21:25:57.773188  3812 solver.cpp:237]     Train net output #1: loss = 1.14425 (* 1 = 1.14425 loss)
I1004 21:25:57.773188  3812 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1004 21:26:00.053295  3812 solver.cpp:218] Iteration 1600 (43.9369 iter/s, 2.27599s/100 iters), loss = 1.03746
I1004 21:26:00.053295  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1004 21:26:00.053295  3812 solver.cpp:237]     Train net output #1: loss = 1.03746 (* 1 = 1.03746 loss)
I1004 21:26:00.053295  3812 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1004 21:26:02.323837  3812 solver.cpp:218] Iteration 1700 (44.0146 iter/s, 2.27197s/100 iters), loss = 1.11749
I1004 21:26:02.323837  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1004 21:26:02.323837  3812 solver.cpp:237]     Train net output #1: loss = 1.11749 (* 1 = 1.11749 loss)
I1004 21:26:02.323837  3812 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1004 21:26:04.571172  3812 solver.cpp:218] Iteration 1800 (44.3939 iter/s, 2.25256s/100 iters), loss = 1.00052
I1004 21:26:04.571172  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1004 21:26:04.571172  3812 solver.cpp:237]     Train net output #1: loss = 1.00052 (* 1 = 1.00052 loss)
I1004 21:26:04.571172  3812 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1004 21:26:06.835798  3812 solver.cpp:218] Iteration 1900 (44.1543 iter/s, 2.26479s/100 iters), loss = 0.939304
I1004 21:26:06.835798  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1004 21:26:06.835798  3812 solver.cpp:237]     Train net output #1: loss = 0.939304 (* 1 = 0.939304 loss)
I1004 21:26:06.835798  3812 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1004 21:26:09.004587 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:26:09.091038  3812 solver.cpp:330] Iteration 2000, Testing net (#0)
I1004 21:26:09.091038  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:26:09.531412 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:26:09.547037  3812 solver.cpp:397]     Test net output #0: accuracy = 0.6343
I1004 21:26:09.547037  3812 solver.cpp:397]     Test net output #1: loss = 1.02411 (* 1 = 1.02411 loss)
I1004 21:26:09.562662  3812 solver.cpp:218] Iteration 2000 (36.6949 iter/s, 2.72518s/100 iters), loss = 1.00248
I1004 21:26:09.562662  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1004 21:26:09.562662  3812 solver.cpp:237]     Train net output #1: loss = 1.00248 (* 1 = 1.00248 loss)
I1004 21:26:09.562662  3812 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1004 21:26:11.824630  3812 solver.cpp:218] Iteration 2100 (44.291 iter/s, 2.25779s/100 iters), loss = 0.938941
I1004 21:26:11.824630  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1004 21:26:11.824630  3812 solver.cpp:237]     Train net output #1: loss = 0.938941 (* 1 = 0.938941 loss)
I1004 21:26:11.824630  3812 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1004 21:26:14.094107  3812 solver.cpp:218] Iteration 2200 (44.0806 iter/s, 2.26857s/100 iters), loss = 1.07485
I1004 21:26:14.094107  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1004 21:26:14.094107  3812 solver.cpp:237]     Train net output #1: loss = 1.07485 (* 1 = 1.07485 loss)
I1004 21:26:14.094107  3812 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1004 21:26:16.366328  3812 solver.cpp:218] Iteration 2300 (44.0623 iter/s, 2.26951s/100 iters), loss = 0.920073
I1004 21:26:16.366328  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1004 21:26:16.366328  3812 solver.cpp:237]     Train net output #1: loss = 0.920073 (* 1 = 0.920073 loss)
I1004 21:26:16.366328  3812 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1004 21:26:18.619700  3812 solver.cpp:218] Iteration 2400 (44.2529 iter/s, 2.25974s/100 iters), loss = 0.791547
I1004 21:26:18.619700  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1004 21:26:18.619700  3812 solver.cpp:237]     Train net output #1: loss = 0.791547 (* 1 = 0.791547 loss)
I1004 21:26:18.619700  3812 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1004 21:26:20.789739 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:26:20.903738  3812 solver.cpp:218] Iteration 2500 (43.919 iter/s, 2.27692s/100 iters), loss = 1.02601
I1004 21:26:20.903738  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1004 21:26:20.903738  3812 solver.cpp:237]     Train net output #1: loss = 1.02601 (* 1 = 1.02601 loss)
I1004 21:26:20.903738  3812 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1004 21:26:23.173280  3812 solver.cpp:218] Iteration 2600 (43.9234 iter/s, 2.27669s/100 iters), loss = 0.886111
I1004 21:26:23.173280  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1004 21:26:23.173280  3812 solver.cpp:237]     Train net output #1: loss = 0.886111 (* 1 = 0.886111 loss)
I1004 21:26:23.173280  3812 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1004 21:26:25.431535  3812 solver.cpp:218] Iteration 2700 (44.2968 iter/s, 2.2575s/100 iters), loss = 1.03824
I1004 21:26:25.431535  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1004 21:26:25.431535  3812 solver.cpp:237]     Train net output #1: loss = 1.03824 (* 1 = 1.03824 loss)
I1004 21:26:25.431535  3812 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1004 21:26:27.698942  3812 solver.cpp:218] Iteration 2800 (44.0102 iter/s, 2.2722s/100 iters), loss = 0.87269
I1004 21:26:27.698942  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1004 21:26:27.698942  3812 solver.cpp:237]     Train net output #1: loss = 0.87269 (* 1 = 0.87269 loss)
I1004 21:26:27.698942  3812 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1004 21:26:29.978308  3812 solver.cpp:218] Iteration 2900 (44.0923 iter/s, 2.26797s/100 iters), loss = 0.909003
I1004 21:26:29.978308  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1004 21:26:29.978308  3812 solver.cpp:237]     Train net output #1: loss = 0.909003 (* 1 = 0.909003 loss)
I1004 21:26:29.978308  3812 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1004 21:26:32.110724 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:26:32.199983  3812 solver.cpp:330] Iteration 3000, Testing net (#0)
I1004 21:26:32.199983  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:26:32.641448 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:26:32.658452  3812 solver.cpp:397]     Test net output #0: accuracy = 0.661
I1004 21:26:32.658452  3812 solver.cpp:397]     Test net output #1: loss = 0.960372 (* 1 = 0.960372 loss)
I1004 21:26:32.679448  3812 solver.cpp:218] Iteration 3000 (37.0388 iter/s, 2.69987s/100 iters), loss = 0.93577
I1004 21:26:32.679448  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1004 21:26:32.679448  3812 solver.cpp:237]     Train net output #1: loss = 0.93577 (* 1 = 0.93577 loss)
I1004 21:26:32.679448  3812 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1004 21:26:34.960546  3812 solver.cpp:218] Iteration 3100 (43.8357 iter/s, 2.28124s/100 iters), loss = 0.842421
I1004 21:26:34.960546  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1004 21:26:34.960546  3812 solver.cpp:237]     Train net output #1: loss = 0.842421 (* 1 = 0.842421 loss)
I1004 21:26:34.960546  3812 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1004 21:26:37.223106  3812 solver.cpp:218] Iteration 3200 (44.1988 iter/s, 2.2625s/100 iters), loss = 0.930157
I1004 21:26:37.223106  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1004 21:26:37.223106  3812 solver.cpp:237]     Train net output #1: loss = 0.930157 (* 1 = 0.930157 loss)
I1004 21:26:37.223106  3812 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1004 21:26:39.478485  3812 solver.cpp:218] Iteration 3300 (44.2947 iter/s, 2.2576s/100 iters), loss = 0.820451
I1004 21:26:39.478485  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1004 21:26:39.478485  3812 solver.cpp:237]     Train net output #1: loss = 0.820451 (* 1 = 0.820451 loss)
I1004 21:26:39.478485  3812 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1004 21:26:41.741950  3812 solver.cpp:218] Iteration 3400 (44.2388 iter/s, 2.26046s/100 iters), loss = 0.769135
I1004 21:26:41.741950  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1004 21:26:41.741950  3812 solver.cpp:237]     Train net output #1: loss = 0.769135 (* 1 = 0.769135 loss)
I1004 21:26:41.741950  3812 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1004 21:26:43.896061 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:26:44.007421  3812 solver.cpp:218] Iteration 3500 (44.1525 iter/s, 2.26488s/100 iters), loss = 0.848042
I1004 21:26:44.007421  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1004 21:26:44.007421  3812 solver.cpp:237]     Train net output #1: loss = 0.848042 (* 1 = 0.848042 loss)
I1004 21:26:44.007421  3812 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1004 21:26:46.266000  3812 solver.cpp:218] Iteration 3600 (44.2045 iter/s, 2.26221s/100 iters), loss = 0.742564
I1004 21:26:46.266000  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1004 21:26:46.266000  3812 solver.cpp:237]     Train net output #1: loss = 0.742564 (* 1 = 0.742564 loss)
I1004 21:26:46.266000  3812 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1004 21:26:48.525048  3812 solver.cpp:218] Iteration 3700 (44.2329 iter/s, 2.26076s/100 iters), loss = 0.866514
I1004 21:26:48.525048  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1004 21:26:48.525048  3812 solver.cpp:237]     Train net output #1: loss = 0.866514 (* 1 = 0.866514 loss)
I1004 21:26:48.525048  3812 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1004 21:26:50.847335  3812 solver.cpp:218] Iteration 3800 (43.1888 iter/s, 2.31541s/100 iters), loss = 0.807812
I1004 21:26:50.847335  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1004 21:26:50.847335  3812 solver.cpp:237]     Train net output #1: loss = 0.807812 (* 1 = 0.807812 loss)
I1004 21:26:50.847335  3812 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1004 21:26:53.102557  3812 solver.cpp:218] Iteration 3900 (44.343 iter/s, 2.25515s/100 iters), loss = 0.675857
I1004 21:26:53.102557  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:26:53.102557  3812 solver.cpp:237]     Train net output #1: loss = 0.675857 (* 1 = 0.675857 loss)
I1004 21:26:53.102557  3812 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1004 21:26:55.283455 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:26:55.364317  3812 solver.cpp:330] Iteration 4000, Testing net (#0)
I1004 21:26:55.364317  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:26:55.798614 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:26:55.814239  3812 solver.cpp:397]     Test net output #0: accuracy = 0.6745
I1004 21:26:55.814239  3812 solver.cpp:397]     Test net output #1: loss = 0.967134 (* 1 = 0.967134 loss)
I1004 21:26:55.829864  3812 solver.cpp:218] Iteration 4000 (36.5444 iter/s, 2.7364s/100 iters), loss = 0.875221
I1004 21:26:55.829864  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1004 21:26:55.829864  3812 solver.cpp:237]     Train net output #1: loss = 0.875221 (* 1 = 0.875221 loss)
I1004 21:26:55.829864  3812 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1004 21:26:58.104430  3812 solver.cpp:218] Iteration 4100 (44.1626 iter/s, 2.26436s/100 iters), loss = 0.694633
I1004 21:26:58.104430  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1004 21:26:58.104430  3812 solver.cpp:237]     Train net output #1: loss = 0.694633 (* 1 = 0.694633 loss)
I1004 21:26:58.104430  3812 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1004 21:27:00.374819  3812 solver.cpp:218] Iteration 4200 (43.8177 iter/s, 2.28218s/100 iters), loss = 0.83594
I1004 21:27:00.374819  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1004 21:27:00.374819  3812 solver.cpp:237]     Train net output #1: loss = 0.83594 (* 1 = 0.83594 loss)
I1004 21:27:00.374819  3812 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1004 21:27:02.658953  3812 solver.cpp:218] Iteration 4300 (44.0022 iter/s, 2.27261s/100 iters), loss = 0.643407
I1004 21:27:02.659953  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 21:27:02.659953  3812 solver.cpp:237]     Train net output #1: loss = 0.643407 (* 1 = 0.643407 loss)
I1004 21:27:02.659953  3812 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1004 21:27:04.924016  3812 solver.cpp:218] Iteration 4400 (44.1746 iter/s, 2.26374s/100 iters), loss = 0.619659
I1004 21:27:04.924016  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:27:04.924016  3812 solver.cpp:237]     Train net output #1: loss = 0.619659 (* 1 = 0.619659 loss)
I1004 21:27:04.924016  3812 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1004 21:27:07.072186 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:27:07.184197  3812 solver.cpp:218] Iteration 4500 (44.2425 iter/s, 2.26027s/100 iters), loss = 0.736902
I1004 21:27:07.184197  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 21:27:07.184197  3812 solver.cpp:237]     Train net output #1: loss = 0.736902 (* 1 = 0.736902 loss)
I1004 21:27:07.184197  3812 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1004 21:27:09.462647  3812 solver.cpp:218] Iteration 4600 (43.7836 iter/s, 2.28396s/100 iters), loss = 0.680393
I1004 21:27:09.462647  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:27:09.462647  3812 solver.cpp:237]     Train net output #1: loss = 0.680393 (* 1 = 0.680393 loss)
I1004 21:27:09.462647  3812 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1004 21:27:11.721156  3812 solver.cpp:218] Iteration 4700 (44.322 iter/s, 2.25622s/100 iters), loss = 0.7959
I1004 21:27:11.721156  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1004 21:27:11.721156  3812 solver.cpp:237]     Train net output #1: loss = 0.7959 (* 1 = 0.7959 loss)
I1004 21:27:11.721156  3812 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1004 21:27:13.978718  3812 solver.cpp:218] Iteration 4800 (44.2197 iter/s, 2.26143s/100 iters), loss = 0.701447
I1004 21:27:13.978718  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:27:13.978718  3812 solver.cpp:237]     Train net output #1: loss = 0.701447 (* 1 = 0.701447 loss)
I1004 21:27:13.978718  3812 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1004 21:27:16.264240  3812 solver.cpp:218] Iteration 4900 (43.9238 iter/s, 2.27667s/100 iters), loss = 0.646018
I1004 21:27:16.264240  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:27:16.264240  3812 solver.cpp:237]     Train net output #1: loss = 0.646018 (* 1 = 0.646018 loss)
I1004 21:27:16.264240  3812 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1004 21:27:18.414418 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:27:18.505386  3812 solver.cpp:330] Iteration 5000, Testing net (#0)
I1004 21:27:18.505386  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:27:18.945459 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:27:18.962460  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7231
I1004 21:27:18.962460  3812 solver.cpp:397]     Test net output #1: loss = 0.805125 (* 1 = 0.805125 loss)
I1004 21:27:18.982458  3812 solver.cpp:218] Iteration 5000 (36.7865 iter/s, 2.71839s/100 iters), loss = 0.746421
I1004 21:27:18.983458  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:27:18.983458  3812 solver.cpp:237]     Train net output #1: loss = 0.746421 (* 1 = 0.746421 loss)
I1004 21:27:18.983458  3812 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I1004 21:27:18.983458  3812 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I1004 21:27:21.256459  3812 solver.cpp:218] Iteration 5100 (43.7177 iter/s, 2.2874s/100 iters), loss = 0.667086
I1004 21:27:21.256459  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1004 21:27:21.256459  3812 solver.cpp:237]     Train net output #1: loss = 0.667086 (* 1 = 0.667086 loss)
I1004 21:27:21.256459  3812 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I1004 21:27:23.526314  3812 solver.cpp:218] Iteration 5200 (44.3143 iter/s, 2.25661s/100 iters), loss = 0.578413
I1004 21:27:23.526314  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:27:23.526314  3812 solver.cpp:237]     Train net output #1: loss = 0.578413 (* 1 = 0.578413 loss)
I1004 21:27:23.526314  3812 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I1004 21:27:25.801064  3812 solver.cpp:218] Iteration 5300 (43.9948 iter/s, 2.273s/100 iters), loss = 0.63147
I1004 21:27:25.801064  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:27:25.801064  3812 solver.cpp:237]     Train net output #1: loss = 0.63147 (* 1 = 0.63147 loss)
I1004 21:27:25.801064  3812 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I1004 21:27:28.097391  3812 solver.cpp:218] Iteration 5400 (43.5578 iter/s, 2.2958s/100 iters), loss = 0.585247
I1004 21:27:28.097391  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1004 21:27:28.097391  3812 solver.cpp:237]     Train net output #1: loss = 0.585247 (* 1 = 0.585247 loss)
I1004 21:27:28.097391  3812 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I1004 21:27:30.250906 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:27:30.363852  3812 solver.cpp:218] Iteration 5500 (44.1029 iter/s, 2.26742s/100 iters), loss = 0.655599
I1004 21:27:30.363852  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1004 21:27:30.363852  3812 solver.cpp:237]     Train net output #1: loss = 0.655599 (* 1 = 0.655599 loss)
I1004 21:27:30.363852  3812 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I1004 21:27:32.603245  3812 solver.cpp:218] Iteration 5600 (44.3948 iter/s, 2.25252s/100 iters), loss = 0.60095
I1004 21:27:32.603245  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:27:32.603245  3812 solver.cpp:237]     Train net output #1: loss = 0.60095 (* 1 = 0.60095 loss)
I1004 21:27:32.603245  3812 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I1004 21:27:34.860154  3812 solver.cpp:218] Iteration 5700 (44.3392 iter/s, 2.25534s/100 iters), loss = 0.602352
I1004 21:27:34.860154  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:27:34.860154  3812 solver.cpp:237]     Train net output #1: loss = 0.602352 (* 1 = 0.602352 loss)
I1004 21:27:34.860154  3812 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I1004 21:27:37.118978  3812 solver.cpp:218] Iteration 5800 (44.4842 iter/s, 2.24799s/100 iters), loss = 0.608602
I1004 21:27:37.118978  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:27:37.118978  3812 solver.cpp:237]     Train net output #1: loss = 0.608602 (* 1 = 0.608602 loss)
I1004 21:27:37.118978  3812 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I1004 21:27:39.367259  3812 solver.cpp:218] Iteration 5900 (44.3534 iter/s, 2.25462s/100 iters), loss = 0.54148
I1004 21:27:39.367259  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:27:39.367259  3812 solver.cpp:237]     Train net output #1: loss = 0.54148 (* 1 = 0.54148 loss)
I1004 21:27:39.367259  3812 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I1004 21:27:41.510457 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:27:41.604207  3812 solver.cpp:330] Iteration 6000, Testing net (#0)
I1004 21:27:41.604207  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:27:42.025101 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:27:42.040729  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7517
I1004 21:27:42.040729  3812 solver.cpp:397]     Test net output #1: loss = 0.705002 (* 1 = 0.705002 loss)
I1004 21:27:42.071990  3812 solver.cpp:218] Iteration 6000 (37.0958 iter/s, 2.69573s/100 iters), loss = 0.613797
I1004 21:27:42.071990  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:27:42.071990  3812 solver.cpp:237]     Train net output #1: loss = 0.613797 (* 1 = 0.613797 loss)
I1004 21:27:42.071990  3812 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I1004 21:27:44.341449  3812 solver.cpp:218] Iteration 6100 (44.084 iter/s, 2.2684s/100 iters), loss = 0.55537
I1004 21:27:44.341449  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:27:44.341449  3812 solver.cpp:237]     Train net output #1: loss = 0.55537 (* 1 = 0.55537 loss)
I1004 21:27:44.341449  3812 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I1004 21:27:46.600117  3812 solver.cpp:218] Iteration 6200 (44.2884 iter/s, 2.25793s/100 iters), loss = 0.663958
I1004 21:27:46.600117  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:27:46.600117  3812 solver.cpp:237]     Train net output #1: loss = 0.663958 (* 1 = 0.663958 loss)
I1004 21:27:46.600117  3812 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I1004 21:27:48.846153  3812 solver.cpp:218] Iteration 6300 (44.2463 iter/s, 2.26008s/100 iters), loss = 0.596391
I1004 21:27:48.846153  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:27:48.846153  3812 solver.cpp:237]     Train net output #1: loss = 0.596391 (* 1 = 0.596391 loss)
I1004 21:27:48.846153  3812 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I1004 21:27:51.138028  3812 solver.cpp:218] Iteration 6400 (43.8797 iter/s, 2.27896s/100 iters), loss = 0.508459
I1004 21:27:51.138028  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:27:51.138028  3812 solver.cpp:237]     Train net output #1: loss = 0.508459 (* 1 = 0.508459 loss)
I1004 21:27:51.138028  3812 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I1004 21:27:53.298044 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:27:53.409037  3812 solver.cpp:218] Iteration 6500 (44.0641 iter/s, 2.26942s/100 iters), loss = 0.56237
I1004 21:27:53.409037  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:27:53.409037  3812 solver.cpp:237]     Train net output #1: loss = 0.56237 (* 1 = 0.56237 loss)
I1004 21:27:53.409037  3812 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I1004 21:27:55.694253  3812 solver.cpp:218] Iteration 6600 (43.7689 iter/s, 2.28473s/100 iters), loss = 0.630399
I1004 21:27:55.694253  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1004 21:27:55.694253  3812 solver.cpp:237]     Train net output #1: loss = 0.630399 (* 1 = 0.630399 loss)
I1004 21:27:55.694253  3812 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I1004 21:27:57.994350  3812 solver.cpp:218] Iteration 6700 (43.4415 iter/s, 2.30194s/100 iters), loss = 0.5714
I1004 21:27:57.994350  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:27:57.994350  3812 solver.cpp:237]     Train net output #1: loss = 0.5714 (* 1 = 0.5714 loss)
I1004 21:27:57.994350  3812 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I1004 21:28:00.249151  3812 solver.cpp:218] Iteration 6800 (44.4008 iter/s, 2.25221s/100 iters), loss = 0.57763
I1004 21:28:00.249151  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:28:00.249151  3812 solver.cpp:237]     Train net output #1: loss = 0.57763 (* 1 = 0.57763 loss)
I1004 21:28:00.249151  3812 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I1004 21:28:02.494170  3812 solver.cpp:218] Iteration 6900 (44.4479 iter/s, 2.24983s/100 iters), loss = 0.508013
I1004 21:28:02.494170  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:28:02.494170  3812 solver.cpp:237]     Train net output #1: loss = 0.508013 (* 1 = 0.508013 loss)
I1004 21:28:02.494170  3812 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I1004 21:28:04.643379 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:28:04.732022  3812 solver.cpp:330] Iteration 7000, Testing net (#0)
I1004 21:28:04.732022  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:28:05.163033 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:28:05.181023  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7564
I1004 21:28:05.181023  3812 solver.cpp:397]     Test net output #1: loss = 0.695579 (* 1 = 0.695579 loss)
I1004 21:28:05.204021  3812 solver.cpp:218] Iteration 7000 (36.983 iter/s, 2.70395s/100 iters), loss = 0.622377
I1004 21:28:05.204021  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:28:05.204021  3812 solver.cpp:237]     Train net output #1: loss = 0.622377 (* 1 = 0.622377 loss)
I1004 21:28:05.204021  3812 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I1004 21:28:07.462718  3812 solver.cpp:218] Iteration 7100 (44.1028 iter/s, 2.26743s/100 iters), loss = 0.599549
I1004 21:28:07.462718  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 21:28:07.462718  3812 solver.cpp:237]     Train net output #1: loss = 0.599549 (* 1 = 0.599549 loss)
I1004 21:28:07.462718  3812 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I1004 21:28:09.720155  3812 solver.cpp:218] Iteration 7200 (44.362 iter/s, 2.25418s/100 iters), loss = 0.611547
I1004 21:28:09.720155  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:28:09.720155  3812 solver.cpp:237]     Train net output #1: loss = 0.611547 (* 1 = 0.611547 loss)
I1004 21:28:09.720155  3812 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I1004 21:28:11.988931  3812 solver.cpp:218] Iteration 7300 (43.9303 iter/s, 2.27633s/100 iters), loss = 0.576853
I1004 21:28:11.988931  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:28:11.988931  3812 solver.cpp:237]     Train net output #1: loss = 0.576853 (* 1 = 0.576853 loss)
I1004 21:28:11.988931  3812 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I1004 21:28:14.265450  3812 solver.cpp:218] Iteration 7400 (44.2009 iter/s, 2.2624s/100 iters), loss = 0.485219
I1004 21:28:14.265450  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:28:14.265450  3812 solver.cpp:237]     Train net output #1: loss = 0.485219 (* 1 = 0.485219 loss)
I1004 21:28:14.265450  3812 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I1004 21:28:16.408414 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:28:16.509668  3812 solver.cpp:218] Iteration 7500 (44.404 iter/s, 2.25205s/100 iters), loss = 0.571157
I1004 21:28:16.509668  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:28:16.509668  3812 solver.cpp:237]     Train net output #1: loss = 0.571157 (* 1 = 0.571157 loss)
I1004 21:28:16.509668  3812 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I1004 21:28:18.764844  3812 solver.cpp:218] Iteration 7600 (44.5029 iter/s, 2.24704s/100 iters), loss = 0.570056
I1004 21:28:18.764844  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:28:18.764844  3812 solver.cpp:237]     Train net output #1: loss = 0.570056 (* 1 = 0.570056 loss)
I1004 21:28:18.764844  3812 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I1004 21:28:21.011204  3812 solver.cpp:218] Iteration 7700 (44.353 iter/s, 2.25464s/100 iters), loss = 0.53079
I1004 21:28:21.011204  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:28:21.011204  3812 solver.cpp:237]     Train net output #1: loss = 0.53079 (* 1 = 0.53079 loss)
I1004 21:28:21.011204  3812 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I1004 21:28:23.272505  3812 solver.cpp:218] Iteration 7800 (44.3537 iter/s, 2.2546s/100 iters), loss = 0.581064
I1004 21:28:23.272505  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:28:23.272505  3812 solver.cpp:237]     Train net output #1: loss = 0.581064 (* 1 = 0.581064 loss)
I1004 21:28:23.272505  3812 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I1004 21:28:25.528743  3812 solver.cpp:218] Iteration 7900 (44.3647 iter/s, 2.25404s/100 iters), loss = 0.508058
I1004 21:28:25.528743  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:28:25.528743  3812 solver.cpp:237]     Train net output #1: loss = 0.508058 (* 1 = 0.508058 loss)
I1004 21:28:25.528743  3812 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I1004 21:28:27.654553 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:28:27.748303  3812 solver.cpp:330] Iteration 8000, Testing net (#0)
I1004 21:28:27.748303  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:28:28.177842 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:28:28.193470  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7576
I1004 21:28:28.193470  3812 solver.cpp:397]     Test net output #1: loss = 0.694762 (* 1 = 0.694762 loss)
I1004 21:28:28.224720  3812 solver.cpp:218] Iteration 8000 (37.0975 iter/s, 2.6956s/100 iters), loss = 0.642731
I1004 21:28:28.224720  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:28:28.224720  3812 solver.cpp:237]     Train net output #1: loss = 0.642731 (* 1 = 0.642731 loss)
I1004 21:28:28.224720  3812 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I1004 21:28:30.479997  3812 solver.cpp:218] Iteration 8100 (44.1905 iter/s, 2.26293s/100 iters), loss = 0.542141
I1004 21:28:30.479997  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:28:30.479997  3812 solver.cpp:237]     Train net output #1: loss = 0.542141 (* 1 = 0.542141 loss)
I1004 21:28:30.479997  3812 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I1004 21:28:32.732832  3812 solver.cpp:218] Iteration 8200 (44.2972 iter/s, 2.25748s/100 iters), loss = 0.594894
I1004 21:28:32.732832  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:28:32.732832  3812 solver.cpp:237]     Train net output #1: loss = 0.594894 (* 1 = 0.594894 loss)
I1004 21:28:32.732832  3812 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I1004 21:28:35.011207  3812 solver.cpp:218] Iteration 8300 (44.074 iter/s, 2.26891s/100 iters), loss = 0.541857
I1004 21:28:35.011207  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:28:35.011207  3812 solver.cpp:237]     Train net output #1: loss = 0.541857 (* 1 = 0.541857 loss)
I1004 21:28:35.011207  3812 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I1004 21:28:37.280405  3812 solver.cpp:218] Iteration 8400 (44.1577 iter/s, 2.26461s/100 iters), loss = 0.487175
I1004 21:28:37.280405  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:28:37.280405  3812 solver.cpp:237]     Train net output #1: loss = 0.487175 (* 1 = 0.487175 loss)
I1004 21:28:37.280405  3812 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I1004 21:28:39.431812 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:28:39.543118  3812 solver.cpp:218] Iteration 8500 (44.2003 iter/s, 2.26243s/100 iters), loss = 0.577588
I1004 21:28:39.543118  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:28:39.543118  3812 solver.cpp:237]     Train net output #1: loss = 0.577588 (* 1 = 0.577588 loss)
I1004 21:28:39.543118  3812 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I1004 21:28:41.812760  3812 solver.cpp:218] Iteration 8600 (44.0745 iter/s, 2.26889s/100 iters), loss = 0.588641
I1004 21:28:41.812760  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:28:41.812760  3812 solver.cpp:237]     Train net output #1: loss = 0.588641 (* 1 = 0.588641 loss)
I1004 21:28:41.812760  3812 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I1004 21:28:44.061723  3812 solver.cpp:218] Iteration 8700 (44.2999 iter/s, 2.25734s/100 iters), loss = 0.548883
I1004 21:28:44.061723  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:28:44.061723  3812 solver.cpp:237]     Train net output #1: loss = 0.548883 (* 1 = 0.548883 loss)
I1004 21:28:44.061723  3812 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I1004 21:28:46.342600  3812 solver.cpp:218] Iteration 8800 (44.0083 iter/s, 2.2723s/100 iters), loss = 0.582002
I1004 21:28:46.342600  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:28:46.342600  3812 solver.cpp:237]     Train net output #1: loss = 0.582002 (* 1 = 0.582002 loss)
I1004 21:28:46.342600  3812 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I1004 21:28:48.603945  3812 solver.cpp:218] Iteration 8900 (44.2264 iter/s, 2.26109s/100 iters), loss = 0.464238
I1004 21:28:48.603945  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:28:48.603945  3812 solver.cpp:237]     Train net output #1: loss = 0.464238 (* 1 = 0.464238 loss)
I1004 21:28:48.603945  3812 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I1004 21:28:50.769536 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:28:50.863286  3812 solver.cpp:330] Iteration 9000, Testing net (#0)
I1004 21:28:50.863286  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:28:51.290792 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:28:51.306418  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7618
I1004 21:28:51.306418  3812 solver.cpp:397]     Test net output #1: loss = 0.688835 (* 1 = 0.688835 loss)
I1004 21:28:51.341447  3812 solver.cpp:218] Iteration 9000 (36.5284 iter/s, 2.7376s/100 iters), loss = 0.537903
I1004 21:28:51.342447  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:28:51.342447  3812 solver.cpp:237]     Train net output #1: loss = 0.537903 (* 1 = 0.537903 loss)
I1004 21:28:51.342447  3812 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I1004 21:28:53.597491  3812 solver.cpp:218] Iteration 9100 (44.2607 iter/s, 2.25934s/100 iters), loss = 0.533432
I1004 21:28:53.597491  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:28:53.597491  3812 solver.cpp:237]     Train net output #1: loss = 0.533432 (* 1 = 0.533432 loss)
I1004 21:28:53.597491  3812 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I1004 21:28:55.862897  3812 solver.cpp:218] Iteration 9200 (44.1565 iter/s, 2.26467s/100 iters), loss = 0.564178
I1004 21:28:55.862897  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:28:55.862897  3812 solver.cpp:237]     Train net output #1: loss = 0.564178 (* 1 = 0.564178 loss)
I1004 21:28:55.862897  3812 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I1004 21:28:58.119174  3812 solver.cpp:218] Iteration 9300 (44.352 iter/s, 2.25469s/100 iters), loss = 0.557414
I1004 21:28:58.119174  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:28:58.119174  3812 solver.cpp:237]     Train net output #1: loss = 0.557414 (* 1 = 0.557414 loss)
I1004 21:28:58.119174  3812 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I1004 21:29:00.375252  3812 solver.cpp:218] Iteration 9400 (44.2321 iter/s, 2.2608s/100 iters), loss = 0.475732
I1004 21:29:00.375252  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:29:00.375252  3812 solver.cpp:237]     Train net output #1: loss = 0.475732 (* 1 = 0.475732 loss)
I1004 21:29:00.375252  3812 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I1004 21:29:02.536530 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:29:02.644168  3812 solver.cpp:218] Iteration 9500 (44.1366 iter/s, 2.26569s/100 iters), loss = 0.628478
I1004 21:29:02.644168  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:29:02.644168  3812 solver.cpp:237]     Train net output #1: loss = 0.628478 (* 1 = 0.628478 loss)
I1004 21:29:02.644168  3812 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1004 21:29:04.913228  3812 solver.cpp:218] Iteration 9600 (44.1705 iter/s, 2.26395s/100 iters), loss = 0.509003
I1004 21:29:04.913228  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:29:04.913228  3812 solver.cpp:237]     Train net output #1: loss = 0.509003 (* 1 = 0.509003 loss)
I1004 21:29:04.913228  3812 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1004 21:29:07.171926  3812 solver.cpp:218] Iteration 9700 (44.1774 iter/s, 2.2636s/100 iters), loss = 0.546337
I1004 21:29:07.171926  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:29:07.171926  3812 solver.cpp:237]     Train net output #1: loss = 0.546337 (* 1 = 0.546337 loss)
I1004 21:29:07.171926  3812 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I1004 21:29:09.442436  3812 solver.cpp:218] Iteration 9800 (44.1359 iter/s, 2.26573s/100 iters), loss = 0.56942
I1004 21:29:09.442436  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:29:09.442436  3812 solver.cpp:237]     Train net output #1: loss = 0.56942 (* 1 = 0.56942 loss)
I1004 21:29:09.442436  3812 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1004 21:29:11.697116  3812 solver.cpp:218] Iteration 9900 (44.2336 iter/s, 2.26073s/100 iters), loss = 0.474743
I1004 21:29:11.697116  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:29:11.697116  3812 solver.cpp:237]     Train net output #1: loss = 0.474743 (* 1 = 0.474743 loss)
I1004 21:29:11.697116  3812 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I1004 21:29:13.854190 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:29:13.931934  3812 solver.cpp:330] Iteration 10000, Testing net (#0)
I1004 21:29:13.931934  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:29:14.381772 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:29:14.398761  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7622
I1004 21:29:14.398761  3812 solver.cpp:397]     Test net output #1: loss = 0.687906 (* 1 = 0.687906 loss)
I1004 21:29:14.419776  3812 solver.cpp:218] Iteration 10000 (36.831 iter/s, 2.71511s/100 iters), loss = 0.552108
I1004 21:29:14.419776  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:29:14.419776  3812 solver.cpp:237]     Train net output #1: loss = 0.552108 (* 1 = 0.552108 loss)
I1004 21:29:14.419776  3812 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I1004 21:29:14.419776  3812 sgd_solver.cpp:105] Iteration 10000, lr = 0.0001
I1004 21:29:16.665813  3812 solver.cpp:218] Iteration 10100 (44.358 iter/s, 2.25439s/100 iters), loss = 0.522814
I1004 21:29:16.665813  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:29:16.665813  3812 solver.cpp:237]     Train net output #1: loss = 0.522814 (* 1 = 0.522814 loss)
I1004 21:29:16.665813  3812 sgd_solver.cpp:105] Iteration 10100, lr = 0.0001
I1004 21:29:18.931565  3812 solver.cpp:218] Iteration 10200 (44.2042 iter/s, 2.26223s/100 iters), loss = 0.550886
I1004 21:29:18.931565  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:29:18.931565  3812 solver.cpp:237]     Train net output #1: loss = 0.550886 (* 1 = 0.550886 loss)
I1004 21:29:18.931565  3812 sgd_solver.cpp:105] Iteration 10200, lr = 0.0001
I1004 21:29:21.188139  3812 solver.cpp:218] Iteration 10300 (44.3675 iter/s, 2.2539s/100 iters), loss = 0.549702
I1004 21:29:21.188139  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:29:21.188139  3812 solver.cpp:237]     Train net output #1: loss = 0.549702 (* 1 = 0.549702 loss)
I1004 21:29:21.188139  3812 sgd_solver.cpp:105] Iteration 10300, lr = 0.0001
I1004 21:29:23.447124  3812 solver.cpp:218] Iteration 10400 (44.0954 iter/s, 2.26781s/100 iters), loss = 0.409053
I1004 21:29:23.447124  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:29:23.447124  3812 solver.cpp:237]     Train net output #1: loss = 0.409053 (* 1 = 0.409053 loss)
I1004 21:29:23.447124  3812 sgd_solver.cpp:105] Iteration 10400, lr = 0.0001
I1004 21:29:25.591486 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:29:25.700861  3812 solver.cpp:218] Iteration 10500 (44.3875 iter/s, 2.25289s/100 iters), loss = 0.527508
I1004 21:29:25.700861  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:29:25.700861  3812 solver.cpp:237]     Train net output #1: loss = 0.527508 (* 1 = 0.527508 loss)
I1004 21:29:25.700861  3812 sgd_solver.cpp:105] Iteration 10500, lr = 0.0001
I1004 21:29:27.962858  3812 solver.cpp:218] Iteration 10600 (44.3192 iter/s, 2.25636s/100 iters), loss = 0.531282
I1004 21:29:27.962858  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:29:27.962858  3812 solver.cpp:237]     Train net output #1: loss = 0.531282 (* 1 = 0.531282 loss)
I1004 21:29:27.962858  3812 sgd_solver.cpp:105] Iteration 10600, lr = 0.0001
I1004 21:29:30.213434  3812 solver.cpp:218] Iteration 10700 (44.2958 iter/s, 2.25755s/100 iters), loss = 0.559131
I1004 21:29:30.213434  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:29:30.213434  3812 solver.cpp:237]     Train net output #1: loss = 0.559131 (* 1 = 0.559131 loss)
I1004 21:29:30.213434  3812 sgd_solver.cpp:105] Iteration 10700, lr = 0.0001
I1004 21:29:32.478127  3812 solver.cpp:218] Iteration 10800 (44.2129 iter/s, 2.26179s/100 iters), loss = 0.517176
I1004 21:29:32.478127  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:29:32.478127  3812 solver.cpp:237]     Train net output #1: loss = 0.517176 (* 1 = 0.517176 loss)
I1004 21:29:32.478127  3812 sgd_solver.cpp:105] Iteration 10800, lr = 0.0001
I1004 21:29:34.743718  3812 solver.cpp:218] Iteration 10900 (44.147 iter/s, 2.26516s/100 iters), loss = 0.421881
I1004 21:29:34.743718  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:29:34.743718  3812 solver.cpp:237]     Train net output #1: loss = 0.421881 (* 1 = 0.421881 loss)
I1004 21:29:34.743718  3812 sgd_solver.cpp:105] Iteration 10900, lr = 0.0001
I1004 21:29:36.892071 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:29:36.978916  3812 solver.cpp:330] Iteration 11000, Testing net (#0)
I1004 21:29:36.978916  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:29:37.425710 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:29:37.441691  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7655
I1004 21:29:37.442692  3812 solver.cpp:397]     Test net output #1: loss = 0.679135 (* 1 = 0.679135 loss)
I1004 21:29:37.462560  3812 solver.cpp:218] Iteration 11000 (36.9236 iter/s, 2.70829s/100 iters), loss = 0.509178
I1004 21:29:37.462560  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:29:37.462560  3812 solver.cpp:237]     Train net output #1: loss = 0.509178 (* 1 = 0.509178 loss)
I1004 21:29:37.462560  3812 sgd_solver.cpp:105] Iteration 11000, lr = 0.0001
I1004 21:29:39.716589  3812 solver.cpp:218] Iteration 11100 (44.3284 iter/s, 2.25589s/100 iters), loss = 0.51781
I1004 21:29:39.716589  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:29:39.716589  3812 solver.cpp:237]     Train net output #1: loss = 0.51781 (* 1 = 0.51781 loss)
I1004 21:29:39.716589  3812 sgd_solver.cpp:105] Iteration 11100, lr = 0.0001
I1004 21:29:41.979007  3812 solver.cpp:218] Iteration 11200 (44.1977 iter/s, 2.26256s/100 iters), loss = 0.553371
I1004 21:29:41.979007  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:29:41.979007  3812 solver.cpp:237]     Train net output #1: loss = 0.553371 (* 1 = 0.553371 loss)
I1004 21:29:41.979007  3812 sgd_solver.cpp:105] Iteration 11200, lr = 0.0001
I1004 21:29:44.234325  3812 solver.cpp:218] Iteration 11300 (44.3735 iter/s, 2.2536s/100 iters), loss = 0.543812
I1004 21:29:44.234325  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:29:44.234325  3812 solver.cpp:237]     Train net output #1: loss = 0.543812 (* 1 = 0.543812 loss)
I1004 21:29:44.234325  3812 sgd_solver.cpp:105] Iteration 11300, lr = 0.0001
I1004 21:29:46.479427  3812 solver.cpp:218] Iteration 11400 (44.2998 iter/s, 2.25735s/100 iters), loss = 0.464789
I1004 21:29:46.479427  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:29:46.479427  3812 solver.cpp:237]     Train net output #1: loss = 0.464789 (* 1 = 0.464789 loss)
I1004 21:29:46.479427  3812 sgd_solver.cpp:105] Iteration 11400, lr = 0.0001
I1004 21:29:48.639111 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:29:48.748486  3812 solver.cpp:218] Iteration 11500 (44.1644 iter/s, 2.26427s/100 iters), loss = 0.603192
I1004 21:29:48.748486  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:29:48.748486  3812 solver.cpp:237]     Train net output #1: loss = 0.603192 (* 1 = 0.603192 loss)
I1004 21:29:48.748486  3812 sgd_solver.cpp:105] Iteration 11500, lr = 0.0001
I1004 21:29:51.016021  3812 solver.cpp:218] Iteration 11600 (44.253 iter/s, 2.25973s/100 iters), loss = 0.55808
I1004 21:29:51.016021  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:29:51.016021  3812 solver.cpp:237]     Train net output #1: loss = 0.55808 (* 1 = 0.55808 loss)
I1004 21:29:51.016021  3812 sgd_solver.cpp:105] Iteration 11600, lr = 0.0001
I1004 21:29:53.264822  3812 solver.cpp:218] Iteration 11700 (44.3365 iter/s, 2.25548s/100 iters), loss = 0.500019
I1004 21:29:53.264822  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:29:53.264822  3812 solver.cpp:237]     Train net output #1: loss = 0.500019 (* 1 = 0.500019 loss)
I1004 21:29:53.264822  3812 sgd_solver.cpp:105] Iteration 11700, lr = 0.0001
I1004 21:29:55.525862  3812 solver.cpp:218] Iteration 11800 (44.3906 iter/s, 2.25273s/100 iters), loss = 0.547419
I1004 21:29:55.525862  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:29:55.525862  3812 solver.cpp:237]     Train net output #1: loss = 0.547419 (* 1 = 0.547419 loss)
I1004 21:29:55.525862  3812 sgd_solver.cpp:105] Iteration 11800, lr = 0.0001
I1004 21:29:57.775364  3812 solver.cpp:218] Iteration 11900 (44.2701 iter/s, 2.25886s/100 iters), loss = 0.429707
I1004 21:29:57.775364  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:29:57.775364  3812 solver.cpp:237]     Train net output #1: loss = 0.429707 (* 1 = 0.429707 loss)
I1004 21:29:57.775364  3812 sgd_solver.cpp:105] Iteration 11900, lr = 0.0001
I1004 21:29:59.930949 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:30:00.019520  3812 solver.cpp:330] Iteration 12000, Testing net (#0)
I1004 21:30:00.019520  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:30:00.446276 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:30:00.461904  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7675
I1004 21:30:00.461904  3812 solver.cpp:397]     Test net output #1: loss = 0.677846 (* 1 = 0.677846 loss)
I1004 21:30:00.493154  3812 solver.cpp:218] Iteration 12000 (36.8826 iter/s, 2.7113s/100 iters), loss = 0.532886
I1004 21:30:00.493154  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:30:00.493154  3812 solver.cpp:237]     Train net output #1: loss = 0.532886 (* 1 = 0.532886 loss)
I1004 21:30:00.493154  3812 sgd_solver.cpp:105] Iteration 12000, lr = 0.0001
I1004 21:30:02.797660  3812 solver.cpp:218] Iteration 12100 (43.4882 iter/s, 2.29948s/100 iters), loss = 0.471646
I1004 21:30:02.797660  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:30:02.797660  3812 solver.cpp:237]     Train net output #1: loss = 0.471646 (* 1 = 0.471646 loss)
I1004 21:30:02.797660  3812 sgd_solver.cpp:105] Iteration 12100, lr = 0.0001
I1004 21:30:05.057067  3812 solver.cpp:218] Iteration 12200 (44.2633 iter/s, 2.25921s/100 iters), loss = 0.556193
I1004 21:30:05.057067  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:30:05.057067  3812 solver.cpp:237]     Train net output #1: loss = 0.556193 (* 1 = 0.556193 loss)
I1004 21:30:05.057067  3812 sgd_solver.cpp:105] Iteration 12200, lr = 0.0001
I1004 21:30:07.324226  3812 solver.cpp:218] Iteration 12300 (44.1179 iter/s, 2.26665s/100 iters), loss = 0.541233
I1004 21:30:07.324226  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:30:07.324226  3812 solver.cpp:237]     Train net output #1: loss = 0.541233 (* 1 = 0.541233 loss)
I1004 21:30:07.324226  3812 sgd_solver.cpp:105] Iteration 12300, lr = 0.0001
I1004 21:30:09.572382  3812 solver.cpp:218] Iteration 12400 (44.22 iter/s, 2.26142s/100 iters), loss = 0.402378
I1004 21:30:09.572382  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:30:09.572382  3812 solver.cpp:237]     Train net output #1: loss = 0.402378 (* 1 = 0.402378 loss)
I1004 21:30:09.572382  3812 sgd_solver.cpp:105] Iteration 12400, lr = 0.0001
I1004 21:30:11.737200 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:30:11.846576  3812 solver.cpp:218] Iteration 12500 (44.1029 iter/s, 2.26742s/100 iters), loss = 0.531202
I1004 21:30:11.846576  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:30:11.846576  3812 solver.cpp:237]     Train net output #1: loss = 0.531202 (* 1 = 0.531202 loss)
I1004 21:30:11.846576  3812 sgd_solver.cpp:105] Iteration 12500, lr = 0.0001
I1004 21:30:14.103427  3812 solver.cpp:218] Iteration 12600 (44.3982 iter/s, 2.25234s/100 iters), loss = 0.509408
I1004 21:30:14.103427  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:30:14.103427  3812 solver.cpp:237]     Train net output #1: loss = 0.509408 (* 1 = 0.509408 loss)
I1004 21:30:14.103427  3812 sgd_solver.cpp:105] Iteration 12600, lr = 0.0001
I1004 21:30:16.364011  3812 solver.cpp:218] Iteration 12700 (44.1555 iter/s, 2.26472s/100 iters), loss = 0.512661
I1004 21:30:16.364011  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:30:16.364011  3812 solver.cpp:237]     Train net output #1: loss = 0.512661 (* 1 = 0.512661 loss)
I1004 21:30:16.364011  3812 sgd_solver.cpp:105] Iteration 12700, lr = 0.0001
I1004 21:30:18.634852  3812 solver.cpp:218] Iteration 12800 (44.0516 iter/s, 2.27007s/100 iters), loss = 0.506016
I1004 21:30:18.634852  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:30:18.634852  3812 solver.cpp:237]     Train net output #1: loss = 0.506016 (* 1 = 0.506016 loss)
I1004 21:30:18.634852  3812 sgd_solver.cpp:105] Iteration 12800, lr = 0.0001
I1004 21:30:20.915038  3812 solver.cpp:218] Iteration 12900 (43.9955 iter/s, 2.27296s/100 iters), loss = 0.390188
I1004 21:30:20.915038  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:30:20.915038  3812 solver.cpp:237]     Train net output #1: loss = 0.390188 (* 1 = 0.390188 loss)
I1004 21:30:20.915038  3812 sgd_solver.cpp:105] Iteration 12900, lr = 0.0001
I1004 21:30:23.085144 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:30:23.177145  3812 solver.cpp:330] Iteration 13000, Testing net (#0)
I1004 21:30:23.177145  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:30:23.610122 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:30:23.627120  3812 solver.cpp:397]     Test net output #0: accuracy = 0.768
I1004 21:30:23.627120  3812 solver.cpp:397]     Test net output #1: loss = 0.678259 (* 1 = 0.678259 loss)
I1004 21:30:23.647120  3812 solver.cpp:218] Iteration 13000 (36.6007 iter/s, 2.73219s/100 iters), loss = 0.54065
I1004 21:30:23.647120  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:30:23.647120  3812 solver.cpp:237]     Train net output #1: loss = 0.54065 (* 1 = 0.54065 loss)
I1004 21:30:23.647120  3812 sgd_solver.cpp:105] Iteration 13000, lr = 0.0001
I1004 21:30:25.948406  3812 solver.cpp:218] Iteration 13100 (43.4724 iter/s, 2.30031s/100 iters), loss = 0.516103
I1004 21:30:25.948406  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:30:25.948406  3812 solver.cpp:237]     Train net output #1: loss = 0.516103 (* 1 = 0.516103 loss)
I1004 21:30:25.948406  3812 sgd_solver.cpp:105] Iteration 13100, lr = 0.0001
I1004 21:30:28.233211  3812 solver.cpp:218] Iteration 13200 (43.7253 iter/s, 2.28701s/100 iters), loss = 0.487688
I1004 21:30:28.233211  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:30:28.233211  3812 solver.cpp:237]     Train net output #1: loss = 0.487688 (* 1 = 0.487688 loss)
I1004 21:30:28.233211  3812 sgd_solver.cpp:105] Iteration 13200, lr = 0.0001
I1004 21:30:30.498214  3812 solver.cpp:218] Iteration 13300 (44.203 iter/s, 2.26229s/100 iters), loss = 0.553967
I1004 21:30:30.498214  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:30:30.498214  3812 solver.cpp:237]     Train net output #1: loss = 0.553967 (* 1 = 0.553967 loss)
I1004 21:30:30.498214  3812 sgd_solver.cpp:105] Iteration 13300, lr = 0.0001
I1004 21:30:32.758908  3812 solver.cpp:218] Iteration 13400 (44.1491 iter/s, 2.26505s/100 iters), loss = 0.499365
I1004 21:30:32.758908  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:30:32.758908  3812 solver.cpp:237]     Train net output #1: loss = 0.499365 (* 1 = 0.499365 loss)
I1004 21:30:32.758908  3812 sgd_solver.cpp:105] Iteration 13400, lr = 0.0001
I1004 21:30:34.918305 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:30:35.028221  3812 solver.cpp:218] Iteration 13500 (44.1625 iter/s, 2.26436s/100 iters), loss = 0.513043
I1004 21:30:35.028221  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:30:35.028221  3812 solver.cpp:237]     Train net output #1: loss = 0.513043 (* 1 = 0.513043 loss)
I1004 21:30:35.028221  3812 sgd_solver.cpp:105] Iteration 13500, lr = 0.0001
I1004 21:30:37.293655  3812 solver.cpp:218] Iteration 13600 (44.1405 iter/s, 2.26549s/100 iters), loss = 0.531295
I1004 21:30:37.293655  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:30:37.293655  3812 solver.cpp:237]     Train net output #1: loss = 0.531295 (* 1 = 0.531295 loss)
I1004 21:30:37.293655  3812 sgd_solver.cpp:105] Iteration 13600, lr = 0.0001
I1004 21:30:39.557607  3812 solver.cpp:218] Iteration 13700 (44.1474 iter/s, 2.26514s/100 iters), loss = 0.496113
I1004 21:30:39.557607  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:30:39.557607  3812 solver.cpp:237]     Train net output #1: loss = 0.496113 (* 1 = 0.496113 loss)
I1004 21:30:39.557607  3812 sgd_solver.cpp:105] Iteration 13700, lr = 0.0001
I1004 21:30:41.824928  3812 solver.cpp:218] Iteration 13800 (44.1511 iter/s, 2.26495s/100 iters), loss = 0.50486
I1004 21:30:41.824928  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:30:41.824928  3812 solver.cpp:237]     Train net output #1: loss = 0.50486 (* 1 = 0.50486 loss)
I1004 21:30:41.824928  3812 sgd_solver.cpp:105] Iteration 13800, lr = 0.0001
I1004 21:30:44.081269  3812 solver.cpp:218] Iteration 13900 (44.2421 iter/s, 2.26029s/100 iters), loss = 0.494719
I1004 21:30:44.081269  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:30:44.081269  3812 solver.cpp:237]     Train net output #1: loss = 0.494719 (* 1 = 0.494719 loss)
I1004 21:30:44.081269  3812 sgd_solver.cpp:105] Iteration 13900, lr = 0.0001
I1004 21:30:46.232460 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:30:46.328336  3812 solver.cpp:330] Iteration 14000, Testing net (#0)
I1004 21:30:46.328336  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:30:46.746842 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:30:46.762468  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7666
I1004 21:30:46.762468  3812 solver.cpp:397]     Test net output #1: loss = 0.678112 (* 1 = 0.678112 loss)
I1004 21:30:46.778111  3812 solver.cpp:218] Iteration 14000 (36.9473 iter/s, 2.70656s/100 iters), loss = 0.495782
I1004 21:30:46.778111  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:30:46.778111  3812 solver.cpp:237]     Train net output #1: loss = 0.495782 (* 1 = 0.495782 loss)
I1004 21:30:46.778111  3812 sgd_solver.cpp:105] Iteration 14000, lr = 0.0001
I1004 21:30:49.041349  3812 solver.cpp:218] Iteration 14100 (44.2124 iter/s, 2.26181s/100 iters), loss = 0.496168
I1004 21:30:49.041349  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:30:49.041349  3812 solver.cpp:237]     Train net output #1: loss = 0.496168 (* 1 = 0.496168 loss)
I1004 21:30:49.041349  3812 sgd_solver.cpp:105] Iteration 14100, lr = 0.0001
I1004 21:30:51.309178  3812 solver.cpp:218] Iteration 14200 (44.2755 iter/s, 2.25858s/100 iters), loss = 0.492396
I1004 21:30:51.309178  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:30:51.309178  3812 solver.cpp:237]     Train net output #1: loss = 0.492396 (* 1 = 0.492396 loss)
I1004 21:30:51.309178  3812 sgd_solver.cpp:105] Iteration 14200, lr = 0.0001
I1004 21:30:53.572742  3812 solver.cpp:218] Iteration 14300 (44.1971 iter/s, 2.26259s/100 iters), loss = 0.556058
I1004 21:30:53.572742  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:30:53.572742  3812 solver.cpp:237]     Train net output #1: loss = 0.556058 (* 1 = 0.556058 loss)
I1004 21:30:53.572742  3812 sgd_solver.cpp:105] Iteration 14300, lr = 0.0001
I1004 21:30:55.835202  3812 solver.cpp:218] Iteration 14400 (44.2764 iter/s, 2.25854s/100 iters), loss = 0.387719
I1004 21:30:55.835202  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:30:55.835202  3812 solver.cpp:237]     Train net output #1: loss = 0.387719 (* 1 = 0.387719 loss)
I1004 21:30:55.835202  3812 sgd_solver.cpp:105] Iteration 14400, lr = 0.0001
I1004 21:30:57.990257 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:30:58.101256  3812 solver.cpp:218] Iteration 14500 (44.1263 iter/s, 2.26622s/100 iters), loss = 0.511857
I1004 21:30:58.101256  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:30:58.101256  3812 solver.cpp:237]     Train net output #1: loss = 0.511857 (* 1 = 0.511857 loss)
I1004 21:30:58.101256  3812 sgd_solver.cpp:105] Iteration 14500, lr = 0.0001
I1004 21:31:00.355278  3812 solver.cpp:218] Iteration 14600 (44.1886 iter/s, 2.26303s/100 iters), loss = 0.50456
I1004 21:31:00.355278  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:31:00.355278  3812 solver.cpp:237]     Train net output #1: loss = 0.50456 (* 1 = 0.50456 loss)
I1004 21:31:00.355278  3812 sgd_solver.cpp:105] Iteration 14600, lr = 0.0001
I1004 21:31:02.647249  3812 solver.cpp:218] Iteration 14700 (43.8178 iter/s, 2.28218s/100 iters), loss = 0.565567
I1004 21:31:02.647249  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:31:02.647249  3812 solver.cpp:237]     Train net output #1: loss = 0.565567 (* 1 = 0.565567 loss)
I1004 21:31:02.647249  3812 sgd_solver.cpp:105] Iteration 14700, lr = 0.0001
I1004 21:31:04.921916  3812 solver.cpp:218] Iteration 14800 (43.9745 iter/s, 2.27404s/100 iters), loss = 0.485388
I1004 21:31:04.921916  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:31:04.921916  3812 solver.cpp:237]     Train net output #1: loss = 0.485388 (* 1 = 0.485388 loss)
I1004 21:31:04.921916  3812 sgd_solver.cpp:105] Iteration 14800, lr = 0.0001
I1004 21:31:07.187072  3812 solver.cpp:218] Iteration 14900 (44.1438 iter/s, 2.26532s/100 iters), loss = 0.467889
I1004 21:31:07.187072  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:31:07.187072  3812 solver.cpp:237]     Train net output #1: loss = 0.467889 (* 1 = 0.467889 loss)
I1004 21:31:07.187072  3812 sgd_solver.cpp:105] Iteration 14900, lr = 0.0001
I1004 21:31:09.334653 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:31:09.431047  3812 solver.cpp:330] Iteration 15000, Testing net (#0)
I1004 21:31:09.431047  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:31:09.859068 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:31:09.876463  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7676
I1004 21:31:09.876463  3812 solver.cpp:397]     Test net output #1: loss = 0.677532 (* 1 = 0.677532 loss)
I1004 21:31:09.897460  3812 solver.cpp:218] Iteration 15000 (36.9046 iter/s, 2.70969s/100 iters), loss = 0.483084
I1004 21:31:09.897460  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:31:09.897460  3812 solver.cpp:237]     Train net output #1: loss = 0.483084 (* 1 = 0.483084 loss)
I1004 21:31:09.897460  3812 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I1004 21:31:09.897460  3812 sgd_solver.cpp:105] Iteration 15000, lr = 1e-05
I1004 21:31:12.152047  3812 solver.cpp:218] Iteration 15100 (44.3547 iter/s, 2.25455s/100 iters), loss = 0.514467
I1004 21:31:12.152047  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:31:12.152047  3812 solver.cpp:237]     Train net output #1: loss = 0.514467 (* 1 = 0.514467 loss)
I1004 21:31:12.152047  3812 sgd_solver.cpp:105] Iteration 15100, lr = 1e-05
I1004 21:31:14.400303  3812 solver.cpp:218] Iteration 15200 (44.2858 iter/s, 2.25806s/100 iters), loss = 0.569615
I1004 21:31:14.400303  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:31:14.400303  3812 solver.cpp:237]     Train net output #1: loss = 0.569615 (* 1 = 0.569615 loss)
I1004 21:31:14.400303  3812 sgd_solver.cpp:105] Iteration 15200, lr = 1e-05
I1004 21:31:16.662906  3812 solver.cpp:218] Iteration 15300 (44.3101 iter/s, 2.25682s/100 iters), loss = 0.591474
I1004 21:31:16.662906  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:31:16.662906  3812 solver.cpp:237]     Train net output #1: loss = 0.591474 (* 1 = 0.591474 loss)
I1004 21:31:16.662906  3812 sgd_solver.cpp:105] Iteration 15300, lr = 1e-05
I1004 21:31:18.932379  3812 solver.cpp:218] Iteration 15400 (44.0858 iter/s, 2.2683s/100 iters), loss = 0.441724
I1004 21:31:18.932379  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:31:18.932379  3812 solver.cpp:237]     Train net output #1: loss = 0.441724 (* 1 = 0.441724 loss)
I1004 21:31:18.932379  3812 sgd_solver.cpp:105] Iteration 15400, lr = 1e-05
I1004 21:31:21.083184 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:31:21.192561  3812 solver.cpp:218] Iteration 15500 (44.0505 iter/s, 2.27012s/100 iters), loss = 0.564222
I1004 21:31:21.192561  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:31:21.192561  3812 solver.cpp:237]     Train net output #1: loss = 0.564222 (* 1 = 0.564222 loss)
I1004 21:31:21.192561  3812 sgd_solver.cpp:105] Iteration 15500, lr = 1e-05
I1004 21:31:23.495410  3812 solver.cpp:218] Iteration 15600 (43.6392 iter/s, 2.29152s/100 iters), loss = 0.527118
I1004 21:31:23.495410  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:31:23.495410  3812 solver.cpp:237]     Train net output #1: loss = 0.527118 (* 1 = 0.527118 loss)
I1004 21:31:23.495410  3812 sgd_solver.cpp:105] Iteration 15600, lr = 1e-05
I1004 21:31:25.750023  3812 solver.cpp:218] Iteration 15700 (44.3226 iter/s, 2.25619s/100 iters), loss = 0.579024
I1004 21:31:25.750023  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:31:25.750023  3812 solver.cpp:237]     Train net output #1: loss = 0.579024 (* 1 = 0.579024 loss)
I1004 21:31:25.750023  3812 sgd_solver.cpp:105] Iteration 15700, lr = 1e-05
I1004 21:31:28.010143  3812 solver.cpp:218] Iteration 15800 (44.312 iter/s, 2.25673s/100 iters), loss = 0.531395
I1004 21:31:28.010143  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:31:28.010143  3812 solver.cpp:237]     Train net output #1: loss = 0.531395 (* 1 = 0.531395 loss)
I1004 21:31:28.010143  3812 sgd_solver.cpp:105] Iteration 15800, lr = 1e-05
I1004 21:31:30.268177  3812 solver.cpp:218] Iteration 15900 (44.2391 iter/s, 2.26045s/100 iters), loss = 0.38881
I1004 21:31:30.268177  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:31:30.268177  3812 solver.cpp:237]     Train net output #1: loss = 0.38881 (* 1 = 0.38881 loss)
I1004 21:31:30.268177  3812 sgd_solver.cpp:105] Iteration 15900, lr = 1e-05
I1004 21:31:32.426407 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:31:32.516960  3812 solver.cpp:330] Iteration 16000, Testing net (#0)
I1004 21:31:32.516960  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:31:32.938239 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:31:32.963126  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7662
I1004 21:31:32.963126  3812 solver.cpp:397]     Test net output #1: loss = 0.677652 (* 1 = 0.677652 loss)
I1004 21:31:32.978752  3812 solver.cpp:218] Iteration 16000 (36.8306 iter/s, 2.71513s/100 iters), loss = 0.541066
I1004 21:31:32.978752  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:31:32.978752  3812 solver.cpp:237]     Train net output #1: loss = 0.541066 (* 1 = 0.541066 loss)
I1004 21:31:32.978752  3812 sgd_solver.cpp:105] Iteration 16000, lr = 1e-05
I1004 21:31:35.282917  3812 solver.cpp:218] Iteration 16100 (43.5825 iter/s, 2.2945s/100 iters), loss = 0.489595
I1004 21:31:35.282917  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:31:35.282917  3812 solver.cpp:237]     Train net output #1: loss = 0.489595 (* 1 = 0.489595 loss)
I1004 21:31:35.282917  3812 sgd_solver.cpp:105] Iteration 16100, lr = 1e-05
I1004 21:31:37.542217  3812 solver.cpp:218] Iteration 16200 (43.9902 iter/s, 2.27324s/100 iters), loss = 0.541487
I1004 21:31:37.542217  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:31:37.542217  3812 solver.cpp:237]     Train net output #1: loss = 0.541487 (* 1 = 0.541487 loss)
I1004 21:31:37.542217  3812 sgd_solver.cpp:105] Iteration 16200, lr = 1e-05
I1004 21:31:39.807883  3812 solver.cpp:218] Iteration 16300 (44.1889 iter/s, 2.26301s/100 iters), loss = 0.535518
I1004 21:31:39.807883  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:31:39.807883  3812 solver.cpp:237]     Train net output #1: loss = 0.535518 (* 1 = 0.535518 loss)
I1004 21:31:39.807883  3812 sgd_solver.cpp:105] Iteration 16300, lr = 1e-05
I1004 21:31:42.066964  3812 solver.cpp:218] Iteration 16400 (44.2437 iter/s, 2.26021s/100 iters), loss = 0.436635
I1004 21:31:42.066964  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:31:42.066964  3812 solver.cpp:237]     Train net output #1: loss = 0.436635 (* 1 = 0.436635 loss)
I1004 21:31:42.066964  3812 sgd_solver.cpp:105] Iteration 16400, lr = 1e-05
I1004 21:31:44.222869 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:31:44.338254  3812 solver.cpp:218] Iteration 16500 (44.2806 iter/s, 2.25833s/100 iters), loss = 0.524015
I1004 21:31:44.338254  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:31:44.338254  3812 solver.cpp:237]     Train net output #1: loss = 0.524015 (* 1 = 0.524015 loss)
I1004 21:31:44.338254  3812 sgd_solver.cpp:105] Iteration 16500, lr = 1e-05
I1004 21:31:46.588058  3812 solver.cpp:218] Iteration 16600 (44.3462 iter/s, 2.25499s/100 iters), loss = 0.495227
I1004 21:31:46.588058  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:31:46.588058  3812 solver.cpp:237]     Train net output #1: loss = 0.495227 (* 1 = 0.495227 loss)
I1004 21:31:46.588058  3812 sgd_solver.cpp:105] Iteration 16600, lr = 1e-05
I1004 21:31:48.858302  3812 solver.cpp:218] Iteration 16700 (44.1886 iter/s, 2.26302s/100 iters), loss = 0.484744
I1004 21:31:48.858302  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:31:48.858302  3812 solver.cpp:237]     Train net output #1: loss = 0.484744 (* 1 = 0.484744 loss)
I1004 21:31:48.858302  3812 sgd_solver.cpp:105] Iteration 16700, lr = 1e-05
I1004 21:31:51.128785  3812 solver.cpp:218] Iteration 16800 (43.7665 iter/s, 2.28485s/100 iters), loss = 0.516374
I1004 21:31:51.128785  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:31:51.128785  3812 solver.cpp:237]     Train net output #1: loss = 0.516374 (* 1 = 0.516374 loss)
I1004 21:31:51.128785  3812 sgd_solver.cpp:105] Iteration 16800, lr = 1e-05
I1004 21:31:53.413166  3812 solver.cpp:218] Iteration 16900 (44.0575 iter/s, 2.26976s/100 iters), loss = 0.378742
I1004 21:31:53.413166  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:31:53.413166  3812 solver.cpp:237]     Train net output #1: loss = 0.378742 (* 1 = 0.378742 loss)
I1004 21:31:53.413166  3812 sgd_solver.cpp:105] Iteration 16900, lr = 1e-05
I1004 21:31:55.578701 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:31:55.669703  3812 solver.cpp:330] Iteration 17000, Testing net (#0)
I1004 21:31:55.669703  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:31:56.102589 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:31:56.120579  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7665
I1004 21:31:56.120579  3812 solver.cpp:397]     Test net output #1: loss = 0.677713 (* 1 = 0.677713 loss)
I1004 21:31:56.135748  3812 solver.cpp:218] Iteration 17000 (36.6701 iter/s, 2.72702s/100 iters), loss = 0.543692
I1004 21:31:56.135748  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:31:56.135748  3812 solver.cpp:237]     Train net output #1: loss = 0.543692 (* 1 = 0.543692 loss)
I1004 21:31:56.135748  3812 sgd_solver.cpp:105] Iteration 17000, lr = 1e-05
I1004 21:31:58.428797  3812 solver.cpp:218] Iteration 17100 (43.708 iter/s, 2.28791s/100 iters), loss = 0.458422
I1004 21:31:58.428797  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:31:58.428797  3812 solver.cpp:237]     Train net output #1: loss = 0.458422 (* 1 = 0.458422 loss)
I1004 21:31:58.428797  3812 sgd_solver.cpp:105] Iteration 17100, lr = 1e-05
I1004 21:32:00.701915  3812 solver.cpp:218] Iteration 17200 (43.998 iter/s, 2.27283s/100 iters), loss = 0.533973
I1004 21:32:00.701915  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:32:00.701915  3812 solver.cpp:237]     Train net output #1: loss = 0.533973 (* 1 = 0.533973 loss)
I1004 21:32:00.701915  3812 sgd_solver.cpp:105] Iteration 17200, lr = 1e-05
I1004 21:32:02.961315  3812 solver.cpp:218] Iteration 17300 (44.0545 iter/s, 2.26992s/100 iters), loss = 0.518844
I1004 21:32:02.961315  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:32:02.961315  3812 solver.cpp:237]     Train net output #1: loss = 0.518844 (* 1 = 0.518844 loss)
I1004 21:32:02.961315  3812 sgd_solver.cpp:105] Iteration 17300, lr = 1e-05
I1004 21:32:05.257237  3812 solver.cpp:218] Iteration 17400 (43.6877 iter/s, 2.28897s/100 iters), loss = 0.398396
I1004 21:32:05.257237  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:32:05.257237  3812 solver.cpp:237]     Train net output #1: loss = 0.398396 (* 1 = 0.398396 loss)
I1004 21:32:05.257237  3812 sgd_solver.cpp:105] Iteration 17400, lr = 1e-05
I1004 21:32:07.410712 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:32:07.511389  3812 solver.cpp:218] Iteration 17500 (44.2444 iter/s, 2.26017s/100 iters), loss = 0.522328
I1004 21:32:07.511389  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:32:07.511389  3812 solver.cpp:237]     Train net output #1: loss = 0.522328 (* 1 = 0.522328 loss)
I1004 21:32:07.511389  3812 sgd_solver.cpp:105] Iteration 17500, lr = 1e-05
I1004 21:32:09.779777  3812 solver.cpp:218] Iteration 17600 (44.295 iter/s, 2.25759s/100 iters), loss = 0.506783
I1004 21:32:09.779777  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:32:09.779777  3812 solver.cpp:237]     Train net output #1: loss = 0.506783 (* 1 = 0.506783 loss)
I1004 21:32:09.779777  3812 sgd_solver.cpp:105] Iteration 17600, lr = 1e-05
I1004 21:32:12.027107  3812 solver.cpp:218] Iteration 17700 (44.2965 iter/s, 2.25751s/100 iters), loss = 0.504693
I1004 21:32:12.027107  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:32:12.027107  3812 solver.cpp:237]     Train net output #1: loss = 0.504693 (* 1 = 0.504693 loss)
I1004 21:32:12.027107  3812 sgd_solver.cpp:105] Iteration 17700, lr = 1e-05
I1004 21:32:14.299630  3812 solver.cpp:218] Iteration 17800 (44.0859 iter/s, 2.2683s/100 iters), loss = 0.522132
I1004 21:32:14.299630  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:32:14.299630  3812 solver.cpp:237]     Train net output #1: loss = 0.522132 (* 1 = 0.522132 loss)
I1004 21:32:14.299630  3812 sgd_solver.cpp:105] Iteration 17800, lr = 1e-05
I1004 21:32:16.567679  3812 solver.cpp:218] Iteration 17900 (43.9554 iter/s, 2.27503s/100 iters), loss = 0.416487
I1004 21:32:16.567679  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:32:16.567679  3812 solver.cpp:237]     Train net output #1: loss = 0.416487 (* 1 = 0.416487 loss)
I1004 21:32:16.567679  3812 sgd_solver.cpp:105] Iteration 17900, lr = 1e-05
I1004 21:32:18.754156 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:32:18.831897  3812 solver.cpp:330] Iteration 18000, Testing net (#0)
I1004 21:32:18.831897  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:32:19.275928 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:32:19.291554  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7672
I1004 21:32:19.291554  3812 solver.cpp:397]     Test net output #1: loss = 0.677496 (* 1 = 0.677496 loss)
I1004 21:32:19.307179  3812 solver.cpp:218] Iteration 18000 (36.5975 iter/s, 2.73243s/100 iters), loss = 0.55248
I1004 21:32:19.307179  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:32:19.307179  3812 solver.cpp:237]     Train net output #1: loss = 0.55248 (* 1 = 0.55248 loss)
I1004 21:32:19.307179  3812 sgd_solver.cpp:105] Iteration 18000, lr = 1e-05
I1004 21:32:21.590718  3812 solver.cpp:218] Iteration 18100 (43.9437 iter/s, 2.27564s/100 iters), loss = 0.486112
I1004 21:32:21.590718  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:32:21.590718  3812 solver.cpp:237]     Train net output #1: loss = 0.486112 (* 1 = 0.486112 loss)
I1004 21:32:21.590718  3812 sgd_solver.cpp:105] Iteration 18100, lr = 1e-05
I1004 21:32:23.870277  3812 solver.cpp:218] Iteration 18200 (43.8705 iter/s, 2.27943s/100 iters), loss = 0.501005
I1004 21:32:23.870277  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:32:23.870277  3812 solver.cpp:237]     Train net output #1: loss = 0.501005 (* 1 = 0.501005 loss)
I1004 21:32:23.870277  3812 sgd_solver.cpp:105] Iteration 18200, lr = 1e-05
I1004 21:32:26.145174  3812 solver.cpp:218] Iteration 18300 (43.8953 iter/s, 2.27815s/100 iters), loss = 0.513968
I1004 21:32:26.145174  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:32:26.145174  3812 solver.cpp:237]     Train net output #1: loss = 0.513968 (* 1 = 0.513968 loss)
I1004 21:32:26.145174  3812 sgd_solver.cpp:105] Iteration 18300, lr = 1e-05
I1004 21:32:28.401469  3812 solver.cpp:218] Iteration 18400 (44.1581 iter/s, 2.26459s/100 iters), loss = 0.416186
I1004 21:32:28.401469  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:32:28.401469  3812 solver.cpp:237]     Train net output #1: loss = 0.416186 (* 1 = 0.416186 loss)
I1004 21:32:28.401469  3812 sgd_solver.cpp:105] Iteration 18400, lr = 1e-05
I1004 21:32:30.572484 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:32:30.686276  3812 solver.cpp:218] Iteration 18500 (43.8916 iter/s, 2.27834s/100 iters), loss = 0.557735
I1004 21:32:30.686276  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:32:30.686276  3812 solver.cpp:237]     Train net output #1: loss = 0.557735 (* 1 = 0.557735 loss)
I1004 21:32:30.686276  3812 sgd_solver.cpp:105] Iteration 18500, lr = 1e-05
I1004 21:32:32.948071  3812 solver.cpp:218] Iteration 18600 (44.0752 iter/s, 2.26885s/100 iters), loss = 0.534933
I1004 21:32:32.948071  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:32:32.948071  3812 solver.cpp:237]     Train net output #1: loss = 0.534933 (* 1 = 0.534933 loss)
I1004 21:32:32.948071  3812 sgd_solver.cpp:105] Iteration 18600, lr = 1e-05
I1004 21:32:35.217667  3812 solver.cpp:218] Iteration 18700 (44.1584 iter/s, 2.26458s/100 iters), loss = 0.502951
I1004 21:32:35.217667  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:32:35.217667  3812 solver.cpp:237]     Train net output #1: loss = 0.502951 (* 1 = 0.502951 loss)
I1004 21:32:35.217667  3812 sgd_solver.cpp:105] Iteration 18700, lr = 1e-05
I1004 21:32:37.478945  3812 solver.cpp:218] Iteration 18800 (44.2279 iter/s, 2.26101s/100 iters), loss = 0.50721
I1004 21:32:37.478945  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:32:37.478945  3812 solver.cpp:237]     Train net output #1: loss = 0.50721 (* 1 = 0.50721 loss)
I1004 21:32:37.478945  3812 sgd_solver.cpp:105] Iteration 18800, lr = 1e-05
I1004 21:32:39.741789  3812 solver.cpp:218] Iteration 18900 (44.2478 iter/s, 2.26s/100 iters), loss = 0.475853
I1004 21:32:39.741789  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:32:39.741789  3812 solver.cpp:237]     Train net output #1: loss = 0.475853 (* 1 = 0.475853 loss)
I1004 21:32:39.741789  3812 sgd_solver.cpp:105] Iteration 18900, lr = 1e-05
I1004 21:32:41.897114 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:32:41.994500  3812 solver.cpp:330] Iteration 19000, Testing net (#0)
I1004 21:32:41.994500  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:32:42.430757 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:32:42.447510  3812 solver.cpp:397]     Test net output #0: accuracy = 0.767
I1004 21:32:42.447510  3812 solver.cpp:397]     Test net output #1: loss = 0.677418 (* 1 = 0.677418 loss)
I1004 21:32:42.463135  3812 solver.cpp:218] Iteration 19000 (36.767 iter/s, 2.71983s/100 iters), loss = 0.594612
I1004 21:32:42.463135  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:32:42.463135  3812 solver.cpp:237]     Train net output #1: loss = 0.594612 (* 1 = 0.594612 loss)
I1004 21:32:42.463135  3812 sgd_solver.cpp:105] Iteration 19000, lr = 1e-05
I1004 21:32:44.735327  3812 solver.cpp:218] Iteration 19100 (44.1193 iter/s, 2.26658s/100 iters), loss = 0.489888
I1004 21:32:44.735327  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:32:44.735327  3812 solver.cpp:237]     Train net output #1: loss = 0.489888 (* 1 = 0.489888 loss)
I1004 21:32:44.735327  3812 sgd_solver.cpp:105] Iteration 19100, lr = 1e-05
I1004 21:32:46.993779  3812 solver.cpp:218] Iteration 19200 (44.2718 iter/s, 2.25878s/100 iters), loss = 0.516466
I1004 21:32:46.993779  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:32:46.993779  3812 solver.cpp:237]     Train net output #1: loss = 0.516466 (* 1 = 0.516466 loss)
I1004 21:32:46.993779  3812 sgd_solver.cpp:105] Iteration 19200, lr = 1e-05
I1004 21:32:49.274229  3812 solver.cpp:218] Iteration 19300 (43.8681 iter/s, 2.27956s/100 iters), loss = 0.573145
I1004 21:32:49.274229  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:32:49.274229  3812 solver.cpp:237]     Train net output #1: loss = 0.573145 (* 1 = 0.573145 loss)
I1004 21:32:49.274229  3812 sgd_solver.cpp:105] Iteration 19300, lr = 1e-05
I1004 21:32:51.557591  3812 solver.cpp:218] Iteration 19400 (43.7898 iter/s, 2.28364s/100 iters), loss = 0.49437
I1004 21:32:51.558593  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:32:51.558593  3812 solver.cpp:237]     Train net output #1: loss = 0.49437 (* 1 = 0.49437 loss)
I1004 21:32:51.558593  3812 sgd_solver.cpp:105] Iteration 19400, lr = 1e-05
I1004 21:32:53.749449 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:32:53.860450  3812 solver.cpp:218] Iteration 19500 (43.438 iter/s, 2.30213s/100 iters), loss = 0.570125
I1004 21:32:53.860450  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:32:53.860450  3812 solver.cpp:237]     Train net output #1: loss = 0.570125 (* 1 = 0.570125 loss)
I1004 21:32:53.860450  3812 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I1004 21:32:56.158327  3812 solver.cpp:218] Iteration 19600 (43.5262 iter/s, 2.29747s/100 iters), loss = 0.502172
I1004 21:32:56.158327  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:32:56.158327  3812 solver.cpp:237]     Train net output #1: loss = 0.502172 (* 1 = 0.502172 loss)
I1004 21:32:56.158327  3812 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I1004 21:32:58.420306  3812 solver.cpp:218] Iteration 19700 (44.2246 iter/s, 2.26118s/100 iters), loss = 0.535283
I1004 21:32:58.420306  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:32:58.420306  3812 solver.cpp:237]     Train net output #1: loss = 0.535283 (* 1 = 0.535283 loss)
I1004 21:32:58.420306  3812 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I1004 21:33:00.667371  3812 solver.cpp:218] Iteration 19800 (44.2818 iter/s, 2.25827s/100 iters), loss = 0.494541
I1004 21:33:00.667371  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:33:00.667371  3812 solver.cpp:237]     Train net output #1: loss = 0.494541 (* 1 = 0.494541 loss)
I1004 21:33:00.667371  3812 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I1004 21:33:02.931978  3812 solver.cpp:218] Iteration 19900 (44.2734 iter/s, 2.25869s/100 iters), loss = 0.47871
I1004 21:33:02.931978  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:33:02.931978  3812 solver.cpp:237]     Train net output #1: loss = 0.47871 (* 1 = 0.47871 loss)
I1004 21:33:02.931978  3812 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I1004 21:33:05.082892 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:33:05.161018  3812 solver.cpp:330] Iteration 20000, Testing net (#0)
I1004 21:33:05.161018  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:33:05.605387 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:33:05.621011  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7671
I1004 21:33:05.621011  3812 solver.cpp:397]     Test net output #1: loss = 0.677614 (* 1 = 0.677614 loss)
I1004 21:33:05.636636  3812 solver.cpp:218] Iteration 20000 (36.9112 iter/s, 2.70921s/100 iters), loss = 0.535631
I1004 21:33:05.636636  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:33:05.636636  3812 solver.cpp:237]     Train net output #1: loss = 0.535631 (* 1 = 0.535631 loss)
I1004 21:33:05.636636  3812 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I1004 21:33:07.895820  3812 solver.cpp:218] Iteration 20100 (44.2181 iter/s, 2.26152s/100 iters), loss = 0.462173
I1004 21:33:07.895820  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:33:07.895820  3812 solver.cpp:237]     Train net output #1: loss = 0.462173 (* 1 = 0.462173 loss)
I1004 21:33:07.895820  3812 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I1004 21:33:10.160290  3812 solver.cpp:218] Iteration 20200 (44.2075 iter/s, 2.26206s/100 iters), loss = 0.484168
I1004 21:33:10.160290  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:33:10.160290  3812 solver.cpp:237]     Train net output #1: loss = 0.484168 (* 1 = 0.484168 loss)
I1004 21:33:10.160290  3812 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I1004 21:33:12.428833  3812 solver.cpp:218] Iteration 20300 (44.2995 iter/s, 2.25736s/100 iters), loss = 0.521474
I1004 21:33:12.428833  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:33:12.428833  3812 solver.cpp:237]     Train net output #1: loss = 0.521474 (* 1 = 0.521474 loss)
I1004 21:33:12.428833  3812 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I1004 21:33:14.683015  3812 solver.cpp:218] Iteration 20400 (44.1322 iter/s, 2.26592s/100 iters), loss = 0.418375
I1004 21:33:14.683015  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:33:14.683015  3812 solver.cpp:237]     Train net output #1: loss = 0.418375 (* 1 = 0.418375 loss)
I1004 21:33:14.683015  3812 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I1004 21:33:16.833670 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:33:16.947584  3812 solver.cpp:218] Iteration 20500 (44.3184 iter/s, 2.2564s/100 iters), loss = 0.521039
I1004 21:33:16.947584  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:33:16.947584  3812 solver.cpp:237]     Train net output #1: loss = 0.521039 (* 1 = 0.521039 loss)
I1004 21:33:16.947584  3812 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I1004 21:33:19.215515  3812 solver.cpp:218] Iteration 20600 (44.1169 iter/s, 2.26671s/100 iters), loss = 0.501934
I1004 21:33:19.215515  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:33:19.215515  3812 solver.cpp:237]     Train net output #1: loss = 0.501934 (* 1 = 0.501934 loss)
I1004 21:33:19.215515  3812 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I1004 21:33:21.494386  3812 solver.cpp:218] Iteration 20700 (43.8262 iter/s, 2.28174s/100 iters), loss = 0.510533
I1004 21:33:21.494386  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:33:21.494386  3812 solver.cpp:237]     Train net output #1: loss = 0.510533 (* 1 = 0.510533 loss)
I1004 21:33:21.494386  3812 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I1004 21:33:23.746982  3812 solver.cpp:218] Iteration 20800 (44.2621 iter/s, 2.25927s/100 iters), loss = 0.503994
I1004 21:33:23.746982  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:33:23.746982  3812 solver.cpp:237]     Train net output #1: loss = 0.503994 (* 1 = 0.503994 loss)
I1004 21:33:23.746982  3812 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I1004 21:33:26.035763  3812 solver.cpp:218] Iteration 20900 (43.9609 iter/s, 2.27475s/100 iters), loss = 0.423692
I1004 21:33:26.035763  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:33:26.035763  3812 solver.cpp:237]     Train net output #1: loss = 0.423692 (* 1 = 0.423692 loss)
I1004 21:33:26.035763  3812 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I1004 21:33:28.203470 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:33:28.296469  3812 solver.cpp:330] Iteration 21000, Testing net (#0)
I1004 21:33:28.296469  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:33:28.733544 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:33:28.751545  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7674
I1004 21:33:28.751545  3812 solver.cpp:397]     Test net output #1: loss = 0.677571 (* 1 = 0.677571 loss)
I1004 21:33:28.771544  3812 solver.cpp:218] Iteration 21000 (36.554 iter/s, 2.73568s/100 iters), loss = 0.520754
I1004 21:33:28.771544  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:33:28.771544  3812 solver.cpp:237]     Train net output #1: loss = 0.520754 (* 1 = 0.520754 loss)
I1004 21:33:28.771544  3812 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I1004 21:33:31.027127  3812 solver.cpp:218] Iteration 21100 (44.2536 iter/s, 2.2597s/100 iters), loss = 0.547548
I1004 21:33:31.027127  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 21:33:31.027127  3812 solver.cpp:237]     Train net output #1: loss = 0.547548 (* 1 = 0.547548 loss)
I1004 21:33:31.027127  3812 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I1004 21:33:33.305063  3812 solver.cpp:218] Iteration 21200 (43.9358 iter/s, 2.27605s/100 iters), loss = 0.497401
I1004 21:33:33.305063  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:33:33.305063  3812 solver.cpp:237]     Train net output #1: loss = 0.497401 (* 1 = 0.497401 loss)
I1004 21:33:33.305063  3812 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I1004 21:33:35.557031  3812 solver.cpp:218] Iteration 21300 (44.1939 iter/s, 2.26276s/100 iters), loss = 0.520592
I1004 21:33:35.557031  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:33:35.557031  3812 solver.cpp:237]     Train net output #1: loss = 0.520592 (* 1 = 0.520592 loss)
I1004 21:33:35.557031  3812 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I1004 21:33:37.835537  3812 solver.cpp:218] Iteration 21400 (44.1534 iter/s, 2.26483s/100 iters), loss = 0.482036
I1004 21:33:37.835537  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:33:37.835537  3812 solver.cpp:237]     Train net output #1: loss = 0.482036 (* 1 = 0.482036 loss)
I1004 21:33:37.835537  3812 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I1004 21:33:39.990114 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:33:40.100720  3812 solver.cpp:218] Iteration 21500 (44.1734 iter/s, 2.26381s/100 iters), loss = 0.531756
I1004 21:33:40.100720  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:33:40.100720  3812 solver.cpp:237]     Train net output #1: loss = 0.531756 (* 1 = 0.531756 loss)
I1004 21:33:40.100720  3812 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I1004 21:33:42.373560  3812 solver.cpp:218] Iteration 21600 (43.9946 iter/s, 2.27301s/100 iters), loss = 0.491159
I1004 21:33:42.373560  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:33:42.373560  3812 solver.cpp:237]     Train net output #1: loss = 0.491159 (* 1 = 0.491159 loss)
I1004 21:33:42.373560  3812 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I1004 21:33:44.626765  3812 solver.cpp:218] Iteration 21700 (44.1278 iter/s, 2.26614s/100 iters), loss = 0.499511
I1004 21:33:44.626765  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:33:44.626765  3812 solver.cpp:237]     Train net output #1: loss = 0.499511 (* 1 = 0.499511 loss)
I1004 21:33:44.626765  3812 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I1004 21:33:46.906147  3812 solver.cpp:218] Iteration 21800 (44.0773 iter/s, 2.26874s/100 iters), loss = 0.555852
I1004 21:33:46.906147  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:33:46.906147  3812 solver.cpp:237]     Train net output #1: loss = 0.555852 (* 1 = 0.555852 loss)
I1004 21:33:46.906147  3812 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I1004 21:33:49.166553  3812 solver.cpp:218] Iteration 21900 (44.1304 iter/s, 2.26601s/100 iters), loss = 0.412109
I1004 21:33:49.166553  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:33:49.166553  3812 solver.cpp:237]     Train net output #1: loss = 0.412109 (* 1 = 0.412109 loss)
I1004 21:33:49.166553  3812 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I1004 21:33:51.350775 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:33:51.441779  3812 solver.cpp:330] Iteration 22000, Testing net (#0)
I1004 21:33:51.441779  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:33:51.887776 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:33:51.904779  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7667
I1004 21:33:51.904779  3812 solver.cpp:397]     Test net output #1: loss = 0.677641 (* 1 = 0.677641 loss)
I1004 21:33:51.926774  3812 solver.cpp:218] Iteration 22000 (36.3551 iter/s, 2.75064s/100 iters), loss = 0.513341
I1004 21:33:51.926774  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:33:51.926774  3812 solver.cpp:237]     Train net output #1: loss = 0.513341 (* 1 = 0.513341 loss)
I1004 21:33:51.926774  3812 sgd_solver.cpp:105] Iteration 22000, lr = 1e-05
I1004 21:33:54.185859  3812 solver.cpp:218] Iteration 22100 (44.0708 iter/s, 2.26908s/100 iters), loss = 0.520512
I1004 21:33:54.185859  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:33:54.185859  3812 solver.cpp:237]     Train net output #1: loss = 0.520512 (* 1 = 0.520512 loss)
I1004 21:33:54.185859  3812 sgd_solver.cpp:105] Iteration 22100, lr = 1e-05
I1004 21:33:56.447934  3812 solver.cpp:218] Iteration 22200 (44.1536 iter/s, 2.26482s/100 iters), loss = 0.539883
I1004 21:33:56.447934  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:33:56.447934  3812 solver.cpp:237]     Train net output #1: loss = 0.539883 (* 1 = 0.539883 loss)
I1004 21:33:56.447934  3812 sgd_solver.cpp:105] Iteration 22200, lr = 1e-05
I1004 21:33:58.733768  3812 solver.cpp:218] Iteration 22300 (43.9884 iter/s, 2.27332s/100 iters), loss = 0.537823
I1004 21:33:58.733768  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:33:58.733768  3812 solver.cpp:237]     Train net output #1: loss = 0.537823 (* 1 = 0.537823 loss)
I1004 21:33:58.733768  3812 sgd_solver.cpp:105] Iteration 22300, lr = 1e-05
I1004 21:34:01.016438  3812 solver.cpp:218] Iteration 22400 (43.835 iter/s, 2.28128s/100 iters), loss = 0.486307
I1004 21:34:01.016438  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:34:01.016438  3812 solver.cpp:237]     Train net output #1: loss = 0.486307 (* 1 = 0.486307 loss)
I1004 21:34:01.016438  3812 sgd_solver.cpp:105] Iteration 22400, lr = 1e-05
I1004 21:34:03.180244 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:34:03.289618  3812 solver.cpp:218] Iteration 22500 (43.8296 iter/s, 2.28156s/100 iters), loss = 0.491235
I1004 21:34:03.289618  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:34:03.289618  3812 solver.cpp:237]     Train net output #1: loss = 0.491235 (* 1 = 0.491235 loss)
I1004 21:34:03.289618  3812 sgd_solver.cpp:105] Iteration 22500, lr = 1e-05
I1004 21:34:05.565531  3812 solver.cpp:218] Iteration 22600 (44.0263 iter/s, 2.27137s/100 iters), loss = 0.467964
I1004 21:34:05.565531  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:34:05.565531  3812 solver.cpp:237]     Train net output #1: loss = 0.467964 (* 1 = 0.467964 loss)
I1004 21:34:05.565531  3812 sgd_solver.cpp:105] Iteration 22600, lr = 1e-05
I1004 21:34:07.845719  3812 solver.cpp:218] Iteration 22700 (43.8344 iter/s, 2.28131s/100 iters), loss = 0.501203
I1004 21:34:07.845719  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:34:07.845719  3812 solver.cpp:237]     Train net output #1: loss = 0.501203 (* 1 = 0.501203 loss)
I1004 21:34:07.845719  3812 sgd_solver.cpp:105] Iteration 22700, lr = 1e-05
I1004 21:34:10.103783  3812 solver.cpp:218] Iteration 22800 (44.1457 iter/s, 2.26523s/100 iters), loss = 0.528453
I1004 21:34:10.103783  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:34:10.103783  3812 solver.cpp:237]     Train net output #1: loss = 0.528453 (* 1 = 0.528453 loss)
I1004 21:34:10.103783  3812 sgd_solver.cpp:105] Iteration 22800, lr = 1e-05
I1004 21:34:12.390333  3812 solver.cpp:218] Iteration 22900 (43.764 iter/s, 2.28498s/100 iters), loss = 0.410707
I1004 21:34:12.390333  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:34:12.390333  3812 solver.cpp:237]     Train net output #1: loss = 0.410707 (* 1 = 0.410707 loss)
I1004 21:34:12.390333  3812 sgd_solver.cpp:105] Iteration 22900, lr = 1e-05
I1004 21:34:14.558805 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:34:14.652552  3812 solver.cpp:330] Iteration 23000, Testing net (#0)
I1004 21:34:14.652552  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:34:15.089048 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:34:15.104671  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7668
I1004 21:34:15.104671  3812 solver.cpp:397]     Test net output #1: loss = 0.677469 (* 1 = 0.677469 loss)
I1004 21:34:15.120296  3812 solver.cpp:218] Iteration 23000 (36.6578 iter/s, 2.72793s/100 iters), loss = 0.501931
I1004 21:34:15.120296  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:34:15.120296  3812 solver.cpp:237]     Train net output #1: loss = 0.501931 (* 1 = 0.501931 loss)
I1004 21:34:15.120296  3812 sgd_solver.cpp:105] Iteration 23000, lr = 1e-05
I1004 21:34:17.386430  3812 solver.cpp:218] Iteration 23100 (44.2846 iter/s, 2.25812s/100 iters), loss = 0.468034
I1004 21:34:17.386430  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:34:17.386430  3812 solver.cpp:237]     Train net output #1: loss = 0.468034 (* 1 = 0.468034 loss)
I1004 21:34:17.386430  3812 sgd_solver.cpp:105] Iteration 23100, lr = 1e-05
I1004 21:34:19.643977  3812 solver.cpp:218] Iteration 23200 (44.3032 iter/s, 2.25717s/100 iters), loss = 0.490928
I1004 21:34:19.643977  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:34:19.643977  3812 solver.cpp:237]     Train net output #1: loss = 0.490928 (* 1 = 0.490928 loss)
I1004 21:34:19.643977  3812 sgd_solver.cpp:105] Iteration 23200, lr = 1e-05
I1004 21:34:21.902127  3812 solver.cpp:218] Iteration 23300 (44.2434 iter/s, 2.26023s/100 iters), loss = 0.544812
I1004 21:34:21.902127  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:34:21.902127  3812 solver.cpp:237]     Train net output #1: loss = 0.544812 (* 1 = 0.544812 loss)
I1004 21:34:21.902127  3812 sgd_solver.cpp:105] Iteration 23300, lr = 1e-05
I1004 21:34:24.153609  3812 solver.cpp:218] Iteration 23400 (44.3782 iter/s, 2.25336s/100 iters), loss = 0.500875
I1004 21:34:24.153609  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:34:24.153609  3812 solver.cpp:237]     Train net output #1: loss = 0.500875 (* 1 = 0.500875 loss)
I1004 21:34:24.153609  3812 sgd_solver.cpp:105] Iteration 23400, lr = 1e-05
I1004 21:34:26.302953 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:34:26.418526  3812 solver.cpp:218] Iteration 23500 (44.3004 iter/s, 2.25732s/100 iters), loss = 0.544215
I1004 21:34:26.418526  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:34:26.418526  3812 solver.cpp:237]     Train net output #1: loss = 0.544215 (* 1 = 0.544215 loss)
I1004 21:34:26.418526  3812 sgd_solver.cpp:105] Iteration 23500, lr = 1e-05
I1004 21:34:28.673244  3812 solver.cpp:218] Iteration 23600 (44.3359 iter/s, 2.25551s/100 iters), loss = 0.523964
I1004 21:34:28.673244  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:34:28.673244  3812 solver.cpp:237]     Train net output #1: loss = 0.523964 (* 1 = 0.523964 loss)
I1004 21:34:28.673244  3812 sgd_solver.cpp:105] Iteration 23600, lr = 1e-05
I1004 21:34:30.932020  3812 solver.cpp:218] Iteration 23700 (44.3041 iter/s, 2.25713s/100 iters), loss = 0.576103
I1004 21:34:30.932020  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:34:30.932020  3812 solver.cpp:237]     Train net output #1: loss = 0.576103 (* 1 = 0.576103 loss)
I1004 21:34:30.932020  3812 sgd_solver.cpp:105] Iteration 23700, lr = 1e-05
I1004 21:34:33.182018  3812 solver.cpp:218] Iteration 23800 (44.3681 iter/s, 2.25387s/100 iters), loss = 0.50379
I1004 21:34:33.182018  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:34:33.182018  3812 solver.cpp:237]     Train net output #1: loss = 0.50379 (* 1 = 0.50379 loss)
I1004 21:34:33.182018  3812 sgd_solver.cpp:105] Iteration 23800, lr = 1e-05
I1004 21:34:35.449111  3812 solver.cpp:218] Iteration 23900 (44.1962 iter/s, 2.26264s/100 iters), loss = 0.419755
I1004 21:34:35.449111  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:34:35.449111  3812 solver.cpp:237]     Train net output #1: loss = 0.419755 (* 1 = 0.419755 loss)
I1004 21:34:35.449111  3812 sgd_solver.cpp:105] Iteration 23900, lr = 1e-05
I1004 21:34:37.589203 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:34:37.682953  3812 solver.cpp:330] Iteration 24000, Testing net (#0)
I1004 21:34:37.682953  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:34:38.105757 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:34:38.121383  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7668
I1004 21:34:38.121383  3812 solver.cpp:397]     Test net output #1: loss = 0.677614 (* 1 = 0.677614 loss)
I1004 21:34:38.152632  3812 solver.cpp:218] Iteration 24000 (36.9789 iter/s, 2.70424s/100 iters), loss = 0.547246
I1004 21:34:38.152632  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:34:38.152632  3812 solver.cpp:237]     Train net output #1: loss = 0.547246 (* 1 = 0.547246 loss)
I1004 21:34:38.152632  3812 sgd_solver.cpp:105] Iteration 24000, lr = 1e-05
I1004 21:34:40.417340  3812 solver.cpp:218] Iteration 24100 (44.1886 iter/s, 2.26303s/100 iters), loss = 0.478588
I1004 21:34:40.417340  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:34:40.417340  3812 solver.cpp:237]     Train net output #1: loss = 0.478588 (* 1 = 0.478588 loss)
I1004 21:34:40.417340  3812 sgd_solver.cpp:105] Iteration 24100, lr = 1e-05
I1004 21:34:42.667160  3812 solver.cpp:218] Iteration 24200 (44.1941 iter/s, 2.26275s/100 iters), loss = 0.486916
I1004 21:34:42.667160  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:34:42.667160  3812 solver.cpp:237]     Train net output #1: loss = 0.486916 (* 1 = 0.486916 loss)
I1004 21:34:42.667160  3812 sgd_solver.cpp:105] Iteration 24200, lr = 1e-05
I1004 21:34:44.932363  3812 solver.cpp:218] Iteration 24300 (44.3787 iter/s, 2.25333s/100 iters), loss = 0.538906
I1004 21:34:44.932363  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:34:44.932363  3812 solver.cpp:237]     Train net output #1: loss = 0.538906 (* 1 = 0.538906 loss)
I1004 21:34:44.932363  3812 sgd_solver.cpp:105] Iteration 24300, lr = 1e-05
I1004 21:34:47.183048  3812 solver.cpp:218] Iteration 24400 (44.2967 iter/s, 2.25751s/100 iters), loss = 0.413221
I1004 21:34:47.183048  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:34:47.183048  3812 solver.cpp:237]     Train net output #1: loss = 0.413221 (* 1 = 0.413221 loss)
I1004 21:34:47.183048  3812 sgd_solver.cpp:105] Iteration 24400, lr = 1e-05
I1004 21:34:49.333098 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:34:49.448185  3812 solver.cpp:218] Iteration 24500 (44.1306 iter/s, 2.266s/100 iters), loss = 0.481274
I1004 21:34:49.448185  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:34:49.448185  3812 solver.cpp:237]     Train net output #1: loss = 0.481274 (* 1 = 0.481274 loss)
I1004 21:34:49.448185  3812 sgd_solver.cpp:105] Iteration 24500, lr = 1e-05
I1004 21:34:51.703897  3812 solver.cpp:218] Iteration 24600 (44.3005 iter/s, 2.25731s/100 iters), loss = 0.461247
I1004 21:34:51.703897  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:34:51.703897  3812 solver.cpp:237]     Train net output #1: loss = 0.461247 (* 1 = 0.461247 loss)
I1004 21:34:51.703897  3812 sgd_solver.cpp:105] Iteration 24600, lr = 1e-05
I1004 21:34:53.964062  3812 solver.cpp:218] Iteration 24700 (44.2182 iter/s, 2.26151s/100 iters), loss = 0.476386
I1004 21:34:53.964062  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:34:53.964062  3812 solver.cpp:237]     Train net output #1: loss = 0.476386 (* 1 = 0.476386 loss)
I1004 21:34:53.964062  3812 sgd_solver.cpp:105] Iteration 24700, lr = 1e-05
I1004 21:34:56.236119  3812 solver.cpp:218] Iteration 24800 (44.2729 iter/s, 2.25872s/100 iters), loss = 0.522853
I1004 21:34:56.236119  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:34:56.236119  3812 solver.cpp:237]     Train net output #1: loss = 0.522853 (* 1 = 0.522853 loss)
I1004 21:34:56.236119  3812 sgd_solver.cpp:105] Iteration 24800, lr = 1e-05
I1004 21:34:58.495268  3812 solver.cpp:218] Iteration 24900 (44.1876 iter/s, 2.26308s/100 iters), loss = 0.464442
I1004 21:34:58.495268  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:34:58.495268  3812 solver.cpp:237]     Train net output #1: loss = 0.464442 (* 1 = 0.464442 loss)
I1004 21:34:58.495268  3812 sgd_solver.cpp:105] Iteration 24900, lr = 1e-05
I1004 21:35:00.650910 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:35:00.729037  3812 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/slimnet_simpnet_P3_iter_25000.caffemodel
I1004 21:35:00.744662  3812 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_simpnet_P3_iter_25000.solverstate
I1004 21:35:00.744662  3812 solver.cpp:330] Iteration 25000, Testing net (#0)
I1004 21:35:00.744662  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:35:01.166446 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:35:01.197696  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7675
I1004 21:35:01.197696  3812 solver.cpp:397]     Test net output #1: loss = 0.677486 (* 1 = 0.677486 loss)
I1004 21:35:01.218550  3812 solver.cpp:218] Iteration 25000 (36.78 iter/s, 2.71887s/100 iters), loss = 0.541881
I1004 21:35:01.218550  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:35:01.218550  3812 solver.cpp:237]     Train net output #1: loss = 0.541881 (* 1 = 0.541881 loss)
I1004 21:35:01.218550  3812 sgd_solver.cpp:46] MultiStep Status: Iteration 25000, step = 4
I1004 21:35:01.218550  3812 sgd_solver.cpp:105] Iteration 25000, lr = 1e-06
I1004 21:35:03.479339  3812 solver.cpp:218] Iteration 25100 (44.1297 iter/s, 2.26605s/100 iters), loss = 0.527335
I1004 21:35:03.479339  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:35:03.479339  3812 solver.cpp:237]     Train net output #1: loss = 0.527335 (* 1 = 0.527335 loss)
I1004 21:35:03.479339  3812 sgd_solver.cpp:105] Iteration 25100, lr = 1e-06
I1004 21:35:05.744792  3812 solver.cpp:218] Iteration 25200 (44.2393 iter/s, 2.26044s/100 iters), loss = 0.492789
I1004 21:35:05.744792  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:35:05.744792  3812 solver.cpp:237]     Train net output #1: loss = 0.492789 (* 1 = 0.492789 loss)
I1004 21:35:05.744792  3812 sgd_solver.cpp:105] Iteration 25200, lr = 1e-06
I1004 21:35:07.994544  3812 solver.cpp:218] Iteration 25300 (44.3418 iter/s, 2.25521s/100 iters), loss = 0.580528
I1004 21:35:07.994544  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:35:07.994544  3812 solver.cpp:237]     Train net output #1: loss = 0.580528 (* 1 = 0.580528 loss)
I1004 21:35:07.994544  3812 sgd_solver.cpp:105] Iteration 25300, lr = 1e-06
I1004 21:35:10.256664  3812 solver.cpp:218] Iteration 25400 (44.3051 iter/s, 2.25708s/100 iters), loss = 0.439547
I1004 21:35:10.256664  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:35:10.256664  3812 solver.cpp:237]     Train net output #1: loss = 0.439547 (* 1 = 0.439547 loss)
I1004 21:35:10.256664  3812 sgd_solver.cpp:105] Iteration 25400, lr = 1e-06
I1004 21:35:12.414675 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:35:12.510964  3812 solver.cpp:218] Iteration 25500 (44.1326 iter/s, 2.2659s/100 iters), loss = 0.580968
I1004 21:35:12.510964  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:35:12.510964  3812 solver.cpp:237]     Train net output #1: loss = 0.580968 (* 1 = 0.580968 loss)
I1004 21:35:12.510964  3812 sgd_solver.cpp:105] Iteration 25500, lr = 1e-06
I1004 21:35:14.777056  3812 solver.cpp:218] Iteration 25600 (44.2109 iter/s, 2.26189s/100 iters), loss = 0.45224
I1004 21:35:14.777056  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:35:14.777056  3812 solver.cpp:237]     Train net output #1: loss = 0.45224 (* 1 = 0.45224 loss)
I1004 21:35:14.777056  3812 sgd_solver.cpp:105] Iteration 25600, lr = 1e-06
I1004 21:35:17.042274  3812 solver.cpp:218] Iteration 25700 (44.2064 iter/s, 2.26212s/100 iters), loss = 0.528163
I1004 21:35:17.042274  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:35:17.042274  3812 solver.cpp:237]     Train net output #1: loss = 0.528163 (* 1 = 0.528163 loss)
I1004 21:35:17.042274  3812 sgd_solver.cpp:105] Iteration 25700, lr = 1e-06
I1004 21:35:19.309442  3812 solver.cpp:218] Iteration 25800 (44.2598 iter/s, 2.25939s/100 iters), loss = 0.501391
I1004 21:35:19.309442  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:35:19.309442  3812 solver.cpp:237]     Train net output #1: loss = 0.501391 (* 1 = 0.501391 loss)
I1004 21:35:19.309442  3812 sgd_solver.cpp:105] Iteration 25800, lr = 1e-06
I1004 21:35:21.566027  3812 solver.cpp:218] Iteration 25900 (44.1732 iter/s, 2.26382s/100 iters), loss = 0.458139
I1004 21:35:21.566027  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:35:21.566027  3812 solver.cpp:237]     Train net output #1: loss = 0.458139 (* 1 = 0.458139 loss)
I1004 21:35:21.566027  3812 sgd_solver.cpp:105] Iteration 25900, lr = 1e-06
I1004 21:35:23.713778 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:35:23.807528  3812 solver.cpp:330] Iteration 26000, Testing net (#0)
I1004 21:35:23.807528  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:35:24.241276 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:35:24.256901  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7669
I1004 21:35:24.256901  3812 solver.cpp:397]     Test net output #1: loss = 0.67746 (* 1 = 0.67746 loss)
I1004 21:35:24.284709  3812 solver.cpp:218] Iteration 26000 (36.8924 iter/s, 2.71058s/100 iters), loss = 0.547992
I1004 21:35:24.284709  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:35:24.284709  3812 solver.cpp:237]     Train net output #1: loss = 0.547992 (* 1 = 0.547992 loss)
I1004 21:35:24.284709  3812 sgd_solver.cpp:105] Iteration 26000, lr = 1e-06
I1004 21:35:26.531060  3812 solver.cpp:218] Iteration 26100 (44.3484 iter/s, 2.25487s/100 iters), loss = 0.511262
I1004 21:35:26.531060  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:35:26.531060  3812 solver.cpp:237]     Train net output #1: loss = 0.511262 (* 1 = 0.511262 loss)
I1004 21:35:26.531060  3812 sgd_solver.cpp:105] Iteration 26100, lr = 1e-06
I1004 21:35:28.794852  3812 solver.cpp:218] Iteration 26200 (44.2486 iter/s, 2.25996s/100 iters), loss = 0.567691
I1004 21:35:28.794852  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:35:28.794852  3812 solver.cpp:237]     Train net output #1: loss = 0.567691 (* 1 = 0.567691 loss)
I1004 21:35:28.794852  3812 sgd_solver.cpp:105] Iteration 26200, lr = 1e-06
I1004 21:35:31.041932  3812 solver.cpp:218] Iteration 26300 (44.3272 iter/s, 2.25595s/100 iters), loss = 0.512083
I1004 21:35:31.041932  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:35:31.041932  3812 solver.cpp:237]     Train net output #1: loss = 0.512083 (* 1 = 0.512083 loss)
I1004 21:35:31.041932  3812 sgd_solver.cpp:105] Iteration 26300, lr = 1e-06
I1004 21:35:33.307106  3812 solver.cpp:218] Iteration 26400 (44.293 iter/s, 2.25769s/100 iters), loss = 0.493163
I1004 21:35:33.307106  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:35:33.307106  3812 solver.cpp:237]     Train net output #1: loss = 0.493163 (* 1 = 0.493163 loss)
I1004 21:35:33.307106  3812 sgd_solver.cpp:105] Iteration 26400, lr = 1e-06
I1004 21:35:35.455485 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:35:35.564862  3812 solver.cpp:218] Iteration 26500 (44.353 iter/s, 2.25464s/100 iters), loss = 0.513972
I1004 21:35:35.564862  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:35:35.564862  3812 solver.cpp:237]     Train net output #1: loss = 0.513972 (* 1 = 0.513972 loss)
I1004 21:35:35.564862  3812 sgd_solver.cpp:105] Iteration 26500, lr = 1e-06
I1004 21:35:37.825410  3812 solver.cpp:218] Iteration 26600 (44.3331 iter/s, 2.25565s/100 iters), loss = 0.498397
I1004 21:35:37.825410  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:35:37.825410  3812 solver.cpp:237]     Train net output #1: loss = 0.498397 (* 1 = 0.498397 loss)
I1004 21:35:37.825410  3812 sgd_solver.cpp:105] Iteration 26600, lr = 1e-06
I1004 21:35:40.073549  3812 solver.cpp:218] Iteration 26700 (44.2405 iter/s, 2.26037s/100 iters), loss = 0.537743
I1004 21:35:40.073549  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:35:40.073549  3812 solver.cpp:237]     Train net output #1: loss = 0.537743 (* 1 = 0.537743 loss)
I1004 21:35:40.073549  3812 sgd_solver.cpp:105] Iteration 26700, lr = 1e-06
I1004 21:35:42.343984  3812 solver.cpp:218] Iteration 26800 (44.2283 iter/s, 2.261s/100 iters), loss = 0.521275
I1004 21:35:42.343984  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:35:42.343984  3812 solver.cpp:237]     Train net output #1: loss = 0.521275 (* 1 = 0.521275 loss)
I1004 21:35:42.343984  3812 sgd_solver.cpp:105] Iteration 26800, lr = 1e-06
I1004 21:35:44.604396  3812 solver.cpp:218] Iteration 26900 (44.3087 iter/s, 2.25689s/100 iters), loss = 0.460243
I1004 21:35:44.604396  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:35:44.604396  3812 solver.cpp:237]     Train net output #1: loss = 0.460243 (* 1 = 0.460243 loss)
I1004 21:35:44.604396  3812 sgd_solver.cpp:105] Iteration 26900, lr = 1e-06
I1004 21:35:46.746103 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:35:46.839623  3812 solver.cpp:330] Iteration 27000, Testing net (#0)
I1004 21:35:46.839623  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:35:47.257280 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:35:47.288172  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7675
I1004 21:35:47.288172  3812 solver.cpp:397]     Test net output #1: loss = 0.677292 (* 1 = 0.677292 loss)
I1004 21:35:47.309166  3812 solver.cpp:218] Iteration 27000 (36.981 iter/s, 2.70409s/100 iters), loss = 0.559434
I1004 21:35:47.309166  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:35:47.309166  3812 solver.cpp:237]     Train net output #1: loss = 0.559434 (* 1 = 0.559434 loss)
I1004 21:35:47.309166  3812 sgd_solver.cpp:105] Iteration 27000, lr = 1e-06
I1004 21:35:49.557831  3812 solver.cpp:218] Iteration 27100 (44.3235 iter/s, 2.25614s/100 iters), loss = 0.450415
I1004 21:35:49.557831  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:35:49.557831  3812 solver.cpp:237]     Train net output #1: loss = 0.450415 (* 1 = 0.450415 loss)
I1004 21:35:49.557831  3812 sgd_solver.cpp:105] Iteration 27100, lr = 1e-06
I1004 21:35:51.810220  3812 solver.cpp:218] Iteration 27200 (44.3034 iter/s, 2.25716s/100 iters), loss = 0.541543
I1004 21:35:51.810220  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:35:51.810220  3812 solver.cpp:237]     Train net output #1: loss = 0.541543 (* 1 = 0.541543 loss)
I1004 21:35:51.810220  3812 sgd_solver.cpp:105] Iteration 27200, lr = 1e-06
I1004 21:35:54.070307  3812 solver.cpp:218] Iteration 27300 (44.3381 iter/s, 2.2554s/100 iters), loss = 0.494335
I1004 21:35:54.070307  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:35:54.070307  3812 solver.cpp:237]     Train net output #1: loss = 0.494335 (* 1 = 0.494335 loss)
I1004 21:35:54.070307  3812 sgd_solver.cpp:105] Iteration 27300, lr = 1e-06
I1004 21:35:56.321029  3812 solver.cpp:218] Iteration 27400 (44.3461 iter/s, 2.25499s/100 iters), loss = 0.49709
I1004 21:35:56.321029  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:35:56.321029  3812 solver.cpp:237]     Train net output #1: loss = 0.49709 (* 1 = 0.49709 loss)
I1004 21:35:56.321029  3812 sgd_solver.cpp:105] Iteration 27400, lr = 1e-06
I1004 21:35:58.463914 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:35:58.573290  3812 solver.cpp:218] Iteration 27500 (44.3934 iter/s, 2.25259s/100 iters), loss = 0.54444
I1004 21:35:58.573290  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:35:58.573290  3812 solver.cpp:237]     Train net output #1: loss = 0.54444 (* 1 = 0.54444 loss)
I1004 21:35:58.573290  3812 sgd_solver.cpp:105] Iteration 27500, lr = 1e-06
I1004 21:36:00.842315  3812 solver.cpp:218] Iteration 27600 (44.2401 iter/s, 2.2604s/100 iters), loss = 0.463615
I1004 21:36:00.842315  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:36:00.842315  3812 solver.cpp:237]     Train net output #1: loss = 0.463615 (* 1 = 0.463615 loss)
I1004 21:36:00.842315  3812 sgd_solver.cpp:105] Iteration 27600, lr = 1e-06
I1004 21:36:03.089030  3812 solver.cpp:218] Iteration 27700 (44.3298 iter/s, 2.25582s/100 iters), loss = 0.546072
I1004 21:36:03.089030  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:36:03.089030  3812 solver.cpp:237]     Train net output #1: loss = 0.546072 (* 1 = 0.546072 loss)
I1004 21:36:03.089030  3812 sgd_solver.cpp:105] Iteration 27700, lr = 1e-06
I1004 21:36:05.351994  3812 solver.cpp:218] Iteration 27800 (44.3851 iter/s, 2.25301s/100 iters), loss = 0.502873
I1004 21:36:05.351994  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:36:05.351994  3812 solver.cpp:237]     Train net output #1: loss = 0.502873 (* 1 = 0.502873 loss)
I1004 21:36:05.351994  3812 sgd_solver.cpp:105] Iteration 27800, lr = 1e-06
I1004 21:36:07.604568  3812 solver.cpp:218] Iteration 27900 (44.3008 iter/s, 2.25729s/100 iters), loss = 0.401809
I1004 21:36:07.604568  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:36:07.604568  3812 solver.cpp:237]     Train net output #1: loss = 0.401809 (* 1 = 0.401809 loss)
I1004 21:36:07.604568  3812 sgd_solver.cpp:105] Iteration 27900, lr = 1e-06
I1004 21:36:09.744180 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:36:09.842422  3812 solver.cpp:330] Iteration 28000, Testing net (#0)
I1004 21:36:09.842422  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:36:10.259521 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:36:10.275148  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7666
I1004 21:36:10.275148  3812 solver.cpp:397]     Test net output #1: loss = 0.67757 (* 1 = 0.67757 loss)
I1004 21:36:10.306397  3812 solver.cpp:218] Iteration 28000 (37.1028 iter/s, 2.69521s/100 iters), loss = 0.550712
I1004 21:36:10.306397  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:36:10.306397  3812 solver.cpp:237]     Train net output #1: loss = 0.550712 (* 1 = 0.550712 loss)
I1004 21:36:10.306397  3812 sgd_solver.cpp:105] Iteration 28000, lr = 1e-06
I1004 21:36:12.557646  3812 solver.cpp:218] Iteration 28100 (44.2007 iter/s, 2.26241s/100 iters), loss = 0.489701
I1004 21:36:12.557646  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:36:12.557646  3812 solver.cpp:237]     Train net output #1: loss = 0.489701 (* 1 = 0.489701 loss)
I1004 21:36:12.557646  3812 sgd_solver.cpp:105] Iteration 28100, lr = 1e-06
I1004 21:36:14.831305  3812 solver.cpp:218] Iteration 28200 (44.2805 iter/s, 2.25833s/100 iters), loss = 0.445921
I1004 21:36:14.831305  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:36:14.831305  3812 solver.cpp:237]     Train net output #1: loss = 0.445921 (* 1 = 0.445921 loss)
I1004 21:36:14.831305  3812 sgd_solver.cpp:105] Iteration 28200, lr = 1e-06
I1004 21:36:17.073714  3812 solver.cpp:218] Iteration 28300 (44.3494 iter/s, 2.25482s/100 iters), loss = 0.53908
I1004 21:36:17.073714  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:36:17.073714  3812 solver.cpp:237]     Train net output #1: loss = 0.53908 (* 1 = 0.53908 loss)
I1004 21:36:17.073714  3812 sgd_solver.cpp:105] Iteration 28300, lr = 1e-06
I1004 21:36:19.349589  3812 solver.cpp:218] Iteration 28400 (44.1813 iter/s, 2.2634s/100 iters), loss = 0.430092
I1004 21:36:19.349589  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:36:19.349589  3812 solver.cpp:237]     Train net output #1: loss = 0.430092 (* 1 = 0.430092 loss)
I1004 21:36:19.349589  3812 sgd_solver.cpp:105] Iteration 28400, lr = 1e-06
I1004 21:36:21.494837 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:36:21.604210  3812 solver.cpp:218] Iteration 28500 (44.3198 iter/s, 2.25633s/100 iters), loss = 0.512621
I1004 21:36:21.604210  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:36:21.604210  3812 solver.cpp:237]     Train net output #1: loss = 0.512621 (* 1 = 0.512621 loss)
I1004 21:36:21.604210  3812 sgd_solver.cpp:105] Iteration 28500, lr = 1e-06
I1004 21:36:23.859256  3812 solver.cpp:218] Iteration 28600 (44.2473 iter/s, 2.26003s/100 iters), loss = 0.470037
I1004 21:36:23.859256  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:36:23.859256  3812 solver.cpp:237]     Train net output #1: loss = 0.470037 (* 1 = 0.470037 loss)
I1004 21:36:23.859256  3812 sgd_solver.cpp:105] Iteration 28600, lr = 1e-06
I1004 21:36:26.120368  3812 solver.cpp:218] Iteration 28700 (44.1445 iter/s, 2.26529s/100 iters), loss = 0.443177
I1004 21:36:26.120368  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:36:26.120368  3812 solver.cpp:237]     Train net output #1: loss = 0.443177 (* 1 = 0.443177 loss)
I1004 21:36:26.120368  3812 sgd_solver.cpp:105] Iteration 28700, lr = 1e-06
I1004 21:36:28.384029  3812 solver.cpp:218] Iteration 28800 (44.2829 iter/s, 2.25821s/100 iters), loss = 0.560653
I1004 21:36:28.384029  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:36:28.384029  3812 solver.cpp:237]     Train net output #1: loss = 0.560653 (* 1 = 0.560653 loss)
I1004 21:36:28.384029  3812 sgd_solver.cpp:105] Iteration 28800, lr = 1e-06
I1004 21:36:30.639148  3812 solver.cpp:218] Iteration 28900 (44.2057 iter/s, 2.26215s/100 iters), loss = 0.477057
I1004 21:36:30.639148  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:36:30.639148  3812 solver.cpp:237]     Train net output #1: loss = 0.477057 (* 1 = 0.477057 loss)
I1004 21:36:30.639148  3812 sgd_solver.cpp:105] Iteration 28900, lr = 1e-06
I1004 21:36:32.803599 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:36:32.890709  3812 solver.cpp:330] Iteration 29000, Testing net (#0)
I1004 21:36:32.890709  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:36:33.328625 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:36:33.337754  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7678
I1004 21:36:33.337754  3812 solver.cpp:397]     Test net output #1: loss = 0.677361 (* 1 = 0.677361 loss)
I1004 21:36:33.353379  3812 solver.cpp:218] Iteration 29000 (36.8651 iter/s, 2.71259s/100 iters), loss = 0.600116
I1004 21:36:33.353379  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:36:33.353379  3812 solver.cpp:237]     Train net output #1: loss = 0.600116 (* 1 = 0.600116 loss)
I1004 21:36:33.353379  3812 sgd_solver.cpp:105] Iteration 29000, lr = 1e-06
I1004 21:36:35.613296  3812 solver.cpp:218] Iteration 29100 (44.2213 iter/s, 2.26135s/100 iters), loss = 0.54692
I1004 21:36:35.628921  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:36:35.628921  3812 solver.cpp:237]     Train net output #1: loss = 0.54692 (* 1 = 0.54692 loss)
I1004 21:36:35.628921  3812 sgd_solver.cpp:105] Iteration 29100, lr = 1e-06
I1004 21:36:37.875541  3812 solver.cpp:218] Iteration 29200 (44.2498 iter/s, 2.2599s/100 iters), loss = 0.519973
I1004 21:36:37.875541  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:36:37.875541  3812 solver.cpp:237]     Train net output #1: loss = 0.519973 (* 1 = 0.519973 loss)
I1004 21:36:37.875541  3812 sgd_solver.cpp:105] Iteration 29200, lr = 1e-06
I1004 21:36:40.135687  3812 solver.cpp:218] Iteration 29300 (44.3238 iter/s, 2.25612s/100 iters), loss = 0.548882
I1004 21:36:40.135687  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:36:40.135687  3812 solver.cpp:237]     Train net output #1: loss = 0.548882 (* 1 = 0.548882 loss)
I1004 21:36:40.135687  3812 sgd_solver.cpp:105] Iteration 29300, lr = 1e-06
I1004 21:36:42.399777  3812 solver.cpp:218] Iteration 29400 (44.1631 iter/s, 2.26433s/100 iters), loss = 0.437949
I1004 21:36:42.399777  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:36:42.399777  3812 solver.cpp:237]     Train net output #1: loss = 0.437949 (* 1 = 0.437949 loss)
I1004 21:36:42.399777  3812 sgd_solver.cpp:105] Iteration 29400, lr = 1e-06
I1004 21:36:44.559185 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:36:44.668558  3812 solver.cpp:218] Iteration 29500 (44.2295 iter/s, 2.26094s/100 iters), loss = 0.61775
I1004 21:36:44.668558  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:36:44.668558  3812 solver.cpp:237]     Train net output #1: loss = 0.61775 (* 1 = 0.61775 loss)
I1004 21:36:44.668558  3812 sgd_solver.cpp:105] Iteration 29500, lr = 1e-06
I1004 21:36:46.932440  3812 solver.cpp:218] Iteration 29600 (44.1801 iter/s, 2.26346s/100 iters), loss = 0.468468
I1004 21:36:46.932440  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:36:46.932440  3812 solver.cpp:237]     Train net output #1: loss = 0.468468 (* 1 = 0.468468 loss)
I1004 21:36:46.932440  3812 sgd_solver.cpp:105] Iteration 29600, lr = 1e-06
I1004 21:36:49.204185  3812 solver.cpp:218] Iteration 29700 (44.0712 iter/s, 2.26906s/100 iters), loss = 0.553199
I1004 21:36:49.204185  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:36:49.204185  3812 solver.cpp:237]     Train net output #1: loss = 0.553199 (* 1 = 0.553199 loss)
I1004 21:36:49.204185  3812 sgd_solver.cpp:105] Iteration 29700, lr = 1e-06
I1004 21:36:51.455490  3812 solver.cpp:218] Iteration 29800 (44.1518 iter/s, 2.26491s/100 iters), loss = 0.547256
I1004 21:36:51.455490  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:36:51.455490  3812 solver.cpp:237]     Train net output #1: loss = 0.547256 (* 1 = 0.547256 loss)
I1004 21:36:51.455490  3812 sgd_solver.cpp:105] Iteration 29800, lr = 1e-06
I1004 21:36:53.716099  3812 solver.cpp:218] Iteration 29900 (44.2523 iter/s, 2.25977s/100 iters), loss = 0.463261
I1004 21:36:53.716099  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:36:53.716099  3812 solver.cpp:237]     Train net output #1: loss = 0.463261 (* 1 = 0.463261 loss)
I1004 21:36:53.716099  3812 sgd_solver.cpp:105] Iteration 29900, lr = 1e-06
I1004 21:36:55.876385 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:36:55.963716  3812 solver.cpp:330] Iteration 30000, Testing net (#0)
I1004 21:36:55.963716  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:36:56.404645 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:36:56.421414  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7669
I1004 21:36:56.421414  3812 solver.cpp:397]     Test net output #1: loss = 0.677503 (* 1 = 0.677503 loss)
I1004 21:36:56.442412  3812 solver.cpp:218] Iteration 30000 (36.8701 iter/s, 2.71222s/100 iters), loss = 0.514018
I1004 21:36:56.442412  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:36:56.442412  3812 solver.cpp:237]     Train net output #1: loss = 0.514018 (* 1 = 0.514018 loss)
I1004 21:36:56.442412  3812 sgd_solver.cpp:105] Iteration 30000, lr = 1e-06
I1004 21:36:58.699034  3812 solver.cpp:218] Iteration 30100 (44.3046 iter/s, 2.2571s/100 iters), loss = 0.543177
I1004 21:36:58.699034  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:36:58.699034  3812 solver.cpp:237]     Train net output #1: loss = 0.543177 (* 1 = 0.543177 loss)
I1004 21:36:58.699034  3812 sgd_solver.cpp:105] Iteration 30100, lr = 1e-06
I1004 21:37:00.947938  3812 solver.cpp:218] Iteration 30200 (44.206 iter/s, 2.26214s/100 iters), loss = 0.600921
I1004 21:37:00.947938  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:37:00.947938  3812 solver.cpp:237]     Train net output #1: loss = 0.600921 (* 1 = 0.600921 loss)
I1004 21:37:00.947938  3812 sgd_solver.cpp:105] Iteration 30200, lr = 1e-06
I1004 21:37:03.226239  3812 solver.cpp:218] Iteration 30300 (44.1713 iter/s, 2.26392s/100 iters), loss = 0.56338
I1004 21:37:03.226239  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:37:03.226239  3812 solver.cpp:237]     Train net output #1: loss = 0.56338 (* 1 = 0.56338 loss)
I1004 21:37:03.226239  3812 sgd_solver.cpp:105] Iteration 30300, lr = 1e-06
I1004 21:37:05.479732  3812 solver.cpp:218] Iteration 30400 (44.2198 iter/s, 2.26143s/100 iters), loss = 0.372355
I1004 21:37:05.479732  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:37:05.479732  3812 solver.cpp:237]     Train net output #1: loss = 0.372355 (* 1 = 0.372355 loss)
I1004 21:37:05.479732  3812 sgd_solver.cpp:105] Iteration 30400, lr = 1e-06
I1004 21:37:07.638353 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:37:07.736336  3812 solver.cpp:218] Iteration 30500 (44.2622 iter/s, 2.25927s/100 iters), loss = 0.515402
I1004 21:37:07.736336  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:37:07.736336  3812 solver.cpp:237]     Train net output #1: loss = 0.515402 (* 1 = 0.515402 loss)
I1004 21:37:07.736336  3812 sgd_solver.cpp:105] Iteration 30500, lr = 1e-06
I1004 21:37:09.995631  3812 solver.cpp:218] Iteration 30600 (44.2109 iter/s, 2.26188s/100 iters), loss = 0.504349
I1004 21:37:09.995631  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:37:09.995631  3812 solver.cpp:237]     Train net output #1: loss = 0.504349 (* 1 = 0.504349 loss)
I1004 21:37:09.995631  3812 sgd_solver.cpp:105] Iteration 30600, lr = 1e-06
I1004 21:37:12.259706  3812 solver.cpp:218] Iteration 30700 (44.2634 iter/s, 2.2592s/100 iters), loss = 0.544552
I1004 21:37:12.259706  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:37:12.259706  3812 solver.cpp:237]     Train net output #1: loss = 0.544552 (* 1 = 0.544552 loss)
I1004 21:37:12.259706  3812 sgd_solver.cpp:105] Iteration 30700, lr = 1e-06
I1004 21:37:14.526672  3812 solver.cpp:218] Iteration 30800 (44.2453 iter/s, 2.26013s/100 iters), loss = 0.490244
I1004 21:37:14.526672  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:37:14.526672  3812 solver.cpp:237]     Train net output #1: loss = 0.490244 (* 1 = 0.490244 loss)
I1004 21:37:14.526672  3812 sgd_solver.cpp:105] Iteration 30800, lr = 1e-06
I1004 21:37:16.783375  3812 solver.cpp:218] Iteration 30900 (44.1576 iter/s, 2.26462s/100 iters), loss = 0.452957
I1004 21:37:16.783375  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:37:16.783375  3812 solver.cpp:237]     Train net output #1: loss = 0.452957 (* 1 = 0.452957 loss)
I1004 21:37:16.783375  3812 sgd_solver.cpp:105] Iteration 30900, lr = 1e-06
I1004 21:37:18.932358 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:37:19.026108  3812 solver.cpp:330] Iteration 31000, Testing net (#0)
I1004 21:37:19.026108  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:37:19.463948 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:37:19.479573  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7671
I1004 21:37:19.479573  3812 solver.cpp:397]     Test net output #1: loss = 0.677321 (* 1 = 0.677321 loss)
I1004 21:37:19.495198  3812 solver.cpp:218] Iteration 31000 (36.8987 iter/s, 2.71012s/100 iters), loss = 0.530324
I1004 21:37:19.495198  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:37:19.495198  3812 solver.cpp:237]     Train net output #1: loss = 0.530324 (* 1 = 0.530324 loss)
I1004 21:37:19.495198  3812 sgd_solver.cpp:105] Iteration 31000, lr = 1e-06
I1004 21:37:21.748232  3812 solver.cpp:218] Iteration 31100 (44.3173 iter/s, 2.25645s/100 iters), loss = 0.487643
I1004 21:37:21.748232  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:37:21.748232  3812 solver.cpp:237]     Train net output #1: loss = 0.487643 (* 1 = 0.487643 loss)
I1004 21:37:21.748232  3812 sgd_solver.cpp:105] Iteration 31100, lr = 1e-06
I1004 21:37:24.017177  3812 solver.cpp:218] Iteration 31200 (44.3373 iter/s, 2.25544s/100 iters), loss = 0.561863
I1004 21:37:24.018177  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:37:24.018177  3812 solver.cpp:237]     Train net output #1: loss = 0.561863 (* 1 = 0.561863 loss)
I1004 21:37:24.018177  3812 sgd_solver.cpp:105] Iteration 31200, lr = 1e-06
I1004 21:37:26.275388  3812 solver.cpp:218] Iteration 31300 (44.2675 iter/s, 2.259s/100 iters), loss = 0.488315
I1004 21:37:26.275388  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:37:26.275388  3812 solver.cpp:237]     Train net output #1: loss = 0.488315 (* 1 = 0.488315 loss)
I1004 21:37:26.275388  3812 sgd_solver.cpp:105] Iteration 31300, lr = 1e-06
I1004 21:37:28.527360  3812 solver.cpp:218] Iteration 31400 (44.2953 iter/s, 2.25758s/100 iters), loss = 0.463904
I1004 21:37:28.527360  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:37:28.527360  3812 solver.cpp:237]     Train net output #1: loss = 0.463904 (* 1 = 0.463904 loss)
I1004 21:37:28.527360  3812 sgd_solver.cpp:105] Iteration 31400, lr = 1e-06
I1004 21:37:30.680228 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:37:30.789603  3812 solver.cpp:218] Iteration 31500 (44.3442 iter/s, 2.25509s/100 iters), loss = 0.617742
I1004 21:37:30.789603  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:37:30.789603  3812 solver.cpp:237]     Train net output #1: loss = 0.617742 (* 1 = 0.617742 loss)
I1004 21:37:30.789603  3812 sgd_solver.cpp:105] Iteration 31500, lr = 1e-06
I1004 21:37:33.042475  3812 solver.cpp:218] Iteration 31600 (44.3362 iter/s, 2.25549s/100 iters), loss = 0.553808
I1004 21:37:33.042475  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:37:33.042475  3812 solver.cpp:237]     Train net output #1: loss = 0.553808 (* 1 = 0.553808 loss)
I1004 21:37:33.042475  3812 sgd_solver.cpp:105] Iteration 31600, lr = 1e-06
I1004 21:37:35.291558  3812 solver.cpp:218] Iteration 31700 (44.3002 iter/s, 2.25733s/100 iters), loss = 0.47486
I1004 21:37:35.291558  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:37:35.291558  3812 solver.cpp:237]     Train net output #1: loss = 0.47486 (* 1 = 0.47486 loss)
I1004 21:37:35.291558  3812 sgd_solver.cpp:105] Iteration 31700, lr = 1e-06
I1004 21:37:37.542197  3812 solver.cpp:218] Iteration 31800 (44.3941 iter/s, 2.25255s/100 iters), loss = 0.519328
I1004 21:37:37.542197  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:37:37.542197  3812 solver.cpp:237]     Train net output #1: loss = 0.519328 (* 1 = 0.519328 loss)
I1004 21:37:37.542197  3812 sgd_solver.cpp:105] Iteration 31800, lr = 1e-06
I1004 21:37:39.792608  3812 solver.cpp:218] Iteration 31900 (44.4425 iter/s, 2.2501s/100 iters), loss = 0.444149
I1004 21:37:39.792608  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:37:39.792608  3812 solver.cpp:237]     Train net output #1: loss = 0.444149 (* 1 = 0.444149 loss)
I1004 21:37:39.792608  3812 sgd_solver.cpp:105] Iteration 31900, lr = 1e-06
I1004 21:37:41.948166 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:37:42.041918  3812 solver.cpp:330] Iteration 32000, Testing net (#0)
I1004 21:37:42.041918  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:37:42.477321 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:37:42.492946  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7668
I1004 21:37:42.492946  3812 solver.cpp:397]     Test net output #1: loss = 0.677348 (* 1 = 0.677348 loss)
I1004 21:37:42.508572  3812 solver.cpp:218] Iteration 32000 (36.8687 iter/s, 2.71233s/100 iters), loss = 0.537264
I1004 21:37:42.508572  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:37:42.508572  3812 solver.cpp:237]     Train net output #1: loss = 0.537264 (* 1 = 0.537264 loss)
I1004 21:37:42.508572  3812 sgd_solver.cpp:105] Iteration 32000, lr = 1e-06
I1004 21:37:44.772187  3812 solver.cpp:218] Iteration 32100 (44.2353 iter/s, 2.26064s/100 iters), loss = 0.540961
I1004 21:37:44.772187  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 21:37:44.772187  3812 solver.cpp:237]     Train net output #1: loss = 0.540961 (* 1 = 0.540961 loss)
I1004 21:37:44.772187  3812 sgd_solver.cpp:105] Iteration 32100, lr = 1e-06
I1004 21:37:47.023763  3812 solver.cpp:218] Iteration 32200 (44.315 iter/s, 2.25657s/100 iters), loss = 0.537901
I1004 21:37:47.023763  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:37:47.023763  3812 solver.cpp:237]     Train net output #1: loss = 0.537901 (* 1 = 0.537901 loss)
I1004 21:37:47.023763  3812 sgd_solver.cpp:105] Iteration 32200, lr = 1e-06
I1004 21:37:49.291061  3812 solver.cpp:218] Iteration 32300 (44.2428 iter/s, 2.26026s/100 iters), loss = 0.560274
I1004 21:37:49.291061  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:37:49.291061  3812 solver.cpp:237]     Train net output #1: loss = 0.560274 (* 1 = 0.560274 loss)
I1004 21:37:49.291061  3812 sgd_solver.cpp:105] Iteration 32300, lr = 1e-06
I1004 21:37:51.558048  3812 solver.cpp:218] Iteration 32400 (44.0079 iter/s, 2.27232s/100 iters), loss = 0.450731
I1004 21:37:51.558048  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:37:51.558048  3812 solver.cpp:237]     Train net output #1: loss = 0.450731 (* 1 = 0.450731 loss)
I1004 21:37:51.558048  3812 sgd_solver.cpp:105] Iteration 32400, lr = 1e-06
I1004 21:37:53.733862 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:37:53.846863  3812 solver.cpp:218] Iteration 32500 (43.9362 iter/s, 2.27603s/100 iters), loss = 0.496495
I1004 21:37:53.846863  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:37:53.846863  3812 solver.cpp:237]     Train net output #1: loss = 0.496495 (* 1 = 0.496495 loss)
I1004 21:37:53.846863  3812 sgd_solver.cpp:105] Iteration 32500, lr = 1e-06
I1004 21:37:56.199136  3812 solver.cpp:218] Iteration 32600 (42.5176 iter/s, 2.35197s/100 iters), loss = 0.493903
I1004 21:37:56.199136  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:37:56.199136  3812 solver.cpp:237]     Train net output #1: loss = 0.493903 (* 1 = 0.493903 loss)
I1004 21:37:56.199136  3812 sgd_solver.cpp:105] Iteration 32600, lr = 1e-06
I1004 21:37:58.479115  3812 solver.cpp:218] Iteration 32700 (43.8712 iter/s, 2.2794s/100 iters), loss = 0.534277
I1004 21:37:58.479115  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:37:58.479115  3812 solver.cpp:237]     Train net output #1: loss = 0.534277 (* 1 = 0.534277 loss)
I1004 21:37:58.479115  3812 sgd_solver.cpp:105] Iteration 32700, lr = 1e-06
I1004 21:38:00.791237  3812 solver.cpp:218] Iteration 32800 (43.2632 iter/s, 2.31143s/100 iters), loss = 0.55899
I1004 21:38:00.791237  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:38:00.791237  3812 solver.cpp:237]     Train net output #1: loss = 0.55899 (* 1 = 0.55899 loss)
I1004 21:38:00.791237  3812 sgd_solver.cpp:105] Iteration 32800, lr = 1e-06
I1004 21:38:03.099448  3812 solver.cpp:218] Iteration 32900 (43.329 iter/s, 2.30792s/100 iters), loss = 0.467442
I1004 21:38:03.099448  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:38:03.099448  3812 solver.cpp:237]     Train net output #1: loss = 0.467442 (* 1 = 0.467442 loss)
I1004 21:38:03.099448  3812 sgd_solver.cpp:105] Iteration 32900, lr = 1e-06
I1004 21:38:05.288669 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:38:05.378672  3812 solver.cpp:330] Iteration 33000, Testing net (#0)
I1004 21:38:05.378672  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:38:05.824671 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:38:05.842669  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7674
I1004 21:38:05.842669  3812 solver.cpp:397]     Test net output #1: loss = 0.677607 (* 1 = 0.677607 loss)
I1004 21:38:05.864668  3812 solver.cpp:218] Iteration 33000 (36.1629 iter/s, 2.76526s/100 iters), loss = 0.511494
I1004 21:38:05.864668  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:38:05.864668  3812 solver.cpp:237]     Train net output #1: loss = 0.511494 (* 1 = 0.511494 loss)
I1004 21:38:05.864668  3812 sgd_solver.cpp:105] Iteration 33000, lr = 1e-06
I1004 21:38:08.209671  3812 solver.cpp:218] Iteration 33100 (42.6556 iter/s, 2.34436s/100 iters), loss = 0.498541
I1004 21:38:08.209671  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:38:08.209671  3812 solver.cpp:237]     Train net output #1: loss = 0.498541 (* 1 = 0.498541 loss)
I1004 21:38:08.209671  3812 sgd_solver.cpp:105] Iteration 33100, lr = 1e-06
I1004 21:38:10.570669  3812 solver.cpp:218] Iteration 33200 (42.3573 iter/s, 2.36087s/100 iters), loss = 0.451608
I1004 21:38:10.570669  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:38:10.570669  3812 solver.cpp:237]     Train net output #1: loss = 0.451608 (* 1 = 0.451608 loss)
I1004 21:38:10.570669  3812 sgd_solver.cpp:105] Iteration 33200, lr = 1e-06
I1004 21:38:12.925669  3812 solver.cpp:218] Iteration 33300 (42.479 iter/s, 2.35411s/100 iters), loss = 0.561857
I1004 21:38:12.925669  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:38:12.925669  3812 solver.cpp:237]     Train net output #1: loss = 0.561857 (* 1 = 0.561857 loss)
I1004 21:38:12.925669  3812 sgd_solver.cpp:105] Iteration 33300, lr = 1e-06
I1004 21:38:15.184672  3812 solver.cpp:218] Iteration 33400 (44.2583 iter/s, 2.25946s/100 iters), loss = 0.460797
I1004 21:38:15.184672  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:38:15.184672  3812 solver.cpp:237]     Train net output #1: loss = 0.460797 (* 1 = 0.460797 loss)
I1004 21:38:15.184672  3812 sgd_solver.cpp:105] Iteration 33400, lr = 1e-06
I1004 21:38:17.330689 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:38:17.439684  3812 solver.cpp:218] Iteration 33500 (44.3648 iter/s, 2.25404s/100 iters), loss = 0.510004
I1004 21:38:17.439684  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:38:17.439684  3812 solver.cpp:237]     Train net output #1: loss = 0.510004 (* 1 = 0.510004 loss)
I1004 21:38:17.439684  3812 sgd_solver.cpp:105] Iteration 33500, lr = 1e-06
I1004 21:38:19.733670  3812 solver.cpp:218] Iteration 33600 (43.6025 iter/s, 2.29345s/100 iters), loss = 0.50366
I1004 21:38:19.733670  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:38:19.733670  3812 solver.cpp:237]     Train net output #1: loss = 0.50366 (* 1 = 0.50366 loss)
I1004 21:38:19.733670  3812 sgd_solver.cpp:105] Iteration 33600, lr = 1e-06
I1004 21:38:22.038669  3812 solver.cpp:218] Iteration 33700 (43.3874 iter/s, 2.30482s/100 iters), loss = 0.504397
I1004 21:38:22.038669  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:38:22.038669  3812 solver.cpp:237]     Train net output #1: loss = 0.504397 (* 1 = 0.504397 loss)
I1004 21:38:22.038669  3812 sgd_solver.cpp:105] Iteration 33700, lr = 1e-06
I1004 21:38:24.343672  3812 solver.cpp:218] Iteration 33800 (43.3837 iter/s, 2.30501s/100 iters), loss = 0.535667
I1004 21:38:24.343672  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:38:24.343672  3812 solver.cpp:237]     Train net output #1: loss = 0.535667 (* 1 = 0.535667 loss)
I1004 21:38:24.343672  3812 sgd_solver.cpp:105] Iteration 33800, lr = 1e-06
I1004 21:38:26.598670  3812 solver.cpp:218] Iteration 33900 (44.3627 iter/s, 2.25414s/100 iters), loss = 0.449194
I1004 21:38:26.598670  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:38:26.598670  3812 solver.cpp:237]     Train net output #1: loss = 0.449194 (* 1 = 0.449194 loss)
I1004 21:38:26.598670  3812 sgd_solver.cpp:105] Iteration 33900, lr = 1e-06
I1004 21:38:28.781672 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:38:28.873670  3812 solver.cpp:330] Iteration 34000, Testing net (#0)
I1004 21:38:28.873670  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:38:29.313675 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:38:29.330672  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7673
I1004 21:38:29.330672  3812 solver.cpp:397]     Test net output #1: loss = 0.677478 (* 1 = 0.677478 loss)
I1004 21:38:29.351670  3812 solver.cpp:218] Iteration 34000 (36.3175 iter/s, 2.75349s/100 iters), loss = 0.510911
I1004 21:38:29.351670  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:38:29.351670  3812 solver.cpp:237]     Train net output #1: loss = 0.510911 (* 1 = 0.510911 loss)
I1004 21:38:29.351670  3812 sgd_solver.cpp:105] Iteration 34000, lr = 1e-06
I1004 21:38:31.708669  3812 solver.cpp:218] Iteration 34100 (42.4451 iter/s, 2.35598s/100 iters), loss = 0.507427
I1004 21:38:31.708669  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:38:31.708669  3812 solver.cpp:237]     Train net output #1: loss = 0.507427 (* 1 = 0.507427 loss)
I1004 21:38:31.708669  3812 sgd_solver.cpp:105] Iteration 34100, lr = 1e-06
I1004 21:38:33.995672  3812 solver.cpp:218] Iteration 34200 (43.7253 iter/s, 2.287s/100 iters), loss = 0.539666
I1004 21:38:33.995672  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:38:33.995672  3812 solver.cpp:237]     Train net output #1: loss = 0.539666 (* 1 = 0.539666 loss)
I1004 21:38:33.995672  3812 sgd_solver.cpp:105] Iteration 34200, lr = 1e-06
I1004 21:38:36.259763  3812 solver.cpp:218] Iteration 34300 (44.168 iter/s, 2.26408s/100 iters), loss = 0.514893
I1004 21:38:36.259763  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:38:36.259763  3812 solver.cpp:237]     Train net output #1: loss = 0.514893 (* 1 = 0.514893 loss)
I1004 21:38:36.259763  3812 sgd_solver.cpp:105] Iteration 34300, lr = 1e-06
I1004 21:38:38.514674  3812 solver.cpp:218] Iteration 34400 (44.3016 iter/s, 2.25725s/100 iters), loss = 0.459485
I1004 21:38:38.514674  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:38:38.514674  3812 solver.cpp:237]     Train net output #1: loss = 0.459485 (* 1 = 0.459485 loss)
I1004 21:38:38.514674  3812 sgd_solver.cpp:105] Iteration 34400, lr = 1e-06
I1004 21:38:40.693353 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:38:40.806993  3812 solver.cpp:218] Iteration 34500 (43.6976 iter/s, 2.28846s/100 iters), loss = 0.5358
I1004 21:38:40.806993  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:38:40.806993  3812 solver.cpp:237]     Train net output #1: loss = 0.5358 (* 1 = 0.5358 loss)
I1004 21:38:40.806993  3812 sgd_solver.cpp:105] Iteration 34500, lr = 1e-06
I1004 21:38:43.072610  3812 solver.cpp:218] Iteration 34600 (44.1002 iter/s, 2.26756s/100 iters), loss = 0.533212
I1004 21:38:43.072610  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:38:43.072610  3812 solver.cpp:237]     Train net output #1: loss = 0.533212 (* 1 = 0.533212 loss)
I1004 21:38:43.072610  3812 sgd_solver.cpp:105] Iteration 34600, lr = 1e-06
I1004 21:38:45.330905  3812 solver.cpp:218] Iteration 34700 (44.3204 iter/s, 2.2563s/100 iters), loss = 0.524868
I1004 21:38:45.330905  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:38:45.330905  3812 solver.cpp:237]     Train net output #1: loss = 0.524868 (* 1 = 0.524868 loss)
I1004 21:38:45.330905  3812 sgd_solver.cpp:105] Iteration 34700, lr = 1e-06
I1004 21:38:47.591249  3812 solver.cpp:218] Iteration 34800 (44.186 iter/s, 2.26316s/100 iters), loss = 0.499767
I1004 21:38:47.591249  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:38:47.591249  3812 solver.cpp:237]     Train net output #1: loss = 0.499767 (* 1 = 0.499767 loss)
I1004 21:38:47.591249  3812 sgd_solver.cpp:105] Iteration 34800, lr = 1e-06
I1004 21:38:49.859135  3812 solver.cpp:218] Iteration 34900 (44.1476 iter/s, 2.26513s/100 iters), loss = 0.433504
I1004 21:38:49.859135  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:38:49.859135  3812 solver.cpp:237]     Train net output #1: loss = 0.433504 (* 1 = 0.433504 loss)
I1004 21:38:49.859135  3812 sgd_solver.cpp:105] Iteration 34900, lr = 1e-06
I1004 21:38:52.013293 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:38:52.091418  3812 solver.cpp:330] Iteration 35000, Testing net (#0)
I1004 21:38:52.091418  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:38:52.533561 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:38:52.549186  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7666
I1004 21:38:52.549186  3812 solver.cpp:397]     Test net output #1: loss = 0.677453 (* 1 = 0.677453 loss)
I1004 21:38:52.564811  3812 solver.cpp:218] Iteration 35000 (36.8449 iter/s, 2.71408s/100 iters), loss = 0.483366
I1004 21:38:52.564811  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:38:52.564811  3812 solver.cpp:237]     Train net output #1: loss = 0.483366 (* 1 = 0.483366 loss)
I1004 21:38:52.564811  3812 sgd_solver.cpp:105] Iteration 35000, lr = 1e-06
I1004 21:38:54.832336  3812 solver.cpp:218] Iteration 35100 (44.2625 iter/s, 2.25925s/100 iters), loss = 0.474503
I1004 21:38:54.832336  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:38:54.832336  3812 solver.cpp:237]     Train net output #1: loss = 0.474503 (* 1 = 0.474503 loss)
I1004 21:38:54.832336  3812 sgd_solver.cpp:105] Iteration 35100, lr = 1e-06
I1004 21:38:57.079841  3812 solver.cpp:218] Iteration 35200 (44.2515 iter/s, 2.25981s/100 iters), loss = 0.56258
I1004 21:38:57.079841  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:38:57.079841  3812 solver.cpp:237]     Train net output #1: loss = 0.56258 (* 1 = 0.56258 loss)
I1004 21:38:57.079841  3812 sgd_solver.cpp:105] Iteration 35200, lr = 1e-06
I1004 21:38:59.341073  3812 solver.cpp:218] Iteration 35300 (44.2606 iter/s, 2.25935s/100 iters), loss = 0.492535
I1004 21:38:59.341073  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:38:59.341073  3812 solver.cpp:237]     Train net output #1: loss = 0.492535 (* 1 = 0.492535 loss)
I1004 21:38:59.341073  3812 sgd_solver.cpp:105] Iteration 35300, lr = 1e-06
I1004 21:39:01.608160  3812 solver.cpp:218] Iteration 35400 (44.3378 iter/s, 2.25541s/100 iters), loss = 0.435395
I1004 21:39:01.608160  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:39:01.608160  3812 solver.cpp:237]     Train net output #1: loss = 0.435395 (* 1 = 0.435395 loss)
I1004 21:39:01.608160  3812 sgd_solver.cpp:105] Iteration 35400, lr = 1e-06
I1004 21:39:03.748083 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:39:03.857458  3812 solver.cpp:218] Iteration 35500 (44.318 iter/s, 2.25642s/100 iters), loss = 0.499881
I1004 21:39:03.857458  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:39:03.857458  3812 solver.cpp:237]     Train net output #1: loss = 0.499881 (* 1 = 0.499881 loss)
I1004 21:39:03.857458  3812 sgd_solver.cpp:105] Iteration 35500, lr = 1e-06
I1004 21:39:06.111865  3812 solver.cpp:218] Iteration 35600 (44.2766 iter/s, 2.25853s/100 iters), loss = 0.524952
I1004 21:39:06.111865  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:39:06.111865  3812 solver.cpp:237]     Train net output #1: loss = 0.524952 (* 1 = 0.524952 loss)
I1004 21:39:06.111865  3812 sgd_solver.cpp:105] Iteration 35600, lr = 1e-06
I1004 21:39:08.380498  3812 solver.cpp:218] Iteration 35700 (44.3214 iter/s, 2.25625s/100 iters), loss = 0.502579
I1004 21:39:08.380498  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:39:08.380498  3812 solver.cpp:237]     Train net output #1: loss = 0.502579 (* 1 = 0.502579 loss)
I1004 21:39:08.380498  3812 sgd_solver.cpp:105] Iteration 35700, lr = 1e-06
I1004 21:39:10.637612  3812 solver.cpp:218] Iteration 35800 (44.3403 iter/s, 2.25528s/100 iters), loss = 0.523807
I1004 21:39:10.637612  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:39:10.637612  3812 solver.cpp:237]     Train net output #1: loss = 0.523807 (* 1 = 0.523807 loss)
I1004 21:39:10.637612  3812 sgd_solver.cpp:105] Iteration 35800, lr = 1e-06
I1004 21:39:12.892189  3812 solver.cpp:218] Iteration 35900 (44.2501 iter/s, 2.25988s/100 iters), loss = 0.510487
I1004 21:39:12.892189  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:39:12.892189  3812 solver.cpp:237]     Train net output #1: loss = 0.510487 (* 1 = 0.510487 loss)
I1004 21:39:12.892189  3812 sgd_solver.cpp:105] Iteration 35900, lr = 1e-06
I1004 21:39:15.041041 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:39:15.119166  3812 solver.cpp:330] Iteration 36000, Testing net (#0)
I1004 21:39:15.119166  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:39:15.561017 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:39:15.576638  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7675
I1004 21:39:15.576638  3812 solver.cpp:397]     Test net output #1: loss = 0.677401 (* 1 = 0.677401 loss)
I1004 21:39:15.592262  3812 solver.cpp:218] Iteration 36000 (36.981 iter/s, 2.70409s/100 iters), loss = 0.473543
I1004 21:39:15.592262  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:39:15.592262  3812 solver.cpp:237]     Train net output #1: loss = 0.473543 (* 1 = 0.473543 loss)
I1004 21:39:15.592262  3812 sgd_solver.cpp:105] Iteration 36000, lr = 1e-06
I1004 21:39:17.856297  3812 solver.cpp:218] Iteration 36100 (44.2377 iter/s, 2.26051s/100 iters), loss = 0.504632
I1004 21:39:17.856297  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:39:17.856297  3812 solver.cpp:237]     Train net output #1: loss = 0.504632 (* 1 = 0.504632 loss)
I1004 21:39:17.856297  3812 sgd_solver.cpp:105] Iteration 36100, lr = 1e-06
I1004 21:39:20.119191  3812 solver.cpp:218] Iteration 36200 (44.3326 iter/s, 2.25568s/100 iters), loss = 0.469871
I1004 21:39:20.119191  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:39:20.119191  3812 solver.cpp:237]     Train net output #1: loss = 0.469871 (* 1 = 0.469871 loss)
I1004 21:39:20.119191  3812 sgd_solver.cpp:105] Iteration 36200, lr = 1e-06
I1004 21:39:22.380810  3812 solver.cpp:218] Iteration 36300 (44.1929 iter/s, 2.26281s/100 iters), loss = 0.521839
I1004 21:39:22.380810  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:39:22.380810  3812 solver.cpp:237]     Train net output #1: loss = 0.521839 (* 1 = 0.521839 loss)
I1004 21:39:22.380810  3812 sgd_solver.cpp:105] Iteration 36300, lr = 1e-06
I1004 21:39:24.637454  3812 solver.cpp:218] Iteration 36400 (44.1937 iter/s, 2.26276s/100 iters), loss = 0.444618
I1004 21:39:24.637454  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:39:24.637454  3812 solver.cpp:237]     Train net output #1: loss = 0.444618 (* 1 = 0.444618 loss)
I1004 21:39:24.637454  3812 sgd_solver.cpp:105] Iteration 36400, lr = 1e-06
I1004 21:39:26.782109 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:39:26.891484  3812 solver.cpp:218] Iteration 36500 (44.3669 iter/s, 2.25393s/100 iters), loss = 0.468097
I1004 21:39:26.891484  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:39:26.891484  3812 solver.cpp:237]     Train net output #1: loss = 0.468097 (* 1 = 0.468097 loss)
I1004 21:39:26.891484  3812 sgd_solver.cpp:105] Iteration 36500, lr = 1e-06
I1004 21:39:29.152778  3812 solver.cpp:218] Iteration 36600 (44.2964 iter/s, 2.25752s/100 iters), loss = 0.46294
I1004 21:39:29.152778  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:39:29.152778  3812 solver.cpp:237]     Train net output #1: loss = 0.46294 (* 1 = 0.46294 loss)
I1004 21:39:29.152778  3812 sgd_solver.cpp:105] Iteration 36600, lr = 1e-06
I1004 21:39:31.414494  3812 solver.cpp:218] Iteration 36700 (44.2179 iter/s, 2.26153s/100 iters), loss = 0.497928
I1004 21:39:31.414494  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:39:31.414494  3812 solver.cpp:237]     Train net output #1: loss = 0.497928 (* 1 = 0.497928 loss)
I1004 21:39:31.414494  3812 sgd_solver.cpp:105] Iteration 36700, lr = 1e-06
I1004 21:39:33.673807  3812 solver.cpp:218] Iteration 36800 (44.3361 iter/s, 2.2555s/100 iters), loss = 0.563198
I1004 21:39:33.673807  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:39:33.673807  3812 solver.cpp:237]     Train net output #1: loss = 0.563198 (* 1 = 0.563198 loss)
I1004 21:39:33.673807  3812 sgd_solver.cpp:105] Iteration 36800, lr = 1e-06
I1004 21:39:35.922791  3812 solver.cpp:218] Iteration 36900 (44.2261 iter/s, 2.26111s/100 iters), loss = 0.478918
I1004 21:39:35.922791  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:39:35.922791  3812 solver.cpp:237]     Train net output #1: loss = 0.478918 (* 1 = 0.478918 loss)
I1004 21:39:35.922791  3812 sgd_solver.cpp:105] Iteration 36900, lr = 1e-06
I1004 21:39:38.080392 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:39:38.174145  3812 solver.cpp:330] Iteration 37000, Testing net (#0)
I1004 21:39:38.174145  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:39:38.606426 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:39:38.622424  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7674
I1004 21:39:38.622424  3812 solver.cpp:397]     Test net output #1: loss = 0.677468 (* 1 = 0.677468 loss)
I1004 21:39:38.631588  3812 solver.cpp:218] Iteration 37000 (36.9478 iter/s, 2.70652s/100 iters), loss = 0.534457
I1004 21:39:38.631588  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:39:38.631588  3812 solver.cpp:237]     Train net output #1: loss = 0.534457 (* 1 = 0.534457 loss)
I1004 21:39:38.631588  3812 sgd_solver.cpp:105] Iteration 37000, lr = 1e-06
I1004 21:39:40.890064  3812 solver.cpp:218] Iteration 37100 (44.2244 iter/s, 2.2612s/100 iters), loss = 0.562562
I1004 21:39:40.890064  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:39:40.890064  3812 solver.cpp:237]     Train net output #1: loss = 0.562562 (* 1 = 0.562562 loss)
I1004 21:39:40.890064  3812 sgd_solver.cpp:105] Iteration 37100, lr = 1e-06
I1004 21:39:43.160024  3812 solver.cpp:218] Iteration 37200 (44.22 iter/s, 2.26142s/100 iters), loss = 0.526364
I1004 21:39:43.160024  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:39:43.160024  3812 solver.cpp:237]     Train net output #1: loss = 0.526364 (* 1 = 0.526364 loss)
I1004 21:39:43.160024  3812 sgd_solver.cpp:105] Iteration 37200, lr = 1e-06
I1004 21:39:45.422616  3812 solver.cpp:218] Iteration 37300 (44.25 iter/s, 2.25989s/100 iters), loss = 0.500066
I1004 21:39:45.422616  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:39:45.422616  3812 solver.cpp:237]     Train net output #1: loss = 0.500066 (* 1 = 0.500066 loss)
I1004 21:39:45.422616  3812 sgd_solver.cpp:105] Iteration 37300, lr = 1e-06
I1004 21:39:47.681025  3812 solver.cpp:218] Iteration 37400 (44.2739 iter/s, 2.25867s/100 iters), loss = 0.449032
I1004 21:39:47.681025  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:39:47.681025  3812 solver.cpp:237]     Train net output #1: loss = 0.449032 (* 1 = 0.449032 loss)
I1004 21:39:47.681025  3812 sgd_solver.cpp:105] Iteration 37400, lr = 1e-06
I1004 21:39:49.828019 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:39:49.937394  3812 solver.cpp:218] Iteration 37500 (44.2704 iter/s, 2.25884s/100 iters), loss = 0.538767
I1004 21:39:49.937394  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:39:49.937394  3812 solver.cpp:237]     Train net output #1: loss = 0.538767 (* 1 = 0.538767 loss)
I1004 21:39:49.937394  3812 sgd_solver.cpp:105] Iteration 37500, lr = 1e-06
I1004 21:39:52.189904  3812 solver.cpp:218] Iteration 37600 (44.2512 iter/s, 2.25982s/100 iters), loss = 0.499591
I1004 21:39:52.189904  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:39:52.189904  3812 solver.cpp:237]     Train net output #1: loss = 0.499591 (* 1 = 0.499591 loss)
I1004 21:39:52.189904  3812 sgd_solver.cpp:105] Iteration 37600, lr = 1e-06
I1004 21:39:54.457206  3812 solver.cpp:218] Iteration 37700 (44.2699 iter/s, 2.25887s/100 iters), loss = 0.490998
I1004 21:39:54.457206  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:39:54.457206  3812 solver.cpp:237]     Train net output #1: loss = 0.490998 (* 1 = 0.490998 loss)
I1004 21:39:54.457206  3812 sgd_solver.cpp:105] Iteration 37700, lr = 1e-06
I1004 21:39:56.726570  3812 solver.cpp:218] Iteration 37800 (44.2016 iter/s, 2.26236s/100 iters), loss = 0.561177
I1004 21:39:56.726570  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:39:56.726570  3812 solver.cpp:237]     Train net output #1: loss = 0.561177 (* 1 = 0.561177 loss)
I1004 21:39:56.726570  3812 sgd_solver.cpp:105] Iteration 37800, lr = 1e-06
I1004 21:39:58.978080  3812 solver.cpp:218] Iteration 37900 (44.2737 iter/s, 2.25868s/100 iters), loss = 0.454856
I1004 21:39:58.978080  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:39:58.978080  3812 solver.cpp:237]     Train net output #1: loss = 0.454856 (* 1 = 0.454856 loss)
I1004 21:39:58.978080  3812 sgd_solver.cpp:105] Iteration 37900, lr = 1e-06
I1004 21:40:01.165062 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:40:01.261066  3812 solver.cpp:330] Iteration 38000, Testing net (#0)
I1004 21:40:01.261066  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:40:01.687472 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:40:01.703095  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7669
I1004 21:40:01.703095  3812 solver.cpp:397]     Test net output #1: loss = 0.677627 (* 1 = 0.677627 loss)
I1004 21:40:01.721073  3812 solver.cpp:218] Iteration 38000 (36.436 iter/s, 2.74454s/100 iters), loss = 0.538505
I1004 21:40:01.721073  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:40:01.721073  3812 solver.cpp:237]     Train net output #1: loss = 0.538505 (* 1 = 0.538505 loss)
I1004 21:40:01.721073  3812 sgd_solver.cpp:105] Iteration 38000, lr = 1e-06
I1004 21:40:03.984293  3812 solver.cpp:218] Iteration 38100 (44.1599 iter/s, 2.2645s/100 iters), loss = 0.485114
I1004 21:40:03.984293  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:40:03.984293  3812 solver.cpp:237]     Train net output #1: loss = 0.485114 (* 1 = 0.485114 loss)
I1004 21:40:03.984293  3812 sgd_solver.cpp:105] Iteration 38100, lr = 1e-06
I1004 21:40:06.261365  3812 solver.cpp:218] Iteration 38200 (44.1188 iter/s, 2.26661s/100 iters), loss = 0.517772
I1004 21:40:06.261365  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:40:06.261365  3812 solver.cpp:237]     Train net output #1: loss = 0.517772 (* 1 = 0.517772 loss)
I1004 21:40:06.261365  3812 sgd_solver.cpp:105] Iteration 38200, lr = 1e-06
I1004 21:40:08.519337  3812 solver.cpp:218] Iteration 38300 (44.2759 iter/s, 2.25857s/100 iters), loss = 0.48223
I1004 21:40:08.519337  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:40:08.519337  3812 solver.cpp:237]     Train net output #1: loss = 0.48223 (* 1 = 0.48223 loss)
I1004 21:40:08.519337  3812 sgd_solver.cpp:105] Iteration 38300, lr = 1e-06
I1004 21:40:10.769588  3812 solver.cpp:218] Iteration 38400 (44.2848 iter/s, 2.25811s/100 iters), loss = 0.432289
I1004 21:40:10.769588  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:40:10.769588  3812 solver.cpp:237]     Train net output #1: loss = 0.432289 (* 1 = 0.432289 loss)
I1004 21:40:10.769588  3812 sgd_solver.cpp:105] Iteration 38400, lr = 1e-06
I1004 21:40:12.931517 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:40:13.025269  3812 solver.cpp:218] Iteration 38500 (44.2498 iter/s, 2.2599s/100 iters), loss = 0.508737
I1004 21:40:13.025269  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:40:13.025269  3812 solver.cpp:237]     Train net output #1: loss = 0.508737 (* 1 = 0.508737 loss)
I1004 21:40:13.025269  3812 sgd_solver.cpp:105] Iteration 38500, lr = 1e-06
I1004 21:40:15.293292  3812 solver.cpp:218] Iteration 38600 (44.2124 iter/s, 2.26181s/100 iters), loss = 0.520123
I1004 21:40:15.293292  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:40:15.293292  3812 solver.cpp:237]     Train net output #1: loss = 0.520123 (* 1 = 0.520123 loss)
I1004 21:40:15.293292  3812 sgd_solver.cpp:105] Iteration 38600, lr = 1e-06
I1004 21:40:17.561638  3812 solver.cpp:218] Iteration 38700 (44.2335 iter/s, 2.26073s/100 iters), loss = 0.532904
I1004 21:40:17.561638  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:40:17.561638  3812 solver.cpp:237]     Train net output #1: loss = 0.532904 (* 1 = 0.532904 loss)
I1004 21:40:17.561638  3812 sgd_solver.cpp:105] Iteration 38700, lr = 1e-06
I1004 21:40:19.806751  3812 solver.cpp:218] Iteration 38800 (44.2912 iter/s, 2.25778s/100 iters), loss = 0.542321
I1004 21:40:19.806751  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:40:19.806751  3812 solver.cpp:237]     Train net output #1: loss = 0.542321 (* 1 = 0.542321 loss)
I1004 21:40:19.806751  3812 sgd_solver.cpp:105] Iteration 38800, lr = 1e-06
I1004 21:40:22.070963  3812 solver.cpp:218] Iteration 38900 (44.3164 iter/s, 2.2565s/100 iters), loss = 0.45257
I1004 21:40:22.070963  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:40:22.070963  3812 solver.cpp:237]     Train net output #1: loss = 0.45257 (* 1 = 0.45257 loss)
I1004 21:40:22.070963  3812 sgd_solver.cpp:105] Iteration 38900, lr = 1e-06
I1004 21:40:24.229358 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:40:24.307482  3812 solver.cpp:330] Iteration 39000, Testing net (#0)
I1004 21:40:24.307482  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:40:24.743510 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:40:24.759133  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7669
I1004 21:40:24.759133  3812 solver.cpp:397]     Test net output #1: loss = 0.677384 (* 1 = 0.677384 loss)
I1004 21:40:24.774760  3812 solver.cpp:218] Iteration 39000 (36.9522 iter/s, 2.7062s/100 iters), loss = 0.536667
I1004 21:40:24.774760  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:40:24.774760  3812 solver.cpp:237]     Train net output #1: loss = 0.536667 (* 1 = 0.536667 loss)
I1004 21:40:24.774760  3812 sgd_solver.cpp:105] Iteration 39000, lr = 1e-06
I1004 21:40:27.032634  3812 solver.cpp:218] Iteration 39100 (44.244 iter/s, 2.2602s/100 iters), loss = 0.511241
I1004 21:40:27.032634  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:40:27.032634  3812 solver.cpp:237]     Train net output #1: loss = 0.511241 (* 1 = 0.511241 loss)
I1004 21:40:27.032634  3812 sgd_solver.cpp:105] Iteration 39100, lr = 1e-06
I1004 21:40:29.301679  3812 solver.cpp:218] Iteration 39200 (44.2969 iter/s, 2.25749s/100 iters), loss = 0.551424
I1004 21:40:29.301679  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:40:29.301679  3812 solver.cpp:237]     Train net output #1: loss = 0.551424 (* 1 = 0.551424 loss)
I1004 21:40:29.301679  3812 sgd_solver.cpp:105] Iteration 39200, lr = 1e-06
I1004 21:40:31.546911  3812 solver.cpp:218] Iteration 39300 (44.3865 iter/s, 2.25294s/100 iters), loss = 0.521376
I1004 21:40:31.546911  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:40:31.546911  3812 solver.cpp:237]     Train net output #1: loss = 0.521376 (* 1 = 0.521376 loss)
I1004 21:40:31.546911  3812 sgd_solver.cpp:105] Iteration 39300, lr = 1e-06
I1004 21:40:33.808300  3812 solver.cpp:218] Iteration 39400 (44.4132 iter/s, 2.25158s/100 iters), loss = 0.462858
I1004 21:40:33.808300  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:40:33.808300  3812 solver.cpp:237]     Train net output #1: loss = 0.462858 (* 1 = 0.462858 loss)
I1004 21:40:33.808300  3812 sgd_solver.cpp:105] Iteration 39400, lr = 1e-06
I1004 21:40:35.944157 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:40:36.058085  3812 solver.cpp:218] Iteration 39500 (44.3347 iter/s, 2.25557s/100 iters), loss = 0.547273
I1004 21:40:36.058085  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:40:36.058085  3812 solver.cpp:237]     Train net output #1: loss = 0.547273 (* 1 = 0.547273 loss)
I1004 21:40:36.058085  3812 sgd_solver.cpp:105] Iteration 39500, lr = 1e-06
I1004 21:40:38.311653  3812 solver.cpp:218] Iteration 39600 (44.4031 iter/s, 2.25209s/100 iters), loss = 0.496679
I1004 21:40:38.311653  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:40:38.311653  3812 solver.cpp:237]     Train net output #1: loss = 0.496679 (* 1 = 0.496679 loss)
I1004 21:40:38.311653  3812 sgd_solver.cpp:105] Iteration 39600, lr = 1e-06
I1004 21:40:40.568739  3812 solver.cpp:218] Iteration 39700 (44.2644 iter/s, 2.25915s/100 iters), loss = 0.482618
I1004 21:40:40.568739  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:40:40.568739  3812 solver.cpp:237]     Train net output #1: loss = 0.482618 (* 1 = 0.482618 loss)
I1004 21:40:40.568739  3812 sgd_solver.cpp:105] Iteration 39700, lr = 1e-06
I1004 21:40:42.833832  3812 solver.cpp:218] Iteration 39800 (44.2753 iter/s, 2.2586s/100 iters), loss = 0.48732
I1004 21:40:42.833832  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:40:42.833832  3812 solver.cpp:237]     Train net output #1: loss = 0.48732 (* 1 = 0.48732 loss)
I1004 21:40:42.833832  3812 sgd_solver.cpp:105] Iteration 39800, lr = 1e-06
I1004 21:40:45.089608  3812 solver.cpp:218] Iteration 39900 (44.2916 iter/s, 2.25776s/100 iters), loss = 0.461537
I1004 21:40:45.089608  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:40:45.089608  3812 solver.cpp:237]     Train net output #1: loss = 0.461537 (* 1 = 0.461537 loss)
I1004 21:40:45.089608  3812 sgd_solver.cpp:105] Iteration 39900, lr = 1e-06
I1004 21:40:47.229826 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:40:47.327818  3812 solver.cpp:330] Iteration 40000, Testing net (#0)
I1004 21:40:47.327818  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:40:47.751137 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:40:47.766762  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7679
I1004 21:40:47.766762  3812 solver.cpp:397]     Test net output #1: loss = 0.677441 (* 1 = 0.677441 loss)
I1004 21:40:47.782387  3812 solver.cpp:218] Iteration 40000 (37.0609 iter/s, 2.69826s/100 iters), loss = 0.54147
I1004 21:40:47.782387  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:40:47.782387  3812 solver.cpp:237]     Train net output #1: loss = 0.54147 (* 1 = 0.54147 loss)
I1004 21:40:47.782387  3812 sgd_solver.cpp:105] Iteration 40000, lr = 1e-06
I1004 21:40:50.046056  3812 solver.cpp:218] Iteration 40100 (44.248 iter/s, 2.25999s/100 iters), loss = 0.48782
I1004 21:40:50.046056  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:40:50.046056  3812 solver.cpp:237]     Train net output #1: loss = 0.48782 (* 1 = 0.48782 loss)
I1004 21:40:50.046056  3812 sgd_solver.cpp:105] Iteration 40100, lr = 1e-06
I1004 21:40:52.306552  3812 solver.cpp:218] Iteration 40200 (44.2578 iter/s, 2.25949s/100 iters), loss = 0.494276
I1004 21:40:52.306552  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:40:52.306552  3812 solver.cpp:237]     Train net output #1: loss = 0.494276 (* 1 = 0.494276 loss)
I1004 21:40:52.306552  3812 sgd_solver.cpp:105] Iteration 40200, lr = 1e-06
I1004 21:40:54.562258  3812 solver.cpp:218] Iteration 40300 (44.3843 iter/s, 2.25305s/100 iters), loss = 0.528784
I1004 21:40:54.562258  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:40:54.562258  3812 solver.cpp:237]     Train net output #1: loss = 0.528784 (* 1 = 0.528784 loss)
I1004 21:40:54.562258  3812 sgd_solver.cpp:105] Iteration 40300, lr = 1e-06
I1004 21:40:56.820919  3812 solver.cpp:218] Iteration 40400 (44.2294 iter/s, 2.26094s/100 iters), loss = 0.485901
I1004 21:40:56.820919  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:40:56.820919  3812 solver.cpp:237]     Train net output #1: loss = 0.485901 (* 1 = 0.485901 loss)
I1004 21:40:56.820919  3812 sgd_solver.cpp:105] Iteration 40400, lr = 1e-06
I1004 21:40:58.970428 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:40:59.079803  3812 solver.cpp:218] Iteration 40500 (44.2905 iter/s, 2.25782s/100 iters), loss = 0.515773
I1004 21:40:59.079803  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:40:59.079803  3812 solver.cpp:237]     Train net output #1: loss = 0.515773 (* 1 = 0.515773 loss)
I1004 21:40:59.079803  3812 sgd_solver.cpp:105] Iteration 40500, lr = 1e-06
I1004 21:41:01.336654  3812 solver.cpp:218] Iteration 40600 (44.2621 iter/s, 2.25927s/100 iters), loss = 0.534231
I1004 21:41:01.336654  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:41:01.336654  3812 solver.cpp:237]     Train net output #1: loss = 0.534231 (* 1 = 0.534231 loss)
I1004 21:41:01.336654  3812 sgd_solver.cpp:105] Iteration 40600, lr = 1e-06
I1004 21:41:03.595824  3812 solver.cpp:218] Iteration 40700 (44.2367 iter/s, 2.26057s/100 iters), loss = 0.53593
I1004 21:41:03.595824  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:41:03.595824  3812 solver.cpp:237]     Train net output #1: loss = 0.53593 (* 1 = 0.53593 loss)
I1004 21:41:03.595824  3812 sgd_solver.cpp:105] Iteration 40700, lr = 1e-06
I1004 21:41:05.864605  3812 solver.cpp:218] Iteration 40800 (44.19 iter/s, 2.26295s/100 iters), loss = 0.506432
I1004 21:41:05.864605  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:41:05.864605  3812 solver.cpp:237]     Train net output #1: loss = 0.506432 (* 1 = 0.506432 loss)
I1004 21:41:05.864605  3812 sgd_solver.cpp:105] Iteration 40800, lr = 1e-06
I1004 21:41:08.111533  3812 solver.cpp:218] Iteration 40900 (44.3652 iter/s, 2.25402s/100 iters), loss = 0.470919
I1004 21:41:08.111533  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:41:08.111533  3812 solver.cpp:237]     Train net output #1: loss = 0.470919 (* 1 = 0.470919 loss)
I1004 21:41:08.111533  3812 sgd_solver.cpp:105] Iteration 40900, lr = 1e-06
I1004 21:41:10.256971 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:41:10.348240  3812 solver.cpp:330] Iteration 41000, Testing net (#0)
I1004 21:41:10.348240  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:41:10.787336 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:41:10.802961  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7677
I1004 21:41:10.802961  3812 solver.cpp:397]     Test net output #1: loss = 0.677426 (* 1 = 0.677426 loss)
I1004 21:41:10.826671  3812 solver.cpp:218] Iteration 41000 (36.9845 iter/s, 2.70383s/100 iters), loss = 0.480344
I1004 21:41:10.826671  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:41:10.826671  3812 solver.cpp:237]     Train net output #1: loss = 0.480344 (* 1 = 0.480344 loss)
I1004 21:41:10.826671  3812 sgd_solver.cpp:105] Iteration 41000, lr = 1e-06
I1004 21:41:13.078812  3812 solver.cpp:218] Iteration 41100 (44.2573 iter/s, 2.25952s/100 iters), loss = 0.496763
I1004 21:41:13.078812  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:41:13.078812  3812 solver.cpp:237]     Train net output #1: loss = 0.496763 (* 1 = 0.496763 loss)
I1004 21:41:13.078812  3812 sgd_solver.cpp:105] Iteration 41100, lr = 1e-06
I1004 21:41:15.345132  3812 solver.cpp:218] Iteration 41200 (44.2017 iter/s, 2.26236s/100 iters), loss = 0.515116
I1004 21:41:15.345132  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:41:15.345132  3812 solver.cpp:237]     Train net output #1: loss = 0.515116 (* 1 = 0.515116 loss)
I1004 21:41:15.345132  3812 sgd_solver.cpp:105] Iteration 41200, lr = 1e-06
I1004 21:41:17.601004  3812 solver.cpp:218] Iteration 41300 (44.203 iter/s, 2.26229s/100 iters), loss = 0.564125
I1004 21:41:17.601004  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:41:17.601004  3812 solver.cpp:237]     Train net output #1: loss = 0.564125 (* 1 = 0.564125 loss)
I1004 21:41:17.601004  3812 sgd_solver.cpp:105] Iteration 41300, lr = 1e-06
I1004 21:41:19.859889  3812 solver.cpp:218] Iteration 41400 (44.3532 iter/s, 2.25463s/100 iters), loss = 0.475776
I1004 21:41:19.859889  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:41:19.859889  3812 solver.cpp:237]     Train net output #1: loss = 0.475776 (* 1 = 0.475776 loss)
I1004 21:41:19.859889  3812 sgd_solver.cpp:105] Iteration 41400, lr = 1e-06
I1004 21:41:22.003216 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:41:22.112591  3812 solver.cpp:218] Iteration 41500 (44.2529 iter/s, 2.25974s/100 iters), loss = 0.494079
I1004 21:41:22.112591  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:41:22.112591  3812 solver.cpp:237]     Train net output #1: loss = 0.494079 (* 1 = 0.494079 loss)
I1004 21:41:22.112591  3812 sgd_solver.cpp:105] Iteration 41500, lr = 1e-06
I1004 21:41:24.375490  3812 solver.cpp:218] Iteration 41600 (44.2878 iter/s, 2.25796s/100 iters), loss = 0.542929
I1004 21:41:24.375490  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:41:24.375490  3812 solver.cpp:237]     Train net output #1: loss = 0.542929 (* 1 = 0.542929 loss)
I1004 21:41:24.375490  3812 sgd_solver.cpp:105] Iteration 41600, lr = 1e-06
I1004 21:41:26.633870  3812 solver.cpp:218] Iteration 41700 (44.2706 iter/s, 2.25884s/100 iters), loss = 0.491872
I1004 21:41:26.633870  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:41:26.633870  3812 solver.cpp:237]     Train net output #1: loss = 0.491872 (* 1 = 0.491872 loss)
I1004 21:41:26.633870  3812 sgd_solver.cpp:105] Iteration 41700, lr = 1e-06
I1004 21:41:28.896211  3812 solver.cpp:218] Iteration 41800 (44.2586 iter/s, 2.25945s/100 iters), loss = 0.511213
I1004 21:41:28.896211  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:41:28.896211  3812 solver.cpp:237]     Train net output #1: loss = 0.511213 (* 1 = 0.511213 loss)
I1004 21:41:28.896211  3812 sgd_solver.cpp:105] Iteration 41800, lr = 1e-06
I1004 21:41:31.166391  3812 solver.cpp:218] Iteration 41900 (44.1735 iter/s, 2.2638s/100 iters), loss = 0.461799
I1004 21:41:31.166391  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:41:31.166391  3812 solver.cpp:237]     Train net output #1: loss = 0.461799 (* 1 = 0.461799 loss)
I1004 21:41:31.166391  3812 sgd_solver.cpp:105] Iteration 41900, lr = 1e-06
I1004 21:41:33.308660 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:41:33.394584  3812 solver.cpp:330] Iteration 42000, Testing net (#0)
I1004 21:41:33.394584  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:41:33.833328 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:41:33.848953  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7678
I1004 21:41:33.848953  3812 solver.cpp:397]     Test net output #1: loss = 0.67733 (* 1 = 0.67733 loss)
I1004 21:41:33.864580  3812 solver.cpp:218] Iteration 42000 (36.9295 iter/s, 2.70786s/100 iters), loss = 0.568829
I1004 21:41:33.864580  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:41:33.864580  3812 solver.cpp:237]     Train net output #1: loss = 0.568829 (* 1 = 0.568829 loss)
I1004 21:41:33.864580  3812 sgd_solver.cpp:105] Iteration 42000, lr = 1e-06
I1004 21:41:36.129752  3812 solver.cpp:218] Iteration 42100 (44.2419 iter/s, 2.2603s/100 iters), loss = 0.52835
I1004 21:41:36.129752  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:41:36.129752  3812 solver.cpp:237]     Train net output #1: loss = 0.52835 (* 1 = 0.52835 loss)
I1004 21:41:36.129752  3812 sgd_solver.cpp:105] Iteration 42100, lr = 1e-06
I1004 21:41:38.396270  3812 solver.cpp:218] Iteration 42200 (44.2619 iter/s, 2.25928s/100 iters), loss = 0.521007
I1004 21:41:38.396270  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:41:38.396270  3812 solver.cpp:237]     Train net output #1: loss = 0.521007 (* 1 = 0.521007 loss)
I1004 21:41:38.396270  3812 sgd_solver.cpp:105] Iteration 42200, lr = 1e-06
I1004 21:41:40.646236  3812 solver.cpp:218] Iteration 42300 (44.2929 iter/s, 2.2577s/100 iters), loss = 0.549409
I1004 21:41:40.646236  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:41:40.646236  3812 solver.cpp:237]     Train net output #1: loss = 0.549409 (* 1 = 0.549409 loss)
I1004 21:41:40.646236  3812 sgd_solver.cpp:105] Iteration 42300, lr = 1e-06
I1004 21:41:42.896116  3812 solver.cpp:218] Iteration 42400 (44.3908 iter/s, 2.25272s/100 iters), loss = 0.42844
I1004 21:41:42.896116  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:41:42.896116  3812 solver.cpp:237]     Train net output #1: loss = 0.42844 (* 1 = 0.42844 loss)
I1004 21:41:42.896116  3812 sgd_solver.cpp:105] Iteration 42400, lr = 1e-06
I1004 21:41:45.081835 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:41:45.194834  3812 solver.cpp:218] Iteration 42500 (43.7207 iter/s, 2.28725s/100 iters), loss = 0.586796
I1004 21:41:45.194834  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:41:45.194834  3812 solver.cpp:237]     Train net output #1: loss = 0.586796 (* 1 = 0.586796 loss)
I1004 21:41:45.194834  3812 sgd_solver.cpp:105] Iteration 42500, lr = 1e-06
I1004 21:41:47.480188  3812 solver.cpp:218] Iteration 42600 (43.5465 iter/s, 2.2964s/100 iters), loss = 0.487416
I1004 21:41:47.480188  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:41:47.480188  3812 solver.cpp:237]     Train net output #1: loss = 0.487416 (* 1 = 0.487416 loss)
I1004 21:41:47.480188  3812 sgd_solver.cpp:105] Iteration 42600, lr = 1e-06
I1004 21:41:49.760820  3812 solver.cpp:218] Iteration 42700 (44.0679 iter/s, 2.26922s/100 iters), loss = 0.464276
I1004 21:41:49.761821  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:41:49.761821  3812 solver.cpp:237]     Train net output #1: loss = 0.464276 (* 1 = 0.464276 loss)
I1004 21:41:49.761821  3812 sgd_solver.cpp:105] Iteration 42700, lr = 1e-06
I1004 21:41:52.011546  3812 solver.cpp:218] Iteration 42800 (44.3039 iter/s, 2.25714s/100 iters), loss = 0.547585
I1004 21:41:52.011546  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:41:52.011546  3812 solver.cpp:237]     Train net output #1: loss = 0.547585 (* 1 = 0.547585 loss)
I1004 21:41:52.011546  3812 sgd_solver.cpp:105] Iteration 42800, lr = 1e-06
I1004 21:41:54.267623  3812 solver.cpp:218] Iteration 42900 (44.2602 iter/s, 2.25937s/100 iters), loss = 0.433286
I1004 21:41:54.267623  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:41:54.267623  3812 solver.cpp:237]     Train net output #1: loss = 0.433286 (* 1 = 0.433286 loss)
I1004 21:41:54.267623  3812 sgd_solver.cpp:105] Iteration 42900, lr = 1e-06
I1004 21:41:56.424119 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:41:56.511312  3812 solver.cpp:330] Iteration 43000, Testing net (#0)
I1004 21:41:56.511312  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:41:56.933509 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:41:56.949124  3812 solver.cpp:397]     Test net output #0: accuracy = 0.767
I1004 21:41:56.949124  3812 solver.cpp:397]     Test net output #1: loss = 0.677362 (* 1 = 0.677362 loss)
I1004 21:41:56.980376  3812 solver.cpp:218] Iteration 43000 (36.9784 iter/s, 2.70428s/100 iters), loss = 0.547347
I1004 21:41:56.980376  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:41:56.980376  3812 solver.cpp:237]     Train net output #1: loss = 0.547347 (* 1 = 0.547347 loss)
I1004 21:41:56.980376  3812 sgd_solver.cpp:105] Iteration 43000, lr = 1e-06
I1004 21:41:59.228577  3812 solver.cpp:218] Iteration 43100 (44.3793 iter/s, 2.2533s/100 iters), loss = 0.493068
I1004 21:41:59.228577  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:41:59.228577  3812 solver.cpp:237]     Train net output #1: loss = 0.493068 (* 1 = 0.493068 loss)
I1004 21:41:59.228577  3812 sgd_solver.cpp:105] Iteration 43100, lr = 1e-06
I1004 21:42:01.495818  3812 solver.cpp:218] Iteration 43200 (44.2442 iter/s, 2.26018s/100 iters), loss = 0.52849
I1004 21:42:01.495818  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:42:01.495818  3812 solver.cpp:237]     Train net output #1: loss = 0.52849 (* 1 = 0.52849 loss)
I1004 21:42:01.495818  3812 sgd_solver.cpp:105] Iteration 43200, lr = 1e-06
I1004 21:42:03.751770  3812 solver.cpp:218] Iteration 43300 (44.2981 iter/s, 2.25743s/100 iters), loss = 0.51518
I1004 21:42:03.751770  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:42:03.751770  3812 solver.cpp:237]     Train net output #1: loss = 0.51518 (* 1 = 0.51518 loss)
I1004 21:42:03.751770  3812 sgd_solver.cpp:105] Iteration 43300, lr = 1e-06
I1004 21:42:06.010725  3812 solver.cpp:218] Iteration 43400 (44.2942 iter/s, 2.25763s/100 iters), loss = 0.471606
I1004 21:42:06.010725  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:42:06.010725  3812 solver.cpp:237]     Train net output #1: loss = 0.471606 (* 1 = 0.471606 loss)
I1004 21:42:06.010725  3812 sgd_solver.cpp:105] Iteration 43400, lr = 1e-06
I1004 21:42:08.142117 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:42:08.251492  3812 solver.cpp:218] Iteration 43500 (44.3911 iter/s, 2.25271s/100 iters), loss = 0.565175
I1004 21:42:08.251492  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:42:08.251492  3812 solver.cpp:237]     Train net output #1: loss = 0.565175 (* 1 = 0.565175 loss)
I1004 21:42:08.251492  3812 sgd_solver.cpp:105] Iteration 43500, lr = 1e-06
I1004 21:42:10.511061  3812 solver.cpp:218] Iteration 43600 (44.3696 iter/s, 2.25379s/100 iters), loss = 0.508971
I1004 21:42:10.511061  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:42:10.511061  3812 solver.cpp:237]     Train net output #1: loss = 0.508971 (* 1 = 0.508971 loss)
I1004 21:42:10.511061  3812 sgd_solver.cpp:105] Iteration 43600, lr = 1e-06
I1004 21:42:12.767961  3812 solver.cpp:218] Iteration 43700 (44.27 iter/s, 2.25887s/100 iters), loss = 0.492233
I1004 21:42:12.767961  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:42:12.767961  3812 solver.cpp:237]     Train net output #1: loss = 0.492233 (* 1 = 0.492233 loss)
I1004 21:42:12.767961  3812 sgd_solver.cpp:105] Iteration 43700, lr = 1e-06
I1004 21:42:15.026334  3812 solver.cpp:218] Iteration 43800 (44.4007 iter/s, 2.25222s/100 iters), loss = 0.532536
I1004 21:42:15.026334  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:42:15.026334  3812 solver.cpp:237]     Train net output #1: loss = 0.532536 (* 1 = 0.532536 loss)
I1004 21:42:15.026334  3812 sgd_solver.cpp:105] Iteration 43800, lr = 1e-06
I1004 21:42:17.276304  3812 solver.cpp:218] Iteration 43900 (44.3154 iter/s, 2.25655s/100 iters), loss = 0.423427
I1004 21:42:17.276304  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:42:17.276304  3812 solver.cpp:237]     Train net output #1: loss = 0.423427 (* 1 = 0.423427 loss)
I1004 21:42:17.276304  3812 sgd_solver.cpp:105] Iteration 43900, lr = 1e-06
I1004 21:42:19.434491 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:42:19.512617  3812 solver.cpp:330] Iteration 44000, Testing net (#0)
I1004 21:42:19.512617  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:42:19.948731 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:42:19.964357  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7674
I1004 21:42:19.964357  3812 solver.cpp:397]     Test net output #1: loss = 0.677483 (* 1 = 0.677483 loss)
I1004 21:42:19.979982  3812 solver.cpp:218] Iteration 44000 (36.9838 iter/s, 2.70389s/100 iters), loss = 0.552361
I1004 21:42:19.979982  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:42:19.979982  3812 solver.cpp:237]     Train net output #1: loss = 0.552361 (* 1 = 0.552361 loss)
I1004 21:42:19.979982  3812 sgd_solver.cpp:105] Iteration 44000, lr = 1e-06
I1004 21:42:22.246642  3812 solver.cpp:218] Iteration 44100 (44.1905 iter/s, 2.26293s/100 iters), loss = 0.473399
I1004 21:42:22.246642  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:42:22.246642  3812 solver.cpp:237]     Train net output #1: loss = 0.473399 (* 1 = 0.473399 loss)
I1004 21:42:22.246642  3812 sgd_solver.cpp:105] Iteration 44100, lr = 1e-06
I1004 21:42:24.511724  3812 solver.cpp:218] Iteration 44200 (44.3364 iter/s, 2.25548s/100 iters), loss = 0.467053
I1004 21:42:24.511724  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:42:24.511724  3812 solver.cpp:237]     Train net output #1: loss = 0.467053 (* 1 = 0.467053 loss)
I1004 21:42:24.511724  3812 sgd_solver.cpp:105] Iteration 44200, lr = 1e-06
I1004 21:42:26.767850  3812 solver.cpp:218] Iteration 44300 (44.2085 iter/s, 2.26201s/100 iters), loss = 0.528489
I1004 21:42:26.767850  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:42:26.767850  3812 solver.cpp:237]     Train net output #1: loss = 0.528489 (* 1 = 0.528489 loss)
I1004 21:42:26.767850  3812 sgd_solver.cpp:105] Iteration 44300, lr = 1e-06
I1004 21:42:29.026499  3812 solver.cpp:218] Iteration 44400 (44.3285 iter/s, 2.25589s/100 iters), loss = 0.423288
I1004 21:42:29.026499  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:42:29.026499  3812 solver.cpp:237]     Train net output #1: loss = 0.423288 (* 1 = 0.423288 loss)
I1004 21:42:29.026499  3812 sgd_solver.cpp:105] Iteration 44400, lr = 1e-06
I1004 21:42:31.167510 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:42:31.276885  3812 solver.cpp:218] Iteration 44500 (44.2791 iter/s, 2.2584s/100 iters), loss = 0.512308
I1004 21:42:31.276885  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:42:31.276885  3812 solver.cpp:237]     Train net output #1: loss = 0.512308 (* 1 = 0.512308 loss)
I1004 21:42:31.276885  3812 sgd_solver.cpp:105] Iteration 44500, lr = 1e-06
I1004 21:42:33.533048  3812 solver.cpp:218] Iteration 44600 (44.2769 iter/s, 2.25851s/100 iters), loss = 0.593943
I1004 21:42:33.533048  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 21:42:33.533048  3812 solver.cpp:237]     Train net output #1: loss = 0.593943 (* 1 = 0.593943 loss)
I1004 21:42:33.533048  3812 sgd_solver.cpp:105] Iteration 44600, lr = 1e-06
I1004 21:42:35.799789  3812 solver.cpp:218] Iteration 44700 (44.2734 iter/s, 2.25869s/100 iters), loss = 0.598458
I1004 21:42:35.799789  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:42:35.799789  3812 solver.cpp:237]     Train net output #1: loss = 0.598458 (* 1 = 0.598458 loss)
I1004 21:42:35.799789  3812 sgd_solver.cpp:105] Iteration 44700, lr = 1e-06
I1004 21:42:38.058696  3812 solver.cpp:218] Iteration 44800 (44.305 iter/s, 2.25708s/100 iters), loss = 0.49994
I1004 21:42:38.058696  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:42:38.058696  3812 solver.cpp:237]     Train net output #1: loss = 0.49994 (* 1 = 0.49994 loss)
I1004 21:42:38.058696  3812 sgd_solver.cpp:105] Iteration 44800, lr = 1e-06
I1004 21:42:40.321173  3812 solver.cpp:218] Iteration 44900 (44.3028 iter/s, 2.25719s/100 iters), loss = 0.472234
I1004 21:42:40.322173  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:42:40.322173  3812 solver.cpp:237]     Train net output #1: loss = 0.472234 (* 1 = 0.472234 loss)
I1004 21:42:40.322173  3812 sgd_solver.cpp:105] Iteration 44900, lr = 1e-06
I1004 21:42:42.461493 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:42:42.555241  3812 solver.cpp:330] Iteration 45000, Testing net (#0)
I1004 21:42:42.555241  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:42:42.980154 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:42:42.995779  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7672
I1004 21:42:42.995779  3812 solver.cpp:397]     Test net output #1: loss = 0.677472 (* 1 = 0.677472 loss)
I1004 21:42:43.027029  3812 solver.cpp:218] Iteration 45000 (36.9347 iter/s, 2.70748s/100 iters), loss = 0.505802
I1004 21:42:43.027029  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:42:43.027029  3812 solver.cpp:237]     Train net output #1: loss = 0.505802 (* 1 = 0.505802 loss)
I1004 21:42:43.027029  3812 sgd_solver.cpp:105] Iteration 45000, lr = 1e-06
I1004 21:42:45.288713  3812 solver.cpp:218] Iteration 45100 (44.2741 iter/s, 2.25866s/100 iters), loss = 0.508602
I1004 21:42:45.288713  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:42:45.288713  3812 solver.cpp:237]     Train net output #1: loss = 0.508602 (* 1 = 0.508602 loss)
I1004 21:42:45.288713  3812 sgd_solver.cpp:105] Iteration 45100, lr = 1e-06
I1004 21:42:47.545750  3812 solver.cpp:218] Iteration 45200 (44.1564 iter/s, 2.26468s/100 iters), loss = 0.520361
I1004 21:42:47.545750  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:42:47.545750  3812 solver.cpp:237]     Train net output #1: loss = 0.520361 (* 1 = 0.520361 loss)
I1004 21:42:47.545750  3812 sgd_solver.cpp:105] Iteration 45200, lr = 1e-06
I1004 21:42:49.802026  3812 solver.cpp:218] Iteration 45300 (44.3266 iter/s, 2.25598s/100 iters), loss = 0.525932
I1004 21:42:49.802026  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:42:49.802026  3812 solver.cpp:237]     Train net output #1: loss = 0.525932 (* 1 = 0.525932 loss)
I1004 21:42:49.802026  3812 sgd_solver.cpp:105] Iteration 45300, lr = 1e-06
I1004 21:42:52.057809  3812 solver.cpp:218] Iteration 45400 (44.3189 iter/s, 2.25637s/100 iters), loss = 0.458242
I1004 21:42:52.057809  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:42:52.057809  3812 solver.cpp:237]     Train net output #1: loss = 0.458242 (* 1 = 0.458242 loss)
I1004 21:42:52.057809  3812 sgd_solver.cpp:105] Iteration 45400, lr = 1e-06
I1004 21:42:54.214527 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:42:54.327836  3812 solver.cpp:218] Iteration 45500 (44.2398 iter/s, 2.26041s/100 iters), loss = 0.450875
I1004 21:42:54.327836  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:42:54.327836  3812 solver.cpp:237]     Train net output #1: loss = 0.450875 (* 1 = 0.450875 loss)
I1004 21:42:54.327836  3812 sgd_solver.cpp:105] Iteration 45500, lr = 1e-06
I1004 21:42:56.577494  3812 solver.cpp:218] Iteration 45600 (44.2009 iter/s, 2.2624s/100 iters), loss = 0.459385
I1004 21:42:56.577494  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:42:56.577494  3812 solver.cpp:237]     Train net output #1: loss = 0.459385 (* 1 = 0.459385 loss)
I1004 21:42:56.577494  3812 sgd_solver.cpp:105] Iteration 45600, lr = 1e-06
I1004 21:42:58.846675  3812 solver.cpp:218] Iteration 45700 (44.2499 iter/s, 2.25989s/100 iters), loss = 0.493045
I1004 21:42:58.846675  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:42:58.846675  3812 solver.cpp:237]     Train net output #1: loss = 0.493045 (* 1 = 0.493045 loss)
I1004 21:42:58.846675  3812 sgd_solver.cpp:105] Iteration 45700, lr = 1e-06
I1004 21:43:01.101289  3812 solver.cpp:218] Iteration 45800 (44.2089 iter/s, 2.26199s/100 iters), loss = 0.53867
I1004 21:43:01.101289  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:43:01.101289  3812 solver.cpp:237]     Train net output #1: loss = 0.53867 (* 1 = 0.53867 loss)
I1004 21:43:01.101289  3812 sgd_solver.cpp:105] Iteration 45800, lr = 1e-06
I1004 21:43:03.369566  3812 solver.cpp:218] Iteration 45900 (44.2371 iter/s, 2.26054s/100 iters), loss = 0.426524
I1004 21:43:03.369566  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:43:03.369566  3812 solver.cpp:237]     Train net output #1: loss = 0.426524 (* 1 = 0.426524 loss)
I1004 21:43:03.369566  3812 sgd_solver.cpp:105] Iteration 45900, lr = 1e-06
I1004 21:43:05.525158 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:43:05.612488  3812 solver.cpp:330] Iteration 46000, Testing net (#0)
I1004 21:43:05.612488  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:43:06.043311 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:43:06.058936  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7675
I1004 21:43:06.058936  3812 solver.cpp:397]     Test net output #1: loss = 0.677474 (* 1 = 0.677474 loss)
I1004 21:43:06.074561  3812 solver.cpp:218] Iteration 46000 (36.8425 iter/s, 2.71426s/100 iters), loss = 0.609358
I1004 21:43:06.074561  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:43:06.074561  3812 solver.cpp:237]     Train net output #1: loss = 0.609358 (* 1 = 0.609358 loss)
I1004 21:43:06.074561  3812 sgd_solver.cpp:105] Iteration 46000, lr = 1e-06
I1004 21:43:08.350035  3812 solver.cpp:218] Iteration 46100 (44.217 iter/s, 2.26157s/100 iters), loss = 0.471067
I1004 21:43:08.350035  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:43:08.350035  3812 solver.cpp:237]     Train net output #1: loss = 0.471067 (* 1 = 0.471067 loss)
I1004 21:43:08.350035  3812 sgd_solver.cpp:105] Iteration 46100, lr = 1e-06
I1004 21:43:10.607419  3812 solver.cpp:218] Iteration 46200 (44.2546 iter/s, 2.25965s/100 iters), loss = 0.496295
I1004 21:43:10.607419  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:43:10.607419  3812 solver.cpp:237]     Train net output #1: loss = 0.496295 (* 1 = 0.496295 loss)
I1004 21:43:10.607419  3812 sgd_solver.cpp:105] Iteration 46200, lr = 1e-06
I1004 21:43:12.871078  3812 solver.cpp:218] Iteration 46300 (44.2214 iter/s, 2.26135s/100 iters), loss = 0.512731
I1004 21:43:12.871078  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:43:12.871078  3812 solver.cpp:237]     Train net output #1: loss = 0.512731 (* 1 = 0.512731 loss)
I1004 21:43:12.871078  3812 sgd_solver.cpp:105] Iteration 46300, lr = 1e-06
I1004 21:43:15.120558  3812 solver.cpp:218] Iteration 46400 (44.2988 iter/s, 2.2574s/100 iters), loss = 0.490424
I1004 21:43:15.120558  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:43:15.120558  3812 solver.cpp:237]     Train net output #1: loss = 0.490424 (* 1 = 0.490424 loss)
I1004 21:43:15.120558  3812 sgd_solver.cpp:105] Iteration 46400, lr = 1e-06
I1004 21:43:17.276629 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:43:17.385535  3812 solver.cpp:218] Iteration 46500 (44.1846 iter/s, 2.26323s/100 iters), loss = 0.471303
I1004 21:43:17.385535  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:43:17.385535  3812 solver.cpp:237]     Train net output #1: loss = 0.471303 (* 1 = 0.471303 loss)
I1004 21:43:17.385535  3812 sgd_solver.cpp:105] Iteration 46500, lr = 1e-06
I1004 21:43:19.651556  3812 solver.cpp:218] Iteration 46600 (44.1651 iter/s, 2.26423s/100 iters), loss = 0.523614
I1004 21:43:19.651556  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:43:19.651556  3812 solver.cpp:237]     Train net output #1: loss = 0.523614 (* 1 = 0.523614 loss)
I1004 21:43:19.651556  3812 sgd_solver.cpp:105] Iteration 46600, lr = 1e-06
I1004 21:43:21.895056  3812 solver.cpp:218] Iteration 46700 (44.3992 iter/s, 2.25229s/100 iters), loss = 0.480024
I1004 21:43:21.910694  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:43:21.910694  3812 solver.cpp:237]     Train net output #1: loss = 0.480024 (* 1 = 0.480024 loss)
I1004 21:43:21.910694  3812 sgd_solver.cpp:105] Iteration 46700, lr = 1e-06
I1004 21:43:24.167440  3812 solver.cpp:218] Iteration 46800 (44.2571 iter/s, 2.25952s/100 iters), loss = 0.548644
I1004 21:43:24.167440  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:43:24.167440  3812 solver.cpp:237]     Train net output #1: loss = 0.548644 (* 1 = 0.548644 loss)
I1004 21:43:24.167440  3812 sgd_solver.cpp:105] Iteration 46800, lr = 1e-06
I1004 21:43:26.432744  3812 solver.cpp:218] Iteration 46900 (44.0862 iter/s, 2.26828s/100 iters), loss = 0.487238
I1004 21:43:26.432744  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:43:26.432744  3812 solver.cpp:237]     Train net output #1: loss = 0.487238 (* 1 = 0.487238 loss)
I1004 21:43:26.432744  3812 sgd_solver.cpp:105] Iteration 46900, lr = 1e-06
I1004 21:43:28.573809 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:43:28.667559  3812 solver.cpp:330] Iteration 47000, Testing net (#0)
I1004 21:43:28.667559  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:43:29.104602 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:43:29.120214  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7673
I1004 21:43:29.120214  3812 solver.cpp:397]     Test net output #1: loss = 0.67745 (* 1 = 0.67745 loss)
I1004 21:43:29.135841  3812 solver.cpp:218] Iteration 47000 (36.9485 iter/s, 2.70647s/100 iters), loss = 0.498392
I1004 21:43:29.135841  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:43:29.135841  3812 solver.cpp:237]     Train net output #1: loss = 0.498392 (* 1 = 0.498392 loss)
I1004 21:43:29.135841  3812 sgd_solver.cpp:105] Iteration 47000, lr = 1e-06
I1004 21:43:31.402264  3812 solver.cpp:218] Iteration 47100 (44.3172 iter/s, 2.25646s/100 iters), loss = 0.527263
I1004 21:43:31.402264  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:43:31.402264  3812 solver.cpp:237]     Train net output #1: loss = 0.527263 (* 1 = 0.527263 loss)
I1004 21:43:31.402264  3812 sgd_solver.cpp:105] Iteration 47100, lr = 1e-06
I1004 21:43:33.661964  3812 solver.cpp:218] Iteration 47200 (44.2548 iter/s, 2.25964s/100 iters), loss = 0.516467
I1004 21:43:33.661964  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:43:33.661964  3812 solver.cpp:237]     Train net output #1: loss = 0.516467 (* 1 = 0.516467 loss)
I1004 21:43:33.661964  3812 sgd_solver.cpp:105] Iteration 47200, lr = 1e-06
I1004 21:43:35.918391  3812 solver.cpp:218] Iteration 47300 (44.3284 iter/s, 2.25589s/100 iters), loss = 0.519894
I1004 21:43:35.918391  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:43:35.918391  3812 solver.cpp:237]     Train net output #1: loss = 0.519894 (* 1 = 0.519894 loss)
I1004 21:43:35.918391  3812 sgd_solver.cpp:105] Iteration 47300, lr = 1e-06
I1004 21:43:38.167663  3812 solver.cpp:218] Iteration 47400 (44.3958 iter/s, 2.25247s/100 iters), loss = 0.494989
I1004 21:43:38.167663  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:43:38.167663  3812 solver.cpp:237]     Train net output #1: loss = 0.494989 (* 1 = 0.494989 loss)
I1004 21:43:38.167663  3812 sgd_solver.cpp:105] Iteration 47400, lr = 1e-06
I1004 21:43:40.307723 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:43:40.429519  3812 solver.cpp:218] Iteration 47500 (44.2801 iter/s, 2.25835s/100 iters), loss = 0.54675
I1004 21:43:40.429519  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:43:40.429519  3812 solver.cpp:237]     Train net output #1: loss = 0.54675 (* 1 = 0.54675 loss)
I1004 21:43:40.429519  3812 sgd_solver.cpp:105] Iteration 47500, lr = 1e-06
I1004 21:43:42.682974  3812 solver.cpp:218] Iteration 47600 (44.3564 iter/s, 2.25447s/100 iters), loss = 0.571198
I1004 21:43:42.682974  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:43:42.682974  3812 solver.cpp:237]     Train net output #1: loss = 0.571198 (* 1 = 0.571198 loss)
I1004 21:43:42.682974  3812 sgd_solver.cpp:105] Iteration 47600, lr = 1e-06
I1004 21:43:44.933099  3812 solver.cpp:218] Iteration 47700 (44.2919 iter/s, 2.25775s/100 iters), loss = 0.58243
I1004 21:43:44.933099  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:43:44.933099  3812 solver.cpp:237]     Train net output #1: loss = 0.58243 (* 1 = 0.58243 loss)
I1004 21:43:44.933099  3812 sgd_solver.cpp:105] Iteration 47700, lr = 1e-06
I1004 21:43:47.198398  3812 solver.cpp:218] Iteration 47800 (44.2797 iter/s, 2.25837s/100 iters), loss = 0.54941
I1004 21:43:47.198398  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:43:47.198398  3812 solver.cpp:237]     Train net output #1: loss = 0.54941 (* 1 = 0.54941 loss)
I1004 21:43:47.198398  3812 sgd_solver.cpp:105] Iteration 47800, lr = 1e-06
I1004 21:43:49.449013  3812 solver.cpp:218] Iteration 47900 (44.3723 iter/s, 2.25366s/100 iters), loss = 0.4767
I1004 21:43:49.449013  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:43:49.449013  3812 solver.cpp:237]     Train net output #1: loss = 0.4767 (* 1 = 0.4767 loss)
I1004 21:43:49.449013  3812 sgd_solver.cpp:105] Iteration 47900, lr = 1e-06
I1004 21:43:51.592720 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:43:51.682045  3812 solver.cpp:330] Iteration 48000, Testing net (#0)
I1004 21:43:51.682045  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:43:52.121598 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:43:52.137220  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7674
I1004 21:43:52.137220  3812 solver.cpp:397]     Test net output #1: loss = 0.677429 (* 1 = 0.677429 loss)
I1004 21:43:52.152846  3812 solver.cpp:218] Iteration 48000 (36.9662 iter/s, 2.70518s/100 iters), loss = 0.578228
I1004 21:43:52.152846  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:43:52.152846  3812 solver.cpp:237]     Train net output #1: loss = 0.578228 (* 1 = 0.578228 loss)
I1004 21:43:52.152846  3812 sgd_solver.cpp:105] Iteration 48000, lr = 1e-06
I1004 21:43:54.425077  3812 solver.cpp:218] Iteration 48100 (44.1793 iter/s, 2.2635s/100 iters), loss = 0.466102
I1004 21:43:54.425077  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:43:54.425077  3812 solver.cpp:237]     Train net output #1: loss = 0.466102 (* 1 = 0.466102 loss)
I1004 21:43:54.425077  3812 sgd_solver.cpp:105] Iteration 48100, lr = 1e-06
I1004 21:43:56.667892  3812 solver.cpp:218] Iteration 48200 (44.3482 iter/s, 2.25488s/100 iters), loss = 0.529369
I1004 21:43:56.667892  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:43:56.667892  3812 solver.cpp:237]     Train net output #1: loss = 0.529369 (* 1 = 0.529369 loss)
I1004 21:43:56.667892  3812 sgd_solver.cpp:105] Iteration 48200, lr = 1e-06
I1004 21:43:58.932771  3812 solver.cpp:218] Iteration 48300 (44.2752 iter/s, 2.2586s/100 iters), loss = 0.569699
I1004 21:43:58.932771  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:43:58.932771  3812 solver.cpp:237]     Train net output #1: loss = 0.569699 (* 1 = 0.569699 loss)
I1004 21:43:58.932771  3812 sgd_solver.cpp:105] Iteration 48300, lr = 1e-06
I1004 21:44:01.183621  3812 solver.cpp:218] Iteration 48400 (44.254 iter/s, 2.25968s/100 iters), loss = 0.525525
I1004 21:44:01.199247  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:44:01.199247  3812 solver.cpp:237]     Train net output #1: loss = 0.525525 (* 1 = 0.525525 loss)
I1004 21:44:01.199247  3812 sgd_solver.cpp:105] Iteration 48400, lr = 1e-06
I1004 21:44:03.345010 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:44:03.448972  3812 solver.cpp:218] Iteration 48500 (44.3411 iter/s, 2.25524s/100 iters), loss = 0.583462
I1004 21:44:03.448972  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:44:03.448972  3812 solver.cpp:237]     Train net output #1: loss = 0.583462 (* 1 = 0.583462 loss)
I1004 21:44:03.448972  3812 sgd_solver.cpp:105] Iteration 48500, lr = 1e-06
I1004 21:44:05.701120  3812 solver.cpp:218] Iteration 48600 (44.2656 iter/s, 2.25909s/100 iters), loss = 0.482318
I1004 21:44:05.701120  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:44:05.701120  3812 solver.cpp:237]     Train net output #1: loss = 0.482318 (* 1 = 0.482318 loss)
I1004 21:44:05.701120  3812 sgd_solver.cpp:105] Iteration 48600, lr = 1e-06
I1004 21:44:07.965476  3812 solver.cpp:218] Iteration 48700 (44.3135 iter/s, 2.25665s/100 iters), loss = 0.524137
I1004 21:44:07.965476  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:44:07.965476  3812 solver.cpp:237]     Train net output #1: loss = 0.524137 (* 1 = 0.524137 loss)
I1004 21:44:07.965476  3812 sgd_solver.cpp:105] Iteration 48700, lr = 1e-06
I1004 21:44:10.224268  3812 solver.cpp:218] Iteration 48800 (44.3644 iter/s, 2.25406s/100 iters), loss = 0.547784
I1004 21:44:10.224268  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:44:10.224268  3812 solver.cpp:237]     Train net output #1: loss = 0.547784 (* 1 = 0.547784 loss)
I1004 21:44:10.224268  3812 sgd_solver.cpp:105] Iteration 48800, lr = 1e-06
I1004 21:44:12.479737  3812 solver.cpp:218] Iteration 48900 (44.3043 iter/s, 2.25712s/100 iters), loss = 0.489839
I1004 21:44:12.479737  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:44:12.479737  3812 solver.cpp:237]     Train net output #1: loss = 0.489839 (* 1 = 0.489839 loss)
I1004 21:44:12.479737  3812 sgd_solver.cpp:105] Iteration 48900, lr = 1e-06
I1004 21:44:14.620908 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:44:14.714658  3812 solver.cpp:330] Iteration 49000, Testing net (#0)
I1004 21:44:14.714658  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:44:15.136642 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:44:15.152268  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7668
I1004 21:44:15.152268  3812 solver.cpp:397]     Test net output #1: loss = 0.677556 (* 1 = 0.677556 loss)
I1004 21:44:15.183519  3812 solver.cpp:218] Iteration 49000 (37.02 iter/s, 2.70124s/100 iters), loss = 0.509616
I1004 21:44:15.183519  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:44:15.183519  3812 solver.cpp:237]     Train net output #1: loss = 0.509616 (* 1 = 0.509616 loss)
I1004 21:44:15.183519  3812 sgd_solver.cpp:105] Iteration 49000, lr = 1e-06
I1004 21:44:17.434353  3812 solver.cpp:218] Iteration 49100 (44.3257 iter/s, 2.25603s/100 iters), loss = 0.459077
I1004 21:44:17.434353  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:44:17.434353  3812 solver.cpp:237]     Train net output #1: loss = 0.459077 (* 1 = 0.459077 loss)
I1004 21:44:17.434353  3812 sgd_solver.cpp:105] Iteration 49100, lr = 1e-06
I1004 21:44:19.698936  3812 solver.cpp:218] Iteration 49200 (44.1283 iter/s, 2.26612s/100 iters), loss = 0.506985
I1004 21:44:19.698936  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:44:19.698936  3812 solver.cpp:237]     Train net output #1: loss = 0.506985 (* 1 = 0.506985 loss)
I1004 21:44:19.698936  3812 sgd_solver.cpp:105] Iteration 49200, lr = 1e-06
I1004 21:44:21.948864  3812 solver.cpp:218] Iteration 49300 (44.3406 iter/s, 2.25527s/100 iters), loss = 0.544297
I1004 21:44:21.948864  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:44:21.948864  3812 solver.cpp:237]     Train net output #1: loss = 0.544297 (* 1 = 0.544297 loss)
I1004 21:44:21.948864  3812 sgd_solver.cpp:105] Iteration 49300, lr = 1e-06
I1004 21:44:24.212879  3812 solver.cpp:218] Iteration 49400 (44.1569 iter/s, 2.26465s/100 iters), loss = 0.423959
I1004 21:44:24.212879  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:44:24.212879  3812 solver.cpp:237]     Train net output #1: loss = 0.423959 (* 1 = 0.423959 loss)
I1004 21:44:24.212879  3812 sgd_solver.cpp:105] Iteration 49400, lr = 1e-06
I1004 21:44:26.372071 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:44:26.480032  3812 solver.cpp:218] Iteration 49500 (44.224 iter/s, 2.26122s/100 iters), loss = 0.50017
I1004 21:44:26.480032  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:44:26.480032  3812 solver.cpp:237]     Train net output #1: loss = 0.50017 (* 1 = 0.50017 loss)
I1004 21:44:26.480032  3812 sgd_solver.cpp:105] Iteration 49500, lr = 1e-06
I1004 21:44:28.751437  3812 solver.cpp:218] Iteration 49600 (44.213 iter/s, 2.26178s/100 iters), loss = 0.523558
I1004 21:44:28.751437  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:44:28.751437  3812 solver.cpp:237]     Train net output #1: loss = 0.523558 (* 1 = 0.523558 loss)
I1004 21:44:28.751437  3812 sgd_solver.cpp:105] Iteration 49600, lr = 1e-06
I1004 21:44:31.010968  3812 solver.cpp:218] Iteration 49700 (44.1899 iter/s, 2.26296s/100 iters), loss = 0.535228
I1004 21:44:31.010968  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:44:31.010968  3812 solver.cpp:237]     Train net output #1: loss = 0.535228 (* 1 = 0.535228 loss)
I1004 21:44:31.010968  3812 sgd_solver.cpp:105] Iteration 49700, lr = 1e-06
I1004 21:44:33.261267  3812 solver.cpp:218] Iteration 49800 (44.2687 iter/s, 2.25893s/100 iters), loss = 0.490335
I1004 21:44:33.261267  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:44:33.261267  3812 solver.cpp:237]     Train net output #1: loss = 0.490335 (* 1 = 0.490335 loss)
I1004 21:44:33.261267  3812 sgd_solver.cpp:105] Iteration 49800, lr = 1e-06
I1004 21:44:35.527115  3812 solver.cpp:218] Iteration 49900 (44.3067 iter/s, 2.25699s/100 iters), loss = 0.440971
I1004 21:44:35.527115  3812 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:44:35.527115  3812 solver.cpp:237]     Train net output #1: loss = 0.440971 (* 1 = 0.440971 loss)
I1004 21:44:35.527115  3812 sgd_solver.cpp:105] Iteration 49900, lr = 1e-06
I1004 21:44:37.683586 16840 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:44:37.771569  3812 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/slimnet_simpnet_P3_iter_50000.caffemodel
I1004 21:44:37.771569  3812 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_simpnet_P3_iter_50000.solverstate
I1004 21:44:37.787195  3812 solver.cpp:310] Iteration 50000, loss = 0.519607
I1004 21:44:37.787195  3812 solver.cpp:330] Iteration 50000, Testing net (#0)
I1004 21:44:37.787195  3812 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:44:38.216223 17180 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:44:38.231848  3812 solver.cpp:397]     Test net output #0: accuracy = 0.7671
I1004 21:44:38.231848  3812 solver.cpp:397]     Test net output #1: loss = 0.677278 (* 1 = 0.677278 loss)
I1004 21:44:38.231848  3812 solver.cpp:315] Optimization Done.
I1004 21:44:38.231848  3812 caffe.cpp:260] Optimization Done.

G:\Caffe>pause
Press any key to continue . . . 
