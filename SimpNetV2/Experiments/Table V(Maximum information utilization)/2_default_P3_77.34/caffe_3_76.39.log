
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I1004 22:49:57.393002 15924 caffe.cpp:219] Using GPUs 0
I1004 22:49:57.564898 15924 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1004 22:49:57.861752 15924 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 22:49:57.877391 15924 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 25000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 25000
snapshot_prefix: "examples/cifar10/slimnet_simpnet_P3"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 25000
type: "Nesterov"
I1004 22:49:57.908664 15924 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 22:49:57.908664 15924 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 22:49:57.908664 15924 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1004 22:49:57.908664 15924 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1004 22:49:57.908664 15924 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P3__"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1004 22:49:57.971139 15924 layer_factory.cpp:58] Creating layer cifar
I1004 22:49:57.986757 15924 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I1004 22:49:57.986757 15924 net.cpp:84] Creating Layer cifar
I1004 22:49:57.986757 15924 net.cpp:380] cifar -> data
I1004 22:49:57.986757 15924 net.cpp:380] cifar -> label
I1004 22:49:57.986757 15924 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1004 22:49:57.986757 15924 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 22:49:57.986757 15924 data_layer.cpp:45] output data size: 100,3,32,32
I1004 22:49:57.986757 15924 net.cpp:122] Setting up cifar
I1004 22:49:57.986757 15924 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1004 22:49:57.986757 15924 net.cpp:129] Top shape: 100 (100)
I1004 22:49:57.986757 15924 net.cpp:137] Memory required for data: 1229200
I1004 22:49:57.986757 15924 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1004 22:49:57.986757 15924 net.cpp:84] Creating Layer label_cifar_1_split
I1004 22:49:57.986757 15924 net.cpp:406] label_cifar_1_split <- label
I1004 22:49:57.986757 15924 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1004 22:49:57.986757 15924 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1004 22:49:57.986757 15924 net.cpp:122] Setting up label_cifar_1_split
I1004 22:49:57.986757 15924 net.cpp:129] Top shape: 100 (100)
I1004 22:49:57.986757 15924 net.cpp:129] Top shape: 100 (100)
I1004 22:49:57.986757 15924 net.cpp:137] Memory required for data: 1230000
I1004 22:49:57.986757 15924 layer_factory.cpp:58] Creating layer conv1
I1004 22:49:57.986757 15924 net.cpp:84] Creating Layer conv1
I1004 22:49:57.986757 15924 net.cpp:406] conv1 <- data
I1004 22:49:57.986757 15924 net.cpp:380] conv1 -> conv1
I1004 22:49:57.986757  1048 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 22:49:58.222954 15924 net.cpp:122] Setting up conv1
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 3687600
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer bn1
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer bn1
I1004 22:49:58.222954 15924 net.cpp:406] bn1 <- conv1
I1004 22:49:58.222954 15924 net.cpp:367] bn1 -> conv1 (in-place)
I1004 22:49:58.222954 15924 net.cpp:122] Setting up bn1
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 6145200
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer scale1
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer scale1
I1004 22:49:58.222954 15924 net.cpp:406] scale1 <- conv1
I1004 22:49:58.222954 15924 net.cpp:367] scale1 -> conv1 (in-place)
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer scale1
I1004 22:49:58.222954 15924 net.cpp:122] Setting up scale1
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 8602800
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer relu1
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer relu1
I1004 22:49:58.222954 15924 net.cpp:406] relu1 <- conv1
I1004 22:49:58.222954 15924 net.cpp:367] relu1 -> conv1 (in-place)
I1004 22:49:58.222954 15924 net.cpp:122] Setting up relu1
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 11060400
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer conv1_0
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer conv1_0
I1004 22:49:58.222954 15924 net.cpp:406] conv1_0 <- conv1
I1004 22:49:58.222954 15924 net.cpp:380] conv1_0 -> conv1_0
I1004 22:49:58.222954 15924 net.cpp:122] Setting up conv1_0
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 15975600
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer bn1_0
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer bn1_0
I1004 22:49:58.222954 15924 net.cpp:406] bn1_0 <- conv1_0
I1004 22:49:58.222954 15924 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1004 22:49:58.222954 15924 net.cpp:122] Setting up bn1_0
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 20890800
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer scale1_0
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer scale1_0
I1004 22:49:58.222954 15924 net.cpp:406] scale1_0 <- conv1_0
I1004 22:49:58.222954 15924 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer scale1_0
I1004 22:49:58.222954 15924 net.cpp:122] Setting up scale1_0
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 25806000
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer relu1_0
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer relu1_0
I1004 22:49:58.222954 15924 net.cpp:406] relu1_0 <- conv1_0
I1004 22:49:58.222954 15924 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1004 22:49:58.222954 15924 net.cpp:122] Setting up relu1_0
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 30721200
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer conv2
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer conv2
I1004 22:49:58.222954 15924 net.cpp:406] conv2 <- conv1_0
I1004 22:49:58.222954 15924 net.cpp:380] conv2 -> conv2
I1004 22:49:58.222954 15924 net.cpp:122] Setting up conv2
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 35636400
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer bn2
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer bn2
I1004 22:49:58.222954 15924 net.cpp:406] bn2 <- conv2
I1004 22:49:58.222954 15924 net.cpp:367] bn2 -> conv2 (in-place)
I1004 22:49:58.222954 15924 net.cpp:122] Setting up bn2
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 40551600
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer scale2
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer scale2
I1004 22:49:58.222954 15924 net.cpp:406] scale2 <- conv2
I1004 22:49:58.222954 15924 net.cpp:367] scale2 -> conv2 (in-place)
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer scale2
I1004 22:49:58.222954 15924 net.cpp:122] Setting up scale2
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 45466800
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer relu2
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer relu2
I1004 22:49:58.222954 15924 net.cpp:406] relu2 <- conv2
I1004 22:49:58.222954 15924 net.cpp:367] relu2 -> conv2 (in-place)
I1004 22:49:58.222954 15924 net.cpp:122] Setting up relu2
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 50382000
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer pool2_1
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer pool2_1
I1004 22:49:58.222954 15924 net.cpp:406] pool2_1 <- conv2
I1004 22:49:58.222954 15924 net.cpp:380] pool2_1 -> pool2_1
I1004 22:49:58.222954 15924 net.cpp:122] Setting up pool2_1
I1004 22:49:58.222954 15924 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 22:49:58.222954 15924 net.cpp:137] Memory required for data: 51610800
I1004 22:49:58.222954 15924 layer_factory.cpp:58] Creating layer conv2_1
I1004 22:49:58.222954 15924 net.cpp:84] Creating Layer conv2_1
I1004 22:49:58.222954 15924 net.cpp:406] conv2_1 <- pool2_1
I1004 22:49:58.222954 15924 net.cpp:380] conv2_1 -> conv2_1
I1004 22:49:58.238559 15924 net.cpp:122] Setting up conv2_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 52839600
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer bn2_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer bn2_1
I1004 22:49:58.238559 15924 net.cpp:406] bn2_1 <- conv2_1
I1004 22:49:58.238559 15924 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up bn2_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 54068400
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale2_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer scale2_1
I1004 22:49:58.238559 15924 net.cpp:406] scale2_1 <- conv2_1
I1004 22:49:58.238559 15924 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale2_1
I1004 22:49:58.238559 15924 net.cpp:122] Setting up scale2_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 55297200
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer relu2_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer relu2_1
I1004 22:49:58.238559 15924 net.cpp:406] relu2_1 <- conv2_1
I1004 22:49:58.238559 15924 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up relu2_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 56526000
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer conv2_2
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer conv2_2
I1004 22:49:58.238559 15924 net.cpp:406] conv2_2 <- conv2_1
I1004 22:49:58.238559 15924 net.cpp:380] conv2_2 -> conv2_2
I1004 22:49:58.238559 15924 net.cpp:122] Setting up conv2_2
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 58471600
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer bn2_2
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer bn2_2
I1004 22:49:58.238559 15924 net.cpp:406] bn2_2 <- conv2_2
I1004 22:49:58.238559 15924 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up bn2_2
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 60417200
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale2_2
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer scale2_2
I1004 22:49:58.238559 15924 net.cpp:406] scale2_2 <- conv2_2
I1004 22:49:58.238559 15924 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale2_2
I1004 22:49:58.238559 15924 net.cpp:122] Setting up scale2_2
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 62362800
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer relu2_2
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer relu2_2
I1004 22:49:58.238559 15924 net.cpp:406] relu2_2 <- conv2_2
I1004 22:49:58.238559 15924 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up relu2_2
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 64308400
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer conv3
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer conv3
I1004 22:49:58.238559 15924 net.cpp:406] conv3 <- conv2_2
I1004 22:49:58.238559 15924 net.cpp:380] conv3 -> conv3
I1004 22:49:58.238559 15924 net.cpp:122] Setting up conv3
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 66254000
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer bn3
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer bn3
I1004 22:49:58.238559 15924 net.cpp:406] bn3 <- conv3
I1004 22:49:58.238559 15924 net.cpp:367] bn3 -> conv3 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up bn3
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 68199600
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale3
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer scale3
I1004 22:49:58.238559 15924 net.cpp:406] scale3 <- conv3
I1004 22:49:58.238559 15924 net.cpp:367] scale3 -> conv3 (in-place)
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale3
I1004 22:49:58.238559 15924 net.cpp:122] Setting up scale3
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 70145200
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer relu3
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer relu3
I1004 22:49:58.238559 15924 net.cpp:406] relu3 <- conv3
I1004 22:49:58.238559 15924 net.cpp:367] relu3 -> conv3 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up relu3
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 72090800
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer conv3_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer conv3_1
I1004 22:49:58.238559 15924 net.cpp:406] conv3_1 <- conv3
I1004 22:49:58.238559 15924 net.cpp:380] conv3_1 -> conv3_1
I1004 22:49:58.238559 15924 net.cpp:122] Setting up conv3_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 74036400
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer bn3_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer bn3_1
I1004 22:49:58.238559 15924 net.cpp:406] bn3_1 <- conv3_1
I1004 22:49:58.238559 15924 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up bn3_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 75982000
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale3_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer scale3_1
I1004 22:49:58.238559 15924 net.cpp:406] scale3_1 <- conv3_1
I1004 22:49:58.238559 15924 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale3_1
I1004 22:49:58.238559 15924 net.cpp:122] Setting up scale3_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 77927600
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer relu3_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer relu3_1
I1004 22:49:58.238559 15924 net.cpp:406] relu3_1 <- conv3_1
I1004 22:49:58.238559 15924 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up relu3_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 79873200
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer conv4
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer conv4
I1004 22:49:58.238559 15924 net.cpp:406] conv4 <- conv3_1
I1004 22:49:58.238559 15924 net.cpp:380] conv4 -> conv4
I1004 22:49:58.238559 15924 net.cpp:122] Setting up conv4
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 81818800
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer bn4
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer bn4
I1004 22:49:58.238559 15924 net.cpp:406] bn4 <- conv4
I1004 22:49:58.238559 15924 net.cpp:367] bn4 -> conv4 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up bn4
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 83764400
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale4
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer scale4
I1004 22:49:58.238559 15924 net.cpp:406] scale4 <- conv4
I1004 22:49:58.238559 15924 net.cpp:367] scale4 -> conv4 (in-place)
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale4
I1004 22:49:58.238559 15924 net.cpp:122] Setting up scale4
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 85710000
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer relu4
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer relu4
I1004 22:49:58.238559 15924 net.cpp:406] relu4 <- conv4
I1004 22:49:58.238559 15924 net.cpp:367] relu4 -> conv4 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up relu4
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 87655600
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer conv4_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer conv4_1
I1004 22:49:58.238559 15924 net.cpp:406] conv4_1 <- conv4
I1004 22:49:58.238559 15924 net.cpp:380] conv4_1 -> conv4_1
I1004 22:49:58.238559 15924 net.cpp:122] Setting up conv4_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 89601200
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer bn4_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer bn4_1
I1004 22:49:58.238559 15924 net.cpp:406] bn4_1 <- conv4_1
I1004 22:49:58.238559 15924 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up bn4_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 91546800
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale4_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer scale4_1
I1004 22:49:58.238559 15924 net.cpp:406] scale4_1 <- conv4_1
I1004 22:49:58.238559 15924 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale4_1
I1004 22:49:58.238559 15924 net.cpp:122] Setting up scale4_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 93492400
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer relu4_1
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer relu4_1
I1004 22:49:58.238559 15924 net.cpp:406] relu4_1 <- conv4_1
I1004 22:49:58.238559 15924 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up relu4_1
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 95438000
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer conv4_2
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer conv4_2
I1004 22:49:58.238559 15924 net.cpp:406] conv4_2 <- conv4_1
I1004 22:49:58.238559 15924 net.cpp:380] conv4_2 -> conv4_2
I1004 22:49:58.238559 15924 net.cpp:122] Setting up conv4_2
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 98305200
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer bn4_2
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer bn4_2
I1004 22:49:58.238559 15924 net.cpp:406] bn4_2 <- conv4_2
I1004 22:49:58.238559 15924 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up bn4_2
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 101172400
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale4_2
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer scale4_2
I1004 22:49:58.238559 15924 net.cpp:406] scale4_2 <- conv4_2
I1004 22:49:58.238559 15924 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale4_2
I1004 22:49:58.238559 15924 net.cpp:122] Setting up scale4_2
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 104039600
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer relu4_2
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer relu4_2
I1004 22:49:58.238559 15924 net.cpp:406] relu4_2 <- conv4_2
I1004 22:49:58.238559 15924 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up relu4_2
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 106906800
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer pool4_2
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer pool4_2
I1004 22:49:58.238559 15924 net.cpp:406] pool4_2 <- conv4_2
I1004 22:49:58.238559 15924 net.cpp:380] pool4_2 -> pool4_2
I1004 22:49:58.238559 15924 net.cpp:122] Setting up pool4_2
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 107623600
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer conv4_0
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer conv4_0
I1004 22:49:58.238559 15924 net.cpp:406] conv4_0 <- pool4_2
I1004 22:49:58.238559 15924 net.cpp:380] conv4_0 -> conv4_0
I1004 22:49:58.238559 15924 net.cpp:122] Setting up conv4_0
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 108340400
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer bn4_0
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer bn4_0
I1004 22:49:58.238559 15924 net.cpp:406] bn4_0 <- conv4_0
I1004 22:49:58.238559 15924 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1004 22:49:58.238559 15924 net.cpp:122] Setting up bn4_0
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 109057200
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale4_0
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer scale4_0
I1004 22:49:58.238559 15924 net.cpp:406] scale4_0 <- conv4_0
I1004 22:49:58.238559 15924 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer scale4_0
I1004 22:49:58.238559 15924 net.cpp:122] Setting up scale4_0
I1004 22:49:58.238559 15924 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 22:49:58.238559 15924 net.cpp:137] Memory required for data: 109774000
I1004 22:49:58.238559 15924 layer_factory.cpp:58] Creating layer relu4_0
I1004 22:49:58.238559 15924 net.cpp:84] Creating Layer relu4_0
I1004 22:49:58.238559 15924 net.cpp:406] relu4_0 <- conv4_0
I1004 22:49:58.238559 15924 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1004 22:49:58.254186 15924 net.cpp:122] Setting up relu4_0
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 110490800
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer conv11
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer conv11
I1004 22:49:58.254186 15924 net.cpp:406] conv11 <- conv4_0
I1004 22:49:58.254186 15924 net.cpp:380] conv11 -> conv11
I1004 22:49:58.254186 15924 net.cpp:122] Setting up conv11
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 111386800
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer bn_conv11
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer bn_conv11
I1004 22:49:58.254186 15924 net.cpp:406] bn_conv11 <- conv11
I1004 22:49:58.254186 15924 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1004 22:49:58.254186 15924 net.cpp:122] Setting up bn_conv11
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 112282800
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer scale_conv11
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer scale_conv11
I1004 22:49:58.254186 15924 net.cpp:406] scale_conv11 <- conv11
I1004 22:49:58.254186 15924 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer scale_conv11
I1004 22:49:58.254186 15924 net.cpp:122] Setting up scale_conv11
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 113178800
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer relu_conv11
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer relu_conv11
I1004 22:49:58.254186 15924 net.cpp:406] relu_conv11 <- conv11
I1004 22:49:58.254186 15924 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1004 22:49:58.254186 15924 net.cpp:122] Setting up relu_conv11
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 114074800
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer conv12
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer conv12
I1004 22:49:58.254186 15924 net.cpp:406] conv12 <- conv11
I1004 22:49:58.254186 15924 net.cpp:380] conv12 -> conv12
I1004 22:49:58.254186 15924 net.cpp:122] Setting up conv12
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 115175600
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer bn_conv12
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer bn_conv12
I1004 22:49:58.254186 15924 net.cpp:406] bn_conv12 <- conv12
I1004 22:49:58.254186 15924 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1004 22:49:58.254186 15924 net.cpp:122] Setting up bn_conv12
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 116276400
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer scale_conv12
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer scale_conv12
I1004 22:49:58.254186 15924 net.cpp:406] scale_conv12 <- conv12
I1004 22:49:58.254186 15924 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer scale_conv12
I1004 22:49:58.254186 15924 net.cpp:122] Setting up scale_conv12
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 117377200
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer relu_conv12
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer relu_conv12
I1004 22:49:58.254186 15924 net.cpp:406] relu_conv12 <- conv12
I1004 22:49:58.254186 15924 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1004 22:49:58.254186 15924 net.cpp:122] Setting up relu_conv12
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 118478000
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer poolcp6
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer poolcp6
I1004 22:49:58.254186 15924 net.cpp:406] poolcp6 <- conv12
I1004 22:49:58.254186 15924 net.cpp:380] poolcp6 -> poolcp6
I1004 22:49:58.254186 15924 net.cpp:122] Setting up poolcp6
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 118495200
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer ip1
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer ip1
I1004 22:49:58.254186 15924 net.cpp:406] ip1 <- poolcp6
I1004 22:49:58.254186 15924 net.cpp:380] ip1 -> ip1
I1004 22:49:58.254186 15924 net.cpp:122] Setting up ip1
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 10 (1000)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 118499200
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer ip1_ip1_0_split
I1004 22:49:58.254186 15924 net.cpp:406] ip1_ip1_0_split <- ip1
I1004 22:49:58.254186 15924 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1004 22:49:58.254186 15924 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1004 22:49:58.254186 15924 net.cpp:122] Setting up ip1_ip1_0_split
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 10 (1000)
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: 100 10 (1000)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 118507200
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer accuracy_training
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer accuracy_training
I1004 22:49:58.254186 15924 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1004 22:49:58.254186 15924 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1004 22:49:58.254186 15924 net.cpp:380] accuracy_training -> accuracy_training
I1004 22:49:58.254186 15924 net.cpp:122] Setting up accuracy_training
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: (1)
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 118507204
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer loss
I1004 22:49:58.254186 15924 net.cpp:84] Creating Layer loss
I1004 22:49:58.254186 15924 net.cpp:406] loss <- ip1_ip1_0_split_1
I1004 22:49:58.254186 15924 net.cpp:406] loss <- label_cifar_1_split_1
I1004 22:49:58.254186 15924 net.cpp:380] loss -> loss
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer loss
I1004 22:49:58.254186 15924 net.cpp:122] Setting up loss
I1004 22:49:58.254186 15924 net.cpp:129] Top shape: (1)
I1004 22:49:58.254186 15924 net.cpp:132]     with loss weight 1
I1004 22:49:58.254186 15924 net.cpp:137] Memory required for data: 118507208
I1004 22:49:58.254186 15924 net.cpp:198] loss needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:200] accuracy_training does not need backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] ip1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] poolcp6 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu_conv12 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale_conv12 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn_conv12 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv12 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu_conv11 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale_conv11 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn_conv11 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv11 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu4_0 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale4_0 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn4_0 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv4_0 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] pool4_2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu4_2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale4_2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn4_2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv4_2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu4_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale4_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn4_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv4_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu4 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale4 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn4 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv4 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu3_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale3_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn3_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv3_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu3 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale3 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn3 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv3 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu2_2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale2_2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn2_2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv2_2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu2_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale2_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn2_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv2_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] pool2_1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv2 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu1_0 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale1_0 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn1_0 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv1_0 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] relu1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] scale1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] bn1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:198] conv1 needs backward computation.
I1004 22:49:58.254186 15924 net.cpp:200] label_cifar_1_split does not need backward computation.
I1004 22:49:58.254186 15924 net.cpp:200] cifar does not need backward computation.
I1004 22:49:58.254186 15924 net.cpp:242] This network produces output accuracy_training
I1004 22:49:58.254186 15924 net.cpp:242] This network produces output loss
I1004 22:49:58.254186 15924 net.cpp:255] Network initialization done.
I1004 22:49:58.254186 15924 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 22:49:58.254186 15924 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1004 22:49:58.254186 15924 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1004 22:49:58.254186 15924 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1004 22:49:58.254186 15924 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P3__"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1004 22:49:58.254186 15924 layer_factory.cpp:58] Creating layer cifar
I1004 22:49:58.269848 15924 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer cifar
I1004 22:49:58.269848 15924 net.cpp:380] cifar -> data
I1004 22:49:58.269848 15924 net.cpp:380] cifar -> label
I1004 22:49:58.269848 15924 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1004 22:49:58.269848 15924 data_layer.cpp:45] output data size: 100,3,32,32
I1004 22:49:58.269848 15924 net.cpp:122] Setting up cifar
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 (100)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 1229200
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer label_cifar_1_split
I1004 22:49:58.269848 15924 net.cpp:406] label_cifar_1_split <- label
I1004 22:49:58.269848 15924 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1004 22:49:58.269848 15924 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1004 22:49:58.269848 15924 net.cpp:122] Setting up label_cifar_1_split
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 (100)
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 (100)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 1230000
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer conv1
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer conv1
I1004 22:49:58.269848 15924 net.cpp:406] conv1 <- data
I1004 22:49:58.269848 15924 net.cpp:380] conv1 -> conv1
I1004 22:49:58.269848 18032 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 22:49:58.269848 15924 net.cpp:122] Setting up conv1
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 3687600
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer bn1
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer bn1
I1004 22:49:58.269848 15924 net.cpp:406] bn1 <- conv1
I1004 22:49:58.269848 15924 net.cpp:367] bn1 -> conv1 (in-place)
I1004 22:49:58.269848 15924 net.cpp:122] Setting up bn1
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 6145200
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer scale1
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer scale1
I1004 22:49:58.269848 15924 net.cpp:406] scale1 <- conv1
I1004 22:49:58.269848 15924 net.cpp:367] scale1 -> conv1 (in-place)
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer scale1
I1004 22:49:58.269848 15924 net.cpp:122] Setting up scale1
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 8602800
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer relu1
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer relu1
I1004 22:49:58.269848 15924 net.cpp:406] relu1 <- conv1
I1004 22:49:58.269848 15924 net.cpp:367] relu1 -> conv1 (in-place)
I1004 22:49:58.269848 15924 net.cpp:122] Setting up relu1
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 11060400
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer conv1_0
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer conv1_0
I1004 22:49:58.269848 15924 net.cpp:406] conv1_0 <- conv1
I1004 22:49:58.269848 15924 net.cpp:380] conv1_0 -> conv1_0
I1004 22:49:58.269848 15924 net.cpp:122] Setting up conv1_0
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 15975600
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer bn1_0
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer bn1_0
I1004 22:49:58.269848 15924 net.cpp:406] bn1_0 <- conv1_0
I1004 22:49:58.269848 15924 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1004 22:49:58.269848 15924 net.cpp:122] Setting up bn1_0
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 20890800
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer scale1_0
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer scale1_0
I1004 22:49:58.269848 15924 net.cpp:406] scale1_0 <- conv1_0
I1004 22:49:58.269848 15924 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer scale1_0
I1004 22:49:58.269848 15924 net.cpp:122] Setting up scale1_0
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 25806000
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer relu1_0
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer relu1_0
I1004 22:49:58.269848 15924 net.cpp:406] relu1_0 <- conv1_0
I1004 22:49:58.269848 15924 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1004 22:49:58.269848 15924 net.cpp:122] Setting up relu1_0
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 30721200
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer conv2
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer conv2
I1004 22:49:58.269848 15924 net.cpp:406] conv2 <- conv1_0
I1004 22:49:58.269848 15924 net.cpp:380] conv2 -> conv2
I1004 22:49:58.269848 15924 net.cpp:122] Setting up conv2
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 35636400
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer bn2
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer bn2
I1004 22:49:58.269848 15924 net.cpp:406] bn2 <- conv2
I1004 22:49:58.269848 15924 net.cpp:367] bn2 -> conv2 (in-place)
I1004 22:49:58.269848 15924 net.cpp:122] Setting up bn2
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 40551600
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer scale2
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer scale2
I1004 22:49:58.269848 15924 net.cpp:406] scale2 <- conv2
I1004 22:49:58.269848 15924 net.cpp:367] scale2 -> conv2 (in-place)
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer scale2
I1004 22:49:58.269848 15924 net.cpp:122] Setting up scale2
I1004 22:49:58.269848 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.269848 15924 net.cpp:137] Memory required for data: 45466800
I1004 22:49:58.269848 15924 layer_factory.cpp:58] Creating layer relu2
I1004 22:49:58.269848 15924 net.cpp:84] Creating Layer relu2
I1004 22:49:58.269848 15924 net.cpp:406] relu2 <- conv2
I1004 22:49:58.269848 15924 net.cpp:367] relu2 -> conv2 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up relu2
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 50382000
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer pool2_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer pool2_1
I1004 22:49:58.285455 15924 net.cpp:406] pool2_1 <- conv2
I1004 22:49:58.285455 15924 net.cpp:380] pool2_1 -> pool2_1
I1004 22:49:58.285455 15924 net.cpp:122] Setting up pool2_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 51610800
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer conv2_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer conv2_1
I1004 22:49:58.285455 15924 net.cpp:406] conv2_1 <- pool2_1
I1004 22:49:58.285455 15924 net.cpp:380] conv2_1 -> conv2_1
I1004 22:49:58.285455 15924 net.cpp:122] Setting up conv2_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 52839600
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer bn2_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer bn2_1
I1004 22:49:58.285455 15924 net.cpp:406] bn2_1 <- conv2_1
I1004 22:49:58.285455 15924 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up bn2_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 54068400
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale2_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer scale2_1
I1004 22:49:58.285455 15924 net.cpp:406] scale2_1 <- conv2_1
I1004 22:49:58.285455 15924 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale2_1
I1004 22:49:58.285455 15924 net.cpp:122] Setting up scale2_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 55297200
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer relu2_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer relu2_1
I1004 22:49:58.285455 15924 net.cpp:406] relu2_1 <- conv2_1
I1004 22:49:58.285455 15924 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up relu2_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 56526000
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer conv2_2
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer conv2_2
I1004 22:49:58.285455 15924 net.cpp:406] conv2_2 <- conv2_1
I1004 22:49:58.285455 15924 net.cpp:380] conv2_2 -> conv2_2
I1004 22:49:58.285455 15924 net.cpp:122] Setting up conv2_2
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 58471600
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer bn2_2
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer bn2_2
I1004 22:49:58.285455 15924 net.cpp:406] bn2_2 <- conv2_2
I1004 22:49:58.285455 15924 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up bn2_2
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 60417200
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale2_2
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer scale2_2
I1004 22:49:58.285455 15924 net.cpp:406] scale2_2 <- conv2_2
I1004 22:49:58.285455 15924 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale2_2
I1004 22:49:58.285455 15924 net.cpp:122] Setting up scale2_2
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 62362800
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer relu2_2
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer relu2_2
I1004 22:49:58.285455 15924 net.cpp:406] relu2_2 <- conv2_2
I1004 22:49:58.285455 15924 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up relu2_2
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 64308400
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer conv3
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer conv3
I1004 22:49:58.285455 15924 net.cpp:406] conv3 <- conv2_2
I1004 22:49:58.285455 15924 net.cpp:380] conv3 -> conv3
I1004 22:49:58.285455 15924 net.cpp:122] Setting up conv3
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 66254000
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer bn3
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer bn3
I1004 22:49:58.285455 15924 net.cpp:406] bn3 <- conv3
I1004 22:49:58.285455 15924 net.cpp:367] bn3 -> conv3 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up bn3
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 68199600
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale3
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer scale3
I1004 22:49:58.285455 15924 net.cpp:406] scale3 <- conv3
I1004 22:49:58.285455 15924 net.cpp:367] scale3 -> conv3 (in-place)
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale3
I1004 22:49:58.285455 15924 net.cpp:122] Setting up scale3
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 70145200
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer relu3
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer relu3
I1004 22:49:58.285455 15924 net.cpp:406] relu3 <- conv3
I1004 22:49:58.285455 15924 net.cpp:367] relu3 -> conv3 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up relu3
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 72090800
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer conv3_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer conv3_1
I1004 22:49:58.285455 15924 net.cpp:406] conv3_1 <- conv3
I1004 22:49:58.285455 15924 net.cpp:380] conv3_1 -> conv3_1
I1004 22:49:58.285455 15924 net.cpp:122] Setting up conv3_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 74036400
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer bn3_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer bn3_1
I1004 22:49:58.285455 15924 net.cpp:406] bn3_1 <- conv3_1
I1004 22:49:58.285455 15924 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up bn3_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 75982000
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale3_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer scale3_1
I1004 22:49:58.285455 15924 net.cpp:406] scale3_1 <- conv3_1
I1004 22:49:58.285455 15924 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale3_1
I1004 22:49:58.285455 15924 net.cpp:122] Setting up scale3_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 77927600
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer relu3_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer relu3_1
I1004 22:49:58.285455 15924 net.cpp:406] relu3_1 <- conv3_1
I1004 22:49:58.285455 15924 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up relu3_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 79873200
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer conv4
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer conv4
I1004 22:49:58.285455 15924 net.cpp:406] conv4 <- conv3_1
I1004 22:49:58.285455 15924 net.cpp:380] conv4 -> conv4
I1004 22:49:58.285455 15924 net.cpp:122] Setting up conv4
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 81818800
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer bn4
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer bn4
I1004 22:49:58.285455 15924 net.cpp:406] bn4 <- conv4
I1004 22:49:58.285455 15924 net.cpp:367] bn4 -> conv4 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up bn4
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 83764400
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale4
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer scale4
I1004 22:49:58.285455 15924 net.cpp:406] scale4 <- conv4
I1004 22:49:58.285455 15924 net.cpp:367] scale4 -> conv4 (in-place)
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale4
I1004 22:49:58.285455 15924 net.cpp:122] Setting up scale4
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 85710000
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer relu4
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer relu4
I1004 22:49:58.285455 15924 net.cpp:406] relu4 <- conv4
I1004 22:49:58.285455 15924 net.cpp:367] relu4 -> conv4 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up relu4
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 87655600
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer conv4_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer conv4_1
I1004 22:49:58.285455 15924 net.cpp:406] conv4_1 <- conv4
I1004 22:49:58.285455 15924 net.cpp:380] conv4_1 -> conv4_1
I1004 22:49:58.285455 15924 net.cpp:122] Setting up conv4_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 89601200
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer bn4_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer bn4_1
I1004 22:49:58.285455 15924 net.cpp:406] bn4_1 <- conv4_1
I1004 22:49:58.285455 15924 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up bn4_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 91546800
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale4_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer scale4_1
I1004 22:49:58.285455 15924 net.cpp:406] scale4_1 <- conv4_1
I1004 22:49:58.285455 15924 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale4_1
I1004 22:49:58.285455 15924 net.cpp:122] Setting up scale4_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 93492400
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer relu4_1
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer relu4_1
I1004 22:49:58.285455 15924 net.cpp:406] relu4_1 <- conv4_1
I1004 22:49:58.285455 15924 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up relu4_1
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 95438000
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer conv4_2
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer conv4_2
I1004 22:49:58.285455 15924 net.cpp:406] conv4_2 <- conv4_1
I1004 22:49:58.285455 15924 net.cpp:380] conv4_2 -> conv4_2
I1004 22:49:58.285455 15924 net.cpp:122] Setting up conv4_2
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 98305200
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer bn4_2
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer bn4_2
I1004 22:49:58.285455 15924 net.cpp:406] bn4_2 <- conv4_2
I1004 22:49:58.285455 15924 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up bn4_2
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 101172400
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale4_2
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer scale4_2
I1004 22:49:58.285455 15924 net.cpp:406] scale4_2 <- conv4_2
I1004 22:49:58.285455 15924 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale4_2
I1004 22:49:58.285455 15924 net.cpp:122] Setting up scale4_2
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 104039600
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer relu4_2
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer relu4_2
I1004 22:49:58.285455 15924 net.cpp:406] relu4_2 <- conv4_2
I1004 22:49:58.285455 15924 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up relu4_2
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 106906800
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer pool4_2
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer pool4_2
I1004 22:49:58.285455 15924 net.cpp:406] pool4_2 <- conv4_2
I1004 22:49:58.285455 15924 net.cpp:380] pool4_2 -> pool4_2
I1004 22:49:58.285455 15924 net.cpp:122] Setting up pool4_2
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 107623600
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer conv4_0
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer conv4_0
I1004 22:49:58.285455 15924 net.cpp:406] conv4_0 <- pool4_2
I1004 22:49:58.285455 15924 net.cpp:380] conv4_0 -> conv4_0
I1004 22:49:58.285455 15924 net.cpp:122] Setting up conv4_0
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 108340400
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer bn4_0
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer bn4_0
I1004 22:49:58.285455 15924 net.cpp:406] bn4_0 <- conv4_0
I1004 22:49:58.285455 15924 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up bn4_0
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 109057200
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale4_0
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer scale4_0
I1004 22:49:58.285455 15924 net.cpp:406] scale4_0 <- conv4_0
I1004 22:49:58.285455 15924 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer scale4_0
I1004 22:49:58.285455 15924 net.cpp:122] Setting up scale4_0
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 109774000
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer relu4_0
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer relu4_0
I1004 22:49:58.285455 15924 net.cpp:406] relu4_0 <- conv4_0
I1004 22:49:58.285455 15924 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1004 22:49:58.285455 15924 net.cpp:122] Setting up relu4_0
I1004 22:49:58.285455 15924 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 22:49:58.285455 15924 net.cpp:137] Memory required for data: 110490800
I1004 22:49:58.285455 15924 layer_factory.cpp:58] Creating layer conv11
I1004 22:49:58.285455 15924 net.cpp:84] Creating Layer conv11
I1004 22:49:58.285455 15924 net.cpp:406] conv11 <- conv4_0
I1004 22:49:58.285455 15924 net.cpp:380] conv11 -> conv11
I1004 22:49:58.301074 15924 net.cpp:122] Setting up conv11
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 111386800
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer bn_conv11
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer bn_conv11
I1004 22:49:58.301074 15924 net.cpp:406] bn_conv11 <- conv11
I1004 22:49:58.301074 15924 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1004 22:49:58.301074 15924 net.cpp:122] Setting up bn_conv11
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 112282800
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer scale_conv11
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer scale_conv11
I1004 22:49:58.301074 15924 net.cpp:406] scale_conv11 <- conv11
I1004 22:49:58.301074 15924 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer scale_conv11
I1004 22:49:58.301074 15924 net.cpp:122] Setting up scale_conv11
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 113178800
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer relu_conv11
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer relu_conv11
I1004 22:49:58.301074 15924 net.cpp:406] relu_conv11 <- conv11
I1004 22:49:58.301074 15924 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1004 22:49:58.301074 15924 net.cpp:122] Setting up relu_conv11
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 114074800
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer conv12
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer conv12
I1004 22:49:58.301074 15924 net.cpp:406] conv12 <- conv11
I1004 22:49:58.301074 15924 net.cpp:380] conv12 -> conv12
I1004 22:49:58.301074 15924 net.cpp:122] Setting up conv12
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 115175600
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer bn_conv12
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer bn_conv12
I1004 22:49:58.301074 15924 net.cpp:406] bn_conv12 <- conv12
I1004 22:49:58.301074 15924 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1004 22:49:58.301074 15924 net.cpp:122] Setting up bn_conv12
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 116276400
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer scale_conv12
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer scale_conv12
I1004 22:49:58.301074 15924 net.cpp:406] scale_conv12 <- conv12
I1004 22:49:58.301074 15924 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer scale_conv12
I1004 22:49:58.301074 15924 net.cpp:122] Setting up scale_conv12
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 117377200
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer relu_conv12
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer relu_conv12
I1004 22:49:58.301074 15924 net.cpp:406] relu_conv12 <- conv12
I1004 22:49:58.301074 15924 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1004 22:49:58.301074 15924 net.cpp:122] Setting up relu_conv12
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 118478000
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer poolcp6
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer poolcp6
I1004 22:49:58.301074 15924 net.cpp:406] poolcp6 <- conv12
I1004 22:49:58.301074 15924 net.cpp:380] poolcp6 -> poolcp6
I1004 22:49:58.301074 15924 net.cpp:122] Setting up poolcp6
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 118495200
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer ip1
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer ip1
I1004 22:49:58.301074 15924 net.cpp:406] ip1 <- poolcp6
I1004 22:49:58.301074 15924 net.cpp:380] ip1 -> ip1
I1004 22:49:58.301074 15924 net.cpp:122] Setting up ip1
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 10 (1000)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 118499200
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer ip1_ip1_0_split
I1004 22:49:58.301074 15924 net.cpp:406] ip1_ip1_0_split <- ip1
I1004 22:49:58.301074 15924 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1004 22:49:58.301074 15924 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1004 22:49:58.301074 15924 net.cpp:122] Setting up ip1_ip1_0_split
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 10 (1000)
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: 100 10 (1000)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 118507200
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer accuracy
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer accuracy
I1004 22:49:58.301074 15924 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1004 22:49:58.301074 15924 net.cpp:406] accuracy <- label_cifar_1_split_0
I1004 22:49:58.301074 15924 net.cpp:380] accuracy -> accuracy
I1004 22:49:58.301074 15924 net.cpp:122] Setting up accuracy
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: (1)
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 118507204
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer loss
I1004 22:49:58.301074 15924 net.cpp:84] Creating Layer loss
I1004 22:49:58.301074 15924 net.cpp:406] loss <- ip1_ip1_0_split_1
I1004 22:49:58.301074 15924 net.cpp:406] loss <- label_cifar_1_split_1
I1004 22:49:58.301074 15924 net.cpp:380] loss -> loss
I1004 22:49:58.301074 15924 layer_factory.cpp:58] Creating layer loss
I1004 22:49:58.301074 15924 net.cpp:122] Setting up loss
I1004 22:49:58.301074 15924 net.cpp:129] Top shape: (1)
I1004 22:49:58.301074 15924 net.cpp:132]     with loss weight 1
I1004 22:49:58.301074 15924 net.cpp:137] Memory required for data: 118507208
I1004 22:49:58.301074 15924 net.cpp:198] loss needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:200] accuracy does not need backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] ip1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] poolcp6 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu_conv12 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale_conv12 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn_conv12 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv12 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu_conv11 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale_conv11 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn_conv11 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv11 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu4_0 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale4_0 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn4_0 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv4_0 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] pool4_2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu4_2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale4_2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn4_2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv4_2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu4_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale4_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn4_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv4_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu4 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale4 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn4 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv4 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu3_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale3_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn3_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv3_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu3 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale3 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn3 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv3 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu2_2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale2_2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn2_2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv2_2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu2_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale2_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn2_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv2_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] pool2_1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv2 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu1_0 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale1_0 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn1_0 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv1_0 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] relu1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] scale1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] bn1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:198] conv1 needs backward computation.
I1004 22:49:58.301074 15924 net.cpp:200] label_cifar_1_split does not need backward computation.
I1004 22:49:58.301074 15924 net.cpp:200] cifar does not need backward computation.
I1004 22:49:58.301074 15924 net.cpp:242] This network produces output accuracy
I1004 22:49:58.301074 15924 net.cpp:242] This network produces output loss
I1004 22:49:58.301074 15924 net.cpp:255] Network initialization done.
I1004 22:49:58.301074 15924 solver.cpp:56] Solver scaffolding done.
I1004 22:49:58.301074 15924 caffe.cpp:249] Starting Optimization
I1004 22:49:58.301074 15924 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_drpall_Simple_P3__
I1004 22:49:58.301074 15924 solver.cpp:273] Learning Rate Policy: multistep
I1004 22:49:58.301074 15924 solver.cpp:330] Iteration 0, Testing net (#0)
I1004 22:49:58.301074 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:49:58.782140 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:49:58.809931 15924 solver.cpp:397]     Test net output #0: accuracy = 0.0939
I1004 22:49:58.809931 15924 solver.cpp:397]     Test net output #1: loss = 79.1356 (* 1 = 79.1356 loss)
I1004 22:49:58.842290 15924 solver.cpp:218] Iteration 0 (0 iter/s, 0.546139s/100 iters), loss = 3.79214
I1004 22:49:58.842290 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.06
I1004 22:49:58.842290 15924 solver.cpp:237]     Train net output #1: loss = 3.79214 (* 1 = 3.79214 loss)
I1004 22:49:58.842290 15924 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1004 22:50:01.156710 15924 solver.cpp:218] Iteration 100 (43.3409 iter/s, 2.30729s/100 iters), loss = 1.72641
I1004 22:50:01.156710 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I1004 22:50:01.156710 15924 solver.cpp:237]     Train net output #1: loss = 1.72641 (* 1 = 1.72641 loss)
I1004 22:50:01.156710 15924 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1004 22:50:03.440033 15924 solver.cpp:218] Iteration 200 (43.8996 iter/s, 2.27793s/100 iters), loss = 1.89002
I1004 22:50:03.440033 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1004 22:50:03.440033 15924 solver.cpp:237]     Train net output #1: loss = 1.89002 (* 1 = 1.89002 loss)
I1004 22:50:03.440033 15924 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1004 22:50:05.713177 15924 solver.cpp:218] Iteration 300 (43.9759 iter/s, 2.27397s/100 iters), loss = 1.56716
I1004 22:50:05.713177 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1004 22:50:05.713177 15924 solver.cpp:237]     Train net output #1: loss = 1.56716 (* 1 = 1.56716 loss)
I1004 22:50:05.713177 15924 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1004 22:50:07.983587 15924 solver.cpp:218] Iteration 400 (43.8795 iter/s, 2.27897s/100 iters), loss = 1.30824
I1004 22:50:07.983587 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1004 22:50:07.983587 15924 solver.cpp:237]     Train net output #1: loss = 1.30824 (* 1 = 1.30824 loss)
I1004 22:50:07.983587 15924 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1004 22:50:10.149827  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:50:10.259205 15924 solver.cpp:218] Iteration 500 (43.982 iter/s, 2.27365s/100 iters), loss = 1.54923
I1004 22:50:10.259205 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1004 22:50:10.259205 15924 solver.cpp:237]     Train net output #1: loss = 1.54923 (* 1 = 1.54923 loss)
I1004 22:50:10.259205 15924 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1004 22:50:12.539517 15924 solver.cpp:218] Iteration 600 (44.0087 iter/s, 2.27228s/100 iters), loss = 1.3743
I1004 22:50:12.539517 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1004 22:50:12.539517 15924 solver.cpp:237]     Train net output #1: loss = 1.3743 (* 1 = 1.3743 loss)
I1004 22:50:12.539517 15924 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1004 22:50:14.798689 15924 solver.cpp:218] Iteration 700 (44.3183 iter/s, 2.2564s/100 iters), loss = 1.37245
I1004 22:50:14.798689 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1004 22:50:14.798689 15924 solver.cpp:237]     Train net output #1: loss = 1.37245 (* 1 = 1.37245 loss)
I1004 22:50:14.798689 15924 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1004 22:50:17.070956 15924 solver.cpp:218] Iteration 800 (43.9569 iter/s, 2.27495s/100 iters), loss = 1.22439
I1004 22:50:17.070956 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1004 22:50:17.070956 15924 solver.cpp:237]     Train net output #1: loss = 1.22439 (* 1 = 1.22439 loss)
I1004 22:50:17.070956 15924 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1004 22:50:19.344995 15924 solver.cpp:218] Iteration 900 (43.9874 iter/s, 2.27338s/100 iters), loss = 1.12701
I1004 22:50:19.344995 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1004 22:50:19.344995 15924 solver.cpp:237]     Train net output #1: loss = 1.12701 (* 1 = 1.12701 loss)
I1004 22:50:19.344995 15924 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1004 22:50:21.500046  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:50:21.593782 15924 solver.cpp:330] Iteration 1000, Testing net (#0)
I1004 22:50:21.593782 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:50:22.029361 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:50:22.044991 15924 solver.cpp:397]     Test net output #0: accuracy = 0.5623
I1004 22:50:22.044991 15924 solver.cpp:397]     Test net output #1: loss = 1.22274 (* 1 = 1.22274 loss)
I1004 22:50:22.060609 15924 solver.cpp:218] Iteration 1000 (36.697 iter/s, 2.72502s/100 iters), loss = 1.23683
I1004 22:50:22.060609 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1004 22:50:22.060609 15924 solver.cpp:237]     Train net output #1: loss = 1.23683 (* 1 = 1.23683 loss)
I1004 22:50:22.060609 15924 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1004 22:50:24.357646 15924 solver.cpp:218] Iteration 1100 (43.7443 iter/s, 2.28601s/100 iters), loss = 1.07615
I1004 22:50:24.357646 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1004 22:50:24.357646 15924 solver.cpp:237]     Train net output #1: loss = 1.07615 (* 1 = 1.07615 loss)
I1004 22:50:24.357646 15924 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1004 22:50:26.608970 15924 solver.cpp:218] Iteration 1200 (44.3032 iter/s, 2.25717s/100 iters), loss = 1.08289
I1004 22:50:26.608970 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1004 22:50:26.608970 15924 solver.cpp:237]     Train net output #1: loss = 1.08289 (* 1 = 1.08289 loss)
I1004 22:50:26.608970 15924 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1004 22:50:28.886458 15924 solver.cpp:218] Iteration 1300 (44.0786 iter/s, 2.26867s/100 iters), loss = 1.08845
I1004 22:50:28.886458 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1004 22:50:28.886458 15924 solver.cpp:237]     Train net output #1: loss = 1.08845 (* 1 = 1.08845 loss)
I1004 22:50:28.886458 15924 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1004 22:50:31.144809 15924 solver.cpp:218] Iteration 1400 (44.09 iter/s, 2.26809s/100 iters), loss = 0.987126
I1004 22:50:31.144809 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1004 22:50:31.144809 15924 solver.cpp:237]     Train net output #1: loss = 0.987126 (* 1 = 0.987126 loss)
I1004 22:50:31.144809 15924 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1004 22:50:33.321557  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:50:33.419813 15924 solver.cpp:218] Iteration 1500 (43.8974 iter/s, 2.27804s/100 iters), loss = 1.09168
I1004 22:50:33.419813 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1004 22:50:33.419813 15924 solver.cpp:237]     Train net output #1: loss = 1.09168 (* 1 = 1.09168 loss)
I1004 22:50:33.419813 15924 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1004 22:50:35.698875 15924 solver.cpp:218] Iteration 1600 (43.9936 iter/s, 2.27306s/100 iters), loss = 0.967802
I1004 22:50:35.698875 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1004 22:50:35.698875 15924 solver.cpp:237]     Train net output #1: loss = 0.967802 (* 1 = 0.967802 loss)
I1004 22:50:35.698875 15924 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1004 22:50:37.981784 15924 solver.cpp:218] Iteration 1700 (43.7786 iter/s, 2.28422s/100 iters), loss = 0.925632
I1004 22:50:37.981784 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1004 22:50:37.981784 15924 solver.cpp:237]     Train net output #1: loss = 0.925632 (* 1 = 0.925632 loss)
I1004 22:50:37.981784 15924 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1004 22:50:40.248862 15924 solver.cpp:218] Iteration 1800 (44.2438 iter/s, 2.2602s/100 iters), loss = 0.944343
I1004 22:50:40.248862 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1004 22:50:40.248862 15924 solver.cpp:237]     Train net output #1: loss = 0.944343 (* 1 = 0.944343 loss)
I1004 22:50:40.248862 15924 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1004 22:50:42.521288 15924 solver.cpp:218] Iteration 1900 (43.929 iter/s, 2.2764s/100 iters), loss = 0.818476
I1004 22:50:42.521288 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1004 22:50:42.521288 15924 solver.cpp:237]     Train net output #1: loss = 0.818476 (* 1 = 0.818476 loss)
I1004 22:50:42.521288 15924 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1004 22:50:44.669379  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:50:44.763129 15924 solver.cpp:330] Iteration 2000, Testing net (#0)
I1004 22:50:44.763129 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:50:45.185003 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:50:45.200634 15924 solver.cpp:397]     Test net output #0: accuracy = 0.63
I1004 22:50:45.200634 15924 solver.cpp:397]     Test net output #1: loss = 1.03661 (* 1 = 1.03661 loss)
I1004 22:50:45.231878 15924 solver.cpp:218] Iteration 2000 (36.9861 iter/s, 2.70371s/100 iters), loss = 1.08874
I1004 22:50:45.231878 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1004 22:50:45.231878 15924 solver.cpp:237]     Train net output #1: loss = 1.08874 (* 1 = 1.08874 loss)
I1004 22:50:45.231878 15924 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1004 22:50:47.491650 15924 solver.cpp:218] Iteration 2100 (44.0507 iter/s, 2.27011s/100 iters), loss = 0.858045
I1004 22:50:47.491650 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1004 22:50:47.491650 15924 solver.cpp:237]     Train net output #1: loss = 0.858045 (* 1 = 0.858045 loss)
I1004 22:50:47.491650 15924 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1004 22:50:49.752544 15924 solver.cpp:218] Iteration 2200 (44.2315 iter/s, 2.26083s/100 iters), loss = 0.910948
I1004 22:50:49.752544 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1004 22:50:49.752544 15924 solver.cpp:237]     Train net output #1: loss = 0.910948 (* 1 = 0.910948 loss)
I1004 22:50:49.752544 15924 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1004 22:50:52.020748 15924 solver.cpp:218] Iteration 2300 (44.1508 iter/s, 2.26497s/100 iters), loss = 0.913562
I1004 22:50:52.020748 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1004 22:50:52.020748 15924 solver.cpp:237]     Train net output #1: loss = 0.913562 (* 1 = 0.913562 loss)
I1004 22:50:52.020748 15924 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1004 22:50:54.284148 15924 solver.cpp:218] Iteration 2400 (44.2481 iter/s, 2.25998s/100 iters), loss = 0.86859
I1004 22:50:54.284148 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1004 22:50:54.284148 15924 solver.cpp:237]     Train net output #1: loss = 0.86859 (* 1 = 0.86859 loss)
I1004 22:50:54.284148 15924 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1004 22:50:56.439092  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:50:56.548451 15924 solver.cpp:218] Iteration 2500 (44.2177 iter/s, 2.26154s/100 iters), loss = 0.895005
I1004 22:50:56.548451 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1004 22:50:56.548451 15924 solver.cpp:237]     Train net output #1: loss = 0.895005 (* 1 = 0.895005 loss)
I1004 22:50:56.548451 15924 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1004 22:50:58.806386 15924 solver.cpp:218] Iteration 2600 (44.3513 iter/s, 2.25472s/100 iters), loss = 0.787991
I1004 22:50:58.806386 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1004 22:50:58.806386 15924 solver.cpp:237]     Train net output #1: loss = 0.787991 (* 1 = 0.787991 loss)
I1004 22:50:58.806386 15924 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1004 22:51:01.063097 15924 solver.cpp:218] Iteration 2700 (44.1604 iter/s, 2.26447s/100 iters), loss = 0.961721
I1004 22:51:01.063097 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1004 22:51:01.063097 15924 solver.cpp:237]     Train net output #1: loss = 0.961721 (* 1 = 0.961721 loss)
I1004 22:51:01.063097 15924 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1004 22:51:03.326021 15924 solver.cpp:218] Iteration 2800 (44.2647 iter/s, 2.25914s/100 iters), loss = 0.810484
I1004 22:51:03.326021 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1004 22:51:03.326021 15924 solver.cpp:237]     Train net output #1: loss = 0.810484 (* 1 = 0.810484 loss)
I1004 22:51:03.326021 15924 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1004 22:51:05.585610 15924 solver.cpp:218] Iteration 2900 (44.1772 iter/s, 2.26361s/100 iters), loss = 0.716627
I1004 22:51:05.585610 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1004 22:51:05.585610 15924 solver.cpp:237]     Train net output #1: loss = 0.716627 (* 1 = 0.716627 loss)
I1004 22:51:05.585610 15924 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1004 22:51:07.741521  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:51:07.835278 15924 solver.cpp:330] Iteration 3000, Testing net (#0)
I1004 22:51:07.835278 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:51:08.272778 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:51:08.288405 15924 solver.cpp:397]     Test net output #0: accuracy = 0.6868
I1004 22:51:08.288405 15924 solver.cpp:397]     Test net output #1: loss = 0.894966 (* 1 = 0.894966 loss)
I1004 22:51:08.304026 15924 solver.cpp:218] Iteration 3000 (36.781 iter/s, 2.7188s/100 iters), loss = 0.922937
I1004 22:51:08.304026 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1004 22:51:08.304026 15924 solver.cpp:237]     Train net output #1: loss = 0.922937 (* 1 = 0.922937 loss)
I1004 22:51:08.304026 15924 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1004 22:51:10.568831 15924 solver.cpp:218] Iteration 3100 (44.0802 iter/s, 2.26859s/100 iters), loss = 0.764147
I1004 22:51:10.568831 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1004 22:51:10.568831 15924 solver.cpp:237]     Train net output #1: loss = 0.764147 (* 1 = 0.764147 loss)
I1004 22:51:10.568831 15924 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1004 22:51:12.831609 15924 solver.cpp:218] Iteration 3200 (44.2722 iter/s, 2.25875s/100 iters), loss = 0.913045
I1004 22:51:12.831609 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1004 22:51:12.831609 15924 solver.cpp:237]     Train net output #1: loss = 0.913045 (* 1 = 0.913045 loss)
I1004 22:51:12.831609 15924 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1004 22:51:15.087805 15924 solver.cpp:218] Iteration 3300 (44.339 iter/s, 2.25535s/100 iters), loss = 0.824759
I1004 22:51:15.087805 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1004 22:51:15.087805 15924 solver.cpp:237]     Train net output #1: loss = 0.824759 (* 1 = 0.824759 loss)
I1004 22:51:15.087805 15924 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1004 22:51:17.351716 15924 solver.cpp:218] Iteration 3400 (44.3655 iter/s, 2.254s/100 iters), loss = 0.736328
I1004 22:51:17.351716 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1004 22:51:17.351716 15924 solver.cpp:237]     Train net output #1: loss = 0.736328 (* 1 = 0.736328 loss)
I1004 22:51:17.351716 15924 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1004 22:51:19.488288  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:51:19.597681 15924 solver.cpp:218] Iteration 3500 (44.2769 iter/s, 2.25851s/100 iters), loss = 0.875146
I1004 22:51:19.597681 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1004 22:51:19.597681 15924 solver.cpp:237]     Train net output #1: loss = 0.875146 (* 1 = 0.875146 loss)
I1004 22:51:19.597681 15924 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1004 22:51:21.866541 15924 solver.cpp:218] Iteration 3600 (44.0959 iter/s, 2.26778s/100 iters), loss = 0.756658
I1004 22:51:21.866541 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 22:51:21.866541 15924 solver.cpp:237]     Train net output #1: loss = 0.756658 (* 1 = 0.756658 loss)
I1004 22:51:21.866541 15924 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1004 22:51:24.141919 15924 solver.cpp:218] Iteration 3700 (44.133 iter/s, 2.26588s/100 iters), loss = 0.887279
I1004 22:51:24.141919 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1004 22:51:24.141919 15924 solver.cpp:237]     Train net output #1: loss = 0.887279 (* 1 = 0.887279 loss)
I1004 22:51:24.141919 15924 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1004 22:51:26.390986 15924 solver.cpp:218] Iteration 3800 (44.2353 iter/s, 2.26064s/100 iters), loss = 0.778817
I1004 22:51:26.390986 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 22:51:26.390986 15924 solver.cpp:237]     Train net output #1: loss = 0.778817 (* 1 = 0.778817 loss)
I1004 22:51:26.390986 15924 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1004 22:51:28.662883 15924 solver.cpp:218] Iteration 3900 (44.1231 iter/s, 2.26639s/100 iters), loss = 0.677855
I1004 22:51:28.662883 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1004 22:51:28.662883 15924 solver.cpp:237]     Train net output #1: loss = 0.677855 (* 1 = 0.677855 loss)
I1004 22:51:28.662883 15924 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1004 22:51:30.810647  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:51:30.904418 15924 solver.cpp:330] Iteration 4000, Testing net (#0)
I1004 22:51:30.904418 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:51:31.339323 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:51:31.354966 15924 solver.cpp:397]     Test net output #0: accuracy = 0.705
I1004 22:51:31.354966 15924 solver.cpp:397]     Test net output #1: loss = 0.85287 (* 1 = 0.85287 loss)
I1004 22:51:31.370573 15924 solver.cpp:218] Iteration 4000 (36.9041 iter/s, 2.70972s/100 iters), loss = 0.876839
I1004 22:51:31.370573 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1004 22:51:31.370573 15924 solver.cpp:237]     Train net output #1: loss = 0.876839 (* 1 = 0.876839 loss)
I1004 22:51:31.370573 15924 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1004 22:51:33.638120 15924 solver.cpp:218] Iteration 4100 (44.1813 iter/s, 2.2634s/100 iters), loss = 0.70233
I1004 22:51:33.638120 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1004 22:51:33.638120 15924 solver.cpp:237]     Train net output #1: loss = 0.70233 (* 1 = 0.70233 loss)
I1004 22:51:33.638120 15924 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1004 22:51:35.909811 15924 solver.cpp:218] Iteration 4200 (44.1728 iter/s, 2.26384s/100 iters), loss = 0.836546
I1004 22:51:35.909811 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1004 22:51:35.909811 15924 solver.cpp:237]     Train net output #1: loss = 0.836546 (* 1 = 0.836546 loss)
I1004 22:51:35.909811 15924 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1004 22:51:38.182731 15924 solver.cpp:218] Iteration 4300 (44.0091 iter/s, 2.27226s/100 iters), loss = 0.745069
I1004 22:51:38.182731 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1004 22:51:38.182731 15924 solver.cpp:237]     Train net output #1: loss = 0.745069 (* 1 = 0.745069 loss)
I1004 22:51:38.182731 15924 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1004 22:51:40.454617 15924 solver.cpp:218] Iteration 4400 (43.9476 iter/s, 2.27544s/100 iters), loss = 0.657249
I1004 22:51:40.454617 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1004 22:51:40.454617 15924 solver.cpp:237]     Train net output #1: loss = 0.657249 (* 1 = 0.657249 loss)
I1004 22:51:40.454617 15924 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1004 22:51:42.635895  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:51:42.736565 15924 solver.cpp:218] Iteration 4500 (43.7155 iter/s, 2.28752s/100 iters), loss = 0.763046
I1004 22:51:42.736565 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1004 22:51:42.736565 15924 solver.cpp:237]     Train net output #1: loss = 0.763046 (* 1 = 0.763046 loss)
I1004 22:51:42.736565 15924 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1004 22:51:45.024914 15924 solver.cpp:218] Iteration 4600 (43.8644 iter/s, 2.27975s/100 iters), loss = 0.596892
I1004 22:51:45.024914 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:51:45.024914 15924 solver.cpp:237]     Train net output #1: loss = 0.596892 (* 1 = 0.596892 loss)
I1004 22:51:45.024914 15924 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1004 22:51:47.284952 15924 solver.cpp:218] Iteration 4700 (44.1772 iter/s, 2.26361s/100 iters), loss = 0.791692
I1004 22:51:47.284952 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 22:51:47.284952 15924 solver.cpp:237]     Train net output #1: loss = 0.791692 (* 1 = 0.791692 loss)
I1004 22:51:47.284952 15924 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1004 22:51:49.558400 15924 solver.cpp:218] Iteration 4800 (43.8913 iter/s, 2.27836s/100 iters), loss = 0.707115
I1004 22:51:49.558400 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 22:51:49.558400 15924 solver.cpp:237]     Train net output #1: loss = 0.707115 (* 1 = 0.707115 loss)
I1004 22:51:49.558400 15924 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1004 22:51:51.869299 15924 solver.cpp:218] Iteration 4900 (43.3635 iter/s, 2.30608s/100 iters), loss = 0.625383
I1004 22:51:51.869299 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 22:51:51.869299 15924 solver.cpp:237]     Train net output #1: loss = 0.625383 (* 1 = 0.625383 loss)
I1004 22:51:51.869299 15924 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1004 22:51:54.038132  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:51:54.119354 15924 solver.cpp:330] Iteration 5000, Testing net (#0)
I1004 22:51:54.119354 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:51:54.556869 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:51:54.572474 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7181
I1004 22:51:54.572474 15924 solver.cpp:397]     Test net output #1: loss = 0.816599 (* 1 = 0.816599 loss)
I1004 22:51:54.588105 15924 solver.cpp:218] Iteration 5000 (36.7106 iter/s, 2.72401s/100 iters), loss = 0.764817
I1004 22:51:54.588105 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1004 22:51:54.588105 15924 solver.cpp:237]     Train net output #1: loss = 0.764817 (* 1 = 0.764817 loss)
I1004 22:51:54.588105 15924 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I1004 22:51:54.588105 15924 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I1004 22:51:56.891796 15924 solver.cpp:218] Iteration 5100 (43.3688 iter/s, 2.30581s/100 iters), loss = 0.5773
I1004 22:51:56.891796 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:51:56.891796 15924 solver.cpp:237]     Train net output #1: loss = 0.5773 (* 1 = 0.5773 loss)
I1004 22:51:56.891796 15924 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I1004 22:51:59.171691 15924 solver.cpp:218] Iteration 5200 (44.1408 iter/s, 2.26548s/100 iters), loss = 0.67061
I1004 22:51:59.171691 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 22:51:59.171691 15924 solver.cpp:237]     Train net output #1: loss = 0.67061 (* 1 = 0.67061 loss)
I1004 22:51:59.171691 15924 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I1004 22:52:01.434342 15924 solver.cpp:218] Iteration 5300 (43.9686 iter/s, 2.27435s/100 iters), loss = 0.627301
I1004 22:52:01.434342 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 22:52:01.434342 15924 solver.cpp:237]     Train net output #1: loss = 0.627301 (* 1 = 0.627301 loss)
I1004 22:52:01.434342 15924 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I1004 22:52:03.766105 15924 solver.cpp:218] Iteration 5400 (43.075 iter/s, 2.32153s/100 iters), loss = 0.566894
I1004 22:52:03.766105 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:52:03.766105 15924 solver.cpp:237]     Train net output #1: loss = 0.566894 (* 1 = 0.566894 loss)
I1004 22:52:03.766105 15924 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I1004 22:52:05.931457  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:52:06.040827 15924 solver.cpp:218] Iteration 5500 (43.7555 iter/s, 2.28543s/100 iters), loss = 0.728602
I1004 22:52:06.040827 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1004 22:52:06.040827 15924 solver.cpp:237]     Train net output #1: loss = 0.728602 (* 1 = 0.728602 loss)
I1004 22:52:06.040827 15924 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I1004 22:52:08.327807 15924 solver.cpp:218] Iteration 5600 (43.9951 iter/s, 2.27298s/100 iters), loss = 0.546764
I1004 22:52:08.327807 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:52:08.327807 15924 solver.cpp:237]     Train net output #1: loss = 0.546764 (* 1 = 0.546764 loss)
I1004 22:52:08.327807 15924 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I1004 22:52:10.637781 15924 solver.cpp:218] Iteration 5700 (43.1141 iter/s, 2.31942s/100 iters), loss = 0.706947
I1004 22:52:10.637781 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 22:52:10.637781 15924 solver.cpp:237]     Train net output #1: loss = 0.706947 (* 1 = 0.706947 loss)
I1004 22:52:10.637781 15924 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I1004 22:52:12.913452 15924 solver.cpp:218] Iteration 5800 (43.909 iter/s, 2.27744s/100 iters), loss = 0.555227
I1004 22:52:12.913452 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:52:12.913452 15924 solver.cpp:237]     Train net output #1: loss = 0.555227 (* 1 = 0.555227 loss)
I1004 22:52:12.913452 15924 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I1004 22:52:15.182343 15924 solver.cpp:218] Iteration 5900 (44.1544 iter/s, 2.26478s/100 iters), loss = 0.535705
I1004 22:52:15.182343 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:52:15.182343 15924 solver.cpp:237]     Train net output #1: loss = 0.535705 (* 1 = 0.535705 loss)
I1004 22:52:15.182343 15924 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I1004 22:52:17.371480  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:52:17.465248 15924 solver.cpp:330] Iteration 6000, Testing net (#0)
I1004 22:52:17.465248 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:52:17.912675 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:52:17.928302 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7513
I1004 22:52:17.928302 15924 solver.cpp:397]     Test net output #1: loss = 0.710775 (* 1 = 0.710775 loss)
I1004 22:52:17.943927 15924 solver.cpp:218] Iteration 6000 (36.167 iter/s, 2.76495s/100 iters), loss = 0.651681
I1004 22:52:17.943927 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 22:52:17.943927 15924 solver.cpp:237]     Train net output #1: loss = 0.651681 (* 1 = 0.651681 loss)
I1004 22:52:17.943927 15924 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I1004 22:52:20.221098 15924 solver.cpp:218] Iteration 6100 (44.0409 iter/s, 2.27061s/100 iters), loss = 0.582889
I1004 22:52:20.221098 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:52:20.221098 15924 solver.cpp:237]     Train net output #1: loss = 0.582889 (* 1 = 0.582889 loss)
I1004 22:52:20.221098 15924 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I1004 22:52:22.502852 15924 solver.cpp:218] Iteration 6200 (43.9449 iter/s, 2.27558s/100 iters), loss = 0.636375
I1004 22:52:22.502852 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:52:22.502852 15924 solver.cpp:237]     Train net output #1: loss = 0.636375 (* 1 = 0.636375 loss)
I1004 22:52:22.502852 15924 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I1004 22:52:24.794898 15924 solver.cpp:218] Iteration 6300 (43.4156 iter/s, 2.30332s/100 iters), loss = 0.568108
I1004 22:52:24.794898 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:52:24.794898 15924 solver.cpp:237]     Train net output #1: loss = 0.568108 (* 1 = 0.568108 loss)
I1004 22:52:24.794898 15924 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I1004 22:52:27.067741 15924 solver.cpp:218] Iteration 6400 (44.2297 iter/s, 2.26092s/100 iters), loss = 0.493159
I1004 22:52:27.067741 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:52:27.067741 15924 solver.cpp:237]     Train net output #1: loss = 0.493159 (* 1 = 0.493159 loss)
I1004 22:52:27.067741 15924 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I1004 22:52:29.215965  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:52:29.331809 15924 solver.cpp:218] Iteration 6500 (44.1686 iter/s, 2.26405s/100 iters), loss = 0.658811
I1004 22:52:29.331809 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 22:52:29.331809 15924 solver.cpp:237]     Train net output #1: loss = 0.658811 (* 1 = 0.658811 loss)
I1004 22:52:29.331809 15924 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I1004 22:52:31.584729 15924 solver.cpp:218] Iteration 6600 (44.2609 iter/s, 2.25933s/100 iters), loss = 0.45428
I1004 22:52:31.584729 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 22:52:31.584729 15924 solver.cpp:237]     Train net output #1: loss = 0.45428 (* 1 = 0.45428 loss)
I1004 22:52:31.584729 15924 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I1004 22:52:33.844096 15924 solver.cpp:218] Iteration 6700 (44.1511 iter/s, 2.26495s/100 iters), loss = 0.615638
I1004 22:52:33.844096 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:52:33.844096 15924 solver.cpp:237]     Train net output #1: loss = 0.615638 (* 1 = 0.615638 loss)
I1004 22:52:33.844096 15924 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I1004 22:52:36.111026 15924 solver.cpp:218] Iteration 6800 (44.2392 iter/s, 2.26044s/100 iters), loss = 0.485301
I1004 22:52:36.111026 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:52:36.111026 15924 solver.cpp:237]     Train net output #1: loss = 0.485301 (* 1 = 0.485301 loss)
I1004 22:52:36.111026 15924 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I1004 22:52:38.381748 15924 solver.cpp:218] Iteration 6900 (44.1195 iter/s, 2.26657s/100 iters), loss = 0.548858
I1004 22:52:38.381748 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:52:38.381748 15924 solver.cpp:237]     Train net output #1: loss = 0.548858 (* 1 = 0.548858 loss)
I1004 22:52:38.381748 15924 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I1004 22:52:40.554651  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:52:40.648406 15924 solver.cpp:330] Iteration 7000, Testing net (#0)
I1004 22:52:40.648406 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:52:41.101534 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:52:41.117139 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7504
I1004 22:52:41.117139 15924 solver.cpp:397]     Test net output #1: loss = 0.706746 (* 1 = 0.706746 loss)
I1004 22:52:41.132764 15924 solver.cpp:218] Iteration 7000 (36.2303 iter/s, 2.76012s/100 iters), loss = 0.614216
I1004 22:52:41.132764 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 22:52:41.132764 15924 solver.cpp:237]     Train net output #1: loss = 0.614216 (* 1 = 0.614216 loss)
I1004 22:52:41.132764 15924 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I1004 22:52:43.468745 15924 solver.cpp:218] Iteration 7100 (42.9576 iter/s, 2.32788s/100 iters), loss = 0.602399
I1004 22:52:43.468745 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:52:43.468745 15924 solver.cpp:237]     Train net output #1: loss = 0.602399 (* 1 = 0.602399 loss)
I1004 22:52:43.468745 15924 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I1004 22:52:45.736047 15924 solver.cpp:218] Iteration 7200 (44.1964 iter/s, 2.26263s/100 iters), loss = 0.602511
I1004 22:52:45.736047 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:52:45.736047 15924 solver.cpp:237]     Train net output #1: loss = 0.602511 (* 1 = 0.602511 loss)
I1004 22:52:45.736047 15924 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I1004 22:52:48.043925 15924 solver.cpp:218] Iteration 7300 (43.1324 iter/s, 2.31844s/100 iters), loss = 0.51716
I1004 22:52:48.043925 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:52:48.043925 15924 solver.cpp:237]     Train net output #1: loss = 0.51716 (* 1 = 0.51716 loss)
I1004 22:52:48.043925 15924 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I1004 22:52:50.319933 15924 solver.cpp:218] Iteration 7400 (43.8839 iter/s, 2.27874s/100 iters), loss = 0.508813
I1004 22:52:50.319933 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:52:50.319933 15924 solver.cpp:237]     Train net output #1: loss = 0.508813 (* 1 = 0.508813 loss)
I1004 22:52:50.319933 15924 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I1004 22:52:52.487166  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:52:52.601219 15924 solver.cpp:218] Iteration 7500 (44.1079 iter/s, 2.26717s/100 iters), loss = 0.636377
I1004 22:52:52.601219 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1004 22:52:52.601219 15924 solver.cpp:237]     Train net output #1: loss = 0.636377 (* 1 = 0.636377 loss)
I1004 22:52:52.601219 15924 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I1004 22:52:54.902326 15924 solver.cpp:218] Iteration 7600 (43.431 iter/s, 2.3025s/100 iters), loss = 0.452594
I1004 22:52:54.902326 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:52:54.902326 15924 solver.cpp:237]     Train net output #1: loss = 0.452594 (* 1 = 0.452594 loss)
I1004 22:52:54.902326 15924 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I1004 22:52:57.193284 15924 solver.cpp:218] Iteration 7700 (43.6441 iter/s, 2.29126s/100 iters), loss = 0.657326
I1004 22:52:57.193284 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:52:57.193284 15924 solver.cpp:237]     Train net output #1: loss = 0.657326 (* 1 = 0.657326 loss)
I1004 22:52:57.193284 15924 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I1004 22:52:59.489318 15924 solver.cpp:218] Iteration 7800 (43.5145 iter/s, 2.29808s/100 iters), loss = 0.507007
I1004 22:52:59.489318 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:52:59.489318 15924 solver.cpp:237]     Train net output #1: loss = 0.507007 (* 1 = 0.507007 loss)
I1004 22:52:59.489318 15924 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I1004 22:53:01.783759 15924 solver.cpp:218] Iteration 7900 (43.4657 iter/s, 2.30066s/100 iters), loss = 0.494661
I1004 22:53:01.783759 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:53:01.783759 15924 solver.cpp:237]     Train net output #1: loss = 0.494661 (* 1 = 0.494661 loss)
I1004 22:53:01.783759 15924 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I1004 22:53:03.970937  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:53:04.049059 15924 solver.cpp:330] Iteration 8000, Testing net (#0)
I1004 22:53:04.049059 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:53:04.478586 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:53:04.494213 15924 solver.cpp:397]     Test net output #0: accuracy = 0.755
I1004 22:53:04.494213 15924 solver.cpp:397]     Test net output #1: loss = 0.704389 (* 1 = 0.704389 loss)
I1004 22:53:04.525462 15924 solver.cpp:218] Iteration 8000 (36.6162 iter/s, 2.73103s/100 iters), loss = 0.549904
I1004 22:53:04.525462 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:53:04.525462 15924 solver.cpp:237]     Train net output #1: loss = 0.549904 (* 1 = 0.549904 loss)
I1004 22:53:04.525462 15924 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I1004 22:53:06.782862 15924 solver.cpp:218] Iteration 8100 (44.0374 iter/s, 2.2708s/100 iters), loss = 0.481281
I1004 22:53:06.782862 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:53:06.782862 15924 solver.cpp:237]     Train net output #1: loss = 0.481281 (* 1 = 0.481281 loss)
I1004 22:53:06.782862 15924 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I1004 22:53:09.096796 15924 solver.cpp:218] Iteration 8200 (43.4409 iter/s, 2.30198s/100 iters), loss = 0.630155
I1004 22:53:09.096796 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:53:09.096796 15924 solver.cpp:237]     Train net output #1: loss = 0.630155 (* 1 = 0.630155 loss)
I1004 22:53:09.096796 15924 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I1004 22:53:11.392065 15924 solver.cpp:218] Iteration 8300 (43.5421 iter/s, 2.29663s/100 iters), loss = 0.505979
I1004 22:53:11.392065 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 22:53:11.392065 15924 solver.cpp:237]     Train net output #1: loss = 0.505979 (* 1 = 0.505979 loss)
I1004 22:53:11.392065 15924 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I1004 22:53:13.685077 15924 solver.cpp:218] Iteration 8400 (43.5992 iter/s, 2.29362s/100 iters), loss = 0.488261
I1004 22:53:13.685077 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:53:13.685077 15924 solver.cpp:237]     Train net output #1: loss = 0.488261 (* 1 = 0.488261 loss)
I1004 22:53:13.685077 15924 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I1004 22:53:15.851272  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:53:15.960647 15924 solver.cpp:218] Iteration 8500 (43.9391 iter/s, 2.27587s/100 iters), loss = 0.606691
I1004 22:53:15.960647 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:53:15.960647 15924 solver.cpp:237]     Train net output #1: loss = 0.606691 (* 1 = 0.606691 loss)
I1004 22:53:15.960647 15924 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I1004 22:53:18.269201 15924 solver.cpp:218] Iteration 8600 (43.2959 iter/s, 2.30969s/100 iters), loss = 0.521704
I1004 22:53:18.269201 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:53:18.269201 15924 solver.cpp:237]     Train net output #1: loss = 0.521704 (* 1 = 0.521704 loss)
I1004 22:53:18.269201 15924 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I1004 22:53:20.546890 15924 solver.cpp:218] Iteration 8700 (43.9002 iter/s, 2.27789s/100 iters), loss = 0.626051
I1004 22:53:20.546890 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:53:20.546890 15924 solver.cpp:237]     Train net output #1: loss = 0.626051 (* 1 = 0.626051 loss)
I1004 22:53:20.546890 15924 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I1004 22:53:22.818625 15924 solver.cpp:218] Iteration 8800 (43.9198 iter/s, 2.27688s/100 iters), loss = 0.481628
I1004 22:53:22.818625 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:53:22.818625 15924 solver.cpp:237]     Train net output #1: loss = 0.481628 (* 1 = 0.481628 loss)
I1004 22:53:22.818625 15924 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I1004 22:53:25.136808 15924 solver.cpp:218] Iteration 8900 (43.177 iter/s, 2.31605s/100 iters), loss = 0.416952
I1004 22:53:25.136808 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:53:25.136808 15924 solver.cpp:237]     Train net output #1: loss = 0.416952 (* 1 = 0.416952 loss)
I1004 22:53:25.136808 15924 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I1004 22:53:27.332937  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:53:27.426689 15924 solver.cpp:330] Iteration 9000, Testing net (#0)
I1004 22:53:27.426689 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:53:27.867919 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:53:27.883548 15924 solver.cpp:397]     Test net output #0: accuracy = 0.758
I1004 22:53:27.883548 15924 solver.cpp:397]     Test net output #1: loss = 0.699527 (* 1 = 0.699527 loss)
I1004 22:53:27.914794 15924 solver.cpp:218] Iteration 9000 (36.1235 iter/s, 2.76828s/100 iters), loss = 0.594569
I1004 22:53:27.914794 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 22:53:27.914794 15924 solver.cpp:237]     Train net output #1: loss = 0.594569 (* 1 = 0.594569 loss)
I1004 22:53:27.914794 15924 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I1004 22:53:30.193620 15924 solver.cpp:218] Iteration 9100 (43.6696 iter/s, 2.28992s/100 iters), loss = 0.425922
I1004 22:53:30.193620 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 22:53:30.193620 15924 solver.cpp:237]     Train net output #1: loss = 0.425922 (* 1 = 0.425922 loss)
I1004 22:53:30.193620 15924 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I1004 22:53:32.481781 15924 solver.cpp:218] Iteration 9200 (43.8182 iter/s, 2.28216s/100 iters), loss = 0.594348
I1004 22:53:32.481781 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:53:32.481781 15924 solver.cpp:237]     Train net output #1: loss = 0.594348 (* 1 = 0.594348 loss)
I1004 22:53:32.481781 15924 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I1004 22:53:34.796466 15924 solver.cpp:218] Iteration 9300 (43.3077 iter/s, 2.30906s/100 iters), loss = 0.461418
I1004 22:53:34.796466 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:53:34.796466 15924 solver.cpp:237]     Train net output #1: loss = 0.461418 (* 1 = 0.461418 loss)
I1004 22:53:34.796466 15924 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I1004 22:53:37.112658 15924 solver.cpp:218] Iteration 9400 (43.0593 iter/s, 2.32238s/100 iters), loss = 0.421491
I1004 22:53:37.112658 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:53:37.112658 15924 solver.cpp:237]     Train net output #1: loss = 0.421491 (* 1 = 0.421491 loss)
I1004 22:53:37.112658 15924 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I1004 22:53:39.304410  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:53:39.422179 15924 solver.cpp:218] Iteration 9500 (43.3503 iter/s, 2.30679s/100 iters), loss = 0.511042
I1004 22:53:39.422179 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:53:39.422179 15924 solver.cpp:237]     Train net output #1: loss = 0.511042 (* 1 = 0.511042 loss)
I1004 22:53:39.422179 15924 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1004 22:53:41.699082 15924 solver.cpp:218] Iteration 9600 (43.9517 iter/s, 2.27522s/100 iters), loss = 0.498063
I1004 22:53:41.699082 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:53:41.699082 15924 solver.cpp:237]     Train net output #1: loss = 0.498063 (* 1 = 0.498063 loss)
I1004 22:53:41.699082 15924 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1004 22:53:44.043970 15924 solver.cpp:218] Iteration 9700 (42.76 iter/s, 2.33863s/100 iters), loss = 0.643588
I1004 22:53:44.043970 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:53:44.043970 15924 solver.cpp:237]     Train net output #1: loss = 0.643588 (* 1 = 0.643588 loss)
I1004 22:53:44.043970 15924 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I1004 22:53:46.309816 15924 solver.cpp:218] Iteration 9800 (43.8839 iter/s, 2.27874s/100 iters), loss = 0.467023
I1004 22:53:46.309816 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:53:46.309816 15924 solver.cpp:237]     Train net output #1: loss = 0.467023 (* 1 = 0.467023 loss)
I1004 22:53:46.309816 15924 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1004 22:53:48.611060 15924 solver.cpp:218] Iteration 9900 (43.5021 iter/s, 2.29874s/100 iters), loss = 0.481499
I1004 22:53:48.611060 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:53:48.611060 15924 solver.cpp:237]     Train net output #1: loss = 0.481499 (* 1 = 0.481499 loss)
I1004 22:53:48.611060 15924 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I1004 22:53:50.827332  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:53:50.921080 15924 solver.cpp:330] Iteration 10000, Testing net (#0)
I1004 22:53:50.921080 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:53:51.339321 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:53:51.354946 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7587
I1004 22:53:51.354946 15924 solver.cpp:397]     Test net output #1: loss = 0.698965 (* 1 = 0.698965 loss)
I1004 22:53:51.386195 15924 solver.cpp:218] Iteration 10000 (36.128 iter/s, 2.76793s/100 iters), loss = 0.617286
I1004 22:53:51.386195 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:53:51.386195 15924 solver.cpp:237]     Train net output #1: loss = 0.617286 (* 1 = 0.617286 loss)
I1004 22:53:51.386195 15924 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I1004 22:53:51.386195 15924 sgd_solver.cpp:105] Iteration 10000, lr = 0.0001
I1004 22:53:53.687685 15924 solver.cpp:218] Iteration 10100 (43.5007 iter/s, 2.29881s/100 iters), loss = 0.507572
I1004 22:53:53.687685 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:53:53.687685 15924 solver.cpp:237]     Train net output #1: loss = 0.507572 (* 1 = 0.507572 loss)
I1004 22:53:53.687685 15924 sgd_solver.cpp:105] Iteration 10100, lr = 0.0001
I1004 22:53:55.969197 15924 solver.cpp:218] Iteration 10200 (43.7747 iter/s, 2.28442s/100 iters), loss = 0.555114
I1004 22:53:55.969197 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:53:55.969197 15924 solver.cpp:237]     Train net output #1: loss = 0.555114 (* 1 = 0.555114 loss)
I1004 22:53:55.969197 15924 sgd_solver.cpp:105] Iteration 10200, lr = 0.0001
I1004 22:53:58.241226 15924 solver.cpp:218] Iteration 10300 (44.1103 iter/s, 2.26704s/100 iters), loss = 0.436364
I1004 22:53:58.241226 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:53:58.241226 15924 solver.cpp:237]     Train net output #1: loss = 0.436364 (* 1 = 0.436364 loss)
I1004 22:53:58.241226 15924 sgd_solver.cpp:105] Iteration 10300, lr = 0.0001
I1004 22:54:00.562980 15924 solver.cpp:218] Iteration 10400 (43.0137 iter/s, 2.32484s/100 iters), loss = 0.505185
I1004 22:54:00.562980 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:54:00.562980 15924 solver.cpp:237]     Train net output #1: loss = 0.505185 (* 1 = 0.505185 loss)
I1004 22:54:00.562980 15924 sgd_solver.cpp:105] Iteration 10400, lr = 0.0001
I1004 22:54:02.725831  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:54:02.835206 15924 solver.cpp:218] Iteration 10500 (43.883 iter/s, 2.27879s/100 iters), loss = 0.558002
I1004 22:54:02.835206 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:54:02.835206 15924 solver.cpp:237]     Train net output #1: loss = 0.558002 (* 1 = 0.558002 loss)
I1004 22:54:02.835206 15924 sgd_solver.cpp:105] Iteration 10500, lr = 0.0001
I1004 22:54:05.149745 15924 solver.cpp:218] Iteration 10600 (43.2487 iter/s, 2.31221s/100 iters), loss = 0.461984
I1004 22:54:05.149745 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:54:05.149745 15924 solver.cpp:237]     Train net output #1: loss = 0.461984 (* 1 = 0.461984 loss)
I1004 22:54:05.149745 15924 sgd_solver.cpp:105] Iteration 10600, lr = 0.0001
I1004 22:54:07.446436 15924 solver.cpp:218] Iteration 10700 (43.4515 iter/s, 2.30142s/100 iters), loss = 0.580406
I1004 22:54:07.446436 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:54:07.446436 15924 solver.cpp:237]     Train net output #1: loss = 0.580406 (* 1 = 0.580406 loss)
I1004 22:54:07.446436 15924 sgd_solver.cpp:105] Iteration 10700, lr = 0.0001
I1004 22:54:09.800388 15924 solver.cpp:218] Iteration 10800 (42.5639 iter/s, 2.34941s/100 iters), loss = 0.461359
I1004 22:54:09.800388 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:54:09.800388 15924 solver.cpp:237]     Train net output #1: loss = 0.461359 (* 1 = 0.461359 loss)
I1004 22:54:09.800388 15924 sgd_solver.cpp:105] Iteration 10800, lr = 0.0001
I1004 22:54:12.078866 15924 solver.cpp:218] Iteration 10900 (43.8394 iter/s, 2.28105s/100 iters), loss = 0.472772
I1004 22:54:12.078866 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:54:12.078866 15924 solver.cpp:237]     Train net output #1: loss = 0.472772 (* 1 = 0.472772 loss)
I1004 22:54:12.078866 15924 sgd_solver.cpp:105] Iteration 10900, lr = 0.0001
I1004 22:54:14.284024  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:54:14.377774 15924 solver.cpp:330] Iteration 11000, Testing net (#0)
I1004 22:54:14.377774 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:54:14.815273 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:54:14.830898 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7633
I1004 22:54:14.830898 15924 solver.cpp:397]     Test net output #1: loss = 0.691835 (* 1 = 0.691835 loss)
I1004 22:54:14.862130 15924 solver.cpp:218] Iteration 11000 (36.077 iter/s, 2.77185s/100 iters), loss = 0.488653
I1004 22:54:14.862130 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:54:14.862130 15924 solver.cpp:237]     Train net output #1: loss = 0.488653 (* 1 = 0.488653 loss)
I1004 22:54:14.862130 15924 sgd_solver.cpp:105] Iteration 11000, lr = 0.0001
I1004 22:54:17.190526 15924 solver.cpp:218] Iteration 11100 (42.9764 iter/s, 2.32686s/100 iters), loss = 0.510012
I1004 22:54:17.190526 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:54:17.190526 15924 solver.cpp:237]     Train net output #1: loss = 0.510012 (* 1 = 0.510012 loss)
I1004 22:54:17.190526 15924 sgd_solver.cpp:105] Iteration 11100, lr = 0.0001
I1004 22:54:19.495939 15924 solver.cpp:218] Iteration 11200 (43.3931 iter/s, 2.30451s/100 iters), loss = 0.623325
I1004 22:54:19.495939 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:54:19.495939 15924 solver.cpp:237]     Train net output #1: loss = 0.623325 (* 1 = 0.623325 loss)
I1004 22:54:19.495939 15924 sgd_solver.cpp:105] Iteration 11200, lr = 0.0001
I1004 22:54:21.784934 15924 solver.cpp:218] Iteration 11300 (43.6872 iter/s, 2.289s/100 iters), loss = 0.445876
I1004 22:54:21.784934 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:54:21.784934 15924 solver.cpp:237]     Train net output #1: loss = 0.445876 (* 1 = 0.445876 loss)
I1004 22:54:21.784934 15924 sgd_solver.cpp:105] Iteration 11300, lr = 0.0001
I1004 22:54:24.097687 15924 solver.cpp:218] Iteration 11400 (43.2068 iter/s, 2.31445s/100 iters), loss = 0.423007
I1004 22:54:24.097687 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:54:24.097687 15924 solver.cpp:237]     Train net output #1: loss = 0.423007 (* 1 = 0.423007 loss)
I1004 22:54:24.097687 15924 sgd_solver.cpp:105] Iteration 11400, lr = 0.0001
I1004 22:54:26.252321  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:54:26.361714 15924 solver.cpp:218] Iteration 11500 (44.0525 iter/s, 2.27002s/100 iters), loss = 0.569354
I1004 22:54:26.361714 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 22:54:26.361714 15924 solver.cpp:237]     Train net output #1: loss = 0.569354 (* 1 = 0.569354 loss)
I1004 22:54:26.361714 15924 sgd_solver.cpp:105] Iteration 11500, lr = 0.0001
I1004 22:54:28.653137 15924 solver.cpp:218] Iteration 11600 (43.6046 iter/s, 2.29334s/100 iters), loss = 0.46418
I1004 22:54:28.653137 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:54:28.653137 15924 solver.cpp:237]     Train net output #1: loss = 0.46418 (* 1 = 0.46418 loss)
I1004 22:54:28.653137 15924 sgd_solver.cpp:105] Iteration 11600, lr = 0.0001
I1004 22:54:30.968415 15924 solver.cpp:218] Iteration 11700 (43.3716 iter/s, 2.30566s/100 iters), loss = 0.577263
I1004 22:54:30.968415 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:54:30.968415 15924 solver.cpp:237]     Train net output #1: loss = 0.577263 (* 1 = 0.577263 loss)
I1004 22:54:30.968415 15924 sgd_solver.cpp:105] Iteration 11700, lr = 0.0001
I1004 22:54:33.274533 15924 solver.cpp:218] Iteration 11800 (43.408 iter/s, 2.30372s/100 iters), loss = 0.485185
I1004 22:54:33.274533 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:54:33.274533 15924 solver.cpp:237]     Train net output #1: loss = 0.485185 (* 1 = 0.485185 loss)
I1004 22:54:33.274533 15924 sgd_solver.cpp:105] Iteration 11800, lr = 0.0001
I1004 22:54:35.529353 15924 solver.cpp:218] Iteration 11900 (44.1484 iter/s, 2.26509s/100 iters), loss = 0.449807
I1004 22:54:35.529353 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:54:35.529353 15924 solver.cpp:237]     Train net output #1: loss = 0.449807 (* 1 = 0.449807 loss)
I1004 22:54:35.529353 15924 sgd_solver.cpp:105] Iteration 11900, lr = 0.0001
I1004 22:54:37.726291  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:54:37.820060 15924 solver.cpp:330] Iteration 12000, Testing net (#0)
I1004 22:54:37.820060 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:54:38.243592 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:54:38.259227 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7636
I1004 22:54:38.259227 15924 solver.cpp:397]     Test net output #1: loss = 0.691582 (* 1 = 0.691582 loss)
I1004 22:54:38.290475 15924 solver.cpp:218] Iteration 12000 (36.3337 iter/s, 2.75227s/100 iters), loss = 0.460459
I1004 22:54:38.290475 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:54:38.290475 15924 solver.cpp:237]     Train net output #1: loss = 0.460459 (* 1 = 0.460459 loss)
I1004 22:54:38.290475 15924 sgd_solver.cpp:105] Iteration 12000, lr = 0.0001
I1004 22:54:40.551573 15924 solver.cpp:218] Iteration 12100 (44.0774 iter/s, 2.26874s/100 iters), loss = 0.43646
I1004 22:54:40.551573 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 22:54:40.551573 15924 solver.cpp:237]     Train net output #1: loss = 0.43646 (* 1 = 0.43646 loss)
I1004 22:54:40.551573 15924 sgd_solver.cpp:105] Iteration 12100, lr = 0.0001
I1004 22:54:42.859992 15924 solver.cpp:218] Iteration 12200 (43.4696 iter/s, 2.30046s/100 iters), loss = 0.632114
I1004 22:54:42.859992 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:54:42.859992 15924 solver.cpp:237]     Train net output #1: loss = 0.632114 (* 1 = 0.632114 loss)
I1004 22:54:42.859992 15924 sgd_solver.cpp:105] Iteration 12200, lr = 0.0001
I1004 22:54:45.144302 15924 solver.cpp:218] Iteration 12300 (43.6774 iter/s, 2.28951s/100 iters), loss = 0.519236
I1004 22:54:45.144302 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:54:45.144302 15924 solver.cpp:237]     Train net output #1: loss = 0.519236 (* 1 = 0.519236 loss)
I1004 22:54:45.144302 15924 sgd_solver.cpp:105] Iteration 12300, lr = 0.0001
I1004 22:54:47.470659 15924 solver.cpp:218] Iteration 12400 (42.9836 iter/s, 2.32647s/100 iters), loss = 0.506971
I1004 22:54:47.470659 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:54:47.470659 15924 solver.cpp:237]     Train net output #1: loss = 0.506971 (* 1 = 0.506971 loss)
I1004 22:54:47.470659 15924 sgd_solver.cpp:105] Iteration 12400, lr = 0.0001
I1004 22:54:49.640813  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:54:49.750188 15924 solver.cpp:218] Iteration 12500 (43.8874 iter/s, 2.27856s/100 iters), loss = 0.597706
I1004 22:54:49.750188 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 22:54:49.750188 15924 solver.cpp:237]     Train net output #1: loss = 0.597706 (* 1 = 0.597706 loss)
I1004 22:54:49.750188 15924 sgd_solver.cpp:105] Iteration 12500, lr = 0.0001
I1004 22:54:52.027585 15924 solver.cpp:218] Iteration 12600 (44.0273 iter/s, 2.27132s/100 iters), loss = 0.452001
I1004 22:54:52.027585 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 22:54:52.027585 15924 solver.cpp:237]     Train net output #1: loss = 0.452001 (* 1 = 0.452001 loss)
I1004 22:54:52.027585 15924 sgd_solver.cpp:105] Iteration 12600, lr = 0.0001
I1004 22:54:54.297801 15924 solver.cpp:218] Iteration 12700 (44.0237 iter/s, 2.2715s/100 iters), loss = 0.614202
I1004 22:54:54.297801 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:54:54.297801 15924 solver.cpp:237]     Train net output #1: loss = 0.614202 (* 1 = 0.614202 loss)
I1004 22:54:54.297801 15924 sgd_solver.cpp:105] Iteration 12700, lr = 0.0001
I1004 22:54:56.639883 15924 solver.cpp:218] Iteration 12800 (42.6619 iter/s, 2.34401s/100 iters), loss = 0.52714
I1004 22:54:56.639883 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:54:56.639883 15924 solver.cpp:237]     Train net output #1: loss = 0.52714 (* 1 = 0.52714 loss)
I1004 22:54:56.639883 15924 sgd_solver.cpp:105] Iteration 12800, lr = 0.0001
I1004 22:54:58.937036 15924 solver.cpp:218] Iteration 12900 (43.5155 iter/s, 2.29803s/100 iters), loss = 0.395096
I1004 22:54:58.937036 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:54:58.937036 15924 solver.cpp:237]     Train net output #1: loss = 0.395096 (* 1 = 0.395096 loss)
I1004 22:54:58.937036 15924 sgd_solver.cpp:105] Iteration 12900, lr = 0.0001
I1004 22:55:01.094228  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:55:01.187996 15924 solver.cpp:330] Iteration 13000, Testing net (#0)
I1004 22:55:01.187996 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:55:01.623105 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:55:01.638746 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7627
I1004 22:55:01.638746 15924 solver.cpp:397]     Test net output #1: loss = 0.691379 (* 1 = 0.691379 loss)
I1004 22:55:01.670012 15924 solver.cpp:218] Iteration 13000 (36.6801 iter/s, 2.72627s/100 iters), loss = 0.590326
I1004 22:55:01.670012 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:55:01.670012 15924 solver.cpp:237]     Train net output #1: loss = 0.590326 (* 1 = 0.590326 loss)
I1004 22:55:01.670012 15924 sgd_solver.cpp:105] Iteration 13000, lr = 0.0001
I1004 22:55:04.004902 15924 solver.cpp:218] Iteration 13100 (42.7311 iter/s, 2.34021s/100 iters), loss = 0.411
I1004 22:55:04.004902 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:55:04.004902 15924 solver.cpp:237]     Train net output #1: loss = 0.411 (* 1 = 0.411 loss)
I1004 22:55:04.004902 15924 sgd_solver.cpp:105] Iteration 13100, lr = 0.0001
I1004 22:55:06.274750 15924 solver.cpp:218] Iteration 13200 (43.9865 iter/s, 2.27342s/100 iters), loss = 0.509055
I1004 22:55:06.274750 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:55:06.274750 15924 solver.cpp:237]     Train net output #1: loss = 0.509055 (* 1 = 0.509055 loss)
I1004 22:55:06.274750 15924 sgd_solver.cpp:105] Iteration 13200, lr = 0.0001
I1004 22:55:08.577406 15924 solver.cpp:218] Iteration 13300 (43.5298 iter/s, 2.29728s/100 iters), loss = 0.452719
I1004 22:55:08.577406 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:55:08.577406 15924 solver.cpp:237]     Train net output #1: loss = 0.452719 (* 1 = 0.452719 loss)
I1004 22:55:08.577406 15924 sgd_solver.cpp:105] Iteration 13300, lr = 0.0001
I1004 22:55:10.874301 15924 solver.cpp:218] Iteration 13400 (43.4856 iter/s, 2.29961s/100 iters), loss = 0.433959
I1004 22:55:10.874301 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:55:10.874301 15924 solver.cpp:237]     Train net output #1: loss = 0.433959 (* 1 = 0.433959 loss)
I1004 22:55:10.874301 15924 sgd_solver.cpp:105] Iteration 13400, lr = 0.0001
I1004 22:55:13.070202  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:55:13.187718 15924 solver.cpp:218] Iteration 13500 (43.3763 iter/s, 2.30541s/100 iters), loss = 0.521084
I1004 22:55:13.187718 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:55:13.187718 15924 solver.cpp:237]     Train net output #1: loss = 0.521084 (* 1 = 0.521084 loss)
I1004 22:55:13.187718 15924 sgd_solver.cpp:105] Iteration 13500, lr = 0.0001
I1004 22:55:15.489392 15924 solver.cpp:218] Iteration 13600 (43.3146 iter/s, 2.30869s/100 iters), loss = 0.483583
I1004 22:55:15.489392 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:55:15.489392 15924 solver.cpp:237]     Train net output #1: loss = 0.483583 (* 1 = 0.483583 loss)
I1004 22:55:15.489392 15924 sgd_solver.cpp:105] Iteration 13600, lr = 0.0001
I1004 22:55:17.759171 15924 solver.cpp:218] Iteration 13700 (43.9975 iter/s, 2.27286s/100 iters), loss = 0.589242
I1004 22:55:17.759171 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:55:17.759171 15924 solver.cpp:237]     Train net output #1: loss = 0.589242 (* 1 = 0.589242 loss)
I1004 22:55:17.759171 15924 sgd_solver.cpp:105] Iteration 13700, lr = 0.0001
I1004 22:55:20.032073 15924 solver.cpp:218] Iteration 13800 (43.9729 iter/s, 2.27413s/100 iters), loss = 0.510107
I1004 22:55:20.032073 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:55:20.032073 15924 solver.cpp:237]     Train net output #1: loss = 0.510107 (* 1 = 0.510107 loss)
I1004 22:55:20.032073 15924 sgd_solver.cpp:105] Iteration 13800, lr = 0.0001
I1004 22:55:22.309096 15924 solver.cpp:218] Iteration 13900 (43.8784 iter/s, 2.27903s/100 iters), loss = 0.419072
I1004 22:55:22.309096 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:55:22.309096 15924 solver.cpp:237]     Train net output #1: loss = 0.419072 (* 1 = 0.419072 loss)
I1004 22:55:22.309096 15924 sgd_solver.cpp:105] Iteration 13900, lr = 0.0001
I1004 22:55:24.505210  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:55:24.598955 15924 solver.cpp:330] Iteration 14000, Testing net (#0)
I1004 22:55:24.598955 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:55:25.036473 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:55:25.052091 15924 solver.cpp:397]     Test net output #0: accuracy = 0.763
I1004 22:55:25.052091 15924 solver.cpp:397]     Test net output #1: loss = 0.691356 (* 1 = 0.691356 loss)
I1004 22:55:25.067705 15924 solver.cpp:218] Iteration 14000 (36.2831 iter/s, 2.7561s/100 iters), loss = 0.619925
I1004 22:55:25.067705 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1004 22:55:25.067705 15924 solver.cpp:237]     Train net output #1: loss = 0.619925 (* 1 = 0.619925 loss)
I1004 22:55:25.067705 15924 sgd_solver.cpp:105] Iteration 14000, lr = 0.0001
I1004 22:55:27.375725 15924 solver.cpp:218] Iteration 14100 (43.4483 iter/s, 2.30159s/100 iters), loss = 0.472167
I1004 22:55:27.375725 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:55:27.375725 15924 solver.cpp:237]     Train net output #1: loss = 0.472167 (* 1 = 0.472167 loss)
I1004 22:55:27.375725 15924 sgd_solver.cpp:105] Iteration 14100, lr = 0.0001
I1004 22:55:29.686033 15924 solver.cpp:218] Iteration 14200 (43.2581 iter/s, 2.31171s/100 iters), loss = 0.546683
I1004 22:55:29.686033 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:55:29.686033 15924 solver.cpp:237]     Train net output #1: loss = 0.546683 (* 1 = 0.546683 loss)
I1004 22:55:29.686033 15924 sgd_solver.cpp:105] Iteration 14200, lr = 0.0001
I1004 22:55:31.986562 15924 solver.cpp:218] Iteration 14300 (43.5115 iter/s, 2.29824s/100 iters), loss = 0.518623
I1004 22:55:31.986562 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:55:31.986562 15924 solver.cpp:237]     Train net output #1: loss = 0.518623 (* 1 = 0.518623 loss)
I1004 22:55:31.986562 15924 sgd_solver.cpp:105] Iteration 14300, lr = 0.0001
I1004 22:55:34.305627 15924 solver.cpp:218] Iteration 14400 (43.125 iter/s, 2.31884s/100 iters), loss = 0.407364
I1004 22:55:34.305627 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:55:34.305627 15924 solver.cpp:237]     Train net output #1: loss = 0.407364 (* 1 = 0.407364 loss)
I1004 22:55:34.305627 15924 sgd_solver.cpp:105] Iteration 14400, lr = 0.0001
I1004 22:55:36.506498  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:55:36.615864 15924 solver.cpp:218] Iteration 14500 (43.291 iter/s, 2.30995s/100 iters), loss = 0.541498
I1004 22:55:36.615864 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:55:36.615864 15924 solver.cpp:237]     Train net output #1: loss = 0.541498 (* 1 = 0.541498 loss)
I1004 22:55:36.615864 15924 sgd_solver.cpp:105] Iteration 14500, lr = 0.0001
I1004 22:55:38.909193 15924 solver.cpp:218] Iteration 14600 (43.7002 iter/s, 2.28832s/100 iters), loss = 0.481721
I1004 22:55:38.909193 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:55:38.909193 15924 solver.cpp:237]     Train net output #1: loss = 0.481721 (* 1 = 0.481721 loss)
I1004 22:55:38.909193 15924 sgd_solver.cpp:105] Iteration 14600, lr = 0.0001
I1004 22:55:41.171896 15924 solver.cpp:218] Iteration 14700 (44.0929 iter/s, 2.26794s/100 iters), loss = 0.597403
I1004 22:55:41.171896 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:55:41.171896 15924 solver.cpp:237]     Train net output #1: loss = 0.597403 (* 1 = 0.597403 loss)
I1004 22:55:41.171896 15924 sgd_solver.cpp:105] Iteration 14700, lr = 0.0001
I1004 22:55:43.442965 15924 solver.cpp:218] Iteration 14800 (44.125 iter/s, 2.26629s/100 iters), loss = 0.479621
I1004 22:55:43.442965 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:55:43.442965 15924 solver.cpp:237]     Train net output #1: loss = 0.479621 (* 1 = 0.479621 loss)
I1004 22:55:43.442965 15924 sgd_solver.cpp:105] Iteration 14800, lr = 0.0001
I1004 22:55:45.705257 15924 solver.cpp:218] Iteration 14900 (44.1569 iter/s, 2.26465s/100 iters), loss = 0.486875
I1004 22:55:45.705257 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:55:45.705257 15924 solver.cpp:237]     Train net output #1: loss = 0.486875 (* 1 = 0.486875 loss)
I1004 22:55:45.705257 15924 sgd_solver.cpp:105] Iteration 14900, lr = 0.0001
I1004 22:55:47.864328  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:55:47.958096 15924 solver.cpp:330] Iteration 15000, Testing net (#0)
I1004 22:55:47.958096 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:55:48.379971 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:55:48.395592 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7631
I1004 22:55:48.395592 15924 solver.cpp:397]     Test net output #1: loss = 0.691152 (* 1 = 0.691152 loss)
I1004 22:55:48.426847 15924 solver.cpp:218] Iteration 15000 (36.8125 iter/s, 2.71647s/100 iters), loss = 0.520152
I1004 22:55:48.426847 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:55:48.426847 15924 solver.cpp:237]     Train net output #1: loss = 0.520152 (* 1 = 0.520152 loss)
I1004 22:55:48.426847 15924 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I1004 22:55:48.426847 15924 sgd_solver.cpp:105] Iteration 15000, lr = 1e-05
I1004 22:55:50.679518 15924 solver.cpp:218] Iteration 15100 (44.1191 iter/s, 2.26659s/100 iters), loss = 0.47833
I1004 22:55:50.679518 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:55:50.679518 15924 solver.cpp:237]     Train net output #1: loss = 0.47833 (* 1 = 0.47833 loss)
I1004 22:55:50.679518 15924 sgd_solver.cpp:105] Iteration 15100, lr = 1e-05
I1004 22:55:52.946708 15924 solver.cpp:218] Iteration 15200 (44.1835 iter/s, 2.26329s/100 iters), loss = 0.61613
I1004 22:55:52.946708 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:55:52.946708 15924 solver.cpp:237]     Train net output #1: loss = 0.61613 (* 1 = 0.61613 loss)
I1004 22:55:52.946708 15924 sgd_solver.cpp:105] Iteration 15200, lr = 1e-05
I1004 22:55:55.218822 15924 solver.cpp:218] Iteration 15300 (44.237 iter/s, 2.26055s/100 iters), loss = 0.409361
I1004 22:55:55.218822 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:55:55.218822 15924 solver.cpp:237]     Train net output #1: loss = 0.409361 (* 1 = 0.409361 loss)
I1004 22:55:55.218822 15924 sgd_solver.cpp:105] Iteration 15300, lr = 1e-05
I1004 22:55:57.477977 15924 solver.cpp:218] Iteration 15400 (44.164 iter/s, 2.26429s/100 iters), loss = 0.406293
I1004 22:55:57.477977 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:55:57.477977 15924 solver.cpp:237]     Train net output #1: loss = 0.406293 (* 1 = 0.406293 loss)
I1004 22:55:57.477977 15924 sgd_solver.cpp:105] Iteration 15400, lr = 1e-05
I1004 22:55:59.628320  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:55:59.737697 15924 solver.cpp:218] Iteration 15500 (44.0833 iter/s, 2.26843s/100 iters), loss = 0.488649
I1004 22:55:59.737697 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:55:59.737697 15924 solver.cpp:237]     Train net output #1: loss = 0.488649 (* 1 = 0.488649 loss)
I1004 22:55:59.737697 15924 sgd_solver.cpp:105] Iteration 15500, lr = 1e-05
I1004 22:56:02.006729 15924 solver.cpp:218] Iteration 15600 (44.0953 iter/s, 2.26781s/100 iters), loss = 0.499088
I1004 22:56:02.006729 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:56:02.006729 15924 solver.cpp:237]     Train net output #1: loss = 0.499088 (* 1 = 0.499088 loss)
I1004 22:56:02.006729 15924 sgd_solver.cpp:105] Iteration 15600, lr = 1e-05
I1004 22:56:04.334022 15924 solver.cpp:218] Iteration 15700 (43.0776 iter/s, 2.32139s/100 iters), loss = 0.588663
I1004 22:56:04.334022 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:56:04.334022 15924 solver.cpp:237]     Train net output #1: loss = 0.588663 (* 1 = 0.588663 loss)
I1004 22:56:04.334022 15924 sgd_solver.cpp:105] Iteration 15700, lr = 1e-05
I1004 22:56:06.655555 15924 solver.cpp:218] Iteration 15800 (43.1061 iter/s, 2.31986s/100 iters), loss = 0.472963
I1004 22:56:06.655555 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:56:06.655555 15924 solver.cpp:237]     Train net output #1: loss = 0.472963 (* 1 = 0.472963 loss)
I1004 22:56:06.655555 15924 sgd_solver.cpp:105] Iteration 15800, lr = 1e-05
I1004 22:56:08.925312 15924 solver.cpp:218] Iteration 15900 (44.1228 iter/s, 2.2664s/100 iters), loss = 0.473557
I1004 22:56:08.925312 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:56:08.925312 15924 solver.cpp:237]     Train net output #1: loss = 0.473557 (* 1 = 0.473557 loss)
I1004 22:56:08.925312 15924 sgd_solver.cpp:105] Iteration 15900, lr = 1e-05
I1004 22:56:11.117359  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:56:11.211132 15924 solver.cpp:330] Iteration 16000, Testing net (#0)
I1004 22:56:11.211132 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:56:11.656183 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:56:11.671811 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7639
I1004 22:56:11.671811 15924 solver.cpp:397]     Test net output #1: loss = 0.690939 (* 1 = 0.690939 loss)
I1004 22:56:11.687417 15924 solver.cpp:218] Iteration 16000 (36.0847 iter/s, 2.77126s/100 iters), loss = 0.496146
I1004 22:56:11.687417 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:56:11.687417 15924 solver.cpp:237]     Train net output #1: loss = 0.496146 (* 1 = 0.496146 loss)
I1004 22:56:11.687417 15924 sgd_solver.cpp:105] Iteration 16000, lr = 1e-05
I1004 22:56:13.981264 15924 solver.cpp:218] Iteration 16100 (43.6529 iter/s, 2.2908s/100 iters), loss = 0.521468
I1004 22:56:13.981264 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:56:13.981264 15924 solver.cpp:237]     Train net output #1: loss = 0.521468 (* 1 = 0.521468 loss)
I1004 22:56:13.981264 15924 sgd_solver.cpp:105] Iteration 16100, lr = 1e-05
I1004 22:56:16.297276 15924 solver.cpp:218] Iteration 16200 (43.2418 iter/s, 2.31258s/100 iters), loss = 0.49429
I1004 22:56:16.297276 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:56:16.297276 15924 solver.cpp:237]     Train net output #1: loss = 0.49429 (* 1 = 0.49429 loss)
I1004 22:56:16.297276 15924 sgd_solver.cpp:105] Iteration 16200, lr = 1e-05
I1004 22:56:18.607686 15924 solver.cpp:218] Iteration 16300 (43.3175 iter/s, 2.30854s/100 iters), loss = 0.457105
I1004 22:56:18.607686 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:56:18.607686 15924 solver.cpp:237]     Train net output #1: loss = 0.457105 (* 1 = 0.457105 loss)
I1004 22:56:18.607686 15924 sgd_solver.cpp:105] Iteration 16300, lr = 1e-05
I1004 22:56:20.892305 15924 solver.cpp:218] Iteration 16400 (43.7478 iter/s, 2.28583s/100 iters), loss = 0.484486
I1004 22:56:20.892305 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:56:20.892305 15924 solver.cpp:237]     Train net output #1: loss = 0.484486 (* 1 = 0.484486 loss)
I1004 22:56:20.892305 15924 sgd_solver.cpp:105] Iteration 16400, lr = 1e-05
I1004 22:56:23.070819  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:56:23.180194 15924 solver.cpp:218] Iteration 16500 (43.7076 iter/s, 2.28793s/100 iters), loss = 0.500562
I1004 22:56:23.180194 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:56:23.180194 15924 solver.cpp:237]     Train net output #1: loss = 0.500562 (* 1 = 0.500562 loss)
I1004 22:56:23.180194 15924 sgd_solver.cpp:105] Iteration 16500, lr = 1e-05
I1004 22:56:25.487592 15924 solver.cpp:218] Iteration 16600 (43.3795 iter/s, 2.30524s/100 iters), loss = 0.465921
I1004 22:56:25.487592 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:56:25.487592 15924 solver.cpp:237]     Train net output #1: loss = 0.465921 (* 1 = 0.465921 loss)
I1004 22:56:25.487592 15924 sgd_solver.cpp:105] Iteration 16600, lr = 1e-05
I1004 22:56:27.775471 15924 solver.cpp:218] Iteration 16700 (43.7081 iter/s, 2.2879s/100 iters), loss = 0.492834
I1004 22:56:27.775471 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:56:27.775471 15924 solver.cpp:237]     Train net output #1: loss = 0.492834 (* 1 = 0.492834 loss)
I1004 22:56:27.775471 15924 sgd_solver.cpp:105] Iteration 16700, lr = 1e-05
I1004 22:56:30.070013 15924 solver.cpp:218] Iteration 16800 (43.5846 iter/s, 2.29439s/100 iters), loss = 0.494027
I1004 22:56:30.070013 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:56:30.070013 15924 solver.cpp:237]     Train net output #1: loss = 0.494027 (* 1 = 0.494027 loss)
I1004 22:56:30.070013 15924 sgd_solver.cpp:105] Iteration 16800, lr = 1e-05
I1004 22:56:32.381808 15924 solver.cpp:218] Iteration 16900 (43.3637 iter/s, 2.30608s/100 iters), loss = 0.429493
I1004 22:56:32.381808 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 22:56:32.381808 15924 solver.cpp:237]     Train net output #1: loss = 0.429493 (* 1 = 0.429493 loss)
I1004 22:56:32.381808 15924 sgd_solver.cpp:105] Iteration 16900, lr = 1e-05
I1004 22:56:34.548914  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:56:34.642663 15924 solver.cpp:330] Iteration 17000, Testing net (#0)
I1004 22:56:34.642663 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:56:35.064539 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:56:35.080164 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7638
I1004 22:56:35.080164 15924 solver.cpp:397]     Test net output #1: loss = 0.690811 (* 1 = 0.690811 loss)
I1004 22:56:35.111415 15924 solver.cpp:218] Iteration 17000 (36.6488 iter/s, 2.7286s/100 iters), loss = 0.518802
I1004 22:56:35.111415 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:56:35.111415 15924 solver.cpp:237]     Train net output #1: loss = 0.518802 (* 1 = 0.518802 loss)
I1004 22:56:35.111415 15924 sgd_solver.cpp:105] Iteration 17000, lr = 1e-05
I1004 22:56:37.397703 15924 solver.cpp:218] Iteration 17100 (43.7315 iter/s, 2.28668s/100 iters), loss = 0.496018
I1004 22:56:37.397703 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:56:37.397703 15924 solver.cpp:237]     Train net output #1: loss = 0.496018 (* 1 = 0.496018 loss)
I1004 22:56:37.397703 15924 sgd_solver.cpp:105] Iteration 17100, lr = 1e-05
I1004 22:56:39.699278 15924 solver.cpp:218] Iteration 17200 (43.4498 iter/s, 2.3015s/100 iters), loss = 0.576406
I1004 22:56:39.699278 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 22:56:39.699278 15924 solver.cpp:237]     Train net output #1: loss = 0.576406 (* 1 = 0.576406 loss)
I1004 22:56:39.699278 15924 sgd_solver.cpp:105] Iteration 17200, lr = 1e-05
I1004 22:56:41.984169 15924 solver.cpp:218] Iteration 17300 (43.5373 iter/s, 2.29688s/100 iters), loss = 0.464439
I1004 22:56:41.984169 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:56:41.984169 15924 solver.cpp:237]     Train net output #1: loss = 0.464439 (* 1 = 0.464439 loss)
I1004 22:56:41.984169 15924 sgd_solver.cpp:105] Iteration 17300, lr = 1e-05
I1004 22:56:44.263979 15924 solver.cpp:218] Iteration 17400 (44.1377 iter/s, 2.26564s/100 iters), loss = 0.435256
I1004 22:56:44.263979 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:56:44.263979 15924 solver.cpp:237]     Train net output #1: loss = 0.435256 (* 1 = 0.435256 loss)
I1004 22:56:44.263979 15924 sgd_solver.cpp:105] Iteration 17400, lr = 1e-05
I1004 22:56:46.490741  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:56:46.600116 15924 solver.cpp:218] Iteration 17500 (42.7017 iter/s, 2.34183s/100 iters), loss = 0.49854
I1004 22:56:46.600116 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:56:46.600116 15924 solver.cpp:237]     Train net output #1: loss = 0.49854 (* 1 = 0.49854 loss)
I1004 22:56:46.600116 15924 sgd_solver.cpp:105] Iteration 17500, lr = 1e-05
I1004 22:56:48.881930 15924 solver.cpp:218] Iteration 17600 (43.8032 iter/s, 2.28294s/100 iters), loss = 0.441547
I1004 22:56:48.881930 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:56:48.881930 15924 solver.cpp:237]     Train net output #1: loss = 0.441547 (* 1 = 0.441547 loss)
I1004 22:56:48.881930 15924 sgd_solver.cpp:105] Iteration 17600, lr = 1e-05
I1004 22:56:51.227710 15924 solver.cpp:218] Iteration 17700 (42.7615 iter/s, 2.33855s/100 iters), loss = 0.529359
I1004 22:56:51.227710 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:56:51.227710 15924 solver.cpp:237]     Train net output #1: loss = 0.529359 (* 1 = 0.529359 loss)
I1004 22:56:51.227710 15924 sgd_solver.cpp:105] Iteration 17700, lr = 1e-05
I1004 22:56:53.496019 15924 solver.cpp:218] Iteration 17800 (43.9084 iter/s, 2.27747s/100 iters), loss = 0.465368
I1004 22:56:53.496019 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:56:53.496019 15924 solver.cpp:237]     Train net output #1: loss = 0.465368 (* 1 = 0.465368 loss)
I1004 22:56:53.496019 15924 sgd_solver.cpp:105] Iteration 17800, lr = 1e-05
I1004 22:56:55.776918 15924 solver.cpp:218] Iteration 17900 (43.9739 iter/s, 2.27407s/100 iters), loss = 0.500899
I1004 22:56:55.776918 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:56:55.776918 15924 solver.cpp:237]     Train net output #1: loss = 0.500899 (* 1 = 0.500899 loss)
I1004 22:56:55.776918 15924 sgd_solver.cpp:105] Iteration 17900, lr = 1e-05
I1004 22:56:57.993162  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:56:58.086911 15924 solver.cpp:330] Iteration 18000, Testing net (#0)
I1004 22:56:58.086911 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:56:58.507557 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:56:58.538821 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7635
I1004 22:56:58.538821 15924 solver.cpp:397]     Test net output #1: loss = 0.690752 (* 1 = 0.690752 loss)
I1004 22:56:58.554417 15924 solver.cpp:218] Iteration 18000 (35.9809 iter/s, 2.77925s/100 iters), loss = 0.558828
I1004 22:56:58.554417 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:56:58.554417 15924 solver.cpp:237]     Train net output #1: loss = 0.558828 (* 1 = 0.558828 loss)
I1004 22:56:58.554417 15924 sgd_solver.cpp:105] Iteration 18000, lr = 1e-05
I1004 22:57:00.839210 15924 solver.cpp:218] Iteration 18100 (43.5986 iter/s, 2.29365s/100 iters), loss = 0.446897
I1004 22:57:00.839210 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:57:00.839210 15924 solver.cpp:237]     Train net output #1: loss = 0.446897 (* 1 = 0.446897 loss)
I1004 22:57:00.839210 15924 sgd_solver.cpp:105] Iteration 18100, lr = 1e-05
I1004 22:57:03.141595 15924 solver.cpp:218] Iteration 18200 (43.7149 iter/s, 2.28755s/100 iters), loss = 0.585397
I1004 22:57:03.141595 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:57:03.141595 15924 solver.cpp:237]     Train net output #1: loss = 0.585397 (* 1 = 0.585397 loss)
I1004 22:57:03.141595 15924 sgd_solver.cpp:105] Iteration 18200, lr = 1e-05
I1004 22:57:05.412961 15924 solver.cpp:218] Iteration 18300 (43.9268 iter/s, 2.27652s/100 iters), loss = 0.443674
I1004 22:57:05.412961 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:57:05.412961 15924 solver.cpp:237]     Train net output #1: loss = 0.443674 (* 1 = 0.443674 loss)
I1004 22:57:05.412961 15924 sgd_solver.cpp:105] Iteration 18300, lr = 1e-05
I1004 22:57:07.756994 15924 solver.cpp:218] Iteration 18400 (42.743 iter/s, 2.33956s/100 iters), loss = 0.487675
I1004 22:57:07.756994 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:57:07.756994 15924 solver.cpp:237]     Train net output #1: loss = 0.487675 (* 1 = 0.487675 loss)
I1004 22:57:07.756994 15924 sgd_solver.cpp:105] Iteration 18400, lr = 1e-05
I1004 22:57:09.930202  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:57:10.039558 15924 solver.cpp:218] Iteration 18500 (43.7032 iter/s, 2.28816s/100 iters), loss = 0.61213
I1004 22:57:10.039558 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 22:57:10.039558 15924 solver.cpp:237]     Train net output #1: loss = 0.61213 (* 1 = 0.61213 loss)
I1004 22:57:10.039558 15924 sgd_solver.cpp:105] Iteration 18500, lr = 1e-05
I1004 22:57:12.318786 15924 solver.cpp:218] Iteration 18600 (43.9569 iter/s, 2.27496s/100 iters), loss = 0.475598
I1004 22:57:12.318786 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:57:12.318786 15924 solver.cpp:237]     Train net output #1: loss = 0.475598 (* 1 = 0.475598 loss)
I1004 22:57:12.318786 15924 sgd_solver.cpp:105] Iteration 18600, lr = 1e-05
I1004 22:57:14.588050 15924 solver.cpp:218] Iteration 18700 (44.1564 iter/s, 2.26468s/100 iters), loss = 0.574988
I1004 22:57:14.588050 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:57:14.588050 15924 solver.cpp:237]     Train net output #1: loss = 0.574988 (* 1 = 0.574988 loss)
I1004 22:57:14.588050 15924 sgd_solver.cpp:105] Iteration 18700, lr = 1e-05
I1004 22:57:16.845818 15924 solver.cpp:218] Iteration 18800 (44.18 iter/s, 2.26347s/100 iters), loss = 0.457959
I1004 22:57:16.845818 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:57:16.845818 15924 solver.cpp:237]     Train net output #1: loss = 0.457959 (* 1 = 0.457959 loss)
I1004 22:57:16.845818 15924 sgd_solver.cpp:105] Iteration 18800, lr = 1e-05
I1004 22:57:19.111871 15924 solver.cpp:218] Iteration 18900 (44.082 iter/s, 2.2685s/100 iters), loss = 0.444444
I1004 22:57:19.111871 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:57:19.111871 15924 solver.cpp:237]     Train net output #1: loss = 0.444444 (* 1 = 0.444444 loss)
I1004 22:57:19.111871 15924 sgd_solver.cpp:105] Iteration 18900, lr = 1e-05
I1004 22:57:21.304783  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:57:21.398515 15924 solver.cpp:330] Iteration 19000, Testing net (#0)
I1004 22:57:21.398515 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:57:21.835129 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:57:21.853971 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7637
I1004 22:57:21.853971 15924 solver.cpp:397]     Test net output #1: loss = 0.690598 (* 1 = 0.690598 loss)
I1004 22:57:21.861127 15924 solver.cpp:218] Iteration 19000 (36.3102 iter/s, 2.75405s/100 iters), loss = 0.561772
I1004 22:57:21.861127 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:57:21.861127 15924 solver.cpp:237]     Train net output #1: loss = 0.561772 (* 1 = 0.561772 loss)
I1004 22:57:21.861127 15924 sgd_solver.cpp:105] Iteration 19000, lr = 1e-05
I1004 22:57:24.189414 15924 solver.cpp:218] Iteration 19100 (42.9991 iter/s, 2.32563s/100 iters), loss = 0.449963
I1004 22:57:24.189414 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:57:24.189414 15924 solver.cpp:237]     Train net output #1: loss = 0.449963 (* 1 = 0.449963 loss)
I1004 22:57:24.189414 15924 sgd_solver.cpp:105] Iteration 19100, lr = 1e-05
I1004 22:57:26.458271 15924 solver.cpp:218] Iteration 19200 (44.1827 iter/s, 2.26333s/100 iters), loss = 0.539091
I1004 22:57:26.458271 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:57:26.458271 15924 solver.cpp:237]     Train net output #1: loss = 0.539091 (* 1 = 0.539091 loss)
I1004 22:57:26.458271 15924 sgd_solver.cpp:105] Iteration 19200, lr = 1e-05
I1004 22:57:28.782503 15924 solver.cpp:218] Iteration 19300 (42.9979 iter/s, 2.3257s/100 iters), loss = 0.46518
I1004 22:57:28.782503 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:57:28.782503 15924 solver.cpp:237]     Train net output #1: loss = 0.46518 (* 1 = 0.46518 loss)
I1004 22:57:28.782503 15924 sgd_solver.cpp:105] Iteration 19300, lr = 1e-05
I1004 22:57:31.075644 15924 solver.cpp:218] Iteration 19400 (43.7436 iter/s, 2.28605s/100 iters), loss = 0.463531
I1004 22:57:31.075644 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:57:31.075644 15924 solver.cpp:237]     Train net output #1: loss = 0.463531 (* 1 = 0.463531 loss)
I1004 22:57:31.075644 15924 sgd_solver.cpp:105] Iteration 19400, lr = 1e-05
I1004 22:57:33.295464  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:57:33.404829 15924 solver.cpp:218] Iteration 19500 (42.8389 iter/s, 2.33433s/100 iters), loss = 0.523098
I1004 22:57:33.404829 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:57:33.404829 15924 solver.cpp:237]     Train net output #1: loss = 0.523098 (* 1 = 0.523098 loss)
I1004 22:57:33.404829 15924 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I1004 22:57:35.676906 15924 solver.cpp:218] Iteration 19600 (44.1165 iter/s, 2.26673s/100 iters), loss = 0.504124
I1004 22:57:35.676906 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:57:35.676906 15924 solver.cpp:237]     Train net output #1: loss = 0.504124 (* 1 = 0.504124 loss)
I1004 22:57:35.676906 15924 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I1004 22:57:37.982455 15924 solver.cpp:218] Iteration 19700 (43.1304 iter/s, 2.31855s/100 iters), loss = 0.54801
I1004 22:57:37.982455 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:57:37.982455 15924 solver.cpp:237]     Train net output #1: loss = 0.54801 (* 1 = 0.54801 loss)
I1004 22:57:37.982455 15924 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I1004 22:57:40.285043 15924 solver.cpp:218] Iteration 19800 (43.5607 iter/s, 2.29565s/100 iters), loss = 0.479619
I1004 22:57:40.285043 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:57:40.285043 15924 solver.cpp:237]     Train net output #1: loss = 0.479619 (* 1 = 0.479619 loss)
I1004 22:57:40.285043 15924 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I1004 22:57:42.606855 15924 solver.cpp:218] Iteration 19900 (42.9476 iter/s, 2.32842s/100 iters), loss = 0.4995
I1004 22:57:42.606855 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:57:42.606855 15924 solver.cpp:237]     Train net output #1: loss = 0.4995 (* 1 = 0.4995 loss)
I1004 22:57:42.606855 15924 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I1004 22:57:44.815075  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:57:44.904546 15924 solver.cpp:330] Iteration 20000, Testing net (#0)
I1004 22:57:44.904546 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:57:45.353137 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:57:45.368767 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7634
I1004 22:57:45.368767 15924 solver.cpp:397]     Test net output #1: loss = 0.690628 (* 1 = 0.690628 loss)
I1004 22:57:45.384354 15924 solver.cpp:218] Iteration 20000 (36.036 iter/s, 2.775s/100 iters), loss = 0.575226
I1004 22:57:45.384354 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:57:45.384354 15924 solver.cpp:237]     Train net output #1: loss = 0.575226 (* 1 = 0.575226 loss)
I1004 22:57:45.384354 15924 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I1004 22:57:47.693877 15924 solver.cpp:218] Iteration 20100 (43.3741 iter/s, 2.30553s/100 iters), loss = 0.479635
I1004 22:57:47.693877 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:57:47.693877 15924 solver.cpp:237]     Train net output #1: loss = 0.479635 (* 1 = 0.479635 loss)
I1004 22:57:47.693877 15924 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I1004 22:57:49.997612 15924 solver.cpp:218] Iteration 20200 (43.4267 iter/s, 2.30273s/100 iters), loss = 0.504999
I1004 22:57:49.997612 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:57:49.997612 15924 solver.cpp:237]     Train net output #1: loss = 0.504999 (* 1 = 0.504999 loss)
I1004 22:57:49.997612 15924 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I1004 22:57:52.279980 15924 solver.cpp:218] Iteration 20300 (43.9014 iter/s, 2.27783s/100 iters), loss = 0.452286
I1004 22:57:52.279980 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:57:52.279980 15924 solver.cpp:237]     Train net output #1: loss = 0.452286 (* 1 = 0.452286 loss)
I1004 22:57:52.279980 15924 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I1004 22:57:54.615696 15924 solver.cpp:218] Iteration 20400 (42.7036 iter/s, 2.34172s/100 iters), loss = 0.472253
I1004 22:57:54.615696 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:57:54.615696 15924 solver.cpp:237]     Train net output #1: loss = 0.472253 (* 1 = 0.472253 loss)
I1004 22:57:54.615696 15924 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I1004 22:57:56.821583  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:57:56.930963 15924 solver.cpp:218] Iteration 20500 (43.376 iter/s, 2.30542s/100 iters), loss = 0.539039
I1004 22:57:56.930963 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:57:56.930963 15924 solver.cpp:237]     Train net output #1: loss = 0.539039 (* 1 = 0.539039 loss)
I1004 22:57:56.930963 15924 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I1004 22:57:59.209494 15924 solver.cpp:218] Iteration 20600 (43.861 iter/s, 2.27993s/100 iters), loss = 0.446537
I1004 22:57:59.209494 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:57:59.209494 15924 solver.cpp:237]     Train net output #1: loss = 0.446537 (* 1 = 0.446537 loss)
I1004 22:57:59.209494 15924 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I1004 22:58:01.540935 15924 solver.cpp:218] Iteration 20700 (42.6849 iter/s, 2.34275s/100 iters), loss = 0.556044
I1004 22:58:01.540935 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:58:01.540935 15924 solver.cpp:237]     Train net output #1: loss = 0.556044 (* 1 = 0.556044 loss)
I1004 22:58:01.540935 15924 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I1004 22:58:03.825245 15924 solver.cpp:218] Iteration 20800 (43.8852 iter/s, 2.27867s/100 iters), loss = 0.464063
I1004 22:58:03.825245 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:58:03.825245 15924 solver.cpp:237]     Train net output #1: loss = 0.464063 (* 1 = 0.464063 loss)
I1004 22:58:03.825245 15924 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I1004 22:58:06.164643 15924 solver.cpp:218] Iteration 20900 (42.791 iter/s, 2.33694s/100 iters), loss = 0.446272
I1004 22:58:06.164643 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:58:06.164643 15924 solver.cpp:237]     Train net output #1: loss = 0.446272 (* 1 = 0.446272 loss)
I1004 22:58:06.164643 15924 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I1004 22:58:08.328996  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:58:08.422747 15924 solver.cpp:330] Iteration 21000, Testing net (#0)
I1004 22:58:08.422747 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:58:08.860267 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:58:08.875891 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7632
I1004 22:58:08.875891 15924 solver.cpp:397]     Test net output #1: loss = 0.690485 (* 1 = 0.690485 loss)
I1004 22:58:08.891517 15924 solver.cpp:218] Iteration 21000 (36.5943 iter/s, 2.73267s/100 iters), loss = 0.60433
I1004 22:58:08.891517 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 22:58:08.891517 15924 solver.cpp:237]     Train net output #1: loss = 0.60433 (* 1 = 0.60433 loss)
I1004 22:58:08.891517 15924 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I1004 22:58:11.176715 15924 solver.cpp:218] Iteration 21100 (43.8393 iter/s, 2.28106s/100 iters), loss = 0.450847
I1004 22:58:11.176715 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:58:11.176715 15924 solver.cpp:237]     Train net output #1: loss = 0.450847 (* 1 = 0.450847 loss)
I1004 22:58:11.176715 15924 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I1004 22:58:13.466734 15924 solver.cpp:218] Iteration 21200 (43.6267 iter/s, 2.29217s/100 iters), loss = 0.573572
I1004 22:58:13.466734 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:58:13.466734 15924 solver.cpp:237]     Train net output #1: loss = 0.573572 (* 1 = 0.573572 loss)
I1004 22:58:13.466734 15924 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I1004 22:58:15.791712 15924 solver.cpp:218] Iteration 21300 (43.2392 iter/s, 2.31272s/100 iters), loss = 0.444067
I1004 22:58:15.791712 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:58:15.791712 15924 solver.cpp:237]     Train net output #1: loss = 0.444067 (* 1 = 0.444067 loss)
I1004 22:58:15.791712 15924 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I1004 22:58:18.060168 15924 solver.cpp:218] Iteration 21400 (43.8539 iter/s, 2.2803s/100 iters), loss = 0.389103
I1004 22:58:18.060168 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:58:18.060168 15924 solver.cpp:237]     Train net output #1: loss = 0.389103 (* 1 = 0.389103 loss)
I1004 22:58:18.060168 15924 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I1004 22:58:20.286610  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:58:20.392880 15924 solver.cpp:218] Iteration 21500 (42.9198 iter/s, 2.32993s/100 iters), loss = 0.538474
I1004 22:58:20.392880 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:58:20.392880 15924 solver.cpp:237]     Train net output #1: loss = 0.538474 (* 1 = 0.538474 loss)
I1004 22:58:20.392880 15924 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I1004 22:58:22.666565 15924 solver.cpp:218] Iteration 21600 (43.9045 iter/s, 2.27767s/100 iters), loss = 0.42245
I1004 22:58:22.666565 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:58:22.666565 15924 solver.cpp:237]     Train net output #1: loss = 0.42245 (* 1 = 0.42245 loss)
I1004 22:58:22.666565 15924 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I1004 22:58:24.996879 15924 solver.cpp:218] Iteration 21700 (42.921 iter/s, 2.32986s/100 iters), loss = 0.527549
I1004 22:58:24.996879 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:58:24.996879 15924 solver.cpp:237]     Train net output #1: loss = 0.527549 (* 1 = 0.527549 loss)
I1004 22:58:24.996879 15924 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I1004 22:58:27.283104 15924 solver.cpp:218] Iteration 21800 (43.885 iter/s, 2.27868s/100 iters), loss = 0.490209
I1004 22:58:27.283104 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:58:27.283104 15924 solver.cpp:237]     Train net output #1: loss = 0.490209 (* 1 = 0.490209 loss)
I1004 22:58:27.283104 15924 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I1004 22:58:29.553709 15924 solver.cpp:218] Iteration 21900 (44.1698 iter/s, 2.26399s/100 iters), loss = 0.436737
I1004 22:58:29.553709 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:58:29.553709 15924 solver.cpp:237]     Train net output #1: loss = 0.436737 (* 1 = 0.436737 loss)
I1004 22:58:29.553709 15924 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I1004 22:58:31.762296  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:58:31.856065 15924 solver.cpp:330] Iteration 22000, Testing net (#0)
I1004 22:58:31.856065 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:58:32.293565 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:58:32.309171 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7632
I1004 22:58:32.309171 15924 solver.cpp:397]     Test net output #1: loss = 0.690557 (* 1 = 0.690557 loss)
I1004 22:58:32.338199 15924 solver.cpp:218] Iteration 22000 (35.8962 iter/s, 2.78581s/100 iters), loss = 0.611716
I1004 22:58:32.338199 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 22:58:32.338199 15924 solver.cpp:237]     Train net output #1: loss = 0.611716 (* 1 = 0.611716 loss)
I1004 22:58:32.338199 15924 sgd_solver.cpp:105] Iteration 22000, lr = 1e-05
I1004 22:58:34.611434 15924 solver.cpp:218] Iteration 22100 (43.7839 iter/s, 2.28395s/100 iters), loss = 0.37717
I1004 22:58:34.611434 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 22:58:34.611434 15924 solver.cpp:237]     Train net output #1: loss = 0.37717 (* 1 = 0.37717 loss)
I1004 22:58:34.611434 15924 sgd_solver.cpp:105] Iteration 22100, lr = 1e-05
I1004 22:58:36.932505 15924 solver.cpp:218] Iteration 22200 (43.228 iter/s, 2.31332s/100 iters), loss = 0.56792
I1004 22:58:36.932505 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:58:36.932505 15924 solver.cpp:237]     Train net output #1: loss = 0.56792 (* 1 = 0.56792 loss)
I1004 22:58:36.932505 15924 sgd_solver.cpp:105] Iteration 22200, lr = 1e-05
I1004 22:58:39.207665 15924 solver.cpp:218] Iteration 22300 (43.9035 iter/s, 2.27772s/100 iters), loss = 0.427192
I1004 22:58:39.207665 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:58:39.207665 15924 solver.cpp:237]     Train net output #1: loss = 0.427192 (* 1 = 0.427192 loss)
I1004 22:58:39.207665 15924 sgd_solver.cpp:105] Iteration 22300, lr = 1e-05
I1004 22:58:41.509953 15924 solver.cpp:218] Iteration 22400 (43.3457 iter/s, 2.30704s/100 iters), loss = 0.408059
I1004 22:58:41.509953 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:58:41.509953 15924 solver.cpp:237]     Train net output #1: loss = 0.408059 (* 1 = 0.408059 loss)
I1004 22:58:41.509953 15924 sgd_solver.cpp:105] Iteration 22400, lr = 1e-05
I1004 22:58:43.709311  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:58:43.818704 15924 solver.cpp:218] Iteration 22500 (43.3391 iter/s, 2.30739s/100 iters), loss = 0.492587
I1004 22:58:43.818704 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:58:43.818704 15924 solver.cpp:237]     Train net output #1: loss = 0.492587 (* 1 = 0.492587 loss)
I1004 22:58:43.818704 15924 sgd_solver.cpp:105] Iteration 22500, lr = 1e-05
I1004 22:58:46.137854 15924 solver.cpp:218] Iteration 22600 (43.2315 iter/s, 2.31313s/100 iters), loss = 0.440984
I1004 22:58:46.137854 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 22:58:46.137854 15924 solver.cpp:237]     Train net output #1: loss = 0.440984 (* 1 = 0.440984 loss)
I1004 22:58:46.137854 15924 sgd_solver.cpp:105] Iteration 22600, lr = 1e-05
I1004 22:58:48.441337 15924 solver.cpp:218] Iteration 22700 (43.3947 iter/s, 2.30443s/100 iters), loss = 0.563934
I1004 22:58:48.441337 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 22:58:48.441337 15924 solver.cpp:237]     Train net output #1: loss = 0.563934 (* 1 = 0.563934 loss)
I1004 22:58:48.441337 15924 sgd_solver.cpp:105] Iteration 22700, lr = 1e-05
I1004 22:58:50.778657 15924 solver.cpp:218] Iteration 22800 (42.7383 iter/s, 2.33982s/100 iters), loss = 0.44357
I1004 22:58:50.778657 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:58:50.778657 15924 solver.cpp:237]     Train net output #1: loss = 0.44357 (* 1 = 0.44357 loss)
I1004 22:58:50.778657 15924 sgd_solver.cpp:105] Iteration 22800, lr = 1e-05
I1004 22:58:53.112030 15924 solver.cpp:218] Iteration 22900 (43.0076 iter/s, 2.32517s/100 iters), loss = 0.425518
I1004 22:58:53.112030 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:58:53.112030 15924 solver.cpp:237]     Train net output #1: loss = 0.425518 (* 1 = 0.425518 loss)
I1004 22:58:53.112030 15924 sgd_solver.cpp:105] Iteration 22900, lr = 1e-05
I1004 22:58:55.295724  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:58:55.371637 15924 solver.cpp:330] Iteration 23000, Testing net (#0)
I1004 22:58:55.371637 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:58:55.818382 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:58:55.834007 15924 solver.cpp:397]     Test net output #0: accuracy = 0.763
I1004 22:58:55.834007 15924 solver.cpp:397]     Test net output #1: loss = 0.690357 (* 1 = 0.690357 loss)
I1004 22:58:55.849632 15924 solver.cpp:218] Iteration 23000 (36.468 iter/s, 2.74213s/100 iters), loss = 0.545874
I1004 22:58:55.849632 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:58:55.849632 15924 solver.cpp:237]     Train net output #1: loss = 0.545874 (* 1 = 0.545874 loss)
I1004 22:58:55.849632 15924 sgd_solver.cpp:105] Iteration 23000, lr = 1e-05
I1004 22:58:58.179703 15924 solver.cpp:218] Iteration 23100 (43.0497 iter/s, 2.3229s/100 iters), loss = 0.499133
I1004 22:58:58.179703 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:58:58.179703 15924 solver.cpp:237]     Train net output #1: loss = 0.499133 (* 1 = 0.499133 loss)
I1004 22:58:58.179703 15924 sgd_solver.cpp:105] Iteration 23100, lr = 1e-05
I1004 22:59:00.451771 15924 solver.cpp:218] Iteration 23200 (43.7899 iter/s, 2.28363s/100 iters), loss = 0.557236
I1004 22:59:00.451771 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 22:59:00.451771 15924 solver.cpp:237]     Train net output #1: loss = 0.557236 (* 1 = 0.557236 loss)
I1004 22:59:00.451771 15924 sgd_solver.cpp:105] Iteration 23200, lr = 1e-05
I1004 22:59:02.782209 15924 solver.cpp:218] Iteration 23300 (42.8998 iter/s, 2.33101s/100 iters), loss = 0.452683
I1004 22:59:02.782209 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:59:02.782209 15924 solver.cpp:237]     Train net output #1: loss = 0.452683 (* 1 = 0.452683 loss)
I1004 22:59:02.782209 15924 sgd_solver.cpp:105] Iteration 23300, lr = 1e-05
I1004 22:59:05.077069 15924 solver.cpp:218] Iteration 23400 (43.848 iter/s, 2.2806s/100 iters), loss = 0.466016
I1004 22:59:05.077069 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:59:05.077069 15924 solver.cpp:237]     Train net output #1: loss = 0.466016 (* 1 = 0.466016 loss)
I1004 22:59:05.077069 15924 sgd_solver.cpp:105] Iteration 23400, lr = 1e-05
I1004 22:59:07.281195  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:59:07.398571 15924 solver.cpp:218] Iteration 23500 (43.0554 iter/s, 2.32259s/100 iters), loss = 0.522921
I1004 22:59:07.398571 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:59:07.398571 15924 solver.cpp:237]     Train net output #1: loss = 0.522921 (* 1 = 0.522921 loss)
I1004 22:59:07.398571 15924 sgd_solver.cpp:105] Iteration 23500, lr = 1e-05
I1004 22:59:09.658529 15924 solver.cpp:218] Iteration 23600 (44.055 iter/s, 2.26989s/100 iters), loss = 0.502511
I1004 22:59:09.658529 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:59:09.658529 15924 solver.cpp:237]     Train net output #1: loss = 0.502511 (* 1 = 0.502511 loss)
I1004 22:59:09.658529 15924 sgd_solver.cpp:105] Iteration 23600, lr = 1e-05
I1004 22:59:11.945683 15924 solver.cpp:218] Iteration 23700 (43.8088 iter/s, 2.28265s/100 iters), loss = 0.53608
I1004 22:59:11.945683 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 22:59:11.945683 15924 solver.cpp:237]     Train net output #1: loss = 0.53608 (* 1 = 0.53608 loss)
I1004 22:59:11.945683 15924 sgd_solver.cpp:105] Iteration 23700, lr = 1e-05
I1004 22:59:14.269604 15924 solver.cpp:218] Iteration 23800 (43.06 iter/s, 2.32234s/100 iters), loss = 0.454748
I1004 22:59:14.269604 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 22:59:14.269604 15924 solver.cpp:237]     Train net output #1: loss = 0.454748 (* 1 = 0.454748 loss)
I1004 22:59:14.269604 15924 sgd_solver.cpp:105] Iteration 23800, lr = 1e-05
I1004 22:59:16.552916 15924 solver.cpp:218] Iteration 23900 (43.7308 iter/s, 2.28672s/100 iters), loss = 0.448245
I1004 22:59:16.552916 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:59:16.552916 15924 solver.cpp:237]     Train net output #1: loss = 0.448245 (* 1 = 0.448245 loss)
I1004 22:59:16.552916 15924 sgd_solver.cpp:105] Iteration 23900, lr = 1e-05
I1004 22:59:18.729619  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:59:18.823348 15924 solver.cpp:330] Iteration 24000, Testing net (#0)
I1004 22:59:18.823348 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:59:19.251688 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:59:19.267330 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7636
I1004 22:59:19.267330 15924 solver.cpp:397]     Test net output #1: loss = 0.690383 (* 1 = 0.690383 loss)
I1004 22:59:19.298553 15924 solver.cpp:218] Iteration 24000 (36.5096 iter/s, 2.739s/100 iters), loss = 0.60876
I1004 22:59:19.298553 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 22:59:19.298553 15924 solver.cpp:237]     Train net output #1: loss = 0.60876 (* 1 = 0.60876 loss)
I1004 22:59:19.298553 15924 sgd_solver.cpp:105] Iteration 24000, lr = 1e-05
I1004 22:59:21.567644 15924 solver.cpp:218] Iteration 24100 (43.8697 iter/s, 2.27948s/100 iters), loss = 0.534896
I1004 22:59:21.567644 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:59:21.567644 15924 solver.cpp:237]     Train net output #1: loss = 0.534896 (* 1 = 0.534896 loss)
I1004 22:59:21.567644 15924 sgd_solver.cpp:105] Iteration 24100, lr = 1e-05
I1004 22:59:23.919672 15924 solver.cpp:218] Iteration 24200 (42.6134 iter/s, 2.34668s/100 iters), loss = 0.605967
I1004 22:59:23.919672 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1004 22:59:23.919672 15924 solver.cpp:237]     Train net output #1: loss = 0.605967 (* 1 = 0.605967 loss)
I1004 22:59:23.919672 15924 sgd_solver.cpp:105] Iteration 24200, lr = 1e-05
I1004 22:59:26.202404 15924 solver.cpp:218] Iteration 24300 (43.7401 iter/s, 2.28623s/100 iters), loss = 0.447639
I1004 22:59:26.202404 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:59:26.202404 15924 solver.cpp:237]     Train net output #1: loss = 0.447639 (* 1 = 0.447639 loss)
I1004 22:59:26.202404 15924 sgd_solver.cpp:105] Iteration 24300, lr = 1e-05
I1004 22:59:28.516353 15924 solver.cpp:218] Iteration 24400 (43.4428 iter/s, 2.30188s/100 iters), loss = 0.472288
I1004 22:59:28.516353 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 22:59:28.516353 15924 solver.cpp:237]     Train net output #1: loss = 0.472288 (* 1 = 0.472288 loss)
I1004 22:59:28.516353 15924 sgd_solver.cpp:105] Iteration 24400, lr = 1e-05
I1004 22:59:30.705591  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:59:30.814949 15924 solver.cpp:218] Iteration 24500 (43.3345 iter/s, 2.30763s/100 iters), loss = 0.570019
I1004 22:59:30.814949 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 22:59:30.814949 15924 solver.cpp:237]     Train net output #1: loss = 0.570019 (* 1 = 0.570019 loss)
I1004 22:59:30.814949 15924 sgd_solver.cpp:105] Iteration 24500, lr = 1e-05
I1004 22:59:33.139570 15924 solver.cpp:218] Iteration 24600 (43.1818 iter/s, 2.31579s/100 iters), loss = 0.443077
I1004 22:59:33.139570 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:59:33.139570 15924 solver.cpp:237]     Train net output #1: loss = 0.443077 (* 1 = 0.443077 loss)
I1004 22:59:33.139570 15924 sgd_solver.cpp:105] Iteration 24600, lr = 1e-05
I1004 22:59:35.451591 15924 solver.cpp:218] Iteration 24700 (43.0957 iter/s, 2.32041s/100 iters), loss = 0.577913
I1004 22:59:35.451591 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 22:59:35.451591 15924 solver.cpp:237]     Train net output #1: loss = 0.577913 (* 1 = 0.577913 loss)
I1004 22:59:35.451591 15924 sgd_solver.cpp:105] Iteration 24700, lr = 1e-05
I1004 22:59:37.752652 15924 solver.cpp:218] Iteration 24800 (43.4481 iter/s, 2.3016s/100 iters), loss = 0.490229
I1004 22:59:37.752652 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 22:59:37.752652 15924 solver.cpp:237]     Train net output #1: loss = 0.490229 (* 1 = 0.490229 loss)
I1004 22:59:37.752652 15924 sgd_solver.cpp:105] Iteration 24800, lr = 1e-05
I1004 22:59:40.042253 15924 solver.cpp:218] Iteration 24900 (43.798 iter/s, 2.28321s/100 iters), loss = 0.44864
I1004 22:59:40.042253 15924 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 22:59:40.042253 15924 solver.cpp:237]     Train net output #1: loss = 0.44864 (* 1 = 0.44864 loss)
I1004 22:59:40.042253 15924 sgd_solver.cpp:105] Iteration 24900, lr = 1e-05
I1004 22:59:42.233968  1048 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:59:42.328660 15924 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/slimnet_simpnet_P3_iter_25000.caffemodel
I1004 22:59:42.336741 15924 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_simpnet_P3_iter_25000.solverstate
I1004 22:59:42.336741 15924 solver.cpp:310] Iteration 25000, loss = 0.501433
I1004 22:59:42.336741 15924 solver.cpp:330] Iteration 25000, Testing net (#0)
I1004 22:59:42.336741 15924 net.cpp:676] Ignoring source layer accuracy_training
I1004 22:59:42.789868 18032 data_layer.cpp:73] Restarting data prefetching from start.
I1004 22:59:42.805505 15924 solver.cpp:397]     Test net output #0: accuracy = 0.7639
I1004 22:59:42.805505 15924 solver.cpp:397]     Test net output #1: loss = 0.690376 (* 1 = 0.690376 loss)
I1004 22:59:42.805505 15924 solver.cpp:315] Optimization Done.
I1004 22:59:42.805505 15924 caffe.cpp:260] Optimization Done.

G:\Caffe>pause
Press any key to continue . . . 
