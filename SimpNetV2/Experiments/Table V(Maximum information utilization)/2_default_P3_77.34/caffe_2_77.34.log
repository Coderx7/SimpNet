
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I1004 21:48:52.927536 15504 caffe.cpp:219] Using GPUs 0
I1004 21:48:53.090898 15504 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1004 21:48:53.378727 15504 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 21:48:53.394353 15504 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 25000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 25000
snapshot_prefix: "examples/cifar10/slimnet_simpnet_P3"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 25000
type: "Nesterov"
I1004 21:48:53.394353 15504 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 21:48:53.394353 15504 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 21:48:53.394353 15504 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1004 21:48:53.394353 15504 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1004 21:48:53.394353 15504 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P3__"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1004 21:48:53.394353 15504 layer_factory.cpp:58] Creating layer cifar
I1004 21:48:53.411216 15504 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I1004 21:48:53.411216 15504 net.cpp:84] Creating Layer cifar
I1004 21:48:53.411216 15504 net.cpp:380] cifar -> data
I1004 21:48:53.411216 15504 net.cpp:380] cifar -> label
I1004 21:48:53.411216 15504 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1004 21:48:53.413214 15504 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 21:48:53.413214 15504 data_layer.cpp:45] output data size: 100,3,32,32
I1004 21:48:53.418215 15504 net.cpp:122] Setting up cifar
I1004 21:48:53.418215 15504 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1004 21:48:53.418215 15504 net.cpp:129] Top shape: 100 (100)
I1004 21:48:53.418215 15504 net.cpp:137] Memory required for data: 1229200
I1004 21:48:53.418215 15504 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1004 21:48:53.418215 15504 net.cpp:84] Creating Layer label_cifar_1_split
I1004 21:48:53.418215 15504 net.cpp:406] label_cifar_1_split <- label
I1004 21:48:53.418215 15504 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1004 21:48:53.418215 15504 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1004 21:48:53.418215 15504 net.cpp:122] Setting up label_cifar_1_split
I1004 21:48:53.418215 15504 net.cpp:129] Top shape: 100 (100)
I1004 21:48:53.418215 15504 net.cpp:129] Top shape: 100 (100)
I1004 21:48:53.418215 15504 net.cpp:137] Memory required for data: 1230000
I1004 21:48:53.418215 15504 layer_factory.cpp:58] Creating layer conv1
I1004 21:48:53.418215 15504 net.cpp:84] Creating Layer conv1
I1004 21:48:53.418215 15504 net.cpp:406] conv1 <- data
I1004 21:48:53.418215 15504 net.cpp:380] conv1 -> conv1
I1004 21:48:53.419215 16316 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 21:48:53.657693 15504 net.cpp:122] Setting up conv1
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 3687600
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer bn1
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer bn1
I1004 21:48:53.657693 15504 net.cpp:406] bn1 <- conv1
I1004 21:48:53.657693 15504 net.cpp:367] bn1 -> conv1 (in-place)
I1004 21:48:53.657693 15504 net.cpp:122] Setting up bn1
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 6145200
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer scale1
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer scale1
I1004 21:48:53.657693 15504 net.cpp:406] scale1 <- conv1
I1004 21:48:53.657693 15504 net.cpp:367] scale1 -> conv1 (in-place)
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer scale1
I1004 21:48:53.657693 15504 net.cpp:122] Setting up scale1
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 8602800
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer relu1
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer relu1
I1004 21:48:53.657693 15504 net.cpp:406] relu1 <- conv1
I1004 21:48:53.657693 15504 net.cpp:367] relu1 -> conv1 (in-place)
I1004 21:48:53.657693 15504 net.cpp:122] Setting up relu1
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 11060400
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer conv1_0
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer conv1_0
I1004 21:48:53.657693 15504 net.cpp:406] conv1_0 <- conv1
I1004 21:48:53.657693 15504 net.cpp:380] conv1_0 -> conv1_0
I1004 21:48:53.657693 15504 net.cpp:122] Setting up conv1_0
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 15975600
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer bn1_0
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer bn1_0
I1004 21:48:53.657693 15504 net.cpp:406] bn1_0 <- conv1_0
I1004 21:48:53.657693 15504 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1004 21:48:53.657693 15504 net.cpp:122] Setting up bn1_0
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 20890800
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer scale1_0
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer scale1_0
I1004 21:48:53.657693 15504 net.cpp:406] scale1_0 <- conv1_0
I1004 21:48:53.657693 15504 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer scale1_0
I1004 21:48:53.657693 15504 net.cpp:122] Setting up scale1_0
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 25806000
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer relu1_0
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer relu1_0
I1004 21:48:53.657693 15504 net.cpp:406] relu1_0 <- conv1_0
I1004 21:48:53.657693 15504 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1004 21:48:53.657693 15504 net.cpp:122] Setting up relu1_0
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 30721200
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer conv2
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer conv2
I1004 21:48:53.657693 15504 net.cpp:406] conv2 <- conv1_0
I1004 21:48:53.657693 15504 net.cpp:380] conv2 -> conv2
I1004 21:48:53.657693 15504 net.cpp:122] Setting up conv2
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 35636400
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer bn2
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer bn2
I1004 21:48:53.657693 15504 net.cpp:406] bn2 <- conv2
I1004 21:48:53.657693 15504 net.cpp:367] bn2 -> conv2 (in-place)
I1004 21:48:53.657693 15504 net.cpp:122] Setting up bn2
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 40551600
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer scale2
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer scale2
I1004 21:48:53.657693 15504 net.cpp:406] scale2 <- conv2
I1004 21:48:53.657693 15504 net.cpp:367] scale2 -> conv2 (in-place)
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer scale2
I1004 21:48:53.657693 15504 net.cpp:122] Setting up scale2
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 45466800
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer relu2
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer relu2
I1004 21:48:53.657693 15504 net.cpp:406] relu2 <- conv2
I1004 21:48:53.657693 15504 net.cpp:367] relu2 -> conv2 (in-place)
I1004 21:48:53.657693 15504 net.cpp:122] Setting up relu2
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 50382000
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer pool2_1
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer pool2_1
I1004 21:48:53.657693 15504 net.cpp:406] pool2_1 <- conv2
I1004 21:48:53.657693 15504 net.cpp:380] pool2_1 -> pool2_1
I1004 21:48:53.657693 15504 net.cpp:122] Setting up pool2_1
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 51610800
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer conv2_1
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer conv2_1
I1004 21:48:53.657693 15504 net.cpp:406] conv2_1 <- pool2_1
I1004 21:48:53.657693 15504 net.cpp:380] conv2_1 -> conv2_1
I1004 21:48:53.657693 15504 net.cpp:122] Setting up conv2_1
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 52839600
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer bn2_1
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer bn2_1
I1004 21:48:53.657693 15504 net.cpp:406] bn2_1 <- conv2_1
I1004 21:48:53.657693 15504 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1004 21:48:53.657693 15504 net.cpp:122] Setting up bn2_1
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 54068400
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer scale2_1
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer scale2_1
I1004 21:48:53.657693 15504 net.cpp:406] scale2_1 <- conv2_1
I1004 21:48:53.657693 15504 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer scale2_1
I1004 21:48:53.657693 15504 net.cpp:122] Setting up scale2_1
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 55297200
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer relu2_1
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer relu2_1
I1004 21:48:53.657693 15504 net.cpp:406] relu2_1 <- conv2_1
I1004 21:48:53.657693 15504 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1004 21:48:53.657693 15504 net.cpp:122] Setting up relu2_1
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 56526000
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer conv2_2
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer conv2_2
I1004 21:48:53.657693 15504 net.cpp:406] conv2_2 <- conv2_1
I1004 21:48:53.657693 15504 net.cpp:380] conv2_2 -> conv2_2
I1004 21:48:53.657693 15504 net.cpp:122] Setting up conv2_2
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 58471600
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer bn2_2
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer bn2_2
I1004 21:48:53.657693 15504 net.cpp:406] bn2_2 <- conv2_2
I1004 21:48:53.657693 15504 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1004 21:48:53.657693 15504 net.cpp:122] Setting up bn2_2
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 60417200
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer scale2_2
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer scale2_2
I1004 21:48:53.657693 15504 net.cpp:406] scale2_2 <- conv2_2
I1004 21:48:53.657693 15504 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer scale2_2
I1004 21:48:53.657693 15504 net.cpp:122] Setting up scale2_2
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 62362800
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer relu2_2
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer relu2_2
I1004 21:48:53.657693 15504 net.cpp:406] relu2_2 <- conv2_2
I1004 21:48:53.657693 15504 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1004 21:48:53.657693 15504 net.cpp:122] Setting up relu2_2
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 64308400
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer conv3
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer conv3
I1004 21:48:53.657693 15504 net.cpp:406] conv3 <- conv2_2
I1004 21:48:53.657693 15504 net.cpp:380] conv3 -> conv3
I1004 21:48:53.657693 15504 net.cpp:122] Setting up conv3
I1004 21:48:53.657693 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.657693 15504 net.cpp:137] Memory required for data: 66254000
I1004 21:48:53.657693 15504 layer_factory.cpp:58] Creating layer bn3
I1004 21:48:53.657693 15504 net.cpp:84] Creating Layer bn3
I1004 21:48:53.657693 15504 net.cpp:406] bn3 <- conv3
I1004 21:48:53.657693 15504 net.cpp:367] bn3 -> conv3 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up bn3
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 68199600
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale3
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer scale3
I1004 21:48:53.673319 15504 net.cpp:406] scale3 <- conv3
I1004 21:48:53.673319 15504 net.cpp:367] scale3 -> conv3 (in-place)
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale3
I1004 21:48:53.673319 15504 net.cpp:122] Setting up scale3
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 70145200
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer relu3
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer relu3
I1004 21:48:53.673319 15504 net.cpp:406] relu3 <- conv3
I1004 21:48:53.673319 15504 net.cpp:367] relu3 -> conv3 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up relu3
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 72090800
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer conv3_1
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer conv3_1
I1004 21:48:53.673319 15504 net.cpp:406] conv3_1 <- conv3
I1004 21:48:53.673319 15504 net.cpp:380] conv3_1 -> conv3_1
I1004 21:48:53.673319 15504 net.cpp:122] Setting up conv3_1
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 74036400
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer bn3_1
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer bn3_1
I1004 21:48:53.673319 15504 net.cpp:406] bn3_1 <- conv3_1
I1004 21:48:53.673319 15504 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up bn3_1
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 75982000
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale3_1
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer scale3_1
I1004 21:48:53.673319 15504 net.cpp:406] scale3_1 <- conv3_1
I1004 21:48:53.673319 15504 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale3_1
I1004 21:48:53.673319 15504 net.cpp:122] Setting up scale3_1
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 77927600
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer relu3_1
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer relu3_1
I1004 21:48:53.673319 15504 net.cpp:406] relu3_1 <- conv3_1
I1004 21:48:53.673319 15504 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up relu3_1
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 79873200
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer conv4
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer conv4
I1004 21:48:53.673319 15504 net.cpp:406] conv4 <- conv3_1
I1004 21:48:53.673319 15504 net.cpp:380] conv4 -> conv4
I1004 21:48:53.673319 15504 net.cpp:122] Setting up conv4
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 81818800
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer bn4
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer bn4
I1004 21:48:53.673319 15504 net.cpp:406] bn4 <- conv4
I1004 21:48:53.673319 15504 net.cpp:367] bn4 -> conv4 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up bn4
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 83764400
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale4
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer scale4
I1004 21:48:53.673319 15504 net.cpp:406] scale4 <- conv4
I1004 21:48:53.673319 15504 net.cpp:367] scale4 -> conv4 (in-place)
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale4
I1004 21:48:53.673319 15504 net.cpp:122] Setting up scale4
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 85710000
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer relu4
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer relu4
I1004 21:48:53.673319 15504 net.cpp:406] relu4 <- conv4
I1004 21:48:53.673319 15504 net.cpp:367] relu4 -> conv4 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up relu4
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 87655600
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer conv4_1
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer conv4_1
I1004 21:48:53.673319 15504 net.cpp:406] conv4_1 <- conv4
I1004 21:48:53.673319 15504 net.cpp:380] conv4_1 -> conv4_1
I1004 21:48:53.673319 15504 net.cpp:122] Setting up conv4_1
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 89601200
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer bn4_1
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer bn4_1
I1004 21:48:53.673319 15504 net.cpp:406] bn4_1 <- conv4_1
I1004 21:48:53.673319 15504 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up bn4_1
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 91546800
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale4_1
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer scale4_1
I1004 21:48:53.673319 15504 net.cpp:406] scale4_1 <- conv4_1
I1004 21:48:53.673319 15504 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale4_1
I1004 21:48:53.673319 15504 net.cpp:122] Setting up scale4_1
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 93492400
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer relu4_1
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer relu4_1
I1004 21:48:53.673319 15504 net.cpp:406] relu4_1 <- conv4_1
I1004 21:48:53.673319 15504 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up relu4_1
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 95438000
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer conv4_2
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer conv4_2
I1004 21:48:53.673319 15504 net.cpp:406] conv4_2 <- conv4_1
I1004 21:48:53.673319 15504 net.cpp:380] conv4_2 -> conv4_2
I1004 21:48:53.673319 15504 net.cpp:122] Setting up conv4_2
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 98305200
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer bn4_2
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer bn4_2
I1004 21:48:53.673319 15504 net.cpp:406] bn4_2 <- conv4_2
I1004 21:48:53.673319 15504 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up bn4_2
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 101172400
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale4_2
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer scale4_2
I1004 21:48:53.673319 15504 net.cpp:406] scale4_2 <- conv4_2
I1004 21:48:53.673319 15504 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale4_2
I1004 21:48:53.673319 15504 net.cpp:122] Setting up scale4_2
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 104039600
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer relu4_2
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer relu4_2
I1004 21:48:53.673319 15504 net.cpp:406] relu4_2 <- conv4_2
I1004 21:48:53.673319 15504 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up relu4_2
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 106906800
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer pool4_2
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer pool4_2
I1004 21:48:53.673319 15504 net.cpp:406] pool4_2 <- conv4_2
I1004 21:48:53.673319 15504 net.cpp:380] pool4_2 -> pool4_2
I1004 21:48:53.673319 15504 net.cpp:122] Setting up pool4_2
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 107623600
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer conv4_0
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer conv4_0
I1004 21:48:53.673319 15504 net.cpp:406] conv4_0 <- pool4_2
I1004 21:48:53.673319 15504 net.cpp:380] conv4_0 -> conv4_0
I1004 21:48:53.673319 15504 net.cpp:122] Setting up conv4_0
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 108340400
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer bn4_0
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer bn4_0
I1004 21:48:53.673319 15504 net.cpp:406] bn4_0 <- conv4_0
I1004 21:48:53.673319 15504 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up bn4_0
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 109057200
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale4_0
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer scale4_0
I1004 21:48:53.673319 15504 net.cpp:406] scale4_0 <- conv4_0
I1004 21:48:53.673319 15504 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale4_0
I1004 21:48:53.673319 15504 net.cpp:122] Setting up scale4_0
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 109774000
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer relu4_0
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer relu4_0
I1004 21:48:53.673319 15504 net.cpp:406] relu4_0 <- conv4_0
I1004 21:48:53.673319 15504 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up relu4_0
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 110490800
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer conv11
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer conv11
I1004 21:48:53.673319 15504 net.cpp:406] conv11 <- conv4_0
I1004 21:48:53.673319 15504 net.cpp:380] conv11 -> conv11
I1004 21:48:53.673319 15504 net.cpp:122] Setting up conv11
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 111386800
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer bn_conv11
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer bn_conv11
I1004 21:48:53.673319 15504 net.cpp:406] bn_conv11 <- conv11
I1004 21:48:53.673319 15504 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up bn_conv11
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 112282800
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale_conv11
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer scale_conv11
I1004 21:48:53.673319 15504 net.cpp:406] scale_conv11 <- conv11
I1004 21:48:53.673319 15504 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale_conv11
I1004 21:48:53.673319 15504 net.cpp:122] Setting up scale_conv11
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 113178800
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer relu_conv11
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer relu_conv11
I1004 21:48:53.673319 15504 net.cpp:406] relu_conv11 <- conv11
I1004 21:48:53.673319 15504 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up relu_conv11
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 114074800
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer conv12
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer conv12
I1004 21:48:53.673319 15504 net.cpp:406] conv12 <- conv11
I1004 21:48:53.673319 15504 net.cpp:380] conv12 -> conv12
I1004 21:48:53.673319 15504 net.cpp:122] Setting up conv12
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 115175600
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer bn_conv12
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer bn_conv12
I1004 21:48:53.673319 15504 net.cpp:406] bn_conv12 <- conv12
I1004 21:48:53.673319 15504 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up bn_conv12
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 116276400
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale_conv12
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer scale_conv12
I1004 21:48:53.673319 15504 net.cpp:406] scale_conv12 <- conv12
I1004 21:48:53.673319 15504 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer scale_conv12
I1004 21:48:53.673319 15504 net.cpp:122] Setting up scale_conv12
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 117377200
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer relu_conv12
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer relu_conv12
I1004 21:48:53.673319 15504 net.cpp:406] relu_conv12 <- conv12
I1004 21:48:53.673319 15504 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1004 21:48:53.673319 15504 net.cpp:122] Setting up relu_conv12
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 118478000
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer poolcp6
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer poolcp6
I1004 21:48:53.673319 15504 net.cpp:406] poolcp6 <- conv12
I1004 21:48:53.673319 15504 net.cpp:380] poolcp6 -> poolcp6
I1004 21:48:53.673319 15504 net.cpp:122] Setting up poolcp6
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 118495200
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer ip1
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer ip1
I1004 21:48:53.673319 15504 net.cpp:406] ip1 <- poolcp6
I1004 21:48:53.673319 15504 net.cpp:380] ip1 -> ip1
I1004 21:48:53.673319 15504 net.cpp:122] Setting up ip1
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 118499200
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer ip1_ip1_0_split
I1004 21:48:53.673319 15504 net.cpp:406] ip1_ip1_0_split <- ip1
I1004 21:48:53.673319 15504 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1004 21:48:53.673319 15504 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1004 21:48:53.673319 15504 net.cpp:122] Setting up ip1_ip1_0_split
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 118507200
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer accuracy_training
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer accuracy_training
I1004 21:48:53.673319 15504 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1004 21:48:53.673319 15504 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1004 21:48:53.673319 15504 net.cpp:380] accuracy_training -> accuracy_training
I1004 21:48:53.673319 15504 net.cpp:122] Setting up accuracy_training
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: (1)
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 118507204
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer loss
I1004 21:48:53.673319 15504 net.cpp:84] Creating Layer loss
I1004 21:48:53.673319 15504 net.cpp:406] loss <- ip1_ip1_0_split_1
I1004 21:48:53.673319 15504 net.cpp:406] loss <- label_cifar_1_split_1
I1004 21:48:53.673319 15504 net.cpp:380] loss -> loss
I1004 21:48:53.673319 15504 layer_factory.cpp:58] Creating layer loss
I1004 21:48:53.673319 15504 net.cpp:122] Setting up loss
I1004 21:48:53.673319 15504 net.cpp:129] Top shape: (1)
I1004 21:48:53.673319 15504 net.cpp:132]     with loss weight 1
I1004 21:48:53.673319 15504 net.cpp:137] Memory required for data: 118507208
I1004 21:48:53.673319 15504 net.cpp:198] loss needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:200] accuracy_training does not need backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] ip1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] poolcp6 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu_conv12 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale_conv12 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn_conv12 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv12 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu_conv11 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale_conv11 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn_conv11 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv11 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu4_0 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale4_0 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn4_0 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv4_0 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] pool4_2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu4_2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale4_2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn4_2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv4_2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu4_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale4_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn4_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv4_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu4 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale4 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn4 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv4 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu3_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale3_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn3_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv3_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu3 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale3 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn3 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv3 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu2_2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale2_2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn2_2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv2_2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu2_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale2_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn2_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv2_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] pool2_1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv2 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu1_0 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale1_0 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn1_0 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv1_0 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] relu1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] scale1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] bn1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:198] conv1 needs backward computation.
I1004 21:48:53.688943 15504 net.cpp:200] label_cifar_1_split does not need backward computation.
I1004 21:48:53.688943 15504 net.cpp:200] cifar does not need backward computation.
I1004 21:48:53.688943 15504 net.cpp:242] This network produces output accuracy_training
I1004 21:48:53.688943 15504 net.cpp:242] This network produces output loss
I1004 21:48:53.688943 15504 net.cpp:255] Network initialization done.
I1004 21:48:53.688943 15504 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 21:48:53.688943 15504 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1004 21:48:53.688943 15504 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1004 21:48:53.688943 15504 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1004 21:48:53.688943 15504 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P3__"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1004 21:48:53.688943 15504 layer_factory.cpp:58] Creating layer cifar
I1004 21:48:53.704581 15504 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer cifar
I1004 21:48:53.704581 15504 net.cpp:380] cifar -> data
I1004 21:48:53.704581 15504 net.cpp:380] cifar -> label
I1004 21:48:53.704581 15504 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1004 21:48:53.704581 15504 data_layer.cpp:45] output data size: 100,3,32,32
I1004 21:48:53.704581 15504 net.cpp:122] Setting up cifar
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 (100)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 1229200
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer label_cifar_1_split
I1004 21:48:53.704581 15504 net.cpp:406] label_cifar_1_split <- label
I1004 21:48:53.704581 15504 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1004 21:48:53.704581 15504 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1004 21:48:53.704581 15504 net.cpp:122] Setting up label_cifar_1_split
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 (100)
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 (100)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 1230000
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer conv1
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer conv1
I1004 21:48:53.704581 15504 net.cpp:406] conv1 <- data
I1004 21:48:53.704581 15504 net.cpp:380] conv1 -> conv1
I1004 21:48:53.704581  6484 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1004 21:48:53.704581 15504 net.cpp:122] Setting up conv1
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 3687600
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer bn1
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer bn1
I1004 21:48:53.704581 15504 net.cpp:406] bn1 <- conv1
I1004 21:48:53.704581 15504 net.cpp:367] bn1 -> conv1 (in-place)
I1004 21:48:53.704581 15504 net.cpp:122] Setting up bn1
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 6145200
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer scale1
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer scale1
I1004 21:48:53.704581 15504 net.cpp:406] scale1 <- conv1
I1004 21:48:53.704581 15504 net.cpp:367] scale1 -> conv1 (in-place)
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer scale1
I1004 21:48:53.704581 15504 net.cpp:122] Setting up scale1
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 8602800
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer relu1
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer relu1
I1004 21:48:53.704581 15504 net.cpp:406] relu1 <- conv1
I1004 21:48:53.704581 15504 net.cpp:367] relu1 -> conv1 (in-place)
I1004 21:48:53.704581 15504 net.cpp:122] Setting up relu1
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 11060400
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer conv1_0
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer conv1_0
I1004 21:48:53.704581 15504 net.cpp:406] conv1_0 <- conv1
I1004 21:48:53.704581 15504 net.cpp:380] conv1_0 -> conv1_0
I1004 21:48:53.704581 15504 net.cpp:122] Setting up conv1_0
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 15975600
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer bn1_0
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer bn1_0
I1004 21:48:53.704581 15504 net.cpp:406] bn1_0 <- conv1_0
I1004 21:48:53.704581 15504 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1004 21:48:53.704581 15504 net.cpp:122] Setting up bn1_0
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 20890800
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer scale1_0
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer scale1_0
I1004 21:48:53.704581 15504 net.cpp:406] scale1_0 <- conv1_0
I1004 21:48:53.704581 15504 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer scale1_0
I1004 21:48:53.704581 15504 net.cpp:122] Setting up scale1_0
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 25806000
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer relu1_0
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer relu1_0
I1004 21:48:53.704581 15504 net.cpp:406] relu1_0 <- conv1_0
I1004 21:48:53.704581 15504 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1004 21:48:53.704581 15504 net.cpp:122] Setting up relu1_0
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 30721200
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer conv2
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer conv2
I1004 21:48:53.704581 15504 net.cpp:406] conv2 <- conv1_0
I1004 21:48:53.704581 15504 net.cpp:380] conv2 -> conv2
I1004 21:48:53.704581 15504 net.cpp:122] Setting up conv2
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 35636400
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer bn2
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer bn2
I1004 21:48:53.704581 15504 net.cpp:406] bn2 <- conv2
I1004 21:48:53.704581 15504 net.cpp:367] bn2 -> conv2 (in-place)
I1004 21:48:53.704581 15504 net.cpp:122] Setting up bn2
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 40551600
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer scale2
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer scale2
I1004 21:48:53.704581 15504 net.cpp:406] scale2 <- conv2
I1004 21:48:53.704581 15504 net.cpp:367] scale2 -> conv2 (in-place)
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer scale2
I1004 21:48:53.704581 15504 net.cpp:122] Setting up scale2
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 45466800
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer relu2
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer relu2
I1004 21:48:53.704581 15504 net.cpp:406] relu2 <- conv2
I1004 21:48:53.704581 15504 net.cpp:367] relu2 -> conv2 (in-place)
I1004 21:48:53.704581 15504 net.cpp:122] Setting up relu2
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 50382000
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer pool2_1
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer pool2_1
I1004 21:48:53.704581 15504 net.cpp:406] pool2_1 <- conv2
I1004 21:48:53.704581 15504 net.cpp:380] pool2_1 -> pool2_1
I1004 21:48:53.704581 15504 net.cpp:122] Setting up pool2_1
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 51610800
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer conv2_1
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer conv2_1
I1004 21:48:53.704581 15504 net.cpp:406] conv2_1 <- pool2_1
I1004 21:48:53.704581 15504 net.cpp:380] conv2_1 -> conv2_1
I1004 21:48:53.704581 15504 net.cpp:122] Setting up conv2_1
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 52839600
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer bn2_1
I1004 21:48:53.704581 15504 net.cpp:84] Creating Layer bn2_1
I1004 21:48:53.704581 15504 net.cpp:406] bn2_1 <- conv2_1
I1004 21:48:53.704581 15504 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1004 21:48:53.704581 15504 net.cpp:122] Setting up bn2_1
I1004 21:48:53.704581 15504 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:48:53.704581 15504 net.cpp:137] Memory required for data: 54068400
I1004 21:48:53.704581 15504 layer_factory.cpp:58] Creating layer scale2_1
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer scale2_1
I1004 21:48:53.720194 15504 net.cpp:406] scale2_1 <- conv2_1
I1004 21:48:53.720194 15504 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale2_1
I1004 21:48:53.720194 15504 net.cpp:122] Setting up scale2_1
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 55297200
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer relu2_1
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer relu2_1
I1004 21:48:53.720194 15504 net.cpp:406] relu2_1 <- conv2_1
I1004 21:48:53.720194 15504 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up relu2_1
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 12 16 16 (307200)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 56526000
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer conv2_2
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer conv2_2
I1004 21:48:53.720194 15504 net.cpp:406] conv2_2 <- conv2_1
I1004 21:48:53.720194 15504 net.cpp:380] conv2_2 -> conv2_2
I1004 21:48:53.720194 15504 net.cpp:122] Setting up conv2_2
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 58471600
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer bn2_2
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer bn2_2
I1004 21:48:53.720194 15504 net.cpp:406] bn2_2 <- conv2_2
I1004 21:48:53.720194 15504 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up bn2_2
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 60417200
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale2_2
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer scale2_2
I1004 21:48:53.720194 15504 net.cpp:406] scale2_2 <- conv2_2
I1004 21:48:53.720194 15504 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale2_2
I1004 21:48:53.720194 15504 net.cpp:122] Setting up scale2_2
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 62362800
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer relu2_2
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer relu2_2
I1004 21:48:53.720194 15504 net.cpp:406] relu2_2 <- conv2_2
I1004 21:48:53.720194 15504 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up relu2_2
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 64308400
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer conv3
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer conv3
I1004 21:48:53.720194 15504 net.cpp:406] conv3 <- conv2_2
I1004 21:48:53.720194 15504 net.cpp:380] conv3 -> conv3
I1004 21:48:53.720194 15504 net.cpp:122] Setting up conv3
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 66254000
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer bn3
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer bn3
I1004 21:48:53.720194 15504 net.cpp:406] bn3 <- conv3
I1004 21:48:53.720194 15504 net.cpp:367] bn3 -> conv3 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up bn3
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 68199600
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale3
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer scale3
I1004 21:48:53.720194 15504 net.cpp:406] scale3 <- conv3
I1004 21:48:53.720194 15504 net.cpp:367] scale3 -> conv3 (in-place)
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale3
I1004 21:48:53.720194 15504 net.cpp:122] Setting up scale3
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 70145200
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer relu3
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer relu3
I1004 21:48:53.720194 15504 net.cpp:406] relu3 <- conv3
I1004 21:48:53.720194 15504 net.cpp:367] relu3 -> conv3 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up relu3
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 72090800
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer conv3_1
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer conv3_1
I1004 21:48:53.720194 15504 net.cpp:406] conv3_1 <- conv3
I1004 21:48:53.720194 15504 net.cpp:380] conv3_1 -> conv3_1
I1004 21:48:53.720194 15504 net.cpp:122] Setting up conv3_1
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 74036400
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer bn3_1
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer bn3_1
I1004 21:48:53.720194 15504 net.cpp:406] bn3_1 <- conv3_1
I1004 21:48:53.720194 15504 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up bn3_1
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 75982000
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale3_1
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer scale3_1
I1004 21:48:53.720194 15504 net.cpp:406] scale3_1 <- conv3_1
I1004 21:48:53.720194 15504 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale3_1
I1004 21:48:53.720194 15504 net.cpp:122] Setting up scale3_1
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 77927600
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer relu3_1
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer relu3_1
I1004 21:48:53.720194 15504 net.cpp:406] relu3_1 <- conv3_1
I1004 21:48:53.720194 15504 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up relu3_1
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 79873200
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer conv4
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer conv4
I1004 21:48:53.720194 15504 net.cpp:406] conv4 <- conv3_1
I1004 21:48:53.720194 15504 net.cpp:380] conv4 -> conv4
I1004 21:48:53.720194 15504 net.cpp:122] Setting up conv4
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 81818800
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer bn4
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer bn4
I1004 21:48:53.720194 15504 net.cpp:406] bn4 <- conv4
I1004 21:48:53.720194 15504 net.cpp:367] bn4 -> conv4 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up bn4
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 83764400
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale4
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer scale4
I1004 21:48:53.720194 15504 net.cpp:406] scale4 <- conv4
I1004 21:48:53.720194 15504 net.cpp:367] scale4 -> conv4 (in-place)
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale4
I1004 21:48:53.720194 15504 net.cpp:122] Setting up scale4
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 85710000
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer relu4
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer relu4
I1004 21:48:53.720194 15504 net.cpp:406] relu4 <- conv4
I1004 21:48:53.720194 15504 net.cpp:367] relu4 -> conv4 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up relu4
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 87655600
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer conv4_1
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer conv4_1
I1004 21:48:53.720194 15504 net.cpp:406] conv4_1 <- conv4
I1004 21:48:53.720194 15504 net.cpp:380] conv4_1 -> conv4_1
I1004 21:48:53.720194 15504 net.cpp:122] Setting up conv4_1
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 89601200
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer bn4_1
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer bn4_1
I1004 21:48:53.720194 15504 net.cpp:406] bn4_1 <- conv4_1
I1004 21:48:53.720194 15504 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up bn4_1
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 91546800
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale4_1
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer scale4_1
I1004 21:48:53.720194 15504 net.cpp:406] scale4_1 <- conv4_1
I1004 21:48:53.720194 15504 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale4_1
I1004 21:48:53.720194 15504 net.cpp:122] Setting up scale4_1
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 93492400
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer relu4_1
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer relu4_1
I1004 21:48:53.720194 15504 net.cpp:406] relu4_1 <- conv4_1
I1004 21:48:53.720194 15504 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up relu4_1
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 95438000
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer conv4_2
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer conv4_2
I1004 21:48:53.720194 15504 net.cpp:406] conv4_2 <- conv4_1
I1004 21:48:53.720194 15504 net.cpp:380] conv4_2 -> conv4_2
I1004 21:48:53.720194 15504 net.cpp:122] Setting up conv4_2
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 98305200
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer bn4_2
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer bn4_2
I1004 21:48:53.720194 15504 net.cpp:406] bn4_2 <- conv4_2
I1004 21:48:53.720194 15504 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up bn4_2
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 101172400
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale4_2
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer scale4_2
I1004 21:48:53.720194 15504 net.cpp:406] scale4_2 <- conv4_2
I1004 21:48:53.720194 15504 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale4_2
I1004 21:48:53.720194 15504 net.cpp:122] Setting up scale4_2
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 104039600
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer relu4_2
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer relu4_2
I1004 21:48:53.720194 15504 net.cpp:406] relu4_2 <- conv4_2
I1004 21:48:53.720194 15504 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up relu4_2
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 106906800
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer pool4_2
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer pool4_2
I1004 21:48:53.720194 15504 net.cpp:406] pool4_2 <- conv4_2
I1004 21:48:53.720194 15504 net.cpp:380] pool4_2 -> pool4_2
I1004 21:48:53.720194 15504 net.cpp:122] Setting up pool4_2
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 107623600
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer conv4_0
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer conv4_0
I1004 21:48:53.720194 15504 net.cpp:406] conv4_0 <- pool4_2
I1004 21:48:53.720194 15504 net.cpp:380] conv4_0 -> conv4_0
I1004 21:48:53.720194 15504 net.cpp:122] Setting up conv4_0
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 108340400
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer bn4_0
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer bn4_0
I1004 21:48:53.720194 15504 net.cpp:406] bn4_0 <- conv4_0
I1004 21:48:53.720194 15504 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up bn4_0
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 109057200
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale4_0
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer scale4_0
I1004 21:48:53.720194 15504 net.cpp:406] scale4_0 <- conv4_0
I1004 21:48:53.720194 15504 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale4_0
I1004 21:48:53.720194 15504 net.cpp:122] Setting up scale4_0
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 109774000
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer relu4_0
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer relu4_0
I1004 21:48:53.720194 15504 net.cpp:406] relu4_0 <- conv4_0
I1004 21:48:53.720194 15504 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up relu4_0
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 110490800
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer conv11
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer conv11
I1004 21:48:53.720194 15504 net.cpp:406] conv11 <- conv4_0
I1004 21:48:53.720194 15504 net.cpp:380] conv11 -> conv11
I1004 21:48:53.720194 15504 net.cpp:122] Setting up conv11
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 111386800
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer bn_conv11
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer bn_conv11
I1004 21:48:53.720194 15504 net.cpp:406] bn_conv11 <- conv11
I1004 21:48:53.720194 15504 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1004 21:48:53.720194 15504 net.cpp:122] Setting up bn_conv11
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 112282800
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale_conv11
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer scale_conv11
I1004 21:48:53.720194 15504 net.cpp:406] scale_conv11 <- conv11
I1004 21:48:53.720194 15504 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer scale_conv11
I1004 21:48:53.720194 15504 net.cpp:122] Setting up scale_conv11
I1004 21:48:53.720194 15504 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:48:53.720194 15504 net.cpp:137] Memory required for data: 113178800
I1004 21:48:53.720194 15504 layer_factory.cpp:58] Creating layer relu_conv11
I1004 21:48:53.720194 15504 net.cpp:84] Creating Layer relu_conv11
I1004 21:48:53.720194 15504 net.cpp:406] relu_conv11 <- conv11
I1004 21:48:53.720194 15504 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1004 21:48:53.735818 15504 net.cpp:122] Setting up relu_conv11
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1004 21:48:53.735818 15504 net.cpp:137] Memory required for data: 114074800
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer conv12
I1004 21:48:53.735818 15504 net.cpp:84] Creating Layer conv12
I1004 21:48:53.735818 15504 net.cpp:406] conv12 <- conv11
I1004 21:48:53.735818 15504 net.cpp:380] conv12 -> conv12
I1004 21:48:53.735818 15504 net.cpp:122] Setting up conv12
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:48:53.735818 15504 net.cpp:137] Memory required for data: 115175600
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer bn_conv12
I1004 21:48:53.735818 15504 net.cpp:84] Creating Layer bn_conv12
I1004 21:48:53.735818 15504 net.cpp:406] bn_conv12 <- conv12
I1004 21:48:53.735818 15504 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1004 21:48:53.735818 15504 net.cpp:122] Setting up bn_conv12
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:48:53.735818 15504 net.cpp:137] Memory required for data: 116276400
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer scale_conv12
I1004 21:48:53.735818 15504 net.cpp:84] Creating Layer scale_conv12
I1004 21:48:53.735818 15504 net.cpp:406] scale_conv12 <- conv12
I1004 21:48:53.735818 15504 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer scale_conv12
I1004 21:48:53.735818 15504 net.cpp:122] Setting up scale_conv12
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:48:53.735818 15504 net.cpp:137] Memory required for data: 117377200
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer relu_conv12
I1004 21:48:53.735818 15504 net.cpp:84] Creating Layer relu_conv12
I1004 21:48:53.735818 15504 net.cpp:406] relu_conv12 <- conv12
I1004 21:48:53.735818 15504 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1004 21:48:53.735818 15504 net.cpp:122] Setting up relu_conv12
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1004 21:48:53.735818 15504 net.cpp:137] Memory required for data: 118478000
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer poolcp6
I1004 21:48:53.735818 15504 net.cpp:84] Creating Layer poolcp6
I1004 21:48:53.735818 15504 net.cpp:406] poolcp6 <- conv12
I1004 21:48:53.735818 15504 net.cpp:380] poolcp6 -> poolcp6
I1004 21:48:53.735818 15504 net.cpp:122] Setting up poolcp6
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1004 21:48:53.735818 15504 net.cpp:137] Memory required for data: 118495200
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer ip1
I1004 21:48:53.735818 15504 net.cpp:84] Creating Layer ip1
I1004 21:48:53.735818 15504 net.cpp:406] ip1 <- poolcp6
I1004 21:48:53.735818 15504 net.cpp:380] ip1 -> ip1
I1004 21:48:53.735818 15504 net.cpp:122] Setting up ip1
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:48:53.735818 15504 net.cpp:137] Memory required for data: 118499200
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1004 21:48:53.735818 15504 net.cpp:84] Creating Layer ip1_ip1_0_split
I1004 21:48:53.735818 15504 net.cpp:406] ip1_ip1_0_split <- ip1
I1004 21:48:53.735818 15504 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1004 21:48:53.735818 15504 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1004 21:48:53.735818 15504 net.cpp:122] Setting up ip1_ip1_0_split
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: 100 10 (1000)
I1004 21:48:53.735818 15504 net.cpp:137] Memory required for data: 118507200
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer accuracy
I1004 21:48:53.735818 15504 net.cpp:84] Creating Layer accuracy
I1004 21:48:53.735818 15504 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1004 21:48:53.735818 15504 net.cpp:406] accuracy <- label_cifar_1_split_0
I1004 21:48:53.735818 15504 net.cpp:380] accuracy -> accuracy
I1004 21:48:53.735818 15504 net.cpp:122] Setting up accuracy
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: (1)
I1004 21:48:53.735818 15504 net.cpp:137] Memory required for data: 118507204
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer loss
I1004 21:48:53.735818 15504 net.cpp:84] Creating Layer loss
I1004 21:48:53.735818 15504 net.cpp:406] loss <- ip1_ip1_0_split_1
I1004 21:48:53.735818 15504 net.cpp:406] loss <- label_cifar_1_split_1
I1004 21:48:53.735818 15504 net.cpp:380] loss -> loss
I1004 21:48:53.735818 15504 layer_factory.cpp:58] Creating layer loss
I1004 21:48:53.735818 15504 net.cpp:122] Setting up loss
I1004 21:48:53.735818 15504 net.cpp:129] Top shape: (1)
I1004 21:48:53.735818 15504 net.cpp:132]     with loss weight 1
I1004 21:48:53.735818 15504 net.cpp:137] Memory required for data: 118507208
I1004 21:48:53.735818 15504 net.cpp:198] loss needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:200] accuracy does not need backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] ip1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] poolcp6 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu_conv12 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale_conv12 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn_conv12 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv12 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu_conv11 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale_conv11 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn_conv11 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv11 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu4_0 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale4_0 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn4_0 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv4_0 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] pool4_2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu4_2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale4_2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn4_2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv4_2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu4_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale4_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn4_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv4_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu4 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale4 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn4 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv4 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu3_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale3_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn3_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv3_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu3 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale3 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn3 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv3 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu2_2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale2_2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn2_2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv2_2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu2_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale2_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn2_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv2_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] pool2_1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv2 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu1_0 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale1_0 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn1_0 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv1_0 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] relu1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] scale1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] bn1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:198] conv1 needs backward computation.
I1004 21:48:53.735818 15504 net.cpp:200] label_cifar_1_split does not need backward computation.
I1004 21:48:53.735818 15504 net.cpp:200] cifar does not need backward computation.
I1004 21:48:53.735818 15504 net.cpp:242] This network produces output accuracy
I1004 21:48:53.735818 15504 net.cpp:242] This network produces output loss
I1004 21:48:53.735818 15504 net.cpp:255] Network initialization done.
I1004 21:48:53.735818 15504 solver.cpp:56] Solver scaffolding done.
I1004 21:48:53.735818 15504 caffe.cpp:249] Starting Optimization
I1004 21:48:53.735818 15504 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_drpall_Simple_P3__
I1004 21:48:53.735818 15504 solver.cpp:273] Learning Rate Policy: multistep
I1004 21:48:53.735818 15504 solver.cpp:330] Iteration 0, Testing net (#0)
I1004 21:48:53.735818 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:48:54.199331  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:48:54.230583 15504 solver.cpp:397]     Test net output #0: accuracy = 0.1001
I1004 21:48:54.230583 15504 solver.cpp:397]     Test net output #1: loss = 78.5941 (* 1 = 78.5941 loss)
I1004 21:48:54.277456 15504 solver.cpp:218] Iteration 0 (-2.16701e-35 iter/s, 0.535941s/100 iters), loss = 3.8873
I1004 21:48:54.277456 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I1004 21:48:54.277456 15504 solver.cpp:237]     Train net output #1: loss = 3.8873 (* 1 = 3.8873 loss)
I1004 21:48:54.277456 15504 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1004 21:48:56.559077 15504 solver.cpp:218] Iteration 100 (43.7085 iter/s, 2.28789s/100 iters), loss = 1.69487
I1004 21:48:56.559077 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1004 21:48:56.559077 15504 solver.cpp:237]     Train net output #1: loss = 1.69487 (* 1 = 1.69487 loss)
I1004 21:48:56.559077 15504 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1004 21:48:58.837294 15504 solver.cpp:218] Iteration 200 (43.8255 iter/s, 2.28177s/100 iters), loss = 2.02973
I1004 21:48:58.837294 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I1004 21:48:58.837294 15504 solver.cpp:237]     Train net output #1: loss = 2.02973 (* 1 = 2.02973 loss)
I1004 21:48:58.837294 15504 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1004 21:49:01.121268 15504 solver.cpp:218] Iteration 300 (43.8961 iter/s, 2.27811s/100 iters), loss = 1.55892
I1004 21:49:01.121268 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1004 21:49:01.121268 15504 solver.cpp:237]     Train net output #1: loss = 1.55892 (* 1 = 1.55892 loss)
I1004 21:49:01.121268 15504 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1004 21:49:03.408972 15504 solver.cpp:218] Iteration 400 (43.8522 iter/s, 2.28039s/100 iters), loss = 1.28468
I1004 21:49:03.408972 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1004 21:49:03.408972 15504 solver.cpp:237]     Train net output #1: loss = 1.28468 (* 1 = 1.28468 loss)
I1004 21:49:03.408972 15504 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1004 21:49:05.595046 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:49:05.705044 15504 solver.cpp:218] Iteration 500 (43.5526 iter/s, 2.29607s/100 iters), loss = 1.61876
I1004 21:49:05.706044 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1004 21:49:05.706044 15504 solver.cpp:237]     Train net output #1: loss = 1.61876 (* 1 = 1.61876 loss)
I1004 21:49:05.706044 15504 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1004 21:49:07.980285 15504 solver.cpp:218] Iteration 600 (43.6859 iter/s, 2.28907s/100 iters), loss = 1.30521
I1004 21:49:07.980285 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1004 21:49:07.980285 15504 solver.cpp:237]     Train net output #1: loss = 1.30521 (* 1 = 1.30521 loss)
I1004 21:49:07.980285 15504 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1004 21:49:10.262326 15504 solver.cpp:218] Iteration 700 (43.9587 iter/s, 2.27486s/100 iters), loss = 1.45845
I1004 21:49:10.262326 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1004 21:49:10.262326 15504 solver.cpp:237]     Train net output #1: loss = 1.45845 (* 1 = 1.45845 loss)
I1004 21:49:10.262326 15504 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1004 21:49:12.534554 15504 solver.cpp:218] Iteration 800 (44.0321 iter/s, 2.27107s/100 iters), loss = 1.21919
I1004 21:49:12.534554 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1004 21:49:12.534554 15504 solver.cpp:237]     Train net output #1: loss = 1.21919 (* 1 = 1.21919 loss)
I1004 21:49:12.534554 15504 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1004 21:49:14.808373 15504 solver.cpp:218] Iteration 900 (44.0891 iter/s, 2.26814s/100 iters), loss = 1.18948
I1004 21:49:14.808373 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1004 21:49:14.808373 15504 solver.cpp:237]     Train net output #1: loss = 1.18948 (* 1 = 1.18948 loss)
I1004 21:49:14.808373 15504 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1004 21:49:16.981050 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:49:17.059176 15504 solver.cpp:330] Iteration 1000, Testing net (#0)
I1004 21:49:17.059176 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:49:17.481060  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:49:17.496685 15504 solver.cpp:397]     Test net output #0: accuracy = 0.5771
I1004 21:49:17.496685 15504 solver.cpp:397]     Test net output #1: loss = 1.18077 (* 1 = 1.18077 loss)
I1004 21:49:17.527935 15504 solver.cpp:218] Iteration 1000 (36.7725 iter/s, 2.71943s/100 iters), loss = 1.32241
I1004 21:49:17.527935 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1004 21:49:17.527935 15504 solver.cpp:237]     Train net output #1: loss = 1.32241 (* 1 = 1.32241 loss)
I1004 21:49:17.527935 15504 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1004 21:49:19.808984 15504 solver.cpp:218] Iteration 1100 (43.8381 iter/s, 2.28112s/100 iters), loss = 1.18192
I1004 21:49:19.808984 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1004 21:49:19.808984 15504 solver.cpp:237]     Train net output #1: loss = 1.18192 (* 1 = 1.18192 loss)
I1004 21:49:19.808984 15504 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1004 21:49:22.075152 15504 solver.cpp:218] Iteration 1200 (43.918 iter/s, 2.27697s/100 iters), loss = 1.28298
I1004 21:49:22.075152 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1004 21:49:22.075152 15504 solver.cpp:237]     Train net output #1: loss = 1.28298 (* 1 = 1.28298 loss)
I1004 21:49:22.075152 15504 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1004 21:49:24.395673 15504 solver.cpp:218] Iteration 1300 (43.3133 iter/s, 2.30876s/100 iters), loss = 1.12316
I1004 21:49:24.395673 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1004 21:49:24.395673 15504 solver.cpp:237]     Train net output #1: loss = 1.12316 (* 1 = 1.12316 loss)
I1004 21:49:24.395673 15504 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1004 21:49:26.668440 15504 solver.cpp:218] Iteration 1400 (43.9464 iter/s, 2.2755s/100 iters), loss = 1.0811
I1004 21:49:26.668440 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1004 21:49:26.668440 15504 solver.cpp:237]     Train net output #1: loss = 1.0811 (* 1 = 1.0811 loss)
I1004 21:49:26.668440 15504 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1004 21:49:28.840361 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:49:28.949326 15504 solver.cpp:218] Iteration 1500 (43.8481 iter/s, 2.2806s/100 iters), loss = 1.16016
I1004 21:49:28.949326 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1004 21:49:28.949326 15504 solver.cpp:237]     Train net output #1: loss = 1.16016 (* 1 = 1.16016 loss)
I1004 21:49:28.949326 15504 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1004 21:49:31.230723 15504 solver.cpp:218] Iteration 1600 (43.7904 iter/s, 2.28361s/100 iters), loss = 1.01154
I1004 21:49:31.230723 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1004 21:49:31.230723 15504 solver.cpp:237]     Train net output #1: loss = 1.01154 (* 1 = 1.01154 loss)
I1004 21:49:31.230723 15504 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1004 21:49:33.512024 15504 solver.cpp:218] Iteration 1700 (43.8217 iter/s, 2.28197s/100 iters), loss = 1.09867
I1004 21:49:33.512024 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1004 21:49:33.512024 15504 solver.cpp:237]     Train net output #1: loss = 1.09867 (* 1 = 1.09867 loss)
I1004 21:49:33.512024 15504 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1004 21:49:35.798691 15504 solver.cpp:218] Iteration 1800 (43.7252 iter/s, 2.28701s/100 iters), loss = 0.953154
I1004 21:49:35.798691 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1004 21:49:35.798691 15504 solver.cpp:237]     Train net output #1: loss = 0.953154 (* 1 = 0.953154 loss)
I1004 21:49:35.798691 15504 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1004 21:49:38.074466 15504 solver.cpp:218] Iteration 1900 (43.9717 iter/s, 2.27419s/100 iters), loss = 0.916135
I1004 21:49:38.074466 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1004 21:49:38.074466 15504 solver.cpp:237]     Train net output #1: loss = 0.916135 (* 1 = 0.916135 loss)
I1004 21:49:38.074466 15504 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1004 21:49:40.246186 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:49:40.339936 15504 solver.cpp:330] Iteration 2000, Testing net (#0)
I1004 21:49:40.339936 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:49:40.761422  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:49:40.777050 15504 solver.cpp:397]     Test net output #0: accuracy = 0.6123
I1004 21:49:40.777050 15504 solver.cpp:397]     Test net output #1: loss = 1.09166 (* 1 = 1.09166 loss)
I1004 21:49:40.808295 15504 solver.cpp:218] Iteration 2000 (36.6358 iter/s, 2.72957s/100 iters), loss = 1.14832
I1004 21:49:40.808295 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1004 21:49:40.808295 15504 solver.cpp:237]     Train net output #1: loss = 1.14832 (* 1 = 1.14832 loss)
I1004 21:49:40.808295 15504 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1004 21:49:43.090133 15504 solver.cpp:218] Iteration 2100 (43.6969 iter/s, 2.28849s/100 iters), loss = 0.963357
I1004 21:49:43.090133 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1004 21:49:43.090133 15504 solver.cpp:237]     Train net output #1: loss = 0.963357 (* 1 = 0.963357 loss)
I1004 21:49:43.090133 15504 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1004 21:49:45.386976 15504 solver.cpp:218] Iteration 2200 (43.7238 iter/s, 2.28709s/100 iters), loss = 0.950861
I1004 21:49:45.386976 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1004 21:49:45.386976 15504 solver.cpp:237]     Train net output #1: loss = 0.950861 (* 1 = 0.950861 loss)
I1004 21:49:45.386976 15504 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1004 21:49:47.684281 15504 solver.cpp:218] Iteration 2300 (43.5339 iter/s, 2.29706s/100 iters), loss = 0.89908
I1004 21:49:47.684281 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1004 21:49:47.684281 15504 solver.cpp:237]     Train net output #1: loss = 0.89908 (* 1 = 0.89908 loss)
I1004 21:49:47.684281 15504 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1004 21:49:49.997017 15504 solver.cpp:218] Iteration 2400 (43.2563 iter/s, 2.3118s/100 iters), loss = 0.798668
I1004 21:49:49.997017 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1004 21:49:49.997017 15504 solver.cpp:237]     Train net output #1: loss = 0.798668 (* 1 = 0.798668 loss)
I1004 21:49:49.997017 15504 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1004 21:49:52.183985 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:49:52.308986 15504 solver.cpp:218] Iteration 2500 (43.1592 iter/s, 2.317s/100 iters), loss = 0.958348
I1004 21:49:52.308986 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1004 21:49:52.308986 15504 solver.cpp:237]     Train net output #1: loss = 0.958348 (* 1 = 0.958348 loss)
I1004 21:49:52.308986 15504 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1004 21:49:54.605849 15504 solver.cpp:218] Iteration 2600 (43.5198 iter/s, 2.2978s/100 iters), loss = 0.884854
I1004 21:49:54.605849 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1004 21:49:54.605849 15504 solver.cpp:237]     Train net output #1: loss = 0.884854 (* 1 = 0.884854 loss)
I1004 21:49:54.605849 15504 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1004 21:49:56.873914 15504 solver.cpp:218] Iteration 2700 (44.1029 iter/s, 2.26743s/100 iters), loss = 0.992494
I1004 21:49:56.873914 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1004 21:49:56.873914 15504 solver.cpp:237]     Train net output #1: loss = 0.992494 (* 1 = 0.992494 loss)
I1004 21:49:56.873914 15504 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1004 21:49:59.149739 15504 solver.cpp:218] Iteration 2800 (43.9138 iter/s, 2.27719s/100 iters), loss = 0.873076
I1004 21:49:59.149739 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1004 21:49:59.149739 15504 solver.cpp:237]     Train net output #1: loss = 0.873076 (* 1 = 0.873076 loss)
I1004 21:49:59.149739 15504 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1004 21:50:01.480545 15504 solver.cpp:218] Iteration 2900 (42.8105 iter/s, 2.33587s/100 iters), loss = 0.749932
I1004 21:50:01.480545 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1004 21:50:01.480545 15504 solver.cpp:237]     Train net output #1: loss = 0.749932 (* 1 = 0.749932 loss)
I1004 21:50:01.480545 15504 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1004 21:50:03.652237 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:50:03.750557 15504 solver.cpp:330] Iteration 3000, Testing net (#0)
I1004 21:50:03.750557 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:50:04.167845  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:50:04.183470 15504 solver.cpp:397]     Test net output #0: accuracy = 0.6684
I1004 21:50:04.183470 15504 solver.cpp:397]     Test net output #1: loss = 0.972631 (* 1 = 0.972631 loss)
I1004 21:50:04.199095 15504 solver.cpp:218] Iteration 3000 (36.8251 iter/s, 2.71554s/100 iters), loss = 0.918803
I1004 21:50:04.199095 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1004 21:50:04.199095 15504 solver.cpp:237]     Train net output #1: loss = 0.918803 (* 1 = 0.918803 loss)
I1004 21:50:04.199095 15504 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1004 21:50:06.496789 15504 solver.cpp:218] Iteration 3100 (43.7545 iter/s, 2.28548s/100 iters), loss = 0.854236
I1004 21:50:06.496789 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1004 21:50:06.496789 15504 solver.cpp:237]     Train net output #1: loss = 0.854236 (* 1 = 0.854236 loss)
I1004 21:50:06.496789 15504 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1004 21:50:08.803568 15504 solver.cpp:218] Iteration 3200 (43.1871 iter/s, 2.3155s/100 iters), loss = 0.912981
I1004 21:50:08.803568 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1004 21:50:08.803568 15504 solver.cpp:237]     Train net output #1: loss = 0.912981 (* 1 = 0.912981 loss)
I1004 21:50:08.803568 15504 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1004 21:50:11.092355 15504 solver.cpp:218] Iteration 3300 (43.8139 iter/s, 2.28238s/100 iters), loss = 0.798309
I1004 21:50:11.092355 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1004 21:50:11.092355 15504 solver.cpp:237]     Train net output #1: loss = 0.798309 (* 1 = 0.798309 loss)
I1004 21:50:11.092355 15504 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1004 21:50:13.390182 15504 solver.cpp:218] Iteration 3400 (43.5435 iter/s, 2.29656s/100 iters), loss = 0.700729
I1004 21:50:13.390182 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1004 21:50:13.390182 15504 solver.cpp:237]     Train net output #1: loss = 0.700729 (* 1 = 0.700729 loss)
I1004 21:50:13.390182 15504 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1004 21:50:15.549118 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:50:15.658493 15504 solver.cpp:218] Iteration 3500 (43.8749 iter/s, 2.27921s/100 iters), loss = 0.862749
I1004 21:50:15.658493 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1004 21:50:15.658493 15504 solver.cpp:237]     Train net output #1: loss = 0.862749 (* 1 = 0.862749 loss)
I1004 21:50:15.658493 15504 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1004 21:50:17.957258 15504 solver.cpp:218] Iteration 3600 (43.6953 iter/s, 2.28857s/100 iters), loss = 0.664849
I1004 21:50:17.957258 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:50:17.957258 15504 solver.cpp:237]     Train net output #1: loss = 0.664849 (* 1 = 0.664849 loss)
I1004 21:50:17.957258 15504 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1004 21:50:20.240226 15504 solver.cpp:218] Iteration 3700 (43.8153 iter/s, 2.28231s/100 iters), loss = 0.761482
I1004 21:50:20.240226 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1004 21:50:20.240226 15504 solver.cpp:237]     Train net output #1: loss = 0.761482 (* 1 = 0.761482 loss)
I1004 21:50:20.240226 15504 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1004 21:50:22.527578 15504 solver.cpp:218] Iteration 3800 (43.678 iter/s, 2.28948s/100 iters), loss = 0.762814
I1004 21:50:22.527578 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:50:22.527578 15504 solver.cpp:237]     Train net output #1: loss = 0.762814 (* 1 = 0.762814 loss)
I1004 21:50:22.527578 15504 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1004 21:50:24.805249 15504 solver.cpp:218] Iteration 3900 (43.899 iter/s, 2.27796s/100 iters), loss = 0.645391
I1004 21:50:24.805249 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 21:50:24.805249 15504 solver.cpp:237]     Train net output #1: loss = 0.645391 (* 1 = 0.645391 loss)
I1004 21:50:24.805249 15504 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1004 21:50:26.964563 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:50:27.058313 15504 solver.cpp:330] Iteration 4000, Testing net (#0)
I1004 21:50:27.058313 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:50:27.480644  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:50:27.496268 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7155
I1004 21:50:27.496268 15504 solver.cpp:397]     Test net output #1: loss = 0.823127 (* 1 = 0.823127 loss)
I1004 21:50:27.511893 15504 solver.cpp:218] Iteration 4000 (36.8411 iter/s, 2.71436s/100 iters), loss = 0.730829
I1004 21:50:27.511893 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1004 21:50:27.511893 15504 solver.cpp:237]     Train net output #1: loss = 0.730829 (* 1 = 0.730829 loss)
I1004 21:50:27.511893 15504 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1004 21:50:29.800151 15504 solver.cpp:218] Iteration 4100 (43.803 iter/s, 2.28295s/100 iters), loss = 0.680186
I1004 21:50:29.800151 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 21:50:29.800151 15504 solver.cpp:237]     Train net output #1: loss = 0.680186 (* 1 = 0.680186 loss)
I1004 21:50:29.800151 15504 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1004 21:50:32.091274 15504 solver.cpp:218] Iteration 4200 (43.6273 iter/s, 2.29214s/100 iters), loss = 0.733757
I1004 21:50:32.091274 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1004 21:50:32.091274 15504 solver.cpp:237]     Train net output #1: loss = 0.733757 (* 1 = 0.733757 loss)
I1004 21:50:32.091274 15504 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1004 21:50:34.376056 15504 solver.cpp:218] Iteration 4300 (43.7969 iter/s, 2.28327s/100 iters), loss = 0.698495
I1004 21:50:34.376056 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:50:34.376056 15504 solver.cpp:237]     Train net output #1: loss = 0.698495 (* 1 = 0.698495 loss)
I1004 21:50:34.376056 15504 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1004 21:50:36.652529 15504 solver.cpp:218] Iteration 4400 (43.8219 iter/s, 2.28197s/100 iters), loss = 0.626796
I1004 21:50:36.652529 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:50:36.652529 15504 solver.cpp:237]     Train net output #1: loss = 0.626796 (* 1 = 0.626796 loss)
I1004 21:50:36.652529 15504 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1004 21:50:38.823508 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:50:38.946414 15504 solver.cpp:218] Iteration 4500 (43.8739 iter/s, 2.27926s/100 iters), loss = 0.756872
I1004 21:50:38.946414 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1004 21:50:38.946414 15504 solver.cpp:237]     Train net output #1: loss = 0.756872 (* 1 = 0.756872 loss)
I1004 21:50:38.946414 15504 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1004 21:50:41.223053 15504 solver.cpp:218] Iteration 4600 (43.832 iter/s, 2.28144s/100 iters), loss = 0.700688
I1004 21:50:41.223053 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1004 21:50:41.223053 15504 solver.cpp:237]     Train net output #1: loss = 0.700688 (* 1 = 0.700688 loss)
I1004 21:50:41.223053 15504 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1004 21:50:43.496183 15504 solver.cpp:218] Iteration 4700 (43.8309 iter/s, 2.28149s/100 iters), loss = 0.637955
I1004 21:50:43.496183 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:50:43.496183 15504 solver.cpp:237]     Train net output #1: loss = 0.637955 (* 1 = 0.637955 loss)
I1004 21:50:43.496183 15504 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1004 21:50:45.778375 15504 solver.cpp:218] Iteration 4800 (44.0827 iter/s, 2.26846s/100 iters), loss = 0.720201
I1004 21:50:45.778375 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:50:45.778375 15504 solver.cpp:237]     Train net output #1: loss = 0.720201 (* 1 = 0.720201 loss)
I1004 21:50:45.778375 15504 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1004 21:50:48.052896 15504 solver.cpp:218] Iteration 4900 (43.8333 iter/s, 2.28137s/100 iters), loss = 0.502785
I1004 21:50:48.052896 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:50:48.052896 15504 solver.cpp:237]     Train net output #1: loss = 0.502785 (* 1 = 0.502785 loss)
I1004 21:50:48.052896 15504 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1004 21:50:50.231967 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:50:50.310093 15504 solver.cpp:330] Iteration 5000, Testing net (#0)
I1004 21:50:50.310093 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:50:50.746249  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:50:50.761873 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7091
I1004 21:50:50.761873 15504 solver.cpp:397]     Test net output #1: loss = 0.862095 (* 1 = 0.862095 loss)
I1004 21:50:50.793123 15504 solver.cpp:218] Iteration 5000 (36.5554 iter/s, 2.73557s/100 iters), loss = 0.664509
I1004 21:50:50.793123 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1004 21:50:50.793123 15504 solver.cpp:237]     Train net output #1: loss = 0.664509 (* 1 = 0.664509 loss)
I1004 21:50:50.793123 15504 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I1004 21:50:50.793123 15504 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I1004 21:50:53.074461 15504 solver.cpp:218] Iteration 5100 (43.7454 iter/s, 2.28595s/100 iters), loss = 0.561578
I1004 21:50:53.074461 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:50:53.074461 15504 solver.cpp:237]     Train net output #1: loss = 0.561578 (* 1 = 0.561578 loss)
I1004 21:50:53.074461 15504 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I1004 21:50:55.370715 15504 solver.cpp:218] Iteration 5200 (43.6838 iter/s, 2.28918s/100 iters), loss = 0.63612
I1004 21:50:55.370715 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:50:55.370715 15504 solver.cpp:237]     Train net output #1: loss = 0.63612 (* 1 = 0.63612 loss)
I1004 21:50:55.370715 15504 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I1004 21:50:57.652555 15504 solver.cpp:218] Iteration 5300 (43.6087 iter/s, 2.29312s/100 iters), loss = 0.62393
I1004 21:50:57.652555 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:50:57.652555 15504 solver.cpp:237]     Train net output #1: loss = 0.62393 (* 1 = 0.62393 loss)
I1004 21:50:57.652555 15504 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I1004 21:50:59.949854 15504 solver.cpp:218] Iteration 5400 (43.5674 iter/s, 2.29529s/100 iters), loss = 0.499557
I1004 21:50:59.949854 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:50:59.949854 15504 solver.cpp:237]     Train net output #1: loss = 0.499557 (* 1 = 0.499557 loss)
I1004 21:50:59.949854 15504 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I1004 21:51:02.137188 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:51:02.246563 15504 solver.cpp:218] Iteration 5500 (43.7513 iter/s, 2.28565s/100 iters), loss = 0.542481
I1004 21:51:02.246563 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:51:02.246563 15504 solver.cpp:237]     Train net output #1: loss = 0.542481 (* 1 = 0.542481 loss)
I1004 21:51:02.246563 15504 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I1004 21:51:04.543350 15504 solver.cpp:218] Iteration 5600 (43.4671 iter/s, 2.30059s/100 iters), loss = 0.513445
I1004 21:51:04.543350 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:51:04.543350 15504 solver.cpp:237]     Train net output #1: loss = 0.513445 (* 1 = 0.513445 loss)
I1004 21:51:04.543350 15504 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I1004 21:51:06.817296 15504 solver.cpp:218] Iteration 5700 (43.9267 iter/s, 2.27652s/100 iters), loss = 0.607498
I1004 21:51:06.817296 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1004 21:51:06.817296 15504 solver.cpp:237]     Train net output #1: loss = 0.607498 (* 1 = 0.607498 loss)
I1004 21:51:06.817296 15504 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I1004 21:51:09.105765 15504 solver.cpp:218] Iteration 5800 (43.8125 iter/s, 2.28246s/100 iters), loss = 0.638173
I1004 21:51:09.105765 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:51:09.105765 15504 solver.cpp:237]     Train net output #1: loss = 0.638173 (* 1 = 0.638173 loss)
I1004 21:51:09.105765 15504 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I1004 21:51:11.387058 15504 solver.cpp:218] Iteration 5900 (43.7122 iter/s, 2.28769s/100 iters), loss = 0.600545
I1004 21:51:11.387058 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:51:11.387058 15504 solver.cpp:237]     Train net output #1: loss = 0.600545 (* 1 = 0.600545 loss)
I1004 21:51:11.387058 15504 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I1004 21:51:13.558876 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:51:13.652626 15504 solver.cpp:330] Iteration 6000, Testing net (#0)
I1004 21:51:13.652626 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:51:14.074138  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:51:14.089763 15504 solver.cpp:397]     Test net output #0: accuracy = 0.762
I1004 21:51:14.089763 15504 solver.cpp:397]     Test net output #1: loss = 0.682598 (* 1 = 0.682598 loss)
I1004 21:51:14.105391 15504 solver.cpp:218] Iteration 6000 (36.8336 iter/s, 2.71491s/100 iters), loss = 0.559913
I1004 21:51:14.105391 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:51:14.105391 15504 solver.cpp:237]     Train net output #1: loss = 0.559913 (* 1 = 0.559913 loss)
I1004 21:51:14.105391 15504 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I1004 21:51:16.385167 15504 solver.cpp:218] Iteration 6100 (43.7222 iter/s, 2.28717s/100 iters), loss = 0.51558
I1004 21:51:16.385167 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:51:16.385167 15504 solver.cpp:237]     Train net output #1: loss = 0.51558 (* 1 = 0.51558 loss)
I1004 21:51:16.385167 15504 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I1004 21:51:18.696750 15504 solver.cpp:218] Iteration 6200 (43.3171 iter/s, 2.30856s/100 iters), loss = 0.580476
I1004 21:51:18.696750 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:51:18.696750 15504 solver.cpp:237]     Train net output #1: loss = 0.580476 (* 1 = 0.580476 loss)
I1004 21:51:18.696750 15504 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I1004 21:51:20.996047 15504 solver.cpp:218] Iteration 6300 (43.7066 iter/s, 2.28798s/100 iters), loss = 0.608205
I1004 21:51:20.996047 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:51:20.996047 15504 solver.cpp:237]     Train net output #1: loss = 0.608205 (* 1 = 0.608205 loss)
I1004 21:51:20.996047 15504 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I1004 21:51:23.280161 15504 solver.cpp:218] Iteration 6400 (43.6599 iter/s, 2.29043s/100 iters), loss = 0.476422
I1004 21:51:23.280161 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:51:23.280161 15504 solver.cpp:237]     Train net output #1: loss = 0.476422 (* 1 = 0.476422 loss)
I1004 21:51:23.280161 15504 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I1004 21:51:25.464987 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:51:25.574362 15504 solver.cpp:218] Iteration 6500 (43.6373 iter/s, 2.29162s/100 iters), loss = 0.523399
I1004 21:51:25.574362 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:51:25.574362 15504 solver.cpp:237]     Train net output #1: loss = 0.523399 (* 1 = 0.523399 loss)
I1004 21:51:25.574362 15504 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I1004 21:51:27.849315 15504 solver.cpp:218] Iteration 6600 (43.9314 iter/s, 2.27628s/100 iters), loss = 0.515904
I1004 21:51:27.849315 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:51:27.849315 15504 solver.cpp:237]     Train net output #1: loss = 0.515904 (* 1 = 0.515904 loss)
I1004 21:51:27.849315 15504 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I1004 21:51:30.130209 15504 solver.cpp:218] Iteration 6700 (43.8577 iter/s, 2.2801s/100 iters), loss = 0.567614
I1004 21:51:30.130209 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:51:30.130209 15504 solver.cpp:237]     Train net output #1: loss = 0.567614 (* 1 = 0.567614 loss)
I1004 21:51:30.130209 15504 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I1004 21:51:32.434412 15504 solver.cpp:218] Iteration 6800 (43.5086 iter/s, 2.2984s/100 iters), loss = 0.643298
I1004 21:51:32.434412 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1004 21:51:32.434412 15504 solver.cpp:237]     Train net output #1: loss = 0.643298 (* 1 = 0.643298 loss)
I1004 21:51:32.434412 15504 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I1004 21:51:34.715677 15504 solver.cpp:218] Iteration 6900 (43.6932 iter/s, 2.28869s/100 iters), loss = 0.46459
I1004 21:51:34.715677 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:51:34.715677 15504 solver.cpp:237]     Train net output #1: loss = 0.46459 (* 1 = 0.46459 loss)
I1004 21:51:34.715677 15504 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I1004 21:51:36.889012 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:51:36.980440 15504 solver.cpp:330] Iteration 7000, Testing net (#0)
I1004 21:51:36.980440 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:51:37.404130  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:51:37.426923 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7658
I1004 21:51:37.426923 15504 solver.cpp:397]     Test net output #1: loss = 0.680723 (* 1 = 0.680723 loss)
I1004 21:51:37.434056 15504 solver.cpp:218] Iteration 7000 (36.6907 iter/s, 2.72548s/100 iters), loss = 0.492445
I1004 21:51:37.434056 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:51:37.434056 15504 solver.cpp:237]     Train net output #1: loss = 0.492445 (* 1 = 0.492445 loss)
I1004 21:51:37.434056 15504 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I1004 21:51:39.730772 15504 solver.cpp:218] Iteration 7100 (43.7868 iter/s, 2.28379s/100 iters), loss = 0.544834
I1004 21:51:39.730772 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:51:39.730772 15504 solver.cpp:237]     Train net output #1: loss = 0.544834 (* 1 = 0.544834 loss)
I1004 21:51:39.730772 15504 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I1004 21:51:42.012223 15504 solver.cpp:218] Iteration 7200 (43.6086 iter/s, 2.29313s/100 iters), loss = 0.571462
I1004 21:51:42.012223 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:51:42.012223 15504 solver.cpp:237]     Train net output #1: loss = 0.571462 (* 1 = 0.571462 loss)
I1004 21:51:42.012223 15504 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I1004 21:51:44.338079 15504 solver.cpp:218] Iteration 7300 (43.2823 iter/s, 2.31041s/100 iters), loss = 0.597692
I1004 21:51:44.338079 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:51:44.338079 15504 solver.cpp:237]     Train net output #1: loss = 0.597692 (* 1 = 0.597692 loss)
I1004 21:51:44.338079 15504 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I1004 21:51:46.637044 15504 solver.cpp:218] Iteration 7400 (43.3857 iter/s, 2.30491s/100 iters), loss = 0.548608
I1004 21:51:46.637044 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:51:46.637044 15504 solver.cpp:237]     Train net output #1: loss = 0.548608 (* 1 = 0.548608 loss)
I1004 21:51:46.637044 15504 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I1004 21:51:48.803771 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:51:48.921285 15504 solver.cpp:218] Iteration 7500 (43.9021 iter/s, 2.2778s/100 iters), loss = 0.551339
I1004 21:51:48.921285 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:51:48.921285 15504 solver.cpp:237]     Train net output #1: loss = 0.551339 (* 1 = 0.551339 loss)
I1004 21:51:48.921285 15504 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I1004 21:51:51.231004 15504 solver.cpp:218] Iteration 7600 (43.2789 iter/s, 2.31059s/100 iters), loss = 0.493379
I1004 21:51:51.231004 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:51:51.231004 15504 solver.cpp:237]     Train net output #1: loss = 0.493379 (* 1 = 0.493379 loss)
I1004 21:51:51.231004 15504 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I1004 21:51:53.527940 15504 solver.cpp:218] Iteration 7700 (43.5329 iter/s, 2.29711s/100 iters), loss = 0.491985
I1004 21:51:53.527940 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:51:53.527940 15504 solver.cpp:237]     Train net output #1: loss = 0.491985 (* 1 = 0.491985 loss)
I1004 21:51:53.527940 15504 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I1004 21:51:55.831044 15504 solver.cpp:218] Iteration 7800 (43.3612 iter/s, 2.30621s/100 iters), loss = 0.650239
I1004 21:51:55.831044 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:51:55.831044 15504 solver.cpp:237]     Train net output #1: loss = 0.650239 (* 1 = 0.650239 loss)
I1004 21:51:55.831044 15504 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I1004 21:51:58.152817 15504 solver.cpp:218] Iteration 7900 (42.888 iter/s, 2.33165s/100 iters), loss = 0.492314
I1004 21:51:58.168433 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:51:58.168433 15504 solver.cpp:237]     Train net output #1: loss = 0.492314 (* 1 = 0.492314 loss)
I1004 21:51:58.168433 15504 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I1004 21:52:00.367118 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:52:00.449959 15504 solver.cpp:330] Iteration 8000, Testing net (#0)
I1004 21:52:00.449959 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:52:00.858395  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:52:00.874022 15504 solver.cpp:397]     Test net output #0: accuracy = 0.765
I1004 21:52:00.874022 15504 solver.cpp:397]     Test net output #1: loss = 0.676395 (* 1 = 0.676395 loss)
I1004 21:52:00.905272 15504 solver.cpp:218] Iteration 8000 (36.5048 iter/s, 2.73936s/100 iters), loss = 0.538423
I1004 21:52:00.905272 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:52:00.905272 15504 solver.cpp:237]     Train net output #1: loss = 0.538423 (* 1 = 0.538423 loss)
I1004 21:52:00.905272 15504 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I1004 21:52:03.183620 15504 solver.cpp:218] Iteration 8100 (43.7996 iter/s, 2.28312s/100 iters), loss = 0.440649
I1004 21:52:03.183620 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:52:03.183620 15504 solver.cpp:237]     Train net output #1: loss = 0.440649 (* 1 = 0.440649 loss)
I1004 21:52:03.183620 15504 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I1004 21:52:05.484202 15504 solver.cpp:218] Iteration 8200 (43.4514 iter/s, 2.30142s/100 iters), loss = 0.563088
I1004 21:52:05.484202 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:52:05.484202 15504 solver.cpp:237]     Train net output #1: loss = 0.563088 (* 1 = 0.563088 loss)
I1004 21:52:05.484202 15504 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I1004 21:52:07.760735 15504 solver.cpp:218] Iteration 8300 (43.8298 iter/s, 2.28155s/100 iters), loss = 0.601963
I1004 21:52:07.760735 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:52:07.760735 15504 solver.cpp:237]     Train net output #1: loss = 0.601963 (* 1 = 0.601963 loss)
I1004 21:52:07.760735 15504 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I1004 21:52:10.043786 15504 solver.cpp:218] Iteration 8400 (43.9513 iter/s, 2.27524s/100 iters), loss = 0.446658
I1004 21:52:10.043786 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:52:10.043786 15504 solver.cpp:237]     Train net output #1: loss = 0.446658 (* 1 = 0.446658 loss)
I1004 21:52:10.043786 15504 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I1004 21:52:12.216302 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:52:12.323711 15504 solver.cpp:218] Iteration 8500 (43.8234 iter/s, 2.28189s/100 iters), loss = 0.566119
I1004 21:52:12.323711 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:52:12.323711 15504 solver.cpp:237]     Train net output #1: loss = 0.566119 (* 1 = 0.566119 loss)
I1004 21:52:12.323711 15504 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I1004 21:52:14.613205 15504 solver.cpp:218] Iteration 8600 (43.8535 iter/s, 2.28032s/100 iters), loss = 0.46821
I1004 21:52:14.613205 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:52:14.613205 15504 solver.cpp:237]     Train net output #1: loss = 0.46821 (* 1 = 0.46821 loss)
I1004 21:52:14.613205 15504 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I1004 21:52:16.899600 15504 solver.cpp:218] Iteration 8700 (43.7481 iter/s, 2.28581s/100 iters), loss = 0.525187
I1004 21:52:16.899600 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:52:16.899600 15504 solver.cpp:237]     Train net output #1: loss = 0.525187 (* 1 = 0.525187 loss)
I1004 21:52:16.899600 15504 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I1004 21:52:19.205420 15504 solver.cpp:218] Iteration 8800 (43.3726 iter/s, 2.3056s/100 iters), loss = 0.600921
I1004 21:52:19.205420 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:52:19.205420 15504 solver.cpp:237]     Train net output #1: loss = 0.600921 (* 1 = 0.600921 loss)
I1004 21:52:19.205420 15504 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I1004 21:52:21.504709 15504 solver.cpp:218] Iteration 8900 (43.4874 iter/s, 2.29952s/100 iters), loss = 0.548155
I1004 21:52:21.504709 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:52:21.504709 15504 solver.cpp:237]     Train net output #1: loss = 0.548155 (* 1 = 0.548155 loss)
I1004 21:52:21.504709 15504 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I1004 21:52:23.689604 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:52:23.769695 15504 solver.cpp:330] Iteration 9000, Testing net (#0)
I1004 21:52:23.769695 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:52:24.198168  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:52:24.214082 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7691
I1004 21:52:24.214082 15504 solver.cpp:397]     Test net output #1: loss = 0.675911 (* 1 = 0.675911 loss)
I1004 21:52:24.235085 15504 solver.cpp:218] Iteration 9000 (36.6305 iter/s, 2.72996s/100 iters), loss = 0.590428
I1004 21:52:24.235085 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:52:24.235085 15504 solver.cpp:237]     Train net output #1: loss = 0.590428 (* 1 = 0.590428 loss)
I1004 21:52:24.235085 15504 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I1004 21:52:26.512379 15504 solver.cpp:218] Iteration 9100 (43.7566 iter/s, 2.28537s/100 iters), loss = 0.514956
I1004 21:52:26.512379 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:52:26.512379 15504 solver.cpp:237]     Train net output #1: loss = 0.514956 (* 1 = 0.514956 loss)
I1004 21:52:26.512379 15504 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I1004 21:52:28.799371 15504 solver.cpp:218] Iteration 9200 (43.9033 iter/s, 2.27774s/100 iters), loss = 0.514459
I1004 21:52:28.799371 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:52:28.799371 15504 solver.cpp:237]     Train net output #1: loss = 0.514459 (* 1 = 0.514459 loss)
I1004 21:52:28.799371 15504 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I1004 21:52:31.074893 15504 solver.cpp:218] Iteration 9300 (43.8391 iter/s, 2.28107s/100 iters), loss = 0.571752
I1004 21:52:31.074893 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:52:31.074893 15504 solver.cpp:237]     Train net output #1: loss = 0.571752 (* 1 = 0.571752 loss)
I1004 21:52:31.074893 15504 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I1004 21:52:33.349319 15504 solver.cpp:218] Iteration 9400 (43.8079 iter/s, 2.28269s/100 iters), loss = 0.518921
I1004 21:52:33.349319 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:52:33.349319 15504 solver.cpp:237]     Train net output #1: loss = 0.518921 (* 1 = 0.518921 loss)
I1004 21:52:33.349319 15504 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I1004 21:52:35.533346 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:52:35.642719 15504 solver.cpp:218] Iteration 9500 (43.6089 iter/s, 2.29311s/100 iters), loss = 0.564531
I1004 21:52:35.642719 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:52:35.642719 15504 solver.cpp:237]     Train net output #1: loss = 0.564531 (* 1 = 0.564531 loss)
I1004 21:52:35.642719 15504 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1004 21:52:37.934463 15504 solver.cpp:218] Iteration 9600 (43.7749 iter/s, 2.28441s/100 iters), loss = 0.486334
I1004 21:52:37.934463 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:52:37.934463 15504 solver.cpp:237]     Train net output #1: loss = 0.486334 (* 1 = 0.486334 loss)
I1004 21:52:37.934463 15504 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1004 21:52:40.216150 15504 solver.cpp:218] Iteration 9700 (43.9313 iter/s, 2.27628s/100 iters), loss = 0.50088
I1004 21:52:40.216150 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:52:40.216150 15504 solver.cpp:237]     Train net output #1: loss = 0.50088 (* 1 = 0.50088 loss)
I1004 21:52:40.216150 15504 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I1004 21:52:42.503911 15504 solver.cpp:218] Iteration 9800 (43.7049 iter/s, 2.28807s/100 iters), loss = 0.600802
I1004 21:52:42.503911 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:52:42.503911 15504 solver.cpp:237]     Train net output #1: loss = 0.600802 (* 1 = 0.600802 loss)
I1004 21:52:42.503911 15504 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1004 21:52:44.786118 15504 solver.cpp:218] Iteration 9900 (43.8307 iter/s, 2.28151s/100 iters), loss = 0.497569
I1004 21:52:44.786118 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:52:44.786118 15504 solver.cpp:237]     Train net output #1: loss = 0.497569 (* 1 = 0.497569 loss)
I1004 21:52:44.786118 15504 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I1004 21:52:46.965454 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:52:47.054184 15504 solver.cpp:330] Iteration 10000, Testing net (#0)
I1004 21:52:47.054184 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:52:47.464978  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:52:47.480604 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7678
I1004 21:52:47.480604 15504 solver.cpp:397]     Test net output #1: loss = 0.675581 (* 1 = 0.675581 loss)
I1004 21:52:47.511857 15504 solver.cpp:218] Iteration 10000 (36.6968 iter/s, 2.72504s/100 iters), loss = 0.444089
I1004 21:52:47.511857 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:52:47.511857 15504 solver.cpp:237]     Train net output #1: loss = 0.444089 (* 1 = 0.444089 loss)
I1004 21:52:47.511857 15504 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I1004 21:52:47.511857 15504 sgd_solver.cpp:105] Iteration 10000, lr = 0.0001
I1004 21:52:49.782960 15504 solver.cpp:218] Iteration 10100 (43.9087 iter/s, 2.27745s/100 iters), loss = 0.463918
I1004 21:52:49.782960 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:52:49.782960 15504 solver.cpp:237]     Train net output #1: loss = 0.463918 (* 1 = 0.463918 loss)
I1004 21:52:49.782960 15504 sgd_solver.cpp:105] Iteration 10100, lr = 0.0001
I1004 21:52:52.067113 15504 solver.cpp:218] Iteration 10200 (43.6831 iter/s, 2.28922s/100 iters), loss = 0.512811
I1004 21:52:52.067113 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:52:52.067113 15504 solver.cpp:237]     Train net output #1: loss = 0.512811 (* 1 = 0.512811 loss)
I1004 21:52:52.067113 15504 sgd_solver.cpp:105] Iteration 10200, lr = 0.0001
I1004 21:52:54.366237 15504 solver.cpp:218] Iteration 10300 (43.6794 iter/s, 2.28941s/100 iters), loss = 0.565887
I1004 21:52:54.366237 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:52:54.366237 15504 solver.cpp:237]     Train net output #1: loss = 0.565887 (* 1 = 0.565887 loss)
I1004 21:52:54.366237 15504 sgd_solver.cpp:105] Iteration 10300, lr = 0.0001
I1004 21:52:56.655553 15504 solver.cpp:218] Iteration 10400 (43.7088 iter/s, 2.28787s/100 iters), loss = 0.430961
I1004 21:52:56.655553 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1004 21:52:56.655553 15504 solver.cpp:237]     Train net output #1: loss = 0.430961 (* 1 = 0.430961 loss)
I1004 21:52:56.655553 15504 sgd_solver.cpp:105] Iteration 10400, lr = 0.0001
I1004 21:52:58.830346 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:52:58.942816 15504 solver.cpp:218] Iteration 10500 (43.8041 iter/s, 2.28289s/100 iters), loss = 0.487561
I1004 21:52:58.942816 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:52:58.942816 15504 solver.cpp:237]     Train net output #1: loss = 0.487561 (* 1 = 0.487561 loss)
I1004 21:52:58.942816 15504 sgd_solver.cpp:105] Iteration 10500, lr = 0.0001
I1004 21:53:01.228004 15504 solver.cpp:218] Iteration 10600 (43.7667 iter/s, 2.28484s/100 iters), loss = 0.477212
I1004 21:53:01.228004 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:53:01.228004 15504 solver.cpp:237]     Train net output #1: loss = 0.477212 (* 1 = 0.477212 loss)
I1004 21:53:01.228004 15504 sgd_solver.cpp:105] Iteration 10600, lr = 0.0001
I1004 21:53:03.527832 15504 solver.cpp:218] Iteration 10700 (43.4919 iter/s, 2.29928s/100 iters), loss = 0.498031
I1004 21:53:03.527832 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:53:03.527832 15504 solver.cpp:237]     Train net output #1: loss = 0.498031 (* 1 = 0.498031 loss)
I1004 21:53:03.527832 15504 sgd_solver.cpp:105] Iteration 10700, lr = 0.0001
I1004 21:53:05.816354 15504 solver.cpp:218] Iteration 10800 (43.539 iter/s, 2.29679s/100 iters), loss = 0.570097
I1004 21:53:05.816354 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:53:05.816354 15504 solver.cpp:237]     Train net output #1: loss = 0.570097 (* 1 = 0.570097 loss)
I1004 21:53:05.816354 15504 sgd_solver.cpp:105] Iteration 10800, lr = 0.0001
I1004 21:53:08.130146 15504 solver.cpp:218] Iteration 10900 (43.3802 iter/s, 2.3052s/100 iters), loss = 0.437628
I1004 21:53:08.130146 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:53:08.130146 15504 solver.cpp:237]     Train net output #1: loss = 0.437628 (* 1 = 0.437628 loss)
I1004 21:53:08.130146 15504 sgd_solver.cpp:105] Iteration 10900, lr = 0.0001
I1004 21:53:10.324169 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:53:10.414793 15504 solver.cpp:330] Iteration 11000, Testing net (#0)
I1004 21:53:10.414793 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:53:10.824496  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:53:10.846063 15504 solver.cpp:397]     Test net output #0: accuracy = 0.771
I1004 21:53:10.846063 15504 solver.cpp:397]     Test net output #1: loss = 0.665764 (* 1 = 0.665764 loss)
I1004 21:53:10.866061 15504 solver.cpp:218] Iteration 11000 (36.5464 iter/s, 2.73625s/100 iters), loss = 0.50336
I1004 21:53:10.867063 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:53:10.867063 15504 solver.cpp:237]     Train net output #1: loss = 0.50336 (* 1 = 0.50336 loss)
I1004 21:53:10.867063 15504 sgd_solver.cpp:105] Iteration 11000, lr = 0.0001
I1004 21:53:13.179195 15504 solver.cpp:218] Iteration 11100 (43.2394 iter/s, 2.31271s/100 iters), loss = 0.427356
I1004 21:53:13.179195 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:53:13.179195 15504 solver.cpp:237]     Train net output #1: loss = 0.427356 (* 1 = 0.427356 loss)
I1004 21:53:13.180197 15504 sgd_solver.cpp:105] Iteration 11100, lr = 0.0001
I1004 21:53:15.457227 15504 solver.cpp:218] Iteration 11200 (43.9092 iter/s, 2.27743s/100 iters), loss = 0.581125
I1004 21:53:15.457227 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:53:15.457227 15504 solver.cpp:237]     Train net output #1: loss = 0.581125 (* 1 = 0.581125 loss)
I1004 21:53:15.457227 15504 sgd_solver.cpp:105] Iteration 11200, lr = 0.0001
I1004 21:53:17.761176 15504 solver.cpp:218] Iteration 11300 (43.4093 iter/s, 2.30366s/100 iters), loss = 0.572478
I1004 21:53:17.761176 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:53:17.761176 15504 solver.cpp:237]     Train net output #1: loss = 0.572478 (* 1 = 0.572478 loss)
I1004 21:53:17.761176 15504 sgd_solver.cpp:105] Iteration 11300, lr = 0.0001
I1004 21:53:20.042589 15504 solver.cpp:218] Iteration 11400 (43.5679 iter/s, 2.29527s/100 iters), loss = 0.435284
I1004 21:53:20.042589 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:53:20.042589 15504 solver.cpp:237]     Train net output #1: loss = 0.435284 (* 1 = 0.435284 loss)
I1004 21:53:20.042589 15504 sgd_solver.cpp:105] Iteration 11400, lr = 0.0001
I1004 21:53:22.223220 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:53:22.332598 15504 solver.cpp:218] Iteration 11500 (43.8335 iter/s, 2.28136s/100 iters), loss = 0.527242
I1004 21:53:22.332598 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:53:22.332598 15504 solver.cpp:237]     Train net output #1: loss = 0.527242 (* 1 = 0.527242 loss)
I1004 21:53:22.332598 15504 sgd_solver.cpp:105] Iteration 11500, lr = 0.0001
I1004 21:53:24.617949 15504 solver.cpp:218] Iteration 11600 (43.7465 iter/s, 2.2859s/100 iters), loss = 0.378985
I1004 21:53:24.617949 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1004 21:53:24.617949 15504 solver.cpp:237]     Train net output #1: loss = 0.378985 (* 1 = 0.378985 loss)
I1004 21:53:24.617949 15504 sgd_solver.cpp:105] Iteration 11600, lr = 0.0001
I1004 21:53:26.909200 15504 solver.cpp:218] Iteration 11700 (43.7854 iter/s, 2.28387s/100 iters), loss = 0.469911
I1004 21:53:26.909200 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:53:26.909200 15504 solver.cpp:237]     Train net output #1: loss = 0.469911 (* 1 = 0.469911 loss)
I1004 21:53:26.909200 15504 sgd_solver.cpp:105] Iteration 11700, lr = 0.0001
I1004 21:53:29.189882 15504 solver.cpp:218] Iteration 11800 (43.7765 iter/s, 2.28433s/100 iters), loss = 0.546276
I1004 21:53:29.189882 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:53:29.189882 15504 solver.cpp:237]     Train net output #1: loss = 0.546276 (* 1 = 0.546276 loss)
I1004 21:53:29.189882 15504 sgd_solver.cpp:105] Iteration 11800, lr = 0.0001
I1004 21:53:31.467279 15504 solver.cpp:218] Iteration 11900 (43.781 iter/s, 2.2841s/100 iters), loss = 0.48028
I1004 21:53:31.467279 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:53:31.467279 15504 solver.cpp:237]     Train net output #1: loss = 0.48028 (* 1 = 0.48028 loss)
I1004 21:53:31.467279 15504 sgd_solver.cpp:105] Iteration 11900, lr = 0.0001
I1004 21:53:33.637256 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:53:33.731006 15504 solver.cpp:330] Iteration 12000, Testing net (#0)
I1004 21:53:33.731006 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:53:34.147584  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:53:34.163210 15504 solver.cpp:397]     Test net output #0: accuracy = 0.773
I1004 21:53:34.163210 15504 solver.cpp:397]     Test net output #1: loss = 0.665453 (* 1 = 0.665453 loss)
I1004 21:53:34.194460 15504 solver.cpp:218] Iteration 12000 (36.8213 iter/s, 2.71582s/100 iters), loss = 0.48553
I1004 21:53:34.194460 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:53:34.194460 15504 solver.cpp:237]     Train net output #1: loss = 0.48553 (* 1 = 0.48553 loss)
I1004 21:53:34.194460 15504 sgd_solver.cpp:105] Iteration 12000, lr = 0.0001
I1004 21:53:36.465131 15504 solver.cpp:218] Iteration 12100 (43.8082 iter/s, 2.28268s/100 iters), loss = 0.474014
I1004 21:53:36.465131 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:53:36.465131 15504 solver.cpp:237]     Train net output #1: loss = 0.474014 (* 1 = 0.474014 loss)
I1004 21:53:36.465131 15504 sgd_solver.cpp:105] Iteration 12100, lr = 0.0001
I1004 21:53:38.746233 15504 solver.cpp:218] Iteration 12200 (43.9375 iter/s, 2.27596s/100 iters), loss = 0.571513
I1004 21:53:38.746233 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:53:38.746233 15504 solver.cpp:237]     Train net output #1: loss = 0.571513 (* 1 = 0.571513 loss)
I1004 21:53:38.746233 15504 sgd_solver.cpp:105] Iteration 12200, lr = 0.0001
I1004 21:53:41.015677 15504 solver.cpp:218] Iteration 12300 (43.9515 iter/s, 2.27524s/100 iters), loss = 0.567117
I1004 21:53:41.015677 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:53:41.015677 15504 solver.cpp:237]     Train net output #1: loss = 0.567117 (* 1 = 0.567117 loss)
I1004 21:53:41.015677 15504 sgd_solver.cpp:105] Iteration 12300, lr = 0.0001
I1004 21:53:43.294385 15504 solver.cpp:218] Iteration 12400 (43.9215 iter/s, 2.27679s/100 iters), loss = 0.479953
I1004 21:53:43.294385 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:53:43.294385 15504 solver.cpp:237]     Train net output #1: loss = 0.479953 (* 1 = 0.479953 loss)
I1004 21:53:43.294385 15504 sgd_solver.cpp:105] Iteration 12400, lr = 0.0001
I1004 21:53:45.465363 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:53:45.580341 15504 solver.cpp:218] Iteration 12500 (43.8148 iter/s, 2.28233s/100 iters), loss = 0.512915
I1004 21:53:45.580341 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:53:45.580341 15504 solver.cpp:237]     Train net output #1: loss = 0.512915 (* 1 = 0.512915 loss)
I1004 21:53:45.580341 15504 sgd_solver.cpp:105] Iteration 12500, lr = 0.0001
I1004 21:53:47.859808 15504 solver.cpp:218] Iteration 12600 (43.801 iter/s, 2.28305s/100 iters), loss = 0.471672
I1004 21:53:47.859808 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:53:47.859808 15504 solver.cpp:237]     Train net output #1: loss = 0.471672 (* 1 = 0.471672 loss)
I1004 21:53:47.859808 15504 sgd_solver.cpp:105] Iteration 12600, lr = 0.0001
I1004 21:53:50.156633 15504 solver.cpp:218] Iteration 12700 (43.7916 iter/s, 2.28354s/100 iters), loss = 0.43575
I1004 21:53:50.156633 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:53:50.156633 15504 solver.cpp:237]     Train net output #1: loss = 0.43575 (* 1 = 0.43575 loss)
I1004 21:53:50.156633 15504 sgd_solver.cpp:105] Iteration 12700, lr = 0.0001
I1004 21:53:52.434319 15504 solver.cpp:218] Iteration 12800 (43.8124 iter/s, 2.28246s/100 iters), loss = 0.572188
I1004 21:53:52.434319 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:53:52.434319 15504 solver.cpp:237]     Train net output #1: loss = 0.572188 (* 1 = 0.572188 loss)
I1004 21:53:52.434319 15504 sgd_solver.cpp:105] Iteration 12800, lr = 0.0001
I1004 21:53:54.700294 15504 solver.cpp:218] Iteration 12900 (44.0241 iter/s, 2.27148s/100 iters), loss = 0.504763
I1004 21:53:54.700294 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:53:54.700294 15504 solver.cpp:237]     Train net output #1: loss = 0.504763 (* 1 = 0.504763 loss)
I1004 21:53:54.700294 15504 sgd_solver.cpp:105] Iteration 12900, lr = 0.0001
I1004 21:53:56.870388 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:53:56.967916 15504 solver.cpp:330] Iteration 13000, Testing net (#0)
I1004 21:53:56.967916 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:53:57.390234  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:53:57.406234 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7729
I1004 21:53:57.406234 15504 solver.cpp:397]     Test net output #1: loss = 0.665105 (* 1 = 0.665105 loss)
I1004 21:53:57.427232 15504 solver.cpp:218] Iteration 13000 (36.8191 iter/s, 2.71598s/100 iters), loss = 0.546929
I1004 21:53:57.427232 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:53:57.427232 15504 solver.cpp:237]     Train net output #1: loss = 0.546929 (* 1 = 0.546929 loss)
I1004 21:53:57.427232 15504 sgd_solver.cpp:105] Iteration 13000, lr = 0.0001
I1004 21:53:59.731781 15504 solver.cpp:218] Iteration 13100 (43.4018 iter/s, 2.30405s/100 iters), loss = 0.458518
I1004 21:53:59.731781 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:53:59.731781 15504 solver.cpp:237]     Train net output #1: loss = 0.458518 (* 1 = 0.458518 loss)
I1004 21:53:59.731781 15504 sgd_solver.cpp:105] Iteration 13100, lr = 0.0001
I1004 21:54:02.006893 15504 solver.cpp:218] Iteration 13200 (43.8923 iter/s, 2.2783s/100 iters), loss = 0.401651
I1004 21:54:02.006893 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1004 21:54:02.006893 15504 solver.cpp:237]     Train net output #1: loss = 0.401651 (* 1 = 0.401651 loss)
I1004 21:54:02.006893 15504 sgd_solver.cpp:105] Iteration 13200, lr = 0.0001
I1004 21:54:04.281779 15504 solver.cpp:218] Iteration 13300 (43.896 iter/s, 2.27811s/100 iters), loss = 0.576895
I1004 21:54:04.281779 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:54:04.281779 15504 solver.cpp:237]     Train net output #1: loss = 0.576895 (* 1 = 0.576895 loss)
I1004 21:54:04.281779 15504 sgd_solver.cpp:105] Iteration 13300, lr = 0.0001
I1004 21:54:06.562525 15504 solver.cpp:218] Iteration 13400 (43.8065 iter/s, 2.28277s/100 iters), loss = 0.529125
I1004 21:54:06.562525 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:54:06.562525 15504 solver.cpp:237]     Train net output #1: loss = 0.529125 (* 1 = 0.529125 loss)
I1004 21:54:06.562525 15504 sgd_solver.cpp:105] Iteration 13400, lr = 0.0001
I1004 21:54:08.745631 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:54:08.857620 15504 solver.cpp:218] Iteration 13500 (43.7489 iter/s, 2.28577s/100 iters), loss = 0.481173
I1004 21:54:08.857620 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:54:08.857620 15504 solver.cpp:237]     Train net output #1: loss = 0.481173 (* 1 = 0.481173 loss)
I1004 21:54:08.857620 15504 sgd_solver.cpp:105] Iteration 13500, lr = 0.0001
I1004 21:54:11.151037 15504 solver.cpp:218] Iteration 13600 (43.6094 iter/s, 2.29308s/100 iters), loss = 0.430555
I1004 21:54:11.151037 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:54:11.152040 15504 solver.cpp:237]     Train net output #1: loss = 0.430555 (* 1 = 0.430555 loss)
I1004 21:54:11.152040 15504 sgd_solver.cpp:105] Iteration 13600, lr = 0.0001
I1004 21:54:13.434839 15504 solver.cpp:218] Iteration 13700 (43.6561 iter/s, 2.29063s/100 iters), loss = 0.473112
I1004 21:54:13.434839 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:54:13.434839 15504 solver.cpp:237]     Train net output #1: loss = 0.473112 (* 1 = 0.473112 loss)
I1004 21:54:13.434839 15504 sgd_solver.cpp:105] Iteration 13700, lr = 0.0001
I1004 21:54:15.725800 15504 solver.cpp:218] Iteration 13800 (43.7982 iter/s, 2.2832s/100 iters), loss = 0.541084
I1004 21:54:15.725800 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:54:15.725800 15504 solver.cpp:237]     Train net output #1: loss = 0.541084 (* 1 = 0.541084 loss)
I1004 21:54:15.725800 15504 sgd_solver.cpp:105] Iteration 13800, lr = 0.0001
I1004 21:54:18.004730 15504 solver.cpp:218] Iteration 13900 (43.7547 iter/s, 2.28547s/100 iters), loss = 0.501941
I1004 21:54:18.004730 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:54:18.004730 15504 solver.cpp:237]     Train net output #1: loss = 0.501941 (* 1 = 0.501941 loss)
I1004 21:54:18.004730 15504 sgd_solver.cpp:105] Iteration 13900, lr = 0.0001
I1004 21:54:20.175985 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:54:20.269234 15504 solver.cpp:330] Iteration 14000, Testing net (#0)
I1004 21:54:20.269234 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:54:20.683393  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:54:20.699018 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7727
I1004 21:54:20.699018 15504 solver.cpp:397]     Test net output #1: loss = 0.665408 (* 1 = 0.665408 loss)
I1004 21:54:20.714643 15504 solver.cpp:218] Iteration 14000 (36.8562 iter/s, 2.71325s/100 iters), loss = 0.483362
I1004 21:54:20.714643 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:54:20.714643 15504 solver.cpp:237]     Train net output #1: loss = 0.483362 (* 1 = 0.483362 loss)
I1004 21:54:20.714643 15504 sgd_solver.cpp:105] Iteration 14000, lr = 0.0001
I1004 21:54:22.990499 15504 solver.cpp:218] Iteration 14100 (43.8909 iter/s, 2.27837s/100 iters), loss = 0.41566
I1004 21:54:22.990499 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:54:22.990499 15504 solver.cpp:237]     Train net output #1: loss = 0.41566 (* 1 = 0.41566 loss)
I1004 21:54:22.990499 15504 sgd_solver.cpp:105] Iteration 14100, lr = 0.0001
I1004 21:54:25.296039 15504 solver.cpp:218] Iteration 14200 (43.578 iter/s, 2.29474s/100 iters), loss = 0.490223
I1004 21:54:25.296039 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:54:25.296039 15504 solver.cpp:237]     Train net output #1: loss = 0.490223 (* 1 = 0.490223 loss)
I1004 21:54:25.296039 15504 sgd_solver.cpp:105] Iteration 14200, lr = 0.0001
I1004 21:54:27.589583 15504 solver.cpp:218] Iteration 14300 (43.6716 iter/s, 2.28982s/100 iters), loss = 0.52758
I1004 21:54:27.589583 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:54:27.589583 15504 solver.cpp:237]     Train net output #1: loss = 0.52758 (* 1 = 0.52758 loss)
I1004 21:54:27.589583 15504 sgd_solver.cpp:105] Iteration 14300, lr = 0.0001
I1004 21:54:29.869078 15504 solver.cpp:218] Iteration 14400 (43.7396 iter/s, 2.28626s/100 iters), loss = 0.462751
I1004 21:54:29.869078 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:54:29.869078 15504 solver.cpp:237]     Train net output #1: loss = 0.462751 (* 1 = 0.462751 loss)
I1004 21:54:29.869078 15504 sgd_solver.cpp:105] Iteration 14400, lr = 0.0001
I1004 21:54:32.043469 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:54:32.152845 15504 solver.cpp:218] Iteration 14500 (43.8397 iter/s, 2.28104s/100 iters), loss = 0.471519
I1004 21:54:32.152845 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:54:32.152845 15504 solver.cpp:237]     Train net output #1: loss = 0.471519 (* 1 = 0.471519 loss)
I1004 21:54:32.152845 15504 sgd_solver.cpp:105] Iteration 14500, lr = 0.0001
I1004 21:54:34.434625 15504 solver.cpp:218] Iteration 14600 (43.8244 iter/s, 2.28183s/100 iters), loss = 0.460887
I1004 21:54:34.434625 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:54:34.434625 15504 solver.cpp:237]     Train net output #1: loss = 0.460887 (* 1 = 0.460887 loss)
I1004 21:54:34.434625 15504 sgd_solver.cpp:105] Iteration 14600, lr = 0.0001
I1004 21:54:36.723451 15504 solver.cpp:218] Iteration 14700 (43.783 iter/s, 2.28399s/100 iters), loss = 0.459048
I1004 21:54:36.723451 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:54:36.723451 15504 solver.cpp:237]     Train net output #1: loss = 0.459048 (* 1 = 0.459048 loss)
I1004 21:54:36.723451 15504 sgd_solver.cpp:105] Iteration 14700, lr = 0.0001
I1004 21:54:38.996816 15504 solver.cpp:218] Iteration 14800 (43.8222 iter/s, 2.28195s/100 iters), loss = 0.567843
I1004 21:54:38.996816 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:54:38.996816 15504 solver.cpp:237]     Train net output #1: loss = 0.567843 (* 1 = 0.567843 loss)
I1004 21:54:38.996816 15504 sgd_solver.cpp:105] Iteration 14800, lr = 0.0001
I1004 21:54:41.281731 15504 solver.cpp:218] Iteration 14900 (43.8686 iter/s, 2.27953s/100 iters), loss = 0.473516
I1004 21:54:41.281731 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:54:41.281731 15504 solver.cpp:237]     Train net output #1: loss = 0.473516 (* 1 = 0.473516 loss)
I1004 21:54:41.281731 15504 sgd_solver.cpp:105] Iteration 14900, lr = 0.0001
I1004 21:54:43.483026 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:54:43.574025 15504 solver.cpp:330] Iteration 15000, Testing net (#0)
I1004 21:54:43.574025 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:54:44.004077  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:54:44.019703 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7734
I1004 21:54:44.019703 15504 solver.cpp:397]     Test net output #1: loss = 0.665655 (* 1 = 0.665655 loss)
I1004 21:54:44.035328 15504 solver.cpp:218] Iteration 15000 (36.2769 iter/s, 2.75657s/100 iters), loss = 0.440015
I1004 21:54:44.035328 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:54:44.035328 15504 solver.cpp:237]     Train net output #1: loss = 0.440015 (* 1 = 0.440015 loss)
I1004 21:54:44.035328 15504 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I1004 21:54:44.035328 15504 sgd_solver.cpp:105] Iteration 15000, lr = 1e-05
I1004 21:54:46.312484 15504 solver.cpp:218] Iteration 15100 (43.9162 iter/s, 2.27707s/100 iters), loss = 0.394183
I1004 21:54:46.312484 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1004 21:54:46.312484 15504 solver.cpp:237]     Train net output #1: loss = 0.394183 (* 1 = 0.394183 loss)
I1004 21:54:46.312484 15504 sgd_solver.cpp:105] Iteration 15100, lr = 1e-05
I1004 21:54:48.606490 15504 solver.cpp:218] Iteration 15200 (43.6598 iter/s, 2.29044s/100 iters), loss = 0.494041
I1004 21:54:48.606490 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:54:48.606490 15504 solver.cpp:237]     Train net output #1: loss = 0.494041 (* 1 = 0.494041 loss)
I1004 21:54:48.606490 15504 sgd_solver.cpp:105] Iteration 15200, lr = 1e-05
I1004 21:54:50.893388 15504 solver.cpp:218] Iteration 15300 (43.8064 iter/s, 2.28277s/100 iters), loss = 0.554619
I1004 21:54:50.893388 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:54:50.893388 15504 solver.cpp:237]     Train net output #1: loss = 0.554619 (* 1 = 0.554619 loss)
I1004 21:54:50.893388 15504 sgd_solver.cpp:105] Iteration 15300, lr = 1e-05
I1004 21:54:53.168170 15504 solver.cpp:218] Iteration 15400 (43.8514 iter/s, 2.28043s/100 iters), loss = 0.414089
I1004 21:54:53.168170 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:54:53.168170 15504 solver.cpp:237]     Train net output #1: loss = 0.414089 (* 1 = 0.414089 loss)
I1004 21:54:53.168170 15504 sgd_solver.cpp:105] Iteration 15400, lr = 1e-05
I1004 21:54:55.341276 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:54:55.449719 15504 solver.cpp:218] Iteration 15500 (43.921 iter/s, 2.27681s/100 iters), loss = 0.410716
I1004 21:54:55.449719 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:54:55.449719 15504 solver.cpp:237]     Train net output #1: loss = 0.410716 (* 1 = 0.410716 loss)
I1004 21:54:55.449719 15504 sgd_solver.cpp:105] Iteration 15500, lr = 1e-05
I1004 21:54:57.721138 15504 solver.cpp:218] Iteration 15600 (43.8392 iter/s, 2.28107s/100 iters), loss = 0.440136
I1004 21:54:57.721138 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:54:57.721138 15504 solver.cpp:237]     Train net output #1: loss = 0.440136 (* 1 = 0.440136 loss)
I1004 21:54:57.721138 15504 sgd_solver.cpp:105] Iteration 15600, lr = 1e-05
I1004 21:55:00.016347 15504 solver.cpp:218] Iteration 15700 (43.7989 iter/s, 2.28316s/100 iters), loss = 0.498876
I1004 21:55:00.016347 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:55:00.016347 15504 solver.cpp:237]     Train net output #1: loss = 0.498876 (* 1 = 0.498876 loss)
I1004 21:55:00.016347 15504 sgd_solver.cpp:105] Iteration 15700, lr = 1e-05
I1004 21:55:02.305640 15504 solver.cpp:218] Iteration 15800 (43.4777 iter/s, 2.30003s/100 iters), loss = 0.580556
I1004 21:55:02.305640 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:55:02.305640 15504 solver.cpp:237]     Train net output #1: loss = 0.580556 (* 1 = 0.580556 loss)
I1004 21:55:02.305640 15504 sgd_solver.cpp:105] Iteration 15800, lr = 1e-05
I1004 21:55:04.603286 15504 solver.cpp:218] Iteration 15900 (43.5952 iter/s, 2.29383s/100 iters), loss = 0.487927
I1004 21:55:04.603286 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:55:04.603286 15504 solver.cpp:237]     Train net output #1: loss = 0.487927 (* 1 = 0.487927 loss)
I1004 21:55:04.603286 15504 sgd_solver.cpp:105] Iteration 15900, lr = 1e-05
I1004 21:55:06.773685 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:55:06.867435 15504 solver.cpp:330] Iteration 16000, Testing net (#0)
I1004 21:55:06.867435 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:55:07.298101  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:55:07.315102 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7723
I1004 21:55:07.315102 15504 solver.cpp:397]     Test net output #1: loss = 0.66492 (* 1 = 0.66492 loss)
I1004 21:55:07.323220 15504 solver.cpp:218] Iteration 16000 (36.7008 iter/s, 2.72474s/100 iters), loss = 0.475461
I1004 21:55:07.323220 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:55:07.323220 15504 solver.cpp:237]     Train net output #1: loss = 0.475461 (* 1 = 0.475461 loss)
I1004 21:55:07.323220 15504 sgd_solver.cpp:105] Iteration 16000, lr = 1e-05
I1004 21:55:09.624972 15504 solver.cpp:218] Iteration 16100 (43.6953 iter/s, 2.28858s/100 iters), loss = 0.410618
I1004 21:55:09.624972 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:55:09.624972 15504 solver.cpp:237]     Train net output #1: loss = 0.410618 (* 1 = 0.410618 loss)
I1004 21:55:09.624972 15504 sgd_solver.cpp:105] Iteration 16100, lr = 1e-05
I1004 21:55:11.933786 15504 solver.cpp:218] Iteration 16200 (43.3307 iter/s, 2.30783s/100 iters), loss = 0.454757
I1004 21:55:11.933786 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:55:11.933786 15504 solver.cpp:237]     Train net output #1: loss = 0.454757 (* 1 = 0.454757 loss)
I1004 21:55:11.933786 15504 sgd_solver.cpp:105] Iteration 16200, lr = 1e-05
I1004 21:55:14.227061 15504 solver.cpp:218] Iteration 16300 (43.5932 iter/s, 2.29393s/100 iters), loss = 0.531628
I1004 21:55:14.227061 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:55:14.227061 15504 solver.cpp:237]     Train net output #1: loss = 0.531628 (* 1 = 0.531628 loss)
I1004 21:55:14.227061 15504 sgd_solver.cpp:105] Iteration 16300, lr = 1e-05
I1004 21:55:16.512116 15504 solver.cpp:218] Iteration 16400 (43.754 iter/s, 2.2855s/100 iters), loss = 0.450831
I1004 21:55:16.512116 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:55:16.512116 15504 solver.cpp:237]     Train net output #1: loss = 0.450831 (* 1 = 0.450831 loss)
I1004 21:55:16.512116 15504 sgd_solver.cpp:105] Iteration 16400, lr = 1e-05
I1004 21:55:18.705637 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:55:18.820895 15504 solver.cpp:218] Iteration 16500 (43.3375 iter/s, 2.30747s/100 iters), loss = 0.520174
I1004 21:55:18.820895 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:55:18.821897 15504 solver.cpp:237]     Train net output #1: loss = 0.520174 (* 1 = 0.520174 loss)
I1004 21:55:18.821897 15504 sgd_solver.cpp:105] Iteration 16500, lr = 1e-05
I1004 21:55:21.106937 15504 solver.cpp:218] Iteration 16600 (43.6118 iter/s, 2.29296s/100 iters), loss = 0.382625
I1004 21:55:21.106937 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1004 21:55:21.106937 15504 solver.cpp:237]     Train net output #1: loss = 0.382625 (* 1 = 0.382625 loss)
I1004 21:55:21.106937 15504 sgd_solver.cpp:105] Iteration 16600, lr = 1e-05
I1004 21:55:23.402062 15504 solver.cpp:218] Iteration 16700 (43.73 iter/s, 2.28676s/100 iters), loss = 0.467055
I1004 21:55:23.402062 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:55:23.402062 15504 solver.cpp:237]     Train net output #1: loss = 0.467055 (* 1 = 0.467055 loss)
I1004 21:55:23.402062 15504 sgd_solver.cpp:105] Iteration 16700, lr = 1e-05
I1004 21:55:25.688645 15504 solver.cpp:218] Iteration 16800 (43.5044 iter/s, 2.29862s/100 iters), loss = 0.558198
I1004 21:55:25.688645 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:55:25.688645 15504 solver.cpp:237]     Train net output #1: loss = 0.558198 (* 1 = 0.558198 loss)
I1004 21:55:25.688645 15504 sgd_solver.cpp:105] Iteration 16800, lr = 1e-05
I1004 21:55:27.982167 15504 solver.cpp:218] Iteration 16900 (43.6504 iter/s, 2.29093s/100 iters), loss = 0.443425
I1004 21:55:27.982167 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:55:27.982167 15504 solver.cpp:237]     Train net output #1: loss = 0.443425 (* 1 = 0.443425 loss)
I1004 21:55:27.982167 15504 sgd_solver.cpp:105] Iteration 16900, lr = 1e-05
I1004 21:55:30.162350 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:55:30.253662 15504 solver.cpp:330] Iteration 17000, Testing net (#0)
I1004 21:55:30.253662 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:55:30.669944  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:55:30.685570 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7721
I1004 21:55:30.685570 15504 solver.cpp:397]     Test net output #1: loss = 0.664984 (* 1 = 0.664984 loss)
I1004 21:55:30.716822 15504 solver.cpp:218] Iteration 17000 (36.6466 iter/s, 2.72876s/100 iters), loss = 0.492736
I1004 21:55:30.716822 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:55:30.716822 15504 solver.cpp:237]     Train net output #1: loss = 0.492736 (* 1 = 0.492736 loss)
I1004 21:55:30.716822 15504 sgd_solver.cpp:105] Iteration 17000, lr = 1e-05
I1004 21:55:33.022719 15504 solver.cpp:218] Iteration 17100 (43.4544 iter/s, 2.30126s/100 iters), loss = 0.480973
I1004 21:55:33.022719 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:55:33.022719 15504 solver.cpp:237]     Train net output #1: loss = 0.480973 (* 1 = 0.480973 loss)
I1004 21:55:33.022719 15504 sgd_solver.cpp:105] Iteration 17100, lr = 1e-05
I1004 21:55:35.305506 15504 solver.cpp:218] Iteration 17200 (43.7719 iter/s, 2.28457s/100 iters), loss = 0.487035
I1004 21:55:35.305506 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:55:35.305506 15504 solver.cpp:237]     Train net output #1: loss = 0.487035 (* 1 = 0.487035 loss)
I1004 21:55:35.305506 15504 sgd_solver.cpp:105] Iteration 17200, lr = 1e-05
I1004 21:55:37.602001 15504 solver.cpp:218] Iteration 17300 (43.4427 iter/s, 2.30188s/100 iters), loss = 0.504369
I1004 21:55:37.602001 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:55:37.602001 15504 solver.cpp:237]     Train net output #1: loss = 0.504369 (* 1 = 0.504369 loss)
I1004 21:55:37.602001 15504 sgd_solver.cpp:105] Iteration 17300, lr = 1e-05
I1004 21:55:39.878048 15504 solver.cpp:218] Iteration 17400 (43.8746 iter/s, 2.27922s/100 iters), loss = 0.441529
I1004 21:55:39.878048 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:55:39.878048 15504 solver.cpp:237]     Train net output #1: loss = 0.441529 (* 1 = 0.441529 loss)
I1004 21:55:39.878048 15504 sgd_solver.cpp:105] Iteration 17400, lr = 1e-05
I1004 21:55:42.043797 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:55:42.162724 15504 solver.cpp:218] Iteration 17500 (43.923 iter/s, 2.27671s/100 iters), loss = 0.518927
I1004 21:55:42.162724 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:55:42.162724 15504 solver.cpp:237]     Train net output #1: loss = 0.518927 (* 1 = 0.518927 loss)
I1004 21:55:42.162724 15504 sgd_solver.cpp:105] Iteration 17500, lr = 1e-05
I1004 21:55:44.442062 15504 solver.cpp:218] Iteration 17600 (43.9576 iter/s, 2.27492s/100 iters), loss = 0.439961
I1004 21:55:44.442062 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:55:44.442062 15504 solver.cpp:237]     Train net output #1: loss = 0.439961 (* 1 = 0.439961 loss)
I1004 21:55:44.442062 15504 sgd_solver.cpp:105] Iteration 17600, lr = 1e-05
I1004 21:55:46.707294 15504 solver.cpp:218] Iteration 17700 (43.9104 iter/s, 2.27736s/100 iters), loss = 0.500963
I1004 21:55:46.707294 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:55:46.707294 15504 solver.cpp:237]     Train net output #1: loss = 0.500963 (* 1 = 0.500963 loss)
I1004 21:55:46.707294 15504 sgd_solver.cpp:105] Iteration 17700, lr = 1e-05
I1004 21:55:48.997239 15504 solver.cpp:218] Iteration 17800 (43.8378 iter/s, 2.28113s/100 iters), loss = 0.569685
I1004 21:55:48.997239 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:55:48.997239 15504 solver.cpp:237]     Train net output #1: loss = 0.569685 (* 1 = 0.569685 loss)
I1004 21:55:48.997239 15504 sgd_solver.cpp:105] Iteration 17800, lr = 1e-05
I1004 21:55:51.263607 15504 solver.cpp:218] Iteration 17900 (44.0361 iter/s, 2.27086s/100 iters), loss = 0.479192
I1004 21:55:51.263607 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:55:51.263607 15504 solver.cpp:237]     Train net output #1: loss = 0.479192 (* 1 = 0.479192 loss)
I1004 21:55:51.263607 15504 sgd_solver.cpp:105] Iteration 17900, lr = 1e-05
I1004 21:55:53.448828 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:55:53.538144 15504 solver.cpp:330] Iteration 18000, Testing net (#0)
I1004 21:55:53.538144 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:55:53.949550  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:55:53.965174 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7724
I1004 21:55:53.965174 15504 solver.cpp:397]     Test net output #1: loss = 0.664711 (* 1 = 0.664711 loss)
I1004 21:55:53.980799 15504 solver.cpp:218] Iteration 18000 (36.8056 iter/s, 2.71698s/100 iters), loss = 0.463697
I1004 21:55:53.980799 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:55:53.980799 15504 solver.cpp:237]     Train net output #1: loss = 0.463697 (* 1 = 0.463697 loss)
I1004 21:55:53.980799 15504 sgd_solver.cpp:105] Iteration 18000, lr = 1e-05
I1004 21:55:56.264865 15504 solver.cpp:218] Iteration 18100 (43.8859 iter/s, 2.27864s/100 iters), loss = 0.461195
I1004 21:55:56.264865 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:55:56.264865 15504 solver.cpp:237]     Train net output #1: loss = 0.461195 (* 1 = 0.461195 loss)
I1004 21:55:56.264865 15504 sgd_solver.cpp:105] Iteration 18100, lr = 1e-05
I1004 21:55:58.543277 15504 solver.cpp:218] Iteration 18200 (43.939 iter/s, 2.27588s/100 iters), loss = 0.546431
I1004 21:55:58.543277 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:55:58.543277 15504 solver.cpp:237]     Train net output #1: loss = 0.546431 (* 1 = 0.546431 loss)
I1004 21:55:58.543277 15504 sgd_solver.cpp:105] Iteration 18200, lr = 1e-05
I1004 21:56:00.816354 15504 solver.cpp:218] Iteration 18300 (43.8937 iter/s, 2.27823s/100 iters), loss = 0.537183
I1004 21:56:00.816354 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:56:00.816354 15504 solver.cpp:237]     Train net output #1: loss = 0.537183 (* 1 = 0.537183 loss)
I1004 21:56:00.816354 15504 sgd_solver.cpp:105] Iteration 18300, lr = 1e-05
I1004 21:56:03.101795 15504 solver.cpp:218] Iteration 18400 (43.8867 iter/s, 2.2786s/100 iters), loss = 0.435457
I1004 21:56:03.101795 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:56:03.101795 15504 solver.cpp:237]     Train net output #1: loss = 0.435457 (* 1 = 0.435457 loss)
I1004 21:56:03.101795 15504 sgd_solver.cpp:105] Iteration 18400, lr = 1e-05
I1004 21:56:05.263432 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:56:05.369755 15504 solver.cpp:218] Iteration 18500 (43.936 iter/s, 2.27604s/100 iters), loss = 0.512527
I1004 21:56:05.369755 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:56:05.369755 15504 solver.cpp:237]     Train net output #1: loss = 0.512527 (* 1 = 0.512527 loss)
I1004 21:56:05.369755 15504 sgd_solver.cpp:105] Iteration 18500, lr = 1e-05
I1004 21:56:07.638029 15504 solver.cpp:218] Iteration 18600 (43.964 iter/s, 2.27459s/100 iters), loss = 0.427733
I1004 21:56:07.653653 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:56:07.653653 15504 solver.cpp:237]     Train net output #1: loss = 0.427733 (* 1 = 0.427733 loss)
I1004 21:56:07.653653 15504 sgd_solver.cpp:105] Iteration 18600, lr = 1e-05
I1004 21:56:09.931516 15504 solver.cpp:218] Iteration 18700 (43.8971 iter/s, 2.27805s/100 iters), loss = 0.490237
I1004 21:56:09.931516 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:56:09.931516 15504 solver.cpp:237]     Train net output #1: loss = 0.490237 (* 1 = 0.490237 loss)
I1004 21:56:09.931516 15504 sgd_solver.cpp:105] Iteration 18700, lr = 1e-05
I1004 21:56:12.201429 15504 solver.cpp:218] Iteration 18800 (43.7767 iter/s, 2.28432s/100 iters), loss = 0.551521
I1004 21:56:12.201429 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:56:12.201429 15504 solver.cpp:237]     Train net output #1: loss = 0.551521 (* 1 = 0.551521 loss)
I1004 21:56:12.201429 15504 sgd_solver.cpp:105] Iteration 18800, lr = 1e-05
I1004 21:56:14.496439 15504 solver.cpp:218] Iteration 18900 (43.8446 iter/s, 2.28078s/100 iters), loss = 0.536405
I1004 21:56:14.496439 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:56:14.496439 15504 solver.cpp:237]     Train net output #1: loss = 0.536405 (* 1 = 0.536405 loss)
I1004 21:56:14.496439 15504 sgd_solver.cpp:105] Iteration 18900, lr = 1e-05
I1004 21:56:16.652901 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:56:16.741092 15504 solver.cpp:330] Iteration 19000, Testing net (#0)
I1004 21:56:16.741092 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:56:17.153622  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:56:17.169247 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7725
I1004 21:56:17.169247 15504 solver.cpp:397]     Test net output #1: loss = 0.664662 (* 1 = 0.664662 loss)
I1004 21:56:17.200497 15504 solver.cpp:218] Iteration 19000 (36.973 iter/s, 2.70468s/100 iters), loss = 0.483566
I1004 21:56:17.200497 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:56:17.200497 15504 solver.cpp:237]     Train net output #1: loss = 0.483566 (* 1 = 0.483566 loss)
I1004 21:56:17.200497 15504 sgd_solver.cpp:105] Iteration 19000, lr = 1e-05
I1004 21:56:19.473115 15504 solver.cpp:218] Iteration 19100 (43.9096 iter/s, 2.27741s/100 iters), loss = 0.467958
I1004 21:56:19.473115 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:56:19.473115 15504 solver.cpp:237]     Train net output #1: loss = 0.467958 (* 1 = 0.467958 loss)
I1004 21:56:19.473115 15504 sgd_solver.cpp:105] Iteration 19100, lr = 1e-05
I1004 21:56:21.757086 15504 solver.cpp:218] Iteration 19200 (43.7613 iter/s, 2.28512s/100 iters), loss = 0.429956
I1004 21:56:21.757086 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1004 21:56:21.757086 15504 solver.cpp:237]     Train net output #1: loss = 0.429956 (* 1 = 0.429956 loss)
I1004 21:56:21.757086 15504 sgd_solver.cpp:105] Iteration 19200, lr = 1e-05
I1004 21:56:24.039675 15504 solver.cpp:218] Iteration 19300 (43.8043 iter/s, 2.28288s/100 iters), loss = 0.528259
I1004 21:56:24.039675 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:56:24.039675 15504 solver.cpp:237]     Train net output #1: loss = 0.528259 (* 1 = 0.528259 loss)
I1004 21:56:24.039675 15504 sgd_solver.cpp:105] Iteration 19300, lr = 1e-05
I1004 21:56:26.323707 15504 solver.cpp:218] Iteration 19400 (43.8659 iter/s, 2.27968s/100 iters), loss = 0.522086
I1004 21:56:26.323707 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:56:26.323707 15504 solver.cpp:237]     Train net output #1: loss = 0.522086 (* 1 = 0.522086 loss)
I1004 21:56:26.323707 15504 sgd_solver.cpp:105] Iteration 19400, lr = 1e-05
I1004 21:56:28.481281 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:56:28.604846 15504 solver.cpp:218] Iteration 19500 (43.9498 iter/s, 2.27532s/100 iters), loss = 0.490927
I1004 21:56:28.604846 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:56:28.604846 15504 solver.cpp:237]     Train net output #1: loss = 0.490927 (* 1 = 0.490927 loss)
I1004 21:56:28.604846 15504 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I1004 21:56:30.877153 15504 solver.cpp:218] Iteration 19600 (43.7655 iter/s, 2.2849s/100 iters), loss = 0.448346
I1004 21:56:30.877153 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:56:30.877153 15504 solver.cpp:237]     Train net output #1: loss = 0.448346 (* 1 = 0.448346 loss)
I1004 21:56:30.877153 15504 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I1004 21:56:33.159011 15504 solver.cpp:218] Iteration 19700 (43.836 iter/s, 2.28123s/100 iters), loss = 0.52296
I1004 21:56:33.159011 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:56:33.159011 15504 solver.cpp:237]     Train net output #1: loss = 0.52296 (* 1 = 0.52296 loss)
I1004 21:56:33.159011 15504 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I1004 21:56:35.434744 15504 solver.cpp:218] Iteration 19800 (43.9306 iter/s, 2.27632s/100 iters), loss = 0.556354
I1004 21:56:35.434744 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:56:35.434744 15504 solver.cpp:237]     Train net output #1: loss = 0.556354 (* 1 = 0.556354 loss)
I1004 21:56:35.434744 15504 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I1004 21:56:37.724021 15504 solver.cpp:218] Iteration 19900 (43.8825 iter/s, 2.27881s/100 iters), loss = 0.434856
I1004 21:56:37.724021 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:56:37.724021 15504 solver.cpp:237]     Train net output #1: loss = 0.434856 (* 1 = 0.434856 loss)
I1004 21:56:37.724021 15504 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I1004 21:56:39.894503 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:56:39.980849 15504 solver.cpp:330] Iteration 20000, Testing net (#0)
I1004 21:56:39.980849 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:56:40.398936  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:56:40.414934 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7732
I1004 21:56:40.415935 15504 solver.cpp:397]     Test net output #1: loss = 0.66449 (* 1 = 0.66449 loss)
I1004 21:56:40.434015 15504 solver.cpp:218] Iteration 20000 (36.9161 iter/s, 2.70884s/100 iters), loss = 0.459684
I1004 21:56:40.434015 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:56:40.434015 15504 solver.cpp:237]     Train net output #1: loss = 0.459684 (* 1 = 0.459684 loss)
I1004 21:56:40.434015 15504 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I1004 21:56:42.707942 15504 solver.cpp:218] Iteration 20100 (43.8013 iter/s, 2.28304s/100 iters), loss = 0.46087
I1004 21:56:42.707942 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:56:42.707942 15504 solver.cpp:237]     Train net output #1: loss = 0.46087 (* 1 = 0.46087 loss)
I1004 21:56:42.707942 15504 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I1004 21:56:44.998921 15504 solver.cpp:218] Iteration 20200 (43.8758 iter/s, 2.27916s/100 iters), loss = 0.470341
I1004 21:56:44.998921 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:56:44.998921 15504 solver.cpp:237]     Train net output #1: loss = 0.470341 (* 1 = 0.470341 loss)
I1004 21:56:44.998921 15504 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I1004 21:56:47.269961 15504 solver.cpp:218] Iteration 20300 (43.9071 iter/s, 2.27754s/100 iters), loss = 0.524194
I1004 21:56:47.269961 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:56:47.269961 15504 solver.cpp:237]     Train net output #1: loss = 0.524194 (* 1 = 0.524194 loss)
I1004 21:56:47.269961 15504 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I1004 21:56:49.555904 15504 solver.cpp:218] Iteration 20400 (43.8569 iter/s, 2.28014s/100 iters), loss = 0.423011
I1004 21:56:49.555904 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:56:49.555904 15504 solver.cpp:237]     Train net output #1: loss = 0.423011 (* 1 = 0.423011 loss)
I1004 21:56:49.555904 15504 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I1004 21:56:51.727957 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:56:51.837333 15504 solver.cpp:218] Iteration 20500 (43.8309 iter/s, 2.2815s/100 iters), loss = 0.501366
I1004 21:56:51.837333 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1004 21:56:51.837333 15504 solver.cpp:237]     Train net output #1: loss = 0.501366 (* 1 = 0.501366 loss)
I1004 21:56:51.837333 15504 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I1004 21:56:54.108131 15504 solver.cpp:218] Iteration 20600 (43.893 iter/s, 2.27827s/100 iters), loss = 0.456646
I1004 21:56:54.108131 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:56:54.108131 15504 solver.cpp:237]     Train net output #1: loss = 0.456646 (* 1 = 0.456646 loss)
I1004 21:56:54.108131 15504 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I1004 21:56:56.396770 15504 solver.cpp:218] Iteration 20700 (43.8814 iter/s, 2.27887s/100 iters), loss = 0.494977
I1004 21:56:56.396770 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:56:56.396770 15504 solver.cpp:237]     Train net output #1: loss = 0.494977 (* 1 = 0.494977 loss)
I1004 21:56:56.396770 15504 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I1004 21:56:58.668990 15504 solver.cpp:218] Iteration 20800 (43.9434 iter/s, 2.27565s/100 iters), loss = 0.538518
I1004 21:56:58.668990 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:56:58.668990 15504 solver.cpp:237]     Train net output #1: loss = 0.538518 (* 1 = 0.538518 loss)
I1004 21:56:58.668990 15504 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I1004 21:57:00.949764 15504 solver.cpp:218] Iteration 20900 (43.7227 iter/s, 2.28714s/100 iters), loss = 0.432843
I1004 21:57:00.949764 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:57:00.949764 15504 solver.cpp:237]     Train net output #1: loss = 0.432843 (* 1 = 0.432843 loss)
I1004 21:57:00.949764 15504 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I1004 21:57:03.123144 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:57:03.216894 15504 solver.cpp:330] Iteration 21000, Testing net (#0)
I1004 21:57:03.216894 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:57:03.622267  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:57:03.637893 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7728
I1004 21:57:03.637893 15504 solver.cpp:397]     Test net output #1: loss = 0.664573 (* 1 = 0.664573 loss)
I1004 21:57:03.669143 15504 solver.cpp:218] Iteration 21000 (36.8685 iter/s, 2.71234s/100 iters), loss = 0.491845
I1004 21:57:03.669143 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:57:03.669143 15504 solver.cpp:237]     Train net output #1: loss = 0.491845 (* 1 = 0.491845 loss)
I1004 21:57:03.669143 15504 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I1004 21:57:05.950042 15504 solver.cpp:218] Iteration 21100 (43.8009 iter/s, 2.28306s/100 iters), loss = 0.443397
I1004 21:57:05.950042 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:57:05.950042 15504 solver.cpp:237]     Train net output #1: loss = 0.443397 (* 1 = 0.443397 loss)
I1004 21:57:05.950042 15504 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I1004 21:57:08.218308 15504 solver.cpp:218] Iteration 21200 (43.9428 iter/s, 2.27569s/100 iters), loss = 0.511171
I1004 21:57:08.218308 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:57:08.218308 15504 solver.cpp:237]     Train net output #1: loss = 0.511171 (* 1 = 0.511171 loss)
I1004 21:57:08.218308 15504 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I1004 21:57:10.512234 15504 solver.cpp:218] Iteration 21300 (43.8102 iter/s, 2.28257s/100 iters), loss = 0.558462
I1004 21:57:10.512234 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:57:10.512234 15504 solver.cpp:237]     Train net output #1: loss = 0.558462 (* 1 = 0.558462 loss)
I1004 21:57:10.512234 15504 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I1004 21:57:12.787092 15504 solver.cpp:218] Iteration 21400 (44.0184 iter/s, 2.27178s/100 iters), loss = 0.448546
I1004 21:57:12.787092 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:57:12.787092 15504 solver.cpp:237]     Train net output #1: loss = 0.448546 (* 1 = 0.448546 loss)
I1004 21:57:12.787092 15504 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I1004 21:57:14.950636 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:57:15.060011 15504 solver.cpp:218] Iteration 21500 (43.8947 iter/s, 2.27818s/100 iters), loss = 0.445381
I1004 21:57:15.060011 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:57:15.060011 15504 solver.cpp:237]     Train net output #1: loss = 0.445381 (* 1 = 0.445381 loss)
I1004 21:57:15.060011 15504 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I1004 21:57:17.331688 15504 solver.cpp:218] Iteration 21600 (43.8937 iter/s, 2.27823s/100 iters), loss = 0.422381
I1004 21:57:17.331688 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:57:17.331688 15504 solver.cpp:237]     Train net output #1: loss = 0.422381 (* 1 = 0.422381 loss)
I1004 21:57:17.331688 15504 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I1004 21:57:19.617177 15504 solver.cpp:218] Iteration 21700 (43.8787 iter/s, 2.27901s/100 iters), loss = 0.548318
I1004 21:57:19.617177 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:57:19.617177 15504 solver.cpp:237]     Train net output #1: loss = 0.548318 (* 1 = 0.548318 loss)
I1004 21:57:19.617177 15504 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I1004 21:57:21.898375 15504 solver.cpp:218] Iteration 21800 (43.8112 iter/s, 2.28252s/100 iters), loss = 0.595201
I1004 21:57:21.898375 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:57:21.898375 15504 solver.cpp:237]     Train net output #1: loss = 0.595201 (* 1 = 0.595201 loss)
I1004 21:57:21.898375 15504 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I1004 21:57:24.185400 15504 solver.cpp:218] Iteration 21900 (43.8451 iter/s, 2.28075s/100 iters), loss = 0.494687
I1004 21:57:24.185400 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:57:24.185400 15504 solver.cpp:237]     Train net output #1: loss = 0.494687 (* 1 = 0.494687 loss)
I1004 21:57:24.185400 15504 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I1004 21:57:26.350841 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:57:26.434568 15504 solver.cpp:330] Iteration 22000, Testing net (#0)
I1004 21:57:26.434568 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:57:26.851267  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:57:26.866892 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7727
I1004 21:57:26.866892 15504 solver.cpp:397]     Test net output #1: loss = 0.664557 (* 1 = 0.664557 loss)
I1004 21:57:26.882517 15504 solver.cpp:218] Iteration 22000 (36.9551 iter/s, 2.70599s/100 iters), loss = 0.501452
I1004 21:57:26.882517 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:57:26.882517 15504 solver.cpp:237]     Train net output #1: loss = 0.501452 (* 1 = 0.501452 loss)
I1004 21:57:26.882517 15504 sgd_solver.cpp:105] Iteration 22000, lr = 1e-05
I1004 21:57:29.156718 15504 solver.cpp:218] Iteration 22100 (43.9292 iter/s, 2.27639s/100 iters), loss = 0.429673
I1004 21:57:29.156718 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:57:29.156718 15504 solver.cpp:237]     Train net output #1: loss = 0.429673 (* 1 = 0.429673 loss)
I1004 21:57:29.156718 15504 sgd_solver.cpp:105] Iteration 22100, lr = 1e-05
I1004 21:57:31.434571 15504 solver.cpp:218] Iteration 22200 (43.8945 iter/s, 2.27819s/100 iters), loss = 0.458501
I1004 21:57:31.434571 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:57:31.434571 15504 solver.cpp:237]     Train net output #1: loss = 0.458501 (* 1 = 0.458501 loss)
I1004 21:57:31.434571 15504 sgd_solver.cpp:105] Iteration 22200, lr = 1e-05
I1004 21:57:33.724973 15504 solver.cpp:218] Iteration 22300 (43.8631 iter/s, 2.27982s/100 iters), loss = 0.567415
I1004 21:57:33.724973 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:57:33.724973 15504 solver.cpp:237]     Train net output #1: loss = 0.567415 (* 1 = 0.567415 loss)
I1004 21:57:33.724973 15504 sgd_solver.cpp:105] Iteration 22300, lr = 1e-05
I1004 21:57:36.012886 15504 solver.cpp:218] Iteration 22400 (43.799 iter/s, 2.28315s/100 iters), loss = 0.45753
I1004 21:57:36.012886 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:57:36.012886 15504 solver.cpp:237]     Train net output #1: loss = 0.45753 (* 1 = 0.45753 loss)
I1004 21:57:36.012886 15504 sgd_solver.cpp:105] Iteration 22400, lr = 1e-05
I1004 21:57:38.190254 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:57:38.289027 15504 solver.cpp:218] Iteration 22500 (43.7346 iter/s, 2.28652s/100 iters), loss = 0.472939
I1004 21:57:38.289027 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:57:38.289027 15504 solver.cpp:237]     Train net output #1: loss = 0.472939 (* 1 = 0.472939 loss)
I1004 21:57:38.289027 15504 sgd_solver.cpp:105] Iteration 22500, lr = 1e-05
I1004 21:57:40.575531 15504 solver.cpp:218] Iteration 22600 (43.7816 iter/s, 2.28407s/100 iters), loss = 0.346099
I1004 21:57:40.575531 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1004 21:57:40.575531 15504 solver.cpp:237]     Train net output #1: loss = 0.346099 (* 1 = 0.346099 loss)
I1004 21:57:40.575531 15504 sgd_solver.cpp:105] Iteration 22600, lr = 1e-05
I1004 21:57:42.865922 15504 solver.cpp:218] Iteration 22700 (43.7721 iter/s, 2.28456s/100 iters), loss = 0.482015
I1004 21:57:42.865922 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:57:42.865922 15504 solver.cpp:237]     Train net output #1: loss = 0.482015 (* 1 = 0.482015 loss)
I1004 21:57:42.865922 15504 sgd_solver.cpp:105] Iteration 22700, lr = 1e-05
I1004 21:57:45.140683 15504 solver.cpp:218] Iteration 22800 (43.766 iter/s, 2.28488s/100 iters), loss = 0.555095
I1004 21:57:45.140683 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:57:45.140683 15504 solver.cpp:237]     Train net output #1: loss = 0.555095 (* 1 = 0.555095 loss)
I1004 21:57:45.140683 15504 sgd_solver.cpp:105] Iteration 22800, lr = 1e-05
I1004 21:57:47.434324 15504 solver.cpp:218] Iteration 22900 (43.8701 iter/s, 2.27945s/100 iters), loss = 0.439956
I1004 21:57:47.434324 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:57:47.434324 15504 solver.cpp:237]     Train net output #1: loss = 0.439956 (* 1 = 0.439956 loss)
I1004 21:57:47.434324 15504 sgd_solver.cpp:105] Iteration 22900, lr = 1e-05
I1004 21:57:49.607069 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:57:49.697690 15504 solver.cpp:330] Iteration 23000, Testing net (#0)
I1004 21:57:49.697690 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:57:50.105212  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:57:50.120837 15504 solver.cpp:397]     Test net output #0: accuracy = 0.773
I1004 21:57:50.120837 15504 solver.cpp:397]     Test net output #1: loss = 0.664467 (* 1 = 0.664467 loss)
I1004 21:57:50.152086 15504 solver.cpp:218] Iteration 23000 (36.761 iter/s, 2.72027s/100 iters), loss = 0.523738
I1004 21:57:50.152086 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1004 21:57:50.152086 15504 solver.cpp:237]     Train net output #1: loss = 0.523738 (* 1 = 0.523738 loss)
I1004 21:57:50.152086 15504 sgd_solver.cpp:105] Iteration 23000, lr = 1e-05
I1004 21:57:52.430021 15504 solver.cpp:218] Iteration 23100 (43.9469 iter/s, 2.27547s/100 iters), loss = 0.426808
I1004 21:57:52.430021 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:57:52.430021 15504 solver.cpp:237]     Train net output #1: loss = 0.426808 (* 1 = 0.426808 loss)
I1004 21:57:52.430021 15504 sgd_solver.cpp:105] Iteration 23100, lr = 1e-05
I1004 21:57:54.693893 15504 solver.cpp:218] Iteration 23200 (43.9667 iter/s, 2.27445s/100 iters), loss = 0.451954
I1004 21:57:54.693893 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:57:54.693893 15504 solver.cpp:237]     Train net output #1: loss = 0.451954 (* 1 = 0.451954 loss)
I1004 21:57:54.693893 15504 sgd_solver.cpp:105] Iteration 23200, lr = 1e-05
I1004 21:57:56.972106 15504 solver.cpp:218] Iteration 23300 (43.9184 iter/s, 2.27695s/100 iters), loss = 0.564736
I1004 21:57:56.972106 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:57:56.972106 15504 solver.cpp:237]     Train net output #1: loss = 0.564736 (* 1 = 0.564736 loss)
I1004 21:57:56.972106 15504 sgd_solver.cpp:105] Iteration 23300, lr = 1e-05
I1004 21:57:59.250494 15504 solver.cpp:218] Iteration 23400 (43.8329 iter/s, 2.28139s/100 iters), loss = 0.434559
I1004 21:57:59.250494 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:57:59.250494 15504 solver.cpp:237]     Train net output #1: loss = 0.434559 (* 1 = 0.434559 loss)
I1004 21:57:59.250494 15504 sgd_solver.cpp:105] Iteration 23400, lr = 1e-05
I1004 21:58:01.434772 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:58:01.544147 15504 solver.cpp:218] Iteration 23500 (43.731 iter/s, 2.28671s/100 iters), loss = 0.450276
I1004 21:58:01.544147 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:58:01.544147 15504 solver.cpp:237]     Train net output #1: loss = 0.450276 (* 1 = 0.450276 loss)
I1004 21:58:01.544147 15504 sgd_solver.cpp:105] Iteration 23500, lr = 1e-05
I1004 21:58:03.827726 15504 solver.cpp:218] Iteration 23600 (43.9315 iter/s, 2.27627s/100 iters), loss = 0.394709
I1004 21:58:03.827726 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:58:03.827726 15504 solver.cpp:237]     Train net output #1: loss = 0.394709 (* 1 = 0.394709 loss)
I1004 21:58:03.827726 15504 sgd_solver.cpp:105] Iteration 23600, lr = 1e-05
I1004 21:58:06.109580 15504 solver.cpp:218] Iteration 23700 (43.7331 iter/s, 2.2866s/100 iters), loss = 0.423145
I1004 21:58:06.109580 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:58:06.109580 15504 solver.cpp:237]     Train net output #1: loss = 0.423145 (* 1 = 0.423145 loss)
I1004 21:58:06.109580 15504 sgd_solver.cpp:105] Iteration 23700, lr = 1e-05
I1004 21:58:08.392241 15504 solver.cpp:218] Iteration 23800 (43.7642 iter/s, 2.28497s/100 iters), loss = 0.556375
I1004 21:58:08.392241 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1004 21:58:08.392241 15504 solver.cpp:237]     Train net output #1: loss = 0.556375 (* 1 = 0.556375 loss)
I1004 21:58:08.392241 15504 sgd_solver.cpp:105] Iteration 23800, lr = 1e-05
I1004 21:58:10.673436 15504 solver.cpp:218] Iteration 23900 (43.9903 iter/s, 2.27323s/100 iters), loss = 0.432722
I1004 21:58:10.673436 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1004 21:58:10.673436 15504 solver.cpp:237]     Train net output #1: loss = 0.432722 (* 1 = 0.432722 loss)
I1004 21:58:10.673436 15504 sgd_solver.cpp:105] Iteration 23900, lr = 1e-05
I1004 21:58:12.836871 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:58:12.935200 15504 solver.cpp:330] Iteration 24000, Testing net (#0)
I1004 21:58:12.935200 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:58:13.351205  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:58:13.366832 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7728
I1004 21:58:13.366832 15504 solver.cpp:397]     Test net output #1: loss = 0.66451 (* 1 = 0.66451 loss)
I1004 21:58:13.382455 15504 solver.cpp:218] Iteration 24000 (36.7582 iter/s, 2.72048s/100 iters), loss = 0.444394
I1004 21:58:13.382455 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:58:13.382455 15504 solver.cpp:237]     Train net output #1: loss = 0.444394 (* 1 = 0.444394 loss)
I1004 21:58:13.382455 15504 sgd_solver.cpp:105] Iteration 24000, lr = 1e-05
I1004 21:58:15.675153 15504 solver.cpp:218] Iteration 24100 (43.8565 iter/s, 2.28016s/100 iters), loss = 0.433672
I1004 21:58:15.675153 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1004 21:58:15.675153 15504 solver.cpp:237]     Train net output #1: loss = 0.433672 (* 1 = 0.433672 loss)
I1004 21:58:15.675153 15504 sgd_solver.cpp:105] Iteration 24100, lr = 1e-05
I1004 21:58:17.958684 15504 solver.cpp:218] Iteration 24200 (43.757 iter/s, 2.28535s/100 iters), loss = 0.476917
I1004 21:58:17.958684 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:58:17.958684 15504 solver.cpp:237]     Train net output #1: loss = 0.476917 (* 1 = 0.476917 loss)
I1004 21:58:17.958684 15504 sgd_solver.cpp:105] Iteration 24200, lr = 1e-05
I1004 21:58:20.261399 15504 solver.cpp:218] Iteration 24300 (43.4617 iter/s, 2.30088s/100 iters), loss = 0.537505
I1004 21:58:20.261399 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1004 21:58:20.261399 15504 solver.cpp:237]     Train net output #1: loss = 0.537505 (* 1 = 0.537505 loss)
I1004 21:58:20.261399 15504 sgd_solver.cpp:105] Iteration 24300, lr = 1e-05
I1004 21:58:22.528035 15504 solver.cpp:218] Iteration 24400 (43.8679 iter/s, 2.27957s/100 iters), loss = 0.439413
I1004 21:58:22.528035 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1004 21:58:22.528035 15504 solver.cpp:237]     Train net output #1: loss = 0.439413 (* 1 = 0.439413 loss)
I1004 21:58:22.528035 15504 sgd_solver.cpp:105] Iteration 24400, lr = 1e-05
I1004 21:58:24.724421 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:58:24.833787 15504 solver.cpp:218] Iteration 24500 (43.5965 iter/s, 2.29376s/100 iters), loss = 0.471565
I1004 21:58:24.833787 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1004 21:58:24.833787 15504 solver.cpp:237]     Train net output #1: loss = 0.471565 (* 1 = 0.471565 loss)
I1004 21:58:24.833787 15504 sgd_solver.cpp:105] Iteration 24500, lr = 1e-05
I1004 21:58:27.122367 15504 solver.cpp:218] Iteration 24600 (43.6486 iter/s, 2.29102s/100 iters), loss = 0.438369
I1004 21:58:27.122367 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1004 21:58:27.122367 15504 solver.cpp:237]     Train net output #1: loss = 0.438369 (* 1 = 0.438369 loss)
I1004 21:58:27.122367 15504 sgd_solver.cpp:105] Iteration 24600, lr = 1e-05
I1004 21:58:29.404796 15504 solver.cpp:218] Iteration 24700 (43.7824 iter/s, 2.28402s/100 iters), loss = 0.467486
I1004 21:58:29.404796 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1004 21:58:29.404796 15504 solver.cpp:237]     Train net output #1: loss = 0.467486 (* 1 = 0.467486 loss)
I1004 21:58:29.404796 15504 sgd_solver.cpp:105] Iteration 24700, lr = 1e-05
I1004 21:58:31.672616 15504 solver.cpp:218] Iteration 24800 (43.9468 iter/s, 2.27548s/100 iters), loss = 0.562794
I1004 21:58:31.672616 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:58:31.672616 15504 solver.cpp:237]     Train net output #1: loss = 0.562794 (* 1 = 0.562794 loss)
I1004 21:58:31.672616 15504 sgd_solver.cpp:105] Iteration 24800, lr = 1e-05
I1004 21:58:33.967092 15504 solver.cpp:218] Iteration 24900 (43.87 iter/s, 2.27946s/100 iters), loss = 0.449801
I1004 21:58:33.967092 15504 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1004 21:58:33.967092 15504 solver.cpp:237]     Train net output #1: loss = 0.449801 (* 1 = 0.449801 loss)
I1004 21:58:33.967092 15504 sgd_solver.cpp:105] Iteration 24900, lr = 1e-05
I1004 21:58:36.161211 16316 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:58:36.253209 15504 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/slimnet_simpnet_P3_iter_25000.caffemodel
I1004 21:58:36.262209 15504 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_simpnet_P3_iter_25000.solverstate
I1004 21:58:36.268209 15504 solver.cpp:310] Iteration 25000, loss = 0.510669
I1004 21:58:36.268209 15504 solver.cpp:330] Iteration 25000, Testing net (#0)
I1004 21:58:36.268209 15504 net.cpp:676] Ignoring source layer accuracy_training
I1004 21:58:36.684505  6484 data_layer.cpp:73] Restarting data prefetching from start.
I1004 21:58:36.700130 15504 solver.cpp:397]     Test net output #0: accuracy = 0.7723
I1004 21:58:36.700130 15504 solver.cpp:397]     Test net output #1: loss = 0.664407 (* 1 = 0.664407 loss)
I1004 21:58:36.700130 15504 solver.cpp:315] Optimization Done.
I1004 21:58:36.700130 15504 caffe.cpp:260] Optimization Done.

G:\Caffe>pause
Press any key to continue . . . 
