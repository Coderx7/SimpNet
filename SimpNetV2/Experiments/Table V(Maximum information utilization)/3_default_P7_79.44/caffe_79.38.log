
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I1005 00:29:11.599665 17840 caffe.cpp:219] Using GPUs 0
I1005 00:29:11.780506 17840 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1005 00:29:12.068505 17840 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 00:29:12.084504 17840 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 25000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 25000
snapshot_prefix: "examples/cifar10/slimnet_simpnet_p7"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 25000
type: "Nesterov"
I1005 00:29:12.084504 17840 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 00:29:12.085505 17840 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 00:29:12.085505 17840 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1005 00:29:12.085505 17840 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1005 00:29:12.085505 17840 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P7"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1005 00:29:12.105504 17840 layer_factory.cpp:58] Creating layer cifar
I1005 00:29:12.111522 17840 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I1005 00:29:12.111522 17840 net.cpp:84] Creating Layer cifar
I1005 00:29:12.111522 17840 net.cpp:380] cifar -> data
I1005 00:29:12.111522 17840 net.cpp:380] cifar -> label
I1005 00:29:12.111522 17840 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1005 00:29:12.113505 17840 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 00:29:12.113505 17840 data_layer.cpp:45] output data size: 100,3,32,32
I1005 00:29:12.118505 17840 net.cpp:122] Setting up cifar
I1005 00:29:12.118505 17840 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1005 00:29:12.118505 17840 net.cpp:129] Top shape: 100 (100)
I1005 00:29:12.118505 17840 net.cpp:137] Memory required for data: 1229200
I1005 00:29:12.118505 17840 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1005 00:29:12.118505 17840 net.cpp:84] Creating Layer label_cifar_1_split
I1005 00:29:12.118505 17840 net.cpp:406] label_cifar_1_split <- label
I1005 00:29:12.118505 17840 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1005 00:29:12.118505 17840 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1005 00:29:12.118505 17840 net.cpp:122] Setting up label_cifar_1_split
I1005 00:29:12.118505 17840 net.cpp:129] Top shape: 100 (100)
I1005 00:29:12.118505 17840 net.cpp:129] Top shape: 100 (100)
I1005 00:29:12.118505 17840 net.cpp:137] Memory required for data: 1230000
I1005 00:29:12.118505 17840 layer_factory.cpp:58] Creating layer conv1
I1005 00:29:12.118505 17840 net.cpp:84] Creating Layer conv1
I1005 00:29:12.118505 17840 net.cpp:406] conv1 <- data
I1005 00:29:12.118505 17840 net.cpp:380] conv1 -> conv1
I1005 00:29:12.119503  2364 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 00:29:12.359505 17840 net.cpp:122] Setting up conv1
I1005 00:29:12.359505 17840 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:29:12.359505 17840 net.cpp:137] Memory required for data: 3687600
I1005 00:29:12.359505 17840 layer_factory.cpp:58] Creating layer bn1
I1005 00:29:12.359505 17840 net.cpp:84] Creating Layer bn1
I1005 00:29:12.359505 17840 net.cpp:406] bn1 <- conv1
I1005 00:29:12.359505 17840 net.cpp:367] bn1 -> conv1 (in-place)
I1005 00:29:12.359505 17840 net.cpp:122] Setting up bn1
I1005 00:29:12.359505 17840 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:29:12.359505 17840 net.cpp:137] Memory required for data: 6145200
I1005 00:29:12.359505 17840 layer_factory.cpp:58] Creating layer scale1
I1005 00:29:12.359505 17840 net.cpp:84] Creating Layer scale1
I1005 00:29:12.359505 17840 net.cpp:406] scale1 <- conv1
I1005 00:29:12.359505 17840 net.cpp:367] scale1 -> conv1 (in-place)
I1005 00:29:12.359505 17840 layer_factory.cpp:58] Creating layer scale1
I1005 00:29:12.359505 17840 net.cpp:122] Setting up scale1
I1005 00:29:12.359505 17840 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:29:12.359505 17840 net.cpp:137] Memory required for data: 8602800
I1005 00:29:12.359505 17840 layer_factory.cpp:58] Creating layer relu1
I1005 00:29:12.359505 17840 net.cpp:84] Creating Layer relu1
I1005 00:29:12.359505 17840 net.cpp:406] relu1 <- conv1
I1005 00:29:12.359505 17840 net.cpp:367] relu1 -> conv1 (in-place)
I1005 00:29:12.360505 17840 net.cpp:122] Setting up relu1
I1005 00:29:12.360505 17840 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:29:12.360505 17840 net.cpp:137] Memory required for data: 11060400
I1005 00:29:12.360505 17840 layer_factory.cpp:58] Creating layer conv1_0
I1005 00:29:12.360505 17840 net.cpp:84] Creating Layer conv1_0
I1005 00:29:12.360505 17840 net.cpp:406] conv1_0 <- conv1
I1005 00:29:12.360505 17840 net.cpp:380] conv1_0 -> conv1_0
I1005 00:29:12.361505 17840 net.cpp:122] Setting up conv1_0
I1005 00:29:12.361505 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.361505 17840 net.cpp:137] Memory required for data: 15975600
I1005 00:29:12.361505 17840 layer_factory.cpp:58] Creating layer bn1_0
I1005 00:29:12.361505 17840 net.cpp:84] Creating Layer bn1_0
I1005 00:29:12.361505 17840 net.cpp:406] bn1_0 <- conv1_0
I1005 00:29:12.361505 17840 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1005 00:29:12.361505 17840 net.cpp:122] Setting up bn1_0
I1005 00:29:12.361505 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.361505 17840 net.cpp:137] Memory required for data: 20890800
I1005 00:29:12.361505 17840 layer_factory.cpp:58] Creating layer scale1_0
I1005 00:29:12.361505 17840 net.cpp:84] Creating Layer scale1_0
I1005 00:29:12.361505 17840 net.cpp:406] scale1_0 <- conv1_0
I1005 00:29:12.361505 17840 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1005 00:29:12.361505 17840 layer_factory.cpp:58] Creating layer scale1_0
I1005 00:29:12.361505 17840 net.cpp:122] Setting up scale1_0
I1005 00:29:12.361505 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.361505 17840 net.cpp:137] Memory required for data: 25806000
I1005 00:29:12.361505 17840 layer_factory.cpp:58] Creating layer relu1_0
I1005 00:29:12.361505 17840 net.cpp:84] Creating Layer relu1_0
I1005 00:29:12.361505 17840 net.cpp:406] relu1_0 <- conv1_0
I1005 00:29:12.361505 17840 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1005 00:29:12.362504 17840 net.cpp:122] Setting up relu1_0
I1005 00:29:12.362504 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.362504 17840 net.cpp:137] Memory required for data: 30721200
I1005 00:29:12.362504 17840 layer_factory.cpp:58] Creating layer conv2
I1005 00:29:12.362504 17840 net.cpp:84] Creating Layer conv2
I1005 00:29:12.362504 17840 net.cpp:406] conv2 <- conv1_0
I1005 00:29:12.362504 17840 net.cpp:380] conv2 -> conv2
I1005 00:29:12.362504 17840 net.cpp:122] Setting up conv2
I1005 00:29:12.362504 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.362504 17840 net.cpp:137] Memory required for data: 35636400
I1005 00:29:12.362504 17840 layer_factory.cpp:58] Creating layer bn2
I1005 00:29:12.362504 17840 net.cpp:84] Creating Layer bn2
I1005 00:29:12.363505 17840 net.cpp:406] bn2 <- conv2
I1005 00:29:12.363505 17840 net.cpp:367] bn2 -> conv2 (in-place)
I1005 00:29:12.363505 17840 net.cpp:122] Setting up bn2
I1005 00:29:12.363505 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.363505 17840 net.cpp:137] Memory required for data: 40551600
I1005 00:29:12.363505 17840 layer_factory.cpp:58] Creating layer scale2
I1005 00:29:12.363505 17840 net.cpp:84] Creating Layer scale2
I1005 00:29:12.363505 17840 net.cpp:406] scale2 <- conv2
I1005 00:29:12.363505 17840 net.cpp:367] scale2 -> conv2 (in-place)
I1005 00:29:12.363505 17840 layer_factory.cpp:58] Creating layer scale2
I1005 00:29:12.363505 17840 net.cpp:122] Setting up scale2
I1005 00:29:12.363505 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.363505 17840 net.cpp:137] Memory required for data: 45466800
I1005 00:29:12.363505 17840 layer_factory.cpp:58] Creating layer relu2
I1005 00:29:12.363505 17840 net.cpp:84] Creating Layer relu2
I1005 00:29:12.363505 17840 net.cpp:406] relu2 <- conv2
I1005 00:29:12.363505 17840 net.cpp:367] relu2 -> conv2 (in-place)
I1005 00:29:12.363505 17840 net.cpp:122] Setting up relu2
I1005 00:29:12.363505 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.363505 17840 net.cpp:137] Memory required for data: 50382000
I1005 00:29:12.363505 17840 layer_factory.cpp:58] Creating layer conv2_1
I1005 00:29:12.363505 17840 net.cpp:84] Creating Layer conv2_1
I1005 00:29:12.363505 17840 net.cpp:406] conv2_1 <- conv2
I1005 00:29:12.363505 17840 net.cpp:380] conv2_1 -> conv2_1
I1005 00:29:12.364504 17840 net.cpp:122] Setting up conv2_1
I1005 00:29:12.364504 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.364504 17840 net.cpp:137] Memory required for data: 55297200
I1005 00:29:12.364504 17840 layer_factory.cpp:58] Creating layer bn2_1
I1005 00:29:12.364504 17840 net.cpp:84] Creating Layer bn2_1
I1005 00:29:12.364504 17840 net.cpp:406] bn2_1 <- conv2_1
I1005 00:29:12.364504 17840 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1005 00:29:12.365504 17840 net.cpp:122] Setting up bn2_1
I1005 00:29:12.365504 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.365504 17840 net.cpp:137] Memory required for data: 60212400
I1005 00:29:12.365504 17840 layer_factory.cpp:58] Creating layer scale2_1
I1005 00:29:12.365504 17840 net.cpp:84] Creating Layer scale2_1
I1005 00:29:12.365504 17840 net.cpp:406] scale2_1 <- conv2_1
I1005 00:29:12.365504 17840 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1005 00:29:12.365504 17840 layer_factory.cpp:58] Creating layer scale2_1
I1005 00:29:12.365504 17840 net.cpp:122] Setting up scale2_1
I1005 00:29:12.365504 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.365504 17840 net.cpp:137] Memory required for data: 65127600
I1005 00:29:12.365504 17840 layer_factory.cpp:58] Creating layer relu2_1
I1005 00:29:12.365504 17840 net.cpp:84] Creating Layer relu2_1
I1005 00:29:12.365504 17840 net.cpp:406] relu2_1 <- conv2_1
I1005 00:29:12.365504 17840 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1005 00:29:12.365504 17840 net.cpp:122] Setting up relu2_1
I1005 00:29:12.365504 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.365504 17840 net.cpp:137] Memory required for data: 70042800
I1005 00:29:12.365504 17840 layer_factory.cpp:58] Creating layer conv2_2
I1005 00:29:12.365504 17840 net.cpp:84] Creating Layer conv2_2
I1005 00:29:12.365504 17840 net.cpp:406] conv2_2 <- conv2_1
I1005 00:29:12.365504 17840 net.cpp:380] conv2_2 -> conv2_2
I1005 00:29:12.366504 17840 net.cpp:122] Setting up conv2_2
I1005 00:29:12.366504 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.366504 17840 net.cpp:137] Memory required for data: 77825200
I1005 00:29:12.366504 17840 layer_factory.cpp:58] Creating layer bn2_2
I1005 00:29:12.366504 17840 net.cpp:84] Creating Layer bn2_2
I1005 00:29:12.366504 17840 net.cpp:406] bn2_2 <- conv2_2
I1005 00:29:12.366504 17840 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1005 00:29:12.366504 17840 net.cpp:122] Setting up bn2_2
I1005 00:29:12.366504 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.366504 17840 net.cpp:137] Memory required for data: 85607600
I1005 00:29:12.366504 17840 layer_factory.cpp:58] Creating layer scale2_2
I1005 00:29:12.366504 17840 net.cpp:84] Creating Layer scale2_2
I1005 00:29:12.366504 17840 net.cpp:406] scale2_2 <- conv2_2
I1005 00:29:12.366504 17840 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1005 00:29:12.366504 17840 layer_factory.cpp:58] Creating layer scale2_2
I1005 00:29:12.366504 17840 net.cpp:122] Setting up scale2_2
I1005 00:29:12.366504 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.366504 17840 net.cpp:137] Memory required for data: 93390000
I1005 00:29:12.366504 17840 layer_factory.cpp:58] Creating layer relu2_2
I1005 00:29:12.366504 17840 net.cpp:84] Creating Layer relu2_2
I1005 00:29:12.366504 17840 net.cpp:406] relu2_2 <- conv2_2
I1005 00:29:12.366504 17840 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1005 00:29:12.367504 17840 net.cpp:122] Setting up relu2_2
I1005 00:29:12.367504 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.367504 17840 net.cpp:137] Memory required for data: 101172400
I1005 00:29:12.367504 17840 layer_factory.cpp:58] Creating layer conv3
I1005 00:29:12.367504 17840 net.cpp:84] Creating Layer conv3
I1005 00:29:12.367504 17840 net.cpp:406] conv3 <- conv2_2
I1005 00:29:12.367504 17840 net.cpp:380] conv3 -> conv3
I1005 00:29:12.368505 17840 net.cpp:122] Setting up conv3
I1005 00:29:12.368505 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.368505 17840 net.cpp:137] Memory required for data: 108954800
I1005 00:29:12.368505 17840 layer_factory.cpp:58] Creating layer bn3
I1005 00:29:12.368505 17840 net.cpp:84] Creating Layer bn3
I1005 00:29:12.368505 17840 net.cpp:406] bn3 <- conv3
I1005 00:29:12.368505 17840 net.cpp:367] bn3 -> conv3 (in-place)
I1005 00:29:12.368505 17840 net.cpp:122] Setting up bn3
I1005 00:29:12.368505 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.368505 17840 net.cpp:137] Memory required for data: 116737200
I1005 00:29:12.368505 17840 layer_factory.cpp:58] Creating layer scale3
I1005 00:29:12.368505 17840 net.cpp:84] Creating Layer scale3
I1005 00:29:12.368505 17840 net.cpp:406] scale3 <- conv3
I1005 00:29:12.368505 17840 net.cpp:367] scale3 -> conv3 (in-place)
I1005 00:29:12.368505 17840 layer_factory.cpp:58] Creating layer scale3
I1005 00:29:12.368505 17840 net.cpp:122] Setting up scale3
I1005 00:29:12.368505 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.368505 17840 net.cpp:137] Memory required for data: 124519600
I1005 00:29:12.368505 17840 layer_factory.cpp:58] Creating layer relu3
I1005 00:29:12.368505 17840 net.cpp:84] Creating Layer relu3
I1005 00:29:12.368505 17840 net.cpp:406] relu3 <- conv3
I1005 00:29:12.368505 17840 net.cpp:367] relu3 -> conv3 (in-place)
I1005 00:29:12.368505 17840 net.cpp:122] Setting up relu3
I1005 00:29:12.368505 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.368505 17840 net.cpp:137] Memory required for data: 132302000
I1005 00:29:12.368505 17840 layer_factory.cpp:58] Creating layer conv3_1
I1005 00:29:12.368505 17840 net.cpp:84] Creating Layer conv3_1
I1005 00:29:12.368505 17840 net.cpp:406] conv3_1 <- conv3
I1005 00:29:12.368505 17840 net.cpp:380] conv3_1 -> conv3_1
I1005 00:29:12.369505 17840 net.cpp:122] Setting up conv3_1
I1005 00:29:12.369505 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.369505 17840 net.cpp:137] Memory required for data: 140084400
I1005 00:29:12.369505 17840 layer_factory.cpp:58] Creating layer bn3_1
I1005 00:29:12.369505 17840 net.cpp:84] Creating Layer bn3_1
I1005 00:29:12.369505 17840 net.cpp:406] bn3_1 <- conv3_1
I1005 00:29:12.369505 17840 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1005 00:29:12.370507 17840 net.cpp:122] Setting up bn3_1
I1005 00:29:12.370507 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.370507 17840 net.cpp:137] Memory required for data: 147866800
I1005 00:29:12.370507 17840 layer_factory.cpp:58] Creating layer scale3_1
I1005 00:29:12.370507 17840 net.cpp:84] Creating Layer scale3_1
I1005 00:29:12.370507 17840 net.cpp:406] scale3_1 <- conv3_1
I1005 00:29:12.370507 17840 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1005 00:29:12.370507 17840 layer_factory.cpp:58] Creating layer scale3_1
I1005 00:29:12.370507 17840 net.cpp:122] Setting up scale3_1
I1005 00:29:12.370507 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.370507 17840 net.cpp:137] Memory required for data: 155649200
I1005 00:29:12.370507 17840 layer_factory.cpp:58] Creating layer relu3_1
I1005 00:29:12.370507 17840 net.cpp:84] Creating Layer relu3_1
I1005 00:29:12.370507 17840 net.cpp:406] relu3_1 <- conv3_1
I1005 00:29:12.370507 17840 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1005 00:29:12.370507 17840 net.cpp:122] Setting up relu3_1
I1005 00:29:12.370507 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.370507 17840 net.cpp:137] Memory required for data: 163431600
I1005 00:29:12.370507 17840 layer_factory.cpp:58] Creating layer pool2_1
I1005 00:29:12.370507 17840 net.cpp:84] Creating Layer pool2_1
I1005 00:29:12.370507 17840 net.cpp:406] pool2_1 <- conv3_1
I1005 00:29:12.370507 17840 net.cpp:380] pool2_1 -> pool2_1
I1005 00:29:12.370507 17840 net.cpp:122] Setting up pool2_1
I1005 00:29:12.370507 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.370507 17840 net.cpp:137] Memory required for data: 165377200
I1005 00:29:12.370507 17840 layer_factory.cpp:58] Creating layer conv4
I1005 00:29:12.370507 17840 net.cpp:84] Creating Layer conv4
I1005 00:29:12.370507 17840 net.cpp:406] conv4 <- pool2_1
I1005 00:29:12.370507 17840 net.cpp:380] conv4 -> conv4
I1005 00:29:12.371505 17840 net.cpp:122] Setting up conv4
I1005 00:29:12.371505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.371505 17840 net.cpp:137] Memory required for data: 167322800
I1005 00:29:12.371505 17840 layer_factory.cpp:58] Creating layer bn4
I1005 00:29:12.371505 17840 net.cpp:84] Creating Layer bn4
I1005 00:29:12.371505 17840 net.cpp:406] bn4 <- conv4
I1005 00:29:12.371505 17840 net.cpp:367] bn4 -> conv4 (in-place)
I1005 00:29:12.371505 17840 net.cpp:122] Setting up bn4
I1005 00:29:12.371505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.371505 17840 net.cpp:137] Memory required for data: 169268400
I1005 00:29:12.371505 17840 layer_factory.cpp:58] Creating layer scale4
I1005 00:29:12.371505 17840 net.cpp:84] Creating Layer scale4
I1005 00:29:12.371505 17840 net.cpp:406] scale4 <- conv4
I1005 00:29:12.371505 17840 net.cpp:367] scale4 -> conv4 (in-place)
I1005 00:29:12.372505 17840 layer_factory.cpp:58] Creating layer scale4
I1005 00:29:12.372505 17840 net.cpp:122] Setting up scale4
I1005 00:29:12.372505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.372505 17840 net.cpp:137] Memory required for data: 171214000
I1005 00:29:12.372505 17840 layer_factory.cpp:58] Creating layer relu4
I1005 00:29:12.372505 17840 net.cpp:84] Creating Layer relu4
I1005 00:29:12.372505 17840 net.cpp:406] relu4 <- conv4
I1005 00:29:12.372505 17840 net.cpp:367] relu4 -> conv4 (in-place)
I1005 00:29:12.372505 17840 net.cpp:122] Setting up relu4
I1005 00:29:12.372505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.372505 17840 net.cpp:137] Memory required for data: 173159600
I1005 00:29:12.372505 17840 layer_factory.cpp:58] Creating layer conv4_1
I1005 00:29:12.372505 17840 net.cpp:84] Creating Layer conv4_1
I1005 00:29:12.372505 17840 net.cpp:406] conv4_1 <- conv4
I1005 00:29:12.372505 17840 net.cpp:380] conv4_1 -> conv4_1
I1005 00:29:12.373505 17840 net.cpp:122] Setting up conv4_1
I1005 00:29:12.373505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.373505 17840 net.cpp:137] Memory required for data: 175105200
I1005 00:29:12.373505 17840 layer_factory.cpp:58] Creating layer bn4_1
I1005 00:29:12.373505 17840 net.cpp:84] Creating Layer bn4_1
I1005 00:29:12.373505 17840 net.cpp:406] bn4_1 <- conv4_1
I1005 00:29:12.373505 17840 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1005 00:29:12.373505 17840 net.cpp:122] Setting up bn4_1
I1005 00:29:12.373505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.373505 17840 net.cpp:137] Memory required for data: 177050800
I1005 00:29:12.373505 17840 layer_factory.cpp:58] Creating layer scale4_1
I1005 00:29:12.373505 17840 net.cpp:84] Creating Layer scale4_1
I1005 00:29:12.373505 17840 net.cpp:406] scale4_1 <- conv4_1
I1005 00:29:12.373505 17840 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1005 00:29:12.373505 17840 layer_factory.cpp:58] Creating layer scale4_1
I1005 00:29:12.373505 17840 net.cpp:122] Setting up scale4_1
I1005 00:29:12.373505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.374505 17840 net.cpp:137] Memory required for data: 178996400
I1005 00:29:12.374505 17840 layer_factory.cpp:58] Creating layer relu4_1
I1005 00:29:12.374505 17840 net.cpp:84] Creating Layer relu4_1
I1005 00:29:12.374505 17840 net.cpp:406] relu4_1 <- conv4_1
I1005 00:29:12.374505 17840 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1005 00:29:12.374505 17840 net.cpp:122] Setting up relu4_1
I1005 00:29:12.374505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.374505 17840 net.cpp:137] Memory required for data: 180942000
I1005 00:29:12.374505 17840 layer_factory.cpp:58] Creating layer conv4_2
I1005 00:29:12.374505 17840 net.cpp:84] Creating Layer conv4_2
I1005 00:29:12.374505 17840 net.cpp:406] conv4_2 <- conv4_1
I1005 00:29:12.374505 17840 net.cpp:380] conv4_2 -> conv4_2
I1005 00:29:12.376505 17840 net.cpp:122] Setting up conv4_2
I1005 00:29:12.376505 17840 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:29:12.376505 17840 net.cpp:137] Memory required for data: 183809200
I1005 00:29:12.376505 17840 layer_factory.cpp:58] Creating layer bn4_2
I1005 00:29:12.376505 17840 net.cpp:84] Creating Layer bn4_2
I1005 00:29:12.376505 17840 net.cpp:406] bn4_2 <- conv4_2
I1005 00:29:12.376505 17840 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1005 00:29:12.376505 17840 net.cpp:122] Setting up bn4_2
I1005 00:29:12.376505 17840 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:29:12.376505 17840 net.cpp:137] Memory required for data: 186676400
I1005 00:29:12.376505 17840 layer_factory.cpp:58] Creating layer scale4_2
I1005 00:29:12.376505 17840 net.cpp:84] Creating Layer scale4_2
I1005 00:29:12.376505 17840 net.cpp:406] scale4_2 <- conv4_2
I1005 00:29:12.376505 17840 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1005 00:29:12.376505 17840 layer_factory.cpp:58] Creating layer scale4_2
I1005 00:29:12.376505 17840 net.cpp:122] Setting up scale4_2
I1005 00:29:12.376505 17840 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:29:12.376505 17840 net.cpp:137] Memory required for data: 189543600
I1005 00:29:12.376505 17840 layer_factory.cpp:58] Creating layer relu4_2
I1005 00:29:12.376505 17840 net.cpp:84] Creating Layer relu4_2
I1005 00:29:12.376505 17840 net.cpp:406] relu4_2 <- conv4_2
I1005 00:29:12.376505 17840 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1005 00:29:12.376505 17840 net.cpp:122] Setting up relu4_2
I1005 00:29:12.376505 17840 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:29:12.376505 17840 net.cpp:137] Memory required for data: 192410800
I1005 00:29:12.376505 17840 layer_factory.cpp:58] Creating layer pool4_2
I1005 00:29:12.376505 17840 net.cpp:84] Creating Layer pool4_2
I1005 00:29:12.376505 17840 net.cpp:406] pool4_2 <- conv4_2
I1005 00:29:12.376505 17840 net.cpp:380] pool4_2 -> pool4_2
I1005 00:29:12.376505 17840 net.cpp:122] Setting up pool4_2
I1005 00:29:12.376505 17840 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:29:12.376505 17840 net.cpp:137] Memory required for data: 193127600
I1005 00:29:12.376505 17840 layer_factory.cpp:58] Creating layer conv4_0
I1005 00:29:12.376505 17840 net.cpp:84] Creating Layer conv4_0
I1005 00:29:12.376505 17840 net.cpp:406] conv4_0 <- pool4_2
I1005 00:29:12.376505 17840 net.cpp:380] conv4_0 -> conv4_0
I1005 00:29:12.378504 17840 net.cpp:122] Setting up conv4_0
I1005 00:29:12.378504 17840 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:29:12.378504 17840 net.cpp:137] Memory required for data: 193844400
I1005 00:29:12.378504 17840 layer_factory.cpp:58] Creating layer bn4_0
I1005 00:29:12.378504 17840 net.cpp:84] Creating Layer bn4_0
I1005 00:29:12.378504 17840 net.cpp:406] bn4_0 <- conv4_0
I1005 00:29:12.378504 17840 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1005 00:29:12.378504 17840 net.cpp:122] Setting up bn4_0
I1005 00:29:12.378504 17840 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:29:12.378504 17840 net.cpp:137] Memory required for data: 194561200
I1005 00:29:12.378504 17840 layer_factory.cpp:58] Creating layer scale4_0
I1005 00:29:12.378504 17840 net.cpp:84] Creating Layer scale4_0
I1005 00:29:12.378504 17840 net.cpp:406] scale4_0 <- conv4_0
I1005 00:29:12.378504 17840 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1005 00:29:12.378504 17840 layer_factory.cpp:58] Creating layer scale4_0
I1005 00:29:12.378504 17840 net.cpp:122] Setting up scale4_0
I1005 00:29:12.378504 17840 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:29:12.378504 17840 net.cpp:137] Memory required for data: 195278000
I1005 00:29:12.378504 17840 layer_factory.cpp:58] Creating layer relu4_0
I1005 00:29:12.378504 17840 net.cpp:84] Creating Layer relu4_0
I1005 00:29:12.378504 17840 net.cpp:406] relu4_0 <- conv4_0
I1005 00:29:12.378504 17840 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1005 00:29:12.378504 17840 net.cpp:122] Setting up relu4_0
I1005 00:29:12.378504 17840 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:29:12.378504 17840 net.cpp:137] Memory required for data: 195994800
I1005 00:29:12.378504 17840 layer_factory.cpp:58] Creating layer conv11
I1005 00:29:12.378504 17840 net.cpp:84] Creating Layer conv11
I1005 00:29:12.378504 17840 net.cpp:406] conv11 <- conv4_0
I1005 00:29:12.378504 17840 net.cpp:380] conv11 -> conv11
I1005 00:29:12.379505 17840 net.cpp:122] Setting up conv11
I1005 00:29:12.379505 17840 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:29:12.379505 17840 net.cpp:137] Memory required for data: 196890800
I1005 00:29:12.379505 17840 layer_factory.cpp:58] Creating layer bn_conv11
I1005 00:29:12.379505 17840 net.cpp:84] Creating Layer bn_conv11
I1005 00:29:12.379505 17840 net.cpp:406] bn_conv11 <- conv11
I1005 00:29:12.379505 17840 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1005 00:29:12.380504 17840 net.cpp:122] Setting up bn_conv11
I1005 00:29:12.380504 17840 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:29:12.380504 17840 net.cpp:137] Memory required for data: 197786800
I1005 00:29:12.380504 17840 layer_factory.cpp:58] Creating layer scale_conv11
I1005 00:29:12.380504 17840 net.cpp:84] Creating Layer scale_conv11
I1005 00:29:12.380504 17840 net.cpp:406] scale_conv11 <- conv11
I1005 00:29:12.380504 17840 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1005 00:29:12.380504 17840 layer_factory.cpp:58] Creating layer scale_conv11
I1005 00:29:12.380504 17840 net.cpp:122] Setting up scale_conv11
I1005 00:29:12.380504 17840 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:29:12.380504 17840 net.cpp:137] Memory required for data: 198682800
I1005 00:29:12.380504 17840 layer_factory.cpp:58] Creating layer relu_conv11
I1005 00:29:12.380504 17840 net.cpp:84] Creating Layer relu_conv11
I1005 00:29:12.380504 17840 net.cpp:406] relu_conv11 <- conv11
I1005 00:29:12.380504 17840 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1005 00:29:12.380504 17840 net.cpp:122] Setting up relu_conv11
I1005 00:29:12.380504 17840 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:29:12.380504 17840 net.cpp:137] Memory required for data: 199578800
I1005 00:29:12.380504 17840 layer_factory.cpp:58] Creating layer conv12
I1005 00:29:12.380504 17840 net.cpp:84] Creating Layer conv12
I1005 00:29:12.380504 17840 net.cpp:406] conv12 <- conv11
I1005 00:29:12.380504 17840 net.cpp:380] conv12 -> conv12
I1005 00:29:12.381505 17840 net.cpp:122] Setting up conv12
I1005 00:29:12.381505 17840 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:29:12.381505 17840 net.cpp:137] Memory required for data: 200679600
I1005 00:29:12.381505 17840 layer_factory.cpp:58] Creating layer bn_conv12
I1005 00:29:12.381505 17840 net.cpp:84] Creating Layer bn_conv12
I1005 00:29:12.381505 17840 net.cpp:406] bn_conv12 <- conv12
I1005 00:29:12.381505 17840 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1005 00:29:12.381505 17840 net.cpp:122] Setting up bn_conv12
I1005 00:29:12.381505 17840 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:29:12.382504 17840 net.cpp:137] Memory required for data: 201780400
I1005 00:29:12.382504 17840 layer_factory.cpp:58] Creating layer scale_conv12
I1005 00:29:12.382504 17840 net.cpp:84] Creating Layer scale_conv12
I1005 00:29:12.382504 17840 net.cpp:406] scale_conv12 <- conv12
I1005 00:29:12.382504 17840 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1005 00:29:12.382504 17840 layer_factory.cpp:58] Creating layer scale_conv12
I1005 00:29:12.382504 17840 net.cpp:122] Setting up scale_conv12
I1005 00:29:12.382504 17840 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:29:12.382504 17840 net.cpp:137] Memory required for data: 202881200
I1005 00:29:12.382504 17840 layer_factory.cpp:58] Creating layer relu_conv12
I1005 00:29:12.382504 17840 net.cpp:84] Creating Layer relu_conv12
I1005 00:29:12.382504 17840 net.cpp:406] relu_conv12 <- conv12
I1005 00:29:12.382504 17840 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1005 00:29:12.382504 17840 net.cpp:122] Setting up relu_conv12
I1005 00:29:12.382504 17840 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:29:12.382504 17840 net.cpp:137] Memory required for data: 203982000
I1005 00:29:12.382504 17840 layer_factory.cpp:58] Creating layer poolcp6
I1005 00:29:12.382504 17840 net.cpp:84] Creating Layer poolcp6
I1005 00:29:12.382504 17840 net.cpp:406] poolcp6 <- conv12
I1005 00:29:12.382504 17840 net.cpp:380] poolcp6 -> poolcp6
I1005 00:29:12.382504 17840 net.cpp:122] Setting up poolcp6
I1005 00:29:12.382504 17840 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1005 00:29:12.382504 17840 net.cpp:137] Memory required for data: 203999200
I1005 00:29:12.382504 17840 layer_factory.cpp:58] Creating layer ip1
I1005 00:29:12.382504 17840 net.cpp:84] Creating Layer ip1
I1005 00:29:12.382504 17840 net.cpp:406] ip1 <- poolcp6
I1005 00:29:12.382504 17840 net.cpp:380] ip1 -> ip1
I1005 00:29:12.382504 17840 net.cpp:122] Setting up ip1
I1005 00:29:12.382504 17840 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:29:12.382504 17840 net.cpp:137] Memory required for data: 204003200
I1005 00:29:12.382504 17840 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1005 00:29:12.382504 17840 net.cpp:84] Creating Layer ip1_ip1_0_split
I1005 00:29:12.382504 17840 net.cpp:406] ip1_ip1_0_split <- ip1
I1005 00:29:12.382504 17840 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1005 00:29:12.382504 17840 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1005 00:29:12.382504 17840 net.cpp:122] Setting up ip1_ip1_0_split
I1005 00:29:12.382504 17840 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:29:12.382504 17840 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:29:12.382504 17840 net.cpp:137] Memory required for data: 204011200
I1005 00:29:12.382504 17840 layer_factory.cpp:58] Creating layer accuracy_training
I1005 00:29:12.382504 17840 net.cpp:84] Creating Layer accuracy_training
I1005 00:29:12.382504 17840 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1005 00:29:12.382504 17840 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1005 00:29:12.382504 17840 net.cpp:380] accuracy_training -> accuracy_training
I1005 00:29:12.382504 17840 net.cpp:122] Setting up accuracy_training
I1005 00:29:12.382504 17840 net.cpp:129] Top shape: (1)
I1005 00:29:12.382504 17840 net.cpp:137] Memory required for data: 204011204
I1005 00:29:12.382504 17840 layer_factory.cpp:58] Creating layer loss
I1005 00:29:12.382504 17840 net.cpp:84] Creating Layer loss
I1005 00:29:12.382504 17840 net.cpp:406] loss <- ip1_ip1_0_split_1
I1005 00:29:12.382504 17840 net.cpp:406] loss <- label_cifar_1_split_1
I1005 00:29:12.382504 17840 net.cpp:380] loss -> loss
I1005 00:29:12.382504 17840 layer_factory.cpp:58] Creating layer loss
I1005 00:29:12.383504 17840 net.cpp:122] Setting up loss
I1005 00:29:12.383504 17840 net.cpp:129] Top shape: (1)
I1005 00:29:12.383504 17840 net.cpp:132]     with loss weight 1
I1005 00:29:12.383504 17840 net.cpp:137] Memory required for data: 204011208
I1005 00:29:12.383504 17840 net.cpp:198] loss needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:200] accuracy_training does not need backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] ip1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] poolcp6 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu_conv12 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale_conv12 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn_conv12 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv12 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu_conv11 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale_conv11 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn_conv11 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv11 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu4_0 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale4_0 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn4_0 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv4_0 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] pool4_2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu4_2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale4_2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn4_2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv4_2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu4_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale4_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn4_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv4_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu4 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale4 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn4 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv4 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] pool2_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu3_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale3_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn3_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv3_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu3 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale3 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn3 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv3 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu2_2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale2_2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn2_2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv2_2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu2_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale2_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn2_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv2_1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv2 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu1_0 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale1_0 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn1_0 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv1_0 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] relu1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] scale1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] bn1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:198] conv1 needs backward computation.
I1005 00:29:12.383504 17840 net.cpp:200] label_cifar_1_split does not need backward computation.
I1005 00:29:12.383504 17840 net.cpp:200] cifar does not need backward computation.
I1005 00:29:12.383504 17840 net.cpp:242] This network produces output accuracy_training
I1005 00:29:12.383504 17840 net.cpp:242] This network produces output loss
I1005 00:29:12.383504 17840 net.cpp:255] Network initialization done.
I1005 00:29:12.384505 17840 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 00:29:12.384505 17840 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 00:29:12.384505 17840 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1005 00:29:12.384505 17840 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1005 00:29:12.385504 17840 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P7"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1005 00:29:12.385504 17840 layer_factory.cpp:58] Creating layer cifar
I1005 00:29:12.391523 17840 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I1005 00:29:12.391523 17840 net.cpp:84] Creating Layer cifar
I1005 00:29:12.391523 17840 net.cpp:380] cifar -> data
I1005 00:29:12.391523 17840 net.cpp:380] cifar -> label
I1005 00:29:12.391523 17840 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1005 00:29:12.391523 17840 data_layer.cpp:45] output data size: 100,3,32,32
I1005 00:29:12.397521 17840 net.cpp:122] Setting up cifar
I1005 00:29:12.397521 17840 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1005 00:29:12.397521 17840 net.cpp:129] Top shape: 100 (100)
I1005 00:29:12.397521 17840 net.cpp:137] Memory required for data: 1229200
I1005 00:29:12.397521 17840 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1005 00:29:12.397521 17840 net.cpp:84] Creating Layer label_cifar_1_split
I1005 00:29:12.397521 17840 net.cpp:406] label_cifar_1_split <- label
I1005 00:29:12.397521 17840 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1005 00:29:12.397521 17840 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1005 00:29:12.397521 17840 net.cpp:122] Setting up label_cifar_1_split
I1005 00:29:12.397521 17840 net.cpp:129] Top shape: 100 (100)
I1005 00:29:12.397521 17840 net.cpp:129] Top shape: 100 (100)
I1005 00:29:12.397521 17840 net.cpp:137] Memory required for data: 1230000
I1005 00:29:12.397521 17840 layer_factory.cpp:58] Creating layer conv1
I1005 00:29:12.397521 17840 net.cpp:84] Creating Layer conv1
I1005 00:29:12.397521 17840 net.cpp:406] conv1 <- data
I1005 00:29:12.397521 17840 net.cpp:380] conv1 -> conv1
I1005 00:29:12.398537 17432 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 00:29:12.399505 17840 net.cpp:122] Setting up conv1
I1005 00:29:12.399505 17840 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:29:12.399505 17840 net.cpp:137] Memory required for data: 3687600
I1005 00:29:12.399505 17840 layer_factory.cpp:58] Creating layer bn1
I1005 00:29:12.399505 17840 net.cpp:84] Creating Layer bn1
I1005 00:29:12.399505 17840 net.cpp:406] bn1 <- conv1
I1005 00:29:12.399505 17840 net.cpp:367] bn1 -> conv1 (in-place)
I1005 00:29:12.399505 17840 net.cpp:122] Setting up bn1
I1005 00:29:12.399505 17840 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:29:12.399505 17840 net.cpp:137] Memory required for data: 6145200
I1005 00:29:12.399505 17840 layer_factory.cpp:58] Creating layer scale1
I1005 00:29:12.399505 17840 net.cpp:84] Creating Layer scale1
I1005 00:29:12.399505 17840 net.cpp:406] scale1 <- conv1
I1005 00:29:12.399505 17840 net.cpp:367] scale1 -> conv1 (in-place)
I1005 00:29:12.399505 17840 layer_factory.cpp:58] Creating layer scale1
I1005 00:29:12.399505 17840 net.cpp:122] Setting up scale1
I1005 00:29:12.399505 17840 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:29:12.399505 17840 net.cpp:137] Memory required for data: 8602800
I1005 00:29:12.399505 17840 layer_factory.cpp:58] Creating layer relu1
I1005 00:29:12.399505 17840 net.cpp:84] Creating Layer relu1
I1005 00:29:12.399505 17840 net.cpp:406] relu1 <- conv1
I1005 00:29:12.399505 17840 net.cpp:367] relu1 -> conv1 (in-place)
I1005 00:29:12.399505 17840 net.cpp:122] Setting up relu1
I1005 00:29:12.399505 17840 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:29:12.399505 17840 net.cpp:137] Memory required for data: 11060400
I1005 00:29:12.399505 17840 layer_factory.cpp:58] Creating layer conv1_0
I1005 00:29:12.399505 17840 net.cpp:84] Creating Layer conv1_0
I1005 00:29:12.399505 17840 net.cpp:406] conv1_0 <- conv1
I1005 00:29:12.399505 17840 net.cpp:380] conv1_0 -> conv1_0
I1005 00:29:12.401504 17840 net.cpp:122] Setting up conv1_0
I1005 00:29:12.401504 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.401504 17840 net.cpp:137] Memory required for data: 15975600
I1005 00:29:12.401504 17840 layer_factory.cpp:58] Creating layer bn1_0
I1005 00:29:12.401504 17840 net.cpp:84] Creating Layer bn1_0
I1005 00:29:12.401504 17840 net.cpp:406] bn1_0 <- conv1_0
I1005 00:29:12.401504 17840 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1005 00:29:12.401504 17840 net.cpp:122] Setting up bn1_0
I1005 00:29:12.401504 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.401504 17840 net.cpp:137] Memory required for data: 20890800
I1005 00:29:12.401504 17840 layer_factory.cpp:58] Creating layer scale1_0
I1005 00:29:12.401504 17840 net.cpp:84] Creating Layer scale1_0
I1005 00:29:12.401504 17840 net.cpp:406] scale1_0 <- conv1_0
I1005 00:29:12.401504 17840 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1005 00:29:12.401504 17840 layer_factory.cpp:58] Creating layer scale1_0
I1005 00:29:12.401504 17840 net.cpp:122] Setting up scale1_0
I1005 00:29:12.401504 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.401504 17840 net.cpp:137] Memory required for data: 25806000
I1005 00:29:12.401504 17840 layer_factory.cpp:58] Creating layer relu1_0
I1005 00:29:12.401504 17840 net.cpp:84] Creating Layer relu1_0
I1005 00:29:12.401504 17840 net.cpp:406] relu1_0 <- conv1_0
I1005 00:29:12.401504 17840 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1005 00:29:12.402504 17840 net.cpp:122] Setting up relu1_0
I1005 00:29:12.402504 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.402504 17840 net.cpp:137] Memory required for data: 30721200
I1005 00:29:12.402504 17840 layer_factory.cpp:58] Creating layer conv2
I1005 00:29:12.402504 17840 net.cpp:84] Creating Layer conv2
I1005 00:29:12.402504 17840 net.cpp:406] conv2 <- conv1_0
I1005 00:29:12.402504 17840 net.cpp:380] conv2 -> conv2
I1005 00:29:12.403503 17840 net.cpp:122] Setting up conv2
I1005 00:29:12.403503 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.403503 17840 net.cpp:137] Memory required for data: 35636400
I1005 00:29:12.403503 17840 layer_factory.cpp:58] Creating layer bn2
I1005 00:29:12.403503 17840 net.cpp:84] Creating Layer bn2
I1005 00:29:12.403503 17840 net.cpp:406] bn2 <- conv2
I1005 00:29:12.403503 17840 net.cpp:367] bn2 -> conv2 (in-place)
I1005 00:29:12.403503 17840 net.cpp:122] Setting up bn2
I1005 00:29:12.403503 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.403503 17840 net.cpp:137] Memory required for data: 40551600
I1005 00:29:12.403503 17840 layer_factory.cpp:58] Creating layer scale2
I1005 00:29:12.403503 17840 net.cpp:84] Creating Layer scale2
I1005 00:29:12.403503 17840 net.cpp:406] scale2 <- conv2
I1005 00:29:12.403503 17840 net.cpp:367] scale2 -> conv2 (in-place)
I1005 00:29:12.403503 17840 layer_factory.cpp:58] Creating layer scale2
I1005 00:29:12.404505 17840 net.cpp:122] Setting up scale2
I1005 00:29:12.404505 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.404505 17840 net.cpp:137] Memory required for data: 45466800
I1005 00:29:12.404505 17840 layer_factory.cpp:58] Creating layer relu2
I1005 00:29:12.404505 17840 net.cpp:84] Creating Layer relu2
I1005 00:29:12.404505 17840 net.cpp:406] relu2 <- conv2
I1005 00:29:12.404505 17840 net.cpp:367] relu2 -> conv2 (in-place)
I1005 00:29:12.404505 17840 net.cpp:122] Setting up relu2
I1005 00:29:12.404505 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.404505 17840 net.cpp:137] Memory required for data: 50382000
I1005 00:29:12.404505 17840 layer_factory.cpp:58] Creating layer conv2_1
I1005 00:29:12.404505 17840 net.cpp:84] Creating Layer conv2_1
I1005 00:29:12.404505 17840 net.cpp:406] conv2_1 <- conv2
I1005 00:29:12.404505 17840 net.cpp:380] conv2_1 -> conv2_1
I1005 00:29:12.405505 17840 net.cpp:122] Setting up conv2_1
I1005 00:29:12.405505 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.405505 17840 net.cpp:137] Memory required for data: 55297200
I1005 00:29:12.405505 17840 layer_factory.cpp:58] Creating layer bn2_1
I1005 00:29:12.405505 17840 net.cpp:84] Creating Layer bn2_1
I1005 00:29:12.405505 17840 net.cpp:406] bn2_1 <- conv2_1
I1005 00:29:12.405505 17840 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1005 00:29:12.405505 17840 net.cpp:122] Setting up bn2_1
I1005 00:29:12.405505 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.405505 17840 net.cpp:137] Memory required for data: 60212400
I1005 00:29:12.405505 17840 layer_factory.cpp:58] Creating layer scale2_1
I1005 00:29:12.405505 17840 net.cpp:84] Creating Layer scale2_1
I1005 00:29:12.405505 17840 net.cpp:406] scale2_1 <- conv2_1
I1005 00:29:12.405505 17840 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1005 00:29:12.405505 17840 layer_factory.cpp:58] Creating layer scale2_1
I1005 00:29:12.406514 17840 net.cpp:122] Setting up scale2_1
I1005 00:29:12.406514 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.406514 17840 net.cpp:137] Memory required for data: 65127600
I1005 00:29:12.406514 17840 layer_factory.cpp:58] Creating layer relu2_1
I1005 00:29:12.406514 17840 net.cpp:84] Creating Layer relu2_1
I1005 00:29:12.406514 17840 net.cpp:406] relu2_1 <- conv2_1
I1005 00:29:12.406514 17840 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1005 00:29:12.406514 17840 net.cpp:122] Setting up relu2_1
I1005 00:29:12.406514 17840 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:29:12.406514 17840 net.cpp:137] Memory required for data: 70042800
I1005 00:29:12.406514 17840 layer_factory.cpp:58] Creating layer conv2_2
I1005 00:29:12.406514 17840 net.cpp:84] Creating Layer conv2_2
I1005 00:29:12.406514 17840 net.cpp:406] conv2_2 <- conv2_1
I1005 00:29:12.406514 17840 net.cpp:380] conv2_2 -> conv2_2
I1005 00:29:12.407505 17840 net.cpp:122] Setting up conv2_2
I1005 00:29:12.407505 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.407505 17840 net.cpp:137] Memory required for data: 77825200
I1005 00:29:12.407505 17840 layer_factory.cpp:58] Creating layer bn2_2
I1005 00:29:12.407505 17840 net.cpp:84] Creating Layer bn2_2
I1005 00:29:12.407505 17840 net.cpp:406] bn2_2 <- conv2_2
I1005 00:29:12.407505 17840 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1005 00:29:12.407505 17840 net.cpp:122] Setting up bn2_2
I1005 00:29:12.407505 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.407505 17840 net.cpp:137] Memory required for data: 85607600
I1005 00:29:12.407505 17840 layer_factory.cpp:58] Creating layer scale2_2
I1005 00:29:12.407505 17840 net.cpp:84] Creating Layer scale2_2
I1005 00:29:12.407505 17840 net.cpp:406] scale2_2 <- conv2_2
I1005 00:29:12.407505 17840 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1005 00:29:12.407505 17840 layer_factory.cpp:58] Creating layer scale2_2
I1005 00:29:12.407505 17840 net.cpp:122] Setting up scale2_2
I1005 00:29:12.407505 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.407505 17840 net.cpp:137] Memory required for data: 93390000
I1005 00:29:12.407505 17840 layer_factory.cpp:58] Creating layer relu2_2
I1005 00:29:12.408504 17840 net.cpp:84] Creating Layer relu2_2
I1005 00:29:12.408504 17840 net.cpp:406] relu2_2 <- conv2_2
I1005 00:29:12.408504 17840 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1005 00:29:12.408504 17840 net.cpp:122] Setting up relu2_2
I1005 00:29:12.408504 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.408504 17840 net.cpp:137] Memory required for data: 101172400
I1005 00:29:12.408504 17840 layer_factory.cpp:58] Creating layer conv3
I1005 00:29:12.408504 17840 net.cpp:84] Creating Layer conv3
I1005 00:29:12.408504 17840 net.cpp:406] conv3 <- conv2_2
I1005 00:29:12.408504 17840 net.cpp:380] conv3 -> conv3
I1005 00:29:12.409509 17840 net.cpp:122] Setting up conv3
I1005 00:29:12.409509 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.409509 17840 net.cpp:137] Memory required for data: 108954800
I1005 00:29:12.409509 17840 layer_factory.cpp:58] Creating layer bn3
I1005 00:29:12.409509 17840 net.cpp:84] Creating Layer bn3
I1005 00:29:12.409509 17840 net.cpp:406] bn3 <- conv3
I1005 00:29:12.409509 17840 net.cpp:367] bn3 -> conv3 (in-place)
I1005 00:29:12.409509 17840 net.cpp:122] Setting up bn3
I1005 00:29:12.409509 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.409509 17840 net.cpp:137] Memory required for data: 116737200
I1005 00:29:12.409509 17840 layer_factory.cpp:58] Creating layer scale3
I1005 00:29:12.409509 17840 net.cpp:84] Creating Layer scale3
I1005 00:29:12.409509 17840 net.cpp:406] scale3 <- conv3
I1005 00:29:12.409509 17840 net.cpp:367] scale3 -> conv3 (in-place)
I1005 00:29:12.409509 17840 layer_factory.cpp:58] Creating layer scale3
I1005 00:29:12.409509 17840 net.cpp:122] Setting up scale3
I1005 00:29:12.409509 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.409509 17840 net.cpp:137] Memory required for data: 124519600
I1005 00:29:12.409509 17840 layer_factory.cpp:58] Creating layer relu3
I1005 00:29:12.409509 17840 net.cpp:84] Creating Layer relu3
I1005 00:29:12.409509 17840 net.cpp:406] relu3 <- conv3
I1005 00:29:12.409509 17840 net.cpp:367] relu3 -> conv3 (in-place)
I1005 00:29:12.410504 17840 net.cpp:122] Setting up relu3
I1005 00:29:12.410504 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.410504 17840 net.cpp:137] Memory required for data: 132302000
I1005 00:29:12.410504 17840 layer_factory.cpp:58] Creating layer conv3_1
I1005 00:29:12.410504 17840 net.cpp:84] Creating Layer conv3_1
I1005 00:29:12.410504 17840 net.cpp:406] conv3_1 <- conv3
I1005 00:29:12.410504 17840 net.cpp:380] conv3_1 -> conv3_1
I1005 00:29:12.411504 17840 net.cpp:122] Setting up conv3_1
I1005 00:29:12.411504 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.411504 17840 net.cpp:137] Memory required for data: 140084400
I1005 00:29:12.411504 17840 layer_factory.cpp:58] Creating layer bn3_1
I1005 00:29:12.411504 17840 net.cpp:84] Creating Layer bn3_1
I1005 00:29:12.411504 17840 net.cpp:406] bn3_1 <- conv3_1
I1005 00:29:12.411504 17840 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1005 00:29:12.412504 17840 net.cpp:122] Setting up bn3_1
I1005 00:29:12.412504 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.412504 17840 net.cpp:137] Memory required for data: 147866800
I1005 00:29:12.412504 17840 layer_factory.cpp:58] Creating layer scale3_1
I1005 00:29:12.412504 17840 net.cpp:84] Creating Layer scale3_1
I1005 00:29:12.412504 17840 net.cpp:406] scale3_1 <- conv3_1
I1005 00:29:12.412504 17840 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1005 00:29:12.412504 17840 layer_factory.cpp:58] Creating layer scale3_1
I1005 00:29:12.412504 17840 net.cpp:122] Setting up scale3_1
I1005 00:29:12.412504 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.412504 17840 net.cpp:137] Memory required for data: 155649200
I1005 00:29:12.412504 17840 layer_factory.cpp:58] Creating layer relu3_1
I1005 00:29:12.412504 17840 net.cpp:84] Creating Layer relu3_1
I1005 00:29:12.412504 17840 net.cpp:406] relu3_1 <- conv3_1
I1005 00:29:12.412504 17840 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1005 00:29:12.412504 17840 net.cpp:122] Setting up relu3_1
I1005 00:29:12.412504 17840 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:29:12.412504 17840 net.cpp:137] Memory required for data: 163431600
I1005 00:29:12.412504 17840 layer_factory.cpp:58] Creating layer pool2_1
I1005 00:29:12.412504 17840 net.cpp:84] Creating Layer pool2_1
I1005 00:29:12.412504 17840 net.cpp:406] pool2_1 <- conv3_1
I1005 00:29:12.412504 17840 net.cpp:380] pool2_1 -> pool2_1
I1005 00:29:12.412504 17840 net.cpp:122] Setting up pool2_1
I1005 00:29:12.412504 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.412504 17840 net.cpp:137] Memory required for data: 165377200
I1005 00:29:12.412504 17840 layer_factory.cpp:58] Creating layer conv4
I1005 00:29:12.412504 17840 net.cpp:84] Creating Layer conv4
I1005 00:29:12.412504 17840 net.cpp:406] conv4 <- pool2_1
I1005 00:29:12.412504 17840 net.cpp:380] conv4 -> conv4
I1005 00:29:12.413504 17840 net.cpp:122] Setting up conv4
I1005 00:29:12.413504 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.413504 17840 net.cpp:137] Memory required for data: 167322800
I1005 00:29:12.413504 17840 layer_factory.cpp:58] Creating layer bn4
I1005 00:29:12.413504 17840 net.cpp:84] Creating Layer bn4
I1005 00:29:12.413504 17840 net.cpp:406] bn4 <- conv4
I1005 00:29:12.413504 17840 net.cpp:367] bn4 -> conv4 (in-place)
I1005 00:29:12.414505 17840 net.cpp:122] Setting up bn4
I1005 00:29:12.414505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.414505 17840 net.cpp:137] Memory required for data: 169268400
I1005 00:29:12.414505 17840 layer_factory.cpp:58] Creating layer scale4
I1005 00:29:12.414505 17840 net.cpp:84] Creating Layer scale4
I1005 00:29:12.414505 17840 net.cpp:406] scale4 <- conv4
I1005 00:29:12.414505 17840 net.cpp:367] scale4 -> conv4 (in-place)
I1005 00:29:12.414505 17840 layer_factory.cpp:58] Creating layer scale4
I1005 00:29:12.414505 17840 net.cpp:122] Setting up scale4
I1005 00:29:12.414505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.414505 17840 net.cpp:137] Memory required for data: 171214000
I1005 00:29:12.414505 17840 layer_factory.cpp:58] Creating layer relu4
I1005 00:29:12.414505 17840 net.cpp:84] Creating Layer relu4
I1005 00:29:12.414505 17840 net.cpp:406] relu4 <- conv4
I1005 00:29:12.414505 17840 net.cpp:367] relu4 -> conv4 (in-place)
I1005 00:29:12.414505 17840 net.cpp:122] Setting up relu4
I1005 00:29:12.414505 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.414505 17840 net.cpp:137] Memory required for data: 173159600
I1005 00:29:12.414505 17840 layer_factory.cpp:58] Creating layer conv4_1
I1005 00:29:12.414505 17840 net.cpp:84] Creating Layer conv4_1
I1005 00:29:12.414505 17840 net.cpp:406] conv4_1 <- conv4
I1005 00:29:12.414505 17840 net.cpp:380] conv4_1 -> conv4_1
I1005 00:29:12.415503 17840 net.cpp:122] Setting up conv4_1
I1005 00:29:12.415503 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.415503 17840 net.cpp:137] Memory required for data: 175105200
I1005 00:29:12.415503 17840 layer_factory.cpp:58] Creating layer bn4_1
I1005 00:29:12.415503 17840 net.cpp:84] Creating Layer bn4_1
I1005 00:29:12.415503 17840 net.cpp:406] bn4_1 <- conv4_1
I1005 00:29:12.415503 17840 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1005 00:29:12.415503 17840 net.cpp:122] Setting up bn4_1
I1005 00:29:12.415503 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.415503 17840 net.cpp:137] Memory required for data: 177050800
I1005 00:29:12.415503 17840 layer_factory.cpp:58] Creating layer scale4_1
I1005 00:29:12.415503 17840 net.cpp:84] Creating Layer scale4_1
I1005 00:29:12.415503 17840 net.cpp:406] scale4_1 <- conv4_1
I1005 00:29:12.415503 17840 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1005 00:29:12.415503 17840 layer_factory.cpp:58] Creating layer scale4_1
I1005 00:29:12.415503 17840 net.cpp:122] Setting up scale4_1
I1005 00:29:12.415503 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.415503 17840 net.cpp:137] Memory required for data: 178996400
I1005 00:29:12.415503 17840 layer_factory.cpp:58] Creating layer relu4_1
I1005 00:29:12.415503 17840 net.cpp:84] Creating Layer relu4_1
I1005 00:29:12.415503 17840 net.cpp:406] relu4_1 <- conv4_1
I1005 00:29:12.415503 17840 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1005 00:29:12.415503 17840 net.cpp:122] Setting up relu4_1
I1005 00:29:12.416504 17840 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:29:12.416504 17840 net.cpp:137] Memory required for data: 180942000
I1005 00:29:12.416504 17840 layer_factory.cpp:58] Creating layer conv4_2
I1005 00:29:12.416504 17840 net.cpp:84] Creating Layer conv4_2
I1005 00:29:12.416504 17840 net.cpp:406] conv4_2 <- conv4_1
I1005 00:29:12.416504 17840 net.cpp:380] conv4_2 -> conv4_2
I1005 00:29:12.417505 17840 net.cpp:122] Setting up conv4_2
I1005 00:29:12.417505 17840 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:29:12.417505 17840 net.cpp:137] Memory required for data: 183809200
I1005 00:29:12.417505 17840 layer_factory.cpp:58] Creating layer bn4_2
I1005 00:29:12.417505 17840 net.cpp:84] Creating Layer bn4_2
I1005 00:29:12.417505 17840 net.cpp:406] bn4_2 <- conv4_2
I1005 00:29:12.417505 17840 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1005 00:29:12.417505 17840 net.cpp:122] Setting up bn4_2
I1005 00:29:12.417505 17840 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:29:12.417505 17840 net.cpp:137] Memory required for data: 186676400
I1005 00:29:12.417505 17840 layer_factory.cpp:58] Creating layer scale4_2
I1005 00:29:12.417505 17840 net.cpp:84] Creating Layer scale4_2
I1005 00:29:12.417505 17840 net.cpp:406] scale4_2 <- conv4_2
I1005 00:29:12.417505 17840 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1005 00:29:12.417505 17840 layer_factory.cpp:58] Creating layer scale4_2
I1005 00:29:12.417505 17840 net.cpp:122] Setting up scale4_2
I1005 00:29:12.417505 17840 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:29:12.417505 17840 net.cpp:137] Memory required for data: 189543600
I1005 00:29:12.417505 17840 layer_factory.cpp:58] Creating layer relu4_2
I1005 00:29:12.417505 17840 net.cpp:84] Creating Layer relu4_2
I1005 00:29:12.417505 17840 net.cpp:406] relu4_2 <- conv4_2
I1005 00:29:12.417505 17840 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1005 00:29:12.417505 17840 net.cpp:122] Setting up relu4_2
I1005 00:29:12.417505 17840 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:29:12.417505 17840 net.cpp:137] Memory required for data: 192410800
I1005 00:29:12.417505 17840 layer_factory.cpp:58] Creating layer pool4_2
I1005 00:29:12.417505 17840 net.cpp:84] Creating Layer pool4_2
I1005 00:29:12.417505 17840 net.cpp:406] pool4_2 <- conv4_2
I1005 00:29:12.417505 17840 net.cpp:380] pool4_2 -> pool4_2
I1005 00:29:12.417505 17840 net.cpp:122] Setting up pool4_2
I1005 00:29:12.417505 17840 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:29:12.417505 17840 net.cpp:137] Memory required for data: 193127600
I1005 00:29:12.417505 17840 layer_factory.cpp:58] Creating layer conv4_0
I1005 00:29:12.417505 17840 net.cpp:84] Creating Layer conv4_0
I1005 00:29:12.417505 17840 net.cpp:406] conv4_0 <- pool4_2
I1005 00:29:12.417505 17840 net.cpp:380] conv4_0 -> conv4_0
I1005 00:29:12.418504 17840 net.cpp:122] Setting up conv4_0
I1005 00:29:12.418504 17840 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:29:12.418504 17840 net.cpp:137] Memory required for data: 193844400
I1005 00:29:12.418504 17840 layer_factory.cpp:58] Creating layer bn4_0
I1005 00:29:12.418504 17840 net.cpp:84] Creating Layer bn4_0
I1005 00:29:12.418504 17840 net.cpp:406] bn4_0 <- conv4_0
I1005 00:29:12.418504 17840 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1005 00:29:12.418504 17840 net.cpp:122] Setting up bn4_0
I1005 00:29:12.419504 17840 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:29:12.419504 17840 net.cpp:137] Memory required for data: 194561200
I1005 00:29:12.419504 17840 layer_factory.cpp:58] Creating layer scale4_0
I1005 00:29:12.419504 17840 net.cpp:84] Creating Layer scale4_0
I1005 00:29:12.419504 17840 net.cpp:406] scale4_0 <- conv4_0
I1005 00:29:12.419504 17840 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1005 00:29:12.419504 17840 layer_factory.cpp:58] Creating layer scale4_0
I1005 00:29:12.419504 17840 net.cpp:122] Setting up scale4_0
I1005 00:29:12.419504 17840 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:29:12.419504 17840 net.cpp:137] Memory required for data: 195278000
I1005 00:29:12.419504 17840 layer_factory.cpp:58] Creating layer relu4_0
I1005 00:29:12.419504 17840 net.cpp:84] Creating Layer relu4_0
I1005 00:29:12.419504 17840 net.cpp:406] relu4_0 <- conv4_0
I1005 00:29:12.419504 17840 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1005 00:29:12.419504 17840 net.cpp:122] Setting up relu4_0
I1005 00:29:12.419504 17840 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:29:12.419504 17840 net.cpp:137] Memory required for data: 195994800
I1005 00:29:12.419504 17840 layer_factory.cpp:58] Creating layer conv11
I1005 00:29:12.419504 17840 net.cpp:84] Creating Layer conv11
I1005 00:29:12.419504 17840 net.cpp:406] conv11 <- conv4_0
I1005 00:29:12.419504 17840 net.cpp:380] conv11 -> conv11
I1005 00:29:12.420505 17840 net.cpp:122] Setting up conv11
I1005 00:29:12.420505 17840 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:29:12.420505 17840 net.cpp:137] Memory required for data: 196890800
I1005 00:29:12.420505 17840 layer_factory.cpp:58] Creating layer bn_conv11
I1005 00:29:12.420505 17840 net.cpp:84] Creating Layer bn_conv11
I1005 00:29:12.420505 17840 net.cpp:406] bn_conv11 <- conv11
I1005 00:29:12.420505 17840 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1005 00:29:12.420505 17840 net.cpp:122] Setting up bn_conv11
I1005 00:29:12.420505 17840 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:29:12.420505 17840 net.cpp:137] Memory required for data: 197786800
I1005 00:29:12.420505 17840 layer_factory.cpp:58] Creating layer scale_conv11
I1005 00:29:12.420505 17840 net.cpp:84] Creating Layer scale_conv11
I1005 00:29:12.420505 17840 net.cpp:406] scale_conv11 <- conv11
I1005 00:29:12.420505 17840 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1005 00:29:12.420505 17840 layer_factory.cpp:58] Creating layer scale_conv11
I1005 00:29:12.420505 17840 net.cpp:122] Setting up scale_conv11
I1005 00:29:12.420505 17840 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:29:12.420505 17840 net.cpp:137] Memory required for data: 198682800
I1005 00:29:12.421504 17840 layer_factory.cpp:58] Creating layer relu_conv11
I1005 00:29:12.421504 17840 net.cpp:84] Creating Layer relu_conv11
I1005 00:29:12.421504 17840 net.cpp:406] relu_conv11 <- conv11
I1005 00:29:12.421504 17840 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1005 00:29:12.421504 17840 net.cpp:122] Setting up relu_conv11
I1005 00:29:12.421504 17840 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:29:12.421504 17840 net.cpp:137] Memory required for data: 199578800
I1005 00:29:12.421504 17840 layer_factory.cpp:58] Creating layer conv12
I1005 00:29:12.421504 17840 net.cpp:84] Creating Layer conv12
I1005 00:29:12.421504 17840 net.cpp:406] conv12 <- conv11
I1005 00:29:12.421504 17840 net.cpp:380] conv12 -> conv12
I1005 00:29:12.422504 17840 net.cpp:122] Setting up conv12
I1005 00:29:12.422504 17840 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:29:12.422504 17840 net.cpp:137] Memory required for data: 200679600
I1005 00:29:12.422504 17840 layer_factory.cpp:58] Creating layer bn_conv12
I1005 00:29:12.422504 17840 net.cpp:84] Creating Layer bn_conv12
I1005 00:29:12.422504 17840 net.cpp:406] bn_conv12 <- conv12
I1005 00:29:12.422504 17840 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1005 00:29:12.423504 17840 net.cpp:122] Setting up bn_conv12
I1005 00:29:12.423504 17840 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:29:12.423504 17840 net.cpp:137] Memory required for data: 201780400
I1005 00:29:12.423504 17840 layer_factory.cpp:58] Creating layer scale_conv12
I1005 00:29:12.423504 17840 net.cpp:84] Creating Layer scale_conv12
I1005 00:29:12.423504 17840 net.cpp:406] scale_conv12 <- conv12
I1005 00:29:12.423504 17840 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1005 00:29:12.423504 17840 layer_factory.cpp:58] Creating layer scale_conv12
I1005 00:29:12.423504 17840 net.cpp:122] Setting up scale_conv12
I1005 00:29:12.423504 17840 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:29:12.423504 17840 net.cpp:137] Memory required for data: 202881200
I1005 00:29:12.423504 17840 layer_factory.cpp:58] Creating layer relu_conv12
I1005 00:29:12.423504 17840 net.cpp:84] Creating Layer relu_conv12
I1005 00:29:12.423504 17840 net.cpp:406] relu_conv12 <- conv12
I1005 00:29:12.423504 17840 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1005 00:29:12.423504 17840 net.cpp:122] Setting up relu_conv12
I1005 00:29:12.423504 17840 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:29:12.423504 17840 net.cpp:137] Memory required for data: 203982000
I1005 00:29:12.423504 17840 layer_factory.cpp:58] Creating layer poolcp6
I1005 00:29:12.423504 17840 net.cpp:84] Creating Layer poolcp6
I1005 00:29:12.423504 17840 net.cpp:406] poolcp6 <- conv12
I1005 00:29:12.423504 17840 net.cpp:380] poolcp6 -> poolcp6
I1005 00:29:12.423504 17840 net.cpp:122] Setting up poolcp6
I1005 00:29:12.423504 17840 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1005 00:29:12.423504 17840 net.cpp:137] Memory required for data: 203999200
I1005 00:29:12.423504 17840 layer_factory.cpp:58] Creating layer ip1
I1005 00:29:12.423504 17840 net.cpp:84] Creating Layer ip1
I1005 00:29:12.423504 17840 net.cpp:406] ip1 <- poolcp6
I1005 00:29:12.423504 17840 net.cpp:380] ip1 -> ip1
I1005 00:29:12.423504 17840 net.cpp:122] Setting up ip1
I1005 00:29:12.423504 17840 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:29:12.423504 17840 net.cpp:137] Memory required for data: 204003200
I1005 00:29:12.423504 17840 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1005 00:29:12.423504 17840 net.cpp:84] Creating Layer ip1_ip1_0_split
I1005 00:29:12.423504 17840 net.cpp:406] ip1_ip1_0_split <- ip1
I1005 00:29:12.423504 17840 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1005 00:29:12.423504 17840 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1005 00:29:12.423504 17840 net.cpp:122] Setting up ip1_ip1_0_split
I1005 00:29:12.423504 17840 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:29:12.423504 17840 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:29:12.423504 17840 net.cpp:137] Memory required for data: 204011200
I1005 00:29:12.423504 17840 layer_factory.cpp:58] Creating layer accuracy
I1005 00:29:12.423504 17840 net.cpp:84] Creating Layer accuracy
I1005 00:29:12.423504 17840 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1005 00:29:12.423504 17840 net.cpp:406] accuracy <- label_cifar_1_split_0
I1005 00:29:12.423504 17840 net.cpp:380] accuracy -> accuracy
I1005 00:29:12.423504 17840 net.cpp:122] Setting up accuracy
I1005 00:29:12.423504 17840 net.cpp:129] Top shape: (1)
I1005 00:29:12.423504 17840 net.cpp:137] Memory required for data: 204011204
I1005 00:29:12.423504 17840 layer_factory.cpp:58] Creating layer loss
I1005 00:29:12.423504 17840 net.cpp:84] Creating Layer loss
I1005 00:29:12.423504 17840 net.cpp:406] loss <- ip1_ip1_0_split_1
I1005 00:29:12.423504 17840 net.cpp:406] loss <- label_cifar_1_split_1
I1005 00:29:12.423504 17840 net.cpp:380] loss -> loss
I1005 00:29:12.423504 17840 layer_factory.cpp:58] Creating layer loss
I1005 00:29:12.424504 17840 net.cpp:122] Setting up loss
I1005 00:29:12.424504 17840 net.cpp:129] Top shape: (1)
I1005 00:29:12.424504 17840 net.cpp:132]     with loss weight 1
I1005 00:29:12.424504 17840 net.cpp:137] Memory required for data: 204011208
I1005 00:29:12.424504 17840 net.cpp:198] loss needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:200] accuracy does not need backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] ip1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] poolcp6 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu_conv12 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale_conv12 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn_conv12 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv12 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu_conv11 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale_conv11 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn_conv11 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv11 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu4_0 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale4_0 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn4_0 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv4_0 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] pool4_2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu4_2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale4_2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn4_2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv4_2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu4_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale4_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn4_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv4_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu4 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale4 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn4 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv4 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] pool2_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu3_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale3_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn3_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv3_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu3 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale3 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn3 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv3 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu2_2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale2_2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn2_2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv2_2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu2_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale2_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn2_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv2_1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv2 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu1_0 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale1_0 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn1_0 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv1_0 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] relu1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] scale1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] bn1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:198] conv1 needs backward computation.
I1005 00:29:12.424504 17840 net.cpp:200] label_cifar_1_split does not need backward computation.
I1005 00:29:12.424504 17840 net.cpp:200] cifar does not need backward computation.
I1005 00:29:12.424504 17840 net.cpp:242] This network produces output accuracy
I1005 00:29:12.424504 17840 net.cpp:242] This network produces output loss
I1005 00:29:12.424504 17840 net.cpp:255] Network initialization done.
I1005 00:29:12.424504 17840 solver.cpp:56] Solver scaffolding done.
I1005 00:29:12.427507 17840 caffe.cpp:249] Starting Optimization
I1005 00:29:12.427507 17840 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_drpall_Simple_P7
I1005 00:29:12.427507 17840 solver.cpp:273] Learning Rate Policy: multistep
I1005 00:29:12.429518 17840 solver.cpp:330] Iteration 0, Testing net (#0)
I1005 00:29:12.431519 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:29:13.113504 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:29:13.139506 17840 solver.cpp:397]     Test net output #0: accuracy = 0.1062
I1005 00:29:13.139506 17840 solver.cpp:397]     Test net output #1: loss = 78.0614 (* 1 = 78.0614 loss)
I1005 00:29:13.203505 17840 solver.cpp:218] Iteration 0 (-nan iter/s, 0.773814s/100 iters), loss = 3.85626
I1005 00:29:13.203505 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I1005 00:29:13.203505 17840 solver.cpp:237]     Train net output #1: loss = 3.85626 (* 1 = 3.85626 loss)
I1005 00:29:13.203505 17840 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1005 00:29:16.495519 17840 solver.cpp:218] Iteration 100 (30.3808 iter/s, 3.29155s/100 iters), loss = 1.80455
I1005 00:29:16.495519 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1005 00:29:16.495519 17840 solver.cpp:237]     Train net output #1: loss = 1.80455 (* 1 = 1.80455 loss)
I1005 00:29:16.495519 17840 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1005 00:29:19.757508 17840 solver.cpp:218] Iteration 200 (30.6582 iter/s, 3.26177s/100 iters), loss = 1.6907
I1005 00:29:19.757508 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1005 00:29:19.757508 17840 solver.cpp:237]     Train net output #1: loss = 1.6907 (* 1 = 1.6907 loss)
I1005 00:29:19.757508 17840 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1005 00:29:23.013525 17840 solver.cpp:218] Iteration 300 (30.7116 iter/s, 3.2561s/100 iters), loss = 1.45771
I1005 00:29:23.013525 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1005 00:29:23.013525 17840 solver.cpp:237]     Train net output #1: loss = 1.45771 (* 1 = 1.45771 loss)
I1005 00:29:23.013525 17840 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1005 00:29:26.270867 17840 solver.cpp:218] Iteration 400 (30.7095 iter/s, 3.25632s/100 iters), loss = 1.304
I1005 00:29:26.270867 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1005 00:29:26.270867 17840 solver.cpp:237]     Train net output #1: loss = 1.304 (* 1 = 1.304 loss)
I1005 00:29:26.270867 17840 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1005 00:29:29.368852  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:29:29.528852 17840 solver.cpp:218] Iteration 500 (30.693 iter/s, 3.25807s/100 iters), loss = 1.47256
I1005 00:29:29.528852 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1005 00:29:29.528852 17840 solver.cpp:237]     Train net output #1: loss = 1.47256 (* 1 = 1.47256 loss)
I1005 00:29:29.528852 17840 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1005 00:29:32.790868 17840 solver.cpp:218] Iteration 600 (30.6589 iter/s, 3.26169s/100 iters), loss = 1.39809
I1005 00:29:32.790868 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1005 00:29:32.790868 17840 solver.cpp:237]     Train net output #1: loss = 1.39809 (* 1 = 1.39809 loss)
I1005 00:29:32.790868 17840 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1005 00:29:36.053867 17840 solver.cpp:218] Iteration 700 (30.6458 iter/s, 3.26309s/100 iters), loss = 1.37585
I1005 00:29:36.053867 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1005 00:29:36.053867 17840 solver.cpp:237]     Train net output #1: loss = 1.37585 (* 1 = 1.37585 loss)
I1005 00:29:36.053867 17840 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1005 00:29:39.330852 17840 solver.cpp:218] Iteration 800 (30.5267 iter/s, 3.27582s/100 iters), loss = 1.21051
I1005 00:29:39.330852 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1005 00:29:39.330852 17840 solver.cpp:237]     Train net output #1: loss = 1.21051 (* 1 = 1.21051 loss)
I1005 00:29:39.330852 17840 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1005 00:29:42.605428 17840 solver.cpp:218] Iteration 900 (30.5417 iter/s, 3.27421s/100 iters), loss = 1.11729
I1005 00:29:42.605428 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1005 00:29:42.605428 17840 solver.cpp:237]     Train net output #1: loss = 1.11729 (* 1 = 1.11729 loss)
I1005 00:29:42.605428 17840 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1005 00:29:45.715427  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:29:45.845432 17840 solver.cpp:330] Iteration 1000, Testing net (#0)
I1005 00:29:45.845432 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:29:46.489429 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:29:46.515427 17840 solver.cpp:397]     Test net output #0: accuracy = 0.5777
I1005 00:29:46.515427 17840 solver.cpp:397]     Test net output #1: loss = 1.1697 (* 1 = 1.1697 loss)
I1005 00:29:46.545428 17840 solver.cpp:218] Iteration 1000 (25.3789 iter/s, 3.94028s/100 iters), loss = 1.19122
I1005 00:29:46.545428 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1005 00:29:46.545428 17840 solver.cpp:237]     Train net output #1: loss = 1.19122 (* 1 = 1.19122 loss)
I1005 00:29:46.545428 17840 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1005 00:29:49.803371 17840 solver.cpp:218] Iteration 1100 (30.6986 iter/s, 3.25747s/100 iters), loss = 1.01674
I1005 00:29:49.803371 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1005 00:29:49.803371 17840 solver.cpp:237]     Train net output #1: loss = 1.01674 (* 1 = 1.01674 loss)
I1005 00:29:49.803371 17840 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1005 00:29:53.061359 17840 solver.cpp:218] Iteration 1200 (30.6985 iter/s, 3.25749s/100 iters), loss = 1.12687
I1005 00:29:53.061359 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1005 00:29:53.061359 17840 solver.cpp:237]     Train net output #1: loss = 1.12687 (* 1 = 1.12687 loss)
I1005 00:29:53.061359 17840 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1005 00:29:56.313359 17840 solver.cpp:218] Iteration 1300 (30.7587 iter/s, 3.25112s/100 iters), loss = 1.11411
I1005 00:29:56.313359 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1005 00:29:56.313359 17840 solver.cpp:237]     Train net output #1: loss = 1.11411 (* 1 = 1.11411 loss)
I1005 00:29:56.313359 17840 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1005 00:29:59.566371 17840 solver.cpp:218] Iteration 1400 (30.7465 iter/s, 3.2524s/100 iters), loss = 0.933581
I1005 00:29:59.566371 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1005 00:29:59.566371 17840 solver.cpp:237]     Train net output #1: loss = 0.933581 (* 1 = 0.933581 loss)
I1005 00:29:59.566371 17840 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1005 00:30:02.698357  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:30:02.859359 17840 solver.cpp:218] Iteration 1500 (30.371 iter/s, 3.29261s/100 iters), loss = 1.03475
I1005 00:30:02.859359 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1005 00:30:02.859359 17840 solver.cpp:237]     Train net output #1: loss = 1.03475 (* 1 = 1.03475 loss)
I1005 00:30:02.859359 17840 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1005 00:30:06.117368 17840 solver.cpp:218] Iteration 1600 (30.697 iter/s, 3.25764s/100 iters), loss = 0.843969
I1005 00:30:06.117368 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 00:30:06.117368 17840 solver.cpp:237]     Train net output #1: loss = 0.843969 (* 1 = 0.843969 loss)
I1005 00:30:06.117368 17840 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1005 00:30:09.382369 17840 solver.cpp:218] Iteration 1700 (30.6295 iter/s, 3.26483s/100 iters), loss = 0.950369
I1005 00:30:09.382369 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1005 00:30:09.382369 17840 solver.cpp:237]     Train net output #1: loss = 0.950369 (* 1 = 0.950369 loss)
I1005 00:30:09.382369 17840 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1005 00:30:12.638367 17840 solver.cpp:218] Iteration 1800 (30.7166 iter/s, 3.25557s/100 iters), loss = 0.923304
I1005 00:30:12.638367 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 00:30:12.638367 17840 solver.cpp:237]     Train net output #1: loss = 0.923304 (* 1 = 0.923304 loss)
I1005 00:30:12.638367 17840 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1005 00:30:15.914037 17840 solver.cpp:218] Iteration 1900 (30.5307 iter/s, 3.2754s/100 iters), loss = 0.777647
I1005 00:30:15.914037 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1005 00:30:15.914037 17840 solver.cpp:237]     Train net output #1: loss = 0.777647 (* 1 = 0.777647 loss)
I1005 00:30:15.914037 17840 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1005 00:30:19.032022  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:30:19.161023 17840 solver.cpp:330] Iteration 2000, Testing net (#0)
I1005 00:30:19.161023 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:30:19.805023 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:30:19.831037 17840 solver.cpp:397]     Test net output #0: accuracy = 0.6753
I1005 00:30:19.831037 17840 solver.cpp:397]     Test net output #1: loss = 0.924554 (* 1 = 0.924554 loss)
I1005 00:30:19.861022 17840 solver.cpp:218] Iteration 2000 (25.3331 iter/s, 3.9474s/100 iters), loss = 0.916559
I1005 00:30:19.862022 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1005 00:30:19.862022 17840 solver.cpp:237]     Train net output #1: loss = 0.916559 (* 1 = 0.916559 loss)
I1005 00:30:19.862022 17840 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1005 00:30:23.117041 17840 solver.cpp:218] Iteration 2100 (30.7195 iter/s, 3.25526s/100 iters), loss = 0.822612
I1005 00:30:23.117041 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1005 00:30:23.117041 17840 solver.cpp:237]     Train net output #1: loss = 0.822612 (* 1 = 0.822612 loss)
I1005 00:30:23.117041 17840 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1005 00:30:26.384040 17840 solver.cpp:218] Iteration 2200 (30.6152 iter/s, 3.26635s/100 iters), loss = 0.922532
I1005 00:30:26.384040 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1005 00:30:26.384040 17840 solver.cpp:237]     Train net output #1: loss = 0.922532 (* 1 = 0.922532 loss)
I1005 00:30:26.384040 17840 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1005 00:30:29.655022 17840 solver.cpp:218] Iteration 2300 (30.5699 iter/s, 3.27119s/100 iters), loss = 0.805154
I1005 00:30:29.655022 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1005 00:30:29.655022 17840 solver.cpp:237]     Train net output #1: loss = 0.805154 (* 1 = 0.805154 loss)
I1005 00:30:29.655022 17840 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1005 00:30:32.926033 17840 solver.cpp:218] Iteration 2400 (30.5764 iter/s, 3.2705s/100 iters), loss = 0.805232
I1005 00:30:32.926033 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 00:30:32.926033 17840 solver.cpp:237]     Train net output #1: loss = 0.805232 (* 1 = 0.805232 loss)
I1005 00:30:32.926033 17840 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1005 00:30:36.018023  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:30:36.177036 17840 solver.cpp:218] Iteration 2500 (30.7596 iter/s, 3.25102s/100 iters), loss = 0.807397
I1005 00:30:36.178031 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 00:30:36.178031 17840 solver.cpp:237]     Train net output #1: loss = 0.807397 (* 1 = 0.807397 loss)
I1005 00:30:36.178031 17840 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1005 00:30:39.448037 17840 solver.cpp:218] Iteration 2600 (30.5796 iter/s, 3.27016s/100 iters), loss = 0.754969
I1005 00:30:39.448037 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1005 00:30:39.448037 17840 solver.cpp:237]     Train net output #1: loss = 0.754969 (* 1 = 0.754969 loss)
I1005 00:30:39.448037 17840 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1005 00:30:42.716032 17840 solver.cpp:218] Iteration 2700 (30.6027 iter/s, 3.26768s/100 iters), loss = 0.946612
I1005 00:30:42.716032 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1005 00:30:42.716032 17840 solver.cpp:237]     Train net output #1: loss = 0.946612 (* 1 = 0.946612 loss)
I1005 00:30:42.716032 17840 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1005 00:30:45.988037 17840 solver.cpp:218] Iteration 2800 (30.5684 iter/s, 3.27135s/100 iters), loss = 0.71229
I1005 00:30:45.988037 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1005 00:30:45.988037 17840 solver.cpp:237]     Train net output #1: loss = 0.71229 (* 1 = 0.71229 loss)
I1005 00:30:45.988037 17840 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1005 00:30:49.253037 17840 solver.cpp:218] Iteration 2900 (30.6323 iter/s, 3.26453s/100 iters), loss = 0.722755
I1005 00:30:49.253037 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 00:30:49.253037 17840 solver.cpp:237]     Train net output #1: loss = 0.722755 (* 1 = 0.722755 loss)
I1005 00:30:49.253037 17840 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1005 00:30:52.371021  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:30:52.500032 17840 solver.cpp:330] Iteration 3000, Testing net (#0)
I1005 00:30:52.500032 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:30:53.146023 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:30:53.171036 17840 solver.cpp:397]     Test net output #0: accuracy = 0.72
I1005 00:30:53.171036 17840 solver.cpp:397]     Test net output #1: loss = 0.820729 (* 1 = 0.820729 loss)
I1005 00:30:53.202040 17840 solver.cpp:218] Iteration 3000 (25.3219 iter/s, 3.94916s/100 iters), loss = 0.784555
I1005 00:30:53.202040 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1005 00:30:53.202040 17840 solver.cpp:237]     Train net output #1: loss = 0.784555 (* 1 = 0.784555 loss)
I1005 00:30:53.202040 17840 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1005 00:30:56.473037 17840 solver.cpp:218] Iteration 3100 (30.5791 iter/s, 3.27021s/100 iters), loss = 0.574488
I1005 00:30:56.473037 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:30:56.473037 17840 solver.cpp:237]     Train net output #1: loss = 0.574488 (* 1 = 0.574488 loss)
I1005 00:30:56.473037 17840 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1005 00:30:59.725037 17840 solver.cpp:218] Iteration 3200 (30.7526 iter/s, 3.25176s/100 iters), loss = 0.747076
I1005 00:30:59.725037 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 00:30:59.725037 17840 solver.cpp:237]     Train net output #1: loss = 0.747076 (* 1 = 0.747076 loss)
I1005 00:30:59.725037 17840 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1005 00:31:02.986601 17840 solver.cpp:218] Iteration 3300 (30.66 iter/s, 3.26158s/100 iters), loss = 0.650621
I1005 00:31:02.986601 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:31:02.986601 17840 solver.cpp:237]     Train net output #1: loss = 0.650621 (* 1 = 0.650621 loss)
I1005 00:31:02.986601 17840 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1005 00:31:06.256935 17840 solver.cpp:218] Iteration 3400 (30.5847 iter/s, 3.26961s/100 iters), loss = 0.719057
I1005 00:31:06.256935 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1005 00:31:06.256935 17840 solver.cpp:237]     Train net output #1: loss = 0.719057 (* 1 = 0.719057 loss)
I1005 00:31:06.256935 17840 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1005 00:31:09.366920  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:31:09.526937 17840 solver.cpp:218] Iteration 3500 (30.5817 iter/s, 3.26993s/100 iters), loss = 0.760257
I1005 00:31:09.526937 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1005 00:31:09.526937 17840 solver.cpp:237]     Train net output #1: loss = 0.760257 (* 1 = 0.760257 loss)
I1005 00:31:09.526937 17840 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1005 00:31:12.797935 17840 solver.cpp:218] Iteration 3600 (30.5788 iter/s, 3.27024s/100 iters), loss = 0.668999
I1005 00:31:12.797935 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:31:12.797935 17840 solver.cpp:237]     Train net output #1: loss = 0.668999 (* 1 = 0.668999 loss)
I1005 00:31:12.797935 17840 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1005 00:31:16.061924 17840 solver.cpp:218] Iteration 3700 (30.6352 iter/s, 3.26422s/100 iters), loss = 0.783182
I1005 00:31:16.061924 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1005 00:31:16.061924 17840 solver.cpp:237]     Train net output #1: loss = 0.783182 (* 1 = 0.783182 loss)
I1005 00:31:16.061924 17840 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1005 00:31:19.337930 17840 solver.cpp:218] Iteration 3800 (30.5364 iter/s, 3.27478s/100 iters), loss = 0.638407
I1005 00:31:19.337930 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:31:19.337930 17840 solver.cpp:237]     Train net output #1: loss = 0.638407 (* 1 = 0.638407 loss)
I1005 00:31:19.337930 17840 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1005 00:31:22.616932 17840 solver.cpp:218] Iteration 3900 (30.4939 iter/s, 3.27935s/100 iters), loss = 0.676925
I1005 00:31:22.616932 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1005 00:31:22.616932 17840 solver.cpp:237]     Train net output #1: loss = 0.676925 (* 1 = 0.676925 loss)
I1005 00:31:22.616932 17840 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1005 00:31:25.723922  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:31:25.854923 17840 solver.cpp:330] Iteration 4000, Testing net (#0)
I1005 00:31:25.854923 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:31:26.509922 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:31:26.535922 17840 solver.cpp:397]     Test net output #0: accuracy = 0.736
I1005 00:31:26.535922 17840 solver.cpp:397]     Test net output #1: loss = 0.759522 (* 1 = 0.759522 loss)
I1005 00:31:26.566933 17840 solver.cpp:218] Iteration 4000 (25.3206 iter/s, 3.94935s/100 iters), loss = 0.684235
I1005 00:31:26.566933 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1005 00:31:26.566933 17840 solver.cpp:237]     Train net output #1: loss = 0.684235 (* 1 = 0.684235 loss)
I1005 00:31:26.566933 17840 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1005 00:31:29.845937 17840 solver.cpp:218] Iteration 4100 (30.4957 iter/s, 3.27915s/100 iters), loss = 0.659801
I1005 00:31:29.845937 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:31:29.845937 17840 solver.cpp:237]     Train net output #1: loss = 0.659801 (* 1 = 0.659801 loss)
I1005 00:31:29.845937 17840 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1005 00:31:33.137936 17840 solver.cpp:218] Iteration 4200 (30.3854 iter/s, 3.29106s/100 iters), loss = 0.702577
I1005 00:31:33.137936 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1005 00:31:33.137936 17840 solver.cpp:237]     Train net output #1: loss = 0.702577 (* 1 = 0.702577 loss)
I1005 00:31:33.137936 17840 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1005 00:31:36.401937 17840 solver.cpp:218] Iteration 4300 (30.6397 iter/s, 3.26374s/100 iters), loss = 0.599735
I1005 00:31:36.401937 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:31:36.401937 17840 solver.cpp:237]     Train net output #1: loss = 0.599735 (* 1 = 0.599735 loss)
I1005 00:31:36.401937 17840 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1005 00:31:39.661940 17840 solver.cpp:218] Iteration 4400 (30.6771 iter/s, 3.25976s/100 iters), loss = 0.673768
I1005 00:31:39.661940 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1005 00:31:39.661940 17840 solver.cpp:237]     Train net output #1: loss = 0.673768 (* 1 = 0.673768 loss)
I1005 00:31:39.661940 17840 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1005 00:31:42.777921  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:31:42.937935 17840 solver.cpp:218] Iteration 4500 (30.5234 iter/s, 3.27617s/100 iters), loss = 0.733799
I1005 00:31:42.938935 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1005 00:31:42.938935 17840 solver.cpp:237]     Train net output #1: loss = 0.733799 (* 1 = 0.733799 loss)
I1005 00:31:42.938935 17840 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1005 00:31:46.208920 17840 solver.cpp:218] Iteration 4600 (30.5782 iter/s, 3.2703s/100 iters), loss = 0.606836
I1005 00:31:46.208920 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1005 00:31:46.208920 17840 solver.cpp:237]     Train net output #1: loss = 0.606836 (* 1 = 0.606836 loss)
I1005 00:31:46.208920 17840 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1005 00:31:49.484923 17840 solver.cpp:218] Iteration 4700 (30.5336 iter/s, 3.27508s/100 iters), loss = 0.657121
I1005 00:31:49.484923 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:31:49.484923 17840 solver.cpp:237]     Train net output #1: loss = 0.657121 (* 1 = 0.657121 loss)
I1005 00:31:49.484923 17840 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1005 00:31:52.764921 17840 solver.cpp:218] Iteration 4800 (30.4881 iter/s, 3.27996s/100 iters), loss = 0.583375
I1005 00:31:52.764921 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:31:52.764921 17840 solver.cpp:237]     Train net output #1: loss = 0.583375 (* 1 = 0.583375 loss)
I1005 00:31:52.764921 17840 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1005 00:31:56.040935 17840 solver.cpp:218] Iteration 4900 (30.5322 iter/s, 3.27523s/100 iters), loss = 0.64096
I1005 00:31:56.040935 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1005 00:31:56.040935 17840 solver.cpp:237]     Train net output #1: loss = 0.64096 (* 1 = 0.64096 loss)
I1005 00:31:56.040935 17840 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1005 00:31:59.160922  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:31:59.289922 17840 solver.cpp:330] Iteration 5000, Testing net (#0)
I1005 00:31:59.289922 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:31:59.936935 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:31:59.962929 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7484
I1005 00:31:59.962929 17840 solver.cpp:397]     Test net output #1: loss = 0.744793 (* 1 = 0.744793 loss)
I1005 00:31:59.992928 17840 solver.cpp:218] Iteration 5000 (25.3013 iter/s, 3.95237s/100 iters), loss = 0.760878
I1005 00:31:59.992928 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1005 00:31:59.992928 17840 solver.cpp:237]     Train net output #1: loss = 0.760878 (* 1 = 0.760878 loss)
I1005 00:31:59.992928 17840 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I1005 00:31:59.992928 17840 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I1005 00:32:03.268936 17840 solver.cpp:218] Iteration 5100 (30.5272 iter/s, 3.27577s/100 iters), loss = 0.493963
I1005 00:32:03.268936 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:32:03.268936 17840 solver.cpp:237]     Train net output #1: loss = 0.493963 (* 1 = 0.493963 loss)
I1005 00:32:03.268936 17840 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I1005 00:32:06.534935 17840 solver.cpp:218] Iteration 5200 (30.6237 iter/s, 3.26544s/100 iters), loss = 0.530874
I1005 00:32:06.534935 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:32:06.534935 17840 solver.cpp:237]     Train net output #1: loss = 0.530874 (* 1 = 0.530874 loss)
I1005 00:32:06.534935 17840 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I1005 00:32:09.813145 17840 solver.cpp:218] Iteration 5300 (30.514 iter/s, 3.27718s/100 iters), loss = 0.470326
I1005 00:32:09.813145 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:32:09.813145 17840 solver.cpp:237]     Train net output #1: loss = 0.470326 (* 1 = 0.470326 loss)
I1005 00:32:09.813145 17840 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I1005 00:32:13.092147 17840 solver.cpp:218] Iteration 5400 (30.4941 iter/s, 3.27933s/100 iters), loss = 0.540987
I1005 00:32:13.092147 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 00:32:13.092147 17840 solver.cpp:237]     Train net output #1: loss = 0.540987 (* 1 = 0.540987 loss)
I1005 00:32:13.092147 17840 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I1005 00:32:16.214277  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:32:16.377292 17840 solver.cpp:218] Iteration 5500 (30.4498 iter/s, 3.2841s/100 iters), loss = 0.586522
I1005 00:32:16.377292 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:32:16.377292 17840 solver.cpp:237]     Train net output #1: loss = 0.586522 (* 1 = 0.586522 loss)
I1005 00:32:16.377292 17840 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I1005 00:32:19.647277 17840 solver.cpp:218] Iteration 5600 (30.5825 iter/s, 3.26984s/100 iters), loss = 0.531387
I1005 00:32:19.647277 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 00:32:19.647277 17840 solver.cpp:237]     Train net output #1: loss = 0.531387 (* 1 = 0.531387 loss)
I1005 00:32:19.647277 17840 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I1005 00:32:22.932296 17840 solver.cpp:218] Iteration 5700 (30.4421 iter/s, 3.28492s/100 iters), loss = 0.528224
I1005 00:32:22.932296 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:32:22.932296 17840 solver.cpp:237]     Train net output #1: loss = 0.528224 (* 1 = 0.528224 loss)
I1005 00:32:22.932296 17840 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I1005 00:32:26.215287 17840 solver.cpp:218] Iteration 5800 (30.4647 iter/s, 3.28249s/100 iters), loss = 0.488405
I1005 00:32:26.215287 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:32:26.215287 17840 solver.cpp:237]     Train net output #1: loss = 0.488405 (* 1 = 0.488405 loss)
I1005 00:32:26.215287 17840 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I1005 00:32:29.502295 17840 solver.cpp:218] Iteration 5900 (30.421 iter/s, 3.28721s/100 iters), loss = 0.514446
I1005 00:32:29.502295 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1005 00:32:29.502295 17840 solver.cpp:237]     Train net output #1: loss = 0.514446 (* 1 = 0.514446 loss)
I1005 00:32:29.502295 17840 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I1005 00:32:32.624277  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:32:32.754279 17840 solver.cpp:330] Iteration 6000, Testing net (#0)
I1005 00:32:32.754279 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:32:33.402277 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:32:33.427278 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7851
I1005 00:32:33.427278 17840 solver.cpp:397]     Test net output #1: loss = 0.627391 (* 1 = 0.627391 loss)
I1005 00:32:33.458292 17840 solver.cpp:218] Iteration 6000 (25.2848 iter/s, 3.95495s/100 iters), loss = 0.532836
I1005 00:32:33.458292 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:32:33.458292 17840 solver.cpp:237]     Train net output #1: loss = 0.532836 (* 1 = 0.532836 loss)
I1005 00:32:33.458292 17840 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I1005 00:32:36.726307 17840 solver.cpp:218] Iteration 6100 (30.5988 iter/s, 3.2681s/100 iters), loss = 0.460987
I1005 00:32:36.726307 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:32:36.726307 17840 solver.cpp:237]     Train net output #1: loss = 0.460987 (* 1 = 0.460987 loss)
I1005 00:32:36.726307 17840 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I1005 00:32:39.996312 17840 solver.cpp:218] Iteration 6200 (30.5846 iter/s, 3.26961s/100 iters), loss = 0.543332
I1005 00:32:39.996312 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:32:39.996312 17840 solver.cpp:237]     Train net output #1: loss = 0.543332 (* 1 = 0.543332 loss)
I1005 00:32:39.996312 17840 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I1005 00:32:43.274276 17840 solver.cpp:218] Iteration 6300 (30.5105 iter/s, 3.27755s/100 iters), loss = 0.423702
I1005 00:32:43.274276 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:32:43.274276 17840 solver.cpp:237]     Train net output #1: loss = 0.423702 (* 1 = 0.423702 loss)
I1005 00:32:43.274276 17840 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I1005 00:32:46.537286 17840 solver.cpp:218] Iteration 6400 (30.6558 iter/s, 3.26202s/100 iters), loss = 0.483212
I1005 00:32:46.537286 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:32:46.537286 17840 solver.cpp:237]     Train net output #1: loss = 0.483212 (* 1 = 0.483212 loss)
I1005 00:32:46.537286 17840 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I1005 00:32:49.652287  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:32:49.813295 17840 solver.cpp:218] Iteration 6500 (30.5216 iter/s, 3.27637s/100 iters), loss = 0.48547
I1005 00:32:49.813295 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:32:49.813295 17840 solver.cpp:237]     Train net output #1: loss = 0.48547 (* 1 = 0.48547 loss)
I1005 00:32:49.813295 17840 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I1005 00:32:53.083279 17840 solver.cpp:218] Iteration 6600 (30.5918 iter/s, 3.26885s/100 iters), loss = 0.487243
I1005 00:32:53.083279 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:32:53.083279 17840 solver.cpp:237]     Train net output #1: loss = 0.487243 (* 1 = 0.487243 loss)
I1005 00:32:53.083279 17840 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I1005 00:32:56.382292 17840 solver.cpp:218] Iteration 6700 (30.3149 iter/s, 3.29871s/100 iters), loss = 0.573493
I1005 00:32:56.382292 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:32:56.382292 17840 solver.cpp:237]     Train net output #1: loss = 0.573493 (* 1 = 0.573493 loss)
I1005 00:32:56.382292 17840 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I1005 00:32:59.716789 17840 solver.cpp:218] Iteration 6800 (29.9933 iter/s, 3.33408s/100 iters), loss = 0.440487
I1005 00:32:59.716789 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:32:59.716789 17840 solver.cpp:237]     Train net output #1: loss = 0.440487 (* 1 = 0.440487 loss)
I1005 00:32:59.716789 17840 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I1005 00:33:03.059788 17840 solver.cpp:218] Iteration 6900 (29.9168 iter/s, 3.34261s/100 iters), loss = 0.481957
I1005 00:33:03.059788 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:33:03.059788 17840 solver.cpp:237]     Train net output #1: loss = 0.481957 (* 1 = 0.481957 loss)
I1005 00:33:03.059788 17840 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I1005 00:33:06.196789  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:33:06.326787 17840 solver.cpp:330] Iteration 7000, Testing net (#0)
I1005 00:33:06.326787 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:33:06.974786 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:33:07.000789 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7888
I1005 00:33:07.000789 17840 solver.cpp:397]     Test net output #1: loss = 0.624262 (* 1 = 0.624262 loss)
I1005 00:33:07.030800 17840 solver.cpp:218] Iteration 7000 (25.1806 iter/s, 3.97131s/100 iters), loss = 0.525062
I1005 00:33:07.030800 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:33:07.030800 17840 solver.cpp:237]     Train net output #1: loss = 0.525062 (* 1 = 0.525062 loss)
I1005 00:33:07.030800 17840 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I1005 00:33:10.339287 17840 solver.cpp:218] Iteration 7100 (30.2364 iter/s, 3.30727s/100 iters), loss = 0.495992
I1005 00:33:10.339287 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:33:10.339287 17840 solver.cpp:237]     Train net output #1: loss = 0.495992 (* 1 = 0.495992 loss)
I1005 00:33:10.339287 17840 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I1005 00:33:13.588471 17840 solver.cpp:218] Iteration 7200 (30.7811 iter/s, 3.24875s/100 iters), loss = 0.557028
I1005 00:33:13.588471 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:33:13.588471 17840 solver.cpp:237]     Train net output #1: loss = 0.557028 (* 1 = 0.557028 loss)
I1005 00:33:13.588471 17840 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I1005 00:33:16.912206 17840 solver.cpp:218] Iteration 7300 (30.0884 iter/s, 3.32354s/100 iters), loss = 0.437988
I1005 00:33:16.912206 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:33:16.912206 17840 solver.cpp:237]     Train net output #1: loss = 0.437988 (* 1 = 0.437988 loss)
I1005 00:33:16.912206 17840 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I1005 00:33:20.233454 17840 solver.cpp:218] Iteration 7400 (30.0257 iter/s, 3.33048s/100 iters), loss = 0.492707
I1005 00:33:20.233454 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:33:20.233454 17840 solver.cpp:237]     Train net output #1: loss = 0.492707 (* 1 = 0.492707 loss)
I1005 00:33:20.233454 17840 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I1005 00:33:23.390988  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:33:23.550500 17840 solver.cpp:218] Iteration 7500 (30.2427 iter/s, 3.30659s/100 iters), loss = 0.49571
I1005 00:33:23.550500 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:33:23.550500 17840 solver.cpp:237]     Train net output #1: loss = 0.49571 (* 1 = 0.49571 loss)
I1005 00:33:23.550500 17840 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I1005 00:33:26.822252 17840 solver.cpp:218] Iteration 7600 (30.5526 iter/s, 3.27304s/100 iters), loss = 0.523692
I1005 00:33:26.822252 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:33:26.822252 17840 solver.cpp:237]     Train net output #1: loss = 0.523692 (* 1 = 0.523692 loss)
I1005 00:33:26.822252 17840 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I1005 00:33:30.077822 17840 solver.cpp:218] Iteration 7700 (30.6647 iter/s, 3.26108s/100 iters), loss = 0.544736
I1005 00:33:30.077822 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:33:30.077822 17840 solver.cpp:237]     Train net output #1: loss = 0.544736 (* 1 = 0.544736 loss)
I1005 00:33:30.077822 17840 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I1005 00:33:33.354537 17840 solver.cpp:218] Iteration 7800 (30.5768 iter/s, 3.27045s/100 iters), loss = 0.477168
I1005 00:33:33.354537 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:33:33.354537 17840 solver.cpp:237]     Train net output #1: loss = 0.477168 (* 1 = 0.477168 loss)
I1005 00:33:33.354537 17840 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I1005 00:33:36.611551 17840 solver.cpp:218] Iteration 7900 (30.5925 iter/s, 3.26877s/100 iters), loss = 0.522005
I1005 00:33:36.611551 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 00:33:36.611551 17840 solver.cpp:237]     Train net output #1: loss = 0.522005 (* 1 = 0.522005 loss)
I1005 00:33:36.611551 17840 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I1005 00:33:39.729225  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:33:39.854239 17840 solver.cpp:330] Iteration 8000, Testing net (#0)
I1005 00:33:39.854239 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:33:40.500571 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:33:40.531821 17840 solver.cpp:397]     Test net output #0: accuracy = 0.79
I1005 00:33:40.531821 17840 solver.cpp:397]     Test net output #1: loss = 0.621788 (* 1 = 0.621788 loss)
I1005 00:33:40.563086 17840 solver.cpp:218] Iteration 8000 (25.3455 iter/s, 3.94548s/100 iters), loss = 0.463739
I1005 00:33:40.563086 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:33:40.563086 17840 solver.cpp:237]     Train net output #1: loss = 0.463739 (* 1 = 0.463739 loss)
I1005 00:33:40.563086 17840 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I1005 00:33:43.828294 17840 solver.cpp:218] Iteration 8100 (30.5648 iter/s, 3.27174s/100 iters), loss = 0.418344
I1005 00:33:43.828294 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:33:43.828294 17840 solver.cpp:237]     Train net output #1: loss = 0.418344 (* 1 = 0.418344 loss)
I1005 00:33:43.828294 17840 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I1005 00:33:47.106415 17840 solver.cpp:218] Iteration 8200 (30.5534 iter/s, 3.27296s/100 iters), loss = 0.554618
I1005 00:33:47.106415 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:33:47.106415 17840 solver.cpp:237]     Train net output #1: loss = 0.554618 (* 1 = 0.554618 loss)
I1005 00:33:47.106415 17840 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I1005 00:33:50.379345 17840 solver.cpp:218] Iteration 8300 (30.5559 iter/s, 3.27269s/100 iters), loss = 0.425905
I1005 00:33:50.379345 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:33:50.379345 17840 solver.cpp:237]     Train net output #1: loss = 0.425905 (* 1 = 0.425905 loss)
I1005 00:33:50.379345 17840 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I1005 00:33:53.650399 17840 solver.cpp:218] Iteration 8400 (30.5574 iter/s, 3.27253s/100 iters), loss = 0.491604
I1005 00:33:53.650399 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:33:53.650399 17840 solver.cpp:237]     Train net output #1: loss = 0.491604 (* 1 = 0.491604 loss)
I1005 00:33:53.650399 17840 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I1005 00:33:56.771287  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:33:56.927569 17840 solver.cpp:218] Iteration 8500 (30.571 iter/s, 3.27107s/100 iters), loss = 0.543034
I1005 00:33:56.927569 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:33:56.927569 17840 solver.cpp:237]     Train net output #1: loss = 0.543034 (* 1 = 0.543034 loss)
I1005 00:33:56.927569 17840 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I1005 00:34:00.197382 17840 solver.cpp:218] Iteration 8600 (30.5872 iter/s, 3.26935s/100 iters), loss = 0.464078
I1005 00:34:00.197382 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:34:00.197382 17840 solver.cpp:237]     Train net output #1: loss = 0.464078 (* 1 = 0.464078 loss)
I1005 00:34:00.197382 17840 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I1005 00:34:03.468894 17840 solver.cpp:218] Iteration 8700 (30.5594 iter/s, 3.27232s/100 iters), loss = 0.510048
I1005 00:34:03.468894 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:34:03.468894 17840 solver.cpp:237]     Train net output #1: loss = 0.510048 (* 1 = 0.510048 loss)
I1005 00:34:03.468894 17840 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I1005 00:34:06.735443 17840 solver.cpp:218] Iteration 8800 (30.5784 iter/s, 3.27028s/100 iters), loss = 0.450415
I1005 00:34:06.735443 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:34:06.735443 17840 solver.cpp:237]     Train net output #1: loss = 0.450415 (* 1 = 0.450415 loss)
I1005 00:34:06.735443 17840 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I1005 00:34:10.010234 17840 solver.cpp:218] Iteration 8900 (30.5493 iter/s, 3.27339s/100 iters), loss = 0.48453
I1005 00:34:10.010234 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:34:10.010234 17840 solver.cpp:237]     Train net output #1: loss = 0.48453 (* 1 = 0.48453 loss)
I1005 00:34:10.010234 17840 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I1005 00:34:13.126276  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:34:13.261553 17840 solver.cpp:330] Iteration 9000, Testing net (#0)
I1005 00:34:13.261553 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:34:13.903991 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:34:13.935242 17840 solver.cpp:397]     Test net output #0: accuracy = 0.789
I1005 00:34:13.935242 17840 solver.cpp:397]     Test net output #1: loss = 0.619834 (* 1 = 0.619834 loss)
I1005 00:34:13.966496 17840 solver.cpp:218] Iteration 9000 (25.316 iter/s, 3.95007s/100 iters), loss = 0.480985
I1005 00:34:13.966496 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:34:13.966496 17840 solver.cpp:237]     Train net output #1: loss = 0.480985 (* 1 = 0.480985 loss)
I1005 00:34:13.966496 17840 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I1005 00:34:17.242913 17840 solver.cpp:218] Iteration 9100 (30.5576 iter/s, 3.2725s/100 iters), loss = 0.454815
I1005 00:34:17.242913 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:34:17.242913 17840 solver.cpp:237]     Train net output #1: loss = 0.454815 (* 1 = 0.454815 loss)
I1005 00:34:17.242913 17840 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I1005 00:34:20.513010 17840 solver.cpp:218] Iteration 9200 (30.5778 iter/s, 3.27034s/100 iters), loss = 0.504878
I1005 00:34:20.513010 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:34:20.513010 17840 solver.cpp:237]     Train net output #1: loss = 0.504878 (* 1 = 0.504878 loss)
I1005 00:34:20.513010 17840 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I1005 00:34:23.773281 17840 solver.cpp:218] Iteration 9300 (30.5733 iter/s, 3.27082s/100 iters), loss = 0.420865
I1005 00:34:23.773281 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:34:23.773281 17840 solver.cpp:237]     Train net output #1: loss = 0.420865 (* 1 = 0.420865 loss)
I1005 00:34:23.773281 17840 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I1005 00:34:27.048681 17840 solver.cpp:218] Iteration 9400 (30.5887 iter/s, 3.26918s/100 iters), loss = 0.478548
I1005 00:34:27.048681 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:34:27.048681 17840 solver.cpp:237]     Train net output #1: loss = 0.478548 (* 1 = 0.478548 loss)
I1005 00:34:27.048681 17840 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I1005 00:34:30.160037  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:34:30.323516 17840 solver.cpp:218] Iteration 9500 (30.5957 iter/s, 3.26843s/100 iters), loss = 0.421037
I1005 00:34:30.323516 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:34:30.323516 17840 solver.cpp:237]     Train net output #1: loss = 0.421037 (* 1 = 0.421037 loss)
I1005 00:34:30.323516 17840 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1005 00:34:33.597280 17840 solver.cpp:218] Iteration 9600 (30.5369 iter/s, 3.27472s/100 iters), loss = 0.463965
I1005 00:34:33.597280 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:34:33.597280 17840 solver.cpp:237]     Train net output #1: loss = 0.463965 (* 1 = 0.463965 loss)
I1005 00:34:33.597280 17840 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1005 00:34:36.871028 17840 solver.cpp:218] Iteration 9700 (30.563 iter/s, 3.27193s/100 iters), loss = 0.45763
I1005 00:34:36.871028 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:34:36.871028 17840 solver.cpp:237]     Train net output #1: loss = 0.45763 (* 1 = 0.45763 loss)
I1005 00:34:36.871028 17840 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I1005 00:34:40.138954 17840 solver.cpp:218] Iteration 9800 (30.5952 iter/s, 3.26849s/100 iters), loss = 0.411361
I1005 00:34:40.138954 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:34:40.138954 17840 solver.cpp:237]     Train net output #1: loss = 0.411361 (* 1 = 0.411361 loss)
I1005 00:34:40.138954 17840 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1005 00:34:43.397660 17840 solver.cpp:218] Iteration 9900 (30.5608 iter/s, 3.27217s/100 iters), loss = 0.441876
I1005 00:34:43.397660 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:34:43.397660 17840 solver.cpp:237]     Train net output #1: loss = 0.441876 (* 1 = 0.441876 loss)
I1005 00:34:43.397660 17840 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I1005 00:34:46.514879  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:34:46.639875 17840 solver.cpp:330] Iteration 10000, Testing net (#0)
I1005 00:34:46.639875 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:34:47.301352 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:34:47.330691 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7898
I1005 00:34:47.330691 17840 solver.cpp:397]     Test net output #1: loss = 0.620224 (* 1 = 0.620224 loss)
I1005 00:34:47.361941 17840 solver.cpp:218] Iteration 10000 (25.3187 iter/s, 3.94965s/100 iters), loss = 0.449625
I1005 00:34:47.361941 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:34:47.361941 17840 solver.cpp:237]     Train net output #1: loss = 0.449625 (* 1 = 0.449625 loss)
I1005 00:34:47.361941 17840 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I1005 00:34:47.361941 17840 sgd_solver.cpp:105] Iteration 10000, lr = 0.0001
I1005 00:34:50.622983 17840 solver.cpp:218] Iteration 10100 (30.6302 iter/s, 3.26475s/100 iters), loss = 0.464047
I1005 00:34:50.622983 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:34:50.622983 17840 solver.cpp:237]     Train net output #1: loss = 0.464047 (* 1 = 0.464047 loss)
I1005 00:34:50.622983 17840 sgd_solver.cpp:105] Iteration 10100, lr = 0.0001
I1005 00:34:53.885263 17840 solver.cpp:218] Iteration 10200 (30.5872 iter/s, 3.26934s/100 iters), loss = 0.490901
I1005 00:34:53.885263 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:34:53.885263 17840 solver.cpp:237]     Train net output #1: loss = 0.490901 (* 1 = 0.490901 loss)
I1005 00:34:53.885263 17840 sgd_solver.cpp:105] Iteration 10200, lr = 0.0001
I1005 00:34:57.150409 17840 solver.cpp:218] Iteration 10300 (30.6648 iter/s, 3.26107s/100 iters), loss = 0.411072
I1005 00:34:57.150409 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:34:57.150409 17840 solver.cpp:237]     Train net output #1: loss = 0.411072 (* 1 = 0.411072 loss)
I1005 00:34:57.150409 17840 sgd_solver.cpp:105] Iteration 10300, lr = 0.0001
I1005 00:35:00.411236 17840 solver.cpp:218] Iteration 10400 (30.6263 iter/s, 3.26517s/100 iters), loss = 0.452814
I1005 00:35:00.411236 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:35:00.411236 17840 solver.cpp:237]     Train net output #1: loss = 0.452814 (* 1 = 0.452814 loss)
I1005 00:35:00.411236 17840 sgd_solver.cpp:105] Iteration 10400, lr = 0.0001
I1005 00:35:03.520225  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:35:03.685880 17840 solver.cpp:218] Iteration 10500 (30.5906 iter/s, 3.26898s/100 iters), loss = 0.443387
I1005 00:35:03.685880 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:35:03.685880 17840 solver.cpp:237]     Train net output #1: loss = 0.443387 (* 1 = 0.443387 loss)
I1005 00:35:03.685880 17840 sgd_solver.cpp:105] Iteration 10500, lr = 0.0001
I1005 00:35:06.953305 17840 solver.cpp:218] Iteration 10600 (30.5576 iter/s, 3.27251s/100 iters), loss = 0.452506
I1005 00:35:06.953305 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:35:06.953305 17840 solver.cpp:237]     Train net output #1: loss = 0.452506 (* 1 = 0.452506 loss)
I1005 00:35:06.953305 17840 sgd_solver.cpp:105] Iteration 10600, lr = 0.0001
I1005 00:35:10.231591 17840 solver.cpp:218] Iteration 10700 (30.562 iter/s, 3.27204s/100 iters), loss = 0.520588
I1005 00:35:10.231591 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:35:10.231591 17840 solver.cpp:237]     Train net output #1: loss = 0.520588 (* 1 = 0.520588 loss)
I1005 00:35:10.231591 17840 sgd_solver.cpp:105] Iteration 10700, lr = 0.0001
I1005 00:35:13.508333 17840 solver.cpp:218] Iteration 10800 (30.5789 iter/s, 3.27023s/100 iters), loss = 0.369368
I1005 00:35:13.508333 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1005 00:35:13.508333 17840 solver.cpp:237]     Train net output #1: loss = 0.369368 (* 1 = 0.369368 loss)
I1005 00:35:13.508333 17840 sgd_solver.cpp:105] Iteration 10800, lr = 0.0001
I1005 00:35:16.765211 17840 solver.cpp:218] Iteration 10900 (30.5825 iter/s, 3.26984s/100 iters), loss = 0.452614
I1005 00:35:16.765211 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:35:16.765211 17840 solver.cpp:237]     Train net output #1: loss = 0.452614 (* 1 = 0.452614 loss)
I1005 00:35:16.765211 17840 sgd_solver.cpp:105] Iteration 10900, lr = 0.0001
I1005 00:35:19.893504  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:35:20.018502 17840 solver.cpp:330] Iteration 11000, Testing net (#0)
I1005 00:35:20.018502 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:35:20.676174 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:35:20.691787 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7923
I1005 00:35:20.691787 17840 solver.cpp:397]     Test net output #1: loss = 0.605959 (* 1 = 0.605959 loss)
I1005 00:35:20.723036 17840 solver.cpp:218] Iteration 11000 (25.2972 iter/s, 3.953s/100 iters), loss = 0.347554
I1005 00:35:20.723036 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1005 00:35:20.723036 17840 solver.cpp:237]     Train net output #1: loss = 0.347554 (* 1 = 0.347554 loss)
I1005 00:35:20.723036 17840 sgd_solver.cpp:105] Iteration 11000, lr = 0.0001
I1005 00:35:23.991293 17840 solver.cpp:218] Iteration 11100 (30.6128 iter/s, 3.26661s/100 iters), loss = 0.374478
I1005 00:35:23.991293 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:35:23.991293 17840 solver.cpp:237]     Train net output #1: loss = 0.374478 (* 1 = 0.374478 loss)
I1005 00:35:23.991293 17840 sgd_solver.cpp:105] Iteration 11100, lr = 0.0001
I1005 00:35:27.258025 17840 solver.cpp:218] Iteration 11200 (30.5913 iter/s, 3.2689s/100 iters), loss = 0.434446
I1005 00:35:27.258025 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:35:27.258025 17840 solver.cpp:237]     Train net output #1: loss = 0.434446 (* 1 = 0.434446 loss)
I1005 00:35:27.258025 17840 sgd_solver.cpp:105] Iteration 11200, lr = 0.0001
I1005 00:35:30.519619 17840 solver.cpp:218] Iteration 11300 (30.6574 iter/s, 3.26185s/100 iters), loss = 0.382745
I1005 00:35:30.519619 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:35:30.519619 17840 solver.cpp:237]     Train net output #1: loss = 0.382745 (* 1 = 0.382745 loss)
I1005 00:35:30.519619 17840 sgd_solver.cpp:105] Iteration 11300, lr = 0.0001
I1005 00:35:33.782891 17840 solver.cpp:218] Iteration 11400 (30.6224 iter/s, 3.26558s/100 iters), loss = 0.466892
I1005 00:35:33.782891 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:35:33.782891 17840 solver.cpp:237]     Train net output #1: loss = 0.466892 (* 1 = 0.466892 loss)
I1005 00:35:33.782891 17840 sgd_solver.cpp:105] Iteration 11400, lr = 0.0001
I1005 00:35:36.893950  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:35:37.050187 17840 solver.cpp:218] Iteration 11500 (30.633 iter/s, 3.26445s/100 iters), loss = 0.468616
I1005 00:35:37.050187 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:35:37.050187 17840 solver.cpp:237]     Train net output #1: loss = 0.468616 (* 1 = 0.468616 loss)
I1005 00:35:37.050187 17840 sgd_solver.cpp:105] Iteration 11500, lr = 0.0001
I1005 00:35:40.326333 17840 solver.cpp:218] Iteration 11600 (30.6348 iter/s, 3.26426s/100 iters), loss = 0.486925
I1005 00:35:40.326333 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:35:40.326333 17840 solver.cpp:237]     Train net output #1: loss = 0.486925 (* 1 = 0.486925 loss)
I1005 00:35:40.326333 17840 sgd_solver.cpp:105] Iteration 11600, lr = 0.0001
I1005 00:35:43.592680 17840 solver.cpp:218] Iteration 11700 (30.6252 iter/s, 3.26529s/100 iters), loss = 0.466591
I1005 00:35:43.592680 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:35:43.592680 17840 solver.cpp:237]     Train net output #1: loss = 0.466591 (* 1 = 0.466591 loss)
I1005 00:35:43.592680 17840 sgd_solver.cpp:105] Iteration 11700, lr = 0.0001
I1005 00:35:46.850067 17840 solver.cpp:218] Iteration 11800 (30.6266 iter/s, 3.26513s/100 iters), loss = 0.4139
I1005 00:35:46.850067 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:35:46.850067 17840 solver.cpp:237]     Train net output #1: loss = 0.4139 (* 1 = 0.4139 loss)
I1005 00:35:46.850067 17840 sgd_solver.cpp:105] Iteration 11800, lr = 0.0001
I1005 00:35:50.125720 17840 solver.cpp:218] Iteration 11900 (30.5644 iter/s, 3.27178s/100 iters), loss = 0.4591
I1005 00:35:50.125720 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:35:50.125720 17840 solver.cpp:237]     Train net output #1: loss = 0.4591 (* 1 = 0.4591 loss)
I1005 00:35:50.125720 17840 sgd_solver.cpp:105] Iteration 11900, lr = 0.0001
I1005 00:35:53.232997  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:35:53.358011 17840 solver.cpp:330] Iteration 12000, Testing net (#0)
I1005 00:35:53.358011 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:35:54.003077 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:35:54.040005 17840 solver.cpp:397]     Test net output #0: accuracy = 0.793
I1005 00:35:54.040005 17840 solver.cpp:397]     Test net output #1: loss = 0.605511 (* 1 = 0.605511 loss)
I1005 00:35:54.065135 17840 solver.cpp:218] Iteration 12000 (25.3822 iter/s, 3.93977s/100 iters), loss = 0.392689
I1005 00:35:54.065135 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:35:54.065135 17840 solver.cpp:237]     Train net output #1: loss = 0.392689 (* 1 = 0.392689 loss)
I1005 00:35:54.065135 17840 sgd_solver.cpp:105] Iteration 12000, lr = 0.0001
I1005 00:35:57.326854 17840 solver.cpp:218] Iteration 12100 (30.5901 iter/s, 3.26903s/100 iters), loss = 0.420902
I1005 00:35:57.326854 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:35:57.326854 17840 solver.cpp:237]     Train net output #1: loss = 0.420902 (* 1 = 0.420902 loss)
I1005 00:35:57.326854 17840 sgd_solver.cpp:105] Iteration 12100, lr = 0.0001
I1005 00:36:00.601708 17840 solver.cpp:218] Iteration 12200 (30.5691 iter/s, 3.27127s/100 iters), loss = 0.521545
I1005 00:36:00.601708 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:36:00.601708 17840 solver.cpp:237]     Train net output #1: loss = 0.521545 (* 1 = 0.521545 loss)
I1005 00:36:00.601708 17840 sgd_solver.cpp:105] Iteration 12200, lr = 0.0001
I1005 00:36:03.880892 17840 solver.cpp:218] Iteration 12300 (30.5707 iter/s, 3.2711s/100 iters), loss = 0.387774
I1005 00:36:03.880892 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:36:03.880892 17840 solver.cpp:237]     Train net output #1: loss = 0.387774 (* 1 = 0.387774 loss)
I1005 00:36:03.880892 17840 sgd_solver.cpp:105] Iteration 12300, lr = 0.0001
I1005 00:36:07.152781 17840 solver.cpp:218] Iteration 12400 (30.5867 iter/s, 3.26939s/100 iters), loss = 0.443754
I1005 00:36:07.152781 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:36:07.152781 17840 solver.cpp:237]     Train net output #1: loss = 0.443754 (* 1 = 0.443754 loss)
I1005 00:36:07.152781 17840 sgd_solver.cpp:105] Iteration 12400, lr = 0.0001
I1005 00:36:10.250349  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:36:10.418962 17840 solver.cpp:218] Iteration 12500 (30.5761 iter/s, 3.27053s/100 iters), loss = 0.398586
I1005 00:36:10.418962 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:36:10.418962 17840 solver.cpp:237]     Train net output #1: loss = 0.398586 (* 1 = 0.398586 loss)
I1005 00:36:10.418962 17840 sgd_solver.cpp:105] Iteration 12500, lr = 0.0001
I1005 00:36:13.683280 17840 solver.cpp:218] Iteration 12600 (30.5479 iter/s, 3.27354s/100 iters), loss = 0.427661
I1005 00:36:13.683280 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:36:13.683280 17840 solver.cpp:237]     Train net output #1: loss = 0.427661 (* 1 = 0.427661 loss)
I1005 00:36:13.683280 17840 sgd_solver.cpp:105] Iteration 12600, lr = 0.0001
I1005 00:36:16.958020 17840 solver.cpp:218] Iteration 12700 (30.551 iter/s, 3.27321s/100 iters), loss = 0.499781
I1005 00:36:16.958020 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:36:16.958020 17840 solver.cpp:237]     Train net output #1: loss = 0.499781 (* 1 = 0.499781 loss)
I1005 00:36:16.958020 17840 sgd_solver.cpp:105] Iteration 12700, lr = 0.0001
I1005 00:36:20.225749 17840 solver.cpp:218] Iteration 12800 (30.5962 iter/s, 3.26837s/100 iters), loss = 0.396497
I1005 00:36:20.225749 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:36:20.225749 17840 solver.cpp:237]     Train net output #1: loss = 0.396497 (* 1 = 0.396497 loss)
I1005 00:36:20.225749 17840 sgd_solver.cpp:105] Iteration 12800, lr = 0.0001
I1005 00:36:23.502079 17840 solver.cpp:218] Iteration 12900 (30.5883 iter/s, 3.26922s/100 iters), loss = 0.440407
I1005 00:36:23.502079 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:36:23.502079 17840 solver.cpp:237]     Train net output #1: loss = 0.440407 (* 1 = 0.440407 loss)
I1005 00:36:23.502079 17840 sgd_solver.cpp:105] Iteration 12900, lr = 0.0001
I1005 00:36:26.604600  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:36:26.743787 17840 solver.cpp:330] Iteration 13000, Testing net (#0)
I1005 00:36:26.743787 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:36:27.394923 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:36:27.410565 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7922
I1005 00:36:27.410565 17840 solver.cpp:397]     Test net output #1: loss = 0.605596 (* 1 = 0.605596 loss)
I1005 00:36:27.441800 17840 solver.cpp:218] Iteration 13000 (25.3497 iter/s, 3.94483s/100 iters), loss = 0.441893
I1005 00:36:27.441800 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:36:27.441800 17840 solver.cpp:237]     Train net output #1: loss = 0.441893 (* 1 = 0.441893 loss)
I1005 00:36:27.441800 17840 sgd_solver.cpp:105] Iteration 13000, lr = 0.0001
I1005 00:36:30.725244 17840 solver.cpp:218] Iteration 13100 (30.527 iter/s, 3.27579s/100 iters), loss = 0.396787
I1005 00:36:30.725244 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:36:30.725244 17840 solver.cpp:237]     Train net output #1: loss = 0.396787 (* 1 = 0.396787 loss)
I1005 00:36:30.725244 17840 sgd_solver.cpp:105] Iteration 13100, lr = 0.0001
I1005 00:36:33.987573 17840 solver.cpp:218] Iteration 13200 (30.5799 iter/s, 3.27012s/100 iters), loss = 0.497024
I1005 00:36:33.987573 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:36:33.987573 17840 solver.cpp:237]     Train net output #1: loss = 0.497024 (* 1 = 0.497024 loss)
I1005 00:36:33.987573 17840 sgd_solver.cpp:105] Iteration 13200, lr = 0.0001
I1005 00:36:37.263603 17840 solver.cpp:218] Iteration 13300 (30.5531 iter/s, 3.27299s/100 iters), loss = 0.434677
I1005 00:36:37.263603 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:36:37.263603 17840 solver.cpp:237]     Train net output #1: loss = 0.434677 (* 1 = 0.434677 loss)
I1005 00:36:37.263603 17840 sgd_solver.cpp:105] Iteration 13300, lr = 0.0001
I1005 00:36:40.545455 17840 solver.cpp:218] Iteration 13400 (30.5655 iter/s, 3.27166s/100 iters), loss = 0.456829
I1005 00:36:40.545455 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:36:40.545455 17840 solver.cpp:237]     Train net output #1: loss = 0.456829 (* 1 = 0.456829 loss)
I1005 00:36:40.545455 17840 sgd_solver.cpp:105] Iteration 13400, lr = 0.0001
I1005 00:36:43.641489  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:36:43.802224 17840 solver.cpp:218] Iteration 13500 (30.602 iter/s, 3.26776s/100 iters), loss = 0.457935
I1005 00:36:43.802224 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:36:43.802224 17840 solver.cpp:237]     Train net output #1: loss = 0.457935 (* 1 = 0.457935 loss)
I1005 00:36:43.802224 17840 sgd_solver.cpp:105] Iteration 13500, lr = 0.0001
I1005 00:36:47.079069 17840 solver.cpp:218] Iteration 13600 (30.5443 iter/s, 3.27393s/100 iters), loss = 0.422574
I1005 00:36:47.079069 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:36:47.079069 17840 solver.cpp:237]     Train net output #1: loss = 0.422574 (* 1 = 0.422574 loss)
I1005 00:36:47.079069 17840 sgd_solver.cpp:105] Iteration 13600, lr = 0.0001
I1005 00:36:50.352156 17840 solver.cpp:218] Iteration 13700 (30.5233 iter/s, 3.27619s/100 iters), loss = 0.450829
I1005 00:36:50.352156 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:36:50.352156 17840 solver.cpp:237]     Train net output #1: loss = 0.450829 (* 1 = 0.450829 loss)
I1005 00:36:50.352156 17840 sgd_solver.cpp:105] Iteration 13700, lr = 0.0001
I1005 00:36:53.625223 17840 solver.cpp:218] Iteration 13800 (30.5682 iter/s, 3.27137s/100 iters), loss = 0.360614
I1005 00:36:53.625223 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:36:53.625223 17840 solver.cpp:237]     Train net output #1: loss = 0.360614 (* 1 = 0.360614 loss)
I1005 00:36:53.625223 17840 sgd_solver.cpp:105] Iteration 13800, lr = 0.0001
I1005 00:36:56.909545 17840 solver.cpp:218] Iteration 13900 (30.5626 iter/s, 3.27197s/100 iters), loss = 0.42268
I1005 00:36:56.909545 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:36:56.909545 17840 solver.cpp:237]     Train net output #1: loss = 0.42268 (* 1 = 0.42268 loss)
I1005 00:36:56.909545 17840 sgd_solver.cpp:105] Iteration 13900, lr = 0.0001
I1005 00:37:00.009210  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:37:00.149837 17840 solver.cpp:330] Iteration 14000, Testing net (#0)
I1005 00:37:00.149837 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:37:00.798992 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:37:00.814613 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7938
I1005 00:37:00.814613 17840 solver.cpp:397]     Test net output #1: loss = 0.605354 (* 1 = 0.605354 loss)
I1005 00:37:00.845854 17840 solver.cpp:218] Iteration 14000 (25.3127 iter/s, 3.95059s/100 iters), loss = 0.429342
I1005 00:37:00.845854 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:37:00.845854 17840 solver.cpp:237]     Train net output #1: loss = 0.429342 (* 1 = 0.429342 loss)
I1005 00:37:00.845854 17840 sgd_solver.cpp:105] Iteration 14000, lr = 0.0001
I1005 00:37:04.116406 17840 solver.cpp:218] Iteration 14100 (30.5707 iter/s, 3.2711s/100 iters), loss = 0.468574
I1005 00:37:04.132047 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:37:04.132047 17840 solver.cpp:237]     Train net output #1: loss = 0.468574 (* 1 = 0.468574 loss)
I1005 00:37:04.132047 17840 sgd_solver.cpp:105] Iteration 14100, lr = 0.0001
I1005 00:37:07.397035 17840 solver.cpp:218] Iteration 14200 (30.6237 iter/s, 3.26544s/100 iters), loss = 0.490331
I1005 00:37:07.397035 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:37:07.397035 17840 solver.cpp:237]     Train net output #1: loss = 0.490331 (* 1 = 0.490331 loss)
I1005 00:37:07.397035 17840 sgd_solver.cpp:105] Iteration 14200, lr = 0.0001
I1005 00:37:10.658666 17840 solver.cpp:218] Iteration 14300 (30.5684 iter/s, 3.27135s/100 iters), loss = 0.390972
I1005 00:37:10.658666 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:37:10.658666 17840 solver.cpp:237]     Train net output #1: loss = 0.390972 (* 1 = 0.390972 loss)
I1005 00:37:10.658666 17840 sgd_solver.cpp:105] Iteration 14300, lr = 0.0001
I1005 00:37:13.945663 17840 solver.cpp:218] Iteration 14400 (30.5241 iter/s, 3.2761s/100 iters), loss = 0.460389
I1005 00:37:13.945663 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:37:13.945663 17840 solver.cpp:237]     Train net output #1: loss = 0.460389 (* 1 = 0.460389 loss)
I1005 00:37:13.945663 17840 sgd_solver.cpp:105] Iteration 14400, lr = 0.0001
I1005 00:37:17.038002  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:37:17.209874 17840 solver.cpp:218] Iteration 14500 (30.6152 iter/s, 3.26635s/100 iters), loss = 0.454723
I1005 00:37:17.209874 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:37:17.209874 17840 solver.cpp:237]     Train net output #1: loss = 0.454723 (* 1 = 0.454723 loss)
I1005 00:37:17.209874 17840 sgd_solver.cpp:105] Iteration 14500, lr = 0.0001
I1005 00:37:20.483893 17840 solver.cpp:218] Iteration 14600 (30.5694 iter/s, 3.27124s/100 iters), loss = 0.44306
I1005 00:37:20.483893 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:37:20.483893 17840 solver.cpp:237]     Train net output #1: loss = 0.44306 (* 1 = 0.44306 loss)
I1005 00:37:20.483893 17840 sgd_solver.cpp:105] Iteration 14600, lr = 0.0001
I1005 00:37:23.747786 17840 solver.cpp:218] Iteration 14700 (30.5899 iter/s, 3.26905s/100 iters), loss = 0.455944
I1005 00:37:23.747786 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:37:23.747786 17840 solver.cpp:237]     Train net output #1: loss = 0.455944 (* 1 = 0.455944 loss)
I1005 00:37:23.747786 17840 sgd_solver.cpp:105] Iteration 14700, lr = 0.0001
I1005 00:37:27.014017 17840 solver.cpp:218] Iteration 14800 (30.5884 iter/s, 3.26922s/100 iters), loss = 0.378173
I1005 00:37:27.014017 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:37:27.014017 17840 solver.cpp:237]     Train net output #1: loss = 0.378173 (* 1 = 0.378173 loss)
I1005 00:37:27.014017 17840 sgd_solver.cpp:105] Iteration 14800, lr = 0.0001
I1005 00:37:30.280635 17840 solver.cpp:218] Iteration 14900 (30.5687 iter/s, 3.27132s/100 iters), loss = 0.40956
I1005 00:37:30.280635 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:37:30.280635 17840 solver.cpp:237]     Train net output #1: loss = 0.40956 (* 1 = 0.40956 loss)
I1005 00:37:30.280635 17840 sgd_solver.cpp:105] Iteration 14900, lr = 0.0001
I1005 00:37:33.401618  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:37:33.526623 17840 solver.cpp:330] Iteration 15000, Testing net (#0)
I1005 00:37:33.526623 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:37:34.186110 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:37:34.201735 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7925
I1005 00:37:34.201735 17840 solver.cpp:397]     Test net output #1: loss = 0.605384 (* 1 = 0.605384 loss)
I1005 00:37:34.232975 17840 solver.cpp:218] Iteration 15000 (25.3032 iter/s, 3.95207s/100 iters), loss = 0.397627
I1005 00:37:34.232975 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:37:34.232975 17840 solver.cpp:237]     Train net output #1: loss = 0.397627 (* 1 = 0.397627 loss)
I1005 00:37:34.232975 17840 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I1005 00:37:34.232975 17840 sgd_solver.cpp:105] Iteration 15000, lr = 1e-05
I1005 00:37:37.518777 17840 solver.cpp:218] Iteration 15100 (30.5647 iter/s, 3.27175s/100 iters), loss = 0.44462
I1005 00:37:37.518777 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:37:37.518777 17840 solver.cpp:237]     Train net output #1: loss = 0.44462 (* 1 = 0.44462 loss)
I1005 00:37:37.518777 17840 sgd_solver.cpp:105] Iteration 15100, lr = 1e-05
I1005 00:37:40.777473 17840 solver.cpp:218] Iteration 15200 (30.6052 iter/s, 3.26742s/100 iters), loss = 0.483845
I1005 00:37:40.777473 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 00:37:40.777473 17840 solver.cpp:237]     Train net output #1: loss = 0.483845 (* 1 = 0.483845 loss)
I1005 00:37:40.777473 17840 sgd_solver.cpp:105] Iteration 15200, lr = 1e-05
I1005 00:37:44.038899 17840 solver.cpp:218] Iteration 15300 (30.6348 iter/s, 3.26426s/100 iters), loss = 0.388757
I1005 00:37:44.038899 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:37:44.038899 17840 solver.cpp:237]     Train net output #1: loss = 0.388757 (* 1 = 0.388757 loss)
I1005 00:37:44.038899 17840 sgd_solver.cpp:105] Iteration 15300, lr = 1e-05
I1005 00:37:47.304252 17840 solver.cpp:218] Iteration 15400 (30.6506 iter/s, 3.26258s/100 iters), loss = 0.469086
I1005 00:37:47.304252 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:37:47.304252 17840 solver.cpp:237]     Train net output #1: loss = 0.469086 (* 1 = 0.469086 loss)
I1005 00:37:47.304252 17840 sgd_solver.cpp:105] Iteration 15400, lr = 1e-05
I1005 00:37:50.411465  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:37:50.567718 17840 solver.cpp:218] Iteration 15500 (30.6687 iter/s, 3.26065s/100 iters), loss = 0.39156
I1005 00:37:50.567718 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:37:50.567718 17840 solver.cpp:237]     Train net output #1: loss = 0.39156 (* 1 = 0.39156 loss)
I1005 00:37:50.567718 17840 sgd_solver.cpp:105] Iteration 15500, lr = 1e-05
I1005 00:37:53.832137 17840 solver.cpp:218] Iteration 15600 (30.6041 iter/s, 3.26754s/100 iters), loss = 0.394302
I1005 00:37:53.832137 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:37:53.832137 17840 solver.cpp:237]     Train net output #1: loss = 0.394302 (* 1 = 0.394302 loss)
I1005 00:37:53.832137 17840 sgd_solver.cpp:105] Iteration 15600, lr = 1e-05
I1005 00:37:57.106815 17840 solver.cpp:218] Iteration 15700 (30.5817 iter/s, 3.26993s/100 iters), loss = 0.454325
I1005 00:37:57.106815 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:37:57.106815 17840 solver.cpp:237]     Train net output #1: loss = 0.454325 (* 1 = 0.454325 loss)
I1005 00:37:57.106815 17840 sgd_solver.cpp:105] Iteration 15700, lr = 1e-05
I1005 00:38:00.372138 17840 solver.cpp:218] Iteration 15800 (30.5805 iter/s, 3.27006s/100 iters), loss = 0.396795
I1005 00:38:00.372138 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:38:00.372138 17840 solver.cpp:237]     Train net output #1: loss = 0.396795 (* 1 = 0.396795 loss)
I1005 00:38:00.372138 17840 sgd_solver.cpp:105] Iteration 15800, lr = 1e-05
I1005 00:38:03.642570 17840 solver.cpp:218] Iteration 15900 (30.634 iter/s, 3.26435s/100 iters), loss = 0.427568
I1005 00:38:03.642570 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:38:03.642570 17840 solver.cpp:237]     Train net output #1: loss = 0.427568 (* 1 = 0.427568 loss)
I1005 00:38:03.642570 17840 sgd_solver.cpp:105] Iteration 15900, lr = 1e-05
I1005 00:38:06.738678  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:38:06.879312 17840 solver.cpp:330] Iteration 16000, Testing net (#0)
I1005 00:38:06.879312 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:38:07.526434 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:38:07.557683 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7924
I1005 00:38:07.557683 17840 solver.cpp:397]     Test net output #1: loss = 0.604785 (* 1 = 0.604785 loss)
I1005 00:38:07.573297 17840 solver.cpp:218] Iteration 16000 (25.3878 iter/s, 3.9389s/100 iters), loss = 0.434428
I1005 00:38:07.573297 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:38:07.573297 17840 solver.cpp:237]     Train net output #1: loss = 0.434428 (* 1 = 0.434428 loss)
I1005 00:38:07.573297 17840 sgd_solver.cpp:105] Iteration 16000, lr = 1e-05
I1005 00:38:10.847003 17840 solver.cpp:218] Iteration 16100 (30.6749 iter/s, 3.25999s/100 iters), loss = 0.423488
I1005 00:38:10.847003 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:38:10.847003 17840 solver.cpp:237]     Train net output #1: loss = 0.423488 (* 1 = 0.423488 loss)
I1005 00:38:10.847003 17840 sgd_solver.cpp:105] Iteration 16100, lr = 1e-05
I1005 00:38:14.094028 17840 solver.cpp:218] Iteration 16200 (30.7275 iter/s, 3.25441s/100 iters), loss = 0.468707
I1005 00:38:14.094028 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:38:14.094028 17840 solver.cpp:237]     Train net output #1: loss = 0.468707 (* 1 = 0.468707 loss)
I1005 00:38:14.094028 17840 sgd_solver.cpp:105] Iteration 16200, lr = 1e-05
I1005 00:38:17.342412 17840 solver.cpp:218] Iteration 16300 (30.7352 iter/s, 3.2536s/100 iters), loss = 0.383698
I1005 00:38:17.342412 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:38:17.342412 17840 solver.cpp:237]     Train net output #1: loss = 0.383698 (* 1 = 0.383698 loss)
I1005 00:38:17.342412 17840 sgd_solver.cpp:105] Iteration 16300, lr = 1e-05
I1005 00:38:20.624294 17840 solver.cpp:218] Iteration 16400 (30.6097 iter/s, 3.26694s/100 iters), loss = 0.453314
I1005 00:38:20.624294 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:38:20.624294 17840 solver.cpp:237]     Train net output #1: loss = 0.453314 (* 1 = 0.453314 loss)
I1005 00:38:20.624294 17840 sgd_solver.cpp:105] Iteration 16400, lr = 1e-05
I1005 00:38:23.788403  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:38:23.955410 17840 solver.cpp:218] Iteration 16500 (30.028 iter/s, 3.33023s/100 iters), loss = 0.442467
I1005 00:38:23.955410 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:38:23.955410 17840 solver.cpp:237]     Train net output #1: loss = 0.442467 (* 1 = 0.442467 loss)
I1005 00:38:23.955410 17840 sgd_solver.cpp:105] Iteration 16500, lr = 1e-05
I1005 00:38:27.286020 17840 solver.cpp:218] Iteration 16600 (30.0219 iter/s, 3.3309s/100 iters), loss = 0.490458
I1005 00:38:27.286020 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:38:27.287021 17840 solver.cpp:237]     Train net output #1: loss = 0.490458 (* 1 = 0.490458 loss)
I1005 00:38:27.287021 17840 sgd_solver.cpp:105] Iteration 16600, lr = 1e-05
I1005 00:38:30.582480 17840 solver.cpp:218] Iteration 16700 (30.3292 iter/s, 3.29715s/100 iters), loss = 0.451879
I1005 00:38:30.582480 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:38:30.582480 17840 solver.cpp:237]     Train net output #1: loss = 0.451879 (* 1 = 0.451879 loss)
I1005 00:38:30.582480 17840 sgd_solver.cpp:105] Iteration 16700, lr = 1e-05
I1005 00:38:33.843777 17840 solver.cpp:218] Iteration 16800 (30.6089 iter/s, 3.26703s/100 iters), loss = 0.405362
I1005 00:38:33.843777 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:38:33.843777 17840 solver.cpp:237]     Train net output #1: loss = 0.405362 (* 1 = 0.405362 loss)
I1005 00:38:33.843777 17840 sgd_solver.cpp:105] Iteration 16800, lr = 1e-05
I1005 00:38:37.147950 17840 solver.cpp:218] Iteration 16900 (30.3218 iter/s, 3.29796s/100 iters), loss = 0.437199
I1005 00:38:37.147950 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:38:37.147950 17840 solver.cpp:237]     Train net output #1: loss = 0.437199 (* 1 = 0.437199 loss)
I1005 00:38:37.147950 17840 sgd_solver.cpp:105] Iteration 16900, lr = 1e-05
I1005 00:38:40.259610  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:38:40.391659 17840 solver.cpp:330] Iteration 17000, Testing net (#0)
I1005 00:38:40.391659 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:38:41.047904 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:38:41.063519 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7929
I1005 00:38:41.063519 17840 solver.cpp:397]     Test net output #1: loss = 0.604813 (* 1 = 0.604813 loss)
I1005 00:38:41.094770 17840 solver.cpp:218] Iteration 17000 (25.2619 iter/s, 3.95853s/100 iters), loss = 0.356613
I1005 00:38:41.094770 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:38:41.094770 17840 solver.cpp:237]     Train net output #1: loss = 0.356613 (* 1 = 0.356613 loss)
I1005 00:38:41.094770 17840 sgd_solver.cpp:105] Iteration 17000, lr = 1e-05
I1005 00:38:44.414458 17840 solver.cpp:218] Iteration 17100 (30.2532 iter/s, 3.30543s/100 iters), loss = 0.388653
I1005 00:38:44.414458 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:38:44.414458 17840 solver.cpp:237]     Train net output #1: loss = 0.388653 (* 1 = 0.388653 loss)
I1005 00:38:44.414458 17840 sgd_solver.cpp:105] Iteration 17100, lr = 1e-05
I1005 00:38:47.671871 17840 solver.cpp:218] Iteration 17200 (30.5872 iter/s, 3.26934s/100 iters), loss = 0.468021
I1005 00:38:47.671871 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:38:47.671871 17840 solver.cpp:237]     Train net output #1: loss = 0.468021 (* 1 = 0.468021 loss)
I1005 00:38:47.671871 17840 sgd_solver.cpp:105] Iteration 17200, lr = 1e-05
I1005 00:38:50.959136 17840 solver.cpp:218] Iteration 17300 (30.5387 iter/s, 3.27453s/100 iters), loss = 0.396164
I1005 00:38:50.959136 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:38:50.959136 17840 solver.cpp:237]     Train net output #1: loss = 0.396164 (* 1 = 0.396164 loss)
I1005 00:38:50.959136 17840 sgd_solver.cpp:105] Iteration 17300, lr = 1e-05
I1005 00:38:54.223177 17840 solver.cpp:218] Iteration 17400 (30.5354 iter/s, 3.27489s/100 iters), loss = 0.447012
I1005 00:38:54.223177 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:38:54.223177 17840 solver.cpp:237]     Train net output #1: loss = 0.447012 (* 1 = 0.447012 loss)
I1005 00:38:54.223177 17840 sgd_solver.cpp:105] Iteration 17400, lr = 1e-05
I1005 00:38:57.340425  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:38:57.512313 17840 solver.cpp:218] Iteration 17500 (30.4889 iter/s, 3.27988s/100 iters), loss = 0.407522
I1005 00:38:57.512313 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:38:57.512313 17840 solver.cpp:237]     Train net output #1: loss = 0.407522 (* 1 = 0.407522 loss)
I1005 00:38:57.512313 17840 sgd_solver.cpp:105] Iteration 17500, lr = 1e-05
I1005 00:39:00.787827 17840 solver.cpp:218] Iteration 17600 (30.4879 iter/s, 3.27999s/100 iters), loss = 0.464458
I1005 00:39:00.787827 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:39:00.787827 17840 solver.cpp:237]     Train net output #1: loss = 0.464458 (* 1 = 0.464458 loss)
I1005 00:39:00.787827 17840 sgd_solver.cpp:105] Iteration 17600, lr = 1e-05
I1005 00:39:04.070272 17840 solver.cpp:218] Iteration 17700 (30.4579 iter/s, 3.28322s/100 iters), loss = 0.470258
I1005 00:39:04.070272 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:39:04.070272 17840 solver.cpp:237]     Train net output #1: loss = 0.470258 (* 1 = 0.470258 loss)
I1005 00:39:04.070272 17840 sgd_solver.cpp:105] Iteration 17700, lr = 1e-05
I1005 00:39:07.364588 17840 solver.cpp:218] Iteration 17800 (30.4358 iter/s, 3.2856s/100 iters), loss = 0.398814
I1005 00:39:07.364588 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:39:07.364588 17840 solver.cpp:237]     Train net output #1: loss = 0.398814 (* 1 = 0.398814 loss)
I1005 00:39:07.364588 17840 sgd_solver.cpp:105] Iteration 17800, lr = 1e-05
I1005 00:39:10.628365 17840 solver.cpp:218] Iteration 17900 (30.5232 iter/s, 3.2762s/100 iters), loss = 0.475134
I1005 00:39:10.628365 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:39:10.628365 17840 solver.cpp:237]     Train net output #1: loss = 0.475134 (* 1 = 0.475134 loss)
I1005 00:39:10.628365 17840 sgd_solver.cpp:105] Iteration 17900, lr = 1e-05
I1005 00:39:13.761212  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:39:13.886212 17840 solver.cpp:330] Iteration 18000, Testing net (#0)
I1005 00:39:13.886212 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:39:14.541896 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:39:14.573130 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7934
I1005 00:39:14.573130 17840 solver.cpp:397]     Test net output #1: loss = 0.604859 (* 1 = 0.604859 loss)
I1005 00:39:14.604399 17840 solver.cpp:218] Iteration 18000 (25.2039 iter/s, 3.96764s/100 iters), loss = 0.484667
I1005 00:39:14.604399 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:39:14.604399 17840 solver.cpp:237]     Train net output #1: loss = 0.484667 (* 1 = 0.484667 loss)
I1005 00:39:14.604399 17840 sgd_solver.cpp:105] Iteration 18000, lr = 1e-05
I1005 00:39:17.884838 17840 solver.cpp:218] Iteration 18100 (30.5276 iter/s, 3.27572s/100 iters), loss = 0.466227
I1005 00:39:17.884838 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:39:17.884838 17840 solver.cpp:237]     Train net output #1: loss = 0.466227 (* 1 = 0.466227 loss)
I1005 00:39:17.884838 17840 sgd_solver.cpp:105] Iteration 18100, lr = 1e-05
I1005 00:39:21.157364 17840 solver.cpp:218] Iteration 18200 (30.4252 iter/s, 3.28675s/100 iters), loss = 0.461617
I1005 00:39:21.157364 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:39:21.157364 17840 solver.cpp:237]     Train net output #1: loss = 0.461617 (* 1 = 0.461617 loss)
I1005 00:39:21.157364 17840 sgd_solver.cpp:105] Iteration 18200, lr = 1e-05
I1005 00:39:24.441150 17840 solver.cpp:218] Iteration 18300 (30.5839 iter/s, 3.26969s/100 iters), loss = 0.383389
I1005 00:39:24.441150 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:39:24.441150 17840 solver.cpp:237]     Train net output #1: loss = 0.383389 (* 1 = 0.383389 loss)
I1005 00:39:24.441150 17840 sgd_solver.cpp:105] Iteration 18300, lr = 1e-05
I1005 00:39:27.720857 17840 solver.cpp:218] Iteration 18400 (30.4453 iter/s, 3.28457s/100 iters), loss = 0.481901
I1005 00:39:27.720857 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:39:27.720857 17840 solver.cpp:237]     Train net output #1: loss = 0.481901 (* 1 = 0.481901 loss)
I1005 00:39:27.720857 17840 sgd_solver.cpp:105] Iteration 18400, lr = 1e-05
I1005 00:39:30.833189  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:39:31.005060 17840 solver.cpp:218] Iteration 18500 (30.4986 iter/s, 3.27884s/100 iters), loss = 0.446974
I1005 00:39:31.005060 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:39:31.005060 17840 solver.cpp:237]     Train net output #1: loss = 0.446974 (* 1 = 0.446974 loss)
I1005 00:39:31.005060 17840 sgd_solver.cpp:105] Iteration 18500, lr = 1e-05
I1005 00:39:34.268364 17840 solver.cpp:218] Iteration 18600 (30.5686 iter/s, 3.27133s/100 iters), loss = 0.379181
I1005 00:39:34.268364 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:39:34.268364 17840 solver.cpp:237]     Train net output #1: loss = 0.379181 (* 1 = 0.379181 loss)
I1005 00:39:34.268364 17840 sgd_solver.cpp:105] Iteration 18600, lr = 1e-05
I1005 00:39:37.558948 17840 solver.cpp:218] Iteration 18700 (30.4112 iter/s, 3.28827s/100 iters), loss = 0.527103
I1005 00:39:37.558948 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:39:37.558948 17840 solver.cpp:237]     Train net output #1: loss = 0.527103 (* 1 = 0.527103 loss)
I1005 00:39:37.558948 17840 sgd_solver.cpp:105] Iteration 18700, lr = 1e-05
I1005 00:39:40.846945 17840 solver.cpp:218] Iteration 18800 (30.4815 iter/s, 3.28067s/100 iters), loss = 0.430847
I1005 00:39:40.846945 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:39:40.846945 17840 solver.cpp:237]     Train net output #1: loss = 0.430847 (* 1 = 0.430847 loss)
I1005 00:39:40.846945 17840 sgd_solver.cpp:105] Iteration 18800, lr = 1e-05
I1005 00:39:44.190264 17840 solver.cpp:218] Iteration 18900 (29.8772 iter/s, 3.34703s/100 iters), loss = 0.43434
I1005 00:39:44.190264 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:39:44.190264 17840 solver.cpp:237]     Train net output #1: loss = 0.43434 (* 1 = 0.43434 loss)
I1005 00:39:44.190264 17840 sgd_solver.cpp:105] Iteration 18900, lr = 1e-05
I1005 00:39:47.320824  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:39:47.445293 17840 solver.cpp:330] Iteration 19000, Testing net (#0)
I1005 00:39:47.445293 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:39:48.101546 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:39:48.117156 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7935
I1005 00:39:48.117156 17840 solver.cpp:397]     Test net output #1: loss = 0.604833 (* 1 = 0.604833 loss)
I1005 00:39:48.148422 17840 solver.cpp:218] Iteration 19000 (25.2225 iter/s, 3.96471s/100 iters), loss = 0.47508
I1005 00:39:48.148422 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:39:48.148422 17840 solver.cpp:237]     Train net output #1: loss = 0.47508 (* 1 = 0.47508 loss)
I1005 00:39:48.148422 17840 sgd_solver.cpp:105] Iteration 19000, lr = 1e-05
I1005 00:39:51.423183 17840 solver.cpp:218] Iteration 19100 (30.5702 iter/s, 3.27116s/100 iters), loss = 0.397939
I1005 00:39:51.423183 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:39:51.423183 17840 solver.cpp:237]     Train net output #1: loss = 0.397939 (* 1 = 0.397939 loss)
I1005 00:39:51.423183 17840 sgd_solver.cpp:105] Iteration 19100, lr = 1e-05
I1005 00:39:54.723227 17840 solver.cpp:218] Iteration 19200 (30.373 iter/s, 3.2924s/100 iters), loss = 0.498731
I1005 00:39:54.723227 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:39:54.723227 17840 solver.cpp:237]     Train net output #1: loss = 0.498731 (* 1 = 0.498731 loss)
I1005 00:39:54.723227 17840 sgd_solver.cpp:105] Iteration 19200, lr = 1e-05
I1005 00:39:57.998101 17840 solver.cpp:218] Iteration 19300 (30.4915 iter/s, 3.2796s/100 iters), loss = 0.385224
I1005 00:39:57.998101 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:39:57.998101 17840 solver.cpp:237]     Train net output #1: loss = 0.385224 (* 1 = 0.385224 loss)
I1005 00:39:57.998101 17840 sgd_solver.cpp:105] Iteration 19300, lr = 1e-05
I1005 00:40:01.369185 17840 solver.cpp:218] Iteration 19400 (29.7207 iter/s, 3.36466s/100 iters), loss = 0.440604
I1005 00:40:01.369185 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:40:01.369185 17840 solver.cpp:237]     Train net output #1: loss = 0.440604 (* 1 = 0.440604 loss)
I1005 00:40:01.369185 17840 sgd_solver.cpp:105] Iteration 19400, lr = 1e-05
I1005 00:40:04.484042  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:40:04.640291 17840 solver.cpp:218] Iteration 19500 (30.5097 iter/s, 3.27765s/100 iters), loss = 0.443346
I1005 00:40:04.640291 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:40:04.640291 17840 solver.cpp:237]     Train net output #1: loss = 0.443346 (* 1 = 0.443346 loss)
I1005 00:40:04.640291 17840 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I1005 00:40:07.925252 17840 solver.cpp:218] Iteration 19600 (30.507 iter/s, 3.27794s/100 iters), loss = 0.399544
I1005 00:40:07.925252 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:40:07.926254 17840 solver.cpp:237]     Train net output #1: loss = 0.399544 (* 1 = 0.399544 loss)
I1005 00:40:07.926254 17840 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I1005 00:40:11.213310 17840 solver.cpp:218] Iteration 19700 (30.312 iter/s, 3.29902s/100 iters), loss = 0.474535
I1005 00:40:11.213310 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:40:11.213310 17840 solver.cpp:237]     Train net output #1: loss = 0.474535 (* 1 = 0.474535 loss)
I1005 00:40:11.213310 17840 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I1005 00:40:14.558843 17840 solver.cpp:218] Iteration 19800 (29.8999 iter/s, 3.34449s/100 iters), loss = 0.402413
I1005 00:40:14.558843 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:40:14.558843 17840 solver.cpp:237]     Train net output #1: loss = 0.402413 (* 1 = 0.402413 loss)
I1005 00:40:14.558843 17840 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I1005 00:40:17.866863 17840 solver.cpp:218] Iteration 19900 (30.3332 iter/s, 3.29671s/100 iters), loss = 0.490097
I1005 00:40:17.866863 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:40:17.866863 17840 solver.cpp:237]     Train net output #1: loss = 0.490097 (* 1 = 0.490097 loss)
I1005 00:40:17.866863 17840 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I1005 00:40:21.021281  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:40:21.146303 17840 solver.cpp:330] Iteration 20000, Testing net (#0)
I1005 00:40:21.146303 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:40:21.797905 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:40:21.829155 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7934
I1005 00:40:21.829155 17840 solver.cpp:397]     Test net output #1: loss = 0.604778 (* 1 = 0.604778 loss)
I1005 00:40:21.860409 17840 solver.cpp:218] Iteration 20000 (25.0049 iter/s, 3.99921s/100 iters), loss = 0.425015
I1005 00:40:21.860409 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:40:21.860409 17840 solver.cpp:237]     Train net output #1: loss = 0.425015 (* 1 = 0.425015 loss)
I1005 00:40:21.860409 17840 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I1005 00:40:25.135852 17840 solver.cpp:218] Iteration 20100 (30.4917 iter/s, 3.27958s/100 iters), loss = 0.401124
I1005 00:40:25.135852 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:40:25.135852 17840 solver.cpp:237]     Train net output #1: loss = 0.401124 (* 1 = 0.401124 loss)
I1005 00:40:25.135852 17840 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I1005 00:40:28.412273 17840 solver.cpp:218] Iteration 20200 (30.5528 iter/s, 3.27302s/100 iters), loss = 0.429322
I1005 00:40:28.412273 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:40:28.412273 17840 solver.cpp:237]     Train net output #1: loss = 0.429322 (* 1 = 0.429322 loss)
I1005 00:40:28.412273 17840 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I1005 00:40:31.689697 17840 solver.cpp:218] Iteration 20300 (30.5508 iter/s, 3.27323s/100 iters), loss = 0.376362
I1005 00:40:31.689697 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:40:31.689697 17840 solver.cpp:237]     Train net output #1: loss = 0.376362 (* 1 = 0.376362 loss)
I1005 00:40:31.689697 17840 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I1005 00:40:34.957409 17840 solver.cpp:218] Iteration 20400 (30.527 iter/s, 3.27579s/100 iters), loss = 0.413948
I1005 00:40:34.957409 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:40:34.957409 17840 solver.cpp:237]     Train net output #1: loss = 0.413948 (* 1 = 0.413948 loss)
I1005 00:40:34.957409 17840 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I1005 00:40:38.099889  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:40:38.267386 17840 solver.cpp:218] Iteration 20500 (30.3263 iter/s, 3.29747s/100 iters), loss = 0.389672
I1005 00:40:38.267386 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:40:38.267386 17840 solver.cpp:237]     Train net output #1: loss = 0.389672 (* 1 = 0.389672 loss)
I1005 00:40:38.267386 17840 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I1005 00:40:41.571462 17840 solver.cpp:218] Iteration 20600 (30.2217 iter/s, 3.30888s/100 iters), loss = 0.406509
I1005 00:40:41.571462 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:40:41.571462 17840 solver.cpp:237]     Train net output #1: loss = 0.406509 (* 1 = 0.406509 loss)
I1005 00:40:41.571462 17840 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I1005 00:40:44.842645 17840 solver.cpp:218] Iteration 20700 (30.516 iter/s, 3.27697s/100 iters), loss = 0.484907
I1005 00:40:44.842645 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:40:44.842645 17840 solver.cpp:237]     Train net output #1: loss = 0.484907 (* 1 = 0.484907 loss)
I1005 00:40:44.842645 17840 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I1005 00:40:48.144379 17840 solver.cpp:218] Iteration 20800 (30.2982 iter/s, 3.30053s/100 iters), loss = 0.420875
I1005 00:40:48.144379 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:40:48.144379 17840 solver.cpp:237]     Train net output #1: loss = 0.420875 (* 1 = 0.420875 loss)
I1005 00:40:48.144379 17840 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I1005 00:40:51.421849 17840 solver.cpp:218] Iteration 20900 (30.5397 iter/s, 3.27442s/100 iters), loss = 0.44036
I1005 00:40:51.421849 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:40:51.421849 17840 solver.cpp:237]     Train net output #1: loss = 0.44036 (* 1 = 0.44036 loss)
I1005 00:40:51.421849 17840 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I1005 00:40:54.546311  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:40:54.671319 17840 solver.cpp:330] Iteration 21000, Testing net (#0)
I1005 00:40:54.671319 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:40:55.325536 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:40:55.356786 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7937
I1005 00:40:55.356786 17840 solver.cpp:397]     Test net output #1: loss = 0.604778 (* 1 = 0.604778 loss)
I1005 00:40:55.372411 17840 solver.cpp:218] Iteration 21000 (25.2693 iter/s, 3.95737s/100 iters), loss = 0.379245
I1005 00:40:55.388051 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:40:55.388051 17840 solver.cpp:237]     Train net output #1: loss = 0.379245 (* 1 = 0.379245 loss)
I1005 00:40:55.388051 17840 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I1005 00:40:58.662699 17840 solver.cpp:218] Iteration 21100 (30.4722 iter/s, 3.28168s/100 iters), loss = 0.45483
I1005 00:40:58.662699 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:40:58.662699 17840 solver.cpp:237]     Train net output #1: loss = 0.45483 (* 1 = 0.45483 loss)
I1005 00:40:58.662699 17840 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I1005 00:41:01.932494 17840 solver.cpp:218] Iteration 21200 (30.5677 iter/s, 3.27142s/100 iters), loss = 0.516324
I1005 00:41:01.932494 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 00:41:01.932494 17840 solver.cpp:237]     Train net output #1: loss = 0.516324 (* 1 = 0.516324 loss)
I1005 00:41:01.932494 17840 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I1005 00:41:05.219745 17840 solver.cpp:218] Iteration 21300 (30.5104 iter/s, 3.27757s/100 iters), loss = 0.386478
I1005 00:41:05.219745 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:41:05.219745 17840 solver.cpp:237]     Train net output #1: loss = 0.386478 (* 1 = 0.386478 loss)
I1005 00:41:05.219745 17840 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I1005 00:41:08.521670 17840 solver.cpp:218] Iteration 21400 (30.2849 iter/s, 3.30198s/100 iters), loss = 0.413627
I1005 00:41:08.521670 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:41:08.521670 17840 solver.cpp:237]     Train net output #1: loss = 0.413627 (* 1 = 0.413627 loss)
I1005 00:41:08.521670 17840 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I1005 00:41:11.634325  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:41:11.792943 17840 solver.cpp:218] Iteration 21500 (30.5229 iter/s, 3.27622s/100 iters), loss = 0.374857
I1005 00:41:11.792943 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:41:11.792943 17840 solver.cpp:237]     Train net output #1: loss = 0.374857 (* 1 = 0.374857 loss)
I1005 00:41:11.792943 17840 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I1005 00:41:15.069052 17840 solver.cpp:218] Iteration 21600 (30.5471 iter/s, 3.27363s/100 iters), loss = 0.40634
I1005 00:41:15.069052 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:41:15.069052 17840 solver.cpp:237]     Train net output #1: loss = 0.40634 (* 1 = 0.40634 loss)
I1005 00:41:15.069052 17840 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I1005 00:41:18.343044 17840 solver.cpp:218] Iteration 21700 (30.5781 iter/s, 3.27031s/100 iters), loss = 0.498907
I1005 00:41:18.343044 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:41:18.343044 17840 solver.cpp:237]     Train net output #1: loss = 0.498907 (* 1 = 0.498907 loss)
I1005 00:41:18.343044 17840 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I1005 00:41:21.681248 17840 solver.cpp:218] Iteration 21800 (29.9598 iter/s, 3.3378s/100 iters), loss = 0.388457
I1005 00:41:21.681248 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:41:21.681248 17840 solver.cpp:237]     Train net output #1: loss = 0.388457 (* 1 = 0.388457 loss)
I1005 00:41:21.681248 17840 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I1005 00:41:25.014312 17840 solver.cpp:218] Iteration 21900 (30.0024 iter/s, 3.33307s/100 iters), loss = 0.44883
I1005 00:41:25.014312 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:41:25.014312 17840 solver.cpp:237]     Train net output #1: loss = 0.44883 (* 1 = 0.44883 loss)
I1005 00:41:25.014312 17840 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I1005 00:41:28.167404  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:41:28.311413 17840 solver.cpp:330] Iteration 22000, Testing net (#0)
I1005 00:41:28.311413 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:41:29.001067 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:41:29.032310 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7932
I1005 00:41:29.032310 17840 solver.cpp:397]     Test net output #1: loss = 0.604826 (* 1 = 0.604826 loss)
I1005 00:41:29.063573 17840 solver.cpp:218] Iteration 22000 (24.6743 iter/s, 4.05281s/100 iters), loss = 0.438358
I1005 00:41:29.063573 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:41:29.063573 17840 solver.cpp:237]     Train net output #1: loss = 0.438358 (* 1 = 0.438358 loss)
I1005 00:41:29.063573 17840 sgd_solver.cpp:105] Iteration 22000, lr = 1e-05
I1005 00:41:32.358031 17840 solver.cpp:218] Iteration 22100 (30.2971 iter/s, 3.30065s/100 iters), loss = 0.408295
I1005 00:41:32.358031 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:41:32.358031 17840 solver.cpp:237]     Train net output #1: loss = 0.408295 (* 1 = 0.408295 loss)
I1005 00:41:32.358031 17840 sgd_solver.cpp:105] Iteration 22100, lr = 1e-05
I1005 00:41:35.691198 17840 solver.cpp:218] Iteration 22200 (30.058 iter/s, 3.3269s/100 iters), loss = 0.496069
I1005 00:41:35.691198 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:41:35.691198 17840 solver.cpp:237]     Train net output #1: loss = 0.496069 (* 1 = 0.496069 loss)
I1005 00:41:35.691198 17840 sgd_solver.cpp:105] Iteration 22200, lr = 1e-05
I1005 00:41:38.977586 17840 solver.cpp:218] Iteration 22300 (30.4641 iter/s, 3.28255s/100 iters), loss = 0.387358
I1005 00:41:38.977586 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1005 00:41:38.977586 17840 solver.cpp:237]     Train net output #1: loss = 0.387358 (* 1 = 0.387358 loss)
I1005 00:41:38.977586 17840 sgd_solver.cpp:105] Iteration 22300, lr = 1e-05
I1005 00:41:42.249791 17840 solver.cpp:218] Iteration 22400 (30.5479 iter/s, 3.27355s/100 iters), loss = 0.456719
I1005 00:41:42.249791 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:41:42.249791 17840 solver.cpp:237]     Train net output #1: loss = 0.456719 (* 1 = 0.456719 loss)
I1005 00:41:42.249791 17840 sgd_solver.cpp:105] Iteration 22400, lr = 1e-05
I1005 00:41:45.358693  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:41:45.523236 17840 solver.cpp:218] Iteration 22500 (30.5137 iter/s, 3.27722s/100 iters), loss = 0.452836
I1005 00:41:45.523236 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:41:45.523236 17840 solver.cpp:237]     Train net output #1: loss = 0.452836 (* 1 = 0.452836 loss)
I1005 00:41:45.523236 17840 sgd_solver.cpp:105] Iteration 22500, lr = 1e-05
I1005 00:41:48.787446 17840 solver.cpp:218] Iteration 22600 (30.6363 iter/s, 3.2641s/100 iters), loss = 0.43999
I1005 00:41:48.787446 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:41:48.787446 17840 solver.cpp:237]     Train net output #1: loss = 0.43999 (* 1 = 0.43999 loss)
I1005 00:41:48.787446 17840 sgd_solver.cpp:105] Iteration 22600, lr = 1e-05
I1005 00:41:52.056960 17840 solver.cpp:218] Iteration 22700 (30.5671 iter/s, 3.27149s/100 iters), loss = 0.500814
I1005 00:41:52.056960 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 00:41:52.056960 17840 solver.cpp:237]     Train net output #1: loss = 0.500814 (* 1 = 0.500814 loss)
I1005 00:41:52.056960 17840 sgd_solver.cpp:105] Iteration 22700, lr = 1e-05
I1005 00:41:55.332361 17840 solver.cpp:218] Iteration 22800 (30.5369 iter/s, 3.27472s/100 iters), loss = 0.34489
I1005 00:41:55.332361 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:41:55.332361 17840 solver.cpp:237]     Train net output #1: loss = 0.34489 (* 1 = 0.34489 loss)
I1005 00:41:55.332361 17840 sgd_solver.cpp:105] Iteration 22800, lr = 1e-05
I1005 00:41:58.606006 17840 solver.cpp:218] Iteration 22900 (30.5808 iter/s, 3.27002s/100 iters), loss = 0.460654
I1005 00:41:58.606006 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:41:58.606006 17840 solver.cpp:237]     Train net output #1: loss = 0.460654 (* 1 = 0.460654 loss)
I1005 00:41:58.606006 17840 sgd_solver.cpp:105] Iteration 22900, lr = 1e-05
I1005 00:42:01.719163  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:42:01.844177 17840 solver.cpp:330] Iteration 23000, Testing net (#0)
I1005 00:42:01.844177 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:42:02.499251 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:42:02.514873 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7938
I1005 00:42:02.514873 17840 solver.cpp:397]     Test net output #1: loss = 0.604834 (* 1 = 0.604834 loss)
I1005 00:42:02.546116 17840 solver.cpp:218] Iteration 23000 (25.3312 iter/s, 3.9477s/100 iters), loss = 0.399273
I1005 00:42:02.546116 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:42:02.546116 17840 solver.cpp:237]     Train net output #1: loss = 0.399273 (* 1 = 0.399273 loss)
I1005 00:42:02.546116 17840 sgd_solver.cpp:105] Iteration 23000, lr = 1e-05
I1005 00:42:05.825134 17840 solver.cpp:218] Iteration 23100 (30.5705 iter/s, 3.27113s/100 iters), loss = 0.45607
I1005 00:42:05.825134 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:42:05.825134 17840 solver.cpp:237]     Train net output #1: loss = 0.45607 (* 1 = 0.45607 loss)
I1005 00:42:05.825134 17840 sgd_solver.cpp:105] Iteration 23100, lr = 1e-05
I1005 00:42:09.102325 17840 solver.cpp:218] Iteration 23200 (30.5666 iter/s, 3.27155s/100 iters), loss = 0.463833
I1005 00:42:09.102325 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:42:09.102325 17840 solver.cpp:237]     Train net output #1: loss = 0.463833 (* 1 = 0.463833 loss)
I1005 00:42:09.102325 17840 sgd_solver.cpp:105] Iteration 23200, lr = 1e-05
I1005 00:42:12.365350 17840 solver.cpp:218] Iteration 23300 (30.5768 iter/s, 3.27046s/100 iters), loss = 0.389527
I1005 00:42:12.365350 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:42:12.365350 17840 solver.cpp:237]     Train net output #1: loss = 0.389527 (* 1 = 0.389527 loss)
I1005 00:42:12.365350 17840 sgd_solver.cpp:105] Iteration 23300, lr = 1e-05
I1005 00:42:15.628275 17840 solver.cpp:218] Iteration 23400 (30.6038 iter/s, 3.26757s/100 iters), loss = 0.508172
I1005 00:42:15.628275 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:42:15.628275 17840 solver.cpp:237]     Train net output #1: loss = 0.508172 (* 1 = 0.508172 loss)
I1005 00:42:15.628275 17840 sgd_solver.cpp:105] Iteration 23400, lr = 1e-05
I1005 00:42:18.736284  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:42:18.908179 17840 solver.cpp:218] Iteration 23500 (30.615 iter/s, 3.26637s/100 iters), loss = 0.462354
I1005 00:42:18.908179 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:42:18.908179 17840 solver.cpp:237]     Train net output #1: loss = 0.462354 (* 1 = 0.462354 loss)
I1005 00:42:18.908179 17840 sgd_solver.cpp:105] Iteration 23500, lr = 1e-05
I1005 00:42:22.168793 17840 solver.cpp:218] Iteration 23600 (30.6142 iter/s, 3.26645s/100 iters), loss = 0.445913
I1005 00:42:22.168793 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:42:22.168793 17840 solver.cpp:237]     Train net output #1: loss = 0.445913 (* 1 = 0.445913 loss)
I1005 00:42:22.168793 17840 sgd_solver.cpp:105] Iteration 23600, lr = 1e-05
I1005 00:42:25.446902 17840 solver.cpp:218] Iteration 23700 (30.5704 iter/s, 3.27113s/100 iters), loss = 0.522374
I1005 00:42:25.446902 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:42:25.446902 17840 solver.cpp:237]     Train net output #1: loss = 0.522374 (* 1 = 0.522374 loss)
I1005 00:42:25.446902 17840 sgd_solver.cpp:105] Iteration 23700, lr = 1e-05
I1005 00:42:28.714503 17840 solver.cpp:218] Iteration 23800 (30.569 iter/s, 3.27129s/100 iters), loss = 0.357494
I1005 00:42:28.714503 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:42:28.714503 17840 solver.cpp:237]     Train net output #1: loss = 0.357494 (* 1 = 0.357494 loss)
I1005 00:42:28.714503 17840 sgd_solver.cpp:105] Iteration 23800, lr = 1e-05
I1005 00:42:31.992799 17840 solver.cpp:218] Iteration 23900 (30.5437 iter/s, 3.274s/100 iters), loss = 0.421802
I1005 00:42:31.993798 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:42:31.993798 17840 solver.cpp:237]     Train net output #1: loss = 0.421802 (* 1 = 0.421802 loss)
I1005 00:42:31.993798 17840 sgd_solver.cpp:105] Iteration 23900, lr = 1e-05
I1005 00:42:35.091459  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:42:35.232076 17840 solver.cpp:330] Iteration 24000, Testing net (#0)
I1005 00:42:35.232076 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:42:35.885736 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:42:35.901351 17840 solver.cpp:397]     Test net output #0: accuracy = 0.7936
I1005 00:42:35.901351 17840 solver.cpp:397]     Test net output #1: loss = 0.604595 (* 1 = 0.604595 loss)
I1005 00:42:35.932600 17840 solver.cpp:218] Iteration 24000 (25.3185 iter/s, 3.94969s/100 iters), loss = 0.387223
I1005 00:42:35.932600 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:42:35.932600 17840 solver.cpp:237]     Train net output #1: loss = 0.387223 (* 1 = 0.387223 loss)
I1005 00:42:35.932600 17840 sgd_solver.cpp:105] Iteration 24000, lr = 1e-05
I1005 00:42:39.215930 17840 solver.cpp:218] Iteration 24100 (30.5047 iter/s, 3.27818s/100 iters), loss = 0.441072
I1005 00:42:39.215930 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:42:39.215930 17840 solver.cpp:237]     Train net output #1: loss = 0.441072 (* 1 = 0.441072 loss)
I1005 00:42:39.215930 17840 sgd_solver.cpp:105] Iteration 24100, lr = 1e-05
I1005 00:42:42.503041 17840 solver.cpp:218] Iteration 24200 (30.3494 iter/s, 3.29496s/100 iters), loss = 0.497171
I1005 00:42:42.503041 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:42:42.503041 17840 solver.cpp:237]     Train net output #1: loss = 0.497171 (* 1 = 0.497171 loss)
I1005 00:42:42.503041 17840 sgd_solver.cpp:105] Iteration 24200, lr = 1e-05
I1005 00:42:45.791628 17840 solver.cpp:218] Iteration 24300 (30.4328 iter/s, 3.28593s/100 iters), loss = 0.36367
I1005 00:42:45.791628 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1005 00:42:45.791628 17840 solver.cpp:237]     Train net output #1: loss = 0.36367 (* 1 = 0.36367 loss)
I1005 00:42:45.791628 17840 sgd_solver.cpp:105] Iteration 24300, lr = 1e-05
I1005 00:42:49.072763 17840 solver.cpp:218] Iteration 24400 (30.5057 iter/s, 3.27807s/100 iters), loss = 0.48385
I1005 00:42:49.072763 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:42:49.072763 17840 solver.cpp:237]     Train net output #1: loss = 0.48385 (* 1 = 0.48385 loss)
I1005 00:42:49.072763 17840 sgd_solver.cpp:105] Iteration 24400, lr = 1e-05
I1005 00:42:52.184355  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:42:52.339263 17840 solver.cpp:218] Iteration 24500 (30.5626 iter/s, 3.27197s/100 iters), loss = 0.464461
I1005 00:42:52.339263 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:42:52.339263 17840 solver.cpp:237]     Train net output #1: loss = 0.464461 (* 1 = 0.464461 loss)
I1005 00:42:52.339263 17840 sgd_solver.cpp:105] Iteration 24500, lr = 1e-05
I1005 00:42:55.624022 17840 solver.cpp:218] Iteration 24600 (30.5105 iter/s, 3.27756s/100 iters), loss = 0.45505
I1005 00:42:55.624022 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:42:55.624022 17840 solver.cpp:237]     Train net output #1: loss = 0.45505 (* 1 = 0.45505 loss)
I1005 00:42:55.624022 17840 sgd_solver.cpp:105] Iteration 24600, lr = 1e-05
I1005 00:42:58.911160 17840 solver.cpp:218] Iteration 24700 (30.4898 iter/s, 3.27979s/100 iters), loss = 0.483131
I1005 00:42:58.911160 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:42:58.911160 17840 solver.cpp:237]     Train net output #1: loss = 0.483131 (* 1 = 0.483131 loss)
I1005 00:42:58.911160 17840 sgd_solver.cpp:105] Iteration 24700, lr = 1e-05
I1005 00:43:02.188668 17840 solver.cpp:218] Iteration 24800 (30.4357 iter/s, 3.28562s/100 iters), loss = 0.390079
I1005 00:43:02.188668 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:43:02.188668 17840 solver.cpp:237]     Train net output #1: loss = 0.390079 (* 1 = 0.390079 loss)
I1005 00:43:02.188668 17840 sgd_solver.cpp:105] Iteration 24800, lr = 1e-05
I1005 00:43:05.572221 17840 solver.cpp:218] Iteration 24900 (29.6326 iter/s, 3.37467s/100 iters), loss = 0.430242
I1005 00:43:05.572221 17840 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:43:05.572221 17840 solver.cpp:237]     Train net output #1: loss = 0.430242 (* 1 = 0.430242 loss)
I1005 00:43:05.572221 17840 sgd_solver.cpp:105] Iteration 24900, lr = 1e-05
I1005 00:43:08.725033  2364 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:43:08.865664 17840 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/slimnet_simpnet_p7_iter_25000.caffemodel
I1005 00:43:08.865664 17840 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_simpnet_p7_iter_25000.solverstate
I1005 00:43:08.912523 17840 solver.cpp:310] Iteration 25000, loss = 0.360266
I1005 00:43:08.912523 17840 solver.cpp:330] Iteration 25000, Testing net (#0)
I1005 00:43:08.912523 17840 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:43:09.566757 17432 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:43:09.597995 17840 solver.cpp:397]     Test net output #0: accuracy = 0.793
I1005 00:43:09.597995 17840 solver.cpp:397]     Test net output #1: loss = 0.604499 (* 1 = 0.604499 loss)
I1005 00:43:09.597995 17840 solver.cpp:315] Optimization Done.
I1005 00:43:09.597995 17840 caffe.cpp:260] Optimization Done.

G:\Caffe>pause
Press any key to continue . . . 
