
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I1005 00:43:45.882119 17516 caffe.cpp:219] Using GPUs 0
I1005 00:43:46.053997 17516 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1005 00:43:46.357662 17516 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 00:43:46.373286 17516 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 25000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 25000
snapshot_prefix: "examples/cifar10/slimnet_simpnet_p7"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 25000
type: "Nesterov"
I1005 00:43:46.373286 17516 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 00:43:46.373286 17516 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 00:43:46.373286 17516 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1005 00:43:46.373286 17516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1005 00:43:46.373286 17516 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P7"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1005 00:43:46.435797 17516 layer_factory.cpp:58] Creating layer cifar
I1005 00:43:46.451419 17516 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I1005 00:43:46.451419 17516 net.cpp:84] Creating Layer cifar
I1005 00:43:46.451419 17516 net.cpp:380] cifar -> data
I1005 00:43:46.451419 17516 net.cpp:380] cifar -> label
I1005 00:43:46.451419 17516 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1005 00:43:46.451419 17516 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 00:43:46.451419 17516 data_layer.cpp:45] output data size: 100,3,32,32
I1005 00:43:46.451419 17516 net.cpp:122] Setting up cifar
I1005 00:43:46.451419 17516 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1005 00:43:46.451419 17516 net.cpp:129] Top shape: 100 (100)
I1005 00:43:46.451419 17516 net.cpp:137] Memory required for data: 1229200
I1005 00:43:46.451419 17516 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1005 00:43:46.451419 17516 net.cpp:84] Creating Layer label_cifar_1_split
I1005 00:43:46.451419 17516 net.cpp:406] label_cifar_1_split <- label
I1005 00:43:46.451419 17516 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1005 00:43:46.451419 17516 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1005 00:43:46.451419 17516 net.cpp:122] Setting up label_cifar_1_split
I1005 00:43:46.451419 17516 net.cpp:129] Top shape: 100 (100)
I1005 00:43:46.451419 17516 net.cpp:129] Top shape: 100 (100)
I1005 00:43:46.451419 17516 net.cpp:137] Memory required for data: 1230000
I1005 00:43:46.451419 17516 layer_factory.cpp:58] Creating layer conv1
I1005 00:43:46.451419 17516 net.cpp:84] Creating Layer conv1
I1005 00:43:46.451419 17516 net.cpp:406] conv1 <- data
I1005 00:43:46.451419 17516 net.cpp:380] conv1 -> conv1
I1005 00:43:46.451419  4780 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 00:43:46.692622 17516 net.cpp:122] Setting up conv1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 3687600
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer bn1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer bn1
I1005 00:43:46.692622 17516 net.cpp:406] bn1 <- conv1
I1005 00:43:46.692622 17516 net.cpp:367] bn1 -> conv1 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up bn1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 6145200
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer scale1
I1005 00:43:46.692622 17516 net.cpp:406] scale1 <- conv1
I1005 00:43:46.692622 17516 net.cpp:367] scale1 -> conv1 (in-place)
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale1
I1005 00:43:46.692622 17516 net.cpp:122] Setting up scale1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 8602800
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer relu1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer relu1
I1005 00:43:46.692622 17516 net.cpp:406] relu1 <- conv1
I1005 00:43:46.692622 17516 net.cpp:367] relu1 -> conv1 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up relu1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 11060400
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer conv1_0
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer conv1_0
I1005 00:43:46.692622 17516 net.cpp:406] conv1_0 <- conv1
I1005 00:43:46.692622 17516 net.cpp:380] conv1_0 -> conv1_0
I1005 00:43:46.692622 17516 net.cpp:122] Setting up conv1_0
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 15975600
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer bn1_0
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer bn1_0
I1005 00:43:46.692622 17516 net.cpp:406] bn1_0 <- conv1_0
I1005 00:43:46.692622 17516 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up bn1_0
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 20890800
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale1_0
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer scale1_0
I1005 00:43:46.692622 17516 net.cpp:406] scale1_0 <- conv1_0
I1005 00:43:46.692622 17516 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale1_0
I1005 00:43:46.692622 17516 net.cpp:122] Setting up scale1_0
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 25806000
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer relu1_0
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer relu1_0
I1005 00:43:46.692622 17516 net.cpp:406] relu1_0 <- conv1_0
I1005 00:43:46.692622 17516 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up relu1_0
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 30721200
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer conv2
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer conv2
I1005 00:43:46.692622 17516 net.cpp:406] conv2 <- conv1_0
I1005 00:43:46.692622 17516 net.cpp:380] conv2 -> conv2
I1005 00:43:46.692622 17516 net.cpp:122] Setting up conv2
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 35636400
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer bn2
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer bn2
I1005 00:43:46.692622 17516 net.cpp:406] bn2 <- conv2
I1005 00:43:46.692622 17516 net.cpp:367] bn2 -> conv2 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up bn2
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 40551600
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale2
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer scale2
I1005 00:43:46.692622 17516 net.cpp:406] scale2 <- conv2
I1005 00:43:46.692622 17516 net.cpp:367] scale2 -> conv2 (in-place)
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale2
I1005 00:43:46.692622 17516 net.cpp:122] Setting up scale2
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 45466800
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer relu2
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer relu2
I1005 00:43:46.692622 17516 net.cpp:406] relu2 <- conv2
I1005 00:43:46.692622 17516 net.cpp:367] relu2 -> conv2 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up relu2
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 50382000
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer conv2_1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer conv2_1
I1005 00:43:46.692622 17516 net.cpp:406] conv2_1 <- conv2
I1005 00:43:46.692622 17516 net.cpp:380] conv2_1 -> conv2_1
I1005 00:43:46.692622 17516 net.cpp:122] Setting up conv2_1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 55297200
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer bn2_1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer bn2_1
I1005 00:43:46.692622 17516 net.cpp:406] bn2_1 <- conv2_1
I1005 00:43:46.692622 17516 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up bn2_1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 60212400
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale2_1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer scale2_1
I1005 00:43:46.692622 17516 net.cpp:406] scale2_1 <- conv2_1
I1005 00:43:46.692622 17516 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale2_1
I1005 00:43:46.692622 17516 net.cpp:122] Setting up scale2_1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 65127600
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer relu2_1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer relu2_1
I1005 00:43:46.692622 17516 net.cpp:406] relu2_1 <- conv2_1
I1005 00:43:46.692622 17516 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up relu2_1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 70042800
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer conv2_2
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer conv2_2
I1005 00:43:46.692622 17516 net.cpp:406] conv2_2 <- conv2_1
I1005 00:43:46.692622 17516 net.cpp:380] conv2_2 -> conv2_2
I1005 00:43:46.692622 17516 net.cpp:122] Setting up conv2_2
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 77825200
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer bn2_2
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer bn2_2
I1005 00:43:46.692622 17516 net.cpp:406] bn2_2 <- conv2_2
I1005 00:43:46.692622 17516 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up bn2_2
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 85607600
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale2_2
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer scale2_2
I1005 00:43:46.692622 17516 net.cpp:406] scale2_2 <- conv2_2
I1005 00:43:46.692622 17516 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale2_2
I1005 00:43:46.692622 17516 net.cpp:122] Setting up scale2_2
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 93390000
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer relu2_2
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer relu2_2
I1005 00:43:46.692622 17516 net.cpp:406] relu2_2 <- conv2_2
I1005 00:43:46.692622 17516 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up relu2_2
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 101172400
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer conv3
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer conv3
I1005 00:43:46.692622 17516 net.cpp:406] conv3 <- conv2_2
I1005 00:43:46.692622 17516 net.cpp:380] conv3 -> conv3
I1005 00:43:46.692622 17516 net.cpp:122] Setting up conv3
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 108954800
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer bn3
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer bn3
I1005 00:43:46.692622 17516 net.cpp:406] bn3 <- conv3
I1005 00:43:46.692622 17516 net.cpp:367] bn3 -> conv3 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up bn3
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 116737200
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale3
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer scale3
I1005 00:43:46.692622 17516 net.cpp:406] scale3 <- conv3
I1005 00:43:46.692622 17516 net.cpp:367] scale3 -> conv3 (in-place)
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale3
I1005 00:43:46.692622 17516 net.cpp:122] Setting up scale3
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 124519600
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer relu3
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer relu3
I1005 00:43:46.692622 17516 net.cpp:406] relu3 <- conv3
I1005 00:43:46.692622 17516 net.cpp:367] relu3 -> conv3 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up relu3
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 132302000
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer conv3_1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer conv3_1
I1005 00:43:46.692622 17516 net.cpp:406] conv3_1 <- conv3
I1005 00:43:46.692622 17516 net.cpp:380] conv3_1 -> conv3_1
I1005 00:43:46.692622 17516 net.cpp:122] Setting up conv3_1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 140084400
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer bn3_1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer bn3_1
I1005 00:43:46.692622 17516 net.cpp:406] bn3_1 <- conv3_1
I1005 00:43:46.692622 17516 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up bn3_1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 147866800
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale3_1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer scale3_1
I1005 00:43:46.692622 17516 net.cpp:406] scale3_1 <- conv3_1
I1005 00:43:46.692622 17516 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer scale3_1
I1005 00:43:46.692622 17516 net.cpp:122] Setting up scale3_1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 155649200
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer relu3_1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer relu3_1
I1005 00:43:46.692622 17516 net.cpp:406] relu3_1 <- conv3_1
I1005 00:43:46.692622 17516 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1005 00:43:46.692622 17516 net.cpp:122] Setting up relu3_1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 163431600
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer pool2_1
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer pool2_1
I1005 00:43:46.692622 17516 net.cpp:406] pool2_1 <- conv3_1
I1005 00:43:46.692622 17516 net.cpp:380] pool2_1 -> pool2_1
I1005 00:43:46.692622 17516 net.cpp:122] Setting up pool2_1
I1005 00:43:46.692622 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.692622 17516 net.cpp:137] Memory required for data: 165377200
I1005 00:43:46.692622 17516 layer_factory.cpp:58] Creating layer conv4
I1005 00:43:46.692622 17516 net.cpp:84] Creating Layer conv4
I1005 00:43:46.692622 17516 net.cpp:406] conv4 <- pool2_1
I1005 00:43:46.692622 17516 net.cpp:380] conv4 -> conv4
I1005 00:43:46.708231 17516 net.cpp:122] Setting up conv4
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 167322800
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer bn4
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer bn4
I1005 00:43:46.708231 17516 net.cpp:406] bn4 <- conv4
I1005 00:43:46.708231 17516 net.cpp:367] bn4 -> conv4 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up bn4
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 169268400
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale4
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer scale4
I1005 00:43:46.708231 17516 net.cpp:406] scale4 <- conv4
I1005 00:43:46.708231 17516 net.cpp:367] scale4 -> conv4 (in-place)
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale4
I1005 00:43:46.708231 17516 net.cpp:122] Setting up scale4
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 171214000
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer relu4
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer relu4
I1005 00:43:46.708231 17516 net.cpp:406] relu4 <- conv4
I1005 00:43:46.708231 17516 net.cpp:367] relu4 -> conv4 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up relu4
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 173159600
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer conv4_1
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer conv4_1
I1005 00:43:46.708231 17516 net.cpp:406] conv4_1 <- conv4
I1005 00:43:46.708231 17516 net.cpp:380] conv4_1 -> conv4_1
I1005 00:43:46.708231 17516 net.cpp:122] Setting up conv4_1
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 175105200
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer bn4_1
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer bn4_1
I1005 00:43:46.708231 17516 net.cpp:406] bn4_1 <- conv4_1
I1005 00:43:46.708231 17516 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up bn4_1
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 177050800
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale4_1
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer scale4_1
I1005 00:43:46.708231 17516 net.cpp:406] scale4_1 <- conv4_1
I1005 00:43:46.708231 17516 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale4_1
I1005 00:43:46.708231 17516 net.cpp:122] Setting up scale4_1
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 178996400
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer relu4_1
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer relu4_1
I1005 00:43:46.708231 17516 net.cpp:406] relu4_1 <- conv4_1
I1005 00:43:46.708231 17516 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up relu4_1
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 180942000
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer conv4_2
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer conv4_2
I1005 00:43:46.708231 17516 net.cpp:406] conv4_2 <- conv4_1
I1005 00:43:46.708231 17516 net.cpp:380] conv4_2 -> conv4_2
I1005 00:43:46.708231 17516 net.cpp:122] Setting up conv4_2
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 183809200
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer bn4_2
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer bn4_2
I1005 00:43:46.708231 17516 net.cpp:406] bn4_2 <- conv4_2
I1005 00:43:46.708231 17516 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up bn4_2
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 186676400
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale4_2
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer scale4_2
I1005 00:43:46.708231 17516 net.cpp:406] scale4_2 <- conv4_2
I1005 00:43:46.708231 17516 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale4_2
I1005 00:43:46.708231 17516 net.cpp:122] Setting up scale4_2
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 189543600
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer relu4_2
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer relu4_2
I1005 00:43:46.708231 17516 net.cpp:406] relu4_2 <- conv4_2
I1005 00:43:46.708231 17516 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up relu4_2
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 192410800
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer pool4_2
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer pool4_2
I1005 00:43:46.708231 17516 net.cpp:406] pool4_2 <- conv4_2
I1005 00:43:46.708231 17516 net.cpp:380] pool4_2 -> pool4_2
I1005 00:43:46.708231 17516 net.cpp:122] Setting up pool4_2
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 193127600
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer conv4_0
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer conv4_0
I1005 00:43:46.708231 17516 net.cpp:406] conv4_0 <- pool4_2
I1005 00:43:46.708231 17516 net.cpp:380] conv4_0 -> conv4_0
I1005 00:43:46.708231 17516 net.cpp:122] Setting up conv4_0
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 193844400
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer bn4_0
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer bn4_0
I1005 00:43:46.708231 17516 net.cpp:406] bn4_0 <- conv4_0
I1005 00:43:46.708231 17516 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up bn4_0
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 194561200
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale4_0
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer scale4_0
I1005 00:43:46.708231 17516 net.cpp:406] scale4_0 <- conv4_0
I1005 00:43:46.708231 17516 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale4_0
I1005 00:43:46.708231 17516 net.cpp:122] Setting up scale4_0
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 195278000
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer relu4_0
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer relu4_0
I1005 00:43:46.708231 17516 net.cpp:406] relu4_0 <- conv4_0
I1005 00:43:46.708231 17516 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up relu4_0
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 195994800
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer conv11
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer conv11
I1005 00:43:46.708231 17516 net.cpp:406] conv11 <- conv4_0
I1005 00:43:46.708231 17516 net.cpp:380] conv11 -> conv11
I1005 00:43:46.708231 17516 net.cpp:122] Setting up conv11
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 196890800
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer bn_conv11
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer bn_conv11
I1005 00:43:46.708231 17516 net.cpp:406] bn_conv11 <- conv11
I1005 00:43:46.708231 17516 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up bn_conv11
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 197786800
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale_conv11
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer scale_conv11
I1005 00:43:46.708231 17516 net.cpp:406] scale_conv11 <- conv11
I1005 00:43:46.708231 17516 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale_conv11
I1005 00:43:46.708231 17516 net.cpp:122] Setting up scale_conv11
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 198682800
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer relu_conv11
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer relu_conv11
I1005 00:43:46.708231 17516 net.cpp:406] relu_conv11 <- conv11
I1005 00:43:46.708231 17516 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up relu_conv11
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 199578800
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer conv12
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer conv12
I1005 00:43:46.708231 17516 net.cpp:406] conv12 <- conv11
I1005 00:43:46.708231 17516 net.cpp:380] conv12 -> conv12
I1005 00:43:46.708231 17516 net.cpp:122] Setting up conv12
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 200679600
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer bn_conv12
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer bn_conv12
I1005 00:43:46.708231 17516 net.cpp:406] bn_conv12 <- conv12
I1005 00:43:46.708231 17516 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up bn_conv12
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 201780400
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale_conv12
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer scale_conv12
I1005 00:43:46.708231 17516 net.cpp:406] scale_conv12 <- conv12
I1005 00:43:46.708231 17516 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer scale_conv12
I1005 00:43:46.708231 17516 net.cpp:122] Setting up scale_conv12
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 202881200
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer relu_conv12
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer relu_conv12
I1005 00:43:46.708231 17516 net.cpp:406] relu_conv12 <- conv12
I1005 00:43:46.708231 17516 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1005 00:43:46.708231 17516 net.cpp:122] Setting up relu_conv12
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 203982000
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer poolcp6
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer poolcp6
I1005 00:43:46.708231 17516 net.cpp:406] poolcp6 <- conv12
I1005 00:43:46.708231 17516 net.cpp:380] poolcp6 -> poolcp6
I1005 00:43:46.708231 17516 net.cpp:122] Setting up poolcp6
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 203999200
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer ip1
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer ip1
I1005 00:43:46.708231 17516 net.cpp:406] ip1 <- poolcp6
I1005 00:43:46.708231 17516 net.cpp:380] ip1 -> ip1
I1005 00:43:46.708231 17516 net.cpp:122] Setting up ip1
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 204003200
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer ip1_ip1_0_split
I1005 00:43:46.708231 17516 net.cpp:406] ip1_ip1_0_split <- ip1
I1005 00:43:46.708231 17516 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1005 00:43:46.708231 17516 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1005 00:43:46.708231 17516 net.cpp:122] Setting up ip1_ip1_0_split
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 204011200
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer accuracy_training
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer accuracy_training
I1005 00:43:46.708231 17516 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1005 00:43:46.708231 17516 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1005 00:43:46.708231 17516 net.cpp:380] accuracy_training -> accuracy_training
I1005 00:43:46.708231 17516 net.cpp:122] Setting up accuracy_training
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: (1)
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 204011204
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer loss
I1005 00:43:46.708231 17516 net.cpp:84] Creating Layer loss
I1005 00:43:46.708231 17516 net.cpp:406] loss <- ip1_ip1_0_split_1
I1005 00:43:46.708231 17516 net.cpp:406] loss <- label_cifar_1_split_1
I1005 00:43:46.708231 17516 net.cpp:380] loss -> loss
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer loss
I1005 00:43:46.708231 17516 net.cpp:122] Setting up loss
I1005 00:43:46.708231 17516 net.cpp:129] Top shape: (1)
I1005 00:43:46.708231 17516 net.cpp:132]     with loss weight 1
I1005 00:43:46.708231 17516 net.cpp:137] Memory required for data: 204011208
I1005 00:43:46.708231 17516 net.cpp:198] loss needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:200] accuracy_training does not need backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] ip1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] poolcp6 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu_conv12 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale_conv12 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn_conv12 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv12 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu_conv11 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale_conv11 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn_conv11 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv11 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu4_0 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale4_0 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn4_0 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv4_0 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] pool4_2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu4_2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale4_2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn4_2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv4_2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu4_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale4_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn4_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv4_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu4 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale4 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn4 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv4 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] pool2_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu3_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale3_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn3_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv3_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu3 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale3 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn3 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv3 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu2_2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale2_2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn2_2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv2_2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu2_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale2_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn2_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv2_1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv2 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu1_0 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale1_0 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn1_0 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv1_0 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] relu1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] scale1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] bn1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:198] conv1 needs backward computation.
I1005 00:43:46.708231 17516 net.cpp:200] label_cifar_1_split does not need backward computation.
I1005 00:43:46.708231 17516 net.cpp:200] cifar does not need backward computation.
I1005 00:43:46.708231 17516 net.cpp:242] This network produces output accuracy_training
I1005 00:43:46.708231 17516 net.cpp:242] This network produces output loss
I1005 00:43:46.708231 17516 net.cpp:255] Network initialization done.
I1005 00:43:46.708231 17516 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 00:43:46.708231 17516 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 00:43:46.708231 17516 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1005 00:43:46.708231 17516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1005 00:43:46.708231 17516 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P7"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1005 00:43:46.708231 17516 layer_factory.cpp:58] Creating layer cifar
I1005 00:43:46.725253 17516 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I1005 00:43:46.725253 17516 net.cpp:84] Creating Layer cifar
I1005 00:43:46.725253 17516 net.cpp:380] cifar -> data
I1005 00:43:46.725253 17516 net.cpp:380] cifar -> label
I1005 00:43:46.725253 17516 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1005 00:43:46.725253 17516 data_layer.cpp:45] output data size: 100,3,32,32
I1005 00:43:46.726372 17516 net.cpp:122] Setting up cifar
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 (100)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 1229200
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer label_cifar_1_split
I1005 00:43:46.726372 17516 net.cpp:406] label_cifar_1_split <- label
I1005 00:43:46.726372 17516 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1005 00:43:46.726372 17516 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1005 00:43:46.726372 17516 net.cpp:122] Setting up label_cifar_1_split
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 (100)
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 (100)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 1230000
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer conv1
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer conv1
I1005 00:43:46.726372 17516 net.cpp:406] conv1 <- data
I1005 00:43:46.726372 17516 net.cpp:380] conv1 -> conv1
I1005 00:43:46.726372 18172 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 00:43:46.726372 17516 net.cpp:122] Setting up conv1
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 3687600
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer bn1
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer bn1
I1005 00:43:46.726372 17516 net.cpp:406] bn1 <- conv1
I1005 00:43:46.726372 17516 net.cpp:367] bn1 -> conv1 (in-place)
I1005 00:43:46.726372 17516 net.cpp:122] Setting up bn1
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 6145200
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer scale1
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer scale1
I1005 00:43:46.726372 17516 net.cpp:406] scale1 <- conv1
I1005 00:43:46.726372 17516 net.cpp:367] scale1 -> conv1 (in-place)
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer scale1
I1005 00:43:46.726372 17516 net.cpp:122] Setting up scale1
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 8602800
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer relu1
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer relu1
I1005 00:43:46.726372 17516 net.cpp:406] relu1 <- conv1
I1005 00:43:46.726372 17516 net.cpp:367] relu1 -> conv1 (in-place)
I1005 00:43:46.726372 17516 net.cpp:122] Setting up relu1
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 11060400
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer conv1_0
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer conv1_0
I1005 00:43:46.726372 17516 net.cpp:406] conv1_0 <- conv1
I1005 00:43:46.726372 17516 net.cpp:380] conv1_0 -> conv1_0
I1005 00:43:46.726372 17516 net.cpp:122] Setting up conv1_0
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 15975600
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer bn1_0
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer bn1_0
I1005 00:43:46.726372 17516 net.cpp:406] bn1_0 <- conv1_0
I1005 00:43:46.726372 17516 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1005 00:43:46.726372 17516 net.cpp:122] Setting up bn1_0
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 20890800
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer scale1_0
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer scale1_0
I1005 00:43:46.726372 17516 net.cpp:406] scale1_0 <- conv1_0
I1005 00:43:46.726372 17516 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer scale1_0
I1005 00:43:46.726372 17516 net.cpp:122] Setting up scale1_0
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 25806000
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer relu1_0
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer relu1_0
I1005 00:43:46.726372 17516 net.cpp:406] relu1_0 <- conv1_0
I1005 00:43:46.726372 17516 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1005 00:43:46.726372 17516 net.cpp:122] Setting up relu1_0
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 30721200
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer conv2
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer conv2
I1005 00:43:46.726372 17516 net.cpp:406] conv2 <- conv1_0
I1005 00:43:46.726372 17516 net.cpp:380] conv2 -> conv2
I1005 00:43:46.726372 17516 net.cpp:122] Setting up conv2
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 35636400
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer bn2
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer bn2
I1005 00:43:46.726372 17516 net.cpp:406] bn2 <- conv2
I1005 00:43:46.726372 17516 net.cpp:367] bn2 -> conv2 (in-place)
I1005 00:43:46.726372 17516 net.cpp:122] Setting up bn2
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 40551600
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer scale2
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer scale2
I1005 00:43:46.726372 17516 net.cpp:406] scale2 <- conv2
I1005 00:43:46.726372 17516 net.cpp:367] scale2 -> conv2 (in-place)
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer scale2
I1005 00:43:46.726372 17516 net.cpp:122] Setting up scale2
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 45466800
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer relu2
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer relu2
I1005 00:43:46.726372 17516 net.cpp:406] relu2 <- conv2
I1005 00:43:46.726372 17516 net.cpp:367] relu2 -> conv2 (in-place)
I1005 00:43:46.726372 17516 net.cpp:122] Setting up relu2
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 50382000
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer conv2_1
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer conv2_1
I1005 00:43:46.726372 17516 net.cpp:406] conv2_1 <- conv2
I1005 00:43:46.726372 17516 net.cpp:380] conv2_1 -> conv2_1
I1005 00:43:46.726372 17516 net.cpp:122] Setting up conv2_1
I1005 00:43:46.726372 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.726372 17516 net.cpp:137] Memory required for data: 55297200
I1005 00:43:46.726372 17516 layer_factory.cpp:58] Creating layer bn2_1
I1005 00:43:46.726372 17516 net.cpp:84] Creating Layer bn2_1
I1005 00:43:46.741998 17516 net.cpp:406] bn2_1 <- conv2_1
I1005 00:43:46.741998 17516 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up bn2_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 60212400
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale2_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer scale2_1
I1005 00:43:46.741998 17516 net.cpp:406] scale2_1 <- conv2_1
I1005 00:43:46.741998 17516 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale2_1
I1005 00:43:46.741998 17516 net.cpp:122] Setting up scale2_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 65127600
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer relu2_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer relu2_1
I1005 00:43:46.741998 17516 net.cpp:406] relu2_1 <- conv2_1
I1005 00:43:46.741998 17516 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up relu2_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 70042800
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer conv2_2
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer conv2_2
I1005 00:43:46.741998 17516 net.cpp:406] conv2_2 <- conv2_1
I1005 00:43:46.741998 17516 net.cpp:380] conv2_2 -> conv2_2
I1005 00:43:46.741998 17516 net.cpp:122] Setting up conv2_2
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 77825200
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer bn2_2
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer bn2_2
I1005 00:43:46.741998 17516 net.cpp:406] bn2_2 <- conv2_2
I1005 00:43:46.741998 17516 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up bn2_2
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 85607600
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale2_2
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer scale2_2
I1005 00:43:46.741998 17516 net.cpp:406] scale2_2 <- conv2_2
I1005 00:43:46.741998 17516 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale2_2
I1005 00:43:46.741998 17516 net.cpp:122] Setting up scale2_2
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 93390000
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer relu2_2
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer relu2_2
I1005 00:43:46.741998 17516 net.cpp:406] relu2_2 <- conv2_2
I1005 00:43:46.741998 17516 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up relu2_2
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 101172400
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer conv3
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer conv3
I1005 00:43:46.741998 17516 net.cpp:406] conv3 <- conv2_2
I1005 00:43:46.741998 17516 net.cpp:380] conv3 -> conv3
I1005 00:43:46.741998 17516 net.cpp:122] Setting up conv3
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 108954800
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer bn3
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer bn3
I1005 00:43:46.741998 17516 net.cpp:406] bn3 <- conv3
I1005 00:43:46.741998 17516 net.cpp:367] bn3 -> conv3 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up bn3
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 116737200
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale3
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer scale3
I1005 00:43:46.741998 17516 net.cpp:406] scale3 <- conv3
I1005 00:43:46.741998 17516 net.cpp:367] scale3 -> conv3 (in-place)
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale3
I1005 00:43:46.741998 17516 net.cpp:122] Setting up scale3
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 124519600
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer relu3
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer relu3
I1005 00:43:46.741998 17516 net.cpp:406] relu3 <- conv3
I1005 00:43:46.741998 17516 net.cpp:367] relu3 -> conv3 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up relu3
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 132302000
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer conv3_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer conv3_1
I1005 00:43:46.741998 17516 net.cpp:406] conv3_1 <- conv3
I1005 00:43:46.741998 17516 net.cpp:380] conv3_1 -> conv3_1
I1005 00:43:46.741998 17516 net.cpp:122] Setting up conv3_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 140084400
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer bn3_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer bn3_1
I1005 00:43:46.741998 17516 net.cpp:406] bn3_1 <- conv3_1
I1005 00:43:46.741998 17516 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up bn3_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 147866800
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale3_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer scale3_1
I1005 00:43:46.741998 17516 net.cpp:406] scale3_1 <- conv3_1
I1005 00:43:46.741998 17516 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale3_1
I1005 00:43:46.741998 17516 net.cpp:122] Setting up scale3_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 155649200
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer relu3_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer relu3_1
I1005 00:43:46.741998 17516 net.cpp:406] relu3_1 <- conv3_1
I1005 00:43:46.741998 17516 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up relu3_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 163431600
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer pool2_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer pool2_1
I1005 00:43:46.741998 17516 net.cpp:406] pool2_1 <- conv3_1
I1005 00:43:46.741998 17516 net.cpp:380] pool2_1 -> pool2_1
I1005 00:43:46.741998 17516 net.cpp:122] Setting up pool2_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 165377200
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer conv4
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer conv4
I1005 00:43:46.741998 17516 net.cpp:406] conv4 <- pool2_1
I1005 00:43:46.741998 17516 net.cpp:380] conv4 -> conv4
I1005 00:43:46.741998 17516 net.cpp:122] Setting up conv4
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 167322800
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer bn4
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer bn4
I1005 00:43:46.741998 17516 net.cpp:406] bn4 <- conv4
I1005 00:43:46.741998 17516 net.cpp:367] bn4 -> conv4 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up bn4
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 169268400
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale4
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer scale4
I1005 00:43:46.741998 17516 net.cpp:406] scale4 <- conv4
I1005 00:43:46.741998 17516 net.cpp:367] scale4 -> conv4 (in-place)
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale4
I1005 00:43:46.741998 17516 net.cpp:122] Setting up scale4
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 171214000
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer relu4
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer relu4
I1005 00:43:46.741998 17516 net.cpp:406] relu4 <- conv4
I1005 00:43:46.741998 17516 net.cpp:367] relu4 -> conv4 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up relu4
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 173159600
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer conv4_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer conv4_1
I1005 00:43:46.741998 17516 net.cpp:406] conv4_1 <- conv4
I1005 00:43:46.741998 17516 net.cpp:380] conv4_1 -> conv4_1
I1005 00:43:46.741998 17516 net.cpp:122] Setting up conv4_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 175105200
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer bn4_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer bn4_1
I1005 00:43:46.741998 17516 net.cpp:406] bn4_1 <- conv4_1
I1005 00:43:46.741998 17516 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up bn4_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 177050800
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale4_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer scale4_1
I1005 00:43:46.741998 17516 net.cpp:406] scale4_1 <- conv4_1
I1005 00:43:46.741998 17516 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale4_1
I1005 00:43:46.741998 17516 net.cpp:122] Setting up scale4_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 178996400
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer relu4_1
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer relu4_1
I1005 00:43:46.741998 17516 net.cpp:406] relu4_1 <- conv4_1
I1005 00:43:46.741998 17516 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up relu4_1
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 180942000
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer conv4_2
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer conv4_2
I1005 00:43:46.741998 17516 net.cpp:406] conv4_2 <- conv4_1
I1005 00:43:46.741998 17516 net.cpp:380] conv4_2 -> conv4_2
I1005 00:43:46.741998 17516 net.cpp:122] Setting up conv4_2
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 183809200
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer bn4_2
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer bn4_2
I1005 00:43:46.741998 17516 net.cpp:406] bn4_2 <- conv4_2
I1005 00:43:46.741998 17516 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up bn4_2
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 186676400
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale4_2
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer scale4_2
I1005 00:43:46.741998 17516 net.cpp:406] scale4_2 <- conv4_2
I1005 00:43:46.741998 17516 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale4_2
I1005 00:43:46.741998 17516 net.cpp:122] Setting up scale4_2
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 189543600
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer relu4_2
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer relu4_2
I1005 00:43:46.741998 17516 net.cpp:406] relu4_2 <- conv4_2
I1005 00:43:46.741998 17516 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up relu4_2
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 192410800
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer pool4_2
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer pool4_2
I1005 00:43:46.741998 17516 net.cpp:406] pool4_2 <- conv4_2
I1005 00:43:46.741998 17516 net.cpp:380] pool4_2 -> pool4_2
I1005 00:43:46.741998 17516 net.cpp:122] Setting up pool4_2
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 193127600
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer conv4_0
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer conv4_0
I1005 00:43:46.741998 17516 net.cpp:406] conv4_0 <- pool4_2
I1005 00:43:46.741998 17516 net.cpp:380] conv4_0 -> conv4_0
I1005 00:43:46.741998 17516 net.cpp:122] Setting up conv4_0
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 193844400
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer bn4_0
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer bn4_0
I1005 00:43:46.741998 17516 net.cpp:406] bn4_0 <- conv4_0
I1005 00:43:46.741998 17516 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up bn4_0
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 194561200
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale4_0
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer scale4_0
I1005 00:43:46.741998 17516 net.cpp:406] scale4_0 <- conv4_0
I1005 00:43:46.741998 17516 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer scale4_0
I1005 00:43:46.741998 17516 net.cpp:122] Setting up scale4_0
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 195278000
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer relu4_0
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer relu4_0
I1005 00:43:46.741998 17516 net.cpp:406] relu4_0 <- conv4_0
I1005 00:43:46.741998 17516 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1005 00:43:46.741998 17516 net.cpp:122] Setting up relu4_0
I1005 00:43:46.741998 17516 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 00:43:46.741998 17516 net.cpp:137] Memory required for data: 195994800
I1005 00:43:46.741998 17516 layer_factory.cpp:58] Creating layer conv11
I1005 00:43:46.741998 17516 net.cpp:84] Creating Layer conv11
I1005 00:43:46.741998 17516 net.cpp:406] conv11 <- conv4_0
I1005 00:43:46.741998 17516 net.cpp:380] conv11 -> conv11
I1005 00:43:46.757624 17516 net.cpp:122] Setting up conv11
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 196890800
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer bn_conv11
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer bn_conv11
I1005 00:43:46.757624 17516 net.cpp:406] bn_conv11 <- conv11
I1005 00:43:46.757624 17516 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1005 00:43:46.757624 17516 net.cpp:122] Setting up bn_conv11
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 197786800
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer scale_conv11
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer scale_conv11
I1005 00:43:46.757624 17516 net.cpp:406] scale_conv11 <- conv11
I1005 00:43:46.757624 17516 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer scale_conv11
I1005 00:43:46.757624 17516 net.cpp:122] Setting up scale_conv11
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 198682800
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer relu_conv11
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer relu_conv11
I1005 00:43:46.757624 17516 net.cpp:406] relu_conv11 <- conv11
I1005 00:43:46.757624 17516 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1005 00:43:46.757624 17516 net.cpp:122] Setting up relu_conv11
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 199578800
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer conv12
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer conv12
I1005 00:43:46.757624 17516 net.cpp:406] conv12 <- conv11
I1005 00:43:46.757624 17516 net.cpp:380] conv12 -> conv12
I1005 00:43:46.757624 17516 net.cpp:122] Setting up conv12
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 200679600
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer bn_conv12
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer bn_conv12
I1005 00:43:46.757624 17516 net.cpp:406] bn_conv12 <- conv12
I1005 00:43:46.757624 17516 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1005 00:43:46.757624 17516 net.cpp:122] Setting up bn_conv12
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 201780400
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer scale_conv12
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer scale_conv12
I1005 00:43:46.757624 17516 net.cpp:406] scale_conv12 <- conv12
I1005 00:43:46.757624 17516 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer scale_conv12
I1005 00:43:46.757624 17516 net.cpp:122] Setting up scale_conv12
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 202881200
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer relu_conv12
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer relu_conv12
I1005 00:43:46.757624 17516 net.cpp:406] relu_conv12 <- conv12
I1005 00:43:46.757624 17516 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1005 00:43:46.757624 17516 net.cpp:122] Setting up relu_conv12
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 203982000
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer poolcp6
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer poolcp6
I1005 00:43:46.757624 17516 net.cpp:406] poolcp6 <- conv12
I1005 00:43:46.757624 17516 net.cpp:380] poolcp6 -> poolcp6
I1005 00:43:46.757624 17516 net.cpp:122] Setting up poolcp6
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 203999200
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer ip1
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer ip1
I1005 00:43:46.757624 17516 net.cpp:406] ip1 <- poolcp6
I1005 00:43:46.757624 17516 net.cpp:380] ip1 -> ip1
I1005 00:43:46.757624 17516 net.cpp:122] Setting up ip1
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 204003200
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer ip1_ip1_0_split
I1005 00:43:46.757624 17516 net.cpp:406] ip1_ip1_0_split <- ip1
I1005 00:43:46.757624 17516 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1005 00:43:46.757624 17516 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1005 00:43:46.757624 17516 net.cpp:122] Setting up ip1_ip1_0_split
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: 100 10 (1000)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 204011200
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer accuracy
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer accuracy
I1005 00:43:46.757624 17516 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1005 00:43:46.757624 17516 net.cpp:406] accuracy <- label_cifar_1_split_0
I1005 00:43:46.757624 17516 net.cpp:380] accuracy -> accuracy
I1005 00:43:46.757624 17516 net.cpp:122] Setting up accuracy
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: (1)
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 204011204
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer loss
I1005 00:43:46.757624 17516 net.cpp:84] Creating Layer loss
I1005 00:43:46.757624 17516 net.cpp:406] loss <- ip1_ip1_0_split_1
I1005 00:43:46.757624 17516 net.cpp:406] loss <- label_cifar_1_split_1
I1005 00:43:46.757624 17516 net.cpp:380] loss -> loss
I1005 00:43:46.757624 17516 layer_factory.cpp:58] Creating layer loss
I1005 00:43:46.757624 17516 net.cpp:122] Setting up loss
I1005 00:43:46.757624 17516 net.cpp:129] Top shape: (1)
I1005 00:43:46.757624 17516 net.cpp:132]     with loss weight 1
I1005 00:43:46.757624 17516 net.cpp:137] Memory required for data: 204011208
I1005 00:43:46.757624 17516 net.cpp:198] loss needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:200] accuracy does not need backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] ip1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] poolcp6 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu_conv12 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale_conv12 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn_conv12 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv12 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu_conv11 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale_conv11 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn_conv11 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv11 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu4_0 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale4_0 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn4_0 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv4_0 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] pool4_2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu4_2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale4_2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn4_2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv4_2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu4_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale4_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn4_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv4_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu4 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale4 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn4 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv4 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] pool2_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu3_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale3_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn3_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv3_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu3 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale3 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn3 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv3 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu2_2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale2_2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn2_2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv2_2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu2_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale2_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn2_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv2_1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv2 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu1_0 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale1_0 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn1_0 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv1_0 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] relu1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] scale1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] bn1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:198] conv1 needs backward computation.
I1005 00:43:46.757624 17516 net.cpp:200] label_cifar_1_split does not need backward computation.
I1005 00:43:46.757624 17516 net.cpp:200] cifar does not need backward computation.
I1005 00:43:46.757624 17516 net.cpp:242] This network produces output accuracy
I1005 00:43:46.757624 17516 net.cpp:242] This network produces output loss
I1005 00:43:46.757624 17516 net.cpp:255] Network initialization done.
I1005 00:43:46.757624 17516 solver.cpp:56] Solver scaffolding done.
I1005 00:43:46.757624 17516 caffe.cpp:249] Starting Optimization
I1005 00:43:46.757624 17516 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_drpall_Simple_P7
I1005 00:43:46.757624 17516 solver.cpp:273] Learning Rate Policy: multistep
I1005 00:43:46.757624 17516 solver.cpp:330] Iteration 0, Testing net (#0)
I1005 00:43:46.757624 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:43:47.455209 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:43:47.470844 17516 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1005 00:43:47.470844 17516 solver.cpp:397]     Test net output #1: loss = 78.6029 (* 1 = 78.6029 loss)
I1005 00:43:47.533354 17516 solver.cpp:218] Iteration 0 (0 iter/s, 0.77963s/100 iters), loss = 4.18075
I1005 00:43:47.533354 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.16
I1005 00:43:47.533354 17516 solver.cpp:237]     Train net output #1: loss = 4.18075 (* 1 = 4.18075 loss)
I1005 00:43:47.533354 17516 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1005 00:43:50.828698 17516 solver.cpp:218] Iteration 100 (30.3989 iter/s, 3.2896s/100 iters), loss = 1.79347
I1005 00:43:50.828698 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I1005 00:43:50.828698 17516 solver.cpp:237]     Train net output #1: loss = 1.79347 (* 1 = 1.79347 loss)
I1005 00:43:50.828698 17516 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1005 00:43:54.104840 17516 solver.cpp:218] Iteration 200 (30.5376 iter/s, 3.27465s/100 iters), loss = 1.81371
I1005 00:43:54.104840 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I1005 00:43:54.104840 17516 solver.cpp:237]     Train net output #1: loss = 1.81371 (* 1 = 1.81371 loss)
I1005 00:43:54.104840 17516 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1005 00:43:57.384223 17516 solver.cpp:218] Iteration 300 (30.55 iter/s, 3.27332s/100 iters), loss = 1.53967
I1005 00:43:57.384223 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1005 00:43:57.384223 17516 solver.cpp:237]     Train net output #1: loss = 1.53967 (* 1 = 1.53967 loss)
I1005 00:43:57.384223 17516 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1005 00:44:00.654567 17516 solver.cpp:218] Iteration 400 (30.5693 iter/s, 3.27126s/100 iters), loss = 1.44365
I1005 00:44:00.654567 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1005 00:44:00.654567 17516 solver.cpp:237]     Train net output #1: loss = 1.44365 (* 1 = 1.44365 loss)
I1005 00:44:00.654567 17516 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1005 00:44:03.775081  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:44:03.931329 17516 solver.cpp:218] Iteration 500 (30.4234 iter/s, 3.28695s/100 iters), loss = 1.46968
I1005 00:44:03.931329 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1005 00:44:03.931329 17516 solver.cpp:237]     Train net output #1: loss = 1.46968 (* 1 = 1.46968 loss)
I1005 00:44:03.931329 17516 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1005 00:44:07.227368 17516 solver.cpp:218] Iteration 600 (30.4364 iter/s, 3.28554s/100 iters), loss = 1.33445
I1005 00:44:07.227368 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1005 00:44:07.227368 17516 solver.cpp:237]     Train net output #1: loss = 1.33445 (* 1 = 1.33445 loss)
I1005 00:44:07.227368 17516 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1005 00:44:10.516551 17516 solver.cpp:218] Iteration 700 (30.3621 iter/s, 3.29358s/100 iters), loss = 1.42083
I1005 00:44:10.516551 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1005 00:44:10.516551 17516 solver.cpp:237]     Train net output #1: loss = 1.42083 (* 1 = 1.42083 loss)
I1005 00:44:10.516551 17516 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1005 00:44:13.795162 17516 solver.cpp:218] Iteration 800 (30.4643 iter/s, 3.28253s/100 iters), loss = 1.2729
I1005 00:44:13.795162 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1005 00:44:13.795162 17516 solver.cpp:237]     Train net output #1: loss = 1.2729 (* 1 = 1.2729 loss)
I1005 00:44:13.795162 17516 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1005 00:44:17.069658 17516 solver.cpp:218] Iteration 900 (30.6 iter/s, 3.26797s/100 iters), loss = 1.19117
I1005 00:44:17.069658 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1005 00:44:17.069658 17516 solver.cpp:237]     Train net output #1: loss = 1.19117 (* 1 = 1.19117 loss)
I1005 00:44:17.069658 17516 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1005 00:44:20.174332  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:44:20.319030 17516 solver.cpp:330] Iteration 1000, Testing net (#0)
I1005 00:44:20.319030 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:44:20.968359 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:44:20.999606 17516 solver.cpp:397]     Test net output #0: accuracy = 0.5658
I1005 00:44:20.999606 17516 solver.cpp:397]     Test net output #1: loss = 1.20616 (* 1 = 1.20616 loss)
I1005 00:44:21.015223 17516 solver.cpp:218] Iteration 1000 (25.2855 iter/s, 3.95483s/100 iters), loss = 1.18525
I1005 00:44:21.015223 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1005 00:44:21.015223 17516 solver.cpp:237]     Train net output #1: loss = 1.18525 (* 1 = 1.18525 loss)
I1005 00:44:21.015223 17516 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1005 00:44:24.333518 17516 solver.cpp:218] Iteration 1100 (30.2812 iter/s, 3.30238s/100 iters), loss = 1.06643
I1005 00:44:24.333518 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1005 00:44:24.333518 17516 solver.cpp:237]     Train net output #1: loss = 1.06643 (* 1 = 1.06643 loss)
I1005 00:44:24.333518 17516 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1005 00:44:27.691555 17516 solver.cpp:218] Iteration 1200 (29.7805 iter/s, 3.3579s/100 iters), loss = 1.16235
I1005 00:44:27.691555 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1005 00:44:27.691555 17516 solver.cpp:237]     Train net output #1: loss = 1.16235 (* 1 = 1.16235 loss)
I1005 00:44:27.691555 17516 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1005 00:44:31.047143 17516 solver.cpp:218] Iteration 1300 (29.8042 iter/s, 3.35523s/100 iters), loss = 1.11413
I1005 00:44:31.047143 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1005 00:44:31.047143 17516 solver.cpp:237]     Train net output #1: loss = 1.11413 (* 1 = 1.11413 loss)
I1005 00:44:31.047143 17516 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1005 00:44:34.333156 17516 solver.cpp:218] Iteration 1400 (30.4377 iter/s, 3.28539s/100 iters), loss = 0.979631
I1005 00:44:34.333156 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1005 00:44:34.333156 17516 solver.cpp:237]     Train net output #1: loss = 0.979631 (* 1 = 0.979631 loss)
I1005 00:44:34.333156 17516 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1005 00:44:37.437144  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:44:37.598141 17516 solver.cpp:218] Iteration 1500 (30.6334 iter/s, 3.26441s/100 iters), loss = 1.09118
I1005 00:44:37.598141 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1005 00:44:37.598141 17516 solver.cpp:237]     Train net output #1: loss = 1.09118 (* 1 = 1.09118 loss)
I1005 00:44:37.598141 17516 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1005 00:44:40.860152 17516 solver.cpp:218] Iteration 1600 (30.6559 iter/s, 3.26202s/100 iters), loss = 0.971675
I1005 00:44:40.860152 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1005 00:44:40.860152 17516 solver.cpp:237]     Train net output #1: loss = 0.971675 (* 1 = 0.971675 loss)
I1005 00:44:40.860152 17516 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1005 00:44:44.113157 17516 solver.cpp:218] Iteration 1700 (30.75 iter/s, 3.25204s/100 iters), loss = 1.10953
I1005 00:44:44.113157 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1005 00:44:44.113157 17516 solver.cpp:237]     Train net output #1: loss = 1.10953 (* 1 = 1.10953 loss)
I1005 00:44:44.113157 17516 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1005 00:44:47.386142 17516 solver.cpp:218] Iteration 1800 (30.5525 iter/s, 3.27305s/100 iters), loss = 1.00357
I1005 00:44:47.386142 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1005 00:44:47.386142 17516 solver.cpp:237]     Train net output #1: loss = 1.00357 (* 1 = 1.00357 loss)
I1005 00:44:47.386142 17516 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1005 00:44:50.744140 17516 solver.cpp:218] Iteration 1900 (29.7832 iter/s, 3.3576s/100 iters), loss = 0.9577
I1005 00:44:50.744140 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1005 00:44:50.744140 17516 solver.cpp:237]     Train net output #1: loss = 0.9577 (* 1 = 0.9577 loss)
I1005 00:44:50.744140 17516 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1005 00:44:53.871142  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:44:54.000142 17516 solver.cpp:330] Iteration 2000, Testing net (#0)
I1005 00:44:54.000142 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:44:54.645143 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:44:54.672142 17516 solver.cpp:397]     Test net output #0: accuracy = 0.6657
I1005 00:44:54.672142 17516 solver.cpp:397]     Test net output #1: loss = 0.949812 (* 1 = 0.949812 loss)
I1005 00:44:54.702142 17516 solver.cpp:218] Iteration 2000 (25.2665 iter/s, 3.95781s/100 iters), loss = 0.924277
I1005 00:44:54.702142 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1005 00:44:54.702142 17516 solver.cpp:237]     Train net output #1: loss = 0.924277 (* 1 = 0.924277 loss)
I1005 00:44:54.703142 17516 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1005 00:44:57.987152 17516 solver.cpp:218] Iteration 2100 (30.4528 iter/s, 3.28377s/100 iters), loss = 0.818999
I1005 00:44:57.987152 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1005 00:44:57.987152 17516 solver.cpp:237]     Train net output #1: loss = 0.818999 (* 1 = 0.818999 loss)
I1005 00:44:57.987152 17516 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1005 00:45:01.264713 17516 solver.cpp:218] Iteration 2200 (30.4977 iter/s, 3.27893s/100 iters), loss = 0.893457
I1005 00:45:01.264713 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1005 00:45:01.264713 17516 solver.cpp:237]     Train net output #1: loss = 0.893457 (* 1 = 0.893457 loss)
I1005 00:45:01.264713 17516 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1005 00:45:04.537632 17516 solver.cpp:218] Iteration 2300 (30.5578 iter/s, 3.27249s/100 iters), loss = 0.83843
I1005 00:45:04.537632 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1005 00:45:04.537632 17516 solver.cpp:237]     Train net output #1: loss = 0.83843 (* 1 = 0.83843 loss)
I1005 00:45:04.537632 17516 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1005 00:45:07.815485 17516 solver.cpp:218] Iteration 2400 (30.4987 iter/s, 3.27883s/100 iters), loss = 0.804903
I1005 00:45:07.815485 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1005 00:45:07.815485 17516 solver.cpp:237]     Train net output #1: loss = 0.804903 (* 1 = 0.804903 loss)
I1005 00:45:07.815485 17516 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1005 00:45:10.938194  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:45:11.100206 17516 solver.cpp:218] Iteration 2500 (30.4721 iter/s, 3.28169s/100 iters), loss = 0.806263
I1005 00:45:11.100206 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1005 00:45:11.100206 17516 solver.cpp:237]     Train net output #1: loss = 0.806263 (* 1 = 0.806263 loss)
I1005 00:45:11.100206 17516 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1005 00:45:14.368558 17516 solver.cpp:218] Iteration 2600 (30.4956 iter/s, 3.27916s/100 iters), loss = 0.653396
I1005 00:45:14.368558 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 00:45:14.368558 17516 solver.cpp:237]     Train net output #1: loss = 0.653396 (* 1 = 0.653396 loss)
I1005 00:45:14.368558 17516 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1005 00:45:17.649132 17516 solver.cpp:218] Iteration 2700 (30.5594 iter/s, 3.27232s/100 iters), loss = 0.878935
I1005 00:45:17.649132 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1005 00:45:17.649132 17516 solver.cpp:237]     Train net output #1: loss = 0.878935 (* 1 = 0.878935 loss)
I1005 00:45:17.649132 17516 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1005 00:45:20.922030 17516 solver.cpp:218] Iteration 2800 (30.538 iter/s, 3.27461s/100 iters), loss = 0.815897
I1005 00:45:20.922030 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1005 00:45:20.922030 17516 solver.cpp:237]     Train net output #1: loss = 0.815897 (* 1 = 0.815897 loss)
I1005 00:45:20.922030 17516 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1005 00:45:24.217747 17516 solver.cpp:218] Iteration 2900 (30.3903 iter/s, 3.29052s/100 iters), loss = 0.681751
I1005 00:45:24.217747 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1005 00:45:24.217747 17516 solver.cpp:237]     Train net output #1: loss = 0.681751 (* 1 = 0.681751 loss)
I1005 00:45:24.217747 17516 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1005 00:45:27.340878  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:45:27.468878 17516 solver.cpp:330] Iteration 3000, Testing net (#0)
I1005 00:45:27.468878 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:45:28.134876 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:45:28.160877 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7123
I1005 00:45:28.160877 17516 solver.cpp:397]     Test net output #1: loss = 0.840183 (* 1 = 0.840183 loss)
I1005 00:45:28.191877 17516 solver.cpp:218] Iteration 3000 (25.1706 iter/s, 3.97289s/100 iters), loss = 0.771824
I1005 00:45:28.191877 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1005 00:45:28.191877 17516 solver.cpp:237]     Train net output #1: loss = 0.771824 (* 1 = 0.771824 loss)
I1005 00:45:28.191877 17516 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1005 00:45:31.492877 17516 solver.cpp:218] Iteration 3100 (30.2886 iter/s, 3.30157s/100 iters), loss = 0.649051
I1005 00:45:31.492877 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:45:31.492877 17516 solver.cpp:237]     Train net output #1: loss = 0.649051 (* 1 = 0.649051 loss)
I1005 00:45:31.493877 17516 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1005 00:45:34.822875 17516 solver.cpp:218] Iteration 3200 (30.0372 iter/s, 3.32921s/100 iters), loss = 0.787684
I1005 00:45:34.822875 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1005 00:45:34.822875 17516 solver.cpp:237]     Train net output #1: loss = 0.787684 (* 1 = 0.787684 loss)
I1005 00:45:34.822875 17516 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1005 00:45:38.136876 17516 solver.cpp:218] Iteration 3300 (30.1746 iter/s, 3.31405s/100 iters), loss = 0.689706
I1005 00:45:38.136876 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 00:45:38.136876 17516 solver.cpp:237]     Train net output #1: loss = 0.689706 (* 1 = 0.689706 loss)
I1005 00:45:38.136876 17516 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1005 00:45:41.451877 17516 solver.cpp:218] Iteration 3400 (30.1733 iter/s, 3.31419s/100 iters), loss = 0.659932
I1005 00:45:41.451877 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 00:45:41.451877 17516 solver.cpp:237]     Train net output #1: loss = 0.659932 (* 1 = 0.659932 loss)
I1005 00:45:41.451877 17516 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1005 00:45:44.587877  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:45:44.746876 17516 solver.cpp:218] Iteration 3500 (30.3473 iter/s, 3.29518s/100 iters), loss = 0.630564
I1005 00:45:44.747876 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:45:44.747876 17516 solver.cpp:237]     Train net output #1: loss = 0.630564 (* 1 = 0.630564 loss)
I1005 00:45:44.747876 17516 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1005 00:45:48.040890 17516 solver.cpp:218] Iteration 3600 (30.3645 iter/s, 3.29332s/100 iters), loss = 0.582305
I1005 00:45:48.040890 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:45:48.040890 17516 solver.cpp:237]     Train net output #1: loss = 0.582305 (* 1 = 0.582305 loss)
I1005 00:45:48.040890 17516 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1005 00:45:51.383671 17516 solver.cpp:218] Iteration 3700 (29.9156 iter/s, 3.34274s/100 iters), loss = 0.686688
I1005 00:45:51.384661 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1005 00:45:51.384661 17516 solver.cpp:237]     Train net output #1: loss = 0.686688 (* 1 = 0.686688 loss)
I1005 00:45:51.384661 17516 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1005 00:45:54.656661 17516 solver.cpp:218] Iteration 3800 (30.5622 iter/s, 3.27202s/100 iters), loss = 0.688163
I1005 00:45:54.656661 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 00:45:54.656661 17516 solver.cpp:237]     Train net output #1: loss = 0.688163 (* 1 = 0.688163 loss)
I1005 00:45:54.656661 17516 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1005 00:45:57.985672 17516 solver.cpp:218] Iteration 3900 (30.038 iter/s, 3.32911s/100 iters), loss = 0.671169
I1005 00:45:57.985672 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1005 00:45:57.985672 17516 solver.cpp:237]     Train net output #1: loss = 0.671169 (* 1 = 0.671169 loss)
I1005 00:45:57.985672 17516 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1005 00:46:01.148661  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:46:01.276677 17516 solver.cpp:330] Iteration 4000, Testing net (#0)
I1005 00:46:01.276677 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:46:01.925675 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:46:01.951661 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7424
I1005 00:46:01.951661 17516 solver.cpp:397]     Test net output #1: loss = 0.742731 (* 1 = 0.742731 loss)
I1005 00:46:01.983661 17516 solver.cpp:218] Iteration 4000 (25.0151 iter/s, 3.99759s/100 iters), loss = 0.630715
I1005 00:46:01.983661 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1005 00:46:01.983661 17516 solver.cpp:237]     Train net output #1: loss = 0.630715 (* 1 = 0.630715 loss)
I1005 00:46:01.983661 17516 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1005 00:46:05.272027 17516 solver.cpp:218] Iteration 4100 (30.4131 iter/s, 3.28806s/100 iters), loss = 0.54317
I1005 00:46:05.273015 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:46:05.273015 17516 solver.cpp:237]     Train net output #1: loss = 0.54317 (* 1 = 0.54317 loss)
I1005 00:46:05.273015 17516 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1005 00:46:08.548213 17516 solver.cpp:218] Iteration 4200 (30.5288 iter/s, 3.27559s/100 iters), loss = 0.675917
I1005 00:46:08.548213 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:46:08.548213 17516 solver.cpp:237]     Train net output #1: loss = 0.675917 (* 1 = 0.675917 loss)
I1005 00:46:08.548213 17516 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1005 00:46:11.811198 17516 solver.cpp:218] Iteration 4300 (30.6528 iter/s, 3.26235s/100 iters), loss = 0.622214
I1005 00:46:11.811198 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 00:46:11.811198 17516 solver.cpp:237]     Train net output #1: loss = 0.622214 (* 1 = 0.622214 loss)
I1005 00:46:11.811198 17516 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1005 00:46:15.072198 17516 solver.cpp:218] Iteration 4400 (30.6641 iter/s, 3.26115s/100 iters), loss = 0.548762
I1005 00:46:15.072198 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 00:46:15.072198 17516 solver.cpp:237]     Train net output #1: loss = 0.548762 (* 1 = 0.548762 loss)
I1005 00:46:15.072198 17516 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1005 00:46:18.192358  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:46:18.353356 17516 solver.cpp:218] Iteration 4500 (30.4796 iter/s, 3.28088s/100 iters), loss = 0.621275
I1005 00:46:18.354357 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1005 00:46:18.354357 17516 solver.cpp:237]     Train net output #1: loss = 0.621275 (* 1 = 0.621275 loss)
I1005 00:46:18.354357 17516 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1005 00:46:21.616638 17516 solver.cpp:218] Iteration 4600 (30.5642 iter/s, 3.2718s/100 iters), loss = 0.587702
I1005 00:46:21.616638 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:46:21.616638 17516 solver.cpp:237]     Train net output #1: loss = 0.587702 (* 1 = 0.587702 loss)
I1005 00:46:21.616638 17516 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1005 00:46:24.923867 17516 solver.cpp:218] Iteration 4700 (30.3253 iter/s, 3.29758s/100 iters), loss = 0.640276
I1005 00:46:24.923867 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:46:24.923867 17516 solver.cpp:237]     Train net output #1: loss = 0.640276 (* 1 = 0.640276 loss)
I1005 00:46:24.923867 17516 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1005 00:46:28.207886 17516 solver.cpp:218] Iteration 4800 (30.453 iter/s, 3.28375s/100 iters), loss = 0.667299
I1005 00:46:28.207886 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:46:28.207886 17516 solver.cpp:237]     Train net output #1: loss = 0.667299 (* 1 = 0.667299 loss)
I1005 00:46:28.207886 17516 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1005 00:46:31.532598 17516 solver.cpp:218] Iteration 4900 (30.0821 iter/s, 3.32424s/100 iters), loss = 0.58849
I1005 00:46:31.532598 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 00:46:31.532598 17516 solver.cpp:237]     Train net output #1: loss = 0.58849 (* 1 = 0.58849 loss)
I1005 00:46:31.532598 17516 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1005 00:46:34.706596  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:46:34.835597 17516 solver.cpp:330] Iteration 5000, Testing net (#0)
I1005 00:46:34.835597 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:46:35.478600 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:46:35.504597 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7479
I1005 00:46:35.504597 17516 solver.cpp:397]     Test net output #1: loss = 0.731731 (* 1 = 0.731731 loss)
I1005 00:46:35.535605 17516 solver.cpp:218] Iteration 5000 (24.9851 iter/s, 4.00238s/100 iters), loss = 0.54982
I1005 00:46:35.535605 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 00:46:35.535605 17516 solver.cpp:237]     Train net output #1: loss = 0.54982 (* 1 = 0.54982 loss)
I1005 00:46:35.535605 17516 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I1005 00:46:35.535605 17516 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I1005 00:46:38.797595 17516 solver.cpp:218] Iteration 5100 (30.6606 iter/s, 3.26152s/100 iters), loss = 0.515601
I1005 00:46:38.797595 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:46:38.797595 17516 solver.cpp:237]     Train net output #1: loss = 0.515601 (* 1 = 0.515601 loss)
I1005 00:46:38.797595 17516 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I1005 00:46:42.116595 17516 solver.cpp:218] Iteration 5200 (30.1301 iter/s, 3.31894s/100 iters), loss = 0.554949
I1005 00:46:42.116595 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:46:42.116595 17516 solver.cpp:237]     Train net output #1: loss = 0.554949 (* 1 = 0.554949 loss)
I1005 00:46:42.116595 17516 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I1005 00:46:45.398610 17516 solver.cpp:218] Iteration 5300 (30.472 iter/s, 3.2817s/100 iters), loss = 0.533397
I1005 00:46:45.398610 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:46:45.398610 17516 solver.cpp:237]     Train net output #1: loss = 0.533397 (* 1 = 0.533397 loss)
I1005 00:46:45.398610 17516 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I1005 00:46:48.720607 17516 solver.cpp:218] Iteration 5400 (30.1049 iter/s, 3.32171s/100 iters), loss = 0.447914
I1005 00:46:48.720607 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:46:48.720607 17516 solver.cpp:237]     Train net output #1: loss = 0.447914 (* 1 = 0.447914 loss)
I1005 00:46:48.720607 17516 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I1005 00:46:51.849596  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:46:52.010607 17516 solver.cpp:218] Iteration 5500 (30.3991 iter/s, 3.28957s/100 iters), loss = 0.510182
I1005 00:46:52.010607 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:46:52.010607 17516 solver.cpp:237]     Train net output #1: loss = 0.510182 (* 1 = 0.510182 loss)
I1005 00:46:52.010607 17516 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I1005 00:46:55.325597 17516 solver.cpp:218] Iteration 5600 (30.1723 iter/s, 3.3143s/100 iters), loss = 0.514
I1005 00:46:55.325597 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:46:55.325597 17516 solver.cpp:237]     Train net output #1: loss = 0.514 (* 1 = 0.514 loss)
I1005 00:46:55.325597 17516 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I1005 00:46:58.614606 17516 solver.cpp:218] Iteration 5700 (30.4075 iter/s, 3.28866s/100 iters), loss = 0.496566
I1005 00:46:58.614606 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:46:58.614606 17516 solver.cpp:237]     Train net output #1: loss = 0.496566 (* 1 = 0.496566 loss)
I1005 00:46:58.614606 17516 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I1005 00:47:01.888610 17516 solver.cpp:218] Iteration 5800 (30.5443 iter/s, 3.27394s/100 iters), loss = 0.51567
I1005 00:47:01.888610 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:47:01.888610 17516 solver.cpp:237]     Train net output #1: loss = 0.51567 (* 1 = 0.51567 loss)
I1005 00:47:01.888610 17516 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I1005 00:47:05.170454 17516 solver.cpp:218] Iteration 5900 (30.474 iter/s, 3.28148s/100 iters), loss = 0.414262
I1005 00:47:05.170454 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:47:05.170454 17516 solver.cpp:237]     Train net output #1: loss = 0.414262 (* 1 = 0.414262 loss)
I1005 00:47:05.170454 17516 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I1005 00:47:08.264613  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:47:08.397524 17516 solver.cpp:330] Iteration 6000, Testing net (#0)
I1005 00:47:08.397524 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:47:09.055470 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:47:09.071107 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7844
I1005 00:47:09.071107 17516 solver.cpp:397]     Test net output #1: loss = 0.61821 (* 1 = 0.61821 loss)
I1005 00:47:09.102347 17516 solver.cpp:218] Iteration 6000 (25.3655 iter/s, 3.94236s/100 iters), loss = 0.436055
I1005 00:47:09.102347 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:47:09.102347 17516 solver.cpp:237]     Train net output #1: loss = 0.436055 (* 1 = 0.436055 loss)
I1005 00:47:09.102347 17516 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I1005 00:47:12.380666 17516 solver.cpp:218] Iteration 6100 (30.5863 iter/s, 3.26944s/100 iters), loss = 0.421902
I1005 00:47:12.380666 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:47:12.380666 17516 solver.cpp:237]     Train net output #1: loss = 0.421902 (* 1 = 0.421902 loss)
I1005 00:47:12.380666 17516 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I1005 00:47:15.649217 17516 solver.cpp:218] Iteration 6200 (30.5247 iter/s, 3.27603s/100 iters), loss = 0.489542
I1005 00:47:15.649217 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:47:15.649217 17516 solver.cpp:237]     Train net output #1: loss = 0.489542 (* 1 = 0.489542 loss)
I1005 00:47:15.649217 17516 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I1005 00:47:18.934711 17516 solver.cpp:218] Iteration 6300 (30.5394 iter/s, 3.27446s/100 iters), loss = 0.569512
I1005 00:47:18.934711 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:47:18.934711 17516 solver.cpp:237]     Train net output #1: loss = 0.569512 (* 1 = 0.569512 loss)
I1005 00:47:18.934711 17516 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I1005 00:47:22.195024 17516 solver.cpp:218] Iteration 6400 (30.5619 iter/s, 3.27204s/100 iters), loss = 0.391661
I1005 00:47:22.195024 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:47:22.195024 17516 solver.cpp:237]     Train net output #1: loss = 0.391661 (* 1 = 0.391661 loss)
I1005 00:47:22.195024 17516 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I1005 00:47:25.319046  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:47:25.480463 17516 solver.cpp:218] Iteration 6500 (30.5558 iter/s, 3.2727s/100 iters), loss = 0.435208
I1005 00:47:25.480463 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:47:25.480463 17516 solver.cpp:237]     Train net output #1: loss = 0.435208 (* 1 = 0.435208 loss)
I1005 00:47:25.480463 17516 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I1005 00:47:28.754287 17516 solver.cpp:218] Iteration 6600 (30.5486 iter/s, 3.27347s/100 iters), loss = 0.455819
I1005 00:47:28.754287 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:47:28.754287 17516 solver.cpp:237]     Train net output #1: loss = 0.455819 (* 1 = 0.455819 loss)
I1005 00:47:28.754287 17516 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I1005 00:47:32.045657 17516 solver.cpp:218] Iteration 6700 (30.3854 iter/s, 3.29105s/100 iters), loss = 0.559704
I1005 00:47:32.045657 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:47:32.045657 17516 solver.cpp:237]     Train net output #1: loss = 0.559704 (* 1 = 0.559704 loss)
I1005 00:47:32.045657 17516 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I1005 00:47:35.361289 17516 solver.cpp:218] Iteration 6800 (30.161 iter/s, 3.31554s/100 iters), loss = 0.558185
I1005 00:47:35.361289 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:47:35.361289 17516 solver.cpp:237]     Train net output #1: loss = 0.558185 (* 1 = 0.558185 loss)
I1005 00:47:35.361289 17516 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I1005 00:47:38.663735 17516 solver.cpp:218] Iteration 6900 (30.2866 iter/s, 3.30179s/100 iters), loss = 0.362458
I1005 00:47:38.663735 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:47:38.663735 17516 solver.cpp:237]     Train net output #1: loss = 0.362458 (* 1 = 0.362458 loss)
I1005 00:47:38.663735 17516 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I1005 00:47:41.767480  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:47:41.908121 17516 solver.cpp:330] Iteration 7000, Testing net (#0)
I1005 00:47:41.908121 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:47:42.558651 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:47:42.574293 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7866
I1005 00:47:42.574293 17516 solver.cpp:397]     Test net output #1: loss = 0.612648 (* 1 = 0.612648 loss)
I1005 00:47:42.605527 17516 solver.cpp:218] Iteration 7000 (25.3012 iter/s, 3.95238s/100 iters), loss = 0.456683
I1005 00:47:42.605527 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:47:42.605527 17516 solver.cpp:237]     Train net output #1: loss = 0.456683 (* 1 = 0.456683 loss)
I1005 00:47:42.605527 17516 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I1005 00:47:45.891332 17516 solver.cpp:218] Iteration 7100 (30.5371 iter/s, 3.2747s/100 iters), loss = 0.437879
I1005 00:47:45.891332 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:47:45.891332 17516 solver.cpp:237]     Train net output #1: loss = 0.437879 (* 1 = 0.437879 loss)
I1005 00:47:45.891332 17516 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I1005 00:47:49.171193 17516 solver.cpp:218] Iteration 7200 (30.4278 iter/s, 3.28647s/100 iters), loss = 0.546282
I1005 00:47:49.171193 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:47:49.171193 17516 solver.cpp:237]     Train net output #1: loss = 0.546282 (* 1 = 0.546282 loss)
I1005 00:47:49.171193 17516 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I1005 00:47:52.446676 17516 solver.cpp:218] Iteration 7300 (30.5697 iter/s, 3.27122s/100 iters), loss = 0.497147
I1005 00:47:52.446676 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:47:52.446676 17516 solver.cpp:237]     Train net output #1: loss = 0.497147 (* 1 = 0.497147 loss)
I1005 00:47:52.446676 17516 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I1005 00:47:55.727983 17516 solver.cpp:218] Iteration 7400 (30.3972 iter/s, 3.28978s/100 iters), loss = 0.373423
I1005 00:47:55.727983 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:47:55.727983 17516 solver.cpp:237]     Train net output #1: loss = 0.373423 (* 1 = 0.373423 loss)
I1005 00:47:55.727983 17516 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I1005 00:47:58.841168  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:47:58.997400 17516 solver.cpp:218] Iteration 7500 (30.5634 iter/s, 3.27188s/100 iters), loss = 0.441148
I1005 00:47:58.997400 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:47:58.997400 17516 solver.cpp:237]     Train net output #1: loss = 0.441148 (* 1 = 0.441148 loss)
I1005 00:47:58.997400 17516 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I1005 00:48:02.271462 17516 solver.cpp:218] Iteration 7600 (30.5868 iter/s, 3.26938s/100 iters), loss = 0.413751
I1005 00:48:02.271462 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:48:02.271462 17516 solver.cpp:237]     Train net output #1: loss = 0.413751 (* 1 = 0.413751 loss)
I1005 00:48:02.271462 17516 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I1005 00:48:05.559680 17516 solver.cpp:218] Iteration 7700 (30.4762 iter/s, 3.28125s/100 iters), loss = 0.505029
I1005 00:48:05.559680 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:48:05.559680 17516 solver.cpp:237]     Train net output #1: loss = 0.505029 (* 1 = 0.505029 loss)
I1005 00:48:05.559680 17516 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I1005 00:48:08.818248 17516 solver.cpp:218] Iteration 7800 (30.6161 iter/s, 3.26626s/100 iters), loss = 0.490341
I1005 00:48:08.818248 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:48:08.818248 17516 solver.cpp:237]     Train net output #1: loss = 0.490341 (* 1 = 0.490341 loss)
I1005 00:48:08.818248 17516 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I1005 00:48:12.089293 17516 solver.cpp:218] Iteration 7900 (30.5802 iter/s, 3.27009s/100 iters), loss = 0.405976
I1005 00:48:12.089293 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:48:12.089293 17516 solver.cpp:237]     Train net output #1: loss = 0.405976 (* 1 = 0.405976 loss)
I1005 00:48:12.089293 17516 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I1005 00:48:15.264392  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:48:15.399411 17516 solver.cpp:330] Iteration 8000, Testing net (#0)
I1005 00:48:15.399411 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:48:16.061363 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:48:16.087374 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7857
I1005 00:48:16.087374 17516 solver.cpp:397]     Test net output #1: loss = 0.616731 (* 1 = 0.616731 loss)
I1005 00:48:16.119365 17516 solver.cpp:218] Iteration 8000 (24.8864 iter/s, 4.01826s/100 iters), loss = 0.415062
I1005 00:48:16.119365 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:48:16.119365 17516 solver.cpp:237]     Train net output #1: loss = 0.415062 (* 1 = 0.415062 loss)
I1005 00:48:16.119365 17516 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I1005 00:48:19.432226 17516 solver.cpp:218] Iteration 8100 (30.0949 iter/s, 3.32282s/100 iters), loss = 0.447524
I1005 00:48:19.432226 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:48:19.432226 17516 solver.cpp:237]     Train net output #1: loss = 0.447524 (* 1 = 0.447524 loss)
I1005 00:48:19.432226 17516 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I1005 00:48:22.721993 17516 solver.cpp:218] Iteration 8200 (30.4325 iter/s, 3.28596s/100 iters), loss = 0.460455
I1005 00:48:22.721993 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:48:22.721993 17516 solver.cpp:237]     Train net output #1: loss = 0.460455 (* 1 = 0.460455 loss)
I1005 00:48:22.721993 17516 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I1005 00:48:25.995796 17516 solver.cpp:218] Iteration 8300 (30.4728 iter/s, 3.28161s/100 iters), loss = 0.550387
I1005 00:48:25.995796 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:48:25.995796 17516 solver.cpp:237]     Train net output #1: loss = 0.550387 (* 1 = 0.550387 loss)
I1005 00:48:25.995796 17516 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I1005 00:48:29.309221 17516 solver.cpp:218] Iteration 8400 (30.2474 iter/s, 3.30607s/100 iters), loss = 0.40774
I1005 00:48:29.309221 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:48:29.309221 17516 solver.cpp:237]     Train net output #1: loss = 0.40774 (* 1 = 0.40774 loss)
I1005 00:48:29.309221 17516 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I1005 00:48:32.475661  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:48:32.642572 17516 solver.cpp:218] Iteration 8500 (30.0765 iter/s, 3.32485s/100 iters), loss = 0.433825
I1005 00:48:32.642572 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:48:32.642572 17516 solver.cpp:237]     Train net output #1: loss = 0.433825 (* 1 = 0.433825 loss)
I1005 00:48:32.642572 17516 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I1005 00:48:35.949334 17516 solver.cpp:218] Iteration 8600 (30.2076 iter/s, 3.31042s/100 iters), loss = 0.440173
I1005 00:48:35.949334 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:48:35.949334 17516 solver.cpp:237]     Train net output #1: loss = 0.440173 (* 1 = 0.440173 loss)
I1005 00:48:35.949334 17516 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I1005 00:48:39.209738 17516 solver.cpp:218] Iteration 8700 (30.6237 iter/s, 3.26544s/100 iters), loss = 0.525658
I1005 00:48:39.209738 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 00:48:39.209738 17516 solver.cpp:237]     Train net output #1: loss = 0.525658 (* 1 = 0.525658 loss)
I1005 00:48:39.209738 17516 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I1005 00:48:42.510999 17516 solver.cpp:218] Iteration 8800 (30.2422 iter/s, 3.30663s/100 iters), loss = 0.519004
I1005 00:48:42.526623 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:48:42.526623 17516 solver.cpp:237]     Train net output #1: loss = 0.519004 (* 1 = 0.519004 loss)
I1005 00:48:42.526623 17516 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I1005 00:48:45.812824 17516 solver.cpp:218] Iteration 8900 (30.353 iter/s, 3.29456s/100 iters), loss = 0.370048
I1005 00:48:45.812824 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:48:45.812824 17516 solver.cpp:237]     Train net output #1: loss = 0.370048 (* 1 = 0.370048 loss)
I1005 00:48:45.812824 17516 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I1005 00:48:48.942297  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:48:49.064898 17516 solver.cpp:330] Iteration 9000, Testing net (#0)
I1005 00:48:49.064898 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:48:49.714053 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:48:49.745298 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7898
I1005 00:48:49.745298 17516 solver.cpp:397]     Test net output #1: loss = 0.611971 (* 1 = 0.611971 loss)
I1005 00:48:49.776546 17516 solver.cpp:218] Iteration 9000 (25.2347 iter/s, 3.9628s/100 iters), loss = 0.439783
I1005 00:48:49.776546 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:48:49.776546 17516 solver.cpp:237]     Train net output #1: loss = 0.439783 (* 1 = 0.439783 loss)
I1005 00:48:49.776546 17516 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I1005 00:48:53.066200 17516 solver.cpp:218] Iteration 9100 (30.4162 iter/s, 3.28772s/100 iters), loss = 0.419325
I1005 00:48:53.066200 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:48:53.066200 17516 solver.cpp:237]     Train net output #1: loss = 0.419325 (* 1 = 0.419325 loss)
I1005 00:48:53.066200 17516 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I1005 00:48:56.354393 17516 solver.cpp:218] Iteration 9200 (30.4763 iter/s, 3.28124s/100 iters), loss = 0.433195
I1005 00:48:56.354393 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:48:56.354393 17516 solver.cpp:237]     Train net output #1: loss = 0.433195 (* 1 = 0.433195 loss)
I1005 00:48:56.354393 17516 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I1005 00:48:59.630918 17516 solver.cpp:218] Iteration 9300 (30.444 iter/s, 3.28472s/100 iters), loss = 0.501443
I1005 00:48:59.630918 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:48:59.630918 17516 solver.cpp:237]     Train net output #1: loss = 0.501443 (* 1 = 0.501443 loss)
I1005 00:48:59.630918 17516 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I1005 00:49:02.917300 17516 solver.cpp:218] Iteration 9400 (30.4807 iter/s, 3.28076s/100 iters), loss = 0.418849
I1005 00:49:02.917300 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:49:02.917300 17516 solver.cpp:237]     Train net output #1: loss = 0.418849 (* 1 = 0.418849 loss)
I1005 00:49:02.917300 17516 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I1005 00:49:06.032366  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:49:06.204241 17516 solver.cpp:218] Iteration 9500 (30.453 iter/s, 3.28375s/100 iters), loss = 0.403338
I1005 00:49:06.204241 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:49:06.204241 17516 solver.cpp:237]     Train net output #1: loss = 0.403338 (* 1 = 0.403338 loss)
I1005 00:49:06.204241 17516 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1005 00:49:09.489507 17516 solver.cpp:218] Iteration 9600 (30.4018 iter/s, 3.28928s/100 iters), loss = 0.362544
I1005 00:49:09.489507 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:49:09.489507 17516 solver.cpp:237]     Train net output #1: loss = 0.362544 (* 1 = 0.362544 loss)
I1005 00:49:09.489507 17516 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1005 00:49:12.774902 17516 solver.cpp:218] Iteration 9700 (30.4852 iter/s, 3.28028s/100 iters), loss = 0.466356
I1005 00:49:12.774902 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:49:12.774902 17516 solver.cpp:237]     Train net output #1: loss = 0.466356 (* 1 = 0.466356 loss)
I1005 00:49:12.774902 17516 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I1005 00:49:16.042232 17516 solver.cpp:218] Iteration 9800 (30.4716 iter/s, 3.28174s/100 iters), loss = 0.475687
I1005 00:49:16.042232 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:49:16.042232 17516 solver.cpp:237]     Train net output #1: loss = 0.475687 (* 1 = 0.475687 loss)
I1005 00:49:16.042232 17516 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1005 00:49:19.335736 17516 solver.cpp:218] Iteration 9900 (30.5029 iter/s, 3.27837s/100 iters), loss = 0.350763
I1005 00:49:19.335736 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:49:19.335736 17516 solver.cpp:237]     Train net output #1: loss = 0.350763 (* 1 = 0.350763 loss)
I1005 00:49:19.335736 17516 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I1005 00:49:22.459579  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:49:22.584594 17516 solver.cpp:330] Iteration 10000, Testing net (#0)
I1005 00:49:22.584594 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:49:23.253914 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:49:23.285164 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7912
I1005 00:49:23.285164 17516 solver.cpp:397]     Test net output #1: loss = 0.60914 (* 1 = 0.60914 loss)
I1005 00:49:23.322800 17516 solver.cpp:218] Iteration 10000 (25.082 iter/s, 3.98693s/100 iters), loss = 0.394069
I1005 00:49:23.322800 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:49:23.322800 17516 solver.cpp:237]     Train net output #1: loss = 0.394069 (* 1 = 0.394069 loss)
I1005 00:49:23.322800 17516 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I1005 00:49:23.322800 17516 sgd_solver.cpp:105] Iteration 10000, lr = 0.0001
I1005 00:49:26.666050 17516 solver.cpp:218] Iteration 10100 (29.9059 iter/s, 3.34383s/100 iters), loss = 0.425714
I1005 00:49:26.666050 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:49:26.666050 17516 solver.cpp:237]     Train net output #1: loss = 0.425714 (* 1 = 0.425714 loss)
I1005 00:49:26.666050 17516 sgd_solver.cpp:105] Iteration 10100, lr = 0.0001
I1005 00:49:29.997962 17516 solver.cpp:218] Iteration 10200 (29.9939 iter/s, 3.33401s/100 iters), loss = 0.44586
I1005 00:49:29.997962 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:49:29.997962 17516 solver.cpp:237]     Train net output #1: loss = 0.44586 (* 1 = 0.44586 loss)
I1005 00:49:29.997962 17516 sgd_solver.cpp:105] Iteration 10200, lr = 0.0001
I1005 00:49:33.266659 17516 solver.cpp:218] Iteration 10300 (30.5189 iter/s, 3.27665s/100 iters), loss = 0.526407
I1005 00:49:33.266659 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 00:49:33.266659 17516 solver.cpp:237]     Train net output #1: loss = 0.526407 (* 1 = 0.526407 loss)
I1005 00:49:33.266659 17516 sgd_solver.cpp:105] Iteration 10300, lr = 0.0001
I1005 00:49:36.542558 17516 solver.cpp:218] Iteration 10400 (30.5205 iter/s, 3.27649s/100 iters), loss = 0.379371
I1005 00:49:36.542558 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:49:36.542558 17516 solver.cpp:237]     Train net output #1: loss = 0.379371 (* 1 = 0.379371 loss)
I1005 00:49:36.542558 17516 sgd_solver.cpp:105] Iteration 10400, lr = 0.0001
I1005 00:49:39.668854  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:49:39.837357 17516 solver.cpp:218] Iteration 10500 (30.4729 iter/s, 3.2816s/100 iters), loss = 0.407153
I1005 00:49:39.837357 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:49:39.837357 17516 solver.cpp:237]     Train net output #1: loss = 0.407153 (* 1 = 0.407153 loss)
I1005 00:49:39.837357 17516 sgd_solver.cpp:105] Iteration 10500, lr = 0.0001
I1005 00:49:43.109472 17516 solver.cpp:218] Iteration 10600 (30.5392 iter/s, 3.27448s/100 iters), loss = 0.3706
I1005 00:49:43.109472 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:49:43.109472 17516 solver.cpp:237]     Train net output #1: loss = 0.3706 (* 1 = 0.3706 loss)
I1005 00:49:43.109472 17516 sgd_solver.cpp:105] Iteration 10600, lr = 0.0001
I1005 00:49:46.382640 17516 solver.cpp:218] Iteration 10700 (30.5235 iter/s, 3.27616s/100 iters), loss = 0.413834
I1005 00:49:46.382640 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:49:46.382640 17516 solver.cpp:237]     Train net output #1: loss = 0.413834 (* 1 = 0.413834 loss)
I1005 00:49:46.382640 17516 sgd_solver.cpp:105] Iteration 10700, lr = 0.0001
I1005 00:49:49.653424 17516 solver.cpp:218] Iteration 10800 (30.5155 iter/s, 3.27702s/100 iters), loss = 0.471885
I1005 00:49:49.653424 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:49:49.653424 17516 solver.cpp:237]     Train net output #1: loss = 0.471885 (* 1 = 0.471885 loss)
I1005 00:49:49.653424 17516 sgd_solver.cpp:105] Iteration 10800, lr = 0.0001
I1005 00:49:52.924604 17516 solver.cpp:218] Iteration 10900 (30.5909 iter/s, 3.26894s/100 iters), loss = 0.392867
I1005 00:49:52.924604 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:49:52.924604 17516 solver.cpp:237]     Train net output #1: loss = 0.392867 (* 1 = 0.392867 loss)
I1005 00:49:52.924604 17516 sgd_solver.cpp:105] Iteration 10900, lr = 0.0001
I1005 00:49:56.043920  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:49:56.184535 17516 solver.cpp:330] Iteration 11000, Testing net (#0)
I1005 00:49:56.184535 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:49:56.823329 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:49:56.854581 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7928
I1005 00:49:56.854581 17516 solver.cpp:397]     Test net output #1: loss = 0.603397 (* 1 = 0.603397 loss)
I1005 00:49:56.885841 17516 solver.cpp:218] Iteration 11000 (25.2673 iter/s, 3.95769s/100 iters), loss = 0.390438
I1005 00:49:56.885841 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:49:56.885841 17516 solver.cpp:237]     Train net output #1: loss = 0.390438 (* 1 = 0.390438 loss)
I1005 00:49:56.885841 17516 sgd_solver.cpp:105] Iteration 11000, lr = 0.0001
I1005 00:50:00.158707 17516 solver.cpp:218] Iteration 11100 (30.5364 iter/s, 3.27478s/100 iters), loss = 0.455811
I1005 00:50:00.158707 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:50:00.158707 17516 solver.cpp:237]     Train net output #1: loss = 0.455811 (* 1 = 0.455811 loss)
I1005 00:50:00.158707 17516 sgd_solver.cpp:105] Iteration 11100, lr = 0.0001
I1005 00:50:03.470753 17516 solver.cpp:218] Iteration 11200 (30.2692 iter/s, 3.30368s/100 iters), loss = 0.457648
I1005 00:50:03.470753 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:50:03.470753 17516 solver.cpp:237]     Train net output #1: loss = 0.457648 (* 1 = 0.457648 loss)
I1005 00:50:03.470753 17516 sgd_solver.cpp:105] Iteration 11200, lr = 0.0001
I1005 00:50:06.753000 17516 solver.cpp:218] Iteration 11300 (30.4783 iter/s, 3.28103s/100 iters), loss = 0.473074
I1005 00:50:06.753000 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:50:06.753000 17516 solver.cpp:237]     Train net output #1: loss = 0.473074 (* 1 = 0.473074 loss)
I1005 00:50:06.753000 17516 sgd_solver.cpp:105] Iteration 11300, lr = 0.0001
I1005 00:50:10.028861 17516 solver.cpp:218] Iteration 11400 (30.5269 iter/s, 3.2758s/100 iters), loss = 0.370748
I1005 00:50:10.028861 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:50:10.028861 17516 solver.cpp:237]     Train net output #1: loss = 0.370748 (* 1 = 0.370748 loss)
I1005 00:50:10.028861 17516 sgd_solver.cpp:105] Iteration 11400, lr = 0.0001
I1005 00:50:13.129148  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:50:13.301036 17516 solver.cpp:218] Iteration 11500 (30.561 iter/s, 3.27214s/100 iters), loss = 0.359485
I1005 00:50:13.301036 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:50:13.301036 17516 solver.cpp:237]     Train net output #1: loss = 0.359485 (* 1 = 0.359485 loss)
I1005 00:50:13.301036 17516 sgd_solver.cpp:105] Iteration 11500, lr = 0.0001
I1005 00:50:16.565220 17516 solver.cpp:218] Iteration 11600 (30.5845 iter/s, 3.26963s/100 iters), loss = 0.401349
I1005 00:50:16.565220 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:50:16.565220 17516 solver.cpp:237]     Train net output #1: loss = 0.401349 (* 1 = 0.401349 loss)
I1005 00:50:16.565220 17516 sgd_solver.cpp:105] Iteration 11600, lr = 0.0001
I1005 00:50:19.834277 17516 solver.cpp:218] Iteration 11700 (30.5651 iter/s, 3.27171s/100 iters), loss = 0.440064
I1005 00:50:19.834277 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:50:19.834277 17516 solver.cpp:237]     Train net output #1: loss = 0.440064 (* 1 = 0.440064 loss)
I1005 00:50:19.834277 17516 sgd_solver.cpp:105] Iteration 11700, lr = 0.0001
I1005 00:50:23.112136 17516 solver.cpp:218] Iteration 11800 (30.5766 iter/s, 3.27047s/100 iters), loss = 0.523763
I1005 00:50:23.112136 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:50:23.112136 17516 solver.cpp:237]     Train net output #1: loss = 0.523763 (* 1 = 0.523763 loss)
I1005 00:50:23.112136 17516 sgd_solver.cpp:105] Iteration 11800, lr = 0.0001
I1005 00:50:26.389457 17516 solver.cpp:218] Iteration 11900 (30.5385 iter/s, 3.27456s/100 iters), loss = 0.370537
I1005 00:50:26.389457 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:50:26.389457 17516 solver.cpp:237]     Train net output #1: loss = 0.370537 (* 1 = 0.370537 loss)
I1005 00:50:26.389457 17516 sgd_solver.cpp:105] Iteration 11900, lr = 0.0001
I1005 00:50:29.503289  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:50:29.628304 17516 solver.cpp:330] Iteration 12000, Testing net (#0)
I1005 00:50:29.628304 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:50:30.268929 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:50:30.300174 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7927
I1005 00:50:30.300174 17516 solver.cpp:397]     Test net output #1: loss = 0.603189 (* 1 = 0.603189 loss)
I1005 00:50:30.331429 17516 solver.cpp:218] Iteration 12000 (25.3228 iter/s, 3.94902s/100 iters), loss = 0.394672
I1005 00:50:30.331429 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:50:30.331429 17516 solver.cpp:237]     Train net output #1: loss = 0.394672 (* 1 = 0.394672 loss)
I1005 00:50:30.331429 17516 sgd_solver.cpp:105] Iteration 12000, lr = 0.0001
I1005 00:50:33.603996 17516 solver.cpp:218] Iteration 12100 (30.5692 iter/s, 3.27127s/100 iters), loss = 0.433776
I1005 00:50:33.603996 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:50:33.603996 17516 solver.cpp:237]     Train net output #1: loss = 0.433776 (* 1 = 0.433776 loss)
I1005 00:50:33.603996 17516 sgd_solver.cpp:105] Iteration 12100, lr = 0.0001
I1005 00:50:36.879374 17516 solver.cpp:218] Iteration 12200 (30.6043 iter/s, 3.26752s/100 iters), loss = 0.470168
I1005 00:50:36.879374 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:50:36.879374 17516 solver.cpp:237]     Train net output #1: loss = 0.470168 (* 1 = 0.470168 loss)
I1005 00:50:36.879374 17516 sgd_solver.cpp:105] Iteration 12200, lr = 0.0001
I1005 00:50:40.144096 17516 solver.cpp:218] Iteration 12300 (30.5269 iter/s, 3.2758s/100 iters), loss = 0.420376
I1005 00:50:40.144096 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:50:40.144096 17516 solver.cpp:237]     Train net output #1: loss = 0.420376 (* 1 = 0.420376 loss)
I1005 00:50:40.144096 17516 sgd_solver.cpp:105] Iteration 12300, lr = 0.0001
I1005 00:50:43.425276 17516 solver.cpp:218] Iteration 12400 (30.5775 iter/s, 3.27038s/100 iters), loss = 0.383472
I1005 00:50:43.425276 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:50:43.425276 17516 solver.cpp:237]     Train net output #1: loss = 0.383472 (* 1 = 0.383472 loss)
I1005 00:50:43.425276 17516 sgd_solver.cpp:105] Iteration 12400, lr = 0.0001
I1005 00:50:46.530342  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:50:46.686594 17516 solver.cpp:218] Iteration 12500 (30.5699 iter/s, 3.27119s/100 iters), loss = 0.363334
I1005 00:50:46.686594 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:50:46.686594 17516 solver.cpp:237]     Train net output #1: loss = 0.363334 (* 1 = 0.363334 loss)
I1005 00:50:46.686594 17516 sgd_solver.cpp:105] Iteration 12500, lr = 0.0001
I1005 00:50:49.954578 17516 solver.cpp:218] Iteration 12600 (30.5976 iter/s, 3.26823s/100 iters), loss = 0.415977
I1005 00:50:49.954578 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:50:49.954578 17516 solver.cpp:237]     Train net output #1: loss = 0.415977 (* 1 = 0.415977 loss)
I1005 00:50:49.954578 17516 sgd_solver.cpp:105] Iteration 12600, lr = 0.0001
I1005 00:50:53.238024 17516 solver.cpp:218] Iteration 12700 (30.5714 iter/s, 3.27103s/100 iters), loss = 0.410871
I1005 00:50:53.238024 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:50:53.238024 17516 solver.cpp:237]     Train net output #1: loss = 0.410871 (* 1 = 0.410871 loss)
I1005 00:50:53.238024 17516 sgd_solver.cpp:105] Iteration 12700, lr = 0.0001
I1005 00:50:56.504029 17516 solver.cpp:218] Iteration 12800 (30.5933 iter/s, 3.26869s/100 iters), loss = 0.503012
I1005 00:50:56.504029 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:50:56.504029 17516 solver.cpp:237]     Train net output #1: loss = 0.503012 (* 1 = 0.503012 loss)
I1005 00:50:56.504029 17516 sgd_solver.cpp:105] Iteration 12800, lr = 0.0001
I1005 00:50:59.767251 17516 solver.cpp:218] Iteration 12900 (30.5466 iter/s, 3.27369s/100 iters), loss = 0.39876
I1005 00:50:59.767251 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:50:59.767251 17516 solver.cpp:237]     Train net output #1: loss = 0.39876 (* 1 = 0.39876 loss)
I1005 00:50:59.767251 17516 sgd_solver.cpp:105] Iteration 12900, lr = 0.0001
I1005 00:51:02.880328  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:51:03.005316 17516 solver.cpp:330] Iteration 13000, Testing net (#0)
I1005 00:51:03.005316 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:51:03.663430 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:51:03.694691 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7927
I1005 00:51:03.694691 17516 solver.cpp:397]     Test net output #1: loss = 0.602989 (* 1 = 0.602989 loss)
I1005 00:51:03.726426 17516 solver.cpp:218] Iteration 13000 (25.348 iter/s, 3.94508s/100 iters), loss = 0.400166
I1005 00:51:03.726426 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:51:03.726426 17516 solver.cpp:237]     Train net output #1: loss = 0.400166 (* 1 = 0.400166 loss)
I1005 00:51:03.726426 17516 sgd_solver.cpp:105] Iteration 13000, lr = 0.0001
I1005 00:51:06.993829 17516 solver.cpp:218] Iteration 13100 (30.5752 iter/s, 3.27063s/100 iters), loss = 0.432442
I1005 00:51:06.993829 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:51:06.993829 17516 solver.cpp:237]     Train net output #1: loss = 0.432442 (* 1 = 0.432442 loss)
I1005 00:51:06.993829 17516 sgd_solver.cpp:105] Iteration 13100, lr = 0.0001
I1005 00:51:10.260978 17516 solver.cpp:218] Iteration 13200 (30.5735 iter/s, 3.2708s/100 iters), loss = 0.429556
I1005 00:51:10.260978 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:51:10.260978 17516 solver.cpp:237]     Train net output #1: loss = 0.429556 (* 1 = 0.429556 loss)
I1005 00:51:10.260978 17516 sgd_solver.cpp:105] Iteration 13200, lr = 0.0001
I1005 00:51:13.530885 17516 solver.cpp:218] Iteration 13300 (30.6008 iter/s, 3.26788s/100 iters), loss = 0.509123
I1005 00:51:13.530885 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:51:13.530885 17516 solver.cpp:237]     Train net output #1: loss = 0.509123 (* 1 = 0.509123 loss)
I1005 00:51:13.530885 17516 sgd_solver.cpp:105] Iteration 13300, lr = 0.0001
I1005 00:51:16.811695 17516 solver.cpp:218] Iteration 13400 (30.5092 iter/s, 3.2777s/100 iters), loss = 0.386184
I1005 00:51:16.811695 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:51:16.811695 17516 solver.cpp:237]     Train net output #1: loss = 0.386184 (* 1 = 0.386184 loss)
I1005 00:51:16.811695 17516 sgd_solver.cpp:105] Iteration 13400, lr = 0.0001
I1005 00:51:19.914954  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:51:20.071190 17516 solver.cpp:218] Iteration 13500 (30.5766 iter/s, 3.27047s/100 iters), loss = 0.406517
I1005 00:51:20.071190 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:51:20.071190 17516 solver.cpp:237]     Train net output #1: loss = 0.406517 (* 1 = 0.406517 loss)
I1005 00:51:20.071190 17516 sgd_solver.cpp:105] Iteration 13500, lr = 0.0001
I1005 00:51:23.356261 17516 solver.cpp:218] Iteration 13600 (30.5674 iter/s, 3.27145s/100 iters), loss = 0.358407
I1005 00:51:23.356261 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:51:23.356261 17516 solver.cpp:237]     Train net output #1: loss = 0.358407 (* 1 = 0.358407 loss)
I1005 00:51:23.356261 17516 sgd_solver.cpp:105] Iteration 13600, lr = 0.0001
I1005 00:51:26.621883 17516 solver.cpp:218] Iteration 13700 (30.5937 iter/s, 3.26865s/100 iters), loss = 0.42018
I1005 00:51:26.621883 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:51:26.621883 17516 solver.cpp:237]     Train net output #1: loss = 0.42018 (* 1 = 0.42018 loss)
I1005 00:51:26.621883 17516 sgd_solver.cpp:105] Iteration 13700, lr = 0.0001
I1005 00:51:29.891402 17516 solver.cpp:218] Iteration 13800 (30.517 iter/s, 3.27686s/100 iters), loss = 0.477325
I1005 00:51:29.891402 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:51:29.891402 17516 solver.cpp:237]     Train net output #1: loss = 0.477325 (* 1 = 0.477325 loss)
I1005 00:51:29.891402 17516 sgd_solver.cpp:105] Iteration 13800, lr = 0.0001
I1005 00:51:33.153976 17516 solver.cpp:218] Iteration 13900 (30.6272 iter/s, 3.26507s/100 iters), loss = 0.376733
I1005 00:51:33.153976 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:51:33.153976 17516 solver.cpp:237]     Train net output #1: loss = 0.376733 (* 1 = 0.376733 loss)
I1005 00:51:33.153976 17516 sgd_solver.cpp:105] Iteration 13900, lr = 0.0001
I1005 00:51:36.263306  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:51:36.397492 17516 solver.cpp:330] Iteration 14000, Testing net (#0)
I1005 00:51:36.397492 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:51:37.052731 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:51:37.087103 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7925
I1005 00:51:37.087103 17516 solver.cpp:397]     Test net output #1: loss = 0.603029 (* 1 = 0.603029 loss)
I1005 00:51:37.108911 17516 solver.cpp:218] Iteration 14000 (25.329 iter/s, 3.94805s/100 iters), loss = 0.378786
I1005 00:51:37.108911 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:51:37.108911 17516 solver.cpp:237]     Train net output #1: loss = 0.378786 (* 1 = 0.378786 loss)
I1005 00:51:37.108911 17516 sgd_solver.cpp:105] Iteration 14000, lr = 0.0001
I1005 00:51:40.395870 17516 solver.cpp:218] Iteration 14100 (30.5045 iter/s, 3.2782s/100 iters), loss = 0.385969
I1005 00:51:40.395870 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:51:40.395870 17516 solver.cpp:237]     Train net output #1: loss = 0.385969 (* 1 = 0.385969 loss)
I1005 00:51:40.395870 17516 sgd_solver.cpp:105] Iteration 14100, lr = 0.0001
I1005 00:51:43.656954 17516 solver.cpp:218] Iteration 14200 (30.5986 iter/s, 3.26813s/100 iters), loss = 0.475579
I1005 00:51:43.656954 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:51:43.656954 17516 solver.cpp:237]     Train net output #1: loss = 0.475579 (* 1 = 0.475579 loss)
I1005 00:51:43.656954 17516 sgd_solver.cpp:105] Iteration 14200, lr = 0.0001
I1005 00:51:46.929677 17516 solver.cpp:218] Iteration 14300 (30.5377 iter/s, 3.27464s/100 iters), loss = 0.476037
I1005 00:51:46.929677 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:51:46.929677 17516 solver.cpp:237]     Train net output #1: loss = 0.476037 (* 1 = 0.476037 loss)
I1005 00:51:46.929677 17516 sgd_solver.cpp:105] Iteration 14300, lr = 0.0001
I1005 00:51:50.208061 17516 solver.cpp:218] Iteration 14400 (30.5437 iter/s, 3.274s/100 iters), loss = 0.347021
I1005 00:51:50.208061 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:51:50.208061 17516 solver.cpp:237]     Train net output #1: loss = 0.347021 (* 1 = 0.347021 loss)
I1005 00:51:50.208061 17516 sgd_solver.cpp:105] Iteration 14400, lr = 0.0001
I1005 00:51:53.327492  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:51:53.486778 17516 solver.cpp:218] Iteration 14500 (30.5376 iter/s, 3.27465s/100 iters), loss = 0.369779
I1005 00:51:53.486778 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:51:53.486778 17516 solver.cpp:237]     Train net output #1: loss = 0.369779 (* 1 = 0.369779 loss)
I1005 00:51:53.486778 17516 sgd_solver.cpp:105] Iteration 14500, lr = 0.0001
I1005 00:51:56.756649 17516 solver.cpp:218] Iteration 14600 (30.5673 iter/s, 3.27146s/100 iters), loss = 0.416861
I1005 00:51:56.756649 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:51:56.756649 17516 solver.cpp:237]     Train net output #1: loss = 0.416861 (* 1 = 0.416861 loss)
I1005 00:51:56.756649 17516 sgd_solver.cpp:105] Iteration 14600, lr = 0.0001
I1005 00:52:00.020071 17516 solver.cpp:218] Iteration 14700 (30.5892 iter/s, 3.26913s/100 iters), loss = 0.426143
I1005 00:52:00.020071 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:52:00.020071 17516 solver.cpp:237]     Train net output #1: loss = 0.426143 (* 1 = 0.426143 loss)
I1005 00:52:00.020071 17516 sgd_solver.cpp:105] Iteration 14700, lr = 0.0001
I1005 00:52:03.288807 17516 solver.cpp:218] Iteration 14800 (30.5631 iter/s, 3.27192s/100 iters), loss = 0.484039
I1005 00:52:03.288807 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 00:52:03.288807 17516 solver.cpp:237]     Train net output #1: loss = 0.484039 (* 1 = 0.484039 loss)
I1005 00:52:03.288807 17516 sgd_solver.cpp:105] Iteration 14800, lr = 0.0001
I1005 00:52:06.566926 17516 solver.cpp:218] Iteration 14900 (30.6036 iter/s, 3.26759s/100 iters), loss = 0.35425
I1005 00:52:06.566926 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:52:06.566926 17516 solver.cpp:237]     Train net output #1: loss = 0.35425 (* 1 = 0.35425 loss)
I1005 00:52:06.566926 17516 sgd_solver.cpp:105] Iteration 14900, lr = 0.0001
I1005 00:52:09.668860  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:52:09.811017 17516 solver.cpp:330] Iteration 15000, Testing net (#0)
I1005 00:52:09.811017 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:52:10.458149 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:52:10.489409 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7932
I1005 00:52:10.489409 17516 solver.cpp:397]     Test net output #1: loss = 0.603563 (* 1 = 0.603563 loss)
I1005 00:52:10.520666 17516 solver.cpp:218] Iteration 15000 (25.3138 iter/s, 3.95041s/100 iters), loss = 0.386698
I1005 00:52:10.520666 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:52:10.520666 17516 solver.cpp:237]     Train net output #1: loss = 0.386698 (* 1 = 0.386698 loss)
I1005 00:52:10.520666 17516 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I1005 00:52:10.520666 17516 sgd_solver.cpp:105] Iteration 15000, lr = 1e-05
I1005 00:52:13.780458 17516 solver.cpp:218] Iteration 15100 (30.5774 iter/s, 3.27039s/100 iters), loss = 0.410783
I1005 00:52:13.780458 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:52:13.780458 17516 solver.cpp:237]     Train net output #1: loss = 0.410783 (* 1 = 0.410783 loss)
I1005 00:52:13.780458 17516 sgd_solver.cpp:105] Iteration 15100, lr = 1e-05
I1005 00:52:17.062070 17516 solver.cpp:218] Iteration 15200 (30.5478 iter/s, 3.27356s/100 iters), loss = 0.420043
I1005 00:52:17.062070 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:52:17.062070 17516 solver.cpp:237]     Train net output #1: loss = 0.420043 (* 1 = 0.420043 loss)
I1005 00:52:17.062070 17516 sgd_solver.cpp:105] Iteration 15200, lr = 1e-05
I1005 00:52:20.335695 17516 solver.cpp:218] Iteration 15300 (30.5849 iter/s, 3.26959s/100 iters), loss = 0.449376
I1005 00:52:20.335695 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:52:20.335695 17516 solver.cpp:237]     Train net output #1: loss = 0.449376 (* 1 = 0.449376 loss)
I1005 00:52:20.335695 17516 sgd_solver.cpp:105] Iteration 15300, lr = 1e-05
I1005 00:52:23.599570 17516 solver.cpp:218] Iteration 15400 (30.5746 iter/s, 3.27069s/100 iters), loss = 0.354635
I1005 00:52:23.599570 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:52:23.599570 17516 solver.cpp:237]     Train net output #1: loss = 0.354635 (* 1 = 0.354635 loss)
I1005 00:52:23.599570 17516 sgd_solver.cpp:105] Iteration 15400, lr = 1e-05
I1005 00:52:26.701428  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:52:26.874716 17516 solver.cpp:218] Iteration 15500 (30.5999 iter/s, 3.26798s/100 iters), loss = 0.381394
I1005 00:52:26.874716 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:52:26.874716 17516 solver.cpp:237]     Train net output #1: loss = 0.381394 (* 1 = 0.381394 loss)
I1005 00:52:26.874716 17516 sgd_solver.cpp:105] Iteration 15500, lr = 1e-05
I1005 00:52:30.142218 17516 solver.cpp:218] Iteration 15600 (30.5454 iter/s, 3.27381s/100 iters), loss = 0.398575
I1005 00:52:30.142218 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:52:30.142218 17516 solver.cpp:237]     Train net output #1: loss = 0.398575 (* 1 = 0.398575 loss)
I1005 00:52:30.142218 17516 sgd_solver.cpp:105] Iteration 15600, lr = 1e-05
I1005 00:52:33.425017 17516 solver.cpp:218] Iteration 15700 (30.5303 iter/s, 3.27543s/100 iters), loss = 0.452217
I1005 00:52:33.425017 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:52:33.425017 17516 solver.cpp:237]     Train net output #1: loss = 0.452217 (* 1 = 0.452217 loss)
I1005 00:52:33.425017 17516 sgd_solver.cpp:105] Iteration 15700, lr = 1e-05
I1005 00:52:36.692080 17516 solver.cpp:218] Iteration 15800 (30.5529 iter/s, 3.27301s/100 iters), loss = 0.526254
I1005 00:52:36.692080 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:52:36.692080 17516 solver.cpp:237]     Train net output #1: loss = 0.526254 (* 1 = 0.526254 loss)
I1005 00:52:36.692080 17516 sgd_solver.cpp:105] Iteration 15800, lr = 1e-05
I1005 00:52:39.966079 17516 solver.cpp:218] Iteration 15900 (30.5864 iter/s, 3.26942s/100 iters), loss = 0.329086
I1005 00:52:39.966079 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:52:39.966079 17516 solver.cpp:237]     Train net output #1: loss = 0.329086 (* 1 = 0.329086 loss)
I1005 00:52:39.966079 17516 sgd_solver.cpp:105] Iteration 15900, lr = 1e-05
I1005 00:52:43.077208  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:52:43.202208 17516 solver.cpp:330] Iteration 16000, Testing net (#0)
I1005 00:52:43.202208 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:52:43.858454 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:52:43.889703 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7927
I1005 00:52:43.889703 17516 solver.cpp:397]     Test net output #1: loss = 0.60337 (* 1 = 0.60337 loss)
I1005 00:52:43.905318 17516 solver.cpp:218] Iteration 16000 (25.3089 iter/s, 3.95118s/100 iters), loss = 0.345969
I1005 00:52:43.905318 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:52:43.905318 17516 solver.cpp:237]     Train net output #1: loss = 0.345969 (* 1 = 0.345969 loss)
I1005 00:52:43.905318 17516 sgd_solver.cpp:105] Iteration 16000, lr = 1e-05
I1005 00:52:47.179407 17516 solver.cpp:218] Iteration 16100 (30.5958 iter/s, 3.26842s/100 iters), loss = 0.355522
I1005 00:52:47.179407 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:52:47.179407 17516 solver.cpp:237]     Train net output #1: loss = 0.355522 (* 1 = 0.355522 loss)
I1005 00:52:47.179407 17516 sgd_solver.cpp:105] Iteration 16100, lr = 1e-05
I1005 00:52:50.441565 17516 solver.cpp:218] Iteration 16200 (30.6055 iter/s, 3.26738s/100 iters), loss = 0.456068
I1005 00:52:50.441565 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:52:50.441565 17516 solver.cpp:237]     Train net output #1: loss = 0.456068 (* 1 = 0.456068 loss)
I1005 00:52:50.441565 17516 sgd_solver.cpp:105] Iteration 16200, lr = 1e-05
I1005 00:52:53.715535 17516 solver.cpp:218] Iteration 16300 (30.625 iter/s, 3.2653s/100 iters), loss = 0.457783
I1005 00:52:53.715535 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:52:53.715535 17516 solver.cpp:237]     Train net output #1: loss = 0.457783 (* 1 = 0.457783 loss)
I1005 00:52:53.715535 17516 sgd_solver.cpp:105] Iteration 16300, lr = 1e-05
I1005 00:52:56.974153 17516 solver.cpp:218] Iteration 16400 (30.6121 iter/s, 3.26669s/100 iters), loss = 0.370029
I1005 00:52:56.974153 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:52:56.974153 17516 solver.cpp:237]     Train net output #1: loss = 0.370029 (* 1 = 0.370029 loss)
I1005 00:52:56.974153 17516 sgd_solver.cpp:105] Iteration 16400, lr = 1e-05
I1005 00:53:00.082492  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:53:00.254367 17516 solver.cpp:218] Iteration 16500 (30.6275 iter/s, 3.26504s/100 iters), loss = 0.346217
I1005 00:53:00.254367 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:53:00.254367 17516 solver.cpp:237]     Train net output #1: loss = 0.346217 (* 1 = 0.346217 loss)
I1005 00:53:00.254367 17516 sgd_solver.cpp:105] Iteration 16500, lr = 1e-05
I1005 00:53:03.520202 17516 solver.cpp:218] Iteration 16600 (30.5821 iter/s, 3.26989s/100 iters), loss = 0.419321
I1005 00:53:03.520202 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:53:03.520202 17516 solver.cpp:237]     Train net output #1: loss = 0.419321 (* 1 = 0.419321 loss)
I1005 00:53:03.520202 17516 sgd_solver.cpp:105] Iteration 16600, lr = 1e-05
I1005 00:53:06.780169 17516 solver.cpp:218] Iteration 16700 (30.5966 iter/s, 3.26833s/100 iters), loss = 0.401172
I1005 00:53:06.780169 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:53:06.780169 17516 solver.cpp:237]     Train net output #1: loss = 0.401172 (* 1 = 0.401172 loss)
I1005 00:53:06.780169 17516 sgd_solver.cpp:105] Iteration 16700, lr = 1e-05
I1005 00:53:10.060454 17516 solver.cpp:218] Iteration 16800 (30.5723 iter/s, 3.27094s/100 iters), loss = 0.457107
I1005 00:53:10.060454 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:53:10.060454 17516 solver.cpp:237]     Train net output #1: loss = 0.457107 (* 1 = 0.457107 loss)
I1005 00:53:10.060454 17516 sgd_solver.cpp:105] Iteration 16800, lr = 1e-05
I1005 00:53:13.330173 17516 solver.cpp:218] Iteration 16900 (30.5825 iter/s, 3.26984s/100 iters), loss = 0.372608
I1005 00:53:13.330173 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:53:13.330173 17516 solver.cpp:237]     Train net output #1: loss = 0.372608 (* 1 = 0.372608 loss)
I1005 00:53:13.330173 17516 sgd_solver.cpp:105] Iteration 16900, lr = 1e-05
I1005 00:53:16.431851  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:53:16.556851 17516 solver.cpp:330] Iteration 17000, Testing net (#0)
I1005 00:53:16.556851 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:53:17.210944 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:53:17.242184 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7923
I1005 00:53:17.242184 17516 solver.cpp:397]     Test net output #1: loss = 0.603214 (* 1 = 0.603214 loss)
I1005 00:53:17.273447 17516 solver.cpp:218] Iteration 17000 (25.3521 iter/s, 3.94445s/100 iters), loss = 0.361703
I1005 00:53:17.273447 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:53:17.273447 17516 solver.cpp:237]     Train net output #1: loss = 0.361703 (* 1 = 0.361703 loss)
I1005 00:53:17.273447 17516 sgd_solver.cpp:105] Iteration 17000, lr = 1e-05
I1005 00:53:20.541816 17516 solver.cpp:218] Iteration 17100 (30.5894 iter/s, 3.2691s/100 iters), loss = 0.411757
I1005 00:53:20.541816 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:53:20.541816 17516 solver.cpp:237]     Train net output #1: loss = 0.411757 (* 1 = 0.411757 loss)
I1005 00:53:20.541816 17516 sgd_solver.cpp:105] Iteration 17100, lr = 1e-05
I1005 00:53:23.812938 17516 solver.cpp:218] Iteration 17200 (30.5564 iter/s, 3.27264s/100 iters), loss = 0.442923
I1005 00:53:23.812938 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:53:23.812938 17516 solver.cpp:237]     Train net output #1: loss = 0.442923 (* 1 = 0.442923 loss)
I1005 00:53:23.812938 17516 sgd_solver.cpp:105] Iteration 17200, lr = 1e-05
I1005 00:53:27.081230 17516 solver.cpp:218] Iteration 17300 (30.5666 iter/s, 3.27155s/100 iters), loss = 0.436998
I1005 00:53:27.081230 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:53:27.081230 17516 solver.cpp:237]     Train net output #1: loss = 0.436998 (* 1 = 0.436998 loss)
I1005 00:53:27.081230 17516 sgd_solver.cpp:105] Iteration 17300, lr = 1e-05
I1005 00:53:30.359464 17516 solver.cpp:218] Iteration 17400 (30.5309 iter/s, 3.27537s/100 iters), loss = 0.3482
I1005 00:53:30.359464 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:53:30.359464 17516 solver.cpp:237]     Train net output #1: loss = 0.3482 (* 1 = 0.3482 loss)
I1005 00:53:30.359464 17516 sgd_solver.cpp:105] Iteration 17400, lr = 1e-05
I1005 00:53:33.472839  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:53:33.628929 17516 solver.cpp:218] Iteration 17500 (30.5871 iter/s, 3.26935s/100 iters), loss = 0.377587
I1005 00:53:33.628929 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:53:33.628929 17516 solver.cpp:237]     Train net output #1: loss = 0.377587 (* 1 = 0.377587 loss)
I1005 00:53:33.628929 17516 sgd_solver.cpp:105] Iteration 17500, lr = 1e-05
I1005 00:53:36.896347 17516 solver.cpp:218] Iteration 17600 (30.5958 iter/s, 3.26842s/100 iters), loss = 0.438832
I1005 00:53:36.896347 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:53:36.896347 17516 solver.cpp:237]     Train net output #1: loss = 0.438832 (* 1 = 0.438832 loss)
I1005 00:53:36.896347 17516 sgd_solver.cpp:105] Iteration 17600, lr = 1e-05
I1005 00:53:40.168548 17516 solver.cpp:218] Iteration 17700 (30.5579 iter/s, 3.27247s/100 iters), loss = 0.441485
I1005 00:53:40.168548 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:53:40.168548 17516 solver.cpp:237]     Train net output #1: loss = 0.441485 (* 1 = 0.441485 loss)
I1005 00:53:40.168548 17516 sgd_solver.cpp:105] Iteration 17700, lr = 1e-05
I1005 00:53:43.440176 17516 solver.cpp:218] Iteration 17800 (30.6007 iter/s, 3.2679s/100 iters), loss = 0.423264
I1005 00:53:43.440176 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:53:43.440176 17516 solver.cpp:237]     Train net output #1: loss = 0.423264 (* 1 = 0.423264 loss)
I1005 00:53:43.440176 17516 sgd_solver.cpp:105] Iteration 17800, lr = 1e-05
I1005 00:53:46.715870 17516 solver.cpp:218] Iteration 17900 (30.5757 iter/s, 3.27058s/100 iters), loss = 0.337828
I1005 00:53:46.715870 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:53:46.715870 17516 solver.cpp:237]     Train net output #1: loss = 0.337828 (* 1 = 0.337828 loss)
I1005 00:53:46.715870 17516 sgd_solver.cpp:105] Iteration 17900, lr = 1e-05
I1005 00:53:49.827347  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:53:49.952333 17516 solver.cpp:330] Iteration 18000, Testing net (#0)
I1005 00:53:49.952333 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:53:50.599162 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:53:50.630409 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7932
I1005 00:53:50.630409 17516 solver.cpp:397]     Test net output #1: loss = 0.603115 (* 1 = 0.603115 loss)
I1005 00:53:50.661648 17516 solver.cpp:218] Iteration 18000 (25.3237 iter/s, 3.94886s/100 iters), loss = 0.416878
I1005 00:53:50.661648 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:53:50.661648 17516 solver.cpp:237]     Train net output #1: loss = 0.416878 (* 1 = 0.416878 loss)
I1005 00:53:50.661648 17516 sgd_solver.cpp:105] Iteration 18000, lr = 1e-05
I1005 00:53:53.932806 17516 solver.cpp:218] Iteration 18100 (30.5486 iter/s, 3.27348s/100 iters), loss = 0.420588
I1005 00:53:53.932806 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:53:53.932806 17516 solver.cpp:237]     Train net output #1: loss = 0.420588 (* 1 = 0.420588 loss)
I1005 00:53:53.932806 17516 sgd_solver.cpp:105] Iteration 18100, lr = 1e-05
I1005 00:53:57.222285 17516 solver.cpp:218] Iteration 18200 (30.4989 iter/s, 3.2788s/100 iters), loss = 0.419227
I1005 00:53:57.222285 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:53:57.222285 17516 solver.cpp:237]     Train net output #1: loss = 0.419227 (* 1 = 0.419227 loss)
I1005 00:53:57.222285 17516 sgd_solver.cpp:105] Iteration 18200, lr = 1e-05
I1005 00:54:00.488200 17516 solver.cpp:218] Iteration 18300 (30.5184 iter/s, 3.27672s/100 iters), loss = 0.430279
I1005 00:54:00.488200 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:54:00.488200 17516 solver.cpp:237]     Train net output #1: loss = 0.430279 (* 1 = 0.430279 loss)
I1005 00:54:00.488200 17516 sgd_solver.cpp:105] Iteration 18300, lr = 1e-05
I1005 00:54:03.769770 17516 solver.cpp:218] Iteration 18400 (30.5178 iter/s, 3.27678s/100 iters), loss = 0.352589
I1005 00:54:03.769770 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:54:03.769770 17516 solver.cpp:237]     Train net output #1: loss = 0.352589 (* 1 = 0.352589 loss)
I1005 00:54:03.769770 17516 sgd_solver.cpp:105] Iteration 18400, lr = 1e-05
I1005 00:54:06.885627  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:54:07.041874 17516 solver.cpp:218] Iteration 18500 (30.5472 iter/s, 3.27363s/100 iters), loss = 0.433115
I1005 00:54:07.041874 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:54:07.041874 17516 solver.cpp:237]     Train net output #1: loss = 0.433115 (* 1 = 0.433115 loss)
I1005 00:54:07.041874 17516 sgd_solver.cpp:105] Iteration 18500, lr = 1e-05
I1005 00:54:10.307672 17516 solver.cpp:218] Iteration 18600 (30.5889 iter/s, 3.26916s/100 iters), loss = 0.429
I1005 00:54:10.307672 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:54:10.307672 17516 solver.cpp:237]     Train net output #1: loss = 0.429 (* 1 = 0.429 loss)
I1005 00:54:10.307672 17516 sgd_solver.cpp:105] Iteration 18600, lr = 1e-05
I1005 00:54:13.583557 17516 solver.cpp:218] Iteration 18700 (30.5532 iter/s, 3.27298s/100 iters), loss = 0.499754
I1005 00:54:13.583557 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:54:13.583557 17516 solver.cpp:237]     Train net output #1: loss = 0.499754 (* 1 = 0.499754 loss)
I1005 00:54:13.583557 17516 sgd_solver.cpp:105] Iteration 18700, lr = 1e-05
I1005 00:54:16.848575 17516 solver.cpp:218] Iteration 18800 (30.5889 iter/s, 3.26916s/100 iters), loss = 0.475635
I1005 00:54:16.848575 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:54:16.848575 17516 solver.cpp:237]     Train net output #1: loss = 0.475635 (* 1 = 0.475635 loss)
I1005 00:54:16.848575 17516 sgd_solver.cpp:105] Iteration 18800, lr = 1e-05
I1005 00:54:20.125998 17516 solver.cpp:218] Iteration 18900 (30.5125 iter/s, 3.27734s/100 iters), loss = 0.350269
I1005 00:54:20.125998 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:54:20.125998 17516 solver.cpp:237]     Train net output #1: loss = 0.350269 (* 1 = 0.350269 loss)
I1005 00:54:20.125998 17516 sgd_solver.cpp:105] Iteration 18900, lr = 1e-05
I1005 00:54:23.250080  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:54:23.373028 17516 solver.cpp:330] Iteration 19000, Testing net (#0)
I1005 00:54:23.373028 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:54:24.023907 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:54:24.055151 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7929
I1005 00:54:24.055151 17516 solver.cpp:397]     Test net output #1: loss = 0.603181 (* 1 = 0.603181 loss)
I1005 00:54:24.086396 17516 solver.cpp:218] Iteration 19000 (25.2957 iter/s, 3.95325s/100 iters), loss = 0.392509
I1005 00:54:24.086396 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:54:24.086396 17516 solver.cpp:237]     Train net output #1: loss = 0.392509 (* 1 = 0.392509 loss)
I1005 00:54:24.086396 17516 sgd_solver.cpp:105] Iteration 19000, lr = 1e-05
I1005 00:54:27.352494 17516 solver.cpp:218] Iteration 19100 (30.5552 iter/s, 3.27277s/100 iters), loss = 0.380536
I1005 00:54:27.352494 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:54:27.352494 17516 solver.cpp:237]     Train net output #1: loss = 0.380536 (* 1 = 0.380536 loss)
I1005 00:54:27.352494 17516 sgd_solver.cpp:105] Iteration 19100, lr = 1e-05
I1005 00:54:30.642470 17516 solver.cpp:218] Iteration 19200 (30.5185 iter/s, 3.2767s/100 iters), loss = 0.391999
I1005 00:54:30.642470 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:54:30.642470 17516 solver.cpp:237]     Train net output #1: loss = 0.391999 (* 1 = 0.391999 loss)
I1005 00:54:30.642470 17516 sgd_solver.cpp:105] Iteration 19200, lr = 1e-05
I1005 00:54:33.903040 17516 solver.cpp:218] Iteration 19300 (30.5907 iter/s, 3.26897s/100 iters), loss = 0.484314
I1005 00:54:33.903040 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:54:33.903040 17516 solver.cpp:237]     Train net output #1: loss = 0.484314 (* 1 = 0.484314 loss)
I1005 00:54:33.903040 17516 sgd_solver.cpp:105] Iteration 19300, lr = 1e-05
I1005 00:54:37.175624 17516 solver.cpp:218] Iteration 19400 (30.6224 iter/s, 3.26558s/100 iters), loss = 0.404537
I1005 00:54:37.175624 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:54:37.175624 17516 solver.cpp:237]     Train net output #1: loss = 0.404537 (* 1 = 0.404537 loss)
I1005 00:54:37.175624 17516 sgd_solver.cpp:105] Iteration 19400, lr = 1e-05
I1005 00:54:40.283895  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:54:40.440156 17516 solver.cpp:218] Iteration 19500 (30.5966 iter/s, 3.26834s/100 iters), loss = 0.364941
I1005 00:54:40.440156 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:54:40.440156 17516 solver.cpp:237]     Train net output #1: loss = 0.364941 (* 1 = 0.364941 loss)
I1005 00:54:40.440156 17516 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I1005 00:54:43.702579 17516 solver.cpp:218] Iteration 19600 (30.6261 iter/s, 3.26519s/100 iters), loss = 0.347166
I1005 00:54:43.702579 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:54:43.702579 17516 solver.cpp:237]     Train net output #1: loss = 0.347166 (* 1 = 0.347166 loss)
I1005 00:54:43.702579 17516 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I1005 00:54:46.981966 17516 solver.cpp:218] Iteration 19700 (30.5703 iter/s, 3.27115s/100 iters), loss = 0.489048
I1005 00:54:46.981966 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:54:46.981966 17516 solver.cpp:237]     Train net output #1: loss = 0.489048 (* 1 = 0.489048 loss)
I1005 00:54:46.981966 17516 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I1005 00:54:50.248858 17516 solver.cpp:218] Iteration 19800 (30.5931 iter/s, 3.26872s/100 iters), loss = 0.449494
I1005 00:54:50.248858 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:54:50.248858 17516 solver.cpp:237]     Train net output #1: loss = 0.449494 (* 1 = 0.449494 loss)
I1005 00:54:50.248858 17516 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I1005 00:54:53.526747 17516 solver.cpp:218] Iteration 19900 (30.5523 iter/s, 3.27308s/100 iters), loss = 0.362897
I1005 00:54:53.526747 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:54:53.526747 17516 solver.cpp:237]     Train net output #1: loss = 0.362897 (* 1 = 0.362897 loss)
I1005 00:54:53.526747 17516 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I1005 00:54:56.629174  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:54:56.756582 17516 solver.cpp:330] Iteration 20000, Testing net (#0)
I1005 00:54:56.756582 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:54:57.410895 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:54:57.442139 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7927
I1005 00:54:57.442139 17516 solver.cpp:397]     Test net output #1: loss = 0.603047 (* 1 = 0.603047 loss)
I1005 00:54:57.473398 17516 solver.cpp:218] Iteration 20000 (25.3207 iter/s, 3.94933s/100 iters), loss = 0.364966
I1005 00:54:57.473398 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:54:57.473398 17516 solver.cpp:237]     Train net output #1: loss = 0.364966 (* 1 = 0.364966 loss)
I1005 00:54:57.473398 17516 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I1005 00:55:00.733500 17516 solver.cpp:218] Iteration 20100 (30.5765 iter/s, 3.27048s/100 iters), loss = 0.406098
I1005 00:55:00.733500 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:55:00.733500 17516 solver.cpp:237]     Train net output #1: loss = 0.406098 (* 1 = 0.406098 loss)
I1005 00:55:00.733500 17516 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I1005 00:55:04.015769 17516 solver.cpp:218] Iteration 20200 (30.5985 iter/s, 3.26813s/100 iters), loss = 0.430819
I1005 00:55:04.015769 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:55:04.015769 17516 solver.cpp:237]     Train net output #1: loss = 0.430819 (* 1 = 0.430819 loss)
I1005 00:55:04.015769 17516 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I1005 00:55:07.281141 17516 solver.cpp:218] Iteration 20300 (30.6124 iter/s, 3.26665s/100 iters), loss = 0.458156
I1005 00:55:07.281141 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:55:07.281141 17516 solver.cpp:237]     Train net output #1: loss = 0.458156 (* 1 = 0.458156 loss)
I1005 00:55:07.281141 17516 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I1005 00:55:10.550115 17516 solver.cpp:218] Iteration 20400 (30.5875 iter/s, 3.26931s/100 iters), loss = 0.356299
I1005 00:55:10.550115 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:55:10.550115 17516 solver.cpp:237]     Train net output #1: loss = 0.356299 (* 1 = 0.356299 loss)
I1005 00:55:10.550115 17516 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I1005 00:55:13.658406  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:55:13.814638 17516 solver.cpp:218] Iteration 20500 (30.5423 iter/s, 3.27415s/100 iters), loss = 0.349051
I1005 00:55:13.814638 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:55:13.814638 17516 solver.cpp:237]     Train net output #1: loss = 0.349051 (* 1 = 0.349051 loss)
I1005 00:55:13.814638 17516 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I1005 00:55:17.087754 17516 solver.cpp:218] Iteration 20600 (30.5693 iter/s, 3.27125s/100 iters), loss = 0.403017
I1005 00:55:17.087754 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:55:17.087754 17516 solver.cpp:237]     Train net output #1: loss = 0.403017 (* 1 = 0.403017 loss)
I1005 00:55:17.087754 17516 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I1005 00:55:20.349910 17516 solver.cpp:218] Iteration 20700 (30.6265 iter/s, 3.26515s/100 iters), loss = 0.460357
I1005 00:55:20.349910 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:55:20.365536 17516 solver.cpp:237]     Train net output #1: loss = 0.460357 (* 1 = 0.460357 loss)
I1005 00:55:20.365536 17516 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I1005 00:55:23.621064 17516 solver.cpp:218] Iteration 20800 (30.6101 iter/s, 3.26689s/100 iters), loss = 0.463064
I1005 00:55:23.621064 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:55:23.621064 17516 solver.cpp:237]     Train net output #1: loss = 0.463064 (* 1 = 0.463064 loss)
I1005 00:55:23.621064 17516 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I1005 00:55:26.895546 17516 solver.cpp:218] Iteration 20900 (30.5892 iter/s, 3.26912s/100 iters), loss = 0.313593
I1005 00:55:26.895546 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:55:26.895546 17516 solver.cpp:237]     Train net output #1: loss = 0.313593 (* 1 = 0.313593 loss)
I1005 00:55:26.895546 17516 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I1005 00:55:30.010782  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:55:30.135797 17516 solver.cpp:330] Iteration 21000, Testing net (#0)
I1005 00:55:30.135797 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:55:30.797926 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:55:30.813561 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7929
I1005 00:55:30.813561 17516 solver.cpp:397]     Test net output #1: loss = 0.603117 (* 1 = 0.603117 loss)
I1005 00:55:30.844815 17516 solver.cpp:218] Iteration 21000 (25.3041 iter/s, 3.95193s/100 iters), loss = 0.381155
I1005 00:55:30.844815 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:55:30.844815 17516 solver.cpp:237]     Train net output #1: loss = 0.381155 (* 1 = 0.381155 loss)
I1005 00:55:30.844815 17516 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I1005 00:55:34.113232 17516 solver.cpp:218] Iteration 21100 (30.5889 iter/s, 3.26916s/100 iters), loss = 0.375624
I1005 00:55:34.113232 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:55:34.113232 17516 solver.cpp:237]     Train net output #1: loss = 0.375624 (* 1 = 0.375624 loss)
I1005 00:55:34.113232 17516 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I1005 00:55:37.391443 17516 solver.cpp:218] Iteration 21200 (30.5294 iter/s, 3.27553s/100 iters), loss = 0.43962
I1005 00:55:37.391443 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:55:37.391443 17516 solver.cpp:237]     Train net output #1: loss = 0.43962 (* 1 = 0.43962 loss)
I1005 00:55:37.391443 17516 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I1005 00:55:40.670814 17516 solver.cpp:218] Iteration 21300 (30.561 iter/s, 3.27215s/100 iters), loss = 0.486425
I1005 00:55:40.670814 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:55:40.670814 17516 solver.cpp:237]     Train net output #1: loss = 0.486425 (* 1 = 0.486425 loss)
I1005 00:55:40.670814 17516 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I1005 00:55:43.929405 17516 solver.cpp:218] Iteration 21400 (30.5933 iter/s, 3.26869s/100 iters), loss = 0.39166
I1005 00:55:43.929405 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:55:43.929405 17516 solver.cpp:237]     Train net output #1: loss = 0.39166 (* 1 = 0.39166 loss)
I1005 00:55:43.929405 17516 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I1005 00:55:47.053164  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:55:47.209412 17516 solver.cpp:218] Iteration 21500 (30.5587 iter/s, 3.27239s/100 iters), loss = 0.351459
I1005 00:55:47.209412 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:55:47.209412 17516 solver.cpp:237]     Train net output #1: loss = 0.351459 (* 1 = 0.351459 loss)
I1005 00:55:47.209412 17516 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I1005 00:55:50.473696 17516 solver.cpp:218] Iteration 21600 (30.603 iter/s, 3.26765s/100 iters), loss = 0.4182
I1005 00:55:50.473696 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:55:50.473696 17516 solver.cpp:237]     Train net output #1: loss = 0.4182 (* 1 = 0.4182 loss)
I1005 00:55:50.473696 17516 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I1005 00:55:53.761313 17516 solver.cpp:218] Iteration 21700 (30.4825 iter/s, 3.28058s/100 iters), loss = 0.456057
I1005 00:55:53.761313 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:55:53.761313 17516 solver.cpp:237]     Train net output #1: loss = 0.456057 (* 1 = 0.456057 loss)
I1005 00:55:53.761313 17516 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I1005 00:55:57.025521 17516 solver.cpp:218] Iteration 21800 (30.5752 iter/s, 3.27062s/100 iters), loss = 0.442997
I1005 00:55:57.025521 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:55:57.025521 17516 solver.cpp:237]     Train net output #1: loss = 0.442997 (* 1 = 0.442997 loss)
I1005 00:55:57.025521 17516 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I1005 00:56:00.296475 17516 solver.cpp:218] Iteration 21900 (30.5228 iter/s, 3.27624s/100 iters), loss = 0.337427
I1005 00:56:00.296475 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 00:56:00.296475 17516 solver.cpp:237]     Train net output #1: loss = 0.337427 (* 1 = 0.337427 loss)
I1005 00:56:00.296475 17516 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I1005 00:56:03.422505  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:56:03.551580 17516 solver.cpp:330] Iteration 22000, Testing net (#0)
I1005 00:56:03.551580 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:56:04.192216 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:56:04.223464 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7933
I1005 00:56:04.223464 17516 solver.cpp:397]     Test net output #1: loss = 0.603054 (* 1 = 0.603054 loss)
I1005 00:56:04.254719 17516 solver.cpp:218] Iteration 22000 (25.3278 iter/s, 3.94824s/100 iters), loss = 0.3528
I1005 00:56:04.254719 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:56:04.254719 17516 solver.cpp:237]     Train net output #1: loss = 0.3528 (* 1 = 0.3528 loss)
I1005 00:56:04.254719 17516 sgd_solver.cpp:105] Iteration 22000, lr = 1e-05
I1005 00:56:07.535151 17516 solver.cpp:218] Iteration 22100 (30.5148 iter/s, 3.27709s/100 iters), loss = 0.40973
I1005 00:56:07.535151 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:56:07.535151 17516 solver.cpp:237]     Train net output #1: loss = 0.40973 (* 1 = 0.40973 loss)
I1005 00:56:07.535151 17516 sgd_solver.cpp:105] Iteration 22100, lr = 1e-05
I1005 00:56:10.800483 17516 solver.cpp:218] Iteration 22200 (30.5648 iter/s, 3.27174s/100 iters), loss = 0.410857
I1005 00:56:10.800483 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:56:10.800483 17516 solver.cpp:237]     Train net output #1: loss = 0.410857 (* 1 = 0.410857 loss)
I1005 00:56:10.800483 17516 sgd_solver.cpp:105] Iteration 22200, lr = 1e-05
I1005 00:56:14.070138 17516 solver.cpp:218] Iteration 22300 (30.5354 iter/s, 3.27488s/100 iters), loss = 0.467848
I1005 00:56:14.070138 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:56:14.070138 17516 solver.cpp:237]     Train net output #1: loss = 0.467848 (* 1 = 0.467848 loss)
I1005 00:56:14.070138 17516 sgd_solver.cpp:105] Iteration 22300, lr = 1e-05
I1005 00:56:17.344571 17516 solver.cpp:218] Iteration 22400 (30.5743 iter/s, 3.27072s/100 iters), loss = 0.383115
I1005 00:56:17.344571 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:56:17.344571 17516 solver.cpp:237]     Train net output #1: loss = 0.383115 (* 1 = 0.383115 loss)
I1005 00:56:17.344571 17516 sgd_solver.cpp:105] Iteration 22400, lr = 1e-05
I1005 00:56:20.461488  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:56:20.617743 17516 solver.cpp:218] Iteration 22500 (30.5521 iter/s, 3.2731s/100 iters), loss = 0.387902
I1005 00:56:20.617743 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:56:20.617743 17516 solver.cpp:237]     Train net output #1: loss = 0.387902 (* 1 = 0.387902 loss)
I1005 00:56:20.617743 17516 sgd_solver.cpp:105] Iteration 22500, lr = 1e-05
I1005 00:56:23.886456 17516 solver.cpp:218] Iteration 22600 (30.5949 iter/s, 3.26852s/100 iters), loss = 0.4073
I1005 00:56:23.886456 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:56:23.886456 17516 solver.cpp:237]     Train net output #1: loss = 0.4073 (* 1 = 0.4073 loss)
I1005 00:56:23.886456 17516 sgd_solver.cpp:105] Iteration 22600, lr = 1e-05
I1005 00:56:27.154120 17516 solver.cpp:218] Iteration 22700 (30.6149 iter/s, 3.26638s/100 iters), loss = 0.421294
I1005 00:56:27.154120 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:56:27.154120 17516 solver.cpp:237]     Train net output #1: loss = 0.421294 (* 1 = 0.421294 loss)
I1005 00:56:27.154120 17516 sgd_solver.cpp:105] Iteration 22700, lr = 1e-05
I1005 00:56:30.437221 17516 solver.cpp:218] Iteration 22800 (30.5193 iter/s, 3.27662s/100 iters), loss = 0.493833
I1005 00:56:30.437221 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:56:30.437221 17516 solver.cpp:237]     Train net output #1: loss = 0.493833 (* 1 = 0.493833 loss)
I1005 00:56:30.437221 17516 sgd_solver.cpp:105] Iteration 22800, lr = 1e-05
I1005 00:56:33.717600 17516 solver.cpp:218] Iteration 22900 (30.5169 iter/s, 3.27687s/100 iters), loss = 0.377091
I1005 00:56:33.717600 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:56:33.717600 17516 solver.cpp:237]     Train net output #1: loss = 0.377091 (* 1 = 0.377091 loss)
I1005 00:56:33.717600 17516 sgd_solver.cpp:105] Iteration 22900, lr = 1e-05
I1005 00:56:36.818450  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:56:36.959062 17516 solver.cpp:330] Iteration 23000, Testing net (#0)
I1005 00:56:36.959062 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:56:37.596756 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:56:37.628017 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7924
I1005 00:56:37.628017 17516 solver.cpp:397]     Test net output #1: loss = 0.603075 (* 1 = 0.603075 loss)
I1005 00:56:37.659271 17516 solver.cpp:218] Iteration 23000 (25.3218 iter/s, 3.94917s/100 iters), loss = 0.36723
I1005 00:56:37.659271 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:56:37.659271 17516 solver.cpp:237]     Train net output #1: loss = 0.36723 (* 1 = 0.36723 loss)
I1005 00:56:37.659271 17516 sgd_solver.cpp:105] Iteration 23000, lr = 1e-05
I1005 00:56:40.921424 17516 solver.cpp:218] Iteration 23100 (30.5958 iter/s, 3.26842s/100 iters), loss = 0.411445
I1005 00:56:40.921424 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:56:40.921424 17516 solver.cpp:237]     Train net output #1: loss = 0.411445 (* 1 = 0.411445 loss)
I1005 00:56:40.921424 17516 sgd_solver.cpp:105] Iteration 23100, lr = 1e-05
I1005 00:56:44.199118 17516 solver.cpp:218] Iteration 23200 (30.5918 iter/s, 3.26885s/100 iters), loss = 0.458586
I1005 00:56:44.199118 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:56:44.199118 17516 solver.cpp:237]     Train net output #1: loss = 0.458586 (* 1 = 0.458586 loss)
I1005 00:56:44.199118 17516 sgd_solver.cpp:105] Iteration 23200, lr = 1e-05
I1005 00:56:47.457664 17516 solver.cpp:218] Iteration 23300 (30.6149 iter/s, 3.26638s/100 iters), loss = 0.526965
I1005 00:56:47.457664 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:56:47.457664 17516 solver.cpp:237]     Train net output #1: loss = 0.526965 (* 1 = 0.526965 loss)
I1005 00:56:47.457664 17516 sgd_solver.cpp:105] Iteration 23300, lr = 1e-05
I1005 00:56:50.743840 17516 solver.cpp:218] Iteration 23400 (30.5427 iter/s, 3.27411s/100 iters), loss = 0.369742
I1005 00:56:50.743840 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:56:50.743840 17516 solver.cpp:237]     Train net output #1: loss = 0.369742 (* 1 = 0.369742 loss)
I1005 00:56:50.743840 17516 sgd_solver.cpp:105] Iteration 23400, lr = 1e-05
I1005 00:56:53.846666  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:56:54.018018 17516 solver.cpp:218] Iteration 23500 (30.5751 iter/s, 3.27063s/100 iters), loss = 0.357559
I1005 00:56:54.018018 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 00:56:54.018018 17516 solver.cpp:237]     Train net output #1: loss = 0.357559 (* 1 = 0.357559 loss)
I1005 00:56:54.018018 17516 sgd_solver.cpp:105] Iteration 23500, lr = 1e-05
I1005 00:56:57.286514 17516 solver.cpp:218] Iteration 23600 (30.5941 iter/s, 3.26861s/100 iters), loss = 0.441445
I1005 00:56:57.286514 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 00:56:57.286514 17516 solver.cpp:237]     Train net output #1: loss = 0.441445 (* 1 = 0.441445 loss)
I1005 00:56:57.286514 17516 sgd_solver.cpp:105] Iteration 23600, lr = 1e-05
I1005 00:57:00.550534 17516 solver.cpp:218] Iteration 23700 (30.5765 iter/s, 3.27048s/100 iters), loss = 0.42856
I1005 00:57:00.550534 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 00:57:00.550534 17516 solver.cpp:237]     Train net output #1: loss = 0.42856 (* 1 = 0.42856 loss)
I1005 00:57:00.550534 17516 sgd_solver.cpp:105] Iteration 23700, lr = 1e-05
I1005 00:57:03.811091 17516 solver.cpp:218] Iteration 23800 (30.61 iter/s, 3.2669s/100 iters), loss = 0.470007
I1005 00:57:03.811091 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 00:57:03.811091 17516 solver.cpp:237]     Train net output #1: loss = 0.470007 (* 1 = 0.470007 loss)
I1005 00:57:03.811091 17516 sgd_solver.cpp:105] Iteration 23800, lr = 1e-05
I1005 00:57:07.087278 17516 solver.cpp:218] Iteration 23900 (30.5515 iter/s, 3.27316s/100 iters), loss = 0.350358
I1005 00:57:07.087278 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:57:07.087278 17516 solver.cpp:237]     Train net output #1: loss = 0.350358 (* 1 = 0.350358 loss)
I1005 00:57:07.087278 17516 sgd_solver.cpp:105] Iteration 23900, lr = 1e-05
I1005 00:57:10.210283  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:57:10.335286 17516 solver.cpp:330] Iteration 24000, Testing net (#0)
I1005 00:57:10.335286 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:57:10.983150 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:57:11.014400 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7932
I1005 00:57:11.014400 17516 solver.cpp:397]     Test net output #1: loss = 0.603138 (* 1 = 0.603138 loss)
I1005 00:57:11.045640 17516 solver.cpp:218] Iteration 24000 (25.3146 iter/s, 3.95029s/100 iters), loss = 0.397006
I1005 00:57:11.045640 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:57:11.045640 17516 solver.cpp:237]     Train net output #1: loss = 0.397006 (* 1 = 0.397006 loss)
I1005 00:57:11.045640 17516 sgd_solver.cpp:105] Iteration 24000, lr = 1e-05
I1005 00:57:14.317445 17516 solver.cpp:218] Iteration 24100 (30.5588 iter/s, 3.27238s/100 iters), loss = 0.411146
I1005 00:57:14.317445 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:57:14.317445 17516 solver.cpp:237]     Train net output #1: loss = 0.411146 (* 1 = 0.411146 loss)
I1005 00:57:14.317445 17516 sgd_solver.cpp:105] Iteration 24100, lr = 1e-05
I1005 00:57:17.589056 17516 solver.cpp:218] Iteration 24200 (30.6143 iter/s, 3.26645s/100 iters), loss = 0.439022
I1005 00:57:17.589056 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:57:17.589056 17516 solver.cpp:237]     Train net output #1: loss = 0.439022 (* 1 = 0.439022 loss)
I1005 00:57:17.589056 17516 sgd_solver.cpp:105] Iteration 24200, lr = 1e-05
I1005 00:57:20.858278 17516 solver.cpp:218] Iteration 24300 (30.5792 iter/s, 3.27019s/100 iters), loss = 0.527827
I1005 00:57:20.858278 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 00:57:20.858278 17516 solver.cpp:237]     Train net output #1: loss = 0.527827 (* 1 = 0.527827 loss)
I1005 00:57:20.858278 17516 sgd_solver.cpp:105] Iteration 24300, lr = 1e-05
I1005 00:57:24.121666 17516 solver.cpp:218] Iteration 24400 (30.5532 iter/s, 3.27298s/100 iters), loss = 0.360586
I1005 00:57:24.121666 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:57:24.121666 17516 solver.cpp:237]     Train net output #1: loss = 0.360586 (* 1 = 0.360586 loss)
I1005 00:57:24.121666 17516 sgd_solver.cpp:105] Iteration 24400, lr = 1e-05
I1005 00:57:27.233785  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:57:27.405645 17516 solver.cpp:218] Iteration 24500 (30.5512 iter/s, 3.2732s/100 iters), loss = 0.356976
I1005 00:57:27.405645 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:57:27.405645 17516 solver.cpp:237]     Train net output #1: loss = 0.356976 (* 1 = 0.356976 loss)
I1005 00:57:27.405645 17516 sgd_solver.cpp:105] Iteration 24500, lr = 1e-05
I1005 00:57:30.668696 17516 solver.cpp:218] Iteration 24600 (30.5701 iter/s, 3.27117s/100 iters), loss = 0.431111
I1005 00:57:30.668696 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:57:30.668696 17516 solver.cpp:237]     Train net output #1: loss = 0.431111 (* 1 = 0.431111 loss)
I1005 00:57:30.668696 17516 sgd_solver.cpp:105] Iteration 24600, lr = 1e-05
I1005 00:57:33.937474 17516 solver.cpp:218] Iteration 24700 (30.5813 iter/s, 3.26997s/100 iters), loss = 0.383253
I1005 00:57:33.937474 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 00:57:33.937474 17516 solver.cpp:237]     Train net output #1: loss = 0.383253 (* 1 = 0.383253 loss)
I1005 00:57:33.937474 17516 sgd_solver.cpp:105] Iteration 24700, lr = 1e-05
I1005 00:57:37.209056 17516 solver.cpp:218] Iteration 24800 (30.6141 iter/s, 3.26647s/100 iters), loss = 0.459746
I1005 00:57:37.209056 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 00:57:37.209056 17516 solver.cpp:237]     Train net output #1: loss = 0.459746 (* 1 = 0.459746 loss)
I1005 00:57:37.209056 17516 sgd_solver.cpp:105] Iteration 24800, lr = 1e-05
I1005 00:57:40.471599 17516 solver.cpp:218] Iteration 24900 (30.6395 iter/s, 3.26376s/100 iters), loss = 0.35027
I1005 00:57:40.471599 17516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 00:57:40.471599 17516 solver.cpp:237]     Train net output #1: loss = 0.35027 (* 1 = 0.35027 loss)
I1005 00:57:40.471599 17516 sgd_solver.cpp:105] Iteration 24900, lr = 1e-05
I1005 00:57:43.586686  4780 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:57:43.714311 17516 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/slimnet_simpnet_p7_iter_25000.caffemodel
I1005 00:57:43.714311 17516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_simpnet_p7_iter_25000.solverstate
I1005 00:57:43.729928 17516 solver.cpp:310] Iteration 25000, loss = 0.348637
I1005 00:57:43.729928 17516 solver.cpp:330] Iteration 25000, Testing net (#0)
I1005 00:57:43.729928 17516 net.cpp:676] Ignoring source layer accuracy_training
I1005 00:57:44.379575 18172 data_layer.cpp:73] Restarting data prefetching from start.
I1005 00:57:44.410820 17516 solver.cpp:397]     Test net output #0: accuracy = 0.7933
I1005 00:57:44.410820 17516 solver.cpp:397]     Test net output #1: loss = 0.603286 (* 1 = 0.603286 loss)
I1005 00:57:44.410820 17516 solver.cpp:315] Optimization Done.
I1005 00:57:44.410820 17516 caffe.cpp:260] Optimization Done.

G:\Caffe>pause
Press any key to continue . . . 
