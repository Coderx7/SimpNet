
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I1005 08:54:59.636294  1784 caffe.cpp:219] Using GPUs 0
I1005 08:54:59.823804  1784 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1005 08:55:00.109143  1784 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 08:55:00.120252  1784 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 25000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 25000
snapshot_prefix: "examples/cifar10/slimnet_simpnet_p7"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 25000
type: "Nesterov"
I1005 08:55:00.151541  1784 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 08:55:00.151541  1784 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 08:55:00.151541  1784 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1005 08:55:00.151541  1784 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1005 08:55:00.151541  1784 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P7"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1005 08:55:00.214015  1784 layer_factory.cpp:58] Creating layer cifar
I1005 08:55:00.346042  1784 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I1005 08:55:00.346042  1784 net.cpp:84] Creating Layer cifar
I1005 08:55:00.346042  1784 net.cpp:380] cifar -> data
I1005 08:55:00.346042  1784 net.cpp:380] cifar -> label
I1005 08:55:00.346042  1784 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1005 08:55:00.346042  1784 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 08:55:00.346042  1784 data_layer.cpp:45] output data size: 100,3,32,32
I1005 08:55:00.346042  1784 net.cpp:122] Setting up cifar
I1005 08:55:00.346042  1784 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1005 08:55:00.346042  1784 net.cpp:129] Top shape: 100 (100)
I1005 08:55:00.346042  1784 net.cpp:137] Memory required for data: 1229200
I1005 08:55:00.346042  1784 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1005 08:55:00.361685  1784 net.cpp:84] Creating Layer label_cifar_1_split
I1005 08:55:00.361685  1784 net.cpp:406] label_cifar_1_split <- label
I1005 08:55:00.361685  1784 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1005 08:55:00.361685  1784 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1005 08:55:00.361685  1784 net.cpp:122] Setting up label_cifar_1_split
I1005 08:55:00.361685  1784 net.cpp:129] Top shape: 100 (100)
I1005 08:55:00.361685  1784 net.cpp:129] Top shape: 100 (100)
I1005 08:55:00.361685  1784 net.cpp:137] Memory required for data: 1230000
I1005 08:55:00.361685  1784 layer_factory.cpp:58] Creating layer conv1
I1005 08:55:00.361685  1784 net.cpp:84] Creating Layer conv1
I1005 08:55:00.361685  1784 net.cpp:406] conv1 <- data
I1005 08:55:00.361685  1784 net.cpp:380] conv1 -> conv1
I1005 08:55:00.361685 17588 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 08:55:00.637555  1784 net.cpp:122] Setting up conv1
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 3687600
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer bn1
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer bn1
I1005 08:55:00.637555  1784 net.cpp:406] bn1 <- conv1
I1005 08:55:00.637555  1784 net.cpp:367] bn1 -> conv1 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up bn1
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 6145200
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale1
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer scale1
I1005 08:55:00.637555  1784 net.cpp:406] scale1 <- conv1
I1005 08:55:00.637555  1784 net.cpp:367] scale1 -> conv1 (in-place)
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale1
I1005 08:55:00.637555  1784 net.cpp:122] Setting up scale1
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 8602800
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer relu1
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer relu1
I1005 08:55:00.637555  1784 net.cpp:406] relu1 <- conv1
I1005 08:55:00.637555  1784 net.cpp:367] relu1 -> conv1 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up relu1
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 11060400
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer conv1_0
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer conv1_0
I1005 08:55:00.637555  1784 net.cpp:406] conv1_0 <- conv1
I1005 08:55:00.637555  1784 net.cpp:380] conv1_0 -> conv1_0
I1005 08:55:00.637555  1784 net.cpp:122] Setting up conv1_0
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 15975600
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer bn1_0
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer bn1_0
I1005 08:55:00.637555  1784 net.cpp:406] bn1_0 <- conv1_0
I1005 08:55:00.637555  1784 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up bn1_0
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 20890800
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale1_0
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer scale1_0
I1005 08:55:00.637555  1784 net.cpp:406] scale1_0 <- conv1_0
I1005 08:55:00.637555  1784 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale1_0
I1005 08:55:00.637555  1784 net.cpp:122] Setting up scale1_0
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 25806000
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer relu1_0
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer relu1_0
I1005 08:55:00.637555  1784 net.cpp:406] relu1_0 <- conv1_0
I1005 08:55:00.637555  1784 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up relu1_0
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 30721200
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer conv2
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer conv2
I1005 08:55:00.637555  1784 net.cpp:406] conv2 <- conv1_0
I1005 08:55:00.637555  1784 net.cpp:380] conv2 -> conv2
I1005 08:55:00.637555  1784 net.cpp:122] Setting up conv2
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 35636400
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer bn2
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer bn2
I1005 08:55:00.637555  1784 net.cpp:406] bn2 <- conv2
I1005 08:55:00.637555  1784 net.cpp:367] bn2 -> conv2 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up bn2
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 40551600
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale2
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer scale2
I1005 08:55:00.637555  1784 net.cpp:406] scale2 <- conv2
I1005 08:55:00.637555  1784 net.cpp:367] scale2 -> conv2 (in-place)
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale2
I1005 08:55:00.637555  1784 net.cpp:122] Setting up scale2
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 45466800
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer relu2
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer relu2
I1005 08:55:00.637555  1784 net.cpp:406] relu2 <- conv2
I1005 08:55:00.637555  1784 net.cpp:367] relu2 -> conv2 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up relu2
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 50382000
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer conv2_1
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer conv2_1
I1005 08:55:00.637555  1784 net.cpp:406] conv2_1 <- conv2
I1005 08:55:00.637555  1784 net.cpp:380] conv2_1 -> conv2_1
I1005 08:55:00.637555  1784 net.cpp:122] Setting up conv2_1
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 55297200
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer bn2_1
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer bn2_1
I1005 08:55:00.637555  1784 net.cpp:406] bn2_1 <- conv2_1
I1005 08:55:00.637555  1784 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up bn2_1
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 60212400
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale2_1
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer scale2_1
I1005 08:55:00.637555  1784 net.cpp:406] scale2_1 <- conv2_1
I1005 08:55:00.637555  1784 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale2_1
I1005 08:55:00.637555  1784 net.cpp:122] Setting up scale2_1
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 65127600
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer relu2_1
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer relu2_1
I1005 08:55:00.637555  1784 net.cpp:406] relu2_1 <- conv2_1
I1005 08:55:00.637555  1784 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up relu2_1
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 70042800
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer conv2_2
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer conv2_2
I1005 08:55:00.637555  1784 net.cpp:406] conv2_2 <- conv2_1
I1005 08:55:00.637555  1784 net.cpp:380] conv2_2 -> conv2_2
I1005 08:55:00.637555  1784 net.cpp:122] Setting up conv2_2
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 77825200
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer bn2_2
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer bn2_2
I1005 08:55:00.637555  1784 net.cpp:406] bn2_2 <- conv2_2
I1005 08:55:00.637555  1784 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up bn2_2
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 85607600
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale2_2
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer scale2_2
I1005 08:55:00.637555  1784 net.cpp:406] scale2_2 <- conv2_2
I1005 08:55:00.637555  1784 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale2_2
I1005 08:55:00.637555  1784 net.cpp:122] Setting up scale2_2
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 93390000
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer relu2_2
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer relu2_2
I1005 08:55:00.637555  1784 net.cpp:406] relu2_2 <- conv2_2
I1005 08:55:00.637555  1784 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up relu2_2
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 101172400
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer conv3
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer conv3
I1005 08:55:00.637555  1784 net.cpp:406] conv3 <- conv2_2
I1005 08:55:00.637555  1784 net.cpp:380] conv3 -> conv3
I1005 08:55:00.637555  1784 net.cpp:122] Setting up conv3
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 108954800
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer bn3
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer bn3
I1005 08:55:00.637555  1784 net.cpp:406] bn3 <- conv3
I1005 08:55:00.637555  1784 net.cpp:367] bn3 -> conv3 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up bn3
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 116737200
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale3
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer scale3
I1005 08:55:00.637555  1784 net.cpp:406] scale3 <- conv3
I1005 08:55:00.637555  1784 net.cpp:367] scale3 -> conv3 (in-place)
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer scale3
I1005 08:55:00.637555  1784 net.cpp:122] Setting up scale3
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 124519600
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer relu3
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer relu3
I1005 08:55:00.637555  1784 net.cpp:406] relu3 <- conv3
I1005 08:55:00.637555  1784 net.cpp:367] relu3 -> conv3 (in-place)
I1005 08:55:00.637555  1784 net.cpp:122] Setting up relu3
I1005 08:55:00.637555  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.637555  1784 net.cpp:137] Memory required for data: 132302000
I1005 08:55:00.637555  1784 layer_factory.cpp:58] Creating layer conv3_1
I1005 08:55:00.637555  1784 net.cpp:84] Creating Layer conv3_1
I1005 08:55:00.637555  1784 net.cpp:406] conv3_1 <- conv3
I1005 08:55:00.637555  1784 net.cpp:380] conv3_1 -> conv3_1
I1005 08:55:00.653172  1784 net.cpp:122] Setting up conv3_1
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 140084400
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer bn3_1
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer bn3_1
I1005 08:55:00.653172  1784 net.cpp:406] bn3_1 <- conv3_1
I1005 08:55:00.653172  1784 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up bn3_1
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 147866800
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale3_1
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer scale3_1
I1005 08:55:00.653172  1784 net.cpp:406] scale3_1 <- conv3_1
I1005 08:55:00.653172  1784 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale3_1
I1005 08:55:00.653172  1784 net.cpp:122] Setting up scale3_1
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 155649200
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer relu3_1
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer relu3_1
I1005 08:55:00.653172  1784 net.cpp:406] relu3_1 <- conv3_1
I1005 08:55:00.653172  1784 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up relu3_1
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 163431600
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer pool2_1
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer pool2_1
I1005 08:55:00.653172  1784 net.cpp:406] pool2_1 <- conv3_1
I1005 08:55:00.653172  1784 net.cpp:380] pool2_1 -> pool2_1
I1005 08:55:00.653172  1784 net.cpp:122] Setting up pool2_1
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 165377200
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer conv4
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer conv4
I1005 08:55:00.653172  1784 net.cpp:406] conv4 <- pool2_1
I1005 08:55:00.653172  1784 net.cpp:380] conv4 -> conv4
I1005 08:55:00.653172  1784 net.cpp:122] Setting up conv4
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 167322800
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer bn4
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer bn4
I1005 08:55:00.653172  1784 net.cpp:406] bn4 <- conv4
I1005 08:55:00.653172  1784 net.cpp:367] bn4 -> conv4 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up bn4
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 169268400
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale4
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer scale4
I1005 08:55:00.653172  1784 net.cpp:406] scale4 <- conv4
I1005 08:55:00.653172  1784 net.cpp:367] scale4 -> conv4 (in-place)
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale4
I1005 08:55:00.653172  1784 net.cpp:122] Setting up scale4
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 171214000
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer relu4
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer relu4
I1005 08:55:00.653172  1784 net.cpp:406] relu4 <- conv4
I1005 08:55:00.653172  1784 net.cpp:367] relu4 -> conv4 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up relu4
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 173159600
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer conv4_1
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer conv4_1
I1005 08:55:00.653172  1784 net.cpp:406] conv4_1 <- conv4
I1005 08:55:00.653172  1784 net.cpp:380] conv4_1 -> conv4_1
I1005 08:55:00.653172  1784 net.cpp:122] Setting up conv4_1
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 175105200
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer bn4_1
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer bn4_1
I1005 08:55:00.653172  1784 net.cpp:406] bn4_1 <- conv4_1
I1005 08:55:00.653172  1784 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up bn4_1
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 177050800
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale4_1
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer scale4_1
I1005 08:55:00.653172  1784 net.cpp:406] scale4_1 <- conv4_1
I1005 08:55:00.653172  1784 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale4_1
I1005 08:55:00.653172  1784 net.cpp:122] Setting up scale4_1
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 178996400
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer relu4_1
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer relu4_1
I1005 08:55:00.653172  1784 net.cpp:406] relu4_1 <- conv4_1
I1005 08:55:00.653172  1784 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up relu4_1
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 180942000
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer conv4_2
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer conv4_2
I1005 08:55:00.653172  1784 net.cpp:406] conv4_2 <- conv4_1
I1005 08:55:00.653172  1784 net.cpp:380] conv4_2 -> conv4_2
I1005 08:55:00.653172  1784 net.cpp:122] Setting up conv4_2
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 183809200
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer bn4_2
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer bn4_2
I1005 08:55:00.653172  1784 net.cpp:406] bn4_2 <- conv4_2
I1005 08:55:00.653172  1784 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up bn4_2
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 186676400
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale4_2
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer scale4_2
I1005 08:55:00.653172  1784 net.cpp:406] scale4_2 <- conv4_2
I1005 08:55:00.653172  1784 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale4_2
I1005 08:55:00.653172  1784 net.cpp:122] Setting up scale4_2
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 189543600
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer relu4_2
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer relu4_2
I1005 08:55:00.653172  1784 net.cpp:406] relu4_2 <- conv4_2
I1005 08:55:00.653172  1784 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up relu4_2
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 192410800
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer pool4_2
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer pool4_2
I1005 08:55:00.653172  1784 net.cpp:406] pool4_2 <- conv4_2
I1005 08:55:00.653172  1784 net.cpp:380] pool4_2 -> pool4_2
I1005 08:55:00.653172  1784 net.cpp:122] Setting up pool4_2
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 193127600
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer conv4_0
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer conv4_0
I1005 08:55:00.653172  1784 net.cpp:406] conv4_0 <- pool4_2
I1005 08:55:00.653172  1784 net.cpp:380] conv4_0 -> conv4_0
I1005 08:55:00.653172  1784 net.cpp:122] Setting up conv4_0
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 193844400
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer bn4_0
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer bn4_0
I1005 08:55:00.653172  1784 net.cpp:406] bn4_0 <- conv4_0
I1005 08:55:00.653172  1784 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up bn4_0
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 194561200
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale4_0
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer scale4_0
I1005 08:55:00.653172  1784 net.cpp:406] scale4_0 <- conv4_0
I1005 08:55:00.653172  1784 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale4_0
I1005 08:55:00.653172  1784 net.cpp:122] Setting up scale4_0
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 195278000
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer relu4_0
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer relu4_0
I1005 08:55:00.653172  1784 net.cpp:406] relu4_0 <- conv4_0
I1005 08:55:00.653172  1784 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up relu4_0
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 195994800
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer conv11
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer conv11
I1005 08:55:00.653172  1784 net.cpp:406] conv11 <- conv4_0
I1005 08:55:00.653172  1784 net.cpp:380] conv11 -> conv11
I1005 08:55:00.653172  1784 net.cpp:122] Setting up conv11
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 196890800
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer bn_conv11
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer bn_conv11
I1005 08:55:00.653172  1784 net.cpp:406] bn_conv11 <- conv11
I1005 08:55:00.653172  1784 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up bn_conv11
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 197786800
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale_conv11
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer scale_conv11
I1005 08:55:00.653172  1784 net.cpp:406] scale_conv11 <- conv11
I1005 08:55:00.653172  1784 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale_conv11
I1005 08:55:00.653172  1784 net.cpp:122] Setting up scale_conv11
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 198682800
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer relu_conv11
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer relu_conv11
I1005 08:55:00.653172  1784 net.cpp:406] relu_conv11 <- conv11
I1005 08:55:00.653172  1784 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up relu_conv11
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 199578800
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer conv12
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer conv12
I1005 08:55:00.653172  1784 net.cpp:406] conv12 <- conv11
I1005 08:55:00.653172  1784 net.cpp:380] conv12 -> conv12
I1005 08:55:00.653172  1784 net.cpp:122] Setting up conv12
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 200679600
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer bn_conv12
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer bn_conv12
I1005 08:55:00.653172  1784 net.cpp:406] bn_conv12 <- conv12
I1005 08:55:00.653172  1784 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up bn_conv12
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 201780400
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale_conv12
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer scale_conv12
I1005 08:55:00.653172  1784 net.cpp:406] scale_conv12 <- conv12
I1005 08:55:00.653172  1784 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer scale_conv12
I1005 08:55:00.653172  1784 net.cpp:122] Setting up scale_conv12
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 202881200
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer relu_conv12
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer relu_conv12
I1005 08:55:00.653172  1784 net.cpp:406] relu_conv12 <- conv12
I1005 08:55:00.653172  1784 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1005 08:55:00.653172  1784 net.cpp:122] Setting up relu_conv12
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 203982000
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer poolcp6
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer poolcp6
I1005 08:55:00.653172  1784 net.cpp:406] poolcp6 <- conv12
I1005 08:55:00.653172  1784 net.cpp:380] poolcp6 -> poolcp6
I1005 08:55:00.653172  1784 net.cpp:122] Setting up poolcp6
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 203999200
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer ip1
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer ip1
I1005 08:55:00.653172  1784 net.cpp:406] ip1 <- poolcp6
I1005 08:55:00.653172  1784 net.cpp:380] ip1 -> ip1
I1005 08:55:00.653172  1784 net.cpp:122] Setting up ip1
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 10 (1000)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 204003200
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer ip1_ip1_0_split
I1005 08:55:00.653172  1784 net.cpp:406] ip1_ip1_0_split <- ip1
I1005 08:55:00.653172  1784 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1005 08:55:00.653172  1784 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1005 08:55:00.653172  1784 net.cpp:122] Setting up ip1_ip1_0_split
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 10 (1000)
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: 100 10 (1000)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 204011200
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer accuracy_training
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer accuracy_training
I1005 08:55:00.653172  1784 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1005 08:55:00.653172  1784 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1005 08:55:00.653172  1784 net.cpp:380] accuracy_training -> accuracy_training
I1005 08:55:00.653172  1784 net.cpp:122] Setting up accuracy_training
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: (1)
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 204011204
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer loss
I1005 08:55:00.653172  1784 net.cpp:84] Creating Layer loss
I1005 08:55:00.653172  1784 net.cpp:406] loss <- ip1_ip1_0_split_1
I1005 08:55:00.653172  1784 net.cpp:406] loss <- label_cifar_1_split_1
I1005 08:55:00.653172  1784 net.cpp:380] loss -> loss
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer loss
I1005 08:55:00.653172  1784 net.cpp:122] Setting up loss
I1005 08:55:00.653172  1784 net.cpp:129] Top shape: (1)
I1005 08:55:00.653172  1784 net.cpp:132]     with loss weight 1
I1005 08:55:00.653172  1784 net.cpp:137] Memory required for data: 204011208
I1005 08:55:00.653172  1784 net.cpp:198] loss needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:200] accuracy_training does not need backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] ip1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] poolcp6 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu_conv12 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale_conv12 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn_conv12 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv12 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu_conv11 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale_conv11 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn_conv11 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv11 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu4_0 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale4_0 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn4_0 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv4_0 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] pool4_2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu4_2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale4_2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn4_2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv4_2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu4_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale4_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn4_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv4_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu4 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale4 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn4 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv4 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] pool2_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu3_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale3_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn3_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv3_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu3 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale3 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn3 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv3 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu2_2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale2_2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn2_2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv2_2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu2_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale2_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn2_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv2_1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv2 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu1_0 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale1_0 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn1_0 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv1_0 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] relu1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] scale1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] bn1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:198] conv1 needs backward computation.
I1005 08:55:00.653172  1784 net.cpp:200] label_cifar_1_split does not need backward computation.
I1005 08:55:00.653172  1784 net.cpp:200] cifar does not need backward computation.
I1005 08:55:00.653172  1784 net.cpp:242] This network produces output accuracy_training
I1005 08:55:00.653172  1784 net.cpp:242] This network produces output loss
I1005 08:55:00.653172  1784 net.cpp:255] Network initialization done.
I1005 08:55:00.653172  1784 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 08:55:00.653172  1784 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 08:55:00.653172  1784 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1005 08:55:00.653172  1784 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1005 08:55:00.653172  1784 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_P7"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1005 08:55:00.653172  1784 layer_factory.cpp:58] Creating layer cifar
I1005 08:55:00.933105  1784 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer cifar
I1005 08:55:00.995604  1784 net.cpp:380] cifar -> data
I1005 08:55:00.995604  1784 net.cpp:380] cifar -> label
I1005 08:55:00.995604  1784 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I1005 08:55:00.995604  1784 data_layer.cpp:45] output data size: 100,3,32,32
I1005 08:55:00.995604  1784 net.cpp:122] Setting up cifar
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 (100)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 1229200
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer label_cifar_1_split
I1005 08:55:00.995604  1784 net.cpp:406] label_cifar_1_split <- label
I1005 08:55:00.995604  1784 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1005 08:55:00.995604  1784 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1005 08:55:00.995604  1784 net.cpp:122] Setting up label_cifar_1_split
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 (100)
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 (100)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 1230000
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer conv1
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer conv1
I1005 08:55:00.995604  1784 net.cpp:406] conv1 <- data
I1005 08:55:00.995604  1784 net.cpp:380] conv1 -> conv1
I1005 08:55:00.995604   596 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1005 08:55:00.995604  1784 net.cpp:122] Setting up conv1
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 3687600
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer bn1
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer bn1
I1005 08:55:00.995604  1784 net.cpp:406] bn1 <- conv1
I1005 08:55:00.995604  1784 net.cpp:367] bn1 -> conv1 (in-place)
I1005 08:55:00.995604  1784 net.cpp:122] Setting up bn1
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 6145200
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer scale1
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer scale1
I1005 08:55:00.995604  1784 net.cpp:406] scale1 <- conv1
I1005 08:55:00.995604  1784 net.cpp:367] scale1 -> conv1 (in-place)
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer scale1
I1005 08:55:00.995604  1784 net.cpp:122] Setting up scale1
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 8602800
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer relu1
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer relu1
I1005 08:55:00.995604  1784 net.cpp:406] relu1 <- conv1
I1005 08:55:00.995604  1784 net.cpp:367] relu1 -> conv1 (in-place)
I1005 08:55:00.995604  1784 net.cpp:122] Setting up relu1
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 6 32 32 (614400)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 11060400
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer conv1_0
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer conv1_0
I1005 08:55:00.995604  1784 net.cpp:406] conv1_0 <- conv1
I1005 08:55:00.995604  1784 net.cpp:380] conv1_0 -> conv1_0
I1005 08:55:00.995604  1784 net.cpp:122] Setting up conv1_0
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 15975600
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer bn1_0
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer bn1_0
I1005 08:55:00.995604  1784 net.cpp:406] bn1_0 <- conv1_0
I1005 08:55:00.995604  1784 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1005 08:55:00.995604  1784 net.cpp:122] Setting up bn1_0
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 20890800
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer scale1_0
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer scale1_0
I1005 08:55:00.995604  1784 net.cpp:406] scale1_0 <- conv1_0
I1005 08:55:00.995604  1784 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer scale1_0
I1005 08:55:00.995604  1784 net.cpp:122] Setting up scale1_0
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 25806000
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer relu1_0
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer relu1_0
I1005 08:55:00.995604  1784 net.cpp:406] relu1_0 <- conv1_0
I1005 08:55:00.995604  1784 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1005 08:55:00.995604  1784 net.cpp:122] Setting up relu1_0
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 30721200
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer conv2
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer conv2
I1005 08:55:00.995604  1784 net.cpp:406] conv2 <- conv1_0
I1005 08:55:00.995604  1784 net.cpp:380] conv2 -> conv2
I1005 08:55:00.995604  1784 net.cpp:122] Setting up conv2
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 35636400
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer bn2
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer bn2
I1005 08:55:00.995604  1784 net.cpp:406] bn2 <- conv2
I1005 08:55:00.995604  1784 net.cpp:367] bn2 -> conv2 (in-place)
I1005 08:55:00.995604  1784 net.cpp:122] Setting up bn2
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 40551600
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer scale2
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer scale2
I1005 08:55:00.995604  1784 net.cpp:406] scale2 <- conv2
I1005 08:55:00.995604  1784 net.cpp:367] scale2 -> conv2 (in-place)
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer scale2
I1005 08:55:00.995604  1784 net.cpp:122] Setting up scale2
I1005 08:55:00.995604  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:00.995604  1784 net.cpp:137] Memory required for data: 45466800
I1005 08:55:00.995604  1784 layer_factory.cpp:58] Creating layer relu2
I1005 08:55:00.995604  1784 net.cpp:84] Creating Layer relu2
I1005 08:55:00.995604  1784 net.cpp:406] relu2 <- conv2
I1005 08:55:00.995604  1784 net.cpp:367] relu2 -> conv2 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up relu2
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 50382000
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer conv2_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer conv2_1
I1005 08:55:01.011219  1784 net.cpp:406] conv2_1 <- conv2
I1005 08:55:01.011219  1784 net.cpp:380] conv2_1 -> conv2_1
I1005 08:55:01.011219  1784 net.cpp:122] Setting up conv2_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 55297200
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer bn2_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer bn2_1
I1005 08:55:01.011219  1784 net.cpp:406] bn2_1 <- conv2_1
I1005 08:55:01.011219  1784 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up bn2_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 60212400
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale2_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer scale2_1
I1005 08:55:01.011219  1784 net.cpp:406] scale2_1 <- conv2_1
I1005 08:55:01.011219  1784 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale2_1
I1005 08:55:01.011219  1784 net.cpp:122] Setting up scale2_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 65127600
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer relu2_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer relu2_1
I1005 08:55:01.011219  1784 net.cpp:406] relu2_1 <- conv2_1
I1005 08:55:01.011219  1784 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up relu2_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 70042800
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer conv2_2
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer conv2_2
I1005 08:55:01.011219  1784 net.cpp:406] conv2_2 <- conv2_1
I1005 08:55:01.011219  1784 net.cpp:380] conv2_2 -> conv2_2
I1005 08:55:01.011219  1784 net.cpp:122] Setting up conv2_2
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 77825200
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer bn2_2
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer bn2_2
I1005 08:55:01.011219  1784 net.cpp:406] bn2_2 <- conv2_2
I1005 08:55:01.011219  1784 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up bn2_2
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 85607600
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale2_2
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer scale2_2
I1005 08:55:01.011219  1784 net.cpp:406] scale2_2 <- conv2_2
I1005 08:55:01.011219  1784 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale2_2
I1005 08:55:01.011219  1784 net.cpp:122] Setting up scale2_2
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 93390000
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer relu2_2
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer relu2_2
I1005 08:55:01.011219  1784 net.cpp:406] relu2_2 <- conv2_2
I1005 08:55:01.011219  1784 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up relu2_2
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 101172400
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer conv3
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer conv3
I1005 08:55:01.011219  1784 net.cpp:406] conv3 <- conv2_2
I1005 08:55:01.011219  1784 net.cpp:380] conv3 -> conv3
I1005 08:55:01.011219  1784 net.cpp:122] Setting up conv3
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 108954800
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer bn3
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer bn3
I1005 08:55:01.011219  1784 net.cpp:406] bn3 <- conv3
I1005 08:55:01.011219  1784 net.cpp:367] bn3 -> conv3 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up bn3
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 116737200
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale3
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer scale3
I1005 08:55:01.011219  1784 net.cpp:406] scale3 <- conv3
I1005 08:55:01.011219  1784 net.cpp:367] scale3 -> conv3 (in-place)
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale3
I1005 08:55:01.011219  1784 net.cpp:122] Setting up scale3
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 124519600
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer relu3
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer relu3
I1005 08:55:01.011219  1784 net.cpp:406] relu3 <- conv3
I1005 08:55:01.011219  1784 net.cpp:367] relu3 -> conv3 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up relu3
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 132302000
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer conv3_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer conv3_1
I1005 08:55:01.011219  1784 net.cpp:406] conv3_1 <- conv3
I1005 08:55:01.011219  1784 net.cpp:380] conv3_1 -> conv3_1
I1005 08:55:01.011219  1784 net.cpp:122] Setting up conv3_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 140084400
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer bn3_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer bn3_1
I1005 08:55:01.011219  1784 net.cpp:406] bn3_1 <- conv3_1
I1005 08:55:01.011219  1784 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up bn3_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 147866800
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale3_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer scale3_1
I1005 08:55:01.011219  1784 net.cpp:406] scale3_1 <- conv3_1
I1005 08:55:01.011219  1784 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale3_1
I1005 08:55:01.011219  1784 net.cpp:122] Setting up scale3_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 155649200
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer relu3_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer relu3_1
I1005 08:55:01.011219  1784 net.cpp:406] relu3_1 <- conv3_1
I1005 08:55:01.011219  1784 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up relu3_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 163431600
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer pool2_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer pool2_1
I1005 08:55:01.011219  1784 net.cpp:406] pool2_1 <- conv3_1
I1005 08:55:01.011219  1784 net.cpp:380] pool2_1 -> pool2_1
I1005 08:55:01.011219  1784 net.cpp:122] Setting up pool2_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 165377200
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer conv4
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer conv4
I1005 08:55:01.011219  1784 net.cpp:406] conv4 <- pool2_1
I1005 08:55:01.011219  1784 net.cpp:380] conv4 -> conv4
I1005 08:55:01.011219  1784 net.cpp:122] Setting up conv4
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 167322800
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer bn4
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer bn4
I1005 08:55:01.011219  1784 net.cpp:406] bn4 <- conv4
I1005 08:55:01.011219  1784 net.cpp:367] bn4 -> conv4 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up bn4
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 169268400
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale4
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer scale4
I1005 08:55:01.011219  1784 net.cpp:406] scale4 <- conv4
I1005 08:55:01.011219  1784 net.cpp:367] scale4 -> conv4 (in-place)
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale4
I1005 08:55:01.011219  1784 net.cpp:122] Setting up scale4
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 171214000
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer relu4
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer relu4
I1005 08:55:01.011219  1784 net.cpp:406] relu4 <- conv4
I1005 08:55:01.011219  1784 net.cpp:367] relu4 -> conv4 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up relu4
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 173159600
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer conv4_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer conv4_1
I1005 08:55:01.011219  1784 net.cpp:406] conv4_1 <- conv4
I1005 08:55:01.011219  1784 net.cpp:380] conv4_1 -> conv4_1
I1005 08:55:01.011219  1784 net.cpp:122] Setting up conv4_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 175105200
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer bn4_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer bn4_1
I1005 08:55:01.011219  1784 net.cpp:406] bn4_1 <- conv4_1
I1005 08:55:01.011219  1784 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up bn4_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 177050800
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale4_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer scale4_1
I1005 08:55:01.011219  1784 net.cpp:406] scale4_1 <- conv4_1
I1005 08:55:01.011219  1784 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale4_1
I1005 08:55:01.011219  1784 net.cpp:122] Setting up scale4_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 178996400
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer relu4_1
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer relu4_1
I1005 08:55:01.011219  1784 net.cpp:406] relu4_1 <- conv4_1
I1005 08:55:01.011219  1784 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up relu4_1
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 19 16 16 (486400)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 180942000
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer conv4_2
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer conv4_2
I1005 08:55:01.011219  1784 net.cpp:406] conv4_2 <- conv4_1
I1005 08:55:01.011219  1784 net.cpp:380] conv4_2 -> conv4_2
I1005 08:55:01.011219  1784 net.cpp:122] Setting up conv4_2
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 183809200
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer bn4_2
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer bn4_2
I1005 08:55:01.011219  1784 net.cpp:406] bn4_2 <- conv4_2
I1005 08:55:01.011219  1784 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up bn4_2
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 186676400
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale4_2
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer scale4_2
I1005 08:55:01.011219  1784 net.cpp:406] scale4_2 <- conv4_2
I1005 08:55:01.011219  1784 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale4_2
I1005 08:55:01.011219  1784 net.cpp:122] Setting up scale4_2
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 189543600
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer relu4_2
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer relu4_2
I1005 08:55:01.011219  1784 net.cpp:406] relu4_2 <- conv4_2
I1005 08:55:01.011219  1784 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up relu4_2
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 28 16 16 (716800)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 192410800
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer pool4_2
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer pool4_2
I1005 08:55:01.011219  1784 net.cpp:406] pool4_2 <- conv4_2
I1005 08:55:01.011219  1784 net.cpp:380] pool4_2 -> pool4_2
I1005 08:55:01.011219  1784 net.cpp:122] Setting up pool4_2
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 193127600
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer conv4_0
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer conv4_0
I1005 08:55:01.011219  1784 net.cpp:406] conv4_0 <- pool4_2
I1005 08:55:01.011219  1784 net.cpp:380] conv4_0 -> conv4_0
I1005 08:55:01.011219  1784 net.cpp:122] Setting up conv4_0
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 193844400
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer bn4_0
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer bn4_0
I1005 08:55:01.011219  1784 net.cpp:406] bn4_0 <- conv4_0
I1005 08:55:01.011219  1784 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1005 08:55:01.011219  1784 net.cpp:122] Setting up bn4_0
I1005 08:55:01.011219  1784 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 08:55:01.011219  1784 net.cpp:137] Memory required for data: 194561200
I1005 08:55:01.011219  1784 layer_factory.cpp:58] Creating layer scale4_0
I1005 08:55:01.011219  1784 net.cpp:84] Creating Layer scale4_0
I1005 08:55:01.011219  1784 net.cpp:406] scale4_0 <- conv4_0
I1005 08:55:01.011219  1784 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer scale4_0
I1005 08:55:01.026854  1784 net.cpp:122] Setting up scale4_0
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 195278000
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer relu4_0
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer relu4_0
I1005 08:55:01.026854  1784 net.cpp:406] relu4_0 <- conv4_0
I1005 08:55:01.026854  1784 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1005 08:55:01.026854  1784 net.cpp:122] Setting up relu4_0
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 28 8 8 (179200)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 195994800
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer conv11
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer conv11
I1005 08:55:01.026854  1784 net.cpp:406] conv11 <- conv4_0
I1005 08:55:01.026854  1784 net.cpp:380] conv11 -> conv11
I1005 08:55:01.026854  1784 net.cpp:122] Setting up conv11
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 196890800
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer bn_conv11
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer bn_conv11
I1005 08:55:01.026854  1784 net.cpp:406] bn_conv11 <- conv11
I1005 08:55:01.026854  1784 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1005 08:55:01.026854  1784 net.cpp:122] Setting up bn_conv11
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 197786800
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer scale_conv11
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer scale_conv11
I1005 08:55:01.026854  1784 net.cpp:406] scale_conv11 <- conv11
I1005 08:55:01.026854  1784 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer scale_conv11
I1005 08:55:01.026854  1784 net.cpp:122] Setting up scale_conv11
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 198682800
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer relu_conv11
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer relu_conv11
I1005 08:55:01.026854  1784 net.cpp:406] relu_conv11 <- conv11
I1005 08:55:01.026854  1784 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1005 08:55:01.026854  1784 net.cpp:122] Setting up relu_conv11
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 35 8 8 (224000)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 199578800
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer conv12
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer conv12
I1005 08:55:01.026854  1784 net.cpp:406] conv12 <- conv11
I1005 08:55:01.026854  1784 net.cpp:380] conv12 -> conv12
I1005 08:55:01.026854  1784 net.cpp:122] Setting up conv12
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 200679600
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer bn_conv12
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer bn_conv12
I1005 08:55:01.026854  1784 net.cpp:406] bn_conv12 <- conv12
I1005 08:55:01.026854  1784 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1005 08:55:01.026854  1784 net.cpp:122] Setting up bn_conv12
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 201780400
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer scale_conv12
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer scale_conv12
I1005 08:55:01.026854  1784 net.cpp:406] scale_conv12 <- conv12
I1005 08:55:01.026854  1784 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer scale_conv12
I1005 08:55:01.026854  1784 net.cpp:122] Setting up scale_conv12
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 202881200
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer relu_conv12
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer relu_conv12
I1005 08:55:01.026854  1784 net.cpp:406] relu_conv12 <- conv12
I1005 08:55:01.026854  1784 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1005 08:55:01.026854  1784 net.cpp:122] Setting up relu_conv12
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 43 8 8 (275200)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 203982000
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer poolcp6
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer poolcp6
I1005 08:55:01.026854  1784 net.cpp:406] poolcp6 <- conv12
I1005 08:55:01.026854  1784 net.cpp:380] poolcp6 -> poolcp6
I1005 08:55:01.026854  1784 net.cpp:122] Setting up poolcp6
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 43 1 1 (4300)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 203999200
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer ip1
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer ip1
I1005 08:55:01.026854  1784 net.cpp:406] ip1 <- poolcp6
I1005 08:55:01.026854  1784 net.cpp:380] ip1 -> ip1
I1005 08:55:01.026854  1784 net.cpp:122] Setting up ip1
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 10 (1000)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 204003200
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer ip1_ip1_0_split
I1005 08:55:01.026854  1784 net.cpp:406] ip1_ip1_0_split <- ip1
I1005 08:55:01.026854  1784 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1005 08:55:01.026854  1784 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1005 08:55:01.026854  1784 net.cpp:122] Setting up ip1_ip1_0_split
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 10 (1000)
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: 100 10 (1000)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 204011200
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer accuracy
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer accuracy
I1005 08:55:01.026854  1784 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1005 08:55:01.026854  1784 net.cpp:406] accuracy <- label_cifar_1_split_0
I1005 08:55:01.026854  1784 net.cpp:380] accuracy -> accuracy
I1005 08:55:01.026854  1784 net.cpp:122] Setting up accuracy
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: (1)
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 204011204
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer loss
I1005 08:55:01.026854  1784 net.cpp:84] Creating Layer loss
I1005 08:55:01.026854  1784 net.cpp:406] loss <- ip1_ip1_0_split_1
I1005 08:55:01.026854  1784 net.cpp:406] loss <- label_cifar_1_split_1
I1005 08:55:01.026854  1784 net.cpp:380] loss -> loss
I1005 08:55:01.026854  1784 layer_factory.cpp:58] Creating layer loss
I1005 08:55:01.026854  1784 net.cpp:122] Setting up loss
I1005 08:55:01.026854  1784 net.cpp:129] Top shape: (1)
I1005 08:55:01.026854  1784 net.cpp:132]     with loss weight 1
I1005 08:55:01.026854  1784 net.cpp:137] Memory required for data: 204011208
I1005 08:55:01.026854  1784 net.cpp:198] loss needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:200] accuracy does not need backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] ip1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] poolcp6 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu_conv12 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale_conv12 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn_conv12 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv12 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu_conv11 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale_conv11 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn_conv11 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv11 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu4_0 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale4_0 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn4_0 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv4_0 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] pool4_2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu4_2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale4_2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn4_2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv4_2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu4_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale4_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn4_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv4_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu4 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale4 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn4 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv4 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] pool2_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu3_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale3_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn3_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv3_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu3 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale3 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn3 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv3 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu2_2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale2_2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn2_2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv2_2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu2_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale2_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn2_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv2_1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv2 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu1_0 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale1_0 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn1_0 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv1_0 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] relu1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] scale1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] bn1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:198] conv1 needs backward computation.
I1005 08:55:01.026854  1784 net.cpp:200] label_cifar_1_split does not need backward computation.
I1005 08:55:01.026854  1784 net.cpp:200] cifar does not need backward computation.
I1005 08:55:01.026854  1784 net.cpp:242] This network produces output accuracy
I1005 08:55:01.026854  1784 net.cpp:242] This network produces output loss
I1005 08:55:01.026854  1784 net.cpp:255] Network initialization done.
I1005 08:55:01.026854  1784 solver.cpp:56] Solver scaffolding done.
I1005 08:55:01.026854  1784 caffe.cpp:249] Starting Optimization
I1005 08:55:01.026854  1784 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_drpall_Simple_P7
I1005 08:55:01.026854  1784 solver.cpp:273] Learning Rate Policy: multistep
I1005 08:55:01.026854  1784 solver.cpp:330] Iteration 0, Testing net (#0)
I1005 08:55:01.026854  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 08:55:01.026854  1784 blocking_queue.cpp:49] Waiting for data
I1005 08:55:04.408695   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:55:04.408695  1784 solver.cpp:397]     Test net output #0: accuracy = 0.0999
I1005 08:55:04.408695  1784 solver.cpp:397]     Test net output #1: loss = 78.6116 (* 1 = 78.6116 loss)
I1005 08:55:04.486807  1784 solver.cpp:218] Iteration 0 (3.7002e+37 iter/s, 3.44917s/100 iters), loss = 4.74846
I1005 08:55:04.486807  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.06
I1005 08:55:04.486807  1784 solver.cpp:237]     Train net output #1: loss = 4.74846 (* 1 = 4.74846 loss)
I1005 08:55:04.486807  1784 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1005 08:55:07.918257  1784 solver.cpp:218] Iteration 100 (29.0886 iter/s, 3.43777s/100 iters), loss = 1.65071
I1005 08:55:07.918257  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1005 08:55:07.918257  1784 solver.cpp:237]     Train net output #1: loss = 1.65071 (* 1 = 1.65071 loss)
I1005 08:55:07.918257  1784 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1005 08:55:11.689904  1784 solver.cpp:218] Iteration 200 (26.5448 iter/s, 3.76721s/100 iters), loss = 1.69103
I1005 08:55:11.689904  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1005 08:55:11.689904  1784 solver.cpp:237]     Train net output #1: loss = 1.69103 (* 1 = 1.69103 loss)
I1005 08:55:11.689904  1784 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1005 08:55:14.925994  1784 solver.cpp:218] Iteration 300 (30.8789 iter/s, 3.23846s/100 iters), loss = 1.45025
I1005 08:55:14.925994  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1005 08:55:14.925994  1784 solver.cpp:237]     Train net output #1: loss = 1.45025 (* 1 = 1.45025 loss)
I1005 08:55:14.925994  1784 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1005 08:55:18.148169  1784 solver.cpp:218] Iteration 400 (30.9497 iter/s, 3.23105s/100 iters), loss = 1.30171
I1005 08:55:18.148169  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1005 08:55:18.148169  1784 solver.cpp:237]     Train net output #1: loss = 1.30171 (* 1 = 1.30171 loss)
I1005 08:55:18.148169  1784 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1005 08:55:21.228796 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:55:21.390776  1784 solver.cpp:218] Iteration 500 (30.9471 iter/s, 3.23132s/100 iters), loss = 1.39701
I1005 08:55:21.390776  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1005 08:55:21.390776  1784 solver.cpp:237]     Train net output #1: loss = 1.39701 (* 1 = 1.39701 loss)
I1005 08:55:21.390776  1784 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1005 08:55:24.620365  1784 solver.cpp:218] Iteration 600 (30.9977 iter/s, 3.22604s/100 iters), loss = 1.38698
I1005 08:55:24.620365  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1005 08:55:24.620365  1784 solver.cpp:237]     Train net output #1: loss = 1.38698 (* 1 = 1.38698 loss)
I1005 08:55:24.620365  1784 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1005 08:55:27.893296  1784 solver.cpp:218] Iteration 700 (30.5541 iter/s, 3.27288s/100 iters), loss = 1.3802
I1005 08:55:27.893296  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1005 08:55:27.893296  1784 solver.cpp:237]     Train net output #1: loss = 1.3802 (* 1 = 1.3802 loss)
I1005 08:55:27.893296  1784 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1005 08:55:31.117995  1784 solver.cpp:218] Iteration 800 (30.9653 iter/s, 3.22942s/100 iters), loss = 1.27683
I1005 08:55:31.117995  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1005 08:55:31.117995  1784 solver.cpp:237]     Train net output #1: loss = 1.27683 (* 1 = 1.27683 loss)
I1005 08:55:31.117995  1784 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1005 08:55:34.343461  1784 solver.cpp:218] Iteration 900 (30.9258 iter/s, 3.23355s/100 iters), loss = 1.00301
I1005 08:55:34.343461  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1005 08:55:34.343461  1784 solver.cpp:237]     Train net output #1: loss = 1.00301 (* 1 = 1.00301 loss)
I1005 08:55:34.343461  1784 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1005 08:55:37.410436 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:55:37.551061  1784 solver.cpp:330] Iteration 1000, Testing net (#0)
I1005 08:55:37.551061  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 08:55:38.190325   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:55:38.221575  1784 solver.cpp:397]     Test net output #0: accuracy = 0.576
I1005 08:55:38.221575  1784 solver.cpp:397]     Test net output #1: loss = 1.18325 (* 1 = 1.18325 loss)
I1005 08:55:38.252826  1784 solver.cpp:218] Iteration 1000 (25.6622 iter/s, 3.89678s/100 iters), loss = 1.19459
I1005 08:55:38.252826  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1005 08:55:38.252826  1784 solver.cpp:237]     Train net output #1: loss = 1.19459 (* 1 = 1.19459 loss)
I1005 08:55:38.252826  1784 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1005 08:55:41.474141  1784 solver.cpp:218] Iteration 1100 (30.9833 iter/s, 3.22754s/100 iters), loss = 1.05992
I1005 08:55:41.474141  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1005 08:55:41.474141  1784 solver.cpp:237]     Train net output #1: loss = 1.05992 (* 1 = 1.05992 loss)
I1005 08:55:41.474141  1784 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1005 08:55:44.699807  1784 solver.cpp:218] Iteration 1200 (30.9666 iter/s, 3.22929s/100 iters), loss = 1.1082
I1005 08:55:44.699807  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1005 08:55:44.699807  1784 solver.cpp:237]     Train net output #1: loss = 1.1082 (* 1 = 1.1082 loss)
I1005 08:55:44.699807  1784 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1005 08:55:47.938197  1784 solver.cpp:218] Iteration 1300 (30.9527 iter/s, 3.23074s/100 iters), loss = 1.07139
I1005 08:55:47.938197  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1005 08:55:47.938197  1784 solver.cpp:237]     Train net output #1: loss = 1.07139 (* 1 = 1.07139 loss)
I1005 08:55:47.938197  1784 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1005 08:55:51.165865  1784 solver.cpp:218] Iteration 1400 (30.9625 iter/s, 3.22971s/100 iters), loss = 0.775437
I1005 08:55:51.165865  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1005 08:55:51.165865  1784 solver.cpp:237]     Train net output #1: loss = 0.775437 (* 1 = 0.775437 loss)
I1005 08:55:51.165865  1784 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1005 08:55:54.246393 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:55:54.396345  1784 solver.cpp:218] Iteration 1500 (30.9461 iter/s, 3.23143s/100 iters), loss = 0.953052
I1005 08:55:54.396345  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1005 08:55:54.396345  1784 solver.cpp:237]     Train net output #1: loss = 0.953052 (* 1 = 0.953052 loss)
I1005 08:55:54.396345  1784 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1005 08:55:57.630472  1784 solver.cpp:218] Iteration 1600 (30.9647 iter/s, 3.22949s/100 iters), loss = 0.995815
I1005 08:55:57.630472  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1005 08:55:57.630472  1784 solver.cpp:237]     Train net output #1: loss = 0.995815 (* 1 = 0.995815 loss)
I1005 08:55:57.630472  1784 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1005 08:56:00.860554  1784 solver.cpp:218] Iteration 1700 (30.9302 iter/s, 3.23309s/100 iters), loss = 0.944224
I1005 08:56:00.860554  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 08:56:00.860554  1784 solver.cpp:237]     Train net output #1: loss = 0.944224 (* 1 = 0.944224 loss)
I1005 08:56:00.860554  1784 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1005 08:56:04.095489  1784 solver.cpp:218] Iteration 1800 (30.9397 iter/s, 3.23209s/100 iters), loss = 0.918328
I1005 08:56:04.095489  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 08:56:04.095489  1784 solver.cpp:237]     Train net output #1: loss = 0.918328 (* 1 = 0.918328 loss)
I1005 08:56:04.095489  1784 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1005 08:56:07.325753  1784 solver.cpp:218] Iteration 1900 (31.0054 iter/s, 3.22525s/100 iters), loss = 0.706242
I1005 08:56:07.326756  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1005 08:56:07.326756  1784 solver.cpp:237]     Train net output #1: loss = 0.706242 (* 1 = 0.706242 loss)
I1005 08:56:07.326756  1784 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1005 08:56:10.391139 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:56:10.516139  1784 solver.cpp:330] Iteration 2000, Testing net (#0)
I1005 08:56:10.516139  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 08:56:11.166132   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:56:11.197381  1784 solver.cpp:397]     Test net output #0: accuracy = 0.6676
I1005 08:56:11.197381  1784 solver.cpp:397]     Test net output #1: loss = 0.943933 (* 1 = 0.943933 loss)
I1005 08:56:11.228634  1784 solver.cpp:218] Iteration 2000 (25.6225 iter/s, 3.90282s/100 iters), loss = 0.858637
I1005 08:56:11.228634  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 08:56:11.228634  1784 solver.cpp:237]     Train net output #1: loss = 0.858637 (* 1 = 0.858637 loss)
I1005 08:56:11.228634  1784 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1005 08:56:14.464820  1784 solver.cpp:218] Iteration 2100 (30.9011 iter/s, 3.23613s/100 iters), loss = 0.882892
I1005 08:56:14.464820  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 08:56:14.464820  1784 solver.cpp:237]     Train net output #1: loss = 0.882892 (* 1 = 0.882892 loss)
I1005 08:56:14.464820  1784 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1005 08:56:17.684165  1784 solver.cpp:218] Iteration 2200 (30.9318 iter/s, 3.23292s/100 iters), loss = 0.800316
I1005 08:56:17.684165  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1005 08:56:17.684165  1784 solver.cpp:237]     Train net output #1: loss = 0.800316 (* 1 = 0.800316 loss)
I1005 08:56:17.684165  1784 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1005 08:56:20.933593  1784 solver.cpp:218] Iteration 2300 (30.8912 iter/s, 3.23717s/100 iters), loss = 0.722957
I1005 08:56:20.933593  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1005 08:56:20.933593  1784 solver.cpp:237]     Train net output #1: loss = 0.722957 (* 1 = 0.722957 loss)
I1005 08:56:20.933593  1784 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1005 08:56:24.167546  1784 solver.cpp:218] Iteration 2400 (30.906 iter/s, 3.23562s/100 iters), loss = 0.69446
I1005 08:56:24.167546  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 08:56:24.167546  1784 solver.cpp:237]     Train net output #1: loss = 0.69446 (* 1 = 0.69446 loss)
I1005 08:56:24.167546  1784 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1005 08:56:27.238349 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:56:27.392705  1784 solver.cpp:218] Iteration 2500 (30.9316 iter/s, 3.23294s/100 iters), loss = 0.734725
I1005 08:56:27.392705  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1005 08:56:27.392705  1784 solver.cpp:237]     Train net output #1: loss = 0.734725 (* 1 = 0.734725 loss)
I1005 08:56:27.392705  1784 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1005 08:56:30.634536  1784 solver.cpp:218] Iteration 2600 (30.8989 iter/s, 3.23636s/100 iters), loss = 0.816244
I1005 08:56:30.634536  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1005 08:56:30.634536  1784 solver.cpp:237]     Train net output #1: loss = 0.816244 (* 1 = 0.816244 loss)
I1005 08:56:30.634536  1784 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1005 08:56:33.873996  1784 solver.cpp:218] Iteration 2700 (30.9529 iter/s, 3.23071s/100 iters), loss = 0.711422
I1005 08:56:33.873996  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 08:56:33.873996  1784 solver.cpp:237]     Train net output #1: loss = 0.711422 (* 1 = 0.711422 loss)
I1005 08:56:33.873996  1784 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1005 08:56:37.101925  1784 solver.cpp:218] Iteration 2800 (30.8962 iter/s, 3.23664s/100 iters), loss = 0.767484
I1005 08:56:37.101925  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1005 08:56:37.101925  1784 solver.cpp:237]     Train net output #1: loss = 0.767484 (* 1 = 0.767484 loss)
I1005 08:56:37.101925  1784 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1005 08:56:40.336750  1784 solver.cpp:218] Iteration 2900 (30.9243 iter/s, 3.2337s/100 iters), loss = 0.669876
I1005 08:56:40.336750  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1005 08:56:40.336750  1784 solver.cpp:237]     Train net output #1: loss = 0.669876 (* 1 = 0.669876 loss)
I1005 08:56:40.336750  1784 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1005 08:56:43.423286 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:56:43.548286  1784 solver.cpp:330] Iteration 3000, Testing net (#0)
I1005 08:56:43.548286  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 08:56:44.191566   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:56:44.222816  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7039
I1005 08:56:44.222816  1784 solver.cpp:397]     Test net output #1: loss = 0.837702 (* 1 = 0.837702 loss)
I1005 08:56:44.254065  1784 solver.cpp:218] Iteration 3000 (25.5676 iter/s, 3.9112s/100 iters), loss = 0.721665
I1005 08:56:44.254065  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 08:56:44.254065  1784 solver.cpp:237]     Train net output #1: loss = 0.721665 (* 1 = 0.721665 loss)
I1005 08:56:44.254065  1784 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1005 08:56:47.478669  1784 solver.cpp:218] Iteration 3100 (30.9277 iter/s, 3.23335s/100 iters), loss = 0.671146
I1005 08:56:47.478669  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 08:56:47.478669  1784 solver.cpp:237]     Train net output #1: loss = 0.671146 (* 1 = 0.671146 loss)
I1005 08:56:47.478669  1784 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1005 08:56:50.723901  1784 solver.cpp:218] Iteration 3200 (30.819 iter/s, 3.24475s/100 iters), loss = 0.634185
I1005 08:56:50.723901  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 08:56:50.723901  1784 solver.cpp:237]     Train net output #1: loss = 0.634185 (* 1 = 0.634185 loss)
I1005 08:56:50.723901  1784 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1005 08:56:53.969223  1784 solver.cpp:218] Iteration 3300 (30.9004 iter/s, 3.23621s/100 iters), loss = 0.665143
I1005 08:56:53.969223  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 08:56:53.969223  1784 solver.cpp:237]     Train net output #1: loss = 0.665143 (* 1 = 0.665143 loss)
I1005 08:56:53.969223  1784 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1005 08:56:57.194744  1784 solver.cpp:218] Iteration 3400 (30.9484 iter/s, 3.23119s/100 iters), loss = 0.58395
I1005 08:56:57.194744  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1005 08:56:57.194744  1784 solver.cpp:237]     Train net output #1: loss = 0.58395 (* 1 = 0.58395 loss)
I1005 08:56:57.194744  1784 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1005 08:57:00.266569 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:57:00.434916  1784 solver.cpp:218] Iteration 3500 (30.9249 iter/s, 3.23364s/100 iters), loss = 0.760851
I1005 08:57:00.434916  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1005 08:57:00.434916  1784 solver.cpp:237]     Train net output #1: loss = 0.760851 (* 1 = 0.760851 loss)
I1005 08:57:00.434916  1784 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1005 08:57:03.659209  1784 solver.cpp:218] Iteration 3600 (30.9424 iter/s, 3.23181s/100 iters), loss = 0.650054
I1005 08:57:03.659209  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1005 08:57:03.659209  1784 solver.cpp:237]     Train net output #1: loss = 0.650054 (* 1 = 0.650054 loss)
I1005 08:57:03.659209  1784 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1005 08:57:06.892762  1784 solver.cpp:218] Iteration 3700 (30.8965 iter/s, 3.23662s/100 iters), loss = 0.644596
I1005 08:57:06.892762  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 08:57:06.892762  1784 solver.cpp:237]     Train net output #1: loss = 0.644596 (* 1 = 0.644596 loss)
I1005 08:57:06.892762  1784 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1005 08:57:10.125479  1784 solver.cpp:218] Iteration 3800 (30.9273 iter/s, 3.23339s/100 iters), loss = 0.675959
I1005 08:57:10.125479  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 08:57:10.125479  1784 solver.cpp:237]     Train net output #1: loss = 0.675959 (* 1 = 0.675959 loss)
I1005 08:57:10.125479  1784 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1005 08:57:13.374888  1784 solver.cpp:218] Iteration 3900 (30.8628 iter/s, 3.24015s/100 iters), loss = 0.561142
I1005 08:57:13.374888  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 08:57:13.374888  1784 solver.cpp:237]     Train net output #1: loss = 0.561142 (* 1 = 0.561142 loss)
I1005 08:57:13.374888  1784 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1005 08:57:16.455339 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:57:16.580339  1784 solver.cpp:330] Iteration 4000, Testing net (#0)
I1005 08:57:16.580339  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 08:57:17.223140   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:57:17.254389  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7339
I1005 08:57:17.254389  1784 solver.cpp:397]     Test net output #1: loss = 0.75162 (* 1 = 0.75162 loss)
I1005 08:57:17.285641  1784 solver.cpp:218] Iteration 4000 (25.5827 iter/s, 3.90889s/100 iters), loss = 0.697975
I1005 08:57:17.285641  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1005 08:57:17.285641  1784 solver.cpp:237]     Train net output #1: loss = 0.697975 (* 1 = 0.697975 loss)
I1005 08:57:17.285641  1784 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1005 08:57:20.514535  1784 solver.cpp:218] Iteration 4100 (30.9224 iter/s, 3.23391s/100 iters), loss = 0.560113
I1005 08:57:20.514535  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 08:57:20.514535  1784 solver.cpp:237]     Train net output #1: loss = 0.560113 (* 1 = 0.560113 loss)
I1005 08:57:20.514535  1784 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1005 08:57:23.751423  1784 solver.cpp:218] Iteration 4200 (30.91 iter/s, 3.2352s/100 iters), loss = 0.526782
I1005 08:57:23.751423  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 08:57:23.751423  1784 solver.cpp:237]     Train net output #1: loss = 0.526782 (* 1 = 0.526782 loss)
I1005 08:57:23.751423  1784 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1005 08:57:26.987480  1784 solver.cpp:218] Iteration 4300 (30.9727 iter/s, 3.22865s/100 iters), loss = 0.607103
I1005 08:57:26.987480  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 08:57:26.987480  1784 solver.cpp:237]     Train net output #1: loss = 0.607103 (* 1 = 0.607103 loss)
I1005 08:57:26.987480  1784 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1005 08:57:30.212450  1784 solver.cpp:218] Iteration 4400 (30.9691 iter/s, 3.22902s/100 iters), loss = 0.582276
I1005 08:57:30.212450  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 08:57:30.212450  1784 solver.cpp:237]     Train net output #1: loss = 0.582276 (* 1 = 0.582276 loss)
I1005 08:57:30.212450  1784 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1005 08:57:33.286615 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:57:33.448742  1784 solver.cpp:218] Iteration 4500 (30.8879 iter/s, 3.23751s/100 iters), loss = 0.677613
I1005 08:57:33.448742  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1005 08:57:33.448742  1784 solver.cpp:237]     Train net output #1: loss = 0.677613 (* 1 = 0.677613 loss)
I1005 08:57:33.448742  1784 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1005 08:57:36.682883  1784 solver.cpp:218] Iteration 4600 (30.9262 iter/s, 3.2335s/100 iters), loss = 0.590845
I1005 08:57:36.682883  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 08:57:36.682883  1784 solver.cpp:237]     Train net output #1: loss = 0.590845 (* 1 = 0.590845 loss)
I1005 08:57:36.682883  1784 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1005 08:57:39.921210  1784 solver.cpp:218] Iteration 4700 (30.9211 iter/s, 3.23404s/100 iters), loss = 0.558118
I1005 08:57:39.921210  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 08:57:39.921210  1784 solver.cpp:237]     Train net output #1: loss = 0.558118 (* 1 = 0.558118 loss)
I1005 08:57:39.921210  1784 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1005 08:57:43.153604  1784 solver.cpp:218] Iteration 4800 (30.9056 iter/s, 3.23566s/100 iters), loss = 0.613257
I1005 08:57:43.153604  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 08:57:43.153604  1784 solver.cpp:237]     Train net output #1: loss = 0.613257 (* 1 = 0.613257 loss)
I1005 08:57:43.153604  1784 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1005 08:57:46.390322  1784 solver.cpp:218] Iteration 4900 (30.9419 iter/s, 3.23186s/100 iters), loss = 0.585085
I1005 08:57:46.390322  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 08:57:46.390322  1784 solver.cpp:237]     Train net output #1: loss = 0.585085 (* 1 = 0.585085 loss)
I1005 08:57:46.390322  1784 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1005 08:57:49.469492 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:57:49.594486  1784 solver.cpp:330] Iteration 5000, Testing net (#0)
I1005 08:57:49.594486  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 08:57:50.241397   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:57:50.257022  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7226
I1005 08:57:50.257022  1784 solver.cpp:397]     Test net output #1: loss = 0.816128 (* 1 = 0.816128 loss)
I1005 08:57:50.288271  1784 solver.cpp:218] Iteration 5000 (25.5995 iter/s, 3.90633s/100 iters), loss = 0.570984
I1005 08:57:50.288271  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 08:57:50.288271  1784 solver.cpp:237]     Train net output #1: loss = 0.570984 (* 1 = 0.570984 loss)
I1005 08:57:50.288271  1784 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I1005 08:57:50.288271  1784 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I1005 08:57:53.523072  1784 solver.cpp:218] Iteration 5100 (30.8938 iter/s, 3.2369s/100 iters), loss = 0.557939
I1005 08:57:53.523072  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 08:57:53.523072  1784 solver.cpp:237]     Train net output #1: loss = 0.557939 (* 1 = 0.557939 loss)
I1005 08:57:53.523072  1784 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I1005 08:57:56.767748  1784 solver.cpp:218] Iteration 5200 (30.916 iter/s, 3.23457s/100 iters), loss = 0.495051
I1005 08:57:56.767748  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 08:57:56.767748  1784 solver.cpp:237]     Train net output #1: loss = 0.495051 (* 1 = 0.495051 loss)
I1005 08:57:56.767748  1784 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I1005 08:57:59.997221  1784 solver.cpp:218] Iteration 5300 (30.8951 iter/s, 3.23676s/100 iters), loss = 0.466407
I1005 08:57:59.997221  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 08:57:59.997221  1784 solver.cpp:237]     Train net output #1: loss = 0.466407 (* 1 = 0.466407 loss)
I1005 08:57:59.997221  1784 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I1005 08:58:03.233332  1784 solver.cpp:218] Iteration 5400 (30.8932 iter/s, 3.23695s/100 iters), loss = 0.473541
I1005 08:58:03.233332  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 08:58:03.233332  1784 solver.cpp:237]     Train net output #1: loss = 0.473541 (* 1 = 0.473541 loss)
I1005 08:58:03.233332  1784 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I1005 08:58:06.325037 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:58:06.474445  1784 solver.cpp:218] Iteration 5500 (30.8949 iter/s, 3.23678s/100 iters), loss = 0.540597
I1005 08:58:06.474445  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 08:58:06.474445  1784 solver.cpp:237]     Train net output #1: loss = 0.540597 (* 1 = 0.540597 loss)
I1005 08:58:06.474445  1784 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I1005 08:58:09.706290  1784 solver.cpp:218] Iteration 5600 (30.9201 iter/s, 3.23414s/100 iters), loss = 0.52426
I1005 08:58:09.706290  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 08:58:09.706290  1784 solver.cpp:237]     Train net output #1: loss = 0.52426 (* 1 = 0.52426 loss)
I1005 08:58:09.706290  1784 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I1005 08:58:12.938982  1784 solver.cpp:218] Iteration 5700 (30.9118 iter/s, 3.23501s/100 iters), loss = 0.382397
I1005 08:58:12.938982  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 08:58:12.938982  1784 solver.cpp:237]     Train net output #1: loss = 0.382397 (* 1 = 0.382397 loss)
I1005 08:58:12.938982  1784 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I1005 08:58:16.181198  1784 solver.cpp:218] Iteration 5800 (30.9252 iter/s, 3.2336s/100 iters), loss = 0.481116
I1005 08:58:16.181198  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 08:58:16.181198  1784 solver.cpp:237]     Train net output #1: loss = 0.481116 (* 1 = 0.481116 loss)
I1005 08:58:16.181198  1784 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I1005 08:58:19.422525  1784 solver.cpp:218] Iteration 5900 (30.8928 iter/s, 3.237s/100 iters), loss = 0.418745
I1005 08:58:19.422525  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 08:58:19.422525  1784 solver.cpp:237]     Train net output #1: loss = 0.418745 (* 1 = 0.418745 loss)
I1005 08:58:19.422525  1784 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I1005 08:58:22.497666 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:58:22.622663  1784 solver.cpp:330] Iteration 6000, Testing net (#0)
I1005 08:58:22.622663  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 08:58:23.265970   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:58:23.297235  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7869
I1005 08:58:23.297235  1784 solver.cpp:397]     Test net output #1: loss = 0.616837 (* 1 = 0.616837 loss)
I1005 08:58:23.328474  1784 solver.cpp:218] Iteration 6000 (25.5599 iter/s, 3.91238s/100 iters), loss = 0.51924
I1005 08:58:23.328474  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 08:58:23.328474  1784 solver.cpp:237]     Train net output #1: loss = 0.51924 (* 1 = 0.51924 loss)
I1005 08:58:23.328474  1784 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I1005 08:58:26.574548  1784 solver.cpp:218] Iteration 6100 (30.8645 iter/s, 3.23997s/100 iters), loss = 0.523168
I1005 08:58:26.574548  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 08:58:26.574548  1784 solver.cpp:237]     Train net output #1: loss = 0.523168 (* 1 = 0.523168 loss)
I1005 08:58:26.574548  1784 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I1005 08:58:29.800777  1784 solver.cpp:218] Iteration 6200 (30.9068 iter/s, 3.23554s/100 iters), loss = 0.409139
I1005 08:58:29.800777  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 08:58:29.800777  1784 solver.cpp:237]     Train net output #1: loss = 0.409139 (* 1 = 0.409139 loss)
I1005 08:58:29.800777  1784 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I1005 08:58:33.035193  1784 solver.cpp:218] Iteration 6300 (30.8904 iter/s, 3.23725s/100 iters), loss = 0.513808
I1005 08:58:33.035193  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 08:58:33.035193  1784 solver.cpp:237]     Train net output #1: loss = 0.513808 (* 1 = 0.513808 loss)
I1005 08:58:33.035193  1784 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I1005 08:58:36.276721  1784 solver.cpp:218] Iteration 6400 (30.9365 iter/s, 3.23243s/100 iters), loss = 0.491358
I1005 08:58:36.276721  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 08:58:36.276721  1784 solver.cpp:237]     Train net output #1: loss = 0.491358 (* 1 = 0.491358 loss)
I1005 08:58:36.276721  1784 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I1005 08:58:39.349174 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:58:39.505424  1784 solver.cpp:218] Iteration 6500 (30.9454 iter/s, 3.2315s/100 iters), loss = 0.483177
I1005 08:58:39.505424  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 08:58:39.505424  1784 solver.cpp:237]     Train net output #1: loss = 0.483177 (* 1 = 0.483177 loss)
I1005 08:58:39.505424  1784 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I1005 08:58:42.745452  1784 solver.cpp:218] Iteration 6600 (30.9134 iter/s, 3.23484s/100 iters), loss = 0.470669
I1005 08:58:42.745452  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 08:58:42.745452  1784 solver.cpp:237]     Train net output #1: loss = 0.470669 (* 1 = 0.470669 loss)
I1005 08:58:42.745452  1784 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I1005 08:58:45.981885  1784 solver.cpp:218] Iteration 6700 (30.9237 iter/s, 3.23376s/100 iters), loss = 0.410279
I1005 08:58:45.981885  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 08:58:45.981885  1784 solver.cpp:237]     Train net output #1: loss = 0.410279 (* 1 = 0.410279 loss)
I1005 08:58:45.981885  1784 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I1005 08:58:49.205456  1784 solver.cpp:218] Iteration 6800 (30.9219 iter/s, 3.23395s/100 iters), loss = 0.486552
I1005 08:58:49.205456  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 08:58:49.205456  1784 solver.cpp:237]     Train net output #1: loss = 0.486552 (* 1 = 0.486552 loss)
I1005 08:58:49.205456  1784 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I1005 08:58:52.435115  1784 solver.cpp:218] Iteration 6900 (30.9515 iter/s, 3.23087s/100 iters), loss = 0.462617
I1005 08:58:52.435115  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 08:58:52.435115  1784 solver.cpp:237]     Train net output #1: loss = 0.462617 (* 1 = 0.462617 loss)
I1005 08:58:52.435115  1784 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I1005 08:58:55.526337 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:58:55.651335  1784 solver.cpp:330] Iteration 7000, Testing net (#0)
I1005 08:58:55.651335  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 08:58:56.291960   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:58:56.330883  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7864
I1005 08:58:56.330883  1784 solver.cpp:397]     Test net output #1: loss = 0.615373 (* 1 = 0.615373 loss)
I1005 08:58:56.353583  1784 solver.cpp:218] Iteration 7000 (25.5617 iter/s, 3.91211s/100 iters), loss = 0.456243
I1005 08:58:56.353583  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 08:58:56.353583  1784 solver.cpp:237]     Train net output #1: loss = 0.456243 (* 1 = 0.456243 loss)
I1005 08:58:56.353583  1784 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I1005 08:58:59.586376  1784 solver.cpp:218] Iteration 7100 (30.8925 iter/s, 3.23703s/100 iters), loss = 0.488159
I1005 08:58:59.586376  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 08:58:59.586376  1784 solver.cpp:237]     Train net output #1: loss = 0.488159 (* 1 = 0.488159 loss)
I1005 08:58:59.586376  1784 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I1005 08:59:02.840878  1784 solver.cpp:218] Iteration 7200 (30.7401 iter/s, 3.25308s/100 iters), loss = 0.430336
I1005 08:59:02.840878  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 08:59:02.840878  1784 solver.cpp:237]     Train net output #1: loss = 0.430336 (* 1 = 0.430336 loss)
I1005 08:59:02.840878  1784 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I1005 08:59:06.105840  1784 solver.cpp:218] Iteration 7300 (30.73 iter/s, 3.25415s/100 iters), loss = 0.424111
I1005 08:59:06.105840  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 08:59:06.105840  1784 solver.cpp:237]     Train net output #1: loss = 0.424111 (* 1 = 0.424111 loss)
I1005 08:59:06.105840  1784 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I1005 08:59:09.347785  1784 solver.cpp:218] Iteration 7400 (30.8242 iter/s, 3.2442s/100 iters), loss = 0.459081
I1005 08:59:09.347785  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 08:59:09.347785  1784 solver.cpp:237]     Train net output #1: loss = 0.459081 (* 1 = 0.459081 loss)
I1005 08:59:09.347785  1784 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I1005 08:59:12.421947 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:59:12.582020  1784 solver.cpp:218] Iteration 7500 (30.8464 iter/s, 3.24186s/100 iters), loss = 0.531251
I1005 08:59:12.582020  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 08:59:12.582020  1784 solver.cpp:237]     Train net output #1: loss = 0.531251 (* 1 = 0.531251 loss)
I1005 08:59:12.582020  1784 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I1005 08:59:15.843850  1784 solver.cpp:218] Iteration 7600 (30.7605 iter/s, 3.25092s/100 iters), loss = 0.466793
I1005 08:59:15.843850  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 08:59:15.843850  1784 solver.cpp:237]     Train net output #1: loss = 0.466793 (* 1 = 0.466793 loss)
I1005 08:59:15.843850  1784 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I1005 08:59:16.889547  1784 solver.cpp:218] Iteration 7700 (30.8668 iter/s, 3.23973s/100 iters), loss = 0.425868
I1005 08:59:16.889547  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 08:59:16.889547  1784 solver.cpp:237]     Train net output #1: loss = 0.425868 (* 1 = 0.425868 loss)
I1005 08:59:16.889547  1784 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I1005 08:59:20.135664  1784 solver.cpp:218] Iteration 7800 (30.8063 iter/s, 3.24609s/100 iters), loss = 0.411913
I1005 08:59:20.135664  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 08:59:20.135664  1784 solver.cpp:237]     Train net output #1: loss = 0.411913 (* 1 = 0.411913 loss)
I1005 08:59:20.135664  1784 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I1005 08:59:23.371734  1784 solver.cpp:218] Iteration 7900 (30.8557 iter/s, 3.24089s/100 iters), loss = 0.463238
I1005 08:59:23.371734  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 08:59:23.371734  1784 solver.cpp:237]     Train net output #1: loss = 0.463238 (* 1 = 0.463238 loss)
I1005 08:59:23.371734  1784 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I1005 08:59:26.466670 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:59:26.591668  1784 solver.cpp:330] Iteration 8000, Testing net (#0)
I1005 08:59:26.591668  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 08:59:27.236290   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:59:27.267540  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7882
I1005 08:59:27.267540  1784 solver.cpp:397]     Test net output #1: loss = 0.612999 (* 1 = 0.612999 loss)
I1005 08:59:27.298804  1784 solver.cpp:218] Iteration 8000 (25.4697 iter/s, 3.92623s/100 iters), loss = 0.523595
I1005 08:59:27.298804  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1005 08:59:27.298804  1784 solver.cpp:237]     Train net output #1: loss = 0.523595 (* 1 = 0.523595 loss)
I1005 08:59:27.298804  1784 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I1005 08:59:30.556603  1784 solver.cpp:218] Iteration 8100 (30.6684 iter/s, 3.26068s/100 iters), loss = 0.494816
I1005 08:59:30.556603  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 08:59:30.556603  1784 solver.cpp:237]     Train net output #1: loss = 0.494816 (* 1 = 0.494816 loss)
I1005 08:59:30.556603  1784 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I1005 08:59:33.814268  1784 solver.cpp:218] Iteration 8200 (30.7416 iter/s, 3.25292s/100 iters), loss = 0.410511
I1005 08:59:33.814268  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 08:59:33.814268  1784 solver.cpp:237]     Train net output #1: loss = 0.410511 (* 1 = 0.410511 loss)
I1005 08:59:33.814268  1784 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I1005 08:59:37.061702  1784 solver.cpp:218] Iteration 8300 (30.7504 iter/s, 3.25199s/100 iters), loss = 0.439143
I1005 08:59:37.061702  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 08:59:37.061702  1784 solver.cpp:237]     Train net output #1: loss = 0.439143 (* 1 = 0.439143 loss)
I1005 08:59:37.061702  1784 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I1005 08:59:40.320474  1784 solver.cpp:218] Iteration 8400 (30.767 iter/s, 3.25024s/100 iters), loss = 0.404774
I1005 08:59:40.320474  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 08:59:40.320474  1784 solver.cpp:237]     Train net output #1: loss = 0.404774 (* 1 = 0.404774 loss)
I1005 08:59:40.320474  1784 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I1005 08:59:43.414047 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:59:43.570294  1784 solver.cpp:218] Iteration 8500 (30.7378 iter/s, 3.25332s/100 iters), loss = 0.488958
I1005 08:59:43.570294  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 08:59:43.570294  1784 solver.cpp:237]     Train net output #1: loss = 0.488958 (* 1 = 0.488958 loss)
I1005 08:59:43.570294  1784 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I1005 08:59:46.820473  1784 solver.cpp:218] Iteration 8600 (30.7683 iter/s, 3.2501s/100 iters), loss = 0.438373
I1005 08:59:46.820473  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 08:59:46.820473  1784 solver.cpp:237]     Train net output #1: loss = 0.438373 (* 1 = 0.438373 loss)
I1005 08:59:46.820473  1784 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I1005 08:59:50.065773  1784 solver.cpp:218] Iteration 8700 (30.7674 iter/s, 3.2502s/100 iters), loss = 0.360359
I1005 08:59:50.065773  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 08:59:50.065773  1784 solver.cpp:237]     Train net output #1: loss = 0.360359 (* 1 = 0.360359 loss)
I1005 08:59:50.065773  1784 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I1005 08:59:53.315938  1784 solver.cpp:218] Iteration 8800 (30.7507 iter/s, 3.25196s/100 iters), loss = 0.437278
I1005 08:59:53.315938  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 08:59:53.315938  1784 solver.cpp:237]     Train net output #1: loss = 0.437278 (* 1 = 0.437278 loss)
I1005 08:59:53.315938  1784 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I1005 08:59:56.564702  1784 solver.cpp:218] Iteration 8900 (30.7562 iter/s, 3.25138s/100 iters), loss = 0.415616
I1005 08:59:56.580332  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 08:59:56.580332  1784 solver.cpp:237]     Train net output #1: loss = 0.415616 (* 1 = 0.415616 loss)
I1005 08:59:56.580332  1784 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I1005 08:59:59.705927 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 08:59:59.830929  1784 solver.cpp:330] Iteration 9000, Testing net (#0)
I1005 08:59:59.830929  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:00:00.489320   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:00:00.504942  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7911
I1005 09:00:00.504942  1784 solver.cpp:397]     Test net output #1: loss = 0.611726 (* 1 = 0.611726 loss)
I1005 09:00:00.536192  1784 solver.cpp:218] Iteration 9000 (25.221 iter/s, 3.96495s/100 iters), loss = 0.501161
I1005 09:00:00.536192  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1005 09:00:00.536192  1784 solver.cpp:237]     Train net output #1: loss = 0.501161 (* 1 = 0.501161 loss)
I1005 09:00:00.536192  1784 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I1005 09:00:03.794714  1784 solver.cpp:218] Iteration 9100 (30.6943 iter/s, 3.25793s/100 iters), loss = 0.466188
I1005 09:00:03.794714  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:00:03.794714  1784 solver.cpp:237]     Train net output #1: loss = 0.466188 (* 1 = 0.466188 loss)
I1005 09:00:03.794714  1784 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I1005 09:00:07.058573  1784 solver.cpp:218] Iteration 9200 (30.6984 iter/s, 3.2575s/100 iters), loss = 0.345827
I1005 09:00:07.058573  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:00:07.058573  1784 solver.cpp:237]     Train net output #1: loss = 0.345827 (* 1 = 0.345827 loss)
I1005 09:00:07.058573  1784 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I1005 09:00:10.320268  1784 solver.cpp:218] Iteration 9300 (30.5841 iter/s, 3.26967s/100 iters), loss = 0.441255
I1005 09:00:10.320268  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:00:10.320268  1784 solver.cpp:237]     Train net output #1: loss = 0.441255 (* 1 = 0.441255 loss)
I1005 09:00:10.320268  1784 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I1005 09:00:13.605206  1784 solver.cpp:218] Iteration 9400 (30.5448 iter/s, 3.27388s/100 iters), loss = 0.420654
I1005 09:00:13.605206  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:00:13.605206  1784 solver.cpp:237]     Train net output #1: loss = 0.420654 (* 1 = 0.420654 loss)
I1005 09:00:13.605206  1784 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I1005 09:00:16.689885 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:00:16.846132  1784 solver.cpp:218] Iteration 9500 (30.7527 iter/s, 3.25175s/100 iters), loss = 0.461178
I1005 09:00:16.846132  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 09:00:16.846132  1784 solver.cpp:237]     Train net output #1: loss = 0.461178 (* 1 = 0.461178 loss)
I1005 09:00:16.846132  1784 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1005 09:00:20.104249  1784 solver.cpp:218] Iteration 9600 (30.7232 iter/s, 3.25487s/100 iters), loss = 0.441253
I1005 09:00:20.104249  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:00:20.104249  1784 solver.cpp:237]     Train net output #1: loss = 0.441253 (* 1 = 0.441253 loss)
I1005 09:00:20.104249  1784 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1005 09:00:23.367439  1784 solver.cpp:218] Iteration 9700 (30.7052 iter/s, 3.25678s/100 iters), loss = 0.364148
I1005 09:00:23.367439  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:00:23.367439  1784 solver.cpp:237]     Train net output #1: loss = 0.364148 (* 1 = 0.364148 loss)
I1005 09:00:23.367439  1784 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I1005 09:00:26.632298  1784 solver.cpp:218] Iteration 9800 (30.6544 iter/s, 3.26217s/100 iters), loss = 0.419716
I1005 09:00:26.632298  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:00:26.632298  1784 solver.cpp:237]     Train net output #1: loss = 0.419716 (* 1 = 0.419716 loss)
I1005 09:00:26.632298  1784 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1005 09:00:29.875247  1784 solver.cpp:218] Iteration 9900 (30.778 iter/s, 3.24907s/100 iters), loss = 0.469943
I1005 09:00:29.875247  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:00:29.875247  1784 solver.cpp:237]     Train net output #1: loss = 0.469943 (* 1 = 0.469943 loss)
I1005 09:00:29.875247  1784 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I1005 09:00:32.965876 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:00:33.106501  1784 solver.cpp:330] Iteration 10000, Testing net (#0)
I1005 09:00:33.106501  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:00:33.747128   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:00:33.778378  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7901
I1005 09:00:33.778378  1784 solver.cpp:397]     Test net output #1: loss = 0.611267 (* 1 = 0.611267 loss)
I1005 09:00:33.809641  1784 solver.cpp:218] Iteration 10000 (25.4182 iter/s, 3.93419s/100 iters), loss = 0.437711
I1005 09:00:33.809641  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 09:00:33.809641  1784 solver.cpp:237]     Train net output #1: loss = 0.437711 (* 1 = 0.437711 loss)
I1005 09:00:33.809641  1784 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I1005 09:00:33.809641  1784 sgd_solver.cpp:105] Iteration 10000, lr = 0.0001
I1005 09:00:37.063665  1784 solver.cpp:218] Iteration 10100 (30.7545 iter/s, 3.25156s/100 iters), loss = 0.403821
I1005 09:00:37.063665  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:00:37.063665  1784 solver.cpp:237]     Train net output #1: loss = 0.403821 (* 1 = 0.403821 loss)
I1005 09:00:37.063665  1784 sgd_solver.cpp:105] Iteration 10100, lr = 0.0001
I1005 09:00:40.302690  1784 solver.cpp:218] Iteration 10200 (30.7959 iter/s, 3.24718s/100 iters), loss = 0.375721
I1005 09:00:40.302690  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 09:00:40.302690  1784 solver.cpp:237]     Train net output #1: loss = 0.375721 (* 1 = 0.375721 loss)
I1005 09:00:40.302690  1784 sgd_solver.cpp:105] Iteration 10200, lr = 0.0001
I1005 09:00:43.562819  1784 solver.cpp:218] Iteration 10300 (30.706 iter/s, 3.25669s/100 iters), loss = 0.411468
I1005 09:00:43.562819  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:00:43.562819  1784 solver.cpp:237]     Train net output #1: loss = 0.411468 (* 1 = 0.411468 loss)
I1005 09:00:43.562819  1784 sgd_solver.cpp:105] Iteration 10300, lr = 0.0001
I1005 09:00:46.828970  1784 solver.cpp:218] Iteration 10400 (30.651 iter/s, 3.26254s/100 iters), loss = 0.415815
I1005 09:00:46.828970  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 09:00:46.828970  1784 solver.cpp:237]     Train net output #1: loss = 0.415815 (* 1 = 0.415815 loss)
I1005 09:00:46.828970  1784 sgd_solver.cpp:105] Iteration 10400, lr = 0.0001
I1005 09:00:49.930848 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:00:50.102717  1784 solver.cpp:218] Iteration 10500 (30.6096 iter/s, 3.26695s/100 iters), loss = 0.44554
I1005 09:00:50.102717  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 09:00:50.102717  1784 solver.cpp:237]     Train net output #1: loss = 0.44554 (* 1 = 0.44554 loss)
I1005 09:00:50.102717  1784 sgd_solver.cpp:105] Iteration 10500, lr = 0.0001
I1005 09:00:53.350162  1784 solver.cpp:218] Iteration 10600 (30.6907 iter/s, 3.25832s/100 iters), loss = 0.384059
I1005 09:00:53.350162  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:00:53.350162  1784 solver.cpp:237]     Train net output #1: loss = 0.384059 (* 1 = 0.384059 loss)
I1005 09:00:53.350162  1784 sgd_solver.cpp:105] Iteration 10600, lr = 0.0001
I1005 09:00:56.615072  1784 solver.cpp:218] Iteration 10700 (30.688 iter/s, 3.25861s/100 iters), loss = 0.341439
I1005 09:00:56.615072  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:00:56.615072  1784 solver.cpp:237]     Train net output #1: loss = 0.341439 (* 1 = 0.341439 loss)
I1005 09:00:56.615072  1784 sgd_solver.cpp:105] Iteration 10700, lr = 0.0001
I1005 09:00:59.867203  1784 solver.cpp:218] Iteration 10800 (30.7871 iter/s, 3.24811s/100 iters), loss = 0.46112
I1005 09:00:59.867203  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:00:59.867203  1784 solver.cpp:237]     Train net output #1: loss = 0.46112 (* 1 = 0.46112 loss)
I1005 09:00:59.867203  1784 sgd_solver.cpp:105] Iteration 10800, lr = 0.0001
I1005 09:01:03.132015  1784 solver.cpp:218] Iteration 10900 (30.6574 iter/s, 3.26185s/100 iters), loss = 0.392104
I1005 09:01:03.132015  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:01:03.132015  1784 solver.cpp:237]     Train net output #1: loss = 0.392104 (* 1 = 0.392104 loss)
I1005 09:01:03.132015  1784 sgd_solver.cpp:105] Iteration 10900, lr = 0.0001
I1005 09:01:06.209877 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:01:06.352212  1784 solver.cpp:330] Iteration 11000, Testing net (#0)
I1005 09:01:06.352212  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:01:06.989573   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:01:07.020823  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7924
I1005 09:01:07.020823  1784 solver.cpp:397]     Test net output #1: loss = 0.602851 (* 1 = 0.602851 loss)
I1005 09:01:07.052073  1784 solver.cpp:218] Iteration 11000 (25.4808 iter/s, 3.92453s/100 iters), loss = 0.439563
I1005 09:01:07.052073  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:01:07.052073  1784 solver.cpp:237]     Train net output #1: loss = 0.439563 (* 1 = 0.439563 loss)
I1005 09:01:07.052073  1784 sgd_solver.cpp:105] Iteration 11000, lr = 0.0001
I1005 09:01:10.291487  1784 solver.cpp:218] Iteration 11100 (30.8659 iter/s, 3.23982s/100 iters), loss = 0.430986
I1005 09:01:10.291487  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:01:10.291487  1784 solver.cpp:237]     Train net output #1: loss = 0.430986 (* 1 = 0.430986 loss)
I1005 09:01:10.291487  1784 sgd_solver.cpp:105] Iteration 11100, lr = 0.0001
I1005 09:01:13.538988  1784 solver.cpp:218] Iteration 11200 (30.7842 iter/s, 3.24842s/100 iters), loss = 0.354169
I1005 09:01:13.538988  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:01:13.538988  1784 solver.cpp:237]     Train net output #1: loss = 0.354169 (* 1 = 0.354169 loss)
I1005 09:01:13.538988  1784 sgd_solver.cpp:105] Iteration 11200, lr = 0.0001
I1005 09:01:16.786134  1784 solver.cpp:218] Iteration 11300 (30.8147 iter/s, 3.2452s/100 iters), loss = 0.404239
I1005 09:01:16.786134  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:01:16.786134  1784 solver.cpp:237]     Train net output #1: loss = 0.404239 (* 1 = 0.404239 loss)
I1005 09:01:16.786134  1784 sgd_solver.cpp:105] Iteration 11300, lr = 0.0001
I1005 09:01:20.025550  1784 solver.cpp:218] Iteration 11400 (30.7826 iter/s, 3.24859s/100 iters), loss = 0.39677
I1005 09:01:20.025550  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:01:20.025550  1784 solver.cpp:237]     Train net output #1: loss = 0.39677 (* 1 = 0.39677 loss)
I1005 09:01:20.025550  1784 sgd_solver.cpp:105] Iteration 11400, lr = 0.0001
I1005 09:01:23.116107 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:01:23.272356  1784 solver.cpp:218] Iteration 11500 (30.8301 iter/s, 3.24359s/100 iters), loss = 0.41532
I1005 09:01:23.272356  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 09:01:23.272356  1784 solver.cpp:237]     Train net output #1: loss = 0.41532 (* 1 = 0.41532 loss)
I1005 09:01:23.272356  1784 sgd_solver.cpp:105] Iteration 11500, lr = 0.0001
I1005 09:01:26.527405  1784 solver.cpp:218] Iteration 11600 (30.7824 iter/s, 3.24861s/100 iters), loss = 0.356331
I1005 09:01:26.527405  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:01:26.527405  1784 solver.cpp:237]     Train net output #1: loss = 0.356331 (* 1 = 0.356331 loss)
I1005 09:01:26.527405  1784 sgd_solver.cpp:105] Iteration 11600, lr = 0.0001
I1005 09:01:29.767643  1784 solver.cpp:218] Iteration 11700 (30.8273 iter/s, 3.24388s/100 iters), loss = 0.348297
I1005 09:01:29.767643  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:01:29.767643  1784 solver.cpp:237]     Train net output #1: loss = 0.348297 (* 1 = 0.348297 loss)
I1005 09:01:29.767643  1784 sgd_solver.cpp:105] Iteration 11700, lr = 0.0001
I1005 09:01:33.012208  1784 solver.cpp:218] Iteration 11800 (30.8305 iter/s, 3.24354s/100 iters), loss = 0.434363
I1005 09:01:33.012208  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:01:33.012208  1784 solver.cpp:237]     Train net output #1: loss = 0.434363 (* 1 = 0.434363 loss)
I1005 09:01:33.012208  1784 sgd_solver.cpp:105] Iteration 11800, lr = 0.0001
I1005 09:01:36.271061  1784 solver.cpp:218] Iteration 11900 (30.7731 iter/s, 3.24959s/100 iters), loss = 0.407177
I1005 09:01:36.271061  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:01:36.271061  1784 solver.cpp:237]     Train net output #1: loss = 0.407177 (* 1 = 0.407177 loss)
I1005 09:01:36.271061  1784 sgd_solver.cpp:105] Iteration 11900, lr = 0.0001
I1005 09:01:39.353993 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:01:39.478993  1784 solver.cpp:330] Iteration 12000, Testing net (#0)
I1005 09:01:39.478993  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:01:40.146173   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:01:40.161797  1784 solver.cpp:397]     Test net output #0: accuracy = 0.794
I1005 09:01:40.161797  1784 solver.cpp:397]     Test net output #1: loss = 0.601979 (* 1 = 0.601979 loss)
I1005 09:01:40.193045  1784 solver.cpp:218] Iteration 12000 (25.4117 iter/s, 3.93519s/100 iters), loss = 0.505656
I1005 09:01:40.193045  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 09:01:40.193045  1784 solver.cpp:237]     Train net output #1: loss = 0.505656 (* 1 = 0.505656 loss)
I1005 09:01:40.193045  1784 sgd_solver.cpp:105] Iteration 12000, lr = 0.0001
I1005 09:01:43.457156  1784 solver.cpp:218] Iteration 12100 (30.698 iter/s, 3.25754s/100 iters), loss = 0.432413
I1005 09:01:43.457156  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:01:43.457156  1784 solver.cpp:237]     Train net output #1: loss = 0.432413 (* 1 = 0.432413 loss)
I1005 09:01:43.457156  1784 sgd_solver.cpp:105] Iteration 12100, lr = 0.0001
I1005 09:01:46.712868  1784 solver.cpp:218] Iteration 12200 (30.7804 iter/s, 3.24882s/100 iters), loss = 0.359853
I1005 09:01:46.712868  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:01:46.712868  1784 solver.cpp:237]     Train net output #1: loss = 0.359853 (* 1 = 0.359853 loss)
I1005 09:01:46.712868  1784 sgd_solver.cpp:105] Iteration 12200, lr = 0.0001
I1005 09:01:49.949681  1784 solver.cpp:218] Iteration 12300 (30.8392 iter/s, 3.24262s/100 iters), loss = 0.439852
I1005 09:01:49.949681  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:01:49.949681  1784 solver.cpp:237]     Train net output #1: loss = 0.439852 (* 1 = 0.439852 loss)
I1005 09:01:49.949681  1784 sgd_solver.cpp:105] Iteration 12300, lr = 0.0001
I1005 09:01:53.204679  1784 solver.cpp:218] Iteration 12400 (30.6822 iter/s, 3.25922s/100 iters), loss = 0.41848
I1005 09:01:53.204679  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:01:53.204679  1784 solver.cpp:237]     Train net output #1: loss = 0.41848 (* 1 = 0.41848 loss)
I1005 09:01:53.204679  1784 sgd_solver.cpp:105] Iteration 12400, lr = 0.0001
I1005 09:01:56.303845 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:01:56.477566  1784 solver.cpp:218] Iteration 12500 (30.6715 iter/s, 3.26036s/100 iters), loss = 0.488959
I1005 09:01:56.477566  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1005 09:01:56.477566  1784 solver.cpp:237]     Train net output #1: loss = 0.488959 (* 1 = 0.488959 loss)
I1005 09:01:56.477566  1784 sgd_solver.cpp:105] Iteration 12500, lr = 0.0001
I1005 09:01:59.714059  1784 solver.cpp:218] Iteration 12600 (30.7799 iter/s, 3.24888s/100 iters), loss = 0.418178
I1005 09:01:59.714059  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:01:59.714059  1784 solver.cpp:237]     Train net output #1: loss = 0.418178 (* 1 = 0.418178 loss)
I1005 09:01:59.714059  1784 sgd_solver.cpp:105] Iteration 12600, lr = 0.0001
I1005 09:02:02.964999  1784 solver.cpp:218] Iteration 12700 (30.858 iter/s, 3.24065s/100 iters), loss = 0.378887
I1005 09:02:02.964999  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:02:02.964999  1784 solver.cpp:237]     Train net output #1: loss = 0.378887 (* 1 = 0.378887 loss)
I1005 09:02:02.964999  1784 sgd_solver.cpp:105] Iteration 12700, lr = 0.0001
I1005 09:02:06.197357  1784 solver.cpp:218] Iteration 12800 (30.8559 iter/s, 3.24088s/100 iters), loss = 0.453555
I1005 09:02:06.197357  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:02:06.197357  1784 solver.cpp:237]     Train net output #1: loss = 0.453555 (* 1 = 0.453555 loss)
I1005 09:02:06.197357  1784 sgd_solver.cpp:105] Iteration 12800, lr = 0.0001
I1005 09:02:09.431571  1784 solver.cpp:218] Iteration 12900 (30.8921 iter/s, 3.23707s/100 iters), loss = 0.430654
I1005 09:02:09.431571  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:02:09.431571  1784 solver.cpp:237]     Train net output #1: loss = 0.430654 (* 1 = 0.430654 loss)
I1005 09:02:09.431571  1784 sgd_solver.cpp:105] Iteration 12900, lr = 0.0001
I1005 09:02:12.531538 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:02:12.656538  1784 solver.cpp:330] Iteration 13000, Testing net (#0)
I1005 09:02:12.656538  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:02:13.300652   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:02:13.331912  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7944
I1005 09:02:13.331912  1784 solver.cpp:397]     Test net output #1: loss = 0.6023 (* 1 = 0.6023 loss)
I1005 09:02:13.363150  1784 solver.cpp:218] Iteration 13000 (25.5206 iter/s, 3.9184s/100 iters), loss = 0.380932
I1005 09:02:13.363150  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:02:13.363150  1784 solver.cpp:237]     Train net output #1: loss = 0.380932 (* 1 = 0.380932 loss)
I1005 09:02:13.363150  1784 sgd_solver.cpp:105] Iteration 13000, lr = 0.0001
I1005 09:02:16.597334  1784 solver.cpp:218] Iteration 13100 (30.8306 iter/s, 3.24353s/100 iters), loss = 0.411057
I1005 09:02:16.597334  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:02:16.597334  1784 solver.cpp:237]     Train net output #1: loss = 0.411057 (* 1 = 0.411057 loss)
I1005 09:02:16.597334  1784 sgd_solver.cpp:105] Iteration 13100, lr = 0.0001
I1005 09:02:19.840889  1784 solver.cpp:218] Iteration 13200 (30.8475 iter/s, 3.24175s/100 iters), loss = 0.344721
I1005 09:02:19.840889  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:02:19.840889  1784 solver.cpp:237]     Train net output #1: loss = 0.344721 (* 1 = 0.344721 loss)
I1005 09:02:19.840889  1784 sgd_solver.cpp:105] Iteration 13200, lr = 0.0001
I1005 09:02:23.084357  1784 solver.cpp:218] Iteration 13300 (30.8334 iter/s, 3.24323s/100 iters), loss = 0.418409
I1005 09:02:23.084357  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:02:23.084357  1784 solver.cpp:237]     Train net output #1: loss = 0.418409 (* 1 = 0.418409 loss)
I1005 09:02:23.084357  1784 sgd_solver.cpp:105] Iteration 13300, lr = 0.0001
I1005 09:02:26.331097  1784 solver.cpp:218] Iteration 13400 (30.8176 iter/s, 3.2449s/100 iters), loss = 0.399837
I1005 09:02:26.331097  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:02:26.331097  1784 solver.cpp:237]     Train net output #1: loss = 0.399837 (* 1 = 0.399837 loss)
I1005 09:02:26.331097  1784 sgd_solver.cpp:105] Iteration 13400, lr = 0.0001
I1005 09:02:29.418162 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:02:29.576874  1784 solver.cpp:218] Iteration 13500 (30.8196 iter/s, 3.24469s/100 iters), loss = 0.438817
I1005 09:02:29.576874  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 09:02:29.576874  1784 solver.cpp:237]     Train net output #1: loss = 0.438817 (* 1 = 0.438817 loss)
I1005 09:02:29.576874  1784 sgd_solver.cpp:105] Iteration 13500, lr = 0.0001
I1005 09:02:32.820883  1784 solver.cpp:218] Iteration 13600 (30.8377 iter/s, 3.24278s/100 iters), loss = 0.410465
I1005 09:02:32.820883  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:02:32.820883  1784 solver.cpp:237]     Train net output #1: loss = 0.410465 (* 1 = 0.410465 loss)
I1005 09:02:32.820883  1784 sgd_solver.cpp:105] Iteration 13600, lr = 0.0001
I1005 09:02:36.059228  1784 solver.cpp:218] Iteration 13700 (30.8348 iter/s, 3.24309s/100 iters), loss = 0.356149
I1005 09:02:36.059228  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:02:36.059228  1784 solver.cpp:237]     Train net output #1: loss = 0.356149 (* 1 = 0.356149 loss)
I1005 09:02:36.059228  1784 sgd_solver.cpp:105] Iteration 13700, lr = 0.0001
I1005 09:02:39.306643  1784 solver.cpp:218] Iteration 13800 (30.8165 iter/s, 3.24501s/100 iters), loss = 0.438217
I1005 09:02:39.306643  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:02:39.306643  1784 solver.cpp:237]     Train net output #1: loss = 0.438217 (* 1 = 0.438217 loss)
I1005 09:02:39.306643  1784 sgd_solver.cpp:105] Iteration 13800, lr = 0.0001
I1005 09:02:42.558003  1784 solver.cpp:218] Iteration 13900 (30.84 iter/s, 3.24255s/100 iters), loss = 0.409763
I1005 09:02:42.558003  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:02:42.558003  1784 solver.cpp:237]     Train net output #1: loss = 0.409763 (* 1 = 0.409763 loss)
I1005 09:02:42.558003  1784 sgd_solver.cpp:105] Iteration 13900, lr = 0.0001
I1005 09:02:45.646214 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:02:45.771212  1784 solver.cpp:330] Iteration 14000, Testing net (#0)
I1005 09:02:45.771212  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:02:46.408879   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:02:46.440119  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7934
I1005 09:02:46.440119  1784 solver.cpp:397]     Test net output #1: loss = 0.601739 (* 1 = 0.601739 loss)
I1005 09:02:46.471369  1784 solver.cpp:218] Iteration 14000 (25.5227 iter/s, 3.91807s/100 iters), loss = 0.437452
I1005 09:02:46.471369  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 09:02:46.471369  1784 solver.cpp:237]     Train net output #1: loss = 0.437452 (* 1 = 0.437452 loss)
I1005 09:02:46.471369  1784 sgd_solver.cpp:105] Iteration 14000, lr = 0.0001
I1005 09:02:49.716941  1784 solver.cpp:218] Iteration 14100 (30.7784 iter/s, 3.24903s/100 iters), loss = 0.402551
I1005 09:02:49.716941  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:02:49.716941  1784 solver.cpp:237]     Train net output #1: loss = 0.402551 (* 1 = 0.402551 loss)
I1005 09:02:49.716941  1784 sgd_solver.cpp:105] Iteration 14100, lr = 0.0001
I1005 09:02:52.964079  1784 solver.cpp:218] Iteration 14200 (30.8312 iter/s, 3.24347s/100 iters), loss = 0.339884
I1005 09:02:52.964079  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:02:52.964079  1784 solver.cpp:237]     Train net output #1: loss = 0.339884 (* 1 = 0.339884 loss)
I1005 09:02:52.964079  1784 sgd_solver.cpp:105] Iteration 14200, lr = 0.0001
I1005 09:02:56.202544  1784 solver.cpp:218] Iteration 14300 (30.8638 iter/s, 3.24004s/100 iters), loss = 0.401602
I1005 09:02:56.202544  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:02:56.202544  1784 solver.cpp:237]     Train net output #1: loss = 0.401602 (* 1 = 0.401602 loss)
I1005 09:02:56.202544  1784 sgd_solver.cpp:105] Iteration 14300, lr = 0.0001
I1005 09:02:59.441527  1784 solver.cpp:218] Iteration 14400 (30.8595 iter/s, 3.24049s/100 iters), loss = 0.383967
I1005 09:02:59.441527  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:02:59.441527  1784 solver.cpp:237]     Train net output #1: loss = 0.383967 (* 1 = 0.383967 loss)
I1005 09:02:59.441527  1784 sgd_solver.cpp:105] Iteration 14400, lr = 0.0001
I1005 09:03:02.534925 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:03:02.691175  1784 solver.cpp:218] Iteration 14500 (30.793 iter/s, 3.24749s/100 iters), loss = 0.449225
I1005 09:03:02.691175  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:03:02.691175  1784 solver.cpp:237]     Train net output #1: loss = 0.449225 (* 1 = 0.449225 loss)
I1005 09:03:02.691175  1784 sgd_solver.cpp:105] Iteration 14500, lr = 0.0001
I1005 09:03:05.935004  1784 solver.cpp:218] Iteration 14600 (30.8391 iter/s, 3.24263s/100 iters), loss = 0.38952
I1005 09:03:05.935004  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:03:05.935004  1784 solver.cpp:237]     Train net output #1: loss = 0.38952 (* 1 = 0.38952 loss)
I1005 09:03:05.935004  1784 sgd_solver.cpp:105] Iteration 14600, lr = 0.0001
I1005 09:03:09.183626  1784 solver.cpp:218] Iteration 14700 (30.8181 iter/s, 3.24484s/100 iters), loss = 0.335441
I1005 09:03:09.183626  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:03:09.183626  1784 solver.cpp:237]     Train net output #1: loss = 0.335441 (* 1 = 0.335441 loss)
I1005 09:03:09.183626  1784 sgd_solver.cpp:105] Iteration 14700, lr = 0.0001
I1005 09:03:12.425361  1784 solver.cpp:218] Iteration 14800 (30.8658 iter/s, 3.23983s/100 iters), loss = 0.411195
I1005 09:03:12.425361  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:03:12.425361  1784 solver.cpp:237]     Train net output #1: loss = 0.411195 (* 1 = 0.411195 loss)
I1005 09:03:12.425361  1784 sgd_solver.cpp:105] Iteration 14800, lr = 0.0001
I1005 09:03:15.660164  1784 solver.cpp:218] Iteration 14900 (30.8744 iter/s, 3.23893s/100 iters), loss = 0.419314
I1005 09:03:15.660164  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:03:15.660164  1784 solver.cpp:237]     Train net output #1: loss = 0.419314 (* 1 = 0.419314 loss)
I1005 09:03:15.660164  1784 sgd_solver.cpp:105] Iteration 14900, lr = 0.0001
I1005 09:03:18.749506 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:03:18.868011  1784 solver.cpp:330] Iteration 15000, Testing net (#0)
I1005 09:03:18.868011  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:03:19.518580   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:03:19.552248  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7937
I1005 09:03:19.552248  1784 solver.cpp:397]     Test net output #1: loss = 0.601866 (* 1 = 0.601866 loss)
I1005 09:03:19.583498  1784 solver.cpp:218] Iteration 15000 (25.5362 iter/s, 3.91601s/100 iters), loss = 0.405698
I1005 09:03:19.583498  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:03:19.583498  1784 solver.cpp:237]     Train net output #1: loss = 0.405698 (* 1 = 0.405698 loss)
I1005 09:03:19.583498  1784 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I1005 09:03:19.583498  1784 sgd_solver.cpp:105] Iteration 15000, lr = 1e-05
I1005 09:03:22.826807  1784 solver.cpp:218] Iteration 15100 (30.8326 iter/s, 3.24332s/100 iters), loss = 0.417385
I1005 09:03:22.826807  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:03:22.826807  1784 solver.cpp:237]     Train net output #1: loss = 0.417385 (* 1 = 0.417385 loss)
I1005 09:03:22.826807  1784 sgd_solver.cpp:105] Iteration 15100, lr = 1e-05
I1005 09:03:26.066823  1784 solver.cpp:218] Iteration 15200 (30.8512 iter/s, 3.24136s/100 iters), loss = 0.317409
I1005 09:03:26.066823  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:03:26.066823  1784 solver.cpp:237]     Train net output #1: loss = 0.317409 (* 1 = 0.317409 loss)
I1005 09:03:26.066823  1784 sgd_solver.cpp:105] Iteration 15200, lr = 1e-05
I1005 09:03:29.297919  1784 solver.cpp:218] Iteration 15300 (30.8881 iter/s, 3.23749s/100 iters), loss = 0.421648
I1005 09:03:29.297919  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:03:29.297919  1784 solver.cpp:237]     Train net output #1: loss = 0.421648 (* 1 = 0.421648 loss)
I1005 09:03:29.297919  1784 sgd_solver.cpp:105] Iteration 15300, lr = 1e-05
I1005 09:03:32.549435  1784 solver.cpp:218] Iteration 15400 (30.8343 iter/s, 3.24314s/100 iters), loss = 0.445922
I1005 09:03:32.549435  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 09:03:32.549435  1784 solver.cpp:237]     Train net output #1: loss = 0.445922 (* 1 = 0.445922 loss)
I1005 09:03:32.549435  1784 sgd_solver.cpp:105] Iteration 15400, lr = 1e-05
I1005 09:03:35.628875 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:03:35.785125  1784 solver.cpp:218] Iteration 15500 (30.8549 iter/s, 3.24098s/100 iters), loss = 0.514274
I1005 09:03:35.785125  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1005 09:03:35.785125  1784 solver.cpp:237]     Train net output #1: loss = 0.514274 (* 1 = 0.514274 loss)
I1005 09:03:35.785125  1784 sgd_solver.cpp:105] Iteration 15500, lr = 1e-05
I1005 09:03:39.028144  1784 solver.cpp:218] Iteration 15600 (30.8337 iter/s, 3.24321s/100 iters), loss = 0.415818
I1005 09:03:39.028144  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:03:39.028144  1784 solver.cpp:237]     Train net output #1: loss = 0.415818 (* 1 = 0.415818 loss)
I1005 09:03:39.028144  1784 sgd_solver.cpp:105] Iteration 15600, lr = 1e-05
I1005 09:03:42.276393  1784 solver.cpp:218] Iteration 15700 (30.8469 iter/s, 3.24182s/100 iters), loss = 0.302442
I1005 09:03:42.276393  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:03:42.276393  1784 solver.cpp:237]     Train net output #1: loss = 0.302442 (* 1 = 0.302442 loss)
I1005 09:03:42.276393  1784 sgd_solver.cpp:105] Iteration 15700, lr = 1e-05
I1005 09:03:45.523115  1784 solver.cpp:218] Iteration 15800 (30.8023 iter/s, 3.24651s/100 iters), loss = 0.455945
I1005 09:03:45.523115  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:03:45.523115  1784 solver.cpp:237]     Train net output #1: loss = 0.455945 (* 1 = 0.455945 loss)
I1005 09:03:45.523115  1784 sgd_solver.cpp:105] Iteration 15800, lr = 1e-05
I1005 09:03:48.767333  1784 solver.cpp:218] Iteration 15900 (30.8145 iter/s, 3.24522s/100 iters), loss = 0.372324
I1005 09:03:48.767333  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:03:48.767333  1784 solver.cpp:237]     Train net output #1: loss = 0.372324 (* 1 = 0.372324 loss)
I1005 09:03:48.767333  1784 sgd_solver.cpp:105] Iteration 15900, lr = 1e-05
I1005 09:03:51.847839 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:03:51.972839  1784 solver.cpp:330] Iteration 16000, Testing net (#0)
I1005 09:03:51.972839  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:03:52.623479   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:03:52.654731  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7928
I1005 09:03:52.654731  1784 solver.cpp:397]     Test net output #1: loss = 0.601958 (* 1 = 0.601958 loss)
I1005 09:03:52.685979  1784 solver.cpp:218] Iteration 16000 (25.5084 iter/s, 3.92027s/100 iters), loss = 0.43799
I1005 09:03:52.685979  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 09:03:52.685979  1784 solver.cpp:237]     Train net output #1: loss = 0.43799 (* 1 = 0.43799 loss)
I1005 09:03:52.685979  1784 sgd_solver.cpp:105] Iteration 16000, lr = 1e-05
I1005 09:03:55.916285  1784 solver.cpp:218] Iteration 16100 (30.9169 iter/s, 3.23448s/100 iters), loss = 0.368883
I1005 09:03:55.916285  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:03:55.916285  1784 solver.cpp:237]     Train net output #1: loss = 0.368883 (* 1 = 0.368883 loss)
I1005 09:03:55.916285  1784 sgd_solver.cpp:105] Iteration 16100, lr = 1e-05
I1005 09:03:59.164947  1784 solver.cpp:218] Iteration 16200 (30.8606 iter/s, 3.24038s/100 iters), loss = 0.346634
I1005 09:03:59.164947  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:03:59.164947  1784 solver.cpp:237]     Train net output #1: loss = 0.346634 (* 1 = 0.346634 loss)
I1005 09:03:59.164947  1784 sgd_solver.cpp:105] Iteration 16200, lr = 1e-05
I1005 09:04:02.397866  1784 solver.cpp:218] Iteration 16300 (30.8545 iter/s, 3.24102s/100 iters), loss = 0.430491
I1005 09:04:02.397866  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:04:02.397866  1784 solver.cpp:237]     Train net output #1: loss = 0.430491 (* 1 = 0.430491 loss)
I1005 09:04:02.397866  1784 sgd_solver.cpp:105] Iteration 16300, lr = 1e-05
I1005 09:04:05.634553  1784 solver.cpp:218] Iteration 16400 (30.8835 iter/s, 3.23797s/100 iters), loss = 0.355012
I1005 09:04:05.634553  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:04:05.634553  1784 solver.cpp:237]     Train net output #1: loss = 0.355012 (* 1 = 0.355012 loss)
I1005 09:04:05.634553  1784 sgd_solver.cpp:105] Iteration 16400, lr = 1e-05
I1005 09:04:08.717730 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:04:08.880270  1784 solver.cpp:218] Iteration 16500 (30.8613 iter/s, 3.2403s/100 iters), loss = 0.42918
I1005 09:04:08.880270  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:04:08.880270  1784 solver.cpp:237]     Train net output #1: loss = 0.42918 (* 1 = 0.42918 loss)
I1005 09:04:08.880270  1784 sgd_solver.cpp:105] Iteration 16500, lr = 1e-05
I1005 09:04:12.129015  1784 solver.cpp:218] Iteration 16600 (30.8443 iter/s, 3.24209s/100 iters), loss = 0.411837
I1005 09:04:12.129015  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:04:12.129015  1784 solver.cpp:237]     Train net output #1: loss = 0.411837 (* 1 = 0.411837 loss)
I1005 09:04:12.129015  1784 sgd_solver.cpp:105] Iteration 16600, lr = 1e-05
I1005 09:04:15.356911  1784 solver.cpp:218] Iteration 16700 (30.8461 iter/s, 3.24191s/100 iters), loss = 0.353557
I1005 09:04:15.356911  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:04:15.356911  1784 solver.cpp:237]     Train net output #1: loss = 0.353557 (* 1 = 0.353557 loss)
I1005 09:04:15.356911  1784 sgd_solver.cpp:105] Iteration 16700, lr = 1e-05
I1005 09:04:18.610810  1784 solver.cpp:218] Iteration 16800 (30.8185 iter/s, 3.24481s/100 iters), loss = 0.423721
I1005 09:04:18.610810  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1005 09:04:18.610810  1784 solver.cpp:237]     Train net output #1: loss = 0.423721 (* 1 = 0.423721 loss)
I1005 09:04:18.610810  1784 sgd_solver.cpp:105] Iteration 16800, lr = 1e-05
I1005 09:04:21.855906  1784 solver.cpp:218] Iteration 16900 (30.8107 iter/s, 3.24562s/100 iters), loss = 0.372005
I1005 09:04:21.855906  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:04:21.855906  1784 solver.cpp:237]     Train net output #1: loss = 0.372005 (* 1 = 0.372005 loss)
I1005 09:04:21.855906  1784 sgd_solver.cpp:105] Iteration 16900, lr = 1e-05
I1005 09:04:24.936148 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:04:25.061149  1784 solver.cpp:330] Iteration 17000, Testing net (#0)
I1005 09:04:25.061149  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:04:25.709313   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:04:25.740561  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7935
I1005 09:04:25.740561  1784 solver.cpp:397]     Test net output #1: loss = 0.6018 (* 1 = 0.6018 loss)
I1005 09:04:25.771819  1784 solver.cpp:218] Iteration 17000 (25.5461 iter/s, 3.91448s/100 iters), loss = 0.392352
I1005 09:04:25.771819  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:04:25.771819  1784 solver.cpp:237]     Train net output #1: loss = 0.392352 (* 1 = 0.392352 loss)
I1005 09:04:25.771819  1784 sgd_solver.cpp:105] Iteration 17000, lr = 1e-05
I1005 09:04:29.009192  1784 solver.cpp:218] Iteration 17100 (30.8634 iter/s, 3.24008s/100 iters), loss = 0.375395
I1005 09:04:29.009192  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:04:29.009192  1784 solver.cpp:237]     Train net output #1: loss = 0.375395 (* 1 = 0.375395 loss)
I1005 09:04:29.009192  1784 sgd_solver.cpp:105] Iteration 17100, lr = 1e-05
I1005 09:04:32.248550  1784 solver.cpp:218] Iteration 17200 (30.8182 iter/s, 3.24484s/100 iters), loss = 0.330325
I1005 09:04:32.248550  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:04:32.248550  1784 solver.cpp:237]     Train net output #1: loss = 0.330325 (* 1 = 0.330325 loss)
I1005 09:04:32.248550  1784 sgd_solver.cpp:105] Iteration 17200, lr = 1e-05
I1005 09:04:35.497982  1784 solver.cpp:218] Iteration 17300 (30.8295 iter/s, 3.24364s/100 iters), loss = 0.402816
I1005 09:04:35.497982  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:04:35.497982  1784 solver.cpp:237]     Train net output #1: loss = 0.402816 (* 1 = 0.402816 loss)
I1005 09:04:35.497982  1784 sgd_solver.cpp:105] Iteration 17300, lr = 1e-05
I1005 09:04:38.749562  1784 solver.cpp:218] Iteration 17400 (30.812 iter/s, 3.24549s/100 iters), loss = 0.363144
I1005 09:04:38.749562  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:04:38.749562  1784 solver.cpp:237]     Train net output #1: loss = 0.363144 (* 1 = 0.363144 loss)
I1005 09:04:38.749562  1784 sgd_solver.cpp:105] Iteration 17400, lr = 1e-05
I1005 09:04:41.827441 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:04:41.983692  1784 solver.cpp:218] Iteration 17500 (30.8371 iter/s, 3.24285s/100 iters), loss = 0.411363
I1005 09:04:41.983692  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:04:41.983692  1784 solver.cpp:237]     Train net output #1: loss = 0.411363 (* 1 = 0.411363 loss)
I1005 09:04:41.983692  1784 sgd_solver.cpp:105] Iteration 17500, lr = 1e-05
I1005 09:04:45.238876  1784 solver.cpp:218] Iteration 17600 (30.8108 iter/s, 3.24562s/100 iters), loss = 0.397222
I1005 09:04:45.238876  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:04:45.238876  1784 solver.cpp:237]     Train net output #1: loss = 0.397222 (* 1 = 0.397222 loss)
I1005 09:04:45.238876  1784 sgd_solver.cpp:105] Iteration 17600, lr = 1e-05
I1005 09:04:48.480876  1784 solver.cpp:218] Iteration 17700 (30.857 iter/s, 3.24076s/100 iters), loss = 0.341233
I1005 09:04:48.480876  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:04:48.480876  1784 solver.cpp:237]     Train net output #1: loss = 0.341233 (* 1 = 0.341233 loss)
I1005 09:04:48.480876  1784 sgd_solver.cpp:105] Iteration 17700, lr = 1e-05
I1005 09:04:51.727246  1784 solver.cpp:218] Iteration 17800 (30.8328 iter/s, 3.2433s/100 iters), loss = 0.439649
I1005 09:04:51.727246  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:04:51.727246  1784 solver.cpp:237]     Train net output #1: loss = 0.439649 (* 1 = 0.439649 loss)
I1005 09:04:51.727246  1784 sgd_solver.cpp:105] Iteration 17800, lr = 1e-05
I1005 09:04:54.971906  1784 solver.cpp:218] Iteration 17900 (30.8156 iter/s, 3.24511s/100 iters), loss = 0.333052
I1005 09:04:54.971906  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:04:54.971906  1784 solver.cpp:237]     Train net output #1: loss = 0.333052 (* 1 = 0.333052 loss)
I1005 09:04:54.971906  1784 sgd_solver.cpp:105] Iteration 17900, lr = 1e-05
I1005 09:04:58.047339 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:04:58.172340  1784 solver.cpp:330] Iteration 18000, Testing net (#0)
I1005 09:04:58.172340  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:04:58.832464   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:04:58.848089  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7931
I1005 09:04:58.848089  1784 solver.cpp:397]     Test net output #1: loss = 0.601959 (* 1 = 0.601959 loss)
I1005 09:04:58.879343  1784 solver.cpp:218] Iteration 18000 (25.5255 iter/s, 3.91766s/100 iters), loss = 0.472336
I1005 09:04:58.879343  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 09:04:58.879343  1784 solver.cpp:237]     Train net output #1: loss = 0.472336 (* 1 = 0.472336 loss)
I1005 09:04:58.879343  1784 sgd_solver.cpp:105] Iteration 18000, lr = 1e-05
I1005 09:05:02.130281  1784 solver.cpp:218] Iteration 18100 (30.864 iter/s, 3.24002s/100 iters), loss = 0.410428
I1005 09:05:02.131285  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:05:02.131285  1784 solver.cpp:237]     Train net output #1: loss = 0.410428 (* 1 = 0.410428 loss)
I1005 09:05:02.131285  1784 sgd_solver.cpp:105] Iteration 18100, lr = 1e-05
I1005 09:05:05.362890  1784 solver.cpp:218] Iteration 18200 (30.8635 iter/s, 3.24007s/100 iters), loss = 0.299345
I1005 09:05:05.362890  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1005 09:05:05.362890  1784 solver.cpp:237]     Train net output #1: loss = 0.299345 (* 1 = 0.299345 loss)
I1005 09:05:05.362890  1784 sgd_solver.cpp:105] Iteration 18200, lr = 1e-05
I1005 09:05:08.612385  1784 solver.cpp:218] Iteration 18300 (30.8607 iter/s, 3.24037s/100 iters), loss = 0.427314
I1005 09:05:08.612385  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:05:08.612385  1784 solver.cpp:237]     Train net output #1: loss = 0.427314 (* 1 = 0.427314 loss)
I1005 09:05:08.612385  1784 sgd_solver.cpp:105] Iteration 18300, lr = 1e-05
I1005 09:05:11.853687  1784 solver.cpp:218] Iteration 18400 (30.8198 iter/s, 3.24467s/100 iters), loss = 0.350385
I1005 09:05:11.853687  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:05:11.853687  1784 solver.cpp:237]     Train net output #1: loss = 0.350385 (* 1 = 0.350385 loss)
I1005 09:05:11.853687  1784 sgd_solver.cpp:105] Iteration 18400, lr = 1e-05
I1005 09:05:14.935806 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:05:15.092054  1784 solver.cpp:218] Iteration 18500 (30.8894 iter/s, 3.23735s/100 iters), loss = 0.43779
I1005 09:05:15.092054  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:05:15.092054  1784 solver.cpp:237]     Train net output #1: loss = 0.43779 (* 1 = 0.43779 loss)
I1005 09:05:15.092054  1784 sgd_solver.cpp:105] Iteration 18500, lr = 1e-05
I1005 09:05:18.320029  1784 solver.cpp:218] Iteration 18600 (30.8634 iter/s, 3.24008s/100 iters), loss = 0.387153
I1005 09:05:18.335654  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:05:18.335654  1784 solver.cpp:237]     Train net output #1: loss = 0.387153 (* 1 = 0.387153 loss)
I1005 09:05:18.335654  1784 sgd_solver.cpp:105] Iteration 18600, lr = 1e-05
I1005 09:05:21.576792  1784 solver.cpp:218] Iteration 18700 (30.8251 iter/s, 3.24411s/100 iters), loss = 0.288551
I1005 09:05:21.576792  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1005 09:05:21.576792  1784 solver.cpp:237]     Train net output #1: loss = 0.288551 (* 1 = 0.288551 loss)
I1005 09:05:21.576792  1784 sgd_solver.cpp:105] Iteration 18700, lr = 1e-05
I1005 09:05:24.809023  1784 solver.cpp:218] Iteration 18800 (30.8892 iter/s, 3.23738s/100 iters), loss = 0.412428
I1005 09:05:24.809023  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:05:24.809023  1784 solver.cpp:237]     Train net output #1: loss = 0.412428 (* 1 = 0.412428 loss)
I1005 09:05:24.809023  1784 sgd_solver.cpp:105] Iteration 18800, lr = 1e-05
I1005 09:05:28.045163  1784 solver.cpp:218] Iteration 18900 (30.8653 iter/s, 3.23988s/100 iters), loss = 0.38994
I1005 09:05:28.045163  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:05:28.045163  1784 solver.cpp:237]     Train net output #1: loss = 0.38994 (* 1 = 0.38994 loss)
I1005 09:05:28.045163  1784 sgd_solver.cpp:105] Iteration 18900, lr = 1e-05
I1005 09:05:31.132827 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:05:31.257827  1784 solver.cpp:330] Iteration 19000, Testing net (#0)
I1005 09:05:31.257827  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:05:31.909695   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:05:31.940944  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7936
I1005 09:05:31.940944  1784 solver.cpp:397]     Test net output #1: loss = 0.60192 (* 1 = 0.60192 loss)
I1005 09:05:31.972194  1784 solver.cpp:218] Iteration 19000 (25.5028 iter/s, 3.92113s/100 iters), loss = 0.390291
I1005 09:05:31.972194  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:05:31.972194  1784 solver.cpp:237]     Train net output #1: loss = 0.390291 (* 1 = 0.390291 loss)
I1005 09:05:31.972194  1784 sgd_solver.cpp:105] Iteration 19000, lr = 1e-05
I1005 09:05:35.222263  1784 solver.cpp:218] Iteration 19100 (30.808 iter/s, 3.24591s/100 iters), loss = 0.367194
I1005 09:05:35.222263  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:05:35.222263  1784 solver.cpp:237]     Train net output #1: loss = 0.367194 (* 1 = 0.367194 loss)
I1005 09:05:35.222263  1784 sgd_solver.cpp:105] Iteration 19100, lr = 1e-05
I1005 09:05:38.466888  1784 solver.cpp:218] Iteration 19200 (30.8249 iter/s, 3.24413s/100 iters), loss = 0.324043
I1005 09:05:38.466888  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:05:38.466888  1784 solver.cpp:237]     Train net output #1: loss = 0.324043 (* 1 = 0.324043 loss)
I1005 09:05:38.466888  1784 sgd_solver.cpp:105] Iteration 19200, lr = 1e-05
I1005 09:05:41.712651  1784 solver.cpp:218] Iteration 19300 (30.834 iter/s, 3.24318s/100 iters), loss = 0.426184
I1005 09:05:41.712651  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:05:41.712651  1784 solver.cpp:237]     Train net output #1: loss = 0.426184 (* 1 = 0.426184 loss)
I1005 09:05:41.712651  1784 sgd_solver.cpp:105] Iteration 19300, lr = 1e-05
I1005 09:05:44.956066  1784 solver.cpp:218] Iteration 19400 (30.8336 iter/s, 3.24321s/100 iters), loss = 0.369096
I1005 09:05:44.956066  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:05:44.956066  1784 solver.cpp:237]     Train net output #1: loss = 0.369096 (* 1 = 0.369096 loss)
I1005 09:05:44.956066  1784 sgd_solver.cpp:105] Iteration 19400, lr = 1e-05
I1005 09:05:48.031697 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:05:48.195232  1784 solver.cpp:218] Iteration 19500 (30.8088 iter/s, 3.24583s/100 iters), loss = 0.468358
I1005 09:05:48.195232  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 09:05:48.195232  1784 solver.cpp:237]     Train net output #1: loss = 0.468358 (* 1 = 0.468358 loss)
I1005 09:05:48.195232  1784 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I1005 09:05:51.432008  1784 solver.cpp:218] Iteration 19600 (30.8554 iter/s, 3.24092s/100 iters), loss = 0.390368
I1005 09:05:51.432008  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:05:51.432008  1784 solver.cpp:237]     Train net output #1: loss = 0.390368 (* 1 = 0.390368 loss)
I1005 09:05:51.432008  1784 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I1005 09:05:54.684527  1784 solver.cpp:218] Iteration 19700 (30.8586 iter/s, 3.24058s/100 iters), loss = 0.3397
I1005 09:05:54.684527  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:05:54.684527  1784 solver.cpp:237]     Train net output #1: loss = 0.3397 (* 1 = 0.3397 loss)
I1005 09:05:54.684527  1784 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I1005 09:05:57.915786  1784 solver.cpp:218] Iteration 19800 (30.8594 iter/s, 3.2405s/100 iters), loss = 0.438464
I1005 09:05:57.915786  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:05:57.915786  1784 solver.cpp:237]     Train net output #1: loss = 0.438464 (* 1 = 0.438464 loss)
I1005 09:05:57.915786  1784 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I1005 09:06:01.165540  1784 solver.cpp:218] Iteration 19900 (30.852 iter/s, 3.24128s/100 iters), loss = 0.344106
I1005 09:06:01.165540  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:06:01.165540  1784 solver.cpp:237]     Train net output #1: loss = 0.344106 (* 1 = 0.344106 loss)
I1005 09:06:01.165540  1784 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I1005 09:06:04.245025 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:06:04.370024  1784 solver.cpp:330] Iteration 20000, Testing net (#0)
I1005 09:06:04.370024  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:06:05.021833   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:06:05.053304  1784 solver.cpp:397]     Test net output #0: accuracy = 0.793
I1005 09:06:05.053304  1784 solver.cpp:397]     Test net output #1: loss = 0.601941 (* 1 = 0.601941 loss)
I1005 09:06:05.082013  1784 solver.cpp:218] Iteration 20000 (25.5422 iter/s, 3.91509s/100 iters), loss = 0.422303
I1005 09:06:05.082013  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:06:05.082013  1784 solver.cpp:237]     Train net output #1: loss = 0.422303 (* 1 = 0.422303 loss)
I1005 09:06:05.082013  1784 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I1005 09:06:08.323269  1784 solver.cpp:218] Iteration 20100 (30.8135 iter/s, 3.24533s/100 iters), loss = 0.436155
I1005 09:06:08.323269  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:06:08.323269  1784 solver.cpp:237]     Train net output #1: loss = 0.436155 (* 1 = 0.436155 loss)
I1005 09:06:08.323269  1784 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I1005 09:06:11.558049  1784 solver.cpp:218] Iteration 20200 (30.8477 iter/s, 3.24173s/100 iters), loss = 0.348359
I1005 09:06:11.558049  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:06:11.558049  1784 solver.cpp:237]     Train net output #1: loss = 0.348359 (* 1 = 0.348359 loss)
I1005 09:06:11.558049  1784 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I1005 09:06:14.806419  1784 solver.cpp:218] Iteration 20300 (30.837 iter/s, 3.24285s/100 iters), loss = 0.446505
I1005 09:06:14.806419  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:06:14.806419  1784 solver.cpp:237]     Train net output #1: loss = 0.446505 (* 1 = 0.446505 loss)
I1005 09:06:14.806419  1784 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I1005 09:06:18.053227  1784 solver.cpp:218] Iteration 20400 (30.8556 iter/s, 3.2409s/100 iters), loss = 0.418456
I1005 09:06:18.053227  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:06:18.053227  1784 solver.cpp:237]     Train net output #1: loss = 0.418456 (* 1 = 0.418456 loss)
I1005 09:06:18.053227  1784 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I1005 09:06:21.135283 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:06:21.291532  1784 solver.cpp:218] Iteration 20500 (30.8074 iter/s, 3.24597s/100 iters), loss = 0.424185
I1005 09:06:21.291532  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:06:21.291532  1784 solver.cpp:237]     Train net output #1: loss = 0.424185 (* 1 = 0.424185 loss)
I1005 09:06:21.291532  1784 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I1005 09:06:24.543418  1784 solver.cpp:218] Iteration 20600 (30.8565 iter/s, 3.24081s/100 iters), loss = 0.433573
I1005 09:06:24.543418  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:06:24.543418  1784 solver.cpp:237]     Train net output #1: loss = 0.433573 (* 1 = 0.433573 loss)
I1005 09:06:24.543835  1784 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I1005 09:06:27.778548  1784 solver.cpp:218] Iteration 20700 (30.8514 iter/s, 3.24135s/100 iters), loss = 0.324975
I1005 09:06:27.778548  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1005 09:06:27.778548  1784 solver.cpp:237]     Train net output #1: loss = 0.324975 (* 1 = 0.324975 loss)
I1005 09:06:27.778548  1784 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I1005 09:06:31.019134  1784 solver.cpp:218] Iteration 20800 (30.8481 iter/s, 3.24169s/100 iters), loss = 0.4124
I1005 09:06:31.019134  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:06:31.019134  1784 solver.cpp:237]     Train net output #1: loss = 0.4124 (* 1 = 0.4124 loss)
I1005 09:06:31.019134  1784 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I1005 09:06:34.256901  1784 solver.cpp:218] Iteration 20900 (30.8299 iter/s, 3.2436s/100 iters), loss = 0.425896
I1005 09:06:34.256901  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 09:06:34.256901  1784 solver.cpp:237]     Train net output #1: loss = 0.425896 (* 1 = 0.425896 loss)
I1005 09:06:34.256901  1784 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I1005 09:06:37.349429 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:06:37.474429  1784 solver.cpp:330] Iteration 21000, Testing net (#0)
I1005 09:06:37.474429  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:06:38.130690   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:06:38.146314  1784 solver.cpp:397]     Test net output #0: accuracy = 0.794
I1005 09:06:38.146314  1784 solver.cpp:397]     Test net output #1: loss = 0.601905 (* 1 = 0.601905 loss)
I1005 09:06:38.177554  1784 solver.cpp:218] Iteration 21000 (25.5272 iter/s, 3.91739s/100 iters), loss = 0.435852
I1005 09:06:38.177554  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:06:38.177554  1784 solver.cpp:237]     Train net output #1: loss = 0.435852 (* 1 = 0.435852 loss)
I1005 09:06:38.177554  1784 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I1005 09:06:41.429047  1784 solver.cpp:218] Iteration 21100 (30.8537 iter/s, 3.2411s/100 iters), loss = 0.383916
I1005 09:06:41.429047  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:06:41.429047  1784 solver.cpp:237]     Train net output #1: loss = 0.383916 (* 1 = 0.383916 loss)
I1005 09:06:41.429047  1784 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I1005 09:06:44.662950  1784 solver.cpp:218] Iteration 21200 (30.8653 iter/s, 3.23988s/100 iters), loss = 0.331505
I1005 09:06:44.662950  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:06:44.662950  1784 solver.cpp:237]     Train net output #1: loss = 0.331505 (* 1 = 0.331505 loss)
I1005 09:06:44.662950  1784 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I1005 09:06:47.895360  1784 solver.cpp:218] Iteration 21300 (30.8904 iter/s, 3.23726s/100 iters), loss = 0.478797
I1005 09:06:47.895360  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:06:47.895360  1784 solver.cpp:237]     Train net output #1: loss = 0.478797 (* 1 = 0.478797 loss)
I1005 09:06:47.895360  1784 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I1005 09:06:51.146039  1784 solver.cpp:218] Iteration 21400 (30.7647 iter/s, 3.25048s/100 iters), loss = 0.376887
I1005 09:06:51.146039  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:06:51.146039  1784 solver.cpp:237]     Train net output #1: loss = 0.376887 (* 1 = 0.376887 loss)
I1005 09:06:51.146039  1784 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I1005 09:06:54.229635 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:06:54.397083  1784 solver.cpp:218] Iteration 21500 (30.8287 iter/s, 3.24373s/100 iters), loss = 0.429072
I1005 09:06:54.397083  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1005 09:06:54.397083  1784 solver.cpp:237]     Train net output #1: loss = 0.429072 (* 1 = 0.429072 loss)
I1005 09:06:54.397083  1784 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I1005 09:06:57.645944  1784 solver.cpp:218] Iteration 21600 (30.8155 iter/s, 3.24512s/100 iters), loss = 0.415433
I1005 09:06:57.645944  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:06:57.645944  1784 solver.cpp:237]     Train net output #1: loss = 0.415433 (* 1 = 0.415433 loss)
I1005 09:06:57.645944  1784 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I1005 09:07:00.875162  1784 solver.cpp:218] Iteration 21700 (30.8577 iter/s, 3.24068s/100 iters), loss = 0.340229
I1005 09:07:00.875162  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:07:00.875162  1784 solver.cpp:237]     Train net output #1: loss = 0.340229 (* 1 = 0.340229 loss)
I1005 09:07:00.875162  1784 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I1005 09:07:04.133616  1784 solver.cpp:218] Iteration 21800 (30.8296 iter/s, 3.24364s/100 iters), loss = 0.471149
I1005 09:07:04.133616  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:07:04.133616  1784 solver.cpp:237]     Train net output #1: loss = 0.471149 (* 1 = 0.471149 loss)
I1005 09:07:04.133616  1784 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I1005 09:07:07.365221  1784 solver.cpp:218] Iteration 21900 (30.8314 iter/s, 3.24345s/100 iters), loss = 0.385966
I1005 09:07:07.365221  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:07:07.365221  1784 solver.cpp:237]     Train net output #1: loss = 0.385966 (* 1 = 0.385966 loss)
I1005 09:07:07.365221  1784 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I1005 09:07:10.461203 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:07:10.586205  1784 solver.cpp:330] Iteration 22000, Testing net (#0)
I1005 09:07:10.586205  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:07:11.226402   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:07:11.257652  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7935
I1005 09:07:11.257652  1784 solver.cpp:397]     Test net output #1: loss = 0.602012 (* 1 = 0.602012 loss)
I1005 09:07:11.288902  1784 solver.cpp:218] Iteration 22000 (25.5176 iter/s, 3.91887s/100 iters), loss = 0.409213
I1005 09:07:11.288902  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:07:11.288902  1784 solver.cpp:237]     Train net output #1: loss = 0.409213 (* 1 = 0.409213 loss)
I1005 09:07:11.288902  1784 sgd_solver.cpp:105] Iteration 22000, lr = 1e-05
I1005 09:07:14.527137  1784 solver.cpp:218] Iteration 22100 (30.842 iter/s, 3.24233s/100 iters), loss = 0.438468
I1005 09:07:14.527137  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:07:14.527137  1784 solver.cpp:237]     Train net output #1: loss = 0.438468 (* 1 = 0.438468 loss)
I1005 09:07:14.527137  1784 sgd_solver.cpp:105] Iteration 22100, lr = 1e-05
I1005 09:07:17.766716  1784 solver.cpp:218] Iteration 22200 (30.8504 iter/s, 3.24145s/100 iters), loss = 0.351545
I1005 09:07:17.766716  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:07:17.766716  1784 solver.cpp:237]     Train net output #1: loss = 0.351545 (* 1 = 0.351545 loss)
I1005 09:07:17.766716  1784 sgd_solver.cpp:105] Iteration 22200, lr = 1e-05
I1005 09:07:21.014979  1784 solver.cpp:218] Iteration 22300 (30.8529 iter/s, 3.24119s/100 iters), loss = 0.422583
I1005 09:07:21.014979  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:07:21.014979  1784 solver.cpp:237]     Train net output #1: loss = 0.422583 (* 1 = 0.422583 loss)
I1005 09:07:21.014979  1784 sgd_solver.cpp:105] Iteration 22300, lr = 1e-05
I1005 09:07:24.255530  1784 solver.cpp:218] Iteration 22400 (30.8176 iter/s, 3.2449s/100 iters), loss = 0.377575
I1005 09:07:24.255530  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:07:24.255530  1784 solver.cpp:237]     Train net output #1: loss = 0.377575 (* 1 = 0.377575 loss)
I1005 09:07:24.255530  1784 sgd_solver.cpp:105] Iteration 22400, lr = 1e-05
I1005 09:07:27.354794 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:07:27.511042  1784 solver.cpp:218] Iteration 22500 (30.806 iter/s, 3.24612s/100 iters), loss = 0.41649
I1005 09:07:27.511042  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:07:27.511042  1784 solver.cpp:237]     Train net output #1: loss = 0.41649 (* 1 = 0.41649 loss)
I1005 09:07:27.511042  1784 sgd_solver.cpp:105] Iteration 22500, lr = 1e-05
I1005 09:07:30.744377  1784 solver.cpp:218] Iteration 22600 (30.8582 iter/s, 3.24063s/100 iters), loss = 0.355286
I1005 09:07:30.744377  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1005 09:07:30.744377  1784 solver.cpp:237]     Train net output #1: loss = 0.355286 (* 1 = 0.355286 loss)
I1005 09:07:30.744377  1784 sgd_solver.cpp:105] Iteration 22600, lr = 1e-05
I1005 09:07:34.000084  1784 solver.cpp:218] Iteration 22700 (30.8152 iter/s, 3.24515s/100 iters), loss = 0.331582
I1005 09:07:34.000084  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:07:34.000084  1784 solver.cpp:237]     Train net output #1: loss = 0.331582 (* 1 = 0.331582 loss)
I1005 09:07:34.000084  1784 sgd_solver.cpp:105] Iteration 22700, lr = 1e-05
I1005 09:07:37.241837  1784 solver.cpp:218] Iteration 22800 (30.8602 iter/s, 3.24042s/100 iters), loss = 0.440223
I1005 09:07:37.241837  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:07:37.241837  1784 solver.cpp:237]     Train net output #1: loss = 0.440223 (* 1 = 0.440223 loss)
I1005 09:07:37.241837  1784 sgd_solver.cpp:105] Iteration 22800, lr = 1e-05
I1005 09:07:40.475864  1784 solver.cpp:218] Iteration 22900 (30.8532 iter/s, 3.24115s/100 iters), loss = 0.406761
I1005 09:07:40.475864  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:07:40.475864  1784 solver.cpp:237]     Train net output #1: loss = 0.406761 (* 1 = 0.406761 loss)
I1005 09:07:40.475864  1784 sgd_solver.cpp:105] Iteration 22900, lr = 1e-05
I1005 09:07:43.565194 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:07:43.690210  1784 solver.cpp:330] Iteration 23000, Testing net (#0)
I1005 09:07:43.690210  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:07:44.338179   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:07:44.369431  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7932
I1005 09:07:44.369431  1784 solver.cpp:397]     Test net output #1: loss = 0.602032 (* 1 = 0.602032 loss)
I1005 09:07:44.400678  1784 solver.cpp:218] Iteration 23000 (25.5254 iter/s, 3.91767s/100 iters), loss = 0.446013
I1005 09:07:44.400678  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1005 09:07:44.400678  1784 solver.cpp:237]     Train net output #1: loss = 0.446013 (* 1 = 0.446013 loss)
I1005 09:07:44.400678  1784 sgd_solver.cpp:105] Iteration 23000, lr = 1e-05
I1005 09:07:47.633040  1784 solver.cpp:218] Iteration 23100 (30.8883 iter/s, 3.23747s/100 iters), loss = 0.440678
I1005 09:07:47.633040  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:07:47.633040  1784 solver.cpp:237]     Train net output #1: loss = 0.440678 (* 1 = 0.440678 loss)
I1005 09:07:47.633040  1784 sgd_solver.cpp:105] Iteration 23100, lr = 1e-05
I1005 09:07:50.868062  1784 solver.cpp:218] Iteration 23200 (30.841 iter/s, 3.24244s/100 iters), loss = 0.35375
I1005 09:07:50.868062  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:07:50.868062  1784 solver.cpp:237]     Train net output #1: loss = 0.35375 (* 1 = 0.35375 loss)
I1005 09:07:50.868062  1784 sgd_solver.cpp:105] Iteration 23200, lr = 1e-05
I1005 09:07:54.107359  1784 solver.cpp:218] Iteration 23300 (30.8605 iter/s, 3.24039s/100 iters), loss = 0.452646
I1005 09:07:54.107359  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:07:54.107359  1784 solver.cpp:237]     Train net output #1: loss = 0.452646 (* 1 = 0.452646 loss)
I1005 09:07:54.107359  1784 sgd_solver.cpp:105] Iteration 23300, lr = 1e-05
I1005 09:07:57.357887  1784 solver.cpp:218] Iteration 23400 (30.8375 iter/s, 3.2428s/100 iters), loss = 0.382496
I1005 09:07:57.357887  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:07:57.357887  1784 solver.cpp:237]     Train net output #1: loss = 0.382496 (* 1 = 0.382496 loss)
I1005 09:07:57.357887  1784 sgd_solver.cpp:105] Iteration 23400, lr = 1e-05
I1005 09:08:00.445382 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:08:00.595294  1784 solver.cpp:218] Iteration 23500 (30.8333 iter/s, 3.24325s/100 iters), loss = 0.490206
I1005 09:08:00.595294  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 09:08:00.595294  1784 solver.cpp:237]     Train net output #1: loss = 0.490206 (* 1 = 0.490206 loss)
I1005 09:08:00.595294  1784 sgd_solver.cpp:105] Iteration 23500, lr = 1e-05
I1005 09:08:03.849217  1784 solver.cpp:218] Iteration 23600 (30.838 iter/s, 3.24275s/100 iters), loss = 0.401354
I1005 09:08:03.849217  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:08:03.849217  1784 solver.cpp:237]     Train net output #1: loss = 0.401354 (* 1 = 0.401354 loss)
I1005 09:08:03.849217  1784 sgd_solver.cpp:105] Iteration 23600, lr = 1e-05
I1005 09:08:07.085117  1784 solver.cpp:218] Iteration 23700 (30.8319 iter/s, 3.2434s/100 iters), loss = 0.328133
I1005 09:08:07.085117  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:08:07.085117  1784 solver.cpp:237]     Train net output #1: loss = 0.328133 (* 1 = 0.328133 loss)
I1005 09:08:07.085117  1784 sgd_solver.cpp:105] Iteration 23700, lr = 1e-05
I1005 09:08:10.328647  1784 solver.cpp:218] Iteration 23800 (30.8629 iter/s, 3.24014s/100 iters), loss = 0.446156
I1005 09:08:10.328647  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:08:10.328647  1784 solver.cpp:237]     Train net output #1: loss = 0.446156 (* 1 = 0.446156 loss)
I1005 09:08:10.328647  1784 sgd_solver.cpp:105] Iteration 23800, lr = 1e-05
I1005 09:08:13.569974  1784 solver.cpp:218] Iteration 23900 (30.881 iter/s, 3.23824s/100 iters), loss = 0.428837
I1005 09:08:13.569974  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:08:13.569974  1784 solver.cpp:237]     Train net output #1: loss = 0.428837 (* 1 = 0.428837 loss)
I1005 09:08:13.569974  1784 sgd_solver.cpp:105] Iteration 23900, lr = 1e-05
I1005 09:08:16.647101 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:08:16.772101  1784 solver.cpp:330] Iteration 24000, Testing net (#0)
I1005 09:08:16.772101  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:08:17.431077   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:08:17.446701  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7936
I1005 09:08:17.446701  1784 solver.cpp:397]     Test net output #1: loss = 0.601871 (* 1 = 0.601871 loss)
I1005 09:08:17.477949  1784 solver.cpp:218] Iteration 24000 (25.5513 iter/s, 3.91369s/100 iters), loss = 0.430098
I1005 09:08:17.477949  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1005 09:08:17.477949  1784 solver.cpp:237]     Train net output #1: loss = 0.430098 (* 1 = 0.430098 loss)
I1005 09:08:17.477949  1784 sgd_solver.cpp:105] Iteration 24000, lr = 1e-05
I1005 09:08:20.719568  1784 solver.cpp:218] Iteration 24100 (30.8701 iter/s, 3.23938s/100 iters), loss = 0.400909
I1005 09:08:20.719568  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:08:20.719568  1784 solver.cpp:237]     Train net output #1: loss = 0.40091 (* 1 = 0.40091 loss)
I1005 09:08:20.719568  1784 sgd_solver.cpp:105] Iteration 24100, lr = 1e-05
I1005 09:08:23.965822  1784 solver.cpp:218] Iteration 24200 (30.8488 iter/s, 3.24161s/100 iters), loss = 0.359392
I1005 09:08:23.965822  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:08:23.965822  1784 solver.cpp:237]     Train net output #1: loss = 0.359392 (* 1 = 0.359392 loss)
I1005 09:08:23.965822  1784 sgd_solver.cpp:105] Iteration 24200, lr = 1e-05
I1005 09:08:27.203804  1784 solver.cpp:218] Iteration 24300 (30.8485 iter/s, 3.24165s/100 iters), loss = 0.451219
I1005 09:08:27.203804  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1005 09:08:27.203804  1784 solver.cpp:237]     Train net output #1: loss = 0.451219 (* 1 = 0.451219 loss)
I1005 09:08:27.203804  1784 sgd_solver.cpp:105] Iteration 24300, lr = 1e-05
I1005 09:08:30.437818  1784 solver.cpp:218] Iteration 24400 (30.8727 iter/s, 3.23911s/100 iters), loss = 0.38766
I1005 09:08:30.437818  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:08:30.437818  1784 solver.cpp:237]     Train net output #1: loss = 0.38766 (* 1 = 0.38766 loss)
I1005 09:08:30.437818  1784 sgd_solver.cpp:105] Iteration 24400, lr = 1e-05
I1005 09:08:33.523603 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:08:33.679855  1784 solver.cpp:218] Iteration 24500 (30.8548 iter/s, 3.24099s/100 iters), loss = 0.486733
I1005 09:08:33.679855  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1005 09:08:33.679855  1784 solver.cpp:237]     Train net output #1: loss = 0.486733 (* 1 = 0.486733 loss)
I1005 09:08:33.679855  1784 sgd_solver.cpp:105] Iteration 24500, lr = 1e-05
I1005 09:08:36.925482  1784 solver.cpp:218] Iteration 24600 (30.8581 iter/s, 3.24064s/100 iters), loss = 0.402411
I1005 09:08:36.925482  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1005 09:08:36.925482  1784 solver.cpp:237]     Train net output #1: loss = 0.402411 (* 1 = 0.402411 loss)
I1005 09:08:36.925482  1784 sgd_solver.cpp:105] Iteration 24600, lr = 1e-05
I1005 09:08:40.163939  1784 solver.cpp:218] Iteration 24700 (30.8394 iter/s, 3.24261s/100 iters), loss = 0.352668
I1005 09:08:40.163939  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1005 09:08:40.163939  1784 solver.cpp:237]     Train net output #1: loss = 0.352668 (* 1 = 0.352668 loss)
I1005 09:08:40.163939  1784 sgd_solver.cpp:105] Iteration 24700, lr = 1e-05
I1005 09:08:43.402469  1784 solver.cpp:218] Iteration 24800 (30.8707 iter/s, 3.23932s/100 iters), loss = 0.403158
I1005 09:08:43.402469  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1005 09:08:43.402469  1784 solver.cpp:237]     Train net output #1: loss = 0.403158 (* 1 = 0.403158 loss)
I1005 09:08:43.402469  1784 sgd_solver.cpp:105] Iteration 24800, lr = 1e-05
I1005 09:08:46.653990  1784 solver.cpp:218] Iteration 24900 (30.82 iter/s, 3.24464s/100 iters), loss = 0.441504
I1005 09:08:46.653990  1784 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1005 09:08:46.653990  1784 solver.cpp:237]     Train net output #1: loss = 0.441504 (* 1 = 0.441504 loss)
I1005 09:08:46.653990  1784 sgd_solver.cpp:105] Iteration 24900, lr = 1e-05
I1005 09:08:49.740469 17588 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:08:49.865470  1784 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/slimnet_simpnet_p7_iter_25000.caffemodel
I1005 09:08:49.881095  1784 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_simpnet_p7_iter_25000.solverstate
I1005 09:08:49.881095  1784 solver.cpp:310] Iteration 25000, loss = 0.475028
I1005 09:08:49.881095  1784 solver.cpp:330] Iteration 25000, Testing net (#0)
I1005 09:08:49.881095  1784 net.cpp:676] Ignoring source layer accuracy_training
I1005 09:08:50.541343   596 data_layer.cpp:73] Restarting data prefetching from start.
I1005 09:08:50.556967  1784 solver.cpp:397]     Test net output #0: accuracy = 0.7928
I1005 09:08:50.556967  1784 solver.cpp:397]     Test net output #1: loss = 0.601707 (* 1 = 0.601707 loss)
I1005 09:08:50.556967  1784 solver.cpp:315] Optimization Done.
I1005 09:08:50.556967  1784 caffe.cpp:260] Optimization Done.

G:\Caffe>pause
Press any key to continue . . . 
