
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0923 20:42:15.267989 14316 caffe.cpp:219] Using GPUs 0
I0923 20:42:15.434126 14316 caffe.cpp:224] GPU 0: GeForce GTX 1080
I0923 20:42:15.700917 14316 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:42:15.715926 14316 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 25000
snapshot_prefix: "examples/cifar10/slimnet_simpnet_nogroupcon"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 25000
type: "Nesterov"
I0923 20:42:15.715926 14316 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:42:15.716928 14316 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:42:15.716928 14316 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I0923 20:42:15.716928 14316 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0923 20:42:15.716928 14316 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_NoGroupCon_NoDrp_noaug"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0923 20:42:15.785603 14316 layer_factory.cpp:58] Creating layer cifar
I0923 20:42:15.791638 14316 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0923 20:42:15.791638 14316 net.cpp:84] Creating Layer cifar
I0923 20:42:15.791638 14316 net.cpp:380] cifar -> data
I0923 20:42:15.791638 14316 net.cpp:380] cifar -> label
I0923 20:42:15.791638 14316 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0923 20:42:15.794641 14316 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:42:15.794641 14316 data_layer.cpp:45] output data size: 100,3,32,32
I0923 20:42:15.798643 14316 net.cpp:122] Setting up cifar
I0923 20:42:15.798643 14316 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0923 20:42:15.798643 14316 net.cpp:129] Top shape: 100 (100)
I0923 20:42:15.798643 14316 net.cpp:137] Memory required for data: 1229200
I0923 20:42:15.798643 14316 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0923 20:42:15.799644 14316 net.cpp:84] Creating Layer label_cifar_1_split
I0923 20:42:15.799644 14316 net.cpp:406] label_cifar_1_split <- label
I0923 20:42:15.799644 14316 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0923 20:42:15.799644 14316 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0923 20:42:15.799644 14316 net.cpp:122] Setting up label_cifar_1_split
I0923 20:42:15.799644 14316 net.cpp:129] Top shape: 100 (100)
I0923 20:42:15.799644 14316 net.cpp:129] Top shape: 100 (100)
I0923 20:42:15.799644 14316 net.cpp:137] Memory required for data: 1230000
I0923 20:42:15.799644 14316 layer_factory.cpp:58] Creating layer conv1
I0923 20:42:15.799644 14316 net.cpp:84] Creating Layer conv1
I0923 20:42:15.799644 14316 net.cpp:406] conv1 <- data
I0923 20:42:15.799644 14316 net.cpp:380] conv1 -> conv1
I0923 20:42:15.799644 10060 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:42:16.011868 14316 net.cpp:122] Setting up conv1
I0923 20:42:16.011868 14316 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:42:16.011868 14316 net.cpp:137] Memory required for data: 3687600
I0923 20:42:16.011868 14316 layer_factory.cpp:58] Creating layer bn1
I0923 20:42:16.011868 14316 net.cpp:84] Creating Layer bn1
I0923 20:42:16.011868 14316 net.cpp:406] bn1 <- conv1
I0923 20:42:16.011868 14316 net.cpp:367] bn1 -> conv1 (in-place)
I0923 20:42:16.011868 14316 net.cpp:122] Setting up bn1
I0923 20:42:16.011868 14316 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:42:16.011868 14316 net.cpp:137] Memory required for data: 6145200
I0923 20:42:16.011868 14316 layer_factory.cpp:58] Creating layer scale1
I0923 20:42:16.011868 14316 net.cpp:84] Creating Layer scale1
I0923 20:42:16.011868 14316 net.cpp:406] scale1 <- conv1
I0923 20:42:16.011868 14316 net.cpp:367] scale1 -> conv1 (in-place)
I0923 20:42:16.011868 14316 layer_factory.cpp:58] Creating layer scale1
I0923 20:42:16.011868 14316 net.cpp:122] Setting up scale1
I0923 20:42:16.011868 14316 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:42:16.011868 14316 net.cpp:137] Memory required for data: 8602800
I0923 20:42:16.011868 14316 layer_factory.cpp:58] Creating layer relu1
I0923 20:42:16.011868 14316 net.cpp:84] Creating Layer relu1
I0923 20:42:16.011868 14316 net.cpp:406] relu1 <- conv1
I0923 20:42:16.011868 14316 net.cpp:367] relu1 -> conv1 (in-place)
I0923 20:42:16.012868 14316 net.cpp:122] Setting up relu1
I0923 20:42:16.012868 14316 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:42:16.012868 14316 net.cpp:137] Memory required for data: 11060400
I0923 20:42:16.012868 14316 layer_factory.cpp:58] Creating layer conv1_0
I0923 20:42:16.012868 14316 net.cpp:84] Creating Layer conv1_0
I0923 20:42:16.012868 14316 net.cpp:406] conv1_0 <- conv1
I0923 20:42:16.012868 14316 net.cpp:380] conv1_0 -> conv1_0
I0923 20:42:16.013870 14316 net.cpp:122] Setting up conv1_0
I0923 20:42:16.013870 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.013870 14316 net.cpp:137] Memory required for data: 15975600
I0923 20:42:16.013870 14316 layer_factory.cpp:58] Creating layer bn1_0
I0923 20:42:16.013870 14316 net.cpp:84] Creating Layer bn1_0
I0923 20:42:16.013870 14316 net.cpp:406] bn1_0 <- conv1_0
I0923 20:42:16.013870 14316 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0923 20:42:16.013870 14316 net.cpp:122] Setting up bn1_0
I0923 20:42:16.013870 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.013870 14316 net.cpp:137] Memory required for data: 20890800
I0923 20:42:16.013870 14316 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:42:16.013870 14316 net.cpp:84] Creating Layer scale1_0
I0923 20:42:16.013870 14316 net.cpp:406] scale1_0 <- conv1_0
I0923 20:42:16.013870 14316 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0923 20:42:16.013870 14316 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:42:16.013870 14316 net.cpp:122] Setting up scale1_0
I0923 20:42:16.013870 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.013870 14316 net.cpp:137] Memory required for data: 25806000
I0923 20:42:16.013870 14316 layer_factory.cpp:58] Creating layer relu1_0
I0923 20:42:16.013870 14316 net.cpp:84] Creating Layer relu1_0
I0923 20:42:16.013870 14316 net.cpp:406] relu1_0 <- conv1_0
I0923 20:42:16.013870 14316 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0923 20:42:16.014870 14316 net.cpp:122] Setting up relu1_0
I0923 20:42:16.014870 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.014870 14316 net.cpp:137] Memory required for data: 30721200
I0923 20:42:16.014870 14316 layer_factory.cpp:58] Creating layer conv2
I0923 20:42:16.014870 14316 net.cpp:84] Creating Layer conv2
I0923 20:42:16.014870 14316 net.cpp:406] conv2 <- conv1_0
I0923 20:42:16.014870 14316 net.cpp:380] conv2 -> conv2
I0923 20:42:16.014870 14316 net.cpp:122] Setting up conv2
I0923 20:42:16.014870 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.014870 14316 net.cpp:137] Memory required for data: 35636400
I0923 20:42:16.014870 14316 layer_factory.cpp:58] Creating layer bn2
I0923 20:42:16.015871 14316 net.cpp:84] Creating Layer bn2
I0923 20:42:16.015871 14316 net.cpp:406] bn2 <- conv2
I0923 20:42:16.015871 14316 net.cpp:367] bn2 -> conv2 (in-place)
I0923 20:42:16.015871 14316 net.cpp:122] Setting up bn2
I0923 20:42:16.015871 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.015871 14316 net.cpp:137] Memory required for data: 40551600
I0923 20:42:16.015871 14316 layer_factory.cpp:58] Creating layer scale2
I0923 20:42:16.015871 14316 net.cpp:84] Creating Layer scale2
I0923 20:42:16.015871 14316 net.cpp:406] scale2 <- conv2
I0923 20:42:16.015871 14316 net.cpp:367] scale2 -> conv2 (in-place)
I0923 20:42:16.015871 14316 layer_factory.cpp:58] Creating layer scale2
I0923 20:42:16.015871 14316 net.cpp:122] Setting up scale2
I0923 20:42:16.015871 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.015871 14316 net.cpp:137] Memory required for data: 45466800
I0923 20:42:16.015871 14316 layer_factory.cpp:58] Creating layer relu2
I0923 20:42:16.015871 14316 net.cpp:84] Creating Layer relu2
I0923 20:42:16.015871 14316 net.cpp:406] relu2 <- conv2
I0923 20:42:16.015871 14316 net.cpp:367] relu2 -> conv2 (in-place)
I0923 20:42:16.015871 14316 net.cpp:122] Setting up relu2
I0923 20:42:16.015871 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.015871 14316 net.cpp:137] Memory required for data: 50382000
I0923 20:42:16.015871 14316 layer_factory.cpp:58] Creating layer conv2_1
I0923 20:42:16.015871 14316 net.cpp:84] Creating Layer conv2_1
I0923 20:42:16.015871 14316 net.cpp:406] conv2_1 <- conv2
I0923 20:42:16.015871 14316 net.cpp:380] conv2_1 -> conv2_1
I0923 20:42:16.017262 14316 net.cpp:122] Setting up conv2_1
I0923 20:42:16.017262 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.017262 14316 net.cpp:137] Memory required for data: 55297200
I0923 20:42:16.017262 14316 layer_factory.cpp:58] Creating layer bn2_1
I0923 20:42:16.017262 14316 net.cpp:84] Creating Layer bn2_1
I0923 20:42:16.017262 14316 net.cpp:406] bn2_1 <- conv2_1
I0923 20:42:16.017262 14316 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0923 20:42:16.017262 14316 net.cpp:122] Setting up bn2_1
I0923 20:42:16.017262 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.017262 14316 net.cpp:137] Memory required for data: 60212400
I0923 20:42:16.017262 14316 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:42:16.017262 14316 net.cpp:84] Creating Layer scale2_1
I0923 20:42:16.017262 14316 net.cpp:406] scale2_1 <- conv2_1
I0923 20:42:16.017262 14316 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0923 20:42:16.017262 14316 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:42:16.017262 14316 net.cpp:122] Setting up scale2_1
I0923 20:42:16.017262 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.017262 14316 net.cpp:137] Memory required for data: 65127600
I0923 20:42:16.017262 14316 layer_factory.cpp:58] Creating layer relu2_1
I0923 20:42:16.017262 14316 net.cpp:84] Creating Layer relu2_1
I0923 20:42:16.017262 14316 net.cpp:406] relu2_1 <- conv2_1
I0923 20:42:16.017262 14316 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0923 20:42:16.017262 14316 net.cpp:122] Setting up relu2_1
I0923 20:42:16.017262 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.017262 14316 net.cpp:137] Memory required for data: 70042800
I0923 20:42:16.017262 14316 layer_factory.cpp:58] Creating layer conv2_2
I0923 20:42:16.017262 14316 net.cpp:84] Creating Layer conv2_2
I0923 20:42:16.017262 14316 net.cpp:406] conv2_2 <- conv2_1
I0923 20:42:16.017262 14316 net.cpp:380] conv2_2 -> conv2_2
I0923 20:42:16.018842 14316 net.cpp:122] Setting up conv2_2
I0923 20:42:16.018842 14316 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:42:16.018842 14316 net.cpp:137] Memory required for data: 77825200
I0923 20:42:16.018842 14316 layer_factory.cpp:58] Creating layer bn2_2
I0923 20:42:16.018842 14316 net.cpp:84] Creating Layer bn2_2
I0923 20:42:16.018842 14316 net.cpp:406] bn2_2 <- conv2_2
I0923 20:42:16.018842 14316 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0923 20:42:16.018842 14316 net.cpp:122] Setting up bn2_2
I0923 20:42:16.018842 14316 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:42:16.018842 14316 net.cpp:137] Memory required for data: 85607600
I0923 20:42:16.018842 14316 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:42:16.018842 14316 net.cpp:84] Creating Layer scale2_2
I0923 20:42:16.018842 14316 net.cpp:406] scale2_2 <- conv2_2
I0923 20:42:16.018842 14316 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0923 20:42:16.018842 14316 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:42:16.018842 14316 net.cpp:122] Setting up scale2_2
I0923 20:42:16.018842 14316 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:42:16.018842 14316 net.cpp:137] Memory required for data: 93390000
I0923 20:42:16.018842 14316 layer_factory.cpp:58] Creating layer relu2_2
I0923 20:42:16.018842 14316 net.cpp:84] Creating Layer relu2_2
I0923 20:42:16.018842 14316 net.cpp:406] relu2_2 <- conv2_2
I0923 20:42:16.018842 14316 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0923 20:42:16.019845 14316 net.cpp:122] Setting up relu2_2
I0923 20:42:16.019845 14316 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:42:16.019845 14316 net.cpp:137] Memory required for data: 101172400
I0923 20:42:16.019845 14316 layer_factory.cpp:58] Creating layer pool2_1
I0923 20:42:16.019845 14316 net.cpp:84] Creating Layer pool2_1
I0923 20:42:16.019845 14316 net.cpp:406] pool2_1 <- conv2_2
I0923 20:42:16.019845 14316 net.cpp:380] pool2_1 -> pool2_1
I0923 20:42:16.019845 14316 net.cpp:122] Setting up pool2_1
I0923 20:42:16.019845 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.019845 14316 net.cpp:137] Memory required for data: 103118000
I0923 20:42:16.019845 14316 layer_factory.cpp:58] Creating layer conv3
I0923 20:42:16.019845 14316 net.cpp:84] Creating Layer conv3
I0923 20:42:16.019845 14316 net.cpp:406] conv3 <- pool2_1
I0923 20:42:16.019845 14316 net.cpp:380] conv3 -> conv3
I0923 20:42:16.020519 14316 net.cpp:122] Setting up conv3
I0923 20:42:16.020519 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.020519 14316 net.cpp:137] Memory required for data: 105063600
I0923 20:42:16.020519 14316 layer_factory.cpp:58] Creating layer bn3
I0923 20:42:16.020519 14316 net.cpp:84] Creating Layer bn3
I0923 20:42:16.020519 14316 net.cpp:406] bn3 <- conv3
I0923 20:42:16.020519 14316 net.cpp:367] bn3 -> conv3 (in-place)
I0923 20:42:16.020519 14316 net.cpp:122] Setting up bn3
I0923 20:42:16.020519 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.020519 14316 net.cpp:137] Memory required for data: 107009200
I0923 20:42:16.020519 14316 layer_factory.cpp:58] Creating layer scale3
I0923 20:42:16.020519 14316 net.cpp:84] Creating Layer scale3
I0923 20:42:16.020519 14316 net.cpp:406] scale3 <- conv3
I0923 20:42:16.020519 14316 net.cpp:367] scale3 -> conv3 (in-place)
I0923 20:42:16.020519 14316 layer_factory.cpp:58] Creating layer scale3
I0923 20:42:16.020519 14316 net.cpp:122] Setting up scale3
I0923 20:42:16.020519 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.020519 14316 net.cpp:137] Memory required for data: 108954800
I0923 20:42:16.020519 14316 layer_factory.cpp:58] Creating layer relu3
I0923 20:42:16.020519 14316 net.cpp:84] Creating Layer relu3
I0923 20:42:16.020519 14316 net.cpp:406] relu3 <- conv3
I0923 20:42:16.020519 14316 net.cpp:367] relu3 -> conv3 (in-place)
I0923 20:42:16.021520 14316 net.cpp:122] Setting up relu3
I0923 20:42:16.021520 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.021520 14316 net.cpp:137] Memory required for data: 110900400
I0923 20:42:16.021520 14316 layer_factory.cpp:58] Creating layer conv3_1
I0923 20:42:16.021520 14316 net.cpp:84] Creating Layer conv3_1
I0923 20:42:16.021520 14316 net.cpp:406] conv3_1 <- conv3
I0923 20:42:16.021520 14316 net.cpp:380] conv3_1 -> conv3_1
I0923 20:42:16.021973 14316 net.cpp:122] Setting up conv3_1
I0923 20:42:16.021973 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.021973 14316 net.cpp:137] Memory required for data: 112846000
I0923 20:42:16.021973 14316 layer_factory.cpp:58] Creating layer bn3_1
I0923 20:42:16.021973 14316 net.cpp:84] Creating Layer bn3_1
I0923 20:42:16.021973 14316 net.cpp:406] bn3_1 <- conv3_1
I0923 20:42:16.021973 14316 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I0923 20:42:16.021973 14316 net.cpp:122] Setting up bn3_1
I0923 20:42:16.021973 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.021973 14316 net.cpp:137] Memory required for data: 114791600
I0923 20:42:16.021973 14316 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:42:16.021973 14316 net.cpp:84] Creating Layer scale3_1
I0923 20:42:16.021973 14316 net.cpp:406] scale3_1 <- conv3_1
I0923 20:42:16.021973 14316 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I0923 20:42:16.021973 14316 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:42:16.021973 14316 net.cpp:122] Setting up scale3_1
I0923 20:42:16.021973 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.021973 14316 net.cpp:137] Memory required for data: 116737200
I0923 20:42:16.021973 14316 layer_factory.cpp:58] Creating layer relu3_1
I0923 20:42:16.021973 14316 net.cpp:84] Creating Layer relu3_1
I0923 20:42:16.022974 14316 net.cpp:406] relu3_1 <- conv3_1
I0923 20:42:16.022974 14316 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0923 20:42:16.022974 14316 net.cpp:122] Setting up relu3_1
I0923 20:42:16.022974 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.022974 14316 net.cpp:137] Memory required for data: 118682800
I0923 20:42:16.022974 14316 layer_factory.cpp:58] Creating layer conv4
I0923 20:42:16.022974 14316 net.cpp:84] Creating Layer conv4
I0923 20:42:16.022974 14316 net.cpp:406] conv4 <- conv3_1
I0923 20:42:16.022974 14316 net.cpp:380] conv4 -> conv4
I0923 20:42:16.023975 14316 net.cpp:122] Setting up conv4
I0923 20:42:16.023975 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.023975 14316 net.cpp:137] Memory required for data: 120628400
I0923 20:42:16.023975 14316 layer_factory.cpp:58] Creating layer bn4
I0923 20:42:16.023975 14316 net.cpp:84] Creating Layer bn4
I0923 20:42:16.023975 14316 net.cpp:406] bn4 <- conv4
I0923 20:42:16.023975 14316 net.cpp:367] bn4 -> conv4 (in-place)
I0923 20:42:16.023975 14316 net.cpp:122] Setting up bn4
I0923 20:42:16.023975 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.023975 14316 net.cpp:137] Memory required for data: 122574000
I0923 20:42:16.023975 14316 layer_factory.cpp:58] Creating layer scale4
I0923 20:42:16.023975 14316 net.cpp:84] Creating Layer scale4
I0923 20:42:16.023975 14316 net.cpp:406] scale4 <- conv4
I0923 20:42:16.023975 14316 net.cpp:367] scale4 -> conv4 (in-place)
I0923 20:42:16.023975 14316 layer_factory.cpp:58] Creating layer scale4
I0923 20:42:16.023975 14316 net.cpp:122] Setting up scale4
I0923 20:42:16.023975 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.023975 14316 net.cpp:137] Memory required for data: 124519600
I0923 20:42:16.023975 14316 layer_factory.cpp:58] Creating layer relu4
I0923 20:42:16.023975 14316 net.cpp:84] Creating Layer relu4
I0923 20:42:16.023975 14316 net.cpp:406] relu4 <- conv4
I0923 20:42:16.023975 14316 net.cpp:367] relu4 -> conv4 (in-place)
I0923 20:42:16.023975 14316 net.cpp:122] Setting up relu4
I0923 20:42:16.023975 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.023975 14316 net.cpp:137] Memory required for data: 126465200
I0923 20:42:16.023975 14316 layer_factory.cpp:58] Creating layer conv4_1
I0923 20:42:16.023975 14316 net.cpp:84] Creating Layer conv4_1
I0923 20:42:16.023975 14316 net.cpp:406] conv4_1 <- conv4
I0923 20:42:16.023975 14316 net.cpp:380] conv4_1 -> conv4_1
I0923 20:42:16.024976 14316 net.cpp:122] Setting up conv4_1
I0923 20:42:16.024976 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.024976 14316 net.cpp:137] Memory required for data: 128410800
I0923 20:42:16.024976 14316 layer_factory.cpp:58] Creating layer bn4_1
I0923 20:42:16.024976 14316 net.cpp:84] Creating Layer bn4_1
I0923 20:42:16.024976 14316 net.cpp:406] bn4_1 <- conv4_1
I0923 20:42:16.024976 14316 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0923 20:42:16.024976 14316 net.cpp:122] Setting up bn4_1
I0923 20:42:16.024976 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.024976 14316 net.cpp:137] Memory required for data: 130356400
I0923 20:42:16.024976 14316 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:42:16.024976 14316 net.cpp:84] Creating Layer scale4_1
I0923 20:42:16.024976 14316 net.cpp:406] scale4_1 <- conv4_1
I0923 20:42:16.024976 14316 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0923 20:42:16.024976 14316 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:42:16.024976 14316 net.cpp:122] Setting up scale4_1
I0923 20:42:16.025977 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.025977 14316 net.cpp:137] Memory required for data: 132302000
I0923 20:42:16.025977 14316 layer_factory.cpp:58] Creating layer relu4_1
I0923 20:42:16.025977 14316 net.cpp:84] Creating Layer relu4_1
I0923 20:42:16.025977 14316 net.cpp:406] relu4_1 <- conv4_1
I0923 20:42:16.025977 14316 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0923 20:42:16.025977 14316 net.cpp:122] Setting up relu4_1
I0923 20:42:16.025977 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.025977 14316 net.cpp:137] Memory required for data: 134247600
I0923 20:42:16.025977 14316 layer_factory.cpp:58] Creating layer conv4_2
I0923 20:42:16.025977 14316 net.cpp:84] Creating Layer conv4_2
I0923 20:42:16.025977 14316 net.cpp:406] conv4_2 <- conv4_1
I0923 20:42:16.025977 14316 net.cpp:380] conv4_2 -> conv4_2
I0923 20:42:16.028182 14316 net.cpp:122] Setting up conv4_2
I0923 20:42:16.028182 14316 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:42:16.028182 14316 net.cpp:137] Memory required for data: 137114800
I0923 20:42:16.028182 14316 layer_factory.cpp:58] Creating layer bn4_2
I0923 20:42:16.028182 14316 net.cpp:84] Creating Layer bn4_2
I0923 20:42:16.028182 14316 net.cpp:406] bn4_2 <- conv4_2
I0923 20:42:16.028182 14316 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0923 20:42:16.028182 14316 net.cpp:122] Setting up bn4_2
I0923 20:42:16.028182 14316 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:42:16.028182 14316 net.cpp:137] Memory required for data: 139982000
I0923 20:42:16.028182 14316 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:42:16.028182 14316 net.cpp:84] Creating Layer scale4_2
I0923 20:42:16.028182 14316 net.cpp:406] scale4_2 <- conv4_2
I0923 20:42:16.028182 14316 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0923 20:42:16.028182 14316 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:42:16.028182 14316 net.cpp:122] Setting up scale4_2
I0923 20:42:16.028182 14316 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:42:16.028182 14316 net.cpp:137] Memory required for data: 142849200
I0923 20:42:16.028182 14316 layer_factory.cpp:58] Creating layer relu4_2
I0923 20:42:16.028182 14316 net.cpp:84] Creating Layer relu4_2
I0923 20:42:16.028182 14316 net.cpp:406] relu4_2 <- conv4_2
I0923 20:42:16.028182 14316 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0923 20:42:16.028182 14316 net.cpp:122] Setting up relu4_2
I0923 20:42:16.028182 14316 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:42:16.028182 14316 net.cpp:137] Memory required for data: 145716400
I0923 20:42:16.028182 14316 layer_factory.cpp:58] Creating layer pool4_2
I0923 20:42:16.028182 14316 net.cpp:84] Creating Layer pool4_2
I0923 20:42:16.028182 14316 net.cpp:406] pool4_2 <- conv4_2
I0923 20:42:16.028182 14316 net.cpp:380] pool4_2 -> pool4_2
I0923 20:42:16.028182 14316 net.cpp:122] Setting up pool4_2
I0923 20:42:16.028182 14316 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:42:16.028182 14316 net.cpp:137] Memory required for data: 146433200
I0923 20:42:16.028182 14316 layer_factory.cpp:58] Creating layer conv4_0
I0923 20:42:16.028182 14316 net.cpp:84] Creating Layer conv4_0
I0923 20:42:16.028182 14316 net.cpp:406] conv4_0 <- pool4_2
I0923 20:42:16.028182 14316 net.cpp:380] conv4_0 -> conv4_0
I0923 20:42:16.029184 14316 net.cpp:122] Setting up conv4_0
I0923 20:42:16.029184 14316 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:42:16.029184 14316 net.cpp:137] Memory required for data: 147150000
I0923 20:42:16.029184 14316 layer_factory.cpp:58] Creating layer bn4_0
I0923 20:42:16.029184 14316 net.cpp:84] Creating Layer bn4_0
I0923 20:42:16.029184 14316 net.cpp:406] bn4_0 <- conv4_0
I0923 20:42:16.029184 14316 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0923 20:42:16.030185 14316 net.cpp:122] Setting up bn4_0
I0923 20:42:16.030185 14316 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:42:16.030185 14316 net.cpp:137] Memory required for data: 147866800
I0923 20:42:16.030185 14316 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:42:16.030185 14316 net.cpp:84] Creating Layer scale4_0
I0923 20:42:16.030185 14316 net.cpp:406] scale4_0 <- conv4_0
I0923 20:42:16.030185 14316 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0923 20:42:16.030185 14316 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:42:16.030185 14316 net.cpp:122] Setting up scale4_0
I0923 20:42:16.030185 14316 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:42:16.030185 14316 net.cpp:137] Memory required for data: 148583600
I0923 20:42:16.030185 14316 layer_factory.cpp:58] Creating layer relu4_0
I0923 20:42:16.030185 14316 net.cpp:84] Creating Layer relu4_0
I0923 20:42:16.030185 14316 net.cpp:406] relu4_0 <- conv4_0
I0923 20:42:16.030185 14316 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0923 20:42:16.030185 14316 net.cpp:122] Setting up relu4_0
I0923 20:42:16.030185 14316 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:42:16.030185 14316 net.cpp:137] Memory required for data: 149300400
I0923 20:42:16.030185 14316 layer_factory.cpp:58] Creating layer conv11
I0923 20:42:16.030185 14316 net.cpp:84] Creating Layer conv11
I0923 20:42:16.030185 14316 net.cpp:406] conv11 <- conv4_0
I0923 20:42:16.030185 14316 net.cpp:380] conv11 -> conv11
I0923 20:42:16.031185 14316 net.cpp:122] Setting up conv11
I0923 20:42:16.031185 14316 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:42:16.031185 14316 net.cpp:137] Memory required for data: 150196400
I0923 20:42:16.031185 14316 layer_factory.cpp:58] Creating layer bn_conv11
I0923 20:42:16.031185 14316 net.cpp:84] Creating Layer bn_conv11
I0923 20:42:16.031185 14316 net.cpp:406] bn_conv11 <- conv11
I0923 20:42:16.031185 14316 net.cpp:367] bn_conv11 -> conv11 (in-place)
I0923 20:42:16.031185 14316 net.cpp:122] Setting up bn_conv11
I0923 20:42:16.031185 14316 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:42:16.031185 14316 net.cpp:137] Memory required for data: 151092400
I0923 20:42:16.031185 14316 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:42:16.031185 14316 net.cpp:84] Creating Layer scale_conv11
I0923 20:42:16.031185 14316 net.cpp:406] scale_conv11 <- conv11
I0923 20:42:16.031185 14316 net.cpp:367] scale_conv11 -> conv11 (in-place)
I0923 20:42:16.031185 14316 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:42:16.032186 14316 net.cpp:122] Setting up scale_conv11
I0923 20:42:16.032186 14316 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:42:16.032186 14316 net.cpp:137] Memory required for data: 151988400
I0923 20:42:16.032186 14316 layer_factory.cpp:58] Creating layer relu_conv11
I0923 20:42:16.032186 14316 net.cpp:84] Creating Layer relu_conv11
I0923 20:42:16.032186 14316 net.cpp:406] relu_conv11 <- conv11
I0923 20:42:16.032186 14316 net.cpp:367] relu_conv11 -> conv11 (in-place)
I0923 20:42:16.032186 14316 net.cpp:122] Setting up relu_conv11
I0923 20:42:16.032186 14316 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:42:16.032186 14316 net.cpp:137] Memory required for data: 152884400
I0923 20:42:16.032186 14316 layer_factory.cpp:58] Creating layer conv12
I0923 20:42:16.032186 14316 net.cpp:84] Creating Layer conv12
I0923 20:42:16.032186 14316 net.cpp:406] conv12 <- conv11
I0923 20:42:16.032186 14316 net.cpp:380] conv12 -> conv12
I0923 20:42:16.033022 14316 net.cpp:122] Setting up conv12
I0923 20:42:16.033022 14316 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:42:16.033022 14316 net.cpp:137] Memory required for data: 153985200
I0923 20:42:16.033022 14316 layer_factory.cpp:58] Creating layer bn_conv12
I0923 20:42:16.033022 14316 net.cpp:84] Creating Layer bn_conv12
I0923 20:42:16.033022 14316 net.cpp:406] bn_conv12 <- conv12
I0923 20:42:16.033022 14316 net.cpp:367] bn_conv12 -> conv12 (in-place)
I0923 20:42:16.033022 14316 net.cpp:122] Setting up bn_conv12
I0923 20:42:16.033022 14316 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:42:16.033022 14316 net.cpp:137] Memory required for data: 155086000
I0923 20:42:16.033022 14316 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:42:16.033022 14316 net.cpp:84] Creating Layer scale_conv12
I0923 20:42:16.033022 14316 net.cpp:406] scale_conv12 <- conv12
I0923 20:42:16.033022 14316 net.cpp:367] scale_conv12 -> conv12 (in-place)
I0923 20:42:16.033022 14316 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:42:16.033022 14316 net.cpp:122] Setting up scale_conv12
I0923 20:42:16.033022 14316 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:42:16.033022 14316 net.cpp:137] Memory required for data: 156186800
I0923 20:42:16.033022 14316 layer_factory.cpp:58] Creating layer relu_conv12
I0923 20:42:16.033022 14316 net.cpp:84] Creating Layer relu_conv12
I0923 20:42:16.033022 14316 net.cpp:406] relu_conv12 <- conv12
I0923 20:42:16.033022 14316 net.cpp:367] relu_conv12 -> conv12 (in-place)
I0923 20:42:16.034024 14316 net.cpp:122] Setting up relu_conv12
I0923 20:42:16.034024 14316 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:42:16.034024 14316 net.cpp:137] Memory required for data: 157287600
I0923 20:42:16.034024 14316 layer_factory.cpp:58] Creating layer poolcp6
I0923 20:42:16.034024 14316 net.cpp:84] Creating Layer poolcp6
I0923 20:42:16.034024 14316 net.cpp:406] poolcp6 <- conv12
I0923 20:42:16.034024 14316 net.cpp:380] poolcp6 -> poolcp6
I0923 20:42:16.034024 14316 net.cpp:122] Setting up poolcp6
I0923 20:42:16.034024 14316 net.cpp:129] Top shape: 100 43 1 1 (4300)
I0923 20:42:16.034024 14316 net.cpp:137] Memory required for data: 157304800
I0923 20:42:16.034024 14316 layer_factory.cpp:58] Creating layer ip1
I0923 20:42:16.034024 14316 net.cpp:84] Creating Layer ip1
I0923 20:42:16.034024 14316 net.cpp:406] ip1 <- poolcp6
I0923 20:42:16.034024 14316 net.cpp:380] ip1 -> ip1
I0923 20:42:16.034024 14316 net.cpp:122] Setting up ip1
I0923 20:42:16.034024 14316 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:42:16.034024 14316 net.cpp:137] Memory required for data: 157308800
I0923 20:42:16.034024 14316 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0923 20:42:16.034024 14316 net.cpp:84] Creating Layer ip1_ip1_0_split
I0923 20:42:16.034024 14316 net.cpp:406] ip1_ip1_0_split <- ip1
I0923 20:42:16.034024 14316 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0923 20:42:16.034024 14316 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0923 20:42:16.034024 14316 net.cpp:122] Setting up ip1_ip1_0_split
I0923 20:42:16.034024 14316 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:42:16.034024 14316 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:42:16.034024 14316 net.cpp:137] Memory required for data: 157316800
I0923 20:42:16.034024 14316 layer_factory.cpp:58] Creating layer accuracy_training
I0923 20:42:16.034024 14316 net.cpp:84] Creating Layer accuracy_training
I0923 20:42:16.034024 14316 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0923 20:42:16.034024 14316 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I0923 20:42:16.034024 14316 net.cpp:380] accuracy_training -> accuracy_training
I0923 20:42:16.034024 14316 net.cpp:122] Setting up accuracy_training
I0923 20:42:16.034024 14316 net.cpp:129] Top shape: (1)
I0923 20:42:16.034024 14316 net.cpp:137] Memory required for data: 157316804
I0923 20:42:16.034024 14316 layer_factory.cpp:58] Creating layer loss
I0923 20:42:16.034024 14316 net.cpp:84] Creating Layer loss
I0923 20:42:16.034024 14316 net.cpp:406] loss <- ip1_ip1_0_split_1
I0923 20:42:16.034024 14316 net.cpp:406] loss <- label_cifar_1_split_1
I0923 20:42:16.034024 14316 net.cpp:380] loss -> loss
I0923 20:42:16.034024 14316 layer_factory.cpp:58] Creating layer loss
I0923 20:42:16.034786 14316 net.cpp:122] Setting up loss
I0923 20:42:16.034786 14316 net.cpp:129] Top shape: (1)
I0923 20:42:16.034786 14316 net.cpp:132]     with loss weight 1
I0923 20:42:16.034786 14316 net.cpp:137] Memory required for data: 157316808
I0923 20:42:16.034786 14316 net.cpp:198] loss needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:200] accuracy_training does not need backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] ip1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] poolcp6 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu_conv12 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale_conv12 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn_conv12 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv12 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu_conv11 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale_conv11 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn_conv11 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv11 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu4_0 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale4_0 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn4_0 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv4_0 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] pool4_2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu4_2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale4_2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn4_2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv4_2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu4_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale4_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn4_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv4_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu4 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale4 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn4 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv4 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu3_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale3_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn3_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv3_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu3 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale3 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn3 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv3 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] pool2_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu2_2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale2_2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn2_2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv2_2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu2_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale2_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn2_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv2_1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv2 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu1_0 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale1_0 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn1_0 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv1_0 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] relu1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] scale1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] bn1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:198] conv1 needs backward computation.
I0923 20:42:16.034786 14316 net.cpp:200] label_cifar_1_split does not need backward computation.
I0923 20:42:16.034786 14316 net.cpp:200] cifar does not need backward computation.
I0923 20:42:16.034786 14316 net.cpp:242] This network produces output accuracy_training
I0923 20:42:16.034786 14316 net.cpp:242] This network produces output loss
I0923 20:42:16.035789 14316 net.cpp:255] Network initialization done.
I0923 20:42:16.035789 14316 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:42:16.035789 14316 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0923 20:42:16.035789 14316 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0923 20:42:16.035789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0923 20:42:16.036789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0923 20:42:16.036789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I0923 20:42:16.036789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I0923 20:42:16.036789 14316 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0923 20:42:16.036789 14316 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_NoGroupCon_NoDrp_noaug"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0923 20:42:16.036789 14316 layer_factory.cpp:58] Creating layer cifar
I0923 20:42:16.042801 14316 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0923 20:42:16.042801 14316 net.cpp:84] Creating Layer cifar
I0923 20:42:16.042801 14316 net.cpp:380] cifar -> data
I0923 20:42:16.042801 14316 net.cpp:380] cifar -> label
I0923 20:42:16.042801 14316 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0923 20:42:16.042801 14316 data_layer.cpp:45] output data size: 100,3,32,32
I0923 20:42:16.049347 14316 net.cpp:122] Setting up cifar
I0923 20:42:16.049347 14316 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0923 20:42:16.049347 14316 net.cpp:129] Top shape: 100 (100)
I0923 20:42:16.049347 14316 net.cpp:137] Memory required for data: 1229200
I0923 20:42:16.049347 14316 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0923 20:42:16.049347 14316 net.cpp:84] Creating Layer label_cifar_1_split
I0923 20:42:16.049347 14316 net.cpp:406] label_cifar_1_split <- label
I0923 20:42:16.049347 14316 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0923 20:42:16.049347 14316 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0923 20:42:16.049347 14316 net.cpp:122] Setting up label_cifar_1_split
I0923 20:42:16.049347 14316 net.cpp:129] Top shape: 100 (100)
I0923 20:42:16.049347 14316 net.cpp:129] Top shape: 100 (100)
I0923 20:42:16.049347 14316 net.cpp:137] Memory required for data: 1230000
I0923 20:42:16.049347 14316 layer_factory.cpp:58] Creating layer conv1
I0923 20:42:16.049347 14316 net.cpp:84] Creating Layer conv1
I0923 20:42:16.049347 14316 net.cpp:406] conv1 <- data
I0923 20:42:16.049347 14316 net.cpp:380] conv1 -> conv1
I0923 20:42:16.050349 15900 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:42:16.051349 14316 net.cpp:122] Setting up conv1
I0923 20:42:16.051349 14316 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:42:16.051349 14316 net.cpp:137] Memory required for data: 3687600
I0923 20:42:16.051349 14316 layer_factory.cpp:58] Creating layer bn1
I0923 20:42:16.051349 14316 net.cpp:84] Creating Layer bn1
I0923 20:42:16.051349 14316 net.cpp:406] bn1 <- conv1
I0923 20:42:16.051349 14316 net.cpp:367] bn1 -> conv1 (in-place)
I0923 20:42:16.051349 14316 net.cpp:122] Setting up bn1
I0923 20:42:16.051349 14316 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:42:16.051349 14316 net.cpp:137] Memory required for data: 6145200
I0923 20:42:16.051349 14316 layer_factory.cpp:58] Creating layer scale1
I0923 20:42:16.051349 14316 net.cpp:84] Creating Layer scale1
I0923 20:42:16.051349 14316 net.cpp:406] scale1 <- conv1
I0923 20:42:16.051349 14316 net.cpp:367] scale1 -> conv1 (in-place)
I0923 20:42:16.051349 14316 layer_factory.cpp:58] Creating layer scale1
I0923 20:42:16.051349 14316 net.cpp:122] Setting up scale1
I0923 20:42:16.051349 14316 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:42:16.051349 14316 net.cpp:137] Memory required for data: 8602800
I0923 20:42:16.051349 14316 layer_factory.cpp:58] Creating layer relu1
I0923 20:42:16.051349 14316 net.cpp:84] Creating Layer relu1
I0923 20:42:16.051349 14316 net.cpp:406] relu1 <- conv1
I0923 20:42:16.051349 14316 net.cpp:367] relu1 -> conv1 (in-place)
I0923 20:42:16.051349 14316 net.cpp:122] Setting up relu1
I0923 20:42:16.051349 14316 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:42:16.051349 14316 net.cpp:137] Memory required for data: 11060400
I0923 20:42:16.051349 14316 layer_factory.cpp:58] Creating layer conv1_0
I0923 20:42:16.051349 14316 net.cpp:84] Creating Layer conv1_0
I0923 20:42:16.051349 14316 net.cpp:406] conv1_0 <- conv1
I0923 20:42:16.051349 14316 net.cpp:380] conv1_0 -> conv1_0
I0923 20:42:16.053351 14316 net.cpp:122] Setting up conv1_0
I0923 20:42:16.053351 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.053351 14316 net.cpp:137] Memory required for data: 15975600
I0923 20:42:16.053351 14316 layer_factory.cpp:58] Creating layer bn1_0
I0923 20:42:16.053351 14316 net.cpp:84] Creating Layer bn1_0
I0923 20:42:16.053351 14316 net.cpp:406] bn1_0 <- conv1_0
I0923 20:42:16.053351 14316 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0923 20:42:16.053351 14316 net.cpp:122] Setting up bn1_0
I0923 20:42:16.053351 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.053351 14316 net.cpp:137] Memory required for data: 20890800
I0923 20:42:16.053351 14316 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:42:16.053351 14316 net.cpp:84] Creating Layer scale1_0
I0923 20:42:16.053351 14316 net.cpp:406] scale1_0 <- conv1_0
I0923 20:42:16.053351 14316 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0923 20:42:16.053351 14316 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:42:16.053351 14316 net.cpp:122] Setting up scale1_0
I0923 20:42:16.053351 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.053351 14316 net.cpp:137] Memory required for data: 25806000
I0923 20:42:16.053351 14316 layer_factory.cpp:58] Creating layer relu1_0
I0923 20:42:16.053351 14316 net.cpp:84] Creating Layer relu1_0
I0923 20:42:16.053351 14316 net.cpp:406] relu1_0 <- conv1_0
I0923 20:42:16.053351 14316 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0923 20:42:16.053351 14316 net.cpp:122] Setting up relu1_0
I0923 20:42:16.053351 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.053351 14316 net.cpp:137] Memory required for data: 30721200
I0923 20:42:16.053351 14316 layer_factory.cpp:58] Creating layer conv2
I0923 20:42:16.053351 14316 net.cpp:84] Creating Layer conv2
I0923 20:42:16.053351 14316 net.cpp:406] conv2 <- conv1_0
I0923 20:42:16.053351 14316 net.cpp:380] conv2 -> conv2
I0923 20:42:16.054981 14316 net.cpp:122] Setting up conv2
I0923 20:42:16.054981 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.054981 14316 net.cpp:137] Memory required for data: 35636400
I0923 20:42:16.054981 14316 layer_factory.cpp:58] Creating layer bn2
I0923 20:42:16.054981 14316 net.cpp:84] Creating Layer bn2
I0923 20:42:16.054981 14316 net.cpp:406] bn2 <- conv2
I0923 20:42:16.054981 14316 net.cpp:367] bn2 -> conv2 (in-place)
I0923 20:42:16.054981 14316 net.cpp:122] Setting up bn2
I0923 20:42:16.054981 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.054981 14316 net.cpp:137] Memory required for data: 40551600
I0923 20:42:16.054981 14316 layer_factory.cpp:58] Creating layer scale2
I0923 20:42:16.054981 14316 net.cpp:84] Creating Layer scale2
I0923 20:42:16.054981 14316 net.cpp:406] scale2 <- conv2
I0923 20:42:16.054981 14316 net.cpp:367] scale2 -> conv2 (in-place)
I0923 20:42:16.054981 14316 layer_factory.cpp:58] Creating layer scale2
I0923 20:42:16.054981 14316 net.cpp:122] Setting up scale2
I0923 20:42:16.054981 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.054981 14316 net.cpp:137] Memory required for data: 45466800
I0923 20:42:16.054981 14316 layer_factory.cpp:58] Creating layer relu2
I0923 20:42:16.054981 14316 net.cpp:84] Creating Layer relu2
I0923 20:42:16.054981 14316 net.cpp:406] relu2 <- conv2
I0923 20:42:16.054981 14316 net.cpp:367] relu2 -> conv2 (in-place)
I0923 20:42:16.054981 14316 net.cpp:122] Setting up relu2
I0923 20:42:16.054981 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.054981 14316 net.cpp:137] Memory required for data: 50382000
I0923 20:42:16.055984 14316 layer_factory.cpp:58] Creating layer conv2_1
I0923 20:42:16.055984 14316 net.cpp:84] Creating Layer conv2_1
I0923 20:42:16.055984 14316 net.cpp:406] conv2_1 <- conv2
I0923 20:42:16.055984 14316 net.cpp:380] conv2_1 -> conv2_1
I0923 20:42:16.056494 14316 net.cpp:122] Setting up conv2_1
I0923 20:42:16.056494 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.056494 14316 net.cpp:137] Memory required for data: 55297200
I0923 20:42:16.056494 14316 layer_factory.cpp:58] Creating layer bn2_1
I0923 20:42:16.056494 14316 net.cpp:84] Creating Layer bn2_1
I0923 20:42:16.056494 14316 net.cpp:406] bn2_1 <- conv2_1
I0923 20:42:16.056494 14316 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0923 20:42:16.056494 14316 net.cpp:122] Setting up bn2_1
I0923 20:42:16.056494 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.056494 14316 net.cpp:137] Memory required for data: 60212400
I0923 20:42:16.056494 14316 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:42:16.056494 14316 net.cpp:84] Creating Layer scale2_1
I0923 20:42:16.056494 14316 net.cpp:406] scale2_1 <- conv2_1
I0923 20:42:16.056494 14316 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0923 20:42:16.056494 14316 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:42:16.056494 14316 net.cpp:122] Setting up scale2_1
I0923 20:42:16.056494 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.056494 14316 net.cpp:137] Memory required for data: 65127600
I0923 20:42:16.056494 14316 layer_factory.cpp:58] Creating layer relu2_1
I0923 20:42:16.056494 14316 net.cpp:84] Creating Layer relu2_1
I0923 20:42:16.056494 14316 net.cpp:406] relu2_1 <- conv2_1
I0923 20:42:16.056494 14316 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0923 20:42:16.057497 14316 net.cpp:122] Setting up relu2_1
I0923 20:42:16.057497 14316 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:42:16.057497 14316 net.cpp:137] Memory required for data: 70042800
I0923 20:42:16.057497 14316 layer_factory.cpp:58] Creating layer conv2_2
I0923 20:42:16.057497 14316 net.cpp:84] Creating Layer conv2_2
I0923 20:42:16.057497 14316 net.cpp:406] conv2_2 <- conv2_1
I0923 20:42:16.057497 14316 net.cpp:380] conv2_2 -> conv2_2
I0923 20:42:16.058497 14316 net.cpp:122] Setting up conv2_2
I0923 20:42:16.058497 14316 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:42:16.058497 14316 net.cpp:137] Memory required for data: 77825200
I0923 20:42:16.058497 14316 layer_factory.cpp:58] Creating layer bn2_2
I0923 20:42:16.058497 14316 net.cpp:84] Creating Layer bn2_2
I0923 20:42:16.058497 14316 net.cpp:406] bn2_2 <- conv2_2
I0923 20:42:16.058497 14316 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0923 20:42:16.058497 14316 net.cpp:122] Setting up bn2_2
I0923 20:42:16.058497 14316 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:42:16.058497 14316 net.cpp:137] Memory required for data: 85607600
I0923 20:42:16.058497 14316 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:42:16.058497 14316 net.cpp:84] Creating Layer scale2_2
I0923 20:42:16.058497 14316 net.cpp:406] scale2_2 <- conv2_2
I0923 20:42:16.058497 14316 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0923 20:42:16.058497 14316 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:42:16.058497 14316 net.cpp:122] Setting up scale2_2
I0923 20:42:16.058497 14316 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:42:16.058497 14316 net.cpp:137] Memory required for data: 93390000
I0923 20:42:16.058497 14316 layer_factory.cpp:58] Creating layer relu2_2
I0923 20:42:16.058497 14316 net.cpp:84] Creating Layer relu2_2
I0923 20:42:16.058497 14316 net.cpp:406] relu2_2 <- conv2_2
I0923 20:42:16.058497 14316 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0923 20:42:16.059497 14316 net.cpp:122] Setting up relu2_2
I0923 20:42:16.059497 14316 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:42:16.059497 14316 net.cpp:137] Memory required for data: 101172400
I0923 20:42:16.059497 14316 layer_factory.cpp:58] Creating layer pool2_1
I0923 20:42:16.059497 14316 net.cpp:84] Creating Layer pool2_1
I0923 20:42:16.059497 14316 net.cpp:406] pool2_1 <- conv2_2
I0923 20:42:16.059497 14316 net.cpp:380] pool2_1 -> pool2_1
I0923 20:42:16.059497 14316 net.cpp:122] Setting up pool2_1
I0923 20:42:16.059497 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.059497 14316 net.cpp:137] Memory required for data: 103118000
I0923 20:42:16.059497 14316 layer_factory.cpp:58] Creating layer conv3
I0923 20:42:16.059497 14316 net.cpp:84] Creating Layer conv3
I0923 20:42:16.059497 14316 net.cpp:406] conv3 <- pool2_1
I0923 20:42:16.059497 14316 net.cpp:380] conv3 -> conv3
I0923 20:42:16.060498 14316 net.cpp:122] Setting up conv3
I0923 20:42:16.060498 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.060498 14316 net.cpp:137] Memory required for data: 105063600
I0923 20:42:16.060498 14316 layer_factory.cpp:58] Creating layer bn3
I0923 20:42:16.060498 14316 net.cpp:84] Creating Layer bn3
I0923 20:42:16.060498 14316 net.cpp:406] bn3 <- conv3
I0923 20:42:16.060498 14316 net.cpp:367] bn3 -> conv3 (in-place)
I0923 20:42:16.060498 14316 net.cpp:122] Setting up bn3
I0923 20:42:16.060498 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.060498 14316 net.cpp:137] Memory required for data: 107009200
I0923 20:42:16.060498 14316 layer_factory.cpp:58] Creating layer scale3
I0923 20:42:16.060498 14316 net.cpp:84] Creating Layer scale3
I0923 20:42:16.060498 14316 net.cpp:406] scale3 <- conv3
I0923 20:42:16.060498 14316 net.cpp:367] scale3 -> conv3 (in-place)
I0923 20:42:16.060498 14316 layer_factory.cpp:58] Creating layer scale3
I0923 20:42:16.060498 14316 net.cpp:122] Setting up scale3
I0923 20:42:16.060498 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.060498 14316 net.cpp:137] Memory required for data: 108954800
I0923 20:42:16.060498 14316 layer_factory.cpp:58] Creating layer relu3
I0923 20:42:16.060498 14316 net.cpp:84] Creating Layer relu3
I0923 20:42:16.060498 14316 net.cpp:406] relu3 <- conv3
I0923 20:42:16.060498 14316 net.cpp:367] relu3 -> conv3 (in-place)
I0923 20:42:16.061504 14316 net.cpp:122] Setting up relu3
I0923 20:42:16.061504 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.061504 14316 net.cpp:137] Memory required for data: 110900400
I0923 20:42:16.061504 14316 layer_factory.cpp:58] Creating layer conv3_1
I0923 20:42:16.061504 14316 net.cpp:84] Creating Layer conv3_1
I0923 20:42:16.061504 14316 net.cpp:406] conv3_1 <- conv3
I0923 20:42:16.061504 14316 net.cpp:380] conv3_1 -> conv3_1
I0923 20:42:16.063352 14316 net.cpp:122] Setting up conv3_1
I0923 20:42:16.063352 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.063352 14316 net.cpp:137] Memory required for data: 112846000
I0923 20:42:16.063352 14316 layer_factory.cpp:58] Creating layer bn3_1
I0923 20:42:16.063352 14316 net.cpp:84] Creating Layer bn3_1
I0923 20:42:16.063352 14316 net.cpp:406] bn3_1 <- conv3_1
I0923 20:42:16.063352 14316 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I0923 20:42:16.063352 14316 net.cpp:122] Setting up bn3_1
I0923 20:42:16.063352 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.063352 14316 net.cpp:137] Memory required for data: 114791600
I0923 20:42:16.063352 14316 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:42:16.063352 14316 net.cpp:84] Creating Layer scale3_1
I0923 20:42:16.063352 14316 net.cpp:406] scale3_1 <- conv3_1
I0923 20:42:16.063352 14316 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I0923 20:42:16.063352 14316 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:42:16.063352 14316 net.cpp:122] Setting up scale3_1
I0923 20:42:16.063352 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.063352 14316 net.cpp:137] Memory required for data: 116737200
I0923 20:42:16.063352 14316 layer_factory.cpp:58] Creating layer relu3_1
I0923 20:42:16.063352 14316 net.cpp:84] Creating Layer relu3_1
I0923 20:42:16.063352 14316 net.cpp:406] relu3_1 <- conv3_1
I0923 20:42:16.063352 14316 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0923 20:42:16.063352 14316 net.cpp:122] Setting up relu3_1
I0923 20:42:16.063352 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.063352 14316 net.cpp:137] Memory required for data: 118682800
I0923 20:42:16.063352 14316 layer_factory.cpp:58] Creating layer conv4
I0923 20:42:16.063352 14316 net.cpp:84] Creating Layer conv4
I0923 20:42:16.063352 14316 net.cpp:406] conv4 <- conv3_1
I0923 20:42:16.063352 14316 net.cpp:380] conv4 -> conv4
I0923 20:42:16.064354 14316 net.cpp:122] Setting up conv4
I0923 20:42:16.064354 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.064354 14316 net.cpp:137] Memory required for data: 120628400
I0923 20:42:16.064354 14316 layer_factory.cpp:58] Creating layer bn4
I0923 20:42:16.064354 14316 net.cpp:84] Creating Layer bn4
I0923 20:42:16.064354 14316 net.cpp:406] bn4 <- conv4
I0923 20:42:16.064354 14316 net.cpp:367] bn4 -> conv4 (in-place)
I0923 20:42:16.064354 14316 net.cpp:122] Setting up bn4
I0923 20:42:16.064354 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.065354 14316 net.cpp:137] Memory required for data: 122574000
I0923 20:42:16.065354 14316 layer_factory.cpp:58] Creating layer scale4
I0923 20:42:16.065354 14316 net.cpp:84] Creating Layer scale4
I0923 20:42:16.065354 14316 net.cpp:406] scale4 <- conv4
I0923 20:42:16.065354 14316 net.cpp:367] scale4 -> conv4 (in-place)
I0923 20:42:16.065354 14316 layer_factory.cpp:58] Creating layer scale4
I0923 20:42:16.065354 14316 net.cpp:122] Setting up scale4
I0923 20:42:16.065354 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.065354 14316 net.cpp:137] Memory required for data: 124519600
I0923 20:42:16.065354 14316 layer_factory.cpp:58] Creating layer relu4
I0923 20:42:16.065354 14316 net.cpp:84] Creating Layer relu4
I0923 20:42:16.065354 14316 net.cpp:406] relu4 <- conv4
I0923 20:42:16.065354 14316 net.cpp:367] relu4 -> conv4 (in-place)
I0923 20:42:16.065354 14316 net.cpp:122] Setting up relu4
I0923 20:42:16.065354 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.065354 14316 net.cpp:137] Memory required for data: 126465200
I0923 20:42:16.065354 14316 layer_factory.cpp:58] Creating layer conv4_1
I0923 20:42:16.065354 14316 net.cpp:84] Creating Layer conv4_1
I0923 20:42:16.065354 14316 net.cpp:406] conv4_1 <- conv4
I0923 20:42:16.065354 14316 net.cpp:380] conv4_1 -> conv4_1
I0923 20:42:16.066357 14316 net.cpp:122] Setting up conv4_1
I0923 20:42:16.066357 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.066357 14316 net.cpp:137] Memory required for data: 128410800
I0923 20:42:16.066357 14316 layer_factory.cpp:58] Creating layer bn4_1
I0923 20:42:16.066357 14316 net.cpp:84] Creating Layer bn4_1
I0923 20:42:16.066357 14316 net.cpp:406] bn4_1 <- conv4_1
I0923 20:42:16.066357 14316 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0923 20:42:16.066357 14316 net.cpp:122] Setting up bn4_1
I0923 20:42:16.066357 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.066357 14316 net.cpp:137] Memory required for data: 130356400
I0923 20:42:16.066357 14316 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:42:16.066357 14316 net.cpp:84] Creating Layer scale4_1
I0923 20:42:16.066357 14316 net.cpp:406] scale4_1 <- conv4_1
I0923 20:42:16.066357 14316 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0923 20:42:16.067359 14316 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:42:16.067359 14316 net.cpp:122] Setting up scale4_1
I0923 20:42:16.067359 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.067359 14316 net.cpp:137] Memory required for data: 132302000
I0923 20:42:16.067359 14316 layer_factory.cpp:58] Creating layer relu4_1
I0923 20:42:16.067359 14316 net.cpp:84] Creating Layer relu4_1
I0923 20:42:16.067359 14316 net.cpp:406] relu4_1 <- conv4_1
I0923 20:42:16.067359 14316 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0923 20:42:16.067359 14316 net.cpp:122] Setting up relu4_1
I0923 20:42:16.067359 14316 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:42:16.067359 14316 net.cpp:137] Memory required for data: 134247600
I0923 20:42:16.067359 14316 layer_factory.cpp:58] Creating layer conv4_2
I0923 20:42:16.067359 14316 net.cpp:84] Creating Layer conv4_2
I0923 20:42:16.067359 14316 net.cpp:406] conv4_2 <- conv4_1
I0923 20:42:16.067359 14316 net.cpp:380] conv4_2 -> conv4_2
I0923 20:42:16.068361 14316 net.cpp:122] Setting up conv4_2
I0923 20:42:16.068361 14316 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:42:16.068361 14316 net.cpp:137] Memory required for data: 137114800
I0923 20:42:16.068361 14316 layer_factory.cpp:58] Creating layer bn4_2
I0923 20:42:16.068361 14316 net.cpp:84] Creating Layer bn4_2
I0923 20:42:16.068361 14316 net.cpp:406] bn4_2 <- conv4_2
I0923 20:42:16.068361 14316 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0923 20:42:16.068361 14316 net.cpp:122] Setting up bn4_2
I0923 20:42:16.068361 14316 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:42:16.068361 14316 net.cpp:137] Memory required for data: 139982000
I0923 20:42:16.068361 14316 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:42:16.068361 14316 net.cpp:84] Creating Layer scale4_2
I0923 20:42:16.068361 14316 net.cpp:406] scale4_2 <- conv4_2
I0923 20:42:16.068361 14316 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0923 20:42:16.068361 14316 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:42:16.068361 14316 net.cpp:122] Setting up scale4_2
I0923 20:42:16.068361 14316 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:42:16.068361 14316 net.cpp:137] Memory required for data: 142849200
I0923 20:42:16.068361 14316 layer_factory.cpp:58] Creating layer relu4_2
I0923 20:42:16.068361 14316 net.cpp:84] Creating Layer relu4_2
I0923 20:42:16.068361 14316 net.cpp:406] relu4_2 <- conv4_2
I0923 20:42:16.068361 14316 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0923 20:42:16.068361 14316 net.cpp:122] Setting up relu4_2
I0923 20:42:16.068361 14316 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:42:16.068361 14316 net.cpp:137] Memory required for data: 145716400
I0923 20:42:16.068361 14316 layer_factory.cpp:58] Creating layer pool4_2
I0923 20:42:16.069361 14316 net.cpp:84] Creating Layer pool4_2
I0923 20:42:16.069361 14316 net.cpp:406] pool4_2 <- conv4_2
I0923 20:42:16.069361 14316 net.cpp:380] pool4_2 -> pool4_2
I0923 20:42:16.069361 14316 net.cpp:122] Setting up pool4_2
I0923 20:42:16.069361 14316 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:42:16.069361 14316 net.cpp:137] Memory required for data: 146433200
I0923 20:42:16.069361 14316 layer_factory.cpp:58] Creating layer conv4_0
I0923 20:42:16.069361 14316 net.cpp:84] Creating Layer conv4_0
I0923 20:42:16.069361 14316 net.cpp:406] conv4_0 <- pool4_2
I0923 20:42:16.069361 14316 net.cpp:380] conv4_0 -> conv4_0
I0923 20:42:16.069872 14316 net.cpp:122] Setting up conv4_0
I0923 20:42:16.069872 14316 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:42:16.069872 14316 net.cpp:137] Memory required for data: 147150000
I0923 20:42:16.069872 14316 layer_factory.cpp:58] Creating layer bn4_0
I0923 20:42:16.069872 14316 net.cpp:84] Creating Layer bn4_0
I0923 20:42:16.069872 14316 net.cpp:406] bn4_0 <- conv4_0
I0923 20:42:16.069872 14316 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0923 20:42:16.069872 14316 net.cpp:122] Setting up bn4_0
I0923 20:42:16.069872 14316 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:42:16.069872 14316 net.cpp:137] Memory required for data: 147866800
I0923 20:42:16.069872 14316 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:42:16.069872 14316 net.cpp:84] Creating Layer scale4_0
I0923 20:42:16.069872 14316 net.cpp:406] scale4_0 <- conv4_0
I0923 20:42:16.069872 14316 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0923 20:42:16.069872 14316 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:42:16.070874 14316 net.cpp:122] Setting up scale4_0
I0923 20:42:16.070874 14316 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:42:16.070874 14316 net.cpp:137] Memory required for data: 148583600
I0923 20:42:16.070874 14316 layer_factory.cpp:58] Creating layer relu4_0
I0923 20:42:16.070874 14316 net.cpp:84] Creating Layer relu4_0
I0923 20:42:16.070874 14316 net.cpp:406] relu4_0 <- conv4_0
I0923 20:42:16.070874 14316 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0923 20:42:16.071259 14316 net.cpp:122] Setting up relu4_0
I0923 20:42:16.071259 14316 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:42:16.071259 14316 net.cpp:137] Memory required for data: 149300400
I0923 20:42:16.071259 14316 layer_factory.cpp:58] Creating layer conv11
I0923 20:42:16.071259 14316 net.cpp:84] Creating Layer conv11
I0923 20:42:16.071259 14316 net.cpp:406] conv11 <- conv4_0
I0923 20:42:16.071259 14316 net.cpp:380] conv11 -> conv11
I0923 20:42:16.072260 14316 net.cpp:122] Setting up conv11
I0923 20:42:16.072260 14316 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:42:16.072260 14316 net.cpp:137] Memory required for data: 150196400
I0923 20:42:16.072260 14316 layer_factory.cpp:58] Creating layer bn_conv11
I0923 20:42:16.072260 14316 net.cpp:84] Creating Layer bn_conv11
I0923 20:42:16.072260 14316 net.cpp:406] bn_conv11 <- conv11
I0923 20:42:16.072260 14316 net.cpp:367] bn_conv11 -> conv11 (in-place)
I0923 20:42:16.072260 14316 net.cpp:122] Setting up bn_conv11
I0923 20:42:16.072260 14316 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:42:16.072260 14316 net.cpp:137] Memory required for data: 151092400
I0923 20:42:16.072260 14316 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:42:16.072260 14316 net.cpp:84] Creating Layer scale_conv11
I0923 20:42:16.072260 14316 net.cpp:406] scale_conv11 <- conv11
I0923 20:42:16.072260 14316 net.cpp:367] scale_conv11 -> conv11 (in-place)
I0923 20:42:16.072760 14316 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:42:16.072760 14316 net.cpp:122] Setting up scale_conv11
I0923 20:42:16.072760 14316 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:42:16.072760 14316 net.cpp:137] Memory required for data: 151988400
I0923 20:42:16.072760 14316 layer_factory.cpp:58] Creating layer relu_conv11
I0923 20:42:16.072760 14316 net.cpp:84] Creating Layer relu_conv11
I0923 20:42:16.072760 14316 net.cpp:406] relu_conv11 <- conv11
I0923 20:42:16.072760 14316 net.cpp:367] relu_conv11 -> conv11 (in-place)
I0923 20:42:16.073262 14316 net.cpp:122] Setting up relu_conv11
I0923 20:42:16.073262 14316 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:42:16.073262 14316 net.cpp:137] Memory required for data: 152884400
I0923 20:42:16.073262 14316 layer_factory.cpp:58] Creating layer conv12
I0923 20:42:16.073262 14316 net.cpp:84] Creating Layer conv12
I0923 20:42:16.073262 14316 net.cpp:406] conv12 <- conv11
I0923 20:42:16.073262 14316 net.cpp:380] conv12 -> conv12
I0923 20:42:16.074512 14316 net.cpp:122] Setting up conv12
I0923 20:42:16.074512 14316 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:42:16.074512 14316 net.cpp:137] Memory required for data: 153985200
I0923 20:42:16.074512 14316 layer_factory.cpp:58] Creating layer bn_conv12
I0923 20:42:16.074512 14316 net.cpp:84] Creating Layer bn_conv12
I0923 20:42:16.074512 14316 net.cpp:406] bn_conv12 <- conv12
I0923 20:42:16.074512 14316 net.cpp:367] bn_conv12 -> conv12 (in-place)
I0923 20:42:16.074512 14316 net.cpp:122] Setting up bn_conv12
I0923 20:42:16.074512 14316 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:42:16.074512 14316 net.cpp:137] Memory required for data: 155086000
I0923 20:42:16.075013 14316 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:42:16.075013 14316 net.cpp:84] Creating Layer scale_conv12
I0923 20:42:16.075013 14316 net.cpp:406] scale_conv12 <- conv12
I0923 20:42:16.075013 14316 net.cpp:367] scale_conv12 -> conv12 (in-place)
I0923 20:42:16.075013 14316 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:42:16.075013 14316 net.cpp:122] Setting up scale_conv12
I0923 20:42:16.075013 14316 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:42:16.075013 14316 net.cpp:137] Memory required for data: 156186800
I0923 20:42:16.075013 14316 layer_factory.cpp:58] Creating layer relu_conv12
I0923 20:42:16.075013 14316 net.cpp:84] Creating Layer relu_conv12
I0923 20:42:16.075013 14316 net.cpp:406] relu_conv12 <- conv12
I0923 20:42:16.075013 14316 net.cpp:367] relu_conv12 -> conv12 (in-place)
I0923 20:42:16.075515 14316 net.cpp:122] Setting up relu_conv12
I0923 20:42:16.075515 14316 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:42:16.075515 14316 net.cpp:137] Memory required for data: 157287600
I0923 20:42:16.075515 14316 layer_factory.cpp:58] Creating layer poolcp6
I0923 20:42:16.075515 14316 net.cpp:84] Creating Layer poolcp6
I0923 20:42:16.075515 14316 net.cpp:406] poolcp6 <- conv12
I0923 20:42:16.075515 14316 net.cpp:380] poolcp6 -> poolcp6
I0923 20:42:16.075515 14316 net.cpp:122] Setting up poolcp6
I0923 20:42:16.075515 14316 net.cpp:129] Top shape: 100 43 1 1 (4300)
I0923 20:42:16.075515 14316 net.cpp:137] Memory required for data: 157304800
I0923 20:42:16.075515 14316 layer_factory.cpp:58] Creating layer ip1
I0923 20:42:16.075515 14316 net.cpp:84] Creating Layer ip1
I0923 20:42:16.075515 14316 net.cpp:406] ip1 <- poolcp6
I0923 20:42:16.075515 14316 net.cpp:380] ip1 -> ip1
I0923 20:42:16.075515 14316 net.cpp:122] Setting up ip1
I0923 20:42:16.075515 14316 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:42:16.075515 14316 net.cpp:137] Memory required for data: 157308800
I0923 20:42:16.075515 14316 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0923 20:42:16.075515 14316 net.cpp:84] Creating Layer ip1_ip1_0_split
I0923 20:42:16.075515 14316 net.cpp:406] ip1_ip1_0_split <- ip1
I0923 20:42:16.075515 14316 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0923 20:42:16.075515 14316 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0923 20:42:16.075515 14316 net.cpp:122] Setting up ip1_ip1_0_split
I0923 20:42:16.075515 14316 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:42:16.075515 14316 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:42:16.075515 14316 net.cpp:137] Memory required for data: 157316800
I0923 20:42:16.075515 14316 layer_factory.cpp:58] Creating layer accuracy
I0923 20:42:16.075515 14316 net.cpp:84] Creating Layer accuracy
I0923 20:42:16.075515 14316 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0923 20:42:16.075515 14316 net.cpp:406] accuracy <- label_cifar_1_split_0
I0923 20:42:16.075515 14316 net.cpp:380] accuracy -> accuracy
I0923 20:42:16.075515 14316 net.cpp:122] Setting up accuracy
I0923 20:42:16.075515 14316 net.cpp:129] Top shape: (1)
I0923 20:42:16.075515 14316 net.cpp:137] Memory required for data: 157316804
I0923 20:42:16.075515 14316 layer_factory.cpp:58] Creating layer loss
I0923 20:42:16.075515 14316 net.cpp:84] Creating Layer loss
I0923 20:42:16.075515 14316 net.cpp:406] loss <- ip1_ip1_0_split_1
I0923 20:42:16.075515 14316 net.cpp:406] loss <- label_cifar_1_split_1
I0923 20:42:16.075515 14316 net.cpp:380] loss -> loss
I0923 20:42:16.075515 14316 layer_factory.cpp:58] Creating layer loss
I0923 20:42:16.076014 14316 net.cpp:122] Setting up loss
I0923 20:42:16.076014 14316 net.cpp:129] Top shape: (1)
I0923 20:42:16.076014 14316 net.cpp:132]     with loss weight 1
I0923 20:42:16.076014 14316 net.cpp:137] Memory required for data: 157316808
I0923 20:42:16.076014 14316 net.cpp:198] loss needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:200] accuracy does not need backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] ip1 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] poolcp6 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] relu_conv12 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] scale_conv12 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] bn_conv12 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] conv12 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] relu_conv11 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] scale_conv11 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] bn_conv11 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] conv11 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] relu4_0 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] scale4_0 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] bn4_0 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] conv4_0 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] pool4_2 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] relu4_2 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] scale4_2 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] bn4_2 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] conv4_2 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] relu4_1 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] scale4_1 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] bn4_1 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] conv4_1 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] relu4 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] scale4 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] bn4 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] conv4 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] relu3_1 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] scale3_1 needs backward computation.
I0923 20:42:16.076014 14316 net.cpp:198] bn3_1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] conv3_1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] relu3 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] scale3 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] bn3 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] conv3 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] pool2_1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] relu2_2 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] scale2_2 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] bn2_2 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] conv2_2 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] relu2_1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] scale2_1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] bn2_1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] conv2_1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] relu2 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] scale2 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] bn2 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] conv2 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] relu1_0 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] scale1_0 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] bn1_0 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] conv1_0 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] relu1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] scale1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] bn1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:198] conv1 needs backward computation.
I0923 20:42:16.076514 14316 net.cpp:200] label_cifar_1_split does not need backward computation.
I0923 20:42:16.076514 14316 net.cpp:200] cifar does not need backward computation.
I0923 20:42:16.076514 14316 net.cpp:242] This network produces output accuracy
I0923 20:42:16.076514 14316 net.cpp:242] This network produces output loss
I0923 20:42:16.076514 14316 net.cpp:255] Network initialization done.
I0923 20:42:16.076514 14316 solver.cpp:56] Solver scaffolding done.
I0923 20:42:16.079517 14316 caffe.cpp:249] Starting Optimization
I0923 20:42:16.079517 14316 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_drpall_Simple_NoGroupCon_NoDrp_noaug
I0923 20:42:16.079517 14316 solver.cpp:273] Learning Rate Policy: multistep
I0923 20:42:16.080739 14316 solver.cpp:330] Iteration 0, Testing net (#0)
I0923 20:42:16.082741 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:42:16.627383 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:42:16.648398 14316 solver.cpp:397]     Test net output #0: accuracy = 0.107
I0923 20:42:16.648398 14316 solver.cpp:397]     Test net output #1: loss = 77.9915 (* 1 = 77.9915 loss)
I0923 20:42:16.697160 14316 solver.cpp:218] Iteration 0 (0 iter/s, 0.616619s/100 iters), loss = 3.50254
I0923 20:42:16.697160 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.07
I0923 20:42:16.697160 14316 solver.cpp:237]     Train net output #1: loss = 3.50254 (* 1 = 3.50254 loss)
I0923 20:42:16.697160 14316 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0923 20:42:19.457773 14316 solver.cpp:218] Iteration 100 (36.2301 iter/s, 2.76013s/100 iters), loss = 1.67459
I0923 20:42:19.457773 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I0923 20:42:19.457773 14316 solver.cpp:237]     Train net output #1: loss = 1.67459 (* 1 = 1.67459 loss)
I0923 20:42:19.457773 14316 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0923 20:42:22.201863 14316 solver.cpp:218] Iteration 200 (36.4553 iter/s, 2.74309s/100 iters), loss = 1.74324
I0923 20:42:22.201863 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I0923 20:42:22.201863 14316 solver.cpp:237]     Train net output #1: loss = 1.74324 (* 1 = 1.74324 loss)
I0923 20:42:22.201863 14316 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0923 20:42:24.937151 14316 solver.cpp:218] Iteration 300 (36.5521 iter/s, 2.73582s/100 iters), loss = 1.48723
I0923 20:42:24.937151 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I0923 20:42:24.937151 14316 solver.cpp:237]     Train net output #1: loss = 1.48723 (* 1 = 1.48723 loss)
I0923 20:42:24.937151 14316 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0923 20:42:27.673631 14316 solver.cpp:218] Iteration 400 (36.5468 iter/s, 2.73622s/100 iters), loss = 1.33007
I0923 20:42:27.673631 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I0923 20:42:27.674633 14316 solver.cpp:237]     Train net output #1: loss = 1.33007 (* 1 = 1.33007 loss)
I0923 20:42:27.674633 14316 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0923 20:42:30.290485 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:42:30.423617 14316 solver.cpp:218] Iteration 500 (36.3706 iter/s, 2.74948s/100 iters), loss = 1.44161
I0923 20:42:30.423617 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I0923 20:42:30.423617 14316 solver.cpp:237]     Train net output #1: loss = 1.44161 (* 1 = 1.44161 loss)
I0923 20:42:30.423617 14316 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0923 20:42:33.184921 14316 solver.cpp:218] Iteration 600 (36.2183 iter/s, 2.76104s/100 iters), loss = 1.24336
I0923 20:42:33.184921 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I0923 20:42:33.184921 14316 solver.cpp:237]     Train net output #1: loss = 1.24336 (* 1 = 1.24336 loss)
I0923 20:42:33.184921 14316 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0923 20:42:35.926388 14316 solver.cpp:218] Iteration 700 (36.4795 iter/s, 2.74126s/100 iters), loss = 1.35151
I0923 20:42:35.926388 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I0923 20:42:35.926388 14316 solver.cpp:237]     Train net output #1: loss = 1.35151 (* 1 = 1.35151 loss)
I0923 20:42:35.926388 14316 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0923 20:42:38.668984 14316 solver.cpp:218] Iteration 800 (36.4726 iter/s, 2.74178s/100 iters), loss = 1.19748
I0923 20:42:38.668984 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I0923 20:42:38.668984 14316 solver.cpp:237]     Train net output #1: loss = 1.19748 (* 1 = 1.19748 loss)
I0923 20:42:38.668984 14316 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0923 20:42:41.432924 14316 solver.cpp:218] Iteration 900 (36.1863 iter/s, 2.76347s/100 iters), loss = 1.08958
I0923 20:42:41.432924 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I0923 20:42:41.432924 14316 solver.cpp:237]     Train net output #1: loss = 1.08958 (* 1 = 1.08958 loss)
I0923 20:42:41.432924 14316 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0923 20:42:44.089231 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:42:44.201050 14316 solver.cpp:330] Iteration 1000, Testing net (#0)
I0923 20:42:44.201050 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:42:44.735030 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:42:44.757063 14316 solver.cpp:397]     Test net output #0: accuracy = 0.5775
I0923 20:42:44.757063 14316 solver.cpp:397]     Test net output #1: loss = 1.1684 (* 1 = 1.1684 loss)
I0923 20:42:44.783643 14316 solver.cpp:218] Iteration 1000 (29.8484 iter/s, 3.35027s/100 iters), loss = 1.22416
I0923 20:42:44.783643 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I0923 20:42:44.783643 14316 solver.cpp:237]     Train net output #1: loss = 1.22416 (* 1 = 1.22416 loss)
I0923 20:42:44.783643 14316 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0923 20:42:47.607422 14316 solver.cpp:218] Iteration 1100 (35.4188 iter/s, 2.82336s/100 iters), loss = 0.989075
I0923 20:42:47.607422 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0923 20:42:47.607422 14316 solver.cpp:237]     Train net output #1: loss = 0.989075 (* 1 = 0.989075 loss)
I0923 20:42:47.607422 14316 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0923 20:42:50.419454 14316 solver.cpp:218] Iteration 1200 (35.5657 iter/s, 2.8117s/100 iters), loss = 1.13799
I0923 20:42:50.419454 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I0923 20:42:50.419454 14316 solver.cpp:237]     Train net output #1: loss = 1.13799 (* 1 = 1.13799 loss)
I0923 20:42:50.419454 14316 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0923 20:42:53.161411 14316 solver.cpp:218] Iteration 1300 (36.4733 iter/s, 2.74173s/100 iters), loss = 1.0837
I0923 20:42:53.161411 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0923 20:42:53.161411 14316 solver.cpp:237]     Train net output #1: loss = 1.0837 (* 1 = 1.0837 loss)
I0923 20:42:53.161411 14316 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0923 20:42:55.899516 14316 solver.cpp:218] Iteration 1400 (36.5256 iter/s, 2.7378s/100 iters), loss = 0.898883
I0923 20:42:55.899516 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0923 20:42:55.899516 14316 solver.cpp:237]     Train net output #1: loss = 0.898883 (* 1 = 0.898883 loss)
I0923 20:42:55.899516 14316 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0923 20:42:58.504333 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:42:58.637995 14316 solver.cpp:218] Iteration 1500 (36.5166 iter/s, 2.73848s/100 iters), loss = 0.947025
I0923 20:42:58.637995 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0923 20:42:58.637995 14316 solver.cpp:237]     Train net output #1: loss = 0.947025 (* 1 = 0.947025 loss)
I0923 20:42:58.637995 14316 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0923 20:43:01.376930 14316 solver.cpp:218] Iteration 1600 (36.5199 iter/s, 2.73823s/100 iters), loss = 0.862148
I0923 20:43:01.376930 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0923 20:43:01.376930 14316 solver.cpp:237]     Train net output #1: loss = 0.862148 (* 1 = 0.862148 loss)
I0923 20:43:01.376930 14316 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0923 20:43:04.112131 14316 solver.cpp:218] Iteration 1700 (36.558 iter/s, 2.73538s/100 iters), loss = 0.964251
I0923 20:43:04.112131 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0923 20:43:04.112131 14316 solver.cpp:237]     Train net output #1: loss = 0.964251 (* 1 = 0.964251 loss)
I0923 20:43:04.112131 14316 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0923 20:43:06.846681 14316 solver.cpp:218] Iteration 1800 (36.5724 iter/s, 2.7343s/100 iters), loss = 1.00158
I0923 20:43:06.846681 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I0923 20:43:06.846681 14316 solver.cpp:237]     Train net output #1: loss = 1.00158 (* 1 = 1.00158 loss)
I0923 20:43:06.846681 14316 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0923 20:43:09.579691 14316 solver.cpp:218] Iteration 1900 (36.5957 iter/s, 2.73256s/100 iters), loss = 0.840618
I0923 20:43:09.580202 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0923 20:43:09.580202 14316 solver.cpp:237]     Train net output #1: loss = 0.840618 (* 1 = 0.840618 loss)
I0923 20:43:09.580202 14316 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0923 20:43:12.188266 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:43:12.295747 14316 solver.cpp:330] Iteration 2000, Testing net (#0)
I0923 20:43:12.295747 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:43:12.815902 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:43:12.835916 14316 solver.cpp:397]     Test net output #0: accuracy = 0.6727
I0923 20:43:12.835916 14316 solver.cpp:397]     Test net output #1: loss = 0.914249 (* 1 = 0.914249 loss)
I0923 20:43:12.860946 14316 solver.cpp:218] Iteration 2000 (30.475 iter/s, 3.28137s/100 iters), loss = 0.905793
I0923 20:43:12.860946 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0923 20:43:12.861946 14316 solver.cpp:237]     Train net output #1: loss = 0.905793 (* 1 = 0.905793 loss)
I0923 20:43:12.861946 14316 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0923 20:43:15.595779 14316 solver.cpp:218] Iteration 2100 (36.5795 iter/s, 2.73377s/100 iters), loss = 0.796952
I0923 20:43:15.595779 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0923 20:43:15.595779 14316 solver.cpp:237]     Train net output #1: loss = 0.796952 (* 1 = 0.796952 loss)
I0923 20:43:15.595779 14316 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0923 20:43:18.334476 14316 solver.cpp:218] Iteration 2200 (36.5104 iter/s, 2.73895s/100 iters), loss = 0.80645
I0923 20:43:18.334476 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:43:18.334476 14316 solver.cpp:237]     Train net output #1: loss = 0.80645 (* 1 = 0.80645 loss)
I0923 20:43:18.334476 14316 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0923 20:43:21.062908 14316 solver.cpp:218] Iteration 2300 (36.6642 iter/s, 2.72746s/100 iters), loss = 0.910408
I0923 20:43:21.062908 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0923 20:43:21.062908 14316 solver.cpp:237]     Train net output #1: loss = 0.910408 (* 1 = 0.910408 loss)
I0923 20:43:21.062908 14316 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0923 20:43:23.793157 14316 solver.cpp:218] Iteration 2400 (36.6249 iter/s, 2.73038s/100 iters), loss = 0.668685
I0923 20:43:23.793157 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:43:23.793157 14316 solver.cpp:237]     Train net output #1: loss = 0.668685 (* 1 = 0.668685 loss)
I0923 20:43:23.793157 14316 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0923 20:43:26.385277 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:43:26.519922 14316 solver.cpp:218] Iteration 2500 (36.6794 iter/s, 2.72632s/100 iters), loss = 0.83953
I0923 20:43:26.520423 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0923 20:43:26.520423 14316 solver.cpp:237]     Train net output #1: loss = 0.83953 (* 1 = 0.83953 loss)
I0923 20:43:26.520423 14316 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0923 20:43:29.255431 14316 solver.cpp:218] Iteration 2600 (36.5663 iter/s, 2.73476s/100 iters), loss = 0.751234
I0923 20:43:29.255431 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 20:43:29.255431 14316 solver.cpp:237]     Train net output #1: loss = 0.751234 (* 1 = 0.751234 loss)
I0923 20:43:29.255431 14316 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0923 20:43:31.989773 14316 solver.cpp:218] Iteration 2700 (36.5697 iter/s, 2.73451s/100 iters), loss = 0.809921
I0923 20:43:31.989773 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0923 20:43:31.989773 14316 solver.cpp:237]     Train net output #1: loss = 0.809921 (* 1 = 0.809921 loss)
I0923 20:43:31.989773 14316 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0923 20:43:34.725908 14316 solver.cpp:218] Iteration 2800 (36.5555 iter/s, 2.73557s/100 iters), loss = 0.796223
I0923 20:43:34.725908 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0923 20:43:34.725908 14316 solver.cpp:237]     Train net output #1: loss = 0.796223 (* 1 = 0.796223 loss)
I0923 20:43:34.725908 14316 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0923 20:43:37.459626 14316 solver.cpp:218] Iteration 2900 (36.5855 iter/s, 2.73333s/100 iters), loss = 0.574351
I0923 20:43:37.459626 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:43:37.459626 14316 solver.cpp:237]     Train net output #1: loss = 0.574351 (* 1 = 0.574351 loss)
I0923 20:43:37.459626 14316 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0923 20:43:40.063812 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:43:40.171949 14316 solver.cpp:330] Iteration 3000, Testing net (#0)
I0923 20:43:40.171949 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:43:40.691864 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:43:40.711894 14316 solver.cpp:397]     Test net output #0: accuracy = 0.694
I0923 20:43:40.711894 14316 solver.cpp:397]     Test net output #1: loss = 0.894696 (* 1 = 0.894696 loss)
I0923 20:43:40.737926 14316 solver.cpp:218] Iteration 3000 (30.5067 iter/s, 3.27797s/100 iters), loss = 0.757267
I0923 20:43:40.737926 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0923 20:43:40.737926 14316 solver.cpp:237]     Train net output #1: loss = 0.757267 (* 1 = 0.757267 loss)
I0923 20:43:40.737926 14316 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0923 20:43:43.478902 14316 solver.cpp:218] Iteration 3100 (36.4884 iter/s, 2.7406s/100 iters), loss = 0.684058
I0923 20:43:43.478902 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:43:43.478902 14316 solver.cpp:237]     Train net output #1: loss = 0.684058 (* 1 = 0.684058 loss)
I0923 20:43:43.478902 14316 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0923 20:43:46.205793 14316 solver.cpp:218] Iteration 3200 (36.6682 iter/s, 2.72716s/100 iters), loss = 0.720843
I0923 20:43:46.205793 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:43:46.205793 14316 solver.cpp:237]     Train net output #1: loss = 0.720843 (* 1 = 0.720843 loss)
I0923 20:43:46.205793 14316 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0923 20:43:48.940515 14316 solver.cpp:218] Iteration 3300 (36.5786 iter/s, 2.73384s/100 iters), loss = 0.730775
I0923 20:43:48.940515 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 20:43:48.940515 14316 solver.cpp:237]     Train net output #1: loss = 0.730775 (* 1 = 0.730775 loss)
I0923 20:43:48.940515 14316 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0923 20:43:51.673388 14316 solver.cpp:218] Iteration 3400 (36.5898 iter/s, 2.733s/100 iters), loss = 0.627411
I0923 20:43:51.673388 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0923 20:43:51.673388 14316 solver.cpp:237]     Train net output #1: loss = 0.627411 (* 1 = 0.627411 loss)
I0923 20:43:51.673388 14316 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0923 20:43:54.261533 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:43:54.394786 14316 solver.cpp:218] Iteration 3500 (36.7509 iter/s, 2.72102s/100 iters), loss = 0.642315
I0923 20:43:54.394786 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:43:54.394786 14316 solver.cpp:237]     Train net output #1: loss = 0.642315 (* 1 = 0.642315 loss)
I0923 20:43:54.394786 14316 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0923 20:43:57.125761 14316 solver.cpp:218] Iteration 3600 (36.6261 iter/s, 2.7303s/100 iters), loss = 0.653299
I0923 20:43:57.125761 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:43:57.125761 14316 solver.cpp:237]     Train net output #1: loss = 0.653299 (* 1 = 0.653299 loss)
I0923 20:43:57.125761 14316 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0923 20:43:59.860458 14316 solver.cpp:218] Iteration 3700 (36.5752 iter/s, 2.73409s/100 iters), loss = 0.661023
I0923 20:43:59.860458 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:43:59.860458 14316 solver.cpp:237]     Train net output #1: loss = 0.661023 (* 1 = 0.661023 loss)
I0923 20:43:59.860458 14316 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0923 20:44:02.593736 14316 solver.cpp:218] Iteration 3800 (36.5816 iter/s, 2.73361s/100 iters), loss = 0.69729
I0923 20:44:02.593736 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0923 20:44:02.593736 14316 solver.cpp:237]     Train net output #1: loss = 0.69729 (* 1 = 0.69729 loss)
I0923 20:44:02.593736 14316 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0923 20:44:05.326140 14316 solver.cpp:218] Iteration 3900 (36.6052 iter/s, 2.73185s/100 iters), loss = 0.614359
I0923 20:44:05.326140 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:44:05.326140 14316 solver.cpp:237]     Train net output #1: loss = 0.614359 (* 1 = 0.614359 loss)
I0923 20:44:05.326140 14316 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0923 20:44:07.927155 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:44:08.033982 14316 solver.cpp:330] Iteration 4000, Testing net (#0)
I0923 20:44:08.033982 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:44:08.555833 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:44:08.575165 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7169
I0923 20:44:08.575165 14316 solver.cpp:397]     Test net output #1: loss = 0.828053 (* 1 = 0.828053 loss)
I0923 20:44:08.600181 14316 solver.cpp:218] Iteration 4000 (30.5449 iter/s, 3.27387s/100 iters), loss = 0.680046
I0923 20:44:08.600181 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 20:44:08.600181 14316 solver.cpp:237]     Train net output #1: loss = 0.680046 (* 1 = 0.680046 loss)
I0923 20:44:08.600181 14316 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0923 20:44:11.325657 14316 solver.cpp:218] Iteration 4100 (36.6974 iter/s, 2.72499s/100 iters), loss = 0.647667
I0923 20:44:11.325657 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:44:11.325657 14316 solver.cpp:237]     Train net output #1: loss = 0.647667 (* 1 = 0.647667 loss)
I0923 20:44:11.325657 14316 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0923 20:44:14.055588 14316 solver.cpp:218] Iteration 4200 (36.6344 iter/s, 2.72967s/100 iters), loss = 0.604016
I0923 20:44:14.056087 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:44:14.056087 14316 solver.cpp:237]     Train net output #1: loss = 0.604016 (* 1 = 0.604016 loss)
I0923 20:44:14.056087 14316 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0923 20:44:16.780699 14316 solver.cpp:218] Iteration 4300 (36.7022 iter/s, 2.72463s/100 iters), loss = 0.679521
I0923 20:44:16.780699 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:44:16.780699 14316 solver.cpp:237]     Train net output #1: loss = 0.679521 (* 1 = 0.679521 loss)
I0923 20:44:16.780699 14316 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0923 20:44:19.514407 14316 solver.cpp:218] Iteration 4400 (36.583 iter/s, 2.73351s/100 iters), loss = 0.522051
I0923 20:44:19.514407 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:44:19.514407 14316 solver.cpp:237]     Train net output #1: loss = 0.522051 (* 1 = 0.522051 loss)
I0923 20:44:19.514407 14316 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0923 20:44:22.110354 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:44:22.243659 14316 solver.cpp:218] Iteration 4500 (36.6375 iter/s, 2.72945s/100 iters), loss = 0.677655
I0923 20:44:22.243659 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:44:22.244659 14316 solver.cpp:237]     Train net output #1: loss = 0.677655 (* 1 = 0.677655 loss)
I0923 20:44:22.244659 14316 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0923 20:44:24.975090 14316 solver.cpp:218] Iteration 4600 (36.6262 iter/s, 2.73028s/100 iters), loss = 0.570919
I0923 20:44:24.975090 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:44:24.975090 14316 solver.cpp:237]     Train net output #1: loss = 0.570919 (* 1 = 0.570919 loss)
I0923 20:44:24.975090 14316 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0923 20:44:27.700160 14316 solver.cpp:218] Iteration 4700 (36.6931 iter/s, 2.72531s/100 iters), loss = 0.62504
I0923 20:44:27.700160 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:44:27.700160 14316 solver.cpp:237]     Train net output #1: loss = 0.62504 (* 1 = 0.62504 loss)
I0923 20:44:27.700160 14316 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0923 20:44:30.429998 14316 solver.cpp:218] Iteration 4800 (36.6437 iter/s, 2.72898s/100 iters), loss = 0.628112
I0923 20:44:30.429998 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:44:30.429998 14316 solver.cpp:237]     Train net output #1: loss = 0.628112 (* 1 = 0.628112 loss)
I0923 20:44:30.429998 14316 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0923 20:44:33.160580 14316 solver.cpp:218] Iteration 4900 (36.6166 iter/s, 2.731s/100 iters), loss = 0.516425
I0923 20:44:33.160580 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:44:33.160580 14316 solver.cpp:237]     Train net output #1: loss = 0.516425 (* 1 = 0.516425 loss)
I0923 20:44:33.160580 14316 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0923 20:44:35.759781 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:44:35.868595 14316 solver.cpp:330] Iteration 5000, Testing net (#0)
I0923 20:44:35.868595 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:44:36.386510 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:44:36.406525 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7509
I0923 20:44:36.406525 14316 solver.cpp:397]     Test net output #1: loss = 0.732303 (* 1 = 0.732303 loss)
I0923 20:44:36.432545 14316 solver.cpp:218] Iteration 5000 (30.5712 iter/s, 3.27105s/100 iters), loss = 0.617515
I0923 20:44:36.432545 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0923 20:44:36.432545 14316 solver.cpp:237]     Train net output #1: loss = 0.617515 (* 1 = 0.617515 loss)
I0923 20:44:36.432545 14316 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I0923 20:44:36.432545 14316 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I0923 20:44:39.160554 14316 solver.cpp:218] Iteration 5100 (36.6576 iter/s, 2.72795s/100 iters), loss = 0.456636
I0923 20:44:39.160554 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:44:39.160554 14316 solver.cpp:237]     Train net output #1: loss = 0.456636 (* 1 = 0.456636 loss)
I0923 20:44:39.160554 14316 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I0923 20:44:41.892997 14316 solver.cpp:218] Iteration 5200 (36.6057 iter/s, 2.73181s/100 iters), loss = 0.569581
I0923 20:44:41.892997 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:44:41.892997 14316 solver.cpp:237]     Train net output #1: loss = 0.569581 (* 1 = 0.569581 loss)
I0923 20:44:41.892997 14316 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I0923 20:44:44.623260 14316 solver.cpp:218] Iteration 5300 (36.628 iter/s, 2.73015s/100 iters), loss = 0.525302
I0923 20:44:44.623260 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:44:44.623260 14316 solver.cpp:237]     Train net output #1: loss = 0.525302 (* 1 = 0.525302 loss)
I0923 20:44:44.623260 14316 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I0923 20:44:47.361404 14316 solver.cpp:218] Iteration 5400 (36.5253 iter/s, 2.73783s/100 iters), loss = 0.474333
I0923 20:44:47.361404 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:44:47.361404 14316 solver.cpp:237]     Train net output #1: loss = 0.474333 (* 1 = 0.474333 loss)
I0923 20:44:47.361404 14316 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I0923 20:44:49.961570 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:44:50.094714 14316 solver.cpp:218] Iteration 5500 (36.5824 iter/s, 2.73356s/100 iters), loss = 0.531778
I0923 20:44:50.095715 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:44:50.095715 14316 solver.cpp:237]     Train net output #1: loss = 0.531778 (* 1 = 0.531778 loss)
I0923 20:44:50.095715 14316 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I0923 20:44:52.831940 14316 solver.cpp:218] Iteration 5600 (36.5482 iter/s, 2.73611s/100 iters), loss = 0.461147
I0923 20:44:52.831940 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:44:52.831940 14316 solver.cpp:237]     Train net output #1: loss = 0.461147 (* 1 = 0.461147 loss)
I0923 20:44:52.831940 14316 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I0923 20:44:55.563035 14316 solver.cpp:218] Iteration 5700 (36.6199 iter/s, 2.73075s/100 iters), loss = 0.536854
I0923 20:44:55.563035 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:44:55.563035 14316 solver.cpp:237]     Train net output #1: loss = 0.536854 (* 1 = 0.536854 loss)
I0923 20:44:55.563035 14316 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I0923 20:44:58.296504 14316 solver.cpp:218] Iteration 5800 (36.5837 iter/s, 2.73345s/100 iters), loss = 0.521889
I0923 20:44:58.296504 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:44:58.296504 14316 solver.cpp:237]     Train net output #1: loss = 0.521889 (* 1 = 0.521889 loss)
I0923 20:44:58.296504 14316 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I0923 20:45:01.028923 14316 solver.cpp:218] Iteration 5900 (36.6003 iter/s, 2.73222s/100 iters), loss = 0.406596
I0923 20:45:01.028923 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:45:01.028923 14316 solver.cpp:237]     Train net output #1: loss = 0.406596 (* 1 = 0.406596 loss)
I0923 20:45:01.028923 14316 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I0923 20:45:03.630007 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:45:03.739104 14316 solver.cpp:330] Iteration 6000, Testing net (#0)
I0923 20:45:03.739104 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:45:04.259594 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:45:04.279628 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7786
I0923 20:45:04.279628 14316 solver.cpp:397]     Test net output #1: loss = 0.632069 (* 1 = 0.632069 loss)
I0923 20:45:04.305627 14316 solver.cpp:218] Iteration 6000 (30.5251 iter/s, 3.276s/100 iters), loss = 0.505166
I0923 20:45:04.305627 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:45:04.305627 14316 solver.cpp:237]     Train net output #1: loss = 0.505166 (* 1 = 0.505166 loss)
I0923 20:45:04.305627 14316 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I0923 20:45:07.035025 14316 solver.cpp:218] Iteration 6100 (36.6402 iter/s, 2.72924s/100 iters), loss = 0.479173
I0923 20:45:07.035025 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:45:07.035025 14316 solver.cpp:237]     Train net output #1: loss = 0.479173 (* 1 = 0.479173 loss)
I0923 20:45:07.035025 14316 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I0923 20:45:09.762709 14316 solver.cpp:218] Iteration 6200 (36.6679 iter/s, 2.72718s/100 iters), loss = 0.447465
I0923 20:45:09.762709 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:45:09.762709 14316 solver.cpp:237]     Train net output #1: loss = 0.447465 (* 1 = 0.447465 loss)
I0923 20:45:09.762709 14316 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I0923 20:45:12.492828 14316 solver.cpp:218] Iteration 6300 (36.6255 iter/s, 2.73034s/100 iters), loss = 0.495598
I0923 20:45:12.492828 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:45:12.492828 14316 solver.cpp:237]     Train net output #1: loss = 0.495598 (* 1 = 0.495598 loss)
I0923 20:45:12.492828 14316 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I0923 20:45:15.228878 14316 solver.cpp:218] Iteration 6400 (36.5534 iter/s, 2.73572s/100 iters), loss = 0.407308
I0923 20:45:15.228878 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:45:15.228878 14316 solver.cpp:237]     Train net output #1: loss = 0.407308 (* 1 = 0.407308 loss)
I0923 20:45:15.228878 14316 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I0923 20:45:17.830790 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:45:17.963888 14316 solver.cpp:218] Iteration 6500 (36.578 iter/s, 2.73388s/100 iters), loss = 0.534697
I0923 20:45:17.963888 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:45:17.963888 14316 solver.cpp:237]     Train net output #1: loss = 0.534697 (* 1 = 0.534697 loss)
I0923 20:45:17.963888 14316 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I0923 20:45:20.705395 14316 solver.cpp:218] Iteration 6600 (36.4753 iter/s, 2.74158s/100 iters), loss = 0.502744
I0923 20:45:20.705395 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:45:20.705395 14316 solver.cpp:237]     Train net output #1: loss = 0.502744 (* 1 = 0.502744 loss)
I0923 20:45:20.705395 14316 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I0923 20:45:23.441211 14316 solver.cpp:218] Iteration 6700 (36.5602 iter/s, 2.73522s/100 iters), loss = 0.469073
I0923 20:45:23.441211 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:45:23.441211 14316 solver.cpp:237]     Train net output #1: loss = 0.469073 (* 1 = 0.469073 loss)
I0923 20:45:23.441211 14316 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I0923 20:45:26.171824 14316 solver.cpp:218] Iteration 6800 (36.6259 iter/s, 2.73031s/100 iters), loss = 0.502212
I0923 20:45:26.171824 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:45:26.171824 14316 solver.cpp:237]     Train net output #1: loss = 0.502212 (* 1 = 0.502212 loss)
I0923 20:45:26.171824 14316 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I0923 20:45:28.904770 14316 solver.cpp:218] Iteration 6900 (36.5934 iter/s, 2.73273s/100 iters), loss = 0.412177
I0923 20:45:28.904770 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:45:28.904770 14316 solver.cpp:237]     Train net output #1: loss = 0.412177 (* 1 = 0.412177 loss)
I0923 20:45:28.904770 14316 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I0923 20:45:31.497211 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:45:31.605324 14316 solver.cpp:330] Iteration 7000, Testing net (#0)
I0923 20:45:31.605324 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:45:32.124702 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:45:32.145220 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7801
I0923 20:45:32.145220 14316 solver.cpp:397]     Test net output #1: loss = 0.630877 (* 1 = 0.630877 loss)
I0923 20:45:32.170346 14316 solver.cpp:218] Iteration 7000 (30.6242 iter/s, 3.26539s/100 iters), loss = 0.498022
I0923 20:45:32.170346 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:45:32.170346 14316 solver.cpp:237]     Train net output #1: loss = 0.498022 (* 1 = 0.498022 loss)
I0923 20:45:32.170346 14316 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I0923 20:45:34.904839 14316 solver.cpp:218] Iteration 7100 (36.5746 iter/s, 2.73414s/100 iters), loss = 0.515615
I0923 20:45:34.904839 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:45:34.904839 14316 solver.cpp:237]     Train net output #1: loss = 0.515615 (* 1 = 0.515615 loss)
I0923 20:45:34.904839 14316 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I0923 20:45:37.640681 14316 solver.cpp:218] Iteration 7200 (36.5599 iter/s, 2.73523s/100 iters), loss = 0.43937
I0923 20:45:37.640681 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:45:37.640681 14316 solver.cpp:237]     Train net output #1: loss = 0.43937 (* 1 = 0.43937 loss)
I0923 20:45:37.640681 14316 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I0923 20:45:40.373442 14316 solver.cpp:218] Iteration 7300 (36.5905 iter/s, 2.73295s/100 iters), loss = 0.532451
I0923 20:45:40.373442 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:45:40.373442 14316 solver.cpp:237]     Train net output #1: loss = 0.532451 (* 1 = 0.532451 loss)
I0923 20:45:40.373442 14316 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I0923 20:45:43.114644 14316 solver.cpp:218] Iteration 7400 (36.4922 iter/s, 2.74031s/100 iters), loss = 0.356945
I0923 20:45:43.114644 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:45:43.114644 14316 solver.cpp:237]     Train net output #1: loss = 0.356945 (* 1 = 0.356945 loss)
I0923 20:45:43.114644 14316 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I0923 20:45:45.711808 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:45:45.846076 14316 solver.cpp:218] Iteration 7500 (36.6135 iter/s, 2.73123s/100 iters), loss = 0.460993
I0923 20:45:45.846076 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:45:45.846076 14316 solver.cpp:237]     Train net output #1: loss = 0.460993 (* 1 = 0.460993 loss)
I0923 20:45:45.846076 14316 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I0923 20:45:48.578833 14316 solver.cpp:218] Iteration 7600 (36.589 iter/s, 2.73306s/100 iters), loss = 0.443154
I0923 20:45:48.578833 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:45:48.578833 14316 solver.cpp:237]     Train net output #1: loss = 0.443154 (* 1 = 0.443154 loss)
I0923 20:45:48.578833 14316 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I0923 20:45:51.311931 14316 solver.cpp:218] Iteration 7700 (36.5923 iter/s, 2.73281s/100 iters), loss = 0.455479
I0923 20:45:51.311931 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:45:51.311931 14316 solver.cpp:237]     Train net output #1: loss = 0.455479 (* 1 = 0.455479 loss)
I0923 20:45:51.311931 14316 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I0923 20:45:54.055212 14316 solver.cpp:218] Iteration 7800 (36.4645 iter/s, 2.74239s/100 iters), loss = 0.503152
I0923 20:45:54.055212 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:45:54.055212 14316 solver.cpp:237]     Train net output #1: loss = 0.503152 (* 1 = 0.503152 loss)
I0923 20:45:54.055212 14316 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I0923 20:45:56.843160 14316 solver.cpp:218] Iteration 7900 (35.8762 iter/s, 2.78736s/100 iters), loss = 0.38253
I0923 20:45:56.843160 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:45:56.843160 14316 solver.cpp:237]     Train net output #1: loss = 0.38253 (* 1 = 0.38253 loss)
I0923 20:45:56.843160 14316 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I0923 20:45:59.492007 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:45:59.600626 14316 solver.cpp:330] Iteration 8000, Testing net (#0)
I0923 20:45:59.600626 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:46:00.117496 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:46:00.137511 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7832
I0923 20:46:00.137511 14316 solver.cpp:397]     Test net output #1: loss = 0.630309 (* 1 = 0.630309 loss)
I0923 20:46:00.163030 14316 solver.cpp:218] Iteration 8000 (30.1206 iter/s, 3.31999s/100 iters), loss = 0.440542
I0923 20:46:00.163530 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:46:00.163530 14316 solver.cpp:237]     Train net output #1: loss = 0.440542 (* 1 = 0.440542 loss)
I0923 20:46:00.163530 14316 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I0923 20:46:02.917618 14316 solver.cpp:218] Iteration 8100 (36.3078 iter/s, 2.75423s/100 iters), loss = 0.44648
I0923 20:46:02.917618 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:46:02.917618 14316 solver.cpp:237]     Train net output #1: loss = 0.44648 (* 1 = 0.44648 loss)
I0923 20:46:02.917618 14316 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I0923 20:46:05.667243 14316 solver.cpp:218] Iteration 8200 (36.3771 iter/s, 2.74898s/100 iters), loss = 0.474218
I0923 20:46:05.667243 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:46:05.667243 14316 solver.cpp:237]     Train net output #1: loss = 0.474218 (* 1 = 0.474218 loss)
I0923 20:46:05.667243 14316 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I0923 20:46:08.433452 14316 solver.cpp:218] Iteration 8300 (36.153 iter/s, 2.76602s/100 iters), loss = 0.508805
I0923 20:46:08.433452 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:46:08.433452 14316 solver.cpp:237]     Train net output #1: loss = 0.508805 (* 1 = 0.508805 loss)
I0923 20:46:08.433452 14316 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I0923 20:46:11.195499 14316 solver.cpp:218] Iteration 8400 (36.2088 iter/s, 2.76176s/100 iters), loss = 0.387839
I0923 20:46:11.195499 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:46:11.195499 14316 solver.cpp:237]     Train net output #1: loss = 0.387839 (* 1 = 0.387839 loss)
I0923 20:46:11.195499 14316 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I0923 20:46:13.812705 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:46:13.945308 14316 solver.cpp:218] Iteration 8500 (36.3632 iter/s, 2.75004s/100 iters), loss = 0.462817
I0923 20:46:13.945308 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:46:13.945308 14316 solver.cpp:237]     Train net output #1: loss = 0.462817 (* 1 = 0.462817 loss)
I0923 20:46:13.945308 14316 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I0923 20:46:16.697598 14316 solver.cpp:218] Iteration 8600 (36.343 iter/s, 2.75156s/100 iters), loss = 0.431549
I0923 20:46:16.697598 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:46:16.697598 14316 solver.cpp:237]     Train net output #1: loss = 0.431549 (* 1 = 0.431549 loss)
I0923 20:46:16.697598 14316 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I0923 20:46:19.450117 14316 solver.cpp:218] Iteration 8700 (36.3278 iter/s, 2.75271s/100 iters), loss = 0.398083
I0923 20:46:19.451118 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:46:19.451118 14316 solver.cpp:237]     Train net output #1: loss = 0.398083 (* 1 = 0.398083 loss)
I0923 20:46:19.451118 14316 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I0923 20:46:22.212894 14316 solver.cpp:218] Iteration 8800 (36.2006 iter/s, 2.76239s/100 iters), loss = 0.520834
I0923 20:46:22.213896 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:46:22.213896 14316 solver.cpp:237]     Train net output #1: loss = 0.520834 (* 1 = 0.520834 loss)
I0923 20:46:22.213896 14316 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I0923 20:46:25.035722 14316 solver.cpp:218] Iteration 8900 (35.4321 iter/s, 2.8223s/100 iters), loss = 0.365552
I0923 20:46:25.035722 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:46:25.035722 14316 solver.cpp:237]     Train net output #1: loss = 0.365552 (* 1 = 0.365552 loss)
I0923 20:46:25.035722 14316 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I0923 20:46:27.640219 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:46:27.749922 14316 solver.cpp:330] Iteration 9000, Testing net (#0)
I0923 20:46:27.749922 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:46:28.269461 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:46:28.289960 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7846
I0923 20:46:28.289960 14316 solver.cpp:397]     Test net output #1: loss = 0.625632 (* 1 = 0.625632 loss)
I0923 20:46:28.315479 14316 solver.cpp:218] Iteration 9000 (30.5004 iter/s, 3.27865s/100 iters), loss = 0.45412
I0923 20:46:28.315479 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:46:28.315479 14316 solver.cpp:237]     Train net output #1: loss = 0.45412 (* 1 = 0.45412 loss)
I0923 20:46:28.315479 14316 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I0923 20:46:31.071146 14316 solver.cpp:218] Iteration 9100 (36.2839 iter/s, 2.75604s/100 iters), loss = 0.479294
I0923 20:46:31.071146 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:46:31.071146 14316 solver.cpp:237]     Train net output #1: loss = 0.479294 (* 1 = 0.479294 loss)
I0923 20:46:31.071146 14316 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I0923 20:46:33.832787 14316 solver.cpp:218] Iteration 9200 (36.2207 iter/s, 2.76085s/100 iters), loss = 0.425968
I0923 20:46:33.832787 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:46:33.832787 14316 solver.cpp:237]     Train net output #1: loss = 0.425968 (* 1 = 0.425968 loss)
I0923 20:46:33.832787 14316 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I0923 20:46:36.607502 14316 solver.cpp:218] Iteration 9300 (36.0468 iter/s, 2.77417s/100 iters), loss = 0.504691
I0923 20:46:36.607502 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:46:36.607502 14316 solver.cpp:237]     Train net output #1: loss = 0.504691 (* 1 = 0.504691 loss)
I0923 20:46:36.607502 14316 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I0923 20:46:39.385457 14316 solver.cpp:218] Iteration 9400 (36.0031 iter/s, 2.77754s/100 iters), loss = 0.357937
I0923 20:46:39.385457 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:46:39.385457 14316 solver.cpp:237]     Train net output #1: loss = 0.357937 (* 1 = 0.357937 loss)
I0923 20:46:39.385457 14316 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I0923 20:46:42.000687 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:46:42.133457 14316 solver.cpp:218] Iteration 9500 (36.3876 iter/s, 2.74819s/100 iters), loss = 0.445559
I0923 20:46:42.133457 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:46:42.133457 14316 solver.cpp:237]     Train net output #1: loss = 0.445559 (* 1 = 0.445559 loss)
I0923 20:46:42.133457 14316 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I0923 20:46:44.872798 14316 solver.cpp:218] Iteration 9600 (36.5147 iter/s, 2.73863s/100 iters), loss = 0.436602
I0923 20:46:44.872798 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:46:44.872798 14316 solver.cpp:237]     Train net output #1: loss = 0.436602 (* 1 = 0.436602 loss)
I0923 20:46:44.872798 14316 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I0923 20:46:47.641816 14316 solver.cpp:218] Iteration 9700 (36.114 iter/s, 2.76901s/100 iters), loss = 0.438054
I0923 20:46:47.641816 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:46:47.641816 14316 solver.cpp:237]     Train net output #1: loss = 0.438054 (* 1 = 0.438054 loss)
I0923 20:46:47.641816 14316 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I0923 20:46:50.381376 14316 solver.cpp:218] Iteration 9800 (36.5003 iter/s, 2.73971s/100 iters), loss = 0.49495
I0923 20:46:50.382377 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:46:50.382377 14316 solver.cpp:237]     Train net output #1: loss = 0.49495 (* 1 = 0.49495 loss)
I0923 20:46:50.382377 14316 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I0923 20:46:53.127326 14316 solver.cpp:218] Iteration 9900 (36.425 iter/s, 2.74537s/100 iters), loss = 0.385958
I0923 20:46:53.127326 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:46:53.127326 14316 solver.cpp:237]     Train net output #1: loss = 0.385958 (* 1 = 0.385958 loss)
I0923 20:46:53.127326 14316 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I0923 20:46:55.760831 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:46:55.869513 14316 solver.cpp:330] Iteration 10000, Testing net (#0)
I0923 20:46:55.869513 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:46:56.391590 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:46:56.412618 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7858
I0923 20:46:56.412618 14316 solver.cpp:397]     Test net output #1: loss = 0.625913 (* 1 = 0.625913 loss)
I0923 20:46:56.438652 14316 solver.cpp:218] Iteration 10000 (30.2096 iter/s, 3.31021s/100 iters), loss = 0.450287
I0923 20:46:56.438652 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:46:56.438652 14316 solver.cpp:237]     Train net output #1: loss = 0.450287 (* 1 = 0.450287 loss)
I0923 20:46:56.438652 14316 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I0923 20:46:56.438652 14316 sgd_solver.cpp:105] Iteration 10000, lr = 0.0001
I0923 20:46:59.185920 14316 solver.cpp:218] Iteration 10100 (36.394 iter/s, 2.7477s/100 iters), loss = 0.435515
I0923 20:46:59.186905 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:46:59.186905 14316 solver.cpp:237]     Train net output #1: loss = 0.435515 (* 1 = 0.435515 loss)
I0923 20:46:59.186905 14316 sgd_solver.cpp:105] Iteration 10100, lr = 0.0001
I0923 20:47:01.921479 14316 solver.cpp:218] Iteration 10200 (36.5704 iter/s, 2.73445s/100 iters), loss = 0.373699
I0923 20:47:01.921479 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:47:01.921479 14316 solver.cpp:237]     Train net output #1: loss = 0.373699 (* 1 = 0.373699 loss)
I0923 20:47:01.921479 14316 sgd_solver.cpp:105] Iteration 10200, lr = 0.0001
I0923 20:47:04.659330 14316 solver.cpp:218] Iteration 10300 (36.5233 iter/s, 2.73798s/100 iters), loss = 0.462023
I0923 20:47:04.659330 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:47:04.659330 14316 solver.cpp:237]     Train net output #1: loss = 0.462023 (* 1 = 0.462023 loss)
I0923 20:47:04.659330 14316 sgd_solver.cpp:105] Iteration 10300, lr = 0.0001
I0923 20:47:07.389302 14316 solver.cpp:218] Iteration 10400 (36.6377 iter/s, 2.72943s/100 iters), loss = 0.353739
I0923 20:47:07.389302 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:47:07.389302 14316 solver.cpp:237]     Train net output #1: loss = 0.353739 (* 1 = 0.353739 loss)
I0923 20:47:07.389302 14316 sgd_solver.cpp:105] Iteration 10400, lr = 0.0001
I0923 20:47:09.990285 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:47:10.124517 14316 solver.cpp:218] Iteration 10500 (36.5686 iter/s, 2.73459s/100 iters), loss = 0.496017
I0923 20:47:10.124517 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:47:10.124517 14316 solver.cpp:237]     Train net output #1: loss = 0.496017 (* 1 = 0.496017 loss)
I0923 20:47:10.124517 14316 sgd_solver.cpp:105] Iteration 10500, lr = 0.0001
I0923 20:47:12.861323 14316 solver.cpp:218] Iteration 10600 (36.5317 iter/s, 2.73735s/100 iters), loss = 0.444776
I0923 20:47:12.861323 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:47:12.861323 14316 solver.cpp:237]     Train net output #1: loss = 0.444776 (* 1 = 0.444776 loss)
I0923 20:47:12.861323 14316 sgd_solver.cpp:105] Iteration 10600, lr = 0.0001
I0923 20:47:15.596640 14316 solver.cpp:218] Iteration 10700 (36.5706 iter/s, 2.73444s/100 iters), loss = 0.352716
I0923 20:47:15.596640 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:47:15.596640 14316 solver.cpp:237]     Train net output #1: loss = 0.352716 (* 1 = 0.352716 loss)
I0923 20:47:15.596640 14316 sgd_solver.cpp:105] Iteration 10700, lr = 0.0001
I0923 20:47:18.322399 14316 solver.cpp:218] Iteration 10800 (36.6843 iter/s, 2.72596s/100 iters), loss = 0.432871
I0923 20:47:18.322399 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:47:18.322399 14316 solver.cpp:237]     Train net output #1: loss = 0.432871 (* 1 = 0.432871 loss)
I0923 20:47:18.322399 14316 sgd_solver.cpp:105] Iteration 10800, lr = 0.0001
I0923 20:47:21.052075 14316 solver.cpp:218] Iteration 10900 (36.6435 iter/s, 2.72899s/100 iters), loss = 0.372931
I0923 20:47:21.052075 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:47:21.052075 14316 solver.cpp:237]     Train net output #1: loss = 0.372931 (* 1 = 0.372931 loss)
I0923 20:47:21.052075 14316 sgd_solver.cpp:105] Iteration 10900, lr = 0.0001
I0923 20:47:23.653414 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:47:23.760030 14316 solver.cpp:330] Iteration 11000, Testing net (#0)
I0923 20:47:23.760030 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:47:24.279498 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:47:24.299512 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7879
I0923 20:47:24.299512 14316 solver.cpp:397]     Test net output #1: loss = 0.618047 (* 1 = 0.618047 loss)
I0923 20:47:24.325546 14316 solver.cpp:218] Iteration 11000 (30.5501 iter/s, 3.27332s/100 iters), loss = 0.441693
I0923 20:47:24.325546 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:47:24.325546 14316 solver.cpp:237]     Train net output #1: loss = 0.441693 (* 1 = 0.441693 loss)
I0923 20:47:24.325546 14316 sgd_solver.cpp:105] Iteration 11000, lr = 0.0001
I0923 20:47:27.058324 14316 solver.cpp:218] Iteration 11100 (36.6021 iter/s, 2.73208s/100 iters), loss = 0.379296
I0923 20:47:27.058324 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:47:27.058324 14316 solver.cpp:237]     Train net output #1: loss = 0.379296 (* 1 = 0.379296 loss)
I0923 20:47:27.058324 14316 sgd_solver.cpp:105] Iteration 11100, lr = 0.0001
I0923 20:47:29.785328 14316 solver.cpp:218] Iteration 11200 (36.6679 iter/s, 2.72718s/100 iters), loss = 0.454103
I0923 20:47:29.785328 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:47:29.785328 14316 solver.cpp:237]     Train net output #1: loss = 0.454103 (* 1 = 0.454103 loss)
I0923 20:47:29.785328 14316 sgd_solver.cpp:105] Iteration 11200, lr = 0.0001
I0923 20:47:32.515820 14316 solver.cpp:218] Iteration 11300 (36.6276 iter/s, 2.73018s/100 iters), loss = 0.491718
I0923 20:47:32.515820 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:47:32.515820 14316 solver.cpp:237]     Train net output #1: loss = 0.491718 (* 1 = 0.491718 loss)
I0923 20:47:32.515820 14316 sgd_solver.cpp:105] Iteration 11300, lr = 0.0001
I0923 20:47:35.248610 14316 solver.cpp:218] Iteration 11400 (36.6075 iter/s, 2.73168s/100 iters), loss = 0.350758
I0923 20:47:35.248610 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:47:35.248610 14316 solver.cpp:237]     Train net output #1: loss = 0.350758 (* 1 = 0.350758 loss)
I0923 20:47:35.248610 14316 sgd_solver.cpp:105] Iteration 11400, lr = 0.0001
I0923 20:47:37.891575 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:47:38.026731 14316 solver.cpp:218] Iteration 11500 (35.9969 iter/s, 2.77802s/100 iters), loss = 0.432805
I0923 20:47:38.026731 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:47:38.026731 14316 solver.cpp:237]     Train net output #1: loss = 0.432805 (* 1 = 0.432805 loss)
I0923 20:47:38.026731 14316 sgd_solver.cpp:105] Iteration 11500, lr = 0.0001
I0923 20:47:40.846505 14316 solver.cpp:218] Iteration 11600 (35.4743 iter/s, 2.81895s/100 iters), loss = 0.414923
I0923 20:47:40.846505 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:47:40.846505 14316 solver.cpp:237]     Train net output #1: loss = 0.414923 (* 1 = 0.414923 loss)
I0923 20:47:40.846505 14316 sgd_solver.cpp:105] Iteration 11600, lr = 0.0001
I0923 20:47:43.650627 14316 solver.cpp:218] Iteration 11700 (35.6593 iter/s, 2.80432s/100 iters), loss = 0.380813
I0923 20:47:43.650627 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:47:43.650627 14316 solver.cpp:237]     Train net output #1: loss = 0.380813 (* 1 = 0.380813 loss)
I0923 20:47:43.650627 14316 sgd_solver.cpp:105] Iteration 11700, lr = 0.0001
I0923 20:47:46.376641 14316 solver.cpp:218] Iteration 11800 (36.6909 iter/s, 2.72547s/100 iters), loss = 0.483537
I0923 20:47:46.376641 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:47:46.376641 14316 solver.cpp:237]     Train net output #1: loss = 0.483537 (* 1 = 0.483537 loss)
I0923 20:47:46.376641 14316 sgd_solver.cpp:105] Iteration 11800, lr = 0.0001
I0923 20:47:49.147368 14316 solver.cpp:218] Iteration 11900 (36.0904 iter/s, 2.77082s/100 iters), loss = 0.389889
I0923 20:47:49.147368 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:47:49.147368 14316 solver.cpp:237]     Train net output #1: loss = 0.389889 (* 1 = 0.389889 loss)
I0923 20:47:49.147368 14316 sgd_solver.cpp:105] Iteration 11900, lr = 0.0001
I0923 20:47:51.776700 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:47:51.888316 14316 solver.cpp:330] Iteration 12000, Testing net (#0)
I0923 20:47:51.888316 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:47:52.416204 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:47:52.437219 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7878
I0923 20:47:52.437219 14316 solver.cpp:397]     Test net output #1: loss = 0.618777 (* 1 = 0.618777 loss)
I0923 20:47:52.463249 14316 solver.cpp:218] Iteration 12000 (30.1682 iter/s, 3.31474s/100 iters), loss = 0.473011
I0923 20:47:52.463249 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:47:52.463249 14316 solver.cpp:237]     Train net output #1: loss = 0.473011 (* 1 = 0.473011 loss)
I0923 20:47:52.463249 14316 sgd_solver.cpp:105] Iteration 12000, lr = 0.0001
I0923 20:47:55.224232 14316 solver.cpp:218] Iteration 12100 (36.2229 iter/s, 2.76069s/100 iters), loss = 0.421295
I0923 20:47:55.224232 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:47:55.224232 14316 solver.cpp:237]     Train net output #1: loss = 0.421295 (* 1 = 0.421295 loss)
I0923 20:47:55.224232 14316 sgd_solver.cpp:105] Iteration 12100, lr = 0.0001
I0923 20:47:57.989670 14316 solver.cpp:218] Iteration 12200 (36.1638 iter/s, 2.76519s/100 iters), loss = 0.443032
I0923 20:47:57.989670 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:47:57.989670 14316 solver.cpp:237]     Train net output #1: loss = 0.443032 (* 1 = 0.443032 loss)
I0923 20:47:57.989670 14316 sgd_solver.cpp:105] Iteration 12200, lr = 0.0001
I0923 20:48:00.719961 14316 solver.cpp:218] Iteration 12300 (36.626 iter/s, 2.7303s/100 iters), loss = 0.450649
I0923 20:48:00.719961 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:48:00.719961 14316 solver.cpp:237]     Train net output #1: loss = 0.450649 (* 1 = 0.450649 loss)
I0923 20:48:00.719961 14316 sgd_solver.cpp:105] Iteration 12300, lr = 0.0001
I0923 20:48:03.446501 14316 solver.cpp:218] Iteration 12400 (36.6782 iter/s, 2.72642s/100 iters), loss = 0.335043
I0923 20:48:03.446501 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:48:03.446501 14316 solver.cpp:237]     Train net output #1: loss = 0.335043 (* 1 = 0.335043 loss)
I0923 20:48:03.446501 14316 sgd_solver.cpp:105] Iteration 12400, lr = 0.0001
I0923 20:48:06.089725 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:48:06.228590 14316 solver.cpp:218] Iteration 12500 (35.9537 iter/s, 2.78136s/100 iters), loss = 0.44331
I0923 20:48:06.228590 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:48:06.228590 14316 solver.cpp:237]     Train net output #1: loss = 0.44331 (* 1 = 0.44331 loss)
I0923 20:48:06.228590 14316 sgd_solver.cpp:105] Iteration 12500, lr = 0.0001
I0923 20:48:08.971259 14316 solver.cpp:218] Iteration 12600 (36.4711 iter/s, 2.7419s/100 iters), loss = 0.392767
I0923 20:48:08.971259 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:48:08.971259 14316 solver.cpp:237]     Train net output #1: loss = 0.392767 (* 1 = 0.392767 loss)
I0923 20:48:08.971259 14316 sgd_solver.cpp:105] Iteration 12600, lr = 0.0001
I0923 20:48:11.715180 14316 solver.cpp:218] Iteration 12700 (36.4442 iter/s, 2.74392s/100 iters), loss = 0.390947
I0923 20:48:11.715180 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:48:11.715180 14316 solver.cpp:237]     Train net output #1: loss = 0.390947 (* 1 = 0.390947 loss)
I0923 20:48:11.715180 14316 sgd_solver.cpp:105] Iteration 12700, lr = 0.0001
I0923 20:48:14.459064 14316 solver.cpp:218] Iteration 12800 (36.4477 iter/s, 2.74366s/100 iters), loss = 0.480064
I0923 20:48:14.459064 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:48:14.459064 14316 solver.cpp:237]     Train net output #1: loss = 0.480064 (* 1 = 0.480064 loss)
I0923 20:48:14.459064 14316 sgd_solver.cpp:105] Iteration 12800, lr = 0.0001
I0923 20:48:17.192668 14316 solver.cpp:218] Iteration 12900 (36.5805 iter/s, 2.7337s/100 iters), loss = 0.354291
I0923 20:48:17.193670 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:48:17.193670 14316 solver.cpp:237]     Train net output #1: loss = 0.354291 (* 1 = 0.354291 loss)
I0923 20:48:17.193670 14316 sgd_solver.cpp:105] Iteration 12900, lr = 0.0001
I0923 20:48:19.800287 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:48:19.907933 14316 solver.cpp:330] Iteration 13000, Testing net (#0)
I0923 20:48:19.908433 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:48:20.424644 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:48:20.444658 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7887
I0923 20:48:20.444658 14316 solver.cpp:397]     Test net output #1: loss = 0.619094 (* 1 = 0.619094 loss)
I0923 20:48:20.470676 14316 solver.cpp:218] Iteration 13000 (30.5181 iter/s, 3.27674s/100 iters), loss = 0.459177
I0923 20:48:20.470676 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:48:20.470676 14316 solver.cpp:237]     Train net output #1: loss = 0.459177 (* 1 = 0.459177 loss)
I0923 20:48:20.470676 14316 sgd_solver.cpp:105] Iteration 13000, lr = 0.0001
I0923 20:48:23.219470 14316 solver.cpp:218] Iteration 13100 (36.379 iter/s, 2.74884s/100 iters), loss = 0.42769
I0923 20:48:23.219470 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:48:23.219470 14316 solver.cpp:237]     Train net output #1: loss = 0.42769 (* 1 = 0.42769 loss)
I0923 20:48:23.219470 14316 sgd_solver.cpp:105] Iteration 13100, lr = 0.0001
I0923 20:48:25.950953 14316 solver.cpp:218] Iteration 13200 (36.6153 iter/s, 2.7311s/100 iters), loss = 0.428263
I0923 20:48:25.950953 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:48:25.950953 14316 solver.cpp:237]     Train net output #1: loss = 0.428263 (* 1 = 0.428263 loss)
I0923 20:48:25.950953 14316 sgd_solver.cpp:105] Iteration 13200, lr = 0.0001
I0923 20:48:28.683692 14316 solver.cpp:218] Iteration 13300 (36.602 iter/s, 2.73209s/100 iters), loss = 0.505362
I0923 20:48:28.683692 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:48:28.683692 14316 solver.cpp:237]     Train net output #1: loss = 0.505362 (* 1 = 0.505362 loss)
I0923 20:48:28.683692 14316 sgd_solver.cpp:105] Iteration 13300, lr = 0.0001
I0923 20:48:31.490110 14316 solver.cpp:218] Iteration 13400 (35.6338 iter/s, 2.80633s/100 iters), loss = 0.359923
I0923 20:48:31.490110 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:48:31.490110 14316 solver.cpp:237]     Train net output #1: loss = 0.359923 (* 1 = 0.359923 loss)
I0923 20:48:31.490110 14316 sgd_solver.cpp:105] Iteration 13400, lr = 0.0001
I0923 20:48:34.207468 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:48:34.347550 14316 solver.cpp:218] Iteration 13500 (35.002 iter/s, 2.85698s/100 iters), loss = 0.420942
I0923 20:48:34.347550 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:48:34.347550 14316 solver.cpp:237]     Train net output #1: loss = 0.420942 (* 1 = 0.420942 loss)
I0923 20:48:34.347550 14316 sgd_solver.cpp:105] Iteration 13500, lr = 0.0001
I0923 20:48:37.189577 14316 solver.cpp:218] Iteration 13600 (35.191 iter/s, 2.84163s/100 iters), loss = 0.38728
I0923 20:48:37.189577 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:48:37.189577 14316 solver.cpp:237]     Train net output #1: loss = 0.38728 (* 1 = 0.38728 loss)
I0923 20:48:37.189577 14316 sgd_solver.cpp:105] Iteration 13600, lr = 0.0001
I0923 20:48:39.990772 14316 solver.cpp:218] Iteration 13700 (35.7022 iter/s, 2.80094s/100 iters), loss = 0.363085
I0923 20:48:39.990772 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0923 20:48:39.990772 14316 solver.cpp:237]     Train net output #1: loss = 0.363085 (* 1 = 0.363085 loss)
I0923 20:48:39.990772 14316 sgd_solver.cpp:105] Iteration 13700, lr = 0.0001
I0923 20:48:42.728078 14316 solver.cpp:218] Iteration 13800 (36.5383 iter/s, 2.73685s/100 iters), loss = 0.448959
I0923 20:48:42.728078 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:48:42.728078 14316 solver.cpp:237]     Train net output #1: loss = 0.448959 (* 1 = 0.448959 loss)
I0923 20:48:42.728078 14316 sgd_solver.cpp:105] Iteration 13800, lr = 0.0001
I0923 20:48:45.457247 14316 solver.cpp:218] Iteration 13900 (36.6471 iter/s, 2.72873s/100 iters), loss = 0.363609
I0923 20:48:45.457247 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:48:45.457247 14316 solver.cpp:237]     Train net output #1: loss = 0.363609 (* 1 = 0.363609 loss)
I0923 20:48:45.457247 14316 sgd_solver.cpp:105] Iteration 13900, lr = 0.0001
I0923 20:48:48.048732 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:48:48.156808 14316 solver.cpp:330] Iteration 14000, Testing net (#0)
I0923 20:48:48.156808 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:48:48.674175 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:48:48.694190 14316 solver.cpp:397]     Test net output #0: accuracy = 0.789
I0923 20:48:48.694190 14316 solver.cpp:397]     Test net output #1: loss = 0.618591 (* 1 = 0.618591 loss)
I0923 20:48:48.719708 14316 solver.cpp:218] Iteration 14000 (30.655 iter/s, 3.26211s/100 iters), loss = 0.401923
I0923 20:48:48.719708 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:48:48.719708 14316 solver.cpp:237]     Train net output #1: loss = 0.401923 (* 1 = 0.401923 loss)
I0923 20:48:48.719708 14316 sgd_solver.cpp:105] Iteration 14000, lr = 0.0001
I0923 20:48:51.445641 14316 solver.cpp:218] Iteration 14100 (36.6841 iter/s, 2.72598s/100 iters), loss = 0.38014
I0923 20:48:51.445641 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:48:51.445641 14316 solver.cpp:237]     Train net output #1: loss = 0.38014 (* 1 = 0.38014 loss)
I0923 20:48:51.445641 14316 sgd_solver.cpp:105] Iteration 14100, lr = 0.0001
I0923 20:48:54.164242 14316 solver.cpp:218] Iteration 14200 (36.79 iter/s, 2.71813s/100 iters), loss = 0.405962
I0923 20:48:54.164744 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:48:54.164744 14316 solver.cpp:237]     Train net output #1: loss = 0.405962 (* 1 = 0.405962 loss)
I0923 20:48:54.164744 14316 sgd_solver.cpp:105] Iteration 14200, lr = 0.0001
I0923 20:48:56.891890 14316 solver.cpp:218] Iteration 14300 (36.6615 iter/s, 2.72766s/100 iters), loss = 0.511484
I0923 20:48:56.891890 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:48:56.891890 14316 solver.cpp:237]     Train net output #1: loss = 0.511484 (* 1 = 0.511484 loss)
I0923 20:48:56.891890 14316 sgd_solver.cpp:105] Iteration 14300, lr = 0.0001
I0923 20:48:59.619104 14316 solver.cpp:218] Iteration 14400 (36.6806 iter/s, 2.72624s/100 iters), loss = 0.328282
I0923 20:48:59.619104 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:48:59.619104 14316 solver.cpp:237]     Train net output #1: loss = 0.328282 (* 1 = 0.328282 loss)
I0923 20:48:59.619104 14316 sgd_solver.cpp:105] Iteration 14400, lr = 0.0001
I0923 20:49:02.216755 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:49:02.351888 14316 solver.cpp:218] Iteration 14500 (36.5965 iter/s, 2.7325s/100 iters), loss = 0.475281
I0923 20:49:02.351888 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:49:02.351888 14316 solver.cpp:237]     Train net output #1: loss = 0.475281 (* 1 = 0.475281 loss)
I0923 20:49:02.351888 14316 sgd_solver.cpp:105] Iteration 14500, lr = 0.0001
I0923 20:49:05.089010 14316 solver.cpp:218] Iteration 14600 (36.5407 iter/s, 2.73667s/100 iters), loss = 0.402473
I0923 20:49:05.089010 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:49:05.089010 14316 solver.cpp:237]     Train net output #1: loss = 0.402473 (* 1 = 0.402473 loss)
I0923 20:49:05.089010 14316 sgd_solver.cpp:105] Iteration 14600, lr = 0.0001
I0923 20:49:07.860759 14316 solver.cpp:218] Iteration 14700 (36.0825 iter/s, 2.77143s/100 iters), loss = 0.374732
I0923 20:49:07.860759 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:49:07.860759 14316 solver.cpp:237]     Train net output #1: loss = 0.374732 (* 1 = 0.374732 loss)
I0923 20:49:07.860759 14316 sgd_solver.cpp:105] Iteration 14700, lr = 0.0001
I0923 20:49:10.708283 14316 solver.cpp:218] Iteration 14800 (35.1248 iter/s, 2.84699s/100 iters), loss = 0.455766
I0923 20:49:10.708283 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:49:10.708283 14316 solver.cpp:237]     Train net output #1: loss = 0.455766 (* 1 = 0.455766 loss)
I0923 20:49:10.708283 14316 sgd_solver.cpp:105] Iteration 14800, lr = 0.0001
I0923 20:49:13.519207 14316 solver.cpp:218] Iteration 14900 (35.5769 iter/s, 2.81081s/100 iters), loss = 0.374709
I0923 20:49:13.519207 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:49:13.519207 14316 solver.cpp:237]     Train net output #1: loss = 0.374709 (* 1 = 0.374709 loss)
I0923 20:49:13.519207 14316 sgd_solver.cpp:105] Iteration 14900, lr = 0.0001
I0923 20:49:16.184101 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:49:16.294180 14316 solver.cpp:330] Iteration 15000, Testing net (#0)
I0923 20:49:16.294180 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:49:16.832574 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:49:16.854578 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7896
I0923 20:49:16.854578 14316 solver.cpp:397]     Test net output #1: loss = 0.618611 (* 1 = 0.618611 loss)
I0923 20:49:16.880596 14316 solver.cpp:218] Iteration 15000 (29.7543 iter/s, 3.36086s/100 iters), loss = 0.446724
I0923 20:49:16.880596 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:49:16.880596 14316 solver.cpp:237]     Train net output #1: loss = 0.446724 (* 1 = 0.446724 loss)
I0923 20:49:16.880596 14316 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I0923 20:49:16.880596 14316 sgd_solver.cpp:105] Iteration 15000, lr = 1e-05
I0923 20:49:19.718158 14316 solver.cpp:218] Iteration 15100 (35.2464 iter/s, 2.83717s/100 iters), loss = 0.442641
I0923 20:49:19.718158 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:49:19.718158 14316 solver.cpp:237]     Train net output #1: loss = 0.442641 (* 1 = 0.442641 loss)
I0923 20:49:19.718158 14316 sgd_solver.cpp:105] Iteration 15100, lr = 1e-05
I0923 20:49:22.505148 14316 solver.cpp:218] Iteration 15200 (35.8893 iter/s, 2.78635s/100 iters), loss = 0.369973
I0923 20:49:22.505148 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:49:22.505148 14316 solver.cpp:237]     Train net output #1: loss = 0.369973 (* 1 = 0.369973 loss)
I0923 20:49:22.505148 14316 sgd_solver.cpp:105] Iteration 15200, lr = 1e-05
I0923 20:49:25.285722 14316 solver.cpp:218] Iteration 15300 (35.9673 iter/s, 2.7803s/100 iters), loss = 0.488865
I0923 20:49:25.285722 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:49:25.285722 14316 solver.cpp:237]     Train net output #1: loss = 0.488865 (* 1 = 0.488865 loss)
I0923 20:49:25.285722 14316 sgd_solver.cpp:105] Iteration 15300, lr = 1e-05
I0923 20:49:28.061697 14316 solver.cpp:218] Iteration 15400 (36.0267 iter/s, 2.77572s/100 iters), loss = 0.366357
I0923 20:49:28.061697 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:49:28.061697 14316 solver.cpp:237]     Train net output #1: loss = 0.366357 (* 1 = 0.366357 loss)
I0923 20:49:28.061697 14316 sgd_solver.cpp:105] Iteration 15400, lr = 1e-05
I0923 20:49:30.707062 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:49:30.843659 14316 solver.cpp:218] Iteration 15500 (35.9521 iter/s, 2.78148s/100 iters), loss = 0.445406
I0923 20:49:30.843659 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:49:30.843659 14316 solver.cpp:237]     Train net output #1: loss = 0.445406 (* 1 = 0.445406 loss)
I0923 20:49:30.843659 14316 sgd_solver.cpp:105] Iteration 15500, lr = 1e-05
I0923 20:49:33.625730 14316 solver.cpp:218] Iteration 15600 (35.9472 iter/s, 2.78185s/100 iters), loss = 0.382799
I0923 20:49:33.625730 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:49:33.625730 14316 solver.cpp:237]     Train net output #1: loss = 0.382799 (* 1 = 0.382799 loss)
I0923 20:49:33.625730 14316 sgd_solver.cpp:105] Iteration 15600, lr = 1e-05
I0923 20:49:36.404026 14316 solver.cpp:218] Iteration 15700 (35.9949 iter/s, 2.77817s/100 iters), loss = 0.362376
I0923 20:49:36.404525 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:49:36.404525 14316 solver.cpp:237]     Train net output #1: loss = 0.362376 (* 1 = 0.362376 loss)
I0923 20:49:36.404525 14316 sgd_solver.cpp:105] Iteration 15700, lr = 1e-05
I0923 20:49:39.180707 14316 solver.cpp:218] Iteration 15800 (36.0195 iter/s, 2.77627s/100 iters), loss = 0.482535
I0923 20:49:39.181207 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:49:39.181207 14316 solver.cpp:237]     Train net output #1: loss = 0.482535 (* 1 = 0.482535 loss)
I0923 20:49:39.181207 14316 sgd_solver.cpp:105] Iteration 15800, lr = 1e-05
I0923 20:49:41.959118 14316 solver.cpp:218] Iteration 15900 (35.9974 iter/s, 2.77798s/100 iters), loss = 0.328247
I0923 20:49:41.959118 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:49:41.959118 14316 solver.cpp:237]     Train net output #1: loss = 0.328247 (* 1 = 0.328247 loss)
I0923 20:49:41.959118 14316 sgd_solver.cpp:105] Iteration 15900, lr = 1e-05
I0923 20:49:44.600266 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:49:44.710845 14316 solver.cpp:330] Iteration 16000, Testing net (#0)
I0923 20:49:44.710845 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:49:45.231230 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:49:45.251230 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7899
I0923 20:49:45.251230 14316 solver.cpp:397]     Test net output #1: loss = 0.618095 (* 1 = 0.618095 loss)
I0923 20:49:45.277765 14316 solver.cpp:218] Iteration 16000 (30.1388 iter/s, 3.31798s/100 iters), loss = 0.40946
I0923 20:49:45.277765 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:49:45.277765 14316 solver.cpp:237]     Train net output #1: loss = 0.40946 (* 1 = 0.40946 loss)
I0923 20:49:45.277765 14316 sgd_solver.cpp:105] Iteration 16000, lr = 1e-05
I0923 20:49:48.058742 14316 solver.cpp:218] Iteration 16100 (35.9578 iter/s, 2.78104s/100 iters), loss = 0.460845
I0923 20:49:48.058742 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:49:48.058742 14316 solver.cpp:237]     Train net output #1: loss = 0.460845 (* 1 = 0.460845 loss)
I0923 20:49:48.058742 14316 sgd_solver.cpp:105] Iteration 16100, lr = 1e-05
I0923 20:49:50.908776 14316 solver.cpp:218] Iteration 16200 (35.0915 iter/s, 2.84969s/100 iters), loss = 0.443559
I0923 20:49:50.908776 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:49:50.909281 14316 solver.cpp:237]     Train net output #1: loss = 0.443559 (* 1 = 0.443559 loss)
I0923 20:49:50.909281 14316 sgd_solver.cpp:105] Iteration 16200, lr = 1e-05
I0923 20:49:53.725304 14316 solver.cpp:218] Iteration 16300 (35.5148 iter/s, 2.81573s/100 iters), loss = 0.471014
I0923 20:49:53.725304 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:49:53.725304 14316 solver.cpp:237]     Train net output #1: loss = 0.471014 (* 1 = 0.471014 loss)
I0923 20:49:53.725304 14316 sgd_solver.cpp:105] Iteration 16300, lr = 1e-05
I0923 20:49:56.576176 14316 solver.cpp:218] Iteration 16400 (35.0828 iter/s, 2.8504s/100 iters), loss = 0.305042
I0923 20:49:56.576176 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:49:56.576176 14316 solver.cpp:237]     Train net output #1: loss = 0.305042 (* 1 = 0.305042 loss)
I0923 20:49:56.576176 14316 sgd_solver.cpp:105] Iteration 16400, lr = 1e-05
I0923 20:49:59.276581 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:49:59.411676 14316 solver.cpp:218] Iteration 16500 (35.2704 iter/s, 2.83524s/100 iters), loss = 0.411593
I0923 20:49:59.411676 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:49:59.411676 14316 solver.cpp:237]     Train net output #1: loss = 0.411593 (* 1 = 0.411593 loss)
I0923 20:49:59.411676 14316 sgd_solver.cpp:105] Iteration 16500, lr = 1e-05
I0923 20:50:02.221696 14316 solver.cpp:218] Iteration 16600 (35.5905 iter/s, 2.80974s/100 iters), loss = 0.410852
I0923 20:50:02.222193 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:50:02.222193 14316 solver.cpp:237]     Train net output #1: loss = 0.410851 (* 1 = 0.410851 loss)
I0923 20:50:02.222193 14316 sgd_solver.cpp:105] Iteration 16600, lr = 1e-05
I0923 20:50:05.062747 14316 solver.cpp:218] Iteration 16700 (35.2048 iter/s, 2.84052s/100 iters), loss = 0.395982
I0923 20:50:05.062747 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:50:05.062747 14316 solver.cpp:237]     Train net output #1: loss = 0.395982 (* 1 = 0.395982 loss)
I0923 20:50:05.062747 14316 sgd_solver.cpp:105] Iteration 16700, lr = 1e-05
I0923 20:50:07.843500 14316 solver.cpp:218] Iteration 16800 (35.9687 iter/s, 2.7802s/100 iters), loss = 0.460301
I0923 20:50:07.843500 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:50:07.843500 14316 solver.cpp:237]     Train net output #1: loss = 0.460301 (* 1 = 0.460301 loss)
I0923 20:50:07.843500 14316 sgd_solver.cpp:105] Iteration 16800, lr = 1e-05
I0923 20:50:10.627981 14316 solver.cpp:218] Iteration 16900 (35.9137 iter/s, 2.78445s/100 iters), loss = 0.334143
I0923 20:50:10.627981 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:50:10.627981 14316 solver.cpp:237]     Train net output #1: loss = 0.334143 (* 1 = 0.334143 loss)
I0923 20:50:10.627981 14316 sgd_solver.cpp:105] Iteration 16900, lr = 1e-05
I0923 20:50:13.279366 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:50:13.388959 14316 solver.cpp:330] Iteration 17000, Testing net (#0)
I0923 20:50:13.389459 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:50:13.912817 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:50:13.933332 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7897
I0923 20:50:13.933332 14316 solver.cpp:397]     Test net output #1: loss = 0.618064 (* 1 = 0.618064 loss)
I0923 20:50:13.959349 14316 solver.cpp:218] Iteration 17000 (30.0227 iter/s, 3.33081s/100 iters), loss = 0.427801
I0923 20:50:13.959349 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:50:13.959349 14316 solver.cpp:237]     Train net output #1: loss = 0.427801 (* 1 = 0.427801 loss)
I0923 20:50:13.959349 14316 sgd_solver.cpp:105] Iteration 17000, lr = 1e-05
I0923 20:50:16.735697 14316 solver.cpp:218] Iteration 17100 (36.0204 iter/s, 2.7762s/100 iters), loss = 0.385181
I0923 20:50:16.735697 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:50:16.736196 14316 solver.cpp:237]     Train net output #1: loss = 0.385181 (* 1 = 0.385181 loss)
I0923 20:50:16.736196 14316 sgd_solver.cpp:105] Iteration 17100, lr = 1e-05
I0923 20:50:19.516662 14316 solver.cpp:218] Iteration 17200 (35.9636 iter/s, 2.78059s/100 iters), loss = 0.470385
I0923 20:50:19.516662 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:50:19.516662 14316 solver.cpp:237]     Train net output #1: loss = 0.470385 (* 1 = 0.470385 loss)
I0923 20:50:19.516662 14316 sgd_solver.cpp:105] Iteration 17200, lr = 1e-05
I0923 20:50:22.290705 14316 solver.cpp:218] Iteration 17300 (36.0532 iter/s, 2.77368s/100 iters), loss = 0.448574
I0923 20:50:22.290705 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:50:22.291189 14316 solver.cpp:237]     Train net output #1: loss = 0.448574 (* 1 = 0.448574 loss)
I0923 20:50:22.291189 14316 sgd_solver.cpp:105] Iteration 17300, lr = 1e-05
I0923 20:50:25.075052 14316 solver.cpp:218] Iteration 17400 (35.9229 iter/s, 2.78374s/100 iters), loss = 0.345107
I0923 20:50:25.075052 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:50:25.075052 14316 solver.cpp:237]     Train net output #1: loss = 0.345107 (* 1 = 0.345107 loss)
I0923 20:50:25.075052 14316 sgd_solver.cpp:105] Iteration 17400, lr = 1e-05
I0923 20:50:27.759102 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:50:27.898200 14316 solver.cpp:218] Iteration 17500 (35.4288 iter/s, 2.82256s/100 iters), loss = 0.410088
I0923 20:50:27.898200 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:50:27.898200 14316 solver.cpp:237]     Train net output #1: loss = 0.410088 (* 1 = 0.410088 loss)
I0923 20:50:27.898200 14316 sgd_solver.cpp:105] Iteration 17500, lr = 1e-05
I0923 20:50:30.731268 14316 solver.cpp:218] Iteration 17600 (35.3003 iter/s, 2.83284s/100 iters), loss = 0.373721
I0923 20:50:30.731268 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:50:30.731268 14316 solver.cpp:237]     Train net output #1: loss = 0.373721 (* 1 = 0.373721 loss)
I0923 20:50:30.731268 14316 sgd_solver.cpp:105] Iteration 17600, lr = 1e-05
I0923 20:50:33.510689 14316 solver.cpp:218] Iteration 17700 (35.9796 iter/s, 2.77935s/100 iters), loss = 0.38257
I0923 20:50:33.510689 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:50:33.510689 14316 solver.cpp:237]     Train net output #1: loss = 0.38257 (* 1 = 0.38257 loss)
I0923 20:50:33.511188 14316 sgd_solver.cpp:105] Iteration 17700, lr = 1e-05
I0923 20:50:36.312531 14316 solver.cpp:218] Iteration 17800 (35.701 iter/s, 2.80105s/100 iters), loss = 0.449628
I0923 20:50:36.312531 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:50:36.312531 14316 solver.cpp:237]     Train net output #1: loss = 0.449628 (* 1 = 0.449628 loss)
I0923 20:50:36.312531 14316 sgd_solver.cpp:105] Iteration 17800, lr = 1e-05
I0923 20:50:39.125008 14316 solver.cpp:218] Iteration 17900 (35.5514 iter/s, 2.81283s/100 iters), loss = 0.386234
I0923 20:50:39.125008 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:50:39.125008 14316 solver.cpp:237]     Train net output #1: loss = 0.386234 (* 1 = 0.386234 loss)
I0923 20:50:39.125008 14316 sgd_solver.cpp:105] Iteration 17900, lr = 1e-05
I0923 20:50:41.816305 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:50:41.926895 14316 solver.cpp:330] Iteration 18000, Testing net (#0)
I0923 20:50:41.926895 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:50:42.458118 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:50:42.479135 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7901
I0923 20:50:42.479135 14316 solver.cpp:397]     Test net output #1: loss = 0.61796 (* 1 = 0.61796 loss)
I0923 20:50:42.505162 14316 solver.cpp:218] Iteration 18000 (29.5889 iter/s, 3.37964s/100 iters), loss = 0.42051
I0923 20:50:42.505162 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:50:42.505162 14316 solver.cpp:237]     Train net output #1: loss = 0.42051 (* 1 = 0.42051 loss)
I0923 20:50:42.505162 14316 sgd_solver.cpp:105] Iteration 18000, lr = 1e-05
I0923 20:50:45.328253 14316 solver.cpp:218] Iteration 18100 (35.431 iter/s, 2.82239s/100 iters), loss = 0.408409
I0923 20:50:45.328253 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:50:45.328253 14316 solver.cpp:237]     Train net output #1: loss = 0.408409 (* 1 = 0.408409 loss)
I0923 20:50:45.328253 14316 sgd_solver.cpp:105] Iteration 18100, lr = 1e-05
I0923 20:50:48.163652 14316 solver.cpp:218] Iteration 18200 (35.2779 iter/s, 2.83463s/100 iters), loss = 0.437186
I0923 20:50:48.163652 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:50:48.163652 14316 solver.cpp:237]     Train net output #1: loss = 0.437186 (* 1 = 0.437186 loss)
I0923 20:50:48.163652 14316 sgd_solver.cpp:105] Iteration 18200, lr = 1e-05
I0923 20:50:50.987800 14316 solver.cpp:218] Iteration 18300 (35.4077 iter/s, 2.82424s/100 iters), loss = 0.499887
I0923 20:50:50.987800 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:50:50.987800 14316 solver.cpp:237]     Train net output #1: loss = 0.499887 (* 1 = 0.499887 loss)
I0923 20:50:50.987800 14316 sgd_solver.cpp:105] Iteration 18300, lr = 1e-05
I0923 20:50:53.803766 14316 solver.cpp:218] Iteration 18400 (35.5141 iter/s, 2.81579s/100 iters), loss = 0.321547
I0923 20:50:53.803766 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:50:53.803766 14316 solver.cpp:237]     Train net output #1: loss = 0.321547 (* 1 = 0.321547 loss)
I0923 20:50:53.803766 14316 sgd_solver.cpp:105] Iteration 18400, lr = 1e-05
I0923 20:50:56.480706 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:50:56.618319 14316 solver.cpp:218] Iteration 18500 (35.5368 iter/s, 2.81398s/100 iters), loss = 0.440717
I0923 20:50:56.618319 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:50:56.618319 14316 solver.cpp:237]     Train net output #1: loss = 0.440717 (* 1 = 0.440717 loss)
I0923 20:50:56.618319 14316 sgd_solver.cpp:105] Iteration 18500, lr = 1e-05
I0923 20:50:59.424511 14316 solver.cpp:218] Iteration 18600 (35.6388 iter/s, 2.80593s/100 iters), loss = 0.389301
I0923 20:50:59.424511 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:50:59.424511 14316 solver.cpp:237]     Train net output #1: loss = 0.389301 (* 1 = 0.389301 loss)
I0923 20:50:59.424511 14316 sgd_solver.cpp:105] Iteration 18600, lr = 1e-05
I0923 20:51:02.229385 14316 solver.cpp:218] Iteration 18700 (35.659 iter/s, 2.80434s/100 iters), loss = 0.371303
I0923 20:51:02.229385 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:51:02.229385 14316 solver.cpp:237]     Train net output #1: loss = 0.371303 (* 1 = 0.371303 loss)
I0923 20:51:02.229385 14316 sgd_solver.cpp:105] Iteration 18700, lr = 1e-05
I0923 20:51:05.046227 14316 solver.cpp:218] Iteration 18800 (35.504 iter/s, 2.81658s/100 iters), loss = 0.508139
I0923 20:51:05.046227 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:51:05.046227 14316 solver.cpp:237]     Train net output #1: loss = 0.508139 (* 1 = 0.508139 loss)
I0923 20:51:05.046227 14316 sgd_solver.cpp:105] Iteration 18800, lr = 1e-05
I0923 20:51:07.867866 14316 solver.cpp:218] Iteration 18900 (35.4488 iter/s, 2.82097s/100 iters), loss = 0.327013
I0923 20:51:07.867866 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:51:07.867866 14316 solver.cpp:237]     Train net output #1: loss = 0.327012 (* 1 = 0.327012 loss)
I0923 20:51:07.868367 14316 sgd_solver.cpp:105] Iteration 18900, lr = 1e-05
I0923 20:51:10.524503 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:51:10.632602 14316 solver.cpp:330] Iteration 19000, Testing net (#0)
I0923 20:51:10.632602 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:51:11.148548 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:51:11.169580 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7902
I0923 20:51:11.169580 14316 solver.cpp:397]     Test net output #1: loss = 0.617896 (* 1 = 0.617896 loss)
I0923 20:51:11.195276 14316 solver.cpp:218] Iteration 19000 (30.0559 iter/s, 3.32713s/100 iters), loss = 0.42727
I0923 20:51:11.195276 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:51:11.195276 14316 solver.cpp:237]     Train net output #1: loss = 0.42727 (* 1 = 0.42727 loss)
I0923 20:51:11.195276 14316 sgd_solver.cpp:105] Iteration 19000, lr = 1e-05
I0923 20:51:13.960974 14316 solver.cpp:218] Iteration 19100 (36.1676 iter/s, 2.7649s/100 iters), loss = 0.406535
I0923 20:51:13.960974 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:51:13.960974 14316 solver.cpp:237]     Train net output #1: loss = 0.406535 (* 1 = 0.406535 loss)
I0923 20:51:13.960974 14316 sgd_solver.cpp:105] Iteration 19100, lr = 1e-05
I0923 20:51:16.790088 14316 solver.cpp:218] Iteration 19200 (35.3488 iter/s, 2.82895s/100 iters), loss = 0.39296
I0923 20:51:16.790088 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:51:16.790088 14316 solver.cpp:237]     Train net output #1: loss = 0.39296 (* 1 = 0.39296 loss)
I0923 20:51:16.790088 14316 sgd_solver.cpp:105] Iteration 19200, lr = 1e-05
I0923 20:51:19.610594 14316 solver.cpp:218] Iteration 19300 (35.4598 iter/s, 2.8201s/100 iters), loss = 0.487564
I0923 20:51:19.610594 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:51:19.610594 14316 solver.cpp:237]     Train net output #1: loss = 0.487564 (* 1 = 0.487564 loss)
I0923 20:51:19.610594 14316 sgd_solver.cpp:105] Iteration 19300, lr = 1e-05
I0923 20:51:22.437988 14316 solver.cpp:218] Iteration 19400 (35.3747 iter/s, 2.82688s/100 iters), loss = 0.365892
I0923 20:51:22.437988 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:51:22.437988 14316 solver.cpp:237]     Train net output #1: loss = 0.365892 (* 1 = 0.365892 loss)
I0923 20:51:22.437988 14316 sgd_solver.cpp:105] Iteration 19400, lr = 1e-05
I0923 20:51:25.098043 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:51:25.237159 14316 solver.cpp:218] Iteration 19500 (35.7296 iter/s, 2.7988s/100 iters), loss = 0.457897
I0923 20:51:25.237159 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:51:25.237159 14316 solver.cpp:237]     Train net output #1: loss = 0.457897 (* 1 = 0.457897 loss)
I0923 20:51:25.237159 14316 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I0923 20:51:28.089529 14316 solver.cpp:218] Iteration 19600 (35.0636 iter/s, 2.85196s/100 iters), loss = 0.390357
I0923 20:51:28.089529 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:51:28.089529 14316 solver.cpp:237]     Train net output #1: loss = 0.390357 (* 1 = 0.390357 loss)
I0923 20:51:28.089529 14316 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I0923 20:51:30.875725 14316 solver.cpp:218] Iteration 19700 (35.8973 iter/s, 2.78573s/100 iters), loss = 0.375005
I0923 20:51:30.875725 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:51:30.875725 14316 solver.cpp:237]     Train net output #1: loss = 0.375005 (* 1 = 0.375005 loss)
I0923 20:51:30.875725 14316 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I0923 20:51:33.653769 14316 solver.cpp:218] Iteration 19800 (35.999 iter/s, 2.77785s/100 iters), loss = 0.430313
I0923 20:51:33.653769 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:51:33.653769 14316 solver.cpp:237]     Train net output #1: loss = 0.430313 (* 1 = 0.430313 loss)
I0923 20:51:33.654268 14316 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I0923 20:51:36.439573 14316 solver.cpp:218] Iteration 19900 (35.9028 iter/s, 2.7853s/100 iters), loss = 0.349884
I0923 20:51:36.439573 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:51:36.439573 14316 solver.cpp:237]     Train net output #1: loss = 0.349884 (* 1 = 0.349884 loss)
I0923 20:51:36.439573 14316 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I0923 20:51:39.099004 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:51:39.208581 14316 solver.cpp:330] Iteration 20000, Testing net (#0)
I0923 20:51:39.209082 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:51:39.734956 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:51:39.755971 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7904
I0923 20:51:39.755971 14316 solver.cpp:397]     Test net output #1: loss = 0.617985 (* 1 = 0.617985 loss)
I0923 20:51:39.782990 14316 solver.cpp:218] Iteration 20000 (29.9136 iter/s, 3.34297s/100 iters), loss = 0.429053
I0923 20:51:39.782990 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:51:39.782990 14316 solver.cpp:237]     Train net output #1: loss = 0.429053 (* 1 = 0.429053 loss)
I0923 20:51:39.782990 14316 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I0923 20:51:42.573837 14316 solver.cpp:218] Iteration 20100 (35.8355 iter/s, 2.79053s/100 iters), loss = 0.347045
I0923 20:51:42.573837 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:51:42.573837 14316 solver.cpp:237]     Train net output #1: loss = 0.347045 (* 1 = 0.347045 loss)
I0923 20:51:42.573837 14316 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I0923 20:51:45.357625 14316 solver.cpp:218] Iteration 20200 (35.9246 iter/s, 2.78361s/100 iters), loss = 0.408048
I0923 20:51:45.357625 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:51:45.357625 14316 solver.cpp:237]     Train net output #1: loss = 0.408048 (* 1 = 0.408048 loss)
I0923 20:51:45.357625 14316 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I0923 20:51:48.132736 14316 solver.cpp:218] Iteration 20300 (36.0443 iter/s, 2.77436s/100 iters), loss = 0.402021
I0923 20:51:48.132736 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:51:48.132736 14316 solver.cpp:237]     Train net output #1: loss = 0.402021 (* 1 = 0.402021 loss)
I0923 20:51:48.132736 14316 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I0923 20:51:50.911432 14316 solver.cpp:218] Iteration 20400 (35.9916 iter/s, 2.77842s/100 iters), loss = 0.343832
I0923 20:51:50.911432 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:51:50.911432 14316 solver.cpp:237]     Train net output #1: loss = 0.343832 (* 1 = 0.343832 loss)
I0923 20:51:50.911432 14316 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I0923 20:51:53.544849 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:51:53.678442 14316 solver.cpp:218] Iteration 20500 (36.1437 iter/s, 2.76674s/100 iters), loss = 0.435234
I0923 20:51:53.678442 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:51:53.678442 14316 solver.cpp:237]     Train net output #1: loss = 0.435234 (* 1 = 0.435234 loss)
I0923 20:51:53.678442 14316 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I0923 20:51:56.469975 14316 solver.cpp:218] Iteration 20600 (35.8249 iter/s, 2.79136s/100 iters), loss = 0.373689
I0923 20:51:56.469975 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:51:56.469975 14316 solver.cpp:237]     Train net output #1: loss = 0.373689 (* 1 = 0.373689 loss)
I0923 20:51:56.469975 14316 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I0923 20:51:59.273483 14316 solver.cpp:218] Iteration 20700 (35.6779 iter/s, 2.80286s/100 iters), loss = 0.404648
I0923 20:51:59.273483 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:51:59.273483 14316 solver.cpp:237]     Train net output #1: loss = 0.404648 (* 1 = 0.404648 loss)
I0923 20:51:59.273483 14316 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I0923 20:52:02.047204 14316 solver.cpp:218] Iteration 20800 (36.0516 iter/s, 2.77381s/100 iters), loss = 0.40251
I0923 20:52:02.047204 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:52:02.047204 14316 solver.cpp:237]     Train net output #1: loss = 0.40251 (* 1 = 0.40251 loss)
I0923 20:52:02.047204 14316 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I0923 20:52:04.793299 14316 solver.cpp:218] Iteration 20900 (36.424 iter/s, 2.74545s/100 iters), loss = 0.33396
I0923 20:52:04.793299 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:52:04.793299 14316 solver.cpp:237]     Train net output #1: loss = 0.33396 (* 1 = 0.33396 loss)
I0923 20:52:04.793299 14316 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I0923 20:52:07.391067 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:52:07.499738 14316 solver.cpp:330] Iteration 21000, Testing net (#0)
I0923 20:52:07.499738 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:52:08.029304 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:52:08.050319 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7902
I0923 20:52:08.050319 14316 solver.cpp:397]     Test net output #1: loss = 0.617827 (* 1 = 0.617827 loss)
I0923 20:52:08.075336 14316 solver.cpp:218] Iteration 21000 (30.4747 iter/s, 3.28141s/100 iters), loss = 0.463979
I0923 20:52:08.075336 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:52:08.075336 14316 solver.cpp:237]     Train net output #1: loss = 0.463979 (* 1 = 0.463979 loss)
I0923 20:52:08.075336 14316 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I0923 20:52:10.809167 14316 solver.cpp:218] Iteration 21100 (36.5823 iter/s, 2.73356s/100 iters), loss = 0.399067
I0923 20:52:10.809167 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:52:10.809167 14316 solver.cpp:237]     Train net output #1: loss = 0.399067 (* 1 = 0.399067 loss)
I0923 20:52:10.809167 14316 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I0923 20:52:13.532709 14316 solver.cpp:218] Iteration 21200 (36.7115 iter/s, 2.72394s/100 iters), loss = 0.424361
I0923 20:52:13.532709 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:52:13.532709 14316 solver.cpp:237]     Train net output #1: loss = 0.424361 (* 1 = 0.424361 loss)
I0923 20:52:13.532709 14316 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I0923 20:52:16.281628 14316 solver.cpp:218] Iteration 21300 (36.3904 iter/s, 2.74798s/100 iters), loss = 0.451906
I0923 20:52:16.281628 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:52:16.281628 14316 solver.cpp:237]     Train net output #1: loss = 0.451906 (* 1 = 0.451906 loss)
I0923 20:52:16.281628 14316 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I0923 20:52:19.017993 14316 solver.cpp:218] Iteration 21400 (36.5493 iter/s, 2.73603s/100 iters), loss = 0.340776
I0923 20:52:19.017993 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:52:19.017993 14316 solver.cpp:237]     Train net output #1: loss = 0.340776 (* 1 = 0.340776 loss)
I0923 20:52:19.017993 14316 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I0923 20:52:21.631399 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:52:21.764480 14316 solver.cpp:218] Iteration 21500 (36.4115 iter/s, 2.74638s/100 iters), loss = 0.42733
I0923 20:52:21.764480 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:52:21.764480 14316 solver.cpp:237]     Train net output #1: loss = 0.42733 (* 1 = 0.42733 loss)
I0923 20:52:21.764480 14316 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I0923 20:52:24.523838 14316 solver.cpp:218] Iteration 21600 (36.2452 iter/s, 2.75899s/100 iters), loss = 0.404578
I0923 20:52:24.524338 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:52:24.524338 14316 solver.cpp:237]     Train net output #1: loss = 0.404578 (* 1 = 0.404578 loss)
I0923 20:52:24.524338 14316 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I0923 20:52:27.277777 14316 solver.cpp:218] Iteration 21700 (36.3198 iter/s, 2.75332s/100 iters), loss = 0.384354
I0923 20:52:27.277777 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:52:27.277777 14316 solver.cpp:237]     Train net output #1: loss = 0.384354 (* 1 = 0.384354 loss)
I0923 20:52:27.277777 14316 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I0923 20:52:30.040568 14316 solver.cpp:218] Iteration 21800 (36.2025 iter/s, 2.76224s/100 iters), loss = 0.460028
I0923 20:52:30.040568 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:52:30.040568 14316 solver.cpp:237]     Train net output #1: loss = 0.460028 (* 1 = 0.460028 loss)
I0923 20:52:30.040568 14316 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I0923 20:52:32.791306 14316 solver.cpp:218] Iteration 21900 (36.3585 iter/s, 2.75039s/100 iters), loss = 0.332339
I0923 20:52:32.791306 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:52:32.791306 14316 solver.cpp:237]     Train net output #1: loss = 0.332339 (* 1 = 0.332339 loss)
I0923 20:52:32.791306 14316 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I0923 20:52:35.406808 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:52:35.512642 14316 solver.cpp:330] Iteration 22000, Testing net (#0)
I0923 20:52:35.512642 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:52:36.028976 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:52:36.048861 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7905
I0923 20:52:36.048861 14316 solver.cpp:397]     Test net output #1: loss = 0.617978 (* 1 = 0.617978 loss)
I0923 20:52:36.073895 14316 solver.cpp:218] Iteration 22000 (30.463 iter/s, 3.28267s/100 iters), loss = 0.445244
I0923 20:52:36.073895 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:52:36.073895 14316 solver.cpp:237]     Train net output #1: loss = 0.445244 (* 1 = 0.445244 loss)
I0923 20:52:36.073895 14316 sgd_solver.cpp:105] Iteration 22000, lr = 1e-05
I0923 20:52:38.798842 14316 solver.cpp:218] Iteration 22100 (36.6978 iter/s, 2.72496s/100 iters), loss = 0.466908
I0923 20:52:38.798842 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:52:38.798842 14316 solver.cpp:237]     Train net output #1: loss = 0.466908 (* 1 = 0.466908 loss)
I0923 20:52:38.798842 14316 sgd_solver.cpp:105] Iteration 22100, lr = 1e-05
I0923 20:52:41.528411 14316 solver.cpp:218] Iteration 22200 (36.6397 iter/s, 2.72928s/100 iters), loss = 0.433732
I0923 20:52:41.528411 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:52:41.528411 14316 solver.cpp:237]     Train net output #1: loss = 0.433732 (* 1 = 0.433732 loss)
I0923 20:52:41.528411 14316 sgd_solver.cpp:105] Iteration 22200, lr = 1e-05
I0923 20:52:44.271312 14316 solver.cpp:218] Iteration 22300 (36.4651 iter/s, 2.74235s/100 iters), loss = 0.47989
I0923 20:52:44.271312 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:52:44.271312 14316 solver.cpp:237]     Train net output #1: loss = 0.479889 (* 1 = 0.479889 loss)
I0923 20:52:44.271312 14316 sgd_solver.cpp:105] Iteration 22300, lr = 1e-05
I0923 20:52:47.001456 14316 solver.cpp:218] Iteration 22400 (36.6366 iter/s, 2.72951s/100 iters), loss = 0.345736
I0923 20:52:47.001456 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:52:47.001456 14316 solver.cpp:237]     Train net output #1: loss = 0.345736 (* 1 = 0.345736 loss)
I0923 20:52:47.001456 14316 sgd_solver.cpp:105] Iteration 22400, lr = 1e-05
I0923 20:52:49.616415 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:52:49.750573 14316 solver.cpp:218] Iteration 22500 (36.38 iter/s, 2.74876s/100 iters), loss = 0.402892
I0923 20:52:49.750573 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:52:49.750573 14316 solver.cpp:237]     Train net output #1: loss = 0.402892 (* 1 = 0.402892 loss)
I0923 20:52:49.750573 14316 sgd_solver.cpp:105] Iteration 22500, lr = 1e-05
I0923 20:52:52.589804 14316 solver.cpp:218] Iteration 22600 (35.2222 iter/s, 2.83912s/100 iters), loss = 0.383816
I0923 20:52:52.590306 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:52:52.590306 14316 solver.cpp:237]     Train net output #1: loss = 0.383816 (* 1 = 0.383816 loss)
I0923 20:52:52.590306 14316 sgd_solver.cpp:105] Iteration 22600, lr = 1e-05
I0923 20:52:55.441334 14316 solver.cpp:218] Iteration 22700 (35.0766 iter/s, 2.8509s/100 iters), loss = 0.357201
I0923 20:52:55.441334 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:52:55.441334 14316 solver.cpp:237]     Train net output #1: loss = 0.357201 (* 1 = 0.357201 loss)
I0923 20:52:55.441334 14316 sgd_solver.cpp:105] Iteration 22700, lr = 1e-05
I0923 20:52:58.283584 14316 solver.cpp:218] Iteration 22800 (35.1901 iter/s, 2.84171s/100 iters), loss = 0.459752
I0923 20:52:58.283584 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:52:58.283584 14316 solver.cpp:237]     Train net output #1: loss = 0.459752 (* 1 = 0.459752 loss)
I0923 20:52:58.283584 14316 sgd_solver.cpp:105] Iteration 22800, lr = 1e-05
I0923 20:53:01.118782 14316 solver.cpp:218] Iteration 22900 (35.2751 iter/s, 2.83486s/100 iters), loss = 0.321384
I0923 20:53:01.118782 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:53:01.118782 14316 solver.cpp:237]     Train net output #1: loss = 0.321384 (* 1 = 0.321384 loss)
I0923 20:53:01.118782 14316 sgd_solver.cpp:105] Iteration 22900, lr = 1e-05
I0923 20:53:03.818366 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:53:03.932430 14316 solver.cpp:330] Iteration 23000, Testing net (#0)
I0923 20:53:03.932430 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:53:04.468811 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:53:04.489838 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7905
I0923 20:53:04.489838 14316 solver.cpp:397]     Test net output #1: loss = 0.61793 (* 1 = 0.61793 loss)
I0923 20:53:04.516345 14316 solver.cpp:218] Iteration 23000 (29.4329 iter/s, 3.39755s/100 iters), loss = 0.469646
I0923 20:53:04.516345 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:53:04.516845 14316 solver.cpp:237]     Train net output #1: loss = 0.469646 (* 1 = 0.469646 loss)
I0923 20:53:04.516845 14316 sgd_solver.cpp:105] Iteration 23000, lr = 1e-05
I0923 20:53:07.318838 14316 solver.cpp:218] Iteration 23100 (35.689 iter/s, 2.80198s/100 iters), loss = 0.395644
I0923 20:53:07.318838 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:53:07.318838 14316 solver.cpp:237]     Train net output #1: loss = 0.395644 (* 1 = 0.395644 loss)
I0923 20:53:07.318838 14316 sgd_solver.cpp:105] Iteration 23100, lr = 1e-05
I0923 20:53:10.111835 14316 solver.cpp:218] Iteration 23200 (35.8061 iter/s, 2.79282s/100 iters), loss = 0.430639
I0923 20:53:10.111835 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:53:10.112334 14316 solver.cpp:237]     Train net output #1: loss = 0.430639 (* 1 = 0.430639 loss)
I0923 20:53:10.112334 14316 sgd_solver.cpp:105] Iteration 23200, lr = 1e-05
I0923 20:53:12.897307 14316 solver.cpp:218] Iteration 23300 (35.9053 iter/s, 2.78511s/100 iters), loss = 0.488119
I0923 20:53:12.897307 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:53:12.897307 14316 solver.cpp:237]     Train net output #1: loss = 0.488119 (* 1 = 0.488119 loss)
I0923 20:53:12.897307 14316 sgd_solver.cpp:105] Iteration 23300, lr = 1e-05
I0923 20:53:15.747376 14316 solver.cpp:218] Iteration 23400 (35.095 iter/s, 2.84941s/100 iters), loss = 0.317501
I0923 20:53:15.747376 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:53:15.747376 14316 solver.cpp:237]     Train net output #1: loss = 0.317501 (* 1 = 0.317501 loss)
I0923 20:53:15.747376 14316 sgd_solver.cpp:105] Iteration 23400, lr = 1e-05
I0923 20:53:18.473781 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:53:18.615383 14316 solver.cpp:218] Iteration 23500 (34.8725 iter/s, 2.86759s/100 iters), loss = 0.434467
I0923 20:53:18.615383 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:53:18.615383 14316 solver.cpp:237]     Train net output #1: loss = 0.434467 (* 1 = 0.434467 loss)
I0923 20:53:18.615383 14316 sgd_solver.cpp:105] Iteration 23500, lr = 1e-05
I0923 20:53:21.444299 14316 solver.cpp:218] Iteration 23600 (35.3499 iter/s, 2.82886s/100 iters), loss = 0.413775
I0923 20:53:21.444800 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:53:21.444800 14316 solver.cpp:237]     Train net output #1: loss = 0.413775 (* 1 = 0.413775 loss)
I0923 20:53:21.444800 14316 sgd_solver.cpp:105] Iteration 23600, lr = 1e-05
I0923 20:53:24.255241 14316 solver.cpp:218] Iteration 23700 (35.5807 iter/s, 2.81051s/100 iters), loss = 0.435289
I0923 20:53:24.255241 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:53:24.255241 14316 solver.cpp:237]     Train net output #1: loss = 0.435289 (* 1 = 0.435289 loss)
I0923 20:53:24.255241 14316 sgd_solver.cpp:105] Iteration 23700, lr = 1e-05
I0923 20:53:27.119269 14316 solver.cpp:218] Iteration 23800 (34.9253 iter/s, 2.86326s/100 iters), loss = 0.473557
I0923 20:53:27.119269 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:53:27.119269 14316 solver.cpp:237]     Train net output #1: loss = 0.473557 (* 1 = 0.473557 loss)
I0923 20:53:27.119269 14316 sgd_solver.cpp:105] Iteration 23800, lr = 1e-05
I0923 20:53:29.973011 14316 solver.cpp:218] Iteration 23900 (35.0421 iter/s, 2.85371s/100 iters), loss = 0.365458
I0923 20:53:29.973011 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:53:29.973011 14316 solver.cpp:237]     Train net output #1: loss = 0.365458 (* 1 = 0.365458 loss)
I0923 20:53:29.973011 14316 sgd_solver.cpp:105] Iteration 23900, lr = 1e-05
I0923 20:53:32.623081 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:53:32.733144 14316 solver.cpp:330] Iteration 24000, Testing net (#0)
I0923 20:53:32.733144 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:53:33.254842 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:53:33.275368 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7904
I0923 20:53:33.275368 14316 solver.cpp:397]     Test net output #1: loss = 0.617933 (* 1 = 0.617933 loss)
I0923 20:53:33.301373 14316 solver.cpp:218] Iteration 24000 (30.0479 iter/s, 3.32802s/100 iters), loss = 0.441292
I0923 20:53:33.301373 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:53:33.301373 14316 solver.cpp:237]     Train net output #1: loss = 0.441292 (* 1 = 0.441292 loss)
I0923 20:53:33.301373 14316 sgd_solver.cpp:105] Iteration 24000, lr = 1e-05
I0923 20:53:36.082094 14316 solver.cpp:218] Iteration 24100 (35.9651 iter/s, 2.78047s/100 iters), loss = 0.4662
I0923 20:53:36.082594 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:53:36.082594 14316 solver.cpp:237]     Train net output #1: loss = 0.4662 (* 1 = 0.4662 loss)
I0923 20:53:36.082594 14316 sgd_solver.cpp:105] Iteration 24100, lr = 1e-05
I0923 20:53:38.867076 14316 solver.cpp:218] Iteration 24200 (35.9137 iter/s, 2.78445s/100 iters), loss = 0.440862
I0923 20:53:38.867076 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:53:38.867076 14316 solver.cpp:237]     Train net output #1: loss = 0.440862 (* 1 = 0.440862 loss)
I0923 20:53:38.867076 14316 sgd_solver.cpp:105] Iteration 24200, lr = 1e-05
I0923 20:53:41.654263 14316 solver.cpp:218] Iteration 24300 (35.8842 iter/s, 2.78675s/100 iters), loss = 0.475994
I0923 20:53:41.654263 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:53:41.654263 14316 solver.cpp:237]     Train net output #1: loss = 0.475994 (* 1 = 0.475994 loss)
I0923 20:53:41.654263 14316 sgd_solver.cpp:105] Iteration 24300, lr = 1e-05
I0923 20:53:44.437211 14316 solver.cpp:218] Iteration 24400 (35.9397 iter/s, 2.78244s/100 iters), loss = 0.314358
I0923 20:53:44.437211 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:53:44.437211 14316 solver.cpp:237]     Train net output #1: loss = 0.314358 (* 1 = 0.314358 loss)
I0923 20:53:44.437211 14316 sgd_solver.cpp:105] Iteration 24400, lr = 1e-05
I0923 20:53:47.085273 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:53:47.220371 14316 solver.cpp:218] Iteration 24500 (35.9319 iter/s, 2.78304s/100 iters), loss = 0.451841
I0923 20:53:47.220371 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:53:47.220371 14316 solver.cpp:237]     Train net output #1: loss = 0.451841 (* 1 = 0.451841 loss)
I0923 20:53:47.220371 14316 sgd_solver.cpp:105] Iteration 24500, lr = 1e-05
I0923 20:53:49.999794 14316 solver.cpp:218] Iteration 24600 (35.9849 iter/s, 2.77895s/100 iters), loss = 0.384655
I0923 20:53:49.999794 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:53:49.999794 14316 solver.cpp:237]     Train net output #1: loss = 0.384655 (* 1 = 0.384655 loss)
I0923 20:53:49.999794 14316 sgd_solver.cpp:105] Iteration 24600, lr = 1e-05
I0923 20:53:52.817145 14316 solver.cpp:218] Iteration 24700 (35.4982 iter/s, 2.81705s/100 iters), loss = 0.35517
I0923 20:53:52.817145 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:53:52.817145 14316 solver.cpp:237]     Train net output #1: loss = 0.35517 (* 1 = 0.35517 loss)
I0923 20:53:52.817145 14316 sgd_solver.cpp:105] Iteration 24700, lr = 1e-05
I0923 20:53:55.612074 14316 solver.cpp:218] Iteration 24800 (35.7817 iter/s, 2.79472s/100 iters), loss = 0.505507
I0923 20:53:55.612074 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:53:55.612074 14316 solver.cpp:237]     Train net output #1: loss = 0.505507 (* 1 = 0.505507 loss)
I0923 20:53:55.612074 14316 sgd_solver.cpp:105] Iteration 24800, lr = 1e-05
I0923 20:53:58.395288 14316 solver.cpp:218] Iteration 24900 (35.9338 iter/s, 2.78289s/100 iters), loss = 0.368815
I0923 20:53:58.395288 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:53:58.395288 14316 solver.cpp:237]     Train net output #1: loss = 0.368815 (* 1 = 0.368815 loss)
I0923 20:53:58.395288 14316 sgd_solver.cpp:105] Iteration 24900, lr = 1e-05
I0923 20:54:01.044971 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:54:01.154551 14316 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/slimnet_simpnet_nogroupcon_iter_25000.caffemodel
I0923 20:54:01.162055 14316 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_simpnet_nogroupcon_iter_25000.solverstate
I0923 20:54:01.163056 14316 solver.cpp:330] Iteration 25000, Testing net (#0)
I0923 20:54:01.163056 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:54:01.686439 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:54:01.707443 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7907
I0923 20:54:01.707443 14316 solver.cpp:397]     Test net output #1: loss = 0.617882 (* 1 = 0.617882 loss)
I0923 20:54:01.733461 14316 solver.cpp:218] Iteration 25000 (29.9597 iter/s, 3.33782s/100 iters), loss = 0.40687
I0923 20:54:01.733461 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:54:01.733961 14316 solver.cpp:237]     Train net output #1: loss = 0.40687 (* 1 = 0.40687 loss)
I0923 20:54:01.733961 14316 sgd_solver.cpp:46] MultiStep Status: Iteration 25000, step = 4
I0923 20:54:01.733961 14316 sgd_solver.cpp:105] Iteration 25000, lr = 1e-06
I0923 20:54:04.528048 14316 solver.cpp:218] Iteration 25100 (35.792 iter/s, 2.79392s/100 iters), loss = 0.417727
I0923 20:54:04.528048 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:54:04.528048 14316 solver.cpp:237]     Train net output #1: loss = 0.417727 (* 1 = 0.417727 loss)
I0923 20:54:04.528048 14316 sgd_solver.cpp:105] Iteration 25100, lr = 1e-06
I0923 20:54:07.321044 14316 solver.cpp:218] Iteration 25200 (35.8075 iter/s, 2.79271s/100 iters), loss = 0.419664
I0923 20:54:07.321044 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:54:07.321044 14316 solver.cpp:237]     Train net output #1: loss = 0.419664 (* 1 = 0.419664 loss)
I0923 20:54:07.321044 14316 sgd_solver.cpp:105] Iteration 25200, lr = 1e-06
I0923 20:54:10.120774 14316 solver.cpp:218] Iteration 25300 (35.7244 iter/s, 2.7992s/100 iters), loss = 0.44635
I0923 20:54:10.120774 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:54:10.120774 14316 solver.cpp:237]     Train net output #1: loss = 0.44635 (* 1 = 0.44635 loss)
I0923 20:54:10.120774 14316 sgd_solver.cpp:105] Iteration 25300, lr = 1e-06
I0923 20:54:12.911259 14316 solver.cpp:218] Iteration 25400 (35.8419 iter/s, 2.79003s/100 iters), loss = 0.319646
I0923 20:54:12.911259 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:54:12.911259 14316 solver.cpp:237]     Train net output #1: loss = 0.319646 (* 1 = 0.319646 loss)
I0923 20:54:12.911259 14316 sgd_solver.cpp:105] Iteration 25400, lr = 1e-06
I0923 20:54:15.562594 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:54:15.698691 14316 solver.cpp:218] Iteration 25500 (35.8806 iter/s, 2.78702s/100 iters), loss = 0.46293
I0923 20:54:15.698691 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:54:15.698691 14316 solver.cpp:237]     Train net output #1: loss = 0.46293 (* 1 = 0.46293 loss)
I0923 20:54:15.698691 14316 sgd_solver.cpp:105] Iteration 25500, lr = 1e-06
I0923 20:54:18.490706 14316 solver.cpp:218] Iteration 25600 (35.8213 iter/s, 2.79163s/100 iters), loss = 0.413973
I0923 20:54:18.490706 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:54:18.490706 14316 solver.cpp:237]     Train net output #1: loss = 0.413973 (* 1 = 0.413973 loss)
I0923 20:54:18.490706 14316 sgd_solver.cpp:105] Iteration 25600, lr = 1e-06
I0923 20:54:21.278240 14316 solver.cpp:218] Iteration 25700 (35.8772 iter/s, 2.78729s/100 iters), loss = 0.385319
I0923 20:54:21.278240 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:54:21.278240 14316 solver.cpp:237]     Train net output #1: loss = 0.385319 (* 1 = 0.385319 loss)
I0923 20:54:21.278240 14316 sgd_solver.cpp:105] Iteration 25700, lr = 1e-06
I0923 20:54:24.067463 14316 solver.cpp:218] Iteration 25800 (35.8577 iter/s, 2.7888s/100 iters), loss = 0.474494
I0923 20:54:24.067463 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:54:24.067463 14316 solver.cpp:237]     Train net output #1: loss = 0.474494 (* 1 = 0.474494 loss)
I0923 20:54:24.067463 14316 sgd_solver.cpp:105] Iteration 25800, lr = 1e-06
I0923 20:54:26.855152 14316 solver.cpp:218] Iteration 25900 (35.8722 iter/s, 2.78767s/100 iters), loss = 0.318048
I0923 20:54:26.855653 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:54:26.855653 14316 solver.cpp:237]     Train net output #1: loss = 0.318048 (* 1 = 0.318048 loss)
I0923 20:54:26.855653 14316 sgd_solver.cpp:105] Iteration 25900, lr = 1e-06
I0923 20:54:29.511977 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:54:29.621572 14316 solver.cpp:330] Iteration 26000, Testing net (#0)
I0923 20:54:29.621572 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:54:30.144943 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:54:30.165441 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7905
I0923 20:54:30.165441 14316 solver.cpp:397]     Test net output #1: loss = 0.617898 (* 1 = 0.617898 loss)
I0923 20:54:30.190969 14316 solver.cpp:218] Iteration 26000 (29.9818 iter/s, 3.33535s/100 iters), loss = 0.415525
I0923 20:54:30.190969 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:54:30.190969 14316 solver.cpp:237]     Train net output #1: loss = 0.415525 (* 1 = 0.415525 loss)
I0923 20:54:30.190969 14316 sgd_solver.cpp:105] Iteration 26000, lr = 1e-06
I0923 20:54:32.976368 14316 solver.cpp:218] Iteration 26100 (35.9068 iter/s, 2.78499s/100 iters), loss = 0.419163
I0923 20:54:32.976368 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:54:32.976368 14316 solver.cpp:237]     Train net output #1: loss = 0.419163 (* 1 = 0.419163 loss)
I0923 20:54:32.976368 14316 sgd_solver.cpp:105] Iteration 26100, lr = 1e-06
I0923 20:54:35.758930 14316 solver.cpp:218] Iteration 26200 (35.9414 iter/s, 2.78231s/100 iters), loss = 0.386154
I0923 20:54:35.758930 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:54:35.758930 14316 solver.cpp:237]     Train net output #1: loss = 0.386154 (* 1 = 0.386154 loss)
I0923 20:54:35.758930 14316 sgd_solver.cpp:105] Iteration 26200, lr = 1e-06
I0923 20:54:38.551476 14316 solver.cpp:218] Iteration 26300 (35.8157 iter/s, 2.79208s/100 iters), loss = 0.444517
I0923 20:54:38.551476 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:54:38.551476 14316 solver.cpp:237]     Train net output #1: loss = 0.444517 (* 1 = 0.444517 loss)
I0923 20:54:38.551476 14316 sgd_solver.cpp:105] Iteration 26300, lr = 1e-06
I0923 20:54:41.345975 14316 solver.cpp:218] Iteration 26400 (35.7916 iter/s, 2.79395s/100 iters), loss = 0.31698
I0923 20:54:41.345975 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:54:41.345975 14316 solver.cpp:237]     Train net output #1: loss = 0.31698 (* 1 = 0.31698 loss)
I0923 20:54:41.345975 14316 sgd_solver.cpp:105] Iteration 26400, lr = 1e-06
I0923 20:54:43.999924 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:54:44.137014 14316 solver.cpp:218] Iteration 26500 (35.8331 iter/s, 2.79072s/100 iters), loss = 0.420524
I0923 20:54:44.137014 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:54:44.137014 14316 solver.cpp:237]     Train net output #1: loss = 0.420524 (* 1 = 0.420524 loss)
I0923 20:54:44.137014 14316 sgd_solver.cpp:105] Iteration 26500, lr = 1e-06
I0923 20:54:46.933239 14316 solver.cpp:218] Iteration 26600 (35.7662 iter/s, 2.79593s/100 iters), loss = 0.413497
I0923 20:54:46.933239 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:54:46.933239 14316 solver.cpp:237]     Train net output #1: loss = 0.413497 (* 1 = 0.413497 loss)
I0923 20:54:46.933239 14316 sgd_solver.cpp:105] Iteration 26600, lr = 1e-06
I0923 20:54:49.722718 14316 solver.cpp:218] Iteration 26700 (35.8549 iter/s, 2.78902s/100 iters), loss = 0.40768
I0923 20:54:49.722718 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:54:49.722718 14316 solver.cpp:237]     Train net output #1: loss = 0.40768 (* 1 = 0.40768 loss)
I0923 20:54:49.722718 14316 sgd_solver.cpp:105] Iteration 26700, lr = 1e-06
I0923 20:54:52.511315 14316 solver.cpp:218] Iteration 26800 (35.8614 iter/s, 2.78851s/100 iters), loss = 0.451277
I0923 20:54:52.511816 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:54:52.511816 14316 solver.cpp:237]     Train net output #1: loss = 0.451276 (* 1 = 0.451276 loss)
I0923 20:54:52.511816 14316 sgd_solver.cpp:105] Iteration 26800, lr = 1e-06
I0923 20:54:55.294559 14316 solver.cpp:218] Iteration 26900 (35.9364 iter/s, 2.78269s/100 iters), loss = 0.298781
I0923 20:54:55.294559 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:54:55.294559 14316 solver.cpp:237]     Train net output #1: loss = 0.298781 (* 1 = 0.298781 loss)
I0923 20:54:55.294559 14316 sgd_solver.cpp:105] Iteration 26900, lr = 1e-06
I0923 20:54:57.942538 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:54:58.052132 14316 solver.cpp:330] Iteration 27000, Testing net (#0)
I0923 20:54:58.052132 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:54:58.577033 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:54:58.598036 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7906
I0923 20:54:58.598036 14316 solver.cpp:397]     Test net output #1: loss = 0.61778 (* 1 = 0.61778 loss)
I0923 20:54:58.623554 14316 solver.cpp:218] Iteration 27000 (30.0408 iter/s, 3.32881s/100 iters), loss = 0.443559
I0923 20:54:58.624054 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:54:58.624054 14316 solver.cpp:237]     Train net output #1: loss = 0.443559 (* 1 = 0.443559 loss)
I0923 20:54:58.624054 14316 sgd_solver.cpp:105] Iteration 27000, lr = 1e-06
I0923 20:55:01.411962 14316 solver.cpp:218] Iteration 27100 (35.869 iter/s, 2.78792s/100 iters), loss = 0.44599
I0923 20:55:01.411962 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:55:01.411962 14316 solver.cpp:237]     Train net output #1: loss = 0.44599 (* 1 = 0.44599 loss)
I0923 20:55:01.411962 14316 sgd_solver.cpp:105] Iteration 27100, lr = 1e-06
I0923 20:55:04.195750 14316 solver.cpp:218] Iteration 27200 (35.9301 iter/s, 2.78318s/100 iters), loss = 0.389247
I0923 20:55:04.195750 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:55:04.195750 14316 solver.cpp:237]     Train net output #1: loss = 0.389247 (* 1 = 0.389247 loss)
I0923 20:55:04.195750 14316 sgd_solver.cpp:105] Iteration 27200, lr = 1e-06
I0923 20:55:06.983058 14316 solver.cpp:218] Iteration 27300 (35.8785 iter/s, 2.78718s/100 iters), loss = 0.483055
I0923 20:55:06.983058 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:55:06.983058 14316 solver.cpp:237]     Train net output #1: loss = 0.483055 (* 1 = 0.483055 loss)
I0923 20:55:06.983058 14316 sgd_solver.cpp:105] Iteration 27300, lr = 1e-06
I0923 20:55:09.779037 14316 solver.cpp:218] Iteration 27400 (35.7708 iter/s, 2.79558s/100 iters), loss = 0.326908
I0923 20:55:09.779037 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:55:09.779037 14316 solver.cpp:237]     Train net output #1: loss = 0.326908 (* 1 = 0.326908 loss)
I0923 20:55:09.779037 14316 sgd_solver.cpp:105] Iteration 27400, lr = 1e-06
I0923 20:55:12.431429 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:55:12.567026 14316 solver.cpp:218] Iteration 27500 (35.8727 iter/s, 2.78764s/100 iters), loss = 0.453717
I0923 20:55:12.567026 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:55:12.567026 14316 solver.cpp:237]     Train net output #1: loss = 0.453717 (* 1 = 0.453717 loss)
I0923 20:55:12.567026 14316 sgd_solver.cpp:105] Iteration 27500, lr = 1e-06
I0923 20:55:15.357681 14316 solver.cpp:218] Iteration 27600 (35.8423 iter/s, 2.79s/100 iters), loss = 0.415912
I0923 20:55:15.357681 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:55:15.357681 14316 solver.cpp:237]     Train net output #1: loss = 0.415912 (* 1 = 0.415912 loss)
I0923 20:55:15.357681 14316 sgd_solver.cpp:105] Iteration 27600, lr = 1e-06
I0923 20:55:18.145161 14316 solver.cpp:218] Iteration 27700 (35.877 iter/s, 2.7873s/100 iters), loss = 0.446805
I0923 20:55:18.145161 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:55:18.145161 14316 solver.cpp:237]     Train net output #1: loss = 0.446805 (* 1 = 0.446805 loss)
I0923 20:55:18.145161 14316 sgd_solver.cpp:105] Iteration 27700, lr = 1e-06
I0923 20:55:20.925947 14316 solver.cpp:218] Iteration 27800 (35.9667 iter/s, 2.78035s/100 iters), loss = 0.463753
I0923 20:55:20.925947 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:55:20.925947 14316 solver.cpp:237]     Train net output #1: loss = 0.463753 (* 1 = 0.463753 loss)
I0923 20:55:20.925947 14316 sgd_solver.cpp:105] Iteration 27800, lr = 1e-06
I0923 20:55:23.717929 14316 solver.cpp:218] Iteration 27900 (35.817 iter/s, 2.79197s/100 iters), loss = 0.345209
I0923 20:55:23.717929 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:55:23.717929 14316 solver.cpp:237]     Train net output #1: loss = 0.345209 (* 1 = 0.345209 loss)
I0923 20:55:23.718430 14316 sgd_solver.cpp:105] Iteration 27900, lr = 1e-06
I0923 20:55:26.374963 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:55:26.485059 14316 solver.cpp:330] Iteration 28000, Testing net (#0)
I0923 20:55:26.485559 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:55:27.007915 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:55:27.028429 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7905
I0923 20:55:27.028429 14316 solver.cpp:397]     Test net output #1: loss = 0.617897 (* 1 = 0.617897 loss)
I0923 20:55:27.054446 14316 solver.cpp:218] Iteration 28000 (29.9749 iter/s, 3.33612s/100 iters), loss = 0.403545
I0923 20:55:27.054446 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:55:27.054446 14316 solver.cpp:237]     Train net output #1: loss = 0.403545 (* 1 = 0.403545 loss)
I0923 20:55:27.054446 14316 sgd_solver.cpp:105] Iteration 28000, lr = 1e-06
I0923 20:55:29.845551 14316 solver.cpp:218] Iteration 28100 (35.8318 iter/s, 2.79081s/100 iters), loss = 0.379811
I0923 20:55:29.846051 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:55:29.846051 14316 solver.cpp:237]     Train net output #1: loss = 0.379811 (* 1 = 0.379811 loss)
I0923 20:55:29.846051 14316 sgd_solver.cpp:105] Iteration 28100, lr = 1e-06
I0923 20:55:32.639251 14316 solver.cpp:218] Iteration 28200 (35.8007 iter/s, 2.79324s/100 iters), loss = 0.42087
I0923 20:55:32.639251 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:55:32.639251 14316 solver.cpp:237]     Train net output #1: loss = 0.42087 (* 1 = 0.42087 loss)
I0923 20:55:32.639251 14316 sgd_solver.cpp:105] Iteration 28200, lr = 1e-06
I0923 20:55:35.422731 14316 solver.cpp:218] Iteration 28300 (35.932 iter/s, 2.78304s/100 iters), loss = 0.482973
I0923 20:55:35.422731 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:55:35.422731 14316 solver.cpp:237]     Train net output #1: loss = 0.482973 (* 1 = 0.482973 loss)
I0923 20:55:35.422731 14316 sgd_solver.cpp:105] Iteration 28300, lr = 1e-06
I0923 20:55:38.214689 14316 solver.cpp:218] Iteration 28400 (35.8243 iter/s, 2.7914s/100 iters), loss = 0.371012
I0923 20:55:38.214689 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:55:38.214689 14316 solver.cpp:237]     Train net output #1: loss = 0.371012 (* 1 = 0.371012 loss)
I0923 20:55:38.214689 14316 sgd_solver.cpp:105] Iteration 28400, lr = 1e-06
I0923 20:55:40.866585 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:55:41.004029 14316 solver.cpp:218] Iteration 28500 (35.8561 iter/s, 2.78893s/100 iters), loss = 0.401386
I0923 20:55:41.004029 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:55:41.004029 14316 solver.cpp:237]     Train net output #1: loss = 0.401386 (* 1 = 0.401386 loss)
I0923 20:55:41.004029 14316 sgd_solver.cpp:105] Iteration 28500, lr = 1e-06
I0923 20:55:43.790206 14316 solver.cpp:218] Iteration 28600 (35.8923 iter/s, 2.78611s/100 iters), loss = 0.438019
I0923 20:55:43.790206 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:55:43.790206 14316 solver.cpp:237]     Train net output #1: loss = 0.438019 (* 1 = 0.438019 loss)
I0923 20:55:43.790206 14316 sgd_solver.cpp:105] Iteration 28600, lr = 1e-06
I0923 20:55:46.575479 14316 solver.cpp:218] Iteration 28700 (35.9081 iter/s, 2.78489s/100 iters), loss = 0.38049
I0923 20:55:46.575479 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:55:46.575479 14316 solver.cpp:237]     Train net output #1: loss = 0.38049 (* 1 = 0.38049 loss)
I0923 20:55:46.575479 14316 sgd_solver.cpp:105] Iteration 28700, lr = 1e-06
I0923 20:55:49.362493 14316 solver.cpp:218] Iteration 28800 (35.8848 iter/s, 2.7867s/100 iters), loss = 0.45363
I0923 20:55:49.362493 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:55:49.362493 14316 solver.cpp:237]     Train net output #1: loss = 0.45363 (* 1 = 0.45363 loss)
I0923 20:55:49.362493 14316 sgd_solver.cpp:105] Iteration 28800, lr = 1e-06
I0923 20:55:52.149905 14316 solver.cpp:218] Iteration 28900 (35.8813 iter/s, 2.78697s/100 iters), loss = 0.331056
I0923 20:55:52.149905 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:55:52.149905 14316 solver.cpp:237]     Train net output #1: loss = 0.331055 (* 1 = 0.331055 loss)
I0923 20:55:52.149905 14316 sgd_solver.cpp:105] Iteration 28900, lr = 1e-06
I0923 20:55:54.803705 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:55:54.913784 14316 solver.cpp:330] Iteration 29000, Testing net (#0)
I0923 20:55:54.913784 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:55:55.439158 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:55:55.459172 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7906
I0923 20:55:55.459172 14316 solver.cpp:397]     Test net output #1: loss = 0.617792 (* 1 = 0.617792 loss)
I0923 20:55:55.485190 14316 solver.cpp:218] Iteration 29000 (29.9829 iter/s, 3.33524s/100 iters), loss = 0.476487
I0923 20:55:55.485692 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:55:55.485692 14316 solver.cpp:237]     Train net output #1: loss = 0.476487 (* 1 = 0.476487 loss)
I0923 20:55:55.485692 14316 sgd_solver.cpp:105] Iteration 29000, lr = 1e-06
I0923 20:55:58.275799 14316 solver.cpp:218] Iteration 29100 (35.8434 iter/s, 2.78991s/100 iters), loss = 0.433107
I0923 20:55:58.275799 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:55:58.275799 14316 solver.cpp:237]     Train net output #1: loss = 0.433107 (* 1 = 0.433107 loss)
I0923 20:55:58.275799 14316 sgd_solver.cpp:105] Iteration 29100, lr = 1e-06
I0923 20:56:01.064309 14316 solver.cpp:218] Iteration 29200 (35.8628 iter/s, 2.7884s/100 iters), loss = 0.35225
I0923 20:56:01.064309 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 20:56:01.064309 14316 solver.cpp:237]     Train net output #1: loss = 0.35225 (* 1 = 0.35225 loss)
I0923 20:56:01.064309 14316 sgd_solver.cpp:105] Iteration 29200, lr = 1e-06
I0923 20:56:03.849741 14316 solver.cpp:218] Iteration 29300 (35.9105 iter/s, 2.7847s/100 iters), loss = 0.470115
I0923 20:56:03.849741 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:56:03.849741 14316 solver.cpp:237]     Train net output #1: loss = 0.470115 (* 1 = 0.470115 loss)
I0923 20:56:03.849741 14316 sgd_solver.cpp:105] Iteration 29300, lr = 1e-06
I0923 20:56:06.586020 14316 solver.cpp:218] Iteration 29400 (36.5457 iter/s, 2.7363s/100 iters), loss = 0.342031
I0923 20:56:06.586020 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:56:06.586020 14316 solver.cpp:237]     Train net output #1: loss = 0.342031 (* 1 = 0.342031 loss)
I0923 20:56:06.586020 14316 sgd_solver.cpp:105] Iteration 29400, lr = 1e-06
I0923 20:56:09.240365 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:56:09.379017 14316 solver.cpp:218] Iteration 29500 (35.8066 iter/s, 2.79278s/100 iters), loss = 0.457136
I0923 20:56:09.379518 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:56:09.379518 14316 solver.cpp:237]     Train net output #1: loss = 0.457136 (* 1 = 0.457136 loss)
I0923 20:56:09.379518 14316 sgd_solver.cpp:105] Iteration 29500, lr = 1e-06
I0923 20:56:12.235208 14316 solver.cpp:218] Iteration 29600 (35.0199 iter/s, 2.85552s/100 iters), loss = 0.397904
I0923 20:56:12.235208 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:56:12.235208 14316 solver.cpp:237]     Train net output #1: loss = 0.397904 (* 1 = 0.397904 loss)
I0923 20:56:12.235208 14316 sgd_solver.cpp:105] Iteration 29600, lr = 1e-06
I0923 20:56:15.064282 14316 solver.cpp:218] Iteration 29700 (35.3513 iter/s, 2.82875s/100 iters), loss = 0.381956
I0923 20:56:15.064282 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:56:15.064282 14316 solver.cpp:237]     Train net output #1: loss = 0.381956 (* 1 = 0.381956 loss)
I0923 20:56:15.064282 14316 sgd_solver.cpp:105] Iteration 29700, lr = 1e-06
I0923 20:56:17.872344 14316 solver.cpp:218] Iteration 29800 (35.6143 iter/s, 2.80786s/100 iters), loss = 0.436219
I0923 20:56:17.872344 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:56:17.872344 14316 solver.cpp:237]     Train net output #1: loss = 0.436218 (* 1 = 0.436218 loss)
I0923 20:56:17.872344 14316 sgd_solver.cpp:105] Iteration 29800, lr = 1e-06
I0923 20:56:20.688040 14316 solver.cpp:218] Iteration 29900 (35.5196 iter/s, 2.81535s/100 iters), loss = 0.353048
I0923 20:56:20.688040 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:56:20.688040 14316 solver.cpp:237]     Train net output #1: loss = 0.353048 (* 1 = 0.353048 loss)
I0923 20:56:20.688539 14316 sgd_solver.cpp:105] Iteration 29900, lr = 1e-06
I0923 20:56:23.340430 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:56:23.450994 14316 solver.cpp:330] Iteration 30000, Testing net (#0)
I0923 20:56:23.450994 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:56:23.973865 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:56:23.994904 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7907
I0923 20:56:23.994904 14316 solver.cpp:397]     Test net output #1: loss = 0.617844 (* 1 = 0.617844 loss)
I0923 20:56:24.022400 14316 solver.cpp:218] Iteration 30000 (29.9945 iter/s, 3.33395s/100 iters), loss = 0.40774
I0923 20:56:24.022400 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:56:24.022400 14316 solver.cpp:237]     Train net output #1: loss = 0.40774 (* 1 = 0.40774 loss)
I0923 20:56:24.022400 14316 sgd_solver.cpp:105] Iteration 30000, lr = 1e-06
I0923 20:56:26.813051 14316 solver.cpp:218] Iteration 30100 (35.8399 iter/s, 2.79019s/100 iters), loss = 0.459126
I0923 20:56:26.813051 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:56:26.813051 14316 solver.cpp:237]     Train net output #1: loss = 0.459126 (* 1 = 0.459126 loss)
I0923 20:56:26.813051 14316 sgd_solver.cpp:105] Iteration 30100, lr = 1e-06
I0923 20:56:29.592478 14316 solver.cpp:218] Iteration 30200 (35.981 iter/s, 2.77924s/100 iters), loss = 0.39503
I0923 20:56:29.592478 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:56:29.592478 14316 solver.cpp:237]     Train net output #1: loss = 0.395029 (* 1 = 0.395029 loss)
I0923 20:56:29.592478 14316 sgd_solver.cpp:105] Iteration 30200, lr = 1e-06
I0923 20:56:32.377023 14316 solver.cpp:218] Iteration 30300 (35.9188 iter/s, 2.78406s/100 iters), loss = 0.476944
I0923 20:56:32.377023 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:56:32.377023 14316 solver.cpp:237]     Train net output #1: loss = 0.476944 (* 1 = 0.476944 loss)
I0923 20:56:32.377023 14316 sgd_solver.cpp:105] Iteration 30300, lr = 1e-06
I0923 20:56:35.159857 14316 solver.cpp:218] Iteration 30400 (35.9373 iter/s, 2.78263s/100 iters), loss = 0.329523
I0923 20:56:35.159857 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:56:35.159857 14316 solver.cpp:237]     Train net output #1: loss = 0.329523 (* 1 = 0.329523 loss)
I0923 20:56:35.159857 14316 sgd_solver.cpp:105] Iteration 30400, lr = 1e-06
I0923 20:56:37.806900 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:56:37.942495 14316 solver.cpp:218] Iteration 30500 (35.9408 iter/s, 2.78235s/100 iters), loss = 0.436624
I0923 20:56:37.942495 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:56:37.942495 14316 solver.cpp:237]     Train net output #1: loss = 0.436624 (* 1 = 0.436624 loss)
I0923 20:56:37.942495 14316 sgd_solver.cpp:105] Iteration 30500, lr = 1e-06
I0923 20:56:40.721163 14316 solver.cpp:218] Iteration 30600 (35.9972 iter/s, 2.778s/100 iters), loss = 0.396232
I0923 20:56:40.721163 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:56:40.721163 14316 solver.cpp:237]     Train net output #1: loss = 0.396232 (* 1 = 0.396232 loss)
I0923 20:56:40.721163 14316 sgd_solver.cpp:105] Iteration 30600, lr = 1e-06
I0923 20:56:43.499881 14316 solver.cpp:218] Iteration 30700 (35.9891 iter/s, 2.77862s/100 iters), loss = 0.399015
I0923 20:56:43.499881 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:56:43.499881 14316 solver.cpp:237]     Train net output #1: loss = 0.399015 (* 1 = 0.399015 loss)
I0923 20:56:43.499881 14316 sgd_solver.cpp:105] Iteration 30700, lr = 1e-06
I0923 20:56:46.286128 14316 solver.cpp:218] Iteration 30800 (35.8987 iter/s, 2.78562s/100 iters), loss = 0.447842
I0923 20:56:46.286128 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:56:46.286128 14316 solver.cpp:237]     Train net output #1: loss = 0.447842 (* 1 = 0.447842 loss)
I0923 20:56:46.286128 14316 sgd_solver.cpp:105] Iteration 30800, lr = 1e-06
I0923 20:56:49.074568 14316 solver.cpp:218] Iteration 30900 (35.8682 iter/s, 2.78798s/100 iters), loss = 0.290833
I0923 20:56:49.074568 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:56:49.074568 14316 solver.cpp:237]     Train net output #1: loss = 0.290833 (* 1 = 0.290833 loss)
I0923 20:56:49.074568 14316 sgd_solver.cpp:105] Iteration 30900, lr = 1e-06
I0923 20:56:51.723794 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:56:51.834373 14316 solver.cpp:330] Iteration 31000, Testing net (#0)
I0923 20:56:51.834373 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:56:52.357852 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:56:52.378366 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7909
I0923 20:56:52.378366 14316 solver.cpp:397]     Test net output #1: loss = 0.617758 (* 1 = 0.617758 loss)
I0923 20:56:52.404224 14316 solver.cpp:218] Iteration 31000 (30.0346 iter/s, 3.3295s/100 iters), loss = 0.404446
I0923 20:56:52.404224 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:56:52.404224 14316 solver.cpp:237]     Train net output #1: loss = 0.404446 (* 1 = 0.404446 loss)
I0923 20:56:52.404224 14316 sgd_solver.cpp:105] Iteration 31000, lr = 1e-06
I0923 20:56:55.183457 14316 solver.cpp:218] Iteration 31100 (35.9872 iter/s, 2.77877s/100 iters), loss = 0.39609
I0923 20:56:55.183457 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:56:55.183457 14316 solver.cpp:237]     Train net output #1: loss = 0.39609 (* 1 = 0.39609 loss)
I0923 20:56:55.183457 14316 sgd_solver.cpp:105] Iteration 31100, lr = 1e-06
I0923 20:56:57.958710 14316 solver.cpp:218] Iteration 31200 (36.0404 iter/s, 2.77466s/100 iters), loss = 0.436355
I0923 20:56:57.958710 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:56:57.958710 14316 solver.cpp:237]     Train net output #1: loss = 0.436355 (* 1 = 0.436355 loss)
I0923 20:56:57.958710 14316 sgd_solver.cpp:105] Iteration 31200, lr = 1e-06
I0923 20:57:00.737226 14316 solver.cpp:218] Iteration 31300 (35.9922 iter/s, 2.77838s/100 iters), loss = 0.444345
I0923 20:57:00.737226 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:57:00.737226 14316 solver.cpp:237]     Train net output #1: loss = 0.444345 (* 1 = 0.444345 loss)
I0923 20:57:00.737226 14316 sgd_solver.cpp:105] Iteration 31300, lr = 1e-06
I0923 20:57:03.515322 14316 solver.cpp:218] Iteration 31400 (36.0023 iter/s, 2.7776s/100 iters), loss = 0.338018
I0923 20:57:03.515322 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:57:03.515322 14316 solver.cpp:237]     Train net output #1: loss = 0.338018 (* 1 = 0.338018 loss)
I0923 20:57:03.515322 14316 sgd_solver.cpp:105] Iteration 31400, lr = 1e-06
I0923 20:57:06.162837 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:57:06.298425 14316 solver.cpp:218] Iteration 31500 (35.9336 iter/s, 2.78291s/100 iters), loss = 0.465379
I0923 20:57:06.298425 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:57:06.298425 14316 solver.cpp:237]     Train net output #1: loss = 0.465379 (* 1 = 0.465379 loss)
I0923 20:57:06.298425 14316 sgd_solver.cpp:105] Iteration 31500, lr = 1e-06
I0923 20:57:09.090665 14316 solver.cpp:218] Iteration 31600 (35.8161 iter/s, 2.79204s/100 iters), loss = 0.343678
I0923 20:57:09.090665 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:57:09.091166 14316 solver.cpp:237]     Train net output #1: loss = 0.343678 (* 1 = 0.343678 loss)
I0923 20:57:09.091166 14316 sgd_solver.cpp:105] Iteration 31600, lr = 1e-06
I0923 20:57:11.872758 14316 solver.cpp:218] Iteration 31700 (35.953 iter/s, 2.78141s/100 iters), loss = 0.441582
I0923 20:57:11.872758 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:57:11.872758 14316 solver.cpp:237]     Train net output #1: loss = 0.441582 (* 1 = 0.441582 loss)
I0923 20:57:11.872758 14316 sgd_solver.cpp:105] Iteration 31700, lr = 1e-06
I0923 20:57:14.655257 14316 solver.cpp:218] Iteration 31800 (35.941 iter/s, 2.78234s/100 iters), loss = 0.45263
I0923 20:57:14.655257 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:57:14.655257 14316 solver.cpp:237]     Train net output #1: loss = 0.45263 (* 1 = 0.45263 loss)
I0923 20:57:14.655257 14316 sgd_solver.cpp:105] Iteration 31800, lr = 1e-06
I0923 20:57:17.437762 14316 solver.cpp:218] Iteration 31900 (35.9469 iter/s, 2.78188s/100 iters), loss = 0.367796
I0923 20:57:17.437762 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:57:17.437762 14316 solver.cpp:237]     Train net output #1: loss = 0.367796 (* 1 = 0.367796 loss)
I0923 20:57:17.437762 14316 sgd_solver.cpp:105] Iteration 31900, lr = 1e-06
I0923 20:57:20.079085 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:57:20.188163 14316 solver.cpp:330] Iteration 32000, Testing net (#0)
I0923 20:57:20.188163 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:57:20.711035 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:57:20.731549 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7908
I0923 20:57:20.731549 14316 solver.cpp:397]     Test net output #1: loss = 0.617824 (* 1 = 0.617824 loss)
I0923 20:57:20.758069 14316 solver.cpp:218] Iteration 32000 (30.1216 iter/s, 3.31988s/100 iters), loss = 0.452406
I0923 20:57:20.758069 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:57:20.758069 14316 solver.cpp:237]     Train net output #1: loss = 0.452406 (* 1 = 0.452406 loss)
I0923 20:57:20.758069 14316 sgd_solver.cpp:105] Iteration 32000, lr = 1e-06
I0923 20:57:23.536589 14316 solver.cpp:218] Iteration 32100 (35.9932 iter/s, 2.7783s/100 iters), loss = 0.3272
I0923 20:57:23.536589 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 20:57:23.536589 14316 solver.cpp:237]     Train net output #1: loss = 0.3272 (* 1 = 0.3272 loss)
I0923 20:57:23.536589 14316 sgd_solver.cpp:105] Iteration 32100, lr = 1e-06
I0923 20:57:26.332562 14316 solver.cpp:218] Iteration 32200 (35.7704 iter/s, 2.79561s/100 iters), loss = 0.407592
I0923 20:57:26.332562 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0923 20:57:26.332562 14316 solver.cpp:237]     Train net output #1: loss = 0.407592 (* 1 = 0.407592 loss)
I0923 20:57:26.332562 14316 sgd_solver.cpp:105] Iteration 32200, lr = 1e-06
I0923 20:57:29.115015 14316 solver.cpp:218] Iteration 32300 (35.9444 iter/s, 2.78207s/100 iters), loss = 0.472115
I0923 20:57:29.115015 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:57:29.115015 14316 solver.cpp:237]     Train net output #1: loss = 0.472115 (* 1 = 0.472115 loss)
I0923 20:57:29.115015 14316 sgd_solver.cpp:105] Iteration 32300, lr = 1e-06
I0923 20:57:31.893813 14316 solver.cpp:218] Iteration 32400 (35.9915 iter/s, 2.77843s/100 iters), loss = 0.320735
I0923 20:57:31.893813 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:57:31.893813 14316 solver.cpp:237]     Train net output #1: loss = 0.320735 (* 1 = 0.320735 loss)
I0923 20:57:31.893813 14316 sgd_solver.cpp:105] Iteration 32400, lr = 1e-06
I0923 20:57:34.540318 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:57:34.675853 14316 solver.cpp:218] Iteration 32500 (35.9461 iter/s, 2.78195s/100 iters), loss = 0.409639
I0923 20:57:34.676342 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:57:34.676342 14316 solver.cpp:237]     Train net output #1: loss = 0.409639 (* 1 = 0.409639 loss)
I0923 20:57:34.676342 14316 sgd_solver.cpp:105] Iteration 32500, lr = 1e-06
I0923 20:57:37.456641 14316 solver.cpp:218] Iteration 32600 (35.9683 iter/s, 2.78023s/100 iters), loss = 0.37321
I0923 20:57:37.456641 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:57:37.456641 14316 solver.cpp:237]     Train net output #1: loss = 0.37321 (* 1 = 0.37321 loss)
I0923 20:57:37.456641 14316 sgd_solver.cpp:105] Iteration 32600, lr = 1e-06
I0923 20:57:40.239343 14316 solver.cpp:218] Iteration 32700 (35.9442 iter/s, 2.78209s/100 iters), loss = 0.463112
I0923 20:57:40.239343 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:57:40.239343 14316 solver.cpp:237]     Train net output #1: loss = 0.463112 (* 1 = 0.463112 loss)
I0923 20:57:40.239343 14316 sgd_solver.cpp:105] Iteration 32700, lr = 1e-06
I0923 20:57:43.021169 14316 solver.cpp:218] Iteration 32800 (35.9475 iter/s, 2.78183s/100 iters), loss = 0.469979
I0923 20:57:43.021169 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:57:43.021169 14316 solver.cpp:237]     Train net output #1: loss = 0.469979 (* 1 = 0.469979 loss)
I0923 20:57:43.021169 14316 sgd_solver.cpp:105] Iteration 32800, lr = 1e-06
I0923 20:57:45.796942 14316 solver.cpp:218] Iteration 32900 (36.032 iter/s, 2.77531s/100 iters), loss = 0.360789
I0923 20:57:45.796942 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:57:45.796942 14316 solver.cpp:237]     Train net output #1: loss = 0.360789 (* 1 = 0.360789 loss)
I0923 20:57:45.796942 14316 sgd_solver.cpp:105] Iteration 32900, lr = 1e-06
I0923 20:57:48.437327 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:57:48.546888 14316 solver.cpp:330] Iteration 33000, Testing net (#0)
I0923 20:57:48.546888 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:57:49.067258 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:57:49.088274 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7909
I0923 20:57:49.088274 14316 solver.cpp:397]     Test net output #1: loss = 0.617867 (* 1 = 0.617867 loss)
I0923 20:57:49.113808 14316 solver.cpp:218] Iteration 33000 (30.1511 iter/s, 3.31663s/100 iters), loss = 0.398005
I0923 20:57:49.113808 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:57:49.113808 14316 solver.cpp:237]     Train net output #1: loss = 0.398005 (* 1 = 0.398005 loss)
I0923 20:57:49.113808 14316 sgd_solver.cpp:105] Iteration 33000, lr = 1e-06
I0923 20:57:51.893278 14316 solver.cpp:218] Iteration 33100 (35.9823 iter/s, 2.77914s/100 iters), loss = 0.42136
I0923 20:57:51.893278 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:57:51.893278 14316 solver.cpp:237]     Train net output #1: loss = 0.42136 (* 1 = 0.42136 loss)
I0923 20:57:51.893278 14316 sgd_solver.cpp:105] Iteration 33100, lr = 1e-06
I0923 20:57:54.679715 14316 solver.cpp:218] Iteration 33200 (35.8924 iter/s, 2.7861s/100 iters), loss = 0.391842
I0923 20:57:54.679715 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 20:57:54.680217 14316 solver.cpp:237]     Train net output #1: loss = 0.391842 (* 1 = 0.391842 loss)
I0923 20:57:54.680217 14316 sgd_solver.cpp:105] Iteration 33200, lr = 1e-06
I0923 20:57:57.460731 14316 solver.cpp:218] Iteration 33300 (35.9669 iter/s, 2.78034s/100 iters), loss = 0.508654
I0923 20:57:57.460731 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:57:57.460731 14316 solver.cpp:237]     Train net output #1: loss = 0.508654 (* 1 = 0.508654 loss)
I0923 20:57:57.460731 14316 sgd_solver.cpp:105] Iteration 33300, lr = 1e-06
I0923 20:58:00.236938 14316 solver.cpp:218] Iteration 33400 (36.0226 iter/s, 2.77604s/100 iters), loss = 0.344801
I0923 20:58:00.236938 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:58:00.236938 14316 solver.cpp:237]     Train net output #1: loss = 0.344801 (* 1 = 0.344801 loss)
I0923 20:58:00.236938 14316 sgd_solver.cpp:105] Iteration 33400, lr = 1e-06
I0923 20:58:02.885241 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:58:03.022337 14316 solver.cpp:218] Iteration 33500 (35.9058 iter/s, 2.78506s/100 iters), loss = 0.422204
I0923 20:58:03.022337 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:58:03.022337 14316 solver.cpp:237]     Train net output #1: loss = 0.422204 (* 1 = 0.422204 loss)
I0923 20:58:03.022337 14316 sgd_solver.cpp:105] Iteration 33500, lr = 1e-06
I0923 20:58:05.809320 14316 solver.cpp:218] Iteration 33600 (35.8862 iter/s, 2.78658s/100 iters), loss = 0.384472
I0923 20:58:05.809320 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:58:05.809320 14316 solver.cpp:237]     Train net output #1: loss = 0.384472 (* 1 = 0.384472 loss)
I0923 20:58:05.809320 14316 sgd_solver.cpp:105] Iteration 33600, lr = 1e-06
I0923 20:58:08.598484 14316 solver.cpp:218] Iteration 33700 (35.8548 iter/s, 2.78903s/100 iters), loss = 0.436092
I0923 20:58:08.598986 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:58:08.598986 14316 solver.cpp:237]     Train net output #1: loss = 0.436092 (* 1 = 0.436092 loss)
I0923 20:58:08.598986 14316 sgd_solver.cpp:105] Iteration 33700, lr = 1e-06
I0923 20:58:11.397416 14316 solver.cpp:218] Iteration 33800 (35.7335 iter/s, 2.7985s/100 iters), loss = 0.407952
I0923 20:58:11.397416 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:58:11.397416 14316 solver.cpp:237]     Train net output #1: loss = 0.407951 (* 1 = 0.407951 loss)
I0923 20:58:11.397416 14316 sgd_solver.cpp:105] Iteration 33800, lr = 1e-06
I0923 20:58:14.212291 14316 solver.cpp:218] Iteration 33900 (35.534 iter/s, 2.8142s/100 iters), loss = 0.371125
I0923 20:58:14.212291 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:58:14.212291 14316 solver.cpp:237]     Train net output #1: loss = 0.371125 (* 1 = 0.371125 loss)
I0923 20:58:14.212291 14316 sgd_solver.cpp:105] Iteration 33900, lr = 1e-06
I0923 20:58:16.872717 10060 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:58:16.982796 14316 solver.cpp:330] Iteration 34000, Testing net (#0)
I0923 20:58:16.982796 14316 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:58:17.508669 15900 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:58:17.529184 14316 solver.cpp:397]     Test net output #0: accuracy = 0.7903
I0923 20:58:17.529184 14316 solver.cpp:397]     Test net output #1: loss = 0.617795 (* 1 = 0.617795 loss)
I0923 20:58:17.555718 14316 solver.cpp:218] Iteration 34000 (29.9097 iter/s, 3.3434s/100 iters), loss = 0.39444
I0923 20:58:17.555718 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:58:17.555718 14316 solver.cpp:237]     Train net output #1: loss = 0.39444 (* 1 = 0.39444 loss)
I0923 20:58:17.555718 14316 sgd_solver.cpp:105] Iteration 34000, lr = 1e-06
I0923 20:58:20.345863 14316 solver.cpp:218] Iteration 34100 (35.8495 iter/s, 2.78944s/100 iters), loss = 0.405572
I0923 20:58:20.345863 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:58:20.345863 14316 solver.cpp:237]     Train net output #1: loss = 0.405572 (* 1 = 0.405572 loss)
I0923 20:58:20.345863 14316 sgd_solver.cpp:105] Iteration 34100, lr = 1e-06
I0923 20:58:23.146755 14316 solver.cpp:218] Iteration 34200 (35.7066 iter/s, 2.8006s/100 iters), loss = 0.355529
I0923 20:58:23.146755 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0923 20:58:23.146755 14316 solver.cpp:237]     Train net output #1: loss = 0.355529 (* 1 = 0.355529 loss)
I0923 20:58:23.146755 14316 sgd_solver.cpp:105] Iteration 34200, lr = 1e-06
I0923 20:58:25.933814 14316 solver.cpp:218] Iteration 34300 (35.8826 iter/s, 2.78687s/100 iters), loss = 0.473444
I0923 20:58:25.933814 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:58:25.933814 14316 solver.cpp:237]     Train net output #1: loss = 0.473444 (* 1 = 0.473444 loss)
I0923 20:58:25.933814 14316 sgd_solver.cpp:105] Iteration 34300, lr = 1e-06
I0923 20:58:28.716589 14316 solver.cpp:218] Iteration 34400 (35.9377 iter/s, 2.7826s/100 iters), loss = 0.343426
I0923 20:58:28.716589 14316 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:58:28.716589 14316 solver.cpp:237]     Train net output #1: loss = 0.343426 (* 1 = 0.343426 loss)
I0923 20:58:28.716589 14316 sgd_solver.cpp:105] Iteration 34400, lr = 