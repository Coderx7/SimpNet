
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0923 20:28:11.261164 17252 caffe.cpp:219] Using GPUs 0
I0923 20:28:11.427254 17252 caffe.cpp:224] GPU 0: GeForce GTX 1080
I0923 20:28:11.706970 17252 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:28:11.722993 17252 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 50000
snapshot_prefix: "examples/cifar10/slimnet_simpnet_nogroupcon"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 25000
type: "Nesterov"
I0923 20:28:11.723994 17252 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:28:11.723994 17252 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:28:11.723994 17252 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I0923 20:28:11.724994 17252 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0923 20:28:11.724994 17252 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_NoGroupCon_NoDrp_noaug"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0923 20:28:11.725567 17252 layer_factory.cpp:58] Creating layer cifar
I0923 20:28:11.730022 17252 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0923 20:28:11.730022 17252 net.cpp:84] Creating Layer cifar
I0923 20:28:11.730022 17252 net.cpp:380] cifar -> data
I0923 20:28:11.730022 17252 net.cpp:380] cifar -> label
I0923 20:28:11.730022 17252 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0923 20:28:11.732022 17252 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:28:11.732022 17252 data_layer.cpp:45] output data size: 100,3,32,32
I0923 20:28:11.736830 17252 net.cpp:122] Setting up cifar
I0923 20:28:11.736830 17252 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0923 20:28:11.736830 17252 net.cpp:129] Top shape: 100 (100)
I0923 20:28:11.736830 17252 net.cpp:137] Memory required for data: 1229200
I0923 20:28:11.736830 17252 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0923 20:28:11.736830 17252 net.cpp:84] Creating Layer label_cifar_1_split
I0923 20:28:11.736830 17252 net.cpp:406] label_cifar_1_split <- label
I0923 20:28:11.736830 17252 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0923 20:28:11.736830 17252 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0923 20:28:11.736830 17252 net.cpp:122] Setting up label_cifar_1_split
I0923 20:28:11.736830 17252 net.cpp:129] Top shape: 100 (100)
I0923 20:28:11.736830 17252 net.cpp:129] Top shape: 100 (100)
I0923 20:28:11.736830 17252 net.cpp:137] Memory required for data: 1230000
I0923 20:28:11.736830 17252 layer_factory.cpp:58] Creating layer conv1
I0923 20:28:11.736830 17252 net.cpp:84] Creating Layer conv1
I0923 20:28:11.736830 17252 net.cpp:406] conv1 <- data
I0923 20:28:11.736830 17252 net.cpp:380] conv1 -> conv1
I0923 20:28:11.736830 17308 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:28:11.948642 17252 net.cpp:122] Setting up conv1
I0923 20:28:11.948642 17252 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:28:11.948642 17252 net.cpp:137] Memory required for data: 3687600
I0923 20:28:11.948642 17252 layer_factory.cpp:58] Creating layer bn1
I0923 20:28:11.948642 17252 net.cpp:84] Creating Layer bn1
I0923 20:28:11.948642 17252 net.cpp:406] bn1 <- conv1
I0923 20:28:11.948642 17252 net.cpp:367] bn1 -> conv1 (in-place)
I0923 20:28:11.948642 17252 net.cpp:122] Setting up bn1
I0923 20:28:11.948642 17252 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:28:11.948642 17252 net.cpp:137] Memory required for data: 6145200
I0923 20:28:11.948642 17252 layer_factory.cpp:58] Creating layer scale1
I0923 20:28:11.948642 17252 net.cpp:84] Creating Layer scale1
I0923 20:28:11.948642 17252 net.cpp:406] scale1 <- conv1
I0923 20:28:11.948642 17252 net.cpp:367] scale1 -> conv1 (in-place)
I0923 20:28:11.948642 17252 layer_factory.cpp:58] Creating layer scale1
I0923 20:28:11.948642 17252 net.cpp:122] Setting up scale1
I0923 20:28:11.948642 17252 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:28:11.948642 17252 net.cpp:137] Memory required for data: 8602800
I0923 20:28:11.948642 17252 layer_factory.cpp:58] Creating layer relu1
I0923 20:28:11.948642 17252 net.cpp:84] Creating Layer relu1
I0923 20:28:11.948642 17252 net.cpp:406] relu1 <- conv1
I0923 20:28:11.948642 17252 net.cpp:367] relu1 -> conv1 (in-place)
I0923 20:28:11.949642 17252 net.cpp:122] Setting up relu1
I0923 20:28:11.949642 17252 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:28:11.949642 17252 net.cpp:137] Memory required for data: 11060400
I0923 20:28:11.949642 17252 layer_factory.cpp:58] Creating layer conv1_0
I0923 20:28:11.949642 17252 net.cpp:84] Creating Layer conv1_0
I0923 20:28:11.949642 17252 net.cpp:406] conv1_0 <- conv1
I0923 20:28:11.949642 17252 net.cpp:380] conv1_0 -> conv1_0
I0923 20:28:11.950207 17252 net.cpp:122] Setting up conv1_0
I0923 20:28:11.950207 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.950207 17252 net.cpp:137] Memory required for data: 15975600
I0923 20:28:11.950207 17252 layer_factory.cpp:58] Creating layer bn1_0
I0923 20:28:11.950207 17252 net.cpp:84] Creating Layer bn1_0
I0923 20:28:11.950207 17252 net.cpp:406] bn1_0 <- conv1_0
I0923 20:28:11.950207 17252 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0923 20:28:11.950207 17252 net.cpp:122] Setting up bn1_0
I0923 20:28:11.950207 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.950207 17252 net.cpp:137] Memory required for data: 20890800
I0923 20:28:11.950207 17252 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:28:11.950207 17252 net.cpp:84] Creating Layer scale1_0
I0923 20:28:11.950207 17252 net.cpp:406] scale1_0 <- conv1_0
I0923 20:28:11.950207 17252 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0923 20:28:11.950207 17252 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:28:11.951210 17252 net.cpp:122] Setting up scale1_0
I0923 20:28:11.951210 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.951210 17252 net.cpp:137] Memory required for data: 25806000
I0923 20:28:11.951210 17252 layer_factory.cpp:58] Creating layer relu1_0
I0923 20:28:11.951210 17252 net.cpp:84] Creating Layer relu1_0
I0923 20:28:11.951210 17252 net.cpp:406] relu1_0 <- conv1_0
I0923 20:28:11.951210 17252 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0923 20:28:11.951210 17252 net.cpp:122] Setting up relu1_0
I0923 20:28:11.951210 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.951210 17252 net.cpp:137] Memory required for data: 30721200
I0923 20:28:11.951210 17252 layer_factory.cpp:58] Creating layer conv2
I0923 20:28:11.951210 17252 net.cpp:84] Creating Layer conv2
I0923 20:28:11.951210 17252 net.cpp:406] conv2 <- conv1_0
I0923 20:28:11.951210 17252 net.cpp:380] conv2 -> conv2
I0923 20:28:11.952210 17252 net.cpp:122] Setting up conv2
I0923 20:28:11.952210 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.952210 17252 net.cpp:137] Memory required for data: 35636400
I0923 20:28:11.952210 17252 layer_factory.cpp:58] Creating layer bn2
I0923 20:28:11.952210 17252 net.cpp:84] Creating Layer bn2
I0923 20:28:11.952210 17252 net.cpp:406] bn2 <- conv2
I0923 20:28:11.952210 17252 net.cpp:367] bn2 -> conv2 (in-place)
I0923 20:28:11.952210 17252 net.cpp:122] Setting up bn2
I0923 20:28:11.952210 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.952210 17252 net.cpp:137] Memory required for data: 40551600
I0923 20:28:11.952210 17252 layer_factory.cpp:58] Creating layer scale2
I0923 20:28:11.952210 17252 net.cpp:84] Creating Layer scale2
I0923 20:28:11.952210 17252 net.cpp:406] scale2 <- conv2
I0923 20:28:11.952210 17252 net.cpp:367] scale2 -> conv2 (in-place)
I0923 20:28:11.952210 17252 layer_factory.cpp:58] Creating layer scale2
I0923 20:28:11.952210 17252 net.cpp:122] Setting up scale2
I0923 20:28:11.952210 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.952210 17252 net.cpp:137] Memory required for data: 45466800
I0923 20:28:11.952210 17252 layer_factory.cpp:58] Creating layer relu2
I0923 20:28:11.952210 17252 net.cpp:84] Creating Layer relu2
I0923 20:28:11.952210 17252 net.cpp:406] relu2 <- conv2
I0923 20:28:11.952210 17252 net.cpp:367] relu2 -> conv2 (in-place)
I0923 20:28:11.953065 17252 net.cpp:122] Setting up relu2
I0923 20:28:11.953065 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.953065 17252 net.cpp:137] Memory required for data: 50382000
I0923 20:28:11.953065 17252 layer_factory.cpp:58] Creating layer conv2_1
I0923 20:28:11.953065 17252 net.cpp:84] Creating Layer conv2_1
I0923 20:28:11.953065 17252 net.cpp:406] conv2_1 <- conv2
I0923 20:28:11.953065 17252 net.cpp:380] conv2_1 -> conv2_1
I0923 20:28:11.953933 17252 net.cpp:122] Setting up conv2_1
I0923 20:28:11.953933 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.953933 17252 net.cpp:137] Memory required for data: 55297200
I0923 20:28:11.953933 17252 layer_factory.cpp:58] Creating layer bn2_1
I0923 20:28:11.953933 17252 net.cpp:84] Creating Layer bn2_1
I0923 20:28:11.953933 17252 net.cpp:406] bn2_1 <- conv2_1
I0923 20:28:11.953933 17252 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0923 20:28:11.953933 17252 net.cpp:122] Setting up bn2_1
I0923 20:28:11.953933 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.953933 17252 net.cpp:137] Memory required for data: 60212400
I0923 20:28:11.953933 17252 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:28:11.953933 17252 net.cpp:84] Creating Layer scale2_1
I0923 20:28:11.953933 17252 net.cpp:406] scale2_1 <- conv2_1
I0923 20:28:11.953933 17252 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0923 20:28:11.953933 17252 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:28:11.953933 17252 net.cpp:122] Setting up scale2_1
I0923 20:28:11.953933 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.953933 17252 net.cpp:137] Memory required for data: 65127600
I0923 20:28:11.953933 17252 layer_factory.cpp:58] Creating layer relu2_1
I0923 20:28:11.953933 17252 net.cpp:84] Creating Layer relu2_1
I0923 20:28:11.953933 17252 net.cpp:406] relu2_1 <- conv2_1
I0923 20:28:11.953933 17252 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0923 20:28:11.953933 17252 net.cpp:122] Setting up relu2_1
I0923 20:28:11.953933 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.953933 17252 net.cpp:137] Memory required for data: 70042800
I0923 20:28:11.953933 17252 layer_factory.cpp:58] Creating layer conv2_2
I0923 20:28:11.953933 17252 net.cpp:84] Creating Layer conv2_2
I0923 20:28:11.953933 17252 net.cpp:406] conv2_2 <- conv2_1
I0923 20:28:11.953933 17252 net.cpp:380] conv2_2 -> conv2_2
I0923 20:28:11.955437 17252 net.cpp:122] Setting up conv2_2
I0923 20:28:11.955437 17252 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:28:11.955437 17252 net.cpp:137] Memory required for data: 77825200
I0923 20:28:11.955437 17252 layer_factory.cpp:58] Creating layer bn2_2
I0923 20:28:11.955437 17252 net.cpp:84] Creating Layer bn2_2
I0923 20:28:11.955437 17252 net.cpp:406] bn2_2 <- conv2_2
I0923 20:28:11.955437 17252 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0923 20:28:11.955437 17252 net.cpp:122] Setting up bn2_2
I0923 20:28:11.955437 17252 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:28:11.955437 17252 net.cpp:137] Memory required for data: 85607600
I0923 20:28:11.955437 17252 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:28:11.955437 17252 net.cpp:84] Creating Layer scale2_2
I0923 20:28:11.955437 17252 net.cpp:406] scale2_2 <- conv2_2
I0923 20:28:11.955437 17252 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0923 20:28:11.955437 17252 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:28:11.955937 17252 net.cpp:122] Setting up scale2_2
I0923 20:28:11.955937 17252 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:28:11.955937 17252 net.cpp:137] Memory required for data: 93390000
I0923 20:28:11.955937 17252 layer_factory.cpp:58] Creating layer relu2_2
I0923 20:28:11.955937 17252 net.cpp:84] Creating Layer relu2_2
I0923 20:28:11.955937 17252 net.cpp:406] relu2_2 <- conv2_2
I0923 20:28:11.955937 17252 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0923 20:28:11.955937 17252 net.cpp:122] Setting up relu2_2
I0923 20:28:11.955937 17252 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:28:11.955937 17252 net.cpp:137] Memory required for data: 101172400
I0923 20:28:11.955937 17252 layer_factory.cpp:58] Creating layer pool2_1
I0923 20:28:11.955937 17252 net.cpp:84] Creating Layer pool2_1
I0923 20:28:11.955937 17252 net.cpp:406] pool2_1 <- conv2_2
I0923 20:28:11.955937 17252 net.cpp:380] pool2_1 -> pool2_1
I0923 20:28:11.955937 17252 net.cpp:122] Setting up pool2_1
I0923 20:28:11.955937 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.955937 17252 net.cpp:137] Memory required for data: 103118000
I0923 20:28:11.955937 17252 layer_factory.cpp:58] Creating layer conv3
I0923 20:28:11.955937 17252 net.cpp:84] Creating Layer conv3
I0923 20:28:11.955937 17252 net.cpp:406] conv3 <- pool2_1
I0923 20:28:11.955937 17252 net.cpp:380] conv3 -> conv3
I0923 20:28:11.956938 17252 net.cpp:122] Setting up conv3
I0923 20:28:11.956938 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.956938 17252 net.cpp:137] Memory required for data: 105063600
I0923 20:28:11.956938 17252 layer_factory.cpp:58] Creating layer bn3
I0923 20:28:11.956938 17252 net.cpp:84] Creating Layer bn3
I0923 20:28:11.956938 17252 net.cpp:406] bn3 <- conv3
I0923 20:28:11.957438 17252 net.cpp:367] bn3 -> conv3 (in-place)
I0923 20:28:11.957438 17252 net.cpp:122] Setting up bn3
I0923 20:28:11.957438 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.957438 17252 net.cpp:137] Memory required for data: 107009200
I0923 20:28:11.957438 17252 layer_factory.cpp:58] Creating layer scale3
I0923 20:28:11.957438 17252 net.cpp:84] Creating Layer scale3
I0923 20:28:11.957438 17252 net.cpp:406] scale3 <- conv3
I0923 20:28:11.957438 17252 net.cpp:367] scale3 -> conv3 (in-place)
I0923 20:28:11.957438 17252 layer_factory.cpp:58] Creating layer scale3
I0923 20:28:11.957438 17252 net.cpp:122] Setting up scale3
I0923 20:28:11.957438 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.957438 17252 net.cpp:137] Memory required for data: 108954800
I0923 20:28:11.957438 17252 layer_factory.cpp:58] Creating layer relu3
I0923 20:28:11.957438 17252 net.cpp:84] Creating Layer relu3
I0923 20:28:11.957438 17252 net.cpp:406] relu3 <- conv3
I0923 20:28:11.957438 17252 net.cpp:367] relu3 -> conv3 (in-place)
I0923 20:28:11.957939 17252 net.cpp:122] Setting up relu3
I0923 20:28:11.957939 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.957939 17252 net.cpp:137] Memory required for data: 110900400
I0923 20:28:11.957939 17252 layer_factory.cpp:58] Creating layer conv3_1
I0923 20:28:11.957939 17252 net.cpp:84] Creating Layer conv3_1
I0923 20:28:11.957939 17252 net.cpp:406] conv3_1 <- conv3
I0923 20:28:11.957939 17252 net.cpp:380] conv3_1 -> conv3_1
I0923 20:28:11.958940 17252 net.cpp:122] Setting up conv3_1
I0923 20:28:11.958940 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.958940 17252 net.cpp:137] Memory required for data: 112846000
I0923 20:28:11.958940 17252 layer_factory.cpp:58] Creating layer bn3_1
I0923 20:28:11.958940 17252 net.cpp:84] Creating Layer bn3_1
I0923 20:28:11.958940 17252 net.cpp:406] bn3_1 <- conv3_1
I0923 20:28:11.958940 17252 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I0923 20:28:11.958940 17252 net.cpp:122] Setting up bn3_1
I0923 20:28:11.958940 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.958940 17252 net.cpp:137] Memory required for data: 114791600
I0923 20:28:11.958940 17252 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:28:11.958940 17252 net.cpp:84] Creating Layer scale3_1
I0923 20:28:11.958940 17252 net.cpp:406] scale3_1 <- conv3_1
I0923 20:28:11.959439 17252 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I0923 20:28:11.959439 17252 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:28:11.959439 17252 net.cpp:122] Setting up scale3_1
I0923 20:28:11.959439 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.959439 17252 net.cpp:137] Memory required for data: 116737200
I0923 20:28:11.959439 17252 layer_factory.cpp:58] Creating layer relu3_1
I0923 20:28:11.959439 17252 net.cpp:84] Creating Layer relu3_1
I0923 20:28:11.959439 17252 net.cpp:406] relu3_1 <- conv3_1
I0923 20:28:11.959439 17252 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0923 20:28:11.959439 17252 net.cpp:122] Setting up relu3_1
I0923 20:28:11.959439 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.959439 17252 net.cpp:137] Memory required for data: 118682800
I0923 20:28:11.959439 17252 layer_factory.cpp:58] Creating layer conv4
I0923 20:28:11.959439 17252 net.cpp:84] Creating Layer conv4
I0923 20:28:11.959439 17252 net.cpp:406] conv4 <- conv3_1
I0923 20:28:11.959439 17252 net.cpp:380] conv4 -> conv4
I0923 20:28:11.960453 17252 net.cpp:122] Setting up conv4
I0923 20:28:11.960453 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.960453 17252 net.cpp:137] Memory required for data: 120628400
I0923 20:28:11.960453 17252 layer_factory.cpp:58] Creating layer bn4
I0923 20:28:11.960942 17252 net.cpp:84] Creating Layer bn4
I0923 20:28:11.960942 17252 net.cpp:406] bn4 <- conv4
I0923 20:28:11.960942 17252 net.cpp:367] bn4 -> conv4 (in-place)
I0923 20:28:11.960942 17252 net.cpp:122] Setting up bn4
I0923 20:28:11.960942 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.960942 17252 net.cpp:137] Memory required for data: 122574000
I0923 20:28:11.960942 17252 layer_factory.cpp:58] Creating layer scale4
I0923 20:28:11.960942 17252 net.cpp:84] Creating Layer scale4
I0923 20:28:11.960942 17252 net.cpp:406] scale4 <- conv4
I0923 20:28:11.960942 17252 net.cpp:367] scale4 -> conv4 (in-place)
I0923 20:28:11.960942 17252 layer_factory.cpp:58] Creating layer scale4
I0923 20:28:11.960942 17252 net.cpp:122] Setting up scale4
I0923 20:28:11.960942 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.960942 17252 net.cpp:137] Memory required for data: 124519600
I0923 20:28:11.960942 17252 layer_factory.cpp:58] Creating layer relu4
I0923 20:28:11.960942 17252 net.cpp:84] Creating Layer relu4
I0923 20:28:11.961441 17252 net.cpp:406] relu4 <- conv4
I0923 20:28:11.961441 17252 net.cpp:367] relu4 -> conv4 (in-place)
I0923 20:28:11.961441 17252 net.cpp:122] Setting up relu4
I0923 20:28:11.961441 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.961441 17252 net.cpp:137] Memory required for data: 126465200
I0923 20:28:11.961441 17252 layer_factory.cpp:58] Creating layer conv4_1
I0923 20:28:11.961441 17252 net.cpp:84] Creating Layer conv4_1
I0923 20:28:11.961441 17252 net.cpp:406] conv4_1 <- conv4
I0923 20:28:11.961941 17252 net.cpp:380] conv4_1 -> conv4_1
I0923 20:28:11.962443 17252 net.cpp:122] Setting up conv4_1
I0923 20:28:11.962443 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.962443 17252 net.cpp:137] Memory required for data: 128410800
I0923 20:28:11.962443 17252 layer_factory.cpp:58] Creating layer bn4_1
I0923 20:28:11.962443 17252 net.cpp:84] Creating Layer bn4_1
I0923 20:28:11.962443 17252 net.cpp:406] bn4_1 <- conv4_1
I0923 20:28:11.962443 17252 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0923 20:28:11.962443 17252 net.cpp:122] Setting up bn4_1
I0923 20:28:11.962443 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.962443 17252 net.cpp:137] Memory required for data: 130356400
I0923 20:28:11.962443 17252 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:28:11.962942 17252 net.cpp:84] Creating Layer scale4_1
I0923 20:28:11.962942 17252 net.cpp:406] scale4_1 <- conv4_1
I0923 20:28:11.962942 17252 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0923 20:28:11.962942 17252 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:28:11.962942 17252 net.cpp:122] Setting up scale4_1
I0923 20:28:11.962942 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.962942 17252 net.cpp:137] Memory required for data: 132302000
I0923 20:28:11.962942 17252 layer_factory.cpp:58] Creating layer relu4_1
I0923 20:28:11.962942 17252 net.cpp:84] Creating Layer relu4_1
I0923 20:28:11.962942 17252 net.cpp:406] relu4_1 <- conv4_1
I0923 20:28:11.962942 17252 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0923 20:28:11.963326 17252 net.cpp:122] Setting up relu4_1
I0923 20:28:11.963326 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.963326 17252 net.cpp:137] Memory required for data: 134247600
I0923 20:28:11.963326 17252 layer_factory.cpp:58] Creating layer conv4_2
I0923 20:28:11.963326 17252 net.cpp:84] Creating Layer conv4_2
I0923 20:28:11.963326 17252 net.cpp:406] conv4_2 <- conv4_1
I0923 20:28:11.963326 17252 net.cpp:380] conv4_2 -> conv4_2
I0923 20:28:11.964843 17252 net.cpp:122] Setting up conv4_2
I0923 20:28:11.964843 17252 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:28:11.964843 17252 net.cpp:137] Memory required for data: 137114800
I0923 20:28:11.964843 17252 layer_factory.cpp:58] Creating layer bn4_2
I0923 20:28:11.964843 17252 net.cpp:84] Creating Layer bn4_2
I0923 20:28:11.964843 17252 net.cpp:406] bn4_2 <- conv4_2
I0923 20:28:11.964843 17252 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0923 20:28:11.964843 17252 net.cpp:122] Setting up bn4_2
I0923 20:28:11.964843 17252 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:28:11.964843 17252 net.cpp:137] Memory required for data: 139982000
I0923 20:28:11.964843 17252 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:28:11.964843 17252 net.cpp:84] Creating Layer scale4_2
I0923 20:28:11.964843 17252 net.cpp:406] scale4_2 <- conv4_2
I0923 20:28:11.965359 17252 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0923 20:28:11.965359 17252 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:28:11.965359 17252 net.cpp:122] Setting up scale4_2
I0923 20:28:11.965359 17252 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:28:11.965359 17252 net.cpp:137] Memory required for data: 142849200
I0923 20:28:11.965359 17252 layer_factory.cpp:58] Creating layer relu4_2
I0923 20:28:11.965359 17252 net.cpp:84] Creating Layer relu4_2
I0923 20:28:11.965359 17252 net.cpp:406] relu4_2 <- conv4_2
I0923 20:28:11.965359 17252 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0923 20:28:11.965359 17252 net.cpp:122] Setting up relu4_2
I0923 20:28:11.965359 17252 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:28:11.965359 17252 net.cpp:137] Memory required for data: 145716400
I0923 20:28:11.965359 17252 layer_factory.cpp:58] Creating layer pool4_2
I0923 20:28:11.965359 17252 net.cpp:84] Creating Layer pool4_2
I0923 20:28:11.965359 17252 net.cpp:406] pool4_2 <- conv4_2
I0923 20:28:11.965359 17252 net.cpp:380] pool4_2 -> pool4_2
I0923 20:28:11.965859 17252 net.cpp:122] Setting up pool4_2
I0923 20:28:11.965859 17252 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:28:11.965859 17252 net.cpp:137] Memory required for data: 146433200
I0923 20:28:11.965859 17252 layer_factory.cpp:58] Creating layer conv4_0
I0923 20:28:11.965859 17252 net.cpp:84] Creating Layer conv4_0
I0923 20:28:11.965859 17252 net.cpp:406] conv4_0 <- pool4_2
I0923 20:28:11.965859 17252 net.cpp:380] conv4_0 -> conv4_0
I0923 20:28:11.966615 17252 net.cpp:122] Setting up conv4_0
I0923 20:28:11.966615 17252 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:28:11.966615 17252 net.cpp:137] Memory required for data: 147150000
I0923 20:28:11.966615 17252 layer_factory.cpp:58] Creating layer bn4_0
I0923 20:28:11.966615 17252 net.cpp:84] Creating Layer bn4_0
I0923 20:28:11.966615 17252 net.cpp:406] bn4_0 <- conv4_0
I0923 20:28:11.966615 17252 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0923 20:28:11.966615 17252 net.cpp:122] Setting up bn4_0
I0923 20:28:11.967116 17252 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:28:11.967116 17252 net.cpp:137] Memory required for data: 147866800
I0923 20:28:11.967116 17252 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:28:11.967116 17252 net.cpp:84] Creating Layer scale4_0
I0923 20:28:11.967116 17252 net.cpp:406] scale4_0 <- conv4_0
I0923 20:28:11.967116 17252 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0923 20:28:11.967116 17252 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:28:11.967116 17252 net.cpp:122] Setting up scale4_0
I0923 20:28:11.967116 17252 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:28:11.967116 17252 net.cpp:137] Memory required for data: 148583600
I0923 20:28:11.967116 17252 layer_factory.cpp:58] Creating layer relu4_0
I0923 20:28:11.967116 17252 net.cpp:84] Creating Layer relu4_0
I0923 20:28:11.967116 17252 net.cpp:406] relu4_0 <- conv4_0
I0923 20:28:11.967116 17252 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0923 20:28:11.967116 17252 net.cpp:122] Setting up relu4_0
I0923 20:28:11.967116 17252 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:28:11.967116 17252 net.cpp:137] Memory required for data: 149300400
I0923 20:28:11.967116 17252 layer_factory.cpp:58] Creating layer conv11
I0923 20:28:11.967116 17252 net.cpp:84] Creating Layer conv11
I0923 20:28:11.967116 17252 net.cpp:406] conv11 <- conv4_0
I0923 20:28:11.967116 17252 net.cpp:380] conv11 -> conv11
I0923 20:28:11.968117 17252 net.cpp:122] Setting up conv11
I0923 20:28:11.968117 17252 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:28:11.968117 17252 net.cpp:137] Memory required for data: 150196400
I0923 20:28:11.968117 17252 layer_factory.cpp:58] Creating layer bn_conv11
I0923 20:28:11.968117 17252 net.cpp:84] Creating Layer bn_conv11
I0923 20:28:11.968117 17252 net.cpp:406] bn_conv11 <- conv11
I0923 20:28:11.968117 17252 net.cpp:367] bn_conv11 -> conv11 (in-place)
I0923 20:28:11.968617 17252 net.cpp:122] Setting up bn_conv11
I0923 20:28:11.968617 17252 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:28:11.968617 17252 net.cpp:137] Memory required for data: 151092400
I0923 20:28:11.968617 17252 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:28:11.968617 17252 net.cpp:84] Creating Layer scale_conv11
I0923 20:28:11.968617 17252 net.cpp:406] scale_conv11 <- conv11
I0923 20:28:11.968617 17252 net.cpp:367] scale_conv11 -> conv11 (in-place)
I0923 20:28:11.968617 17252 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:28:11.968617 17252 net.cpp:122] Setting up scale_conv11
I0923 20:28:11.968617 17252 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:28:11.968617 17252 net.cpp:137] Memory required for data: 151988400
I0923 20:28:11.968617 17252 layer_factory.cpp:58] Creating layer relu_conv11
I0923 20:28:11.968617 17252 net.cpp:84] Creating Layer relu_conv11
I0923 20:28:11.968617 17252 net.cpp:406] relu_conv11 <- conv11
I0923 20:28:11.968617 17252 net.cpp:367] relu_conv11 -> conv11 (in-place)
I0923 20:28:11.969117 17252 net.cpp:122] Setting up relu_conv11
I0923 20:28:11.969117 17252 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:28:11.969117 17252 net.cpp:137] Memory required for data: 152884400
I0923 20:28:11.969117 17252 layer_factory.cpp:58] Creating layer conv12
I0923 20:28:11.969117 17252 net.cpp:84] Creating Layer conv12
I0923 20:28:11.969117 17252 net.cpp:406] conv12 <- conv11
I0923 20:28:11.969117 17252 net.cpp:380] conv12 -> conv12
I0923 20:28:11.969779 17252 net.cpp:122] Setting up conv12
I0923 20:28:11.969779 17252 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:28:11.970280 17252 net.cpp:137] Memory required for data: 153985200
I0923 20:28:11.970280 17252 layer_factory.cpp:58] Creating layer bn_conv12
I0923 20:28:11.970280 17252 net.cpp:84] Creating Layer bn_conv12
I0923 20:28:11.970280 17252 net.cpp:406] bn_conv12 <- conv12
I0923 20:28:11.970280 17252 net.cpp:367] bn_conv12 -> conv12 (in-place)
I0923 20:28:11.970280 17252 net.cpp:122] Setting up bn_conv12
I0923 20:28:11.970280 17252 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:28:11.970280 17252 net.cpp:137] Memory required for data: 155086000
I0923 20:28:11.970280 17252 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:28:11.970280 17252 net.cpp:84] Creating Layer scale_conv12
I0923 20:28:11.970280 17252 net.cpp:406] scale_conv12 <- conv12
I0923 20:28:11.970280 17252 net.cpp:367] scale_conv12 -> conv12 (in-place)
I0923 20:28:11.970280 17252 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:28:11.970280 17252 net.cpp:122] Setting up scale_conv12
I0923 20:28:11.970280 17252 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:28:11.970280 17252 net.cpp:137] Memory required for data: 156186800
I0923 20:28:11.970280 17252 layer_factory.cpp:58] Creating layer relu_conv12
I0923 20:28:11.970280 17252 net.cpp:84] Creating Layer relu_conv12
I0923 20:28:11.970280 17252 net.cpp:406] relu_conv12 <- conv12
I0923 20:28:11.970280 17252 net.cpp:367] relu_conv12 -> conv12 (in-place)
I0923 20:28:11.970782 17252 net.cpp:122] Setting up relu_conv12
I0923 20:28:11.970782 17252 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:28:11.970782 17252 net.cpp:137] Memory required for data: 157287600
I0923 20:28:11.970782 17252 layer_factory.cpp:58] Creating layer poolcp6
I0923 20:28:11.970782 17252 net.cpp:84] Creating Layer poolcp6
I0923 20:28:11.970782 17252 net.cpp:406] poolcp6 <- conv12
I0923 20:28:11.970782 17252 net.cpp:380] poolcp6 -> poolcp6
I0923 20:28:11.970782 17252 net.cpp:122] Setting up poolcp6
I0923 20:28:11.970782 17252 net.cpp:129] Top shape: 100 43 1 1 (4300)
I0923 20:28:11.970782 17252 net.cpp:137] Memory required for data: 157304800
I0923 20:28:11.970782 17252 layer_factory.cpp:58] Creating layer ip1
I0923 20:28:11.970782 17252 net.cpp:84] Creating Layer ip1
I0923 20:28:11.970782 17252 net.cpp:406] ip1 <- poolcp6
I0923 20:28:11.970782 17252 net.cpp:380] ip1 -> ip1
I0923 20:28:11.970782 17252 net.cpp:122] Setting up ip1
I0923 20:28:11.970782 17252 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:28:11.970782 17252 net.cpp:137] Memory required for data: 157308800
I0923 20:28:11.970782 17252 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0923 20:28:11.970782 17252 net.cpp:84] Creating Layer ip1_ip1_0_split
I0923 20:28:11.970782 17252 net.cpp:406] ip1_ip1_0_split <- ip1
I0923 20:28:11.970782 17252 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0923 20:28:11.970782 17252 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0923 20:28:11.970782 17252 net.cpp:122] Setting up ip1_ip1_0_split
I0923 20:28:11.970782 17252 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:28:11.970782 17252 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:28:11.970782 17252 net.cpp:137] Memory required for data: 157316800
I0923 20:28:11.970782 17252 layer_factory.cpp:58] Creating layer accuracy_training
I0923 20:28:11.970782 17252 net.cpp:84] Creating Layer accuracy_training
I0923 20:28:11.970782 17252 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0923 20:28:11.970782 17252 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I0923 20:28:11.970782 17252 net.cpp:380] accuracy_training -> accuracy_training
I0923 20:28:11.970782 17252 net.cpp:122] Setting up accuracy_training
I0923 20:28:11.970782 17252 net.cpp:129] Top shape: (1)
I0923 20:28:11.970782 17252 net.cpp:137] Memory required for data: 157316804
I0923 20:28:11.970782 17252 layer_factory.cpp:58] Creating layer loss
I0923 20:28:11.970782 17252 net.cpp:84] Creating Layer loss
I0923 20:28:11.970782 17252 net.cpp:406] loss <- ip1_ip1_0_split_1
I0923 20:28:11.970782 17252 net.cpp:406] loss <- label_cifar_1_split_1
I0923 20:28:11.970782 17252 net.cpp:380] loss -> loss
I0923 20:28:11.970782 17252 layer_factory.cpp:58] Creating layer loss
I0923 20:28:11.971582 17252 net.cpp:122] Setting up loss
I0923 20:28:11.971582 17252 net.cpp:129] Top shape: (1)
I0923 20:28:11.971582 17252 net.cpp:132]     with loss weight 1
I0923 20:28:11.971582 17252 net.cpp:137] Memory required for data: 157316808
I0923 20:28:11.971582 17252 net.cpp:198] loss needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:200] accuracy_training does not need backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] ip1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] poolcp6 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu_conv12 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale_conv12 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn_conv12 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv12 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu_conv11 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale_conv11 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn_conv11 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv11 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu4_0 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale4_0 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn4_0 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv4_0 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] pool4_2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu4_2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale4_2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn4_2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv4_2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu4_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale4_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn4_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv4_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu4 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale4 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn4 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv4 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu3_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale3_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn3_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv3_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu3 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale3 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn3 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv3 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] pool2_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu2_2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale2_2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn2_2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv2_2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu2_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale2_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn2_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv2_1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv2 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu1_0 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale1_0 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn1_0 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv1_0 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] relu1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] scale1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] bn1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:198] conv1 needs backward computation.
I0923 20:28:11.971582 17252 net.cpp:200] label_cifar_1_split does not need backward computation.
I0923 20:28:11.971582 17252 net.cpp:200] cifar does not need backward computation.
I0923 20:28:11.971582 17252 net.cpp:242] This network produces output accuracy_training
I0923 20:28:11.971582 17252 net.cpp:242] This network produces output loss
I0923 20:28:11.971582 17252 net.cpp:255] Network initialization done.
I0923 20:28:11.972584 17252 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:28:11.972584 17252 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0923 20:28:11.972584 17252 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I0923 20:28:11.972584 17252 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0923 20:28:11.972584 17252 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_NoGroupCon_NoDrp_noaug"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0923 20:28:11.973585 17252 layer_factory.cpp:58] Creating layer cifar
I0923 20:28:11.980211 17252 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0923 20:28:11.980211 17252 net.cpp:84] Creating Layer cifar
I0923 20:28:11.980211 17252 net.cpp:380] cifar -> data
I0923 20:28:11.980211 17252 net.cpp:380] cifar -> label
I0923 20:28:11.980211 17252 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0923 20:28:11.980211 17252 data_layer.cpp:45] output data size: 100,3,32,32
I0923 20:28:11.985249 17252 net.cpp:122] Setting up cifar
I0923 20:28:11.985249 17252 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0923 20:28:11.985249 17252 net.cpp:129] Top shape: 100 (100)
I0923 20:28:11.985249 17252 net.cpp:137] Memory required for data: 1229200
I0923 20:28:11.985249 17252 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0923 20:28:11.985249 17252 net.cpp:84] Creating Layer label_cifar_1_split
I0923 20:28:11.985249 17252 net.cpp:406] label_cifar_1_split <- label
I0923 20:28:11.985249 17252 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0923 20:28:11.985249 17252 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0923 20:28:11.986251 17252 net.cpp:122] Setting up label_cifar_1_split
I0923 20:28:11.986251 17252 net.cpp:129] Top shape: 100 (100)
I0923 20:28:11.986251 17252 net.cpp:129] Top shape: 100 (100)
I0923 20:28:11.986251 17252 net.cpp:137] Memory required for data: 1230000
I0923 20:28:11.986251 17252 layer_factory.cpp:58] Creating layer conv1
I0923 20:28:11.986251 17252 net.cpp:84] Creating Layer conv1
I0923 20:28:11.986251 17252 net.cpp:406] conv1 <- data
I0923 20:28:11.986251 17252 net.cpp:380] conv1 -> conv1
I0923 20:28:11.986251 17312 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:28:11.987251 17252 net.cpp:122] Setting up conv1
I0923 20:28:11.987251 17252 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:28:11.987251 17252 net.cpp:137] Memory required for data: 3687600
I0923 20:28:11.987251 17252 layer_factory.cpp:58] Creating layer bn1
I0923 20:28:11.987251 17252 net.cpp:84] Creating Layer bn1
I0923 20:28:11.987251 17252 net.cpp:406] bn1 <- conv1
I0923 20:28:11.987251 17252 net.cpp:367] bn1 -> conv1 (in-place)
I0923 20:28:11.987251 17252 net.cpp:122] Setting up bn1
I0923 20:28:11.987251 17252 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:28:11.987251 17252 net.cpp:137] Memory required for data: 6145200
I0923 20:28:11.987251 17252 layer_factory.cpp:58] Creating layer scale1
I0923 20:28:11.987251 17252 net.cpp:84] Creating Layer scale1
I0923 20:28:11.987251 17252 net.cpp:406] scale1 <- conv1
I0923 20:28:11.987251 17252 net.cpp:367] scale1 -> conv1 (in-place)
I0923 20:28:11.987251 17252 layer_factory.cpp:58] Creating layer scale1
I0923 20:28:11.987251 17252 net.cpp:122] Setting up scale1
I0923 20:28:11.987251 17252 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:28:11.987251 17252 net.cpp:137] Memory required for data: 8602800
I0923 20:28:11.987251 17252 layer_factory.cpp:58] Creating layer relu1
I0923 20:28:11.987251 17252 net.cpp:84] Creating Layer relu1
I0923 20:28:11.987251 17252 net.cpp:406] relu1 <- conv1
I0923 20:28:11.987251 17252 net.cpp:367] relu1 -> conv1 (in-place)
I0923 20:28:11.988252 17252 net.cpp:122] Setting up relu1
I0923 20:28:11.988252 17252 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:28:11.988252 17252 net.cpp:137] Memory required for data: 11060400
I0923 20:28:11.988252 17252 layer_factory.cpp:58] Creating layer conv1_0
I0923 20:28:11.988252 17252 net.cpp:84] Creating Layer conv1_0
I0923 20:28:11.988252 17252 net.cpp:406] conv1_0 <- conv1
I0923 20:28:11.988252 17252 net.cpp:380] conv1_0 -> conv1_0
I0923 20:28:11.989253 17252 net.cpp:122] Setting up conv1_0
I0923 20:28:11.989253 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.989253 17252 net.cpp:137] Memory required for data: 15975600
I0923 20:28:11.989253 17252 layer_factory.cpp:58] Creating layer bn1_0
I0923 20:28:11.989253 17252 net.cpp:84] Creating Layer bn1_0
I0923 20:28:11.989253 17252 net.cpp:406] bn1_0 <- conv1_0
I0923 20:28:11.989253 17252 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0923 20:28:11.989253 17252 net.cpp:122] Setting up bn1_0
I0923 20:28:11.989253 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.989253 17252 net.cpp:137] Memory required for data: 20890800
I0923 20:28:11.989253 17252 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:28:11.989253 17252 net.cpp:84] Creating Layer scale1_0
I0923 20:28:11.989253 17252 net.cpp:406] scale1_0 <- conv1_0
I0923 20:28:11.989253 17252 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0923 20:28:11.989253 17252 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:28:11.989253 17252 net.cpp:122] Setting up scale1_0
I0923 20:28:11.989253 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.989253 17252 net.cpp:137] Memory required for data: 25806000
I0923 20:28:11.989253 17252 layer_factory.cpp:58] Creating layer relu1_0
I0923 20:28:11.989253 17252 net.cpp:84] Creating Layer relu1_0
I0923 20:28:11.989253 17252 net.cpp:406] relu1_0 <- conv1_0
I0923 20:28:11.989253 17252 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0923 20:28:11.990254 17252 net.cpp:122] Setting up relu1_0
I0923 20:28:11.990254 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.990254 17252 net.cpp:137] Memory required for data: 30721200
I0923 20:28:11.990254 17252 layer_factory.cpp:58] Creating layer conv2
I0923 20:28:11.990254 17252 net.cpp:84] Creating Layer conv2
I0923 20:28:11.990254 17252 net.cpp:406] conv2 <- conv1_0
I0923 20:28:11.990254 17252 net.cpp:380] conv2 -> conv2
I0923 20:28:11.990952 17252 net.cpp:122] Setting up conv2
I0923 20:28:11.990952 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.990952 17252 net.cpp:137] Memory required for data: 35636400
I0923 20:28:11.990952 17252 layer_factory.cpp:58] Creating layer bn2
I0923 20:28:11.990952 17252 net.cpp:84] Creating Layer bn2
I0923 20:28:11.990952 17252 net.cpp:406] bn2 <- conv2
I0923 20:28:11.990952 17252 net.cpp:367] bn2 -> conv2 (in-place)
I0923 20:28:11.990952 17252 net.cpp:122] Setting up bn2
I0923 20:28:11.990952 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.990952 17252 net.cpp:137] Memory required for data: 40551600
I0923 20:28:11.990952 17252 layer_factory.cpp:58] Creating layer scale2
I0923 20:28:11.990952 17252 net.cpp:84] Creating Layer scale2
I0923 20:28:11.990952 17252 net.cpp:406] scale2 <- conv2
I0923 20:28:11.990952 17252 net.cpp:367] scale2 -> conv2 (in-place)
I0923 20:28:11.990952 17252 layer_factory.cpp:58] Creating layer scale2
I0923 20:28:11.990952 17252 net.cpp:122] Setting up scale2
I0923 20:28:11.990952 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.990952 17252 net.cpp:137] Memory required for data: 45466800
I0923 20:28:11.990952 17252 layer_factory.cpp:58] Creating layer relu2
I0923 20:28:11.990952 17252 net.cpp:84] Creating Layer relu2
I0923 20:28:11.990952 17252 net.cpp:406] relu2 <- conv2
I0923 20:28:11.990952 17252 net.cpp:367] relu2 -> conv2 (in-place)
I0923 20:28:11.991953 17252 net.cpp:122] Setting up relu2
I0923 20:28:11.991953 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.991953 17252 net.cpp:137] Memory required for data: 50382000
I0923 20:28:11.991953 17252 layer_factory.cpp:58] Creating layer conv2_1
I0923 20:28:11.991953 17252 net.cpp:84] Creating Layer conv2_1
I0923 20:28:11.991953 17252 net.cpp:406] conv2_1 <- conv2
I0923 20:28:11.991953 17252 net.cpp:380] conv2_1 -> conv2_1
I0923 20:28:11.992698 17252 net.cpp:122] Setting up conv2_1
I0923 20:28:11.992698 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.992698 17252 net.cpp:137] Memory required for data: 55297200
I0923 20:28:11.992698 17252 layer_factory.cpp:58] Creating layer bn2_1
I0923 20:28:11.992698 17252 net.cpp:84] Creating Layer bn2_1
I0923 20:28:11.992698 17252 net.cpp:406] bn2_1 <- conv2_1
I0923 20:28:11.992698 17252 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0923 20:28:11.992698 17252 net.cpp:122] Setting up bn2_1
I0923 20:28:11.992698 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.992698 17252 net.cpp:137] Memory required for data: 60212400
I0923 20:28:11.992698 17252 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:28:11.992698 17252 net.cpp:84] Creating Layer scale2_1
I0923 20:28:11.992698 17252 net.cpp:406] scale2_1 <- conv2_1
I0923 20:28:11.992698 17252 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0923 20:28:11.992698 17252 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:28:11.992698 17252 net.cpp:122] Setting up scale2_1
I0923 20:28:11.992698 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.992698 17252 net.cpp:137] Memory required for data: 65127600
I0923 20:28:11.992698 17252 layer_factory.cpp:58] Creating layer relu2_1
I0923 20:28:11.992698 17252 net.cpp:84] Creating Layer relu2_1
I0923 20:28:11.992698 17252 net.cpp:406] relu2_1 <- conv2_1
I0923 20:28:11.992698 17252 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0923 20:28:11.993700 17252 net.cpp:122] Setting up relu2_1
I0923 20:28:11.993700 17252 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:28:11.993700 17252 net.cpp:137] Memory required for data: 70042800
I0923 20:28:11.993700 17252 layer_factory.cpp:58] Creating layer conv2_2
I0923 20:28:11.993700 17252 net.cpp:84] Creating Layer conv2_2
I0923 20:28:11.993700 17252 net.cpp:406] conv2_2 <- conv2_1
I0923 20:28:11.993700 17252 net.cpp:380] conv2_2 -> conv2_2
I0923 20:28:11.994246 17252 net.cpp:122] Setting up conv2_2
I0923 20:28:11.994246 17252 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:28:11.994246 17252 net.cpp:137] Memory required for data: 77825200
I0923 20:28:11.994246 17252 layer_factory.cpp:58] Creating layer bn2_2
I0923 20:28:11.994246 17252 net.cpp:84] Creating Layer bn2_2
I0923 20:28:11.994246 17252 net.cpp:406] bn2_2 <- conv2_2
I0923 20:28:11.994246 17252 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0923 20:28:11.994246 17252 net.cpp:122] Setting up bn2_2
I0923 20:28:11.994246 17252 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:28:11.994246 17252 net.cpp:137] Memory required for data: 85607600
I0923 20:28:11.994246 17252 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:28:11.994246 17252 net.cpp:84] Creating Layer scale2_2
I0923 20:28:11.994246 17252 net.cpp:406] scale2_2 <- conv2_2
I0923 20:28:11.994246 17252 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0923 20:28:11.994246 17252 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:28:11.994246 17252 net.cpp:122] Setting up scale2_2
I0923 20:28:11.994246 17252 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:28:11.994246 17252 net.cpp:137] Memory required for data: 93390000
I0923 20:28:11.994246 17252 layer_factory.cpp:58] Creating layer relu2_2
I0923 20:28:11.994246 17252 net.cpp:84] Creating Layer relu2_2
I0923 20:28:11.994246 17252 net.cpp:406] relu2_2 <- conv2_2
I0923 20:28:11.994246 17252 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0923 20:28:11.995474 17252 net.cpp:122] Setting up relu2_2
I0923 20:28:11.995474 17252 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:28:11.995474 17252 net.cpp:137] Memory required for data: 101172400
I0923 20:28:11.995474 17252 layer_factory.cpp:58] Creating layer pool2_1
I0923 20:28:11.995474 17252 net.cpp:84] Creating Layer pool2_1
I0923 20:28:11.995474 17252 net.cpp:406] pool2_1 <- conv2_2
I0923 20:28:11.995474 17252 net.cpp:380] pool2_1 -> pool2_1
I0923 20:28:11.995474 17252 net.cpp:122] Setting up pool2_1
I0923 20:28:11.995474 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.995474 17252 net.cpp:137] Memory required for data: 103118000
I0923 20:28:11.995474 17252 layer_factory.cpp:58] Creating layer conv3
I0923 20:28:11.995474 17252 net.cpp:84] Creating Layer conv3
I0923 20:28:11.995474 17252 net.cpp:406] conv3 <- pool2_1
I0923 20:28:11.995474 17252 net.cpp:380] conv3 -> conv3
I0923 20:28:11.996476 17252 net.cpp:122] Setting up conv3
I0923 20:28:11.996476 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.996476 17252 net.cpp:137] Memory required for data: 105063600
I0923 20:28:11.996476 17252 layer_factory.cpp:58] Creating layer bn3
I0923 20:28:11.996476 17252 net.cpp:84] Creating Layer bn3
I0923 20:28:11.996476 17252 net.cpp:406] bn3 <- conv3
I0923 20:28:11.996476 17252 net.cpp:367] bn3 -> conv3 (in-place)
I0923 20:28:11.996476 17252 net.cpp:122] Setting up bn3
I0923 20:28:11.996476 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.996476 17252 net.cpp:137] Memory required for data: 107009200
I0923 20:28:11.996476 17252 layer_factory.cpp:58] Creating layer scale3
I0923 20:28:11.996476 17252 net.cpp:84] Creating Layer scale3
I0923 20:28:11.996476 17252 net.cpp:406] scale3 <- conv3
I0923 20:28:11.996476 17252 net.cpp:367] scale3 -> conv3 (in-place)
I0923 20:28:11.996476 17252 layer_factory.cpp:58] Creating layer scale3
I0923 20:28:11.996476 17252 net.cpp:122] Setting up scale3
I0923 20:28:11.996476 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.996476 17252 net.cpp:137] Memory required for data: 108954800
I0923 20:28:11.996476 17252 layer_factory.cpp:58] Creating layer relu3
I0923 20:28:11.996476 17252 net.cpp:84] Creating Layer relu3
I0923 20:28:11.996476 17252 net.cpp:406] relu3 <- conv3
I0923 20:28:11.996476 17252 net.cpp:367] relu3 -> conv3 (in-place)
I0923 20:28:11.996476 17252 net.cpp:122] Setting up relu3
I0923 20:28:11.996476 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.996476 17252 net.cpp:137] Memory required for data: 110900400
I0923 20:28:11.996476 17252 layer_factory.cpp:58] Creating layer conv3_1
I0923 20:28:11.996476 17252 net.cpp:84] Creating Layer conv3_1
I0923 20:28:11.996476 17252 net.cpp:406] conv3_1 <- conv3
I0923 20:28:11.996476 17252 net.cpp:380] conv3_1 -> conv3_1
I0923 20:28:11.998322 17252 net.cpp:122] Setting up conv3_1
I0923 20:28:11.998322 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.998322 17252 net.cpp:137] Memory required for data: 112846000
I0923 20:28:11.998322 17252 layer_factory.cpp:58] Creating layer bn3_1
I0923 20:28:11.998322 17252 net.cpp:84] Creating Layer bn3_1
I0923 20:28:11.998322 17252 net.cpp:406] bn3_1 <- conv3_1
I0923 20:28:11.998322 17252 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I0923 20:28:11.998322 17252 net.cpp:122] Setting up bn3_1
I0923 20:28:11.998322 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.998322 17252 net.cpp:137] Memory required for data: 114791600
I0923 20:28:11.998322 17252 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:28:11.998322 17252 net.cpp:84] Creating Layer scale3_1
I0923 20:28:11.998322 17252 net.cpp:406] scale3_1 <- conv3_1
I0923 20:28:11.998322 17252 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I0923 20:28:11.998322 17252 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:28:11.998322 17252 net.cpp:122] Setting up scale3_1
I0923 20:28:11.998322 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.998322 17252 net.cpp:137] Memory required for data: 116737200
I0923 20:28:11.998322 17252 layer_factory.cpp:58] Creating layer relu3_1
I0923 20:28:11.998322 17252 net.cpp:84] Creating Layer relu3_1
I0923 20:28:11.998322 17252 net.cpp:406] relu3_1 <- conv3_1
I0923 20:28:11.998322 17252 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0923 20:28:11.998322 17252 net.cpp:122] Setting up relu3_1
I0923 20:28:11.999325 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:11.999325 17252 net.cpp:137] Memory required for data: 118682800
I0923 20:28:11.999325 17252 layer_factory.cpp:58] Creating layer conv4
I0923 20:28:11.999325 17252 net.cpp:84] Creating Layer conv4
I0923 20:28:11.999325 17252 net.cpp:406] conv4 <- conv3_1
I0923 20:28:11.999325 17252 net.cpp:380] conv4 -> conv4
I0923 20:28:12.000329 17252 net.cpp:122] Setting up conv4
I0923 20:28:12.000329 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:12.000329 17252 net.cpp:137] Memory required for data: 120628400
I0923 20:28:12.000329 17252 layer_factory.cpp:58] Creating layer bn4
I0923 20:28:12.000329 17252 net.cpp:84] Creating Layer bn4
I0923 20:28:12.000329 17252 net.cpp:406] bn4 <- conv4
I0923 20:28:12.000329 17252 net.cpp:367] bn4 -> conv4 (in-place)
I0923 20:28:12.000329 17252 net.cpp:122] Setting up bn4
I0923 20:28:12.000329 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:12.000329 17252 net.cpp:137] Memory required for data: 122574000
I0923 20:28:12.000329 17252 layer_factory.cpp:58] Creating layer scale4
I0923 20:28:12.000329 17252 net.cpp:84] Creating Layer scale4
I0923 20:28:12.000329 17252 net.cpp:406] scale4 <- conv4
I0923 20:28:12.000329 17252 net.cpp:367] scale4 -> conv4 (in-place)
I0923 20:28:12.000329 17252 layer_factory.cpp:58] Creating layer scale4
I0923 20:28:12.000329 17252 net.cpp:122] Setting up scale4
I0923 20:28:12.000329 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:12.000329 17252 net.cpp:137] Memory required for data: 124519600
I0923 20:28:12.000329 17252 layer_factory.cpp:58] Creating layer relu4
I0923 20:28:12.000329 17252 net.cpp:84] Creating Layer relu4
I0923 20:28:12.000329 17252 net.cpp:406] relu4 <- conv4
I0923 20:28:12.000329 17252 net.cpp:367] relu4 -> conv4 (in-place)
I0923 20:28:12.000329 17252 net.cpp:122] Setting up relu4
I0923 20:28:12.000329 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:12.000329 17252 net.cpp:137] Memory required for data: 126465200
I0923 20:28:12.000329 17252 layer_factory.cpp:58] Creating layer conv4_1
I0923 20:28:12.000329 17252 net.cpp:84] Creating Layer conv4_1
I0923 20:28:12.000329 17252 net.cpp:406] conv4_1 <- conv4
I0923 20:28:12.000329 17252 net.cpp:380] conv4_1 -> conv4_1
I0923 20:28:12.002328 17252 net.cpp:122] Setting up conv4_1
I0923 20:28:12.002328 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:12.002328 17252 net.cpp:137] Memory required for data: 128410800
I0923 20:28:12.002328 17252 layer_factory.cpp:58] Creating layer bn4_1
I0923 20:28:12.002328 17252 net.cpp:84] Creating Layer bn4_1
I0923 20:28:12.002328 17252 net.cpp:406] bn4_1 <- conv4_1
I0923 20:28:12.002328 17252 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0923 20:28:12.002328 17252 net.cpp:122] Setting up bn4_1
I0923 20:28:12.002328 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:12.002328 17252 net.cpp:137] Memory required for data: 130356400
I0923 20:28:12.002328 17252 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:28:12.002328 17252 net.cpp:84] Creating Layer scale4_1
I0923 20:28:12.002328 17252 net.cpp:406] scale4_1 <- conv4_1
I0923 20:28:12.002328 17252 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0923 20:28:12.002328 17252 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:28:12.002328 17252 net.cpp:122] Setting up scale4_1
I0923 20:28:12.002328 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:12.002328 17252 net.cpp:137] Memory required for data: 132302000
I0923 20:28:12.002328 17252 layer_factory.cpp:58] Creating layer relu4_1
I0923 20:28:12.002328 17252 net.cpp:84] Creating Layer relu4_1
I0923 20:28:12.002328 17252 net.cpp:406] relu4_1 <- conv4_1
I0923 20:28:12.002328 17252 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0923 20:28:12.002328 17252 net.cpp:122] Setting up relu4_1
I0923 20:28:12.002328 17252 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:28:12.002328 17252 net.cpp:137] Memory required for data: 134247600
I0923 20:28:12.002328 17252 layer_factory.cpp:58] Creating layer conv4_2
I0923 20:28:12.002328 17252 net.cpp:84] Creating Layer conv4_2
I0923 20:28:12.002328 17252 net.cpp:406] conv4_2 <- conv4_1
I0923 20:28:12.002328 17252 net.cpp:380] conv4_2 -> conv4_2
I0923 20:28:12.004329 17252 net.cpp:122] Setting up conv4_2
I0923 20:28:12.004329 17252 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:28:12.004329 17252 net.cpp:137] Memory required for data: 137114800
I0923 20:28:12.004329 17252 layer_factory.cpp:58] Creating layer bn4_2
I0923 20:28:12.004329 17252 net.cpp:84] Creating Layer bn4_2
I0923 20:28:12.004329 17252 net.cpp:406] bn4_2 <- conv4_2
I0923 20:28:12.004329 17252 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0923 20:28:12.004329 17252 net.cpp:122] Setting up bn4_2
I0923 20:28:12.004329 17252 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:28:12.004329 17252 net.cpp:137] Memory required for data: 139982000
I0923 20:28:12.004329 17252 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:28:12.004329 17252 net.cpp:84] Creating Layer scale4_2
I0923 20:28:12.004329 17252 net.cpp:406] scale4_2 <- conv4_2
I0923 20:28:12.004329 17252 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0923 20:28:12.004329 17252 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:28:12.004329 17252 net.cpp:122] Setting up scale4_2
I0923 20:28:12.004329 17252 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:28:12.004329 17252 net.cpp:137] Memory required for data: 142849200
I0923 20:28:12.004329 17252 layer_factory.cpp:58] Creating layer relu4_2
I0923 20:28:12.004329 17252 net.cpp:84] Creating Layer relu4_2
I0923 20:28:12.004329 17252 net.cpp:406] relu4_2 <- conv4_2
I0923 20:28:12.004329 17252 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0923 20:28:12.005331 17252 net.cpp:122] Setting up relu4_2
I0923 20:28:12.005331 17252 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:28:12.005331 17252 net.cpp:137] Memory required for data: 145716400
I0923 20:28:12.005331 17252 layer_factory.cpp:58] Creating layer pool4_2
I0923 20:28:12.005331 17252 net.cpp:84] Creating Layer pool4_2
I0923 20:28:12.005331 17252 net.cpp:406] pool4_2 <- conv4_2
I0923 20:28:12.005331 17252 net.cpp:380] pool4_2 -> pool4_2
I0923 20:28:12.005331 17252 net.cpp:122] Setting up pool4_2
I0923 20:28:12.005331 17252 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:28:12.005331 17252 net.cpp:137] Memory required for data: 146433200
I0923 20:28:12.005331 17252 layer_factory.cpp:58] Creating layer conv4_0
I0923 20:28:12.005331 17252 net.cpp:84] Creating Layer conv4_0
I0923 20:28:12.005331 17252 net.cpp:406] conv4_0 <- pool4_2
I0923 20:28:12.005331 17252 net.cpp:380] conv4_0 -> conv4_0
I0923 20:28:12.006330 17252 net.cpp:122] Setting up conv4_0
I0923 20:28:12.006330 17252 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:28:12.006330 17252 net.cpp:137] Memory required for data: 147150000
I0923 20:28:12.006330 17252 layer_factory.cpp:58] Creating layer bn4_0
I0923 20:28:12.006330 17252 net.cpp:84] Creating Layer bn4_0
I0923 20:28:12.006330 17252 net.cpp:406] bn4_0 <- conv4_0
I0923 20:28:12.006330 17252 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0923 20:28:12.006330 17252 net.cpp:122] Setting up bn4_0
I0923 20:28:12.006330 17252 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:28:12.006330 17252 net.cpp:137] Memory required for data: 147866800
I0923 20:28:12.006330 17252 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:28:12.006330 17252 net.cpp:84] Creating Layer scale4_0
I0923 20:28:12.006330 17252 net.cpp:406] scale4_0 <- conv4_0
I0923 20:28:12.006330 17252 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0923 20:28:12.006330 17252 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:28:12.006330 17252 net.cpp:122] Setting up scale4_0
I0923 20:28:12.006330 17252 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:28:12.006330 17252 net.cpp:137] Memory required for data: 148583600
I0923 20:28:12.006330 17252 layer_factory.cpp:58] Creating layer relu4_0
I0923 20:28:12.006330 17252 net.cpp:84] Creating Layer relu4_0
I0923 20:28:12.006330 17252 net.cpp:406] relu4_0 <- conv4_0
I0923 20:28:12.007333 17252 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0923 20:28:12.007333 17252 net.cpp:122] Setting up relu4_0
I0923 20:28:12.007333 17252 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:28:12.007333 17252 net.cpp:137] Memory required for data: 149300400
I0923 20:28:12.007333 17252 layer_factory.cpp:58] Creating layer conv11
I0923 20:28:12.007333 17252 net.cpp:84] Creating Layer conv11
I0923 20:28:12.007333 17252 net.cpp:406] conv11 <- conv4_0
I0923 20:28:12.007333 17252 net.cpp:380] conv11 -> conv11
I0923 20:28:12.008332 17252 net.cpp:122] Setting up conv11
I0923 20:28:12.008332 17252 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:28:12.008332 17252 net.cpp:137] Memory required for data: 150196400
I0923 20:28:12.008332 17252 layer_factory.cpp:58] Creating layer bn_conv11
I0923 20:28:12.008332 17252 net.cpp:84] Creating Layer bn_conv11
I0923 20:28:12.008332 17252 net.cpp:406] bn_conv11 <- conv11
I0923 20:28:12.008332 17252 net.cpp:367] bn_conv11 -> conv11 (in-place)
I0923 20:28:12.008332 17252 net.cpp:122] Setting up bn_conv11
I0923 20:28:12.009332 17252 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:28:12.009332 17252 net.cpp:137] Memory required for data: 151092400
I0923 20:28:12.009332 17252 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:28:12.009332 17252 net.cpp:84] Creating Layer scale_conv11
I0923 20:28:12.009332 17252 net.cpp:406] scale_conv11 <- conv11
I0923 20:28:12.009332 17252 net.cpp:367] scale_conv11 -> conv11 (in-place)
I0923 20:28:12.009332 17252 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:28:12.009332 17252 net.cpp:122] Setting up scale_conv11
I0923 20:28:12.009332 17252 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:28:12.009332 17252 net.cpp:137] Memory required for data: 151988400
I0923 20:28:12.009332 17252 layer_factory.cpp:58] Creating layer relu_conv11
I0923 20:28:12.009332 17252 net.cpp:84] Creating Layer relu_conv11
I0923 20:28:12.009332 17252 net.cpp:406] relu_conv11 <- conv11
I0923 20:28:12.009332 17252 net.cpp:367] relu_conv11 -> conv11 (in-place)
I0923 20:28:12.010334 17252 net.cpp:122] Setting up relu_conv11
I0923 20:28:12.010334 17252 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:28:12.010334 17252 net.cpp:137] Memory required for data: 152884400
I0923 20:28:12.010334 17252 layer_factory.cpp:58] Creating layer conv12
I0923 20:28:12.010334 17252 net.cpp:84] Creating Layer conv12
I0923 20:28:12.010334 17252 net.cpp:406] conv12 <- conv11
I0923 20:28:12.010334 17252 net.cpp:380] conv12 -> conv12
I0923 20:28:12.011335 17252 net.cpp:122] Setting up conv12
I0923 20:28:12.011335 17252 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:28:12.011335 17252 net.cpp:137] Memory required for data: 153985200
I0923 20:28:12.011335 17252 layer_factory.cpp:58] Creating layer bn_conv12
I0923 20:28:12.011335 17252 net.cpp:84] Creating Layer bn_conv12
I0923 20:28:12.011335 17252 net.cpp:406] bn_conv12 <- conv12
I0923 20:28:12.011335 17252 net.cpp:367] bn_conv12 -> conv12 (in-place)
I0923 20:28:12.011335 17252 net.cpp:122] Setting up bn_conv12
I0923 20:28:12.011335 17252 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:28:12.011335 17252 net.cpp:137] Memory required for data: 155086000
I0923 20:28:12.011335 17252 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:28:12.011335 17252 net.cpp:84] Creating Layer scale_conv12
I0923 20:28:12.011335 17252 net.cpp:406] scale_conv12 <- conv12
I0923 20:28:12.011335 17252 net.cpp:367] scale_conv12 -> conv12 (in-place)
I0923 20:28:12.011335 17252 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:28:12.011335 17252 net.cpp:122] Setting up scale_conv12
I0923 20:28:12.011335 17252 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:28:12.011335 17252 net.cpp:137] Memory required for data: 156186800
I0923 20:28:12.011335 17252 layer_factory.cpp:58] Creating layer relu_conv12
I0923 20:28:12.011335 17252 net.cpp:84] Creating Layer relu_conv12
I0923 20:28:12.011335 17252 net.cpp:406] relu_conv12 <- conv12
I0923 20:28:12.012336 17252 net.cpp:367] relu_conv12 -> conv12 (in-place)
I0923 20:28:12.012336 17252 net.cpp:122] Setting up relu_conv12
I0923 20:28:12.012336 17252 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:28:12.012336 17252 net.cpp:137] Memory required for data: 157287600
I0923 20:28:12.012336 17252 layer_factory.cpp:58] Creating layer poolcp6
I0923 20:28:12.012336 17252 net.cpp:84] Creating Layer poolcp6
I0923 20:28:12.012336 17252 net.cpp:406] poolcp6 <- conv12
I0923 20:28:12.012336 17252 net.cpp:380] poolcp6 -> poolcp6
I0923 20:28:12.012336 17252 net.cpp:122] Setting up poolcp6
I0923 20:28:12.012336 17252 net.cpp:129] Top shape: 100 43 1 1 (4300)
I0923 20:28:12.012336 17252 net.cpp:137] Memory required for data: 157304800
I0923 20:28:12.012336 17252 layer_factory.cpp:58] Creating layer ip1
I0923 20:28:12.012336 17252 net.cpp:84] Creating Layer ip1
I0923 20:28:12.012336 17252 net.cpp:406] ip1 <- poolcp6
I0923 20:28:12.012336 17252 net.cpp:380] ip1 -> ip1
I0923 20:28:12.012336 17252 net.cpp:122] Setting up ip1
I0923 20:28:12.012336 17252 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:28:12.012336 17252 net.cpp:137] Memory required for data: 157308800
I0923 20:28:12.012336 17252 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0923 20:28:12.012336 17252 net.cpp:84] Creating Layer ip1_ip1_0_split
I0923 20:28:12.012336 17252 net.cpp:406] ip1_ip1_0_split <- ip1
I0923 20:28:12.012336 17252 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0923 20:28:12.012336 17252 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0923 20:28:12.012336 17252 net.cpp:122] Setting up ip1_ip1_0_split
I0923 20:28:12.012336 17252 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:28:12.012336 17252 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:28:12.012336 17252 net.cpp:137] Memory required for data: 157316800
I0923 20:28:12.012336 17252 layer_factory.cpp:58] Creating layer accuracy
I0923 20:28:12.012336 17252 net.cpp:84] Creating Layer accuracy
I0923 20:28:12.012336 17252 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0923 20:28:12.012336 17252 net.cpp:406] accuracy <- label_cifar_1_split_0
I0923 20:28:12.012336 17252 net.cpp:380] accuracy -> accuracy
I0923 20:28:12.012336 17252 net.cpp:122] Setting up accuracy
I0923 20:28:12.012336 17252 net.cpp:129] Top shape: (1)
I0923 20:28:12.012336 17252 net.cpp:137] Memory required for data: 157316804
I0923 20:28:12.012336 17252 layer_factory.cpp:58] Creating layer loss
I0923 20:28:12.012336 17252 net.cpp:84] Creating Layer loss
I0923 20:28:12.012336 17252 net.cpp:406] loss <- ip1_ip1_0_split_1
I0923 20:28:12.012336 17252 net.cpp:406] loss <- label_cifar_1_split_1
I0923 20:28:12.012336 17252 net.cpp:380] loss -> loss
I0923 20:28:12.012336 17252 layer_factory.cpp:58] Creating layer loss
I0923 20:28:12.013336 17252 net.cpp:122] Setting up loss
I0923 20:28:12.013336 17252 net.cpp:129] Top shape: (1)
I0923 20:28:12.013336 17252 net.cpp:132]     with loss weight 1
I0923 20:28:12.013336 17252 net.cpp:137] Memory required for data: 157316808
I0923 20:28:12.013336 17252 net.cpp:198] loss needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:200] accuracy does not need backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] ip1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] poolcp6 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu_conv12 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale_conv12 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn_conv12 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv12 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu_conv11 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale_conv11 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn_conv11 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv11 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu4_0 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale4_0 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn4_0 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv4_0 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] pool4_2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu4_2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale4_2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn4_2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv4_2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu4_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale4_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn4_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv4_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu4 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale4 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn4 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv4 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu3_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale3_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn3_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv3_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu3 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale3 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn3 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv3 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] pool2_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu2_2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale2_2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn2_2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv2_2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu2_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale2_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn2_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv2_1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv2 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu1_0 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale1_0 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn1_0 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv1_0 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] relu1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] scale1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] bn1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:198] conv1 needs backward computation.
I0923 20:28:12.013336 17252 net.cpp:200] label_cifar_1_split does not need backward computation.
I0923 20:28:12.013336 17252 net.cpp:200] cifar does not need backward computation.
I0923 20:28:12.013336 17252 net.cpp:242] This network produces output accuracy
I0923 20:28:12.013336 17252 net.cpp:242] This network produces output loss
I0923 20:28:12.013336 17252 net.cpp:255] Network initialization done.
I0923 20:28:12.014338 17252 solver.cpp:56] Solver scaffolding done.
I0923 20:28:12.016350 17252 caffe.cpp:249] Starting Optimization
I0923 20:28:12.016350 17252 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_drpall_Simple_NoGroupCon_NoDrp_noaug
I0923 20:28:12.016350 17252 solver.cpp:273] Learning Rate Policy: multistep
I0923 20:28:12.018030 17252 solver.cpp:330] Iteration 0, Testing net (#0)
I0923 20:28:12.020045 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:28:12.572175 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:28:12.592188 17252 solver.cpp:397]     Test net output #0: accuracy = 0.0937
I0923 20:28:12.592188 17252 solver.cpp:397]     Test net output #1: loss = 79.1531 (* 1 = 79.1531 loss)
I0923 20:28:12.642349 17252 solver.cpp:218] Iteration 0 (-4.39223e-41 iter/s, 0.624039s/100 iters), loss = 3.76685
I0923 20:28:12.642349 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I0923 20:28:12.642349 17252 solver.cpp:237]     Train net output #1: loss = 3.76685 (* 1 = 3.76685 loss)
I0923 20:28:12.642349 17252 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0923 20:28:15.405179 17252 solver.cpp:218] Iteration 100 (36.2028 iter/s, 2.76222s/100 iters), loss = 1.68671
I0923 20:28:15.405179 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I0923 20:28:15.405179 17252 solver.cpp:237]     Train net output #1: loss = 1.68671 (* 1 = 1.68671 loss)
I0923 20:28:15.405179 17252 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0923 20:28:18.160986 17252 solver.cpp:218] Iteration 200 (36.2889 iter/s, 2.75567s/100 iters), loss = 1.84611
I0923 20:28:18.161487 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I0923 20:28:18.161487 17252 solver.cpp:237]     Train net output #1: loss = 1.84611 (* 1 = 1.84611 loss)
I0923 20:28:18.161487 17252 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0923 20:28:20.960355 17252 solver.cpp:218] Iteration 300 (35.725 iter/s, 2.79916s/100 iters), loss = 1.46352
I0923 20:28:20.960355 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I0923 20:28:20.960355 17252 solver.cpp:237]     Train net output #1: loss = 1.46352 (* 1 = 1.46352 loss)
I0923 20:28:20.960355 17252 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0923 20:28:23.810231 17252 solver.cpp:218] Iteration 400 (35.0892 iter/s, 2.84988s/100 iters), loss = 1.37012
I0923 20:28:23.811215 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I0923 20:28:23.811215 17252 solver.cpp:237]     Train net output #1: loss = 1.37012 (* 1 = 1.37012 loss)
I0923 20:28:23.811215 17252 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0923 20:28:26.422967 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:28:26.557113 17252 solver.cpp:218] Iteration 500 (36.4203 iter/s, 2.74572s/100 iters), loss = 1.51382
I0923 20:28:26.557113 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I0923 20:28:26.557113 17252 solver.cpp:237]     Train net output #1: loss = 1.51382 (* 1 = 1.51382 loss)
I0923 20:28:26.557113 17252 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0923 20:28:29.318629 17252 solver.cpp:218] Iteration 600 (36.2109 iter/s, 2.7616s/100 iters), loss = 1.38488
I0923 20:28:29.318629 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I0923 20:28:29.318629 17252 solver.cpp:237]     Train net output #1: loss = 1.38488 (* 1 = 1.38488 loss)
I0923 20:28:29.318629 17252 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0923 20:28:32.108983 17252 solver.cpp:218] Iteration 700 (35.8442 iter/s, 2.78985s/100 iters), loss = 1.49547
I0923 20:28:32.108983 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I0923 20:28:32.108983 17252 solver.cpp:237]     Train net output #1: loss = 1.49547 (* 1 = 1.49547 loss)
I0923 20:28:32.108983 17252 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0923 20:28:34.840883 17252 solver.cpp:218] Iteration 800 (36.6117 iter/s, 2.73137s/100 iters), loss = 1.29033
I0923 20:28:34.840883 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I0923 20:28:34.840883 17252 solver.cpp:237]     Train net output #1: loss = 1.29033 (* 1 = 1.29033 loss)
I0923 20:28:34.840883 17252 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0923 20:28:37.657622 17252 solver.cpp:218] Iteration 900 (35.5007 iter/s, 2.81684s/100 iters), loss = 1.26155
I0923 20:28:37.657622 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I0923 20:28:37.657622 17252 solver.cpp:237]     Train net output #1: loss = 1.26155 (* 1 = 1.26155 loss)
I0923 20:28:37.657622 17252 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0923 20:28:40.311709 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:28:40.423625 17252 solver.cpp:330] Iteration 1000, Testing net (#0)
I0923 20:28:40.423625 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:28:40.946116 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:28:40.966145 17252 solver.cpp:397]     Test net output #0: accuracy = 0.5163
I0923 20:28:40.966145 17252 solver.cpp:397]     Test net output #1: loss = 1.3514 (* 1 = 1.3514 loss)
I0923 20:28:40.992184 17252 solver.cpp:218] Iteration 1000 (29.9957 iter/s, 3.33381s/100 iters), loss = 1.37254
I0923 20:28:40.992184 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I0923 20:28:40.992184 17252 solver.cpp:237]     Train net output #1: loss = 1.37254 (* 1 = 1.37254 loss)
I0923 20:28:40.992184 17252 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0923 20:28:43.748128 17252 solver.cpp:218] Iteration 1100 (36.2845 iter/s, 2.756s/100 iters), loss = 1.21759
I0923 20:28:43.748128 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I0923 20:28:43.748128 17252 solver.cpp:237]     Train net output #1: loss = 1.21759 (* 1 = 1.21759 loss)
I0923 20:28:43.748128 17252 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0923 20:28:46.531584 17252 solver.cpp:218] Iteration 1200 (35.93 iter/s, 2.78319s/100 iters), loss = 1.30298
I0923 20:28:46.531584 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I0923 20:28:46.531584 17252 solver.cpp:237]     Train net output #1: loss = 1.30298 (* 1 = 1.30298 loss)
I0923 20:28:46.531584 17252 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0923 20:28:49.308769 17252 solver.cpp:218] Iteration 1300 (36.0188 iter/s, 2.77633s/100 iters), loss = 1.16195
I0923 20:28:49.308769 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I0923 20:28:49.308769 17252 solver.cpp:237]     Train net output #1: loss = 1.16195 (* 1 = 1.16195 loss)
I0923 20:28:49.308769 17252 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0923 20:28:52.077934 17252 solver.cpp:218] Iteration 1400 (36.1111 iter/s, 2.76923s/100 iters), loss = 1.07649
I0923 20:28:52.077934 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I0923 20:28:52.077934 17252 solver.cpp:237]     Train net output #1: loss = 1.07649 (* 1 = 1.07649 loss)
I0923 20:28:52.077934 17252 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0923 20:28:54.730235 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:28:54.865850 17252 solver.cpp:218] Iteration 1500 (35.8724 iter/s, 2.78766s/100 iters), loss = 1.05611
I0923 20:28:54.865850 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I0923 20:28:54.865850 17252 solver.cpp:237]     Train net output #1: loss = 1.05611 (* 1 = 1.05611 loss)
I0923 20:28:54.865850 17252 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0923 20:28:57.621439 17252 solver.cpp:218] Iteration 1600 (36.2985 iter/s, 2.75494s/100 iters), loss = 1.02332
I0923 20:28:57.621439 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0923 20:28:57.621439 17252 solver.cpp:237]     Train net output #1: loss = 1.02332 (* 1 = 1.02332 loss)
I0923 20:28:57.621439 17252 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0923 20:29:00.371203 17252 solver.cpp:218] Iteration 1700 (36.3623 iter/s, 2.7501s/100 iters), loss = 1.06606
I0923 20:29:00.371203 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0923 20:29:00.371203 17252 solver.cpp:237]     Train net output #1: loss = 1.06606 (* 1 = 1.06606 loss)
I0923 20:29:00.371203 17252 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0923 20:29:03.137477 17252 solver.cpp:218] Iteration 1800 (36.164 iter/s, 2.76518s/100 iters), loss = 1.00847
I0923 20:29:03.137477 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I0923 20:29:03.137477 17252 solver.cpp:237]     Train net output #1: loss = 1.00847 (* 1 = 1.00847 loss)
I0923 20:29:03.137477 17252 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0923 20:29:05.895226 17252 solver.cpp:218] Iteration 1900 (36.2639 iter/s, 2.75756s/100 iters), loss = 0.894686
I0923 20:29:05.895226 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0923 20:29:05.895226 17252 solver.cpp:237]     Train net output #1: loss = 0.894686 (* 1 = 0.894686 loss)
I0923 20:29:05.895226 17252 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0923 20:29:08.530900 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:29:08.639979 17252 solver.cpp:330] Iteration 2000, Testing net (#0)
I0923 20:29:08.639979 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:29:09.155156 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:29:09.175170 17252 solver.cpp:397]     Test net output #0: accuracy = 0.6194
I0923 20:29:09.175170 17252 solver.cpp:397]     Test net output #1: loss = 1.08504 (* 1 = 1.08504 loss)
I0923 20:29:09.200188 17252 solver.cpp:218] Iteration 2000 (30.2544 iter/s, 3.30531s/100 iters), loss = 1.05002
I0923 20:29:09.200188 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0923 20:29:09.201189 17252 solver.cpp:237]     Train net output #1: loss = 1.05002 (* 1 = 1.05002 loss)
I0923 20:29:09.201189 17252 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0923 20:29:11.956573 17252 solver.cpp:218] Iteration 2100 (36.2872 iter/s, 2.7558s/100 iters), loss = 0.936765
I0923 20:29:11.956573 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0923 20:29:11.956573 17252 solver.cpp:237]     Train net output #1: loss = 0.936765 (* 1 = 0.936765 loss)
I0923 20:29:11.956573 17252 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0923 20:29:14.700595 17252 solver.cpp:218] Iteration 2200 (36.4444 iter/s, 2.74391s/100 iters), loss = 0.996579
I0923 20:29:14.700595 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0923 20:29:14.700595 17252 solver.cpp:237]     Train net output #1: loss = 0.996579 (* 1 = 0.996579 loss)
I0923 20:29:14.700595 17252 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0923 20:29:17.455159 17252 solver.cpp:218] Iteration 2300 (36.3099 iter/s, 2.75407s/100 iters), loss = 0.941376
I0923 20:29:17.455159 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I0923 20:29:17.455159 17252 solver.cpp:237]     Train net output #1: loss = 0.941376 (* 1 = 0.941376 loss)
I0923 20:29:17.455159 17252 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0923 20:29:20.262742 17252 solver.cpp:218] Iteration 2400 (35.622 iter/s, 2.80725s/100 iters), loss = 0.815507
I0923 20:29:20.262742 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I0923 20:29:20.262742 17252 solver.cpp:237]     Train net output #1: loss = 0.815507 (* 1 = 0.815507 loss)
I0923 20:29:20.262742 17252 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0923 20:29:22.870412 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:29:23.004655 17252 solver.cpp:218] Iteration 2500 (36.4747 iter/s, 2.74162s/100 iters), loss = 0.977318
I0923 20:29:23.004655 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0923 20:29:23.004655 17252 solver.cpp:237]     Train net output #1: loss = 0.977318 (* 1 = 0.977318 loss)
I0923 20:29:23.004655 17252 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0923 20:29:25.769428 17252 solver.cpp:218] Iteration 2600 (36.1795 iter/s, 2.76399s/100 iters), loss = 0.8495
I0923 20:29:25.769428 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0923 20:29:25.769428 17252 solver.cpp:237]     Train net output #1: loss = 0.8495 (* 1 = 0.8495 loss)
I0923 20:29:25.769428 17252 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0923 20:29:28.556198 17252 solver.cpp:218] Iteration 2700 (35.879 iter/s, 2.78715s/100 iters), loss = 0.902767
I0923 20:29:28.557199 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0923 20:29:28.557199 17252 solver.cpp:237]     Train net output #1: loss = 0.902767 (* 1 = 0.902767 loss)
I0923 20:29:28.557199 17252 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0923 20:29:31.343678 17252 solver.cpp:218] Iteration 2800 (35.8893 iter/s, 2.78634s/100 iters), loss = 0.778889
I0923 20:29:31.343678 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:29:31.343678 17252 solver.cpp:237]     Train net output #1: loss = 0.778889 (* 1 = 0.778889 loss)
I0923 20:29:31.343678 17252 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0923 20:29:34.105269 17252 solver.cpp:218] Iteration 2900 (36.2154 iter/s, 2.76126s/100 iters), loss = 0.813108
I0923 20:29:34.105269 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0923 20:29:34.105269 17252 solver.cpp:237]     Train net output #1: loss = 0.813108 (* 1 = 0.813108 loss)
I0923 20:29:34.105269 17252 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0923 20:29:36.713445 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:29:36.822023 17252 solver.cpp:330] Iteration 3000, Testing net (#0)
I0923 20:29:36.822023 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:29:37.352031 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:29:37.373047 17252 solver.cpp:397]     Test net output #0: accuracy = 0.6832
I0923 20:29:37.373047 17252 solver.cpp:397]     Test net output #1: loss = 0.898145 (* 1 = 0.898145 loss)
I0923 20:29:37.399065 17252 solver.cpp:218] Iteration 3000 (30.3613 iter/s, 3.29367s/100 iters), loss = 0.857895
I0923 20:29:37.399065 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0923 20:29:37.399065 17252 solver.cpp:237]     Train net output #1: loss = 0.857895 (* 1 = 0.857895 loss)
I0923 20:29:37.399065 17252 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0923 20:29:40.157028 17252 solver.cpp:218] Iteration 3100 (36.2667 iter/s, 2.75735s/100 iters), loss = 0.803308
I0923 20:29:40.157028 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 20:29:40.157028 17252 solver.cpp:237]     Train net output #1: loss = 0.803308 (* 1 = 0.803308 loss)
I0923 20:29:40.157028 17252 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0923 20:29:42.934154 17252 solver.cpp:218] Iteration 3200 (36.0072 iter/s, 2.77722s/100 iters), loss = 0.78906
I0923 20:29:42.934154 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0923 20:29:42.934154 17252 solver.cpp:237]     Train net output #1: loss = 0.78906 (* 1 = 0.78906 loss)
I0923 20:29:42.934154 17252 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0923 20:29:45.723062 17252 solver.cpp:218] Iteration 3300 (35.8606 iter/s, 2.78857s/100 iters), loss = 0.784059
I0923 20:29:45.723062 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:29:45.723062 17252 solver.cpp:237]     Train net output #1: loss = 0.784059 (* 1 = 0.784059 loss)
I0923 20:29:45.723062 17252 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0923 20:29:48.498420 17252 solver.cpp:218] Iteration 3400 (36.0375 iter/s, 2.77489s/100 iters), loss = 0.747333
I0923 20:29:48.498420 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0923 20:29:48.498420 17252 solver.cpp:237]     Train net output #1: loss = 0.747333 (* 1 = 0.747333 loss)
I0923 20:29:48.498420 17252 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0923 20:29:51.118675 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:29:51.251832 17252 solver.cpp:218] Iteration 3500 (36.3215 iter/s, 2.75319s/100 iters), loss = 0.829453
I0923 20:29:51.251832 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0923 20:29:51.251832 17252 solver.cpp:237]     Train net output #1: loss = 0.829453 (* 1 = 0.829453 loss)
I0923 20:29:51.251832 17252 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0923 20:29:54.046217 17252 solver.cpp:218] Iteration 3600 (35.7933 iter/s, 2.79382s/100 iters), loss = 0.69279
I0923 20:29:54.046217 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:29:54.046217 17252 solver.cpp:237]     Train net output #1: loss = 0.69279 (* 1 = 0.69279 loss)
I0923 20:29:54.046217 17252 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0923 20:29:56.830188 17252 solver.cpp:218] Iteration 3700 (35.9239 iter/s, 2.78366s/100 iters), loss = 0.723428
I0923 20:29:56.830188 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:29:56.830188 17252 solver.cpp:237]     Train net output #1: loss = 0.723428 (* 1 = 0.723428 loss)
I0923 20:29:56.830188 17252 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0923 20:29:59.603996 17252 solver.cpp:218] Iteration 3800 (36.0544 iter/s, 2.77359s/100 iters), loss = 0.64283
I0923 20:29:59.603996 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:29:59.603996 17252 solver.cpp:237]     Train net output #1: loss = 0.64283 (* 1 = 0.64283 loss)
I0923 20:29:59.603996 17252 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0923 20:30:02.411634 17252 solver.cpp:218] Iteration 3900 (35.6218 iter/s, 2.80727s/100 iters), loss = 0.710204
I0923 20:30:02.411634 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0923 20:30:02.411634 17252 solver.cpp:237]     Train net output #1: loss = 0.710204 (* 1 = 0.710204 loss)
I0923 20:30:02.411634 17252 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0923 20:30:05.036867 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:30:05.148948 17252 solver.cpp:330] Iteration 4000, Testing net (#0)
I0923 20:30:05.148948 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:30:05.671456 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:30:05.693473 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7004
I0923 20:30:05.693473 17252 solver.cpp:397]     Test net output #1: loss = 0.859781 (* 1 = 0.859781 loss)
I0923 20:30:05.720494 17252 solver.cpp:218] Iteration 4000 (30.2281 iter/s, 3.30818s/100 iters), loss = 0.682477
I0923 20:30:05.720494 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 20:30:05.720494 17252 solver.cpp:237]     Train net output #1: loss = 0.682477 (* 1 = 0.682477 loss)
I0923 20:30:05.720494 17252 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0923 20:30:08.459643 17252 solver.cpp:218] Iteration 4100 (36.5197 iter/s, 2.73824s/100 iters), loss = 0.650489
I0923 20:30:08.459643 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:30:08.459643 17252 solver.cpp:237]     Train net output #1: loss = 0.650489 (* 1 = 0.650489 loss)
I0923 20:30:08.459643 17252 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0923 20:30:11.203752 17252 solver.cpp:218] Iteration 4200 (36.4465 iter/s, 2.74375s/100 iters), loss = 0.753622
I0923 20:30:11.203752 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:30:11.203752 17252 solver.cpp:237]     Train net output #1: loss = 0.753622 (* 1 = 0.753622 loss)
I0923 20:30:11.203752 17252 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0923 20:30:13.950942 17252 solver.cpp:218] Iteration 4300 (36.3986 iter/s, 2.74736s/100 iters), loss = 0.786001
I0923 20:30:13.950942 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0923 20:30:13.950942 17252 solver.cpp:237]     Train net output #1: loss = 0.786001 (* 1 = 0.786001 loss)
I0923 20:30:13.950942 17252 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0923 20:30:16.764220 17252 solver.cpp:218] Iteration 4400 (35.5543 iter/s, 2.8126s/100 iters), loss = 0.684863
I0923 20:30:16.764220 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:30:16.764220 17252 solver.cpp:237]     Train net output #1: loss = 0.684863 (* 1 = 0.684863 loss)
I0923 20:30:16.764220 17252 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0923 20:30:19.428360 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:30:19.567044 17252 solver.cpp:218] Iteration 4500 (35.6868 iter/s, 2.80216s/100 iters), loss = 0.685769
I0923 20:30:19.567044 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:30:19.567044 17252 solver.cpp:237]     Train net output #1: loss = 0.685769 (* 1 = 0.685769 loss)
I0923 20:30:19.567044 17252 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0923 20:30:22.347699 17252 solver.cpp:218] Iteration 4600 (35.9647 iter/s, 2.78051s/100 iters), loss = 0.635676
I0923 20:30:22.347699 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:30:22.347699 17252 solver.cpp:237]     Train net output #1: loss = 0.635676 (* 1 = 0.635676 loss)
I0923 20:30:22.347699 17252 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0923 20:30:25.088275 17252 solver.cpp:218] Iteration 4700 (36.495 iter/s, 2.7401s/100 iters), loss = 0.809169
I0923 20:30:25.088275 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 20:30:25.088275 17252 solver.cpp:237]     Train net output #1: loss = 0.809169 (* 1 = 0.809169 loss)
I0923 20:30:25.088275 17252 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0923 20:30:27.820945 17252 solver.cpp:218] Iteration 4800 (36.5886 iter/s, 2.73309s/100 iters), loss = 0.66529
I0923 20:30:27.820945 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:30:27.820945 17252 solver.cpp:237]     Train net output #1: loss = 0.66529 (* 1 = 0.66529 loss)
I0923 20:30:27.820945 17252 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0923 20:30:30.549505 17252 solver.cpp:218] Iteration 4900 (36.659 iter/s, 2.72784s/100 iters), loss = 0.688087
I0923 20:30:30.549505 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0923 20:30:30.549505 17252 solver.cpp:237]     Train net output #1: loss = 0.688087 (* 1 = 0.688087 loss)
I0923 20:30:30.549505 17252 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0923 20:30:33.145385 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:30:33.253515 17252 solver.cpp:330] Iteration 5000, Testing net (#0)
I0923 20:30:33.253515 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:30:33.773869 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:30:33.794397 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7428
I0923 20:30:33.794397 17252 solver.cpp:397]     Test net output #1: loss = 0.745826 (* 1 = 0.745826 loss)
I0923 20:30:33.820492 17252 solver.cpp:218] Iteration 5000 (30.5788 iter/s, 3.27024s/100 iters), loss = 0.648357
I0923 20:30:33.820492 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:30:33.820492 17252 solver.cpp:237]     Train net output #1: loss = 0.648357 (* 1 = 0.648357 loss)
I0923 20:30:33.820492 17252 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I0923 20:30:33.820492 17252 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I0923 20:30:36.553527 17252 solver.cpp:218] Iteration 5100 (36.5845 iter/s, 2.7334s/100 iters), loss = 0.541475
I0923 20:30:36.553527 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:30:36.553527 17252 solver.cpp:237]     Train net output #1: loss = 0.541475 (* 1 = 0.541475 loss)
I0923 20:30:36.553527 17252 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I0923 20:30:39.282491 17252 solver.cpp:218] Iteration 5200 (36.6501 iter/s, 2.72851s/100 iters), loss = 0.599093
I0923 20:30:39.282491 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:30:39.282491 17252 solver.cpp:237]     Train net output #1: loss = 0.599093 (* 1 = 0.599093 loss)
I0923 20:30:39.282491 17252 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I0923 20:30:42.006564 17252 solver.cpp:218] Iteration 5300 (36.7191 iter/s, 2.72338s/100 iters), loss = 0.608238
I0923 20:30:42.006564 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:30:42.006564 17252 solver.cpp:237]     Train net output #1: loss = 0.608238 (* 1 = 0.608238 loss)
I0923 20:30:42.006564 17252 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I0923 20:30:44.733983 17252 solver.cpp:218] Iteration 5400 (36.6668 iter/s, 2.72726s/100 iters), loss = 0.544549
I0923 20:30:44.733983 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:30:44.733983 17252 solver.cpp:237]     Train net output #1: loss = 0.544549 (* 1 = 0.544549 loss)
I0923 20:30:44.733983 17252 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I0923 20:30:47.342495 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:30:47.475040 17252 solver.cpp:218] Iteration 5500 (36.4853 iter/s, 2.74083s/100 iters), loss = 0.579185
I0923 20:30:47.475040 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:30:47.475040 17252 solver.cpp:237]     Train net output #1: loss = 0.579185 (* 1 = 0.579185 loss)
I0923 20:30:47.475040 17252 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I0923 20:30:50.216543 17252 solver.cpp:218] Iteration 5600 (36.4825 iter/s, 2.74104s/100 iters), loss = 0.520645
I0923 20:30:50.216543 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:30:50.216543 17252 solver.cpp:237]     Train net output #1: loss = 0.520645 (* 1 = 0.520645 loss)
I0923 20:30:50.216543 17252 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I0923 20:30:52.954605 17252 solver.cpp:218] Iteration 5700 (36.5193 iter/s, 2.73828s/100 iters), loss = 0.616005
I0923 20:30:52.954605 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:30:52.954605 17252 solver.cpp:237]     Train net output #1: loss = 0.616005 (* 1 = 0.616005 loss)
I0923 20:30:52.954605 17252 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I0923 20:30:55.717278 17252 solver.cpp:218] Iteration 5800 (36.2062 iter/s, 2.76196s/100 iters), loss = 0.619188
I0923 20:30:55.717778 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:30:55.717778 17252 solver.cpp:237]     Train net output #1: loss = 0.619188 (* 1 = 0.619188 loss)
I0923 20:30:55.717778 17252 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I0923 20:30:58.484475 17252 solver.cpp:218] Iteration 5900 (36.1481 iter/s, 2.7664s/100 iters), loss = 0.590088
I0923 20:30:58.484475 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:30:58.484475 17252 solver.cpp:237]     Train net output #1: loss = 0.590088 (* 1 = 0.590088 loss)
I0923 20:30:58.484475 17252 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I0923 20:31:01.094535 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:31:01.206606 17252 solver.cpp:330] Iteration 6000, Testing net (#0)
I0923 20:31:01.206606 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:31:01.739506 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:31:01.760522 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7716
I0923 20:31:01.760522 17252 solver.cpp:397]     Test net output #1: loss = 0.655767 (* 1 = 0.655767 loss)
I0923 20:31:01.788540 17252 solver.cpp:218] Iteration 6000 (30.2679 iter/s, 3.30383s/100 iters), loss = 0.500757
I0923 20:31:01.788540 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:31:01.788540 17252 solver.cpp:237]     Train net output #1: loss = 0.500757 (* 1 = 0.500757 loss)
I0923 20:31:01.788540 17252 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I0923 20:31:04.557330 17252 solver.cpp:218] Iteration 6100 (36.1211 iter/s, 2.76846s/100 iters), loss = 0.453807
I0923 20:31:04.557330 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:31:04.557330 17252 solver.cpp:237]     Train net output #1: loss = 0.453807 (* 1 = 0.453807 loss)
I0923 20:31:04.557330 17252 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I0923 20:31:07.292693 17252 solver.cpp:218] Iteration 6200 (36.5652 iter/s, 2.73484s/100 iters), loss = 0.61326
I0923 20:31:07.292693 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0923 20:31:07.292693 17252 solver.cpp:237]     Train net output #1: loss = 0.61326 (* 1 = 0.61326 loss)
I0923 20:31:07.292693 17252 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I0923 20:31:10.023803 17252 solver.cpp:218] Iteration 6300 (36.6192 iter/s, 2.73081s/100 iters), loss = 0.559982
I0923 20:31:10.023803 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:31:10.023803 17252 solver.cpp:237]     Train net output #1: loss = 0.559982 (* 1 = 0.559982 loss)
I0923 20:31:10.023803 17252 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I0923 20:31:12.750452 17252 solver.cpp:218] Iteration 6400 (36.6682 iter/s, 2.72716s/100 iters), loss = 0.575399
I0923 20:31:12.751453 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:31:12.751453 17252 solver.cpp:237]     Train net output #1: loss = 0.575399 (* 1 = 0.575399 loss)
I0923 20:31:12.751453 17252 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I0923 20:31:15.346067 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:31:15.477866 17252 solver.cpp:218] Iteration 6500 (36.6752 iter/s, 2.72664s/100 iters), loss = 0.567117
I0923 20:31:15.477866 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:31:15.477866 17252 solver.cpp:237]     Train net output #1: loss = 0.567117 (* 1 = 0.567117 loss)
I0923 20:31:15.477866 17252 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I0923 20:31:18.209070 17252 solver.cpp:218] Iteration 6600 (36.6176 iter/s, 2.73093s/100 iters), loss = 0.492775
I0923 20:31:18.209070 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:31:18.209070 17252 solver.cpp:237]     Train net output #1: loss = 0.492775 (* 1 = 0.492775 loss)
I0923 20:31:18.209070 17252 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I0923 20:31:20.933167 17252 solver.cpp:218] Iteration 6700 (36.7103 iter/s, 2.72403s/100 iters), loss = 0.506984
I0923 20:31:20.933167 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:31:20.933167 17252 solver.cpp:237]     Train net output #1: loss = 0.506984 (* 1 = 0.506984 loss)
I0923 20:31:20.933167 17252 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I0923 20:31:23.658345 17252 solver.cpp:218] Iteration 6800 (36.7059 iter/s, 2.72436s/100 iters), loss = 0.562877
I0923 20:31:23.658345 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:31:23.658345 17252 solver.cpp:237]     Train net output #1: loss = 0.562877 (* 1 = 0.562877 loss)
I0923 20:31:23.658345 17252 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I0923 20:31:26.381234 17252 solver.cpp:218] Iteration 6900 (36.7215 iter/s, 2.7232s/100 iters), loss = 0.577418
I0923 20:31:26.382235 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:31:26.382235 17252 solver.cpp:237]     Train net output #1: loss = 0.577418 (* 1 = 0.577418 loss)
I0923 20:31:26.382235 17252 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I0923 20:31:28.978713 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:31:29.087007 17252 solver.cpp:330] Iteration 7000, Testing net (#0)
I0923 20:31:29.087007 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:31:29.605355 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:31:29.625368 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7748
I0923 20:31:29.625368 17252 solver.cpp:397]     Test net output #1: loss = 0.65123 (* 1 = 0.65123 loss)
I0923 20:31:29.650888 17252 solver.cpp:218] Iteration 7000 (30.5919 iter/s, 3.26884s/100 iters), loss = 0.497921
I0923 20:31:29.651388 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:31:29.651388 17252 solver.cpp:237]     Train net output #1: loss = 0.497921 (* 1 = 0.497921 loss)
I0923 20:31:29.651388 17252 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I0923 20:31:32.376194 17252 solver.cpp:218] Iteration 7100 (36.692 iter/s, 2.72539s/100 iters), loss = 0.540013
I0923 20:31:32.376194 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:31:32.376194 17252 solver.cpp:237]     Train net output #1: loss = 0.540013 (* 1 = 0.540013 loss)
I0923 20:31:32.376194 17252 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I0923 20:31:35.104560 17252 solver.cpp:218] Iteration 7200 (36.6601 iter/s, 2.72776s/100 iters), loss = 0.539851
I0923 20:31:35.104560 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:31:35.104560 17252 solver.cpp:237]     Train net output #1: loss = 0.539851 (* 1 = 0.539851 loss)
I0923 20:31:35.104560 17252 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I0923 20:31:37.856626 17252 solver.cpp:218] Iteration 7300 (36.3465 iter/s, 2.75129s/100 iters), loss = 0.578404
I0923 20:31:37.856626 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:31:37.856626 17252 solver.cpp:237]     Train net output #1: loss = 0.578404 (* 1 = 0.578404 loss)
I0923 20:31:37.856626 17252 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I0923 20:31:40.637037 17252 solver.cpp:218] Iteration 7400 (35.9627 iter/s, 2.78066s/100 iters), loss = 0.555231
I0923 20:31:40.637037 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:31:40.637037 17252 solver.cpp:237]     Train net output #1: loss = 0.555231 (* 1 = 0.555231 loss)
I0923 20:31:40.637037 17252 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I0923 20:31:43.273447 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:31:43.408123 17252 solver.cpp:218] Iteration 7500 (36.0953 iter/s, 2.77045s/100 iters), loss = 0.463295
I0923 20:31:43.408123 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:31:43.408123 17252 solver.cpp:237]     Train net output #1: loss = 0.463295 (* 1 = 0.463295 loss)
I0923 20:31:43.408123 17252 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I0923 20:31:46.141499 17252 solver.cpp:218] Iteration 7600 (36.586 iter/s, 2.73328s/100 iters), loss = 0.460583
I0923 20:31:46.141499 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:31:46.141499 17252 solver.cpp:237]     Train net output #1: loss = 0.460583 (* 1 = 0.460583 loss)
I0923 20:31:46.141499 17252 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I0923 20:31:48.940963 17252 solver.cpp:218] Iteration 7700 (35.727 iter/s, 2.799s/100 iters), loss = 0.541734
I0923 20:31:48.940963 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:31:48.940963 17252 solver.cpp:237]     Train net output #1: loss = 0.541734 (* 1 = 0.541734 loss)
I0923 20:31:48.940963 17252 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I0923 20:31:51.718142 17252 solver.cpp:218] Iteration 7800 (36.0068 iter/s, 2.77726s/100 iters), loss = 0.523584
I0923 20:31:51.719143 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:31:51.719143 17252 solver.cpp:237]     Train net output #1: loss = 0.523584 (* 1 = 0.523584 loss)
I0923 20:31:51.719143 17252 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I0923 20:31:54.469291 17252 solver.cpp:218] Iteration 7900 (36.3645 iter/s, 2.74994s/100 iters), loss = 0.574846
I0923 20:31:54.469291 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:31:54.469291 17252 solver.cpp:237]     Train net output #1: loss = 0.574846 (* 1 = 0.574846 loss)
I0923 20:31:54.469291 17252 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I0923 20:31:57.097761 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:31:57.204924 17252 solver.cpp:330] Iteration 8000, Testing net (#0)
I0923 20:31:57.204924 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:31:57.728247 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:31:57.749261 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7766
I0923 20:31:57.749261 17252 solver.cpp:397]     Test net output #1: loss = 0.644649 (* 1 = 0.644649 loss)
I0923 20:31:57.775279 17252 solver.cpp:218] Iteration 8000 (30.2523 iter/s, 3.30554s/100 iters), loss = 0.475104
I0923 20:31:57.775279 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:31:57.775279 17252 solver.cpp:237]     Train net output #1: loss = 0.475104 (* 1 = 0.475104 loss)
I0923 20:31:57.775279 17252 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I0923 20:32:00.559703 17252 solver.cpp:218] Iteration 8100 (35.9074 iter/s, 2.78494s/100 iters), loss = 0.534235
I0923 20:32:00.559703 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:32:00.559703 17252 solver.cpp:237]     Train net output #1: loss = 0.534235 (* 1 = 0.534235 loss)
I0923 20:32:00.559703 17252 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I0923 20:32:03.315325 17252 solver.cpp:218] Iteration 8200 (36.2958 iter/s, 2.75514s/100 iters), loss = 0.526753
I0923 20:32:03.315325 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:32:03.315325 17252 solver.cpp:237]     Train net output #1: loss = 0.526753 (* 1 = 0.526753 loss)
I0923 20:32:03.315325 17252 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I0923 20:32:06.119684 17252 solver.cpp:218] Iteration 8300 (35.6665 iter/s, 2.80375s/100 iters), loss = 0.538449
I0923 20:32:06.119684 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:32:06.119684 17252 solver.cpp:237]     Train net output #1: loss = 0.538449 (* 1 = 0.538449 loss)
I0923 20:32:06.119684 17252 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I0923 20:32:08.855103 17252 solver.cpp:218] Iteration 8400 (36.5644 iter/s, 2.7349s/100 iters), loss = 0.56944
I0923 20:32:08.855103 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:32:08.855103 17252 solver.cpp:237]     Train net output #1: loss = 0.56944 (* 1 = 0.56944 loss)
I0923 20:32:08.855103 17252 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I0923 20:32:11.477339 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:32:11.611570 17252 solver.cpp:218] Iteration 8500 (36.2806 iter/s, 2.75629s/100 iters), loss = 0.524804
I0923 20:32:11.611570 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:32:11.611570 17252 solver.cpp:237]     Train net output #1: loss = 0.524804 (* 1 = 0.524804 loss)
I0923 20:32:11.611570 17252 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I0923 20:32:14.339967 17252 solver.cpp:218] Iteration 8600 (36.6494 iter/s, 2.72856s/100 iters), loss = 0.577727
I0923 20:32:14.340955 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:32:14.340955 17252 solver.cpp:237]     Train net output #1: loss = 0.577727 (* 1 = 0.577727 loss)
I0923 20:32:14.340955 17252 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I0923 20:32:17.071377 17252 solver.cpp:218] Iteration 8700 (36.6171 iter/s, 2.73096s/100 iters), loss = 0.552852
I0923 20:32:17.071377 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:32:17.071377 17252 solver.cpp:237]     Train net output #1: loss = 0.552852 (* 1 = 0.552852 loss)
I0923 20:32:17.071377 17252 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I0923 20:32:19.806303 17252 solver.cpp:218] Iteration 8800 (36.5772 iter/s, 2.73394s/100 iters), loss = 0.533875
I0923 20:32:19.806303 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:32:19.806303 17252 solver.cpp:237]     Train net output #1: loss = 0.533875 (* 1 = 0.533875 loss)
I0923 20:32:19.806303 17252 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I0923 20:32:22.536834 17252 solver.cpp:218] Iteration 8900 (36.6257 iter/s, 2.73032s/100 iters), loss = 0.521233
I0923 20:32:22.536834 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:32:22.536834 17252 solver.cpp:237]     Train net output #1: loss = 0.521233 (* 1 = 0.521233 loss)
I0923 20:32:22.536834 17252 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I0923 20:32:25.135148 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:32:25.242760 17252 solver.cpp:330] Iteration 9000, Testing net (#0)
I0923 20:32:25.242760 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:32:25.762262 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:32:25.782289 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7775
I0923 20:32:25.782289 17252 solver.cpp:397]     Test net output #1: loss = 0.645888 (* 1 = 0.645888 loss)
I0923 20:32:25.807826 17252 solver.cpp:218] Iteration 9000 (30.5781 iter/s, 3.27031s/100 iters), loss = 0.539617
I0923 20:32:25.807826 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:32:25.807826 17252 solver.cpp:237]     Train net output #1: loss = 0.539617 (* 1 = 0.539617 loss)
I0923 20:32:25.807826 17252 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I0923 20:32:28.537618 17252 solver.cpp:218] Iteration 9100 (36.6309 iter/s, 2.72994s/100 iters), loss = 0.535165
I0923 20:32:28.537618 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:32:28.537618 17252 solver.cpp:237]     Train net output #1: loss = 0.535165 (* 1 = 0.535165 loss)
I0923 20:32:28.537618 17252 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I0923 20:32:31.272997 17252 solver.cpp:218] Iteration 9200 (36.5614 iter/s, 2.73513s/100 iters), loss = 0.488371
I0923 20:32:31.272997 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:32:31.272997 17252 solver.cpp:237]     Train net output #1: loss = 0.488371 (* 1 = 0.488371 loss)
I0923 20:32:31.272997 17252 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I0923 20:32:34.001992 17252 solver.cpp:218] Iteration 9300 (36.6438 iter/s, 2.72897s/100 iters), loss = 0.536331
I0923 20:32:34.001992 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:32:34.002993 17252 solver.cpp:237]     Train net output #1: loss = 0.536331 (* 1 = 0.536331 loss)
I0923 20:32:34.002993 17252 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I0923 20:32:36.765117 17252 solver.cpp:218] Iteration 9400 (36.1987 iter/s, 2.76253s/100 iters), loss = 0.561559
I0923 20:32:36.765117 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:32:36.765117 17252 solver.cpp:237]     Train net output #1: loss = 0.561559 (* 1 = 0.561559 loss)
I0923 20:32:36.765117 17252 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I0923 20:32:39.435760 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:32:39.572885 17252 solver.cpp:218] Iteration 9500 (35.6158 iter/s, 2.80774s/100 iters), loss = 0.526085
I0923 20:32:39.573886 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:32:39.573886 17252 solver.cpp:237]     Train net output #1: loss = 0.526085 (* 1 = 0.526085 loss)
I0923 20:32:39.573886 17252 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I0923 20:32:42.352771 17252 solver.cpp:218] Iteration 9600 (35.9904 iter/s, 2.77852s/100 iters), loss = 0.582081
I0923 20:32:42.352771 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:32:42.352771 17252 solver.cpp:237]     Train net output #1: loss = 0.582081 (* 1 = 0.582081 loss)
I0923 20:32:42.352771 17252 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I0923 20:32:45.137410 17252 solver.cpp:218] Iteration 9700 (35.9126 iter/s, 2.78454s/100 iters), loss = 0.556914
I0923 20:32:45.137410 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:32:45.137410 17252 solver.cpp:237]     Train net output #1: loss = 0.556914 (* 1 = 0.556914 loss)
I0923 20:32:45.137410 17252 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I0923 20:32:47.911417 17252 solver.cpp:218] Iteration 9800 (36.0452 iter/s, 2.77429s/100 iters), loss = 0.549179
I0923 20:32:47.911417 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:32:47.911417 17252 solver.cpp:237]     Train net output #1: loss = 0.549179 (* 1 = 0.549179 loss)
I0923 20:32:47.911417 17252 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I0923 20:32:50.644063 17252 solver.cpp:218] Iteration 9900 (36.6051 iter/s, 2.73186s/100 iters), loss = 0.528525
I0923 20:32:50.644063 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:32:50.644063 17252 solver.cpp:237]     Train net output #1: loss = 0.528525 (* 1 = 0.528525 loss)
I0923 20:32:50.644063 17252 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I0923 20:32:53.240603 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:32:53.349316 17252 solver.cpp:330] Iteration 10000, Testing net (#0)
I0923 20:32:53.349316 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:32:53.870529 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:32:53.891559 17252 solver.cpp:397]     Test net output #0: accuracy = 0.778
I0923 20:32:53.891559 17252 solver.cpp:397]     Test net output #1: loss = 0.644372 (* 1 = 0.644372 loss)
I0923 20:32:53.917573 17252 solver.cpp:218] Iteration 10000 (30.5542 iter/s, 3.27287s/100 iters), loss = 0.496134
I0923 20:32:53.917573 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:32:53.917573 17252 solver.cpp:237]     Train net output #1: loss = 0.496134 (* 1 = 0.496134 loss)
I0923 20:32:53.917573 17252 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I0923 20:32:53.917573 17252 sgd_solver.cpp:105] Iteration 10000, lr = 0.0001
I0923 20:32:56.685497 17252 solver.cpp:218] Iteration 10100 (36.1241 iter/s, 2.76823s/100 iters), loss = 0.528883
I0923 20:32:56.685497 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:32:56.685497 17252 solver.cpp:237]     Train net output #1: loss = 0.528883 (* 1 = 0.528883 loss)
I0923 20:32:56.685497 17252 sgd_solver.cpp:105] Iteration 10100, lr = 0.0001
I0923 20:32:59.474381 17252 solver.cpp:218] Iteration 10200 (35.8648 iter/s, 2.78825s/100 iters), loss = 0.491258
I0923 20:32:59.474381 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:32:59.474381 17252 solver.cpp:237]     Train net output #1: loss = 0.491258 (* 1 = 0.491258 loss)
I0923 20:32:59.474381 17252 sgd_solver.cpp:105] Iteration 10200, lr = 0.0001
I0923 20:33:02.265306 17252 solver.cpp:218] Iteration 10300 (35.84 iter/s, 2.79018s/100 iters), loss = 0.529546
I0923 20:33:02.265306 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:33:02.265306 17252 solver.cpp:237]     Train net output #1: loss = 0.529546 (* 1 = 0.529546 loss)
I0923 20:33:02.265306 17252 sgd_solver.cpp:105] Iteration 10300, lr = 0.0001
I0923 20:33:05.052263 17252 solver.cpp:218] Iteration 10400 (35.8847 iter/s, 2.7867s/100 iters), loss = 0.529935
I0923 20:33:05.052263 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:33:05.052263 17252 solver.cpp:237]     Train net output #1: loss = 0.529935 (* 1 = 0.529935 loss)
I0923 20:33:05.052263 17252 sgd_solver.cpp:105] Iteration 10400, lr = 0.0001
I0923 20:33:07.676374 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:33:07.814330 17252 solver.cpp:218] Iteration 10500 (36.2056 iter/s, 2.762s/100 iters), loss = 0.506776
I0923 20:33:07.814330 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:33:07.814330 17252 solver.cpp:237]     Train net output #1: loss = 0.506776 (* 1 = 0.506776 loss)
I0923 20:33:07.814330 17252 sgd_solver.cpp:105] Iteration 10500, lr = 0.0001
I0923 20:33:10.612097 17252 solver.cpp:218] Iteration 10600 (35.7429 iter/s, 2.79776s/100 iters), loss = 0.480791
I0923 20:33:10.612097 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:33:10.612097 17252 solver.cpp:237]     Train net output #1: loss = 0.480791 (* 1 = 0.480791 loss)
I0923 20:33:10.612097 17252 sgd_solver.cpp:105] Iteration 10600, lr = 0.0001
I0923 20:33:13.378329 17252 solver.cpp:218] Iteration 10700 (36.1603 iter/s, 2.76546s/100 iters), loss = 0.436791
I0923 20:33:13.378329 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:33:13.378329 17252 solver.cpp:237]     Train net output #1: loss = 0.436791 (* 1 = 0.436791 loss)
I0923 20:33:13.378329 17252 sgd_solver.cpp:105] Iteration 10700, lr = 0.0001
I0923 20:33:16.165377 17252 solver.cpp:218] Iteration 10800 (35.8879 iter/s, 2.78645s/100 iters), loss = 0.529671
I0923 20:33:16.165377 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:33:16.165377 17252 solver.cpp:237]     Train net output #1: loss = 0.529671 (* 1 = 0.529671 loss)
I0923 20:33:16.165377 17252 sgd_solver.cpp:105] Iteration 10800, lr = 0.0001
I0923 20:33:18.935003 17252 solver.cpp:218] Iteration 10900 (36.104 iter/s, 2.76977s/100 iters), loss = 0.512005
I0923 20:33:18.935003 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:33:18.935003 17252 solver.cpp:237]     Train net output #1: loss = 0.512005 (* 1 = 0.512005 loss)
I0923 20:33:18.935003 17252 sgd_solver.cpp:105] Iteration 10900, lr = 0.0001
I0923 20:33:21.568632 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:33:21.675745 17252 solver.cpp:330] Iteration 11000, Testing net (#0)
I0923 20:33:21.675745 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:33:22.197600 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:33:22.218632 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7812
I0923 20:33:22.218632 17252 solver.cpp:397]     Test net output #1: loss = 0.637931 (* 1 = 0.637931 loss)
I0923 20:33:22.244634 17252 solver.cpp:218] Iteration 11000 (30.2252 iter/s, 3.3085s/100 iters), loss = 0.490014
I0923 20:33:22.244634 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:33:22.244634 17252 solver.cpp:237]     Train net output #1: loss = 0.490014 (* 1 = 0.490014 loss)
I0923 20:33:22.244634 17252 sgd_solver.cpp:105] Iteration 11000, lr = 0.0001
I0923 20:33:25.052719 17252 solver.cpp:218] Iteration 11100 (35.6159 iter/s, 2.80774s/100 iters), loss = 0.624076
I0923 20:33:25.052719 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:33:25.052719 17252 solver.cpp:237]     Train net output #1: loss = 0.624076 (* 1 = 0.624076 loss)
I0923 20:33:25.052719 17252 sgd_solver.cpp:105] Iteration 11100, lr = 0.0001
I0923 20:33:27.825191 17252 solver.cpp:218] Iteration 11200 (36.0711 iter/s, 2.7723s/100 iters), loss = 0.471273
I0923 20:33:27.825191 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:33:27.825191 17252 solver.cpp:237]     Train net output #1: loss = 0.471273 (* 1 = 0.471273 loss)
I0923 20:33:27.825191 17252 sgd_solver.cpp:105] Iteration 11200, lr = 0.0001
I0923 20:33:30.560817 17252 solver.cpp:218] Iteration 11300 (36.5617 iter/s, 2.7351s/100 iters), loss = 0.494185
I0923 20:33:30.560817 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:33:30.560817 17252 solver.cpp:237]     Train net output #1: loss = 0.494185 (* 1 = 0.494185 loss)
I0923 20:33:30.560817 17252 sgd_solver.cpp:105] Iteration 11300, lr = 0.0001
I0923 20:33:33.340212 17252 solver.cpp:218] Iteration 11400 (35.9751 iter/s, 2.7797s/100 iters), loss = 0.584297
I0923 20:33:33.340212 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:33:33.340212 17252 solver.cpp:237]     Train net output #1: loss = 0.584297 (* 1 = 0.584297 loss)
I0923 20:33:33.340212 17252 sgd_solver.cpp:105] Iteration 11400, lr = 0.0001
I0923 20:33:36.018957 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:33:36.157088 17252 solver.cpp:218] Iteration 11500 (35.5125 iter/s, 2.81591s/100 iters), loss = 0.428072
I0923 20:33:36.157088 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:33:36.157088 17252 solver.cpp:237]     Train net output #1: loss = 0.428072 (* 1 = 0.428072 loss)
I0923 20:33:36.157088 17252 sgd_solver.cpp:105] Iteration 11500, lr = 0.0001
I0923 20:33:38.927413 17252 solver.cpp:218] Iteration 11600 (36.1015 iter/s, 2.76997s/100 iters), loss = 0.5709
I0923 20:33:38.927413 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:33:38.927413 17252 solver.cpp:237]     Train net output #1: loss = 0.5709 (* 1 = 0.5709 loss)
I0923 20:33:38.927413 17252 sgd_solver.cpp:105] Iteration 11600, lr = 0.0001
I0923 20:33:41.685075 17252 solver.cpp:218] Iteration 11700 (36.2618 iter/s, 2.75772s/100 iters), loss = 0.483429
I0923 20:33:41.685580 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:33:41.685580 17252 solver.cpp:237]     Train net output #1: loss = 0.483429 (* 1 = 0.483429 loss)
I0923 20:33:41.685580 17252 sgd_solver.cpp:105] Iteration 11700, lr = 0.0001
I0923 20:33:44.415724 17252 solver.cpp:218] Iteration 11800 (36.6196 iter/s, 2.73078s/100 iters), loss = 0.479602
I0923 20:33:44.415724 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:33:44.415724 17252 solver.cpp:237]     Train net output #1: loss = 0.479602 (* 1 = 0.479602 loss)
I0923 20:33:44.415724 17252 sgd_solver.cpp:105] Iteration 11800, lr = 0.0001
I0923 20:33:47.148598 17252 solver.cpp:218] Iteration 11900 (36.6062 iter/s, 2.73178s/100 iters), loss = 0.5604
I0923 20:33:47.148598 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:33:47.148598 17252 solver.cpp:237]     Train net output #1: loss = 0.5604 (* 1 = 0.5604 loss)
I0923 20:33:47.148598 17252 sgd_solver.cpp:105] Iteration 11900, lr = 0.0001
I0923 20:33:49.748503 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:33:49.857659 17252 solver.cpp:330] Iteration 12000, Testing net (#0)
I0923 20:33:49.857659 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:33:50.378284 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:33:50.399801 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7819
I0923 20:33:50.399801 17252 solver.cpp:397]     Test net output #1: loss = 0.637463 (* 1 = 0.637463 loss)
I0923 20:33:50.424831 17252 solver.cpp:218] Iteration 12000 (30.5272 iter/s, 3.27577s/100 iters), loss = 0.42374
I0923 20:33:50.424831 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:33:50.424831 17252 solver.cpp:237]     Train net output #1: loss = 0.42374 (* 1 = 0.42374 loss)
I0923 20:33:50.424831 17252 sgd_solver.cpp:105] Iteration 12000, lr = 0.0001
I0923 20:33:53.151795 17252 solver.cpp:218] Iteration 12100 (36.666 iter/s, 2.72733s/100 iters), loss = 0.450531
I0923 20:33:53.151795 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:33:53.151795 17252 solver.cpp:237]     Train net output #1: loss = 0.450531 (* 1 = 0.450531 loss)
I0923 20:33:53.151795 17252 sgd_solver.cpp:105] Iteration 12100, lr = 0.0001
I0923 20:33:55.894760 17252 solver.cpp:218] Iteration 12200 (36.4698 iter/s, 2.742s/100 iters), loss = 0.559059
I0923 20:33:55.894760 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:33:55.894760 17252 solver.cpp:237]     Train net output #1: loss = 0.559059 (* 1 = 0.559059 loss)
I0923 20:33:55.894760 17252 sgd_solver.cpp:105] Iteration 12200, lr = 0.0001
I0923 20:33:58.635634 17252 solver.cpp:218] Iteration 12300 (36.488 iter/s, 2.74062s/100 iters), loss = 0.52393
I0923 20:33:58.635634 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:33:58.635634 17252 solver.cpp:237]     Train net output #1: loss = 0.52393 (* 1 = 0.52393 loss)
I0923 20:33:58.635634 17252 sgd_solver.cpp:105] Iteration 12300, lr = 0.0001
I0923 20:34:01.442029 17252 solver.cpp:218] Iteration 12400 (35.6331 iter/s, 2.80638s/100 iters), loss = 0.544516
I0923 20:34:01.442029 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:34:01.442029 17252 solver.cpp:237]     Train net output #1: loss = 0.544516 (* 1 = 0.544516 loss)
I0923 20:34:01.442029 17252 sgd_solver.cpp:105] Iteration 12400, lr = 0.0001
I0923 20:34:04.089244 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:34:04.223347 17252 solver.cpp:218] Iteration 12500 (35.9573 iter/s, 2.78107s/100 iters), loss = 0.436846
I0923 20:34:04.223347 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:34:04.223347 17252 solver.cpp:237]     Train net output #1: loss = 0.436846 (* 1 = 0.436846 loss)
I0923 20:34:04.223347 17252 sgd_solver.cpp:105] Iteration 12500, lr = 0.0001
I0923 20:34:06.992988 17252 solver.cpp:218] Iteration 12600 (36.1052 iter/s, 2.76969s/100 iters), loss = 0.556483
I0923 20:34:06.992988 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:34:06.992988 17252 solver.cpp:237]     Train net output #1: loss = 0.556483 (* 1 = 0.556483 loss)
I0923 20:34:06.992988 17252 sgd_solver.cpp:105] Iteration 12600, lr = 0.0001
I0923 20:34:09.786412 17252 solver.cpp:218] Iteration 12700 (35.8062 iter/s, 2.79281s/100 iters), loss = 0.481536
I0923 20:34:09.786412 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:34:09.786412 17252 solver.cpp:237]     Train net output #1: loss = 0.481536 (* 1 = 0.481536 loss)
I0923 20:34:09.786412 17252 sgd_solver.cpp:105] Iteration 12700, lr = 0.0001
I0923 20:34:12.584810 17252 solver.cpp:218] Iteration 12800 (35.7411 iter/s, 2.7979s/100 iters), loss = 0.448716
I0923 20:34:12.584810 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:34:12.584810 17252 solver.cpp:237]     Train net output #1: loss = 0.448716 (* 1 = 0.448716 loss)
I0923 20:34:12.584810 17252 sgd_solver.cpp:105] Iteration 12800, lr = 0.0001
I0923 20:34:15.393599 17252 solver.cpp:218] Iteration 12900 (35.6083 iter/s, 2.80833s/100 iters), loss = 0.539193
I0923 20:34:15.393599 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:34:15.393599 17252 solver.cpp:237]     Train net output #1: loss = 0.539193 (* 1 = 0.539193 loss)
I0923 20:34:15.393599 17252 sgd_solver.cpp:105] Iteration 12900, lr = 0.0001
I0923 20:34:18.013556 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:34:18.122174 17252 solver.cpp:330] Iteration 13000, Testing net (#0)
I0923 20:34:18.122174 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:34:18.641340 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:34:18.662338 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7807
I0923 20:34:18.662338 17252 solver.cpp:397]     Test net output #1: loss = 0.63761 (* 1 = 0.63761 loss)
I0923 20:34:18.687360 17252 solver.cpp:218] Iteration 13000 (30.3596 iter/s, 3.29385s/100 iters), loss = 0.515921
I0923 20:34:18.687360 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:34:18.687360 17252 solver.cpp:237]     Train net output #1: loss = 0.515921 (* 1 = 0.515921 loss)
I0923 20:34:18.687360 17252 sgd_solver.cpp:105] Iteration 13000, lr = 0.0001
I0923 20:34:21.468869 17252 solver.cpp:218] Iteration 13100 (35.9613 iter/s, 2.78077s/100 iters), loss = 0.489269
I0923 20:34:21.468869 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:34:21.468869 17252 solver.cpp:237]     Train net output #1: loss = 0.489269 (* 1 = 0.489269 loss)
I0923 20:34:21.468869 17252 sgd_solver.cpp:105] Iteration 13100, lr = 0.0001
I0923 20:34:24.262962 17252 solver.cpp:218] Iteration 13200 (35.795 iter/s, 2.79369s/100 iters), loss = 0.49956
I0923 20:34:24.262962 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:34:24.262962 17252 solver.cpp:237]     Train net output #1: loss = 0.49956 (* 1 = 0.49956 loss)
I0923 20:34:24.262962 17252 sgd_solver.cpp:105] Iteration 13200, lr = 0.0001
I0923 20:34:27.016152 17252 solver.cpp:218] Iteration 13300 (36.3271 iter/s, 2.75277s/100 iters), loss = 0.49128
I0923 20:34:27.016152 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:34:27.016152 17252 solver.cpp:237]     Train net output #1: loss = 0.49128 (* 1 = 0.49128 loss)
I0923 20:34:27.016152 17252 sgd_solver.cpp:105] Iteration 13300, lr = 0.0001
I0923 20:34:29.764295 17252 solver.cpp:218] Iteration 13400 (36.3832 iter/s, 2.74852s/100 iters), loss = 0.512945
I0923 20:34:29.765295 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:34:29.765295 17252 solver.cpp:237]     Train net output #1: loss = 0.512945 (* 1 = 0.512945 loss)
I0923 20:34:29.765295 17252 sgd_solver.cpp:105] Iteration 13400, lr = 0.0001
I0923 20:34:32.370961 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:34:32.504101 17252 solver.cpp:218] Iteration 13500 (36.5034 iter/s, 2.73947s/100 iters), loss = 0.486433
I0923 20:34:32.505101 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:34:32.505101 17252 solver.cpp:237]     Train net output #1: loss = 0.486433 (* 1 = 0.486433 loss)
I0923 20:34:32.505101 17252 sgd_solver.cpp:105] Iteration 13500, lr = 0.0001
I0923 20:34:35.230460 17252 solver.cpp:218] Iteration 13600 (36.6918 iter/s, 2.72541s/100 iters), loss = 0.533401
I0923 20:34:35.230460 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:34:35.230460 17252 solver.cpp:237]     Train net output #1: loss = 0.533401 (* 1 = 0.533401 loss)
I0923 20:34:35.230460 17252 sgd_solver.cpp:105] Iteration 13600, lr = 0.0001
I0923 20:34:37.958325 17252 solver.cpp:218] Iteration 13700 (36.6643 iter/s, 2.72745s/100 iters), loss = 0.515782
I0923 20:34:37.958325 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:34:37.958325 17252 solver.cpp:237]     Train net output #1: loss = 0.515782 (* 1 = 0.515782 loss)
I0923 20:34:37.958325 17252 sgd_solver.cpp:105] Iteration 13700, lr = 0.0001
I0923 20:34:40.686156 17252 solver.cpp:218] Iteration 13800 (36.6666 iter/s, 2.72728s/100 iters), loss = 0.501578
I0923 20:34:40.686156 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:34:40.686156 17252 solver.cpp:237]     Train net output #1: loss = 0.501578 (* 1 = 0.501578 loss)
I0923 20:34:40.686156 17252 sgd_solver.cpp:105] Iteration 13800, lr = 0.0001
I0923 20:34:43.426626 17252 solver.cpp:218] Iteration 13900 (36.4913 iter/s, 2.74038s/100 iters), loss = 0.544706
I0923 20:34:43.426626 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:34:43.426626 17252 solver.cpp:237]     Train net output #1: loss = 0.544706 (* 1 = 0.544706 loss)
I0923 20:34:43.426626 17252 sgd_solver.cpp:105] Iteration 13900, lr = 0.0001
I0923 20:34:46.034750 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:34:46.142346 17252 solver.cpp:330] Iteration 14000, Testing net (#0)
I0923 20:34:46.142848 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:34:46.664058 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:34:46.686074 17252 solver.cpp:397]     Test net output #0: accuracy = 0.781
I0923 20:34:46.686074 17252 solver.cpp:397]     Test net output #1: loss = 0.637361 (* 1 = 0.637361 loss)
I0923 20:34:46.711091 17252 solver.cpp:218] Iteration 14000 (30.443 iter/s, 3.28483s/100 iters), loss = 0.510497
I0923 20:34:46.712092 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:34:46.712092 17252 solver.cpp:237]     Train net output #1: loss = 0.510497 (* 1 = 0.510497 loss)
I0923 20:34:46.712092 17252 sgd_solver.cpp:105] Iteration 14000, lr = 0.0001
I0923 20:34:49.485600 17252 solver.cpp:218] Iteration 14100 (36.052 iter/s, 2.77377s/100 iters), loss = 0.435508
I0923 20:34:49.485600 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:34:49.485600 17252 solver.cpp:237]     Train net output #1: loss = 0.435508 (* 1 = 0.435508 loss)
I0923 20:34:49.485600 17252 sgd_solver.cpp:105] Iteration 14100, lr = 0.0001
I0923 20:34:52.232424 17252 solver.cpp:218] Iteration 14200 (36.4165 iter/s, 2.74601s/100 iters), loss = 0.513037
I0923 20:34:52.232424 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:34:52.232424 17252 solver.cpp:237]     Train net output #1: loss = 0.513037 (* 1 = 0.513037 loss)
I0923 20:34:52.232424 17252 sgd_solver.cpp:105] Iteration 14200, lr = 0.0001
I0923 20:34:54.958400 17252 solver.cpp:218] Iteration 14300 (36.6772 iter/s, 2.72649s/100 iters), loss = 0.506633
I0923 20:34:54.959400 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:34:54.959400 17252 solver.cpp:237]     Train net output #1: loss = 0.506633 (* 1 = 0.506633 loss)
I0923 20:34:54.959400 17252 sgd_solver.cpp:105] Iteration 14300, lr = 0.0001
I0923 20:34:57.686352 17252 solver.cpp:218] Iteration 14400 (36.6702 iter/s, 2.72701s/100 iters), loss = 0.525953
I0923 20:34:57.686352 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:34:57.686352 17252 solver.cpp:237]     Train net output #1: loss = 0.525953 (* 1 = 0.525953 loss)
I0923 20:34:57.686352 17252 sgd_solver.cpp:105] Iteration 14400, lr = 0.0001
I0923 20:35:00.297091 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:35:00.430701 17252 solver.cpp:218] Iteration 14500 (36.4428 iter/s, 2.74402s/100 iters), loss = 0.469201
I0923 20:35:00.430701 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:35:00.430701 17252 solver.cpp:237]     Train net output #1: loss = 0.469201 (* 1 = 0.469201 loss)
I0923 20:35:00.430701 17252 sgd_solver.cpp:105] Iteration 14500, lr = 0.0001
I0923 20:35:03.183481 17252 solver.cpp:218] Iteration 14600 (36.3338 iter/s, 2.75226s/100 iters), loss = 0.4743
I0923 20:35:03.183481 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:35:03.183481 17252 solver.cpp:237]     Train net output #1: loss = 0.4743 (* 1 = 0.4743 loss)
I0923 20:35:03.183481 17252 sgd_solver.cpp:105] Iteration 14600, lr = 0.0001
I0923 20:35:05.918359 17252 solver.cpp:218] Iteration 14700 (36.5605 iter/s, 2.73519s/100 iters), loss = 0.516291
I0923 20:35:05.918359 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:35:05.918359 17252 solver.cpp:237]     Train net output #1: loss = 0.516291 (* 1 = 0.516291 loss)
I0923 20:35:05.918359 17252 sgd_solver.cpp:105] Iteration 14700, lr = 0.0001
I0923 20:35:08.649454 17252 solver.cpp:218] Iteration 14800 (36.6192 iter/s, 2.73081s/100 iters), loss = 0.488321
I0923 20:35:08.649454 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:35:08.649454 17252 solver.cpp:237]     Train net output #1: loss = 0.488321 (* 1 = 0.488321 loss)
I0923 20:35:08.649454 17252 sgd_solver.cpp:105] Iteration 14800, lr = 0.0001
I0923 20:35:11.380441 17252 solver.cpp:218] Iteration 14900 (36.6241 iter/s, 2.73044s/100 iters), loss = 0.547141
I0923 20:35:11.380441 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:35:11.380441 17252 solver.cpp:237]     Train net output #1: loss = 0.547141 (* 1 = 0.547141 loss)
I0923 20:35:11.380441 17252 sgd_solver.cpp:105] Iteration 14900, lr = 0.0001
I0923 20:35:13.989871 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:35:14.098481 17252 solver.cpp:330] Iteration 15000, Testing net (#0)
I0923 20:35:14.098481 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:35:14.618899 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:35:14.638922 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7808
I0923 20:35:14.638922 17252 solver.cpp:397]     Test net output #1: loss = 0.637602 (* 1 = 0.637602 loss)
I0923 20:35:14.664950 17252 solver.cpp:218] Iteration 15000 (30.456 iter/s, 3.28343s/100 iters), loss = 0.514443
I0923 20:35:14.664950 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:35:14.664950 17252 solver.cpp:237]     Train net output #1: loss = 0.514443 (* 1 = 0.514443 loss)
I0923 20:35:14.664950 17252 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I0923 20:35:14.664950 17252 sgd_solver.cpp:105] Iteration 15000, lr = 1e-05
I0923 20:35:17.407627 17252 solver.cpp:218] Iteration 15100 (36.4653 iter/s, 2.74233s/100 iters), loss = 0.441513
I0923 20:35:17.407627 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:35:17.407627 17252 solver.cpp:237]     Train net output #1: loss = 0.441513 (* 1 = 0.441513 loss)
I0923 20:35:17.407627 17252 sgd_solver.cpp:105] Iteration 15100, lr = 1e-05
I0923 20:35:20.175261 17252 solver.cpp:218] Iteration 15200 (36.1271 iter/s, 2.76801s/100 iters), loss = 0.502625
I0923 20:35:20.175261 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:35:20.175261 17252 solver.cpp:237]     Train net output #1: loss = 0.502625 (* 1 = 0.502625 loss)
I0923 20:35:20.175261 17252 sgd_solver.cpp:105] Iteration 15200, lr = 1e-05
I0923 20:35:22.981458 17252 solver.cpp:218] Iteration 15300 (35.642 iter/s, 2.80568s/100 iters), loss = 0.468395
I0923 20:35:22.981458 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:35:22.981458 17252 solver.cpp:237]     Train net output #1: loss = 0.468395 (* 1 = 0.468395 loss)
I0923 20:35:22.981458 17252 sgd_solver.cpp:105] Iteration 15300, lr = 1e-05
I0923 20:35:25.791442 17252 solver.cpp:218] Iteration 15400 (35.5948 iter/s, 2.8094s/100 iters), loss = 0.515635
I0923 20:35:25.791442 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:35:25.791442 17252 solver.cpp:237]     Train net output #1: loss = 0.515635 (* 1 = 0.515635 loss)
I0923 20:35:25.791442 17252 sgd_solver.cpp:105] Iteration 15400, lr = 1e-05
I0923 20:35:28.474957 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:35:28.609019 17252 solver.cpp:218] Iteration 15500 (35.495 iter/s, 2.8173s/100 iters), loss = 0.509611
I0923 20:35:28.609019 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:35:28.609019 17252 solver.cpp:237]     Train net output #1: loss = 0.509611 (* 1 = 0.509611 loss)
I0923 20:35:28.609019 17252 sgd_solver.cpp:105] Iteration 15500, lr = 1e-05
I0923 20:35:31.339905 17252 solver.cpp:218] Iteration 15600 (36.6211 iter/s, 2.73067s/100 iters), loss = 0.500937
I0923 20:35:31.339905 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:35:31.339905 17252 solver.cpp:237]     Train net output #1: loss = 0.500937 (* 1 = 0.500937 loss)
I0923 20:35:31.339905 17252 sgd_solver.cpp:105] Iteration 15600, lr = 1e-05
I0923 20:35:34.078107 17252 solver.cpp:218] Iteration 15700 (36.5236 iter/s, 2.73795s/100 iters), loss = 0.493622
I0923 20:35:34.078107 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:35:34.078107 17252 solver.cpp:237]     Train net output #1: loss = 0.493622 (* 1 = 0.493622 loss)
I0923 20:35:34.078107 17252 sgd_solver.cpp:105] Iteration 15700, lr = 1e-05
I0923 20:35:36.826315 17252 solver.cpp:218] Iteration 15800 (36.3999 iter/s, 2.74726s/100 iters), loss = 0.469845
I0923 20:35:36.826315 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:35:36.826315 17252 solver.cpp:237]     Train net output #1: loss = 0.469845 (* 1 = 0.469845 loss)
I0923 20:35:36.826315 17252 sgd_solver.cpp:105] Iteration 15800, lr = 1e-05
I0923 20:35:39.621137 17252 solver.cpp:218] Iteration 15900 (35.7868 iter/s, 2.79432s/100 iters), loss = 0.502373
I0923 20:35:39.621137 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:35:39.621137 17252 solver.cpp:237]     Train net output #1: loss = 0.502373 (* 1 = 0.502373 loss)
I0923 20:35:39.621137 17252 sgd_solver.cpp:105] Iteration 15900, lr = 1e-05
I0923 20:35:42.285249 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:35:42.395339 17252 solver.cpp:330] Iteration 16000, Testing net (#0)
I0923 20:35:42.395339 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:35:42.921890 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:35:42.942458 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7808
I0923 20:35:42.942458 17252 solver.cpp:397]     Test net output #1: loss = 0.637082 (* 1 = 0.637082 loss)
I0923 20:35:42.968477 17252 solver.cpp:218] Iteration 16000 (29.8758 iter/s, 3.34719s/100 iters), loss = 0.486692
I0923 20:35:42.968477 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:35:42.968477 17252 solver.cpp:237]     Train net output #1: loss = 0.486692 (* 1 = 0.486692 loss)
I0923 20:35:42.968477 17252 sgd_solver.cpp:105] Iteration 16000, lr = 1e-05
I0923 20:35:45.729637 17252 solver.cpp:218] Iteration 16100 (36.2229 iter/s, 2.76069s/100 iters), loss = 0.585247
I0923 20:35:45.729637 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:35:45.729637 17252 solver.cpp:237]     Train net output #1: loss = 0.585247 (* 1 = 0.585247 loss)
I0923 20:35:45.729637 17252 sgd_solver.cpp:105] Iteration 16100, lr = 1e-05
I0923 20:35:48.471498 17252 solver.cpp:218] Iteration 16200 (36.4712 iter/s, 2.74189s/100 iters), loss = 0.536794
I0923 20:35:48.471498 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:35:48.471498 17252 solver.cpp:237]     Train net output #1: loss = 0.536794 (* 1 = 0.536794 loss)
I0923 20:35:48.471498 17252 sgd_solver.cpp:105] Iteration 16200, lr = 1e-05
I0923 20:35:51.280743 17252 solver.cpp:218] Iteration 16300 (35.6081 iter/s, 2.80835s/100 iters), loss = 0.527218
I0923 20:35:51.280743 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:35:51.280743 17252 solver.cpp:237]     Train net output #1: loss = 0.527218 (* 1 = 0.527218 loss)
I0923 20:35:51.280743 17252 sgd_solver.cpp:105] Iteration 16300, lr = 1e-05
I0923 20:35:54.076153 17252 solver.cpp:218] Iteration 16400 (35.772 iter/s, 2.79548s/100 iters), loss = 0.599572
I0923 20:35:54.076153 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:35:54.076153 17252 solver.cpp:237]     Train net output #1: loss = 0.599572 (* 1 = 0.599572 loss)
I0923 20:35:54.076153 17252 sgd_solver.cpp:105] Iteration 16400, lr = 1e-05
I0923 20:35:56.702329 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:35:56.836948 17252 solver.cpp:218] Iteration 16500 (36.23 iter/s, 2.76014s/100 iters), loss = 0.444472
I0923 20:35:56.836948 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:35:56.836948 17252 solver.cpp:237]     Train net output #1: loss = 0.444472 (* 1 = 0.444472 loss)
I0923 20:35:56.836948 17252 sgd_solver.cpp:105] Iteration 16500, lr = 1e-05
I0923 20:35:59.618415 17252 solver.cpp:218] Iteration 16600 (35.958 iter/s, 2.78102s/100 iters), loss = 0.489975
I0923 20:35:59.618415 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:35:59.618415 17252 solver.cpp:237]     Train net output #1: loss = 0.489975 (* 1 = 0.489975 loss)
I0923 20:35:59.618415 17252 sgd_solver.cpp:105] Iteration 16600, lr = 1e-05
I0923 20:36:02.410251 17252 solver.cpp:218] Iteration 16700 (35.8137 iter/s, 2.79223s/100 iters), loss = 0.467671
I0923 20:36:02.410251 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:36:02.411252 17252 solver.cpp:237]     Train net output #1: loss = 0.467671 (* 1 = 0.467671 loss)
I0923 20:36:02.411252 17252 sgd_solver.cpp:105] Iteration 16700, lr = 1e-05
I0923 20:36:05.214509 17252 solver.cpp:218] Iteration 16800 (35.6671 iter/s, 2.80371s/100 iters), loss = 0.500533
I0923 20:36:05.214509 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:36:05.214509 17252 solver.cpp:237]     Train net output #1: loss = 0.500533 (* 1 = 0.500533 loss)
I0923 20:36:05.214509 17252 sgd_solver.cpp:105] Iteration 16800, lr = 1e-05
I0923 20:36:08.018052 17252 solver.cpp:218] Iteration 16900 (35.6794 iter/s, 2.80274s/100 iters), loss = 0.493904
I0923 20:36:08.018052 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:36:08.018052 17252 solver.cpp:237]     Train net output #1: loss = 0.493904 (* 1 = 0.493904 loss)
I0923 20:36:08.018052 17252 sgd_solver.cpp:105] Iteration 16900, lr = 1e-05
I0923 20:36:10.661403 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:36:10.772485 17252 solver.cpp:330] Iteration 17000, Testing net (#0)
I0923 20:36:10.772485 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:36:11.302330 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:36:11.323343 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7813
I0923 20:36:11.323343 17252 solver.cpp:397]     Test net output #1: loss = 0.636824 (* 1 = 0.636824 loss)
I0923 20:36:11.349884 17252 solver.cpp:218] Iteration 17000 (30.0191 iter/s, 3.33121s/100 iters), loss = 0.472185
I0923 20:36:11.349884 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:36:11.349884 17252 solver.cpp:237]     Train net output #1: loss = 0.472185 (* 1 = 0.472185 loss)
I0923 20:36:11.349884 17252 sgd_solver.cpp:105] Iteration 17000, lr = 1e-05
I0923 20:36:14.153108 17252 solver.cpp:218] Iteration 17100 (35.678 iter/s, 2.80285s/100 iters), loss = 0.514114
I0923 20:36:14.153108 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:36:14.153108 17252 solver.cpp:237]     Train net output #1: loss = 0.514114 (* 1 = 0.514114 loss)
I0923 20:36:14.153108 17252 sgd_solver.cpp:105] Iteration 17100, lr = 1e-05
I0923 20:36:16.901175 17252 solver.cpp:218] Iteration 17200 (36.3941 iter/s, 2.7477s/100 iters), loss = 0.523599
I0923 20:36:16.901175 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:36:16.901175 17252 solver.cpp:237]     Train net output #1: loss = 0.523599 (* 1 = 0.523599 loss)
I0923 20:36:16.901175 17252 sgd_solver.cpp:105] Iteration 17200, lr = 1e-05
I0923 20:36:19.686731 17252 solver.cpp:218] Iteration 17300 (35.8939 iter/s, 2.78599s/100 iters), loss = 0.496638
I0923 20:36:19.686731 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:36:19.686731 17252 solver.cpp:237]     Train net output #1: loss = 0.496638 (* 1 = 0.496638 loss)
I0923 20:36:19.686731 17252 sgd_solver.cpp:105] Iteration 17300, lr = 1e-05
I0923 20:36:22.483364 17252 solver.cpp:218] Iteration 17400 (35.7608 iter/s, 2.79635s/100 iters), loss = 0.539014
I0923 20:36:22.484354 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:36:22.484354 17252 solver.cpp:237]     Train net output #1: loss = 0.539014 (* 1 = 0.539014 loss)
I0923 20:36:22.484354 17252 sgd_solver.cpp:105] Iteration 17400, lr = 1e-05
I0923 20:36:25.112037 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:36:25.248138 17252 solver.cpp:218] Iteration 17500 (36.1761 iter/s, 2.76426s/100 iters), loss = 0.490872
I0923 20:36:25.248138 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:36:25.248138 17252 solver.cpp:237]     Train net output #1: loss = 0.490872 (* 1 = 0.490872 loss)
I0923 20:36:25.248138 17252 sgd_solver.cpp:105] Iteration 17500, lr = 1e-05
I0923 20:36:28.044805 17252 solver.cpp:218] Iteration 17600 (35.7719 iter/s, 2.79549s/100 iters), loss = 0.417059
I0923 20:36:28.044805 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:36:28.044805 17252 solver.cpp:237]     Train net output #1: loss = 0.417059 (* 1 = 0.417059 loss)
I0923 20:36:28.044805 17252 sgd_solver.cpp:105] Iteration 17600, lr = 1e-05
I0923 20:36:30.805896 17252 solver.cpp:218] Iteration 17700 (36.2211 iter/s, 2.76082s/100 iters), loss = 0.480266
I0923 20:36:30.805896 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:36:30.805896 17252 solver.cpp:237]     Train net output #1: loss = 0.480266 (* 1 = 0.480266 loss)
I0923 20:36:30.805896 17252 sgd_solver.cpp:105] Iteration 17700, lr = 1e-05
I0923 20:36:33.551980 17252 solver.cpp:218] Iteration 17800 (36.4195 iter/s, 2.74578s/100 iters), loss = 0.437281
I0923 20:36:33.551980 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:36:33.551980 17252 solver.cpp:237]     Train net output #1: loss = 0.437281 (* 1 = 0.437281 loss)
I0923 20:36:33.551980 17252 sgd_solver.cpp:105] Iteration 17800, lr = 1e-05
I0923 20:36:36.351596 17252 solver.cpp:218] Iteration 17900 (35.7169 iter/s, 2.79979s/100 iters), loss = 0.527466
I0923 20:36:36.351596 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:36:36.351596 17252 solver.cpp:237]     Train net output #1: loss = 0.527466 (* 1 = 0.527466 loss)
I0923 20:36:36.351596 17252 sgd_solver.cpp:105] Iteration 17900, lr = 1e-05
I0923 20:36:39.012184 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:36:39.120313 17252 solver.cpp:330] Iteration 18000, Testing net (#0)
I0923 20:36:39.120313 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:36:39.641772 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:36:39.661797 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7807
I0923 20:36:39.661797 17252 solver.cpp:397]     Test net output #1: loss = 0.636763 (* 1 = 0.636763 loss)
I0923 20:36:39.688336 17252 solver.cpp:218] Iteration 18000 (29.9766 iter/s, 3.33594s/100 iters), loss = 0.466784
I0923 20:36:39.688336 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:36:39.688336 17252 solver.cpp:237]     Train net output #1: loss = 0.466784 (* 1 = 0.466784 loss)
I0923 20:36:39.688336 17252 sgd_solver.cpp:105] Iteration 18000, lr = 1e-05
I0923 20:36:42.452941 17252 solver.cpp:218] Iteration 18100 (36.1685 iter/s, 2.76483s/100 iters), loss = 0.463636
I0923 20:36:42.452941 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:36:42.452941 17252 solver.cpp:237]     Train net output #1: loss = 0.463636 (* 1 = 0.463636 loss)
I0923 20:36:42.452941 17252 sgd_solver.cpp:105] Iteration 18100, lr = 1e-05
I0923 20:36:45.248373 17252 solver.cpp:218] Iteration 18200 (35.7778 iter/s, 2.79503s/100 iters), loss = 0.475633
I0923 20:36:45.248373 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:36:45.248373 17252 solver.cpp:237]     Train net output #1: loss = 0.475633 (* 1 = 0.475633 loss)
I0923 20:36:45.248373 17252 sgd_solver.cpp:105] Iteration 18200, lr = 1e-05
I0923 20:36:48.040305 17252 solver.cpp:218] Iteration 18300 (35.8236 iter/s, 2.79145s/100 iters), loss = 0.46367
I0923 20:36:48.040305 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:36:48.040305 17252 solver.cpp:237]     Train net output #1: loss = 0.46367 (* 1 = 0.46367 loss)
I0923 20:36:48.040305 17252 sgd_solver.cpp:105] Iteration 18300, lr = 1e-05
I0923 20:36:50.847900 17252 solver.cpp:218] Iteration 18400 (35.6202 iter/s, 2.8074s/100 iters), loss = 0.571082
I0923 20:36:50.847900 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:36:50.847900 17252 solver.cpp:237]     Train net output #1: loss = 0.571082 (* 1 = 0.571082 loss)
I0923 20:36:50.847900 17252 sgd_solver.cpp:105] Iteration 18400, lr = 1e-05
I0923 20:36:53.512137 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:36:53.649287 17252 solver.cpp:218] Iteration 18500 (35.7065 iter/s, 2.80061s/100 iters), loss = 0.464329
I0923 20:36:53.649287 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:36:53.649287 17252 solver.cpp:237]     Train net output #1: loss = 0.464329 (* 1 = 0.464329 loss)
I0923 20:36:53.649287 17252 sgd_solver.cpp:105] Iteration 18500, lr = 1e-05
I0923 20:36:56.454793 17252 solver.cpp:218] Iteration 18600 (35.6467 iter/s, 2.80531s/100 iters), loss = 0.47314
I0923 20:36:56.454793 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:36:56.454793 17252 solver.cpp:237]     Train net output #1: loss = 0.47314 (* 1 = 0.47314 loss)
I0923 20:36:56.454793 17252 sgd_solver.cpp:105] Iteration 18600, lr = 1e-05
I0923 20:36:59.238243 17252 solver.cpp:218] Iteration 18700 (35.9296 iter/s, 2.78322s/100 iters), loss = 0.519681
I0923 20:36:59.238243 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:36:59.238243 17252 solver.cpp:237]     Train net output #1: loss = 0.519681 (* 1 = 0.519681 loss)
I0923 20:36:59.238243 17252 sgd_solver.cpp:105] Iteration 18700, lr = 1e-05
I0923 20:37:02.050915 17252 solver.cpp:218] Iteration 18800 (35.5554 iter/s, 2.81251s/100 iters), loss = 0.482631
I0923 20:37:02.050915 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:37:02.050915 17252 solver.cpp:237]     Train net output #1: loss = 0.482631 (* 1 = 0.482631 loss)
I0923 20:37:02.050915 17252 sgd_solver.cpp:105] Iteration 18800, lr = 1e-05
I0923 20:37:04.856276 17252 solver.cpp:218] Iteration 18900 (35.6586 iter/s, 2.80437s/100 iters), loss = 0.576156
I0923 20:37:04.856276 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:37:04.856276 17252 solver.cpp:237]     Train net output #1: loss = 0.576156 (* 1 = 0.576156 loss)
I0923 20:37:04.856276 17252 sgd_solver.cpp:105] Iteration 18900, lr = 1e-05
I0923 20:37:07.545872 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:37:07.656551 17252 solver.cpp:330] Iteration 19000, Testing net (#0)
I0923 20:37:07.656551 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:37:08.191756 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:37:08.213760 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7811
I0923 20:37:08.213760 17252 solver.cpp:397]     Test net output #1: loss = 0.636662 (* 1 = 0.636662 loss)
I0923 20:37:08.239905 17252 solver.cpp:218] Iteration 19000 (29.558 iter/s, 3.38318s/100 iters), loss = 0.449127
I0923 20:37:08.239905 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:37:08.239905 17252 solver.cpp:237]     Train net output #1: loss = 0.449127 (* 1 = 0.449127 loss)
I0923 20:37:08.239905 17252 sgd_solver.cpp:105] Iteration 19000, lr = 1e-05
I0923 20:37:11.057869 17252 solver.cpp:218] Iteration 19100 (35.4892 iter/s, 2.81776s/100 iters), loss = 0.583236
I0923 20:37:11.057869 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:37:11.057869 17252 solver.cpp:237]     Train net output #1: loss = 0.583236 (* 1 = 0.583236 loss)
I0923 20:37:11.057869 17252 sgd_solver.cpp:105] Iteration 19100, lr = 1e-05
I0923 20:37:13.838240 17252 solver.cpp:218] Iteration 19200 (35.9617 iter/s, 2.78073s/100 iters), loss = 0.509772
I0923 20:37:13.838240 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:37:13.838240 17252 solver.cpp:237]     Train net output #1: loss = 0.509772 (* 1 = 0.509772 loss)
I0923 20:37:13.838240 17252 sgd_solver.cpp:105] Iteration 19200, lr = 1e-05
I0923 20:37:16.613009 17252 solver.cpp:218] Iteration 19300 (36.0544 iter/s, 2.77359s/100 iters), loss = 0.533998
I0923 20:37:16.613009 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:37:16.613009 17252 solver.cpp:237]     Train net output #1: loss = 0.533998 (* 1 = 0.533998 loss)
I0923 20:37:16.613009 17252 sgd_solver.cpp:105] Iteration 19300, lr = 1e-05
I0923 20:37:19.351907 17252 solver.cpp:218] Iteration 19400 (36.5062 iter/s, 2.73926s/100 iters), loss = 0.471361
I0923 20:37:19.351907 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:37:19.351907 17252 solver.cpp:237]     Train net output #1: loss = 0.471361 (* 1 = 0.471361 loss)
I0923 20:37:19.351907 17252 sgd_solver.cpp:105] Iteration 19400, lr = 1e-05
I0923 20:37:21.951949 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:37:22.085638 17252 solver.cpp:218] Iteration 19500 (36.5815 iter/s, 2.73362s/100 iters), loss = 0.45734
I0923 20:37:22.085638 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:37:22.085638 17252 solver.cpp:237]     Train net output #1: loss = 0.45734 (* 1 = 0.45734 loss)
I0923 20:37:22.086638 17252 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I0923 20:37:24.829840 17252 solver.cpp:218] Iteration 19600 (36.4545 iter/s, 2.74315s/100 iters), loss = 0.483222
I0923 20:37:24.829840 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:37:24.829840 17252 solver.cpp:237]     Train net output #1: loss = 0.483222 (* 1 = 0.483222 loss)
I0923 20:37:24.829840 17252 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I0923 20:37:27.566395 17252 solver.cpp:218] Iteration 19700 (36.5384 iter/s, 2.73685s/100 iters), loss = 0.473335
I0923 20:37:27.566395 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:37:27.566395 17252 solver.cpp:237]     Train net output #1: loss = 0.473335 (* 1 = 0.473335 loss)
I0923 20:37:27.566395 17252 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I0923 20:37:30.292358 17252 solver.cpp:218] Iteration 19800 (36.6972 iter/s, 2.725s/100 iters), loss = 0.476087
I0923 20:37:30.292358 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:37:30.292358 17252 solver.cpp:237]     Train net output #1: loss = 0.476087 (* 1 = 0.476087 loss)
I0923 20:37:30.292358 17252 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I0923 20:37:33.045686 17252 solver.cpp:218] Iteration 19900 (36.3255 iter/s, 2.75289s/100 iters), loss = 0.543937
I0923 20:37:33.045686 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0923 20:37:33.045686 17252 solver.cpp:237]     Train net output #1: loss = 0.543937 (* 1 = 0.543937 loss)
I0923 20:37:33.045686 17252 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I0923 20:37:35.685286 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:37:35.792897 17252 solver.cpp:330] Iteration 20000, Testing net (#0)
I0923 20:37:35.792897 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:37:36.328352 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:37:36.349155 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7815
I0923 20:37:36.349155 17252 solver.cpp:397]     Test net output #1: loss = 0.636653 (* 1 = 0.636653 loss)
I0923 20:37:36.376173 17252 solver.cpp:218] Iteration 20000 (30.0289 iter/s, 3.33012s/100 iters), loss = 0.448694
I0923 20:37:36.376173 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:37:36.376173 17252 solver.cpp:237]     Train net output #1: loss = 0.448694 (* 1 = 0.448694 loss)
I0923 20:37:36.376173 17252 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I0923 20:37:39.168334 17252 solver.cpp:218] Iteration 20100 (35.8119 iter/s, 2.79237s/100 iters), loss = 0.49521
I0923 20:37:39.168334 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:37:39.168334 17252 solver.cpp:237]     Train net output #1: loss = 0.49521 (* 1 = 0.49521 loss)
I0923 20:37:39.168334 17252 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I0923 20:37:41.903090 17252 solver.cpp:218] Iteration 20200 (36.5754 iter/s, 2.73408s/100 iters), loss = 0.449082
I0923 20:37:41.903090 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:37:41.903090 17252 solver.cpp:237]     Train net output #1: loss = 0.449082 (* 1 = 0.449082 loss)
I0923 20:37:41.903090 17252 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I0923 20:37:44.635366 17252 solver.cpp:218] Iteration 20300 (36.6037 iter/s, 2.73196s/100 iters), loss = 0.456894
I0923 20:37:44.635366 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:37:44.635366 17252 solver.cpp:237]     Train net output #1: loss = 0.456894 (* 1 = 0.456894 loss)
I0923 20:37:44.635366 17252 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I0923 20:37:47.394374 17252 solver.cpp:218] Iteration 20400 (36.2538 iter/s, 2.75833s/100 iters), loss = 0.523712
I0923 20:37:47.394374 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:37:47.394374 17252 solver.cpp:237]     Train net output #1: loss = 0.523712 (* 1 = 0.523712 loss)
I0923 20:37:47.394374 17252 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I0923 20:37:50.004485 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:37:50.137110 17252 solver.cpp:218] Iteration 20500 (36.4543 iter/s, 2.74316s/100 iters), loss = 0.460502
I0923 20:37:50.138111 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:37:50.138111 17252 solver.cpp:237]     Train net output #1: loss = 0.460502 (* 1 = 0.460502 loss)
I0923 20:37:50.138111 17252 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I0923 20:37:52.926928 17252 solver.cpp:218] Iteration 20600 (35.8585 iter/s, 2.78874s/100 iters), loss = 0.4467
I0923 20:37:52.926928 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:37:52.926928 17252 solver.cpp:237]     Train net output #1: loss = 0.4467 (* 1 = 0.4467 loss)
I0923 20:37:52.926928 17252 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I0923 20:37:55.711031 17252 solver.cpp:218] Iteration 20700 (35.9218 iter/s, 2.78382s/100 iters), loss = 0.452561
I0923 20:37:55.711031 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:37:55.711031 17252 solver.cpp:237]     Train net output #1: loss = 0.452561 (* 1 = 0.452561 loss)
I0923 20:37:55.711031 17252 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I0923 20:37:58.443600 17252 solver.cpp:218] Iteration 20800 (36.5979 iter/s, 2.7324s/100 iters), loss = 0.535095
I0923 20:37:58.443600 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:37:58.443600 17252 solver.cpp:237]     Train net output #1: loss = 0.535095 (* 1 = 0.535095 loss)
I0923 20:37:58.443600 17252 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I0923 20:38:01.167841 17252 solver.cpp:218] Iteration 20900 (36.7076 iter/s, 2.72423s/100 iters), loss = 0.57975
I0923 20:38:01.167841 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 20:38:01.167841 17252 solver.cpp:237]     Train net output #1: loss = 0.57975 (* 1 = 0.57975 loss)
I0923 20:38:01.167841 17252 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I0923 20:38:03.760078 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:38:03.868371 17252 solver.cpp:330] Iteration 21000, Testing net (#0)
I0923 20:38:03.868371 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:38:04.387823 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:38:04.407840 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7812
I0923 20:38:04.407840 17252 solver.cpp:397]     Test net output #1: loss = 0.63668 (* 1 = 0.63668 loss)
I0923 20:38:04.432888 17252 solver.cpp:218] Iteration 21000 (30.6333 iter/s, 3.26442s/100 iters), loss = 0.441048
I0923 20:38:04.432888 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:38:04.432888 17252 solver.cpp:237]     Train net output #1: loss = 0.441048 (* 1 = 0.441048 loss)
I0923 20:38:04.432888 17252 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I0923 20:38:07.157867 17252 solver.cpp:218] Iteration 21100 (36.7024 iter/s, 2.72461s/100 iters), loss = 0.51185
I0923 20:38:07.157867 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:38:07.157867 17252 solver.cpp:237]     Train net output #1: loss = 0.51185 (* 1 = 0.51185 loss)
I0923 20:38:07.157867 17252 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I0923 20:38:09.885512 17252 solver.cpp:218] Iteration 21200 (36.659 iter/s, 2.72784s/100 iters), loss = 0.449507
I0923 20:38:09.886520 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:38:09.886520 17252 solver.cpp:237]     Train net output #1: loss = 0.449507 (* 1 = 0.449507 loss)
I0923 20:38:09.886520 17252 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I0923 20:38:12.610689 17252 solver.cpp:218] Iteration 21300 (36.709 iter/s, 2.72413s/100 iters), loss = 0.549628
I0923 20:38:12.610689 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:38:12.610689 17252 solver.cpp:237]     Train net output #1: loss = 0.549628 (* 1 = 0.549628 loss)
I0923 20:38:12.610689 17252 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I0923 20:38:15.337761 17252 solver.cpp:218] Iteration 21400 (36.6764 iter/s, 2.72655s/100 iters), loss = 0.504184
I0923 20:38:15.337761 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:38:15.337761 17252 solver.cpp:237]     Train net output #1: loss = 0.504184 (* 1 = 0.504184 loss)
I0923 20:38:15.337761 17252 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I0923 20:38:17.925674 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:38:18.058064 17252 solver.cpp:218] Iteration 21500 (36.7553 iter/s, 2.72069s/100 iters), loss = 0.447685
I0923 20:38:18.058064 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:38:18.058064 17252 solver.cpp:237]     Train net output #1: loss = 0.447685 (* 1 = 0.447685 loss)
I0923 20:38:18.058064 17252 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I0923 20:38:20.785676 17252 solver.cpp:218] Iteration 21600 (36.6671 iter/s, 2.72724s/100 iters), loss = 0.410379
I0923 20:38:20.785676 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 20:38:20.785676 17252 solver.cpp:237]     Train net output #1: loss = 0.410379 (* 1 = 0.410379 loss)
I0923 20:38:20.785676 17252 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I0923 20:38:23.511106 17252 solver.cpp:218] Iteration 21700 (36.6978 iter/s, 2.72496s/100 iters), loss = 0.530646
I0923 20:38:23.511106 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:38:23.511106 17252 solver.cpp:237]     Train net output #1: loss = 0.530646 (* 1 = 0.530646 loss)
I0923 20:38:23.511106 17252 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I0923 20:38:26.241114 17252 solver.cpp:218] Iteration 21800 (36.6316 iter/s, 2.72988s/100 iters), loss = 0.471894
I0923 20:38:26.241114 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:38:26.241114 17252 solver.cpp:237]     Train net output #1: loss = 0.471894 (* 1 = 0.471894 loss)
I0923 20:38:26.241114 17252 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I0923 20:38:28.970916 17252 solver.cpp:218] Iteration 21900 (36.6407 iter/s, 2.7292s/100 iters), loss = 0.524825
I0923 20:38:28.970916 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:38:28.970916 17252 solver.cpp:237]     Train net output #1: loss = 0.524825 (* 1 = 0.524825 loss)
I0923 20:38:28.970916 17252 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I0923 20:38:31.569012 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:38:31.681618 17252 solver.cpp:330] Iteration 22000, Testing net (#0)
I0923 20:38:31.681618 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:38:32.201000 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:38:32.220013 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7816
I0923 20:38:32.221014 17252 solver.cpp:397]     Test net output #1: loss = 0.636589 (* 1 = 0.636589 loss)
I0923 20:38:32.246352 17252 solver.cpp:218] Iteration 22000 (30.5387 iter/s, 3.27453s/100 iters), loss = 0.479817
I0923 20:38:32.246352 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:38:32.246352 17252 solver.cpp:237]     Train net output #1: loss = 0.479817 (* 1 = 0.479817 loss)
I0923 20:38:32.246352 17252 sgd_solver.cpp:105] Iteration 22000, lr = 1e-05
I0923 20:38:34.974131 17252 solver.cpp:218] Iteration 22100 (36.6523 iter/s, 2.72834s/100 iters), loss = 0.506087
I0923 20:38:34.974131 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:38:34.974131 17252 solver.cpp:237]     Train net output #1: loss = 0.506087 (* 1 = 0.506087 loss)
I0923 20:38:34.974131 17252 sgd_solver.cpp:105] Iteration 22100, lr = 1e-05
I0923 20:38:37.702728 17252 solver.cpp:218] Iteration 22200 (36.6562 iter/s, 2.72806s/100 iters), loss = 0.458397
I0923 20:38:37.702728 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 20:38:37.702728 17252 solver.cpp:237]     Train net output #1: loss = 0.458397 (* 1 = 0.458397 loss)
I0923 20:38:37.702728 17252 sgd_solver.cpp:105] Iteration 22200, lr = 1e-05
I0923 20:38:40.427438 17252 solver.cpp:218] Iteration 22300 (36.7043 iter/s, 2.72448s/100 iters), loss = 0.507157
I0923 20:38:40.427438 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:38:40.427438 17252 solver.cpp:237]     Train net output #1: loss = 0.507157 (* 1 = 0.507157 loss)
I0923 20:38:40.427438 17252 sgd_solver.cpp:105] Iteration 22300, lr = 1e-05
I0923 20:38:43.157821 17252 solver.cpp:218] Iteration 22400 (36.6367 iter/s, 2.7295s/100 iters), loss = 0.543141
I0923 20:38:43.157821 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:38:43.157821 17252 solver.cpp:237]     Train net output #1: loss = 0.543141 (* 1 = 0.543141 loss)
I0923 20:38:43.157821 17252 sgd_solver.cpp:105] Iteration 22400, lr = 1e-05
I0923 20:38:45.755713 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:38:45.889823 17252 solver.cpp:218] Iteration 22500 (36.6084 iter/s, 2.73161s/100 iters), loss = 0.479067
I0923 20:38:45.889823 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:38:45.889823 17252 solver.cpp:237]     Train net output #1: loss = 0.479067 (* 1 = 0.479067 loss)
I0923 20:38:45.889823 17252 sgd_solver.cpp:105] Iteration 22500, lr = 1e-05
I0923 20:38:48.616704 17252 solver.cpp:218] Iteration 22600 (36.6663 iter/s, 2.7273s/100 iters), loss = 0.499881
I0923 20:38:48.616704 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:38:48.616704 17252 solver.cpp:237]     Train net output #1: loss = 0.499881 (* 1 = 0.499881 loss)
I0923 20:38:48.616704 17252 sgd_solver.cpp:105] Iteration 22600, lr = 1e-05
I0923 20:38:51.339692 17252 solver.cpp:218] Iteration 22700 (36.7387 iter/s, 2.72193s/100 iters), loss = 0.500554
I0923 20:38:51.339692 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:38:51.339692 17252 solver.cpp:237]     Train net output #1: loss = 0.500554 (* 1 = 0.500554 loss)
I0923 20:38:51.339692 17252 sgd_solver.cpp:105] Iteration 22700, lr = 1e-05
I0923 20:38:54.062974 17252 solver.cpp:218] Iteration 22800 (36.7255 iter/s, 2.7229s/100 iters), loss = 0.453674
I0923 20:38:54.062974 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:38:54.062974 17252 solver.cpp:237]     Train net output #1: loss = 0.453674 (* 1 = 0.453674 loss)
I0923 20:38:54.062974 17252 sgd_solver.cpp:105] Iteration 22800, lr = 1e-05
I0923 20:38:56.791123 17252 solver.cpp:218] Iteration 22900 (36.6521 iter/s, 2.72836s/100 iters), loss = 0.560014
I0923 20:38:56.791123 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:38:56.791123 17252 solver.cpp:237]     Train net output #1: loss = 0.560014 (* 1 = 0.560014 loss)
I0923 20:38:56.791123 17252 sgd_solver.cpp:105] Iteration 22900, lr = 1e-05
I0923 20:38:59.390722 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:38:59.497843 17252 solver.cpp:330] Iteration 23000, Testing net (#0)
I0923 20:38:59.497843 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:39:00.018177 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:39:00.039206 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7811
I0923 20:39:00.039206 17252 solver.cpp:397]     Test net output #1: loss = 0.636369 (* 1 = 0.636369 loss)
I0923 20:39:00.064736 17252 solver.cpp:218] Iteration 23000 (30.5579 iter/s, 3.27247s/100 iters), loss = 0.508005
I0923 20:39:00.064736 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:39:00.064736 17252 solver.cpp:237]     Train net output #1: loss = 0.508005 (* 1 = 0.508005 loss)
I0923 20:39:00.064736 17252 sgd_solver.cpp:105] Iteration 23000, lr = 1e-05
I0923 20:39:02.814555 17252 solver.cpp:218] Iteration 23100 (36.3626 iter/s, 2.75008s/100 iters), loss = 0.485392
I0923 20:39:02.814555 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:39:02.814555 17252 solver.cpp:237]     Train net output #1: loss = 0.485392 (* 1 = 0.485392 loss)
I0923 20:39:02.814555 17252 sgd_solver.cpp:105] Iteration 23100, lr = 1e-05
I0923 20:39:05.617823 17252 solver.cpp:218] Iteration 23200 (35.6774 iter/s, 2.8029s/100 iters), loss = 0.534511
I0923 20:39:05.617823 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:39:05.617823 17252 solver.cpp:237]     Train net output #1: loss = 0.534511 (* 1 = 0.534511 loss)
I0923 20:39:05.617823 17252 sgd_solver.cpp:105] Iteration 23200, lr = 1e-05
I0923 20:39:08.436190 17252 solver.cpp:218] Iteration 23300 (35.485 iter/s, 2.81809s/100 iters), loss = 0.489749
I0923 20:39:08.436190 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:39:08.436190 17252 solver.cpp:237]     Train net output #1: loss = 0.489749 (* 1 = 0.489749 loss)
I0923 20:39:08.436190 17252 sgd_solver.cpp:105] Iteration 23300, lr = 1e-05
I0923 20:39:11.230515 17252 solver.cpp:218] Iteration 23400 (35.8007 iter/s, 2.79324s/100 iters), loss = 0.51279
I0923 20:39:11.230515 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:39:11.230515 17252 solver.cpp:237]     Train net output #1: loss = 0.51279 (* 1 = 0.51279 loss)
I0923 20:39:11.230515 17252 sgd_solver.cpp:105] Iteration 23400, lr = 1e-05
I0923 20:39:13.833132 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:39:13.968317 17252 solver.cpp:218] Iteration 23500 (36.5287 iter/s, 2.73758s/100 iters), loss = 0.472392
I0923 20:39:13.968317 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:39:13.968317 17252 solver.cpp:237]     Train net output #1: loss = 0.472392 (* 1 = 0.472392 loss)
I0923 20:39:13.968317 17252 sgd_solver.cpp:105] Iteration 23500, lr = 1e-05
I0923 20:39:16.763819 17252 solver.cpp:218] Iteration 23600 (35.7697 iter/s, 2.79566s/100 iters), loss = 0.517165
I0923 20:39:16.763819 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:39:16.763819 17252 solver.cpp:237]     Train net output #1: loss = 0.517165 (* 1 = 0.517165 loss)
I0923 20:39:16.763819 17252 sgd_solver.cpp:105] Iteration 23600, lr = 1e-05
I0923 20:39:19.554060 17252 solver.cpp:218] Iteration 23700 (35.8492 iter/s, 2.78947s/100 iters), loss = 0.505414
I0923 20:39:19.554060 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:39:19.554060 17252 solver.cpp:237]     Train net output #1: loss = 0.505414 (* 1 = 0.505414 loss)
I0923 20:39:19.554060 17252 sgd_solver.cpp:105] Iteration 23700, lr = 1e-05
I0923 20:39:22.336848 17252 solver.cpp:218] Iteration 23800 (35.9314 iter/s, 2.78308s/100 iters), loss = 0.476858
I0923 20:39:22.337839 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:39:22.337839 17252 solver.cpp:237]     Train net output #1: loss = 0.476858 (* 1 = 0.476858 loss)
I0923 20:39:22.337839 17252 sgd_solver.cpp:105] Iteration 23800, lr = 1e-05
I0923 20:39:25.149828 17252 solver.cpp:218] Iteration 23900 (35.5663 iter/s, 2.81165s/100 iters), loss = 0.527856
I0923 20:39:25.149828 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:39:25.149828 17252 solver.cpp:237]     Train net output #1: loss = 0.527856 (* 1 = 0.527856 loss)
I0923 20:39:25.149828 17252 sgd_solver.cpp:105] Iteration 23900, lr = 1e-05
I0923 20:39:27.772650 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:39:27.881250 17252 solver.cpp:330] Iteration 24000, Testing net (#0)
I0923 20:39:27.881250 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:39:28.399251 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:39:28.420295 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7812
I0923 20:39:28.420295 17252 solver.cpp:397]     Test net output #1: loss = 0.636312 (* 1 = 0.636312 loss)
I0923 20:39:28.445294 17252 solver.cpp:218] Iteration 24000 (30.3422 iter/s, 3.29574s/100 iters), loss = 0.468265
I0923 20:39:28.445294 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:39:28.445294 17252 solver.cpp:237]     Train net output #1: loss = 0.468265 (* 1 = 0.468265 loss)
I0923 20:39:28.445294 17252 sgd_solver.cpp:105] Iteration 24000, lr = 1e-05
I0923 20:39:31.174736 17252 solver.cpp:218] Iteration 24100 (36.6406 iter/s, 2.72921s/100 iters), loss = 0.517317
I0923 20:39:31.174736 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:39:31.174736 17252 solver.cpp:237]     Train net output #1: loss = 0.517317 (* 1 = 0.517317 loss)
I0923 20:39:31.174736 17252 sgd_solver.cpp:105] Iteration 24100, lr = 1e-05
I0923 20:39:33.906862 17252 solver.cpp:218] Iteration 24200 (36.6128 iter/s, 2.73129s/100 iters), loss = 0.527356
I0923 20:39:33.906862 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:39:33.906862 17252 solver.cpp:237]     Train net output #1: loss = 0.527356 (* 1 = 0.527356 loss)
I0923 20:39:33.906862 17252 sgd_solver.cpp:105] Iteration 24200, lr = 1e-05
I0923 20:39:36.633569 17252 solver.cpp:218] Iteration 24300 (36.6722 iter/s, 2.72686s/100 iters), loss = 0.505035
I0923 20:39:36.633569 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:39:36.633569 17252 solver.cpp:237]     Train net output #1: loss = 0.505035 (* 1 = 0.505035 loss)
I0923 20:39:36.633569 17252 sgd_solver.cpp:105] Iteration 24300, lr = 1e-05
I0923 20:39:39.363891 17252 solver.cpp:218] Iteration 24400 (36.64 iter/s, 2.72926s/100 iters), loss = 0.511195
I0923 20:39:39.363891 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:39:39.363891 17252 solver.cpp:237]     Train net output #1: loss = 0.511195 (* 1 = 0.511195 loss)
I0923 20:39:39.363891 17252 sgd_solver.cpp:105] Iteration 24400, lr = 1e-05
I0923 20:39:41.980618 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:39:42.118441 17252 solver.cpp:218] Iteration 24500 (36.3085 iter/s, 2.75418s/100 iters), loss = 0.444886
I0923 20:39:42.118441 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:39:42.118441 17252 solver.cpp:237]     Train net output #1: loss = 0.444886 (* 1 = 0.444886 loss)
I0923 20:39:42.118441 17252 sgd_solver.cpp:105] Iteration 24500, lr = 1e-05
I0923 20:39:44.925235 17252 solver.cpp:218] Iteration 24600 (35.6256 iter/s, 2.80697s/100 iters), loss = 0.484838
I0923 20:39:44.925235 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:39:44.925235 17252 solver.cpp:237]     Train net output #1: loss = 0.484838 (* 1 = 0.484838 loss)
I0923 20:39:44.925235 17252 sgd_solver.cpp:105] Iteration 24600, lr = 1e-05
I0923 20:39:47.721870 17252 solver.cpp:218] Iteration 24700 (35.7698 iter/s, 2.79565s/100 iters), loss = 0.487523
I0923 20:39:47.721870 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:39:47.721870 17252 solver.cpp:237]     Train net output #1: loss = 0.487523 (* 1 = 0.487523 loss)
I0923 20:39:47.721870 17252 sgd_solver.cpp:105] Iteration 24700, lr = 1e-05
I0923 20:39:50.499214 17252 solver.cpp:218] Iteration 24800 (36.0105 iter/s, 2.77697s/100 iters), loss = 0.509881
I0923 20:39:50.499214 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:39:50.499214 17252 solver.cpp:237]     Train net output #1: loss = 0.509881 (* 1 = 0.509881 loss)
I0923 20:39:50.499214 17252 sgd_solver.cpp:105] Iteration 24800, lr = 1e-05
I0923 20:39:53.250887 17252 solver.cpp:218] Iteration 24900 (36.3388 iter/s, 2.75188s/100 iters), loss = 0.513596
I0923 20:39:53.250887 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:39:53.250887 17252 solver.cpp:237]     Train net output #1: loss = 0.513596 (* 1 = 0.513596 loss)
I0923 20:39:53.250887 17252 sgd_solver.cpp:105] Iteration 24900, lr = 1e-05
I0923 20:39:55.911371 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:39:56.021994 17252 solver.cpp:330] Iteration 25000, Testing net (#0)
I0923 20:39:56.022495 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:39:56.552121 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:39:56.573137 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7804
I0923 20:39:56.573137 17252 solver.cpp:397]     Test net output #1: loss = 0.636371 (* 1 = 0.636371 loss)
I0923 20:39:56.598165 17252 solver.cpp:218] Iteration 25000 (29.8762 iter/s, 3.34714s/100 iters), loss = 0.503463
I0923 20:39:56.598165 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:39:56.598165 17252 solver.cpp:237]     Train net output #1: loss = 0.503463 (* 1 = 0.503463 loss)
I0923 20:39:56.598165 17252 sgd_solver.cpp:46] MultiStep Status: Iteration 25000, step = 4
I0923 20:39:56.598165 17252 sgd_solver.cpp:105] Iteration 25000, lr = 1e-06
I0923 20:39:59.402096 17252 solver.cpp:218] Iteration 25100 (35.672 iter/s, 2.80332s/100 iters), loss = 0.515787
I0923 20:39:59.402096 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:39:59.402096 17252 solver.cpp:237]     Train net output #1: loss = 0.515787 (* 1 = 0.515787 loss)
I0923 20:39:59.402096 17252 sgd_solver.cpp:105] Iteration 25100, lr = 1e-06
I0923 20:40:02.237407 17252 solver.cpp:218] Iteration 25200 (35.2696 iter/s, 2.8353s/100 iters), loss = 0.493963
I0923 20:40:02.238407 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:40:02.238407 17252 solver.cpp:237]     Train net output #1: loss = 0.493963 (* 1 = 0.493963 loss)
I0923 20:40:02.238407 17252 sgd_solver.cpp:105] Iteration 25200, lr = 1e-06
I0923 20:40:05.034657 17252 solver.cpp:218] Iteration 25300 (35.7641 iter/s, 2.7961s/100 iters), loss = 0.490615
I0923 20:40:05.034657 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:40:05.034657 17252 solver.cpp:237]     Train net output #1: loss = 0.490615 (* 1 = 0.490615 loss)
I0923 20:40:05.034657 17252 sgd_solver.cpp:105] Iteration 25300, lr = 1e-06
I0923 20:40:07.817057 17252 solver.cpp:218] Iteration 25400 (35.9465 iter/s, 2.78191s/100 iters), loss = 0.461667
I0923 20:40:07.817057 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:40:07.817057 17252 solver.cpp:237]     Train net output #1: loss = 0.461667 (* 1 = 0.461667 loss)
I0923 20:40:07.817057 17252 sgd_solver.cpp:105] Iteration 25400, lr = 1e-06
I0923 20:40:10.481143 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:40:10.616406 17252 solver.cpp:218] Iteration 25500 (35.7236 iter/s, 2.79927s/100 iters), loss = 0.486019
I0923 20:40:10.616406 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:40:10.616406 17252 solver.cpp:237]     Train net output #1: loss = 0.486019 (* 1 = 0.486019 loss)
I0923 20:40:10.616406 17252 sgd_solver.cpp:105] Iteration 25500, lr = 1e-06
I0923 20:40:13.412446 17252 solver.cpp:218] Iteration 25600 (35.7748 iter/s, 2.79526s/100 iters), loss = 0.489286
I0923 20:40:13.412446 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:40:13.412446 17252 solver.cpp:237]     Train net output #1: loss = 0.489286 (* 1 = 0.489286 loss)
I0923 20:40:13.412446 17252 sgd_solver.cpp:105] Iteration 25600, lr = 1e-06
I0923 20:40:16.189502 17252 solver.cpp:218] Iteration 25700 (36.0144 iter/s, 2.77667s/100 iters), loss = 0.567237
I0923 20:40:16.189502 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:40:16.189502 17252 solver.cpp:237]     Train net output #1: loss = 0.567237 (* 1 = 0.567237 loss)
I0923 20:40:16.189502 17252 sgd_solver.cpp:105] Iteration 25700, lr = 1e-06
I0923 20:40:18.957448 17252 solver.cpp:218] Iteration 25800 (36.1243 iter/s, 2.76822s/100 iters), loss = 0.556436
I0923 20:40:18.957448 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:40:18.957448 17252 solver.cpp:237]     Train net output #1: loss = 0.556436 (* 1 = 0.556436 loss)
I0923 20:40:18.957448 17252 sgd_solver.cpp:105] Iteration 25800, lr = 1e-06
I0923 20:40:21.743815 17252 solver.cpp:218] Iteration 25900 (35.8974 iter/s, 2.78572s/100 iters), loss = 0.509716
I0923 20:40:21.744315 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:40:21.744315 17252 solver.cpp:237]     Train net output #1: loss = 0.509716 (* 1 = 0.509716 loss)
I0923 20:40:21.744315 17252 sgd_solver.cpp:105] Iteration 25900, lr = 1e-06
I0923 20:40:24.406492 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:40:24.517573 17252 solver.cpp:330] Iteration 26000, Testing net (#0)
I0923 20:40:24.517573 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:40:25.052423 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:40:25.073225 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7813
I0923 20:40:25.073225 17252 solver.cpp:397]     Test net output #1: loss = 0.636619 (* 1 = 0.636619 loss)
I0923 20:40:25.099257 17252 solver.cpp:218] Iteration 26000 (29.8028 iter/s, 3.35539s/100 iters), loss = 0.45601
I0923 20:40:25.099257 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:40:25.099257 17252 solver.cpp:237]     Train net output #1: loss = 0.45601 (* 1 = 0.45601 loss)
I0923 20:40:25.099257 17252 sgd_solver.cpp:105] Iteration 26000, lr = 1e-06
I0923 20:40:27.846813 17252 solver.cpp:218] Iteration 26100 (36.4062 iter/s, 2.74678s/100 iters), loss = 0.482115
I0923 20:40:27.846813 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:40:27.846813 17252 solver.cpp:237]     Train net output #1: loss = 0.482115 (* 1 = 0.482115 loss)
I0923 20:40:27.846813 17252 sgd_solver.cpp:105] Iteration 26100, lr = 1e-06
I0923 20:40:30.646658 17252 solver.cpp:218] Iteration 26200 (35.7189 iter/s, 2.79964s/100 iters), loss = 0.463439
I0923 20:40:30.647158 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:40:30.647158 17252 solver.cpp:237]     Train net output #1: loss = 0.463439 (* 1 = 0.463439 loss)
I0923 20:40:30.647158 17252 sgd_solver.cpp:105] Iteration 26200, lr = 1e-06
I0923 20:40:33.448786 17252 solver.cpp:218] Iteration 26300 (35.6943 iter/s, 2.80156s/100 iters), loss = 0.477795
I0923 20:40:33.448786 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:40:33.448786 17252 solver.cpp:237]     Train net output #1: loss = 0.477795 (* 1 = 0.477795 loss)
I0923 20:40:33.448786 17252 sgd_solver.cpp:105] Iteration 26300, lr = 1e-06
I0923 20:40:36.238708 17252 solver.cpp:218] Iteration 26400 (35.8489 iter/s, 2.78948s/100 iters), loss = 0.56048
I0923 20:40:36.238708 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:40:36.238708 17252 solver.cpp:237]     Train net output #1: loss = 0.56048 (* 1 = 0.56048 loss)
I0923 20:40:36.238708 17252 sgd_solver.cpp:105] Iteration 26400, lr = 1e-06
I0923 20:40:38.832759 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:40:38.965760 17252 solver.cpp:218] Iteration 26500 (36.6757 iter/s, 2.7266s/100 iters), loss = 0.461568
I0923 20:40:38.965760 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:40:38.965760 17252 solver.cpp:237]     Train net output #1: loss = 0.461568 (* 1 = 0.461568 loss)
I0923 20:40:38.965760 17252 sgd_solver.cpp:105] Iteration 26500, lr = 1e-06
I0923 20:40:41.698467 17252 solver.cpp:218] Iteration 26600 (36.5893 iter/s, 2.73304s/100 iters), loss = 0.472862
I0923 20:40:41.698467 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:40:41.698467 17252 solver.cpp:237]     Train net output #1: loss = 0.472862 (* 1 = 0.472862 loss)
I0923 20:40:41.698467 17252 sgd_solver.cpp:105] Iteration 26600, lr = 1e-06
I0923 20:40:44.427240 17252 solver.cpp:218] Iteration 26700 (36.6509 iter/s, 2.72845s/100 iters), loss = 0.501177
I0923 20:40:44.427240 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:40:44.427240 17252 solver.cpp:237]     Train net output #1: loss = 0.501177 (* 1 = 0.501177 loss)
I0923 20:40:44.427240 17252 sgd_solver.cpp:105] Iteration 26700, lr = 1e-06
I0923 20:40:47.147397 17252 solver.cpp:218] Iteration 26800 (36.7695 iter/s, 2.71964s/100 iters), loss = 0.503857
I0923 20:40:47.147397 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:40:47.147397 17252 solver.cpp:237]     Train net output #1: loss = 0.503857 (* 1 = 0.503857 loss)
I0923 20:40:47.147397 17252 sgd_solver.cpp:105] Iteration 26800, lr = 1e-06
I0923 20:40:49.866101 17252 solver.cpp:218] Iteration 26900 (36.7805 iter/s, 2.71883s/100 iters), loss = 0.511942
I0923 20:40:49.866101 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:40:49.866101 17252 solver.cpp:237]     Train net output #1: loss = 0.511942 (* 1 = 0.511942 loss)
I0923 20:40:49.866101 17252 sgd_solver.cpp:105] Iteration 26900, lr = 1e-06
I0923 20:40:52.480063 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:40:52.588145 17252 solver.cpp:330] Iteration 27000, Testing net (#0)
I0923 20:40:52.588145 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:40:53.115293 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:40:53.136307 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7808
I0923 20:40:53.136307 17252 solver.cpp:397]     Test net output #1: loss = 0.636521 (* 1 = 0.636521 loss)
I0923 20:40:53.161332 17252 solver.cpp:218] Iteration 27000 (30.3505 iter/s, 3.29484s/100 iters), loss = 0.501642
I0923 20:40:53.161332 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:40:53.161332 17252 solver.cpp:237]     Train net output #1: loss = 0.501642 (* 1 = 0.501642 loss)
I0923 20:40:53.161332 17252 sgd_solver.cpp:105] Iteration 27000, lr = 1e-06
I0923 20:40:55.965464 17252 solver.cpp:218] Iteration 27100 (35.6639 iter/s, 2.80396s/100 iters), loss = 0.454061
I0923 20:40:55.965464 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:40:55.965464 17252 solver.cpp:237]     Train net output #1: loss = 0.454061 (* 1 = 0.454061 loss)
I0923 20:40:55.965464 17252 sgd_solver.cpp:105] Iteration 27100, lr = 1e-06
I0923 20:40:58.750218 17252 solver.cpp:218] Iteration 27200 (35.9258 iter/s, 2.78351s/100 iters), loss = 0.493283
I0923 20:40:58.750218 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:40:58.750218 17252 solver.cpp:237]     Train net output #1: loss = 0.493283 (* 1 = 0.493283 loss)
I0923 20:40:58.750218 17252 sgd_solver.cpp:105] Iteration 27200, lr = 1e-06
I0923 20:41:01.554178 17252 solver.cpp:218] Iteration 27300 (35.6666 iter/s, 2.80375s/100 iters), loss = 0.519766
I0923 20:41:01.554178 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:41:01.554178 17252 solver.cpp:237]     Train net output #1: loss = 0.519766 (* 1 = 0.519766 loss)
I0923 20:41:01.554178 17252 sgd_solver.cpp:105] Iteration 27300, lr = 1e-06
I0923 20:41:04.362798 17252 solver.cpp:218] Iteration 27400 (35.6087 iter/s, 2.8083s/100 iters), loss = 0.576845
I0923 20:41:04.362798 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:41:04.362798 17252 solver.cpp:237]     Train net output #1: loss = 0.576845 (* 1 = 0.576845 loss)
I0923 20:41:04.362798 17252 sgd_solver.cpp:105] Iteration 27400, lr = 1e-06
I0923 20:41:06.958629 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:41:07.095777 17252 solver.cpp:218] Iteration 27500 (36.5916 iter/s, 2.73287s/100 iters), loss = 0.450282
I0923 20:41:07.096278 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:41:07.096278 17252 solver.cpp:237]     Train net output #1: loss = 0.450282 (* 1 = 0.450282 loss)
I0923 20:41:07.096278 17252 sgd_solver.cpp:105] Iteration 27500, lr = 1e-06
I0923 20:41:09.888514 17252 solver.cpp:218] Iteration 27600 (35.8073 iter/s, 2.79273s/100 iters), loss = 0.54029
I0923 20:41:09.888514 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 20:41:09.889513 17252 solver.cpp:237]     Train net output #1: loss = 0.54029 (* 1 = 0.54029 loss)
I0923 20:41:09.889513 17252 sgd_solver.cpp:105] Iteration 27600, lr = 1e-06
I0923 20:41:12.644317 17252 solver.cpp:218] Iteration 27700 (36.2906 iter/s, 2.75553s/100 iters), loss = 0.47322
I0923 20:41:12.645318 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:41:12.645318 17252 solver.cpp:237]     Train net output #1: loss = 0.47322 (* 1 = 0.47322 loss)
I0923 20:41:12.645318 17252 sgd_solver.cpp:105] Iteration 27700, lr = 1e-06
I0923 20:41:15.387749 17252 solver.cpp:218] Iteration 27800 (36.4596 iter/s, 2.74276s/100 iters), loss = 0.500433
I0923 20:41:15.387749 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 20:41:15.387749 17252 solver.cpp:237]     Train net output #1: loss = 0.500433 (* 1 = 0.500433 loss)
I0923 20:41:15.387749 17252 sgd_solver.cpp:105] Iteration 27800, lr = 1e-06
I0923 20:41:18.129966 17252 solver.cpp:218] Iteration 27900 (36.4723 iter/s, 2.74181s/100 iters), loss = 0.485052
I0923 20:41:18.129966 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 20:41:18.129966 17252 solver.cpp:237]     Train net output #1: loss = 0.485052 (* 1 = 0.485052 loss)
I0923 20:41:18.129966 17252 sgd_solver.cpp:105] Iteration 27900, lr = 1e-06
I0923 20:41:20.733007 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:41:20.841683 17252 solver.cpp:330] Iteration 28000, Testing net (#0)
I0923 20:41:20.841683 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:41:21.357848 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:41:21.377450 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7815
I0923 20:41:21.377450 17252 solver.cpp:397]     Test net output #1: loss = 0.636702 (* 1 = 0.636702 loss)
I0923 20:41:21.403468 17252 solver.cpp:218] Iteration 28000 (30.5551 iter/s, 3.27278s/100 iters), loss = 0.401386
I0923 20:41:21.403468 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 20:41:21.403468 17252 solver.cpp:237]     Train net output #1: loss = 0.401386 (* 1 = 0.401386 loss)
I0923 20:41:21.403468 17252 sgd_solver.cpp:105] Iteration 28000, lr = 1e-06
I0923 20:41:24.151619 17252 solver.cpp:218] Iteration 28100 (36.3885 iter/s, 2.74812s/100 iters), loss = 0.51023
I0923 20:41:24.151619 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:41:24.151619 17252 solver.cpp:237]     Train net output #1: loss = 0.51023 (* 1 = 0.51023 loss)
I0923 20:41:24.151619 17252 sgd_solver.cpp:105] Iteration 28100, lr = 1e-06
I0923 20:41:26.879225 17252 solver.cpp:218] Iteration 28200 (36.6642 iter/s, 2.72746s/100 iters), loss = 0.493157
I0923 20:41:26.879225 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 20:41:26.879225 17252 solver.cpp:237]     Train net output #1: loss = 0.493157 (* 1 = 0.493157 loss)
I0923 20:41:26.879225 17252 sgd_solver.cpp:105] Iteration 28200, lr = 1e-06
I0923 20:41:29.611181 17252 solver.cpp:218] Iteration 28300 (36.6112 iter/s, 2.7314s/100 iters), loss = 0.547897
I0923 20:41:29.611680 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:41:29.611680 17252 solver.cpp:237]     Train net output #1: loss = 0.547897 (* 1 = 0.547897 loss)
I0923 20:41:29.611680 17252 sgd_solver.cpp:105] Iteration 28300, lr = 1e-06
I0923 20:41:32.352535 17252 solver.cpp:218] Iteration 28400 (36.4806 iter/s, 2.74118s/100 iters), loss = 0.509724
I0923 20:41:32.352535 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:41:32.352535 17252 solver.cpp:237]     Train net output #1: loss = 0.509724 (* 1 = 0.509724 loss)
I0923 20:41:32.352535 17252 sgd_solver.cpp:105] Iteration 28400, lr = 1e-06
I0923 20:41:34.948235 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:41:35.081851 17252 solver.cpp:218] Iteration 28500 (36.6459 iter/s, 2.72882s/100 iters), loss = 0.523987
I0923 20:41:35.082351 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:41:35.082351 17252 solver.cpp:237]     Train net output #1: loss = 0.523987 (* 1 = 0.523987 loss)
I0923 20:41:35.082351 17252 sgd_solver.cpp:105] Iteration 28500, lr = 1e-06
I0923 20:41:37.816895 17252 solver.cpp:218] Iteration 28600 (36.5653 iter/s, 2.73483s/100 iters), loss = 0.491925
I0923 20:41:37.816895 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:41:37.816895 17252 solver.cpp:237]     Train net output #1: loss = 0.491925 (* 1 = 0.491925 loss)
I0923 20:41:37.816895 17252 sgd_solver.cpp:105] Iteration 28600, lr = 1e-06
I0923 20:41:40.555143 17252 solver.cpp:218] Iteration 28700 (36.5213 iter/s, 2.73813s/100 iters), loss = 0.468989
I0923 20:41:40.555143 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 20:41:40.555143 17252 solver.cpp:237]     Train net output #1: loss = 0.468989 (* 1 = 0.468989 loss)
I0923 20:41:40.555143 17252 sgd_solver.cpp:105] Iteration 28700, lr = 1e-06
I0923 20:41:43.341728 17252 solver.cpp:218] Iteration 28800 (35.8902 iter/s, 2.78627s/100 iters), loss = 0.483445
I0923 20:41:43.341728 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 20:41:43.341728 17252 solver.cpp:237]     Train net output #1: loss = 0.483445 (* 1 = 0.483445 loss)
I0923 20:41:43.341728 17252 sgd_solver.cpp:105] Iteration 28800, lr = 1e-06
I0923 20:41:46.105500 17252 solver.cpp:218] Iteration 28900 (36.1893 iter/s, 2.76325s/100 iters), loss = 0.553583
I0923 20:41:46.105500 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 20:41:46.105500 17252 solver.cpp:237]     Train net output #1: loss = 0.553583 (* 1 = 0.553583 loss)
I0923 20:41:46.105500 17252 sgd_solver.cpp:105] Iteration 28900, lr = 1e-06
I0923 20:41:48.708511 17308 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:41:48.816138 17252 solver.cpp:330] Iteration 29000, Testing net (#0)
I0923 20:41:48.816138 17252 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:41:49.341620 17312 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:41:49.361651 17252 solver.cpp:397]     Test net output #0: accuracy = 0.7811
I0923 20:41:49.362651 17252 solver.cpp:397]     Test net output #1: loss = 0.636472 (* 1 = 0.636472 loss)
I0923 20:41:49.388154 17252 solver.cpp:218] Iteration 29000 (30.4705 iter/s, 3.28186s/100 iters), loss = 0.468357
I0923 20:41:49.388154 17252 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 20:41:49.388154 17252 solver.cpp:237