
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0923 20:58:47.454655  9080 caffe.cpp:219] Using GPUs 0
I0923 20:58:47.623404  9080 caffe.cpp:224] GPU 0: GeForce GTX 1080
I0923 20:58:47.919667  9080 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:58:47.936162  9080 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 25000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 25000
snapshot_prefix: "examples/cifar10/slimnet_simpnet_nogroupcon"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 25000
type: "Nesterov"
I0923 20:58:47.937163  9080 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:58:47.937680  9080 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:58:47.937680  9080 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0923 20:58:47.937680  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0923 20:58:47.937680  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0923 20:58:47.937680  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I0923 20:58:47.938175  9080 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0923 20:58:47.938175  9080 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_NoGroupCon_NoDrp_noaug"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0923 20:58:47.968092  9080 layer_factory.cpp:58] Creating layer cifar
I0923 20:58:47.975138  9080 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0923 20:58:47.975138  9080 net.cpp:84] Creating Layer cifar
I0923 20:58:47.975138  9080 net.cpp:380] cifar -> data
I0923 20:58:47.975138  9080 net.cpp:380] cifar -> label
I0923 20:58:47.975138  9080 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0923 20:58:47.976668  9080 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:58:47.976668  9080 data_layer.cpp:45] output data size: 100,3,32,32
I0923 20:58:47.981611  9080 net.cpp:122] Setting up cifar
I0923 20:58:47.981611  9080 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0923 20:58:47.981611  9080 net.cpp:129] Top shape: 100 (100)
I0923 20:58:47.981611  9080 net.cpp:137] Memory required for data: 1229200
I0923 20:58:47.981611  9080 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0923 20:58:47.981611  9080 net.cpp:84] Creating Layer label_cifar_1_split
I0923 20:58:47.981611  9080 net.cpp:406] label_cifar_1_split <- label
I0923 20:58:47.981611  9080 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0923 20:58:47.981611  9080 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0923 20:58:47.981611  9080 net.cpp:122] Setting up label_cifar_1_split
I0923 20:58:47.981611  9080 net.cpp:129] Top shape: 100 (100)
I0923 20:58:47.981611  9080 net.cpp:129] Top shape: 100 (100)
I0923 20:58:47.981611  9080 net.cpp:137] Memory required for data: 1230000
I0923 20:58:47.981611  9080 layer_factory.cpp:58] Creating layer conv1
I0923 20:58:47.982111  9080 net.cpp:84] Creating Layer conv1
I0923 20:58:47.982111  9080 net.cpp:406] conv1 <- data
I0923 20:58:47.982111  9080 net.cpp:380] conv1 -> conv1
I0923 20:58:47.982111 11752 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:58:48.216312  9080 net.cpp:122] Setting up conv1
I0923 20:58:48.216312  9080 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:58:48.216312  9080 net.cpp:137] Memory required for data: 3687600
I0923 20:58:48.216312  9080 layer_factory.cpp:58] Creating layer bn1
I0923 20:58:48.216312  9080 net.cpp:84] Creating Layer bn1
I0923 20:58:48.216312  9080 net.cpp:406] bn1 <- conv1
I0923 20:58:48.216312  9080 net.cpp:367] bn1 -> conv1 (in-place)
I0923 20:58:48.216312  9080 net.cpp:122] Setting up bn1
I0923 20:58:48.216312  9080 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:58:48.216312  9080 net.cpp:137] Memory required for data: 6145200
I0923 20:58:48.216312  9080 layer_factory.cpp:58] Creating layer scale1
I0923 20:58:48.216312  9080 net.cpp:84] Creating Layer scale1
I0923 20:58:48.216312  9080 net.cpp:406] scale1 <- conv1
I0923 20:58:48.216312  9080 net.cpp:367] scale1 -> conv1 (in-place)
I0923 20:58:48.216312  9080 layer_factory.cpp:58] Creating layer scale1
I0923 20:58:48.216814  9080 net.cpp:122] Setting up scale1
I0923 20:58:48.216814  9080 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:58:48.216814  9080 net.cpp:137] Memory required for data: 8602800
I0923 20:58:48.216814  9080 layer_factory.cpp:58] Creating layer relu1
I0923 20:58:48.216814  9080 net.cpp:84] Creating Layer relu1
I0923 20:58:48.216814  9080 net.cpp:406] relu1 <- conv1
I0923 20:58:48.216814  9080 net.cpp:367] relu1 -> conv1 (in-place)
I0923 20:58:48.216814  9080 net.cpp:122] Setting up relu1
I0923 20:58:48.216814  9080 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:58:48.216814  9080 net.cpp:137] Memory required for data: 11060400
I0923 20:58:48.216814  9080 layer_factory.cpp:58] Creating layer conv1_0
I0923 20:58:48.216814  9080 net.cpp:84] Creating Layer conv1_0
I0923 20:58:48.216814  9080 net.cpp:406] conv1_0 <- conv1
I0923 20:58:48.216814  9080 net.cpp:380] conv1_0 -> conv1_0
I0923 20:58:48.218315  9080 net.cpp:122] Setting up conv1_0
I0923 20:58:48.218315  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.218315  9080 net.cpp:137] Memory required for data: 15975600
I0923 20:58:48.218315  9080 layer_factory.cpp:58] Creating layer bn1_0
I0923 20:58:48.218315  9080 net.cpp:84] Creating Layer bn1_0
I0923 20:58:48.218315  9080 net.cpp:406] bn1_0 <- conv1_0
I0923 20:58:48.218315  9080 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0923 20:58:48.218315  9080 net.cpp:122] Setting up bn1_0
I0923 20:58:48.218315  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.218315  9080 net.cpp:137] Memory required for data: 20890800
I0923 20:58:48.218315  9080 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:58:48.218315  9080 net.cpp:84] Creating Layer scale1_0
I0923 20:58:48.218315  9080 net.cpp:406] scale1_0 <- conv1_0
I0923 20:58:48.218315  9080 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0923 20:58:48.218821  9080 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:58:48.218821  9080 net.cpp:122] Setting up scale1_0
I0923 20:58:48.218821  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.218821  9080 net.cpp:137] Memory required for data: 25806000
I0923 20:58:48.304380  9080 layer_factory.cpp:58] Creating layer relu1_0
I0923 20:58:48.304380  9080 net.cpp:84] Creating Layer relu1_0
I0923 20:58:48.304380  9080 net.cpp:406] relu1_0 <- conv1_0
I0923 20:58:48.304380  9080 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0923 20:58:48.304918  9080 net.cpp:122] Setting up relu1_0
I0923 20:58:48.304918  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.304918  9080 net.cpp:137] Memory required for data: 30721200
I0923 20:58:48.304918  9080 layer_factory.cpp:58] Creating layer conv2
I0923 20:58:48.304918  9080 net.cpp:84] Creating Layer conv2
I0923 20:58:48.304918  9080 net.cpp:406] conv2 <- conv1_0
I0923 20:58:48.304918  9080 net.cpp:380] conv2 -> conv2
I0923 20:58:48.305919  9080 net.cpp:122] Setting up conv2
I0923 20:58:48.305919  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.305919  9080 net.cpp:137] Memory required for data: 35636400
I0923 20:58:48.305919  9080 layer_factory.cpp:58] Creating layer bn2
I0923 20:58:48.305919  9080 net.cpp:84] Creating Layer bn2
I0923 20:58:48.305919  9080 net.cpp:406] bn2 <- conv2
I0923 20:58:48.305919  9080 net.cpp:367] bn2 -> conv2 (in-place)
I0923 20:58:48.305919  9080 net.cpp:122] Setting up bn2
I0923 20:58:48.305919  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.305919  9080 net.cpp:137] Memory required for data: 40551600
I0923 20:58:48.305919  9080 layer_factory.cpp:58] Creating layer scale2
I0923 20:58:48.305919  9080 net.cpp:84] Creating Layer scale2
I0923 20:58:48.305919  9080 net.cpp:406] scale2 <- conv2
I0923 20:58:48.305919  9080 net.cpp:367] scale2 -> conv2 (in-place)
I0923 20:58:48.305919  9080 layer_factory.cpp:58] Creating layer scale2
I0923 20:58:48.306421  9080 net.cpp:122] Setting up scale2
I0923 20:58:48.306421  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.306421  9080 net.cpp:137] Memory required for data: 45466800
I0923 20:58:48.306421  9080 layer_factory.cpp:58] Creating layer relu2
I0923 20:58:48.306421  9080 net.cpp:84] Creating Layer relu2
I0923 20:58:48.306421  9080 net.cpp:406] relu2 <- conv2
I0923 20:58:48.306421  9080 net.cpp:367] relu2 -> conv2 (in-place)
I0923 20:58:48.306919  9080 net.cpp:122] Setting up relu2
I0923 20:58:48.306919  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.306919  9080 net.cpp:137] Memory required for data: 50382000
I0923 20:58:48.306919  9080 layer_factory.cpp:58] Creating layer conv2_1
I0923 20:58:48.306919  9080 net.cpp:84] Creating Layer conv2_1
I0923 20:58:48.306919  9080 net.cpp:406] conv2_1 <- conv2
I0923 20:58:48.306919  9080 net.cpp:380] conv2_1 -> conv2_1
I0923 20:58:48.307807  9080 net.cpp:122] Setting up conv2_1
I0923 20:58:48.307807  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.307807  9080 net.cpp:137] Memory required for data: 55297200
I0923 20:58:48.307807  9080 layer_factory.cpp:58] Creating layer bn2_1
I0923 20:58:48.307807  9080 net.cpp:84] Creating Layer bn2_1
I0923 20:58:48.307807  9080 net.cpp:406] bn2_1 <- conv2_1
I0923 20:58:48.307807  9080 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0923 20:58:48.307807  9080 net.cpp:122] Setting up bn2_1
I0923 20:58:48.307807  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.307807  9080 net.cpp:137] Memory required for data: 60212400
I0923 20:58:48.307807  9080 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:58:48.307807  9080 net.cpp:84] Creating Layer scale2_1
I0923 20:58:48.307807  9080 net.cpp:406] scale2_1 <- conv2_1
I0923 20:58:48.307807  9080 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0923 20:58:48.308310  9080 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:58:48.308310  9080 net.cpp:122] Setting up scale2_1
I0923 20:58:48.308310  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.308310  9080 net.cpp:137] Memory required for data: 65127600
I0923 20:58:48.308310  9080 layer_factory.cpp:58] Creating layer relu2_1
I0923 20:58:48.308310  9080 net.cpp:84] Creating Layer relu2_1
I0923 20:58:48.308310  9080 net.cpp:406] relu2_1 <- conv2_1
I0923 20:58:48.308310  9080 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0923 20:58:48.308310  9080 net.cpp:122] Setting up relu2_1
I0923 20:58:48.308310  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.308310  9080 net.cpp:137] Memory required for data: 70042800
I0923 20:58:48.308310  9080 layer_factory.cpp:58] Creating layer conv2_2
I0923 20:58:48.308310  9080 net.cpp:84] Creating Layer conv2_2
I0923 20:58:48.308310  9080 net.cpp:406] conv2_2 <- conv2_1
I0923 20:58:48.308310  9080 net.cpp:380] conv2_2 -> conv2_2
I0923 20:58:48.309479  9080 net.cpp:122] Setting up conv2_2
I0923 20:58:48.309479  9080 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:58:48.309479  9080 net.cpp:137] Memory required for data: 77825200
I0923 20:58:48.309479  9080 layer_factory.cpp:58] Creating layer bn2_2
I0923 20:58:48.309479  9080 net.cpp:84] Creating Layer bn2_2
I0923 20:58:48.309479  9080 net.cpp:406] bn2_2 <- conv2_2
I0923 20:58:48.309479  9080 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0923 20:58:48.309981  9080 net.cpp:122] Setting up bn2_2
I0923 20:58:48.309981  9080 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:58:48.309981  9080 net.cpp:137] Memory required for data: 85607600
I0923 20:58:48.309981  9080 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:58:48.309981  9080 net.cpp:84] Creating Layer scale2_2
I0923 20:58:48.309981  9080 net.cpp:406] scale2_2 <- conv2_2
I0923 20:58:48.309981  9080 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0923 20:58:48.309981  9080 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:58:48.309981  9080 net.cpp:122] Setting up scale2_2
I0923 20:58:48.309981  9080 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:58:48.309981  9080 net.cpp:137] Memory required for data: 93390000
I0923 20:58:48.309981  9080 layer_factory.cpp:58] Creating layer relu2_2
I0923 20:58:48.309981  9080 net.cpp:84] Creating Layer relu2_2
I0923 20:58:48.309981  9080 net.cpp:406] relu2_2 <- conv2_2
I0923 20:58:48.309981  9080 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0923 20:58:48.309981  9080 net.cpp:122] Setting up relu2_2
I0923 20:58:48.309981  9080 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:58:48.309981  9080 net.cpp:137] Memory required for data: 101172400
I0923 20:58:48.309981  9080 layer_factory.cpp:58] Creating layer pool2_1
I0923 20:58:48.309981  9080 net.cpp:84] Creating Layer pool2_1
I0923 20:58:48.309981  9080 net.cpp:406] pool2_1 <- conv2_2
I0923 20:58:48.309981  9080 net.cpp:380] pool2_1 -> pool2_1
I0923 20:58:48.310482  9080 net.cpp:122] Setting up pool2_1
I0923 20:58:48.310482  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.310482  9080 net.cpp:137] Memory required for data: 103118000
I0923 20:58:48.310482  9080 layer_factory.cpp:58] Creating layer conv3
I0923 20:58:48.310482  9080 net.cpp:84] Creating Layer conv3
I0923 20:58:48.310482  9080 net.cpp:406] conv3 <- pool2_1
I0923 20:58:48.310482  9080 net.cpp:380] conv3 -> conv3
I0923 20:58:48.311642  9080 net.cpp:122] Setting up conv3
I0923 20:58:48.311642  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.311642  9080 net.cpp:137] Memory required for data: 105063600
I0923 20:58:48.311642  9080 layer_factory.cpp:58] Creating layer bn3
I0923 20:58:48.311642  9080 net.cpp:84] Creating Layer bn3
I0923 20:58:48.311642  9080 net.cpp:406] bn3 <- conv3
I0923 20:58:48.311642  9080 net.cpp:367] bn3 -> conv3 (in-place)
I0923 20:58:48.311642  9080 net.cpp:122] Setting up bn3
I0923 20:58:48.311642  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.311642  9080 net.cpp:137] Memory required for data: 107009200
I0923 20:58:48.311642  9080 layer_factory.cpp:58] Creating layer scale3
I0923 20:58:48.311642  9080 net.cpp:84] Creating Layer scale3
I0923 20:58:48.311642  9080 net.cpp:406] scale3 <- conv3
I0923 20:58:48.311642  9080 net.cpp:367] scale3 -> conv3 (in-place)
I0923 20:58:48.311642  9080 layer_factory.cpp:58] Creating layer scale3
I0923 20:58:48.311642  9080 net.cpp:122] Setting up scale3
I0923 20:58:48.311642  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.312142  9080 net.cpp:137] Memory required for data: 108954800
I0923 20:58:48.312142  9080 layer_factory.cpp:58] Creating layer relu3
I0923 20:58:48.312142  9080 net.cpp:84] Creating Layer relu3
I0923 20:58:48.312142  9080 net.cpp:406] relu3 <- conv3
I0923 20:58:48.312142  9080 net.cpp:367] relu3 -> conv3 (in-place)
I0923 20:58:48.312142  9080 net.cpp:122] Setting up relu3
I0923 20:58:48.312142  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.312142  9080 net.cpp:137] Memory required for data: 110900400
I0923 20:58:48.312142  9080 layer_factory.cpp:58] Creating layer conv3_1
I0923 20:58:48.312142  9080 net.cpp:84] Creating Layer conv3_1
I0923 20:58:48.312142  9080 net.cpp:406] conv3_1 <- conv3
I0923 20:58:48.312142  9080 net.cpp:380] conv3_1 -> conv3_1
I0923 20:58:48.313308  9080 net.cpp:122] Setting up conv3_1
I0923 20:58:48.313308  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.313308  9080 net.cpp:137] Memory required for data: 112846000
I0923 20:58:48.313308  9080 layer_factory.cpp:58] Creating layer bn3_1
I0923 20:58:48.313308  9080 net.cpp:84] Creating Layer bn3_1
I0923 20:58:48.313308  9080 net.cpp:406] bn3_1 <- conv3_1
I0923 20:58:48.313308  9080 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I0923 20:58:48.313308  9080 net.cpp:122] Setting up bn3_1
I0923 20:58:48.313308  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.313308  9080 net.cpp:137] Memory required for data: 114791600
I0923 20:58:48.313308  9080 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:58:48.313308  9080 net.cpp:84] Creating Layer scale3_1
I0923 20:58:48.313308  9080 net.cpp:406] scale3_1 <- conv3_1
I0923 20:58:48.313308  9080 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I0923 20:58:48.313308  9080 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:58:48.313810  9080 net.cpp:122] Setting up scale3_1
I0923 20:58:48.313810  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.313810  9080 net.cpp:137] Memory required for data: 116737200
I0923 20:58:48.313810  9080 layer_factory.cpp:58] Creating layer relu3_1
I0923 20:58:48.313810  9080 net.cpp:84] Creating Layer relu3_1
I0923 20:58:48.313810  9080 net.cpp:406] relu3_1 <- conv3_1
I0923 20:58:48.313810  9080 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0923 20:58:48.313810  9080 net.cpp:122] Setting up relu3_1
I0923 20:58:48.313810  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.313810  9080 net.cpp:137] Memory required for data: 118682800
I0923 20:58:48.313810  9080 layer_factory.cpp:58] Creating layer conv4
I0923 20:58:48.313810  9080 net.cpp:84] Creating Layer conv4
I0923 20:58:48.313810  9080 net.cpp:406] conv4 <- conv3_1
I0923 20:58:48.313810  9080 net.cpp:380] conv4 -> conv4
I0923 20:58:48.314975  9080 net.cpp:122] Setting up conv4
I0923 20:58:48.314975  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.314975  9080 net.cpp:137] Memory required for data: 120628400
I0923 20:58:48.314975  9080 layer_factory.cpp:58] Creating layer bn4
I0923 20:58:48.314975  9080 net.cpp:84] Creating Layer bn4
I0923 20:58:48.314975  9080 net.cpp:406] bn4 <- conv4
I0923 20:58:48.314975  9080 net.cpp:367] bn4 -> conv4 (in-place)
I0923 20:58:48.314975  9080 net.cpp:122] Setting up bn4
I0923 20:58:48.314975  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.314975  9080 net.cpp:137] Memory required for data: 122574000
I0923 20:58:48.314975  9080 layer_factory.cpp:58] Creating layer scale4
I0923 20:58:48.314975  9080 net.cpp:84] Creating Layer scale4
I0923 20:58:48.314975  9080 net.cpp:406] scale4 <- conv4
I0923 20:58:48.314975  9080 net.cpp:367] scale4 -> conv4 (in-place)
I0923 20:58:48.314975  9080 layer_factory.cpp:58] Creating layer scale4
I0923 20:58:48.315474  9080 net.cpp:122] Setting up scale4
I0923 20:58:48.315474  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.315474  9080 net.cpp:137] Memory required for data: 124519600
I0923 20:58:48.315474  9080 layer_factory.cpp:58] Creating layer relu4
I0923 20:58:48.315474  9080 net.cpp:84] Creating Layer relu4
I0923 20:58:48.315474  9080 net.cpp:406] relu4 <- conv4
I0923 20:58:48.315474  9080 net.cpp:367] relu4 -> conv4 (in-place)
I0923 20:58:48.315910  9080 net.cpp:122] Setting up relu4
I0923 20:58:48.315910  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.315910  9080 net.cpp:137] Memory required for data: 126465200
I0923 20:58:48.315910  9080 layer_factory.cpp:58] Creating layer conv4_1
I0923 20:58:48.315910  9080 net.cpp:84] Creating Layer conv4_1
I0923 20:58:48.315910  9080 net.cpp:406] conv4_1 <- conv4
I0923 20:58:48.315910  9080 net.cpp:380] conv4_1 -> conv4_1
I0923 20:58:48.316385  9080 net.cpp:122] Setting up conv4_1
I0923 20:58:48.316385  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.316385  9080 net.cpp:137] Memory required for data: 128410800
I0923 20:58:48.316385  9080 layer_factory.cpp:58] Creating layer bn4_1
I0923 20:58:48.316385  9080 net.cpp:84] Creating Layer bn4_1
I0923 20:58:48.316887  9080 net.cpp:406] bn4_1 <- conv4_1
I0923 20:58:48.316887  9080 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0923 20:58:48.316887  9080 net.cpp:122] Setting up bn4_1
I0923 20:58:48.316887  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.316887  9080 net.cpp:137] Memory required for data: 130356400
I0923 20:58:48.316887  9080 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:58:48.316887  9080 net.cpp:84] Creating Layer scale4_1
I0923 20:58:48.316887  9080 net.cpp:406] scale4_1 <- conv4_1
I0923 20:58:48.316887  9080 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0923 20:58:48.316887  9080 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:58:48.316887  9080 net.cpp:122] Setting up scale4_1
I0923 20:58:48.316887  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.316887  9080 net.cpp:137] Memory required for data: 132302000
I0923 20:58:48.316887  9080 layer_factory.cpp:58] Creating layer relu4_1
I0923 20:58:48.316887  9080 net.cpp:84] Creating Layer relu4_1
I0923 20:58:48.316887  9080 net.cpp:406] relu4_1 <- conv4_1
I0923 20:58:48.316887  9080 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0923 20:58:48.317387  9080 net.cpp:122] Setting up relu4_1
I0923 20:58:48.317387  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.317387  9080 net.cpp:137] Memory required for data: 134247600
I0923 20:58:48.317387  9080 layer_factory.cpp:58] Creating layer conv4_2
I0923 20:58:48.317387  9080 net.cpp:84] Creating Layer conv4_2
I0923 20:58:48.317387  9080 net.cpp:406] conv4_2 <- conv4_1
I0923 20:58:48.317387  9080 net.cpp:380] conv4_2 -> conv4_2
I0923 20:58:48.319388  9080 net.cpp:122] Setting up conv4_2
I0923 20:58:48.319388  9080 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:58:48.319388  9080 net.cpp:137] Memory required for data: 137114800
I0923 20:58:48.319388  9080 layer_factory.cpp:58] Creating layer bn4_2
I0923 20:58:48.319388  9080 net.cpp:84] Creating Layer bn4_2
I0923 20:58:48.319388  9080 net.cpp:406] bn4_2 <- conv4_2
I0923 20:58:48.319388  9080 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0923 20:58:48.319388  9080 net.cpp:122] Setting up bn4_2
I0923 20:58:48.319388  9080 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:58:48.319388  9080 net.cpp:137] Memory required for data: 139982000
I0923 20:58:48.319388  9080 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:58:48.319388  9080 net.cpp:84] Creating Layer scale4_2
I0923 20:58:48.319388  9080 net.cpp:406] scale4_2 <- conv4_2
I0923 20:58:48.319388  9080 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0923 20:58:48.319388  9080 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:58:48.319890  9080 net.cpp:122] Setting up scale4_2
I0923 20:58:48.319890  9080 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:58:48.319890  9080 net.cpp:137] Memory required for data: 142849200
I0923 20:58:48.319890  9080 layer_factory.cpp:58] Creating layer relu4_2
I0923 20:58:48.319890  9080 net.cpp:84] Creating Layer relu4_2
I0923 20:58:48.319890  9080 net.cpp:406] relu4_2 <- conv4_2
I0923 20:58:48.319890  9080 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0923 20:58:48.319890  9080 net.cpp:122] Setting up relu4_2
I0923 20:58:48.319890  9080 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:58:48.319890  9080 net.cpp:137] Memory required for data: 145716400
I0923 20:58:48.319890  9080 layer_factory.cpp:58] Creating layer pool4_2
I0923 20:58:48.319890  9080 net.cpp:84] Creating Layer pool4_2
I0923 20:58:48.319890  9080 net.cpp:406] pool4_2 <- conv4_2
I0923 20:58:48.319890  9080 net.cpp:380] pool4_2 -> pool4_2
I0923 20:58:48.319890  9080 net.cpp:122] Setting up pool4_2
I0923 20:58:48.319890  9080 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:58:48.319890  9080 net.cpp:137] Memory required for data: 146433200
I0923 20:58:48.319890  9080 layer_factory.cpp:58] Creating layer conv4_0
I0923 20:58:48.320389  9080 net.cpp:84] Creating Layer conv4_0
I0923 20:58:48.320389  9080 net.cpp:406] conv4_0 <- pool4_2
I0923 20:58:48.320389  9080 net.cpp:380] conv4_0 -> conv4_0
I0923 20:58:48.321092  9080 net.cpp:122] Setting up conv4_0
I0923 20:58:48.321092  9080 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:58:48.321092  9080 net.cpp:137] Memory required for data: 147150000
I0923 20:58:48.321092  9080 layer_factory.cpp:58] Creating layer bn4_0
I0923 20:58:48.321092  9080 net.cpp:84] Creating Layer bn4_0
I0923 20:58:48.321595  9080 net.cpp:406] bn4_0 <- conv4_0
I0923 20:58:48.321595  9080 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0923 20:58:48.321595  9080 net.cpp:122] Setting up bn4_0
I0923 20:58:48.321595  9080 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:58:48.321595  9080 net.cpp:137] Memory required for data: 147866800
I0923 20:58:48.321595  9080 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:58:48.321595  9080 net.cpp:84] Creating Layer scale4_0
I0923 20:58:48.321595  9080 net.cpp:406] scale4_0 <- conv4_0
I0923 20:58:48.321595  9080 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0923 20:58:48.321595  9080 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:58:48.321595  9080 net.cpp:122] Setting up scale4_0
I0923 20:58:48.321595  9080 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:58:48.321595  9080 net.cpp:137] Memory required for data: 148583600
I0923 20:58:48.321595  9080 layer_factory.cpp:58] Creating layer relu4_0
I0923 20:58:48.321595  9080 net.cpp:84] Creating Layer relu4_0
I0923 20:58:48.321595  9080 net.cpp:406] relu4_0 <- conv4_0
I0923 20:58:48.321595  9080 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0923 20:58:48.322095  9080 net.cpp:122] Setting up relu4_0
I0923 20:58:48.322095  9080 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:58:48.322095  9080 net.cpp:137] Memory required for data: 149300400
I0923 20:58:48.322095  9080 layer_factory.cpp:58] Creating layer conv11
I0923 20:58:48.322095  9080 net.cpp:84] Creating Layer conv11
I0923 20:58:48.322095  9080 net.cpp:406] conv11 <- conv4_0
I0923 20:58:48.322095  9080 net.cpp:380] conv11 -> conv11
I0923 20:58:48.323096  9080 net.cpp:122] Setting up conv11
I0923 20:58:48.323096  9080 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:58:48.323096  9080 net.cpp:137] Memory required for data: 150196400
I0923 20:58:48.323096  9080 layer_factory.cpp:58] Creating layer bn_conv11
I0923 20:58:48.323096  9080 net.cpp:84] Creating Layer bn_conv11
I0923 20:58:48.323096  9080 net.cpp:406] bn_conv11 <- conv11
I0923 20:58:48.323096  9080 net.cpp:367] bn_conv11 -> conv11 (in-place)
I0923 20:58:48.323096  9080 net.cpp:122] Setting up bn_conv11
I0923 20:58:48.323096  9080 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:58:48.323096  9080 net.cpp:137] Memory required for data: 151092400
I0923 20:58:48.323096  9080 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:58:48.323096  9080 net.cpp:84] Creating Layer scale_conv11
I0923 20:58:48.323096  9080 net.cpp:406] scale_conv11 <- conv11
I0923 20:58:48.323096  9080 net.cpp:367] scale_conv11 -> conv11 (in-place)
I0923 20:58:48.323096  9080 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:58:48.323096  9080 net.cpp:122] Setting up scale_conv11
I0923 20:58:48.323096  9080 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:58:48.323096  9080 net.cpp:137] Memory required for data: 151988400
I0923 20:58:48.323596  9080 layer_factory.cpp:58] Creating layer relu_conv11
I0923 20:58:48.323596  9080 net.cpp:84] Creating Layer relu_conv11
I0923 20:58:48.323596  9080 net.cpp:406] relu_conv11 <- conv11
I0923 20:58:48.323596  9080 net.cpp:367] relu_conv11 -> conv11 (in-place)
I0923 20:58:48.323596  9080 net.cpp:122] Setting up relu_conv11
I0923 20:58:48.323596  9080 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:58:48.323596  9080 net.cpp:137] Memory required for data: 152884400
I0923 20:58:48.323596  9080 layer_factory.cpp:58] Creating layer conv12
I0923 20:58:48.323596  9080 net.cpp:84] Creating Layer conv12
I0923 20:58:48.323596  9080 net.cpp:406] conv12 <- conv11
I0923 20:58:48.323596  9080 net.cpp:380] conv12 -> conv12
I0923 20:58:48.324951  9080 net.cpp:122] Setting up conv12
I0923 20:58:48.324951  9080 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:58:48.324951  9080 net.cpp:137] Memory required for data: 153985200
I0923 20:58:48.324951  9080 layer_factory.cpp:58] Creating layer bn_conv12
I0923 20:58:48.324951  9080 net.cpp:84] Creating Layer bn_conv12
I0923 20:58:48.324951  9080 net.cpp:406] bn_conv12 <- conv12
I0923 20:58:48.324951  9080 net.cpp:367] bn_conv12 -> conv12 (in-place)
I0923 20:58:48.324951  9080 net.cpp:122] Setting up bn_conv12
I0923 20:58:48.324951  9080 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:58:48.324951  9080 net.cpp:137] Memory required for data: 155086000
I0923 20:58:48.324951  9080 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:58:48.324951  9080 net.cpp:84] Creating Layer scale_conv12
I0923 20:58:48.324951  9080 net.cpp:406] scale_conv12 <- conv12
I0923 20:58:48.324951  9080 net.cpp:367] scale_conv12 -> conv12 (in-place)
I0923 20:58:48.324951  9080 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:58:48.324951  9080 net.cpp:122] Setting up scale_conv12
I0923 20:58:48.324951  9080 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:58:48.324951  9080 net.cpp:137] Memory required for data: 156186800
I0923 20:58:48.324951  9080 layer_factory.cpp:58] Creating layer relu_conv12
I0923 20:58:48.325451  9080 net.cpp:84] Creating Layer relu_conv12
I0923 20:58:48.325451  9080 net.cpp:406] relu_conv12 <- conv12
I0923 20:58:48.325451  9080 net.cpp:367] relu_conv12 -> conv12 (in-place)
I0923 20:58:48.325451  9080 net.cpp:122] Setting up relu_conv12
I0923 20:58:48.325451  9080 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:58:48.325451  9080 net.cpp:137] Memory required for data: 157287600
I0923 20:58:48.325451  9080 layer_factory.cpp:58] Creating layer poolcp6
I0923 20:58:48.325451  9080 net.cpp:84] Creating Layer poolcp6
I0923 20:58:48.325451  9080 net.cpp:406] poolcp6 <- conv12
I0923 20:58:48.325451  9080 net.cpp:380] poolcp6 -> poolcp6
I0923 20:58:48.325451  9080 net.cpp:122] Setting up poolcp6
I0923 20:58:48.325451  9080 net.cpp:129] Top shape: 100 43 1 1 (4300)
I0923 20:58:48.325451  9080 net.cpp:137] Memory required for data: 157304800
I0923 20:58:48.325451  9080 layer_factory.cpp:58] Creating layer ip1
I0923 20:58:48.325451  9080 net.cpp:84] Creating Layer ip1
I0923 20:58:48.325451  9080 net.cpp:406] ip1 <- poolcp6
I0923 20:58:48.325451  9080 net.cpp:380] ip1 -> ip1
I0923 20:58:48.325451  9080 net.cpp:122] Setting up ip1
I0923 20:58:48.325953  9080 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:58:48.325953  9080 net.cpp:137] Memory required for data: 157308800
I0923 20:58:48.325953  9080 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0923 20:58:48.325953  9080 net.cpp:84] Creating Layer ip1_ip1_0_split
I0923 20:58:48.325953  9080 net.cpp:406] ip1_ip1_0_split <- ip1
I0923 20:58:48.325953  9080 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0923 20:58:48.325953  9080 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0923 20:58:48.325953  9080 net.cpp:122] Setting up ip1_ip1_0_split
I0923 20:58:48.325953  9080 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:58:48.325953  9080 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:58:48.325953  9080 net.cpp:137] Memory required for data: 157316800
I0923 20:58:48.325953  9080 layer_factory.cpp:58] Creating layer accuracy_training
I0923 20:58:48.325953  9080 net.cpp:84] Creating Layer accuracy_training
I0923 20:58:48.325953  9080 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0923 20:58:48.325953  9080 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I0923 20:58:48.325953  9080 net.cpp:380] accuracy_training -> accuracy_training
I0923 20:58:48.325953  9080 net.cpp:122] Setting up accuracy_training
I0923 20:58:48.325953  9080 net.cpp:129] Top shape: (1)
I0923 20:58:48.325953  9080 net.cpp:137] Memory required for data: 157316804
I0923 20:58:48.325953  9080 layer_factory.cpp:58] Creating layer loss
I0923 20:58:48.325953  9080 net.cpp:84] Creating Layer loss
I0923 20:58:48.325953  9080 net.cpp:406] loss <- ip1_ip1_0_split_1
I0923 20:58:48.325953  9080 net.cpp:406] loss <- label_cifar_1_split_1
I0923 20:58:48.325953  9080 net.cpp:380] loss -> loss
I0923 20:58:48.325953  9080 layer_factory.cpp:58] Creating layer loss
I0923 20:58:48.326428  9080 net.cpp:122] Setting up loss
I0923 20:58:48.326428  9080 net.cpp:129] Top shape: (1)
I0923 20:58:48.326428  9080 net.cpp:132]     with loss weight 1
I0923 20:58:48.326428  9080 net.cpp:137] Memory required for data: 157316808
I0923 20:58:48.326428  9080 net.cpp:198] loss needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:200] accuracy_training does not need backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] ip1 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] poolcp6 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] relu_conv12 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] scale_conv12 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] bn_conv12 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] conv12 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] relu_conv11 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] scale_conv11 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] bn_conv11 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] conv11 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] relu4_0 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] scale4_0 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] bn4_0 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] conv4_0 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] pool4_2 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] relu4_2 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] scale4_2 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] bn4_2 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] conv4_2 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] relu4_1 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] scale4_1 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] bn4_1 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] conv4_1 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] relu4 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] scale4 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] bn4 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] conv4 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] relu3_1 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] scale3_1 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] bn3_1 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] conv3_1 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] relu3 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] scale3 needs backward computation.
I0923 20:58:48.326428  9080 net.cpp:198] bn3 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] conv3 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] pool2_1 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] relu2_2 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] scale2_2 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] bn2_2 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] conv2_2 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] relu2_1 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] scale2_1 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] bn2_1 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] conv2_1 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] relu2 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] scale2 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] bn2 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] conv2 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] relu1_0 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] scale1_0 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] bn1_0 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] conv1_0 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] relu1 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] scale1 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] bn1 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:198] conv1 needs backward computation.
I0923 20:58:48.326931  9080 net.cpp:200] label_cifar_1_split does not need backward computation.
I0923 20:58:48.326931  9080 net.cpp:200] cifar does not need backward computation.
I0923 20:58:48.326931  9080 net.cpp:242] This network produces output accuracy_training
I0923 20:58:48.326931  9080 net.cpp:242] This network produces output loss
I0923 20:58:48.326931  9080 net.cpp:255] Network initialization done.
I0923 20:58:48.327431  9080 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:58:48.327431  9080 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0923 20:58:48.327431  9080 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I0923 20:58:48.327931  9080 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0923 20:58:48.327931  9080 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_drpall_Simple_NoGroupCon_NoDrp_noaug"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 35
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 43
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0923 20:58:48.328433  9080 layer_factory.cpp:58] Creating layer cifar
I0923 20:58:48.335175  9080 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0923 20:58:48.335175  9080 net.cpp:84] Creating Layer cifar
I0923 20:58:48.335175  9080 net.cpp:380] cifar -> data
I0923 20:58:48.335175  9080 net.cpp:380] cifar -> label
I0923 20:58:48.335175  9080 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0923 20:58:48.335675  9080 data_layer.cpp:45] output data size: 100,3,32,32
I0923 20:58:48.341590  9080 net.cpp:122] Setting up cifar
I0923 20:58:48.341590  9080 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0923 20:58:48.341590  9080 net.cpp:129] Top shape: 100 (100)
I0923 20:58:48.341590  9080 net.cpp:137] Memory required for data: 1229200
I0923 20:58:48.341590  9080 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0923 20:58:48.341590  9080 net.cpp:84] Creating Layer label_cifar_1_split
I0923 20:58:48.341590  9080 net.cpp:406] label_cifar_1_split <- label
I0923 20:58:48.341590  9080 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0923 20:58:48.341590  9080 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0923 20:58:48.341590  9080 net.cpp:122] Setting up label_cifar_1_split
I0923 20:58:48.341590  9080 net.cpp:129] Top shape: 100 (100)
I0923 20:58:48.341590  9080 net.cpp:129] Top shape: 100 (100)
I0923 20:58:48.341590  9080 net.cpp:137] Memory required for data: 1230000
I0923 20:58:48.341590  9080 layer_factory.cpp:58] Creating layer conv1
I0923 20:58:48.341590  9080 net.cpp:84] Creating Layer conv1
I0923 20:58:48.341590  9080 net.cpp:406] conv1 <- data
I0923 20:58:48.341590  9080 net.cpp:380] conv1 -> conv1
I0923 20:58:48.342582  6276 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0923 20:58:48.343081  9080 net.cpp:122] Setting up conv1
I0923 20:58:48.343081  9080 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:58:48.343081  9080 net.cpp:137] Memory required for data: 3687600
I0923 20:58:48.343081  9080 layer_factory.cpp:58] Creating layer bn1
I0923 20:58:48.343582  9080 net.cpp:84] Creating Layer bn1
I0923 20:58:48.343582  9080 net.cpp:406] bn1 <- conv1
I0923 20:58:48.343582  9080 net.cpp:367] bn1 -> conv1 (in-place)
I0923 20:58:48.343582  9080 net.cpp:122] Setting up bn1
I0923 20:58:48.343582  9080 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:58:48.343582  9080 net.cpp:137] Memory required for data: 6145200
I0923 20:58:48.343582  9080 layer_factory.cpp:58] Creating layer scale1
I0923 20:58:48.343582  9080 net.cpp:84] Creating Layer scale1
I0923 20:58:48.343582  9080 net.cpp:406] scale1 <- conv1
I0923 20:58:48.343582  9080 net.cpp:367] scale1 -> conv1 (in-place)
I0923 20:58:48.343582  9080 layer_factory.cpp:58] Creating layer scale1
I0923 20:58:48.343582  9080 net.cpp:122] Setting up scale1
I0923 20:58:48.343582  9080 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:58:48.343582  9080 net.cpp:137] Memory required for data: 8602800
I0923 20:58:48.343582  9080 layer_factory.cpp:58] Creating layer relu1
I0923 20:58:48.343582  9080 net.cpp:84] Creating Layer relu1
I0923 20:58:48.343582  9080 net.cpp:406] relu1 <- conv1
I0923 20:58:48.343582  9080 net.cpp:367] relu1 -> conv1 (in-place)
I0923 20:58:48.344082  9080 net.cpp:122] Setting up relu1
I0923 20:58:48.344082  9080 net.cpp:129] Top shape: 100 6 32 32 (614400)
I0923 20:58:48.344082  9080 net.cpp:137] Memory required for data: 11060400
I0923 20:58:48.344082  9080 layer_factory.cpp:58] Creating layer conv1_0
I0923 20:58:48.344082  9080 net.cpp:84] Creating Layer conv1_0
I0923 20:58:48.344082  9080 net.cpp:406] conv1_0 <- conv1
I0923 20:58:48.344082  9080 net.cpp:380] conv1_0 -> conv1_0
I0923 20:58:48.345584  9080 net.cpp:122] Setting up conv1_0
I0923 20:58:48.346086  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.346086  9080 net.cpp:137] Memory required for data: 15975600
I0923 20:58:48.346086  9080 layer_factory.cpp:58] Creating layer bn1_0
I0923 20:58:48.346086  9080 net.cpp:84] Creating Layer bn1_0
I0923 20:58:48.346086  9080 net.cpp:406] bn1_0 <- conv1_0
I0923 20:58:48.346086  9080 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I0923 20:58:48.346086  9080 net.cpp:122] Setting up bn1_0
I0923 20:58:48.346086  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.346086  9080 net.cpp:137] Memory required for data: 20890800
I0923 20:58:48.346585  9080 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:58:48.346585  9080 net.cpp:84] Creating Layer scale1_0
I0923 20:58:48.346585  9080 net.cpp:406] scale1_0 <- conv1_0
I0923 20:58:48.346585  9080 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I0923 20:58:48.346585  9080 layer_factory.cpp:58] Creating layer scale1_0
I0923 20:58:48.346585  9080 net.cpp:122] Setting up scale1_0
I0923 20:58:48.346585  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.346585  9080 net.cpp:137] Memory required for data: 25806000
I0923 20:58:48.346585  9080 layer_factory.cpp:58] Creating layer relu1_0
I0923 20:58:48.346585  9080 net.cpp:84] Creating Layer relu1_0
I0923 20:58:48.346585  9080 net.cpp:406] relu1_0 <- conv1_0
I0923 20:58:48.346585  9080 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I0923 20:58:48.346585  9080 net.cpp:122] Setting up relu1_0
I0923 20:58:48.346585  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.346585  9080 net.cpp:137] Memory required for data: 30721200
I0923 20:58:48.346585  9080 layer_factory.cpp:58] Creating layer conv2
I0923 20:58:48.346585  9080 net.cpp:84] Creating Layer conv2
I0923 20:58:48.346585  9080 net.cpp:406] conv2 <- conv1_0
I0923 20:58:48.346585  9080 net.cpp:380] conv2 -> conv2
I0923 20:58:48.348585  9080 net.cpp:122] Setting up conv2
I0923 20:58:48.348585  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.348585  9080 net.cpp:137] Memory required for data: 35636400
I0923 20:58:48.348585  9080 layer_factory.cpp:58] Creating layer bn2
I0923 20:58:48.348585  9080 net.cpp:84] Creating Layer bn2
I0923 20:58:48.348585  9080 net.cpp:406] bn2 <- conv2
I0923 20:58:48.348585  9080 net.cpp:367] bn2 -> conv2 (in-place)
I0923 20:58:48.348585  9080 net.cpp:122] Setting up bn2
I0923 20:58:48.348585  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.348585  9080 net.cpp:137] Memory required for data: 40551600
I0923 20:58:48.349086  9080 layer_factory.cpp:58] Creating layer scale2
I0923 20:58:48.349086  9080 net.cpp:84] Creating Layer scale2
I0923 20:58:48.349086  9080 net.cpp:406] scale2 <- conv2
I0923 20:58:48.349086  9080 net.cpp:367] scale2 -> conv2 (in-place)
I0923 20:58:48.349086  9080 layer_factory.cpp:58] Creating layer scale2
I0923 20:58:48.349086  9080 net.cpp:122] Setting up scale2
I0923 20:58:48.349086  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.349086  9080 net.cpp:137] Memory required for data: 45466800
I0923 20:58:48.349086  9080 layer_factory.cpp:58] Creating layer relu2
I0923 20:58:48.349086  9080 net.cpp:84] Creating Layer relu2
I0923 20:58:48.349086  9080 net.cpp:406] relu2 <- conv2
I0923 20:58:48.349086  9080 net.cpp:367] relu2 -> conv2 (in-place)
I0923 20:58:48.349586  9080 net.cpp:122] Setting up relu2
I0923 20:58:48.349586  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.349586  9080 net.cpp:137] Memory required for data: 50382000
I0923 20:58:48.349586  9080 layer_factory.cpp:58] Creating layer conv2_1
I0923 20:58:48.349586  9080 net.cpp:84] Creating Layer conv2_1
I0923 20:58:48.349586  9080 net.cpp:406] conv2_1 <- conv2
I0923 20:58:48.349586  9080 net.cpp:380] conv2_1 -> conv2_1
I0923 20:58:48.350376  9080 net.cpp:122] Setting up conv2_1
I0923 20:58:48.350376  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.350376  9080 net.cpp:137] Memory required for data: 55297200
I0923 20:58:48.350376  9080 layer_factory.cpp:58] Creating layer bn2_1
I0923 20:58:48.350878  9080 net.cpp:84] Creating Layer bn2_1
I0923 20:58:48.350878  9080 net.cpp:406] bn2_1 <- conv2_1
I0923 20:58:48.350878  9080 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I0923 20:58:48.350878  9080 net.cpp:122] Setting up bn2_1
I0923 20:58:48.350878  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.350878  9080 net.cpp:137] Memory required for data: 60212400
I0923 20:58:48.350878  9080 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:58:48.350878  9080 net.cpp:84] Creating Layer scale2_1
I0923 20:58:48.350878  9080 net.cpp:406] scale2_1 <- conv2_1
I0923 20:58:48.350878  9080 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I0923 20:58:48.350878  9080 layer_factory.cpp:58] Creating layer scale2_1
I0923 20:58:48.350878  9080 net.cpp:122] Setting up scale2_1
I0923 20:58:48.350878  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.350878  9080 net.cpp:137] Memory required for data: 65127600
I0923 20:58:48.350878  9080 layer_factory.cpp:58] Creating layer relu2_1
I0923 20:58:48.350878  9080 net.cpp:84] Creating Layer relu2_1
I0923 20:58:48.350878  9080 net.cpp:406] relu2_1 <- conv2_1
I0923 20:58:48.350878  9080 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0923 20:58:48.351378  9080 net.cpp:122] Setting up relu2_1
I0923 20:58:48.351378  9080 net.cpp:129] Top shape: 100 12 32 32 (1228800)
I0923 20:58:48.351378  9080 net.cpp:137] Memory required for data: 70042800
I0923 20:58:48.351378  9080 layer_factory.cpp:58] Creating layer conv2_2
I0923 20:58:48.351378  9080 net.cpp:84] Creating Layer conv2_2
I0923 20:58:48.351378  9080 net.cpp:406] conv2_2 <- conv2_1
I0923 20:58:48.351378  9080 net.cpp:380] conv2_2 -> conv2_2
I0923 20:58:48.352380  9080 net.cpp:122] Setting up conv2_2
I0923 20:58:48.352380  9080 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:58:48.352380  9080 net.cpp:137] Memory required for data: 77825200
I0923 20:58:48.352380  9080 layer_factory.cpp:58] Creating layer bn2_2
I0923 20:58:48.352380  9080 net.cpp:84] Creating Layer bn2_2
I0923 20:58:48.352380  9080 net.cpp:406] bn2_2 <- conv2_2
I0923 20:58:48.352380  9080 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I0923 20:58:48.352880  9080 net.cpp:122] Setting up bn2_2
I0923 20:58:48.352880  9080 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:58:48.352880  9080 net.cpp:137] Memory required for data: 85607600
I0923 20:58:48.352880  9080 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:58:48.352880  9080 net.cpp:84] Creating Layer scale2_2
I0923 20:58:48.352880  9080 net.cpp:406] scale2_2 <- conv2_2
I0923 20:58:48.352880  9080 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I0923 20:58:48.352880  9080 layer_factory.cpp:58] Creating layer scale2_2
I0923 20:58:48.352880  9080 net.cpp:122] Setting up scale2_2
I0923 20:58:48.352880  9080 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:58:48.352880  9080 net.cpp:137] Memory required for data: 93390000
I0923 20:58:48.352880  9080 layer_factory.cpp:58] Creating layer relu2_2
I0923 20:58:48.352880  9080 net.cpp:84] Creating Layer relu2_2
I0923 20:58:48.352880  9080 net.cpp:406] relu2_2 <- conv2_2
I0923 20:58:48.352880  9080 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0923 20:58:48.353499  9080 net.cpp:122] Setting up relu2_2
I0923 20:58:48.353499  9080 net.cpp:129] Top shape: 100 19 32 32 (1945600)
I0923 20:58:48.353499  9080 net.cpp:137] Memory required for data: 101172400
I0923 20:58:48.353499  9080 layer_factory.cpp:58] Creating layer pool2_1
I0923 20:58:48.353499  9080 net.cpp:84] Creating Layer pool2_1
I0923 20:58:48.353499  9080 net.cpp:406] pool2_1 <- conv2_2
I0923 20:58:48.353499  9080 net.cpp:380] pool2_1 -> pool2_1
I0923 20:58:48.353499  9080 net.cpp:122] Setting up pool2_1
I0923 20:58:48.353499  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.353499  9080 net.cpp:137] Memory required for data: 103118000
I0923 20:58:48.353499  9080 layer_factory.cpp:58] Creating layer conv3
I0923 20:58:48.353499  9080 net.cpp:84] Creating Layer conv3
I0923 20:58:48.353499  9080 net.cpp:406] conv3 <- pool2_1
I0923 20:58:48.353499  9080 net.cpp:380] conv3 -> conv3
I0923 20:58:48.354502  9080 net.cpp:122] Setting up conv3
I0923 20:58:48.354502  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.354502  9080 net.cpp:137] Memory required for data: 105063600
I0923 20:58:48.354502  9080 layer_factory.cpp:58] Creating layer bn3
I0923 20:58:48.354502  9080 net.cpp:84] Creating Layer bn3
I0923 20:58:48.354502  9080 net.cpp:406] bn3 <- conv3
I0923 20:58:48.354502  9080 net.cpp:367] bn3 -> conv3 (in-place)
I0923 20:58:48.354502  9080 net.cpp:122] Setting up bn3
I0923 20:58:48.354502  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.354502  9080 net.cpp:137] Memory required for data: 107009200
I0923 20:58:48.354502  9080 layer_factory.cpp:58] Creating layer scale3
I0923 20:58:48.354502  9080 net.cpp:84] Creating Layer scale3
I0923 20:58:48.354502  9080 net.cpp:406] scale3 <- conv3
I0923 20:58:48.354502  9080 net.cpp:367] scale3 -> conv3 (in-place)
I0923 20:58:48.354502  9080 layer_factory.cpp:58] Creating layer scale3
I0923 20:58:48.355003  9080 net.cpp:122] Setting up scale3
I0923 20:58:48.355003  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.355003  9080 net.cpp:137] Memory required for data: 108954800
I0923 20:58:48.355003  9080 layer_factory.cpp:58] Creating layer relu3
I0923 20:58:48.355003  9080 net.cpp:84] Creating Layer relu3
I0923 20:58:48.355003  9080 net.cpp:406] relu3 <- conv3
I0923 20:58:48.355003  9080 net.cpp:367] relu3 -> conv3 (in-place)
I0923 20:58:48.355003  9080 net.cpp:122] Setting up relu3
I0923 20:58:48.355504  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.355504  9080 net.cpp:137] Memory required for data: 110900400
I0923 20:58:48.355504  9080 layer_factory.cpp:58] Creating layer conv3_1
I0923 20:58:48.355504  9080 net.cpp:84] Creating Layer conv3_1
I0923 20:58:48.355504  9080 net.cpp:406] conv3_1 <- conv3
I0923 20:58:48.355504  9080 net.cpp:380] conv3_1 -> conv3_1
I0923 20:58:48.356503  9080 net.cpp:122] Setting up conv3_1
I0923 20:58:48.356503  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.356503  9080 net.cpp:137] Memory required for data: 112846000
I0923 20:58:48.356503  9080 layer_factory.cpp:58] Creating layer bn3_1
I0923 20:58:48.356503  9080 net.cpp:84] Creating Layer bn3_1
I0923 20:58:48.356503  9080 net.cpp:406] bn3_1 <- conv3_1
I0923 20:58:48.356503  9080 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I0923 20:58:48.356503  9080 net.cpp:122] Setting up bn3_1
I0923 20:58:48.356503  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.356503  9080 net.cpp:137] Memory required for data: 114791600
I0923 20:58:48.356503  9080 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:58:48.356503  9080 net.cpp:84] Creating Layer scale3_1
I0923 20:58:48.357004  9080 net.cpp:406] scale3_1 <- conv3_1
I0923 20:58:48.357004  9080 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I0923 20:58:48.357004  9080 layer_factory.cpp:58] Creating layer scale3_1
I0923 20:58:48.357004  9080 net.cpp:122] Setting up scale3_1
I0923 20:58:48.357004  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.357004  9080 net.cpp:137] Memory required for data: 116737200
I0923 20:58:48.357004  9080 layer_factory.cpp:58] Creating layer relu3_1
I0923 20:58:48.357004  9080 net.cpp:84] Creating Layer relu3_1
I0923 20:58:48.357004  9080 net.cpp:406] relu3_1 <- conv3_1
I0923 20:58:48.357004  9080 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0923 20:58:48.357004  9080 net.cpp:122] Setting up relu3_1
I0923 20:58:48.357004  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.357004  9080 net.cpp:137] Memory required for data: 118682800
I0923 20:58:48.357004  9080 layer_factory.cpp:58] Creating layer conv4
I0923 20:58:48.357004  9080 net.cpp:84] Creating Layer conv4
I0923 20:58:48.357004  9080 net.cpp:406] conv4 <- conv3_1
I0923 20:58:48.357004  9080 net.cpp:380] conv4 -> conv4
I0923 20:58:48.358505  9080 net.cpp:122] Setting up conv4
I0923 20:58:48.358505  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.358505  9080 net.cpp:137] Memory required for data: 120628400
I0923 20:58:48.358505  9080 layer_factory.cpp:58] Creating layer bn4
I0923 20:58:48.358505  9080 net.cpp:84] Creating Layer bn4
I0923 20:58:48.358505  9080 net.cpp:406] bn4 <- conv4
I0923 20:58:48.358505  9080 net.cpp:367] bn4 -> conv4 (in-place)
I0923 20:58:48.358505  9080 net.cpp:122] Setting up bn4
I0923 20:58:48.358505  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.358505  9080 net.cpp:137] Memory required for data: 122574000
I0923 20:58:48.358505  9080 layer_factory.cpp:58] Creating layer scale4
I0923 20:58:48.358505  9080 net.cpp:84] Creating Layer scale4
I0923 20:58:48.358505  9080 net.cpp:406] scale4 <- conv4
I0923 20:58:48.358505  9080 net.cpp:367] scale4 -> conv4 (in-place)
I0923 20:58:48.358505  9080 layer_factory.cpp:58] Creating layer scale4
I0923 20:58:48.359005  9080 net.cpp:122] Setting up scale4
I0923 20:58:48.359005  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.359005  9080 net.cpp:137] Memory required for data: 124519600
I0923 20:58:48.359005  9080 layer_factory.cpp:58] Creating layer relu4
I0923 20:58:48.359005  9080 net.cpp:84] Creating Layer relu4
I0923 20:58:48.359005  9080 net.cpp:406] relu4 <- conv4
I0923 20:58:48.359005  9080 net.cpp:367] relu4 -> conv4 (in-place)
I0923 20:58:48.359005  9080 net.cpp:122] Setting up relu4
I0923 20:58:48.359005  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.359005  9080 net.cpp:137] Memory required for data: 126465200
I0923 20:58:48.359005  9080 layer_factory.cpp:58] Creating layer conv4_1
I0923 20:58:48.359005  9080 net.cpp:84] Creating Layer conv4_1
I0923 20:58:48.359005  9080 net.cpp:406] conv4_1 <- conv4
I0923 20:58:48.359005  9080 net.cpp:380] conv4_1 -> conv4_1
I0923 20:58:48.359843  9080 net.cpp:122] Setting up conv4_1
I0923 20:58:48.359843  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.359843  9080 net.cpp:137] Memory required for data: 128410800
I0923 20:58:48.359843  9080 layer_factory.cpp:58] Creating layer bn4_1
I0923 20:58:48.359843  9080 net.cpp:84] Creating Layer bn4_1
I0923 20:58:48.359843  9080 net.cpp:406] bn4_1 <- conv4_1
I0923 20:58:48.359843  9080 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I0923 20:58:48.360347  9080 net.cpp:122] Setting up bn4_1
I0923 20:58:48.360347  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.360347  9080 net.cpp:137] Memory required for data: 130356400
I0923 20:58:48.360347  9080 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:58:48.360347  9080 net.cpp:84] Creating Layer scale4_1
I0923 20:58:48.360347  9080 net.cpp:406] scale4_1 <- conv4_1
I0923 20:58:48.360347  9080 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I0923 20:58:48.360347  9080 layer_factory.cpp:58] Creating layer scale4_1
I0923 20:58:48.360347  9080 net.cpp:122] Setting up scale4_1
I0923 20:58:48.360347  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.360347  9080 net.cpp:137] Memory required for data: 132302000
I0923 20:58:48.360347  9080 layer_factory.cpp:58] Creating layer relu4_1
I0923 20:58:48.360347  9080 net.cpp:84] Creating Layer relu4_1
I0923 20:58:48.360347  9080 net.cpp:406] relu4_1 <- conv4_1
I0923 20:58:48.360347  9080 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0923 20:58:48.360347  9080 net.cpp:122] Setting up relu4_1
I0923 20:58:48.360347  9080 net.cpp:129] Top shape: 100 19 16 16 (486400)
I0923 20:58:48.360347  9080 net.cpp:137] Memory required for data: 134247600
I0923 20:58:48.360347  9080 layer_factory.cpp:58] Creating layer conv4_2
I0923 20:58:48.360846  9080 net.cpp:84] Creating Layer conv4_2
I0923 20:58:48.360846  9080 net.cpp:406] conv4_2 <- conv4_1
I0923 20:58:48.360846  9080 net.cpp:380] conv4_2 -> conv4_2
I0923 20:58:48.361516  9080 net.cpp:122] Setting up conv4_2
I0923 20:58:48.362020  9080 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:58:48.362020  9080 net.cpp:137] Memory required for data: 137114800
I0923 20:58:48.362020  9080 layer_factory.cpp:58] Creating layer bn4_2
I0923 20:58:48.362020  9080 net.cpp:84] Creating Layer bn4_2
I0923 20:58:48.362020  9080 net.cpp:406] bn4_2 <- conv4_2
I0923 20:58:48.362020  9080 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I0923 20:58:48.362020  9080 net.cpp:122] Setting up bn4_2
I0923 20:58:48.362020  9080 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:58:48.362020  9080 net.cpp:137] Memory required for data: 139982000
I0923 20:58:48.362020  9080 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:58:48.362020  9080 net.cpp:84] Creating Layer scale4_2
I0923 20:58:48.362020  9080 net.cpp:406] scale4_2 <- conv4_2
I0923 20:58:48.362020  9080 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I0923 20:58:48.362020  9080 layer_factory.cpp:58] Creating layer scale4_2
I0923 20:58:48.362020  9080 net.cpp:122] Setting up scale4_2
I0923 20:58:48.362020  9080 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:58:48.362020  9080 net.cpp:137] Memory required for data: 142849200
I0923 20:58:48.362020  9080 layer_factory.cpp:58] Creating layer relu4_2
I0923 20:58:48.362020  9080 net.cpp:84] Creating Layer relu4_2
I0923 20:58:48.362020  9080 net.cpp:406] relu4_2 <- conv4_2
I0923 20:58:48.362020  9080 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0923 20:58:48.362519  9080 net.cpp:122] Setting up relu4_2
I0923 20:58:48.362519  9080 net.cpp:129] Top shape: 100 28 16 16 (716800)
I0923 20:58:48.362519  9080 net.cpp:137] Memory required for data: 145716400
I0923 20:58:48.362519  9080 layer_factory.cpp:58] Creating layer pool4_2
I0923 20:58:48.362519  9080 net.cpp:84] Creating Layer pool4_2
I0923 20:58:48.362519  9080 net.cpp:406] pool4_2 <- conv4_2
I0923 20:58:48.362519  9080 net.cpp:380] pool4_2 -> pool4_2
I0923 20:58:48.362519  9080 net.cpp:122] Setting up pool4_2
I0923 20:58:48.362519  9080 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:58:48.362519  9080 net.cpp:137] Memory required for data: 146433200
I0923 20:58:48.362519  9080 layer_factory.cpp:58] Creating layer conv4_0
I0923 20:58:48.362519  9080 net.cpp:84] Creating Layer conv4_0
I0923 20:58:48.362519  9080 net.cpp:406] conv4_0 <- pool4_2
I0923 20:58:48.362519  9080 net.cpp:380] conv4_0 -> conv4_0
I0923 20:58:48.363519  9080 net.cpp:122] Setting up conv4_0
I0923 20:58:48.363519  9080 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:58:48.363519  9080 net.cpp:137] Memory required for data: 147150000
I0923 20:58:48.363519  9080 layer_factory.cpp:58] Creating layer bn4_0
I0923 20:58:48.363519  9080 net.cpp:84] Creating Layer bn4_0
I0923 20:58:48.363519  9080 net.cpp:406] bn4_0 <- conv4_0
I0923 20:58:48.363519  9080 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I0923 20:58:48.364019  9080 net.cpp:122] Setting up bn4_0
I0923 20:58:48.364019  9080 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:58:48.364019  9080 net.cpp:137] Memory required for data: 147866800
I0923 20:58:48.364019  9080 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:58:48.364019  9080 net.cpp:84] Creating Layer scale4_0
I0923 20:58:48.364019  9080 net.cpp:406] scale4_0 <- conv4_0
I0923 20:58:48.364019  9080 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I0923 20:58:48.364019  9080 layer_factory.cpp:58] Creating layer scale4_0
I0923 20:58:48.364019  9080 net.cpp:122] Setting up scale4_0
I0923 20:58:48.364019  9080 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:58:48.364019  9080 net.cpp:137] Memory required for data: 148583600
I0923 20:58:48.364019  9080 layer_factory.cpp:58] Creating layer relu4_0
I0923 20:58:48.364019  9080 net.cpp:84] Creating Layer relu4_0
I0923 20:58:48.364019  9080 net.cpp:406] relu4_0 <- conv4_0
I0923 20:58:48.364019  9080 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I0923 20:58:48.364519  9080 net.cpp:122] Setting up relu4_0
I0923 20:58:48.364519  9080 net.cpp:129] Top shape: 100 28 8 8 (179200)
I0923 20:58:48.364519  9080 net.cpp:137] Memory required for data: 149300400
I0923 20:58:48.364519  9080 layer_factory.cpp:58] Creating layer conv11
I0923 20:58:48.365020  9080 net.cpp:84] Creating Layer conv11
I0923 20:58:48.365020  9080 net.cpp:406] conv11 <- conv4_0
I0923 20:58:48.365020  9080 net.cpp:380] conv11 -> conv11
I0923 20:58:48.365520  9080 net.cpp:122] Setting up conv11
I0923 20:58:48.366020  9080 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:58:48.366020  9080 net.cpp:137] Memory required for data: 150196400
I0923 20:58:48.366020  9080 layer_factory.cpp:58] Creating layer bn_conv11
I0923 20:58:48.366020  9080 net.cpp:84] Creating Layer bn_conv11
I0923 20:58:48.366020  9080 net.cpp:406] bn_conv11 <- conv11
I0923 20:58:48.366020  9080 net.cpp:367] bn_conv11 -> conv11 (in-place)
I0923 20:58:48.366020  9080 net.cpp:122] Setting up bn_conv11
I0923 20:58:48.366020  9080 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:58:48.366020  9080 net.cpp:137] Memory required for data: 151092400
I0923 20:58:48.366020  9080 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:58:48.366020  9080 net.cpp:84] Creating Layer scale_conv11
I0923 20:58:48.366020  9080 net.cpp:406] scale_conv11 <- conv11
I0923 20:58:48.366020  9080 net.cpp:367] scale_conv11 -> conv11 (in-place)
I0923 20:58:48.366020  9080 layer_factory.cpp:58] Creating layer scale_conv11
I0923 20:58:48.366521  9080 net.cpp:122] Setting up scale_conv11
I0923 20:58:48.366521  9080 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:58:48.366521  9080 net.cpp:137] Memory required for data: 151988400
I0923 20:58:48.366521  9080 layer_factory.cpp:58] Creating layer relu_conv11
I0923 20:58:48.366521  9080 net.cpp:84] Creating Layer relu_conv11
I0923 20:58:48.366521  9080 net.cpp:406] relu_conv11 <- conv11
I0923 20:58:48.366521  9080 net.cpp:367] relu_conv11 -> conv11 (in-place)
I0923 20:58:48.367022  9080 net.cpp:122] Setting up relu_conv11
I0923 20:58:48.367022  9080 net.cpp:129] Top shape: 100 35 8 8 (224000)
I0923 20:58:48.367022  9080 net.cpp:137] Memory required for data: 152884400
I0923 20:58:48.367022  9080 layer_factory.cpp:58] Creating layer conv12
I0923 20:58:48.367022  9080 net.cpp:84] Creating Layer conv12
I0923 20:58:48.367022  9080 net.cpp:406] conv12 <- conv11
I0923 20:58:48.367022  9080 net.cpp:380] conv12 -> conv12
I0923 20:58:48.369524  9080 net.cpp:122] Setting up conv12
I0923 20:58:48.369524  9080 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:58:48.369524  9080 net.cpp:137] Memory required for data: 153985200
I0923 20:58:48.370023  9080 layer_factory.cpp:58] Creating layer bn_conv12
I0923 20:58:48.370023  9080 net.cpp:84] Creating Layer bn_conv12
I0923 20:58:48.370023  9080 net.cpp:406] bn_conv12 <- conv12
I0923 20:58:48.370023  9080 net.cpp:367] bn_conv12 -> conv12 (in-place)
I0923 20:58:48.371032  9080 net.cpp:122] Setting up bn_conv12
I0923 20:58:48.371032  9080 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:58:48.371032  9080 net.cpp:137] Memory required for data: 155086000
I0923 20:58:48.371032  9080 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:58:48.371032  9080 net.cpp:84] Creating Layer scale_conv12
I0923 20:58:48.371032  9080 net.cpp:406] scale_conv12 <- conv12
I0923 20:58:48.371032  9080 net.cpp:367] scale_conv12 -> conv12 (in-place)
I0923 20:58:48.371032  9080 layer_factory.cpp:58] Creating layer scale_conv12
I0923 20:58:48.371525  9080 net.cpp:122] Setting up scale_conv12
I0923 20:58:48.371525  9080 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:58:48.371525  9080 net.cpp:137] Memory required for data: 156186800
I0923 20:58:48.371525  9080 layer_factory.cpp:58] Creating layer relu_conv12
I0923 20:58:48.371525  9080 net.cpp:84] Creating Layer relu_conv12
I0923 20:58:48.372030  9080 net.cpp:406] relu_conv12 <- conv12
I0923 20:58:48.372030  9080 net.cpp:367] relu_conv12 -> conv12 (in-place)
I0923 20:58:48.373026  9080 net.cpp:122] Setting up relu_conv12
I0923 20:58:48.373527  9080 net.cpp:129] Top shape: 100 43 8 8 (275200)
I0923 20:58:48.373527  9080 net.cpp:137] Memory required for data: 157287600
I0923 20:58:48.373527  9080 layer_factory.cpp:58] Creating layer poolcp6
I0923 20:58:48.373527  9080 net.cpp:84] Creating Layer poolcp6
I0923 20:58:48.373527  9080 net.cpp:406] poolcp6 <- conv12
I0923 20:58:48.373527  9080 net.cpp:380] poolcp6 -> poolcp6
I0923 20:58:48.373527  9080 net.cpp:122] Setting up poolcp6
I0923 20:58:48.373527  9080 net.cpp:129] Top shape: 100 43 1 1 (4300)
I0923 20:58:48.373527  9080 net.cpp:137] Memory required for data: 157304800
I0923 20:58:48.373527  9080 layer_factory.cpp:58] Creating layer ip1
I0923 20:58:48.374027  9080 net.cpp:84] Creating Layer ip1
I0923 20:58:48.374027  9080 net.cpp:406] ip1 <- poolcp6
I0923 20:58:48.374027  9080 net.cpp:380] ip1 -> ip1
I0923 20:58:48.374526  9080 net.cpp:122] Setting up ip1
I0923 20:58:48.374526  9080 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:58:48.374526  9080 net.cpp:137] Memory required for data: 157308800
I0923 20:58:48.374526  9080 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0923 20:58:48.374526  9080 net.cpp:84] Creating Layer ip1_ip1_0_split
I0923 20:58:48.374526  9080 net.cpp:406] ip1_ip1_0_split <- ip1
I0923 20:58:48.375027  9080 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0923 20:58:48.375027  9080 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0923 20:58:48.375027  9080 net.cpp:122] Setting up ip1_ip1_0_split
I0923 20:58:48.375027  9080 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:58:48.375027  9080 net.cpp:129] Top shape: 100 10 (1000)
I0923 20:58:48.375027  9080 net.cpp:137] Memory required for data: 157316800
I0923 20:58:48.375027  9080 layer_factory.cpp:58] Creating layer accuracy
I0923 20:58:48.375027  9080 net.cpp:84] Creating Layer accuracy
I0923 20:58:48.375027  9080 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0923 20:58:48.375027  9080 net.cpp:406] accuracy <- label_cifar_1_split_0
I0923 20:58:48.375027  9080 net.cpp:380] accuracy -> accuracy
I0923 20:58:48.375027  9080 net.cpp:122] Setting up accuracy
I0923 20:58:48.375027  9080 net.cpp:129] Top shape: (1)
I0923 20:58:48.375027  9080 net.cpp:137] Memory required for data: 157316804
I0923 20:58:48.375027  9080 layer_factory.cpp:58] Creating layer loss
I0923 20:58:48.375027  9080 net.cpp:84] Creating Layer loss
I0923 20:58:48.375027  9080 net.cpp:406] loss <- ip1_ip1_0_split_1
I0923 20:58:48.375027  9080 net.cpp:406] loss <- label_cifar_1_split_1
I0923 20:58:48.375527  9080 net.cpp:380] loss -> loss
I0923 20:58:48.375527  9080 layer_factory.cpp:58] Creating layer loss
I0923 20:58:48.376528  9080 net.cpp:122] Setting up loss
I0923 20:58:48.376528  9080 net.cpp:129] Top shape: (1)
I0923 20:58:48.376528  9080 net.cpp:132]     with loss weight 1
I0923 20:58:48.376528  9080 net.cpp:137] Memory required for data: 157316808
I0923 20:58:48.376528  9080 net.cpp:198] loss needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:200] accuracy does not need backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] ip1 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] poolcp6 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] relu_conv12 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] scale_conv12 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] bn_conv12 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] conv12 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] relu_conv11 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] scale_conv11 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] bn_conv11 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] conv11 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] relu4_0 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] scale4_0 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] bn4_0 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] conv4_0 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] pool4_2 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] relu4_2 needs backward computation.
I0923 20:58:48.376528  9080 net.cpp:198] scale4_2 needs backward computation.
I0923 20:58:48.377028  9080 net.cpp:198] bn4_2 needs backward computation.
I0923 20:58:48.377028  9080 net.cpp:198] conv4_2 needs backward computation.
I0923 20:58:48.377028  9080 net.cpp:198] relu4_1 needs backward computation.
I0923 20:58:48.377028  9080 net.cpp:198] scale4_1 needs backward computation.
I0923 20:58:48.377028  9080 net.cpp:198] bn4_1 needs backward computation.
I0923 20:58:48.377028  9080 net.cpp:198] conv4_1 needs backward computation.
I0923 20:58:48.377028  9080 net.cpp:198] relu4 needs backward computation.
I0923 20:58:48.377028  9080 net.cpp:198] scale4 needs backward computation.
I0923 20:58:48.377028  9080 net.cpp:198] bn4 needs backward computation.
I0923 20:58:48.377028  9080 net.cpp:198] conv4 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] relu3_1 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] scale3_1 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] bn3_1 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] conv3_1 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] relu3 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] scale3 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] bn3 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] conv3 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] pool2_1 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] relu2_2 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] scale2_2 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] bn2_2 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] conv2_2 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] relu2_1 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] scale2_1 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] bn2_1 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] conv2_1 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] relu2 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] scale2 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] bn2 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] conv2 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] relu1_0 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] scale1_0 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] bn1_0 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] conv1_0 needs backward computation.
I0923 20:58:48.377537  9080 net.cpp:198] relu1 needs backward computation.
I0923 20:58:48.378029  9080 net.cpp:198] scale1 needs backward computation.
I0923 20:58:48.378029  9080 net.cpp:198] bn1 needs backward computation.
I0923 20:58:48.378029  9080 net.cpp:198] conv1 needs backward computation.
I0923 20:58:48.378029  9080 net.cpp:200] label_cifar_1_split does not need backward computation.
I0923 20:58:48.378029  9080 net.cpp:200] cifar does not need backward computation.
I0923 20:58:48.378029  9080 net.cpp:242] This network produces output accuracy
I0923 20:58:48.378029  9080 net.cpp:242] This network produces output loss
I0923 20:58:48.378029  9080 net.cpp:255] Network initialization done.
I0923 20:58:48.379029  9080 solver.cpp:56] Solver scaffolding done.
I0923 20:58:48.383034  9080 caffe.cpp:249] Starting Optimization
I0923 20:58:48.383034  9080 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_drpall_Simple_NoGroupCon_NoDrp_noaug
I0923 20:58:48.383034  9080 solver.cpp:273] Learning Rate Policy: multistep
I0923 20:58:48.385040  9080 solver.cpp:330] Iteration 0, Testing net (#0)
I0923 20:58:48.387042  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:58:48.948724  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:58:48.969748  9080 solver.cpp:397]     Test net output #0: accuracy = 0.0983
I0923 20:58:48.969748  9080 solver.cpp:397]     Test net output #1: loss = 78.7514 (* 1 = 78.7514 loss)
I0923 20:58:49.022322  9080 solver.cpp:218] Iteration 0 (-3.60274e-41 iter/s, 0.637099s/100 iters), loss = 3.52576
I0923 20:58:49.022322  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.1
I0923 20:58:49.022322  9080 solver.cpp:237]     Train net output #1: loss = 3.52576 (* 1 = 3.52576 loss)
I0923 20:58:49.022322  9080 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0923 20:58:51.835825  9080 solver.cpp:218] Iteration 100 (35.5444 iter/s, 2.81338s/100 iters), loss = 1.75646
I0923 20:58:51.836325  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I0923 20:58:51.836325  9080 solver.cpp:237]     Train net output #1: loss = 1.75646 (* 1 = 1.75646 loss)
I0923 20:58:51.836325  9080 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0923 20:58:54.642843  9080 solver.cpp:218] Iteration 200 (35.6305 iter/s, 2.80658s/100 iters), loss = 1.75837
I0923 20:58:54.642843  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I0923 20:58:54.642843  9080 solver.cpp:237]     Train net output #1: loss = 1.75837 (* 1 = 1.75837 loss)
I0923 20:58:54.642843  9080 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0923 20:58:57.443225  9080 solver.cpp:218] Iteration 300 (35.7139 iter/s, 2.80003s/100 iters), loss = 1.4652
I0923 20:58:57.443225  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I0923 20:58:57.443225  9080 solver.cpp:237]     Train net output #1: loss = 1.4652 (* 1 = 1.4652 loss)
I0923 20:58:57.443225  9080 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0923 20:59:00.245730  9080 solver.cpp:218] Iteration 400 (35.6895 iter/s, 2.80194s/100 iters), loss = 1.35006
I0923 20:59:00.245730  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I0923 20:59:00.245730  9080 solver.cpp:237]     Train net output #1: loss = 1.35006 (* 1 = 1.35006 loss)
I0923 20:59:00.245730  9080 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0923 20:59:02.905620 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:59:03.041726  9080 solver.cpp:218] Iteration 500 (35.7674 iter/s, 2.79585s/100 iters), loss = 1.35615
I0923 20:59:03.041726  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I0923 20:59:03.041726  9080 solver.cpp:237]     Train net output #1: loss = 1.35615 (* 1 = 1.35615 loss)
I0923 20:59:03.041726  9080 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0923 20:59:05.830786  9080 solver.cpp:218] Iteration 600 (35.8627 iter/s, 2.78841s/100 iters), loss = 1.31067
I0923 20:59:05.830786  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I0923 20:59:05.830786  9080 solver.cpp:237]     Train net output #1: loss = 1.31067 (* 1 = 1.31067 loss)
I0923 20:59:05.830786  9080 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0923 20:59:08.623770  9080 solver.cpp:218] Iteration 700 (35.8043 iter/s, 2.79296s/100 iters), loss = 1.3315
I0923 20:59:08.623770  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I0923 20:59:08.623770  9080 solver.cpp:237]     Train net output #1: loss = 1.3315 (* 1 = 1.3315 loss)
I0923 20:59:08.623770  9080 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0923 20:59:11.408795  9080 solver.cpp:218] Iteration 800 (35.9098 iter/s, 2.78476s/100 iters), loss = 1.16739
I0923 20:59:11.409296  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I0923 20:59:11.409296  9080 solver.cpp:237]     Train net output #1: loss = 1.16739 (* 1 = 1.16739 loss)
I0923 20:59:11.409296  9080 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0923 20:59:14.196578  9080 solver.cpp:218] Iteration 900 (35.8758 iter/s, 2.78739s/100 iters), loss = 1.06342
I0923 20:59:14.196578  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I0923 20:59:14.196578  9080 solver.cpp:237]     Train net output #1: loss = 1.06342 (* 1 = 1.06342 loss)
I0923 20:59:14.196578  9080 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0923 20:59:16.850968 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:59:16.960551  9080 solver.cpp:330] Iteration 1000, Testing net (#0)
I0923 20:59:16.960551  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:59:17.487725  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:59:17.508739  9080 solver.cpp:397]     Test net output #0: accuracy = 0.5946
I0923 20:59:17.508739  9080 solver.cpp:397]     Test net output #1: loss = 1.13001 (* 1 = 1.13001 loss)
I0923 20:59:17.533756  9080 solver.cpp:218] Iteration 1000 (29.9679 iter/s, 3.3369s/100 iters), loss = 1.17908
I0923 20:59:17.533756  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I0923 20:59:17.534257  9080 solver.cpp:237]     Train net output #1: loss = 1.17908 (* 1 = 1.17908 loss)
I0923 20:59:17.534257  9080 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0923 20:59:20.327744  9080 solver.cpp:218] Iteration 1100 (35.8002 iter/s, 2.79328s/100 iters), loss = 1.13188
I0923 20:59:20.327744  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I0923 20:59:20.327744  9080 solver.cpp:237]     Train net output #1: loss = 1.13188 (* 1 = 1.13188 loss)
I0923 20:59:20.327744  9080 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0923 20:59:23.114811  9080 solver.cpp:218] Iteration 1200 (35.8823 iter/s, 2.78689s/100 iters), loss = 1.07295
I0923 20:59:23.114811  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I0923 20:59:23.114811  9080 solver.cpp:237]     Train net output #1: loss = 1.07295 (* 1 = 1.07295 loss)
I0923 20:59:23.114811  9080 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0923 20:59:25.904475  9080 solver.cpp:218] Iteration 1300 (35.8531 iter/s, 2.78916s/100 iters), loss = 0.945876
I0923 20:59:25.904475  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0923 20:59:25.904475  9080 solver.cpp:237]     Train net output #1: loss = 0.945876 (* 1 = 0.945876 loss)
I0923 20:59:25.904475  9080 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0923 20:59:28.684790  9080 solver.cpp:218] Iteration 1400 (35.9687 iter/s, 2.7802s/100 iters), loss = 0.857652
I0923 20:59:28.684790  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0923 20:59:28.684790  9080 solver.cpp:237]     Train net output #1: loss = 0.857652 (* 1 = 0.857652 loss)
I0923 20:59:28.684790  9080 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0923 20:59:31.338306 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:59:31.474417  9080 solver.cpp:218] Iteration 1500 (35.8545 iter/s, 2.78905s/100 iters), loss = 1.01397
I0923 20:59:31.474417  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I0923 20:59:31.474417  9080 solver.cpp:237]     Train net output #1: loss = 1.01397 (* 1 = 1.01397 loss)
I0923 20:59:31.474417  9080 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0923 20:59:34.262681  9080 solver.cpp:218] Iteration 1600 (35.8672 iter/s, 2.78806s/100 iters), loss = 0.846119
I0923 20:59:34.262681  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0923 20:59:34.262681  9080 solver.cpp:237]     Train net output #1: loss = 0.846119 (* 1 = 0.846119 loss)
I0923 20:59:34.262681  9080 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0923 20:59:37.055600  9080 solver.cpp:218] Iteration 1700 (35.8119 iter/s, 2.79237s/100 iters), loss = 1.08197
I0923 20:59:37.055600  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I0923 20:59:37.055600  9080 solver.cpp:237]     Train net output #1: loss = 1.08197 (* 1 = 1.08197 loss)
I0923 20:59:37.055600  9080 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0923 20:59:39.849608  9080 solver.cpp:218] Iteration 1800 (35.7934 iter/s, 2.79381s/100 iters), loss = 0.881866
I0923 20:59:39.849608  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 20:59:39.849608  9080 solver.cpp:237]     Train net output #1: loss = 0.881866 (* 1 = 0.881866 loss)
I0923 20:59:39.849608  9080 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0923 20:59:42.641499  9080 solver.cpp:218] Iteration 1900 (35.8247 iter/s, 2.79137s/100 iters), loss = 0.927134
I0923 20:59:42.641499  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0923 20:59:42.641499  9080 solver.cpp:237]     Train net output #1: loss = 0.927134 (* 1 = 0.927134 loss)
I0923 20:59:42.641499  9080 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0923 20:59:45.297883 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:59:45.407971  9080 solver.cpp:330] Iteration 2000, Testing net (#0)
I0923 20:59:45.407971  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 20:59:45.934316  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:59:45.955319  9080 solver.cpp:397]     Test net output #0: accuracy = 0.6593
I0923 20:59:45.955319  9080 solver.cpp:397]     Test net output #1: loss = 0.969558 (* 1 = 0.969558 loss)
I0923 20:59:45.980847  9080 solver.cpp:218] Iteration 2000 (29.9481 iter/s, 3.33911s/100 iters), loss = 0.945135
I0923 20:59:45.980847  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I0923 20:59:45.980847  9080 solver.cpp:237]     Train net output #1: loss = 0.945135 (* 1 = 0.945135 loss)
I0923 20:59:45.980847  9080 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0923 20:59:48.766965  9080 solver.cpp:218] Iteration 2100 (35.8936 iter/s, 2.78601s/100 iters), loss = 0.797538
I0923 20:59:48.766965  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 20:59:48.767467  9080 solver.cpp:237]     Train net output #1: loss = 0.797538 (* 1 = 0.797538 loss)
I0923 20:59:48.767467  9080 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0923 20:59:51.553874  9080 solver.cpp:218] Iteration 2200 (35.8877 iter/s, 2.78647s/100 iters), loss = 0.838348
I0923 20:59:51.553874  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0923 20:59:51.553874  9080 solver.cpp:237]     Train net output #1: loss = 0.838348 (* 1 = 0.838348 loss)
I0923 20:59:51.553874  9080 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0923 20:59:54.341398  9080 solver.cpp:218] Iteration 2300 (35.8807 iter/s, 2.78701s/100 iters), loss = 0.846277
I0923 20:59:54.341398  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0923 20:59:54.341398  9080 solver.cpp:237]     Train net output #1: loss = 0.846277 (* 1 = 0.846277 loss)
I0923 20:59:54.341398  9080 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0923 20:59:57.131018  9080 solver.cpp:218] Iteration 2400 (35.8522 iter/s, 2.78923s/100 iters), loss = 0.734961
I0923 20:59:57.131018  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 20:59:57.131018  9080 solver.cpp:237]     Train net output #1: loss = 0.734961 (* 1 = 0.734961 loss)
I0923 20:59:57.131018  9080 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0923 20:59:59.785919 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 20:59:59.922494  9080 solver.cpp:218] Iteration 2500 (35.8232 iter/s, 2.79148s/100 iters), loss = 0.913603
I0923 20:59:59.922996  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I0923 20:59:59.922996  9080 solver.cpp:237]     Train net output #1: loss = 0.913603 (* 1 = 0.913603 loss)
I0923 20:59:59.922996  9080 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0923 21:00:02.751587  9080 solver.cpp:218] Iteration 2600 (35.3556 iter/s, 2.82841s/100 iters), loss = 0.793302
I0923 21:00:02.751587  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 21:00:02.751587  9080 solver.cpp:237]     Train net output #1: loss = 0.793302 (* 1 = 0.793302 loss)
I0923 21:00:02.751587  9080 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0923 21:00:05.548883  9080 solver.cpp:218] Iteration 2700 (35.7497 iter/s, 2.79722s/100 iters), loss = 0.721999
I0923 21:00:05.548883  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0923 21:00:05.548883  9080 solver.cpp:237]     Train net output #1: loss = 0.721999 (* 1 = 0.721999 loss)
I0923 21:00:05.548883  9080 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0923 21:00:08.351400  9080 solver.cpp:218] Iteration 2800 (35.6869 iter/s, 2.80215s/100 iters), loss = 0.750786
I0923 21:00:08.351400  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0923 21:00:08.351400  9080 solver.cpp:237]     Train net output #1: loss = 0.750786 (* 1 = 0.750786 loss)
I0923 21:00:08.351400  9080 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0923 21:00:11.149894  9080 solver.cpp:218] Iteration 2900 (35.7394 iter/s, 2.79803s/100 iters), loss = 0.781418
I0923 21:00:11.149894  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0923 21:00:11.149894  9080 solver.cpp:237]     Train net output #1: loss = 0.781418 (* 1 = 0.781418 loss)
I0923 21:00:11.149894  9080 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0923 21:00:13.803678 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:00:13.914271  9080 solver.cpp:330] Iteration 3000, Testing net (#0)
I0923 21:00:13.914271  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:00:14.440475  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:00:14.461992  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7148
I0923 21:00:14.461992  9080 solver.cpp:397]     Test net output #1: loss = 0.8288 (* 1 = 0.8288 loss)
I0923 21:00:14.487509  9080 solver.cpp:218] Iteration 3000 (29.9671 iter/s, 3.33699s/100 iters), loss = 0.791579
I0923 21:00:14.487509  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0923 21:00:14.487509  9080 solver.cpp:237]     Train net output #1: loss = 0.791579 (* 1 = 0.791579 loss)
I0923 21:00:14.487509  9080 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0923 21:00:17.281777  9080 solver.cpp:218] Iteration 3100 (35.7934 iter/s, 2.79381s/100 iters), loss = 0.705706
I0923 21:00:17.281777  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 21:00:17.281777  9080 solver.cpp:237]     Train net output #1: loss = 0.705706 (* 1 = 0.705706 loss)
I0923 21:00:17.281777  9080 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0923 21:00:20.075772  9080 solver.cpp:218] Iteration 3200 (35.7954 iter/s, 2.79366s/100 iters), loss = 0.622316
I0923 21:00:20.075772  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 21:00:20.075772  9080 solver.cpp:237]     Train net output #1: loss = 0.622316 (* 1 = 0.622316 loss)
I0923 21:00:20.075772  9080 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0923 21:00:22.865739  9080 solver.cpp:218] Iteration 3300 (35.8432 iter/s, 2.78993s/100 iters), loss = 0.749161
I0923 21:00:22.865739  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 21:00:22.865739  9080 solver.cpp:237]     Train net output #1: loss = 0.749161 (* 1 = 0.749161 loss)
I0923 21:00:22.865739  9080 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0923 21:00:25.662238  9080 solver.cpp:218] Iteration 3400 (35.7633 iter/s, 2.79616s/100 iters), loss = 0.633644
I0923 21:00:25.662238  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 21:00:25.662238  9080 solver.cpp:237]     Train net output #1: loss = 0.633644 (* 1 = 0.633644 loss)
I0923 21:00:25.662238  9080 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0923 21:00:28.314151 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:00:28.449756  9080 solver.cpp:218] Iteration 3500 (35.8787 iter/s, 2.78717s/100 iters), loss = 0.76147
I0923 21:00:28.449756  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0923 21:00:28.449756  9080 solver.cpp:237]     Train net output #1: loss = 0.76147 (* 1 = 0.76147 loss)
I0923 21:00:28.449756  9080 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0923 21:00:31.238827  9080 solver.cpp:218] Iteration 3600 (35.8578 iter/s, 2.78879s/100 iters), loss = 0.635776
I0923 21:00:31.239326  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:00:31.239326  9080 solver.cpp:237]     Train net output #1: loss = 0.635776 (* 1 = 0.635776 loss)
I0923 21:00:31.239326  9080 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0923 21:00:34.037417  9080 solver.cpp:218] Iteration 3700 (35.7403 iter/s, 2.79796s/100 iters), loss = 0.588398
I0923 21:00:34.037417  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:00:34.037417  9080 solver.cpp:237]     Train net output #1: loss = 0.588398 (* 1 = 0.588398 loss)
I0923 21:00:34.037417  9080 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0923 21:00:36.852001  9080 solver.cpp:218] Iteration 3800 (35.5332 iter/s, 2.81427s/100 iters), loss = 0.673196
I0923 21:00:36.852001  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 21:00:36.852501  9080 solver.cpp:237]     Train net output #1: loss = 0.673196 (* 1 = 0.673196 loss)
I0923 21:00:36.852501  9080 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0923 21:00:39.655411  9080 solver.cpp:218] Iteration 3900 (35.675 iter/s, 2.80308s/100 iters), loss = 0.645972
I0923 21:00:39.655910  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I0923 21:00:39.655910  9080 solver.cpp:237]     Train net output #1: loss = 0.645972 (* 1 = 0.645972 loss)
I0923 21:00:39.655910  9080 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0923 21:00:42.316033 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:00:42.425611  9080 solver.cpp:330] Iteration 4000, Testing net (#0)
I0923 21:00:42.425611  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:00:42.950269  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:00:42.970782  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7229
I0923 21:00:42.970782  9080 solver.cpp:397]     Test net output #1: loss = 0.821109 (* 1 = 0.821109 loss)
I0923 21:00:42.996803  9080 solver.cpp:218] Iteration 4000 (29.9337 iter/s, 3.34072s/100 iters), loss = 0.728793
I0923 21:00:42.996803  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 21:00:42.996803  9080 solver.cpp:237]     Train net output #1: loss = 0.728793 (* 1 = 0.728793 loss)
I0923 21:00:42.996803  9080 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0923 21:00:45.815563  9080 solver.cpp:218] Iteration 4100 (35.4821 iter/s, 2.81832s/100 iters), loss = 0.670592
I0923 21:00:45.815563  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 21:00:45.815563  9080 solver.cpp:237]     Train net output #1: loss = 0.670592 (* 1 = 0.670592 loss)
I0923 21:00:45.815563  9080 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0923 21:00:48.629438  9080 solver.cpp:218] Iteration 4200 (35.5386 iter/s, 2.81384s/100 iters), loss = 0.703297
I0923 21:00:48.629438  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 21:00:48.629438  9080 solver.cpp:237]     Train net output #1: loss = 0.703297 (* 1 = 0.703297 loss)
I0923 21:00:48.629438  9080 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0923 21:00:51.380565  9080 solver.cpp:218] Iteration 4300 (36.3517 iter/s, 2.7509s/100 iters), loss = 0.64766
I0923 21:00:51.381065  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0923 21:00:51.381065  9080 solver.cpp:237]     Train net output #1: loss = 0.64766 (* 1 = 0.64766 loss)
I0923 21:00:51.381065  9080 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0923 21:00:54.155457  9080 solver.cpp:218] Iteration 4400 (36.0422 iter/s, 2.77452s/100 iters), loss = 0.552301
I0923 21:00:54.155457  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:00:54.155956  9080 solver.cpp:237]     Train net output #1: loss = 0.552301 (* 1 = 0.552301 loss)
I0923 21:00:54.155956  9080 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0923 21:00:56.865891 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:00:57.002485  9080 solver.cpp:218] Iteration 4500 (35.1326 iter/s, 2.84636s/100 iters), loss = 0.691477
I0923 21:00:57.002485  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0923 21:00:57.002485  9080 solver.cpp:237]     Train net output #1: loss = 0.691477 (* 1 = 0.691477 loss)
I0923 21:00:57.002485  9080 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0923 21:00:59.858506  9080 solver.cpp:218] Iteration 4600 (35.0141 iter/s, 2.85599s/100 iters), loss = 0.714303
I0923 21:00:59.858506  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 21:00:59.859006  9080 solver.cpp:237]     Train net output #1: loss = 0.714303 (* 1 = 0.714303 loss)
I0923 21:00:59.859006  9080 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0923 21:01:02.754065  9080 solver.cpp:218] Iteration 4700 (34.5455 iter/s, 2.89473s/100 iters), loss = 0.586413
I0923 21:01:02.754065  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:01:02.754065  9080 solver.cpp:237]     Train net output #1: loss = 0.586413 (* 1 = 0.586413 loss)
I0923 21:01:02.754065  9080 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0923 21:01:05.586597  9080 solver.cpp:218] Iteration 4800 (35.3095 iter/s, 2.8321s/100 iters), loss = 0.623092
I0923 21:01:05.586597  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 21:01:05.586597  9080 solver.cpp:237]     Train net output #1: loss = 0.623092 (* 1 = 0.623092 loss)
I0923 21:01:05.586597  9080 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0923 21:01:08.432106  9080 solver.cpp:218] Iteration 4900 (35.1445 iter/s, 2.84539s/100 iters), loss = 0.693545
I0923 21:01:08.432106  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I0923 21:01:08.432106  9080 solver.cpp:237]     Train net output #1: loss = 0.693545 (* 1 = 0.693545 loss)
I0923 21:01:08.432106  9080 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0923 21:01:11.111141 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:01:11.222204  9080 solver.cpp:330] Iteration 5000, Testing net (#0)
I0923 21:01:11.222204  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:01:11.749579  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:01:11.770108  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7414
I0923 21:01:11.770608  9080 solver.cpp:397]     Test net output #1: loss = 0.761225 (* 1 = 0.761225 loss)
I0923 21:01:11.796612  9080 solver.cpp:218] Iteration 5000 (29.7264 iter/s, 3.36402s/100 iters), loss = 0.582572
I0923 21:01:11.796612  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 21:01:11.796612  9080 solver.cpp:237]     Train net output #1: loss = 0.582572 (* 1 = 0.582572 loss)
I0923 21:01:11.796612  9080 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I0923 21:01:11.796612  9080 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I0923 21:01:14.647140  9080 solver.cpp:218] Iteration 5100 (35.0898 iter/s, 2.84983s/100 iters), loss = 0.6127
I0923 21:01:14.647140  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0923 21:01:14.647140  9080 solver.cpp:237]     Train net output #1: loss = 0.6127 (* 1 = 0.6127 loss)
I0923 21:01:14.647140  9080 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I0923 21:01:17.503653  9080 solver.cpp:218] Iteration 5200 (35.0089 iter/s, 2.85642s/100 iters), loss = 0.491363
I0923 21:01:17.503653  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:01:17.503653  9080 solver.cpp:237]     Train net output #1: loss = 0.491363 (* 1 = 0.491363 loss)
I0923 21:01:17.503653  9080 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I0923 21:01:20.303858  9080 solver.cpp:218] Iteration 5300 (35.7177 iter/s, 2.79974s/100 iters), loss = 0.510493
I0923 21:01:20.303858  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:01:20.303858  9080 solver.cpp:237]     Train net output #1: loss = 0.510493 (* 1 = 0.510493 loss)
I0923 21:01:20.303858  9080 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I0923 21:01:23.102309  9080 solver.cpp:218] Iteration 5400 (35.7393 iter/s, 2.79804s/100 iters), loss = 0.515757
I0923 21:01:23.102309  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:01:23.102309  9080 solver.cpp:237]     Train net output #1: loss = 0.515757 (* 1 = 0.515757 loss)
I0923 21:01:23.102309  9080 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I0923 21:01:25.765502 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:01:25.902609  9080 solver.cpp:218] Iteration 5500 (35.7131 iter/s, 2.8001s/100 iters), loss = 0.533398
I0923 21:01:25.902609  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:01:25.902609  9080 solver.cpp:237]     Train net output #1: loss = 0.533398 (* 1 = 0.533398 loss)
I0923 21:01:25.902609  9080 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I0923 21:01:28.704149  9080 solver.cpp:218] Iteration 5600 (35.7004 iter/s, 2.80109s/100 iters), loss = 0.535561
I0923 21:01:28.704149  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:01:28.704149  9080 solver.cpp:237]     Train net output #1: loss = 0.535561 (* 1 = 0.535561 loss)
I0923 21:01:28.704149  9080 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I0923 21:01:31.498240  9080 solver.cpp:218] Iteration 5700 (35.7927 iter/s, 2.79386s/100 iters), loss = 0.545827
I0923 21:01:31.498240  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:01:31.498240  9080 solver.cpp:237]     Train net output #1: loss = 0.545827 (* 1 = 0.545827 loss)
I0923 21:01:31.498240  9080 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I0923 21:01:34.291470  9080 solver.cpp:218] Iteration 5800 (35.807 iter/s, 2.79275s/100 iters), loss = 0.58509
I0923 21:01:34.291470  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:01:34.291470  9080 solver.cpp:237]     Train net output #1: loss = 0.58509 (* 1 = 0.58509 loss)
I0923 21:01:34.291470  9080 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I0923 21:01:37.082959  9080 solver.cpp:218] Iteration 5900 (35.8247 iter/s, 2.79137s/100 iters), loss = 0.421448
I0923 21:01:37.083459  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 21:01:37.083459  9080 solver.cpp:237]     Train net output #1: loss = 0.421448 (* 1 = 0.421448 loss)
I0923 21:01:37.083459  9080 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I0923 21:01:39.740432 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:01:39.850512  9080 solver.cpp:330] Iteration 6000, Testing net (#0)
I0923 21:01:39.850512  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:01:40.377521  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:01:40.397534  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7806
I0923 21:01:40.398036  9080 solver.cpp:397]     Test net output #1: loss = 0.639378 (* 1 = 0.639378 loss)
I0923 21:01:40.424053  9080 solver.cpp:218] Iteration 6000 (29.9367 iter/s, 3.34038s/100 iters), loss = 0.560919
I0923 21:01:40.424053  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:01:40.424053  9080 solver.cpp:237]     Train net output #1: loss = 0.560919 (* 1 = 0.560919 loss)
I0923 21:01:40.424053  9080 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I0923 21:01:43.215919  9080 solver.cpp:218] Iteration 6100 (35.8219 iter/s, 2.79159s/100 iters), loss = 0.538069
I0923 21:01:43.215919  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:01:43.215919  9080 solver.cpp:237]     Train net output #1: loss = 0.538069 (* 1 = 0.538069 loss)
I0923 21:01:43.215919  9080 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I0923 21:01:46.013411  9080 solver.cpp:218] Iteration 6200 (35.7514 iter/s, 2.79709s/100 iters), loss = 0.51234
I0923 21:01:46.013411  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:01:46.013411  9080 solver.cpp:237]     Train net output #1: loss = 0.51234 (* 1 = 0.51234 loss)
I0923 21:01:46.013411  9080 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I0923 21:01:48.810035  9080 solver.cpp:218] Iteration 6300 (35.7601 iter/s, 2.79641s/100 iters), loss = 0.543103
I0923 21:01:48.810035  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:01:48.810035  9080 solver.cpp:237]     Train net output #1: loss = 0.543103 (* 1 = 0.543103 loss)
I0923 21:01:48.810035  9080 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I0923 21:01:51.609601  9080 solver.cpp:218] Iteration 6400 (35.7275 iter/s, 2.79896s/100 iters), loss = 0.466336
I0923 21:01:51.609601  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:01:51.609601  9080 solver.cpp:237]     Train net output #1: loss = 0.466336 (* 1 = 0.466336 loss)
I0923 21:01:51.609601  9080 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I0923 21:01:54.271999 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:01:54.410090  9080 solver.cpp:218] Iteration 6500 (35.7105 iter/s, 2.8003s/100 iters), loss = 0.572813
I0923 21:01:54.410090  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 21:01:54.410090  9080 solver.cpp:237]     Train net output #1: loss = 0.572813 (* 1 = 0.572813 loss)
I0923 21:01:54.410090  9080 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I0923 21:01:57.203764  9080 solver.cpp:218] Iteration 6600 (35.7972 iter/s, 2.79351s/100 iters), loss = 0.56734
I0923 21:01:57.203764  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 21:01:57.203764  9080 solver.cpp:237]     Train net output #1: loss = 0.56734 (* 1 = 0.56734 loss)
I0923 21:01:57.203764  9080 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I0923 21:02:00.003825  9080 solver.cpp:218] Iteration 6700 (35.718 iter/s, 2.79971s/100 iters), loss = 0.421998
I0923 21:02:00.003825  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:02:00.003825  9080 solver.cpp:237]     Train net output #1: loss = 0.421998 (* 1 = 0.421998 loss)
I0923 21:02:00.003825  9080 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I0923 21:02:02.802933  9080 solver.cpp:218] Iteration 6800 (35.7312 iter/s, 2.79867s/100 iters), loss = 0.521853
I0923 21:02:02.802933  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:02:02.802933  9080 solver.cpp:237]     Train net output #1: loss = 0.521853 (* 1 = 0.521853 loss)
I0923 21:02:02.802933  9080 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I0923 21:02:05.599840  9080 solver.cpp:218] Iteration 6900 (35.7607 iter/s, 2.79636s/100 iters), loss = 0.455989
I0923 21:02:05.599840  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:02:05.599840  9080 solver.cpp:237]     Train net output #1: loss = 0.455989 (* 1 = 0.455989 loss)
I0923 21:02:05.599840  9080 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I0923 21:02:08.259747 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:02:08.370309  9080 solver.cpp:330] Iteration 7000, Testing net (#0)
I0923 21:02:08.370309  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:02:08.907703  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:02:08.928223  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7803
I0923 21:02:08.928724  9080 solver.cpp:397]     Test net output #1: loss = 0.636297 (* 1 = 0.636297 loss)
I0923 21:02:08.954226  9080 solver.cpp:218] Iteration 7000 (29.8138 iter/s, 3.35415s/100 iters), loss = 0.561376
I0923 21:02:08.954226  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:02:08.954725  9080 solver.cpp:237]     Train net output #1: loss = 0.561376 (* 1 = 0.561376 loss)
I0923 21:02:08.954725  9080 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I0923 21:02:11.799531  9080 solver.cpp:218] Iteration 7100 (35.1465 iter/s, 2.84523s/100 iters), loss = 0.489041
I0923 21:02:11.799531  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:02:11.799531  9080 solver.cpp:237]     Train net output #1: loss = 0.489041 (* 1 = 0.489041 loss)
I0923 21:02:11.799531  9080 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I0923 21:02:14.577872  9080 solver.cpp:218] Iteration 7200 (35.9951 iter/s, 2.77816s/100 iters), loss = 0.475865
I0923 21:02:14.577872  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:02:14.578873  9080 solver.cpp:237]     Train net output #1: loss = 0.475865 (* 1 = 0.475865 loss)
I0923 21:02:14.578873  9080 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I0923 21:02:17.382393  9080 solver.cpp:218] Iteration 7300 (35.6627 iter/s, 2.80405s/100 iters), loss = 0.537794
I0923 21:02:17.382393  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:02:17.382393  9080 solver.cpp:237]     Train net output #1: loss = 0.537794 (* 1 = 0.537794 loss)
I0923 21:02:17.382393  9080 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I0923 21:02:20.158913  9080 solver.cpp:218] Iteration 7400 (36.0308 iter/s, 2.7754s/100 iters), loss = 0.460819
I0923 21:02:20.158913  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 21:02:20.158913  9080 solver.cpp:237]     Train net output #1: loss = 0.460819 (* 1 = 0.460819 loss)
I0923 21:02:20.158913  9080 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I0923 21:02:22.746850 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:02:22.878926  9080 solver.cpp:218] Iteration 7500 (36.7621 iter/s, 2.72019s/100 iters), loss = 0.537287
I0923 21:02:22.878926  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:02:22.878926  9080 solver.cpp:237]     Train net output #1: loss = 0.537287 (* 1 = 0.537287 loss)
I0923 21:02:22.878926  9080 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I0923 21:02:25.607724  9080 solver.cpp:218] Iteration 7600 (36.6566 iter/s, 2.72803s/100 iters), loss = 0.472257
I0923 21:02:25.607724  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:02:25.607724  9080 solver.cpp:237]     Train net output #1: loss = 0.472257 (* 1 = 0.472257 loss)
I0923 21:02:25.607724  9080 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I0923 21:02:28.331138  9080 solver.cpp:218] Iteration 7700 (36.7252 iter/s, 2.72293s/100 iters), loss = 0.427095
I0923 21:02:28.331138  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:02:28.331138  9080 solver.cpp:237]     Train net output #1: loss = 0.427095 (* 1 = 0.427095 loss)
I0923 21:02:28.331138  9080 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I0923 21:02:31.038745  9080 solver.cpp:218] Iteration 7800 (36.9285 iter/s, 2.70793s/100 iters), loss = 0.536605
I0923 21:02:31.038745  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:02:31.038745  9080 solver.cpp:237]     Train net output #1: loss = 0.536605 (* 1 = 0.536605 loss)
I0923 21:02:31.038745  9080 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I0923 21:02:33.761970  9080 solver.cpp:218] Iteration 7900 (36.7305 iter/s, 2.72253s/100 iters), loss = 0.448225
I0923 21:02:33.761970  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:02:33.761970  9080 solver.cpp:237]     Train net output #1: loss = 0.448225 (* 1 = 0.448225 loss)
I0923 21:02:33.761970  9080 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I0923 21:02:36.347666 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:02:36.455272  9080 solver.cpp:330] Iteration 8000, Testing net (#0)
I0923 21:02:36.456274  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:02:36.966584  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:02:36.987306  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7807
I0923 21:02:36.987306  9080 solver.cpp:397]     Test net output #1: loss = 0.636869 (* 1 = 0.636869 loss)
I0923 21:02:37.012854  9080 solver.cpp:218] Iteration 8000 (30.7657 iter/s, 3.25038s/100 iters), loss = 0.551846
I0923 21:02:37.012854  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:02:37.012854  9080 solver.cpp:237]     Train net output #1: loss = 0.551846 (* 1 = 0.551846 loss)
I0923 21:02:37.012854  9080 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I0923 21:02:39.735736  9080 solver.cpp:218] Iteration 8100 (36.7212 iter/s, 2.72322s/100 iters), loss = 0.501211
I0923 21:02:39.735736  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 21:02:39.735736  9080 solver.cpp:237]     Train net output #1: loss = 0.501211 (* 1 = 0.501211 loss)
I0923 21:02:39.735736  9080 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I0923 21:02:42.450335  9080 solver.cpp:218] Iteration 8200 (36.846 iter/s, 2.714s/100 iters), loss = 0.464473
I0923 21:02:42.450335  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:02:42.450335  9080 solver.cpp:237]     Train net output #1: loss = 0.464473 (* 1 = 0.464473 loss)
I0923 21:02:42.450335  9080 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I0923 21:02:45.160703  9080 solver.cpp:218] Iteration 8300 (36.8936 iter/s, 2.7105s/100 iters), loss = 0.514672
I0923 21:02:45.160703  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:02:45.160703  9080 solver.cpp:237]     Train net output #1: loss = 0.514672 (* 1 = 0.514672 loss)
I0923 21:02:45.160703  9080 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I0923 21:02:47.926710  9080 solver.cpp:218] Iteration 8400 (36.1681 iter/s, 2.76487s/100 iters), loss = 0.453758
I0923 21:02:47.926710  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:02:47.926710  9080 solver.cpp:237]     Train net output #1: loss = 0.453758 (* 1 = 0.453758 loss)
I0923 21:02:47.926710  9080 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I0923 21:02:50.548935 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:02:50.680040  9080 solver.cpp:218] Iteration 8500 (36.3167 iter/s, 2.75355s/100 iters), loss = 0.496569
I0923 21:02:50.680040  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:02:50.680040  9080 solver.cpp:237]     Train net output #1: loss = 0.496569 (* 1 = 0.496569 loss)
I0923 21:02:50.680040  9080 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I0923 21:02:53.411413  9080 solver.cpp:218] Iteration 8600 (36.6223 iter/s, 2.73058s/100 iters), loss = 0.482088
I0923 21:02:53.411413  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:02:53.411413  9080 solver.cpp:237]     Train net output #1: loss = 0.482088 (* 1 = 0.482088 loss)
I0923 21:02:53.411413  9080 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I0923 21:02:56.137243  9080 solver.cpp:218] Iteration 8700 (36.693 iter/s, 2.72532s/100 iters), loss = 0.505328
I0923 21:02:56.137243  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:02:56.137243  9080 solver.cpp:237]     Train net output #1: loss = 0.505328 (* 1 = 0.505328 loss)
I0923 21:02:56.137243  9080 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I0923 21:02:58.868082  9080 solver.cpp:218] Iteration 8800 (36.6247 iter/s, 2.7304s/100 iters), loss = 0.531848
I0923 21:02:58.868082  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:02:58.868082  9080 solver.cpp:237]     Train net output #1: loss = 0.531848 (* 1 = 0.531848 loss)
I0923 21:02:58.868082  9080 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I0923 21:03:01.638182  9080 solver.cpp:218] Iteration 8900 (36.1005 iter/s, 2.77005s/100 iters), loss = 0.423977
I0923 21:03:01.638182  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:03:01.638182  9080 solver.cpp:237]     Train net output #1: loss = 0.423977 (* 1 = 0.423977 loss)
I0923 21:03:01.638182  9080 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I0923 21:03:04.300696 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:03:04.414573  9080 solver.cpp:330] Iteration 9000, Testing net (#0)
I0923 21:03:04.414573  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:03:04.946324  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:03:04.967339  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7835
I0923 21:03:04.967339  9080 solver.cpp:397]     Test net output #1: loss = 0.634249 (* 1 = 0.634249 loss)
I0923 21:03:04.993358  9080 solver.cpp:218] Iteration 9000 (29.8099 iter/s, 3.35459s/100 iters), loss = 0.473648
I0923 21:03:04.993358  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:03:04.993358  9080 solver.cpp:237]     Train net output #1: loss = 0.473648 (* 1 = 0.473648 loss)
I0923 21:03:04.993358  9080 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I0923 21:03:07.732168  9080 solver.cpp:218] Iteration 9100 (36.5152 iter/s, 2.73859s/100 iters), loss = 0.522045
I0923 21:03:07.732168  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 21:03:07.732168  9080 solver.cpp:237]     Train net output #1: loss = 0.522045 (* 1 = 0.522045 loss)
I0923 21:03:07.732168  9080 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I0923 21:03:10.457201  9080 solver.cpp:218] Iteration 9200 (36.6965 iter/s, 2.72506s/100 iters), loss = 0.44602
I0923 21:03:10.457201  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:03:10.457201  9080 solver.cpp:237]     Train net output #1: loss = 0.44602 (* 1 = 0.44602 loss)
I0923 21:03:10.457201  9080 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I0923 21:03:13.204965  9080 solver.cpp:218] Iteration 9300 (36.3952 iter/s, 2.74762s/100 iters), loss = 0.539976
I0923 21:03:13.204965  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:03:13.204965  9080 solver.cpp:237]     Train net output #1: loss = 0.539976 (* 1 = 0.539976 loss)
I0923 21:03:13.204965  9080 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I0923 21:03:15.931926  9080 solver.cpp:218] Iteration 9400 (36.683 iter/s, 2.72606s/100 iters), loss = 0.403897
I0923 21:03:15.931926  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:03:15.931926  9080 solver.cpp:237]     Train net output #1: loss = 0.403897 (* 1 = 0.403897 loss)
I0923 21:03:15.931926  9080 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I0923 21:03:18.571036 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:03:18.709359  9080 solver.cpp:218] Iteration 9500 (36.0045 iter/s, 2.77743s/100 iters), loss = 0.537811
I0923 21:03:18.709359  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:03:18.709359  9080 solver.cpp:237]     Train net output #1: loss = 0.537811 (* 1 = 0.537811 loss)
I0923 21:03:18.709359  9080 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I0923 21:03:21.461148  9080 solver.cpp:218] Iteration 9600 (36.3485 iter/s, 2.75114s/100 iters), loss = 0.455985
I0923 21:03:21.461148  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:03:21.461148  9080 solver.cpp:237]     Train net output #1: loss = 0.455985 (* 1 = 0.455985 loss)
I0923 21:03:21.461148  9080 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I0923 21:03:24.187571  9080 solver.cpp:218] Iteration 9700 (36.6758 iter/s, 2.7266s/100 iters), loss = 0.466689
I0923 21:03:24.187571  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:03:24.187571  9080 solver.cpp:237]     Train net output #1: loss = 0.466689 (* 1 = 0.466689 loss)
I0923 21:03:24.187571  9080 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I0923 21:03:26.913827  9080 solver.cpp:218] Iteration 9800 (36.6864 iter/s, 2.7258s/100 iters), loss = 0.491691
I0923 21:03:26.913827  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:03:26.913827  9080 solver.cpp:237]     Train net output #1: loss = 0.491691 (* 1 = 0.491691 loss)
I0923 21:03:26.913827  9080 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I0923 21:03:29.632982  9080 solver.cpp:218] Iteration 9900 (36.7761 iter/s, 2.71915s/100 iters), loss = 0.355457
I0923 21:03:29.632982  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:03:29.632982  9080 solver.cpp:237]     Train net output #1: loss = 0.355457 (* 1 = 0.355457 loss)
I0923 21:03:29.632982  9080 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I0923 21:03:32.221858 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:03:32.329962  9080 solver.cpp:330] Iteration 10000, Testing net (#0)
I0923 21:03:32.330962  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:03:32.847738  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:03:32.867826  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7841
I0923 21:03:32.867826  9080 solver.cpp:397]     Test net output #1: loss = 0.633216 (* 1 = 0.633216 loss)
I0923 21:03:32.893844  9080 solver.cpp:218] Iteration 10000 (30.6715 iter/s, 3.26035s/100 iters), loss = 0.523832
I0923 21:03:32.893844  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:03:32.893844  9080 solver.cpp:237]     Train net output #1: loss = 0.523832 (* 1 = 0.523832 loss)
I0923 21:03:32.893844  9080 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I0923 21:03:32.893844  9080 sgd_solver.cpp:105] Iteration 10000, lr = 0.0001
I0923 21:03:35.705482  9080 solver.cpp:218] Iteration 10100 (35.5797 iter/s, 2.81059s/100 iters), loss = 0.49818
I0923 21:03:35.705482  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 21:03:35.705482  9080 solver.cpp:237]     Train net output #1: loss = 0.49818 (* 1 = 0.49818 loss)
I0923 21:03:35.705482  9080 sgd_solver.cpp:105] Iteration 10100, lr = 0.0001
I0923 21:03:38.493917  9080 solver.cpp:218] Iteration 10200 (35.8571 iter/s, 2.78885s/100 iters), loss = 0.452013
I0923 21:03:38.493917  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:03:38.493917  9080 solver.cpp:237]     Train net output #1: loss = 0.452013 (* 1 = 0.452013 loss)
I0923 21:03:38.493917  9080 sgd_solver.cpp:105] Iteration 10200, lr = 0.0001
I0923 21:03:41.214644  9080 solver.cpp:218] Iteration 10300 (36.7633 iter/s, 2.7201s/100 iters), loss = 0.441833
I0923 21:03:41.214644  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:03:41.214644  9080 solver.cpp:237]     Train net output #1: loss = 0.441833 (* 1 = 0.441833 loss)
I0923 21:03:41.214644  9080 sgd_solver.cpp:105] Iteration 10300, lr = 0.0001
I0923 21:03:43.930428  9080 solver.cpp:218] Iteration 10400 (36.8206 iter/s, 2.71587s/100 iters), loss = 0.418082
I0923 21:03:43.930428  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:03:43.930428  9080 solver.cpp:237]     Train net output #1: loss = 0.418082 (* 1 = 0.418082 loss)
I0923 21:03:43.930428  9080 sgd_solver.cpp:105] Iteration 10400, lr = 0.0001
I0923 21:03:46.547394 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:03:46.685369  9080 solver.cpp:218] Iteration 10500 (36.3107 iter/s, 2.75401s/100 iters), loss = 0.499917
I0923 21:03:46.685369  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:03:46.685369  9080 solver.cpp:237]     Train net output #1: loss = 0.499917 (* 1 = 0.499917 loss)
I0923 21:03:46.685369  9080 sgd_solver.cpp:105] Iteration 10500, lr = 0.0001
I0923 21:03:49.491834  9080 solver.cpp:218] Iteration 10600 (35.6376 iter/s, 2.80603s/100 iters), loss = 0.518904
I0923 21:03:49.491834  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:03:49.491834  9080 solver.cpp:237]     Train net output #1: loss = 0.518904 (* 1 = 0.518904 loss)
I0923 21:03:49.491834  9080 sgd_solver.cpp:105] Iteration 10600, lr = 0.0001
I0923 21:03:52.290639  9080 solver.cpp:218] Iteration 10700 (35.7262 iter/s, 2.79907s/100 iters), loss = 0.427298
I0923 21:03:52.290639  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:03:52.290639  9080 solver.cpp:237]     Train net output #1: loss = 0.427298 (* 1 = 0.427298 loss)
I0923 21:03:52.290639  9080 sgd_solver.cpp:105] Iteration 10700, lr = 0.0001
I0923 21:03:55.083000  9080 solver.cpp:218] Iteration 10800 (35.8263 iter/s, 2.79125s/100 iters), loss = 0.503257
I0923 21:03:55.083000  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:03:55.083000  9080 solver.cpp:237]     Train net output #1: loss = 0.503257 (* 1 = 0.503257 loss)
I0923 21:03:55.083000  9080 sgd_solver.cpp:105] Iteration 10800, lr = 0.0001
I0923 21:03:57.801616  9080 solver.cpp:218] Iteration 10900 (36.7881 iter/s, 2.71827s/100 iters), loss = 0.370537
I0923 21:03:57.801616  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 21:03:57.801616  9080 solver.cpp:237]     Train net output #1: loss = 0.370537 (* 1 = 0.370537 loss)
I0923 21:03:57.801616  9080 sgd_solver.cpp:105] Iteration 10900, lr = 0.0001
I0923 21:04:00.392423 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:04:00.500053  9080 solver.cpp:330] Iteration 11000, Testing net (#0)
I0923 21:04:00.500053  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:04:01.016597  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:04:01.037595  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7867
I0923 21:04:01.037595  9080 solver.cpp:397]     Test net output #1: loss = 0.624641 (* 1 = 0.624641 loss)
I0923 21:04:01.062624  9080 solver.cpp:218] Iteration 11000 (30.6645 iter/s, 3.2611s/100 iters), loss = 0.480874
I0923 21:04:01.062624  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:04:01.062624  9080 solver.cpp:237]     Train net output #1: loss = 0.480874 (* 1 = 0.480874 loss)
I0923 21:04:01.062624  9080 sgd_solver.cpp:105] Iteration 11000, lr = 0.0001
I0923 21:04:03.795095  9080 solver.cpp:218] Iteration 11100 (36.6032 iter/s, 2.732s/100 iters), loss = 0.47489
I0923 21:04:03.795095  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:04:03.795095  9080 solver.cpp:237]     Train net output #1: loss = 0.47489 (* 1 = 0.47489 loss)
I0923 21:04:03.795095  9080 sgd_solver.cpp:105] Iteration 11100, lr = 0.0001
I0923 21:04:06.524909  9080 solver.cpp:218] Iteration 11200 (36.6347 iter/s, 2.72965s/100 iters), loss = 0.450959
I0923 21:04:06.524909  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:04:06.524909  9080 solver.cpp:237]     Train net output #1: loss = 0.450959 (* 1 = 0.450959 loss)
I0923 21:04:06.524909  9080 sgd_solver.cpp:105] Iteration 11200, lr = 0.0001
I0923 21:04:09.341826  9080 solver.cpp:218] Iteration 11300 (35.4984 iter/s, 2.81703s/100 iters), loss = 0.503903
I0923 21:04:09.341826  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:04:09.342814  9080 solver.cpp:237]     Train net output #1: loss = 0.503903 (* 1 = 0.503903 loss)
I0923 21:04:09.342814  9080 sgd_solver.cpp:105] Iteration 11300, lr = 0.0001
I0923 21:04:12.157631  9080 solver.cpp:218] Iteration 11400 (35.5287 iter/s, 2.81462s/100 iters), loss = 0.425078
I0923 21:04:12.157631  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:04:12.157631  9080 solver.cpp:237]     Train net output #1: loss = 0.425078 (* 1 = 0.425078 loss)
I0923 21:04:12.157631  9080 sgd_solver.cpp:105] Iteration 11400, lr = 0.0001
I0923 21:04:14.834085 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:04:14.970871  9080 solver.cpp:218] Iteration 11500 (35.5487 iter/s, 2.81305s/100 iters), loss = 0.502398
I0923 21:04:14.970871  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:04:14.970871  9080 solver.cpp:237]     Train net output #1: loss = 0.502398 (* 1 = 0.502398 loss)
I0923 21:04:14.970871  9080 sgd_solver.cpp:105] Iteration 11500, lr = 0.0001
I0923 21:04:17.790570  9080 solver.cpp:218] Iteration 11600 (35.4665 iter/s, 2.81956s/100 iters), loss = 0.510632
I0923 21:04:17.790570  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 21:04:17.790570  9080 solver.cpp:237]     Train net output #1: loss = 0.510632 (* 1 = 0.510632 loss)
I0923 21:04:17.790570  9080 sgd_solver.cpp:105] Iteration 11600, lr = 0.0001
I0923 21:04:20.607878  9080 solver.cpp:218] Iteration 11700 (35.5033 iter/s, 2.81664s/100 iters), loss = 0.419881
I0923 21:04:20.607878  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:04:20.607878  9080 solver.cpp:237]     Train net output #1: loss = 0.419881 (* 1 = 0.419881 loss)
I0923 21:04:20.607878  9080 sgd_solver.cpp:105] Iteration 11700, lr = 0.0001
I0923 21:04:23.388641  9080 solver.cpp:218] Iteration 11800 (35.9617 iter/s, 2.78074s/100 iters), loss = 0.432399
I0923 21:04:23.388641  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 21:04:23.388641  9080 solver.cpp:237]     Train net output #1: loss = 0.432399 (* 1 = 0.432399 loss)
I0923 21:04:23.388641  9080 sgd_solver.cpp:105] Iteration 11800, lr = 0.0001
I0923 21:04:26.175379  9080 solver.cpp:218] Iteration 11900 (35.8855 iter/s, 2.78664s/100 iters), loss = 0.410215
I0923 21:04:26.175379  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 21:04:26.175379  9080 solver.cpp:237]     Train net output #1: loss = 0.410215 (* 1 = 0.410215 loss)
I0923 21:04:26.175379  9080 sgd_solver.cpp:105] Iteration 11900, lr = 0.0001
I0923 21:04:28.834326 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:04:28.941931  9080 solver.cpp:330] Iteration 12000, Testing net (#0)
I0923 21:04:28.941931  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:04:29.457195  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:04:29.477191  9080 solver.cpp:397]     Test net output #0: accuracy = 0.786
I0923 21:04:29.477191  9080 solver.cpp:397]     Test net output #1: loss = 0.624527 (* 1 = 0.624527 loss)
I0923 21:04:29.502221  9080 solver.cpp:218] Iteration 12000 (30.0623 iter/s, 3.32643s/100 iters), loss = 0.523746
I0923 21:04:29.502221  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:04:29.502221  9080 solver.cpp:237]     Train net output #1: loss = 0.523746 (* 1 = 0.523746 loss)
I0923 21:04:29.502221  9080 sgd_solver.cpp:105] Iteration 12000, lr = 0.0001
I0923 21:04:32.284445  9080 solver.cpp:218] Iteration 12100 (35.9499 iter/s, 2.78165s/100 iters), loss = 0.473225
I0923 21:04:32.284445  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:04:32.284445  9080 solver.cpp:237]     Train net output #1: loss = 0.473225 (* 1 = 0.473225 loss)
I0923 21:04:32.284445  9080 sgd_solver.cpp:105] Iteration 12100, lr = 0.0001
I0923 21:04:35.080103  9080 solver.cpp:218] Iteration 12200 (35.7778 iter/s, 2.79503s/100 iters), loss = 0.441375
I0923 21:04:35.080103  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:04:35.080103  9080 solver.cpp:237]     Train net output #1: loss = 0.441375 (* 1 = 0.441375 loss)
I0923 21:04:35.080103  9080 sgd_solver.cpp:105] Iteration 12200, lr = 0.0001
I0923 21:04:37.815088  9080 solver.cpp:218] Iteration 12300 (36.5723 iter/s, 2.73431s/100 iters), loss = 0.517704
I0923 21:04:37.815088  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:04:37.815088  9080 solver.cpp:237]     Train net output #1: loss = 0.517704 (* 1 = 0.517704 loss)
I0923 21:04:37.815088  9080 sgd_solver.cpp:105] Iteration 12300, lr = 0.0001
I0923 21:04:40.617694  9080 solver.cpp:218] Iteration 12400 (35.6805 iter/s, 2.80265s/100 iters), loss = 0.362116
I0923 21:04:40.617694  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:04:40.617694  9080 solver.cpp:237]     Train net output #1: loss = 0.362116 (* 1 = 0.362116 loss)
I0923 21:04:40.617694  9080 sgd_solver.cpp:105] Iteration 12400, lr = 0.0001
I0923 21:04:43.289263 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:04:43.428388  9080 solver.cpp:218] Iteration 12500 (35.5852 iter/s, 2.81016s/100 iters), loss = 0.471799
I0923 21:04:43.428388  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:04:43.428388  9080 solver.cpp:237]     Train net output #1: loss = 0.471799 (* 1 = 0.471799 loss)
I0923 21:04:43.428388  9080 sgd_solver.cpp:105] Iteration 12500, lr = 0.0001
I0923 21:04:46.241093  9080 solver.cpp:218] Iteration 12600 (35.557 iter/s, 2.81239s/100 iters), loss = 0.468048
I0923 21:04:46.241093  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:04:46.241093  9080 solver.cpp:237]     Train net output #1: loss = 0.468048 (* 1 = 0.468048 loss)
I0923 21:04:46.241093  9080 sgd_solver.cpp:105] Iteration 12600, lr = 0.0001
I0923 21:04:49.047121  9080 solver.cpp:218] Iteration 12700 (35.6428 iter/s, 2.80561s/100 iters), loss = 0.466162
I0923 21:04:49.047121  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:04:49.047121  9080 solver.cpp:237]     Train net output #1: loss = 0.466162 (* 1 = 0.466162 loss)
I0923 21:04:49.047121  9080 sgd_solver.cpp:105] Iteration 12700, lr = 0.0001
I0923 21:04:51.782445  9080 solver.cpp:218] Iteration 12800 (36.554 iter/s, 2.73568s/100 iters), loss = 0.527973
I0923 21:04:51.782445  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:04:51.782445  9080 solver.cpp:237]     Train net output #1: loss = 0.527973 (* 1 = 0.527973 loss)
I0923 21:04:51.783447  9080 sgd_solver.cpp:105] Iteration 12800, lr = 0.0001
I0923 21:04:54.548997  9080 solver.cpp:218] Iteration 12900 (36.1517 iter/s, 2.76612s/100 iters), loss = 0.407096
I0923 21:04:54.548997  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:04:54.548997  9080 solver.cpp:237]     Train net output #1: loss = 0.407096 (* 1 = 0.407096 loss)
I0923 21:04:54.548997  9080 sgd_solver.cpp:105] Iteration 12900, lr = 0.0001
I0923 21:04:57.235128 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:04:57.347113  9080 solver.cpp:330] Iteration 13000, Testing net (#0)
I0923 21:04:57.348109  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:04:57.878281  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:04:57.899296  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7877
I0923 21:04:57.899296  9080 solver.cpp:397]     Test net output #1: loss = 0.624629 (* 1 = 0.624629 loss)
I0923 21:04:57.925314  9080 solver.cpp:218] Iteration 13000 (29.6246 iter/s, 3.37558s/100 iters), loss = 0.500917
I0923 21:04:57.925314  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:04:57.925314  9080 solver.cpp:237]     Train net output #1: loss = 0.500917 (* 1 = 0.500917 loss)
I0923 21:04:57.925314  9080 sgd_solver.cpp:105] Iteration 13000, lr = 0.0001
I0923 21:05:00.713939  9080 solver.cpp:218] Iteration 13100 (35.859 iter/s, 2.7887s/100 iters), loss = 0.509869
I0923 21:05:00.714939  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:05:00.714939  9080 solver.cpp:237]     Train net output #1: loss = 0.509869 (* 1 = 0.509869 loss)
I0923 21:05:00.714939  9080 sgd_solver.cpp:105] Iteration 13100, lr = 0.0001
I0923 21:05:03.507419  9080 solver.cpp:218] Iteration 13200 (35.8139 iter/s, 2.79221s/100 iters), loss = 0.416475
I0923 21:05:03.507419  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:05:03.507419  9080 solver.cpp:237]     Train net output #1: loss = 0.416475 (* 1 = 0.416475 loss)
I0923 21:05:03.507419  9080 sgd_solver.cpp:105] Iteration 13200, lr = 0.0001
I0923 21:05:06.279747  9080 solver.cpp:218] Iteration 13300 (36.0688 iter/s, 2.77248s/100 iters), loss = 0.451158
I0923 21:05:06.279747  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:05:06.279747  9080 solver.cpp:237]     Train net output #1: loss = 0.451158 (* 1 = 0.451158 loss)
I0923 21:05:06.279747  9080 sgd_solver.cpp:105] Iteration 13300, lr = 0.0001
I0923 21:05:09.012187  9080 solver.cpp:218] Iteration 13400 (36.6061 iter/s, 2.73178s/100 iters), loss = 0.418024
I0923 21:05:09.012187  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:05:09.012187  9080 solver.cpp:237]     Train net output #1: loss = 0.418024 (* 1 = 0.418024 loss)
I0923 21:05:09.012187  9080 sgd_solver.cpp:105] Iteration 13400, lr = 0.0001
I0923 21:05:11.634408 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:05:11.769554  9080 solver.cpp:218] Iteration 13500 (36.2616 iter/s, 2.75774s/100 iters), loss = 0.516277
I0923 21:05:11.769554  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:05:11.769554  9080 solver.cpp:237]     Train net output #1: loss = 0.516277 (* 1 = 0.516277 loss)
I0923 21:05:11.769554  9080 sgd_solver.cpp:105] Iteration 13500, lr = 0.0001
I0923 21:05:14.589462  9080 solver.cpp:218] Iteration 13600 (35.474 iter/s, 2.81896s/100 iters), loss = 0.513421
I0923 21:05:14.589462  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:05:14.589462  9080 solver.cpp:237]     Train net output #1: loss = 0.513421 (* 1 = 0.513421 loss)
I0923 21:05:14.589462  9080 sgd_solver.cpp:105] Iteration 13600, lr = 0.0001
I0923 21:05:17.408732  9080 solver.cpp:218] Iteration 13700 (35.4702 iter/s, 2.81927s/100 iters), loss = 0.37601
I0923 21:05:17.408732  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:05:17.408732  9080 solver.cpp:237]     Train net output #1: loss = 0.37601 (* 1 = 0.37601 loss)
I0923 21:05:17.408732  9080 sgd_solver.cpp:105] Iteration 13700, lr = 0.0001
I0923 21:05:20.181552  9080 solver.cpp:218] Iteration 13800 (36.0752 iter/s, 2.77199s/100 iters), loss = 0.518426
I0923 21:05:20.181552  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:05:20.181552  9080 solver.cpp:237]     Train net output #1: loss = 0.518426 (* 1 = 0.518426 loss)
I0923 21:05:20.181552  9080 sgd_solver.cpp:105] Iteration 13800, lr = 0.0001
I0923 21:05:22.978056  9080 solver.cpp:218] Iteration 13900 (35.7585 iter/s, 2.79654s/100 iters), loss = 0.366507
I0923 21:05:22.978056  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:05:22.978056  9080 solver.cpp:237]     Train net output #1: loss = 0.366507 (* 1 = 0.366507 loss)
I0923 21:05:22.978056  9080 sgd_solver.cpp:105] Iteration 13900, lr = 0.0001
I0923 21:05:25.652817 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:05:25.763914  9080 solver.cpp:330] Iteration 14000, Testing net (#0)
I0923 21:05:25.763914  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:05:26.299119  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:05:26.320133  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7867
I0923 21:05:26.320133  9080 solver.cpp:397]     Test net output #1: loss = 0.624764 (* 1 = 0.624764 loss)
I0923 21:05:26.346151  9080 solver.cpp:218] Iteration 14000 (29.6958 iter/s, 3.36748s/100 iters), loss = 0.411909
I0923 21:05:26.346151  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:05:26.346151  9080 solver.cpp:237]     Train net output #1: loss = 0.411909 (* 1 = 0.411909 loss)
I0923 21:05:26.346151  9080 sgd_solver.cpp:105] Iteration 14000, lr = 0.0001
I0923 21:05:29.112401  9080 solver.cpp:218] Iteration 14100 (36.1561 iter/s, 2.76578s/100 iters), loss = 0.506159
I0923 21:05:29.112401  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:05:29.112401  9080 solver.cpp:237]     Train net output #1: loss = 0.506159 (* 1 = 0.506159 loss)
I0923 21:05:29.112401  9080 sgd_solver.cpp:105] Iteration 14100, lr = 0.0001
I0923 21:05:31.838670  9080 solver.cpp:218] Iteration 14200 (36.6813 iter/s, 2.72618s/100 iters), loss = 0.415924
I0923 21:05:31.838670  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:05:31.838670  9080 solver.cpp:237]     Train net output #1: loss = 0.415924 (* 1 = 0.415924 loss)
I0923 21:05:31.838670  9080 sgd_solver.cpp:105] Iteration 14200, lr = 0.0001
I0923 21:05:34.581308  9080 solver.cpp:218] Iteration 14300 (36.4687 iter/s, 2.74208s/100 iters), loss = 0.501412
I0923 21:05:34.581809  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:05:34.581809  9080 solver.cpp:237]     Train net output #1: loss = 0.501412 (* 1 = 0.501412 loss)
I0923 21:05:34.581809  9080 sgd_solver.cpp:105] Iteration 14300, lr = 0.0001
I0923 21:05:37.402861  9080 solver.cpp:218] Iteration 14400 (35.4462 iter/s, 2.82117s/100 iters), loss = 0.367278
I0923 21:05:37.402861  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:05:37.402861  9080 solver.cpp:237]     Train net output #1: loss = 0.367278 (* 1 = 0.367278 loss)
I0923 21:05:37.402861  9080 sgd_solver.cpp:105] Iteration 14400, lr = 0.0001
I0923 21:05:40.067988 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:05:40.205575  9080 solver.cpp:218] Iteration 14500 (35.6917 iter/s, 2.80177s/100 iters), loss = 0.454189
I0923 21:05:40.205575  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:05:40.205575  9080 solver.cpp:237]     Train net output #1: loss = 0.454189 (* 1 = 0.454189 loss)
I0923 21:05:40.205575  9080 sgd_solver.cpp:105] Iteration 14500, lr = 0.0001
I0923 21:05:43.011843  9080 solver.cpp:218] Iteration 14600 (35.6266 iter/s, 2.80689s/100 iters), loss = 0.385295
I0923 21:05:43.012843  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:05:43.012843  9080 solver.cpp:237]     Train net output #1: loss = 0.385295 (* 1 = 0.385295 loss)
I0923 21:05:43.012843  9080 sgd_solver.cpp:105] Iteration 14600, lr = 0.0001
I0923 21:05:45.825009  9080 solver.cpp:218] Iteration 14700 (35.5607 iter/s, 2.8121s/100 iters), loss = 0.444857
I0923 21:05:45.825009  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:05:45.825009  9080 solver.cpp:237]     Train net output #1: loss = 0.444857 (* 1 = 0.444857 loss)
I0923 21:05:45.825009  9080 sgd_solver.cpp:105] Iteration 14700, lr = 0.0001
I0923 21:05:48.628139  9080 solver.cpp:218] Iteration 14800 (35.6809 iter/s, 2.80262s/100 iters), loss = 0.522938
I0923 21:05:48.628139  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:05:48.628139  9080 solver.cpp:237]     Train net output #1: loss = 0.522938 (* 1 = 0.522938 loss)
I0923 21:05:48.628139  9080 sgd_solver.cpp:105] Iteration 14800, lr = 0.0001
I0923 21:05:51.435262  9080 solver.cpp:218] Iteration 14900 (35.6205 iter/s, 2.80737s/100 iters), loss = 0.416342
I0923 21:05:51.435262  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:05:51.435262  9080 solver.cpp:237]     Train net output #1: loss = 0.416342 (* 1 = 0.416342 loss)
I0923 21:05:51.435262  9080 sgd_solver.cpp:105] Iteration 14900, lr = 0.0001
I0923 21:05:54.088452 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:05:54.196565  9080 solver.cpp:330] Iteration 15000, Testing net (#0)
I0923 21:05:54.196565  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:05:54.711474  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:05:54.731500  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7867
I0923 21:05:54.731500  9080 solver.cpp:397]     Test net output #1: loss = 0.62469 (* 1 = 0.62469 loss)
I0923 21:05:54.756518  9080 solver.cpp:218] Iteration 15000 (30.1109 iter/s, 3.32106s/100 iters), loss = 0.488009
I0923 21:05:54.756518  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:05:54.756518  9080 solver.cpp:237]     Train net output #1: loss = 0.488009 (* 1 = 0.488009 loss)
I0923 21:05:54.756518  9080 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I0923 21:05:54.756518  9080 sgd_solver.cpp:105] Iteration 15000, lr = 1e-05
I0923 21:05:57.515785  9080 solver.cpp:218] Iteration 15100 (36.2471 iter/s, 2.75884s/100 iters), loss = 0.436274
I0923 21:05:57.515785  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:05:57.515785  9080 solver.cpp:237]     Train net output #1: loss = 0.436274 (* 1 = 0.436274 loss)
I0923 21:05:57.515785  9080 sgd_solver.cpp:105] Iteration 15100, lr = 1e-05
I0923 21:06:00.267768  9080 solver.cpp:218] Iteration 15200 (36.3397 iter/s, 2.75181s/100 iters), loss = 0.38369
I0923 21:06:00.267768  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 21:06:00.267768  9080 solver.cpp:237]     Train net output #1: loss = 0.38369 (* 1 = 0.38369 loss)
I0923 21:06:00.267768  9080 sgd_solver.cpp:105] Iteration 15200, lr = 1e-05
I0923 21:06:03.001400  9080 solver.cpp:218] Iteration 15300 (36.5945 iter/s, 2.73265s/100 iters), loss = 0.486907
I0923 21:06:03.001400  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:06:03.001400  9080 solver.cpp:237]     Train net output #1: loss = 0.486907 (* 1 = 0.486907 loss)
I0923 21:06:03.001400  9080 sgd_solver.cpp:105] Iteration 15300, lr = 1e-05
I0923 21:06:05.735278  9080 solver.cpp:218] Iteration 15400 (36.5853 iter/s, 2.73334s/100 iters), loss = 0.396733
I0923 21:06:05.735278  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:06:05.735278  9080 solver.cpp:237]     Train net output #1: loss = 0.396733 (* 1 = 0.396733 loss)
I0923 21:06:05.735278  9080 sgd_solver.cpp:105] Iteration 15400, lr = 1e-05
I0923 21:06:08.341575 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:06:08.475703  9080 solver.cpp:218] Iteration 15500 (36.4854 iter/s, 2.74082s/100 iters), loss = 0.45945
I0923 21:06:08.475703  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:06:08.475703  9080 solver.cpp:237]     Train net output #1: loss = 0.45945 (* 1 = 0.45945 loss)
I0923 21:06:08.475703  9080 sgd_solver.cpp:105] Iteration 15500, lr = 1e-05
I0923 21:06:11.213052  9080 solver.cpp:218] Iteration 15600 (36.546 iter/s, 2.73628s/100 iters), loss = 0.475568
I0923 21:06:11.213052  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 21:06:11.213052  9080 solver.cpp:237]     Train net output #1: loss = 0.475568 (* 1 = 0.475568 loss)
I0923 21:06:11.213052  9080 sgd_solver.cpp:105] Iteration 15600, lr = 1e-05
I0923 21:06:13.961249  9080 solver.cpp:218] Iteration 15700 (36.3879 iter/s, 2.74817s/100 iters), loss = 0.418941
I0923 21:06:13.961249  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:06:13.961249  9080 solver.cpp:237]     Train net output #1: loss = 0.418941 (* 1 = 0.418941 loss)
I0923 21:06:13.961249  9080 sgd_solver.cpp:105] Iteration 15700, lr = 1e-05
I0923 21:06:16.722766  9080 solver.cpp:218] Iteration 15800 (36.2161 iter/s, 2.7612s/100 iters), loss = 0.494225
I0923 21:06:16.723264  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:06:16.723264  9080 solver.cpp:237]     Train net output #1: loss = 0.494225 (* 1 = 0.494225 loss)
I0923 21:06:16.723264  9080 sgd_solver.cpp:105] Iteration 15800, lr = 1e-05
I0923 21:06:19.528153  9080 solver.cpp:218] Iteration 15900 (35.656 iter/s, 2.80458s/100 iters), loss = 0.409359
I0923 21:06:19.528153  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:06:19.528153  9080 solver.cpp:237]     Train net output #1: loss = 0.409359 (* 1 = 0.409359 loss)
I0923 21:06:19.528153  9080 sgd_solver.cpp:105] Iteration 15900, lr = 1e-05
I0923 21:06:22.135349 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:06:22.242064  9080 solver.cpp:330] Iteration 16000, Testing net (#0)
I0923 21:06:22.242064  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:06:22.754788  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:06:22.775804  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7867
I0923 21:06:22.775804  9080 solver.cpp:397]     Test net output #1: loss = 0.62414 (* 1 = 0.62414 loss)
I0923 21:06:22.801821  9080 solver.cpp:218] Iteration 16000 (30.5497 iter/s, 3.27335s/100 iters), loss = 0.481135
I0923 21:06:22.801821  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:06:22.801821  9080 solver.cpp:237]     Train net output #1: loss = 0.481135 (* 1 = 0.481135 loss)
I0923 21:06:22.801821  9080 sgd_solver.cpp:105] Iteration 16000, lr = 1e-05
I0923 21:06:25.576921  9080 solver.cpp:218] Iteration 16100 (36.0322 iter/s, 2.77529s/100 iters), loss = 0.427115
I0923 21:06:25.576921  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:06:25.576921  9080 solver.cpp:237]     Train net output #1: loss = 0.427115 (* 1 = 0.427115 loss)
I0923 21:06:25.576921  9080 sgd_solver.cpp:105] Iteration 16100, lr = 1e-05
I0923 21:06:28.400068  9080 solver.cpp:218] Iteration 16200 (35.4321 iter/s, 2.8223s/100 iters), loss = 0.43064
I0923 21:06:28.400068  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:06:28.400068  9080 solver.cpp:237]     Train net output #1: loss = 0.43064 (* 1 = 0.43064 loss)
I0923 21:06:28.400068  9080 sgd_solver.cpp:105] Iteration 16200, lr = 1e-05
I0923 21:06:31.134727  9080 solver.cpp:218] Iteration 16300 (36.5735 iter/s, 2.73422s/100 iters), loss = 0.518807
I0923 21:06:31.134727  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:06:31.134727  9080 solver.cpp:237]     Train net output #1: loss = 0.518807 (* 1 = 0.518807 loss)
I0923 21:06:31.134727  9080 sgd_solver.cpp:105] Iteration 16300, lr = 1e-05
I0923 21:06:33.872854  9080 solver.cpp:218] Iteration 16400 (36.5275 iter/s, 2.73766s/100 iters), loss = 0.380281
I0923 21:06:33.872854  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:06:33.872854  9080 solver.cpp:237]     Train net output #1: loss = 0.380281 (* 1 = 0.380281 loss)
I0923 21:06:33.872854  9080 sgd_solver.cpp:105] Iteration 16400, lr = 1e-05
I0923 21:06:36.467768 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:06:36.601894  9080 solver.cpp:218] Iteration 16500 (36.6429 iter/s, 2.72904s/100 iters), loss = 0.49856
I0923 21:06:36.601894  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:06:36.601894  9080 solver.cpp:237]     Train net output #1: loss = 0.49856 (* 1 = 0.49856 loss)
I0923 21:06:36.601894  9080 sgd_solver.cpp:105] Iteration 16500, lr = 1e-05
I0923 21:06:39.332170  9080 solver.cpp:218] Iteration 16600 (36.6312 iter/s, 2.72991s/100 iters), loss = 0.515009
I0923 21:06:39.332170  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:06:39.332170  9080 solver.cpp:237]     Train net output #1: loss = 0.515009 (* 1 = 0.515009 loss)
I0923 21:06:39.332170  9080 sgd_solver.cpp:105] Iteration 16600, lr = 1e-05
I0923 21:06:42.068150  9080 solver.cpp:218] Iteration 16700 (36.5528 iter/s, 2.73577s/100 iters), loss = 0.424831
I0923 21:06:42.068150  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:06:42.068150  9080 solver.cpp:237]     Train net output #1: loss = 0.424831 (* 1 = 0.424831 loss)
I0923 21:06:42.068150  9080 sgd_solver.cpp:105] Iteration 16700, lr = 1e-05
I0923 21:06:44.807381  9080 solver.cpp:218] Iteration 16800 (36.5094 iter/s, 2.73902s/100 iters), loss = 0.549961
I0923 21:06:44.807381  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 21:06:44.807381  9080 solver.cpp:237]     Train net output #1: loss = 0.549961 (* 1 = 0.549961 loss)
I0923 21:06:44.807381  9080 sgd_solver.cpp:105] Iteration 16800, lr = 1e-05
I0923 21:06:47.538616  9080 solver.cpp:218] Iteration 16900 (36.6214 iter/s, 2.73065s/100 iters), loss = 0.406931
I0923 21:06:47.538616  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:06:47.538616  9080 solver.cpp:237]     Train net output #1: loss = 0.406931 (* 1 = 0.406931 loss)
I0923 21:06:47.538616  9080 sgd_solver.cpp:105] Iteration 16900, lr = 1e-05
I0923 21:06:50.148730 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:06:50.256857  9080 solver.cpp:330] Iteration 17000, Testing net (#0)
I0923 21:06:50.256857  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:06:50.780563  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:06:50.800578  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7865
I0923 21:06:50.801578  9080 solver.cpp:397]     Test net output #1: loss = 0.624042 (* 1 = 0.624042 loss)
I0923 21:06:50.827607  9080 solver.cpp:218] Iteration 17000 (30.4046 iter/s, 3.28897s/100 iters), loss = 0.485489
I0923 21:06:50.827607  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:06:50.827607  9080 solver.cpp:237]     Train net output #1: loss = 0.485489 (* 1 = 0.485489 loss)
I0923 21:06:50.827607  9080 sgd_solver.cpp:105] Iteration 17000, lr = 1e-05
I0923 21:06:53.644870  9080 solver.cpp:218] Iteration 17100 (35.5052 iter/s, 2.81649s/100 iters), loss = 0.486015
I0923 21:06:53.644870  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I0923 21:06:53.644870  9080 solver.cpp:237]     Train net output #1: loss = 0.486015 (* 1 = 0.486015 loss)
I0923 21:06:53.644870  9080 sgd_solver.cpp:105] Iteration 17100, lr = 1e-05
I0923 21:06:56.459542  9080 solver.cpp:218] Iteration 17200 (35.5297 iter/s, 2.81455s/100 iters), loss = 0.423165
I0923 21:06:56.459542  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:06:56.459542  9080 solver.cpp:237]     Train net output #1: loss = 0.423165 (* 1 = 0.423165 loss)
I0923 21:06:56.459542  9080 sgd_solver.cpp:105] Iteration 17200, lr = 1e-05
I0923 21:06:59.225051  9080 solver.cpp:218] Iteration 17300 (36.1603 iter/s, 2.76547s/100 iters), loss = 0.496424
I0923 21:06:59.225051  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:06:59.225051  9080 solver.cpp:237]     Train net output #1: loss = 0.496424 (* 1 = 0.496424 loss)
I0923 21:06:59.225051  9080 sgd_solver.cpp:105] Iteration 17300, lr = 1e-05
I0923 21:07:01.986748  9080 solver.cpp:218] Iteration 17400 (36.2186 iter/s, 2.76101s/100 iters), loss = 0.421567
I0923 21:07:01.986748  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:07:01.986748  9080 solver.cpp:237]     Train net output #1: loss = 0.421567 (* 1 = 0.421567 loss)
I0923 21:07:01.986748  9080 sgd_solver.cpp:105] Iteration 17400, lr = 1e-05
I0923 21:07:04.667284 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:07:04.803946  9080 solver.cpp:218] Iteration 17500 (35.5001 iter/s, 2.81689s/100 iters), loss = 0.448584
I0923 21:07:04.803946  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:07:04.803946  9080 solver.cpp:237]     Train net output #1: loss = 0.448584 (* 1 = 0.448584 loss)
I0923 21:07:04.803946  9080 sgd_solver.cpp:105] Iteration 17500, lr = 1e-05
I0923 21:07:07.569536  9080 solver.cpp:218] Iteration 17600 (36.163 iter/s, 2.76525s/100 iters), loss = 0.423117
I0923 21:07:07.569536  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:07:07.569536  9080 solver.cpp:237]     Train net output #1: loss = 0.423117 (* 1 = 0.423117 loss)
I0923 21:07:07.569536  9080 sgd_solver.cpp:105] Iteration 17600, lr = 1e-05
I0923 21:07:10.294800  9080 solver.cpp:218] Iteration 17700 (36.6979 iter/s, 2.72495s/100 iters), loss = 0.37815
I0923 21:07:10.294800  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0923 21:07:10.294800  9080 solver.cpp:237]     Train net output #1: loss = 0.37815 (* 1 = 0.37815 loss)
I0923 21:07:10.294800  9080 sgd_solver.cpp:105] Iteration 17700, lr = 1e-05
I0923 21:07:13.054241  9080 solver.cpp:218] Iteration 17800 (36.2432 iter/s, 2.75914s/100 iters), loss = 0.511719
I0923 21:07:13.054241  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:07:13.054241  9080 solver.cpp:237]     Train net output #1: loss = 0.511719 (* 1 = 0.511719 loss)
I0923 21:07:13.054241  9080 sgd_solver.cpp:105] Iteration 17800, lr = 1e-05
I0923 21:07:15.867132  9080 solver.cpp:218] Iteration 17900 (35.5578 iter/s, 2.81232s/100 iters), loss = 0.372645
I0923 21:07:15.867132  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:07:15.867132  9080 solver.cpp:237]     Train net output #1: loss = 0.372645 (* 1 = 0.372645 loss)
I0923 21:07:15.867132  9080 sgd_solver.cpp:105] Iteration 17900, lr = 1e-05
I0923 21:07:18.488257 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:07:18.595845  9080 solver.cpp:330] Iteration 18000, Testing net (#0)
I0923 21:07:18.595845  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:07:19.109386  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:07:19.129416  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7866
I0923 21:07:19.129416  9080 solver.cpp:397]     Test net output #1: loss = 0.624095 (* 1 = 0.624095 loss)
I0923 21:07:19.155431  9080 solver.cpp:218] Iteration 18000 (30.4178 iter/s, 3.28754s/100 iters), loss = 0.53813
I0923 21:07:19.155431  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:07:19.155431  9080 solver.cpp:237]     Train net output #1: loss = 0.53813 (* 1 = 0.53813 loss)
I0923 21:07:19.155431  9080 sgd_solver.cpp:105] Iteration 18000, lr = 1e-05
I0923 21:07:21.872359  9080 solver.cpp:218] Iteration 18100 (36.7993 iter/s, 2.71744s/100 iters), loss = 0.42676
I0923 21:07:21.872359  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:07:21.872359  9080 solver.cpp:237]     Train net output #1: loss = 0.42676 (* 1 = 0.42676 loss)
I0923 21:07:21.872359  9080 sgd_solver.cpp:105] Iteration 18100, lr = 1e-05
I0923 21:07:24.592519  9080 solver.cpp:218] Iteration 18200 (36.7763 iter/s, 2.71914s/100 iters), loss = 0.471319
I0923 21:07:24.592519  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:07:24.592519  9080 solver.cpp:237]     Train net output #1: loss = 0.471319 (* 1 = 0.471319 loss)
I0923 21:07:24.592519  9080 sgd_solver.cpp:105] Iteration 18200, lr = 1e-05
I0923 21:07:27.348798  9080 solver.cpp:218] Iteration 18300 (36.2806 iter/s, 2.7563s/100 iters), loss = 0.440987
I0923 21:07:27.348798  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:07:27.348798  9080 solver.cpp:237]     Train net output #1: loss = 0.440987 (* 1 = 0.440987 loss)
I0923 21:07:27.348798  9080 sgd_solver.cpp:105] Iteration 18300, lr = 1e-05
I0923 21:07:30.081332  9080 solver.cpp:218] Iteration 18400 (36.5972 iter/s, 2.73245s/100 iters), loss = 0.437064
I0923 21:07:30.081332  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:07:30.081332  9080 solver.cpp:237]     Train net output #1: loss = 0.437064 (* 1 = 0.437064 loss)
I0923 21:07:30.081332  9080 sgd_solver.cpp:105] Iteration 18400, lr = 1e-05
I0923 21:07:32.736903 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:07:32.873006  9080 solver.cpp:218] Iteration 18500 (35.8291 iter/s, 2.79103s/100 iters), loss = 0.455901
I0923 21:07:32.873006  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:07:32.873006  9080 solver.cpp:237]     Train net output #1: loss = 0.455901 (* 1 = 0.455901 loss)
I0923 21:07:32.873006  9080 sgd_solver.cpp:105] Iteration 18500, lr = 1e-05
I0923 21:07:35.674803  9080 solver.cpp:218] Iteration 18600 (35.6912 iter/s, 2.80181s/100 iters), loss = 0.459965
I0923 21:07:35.674803  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:07:35.674803  9080 solver.cpp:237]     Train net output #1: loss = 0.459965 (* 1 = 0.459965 loss)
I0923 21:07:35.674803  9080 sgd_solver.cpp:105] Iteration 18600, lr = 1e-05
I0923 21:07:38.408541  9080 solver.cpp:218] Iteration 18700 (36.5856 iter/s, 2.73332s/100 iters), loss = 0.414483
I0923 21:07:38.408541  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:07:38.408541  9080 solver.cpp:237]     Train net output #1: loss = 0.414483 (* 1 = 0.414483 loss)
I0923 21:07:38.408541  9080 sgd_solver.cpp:105] Iteration 18700, lr = 1e-05
I0923 21:07:41.148164  9080 solver.cpp:218] Iteration 18800 (36.5102 iter/s, 2.73896s/100 iters), loss = 0.506056
I0923 21:07:41.148164  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:07:41.148164  9080 solver.cpp:237]     Train net output #1: loss = 0.506056 (* 1 = 0.506056 loss)
I0923 21:07:41.148164  9080 sgd_solver.cpp:105] Iteration 18800, lr = 1e-05
I0923 21:07:43.901196  9080 solver.cpp:218] Iteration 18900 (36.3314 iter/s, 2.75244s/100 iters), loss = 0.389734
I0923 21:07:43.901196  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:07:43.901196  9080 solver.cpp:237]     Train net output #1: loss = 0.389734 (* 1 = 0.389734 loss)
I0923 21:07:43.901196  9080 sgd_solver.cpp:105] Iteration 18900, lr = 1e-05
I0923 21:07:46.507369 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:07:46.616534  9080 solver.cpp:330] Iteration 19000, Testing net (#0)
I0923 21:07:46.616534  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:07:47.139180  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:07:47.160195  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7857
I0923 21:07:47.160195  9080 solver.cpp:397]     Test net output #1: loss = 0.624071 (* 1 = 0.624071 loss)
I0923 21:07:47.186214  9080 solver.cpp:218] Iteration 19000 (30.4449 iter/s, 3.28463s/100 iters), loss = 0.490241
I0923 21:07:47.186214  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:07:47.186214  9080 solver.cpp:237]     Train net output #1: loss = 0.490241 (* 1 = 0.490241 loss)
I0923 21:07:47.186214  9080 sgd_solver.cpp:105] Iteration 19000, lr = 1e-05
I0923 21:07:49.950268  9080 solver.cpp:218] Iteration 19100 (36.1777 iter/s, 2.76413s/100 iters), loss = 0.561549
I0923 21:07:49.950268  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0923 21:07:49.950268  9080 solver.cpp:237]     Train net output #1: loss = 0.561549 (* 1 = 0.561549 loss)
I0923 21:07:49.950268  9080 sgd_solver.cpp:105] Iteration 19100, lr = 1e-05
I0923 21:07:52.771046  9080 solver.cpp:218] Iteration 19200 (35.4602 iter/s, 2.82006s/100 iters), loss = 0.438965
I0923 21:07:52.771046  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:07:52.771046  9080 solver.cpp:237]     Train net output #1: loss = 0.438965 (* 1 = 0.438965 loss)
I0923 21:07:52.771046  9080 sgd_solver.cpp:105] Iteration 19200, lr = 1e-05
I0923 21:07:55.545011  9080 solver.cpp:218] Iteration 19300 (36.0478 iter/s, 2.7741s/100 iters), loss = 0.501806
I0923 21:07:55.545011  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:07:55.545011  9080 solver.cpp:237]     Train net output #1: loss = 0.501806 (* 1 = 0.501806 loss)
I0923 21:07:55.545011  9080 sgd_solver.cpp:105] Iteration 19300, lr = 1e-05
I0923 21:07:58.350395  9080 solver.cpp:218] Iteration 19400 (35.6606 iter/s, 2.80422s/100 iters), loss = 0.427533
I0923 21:07:58.350395  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:07:58.350395  9080 solver.cpp:237]     Train net output #1: loss = 0.427533 (* 1 = 0.427533 loss)
I0923 21:07:58.350395  9080 sgd_solver.cpp:105] Iteration 19400, lr = 1e-05
I0923 21:08:01.002087 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:08:01.135226  9080 solver.cpp:218] Iteration 19500 (35.9026 iter/s, 2.78531s/100 iters), loss = 0.493796
I0923 21:08:01.136226  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:08:01.136226  9080 solver.cpp:237]     Train net output #1: loss = 0.493796 (* 1 = 0.493796 loss)
I0923 21:08:01.136226  9080 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I0923 21:08:03.915750  9080 solver.cpp:218] Iteration 19600 (35.9794 iter/s, 2.77937s/100 iters), loss = 0.435504
I0923 21:08:03.915750  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:08:03.915750  9080 solver.cpp:237]     Train net output #1: loss = 0.435504 (* 1 = 0.435504 loss)
I0923 21:08:03.915750  9080 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I0923 21:08:06.719861  9080 solver.cpp:218] Iteration 19700 (35.6583 iter/s, 2.8044s/100 iters), loss = 0.394576
I0923 21:08:06.719861  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:08:06.719861  9080 solver.cpp:237]     Train net output #1: loss = 0.394576 (* 1 = 0.394576 loss)
I0923 21:08:06.719861  9080 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I0923 21:08:09.474274  9080 solver.cpp:218] Iteration 19800 (36.3142 iter/s, 2.75374s/100 iters), loss = 0.494662
I0923 21:08:09.474274  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:08:09.474274  9080 solver.cpp:237]     Train net output #1: loss = 0.494662 (* 1 = 0.494662 loss)
I0923 21:08:09.474274  9080 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I0923 21:08:12.278096  9080 solver.cpp:218] Iteration 19900 (35.6738 iter/s, 2.80317s/100 iters), loss = 0.394451
I0923 21:08:12.278096  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:08:12.278096  9080 solver.cpp:237]     Train net output #1: loss = 0.394451 (* 1 = 0.394451 loss)
I0923 21:08:12.278096  9080 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I0923 21:08:14.942914 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:08:15.052991  9080 solver.cpp:330] Iteration 20000, Testing net (#0)
I0923 21:08:15.052991  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:08:15.579169  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:08:15.600185  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7856
I0923 21:08:15.600185  9080 solver.cpp:397]     Test net output #1: loss = 0.624115 (* 1 = 0.624115 loss)
I0923 21:08:15.626199  9080 solver.cpp:218] Iteration 20000 (29.8686 iter/s, 3.348s/100 iters), loss = 0.508061
I0923 21:08:15.626699  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:08:15.626699  9080 solver.cpp:237]     Train net output #1: loss = 0.508061 (* 1 = 0.508061 loss)
I0923 21:08:15.626699  9080 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I0923 21:08:18.440696  9080 solver.cpp:218] Iteration 20100 (35.5313 iter/s, 2.81442s/100 iters), loss = 0.485349
I0923 21:08:18.440696  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 21:08:18.440696  9080 solver.cpp:237]     Train net output #1: loss = 0.485349 (* 1 = 0.485349 loss)
I0923 21:08:18.440696  9080 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I0923 21:08:21.222466  9080 solver.cpp:218] Iteration 20200 (35.963 iter/s, 2.78064s/100 iters), loss = 0.391264
I0923 21:08:21.222466  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:08:21.222466  9080 solver.cpp:237]     Train net output #1: loss = 0.391264 (* 1 = 0.391264 loss)
I0923 21:08:21.222466  9080 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I0923 21:08:23.949844  9080 solver.cpp:218] Iteration 20300 (36.658 iter/s, 2.72792s/100 iters), loss = 0.475775
I0923 21:08:23.949844  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:08:23.949844  9080 solver.cpp:237]     Train net output #1: loss = 0.475775 (* 1 = 0.475775 loss)
I0923 21:08:23.949844  9080 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I0923 21:08:26.749562  9080 solver.cpp:218] Iteration 20400 (35.73 iter/s, 2.79877s/100 iters), loss = 0.44944
I0923 21:08:26.749562  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:08:26.749562  9080 solver.cpp:237]     Train net output #1: loss = 0.44944 (* 1 = 0.44944 loss)
I0923 21:08:26.749562  9080 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I0923 21:08:29.424366 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:08:29.559484  9080 solver.cpp:218] Iteration 20500 (35.5874 iter/s, 2.80998s/100 iters), loss = 0.507598
I0923 21:08:29.559484  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:08:29.559484  9080 solver.cpp:237]     Train net output #1: loss = 0.507598 (* 1 = 0.507598 loss)
I0923 21:08:29.559484  9080 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I0923 21:08:32.319928  9080 solver.cpp:218] Iteration 20600 (36.2361 iter/s, 2.75968s/100 iters), loss = 0.528777
I0923 21:08:32.319928  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:08:32.319928  9080 solver.cpp:237]     Train net output #1: loss = 0.528777 (* 1 = 0.528777 loss)
I0923 21:08:32.319928  9080 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I0923 21:08:35.044893  9080 solver.cpp:218] Iteration 20700 (36.7041 iter/s, 2.72449s/100 iters), loss = 0.418942
I0923 21:08:35.044893  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:08:35.044893  9080 solver.cpp:237]     Train net output #1: loss = 0.418942 (* 1 = 0.418942 loss)
I0923 21:08:35.044893  9080 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I0923 21:08:37.783131  9080 solver.cpp:218] Iteration 20800 (36.5183 iter/s, 2.73836s/100 iters), loss = 0.461891
I0923 21:08:37.783131  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:08:37.783131  9080 solver.cpp:237]     Train net output #1: loss = 0.461891 (* 1 = 0.461891 loss)
I0923 21:08:37.783131  9080 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I0923 21:08:40.516389  9080 solver.cpp:218] Iteration 20900 (36.5935 iter/s, 2.73273s/100 iters), loss = 0.409523
I0923 21:08:40.516389  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:08:40.516389  9080 solver.cpp:237]     Train net output #1: loss = 0.409523 (* 1 = 0.409523 loss)
I0923 21:08:40.516389  9080 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I0923 21:08:43.102821 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:08:43.208508  9080 solver.cpp:330] Iteration 21000, Testing net (#0)
I0923 21:08:43.208508  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:08:43.724236  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:08:43.744251  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7866
I0923 21:08:43.744251  9080 solver.cpp:397]     Test net output #1: loss = 0.623957 (* 1 = 0.623957 loss)
I0923 21:08:43.769771  9080 solver.cpp:218] Iteration 21000 (30.7429 iter/s, 3.25278s/100 iters), loss = 0.47723
I0923 21:08:43.770272  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:08:43.770272  9080 solver.cpp:237]     Train net output #1: loss = 0.47723 (* 1 = 0.47723 loss)
I0923 21:08:43.770272  9080 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I0923 21:08:46.503891  9080 solver.cpp:218] Iteration 21100 (36.5853 iter/s, 2.73334s/100 iters), loss = 0.47665
I0923 21:08:46.503891  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 21:08:46.503891  9080 solver.cpp:237]     Train net output #1: loss = 0.47665 (* 1 = 0.47665 loss)
I0923 21:08:46.503891  9080 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I0923 21:08:49.230888  9080 solver.cpp:218] Iteration 21200 (36.665 iter/s, 2.72739s/100 iters), loss = 0.46216
I0923 21:08:49.230888  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:08:49.230888  9080 solver.cpp:237]     Train net output #1: loss = 0.46216 (* 1 = 0.46216 loss)
I0923 21:08:49.230888  9080 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I0923 21:08:51.973209  9080 solver.cpp:218] Iteration 21300 (36.4752 iter/s, 2.74159s/100 iters), loss = 0.52303
I0923 21:08:51.973209  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:08:51.973209  9080 solver.cpp:237]     Train net output #1: loss = 0.52303 (* 1 = 0.52303 loss)
I0923 21:08:51.973209  9080 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I0923 21:08:54.701979  9080 solver.cpp:218] Iteration 21400 (36.6473 iter/s, 2.72871s/100 iters), loss = 0.427104
I0923 21:08:54.701979  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:08:54.701979  9080 solver.cpp:237]     Train net output #1: loss = 0.427104 (* 1 = 0.427104 loss)
I0923 21:08:54.701979  9080 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I0923 21:08:57.293524 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:08:57.427621  9080 solver.cpp:218] Iteration 21500 (36.6895 iter/s, 2.72558s/100 iters), loss = 0.485616
I0923 21:08:57.427621  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:08:57.427621  9080 solver.cpp:237]     Train net output #1: loss = 0.485616 (* 1 = 0.485616 loss)
I0923 21:08:57.427621  9080 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I0923 21:09:00.157351  9080 solver.cpp:218] Iteration 21600 (36.6422 iter/s, 2.72909s/100 iters), loss = 0.510363
I0923 21:09:00.157351  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:09:00.157351  9080 solver.cpp:237]     Train net output #1: loss = 0.510363 (* 1 = 0.510363 loss)
I0923 21:09:00.157351  9080 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I0923 21:09:02.891914  9080 solver.cpp:218] Iteration 21700 (36.5697 iter/s, 2.7345s/100 iters), loss = 0.462426
I0923 21:09:02.891914  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:09:02.891914  9080 solver.cpp:237]     Train net output #1: loss = 0.462426 (* 1 = 0.462426 loss)
I0923 21:09:02.891914  9080 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I0923 21:09:05.627473  9080 solver.cpp:218] Iteration 21800 (36.5664 iter/s, 2.73475s/100 iters), loss = 0.452737
I0923 21:09:05.627473  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:09:05.627473  9080 solver.cpp:237]     Train net output #1: loss = 0.452737 (* 1 = 0.452737 loss)
I0923 21:09:05.627473  9080 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I0923 21:09:08.388078  9080 solver.cpp:218] Iteration 21900 (36.232 iter/s, 2.75999s/100 iters), loss = 0.397318
I0923 21:09:08.388078  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:09:08.388078  9080 solver.cpp:237]     Train net output #1: loss = 0.397318 (* 1 = 0.397318 loss)
I0923 21:09:08.388078  9080 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I0923 21:09:11.035387 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:09:11.144948  9080 solver.cpp:330] Iteration 22000, Testing net (#0)
I0923 21:09:11.144948  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:09:11.663316  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:09:11.684331  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7863
I0923 21:09:11.684331  9080 solver.cpp:397]     Test net output #1: loss = 0.624154 (* 1 = 0.624154 loss)
I0923 21:09:11.709851  9080 solver.cpp:218] Iteration 22000 (30.1054 iter/s, 3.32167s/100 iters), loss = 0.496058
I0923 21:09:11.709851  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:09:11.709851  9080 solver.cpp:237]     Train net output #1: loss = 0.496058 (* 1 = 0.496058 loss)
I0923 21:09:11.709851  9080 sgd_solver.cpp:105] Iteration 22000, lr = 1e-05
I0923 21:09:14.454267  9080 solver.cpp:218] Iteration 22100 (36.4444 iter/s, 2.74391s/100 iters), loss = 0.478095
I0923 21:09:14.454267  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:09:14.454267  9080 solver.cpp:237]     Train net output #1: loss = 0.478095 (* 1 = 0.478095 loss)
I0923 21:09:14.454267  9080 sgd_solver.cpp:105] Iteration 22100, lr = 1e-05
I0923 21:09:17.203745  9080 solver.cpp:218] Iteration 22200 (36.3774 iter/s, 2.74896s/100 iters), loss = 0.401814
I0923 21:09:17.203745  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:09:17.203745  9080 solver.cpp:237]     Train net output #1: loss = 0.401814 (* 1 = 0.401814 loss)
I0923 21:09:17.203745  9080 sgd_solver.cpp:105] Iteration 22200, lr = 1e-05
I0923 21:09:19.961730  9080 solver.cpp:218] Iteration 22300 (36.2636 iter/s, 2.75759s/100 iters), loss = 0.490927
I0923 21:09:19.961730  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0923 21:09:19.961730  9080 solver.cpp:237]     Train net output #1: loss = 0.490927 (* 1 = 0.490927 loss)
I0923 21:09:19.961730  9080 sgd_solver.cpp:105] Iteration 22300, lr = 1e-05
I0923 21:09:22.710098  9080 solver.cpp:218] Iteration 22400 (36.3864 iter/s, 2.74828s/100 iters), loss = 0.357301
I0923 21:09:22.710098  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0923 21:09:22.710098  9080 solver.cpp:237]     Train net output #1: loss = 0.357301 (* 1 = 0.357301 loss)
I0923 21:09:22.710098  9080 sgd_solver.cpp:105] Iteration 22400, lr = 1e-05
I0923 21:09:25.311795 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:09:25.445991  9080 solver.cpp:218] Iteration 22500 (36.554 iter/s, 2.73568s/100 iters), loss = 0.452574
I0923 21:09:25.445991  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:09:25.445991  9080 solver.cpp:237]     Train net output #1: loss = 0.452574 (* 1 = 0.452574 loss)
I0923 21:09:25.445991  9080 sgd_solver.cpp:105] Iteration 22500, lr = 1e-05
I0923 21:09:28.197937  9080 solver.cpp:218] Iteration 22600 (36.3449 iter/s, 2.75141s/100 iters), loss = 0.480461
I0923 21:09:28.197937  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:09:28.197937  9080 solver.cpp:237]     Train net output #1: loss = 0.480461 (* 1 = 0.480461 loss)
I0923 21:09:28.197937  9080 sgd_solver.cpp:105] Iteration 22600, lr = 1e-05
I0923 21:09:30.930523  9080 solver.cpp:218] Iteration 22700 (36.6005 iter/s, 2.7322s/100 iters), loss = 0.393249
I0923 21:09:30.930523  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:09:30.930523  9080 solver.cpp:237]     Train net output #1: loss = 0.393249 (* 1 = 0.393249 loss)
I0923 21:09:30.930523  9080 sgd_solver.cpp:105] Iteration 22700, lr = 1e-05
I0923 21:09:33.660279  9080 solver.cpp:218] Iteration 22800 (36.6335 iter/s, 2.72974s/100 iters), loss = 0.502819
I0923 21:09:33.660279  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I0923 21:09:33.660279  9080 solver.cpp:237]     Train net output #1: loss = 0.502819 (* 1 = 0.502819 loss)
I0923 21:09:33.660279  9080 sgd_solver.cpp:105] Iteration 22800, lr = 1e-05
I0923 21:09:36.396728  9080 solver.cpp:218] Iteration 22900 (36.5494 iter/s, 2.73602s/100 iters), loss = 0.356742
I0923 21:09:36.396728  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:09:36.396728  9080 solver.cpp:237]     Train net output #1: loss = 0.356742 (* 1 = 0.356742 loss)
I0923 21:09:36.396728  9080 sgd_solver.cpp:105] Iteration 22900, lr = 1e-05
I0923 21:09:39.009935 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:09:39.122030  9080 solver.cpp:330] Iteration 23000, Testing net (#0)
I0923 21:09:39.122030  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:09:39.657559  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:09:39.677556  9080 solver.cpp:397]     Test net output #0: accuracy = 0.7862
I0923 21:09:39.677556  9080 solver.cpp:397]     Test net output #1: loss = 0.624071 (* 1 = 0.624071 loss)
I0923 21:09:39.703591  9080 solver.cpp:218] Iteration 23000 (30.2434 iter/s, 3.3065s/100 iters), loss = 0.466824
I0923 21:09:39.703591  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:09:39.703591  9080 solver.cpp:237]     Train net output #1: loss = 0.466824 (* 1 = 0.466824 loss)
I0923 21:09:39.703591  9080 sgd_solver.cpp:105] Iteration 23000, lr = 1e-05
I0923 21:09:42.471595  9080 solver.cpp:218] Iteration 23100 (36.1306 iter/s, 2.76774s/100 iters), loss = 0.459984
I0923 21:09:42.471595  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0923 21:09:42.471595  9080 solver.cpp:237]     Train net output #1: loss = 0.459984 (* 1 = 0.459984 loss)
I0923 21:09:42.471595  9080 sgd_solver.cpp:105] Iteration 23100, lr = 1e-05
I0923 21:09:45.225178  9080 solver.cpp:218] Iteration 23200 (36.3184 iter/s, 2.75342s/100 iters), loss = 0.364109
I0923 21:09:45.225178  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0923 21:09:45.225178  9080 solver.cpp:237]     Train net output #1: loss = 0.364109 (* 1 = 0.364109 loss)
I0923 21:09:45.225178  9080 sgd_solver.cpp:105] Iteration 23200, lr = 1e-05
I0923 21:09:47.967233  9080 solver.cpp:218] Iteration 23300 (36.4775 iter/s, 2.74142s/100 iters), loss = 0.500227
I0923 21:09:47.967233  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:09:47.967233  9080 solver.cpp:237]     Train net output #1: loss = 0.500227 (* 1 = 0.500227 loss)
I0923 21:09:47.967233  9080 sgd_solver.cpp:105] Iteration 23300, lr = 1e-05
I0923 21:09:50.735077  9080 solver.cpp:218] Iteration 23400 (36.1244 iter/s, 2.76821s/100 iters), loss = 0.398177
I0923 21:09:50.736083  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:09:50.736083  9080 solver.cpp:237]     Train net output #1: loss = 0.398177 (* 1 = 0.398177 loss)
I0923 21:09:50.736083  9080 sgd_solver.cpp:105] Iteration 23400, lr = 1e-05
I0923 21:09:53.424849 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:09:53.562948  9080 solver.cpp:218] Iteration 23500 (35.3795 iter/s, 2.8265s/100 iters), loss = 0.472559
I0923 21:09:53.562948  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:09:53.562948  9080 solver.cpp:237]     Train net output #1: loss = 0.472559 (* 1 = 0.472559 loss)
I0923 21:09:53.562948  9080 sgd_solver.cpp:105] Iteration 23500, lr = 1e-05
I0923 21:09:56.388489  9080 solver.cpp:218] Iteration 23600 (35.3947 iter/s, 2.82528s/100 iters), loss = 0.473897
I0923 21:09:56.388489  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0923 21:09:56.388489  9080 solver.cpp:237]     Train net output #1: loss = 0.473897 (* 1 = 0.473897 loss)
I0923 21:09:56.388489  9080 sgd_solver.cpp:105] Iteration 23600, lr = 1e-05
I0923 21:09:59.120813  9080 solver.cpp:218] Iteration 23700 (36.5973 iter/s, 2.73244s/100 iters), loss = 0.364872
I0923 21:09:59.120813  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:09:59.120813  9080 solver.cpp:237]     Train net output #1: loss = 0.364872 (* 1 = 0.364872 loss)
I0923 21:09:59.120813  9080 sgd_solver.cpp:105] Iteration 23700, lr = 1e-05
I0923 21:10:01.885113  9080 solver.cpp:218] Iteration 23800 (36.183 iter/s, 2.76373s/100 iters), loss = 0.456687
I0923 21:10:01.885113  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:10:01.885113  9080 solver.cpp:237]     Train net output #1: loss = 0.456687 (* 1 = 0.456687 loss)
I0923 21:10:01.885113  9080 sgd_solver.cpp:105] Iteration 23800, lr = 1e-05
I0923 21:10:04.617772  9080 solver.cpp:218] Iteration 23900 (36.5976 iter/s, 2.73242s/100 iters), loss = 0.381348
I0923 21:10:04.617772  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:10:04.617772  9080 solver.cpp:237]     Train net output #1: loss = 0.381348 (* 1 = 0.381348 loss)
I0923 21:10:04.617772  9080 sgd_solver.cpp:105] Iteration 23900, lr = 1e-05
I0923 21:10:07.209903 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:10:07.317006  9080 solver.cpp:330] Iteration 24000, Testing net (#0)
I0923 21:10:07.317006  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:10:07.831516  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:10:07.851514  9080 solver.cpp:397]     Test net output #0: accuracy = 0.786
I0923 21:10:07.851514  9080 solver.cpp:397]     Test net output #1: loss = 0.624161 (* 1 = 0.624161 loss)
I0923 21:10:07.876574  9080 solver.cpp:218] Iteration 24000 (30.6858 iter/s, 3.25884s/100 iters), loss = 0.47714
I0923 21:10:07.876574  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:10:07.876574  9080 solver.cpp:237]     Train net output #1: loss = 0.47714 (* 1 = 0.47714 loss)
I0923 21:10:07.876574  9080 sgd_solver.cpp:105] Iteration 24000, lr = 1e-05
I0923 21:10:10.594107  9080 solver.cpp:218] Iteration 24100 (36.814 iter/s, 2.71636s/100 iters), loss = 0.41902
I0923 21:10:10.594107  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:10:10.594107  9080 solver.cpp:237]     Train net output #1: loss = 0.41902 (* 1 = 0.41902 loss)
I0923 21:10:10.594107  9080 sgd_solver.cpp:105] Iteration 24100, lr = 1e-05
I0923 21:10:13.329761  9080 solver.cpp:218] Iteration 24200 (36.5576 iter/s, 2.73541s/100 iters), loss = 0.405132
I0923 21:10:13.329761  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0923 21:10:13.329761  9080 solver.cpp:237]     Train net output #1: loss = 0.405132 (* 1 = 0.405132 loss)
I0923 21:10:13.329761  9080 sgd_solver.cpp:105] Iteration 24200, lr = 1e-05
I0923 21:10:16.144502  9080 solver.cpp:218] Iteration 24300 (35.5198 iter/s, 2.81533s/100 iters), loss = 0.495494
I0923 21:10:16.145503  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:10:16.145503  9080 solver.cpp:237]     Train net output #1: loss = 0.495494 (* 1 = 0.495494 loss)
I0923 21:10:16.145503  9080 sgd_solver.cpp:105] Iteration 24300, lr = 1e-05
I0923 21:10:18.951637  9080 solver.cpp:218] Iteration 24400 (35.6337 iter/s, 2.80633s/100 iters), loss = 0.364506
I0923 21:10:18.951637  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0923 21:10:18.951637  9080 solver.cpp:237]     Train net output #1: loss = 0.364506 (* 1 = 0.364506 loss)
I0923 21:10:18.951637  9080 sgd_solver.cpp:105] Iteration 24400, lr = 1e-05
I0923 21:10:21.567067 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:10:21.703809  9080 solver.cpp:218] Iteration 24500 (36.3379 iter/s, 2.75195s/100 iters), loss = 0.454976
I0923 21:10:21.703809  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:10:21.703809  9080 solver.cpp:237]     Train net output #1: loss = 0.454976 (* 1 = 0.454976 loss)
I0923 21:10:21.703809  9080 sgd_solver.cpp:105] Iteration 24500, lr = 1e-05
I0923 21:10:24.515663  9080 solver.cpp:218] Iteration 24600 (35.5734 iter/s, 2.81109s/100 iters), loss = 0.415779
I0923 21:10:24.515663  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0923 21:10:24.515663  9080 solver.cpp:237]     Train net output #1: loss = 0.415779 (* 1 = 0.415779 loss)
I0923 21:10:24.515663  9080 sgd_solver.cpp:105] Iteration 24600, lr = 1e-05
I0923 21:10:27.301375  9080 solver.cpp:218] Iteration 24700 (35.8982 iter/s, 2.78566s/100 iters), loss = 0.412829
I0923 21:10:27.301375  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:10:27.301375  9080 solver.cpp:237]     Train net output #1: loss = 0.412829 (* 1 = 0.412829 loss)
I0923 21:10:27.301375  9080 sgd_solver.cpp:105] Iteration 24700, lr = 1e-05
I0923 21:10:30.084918  9080 solver.cpp:218] Iteration 24800 (35.941 iter/s, 2.78234s/100 iters), loss = 0.450945
I0923 21:10:30.084918  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:10:30.084918  9080 solver.cpp:237]     Train net output #1: loss = 0.450945 (* 1 = 0.450945 loss)
I0923 21:10:30.084918  9080 sgd_solver.cpp:105] Iteration 24800, lr = 1e-05
I0923 21:10:32.893585  9080 solver.cpp:218] Iteration 24900 (35.6038 iter/s, 2.80869s/100 iters), loss = 0.416026
I0923 21:10:32.893585  9080 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0923 21:10:32.893585  9080 solver.cpp:237]     Train net output #1: loss = 0.416026 (* 1 = 0.416026 loss)
I0923 21:10:32.894085  9080 sgd_solver.cpp:105] Iteration 24900, lr = 1e-05
I0923 21:10:35.522605 11752 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:10:35.629710  9080 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/slimnet_simpnet_nogroupcon_iter_25000.caffemodel
I0923 21:10:35.637715  9080 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_simpnet_nogroupcon_iter_25000.solverstate
I0923 21:10:35.644716  9080 solver.cpp:310] Iteration 25000, loss = 0.520533
I0923 21:10:35.644716  9080 solver.cpp:330] Iteration 25000, Testing net (#0)
I0923 21:10:35.644716  9080 net.cpp:676] Ignoring source layer accuracy_training
I0923 21:10:36.160719  6276 data_layer.cpp:73] Restarting data prefetching from start.
I0923 21:10:36.180733  9080 solver.cpp:397]     Test net output #0: accuracy = 0.786
I0923 21:10:36.180733  9080 solver.cpp:397]     Test net output #1: loss = 0.624084 (* 1 = 0.624084 loss)
I0923 21:10:36.180733  9080 solver.cpp:315] Optimization Done.
I0923 21:10:36.181717  9080 caffe.cpp:260] Optimization Done.

G:\Caffe>pause
Press any key to continue . . . 
