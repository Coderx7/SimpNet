
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I1123 17:03:59.914578 26520 caffe.cpp:219] Using GPUs 0
I1123 17:04:00.071617 26520 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1123 17:04:00.375336 26520 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1123 17:04:00.391858 26520 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 30000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 5000
stepvalue: 9500
stepvalue: 15300
stepvalue: 19500
stepvalue: 22000
stepvalue: 27000
type: "AdaDelta"
I1123 17:04:00.392357 26520 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1123 17:04:00.392858 26520 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1123 17:04:00.392858 26520 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1123 17:04:00.392858 26520 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1123 17:04:00.392858 26520 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1123 17:04:00.392858 26520 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1123 17:04:00.392858 26520 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1123 17:04:00.392858 26520 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1123 17:04:00.392858 26520 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1123 17:04:00.392858 26520 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1123 17:04:00.393357 26520 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1123 17:04:00.393357 26520 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1123 17:04:00.393357 26520 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1123 17:04:00.393357 26520 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_8L_Simple_NoGrpCon_NoDrp_300k_7x7_first2layers"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb_zeropad"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 35
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 38
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 65
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 65
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 65
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 65
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 74
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 75
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1123 17:04:00.398845 26520 layer_factory.cpp:58] Creating layer cifar
I1123 17:04:00.405858 26520 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb_zeropad
I1123 17:04:00.405858 26520 net.cpp:84] Creating Layer cifar
I1123 17:04:00.405858 26520 net.cpp:380] cifar -> data
I1123 17:04:00.405858 26520 net.cpp:380] cifar -> label
I1123 17:04:00.406859 26520 data_layer.cpp:45] output data size: 100,3,32,32
I1123 17:04:00.412878 26520 net.cpp:122] Setting up cifar
I1123 17:04:00.412878 26520 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1123 17:04:00.412878 26520 net.cpp:129] Top shape: 100 (100)
I1123 17:04:00.412878 26520 net.cpp:137] Memory required for data: 1229200
I1123 17:04:00.412878 26520 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1123 17:04:00.412878 26520 net.cpp:84] Creating Layer label_cifar_1_split
I1123 17:04:00.412878 26520 net.cpp:406] label_cifar_1_split <- label
I1123 17:04:00.412878 26520 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1123 17:04:00.412878 26520 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1123 17:04:00.412878 26520 net.cpp:122] Setting up label_cifar_1_split
I1123 17:04:00.412878 26520 net.cpp:129] Top shape: 100 (100)
I1123 17:04:00.412878 26520 net.cpp:129] Top shape: 100 (100)
I1123 17:04:00.412878 26520 net.cpp:137] Memory required for data: 1230000
I1123 17:04:00.412878 26520 layer_factory.cpp:58] Creating layer conv1
I1123 17:04:00.412878 26520 net.cpp:84] Creating Layer conv1
I1123 17:04:00.412878 26520 net.cpp:406] conv1 <- data
I1123 17:04:00.412878 26520 net.cpp:380] conv1 -> conv1
I1123 17:04:00.414861  6556 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1123 17:04:00.656466 26520 net.cpp:122] Setting up conv1
I1123 17:04:00.656466 26520 net.cpp:129] Top shape: 100 35 32 32 (3584000)
I1123 17:04:00.656466 26520 net.cpp:137] Memory required for data: 15566000
I1123 17:04:00.656466 26520 layer_factory.cpp:58] Creating layer bn1
I1123 17:04:00.656466 26520 net.cpp:84] Creating Layer bn1
I1123 17:04:00.656466 26520 net.cpp:406] bn1 <- conv1
I1123 17:04:00.656466 26520 net.cpp:367] bn1 -> conv1 (in-place)
I1123 17:04:00.657466 26520 net.cpp:122] Setting up bn1
I1123 17:04:00.657466 26520 net.cpp:129] Top shape: 100 35 32 32 (3584000)
I1123 17:04:00.657466 26520 net.cpp:137] Memory required for data: 29902000
I1123 17:04:00.657466 26520 layer_factory.cpp:58] Creating layer scale1
I1123 17:04:00.657466 26520 net.cpp:84] Creating Layer scale1
I1123 17:04:00.657466 26520 net.cpp:406] scale1 <- conv1
I1123 17:04:00.657466 26520 net.cpp:367] scale1 -> conv1 (in-place)
I1123 17:04:00.657466 26520 layer_factory.cpp:58] Creating layer scale1
I1123 17:04:00.657466 26520 net.cpp:122] Setting up scale1
I1123 17:04:00.657466 26520 net.cpp:129] Top shape: 100 35 32 32 (3584000)
I1123 17:04:00.657466 26520 net.cpp:137] Memory required for data: 44238000
I1123 17:04:00.657466 26520 layer_factory.cpp:58] Creating layer relu1
I1123 17:04:00.657466 26520 net.cpp:84] Creating Layer relu1
I1123 17:04:00.657466 26520 net.cpp:406] relu1 <- conv1
I1123 17:04:00.657466 26520 net.cpp:367] relu1 -> conv1 (in-place)
I1123 17:04:00.657466 26520 net.cpp:122] Setting up relu1
I1123 17:04:00.657466 26520 net.cpp:129] Top shape: 100 35 32 32 (3584000)
I1123 17:04:00.657466 26520 net.cpp:137] Memory required for data: 58574000
I1123 17:04:00.657466 26520 layer_factory.cpp:58] Creating layer conv2
I1123 17:04:00.657466 26520 net.cpp:84] Creating Layer conv2
I1123 17:04:00.657466 26520 net.cpp:406] conv2 <- conv1
I1123 17:04:00.657466 26520 net.cpp:380] conv2 -> conv2
I1123 17:04:00.659466 26520 net.cpp:122] Setting up conv2
I1123 17:04:00.659466 26520 net.cpp:129] Top shape: 100 38 32 32 (3891200)
I1123 17:04:00.659466 26520 net.cpp:137] Memory required for data: 74138800
I1123 17:04:00.659466 26520 layer_factory.cpp:58] Creating layer bn2
I1123 17:04:00.659466 26520 net.cpp:84] Creating Layer bn2
I1123 17:04:00.659466 26520 net.cpp:406] bn2 <- conv2
I1123 17:04:00.659466 26520 net.cpp:367] bn2 -> conv2 (in-place)
I1123 17:04:00.660465 26520 net.cpp:122] Setting up bn2
I1123 17:04:00.660465 26520 net.cpp:129] Top shape: 100 38 32 32 (3891200)
I1123 17:04:00.660465 26520 net.cpp:137] Memory required for data: 89703600
I1123 17:04:00.660465 26520 layer_factory.cpp:58] Creating layer scale2
I1123 17:04:00.660465 26520 net.cpp:84] Creating Layer scale2
I1123 17:04:00.660465 26520 net.cpp:406] scale2 <- conv2
I1123 17:04:00.660465 26520 net.cpp:367] scale2 -> conv2 (in-place)
I1123 17:04:00.660465 26520 layer_factory.cpp:58] Creating layer scale2
I1123 17:04:00.660465 26520 net.cpp:122] Setting up scale2
I1123 17:04:00.660465 26520 net.cpp:129] Top shape: 100 38 32 32 (3891200)
I1123 17:04:00.660465 26520 net.cpp:137] Memory required for data: 105268400
I1123 17:04:00.660465 26520 layer_factory.cpp:58] Creating layer relu2
I1123 17:04:00.660465 26520 net.cpp:84] Creating Layer relu2
I1123 17:04:00.660465 26520 net.cpp:406] relu2 <- conv2
I1123 17:04:00.660465 26520 net.cpp:367] relu2 -> conv2 (in-place)
I1123 17:04:00.660465 26520 net.cpp:122] Setting up relu2
I1123 17:04:00.660465 26520 net.cpp:129] Top shape: 100 38 32 32 (3891200)
I1123 17:04:00.660465 26520 net.cpp:137] Memory required for data: 120833200
I1123 17:04:00.660465 26520 layer_factory.cpp:58] Creating layer conv2_2
I1123 17:04:00.660465 26520 net.cpp:84] Creating Layer conv2_2
I1123 17:04:00.660465 26520 net.cpp:406] conv2_2 <- conv2
I1123 17:04:00.660465 26520 net.cpp:380] conv2_2 -> conv2_2
I1123 17:04:00.661466 26520 net.cpp:122] Setting up conv2_2
I1123 17:04:00.661466 26520 net.cpp:129] Top shape: 100 65 32 32 (6656000)
I1123 17:04:00.661466 26520 net.cpp:137] Memory required for data: 147457200
I1123 17:04:00.661466 26520 layer_factory.cpp:58] Creating layer bn2_2
I1123 17:04:00.661466 26520 net.cpp:84] Creating Layer bn2_2
I1123 17:04:00.661466 26520 net.cpp:406] bn2_2 <- conv2_2
I1123 17:04:00.661466 26520 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1123 17:04:00.662467 26520 net.cpp:122] Setting up bn2_2
I1123 17:04:00.662467 26520 net.cpp:129] Top shape: 100 65 32 32 (6656000)
I1123 17:04:00.662467 26520 net.cpp:137] Memory required for data: 174081200
I1123 17:04:00.662467 26520 layer_factory.cpp:58] Creating layer scale2_2
I1123 17:04:00.662467 26520 net.cpp:84] Creating Layer scale2_2
I1123 17:04:00.662467 26520 net.cpp:406] scale2_2 <- conv2_2
I1123 17:04:00.662467 26520 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1123 17:04:00.662467 26520 layer_factory.cpp:58] Creating layer scale2_2
I1123 17:04:00.662467 26520 net.cpp:122] Setting up scale2_2
I1123 17:04:00.662467 26520 net.cpp:129] Top shape: 100 65 32 32 (6656000)
I1123 17:04:00.662467 26520 net.cpp:137] Memory required for data: 200705200
I1123 17:04:00.662467 26520 layer_factory.cpp:58] Creating layer relu2_2
I1123 17:04:00.662467 26520 net.cpp:84] Creating Layer relu2_2
I1123 17:04:00.662467 26520 net.cpp:406] relu2_2 <- conv2_2
I1123 17:04:00.662467 26520 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1123 17:04:00.662467 26520 net.cpp:122] Setting up relu2_2
I1123 17:04:00.662467 26520 net.cpp:129] Top shape: 100 65 32 32 (6656000)
I1123 17:04:00.662467 26520 net.cpp:137] Memory required for data: 227329200
I1123 17:04:00.662467 26520 layer_factory.cpp:58] Creating layer pool2_1
I1123 17:04:00.662467 26520 net.cpp:84] Creating Layer pool2_1
I1123 17:04:00.662467 26520 net.cpp:406] pool2_1 <- conv2_2
I1123 17:04:00.662467 26520 net.cpp:380] pool2_1 -> pool2_1
I1123 17:04:00.662467 26520 net.cpp:122] Setting up pool2_1
I1123 17:04:00.662467 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.662467 26520 net.cpp:137] Memory required for data: 233985200
I1123 17:04:00.662467 26520 layer_factory.cpp:58] Creating layer conv3
I1123 17:04:00.662467 26520 net.cpp:84] Creating Layer conv3
I1123 17:04:00.662467 26520 net.cpp:406] conv3 <- pool2_1
I1123 17:04:00.662467 26520 net.cpp:380] conv3 -> conv3
I1123 17:04:00.664466 26520 net.cpp:122] Setting up conv3
I1123 17:04:00.664466 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.664466 26520 net.cpp:137] Memory required for data: 240641200
I1123 17:04:00.664466 26520 layer_factory.cpp:58] Creating layer bn3
I1123 17:04:00.664466 26520 net.cpp:84] Creating Layer bn3
I1123 17:04:00.664466 26520 net.cpp:406] bn3 <- conv3
I1123 17:04:00.664466 26520 net.cpp:367] bn3 -> conv3 (in-place)
I1123 17:04:00.664466 26520 net.cpp:122] Setting up bn3
I1123 17:04:00.664466 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.664466 26520 net.cpp:137] Memory required for data: 247297200
I1123 17:04:00.664466 26520 layer_factory.cpp:58] Creating layer scale3
I1123 17:04:00.664466 26520 net.cpp:84] Creating Layer scale3
I1123 17:04:00.664466 26520 net.cpp:406] scale3 <- conv3
I1123 17:04:00.664466 26520 net.cpp:367] scale3 -> conv3 (in-place)
I1123 17:04:00.664466 26520 layer_factory.cpp:58] Creating layer scale3
I1123 17:04:00.664466 26520 net.cpp:122] Setting up scale3
I1123 17:04:00.664466 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.664466 26520 net.cpp:137] Memory required for data: 253953200
I1123 17:04:00.664466 26520 layer_factory.cpp:58] Creating layer relu3
I1123 17:04:00.664466 26520 net.cpp:84] Creating Layer relu3
I1123 17:04:00.664466 26520 net.cpp:406] relu3 <- conv3
I1123 17:04:00.664466 26520 net.cpp:367] relu3 -> conv3 (in-place)
I1123 17:04:00.664466 26520 net.cpp:122] Setting up relu3
I1123 17:04:00.664466 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.664466 26520 net.cpp:137] Memory required for data: 260609200
I1123 17:04:00.664466 26520 layer_factory.cpp:58] Creating layer conv4
I1123 17:04:00.664466 26520 net.cpp:84] Creating Layer conv4
I1123 17:04:00.664466 26520 net.cpp:406] conv4 <- conv3
I1123 17:04:00.664466 26520 net.cpp:380] conv4 -> conv4
I1123 17:04:00.666466 26520 net.cpp:122] Setting up conv4
I1123 17:04:00.666466 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.666466 26520 net.cpp:137] Memory required for data: 267265200
I1123 17:04:00.666466 26520 layer_factory.cpp:58] Creating layer bn4
I1123 17:04:00.666466 26520 net.cpp:84] Creating Layer bn4
I1123 17:04:00.666466 26520 net.cpp:406] bn4 <- conv4
I1123 17:04:00.666466 26520 net.cpp:367] bn4 -> conv4 (in-place)
I1123 17:04:00.666466 26520 net.cpp:122] Setting up bn4
I1123 17:04:00.666466 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.666466 26520 net.cpp:137] Memory required for data: 273921200
I1123 17:04:00.666466 26520 layer_factory.cpp:58] Creating layer scale4
I1123 17:04:00.666466 26520 net.cpp:84] Creating Layer scale4
I1123 17:04:00.666466 26520 net.cpp:406] scale4 <- conv4
I1123 17:04:00.666466 26520 net.cpp:367] scale4 -> conv4 (in-place)
I1123 17:04:00.666466 26520 layer_factory.cpp:58] Creating layer scale4
I1123 17:04:00.666466 26520 net.cpp:122] Setting up scale4
I1123 17:04:00.666466 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.666466 26520 net.cpp:137] Memory required for data: 280577200
I1123 17:04:00.666466 26520 layer_factory.cpp:58] Creating layer relu4
I1123 17:04:00.666466 26520 net.cpp:84] Creating Layer relu4
I1123 17:04:00.666466 26520 net.cpp:406] relu4 <- conv4
I1123 17:04:00.666466 26520 net.cpp:367] relu4 -> conv4 (in-place)
I1123 17:04:00.667484 26520 net.cpp:122] Setting up relu4
I1123 17:04:00.667484 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.667484 26520 net.cpp:137] Memory required for data: 287233200
I1123 17:04:00.667484 26520 layer_factory.cpp:58] Creating layer conv4_1
I1123 17:04:00.667484 26520 net.cpp:84] Creating Layer conv4_1
I1123 17:04:00.667484 26520 net.cpp:406] conv4_1 <- conv4
I1123 17:04:00.667484 26520 net.cpp:380] conv4_1 -> conv4_1
I1123 17:04:00.668484 26520 net.cpp:122] Setting up conv4_1
I1123 17:04:00.668484 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.668484 26520 net.cpp:137] Memory required for data: 293889200
I1123 17:04:00.668484 26520 layer_factory.cpp:58] Creating layer bn4_1
I1123 17:04:00.668484 26520 net.cpp:84] Creating Layer bn4_1
I1123 17:04:00.668484 26520 net.cpp:406] bn4_1 <- conv4_1
I1123 17:04:00.668484 26520 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1123 17:04:00.668484 26520 net.cpp:122] Setting up bn4_1
I1123 17:04:00.668484 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.668484 26520 net.cpp:137] Memory required for data: 300545200
I1123 17:04:00.668484 26520 layer_factory.cpp:58] Creating layer scale4_1
I1123 17:04:00.668484 26520 net.cpp:84] Creating Layer scale4_1
I1123 17:04:00.668484 26520 net.cpp:406] scale4_1 <- conv4_1
I1123 17:04:00.668484 26520 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1123 17:04:00.668484 26520 layer_factory.cpp:58] Creating layer scale4_1
I1123 17:04:00.668484 26520 net.cpp:122] Setting up scale4_1
I1123 17:04:00.668484 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.668484 26520 net.cpp:137] Memory required for data: 307201200
I1123 17:04:00.668484 26520 layer_factory.cpp:58] Creating layer relu4_1
I1123 17:04:00.668484 26520 net.cpp:84] Creating Layer relu4_1
I1123 17:04:00.669484 26520 net.cpp:406] relu4_1 <- conv4_1
I1123 17:04:00.669484 26520 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1123 17:04:00.669484 26520 net.cpp:122] Setting up relu4_1
I1123 17:04:00.669484 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.669484 26520 net.cpp:137] Memory required for data: 313857200
I1123 17:04:00.669484 26520 layer_factory.cpp:58] Creating layer conv4_2
I1123 17:04:00.669484 26520 net.cpp:84] Creating Layer conv4_2
I1123 17:04:00.669484 26520 net.cpp:406] conv4_2 <- conv4_1
I1123 17:04:00.669484 26520 net.cpp:380] conv4_2 -> conv4_2
I1123 17:04:00.670469 26520 net.cpp:122] Setting up conv4_2
I1123 17:04:00.670469 26520 net.cpp:129] Top shape: 100 74 16 16 (1894400)
I1123 17:04:00.670469 26520 net.cpp:137] Memory required for data: 321434800
I1123 17:04:00.671469 26520 layer_factory.cpp:58] Creating layer bn4_2
I1123 17:04:00.671469 26520 net.cpp:84] Creating Layer bn4_2
I1123 17:04:00.671469 26520 net.cpp:406] bn4_2 <- conv4_2
I1123 17:04:00.671469 26520 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1123 17:04:00.671469 26520 net.cpp:122] Setting up bn4_2
I1123 17:04:00.671469 26520 net.cpp:129] Top shape: 100 74 16 16 (1894400)
I1123 17:04:00.671469 26520 net.cpp:137] Memory required for data: 329012400
I1123 17:04:00.671469 26520 layer_factory.cpp:58] Creating layer scale4_2
I1123 17:04:00.671469 26520 net.cpp:84] Creating Layer scale4_2
I1123 17:04:00.671469 26520 net.cpp:406] scale4_2 <- conv4_2
I1123 17:04:00.671469 26520 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1123 17:04:00.671469 26520 layer_factory.cpp:58] Creating layer scale4_2
I1123 17:04:00.671469 26520 net.cpp:122] Setting up scale4_2
I1123 17:04:00.671469 26520 net.cpp:129] Top shape: 100 74 16 16 (1894400)
I1123 17:04:00.671469 26520 net.cpp:137] Memory required for data: 336590000
I1123 17:04:00.671469 26520 layer_factory.cpp:58] Creating layer relu4_2
I1123 17:04:00.671469 26520 net.cpp:84] Creating Layer relu4_2
I1123 17:04:00.671469 26520 net.cpp:406] relu4_2 <- conv4_2
I1123 17:04:00.671469 26520 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1123 17:04:00.671469 26520 net.cpp:122] Setting up relu4_2
I1123 17:04:00.671469 26520 net.cpp:129] Top shape: 100 74 16 16 (1894400)
I1123 17:04:00.671469 26520 net.cpp:137] Memory required for data: 344167600
I1123 17:04:00.671469 26520 layer_factory.cpp:58] Creating layer pool4_2
I1123 17:04:00.671469 26520 net.cpp:84] Creating Layer pool4_2
I1123 17:04:00.671469 26520 net.cpp:406] pool4_2 <- conv4_2
I1123 17:04:00.671469 26520 net.cpp:380] pool4_2 -> pool4_2
I1123 17:04:00.671469 26520 net.cpp:122] Setting up pool4_2
I1123 17:04:00.671469 26520 net.cpp:129] Top shape: 100 74 8 8 (473600)
I1123 17:04:00.671469 26520 net.cpp:137] Memory required for data: 346062000
I1123 17:04:00.671469 26520 layer_factory.cpp:58] Creating layer conv12
I1123 17:04:00.671469 26520 net.cpp:84] Creating Layer conv12
I1123 17:04:00.671469 26520 net.cpp:406] conv12 <- pool4_2
I1123 17:04:00.671469 26520 net.cpp:380] conv12 -> conv12
I1123 17:04:00.673468 26520 net.cpp:122] Setting up conv12
I1123 17:04:00.673468 26520 net.cpp:129] Top shape: 100 75 8 8 (480000)
I1123 17:04:00.673468 26520 net.cpp:137] Memory required for data: 347982000
I1123 17:04:00.673468 26520 layer_factory.cpp:58] Creating layer bn_conv12
I1123 17:04:00.673468 26520 net.cpp:84] Creating Layer bn_conv12
I1123 17:04:00.673468 26520 net.cpp:406] bn_conv12 <- conv12
I1123 17:04:00.673468 26520 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1123 17:04:00.673468 26520 net.cpp:122] Setting up bn_conv12
I1123 17:04:00.673468 26520 net.cpp:129] Top shape: 100 75 8 8 (480000)
I1123 17:04:00.673468 26520 net.cpp:137] Memory required for data: 349902000
I1123 17:04:00.673468 26520 layer_factory.cpp:58] Creating layer scale_conv12
I1123 17:04:00.673468 26520 net.cpp:84] Creating Layer scale_conv12
I1123 17:04:00.673468 26520 net.cpp:406] scale_conv12 <- conv12
I1123 17:04:00.673468 26520 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1123 17:04:00.673468 26520 layer_factory.cpp:58] Creating layer scale_conv12
I1123 17:04:00.673468 26520 net.cpp:122] Setting up scale_conv12
I1123 17:04:00.673468 26520 net.cpp:129] Top shape: 100 75 8 8 (480000)
I1123 17:04:00.673468 26520 net.cpp:137] Memory required for data: 351822000
I1123 17:04:00.673468 26520 layer_factory.cpp:58] Creating layer relu_conv12
I1123 17:04:00.673468 26520 net.cpp:84] Creating Layer relu_conv12
I1123 17:04:00.674468 26520 net.cpp:406] relu_conv12 <- conv12
I1123 17:04:00.674468 26520 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1123 17:04:00.674468 26520 net.cpp:122] Setting up relu_conv12
I1123 17:04:00.674468 26520 net.cpp:129] Top shape: 100 75 8 8 (480000)
I1123 17:04:00.674468 26520 net.cpp:137] Memory required for data: 353742000
I1123 17:04:00.674468 26520 layer_factory.cpp:58] Creating layer poolcp6
I1123 17:04:00.674468 26520 net.cpp:84] Creating Layer poolcp6
I1123 17:04:00.674468 26520 net.cpp:406] poolcp6 <- conv12
I1123 17:04:00.674468 26520 net.cpp:380] poolcp6 -> poolcp6
I1123 17:04:00.674468 26520 net.cpp:122] Setting up poolcp6
I1123 17:04:00.674468 26520 net.cpp:129] Top shape: 100 75 1 1 (7500)
I1123 17:04:00.674468 26520 net.cpp:137] Memory required for data: 353772000
I1123 17:04:00.674468 26520 layer_factory.cpp:58] Creating layer ip1
I1123 17:04:00.674468 26520 net.cpp:84] Creating Layer ip1
I1123 17:04:00.674468 26520 net.cpp:406] ip1 <- poolcp6
I1123 17:04:00.674468 26520 net.cpp:380] ip1 -> ip1
I1123 17:04:00.674468 26520 net.cpp:122] Setting up ip1
I1123 17:04:00.674468 26520 net.cpp:129] Top shape: 100 10 (1000)
I1123 17:04:00.674468 26520 net.cpp:137] Memory required for data: 353776000
I1123 17:04:00.674468 26520 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1123 17:04:00.674468 26520 net.cpp:84] Creating Layer ip1_ip1_0_split
I1123 17:04:00.674468 26520 net.cpp:406] ip1_ip1_0_split <- ip1
I1123 17:04:00.674468 26520 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1123 17:04:00.674468 26520 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1123 17:04:00.674468 26520 net.cpp:122] Setting up ip1_ip1_0_split
I1123 17:04:00.674468 26520 net.cpp:129] Top shape: 100 10 (1000)
I1123 17:04:00.674468 26520 net.cpp:129] Top shape: 100 10 (1000)
I1123 17:04:00.674468 26520 net.cpp:137] Memory required for data: 353784000
I1123 17:04:00.674468 26520 layer_factory.cpp:58] Creating layer accuracy_training
I1123 17:04:00.674468 26520 net.cpp:84] Creating Layer accuracy_training
I1123 17:04:00.674468 26520 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1123 17:04:00.674468 26520 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1123 17:04:00.674468 26520 net.cpp:380] accuracy_training -> accuracy_training
I1123 17:04:00.674468 26520 net.cpp:122] Setting up accuracy_training
I1123 17:04:00.674468 26520 net.cpp:129] Top shape: (1)
I1123 17:04:00.674468 26520 net.cpp:137] Memory required for data: 353784004
I1123 17:04:00.674468 26520 layer_factory.cpp:58] Creating layer loss
I1123 17:04:00.674468 26520 net.cpp:84] Creating Layer loss
I1123 17:04:00.674468 26520 net.cpp:406] loss <- ip1_ip1_0_split_1
I1123 17:04:00.674468 26520 net.cpp:406] loss <- label_cifar_1_split_1
I1123 17:04:00.674468 26520 net.cpp:380] loss -> loss
I1123 17:04:00.674468 26520 layer_factory.cpp:58] Creating layer loss
I1123 17:04:00.675468 26520 net.cpp:122] Setting up loss
I1123 17:04:00.675468 26520 net.cpp:129] Top shape: (1)
I1123 17:04:00.675468 26520 net.cpp:132]     with loss weight 1
I1123 17:04:00.675468 26520 net.cpp:137] Memory required for data: 353784008
I1123 17:04:00.675468 26520 net.cpp:198] loss needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:200] accuracy_training does not need backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] ip1 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] poolcp6 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] relu_conv12 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] scale_conv12 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] bn_conv12 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] conv12 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] pool4_2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] relu4_2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] scale4_2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] bn4_2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] conv4_2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] relu4_1 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] scale4_1 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] bn4_1 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] conv4_1 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] relu4 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] scale4 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] bn4 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] conv4 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] relu3 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] scale3 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] bn3 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] conv3 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] pool2_1 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] relu2_2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] scale2_2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] bn2_2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] conv2_2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] relu2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] scale2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] bn2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] conv2 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] relu1 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] scale1 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] bn1 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:198] conv1 needs backward computation.
I1123 17:04:00.675468 26520 net.cpp:200] label_cifar_1_split does not need backward computation.
I1123 17:04:00.675468 26520 net.cpp:200] cifar does not need backward computation.
I1123 17:04:00.675468 26520 net.cpp:242] This network produces output accuracy_training
I1123 17:04:00.675468 26520 net.cpp:242] This network produces output loss
I1123 17:04:00.675468 26520 net.cpp:255] Network initialization done.
I1123 17:04:00.676468 26520 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1123 17:04:00.676468 26520 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1123 17:04:00.676468 26520 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1123 17:04:00.676468 26520 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1123 17:04:00.676468 26520 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1123 17:04:00.676468 26520 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1123 17:04:00.676468 26520 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1123 17:04:00.676468 26520 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1123 17:04:00.676468 26520 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1123 17:04:00.676468 26520 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1123 17:04:00.676468 26520 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1123 17:04:00.676468 26520 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1123 17:04:00.676468 26520 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1123 17:04:00.676468 26520 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_8L_Simple_NoGrpCon_NoDrp_300k_7x7_first2layers"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb_zeropad"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 35
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 38
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 65
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 65
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 65
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 65
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 74
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 75
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1123 17:04:00.676468 26520 layer_factory.cpp:58] Creating layer cifar
I1123 17:04:00.683467 26520 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb_zeropad
I1123 17:04:00.683467 26520 net.cpp:84] Creating Layer cifar
I1123 17:04:00.683467 26520 net.cpp:380] cifar -> data
I1123 17:04:00.683467 26520 net.cpp:380] cifar -> label
I1123 17:04:00.683467 26520 data_layer.cpp:45] output data size: 100,3,32,32
I1123 17:04:00.689474 26520 net.cpp:122] Setting up cifar
I1123 17:04:00.689474 26520 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1123 17:04:00.689474 26520 net.cpp:129] Top shape: 100 (100)
I1123 17:04:00.690466 26520 net.cpp:137] Memory required for data: 1229200
I1123 17:04:00.690466 26520 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1123 17:04:00.690466 26520 net.cpp:84] Creating Layer label_cifar_1_split
I1123 17:04:00.690466 26520 net.cpp:406] label_cifar_1_split <- label
I1123 17:04:00.690466 26520 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1123 17:04:00.690466 26520 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1123 17:04:00.690466 26520 net.cpp:122] Setting up label_cifar_1_split
I1123 17:04:00.690466 26520 net.cpp:129] Top shape: 100 (100)
I1123 17:04:00.690466 26520 net.cpp:129] Top shape: 100 (100)
I1123 17:04:00.690466 26520 net.cpp:137] Memory required for data: 1230000
I1123 17:04:00.690466 26520 layer_factory.cpp:58] Creating layer conv1
I1123 17:04:00.690466 26520 net.cpp:84] Creating Layer conv1
I1123 17:04:00.690466 26520 net.cpp:406] conv1 <- data
I1123 17:04:00.690466 26520 net.cpp:380] conv1 -> conv1
I1123 17:04:00.692478 26520 net.cpp:122] Setting up conv1
I1123 17:04:00.692478 26520 net.cpp:129] Top shape: 100 35 32 32 (3584000)
I1123 17:04:00.692478 26520 net.cpp:137] Memory required for data: 15566000
I1123 17:04:00.692478 26520 layer_factory.cpp:58] Creating layer bn1
I1123 17:04:00.692478 14276 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1123 17:04:00.692478 26520 net.cpp:84] Creating Layer bn1
I1123 17:04:00.692478 26520 net.cpp:406] bn1 <- conv1
I1123 17:04:00.692478 26520 net.cpp:367] bn1 -> conv1 (in-place)
I1123 17:04:00.692979 26520 net.cpp:122] Setting up bn1
I1123 17:04:00.692979 26520 net.cpp:129] Top shape: 100 35 32 32 (3584000)
I1123 17:04:00.692979 26520 net.cpp:137] Memory required for data: 29902000
I1123 17:04:00.692979 26520 layer_factory.cpp:58] Creating layer scale1
I1123 17:04:00.692979 26520 net.cpp:84] Creating Layer scale1
I1123 17:04:00.692979 26520 net.cpp:406] scale1 <- conv1
I1123 17:04:00.692979 26520 net.cpp:367] scale1 -> conv1 (in-place)
I1123 17:04:00.692979 26520 layer_factory.cpp:58] Creating layer scale1
I1123 17:04:00.693480 26520 net.cpp:122] Setting up scale1
I1123 17:04:00.693480 26520 net.cpp:129] Top shape: 100 35 32 32 (3584000)
I1123 17:04:00.693480 26520 net.cpp:137] Memory required for data: 44238000
I1123 17:04:00.693480 26520 layer_factory.cpp:58] Creating layer relu1
I1123 17:04:00.693480 26520 net.cpp:84] Creating Layer relu1
I1123 17:04:00.693480 26520 net.cpp:406] relu1 <- conv1
I1123 17:04:00.693480 26520 net.cpp:367] relu1 -> conv1 (in-place)
I1123 17:04:00.693976 26520 net.cpp:122] Setting up relu1
I1123 17:04:00.693976 26520 net.cpp:129] Top shape: 100 35 32 32 (3584000)
I1123 17:04:00.693976 26520 net.cpp:137] Memory required for data: 58574000
I1123 17:04:00.693976 26520 layer_factory.cpp:58] Creating layer conv2
I1123 17:04:00.694479 26520 net.cpp:84] Creating Layer conv2
I1123 17:04:00.694479 26520 net.cpp:406] conv2 <- conv1
I1123 17:04:00.694479 26520 net.cpp:380] conv2 -> conv2
I1123 17:04:00.696478 26520 net.cpp:122] Setting up conv2
I1123 17:04:00.696478 26520 net.cpp:129] Top shape: 100 38 32 32 (3891200)
I1123 17:04:00.696478 26520 net.cpp:137] Memory required for data: 74138800
I1123 17:04:00.696478 26520 layer_factory.cpp:58] Creating layer bn2
I1123 17:04:00.696478 26520 net.cpp:84] Creating Layer bn2
I1123 17:04:00.696478 26520 net.cpp:406] bn2 <- conv2
I1123 17:04:00.696478 26520 net.cpp:367] bn2 -> conv2 (in-place)
I1123 17:04:00.696975 26520 net.cpp:122] Setting up bn2
I1123 17:04:00.696975 26520 net.cpp:129] Top shape: 100 38 32 32 (3891200)
I1123 17:04:00.696975 26520 net.cpp:137] Memory required for data: 89703600
I1123 17:04:00.696975 26520 layer_factory.cpp:58] Creating layer scale2
I1123 17:04:00.696975 26520 net.cpp:84] Creating Layer scale2
I1123 17:04:00.696975 26520 net.cpp:406] scale2 <- conv2
I1123 17:04:00.696975 26520 net.cpp:367] scale2 -> conv2 (in-place)
I1123 17:04:00.696975 26520 layer_factory.cpp:58] Creating layer scale2
I1123 17:04:00.696975 26520 net.cpp:122] Setting up scale2
I1123 17:04:00.696975 26520 net.cpp:129] Top shape: 100 38 32 32 (3891200)
I1123 17:04:00.697475 26520 net.cpp:137] Memory required for data: 105268400
I1123 17:04:00.697475 26520 layer_factory.cpp:58] Creating layer relu2
I1123 17:04:00.697475 26520 net.cpp:84] Creating Layer relu2
I1123 17:04:00.697475 26520 net.cpp:406] relu2 <- conv2
I1123 17:04:00.697475 26520 net.cpp:367] relu2 -> conv2 (in-place)
I1123 17:04:00.697978 26520 net.cpp:122] Setting up relu2
I1123 17:04:00.697978 26520 net.cpp:129] Top shape: 100 38 32 32 (3891200)
I1123 17:04:00.697978 26520 net.cpp:137] Memory required for data: 120833200
I1123 17:04:00.697978 26520 layer_factory.cpp:58] Creating layer conv2_2
I1123 17:04:00.697978 26520 net.cpp:84] Creating Layer conv2_2
I1123 17:04:00.697978 26520 net.cpp:406] conv2_2 <- conv2
I1123 17:04:00.697978 26520 net.cpp:380] conv2_2 -> conv2_2
I1123 17:04:00.700479 26520 net.cpp:122] Setting up conv2_2
I1123 17:04:00.700479 26520 net.cpp:129] Top shape: 100 65 32 32 (6656000)
I1123 17:04:00.700479 26520 net.cpp:137] Memory required for data: 147457200
I1123 17:04:00.700479 26520 layer_factory.cpp:58] Creating layer bn2_2
I1123 17:04:00.700479 26520 net.cpp:84] Creating Layer bn2_2
I1123 17:04:00.700479 26520 net.cpp:406] bn2_2 <- conv2_2
I1123 17:04:00.700479 26520 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1123 17:04:00.700479 26520 net.cpp:122] Setting up bn2_2
I1123 17:04:00.700479 26520 net.cpp:129] Top shape: 100 65 32 32 (6656000)
I1123 17:04:00.700479 26520 net.cpp:137] Memory required for data: 174081200
I1123 17:04:00.700479 26520 layer_factory.cpp:58] Creating layer scale2_2
I1123 17:04:00.700479 26520 net.cpp:84] Creating Layer scale2_2
I1123 17:04:00.700479 26520 net.cpp:406] scale2_2 <- conv2_2
I1123 17:04:00.700479 26520 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1123 17:04:00.700994 26520 layer_factory.cpp:58] Creating layer scale2_2
I1123 17:04:00.700994 26520 net.cpp:122] Setting up scale2_2
I1123 17:04:00.700994 26520 net.cpp:129] Top shape: 100 65 32 32 (6656000)
I1123 17:04:00.700994 26520 net.cpp:137] Memory required for data: 200705200
I1123 17:04:00.700994 26520 layer_factory.cpp:58] Creating layer relu2_2
I1123 17:04:00.700994 26520 net.cpp:84] Creating Layer relu2_2
I1123 17:04:00.700994 26520 net.cpp:406] relu2_2 <- conv2_2
I1123 17:04:00.700994 26520 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1123 17:04:00.701490 26520 net.cpp:122] Setting up relu2_2
I1123 17:04:00.701490 26520 net.cpp:129] Top shape: 100 65 32 32 (6656000)
I1123 17:04:00.701490 26520 net.cpp:137] Memory required for data: 227329200
I1123 17:04:00.701490 26520 layer_factory.cpp:58] Creating layer pool2_1
I1123 17:04:00.701490 26520 net.cpp:84] Creating Layer pool2_1
I1123 17:04:00.701490 26520 net.cpp:406] pool2_1 <- conv2_2
I1123 17:04:00.701490 26520 net.cpp:380] pool2_1 -> pool2_1
I1123 17:04:00.701490 26520 net.cpp:122] Setting up pool2_1
I1123 17:04:00.701490 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.701490 26520 net.cpp:137] Memory required for data: 233985200
I1123 17:04:00.701490 26520 layer_factory.cpp:58] Creating layer conv3
I1123 17:04:00.701490 26520 net.cpp:84] Creating Layer conv3
I1123 17:04:00.701490 26520 net.cpp:406] conv3 <- pool2_1
I1123 17:04:00.701490 26520 net.cpp:380] conv3 -> conv3
I1123 17:04:00.703975 26520 net.cpp:122] Setting up conv3
I1123 17:04:00.703975 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.703975 26520 net.cpp:137] Memory required for data: 240641200
I1123 17:04:00.703975 26520 layer_factory.cpp:58] Creating layer bn3
I1123 17:04:00.703975 26520 net.cpp:84] Creating Layer bn3
I1123 17:04:00.703975 26520 net.cpp:406] bn3 <- conv3
I1123 17:04:00.703975 26520 net.cpp:367] bn3 -> conv3 (in-place)
I1123 17:04:00.703975 26520 net.cpp:122] Setting up bn3
I1123 17:04:00.703975 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.703975 26520 net.cpp:137] Memory required for data: 247297200
I1123 17:04:00.703975 26520 layer_factory.cpp:58] Creating layer scale3
I1123 17:04:00.703975 26520 net.cpp:84] Creating Layer scale3
I1123 17:04:00.703975 26520 net.cpp:406] scale3 <- conv3
I1123 17:04:00.704478 26520 net.cpp:367] scale3 -> conv3 (in-place)
I1123 17:04:00.704478 26520 layer_factory.cpp:58] Creating layer scale3
I1123 17:04:00.704478 26520 net.cpp:122] Setting up scale3
I1123 17:04:00.704478 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.704478 26520 net.cpp:137] Memory required for data: 253953200
I1123 17:04:00.704478 26520 layer_factory.cpp:58] Creating layer relu3
I1123 17:04:00.704478 26520 net.cpp:84] Creating Layer relu3
I1123 17:04:00.704478 26520 net.cpp:406] relu3 <- conv3
I1123 17:04:00.704478 26520 net.cpp:367] relu3 -> conv3 (in-place)
I1123 17:04:00.704478 26520 net.cpp:122] Setting up relu3
I1123 17:04:00.704478 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.704977 26520 net.cpp:137] Memory required for data: 260609200
I1123 17:04:00.704977 26520 layer_factory.cpp:58] Creating layer conv4
I1123 17:04:00.704977 26520 net.cpp:84] Creating Layer conv4
I1123 17:04:00.704977 26520 net.cpp:406] conv4 <- conv3
I1123 17:04:00.704977 26520 net.cpp:380] conv4 -> conv4
I1123 17:04:00.706478 26520 net.cpp:122] Setting up conv4
I1123 17:04:00.706478 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.706478 26520 net.cpp:137] Memory required for data: 267265200
I1123 17:04:00.706478 26520 layer_factory.cpp:58] Creating layer bn4
I1123 17:04:00.706478 26520 net.cpp:84] Creating Layer bn4
I1123 17:04:00.706478 26520 net.cpp:406] bn4 <- conv4
I1123 17:04:00.706478 26520 net.cpp:367] bn4 -> conv4 (in-place)
I1123 17:04:00.706980 26520 net.cpp:122] Setting up bn4
I1123 17:04:00.706980 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.706980 26520 net.cpp:137] Memory required for data: 273921200
I1123 17:04:00.706980 26520 layer_factory.cpp:58] Creating layer scale4
I1123 17:04:00.706980 26520 net.cpp:84] Creating Layer scale4
I1123 17:04:00.706980 26520 net.cpp:406] scale4 <- conv4
I1123 17:04:00.706980 26520 net.cpp:367] scale4 -> conv4 (in-place)
I1123 17:04:00.706980 26520 layer_factory.cpp:58] Creating layer scale4
I1123 17:04:00.706980 26520 net.cpp:122] Setting up scale4
I1123 17:04:00.706980 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.706980 26520 net.cpp:137] Memory required for data: 280577200
I1123 17:04:00.706980 26520 layer_factory.cpp:58] Creating layer relu4
I1123 17:04:00.706980 26520 net.cpp:84] Creating Layer relu4
I1123 17:04:00.706980 26520 net.cpp:406] relu4 <- conv4
I1123 17:04:00.706980 26520 net.cpp:367] relu4 -> conv4 (in-place)
I1123 17:04:00.706980 26520 net.cpp:122] Setting up relu4
I1123 17:04:00.706980 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.706980 26520 net.cpp:137] Memory required for data: 287233200
I1123 17:04:00.706980 26520 layer_factory.cpp:58] Creating layer conv4_1
I1123 17:04:00.706980 26520 net.cpp:84] Creating Layer conv4_1
I1123 17:04:00.706980 26520 net.cpp:406] conv4_1 <- conv4
I1123 17:04:00.706980 26520 net.cpp:380] conv4_1 -> conv4_1
I1123 17:04:00.708983 26520 net.cpp:122] Setting up conv4_1
I1123 17:04:00.708983 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.708983 26520 net.cpp:137] Memory required for data: 293889200
I1123 17:04:00.708983 26520 layer_factory.cpp:58] Creating layer bn4_1
I1123 17:04:00.708983 26520 net.cpp:84] Creating Layer bn4_1
I1123 17:04:00.708983 26520 net.cpp:406] bn4_1 <- conv4_1
I1123 17:04:00.708983 26520 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1123 17:04:00.708983 26520 net.cpp:122] Setting up bn4_1
I1123 17:04:00.708983 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.708983 26520 net.cpp:137] Memory required for data: 300545200
I1123 17:04:00.708983 26520 layer_factory.cpp:58] Creating layer scale4_1
I1123 17:04:00.708983 26520 net.cpp:84] Creating Layer scale4_1
I1123 17:04:00.708983 26520 net.cpp:406] scale4_1 <- conv4_1
I1123 17:04:00.708983 26520 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1123 17:04:00.708983 26520 layer_factory.cpp:58] Creating layer scale4_1
I1123 17:04:00.708983 26520 net.cpp:122] Setting up scale4_1
I1123 17:04:00.709983 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.709983 26520 net.cpp:137] Memory required for data: 307201200
I1123 17:04:00.709983 26520 layer_factory.cpp:58] Creating layer relu4_1
I1123 17:04:00.709983 26520 net.cpp:84] Creating Layer relu4_1
I1123 17:04:00.709983 26520 net.cpp:406] relu4_1 <- conv4_1
I1123 17:04:00.709983 26520 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1123 17:04:00.709983 26520 net.cpp:122] Setting up relu4_1
I1123 17:04:00.709983 26520 net.cpp:129] Top shape: 100 65 16 16 (1664000)
I1123 17:04:00.709983 26520 net.cpp:137] Memory required for data: 313857200
I1123 17:04:00.709983 26520 layer_factory.cpp:58] Creating layer conv4_2
I1123 17:04:00.709983 26520 net.cpp:84] Creating Layer conv4_2
I1123 17:04:00.709983 26520 net.cpp:406] conv4_2 <- conv4_1
I1123 17:04:00.709983 26520 net.cpp:380] conv4_2 -> conv4_2
I1123 17:04:00.712982 26520 net.cpp:122] Setting up conv4_2
I1123 17:04:00.712982 26520 net.cpp:129] Top shape: 100 74 16 16 (1894400)
I1123 17:04:00.712982 26520 net.cpp:137] Memory required for data: 321434800
I1123 17:04:00.712982 26520 layer_factory.cpp:58] Creating layer bn4_2
I1123 17:04:00.712982 26520 net.cpp:84] Creating Layer bn4_2
I1123 17:04:00.712982 26520 net.cpp:406] bn4_2 <- conv4_2
I1123 17:04:00.712982 26520 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1123 17:04:00.712982 26520 net.cpp:122] Setting up bn4_2
I1123 17:04:00.712982 26520 net.cpp:129] Top shape: 100 74 16 16 (1894400)
I1123 17:04:00.712982 26520 net.cpp:137] Memory required for data: 329012400
I1123 17:04:00.712982 26520 layer_factory.cpp:58] Creating layer scale4_2
I1123 17:04:00.712982 26520 net.cpp:84] Creating Layer scale4_2
I1123 17:04:00.712982 26520 net.cpp:406] scale4_2 <- conv4_2
I1123 17:04:00.712982 26520 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1123 17:04:00.712982 26520 layer_factory.cpp:58] Creating layer scale4_2
I1123 17:04:00.712982 26520 net.cpp:122] Setting up scale4_2
I1123 17:04:00.712982 26520 net.cpp:129] Top shape: 100 74 16 16 (1894400)
I1123 17:04:00.712982 26520 net.cpp:137] Memory required for data: 336590000
I1123 17:04:00.712982 26520 layer_factory.cpp:58] Creating layer relu4_2
I1123 17:04:00.712982 26520 net.cpp:84] Creating Layer relu4_2
I1123 17:04:00.712982 26520 net.cpp:406] relu4_2 <- conv4_2
I1123 17:04:00.712982 26520 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1123 17:04:00.713982 26520 net.cpp:122] Setting up relu4_2
I1123 17:04:00.713982 26520 net.cpp:129] Top shape: 100 74 16 16 (1894400)
I1123 17:04:00.713982 26520 net.cpp:137] Memory required for data: 344167600
I1123 17:04:00.713982 26520 layer_factory.cpp:58] Creating layer pool4_2
I1123 17:04:00.713982 26520 net.cpp:84] Creating Layer pool4_2
I1123 17:04:00.713982 26520 net.cpp:406] pool4_2 <- conv4_2
I1123 17:04:00.713982 26520 net.cpp:380] pool4_2 -> pool4_2
I1123 17:04:00.713982 26520 net.cpp:122] Setting up pool4_2
I1123 17:04:00.713982 26520 net.cpp:129] Top shape: 100 74 8 8 (473600)
I1123 17:04:00.713982 26520 net.cpp:137] Memory required for data: 346062000
I1123 17:04:00.713982 26520 layer_factory.cpp:58] Creating layer conv12
I1123 17:04:00.713982 26520 net.cpp:84] Creating Layer conv12
I1123 17:04:00.713982 26520 net.cpp:406] conv12 <- pool4_2
I1123 17:04:00.713982 26520 net.cpp:380] conv12 -> conv12
I1123 17:04:00.714983 26520 net.cpp:122] Setting up conv12
I1123 17:04:00.714983 26520 net.cpp:129] Top shape: 100 75 8 8 (480000)
I1123 17:04:00.714983 26520 net.cpp:137] Memory required for data: 347982000
I1123 17:04:00.714983 26520 layer_factory.cpp:58] Creating layer bn_conv12
I1123 17:04:00.714983 26520 net.cpp:84] Creating Layer bn_conv12
I1123 17:04:00.714983 26520 net.cpp:406] bn_conv12 <- conv12
I1123 17:04:00.714983 26520 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1123 17:04:00.714983 26520 net.cpp:122] Setting up bn_conv12
I1123 17:04:00.714983 26520 net.cpp:129] Top shape: 100 75 8 8 (480000)
I1123 17:04:00.714983 26520 net.cpp:137] Memory required for data: 349902000
I1123 17:04:00.714983 26520 layer_factory.cpp:58] Creating layer scale_conv12
I1123 17:04:00.714983 26520 net.cpp:84] Creating Layer scale_conv12
I1123 17:04:00.715983 26520 net.cpp:406] scale_conv12 <- conv12
I1123 17:04:00.715983 26520 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1123 17:04:00.715983 26520 layer_factory.cpp:58] Creating layer scale_conv12
I1123 17:04:00.715983 26520 net.cpp:122] Setting up scale_conv12
I1123 17:04:00.715983 26520 net.cpp:129] Top shape: 100 75 8 8 (480000)
I1123 17:04:00.715983 26520 net.cpp:137] Memory required for data: 351822000
I1123 17:04:00.715983 26520 layer_factory.cpp:58] Creating layer relu_conv12
I1123 17:04:00.715983 26520 net.cpp:84] Creating Layer relu_conv12
I1123 17:04:00.715983 26520 net.cpp:406] relu_conv12 <- conv12
I1123 17:04:00.715983 26520 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1123 17:04:00.715983 26520 net.cpp:122] Setting up relu_conv12
I1123 17:04:00.715983 26520 net.cpp:129] Top shape: 100 75 8 8 (480000)
I1123 17:04:00.715983 26520 net.cpp:137] Memory required for data: 353742000
I1123 17:04:00.715983 26520 layer_factory.cpp:58] Creating layer poolcp6
I1123 17:04:00.715983 26520 net.cpp:84] Creating Layer poolcp6
I1123 17:04:00.715983 26520 net.cpp:406] poolcp6 <- conv12
I1123 17:04:00.715983 26520 net.cpp:380] poolcp6 -> poolcp6
I1123 17:04:00.715983 26520 net.cpp:122] Setting up poolcp6
I1123 17:04:00.715983 26520 net.cpp:129] Top shape: 100 75 1 1 (7500)
I1123 17:04:00.715983 26520 net.cpp:137] Memory required for data: 353772000
I1123 17:04:00.715983 26520 layer_factory.cpp:58] Creating layer ip1
I1123 17:04:00.715983 26520 net.cpp:84] Creating Layer ip1
I1123 17:04:00.715983 26520 net.cpp:406] ip1 <- poolcp6
I1123 17:04:00.715983 26520 net.cpp:380] ip1 -> ip1
I1123 17:04:00.716982 26520 net.cpp:122] Setting up ip1
I1123 17:04:00.716982 26520 net.cpp:129] Top shape: 100 10 (1000)
I1123 17:04:00.716982 26520 net.cpp:137] Memory required for data: 353776000
I1123 17:04:00.716982 26520 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1123 17:04:00.716982 26520 net.cpp:84] Creating Layer ip1_ip1_0_split
I1123 17:04:00.716982 26520 net.cpp:406] ip1_ip1_0_split <- ip1
I1123 17:04:00.716982 26520 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1123 17:04:00.716982 26520 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1123 17:04:00.716982 26520 net.cpp:122] Setting up ip1_ip1_0_split
I1123 17:04:00.716982 26520 net.cpp:129] Top shape: 100 10 (1000)
I1123 17:04:00.716982 26520 net.cpp:129] Top shape: 100 10 (1000)
I1123 17:04:00.716982 26520 net.cpp:137] Memory required for data: 353784000
I1123 17:04:00.716982 26520 layer_factory.cpp:58] Creating layer accuracy
I1123 17:04:00.716982 26520 net.cpp:84] Creating Layer accuracy
I1123 17:04:00.716982 26520 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1123 17:04:00.716982 26520 net.cpp:406] accuracy <- label_cifar_1_split_0
I1123 17:04:00.716982 26520 net.cpp:380] accuracy -> accuracy
I1123 17:04:00.716982 26520 net.cpp:122] Setting up accuracy
I1123 17:04:00.716982 26520 net.cpp:129] Top shape: (1)
I1123 17:04:00.716982 26520 net.cpp:137] Memory required for data: 353784004
I1123 17:04:00.716982 26520 layer_factory.cpp:58] Creating layer loss
I1123 17:04:00.716982 26520 net.cpp:84] Creating Layer loss
I1123 17:04:00.716982 26520 net.cpp:406] loss <- ip1_ip1_0_split_1
I1123 17:04:00.716982 26520 net.cpp:406] loss <- label_cifar_1_split_1
I1123 17:04:00.716982 26520 net.cpp:380] loss -> loss
I1123 17:04:00.716982 26520 layer_factory.cpp:58] Creating layer loss
I1123 17:04:00.716982 26520 net.cpp:122] Setting up loss
I1123 17:04:00.716982 26520 net.cpp:129] Top shape: (1)
I1123 17:04:00.716982 26520 net.cpp:132]     with loss weight 1
I1123 17:04:00.716982 26520 net.cpp:137] Memory required for data: 353784008
I1123 17:04:00.716982 26520 net.cpp:198] loss needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:200] accuracy does not need backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] ip1 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] poolcp6 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] relu_conv12 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] scale_conv12 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] bn_conv12 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] conv12 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] pool4_2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] relu4_2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] scale4_2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] bn4_2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] conv4_2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] relu4_1 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] scale4_1 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] bn4_1 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] conv4_1 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] relu4 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] scale4 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] bn4 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] conv4 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] relu3 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] scale3 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] bn3 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] conv3 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] pool2_1 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] relu2_2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] scale2_2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] bn2_2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] conv2_2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] relu2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] scale2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] bn2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] conv2 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] relu1 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] scale1 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] bn1 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:198] conv1 needs backward computation.
I1123 17:04:00.716982 26520 net.cpp:200] label_cifar_1_split does not need backward computation.
I1123 17:04:00.716982 26520 net.cpp:200] cifar does not need backward computation.
I1123 17:04:00.716982 26520 net.cpp:242] This network produces output accuracy
I1123 17:04:00.716982 26520 net.cpp:242] This network produces output loss
I1123 17:04:00.716982 26520 net.cpp:255] Network initialization done.
I1123 17:04:00.717983 26520 solver.cpp:56] Solver scaffolding done.
I1123 17:04:00.719982 26520 caffe.cpp:249] Starting Optimization
I1123 17:04:00.719982 26520 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_8L_Simple_NoGrpCon_NoDrp_300k_7x7_first2layers
I1123 17:04:00.719982 26520 solver.cpp:273] Learning Rate Policy: multistep
I1123 17:04:00.721993 26520 solver.cpp:330] Iteration 0, Testing net (#0)
I1123 17:04:00.722982 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:04:02.027806 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:04:02.076804 26520 solver.cpp:397]     Test net output #0: accuracy = 0.1018
I1123 17:04:02.076804 26520 solver.cpp:397]     Test net output #1: loss = 78.4457 (* 1 = 78.4457 loss)
I1123 17:04:02.154461 26520 solver.cpp:218] Iteration 0 (0 iter/s, 1.43425s/100 iters), loss = 3.46642
I1123 17:04:02.154461 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.03
I1123 17:04:02.154461 26520 solver.cpp:237]     Train net output #1: loss = 3.46642 (* 1 = 3.46642 loss)
I1123 17:04:02.154461 26520 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1123 17:04:06.923720 26520 solver.cpp:218] Iteration 100 (20.9697 iter/s, 4.76879s/100 iters), loss = 1.7864
I1123 17:04:06.923720 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I1123 17:04:06.923720 26520 solver.cpp:237]     Train net output #1: loss = 1.7864 (* 1 = 1.7864 loss)
I1123 17:04:06.923720 26520 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1123 17:04:11.689609 26520 solver.cpp:218] Iteration 200 (20.9836 iter/s, 4.76564s/100 iters), loss = 1.73103
I1123 17:04:11.689609 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1123 17:04:11.689609 26520 solver.cpp:237]     Train net output #1: loss = 1.73103 (* 1 = 1.73103 loss)
I1123 17:04:11.689609 26520 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1123 17:04:16.468899 26520 solver.cpp:218] Iteration 300 (20.9258 iter/s, 4.77879s/100 iters), loss = 1.41151
I1123 17:04:16.468899 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1123 17:04:16.468899 26520 solver.cpp:237]     Train net output #1: loss = 1.41151 (* 1 = 1.41151 loss)
I1123 17:04:16.468899 26520 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1123 17:04:21.265427 26520 solver.cpp:218] Iteration 400 (20.8514 iter/s, 4.79583s/100 iters), loss = 1.40695
I1123 17:04:21.265427 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1123 17:04:21.265427 26520 solver.cpp:237]     Train net output #1: loss = 1.40695 (* 1 = 1.40695 loss)
I1123 17:04:21.265427 26520 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1123 17:04:25.817719  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:04:26.005807 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_500.caffemodel
I1123 17:04:26.019273 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_500.solverstate
I1123 17:04:26.023443 26520 solver.cpp:330] Iteration 500, Testing net (#0)
I1123 17:04:26.023443 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:04:27.281708 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:04:27.331734 26520 solver.cpp:397]     Test net output #0: accuracy = 0.4697
I1123 17:04:27.331734 26520 solver.cpp:397]     Test net output #1: loss = 1.47814 (* 1 = 1.47814 loss)
I1123 17:04:27.377748 26520 solver.cpp:218] Iteration 500 (16.3608 iter/s, 6.11219s/100 iters), loss = 1.41313
I1123 17:04:27.377748 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1123 17:04:27.377748 26520 solver.cpp:237]     Train net output #1: loss = 1.41313 (* 1 = 1.41313 loss)
I1123 17:04:27.377748 26520 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1123 17:04:32.170274 26520 solver.cpp:218] Iteration 600 (20.8663 iter/s, 4.79241s/100 iters), loss = 1.27006
I1123 17:04:32.171274 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1123 17:04:32.171274 26520 solver.cpp:237]     Train net output #1: loss = 1.27006 (* 1 = 1.27006 loss)
I1123 17:04:32.171274 26520 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1123 17:04:36.969341 26520 solver.cpp:218] Iteration 700 (20.8428 iter/s, 4.79781s/100 iters), loss = 1.09302
I1123 17:04:36.969341 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1123 17:04:36.969341 26520 solver.cpp:237]     Train net output #1: loss = 1.09302 (* 1 = 1.09302 loss)
I1123 17:04:36.969341 26520 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1123 17:04:41.766005 26520 solver.cpp:218] Iteration 800 (20.8509 iter/s, 4.79595s/100 iters), loss = 0.96403
I1123 17:04:41.766005 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1123 17:04:41.766005 26520 solver.cpp:237]     Train net output #1: loss = 0.96403 (* 1 = 0.96403 loss)
I1123 17:04:41.766005 26520 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1123 17:04:46.561236 26520 solver.cpp:218] Iteration 900 (20.8526 iter/s, 4.79556s/100 iters), loss = 1.03844
I1123 17:04:46.561236 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1123 17:04:46.561236 26520 solver.cpp:237]     Train net output #1: loss = 1.03844 (* 1 = 1.03844 loss)
I1123 17:04:46.561236 26520 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1123 17:04:51.123071  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:04:51.312117 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_1000.caffemodel
I1123 17:04:51.322118 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_1000.solverstate
I1123 17:04:51.326119 26520 solver.cpp:330] Iteration 1000, Testing net (#0)
I1123 17:04:51.326119 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:04:52.589396 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:04:52.639922 26520 solver.cpp:397]     Test net output #0: accuracy = 0.5976
I1123 17:04:52.639922 26520 solver.cpp:397]     Test net output #1: loss = 1.17035 (* 1 = 1.17035 loss)
I1123 17:04:52.685930 26520 solver.cpp:218] Iteration 1000 (16.3287 iter/s, 6.12417s/100 iters), loss = 1.03566
I1123 17:04:52.685930 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1123 17:04:52.685930 26520 solver.cpp:237]     Train net output #1: loss = 1.03566 (* 1 = 1.03566 loss)
I1123 17:04:52.685930 26520 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1123 17:04:57.498841 26520 solver.cpp:218] Iteration 1100 (20.7805 iter/s, 4.81221s/100 iters), loss = 0.987899
I1123 17:04:57.498841 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1123 17:04:57.498841 26520 solver.cpp:237]     Train net output #1: loss = 0.987899 (* 1 = 0.987899 loss)
I1123 17:04:57.498841 26520 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1123 17:05:02.318277 26520 solver.cpp:218] Iteration 1200 (20.749 iter/s, 4.81951s/100 iters), loss = 0.955289
I1123 17:05:02.318277 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1123 17:05:02.318277 26520 solver.cpp:237]     Train net output #1: loss = 0.955289 (* 1 = 0.955289 loss)
I1123 17:05:02.318277 26520 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1123 17:05:07.135222 26520 solver.cpp:218] Iteration 1300 (20.7647 iter/s, 4.81586s/100 iters), loss = 0.811507
I1123 17:05:07.135222 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1123 17:05:07.135222 26520 solver.cpp:237]     Train net output #1: loss = 0.811507 (* 1 = 0.811507 loss)
I1123 17:05:07.135222 26520 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1123 17:05:11.953150 26520 solver.cpp:218] Iteration 1400 (20.7545 iter/s, 4.81823s/100 iters), loss = 0.880349
I1123 17:05:11.953150 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1123 17:05:11.953150 26520 solver.cpp:237]     Train net output #1: loss = 0.880349 (* 1 = 0.880349 loss)
I1123 17:05:11.953150 26520 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1123 17:05:16.521162  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:05:16.710724 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_1500.caffemodel
I1123 17:05:16.723242 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_1500.solverstate
I1123 17:05:16.727241 26520 solver.cpp:330] Iteration 1500, Testing net (#0)
I1123 17:05:16.727241 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:05:17.990512 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:05:18.041033 26520 solver.cpp:397]     Test net output #0: accuracy = 0.6301
I1123 17:05:18.041033 26520 solver.cpp:397]     Test net output #1: loss = 1.0038 (* 1 = 1.0038 loss)
I1123 17:05:18.088043 26520 solver.cpp:218] Iteration 1500 (16.3037 iter/s, 6.13359s/100 iters), loss = 0.77707
I1123 17:05:18.088043 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1123 17:05:18.088043 26520 solver.cpp:237]     Train net output #1: loss = 0.77707 (* 1 = 0.77707 loss)
I1123 17:05:18.088043 26520 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1123 17:05:22.887600 26520 solver.cpp:218] Iteration 1600 (20.8368 iter/s, 4.79919s/100 iters), loss = 0.791035
I1123 17:05:22.887600 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1123 17:05:22.887600 26520 solver.cpp:237]     Train net output #1: loss = 0.791035 (* 1 = 0.791035 loss)
I1123 17:05:22.887600 26520 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1123 17:05:27.684942 26520 solver.cpp:218] Iteration 1700 (20.8427 iter/s, 4.79785s/100 iters), loss = 0.711014
I1123 17:05:27.685947 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1123 17:05:27.685947 26520 solver.cpp:237]     Train net output #1: loss = 0.711014 (* 1 = 0.711014 loss)
I1123 17:05:27.685947 26520 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1123 17:05:32.500397 26520 solver.cpp:218] Iteration 1800 (20.7714 iter/s, 4.81431s/100 iters), loss = 0.750996
I1123 17:05:32.500397 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1123 17:05:32.500397 26520 solver.cpp:237]     Train net output #1: loss = 0.750996 (* 1 = 0.750996 loss)
I1123 17:05:32.500397 26520 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1123 17:05:37.306140 26520 solver.cpp:218] Iteration 1900 (20.8077 iter/s, 4.8059s/100 iters), loss = 0.735511
I1123 17:05:37.306140 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1123 17:05:37.306140 26520 solver.cpp:237]     Train net output #1: loss = 0.735511 (* 1 = 0.735511 loss)
I1123 17:05:37.306140 26520 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1123 17:05:41.871587  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:05:42.059734 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_2000.caffemodel
I1123 17:05:42.069725 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_2000.solverstate
I1123 17:05:42.073724 26520 solver.cpp:330] Iteration 2000, Testing net (#0)
I1123 17:05:42.073724 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:05:43.338480 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:05:43.388481 26520 solver.cpp:397]     Test net output #0: accuracy = 0.6083
I1123 17:05:43.388481 26520 solver.cpp:397]     Test net output #1: loss = 1.15203 (* 1 = 1.15203 loss)
I1123 17:05:43.434501 26520 solver.cpp:218] Iteration 2000 (16.3195 iter/s, 6.12765s/100 iters), loss = 0.671717
I1123 17:05:43.434501 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1123 17:05:43.434501 26520 solver.cpp:237]     Train net output #1: loss = 0.671717 (* 1 = 0.671717 loss)
I1123 17:05:43.434501 26520 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1123 17:05:48.243196 26520 solver.cpp:218] Iteration 2100 (20.7999 iter/s, 4.80771s/100 iters), loss = 0.700977
I1123 17:05:48.243196 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1123 17:05:48.243196 26520 solver.cpp:237]     Train net output #1: loss = 0.700977 (* 1 = 0.700977 loss)
I1123 17:05:48.243196 26520 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1123 17:05:53.040202 26520 solver.cpp:218] Iteration 2200 (20.8469 iter/s, 4.79687s/100 iters), loss = 0.672733
I1123 17:05:53.040202 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1123 17:05:53.040202 26520 solver.cpp:237]     Train net output #1: loss = 0.672733 (* 1 = 0.672733 loss)
I1123 17:05:53.040202 26520 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1123 17:05:57.837615 26520 solver.cpp:218] Iteration 2300 (20.8467 iter/s, 4.79692s/100 iters), loss = 0.80132
I1123 17:05:57.837615 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1123 17:05:57.837615 26520 solver.cpp:237]     Train net output #1: loss = 0.80132 (* 1 = 0.80132 loss)
I1123 17:05:57.837615 26520 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1123 17:06:02.633332 26520 solver.cpp:218] Iteration 2400 (20.8526 iter/s, 4.79556s/100 iters), loss = 0.678404
I1123 17:06:02.633837 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1123 17:06:02.633837 26520 solver.cpp:237]     Train net output #1: loss = 0.678404 (* 1 = 0.678404 loss)
I1123 17:06:02.633837 26520 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1123 17:06:07.193945  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:06:07.382700 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_2500.caffemodel
I1123 17:06:07.392685 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_2500.solverstate
I1123 17:06:07.396685 26520 solver.cpp:330] Iteration 2500, Testing net (#0)
I1123 17:06:07.396685 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:06:08.660795 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:06:08.710801 26520 solver.cpp:397]     Test net output #0: accuracy = 0.6812
I1123 17:06:08.710801 26520 solver.cpp:397]     Test net output #1: loss = 0.914536 (* 1 = 0.914536 loss)
I1123 17:06:08.757786 26520 solver.cpp:218] Iteration 2500 (16.3299 iter/s, 6.12375s/100 iters), loss = 0.621217
I1123 17:06:08.757786 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1123 17:06:08.757786 26520 solver.cpp:237]     Train net output #1: loss = 0.621217 (* 1 = 0.621217 loss)
I1123 17:06:08.757786 26520 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1123 17:06:13.554425 26520 solver.cpp:218] Iteration 2600 (20.8492 iter/s, 4.79634s/100 iters), loss = 0.638246
I1123 17:06:13.554425 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1123 17:06:13.554425 26520 solver.cpp:237]     Train net output #1: loss = 0.638246 (* 1 = 0.638246 loss)
I1123 17:06:13.554425 26520 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1123 17:06:18.348826 26520 solver.cpp:218] Iteration 2700 (20.8606 iter/s, 4.79373s/100 iters), loss = 0.581087
I1123 17:06:18.348826 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1123 17:06:18.348826 26520 solver.cpp:237]     Train net output #1: loss = 0.581087 (* 1 = 0.581087 loss)
I1123 17:06:18.348826 26520 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1123 17:06:23.144647 26520 solver.cpp:218] Iteration 2800 (20.853 iter/s, 4.79548s/100 iters), loss = 0.585929
I1123 17:06:23.144647 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1123 17:06:23.144647 26520 solver.cpp:237]     Train net output #1: loss = 0.585929 (* 1 = 0.585929 loss)
I1123 17:06:23.144647 26520 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1123 17:06:27.941686 26520 solver.cpp:218] Iteration 2900 (20.8444 iter/s, 4.79744s/100 iters), loss = 0.636892
I1123 17:06:27.942692 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1123 17:06:27.942692 26520 solver.cpp:237]     Train net output #1: loss = 0.636892 (* 1 = 0.636892 loss)
I1123 17:06:27.942692 26520 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1123 17:06:32.506505  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:06:32.695354 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_3000.caffemodel
I1123 17:06:32.705374 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_3000.solverstate
I1123 17:06:32.709374 26520 solver.cpp:330] Iteration 3000, Testing net (#0)
I1123 17:06:32.709374 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:06:33.973126 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:06:34.023123 26520 solver.cpp:397]     Test net output #0: accuracy = 0.7055
I1123 17:06:34.023123 26520 solver.cpp:397]     Test net output #1: loss = 0.833703 (* 1 = 0.833703 loss)
I1123 17:06:34.069658 26520 solver.cpp:218] Iteration 3000 (16.3217 iter/s, 6.12681s/100 iters), loss = 0.602249
I1123 17:06:34.069658 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1123 17:06:34.069658 26520 solver.cpp:237]     Train net output #1: loss = 0.602249 (* 1 = 0.602249 loss)
I1123 17:06:34.069658 26520 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1123 17:06:38.875737 26520 solver.cpp:218] Iteration 3100 (20.8088 iter/s, 4.80565s/100 iters), loss = 0.612442
I1123 17:06:38.875737 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1123 17:06:38.875737 26520 solver.cpp:237]     Train net output #1: loss = 0.612442 (* 1 = 0.612442 loss)
I1123 17:06:38.875737 26520 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1123 17:06:43.674868 26520 solver.cpp:218] Iteration 3200 (20.8387 iter/s, 4.79877s/100 iters), loss = 0.5793
I1123 17:06:43.674868 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1123 17:06:43.674868 26520 solver.cpp:237]     Train net output #1: loss = 0.5793 (* 1 = 0.5793 loss)
I1123 17:06:43.674868 26520 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1123 17:06:48.489030 26520 solver.cpp:218] Iteration 3300 (20.7754 iter/s, 4.81339s/100 iters), loss = 0.70354
I1123 17:06:48.489030 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1123 17:06:48.489030 26520 solver.cpp:237]     Train net output #1: loss = 0.70354 (* 1 = 0.70354 loss)
I1123 17:06:48.489030 26520 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1123 17:06:53.284710 26520 solver.cpp:218] Iteration 3400 (20.8505 iter/s, 4.79605s/100 iters), loss = 0.629903
I1123 17:06:53.284710 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1123 17:06:53.284710 26520 solver.cpp:237]     Train net output #1: loss = 0.629903 (* 1 = 0.629903 loss)
I1123 17:06:53.284710 26520 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1123 17:06:57.845890  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:06:58.034795 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_3500.caffemodel
I1123 17:06:58.045791 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_3500.solverstate
I1123 17:06:58.049808 26520 solver.cpp:330] Iteration 3500, Testing net (#0)
I1123 17:06:58.049808 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:06:59.311822 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:06:59.361826 26520 solver.cpp:397]     Test net output #0: accuracy = 0.6859
I1123 17:06:59.361826 26520 solver.cpp:397]     Test net output #1: loss = 0.931546 (* 1 = 0.931546 loss)
I1123 17:06:59.408334 26520 solver.cpp:218] Iteration 3500 (16.3321 iter/s, 6.12291s/100 iters), loss = 0.626677
I1123 17:06:59.408334 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1123 17:06:59.408334 26520 solver.cpp:237]     Train net output #1: loss = 0.626677 (* 1 = 0.626677 loss)
I1123 17:06:59.408334 26520 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1123 17:07:04.208359 26520 solver.cpp:218] Iteration 3600 (20.8359 iter/s, 4.79942s/100 iters), loss = 0.63055
I1123 17:07:04.208359 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1123 17:07:04.208359 26520 solver.cpp:237]     Train net output #1: loss = 0.63055 (* 1 = 0.63055 loss)
I1123 17:07:04.208359 26520 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1123 17:07:09.009219 26520 solver.cpp:218] Iteration 3700 (20.8317 iter/s, 4.80039s/100 iters), loss = 0.566983
I1123 17:07:09.009219 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1123 17:07:09.009219 26520 solver.cpp:237]     Train net output #1: loss = 0.566983 (* 1 = 0.566983 loss)
I1123 17:07:09.009219 26520 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1123 17:07:13.808593 26520 solver.cpp:218] Iteration 3800 (20.8372 iter/s, 4.79911s/100 iters), loss = 0.62483
I1123 17:07:13.808593 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1123 17:07:13.808593 26520 solver.cpp:237]     Train net output #1: loss = 0.62483 (* 1 = 0.62483 loss)
I1123 17:07:13.808593 26520 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1123 17:07:18.607842 26520 solver.cpp:218] Iteration 3900 (20.839 iter/s, 4.7987s/100 iters), loss = 0.759941
I1123 17:07:18.607842 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1123 17:07:18.607842 26520 solver.cpp:237]     Train net output #1: loss = 0.759941 (* 1 = 0.759941 loss)
I1123 17:07:18.607842 26520 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1123 17:07:23.167585  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:07:23.356180 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_4000.caffemodel
I1123 17:07:23.366178 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_4000.solverstate
I1123 17:07:23.370177 26520 solver.cpp:330] Iteration 4000, Testing net (#0)
I1123 17:07:23.370177 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:07:24.634981 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:07:24.684993 26520 solver.cpp:397]     Test net output #0: accuracy = 0.7339
I1123 17:07:24.684993 26520 solver.cpp:397]     Test net output #1: loss = 0.74521 (* 1 = 0.74521 loss)
I1123 17:07:24.731015 26520 solver.cpp:218] Iteration 4000 (16.3312 iter/s, 6.12325s/100 iters), loss = 0.525349
I1123 17:07:24.731015 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1123 17:07:24.731015 26520 solver.cpp:237]     Train net output #1: loss = 0.525349 (* 1 = 0.525349 loss)
I1123 17:07:24.731015 26520 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1123 17:07:29.536331 26520 solver.cpp:218] Iteration 4100 (20.8142 iter/s, 4.80441s/100 iters), loss = 0.607232
I1123 17:07:29.536331 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1123 17:07:29.536331 26520 solver.cpp:237]     Train net output #1: loss = 0.607232 (* 1 = 0.607232 loss)
I1123 17:07:29.536331 26520 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1123 17:07:34.334970 26520 solver.cpp:218] Iteration 4200 (20.8381 iter/s, 4.7989s/100 iters), loss = 0.704877
I1123 17:07:34.334970 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1123 17:07:34.334970 26520 solver.cpp:237]     Train net output #1: loss = 0.704877 (* 1 = 0.704877 loss)
I1123 17:07:34.334970 26520 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1123 17:07:39.167099 26520 solver.cpp:218] Iteration 4300 (20.6971 iter/s, 4.83159s/100 iters), loss = 0.616863
I1123 17:07:39.167099 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1123 17:07:39.167099 26520 solver.cpp:237]     Train net output #1: loss = 0.616863 (* 1 = 0.616863 loss)
I1123 17:07:39.167099 26520 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1123 17:07:43.969512 26520 solver.cpp:218] Iteration 4400 (20.8273 iter/s, 4.80139s/100 iters), loss = 0.520113
I1123 17:07:43.969512 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1123 17:07:43.969512 26520 solver.cpp:237]     Train net output #1: loss = 0.520113 (* 1 = 0.520113 loss)
I1123 17:07:43.969512 26520 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1123 17:07:48.531613  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:07:48.719816 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_4500.caffemodel
I1123 17:07:48.732833 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_4500.solverstate
I1123 17:07:48.736832 26520 solver.cpp:330] Iteration 4500, Testing net (#0)
I1123 17:07:48.736832 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:07:50.001214 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:07:50.050246 26520 solver.cpp:397]     Test net output #0: accuracy = 0.6346
I1123 17:07:50.050246 26520 solver.cpp:397]     Test net output #1: loss = 1.0606 (* 1 = 1.0606 loss)
I1123 17:07:50.097245 26520 solver.cpp:218] Iteration 4500 (16.3203 iter/s, 6.12734s/100 iters), loss = 0.529904
I1123 17:07:50.097245 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1123 17:07:50.097245 26520 solver.cpp:237]     Train net output #1: loss = 0.529904 (* 1 = 0.529904 loss)
I1123 17:07:50.097245 26520 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1123 17:07:54.884126 26520 solver.cpp:218] Iteration 4600 (20.8909 iter/s, 4.78678s/100 iters), loss = 0.452967
I1123 17:07:54.884626 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1123 17:07:54.884626 26520 solver.cpp:237]     Train net output #1: loss = 0.452967 (* 1 = 0.452967 loss)
I1123 17:07:54.884626 26520 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1123 17:07:59.667402 26520 solver.cpp:218] Iteration 4700 (20.9091 iter/s, 4.7826s/100 iters), loss = 0.644618
I1123 17:07:59.667402 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1123 17:07:59.667402 26520 solver.cpp:237]     Train net output #1: loss = 0.644618 (* 1 = 0.644618 loss)
I1123 17:07:59.667402 26520 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1123 17:08:04.461405 26520 solver.cpp:218] Iteration 4800 (20.8617 iter/s, 4.79348s/100 iters), loss = 0.551897
I1123 17:08:04.461405 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1123 17:08:04.461405 26520 solver.cpp:237]     Train net output #1: loss = 0.551897 (* 1 = 0.551897 loss)
I1123 17:08:04.461405 26520 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1123 17:08:09.255317 26520 solver.cpp:218] Iteration 4900 (20.8577 iter/s, 4.79439s/100 iters), loss = 0.544667
I1123 17:08:09.256315 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1123 17:08:09.256315 26520 solver.cpp:237]     Train net output #1: loss = 0.544667 (* 1 = 0.544667 loss)
I1123 17:08:09.256315 26520 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1123 17:08:13.814968  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:08:14.003440 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_5000.caffemodel
I1123 17:08:14.013454 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_5000.solverstate
I1123 17:08:14.017454 26520 solver.cpp:330] Iteration 5000, Testing net (#0)
I1123 17:08:14.017956 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:08:15.280300 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:08:15.330348 26520 solver.cpp:397]     Test net output #0: accuracy = 0.6746
I1123 17:08:15.330348 26520 solver.cpp:397]     Test net output #1: loss = 0.971081 (* 1 = 0.971081 loss)
I1123 17:08:15.377347 26520 solver.cpp:218] Iteration 5000 (16.3377 iter/s, 6.12081s/100 iters), loss = 0.536728
I1123 17:08:15.377347 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1123 17:08:15.377347 26520 solver.cpp:237]     Train net output #1: loss = 0.536728 (* 1 = 0.536728 loss)
I1123 17:08:15.377347 26520 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I1123 17:08:15.377347 26520 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1123 17:08:20.166133 26520 solver.cpp:218] Iteration 5100 (20.8825 iter/s, 4.78871s/100 iters), loss = 0.38556
I1123 17:08:20.166133 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1123 17:08:20.166133 26520 solver.cpp:237]     Train net output #1: loss = 0.38556 (* 1 = 0.38556 loss)
I1123 17:08:20.166133 26520 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1123 17:08:24.957470 26520 solver.cpp:218] Iteration 5200 (20.8741 iter/s, 4.79062s/100 iters), loss = 0.404866
I1123 17:08:24.957470 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1123 17:08:24.957470 26520 solver.cpp:237]     Train net output #1: loss = 0.404866 (* 1 = 0.404866 loss)
I1123 17:08:24.957470 26520 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1123 17:08:29.747668 26520 solver.cpp:218] Iteration 5300 (20.8745 iter/s, 4.79053s/100 iters), loss = 0.377894
I1123 17:08:29.747668 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1123 17:08:29.747668 26520 solver.cpp:237]     Train net output #1: loss = 0.377894 (* 1 = 0.377894 loss)
I1123 17:08:29.747668 26520 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1123 17:08:34.543782 26520 solver.cpp:218] Iteration 5400 (20.853 iter/s, 4.79548s/100 iters), loss = 0.363947
I1123 17:08:34.543782 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1123 17:08:34.543782 26520 solver.cpp:237]     Train net output #1: loss = 0.363947 (* 1 = 0.363947 loss)
I1123 17:08:34.543782 26520 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1123 17:08:39.102212  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:08:39.291267 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_5500.caffemodel
I1123 17:08:39.301292 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_5500.solverstate
I1123 17:08:39.305801 26520 solver.cpp:330] Iteration 5500, Testing net (#0)
I1123 17:08:39.305801 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:08:40.570897 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:08:40.620924 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8516
I1123 17:08:40.620924 26520 solver.cpp:397]     Test net output #1: loss = 0.431037 (* 1 = 0.431037 loss)
I1123 17:08:40.666929 26520 solver.cpp:218] Iteration 5500 (16.3327 iter/s, 6.1227s/100 iters), loss = 0.327976
I1123 17:08:40.666929 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:08:40.666929 26520 solver.cpp:237]     Train net output #1: loss = 0.327976 (* 1 = 0.327976 loss)
I1123 17:08:40.666929 26520 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1123 17:08:45.461365 26520 solver.cpp:218] Iteration 5600 (20.8591 iter/s, 4.79408s/100 iters), loss = 0.366979
I1123 17:08:45.461365 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1123 17:08:45.461365 26520 solver.cpp:237]     Train net output #1: loss = 0.366979 (* 1 = 0.366979 loss)
I1123 17:08:45.461365 26520 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1123 17:08:50.256671 26520 solver.cpp:218] Iteration 5700 (20.8579 iter/s, 4.79434s/100 iters), loss = 0.320546
I1123 17:08:50.256671 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1123 17:08:50.256671 26520 solver.cpp:237]     Train net output #1: loss = 0.320546 (* 1 = 0.320546 loss)
I1123 17:08:50.256671 26520 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1123 17:08:55.052734 26520 solver.cpp:218] Iteration 5800 (20.8492 iter/s, 4.79635s/100 iters), loss = 0.37872
I1123 17:08:55.052734 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1123 17:08:55.052734 26520 solver.cpp:237]     Train net output #1: loss = 0.37872 (* 1 = 0.37872 loss)
I1123 17:08:55.052734 26520 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1123 17:08:59.849617 26520 solver.cpp:218] Iteration 5900 (20.849 iter/s, 4.79639s/100 iters), loss = 0.378658
I1123 17:08:59.849617 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1123 17:08:59.849617 26520 solver.cpp:237]     Train net output #1: loss = 0.378658 (* 1 = 0.378658 loss)
I1123 17:08:59.849617 26520 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1123 17:09:04.411460  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:09:04.598394 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_6000.caffemodel
I1123 17:09:04.610378 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_6000.solverstate
I1123 17:09:04.614881 26520 solver.cpp:330] Iteration 6000, Testing net (#0)
I1123 17:09:04.614881 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:09:05.879076 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:09:05.928618 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8641
I1123 17:09:05.928618 26520 solver.cpp:397]     Test net output #1: loss = 0.401597 (* 1 = 0.401597 loss)
I1123 17:09:05.974118 26520 solver.cpp:218] Iteration 6000 (16.3282 iter/s, 6.12438s/100 iters), loss = 0.315102
I1123 17:09:05.975122 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:09:05.975122 26520 solver.cpp:237]     Train net output #1: loss = 0.315102 (* 1 = 0.315102 loss)
I1123 17:09:05.975122 26520 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1123 17:09:10.768689 26520 solver.cpp:218] Iteration 6100 (20.8612 iter/s, 4.79359s/100 iters), loss = 0.376528
I1123 17:09:10.768689 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1123 17:09:10.768689 26520 solver.cpp:237]     Train net output #1: loss = 0.376528 (* 1 = 0.376528 loss)
I1123 17:09:10.768689 26520 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1123 17:09:15.566103 26520 solver.cpp:218] Iteration 6200 (20.8463 iter/s, 4.79701s/100 iters), loss = 0.29302
I1123 17:09:15.566103 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:09:15.566103 26520 solver.cpp:237]     Train net output #1: loss = 0.293021 (* 1 = 0.293021 loss)
I1123 17:09:15.566103 26520 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1123 17:09:20.362815 26520 solver.cpp:218] Iteration 6300 (20.8494 iter/s, 4.79631s/100 iters), loss = 0.369294
I1123 17:09:20.362815 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:09:20.362815 26520 solver.cpp:237]     Train net output #1: loss = 0.369294 (* 1 = 0.369294 loss)
I1123 17:09:20.362815 26520 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1123 17:09:25.156174 26520 solver.cpp:218] Iteration 6400 (20.862 iter/s, 4.79339s/100 iters), loss = 0.260594
I1123 17:09:25.156174 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1123 17:09:25.156174 26520 solver.cpp:237]     Train net output #1: loss = 0.260594 (* 1 = 0.260594 loss)
I1123 17:09:25.156174 26520 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1123 17:09:29.717810  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:09:29.906366 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_6500.caffemodel
I1123 17:09:29.916370 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_6500.solverstate
I1123 17:09:29.920388 26520 solver.cpp:330] Iteration 6500, Testing net (#0)
I1123 17:09:29.920388 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:09:31.184913 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:09:31.235435 26520 solver.cpp:397]     Test net output #0: accuracy = 0.864
I1123 17:09:31.235435 26520 solver.cpp:397]     Test net output #1: loss = 0.390971 (* 1 = 0.390971 loss)
I1123 17:09:31.281446 26520 solver.cpp:218] Iteration 6500 (16.3274 iter/s, 6.12469s/100 iters), loss = 0.334891
I1123 17:09:31.281446 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1123 17:09:31.281446 26520 solver.cpp:237]     Train net output #1: loss = 0.334891 (* 1 = 0.334891 loss)
I1123 17:09:31.281446 26520 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1123 17:09:36.077330 26520 solver.cpp:218] Iteration 6600 (20.8526 iter/s, 4.79557s/100 iters), loss = 0.299648
I1123 17:09:36.077330 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:09:36.077330 26520 solver.cpp:237]     Train net output #1: loss = 0.299648 (* 1 = 0.299648 loss)
I1123 17:09:36.077330 26520 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1123 17:09:40.872947 26520 solver.cpp:218] Iteration 6700 (20.8571 iter/s, 4.79454s/100 iters), loss = 0.283226
I1123 17:09:40.872947 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:09:40.872947 26520 solver.cpp:237]     Train net output #1: loss = 0.283226 (* 1 = 0.283226 loss)
I1123 17:09:40.872947 26520 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1123 17:09:45.670217 26520 solver.cpp:218] Iteration 6800 (20.8449 iter/s, 4.79733s/100 iters), loss = 0.376491
I1123 17:09:45.670217 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:09:45.670217 26520 solver.cpp:237]     Train net output #1: loss = 0.376491 (* 1 = 0.376491 loss)
I1123 17:09:45.670217 26520 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1123 17:09:50.463430 26520 solver.cpp:218] Iteration 6900 (20.8642 iter/s, 4.7929s/100 iters), loss = 0.304374
I1123 17:09:50.463430 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:09:50.463430 26520 solver.cpp:237]     Train net output #1: loss = 0.304374 (* 1 = 0.304374 loss)
I1123 17:09:50.463430 26520 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1123 17:09:55.021199  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:09:55.209739 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_7000.caffemodel
I1123 17:09:55.219739 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_7000.solverstate
I1123 17:09:55.223739 26520 solver.cpp:330] Iteration 7000, Testing net (#0)
I1123 17:09:55.223739 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:09:56.489050 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:09:56.538163 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8653
I1123 17:09:56.538163 26520 solver.cpp:397]     Test net output #1: loss = 0.389702 (* 1 = 0.389702 loss)
I1123 17:09:56.585177 26520 solver.cpp:218] Iteration 7000 (16.3379 iter/s, 6.12072s/100 iters), loss = 0.262814
I1123 17:09:56.585177 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:09:56.585177 26520 solver.cpp:237]     Train net output #1: loss = 0.262814 (* 1 = 0.262814 loss)
I1123 17:09:56.585177 26520 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1123 17:10:01.402724 26520 solver.cpp:218] Iteration 7100 (20.7574 iter/s, 4.81756s/100 iters), loss = 0.265602
I1123 17:10:01.402724 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:10:01.402724 26520 solver.cpp:237]     Train net output #1: loss = 0.265602 (* 1 = 0.265602 loss)
I1123 17:10:01.402724 26520 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1123 17:10:06.197402 26520 solver.cpp:218] Iteration 7200 (20.8571 iter/s, 4.79454s/100 iters), loss = 0.292028
I1123 17:10:06.197402 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:10:06.198403 26520 solver.cpp:237]     Train net output #1: loss = 0.292028 (* 1 = 0.292028 loss)
I1123 17:10:06.198403 26520 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1123 17:10:10.991582 26520 solver.cpp:218] Iteration 7300 (20.8609 iter/s, 4.79366s/100 iters), loss = 0.311817
I1123 17:10:10.991582 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1123 17:10:10.991582 26520 solver.cpp:237]     Train net output #1: loss = 0.311817 (* 1 = 0.311817 loss)
I1123 17:10:10.991582 26520 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1123 17:10:15.786201 26520 solver.cpp:218] Iteration 7400 (20.8605 iter/s, 4.79374s/100 iters), loss = 0.256151
I1123 17:10:15.786201 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1123 17:10:15.786201 26520 solver.cpp:237]     Train net output #1: loss = 0.256151 (* 1 = 0.256151 loss)
I1123 17:10:15.786201 26520 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1123 17:10:20.344316  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:10:20.532640 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_7500.caffemodel
I1123 17:10:20.542639 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_7500.solverstate
I1123 17:10:20.547641 26520 solver.cpp:330] Iteration 7500, Testing net (#0)
I1123 17:10:20.547641 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:10:21.809482 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:10:21.859498 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8696
I1123 17:10:21.859498 26520 solver.cpp:397]     Test net output #1: loss = 0.383577 (* 1 = 0.383577 loss)
I1123 17:10:21.905720 26520 solver.cpp:218] Iteration 7500 (16.3425 iter/s, 6.11902s/100 iters), loss = 0.251649
I1123 17:10:21.905720 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:10:21.905720 26520 solver.cpp:237]     Train net output #1: loss = 0.251649 (* 1 = 0.251649 loss)
I1123 17:10:21.905720 26520 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1123 17:10:26.700139 26520 solver.cpp:218] Iteration 7600 (20.8598 iter/s, 4.79391s/100 iters), loss = 0.27891
I1123 17:10:26.700139 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1123 17:10:26.700139 26520 solver.cpp:237]     Train net output #1: loss = 0.27891 (* 1 = 0.27891 loss)
I1123 17:10:26.700139 26520 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1123 17:10:31.496546 26520 solver.cpp:218] Iteration 7700 (20.8499 iter/s, 4.79618s/100 iters), loss = 0.250434
I1123 17:10:31.496546 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:10:31.496546 26520 solver.cpp:237]     Train net output #1: loss = 0.250434 (* 1 = 0.250434 loss)
I1123 17:10:31.496546 26520 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1123 17:10:36.293157 26520 solver.cpp:218] Iteration 7800 (20.8497 iter/s, 4.79624s/100 iters), loss = 0.350584
I1123 17:10:36.293157 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1123 17:10:36.293157 26520 solver.cpp:237]     Train net output #1: loss = 0.350584 (* 1 = 0.350584 loss)
I1123 17:10:36.293157 26520 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1123 17:10:41.087785 26520 solver.cpp:218] Iteration 7900 (20.8577 iter/s, 4.7944s/100 iters), loss = 0.231494
I1123 17:10:41.087785 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:10:41.087785 26520 solver.cpp:237]     Train net output #1: loss = 0.231494 (* 1 = 0.231494 loss)
I1123 17:10:41.087785 26520 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1123 17:10:45.645938  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:10:45.834452 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_8000.caffemodel
I1123 17:10:45.845453 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_8000.solverstate
I1123 17:10:45.849452 26520 solver.cpp:330] Iteration 8000, Testing net (#0)
I1123 17:10:45.849452 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:10:47.113215 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:10:47.162732 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8607
I1123 17:10:47.162732 26520 solver.cpp:397]     Test net output #1: loss = 0.399587 (* 1 = 0.399587 loss)
I1123 17:10:47.209745 26520 solver.cpp:218] Iteration 8000 (16.3368 iter/s, 6.12113s/100 iters), loss = 0.236114
I1123 17:10:47.209745 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:10:47.209745 26520 solver.cpp:237]     Train net output #1: loss = 0.236115 (* 1 = 0.236115 loss)
I1123 17:10:47.209745 26520 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1123 17:10:52.000149 26520 solver.cpp:218] Iteration 8100 (20.8745 iter/s, 4.79054s/100 iters), loss = 0.311639
I1123 17:10:52.000149 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:10:52.000149 26520 solver.cpp:237]     Train net output #1: loss = 0.311639 (* 1 = 0.311639 loss)
I1123 17:10:52.000149 26520 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1123 17:10:56.794006 26520 solver.cpp:218] Iteration 8200 (20.862 iter/s, 4.7934s/100 iters), loss = 0.238928
I1123 17:10:56.794006 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:10:56.794006 26520 solver.cpp:237]     Train net output #1: loss = 0.238928 (* 1 = 0.238928 loss)
I1123 17:10:56.794006 26520 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1123 17:11:01.590639 26520 solver.cpp:218] Iteration 8300 (20.8508 iter/s, 4.79598s/100 iters), loss = 0.283965
I1123 17:11:01.590639 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:11:01.590639 26520 solver.cpp:237]     Train net output #1: loss = 0.283965 (* 1 = 0.283965 loss)
I1123 17:11:01.590639 26520 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1123 17:11:06.387570 26520 solver.cpp:218] Iteration 8400 (20.8491 iter/s, 4.79638s/100 iters), loss = 0.225216
I1123 17:11:06.387570 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:11:06.387570 26520 solver.cpp:237]     Train net output #1: loss = 0.225216 (* 1 = 0.225216 loss)
I1123 17:11:06.387570 26520 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1123 17:11:10.946316  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:11:11.135099 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_8500.caffemodel
I1123 17:11:11.145099 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_8500.solverstate
I1123 17:11:11.149099 26520 solver.cpp:330] Iteration 8500, Testing net (#0)
I1123 17:11:11.149099 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:11:12.412708 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:11:12.462718 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8655
I1123 17:11:12.462718 26520 solver.cpp:397]     Test net output #1: loss = 0.389037 (* 1 = 0.389037 loss)
I1123 17:11:12.508715 26520 solver.cpp:218] Iteration 8500 (16.3364 iter/s, 6.12129s/100 iters), loss = 0.214694
I1123 17:11:12.508715 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:11:12.508715 26520 solver.cpp:237]     Train net output #1: loss = 0.214694 (* 1 = 0.214694 loss)
I1123 17:11:12.508715 26520 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1123 17:11:17.303833 26520 solver.cpp:218] Iteration 8600 (20.8585 iter/s, 4.7942s/100 iters), loss = 0.253309
I1123 17:11:17.303833 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:11:17.303833 26520 solver.cpp:237]     Train net output #1: loss = 0.253309 (* 1 = 0.253309 loss)
I1123 17:11:17.303833 26520 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1123 17:11:22.097720 26520 solver.cpp:218] Iteration 8700 (20.8621 iter/s, 4.79339s/100 iters), loss = 0.265792
I1123 17:11:22.097720 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:11:22.097720 26520 solver.cpp:237]     Train net output #1: loss = 0.265792 (* 1 = 0.265792 loss)
I1123 17:11:22.097720 26520 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1123 17:11:26.893055 26520 solver.cpp:218] Iteration 8800 (20.8532 iter/s, 4.79544s/100 iters), loss = 0.252274
I1123 17:11:26.893055 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:11:26.893055 26520 solver.cpp:237]     Train net output #1: loss = 0.252274 (* 1 = 0.252274 loss)
I1123 17:11:26.893055 26520 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1123 17:11:31.688817 26520 solver.cpp:218] Iteration 8900 (20.8518 iter/s, 4.79575s/100 iters), loss = 0.196049
I1123 17:11:31.688817 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:11:31.688817 26520 solver.cpp:237]     Train net output #1: loss = 0.196049 (* 1 = 0.196049 loss)
I1123 17:11:31.688817 26520 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1123 17:11:36.250155  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:11:36.438874 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_9000.caffemodel
I1123 17:11:36.448928 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_9000.solverstate
I1123 17:11:36.453939 26520 solver.cpp:330] Iteration 9000, Testing net (#0)
I1123 17:11:36.453939 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:11:37.715872 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:11:37.765893 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8581
I1123 17:11:37.765893 26520 solver.cpp:397]     Test net output #1: loss = 0.40451 (* 1 = 0.40451 loss)
I1123 17:11:37.812907 26520 solver.cpp:218] Iteration 9000 (16.3323 iter/s, 6.12284s/100 iters), loss = 0.263447
I1123 17:11:37.812907 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:11:37.812907 26520 solver.cpp:237]     Train net output #1: loss = 0.263447 (* 1 = 0.263447 loss)
I1123 17:11:37.812907 26520 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1123 17:11:42.610651 26520 solver.cpp:218] Iteration 9100 (20.8413 iter/s, 4.79817s/100 iters), loss = 0.221374
I1123 17:11:42.610651 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:11:42.610651 26520 solver.cpp:237]     Train net output #1: loss = 0.221374 (* 1 = 0.221374 loss)
I1123 17:11:42.610651 26520 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1123 17:11:47.408777 26520 solver.cpp:218] Iteration 9200 (20.8434 iter/s, 4.79769s/100 iters), loss = 0.223222
I1123 17:11:47.408777 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:11:47.408777 26520 solver.cpp:237]     Train net output #1: loss = 0.223222 (* 1 = 0.223222 loss)
I1123 17:11:47.408777 26520 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1123 17:11:52.202641 26520 solver.cpp:218] Iteration 9300 (20.8611 iter/s, 4.79361s/100 iters), loss = 0.252811
I1123 17:11:52.203645 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:11:52.203645 26520 solver.cpp:237]     Train net output #1: loss = 0.252811 (* 1 = 0.252811 loss)
I1123 17:11:52.203645 26520 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1123 17:11:57.001029 26520 solver.cpp:218] Iteration 9400 (20.8464 iter/s, 4.79699s/100 iters), loss = 0.260766
I1123 17:11:57.001029 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1123 17:11:57.001029 26520 solver.cpp:237]     Train net output #1: loss = 0.260766 (* 1 = 0.260766 loss)
I1123 17:11:57.001029 26520 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1123 17:12:01.562119  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:12:01.751144 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_9500.caffemodel
I1123 17:12:01.761144 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_9500.solverstate
I1123 17:12:01.766145 26520 solver.cpp:330] Iteration 9500, Testing net (#0)
I1123 17:12:01.766145 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:12:03.028729 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:12:03.078745 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8578
I1123 17:12:03.078745 26520 solver.cpp:397]     Test net output #1: loss = 0.41182 (* 1 = 0.41182 loss)
I1123 17:12:03.125252 26520 solver.cpp:218] Iteration 9500 (16.3294 iter/s, 6.12393s/100 iters), loss = 0.240712
I1123 17:12:03.125252 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:12:03.125252 26520 solver.cpp:237]     Train net output #1: loss = 0.240712 (* 1 = 0.240712 loss)
I1123 17:12:03.125252 26520 sgd_solver.cpp:46] MultiStep Status: Iteration 9500, step = 2
I1123 17:12:03.125252 26520 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1123 17:12:07.918877 26520 solver.cpp:218] Iteration 9600 (20.8621 iter/s, 4.79337s/100 iters), loss = 0.260018
I1123 17:12:07.918877 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:12:07.918877 26520 solver.cpp:237]     Train net output #1: loss = 0.260018 (* 1 = 0.260018 loss)
I1123 17:12:07.918877 26520 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1123 17:12:12.710371 26520 solver.cpp:218] Iteration 9700 (20.8713 iter/s, 4.79127s/100 iters), loss = 0.223683
I1123 17:12:12.710371 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:12:12.710371 26520 solver.cpp:237]     Train net output #1: loss = 0.223683 (* 1 = 0.223683 loss)
I1123 17:12:12.710371 26520 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I1123 17:12:17.504382 26520 solver.cpp:218] Iteration 9800 (20.8603 iter/s, 4.79381s/100 iters), loss = 0.268768
I1123 17:12:17.504382 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:12:17.504382 26520 solver.cpp:237]     Train net output #1: loss = 0.268768 (* 1 = 0.268768 loss)
I1123 17:12:17.504382 26520 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1123 17:12:22.300323 26520 solver.cpp:218] Iteration 9900 (20.8522 iter/s, 4.79565s/100 iters), loss = 0.236806
I1123 17:12:22.300323 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:12:22.300323 26520 solver.cpp:237]     Train net output #1: loss = 0.236806 (* 1 = 0.236806 loss)
I1123 17:12:22.300323 26520 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I1123 17:12:26.860186  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:12:27.048861 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_10000.caffemodel
I1123 17:12:27.058846 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_10000.solverstate
I1123 17:12:27.062845 26520 solver.cpp:330] Iteration 10000, Testing net (#0)
I1123 17:12:27.062845 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:12:28.327435 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:12:28.377969 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8796
I1123 17:12:28.377969 26520 solver.cpp:397]     Test net output #1: loss = 0.349739 (* 1 = 0.349739 loss)
I1123 17:12:28.423962 26520 solver.cpp:218] Iteration 10000 (16.3319 iter/s, 6.123s/100 iters), loss = 0.263426
I1123 17:12:28.423962 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1123 17:12:28.423962 26520 solver.cpp:237]     Train net output #1: loss = 0.263426 (* 1 = 0.263426 loss)
I1123 17:12:28.423962 26520 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I1123 17:12:33.223438 26520 solver.cpp:218] Iteration 10100 (20.838 iter/s, 4.79892s/100 iters), loss = 0.196265
I1123 17:12:33.223438 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:12:33.223438 26520 solver.cpp:237]     Train net output #1: loss = 0.196265 (* 1 = 0.196265 loss)
I1123 17:12:33.223438 26520 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I1123 17:12:38.018486 26520 solver.cpp:218] Iteration 10200 (20.8554 iter/s, 4.79492s/100 iters), loss = 0.250829
I1123 17:12:38.018486 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:12:38.018486 26520 solver.cpp:237]     Train net output #1: loss = 0.250829 (* 1 = 0.250829 loss)
I1123 17:12:38.018486 26520 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I1123 17:12:42.814663 26520 solver.cpp:218] Iteration 10300 (20.8505 iter/s, 4.79604s/100 iters), loss = 0.216812
I1123 17:12:42.814663 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:12:42.815665 26520 solver.cpp:237]     Train net output #1: loss = 0.216812 (* 1 = 0.216812 loss)
I1123 17:12:42.815665 26520 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I1123 17:12:47.607204 26520 solver.cpp:218] Iteration 10400 (20.8687 iter/s, 4.79186s/100 iters), loss = 0.153922
I1123 17:12:47.607204 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:12:47.607204 26520 solver.cpp:237]     Train net output #1: loss = 0.153922 (* 1 = 0.153922 loss)
I1123 17:12:47.607204 26520 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I1123 17:12:52.168025  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:12:52.358031 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_10500.caffemodel
I1123 17:12:52.369521 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_10500.solverstate
I1123 17:12:52.374022 26520 solver.cpp:330] Iteration 10500, Testing net (#0)
I1123 17:12:52.374022 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:12:53.629629 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:12:53.679628 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8823
I1123 17:12:53.679628 26520 solver.cpp:397]     Test net output #1: loss = 0.347001 (* 1 = 0.347001 loss)
I1123 17:12:53.726128 26520 solver.cpp:218] Iteration 10500 (16.3447 iter/s, 6.11819s/100 iters), loss = 0.234981
I1123 17:12:53.726128 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:12:53.726128 26520 solver.cpp:237]     Train net output #1: loss = 0.234981 (* 1 = 0.234981 loss)
I1123 17:12:53.726128 26520 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I1123 17:12:58.515766 26520 solver.cpp:218] Iteration 10600 (20.881 iter/s, 4.78905s/100 iters), loss = 0.245902
I1123 17:12:58.515766 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:12:58.515766 26520 solver.cpp:237]     Train net output #1: loss = 0.245902 (* 1 = 0.245902 loss)
I1123 17:12:58.515766 26520 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I1123 17:13:03.313807 26520 solver.cpp:218] Iteration 10700 (20.8408 iter/s, 4.79829s/100 iters), loss = 0.163137
I1123 17:13:03.313807 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:13:03.313807 26520 solver.cpp:237]     Train net output #1: loss = 0.163137 (* 1 = 0.163137 loss)
I1123 17:13:03.313807 26520 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I1123 17:13:08.113472 26520 solver.cpp:218] Iteration 10800 (20.8399 iter/s, 4.79848s/100 iters), loss = 0.219491
I1123 17:13:08.113472 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:13:08.113472 26520 solver.cpp:237]     Train net output #1: loss = 0.219491 (* 1 = 0.219491 loss)
I1123 17:13:08.113472 26520 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I1123 17:13:12.909806 26520 solver.cpp:218] Iteration 10900 (20.8495 iter/s, 4.79627s/100 iters), loss = 0.201759
I1123 17:13:12.909806 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:13:12.909806 26520 solver.cpp:237]     Train net output #1: loss = 0.201759 (* 1 = 0.201759 loss)
I1123 17:13:12.909806 26520 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I1123 17:13:17.469235  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:13:17.657878 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_11000.caffemodel
I1123 17:13:17.667883 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_11000.solverstate
I1123 17:13:17.671882 26520 solver.cpp:330] Iteration 11000, Testing net (#0)
I1123 17:13:17.671882 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:13:18.934187 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:13:18.984182 26520 solver.cpp:397]     Test net output #0: accuracy = 0.882
I1123 17:13:18.984182 26520 solver.cpp:397]     Test net output #1: loss = 0.344563 (* 1 = 0.344563 loss)
I1123 17:13:19.031136 26520 solver.cpp:218] Iteration 11000 (16.3382 iter/s, 6.12064s/100 iters), loss = 0.225194
I1123 17:13:19.031136 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:13:19.031136 26520 solver.cpp:237]     Train net output #1: loss = 0.225194 (* 1 = 0.225194 loss)
I1123 17:13:19.031136 26520 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I1123 17:13:23.825137 26520 solver.cpp:218] Iteration 11100 (20.8587 iter/s, 4.79417s/100 iters), loss = 0.242314
I1123 17:13:23.825137 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:13:23.825137 26520 solver.cpp:237]     Train net output #1: loss = 0.242314 (* 1 = 0.242314 loss)
I1123 17:13:23.825137 26520 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I1123 17:13:28.619169 26520 solver.cpp:218] Iteration 11200 (20.8634 iter/s, 4.79309s/100 iters), loss = 0.217782
I1123 17:13:28.619169 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:13:28.619169 26520 solver.cpp:237]     Train net output #1: loss = 0.217782 (* 1 = 0.217782 loss)
I1123 17:13:28.619169 26520 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I1123 17:13:33.415755 26520 solver.cpp:218] Iteration 11300 (20.8497 iter/s, 4.79622s/100 iters), loss = 0.226344
I1123 17:13:33.415755 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:13:33.415755 26520 solver.cpp:237]     Train net output #1: loss = 0.226344 (* 1 = 0.226344 loss)
I1123 17:13:33.415755 26520 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I1123 17:13:38.210711 26520 solver.cpp:218] Iteration 11400 (20.8563 iter/s, 4.79472s/100 iters), loss = 0.176764
I1123 17:13:38.210711 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:13:38.210711 26520 solver.cpp:237]     Train net output #1: loss = 0.176764 (* 1 = 0.176764 loss)
I1123 17:13:38.210711 26520 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I1123 17:13:42.767457  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:13:42.956876 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_11500.caffemodel
I1123 17:13:42.965876 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_11500.solverstate
I1123 17:13:42.970381 26520 solver.cpp:330] Iteration 11500, Testing net (#0)
I1123 17:13:42.970381 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:13:44.233372 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:13:44.283871 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8814
I1123 17:13:44.283871 26520 solver.cpp:397]     Test net output #1: loss = 0.343671 (* 1 = 0.343671 loss)
I1123 17:13:44.329385 26520 solver.cpp:218] Iteration 11500 (16.3428 iter/s, 6.11892s/100 iters), loss = 0.26167
I1123 17:13:44.330396 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:13:44.330396 26520 solver.cpp:237]     Train net output #1: loss = 0.26167 (* 1 = 0.26167 loss)
I1123 17:13:44.330396 26520 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I1123 17:13:49.120725 26520 solver.cpp:218] Iteration 11600 (20.8728 iter/s, 4.79093s/100 iters), loss = 0.239282
I1123 17:13:49.121729 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:13:49.121729 26520 solver.cpp:237]     Train net output #1: loss = 0.239282 (* 1 = 0.239282 loss)
I1123 17:13:49.121729 26520 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I1123 17:13:53.916338 26520 solver.cpp:218] Iteration 11700 (20.8573 iter/s, 4.79448s/100 iters), loss = 0.221022
I1123 17:13:53.916338 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:13:53.916338 26520 solver.cpp:237]     Train net output #1: loss = 0.221022 (* 1 = 0.221022 loss)
I1123 17:13:53.916338 26520 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I1123 17:13:58.711850 26520 solver.cpp:218] Iteration 11800 (20.8538 iter/s, 4.79529s/100 iters), loss = 0.215438
I1123 17:13:58.712350 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:13:58.712350 26520 solver.cpp:237]     Train net output #1: loss = 0.215438 (* 1 = 0.215438 loss)
I1123 17:13:58.712350 26520 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I1123 17:14:03.505090 26520 solver.cpp:218] Iteration 11900 (20.8636 iter/s, 4.79304s/100 iters), loss = 0.220745
I1123 17:14:03.505090 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:14:03.505090 26520 solver.cpp:237]     Train net output #1: loss = 0.220745 (* 1 = 0.220745 loss)
I1123 17:14:03.505090 26520 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I1123 17:14:08.066624  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:14:08.255209 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_12000.caffemodel
I1123 17:14:08.266225 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_12000.solverstate
I1123 17:14:08.270221 26520 solver.cpp:330] Iteration 12000, Testing net (#0)
I1123 17:14:08.270221 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:14:09.532524 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:14:09.582551 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8818
I1123 17:14:09.582551 26520 solver.cpp:397]     Test net output #1: loss = 0.344353 (* 1 = 0.344353 loss)
I1123 17:14:09.628561 26520 solver.cpp:218] Iteration 12000 (16.332 iter/s, 6.12296s/100 iters), loss = 0.21345
I1123 17:14:09.628561 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:14:09.628561 26520 solver.cpp:237]     Train net output #1: loss = 0.21345 (* 1 = 0.21345 loss)
I1123 17:14:09.628561 26520 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I1123 17:14:14.425375 26520 solver.cpp:218] Iteration 12100 (20.8497 iter/s, 4.79624s/100 iters), loss = 0.226822
I1123 17:14:14.425375 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:14:14.425375 26520 solver.cpp:237]     Train net output #1: loss = 0.226822 (* 1 = 0.226822 loss)
I1123 17:14:14.425375 26520 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I1123 17:14:19.219323 26520 solver.cpp:218] Iteration 12200 (20.8619 iter/s, 4.79343s/100 iters), loss = 0.193853
I1123 17:14:19.219323 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:14:19.219323 26520 solver.cpp:237]     Train net output #1: loss = 0.193853 (* 1 = 0.193853 loss)
I1123 17:14:19.219323 26520 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I1123 17:14:24.010857 26520 solver.cpp:218] Iteration 12300 (20.8702 iter/s, 4.79152s/100 iters), loss = 0.205134
I1123 17:14:24.010857 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:14:24.010857 26520 solver.cpp:237]     Train net output #1: loss = 0.205134 (* 1 = 0.205134 loss)
I1123 17:14:24.010857 26520 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I1123 17:14:28.804308 26520 solver.cpp:218] Iteration 12400 (20.8621 iter/s, 4.79338s/100 iters), loss = 0.160482
I1123 17:14:28.804308 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:14:28.804308 26520 solver.cpp:237]     Train net output #1: loss = 0.160482 (* 1 = 0.160482 loss)
I1123 17:14:28.804308 26520 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I1123 17:14:33.363503  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:14:33.551059 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_12500.caffemodel
I1123 17:14:33.561046 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_12500.solverstate
I1123 17:14:33.565047 26520 solver.cpp:330] Iteration 12500, Testing net (#0)
I1123 17:14:33.566045 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:14:34.829746 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:14:34.880250 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8836
I1123 17:14:34.880250 26520 solver.cpp:397]     Test net output #1: loss = 0.343521 (* 1 = 0.343521 loss)
I1123 17:14:34.925755 26520 solver.cpp:218] Iteration 12500 (16.3372 iter/s, 6.12098s/100 iters), loss = 0.174148
I1123 17:14:34.925755 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:14:34.925755 26520 solver.cpp:237]     Train net output #1: loss = 0.174148 (* 1 = 0.174148 loss)
I1123 17:14:34.925755 26520 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I1123 17:14:39.717108 26520 solver.cpp:218] Iteration 12600 (20.8739 iter/s, 4.79066s/100 iters), loss = 0.242252
I1123 17:14:39.717108 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:14:39.717108 26520 solver.cpp:237]     Train net output #1: loss = 0.242252 (* 1 = 0.242252 loss)
I1123 17:14:39.717108 26520 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I1123 17:14:44.514515 26520 solver.cpp:218] Iteration 12700 (20.8455 iter/s, 4.7972s/100 iters), loss = 0.188689
I1123 17:14:44.514515 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:14:44.514515 26520 solver.cpp:237]     Train net output #1: loss = 0.188688 (* 1 = 0.188688 loss)
I1123 17:14:44.514515 26520 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I1123 17:14:49.308138 26520 solver.cpp:218] Iteration 12800 (20.8636 iter/s, 4.79304s/100 iters), loss = 0.206181
I1123 17:14:49.308138 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:14:49.308138 26520 solver.cpp:237]     Train net output #1: loss = 0.206181 (* 1 = 0.206181 loss)
I1123 17:14:49.308138 26520 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I1123 17:14:54.102880 26520 solver.cpp:218] Iteration 12900 (20.8587 iter/s, 4.79417s/100 iters), loss = 0.163984
I1123 17:14:54.102880 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:14:54.102880 26520 solver.cpp:237]     Train net output #1: loss = 0.163984 (* 1 = 0.163984 loss)
I1123 17:14:54.102880 26520 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I1123 17:14:58.660797  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:14:58.850361 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_13000.caffemodel
I1123 17:14:58.859356 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_13000.solverstate
I1123 17:14:58.863358 26520 solver.cpp:330] Iteration 13000, Testing net (#0)
I1123 17:14:58.864356 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:15:00.126387 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:15:00.176375 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8828
I1123 17:15:00.176375 26520 solver.cpp:397]     Test net output #1: loss = 0.344796 (* 1 = 0.344796 loss)
I1123 17:15:00.223414 26520 solver.cpp:218] Iteration 13000 (16.3403 iter/s, 6.11982s/100 iters), loss = 0.191395
I1123 17:15:00.223414 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:15:00.223414 26520 solver.cpp:237]     Train net output #1: loss = 0.191395 (* 1 = 0.191395 loss)
I1123 17:15:00.223414 26520 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I1123 17:15:05.016517 26520 solver.cpp:218] Iteration 13100 (20.8628 iter/s, 4.79322s/100 iters), loss = 0.257676
I1123 17:15:05.016517 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:15:05.016517 26520 solver.cpp:237]     Train net output #1: loss = 0.257675 (* 1 = 0.257675 loss)
I1123 17:15:05.016517 26520 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I1123 17:15:09.810513 26520 solver.cpp:218] Iteration 13200 (20.8623 iter/s, 4.79333s/100 iters), loss = 0.178553
I1123 17:15:09.810513 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:15:09.810513 26520 solver.cpp:237]     Train net output #1: loss = 0.178553 (* 1 = 0.178553 loss)
I1123 17:15:09.810513 26520 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I1123 17:15:14.604846 26520 solver.cpp:218] Iteration 13300 (20.8576 iter/s, 4.79443s/100 iters), loss = 0.222959
I1123 17:15:14.604846 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:15:14.604846 26520 solver.cpp:237]     Train net output #1: loss = 0.222959 (* 1 = 0.222959 loss)
I1123 17:15:14.604846 26520 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I1123 17:15:19.400795 26520 solver.cpp:218] Iteration 13400 (20.8542 iter/s, 4.7952s/100 iters), loss = 0.152329
I1123 17:15:19.401301 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:15:19.401301 26520 solver.cpp:237]     Train net output #1: loss = 0.152329 (* 1 = 0.152329 loss)
I1123 17:15:19.401301 26520 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I1123 17:15:23.962987  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:15:24.152063 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_13500.caffemodel
I1123 17:15:24.161051 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_13500.solverstate
I1123 17:15:24.165052 26520 solver.cpp:330] Iteration 13500, Testing net (#0)
I1123 17:15:24.165052 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:15:25.428508 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:15:25.478510 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8817
I1123 17:15:25.478510 26520 solver.cpp:397]     Test net output #1: loss = 0.343229 (* 1 = 0.343229 loss)
I1123 17:15:25.524924 26520 solver.cpp:218] Iteration 13500 (16.3307 iter/s, 6.12345s/100 iters), loss = 0.16542
I1123 17:15:25.524924 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:15:25.524924 26520 solver.cpp:237]     Train net output #1: loss = 0.16542 (* 1 = 0.16542 loss)
I1123 17:15:25.524924 26520 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I1123 17:15:30.322134 26520 solver.cpp:218] Iteration 13600 (20.8463 iter/s, 4.79701s/100 iters), loss = 0.209452
I1123 17:15:30.322134 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:15:30.322134 26520 solver.cpp:237]     Train net output #1: loss = 0.209452 (* 1 = 0.209452 loss)
I1123 17:15:30.322134 26520 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I1123 17:15:35.113796 26520 solver.cpp:218] Iteration 13700 (20.8715 iter/s, 4.79122s/100 iters), loss = 0.169726
I1123 17:15:35.113796 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:15:35.113796 26520 solver.cpp:237]     Train net output #1: loss = 0.169726 (* 1 = 0.169726 loss)
I1123 17:15:35.113796 26520 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I1123 17:15:39.909940 26520 solver.cpp:218] Iteration 13800 (20.8526 iter/s, 4.79556s/100 iters), loss = 0.229854
I1123 17:15:39.909940 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:15:39.909940 26520 solver.cpp:237]     Train net output #1: loss = 0.229854 (* 1 = 0.229854 loss)
I1123 17:15:39.909940 26520 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I1123 17:15:44.705968 26520 solver.cpp:218] Iteration 13900 (20.8513 iter/s, 4.79585s/100 iters), loss = 0.153335
I1123 17:15:44.705968 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:15:44.705968 26520 solver.cpp:237]     Train net output #1: loss = 0.153335 (* 1 = 0.153335 loss)
I1123 17:15:44.705968 26520 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I1123 17:15:49.265712  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:15:49.453567 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_14000.caffemodel
I1123 17:15:49.464565 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_14000.solverstate
I1123 17:15:49.468566 26520 solver.cpp:330] Iteration 14000, Testing net (#0)
I1123 17:15:49.468566 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:15:50.733176 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:15:50.783159 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8825
I1123 17:15:50.783159 26520 solver.cpp:397]     Test net output #1: loss = 0.342547 (* 1 = 0.342547 loss)
I1123 17:15:50.829205 26520 solver.cpp:218] Iteration 14000 (16.3321 iter/s, 6.12293s/100 iters), loss = 0.193902
I1123 17:15:50.829205 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:15:50.829205 26520 solver.cpp:237]     Train net output #1: loss = 0.193902 (* 1 = 0.193902 loss)
I1123 17:15:50.829205 26520 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I1123 17:15:55.626341 26520 solver.cpp:218] Iteration 14100 (20.8487 iter/s, 4.79645s/100 iters), loss = 0.243255
I1123 17:15:55.626341 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:15:55.626341 26520 solver.cpp:237]     Train net output #1: loss = 0.243255 (* 1 = 0.243255 loss)
I1123 17:15:55.626341 26520 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I1123 17:16:00.423691 26520 solver.cpp:218] Iteration 14200 (20.8479 iter/s, 4.79664s/100 iters), loss = 0.154369
I1123 17:16:00.423691 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:16:00.423691 26520 solver.cpp:237]     Train net output #1: loss = 0.154369 (* 1 = 0.154369 loss)
I1123 17:16:00.423691 26520 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I1123 17:16:05.218881 26520 solver.cpp:218] Iteration 14300 (20.8548 iter/s, 4.79506s/100 iters), loss = 0.23669
I1123 17:16:05.218881 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:16:05.218881 26520 solver.cpp:237]     Train net output #1: loss = 0.23669 (* 1 = 0.23669 loss)
I1123 17:16:05.218881 26520 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I1123 17:16:10.022706 26520 solver.cpp:218] Iteration 14400 (20.8183 iter/s, 4.80346s/100 iters), loss = 0.123205
I1123 17:16:10.022706 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:16:10.022706 26520 solver.cpp:237]     Train net output #1: loss = 0.123205 (* 1 = 0.123205 loss)
I1123 17:16:10.022706 26520 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I1123 17:16:14.585978  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:16:14.774979 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_14500.caffemodel
I1123 17:16:14.784979 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_14500.solverstate
I1123 17:16:14.789480 26520 solver.cpp:330] Iteration 14500, Testing net (#0)
I1123 17:16:14.789480 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:16:16.052860 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:16:16.102849 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8825
I1123 17:16:16.102849 26520 solver.cpp:397]     Test net output #1: loss = 0.343134 (* 1 = 0.343134 loss)
I1123 17:16:16.149497 26520 solver.cpp:218] Iteration 14500 (16.323 iter/s, 6.12632s/100 iters), loss = 0.25282
I1123 17:16:16.149497 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:16:16.149497 26520 solver.cpp:237]     Train net output #1: loss = 0.252819 (* 1 = 0.252819 loss)
I1123 17:16:16.149497 26520 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I1123 17:16:20.944054 26520 solver.cpp:218] Iteration 14600 (20.8596 iter/s, 4.79395s/100 iters), loss = 0.20122
I1123 17:16:20.944054 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:16:20.944054 26520 solver.cpp:237]     Train net output #1: loss = 0.20122 (* 1 = 0.20122 loss)
I1123 17:16:20.944054 26520 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I1123 17:16:25.735512 26520 solver.cpp:218] Iteration 14700 (20.8706 iter/s, 4.79143s/100 iters), loss = 0.193751
I1123 17:16:25.735512 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:16:25.735512 26520 solver.cpp:237]     Train net output #1: loss = 0.193751 (* 1 = 0.193751 loss)
I1123 17:16:25.735512 26520 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I1123 17:16:30.527943 26520 solver.cpp:218] Iteration 14800 (20.8667 iter/s, 4.79232s/100 iters), loss = 0.203042
I1123 17:16:30.527943 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:16:30.527943 26520 solver.cpp:237]     Train net output #1: loss = 0.203042 (* 1 = 0.203042 loss)
I1123 17:16:30.527943 26520 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I1123 17:16:35.318547 26520 solver.cpp:218] Iteration 14900 (20.8767 iter/s, 4.79004s/100 iters), loss = 0.158063
I1123 17:16:35.318547 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:16:35.318547 26520 solver.cpp:237]     Train net output #1: loss = 0.158063 (* 1 = 0.158063 loss)
I1123 17:16:35.318547 26520 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I1123 17:16:39.873695  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:16:40.061806 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_15000.caffemodel
I1123 17:16:40.071807 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_15000.solverstate
I1123 17:16:40.075808 26520 solver.cpp:330] Iteration 15000, Testing net (#0)
I1123 17:16:40.075808 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:16:41.339617 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:16:41.390136 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8825
I1123 17:16:41.390136 26520 solver.cpp:397]     Test net output #1: loss = 0.343161 (* 1 = 0.343161 loss)
I1123 17:16:41.435659 26520 solver.cpp:218] Iteration 15000 (16.3478 iter/s, 6.11703s/100 iters), loss = 0.210709
I1123 17:16:41.435659 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:16:41.435659 26520 solver.cpp:237]     Train net output #1: loss = 0.210709 (* 1 = 0.210709 loss)
I1123 17:16:41.435659 26520 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I1123 17:16:46.231442 26520 solver.cpp:218] Iteration 15100 (20.8535 iter/s, 4.79537s/100 iters), loss = 0.22783
I1123 17:16:46.231442 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:16:46.231442 26520 solver.cpp:237]     Train net output #1: loss = 0.22783 (* 1 = 0.22783 loss)
I1123 17:16:46.231442 26520 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I1123 17:16:51.025353 26520 solver.cpp:218] Iteration 15200 (20.8611 iter/s, 4.79361s/100 iters), loss = 0.182969
I1123 17:16:51.026356 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:16:51.026356 26520 solver.cpp:237]     Train net output #1: loss = 0.182969 (* 1 = 0.182969 loss)
I1123 17:16:51.026356 26520 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I1123 17:16:55.821704 26520 solver.cpp:218] Iteration 15300 (20.8551 iter/s, 4.79498s/100 iters), loss = 0.174715
I1123 17:16:55.821704 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:16:55.821704 26520 solver.cpp:237]     Train net output #1: loss = 0.174715 (* 1 = 0.174715 loss)
I1123 17:16:55.821704 26520 sgd_solver.cpp:46] MultiStep Status: Iteration 15300, step = 3
I1123 17:16:55.821704 26520 sgd_solver.cpp:105] Iteration 15300, lr = 0.0001
I1123 17:17:00.616550 26520 solver.cpp:218] Iteration 15400 (20.8571 iter/s, 4.79453s/100 iters), loss = 0.141764
I1123 17:17:00.616550 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:17:00.616550 26520 solver.cpp:237]     Train net output #1: loss = 0.141764 (* 1 = 0.141764 loss)
I1123 17:17:00.616550 26520 sgd_solver.cpp:105] Iteration 15400, lr = 0.0001
I1123 17:17:05.176028  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:17:05.364161 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_15500.caffemodel
I1123 17:17:05.374172 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_15500.solverstate
I1123 17:17:05.379171 26520 solver.cpp:330] Iteration 15500, Testing net (#0)
I1123 17:17:05.379171 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:17:06.640239 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:17:06.689441 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8832
I1123 17:17:06.689441 26520 solver.cpp:397]     Test net output #1: loss = 0.341013 (* 1 = 0.341013 loss)
I1123 17:17:06.736459 26520 solver.cpp:218] Iteration 15500 (16.3409 iter/s, 6.1196s/100 iters), loss = 0.178527
I1123 17:17:06.736459 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:17:06.736459 26520 solver.cpp:237]     Train net output #1: loss = 0.178526 (* 1 = 0.178526 loss)
I1123 17:17:06.736459 26520 sgd_solver.cpp:105] Iteration 15500, lr = 0.0001
I1123 17:17:11.530421 26520 solver.cpp:218] Iteration 15600 (20.8582 iter/s, 4.79428s/100 iters), loss = 0.22109
I1123 17:17:11.531421 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:17:11.531421 26520 solver.cpp:237]     Train net output #1: loss = 0.22109 (* 1 = 0.22109 loss)
I1123 17:17:11.531421 26520 sgd_solver.cpp:105] Iteration 15600, lr = 0.0001
I1123 17:17:16.326998 26520 solver.cpp:218] Iteration 15700 (20.851 iter/s, 4.79593s/100 iters), loss = 0.153384
I1123 17:17:16.326998 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:17:16.326998 26520 solver.cpp:237]     Train net output #1: loss = 0.153384 (* 1 = 0.153384 loss)
I1123 17:17:16.326998 26520 sgd_solver.cpp:105] Iteration 15700, lr = 0.0001
I1123 17:17:21.122174 26520 solver.cpp:218] Iteration 15800 (20.8564 iter/s, 4.79468s/100 iters), loss = 0.186806
I1123 17:17:21.122174 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:17:21.122174 26520 solver.cpp:237]     Train net output #1: loss = 0.186806 (* 1 = 0.186806 loss)
I1123 17:17:21.122174 26520 sgd_solver.cpp:105] Iteration 15800, lr = 0.0001
I1123 17:17:25.912956 26520 solver.cpp:218] Iteration 15900 (20.8735 iter/s, 4.79077s/100 iters), loss = 0.141501
I1123 17:17:25.913961 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:17:25.913961 26520 solver.cpp:237]     Train net output #1: loss = 0.141501 (* 1 = 0.141501 loss)
I1123 17:17:25.913961 26520 sgd_solver.cpp:105] Iteration 15900, lr = 0.0001
I1123 17:17:30.475033  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:17:30.663141 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_16000.caffemodel
I1123 17:17:30.675122 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_16000.solverstate
I1123 17:17:30.679126 26520 solver.cpp:330] Iteration 16000, Testing net (#0)
I1123 17:17:30.679126 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:17:31.940367 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:17:31.990397 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8829
I1123 17:17:31.990397 26520 solver.cpp:397]     Test net output #1: loss = 0.340487 (* 1 = 0.340487 loss)
I1123 17:17:32.036401 26520 solver.cpp:218] Iteration 16000 (16.3322 iter/s, 6.12286s/100 iters), loss = 0.175843
I1123 17:17:32.036401 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:17:32.036401 26520 solver.cpp:237]     Train net output #1: loss = 0.175843 (* 1 = 0.175843 loss)
I1123 17:17:32.036401 26520 sgd_solver.cpp:105] Iteration 16000, lr = 0.0001
I1123 17:17:36.834985 26520 solver.cpp:218] Iteration 16100 (20.8441 iter/s, 4.79753s/100 iters), loss = 0.248678
I1123 17:17:36.834985 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:17:36.834985 26520 solver.cpp:237]     Train net output #1: loss = 0.248678 (* 1 = 0.248678 loss)
I1123 17:17:36.834985 26520 sgd_solver.cpp:105] Iteration 16100, lr = 0.0001
I1123 17:17:41.633163 26520 solver.cpp:218] Iteration 16200 (20.8433 iter/s, 4.7977s/100 iters), loss = 0.179136
I1123 17:17:41.633163 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:17:41.633163 26520 solver.cpp:237]     Train net output #1: loss = 0.179136 (* 1 = 0.179136 loss)
I1123 17:17:41.633163 26520 sgd_solver.cpp:105] Iteration 16200, lr = 0.0001
I1123 17:17:46.428362 26520 solver.cpp:218] Iteration 16300 (20.8534 iter/s, 4.79537s/100 iters), loss = 0.179466
I1123 17:17:46.428362 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:17:46.428362 26520 solver.cpp:237]     Train net output #1: loss = 0.179466 (* 1 = 0.179466 loss)
I1123 17:17:46.428362 26520 sgd_solver.cpp:105] Iteration 16300, lr = 0.0001
I1123 17:17:51.226830 26520 solver.cpp:218] Iteration 16400 (20.8429 iter/s, 4.79779s/100 iters), loss = 0.123467
I1123 17:17:51.226830 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:17:51.226830 26520 solver.cpp:237]     Train net output #1: loss = 0.123467 (* 1 = 0.123467 loss)
I1123 17:17:51.226830 26520 sgd_solver.cpp:105] Iteration 16400, lr = 0.0001
I1123 17:17:55.788122  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:17:55.977226 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_16500.caffemodel
I1123 17:17:55.987210 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_16500.solverstate
I1123 17:17:55.991230 26520 solver.cpp:330] Iteration 16500, Testing net (#0)
I1123 17:17:55.991230 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:17:57.254781 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:17:57.304778 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8834
I1123 17:17:57.304778 26520 solver.cpp:397]     Test net output #1: loss = 0.340011 (* 1 = 0.340011 loss)
I1123 17:17:57.350788 26520 solver.cpp:218] Iteration 16500 (16.3296 iter/s, 6.12386s/100 iters), loss = 0.218286
I1123 17:17:57.350788 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:17:57.350788 26520 solver.cpp:237]     Train net output #1: loss = 0.218286 (* 1 = 0.218286 loss)
I1123 17:17:57.350788 26520 sgd_solver.cpp:105] Iteration 16500, lr = 0.0001
I1123 17:18:02.147161 26520 solver.cpp:218] Iteration 16600 (20.8522 iter/s, 4.79566s/100 iters), loss = 0.225376
I1123 17:18:02.147161 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:18:02.147161 26520 solver.cpp:237]     Train net output #1: loss = 0.225375 (* 1 = 0.225375 loss)
I1123 17:18:02.147161 26520 sgd_solver.cpp:105] Iteration 16600, lr = 0.0001
I1123 17:18:06.941326 26520 solver.cpp:218] Iteration 16700 (20.8615 iter/s, 4.79351s/100 iters), loss = 0.192088
I1123 17:18:06.941326 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:18:06.941326 26520 solver.cpp:237]     Train net output #1: loss = 0.192087 (* 1 = 0.192087 loss)
I1123 17:18:06.941326 26520 sgd_solver.cpp:105] Iteration 16700, lr = 0.0001
I1123 17:18:11.732128 26520 solver.cpp:218] Iteration 16800 (20.8734 iter/s, 4.79079s/100 iters), loss = 0.208027
I1123 17:18:11.732128 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:18:11.732128 26520 solver.cpp:237]     Train net output #1: loss = 0.208027 (* 1 = 0.208027 loss)
I1123 17:18:11.732128 26520 sgd_solver.cpp:105] Iteration 16800, lr = 0.0001
I1123 17:18:16.529172 26520 solver.cpp:218] Iteration 16900 (20.8459 iter/s, 4.79711s/100 iters), loss = 0.164054
I1123 17:18:16.530177 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:18:16.530177 26520 solver.cpp:237]     Train net output #1: loss = 0.164054 (* 1 = 0.164054 loss)
I1123 17:18:16.530177 26520 sgd_solver.cpp:105] Iteration 16900, lr = 0.0001
I1123 17:18:21.088701  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:18:21.278276 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_17000.caffemodel
I1123 17:18:21.288264 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_17000.solverstate
I1123 17:18:21.292265 26520 solver.cpp:330] Iteration 17000, Testing net (#0)
I1123 17:18:21.292265 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:18:22.555485 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:18:22.605034 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8837
I1123 17:18:22.605034 26520 solver.cpp:397]     Test net output #1: loss = 0.340162 (* 1 = 0.340162 loss)
I1123 17:18:22.651016 26520 solver.cpp:218] Iteration 17000 (16.337 iter/s, 6.12107s/100 iters), loss = 0.197039
I1123 17:18:22.651016 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:18:22.651016 26520 solver.cpp:237]     Train net output #1: loss = 0.197039 (* 1 = 0.197039 loss)
I1123 17:18:22.651016 26520 sgd_solver.cpp:105] Iteration 17000, lr = 0.0001
I1123 17:18:27.450112 26520 solver.cpp:218] Iteration 17100 (20.8373 iter/s, 4.79908s/100 iters), loss = 0.19591
I1123 17:18:27.451117 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:18:27.451117 26520 solver.cpp:237]     Train net output #1: loss = 0.19591 (* 1 = 0.19591 loss)
I1123 17:18:27.451117 26520 sgd_solver.cpp:105] Iteration 17100, lr = 0.0001
I1123 17:18:32.244700 26520 solver.cpp:218] Iteration 17200 (20.8597 iter/s, 4.79394s/100 iters), loss = 0.197523
I1123 17:18:32.244700 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:18:32.244700 26520 solver.cpp:237]     Train net output #1: loss = 0.197523 (* 1 = 0.197523 loss)
I1123 17:18:32.244700 26520 sgd_solver.cpp:105] Iteration 17200, lr = 0.0001
I1123 17:18:37.039835 26520 solver.cpp:218] Iteration 17300 (20.8589 iter/s, 4.79412s/100 iters), loss = 0.188451
I1123 17:18:37.039835 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:18:37.039835 26520 solver.cpp:237]     Train net output #1: loss = 0.18845 (* 1 = 0.18845 loss)
I1123 17:18:37.039835 26520 sgd_solver.cpp:105] Iteration 17300, lr = 0.0001
I1123 17:18:41.836055 26520 solver.cpp:218] Iteration 17400 (20.8511 iter/s, 4.7959s/100 iters), loss = 0.178074
I1123 17:18:41.836055 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:18:41.836055 26520 solver.cpp:237]     Train net output #1: loss = 0.178074 (* 1 = 0.178074 loss)
I1123 17:18:41.836055 26520 sgd_solver.cpp:105] Iteration 17400, lr = 0.0001
I1123 17:18:46.394701  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:18:46.583343 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_17500.caffemodel
I1123 17:18:46.593327 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_17500.solverstate
I1123 17:18:46.596830 26520 solver.cpp:330] Iteration 17500, Testing net (#0)
I1123 17:18:46.596830 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:18:47.859285 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:18:47.908818 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8839
I1123 17:18:47.908818 26520 solver.cpp:397]     Test net output #1: loss = 0.340043 (* 1 = 0.340043 loss)
I1123 17:18:47.955813 26520 solver.cpp:218] Iteration 17500 (16.3419 iter/s, 6.11923s/100 iters), loss = 0.251419
I1123 17:18:47.955813 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:18:47.955813 26520 solver.cpp:237]     Train net output #1: loss = 0.251419 (* 1 = 0.251419 loss)
I1123 17:18:47.955813 26520 sgd_solver.cpp:105] Iteration 17500, lr = 0.0001
I1123 17:18:52.752005 26520 solver.cpp:218] Iteration 17600 (20.8505 iter/s, 4.79606s/100 iters), loss = 0.182674
I1123 17:18:52.752005 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:18:52.752005 26520 solver.cpp:237]     Train net output #1: loss = 0.182674 (* 1 = 0.182674 loss)
I1123 17:18:52.752005 26520 sgd_solver.cpp:105] Iteration 17600, lr = 0.0001
I1123 17:18:57.547103 26520 solver.cpp:218] Iteration 17700 (20.8546 iter/s, 4.79511s/100 iters), loss = 0.202886
I1123 17:18:57.547103 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:18:57.547103 26520 solver.cpp:237]     Train net output #1: loss = 0.202886 (* 1 = 0.202886 loss)
I1123 17:18:57.547103 26520 sgd_solver.cpp:105] Iteration 17700, lr = 0.0001
I1123 17:19:02.340823 26520 solver.cpp:218] Iteration 17800 (20.8631 iter/s, 4.79316s/100 iters), loss = 0.171768
I1123 17:19:02.340823 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:19:02.340823 26520 solver.cpp:237]     Train net output #1: loss = 0.171768 (* 1 = 0.171768 loss)
I1123 17:19:02.340823 26520 sgd_solver.cpp:105] Iteration 17800, lr = 0.0001
I1123 17:19:07.138231 26520 solver.cpp:218] Iteration 17900 (20.8465 iter/s, 4.79697s/100 iters), loss = 0.13446
I1123 17:19:07.138231 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:19:07.138231 26520 solver.cpp:237]     Train net output #1: loss = 0.13446 (* 1 = 0.13446 loss)
I1123 17:19:07.138231 26520 sgd_solver.cpp:105] Iteration 17900, lr = 0.0001
I1123 17:19:11.703153  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:19:11.891894 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_18000.caffemodel
I1123 17:19:11.902881 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_18000.solverstate
I1123 17:19:11.907405 26520 solver.cpp:330] Iteration 18000, Testing net (#0)
I1123 17:19:11.907405 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:19:13.172497 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:19:13.222156 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8835
I1123 17:19:13.222156 26520 solver.cpp:397]     Test net output #1: loss = 0.340126 (* 1 = 0.340126 loss)
I1123 17:19:13.268153 26520 solver.cpp:218] Iteration 18000 (16.3143 iter/s, 6.12959s/100 iters), loss = 0.198484
I1123 17:19:13.268153 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:19:13.268153 26520 solver.cpp:237]     Train net output #1: loss = 0.198484 (* 1 = 0.198484 loss)
I1123 17:19:13.268153 26520 sgd_solver.cpp:105] Iteration 18000, lr = 0.0001
I1123 17:19:18.059007 26520 solver.cpp:218] Iteration 18100 (20.8754 iter/s, 4.79032s/100 iters), loss = 0.196481
I1123 17:19:18.059007 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:19:18.059007 26520 solver.cpp:237]     Train net output #1: loss = 0.19648 (* 1 = 0.19648 loss)
I1123 17:19:18.059007 26520 sgd_solver.cpp:105] Iteration 18100, lr = 0.0001
I1123 17:19:22.851467 26520 solver.cpp:218] Iteration 18200 (20.8689 iter/s, 4.79181s/100 iters), loss = 0.195392
I1123 17:19:22.851467 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:19:22.851467 26520 solver.cpp:237]     Train net output #1: loss = 0.195392 (* 1 = 0.195392 loss)
I1123 17:19:22.851467 26520 sgd_solver.cpp:105] Iteration 18200, lr = 0.0001
I1123 17:19:27.645478 26520 solver.cpp:218] Iteration 18300 (20.8622 iter/s, 4.79335s/100 iters), loss = 0.194104
I1123 17:19:27.645478 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:19:27.645478 26520 solver.cpp:237]     Train net output #1: loss = 0.194104 (* 1 = 0.194104 loss)
I1123 17:19:27.645478 26520 sgd_solver.cpp:105] Iteration 18300, lr = 0.0001
I1123 17:19:32.438241 26520 solver.cpp:218] Iteration 18400 (20.864 iter/s, 4.79295s/100 iters), loss = 0.223128
I1123 17:19:32.438241 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:19:32.438241 26520 solver.cpp:237]     Train net output #1: loss = 0.223128 (* 1 = 0.223128 loss)
I1123 17:19:32.438241 26520 sgd_solver.cpp:105] Iteration 18400, lr = 0.0001
I1123 17:19:36.997953  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:19:37.186331 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_18500.caffemodel
I1123 17:19:37.196313 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_18500.solverstate
I1123 17:19:37.201316 26520 solver.cpp:330] Iteration 18500, Testing net (#0)
I1123 17:19:37.201316 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:19:38.465443 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:19:38.515949 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8849
I1123 17:19:38.515949 26520 solver.cpp:397]     Test net output #1: loss = 0.339668 (* 1 = 0.339668 loss)
I1123 17:19:38.562145 26520 solver.cpp:218] Iteration 18500 (16.3321 iter/s, 6.1229s/100 iters), loss = 0.185318
I1123 17:19:38.562145 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:19:38.562145 26520 solver.cpp:237]     Train net output #1: loss = 0.185318 (* 1 = 0.185318 loss)
I1123 17:19:38.562145 26520 sgd_solver.cpp:105] Iteration 18500, lr = 0.0001
I1123 17:19:43.357146 26520 solver.cpp:218] Iteration 18600 (20.8556 iter/s, 4.79487s/100 iters), loss = 0.193942
I1123 17:19:43.357146 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:19:43.357146 26520 solver.cpp:237]     Train net output #1: loss = 0.193941 (* 1 = 0.193941 loss)
I1123 17:19:43.357146 26520 sgd_solver.cpp:105] Iteration 18600, lr = 0.0001
I1123 17:19:48.150883 26520 solver.cpp:218] Iteration 18700 (20.8613 iter/s, 4.79357s/100 iters), loss = 0.187009
I1123 17:19:48.150883 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:19:48.150883 26520 solver.cpp:237]     Train net output #1: loss = 0.187009 (* 1 = 0.187009 loss)
I1123 17:19:48.150883 26520 sgd_solver.cpp:105] Iteration 18700, lr = 0.0001
I1123 17:19:52.943482 26520 solver.cpp:218] Iteration 18800 (20.8665 iter/s, 4.79238s/100 iters), loss = 0.191668
I1123 17:19:52.943482 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:19:52.943482 26520 solver.cpp:237]     Train net output #1: loss = 0.191667 (* 1 = 0.191667 loss)
I1123 17:19:52.943482 26520 sgd_solver.cpp:105] Iteration 18800, lr = 0.0001
I1123 17:19:57.740098 26520 solver.cpp:218] Iteration 18900 (20.85 iter/s, 4.79615s/100 iters), loss = 0.119574
I1123 17:19:57.740098 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 17:19:57.740098 26520 solver.cpp:237]     Train net output #1: loss = 0.119574 (* 1 = 0.119574 loss)
I1123 17:19:57.740098 26520 sgd_solver.cpp:105] Iteration 18900, lr = 0.0001
I1123 17:20:02.321352  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:20:02.509361 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_19000.caffemodel
I1123 17:20:02.519361 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_19000.solverstate
I1123 17:20:02.523361 26520 solver.cpp:330] Iteration 19000, Testing net (#0)
I1123 17:20:02.523361 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:20:03.786612 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:20:03.837113 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8844
I1123 17:20:03.837113 26520 solver.cpp:397]     Test net output #1: loss = 0.339903 (* 1 = 0.339903 loss)
I1123 17:20:03.883144 26520 solver.cpp:218] Iteration 19000 (16.281 iter/s, 6.14212s/100 iters), loss = 0.22017
I1123 17:20:03.883144 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:20:03.883144 26520 solver.cpp:237]     Train net output #1: loss = 0.22017 (* 1 = 0.22017 loss)
I1123 17:20:03.883144 26520 sgd_solver.cpp:105] Iteration 19000, lr = 0.0001
I1123 17:20:08.680706 26520 solver.cpp:218] Iteration 19100 (20.8459 iter/s, 4.7971s/100 iters), loss = 0.21778
I1123 17:20:08.680706 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:20:08.680706 26520 solver.cpp:237]     Train net output #1: loss = 0.21778 (* 1 = 0.21778 loss)
I1123 17:20:08.680706 26520 sgd_solver.cpp:105] Iteration 19100, lr = 0.0001
I1123 17:20:13.476292 26520 solver.cpp:218] Iteration 19200 (20.8502 iter/s, 4.79611s/100 iters), loss = 0.18168
I1123 17:20:13.477298 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:20:13.477298 26520 solver.cpp:237]     Train net output #1: loss = 0.18168 (* 1 = 0.18168 loss)
I1123 17:20:13.477298 26520 sgd_solver.cpp:105] Iteration 19200, lr = 0.0001
I1123 17:20:18.272653 26520 solver.cpp:218] Iteration 19300 (20.8547 iter/s, 4.79508s/100 iters), loss = 0.194045
I1123 17:20:18.272653 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:20:18.272653 26520 solver.cpp:237]     Train net output #1: loss = 0.194045 (* 1 = 0.194045 loss)
I1123 17:20:18.272653 26520 sgd_solver.cpp:105] Iteration 19300, lr = 0.0001
I1123 17:20:23.068992 26520 solver.cpp:218] Iteration 19400 (20.85 iter/s, 4.79616s/100 iters), loss = 0.152566
I1123 17:20:23.068992 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:20:23.068992 26520 solver.cpp:237]     Train net output #1: loss = 0.152565 (* 1 = 0.152565 loss)
I1123 17:20:23.068992 26520 sgd_solver.cpp:105] Iteration 19400, lr = 0.0001
I1123 17:20:27.632172  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:20:27.821216 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_19500.caffemodel
I1123 17:20:27.830211 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_19500.solverstate
I1123 17:20:27.835212 26520 solver.cpp:330] Iteration 19500, Testing net (#0)
I1123 17:20:27.835212 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:20:29.099261 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:20:29.148772 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8848
I1123 17:20:29.149790 26520 solver.cpp:397]     Test net output #1: loss = 0.339525 (* 1 = 0.339525 loss)
I1123 17:20:29.196297 26520 solver.cpp:218] Iteration 19500 (16.3223 iter/s, 6.12658s/100 iters), loss = 0.192784
I1123 17:20:29.196297 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:20:29.196297 26520 solver.cpp:237]     Train net output #1: loss = 0.192784 (* 1 = 0.192784 loss)
I1123 17:20:29.196297 26520 sgd_solver.cpp:46] MultiStep Status: Iteration 19500, step = 4
I1123 17:20:29.196297 26520 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I1123 17:20:33.989131 26520 solver.cpp:218] Iteration 19600 (20.8643 iter/s, 4.79288s/100 iters), loss = 0.177131
I1123 17:20:33.989660 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:20:33.989660 26520 solver.cpp:237]     Train net output #1: loss = 0.177131 (* 1 = 0.177131 loss)
I1123 17:20:33.989660 26520 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I1123 17:20:38.782101 26520 solver.cpp:218] Iteration 19700 (20.8677 iter/s, 4.79211s/100 iters), loss = 0.177274
I1123 17:20:38.782101 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:20:38.782101 26520 solver.cpp:237]     Train net output #1: loss = 0.177274 (* 1 = 0.177274 loss)
I1123 17:20:38.782101 26520 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I1123 17:20:43.575028 26520 solver.cpp:218] Iteration 19800 (20.8659 iter/s, 4.79252s/100 iters), loss = 0.181135
I1123 17:20:43.575028 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:20:43.575028 26520 solver.cpp:237]     Train net output #1: loss = 0.181135 (* 1 = 0.181135 loss)
I1123 17:20:43.575028 26520 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I1123 17:20:48.367144 26520 solver.cpp:218] Iteration 19900 (20.8688 iter/s, 4.79183s/100 iters), loss = 0.187053
I1123 17:20:48.367144 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:20:48.367144 26520 solver.cpp:237]     Train net output #1: loss = 0.187053 (* 1 = 0.187053 loss)
I1123 17:20:48.367144 26520 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I1123 17:20:52.926240  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:20:53.114800 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_20000.caffemodel
I1123 17:20:53.124320 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_20000.solverstate
I1123 17:20:53.129320 26520 solver.cpp:330] Iteration 20000, Testing net (#0)
I1123 17:20:53.129320 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:20:54.393177 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:20:54.443219 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8848
I1123 17:20:54.443219 26520 solver.cpp:397]     Test net output #1: loss = 0.339663 (* 1 = 0.339663 loss)
I1123 17:20:54.489231 26520 solver.cpp:218] Iteration 20000 (16.3344 iter/s, 6.12205s/100 iters), loss = 0.192692
I1123 17:20:54.489231 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:20:54.489231 26520 solver.cpp:237]     Train net output #1: loss = 0.192692 (* 1 = 0.192692 loss)
I1123 17:20:54.489231 26520 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I1123 17:20:59.287259 26520 solver.cpp:218] Iteration 20100 (20.8453 iter/s, 4.79725s/100 iters), loss = 0.155333
I1123 17:20:59.287259 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:20:59.287259 26520 solver.cpp:237]     Train net output #1: loss = 0.155332 (* 1 = 0.155332 loss)
I1123 17:20:59.287259 26520 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I1123 17:21:04.077177 26520 solver.cpp:218] Iteration 20200 (20.8755 iter/s, 4.7903s/100 iters), loss = 0.141491
I1123 17:21:04.077177 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:21:04.077177 26520 solver.cpp:237]     Train net output #1: loss = 0.141491 (* 1 = 0.141491 loss)
I1123 17:21:04.077177 26520 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I1123 17:21:08.871528 26520 solver.cpp:218] Iteration 20300 (20.8619 iter/s, 4.79343s/100 iters), loss = 0.212348
I1123 17:21:08.871528 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:21:08.871528 26520 solver.cpp:237]     Train net output #1: loss = 0.212348 (* 1 = 0.212348 loss)
I1123 17:21:08.871528 26520 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I1123 17:21:13.660411 26520 solver.cpp:218] Iteration 20400 (20.881 iter/s, 4.78905s/100 iters), loss = 0.131134
I1123 17:21:13.661412 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:21:13.661412 26520 solver.cpp:237]     Train net output #1: loss = 0.131134 (* 1 = 0.131134 loss)
I1123 17:21:13.661412 26520 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I1123 17:21:18.221398  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:21:18.410457 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_20500.caffemodel
I1123 17:21:18.420486 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_20500.solverstate
I1123 17:21:18.446521 26520 solver.cpp:330] Iteration 20500, Testing net (#0)
I1123 17:21:18.446521 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:21:19.708808 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:21:19.758836 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8844
I1123 17:21:19.758836 26520 solver.cpp:397]     Test net output #1: loss = 0.339578 (* 1 = 0.339578 loss)
I1123 17:21:19.805847 26520 solver.cpp:218] Iteration 20500 (16.2759 iter/s, 6.14404s/100 iters), loss = 0.190492
I1123 17:21:19.805847 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:21:19.805847 26520 solver.cpp:237]     Train net output #1: loss = 0.190491 (* 1 = 0.190491 loss)
I1123 17:21:19.805847 26520 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I1123 17:21:24.603185 26520 solver.cpp:218] Iteration 20600 (20.8434 iter/s, 4.79769s/100 iters), loss = 0.210958
I1123 17:21:24.603185 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:21:24.603185 26520 solver.cpp:237]     Train net output #1: loss = 0.210958 (* 1 = 0.210958 loss)
I1123 17:21:24.603185 26520 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I1123 17:21:29.401779 26520 solver.cpp:218] Iteration 20700 (20.8423 iter/s, 4.79793s/100 iters), loss = 0.166364
I1123 17:21:29.401779 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:21:29.401779 26520 solver.cpp:237]     Train net output #1: loss = 0.166364 (* 1 = 0.166364 loss)
I1123 17:21:29.401779 26520 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I1123 17:21:34.198271 26520 solver.cpp:218] Iteration 20800 (20.8514 iter/s, 4.79585s/100 iters), loss = 0.210792
I1123 17:21:34.198271 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:21:34.198271 26520 solver.cpp:237]     Train net output #1: loss = 0.210792 (* 1 = 0.210792 loss)
I1123 17:21:34.198271 26520 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I1123 17:21:38.995203 26520 solver.cpp:218] Iteration 20900 (20.8473 iter/s, 4.79679s/100 iters), loss = 0.157086
I1123 17:21:38.995203 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:21:38.995203 26520 solver.cpp:237]     Train net output #1: loss = 0.157086 (* 1 = 0.157086 loss)
I1123 17:21:38.995203 26520 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I1123 17:21:43.556983  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:21:43.745575 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_21000.caffemodel
I1123 17:21:43.756559 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_21000.solverstate
I1123 17:21:43.760576 26520 solver.cpp:330] Iteration 21000, Testing net (#0)
I1123 17:21:43.760576 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:21:45.023792 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:21:45.073782 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8847
I1123 17:21:45.073782 26520 solver.cpp:397]     Test net output #1: loss = 0.339611 (* 1 = 0.339611 loss)
I1123 17:21:45.119822 26520 solver.cpp:218] Iteration 21000 (16.3289 iter/s, 6.12412s/100 iters), loss = 0.25967
I1123 17:21:45.120323 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:21:45.120323 26520 solver.cpp:237]     Train net output #1: loss = 0.259669 (* 1 = 0.259669 loss)
I1123 17:21:45.120323 26520 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I1123 17:21:49.919368 26520 solver.cpp:218] Iteration 21100 (20.8383 iter/s, 4.79885s/100 iters), loss = 0.223836
I1123 17:21:49.919368 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:21:49.919368 26520 solver.cpp:237]     Train net output #1: loss = 0.223835 (* 1 = 0.223835 loss)
I1123 17:21:49.919368 26520 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I1123 17:21:54.715781 26520 solver.cpp:218] Iteration 21200 (20.8483 iter/s, 4.79654s/100 iters), loss = 0.122508
I1123 17:21:54.715781 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:21:54.715781 26520 solver.cpp:237]     Train net output #1: loss = 0.122508 (* 1 = 0.122508 loss)
I1123 17:21:54.715781 26520 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I1123 17:21:59.511618 26520 solver.cpp:218] Iteration 21300 (20.8547 iter/s, 4.79507s/100 iters), loss = 0.194993
I1123 17:21:59.511618 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:21:59.511618 26520 solver.cpp:237]     Train net output #1: loss = 0.194993 (* 1 = 0.194993 loss)
I1123 17:21:59.511618 26520 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I1123 17:22:04.304289 26520 solver.cpp:218] Iteration 21400 (20.8638 iter/s, 4.79299s/100 iters), loss = 0.0885743
I1123 17:22:04.305294 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 17:22:04.305294 26520 solver.cpp:237]     Train net output #1: loss = 0.0885741 (* 1 = 0.0885741 loss)
I1123 17:22:04.305294 26520 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I1123 17:22:08.865100  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:22:09.053673 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_21500.caffemodel
I1123 17:22:09.064154 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_21500.solverstate
I1123 17:22:09.067674 26520 solver.cpp:330] Iteration 21500, Testing net (#0)
I1123 17:22:09.067674 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:22:10.332077 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:22:10.382017 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8846
I1123 17:22:10.382017 26520 solver.cpp:397]     Test net output #1: loss = 0.339756 (* 1 = 0.339756 loss)
I1123 17:22:10.428997 26520 solver.cpp:218] Iteration 21500 (16.3309 iter/s, 6.12334s/100 iters), loss = 0.198622
I1123 17:22:10.428997 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:22:10.428997 26520 solver.cpp:237]     Train net output #1: loss = 0.198622 (* 1 = 0.198622 loss)
I1123 17:22:10.428997 26520 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I1123 17:22:15.226399 26520 solver.cpp:218] Iteration 21600 (20.8453 iter/s, 4.79724s/100 iters), loss = 0.224117
I1123 17:22:15.226399 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:22:15.226399 26520 solver.cpp:237]     Train net output #1: loss = 0.224116 (* 1 = 0.224116 loss)
I1123 17:22:15.226399 26520 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I1123 17:22:20.021837 26520 solver.cpp:218] Iteration 21700 (20.8537 iter/s, 4.79532s/100 iters), loss = 0.187733
I1123 17:22:20.021837 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:22:20.021837 26520 solver.cpp:237]     Train net output #1: loss = 0.187733 (* 1 = 0.187733 loss)
I1123 17:22:20.021837 26520 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I1123 17:22:24.818917 26520 solver.cpp:218] Iteration 21800 (20.8478 iter/s, 4.79666s/100 iters), loss = 0.221002
I1123 17:22:24.818917 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:22:24.818917 26520 solver.cpp:237]     Train net output #1: loss = 0.221001 (* 1 = 0.221001 loss)
I1123 17:22:24.818917 26520 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I1123 17:22:29.615784 26520 solver.cpp:218] Iteration 21900 (20.8504 iter/s, 4.79606s/100 iters), loss = 0.162358
I1123 17:22:29.615784 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:22:29.615784 26520 solver.cpp:237]     Train net output #1: loss = 0.162358 (* 1 = 0.162358 loss)
I1123 17:22:29.615784 26520 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I1123 17:22:34.179652  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:22:34.368232 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_22000.caffemodel
I1123 17:22:34.379212 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_22000.solverstate
I1123 17:22:34.383240 26520 solver.cpp:330] Iteration 22000, Testing net (#0)
I1123 17:22:34.383240 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:22:35.647840 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:22:35.697355 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8847
I1123 17:22:35.697355 26520 solver.cpp:397]     Test net output #1: loss = 0.339694 (* 1 = 0.339694 loss)
I1123 17:22:35.743355 26520 solver.cpp:218] Iteration 22000 (16.3186 iter/s, 6.12799s/100 iters), loss = 0.177173
I1123 17:22:35.744355 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:22:35.744355 26520 solver.cpp:237]     Train net output #1: loss = 0.177173 (* 1 = 0.177173 loss)
I1123 17:22:35.744355 26520 sgd_solver.cpp:46] MultiStep Status: Iteration 22000, step = 5
I1123 17:22:35.744355 26520 sgd_solver.cpp:105] Iteration 22000, lr = 1e-06
I1123 17:22:40.539407 26520 solver.cpp:218] Iteration 22100 (20.8527 iter/s, 4.79555s/100 iters), loss = 0.228359
I1123 17:22:40.539407 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 17:22:40.539407 26520 solver.cpp:237]     Train net output #1: loss = 0.228358 (* 1 = 0.228358 loss)
I1123 17:22:40.539407 26520 sgd_solver.cpp:105] Iteration 22100, lr = 1e-06
I1123 17:22:45.335680 26520 solver.cpp:218] Iteration 22200 (20.8514 iter/s, 4.79583s/100 iters), loss = 0.15554
I1123 17:22:45.335680 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:22:45.335680 26520 solver.cpp:237]     Train net output #1: loss = 0.15554 (* 1 = 0.15554 loss)
I1123 17:22:45.335680 26520 sgd_solver.cpp:105] Iteration 22200, lr = 1e-06
I1123 17:22:50.131541 26520 solver.cpp:218] Iteration 22300 (20.8566 iter/s, 4.79464s/100 iters), loss = 0.182315
I1123 17:22:50.131541 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:22:50.131541 26520 solver.cpp:237]     Train net output #1: loss = 0.182315 (* 1 = 0.182315 loss)
I1123 17:22:50.131541 26520 sgd_solver.cpp:105] Iteration 22300, lr = 1e-06
I1123 17:22:54.927520 26520 solver.cpp:218] Iteration 22400 (20.8525 iter/s, 4.7956s/100 iters), loss = 0.145517
I1123 17:22:54.927520 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:22:54.927520 26520 solver.cpp:237]     Train net output #1: loss = 0.145517 (* 1 = 0.145517 loss)
I1123 17:22:54.927520 26520 sgd_solver.cpp:105] Iteration 22400, lr = 1e-06
I1123 17:22:59.487998  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:22:59.676128 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_22500.caffemodel
I1123 17:22:59.686111 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_22500.solverstate
I1123 17:22:59.691117 26520 solver.cpp:330] Iteration 22500, Testing net (#0)
I1123 17:22:59.691117 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:23:00.954617 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:23:01.005102 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8849
I1123 17:23:01.005102 26520 solver.cpp:397]     Test net output #1: loss = 0.3397 (* 1 = 0.3397 loss)
I1123 17:23:01.051631 26520 solver.cpp:218] Iteration 22500 (16.3304 iter/s, 6.12355s/100 iters), loss = 0.171556
I1123 17:23:01.051631 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:23:01.051631 26520 solver.cpp:237]     Train net output #1: loss = 0.171556 (* 1 = 0.171556 loss)
I1123 17:23:01.051631 26520 sgd_solver.cpp:105] Iteration 22500, lr = 1e-06
I1123 17:23:05.846828 26520 solver.cpp:218] Iteration 22600 (20.8542 iter/s, 4.79519s/100 iters), loss = 0.18958
I1123 17:23:05.846828 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:23:05.846828 26520 solver.cpp:237]     Train net output #1: loss = 0.18958 (* 1 = 0.18958 loss)
I1123 17:23:05.846828 26520 sgd_solver.cpp:105] Iteration 22600, lr = 1e-06
I1123 17:23:10.645894 26520 solver.cpp:218] Iteration 22700 (20.84 iter/s, 4.79846s/100 iters), loss = 0.203513
I1123 17:23:10.645894 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:23:10.645894 26520 solver.cpp:237]     Train net output #1: loss = 0.203513 (* 1 = 0.203513 loss)
I1123 17:23:10.645894 26520 sgd_solver.cpp:105] Iteration 22700, lr = 1e-06
I1123 17:23:15.441264 26520 solver.cpp:218] Iteration 22800 (20.8547 iter/s, 4.79509s/100 iters), loss = 0.171698
I1123 17:23:15.441264 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:23:15.441264 26520 solver.cpp:237]     Train net output #1: loss = 0.171698 (* 1 = 0.171698 loss)
I1123 17:23:15.441264 26520 sgd_solver.cpp:105] Iteration 22800, lr = 1e-06
I1123 17:23:20.237040 26520 solver.cpp:218] Iteration 22900 (20.8539 iter/s, 4.79527s/100 iters), loss = 0.169687
I1123 17:23:20.237040 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:23:20.237040 26520 solver.cpp:237]     Train net output #1: loss = 0.169687 (* 1 = 0.169687 loss)
I1123 17:23:20.237040 26520 sgd_solver.cpp:105] Iteration 22900, lr = 1e-06
I1123 17:23:24.798498  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:23:24.987778 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_23000.caffemodel
I1123 17:23:24.998776 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_23000.solverstate
I1123 17:23:25.003281 26520 solver.cpp:330] Iteration 23000, Testing net (#0)
I1123 17:23:25.003281 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:23:26.267603 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:23:26.317548 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8846
I1123 17:23:26.317548 26520 solver.cpp:397]     Test net output #1: loss = 0.339671 (* 1 = 0.339671 loss)
I1123 17:23:26.363550 26520 solver.cpp:218] Iteration 23000 (16.322 iter/s, 6.12669s/100 iters), loss = 0.192159
I1123 17:23:26.363550 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:23:26.363550 26520 solver.cpp:237]     Train net output #1: loss = 0.192159 (* 1 = 0.192159 loss)
I1123 17:23:26.363550 26520 sgd_solver.cpp:105] Iteration 23000, lr = 1e-06
I1123 17:23:31.158203 26520 solver.cpp:218] Iteration 23100 (20.8605 iter/s, 4.79375s/100 iters), loss = 0.221985
I1123 17:23:31.158203 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:23:31.158203 26520 solver.cpp:237]     Train net output #1: loss = 0.221985 (* 1 = 0.221985 loss)
I1123 17:23:31.158203 26520 sgd_solver.cpp:105] Iteration 23100, lr = 1e-06
I1123 17:23:35.950887 26520 solver.cpp:218] Iteration 23200 (20.868 iter/s, 4.79202s/100 iters), loss = 0.187446
I1123 17:23:35.950887 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:23:35.950887 26520 solver.cpp:237]     Train net output #1: loss = 0.187445 (* 1 = 0.187445 loss)
I1123 17:23:35.950887 26520 sgd_solver.cpp:105] Iteration 23200, lr = 1e-06
I1123 17:23:40.747895 26520 solver.cpp:218] Iteration 23300 (20.8464 iter/s, 4.797s/100 iters), loss = 0.183207
I1123 17:23:40.747895 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:23:40.747895 26520 solver.cpp:237]     Train net output #1: loss = 0.183206 (* 1 = 0.183206 loss)
I1123 17:23:40.747895 26520 sgd_solver.cpp:105] Iteration 23300, lr = 1e-06
I1123 17:23:45.542291 26520 solver.cpp:218] Iteration 23400 (20.8595 iter/s, 4.79399s/100 iters), loss = 0.192416
I1123 17:23:45.542291 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:23:45.542291 26520 solver.cpp:237]     Train net output #1: loss = 0.192415 (* 1 = 0.192415 loss)
I1123 17:23:45.542291 26520 sgd_solver.cpp:105] Iteration 23400, lr = 1e-06
I1123 17:23:50.103572  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:23:50.292623 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_23500.caffemodel
I1123 17:23:50.303617 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_23500.solverstate
I1123 17:23:50.307615 26520 solver.cpp:330] Iteration 23500, Testing net (#0)
I1123 17:23:50.307615 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:23:51.572180 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:23:51.622701 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8847
I1123 17:23:51.622701 26520 solver.cpp:397]     Test net output #1: loss = 0.339625 (* 1 = 0.339625 loss)
I1123 17:23:51.668213 26520 solver.cpp:218] Iteration 23500 (16.3244 iter/s, 6.12579s/100 iters), loss = 0.198572
I1123 17:23:51.668213 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:23:51.668213 26520 solver.cpp:237]     Train net output #1: loss = 0.198572 (* 1 = 0.198572 loss)
I1123 17:23:51.669214 26520 sgd_solver.cpp:105] Iteration 23500, lr = 1e-06
I1123 17:23:56.463938 26520 solver.cpp:218] Iteration 23600 (20.8536 iter/s, 4.79534s/100 iters), loss = 0.230902
I1123 17:23:56.464942 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:23:56.464942 26520 solver.cpp:237]     Train net output #1: loss = 0.230902 (* 1 = 0.230902 loss)
I1123 17:23:56.464942 26520 sgd_solver.cpp:105] Iteration 23600, lr = 1e-06
I1123 17:24:01.262078 26520 solver.cpp:218] Iteration 23700 (20.847 iter/s, 4.79685s/100 iters), loss = 0.20303
I1123 17:24:01.262078 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:24:01.262078 26520 solver.cpp:237]     Train net output #1: loss = 0.203029 (* 1 = 0.203029 loss)
I1123 17:24:01.262078 26520 sgd_solver.cpp:105] Iteration 23700, lr = 1e-06
I1123 17:24:06.056973 26520 solver.cpp:218] Iteration 23800 (20.8565 iter/s, 4.79466s/100 iters), loss = 0.166674
I1123 17:24:06.056973 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:24:06.056973 26520 solver.cpp:237]     Train net output #1: loss = 0.166673 (* 1 = 0.166673 loss)
I1123 17:24:06.056973 26520 sgd_solver.cpp:105] Iteration 23800, lr = 1e-06
I1123 17:24:10.851696 26520 solver.cpp:218] Iteration 23900 (20.8577 iter/s, 4.7944s/100 iters), loss = 0.124242
I1123 17:24:10.851696 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:24:10.851696 26520 solver.cpp:237]     Train net output #1: loss = 0.124241 (* 1 = 0.124241 loss)
I1123 17:24:10.851696 26520 sgd_solver.cpp:105] Iteration 23900, lr = 1e-06
I1123 17:24:15.413755  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:24:15.602841 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_24000.caffemodel
I1123 17:24:15.613862 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_24000.solverstate
I1123 17:24:15.617861 26520 solver.cpp:330] Iteration 24000, Testing net (#0)
I1123 17:24:15.617861 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:24:16.880266 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:24:16.930264 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8847
I1123 17:24:16.930264 26520 solver.cpp:397]     Test net output #1: loss = 0.33975 (* 1 = 0.33975 loss)
I1123 17:24:16.976891 26520 solver.cpp:218] Iteration 24000 (16.3275 iter/s, 6.12464s/100 iters), loss = 0.170344
I1123 17:24:16.976891 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:24:16.976891 26520 solver.cpp:237]     Train net output #1: loss = 0.170344 (* 1 = 0.170344 loss)
I1123 17:24:16.976891 26520 sgd_solver.cpp:105] Iteration 24000, lr = 1e-06
I1123 17:24:21.773080 26520 solver.cpp:218] Iteration 24100 (20.8497 iter/s, 4.79623s/100 iters), loss = 0.217938
I1123 17:24:21.773080 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:24:21.773080 26520 solver.cpp:237]     Train net output #1: loss = 0.217938 (* 1 = 0.217938 loss)
I1123 17:24:21.773080 26520 sgd_solver.cpp:105] Iteration 24100, lr = 1e-06
I1123 17:24:26.566401 26520 solver.cpp:218] Iteration 24200 (20.8646 iter/s, 4.79281s/100 iters), loss = 0.170913
I1123 17:24:26.566401 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:24:26.566401 26520 solver.cpp:237]     Train net output #1: loss = 0.170913 (* 1 = 0.170913 loss)
I1123 17:24:26.566401 26520 sgd_solver.cpp:105] Iteration 24200, lr = 1e-06
I1123 17:24:31.362576 26520 solver.cpp:218] Iteration 24300 (20.8506 iter/s, 4.79602s/100 iters), loss = 0.177908
I1123 17:24:31.362576 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:24:31.362576 26520 solver.cpp:237]     Train net output #1: loss = 0.177908 (* 1 = 0.177908 loss)
I1123 17:24:31.362576 26520 sgd_solver.cpp:105] Iteration 24300, lr = 1e-06
I1123 17:24:36.158246 26520 solver.cpp:218] Iteration 24400 (20.8555 iter/s, 4.7949s/100 iters), loss = 0.163415
I1123 17:24:36.158246 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:24:36.158246 26520 solver.cpp:237]     Train net output #1: loss = 0.163415 (* 1 = 0.163415 loss)
I1123 17:24:36.158246 26520 sgd_solver.cpp:105] Iteration 24400, lr = 1e-06
I1123 17:24:40.719585  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:24:40.907621 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_24500.caffemodel
I1123 17:24:40.918620 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_24500.solverstate
I1123 17:24:40.922634 26520 solver.cpp:330] Iteration 24500, Testing net (#0)
I1123 17:24:40.922634 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:24:42.185521 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:24:42.235522 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8849
I1123 17:24:42.235522 26520 solver.cpp:397]     Test net output #1: loss = 0.339708 (* 1 = 0.339708 loss)
I1123 17:24:42.281579 26520 solver.cpp:218] Iteration 24500 (16.3306 iter/s, 6.12347s/100 iters), loss = 0.18102
I1123 17:24:42.281579 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:24:42.282595 26520 solver.cpp:237]     Train net output #1: loss = 0.18102 (* 1 = 0.18102 loss)
I1123 17:24:42.282595 26520 sgd_solver.cpp:105] Iteration 24500, lr = 1e-06
I1123 17:24:47.078143 26520 solver.cpp:218] Iteration 24600 (20.8533 iter/s, 4.79541s/100 iters), loss = 0.179123
I1123 17:24:47.078143 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:24:47.078143 26520 solver.cpp:237]     Train net output #1: loss = 0.179122 (* 1 = 0.179122 loss)
I1123 17:24:47.078143 26520 sgd_solver.cpp:105] Iteration 24600, lr = 1e-06
I1123 17:24:51.871799 26520 solver.cpp:218] Iteration 24700 (20.863 iter/s, 4.79317s/100 iters), loss = 0.217327
I1123 17:24:51.871799 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:24:51.871799 26520 solver.cpp:237]     Train net output #1: loss = 0.217326 (* 1 = 0.217326 loss)
I1123 17:24:51.871799 26520 sgd_solver.cpp:105] Iteration 24700, lr = 1e-06
I1123 17:24:56.662948 26520 solver.cpp:218] Iteration 24800 (20.8737 iter/s, 4.79073s/100 iters), loss = 0.189036
I1123 17:24:56.662948 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:24:56.662948 26520 solver.cpp:237]     Train net output #1: loss = 0.189035 (* 1 = 0.189035 loss)
I1123 17:24:56.662948 26520 sgd_solver.cpp:105] Iteration 24800, lr = 1e-06
I1123 17:25:01.457114 26520 solver.cpp:218] Iteration 24900 (20.8608 iter/s, 4.79369s/100 iters), loss = 0.152582
I1123 17:25:01.457114 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:25:01.457114 26520 solver.cpp:237]     Train net output #1: loss = 0.152582 (* 1 = 0.152582 loss)
I1123 17:25:01.457114 26520 sgd_solver.cpp:105] Iteration 24900, lr = 1e-06
I1123 17:25:06.013466  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:25:06.202073 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_25000.caffemodel
I1123 17:25:06.213055 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_25000.solverstate
I1123 17:25:06.217072 26520 solver.cpp:330] Iteration 25000, Testing net (#0)
I1123 17:25:06.217072 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:25:07.479194 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:25:07.528700 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8846
I1123 17:25:07.528700 26520 solver.cpp:397]     Test net output #1: loss = 0.33973 (* 1 = 0.33973 loss)
I1123 17:25:07.575729 26520 solver.cpp:218] Iteration 25000 (16.3443 iter/s, 6.11835s/100 iters), loss = 0.231887
I1123 17:25:07.575729 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:25:07.575729 26520 solver.cpp:237]     Train net output #1: loss = 0.231886 (* 1 = 0.231886 loss)
I1123 17:25:07.575729 26520 sgd_solver.cpp:105] Iteration 25000, lr = 1e-06
I1123 17:25:12.368409 26520 solver.cpp:218] Iteration 25100 (20.8671 iter/s, 4.79223s/100 iters), loss = 0.233121
I1123 17:25:12.368409 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:25:12.368409 26520 solver.cpp:237]     Train net output #1: loss = 0.233121 (* 1 = 0.233121 loss)
I1123 17:25:12.368409 26520 sgd_solver.cpp:105] Iteration 25100, lr = 1e-06
I1123 17:25:17.158457 26520 solver.cpp:218] Iteration 25200 (20.8776 iter/s, 4.78983s/100 iters), loss = 0.143681
I1123 17:25:17.158457 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:25:17.158457 26520 solver.cpp:237]     Train net output #1: loss = 0.143681 (* 1 = 0.143681 loss)
I1123 17:25:17.158457 26520 sgd_solver.cpp:105] Iteration 25200, lr = 1e-06
I1123 17:25:21.957756 26520 solver.cpp:218] Iteration 25300 (20.8386 iter/s, 4.79878s/100 iters), loss = 0.193871
I1123 17:25:21.957756 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:25:21.957756 26520 solver.cpp:237]     Train net output #1: loss = 0.193871 (* 1 = 0.193871 loss)
I1123 17:25:21.957756 26520 sgd_solver.cpp:105] Iteration 25300, lr = 1e-06
I1123 17:25:26.753656 26520 solver.cpp:218] Iteration 25400 (20.8533 iter/s, 4.79542s/100 iters), loss = 0.181097
I1123 17:25:26.753656 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:25:26.753656 26520 solver.cpp:237]     Train net output #1: loss = 0.181097 (* 1 = 0.181097 loss)
I1123 17:25:26.753656 26520 sgd_solver.cpp:105] Iteration 25400, lr = 1e-06
I1123 17:25:31.311050  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:25:31.498744 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_25500.caffemodel
I1123 17:25:31.508743 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_25500.solverstate
I1123 17:25:31.512743 26520 solver.cpp:330] Iteration 25500, Testing net (#0)
I1123 17:25:31.512743 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:25:32.776901 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:25:32.826905 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8846
I1123 17:25:32.826905 26520 solver.cpp:397]     Test net output #1: loss = 0.339759 (* 1 = 0.339759 loss)
I1123 17:25:32.873412 26520 solver.cpp:218] Iteration 25500 (16.3417 iter/s, 6.11932s/100 iters), loss = 0.205741
I1123 17:25:32.873412 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:25:32.873412 26520 solver.cpp:237]     Train net output #1: loss = 0.20574 (* 1 = 0.20574 loss)
I1123 17:25:32.873412 26520 sgd_solver.cpp:105] Iteration 25500, lr = 1e-06
I1123 17:25:37.670711 26520 solver.cpp:218] Iteration 25600 (20.8463 iter/s, 4.79701s/100 iters), loss = 0.243465
I1123 17:25:37.670711 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:25:37.670711 26520 solver.cpp:237]     Train net output #1: loss = 0.243465 (* 1 = 0.243465 loss)
I1123 17:25:37.670711 26520 sgd_solver.cpp:105] Iteration 25600, lr = 1e-06
I1123 17:25:42.465229 26520 solver.cpp:218] Iteration 25700 (20.8592 iter/s, 4.79404s/100 iters), loss = 0.149159
I1123 17:25:42.465229 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:25:42.465229 26520 solver.cpp:237]     Train net output #1: loss = 0.149159 (* 1 = 0.149159 loss)
I1123 17:25:42.465229 26520 sgd_solver.cpp:105] Iteration 25700, lr = 1e-06
I1123 17:25:47.259414 26520 solver.cpp:218] Iteration 25800 (20.8587 iter/s, 4.79416s/100 iters), loss = 0.204847
I1123 17:25:47.259414 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:25:47.259414 26520 solver.cpp:237]     Train net output #1: loss = 0.204847 (* 1 = 0.204847 loss)
I1123 17:25:47.259414 26520 sgd_solver.cpp:105] Iteration 25800, lr = 1e-06
I1123 17:25:52.051852 26520 solver.cpp:218] Iteration 25900 (20.8669 iter/s, 4.79228s/100 iters), loss = 0.160502
I1123 17:25:52.051852 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:25:52.051852 26520 solver.cpp:237]     Train net output #1: loss = 0.160502 (* 1 = 0.160502 loss)
I1123 17:25:52.051852 26520 sgd_solver.cpp:105] Iteration 25900, lr = 1e-06
I1123 17:25:56.614689  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:25:56.803242 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_26000.caffemodel
I1123 17:25:56.815255 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_26000.solverstate
I1123 17:25:56.819253 26520 solver.cpp:330] Iteration 26000, Testing net (#0)
I1123 17:25:56.819253 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:25:58.082399 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:25:58.131916 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8848
I1123 17:25:58.131916 26520 solver.cpp:397]     Test net output #1: loss = 0.339645 (* 1 = 0.339645 loss)
I1123 17:25:58.178928 26520 solver.cpp:218] Iteration 26000 (16.324 iter/s, 6.12595s/100 iters), loss = 0.199884
I1123 17:25:58.178928 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:25:58.178928 26520 solver.cpp:237]     Train net output #1: loss = 0.199884 (* 1 = 0.199884 loss)
I1123 17:25:58.178928 26520 sgd_solver.cpp:105] Iteration 26000, lr = 1e-06
I1123 17:26:02.974354 26520 solver.cpp:218] Iteration 26100 (20.8522 iter/s, 4.79565s/100 iters), loss = 0.208188
I1123 17:26:02.974354 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:26:02.974354 26520 solver.cpp:237]     Train net output #1: loss = 0.208188 (* 1 = 0.208188 loss)
I1123 17:26:02.974354 26520 sgd_solver.cpp:105] Iteration 26100, lr = 1e-06
I1123 17:26:07.772658 26520 solver.cpp:218] Iteration 26200 (20.8446 iter/s, 4.79741s/100 iters), loss = 0.124834
I1123 17:26:07.772658 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:26:07.772658 26520 solver.cpp:237]     Train net output #1: loss = 0.124833 (* 1 = 0.124833 loss)
I1123 17:26:07.772658 26520 sgd_solver.cpp:105] Iteration 26200, lr = 1e-06
I1123 17:26:12.569536 26520 solver.cpp:218] Iteration 26300 (20.8493 iter/s, 4.79633s/100 iters), loss = 0.191111
I1123 17:26:12.569536 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:26:12.569536 26520 solver.cpp:237]     Train net output #1: loss = 0.191111 (* 1 = 0.191111 loss)
I1123 17:26:12.569536 26520 sgd_solver.cpp:105] Iteration 26300, lr = 1e-06
I1123 17:26:17.362069 26520 solver.cpp:218] Iteration 26400 (20.8645 iter/s, 4.79282s/100 iters), loss = 0.173359
I1123 17:26:17.362069 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:26:17.362069 26520 solver.cpp:237]     Train net output #1: loss = 0.173359 (* 1 = 0.173359 loss)
I1123 17:26:17.362069 26520 sgd_solver.cpp:105] Iteration 26400, lr = 1e-06
I1123 17:26:21.920989  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:26:22.110028 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_26500.caffemodel
I1123 17:26:22.119026 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_26500.solverstate
I1123 17:26:22.123028 26520 solver.cpp:330] Iteration 26500, Testing net (#0)
I1123 17:26:22.123028 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:26:23.386631 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:26:23.436146 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8847
I1123 17:26:23.436146 26520 solver.cpp:397]     Test net output #1: loss = 0.339761 (* 1 = 0.339761 loss)
I1123 17:26:23.482142 26520 solver.cpp:218] Iteration 26500 (16.3408 iter/s, 6.11966s/100 iters), loss = 0.156997
I1123 17:26:23.482142 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:26:23.482142 26520 solver.cpp:237]     Train net output #1: loss = 0.156997 (* 1 = 0.156997 loss)
I1123 17:26:23.482142 26520 sgd_solver.cpp:105] Iteration 26500, lr = 1e-06
I1123 17:26:28.279619 26520 solver.cpp:218] Iteration 26600 (20.8482 iter/s, 4.79659s/100 iters), loss = 0.234949
I1123 17:26:28.279619 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:26:28.279619 26520 solver.cpp:237]     Train net output #1: loss = 0.234949 (* 1 = 0.234949 loss)
I1123 17:26:28.279619 26520 sgd_solver.cpp:105] Iteration 26600, lr = 1e-06
I1123 17:26:33.074651 26520 solver.cpp:218] Iteration 26700 (20.8581 iter/s, 4.7943s/100 iters), loss = 0.155875
I1123 17:26:33.074651 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:26:33.074651 26520 solver.cpp:237]     Train net output #1: loss = 0.155875 (* 1 = 0.155875 loss)
I1123 17:26:33.074651 26520 sgd_solver.cpp:105] Iteration 26700, lr = 1e-06
I1123 17:26:37.869195 26520 solver.cpp:218] Iteration 26800 (20.8551 iter/s, 4.79498s/100 iters), loss = 0.185359
I1123 17:26:37.869195 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:26:37.869195 26520 solver.cpp:237]     Train net output #1: loss = 0.185358 (* 1 = 0.185358 loss)
I1123 17:26:37.869195 26520 sgd_solver.cpp:105] Iteration 26800, lr = 1e-06
I1123 17:26:42.661280 26520 solver.cpp:218] Iteration 26900 (20.8698 iter/s, 4.79162s/100 iters), loss = 0.154419
I1123 17:26:42.661280 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:26:42.661280 26520 solver.cpp:237]     Train net output #1: loss = 0.154418 (* 1 = 0.154418 loss)
I1123 17:26:42.661280 26520 sgd_solver.cpp:105] Iteration 26900, lr = 1e-06
I1123 17:26:47.222043  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:26:47.410099 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_27000.caffemodel
I1123 17:26:47.420101 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_27000.solverstate
I1123 17:26:47.424101 26520 solver.cpp:330] Iteration 27000, Testing net (#0)
I1123 17:26:47.424101 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:26:48.687587 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:26:48.738158 26520 solver.cpp:397]     Test net output #0: accuracy = 0.885
I1123 17:26:48.738158 26520 solver.cpp:397]     Test net output #1: loss = 0.339611 (* 1 = 0.339611 loss)
I1123 17:26:48.784173 26520 solver.cpp:218] Iteration 27000 (16.3331 iter/s, 6.12253s/100 iters), loss = 0.190951
I1123 17:26:48.784173 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:26:48.784173 26520 solver.cpp:237]     Train net output #1: loss = 0.19095 (* 1 = 0.19095 loss)
I1123 17:26:48.784173 26520 sgd_solver.cpp:46] MultiStep Status: Iteration 27000, step = 6
I1123 17:26:48.784173 26520 sgd_solver.cpp:105] Iteration 27000, lr = 1e-07
I1123 17:26:53.583902 26520 solver.cpp:218] Iteration 27100 (20.8371 iter/s, 4.79914s/100 iters), loss = 0.253304
I1123 17:26:53.583902 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:26:53.583902 26520 solver.cpp:237]     Train net output #1: loss = 0.253303 (* 1 = 0.253303 loss)
I1123 17:26:53.583902 26520 sgd_solver.cpp:105] Iteration 27100, lr = 1e-07
I1123 17:26:58.377789 26520 solver.cpp:218] Iteration 27200 (20.8645 iter/s, 4.79284s/100 iters), loss = 0.21118
I1123 17:26:58.377789 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:26:58.377789 26520 solver.cpp:237]     Train net output #1: loss = 0.21118 (* 1 = 0.21118 loss)
I1123 17:26:58.377789 26520 sgd_solver.cpp:105] Iteration 27200, lr = 1e-07
I1123 17:27:03.173832 26520 solver.cpp:218] Iteration 27300 (20.8523 iter/s, 4.79564s/100 iters), loss = 0.180847
I1123 17:27:03.173832 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:27:03.173832 26520 solver.cpp:237]     Train net output #1: loss = 0.180847 (* 1 = 0.180847 loss)
I1123 17:27:03.173832 26520 sgd_solver.cpp:105] Iteration 27300, lr = 1e-07
I1123 17:27:07.969677 26520 solver.cpp:218] Iteration 27400 (20.8525 iter/s, 4.79559s/100 iters), loss = 0.151318
I1123 17:27:07.969677 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:27:07.969677 26520 solver.cpp:237]     Train net output #1: loss = 0.151318 (* 1 = 0.151318 loss)
I1123 17:27:07.969677 26520 sgd_solver.cpp:105] Iteration 27400, lr = 1e-07
I1123 17:27:12.531754  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:27:12.720285 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_27500.caffemodel
I1123 17:27:12.729310 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_27500.solverstate
I1123 17:27:12.734309 26520 solver.cpp:330] Iteration 27500, Testing net (#0)
I1123 17:27:12.734309 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:27:13.998531 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:27:14.047569 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8848
I1123 17:27:14.047569 26520 solver.cpp:397]     Test net output #1: loss = 0.339725 (* 1 = 0.339725 loss)
I1123 17:27:14.094564 26520 solver.cpp:218] Iteration 27500 (16.3275 iter/s, 6.12464s/100 iters), loss = 0.195167
I1123 17:27:14.094564 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:27:14.094564 26520 solver.cpp:237]     Train net output #1: loss = 0.195167 (* 1 = 0.195167 loss)
I1123 17:27:14.094564 26520 sgd_solver.cpp:105] Iteration 27500, lr = 1e-07
I1123 17:27:18.887410 26520 solver.cpp:218] Iteration 27600 (20.864 iter/s, 4.79295s/100 iters), loss = 0.173927
I1123 17:27:18.887410 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:27:18.887410 26520 solver.cpp:237]     Train net output #1: loss = 0.173926 (* 1 = 0.173926 loss)
I1123 17:27:18.887410 26520 sgd_solver.cpp:105] Iteration 27600, lr = 1e-07
I1123 17:27:23.683764 26520 solver.cpp:218] Iteration 27700 (20.851 iter/s, 4.79594s/100 iters), loss = 0.157776
I1123 17:27:23.683764 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:27:23.683764 26520 solver.cpp:237]     Train net output #1: loss = 0.157776 (* 1 = 0.157776 loss)
I1123 17:27:23.683764 26520 sgd_solver.cpp:105] Iteration 27700, lr = 1e-07
I1123 17:27:28.478153 26520 solver.cpp:218] Iteration 27800 (20.8596 iter/s, 4.79397s/100 iters), loss = 0.169774
I1123 17:27:28.478153 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:27:28.478153 26520 solver.cpp:237]     Train net output #1: loss = 0.169773 (* 1 = 0.169773 loss)
I1123 17:27:28.478153 26520 sgd_solver.cpp:105] Iteration 27800, lr = 1e-07
I1123 17:27:33.274461 26520 solver.cpp:218] Iteration 27900 (20.8518 iter/s, 4.79575s/100 iters), loss = 0.143714
I1123 17:27:33.274461 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:27:33.274461 26520 solver.cpp:237]     Train net output #1: loss = 0.143714 (* 1 = 0.143714 loss)
I1123 17:27:33.274461 26520 sgd_solver.cpp:105] Iteration 27900, lr = 1e-07
I1123 17:27:37.836285  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:27:38.024865 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_28000.caffemodel
I1123 17:27:38.035343 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_28000.solverstate
I1123 17:27:38.039860 26520 solver.cpp:330] Iteration 28000, Testing net (#0)
I1123 17:27:38.039860 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:27:39.303169 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:27:39.353675 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8845
I1123 17:27:39.353675 26520 solver.cpp:397]     Test net output #1: loss = 0.339799 (* 1 = 0.339799 loss)
I1123 17:27:39.400176 26520 solver.cpp:218] Iteration 28000 (16.3277 iter/s, 6.12456s/100 iters), loss = 0.223768
I1123 17:27:39.400176 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 17:27:39.400176 26520 solver.cpp:237]     Train net output #1: loss = 0.223767 (* 1 = 0.223767 loss)
I1123 17:27:39.400176 26520 sgd_solver.cpp:105] Iteration 28000, lr = 1e-07
I1123 17:27:44.196162 26520 solver.cpp:218] Iteration 28100 (20.8494 iter/s, 4.79629s/100 iters), loss = 0.182794
I1123 17:27:44.196162 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:27:44.196162 26520 solver.cpp:237]     Train net output #1: loss = 0.182793 (* 1 = 0.182793 loss)
I1123 17:27:44.196162 26520 sgd_solver.cpp:105] Iteration 28100, lr = 1e-07
I1123 17:27:48.990533 26520 solver.cpp:218] Iteration 28200 (20.8586 iter/s, 4.7942s/100 iters), loss = 0.15772
I1123 17:27:48.991549 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:27:48.991549 26520 solver.cpp:237]     Train net output #1: loss = 0.157719 (* 1 = 0.157719 loss)
I1123 17:27:48.991549 26520 sgd_solver.cpp:105] Iteration 28200, lr = 1e-07
I1123 17:27:53.782338 26520 solver.cpp:218] Iteration 28300 (20.8711 iter/s, 4.79132s/100 iters), loss = 0.19171
I1123 17:27:53.783344 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:27:53.783344 26520 solver.cpp:237]     Train net output #1: loss = 0.19171 (* 1 = 0.19171 loss)
I1123 17:27:53.783344 26520 sgd_solver.cpp:105] Iteration 28300, lr = 1e-07
I1123 17:27:58.576167 26520 solver.cpp:218] Iteration 28400 (20.8627 iter/s, 4.79323s/100 iters), loss = 0.147793
I1123 17:27:58.576167 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:27:58.576167 26520 solver.cpp:237]     Train net output #1: loss = 0.147792 (* 1 = 0.147792 loss)
I1123 17:27:58.576167 26520 sgd_solver.cpp:105] Iteration 28400, lr = 1e-07
I1123 17:28:03.134829  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:28:03.323442 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_28500.caffemodel
I1123 17:28:03.333438 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_28500.solverstate
I1123 17:28:03.337440 26520 solver.cpp:330] Iteration 28500, Testing net (#0)
I1123 17:28:03.337440 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:28:04.600729 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:28:04.650733 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8846
I1123 17:28:04.650733 26520 solver.cpp:397]     Test net output #1: loss = 0.339743 (* 1 = 0.339743 loss)
I1123 17:28:04.696437 26520 solver.cpp:218] Iteration 28500 (16.3399 iter/s, 6.11999s/100 iters), loss = 0.203451
I1123 17:28:04.697438 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:28:04.697438 26520 solver.cpp:237]     Train net output #1: loss = 0.203451 (* 1 = 0.203451 loss)
I1123 17:28:04.697438 26520 sgd_solver.cpp:105] Iteration 28500, lr = 1e-07
I1123 17:28:09.493273 26520 solver.cpp:218] Iteration 28600 (20.853 iter/s, 4.79546s/100 iters), loss = 0.212927
I1123 17:28:09.493273 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 17:28:09.493273 26520 solver.cpp:237]     Train net output #1: loss = 0.212927 (* 1 = 0.212927 loss)
I1123 17:28:09.493273 26520 sgd_solver.cpp:105] Iteration 28600, lr = 1e-07
I1123 17:28:14.286895 26520 solver.cpp:218] Iteration 28700 (20.8591 iter/s, 4.79407s/100 iters), loss = 0.199889
I1123 17:28:14.286895 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:28:14.286895 26520 solver.cpp:237]     Train net output #1: loss = 0.199889 (* 1 = 0.199889 loss)
I1123 17:28:14.286895 26520 sgd_solver.cpp:105] Iteration 28700, lr = 1e-07
I1123 17:28:19.082702 26520 solver.cpp:218] Iteration 28800 (20.8545 iter/s, 4.79513s/100 iters), loss = 0.218837
I1123 17:28:19.082702 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:28:19.082702 26520 solver.cpp:237]     Train net output #1: loss = 0.218837 (* 1 = 0.218837 loss)
I1123 17:28:19.082702 26520 sgd_solver.cpp:105] Iteration 28800, lr = 1e-07
I1123 17:28:23.877897 26520 solver.cpp:218] Iteration 28900 (20.8579 iter/s, 4.79434s/100 iters), loss = 0.16486
I1123 17:28:23.877897 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:28:23.877897 26520 solver.cpp:237]     Train net output #1: loss = 0.16486 (* 1 = 0.16486 loss)
I1123 17:28:23.877897 26520 sgd_solver.cpp:105] Iteration 28900, lr = 1e-07
I1123 17:28:28.437908  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:28:28.625969 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_29000.caffemodel
I1123 17:28:28.635974 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_29000.solverstate
I1123 17:28:28.639969 26520 solver.cpp:330] Iteration 29000, Testing net (#0)
I1123 17:28:28.639969 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:28:29.902498 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:28:29.952497 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8847
I1123 17:28:29.952497 26520 solver.cpp:397]     Test net output #1: loss = 0.339788 (* 1 = 0.339788 loss)
I1123 17:28:29.998524 26520 solver.cpp:218] Iteration 29000 (16.3388 iter/s, 6.12041s/100 iters), loss = 0.20879
I1123 17:28:29.998524 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:28:29.998524 26520 solver.cpp:237]     Train net output #1: loss = 0.208789 (* 1 = 0.208789 loss)
I1123 17:28:29.998524 26520 sgd_solver.cpp:105] Iteration 29000, lr = 1e-07
I1123 17:28:34.792966 26520 solver.cpp:218] Iteration 29100 (20.8598 iter/s, 4.7939s/100 iters), loss = 0.219964
I1123 17:28:34.792966 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 17:28:34.792966 26520 solver.cpp:237]     Train net output #1: loss = 0.219963 (* 1 = 0.219963 loss)
I1123 17:28:34.792966 26520 sgd_solver.cpp:105] Iteration 29100, lr = 1e-07
I1123 17:28:39.593806 26520 solver.cpp:218] Iteration 29200 (20.8302 iter/s, 4.80071s/100 iters), loss = 0.158806
I1123 17:28:39.594306 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:28:39.594306 26520 solver.cpp:237]     Train net output #1: loss = 0.158806 (* 1 = 0.158806 loss)
I1123 17:28:39.594306 26520 sgd_solver.cpp:105] Iteration 29200, lr = 1e-07
I1123 17:28:44.388756 26520 solver.cpp:218] Iteration 29300 (20.8584 iter/s, 4.79423s/100 iters), loss = 0.198455
I1123 17:28:44.388756 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:28:44.388756 26520 solver.cpp:237]     Train net output #1: loss = 0.198455 (* 1 = 0.198455 loss)
I1123 17:28:44.388756 26520 sgd_solver.cpp:105] Iteration 29300, lr = 1e-07
I1123 17:28:49.186722 26520 solver.cpp:218] Iteration 29400 (20.843 iter/s, 4.79776s/100 iters), loss = 0.154926
I1123 17:28:49.186722 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:28:49.186722 26520 solver.cpp:237]     Train net output #1: loss = 0.154926 (* 1 = 0.154926 loss)
I1123 17:28:49.186722 26520 sgd_solver.cpp:105] Iteration 29400, lr = 1e-07
I1123 17:28:53.749049  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:28:53.938978 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_29500.caffemodel
I1123 17:28:53.949991 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_29500.solverstate
I1123 17:28:53.953991 26520 solver.cpp:330] Iteration 29500, Testing net (#0)
I1123 17:28:53.953991 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:28:55.218195 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:28:55.268184 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8849
I1123 17:28:55.268184 26520 solver.cpp:397]     Test net output #1: loss = 0.339723 (* 1 = 0.339723 loss)
I1123 17:28:55.313709 26520 solver.cpp:218] Iteration 29500 (16.3208 iter/s, 6.12715s/100 iters), loss = 0.182673
I1123 17:28:55.313709 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 17:28:55.313709 26520 solver.cpp:237]     Train net output #1: loss = 0.182673 (* 1 = 0.182673 loss)
I1123 17:28:55.313709 26520 sgd_solver.cpp:105] Iteration 29500, lr = 1e-07
I1123 17:29:00.105732 26520 solver.cpp:218] Iteration 29600 (20.8716 iter/s, 4.7912s/100 iters), loss = 0.19594
I1123 17:29:00.105732 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:29:00.105732 26520 solver.cpp:237]     Train net output #1: loss = 0.19594 (* 1 = 0.19594 loss)
I1123 17:29:00.105732 26520 sgd_solver.cpp:105] Iteration 29600, lr = 1e-07
I1123 17:29:04.899991 26520 solver.cpp:218] Iteration 29700 (20.8604 iter/s, 4.79377s/100 iters), loss = 0.169521
I1123 17:29:04.899991 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 17:29:04.899991 26520 solver.cpp:237]     Train net output #1: loss = 0.169521 (* 1 = 0.169521 loss)
I1123 17:29:04.900496 26520 sgd_solver.cpp:105] Iteration 29700, lr = 1e-07
I1123 17:29:09.688516 26520 solver.cpp:218] Iteration 29800 (20.8827 iter/s, 4.78865s/100 iters), loss = 0.169676
I1123 17:29:09.689520 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 17:29:09.689520 26520 solver.cpp:237]     Train net output #1: loss = 0.169676 (* 1 = 0.169676 loss)
I1123 17:29:09.689520 26520 sgd_solver.cpp:105] Iteration 29800, lr = 1e-07
I1123 17:29:14.482985 26520 solver.cpp:218] Iteration 29900 (20.8632 iter/s, 4.79314s/100 iters), loss = 0.13924
I1123 17:29:14.482985 26520 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 17:29:14.482985 26520 solver.cpp:237]     Train net output #1: loss = 0.13924 (* 1 = 0.13924 loss)
I1123 17:29:14.482985 26520 sgd_solver.cpp:105] Iteration 29900, lr = 1e-07
I1123 17:29:19.039815  6556 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:29:19.228992 26520 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_30000.caffemodel
I1123 17:29:19.238975 26520 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_300k_8L_7x7_F2L_iter_30000.solverstate
I1123 17:29:19.257974 26520 solver.cpp:310] Iteration 30000, loss = 0.201753
I1123 17:29:19.257974 26520 solver.cpp:330] Iteration 30000, Testing net (#0)
I1123 17:29:19.257974 26520 net.cpp:676] Ignoring source layer accuracy_training
I1123 17:29:20.520686 14276 data_layer.cpp:73] Restarting data prefetching from start.
I1123 17:29:20.570667 26520 solver.cpp:397]     Test net output #0: accuracy = 0.8845
I1123 17:29:20.570667 26520 solver.cpp:397]     Test net output #1: loss = 0.339664 (* 1 = 0.339664 loss)
I1123 17:29:20.570667 26520 solver.cpp:315] Optimization Done.
I1123 17:29:20.570667 26520 caffe.cpp:260] Optimization Done.

G:\Caffe>pause
Press any key to continue . . . 
