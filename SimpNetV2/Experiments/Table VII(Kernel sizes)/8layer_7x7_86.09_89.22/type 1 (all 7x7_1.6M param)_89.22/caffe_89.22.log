
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I1123 18:53:33.191191 14064 caffe.cpp:219] Using GPUs 0
I1123 18:53:33.353699 14064 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1123 18:53:33.646761 14064 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1123 18:53:33.662761 14064 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 30000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar10/snaps/slimnet_1.6M_8L_7x7"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 5000
stepvalue: 9500
stepvalue: 15300
stepvalue: 19500
stepvalue: 22000
stepvalue: 27000
type: "AdaDelta"
I1123 18:53:33.663767 14064 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1123 18:53:33.663767 14064 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1123 18:53:33.663767 14064 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1123 18:53:33.663767 14064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1123 18:53:33.663767 14064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1123 18:53:33.663767 14064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1123 18:53:33.663767 14064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1123 18:53:33.663767 14064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1123 18:53:33.663767 14064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1123 18:53:33.663767 14064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1123 18:53:33.663767 14064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1123 18:53:33.663767 14064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1123 18:53:33.663767 14064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1123 18:53:33.663767 14064 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_8L_Simple_7x7_1.6M"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb_zeropad"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 41
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 43
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 85
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 3
    kernel_size: 7
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1123 18:53:33.666760 14064 layer_factory.cpp:58] Creating layer cifar
I1123 18:53:33.671758 14064 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb_zeropad
I1123 18:53:33.671758 14064 net.cpp:84] Creating Layer cifar
I1123 18:53:33.671758 14064 net.cpp:380] cifar -> data
I1123 18:53:33.671758 14064 net.cpp:380] cifar -> label
I1123 18:53:33.672762 14064 data_layer.cpp:45] output data size: 100,3,32,32
I1123 18:53:33.677762 14064 net.cpp:122] Setting up cifar
I1123 18:53:33.677762 14064 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1123 18:53:33.677762 14064 net.cpp:129] Top shape: 100 (100)
I1123 18:53:33.678771 14064 net.cpp:137] Memory required for data: 1229200
I1123 18:53:33.678771 14064 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1123 18:53:33.678771 14064 net.cpp:84] Creating Layer label_cifar_1_split
I1123 18:53:33.678771 14064 net.cpp:406] label_cifar_1_split <- label
I1123 18:53:33.678771 14064 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1123 18:53:33.678771 14064 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1123 18:53:33.678771 14064 net.cpp:122] Setting up label_cifar_1_split
I1123 18:53:33.678771 14064 net.cpp:129] Top shape: 100 (100)
I1123 18:53:33.678771 14064 net.cpp:129] Top shape: 100 (100)
I1123 18:53:33.678771 14064 net.cpp:137] Memory required for data: 1230000
I1123 18:53:33.678771 14064 layer_factory.cpp:58] Creating layer conv1
I1123 18:53:33.678771 14064 net.cpp:84] Creating Layer conv1
I1123 18:53:33.678771 14064 net.cpp:406] conv1 <- data
I1123 18:53:33.678771 14064 net.cpp:380] conv1 -> conv1
I1123 18:53:33.680759  4236 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1123 18:53:33.925801 14064 net.cpp:122] Setting up conv1
I1123 18:53:33.925801 14064 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1123 18:53:33.925801 14064 net.cpp:137] Memory required for data: 18023600
I1123 18:53:33.925801 14064 layer_factory.cpp:58] Creating layer bn1
I1123 18:53:33.925801 14064 net.cpp:84] Creating Layer bn1
I1123 18:53:33.925801 14064 net.cpp:406] bn1 <- conv1
I1123 18:53:33.925801 14064 net.cpp:367] bn1 -> conv1 (in-place)
I1123 18:53:33.925801 14064 net.cpp:122] Setting up bn1
I1123 18:53:33.925801 14064 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1123 18:53:33.925801 14064 net.cpp:137] Memory required for data: 34817200
I1123 18:53:33.925801 14064 layer_factory.cpp:58] Creating layer scale1
I1123 18:53:33.925801 14064 net.cpp:84] Creating Layer scale1
I1123 18:53:33.925801 14064 net.cpp:406] scale1 <- conv1
I1123 18:53:33.925801 14064 net.cpp:367] scale1 -> conv1 (in-place)
I1123 18:53:33.925801 14064 layer_factory.cpp:58] Creating layer scale1
I1123 18:53:33.925801 14064 net.cpp:122] Setting up scale1
I1123 18:53:33.925801 14064 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1123 18:53:33.925801 14064 net.cpp:137] Memory required for data: 51610800
I1123 18:53:33.925801 14064 layer_factory.cpp:58] Creating layer relu1
I1123 18:53:33.925801 14064 net.cpp:84] Creating Layer relu1
I1123 18:53:33.925801 14064 net.cpp:406] relu1 <- conv1
I1123 18:53:33.925801 14064 net.cpp:367] relu1 -> conv1 (in-place)
I1123 18:53:33.925801 14064 net.cpp:122] Setting up relu1
I1123 18:53:33.925801 14064 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1123 18:53:33.925801 14064 net.cpp:137] Memory required for data: 68404400
I1123 18:53:33.925801 14064 layer_factory.cpp:58] Creating layer conv2
I1123 18:53:33.925801 14064 net.cpp:84] Creating Layer conv2
I1123 18:53:33.925801 14064 net.cpp:406] conv2 <- conv1
I1123 18:53:33.925801 14064 net.cpp:380] conv2 -> conv2
I1123 18:53:33.927801 14064 net.cpp:122] Setting up conv2
I1123 18:53:33.927801 14064 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1123 18:53:33.927801 14064 net.cpp:137] Memory required for data: 86017200
I1123 18:53:33.927801 14064 layer_factory.cpp:58] Creating layer bn2
I1123 18:53:33.927801 14064 net.cpp:84] Creating Layer bn2
I1123 18:53:33.927801 14064 net.cpp:406] bn2 <- conv2
I1123 18:53:33.927801 14064 net.cpp:367] bn2 -> conv2 (in-place)
I1123 18:53:33.927801 14064 net.cpp:122] Setting up bn2
I1123 18:53:33.927801 14064 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1123 18:53:33.927801 14064 net.cpp:137] Memory required for data: 103630000
I1123 18:53:33.927801 14064 layer_factory.cpp:58] Creating layer scale2
I1123 18:53:33.927801 14064 net.cpp:84] Creating Layer scale2
I1123 18:53:33.927801 14064 net.cpp:406] scale2 <- conv2
I1123 18:53:33.927801 14064 net.cpp:367] scale2 -> conv2 (in-place)
I1123 18:53:33.927801 14064 layer_factory.cpp:58] Creating layer scale2
I1123 18:53:33.927801 14064 net.cpp:122] Setting up scale2
I1123 18:53:33.927801 14064 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1123 18:53:33.927801 14064 net.cpp:137] Memory required for data: 121242800
I1123 18:53:33.927801 14064 layer_factory.cpp:58] Creating layer relu2
I1123 18:53:33.927801 14064 net.cpp:84] Creating Layer relu2
I1123 18:53:33.927801 14064 net.cpp:406] relu2 <- conv2
I1123 18:53:33.927801 14064 net.cpp:367] relu2 -> conv2 (in-place)
I1123 18:53:33.928804 14064 net.cpp:122] Setting up relu2
I1123 18:53:33.928804 14064 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1123 18:53:33.928804 14064 net.cpp:137] Memory required for data: 138855600
I1123 18:53:33.928804 14064 layer_factory.cpp:58] Creating layer conv2_2
I1123 18:53:33.928804 14064 net.cpp:84] Creating Layer conv2_2
I1123 18:53:33.928804 14064 net.cpp:406] conv2_2 <- conv2
I1123 18:53:33.928804 14064 net.cpp:380] conv2_2 -> conv2_2
I1123 18:53:34.078887 14064 net.cpp:122] Setting up conv2_2
I1123 18:53:34.078887 14064 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1123 18:53:34.078887 14064 net.cpp:137] Memory required for data: 167527600
I1123 18:53:34.078887 14064 layer_factory.cpp:58] Creating layer bn2_2
I1123 18:53:34.078887 14064 net.cpp:84] Creating Layer bn2_2
I1123 18:53:34.078887 14064 net.cpp:406] bn2_2 <- conv2_2
I1123 18:53:34.078887 14064 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1123 18:53:34.078887 14064 net.cpp:122] Setting up bn2_2
I1123 18:53:34.078887 14064 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1123 18:53:34.078887 14064 net.cpp:137] Memory required for data: 196199600
I1123 18:53:34.078887 14064 layer_factory.cpp:58] Creating layer scale2_2
I1123 18:53:34.078887 14064 net.cpp:84] Creating Layer scale2_2
I1123 18:53:34.078887 14064 net.cpp:406] scale2_2 <- conv2_2
I1123 18:53:34.078887 14064 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1123 18:53:34.078887 14064 layer_factory.cpp:58] Creating layer scale2_2
I1123 18:53:34.078887 14064 net.cpp:122] Setting up scale2_2
I1123 18:53:34.078887 14064 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1123 18:53:34.078887 14064 net.cpp:137] Memory required for data: 224871600
I1123 18:53:34.078887 14064 layer_factory.cpp:58] Creating layer relu2_2
I1123 18:53:34.078887 14064 net.cpp:84] Creating Layer relu2_2
I1123 18:53:34.078887 14064 net.cpp:406] relu2_2 <- conv2_2
I1123 18:53:34.078887 14064 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1123 18:53:34.079887 14064 net.cpp:122] Setting up relu2_2
I1123 18:53:34.079887 14064 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1123 18:53:34.079887 14064 net.cpp:137] Memory required for data: 253543600
I1123 18:53:34.079887 14064 layer_factory.cpp:58] Creating layer pool2_1
I1123 18:53:34.079887 14064 net.cpp:84] Creating Layer pool2_1
I1123 18:53:34.079887 14064 net.cpp:406] pool2_1 <- conv2_2
I1123 18:53:34.079887 14064 net.cpp:380] pool2_1 -> pool2_1
I1123 18:53:34.079887 14064 net.cpp:122] Setting up pool2_1
I1123 18:53:34.079887 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.079887 14064 net.cpp:137] Memory required for data: 260711600
I1123 18:53:34.079887 14064 layer_factory.cpp:58] Creating layer conv3
I1123 18:53:34.079887 14064 net.cpp:84] Creating Layer conv3
I1123 18:53:34.079887 14064 net.cpp:406] conv3 <- pool2_1
I1123 18:53:34.079887 14064 net.cpp:380] conv3 -> conv3
I1123 18:53:34.082872 14064 net.cpp:122] Setting up conv3
I1123 18:53:34.082872 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.082872 14064 net.cpp:137] Memory required for data: 267879600
I1123 18:53:34.082872 14064 layer_factory.cpp:58] Creating layer bn3
I1123 18:53:34.082872 14064 net.cpp:84] Creating Layer bn3
I1123 18:53:34.082872 14064 net.cpp:406] bn3 <- conv3
I1123 18:53:34.082872 14064 net.cpp:367] bn3 -> conv3 (in-place)
I1123 18:53:34.082872 14064 net.cpp:122] Setting up bn3
I1123 18:53:34.082872 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.082872 14064 net.cpp:137] Memory required for data: 275047600
I1123 18:53:34.082872 14064 layer_factory.cpp:58] Creating layer scale3
I1123 18:53:34.082872 14064 net.cpp:84] Creating Layer scale3
I1123 18:53:34.082872 14064 net.cpp:406] scale3 <- conv3
I1123 18:53:34.082872 14064 net.cpp:367] scale3 -> conv3 (in-place)
I1123 18:53:34.082872 14064 layer_factory.cpp:58] Creating layer scale3
I1123 18:53:34.082872 14064 net.cpp:122] Setting up scale3
I1123 18:53:34.082872 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.082872 14064 net.cpp:137] Memory required for data: 282215600
I1123 18:53:34.082872 14064 layer_factory.cpp:58] Creating layer relu3
I1123 18:53:34.082872 14064 net.cpp:84] Creating Layer relu3
I1123 18:53:34.082872 14064 net.cpp:406] relu3 <- conv3
I1123 18:53:34.082872 14064 net.cpp:367] relu3 -> conv3 (in-place)
I1123 18:53:34.083887 14064 net.cpp:122] Setting up relu3
I1123 18:53:34.083887 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.083887 14064 net.cpp:137] Memory required for data: 289383600
I1123 18:53:34.083887 14064 layer_factory.cpp:58] Creating layer conv4
I1123 18:53:34.083887 14064 net.cpp:84] Creating Layer conv4
I1123 18:53:34.083887 14064 net.cpp:406] conv4 <- conv3
I1123 18:53:34.083887 14064 net.cpp:380] conv4 -> conv4
I1123 18:53:34.085896 14064 net.cpp:122] Setting up conv4
I1123 18:53:34.085896 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.085896 14064 net.cpp:137] Memory required for data: 296551600
I1123 18:53:34.085896 14064 layer_factory.cpp:58] Creating layer bn4
I1123 18:53:34.085896 14064 net.cpp:84] Creating Layer bn4
I1123 18:53:34.085896 14064 net.cpp:406] bn4 <- conv4
I1123 18:53:34.085896 14064 net.cpp:367] bn4 -> conv4 (in-place)
I1123 18:53:34.085896 14064 net.cpp:122] Setting up bn4
I1123 18:53:34.085896 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.085896 14064 net.cpp:137] Memory required for data: 303719600
I1123 18:53:34.086887 14064 layer_factory.cpp:58] Creating layer scale4
I1123 18:53:34.086887 14064 net.cpp:84] Creating Layer scale4
I1123 18:53:34.086887 14064 net.cpp:406] scale4 <- conv4
I1123 18:53:34.086887 14064 net.cpp:367] scale4 -> conv4 (in-place)
I1123 18:53:34.086887 14064 layer_factory.cpp:58] Creating layer scale4
I1123 18:53:34.086887 14064 net.cpp:122] Setting up scale4
I1123 18:53:34.086887 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.086887 14064 net.cpp:137] Memory required for data: 310887600
I1123 18:53:34.086887 14064 layer_factory.cpp:58] Creating layer relu4
I1123 18:53:34.086887 14064 net.cpp:84] Creating Layer relu4
I1123 18:53:34.086887 14064 net.cpp:406] relu4 <- conv4
I1123 18:53:34.086887 14064 net.cpp:367] relu4 -> conv4 (in-place)
I1123 18:53:34.086887 14064 net.cpp:122] Setting up relu4
I1123 18:53:34.086887 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.086887 14064 net.cpp:137] Memory required for data: 318055600
I1123 18:53:34.086887 14064 layer_factory.cpp:58] Creating layer conv4_1
I1123 18:53:34.086887 14064 net.cpp:84] Creating Layer conv4_1
I1123 18:53:34.086887 14064 net.cpp:406] conv4_1 <- conv4
I1123 18:53:34.086887 14064 net.cpp:380] conv4_1 -> conv4_1
I1123 18:53:34.089880 14064 net.cpp:122] Setting up conv4_1
I1123 18:53:34.089880 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.089880 14064 net.cpp:137] Memory required for data: 325223600
I1123 18:53:34.089880 14064 layer_factory.cpp:58] Creating layer bn4_1
I1123 18:53:34.089880 14064 net.cpp:84] Creating Layer bn4_1
I1123 18:53:34.089880 14064 net.cpp:406] bn4_1 <- conv4_1
I1123 18:53:34.089880 14064 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1123 18:53:34.089880 14064 net.cpp:122] Setting up bn4_1
I1123 18:53:34.089880 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.089880 14064 net.cpp:137] Memory required for data: 332391600
I1123 18:53:34.089880 14064 layer_factory.cpp:58] Creating layer scale4_1
I1123 18:53:34.089880 14064 net.cpp:84] Creating Layer scale4_1
I1123 18:53:34.089880 14064 net.cpp:406] scale4_1 <- conv4_1
I1123 18:53:34.089880 14064 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1123 18:53:34.089880 14064 layer_factory.cpp:58] Creating layer scale4_1
I1123 18:53:34.089880 14064 net.cpp:122] Setting up scale4_1
I1123 18:53:34.089880 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.089880 14064 net.cpp:137] Memory required for data: 339559600
I1123 18:53:34.089880 14064 layer_factory.cpp:58] Creating layer relu4_1
I1123 18:53:34.089880 14064 net.cpp:84] Creating Layer relu4_1
I1123 18:53:34.089880 14064 net.cpp:406] relu4_1 <- conv4_1
I1123 18:53:34.089880 14064 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1123 18:53:34.090883 14064 net.cpp:122] Setting up relu4_1
I1123 18:53:34.090883 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.090883 14064 net.cpp:137] Memory required for data: 346727600
I1123 18:53:34.090883 14064 layer_factory.cpp:58] Creating layer conv4_2
I1123 18:53:34.090883 14064 net.cpp:84] Creating Layer conv4_2
I1123 18:53:34.090883 14064 net.cpp:406] conv4_2 <- conv4_1
I1123 18:53:34.090883 14064 net.cpp:380] conv4_2 -> conv4_2
I1123 18:53:34.093883 14064 net.cpp:122] Setting up conv4_2
I1123 18:53:34.093883 14064 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1123 18:53:34.093883 14064 net.cpp:137] Memory required for data: 355431600
I1123 18:53:34.093883 14064 layer_factory.cpp:58] Creating layer bn4_2
I1123 18:53:34.093883 14064 net.cpp:84] Creating Layer bn4_2
I1123 18:53:34.093883 14064 net.cpp:406] bn4_2 <- conv4_2
I1123 18:53:34.093883 14064 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1123 18:53:34.094872 14064 net.cpp:122] Setting up bn4_2
I1123 18:53:34.094872 14064 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1123 18:53:34.094872 14064 net.cpp:137] Memory required for data: 364135600
I1123 18:53:34.094872 14064 layer_factory.cpp:58] Creating layer scale4_2
I1123 18:53:34.094872 14064 net.cpp:84] Creating Layer scale4_2
I1123 18:53:34.094872 14064 net.cpp:406] scale4_2 <- conv4_2
I1123 18:53:34.094872 14064 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1123 18:53:34.094872 14064 layer_factory.cpp:58] Creating layer scale4_2
I1123 18:53:34.094872 14064 net.cpp:122] Setting up scale4_2
I1123 18:53:34.094872 14064 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1123 18:53:34.094872 14064 net.cpp:137] Memory required for data: 372839600
I1123 18:53:34.094872 14064 layer_factory.cpp:58] Creating layer relu4_2
I1123 18:53:34.094872 14064 net.cpp:84] Creating Layer relu4_2
I1123 18:53:34.094872 14064 net.cpp:406] relu4_2 <- conv4_2
I1123 18:53:34.094872 14064 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1123 18:53:34.094872 14064 net.cpp:122] Setting up relu4_2
I1123 18:53:34.094872 14064 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1123 18:53:34.094872 14064 net.cpp:137] Memory required for data: 381543600
I1123 18:53:34.094872 14064 layer_factory.cpp:58] Creating layer pool4_2
I1123 18:53:34.094872 14064 net.cpp:84] Creating Layer pool4_2
I1123 18:53:34.094872 14064 net.cpp:406] pool4_2 <- conv4_2
I1123 18:53:34.094872 14064 net.cpp:380] pool4_2 -> pool4_2
I1123 18:53:34.094872 14064 net.cpp:122] Setting up pool4_2
I1123 18:53:34.094872 14064 net.cpp:129] Top shape: 100 85 8 8 (544000)
I1123 18:53:34.094872 14064 net.cpp:137] Memory required for data: 383719600
I1123 18:53:34.094872 14064 layer_factory.cpp:58] Creating layer conv12
I1123 18:53:34.094872 14064 net.cpp:84] Creating Layer conv12
I1123 18:53:34.094872 14064 net.cpp:406] conv12 <- pool4_2
I1123 18:53:34.094872 14064 net.cpp:380] conv12 -> conv12
I1123 18:53:34.098877 14064 net.cpp:122] Setting up conv12
I1123 18:53:34.098877 14064 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1123 18:53:34.098877 14064 net.cpp:137] Memory required for data: 386023600
I1123 18:53:34.098877 14064 layer_factory.cpp:58] Creating layer bn_conv12
I1123 18:53:34.098877 14064 net.cpp:84] Creating Layer bn_conv12
I1123 18:53:34.098877 14064 net.cpp:406] bn_conv12 <- conv12
I1123 18:53:34.098877 14064 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1123 18:53:34.098877 14064 net.cpp:122] Setting up bn_conv12
I1123 18:53:34.098877 14064 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1123 18:53:34.098877 14064 net.cpp:137] Memory required for data: 388327600
I1123 18:53:34.098877 14064 layer_factory.cpp:58] Creating layer scale_conv12
I1123 18:53:34.098877 14064 net.cpp:84] Creating Layer scale_conv12
I1123 18:53:34.098877 14064 net.cpp:406] scale_conv12 <- conv12
I1123 18:53:34.098877 14064 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1123 18:53:34.099884 14064 layer_factory.cpp:58] Creating layer scale_conv12
I1123 18:53:34.099884 14064 net.cpp:122] Setting up scale_conv12
I1123 18:53:34.099884 14064 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1123 18:53:34.099884 14064 net.cpp:137] Memory required for data: 390631600
I1123 18:53:34.099884 14064 layer_factory.cpp:58] Creating layer relu_conv12
I1123 18:53:34.099884 14064 net.cpp:84] Creating Layer relu_conv12
I1123 18:53:34.099884 14064 net.cpp:406] relu_conv12 <- conv12
I1123 18:53:34.099884 14064 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1123 18:53:34.099884 14064 net.cpp:122] Setting up relu_conv12
I1123 18:53:34.099884 14064 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1123 18:53:34.099884 14064 net.cpp:137] Memory required for data: 392935600
I1123 18:53:34.099884 14064 layer_factory.cpp:58] Creating layer poolcp6
I1123 18:53:34.099884 14064 net.cpp:84] Creating Layer poolcp6
I1123 18:53:34.099884 14064 net.cpp:406] poolcp6 <- conv12
I1123 18:53:34.099884 14064 net.cpp:380] poolcp6 -> poolcp6
I1123 18:53:34.099884 14064 net.cpp:122] Setting up poolcp6
I1123 18:53:34.099884 14064 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1123 18:53:34.099884 14064 net.cpp:137] Memory required for data: 392971600
I1123 18:53:34.099884 14064 layer_factory.cpp:58] Creating layer ip1
I1123 18:53:34.099884 14064 net.cpp:84] Creating Layer ip1
I1123 18:53:34.099884 14064 net.cpp:406] ip1 <- poolcp6
I1123 18:53:34.099884 14064 net.cpp:380] ip1 -> ip1
I1123 18:53:34.099884 14064 net.cpp:122] Setting up ip1
I1123 18:53:34.099884 14064 net.cpp:129] Top shape: 100 10 (1000)
I1123 18:53:34.099884 14064 net.cpp:137] Memory required for data: 392975600
I1123 18:53:34.099884 14064 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1123 18:53:34.099884 14064 net.cpp:84] Creating Layer ip1_ip1_0_split
I1123 18:53:34.099884 14064 net.cpp:406] ip1_ip1_0_split <- ip1
I1123 18:53:34.099884 14064 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1123 18:53:34.099884 14064 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1123 18:53:34.099884 14064 net.cpp:122] Setting up ip1_ip1_0_split
I1123 18:53:34.099884 14064 net.cpp:129] Top shape: 100 10 (1000)
I1123 18:53:34.099884 14064 net.cpp:129] Top shape: 100 10 (1000)
I1123 18:53:34.099884 14064 net.cpp:137] Memory required for data: 392983600
I1123 18:53:34.099884 14064 layer_factory.cpp:58] Creating layer accuracy_training
I1123 18:53:34.099884 14064 net.cpp:84] Creating Layer accuracy_training
I1123 18:53:34.099884 14064 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1123 18:53:34.099884 14064 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1123 18:53:34.099884 14064 net.cpp:380] accuracy_training -> accuracy_training
I1123 18:53:34.099884 14064 net.cpp:122] Setting up accuracy_training
I1123 18:53:34.099884 14064 net.cpp:129] Top shape: (1)
I1123 18:53:34.099884 14064 net.cpp:137] Memory required for data: 392983604
I1123 18:53:34.099884 14064 layer_factory.cpp:58] Creating layer loss
I1123 18:53:34.099884 14064 net.cpp:84] Creating Layer loss
I1123 18:53:34.099884 14064 net.cpp:406] loss <- ip1_ip1_0_split_1
I1123 18:53:34.099884 14064 net.cpp:406] loss <- label_cifar_1_split_1
I1123 18:53:34.099884 14064 net.cpp:380] loss -> loss
I1123 18:53:34.099884 14064 layer_factory.cpp:58] Creating layer loss
I1123 18:53:34.100888 14064 net.cpp:122] Setting up loss
I1123 18:53:34.100888 14064 net.cpp:129] Top shape: (1)
I1123 18:53:34.100888 14064 net.cpp:132]     with loss weight 1
I1123 18:53:34.100888 14064 net.cpp:137] Memory required for data: 392983608
I1123 18:53:34.100888 14064 net.cpp:198] loss needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:200] accuracy_training does not need backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] ip1 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] poolcp6 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] relu_conv12 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] scale_conv12 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] bn_conv12 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] conv12 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] pool4_2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] relu4_2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] scale4_2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] bn4_2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] conv4_2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] relu4_1 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] scale4_1 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] bn4_1 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] conv4_1 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] relu4 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] scale4 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] bn4 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] conv4 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] relu3 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] scale3 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] bn3 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] conv3 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] pool2_1 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] relu2_2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] scale2_2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] bn2_2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] conv2_2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] relu2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] scale2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] bn2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] conv2 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] relu1 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] scale1 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] bn1 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:198] conv1 needs backward computation.
I1123 18:53:34.100888 14064 net.cpp:200] label_cifar_1_split does not need backward computation.
I1123 18:53:34.100888 14064 net.cpp:200] cifar does not need backward computation.
I1123 18:53:34.100888 14064 net.cpp:242] This network produces output accuracy_training
I1123 18:53:34.100888 14064 net.cpp:242] This network produces output loss
I1123 18:53:34.100888 14064 net.cpp:255] Network initialization done.
I1123 18:53:34.101883 14064 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1123 18:53:34.101883 14064 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1123 18:53:34.101883 14064 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1123 18:53:34.101883 14064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1123 18:53:34.101883 14064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1123 18:53:34.101883 14064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1123 18:53:34.101883 14064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1123 18:53:34.101883 14064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1123 18:53:34.101883 14064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1123 18:53:34.101883 14064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1123 18:53:34.101883 14064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1123 18:53:34.101883 14064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1123 18:53:34.101883 14064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1123 18:53:34.101883 14064 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_8L_Simple_7x7_1.6M"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb_zeropad"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 41
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 43
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 85
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 3
    kernel_size: 7
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1123 18:53:34.101883 14064 layer_factory.cpp:58] Creating layer cifar
I1123 18:53:34.109395 14064 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb_zeropad
I1123 18:53:34.109395 14064 net.cpp:84] Creating Layer cifar
I1123 18:53:34.109395 14064 net.cpp:380] cifar -> data
I1123 18:53:34.109395 14064 net.cpp:380] cifar -> label
I1123 18:53:34.109395 14064 data_layer.cpp:45] output data size: 100,3,32,32
I1123 18:53:34.115394 14064 net.cpp:122] Setting up cifar
I1123 18:53:34.115394 14064 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1123 18:53:34.115394 14064 net.cpp:129] Top shape: 100 (100)
I1123 18:53:34.115394 14064 net.cpp:137] Memory required for data: 1229200
I1123 18:53:34.115896 14064 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1123 18:53:34.115896 14064 net.cpp:84] Creating Layer label_cifar_1_split
I1123 18:53:34.115896 14064 net.cpp:406] label_cifar_1_split <- label
I1123 18:53:34.115896 14064 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1123 18:53:34.115896 14064 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1123 18:53:34.115896 14064 net.cpp:122] Setting up label_cifar_1_split
I1123 18:53:34.115896 14064 net.cpp:129] Top shape: 100 (100)
I1123 18:53:34.115896 14064 net.cpp:129] Top shape: 100 (100)
I1123 18:53:34.115896 14064 net.cpp:137] Memory required for data: 1230000
I1123 18:53:34.115896 14064 layer_factory.cpp:58] Creating layer conv1
I1123 18:53:34.115896 14064 net.cpp:84] Creating Layer conv1
I1123 18:53:34.115896 14064 net.cpp:406] conv1 <- data
I1123 18:53:34.115896 14064 net.cpp:380] conv1 -> conv1
I1123 18:53:34.116899 32444 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1123 18:53:34.117897 14064 net.cpp:122] Setting up conv1
I1123 18:53:34.117897 14064 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1123 18:53:34.117897 14064 net.cpp:137] Memory required for data: 18023600
I1123 18:53:34.117897 14064 layer_factory.cpp:58] Creating layer bn1
I1123 18:53:34.117897 14064 net.cpp:84] Creating Layer bn1
I1123 18:53:34.117897 14064 net.cpp:406] bn1 <- conv1
I1123 18:53:34.117897 14064 net.cpp:367] bn1 -> conv1 (in-place)
I1123 18:53:34.117897 14064 net.cpp:122] Setting up bn1
I1123 18:53:34.117897 14064 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1123 18:53:34.117897 14064 net.cpp:137] Memory required for data: 34817200
I1123 18:53:34.117897 14064 layer_factory.cpp:58] Creating layer scale1
I1123 18:53:34.117897 14064 net.cpp:84] Creating Layer scale1
I1123 18:53:34.117897 14064 net.cpp:406] scale1 <- conv1
I1123 18:53:34.117897 14064 net.cpp:367] scale1 -> conv1 (in-place)
I1123 18:53:34.117897 14064 layer_factory.cpp:58] Creating layer scale1
I1123 18:53:34.117897 14064 net.cpp:122] Setting up scale1
I1123 18:53:34.117897 14064 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1123 18:53:34.117897 14064 net.cpp:137] Memory required for data: 51610800
I1123 18:53:34.117897 14064 layer_factory.cpp:58] Creating layer relu1
I1123 18:53:34.117897 14064 net.cpp:84] Creating Layer relu1
I1123 18:53:34.117897 14064 net.cpp:406] relu1 <- conv1
I1123 18:53:34.118396 14064 net.cpp:367] relu1 -> conv1 (in-place)
I1123 18:53:34.118903 14064 net.cpp:122] Setting up relu1
I1123 18:53:34.118903 14064 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1123 18:53:34.118903 14064 net.cpp:137] Memory required for data: 68404400
I1123 18:53:34.118903 14064 layer_factory.cpp:58] Creating layer conv2
I1123 18:53:34.118903 14064 net.cpp:84] Creating Layer conv2
I1123 18:53:34.118903 14064 net.cpp:406] conv2 <- conv1
I1123 18:53:34.118903 14064 net.cpp:380] conv2 -> conv2
I1123 18:53:34.120407 14064 net.cpp:122] Setting up conv2
I1123 18:53:34.120407 14064 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1123 18:53:34.120407 14064 net.cpp:137] Memory required for data: 86017200
I1123 18:53:34.120407 14064 layer_factory.cpp:58] Creating layer bn2
I1123 18:53:34.120407 14064 net.cpp:84] Creating Layer bn2
I1123 18:53:34.120407 14064 net.cpp:406] bn2 <- conv2
I1123 18:53:34.120407 14064 net.cpp:367] bn2 -> conv2 (in-place)
I1123 18:53:34.120407 14064 net.cpp:122] Setting up bn2
I1123 18:53:34.120407 14064 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1123 18:53:34.120407 14064 net.cpp:137] Memory required for data: 103630000
I1123 18:53:34.120407 14064 layer_factory.cpp:58] Creating layer scale2
I1123 18:53:34.120407 14064 net.cpp:84] Creating Layer scale2
I1123 18:53:34.120407 14064 net.cpp:406] scale2 <- conv2
I1123 18:53:34.120407 14064 net.cpp:367] scale2 -> conv2 (in-place)
I1123 18:53:34.120407 14064 layer_factory.cpp:58] Creating layer scale2
I1123 18:53:34.120898 14064 net.cpp:122] Setting up scale2
I1123 18:53:34.120898 14064 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1123 18:53:34.120898 14064 net.cpp:137] Memory required for data: 121242800
I1123 18:53:34.120898 14064 layer_factory.cpp:58] Creating layer relu2
I1123 18:53:34.120898 14064 net.cpp:84] Creating Layer relu2
I1123 18:53:34.120898 14064 net.cpp:406] relu2 <- conv2
I1123 18:53:34.120898 14064 net.cpp:367] relu2 -> conv2 (in-place)
I1123 18:53:34.121397 14064 net.cpp:122] Setting up relu2
I1123 18:53:34.121397 14064 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1123 18:53:34.121397 14064 net.cpp:137] Memory required for data: 138855600
I1123 18:53:34.121397 14064 layer_factory.cpp:58] Creating layer conv2_2
I1123 18:53:34.121397 14064 net.cpp:84] Creating Layer conv2_2
I1123 18:53:34.121397 14064 net.cpp:406] conv2_2 <- conv2
I1123 18:53:34.121397 14064 net.cpp:380] conv2_2 -> conv2_2
I1123 18:53:34.123425 14064 net.cpp:122] Setting up conv2_2
I1123 18:53:34.123425 14064 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1123 18:53:34.123425 14064 net.cpp:137] Memory required for data: 167527600
I1123 18:53:34.123425 14064 layer_factory.cpp:58] Creating layer bn2_2
I1123 18:53:34.123425 14064 net.cpp:84] Creating Layer bn2_2
I1123 18:53:34.123425 14064 net.cpp:406] bn2_2 <- conv2_2
I1123 18:53:34.123425 14064 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1123 18:53:34.123425 14064 net.cpp:122] Setting up bn2_2
I1123 18:53:34.123425 14064 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1123 18:53:34.123425 14064 net.cpp:137] Memory required for data: 196199600
I1123 18:53:34.123425 14064 layer_factory.cpp:58] Creating layer scale2_2
I1123 18:53:34.123425 14064 net.cpp:84] Creating Layer scale2_2
I1123 18:53:34.123425 14064 net.cpp:406] scale2_2 <- conv2_2
I1123 18:53:34.123425 14064 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1123 18:53:34.123425 14064 layer_factory.cpp:58] Creating layer scale2_2
I1123 18:53:34.123425 14064 net.cpp:122] Setting up scale2_2
I1123 18:53:34.123425 14064 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1123 18:53:34.123425 14064 net.cpp:137] Memory required for data: 224871600
I1123 18:53:34.123425 14064 layer_factory.cpp:58] Creating layer relu2_2
I1123 18:53:34.123425 14064 net.cpp:84] Creating Layer relu2_2
I1123 18:53:34.123425 14064 net.cpp:406] relu2_2 <- conv2_2
I1123 18:53:34.123425 14064 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1123 18:53:34.124424 14064 net.cpp:122] Setting up relu2_2
I1123 18:53:34.124424 14064 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1123 18:53:34.124424 14064 net.cpp:137] Memory required for data: 253543600
I1123 18:53:34.124424 14064 layer_factory.cpp:58] Creating layer pool2_1
I1123 18:53:34.124424 14064 net.cpp:84] Creating Layer pool2_1
I1123 18:53:34.124424 14064 net.cpp:406] pool2_1 <- conv2_2
I1123 18:53:34.124424 14064 net.cpp:380] pool2_1 -> pool2_1
I1123 18:53:34.124424 14064 net.cpp:122] Setting up pool2_1
I1123 18:53:34.124424 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.124424 14064 net.cpp:137] Memory required for data: 260711600
I1123 18:53:34.124424 14064 layer_factory.cpp:58] Creating layer conv3
I1123 18:53:34.124424 14064 net.cpp:84] Creating Layer conv3
I1123 18:53:34.124424 14064 net.cpp:406] conv3 <- pool2_1
I1123 18:53:34.124424 14064 net.cpp:380] conv3 -> conv3
I1123 18:53:34.126427 14064 net.cpp:122] Setting up conv3
I1123 18:53:34.126427 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.126427 14064 net.cpp:137] Memory required for data: 267879600
I1123 18:53:34.126427 14064 layer_factory.cpp:58] Creating layer bn3
I1123 18:53:34.126427 14064 net.cpp:84] Creating Layer bn3
I1123 18:53:34.126427 14064 net.cpp:406] bn3 <- conv3
I1123 18:53:34.126427 14064 net.cpp:367] bn3 -> conv3 (in-place)
I1123 18:53:34.126427 14064 net.cpp:122] Setting up bn3
I1123 18:53:34.126427 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.126427 14064 net.cpp:137] Memory required for data: 275047600
I1123 18:53:34.126427 14064 layer_factory.cpp:58] Creating layer scale3
I1123 18:53:34.126427 14064 net.cpp:84] Creating Layer scale3
I1123 18:53:34.126427 14064 net.cpp:406] scale3 <- conv3
I1123 18:53:34.126427 14064 net.cpp:367] scale3 -> conv3 (in-place)
I1123 18:53:34.126427 14064 layer_factory.cpp:58] Creating layer scale3
I1123 18:53:34.127424 14064 net.cpp:122] Setting up scale3
I1123 18:53:34.127424 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.127424 14064 net.cpp:137] Memory required for data: 282215600
I1123 18:53:34.127424 14064 layer_factory.cpp:58] Creating layer relu3
I1123 18:53:34.127424 14064 net.cpp:84] Creating Layer relu3
I1123 18:53:34.127424 14064 net.cpp:406] relu3 <- conv3
I1123 18:53:34.127424 14064 net.cpp:367] relu3 -> conv3 (in-place)
I1123 18:53:34.127424 14064 net.cpp:122] Setting up relu3
I1123 18:53:34.127424 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.127424 14064 net.cpp:137] Memory required for data: 289383600
I1123 18:53:34.127424 14064 layer_factory.cpp:58] Creating layer conv4
I1123 18:53:34.127424 14064 net.cpp:84] Creating Layer conv4
I1123 18:53:34.127424 14064 net.cpp:406] conv4 <- conv3
I1123 18:53:34.127424 14064 net.cpp:380] conv4 -> conv4
I1123 18:53:34.130426 14064 net.cpp:122] Setting up conv4
I1123 18:53:34.130426 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.130426 14064 net.cpp:137] Memory required for data: 296551600
I1123 18:53:34.130426 14064 layer_factory.cpp:58] Creating layer bn4
I1123 18:53:34.130426 14064 net.cpp:84] Creating Layer bn4
I1123 18:53:34.130426 14064 net.cpp:406] bn4 <- conv4
I1123 18:53:34.130426 14064 net.cpp:367] bn4 -> conv4 (in-place)
I1123 18:53:34.131439 14064 net.cpp:122] Setting up bn4
I1123 18:53:34.131439 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.131439 14064 net.cpp:137] Memory required for data: 303719600
I1123 18:53:34.131439 14064 layer_factory.cpp:58] Creating layer scale4
I1123 18:53:34.131439 14064 net.cpp:84] Creating Layer scale4
I1123 18:53:34.131439 14064 net.cpp:406] scale4 <- conv4
I1123 18:53:34.131439 14064 net.cpp:367] scale4 -> conv4 (in-place)
I1123 18:53:34.131439 14064 layer_factory.cpp:58] Creating layer scale4
I1123 18:53:34.131439 14064 net.cpp:122] Setting up scale4
I1123 18:53:34.131439 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.131439 14064 net.cpp:137] Memory required for data: 310887600
I1123 18:53:34.131439 14064 layer_factory.cpp:58] Creating layer relu4
I1123 18:53:34.131439 14064 net.cpp:84] Creating Layer relu4
I1123 18:53:34.131439 14064 net.cpp:406] relu4 <- conv4
I1123 18:53:34.131439 14064 net.cpp:367] relu4 -> conv4 (in-place)
I1123 18:53:34.131439 14064 net.cpp:122] Setting up relu4
I1123 18:53:34.131439 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.131439 14064 net.cpp:137] Memory required for data: 318055600
I1123 18:53:34.131439 14064 layer_factory.cpp:58] Creating layer conv4_1
I1123 18:53:34.131439 14064 net.cpp:84] Creating Layer conv4_1
I1123 18:53:34.131439 14064 net.cpp:406] conv4_1 <- conv4
I1123 18:53:34.131439 14064 net.cpp:380] conv4_1 -> conv4_1
I1123 18:53:34.134424 14064 net.cpp:122] Setting up conv4_1
I1123 18:53:34.134424 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.134424 14064 net.cpp:137] Memory required for data: 325223600
I1123 18:53:34.134424 14064 layer_factory.cpp:58] Creating layer bn4_1
I1123 18:53:34.134424 14064 net.cpp:84] Creating Layer bn4_1
I1123 18:53:34.134424 14064 net.cpp:406] bn4_1 <- conv4_1
I1123 18:53:34.134424 14064 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1123 18:53:34.134424 14064 net.cpp:122] Setting up bn4_1
I1123 18:53:34.134424 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.134424 14064 net.cpp:137] Memory required for data: 332391600
I1123 18:53:34.134424 14064 layer_factory.cpp:58] Creating layer scale4_1
I1123 18:53:34.134424 14064 net.cpp:84] Creating Layer scale4_1
I1123 18:53:34.134424 14064 net.cpp:406] scale4_1 <- conv4_1
I1123 18:53:34.134424 14064 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1123 18:53:34.134424 14064 layer_factory.cpp:58] Creating layer scale4_1
I1123 18:53:34.134424 14064 net.cpp:122] Setting up scale4_1
I1123 18:53:34.134424 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.134424 14064 net.cpp:137] Memory required for data: 339559600
I1123 18:53:34.134424 14064 layer_factory.cpp:58] Creating layer relu4_1
I1123 18:53:34.134424 14064 net.cpp:84] Creating Layer relu4_1
I1123 18:53:34.134424 14064 net.cpp:406] relu4_1 <- conv4_1
I1123 18:53:34.134424 14064 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1123 18:53:34.134424 14064 net.cpp:122] Setting up relu4_1
I1123 18:53:34.134424 14064 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1123 18:53:34.134424 14064 net.cpp:137] Memory required for data: 346727600
I1123 18:53:34.134424 14064 layer_factory.cpp:58] Creating layer conv4_2
I1123 18:53:34.134424 14064 net.cpp:84] Creating Layer conv4_2
I1123 18:53:34.134424 14064 net.cpp:406] conv4_2 <- conv4_1
I1123 18:53:34.134424 14064 net.cpp:380] conv4_2 -> conv4_2
I1123 18:53:34.138424 14064 net.cpp:122] Setting up conv4_2
I1123 18:53:34.138424 14064 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1123 18:53:34.138424 14064 net.cpp:137] Memory required for data: 355431600
I1123 18:53:34.138424 14064 layer_factory.cpp:58] Creating layer bn4_2
I1123 18:53:34.138424 14064 net.cpp:84] Creating Layer bn4_2
I1123 18:53:34.138424 14064 net.cpp:406] bn4_2 <- conv4_2
I1123 18:53:34.138424 14064 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1123 18:53:34.138424 14064 net.cpp:122] Setting up bn4_2
I1123 18:53:34.138424 14064 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1123 18:53:34.138424 14064 net.cpp:137] Memory required for data: 364135600
I1123 18:53:34.138424 14064 layer_factory.cpp:58] Creating layer scale4_2
I1123 18:53:34.138424 14064 net.cpp:84] Creating Layer scale4_2
I1123 18:53:34.138424 14064 net.cpp:406] scale4_2 <- conv4_2
I1123 18:53:34.138424 14064 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1123 18:53:34.138424 14064 layer_factory.cpp:58] Creating layer scale4_2
I1123 18:53:34.138424 14064 net.cpp:122] Setting up scale4_2
I1123 18:53:34.138424 14064 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1123 18:53:34.138424 14064 net.cpp:137] Memory required for data: 372839600
I1123 18:53:34.138424 14064 layer_factory.cpp:58] Creating layer relu4_2
I1123 18:53:34.138424 14064 net.cpp:84] Creating Layer relu4_2
I1123 18:53:34.138424 14064 net.cpp:406] relu4_2 <- conv4_2
I1123 18:53:34.138424 14064 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1123 18:53:34.139425 14064 net.cpp:122] Setting up relu4_2
I1123 18:53:34.139425 14064 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1123 18:53:34.139425 14064 net.cpp:137] Memory required for data: 381543600
I1123 18:53:34.139425 14064 layer_factory.cpp:58] Creating layer pool4_2
I1123 18:53:34.139425 14064 net.cpp:84] Creating Layer pool4_2
I1123 18:53:34.139425 14064 net.cpp:406] pool4_2 <- conv4_2
I1123 18:53:34.139425 14064 net.cpp:380] pool4_2 -> pool4_2
I1123 18:53:34.139425 14064 net.cpp:122] Setting up pool4_2
I1123 18:53:34.139425 14064 net.cpp:129] Top shape: 100 85 8 8 (544000)
I1123 18:53:34.139425 14064 net.cpp:137] Memory required for data: 383719600
I1123 18:53:34.139425 14064 layer_factory.cpp:58] Creating layer conv12
I1123 18:53:34.139425 14064 net.cpp:84] Creating Layer conv12
I1123 18:53:34.139425 14064 net.cpp:406] conv12 <- pool4_2
I1123 18:53:34.139425 14064 net.cpp:380] conv12 -> conv12
I1123 18:53:34.142424 14064 net.cpp:122] Setting up conv12
I1123 18:53:34.142424 14064 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1123 18:53:34.142424 14064 net.cpp:137] Memory required for data: 386023600
I1123 18:53:34.142424 14064 layer_factory.cpp:58] Creating layer bn_conv12
I1123 18:53:34.142424 14064 net.cpp:84] Creating Layer bn_conv12
I1123 18:53:34.142424 14064 net.cpp:406] bn_conv12 <- conv12
I1123 18:53:34.142424 14064 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1123 18:53:34.142424 14064 net.cpp:122] Setting up bn_conv12
I1123 18:53:34.142424 14064 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1123 18:53:34.142424 14064 net.cpp:137] Memory required for data: 388327600
I1123 18:53:34.142424 14064 layer_factory.cpp:58] Creating layer scale_conv12
I1123 18:53:34.142424 14064 net.cpp:84] Creating Layer scale_conv12
I1123 18:53:34.142424 14064 net.cpp:406] scale_conv12 <- conv12
I1123 18:53:34.142424 14064 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1123 18:53:34.142424 14064 layer_factory.cpp:58] Creating layer scale_conv12
I1123 18:53:34.142424 14064 net.cpp:122] Setting up scale_conv12
I1123 18:53:34.142424 14064 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1123 18:53:34.142424 14064 net.cpp:137] Memory required for data: 390631600
I1123 18:53:34.142424 14064 layer_factory.cpp:58] Creating layer relu_conv12
I1123 18:53:34.143438 14064 net.cpp:84] Creating Layer relu_conv12
I1123 18:53:34.143438 14064 net.cpp:406] relu_conv12 <- conv12
I1123 18:53:34.143438 14064 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1123 18:53:34.143438 14064 net.cpp:122] Setting up relu_conv12
I1123 18:53:34.143438 14064 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1123 18:53:34.143438 14064 net.cpp:137] Memory required for data: 392935600
I1123 18:53:34.143438 14064 layer_factory.cpp:58] Creating layer poolcp6
I1123 18:53:34.143438 14064 net.cpp:84] Creating Layer poolcp6
I1123 18:53:34.143438 14064 net.cpp:406] poolcp6 <- conv12
I1123 18:53:34.143438 14064 net.cpp:380] poolcp6 -> poolcp6
I1123 18:53:34.143438 14064 net.cpp:122] Setting up poolcp6
I1123 18:53:34.143438 14064 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1123 18:53:34.143438 14064 net.cpp:137] Memory required for data: 392971600
I1123 18:53:34.143438 14064 layer_factory.cpp:58] Creating layer ip1
I1123 18:53:34.143438 14064 net.cpp:84] Creating Layer ip1
I1123 18:53:34.143438 14064 net.cpp:406] ip1 <- poolcp6
I1123 18:53:34.143438 14064 net.cpp:380] ip1 -> ip1
I1123 18:53:34.143438 14064 net.cpp:122] Setting up ip1
I1123 18:53:34.143438 14064 net.cpp:129] Top shape: 100 10 (1000)
I1123 18:53:34.143438 14064 net.cpp:137] Memory required for data: 392975600
I1123 18:53:34.143438 14064 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1123 18:53:34.143438 14064 net.cpp:84] Creating Layer ip1_ip1_0_split
I1123 18:53:34.143438 14064 net.cpp:406] ip1_ip1_0_split <- ip1
I1123 18:53:34.143438 14064 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1123 18:53:34.143438 14064 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1123 18:53:34.143438 14064 net.cpp:122] Setting up ip1_ip1_0_split
I1123 18:53:34.143438 14064 net.cpp:129] Top shape: 100 10 (1000)
I1123 18:53:34.143438 14064 net.cpp:129] Top shape: 100 10 (1000)
I1123 18:53:34.143438 14064 net.cpp:137] Memory required for data: 392983600
I1123 18:53:34.143438 14064 layer_factory.cpp:58] Creating layer accuracy
I1123 18:53:34.143438 14064 net.cpp:84] Creating Layer accuracy
I1123 18:53:34.143438 14064 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1123 18:53:34.143438 14064 net.cpp:406] accuracy <- label_cifar_1_split_0
I1123 18:53:34.143438 14064 net.cpp:380] accuracy -> accuracy
I1123 18:53:34.143438 14064 net.cpp:122] Setting up accuracy
I1123 18:53:34.143438 14064 net.cpp:129] Top shape: (1)
I1123 18:53:34.143438 14064 net.cpp:137] Memory required for data: 392983604
I1123 18:53:34.143438 14064 layer_factory.cpp:58] Creating layer loss
I1123 18:53:34.143438 14064 net.cpp:84] Creating Layer loss
I1123 18:53:34.143438 14064 net.cpp:406] loss <- ip1_ip1_0_split_1
I1123 18:53:34.143438 14064 net.cpp:406] loss <- label_cifar_1_split_1
I1123 18:53:34.143438 14064 net.cpp:380] loss -> loss
I1123 18:53:34.143438 14064 layer_factory.cpp:58] Creating layer loss
I1123 18:53:34.144438 14064 net.cpp:122] Setting up loss
I1123 18:53:34.144438 14064 net.cpp:129] Top shape: (1)
I1123 18:53:34.144438 14064 net.cpp:132]     with loss weight 1
I1123 18:53:34.144438 14064 net.cpp:137] Memory required for data: 392983608
I1123 18:53:34.144438 14064 net.cpp:198] loss needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:200] accuracy does not need backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] ip1 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] poolcp6 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] relu_conv12 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] scale_conv12 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] bn_conv12 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] conv12 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] pool4_2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] relu4_2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] scale4_2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] bn4_2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] conv4_2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] relu4_1 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] scale4_1 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] bn4_1 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] conv4_1 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] relu4 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] scale4 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] bn4 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] conv4 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] relu3 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] scale3 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] bn3 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] conv3 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] pool2_1 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] relu2_2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] scale2_2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] bn2_2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] conv2_2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] relu2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] scale2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] bn2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] conv2 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] relu1 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] scale1 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] bn1 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:198] conv1 needs backward computation.
I1123 18:53:34.144438 14064 net.cpp:200] label_cifar_1_split does not need backward computation.
I1123 18:53:34.144438 14064 net.cpp:200] cifar does not need backward computation.
I1123 18:53:34.144438 14064 net.cpp:242] This network produces output accuracy
I1123 18:53:34.144438 14064 net.cpp:242] This network produces output loss
I1123 18:53:34.144438 14064 net.cpp:255] Network initialization done.
I1123 18:53:34.144438 14064 solver.cpp:56] Solver scaffolding done.
I1123 18:53:34.147439 14064 caffe.cpp:249] Starting Optimization
I1123 18:53:34.147439 14064 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_8L_Simple_7x7_1.6M
I1123 18:53:34.147439 14064 solver.cpp:273] Learning Rate Policy: multistep
I1123 18:53:34.149427 14064 solver.cpp:330] Iteration 0, Testing net (#0)
I1123 18:53:34.151425 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 18:53:38.175683 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:53:38.337761 14064 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1123 18:53:38.337761 14064 solver.cpp:397]     Test net output #1: loss = 78.6029 (* 1 = 78.6029 loss)
I1123 18:53:38.487778 14064 solver.cpp:218] Iteration 0 (-1.63798e-41 iter/s, 4.34036s/100 iters), loss = 3.45264
I1123 18:53:38.487778 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I1123 18:53:38.487778 14064 solver.cpp:237]     Train net output #1: loss = 3.45264 (* 1 = 3.45264 loss)
I1123 18:53:38.487778 14064 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1123 18:53:50.382612 14064 solver.cpp:218] Iteration 100 (8.40763 iter/s, 11.894s/100 iters), loss = 1.70101
I1123 18:53:50.382612 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1123 18:53:50.382612 14064 solver.cpp:237]     Train net output #1: loss = 1.70101 (* 1 = 1.70101 loss)
I1123 18:53:50.382612 14064 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1123 18:54:02.334506 14064 solver.cpp:218] Iteration 200 (8.3672 iter/s, 11.9514s/100 iters), loss = 1.84422
I1123 18:54:02.334506 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1123 18:54:02.334506 14064 solver.cpp:237]     Train net output #1: loss = 1.84422 (* 1 = 1.84422 loss)
I1123 18:54:02.334506 14064 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1123 18:54:14.313319 14064 solver.cpp:218] Iteration 300 (8.34853 iter/s, 11.9782s/100 iters), loss = 1.55565
I1123 18:54:14.313319 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1123 18:54:14.313319 14064 solver.cpp:237]     Train net output #1: loss = 1.55565 (* 1 = 1.55565 loss)
I1123 18:54:14.313319 14064 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1123 18:54:26.370067 14064 solver.cpp:218] Iteration 400 (8.29456 iter/s, 12.0561s/100 iters), loss = 1.42815
I1123 18:54:26.370067 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1123 18:54:26.370067 14064 solver.cpp:237]     Train net output #1: loss = 1.42815 (* 1 = 1.42815 loss)
I1123 18:54:26.370067 14064 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1123 18:54:37.832782  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:54:38.310283 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_500.caffemodel
I1123 18:54:38.357281 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_500.solverstate
I1123 18:54:38.376284 14064 solver.cpp:330] Iteration 500, Testing net (#0)
I1123 18:54:38.376284 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 18:54:42.374424 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:54:42.537477 14064 solver.cpp:397]     Test net output #0: accuracy = 0.4378
I1123 18:54:42.537477 14064 solver.cpp:397]     Test net output #1: loss = 1.5525 (* 1 = 1.5525 loss)
I1123 18:54:42.654521 14064 solver.cpp:218] Iteration 500 (6.14097 iter/s, 16.2841s/100 iters), loss = 1.35879
I1123 18:54:42.654521 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1123 18:54:42.654521 14064 solver.cpp:237]     Train net output #1: loss = 1.35879 (* 1 = 1.35879 loss)
I1123 18:54:42.654521 14064 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1123 18:54:54.704565 14064 solver.cpp:218] Iteration 600 (8.29922 iter/s, 12.0493s/100 iters), loss = 1.21708
I1123 18:54:54.704565 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1123 18:54:54.704565 14064 solver.cpp:237]     Train net output #1: loss = 1.21708 (* 1 = 1.21708 loss)
I1123 18:54:54.704565 14064 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1123 18:55:06.757017 14064 solver.cpp:218] Iteration 700 (8.29759 iter/s, 12.0517s/100 iters), loss = 1.14056
I1123 18:55:06.757017 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1123 18:55:06.757017 14064 solver.cpp:237]     Train net output #1: loss = 1.14056 (* 1 = 1.14056 loss)
I1123 18:55:06.757017 14064 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1123 18:55:18.816251 14064 solver.cpp:218] Iteration 800 (8.29268 iter/s, 12.0588s/100 iters), loss = 0.959735
I1123 18:55:18.816251 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1123 18:55:18.816251 14064 solver.cpp:237]     Train net output #1: loss = 0.959735 (* 1 = 0.959735 loss)
I1123 18:55:18.816251 14064 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1123 18:55:30.871618 14064 solver.cpp:218] Iteration 900 (8.2956 iter/s, 12.0546s/100 iters), loss = 1.04877
I1123 18:55:30.871618 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1123 18:55:30.871618 14064 solver.cpp:237]     Train net output #1: loss = 1.04877 (* 1 = 1.04877 loss)
I1123 18:55:30.871618 14064 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1123 18:55:42.329136  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:55:42.808143 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_1000.caffemodel
I1123 18:55:42.847638 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_1000.solverstate
I1123 18:55:42.867136 14064 solver.cpp:330] Iteration 1000, Testing net (#0)
I1123 18:55:42.867646 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 18:55:46.893992 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:55:47.058008 14064 solver.cpp:397]     Test net output #0: accuracy = 0.5459
I1123 18:55:47.058008 14064 solver.cpp:397]     Test net output #1: loss = 1.25565 (* 1 = 1.25565 loss)
I1123 18:55:47.174535 14064 solver.cpp:218] Iteration 1000 (6.13411 iter/s, 16.3023s/100 iters), loss = 1.06584
I1123 18:55:47.174535 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1123 18:55:47.174535 14064 solver.cpp:237]     Train net output #1: loss = 1.06584 (* 1 = 1.06584 loss)
I1123 18:55:47.174535 14064 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1123 18:55:59.237457 14064 solver.cpp:218] Iteration 1100 (8.29061 iter/s, 12.0618s/100 iters), loss = 0.911173
I1123 18:55:59.237457 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1123 18:55:59.237457 14064 solver.cpp:237]     Train net output #1: loss = 0.911173 (* 1 = 0.911173 loss)
I1123 18:55:59.237457 14064 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1123 18:56:11.302987 14064 solver.cpp:218] Iteration 1200 (8.28849 iter/s, 12.0649s/100 iters), loss = 0.964373
I1123 18:56:11.302987 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1123 18:56:11.302987 14064 solver.cpp:237]     Train net output #1: loss = 0.964373 (* 1 = 0.964373 loss)
I1123 18:56:11.302987 14064 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1123 18:56:23.365250 14064 solver.cpp:218] Iteration 1300 (8.29054 iter/s, 12.0619s/100 iters), loss = 0.730954
I1123 18:56:23.365250 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1123 18:56:23.365250 14064 solver.cpp:237]     Train net output #1: loss = 0.730954 (* 1 = 0.730954 loss)
I1123 18:56:23.365250 14064 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1123 18:56:35.425496 14064 solver.cpp:218] Iteration 1400 (8.29201 iter/s, 12.0598s/100 iters), loss = 0.898215
I1123 18:56:35.425987 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1123 18:56:35.425987 14064 solver.cpp:237]     Train net output #1: loss = 0.898215 (* 1 = 0.898215 loss)
I1123 18:56:35.425987 14064 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1123 18:56:46.936327  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:56:47.415894 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_1500.caffemodel
I1123 18:56:47.452378 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_1500.solverstate
I1123 18:56:47.470878 14064 solver.cpp:330] Iteration 1500, Testing net (#0)
I1123 18:56:47.470878 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 18:56:51.526252 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:56:51.690325 14064 solver.cpp:397]     Test net output #0: accuracy = 0.5664
I1123 18:56:51.690325 14064 solver.cpp:397]     Test net output #1: loss = 1.22733 (* 1 = 1.22733 loss)
I1123 18:56:51.810374 14064 solver.cpp:218] Iteration 1500 (6.1035 iter/s, 16.384s/100 iters), loss = 0.782015
I1123 18:56:51.810374 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1123 18:56:51.810374 14064 solver.cpp:237]     Train net output #1: loss = 0.782015 (* 1 = 0.782015 loss)
I1123 18:56:51.810374 14064 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1123 18:57:03.885967 14064 solver.cpp:218] Iteration 1600 (8.28176 iter/s, 12.0747s/100 iters), loss = 0.689936
I1123 18:57:03.885967 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1123 18:57:03.885967 14064 solver.cpp:237]     Train net output #1: loss = 0.689936 (* 1 = 0.689936 loss)
I1123 18:57:03.885967 14064 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1123 18:57:15.969991 14064 solver.cpp:218] Iteration 1700 (8.27564 iter/s, 12.0837s/100 iters), loss = 0.730663
I1123 18:57:15.969991 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1123 18:57:15.969991 14064 solver.cpp:237]     Train net output #1: loss = 0.730663 (* 1 = 0.730663 loss)
I1123 18:57:15.969991 14064 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1123 18:57:28.087791 14064 solver.cpp:218] Iteration 1800 (8.25276 iter/s, 12.1172s/100 iters), loss = 0.658923
I1123 18:57:28.087791 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1123 18:57:28.087791 14064 solver.cpp:237]     Train net output #1: loss = 0.658923 (* 1 = 0.658923 loss)
I1123 18:57:28.087791 14064 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1123 18:57:40.176836 14064 solver.cpp:218] Iteration 1900 (8.27252 iter/s, 12.0882s/100 iters), loss = 0.682455
I1123 18:57:40.176836 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1123 18:57:40.176836 14064 solver.cpp:237]     Train net output #1: loss = 0.682455 (* 1 = 0.682455 loss)
I1123 18:57:40.176836 14064 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1123 18:57:51.672559  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:57:52.151650 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_2000.caffemodel
I1123 18:57:52.194150 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_2000.solverstate
I1123 18:57:52.213135 14064 solver.cpp:330] Iteration 2000, Testing net (#0)
I1123 18:57:52.213135 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 18:57:56.266054 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:57:56.431123 14064 solver.cpp:397]     Test net output #0: accuracy = 0.6895
I1123 18:57:56.431123 14064 solver.cpp:397]     Test net output #1: loss = 0.890663 (* 1 = 0.890663 loss)
I1123 18:57:56.550170 14064 solver.cpp:218] Iteration 2000 (6.10779 iter/s, 16.3725s/100 iters), loss = 0.60215
I1123 18:57:56.550170 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1123 18:57:56.550170 14064 solver.cpp:237]     Train net output #1: loss = 0.60215 (* 1 = 0.60215 loss)
I1123 18:57:56.550170 14064 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1123 18:58:08.675868 14064 solver.cpp:218] Iteration 2100 (8.24729 iter/s, 12.1252s/100 iters), loss = 0.562909
I1123 18:58:08.675868 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1123 18:58:08.675868 14064 solver.cpp:237]     Train net output #1: loss = 0.562909 (* 1 = 0.562909 loss)
I1123 18:58:08.675868 14064 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1123 18:58:20.808682 14064 solver.cpp:218] Iteration 2200 (8.24252 iter/s, 12.1322s/100 iters), loss = 0.608027
I1123 18:58:20.808682 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1123 18:58:20.808682 14064 solver.cpp:237]     Train net output #1: loss = 0.608027 (* 1 = 0.608027 loss)
I1123 18:58:20.808682 14064 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1123 18:58:32.921716 14064 solver.cpp:218] Iteration 2300 (8.25606 iter/s, 12.1123s/100 iters), loss = 0.631941
I1123 18:58:32.921716 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1123 18:58:32.921716 14064 solver.cpp:237]     Train net output #1: loss = 0.631941 (* 1 = 0.631941 loss)
I1123 18:58:32.921716 14064 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1123 18:58:45.016482 14064 solver.cpp:218] Iteration 2400 (8.26859 iter/s, 12.094s/100 iters), loss = 0.661589
I1123 18:58:45.016482 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1123 18:58:45.016482 14064 solver.cpp:237]     Train net output #1: loss = 0.661589 (* 1 = 0.661589 loss)
I1123 18:58:45.016482 14064 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1123 18:58:56.540212  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:58:57.018713 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_2500.caffemodel
I1123 18:58:57.056713 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_2500.solverstate
I1123 18:58:57.075713 14064 solver.cpp:330] Iteration 2500, Testing net (#0)
I1123 18:58:57.075713 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 18:59:01.132383 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 18:59:01.298712 14064 solver.cpp:397]     Test net output #0: accuracy = 0.6188
I1123 18:59:01.298712 14064 solver.cpp:397]     Test net output #1: loss = 1.06568 (* 1 = 1.06568 loss)
I1123 18:59:01.417245 14064 solver.cpp:218] Iteration 2500 (6.09763 iter/s, 16.3998s/100 iters), loss = 0.561229
I1123 18:59:01.417245 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1123 18:59:01.417245 14064 solver.cpp:237]     Train net output #1: loss = 0.561229 (* 1 = 0.561229 loss)
I1123 18:59:01.417245 14064 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1123 18:59:13.514667 14064 solver.cpp:218] Iteration 2600 (8.26612 iter/s, 12.0976s/100 iters), loss = 0.494728
I1123 18:59:13.514667 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1123 18:59:13.514667 14064 solver.cpp:237]     Train net output #1: loss = 0.494728 (* 1 = 0.494728 loss)
I1123 18:59:13.514667 14064 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1123 18:59:25.639196 14064 solver.cpp:218] Iteration 2700 (8.24874 iter/s, 12.1231s/100 iters), loss = 0.561734
I1123 18:59:25.639196 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1123 18:59:25.639196 14064 solver.cpp:237]     Train net output #1: loss = 0.561734 (* 1 = 0.561734 loss)
I1123 18:59:25.639196 14064 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1123 18:59:37.689424 14064 solver.cpp:218] Iteration 2800 (8.29902 iter/s, 12.0496s/100 iters), loss = 0.608561
I1123 18:59:37.689424 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1123 18:59:37.689424 14064 solver.cpp:237]     Train net output #1: loss = 0.608561 (* 1 = 0.608561 loss)
I1123 18:59:37.689424 14064 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1123 18:59:49.736325 14064 solver.cpp:218] Iteration 2900 (8.30129 iter/s, 12.0463s/100 iters), loss = 0.575572
I1123 18:59:49.736325 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1123 18:59:49.736325 14064 solver.cpp:237]     Train net output #1: loss = 0.575572 (* 1 = 0.575572 loss)
I1123 18:59:49.736325 14064 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1123 19:00:01.206271  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:00:01.699890 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_3000.caffemodel
I1123 19:00:01.741909 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_3000.solverstate
I1123 19:00:01.760910 14064 solver.cpp:330] Iteration 3000, Testing net (#0)
I1123 19:00:01.760910 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:00:05.824229 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:00:05.990250 14064 solver.cpp:397]     Test net output #0: accuracy = 0.6674
I1123 19:00:05.990250 14064 solver.cpp:397]     Test net output #1: loss = 0.94947 (* 1 = 0.94947 loss)
I1123 19:00:06.109277 14064 solver.cpp:218] Iteration 3000 (6.10787 iter/s, 16.3723s/100 iters), loss = 0.607422
I1123 19:00:06.109277 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1123 19:00:06.109277 14064 solver.cpp:237]     Train net output #1: loss = 0.607422 (* 1 = 0.607422 loss)
I1123 19:00:06.109277 14064 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1123 19:00:18.388406 14064 solver.cpp:218] Iteration 3100 (8.14418 iter/s, 12.2787s/100 iters), loss = 0.50232
I1123 19:00:18.388406 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1123 19:00:18.388406 14064 solver.cpp:237]     Train net output #1: loss = 0.50232 (* 1 = 0.50232 loss)
I1123 19:00:18.388406 14064 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1123 19:00:30.622123 14064 solver.cpp:218] Iteration 3200 (8.17478 iter/s, 12.2327s/100 iters), loss = 0.605574
I1123 19:00:30.622123 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1123 19:00:30.622123 14064 solver.cpp:237]     Train net output #1: loss = 0.605574 (* 1 = 0.605574 loss)
I1123 19:00:30.622123 14064 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1123 19:00:43.025586 14064 solver.cpp:218] Iteration 3300 (8.06265 iter/s, 12.4029s/100 iters), loss = 0.577774
I1123 19:00:43.025586 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1123 19:00:43.025586 14064 solver.cpp:237]     Train net output #1: loss = 0.577774 (* 1 = 0.577774 loss)
I1123 19:00:43.025586 14064 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1123 19:00:55.442605 14064 solver.cpp:218] Iteration 3400 (8.05395 iter/s, 12.4163s/100 iters), loss = 0.592551
I1123 19:00:55.442605 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1123 19:00:55.442605 14064 solver.cpp:237]     Train net output #1: loss = 0.592551 (* 1 = 0.592551 loss)
I1123 19:00:55.442605 14064 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1123 19:01:07.257117  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:01:07.747617 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_3500.caffemodel
I1123 19:01:07.790115 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_3500.solverstate
I1123 19:01:07.808615 14064 solver.cpp:330] Iteration 3500, Testing net (#0)
I1123 19:01:07.809115 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:01:11.922118 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:01:12.089619 14064 solver.cpp:397]     Test net output #0: accuracy = 0.7481
I1123 19:01:12.089619 14064 solver.cpp:397]     Test net output #1: loss = 0.739076 (* 1 = 0.739076 loss)
I1123 19:01:12.210630 14064 solver.cpp:218] Iteration 3500 (5.96398 iter/s, 16.7673s/100 iters), loss = 0.50731
I1123 19:01:12.210630 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1123 19:01:12.210630 14064 solver.cpp:237]     Train net output #1: loss = 0.50731 (* 1 = 0.50731 loss)
I1123 19:01:12.210630 14064 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1123 19:01:24.541880 14064 solver.cpp:218] Iteration 3600 (8.10968 iter/s, 12.3309s/100 iters), loss = 0.51322
I1123 19:01:24.542379 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1123 19:01:24.542379 14064 solver.cpp:237]     Train net output #1: loss = 0.51322 (* 1 = 0.51322 loss)
I1123 19:01:24.542379 14064 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1123 19:01:36.882556 14064 solver.cpp:218] Iteration 3700 (8.10399 iter/s, 12.3396s/100 iters), loss = 0.526011
I1123 19:01:36.882556 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1123 19:01:36.882556 14064 solver.cpp:237]     Train net output #1: loss = 0.526011 (* 1 = 0.526011 loss)
I1123 19:01:36.882556 14064 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1123 19:01:49.024375 14064 solver.cpp:218] Iteration 3800 (8.23585 iter/s, 12.142s/100 iters), loss = 0.588122
I1123 19:01:49.024375 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1123 19:01:49.025370 14064 solver.cpp:237]     Train net output #1: loss = 0.588122 (* 1 = 0.588122 loss)
I1123 19:01:49.025370 14064 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1123 19:02:01.133244 14064 solver.cpp:218] Iteration 3900 (8.25947 iter/s, 12.1073s/100 iters), loss = 0.563186
I1123 19:02:01.133244 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1123 19:02:01.133244 14064 solver.cpp:237]     Train net output #1: loss = 0.563186 (* 1 = 0.563186 loss)
I1123 19:02:01.133244 14064 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1123 19:02:12.646877  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:02:13.131410 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_4000.caffemodel
I1123 19:02:13.172905 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_4000.solverstate
I1123 19:02:13.191423 14064 solver.cpp:330] Iteration 4000, Testing net (#0)
I1123 19:02:13.191906 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:02:17.249138 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:02:17.414675 14064 solver.cpp:397]     Test net output #0: accuracy = 0.6444
I1123 19:02:17.414675 14064 solver.cpp:397]     Test net output #1: loss = 1.05561 (* 1 = 1.05561 loss)
I1123 19:02:17.532696 14064 solver.cpp:218] Iteration 4000 (6.09787 iter/s, 16.3992s/100 iters), loss = 0.515383
I1123 19:02:17.532696 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1123 19:02:17.532696 14064 solver.cpp:237]     Train net output #1: loss = 0.515383 (* 1 = 0.515383 loss)
I1123 19:02:17.532696 14064 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1123 19:02:29.593966 14064 solver.cpp:218] Iteration 4100 (8.29175 iter/s, 12.0602s/100 iters), loss = 0.487856
I1123 19:02:29.593966 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1123 19:02:29.593966 14064 solver.cpp:237]     Train net output #1: loss = 0.487856 (* 1 = 0.487856 loss)
I1123 19:02:29.593966 14064 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1123 19:02:41.667467 14064 solver.cpp:218] Iteration 4200 (8.28289 iter/s, 12.0731s/100 iters), loss = 0.470782
I1123 19:02:41.667467 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1123 19:02:41.667467 14064 solver.cpp:237]     Train net output #1: loss = 0.470782 (* 1 = 0.470782 loss)
I1123 19:02:41.667467 14064 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1123 19:02:53.815631 14064 solver.cpp:218] Iteration 4300 (8.23209 iter/s, 12.1476s/100 iters), loss = 0.521723
I1123 19:02:53.815631 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1123 19:02:53.815631 14064 solver.cpp:237]     Train net output #1: loss = 0.521723 (* 1 = 0.521723 loss)
I1123 19:02:53.815631 14064 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1123 19:03:05.861683 14064 solver.cpp:218] Iteration 4400 (8.30205 iter/s, 12.0452s/100 iters), loss = 0.493754
I1123 19:03:05.861683 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1123 19:03:05.861683 14064 solver.cpp:237]     Train net output #1: loss = 0.493754 (* 1 = 0.493754 loss)
I1123 19:03:05.861683 14064 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1123 19:03:17.332495  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:03:17.821360 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_4500.caffemodel
I1123 19:03:17.862866 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_4500.solverstate
I1123 19:03:17.881867 14064 solver.cpp:330] Iteration 4500, Testing net (#0)
I1123 19:03:17.881867 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:03:22.012821 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:03:22.178875 14064 solver.cpp:397]     Test net output #0: accuracy = 0.6489
I1123 19:03:22.178875 14064 solver.cpp:397]     Test net output #1: loss = 1.08694 (* 1 = 1.08694 loss)
I1123 19:03:22.296936 14064 solver.cpp:218] Iteration 4500 (6.08456 iter/s, 16.435s/100 iters), loss = 0.341158
I1123 19:03:22.296936 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1123 19:03:22.296936 14064 solver.cpp:237]     Train net output #1: loss = 0.341158 (* 1 = 0.341158 loss)
I1123 19:03:22.296936 14064 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1123 19:03:34.354014 14064 solver.cpp:218] Iteration 4600 (8.29439 iter/s, 12.0563s/100 iters), loss = 0.505004
I1123 19:03:34.354504 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1123 19:03:34.354504 14064 solver.cpp:237]     Train net output #1: loss = 0.505004 (* 1 = 0.505004 loss)
I1123 19:03:34.354504 14064 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1123 19:03:46.494372 14064 solver.cpp:218] Iteration 4700 (8.23755 iter/s, 12.1395s/100 iters), loss = 0.539862
I1123 19:03:46.494372 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1123 19:03:46.494372 14064 solver.cpp:237]     Train net output #1: loss = 0.539862 (* 1 = 0.539862 loss)
I1123 19:03:46.494372 14064 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1123 19:03:58.734814 14064 solver.cpp:218] Iteration 4800 (8.17018 iter/s, 12.2396s/100 iters), loss = 0.463565
I1123 19:03:58.734814 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1123 19:03:58.734814 14064 solver.cpp:237]     Train net output #1: loss = 0.463565 (* 1 = 0.463565 loss)
I1123 19:03:58.734814 14064 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1123 19:04:10.948652 14064 solver.cpp:218] Iteration 4900 (8.18778 iter/s, 12.2133s/100 iters), loss = 0.464984
I1123 19:04:10.948652 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1123 19:04:10.948652 14064 solver.cpp:237]     Train net output #1: loss = 0.464984 (* 1 = 0.464984 loss)
I1123 19:04:10.948652 14064 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1123 19:04:22.535236  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:04:23.018296 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_5000.caffemodel
I1123 19:04:23.058295 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_5000.solverstate
I1123 19:04:23.077294 14064 solver.cpp:330] Iteration 5000, Testing net (#0)
I1123 19:04:23.077294 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:04:27.124661 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:04:27.289712 14064 solver.cpp:397]     Test net output #0: accuracy = 0.684
I1123 19:04:27.289712 14064 solver.cpp:397]     Test net output #1: loss = 0.911613 (* 1 = 0.911613 loss)
I1123 19:04:27.407763 14064 solver.cpp:218] Iteration 5000 (6.07568 iter/s, 16.4591s/100 iters), loss = 0.483246
I1123 19:04:27.407763 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1123 19:04:27.407763 14064 solver.cpp:237]     Train net output #1: loss = 0.483246 (* 1 = 0.483246 loss)
I1123 19:04:27.407763 14064 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I1123 19:04:27.407763 14064 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1123 19:04:39.553117 14064 solver.cpp:218] Iteration 5100 (8.2345 iter/s, 12.144s/100 iters), loss = 0.367634
I1123 19:04:39.553117 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1123 19:04:39.553117 14064 solver.cpp:237]     Train net output #1: loss = 0.367634 (* 1 = 0.367634 loss)
I1123 19:04:39.553117 14064 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1123 19:04:51.697674 14064 solver.cpp:218] Iteration 5200 (8.23457 iter/s, 12.1439s/100 iters), loss = 0.391436
I1123 19:04:51.697674 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1123 19:04:51.697674 14064 solver.cpp:237]     Train net output #1: loss = 0.391436 (* 1 = 0.391436 loss)
I1123 19:04:51.697674 14064 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1123 19:05:03.783092 14064 solver.cpp:218] Iteration 5300 (8.27466 iter/s, 12.0851s/100 iters), loss = 0.338306
I1123 19:05:03.783591 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1123 19:05:03.783591 14064 solver.cpp:237]     Train net output #1: loss = 0.338306 (* 1 = 0.338306 loss)
I1123 19:05:03.783591 14064 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1123 19:05:15.854591 14064 solver.cpp:218] Iteration 5400 (8.28411 iter/s, 12.0713s/100 iters), loss = 0.302036
I1123 19:05:15.855579 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 19:05:15.855579 14064 solver.cpp:237]     Train net output #1: loss = 0.302036 (* 1 = 0.302036 loss)
I1123 19:05:15.855579 14064 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1123 19:05:27.377329  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:05:27.856832 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_5500.caffemodel
I1123 19:05:27.895330 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_5500.solverstate
I1123 19:05:27.913831 14064 solver.cpp:330] Iteration 5500, Testing net (#0)
I1123 19:05:27.913831 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:05:31.959890 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:05:32.125970 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8596
I1123 19:05:32.125970 14064 solver.cpp:397]     Test net output #1: loss = 0.402707 (* 1 = 0.402707 loss)
I1123 19:05:32.244962 14064 solver.cpp:218] Iteration 5500 (6.10161 iter/s, 16.3891s/100 iters), loss = 0.240171
I1123 19:05:32.244962 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 19:05:32.244962 14064 solver.cpp:237]     Train net output #1: loss = 0.240171 (* 1 = 0.240171 loss)
I1123 19:05:32.244962 14064 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1123 19:05:44.464275 14064 solver.cpp:218] Iteration 5600 (8.18444 iter/s, 12.2183s/100 iters), loss = 0.330621
I1123 19:05:44.464275 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1123 19:05:44.464275 14064 solver.cpp:237]     Train net output #1: loss = 0.330621 (* 1 = 0.330621 loss)
I1123 19:05:44.464275 14064 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1123 19:05:56.578830 14064 solver.cpp:218] Iteration 5700 (8.25476 iter/s, 12.1142s/100 iters), loss = 0.328694
I1123 19:05:56.578830 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1123 19:05:56.578830 14064 solver.cpp:237]     Train net output #1: loss = 0.328694 (* 1 = 0.328694 loss)
I1123 19:05:56.578830 14064 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1123 19:06:08.889138 14064 solver.cpp:218] Iteration 5800 (8.12376 iter/s, 12.3096s/100 iters), loss = 0.278043
I1123 19:06:08.889138 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 19:06:08.889138 14064 solver.cpp:237]     Train net output #1: loss = 0.278043 (* 1 = 0.278043 loss)
I1123 19:06:08.889138 14064 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1123 19:06:20.968513 14064 solver.cpp:218] Iteration 5900 (8.27908 iter/s, 12.0786s/100 iters), loss = 0.224457
I1123 19:06:20.968513 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:06:20.968513 14064 solver.cpp:237]     Train net output #1: loss = 0.224457 (* 1 = 0.224457 loss)
I1123 19:06:20.968513 14064 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1123 19:06:32.417063  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:06:32.895047 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_6000.caffemodel
I1123 19:06:32.936547 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_6000.solverstate
I1123 19:06:32.954546 14064 solver.cpp:330] Iteration 6000, Testing net (#0)
I1123 19:06:32.955046 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:06:36.992142 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:06:37.156430 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8666
I1123 19:06:37.156430 14064 solver.cpp:397]     Test net output #1: loss = 0.385765 (* 1 = 0.385765 loss)
I1123 19:06:37.274443 14064 solver.cpp:218] Iteration 6000 (6.13303 iter/s, 16.3052s/100 iters), loss = 0.236408
I1123 19:06:37.274443 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:06:37.274443 14064 solver.cpp:237]     Train net output #1: loss = 0.236408 (* 1 = 0.236408 loss)
I1123 19:06:37.274443 14064 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1123 19:06:49.334985 14064 solver.cpp:218] Iteration 6100 (8.29177 iter/s, 12.0601s/100 iters), loss = 0.357412
I1123 19:06:49.334985 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1123 19:06:49.334985 14064 solver.cpp:237]     Train net output #1: loss = 0.357412 (* 1 = 0.357412 loss)
I1123 19:06:49.334985 14064 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1123 19:07:01.404307 14064 solver.cpp:218] Iteration 6200 (8.28618 iter/s, 12.0683s/100 iters), loss = 0.214053
I1123 19:07:01.404307 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:07:01.404307 14064 solver.cpp:237]     Train net output #1: loss = 0.214053 (* 1 = 0.214053 loss)
I1123 19:07:01.404307 14064 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1123 19:07:13.452236 14064 solver.cpp:218] Iteration 6300 (8.30054 iter/s, 12.0474s/100 iters), loss = 0.283001
I1123 19:07:13.452236 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1123 19:07:13.452236 14064 solver.cpp:237]     Train net output #1: loss = 0.283001 (* 1 = 0.283001 loss)
I1123 19:07:13.452236 14064 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1123 19:07:25.526137 14064 solver.cpp:218] Iteration 6400 (8.28275 iter/s, 12.0733s/100 iters), loss = 0.217304
I1123 19:07:25.526137 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 19:07:25.526137 14064 solver.cpp:237]     Train net output #1: loss = 0.217304 (* 1 = 0.217304 loss)
I1123 19:07:25.526137 14064 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1123 19:07:37.040360  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:07:37.523409 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_6500.caffemodel
I1123 19:07:37.563894 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_6500.solverstate
I1123 19:07:37.582892 14064 solver.cpp:330] Iteration 6500, Testing net (#0)
I1123 19:07:37.582892 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:07:41.626206 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:07:41.791218 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8715
I1123 19:07:41.791218 14064 solver.cpp:397]     Test net output #1: loss = 0.376072 (* 1 = 0.376072 loss)
I1123 19:07:41.910223 14064 solver.cpp:218] Iteration 6500 (6.10346 iter/s, 16.3841s/100 iters), loss = 0.170435
I1123 19:07:41.910223 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:07:41.910223 14064 solver.cpp:237]     Train net output #1: loss = 0.170435 (* 1 = 0.170435 loss)
I1123 19:07:41.910223 14064 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1123 19:07:53.969576 14064 solver.cpp:218] Iteration 6600 (8.29295 iter/s, 12.0584s/100 iters), loss = 0.254783
I1123 19:07:53.969576 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 19:07:53.969576 14064 solver.cpp:237]     Train net output #1: loss = 0.254783 (* 1 = 0.254783 loss)
I1123 19:07:53.969576 14064 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1123 19:08:06.133669 14064 solver.cpp:218] Iteration 6700 (8.22165 iter/s, 12.163s/100 iters), loss = 0.224925
I1123 19:08:06.133669 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:08:06.133669 14064 solver.cpp:237]     Train net output #1: loss = 0.224926 (* 1 = 0.224926 loss)
I1123 19:08:06.133669 14064 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1123 19:08:18.192436 14064 solver.cpp:218] Iteration 6800 (8.29299 iter/s, 12.0584s/100 iters), loss = 0.215365
I1123 19:08:18.192436 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 19:08:18.192436 14064 solver.cpp:237]     Train net output #1: loss = 0.215365 (* 1 = 0.215365 loss)
I1123 19:08:18.192436 14064 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1123 19:08:30.260779 14064 solver.cpp:218] Iteration 6900 (8.28675 iter/s, 12.0675s/100 iters), loss = 0.21137
I1123 19:08:30.260779 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 19:08:30.260779 14064 solver.cpp:237]     Train net output #1: loss = 0.21137 (* 1 = 0.21137 loss)
I1123 19:08:30.260779 14064 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1123 19:08:41.716368  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:08:42.194404 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_7000.caffemodel
I1123 19:08:42.230897 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_7000.solverstate
I1123 19:08:42.248919 14064 solver.cpp:330] Iteration 7000, Testing net (#0)
I1123 19:08:42.248919 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:08:46.291132 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:08:46.457664 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8727
I1123 19:08:46.457664 14064 solver.cpp:397]     Test net output #1: loss = 0.371485 (* 1 = 0.371485 loss)
I1123 19:08:46.576392 14064 solver.cpp:218] Iteration 7000 (6.12933 iter/s, 16.315s/100 iters), loss = 0.161315
I1123 19:08:46.576392 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:08:46.576392 14064 solver.cpp:237]     Train net output #1: loss = 0.161315 (* 1 = 0.161315 loss)
I1123 19:08:46.576392 14064 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1123 19:08:58.623754 14064 solver.cpp:218] Iteration 7100 (8.30105 iter/s, 12.0467s/100 iters), loss = 0.221395
I1123 19:08:58.623754 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 19:08:58.623754 14064 solver.cpp:237]     Train net output #1: loss = 0.221395 (* 1 = 0.221395 loss)
I1123 19:08:58.623754 14064 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1123 19:09:10.692072 14064 solver.cpp:218] Iteration 7200 (8.28632 iter/s, 12.0681s/100 iters), loss = 0.227757
I1123 19:09:10.692572 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:09:10.692572 14064 solver.cpp:237]     Train net output #1: loss = 0.227757 (* 1 = 0.227757 loss)
I1123 19:09:10.692572 14064 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1123 19:09:22.734220 14064 solver.cpp:218] Iteration 7300 (8.30467 iter/s, 12.0414s/100 iters), loss = 0.165271
I1123 19:09:22.734220 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:09:22.734220 14064 solver.cpp:237]     Train net output #1: loss = 0.165271 (* 1 = 0.165271 loss)
I1123 19:09:22.734220 14064 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1123 19:09:34.777343 14064 solver.cpp:218] Iteration 7400 (8.30387 iter/s, 12.0426s/100 iters), loss = 0.208859
I1123 19:09:34.777343 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 19:09:34.777842 14064 solver.cpp:237]     Train net output #1: loss = 0.208859 (* 1 = 0.208859 loss)
I1123 19:09:34.777842 14064 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1123 19:09:46.225303  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:09:46.702850 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_7500.caffemodel
I1123 19:09:46.742350 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_7500.solverstate
I1123 19:09:46.761349 14064 solver.cpp:330] Iteration 7500, Testing net (#0)
I1123 19:09:46.761349 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:09:50.795938 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:09:50.961483 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8672
I1123 19:09:50.961483 14064 solver.cpp:397]     Test net output #1: loss = 0.390428 (* 1 = 0.390428 loss)
I1123 19:09:51.079522 14064 solver.cpp:218] Iteration 7500 (6.13442 iter/s, 16.3015s/100 iters), loss = 0.186064
I1123 19:09:51.079522 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 19:09:51.079522 14064 solver.cpp:237]     Train net output #1: loss = 0.186064 (* 1 = 0.186064 loss)
I1123 19:09:51.079522 14064 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1123 19:10:03.178067 14064 solver.cpp:218] Iteration 7600 (8.26562 iter/s, 12.0983s/100 iters), loss = 0.268596
I1123 19:10:03.178067 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 19:10:03.178067 14064 solver.cpp:237]     Train net output #1: loss = 0.268596 (* 1 = 0.268596 loss)
I1123 19:10:03.178067 14064 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1123 19:10:15.236837 14064 solver.cpp:218] Iteration 7700 (8.29361 iter/s, 12.0575s/100 iters), loss = 0.178973
I1123 19:10:15.236837 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:10:15.236837 14064 solver.cpp:237]     Train net output #1: loss = 0.178973 (* 1 = 0.178973 loss)
I1123 19:10:15.236837 14064 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1123 19:10:27.279964 14064 solver.cpp:218] Iteration 7800 (8.30378 iter/s, 12.0427s/100 iters), loss = 0.234506
I1123 19:10:27.279964 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 19:10:27.279964 14064 solver.cpp:237]     Train net output #1: loss = 0.234506 (* 1 = 0.234506 loss)
I1123 19:10:27.279964 14064 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1123 19:10:39.336513 14064 solver.cpp:218] Iteration 7900 (8.29486 iter/s, 12.0557s/100 iters), loss = 0.195377
I1123 19:10:39.336513 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 19:10:39.336513 14064 solver.cpp:237]     Train net output #1: loss = 0.195377 (* 1 = 0.195377 loss)
I1123 19:10:39.336513 14064 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1123 19:10:50.777161  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:10:51.256718 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_8000.caffemodel
I1123 19:10:51.322274 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_8000.solverstate
I1123 19:10:51.342278 14064 solver.cpp:330] Iteration 8000, Testing net (#0)
I1123 19:10:51.342278 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:10:55.383498 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:10:55.548569 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I1123 19:10:55.548569 14064 solver.cpp:397]     Test net output #1: loss = 0.371927 (* 1 = 0.371927 loss)
I1123 19:10:55.667619 14064 solver.cpp:218] Iteration 8000 (6.12357 iter/s, 16.3303s/100 iters), loss = 0.156516
I1123 19:10:55.667619 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:10:55.667619 14064 solver.cpp:237]     Train net output #1: loss = 0.156516 (* 1 = 0.156516 loss)
I1123 19:10:55.667619 14064 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1123 19:11:07.776425 14064 solver.cpp:218] Iteration 8100 (8.25882 iter/s, 12.1083s/100 iters), loss = 0.286844
I1123 19:11:07.776425 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1123 19:11:07.776425 14064 solver.cpp:237]     Train net output #1: loss = 0.286844 (* 1 = 0.286844 loss)
I1123 19:11:07.776425 14064 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1123 19:11:19.899421 14064 solver.cpp:218] Iteration 8200 (8.24928 iter/s, 12.1223s/100 iters), loss = 0.188179
I1123 19:11:19.899421 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:11:19.899421 14064 solver.cpp:237]     Train net output #1: loss = 0.188179 (* 1 = 0.188179 loss)
I1123 19:11:19.899421 14064 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1123 19:11:32.039165 14064 solver.cpp:218] Iteration 8300 (8.23788 iter/s, 12.139s/100 iters), loss = 0.200315
I1123 19:11:32.039165 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 19:11:32.039165 14064 solver.cpp:237]     Train net output #1: loss = 0.200315 (* 1 = 0.200315 loss)
I1123 19:11:32.039165 14064 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1123 19:11:44.122555 14064 solver.cpp:218] Iteration 8400 (8.27606 iter/s, 12.083s/100 iters), loss = 0.151615
I1123 19:11:44.122555 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:11:44.122555 14064 solver.cpp:237]     Train net output #1: loss = 0.151615 (* 1 = 0.151615 loss)
I1123 19:11:44.122555 14064 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1123 19:11:55.564422  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:11:56.043421 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_8500.caffemodel
I1123 19:11:56.083421 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_8500.solverstate
I1123 19:11:56.102921 14064 solver.cpp:330] Iteration 8500, Testing net (#0)
I1123 19:11:56.102921 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:12:00.142477 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:12:00.307536 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8674
I1123 19:12:00.307536 14064 solver.cpp:397]     Test net output #1: loss = 0.386772 (* 1 = 0.386772 loss)
I1123 19:12:00.425601 14064 solver.cpp:218] Iteration 8500 (6.13406 iter/s, 16.3024s/100 iters), loss = 0.142674
I1123 19:12:00.425601 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:12:00.425601 14064 solver.cpp:237]     Train net output #1: loss = 0.142674 (* 1 = 0.142674 loss)
I1123 19:12:00.425601 14064 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1123 19:12:12.573400 14064 solver.cpp:218] Iteration 8600 (8.23243 iter/s, 12.1471s/100 iters), loss = 0.167771
I1123 19:12:12.573400 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:12:12.573400 14064 solver.cpp:237]     Train net output #1: loss = 0.167771 (* 1 = 0.167771 loss)
I1123 19:12:12.573400 14064 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1123 19:12:24.683610 14064 solver.cpp:218] Iteration 8700 (8.25789 iter/s, 12.1096s/100 iters), loss = 0.197191
I1123 19:12:24.684111 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 19:12:24.684111 14064 solver.cpp:237]     Train net output #1: loss = 0.197191 (* 1 = 0.197191 loss)
I1123 19:12:24.684111 14064 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1123 19:12:36.764047 14064 solver.cpp:218] Iteration 8800 (8.27833 iter/s, 12.0797s/100 iters), loss = 0.159745
I1123 19:12:36.764047 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:12:36.764047 14064 solver.cpp:237]     Train net output #1: loss = 0.159745 (* 1 = 0.159745 loss)
I1123 19:12:36.764047 14064 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1123 19:12:48.879313 14064 solver.cpp:218] Iteration 8900 (8.2546 iter/s, 12.1145s/100 iters), loss = 0.171318
I1123 19:12:48.879313 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:12:48.879313 14064 solver.cpp:237]     Train net output #1: loss = 0.171318 (* 1 = 0.171318 loss)
I1123 19:12:48.879313 14064 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1123 19:13:00.444335  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:13:00.925882 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_9000.caffemodel
I1123 19:13:00.964383 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_9000.solverstate
I1123 19:13:01.014441 14064 solver.cpp:330] Iteration 9000, Testing net (#0)
I1123 19:13:01.014441 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:13:05.057312 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:13:05.223382 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8738
I1123 19:13:05.223382 14064 solver.cpp:397]     Test net output #1: loss = 0.37319 (* 1 = 0.37319 loss)
I1123 19:13:05.341362 14064 solver.cpp:218] Iteration 9000 (6.07476 iter/s, 16.4616s/100 iters), loss = 0.158068
I1123 19:13:05.341362 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:13:05.341362 14064 solver.cpp:237]     Train net output #1: loss = 0.158068 (* 1 = 0.158068 loss)
I1123 19:13:05.341362 14064 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1123 19:13:17.405733 14064 solver.cpp:218] Iteration 9100 (8.28927 iter/s, 12.0638s/100 iters), loss = 0.194564
I1123 19:13:17.405733 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:13:17.405733 14064 solver.cpp:237]     Train net output #1: loss = 0.194564 (* 1 = 0.194564 loss)
I1123 19:13:17.405733 14064 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1123 19:13:29.475134 14064 solver.cpp:218] Iteration 9200 (8.28583 iter/s, 12.0688s/100 iters), loss = 0.151763
I1123 19:13:29.475134 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:13:29.475134 14064 solver.cpp:237]     Train net output #1: loss = 0.151763 (* 1 = 0.151763 loss)
I1123 19:13:29.475134 14064 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1123 19:13:41.527463 14064 solver.cpp:218] Iteration 9300 (8.29779 iter/s, 12.0514s/100 iters), loss = 0.109578
I1123 19:13:41.527463 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:13:41.527463 14064 solver.cpp:237]     Train net output #1: loss = 0.109578 (* 1 = 0.109578 loss)
I1123 19:13:41.527463 14064 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1123 19:13:53.574084 14064 solver.cpp:218] Iteration 9400 (8.30128 iter/s, 12.0463s/100 iters), loss = 0.13779
I1123 19:13:53.574084 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:13:53.574084 14064 solver.cpp:237]     Train net output #1: loss = 0.13779 (* 1 = 0.13779 loss)
I1123 19:13:53.574084 14064 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1123 19:14:05.079949  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:14:05.561540 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_9500.caffemodel
I1123 19:14:05.601032 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_9500.solverstate
I1123 19:14:05.640091 14064 solver.cpp:330] Iteration 9500, Testing net (#0)
I1123 19:14:05.640091 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:14:09.693537 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:14:09.859581 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8666
I1123 19:14:09.859581 14064 solver.cpp:397]     Test net output #1: loss = 0.412242 (* 1 = 0.412242 loss)
I1123 19:14:09.978490 14064 solver.cpp:218] Iteration 9500 (6.0961 iter/s, 16.4039s/100 iters), loss = 0.154895
I1123 19:14:09.978490 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:14:09.978490 14064 solver.cpp:237]     Train net output #1: loss = 0.154895 (* 1 = 0.154895 loss)
I1123 19:14:09.978490 14064 sgd_solver.cpp:46] MultiStep Status: Iteration 9500, step = 2
I1123 19:14:09.978490 14064 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1123 19:14:22.084828 14064 solver.cpp:218] Iteration 9600 (8.26085 iter/s, 12.1053s/100 iters), loss = 0.185201
I1123 19:14:22.084828 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:14:22.084828 14064 solver.cpp:237]     Train net output #1: loss = 0.185201 (* 1 = 0.185201 loss)
I1123 19:14:22.084828 14064 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1123 19:14:34.135481 14064 solver.cpp:218] Iteration 9700 (8.29856 iter/s, 12.0503s/100 iters), loss = 0.145958
I1123 19:14:34.135481 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:14:34.135481 14064 solver.cpp:237]     Train net output #1: loss = 0.145958 (* 1 = 0.145958 loss)
I1123 19:14:34.135982 14064 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I1123 19:14:46.181344 14064 solver.cpp:218] Iteration 9800 (8.30227 iter/s, 12.0449s/100 iters), loss = 0.115347
I1123 19:14:46.181344 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:14:46.181344 14064 solver.cpp:237]     Train net output #1: loss = 0.115347 (* 1 = 0.115347 loss)
I1123 19:14:46.181344 14064 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1123 19:14:58.225324 14064 solver.cpp:218] Iteration 9900 (8.30341 iter/s, 12.0432s/100 iters), loss = 0.129121
I1123 19:14:58.225324 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:14:58.225324 14064 solver.cpp:237]     Train net output #1: loss = 0.129121 (* 1 = 0.129121 loss)
I1123 19:14:58.225324 14064 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I1123 19:15:09.675180  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:15:10.154682 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_10000.caffemodel
I1123 19:15:10.198680 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_10000.solverstate
I1123 19:15:10.217181 14064 solver.cpp:330] Iteration 10000, Testing net (#0)
I1123 19:15:10.217181 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:15:14.252449 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:15:14.417956 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8882
I1123 19:15:14.417956 14064 solver.cpp:397]     Test net output #1: loss = 0.340969 (* 1 = 0.340969 loss)
I1123 19:15:14.534982 14064 solver.cpp:218] Iteration 10000 (6.13139 iter/s, 16.3095s/100 iters), loss = 0.116217
I1123 19:15:14.534982 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:15:14.534982 14064 solver.cpp:237]     Train net output #1: loss = 0.116217 (* 1 = 0.116217 loss)
I1123 19:15:14.534982 14064 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I1123 19:15:26.618549 14064 solver.cpp:218] Iteration 10100 (8.27653 iter/s, 12.0824s/100 iters), loss = 0.168129
I1123 19:15:26.618549 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:15:26.618549 14064 solver.cpp:237]     Train net output #1: loss = 0.168129 (* 1 = 0.168129 loss)
I1123 19:15:26.618549 14064 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I1123 19:15:38.674420 14064 solver.cpp:218] Iteration 10200 (8.295 iter/s, 12.0555s/100 iters), loss = 0.171121
I1123 19:15:38.674420 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:15:38.674420 14064 solver.cpp:237]     Train net output #1: loss = 0.171121 (* 1 = 0.171121 loss)
I1123 19:15:38.674420 14064 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I1123 19:15:50.733220 14064 solver.cpp:218] Iteration 10300 (8.29313 iter/s, 12.0582s/100 iters), loss = 0.0993026
I1123 19:15:50.733220 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:15:50.733220 14064 solver.cpp:237]     Train net output #1: loss = 0.0993026 (* 1 = 0.0993026 loss)
I1123 19:15:50.733220 14064 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I1123 19:16:02.796738 14064 solver.cpp:218] Iteration 10400 (8.28967 iter/s, 12.0632s/100 iters), loss = 0.102567
I1123 19:16:02.797240 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:16:02.797240 14064 solver.cpp:237]     Train net output #1: loss = 0.102567 (* 1 = 0.102567 loss)
I1123 19:16:02.797240 14064 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I1123 19:16:14.267084  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:16:14.744670 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_10500.caffemodel
I1123 19:16:14.783170 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_10500.solverstate
I1123 19:16:14.801688 14064 solver.cpp:330] Iteration 10500, Testing net (#0)
I1123 19:16:14.801688 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:16:18.841032 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:16:19.005930 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8894
I1123 19:16:19.005930 14064 solver.cpp:397]     Test net output #1: loss = 0.341366 (* 1 = 0.341366 loss)
I1123 19:16:19.124526 14064 solver.cpp:218] Iteration 10500 (6.12476 iter/s, 16.3272s/100 iters), loss = 0.115958
I1123 19:16:19.124526 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:16:19.124526 14064 solver.cpp:237]     Train net output #1: loss = 0.115958 (* 1 = 0.115958 loss)
I1123 19:16:19.124526 14064 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I1123 19:16:31.184480 14064 solver.cpp:218] Iteration 10600 (8.29238 iter/s, 12.0593s/100 iters), loss = 0.137351
I1123 19:16:31.184980 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:16:31.184980 14064 solver.cpp:237]     Train net output #1: loss = 0.137351 (* 1 = 0.137351 loss)
I1123 19:16:31.184980 14064 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I1123 19:16:43.245533 14064 solver.cpp:218] Iteration 10700 (8.29175 iter/s, 12.0602s/100 iters), loss = 0.0968657
I1123 19:16:43.245533 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:16:43.245533 14064 solver.cpp:237]     Train net output #1: loss = 0.0968658 (* 1 = 0.0968658 loss)
I1123 19:16:43.245533 14064 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I1123 19:16:55.287892 14064 solver.cpp:218] Iteration 10800 (8.30432 iter/s, 12.0419s/100 iters), loss = 0.102688
I1123 19:16:55.288383 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:16:55.288383 14064 solver.cpp:237]     Train net output #1: loss = 0.102688 (* 1 = 0.102688 loss)
I1123 19:16:55.288383 14064 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I1123 19:17:07.347960 14064 solver.cpp:218] Iteration 10900 (8.29231 iter/s, 12.0594s/100 iters), loss = 0.12355
I1123 19:17:07.347960 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:17:07.347960 14064 solver.cpp:237]     Train net output #1: loss = 0.12355 (* 1 = 0.12355 loss)
I1123 19:17:07.347960 14064 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I1123 19:17:18.804864  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:17:19.281865 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_11000.caffemodel
I1123 19:17:19.319959 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_11000.solverstate
I1123 19:17:19.339458 14064 solver.cpp:330] Iteration 11000, Testing net (#0)
I1123 19:17:19.339458 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:17:23.377588 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:17:23.542145 14064 solver.cpp:397]     Test net output #0: accuracy = 0.889
I1123 19:17:23.542145 14064 solver.cpp:397]     Test net output #1: loss = 0.341965 (* 1 = 0.341965 loss)
I1123 19:17:23.659809 14064 solver.cpp:218] Iteration 11000 (6.13066 iter/s, 16.3115s/100 iters), loss = 0.101608
I1123 19:17:23.659809 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:17:23.659809 14064 solver.cpp:237]     Train net output #1: loss = 0.101608 (* 1 = 0.101608 loss)
I1123 19:17:23.659809 14064 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I1123 19:17:35.703155 14064 solver.cpp:218] Iteration 11100 (8.30418 iter/s, 12.0421s/100 iters), loss = 0.186389
I1123 19:17:35.703155 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:17:35.703155 14064 solver.cpp:237]     Train net output #1: loss = 0.186389 (* 1 = 0.186389 loss)
I1123 19:17:35.703155 14064 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I1123 19:17:47.760321 14064 solver.cpp:218] Iteration 11200 (8.29402 iter/s, 12.0569s/100 iters), loss = 0.13029
I1123 19:17:47.760321 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:17:47.760821 14064 solver.cpp:237]     Train net output #1: loss = 0.13029 (* 1 = 0.13029 loss)
I1123 19:17:47.760821 14064 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I1123 19:17:59.821508 14064 solver.cpp:218] Iteration 11300 (8.29177 iter/s, 12.0602s/100 iters), loss = 0.111202
I1123 19:17:59.821508 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:17:59.821508 14064 solver.cpp:237]     Train net output #1: loss = 0.111202 (* 1 = 0.111202 loss)
I1123 19:17:59.821508 14064 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I1123 19:18:11.862807 14064 solver.cpp:218] Iteration 11400 (8.30508 iter/s, 12.0408s/100 iters), loss = 0.116318
I1123 19:18:11.862807 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:18:11.862807 14064 solver.cpp:237]     Train net output #1: loss = 0.116318 (* 1 = 0.116318 loss)
I1123 19:18:11.862807 14064 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I1123 19:18:23.313022  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:18:23.789597 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_11500.caffemodel
I1123 19:18:23.826597 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_11500.solverstate
I1123 19:18:23.844601 14064 solver.cpp:330] Iteration 11500, Testing net (#0)
I1123 19:18:23.844601 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:18:27.884124 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:18:28.049156 14064 solver.cpp:397]     Test net output #0: accuracy = 0.888
I1123 19:18:28.049156 14064 solver.cpp:397]     Test net output #1: loss = 0.343016 (* 1 = 0.343016 loss)
I1123 19:18:28.166781 14064 solver.cpp:218] Iteration 11500 (6.13362 iter/s, 16.3036s/100 iters), loss = 0.17729
I1123 19:18:28.166781 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 19:18:28.166781 14064 solver.cpp:237]     Train net output #1: loss = 0.17729 (* 1 = 0.17729 loss)
I1123 19:18:28.166781 14064 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I1123 19:18:40.226691 14064 solver.cpp:218] Iteration 11600 (8.29256 iter/s, 12.059s/100 iters), loss = 0.172776
I1123 19:18:40.227179 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:18:40.227179 14064 solver.cpp:237]     Train net output #1: loss = 0.172776 (* 1 = 0.172776 loss)
I1123 19:18:40.227179 14064 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I1123 19:18:52.276170 14064 solver.cpp:218] Iteration 11700 (8.29967 iter/s, 12.0487s/100 iters), loss = 0.140415
I1123 19:18:52.276170 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:18:52.276170 14064 solver.cpp:237]     Train net output #1: loss = 0.140415 (* 1 = 0.140415 loss)
I1123 19:18:52.276170 14064 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I1123 19:19:04.323490 14064 solver.cpp:218] Iteration 11800 (8.30103 iter/s, 12.0467s/100 iters), loss = 0.135119
I1123 19:19:04.323490 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:19:04.323490 14064 solver.cpp:237]     Train net output #1: loss = 0.135119 (* 1 = 0.135119 loss)
I1123 19:19:04.323490 14064 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I1123 19:19:16.370502 14064 solver.cpp:218] Iteration 11900 (8.30131 iter/s, 12.0463s/100 iters), loss = 0.0997063
I1123 19:19:16.370502 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:19:16.370502 14064 solver.cpp:237]     Train net output #1: loss = 0.0997063 (* 1 = 0.0997063 loss)
I1123 19:19:16.370502 14064 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I1123 19:19:27.817222  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:19:28.296783 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_12000.caffemodel
I1123 19:19:28.334767 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_12000.solverstate
I1123 19:19:28.352782 14064 solver.cpp:330] Iteration 12000, Testing net (#0)
I1123 19:19:28.353267 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:19:32.391628 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:19:32.557538 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8891
I1123 19:19:32.557538 14064 solver.cpp:397]     Test net output #1: loss = 0.340889 (* 1 = 0.340889 loss)
I1123 19:19:32.675472 14064 solver.cpp:218] Iteration 12000 (6.13309 iter/s, 16.305s/100 iters), loss = 0.120007
I1123 19:19:32.675472 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:19:32.675472 14064 solver.cpp:237]     Train net output #1: loss = 0.120007 (* 1 = 0.120007 loss)
I1123 19:19:32.675472 14064 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I1123 19:19:44.732170 14064 solver.cpp:218] Iteration 12100 (8.29493 iter/s, 12.0556s/100 iters), loss = 0.210917
I1123 19:19:44.732170 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1123 19:19:44.732658 14064 solver.cpp:237]     Train net output #1: loss = 0.210917 (* 1 = 0.210917 loss)
I1123 19:19:44.732658 14064 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I1123 19:19:56.779104 14064 solver.cpp:218] Iteration 12200 (8.3013 iter/s, 12.0463s/100 iters), loss = 0.129295
I1123 19:19:56.779104 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:19:56.779104 14064 solver.cpp:237]     Train net output #1: loss = 0.129295 (* 1 = 0.129295 loss)
I1123 19:19:56.779104 14064 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I1123 19:20:08.865707 14064 solver.cpp:218] Iteration 12300 (8.27425 iter/s, 12.0857s/100 iters), loss = 0.0818885
I1123 19:20:08.865707 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:20:08.865707 14064 solver.cpp:237]     Train net output #1: loss = 0.0818885 (* 1 = 0.0818885 loss)
I1123 19:20:08.865707 14064 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I1123 19:20:20.919669 14064 solver.cpp:218] Iteration 12400 (8.29655 iter/s, 12.0532s/100 iters), loss = 0.0884246
I1123 19:20:20.919669 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:20:20.919669 14064 solver.cpp:237]     Train net output #1: loss = 0.0884247 (* 1 = 0.0884247 loss)
I1123 19:20:20.919669 14064 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I1123 19:20:32.401183  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:20:32.882736 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_12500.caffemodel
I1123 19:20:32.920734 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_12500.solverstate
I1123 19:20:32.939254 14064 solver.cpp:330] Iteration 12500, Testing net (#0)
I1123 19:20:32.939254 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:20:36.981695 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:20:37.147722 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8892
I1123 19:20:37.147722 14064 solver.cpp:397]     Test net output #1: loss = 0.341733 (* 1 = 0.341733 loss)
I1123 19:20:37.266258 14064 solver.cpp:218] Iteration 12500 (6.11761 iter/s, 16.3463s/100 iters), loss = 0.102553
I1123 19:20:37.266258 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:20:37.266258 14064 solver.cpp:237]     Train net output #1: loss = 0.102553 (* 1 = 0.102553 loss)
I1123 19:20:37.266258 14064 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I1123 19:20:49.361862 14064 solver.cpp:218] Iteration 12600 (8.26815 iter/s, 12.0946s/100 iters), loss = 0.172464
I1123 19:20:49.361862 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:20:49.361862 14064 solver.cpp:237]     Train net output #1: loss = 0.172464 (* 1 = 0.172464 loss)
I1123 19:20:49.361862 14064 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I1123 19:21:01.487095 14064 solver.cpp:218] Iteration 12700 (8.24771 iter/s, 12.1246s/100 iters), loss = 0.0924069
I1123 19:21:01.487095 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:21:01.487095 14064 solver.cpp:237]     Train net output #1: loss = 0.092407 (* 1 = 0.092407 loss)
I1123 19:21:01.487095 14064 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I1123 19:21:13.644978 14064 solver.cpp:218] Iteration 12800 (8.22548 iter/s, 12.1573s/100 iters), loss = 0.105243
I1123 19:21:13.644978 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:21:13.644978 14064 solver.cpp:237]     Train net output #1: loss = 0.105243 (* 1 = 0.105243 loss)
I1123 19:21:13.644978 14064 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I1123 19:21:25.726265 14064 solver.cpp:218] Iteration 12900 (8.27748 iter/s, 12.081s/100 iters), loss = 0.0870529
I1123 19:21:25.726750 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:21:25.726750 14064 solver.cpp:237]     Train net output #1: loss = 0.0870531 (* 1 = 0.0870531 loss)
I1123 19:21:25.726750 14064 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I1123 19:21:37.173527  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:21:37.652318 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_13000.caffemodel
I1123 19:21:37.690874 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_13000.solverstate
I1123 19:21:37.709874 14064 solver.cpp:330] Iteration 13000, Testing net (#0)
I1123 19:21:37.710374 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:21:41.752115 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:21:41.921720 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8901
I1123 19:21:41.921720 14064 solver.cpp:397]     Test net output #1: loss = 0.343654 (* 1 = 0.343654 loss)
I1123 19:21:42.040225 14064 solver.cpp:218] Iteration 13000 (6.12979 iter/s, 16.3138s/100 iters), loss = 0.121894
I1123 19:21:42.041225 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:21:42.041225 14064 solver.cpp:237]     Train net output #1: loss = 0.121894 (* 1 = 0.121894 loss)
I1123 19:21:42.041225 14064 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I1123 19:21:54.170989 14064 solver.cpp:218] Iteration 13100 (8.24456 iter/s, 12.1292s/100 iters), loss = 0.173092
I1123 19:21:54.170989 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:21:54.170989 14064 solver.cpp:237]     Train net output #1: loss = 0.173092 (* 1 = 0.173092 loss)
I1123 19:21:54.170989 14064 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I1123 19:22:06.292805 14064 solver.cpp:218] Iteration 13200 (8.24989 iter/s, 12.1214s/100 iters), loss = 0.0974991
I1123 19:22:06.293303 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:22:06.293303 14064 solver.cpp:237]     Train net output #1: loss = 0.0974992 (* 1 = 0.0974992 loss)
I1123 19:22:06.293303 14064 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I1123 19:22:18.438239 14064 solver.cpp:218] Iteration 13300 (8.23424 iter/s, 12.1444s/100 iters), loss = 0.0720221
I1123 19:22:18.438239 14064 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1123 19:22:18.438239 14064 solver.cpp:237]     Train net output #1: loss = 0.0720222 (* 1 = 0.0720222 loss)
I1123 19:22:18.438239 14064 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I1123 19:22:30.491727 14064 solver.cpp:218] Iteration 13400 (8.29679 iter/s, 12.0529s/100 iters), loss = 0.0840918
I1123 19:22:30.491727 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:22:30.491727 14064 solver.cpp:237]     Train net output #1: loss = 0.0840919 (* 1 = 0.0840919 loss)
I1123 19:22:30.491727 14064 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I1123 19:22:41.959798  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:22:42.445648 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_13500.caffemodel
I1123 19:22:42.488148 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_13500.solverstate
I1123 19:22:42.507648 14064 solver.cpp:330] Iteration 13500, Testing net (#0)
I1123 19:22:42.507648 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:22:46.562837 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:22:46.728860 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8871
I1123 19:22:46.728860 14064 solver.cpp:397]     Test net output #1: loss = 0.345058 (* 1 = 0.345058 loss)
I1123 19:22:46.846923 14064 solver.cpp:218] Iteration 13500 (6.11455 iter/s, 16.3544s/100 iters), loss = 0.0863478
I1123 19:22:46.846923 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:22:46.846923 14064 solver.cpp:237]     Train net output #1: loss = 0.0863479 (* 1 = 0.0863479 loss)
I1123 19:22:46.846923 14064 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I1123 19:22:58.895042 14064 solver.cpp:218] Iteration 13600 (8.30049 iter/s, 12.0475s/100 iters), loss = 0.133176
I1123 19:22:58.895042 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:22:58.895042 14064 solver.cpp:237]     Train net output #1: loss = 0.133177 (* 1 = 0.133177 loss)
I1123 19:22:58.895042 14064 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I1123 19:23:10.967725 14064 solver.cpp:218] Iteration 13700 (8.28339 iter/s, 12.0724s/100 iters), loss = 0.111395
I1123 19:23:10.967725 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:23:10.967725 14064 solver.cpp:237]     Train net output #1: loss = 0.111395 (* 1 = 0.111395 loss)
I1123 19:23:10.967725 14064 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I1123 19:23:23.087266 14064 solver.cpp:218] Iteration 13800 (8.25164 iter/s, 12.1188s/100 iters), loss = 0.119507
I1123 19:23:23.087266 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:23:23.087266 14064 solver.cpp:237]     Train net output #1: loss = 0.119507 (* 1 = 0.119507 loss)
I1123 19:23:23.087266 14064 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I1123 19:23:35.178203 14064 solver.cpp:218] Iteration 13900 (8.27105 iter/s, 12.0904s/100 iters), loss = 0.0773827
I1123 19:23:35.178203 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:23:35.178203 14064 solver.cpp:237]     Train net output #1: loss = 0.0773828 (* 1 = 0.0773828 loss)
I1123 19:23:35.178203 14064 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I1123 19:23:46.683598  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:23:47.164144 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_14000.caffemodel
I1123 19:23:47.205651 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_14000.solverstate
I1123 19:23:47.225142 14064 solver.cpp:330] Iteration 14000, Testing net (#0)
I1123 19:23:47.225641 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:23:51.274966 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:23:51.440017 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8904
I1123 19:23:51.440017 14064 solver.cpp:397]     Test net output #1: loss = 0.343114 (* 1 = 0.343114 loss)
I1123 19:23:51.558063 14064 solver.cpp:218] Iteration 14000 (6.10508 iter/s, 16.3798s/100 iters), loss = 0.116455
I1123 19:23:51.558063 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:23:51.559051 14064 solver.cpp:237]     Train net output #1: loss = 0.116455 (* 1 = 0.116455 loss)
I1123 19:23:51.559051 14064 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I1123 19:24:03.652386 14064 solver.cpp:218] Iteration 14100 (8.26931 iter/s, 12.0929s/100 iters), loss = 0.158479
I1123 19:24:03.652386 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:24:03.652386 14064 solver.cpp:237]     Train net output #1: loss = 0.158479 (* 1 = 0.158479 loss)
I1123 19:24:03.652386 14064 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I1123 19:24:15.723193 14064 solver.cpp:218] Iteration 14200 (8.28482 iter/s, 12.0703s/100 iters), loss = 0.0977725
I1123 19:24:15.723193 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:24:15.723193 14064 solver.cpp:237]     Train net output #1: loss = 0.0977726 (* 1 = 0.0977726 loss)
I1123 19:24:15.723193 14064 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I1123 19:24:27.772462 14064 solver.cpp:218] Iteration 14300 (8.2996 iter/s, 12.0488s/100 iters), loss = 0.10336
I1123 19:24:27.772462 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:24:27.772462 14064 solver.cpp:237]     Train net output #1: loss = 0.10336 (* 1 = 0.10336 loss)
I1123 19:24:27.772462 14064 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I1123 19:24:39.822067 14064 solver.cpp:218] Iteration 14400 (8.29938 iter/s, 12.0491s/100 iters), loss = 0.0719023
I1123 19:24:39.822067 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:24:39.822067 14064 solver.cpp:237]     Train net output #1: loss = 0.0719024 (* 1 = 0.0719024 loss)
I1123 19:24:39.822067 14064 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I1123 19:24:51.317250  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:24:51.796474 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_14500.caffemodel
I1123 19:24:51.836465 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_14500.solverstate
I1123 19:24:51.855964 14064 solver.cpp:330] Iteration 14500, Testing net (#0)
I1123 19:24:51.855964 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:24:55.901202 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:24:56.067209 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1123 19:24:56.067710 14064 solver.cpp:397]     Test net output #1: loss = 0.344687 (* 1 = 0.344687 loss)
I1123 19:24:56.185245 14064 solver.cpp:218] Iteration 14500 (6.11148 iter/s, 16.3627s/100 iters), loss = 0.11243
I1123 19:24:56.185245 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:24:56.185245 14064 solver.cpp:237]     Train net output #1: loss = 0.11243 (* 1 = 0.11243 loss)
I1123 19:24:56.185245 14064 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I1123 19:25:08.242656 14064 solver.cpp:218] Iteration 14600 (8.29463 iter/s, 12.056s/100 iters), loss = 0.140972
I1123 19:25:08.242656 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:25:08.242656 14064 solver.cpp:237]     Train net output #1: loss = 0.140972 (* 1 = 0.140972 loss)
I1123 19:25:08.242656 14064 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I1123 19:25:20.281044 14064 solver.cpp:218] Iteration 14700 (8.30695 iter/s, 12.0381s/100 iters), loss = 0.0906074
I1123 19:25:20.281530 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:25:20.281530 14064 solver.cpp:237]     Train net output #1: loss = 0.0906075 (* 1 = 0.0906075 loss)
I1123 19:25:20.281530 14064 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I1123 19:25:32.343825 14064 solver.cpp:218] Iteration 14800 (8.29019 iter/s, 12.0624s/100 iters), loss = 0.0889362
I1123 19:25:32.343825 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:25:32.343825 14064 solver.cpp:237]     Train net output #1: loss = 0.0889363 (* 1 = 0.0889363 loss)
I1123 19:25:32.343825 14064 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I1123 19:25:44.398530 14064 solver.cpp:218] Iteration 14900 (8.29637 iter/s, 12.0535s/100 iters), loss = 0.0958426
I1123 19:25:44.398530 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:25:44.398530 14064 solver.cpp:237]     Train net output #1: loss = 0.0958427 (* 1 = 0.0958427 loss)
I1123 19:25:44.398530 14064 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I1123 19:25:55.849189  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:25:56.329216 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_15000.caffemodel
I1123 19:25:56.368690 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_15000.solverstate
I1123 19:25:56.387209 14064 solver.cpp:330] Iteration 15000, Testing net (#0)
I1123 19:25:56.387689 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:26:00.424988 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:26:00.590997 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8908
I1123 19:26:00.590997 14064 solver.cpp:397]     Test net output #1: loss = 0.344794 (* 1 = 0.344794 loss)
I1123 19:26:00.710034 14064 solver.cpp:218] Iteration 15000 (6.13091 iter/s, 16.3108s/100 iters), loss = 0.0918475
I1123 19:26:00.710034 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:26:00.710034 14064 solver.cpp:237]     Train net output #1: loss = 0.0918476 (* 1 = 0.0918476 loss)
I1123 19:26:00.710034 14064 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I1123 19:26:12.765027 14064 solver.cpp:218] Iteration 15100 (8.29554 iter/s, 12.0547s/100 iters), loss = 0.178936
I1123 19:26:12.765027 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:26:12.765527 14064 solver.cpp:237]     Train net output #1: loss = 0.178936 (* 1 = 0.178936 loss)
I1123 19:26:12.765527 14064 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I1123 19:26:24.815858 14064 solver.cpp:218] Iteration 15200 (8.29863 iter/s, 12.0502s/100 iters), loss = 0.0900798
I1123 19:26:24.815858 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:26:24.815858 14064 solver.cpp:237]     Train net output #1: loss = 0.0900799 (* 1 = 0.0900799 loss)
I1123 19:26:24.815858 14064 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I1123 19:26:36.865614 14064 solver.cpp:218] Iteration 15300 (8.29949 iter/s, 12.0489s/100 iters), loss = 0.0752262
I1123 19:26:36.865614 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:26:36.865614 14064 solver.cpp:237]     Train net output #1: loss = 0.0752263 (* 1 = 0.0752263 loss)
I1123 19:26:36.865614 14064 sgd_solver.cpp:46] MultiStep Status: Iteration 15300, step = 3
I1123 19:26:36.865614 14064 sgd_solver.cpp:105] Iteration 15300, lr = 0.0001
I1123 19:26:48.909030 14064 solver.cpp:218] Iteration 15400 (8.30374 iter/s, 12.0428s/100 iters), loss = 0.0815858
I1123 19:26:48.909030 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:26:48.909030 14064 solver.cpp:237]     Train net output #1: loss = 0.0815859 (* 1 = 0.0815859 loss)
I1123 19:26:48.909030 14064 sgd_solver.cpp:105] Iteration 15400, lr = 0.0001
I1123 19:27:00.361868  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:27:00.838186 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_15500.caffemodel
I1123 19:27:00.876687 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_15500.solverstate
I1123 19:27:00.895701 14064 solver.cpp:330] Iteration 15500, Testing net (#0)
I1123 19:27:00.895701 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:27:04.935292 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:27:05.100327 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8917
I1123 19:27:05.100327 14064 solver.cpp:397]     Test net output #1: loss = 0.345523 (* 1 = 0.345523 loss)
I1123 19:27:05.218871 14064 solver.cpp:218] Iteration 15500 (6.13153 iter/s, 16.3091s/100 iters), loss = 0.103839
I1123 19:27:05.218871 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:27:05.218871 14064 solver.cpp:237]     Train net output #1: loss = 0.10384 (* 1 = 0.10384 loss)
I1123 19:27:05.218871 14064 sgd_solver.cpp:105] Iteration 15500, lr = 0.0001
I1123 19:27:17.269646 14064 solver.cpp:218] Iteration 15600 (8.29848 iter/s, 12.0504s/100 iters), loss = 0.148629
I1123 19:27:17.269646 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:27:17.269646 14064 solver.cpp:237]     Train net output #1: loss = 0.148629 (* 1 = 0.148629 loss)
I1123 19:27:17.269646 14064 sgd_solver.cpp:105] Iteration 15600, lr = 0.0001
I1123 19:27:29.399940 14064 solver.cpp:218] Iteration 15700 (8.24399 iter/s, 12.1301s/100 iters), loss = 0.115898
I1123 19:27:29.399940 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:27:29.399940 14064 solver.cpp:237]     Train net output #1: loss = 0.115899 (* 1 = 0.115899 loss)
I1123 19:27:29.399940 14064 sgd_solver.cpp:105] Iteration 15700, lr = 0.0001
I1123 19:27:41.482578 14064 solver.cpp:218] Iteration 15800 (8.27726 iter/s, 12.0813s/100 iters), loss = 0.0585059
I1123 19:27:41.482578 14064 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1123 19:27:41.482578 14064 solver.cpp:237]     Train net output #1: loss = 0.058506 (* 1 = 0.058506 loss)
I1123 19:27:41.482578 14064 sgd_solver.cpp:105] Iteration 15800, lr = 0.0001
I1123 19:27:53.541906 14064 solver.cpp:218] Iteration 15900 (8.29261 iter/s, 12.0589s/100 iters), loss = 0.0877198
I1123 19:27:53.541906 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:27:53.541906 14064 solver.cpp:237]     Train net output #1: loss = 0.0877199 (* 1 = 0.0877199 loss)
I1123 19:27:53.541906 14064 sgd_solver.cpp:105] Iteration 15900, lr = 0.0001
I1123 19:28:04.989043  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:28:05.466543 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_16000.caffemodel
I1123 19:28:05.507045 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_16000.solverstate
I1123 19:28:05.526043 14064 solver.cpp:330] Iteration 16000, Testing net (#0)
I1123 19:28:05.526043 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:28:09.569806 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:28:09.735877 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I1123 19:28:09.735877 14064 solver.cpp:397]     Test net output #1: loss = 0.344943 (* 1 = 0.344943 loss)
I1123 19:28:09.853925 14064 solver.cpp:218] Iteration 16000 (6.1307 iter/s, 16.3113s/100 iters), loss = 0.113765
I1123 19:28:09.853925 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:28:09.853925 14064 solver.cpp:237]     Train net output #1: loss = 0.113765 (* 1 = 0.113765 loss)
I1123 19:28:09.853925 14064 sgd_solver.cpp:105] Iteration 16000, lr = 0.0001
I1123 19:28:22.012090 14064 solver.cpp:218] Iteration 16100 (8.22536 iter/s, 12.1575s/100 iters), loss = 0.118163
I1123 19:28:22.012090 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:28:22.012090 14064 solver.cpp:237]     Train net output #1: loss = 0.118163 (* 1 = 0.118163 loss)
I1123 19:28:22.012090 14064 sgd_solver.cpp:105] Iteration 16100, lr = 0.0001
I1123 19:28:34.074800 14064 solver.cpp:218] Iteration 16200 (8.29013 iter/s, 12.0625s/100 iters), loss = 0.0562452
I1123 19:28:34.074800 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:28:34.074800 14064 solver.cpp:237]     Train net output #1: loss = 0.0562453 (* 1 = 0.0562453 loss)
I1123 19:28:34.074800 14064 sgd_solver.cpp:105] Iteration 16200, lr = 0.0001
I1123 19:28:46.151284 14064 solver.cpp:218] Iteration 16300 (8.28129 iter/s, 12.0754s/100 iters), loss = 0.0878913
I1123 19:28:46.151284 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:28:46.151284 14064 solver.cpp:237]     Train net output #1: loss = 0.0878914 (* 1 = 0.0878914 loss)
I1123 19:28:46.151284 14064 sgd_solver.cpp:105] Iteration 16300, lr = 0.0001
I1123 19:28:58.200970 14064 solver.cpp:218] Iteration 16400 (8.2994 iter/s, 12.0491s/100 iters), loss = 0.0884606
I1123 19:28:58.201470 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:28:58.201470 14064 solver.cpp:237]     Train net output #1: loss = 0.0884607 (* 1 = 0.0884607 loss)
I1123 19:28:58.201470 14064 sgd_solver.cpp:105] Iteration 16400, lr = 0.0001
I1123 19:29:09.671454  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:29:10.149518 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_16500.caffemodel
I1123 19:29:10.195024 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_16500.solverstate
I1123 19:29:10.214524 14064 solver.cpp:330] Iteration 16500, Testing net (#0)
I1123 19:29:10.214524 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:29:14.253433 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:29:14.418503 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8918
I1123 19:29:14.418503 14064 solver.cpp:397]     Test net output #1: loss = 0.344821 (* 1 = 0.344821 loss)
I1123 19:29:14.537546 14064 solver.cpp:218] Iteration 16500 (6.12154 iter/s, 16.3358s/100 iters), loss = 0.0758899
I1123 19:29:14.537546 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:29:14.537546 14064 solver.cpp:237]     Train net output #1: loss = 0.07589 (* 1 = 0.07589 loss)
I1123 19:29:14.537546 14064 sgd_solver.cpp:105] Iteration 16500, lr = 0.0001
I1123 19:29:26.670776 14064 solver.cpp:218] Iteration 16600 (8.24217 iter/s, 12.1327s/100 iters), loss = 0.116498
I1123 19:29:26.671267 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:29:26.671267 14064 solver.cpp:237]     Train net output #1: loss = 0.116498 (* 1 = 0.116498 loss)
I1123 19:29:26.671267 14064 sgd_solver.cpp:105] Iteration 16600, lr = 0.0001
I1123 19:29:38.782310 14064 solver.cpp:218] Iteration 16700 (8.25668 iter/s, 12.1114s/100 iters), loss = 0.0908047
I1123 19:29:38.783298 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:29:38.783298 14064 solver.cpp:237]     Train net output #1: loss = 0.0908048 (* 1 = 0.0908048 loss)
I1123 19:29:38.783298 14064 sgd_solver.cpp:105] Iteration 16700, lr = 0.0001
I1123 19:29:50.835986 14064 solver.cpp:218] Iteration 16800 (8.29708 iter/s, 12.0524s/100 iters), loss = 0.0885794
I1123 19:29:50.835986 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:29:50.835986 14064 solver.cpp:237]     Train net output #1: loss = 0.0885794 (* 1 = 0.0885794 loss)
I1123 19:29:50.835986 14064 sgd_solver.cpp:105] Iteration 16800, lr = 0.0001
I1123 19:30:02.924608 14064 solver.cpp:218] Iteration 16900 (8.27285 iter/s, 12.0877s/100 iters), loss = 0.062153
I1123 19:30:02.924608 14064 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1123 19:30:02.924608 14064 solver.cpp:237]     Train net output #1: loss = 0.062153 (* 1 = 0.062153 loss)
I1123 19:30:02.924608 14064 sgd_solver.cpp:105] Iteration 16900, lr = 0.0001
I1123 19:30:14.423691  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:30:14.904273 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_17000.caffemodel
I1123 19:30:14.942775 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_17000.solverstate
I1123 19:30:14.962275 14064 solver.cpp:330] Iteration 17000, Testing net (#0)
I1123 19:30:14.962275 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:30:19.013458 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:30:19.179522 14064 solver.cpp:397]     Test net output #0: accuracy = 0.892
I1123 19:30:19.179522 14064 solver.cpp:397]     Test net output #1: loss = 0.344721 (* 1 = 0.344721 loss)
I1123 19:30:19.298553 14064 solver.cpp:218] Iteration 17000 (6.10724 iter/s, 16.374s/100 iters), loss = 0.0776805
I1123 19:30:19.299541 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:30:19.299541 14064 solver.cpp:237]     Train net output #1: loss = 0.0776805 (* 1 = 0.0776805 loss)
I1123 19:30:19.299541 14064 sgd_solver.cpp:105] Iteration 17000, lr = 0.0001
I1123 19:30:31.415658 14064 solver.cpp:218] Iteration 17100 (8.2539 iter/s, 12.1155s/100 iters), loss = 0.115437
I1123 19:30:31.415658 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:30:31.415658 14064 solver.cpp:237]     Train net output #1: loss = 0.115437 (* 1 = 0.115437 loss)
I1123 19:30:31.415658 14064 sgd_solver.cpp:105] Iteration 17100, lr = 0.0001
I1123 19:30:43.469806 14064 solver.cpp:218] Iteration 17200 (8.2963 iter/s, 12.0536s/100 iters), loss = 0.10651
I1123 19:30:43.469806 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:30:43.469806 14064 solver.cpp:237]     Train net output #1: loss = 0.10651 (* 1 = 0.10651 loss)
I1123 19:30:43.469806 14064 sgd_solver.cpp:105] Iteration 17200, lr = 0.0001
I1123 19:30:55.560369 14064 solver.cpp:218] Iteration 17300 (8.27128 iter/s, 12.09s/100 iters), loss = 0.0735961
I1123 19:30:55.560369 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:30:55.560369 14064 solver.cpp:237]     Train net output #1: loss = 0.0735962 (* 1 = 0.0735962 loss)
I1123 19:30:55.560369 14064 sgd_solver.cpp:105] Iteration 17300, lr = 0.0001
I1123 19:31:07.625306 14064 solver.cpp:218] Iteration 17400 (8.28891 iter/s, 12.0643s/100 iters), loss = 0.0781254
I1123 19:31:07.625306 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:31:07.625306 14064 solver.cpp:237]     Train net output #1: loss = 0.0781254 (* 1 = 0.0781254 loss)
I1123 19:31:07.625306 14064 sgd_solver.cpp:105] Iteration 17400, lr = 0.0001
I1123 19:31:19.111585  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:31:19.589129 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_17500.caffemodel
I1123 19:31:19.628630 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_17500.solverstate
I1123 19:31:19.647635 14064 solver.cpp:330] Iteration 17500, Testing net (#0)
I1123 19:31:19.647635 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:31:23.686636 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:31:23.853149 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8915
I1123 19:31:23.853149 14064 solver.cpp:397]     Test net output #1: loss = 0.344714 (* 1 = 0.344714 loss)
I1123 19:31:23.971199 14064 solver.cpp:218] Iteration 17500 (6.11772 iter/s, 16.346s/100 iters), loss = 0.0878517
I1123 19:31:23.971199 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:31:23.971199 14064 solver.cpp:237]     Train net output #1: loss = 0.0878518 (* 1 = 0.0878518 loss)
I1123 19:31:23.971199 14064 sgd_solver.cpp:105] Iteration 17500, lr = 0.0001
I1123 19:31:36.070597 14064 solver.cpp:218] Iteration 17600 (8.26564 iter/s, 12.0983s/100 iters), loss = 0.0993164
I1123 19:31:36.070597 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:31:36.070597 14064 solver.cpp:237]     Train net output #1: loss = 0.0993165 (* 1 = 0.0993165 loss)
I1123 19:31:36.070597 14064 sgd_solver.cpp:105] Iteration 17600, lr = 0.0001
I1123 19:31:48.117065 14064 solver.cpp:218] Iteration 17700 (8.30179 iter/s, 12.0456s/100 iters), loss = 0.0930297
I1123 19:31:48.117065 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:31:48.117065 14064 solver.cpp:237]     Train net output #1: loss = 0.0930297 (* 1 = 0.0930297 loss)
I1123 19:31:48.117065 14064 sgd_solver.cpp:105] Iteration 17700, lr = 0.0001
I1123 19:32:00.159633 14064 solver.cpp:218] Iteration 17800 (8.30431 iter/s, 12.0419s/100 iters), loss = 0.0661148
I1123 19:32:00.159633 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:32:00.159633 14064 solver.cpp:237]     Train net output #1: loss = 0.0661148 (* 1 = 0.0661148 loss)
I1123 19:32:00.159633 14064 sgd_solver.cpp:105] Iteration 17800, lr = 0.0001
I1123 19:32:12.230557 14064 solver.cpp:218] Iteration 17900 (8.2846 iter/s, 12.0706s/100 iters), loss = 0.0718465
I1123 19:32:12.231043 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:32:12.231043 14064 solver.cpp:237]     Train net output #1: loss = 0.0718466 (* 1 = 0.0718466 loss)
I1123 19:32:12.231043 14064 sgd_solver.cpp:105] Iteration 17900, lr = 0.0001
I1123 19:32:23.679066  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:32:24.157569 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_18000.caffemodel
I1123 19:32:24.201582 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_18000.solverstate
I1123 19:32:24.221066 14064 solver.cpp:330] Iteration 18000, Testing net (#0)
I1123 19:32:24.221066 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:32:28.252919 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:32:28.417979 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8918
I1123 19:32:28.417979 14064 solver.cpp:397]     Test net output #1: loss = 0.345181 (* 1 = 0.345181 loss)
I1123 19:32:28.537011 14064 solver.cpp:218] Iteration 18000 (6.13289 iter/s, 16.3055s/100 iters), loss = 0.0753317
I1123 19:32:28.537011 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:32:28.537011 14064 solver.cpp:237]     Train net output #1: loss = 0.0753317 (* 1 = 0.0753317 loss)
I1123 19:32:28.537011 14064 sgd_solver.cpp:105] Iteration 18000, lr = 0.0001
I1123 19:32:40.601105 14064 solver.cpp:218] Iteration 18100 (8.28946 iter/s, 12.0635s/100 iters), loss = 0.166581
I1123 19:32:40.601105 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1123 19:32:40.601105 14064 solver.cpp:237]     Train net output #1: loss = 0.166581 (* 1 = 0.166581 loss)
I1123 19:32:40.601105 14064 sgd_solver.cpp:105] Iteration 18100, lr = 0.0001
I1123 19:32:52.645777 14064 solver.cpp:218] Iteration 18200 (8.30304 iter/s, 12.0438s/100 iters), loss = 0.0999898
I1123 19:32:52.645777 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:32:52.645777 14064 solver.cpp:237]     Train net output #1: loss = 0.0999899 (* 1 = 0.0999899 loss)
I1123 19:32:52.645777 14064 sgd_solver.cpp:105] Iteration 18200, lr = 0.0001
I1123 19:33:04.694176 14064 solver.cpp:218] Iteration 18300 (8.30025 iter/s, 12.0478s/100 iters), loss = 0.0744307
I1123 19:33:04.694176 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:33:04.694176 14064 solver.cpp:237]     Train net output #1: loss = 0.0744308 (* 1 = 0.0744308 loss)
I1123 19:33:04.694176 14064 sgd_solver.cpp:105] Iteration 18300, lr = 0.0001
I1123 19:33:16.755069 14064 solver.cpp:218] Iteration 18400 (8.2917 iter/s, 12.0603s/100 iters), loss = 0.111093
I1123 19:33:16.755069 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:33:16.755069 14064 solver.cpp:237]     Train net output #1: loss = 0.111093 (* 1 = 0.111093 loss)
I1123 19:33:16.755069 14064 sgd_solver.cpp:105] Iteration 18400, lr = 0.0001
I1123 19:33:28.253504  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:33:28.732043 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_18500.caffemodel
I1123 19:33:28.772543 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_18500.solverstate
I1123 19:33:28.791563 14064 solver.cpp:330] Iteration 18500, Testing net (#0)
I1123 19:33:28.791563 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:33:32.827337 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:33:32.992372 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8913
I1123 19:33:32.992372 14064 solver.cpp:397]     Test net output #1: loss = 0.345332 (* 1 = 0.345332 loss)
I1123 19:33:33.110416 14064 solver.cpp:218] Iteration 18500 (6.11429 iter/s, 16.3551s/100 iters), loss = 0.084233
I1123 19:33:33.110416 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:33:33.110416 14064 solver.cpp:237]     Train net output #1: loss = 0.0842331 (* 1 = 0.0842331 loss)
I1123 19:33:33.110416 14064 sgd_solver.cpp:105] Iteration 18500, lr = 0.0001
I1123 19:33:45.175246 14064 solver.cpp:218] Iteration 18600 (8.2891 iter/s, 12.064s/100 iters), loss = 0.0732115
I1123 19:33:45.175246 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:33:45.175246 14064 solver.cpp:237]     Train net output #1: loss = 0.0732117 (* 1 = 0.0732117 loss)
I1123 19:33:45.175246 14064 sgd_solver.cpp:105] Iteration 18600, lr = 0.0001
I1123 19:33:57.219645 14064 solver.cpp:218] Iteration 18700 (8.30319 iter/s, 12.0436s/100 iters), loss = 0.0893672
I1123 19:33:57.219645 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:33:57.219645 14064 solver.cpp:237]     Train net output #1: loss = 0.0893673 (* 1 = 0.0893673 loss)
I1123 19:33:57.219645 14064 sgd_solver.cpp:105] Iteration 18700, lr = 0.0001
I1123 19:34:09.263893 14064 solver.cpp:218] Iteration 18800 (8.30334 iter/s, 12.0433s/100 iters), loss = 0.0811878
I1123 19:34:09.263893 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:34:09.263893 14064 solver.cpp:237]     Train net output #1: loss = 0.0811879 (* 1 = 0.0811879 loss)
I1123 19:34:09.263893 14064 sgd_solver.cpp:105] Iteration 18800, lr = 0.0001
I1123 19:34:21.308980 14064 solver.cpp:218] Iteration 18900 (8.30225 iter/s, 12.0449s/100 iters), loss = 0.0788169
I1123 19:34:21.309469 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:34:21.309469 14064 solver.cpp:237]     Train net output #1: loss = 0.078817 (* 1 = 0.078817 loss)
I1123 19:34:21.309469 14064 sgd_solver.cpp:105] Iteration 18900, lr = 0.0001
I1123 19:34:32.756662  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:34:33.238345 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_19000.caffemodel
I1123 19:34:33.277844 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_19000.solverstate
I1123 19:34:33.297343 14064 solver.cpp:330] Iteration 19000, Testing net (#0)
I1123 19:34:33.297343 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:34:37.370682 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:34:37.539683 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8916
I1123 19:34:37.539683 14064 solver.cpp:397]     Test net output #1: loss = 0.345159 (* 1 = 0.345159 loss)
I1123 19:34:37.658246 14064 solver.cpp:218] Iteration 19000 (6.11678 iter/s, 16.3485s/100 iters), loss = 0.0868172
I1123 19:34:37.658246 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:34:37.658246 14064 solver.cpp:237]     Train net output #1: loss = 0.0868174 (* 1 = 0.0868174 loss)
I1123 19:34:37.658246 14064 sgd_solver.cpp:105] Iteration 19000, lr = 0.0001
I1123 19:34:49.709792 14064 solver.cpp:218] Iteration 19100 (8.29839 iter/s, 12.0505s/100 iters), loss = 0.16504
I1123 19:34:49.709792 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:34:49.709792 14064 solver.cpp:237]     Train net output #1: loss = 0.16504 (* 1 = 0.16504 loss)
I1123 19:34:49.709792 14064 sgd_solver.cpp:105] Iteration 19100, lr = 0.0001
I1123 19:35:01.755866 14064 solver.cpp:218] Iteration 19200 (8.30172 iter/s, 12.0457s/100 iters), loss = 0.113604
I1123 19:35:01.755866 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:35:01.755866 14064 solver.cpp:237]     Train net output #1: loss = 0.113604 (* 1 = 0.113604 loss)
I1123 19:35:01.755866 14064 sgd_solver.cpp:105] Iteration 19200, lr = 0.0001
I1123 19:35:13.864951 14064 solver.cpp:218] Iteration 19300 (8.25881 iter/s, 12.1083s/100 iters), loss = 0.0557604
I1123 19:35:13.864951 14064 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1123 19:35:13.864951 14064 solver.cpp:237]     Train net output #1: loss = 0.0557606 (* 1 = 0.0557606 loss)
I1123 19:35:13.864951 14064 sgd_solver.cpp:105] Iteration 19300, lr = 0.0001
I1123 19:35:25.972774 14064 solver.cpp:218] Iteration 19400 (8.2595 iter/s, 12.1073s/100 iters), loss = 0.0703097
I1123 19:35:25.972774 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:35:25.972774 14064 solver.cpp:237]     Train net output #1: loss = 0.0703098 (* 1 = 0.0703098 loss)
I1123 19:35:25.972774 14064 sgd_solver.cpp:105] Iteration 19400, lr = 0.0001
I1123 19:35:37.438017  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:35:37.915791 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_19500.caffemodel
I1123 19:35:37.955305 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_19500.solverstate
I1123 19:35:37.974298 14064 solver.cpp:330] Iteration 19500, Testing net (#0)
I1123 19:35:37.974298 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:35:42.021658 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:35:42.187026 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8914
I1123 19:35:42.187026 14064 solver.cpp:397]     Test net output #1: loss = 0.345103 (* 1 = 0.345103 loss)
I1123 19:35:42.305899 14064 solver.cpp:218] Iteration 19500 (6.12252 iter/s, 16.3332s/100 iters), loss = 0.0718729
I1123 19:35:42.306887 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:35:42.306887 14064 solver.cpp:237]     Train net output #1: loss = 0.0718731 (* 1 = 0.0718731 loss)
I1123 19:35:42.306887 14064 sgd_solver.cpp:46] MultiStep Status: Iteration 19500, step = 4
I1123 19:35:42.306887 14064 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I1123 19:35:54.461527 14064 solver.cpp:218] Iteration 19600 (8.22757 iter/s, 12.1543s/100 iters), loss = 0.159343
I1123 19:35:54.461527 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:35:54.461527 14064 solver.cpp:237]     Train net output #1: loss = 0.159343 (* 1 = 0.159343 loss)
I1123 19:35:54.461527 14064 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I1123 19:36:06.544023 14064 solver.cpp:218] Iteration 19700 (8.27693 iter/s, 12.0818s/100 iters), loss = 0.105681
I1123 19:36:06.544023 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:36:06.544023 14064 solver.cpp:237]     Train net output #1: loss = 0.105681 (* 1 = 0.105681 loss)
I1123 19:36:06.544023 14064 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I1123 19:36:18.586009 14064 solver.cpp:218] Iteration 19800 (8.30468 iter/s, 12.0414s/100 iters), loss = 0.0785802
I1123 19:36:18.586009 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:36:18.586009 14064 solver.cpp:237]     Train net output #1: loss = 0.0785804 (* 1 = 0.0785804 loss)
I1123 19:36:18.586009 14064 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I1123 19:36:30.666703 14064 solver.cpp:218] Iteration 19900 (8.27805 iter/s, 12.0801s/100 iters), loss = 0.0503109
I1123 19:36:30.666703 14064 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1123 19:36:30.666703 14064 solver.cpp:237]     Train net output #1: loss = 0.050311 (* 1 = 0.050311 loss)
I1123 19:36:30.666703 14064 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I1123 19:36:42.204587  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:36:42.683634 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_20000.caffemodel
I1123 19:36:42.720726 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_20000.solverstate
I1123 19:36:42.739727 14064 solver.cpp:330] Iteration 20000, Testing net (#0)
I1123 19:36:42.739727 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:36:46.786190 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:36:46.952744 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8916
I1123 19:36:46.952744 14064 solver.cpp:397]     Test net output #1: loss = 0.345206 (* 1 = 0.345206 loss)
I1123 19:36:47.070789 14064 solver.cpp:218] Iteration 20000 (6.09626 iter/s, 16.4035s/100 iters), loss = 0.0947845
I1123 19:36:47.070789 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:36:47.070789 14064 solver.cpp:237]     Train net output #1: loss = 0.0947847 (* 1 = 0.0947847 loss)
I1123 19:36:47.070789 14064 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I1123 19:36:59.163938 14064 solver.cpp:218] Iteration 20100 (8.26963 iter/s, 12.0924s/100 iters), loss = 0.137995
I1123 19:36:59.163938 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:36:59.163938 14064 solver.cpp:237]     Train net output #1: loss = 0.137995 (* 1 = 0.137995 loss)
I1123 19:36:59.163938 14064 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I1123 19:37:11.284088 14064 solver.cpp:218] Iteration 20200 (8.25099 iter/s, 12.1198s/100 iters), loss = 0.0744887
I1123 19:37:11.284579 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:37:11.284579 14064 solver.cpp:237]     Train net output #1: loss = 0.0744889 (* 1 = 0.0744889 loss)
I1123 19:37:11.284579 14064 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I1123 19:37:23.396641 14064 solver.cpp:218] Iteration 20300 (8.25654 iter/s, 12.1116s/100 iters), loss = 0.0900139
I1123 19:37:23.396641 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:37:23.396641 14064 solver.cpp:237]     Train net output #1: loss = 0.090014 (* 1 = 0.090014 loss)
I1123 19:37:23.396641 14064 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I1123 19:37:35.455297 14064 solver.cpp:218] Iteration 20400 (8.29329 iter/s, 12.0579s/100 iters), loss = 0.0961652
I1123 19:37:35.455297 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:37:35.455297 14064 solver.cpp:237]     Train net output #1: loss = 0.0961653 (* 1 = 0.0961653 loss)
I1123 19:37:35.455297 14064 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I1123 19:37:46.925103  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:37:47.400451 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_20500.caffemodel
I1123 19:37:47.439436 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_20500.solverstate
I1123 19:37:47.458448 14064 solver.cpp:330] Iteration 20500, Testing net (#0)
I1123 19:37:47.458448 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:37:51.495401 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:37:51.661473 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8912
I1123 19:37:51.661473 14064 solver.cpp:397]     Test net output #1: loss = 0.345131 (* 1 = 0.345131 loss)
I1123 19:37:51.780499 14064 solver.cpp:218] Iteration 20500 (6.12573 iter/s, 16.3246s/100 iters), loss = 0.115524
I1123 19:37:51.780499 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:37:51.780499 14064 solver.cpp:237]     Train net output #1: loss = 0.115524 (* 1 = 0.115524 loss)
I1123 19:37:51.780499 14064 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I1123 19:38:03.842983 14064 solver.cpp:218] Iteration 20600 (8.29071 iter/s, 12.0617s/100 iters), loss = 0.141883
I1123 19:38:03.842983 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:38:03.842983 14064 solver.cpp:237]     Train net output #1: loss = 0.141883 (* 1 = 0.141883 loss)
I1123 19:38:03.842983 14064 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I1123 19:38:15.904103 14064 solver.cpp:218] Iteration 20700 (8.2913 iter/s, 12.0608s/100 iters), loss = 0.0594232
I1123 19:38:15.904103 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:38:15.904103 14064 solver.cpp:237]     Train net output #1: loss = 0.0594233 (* 1 = 0.0594233 loss)
I1123 19:38:15.904604 14064 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I1123 19:38:27.964875 14064 solver.cpp:218] Iteration 20800 (8.29176 iter/s, 12.0602s/100 iters), loss = 0.108065
I1123 19:38:27.964875 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:38:27.964875 14064 solver.cpp:237]     Train net output #1: loss = 0.108065 (* 1 = 0.108065 loss)
I1123 19:38:27.964875 14064 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I1123 19:38:40.006300 14064 solver.cpp:218] Iteration 20900 (8.30536 iter/s, 12.0404s/100 iters), loss = 0.0824571
I1123 19:38:40.006300 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:38:40.006300 14064 solver.cpp:237]     Train net output #1: loss = 0.0824572 (* 1 = 0.0824572 loss)
I1123 19:38:40.006300 14064 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I1123 19:38:51.475577  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:38:51.955114 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_21000.caffemodel
I1123 19:38:51.994114 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_21000.solverstate
I1123 19:38:52.013113 14064 solver.cpp:330] Iteration 21000, Testing net (#0)
I1123 19:38:52.013113 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:38:56.044518 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:38:56.210054 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8913
I1123 19:38:56.210054 14064 solver.cpp:397]     Test net output #1: loss = 0.345116 (* 1 = 0.345116 loss)
I1123 19:38:56.327090 14064 solver.cpp:218] Iteration 21000 (6.12704 iter/s, 16.3211s/100 iters), loss = 0.107471
I1123 19:38:56.328078 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:38:56.328078 14064 solver.cpp:237]     Train net output #1: loss = 0.107471 (* 1 = 0.107471 loss)
I1123 19:38:56.328078 14064 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I1123 19:39:08.379515 14064 solver.cpp:218] Iteration 21100 (8.29802 iter/s, 12.0511s/100 iters), loss = 0.097308
I1123 19:39:08.379515 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:39:08.379515 14064 solver.cpp:237]     Train net output #1: loss = 0.0973082 (* 1 = 0.0973082 loss)
I1123 19:39:08.379515 14064 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I1123 19:39:20.431248 14064 solver.cpp:218] Iteration 21200 (8.2979 iter/s, 12.0512s/100 iters), loss = 0.0825217
I1123 19:39:20.431248 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:39:20.431248 14064 solver.cpp:237]     Train net output #1: loss = 0.0825219 (* 1 = 0.0825219 loss)
I1123 19:39:20.431248 14064 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I1123 19:39:32.531193 14064 solver.cpp:218] Iteration 21300 (8.265 iter/s, 12.0992s/100 iters), loss = 0.093342
I1123 19:39:32.531193 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:39:32.531193 14064 solver.cpp:237]     Train net output #1: loss = 0.0933422 (* 1 = 0.0933422 loss)
I1123 19:39:32.531193 14064 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I1123 19:39:44.606191 14064 solver.cpp:218] Iteration 21400 (8.28217 iter/s, 12.0741s/100 iters), loss = 0.0886587
I1123 19:39:44.606191 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:39:44.606191 14064 solver.cpp:237]     Train net output #1: loss = 0.0886588 (* 1 = 0.0886588 loss)
I1123 19:39:44.606191 14064 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I1123 19:39:56.125619  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:39:56.611794 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_21500.caffemodel
I1123 19:39:56.650279 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_21500.solverstate
I1123 19:39:56.670280 14064 solver.cpp:330] Iteration 21500, Testing net (#0)
I1123 19:39:56.670280 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:40:00.753486 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:40:00.919221 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8911
I1123 19:40:00.919221 14064 solver.cpp:397]     Test net output #1: loss = 0.344999 (* 1 = 0.344999 loss)
I1123 19:40:01.039741 14064 solver.cpp:218] Iteration 21500 (6.08509 iter/s, 16.4336s/100 iters), loss = 0.0971244
I1123 19:40:01.039741 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:40:01.039741 14064 solver.cpp:237]     Train net output #1: loss = 0.0971246 (* 1 = 0.0971246 loss)
I1123 19:40:01.039741 14064 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I1123 19:40:13.183408 14064 solver.cpp:218] Iteration 21600 (8.23551 iter/s, 12.1425s/100 iters), loss = 0.182196
I1123 19:40:13.183923 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:40:13.183923 14064 solver.cpp:237]     Train net output #1: loss = 0.182196 (* 1 = 0.182196 loss)
I1123 19:40:13.183923 14064 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I1123 19:40:25.277386 14064 solver.cpp:218] Iteration 21700 (8.26903 iter/s, 12.0933s/100 iters), loss = 0.132776
I1123 19:40:25.277386 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:40:25.277386 14064 solver.cpp:237]     Train net output #1: loss = 0.132776 (* 1 = 0.132776 loss)
I1123 19:40:25.277886 14064 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I1123 19:40:37.323629 14064 solver.cpp:218] Iteration 21800 (8.30175 iter/s, 12.0456s/100 iters), loss = 0.105203
I1123 19:40:37.324112 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:40:37.324112 14064 solver.cpp:237]     Train net output #1: loss = 0.105203 (* 1 = 0.105203 loss)
I1123 19:40:37.324112 14064 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I1123 19:40:49.395594 14064 solver.cpp:218] Iteration 21900 (8.28437 iter/s, 12.0709s/100 iters), loss = 0.0567517
I1123 19:40:49.395594 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:40:49.395594 14064 solver.cpp:237]     Train net output #1: loss = 0.0567519 (* 1 = 0.0567519 loss)
I1123 19:40:49.395594 14064 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I1123 19:41:00.988163  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:41:01.467200 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_22000.caffemodel
I1123 19:41:01.507201 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_22000.solverstate
I1123 19:41:01.525719 14064 solver.cpp:330] Iteration 22000, Testing net (#0)
I1123 19:41:01.526201 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:41:05.594065 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:41:05.762379 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8912
I1123 19:41:05.762379 14064 solver.cpp:397]     Test net output #1: loss = 0.345107 (* 1 = 0.345107 loss)
I1123 19:41:05.884899 14064 solver.cpp:218] Iteration 22000 (6.06483 iter/s, 16.4885s/100 iters), loss = 0.0999666
I1123 19:41:05.884899 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:41:05.884899 14064 solver.cpp:237]     Train net output #1: loss = 0.0999668 (* 1 = 0.0999668 loss)
I1123 19:41:05.884899 14064 sgd_solver.cpp:46] MultiStep Status: Iteration 22000, step = 5
I1123 19:41:05.884899 14064 sgd_solver.cpp:105] Iteration 22000, lr = 1e-06
I1123 19:41:18.085429 14064 solver.cpp:218] Iteration 22100 (8.19679 iter/s, 12.1999s/100 iters), loss = 0.159436
I1123 19:41:18.085429 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:41:18.085429 14064 solver.cpp:237]     Train net output #1: loss = 0.159437 (* 1 = 0.159437 loss)
I1123 19:41:18.085429 14064 sgd_solver.cpp:105] Iteration 22100, lr = 1e-06
I1123 19:41:30.255080 14064 solver.cpp:218] Iteration 22200 (8.21748 iter/s, 12.1692s/100 iters), loss = 0.0901512
I1123 19:41:30.255080 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:41:30.255080 14064 solver.cpp:237]     Train net output #1: loss = 0.0901514 (* 1 = 0.0901514 loss)
I1123 19:41:30.255581 14064 sgd_solver.cpp:105] Iteration 22200, lr = 1e-06
I1123 19:41:42.326974 14064 solver.cpp:218] Iteration 22300 (8.28432 iter/s, 12.071s/100 iters), loss = 0.0747292
I1123 19:41:42.326974 14064 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1123 19:41:42.326974 14064 solver.cpp:237]     Train net output #1: loss = 0.0747293 (* 1 = 0.0747293 loss)
I1123 19:41:42.326974 14064 sgd_solver.cpp:105] Iteration 22300, lr = 1e-06
I1123 19:41:54.405654 14064 solver.cpp:218] Iteration 22400 (8.27944 iter/s, 12.0781s/100 iters), loss = 0.062732
I1123 19:41:54.405654 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:41:54.405654 14064 solver.cpp:237]     Train net output #1: loss = 0.0627322 (* 1 = 0.0627322 loss)
I1123 19:41:54.405654 14064 sgd_solver.cpp:105] Iteration 22400, lr = 1e-06
I1123 19:42:05.896059  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:42:06.374559 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_22500.caffemodel
I1123 19:42:06.411092 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_22500.solverstate
I1123 19:42:06.430094 14064 solver.cpp:330] Iteration 22500, Testing net (#0)
I1123 19:42:06.430094 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:42:10.464923 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:42:10.629957 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8913
I1123 19:42:10.629957 14064 solver.cpp:397]     Test net output #1: loss = 0.345093 (* 1 = 0.345093 loss)
I1123 19:42:10.748018 14064 solver.cpp:218] Iteration 22500 (6.11938 iter/s, 16.3415s/100 iters), loss = 0.093744
I1123 19:42:10.748018 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:42:10.748018 14064 solver.cpp:237]     Train net output #1: loss = 0.0937442 (* 1 = 0.0937442 loss)
I1123 19:42:10.748018 14064 sgd_solver.cpp:105] Iteration 22500, lr = 1e-06
I1123 19:42:22.814743 14064 solver.cpp:218] Iteration 22600 (8.28741 iter/s, 12.0665s/100 iters), loss = 0.113455
I1123 19:42:22.814743 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:42:22.814743 14064 solver.cpp:237]     Train net output #1: loss = 0.113455 (* 1 = 0.113455 loss)
I1123 19:42:22.814743 14064 sgd_solver.cpp:105] Iteration 22600, lr = 1e-06
I1123 19:42:34.959081 14064 solver.cpp:218] Iteration 22700 (8.23484 iter/s, 12.1435s/100 iters), loss = 0.086823
I1123 19:42:34.959081 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:42:34.959081 14064 solver.cpp:237]     Train net output #1: loss = 0.0868232 (* 1 = 0.0868232 loss)
I1123 19:42:34.959580 14064 sgd_solver.cpp:105] Iteration 22700, lr = 1e-06
I1123 19:42:47.093874 14064 solver.cpp:218] Iteration 22800 (8.24123 iter/s, 12.1341s/100 iters), loss = 0.0880763
I1123 19:42:47.093874 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:42:47.093874 14064 solver.cpp:237]     Train net output #1: loss = 0.0880765 (* 1 = 0.0880765 loss)
I1123 19:42:47.093874 14064 sgd_solver.cpp:105] Iteration 22800, lr = 1e-06
I1123 19:42:59.292870 14064 solver.cpp:218] Iteration 22900 (8.19799 iter/s, 12.1981s/100 iters), loss = 0.0946293
I1123 19:42:59.292870 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:42:59.292870 14064 solver.cpp:237]     Train net output #1: loss = 0.0946295 (* 1 = 0.0946295 loss)
I1123 19:42:59.292870 14064 sgd_solver.cpp:105] Iteration 22900, lr = 1e-06
I1123 19:43:10.873756  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:43:11.352777 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_23000.caffemodel
I1123 19:43:11.395776 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_23000.solverstate
I1123 19:43:11.422776 14064 solver.cpp:330] Iteration 23000, Testing net (#0)
I1123 19:43:11.422776 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:43:15.481398 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:43:15.645961 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8914
I1123 19:43:15.645961 14064 solver.cpp:397]     Test net output #1: loss = 0.345174 (* 1 = 0.345174 loss)
I1123 19:43:15.765002 14064 solver.cpp:218] Iteration 23000 (6.0711 iter/s, 16.4715s/100 iters), loss = 0.107829
I1123 19:43:15.765002 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:43:15.765002 14064 solver.cpp:237]     Train net output #1: loss = 0.107829 (* 1 = 0.107829 loss)
I1123 19:43:15.765002 14064 sgd_solver.cpp:105] Iteration 23000, lr = 1e-06
I1123 19:43:27.812445 14064 solver.cpp:218] Iteration 23100 (8.30087 iter/s, 12.0469s/100 iters), loss = 0.149641
I1123 19:43:27.812445 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:43:27.812445 14064 solver.cpp:237]     Train net output #1: loss = 0.149641 (* 1 = 0.149641 loss)
I1123 19:43:27.812445 14064 sgd_solver.cpp:105] Iteration 23100, lr = 1e-06
I1123 19:43:39.852604 14064 solver.cpp:218] Iteration 23200 (8.30592 iter/s, 12.0396s/100 iters), loss = 0.100454
I1123 19:43:39.852604 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:43:39.852604 14064 solver.cpp:237]     Train net output #1: loss = 0.100454 (* 1 = 0.100454 loss)
I1123 19:43:39.852604 14064 sgd_solver.cpp:105] Iteration 23200, lr = 1e-06
I1123 19:43:52.064262 14064 solver.cpp:218] Iteration 23300 (8.1896 iter/s, 12.2106s/100 iters), loss = 0.086377
I1123 19:43:52.064262 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:43:52.064262 14064 solver.cpp:237]     Train net output #1: loss = 0.0863772 (* 1 = 0.0863772 loss)
I1123 19:43:52.064262 14064 sgd_solver.cpp:105] Iteration 23300, lr = 1e-06
I1123 19:44:04.283818 14064 solver.cpp:218] Iteration 23400 (8.18377 iter/s, 12.2193s/100 iters), loss = 0.105614
I1123 19:44:04.283818 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:44:04.284318 14064 solver.cpp:237]     Train net output #1: loss = 0.105614 (* 1 = 0.105614 loss)
I1123 19:44:04.284318 14064 sgd_solver.cpp:105] Iteration 23400, lr = 1e-06
I1123 19:44:15.820405  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:44:16.297905 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_23500.caffemodel
I1123 19:44:16.339905 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_23500.solverstate
I1123 19:44:16.359405 14064 solver.cpp:330] Iteration 23500, Testing net (#0)
I1123 19:44:16.359405 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:44:20.446007 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:44:20.611562 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8909
I1123 19:44:20.611562 14064 solver.cpp:397]     Test net output #1: loss = 0.344928 (* 1 = 0.344928 loss)
I1123 19:44:20.729149 14064 solver.cpp:218] Iteration 23500 (6.08103 iter/s, 16.4446s/100 iters), loss = 0.0884895
I1123 19:44:20.729149 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:44:20.729653 14064 solver.cpp:237]     Train net output #1: loss = 0.0884897 (* 1 = 0.0884897 loss)
I1123 19:44:20.729653 14064 sgd_solver.cpp:105] Iteration 23500, lr = 1e-06
I1123 19:44:32.860178 14064 solver.cpp:218] Iteration 23600 (8.24384 iter/s, 12.1303s/100 iters), loss = 0.103328
I1123 19:44:32.860178 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:44:32.860178 14064 solver.cpp:237]     Train net output #1: loss = 0.103328 (* 1 = 0.103328 loss)
I1123 19:44:32.860178 14064 sgd_solver.cpp:105] Iteration 23600, lr = 1e-06
I1123 19:44:44.956930 14064 solver.cpp:218] Iteration 23700 (8.26716 iter/s, 12.0961s/100 iters), loss = 0.100964
I1123 19:44:44.956930 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:44:44.956930 14064 solver.cpp:237]     Train net output #1: loss = 0.100964 (* 1 = 0.100964 loss)
I1123 19:44:44.956930 14064 sgd_solver.cpp:105] Iteration 23700, lr = 1e-06
I1123 19:44:57.056908 14064 solver.cpp:218] Iteration 23800 (8.26483 iter/s, 12.0995s/100 iters), loss = 0.0910557
I1123 19:44:57.056908 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:44:57.056908 14064 solver.cpp:237]     Train net output #1: loss = 0.0910559 (* 1 = 0.0910559 loss)
I1123 19:44:57.056908 14064 sgd_solver.cpp:105] Iteration 23800, lr = 1e-06
I1123 19:45:09.106005 14064 solver.cpp:218] Iteration 23900 (8.29977 iter/s, 12.0485s/100 iters), loss = 0.0803415
I1123 19:45:09.106005 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:45:09.106500 14064 solver.cpp:237]     Train net output #1: loss = 0.0803417 (* 1 = 0.0803417 loss)
I1123 19:45:09.106500 14064 sgd_solver.cpp:105] Iteration 23900, lr = 1e-06
I1123 19:45:20.592934  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:45:21.083278 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_24000.caffemodel
I1123 19:45:21.122782 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_24000.solverstate
I1123 19:45:21.141321 14064 solver.cpp:330] Iteration 24000, Testing net (#0)
I1123 19:45:21.141321 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:45:25.222952 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:45:25.389008 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8911
I1123 19:45:25.389008 14064 solver.cpp:397]     Test net output #1: loss = 0.345196 (* 1 = 0.345196 loss)
I1123 19:45:25.508054 14064 solver.cpp:218] Iteration 24000 (6.09721 iter/s, 16.4009s/100 iters), loss = 0.110558
I1123 19:45:25.508054 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:45:25.508054 14064 solver.cpp:237]     Train net output #1: loss = 0.110558 (* 1 = 0.110558 loss)
I1123 19:45:25.508054 14064 sgd_solver.cpp:105] Iteration 24000, lr = 1e-06
I1123 19:45:37.666275 14064 solver.cpp:218] Iteration 24100 (8.22512 iter/s, 12.1579s/100 iters), loss = 0.113538
I1123 19:45:37.666275 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:45:37.666275 14064 solver.cpp:237]     Train net output #1: loss = 0.113538 (* 1 = 0.113538 loss)
I1123 19:45:37.666275 14064 sgd_solver.cpp:105] Iteration 24100, lr = 1e-06
I1123 19:45:49.773818 14064 solver.cpp:218] Iteration 24200 (8.25975 iter/s, 12.1069s/100 iters), loss = 0.103052
I1123 19:45:49.773818 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:45:49.774298 14064 solver.cpp:237]     Train net output #1: loss = 0.103052 (* 1 = 0.103052 loss)
I1123 19:45:49.774298 14064 sgd_solver.cpp:105] Iteration 24200, lr = 1e-06
I1123 19:46:01.844554 14064 solver.cpp:218] Iteration 24300 (8.28505 iter/s, 12.0699s/100 iters), loss = 0.122378
I1123 19:46:01.844554 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1123 19:46:01.844554 14064 solver.cpp:237]     Train net output #1: loss = 0.122378 (* 1 = 0.122378 loss)
I1123 19:46:01.844554 14064 sgd_solver.cpp:105] Iteration 24300, lr = 1e-06
I1123 19:46:14.042490 14064 solver.cpp:218] Iteration 24400 (8.19817 iter/s, 12.1978s/100 iters), loss = 0.121387
I1123 19:46:14.043483 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:46:14.043483 14064 solver.cpp:237]     Train net output #1: loss = 0.121387 (* 1 = 0.121387 loss)
I1123 19:46:14.043483 14064 sgd_solver.cpp:105] Iteration 24400, lr = 1e-06
I1123 19:46:25.671392  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:46:26.153512 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_24500.caffemodel
I1123 19:46:26.200033 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_24500.solverstate
I1123 19:46:26.218037 14064 solver.cpp:330] Iteration 24500, Testing net (#0)
I1123 19:46:26.218037 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:46:30.257521 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:46:30.423554 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8912
I1123 19:46:30.423554 14064 solver.cpp:397]     Test net output #1: loss = 0.345163 (* 1 = 0.345163 loss)
I1123 19:46:30.542127 14064 solver.cpp:218] Iteration 24500 (6.06146 iter/s, 16.4977s/100 iters), loss = 0.0918113
I1123 19:46:30.542127 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:46:30.542127 14064 solver.cpp:237]     Train net output #1: loss = 0.0918115 (* 1 = 0.0918115 loss)
I1123 19:46:30.542127 14064 sgd_solver.cpp:105] Iteration 24500, lr = 1e-06
I1123 19:46:42.773900 14064 solver.cpp:218] Iteration 24600 (8.17591 iter/s, 12.2311s/100 iters), loss = 0.0951867
I1123 19:46:42.773900 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:46:42.773900 14064 solver.cpp:237]     Train net output #1: loss = 0.0951869 (* 1 = 0.0951869 loss)
I1123 19:46:42.773900 14064 sgd_solver.cpp:105] Iteration 24600, lr = 1e-06
I1123 19:46:54.919384 14064 solver.cpp:218] Iteration 24700 (8.2341 iter/s, 12.1446s/100 iters), loss = 0.0807383
I1123 19:46:54.919384 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:46:54.919384 14064 solver.cpp:237]     Train net output #1: loss = 0.0807385 (* 1 = 0.0807385 loss)
I1123 19:46:54.919384 14064 sgd_solver.cpp:105] Iteration 24700, lr = 1e-06
I1123 19:47:06.999501 14064 solver.cpp:218] Iteration 24800 (8.27857 iter/s, 12.0794s/100 iters), loss = 0.0676318
I1123 19:47:06.999501 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:47:06.999501 14064 solver.cpp:237]     Train net output #1: loss = 0.067632 (* 1 = 0.067632 loss)
I1123 19:47:06.999501 14064 sgd_solver.cpp:105] Iteration 24800, lr = 1e-06
I1123 19:47:19.103737 14064 solver.cpp:218] Iteration 24900 (8.26192 iter/s, 12.1037s/100 iters), loss = 0.0953662
I1123 19:47:19.103737 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:47:19.103737 14064 solver.cpp:237]     Train net output #1: loss = 0.0953664 (* 1 = 0.0953664 loss)
I1123 19:47:19.103737 14064 sgd_solver.cpp:105] Iteration 24900, lr = 1e-06
I1123 19:47:30.597640  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:47:31.098811 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_25000.caffemodel
I1123 19:47:31.137825 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_25000.solverstate
I1123 19:47:31.156328 14064 solver.cpp:330] Iteration 25000, Testing net (#0)
I1123 19:47:31.156328 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:47:35.214712 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:47:35.380220 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8913
I1123 19:47:35.380220 14064 solver.cpp:397]     Test net output #1: loss = 0.345328 (* 1 = 0.345328 loss)
I1123 19:47:35.498273 14064 solver.cpp:218] Iteration 25000 (6.09967 iter/s, 16.3943s/100 iters), loss = 0.0946716
I1123 19:47:35.498273 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:47:35.498273 14064 solver.cpp:237]     Train net output #1: loss = 0.0946717 (* 1 = 0.0946717 loss)
I1123 19:47:35.498273 14064 sgd_solver.cpp:105] Iteration 25000, lr = 1e-06
I1123 19:47:47.641762 14064 solver.cpp:218] Iteration 25100 (8.23551 iter/s, 12.1425s/100 iters), loss = 0.150129
I1123 19:47:47.641762 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:47:47.641762 14064 solver.cpp:237]     Train net output #1: loss = 0.150129 (* 1 = 0.150129 loss)
I1123 19:47:47.641762 14064 sgd_solver.cpp:105] Iteration 25100, lr = 1e-06
I1123 19:47:59.711619 14064 solver.cpp:218] Iteration 25200 (8.28584 iter/s, 12.0688s/100 iters), loss = 0.0686035
I1123 19:47:59.711619 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:47:59.711619 14064 solver.cpp:237]     Train net output #1: loss = 0.0686037 (* 1 = 0.0686037 loss)
I1123 19:47:59.711619 14064 sgd_solver.cpp:105] Iteration 25200, lr = 1e-06
I1123 19:48:11.865655 14064 solver.cpp:218] Iteration 25300 (8.22794 iter/s, 12.1537s/100 iters), loss = 0.0697877
I1123 19:48:11.865655 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:48:11.865655 14064 solver.cpp:237]     Train net output #1: loss = 0.0697879 (* 1 = 0.0697879 loss)
I1123 19:48:11.865655 14064 sgd_solver.cpp:105] Iteration 25300, lr = 1e-06
I1123 19:48:24.073524 14064 solver.cpp:218] Iteration 25400 (8.19205 iter/s, 12.207s/100 iters), loss = 0.0703567
I1123 19:48:24.073524 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:48:24.073524 14064 solver.cpp:237]     Train net output #1: loss = 0.0703569 (* 1 = 0.0703569 loss)
I1123 19:48:24.073524 14064 sgd_solver.cpp:105] Iteration 25400, lr = 1e-06
I1123 19:48:35.589543  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:48:36.065577 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_25500.caffemodel
I1123 19:48:36.102061 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_25500.solverstate
I1123 19:48:36.120061 14064 solver.cpp:330] Iteration 25500, Testing net (#0)
I1123 19:48:36.120061 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:48:40.176872 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:48:40.341897 14064 solver.cpp:397]     Test net output #0: accuracy = 0.891
I1123 19:48:40.341897 14064 solver.cpp:397]     Test net output #1: loss = 0.345049 (* 1 = 0.345049 loss)
I1123 19:48:40.459906 14064 solver.cpp:218] Iteration 25500 (6.10268 iter/s, 16.3862s/100 iters), loss = 0.095288
I1123 19:48:40.459906 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:48:40.459906 14064 solver.cpp:237]     Train net output #1: loss = 0.0952883 (* 1 = 0.0952883 loss)
I1123 19:48:40.460893 14064 sgd_solver.cpp:105] Iteration 25500, lr = 1e-06
I1123 19:48:52.516345 14064 solver.cpp:218] Iteration 25600 (8.29516 iter/s, 12.0552s/100 iters), loss = 0.165392
I1123 19:48:52.516345 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:48:52.516345 14064 solver.cpp:237]     Train net output #1: loss = 0.165393 (* 1 = 0.165393 loss)
I1123 19:48:52.516345 14064 sgd_solver.cpp:105] Iteration 25600, lr = 1e-06
I1123 19:49:04.659382 14064 solver.cpp:218] Iteration 25700 (8.2357 iter/s, 12.1423s/100 iters), loss = 0.0965427
I1123 19:49:04.659382 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:49:04.659382 14064 solver.cpp:237]     Train net output #1: loss = 0.0965429 (* 1 = 0.0965429 loss)
I1123 19:49:04.659382 14064 sgd_solver.cpp:105] Iteration 25700, lr = 1e-06
I1123 19:49:16.792400 14064 solver.cpp:218] Iteration 25800 (8.24234 iter/s, 12.1325s/100 iters), loss = 0.0814876
I1123 19:49:16.792400 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:49:16.792400 14064 solver.cpp:237]     Train net output #1: loss = 0.0814878 (* 1 = 0.0814878 loss)
I1123 19:49:16.792400 14064 sgd_solver.cpp:105] Iteration 25800, lr = 1e-06
I1123 19:49:28.887795 14064 solver.cpp:218] Iteration 25900 (8.26799 iter/s, 12.0948s/100 iters), loss = 0.0717944
I1123 19:49:28.887795 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:49:28.887795 14064 solver.cpp:237]     Train net output #1: loss = 0.0717946 (* 1 = 0.0717946 loss)
I1123 19:49:28.887795 14064 sgd_solver.cpp:105] Iteration 25900, lr = 1e-06
I1123 19:49:40.374522  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:49:40.852093 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_26000.caffemodel
I1123 19:49:40.895092 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_26000.solverstate
I1123 19:49:40.915093 14064 solver.cpp:330] Iteration 26000, Testing net (#0)
I1123 19:49:40.915093 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:49:44.952862 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:49:45.118901 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8914
I1123 19:49:45.118901 14064 solver.cpp:397]     Test net output #1: loss = 0.344997 (* 1 = 0.344997 loss)
I1123 19:49:45.237452 14064 solver.cpp:218] Iteration 26000 (6.11671 iter/s, 16.3487s/100 iters), loss = 0.0846688
I1123 19:49:45.237452 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:49:45.237452 14064 solver.cpp:237]     Train net output #1: loss = 0.0846691 (* 1 = 0.0846691 loss)
I1123 19:49:45.237452 14064 sgd_solver.cpp:105] Iteration 26000, lr = 1e-06
I1123 19:49:57.486918 14064 solver.cpp:218] Iteration 26100 (8.16377 iter/s, 12.2492s/100 iters), loss = 0.11753
I1123 19:49:57.487407 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:49:57.487407 14064 solver.cpp:237]     Train net output #1: loss = 0.11753 (* 1 = 0.11753 loss)
I1123 19:49:57.487407 14064 sgd_solver.cpp:105] Iteration 26100, lr = 1e-06
I1123 19:50:09.596442 14064 solver.cpp:218] Iteration 26200 (8.25853 iter/s, 12.1087s/100 iters), loss = 0.0845319
I1123 19:50:09.596442 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:50:09.596442 14064 solver.cpp:237]     Train net output #1: loss = 0.0845321 (* 1 = 0.0845321 loss)
I1123 19:50:09.596442 14064 sgd_solver.cpp:105] Iteration 26200, lr = 1e-06
I1123 19:50:21.697842 14064 solver.cpp:218] Iteration 26300 (8.26387 iter/s, 12.1009s/100 iters), loss = 0.0869505
I1123 19:50:21.697842 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:50:21.697842 14064 solver.cpp:237]     Train net output #1: loss = 0.0869508 (* 1 = 0.0869508 loss)
I1123 19:50:21.697842 14064 sgd_solver.cpp:105] Iteration 26300, lr = 1e-06
I1123 19:50:33.786098 14064 solver.cpp:218] Iteration 26400 (8.2732 iter/s, 12.0872s/100 iters), loss = 0.0974641
I1123 19:50:33.786098 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:50:33.786098 14064 solver.cpp:237]     Train net output #1: loss = 0.0974643 (* 1 = 0.0974643 loss)
I1123 19:50:33.786098 14064 sgd_solver.cpp:105] Iteration 26400, lr = 1e-06
I1123 19:50:45.292961  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:50:45.771082 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_26500.caffemodel
I1123 19:50:45.810572 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_26500.solverstate
I1123 19:50:45.829561 14064 solver.cpp:330] Iteration 26500, Testing net (#0)
I1123 19:50:45.829561 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:50:49.882542 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:50:50.048596 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8915
I1123 19:50:50.049582 14064 solver.cpp:397]     Test net output #1: loss = 0.345202 (* 1 = 0.345202 loss)
I1123 19:50:50.167306 14064 solver.cpp:218] Iteration 26500 (6.10477 iter/s, 16.3806s/100 iters), loss = 0.064431
I1123 19:50:50.167306 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:50:50.167306 14064 solver.cpp:237]     Train net output #1: loss = 0.0644313 (* 1 = 0.0644313 loss)
I1123 19:50:50.167306 14064 sgd_solver.cpp:105] Iteration 26500, lr = 1e-06
I1123 19:51:02.380641 14064 solver.cpp:218] Iteration 26600 (8.18833 iter/s, 12.2125s/100 iters), loss = 0.135008
I1123 19:51:02.380641 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:51:02.380641 14064 solver.cpp:237]     Train net output #1: loss = 0.135008 (* 1 = 0.135008 loss)
I1123 19:51:02.380641 14064 sgd_solver.cpp:105] Iteration 26600, lr = 1e-06
I1123 19:51:14.740871 14064 solver.cpp:218] Iteration 26700 (8.09057 iter/s, 12.3601s/100 iters), loss = 0.0945477
I1123 19:51:14.740871 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:51:14.740871 14064 solver.cpp:237]     Train net output #1: loss = 0.0945479 (* 1 = 0.0945479 loss)
I1123 19:51:14.740871 14064 sgd_solver.cpp:105] Iteration 26700, lr = 1e-06
I1123 19:51:27.030462 14064 solver.cpp:218] Iteration 26800 (8.13762 iter/s, 12.2886s/100 iters), loss = 0.089685
I1123 19:51:27.030462 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:51:27.030462 14064 solver.cpp:237]     Train net output #1: loss = 0.0896853 (* 1 = 0.0896853 loss)
I1123 19:51:27.030462 14064 sgd_solver.cpp:105] Iteration 26800, lr = 1e-06
I1123 19:51:39.092489 14064 solver.cpp:218] Iteration 26900 (8.2908 iter/s, 12.0616s/100 iters), loss = 0.0837218
I1123 19:51:39.092489 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:51:39.092489 14064 solver.cpp:237]     Train net output #1: loss = 0.0837221 (* 1 = 0.0837221 loss)
I1123 19:51:39.092489 14064 sgd_solver.cpp:105] Iteration 26900, lr = 1e-06
I1123 19:51:50.648802  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:51:51.129544 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_27000.caffemodel
I1123 19:51:51.167544 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_27000.solverstate
I1123 19:51:51.190042 14064 solver.cpp:330] Iteration 27000, Testing net (#0)
I1123 19:51:51.190042 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:51:55.234513 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:51:55.401525 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8911
I1123 19:51:55.401525 14064 solver.cpp:397]     Test net output #1: loss = 0.345062 (* 1 = 0.345062 loss)
I1123 19:51:55.522577 14064 solver.cpp:218] Iteration 27000 (6.08672 iter/s, 16.4292s/100 iters), loss = 0.102493
I1123 19:51:55.522577 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:51:55.522577 14064 solver.cpp:237]     Train net output #1: loss = 0.102493 (* 1 = 0.102493 loss)
I1123 19:51:55.522577 14064 sgd_solver.cpp:46] MultiStep Status: Iteration 27000, step = 6
I1123 19:51:55.522577 14064 sgd_solver.cpp:105] Iteration 27000, lr = 1e-07
I1123 19:52:07.722795 14064 solver.cpp:218] Iteration 27100 (8.19708 iter/s, 12.1995s/100 iters), loss = 0.134757
I1123 19:52:07.722795 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:52:07.722795 14064 solver.cpp:237]     Train net output #1: loss = 0.134757 (* 1 = 0.134757 loss)
I1123 19:52:07.722795 14064 sgd_solver.cpp:105] Iteration 27100, lr = 1e-07
I1123 19:52:19.821184 14064 solver.cpp:218] Iteration 27200 (8.26582 iter/s, 12.098s/100 iters), loss = 0.0881302
I1123 19:52:19.821184 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:52:19.821184 14064 solver.cpp:237]     Train net output #1: loss = 0.0881305 (* 1 = 0.0881305 loss)
I1123 19:52:19.821184 14064 sgd_solver.cpp:105] Iteration 27200, lr = 1e-07
I1123 19:52:31.882305 14064 solver.cpp:218] Iteration 27300 (8.29113 iter/s, 12.0611s/100 iters), loss = 0.0751874
I1123 19:52:31.883298 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:52:31.883298 14064 solver.cpp:237]     Train net output #1: loss = 0.0751877 (* 1 = 0.0751877 loss)
I1123 19:52:31.883298 14064 sgd_solver.cpp:105] Iteration 27300, lr = 1e-07
I1123 19:52:43.937446 14064 solver.cpp:218] Iteration 27400 (8.29613 iter/s, 12.0538s/100 iters), loss = 0.0887116
I1123 19:52:43.937446 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:52:43.937446 14064 solver.cpp:237]     Train net output #1: loss = 0.0887119 (* 1 = 0.0887119 loss)
I1123 19:52:43.937446 14064 sgd_solver.cpp:105] Iteration 27400, lr = 1e-07
I1123 19:52:55.478276  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:52:55.967438 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_27500.caffemodel
I1123 19:52:56.007446 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_27500.solverstate
I1123 19:52:56.025950 14064 solver.cpp:330] Iteration 27500, Testing net (#0)
I1123 19:52:56.025950 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:53:00.067397 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:53:00.232468 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8913
I1123 19:53:00.232468 14064 solver.cpp:397]     Test net output #1: loss = 0.345183 (* 1 = 0.345183 loss)
I1123 19:53:00.350498 14064 solver.cpp:218] Iteration 27500 (6.09291 iter/s, 16.4125s/100 iters), loss = 0.0932216
I1123 19:53:00.350498 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:53:00.350498 14064 solver.cpp:237]     Train net output #1: loss = 0.0932219 (* 1 = 0.0932219 loss)
I1123 19:53:00.350498 14064 sgd_solver.cpp:105] Iteration 27500, lr = 1e-07
I1123 19:53:12.467555 14064 solver.cpp:218] Iteration 27600 (8.25351 iter/s, 12.1161s/100 iters), loss = 0.154772
I1123 19:53:12.467555 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:53:12.467555 14064 solver.cpp:237]     Train net output #1: loss = 0.154772 (* 1 = 0.154772 loss)
I1123 19:53:12.467555 14064 sgd_solver.cpp:105] Iteration 27600, lr = 1e-07
I1123 19:53:24.535567 14064 solver.cpp:218] Iteration 27700 (8.28678 iter/s, 12.0674s/100 iters), loss = 0.0804752
I1123 19:53:24.536056 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:53:24.536056 14064 solver.cpp:237]     Train net output #1: loss = 0.0804755 (* 1 = 0.0804755 loss)
I1123 19:53:24.536056 14064 sgd_solver.cpp:105] Iteration 27700, lr = 1e-07
I1123 19:53:36.613807 14064 solver.cpp:218] Iteration 27800 (8.28001 iter/s, 12.0773s/100 iters), loss = 0.100846
I1123 19:53:36.613807 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:53:36.613807 14064 solver.cpp:237]     Train net output #1: loss = 0.100847 (* 1 = 0.100847 loss)
I1123 19:53:36.613807 14064 sgd_solver.cpp:105] Iteration 27800, lr = 1e-07
I1123 19:53:48.725369 14064 solver.cpp:218] Iteration 27900 (8.25708 iter/s, 12.1108s/100 iters), loss = 0.102034
I1123 19:53:48.725369 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1123 19:53:48.725369 14064 solver.cpp:237]     Train net output #1: loss = 0.102034 (* 1 = 0.102034 loss)
I1123 19:53:48.725369 14064 sgd_solver.cpp:105] Iteration 27900, lr = 1e-07
I1123 19:54:00.244559  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:54:00.727607 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_28000.caffemodel
I1123 19:54:00.766592 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_28000.solverstate
I1123 19:54:00.785091 14064 solver.cpp:330] Iteration 28000, Testing net (#0)
I1123 19:54:00.785590 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:54:04.814975 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:54:04.980021 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8913
I1123 19:54:04.980021 14064 solver.cpp:397]     Test net output #1: loss = 0.345179 (* 1 = 0.345179 loss)
I1123 19:54:05.098070 14064 solver.cpp:218] Iteration 28000 (6.10787 iter/s, 16.3723s/100 iters), loss = 0.116399
I1123 19:54:05.098070 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:54:05.098070 14064 solver.cpp:237]     Train net output #1: loss = 0.116399 (* 1 = 0.116399 loss)
I1123 19:54:05.098070 14064 sgd_solver.cpp:105] Iteration 28000, lr = 1e-07
I1123 19:54:17.140538 14064 solver.cpp:218] Iteration 28100 (8.30459 iter/s, 12.0415s/100 iters), loss = 0.113741
I1123 19:54:17.140538 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:54:17.140538 14064 solver.cpp:237]     Train net output #1: loss = 0.113741 (* 1 = 0.113741 loss)
I1123 19:54:17.140538 14064 sgd_solver.cpp:105] Iteration 28100, lr = 1e-07
I1123 19:54:29.240813 14064 solver.cpp:218] Iteration 28200 (8.26431 iter/s, 12.1002s/100 iters), loss = 0.102451
I1123 19:54:29.240813 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:54:29.240813 14064 solver.cpp:237]     Train net output #1: loss = 0.102452 (* 1 = 0.102452 loss)
I1123 19:54:29.240813 14064 sgd_solver.cpp:105] Iteration 28200, lr = 1e-07
I1123 19:54:41.464253 14064 solver.cpp:218] Iteration 28300 (8.18169 iter/s, 12.2224s/100 iters), loss = 0.0635347
I1123 19:54:41.464253 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:54:41.464253 14064 solver.cpp:237]     Train net output #1: loss = 0.0635351 (* 1 = 0.0635351 loss)
I1123 19:54:41.464253 14064 sgd_solver.cpp:105] Iteration 28300, lr = 1e-07
I1123 19:54:53.575328 14064 solver.cpp:218] Iteration 28400 (8.25688 iter/s, 12.1111s/100 iters), loss = 0.0877747
I1123 19:54:53.576309 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:54:53.576309 14064 solver.cpp:237]     Train net output #1: loss = 0.087775 (* 1 = 0.087775 loss)
I1123 19:54:53.576309 14064 sgd_solver.cpp:105] Iteration 28400, lr = 1e-07
I1123 19:55:05.044363  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:55:05.521920 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_28500.caffemodel
I1123 19:55:05.557917 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_28500.solverstate
I1123 19:55:05.576417 14064 solver.cpp:330] Iteration 28500, Testing net (#0)
I1123 19:55:05.576417 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:55:09.643184 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:55:09.809150 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8913
I1123 19:55:09.809150 14064 solver.cpp:397]     Test net output #1: loss = 0.345207 (* 1 = 0.345207 loss)
I1123 19:55:09.928210 14064 solver.cpp:218] Iteration 28500 (6.11561 iter/s, 16.3516s/100 iters), loss = 0.103219
I1123 19:55:09.928210 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:55:09.928712 14064 solver.cpp:237]     Train net output #1: loss = 0.103219 (* 1 = 0.103219 loss)
I1123 19:55:09.928712 14064 sgd_solver.cpp:105] Iteration 28500, lr = 1e-07
I1123 19:55:22.086555 14064 solver.cpp:218] Iteration 28600 (8.2253 iter/s, 12.1576s/100 iters), loss = 0.12264
I1123 19:55:22.087045 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:55:22.087045 14064 solver.cpp:237]     Train net output #1: loss = 0.122641 (* 1 = 0.122641 loss)
I1123 19:55:22.087045 14064 sgd_solver.cpp:105] Iteration 28600, lr = 1e-07
I1123 19:55:34.216681 14064 solver.cpp:218] Iteration 28700 (8.24466 iter/s, 12.1291s/100 iters), loss = 0.075824
I1123 19:55:34.216681 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:55:34.216681 14064 solver.cpp:237]     Train net output #1: loss = 0.0758242 (* 1 = 0.0758242 loss)
I1123 19:55:34.216681 14064 sgd_solver.cpp:105] Iteration 28700, lr = 1e-07
I1123 19:55:46.377897 14064 solver.cpp:218] Iteration 28800 (8.22272 iter/s, 12.1614s/100 iters), loss = 0.0683194
I1123 19:55:46.378896 14064 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1123 19:55:46.378896 14064 solver.cpp:237]     Train net output #1: loss = 0.0683197 (* 1 = 0.0683197 loss)
I1123 19:55:46.378896 14064 sgd_solver.cpp:105] Iteration 28800, lr = 1e-07
I1123 19:55:58.548106 14064 solver.cpp:218] Iteration 28900 (8.21773 iter/s, 12.1688s/100 iters), loss = 0.0720179
I1123 19:55:58.548106 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:55:58.548106 14064 solver.cpp:237]     Train net output #1: loss = 0.0720182 (* 1 = 0.0720182 loss)
I1123 19:55:58.548106 14064 sgd_solver.cpp:105] Iteration 28900, lr = 1e-07
I1123 19:56:10.064785  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:56:10.541822 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_29000.caffemodel
I1123 19:56:10.580338 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_29000.solverstate
I1123 19:56:10.599320 14064 solver.cpp:330] Iteration 29000, Testing net (#0)
I1123 19:56:10.599320 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:56:14.648708 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:56:14.814746 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8914
I1123 19:56:14.814746 14064 solver.cpp:397]     Test net output #1: loss = 0.345235 (* 1 = 0.345235 loss)
I1123 19:56:14.931790 14064 solver.cpp:218] Iteration 29000 (6.10362 iter/s, 16.3837s/100 iters), loss = 0.0861371
I1123 19:56:14.932790 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:56:14.932790 14064 solver.cpp:237]     Train net output #1: loss = 0.0861374 (* 1 = 0.0861374 loss)
I1123 19:56:14.932790 14064 sgd_solver.cpp:105] Iteration 29000, lr = 1e-07
I1123 19:56:27.031725 14064 solver.cpp:218] Iteration 29100 (8.26558 iter/s, 12.0984s/100 iters), loss = 0.13043
I1123 19:56:27.031725 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:56:27.031725 14064 solver.cpp:237]     Train net output #1: loss = 0.13043 (* 1 = 0.13043 loss)
I1123 19:56:27.031725 14064 sgd_solver.cpp:105] Iteration 29100, lr = 1e-07
I1123 19:56:39.204011 14064 solver.cpp:218] Iteration 29200 (8.2158 iter/s, 12.1717s/100 iters), loss = 0.0751383
I1123 19:56:39.204011 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1123 19:56:39.204011 14064 solver.cpp:237]     Train net output #1: loss = 0.0751386 (* 1 = 0.0751386 loss)
I1123 19:56:39.204011 14064 sgd_solver.cpp:105] Iteration 29200, lr = 1e-07
I1123 19:56:51.348645 14064 solver.cpp:218] Iteration 29300 (8.23419 iter/s, 12.1445s/100 iters), loss = 0.0831499
I1123 19:56:51.348645 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:56:51.348645 14064 solver.cpp:237]     Train net output #1: loss = 0.0831502 (* 1 = 0.0831502 loss)
I1123 19:56:51.348645 14064 sgd_solver.cpp:105] Iteration 29300, lr = 1e-07
I1123 19:57:03.512601 14064 solver.cpp:218] Iteration 29400 (8.22165 iter/s, 12.163s/100 iters), loss = 0.0894869
I1123 19:57:03.512601 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:57:03.512601 14064 solver.cpp:237]     Train net output #1: loss = 0.0894872 (* 1 = 0.0894872 loss)
I1123 19:57:03.512601 14064 sgd_solver.cpp:105] Iteration 29400, lr = 1e-07
I1123 19:57:15.021373  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:57:15.500205 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_29500.caffemodel
I1123 19:57:15.563433 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_29500.solverstate
I1123 19:57:15.582443 14064 solver.cpp:330] Iteration 29500, Testing net (#0)
I1123 19:57:15.582443 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:57:19.638902 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:57:19.803879 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8913
I1123 19:57:19.803879 14064 solver.cpp:397]     Test net output #1: loss = 0.345019 (* 1 = 0.345019 loss)
I1123 19:57:19.922921 14064 solver.cpp:218] Iteration 29500 (6.09404 iter/s, 16.4095s/100 iters), loss = 0.078591
I1123 19:57:19.922921 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1123 19:57:19.922921 14064 solver.cpp:237]     Train net output #1: loss = 0.0785913 (* 1 = 0.0785913 loss)
I1123 19:57:19.922921 14064 sgd_solver.cpp:105] Iteration 29500, lr = 1e-07
I1123 19:57:32.022754 14064 solver.cpp:218] Iteration 29600 (8.26501 iter/s, 12.0992s/100 iters), loss = 0.143361
I1123 19:57:32.022754 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:57:32.022754 14064 solver.cpp:237]     Train net output #1: loss = 0.143361 (* 1 = 0.143361 loss)
I1123 19:57:32.022754 14064 sgd_solver.cpp:105] Iteration 29600, lr = 1e-07
I1123 19:57:44.108741 14064 solver.cpp:218] Iteration 29700 (8.27443 iter/s, 12.0854s/100 iters), loss = 0.0969546
I1123 19:57:44.108741 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1123 19:57:44.108741 14064 solver.cpp:237]     Train net output #1: loss = 0.0969549 (* 1 = 0.0969549 loss)
I1123 19:57:44.108741 14064 sgd_solver.cpp:105] Iteration 29700, lr = 1e-07
I1123 19:57:56.210069 14064 solver.cpp:218] Iteration 29800 (8.26401 iter/s, 12.1007s/100 iters), loss = 0.0748416
I1123 19:57:56.210069 14064 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1123 19:57:56.210069 14064 solver.cpp:237]     Train net output #1: loss = 0.0748419 (* 1 = 0.0748419 loss)
I1123 19:57:56.210069 14064 sgd_solver.cpp:105] Iteration 29800, lr = 1e-07
I1123 19:58:08.300999 14064 solver.cpp:218] Iteration 29900 (8.27104 iter/s, 12.0904s/100 iters), loss = 0.0938017
I1123 19:58:08.300999 14064 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1123 19:58:08.300999 14064 solver.cpp:237]     Train net output #1: loss = 0.0938019 (* 1 = 0.0938019 loss)
I1123 19:58:08.300999 14064 sgd_solver.cpp:105] Iteration 29900, lr = 1e-07
I1123 19:58:19.781533  4236 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:58:20.259018 14064 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_30000.caffemodel
I1123 19:58:20.295516 14064 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_iter_30000.solverstate
I1123 19:58:20.359019 14064 solver.cpp:310] Iteration 30000, loss = 0.121765
I1123 19:58:20.359019 14064 solver.cpp:330] Iteration 30000, Testing net (#0)
I1123 19:58:20.359019 14064 net.cpp:676] Ignoring source layer accuracy_training
I1123 19:58:24.403666 32444 data_layer.cpp:73] Restarting data prefetching from start.
I1123 19:58:24.569730 14064 solver.cpp:397]     Test net output #0: accuracy = 0.8913
I1123 19:58:24.569730 14064 solver.cpp:397]     Test net output #1: loss = 0.345055 (* 1 = 0.345055 loss)
I1123 19:58:24.569730 14064 solver.cpp:315] Optimization Done.
I1123 19:58:24.569730 14064 caffe.cpp:260] Optimization Done.

G:\Caffe>pause
Press any key to continue . . . 