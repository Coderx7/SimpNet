
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I1124 10:02:23.363703  3844 caffe.cpp:219] Using GPUs 0
I1124 10:02:23.529302  3844 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1124 10:02:23.823887  3844 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1124 10:02:23.840886  3844 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 30000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 5000
stepvalue: 9500
stepvalue: 15300
stepvalue: 19500
stepvalue: 22000
stepvalue: 27000
type: "AdaDelta"
I1124 10:02:23.840886  3844 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1124 10:02:23.841886  3844 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1124 10:02:23.841886  3844 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1124 10:02:23.841886  3844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1124 10:02:23.841886  3844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1124 10:02:23.841886  3844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1124 10:02:23.841886  3844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1124 10:02:23.841886  3844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1124 10:02:23.841886  3844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1124 10:02:23.841886  3844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1124 10:02:23.841886  3844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1124 10:02:23.841886  3844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1124 10:02:23.841886  3844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1124 10:02:23.841886  3844 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_8L_Simple_7x7_1.6M"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb_zeropad"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 41
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 43
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 83
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 89
    pad: 3
    kernel_size: 7
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1124 10:02:23.870899  3844 layer_factory.cpp:58] Creating layer cifar
I1124 10:02:23.878887  3844 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb_zeropad
I1124 10:02:23.878887  3844 net.cpp:84] Creating Layer cifar
I1124 10:02:23.878887  3844 net.cpp:380] cifar -> data
I1124 10:02:23.878887  3844 net.cpp:380] cifar -> label
I1124 10:02:23.879890  3844 data_layer.cpp:45] output data size: 100,3,32,32
I1124 10:02:23.883886  3844 net.cpp:122] Setting up cifar
I1124 10:02:23.884886  3844 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1124 10:02:23.884886  3844 net.cpp:129] Top shape: 100 (100)
I1124 10:02:23.884886  3844 net.cpp:137] Memory required for data: 1229200
I1124 10:02:23.884886  3844 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1124 10:02:23.884886  3844 net.cpp:84] Creating Layer label_cifar_1_split
I1124 10:02:23.884886  3844 net.cpp:406] label_cifar_1_split <- label
I1124 10:02:23.884886  3844 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1124 10:02:23.884886  3844 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1124 10:02:23.884886  3844 net.cpp:122] Setting up label_cifar_1_split
I1124 10:02:23.884886  3844 net.cpp:129] Top shape: 100 (100)
I1124 10:02:23.884886  3844 net.cpp:129] Top shape: 100 (100)
I1124 10:02:23.884886  3844 net.cpp:137] Memory required for data: 1230000
I1124 10:02:23.884886  3844 layer_factory.cpp:58] Creating layer conv1
I1124 10:02:23.884886  3844 net.cpp:84] Creating Layer conv1
I1124 10:02:23.884886  3844 net.cpp:406] conv1 <- data
I1124 10:02:23.884886  3844 net.cpp:380] conv1 -> conv1
I1124 10:02:23.885890 14536 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1124 10:02:24.130136  3844 net.cpp:122] Setting up conv1
I1124 10:02:24.130136  3844 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1124 10:02:24.130136  3844 net.cpp:137] Memory required for data: 18023600
I1124 10:02:24.130136  3844 layer_factory.cpp:58] Creating layer bn1
I1124 10:02:24.130136  3844 net.cpp:84] Creating Layer bn1
I1124 10:02:24.130136  3844 net.cpp:406] bn1 <- conv1
I1124 10:02:24.130136  3844 net.cpp:367] bn1 -> conv1 (in-place)
I1124 10:02:24.131135  3844 net.cpp:122] Setting up bn1
I1124 10:02:24.131135  3844 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1124 10:02:24.131135  3844 net.cpp:137] Memory required for data: 34817200
I1124 10:02:24.131135  3844 layer_factory.cpp:58] Creating layer scale1
I1124 10:02:24.131135  3844 net.cpp:84] Creating Layer scale1
I1124 10:02:24.131135  3844 net.cpp:406] scale1 <- conv1
I1124 10:02:24.131135  3844 net.cpp:367] scale1 -> conv1 (in-place)
I1124 10:02:24.131135  3844 layer_factory.cpp:58] Creating layer scale1
I1124 10:02:24.131135  3844 net.cpp:122] Setting up scale1
I1124 10:02:24.131135  3844 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1124 10:02:24.131135  3844 net.cpp:137] Memory required for data: 51610800
I1124 10:02:24.131135  3844 layer_factory.cpp:58] Creating layer relu1
I1124 10:02:24.131135  3844 net.cpp:84] Creating Layer relu1
I1124 10:02:24.131135  3844 net.cpp:406] relu1 <- conv1
I1124 10:02:24.131135  3844 net.cpp:367] relu1 -> conv1 (in-place)
I1124 10:02:24.131135  3844 net.cpp:122] Setting up relu1
I1124 10:02:24.131135  3844 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1124 10:02:24.131135  3844 net.cpp:137] Memory required for data: 68404400
I1124 10:02:24.131135  3844 layer_factory.cpp:58] Creating layer conv2
I1124 10:02:24.131135  3844 net.cpp:84] Creating Layer conv2
I1124 10:02:24.131135  3844 net.cpp:406] conv2 <- conv1
I1124 10:02:24.131135  3844 net.cpp:380] conv2 -> conv2
I1124 10:02:24.132134  3844 net.cpp:122] Setting up conv2
I1124 10:02:24.132134  3844 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1124 10:02:24.132134  3844 net.cpp:137] Memory required for data: 86017200
I1124 10:02:24.132134  3844 layer_factory.cpp:58] Creating layer bn2
I1124 10:02:24.132134  3844 net.cpp:84] Creating Layer bn2
I1124 10:02:24.132134  3844 net.cpp:406] bn2 <- conv2
I1124 10:02:24.132134  3844 net.cpp:367] bn2 -> conv2 (in-place)
I1124 10:02:24.133136  3844 net.cpp:122] Setting up bn2
I1124 10:02:24.133136  3844 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1124 10:02:24.133136  3844 net.cpp:137] Memory required for data: 103630000
I1124 10:02:24.133136  3844 layer_factory.cpp:58] Creating layer scale2
I1124 10:02:24.133136  3844 net.cpp:84] Creating Layer scale2
I1124 10:02:24.133136  3844 net.cpp:406] scale2 <- conv2
I1124 10:02:24.133136  3844 net.cpp:367] scale2 -> conv2 (in-place)
I1124 10:02:24.133136  3844 layer_factory.cpp:58] Creating layer scale2
I1124 10:02:24.133136  3844 net.cpp:122] Setting up scale2
I1124 10:02:24.133136  3844 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1124 10:02:24.133136  3844 net.cpp:137] Memory required for data: 121242800
I1124 10:02:24.133136  3844 layer_factory.cpp:58] Creating layer relu2
I1124 10:02:24.133136  3844 net.cpp:84] Creating Layer relu2
I1124 10:02:24.133136  3844 net.cpp:406] relu2 <- conv2
I1124 10:02:24.133136  3844 net.cpp:367] relu2 -> conv2 (in-place)
I1124 10:02:24.133136  3844 net.cpp:122] Setting up relu2
I1124 10:02:24.133136  3844 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1124 10:02:24.133136  3844 net.cpp:137] Memory required for data: 138855600
I1124 10:02:24.133136  3844 layer_factory.cpp:58] Creating layer conv2_2
I1124 10:02:24.133136  3844 net.cpp:84] Creating Layer conv2_2
I1124 10:02:24.133136  3844 net.cpp:406] conv2_2 <- conv2
I1124 10:02:24.133136  3844 net.cpp:380] conv2_2 -> conv2_2
I1124 10:02:24.135134  3844 net.cpp:122] Setting up conv2_2
I1124 10:02:24.135134  3844 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1124 10:02:24.135134  3844 net.cpp:137] Memory required for data: 167527600
I1124 10:02:24.135134  3844 layer_factory.cpp:58] Creating layer bn2_2
I1124 10:02:24.135134  3844 net.cpp:84] Creating Layer bn2_2
I1124 10:02:24.135134  3844 net.cpp:406] bn2_2 <- conv2_2
I1124 10:02:24.135134  3844 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1124 10:02:24.135134  3844 net.cpp:122] Setting up bn2_2
I1124 10:02:24.135134  3844 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1124 10:02:24.135134  3844 net.cpp:137] Memory required for data: 196199600
I1124 10:02:24.135134  3844 layer_factory.cpp:58] Creating layer scale2_2
I1124 10:02:24.135134  3844 net.cpp:84] Creating Layer scale2_2
I1124 10:02:24.135134  3844 net.cpp:406] scale2_2 <- conv2_2
I1124 10:02:24.135134  3844 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1124 10:02:24.135134  3844 layer_factory.cpp:58] Creating layer scale2_2
I1124 10:02:24.135134  3844 net.cpp:122] Setting up scale2_2
I1124 10:02:24.135134  3844 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1124 10:02:24.135134  3844 net.cpp:137] Memory required for data: 224871600
I1124 10:02:24.135134  3844 layer_factory.cpp:58] Creating layer relu2_2
I1124 10:02:24.135134  3844 net.cpp:84] Creating Layer relu2_2
I1124 10:02:24.135134  3844 net.cpp:406] relu2_2 <- conv2_2
I1124 10:02:24.135134  3844 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1124 10:02:24.135134  3844 net.cpp:122] Setting up relu2_2
I1124 10:02:24.136135  3844 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1124 10:02:24.136135  3844 net.cpp:137] Memory required for data: 253543600
I1124 10:02:24.136135  3844 layer_factory.cpp:58] Creating layer pool2_1
I1124 10:02:24.136135  3844 net.cpp:84] Creating Layer pool2_1
I1124 10:02:24.136135  3844 net.cpp:406] pool2_1 <- conv2_2
I1124 10:02:24.136135  3844 net.cpp:380] pool2_1 -> pool2_1
I1124 10:02:24.136135  3844 net.cpp:122] Setting up pool2_1
I1124 10:02:24.136135  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.136135  3844 net.cpp:137] Memory required for data: 260711600
I1124 10:02:24.136135  3844 layer_factory.cpp:58] Creating layer conv3
I1124 10:02:24.136135  3844 net.cpp:84] Creating Layer conv3
I1124 10:02:24.136135  3844 net.cpp:406] conv3 <- pool2_1
I1124 10:02:24.136135  3844 net.cpp:380] conv3 -> conv3
I1124 10:02:24.138134  3844 net.cpp:122] Setting up conv3
I1124 10:02:24.138134  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.138134  3844 net.cpp:137] Memory required for data: 267879600
I1124 10:02:24.138134  3844 layer_factory.cpp:58] Creating layer bn3
I1124 10:02:24.138134  3844 net.cpp:84] Creating Layer bn3
I1124 10:02:24.138134  3844 net.cpp:406] bn3 <- conv3
I1124 10:02:24.138134  3844 net.cpp:367] bn3 -> conv3 (in-place)
I1124 10:02:24.139145  3844 net.cpp:122] Setting up bn3
I1124 10:02:24.139145  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.139145  3844 net.cpp:137] Memory required for data: 275047600
I1124 10:02:24.139145  3844 layer_factory.cpp:58] Creating layer scale3
I1124 10:02:24.139145  3844 net.cpp:84] Creating Layer scale3
I1124 10:02:24.139145  3844 net.cpp:406] scale3 <- conv3
I1124 10:02:24.139145  3844 net.cpp:367] scale3 -> conv3 (in-place)
I1124 10:02:24.139145  3844 layer_factory.cpp:58] Creating layer scale3
I1124 10:02:24.139145  3844 net.cpp:122] Setting up scale3
I1124 10:02:24.139145  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.139145  3844 net.cpp:137] Memory required for data: 282215600
I1124 10:02:24.139145  3844 layer_factory.cpp:58] Creating layer relu3
I1124 10:02:24.139145  3844 net.cpp:84] Creating Layer relu3
I1124 10:02:24.139145  3844 net.cpp:406] relu3 <- conv3
I1124 10:02:24.139145  3844 net.cpp:367] relu3 -> conv3 (in-place)
I1124 10:02:24.139145  3844 net.cpp:122] Setting up relu3
I1124 10:02:24.139145  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.139145  3844 net.cpp:137] Memory required for data: 289383600
I1124 10:02:24.139145  3844 layer_factory.cpp:58] Creating layer conv4
I1124 10:02:24.139145  3844 net.cpp:84] Creating Layer conv4
I1124 10:02:24.139145  3844 net.cpp:406] conv4 <- conv3
I1124 10:02:24.139145  3844 net.cpp:380] conv4 -> conv4
I1124 10:02:24.141135  3844 net.cpp:122] Setting up conv4
I1124 10:02:24.141135  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.141135  3844 net.cpp:137] Memory required for data: 296551600
I1124 10:02:24.141135  3844 layer_factory.cpp:58] Creating layer bn4
I1124 10:02:24.141135  3844 net.cpp:84] Creating Layer bn4
I1124 10:02:24.141135  3844 net.cpp:406] bn4 <- conv4
I1124 10:02:24.141135  3844 net.cpp:367] bn4 -> conv4 (in-place)
I1124 10:02:24.142135  3844 net.cpp:122] Setting up bn4
I1124 10:02:24.142135  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.142135  3844 net.cpp:137] Memory required for data: 303719600
I1124 10:02:24.142135  3844 layer_factory.cpp:58] Creating layer scale4
I1124 10:02:24.142135  3844 net.cpp:84] Creating Layer scale4
I1124 10:02:24.142135  3844 net.cpp:406] scale4 <- conv4
I1124 10:02:24.142135  3844 net.cpp:367] scale4 -> conv4 (in-place)
I1124 10:02:24.142135  3844 layer_factory.cpp:58] Creating layer scale4
I1124 10:02:24.142135  3844 net.cpp:122] Setting up scale4
I1124 10:02:24.142135  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.142135  3844 net.cpp:137] Memory required for data: 310887600
I1124 10:02:24.142135  3844 layer_factory.cpp:58] Creating layer relu4
I1124 10:02:24.142135  3844 net.cpp:84] Creating Layer relu4
I1124 10:02:24.142135  3844 net.cpp:406] relu4 <- conv4
I1124 10:02:24.142135  3844 net.cpp:367] relu4 -> conv4 (in-place)
I1124 10:02:24.142135  3844 net.cpp:122] Setting up relu4
I1124 10:02:24.142135  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.142135  3844 net.cpp:137] Memory required for data: 318055600
I1124 10:02:24.142135  3844 layer_factory.cpp:58] Creating layer conv4_1
I1124 10:02:24.142135  3844 net.cpp:84] Creating Layer conv4_1
I1124 10:02:24.142135  3844 net.cpp:406] conv4_1 <- conv4
I1124 10:02:24.142135  3844 net.cpp:380] conv4_1 -> conv4_1
I1124 10:02:24.145138  3844 net.cpp:122] Setting up conv4_1
I1124 10:02:24.145138  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.145138  3844 net.cpp:137] Memory required for data: 325223600
I1124 10:02:24.145138  3844 layer_factory.cpp:58] Creating layer bn4_1
I1124 10:02:24.145138  3844 net.cpp:84] Creating Layer bn4_1
I1124 10:02:24.145138  3844 net.cpp:406] bn4_1 <- conv4_1
I1124 10:02:24.145138  3844 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1124 10:02:24.146136  3844 net.cpp:122] Setting up bn4_1
I1124 10:02:24.146136  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.146136  3844 net.cpp:137] Memory required for data: 332391600
I1124 10:02:24.146136  3844 layer_factory.cpp:58] Creating layer scale4_1
I1124 10:02:24.146136  3844 net.cpp:84] Creating Layer scale4_1
I1124 10:02:24.146136  3844 net.cpp:406] scale4_1 <- conv4_1
I1124 10:02:24.146136  3844 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1124 10:02:24.146136  3844 layer_factory.cpp:58] Creating layer scale4_1
I1124 10:02:24.146136  3844 net.cpp:122] Setting up scale4_1
I1124 10:02:24.146136  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.146136  3844 net.cpp:137] Memory required for data: 339559600
I1124 10:02:24.146136  3844 layer_factory.cpp:58] Creating layer relu4_1
I1124 10:02:24.146136  3844 net.cpp:84] Creating Layer relu4_1
I1124 10:02:24.146136  3844 net.cpp:406] relu4_1 <- conv4_1
I1124 10:02:24.146136  3844 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1124 10:02:24.146136  3844 net.cpp:122] Setting up relu4_1
I1124 10:02:24.146136  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.146136  3844 net.cpp:137] Memory required for data: 346727600
I1124 10:02:24.146136  3844 layer_factory.cpp:58] Creating layer conv4_2
I1124 10:02:24.146136  3844 net.cpp:84] Creating Layer conv4_2
I1124 10:02:24.146136  3844 net.cpp:406] conv4_2 <- conv4_1
I1124 10:02:24.146136  3844 net.cpp:380] conv4_2 -> conv4_2
I1124 10:02:24.149149  3844 net.cpp:122] Setting up conv4_2
I1124 10:02:24.149149  3844 net.cpp:129] Top shape: 100 83 16 16 (2124800)
I1124 10:02:24.149149  3844 net.cpp:137] Memory required for data: 355226800
I1124 10:02:24.149149  3844 layer_factory.cpp:58] Creating layer bn4_2
I1124 10:02:24.149149  3844 net.cpp:84] Creating Layer bn4_2
I1124 10:02:24.149149  3844 net.cpp:406] bn4_2 <- conv4_2
I1124 10:02:24.149149  3844 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1124 10:02:24.150149  3844 net.cpp:122] Setting up bn4_2
I1124 10:02:24.150149  3844 net.cpp:129] Top shape: 100 83 16 16 (2124800)
I1124 10:02:24.150149  3844 net.cpp:137] Memory required for data: 363726000
I1124 10:02:24.150149  3844 layer_factory.cpp:58] Creating layer scale4_2
I1124 10:02:24.150149  3844 net.cpp:84] Creating Layer scale4_2
I1124 10:02:24.150149  3844 net.cpp:406] scale4_2 <- conv4_2
I1124 10:02:24.150149  3844 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1124 10:02:24.150149  3844 layer_factory.cpp:58] Creating layer scale4_2
I1124 10:02:24.150149  3844 net.cpp:122] Setting up scale4_2
I1124 10:02:24.150149  3844 net.cpp:129] Top shape: 100 83 16 16 (2124800)
I1124 10:02:24.150149  3844 net.cpp:137] Memory required for data: 372225200
I1124 10:02:24.150149  3844 layer_factory.cpp:58] Creating layer relu4_2
I1124 10:02:24.150149  3844 net.cpp:84] Creating Layer relu4_2
I1124 10:02:24.150149  3844 net.cpp:406] relu4_2 <- conv4_2
I1124 10:02:24.150149  3844 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1124 10:02:24.150149  3844 net.cpp:122] Setting up relu4_2
I1124 10:02:24.150149  3844 net.cpp:129] Top shape: 100 83 16 16 (2124800)
I1124 10:02:24.150149  3844 net.cpp:137] Memory required for data: 380724400
I1124 10:02:24.150149  3844 layer_factory.cpp:58] Creating layer pool4_2
I1124 10:02:24.150149  3844 net.cpp:84] Creating Layer pool4_2
I1124 10:02:24.150149  3844 net.cpp:406] pool4_2 <- conv4_2
I1124 10:02:24.150149  3844 net.cpp:380] pool4_2 -> pool4_2
I1124 10:02:24.150149  3844 net.cpp:122] Setting up pool4_2
I1124 10:02:24.150149  3844 net.cpp:129] Top shape: 100 83 8 8 (531200)
I1124 10:02:24.150149  3844 net.cpp:137] Memory required for data: 382849200
I1124 10:02:24.150149  3844 layer_factory.cpp:58] Creating layer conv12
I1124 10:02:24.150149  3844 net.cpp:84] Creating Layer conv12
I1124 10:02:24.150149  3844 net.cpp:406] conv12 <- pool4_2
I1124 10:02:24.150149  3844 net.cpp:380] conv12 -> conv12
I1124 10:02:24.154135  3844 net.cpp:122] Setting up conv12
I1124 10:02:24.154135  3844 net.cpp:129] Top shape: 100 89 8 8 (569600)
I1124 10:02:24.154135  3844 net.cpp:137] Memory required for data: 385127600
I1124 10:02:24.154135  3844 layer_factory.cpp:58] Creating layer bn_conv12
I1124 10:02:24.154135  3844 net.cpp:84] Creating Layer bn_conv12
I1124 10:02:24.154135  3844 net.cpp:406] bn_conv12 <- conv12
I1124 10:02:24.154135  3844 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1124 10:02:24.154135  3844 net.cpp:122] Setting up bn_conv12
I1124 10:02:24.154135  3844 net.cpp:129] Top shape: 100 89 8 8 (569600)
I1124 10:02:24.154135  3844 net.cpp:137] Memory required for data: 387406000
I1124 10:02:24.154135  3844 layer_factory.cpp:58] Creating layer scale_conv12
I1124 10:02:24.154135  3844 net.cpp:84] Creating Layer scale_conv12
I1124 10:02:24.154135  3844 net.cpp:406] scale_conv12 <- conv12
I1124 10:02:24.154135  3844 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1124 10:02:24.155149  3844 layer_factory.cpp:58] Creating layer scale_conv12
I1124 10:02:24.155149  3844 net.cpp:122] Setting up scale_conv12
I1124 10:02:24.155149  3844 net.cpp:129] Top shape: 100 89 8 8 (569600)
I1124 10:02:24.155149  3844 net.cpp:137] Memory required for data: 389684400
I1124 10:02:24.155149  3844 layer_factory.cpp:58] Creating layer relu_conv12
I1124 10:02:24.155149  3844 net.cpp:84] Creating Layer relu_conv12
I1124 10:02:24.155149  3844 net.cpp:406] relu_conv12 <- conv12
I1124 10:02:24.155149  3844 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1124 10:02:24.155149  3844 net.cpp:122] Setting up relu_conv12
I1124 10:02:24.155149  3844 net.cpp:129] Top shape: 100 89 8 8 (569600)
I1124 10:02:24.155149  3844 net.cpp:137] Memory required for data: 391962800
I1124 10:02:24.155149  3844 layer_factory.cpp:58] Creating layer poolcp6
I1124 10:02:24.155149  3844 net.cpp:84] Creating Layer poolcp6
I1124 10:02:24.155149  3844 net.cpp:406] poolcp6 <- conv12
I1124 10:02:24.155149  3844 net.cpp:380] poolcp6 -> poolcp6
I1124 10:02:24.155149  3844 net.cpp:122] Setting up poolcp6
I1124 10:02:24.155149  3844 net.cpp:129] Top shape: 100 89 1 1 (8900)
I1124 10:02:24.155149  3844 net.cpp:137] Memory required for data: 391998400
I1124 10:02:24.155149  3844 layer_factory.cpp:58] Creating layer ip1
I1124 10:02:24.155149  3844 net.cpp:84] Creating Layer ip1
I1124 10:02:24.155149  3844 net.cpp:406] ip1 <- poolcp6
I1124 10:02:24.155149  3844 net.cpp:380] ip1 -> ip1
I1124 10:02:24.155149  3844 net.cpp:122] Setting up ip1
I1124 10:02:24.155149  3844 net.cpp:129] Top shape: 100 10 (1000)
I1124 10:02:24.155149  3844 net.cpp:137] Memory required for data: 392002400
I1124 10:02:24.155149  3844 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1124 10:02:24.155149  3844 net.cpp:84] Creating Layer ip1_ip1_0_split
I1124 10:02:24.155149  3844 net.cpp:406] ip1_ip1_0_split <- ip1
I1124 10:02:24.155149  3844 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1124 10:02:24.155149  3844 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1124 10:02:24.155149  3844 net.cpp:122] Setting up ip1_ip1_0_split
I1124 10:02:24.155149  3844 net.cpp:129] Top shape: 100 10 (1000)
I1124 10:02:24.155149  3844 net.cpp:129] Top shape: 100 10 (1000)
I1124 10:02:24.155149  3844 net.cpp:137] Memory required for data: 392010400
I1124 10:02:24.155149  3844 layer_factory.cpp:58] Creating layer accuracy_training
I1124 10:02:24.155149  3844 net.cpp:84] Creating Layer accuracy_training
I1124 10:02:24.155149  3844 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1124 10:02:24.155149  3844 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1124 10:02:24.155149  3844 net.cpp:380] accuracy_training -> accuracy_training
I1124 10:02:24.155149  3844 net.cpp:122] Setting up accuracy_training
I1124 10:02:24.155149  3844 net.cpp:129] Top shape: (1)
I1124 10:02:24.155149  3844 net.cpp:137] Memory required for data: 392010404
I1124 10:02:24.155149  3844 layer_factory.cpp:58] Creating layer loss
I1124 10:02:24.155149  3844 net.cpp:84] Creating Layer loss
I1124 10:02:24.155149  3844 net.cpp:406] loss <- ip1_ip1_0_split_1
I1124 10:02:24.155149  3844 net.cpp:406] loss <- label_cifar_1_split_1
I1124 10:02:24.155149  3844 net.cpp:380] loss -> loss
I1124 10:02:24.155149  3844 layer_factory.cpp:58] Creating layer loss
I1124 10:02:24.156148  3844 net.cpp:122] Setting up loss
I1124 10:02:24.156148  3844 net.cpp:129] Top shape: (1)
I1124 10:02:24.156148  3844 net.cpp:132]     with loss weight 1
I1124 10:02:24.156148  3844 net.cpp:137] Memory required for data: 392010408
I1124 10:02:24.156148  3844 net.cpp:198] loss needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:200] accuracy_training does not need backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] ip1 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] poolcp6 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] relu_conv12 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] scale_conv12 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] bn_conv12 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] conv12 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] pool4_2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] relu4_2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] scale4_2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] bn4_2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] conv4_2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] relu4_1 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] scale4_1 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] bn4_1 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] conv4_1 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] relu4 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] scale4 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] bn4 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] conv4 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] relu3 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] scale3 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] bn3 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] conv3 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] pool2_1 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] relu2_2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] scale2_2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] bn2_2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] conv2_2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] relu2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] scale2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] bn2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] conv2 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] relu1 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] scale1 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] bn1 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:198] conv1 needs backward computation.
I1124 10:02:24.156148  3844 net.cpp:200] label_cifar_1_split does not need backward computation.
I1124 10:02:24.156148  3844 net.cpp:200] cifar does not need backward computation.
I1124 10:02:24.156148  3844 net.cpp:242] This network produces output accuracy_training
I1124 10:02:24.156148  3844 net.cpp:242] This network produces output loss
I1124 10:02:24.156148  3844 net.cpp:255] Network initialization done.
I1124 10:02:24.157150  3844 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1124 10:02:24.157150  3844 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1124 10:02:24.157150  3844 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1124 10:02:24.157150  3844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1124 10:02:24.157150  3844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1124 10:02:24.157150  3844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1124 10:02:24.157150  3844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1124 10:02:24.157150  3844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1124 10:02:24.157150  3844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1124 10:02:24.157150  3844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1124 10:02:24.157150  3844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1124 10:02:24.157150  3844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1124 10:02:24.157150  3844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1124 10:02:24.157150  3844 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_8L_Simple_7x7_1.6M"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb_zeropad"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 41
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 43
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 70
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 83
    bias_term: true
    pad: 3
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 89
    pad: 3
    kernel_size: 7
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1124 10:02:24.157150  3844 layer_factory.cpp:58] Creating layer cifar
I1124 10:02:24.163138  3844 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb_zeropad
I1124 10:02:24.163138  3844 net.cpp:84] Creating Layer cifar
I1124 10:02:24.163138  3844 net.cpp:380] cifar -> data
I1124 10:02:24.163138  3844 net.cpp:380] cifar -> label
I1124 10:02:24.163138  3844 data_layer.cpp:45] output data size: 100,3,32,32
I1124 10:02:24.169139  3844 net.cpp:122] Setting up cifar
I1124 10:02:24.169139  3844 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1124 10:02:24.169139  3844 net.cpp:129] Top shape: 100 (100)
I1124 10:02:24.169139  3844 net.cpp:137] Memory required for data: 1229200
I1124 10:02:24.169139  3844 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1124 10:02:24.169139  3844 net.cpp:84] Creating Layer label_cifar_1_split
I1124 10:02:24.169139  3844 net.cpp:406] label_cifar_1_split <- label
I1124 10:02:24.169139  3844 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1124 10:02:24.169139  3844 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1124 10:02:24.169139  3844 net.cpp:122] Setting up label_cifar_1_split
I1124 10:02:24.170140  3844 net.cpp:129] Top shape: 100 (100)
I1124 10:02:24.170140  3844 net.cpp:129] Top shape: 100 (100)
I1124 10:02:24.170140  3844 net.cpp:137] Memory required for data: 1230000
I1124 10:02:24.170140  3844 layer_factory.cpp:58] Creating layer conv1
I1124 10:02:24.170140  3844 net.cpp:84] Creating Layer conv1
I1124 10:02:24.170140  3844 net.cpp:406] conv1 <- data
I1124 10:02:24.170140  3844 net.cpp:380] conv1 -> conv1
I1124 10:02:24.171141   136 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1124 10:02:24.172142  3844 net.cpp:122] Setting up conv1
I1124 10:02:24.172142  3844 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1124 10:02:24.172142  3844 net.cpp:137] Memory required for data: 18023600
I1124 10:02:24.172142  3844 layer_factory.cpp:58] Creating layer bn1
I1124 10:02:24.172142  3844 net.cpp:84] Creating Layer bn1
I1124 10:02:24.172142  3844 net.cpp:406] bn1 <- conv1
I1124 10:02:24.172142  3844 net.cpp:367] bn1 -> conv1 (in-place)
I1124 10:02:24.172142  3844 net.cpp:122] Setting up bn1
I1124 10:02:24.173137  3844 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1124 10:02:24.173137  3844 net.cpp:137] Memory required for data: 34817200
I1124 10:02:24.173137  3844 layer_factory.cpp:58] Creating layer scale1
I1124 10:02:24.173137  3844 net.cpp:84] Creating Layer scale1
I1124 10:02:24.173137  3844 net.cpp:406] scale1 <- conv1
I1124 10:02:24.173137  3844 net.cpp:367] scale1 -> conv1 (in-place)
I1124 10:02:24.173137  3844 layer_factory.cpp:58] Creating layer scale1
I1124 10:02:24.173137  3844 net.cpp:122] Setting up scale1
I1124 10:02:24.173137  3844 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1124 10:02:24.173137  3844 net.cpp:137] Memory required for data: 51610800
I1124 10:02:24.173137  3844 layer_factory.cpp:58] Creating layer relu1
I1124 10:02:24.173137  3844 net.cpp:84] Creating Layer relu1
I1124 10:02:24.173137  3844 net.cpp:406] relu1 <- conv1
I1124 10:02:24.173137  3844 net.cpp:367] relu1 -> conv1 (in-place)
I1124 10:02:24.174139  3844 net.cpp:122] Setting up relu1
I1124 10:02:24.174139  3844 net.cpp:129] Top shape: 100 41 32 32 (4198400)
I1124 10:02:24.174139  3844 net.cpp:137] Memory required for data: 68404400
I1124 10:02:24.174139  3844 layer_factory.cpp:58] Creating layer conv2
I1124 10:02:24.174139  3844 net.cpp:84] Creating Layer conv2
I1124 10:02:24.174139  3844 net.cpp:406] conv2 <- conv1
I1124 10:02:24.174139  3844 net.cpp:380] conv2 -> conv2
I1124 10:02:24.176138  3844 net.cpp:122] Setting up conv2
I1124 10:02:24.176138  3844 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1124 10:02:24.176138  3844 net.cpp:137] Memory required for data: 86017200
I1124 10:02:24.176138  3844 layer_factory.cpp:58] Creating layer bn2
I1124 10:02:24.176138  3844 net.cpp:84] Creating Layer bn2
I1124 10:02:24.177139  3844 net.cpp:406] bn2 <- conv2
I1124 10:02:24.177139  3844 net.cpp:367] bn2 -> conv2 (in-place)
I1124 10:02:24.177139  3844 net.cpp:122] Setting up bn2
I1124 10:02:24.177139  3844 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1124 10:02:24.177139  3844 net.cpp:137] Memory required for data: 103630000
I1124 10:02:24.177139  3844 layer_factory.cpp:58] Creating layer scale2
I1124 10:02:24.177139  3844 net.cpp:84] Creating Layer scale2
I1124 10:02:24.177139  3844 net.cpp:406] scale2 <- conv2
I1124 10:02:24.177139  3844 net.cpp:367] scale2 -> conv2 (in-place)
I1124 10:02:24.177139  3844 layer_factory.cpp:58] Creating layer scale2
I1124 10:02:24.177139  3844 net.cpp:122] Setting up scale2
I1124 10:02:24.177139  3844 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1124 10:02:24.177139  3844 net.cpp:137] Memory required for data: 121242800
I1124 10:02:24.177139  3844 layer_factory.cpp:58] Creating layer relu2
I1124 10:02:24.177139  3844 net.cpp:84] Creating Layer relu2
I1124 10:02:24.177139  3844 net.cpp:406] relu2 <- conv2
I1124 10:02:24.177139  3844 net.cpp:367] relu2 -> conv2 (in-place)
I1124 10:02:24.178140  3844 net.cpp:122] Setting up relu2
I1124 10:02:24.179144  3844 net.cpp:129] Top shape: 100 43 32 32 (4403200)
I1124 10:02:24.179144  3844 net.cpp:137] Memory required for data: 138855600
I1124 10:02:24.179144  3844 layer_factory.cpp:58] Creating layer conv2_2
I1124 10:02:24.179144  3844 net.cpp:84] Creating Layer conv2_2
I1124 10:02:24.179144  3844 net.cpp:406] conv2_2 <- conv2
I1124 10:02:24.179144  3844 net.cpp:380] conv2_2 -> conv2_2
I1124 10:02:24.182137  3844 net.cpp:122] Setting up conv2_2
I1124 10:02:24.182137  3844 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1124 10:02:24.182137  3844 net.cpp:137] Memory required for data: 167527600
I1124 10:02:24.183138  3844 layer_factory.cpp:58] Creating layer bn2_2
I1124 10:02:24.183138  3844 net.cpp:84] Creating Layer bn2_2
I1124 10:02:24.183138  3844 net.cpp:406] bn2_2 <- conv2_2
I1124 10:02:24.183138  3844 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1124 10:02:24.183138  3844 net.cpp:122] Setting up bn2_2
I1124 10:02:24.183138  3844 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1124 10:02:24.183138  3844 net.cpp:137] Memory required for data: 196199600
I1124 10:02:24.183138  3844 layer_factory.cpp:58] Creating layer scale2_2
I1124 10:02:24.183138  3844 net.cpp:84] Creating Layer scale2_2
I1124 10:02:24.183138  3844 net.cpp:406] scale2_2 <- conv2_2
I1124 10:02:24.183138  3844 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1124 10:02:24.183138  3844 layer_factory.cpp:58] Creating layer scale2_2
I1124 10:02:24.183138  3844 net.cpp:122] Setting up scale2_2
I1124 10:02:24.183138  3844 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1124 10:02:24.183138  3844 net.cpp:137] Memory required for data: 224871600
I1124 10:02:24.184139  3844 layer_factory.cpp:58] Creating layer relu2_2
I1124 10:02:24.184139  3844 net.cpp:84] Creating Layer relu2_2
I1124 10:02:24.184139  3844 net.cpp:406] relu2_2 <- conv2_2
I1124 10:02:24.184139  3844 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1124 10:02:24.184139  3844 net.cpp:122] Setting up relu2_2
I1124 10:02:24.184139  3844 net.cpp:129] Top shape: 100 70 32 32 (7168000)
I1124 10:02:24.184139  3844 net.cpp:137] Memory required for data: 253543600
I1124 10:02:24.184139  3844 layer_factory.cpp:58] Creating layer pool2_1
I1124 10:02:24.184139  3844 net.cpp:84] Creating Layer pool2_1
I1124 10:02:24.184139  3844 net.cpp:406] pool2_1 <- conv2_2
I1124 10:02:24.184139  3844 net.cpp:380] pool2_1 -> pool2_1
I1124 10:02:24.184139  3844 net.cpp:122] Setting up pool2_1
I1124 10:02:24.184139  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.184139  3844 net.cpp:137] Memory required for data: 260711600
I1124 10:02:24.184139  3844 layer_factory.cpp:58] Creating layer conv3
I1124 10:02:24.184139  3844 net.cpp:84] Creating Layer conv3
I1124 10:02:24.184139  3844 net.cpp:406] conv3 <- pool2_1
I1124 10:02:24.184139  3844 net.cpp:380] conv3 -> conv3
I1124 10:02:24.187136  3844 net.cpp:122] Setting up conv3
I1124 10:02:24.187136  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.187136  3844 net.cpp:137] Memory required for data: 267879600
I1124 10:02:24.187136  3844 layer_factory.cpp:58] Creating layer bn3
I1124 10:02:24.187136  3844 net.cpp:84] Creating Layer bn3
I1124 10:02:24.187136  3844 net.cpp:406] bn3 <- conv3
I1124 10:02:24.187136  3844 net.cpp:367] bn3 -> conv3 (in-place)
I1124 10:02:24.187136  3844 net.cpp:122] Setting up bn3
I1124 10:02:24.187136  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.187136  3844 net.cpp:137] Memory required for data: 275047600
I1124 10:02:24.187136  3844 layer_factory.cpp:58] Creating layer scale3
I1124 10:02:24.187136  3844 net.cpp:84] Creating Layer scale3
I1124 10:02:24.187136  3844 net.cpp:406] scale3 <- conv3
I1124 10:02:24.188140  3844 net.cpp:367] scale3 -> conv3 (in-place)
I1124 10:02:24.188140  3844 layer_factory.cpp:58] Creating layer scale3
I1124 10:02:24.188140  3844 net.cpp:122] Setting up scale3
I1124 10:02:24.188140  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.188140  3844 net.cpp:137] Memory required for data: 282215600
I1124 10:02:24.188140  3844 layer_factory.cpp:58] Creating layer relu3
I1124 10:02:24.188140  3844 net.cpp:84] Creating Layer relu3
I1124 10:02:24.188140  3844 net.cpp:406] relu3 <- conv3
I1124 10:02:24.188140  3844 net.cpp:367] relu3 -> conv3 (in-place)
I1124 10:02:24.188140  3844 net.cpp:122] Setting up relu3
I1124 10:02:24.188140  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.188140  3844 net.cpp:137] Memory required for data: 289383600
I1124 10:02:24.188140  3844 layer_factory.cpp:58] Creating layer conv4
I1124 10:02:24.188140  3844 net.cpp:84] Creating Layer conv4
I1124 10:02:24.188140  3844 net.cpp:406] conv4 <- conv3
I1124 10:02:24.188140  3844 net.cpp:380] conv4 -> conv4
I1124 10:02:24.192136  3844 net.cpp:122] Setting up conv4
I1124 10:02:24.192136  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.192136  3844 net.cpp:137] Memory required for data: 296551600
I1124 10:02:24.192136  3844 layer_factory.cpp:58] Creating layer bn4
I1124 10:02:24.192136  3844 net.cpp:84] Creating Layer bn4
I1124 10:02:24.192136  3844 net.cpp:406] bn4 <- conv4
I1124 10:02:24.192136  3844 net.cpp:367] bn4 -> conv4 (in-place)
I1124 10:02:24.192136  3844 net.cpp:122] Setting up bn4
I1124 10:02:24.192136  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.192136  3844 net.cpp:137] Memory required for data: 303719600
I1124 10:02:24.193140  3844 layer_factory.cpp:58] Creating layer scale4
I1124 10:02:24.193140  3844 net.cpp:84] Creating Layer scale4
I1124 10:02:24.193140  3844 net.cpp:406] scale4 <- conv4
I1124 10:02:24.193140  3844 net.cpp:367] scale4 -> conv4 (in-place)
I1124 10:02:24.193140  3844 layer_factory.cpp:58] Creating layer scale4
I1124 10:02:24.193140  3844 net.cpp:122] Setting up scale4
I1124 10:02:24.193140  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.193140  3844 net.cpp:137] Memory required for data: 310887600
I1124 10:02:24.193140  3844 layer_factory.cpp:58] Creating layer relu4
I1124 10:02:24.193140  3844 net.cpp:84] Creating Layer relu4
I1124 10:02:24.193140  3844 net.cpp:406] relu4 <- conv4
I1124 10:02:24.193140  3844 net.cpp:367] relu4 -> conv4 (in-place)
I1124 10:02:24.193140  3844 net.cpp:122] Setting up relu4
I1124 10:02:24.193140  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.193140  3844 net.cpp:137] Memory required for data: 318055600
I1124 10:02:24.193140  3844 layer_factory.cpp:58] Creating layer conv4_1
I1124 10:02:24.193140  3844 net.cpp:84] Creating Layer conv4_1
I1124 10:02:24.193140  3844 net.cpp:406] conv4_1 <- conv4
I1124 10:02:24.193140  3844 net.cpp:380] conv4_1 -> conv4_1
I1124 10:02:24.197137  3844 net.cpp:122] Setting up conv4_1
I1124 10:02:24.197137  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.197137  3844 net.cpp:137] Memory required for data: 325223600
I1124 10:02:24.197137  3844 layer_factory.cpp:58] Creating layer bn4_1
I1124 10:02:24.197137  3844 net.cpp:84] Creating Layer bn4_1
I1124 10:02:24.197137  3844 net.cpp:406] bn4_1 <- conv4_1
I1124 10:02:24.197137  3844 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1124 10:02:24.197137  3844 net.cpp:122] Setting up bn4_1
I1124 10:02:24.197137  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.197137  3844 net.cpp:137] Memory required for data: 332391600
I1124 10:02:24.197137  3844 layer_factory.cpp:58] Creating layer scale4_1
I1124 10:02:24.197137  3844 net.cpp:84] Creating Layer scale4_1
I1124 10:02:24.197137  3844 net.cpp:406] scale4_1 <- conv4_1
I1124 10:02:24.197137  3844 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1124 10:02:24.197137  3844 layer_factory.cpp:58] Creating layer scale4_1
I1124 10:02:24.197137  3844 net.cpp:122] Setting up scale4_1
I1124 10:02:24.197137  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.197137  3844 net.cpp:137] Memory required for data: 339559600
I1124 10:02:24.197137  3844 layer_factory.cpp:58] Creating layer relu4_1
I1124 10:02:24.197137  3844 net.cpp:84] Creating Layer relu4_1
I1124 10:02:24.197137  3844 net.cpp:406] relu4_1 <- conv4_1
I1124 10:02:24.197137  3844 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1124 10:02:24.198137  3844 net.cpp:122] Setting up relu4_1
I1124 10:02:24.198137  3844 net.cpp:129] Top shape: 100 70 16 16 (1792000)
I1124 10:02:24.198137  3844 net.cpp:137] Memory required for data: 346727600
I1124 10:02:24.198137  3844 layer_factory.cpp:58] Creating layer conv4_2
I1124 10:02:24.198137  3844 net.cpp:84] Creating Layer conv4_2
I1124 10:02:24.198137  3844 net.cpp:406] conv4_2 <- conv4_1
I1124 10:02:24.198137  3844 net.cpp:380] conv4_2 -> conv4_2
I1124 10:02:24.201645  3844 net.cpp:122] Setting up conv4_2
I1124 10:02:24.201645  3844 net.cpp:129] Top shape: 100 83 16 16 (2124800)
I1124 10:02:24.201645  3844 net.cpp:137] Memory required for data: 355226800
I1124 10:02:24.201645  3844 layer_factory.cpp:58] Creating layer bn4_2
I1124 10:02:24.201645  3844 net.cpp:84] Creating Layer bn4_2
I1124 10:02:24.201645  3844 net.cpp:406] bn4_2 <- conv4_2
I1124 10:02:24.201645  3844 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1124 10:02:24.201645  3844 net.cpp:122] Setting up bn4_2
I1124 10:02:24.201645  3844 net.cpp:129] Top shape: 100 83 16 16 (2124800)
I1124 10:02:24.201645  3844 net.cpp:137] Memory required for data: 363726000
I1124 10:02:24.201645  3844 layer_factory.cpp:58] Creating layer scale4_2
I1124 10:02:24.201645  3844 net.cpp:84] Creating Layer scale4_2
I1124 10:02:24.201645  3844 net.cpp:406] scale4_2 <- conv4_2
I1124 10:02:24.201645  3844 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1124 10:02:24.201645  3844 layer_factory.cpp:58] Creating layer scale4_2
I1124 10:02:24.202147  3844 net.cpp:122] Setting up scale4_2
I1124 10:02:24.202147  3844 net.cpp:129] Top shape: 100 83 16 16 (2124800)
I1124 10:02:24.202147  3844 net.cpp:137] Memory required for data: 372225200
I1124 10:02:24.202147  3844 layer_factory.cpp:58] Creating layer relu4_2
I1124 10:02:24.202147  3844 net.cpp:84] Creating Layer relu4_2
I1124 10:02:24.202147  3844 net.cpp:406] relu4_2 <- conv4_2
I1124 10:02:24.202147  3844 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1124 10:02:24.202656  3844 net.cpp:122] Setting up relu4_2
I1124 10:02:24.202656  3844 net.cpp:129] Top shape: 100 83 16 16 (2124800)
I1124 10:02:24.202656  3844 net.cpp:137] Memory required for data: 380724400
I1124 10:02:24.202656  3844 layer_factory.cpp:58] Creating layer pool4_2
I1124 10:02:24.202656  3844 net.cpp:84] Creating Layer pool4_2
I1124 10:02:24.202656  3844 net.cpp:406] pool4_2 <- conv4_2
I1124 10:02:24.202656  3844 net.cpp:380] pool4_2 -> pool4_2
I1124 10:02:24.202656  3844 net.cpp:122] Setting up pool4_2
I1124 10:02:24.202656  3844 net.cpp:129] Top shape: 100 83 8 8 (531200)
I1124 10:02:24.202656  3844 net.cpp:137] Memory required for data: 382849200
I1124 10:02:24.202656  3844 layer_factory.cpp:58] Creating layer conv12
I1124 10:02:24.202656  3844 net.cpp:84] Creating Layer conv12
I1124 10:02:24.202656  3844 net.cpp:406] conv12 <- pool4_2
I1124 10:02:24.202656  3844 net.cpp:380] conv12 -> conv12
I1124 10:02:24.208158  3844 net.cpp:122] Setting up conv12
I1124 10:02:24.208158  3844 net.cpp:129] Top shape: 100 89 8 8 (569600)
I1124 10:02:24.208158  3844 net.cpp:137] Memory required for data: 385127600
I1124 10:02:24.208158  3844 layer_factory.cpp:58] Creating layer bn_conv12
I1124 10:02:24.208158  3844 net.cpp:84] Creating Layer bn_conv12
I1124 10:02:24.208158  3844 net.cpp:406] bn_conv12 <- conv12
I1124 10:02:24.208158  3844 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1124 10:02:24.208158  3844 net.cpp:122] Setting up bn_conv12
I1124 10:02:24.208158  3844 net.cpp:129] Top shape: 100 89 8 8 (569600)
I1124 10:02:24.208158  3844 net.cpp:137] Memory required for data: 387406000
I1124 10:02:24.208658  3844 layer_factory.cpp:58] Creating layer scale_conv12
I1124 10:02:24.208658  3844 net.cpp:84] Creating Layer scale_conv12
I1124 10:02:24.208658  3844 net.cpp:406] scale_conv12 <- conv12
I1124 10:02:24.208658  3844 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1124 10:02:24.208658  3844 layer_factory.cpp:58] Creating layer scale_conv12
I1124 10:02:24.208658  3844 net.cpp:122] Setting up scale_conv12
I1124 10:02:24.208658  3844 net.cpp:129] Top shape: 100 89 8 8 (569600)
I1124 10:02:24.208658  3844 net.cpp:137] Memory required for data: 389684400
I1124 10:02:24.208658  3844 layer_factory.cpp:58] Creating layer relu_conv12
I1124 10:02:24.208658  3844 net.cpp:84] Creating Layer relu_conv12
I1124 10:02:24.208658  3844 net.cpp:406] relu_conv12 <- conv12
I1124 10:02:24.208658  3844 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1124 10:02:24.209650  3844 net.cpp:122] Setting up relu_conv12
I1124 10:02:24.209650  3844 net.cpp:129] Top shape: 100 89 8 8 (569600)
I1124 10:02:24.209650  3844 net.cpp:137] Memory required for data: 391962800
I1124 10:02:24.209650  3844 layer_factory.cpp:58] Creating layer poolcp6
I1124 10:02:24.209650  3844 net.cpp:84] Creating Layer poolcp6
I1124 10:02:24.209650  3844 net.cpp:406] poolcp6 <- conv12
I1124 10:02:24.209650  3844 net.cpp:380] poolcp6 -> poolcp6
I1124 10:02:24.209650  3844 net.cpp:122] Setting up poolcp6
I1124 10:02:24.209650  3844 net.cpp:129] Top shape: 100 89 1 1 (8900)
I1124 10:02:24.209650  3844 net.cpp:137] Memory required for data: 391998400
I1124 10:02:24.209650  3844 layer_factory.cpp:58] Creating layer ip1
I1124 10:02:24.209650  3844 net.cpp:84] Creating Layer ip1
I1124 10:02:24.209650  3844 net.cpp:406] ip1 <- poolcp6
I1124 10:02:24.209650  3844 net.cpp:380] ip1 -> ip1
I1124 10:02:24.210144  3844 net.cpp:122] Setting up ip1
I1124 10:02:24.210144  3844 net.cpp:129] Top shape: 100 10 (1000)
I1124 10:02:24.210144  3844 net.cpp:137] Memory required for data: 392002400
I1124 10:02:24.210144  3844 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1124 10:02:24.210144  3844 net.cpp:84] Creating Layer ip1_ip1_0_split
I1124 10:02:24.210144  3844 net.cpp:406] ip1_ip1_0_split <- ip1
I1124 10:02:24.210144  3844 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1124 10:02:24.210144  3844 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1124 10:02:24.210144  3844 net.cpp:122] Setting up ip1_ip1_0_split
I1124 10:02:24.210144  3844 net.cpp:129] Top shape: 100 10 (1000)
I1124 10:02:24.210144  3844 net.cpp:129] Top shape: 100 10 (1000)
I1124 10:02:24.210144  3844 net.cpp:137] Memory required for data: 392010400
I1124 10:02:24.210144  3844 layer_factory.cpp:58] Creating layer accuracy
I1124 10:02:24.210144  3844 net.cpp:84] Creating Layer accuracy
I1124 10:02:24.210144  3844 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1124 10:02:24.210144  3844 net.cpp:406] accuracy <- label_cifar_1_split_0
I1124 10:02:24.210144  3844 net.cpp:380] accuracy -> accuracy
I1124 10:02:24.210144  3844 net.cpp:122] Setting up accuracy
I1124 10:02:24.210144  3844 net.cpp:129] Top shape: (1)
I1124 10:02:24.210144  3844 net.cpp:137] Memory required for data: 392010404
I1124 10:02:24.210144  3844 layer_factory.cpp:58] Creating layer loss
I1124 10:02:24.210144  3844 net.cpp:84] Creating Layer loss
I1124 10:02:24.210144  3844 net.cpp:406] loss <- ip1_ip1_0_split_1
I1124 10:02:24.210144  3844 net.cpp:406] loss <- label_cifar_1_split_1
I1124 10:02:24.210144  3844 net.cpp:380] loss -> loss
I1124 10:02:24.210144  3844 layer_factory.cpp:58] Creating layer loss
I1124 10:02:24.210644  3844 net.cpp:122] Setting up loss
I1124 10:02:24.210644  3844 net.cpp:129] Top shape: (1)
I1124 10:02:24.210644  3844 net.cpp:132]     with loss weight 1
I1124 10:02:24.210644  3844 net.cpp:137] Memory required for data: 392010408
I1124 10:02:24.210644  3844 net.cpp:198] loss needs backward computation.
I1124 10:02:24.210644  3844 net.cpp:200] accuracy does not need backward computation.
I1124 10:02:24.210644  3844 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1124 10:02:24.210644  3844 net.cpp:198] ip1 needs backward computation.
I1124 10:02:24.210644  3844 net.cpp:198] poolcp6 needs backward computation.
I1124 10:02:24.210644  3844 net.cpp:198] relu_conv12 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] scale_conv12 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] bn_conv12 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] conv12 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] pool4_2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] relu4_2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] scale4_2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] bn4_2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] conv4_2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] relu4_1 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] scale4_1 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] bn4_1 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] conv4_1 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] relu4 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] scale4 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] bn4 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] conv4 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] relu3 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] scale3 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] bn3 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] conv3 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] pool2_1 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] relu2_2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] scale2_2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] bn2_2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] conv2_2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] relu2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] scale2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] bn2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] conv2 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] relu1 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] scale1 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] bn1 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:198] conv1 needs backward computation.
I1124 10:02:24.211143  3844 net.cpp:200] label_cifar_1_split does not need backward computation.
I1124 10:02:24.211143  3844 net.cpp:200] cifar does not need backward computation.
I1124 10:02:24.211143  3844 net.cpp:242] This network produces output accuracy
I1124 10:02:24.211143  3844 net.cpp:242] This network produces output loss
I1124 10:02:24.211143  3844 net.cpp:255] Network initialization done.
I1124 10:02:24.211143  3844 solver.cpp:56] Solver scaffolding done.
I1124 10:02:24.213642  3844 caffe.cpp:249] Starting Optimization
I1124 10:02:24.213642  3844 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_8L_Simple_7x7_1.6M
I1124 10:02:24.213642  3844 solver.cpp:273] Learning Rate Policy: multistep
I1124 10:02:24.216516  3844 solver.cpp:330] Iteration 0, Testing net (#0)
I1124 10:02:24.218514  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:02:28.245484   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:02:28.408521  3844 solver.cpp:397]     Test net output #0: accuracy = 0.1002
I1124 10:02:28.408521  3844 solver.cpp:397]     Test net output #1: loss = 78.5854 (* 1 = 78.5854 loss)
I1124 10:02:28.559558  3844 solver.cpp:218] Iteration 0 (0 iter/s, 4.3463s/100 iters), loss = 3.37862
I1124 10:02:28.559558  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.13
I1124 10:02:28.560560  3844 solver.cpp:237]     Train net output #1: loss = 3.37862 (* 1 = 3.37862 loss)
I1124 10:02:28.560560  3844 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1124 10:02:40.421932  3844 solver.cpp:218] Iteration 100 (8.43084 iter/s, 11.8612s/100 iters), loss = 1.69071
I1124 10:02:40.421932  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1124 10:02:40.421932  3844 solver.cpp:237]     Train net output #1: loss = 1.69071 (* 1 = 1.69071 loss)
I1124 10:02:40.421932  3844 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1124 10:02:52.313946  3844 solver.cpp:218] Iteration 200 (8.4097 iter/s, 11.891s/100 iters), loss = 1.78651
I1124 10:02:52.313946  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1124 10:02:52.313946  3844 solver.cpp:237]     Train net output #1: loss = 1.78651 (* 1 = 1.78651 loss)
I1124 10:02:52.313946  3844 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1124 10:03:04.261018  3844 solver.cpp:218] Iteration 300 (8.37057 iter/s, 11.9466s/100 iters), loss = 1.44204
I1124 10:03:04.261018  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1124 10:03:04.261018  3844 solver.cpp:237]     Train net output #1: loss = 1.44204 (* 1 = 1.44204 loss)
I1124 10:03:04.261018  3844 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1124 10:03:16.219852  3844 solver.cpp:218] Iteration 400 (8.36239 iter/s, 11.9583s/100 iters), loss = 1.35338
I1124 10:03:16.219852  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1124 10:03:16.219852  3844 solver.cpp:237]     Train net output #1: loss = 1.35338 (* 1 = 1.35338 loss)
I1124 10:03:16.219852  3844 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1124 10:03:27.724102 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:03:28.204460  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_500.caffemodel
I1124 10:03:28.251248  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_500.solverstate
I1124 10:03:28.296264  3844 solver.cpp:330] Iteration 500, Testing net (#0)
I1124 10:03:28.296264  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:03:32.346418   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:03:32.510924  3844 solver.cpp:397]     Test net output #0: accuracy = 0.4764
I1124 10:03:32.510924  3844 solver.cpp:397]     Test net output #1: loss = 1.43156 (* 1 = 1.43156 loss)
I1124 10:03:32.628993  3844 solver.cpp:218] Iteration 500 (6.09439 iter/s, 16.4085s/100 iters), loss = 1.35564
I1124 10:03:32.628993  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1124 10:03:32.628993  3844 solver.cpp:237]     Train net output #1: loss = 1.35564 (* 1 = 1.35564 loss)
I1124 10:03:32.628993  3844 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1124 10:03:44.718739  3844 solver.cpp:218] Iteration 600 (8.2719 iter/s, 12.0891s/100 iters), loss = 1.20567
I1124 10:03:44.718739  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1124 10:03:44.718739  3844 solver.cpp:237]     Train net output #1: loss = 1.20567 (* 1 = 1.20567 loss)
I1124 10:03:44.718739  3844 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1124 10:03:56.787328  3844 solver.cpp:218] Iteration 700 (8.28637 iter/s, 12.068s/100 iters), loss = 1.11189
I1124 10:03:56.787819  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1124 10:03:56.787819  3844 solver.cpp:237]     Train net output #1: loss = 1.11189 (* 1 = 1.11189 loss)
I1124 10:03:56.787819  3844 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1124 10:04:08.877457  3844 solver.cpp:218] Iteration 800 (8.27185 iter/s, 12.0892s/100 iters), loss = 0.979093
I1124 10:04:08.877457  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1124 10:04:08.877457  3844 solver.cpp:237]     Train net output #1: loss = 0.979093 (* 1 = 0.979093 loss)
I1124 10:04:08.877457  3844 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1124 10:04:20.986482  3844 solver.cpp:218] Iteration 900 (8.25874 iter/s, 12.1084s/100 iters), loss = 0.915977
I1124 10:04:20.986482  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1124 10:04:20.986482  3844 solver.cpp:237]     Train net output #1: loss = 0.915977 (* 1 = 0.915977 loss)
I1124 10:04:20.986482  3844 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1124 10:04:32.450812 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:04:32.928874  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_1000.caffemodel
I1124 10:04:32.969373  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_1000.solverstate
I1124 10:04:32.987872  3844 solver.cpp:330] Iteration 1000, Testing net (#0)
I1124 10:04:32.988373  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:04:36.996891   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:04:37.161005  3844 solver.cpp:397]     Test net output #0: accuracy = 0.5618
I1124 10:04:37.161005  3844 solver.cpp:397]     Test net output #1: loss = 1.248 (* 1 = 1.248 loss)
I1124 10:04:37.278802  3844 solver.cpp:218] Iteration 1000 (6.13817 iter/s, 16.2915s/100 iters), loss = 1.0339
I1124 10:04:37.278802  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1124 10:04:37.278802  3844 solver.cpp:237]     Train net output #1: loss = 1.0339 (* 1 = 1.0339 loss)
I1124 10:04:37.278802  3844 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1124 10:04:49.336104  3844 solver.cpp:218] Iteration 1100 (8.2939 iter/s, 12.057s/100 iters), loss = 0.887084
I1124 10:04:49.336104  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1124 10:04:49.336104  3844 solver.cpp:237]     Train net output #1: loss = 0.887084 (* 1 = 0.887084 loss)
I1124 10:04:49.336104  3844 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1124 10:05:01.389865  3844 solver.cpp:218] Iteration 1200 (8.29681 iter/s, 12.0528s/100 iters), loss = 0.87268
I1124 10:05:01.389865  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1124 10:05:01.389865  3844 solver.cpp:237]     Train net output #1: loss = 0.87268 (* 1 = 0.87268 loss)
I1124 10:05:01.389865  3844 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1124 10:05:13.442080  3844 solver.cpp:218] Iteration 1300 (8.29716 iter/s, 12.0523s/100 iters), loss = 0.797734
I1124 10:05:13.442080  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1124 10:05:13.442080  3844 solver.cpp:237]     Train net output #1: loss = 0.797734 (* 1 = 0.797734 loss)
I1124 10:05:13.442080  3844 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1124 10:05:25.510797  3844 solver.cpp:218] Iteration 1400 (8.28628 iter/s, 12.0681s/100 iters), loss = 0.810603
I1124 10:05:25.510797  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1124 10:05:25.510797  3844 solver.cpp:237]     Train net output #1: loss = 0.810603 (* 1 = 0.810603 loss)
I1124 10:05:25.510797  3844 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1124 10:05:37.039851 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:05:37.525861  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_1500.caffemodel
I1124 10:05:37.564349  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_1500.solverstate
I1124 10:05:37.604890  3844 solver.cpp:330] Iteration 1500, Testing net (#0)
I1124 10:05:37.604890  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:05:41.695519   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:05:41.866076  3844 solver.cpp:397]     Test net output #0: accuracy = 0.6855
I1124 10:05:41.866076  3844 solver.cpp:397]     Test net output #1: loss = 0.918592 (* 1 = 0.918592 loss)
I1124 10:05:41.985105  3844 solver.cpp:218] Iteration 1500 (6.0705 iter/s, 16.4731s/100 iters), loss = 0.742083
I1124 10:05:41.985105  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1124 10:05:41.985105  3844 solver.cpp:237]     Train net output #1: loss = 0.742083 (* 1 = 0.742083 loss)
I1124 10:05:41.985105  3844 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1124 10:05:54.315557  3844 solver.cpp:218] Iteration 1600 (8.11036 iter/s, 12.3299s/100 iters), loss = 0.616604
I1124 10:05:54.315557  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1124 10:05:54.315557  3844 solver.cpp:237]     Train net output #1: loss = 0.616604 (* 1 = 0.616604 loss)
I1124 10:05:54.315557  3844 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1124 10:06:06.555704  3844 solver.cpp:218] Iteration 1700 (8.17022 iter/s, 12.2396s/100 iters), loss = 0.679025
I1124 10:06:06.555704  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1124 10:06:06.555704  3844 solver.cpp:237]     Train net output #1: loss = 0.679025 (* 1 = 0.679025 loss)
I1124 10:06:06.555704  3844 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1124 10:06:18.765627  3844 solver.cpp:218] Iteration 1800 (8.19094 iter/s, 12.2086s/100 iters), loss = 0.708941
I1124 10:06:18.765627  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1124 10:06:18.765627  3844 solver.cpp:237]     Train net output #1: loss = 0.708941 (* 1 = 0.708941 loss)
I1124 10:06:18.765627  3844 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1124 10:06:30.958823  3844 solver.cpp:218] Iteration 1900 (8.20167 iter/s, 12.1926s/100 iters), loss = 0.703862
I1124 10:06:30.958823  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1124 10:06:30.958823  3844 solver.cpp:237]     Train net output #1: loss = 0.703862 (* 1 = 0.703862 loss)
I1124 10:06:30.958823  3844 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1124 10:06:42.427470 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:06:42.905875  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_2000.caffemodel
I1124 10:06:42.945873  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_2000.solverstate
I1124 10:06:42.964874  3844 solver.cpp:330] Iteration 2000, Testing net (#0)
I1124 10:06:42.965373  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:06:46.981171   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:06:47.145123  3844 solver.cpp:397]     Test net output #0: accuracy = 0.6696
I1124 10:06:47.145123  3844 solver.cpp:397]     Test net output #1: loss = 0.946824 (* 1 = 0.946824 loss)
I1124 10:06:47.262125  3844 solver.cpp:218] Iteration 2000 (6.13371 iter/s, 16.3033s/100 iters), loss = 0.621814
I1124 10:06:47.263124  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1124 10:06:47.263124  3844 solver.cpp:237]     Train net output #1: loss = 0.621814 (* 1 = 0.621814 loss)
I1124 10:06:47.263124  3844 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1124 10:06:59.330929  3844 solver.cpp:218] Iteration 2100 (8.28685 iter/s, 12.0673s/100 iters), loss = 0.598164
I1124 10:06:59.330929  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1124 10:06:59.330929  3844 solver.cpp:237]     Train net output #1: loss = 0.598164 (* 1 = 0.598164 loss)
I1124 10:06:59.330929  3844 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1124 10:07:11.382438  3844 solver.cpp:218] Iteration 2200 (8.29774 iter/s, 12.0515s/100 iters), loss = 0.636371
I1124 10:07:11.382438  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1124 10:07:11.382438  3844 solver.cpp:237]     Train net output #1: loss = 0.636371 (* 1 = 0.636371 loss)
I1124 10:07:11.382438  3844 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1124 10:07:23.435256  3844 solver.cpp:218] Iteration 2300 (8.29745 iter/s, 12.0519s/100 iters), loss = 0.604214
I1124 10:07:23.435256  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1124 10:07:23.435256  3844 solver.cpp:237]     Train net output #1: loss = 0.604214 (* 1 = 0.604214 loss)
I1124 10:07:23.435256  3844 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1124 10:07:35.503304  3844 solver.cpp:218] Iteration 2400 (8.28672 iter/s, 12.0675s/100 iters), loss = 0.66484
I1124 10:07:35.503304  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1124 10:07:35.503304  3844 solver.cpp:237]     Train net output #1: loss = 0.66484 (* 1 = 0.66484 loss)
I1124 10:07:35.503304  3844 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1124 10:07:46.999897 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:07:47.473039  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_2500.caffemodel
I1124 10:07:47.512043  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_2500.solverstate
I1124 10:07:47.553063  3844 solver.cpp:330] Iteration 2500, Testing net (#0)
I1124 10:07:47.553063  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:07:51.605171   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:07:51.769232  3844 solver.cpp:397]     Test net output #0: accuracy = 0.6124
I1124 10:07:51.769232  3844 solver.cpp:397]     Test net output #1: loss = 1.09975 (* 1 = 1.09975 loss)
I1124 10:07:51.886257  3844 solver.cpp:218] Iteration 2500 (6.10406 iter/s, 16.3825s/100 iters), loss = 0.521967
I1124 10:07:51.886257  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1124 10:07:51.886257  3844 solver.cpp:237]     Train net output #1: loss = 0.521967 (* 1 = 0.521967 loss)
I1124 10:07:51.886257  3844 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1124 10:08:04.013363  3844 solver.cpp:218] Iteration 2600 (8.24672 iter/s, 12.126s/100 iters), loss = 0.563614
I1124 10:08:04.013363  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1124 10:08:04.013363  3844 solver.cpp:237]     Train net output #1: loss = 0.563614 (* 1 = 0.563614 loss)
I1124 10:08:04.013363  3844 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1124 10:08:16.368929  3844 solver.cpp:218] Iteration 2700 (8.09383 iter/s, 12.3551s/100 iters), loss = 0.596886
I1124 10:08:16.369415  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1124 10:08:16.369415  3844 solver.cpp:237]     Train net output #1: loss = 0.596886 (* 1 = 0.596886 loss)
I1124 10:08:16.369415  3844 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1124 10:08:28.627106  3844 solver.cpp:218] Iteration 2800 (8.15857 iter/s, 12.257s/100 iters), loss = 0.56319
I1124 10:08:28.627106  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1124 10:08:28.627106  3844 solver.cpp:237]     Train net output #1: loss = 0.56319 (* 1 = 0.56319 loss)
I1124 10:08:28.627106  3844 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1124 10:08:40.891803  3844 solver.cpp:218] Iteration 2900 (8.15375 iter/s, 12.2643s/100 iters), loss = 0.652481
I1124 10:08:40.891803  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1124 10:08:40.891803  3844 solver.cpp:237]     Train net output #1: loss = 0.652481 (* 1 = 0.652481 loss)
I1124 10:08:40.891803  3844 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1124 10:08:52.553936 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:08:53.040436  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_3000.caffemodel
I1124 10:08:53.081434  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_3000.solverstate
I1124 10:08:53.101450  3844 solver.cpp:330] Iteration 3000, Testing net (#0)
I1124 10:08:53.101934  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:08:57.183461   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:08:57.349951  3844 solver.cpp:397]     Test net output #0: accuracy = 0.7129
I1124 10:08:57.349951  3844 solver.cpp:397]     Test net output #1: loss = 0.818365 (* 1 = 0.818365 loss)
I1124 10:08:57.468961  3844 solver.cpp:218] Iteration 3000 (6.03261 iter/s, 16.5766s/100 iters), loss = 0.531561
I1124 10:08:57.469460  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1124 10:08:57.469460  3844 solver.cpp:237]     Train net output #1: loss = 0.531561 (* 1 = 0.531561 loss)
I1124 10:08:57.469460  3844 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1124 10:09:09.623646  3844 solver.cpp:218] Iteration 3100 (8.22799 iter/s, 12.1536s/100 iters), loss = 0.4846
I1124 10:09:09.623646  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1124 10:09:09.623646  3844 solver.cpp:237]     Train net output #1: loss = 0.4846 (* 1 = 0.4846 loss)
I1124 10:09:09.623646  3844 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1124 10:09:21.708403  3844 solver.cpp:218] Iteration 3200 (8.27505 iter/s, 12.0845s/100 iters), loss = 0.56368
I1124 10:09:21.708403  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1124 10:09:21.708403  3844 solver.cpp:237]     Train net output #1: loss = 0.56368 (* 1 = 0.56368 loss)
I1124 10:09:21.708403  3844 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1124 10:09:33.832278  3844 solver.cpp:218] Iteration 3300 (8.24875 iter/s, 12.123s/100 iters), loss = 0.590091
I1124 10:09:33.832278  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1124 10:09:33.832278  3844 solver.cpp:237]     Train net output #1: loss = 0.590091 (* 1 = 0.590091 loss)
I1124 10:09:33.832278  3844 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1124 10:09:46.217041  3844 solver.cpp:218] Iteration 3400 (8.07495 iter/s, 12.384s/100 iters), loss = 0.552802
I1124 10:09:46.217041  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1124 10:09:46.217041  3844 solver.cpp:237]     Train net output #1: loss = 0.552802 (* 1 = 0.552802 loss)
I1124 10:09:46.217041  3844 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1124 10:09:57.908030 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:09:58.392030  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_3500.caffemodel
I1124 10:09:58.432530  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_3500.solverstate
I1124 10:09:58.479029  3844 solver.cpp:330] Iteration 3500, Testing net (#0)
I1124 10:09:58.479029  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:10:02.630031   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:10:02.802031  3844 solver.cpp:397]     Test net output #0: accuracy = 0.6588
I1124 10:10:02.802031  3844 solver.cpp:397]     Test net output #1: loss = 0.990718 (* 1 = 0.990718 loss)
I1124 10:10:02.922529  3844 solver.cpp:218] Iteration 3500 (5.98624 iter/s, 16.705s/100 iters), loss = 0.449021
I1124 10:10:02.922529  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1124 10:10:02.922529  3844 solver.cpp:237]     Train net output #1: loss = 0.449021 (* 1 = 0.449021 loss)
I1124 10:10:02.922529  3844 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1124 10:10:15.316202  3844 solver.cpp:218] Iteration 3600 (8.06911 iter/s, 12.3929s/100 iters), loss = 0.452361
I1124 10:10:15.316202  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1124 10:10:15.316202  3844 solver.cpp:237]     Train net output #1: loss = 0.452361 (* 1 = 0.452361 loss)
I1124 10:10:15.316202  3844 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1124 10:10:27.586016  3844 solver.cpp:218] Iteration 3700 (8.15053 iter/s, 12.2691s/100 iters), loss = 0.60108
I1124 10:10:27.586016  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1124 10:10:27.586016  3844 solver.cpp:237]     Train net output #1: loss = 0.60108 (* 1 = 0.60108 loss)
I1124 10:10:27.586016  3844 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1124 10:10:39.892516  3844 solver.cpp:218] Iteration 3800 (8.12612 iter/s, 12.306s/100 iters), loss = 0.580805
I1124 10:10:39.892516  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1124 10:10:39.892516  3844 solver.cpp:237]     Train net output #1: loss = 0.580805 (* 1 = 0.580805 loss)
I1124 10:10:39.892516  3844 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1124 10:10:52.254030  3844 solver.cpp:218] Iteration 3900 (8.09025 iter/s, 12.3606s/100 iters), loss = 0.589909
I1124 10:10:52.254030  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1124 10:10:52.254030  3844 solver.cpp:237]     Train net output #1: loss = 0.589909 (* 1 = 0.589909 loss)
I1124 10:10:52.254030  3844 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1124 10:11:03.869057 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:11:04.356060  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_4000.caffemodel
I1124 10:11:04.397558  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_4000.solverstate
I1124 10:11:04.418560  3844 solver.cpp:330] Iteration 4000, Testing net (#0)
I1124 10:11:04.418560  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:11:08.538980   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:11:08.707468  3844 solver.cpp:397]     Test net output #0: accuracy = 0.6337
I1124 10:11:08.707468  3844 solver.cpp:397]     Test net output #1: loss = 1.08304 (* 1 = 1.08304 loss)
I1124 10:11:08.826975  3844 solver.cpp:218] Iteration 4000 (6.03412 iter/s, 16.5724s/100 iters), loss = 0.5054
I1124 10:11:08.826975  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1124 10:11:08.826975  3844 solver.cpp:237]     Train net output #1: loss = 0.5054 (* 1 = 0.5054 loss)
I1124 10:11:08.826975  3844 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1124 10:11:21.191742  3844 solver.cpp:218] Iteration 4100 (8.08807 iter/s, 12.3639s/100 iters), loss = 0.501659
I1124 10:11:21.191742  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1124 10:11:21.191742  3844 solver.cpp:237]     Train net output #1: loss = 0.501659 (* 1 = 0.501659 loss)
I1124 10:11:21.191742  3844 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1124 10:11:33.400861  3844 solver.cpp:218] Iteration 4200 (8.19096 iter/s, 12.2086s/100 iters), loss = 0.533888
I1124 10:11:33.400861  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1124 10:11:33.400861  3844 solver.cpp:237]     Train net output #1: loss = 0.533888 (* 1 = 0.533888 loss)
I1124 10:11:33.400861  3844 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1124 10:11:45.681593  3844 solver.cpp:218] Iteration 4300 (8.14344 iter/s, 12.2798s/100 iters), loss = 0.553286
I1124 10:11:45.681593  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1124 10:11:45.681593  3844 solver.cpp:237]     Train net output #1: loss = 0.553286 (* 1 = 0.553286 loss)
I1124 10:11:45.681593  3844 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1124 10:11:57.906942  3844 solver.cpp:218] Iteration 4400 (8.17997 iter/s, 12.225s/100 iters), loss = 0.391681
I1124 10:11:57.906942  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1124 10:11:57.906942  3844 solver.cpp:237]     Train net output #1: loss = 0.391681 (* 1 = 0.391681 loss)
I1124 10:11:57.906942  3844 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1124 10:12:09.603130 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:12:10.090287  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_4500.caffemodel
I1124 10:12:10.131287  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_4500.solverstate
I1124 10:12:10.163830  3844 solver.cpp:330] Iteration 4500, Testing net (#0)
I1124 10:12:10.163830  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:12:14.317832   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:12:14.485836  3844 solver.cpp:397]     Test net output #0: accuracy = 0.7399
I1124 10:12:14.486332  3844 solver.cpp:397]     Test net output #1: loss = 0.772571 (* 1 = 0.772571 loss)
I1124 10:12:14.606330  3844 solver.cpp:218] Iteration 4500 (5.98849 iter/s, 16.6987s/100 iters), loss = 0.371471
I1124 10:12:14.606330  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1124 10:12:14.606330  3844 solver.cpp:237]     Train net output #1: loss = 0.371471 (* 1 = 0.371471 loss)
I1124 10:12:14.606330  3844 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1124 10:12:27.009054  3844 solver.cpp:218] Iteration 4600 (8.06338 iter/s, 12.4017s/100 iters), loss = 0.431024
I1124 10:12:27.009054  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1124 10:12:27.009054  3844 solver.cpp:237]     Train net output #1: loss = 0.431024 (* 1 = 0.431024 loss)
I1124 10:12:27.009054  3844 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1124 10:12:39.232182  3844 solver.cpp:218] Iteration 4700 (8.18177 iter/s, 12.2223s/100 iters), loss = 0.526356
I1124 10:12:39.232182  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1124 10:12:39.232182  3844 solver.cpp:237]     Train net output #1: loss = 0.526356 (* 1 = 0.526356 loss)
I1124 10:12:39.232182  3844 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1124 10:12:51.471877  3844 solver.cpp:218] Iteration 4800 (8.17059 iter/s, 12.239s/100 iters), loss = 0.48402
I1124 10:12:51.471877  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1124 10:12:51.471877  3844 solver.cpp:237]     Train net output #1: loss = 0.48402 (* 1 = 0.48402 loss)
I1124 10:12:51.471877  3844 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1124 10:13:03.592793  3844 solver.cpp:218] Iteration 4900 (8.25057 iter/s, 12.1204s/100 iters), loss = 0.46509
I1124 10:13:03.592793  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1124 10:13:03.592793  3844 solver.cpp:237]     Train net output #1: loss = 0.46509 (* 1 = 0.46509 loss)
I1124 10:13:03.592793  3844 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1124 10:13:15.394889 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:13:15.889380  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_5000.caffemodel
I1124 10:13:15.932880  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_5000.solverstate
I1124 10:13:15.955381  3844 solver.cpp:330] Iteration 5000, Testing net (#0)
I1124 10:13:15.955381  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:13:20.124439   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:13:20.296438  3844 solver.cpp:397]     Test net output #0: accuracy = 0.557
I1124 10:13:20.296438  3844 solver.cpp:397]     Test net output #1: loss = 1.42644 (* 1 = 1.42644 loss)
I1124 10:13:20.417449  3844 solver.cpp:218] Iteration 5000 (5.94392 iter/s, 16.8239s/100 iters), loss = 0.400995
I1124 10:13:20.417449  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1124 10:13:20.417449  3844 solver.cpp:237]     Train net output #1: loss = 0.400995 (* 1 = 0.400995 loss)
I1124 10:13:20.417449  3844 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I1124 10:13:20.417449  3844 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1124 10:13:32.862371  3844 solver.cpp:218] Iteration 5100 (8.03583 iter/s, 12.4443s/100 iters), loss = 0.299217
I1124 10:13:32.862371  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1124 10:13:32.862371  3844 solver.cpp:237]     Train net output #1: loss = 0.299217 (* 1 = 0.299217 loss)
I1124 10:13:32.862371  3844 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1124 10:13:45.121484  3844 solver.cpp:218] Iteration 5200 (8.15749 iter/s, 12.2587s/100 iters), loss = 0.387818
I1124 10:13:45.121484  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1124 10:13:45.121984  3844 solver.cpp:237]     Train net output #1: loss = 0.387818 (* 1 = 0.387818 loss)
I1124 10:13:45.121984  3844 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1124 10:13:57.328966  3844 solver.cpp:218] Iteration 5300 (8.19213 iter/s, 12.2068s/100 iters), loss = 0.433911
I1124 10:13:57.329468  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1124 10:13:57.329468  3844 solver.cpp:237]     Train net output #1: loss = 0.433911 (* 1 = 0.433911 loss)
I1124 10:13:57.329468  3844 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1124 10:14:09.572429  3844 solver.cpp:218] Iteration 5400 (8.16816 iter/s, 12.2427s/100 iters), loss = 0.286205
I1124 10:14:09.572929  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1124 10:14:09.572929  3844 solver.cpp:237]     Train net output #1: loss = 0.286205 (* 1 = 0.286205 loss)
I1124 10:14:09.572929  3844 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1124 10:14:21.258476 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:14:21.756476  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_5500.caffemodel
I1124 10:14:21.796975  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_5500.solverstate
I1124 10:14:21.855975  3844 solver.cpp:330] Iteration 5500, Testing net (#0)
I1124 10:14:21.855975  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:14:25.961977   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:14:26.132977  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8644
I1124 10:14:26.132977  3844 solver.cpp:397]     Test net output #1: loss = 0.397109 (* 1 = 0.397109 loss)
I1124 10:14:26.252477  3844 solver.cpp:218] Iteration 5500 (5.99553 iter/s, 16.6791s/100 iters), loss = 0.236739
I1124 10:14:26.252477  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1124 10:14:26.252477  3844 solver.cpp:237]     Train net output #1: loss = 0.236739 (* 1 = 0.236739 loss)
I1124 10:14:26.252477  3844 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1124 10:14:38.449838  3844 solver.cpp:218] Iteration 5600 (8.19908 iter/s, 12.1965s/100 iters), loss = 0.287247
I1124 10:14:38.449838  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1124 10:14:38.449838  3844 solver.cpp:237]     Train net output #1: loss = 0.287247 (* 1 = 0.287247 loss)
I1124 10:14:38.449838  3844 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1124 10:14:50.648453  3844 solver.cpp:218] Iteration 5700 (8.19798 iter/s, 12.1981s/100 iters), loss = 0.328638
I1124 10:14:50.648453  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1124 10:14:50.648453  3844 solver.cpp:237]     Train net output #1: loss = 0.328638 (* 1 = 0.328638 loss)
I1124 10:14:50.648453  3844 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1124 10:15:02.854198  3844 solver.cpp:218] Iteration 5800 (8.19329 iter/s, 12.2051s/100 iters), loss = 0.3261
I1124 10:15:02.854198  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1124 10:15:02.854198  3844 solver.cpp:237]     Train net output #1: loss = 0.3261 (* 1 = 0.3261 loss)
I1124 10:15:02.854198  3844 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1124 10:15:15.058404  3844 solver.cpp:218] Iteration 5900 (8.1945 iter/s, 12.2033s/100 iters), loss = 0.224437
I1124 10:15:15.058404  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:15:15.058404  3844 solver.cpp:237]     Train net output #1: loss = 0.224437 (* 1 = 0.224437 loss)
I1124 10:15:15.058404  3844 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1124 10:15:26.673679 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:15:27.158772  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_6000.caffemodel
I1124 10:15:27.202365  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_6000.solverstate
I1124 10:15:27.221876  3844 solver.cpp:330] Iteration 6000, Testing net (#0)
I1124 10:15:27.222370  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:15:31.321362   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:15:31.490361  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8647
I1124 10:15:31.490361  3844 solver.cpp:397]     Test net output #1: loss = 0.396701 (* 1 = 0.396701 loss)
I1124 10:15:31.609376  3844 solver.cpp:218] Iteration 6000 (6.04212 iter/s, 16.5505s/100 iters), loss = 0.234025
I1124 10:15:31.609376  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1124 10:15:31.609376  3844 solver.cpp:237]     Train net output #1: loss = 0.234025 (* 1 = 0.234025 loss)
I1124 10:15:31.609875  3844 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1124 10:15:43.816635  3844 solver.cpp:218] Iteration 6100 (8.19239 iter/s, 12.2064s/100 iters), loss = 0.308885
I1124 10:15:43.816635  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:15:43.816635  3844 solver.cpp:237]     Train net output #1: loss = 0.308885 (* 1 = 0.308885 loss)
I1124 10:15:43.816635  3844 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1124 10:15:56.021234  3844 solver.cpp:218] Iteration 6200 (8.19396 iter/s, 12.2041s/100 iters), loss = 0.253419
I1124 10:15:56.021733  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:15:56.021733  3844 solver.cpp:237]     Train net output #1: loss = 0.253419 (* 1 = 0.253419 loss)
I1124 10:15:56.021733  3844 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1124 10:16:08.211711  3844 solver.cpp:218] Iteration 6300 (8.20388 iter/s, 12.1894s/100 iters), loss = 0.295886
I1124 10:16:08.211711  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1124 10:16:08.211711  3844 solver.cpp:237]     Train net output #1: loss = 0.295886 (* 1 = 0.295886 loss)
I1124 10:16:08.211711  3844 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1124 10:16:20.633102  3844 solver.cpp:218] Iteration 6400 (8.05078 iter/s, 12.4212s/100 iters), loss = 0.197138
I1124 10:16:20.633604  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:16:20.633604  3844 solver.cpp:237]     Train net output #1: loss = 0.197138 (* 1 = 0.197138 loss)
I1124 10:16:20.633604  3844 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1124 10:16:32.250701 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:16:32.734699  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_6500.caffemodel
I1124 10:16:32.776197  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_6500.solverstate
I1124 10:16:32.846698  3844 solver.cpp:330] Iteration 6500, Testing net (#0)
I1124 10:16:32.847198  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:16:37.015198   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:16:37.185199  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8723
I1124 10:16:37.185701  3844 solver.cpp:397]     Test net output #1: loss = 0.375442 (* 1 = 0.375442 loss)
I1124 10:16:37.307198  3844 solver.cpp:218] Iteration 6500 (5.99774 iter/s, 16.673s/100 iters), loss = 0.164774
I1124 10:16:37.307198  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:16:37.307198  3844 solver.cpp:237]     Train net output #1: loss = 0.164774 (* 1 = 0.164774 loss)
I1124 10:16:37.307198  3844 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1124 10:16:49.796211  3844 solver.cpp:218] Iteration 6600 (8.00754 iter/s, 12.4882s/100 iters), loss = 0.197265
I1124 10:16:49.796211  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:16:49.796211  3844 solver.cpp:237]     Train net output #1: loss = 0.197265 (* 1 = 0.197265 loss)
I1124 10:16:49.796211  3844 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1124 10:17:02.296064  3844 solver.cpp:218] Iteration 6700 (8.00032 iter/s, 12.4995s/100 iters), loss = 0.263723
I1124 10:17:02.296064  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1124 10:17:02.296064  3844 solver.cpp:237]     Train net output #1: loss = 0.263723 (* 1 = 0.263723 loss)
I1124 10:17:02.296064  3844 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1124 10:17:14.791533  3844 solver.cpp:218] Iteration 6800 (8.00343 iter/s, 12.4946s/100 iters), loss = 0.278397
I1124 10:17:14.791533  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1124 10:17:14.791533  3844 solver.cpp:237]     Train net output #1: loss = 0.278397 (* 1 = 0.278397 loss)
I1124 10:17:14.791533  3844 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1124 10:17:27.279695  3844 solver.cpp:218] Iteration 6900 (8.00798 iter/s, 12.4875s/100 iters), loss = 0.15841
I1124 10:17:27.279695  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:17:27.279695  3844 solver.cpp:237]     Train net output #1: loss = 0.15841 (* 1 = 0.15841 loss)
I1124 10:17:27.279695  3844 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1124 10:17:39.148579 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:17:39.645135  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_7000.caffemodel
I1124 10:17:39.685624  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_7000.solverstate
I1124 10:17:39.707123  3844 solver.cpp:330] Iteration 7000, Testing net (#0)
I1124 10:17:39.707123  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:17:43.868005   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:17:44.037505  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8752
I1124 10:17:44.037505  3844 solver.cpp:397]     Test net output #1: loss = 0.371331 (* 1 = 0.371331 loss)
I1124 10:17:44.159504  3844 solver.cpp:218] Iteration 7000 (5.92451 iter/s, 16.879s/100 iters), loss = 0.127877
I1124 10:17:44.159504  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:17:44.159504  3844 solver.cpp:237]     Train net output #1: loss = 0.127877 (* 1 = 0.127877 loss)
I1124 10:17:44.159504  3844 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1124 10:17:56.638998  3844 solver.cpp:218] Iteration 7100 (8.0138 iter/s, 12.4785s/100 iters), loss = 0.184537
I1124 10:17:56.638998  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:17:56.638998  3844 solver.cpp:237]     Train net output #1: loss = 0.184537 (* 1 = 0.184537 loss)
I1124 10:17:56.638998  3844 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1124 10:18:09.128747  3844 solver.cpp:218] Iteration 7200 (8.00686 iter/s, 12.4893s/100 iters), loss = 0.249266
I1124 10:18:09.128747  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1124 10:18:09.128747  3844 solver.cpp:237]     Train net output #1: loss = 0.249266 (* 1 = 0.249266 loss)
I1124 10:18:09.128747  3844 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1124 10:18:21.405624  3844 solver.cpp:218] Iteration 7300 (8.14603 iter/s, 12.2759s/100 iters), loss = 0.179211
I1124 10:18:21.405624  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:18:21.405624  3844 solver.cpp:237]     Train net output #1: loss = 0.179211 (* 1 = 0.179211 loss)
I1124 10:18:21.405624  3844 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1124 10:18:33.639411  3844 solver.cpp:218] Iteration 7400 (8.17436 iter/s, 12.2334s/100 iters), loss = 0.195098
I1124 10:18:33.639411  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1124 10:18:33.639411  3844 solver.cpp:237]     Train net output #1: loss = 0.195098 (* 1 = 0.195098 loss)
I1124 10:18:33.639411  3844 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1124 10:18:45.264662 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:18:45.751660  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_7500.caffemodel
I1124 10:18:45.795660  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_7500.solverstate
I1124 10:18:45.837661  3844 solver.cpp:330] Iteration 7500, Testing net (#0)
I1124 10:18:45.837661  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:18:49.953677   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:18:50.122170  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8723
I1124 10:18:50.122170  3844 solver.cpp:397]     Test net output #1: loss = 0.376996 (* 1 = 0.376996 loss)
I1124 10:18:50.245163  3844 solver.cpp:218] Iteration 7500 (6.02239 iter/s, 16.6047s/100 iters), loss = 0.149854
I1124 10:18:50.245163  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:18:50.245163  3844 solver.cpp:237]     Train net output #1: loss = 0.149854 (* 1 = 0.149854 loss)
I1124 10:18:50.245163  3844 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1124 10:19:02.517709  3844 solver.cpp:218] Iteration 7600 (8.14877 iter/s, 12.2718s/100 iters), loss = 0.197484
I1124 10:19:02.517709  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:19:02.517709  3844 solver.cpp:237]     Train net output #1: loss = 0.197484 (* 1 = 0.197484 loss)
I1124 10:19:02.517709  3844 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1124 10:19:14.750452  3844 solver.cpp:218] Iteration 7700 (8.17506 iter/s, 12.2323s/100 iters), loss = 0.203106
I1124 10:19:14.750452  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:19:14.750452  3844 solver.cpp:237]     Train net output #1: loss = 0.203106 (* 1 = 0.203106 loss)
I1124 10:19:14.750452  3844 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1124 10:19:27.095870  3844 solver.cpp:218] Iteration 7800 (8.10058 iter/s, 12.3448s/100 iters), loss = 0.264249
I1124 10:19:27.095870  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1124 10:19:27.095870  3844 solver.cpp:237]     Train net output #1: loss = 0.264249 (* 1 = 0.264249 loss)
I1124 10:19:27.095870  3844 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1124 10:19:39.333942  3844 solver.cpp:218] Iteration 7900 (8.17175 iter/s, 12.2373s/100 iters), loss = 0.151908
I1124 10:19:39.333942  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:19:39.333942  3844 solver.cpp:237]     Train net output #1: loss = 0.151908 (* 1 = 0.151908 loss)
I1124 10:19:39.333942  3844 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1124 10:19:50.969202 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:19:51.455201  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_8000.caffemodel
I1124 10:19:51.496201  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_8000.solverstate
I1124 10:19:51.516201  3844 solver.cpp:330] Iteration 8000, Testing net (#0)
I1124 10:19:51.516201  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:19:55.636216   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:19:55.805702  3844 solver.cpp:397]     Test net output #0: accuracy = 0.878
I1124 10:19:55.805702  3844 solver.cpp:397]     Test net output #1: loss = 0.370458 (* 1 = 0.370458 loss)
I1124 10:19:55.923702  3844 solver.cpp:218] Iteration 8000 (6.02813 iter/s, 16.5889s/100 iters), loss = 0.218885
I1124 10:19:55.923702  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:19:55.923702  3844 solver.cpp:237]     Train net output #1: loss = 0.218885 (* 1 = 0.218885 loss)
I1124 10:19:55.923702  3844 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1124 10:20:08.209677  3844 solver.cpp:218] Iteration 8100 (8.1399 iter/s, 12.2852s/100 iters), loss = 0.215797
I1124 10:20:08.209677  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:20:08.209677  3844 solver.cpp:237]     Train net output #1: loss = 0.215797 (* 1 = 0.215797 loss)
I1124 10:20:08.209677  3844 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1124 10:20:20.576544  3844 solver.cpp:218] Iteration 8200 (8.0865 iter/s, 12.3663s/100 iters), loss = 0.218759
I1124 10:20:20.576544  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1124 10:20:20.576544  3844 solver.cpp:237]     Train net output #1: loss = 0.218758 (* 1 = 0.218758 loss)
I1124 10:20:20.576544  3844 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1124 10:20:32.997769  3844 solver.cpp:218] Iteration 8300 (8.05116 iter/s, 12.4206s/100 iters), loss = 0.174591
I1124 10:20:32.998270  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:20:32.998270  3844 solver.cpp:237]     Train net output #1: loss = 0.174591 (* 1 = 0.174591 loss)
I1124 10:20:32.998270  3844 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1124 10:20:45.241025  3844 solver.cpp:218] Iteration 8400 (8.16845 iter/s, 12.2422s/100 iters), loss = 0.151526
I1124 10:20:45.241025  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:20:45.241025  3844 solver.cpp:237]     Train net output #1: loss = 0.151526 (* 1 = 0.151526 loss)
I1124 10:20:45.241025  3844 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1124 10:20:56.861435 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:20:57.345934  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_8500.caffemodel
I1124 10:20:57.384934  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_8500.solverstate
I1124 10:20:57.428434  3844 solver.cpp:330] Iteration 8500, Testing net (#0)
I1124 10:20:57.428434  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:21:01.552446   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:21:01.720937  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8798
I1124 10:21:01.721436  3844 solver.cpp:397]     Test net output #1: loss = 0.36237 (* 1 = 0.36237 loss)
I1124 10:21:01.840435  3844 solver.cpp:218] Iteration 8500 (6.02454 iter/s, 16.5988s/100 iters), loss = 0.157159
I1124 10:21:01.840435  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:21:01.840935  3844 solver.cpp:237]     Train net output #1: loss = 0.157159 (* 1 = 0.157159 loss)
I1124 10:21:01.840935  3844 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1124 10:21:14.082136  3844 solver.cpp:218] Iteration 8600 (8.1695 iter/s, 12.2407s/100 iters), loss = 0.152741
I1124 10:21:14.082136  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:21:14.082136  3844 solver.cpp:237]     Train net output #1: loss = 0.152741 (* 1 = 0.152741 loss)
I1124 10:21:14.082136  3844 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1124 10:21:26.320439  3844 solver.cpp:218] Iteration 8700 (8.17125 iter/s, 12.238s/100 iters), loss = 0.243285
I1124 10:21:26.320439  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1124 10:21:26.320941  3844 solver.cpp:237]     Train net output #1: loss = 0.243284 (* 1 = 0.243284 loss)
I1124 10:21:26.320941  3844 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1124 10:21:38.561123  3844 solver.cpp:218] Iteration 8800 (8.17005 iter/s, 12.2398s/100 iters), loss = 0.197967
I1124 10:21:38.561123  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1124 10:21:38.561123  3844 solver.cpp:237]     Train net output #1: loss = 0.197967 (* 1 = 0.197967 loss)
I1124 10:21:38.561123  3844 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1124 10:21:50.784716  3844 solver.cpp:218] Iteration 8900 (8.18141 iter/s, 12.2228s/100 iters), loss = 0.138332
I1124 10:21:50.784716  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:21:50.784716  3844 solver.cpp:237]     Train net output #1: loss = 0.138332 (* 1 = 0.138332 loss)
I1124 10:21:50.784716  3844 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1124 10:22:02.403559 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:22:02.888597  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_9000.caffemodel
I1124 10:22:02.929102  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_9000.solverstate
I1124 10:22:02.951597  3844 solver.cpp:330] Iteration 9000, Testing net (#0)
I1124 10:22:02.951597  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:22:07.072101   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:22:07.241597  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8715
I1124 10:22:07.241597  3844 solver.cpp:397]     Test net output #1: loss = 0.39477 (* 1 = 0.39477 loss)
I1124 10:22:07.361608  3844 solver.cpp:218] Iteration 9000 (6.03267 iter/s, 16.5764s/100 iters), loss = 0.186663
I1124 10:22:07.361608  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:22:07.361608  3844 solver.cpp:237]     Train net output #1: loss = 0.186663 (* 1 = 0.186663 loss)
I1124 10:22:07.361608  3844 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1124 10:22:19.590853  3844 solver.cpp:218] Iteration 9100 (8.17756 iter/s, 12.2286s/100 iters), loss = 0.184085
I1124 10:22:19.590853  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:22:19.590853  3844 solver.cpp:237]     Train net output #1: loss = 0.184085 (* 1 = 0.184085 loss)
I1124 10:22:19.590853  3844 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1124 10:22:31.822901  3844 solver.cpp:218] Iteration 9200 (8.17558 iter/s, 12.2315s/100 iters), loss = 0.271943
I1124 10:22:31.823400  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:22:31.823400  3844 solver.cpp:237]     Train net output #1: loss = 0.271943 (* 1 = 0.271943 loss)
I1124 10:22:31.823400  3844 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1124 10:22:44.068642  3844 solver.cpp:218] Iteration 9300 (8.16677 iter/s, 12.2447s/100 iters), loss = 0.145733
I1124 10:22:44.068642  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:22:44.068642  3844 solver.cpp:237]     Train net output #1: loss = 0.145733 (* 1 = 0.145733 loss)
I1124 10:22:44.068642  3844 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1124 10:22:56.316874  3844 solver.cpp:218] Iteration 9400 (8.16497 iter/s, 12.2474s/100 iters), loss = 0.120246
I1124 10:22:56.316874  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:22:56.316874  3844 solver.cpp:237]     Train net output #1: loss = 0.120246 (* 1 = 0.120246 loss)
I1124 10:22:56.316874  3844 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1124 10:23:07.951135 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:23:08.437640  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_9500.caffemodel
I1124 10:23:08.478641  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_9500.solverstate
I1124 10:23:08.521136  3844 solver.cpp:330] Iteration 9500, Testing net (#0)
I1124 10:23:08.521636  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:23:12.641650   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:23:12.812146  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8654
I1124 10:23:12.812146  3844 solver.cpp:397]     Test net output #1: loss = 0.405008 (* 1 = 0.405008 loss)
I1124 10:23:12.930646  3844 solver.cpp:218] Iteration 9500 (6.0193 iter/s, 16.6132s/100 iters), loss = 0.147588
I1124 10:23:12.930646  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:23:12.930646  3844 solver.cpp:237]     Train net output #1: loss = 0.147588 (* 1 = 0.147588 loss)
I1124 10:23:12.930646  3844 sgd_solver.cpp:46] MultiStep Status: Iteration 9500, step = 2
I1124 10:23:12.930646  3844 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1124 10:23:25.171267  3844 solver.cpp:218] Iteration 9600 (8.16989 iter/s, 12.2401s/100 iters), loss = 0.13885
I1124 10:23:25.171267  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:23:25.171267  3844 solver.cpp:237]     Train net output #1: loss = 0.13885 (* 1 = 0.13885 loss)
I1124 10:23:25.171267  3844 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1124 10:23:37.405546  3844 solver.cpp:218] Iteration 9700 (8.17428 iter/s, 12.2335s/100 iters), loss = 0.117582
I1124 10:23:37.405546  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:23:37.405546  3844 solver.cpp:237]     Train net output #1: loss = 0.117582 (* 1 = 0.117582 loss)
I1124 10:23:37.405546  3844 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I1124 10:23:49.635205  3844 solver.cpp:218] Iteration 9800 (8.17731 iter/s, 12.229s/100 iters), loss = 0.139716
I1124 10:23:49.635205  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:23:49.635205  3844 solver.cpp:237]     Train net output #1: loss = 0.139716 (* 1 = 0.139716 loss)
I1124 10:23:49.635205  3844 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1124 10:24:01.876682  3844 solver.cpp:218] Iteration 9900 (8.16942 iter/s, 12.2408s/100 iters), loss = 0.117046
I1124 10:24:01.876682  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:24:01.876682  3844 solver.cpp:237]     Train net output #1: loss = 0.117046 (* 1 = 0.117046 loss)
I1124 10:24:01.876682  3844 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I1124 10:24:13.502370 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:24:13.990870  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_10000.caffemodel
I1124 10:24:14.031870  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_10000.solverstate
I1124 10:24:14.052379  3844 solver.cpp:330] Iteration 10000, Testing net (#0)
I1124 10:24:14.052379  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:24:18.183949   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:24:18.351449  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8868
I1124 10:24:18.351449  3844 solver.cpp:397]     Test net output #1: loss = 0.341614 (* 1 = 0.341614 loss)
I1124 10:24:18.470449  3844 solver.cpp:218] Iteration 10000 (6.02668 iter/s, 16.5929s/100 iters), loss = 0.103327
I1124 10:24:18.470449  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:24:18.470449  3844 solver.cpp:237]     Train net output #1: loss = 0.103326 (* 1 = 0.103326 loss)
I1124 10:24:18.470449  3844 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I1124 10:24:30.718283  3844 solver.cpp:218] Iteration 10100 (8.16508 iter/s, 12.2473s/100 iters), loss = 0.152263
I1124 10:24:30.718283  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:24:30.718283  3844 solver.cpp:237]     Train net output #1: loss = 0.152262 (* 1 = 0.152262 loss)
I1124 10:24:30.718283  3844 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I1124 10:24:42.967681  3844 solver.cpp:218] Iteration 10200 (8.16399 iter/s, 12.2489s/100 iters), loss = 0.171869
I1124 10:24:42.967681  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:24:42.967681  3844 solver.cpp:237]     Train net output #1: loss = 0.171869 (* 1 = 0.171869 loss)
I1124 10:24:42.967681  3844 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I1124 10:24:55.269485  3844 solver.cpp:218] Iteration 10300 (8.12922 iter/s, 12.3013s/100 iters), loss = 0.188939
I1124 10:24:55.269985  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:24:55.269985  3844 solver.cpp:237]     Train net output #1: loss = 0.188939 (* 1 = 0.188939 loss)
I1124 10:24:55.269985  3844 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I1124 10:25:07.483512  3844 solver.cpp:218] Iteration 10400 (8.18791 iter/s, 12.2131s/100 iters), loss = 0.0951963
I1124 10:25:07.483512  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:25:07.483512  3844 solver.cpp:237]     Train net output #1: loss = 0.0951961 (* 1 = 0.0951961 loss)
I1124 10:25:07.483512  3844 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I1124 10:25:18.947566 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:25:19.428066  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_10500.caffemodel
I1124 10:25:19.467128  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_10500.solverstate
I1124 10:25:19.510977  3844 solver.cpp:330] Iteration 10500, Testing net (#0)
I1124 10:25:19.510977  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:25:23.520701   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:25:23.684700  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8895
I1124 10:25:23.685199  3844 solver.cpp:397]     Test net output #1: loss = 0.343056 (* 1 = 0.343056 loss)
I1124 10:25:23.802713  3844 solver.cpp:218] Iteration 10500 (6.12802 iter/s, 16.3185s/100 iters), loss = 0.10795
I1124 10:25:23.802713  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:25:23.802713  3844 solver.cpp:237]     Train net output #1: loss = 0.10795 (* 1 = 0.10795 loss)
I1124 10:25:23.802713  3844 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I1124 10:25:35.856750  3844 solver.cpp:218] Iteration 10600 (8.29623 iter/s, 12.0537s/100 iters), loss = 0.131538
I1124 10:25:35.856750  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:25:35.856750  3844 solver.cpp:237]     Train net output #1: loss = 0.131538 (* 1 = 0.131538 loss)
I1124 10:25:35.856750  3844 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I1124 10:25:47.917127  3844 solver.cpp:218] Iteration 10700 (8.29213 iter/s, 12.0596s/100 iters), loss = 0.101313
I1124 10:25:47.917127  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:25:47.917127  3844 solver.cpp:237]     Train net output #1: loss = 0.101312 (* 1 = 0.101312 loss)
I1124 10:25:47.917127  3844 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I1124 10:26:00.004875  3844 solver.cpp:218] Iteration 10800 (8.2733 iter/s, 12.0871s/100 iters), loss = 0.146103
I1124 10:26:00.004875  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:26:00.004875  3844 solver.cpp:237]     Train net output #1: loss = 0.146103 (* 1 = 0.146103 loss)
I1124 10:26:00.004875  3844 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I1124 10:26:12.081913  3844 solver.cpp:218] Iteration 10900 (8.28057 iter/s, 12.0765s/100 iters), loss = 0.0930888
I1124 10:26:12.081913  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:26:12.081913  3844 solver.cpp:237]     Train net output #1: loss = 0.0930886 (* 1 = 0.0930886 loss)
I1124 10:26:12.082413  3844 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I1124 10:26:23.540109 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:26:24.018110  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_11000.caffemodel
I1124 10:26:24.058609  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_11000.solverstate
I1124 10:26:24.079110  3844 solver.cpp:330] Iteration 11000, Testing net (#0)
I1124 10:26:24.079110  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:26:28.084873   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:26:28.248899  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8888
I1124 10:26:28.248899  3844 solver.cpp:397]     Test net output #1: loss = 0.341027 (* 1 = 0.341027 loss)
I1124 10:26:28.366966  3844 solver.cpp:218] Iteration 11000 (6.14099 iter/s, 16.284s/100 iters), loss = 0.109786
I1124 10:26:28.366966  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:26:28.366966  3844 solver.cpp:237]     Train net output #1: loss = 0.109785 (* 1 = 0.109785 loss)
I1124 10:26:28.366966  3844 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I1124 10:26:40.428369  3844 solver.cpp:218] Iteration 11100 (8.2911 iter/s, 12.0611s/100 iters), loss = 0.155083
I1124 10:26:40.428860  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:26:40.428860  3844 solver.cpp:237]     Train net output #1: loss = 0.155083 (* 1 = 0.155083 loss)
I1124 10:26:40.428860  3844 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I1124 10:26:52.596874  3844 solver.cpp:218] Iteration 11200 (8.21858 iter/s, 12.1676s/100 iters), loss = 0.138145
I1124 10:26:52.596874  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:26:52.596874  3844 solver.cpp:237]     Train net output #1: loss = 0.138145 (* 1 = 0.138145 loss)
I1124 10:26:52.596874  3844 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I1124 10:27:04.895077  3844 solver.cpp:218] Iteration 11300 (8.1318 iter/s, 12.2974s/100 iters), loss = 0.124931
I1124 10:27:04.895077  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:27:04.895077  3844 solver.cpp:237]     Train net output #1: loss = 0.124931 (* 1 = 0.124931 loss)
I1124 10:27:04.895077  3844 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I1124 10:27:17.156231  3844 solver.cpp:218] Iteration 11400 (8.15601 iter/s, 12.2609s/100 iters), loss = 0.122187
I1124 10:27:17.156731  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:27:17.156731  3844 solver.cpp:237]     Train net output #1: loss = 0.122187 (* 1 = 0.122187 loss)
I1124 10:27:17.156731  3844 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I1124 10:27:28.776675 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:27:29.259675  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_11500.caffemodel
I1124 10:27:29.297175  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_11500.solverstate
I1124 10:27:29.338675  3844 solver.cpp:330] Iteration 11500, Testing net (#0)
I1124 10:27:29.338675  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:27:33.477689   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:27:33.646674  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8903
I1124 10:27:33.646674  3844 solver.cpp:397]     Test net output #1: loss = 0.341611 (* 1 = 0.341611 loss)
I1124 10:27:33.765686  3844 solver.cpp:218] Iteration 11500 (6.02097 iter/s, 16.6086s/100 iters), loss = 0.162954
I1124 10:27:33.765686  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1124 10:27:33.766175  3844 solver.cpp:237]     Train net output #1: loss = 0.162954 (* 1 = 0.162954 loss)
I1124 10:27:33.766175  3844 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I1124 10:27:46.040206  3844 solver.cpp:218] Iteration 11600 (8.1476 iter/s, 12.2736s/100 iters), loss = 0.135642
I1124 10:27:46.040206  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:27:46.040206  3844 solver.cpp:237]     Train net output #1: loss = 0.135642 (* 1 = 0.135642 loss)
I1124 10:27:46.040206  3844 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I1124 10:27:58.138490  3844 solver.cpp:218] Iteration 11700 (8.26598 iter/s, 12.0978s/100 iters), loss = 0.176629
I1124 10:27:58.138490  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:27:58.138490  3844 solver.cpp:237]     Train net output #1: loss = 0.176628 (* 1 = 0.176628 loss)
I1124 10:27:58.138490  3844 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I1124 10:28:10.191612  3844 solver.cpp:218] Iteration 11800 (8.29703 iter/s, 12.0525s/100 iters), loss = 0.106295
I1124 10:28:10.191612  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:28:10.191612  3844 solver.cpp:237]     Train net output #1: loss = 0.106295 (* 1 = 0.106295 loss)
I1124 10:28:10.191612  3844 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I1124 10:28:22.248044  3844 solver.cpp:218] Iteration 11900 (8.29471 iter/s, 12.0559s/100 iters), loss = 0.0763943
I1124 10:28:22.248044  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:28:22.248044  3844 solver.cpp:237]     Train net output #1: loss = 0.0763941 (* 1 = 0.0763941 loss)
I1124 10:28:22.248044  3844 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I1124 10:28:33.721639 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:28:34.203138  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_12000.caffemodel
I1124 10:28:34.243139  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_12000.solverstate
I1124 10:28:34.262639  3844 solver.cpp:330] Iteration 12000, Testing net (#0)
I1124 10:28:34.262639  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:28:38.282585   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:28:38.446089  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8904
I1124 10:28:38.446089  3844 solver.cpp:397]     Test net output #1: loss = 0.341753 (* 1 = 0.341753 loss)
I1124 10:28:38.563586  3844 solver.cpp:218] Iteration 12000 (6.12934 iter/s, 16.315s/100 iters), loss = 0.137123
I1124 10:28:38.564087  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:28:38.564087  3844 solver.cpp:237]     Train net output #1: loss = 0.137122 (* 1 = 0.137122 loss)
I1124 10:28:38.564087  3844 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I1124 10:28:50.651062  3844 solver.cpp:218] Iteration 12100 (8.27347 iter/s, 12.0868s/100 iters), loss = 0.147383
I1124 10:28:50.651551  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:28:50.651551  3844 solver.cpp:237]     Train net output #1: loss = 0.147382 (* 1 = 0.147382 loss)
I1124 10:28:50.651551  3844 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I1124 10:29:02.703318  3844 solver.cpp:218] Iteration 12200 (8.29763 iter/s, 12.0516s/100 iters), loss = 0.163123
I1124 10:29:02.703809  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:29:02.703809  3844 solver.cpp:237]     Train net output #1: loss = 0.163123 (* 1 = 0.163123 loss)
I1124 10:29:02.703809  3844 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I1124 10:29:14.778903  3844 solver.cpp:218] Iteration 12300 (8.28164 iter/s, 12.0749s/100 iters), loss = 0.107531
I1124 10:29:14.778903  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:29:14.778903  3844 solver.cpp:237]     Train net output #1: loss = 0.107531 (* 1 = 0.107531 loss)
I1124 10:29:14.778903  3844 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I1124 10:29:26.833562  3844 solver.cpp:218] Iteration 12400 (8.29602 iter/s, 12.054s/100 iters), loss = 0.0850665
I1124 10:29:26.833562  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:29:26.833562  3844 solver.cpp:237]     Train net output #1: loss = 0.0850662 (* 1 = 0.0850662 loss)
I1124 10:29:26.833562  3844 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I1124 10:29:38.296849 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:29:38.774348  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_12500.caffemodel
I1124 10:29:38.848757  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_12500.solverstate
I1124 10:29:38.869257  3844 solver.cpp:330] Iteration 12500, Testing net (#0)
I1124 10:29:38.869257  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:29:42.880265   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:29:43.052259  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8899
I1124 10:29:43.052757  3844 solver.cpp:397]     Test net output #1: loss = 0.342524 (* 1 = 0.342524 loss)
I1124 10:29:43.176776  3844 solver.cpp:218] Iteration 12500 (6.11906 iter/s, 16.3424s/100 iters), loss = 0.121356
I1124 10:29:43.176776  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:29:43.176776  3844 solver.cpp:237]     Train net output #1: loss = 0.121355 (* 1 = 0.121355 loss)
I1124 10:29:43.176776  3844 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I1124 10:29:55.250730  3844 solver.cpp:218] Iteration 12600 (8.28286 iter/s, 12.0731s/100 iters), loss = 0.145714
I1124 10:29:55.250730  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:29:55.250730  3844 solver.cpp:237]     Train net output #1: loss = 0.145714 (* 1 = 0.145714 loss)
I1124 10:29:55.250730  3844 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I1124 10:30:07.325816  3844 solver.cpp:218] Iteration 12700 (8.28186 iter/s, 12.0746s/100 iters), loss = 0.133929
I1124 10:30:07.325816  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:30:07.325816  3844 solver.cpp:237]     Train net output #1: loss = 0.133929 (* 1 = 0.133929 loss)
I1124 10:30:07.325816  3844 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I1124 10:30:19.400336  3844 solver.cpp:218] Iteration 12800 (8.28239 iter/s, 12.0738s/100 iters), loss = 0.118114
I1124 10:30:19.400336  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:30:19.400336  3844 solver.cpp:237]     Train net output #1: loss = 0.118114 (* 1 = 0.118114 loss)
I1124 10:30:19.400336  3844 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I1124 10:30:31.460182  3844 solver.cpp:218] Iteration 12900 (8.29218 iter/s, 12.0596s/100 iters), loss = 0.0949651
I1124 10:30:31.460683  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:30:31.460683  3844 solver.cpp:237]     Train net output #1: loss = 0.0949648 (* 1 = 0.0949648 loss)
I1124 10:30:31.460683  3844 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I1124 10:30:42.964468 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:30:43.445477  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_13000.caffemodel
I1124 10:30:43.487470  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_13000.solverstate
I1124 10:30:43.508467  3844 solver.cpp:330] Iteration 13000, Testing net (#0)
I1124 10:30:43.508467  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:30:47.628476   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:30:47.797971  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8887
I1124 10:30:47.797971  3844 solver.cpp:397]     Test net output #1: loss = 0.344159 (* 1 = 0.344159 loss)
I1124 10:30:47.919968  3844 solver.cpp:218] Iteration 13000 (6.07576 iter/s, 16.4588s/100 iters), loss = 0.134382
I1124 10:30:47.919968  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:30:47.919968  3844 solver.cpp:237]     Train net output #1: loss = 0.134381 (* 1 = 0.134381 loss)
I1124 10:30:47.919968  3844 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I1124 10:31:00.194129  3844 solver.cpp:218] Iteration 13100 (8.1478 iter/s, 12.2732s/100 iters), loss = 0.182904
I1124 10:31:00.194129  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:31:00.194129  3844 solver.cpp:237]     Train net output #1: loss = 0.182903 (* 1 = 0.182903 loss)
I1124 10:31:00.194129  3844 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I1124 10:31:12.351814  3844 solver.cpp:218] Iteration 13200 (8.22575 iter/s, 12.1569s/100 iters), loss = 0.171552
I1124 10:31:12.351814  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:31:12.351814  3844 solver.cpp:237]     Train net output #1: loss = 0.171551 (* 1 = 0.171551 loss)
I1124 10:31:12.351814  3844 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I1124 10:31:24.422364  3844 solver.cpp:218] Iteration 13300 (8.28504 iter/s, 12.0699s/100 iters), loss = 0.125214
I1124 10:31:24.422364  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:31:24.422364  3844 solver.cpp:237]     Train net output #1: loss = 0.125214 (* 1 = 0.125214 loss)
I1124 10:31:24.422364  3844 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I1124 10:31:36.498793  3844 solver.cpp:218] Iteration 13400 (8.2811 iter/s, 12.0757s/100 iters), loss = 0.0669465
I1124 10:31:36.498793  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:31:36.498793  3844 solver.cpp:237]     Train net output #1: loss = 0.0669462 (* 1 = 0.0669462 loss)
I1124 10:31:36.498793  3844 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I1124 10:31:48.137495 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:31:48.625497  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_13500.caffemodel
I1124 10:31:48.688992  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_13500.solverstate
I1124 10:31:48.710988  3844 solver.cpp:330] Iteration 13500, Testing net (#0)
I1124 10:31:48.710988  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:31:52.851733   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:31:53.020733  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8902
I1124 10:31:53.020733  3844 solver.cpp:397]     Test net output #1: loss = 0.344575 (* 1 = 0.344575 loss)
I1124 10:31:53.140748  3844 solver.cpp:218] Iteration 13500 (6.00909 iter/s, 16.6414s/100 iters), loss = 0.102879
I1124 10:31:53.141253  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:31:53.141253  3844 solver.cpp:237]     Train net output #1: loss = 0.102879 (* 1 = 0.102879 loss)
I1124 10:31:53.141253  3844 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I1124 10:32:05.419838  3844 solver.cpp:218] Iteration 13600 (8.14455 iter/s, 12.2781s/100 iters), loss = 0.100093
I1124 10:32:05.419838  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:32:05.419838  3844 solver.cpp:237]     Train net output #1: loss = 0.100093 (* 1 = 0.100093 loss)
I1124 10:32:05.419838  3844 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I1124 10:32:17.662767  3844 solver.cpp:218] Iteration 13700 (8.16844 iter/s, 12.2422s/100 iters), loss = 0.169876
I1124 10:32:17.662767  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:32:17.662767  3844 solver.cpp:237]     Train net output #1: loss = 0.169875 (* 1 = 0.169875 loss)
I1124 10:32:17.662767  3844 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I1124 10:32:29.903056  3844 solver.cpp:218] Iteration 13800 (8.17012 iter/s, 12.2397s/100 iters), loss = 0.132829
I1124 10:32:29.903558  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:32:29.903558  3844 solver.cpp:237]     Train net output #1: loss = 0.132829 (* 1 = 0.132829 loss)
I1124 10:32:29.903558  3844 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I1124 10:32:42.161854  3844 solver.cpp:218] Iteration 13900 (8.15799 iter/s, 12.2579s/100 iters), loss = 0.0790784
I1124 10:32:42.161854  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:32:42.161854  3844 solver.cpp:237]     Train net output #1: loss = 0.079078 (* 1 = 0.079078 loss)
I1124 10:32:42.161854  3844 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I1124 10:32:53.816468 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:32:54.303467  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_14000.caffemodel
I1124 10:32:54.345466  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_14000.solverstate
I1124 10:32:54.365468  3844 solver.cpp:330] Iteration 14000, Testing net (#0)
I1124 10:32:54.365468  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:32:58.485484   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:32:58.653970  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8899
I1124 10:32:58.653970  3844 solver.cpp:397]     Test net output #1: loss = 0.345407 (* 1 = 0.345407 loss)
I1124 10:32:58.773982  3844 solver.cpp:218] Iteration 14000 (6.01997 iter/s, 16.6114s/100 iters), loss = 0.116954
I1124 10:32:58.773982  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:32:58.773982  3844 solver.cpp:237]     Train net output #1: loss = 0.116954 (* 1 = 0.116954 loss)
I1124 10:32:58.773982  3844 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I1124 10:33:11.043597  3844 solver.cpp:218] Iteration 14100 (8.15065 iter/s, 12.269s/100 iters), loss = 0.132842
I1124 10:33:11.043597  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:33:11.043597  3844 solver.cpp:237]     Train net output #1: loss = 0.132842 (* 1 = 0.132842 loss)
I1124 10:33:11.043597  3844 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I1124 10:33:23.314880  3844 solver.cpp:218] Iteration 14200 (8.14954 iter/s, 12.2706s/100 iters), loss = 0.15049
I1124 10:33:23.314880  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:33:23.314880  3844 solver.cpp:237]     Train net output #1: loss = 0.15049 (* 1 = 0.15049 loss)
I1124 10:33:23.314880  3844 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I1124 10:33:35.595954  3844 solver.cpp:218] Iteration 14300 (8.14304 iter/s, 12.2804s/100 iters), loss = 0.145792
I1124 10:33:35.595954  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:33:35.595954  3844 solver.cpp:237]     Train net output #1: loss = 0.145792 (* 1 = 0.145792 loss)
I1124 10:33:35.595954  3844 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I1124 10:33:47.720633  3844 solver.cpp:218] Iteration 14400 (8.24837 iter/s, 12.1236s/100 iters), loss = 0.070827
I1124 10:33:47.720633  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:33:47.720633  3844 solver.cpp:237]     Train net output #1: loss = 0.0708267 (* 1 = 0.0708267 loss)
I1124 10:33:47.720633  3844 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I1124 10:33:59.199019 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:33:59.677007  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_14500.caffemodel
I1124 10:33:59.738523  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_14500.solverstate
I1124 10:33:59.757508  3844 solver.cpp:330] Iteration 14500, Testing net (#0)
I1124 10:33:59.758023  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:34:03.813006   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:34:03.983511  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 10:34:03.983511  3844 solver.cpp:397]     Test net output #1: loss = 0.347957 (* 1 = 0.347957 loss)
I1124 10:34:04.102519  3844 solver.cpp:218] Iteration 14500 (6.10451 iter/s, 16.3813s/100 iters), loss = 0.114248
I1124 10:34:04.102519  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:34:04.102519  3844 solver.cpp:237]     Train net output #1: loss = 0.114248 (* 1 = 0.114248 loss)
I1124 10:34:04.102519  3844 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I1124 10:34:16.181666  3844 solver.cpp:218] Iteration 14600 (8.27896 iter/s, 12.0788s/100 iters), loss = 0.122321
I1124 10:34:16.182173  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:34:16.182173  3844 solver.cpp:237]     Train net output #1: loss = 0.122321 (* 1 = 0.122321 loss)
I1124 10:34:16.182173  3844 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I1124 10:34:28.273504  3844 solver.cpp:218] Iteration 14700 (8.27052 iter/s, 12.0911s/100 iters), loss = 0.1256
I1124 10:34:28.274003  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:34:28.274003  3844 solver.cpp:237]     Train net output #1: loss = 0.1256 (* 1 = 0.1256 loss)
I1124 10:34:28.274003  3844 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I1124 10:34:40.345420  3844 solver.cpp:218] Iteration 14800 (8.28443 iter/s, 12.0708s/100 iters), loss = 0.119948
I1124 10:34:40.345420  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:34:40.345420  3844 solver.cpp:237]     Train net output #1: loss = 0.119948 (* 1 = 0.119948 loss)
I1124 10:34:40.345420  3844 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I1124 10:34:52.421262  3844 solver.cpp:218] Iteration 14900 (8.28145 iter/s, 12.0752s/100 iters), loss = 0.0760286
I1124 10:34:52.421262  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:34:52.421262  3844 solver.cpp:237]     Train net output #1: loss = 0.0760283 (* 1 = 0.0760283 loss)
I1124 10:34:52.421262  3844 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I1124 10:35:03.894829 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:35:04.372328  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_15000.caffemodel
I1124 10:35:04.412330  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_15000.solverstate
I1124 10:35:04.431831  3844 solver.cpp:330] Iteration 15000, Testing net (#0)
I1124 10:35:04.431831  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:35:08.469314   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:35:08.635814  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8894
I1124 10:35:08.635814  3844 solver.cpp:397]     Test net output #1: loss = 0.348825 (* 1 = 0.348825 loss)
I1124 10:35:08.755326  3844 solver.cpp:218] Iteration 15000 (6.12243 iter/s, 16.3334s/100 iters), loss = 0.122958
I1124 10:35:08.755326  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:35:08.755326  3844 solver.cpp:237]     Train net output #1: loss = 0.122958 (* 1 = 0.122958 loss)
I1124 10:35:08.755326  3844 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I1124 10:35:20.818737  3844 solver.cpp:218] Iteration 15100 (8.29016 iter/s, 12.0625s/100 iters), loss = 0.13674
I1124 10:35:20.818737  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:35:20.818737  3844 solver.cpp:237]     Train net output #1: loss = 0.13674 (* 1 = 0.13674 loss)
I1124 10:35:20.818737  3844 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I1124 10:35:32.893309  3844 solver.cpp:218] Iteration 15200 (8.2822 iter/s, 12.0741s/100 iters), loss = 0.102041
I1124 10:35:32.893309  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:35:32.893309  3844 solver.cpp:237]     Train net output #1: loss = 0.102041 (* 1 = 0.102041 loss)
I1124 10:35:32.893309  3844 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I1124 10:35:44.948465  3844 solver.cpp:218] Iteration 15300 (8.29545 iter/s, 12.0548s/100 iters), loss = 0.127977
I1124 10:35:44.948465  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:35:44.948966  3844 solver.cpp:237]     Train net output #1: loss = 0.127977 (* 1 = 0.127977 loss)
I1124 10:35:44.948966  3844 sgd_solver.cpp:46] MultiStep Status: Iteration 15300, step = 3
I1124 10:35:44.948966  3844 sgd_solver.cpp:105] Iteration 15300, lr = 0.0001
I1124 10:35:57.101686  3844 solver.cpp:218] Iteration 15400 (8.22899 iter/s, 12.1522s/100 iters), loss = 0.09938
I1124 10:35:57.101686  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:35:57.101686  3844 solver.cpp:237]     Train net output #1: loss = 0.0993797 (* 1 = 0.0993797 loss)
I1124 10:35:57.101686  3844 sgd_solver.cpp:105] Iteration 15400, lr = 0.0001
I1124 10:36:08.690248 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:36:09.174255  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_15500.caffemodel
I1124 10:36:09.239749  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_15500.solverstate
I1124 10:36:09.259248  3844 solver.cpp:330] Iteration 15500, Testing net (#0)
I1124 10:36:09.259248  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:36:13.296823   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:36:13.461824  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8904
I1124 10:36:13.461824  3844 solver.cpp:397]     Test net output #1: loss = 0.346985 (* 1 = 0.346985 loss)
I1124 10:36:13.580819  3844 solver.cpp:218] Iteration 15500 (6.06846 iter/s, 16.4787s/100 iters), loss = 0.066894
I1124 10:36:13.580819  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:36:13.580819  3844 solver.cpp:237]     Train net output #1: loss = 0.0668937 (* 1 = 0.0668937 loss)
I1124 10:36:13.580819  3844 sgd_solver.cpp:105] Iteration 15500, lr = 0.0001
I1124 10:36:25.661347  3844 solver.cpp:218] Iteration 15600 (8.27817 iter/s, 12.08s/100 iters), loss = 0.0843384
I1124 10:36:25.661847  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:36:25.661847  3844 solver.cpp:237]     Train net output #1: loss = 0.084338 (* 1 = 0.084338 loss)
I1124 10:36:25.661847  3844 sgd_solver.cpp:105] Iteration 15600, lr = 0.0001
I1124 10:36:37.786065  3844 solver.cpp:218] Iteration 15700 (8.24839 iter/s, 12.1236s/100 iters), loss = 0.109538
I1124 10:36:37.786065  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:36:37.786065  3844 solver.cpp:237]     Train net output #1: loss = 0.109538 (* 1 = 0.109538 loss)
I1124 10:36:37.786065  3844 sgd_solver.cpp:105] Iteration 15700, lr = 0.0001
I1124 10:36:49.844781  3844 solver.cpp:218] Iteration 15800 (8.29294 iter/s, 12.0585s/100 iters), loss = 0.108906
I1124 10:36:49.844781  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:36:49.844781  3844 solver.cpp:237]     Train net output #1: loss = 0.108906 (* 1 = 0.108906 loss)
I1124 10:36:49.844781  3844 sgd_solver.cpp:105] Iteration 15800, lr = 0.0001
I1124 10:37:01.922847  3844 solver.cpp:218] Iteration 15900 (8.27998 iter/s, 12.0773s/100 iters), loss = 0.071941
I1124 10:37:01.922847  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:37:01.922847  3844 solver.cpp:237]     Train net output #1: loss = 0.0719407 (* 1 = 0.0719407 loss)
I1124 10:37:01.922847  3844 sgd_solver.cpp:105] Iteration 15900, lr = 0.0001
I1124 10:37:13.411061 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:37:13.889633  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_16000.caffemodel
I1124 10:37:13.928634  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_16000.solverstate
I1124 10:37:13.948127  3844 solver.cpp:330] Iteration 16000, Testing net (#0)
I1124 10:37:13.948127  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:37:17.964618   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:37:18.129129  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 10:37:18.129129  3844 solver.cpp:397]     Test net output #1: loss = 0.347122 (* 1 = 0.347122 loss)
I1124 10:37:18.246616  3844 solver.cpp:218] Iteration 16000 (6.1263 iter/s, 16.3231s/100 iters), loss = 0.104666
I1124 10:37:18.246616  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:37:18.246616  3844 solver.cpp:237]     Train net output #1: loss = 0.104666 (* 1 = 0.104666 loss)
I1124 10:37:18.246616  3844 sgd_solver.cpp:105] Iteration 16000, lr = 0.0001
I1124 10:37:30.331691  3844 solver.cpp:218] Iteration 16100 (8.27503 iter/s, 12.0845s/100 iters), loss = 0.125496
I1124 10:37:30.332201  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:37:30.332201  3844 solver.cpp:237]     Train net output #1: loss = 0.125495 (* 1 = 0.125495 loss)
I1124 10:37:30.332201  3844 sgd_solver.cpp:105] Iteration 16100, lr = 0.0001
I1124 10:37:42.430233  3844 solver.cpp:218] Iteration 16200 (8.26611 iter/s, 12.0976s/100 iters), loss = 0.0833615
I1124 10:37:42.430233  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:37:42.430233  3844 solver.cpp:237]     Train net output #1: loss = 0.0833611 (* 1 = 0.0833611 loss)
I1124 10:37:42.430233  3844 sgd_solver.cpp:105] Iteration 16200, lr = 0.0001
I1124 10:37:54.503413  3844 solver.cpp:218] Iteration 16300 (8.28346 iter/s, 12.0723s/100 iters), loss = 0.126931
I1124 10:37:54.503413  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:37:54.503413  3844 solver.cpp:237]     Train net output #1: loss = 0.126931 (* 1 = 0.126931 loss)
I1124 10:37:54.503413  3844 sgd_solver.cpp:105] Iteration 16300, lr = 0.0001
I1124 10:38:06.578363  3844 solver.cpp:218] Iteration 16400 (8.28192 iter/s, 12.0745s/100 iters), loss = 0.0638555
I1124 10:38:06.578363  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:38:06.578363  3844 solver.cpp:237]     Train net output #1: loss = 0.0638551 (* 1 = 0.0638551 loss)
I1124 10:38:06.578363  3844 sgd_solver.cpp:105] Iteration 16400, lr = 0.0001
I1124 10:38:18.029240 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:38:18.508765  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_16500.caffemodel
I1124 10:38:18.573241  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_16500.solverstate
I1124 10:38:18.591742  3844 solver.cpp:330] Iteration 16500, Testing net (#0)
I1124 10:38:18.591742  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:38:22.605741   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:38:22.770242  3844 solver.cpp:397]     Test net output #0: accuracy = 0.891
I1124 10:38:22.770242  3844 solver.cpp:397]     Test net output #1: loss = 0.347046 (* 1 = 0.347046 loss)
I1124 10:38:22.887748  3844 solver.cpp:218] Iteration 16500 (6.13179 iter/s, 16.3085s/100 iters), loss = 0.100524
I1124 10:38:22.887748  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:38:22.887748  3844 solver.cpp:237]     Train net output #1: loss = 0.100523 (* 1 = 0.100523 loss)
I1124 10:38:22.887748  3844 sgd_solver.cpp:105] Iteration 16500, lr = 0.0001
I1124 10:38:35.122473  3844 solver.cpp:218] Iteration 16600 (8.17361 iter/s, 12.2345s/100 iters), loss = 0.132349
I1124 10:38:35.122974  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:38:35.122974  3844 solver.cpp:237]     Train net output #1: loss = 0.132349 (* 1 = 0.132349 loss)
I1124 10:38:35.122974  3844 sgd_solver.cpp:105] Iteration 16600, lr = 0.0001
I1124 10:38:47.211493  3844 solver.cpp:218] Iteration 16700 (8.27265 iter/s, 12.088s/100 iters), loss = 0.126145
I1124 10:38:47.211493  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:38:47.211493  3844 solver.cpp:237]     Train net output #1: loss = 0.126144 (* 1 = 0.126144 loss)
I1124 10:38:47.211493  3844 sgd_solver.cpp:105] Iteration 16700, lr = 0.0001
I1124 10:38:59.370461  3844 solver.cpp:218] Iteration 16800 (8.22465 iter/s, 12.1586s/100 iters), loss = 0.124218
I1124 10:38:59.370461  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:38:59.370461  3844 solver.cpp:237]     Train net output #1: loss = 0.124218 (* 1 = 0.124218 loss)
I1124 10:38:59.370461  3844 sgd_solver.cpp:105] Iteration 16800, lr = 0.0001
I1124 10:39:11.450670  3844 solver.cpp:218] Iteration 16900 (8.2787 iter/s, 12.0792s/100 iters), loss = 0.0621464
I1124 10:39:11.450670  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:39:11.450670  3844 solver.cpp:237]     Train net output #1: loss = 0.062146 (* 1 = 0.062146 loss)
I1124 10:39:11.450670  3844 sgd_solver.cpp:105] Iteration 16900, lr = 0.0001
I1124 10:39:22.926635 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:39:23.408151  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_17000.caffemodel
I1124 10:39:23.447131  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_17000.solverstate
I1124 10:39:23.466650  3844 solver.cpp:330] Iteration 17000, Testing net (#0)
I1124 10:39:23.467133  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:39:27.484179   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:39:27.648694  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8909
I1124 10:39:27.648694  3844 solver.cpp:397]     Test net output #1: loss = 0.347452 (* 1 = 0.347452 loss)
I1124 10:39:27.769191  3844 solver.cpp:218] Iteration 17000 (6.12819 iter/s, 16.318s/100 iters), loss = 0.0834636
I1124 10:39:27.769191  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:39:27.769191  3844 solver.cpp:237]     Train net output #1: loss = 0.0834632 (* 1 = 0.0834632 loss)
I1124 10:39:27.769191  3844 sgd_solver.cpp:105] Iteration 17000, lr = 0.0001
I1124 10:39:39.828919  3844 solver.cpp:218] Iteration 17100 (8.2925 iter/s, 12.0591s/100 iters), loss = 0.115738
I1124 10:39:39.828919  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:39:39.828919  3844 solver.cpp:237]     Train net output #1: loss = 0.115737 (* 1 = 0.115737 loss)
I1124 10:39:39.828919  3844 sgd_solver.cpp:105] Iteration 17100, lr = 0.0001
I1124 10:39:51.885339  3844 solver.cpp:218] Iteration 17200 (8.29477 iter/s, 12.0558s/100 iters), loss = 0.153892
I1124 10:39:51.885339  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:39:51.885339  3844 solver.cpp:237]     Train net output #1: loss = 0.153892 (* 1 = 0.153892 loss)
I1124 10:39:51.885339  3844 sgd_solver.cpp:105] Iteration 17200, lr = 0.0001
I1124 10:40:03.981608  3844 solver.cpp:218] Iteration 17300 (8.26752 iter/s, 12.0955s/100 iters), loss = 0.0990212
I1124 10:40:03.981608  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:40:03.981608  3844 solver.cpp:237]     Train net output #1: loss = 0.0990208 (* 1 = 0.0990208 loss)
I1124 10:40:03.981608  3844 sgd_solver.cpp:105] Iteration 17300, lr = 0.0001
I1124 10:40:16.095064  3844 solver.cpp:218] Iteration 17400 (8.25568 iter/s, 12.1129s/100 iters), loss = 0.0794601
I1124 10:40:16.095064  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:40:16.095064  3844 solver.cpp:237]     Train net output #1: loss = 0.0794597 (* 1 = 0.0794597 loss)
I1124 10:40:16.095064  3844 sgd_solver.cpp:105] Iteration 17400, lr = 0.0001
I1124 10:40:27.578409 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:40:28.067896  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_17500.caffemodel
I1124 10:40:28.122894  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_17500.solverstate
I1124 10:40:28.143395  3844 solver.cpp:330] Iteration 17500, Testing net (#0)
I1124 10:40:28.143395  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:40:32.195896   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:40:32.362397  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8908
I1124 10:40:32.362397  3844 solver.cpp:397]     Test net output #1: loss = 0.347196 (* 1 = 0.347196 loss)
I1124 10:40:32.479908  3844 solver.cpp:218] Iteration 17500 (6.10345 iter/s, 16.3842s/100 iters), loss = 0.0853641
I1124 10:40:32.480409  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:40:32.480409  3844 solver.cpp:237]     Train net output #1: loss = 0.0853636 (* 1 = 0.0853636 loss)
I1124 10:40:32.480409  3844 sgd_solver.cpp:105] Iteration 17500, lr = 0.0001
I1124 10:40:44.597321  3844 solver.cpp:218] Iteration 17600 (8.25332 iter/s, 12.1163s/100 iters), loss = 0.0792097
I1124 10:40:44.597321  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:40:44.597321  3844 solver.cpp:237]     Train net output #1: loss = 0.0792093 (* 1 = 0.0792093 loss)
I1124 10:40:44.597321  3844 sgd_solver.cpp:105] Iteration 17600, lr = 0.0001
I1124 10:40:56.653280  3844 solver.cpp:218] Iteration 17700 (8.2949 iter/s, 12.0556s/100 iters), loss = 0.155035
I1124 10:40:56.653280  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:40:56.653280  3844 solver.cpp:237]     Train net output #1: loss = 0.155035 (* 1 = 0.155035 loss)
I1124 10:40:56.653280  3844 sgd_solver.cpp:105] Iteration 17700, lr = 0.0001
I1124 10:41:08.741068  3844 solver.cpp:218] Iteration 17800 (8.2732 iter/s, 12.0872s/100 iters), loss = 0.0712071
I1124 10:41:08.741569  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:41:08.741569  3844 solver.cpp:237]     Train net output #1: loss = 0.0712066 (* 1 = 0.0712066 loss)
I1124 10:41:08.741569  3844 sgd_solver.cpp:105] Iteration 17800, lr = 0.0001
I1124 10:41:20.801856  3844 solver.cpp:218] Iteration 17900 (8.29186 iter/s, 12.06s/100 iters), loss = 0.0683811
I1124 10:41:20.801856  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:41:20.801856  3844 solver.cpp:237]     Train net output #1: loss = 0.0683807 (* 1 = 0.0683807 loss)
I1124 10:41:20.801856  3844 sgd_solver.cpp:105] Iteration 17900, lr = 0.0001
I1124 10:41:32.266062 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:41:32.746557  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_18000.caffemodel
I1124 10:41:32.787556  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_18000.solverstate
I1124 10:41:32.808045  3844 solver.cpp:330] Iteration 18000, Testing net (#0)
I1124 10:41:32.808045  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:41:36.852046   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:41:37.017046  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8912
I1124 10:41:37.017046  3844 solver.cpp:397]     Test net output #1: loss = 0.347679 (* 1 = 0.347679 loss)
I1124 10:41:37.135557  3844 solver.cpp:218] Iteration 18000 (6.12257 iter/s, 16.333s/100 iters), loss = 0.0796872
I1124 10:41:37.135557  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:41:37.135557  3844 solver.cpp:237]     Train net output #1: loss = 0.0796867 (* 1 = 0.0796867 loss)
I1124 10:41:37.135557  3844 sgd_solver.cpp:105] Iteration 18000, lr = 0.0001
I1124 10:41:49.219331  3844 solver.cpp:218] Iteration 18100 (8.27619 iter/s, 12.0829s/100 iters), loss = 0.133669
I1124 10:41:49.219331  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:41:49.219331  3844 solver.cpp:237]     Train net output #1: loss = 0.133668 (* 1 = 0.133668 loss)
I1124 10:41:49.219331  3844 sgd_solver.cpp:105] Iteration 18100, lr = 0.0001
I1124 10:42:01.313316  3844 solver.cpp:218] Iteration 18200 (8.26888 iter/s, 12.0935s/100 iters), loss = 0.101243
I1124 10:42:01.313316  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:42:01.313316  3844 solver.cpp:237]     Train net output #1: loss = 0.101242 (* 1 = 0.101242 loss)
I1124 10:42:01.313316  3844 sgd_solver.cpp:105] Iteration 18200, lr = 0.0001
I1124 10:42:13.447381  3844 solver.cpp:218] Iteration 18300 (8.24168 iter/s, 12.1334s/100 iters), loss = 0.176892
I1124 10:42:13.447381  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1124 10:42:13.447381  3844 solver.cpp:237]     Train net output #1: loss = 0.176891 (* 1 = 0.176891 loss)
I1124 10:42:13.447893  3844 sgd_solver.cpp:105] Iteration 18300, lr = 0.0001
I1124 10:42:25.547004  3844 solver.cpp:218] Iteration 18400 (8.26458 iter/s, 12.0998s/100 iters), loss = 0.114172
I1124 10:42:25.548300  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:42:25.548300  3844 solver.cpp:237]     Train net output #1: loss = 0.114171 (* 1 = 0.114171 loss)
I1124 10:42:25.548300  3844 sgd_solver.cpp:105] Iteration 18400, lr = 0.0001
I1124 10:42:37.001456 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:42:37.481951  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_18500.caffemodel
I1124 10:42:37.546943  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_18500.solverstate
I1124 10:42:37.565943  3844 solver.cpp:330] Iteration 18500, Testing net (#0)
I1124 10:42:37.565943  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:42:41.603942   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:42:41.768451  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8909
I1124 10:42:41.768941  3844 solver.cpp:397]     Test net output #1: loss = 0.348009 (* 1 = 0.348009 loss)
I1124 10:42:41.888451  3844 solver.cpp:218] Iteration 18500 (6.12014 iter/s, 16.3395s/100 iters), loss = 0.101655
I1124 10:42:41.888451  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:42:41.888451  3844 solver.cpp:237]     Train net output #1: loss = 0.101654 (* 1 = 0.101654 loss)
I1124 10:42:41.888451  3844 sgd_solver.cpp:105] Iteration 18500, lr = 0.0001
I1124 10:42:53.971437  3844 solver.cpp:218] Iteration 18600 (8.27646 iter/s, 12.0825s/100 iters), loss = 0.100084
I1124 10:42:53.971437  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:42:53.971437  3844 solver.cpp:237]     Train net output #1: loss = 0.100084 (* 1 = 0.100084 loss)
I1124 10:42:53.971437  3844 sgd_solver.cpp:105] Iteration 18600, lr = 0.0001
I1124 10:43:06.092088  3844 solver.cpp:218] Iteration 18700 (8.25082 iter/s, 12.12s/100 iters), loss = 0.148053
I1124 10:43:06.092088  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:43:06.092088  3844 solver.cpp:237]     Train net output #1: loss = 0.148053 (* 1 = 0.148053 loss)
I1124 10:43:06.092088  3844 sgd_solver.cpp:105] Iteration 18700, lr = 0.0001
I1124 10:43:18.189630  3844 solver.cpp:218] Iteration 18800 (8.26677 iter/s, 12.0966s/100 iters), loss = 0.127679
I1124 10:43:18.189630  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:43:18.189630  3844 solver.cpp:237]     Train net output #1: loss = 0.127678 (* 1 = 0.127678 loss)
I1124 10:43:18.189630  3844 sgd_solver.cpp:105] Iteration 18800, lr = 0.0001
I1124 10:43:30.241128  3844 solver.cpp:218] Iteration 18900 (8.2981 iter/s, 12.051s/100 iters), loss = 0.0835911
I1124 10:43:30.241128  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:43:30.241128  3844 solver.cpp:237]     Train net output #1: loss = 0.0835906 (* 1 = 0.0835906 loss)
I1124 10:43:30.241128  3844 sgd_solver.cpp:105] Iteration 18900, lr = 0.0001
I1124 10:43:41.731709 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:43:42.208709  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_19000.caffemodel
I1124 10:43:42.247231  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_19000.solverstate
I1124 10:43:42.266235  3844 solver.cpp:330] Iteration 19000, Testing net (#0)
I1124 10:43:42.266235  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:43:46.278712   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:43:46.442734  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8911
I1124 10:43:46.442734  3844 solver.cpp:397]     Test net output #1: loss = 0.348 (* 1 = 0.348 loss)
I1124 10:43:46.560214  3844 solver.cpp:218] Iteration 19000 (6.12818 iter/s, 16.3181s/100 iters), loss = 0.110245
I1124 10:43:46.560214  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:43:46.560214  3844 solver.cpp:237]     Train net output #1: loss = 0.110244 (* 1 = 0.110244 loss)
I1124 10:43:46.560214  3844 sgd_solver.cpp:105] Iteration 19000, lr = 0.0001
I1124 10:43:58.623991  3844 solver.cpp:218] Iteration 19100 (8.28969 iter/s, 12.0632s/100 iters), loss = 0.140843
I1124 10:43:58.623991  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:43:58.623991  3844 solver.cpp:237]     Train net output #1: loss = 0.140843 (* 1 = 0.140843 loss)
I1124 10:43:58.623991  3844 sgd_solver.cpp:105] Iteration 19100, lr = 0.0001
I1124 10:44:10.700050  3844 solver.cpp:218] Iteration 19200 (8.28106 iter/s, 12.0757s/100 iters), loss = 0.121784
I1124 10:44:10.700050  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:44:10.700050  3844 solver.cpp:237]     Train net output #1: loss = 0.121784 (* 1 = 0.121784 loss)
I1124 10:44:10.700050  3844 sgd_solver.cpp:105] Iteration 19200, lr = 0.0001
I1124 10:44:22.760219  3844 solver.cpp:218] Iteration 19300 (8.29236 iter/s, 12.0593s/100 iters), loss = 0.0835721
I1124 10:44:22.760219  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:44:22.760219  3844 solver.cpp:237]     Train net output #1: loss = 0.0835716 (* 1 = 0.0835716 loss)
I1124 10:44:22.760219  3844 sgd_solver.cpp:105] Iteration 19300, lr = 0.0001
I1124 10:44:34.840687  3844 solver.cpp:218] Iteration 19400 (8.27822 iter/s, 12.0799s/100 iters), loss = 0.0609994
I1124 10:44:34.840687  3844 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1124 10:44:34.840687  3844 solver.cpp:237]     Train net output #1: loss = 0.0609989 (* 1 = 0.0609989 loss)
I1124 10:44:34.840687  3844 sgd_solver.cpp:105] Iteration 19400, lr = 0.0001
I1124 10:44:46.336284 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:44:46.816272  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_19500.caffemodel
I1124 10:44:46.863766  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_19500.solverstate
I1124 10:44:46.882768  3844 solver.cpp:330] Iteration 19500, Testing net (#0)
I1124 10:44:46.882768  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:44:50.892766   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:44:51.057267  3844 solver.cpp:397]     Test net output #0: accuracy = 0.89
I1124 10:44:51.057267  3844 solver.cpp:397]     Test net output #1: loss = 0.348051 (* 1 = 0.348051 loss)
I1124 10:44:51.173777  3844 solver.cpp:218] Iteration 19500 (6.12276 iter/s, 16.3325s/100 iters), loss = 0.0660382
I1124 10:44:51.173777  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:44:51.173777  3844 solver.cpp:237]     Train net output #1: loss = 0.0660377 (* 1 = 0.0660377 loss)
I1124 10:44:51.173777  3844 sgd_solver.cpp:46] MultiStep Status: Iteration 19500, step = 4
I1124 10:44:51.173777  3844 sgd_solver.cpp:105] Iteration 19500, lr = 1e-05
I1124 10:45:03.237812  3844 solver.cpp:218] Iteration 19600 (8.2897 iter/s, 12.0632s/100 iters), loss = 0.130413
I1124 10:45:03.237812  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:45:03.237812  3844 solver.cpp:237]     Train net output #1: loss = 0.130413 (* 1 = 0.130413 loss)
I1124 10:45:03.237812  3844 sgd_solver.cpp:105] Iteration 19600, lr = 1e-05
I1124 10:45:15.296237  3844 solver.cpp:218] Iteration 19700 (8.29345 iter/s, 12.0577s/100 iters), loss = 0.0894556
I1124 10:45:15.296237  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:45:15.296237  3844 solver.cpp:237]     Train net output #1: loss = 0.0894551 (* 1 = 0.0894551 loss)
I1124 10:45:15.296237  3844 sgd_solver.cpp:105] Iteration 19700, lr = 1e-05
I1124 10:45:27.349725  3844 solver.cpp:218] Iteration 19800 (8.29675 iter/s, 12.0529s/100 iters), loss = 0.144634
I1124 10:45:27.349725  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:45:27.349725  3844 solver.cpp:237]     Train net output #1: loss = 0.144633 (* 1 = 0.144633 loss)
I1124 10:45:27.349725  3844 sgd_solver.cpp:105] Iteration 19800, lr = 1e-05
I1124 10:45:39.618837  3844 solver.cpp:218] Iteration 19900 (8.15089 iter/s, 12.2686s/100 iters), loss = 0.0573624
I1124 10:45:39.618837  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:45:39.618837  3844 solver.cpp:237]     Train net output #1: loss = 0.0573619 (* 1 = 0.0573619 loss)
I1124 10:45:39.618837  3844 sgd_solver.cpp:105] Iteration 19900, lr = 1e-05
I1124 10:45:51.255672 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:45:51.744177  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_20000.caffemodel
I1124 10:45:51.783164  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_20000.solverstate
I1124 10:45:51.829665  3844 solver.cpp:330] Iteration 20000, Testing net (#0)
I1124 10:45:51.829665  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:45:55.948173   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:45:56.118165  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8907
I1124 10:45:56.118165  3844 solver.cpp:397]     Test net output #1: loss = 0.348045 (* 1 = 0.348045 loss)
I1124 10:45:56.237661  3844 solver.cpp:218] Iteration 20000 (6.01755 iter/s, 16.6181s/100 iters), loss = 0.096992
I1124 10:45:56.237661  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:45:56.237661  3844 solver.cpp:237]     Train net output #1: loss = 0.0969915 (* 1 = 0.0969915 loss)
I1124 10:45:56.237661  3844 sgd_solver.cpp:105] Iteration 20000, lr = 1e-05
I1124 10:46:08.475685  3844 solver.cpp:218] Iteration 20100 (8.17182 iter/s, 12.2372s/100 iters), loss = 0.106794
I1124 10:46:08.475685  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:46:08.475685  3844 solver.cpp:237]     Train net output #1: loss = 0.106793 (* 1 = 0.106793 loss)
I1124 10:46:08.475685  3844 sgd_solver.cpp:105] Iteration 20100, lr = 1e-05
I1124 10:46:20.701002  3844 solver.cpp:218] Iteration 20200 (8.18014 iter/s, 12.2247s/100 iters), loss = 0.0856939
I1124 10:46:20.701002  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:46:20.701002  3844 solver.cpp:237]     Train net output #1: loss = 0.0856934 (* 1 = 0.0856934 loss)
I1124 10:46:20.701002  3844 sgd_solver.cpp:105] Iteration 20200, lr = 1e-05
I1124 10:46:32.926837  3844 solver.cpp:218] Iteration 20300 (8.17992 iter/s, 12.2251s/100 iters), loss = 0.136504
I1124 10:46:32.926837  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:46:32.926837  3844 solver.cpp:237]     Train net output #1: loss = 0.136504 (* 1 = 0.136504 loss)
I1124 10:46:32.926837  3844 sgd_solver.cpp:105] Iteration 20300, lr = 1e-05
I1124 10:46:45.152513  3844 solver.cpp:218] Iteration 20400 (8.17985 iter/s, 12.2252s/100 iters), loss = 0.0708003
I1124 10:46:45.152513  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:46:45.152513  3844 solver.cpp:237]     Train net output #1: loss = 0.0707998 (* 1 = 0.0707998 loss)
I1124 10:46:45.152513  3844 sgd_solver.cpp:105] Iteration 20400, lr = 1e-05
I1124 10:46:56.771663 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:46:57.258666  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_20500.caffemodel
I1124 10:46:57.323668  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_20500.solverstate
I1124 10:46:57.343169  3844 solver.cpp:330] Iteration 20500, Testing net (#0)
I1124 10:46:57.343169  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:47:01.468166   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:47:01.636675  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 10:47:01.636675  3844 solver.cpp:397]     Test net output #1: loss = 0.347903 (* 1 = 0.347903 loss)
I1124 10:47:01.755174  3844 solver.cpp:218] Iteration 20500 (6.02333 iter/s, 16.6021s/100 iters), loss = 0.109168
I1124 10:47:01.755668  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:47:01.755668  3844 solver.cpp:237]     Train net output #1: loss = 0.109168 (* 1 = 0.109168 loss)
I1124 10:47:01.755668  3844 sgd_solver.cpp:105] Iteration 20500, lr = 1e-05
I1124 10:47:14.120326  3844 solver.cpp:218] Iteration 20600 (8.08784 iter/s, 12.3642s/100 iters), loss = 0.126702
I1124 10:47:14.120326  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:47:14.120326  3844 solver.cpp:237]     Train net output #1: loss = 0.126702 (* 1 = 0.126702 loss)
I1124 10:47:14.120326  3844 sgd_solver.cpp:105] Iteration 20600, lr = 1e-05
I1124 10:47:26.445638  3844 solver.cpp:218] Iteration 20700 (8.11377 iter/s, 12.3247s/100 iters), loss = 0.121968
I1124 10:47:26.445638  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:47:26.445638  3844 solver.cpp:237]     Train net output #1: loss = 0.121967 (* 1 = 0.121967 loss)
I1124 10:47:26.445638  3844 sgd_solver.cpp:105] Iteration 20700, lr = 1e-05
I1124 10:47:38.678123  3844 solver.cpp:218] Iteration 20800 (8.17555 iter/s, 12.2316s/100 iters), loss = 0.1974
I1124 10:47:38.678123  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1124 10:47:38.678123  3844 solver.cpp:237]     Train net output #1: loss = 0.197399 (* 1 = 0.197399 loss)
I1124 10:47:38.678123  3844 sgd_solver.cpp:105] Iteration 20800, lr = 1e-05
I1124 10:47:50.926821  3844 solver.cpp:218] Iteration 20900 (8.16441 iter/s, 12.2483s/100 iters), loss = 0.067248
I1124 10:47:50.926821  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:47:50.926821  3844 solver.cpp:237]     Train net output #1: loss = 0.0672476 (* 1 = 0.0672476 loss)
I1124 10:47:50.926821  3844 sgd_solver.cpp:105] Iteration 20900, lr = 1e-05
I1124 10:48:02.543470 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:48:03.024569  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_21000.caffemodel
I1124 10:48:03.066064  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_21000.solverstate
I1124 10:48:03.086573  3844 solver.cpp:330] Iteration 21000, Testing net (#0)
I1124 10:48:03.086573  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:48:07.208636   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:48:07.376619  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 10:48:07.376619  3844 solver.cpp:397]     Test net output #1: loss = 0.347947 (* 1 = 0.347947 loss)
I1124 10:48:07.495626  3844 solver.cpp:218] Iteration 21000 (6.03572 iter/s, 16.568s/100 iters), loss = 0.0973796
I1124 10:48:07.495626  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:48:07.495626  3844 solver.cpp:237]     Train net output #1: loss = 0.097379 (* 1 = 0.097379 loss)
I1124 10:48:07.495626  3844 sgd_solver.cpp:105] Iteration 21000, lr = 1e-05
I1124 10:48:19.746912  3844 solver.cpp:218] Iteration 21100 (8.16278 iter/s, 12.2507s/100 iters), loss = 0.118272
I1124 10:48:19.746912  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:48:19.746912  3844 solver.cpp:237]     Train net output #1: loss = 0.118271 (* 1 = 0.118271 loss)
I1124 10:48:19.746912  3844 sgd_solver.cpp:105] Iteration 21100, lr = 1e-05
I1124 10:48:31.992553  3844 solver.cpp:218] Iteration 21200 (8.16663 iter/s, 12.245s/100 iters), loss = 0.0800124
I1124 10:48:31.993053  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:48:31.993053  3844 solver.cpp:237]     Train net output #1: loss = 0.0800119 (* 1 = 0.0800119 loss)
I1124 10:48:31.993053  3844 sgd_solver.cpp:105] Iteration 21200, lr = 1e-05
I1124 10:48:44.247078  3844 solver.cpp:218] Iteration 21300 (8.16077 iter/s, 12.2537s/100 iters), loss = 0.141151
I1124 10:48:44.247078  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:48:44.247078  3844 solver.cpp:237]     Train net output #1: loss = 0.14115 (* 1 = 0.14115 loss)
I1124 10:48:44.247579  3844 sgd_solver.cpp:105] Iteration 21300, lr = 1e-05
I1124 10:48:56.487098  3844 solver.cpp:218] Iteration 21400 (8.17066 iter/s, 12.2389s/100 iters), loss = 0.0847629
I1124 10:48:56.487098  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:48:56.487098  3844 solver.cpp:237]     Train net output #1: loss = 0.0847624 (* 1 = 0.0847624 loss)
I1124 10:48:56.487098  3844 sgd_solver.cpp:105] Iteration 21400, lr = 1e-05
I1124 10:49:08.120728 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:49:08.607729  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_21500.caffemodel
I1124 10:49:08.654747  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_21500.solverstate
I1124 10:49:08.674737  3844 solver.cpp:330] Iteration 21500, Testing net (#0)
I1124 10:49:08.674737  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:49:12.790230   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:49:12.960244  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8905
I1124 10:49:12.960244  3844 solver.cpp:397]     Test net output #1: loss = 0.347929 (* 1 = 0.347929 loss)
I1124 10:49:13.079726  3844 solver.cpp:218] Iteration 21500 (6.02695 iter/s, 16.5922s/100 iters), loss = 0.0845913
I1124 10:49:13.079726  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:49:13.079726  3844 solver.cpp:237]     Train net output #1: loss = 0.0845908 (* 1 = 0.0845908 loss)
I1124 10:49:13.080226  3844 sgd_solver.cpp:105] Iteration 21500, lr = 1e-05
I1124 10:49:25.307551  3844 solver.cpp:218] Iteration 21600 (8.17858 iter/s, 12.2271s/100 iters), loss = 0.134095
I1124 10:49:25.307551  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:49:25.307551  3844 solver.cpp:237]     Train net output #1: loss = 0.134094 (* 1 = 0.134094 loss)
I1124 10:49:25.307551  3844 sgd_solver.cpp:105] Iteration 21600, lr = 1e-05
I1124 10:49:37.599577  3844 solver.cpp:218] Iteration 21700 (8.13579 iter/s, 12.2914s/100 iters), loss = 0.145934
I1124 10:49:37.599577  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:49:37.599577  3844 solver.cpp:237]     Train net output #1: loss = 0.145934 (* 1 = 0.145934 loss)
I1124 10:49:37.599577  3844 sgd_solver.cpp:105] Iteration 21700, lr = 1e-05
I1124 10:49:49.926506  3844 solver.cpp:218] Iteration 21800 (8.11271 iter/s, 12.3263s/100 iters), loss = 0.147466
I1124 10:49:49.926506  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:49:49.926506  3844 solver.cpp:237]     Train net output #1: loss = 0.147466 (* 1 = 0.147466 loss)
I1124 10:49:49.926506  3844 sgd_solver.cpp:105] Iteration 21800, lr = 1e-05
I1124 10:50:02.353508  3844 solver.cpp:218] Iteration 21900 (8.04742 iter/s, 12.4263s/100 iters), loss = 0.0401379
I1124 10:50:02.353508  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:50:02.353508  3844 solver.cpp:237]     Train net output #1: loss = 0.0401374 (* 1 = 0.0401374 loss)
I1124 10:50:02.353508  3844 sgd_solver.cpp:105] Iteration 21900, lr = 1e-05
I1124 10:50:14.123181 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:50:14.618173  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_22000.caffemodel
I1124 10:50:14.658686  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_22000.solverstate
I1124 10:50:14.678686  3844 solver.cpp:330] Iteration 22000, Testing net (#0)
I1124 10:50:14.679186  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:50:18.878669   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:50:19.051178  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 10:50:19.051178  3844 solver.cpp:397]     Test net output #1: loss = 0.348098 (* 1 = 0.348098 loss)
I1124 10:50:19.175186  3844 solver.cpp:218] Iteration 22000 (5.94512 iter/s, 16.8205s/100 iters), loss = 0.0887937
I1124 10:50:19.175186  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:50:19.175186  3844 solver.cpp:237]     Train net output #1: loss = 0.0887933 (* 1 = 0.0887933 loss)
I1124 10:50:19.175186  3844 sgd_solver.cpp:46] MultiStep Status: Iteration 22000, step = 5
I1124 10:50:19.175186  3844 sgd_solver.cpp:105] Iteration 22000, lr = 1e-06
I1124 10:50:31.642745  3844 solver.cpp:218] Iteration 22100 (8.02113 iter/s, 12.4671s/100 iters), loss = 0.082137
I1124 10:50:31.642745  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:50:31.643244  3844 solver.cpp:237]     Train net output #1: loss = 0.0821365 (* 1 = 0.0821365 loss)
I1124 10:50:31.643244  3844 sgd_solver.cpp:105] Iteration 22100, lr = 1e-06
I1124 10:50:44.087771  3844 solver.cpp:218] Iteration 22200 (8.03592 iter/s, 12.4441s/100 iters), loss = 0.168499
I1124 10:50:44.087771  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:50:44.087771  3844 solver.cpp:237]     Train net output #1: loss = 0.168498 (* 1 = 0.168498 loss)
I1124 10:50:44.087771  3844 sgd_solver.cpp:105] Iteration 22200, lr = 1e-06
I1124 10:50:56.489701  3844 solver.cpp:218] Iteration 22300 (8.06393 iter/s, 12.4009s/100 iters), loss = 0.131418
I1124 10:50:56.489701  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:50:56.489701  3844 solver.cpp:237]     Train net output #1: loss = 0.131417 (* 1 = 0.131417 loss)
I1124 10:50:56.489701  3844 sgd_solver.cpp:105] Iteration 22300, lr = 1e-06
I1124 10:51:08.812605  3844 solver.cpp:218] Iteration 22400 (8.11555 iter/s, 12.322s/100 iters), loss = 0.0703558
I1124 10:51:08.812605  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:51:08.812605  3844 solver.cpp:237]     Train net output #1: loss = 0.0703554 (* 1 = 0.0703554 loss)
I1124 10:51:08.812605  3844 sgd_solver.cpp:105] Iteration 22400, lr = 1e-06
I1124 10:51:20.480921 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:51:20.966428  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_22500.caffemodel
I1124 10:51:21.031419  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_22500.solverstate
I1124 10:51:21.050921  3844 solver.cpp:330] Iteration 22500, Testing net (#0)
I1124 10:51:21.050921  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:51:25.175917   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:51:25.343919  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 10:51:25.344439  3844 solver.cpp:397]     Test net output #1: loss = 0.347946 (* 1 = 0.347946 loss)
I1124 10:51:25.463927  3844 solver.cpp:218] Iteration 22500 (6.00575 iter/s, 16.6507s/100 iters), loss = 0.112294
I1124 10:51:25.463927  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:51:25.463927  3844 solver.cpp:237]     Train net output #1: loss = 0.112293 (* 1 = 0.112293 loss)
I1124 10:51:25.463927  3844 sgd_solver.cpp:105] Iteration 22500, lr = 1e-06
I1124 10:51:37.705785  3844 solver.cpp:218] Iteration 22600 (8.1691 iter/s, 12.2413s/100 iters), loss = 0.136629
I1124 10:51:37.705785  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:51:37.705785  3844 solver.cpp:237]     Train net output #1: loss = 0.136629 (* 1 = 0.136629 loss)
I1124 10:51:37.705785  3844 sgd_solver.cpp:105] Iteration 22600, lr = 1e-06
I1124 10:51:49.948225  3844 solver.cpp:218] Iteration 22700 (8.16887 iter/s, 12.2416s/100 iters), loss = 0.12233
I1124 10:51:49.948225  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:51:49.948225  3844 solver.cpp:237]     Train net output #1: loss = 0.122329 (* 1 = 0.122329 loss)
I1124 10:51:49.948225  3844 sgd_solver.cpp:105] Iteration 22700, lr = 1e-06
I1124 10:52:02.192801  3844 solver.cpp:218] Iteration 22800 (8.16729 iter/s, 12.244s/100 iters), loss = 0.131798
I1124 10:52:02.192801  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:52:02.192801  3844 solver.cpp:237]     Train net output #1: loss = 0.131798 (* 1 = 0.131798 loss)
I1124 10:52:02.192801  3844 sgd_solver.cpp:105] Iteration 22800, lr = 1e-06
I1124 10:52:14.440030  3844 solver.cpp:218] Iteration 22900 (8.16571 iter/s, 12.2463s/100 iters), loss = 0.0985922
I1124 10:52:14.440030  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:52:14.440030  3844 solver.cpp:237]     Train net output #1: loss = 0.0985918 (* 1 = 0.0985918 loss)
I1124 10:52:14.440030  3844 sgd_solver.cpp:105] Iteration 22900, lr = 1e-06
I1124 10:52:26.056995 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:52:26.545042  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_23000.caffemodel
I1124 10:52:26.583541  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_23000.solverstate
I1124 10:52:26.604043  3844 solver.cpp:330] Iteration 23000, Testing net (#0)
I1124 10:52:26.604043  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:52:30.718578   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:52:30.887081  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8907
I1124 10:52:30.887588  3844 solver.cpp:397]     Test net output #1: loss = 0.348121 (* 1 = 0.348121 loss)
I1124 10:52:31.006080  3844 solver.cpp:218] Iteration 23000 (6.03669 iter/s, 16.5654s/100 iters), loss = 0.0781078
I1124 10:52:31.006080  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:52:31.006080  3844 solver.cpp:237]     Train net output #1: loss = 0.0781073 (* 1 = 0.0781073 loss)
I1124 10:52:31.006590  3844 sgd_solver.cpp:105] Iteration 23000, lr = 1e-06
I1124 10:52:43.235460  3844 solver.cpp:218] Iteration 23100 (8.17753 iter/s, 12.2286s/100 iters), loss = 0.134551
I1124 10:52:43.235960  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:52:43.235960  3844 solver.cpp:237]     Train net output #1: loss = 0.13455 (* 1 = 0.13455 loss)
I1124 10:52:43.235960  3844 sgd_solver.cpp:105] Iteration 23100, lr = 1e-06
I1124 10:52:55.456563  3844 solver.cpp:218] Iteration 23200 (8.18323 iter/s, 12.2201s/100 iters), loss = 0.141548
I1124 10:52:55.456563  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 10:52:55.456563  3844 solver.cpp:237]     Train net output #1: loss = 0.141548 (* 1 = 0.141548 loss)
I1124 10:52:55.456563  3844 sgd_solver.cpp:105] Iteration 23200, lr = 1e-06
I1124 10:53:07.699147  3844 solver.cpp:218] Iteration 23300 (8.16864 iter/s, 12.2419s/100 iters), loss = 0.13195
I1124 10:53:07.699147  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:53:07.699147  3844 solver.cpp:237]     Train net output #1: loss = 0.131949 (* 1 = 0.131949 loss)
I1124 10:53:07.699147  3844 sgd_solver.cpp:105] Iteration 23300, lr = 1e-06
I1124 10:53:19.920518  3844 solver.cpp:218] Iteration 23400 (8.18272 iter/s, 12.2209s/100 iters), loss = 0.0946634
I1124 10:53:19.920518  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:53:19.920518  3844 solver.cpp:237]     Train net output #1: loss = 0.094663 (* 1 = 0.094663 loss)
I1124 10:53:19.920518  3844 sgd_solver.cpp:105] Iteration 23400, lr = 1e-06
I1124 10:53:31.544721 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:53:32.032904  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_23500.caffemodel
I1124 10:53:32.097898  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_23500.solverstate
I1124 10:53:32.117904  3844 solver.cpp:330] Iteration 23500, Testing net (#0)
I1124 10:53:32.117904  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:53:36.237888   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:53:36.406904  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 10:53:36.406904  3844 solver.cpp:397]     Test net output #1: loss = 0.347886 (* 1 = 0.347886 loss)
I1124 10:53:36.526394  3844 solver.cpp:218] Iteration 23500 (6.02236 iter/s, 16.6048s/100 iters), loss = 0.124512
I1124 10:53:36.526394  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:53:36.526394  3844 solver.cpp:237]     Train net output #1: loss = 0.124511 (* 1 = 0.124511 loss)
I1124 10:53:36.526394  3844 sgd_solver.cpp:105] Iteration 23500, lr = 1e-06
I1124 10:53:48.766662  3844 solver.cpp:218] Iteration 23600 (8.17018 iter/s, 12.2396s/100 iters), loss = 0.12078
I1124 10:53:48.766662  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:53:48.766662  3844 solver.cpp:237]     Train net output #1: loss = 0.12078 (* 1 = 0.12078 loss)
I1124 10:53:48.766662  3844 sgd_solver.cpp:105] Iteration 23600, lr = 1e-06
I1124 10:54:01.004387  3844 solver.cpp:218] Iteration 23700 (8.172 iter/s, 12.2369s/100 iters), loss = 0.0806065
I1124 10:54:01.004387  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:54:01.004387  3844 solver.cpp:237]     Train net output #1: loss = 0.0806061 (* 1 = 0.0806061 loss)
I1124 10:54:01.004387  3844 sgd_solver.cpp:105] Iteration 23700, lr = 1e-06
I1124 10:54:13.256085  3844 solver.cpp:218] Iteration 23800 (8.16254 iter/s, 12.2511s/100 iters), loss = 0.190971
I1124 10:54:13.256085  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:54:13.256085  3844 solver.cpp:237]     Train net output #1: loss = 0.19097 (* 1 = 0.19097 loss)
I1124 10:54:13.256085  3844 sgd_solver.cpp:105] Iteration 23800, lr = 1e-06
I1124 10:54:25.506397  3844 solver.cpp:218] Iteration 23900 (8.16332 iter/s, 12.2499s/100 iters), loss = 0.101654
I1124 10:54:25.506397  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:54:25.506397  3844 solver.cpp:237]     Train net output #1: loss = 0.101654 (* 1 = 0.101654 loss)
I1124 10:54:25.506397  3844 sgd_solver.cpp:105] Iteration 23900, lr = 1e-06
I1124 10:54:37.150172 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:54:37.639679  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_24000.caffemodel
I1124 10:54:37.679688  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_24000.solverstate
I1124 10:54:37.699672  3844 solver.cpp:330] Iteration 24000, Testing net (#0)
I1124 10:54:37.699672  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:54:41.851181   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:54:42.023170  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 10:54:42.023170  3844 solver.cpp:397]     Test net output #1: loss = 0.348109 (* 1 = 0.348109 loss)
I1124 10:54:42.145673  3844 solver.cpp:218] Iteration 24000 (6.01022 iter/s, 16.6383s/100 iters), loss = 0.0874409
I1124 10:54:42.145673  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:54:42.145673  3844 solver.cpp:237]     Train net output #1: loss = 0.0874405 (* 1 = 0.0874405 loss)
I1124 10:54:42.145673  3844 sgd_solver.cpp:105] Iteration 24000, lr = 1e-06
I1124 10:54:54.626252  3844 solver.cpp:218] Iteration 24100 (8.01277 iter/s, 12.4801s/100 iters), loss = 0.134298
I1124 10:54:54.626747  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:54:54.626747  3844 solver.cpp:237]     Train net output #1: loss = 0.134298 (* 1 = 0.134298 loss)
I1124 10:54:54.626747  3844 sgd_solver.cpp:105] Iteration 24100, lr = 1e-06
I1124 10:55:06.939946  3844 solver.cpp:218] Iteration 24200 (8.1215 iter/s, 12.313s/100 iters), loss = 0.1706
I1124 10:55:06.940446  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1124 10:55:06.940446  3844 solver.cpp:237]     Train net output #1: loss = 0.1706 (* 1 = 0.1706 loss)
I1124 10:55:06.940446  3844 sgd_solver.cpp:105] Iteration 24200, lr = 1e-06
I1124 10:55:19.412636  3844 solver.cpp:218] Iteration 24300 (8.01817 iter/s, 12.4717s/100 iters), loss = 0.132348
I1124 10:55:19.412636  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:55:19.412636  3844 solver.cpp:237]     Train net output #1: loss = 0.132348 (* 1 = 0.132348 loss)
I1124 10:55:19.412636  3844 sgd_solver.cpp:105] Iteration 24300, lr = 1e-06
I1124 10:55:31.767557  3844 solver.cpp:218] Iteration 24400 (8.09415 iter/s, 12.3546s/100 iters), loss = 0.0787603
I1124 10:55:31.768059  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:55:31.768059  3844 solver.cpp:237]     Train net output #1: loss = 0.0787599 (* 1 = 0.0787599 loss)
I1124 10:55:31.768059  3844 sgd_solver.cpp:105] Iteration 24400, lr = 1e-06
I1124 10:55:43.538180 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:55:44.036695  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_24500.caffemodel
I1124 10:55:44.109693  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_24500.solverstate
I1124 10:55:44.130185  3844 solver.cpp:330] Iteration 24500, Testing net (#0)
I1124 10:55:44.130686  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:55:48.331182   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:55:48.503681  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8905
I1124 10:55:48.503681  3844 solver.cpp:397]     Test net output #1: loss = 0.348042 (* 1 = 0.348042 loss)
I1124 10:55:48.627192  3844 solver.cpp:218] Iteration 24500 (5.93175 iter/s, 16.8584s/100 iters), loss = 0.0946627
I1124 10:55:48.627192  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:55:48.627192  3844 solver.cpp:237]     Train net output #1: loss = 0.0946623 (* 1 = 0.0946623 loss)
I1124 10:55:48.627192  3844 sgd_solver.cpp:105] Iteration 24500, lr = 1e-06
I1124 10:56:01.023250  3844 solver.cpp:218] Iteration 24600 (8.06732 iter/s, 12.3957s/100 iters), loss = 0.0819818
I1124 10:56:01.023751  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:56:01.023751  3844 solver.cpp:237]     Train net output #1: loss = 0.0819815 (* 1 = 0.0819815 loss)
I1124 10:56:01.023751  3844 sgd_solver.cpp:105] Iteration 24600, lr = 1e-06
I1124 10:56:13.375305  3844 solver.cpp:218] Iteration 24700 (8.09657 iter/s, 12.3509s/100 iters), loss = 0.113391
I1124 10:56:13.375305  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:56:13.375305  3844 solver.cpp:237]     Train net output #1: loss = 0.11339 (* 1 = 0.11339 loss)
I1124 10:56:13.375305  3844 sgd_solver.cpp:105] Iteration 24700, lr = 1e-06
I1124 10:56:25.696533  3844 solver.cpp:218] Iteration 24800 (8.11642 iter/s, 12.3207s/100 iters), loss = 0.123013
I1124 10:56:25.696533  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:56:25.696533  3844 solver.cpp:237]     Train net output #1: loss = 0.123012 (* 1 = 0.123012 loss)
I1124 10:56:25.696533  3844 sgd_solver.cpp:105] Iteration 24800, lr = 1e-06
I1124 10:56:38.115466  3844 solver.cpp:218] Iteration 24900 (8.0528 iter/s, 12.418s/100 iters), loss = 0.0827764
I1124 10:56:38.115466  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:56:38.115466  3844 solver.cpp:237]     Train net output #1: loss = 0.082776 (* 1 = 0.082776 loss)
I1124 10:56:38.115466  3844 sgd_solver.cpp:105] Iteration 24900, lr = 1e-06
I1124 10:56:49.967213 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:56:50.458236  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_25000.caffemodel
I1124 10:56:50.498718  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_25000.solverstate
I1124 10:56:50.517735  3844 solver.cpp:330] Iteration 25000, Testing net (#0)
I1124 10:56:50.517735  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:56:54.674218   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:56:54.844228  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 10:56:54.844228  3844 solver.cpp:397]     Test net output #1: loss = 0.348071 (* 1 = 0.348071 loss)
I1124 10:56:54.964227  3844 solver.cpp:218] Iteration 25000 (5.93543 iter/s, 16.848s/100 iters), loss = 0.140795
I1124 10:56:54.964227  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:56:54.964227  3844 solver.cpp:237]     Train net output #1: loss = 0.140794 (* 1 = 0.140794 loss)
I1124 10:56:54.964227  3844 sgd_solver.cpp:105] Iteration 25000, lr = 1e-06
I1124 10:57:07.258280  3844 solver.cpp:218] Iteration 25100 (8.13457 iter/s, 12.2932s/100 iters), loss = 0.154504
I1124 10:57:07.258280  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:57:07.258280  3844 solver.cpp:237]     Train net output #1: loss = 0.154503 (* 1 = 0.154503 loss)
I1124 10:57:07.258280  3844 sgd_solver.cpp:105] Iteration 25100, lr = 1e-06
I1124 10:57:19.570029  3844 solver.cpp:218] Iteration 25200 (8.12255 iter/s, 12.3114s/100 iters), loss = 0.111788
I1124 10:57:19.570530  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:57:19.570530  3844 solver.cpp:237]     Train net output #1: loss = 0.111788 (* 1 = 0.111788 loss)
I1124 10:57:19.570530  3844 sgd_solver.cpp:105] Iteration 25200, lr = 1e-06
I1124 10:57:31.948043  3844 solver.cpp:218] Iteration 25300 (8.07943 iter/s, 12.3771s/100 iters), loss = 0.110348
I1124 10:57:31.948043  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:57:31.948043  3844 solver.cpp:237]     Train net output #1: loss = 0.110348 (* 1 = 0.110348 loss)
I1124 10:57:31.948043  3844 sgd_solver.cpp:105] Iteration 25300, lr = 1e-06
I1124 10:57:44.391381  3844 solver.cpp:218] Iteration 25400 (8.03674 iter/s, 12.4429s/100 iters), loss = 0.0968614
I1124 10:57:44.391381  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:57:44.391381  3844 solver.cpp:237]     Train net output #1: loss = 0.096861 (* 1 = 0.096861 loss)
I1124 10:57:44.391381  3844 sgd_solver.cpp:105] Iteration 25400, lr = 1e-06
I1124 10:57:56.199203 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:57:56.689728  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_25500.caffemodel
I1124 10:57:56.755204  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_25500.solverstate
I1124 10:57:56.774722  3844 solver.cpp:330] Iteration 25500, Testing net (#0)
I1124 10:57:56.774722  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:58:00.917737   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:58:01.088737  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8904
I1124 10:58:01.088737  3844 solver.cpp:397]     Test net output #1: loss = 0.347937 (* 1 = 0.347937 loss)
I1124 10:58:01.209734  3844 solver.cpp:218] Iteration 25500 (5.94621 iter/s, 16.8174s/100 iters), loss = 0.107379
I1124 10:58:01.209734  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:58:01.209734  3844 solver.cpp:237]     Train net output #1: loss = 0.107379 (* 1 = 0.107379 loss)
I1124 10:58:01.209734  3844 sgd_solver.cpp:105] Iteration 25500, lr = 1e-06
I1124 10:58:13.595399  3844 solver.cpp:218] Iteration 25600 (8.07421 iter/s, 12.3851s/100 iters), loss = 0.162823
I1124 10:58:13.595399  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:58:13.595399  3844 solver.cpp:237]     Train net output #1: loss = 0.162823 (* 1 = 0.162823 loss)
I1124 10:58:13.595399  3844 sgd_solver.cpp:105] Iteration 25600, lr = 1e-06
I1124 10:58:26.078332  3844 solver.cpp:218] Iteration 25700 (8.01155 iter/s, 12.482s/100 iters), loss = 0.156139
I1124 10:58:26.078332  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:58:26.078332  3844 solver.cpp:237]     Train net output #1: loss = 0.156139 (* 1 = 0.156139 loss)
I1124 10:58:26.078332  3844 sgd_solver.cpp:105] Iteration 25700, lr = 1e-06
I1124 10:58:38.492162  3844 solver.cpp:218] Iteration 25800 (8.0557 iter/s, 12.4136s/100 iters), loss = 0.154954
I1124 10:58:38.492663  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1124 10:58:38.492663  3844 solver.cpp:237]     Train net output #1: loss = 0.154954 (* 1 = 0.154954 loss)
I1124 10:58:38.492663  3844 sgd_solver.cpp:105] Iteration 25800, lr = 1e-06
I1124 10:58:50.837246  3844 solver.cpp:218] Iteration 25900 (8.10112 iter/s, 12.344s/100 iters), loss = 0.0721042
I1124 10:58:50.837246  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 10:58:50.837246  3844 solver.cpp:237]     Train net output #1: loss = 0.0721038 (* 1 = 0.0721038 loss)
I1124 10:58:50.837246  3844 sgd_solver.cpp:105] Iteration 25900, lr = 1e-06
I1124 10:59:02.504884 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:59:03.000394  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_26000.caffemodel
I1124 10:59:03.041404  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_26000.solverstate
I1124 10:59:03.060894  3844 solver.cpp:330] Iteration 26000, Testing net (#0)
I1124 10:59:03.061394  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 10:59:07.208387   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 10:59:07.377884  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8903
I1124 10:59:07.377884  3844 solver.cpp:397]     Test net output #1: loss = 0.347976 (* 1 = 0.347976 loss)
I1124 10:59:07.498394  3844 solver.cpp:218] Iteration 26000 (6.00229 iter/s, 16.6603s/100 iters), loss = 0.0914536
I1124 10:59:07.498394  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:59:07.498394  3844 solver.cpp:237]     Train net output #1: loss = 0.0914532 (* 1 = 0.0914532 loss)
I1124 10:59:07.498394  3844 sgd_solver.cpp:105] Iteration 26000, lr = 1e-06
I1124 10:59:19.813226  3844 solver.cpp:218] Iteration 26100 (8.12045 iter/s, 12.3146s/100 iters), loss = 0.131043
I1124 10:59:19.813727  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 10:59:19.813727  3844 solver.cpp:237]     Train net output #1: loss = 0.131042 (* 1 = 0.131042 loss)
I1124 10:59:19.813727  3844 sgd_solver.cpp:105] Iteration 26100, lr = 1e-06
I1124 10:59:32.120824  3844 solver.cpp:218] Iteration 26200 (8.12566 iter/s, 12.3067s/100 iters), loss = 0.12441
I1124 10:59:32.120824  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 10:59:32.120824  3844 solver.cpp:237]     Train net output #1: loss = 0.12441 (* 1 = 0.12441 loss)
I1124 10:59:32.120824  3844 sgd_solver.cpp:105] Iteration 26200, lr = 1e-06
I1124 10:59:44.431848  3844 solver.cpp:218] Iteration 26300 (8.12326 iter/s, 12.3103s/100 iters), loss = 0.160649
I1124 10:59:44.431848  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 10:59:44.431848  3844 solver.cpp:237]     Train net output #1: loss = 0.160649 (* 1 = 0.160649 loss)
I1124 10:59:44.431848  3844 sgd_solver.cpp:105] Iteration 26300, lr = 1e-06
I1124 10:59:56.617175  3844 solver.cpp:218] Iteration 26400 (8.20694 iter/s, 12.1848s/100 iters), loss = 0.0912631
I1124 10:59:56.617676  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 10:59:56.617676  3844 solver.cpp:237]     Train net output #1: loss = 0.0912626 (* 1 = 0.0912626 loss)
I1124 10:59:56.617676  3844 sgd_solver.cpp:105] Iteration 26400, lr = 1e-06
I1124 11:00:08.106329 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:00:08.585348  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_26500.caffemodel
I1124 11:00:08.646848  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_26500.solverstate
I1124 11:00:08.666349  3844 solver.cpp:330] Iteration 26500, Testing net (#0)
I1124 11:00:08.666349  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 11:00:12.682332   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:00:12.845867  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8905
I1124 11:00:12.845867  3844 solver.cpp:397]     Test net output #1: loss = 0.34809 (* 1 = 0.34809 loss)
I1124 11:00:12.963840  3844 solver.cpp:218] Iteration 26500 (6.11785 iter/s, 16.3456s/100 iters), loss = 0.0905828
I1124 11:00:12.963840  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 11:00:12.963840  3844 solver.cpp:237]     Train net output #1: loss = 0.0905823 (* 1 = 0.0905823 loss)
I1124 11:00:12.963840  3844 sgd_solver.cpp:105] Iteration 26500, lr = 1e-06
I1124 11:00:25.025323  3844 solver.cpp:218] Iteration 26600 (8.29104 iter/s, 12.0612s/100 iters), loss = 0.0939955
I1124 11:00:25.025828  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 11:00:25.025828  3844 solver.cpp:237]     Train net output #1: loss = 0.0939951 (* 1 = 0.0939951 loss)
I1124 11:00:25.025828  3844 sgd_solver.cpp:105] Iteration 26600, lr = 1e-06
I1124 11:00:37.082072  3844 solver.cpp:218] Iteration 26700 (8.29478 iter/s, 12.0558s/100 iters), loss = 0.154559
I1124 11:00:37.082072  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 11:00:37.082072  3844 solver.cpp:237]     Train net output #1: loss = 0.154559 (* 1 = 0.154559 loss)
I1124 11:00:37.082072  3844 sgd_solver.cpp:105] Iteration 26700, lr = 1e-06
I1124 11:00:49.140302  3844 solver.cpp:218] Iteration 26800 (8.29349 iter/s, 12.0577s/100 iters), loss = 0.152952
I1124 11:00:49.140302  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 11:00:49.140302  3844 solver.cpp:237]     Train net output #1: loss = 0.152952 (* 1 = 0.152952 loss)
I1124 11:00:49.140302  3844 sgd_solver.cpp:105] Iteration 26800, lr = 1e-06
I1124 11:01:01.350657  3844 solver.cpp:218] Iteration 26900 (8.19016 iter/s, 12.2098s/100 iters), loss = 0.0716874
I1124 11:01:01.350657  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 11:01:01.350657  3844 solver.cpp:237]     Train net output #1: loss = 0.0716869 (* 1 = 0.0716869 loss)
I1124 11:01:01.350657  3844 sgd_solver.cpp:105] Iteration 26900, lr = 1e-06
I1124 11:01:12.992830 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:01:13.481333  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_27000.caffemodel
I1124 11:01:13.522332  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_27000.solverstate
I1124 11:01:13.542331  3844 solver.cpp:330] Iteration 27000, Testing net (#0)
I1124 11:01:13.542331  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 11:01:17.662904   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:01:17.829905  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 11:01:17.829905  3844 solver.cpp:397]     Test net output #1: loss = 0.348061 (* 1 = 0.348061 loss)
I1124 11:01:17.948912  3844 solver.cpp:218] Iteration 27000 (6.02492 iter/s, 16.5977s/100 iters), loss = 0.155521
I1124 11:01:17.949412  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 11:01:17.949412  3844 solver.cpp:237]     Train net output #1: loss = 0.155521 (* 1 = 0.155521 loss)
I1124 11:01:17.949412  3844 sgd_solver.cpp:46] MultiStep Status: Iteration 27000, step = 6
I1124 11:01:17.949412  3844 sgd_solver.cpp:105] Iteration 27000, lr = 1e-07
I1124 11:01:30.211315  3844 solver.cpp:218] Iteration 27100 (8.15567 iter/s, 12.2614s/100 iters), loss = 0.117273
I1124 11:01:30.211315  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 11:01:30.211315  3844 solver.cpp:237]     Train net output #1: loss = 0.117272 (* 1 = 0.117272 loss)
I1124 11:01:30.211315  3844 sgd_solver.cpp:105] Iteration 27100, lr = 1e-07
I1124 11:01:42.517352  3844 solver.cpp:218] Iteration 27200 (8.12656 iter/s, 12.3053s/100 iters), loss = 0.125886
I1124 11:01:42.517352  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 11:01:42.517352  3844 solver.cpp:237]     Train net output #1: loss = 0.125885 (* 1 = 0.125885 loss)
I1124 11:01:42.517352  3844 sgd_solver.cpp:105] Iteration 27200, lr = 1e-07
I1124 11:01:54.748423  3844 solver.cpp:218] Iteration 27300 (8.17601 iter/s, 12.2309s/100 iters), loss = 0.117268
I1124 11:01:54.748922  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 11:01:54.748922  3844 solver.cpp:237]     Train net output #1: loss = 0.117268 (* 1 = 0.117268 loss)
I1124 11:01:54.748922  3844 sgd_solver.cpp:105] Iteration 27300, lr = 1e-07
I1124 11:02:06.978538  3844 solver.cpp:218] Iteration 27400 (8.1771 iter/s, 12.2293s/100 iters), loss = 0.0628299
I1124 11:02:06.978538  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 11:02:06.978538  3844 solver.cpp:237]     Train net output #1: loss = 0.0628295 (* 1 = 0.0628295 loss)
I1124 11:02:06.978538  3844 sgd_solver.cpp:105] Iteration 27400, lr = 1e-07
I1124 11:02:18.610175 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:02:19.093205  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_27500.caffemodel
I1124 11:02:19.162703  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_27500.solverstate
I1124 11:02:19.183223  3844 solver.cpp:330] Iteration 27500, Testing net (#0)
I1124 11:02:19.183223  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 11:02:23.301249   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:02:23.469260  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8905
I1124 11:02:23.469759  3844 solver.cpp:397]     Test net output #1: loss = 0.347963 (* 1 = 0.347963 loss)
I1124 11:02:23.588253  3844 solver.cpp:218] Iteration 27500 (6.02085 iter/s, 16.609s/100 iters), loss = 0.107157
I1124 11:02:23.588253  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 11:02:23.588253  3844 solver.cpp:237]     Train net output #1: loss = 0.107157 (* 1 = 0.107157 loss)
I1124 11:02:23.588253  3844 sgd_solver.cpp:105] Iteration 27500, lr = 1e-07
I1124 11:02:35.814970  3844 solver.cpp:218] Iteration 27600 (8.17938 iter/s, 12.2259s/100 iters), loss = 0.125444
I1124 11:02:35.814970  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 11:02:35.814970  3844 solver.cpp:237]     Train net output #1: loss = 0.125444 (* 1 = 0.125444 loss)
I1124 11:02:35.814970  3844 sgd_solver.cpp:105] Iteration 27600, lr = 1e-07
I1124 11:02:48.050745  3844 solver.cpp:218] Iteration 27700 (8.17323 iter/s, 12.2351s/100 iters), loss = 0.121214
I1124 11:02:48.050745  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 11:02:48.050745  3844 solver.cpp:237]     Train net output #1: loss = 0.121214 (* 1 = 0.121214 loss)
I1124 11:02:48.050745  3844 sgd_solver.cpp:105] Iteration 27700, lr = 1e-07
I1124 11:03:00.287873  3844 solver.cpp:218] Iteration 27800 (8.17214 iter/s, 12.2367s/100 iters), loss = 0.103578
I1124 11:03:00.287873  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 11:03:00.287873  3844 solver.cpp:237]     Train net output #1: loss = 0.103578 (* 1 = 0.103578 loss)
I1124 11:03:00.287873  3844 sgd_solver.cpp:105] Iteration 27800, lr = 1e-07
I1124 11:03:12.545816  3844 solver.cpp:218] Iteration 27900 (8.15847 iter/s, 12.2572s/100 iters), loss = 0.0612252
I1124 11:03:12.545816  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 11:03:12.546315  3844 solver.cpp:237]     Train net output #1: loss = 0.0612247 (* 1 = 0.0612247 loss)
I1124 11:03:12.546315  3844 sgd_solver.cpp:105] Iteration 27900, lr = 1e-07
I1124 11:03:24.283540 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:03:24.767062  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_28000.caffemodel
I1124 11:03:24.807101  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_28000.solverstate
I1124 11:03:24.826597  3844 solver.cpp:330] Iteration 28000, Testing net (#0)
I1124 11:03:24.826597  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 11:03:28.950099   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:03:29.118119  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8905
I1124 11:03:29.118616  3844 solver.cpp:397]     Test net output #1: loss = 0.348044 (* 1 = 0.348044 loss)
I1124 11:03:29.237596  3844 solver.cpp:218] Iteration 28000 (5.99137 iter/s, 16.6907s/100 iters), loss = 0.098829
I1124 11:03:29.237596  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 11:03:29.237596  3844 solver.cpp:237]     Train net output #1: loss = 0.0988286 (* 1 = 0.0988286 loss)
I1124 11:03:29.237596  3844 sgd_solver.cpp:105] Iteration 28000, lr = 1e-07
I1124 11:03:41.475039  3844 solver.cpp:218] Iteration 28100 (8.172 iter/s, 12.2369s/100 iters), loss = 0.122117
I1124 11:03:41.475039  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 11:03:41.475039  3844 solver.cpp:237]     Train net output #1: loss = 0.122117 (* 1 = 0.122117 loss)
I1124 11:03:41.475039  3844 sgd_solver.cpp:105] Iteration 28100, lr = 1e-07
I1124 11:03:53.725793  3844 solver.cpp:218] Iteration 28200 (8.16335 iter/s, 12.2499s/100 iters), loss = 0.102973
I1124 11:03:53.725793  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 11:03:53.725793  3844 solver.cpp:237]     Train net output #1: loss = 0.102973 (* 1 = 0.102973 loss)
I1124 11:03:53.725793  3844 sgd_solver.cpp:105] Iteration 28200, lr = 1e-07
I1124 11:04:05.949595  3844 solver.cpp:218] Iteration 28300 (8.18112 iter/s, 12.2233s/100 iters), loss = 0.15487
I1124 11:04:05.949595  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 11:04:05.949595  3844 solver.cpp:237]     Train net output #1: loss = 0.154869 (* 1 = 0.154869 loss)
I1124 11:04:05.949595  3844 sgd_solver.cpp:105] Iteration 28300, lr = 1e-07
I1124 11:04:18.007802  3844 solver.cpp:218] Iteration 28400 (8.29363 iter/s, 12.0574s/100 iters), loss = 0.0627423
I1124 11:04:18.007802  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1124 11:04:18.007802  3844 solver.cpp:237]     Train net output #1: loss = 0.0627418 (* 1 = 0.0627418 loss)
I1124 11:04:18.007802  3844 sgd_solver.cpp:105] Iteration 28400, lr = 1e-07
I1124 11:04:29.465978 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:04:29.942999  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_28500.caffemodel
I1124 11:04:30.004556  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_28500.solverstate
I1124 11:04:30.023540  3844 solver.cpp:330] Iteration 28500, Testing net (#0)
I1124 11:04:30.023540  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 11:04:34.030982   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:04:34.194032  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8904
I1124 11:04:34.194032  3844 solver.cpp:397]     Test net output #1: loss = 0.34813 (* 1 = 0.34813 loss)
I1124 11:04:34.311074  3844 solver.cpp:218] Iteration 28500 (6.13372 iter/s, 16.3033s/100 iters), loss = 0.115192
I1124 11:04:34.311074  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 11:04:34.312075  3844 solver.cpp:237]     Train net output #1: loss = 0.115191 (* 1 = 0.115191 loss)
I1124 11:04:34.312075  3844 sgd_solver.cpp:105] Iteration 28500, lr = 1e-07
I1124 11:04:46.370867  3844 solver.cpp:218] Iteration 28600 (8.29273 iter/s, 12.0588s/100 iters), loss = 0.130666
I1124 11:04:46.370867  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1124 11:04:46.370867  3844 solver.cpp:237]     Train net output #1: loss = 0.130665 (* 1 = 0.130665 loss)
I1124 11:04:46.370867  3844 sgd_solver.cpp:105] Iteration 28600, lr = 1e-07
I1124 11:04:58.430531  3844 solver.cpp:218] Iteration 28700 (8.2928 iter/s, 12.0587s/100 iters), loss = 0.0879006
I1124 11:04:58.430531  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 11:04:58.430531  3844 solver.cpp:237]     Train net output #1: loss = 0.0879002 (* 1 = 0.0879002 loss)
I1124 11:04:58.430531  3844 sgd_solver.cpp:105] Iteration 28700, lr = 1e-07
I1124 11:05:10.484895  3844 solver.cpp:218] Iteration 28800 (8.29616 iter/s, 12.0538s/100 iters), loss = 0.139371
I1124 11:05:10.484895  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 11:05:10.484895  3844 solver.cpp:237]     Train net output #1: loss = 0.139371 (* 1 = 0.139371 loss)
I1124 11:05:10.484895  3844 sgd_solver.cpp:105] Iteration 28800, lr = 1e-07
I1124 11:05:22.544270  3844 solver.cpp:218] Iteration 28900 (8.29258 iter/s, 12.059s/100 iters), loss = 0.0706526
I1124 11:05:22.544270  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 11:05:22.544270  3844 solver.cpp:237]     Train net output #1: loss = 0.0706521 (* 1 = 0.0706521 loss)
I1124 11:05:22.544270  3844 sgd_solver.cpp:105] Iteration 28900, lr = 1e-07
I1124 11:05:34.001693 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:05:34.482825  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_29000.caffemodel
I1124 11:05:34.519847  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_29000.solverstate
I1124 11:05:34.561897  3844 solver.cpp:330] Iteration 29000, Testing net (#0)
I1124 11:05:34.561897  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 11:05:38.566833   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:05:38.730890  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8905
I1124 11:05:38.731405  3844 solver.cpp:397]     Test net output #1: loss = 0.348077 (* 1 = 0.348077 loss)
I1124 11:05:38.848436  3844 solver.cpp:218] Iteration 29000 (6.13369 iter/s, 16.3034s/100 iters), loss = 0.114725
I1124 11:05:38.848436  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 11:05:38.848436  3844 solver.cpp:237]     Train net output #1: loss = 0.114725 (* 1 = 0.114725 loss)
I1124 11:05:38.848436  3844 sgd_solver.cpp:105] Iteration 29000, lr = 1e-07
I1124 11:05:50.908087  3844 solver.cpp:218] Iteration 29100 (8.29248 iter/s, 12.0591s/100 iters), loss = 0.0935434
I1124 11:05:50.908087  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 11:05:50.908087  3844 solver.cpp:237]     Train net output #1: loss = 0.093543 (* 1 = 0.093543 loss)
I1124 11:05:50.908087  3844 sgd_solver.cpp:105] Iteration 29100, lr = 1e-07
I1124 11:06:02.961410  3844 solver.cpp:218] Iteration 29200 (8.29688 iter/s, 12.0527s/100 iters), loss = 0.150834
I1124 11:06:02.961410  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 11:06:02.961410  3844 solver.cpp:237]     Train net output #1: loss = 0.150834 (* 1 = 0.150834 loss)
I1124 11:06:02.961410  3844 sgd_solver.cpp:105] Iteration 29200, lr = 1e-07
I1124 11:06:15.022433  3844 solver.cpp:218] Iteration 29300 (8.29148 iter/s, 12.0606s/100 iters), loss = 0.161105
I1124 11:06:15.022433  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 11:06:15.022433  3844 solver.cpp:237]     Train net output #1: loss = 0.161105 (* 1 = 0.161105 loss)
I1124 11:06:15.022433  3844 sgd_solver.cpp:105] Iteration 29300, lr = 1e-07
I1124 11:06:27.078097  3844 solver.cpp:218] Iteration 29400 (8.29535 iter/s, 12.055s/100 iters), loss = 0.0655717
I1124 11:06:27.078097  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1124 11:06:27.078097  3844 solver.cpp:237]     Train net output #1: loss = 0.0655713 (* 1 = 0.0655713 loss)
I1124 11:06:27.078097  3844 sgd_solver.cpp:105] Iteration 29400, lr = 1e-07
I1124 11:06:38.536519 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:06:39.016105  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_29500.caffemodel
I1124 11:06:39.080646  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_29500.solverstate
I1124 11:06:39.099663  3844 solver.cpp:330] Iteration 29500, Testing net (#0)
I1124 11:06:39.099663  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 11:06:43.098021   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:06:43.262953  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8905
I1124 11:06:43.262953  3844 solver.cpp:397]     Test net output #1: loss = 0.34802 (* 1 = 0.34802 loss)
I1124 11:06:43.379988  3844 solver.cpp:218] Iteration 29500 (6.13443 iter/s, 16.3014s/100 iters), loss = 0.115872
I1124 11:06:43.379988  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 11:06:43.379988  3844 solver.cpp:237]     Train net output #1: loss = 0.115871 (* 1 = 0.115871 loss)
I1124 11:06:43.379988  3844 sgd_solver.cpp:105] Iteration 29500, lr = 1e-07
I1124 11:06:55.436738  3844 solver.cpp:218] Iteration 29600 (8.29475 iter/s, 12.0558s/100 iters), loss = 0.0905793
I1124 11:06:55.436738  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1124 11:06:55.436738  3844 solver.cpp:237]     Train net output #1: loss = 0.0905789 (* 1 = 0.0905789 loss)
I1124 11:06:55.436738  3844 sgd_solver.cpp:105] Iteration 29600, lr = 1e-07
I1124 11:07:07.486018  3844 solver.cpp:218] Iteration 29700 (8.29975 iter/s, 12.0486s/100 iters), loss = 0.113012
I1124 11:07:07.486018  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1124 11:07:07.486018  3844 solver.cpp:237]     Train net output #1: loss = 0.113012 (* 1 = 0.113012 loss)
I1124 11:07:07.486018  3844 sgd_solver.cpp:105] Iteration 29700, lr = 1e-07
I1124 11:07:19.542510  3844 solver.cpp:218] Iteration 29800 (8.29429 iter/s, 12.0565s/100 iters), loss = 0.144129
I1124 11:07:19.542510  3844 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1124 11:07:19.542510  3844 solver.cpp:237]     Train net output #1: loss = 0.144129 (* 1 = 0.144129 loss)
I1124 11:07:19.542510  3844 sgd_solver.cpp:105] Iteration 29800, lr = 1e-07
I1124 11:07:31.599752  3844 solver.cpp:218] Iteration 29900 (8.2946 iter/s, 12.056s/100 iters), loss = 0.0523114
I1124 11:07:31.599752  3844 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1124 11:07:31.599752  3844 solver.cpp:237]     Train net output #1: loss = 0.052311 (* 1 = 0.052311 loss)
I1124 11:07:31.599752  3844 sgd_solver.cpp:105] Iteration 29900, lr = 1e-07
I1124 11:07:43.061774 14536 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:07:43.541797  3844 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_30000.caffemodel
I1124 11:07:43.583302  3844 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1.6M_8L_7x7_v2_iter_30000.solverstate
I1124 11:07:43.646302  3844 solver.cpp:310] Iteration 30000, loss = 0.132935
I1124 11:07:43.646302  3844 solver.cpp:330] Iteration 30000, Testing net (#0)
I1124 11:07:43.646302  3844 net.cpp:676] Ignoring source layer accuracy_training
I1124 11:07:47.651489   136 data_layer.cpp:73] Restarting data prefetching from start.
I1124 11:07:47.815572  3844 solver.cpp:397]     Test net output #0: accuracy = 0.8906
I1124 11:07:47.815572  3844 solver.cpp:397]     Test net output #1: loss = 0.348046 (* 1 = 0.348046 loss)
I1124 11:07:47.815572  3844 solver.cpp:315] Optimization Done.
I1124 11:07:47.815572  3844 caffe.cpp:260] Optimization Done.

G:\Caffe>pause
Press any key to continue . . . 
