
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0314 11:46:28.785665 16588 caffe.cpp:218] Using GPUs 0
I0314 11:46:28.959699 16588 caffe.cpp:223] GPU 0: GeForce GTX 980
I0314 11:46:29.237787 16588 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0314 11:46:29.237787 16588 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar10_slim_baseline"
solver_mode: GPU
device_id: 0
random_seed: 1705
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 220000
stepvalue: 295000
stepvalue: 320000
stepvalue: 270000
type: "AdaDelta"
I0314 11:46:29.238786 16588 solver.cpp:91] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0314 11:46:29.238786 16588 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0314 11:46:29.238786 16588 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0314 11:46:29.238786 16588 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0314 11:46:29.239786 16588 net.cpp:58] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0314 11:46:29.245800 16588 layer_factory.cpp:58] Creating layer cifar
I0314 11:46:29.246800 16588 net.cpp:100] Creating Layer cifar
I0314 11:46:29.246800 16588 net.cpp:408] cifar -> data
I0314 11:46:29.246800 16588 net.cpp:408] cifar -> label
I0314 11:46:29.246800 16588 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0314 11:46:29.250800 14392 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0314 11:46:29.257786 14392 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0314 11:46:29.268290 16588 data_layer.cpp:41] output data size: 100,3,32,32
I0314 11:46:29.271790 16588 net.cpp:150] Setting up cifar
I0314 11:46:29.271790 16588 net.cpp:157] Top shape: 100 3 32 32 (307200)
I0314 11:46:29.271790 16588 net.cpp:157] Top shape: 100 (100)
I0314 11:46:29.271790 16588 net.cpp:165] Memory required for data: 1229200
I0314 11:46:29.271790 16588 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0314 11:46:29.271790 16588 net.cpp:100] Creating Layer label_cifar_1_split
I0314 11:46:29.271790 16588 net.cpp:434] label_cifar_1_split <- label
I0314 11:46:29.271790 16588 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_0
I0314 11:46:29.271790 16588 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_1
I0314 11:46:29.271790 16588 net.cpp:150] Setting up label_cifar_1_split
I0314 11:46:29.271790 16588 net.cpp:157] Top shape: 100 (100)
I0314 11:46:29.271790 16588 net.cpp:157] Top shape: 100 (100)
I0314 11:46:29.271790 16588 net.cpp:165] Memory required for data: 1230000
I0314 11:46:29.271790 16588 layer_factory.cpp:58] Creating layer conv1
I0314 11:46:29.271790 16588 net.cpp:100] Creating Layer conv1
I0314 11:46:29.271790 16588 net.cpp:434] conv1 <- data
I0314 11:46:29.271790 16588 net.cpp:408] conv1 -> conv1
I0314 11:46:29.272790  3876 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0314 11:46:29.505614 16588 net.cpp:150] Setting up conv1
I0314 11:46:29.505614 16588 net.cpp:157] Top shape: 100 64 32 32 (6553600)
I0314 11:46:29.505614 16588 net.cpp:165] Memory required for data: 27444400
I0314 11:46:29.505614 16588 layer_factory.cpp:58] Creating layer bn1
I0314 11:46:29.505614 16588 net.cpp:100] Creating Layer bn1
I0314 11:46:29.505614 16588 net.cpp:434] bn1 <- conv1
I0314 11:46:29.505614 16588 net.cpp:408] bn1 -> bn1
I0314 11:46:29.506603 16588 net.cpp:150] Setting up bn1
I0314 11:46:29.506603 16588 net.cpp:157] Top shape: 100 64 32 32 (6553600)
I0314 11:46:29.506603 16588 net.cpp:165] Memory required for data: 53658800
I0314 11:46:29.506603 16588 layer_factory.cpp:58] Creating layer scale1
I0314 11:46:29.506603 16588 net.cpp:100] Creating Layer scale1
I0314 11:46:29.506603 16588 net.cpp:434] scale1 <- bn1
I0314 11:46:29.506603 16588 net.cpp:408] scale1 -> scale1
I0314 11:46:29.506603 16588 layer_factory.cpp:58] Creating layer scale1
I0314 11:46:29.506603 16588 net.cpp:150] Setting up scale1
I0314 11:46:29.506603 16588 net.cpp:157] Top shape: 100 64 32 32 (6553600)
I0314 11:46:29.506603 16588 net.cpp:165] Memory required for data: 79873200
I0314 11:46:29.506603 16588 layer_factory.cpp:58] Creating layer relu1
I0314 11:46:29.506603 16588 net.cpp:100] Creating Layer relu1
I0314 11:46:29.506603 16588 net.cpp:434] relu1 <- scale1
I0314 11:46:29.506603 16588 net.cpp:408] relu1 -> relu1
I0314 11:46:29.506603 16588 net.cpp:150] Setting up relu1
I0314 11:46:29.506603 16588 net.cpp:157] Top shape: 100 64 32 32 (6553600)
I0314 11:46:29.506603 16588 net.cpp:165] Memory required for data: 106087600
I0314 11:46:29.506603 16588 layer_factory.cpp:58] Creating layer conv1_0
I0314 11:46:29.506603 16588 net.cpp:100] Creating Layer conv1_0
I0314 11:46:29.506603 16588 net.cpp:434] conv1_0 <- relu1
I0314 11:46:29.506603 16588 net.cpp:408] conv1_0 -> conv1_0
I0314 11:46:29.509588 16588 net.cpp:150] Setting up conv1_0
I0314 11:46:29.509588 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.509588 16588 net.cpp:165] Memory required for data: 119194800
I0314 11:46:29.509588 16588 layer_factory.cpp:58] Creating layer bn1_0
I0314 11:46:29.509588 16588 net.cpp:100] Creating Layer bn1_0
I0314 11:46:29.509588 16588 net.cpp:434] bn1_0 <- conv1_0
I0314 11:46:29.509588 16588 net.cpp:408] bn1_0 -> bn1_0
I0314 11:46:29.509588 16588 net.cpp:150] Setting up bn1_0
I0314 11:46:29.509588 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.509588 16588 net.cpp:165] Memory required for data: 132302000
I0314 11:46:29.509588 16588 layer_factory.cpp:58] Creating layer scale1_0
I0314 11:46:29.509588 16588 net.cpp:100] Creating Layer scale1_0
I0314 11:46:29.509588 16588 net.cpp:434] scale1_0 <- bn1_0
I0314 11:46:29.509588 16588 net.cpp:408] scale1_0 -> scale1_0
I0314 11:46:29.509588 16588 layer_factory.cpp:58] Creating layer scale1_0
I0314 11:46:29.510592 16588 net.cpp:150] Setting up scale1_0
I0314 11:46:29.510592 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.510592 16588 net.cpp:165] Memory required for data: 145409200
I0314 11:46:29.510592 16588 layer_factory.cpp:58] Creating layer relu1_0
I0314 11:46:29.510592 16588 net.cpp:100] Creating Layer relu1_0
I0314 11:46:29.510592 16588 net.cpp:434] relu1_0 <- scale1_0
I0314 11:46:29.510592 16588 net.cpp:408] relu1_0 -> relu1_0
I0314 11:46:29.510592 16588 net.cpp:150] Setting up relu1_0
I0314 11:46:29.510592 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.510592 16588 net.cpp:165] Memory required for data: 158516400
I0314 11:46:29.510592 16588 layer_factory.cpp:58] Creating layer conv2
I0314 11:46:29.510592 16588 net.cpp:100] Creating Layer conv2
I0314 11:46:29.510592 16588 net.cpp:434] conv2 <- relu1_0
I0314 11:46:29.510592 16588 net.cpp:408] conv2 -> conv2
I0314 11:46:29.512590 16588 net.cpp:150] Setting up conv2
I0314 11:46:29.512590 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.512590 16588 net.cpp:165] Memory required for data: 171623600
I0314 11:46:29.512590 16588 layer_factory.cpp:58] Creating layer bn2
I0314 11:46:29.512590 16588 net.cpp:100] Creating Layer bn2
I0314 11:46:29.512590 16588 net.cpp:434] bn2 <- conv2
I0314 11:46:29.512590 16588 net.cpp:408] bn2 -> bn2
I0314 11:46:29.512590 16588 net.cpp:150] Setting up bn2
I0314 11:46:29.512590 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.512590 16588 net.cpp:165] Memory required for data: 184730800
I0314 11:46:29.512590 16588 layer_factory.cpp:58] Creating layer scale2
I0314 11:46:29.512590 16588 net.cpp:100] Creating Layer scale2
I0314 11:46:29.512590 16588 net.cpp:434] scale2 <- bn2
I0314 11:46:29.512590 16588 net.cpp:408] scale2 -> scale2
I0314 11:46:29.512590 16588 layer_factory.cpp:58] Creating layer scale2
I0314 11:46:29.512590 16588 net.cpp:150] Setting up scale2
I0314 11:46:29.512590 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.513607 16588 net.cpp:165] Memory required for data: 197838000
I0314 11:46:29.513607 16588 layer_factory.cpp:58] Creating layer relu2
I0314 11:46:29.513607 16588 net.cpp:100] Creating Layer relu2
I0314 11:46:29.513607 16588 net.cpp:434] relu2 <- scale2
I0314 11:46:29.513607 16588 net.cpp:408] relu2 -> relu2
I0314 11:46:29.513607 16588 net.cpp:150] Setting up relu2
I0314 11:46:29.513607 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.513607 16588 net.cpp:165] Memory required for data: 210945200
I0314 11:46:29.513607 16588 layer_factory.cpp:58] Creating layer conv2_1
I0314 11:46:29.513607 16588 net.cpp:100] Creating Layer conv2_1
I0314 11:46:29.513607 16588 net.cpp:434] conv2_1 <- relu2
I0314 11:46:29.513607 16588 net.cpp:408] conv2_1 -> conv2_1
I0314 11:46:29.515599 16588 net.cpp:150] Setting up conv2_1
I0314 11:46:29.515599 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.515599 16588 net.cpp:165] Memory required for data: 224052400
I0314 11:46:29.515599 16588 layer_factory.cpp:58] Creating layer bn2_1
I0314 11:46:29.515599 16588 net.cpp:100] Creating Layer bn2_1
I0314 11:46:29.515599 16588 net.cpp:434] bn2_1 <- conv2_1
I0314 11:46:29.515599 16588 net.cpp:408] bn2_1 -> bn2_1
I0314 11:46:29.515599 16588 net.cpp:150] Setting up bn2_1
I0314 11:46:29.515599 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.515599 16588 net.cpp:165] Memory required for data: 237159600
I0314 11:46:29.515599 16588 layer_factory.cpp:58] Creating layer scale2_1
I0314 11:46:29.515599 16588 net.cpp:100] Creating Layer scale2_1
I0314 11:46:29.515599 16588 net.cpp:434] scale2_1 <- bn2_1
I0314 11:46:29.515599 16588 net.cpp:408] scale2_1 -> scale2_1
I0314 11:46:29.515599 16588 layer_factory.cpp:58] Creating layer scale2_1
I0314 11:46:29.515599 16588 net.cpp:150] Setting up scale2_1
I0314 11:46:29.515599 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.515599 16588 net.cpp:165] Memory required for data: 250266800
I0314 11:46:29.515599 16588 layer_factory.cpp:58] Creating layer relu2_1
I0314 11:46:29.515599 16588 net.cpp:100] Creating Layer relu2_1
I0314 11:46:29.515599 16588 net.cpp:434] relu2_1 <- scale2_1
I0314 11:46:29.515599 16588 net.cpp:408] relu2_1 -> relu2_1
I0314 11:46:29.516618 16588 net.cpp:150] Setting up relu2_1
I0314 11:46:29.516618 16588 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0314 11:46:29.516618 16588 net.cpp:165] Memory required for data: 263374000
I0314 11:46:29.516618 16588 layer_factory.cpp:58] Creating layer pool2_1
I0314 11:46:29.516618 16588 net.cpp:100] Creating Layer pool2_1
I0314 11:46:29.516618 16588 net.cpp:434] pool2_1 <- relu2_1
I0314 11:46:29.516618 16588 net.cpp:408] pool2_1 -> pool2_1
I0314 11:46:29.516618 16588 net.cpp:150] Setting up pool2_1
I0314 11:46:29.516618 16588 net.cpp:157] Top shape: 100 32 16 16 (819200)
I0314 11:46:29.516618 16588 net.cpp:165] Memory required for data: 266650800
I0314 11:46:29.516618 16588 layer_factory.cpp:58] Creating layer conv2_2
I0314 11:46:29.516618 16588 net.cpp:100] Creating Layer conv2_2
I0314 11:46:29.516618 16588 net.cpp:434] conv2_2 <- pool2_1
I0314 11:46:29.516618 16588 net.cpp:408] conv2_2 -> conv2_2
I0314 11:46:29.518597 16588 net.cpp:150] Setting up conv2_2
I0314 11:46:29.518597 16588 net.cpp:157] Top shape: 100 32 16 16 (819200)
I0314 11:46:29.518597 16588 net.cpp:165] Memory required for data: 269927600
I0314 11:46:29.518597 16588 layer_factory.cpp:58] Creating layer bn2_2
I0314 11:46:29.518597 16588 net.cpp:100] Creating Layer bn2_2
I0314 11:46:29.518597 16588 net.cpp:434] bn2_2 <- conv2_2
I0314 11:46:29.518597 16588 net.cpp:408] bn2_2 -> bn2_2
I0314 11:46:29.518597 16588 net.cpp:150] Setting up bn2_2
I0314 11:46:29.518597 16588 net.cpp:157] Top shape: 100 32 16 16 (819200)
I0314 11:46:29.518597 16588 net.cpp:165] Memory required for data: 273204400
I0314 11:46:29.518597 16588 layer_factory.cpp:58] Creating layer scale2_2
I0314 11:46:29.518597 16588 net.cpp:100] Creating Layer scale2_2
I0314 11:46:29.518597 16588 net.cpp:434] scale2_2 <- bn2_2
I0314 11:46:29.518597 16588 net.cpp:408] scale2_2 -> scale2_2
I0314 11:46:29.518597 16588 layer_factory.cpp:58] Creating layer scale2_2
I0314 11:46:29.518597 16588 net.cpp:150] Setting up scale2_2
I0314 11:46:29.518597 16588 net.cpp:157] Top shape: 100 32 16 16 (819200)
I0314 11:46:29.518597 16588 net.cpp:165] Memory required for data: 276481200
I0314 11:46:29.518597 16588 layer_factory.cpp:58] Creating layer relu2_2
I0314 11:46:29.518597 16588 net.cpp:100] Creating Layer relu2_2
I0314 11:46:29.518597 16588 net.cpp:434] relu2_2 <- scale2_2
I0314 11:46:29.518597 16588 net.cpp:408] relu2_2 -> relu2_2
I0314 11:46:29.518597 16588 net.cpp:150] Setting up relu2_2
I0314 11:46:29.518597 16588 net.cpp:157] Top shape: 100 32 16 16 (819200)
I0314 11:46:29.518597 16588 net.cpp:165] Memory required for data: 279758000
I0314 11:46:29.518597 16588 layer_factory.cpp:58] Creating layer conv3
I0314 11:46:29.518597 16588 net.cpp:100] Creating Layer conv3
I0314 11:46:29.518597 16588 net.cpp:434] conv3 <- relu2_2
I0314 11:46:29.518597 16588 net.cpp:408] conv3 -> conv3
I0314 11:46:29.520587 16588 net.cpp:150] Setting up conv3
I0314 11:46:29.520587 16588 net.cpp:157] Top shape: 100 32 16 16 (819200)
I0314 11:46:29.520587 16588 net.cpp:165] Memory required for data: 283034800
I0314 11:46:29.520587 16588 layer_factory.cpp:58] Creating layer bn3
I0314 11:46:29.520587 16588 net.cpp:100] Creating Layer bn3
I0314 11:46:29.520587 16588 net.cpp:434] bn3 <- conv3
I0314 11:46:29.520587 16588 net.cpp:408] bn3 -> bn3
I0314 11:46:29.520587 16588 net.cpp:150] Setting up bn3
I0314 11:46:29.520587 16588 net.cpp:157] Top shape: 100 32 16 16 (819200)
I0314 11:46:29.520587 16588 net.cpp:165] Memory required for data: 286311600
I0314 11:46:29.520587 16588 layer_factory.cpp:58] Creating layer scale3
I0314 11:46:29.520587 16588 net.cpp:100] Creating Layer scale3
I0314 11:46:29.520587 16588 net.cpp:434] scale3 <- bn3
I0314 11:46:29.520587 16588 net.cpp:408] scale3 -> scale3
I0314 11:46:29.520587 16588 layer_factory.cpp:58] Creating layer scale3
I0314 11:46:29.520587 16588 net.cpp:150] Setting up scale3
I0314 11:46:29.520587 16588 net.cpp:157] Top shape: 100 32 16 16 (819200)
I0314 11:46:29.520587 16588 net.cpp:165] Memory required for data: 289588400
I0314 11:46:29.520587 16588 layer_factory.cpp:58] Creating layer relu3
I0314 11:46:29.520587 16588 net.cpp:100] Creating Layer relu3
I0314 11:46:29.520587 16588 net.cpp:434] relu3 <- scale3
I0314 11:46:29.520587 16588 net.cpp:408] relu3 -> relu3
I0314 11:46:29.520587 16588 net.cpp:150] Setting up relu3
I0314 11:46:29.520587 16588 net.cpp:157] Top shape: 100 32 16 16 (819200)
I0314 11:46:29.520587 16588 net.cpp:165] Memory required for data: 292865200
I0314 11:46:29.520587 16588 layer_factory.cpp:58] Creating layer conv4
I0314 11:46:29.520587 16588 net.cpp:100] Creating Layer conv4
I0314 11:46:29.520587 16588 net.cpp:434] conv4 <- relu3
I0314 11:46:29.520587 16588 net.cpp:408] conv4 -> conv4
I0314 11:46:29.523587 16588 net.cpp:150] Setting up conv4
I0314 11:46:29.523587 16588 net.cpp:157] Top shape: 100 64 16 16 (1638400)
I0314 11:46:29.523587 16588 net.cpp:165] Memory required for data: 299418800
I0314 11:46:29.523587 16588 layer_factory.cpp:58] Creating layer pool4
I0314 11:46:29.523587 16588 net.cpp:100] Creating Layer pool4
I0314 11:46:29.523587 16588 net.cpp:434] pool4 <- conv4
I0314 11:46:29.523587 16588 net.cpp:408] pool4 -> pool4
I0314 11:46:29.523587 16588 net.cpp:150] Setting up pool4
I0314 11:46:29.523587 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.523587 16588 net.cpp:165] Memory required for data: 301057200
I0314 11:46:29.523587 16588 layer_factory.cpp:58] Creating layer bn4
I0314 11:46:29.523587 16588 net.cpp:100] Creating Layer bn4
I0314 11:46:29.523587 16588 net.cpp:434] bn4 <- pool4
I0314 11:46:29.523587 16588 net.cpp:408] bn4 -> bn4
I0314 11:46:29.523587 16588 net.cpp:150] Setting up bn4
I0314 11:46:29.523587 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.523587 16588 net.cpp:165] Memory required for data: 302695600
I0314 11:46:29.523587 16588 layer_factory.cpp:58] Creating layer scale4
I0314 11:46:29.523587 16588 net.cpp:100] Creating Layer scale4
I0314 11:46:29.523587 16588 net.cpp:434] scale4 <- bn4
I0314 11:46:29.523587 16588 net.cpp:408] scale4 -> scale4
I0314 11:46:29.523587 16588 layer_factory.cpp:58] Creating layer scale4
I0314 11:46:29.523587 16588 net.cpp:150] Setting up scale4
I0314 11:46:29.523587 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.523587 16588 net.cpp:165] Memory required for data: 304334000
I0314 11:46:29.523587 16588 layer_factory.cpp:58] Creating layer relu4
I0314 11:46:29.523587 16588 net.cpp:100] Creating Layer relu4
I0314 11:46:29.523587 16588 net.cpp:434] relu4 <- scale4
I0314 11:46:29.523587 16588 net.cpp:408] relu4 -> relu4
I0314 11:46:29.524598 16588 net.cpp:150] Setting up relu4
I0314 11:46:29.524598 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.524598 16588 net.cpp:165] Memory required for data: 305972400
I0314 11:46:29.524598 16588 layer_factory.cpp:58] Creating layer conv4_1
I0314 11:46:29.524598 16588 net.cpp:100] Creating Layer conv4_1
I0314 11:46:29.524598 16588 net.cpp:434] conv4_1 <- relu4
I0314 11:46:29.524598 16588 net.cpp:408] conv4_1 -> conv4_1
I0314 11:46:29.526588 16588 net.cpp:150] Setting up conv4_1
I0314 11:46:29.526588 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.526588 16588 net.cpp:165] Memory required for data: 307610800
I0314 11:46:29.526588 16588 layer_factory.cpp:58] Creating layer bn4_1
I0314 11:46:29.526588 16588 net.cpp:100] Creating Layer bn4_1
I0314 11:46:29.526588 16588 net.cpp:434] bn4_1 <- conv4_1
I0314 11:46:29.526588 16588 net.cpp:408] bn4_1 -> bn4_1
I0314 11:46:29.526588 16588 net.cpp:150] Setting up bn4_1
I0314 11:46:29.526588 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.526588 16588 net.cpp:165] Memory required for data: 309249200
I0314 11:46:29.526588 16588 layer_factory.cpp:58] Creating layer scale4_1
I0314 11:46:29.527590 16588 net.cpp:100] Creating Layer scale4_1
I0314 11:46:29.527590 16588 net.cpp:434] scale4_1 <- bn4_1
I0314 11:46:29.527590 16588 net.cpp:408] scale4_1 -> scale4_1
I0314 11:46:29.527590 16588 layer_factory.cpp:58] Creating layer scale4_1
I0314 11:46:29.527590 16588 net.cpp:150] Setting up scale4_1
I0314 11:46:29.527590 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.527590 16588 net.cpp:165] Memory required for data: 310887600
I0314 11:46:29.527590 16588 layer_factory.cpp:58] Creating layer relu4_1
I0314 11:46:29.527590 16588 net.cpp:100] Creating Layer relu4_1
I0314 11:46:29.527590 16588 net.cpp:434] relu4_1 <- scale4_1
I0314 11:46:29.527590 16588 net.cpp:408] relu4_1 -> relu4_1
I0314 11:46:29.527590 16588 net.cpp:150] Setting up relu4_1
I0314 11:46:29.527590 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.527590 16588 net.cpp:165] Memory required for data: 312526000
I0314 11:46:29.527590 16588 layer_factory.cpp:58] Creating layer conv4_2
I0314 11:46:29.527590 16588 net.cpp:100] Creating Layer conv4_2
I0314 11:46:29.527590 16588 net.cpp:434] conv4_2 <- relu4_1
I0314 11:46:29.527590 16588 net.cpp:408] conv4_2 -> conv4_2
I0314 11:46:29.530591 16588 net.cpp:150] Setting up conv4_2
I0314 11:46:29.530591 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.530591 16588 net.cpp:165] Memory required for data: 314164400
I0314 11:46:29.530591 16588 layer_factory.cpp:58] Creating layer bn4_2
I0314 11:46:29.530591 16588 net.cpp:100] Creating Layer bn4_2
I0314 11:46:29.530591 16588 net.cpp:434] bn4_2 <- conv4_2
I0314 11:46:29.530591 16588 net.cpp:408] bn4_2 -> bn4_2
I0314 11:46:29.530591 16588 net.cpp:150] Setting up bn4_2
I0314 11:46:29.530591 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.530591 16588 net.cpp:165] Memory required for data: 315802800
I0314 11:46:29.530591 16588 layer_factory.cpp:58] Creating layer scale4_2
I0314 11:46:29.530591 16588 net.cpp:100] Creating Layer scale4_2
I0314 11:46:29.530591 16588 net.cpp:434] scale4_2 <- bn4_2
I0314 11:46:29.530591 16588 net.cpp:408] scale4_2 -> scale4_2
I0314 11:46:29.530591 16588 layer_factory.cpp:58] Creating layer scale4_2
I0314 11:46:29.530591 16588 net.cpp:150] Setting up scale4_2
I0314 11:46:29.530591 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.530591 16588 net.cpp:165] Memory required for data: 317441200
I0314 11:46:29.530591 16588 layer_factory.cpp:58] Creating layer relu4_2
I0314 11:46:29.530591 16588 net.cpp:100] Creating Layer relu4_2
I0314 11:46:29.530591 16588 net.cpp:434] relu4_2 <- scale4_2
I0314 11:46:29.530591 16588 net.cpp:408] relu4_2 -> relu4_2
I0314 11:46:29.530591 16588 net.cpp:150] Setting up relu4_2
I0314 11:46:29.530591 16588 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0314 11:46:29.530591 16588 net.cpp:165] Memory required for data: 319079600
I0314 11:46:29.530591 16588 layer_factory.cpp:58] Creating layer pool4_2
I0314 11:46:29.530591 16588 net.cpp:100] Creating Layer pool4_2
I0314 11:46:29.530591 16588 net.cpp:434] pool4_2 <- relu4_2
I0314 11:46:29.531601 16588 net.cpp:408] pool4_2 -> pool4_2
I0314 11:46:29.531601 16588 net.cpp:150] Setting up pool4_2
I0314 11:46:29.531601 16588 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0314 11:46:29.531601 16588 net.cpp:165] Memory required for data: 319489200
I0314 11:46:29.531601 16588 layer_factory.cpp:58] Creating layer conv4_0
I0314 11:46:29.531601 16588 net.cpp:100] Creating Layer conv4_0
I0314 11:46:29.531601 16588 net.cpp:434] conv4_0 <- pool4_2
I0314 11:46:29.531601 16588 net.cpp:408] conv4_0 -> conv4_0
I0314 11:46:29.533602 16588 net.cpp:150] Setting up conv4_0
I0314 11:46:29.533602 16588 net.cpp:157] Top shape: 100 128 4 4 (204800)
I0314 11:46:29.533602 16588 net.cpp:165] Memory required for data: 320308400
I0314 11:46:29.533602 16588 layer_factory.cpp:58] Creating layer bn4_0
I0314 11:46:29.533602 16588 net.cpp:100] Creating Layer bn4_0
I0314 11:46:29.533602 16588 net.cpp:434] bn4_0 <- conv4_0
I0314 11:46:29.533602 16588 net.cpp:408] bn4_0 -> bn4_0
I0314 11:46:29.534588 16588 net.cpp:150] Setting up bn4_0
I0314 11:46:29.534588 16588 net.cpp:157] Top shape: 100 128 4 4 (204800)
I0314 11:46:29.534588 16588 net.cpp:165] Memory required for data: 321127600
I0314 11:46:29.534588 16588 layer_factory.cpp:58] Creating layer scale4_0
I0314 11:46:29.534588 16588 net.cpp:100] Creating Layer scale4_0
I0314 11:46:29.534588 16588 net.cpp:434] scale4_0 <- bn4_0
I0314 11:46:29.534588 16588 net.cpp:408] scale4_0 -> scale4_0
I0314 11:46:29.534588 16588 layer_factory.cpp:58] Creating layer scale4_0
I0314 11:46:29.534588 16588 net.cpp:150] Setting up scale4_0
I0314 11:46:29.534588 16588 net.cpp:157] Top shape: 100 128 4 4 (204800)
I0314 11:46:29.534588 16588 net.cpp:165] Memory required for data: 321946800
I0314 11:46:29.534588 16588 layer_factory.cpp:58] Creating layer relu4_0
I0314 11:46:29.534588 16588 net.cpp:100] Creating Layer relu4_0
I0314 11:46:29.534588 16588 net.cpp:434] relu4_0 <- scale4_0
I0314 11:46:29.534588 16588 net.cpp:408] relu4_0 -> relu4_0
I0314 11:46:29.534588 16588 net.cpp:150] Setting up relu4_0
I0314 11:46:29.534588 16588 net.cpp:157] Top shape: 100 128 4 4 (204800)
I0314 11:46:29.534588 16588 net.cpp:165] Memory required for data: 322766000
I0314 11:46:29.534588 16588 layer_factory.cpp:58] Creating layer cccp4
I0314 11:46:29.534588 16588 net.cpp:100] Creating Layer cccp4
I0314 11:46:29.534588 16588 net.cpp:434] cccp4 <- relu4_0
I0314 11:46:29.534588 16588 net.cpp:408] cccp4 -> cccp4
I0314 11:46:29.536589 16588 net.cpp:150] Setting up cccp4
I0314 11:46:29.536589 16588 net.cpp:157] Top shape: 100 256 4 4 (409600)
I0314 11:46:29.536589 16588 net.cpp:165] Memory required for data: 324404400
I0314 11:46:29.536589 16588 layer_factory.cpp:58] Creating layer relu_cccp4
I0314 11:46:29.536589 16588 net.cpp:100] Creating Layer relu_cccp4
I0314 11:46:29.536589 16588 net.cpp:434] relu_cccp4 <- cccp4
I0314 11:46:29.536589 16588 net.cpp:395] relu_cccp4 -> cccp4 (in-place)
I0314 11:46:29.537590 16588 net.cpp:150] Setting up relu_cccp4
I0314 11:46:29.537590 16588 net.cpp:157] Top shape: 100 256 4 4 (409600)
I0314 11:46:29.537590 16588 net.cpp:165] Memory required for data: 326042800
I0314 11:46:29.537590 16588 layer_factory.cpp:58] Creating layer cccp5
I0314 11:46:29.537590 16588 net.cpp:100] Creating Layer cccp5
I0314 11:46:29.537590 16588 net.cpp:434] cccp5 <- cccp4
I0314 11:46:29.537590 16588 net.cpp:408] cccp5 -> cccp5
I0314 11:46:29.538589 16588 net.cpp:150] Setting up cccp5
I0314 11:46:29.538589 16588 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0314 11:46:29.538589 16588 net.cpp:165] Memory required for data: 326452400
I0314 11:46:29.538589 16588 layer_factory.cpp:58] Creating layer relu_cccp5
I0314 11:46:29.538589 16588 net.cpp:100] Creating Layer relu_cccp5
I0314 11:46:29.538589 16588 net.cpp:434] relu_cccp5 <- cccp5
I0314 11:46:29.538589 16588 net.cpp:395] relu_cccp5 -> cccp5 (in-place)
I0314 11:46:29.538589 16588 net.cpp:150] Setting up relu_cccp5
I0314 11:46:29.538589 16588 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0314 11:46:29.538589 16588 net.cpp:165] Memory required for data: 326862000
I0314 11:46:29.538589 16588 layer_factory.cpp:58] Creating layer poolcp5
I0314 11:46:29.538589 16588 net.cpp:100] Creating Layer poolcp5
I0314 11:46:29.538589 16588 net.cpp:434] poolcp5 <- cccp5
I0314 11:46:29.538589 16588 net.cpp:408] poolcp5 -> poolcp5
I0314 11:46:29.539589 16588 net.cpp:150] Setting up poolcp5
I0314 11:46:29.539589 16588 net.cpp:157] Top shape: 100 64 2 2 (25600)
I0314 11:46:29.539589 16588 net.cpp:165] Memory required for data: 326964400
I0314 11:46:29.539589 16588 layer_factory.cpp:58] Creating layer cccp6
I0314 11:46:29.539589 16588 net.cpp:100] Creating Layer cccp6
I0314 11:46:29.539589 16588 net.cpp:434] cccp6 <- poolcp5
I0314 11:46:29.539589 16588 net.cpp:408] cccp6 -> cccp6
I0314 11:46:29.541589 16588 net.cpp:150] Setting up cccp6
I0314 11:46:29.541589 16588 net.cpp:157] Top shape: 100 64 2 2 (25600)
I0314 11:46:29.541589 16588 net.cpp:165] Memory required for data: 327066800
I0314 11:46:29.541589 16588 layer_factory.cpp:58] Creating layer relu_cccp6
I0314 11:46:29.541589 16588 net.cpp:100] Creating Layer relu_cccp6
I0314 11:46:29.541589 16588 net.cpp:434] relu_cccp6 <- cccp6
I0314 11:46:29.541589 16588 net.cpp:395] relu_cccp6 -> cccp6 (in-place)
I0314 11:46:29.541589 16588 net.cpp:150] Setting up relu_cccp6
I0314 11:46:29.541589 16588 net.cpp:157] Top shape: 100 64 2 2 (25600)
I0314 11:46:29.541589 16588 net.cpp:165] Memory required for data: 327169200
I0314 11:46:29.541589 16588 layer_factory.cpp:58] Creating layer poolcp6
I0314 11:46:29.541589 16588 net.cpp:100] Creating Layer poolcp6
I0314 11:46:29.541589 16588 net.cpp:434] poolcp6 <- cccp6
I0314 11:46:29.541589 16588 net.cpp:408] poolcp6 -> poolcp6
I0314 11:46:29.541589 16588 net.cpp:150] Setting up poolcp6
I0314 11:46:29.541589 16588 net.cpp:157] Top shape: 100 64 1 1 (6400)
I0314 11:46:29.541589 16588 net.cpp:165] Memory required for data: 327194800
I0314 11:46:29.541589 16588 layer_factory.cpp:58] Creating layer ip1
I0314 11:46:29.541589 16588 net.cpp:100] Creating Layer ip1
I0314 11:46:29.541589 16588 net.cpp:434] ip1 <- poolcp6
I0314 11:46:29.541589 16588 net.cpp:408] ip1 -> ip1
I0314 11:46:29.542587 16588 net.cpp:150] Setting up ip1
I0314 11:46:29.542587 16588 net.cpp:157] Top shape: 100 10 (1000)
I0314 11:46:29.542587 16588 net.cpp:165] Memory required for data: 327198800
I0314 11:46:29.542587 16588 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0314 11:46:29.542587 16588 net.cpp:100] Creating Layer ip1_ip1_0_split
I0314 11:46:29.542587 16588 net.cpp:434] ip1_ip1_0_split <- ip1
I0314 11:46:29.542587 16588 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0314 11:46:29.542587 16588 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0314 11:46:29.542587 16588 net.cpp:150] Setting up ip1_ip1_0_split
I0314 11:46:29.542587 16588 net.cpp:157] Top shape: 100 10 (1000)
I0314 11:46:29.542587 16588 net.cpp:157] Top shape: 100 10 (1000)
I0314 11:46:29.542587 16588 net.cpp:165] Memory required for data: 327206800
I0314 11:46:29.542587 16588 layer_factory.cpp:58] Creating layer accuracy_training
I0314 11:46:29.542587 16588 net.cpp:100] Creating Layer accuracy_training
I0314 11:46:29.542587 16588 net.cpp:434] accuracy_training <- ip1_ip1_0_split_0
I0314 11:46:29.542587 16588 net.cpp:434] accuracy_training <- label_cifar_1_split_0
I0314 11:46:29.542587 16588 net.cpp:408] accuracy_training -> accuracy_training
I0314 11:46:29.542587 16588 net.cpp:150] Setting up accuracy_training
I0314 11:46:29.542587 16588 net.cpp:157] Top shape: (1)
I0314 11:46:29.542587 16588 net.cpp:165] Memory required for data: 327206804
I0314 11:46:29.542587 16588 layer_factory.cpp:58] Creating layer loss
I0314 11:46:29.542587 16588 net.cpp:100] Creating Layer loss
I0314 11:46:29.542587 16588 net.cpp:434] loss <- ip1_ip1_0_split_1
I0314 11:46:29.542587 16588 net.cpp:434] loss <- label_cifar_1_split_1
I0314 11:46:29.542587 16588 net.cpp:408] loss -> loss
I0314 11:46:29.542587 16588 layer_factory.cpp:58] Creating layer loss
I0314 11:46:29.542587 16588 net.cpp:150] Setting up loss
I0314 11:46:29.542587 16588 net.cpp:157] Top shape: (1)
I0314 11:46:29.542587 16588 net.cpp:160]     with loss weight 1
I0314 11:46:29.542587 16588 net.cpp:165] Memory required for data: 327206808
I0314 11:46:29.542587 16588 net.cpp:226] loss needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:228] accuracy_training does not need backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] ip1 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] poolcp6 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] relu_cccp6 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] cccp6 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] poolcp5 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] relu_cccp5 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] cccp5 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] relu_cccp4 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] cccp4 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] relu4_0 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] scale4_0 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] bn4_0 needs backward computation.
I0314 11:46:29.542587 16588 net.cpp:226] conv4_0 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] pool4_2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] relu4_2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] scale4_2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] bn4_2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] conv4_2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] relu4_1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] scale4_1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] bn4_1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] conv4_1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] relu4 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] scale4 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] bn4 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] pool4 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] conv4 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] relu3 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] scale3 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] bn3 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] conv3 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] relu2_2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] scale2_2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] bn2_2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] conv2_2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] pool2_1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] relu2_1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] scale2_1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] bn2_1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] conv2_1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] relu2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] scale2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] bn2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] conv2 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] relu1_0 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] scale1_0 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] bn1_0 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] conv1_0 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] relu1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] scale1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] bn1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:226] conv1 needs backward computation.
I0314 11:46:29.543589 16588 net.cpp:228] label_cifar_1_split does not need backward computation.
I0314 11:46:29.543589 16588 net.cpp:228] cifar does not need backward computation.
I0314 11:46:29.543589 16588 net.cpp:270] This network produces output accuracy_training
I0314 11:46:29.543589 16588 net.cpp:270] This network produces output loss
I0314 11:46:29.543589 16588 net.cpp:283] Network initialization done.
I0314 11:46:29.544589 16588 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0314 11:46:29.544589 16588 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0314 11:46:29.544589 16588 solver.cpp:181] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0314 11:46:29.544589 16588 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0314 11:46:29.544589 16588 net.cpp:58] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0314 11:46:29.544589 16588 layer_factory.cpp:58] Creating layer cifar
I0314 11:46:29.545590 16588 net.cpp:100] Creating Layer cifar
I0314 11:46:29.545590 16588 net.cpp:408] cifar -> data
I0314 11:46:29.545590 16588 net.cpp:408] cifar -> label
I0314 11:46:29.545590 16588 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0314 11:46:29.546588 17736 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0314 11:46:29.550588 17736 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0314 11:46:29.550588 16588 data_layer.cpp:41] output data size: 50,3,32,32
I0314 11:46:29.557598 16588 net.cpp:150] Setting up cifar
I0314 11:46:29.557598 16588 net.cpp:157] Top shape: 50 3 32 32 (153600)
I0314 11:46:29.557598 16588 net.cpp:157] Top shape: 50 (50)
I0314 11:46:29.557598 16588 net.cpp:165] Memory required for data: 614600
I0314 11:46:29.557598 16588 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0314 11:46:29.557598 16588 net.cpp:100] Creating Layer label_cifar_1_split
I0314 11:46:29.557598 16588 net.cpp:434] label_cifar_1_split <- label
I0314 11:46:29.557598 16588 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_0
I0314 11:46:29.557598 16588 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_1
I0314 11:46:29.557598 16588 net.cpp:150] Setting up label_cifar_1_split
I0314 11:46:29.557598 16588 net.cpp:157] Top shape: 50 (50)
I0314 11:46:29.557598 16588 net.cpp:157] Top shape: 50 (50)
I0314 11:46:29.557598 16588 net.cpp:165] Memory required for data: 615000
I0314 11:46:29.557598 16588 layer_factory.cpp:58] Creating layer conv1
I0314 11:46:29.557598 16588 net.cpp:100] Creating Layer conv1
I0314 11:46:29.557598 16588 net.cpp:434] conv1 <- data
I0314 11:46:29.557598 16588 net.cpp:408] conv1 -> conv1
I0314 11:46:29.560600  7228 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0314 11:46:29.561589 16588 net.cpp:150] Setting up conv1
I0314 11:46:29.561589 16588 net.cpp:157] Top shape: 50 64 32 32 (3276800)
I0314 11:46:29.561589 16588 net.cpp:165] Memory required for data: 13722200
I0314 11:46:29.561589 16588 layer_factory.cpp:58] Creating layer bn1
I0314 11:46:29.561589 16588 net.cpp:100] Creating Layer bn1
I0314 11:46:29.561589 16588 net.cpp:434] bn1 <- conv1
I0314 11:46:29.561589 16588 net.cpp:408] bn1 -> bn1
I0314 11:46:29.561589 16588 net.cpp:150] Setting up bn1
I0314 11:46:29.561589 16588 net.cpp:157] Top shape: 50 64 32 32 (3276800)
I0314 11:46:29.561589 16588 net.cpp:165] Memory required for data: 26829400
I0314 11:46:29.561589 16588 layer_factory.cpp:58] Creating layer scale1
I0314 11:46:29.561589 16588 net.cpp:100] Creating Layer scale1
I0314 11:46:29.561589 16588 net.cpp:434] scale1 <- bn1
I0314 11:46:29.561589 16588 net.cpp:408] scale1 -> scale1
I0314 11:46:29.561589 16588 layer_factory.cpp:58] Creating layer scale1
I0314 11:46:29.561589 16588 net.cpp:150] Setting up scale1
I0314 11:46:29.561589 16588 net.cpp:157] Top shape: 50 64 32 32 (3276800)
I0314 11:46:29.561589 16588 net.cpp:165] Memory required for data: 39936600
I0314 11:46:29.561589 16588 layer_factory.cpp:58] Creating layer relu1
I0314 11:46:29.561589 16588 net.cpp:100] Creating Layer relu1
I0314 11:46:29.561589 16588 net.cpp:434] relu1 <- scale1
I0314 11:46:29.561589 16588 net.cpp:408] relu1 -> relu1
I0314 11:46:29.562589 16588 net.cpp:150] Setting up relu1
I0314 11:46:29.562589 16588 net.cpp:157] Top shape: 50 64 32 32 (3276800)
I0314 11:46:29.562589 16588 net.cpp:165] Memory required for data: 53043800
I0314 11:46:29.562589 16588 layer_factory.cpp:58] Creating layer conv1_0
I0314 11:46:29.562589 16588 net.cpp:100] Creating Layer conv1_0
I0314 11:46:29.562589 16588 net.cpp:434] conv1_0 <- relu1
I0314 11:46:29.562589 16588 net.cpp:408] conv1_0 -> conv1_0
I0314 11:46:29.565093 16588 net.cpp:150] Setting up conv1_0
I0314 11:46:29.565093 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.565093 16588 net.cpp:165] Memory required for data: 59597400
I0314 11:46:29.565093 16588 layer_factory.cpp:58] Creating layer bn1_0
I0314 11:46:29.565093 16588 net.cpp:100] Creating Layer bn1_0
I0314 11:46:29.565093 16588 net.cpp:434] bn1_0 <- conv1_0
I0314 11:46:29.565093 16588 net.cpp:408] bn1_0 -> bn1_0
I0314 11:46:29.565594 16588 net.cpp:150] Setting up bn1_0
I0314 11:46:29.565594 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.565594 16588 net.cpp:165] Memory required for data: 66151000
I0314 11:46:29.565594 16588 layer_factory.cpp:58] Creating layer scale1_0
I0314 11:46:29.565594 16588 net.cpp:100] Creating Layer scale1_0
I0314 11:46:29.565594 16588 net.cpp:434] scale1_0 <- bn1_0
I0314 11:46:29.565594 16588 net.cpp:408] scale1_0 -> scale1_0
I0314 11:46:29.565594 16588 layer_factory.cpp:58] Creating layer scale1_0
I0314 11:46:29.566093 16588 net.cpp:150] Setting up scale1_0
I0314 11:46:29.566093 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.566093 16588 net.cpp:165] Memory required for data: 72704600
I0314 11:46:29.566093 16588 layer_factory.cpp:58] Creating layer relu1_0
I0314 11:46:29.566093 16588 net.cpp:100] Creating Layer relu1_0
I0314 11:46:29.566093 16588 net.cpp:434] relu1_0 <- scale1_0
I0314 11:46:29.566093 16588 net.cpp:408] relu1_0 -> relu1_0
I0314 11:46:29.566593 16588 net.cpp:150] Setting up relu1_0
I0314 11:46:29.566593 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.566593 16588 net.cpp:165] Memory required for data: 79258200
I0314 11:46:29.566593 16588 layer_factory.cpp:58] Creating layer conv2
I0314 11:46:29.566593 16588 net.cpp:100] Creating Layer conv2
I0314 11:46:29.566593 16588 net.cpp:434] conv2 <- relu1_0
I0314 11:46:29.566593 16588 net.cpp:408] conv2 -> conv2
I0314 11:46:29.568094 16588 net.cpp:150] Setting up conv2
I0314 11:46:29.568094 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.568094 16588 net.cpp:165] Memory required for data: 85811800
I0314 11:46:29.568094 16588 layer_factory.cpp:58] Creating layer bn2
I0314 11:46:29.568094 16588 net.cpp:100] Creating Layer bn2
I0314 11:46:29.568094 16588 net.cpp:434] bn2 <- conv2
I0314 11:46:29.568094 16588 net.cpp:408] bn2 -> bn2
I0314 11:46:29.568593 16588 net.cpp:150] Setting up bn2
I0314 11:46:29.568593 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.568593 16588 net.cpp:165] Memory required for data: 92365400
I0314 11:46:29.568593 16588 layer_factory.cpp:58] Creating layer scale2
I0314 11:46:29.568593 16588 net.cpp:100] Creating Layer scale2
I0314 11:46:29.568593 16588 net.cpp:434] scale2 <- bn2
I0314 11:46:29.568593 16588 net.cpp:408] scale2 -> scale2
I0314 11:46:29.568593 16588 layer_factory.cpp:58] Creating layer scale2
I0314 11:46:29.568593 16588 net.cpp:150] Setting up scale2
I0314 11:46:29.568593 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.568593 16588 net.cpp:165] Memory required for data: 98919000
I0314 11:46:29.568593 16588 layer_factory.cpp:58] Creating layer relu2
I0314 11:46:29.568593 16588 net.cpp:100] Creating Layer relu2
I0314 11:46:29.568593 16588 net.cpp:434] relu2 <- scale2
I0314 11:46:29.568593 16588 net.cpp:408] relu2 -> relu2
I0314 11:46:29.569092 16588 net.cpp:150] Setting up relu2
I0314 11:46:29.569092 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.569092 16588 net.cpp:165] Memory required for data: 105472600
I0314 11:46:29.569092 16588 layer_factory.cpp:58] Creating layer conv2_1
I0314 11:46:29.569092 16588 net.cpp:100] Creating Layer conv2_1
I0314 11:46:29.569092 16588 net.cpp:434] conv2_1 <- relu2
I0314 11:46:29.569092 16588 net.cpp:408] conv2_1 -> conv2_1
I0314 11:46:29.572093 16588 net.cpp:150] Setting up conv2_1
I0314 11:46:29.572093 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.572093 16588 net.cpp:165] Memory required for data: 112026200
I0314 11:46:29.572093 16588 layer_factory.cpp:58] Creating layer bn2_1
I0314 11:46:29.572093 16588 net.cpp:100] Creating Layer bn2_1
I0314 11:46:29.572093 16588 net.cpp:434] bn2_1 <- conv2_1
I0314 11:46:29.572093 16588 net.cpp:408] bn2_1 -> bn2_1
I0314 11:46:29.572597 16588 net.cpp:150] Setting up bn2_1
I0314 11:46:29.572597 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.572597 16588 net.cpp:165] Memory required for data: 118579800
I0314 11:46:29.572597 16588 layer_factory.cpp:58] Creating layer scale2_1
I0314 11:46:29.572597 16588 net.cpp:100] Creating Layer scale2_1
I0314 11:46:29.572597 16588 net.cpp:434] scale2_1 <- bn2_1
I0314 11:46:29.572597 16588 net.cpp:408] scale2_1 -> scale2_1
I0314 11:46:29.572597 16588 layer_factory.cpp:58] Creating layer scale2_1
I0314 11:46:29.572597 16588 net.cpp:150] Setting up scale2_1
I0314 11:46:29.572597 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.572597 16588 net.cpp:165] Memory required for data: 125133400
I0314 11:46:29.572597 16588 layer_factory.cpp:58] Creating layer relu2_1
I0314 11:46:29.572597 16588 net.cpp:100] Creating Layer relu2_1
I0314 11:46:29.572597 16588 net.cpp:434] relu2_1 <- scale2_1
I0314 11:46:29.572597 16588 net.cpp:408] relu2_1 -> relu2_1
I0314 11:46:29.573592 16588 net.cpp:150] Setting up relu2_1
I0314 11:46:29.573592 16588 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0314 11:46:29.573592 16588 net.cpp:165] Memory required for data: 131687000
I0314 11:46:29.573592 16588 layer_factory.cpp:58] Creating layer pool2_1
I0314 11:46:29.573592 16588 net.cpp:100] Creating Layer pool2_1
I0314 11:46:29.573592 16588 net.cpp:434] pool2_1 <- relu2_1
I0314 11:46:29.573592 16588 net.cpp:408] pool2_1 -> pool2_1
I0314 11:46:29.573592 16588 net.cpp:150] Setting up pool2_1
I0314 11:46:29.573592 16588 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0314 11:46:29.573592 16588 net.cpp:165] Memory required for data: 133325400
I0314 11:46:29.573592 16588 layer_factory.cpp:58] Creating layer conv2_2
I0314 11:46:29.573592 16588 net.cpp:100] Creating Layer conv2_2
I0314 11:46:29.573592 16588 net.cpp:434] conv2_2 <- pool2_1
I0314 11:46:29.573592 16588 net.cpp:408] conv2_2 -> conv2_2
I0314 11:46:29.575093 16588 net.cpp:150] Setting up conv2_2
I0314 11:46:29.575093 16588 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0314 11:46:29.575093 16588 net.cpp:165] Memory required for data: 134963800
I0314 11:46:29.575093 16588 layer_factory.cpp:58] Creating layer bn2_2
I0314 11:46:29.575093 16588 net.cpp:100] Creating Layer bn2_2
I0314 11:46:29.575093 16588 net.cpp:434] bn2_2 <- conv2_2
I0314 11:46:29.575093 16588 net.cpp:408] bn2_2 -> bn2_2
I0314 11:46:29.575614 16588 net.cpp:150] Setting up bn2_2
I0314 11:46:29.575614 16588 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0314 11:46:29.575614 16588 net.cpp:165] Memory required for data: 136602200
I0314 11:46:29.575614 16588 layer_factory.cpp:58] Creating layer scale2_2
I0314 11:46:29.575614 16588 net.cpp:100] Creating Layer scale2_2
I0314 11:46:29.575614 16588 net.cpp:434] scale2_2 <- bn2_2
I0314 11:46:29.575614 16588 net.cpp:408] scale2_2 -> scale2_2
I0314 11:46:29.575614 16588 layer_factory.cpp:58] Creating layer scale2_2
I0314 11:46:29.575614 16588 net.cpp:150] Setting up scale2_2
I0314 11:46:29.575614 16588 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0314 11:46:29.575614 16588 net.cpp:165] Memory required for data: 138240600
I0314 11:46:29.575614 16588 layer_factory.cpp:58] Creating layer relu2_2
I0314 11:46:29.575614 16588 net.cpp:100] Creating Layer relu2_2
I0314 11:46:29.575614 16588 net.cpp:434] relu2_2 <- scale2_2
I0314 11:46:29.575614 16588 net.cpp:408] relu2_2 -> relu2_2
I0314 11:46:29.576107 16588 net.cpp:150] Setting up relu2_2
I0314 11:46:29.576107 16588 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0314 11:46:29.576107 16588 net.cpp:165] Memory required for data: 139879000
I0314 11:46:29.576594 16588 layer_factory.cpp:58] Creating layer conv3
I0314 11:46:29.576594 16588 net.cpp:100] Creating Layer conv3
I0314 11:46:29.576594 16588 net.cpp:434] conv3 <- relu2_2
I0314 11:46:29.576594 16588 net.cpp:408] conv3 -> conv3
I0314 11:46:29.578095 16588 net.cpp:150] Setting up conv3
I0314 11:46:29.578595 16588 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0314 11:46:29.578595 16588 net.cpp:165] Memory required for data: 141517400
I0314 11:46:29.578595 16588 layer_factory.cpp:58] Creating layer bn3
I0314 11:46:29.578595 16588 net.cpp:100] Creating Layer bn3
I0314 11:46:29.578595 16588 net.cpp:434] bn3 <- conv3
I0314 11:46:29.578595 16588 net.cpp:408] bn3 -> bn3
I0314 11:46:29.578595 16588 net.cpp:150] Setting up bn3
I0314 11:46:29.578595 16588 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0314 11:46:29.578595 16588 net.cpp:165] Memory required for data: 143155800
I0314 11:46:29.578595 16588 layer_factory.cpp:58] Creating layer scale3
I0314 11:46:29.578595 16588 net.cpp:100] Creating Layer scale3
I0314 11:46:29.578595 16588 net.cpp:434] scale3 <- bn3
I0314 11:46:29.578595 16588 net.cpp:408] scale3 -> scale3
I0314 11:46:29.579095 16588 layer_factory.cpp:58] Creating layer scale3
I0314 11:46:29.579095 16588 net.cpp:150] Setting up scale3
I0314 11:46:29.579095 16588 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0314 11:46:29.579095 16588 net.cpp:165] Memory required for data: 144794200
I0314 11:46:29.579095 16588 layer_factory.cpp:58] Creating layer relu3
I0314 11:46:29.579095 16588 net.cpp:100] Creating Layer relu3
I0314 11:46:29.579095 16588 net.cpp:434] relu3 <- scale3
I0314 11:46:29.579095 16588 net.cpp:408] relu3 -> relu3
I0314 11:46:29.579095 16588 net.cpp:150] Setting up relu3
I0314 11:46:29.579095 16588 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0314 11:46:29.579095 16588 net.cpp:165] Memory required for data: 146432600
I0314 11:46:29.579095 16588 layer_factory.cpp:58] Creating layer conv4
I0314 11:46:29.579095 16588 net.cpp:100] Creating Layer conv4
I0314 11:46:29.579095 16588 net.cpp:434] conv4 <- relu3
I0314 11:46:29.579095 16588 net.cpp:408] conv4 -> conv4
I0314 11:46:29.581111 16588 net.cpp:150] Setting up conv4
I0314 11:46:29.581111 16588 net.cpp:157] Top shape: 50 64 16 16 (819200)
I0314 11:46:29.581111 16588 net.cpp:165] Memory required for data: 149709400
I0314 11:46:29.581111 16588 layer_factory.cpp:58] Creating layer pool4
I0314 11:46:29.581111 16588 net.cpp:100] Creating Layer pool4
I0314 11:46:29.581111 16588 net.cpp:434] pool4 <- conv4
I0314 11:46:29.581111 16588 net.cpp:408] pool4 -> pool4
I0314 11:46:29.581111 16588 net.cpp:150] Setting up pool4
I0314 11:46:29.581111 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.581111 16588 net.cpp:165] Memory required for data: 150528600
I0314 11:46:29.581111 16588 layer_factory.cpp:58] Creating layer bn4
I0314 11:46:29.581111 16588 net.cpp:100] Creating Layer bn4
I0314 11:46:29.581111 16588 net.cpp:434] bn4 <- pool4
I0314 11:46:29.581111 16588 net.cpp:408] bn4 -> bn4
I0314 11:46:29.582101 16588 net.cpp:150] Setting up bn4
I0314 11:46:29.582101 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.582101 16588 net.cpp:165] Memory required for data: 151347800
I0314 11:46:29.582101 16588 layer_factory.cpp:58] Creating layer scale4
I0314 11:46:29.582101 16588 net.cpp:100] Creating Layer scale4
I0314 11:46:29.582101 16588 net.cpp:434] scale4 <- bn4
I0314 11:46:29.582101 16588 net.cpp:408] scale4 -> scale4
I0314 11:46:29.582101 16588 layer_factory.cpp:58] Creating layer scale4
I0314 11:46:29.582101 16588 net.cpp:150] Setting up scale4
I0314 11:46:29.582101 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.582101 16588 net.cpp:165] Memory required for data: 152167000
I0314 11:46:29.582101 16588 layer_factory.cpp:58] Creating layer relu4
I0314 11:46:29.582101 16588 net.cpp:100] Creating Layer relu4
I0314 11:46:29.582101 16588 net.cpp:434] relu4 <- scale4
I0314 11:46:29.582101 16588 net.cpp:408] relu4 -> relu4
I0314 11:46:29.582101 16588 net.cpp:150] Setting up relu4
I0314 11:46:29.582101 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.583101 16588 net.cpp:165] Memory required for data: 152986200
I0314 11:46:29.583101 16588 layer_factory.cpp:58] Creating layer conv4_1
I0314 11:46:29.583101 16588 net.cpp:100] Creating Layer conv4_1
I0314 11:46:29.583101 16588 net.cpp:434] conv4_1 <- relu4
I0314 11:46:29.583101 16588 net.cpp:408] conv4_1 -> conv4_1
I0314 11:46:29.585101 16588 net.cpp:150] Setting up conv4_1
I0314 11:46:29.585101 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.585101 16588 net.cpp:165] Memory required for data: 153805400
I0314 11:46:29.585101 16588 layer_factory.cpp:58] Creating layer bn4_1
I0314 11:46:29.585101 16588 net.cpp:100] Creating Layer bn4_1
I0314 11:46:29.585101 16588 net.cpp:434] bn4_1 <- conv4_1
I0314 11:46:29.585101 16588 net.cpp:408] bn4_1 -> bn4_1
I0314 11:46:29.585101 16588 net.cpp:150] Setting up bn4_1
I0314 11:46:29.585101 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.585101 16588 net.cpp:165] Memory required for data: 154624600
I0314 11:46:29.585101 16588 layer_factory.cpp:58] Creating layer scale4_1
I0314 11:46:29.585101 16588 net.cpp:100] Creating Layer scale4_1
I0314 11:46:29.585101 16588 net.cpp:434] scale4_1 <- bn4_1
I0314 11:46:29.585101 16588 net.cpp:408] scale4_1 -> scale4_1
I0314 11:46:29.585101 16588 layer_factory.cpp:58] Creating layer scale4_1
I0314 11:46:29.585101 16588 net.cpp:150] Setting up scale4_1
I0314 11:46:29.585101 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.585101 16588 net.cpp:165] Memory required for data: 155443800
I0314 11:46:29.585101 16588 layer_factory.cpp:58] Creating layer relu4_1
I0314 11:46:29.585101 16588 net.cpp:100] Creating Layer relu4_1
I0314 11:46:29.585101 16588 net.cpp:434] relu4_1 <- scale4_1
I0314 11:46:29.585101 16588 net.cpp:408] relu4_1 -> relu4_1
I0314 11:46:29.586102 16588 net.cpp:150] Setting up relu4_1
I0314 11:46:29.586102 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.586102 16588 net.cpp:165] Memory required for data: 156263000
I0314 11:46:29.586102 16588 layer_factory.cpp:58] Creating layer conv4_2
I0314 11:46:29.586102 16588 net.cpp:100] Creating Layer conv4_2
I0314 11:46:29.586102 16588 net.cpp:434] conv4_2 <- relu4_1
I0314 11:46:29.586102 16588 net.cpp:408] conv4_2 -> conv4_2
I0314 11:46:29.588101 16588 net.cpp:150] Setting up conv4_2
I0314 11:46:29.588101 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.588101 16588 net.cpp:165] Memory required for data: 157082200
I0314 11:46:29.588101 16588 layer_factory.cpp:58] Creating layer bn4_2
I0314 11:46:29.588101 16588 net.cpp:100] Creating Layer bn4_2
I0314 11:46:29.588101 16588 net.cpp:434] bn4_2 <- conv4_2
I0314 11:46:29.588101 16588 net.cpp:408] bn4_2 -> bn4_2
I0314 11:46:29.588101 16588 net.cpp:150] Setting up bn4_2
I0314 11:46:29.588101 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.588101 16588 net.cpp:165] Memory required for data: 157901400
I0314 11:46:29.588101 16588 layer_factory.cpp:58] Creating layer scale4_2
I0314 11:46:29.588101 16588 net.cpp:100] Creating Layer scale4_2
I0314 11:46:29.588101 16588 net.cpp:434] scale4_2 <- bn4_2
I0314 11:46:29.588101 16588 net.cpp:408] scale4_2 -> scale4_2
I0314 11:46:29.588101 16588 layer_factory.cpp:58] Creating layer scale4_2
I0314 11:46:29.589102 16588 net.cpp:150] Setting up scale4_2
I0314 11:46:29.589102 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.589102 16588 net.cpp:165] Memory required for data: 158720600
I0314 11:46:29.589102 16588 layer_factory.cpp:58] Creating layer relu4_2
I0314 11:46:29.589102 16588 net.cpp:100] Creating Layer relu4_2
I0314 11:46:29.589102 16588 net.cpp:434] relu4_2 <- scale4_2
I0314 11:46:29.589102 16588 net.cpp:408] relu4_2 -> relu4_2
I0314 11:46:29.589102 16588 net.cpp:150] Setting up relu4_2
I0314 11:46:29.589102 16588 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0314 11:46:29.589102 16588 net.cpp:165] Memory required for data: 159539800
I0314 11:46:29.589102 16588 layer_factory.cpp:58] Creating layer pool4_2
I0314 11:46:29.589102 16588 net.cpp:100] Creating Layer pool4_2
I0314 11:46:29.589102 16588 net.cpp:434] pool4_2 <- relu4_2
I0314 11:46:29.589102 16588 net.cpp:408] pool4_2 -> pool4_2
I0314 11:46:29.589102 16588 net.cpp:150] Setting up pool4_2
I0314 11:46:29.589102 16588 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0314 11:46:29.589102 16588 net.cpp:165] Memory required for data: 159744600
I0314 11:46:29.589102 16588 layer_factory.cpp:58] Creating layer conv4_0
I0314 11:46:29.589102 16588 net.cpp:100] Creating Layer conv4_0
I0314 11:46:29.589102 16588 net.cpp:434] conv4_0 <- pool4_2
I0314 11:46:29.589102 16588 net.cpp:408] conv4_0 -> conv4_0
I0314 11:46:29.592102 16588 net.cpp:150] Setting up conv4_0
I0314 11:46:29.592102 16588 net.cpp:157] Top shape: 50 128 4 4 (102400)
I0314 11:46:29.592102 16588 net.cpp:165] Memory required for data: 160154200
I0314 11:46:29.592102 16588 layer_factory.cpp:58] Creating layer bn4_0
I0314 11:46:29.592102 16588 net.cpp:100] Creating Layer bn4_0
I0314 11:46:29.592102 16588 net.cpp:434] bn4_0 <- conv4_0
I0314 11:46:29.592102 16588 net.cpp:408] bn4_0 -> bn4_0
I0314 11:46:29.592102 16588 net.cpp:150] Setting up bn4_0
I0314 11:46:29.592102 16588 net.cpp:157] Top shape: 50 128 4 4 (102400)
I0314 11:46:29.592102 16588 net.cpp:165] Memory required for data: 160563800
I0314 11:46:29.592102 16588 layer_factory.cpp:58] Creating layer scale4_0
I0314 11:46:29.592102 16588 net.cpp:100] Creating Layer scale4_0
I0314 11:46:29.592102 16588 net.cpp:434] scale4_0 <- bn4_0
I0314 11:46:29.592102 16588 net.cpp:408] scale4_0 -> scale4_0
I0314 11:46:29.592102 16588 layer_factory.cpp:58] Creating layer scale4_0
I0314 11:46:29.592102 16588 net.cpp:150] Setting up scale4_0
I0314 11:46:29.592102 16588 net.cpp:157] Top shape: 50 128 4 4 (102400)
I0314 11:46:29.592102 16588 net.cpp:165] Memory required for data: 160973400
I0314 11:46:29.592102 16588 layer_factory.cpp:58] Creating layer relu4_0
I0314 11:46:29.592102 16588 net.cpp:100] Creating Layer relu4_0
I0314 11:46:29.592102 16588 net.cpp:434] relu4_0 <- scale4_0
I0314 11:46:29.592102 16588 net.cpp:408] relu4_0 -> relu4_0
I0314 11:46:29.593101 16588 net.cpp:150] Setting up relu4_0
I0314 11:46:29.593101 16588 net.cpp:157] Top shape: 50 128 4 4 (102400)
I0314 11:46:29.593101 16588 net.cpp:165] Memory required for data: 161383000
I0314 11:46:29.593101 16588 layer_factory.cpp:58] Creating layer cccp4
I0314 11:46:29.593101 16588 net.cpp:100] Creating Layer cccp4
I0314 11:46:29.593101 16588 net.cpp:434] cccp4 <- relu4_0
I0314 11:46:29.593101 16588 net.cpp:408] cccp4 -> cccp4
I0314 11:46:29.595101 16588 net.cpp:150] Setting up cccp4
I0314 11:46:29.595101 16588 net.cpp:157] Top shape: 50 256 4 4 (204800)
I0314 11:46:29.595101 16588 net.cpp:165] Memory required for data: 162202200
I0314 11:46:29.595101 16588 layer_factory.cpp:58] Creating layer relu_cccp4
I0314 11:46:29.595101 16588 net.cpp:100] Creating Layer relu_cccp4
I0314 11:46:29.595101 16588 net.cpp:434] relu_cccp4 <- cccp4
I0314 11:46:29.595101 16588 net.cpp:395] relu_cccp4 -> cccp4 (in-place)
I0314 11:46:29.596102 16588 net.cpp:150] Setting up relu_cccp4
I0314 11:46:29.596102 16588 net.cpp:157] Top shape: 50 256 4 4 (204800)
I0314 11:46:29.596102 16588 net.cpp:165] Memory required for data: 163021400
I0314 11:46:29.596102 16588 layer_factory.cpp:58] Creating layer cccp5
I0314 11:46:29.596102 16588 net.cpp:100] Creating Layer cccp5
I0314 11:46:29.596102 16588 net.cpp:434] cccp5 <- cccp4
I0314 11:46:29.596102 16588 net.cpp:408] cccp5 -> cccp5
I0314 11:46:29.598101 16588 net.cpp:150] Setting up cccp5
I0314 11:46:29.598101 16588 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0314 11:46:29.598101 16588 net.cpp:165] Memory required for data: 163226200
I0314 11:46:29.598101 16588 layer_factory.cpp:58] Creating layer relu_cccp5
I0314 11:46:29.598101 16588 net.cpp:100] Creating Layer relu_cccp5
I0314 11:46:29.598101 16588 net.cpp:434] relu_cccp5 <- cccp5
I0314 11:46:29.598101 16588 net.cpp:395] relu_cccp5 -> cccp5 (in-place)
I0314 11:46:29.599102 16588 net.cpp:150] Setting up relu_cccp5
I0314 11:46:29.599102 16588 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0314 11:46:29.599102 16588 net.cpp:165] Memory required for data: 163431000
I0314 11:46:29.599102 16588 layer_factory.cpp:58] Creating layer poolcp5
I0314 11:46:29.599102 16588 net.cpp:100] Creating Layer poolcp5
I0314 11:46:29.599102 16588 net.cpp:434] poolcp5 <- cccp5
I0314 11:46:29.599102 16588 net.cpp:408] poolcp5 -> poolcp5
I0314 11:46:29.599102 16588 net.cpp:150] Setting up poolcp5
I0314 11:46:29.599102 16588 net.cpp:157] Top shape: 50 64 2 2 (12800)
I0314 11:46:29.599102 16588 net.cpp:165] Memory required for data: 163482200
I0314 11:46:29.599102 16588 layer_factory.cpp:58] Creating layer cccp6
I0314 11:46:29.599102 16588 net.cpp:100] Creating Layer cccp6
I0314 11:46:29.599102 16588 net.cpp:434] cccp6 <- poolcp5
I0314 11:46:29.599102 16588 net.cpp:408] cccp6 -> cccp6
I0314 11:46:29.601112 16588 net.cpp:150] Setting up cccp6
I0314 11:46:29.601112 16588 net.cpp:157] Top shape: 50 64 2 2 (12800)
I0314 11:46:29.601112 16588 net.cpp:165] Memory required for data: 163533400
I0314 11:46:29.601112 16588 layer_factory.cpp:58] Creating layer relu_cccp6
I0314 11:46:29.601112 16588 net.cpp:100] Creating Layer relu_cccp6
I0314 11:46:29.601112 16588 net.cpp:434] relu_cccp6 <- cccp6
I0314 11:46:29.601112 16588 net.cpp:395] relu_cccp6 -> cccp6 (in-place)
I0314 11:46:29.602102 16588 net.cpp:150] Setting up relu_cccp6
I0314 11:46:29.602102 16588 net.cpp:157] Top shape: 50 64 2 2 (12800)
I0314 11:46:29.602102 16588 net.cpp:165] Memory required for data: 163584600
I0314 11:46:29.602102 16588 layer_factory.cpp:58] Creating layer poolcp6
I0314 11:46:29.602102 16588 net.cpp:100] Creating Layer poolcp6
I0314 11:46:29.602102 16588 net.cpp:434] poolcp6 <- cccp6
I0314 11:46:29.602102 16588 net.cpp:408] poolcp6 -> poolcp6
I0314 11:46:29.602102 16588 net.cpp:150] Setting up poolcp6
I0314 11:46:29.602102 16588 net.cpp:157] Top shape: 50 64 1 1 (3200)
I0314 11:46:29.602102 16588 net.cpp:165] Memory required for data: 163597400
I0314 11:46:29.602102 16588 layer_factory.cpp:58] Creating layer ip1
I0314 11:46:29.602102 16588 net.cpp:100] Creating Layer ip1
I0314 11:46:29.602102 16588 net.cpp:434] ip1 <- poolcp6
I0314 11:46:29.602102 16588 net.cpp:408] ip1 -> ip1
I0314 11:46:29.602102 16588 net.cpp:150] Setting up ip1
I0314 11:46:29.602102 16588 net.cpp:157] Top shape: 50 10 (500)
I0314 11:46:29.602102 16588 net.cpp:165] Memory required for data: 163599400
I0314 11:46:29.602102 16588 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0314 11:46:29.602102 16588 net.cpp:100] Creating Layer ip1_ip1_0_split
I0314 11:46:29.602102 16588 net.cpp:434] ip1_ip1_0_split <- ip1
I0314 11:46:29.602102 16588 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0314 11:46:29.602102 16588 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0314 11:46:29.602102 16588 net.cpp:150] Setting up ip1_ip1_0_split
I0314 11:46:29.602102 16588 net.cpp:157] Top shape: 50 10 (500)
I0314 11:46:29.602102 16588 net.cpp:157] Top shape: 50 10 (500)
I0314 11:46:29.602102 16588 net.cpp:165] Memory required for data: 163603400
I0314 11:46:29.602102 16588 layer_factory.cpp:58] Creating layer accuracy
I0314 11:46:29.602102 16588 net.cpp:100] Creating Layer accuracy
I0314 11:46:29.602102 16588 net.cpp:434] accuracy <- ip1_ip1_0_split_0
I0314 11:46:29.602102 16588 net.cpp:434] accuracy <- label_cifar_1_split_0
I0314 11:46:29.602102 16588 net.cpp:408] accuracy -> accuracy
I0314 11:46:29.602102 16588 net.cpp:150] Setting up accuracy
I0314 11:46:29.602102 16588 net.cpp:157] Top shape: (1)
I0314 11:46:29.602102 16588 net.cpp:165] Memory required for data: 163603404
I0314 11:46:29.602102 16588 layer_factory.cpp:58] Creating layer loss
I0314 11:46:29.602102 16588 net.cpp:100] Creating Layer loss
I0314 11:46:29.602102 16588 net.cpp:434] loss <- ip1_ip1_0_split_1
I0314 11:46:29.602102 16588 net.cpp:434] loss <- label_cifar_1_split_1
I0314 11:46:29.602102 16588 net.cpp:408] loss -> loss
I0314 11:46:29.602102 16588 layer_factory.cpp:58] Creating layer loss
I0314 11:46:29.603103 16588 net.cpp:150] Setting up loss
I0314 11:46:29.603103 16588 net.cpp:157] Top shape: (1)
I0314 11:46:29.603103 16588 net.cpp:160]     with loss weight 1
I0314 11:46:29.603103 16588 net.cpp:165] Memory required for data: 163603408
I0314 11:46:29.603103 16588 net.cpp:226] loss needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:228] accuracy does not need backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] ip1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] poolcp6 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu_cccp6 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] cccp6 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] poolcp5 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu_cccp5 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] cccp5 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu_cccp4 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] cccp4 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu4_0 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] scale4_0 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] bn4_0 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] conv4_0 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] pool4_2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu4_2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] scale4_2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] bn4_2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] conv4_2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu4_1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] scale4_1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] bn4_1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] conv4_1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu4 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] scale4 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] bn4 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] pool4 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] conv4 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu3 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] scale3 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] bn3 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] conv3 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu2_2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] scale2_2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] bn2_2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] conv2_2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] pool2_1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu2_1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] scale2_1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] bn2_1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] conv2_1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] scale2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] bn2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] conv2 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu1_0 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] scale1_0 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] bn1_0 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] conv1_0 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] relu1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] scale1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] bn1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:226] conv1 needs backward computation.
I0314 11:46:29.603103 16588 net.cpp:228] label_cifar_1_split does not need backward computation.
I0314 11:46:29.603103 16588 net.cpp:228] cifar does not need backward computation.
I0314 11:46:29.603103 16588 net.cpp:270] This network produces output accuracy
I0314 11:46:29.603103 16588 net.cpp:270] This network produces output loss
I0314 11:46:29.603103 16588 net.cpp:283] Network initialization done.
I0314 11:46:29.604104 16588 solver.cpp:60] Solver scaffolding done.
I0314 11:46:29.609102 16588 caffe.cpp:252] Starting Optimization
I0314 11:46:29.609102 16588 solver.cpp:279] Solving CIFAR10_full
I0314 11:46:29.609102 16588 solver.cpp:280] Learning Rate Policy: multistep
I0314 11:46:29.611102 16588 solver.cpp:337] Iteration 0, Testing net (#0)
I0314 11:46:29.614104 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:46:31.993626 16588 solver.cpp:404]     Test net output #0: accuracy = 0.1
I0314 11:46:31.993626 16588 solver.cpp:404]     Test net output #1: loss = 78.6029 (* 1 = 78.6029 loss)
I0314 11:46:32.186513 16588 solver.cpp:228] Iteration 0, loss = 2.44064
I0314 11:46:32.186513 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.07
I0314 11:46:32.186513 16588 solver.cpp:244]     Train net output #1: loss = 2.44064 (* 1 = 2.44064 loss)
I0314 11:46:32.186513 16588 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0314 11:46:46.206800 16588 solver.cpp:228] Iteration 100, loss = 1.66814
I0314 11:46:46.206800 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.39
I0314 11:46:46.206800 16588 solver.cpp:244]     Train net output #1: loss = 1.66814 (* 1 = 1.66814 loss)
I0314 11:46:46.206800 16588 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0314 11:47:00.676046 16588 solver.cpp:228] Iteration 200, loss = 1.76054
I0314 11:47:00.676046 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.36
I0314 11:47:00.676046 16588 solver.cpp:244]     Train net output #1: loss = 1.76054 (* 1 = 1.76054 loss)
I0314 11:47:00.676046 16588 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0314 11:47:15.322495 16588 solver.cpp:228] Iteration 300, loss = 1.56863
I0314 11:47:15.322495 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.44
I0314 11:47:15.322495 16588 solver.cpp:244]     Train net output #1: loss = 1.56863 (* 1 = 1.56863 loss)
I0314 11:47:15.322495 16588 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0314 11:47:30.008774 16588 solver.cpp:228] Iteration 400, loss = 1.42217
I0314 11:47:30.008774 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.46
I0314 11:47:30.008774 16588 solver.cpp:244]     Train net output #1: loss = 1.42217 (* 1 = 1.42217 loss)
I0314 11:47:30.008774 16588 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0314 11:47:44.547063 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_500.caffemodel
I0314 11:47:44.591563 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_500.solverstate
I0314 11:47:44.598063 16588 solver.cpp:337] Iteration 500, Testing net (#0)
I0314 11:47:44.598063 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:47:49.332691 16588 solver.cpp:404]     Test net output #0: accuracy = 0.5136
I0314 11:47:49.332691 16588 solver.cpp:404]     Test net output #1: loss = 1.35033 (* 1 = 1.35033 loss)
I0314 11:47:49.374203 16588 solver.cpp:228] Iteration 500, loss = 1.32813
I0314 11:47:49.374203 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.53
I0314 11:47:49.374203 16588 solver.cpp:244]     Train net output #1: loss = 1.32813 (* 1 = 1.32813 loss)
I0314 11:47:49.374203 16588 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0314 11:48:03.597761 16588 solver.cpp:228] Iteration 600, loss = 1.21075
I0314 11:48:03.597761 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.58
I0314 11:48:03.597761 16588 solver.cpp:244]     Train net output #1: loss = 1.21075 (* 1 = 1.21075 loss)
I0314 11:48:03.597761 16588 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0314 11:48:18.251603 16588 solver.cpp:228] Iteration 700, loss = 1.12128
I0314 11:48:18.251603 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.56
I0314 11:48:18.251603 16588 solver.cpp:244]     Train net output #1: loss = 1.12128 (* 1 = 1.12128 loss)
I0314 11:48:18.251603 16588 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0314 11:48:32.780489 16588 solver.cpp:228] Iteration 800, loss = 1.10572
I0314 11:48:32.780489 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.64
I0314 11:48:32.780489 16588 solver.cpp:244]     Train net output #1: loss = 1.10572 (* 1 = 1.10572 loss)
I0314 11:48:32.780990 16588 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0314 11:48:47.266849 16588 solver.cpp:228] Iteration 900, loss = 1.09829
I0314 11:48:47.266849 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.64
I0314 11:48:47.266849 16588 solver.cpp:244]     Train net output #1: loss = 1.09829 (* 1 = 1.09829 loss)
I0314 11:48:47.266849 16588 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0314 11:49:01.809504 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_1000.caffemodel
I0314 11:49:01.828003 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_1000.solverstate
I0314 11:49:01.834503 16588 solver.cpp:337] Iteration 1000, Testing net (#0)
I0314 11:49:01.834503 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:49:06.631409 16588 solver.cpp:404]     Test net output #0: accuracy = 0.5873
I0314 11:49:06.631409 16588 solver.cpp:404]     Test net output #1: loss = 1.13645 (* 1 = 1.13645 loss)
I0314 11:49:06.685417 16588 solver.cpp:228] Iteration 1000, loss = 1.02425
I0314 11:49:06.685417 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.64
I0314 11:49:06.685417 16588 solver.cpp:244]     Train net output #1: loss = 1.02425 (* 1 = 1.02425 loss)
I0314 11:49:06.685417 16588 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0314 11:49:20.958241 16588 solver.cpp:228] Iteration 1100, loss = 0.987604
I0314 11:49:20.958241 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.64
I0314 11:49:20.958241 16588 solver.cpp:244]     Train net output #1: loss = 0.987604 (* 1 = 0.987604 loss)
I0314 11:49:20.958241 16588 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0314 11:49:35.600174 16588 solver.cpp:228] Iteration 1200, loss = 0.890796
I0314 11:49:35.600174 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.71
I0314 11:49:35.600174 16588 solver.cpp:244]     Train net output #1: loss = 0.890796 (* 1 = 0.890796 loss)
I0314 11:49:35.600174 16588 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0314 11:49:50.184072 16588 solver.cpp:228] Iteration 1300, loss = 0.861837
I0314 11:49:50.184072 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.72
I0314 11:49:50.184072 16588 solver.cpp:244]     Train net output #1: loss = 0.861837 (* 1 = 0.861837 loss)
I0314 11:49:50.184072 16588 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0314 11:50:04.777729 16588 solver.cpp:228] Iteration 1400, loss = 0.848803
I0314 11:50:04.777729 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.72
I0314 11:50:04.777729 16588 solver.cpp:244]     Train net output #1: loss = 0.848803 (* 1 = 0.848803 loss)
I0314 11:50:04.777729 16588 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0314 11:50:19.206833 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_1500.caffemodel
I0314 11:50:19.248333 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_1500.solverstate
I0314 11:50:19.255333 16588 solver.cpp:337] Iteration 1500, Testing net (#0)
I0314 11:50:19.255333 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:50:24.066385 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6334
I0314 11:50:24.066385 16588 solver.cpp:404]     Test net output #1: loss = 1.01308 (* 1 = 1.01308 loss)
I0314 11:50:24.115386 16588 solver.cpp:228] Iteration 1500, loss = 0.748934
I0314 11:50:24.116387 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.77
I0314 11:50:24.116387 16588 solver.cpp:244]     Train net output #1: loss = 0.748934 (* 1 = 0.748934 loss)
I0314 11:50:24.116387 16588 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0314 11:50:38.321163 16588 solver.cpp:228] Iteration 1600, loss = 0.745601
I0314 11:50:38.321163 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.74
I0314 11:50:38.321663 16588 solver.cpp:244]     Train net output #1: loss = 0.745601 (* 1 = 0.745601 loss)
I0314 11:50:38.321663 16588 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0314 11:50:52.844023 16588 solver.cpp:228] Iteration 1700, loss = 0.801342
I0314 11:50:52.844023 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.76
I0314 11:50:52.844023 16588 solver.cpp:244]     Train net output #1: loss = 0.801342 (* 1 = 0.801342 loss)
I0314 11:50:52.844023 16588 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0314 11:51:07.370908 16588 solver.cpp:228] Iteration 1800, loss = 0.691532
I0314 11:51:07.370908 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.77
I0314 11:51:07.370908 16588 solver.cpp:244]     Train net output #1: loss = 0.691532 (* 1 = 0.691532 loss)
I0314 11:51:07.370908 16588 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0314 11:51:21.877849 16588 solver.cpp:228] Iteration 1900, loss = 0.836012
I0314 11:51:21.877849 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.7
I0314 11:51:21.877849 16588 solver.cpp:244]     Train net output #1: loss = 0.836012 (* 1 = 0.836012 loss)
I0314 11:51:21.877849 16588 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0314 11:51:36.346045 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_2000.caffemodel
I0314 11:51:36.386545 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_2000.solverstate
I0314 11:51:36.392046 16588 solver.cpp:337] Iteration 2000, Testing net (#0)
I0314 11:51:36.392046 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:51:41.162041 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6727
I0314 11:51:41.162541 16588 solver.cpp:404]     Test net output #1: loss = 0.954664 (* 1 = 0.954664 loss)
I0314 11:51:41.210041 16588 solver.cpp:228] Iteration 2000, loss = 0.742
I0314 11:51:41.210041 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0314 11:51:41.210041 16588 solver.cpp:244]     Train net output #1: loss = 0.742 (* 1 = 0.742 loss)
I0314 11:51:41.210041 16588 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0314 11:51:55.308770 16588 solver.cpp:228] Iteration 2100, loss = 0.809069
I0314 11:51:55.308770 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.71
I0314 11:51:55.308770 16588 solver.cpp:244]     Train net output #1: loss = 0.809069 (* 1 = 0.809069 loss)
I0314 11:51:55.308770 16588 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0314 11:52:09.740754 16588 solver.cpp:228] Iteration 2200, loss = 0.691042
I0314 11:52:09.741253 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.76
I0314 11:52:09.741253 16588 solver.cpp:244]     Train net output #1: loss = 0.691042 (* 1 = 0.691042 loss)
I0314 11:52:09.741253 16588 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0314 11:52:24.273640 16588 solver.cpp:228] Iteration 2300, loss = 0.584902
I0314 11:52:24.273640 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 11:52:24.273640 16588 solver.cpp:244]     Train net output #1: loss = 0.584902 (* 1 = 0.584902 loss)
I0314 11:52:24.273640 16588 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0314 11:52:38.768229 16588 solver.cpp:228] Iteration 2400, loss = 0.68496
I0314 11:52:38.768229 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.71
I0314 11:52:38.768714 16588 solver.cpp:244]     Train net output #1: loss = 0.68496 (* 1 = 0.68496 loss)
I0314 11:52:38.768714 16588 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0314 11:52:53.203102 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_2500.caffemodel
I0314 11:52:53.241101 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_2500.solverstate
I0314 11:52:53.247625 16588 solver.cpp:337] Iteration 2500, Testing net (#0)
I0314 11:52:53.247625 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:52:58.026022 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7394
I0314 11:52:58.026022 16588 solver.cpp:404]     Test net output #1: loss = 0.765805 (* 1 = 0.765805 loss)
I0314 11:52:58.071522 16588 solver.cpp:228] Iteration 2500, loss = 0.58586
I0314 11:52:58.071522 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0314 11:52:58.071522 16588 solver.cpp:244]     Train net output #1: loss = 0.58586 (* 1 = 0.58586 loss)
I0314 11:52:58.071522 16588 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0314 11:53:12.293543 16588 solver.cpp:228] Iteration 2600, loss = 0.629601
I0314 11:53:12.293543 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.77
I0314 11:53:12.293543 16588 solver.cpp:244]     Train net output #1: loss = 0.629601 (* 1 = 0.629601 loss)
I0314 11:53:12.293543 16588 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0314 11:53:26.838696 16588 solver.cpp:228] Iteration 2700, loss = 0.634813
I0314 11:53:26.838696 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0314 11:53:26.838696 16588 solver.cpp:244]     Train net output #1: loss = 0.634813 (* 1 = 0.634813 loss)
I0314 11:53:26.838696 16588 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0314 11:53:41.330760 16588 solver.cpp:228] Iteration 2800, loss = 0.541962
I0314 11:53:41.330760 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 11:53:41.330760 16588 solver.cpp:244]     Train net output #1: loss = 0.541962 (* 1 = 0.541962 loss)
I0314 11:53:41.330760 16588 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0314 11:53:55.908839 16588 solver.cpp:228] Iteration 2900, loss = 0.544509
I0314 11:53:55.908839 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0314 11:53:55.908839 16588 solver.cpp:244]     Train net output #1: loss = 0.544509 (* 1 = 0.544509 loss)
I0314 11:53:55.908839 16588 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0314 11:54:10.348903 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_3000.caffemodel
I0314 11:54:10.368446 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_3000.solverstate
I0314 11:54:10.373947 16588 solver.cpp:337] Iteration 3000, Testing net (#0)
I0314 11:54:10.373947 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:54:15.087510 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7248
I0314 11:54:15.088016 16588 solver.cpp:404]     Test net output #1: loss = 0.796079 (* 1 = 0.796079 loss)
I0314 11:54:15.115072 16588 solver.cpp:228] Iteration 3000, loss = 0.488046
I0314 11:54:15.115072 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 11:54:15.115072 16588 solver.cpp:244]     Train net output #1: loss = 0.488046 (* 1 = 0.488046 loss)
I0314 11:54:15.115072 16588 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0314 11:54:29.169980 16588 solver.cpp:228] Iteration 3100, loss = 0.604799
I0314 11:54:29.169980 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.77
I0314 11:54:29.169980 16588 solver.cpp:244]     Train net output #1: loss = 0.604799 (* 1 = 0.604799 loss)
I0314 11:54:29.169980 16588 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0314 11:54:43.737838 16588 solver.cpp:228] Iteration 3200, loss = 0.558906
I0314 11:54:43.737838 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 11:54:43.737838 16588 solver.cpp:244]     Train net output #1: loss = 0.558906 (* 1 = 0.558906 loss)
I0314 11:54:43.737838 16588 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0314 11:54:58.217900 16588 solver.cpp:228] Iteration 3300, loss = 0.560365
I0314 11:54:58.217900 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 11:54:58.217900 16588 solver.cpp:244]     Train net output #1: loss = 0.560365 (* 1 = 0.560365 loss)
I0314 11:54:58.217900 16588 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0314 11:55:12.778568 16588 solver.cpp:228] Iteration 3400, loss = 0.538271
I0314 11:55:12.778568 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0314 11:55:12.778568 16588 solver.cpp:244]     Train net output #1: loss = 0.538271 (* 1 = 0.538271 loss)
I0314 11:55:12.778568 16588 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0314 11:55:27.256304 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_3500.caffemodel
I0314 11:55:27.297803 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_3500.solverstate
I0314 11:55:27.303804 16588 solver.cpp:337] Iteration 3500, Testing net (#0)
I0314 11:55:27.304304 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:55:32.063519 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7329
I0314 11:55:32.063519 16588 solver.cpp:404]     Test net output #1: loss = 0.786231 (* 1 = 0.786231 loss)
I0314 11:55:32.108018 16588 solver.cpp:228] Iteration 3500, loss = 0.524953
I0314 11:55:32.108018 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 11:55:32.108018 16588 solver.cpp:244]     Train net output #1: loss = 0.524953 (* 1 = 0.524953 loss)
I0314 11:55:32.108018 16588 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0314 11:55:46.199204 16588 solver.cpp:228] Iteration 3600, loss = 0.511915
I0314 11:55:46.199204 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 11:55:46.199204 16588 solver.cpp:244]     Train net output #1: loss = 0.511915 (* 1 = 0.511915 loss)
I0314 11:55:46.199687 16588 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0314 11:56:00.779319 16588 solver.cpp:228] Iteration 3700, loss = 0.543281
I0314 11:56:00.779319 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 11:56:00.779319 16588 solver.cpp:244]     Train net output #1: loss = 0.543281 (* 1 = 0.543281 loss)
I0314 11:56:00.779319 16588 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0314 11:56:15.249189 16588 solver.cpp:228] Iteration 3800, loss = 0.544006
I0314 11:56:15.249189 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 11:56:15.249189 16588 solver.cpp:244]     Train net output #1: loss = 0.544006 (* 1 = 0.544006 loss)
I0314 11:56:15.249189 16588 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0314 11:56:29.811704 16588 solver.cpp:228] Iteration 3900, loss = 0.468282
I0314 11:56:29.811704 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 11:56:29.811704 16588 solver.cpp:244]     Train net output #1: loss = 0.468282 (* 1 = 0.468282 loss)
I0314 11:56:29.811704 16588 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0314 11:56:44.354393 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_4000.caffemodel
I0314 11:56:44.391731 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_4000.solverstate
I0314 11:56:44.398730 16588 solver.cpp:337] Iteration 4000, Testing net (#0)
I0314 11:56:44.398730 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:56:49.277390 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7168
I0314 11:56:49.277390 16588 solver.cpp:404]     Test net output #1: loss = 0.823114 (* 1 = 0.823114 loss)
I0314 11:56:49.340890 16588 solver.cpp:228] Iteration 4000, loss = 0.563133
I0314 11:56:49.340890 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 11:56:49.340890 16588 solver.cpp:244]     Train net output #1: loss = 0.563133 (* 1 = 0.563133 loss)
I0314 11:56:49.341392 16588 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0314 11:57:04.146157 16588 solver.cpp:228] Iteration 4100, loss = 0.530325
I0314 11:57:04.146157 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 11:57:04.146157 16588 solver.cpp:244]     Train net output #1: loss = 0.530325 (* 1 = 0.530325 loss)
I0314 11:57:04.146157 16588 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0314 11:57:20.433250 16588 solver.cpp:228] Iteration 4200, loss = 0.673273
I0314 11:57:20.433250 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0314 11:57:20.433250 16588 solver.cpp:244]     Train net output #1: loss = 0.673273 (* 1 = 0.673273 loss)
I0314 11:57:20.433250 16588 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0314 11:57:36.555583 16588 solver.cpp:228] Iteration 4300, loss = 0.47985
I0314 11:57:36.555583 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 11:57:36.555583 16588 solver.cpp:244]     Train net output #1: loss = 0.47985 (* 1 = 0.47985 loss)
I0314 11:57:36.555583 16588 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0314 11:57:52.194973 16588 solver.cpp:228] Iteration 4400, loss = 0.520643
I0314 11:57:52.195474 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 11:57:52.195474 16588 solver.cpp:244]     Train net output #1: loss = 0.520643 (* 1 = 0.520643 loss)
I0314 11:57:52.195474 16588 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0314 11:58:06.926597 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_4500.caffemodel
I0314 11:58:06.946092 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_4500.solverstate
I0314 11:58:06.952095 16588 solver.cpp:337] Iteration 4500, Testing net (#0)
I0314 11:58:06.952596 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:58:12.030261 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7407
I0314 11:58:12.030261 16588 solver.cpp:404]     Test net output #1: loss = 0.769986 (* 1 = 0.769986 loss)
I0314 11:58:12.080760 16588 solver.cpp:228] Iteration 4500, loss = 0.534774
I0314 11:58:12.080760 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 11:58:12.080760 16588 solver.cpp:244]     Train net output #1: loss = 0.534774 (* 1 = 0.534774 loss)
I0314 11:58:12.080760 16588 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0314 11:58:26.749294 16588 solver.cpp:228] Iteration 4600, loss = 0.449729
I0314 11:58:26.749294 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 11:58:26.749294 16588 solver.cpp:244]     Train net output #1: loss = 0.449729 (* 1 = 0.449729 loss)
I0314 11:58:26.749294 16588 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0314 11:58:42.445673 16588 solver.cpp:228] Iteration 4700, loss = 0.559159
I0314 11:58:42.445673 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 11:58:42.445673 16588 solver.cpp:244]     Train net output #1: loss = 0.559159 (* 1 = 0.559159 loss)
I0314 11:58:42.445673 16588 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0314 11:58:58.423367 16588 solver.cpp:228] Iteration 4800, loss = 0.506894
I0314 11:58:58.423367 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 11:58:58.423367 16588 solver.cpp:244]     Train net output #1: loss = 0.506894 (* 1 = 0.506894 loss)
I0314 11:58:58.423367 16588 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0314 11:59:13.527108 16588 solver.cpp:228] Iteration 4900, loss = 0.496532
I0314 11:59:13.527108 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 11:59:13.527108 16588 solver.cpp:244]     Train net output #1: loss = 0.496532 (* 1 = 0.496532 loss)
I0314 11:59:13.527108 16588 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0314 11:59:28.337016 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_5000.caffemodel
I0314 11:59:28.356015 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_5000.solverstate
I0314 11:59:28.362514 16588 solver.cpp:337] Iteration 5000, Testing net (#0)
I0314 11:59:28.363014 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 11:59:33.390130 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7312
I0314 11:59:33.391136 16588 solver.cpp:404]     Test net output #1: loss = 0.799135 (* 1 = 0.799135 loss)
I0314 11:59:33.434140 16588 solver.cpp:228] Iteration 5000, loss = 0.591511
I0314 11:59:33.434140 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0314 11:59:33.434140 16588 solver.cpp:244]     Train net output #1: loss = 0.591511 (* 1 = 0.591511 loss)
I0314 11:59:33.434140 16588 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0314 11:59:47.948101 16588 solver.cpp:228] Iteration 5100, loss = 0.540075
I0314 11:59:47.948101 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0314 11:59:47.948101 16588 solver.cpp:244]     Train net output #1: loss = 0.540075 (* 1 = 0.540075 loss)
I0314 11:59:47.948101 16588 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0314 12:00:02.825387 16588 solver.cpp:228] Iteration 5200, loss = 0.482572
I0314 12:00:02.825387 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:00:02.825387 16588 solver.cpp:244]     Train net output #1: loss = 0.482572 (* 1 = 0.482572 loss)
I0314 12:00:02.825387 16588 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0314 12:00:17.466920 16588 solver.cpp:228] Iteration 5300, loss = 0.515981
I0314 12:00:17.466920 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:00:17.466920 16588 solver.cpp:244]     Train net output #1: loss = 0.515981 (* 1 = 0.515981 loss)
I0314 12:00:17.466920 16588 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0314 12:00:31.970393 16588 solver.cpp:228] Iteration 5400, loss = 0.459208
I0314 12:00:31.970393 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:00:31.970892 16588 solver.cpp:244]     Train net output #1: loss = 0.459208 (* 1 = 0.459208 loss)
I0314 12:00:31.970892 16588 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0314 12:00:46.455118 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_5500.caffemodel
I0314 12:00:46.493618 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_5500.solverstate
I0314 12:00:46.500119 16588 solver.cpp:337] Iteration 5500, Testing net (#0)
I0314 12:00:46.500119 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:00:51.315912 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7246
I0314 12:00:51.316390 16588 solver.cpp:404]     Test net output #1: loss = 0.82735 (* 1 = 0.82735 loss)
I0314 12:00:51.360406 16588 solver.cpp:228] Iteration 5500, loss = 0.498452
I0314 12:00:51.360406 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:00:51.360406 16588 solver.cpp:244]     Train net output #1: loss = 0.498452 (* 1 = 0.498452 loss)
I0314 12:00:51.360406 16588 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0314 12:01:05.542666 16588 solver.cpp:228] Iteration 5600, loss = 0.474217
I0314 12:01:05.542666 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:01:05.542666 16588 solver.cpp:244]     Train net output #1: loss = 0.474217 (* 1 = 0.474217 loss)
I0314 12:01:05.542666 16588 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0314 12:01:20.141634 16588 solver.cpp:228] Iteration 5700, loss = 0.530419
I0314 12:01:20.141634 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:01:20.141634 16588 solver.cpp:244]     Train net output #1: loss = 0.530419 (* 1 = 0.530419 loss)
I0314 12:01:20.141634 16588 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0314 12:01:34.638403 16588 solver.cpp:228] Iteration 5800, loss = 0.488351
I0314 12:01:34.638403 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:01:34.638403 16588 solver.cpp:244]     Train net output #1: loss = 0.488351 (* 1 = 0.488351 loss)
I0314 12:01:34.638403 16588 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0314 12:01:49.132246 16588 solver.cpp:228] Iteration 5900, loss = 0.49295
I0314 12:01:49.132246 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:01:49.132246 16588 solver.cpp:244]     Train net output #1: loss = 0.49295 (* 1 = 0.49295 loss)
I0314 12:01:49.132246 16588 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0314 12:02:03.595000 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_6000.caffemodel
I0314 12:02:03.633056 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_6000.solverstate
I0314 12:02:03.640056 16588 solver.cpp:337] Iteration 6000, Testing net (#0)
I0314 12:02:03.640056 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:02:08.371997 16588 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0314 12:02:08.371997 16588 solver.cpp:404]     Test net output #1: loss = 0.709622 (* 1 = 0.709622 loss)
I0314 12:02:08.422497 16588 solver.cpp:228] Iteration 6000, loss = 0.448107
I0314 12:02:08.422497 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:02:08.422497 16588 solver.cpp:244]     Train net output #1: loss = 0.448107 (* 1 = 0.448107 loss)
I0314 12:02:08.422497 16588 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0314 12:02:22.651908 16588 solver.cpp:228] Iteration 6100, loss = 0.511905
I0314 12:02:22.651908 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 12:02:22.651908 16588 solver.cpp:244]     Train net output #1: loss = 0.511905 (* 1 = 0.511905 loss)
I0314 12:02:22.651908 16588 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0314 12:02:37.209033 16588 solver.cpp:228] Iteration 6200, loss = 0.634278
I0314 12:02:37.209033 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0314 12:02:37.209033 16588 solver.cpp:244]     Train net output #1: loss = 0.634278 (* 1 = 0.634278 loss)
I0314 12:02:37.209033 16588 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0314 12:02:51.741979 16588 solver.cpp:228] Iteration 6300, loss = 0.472082
I0314 12:02:51.741979 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:02:51.741979 16588 solver.cpp:244]     Train net output #1: loss = 0.472082 (* 1 = 0.472082 loss)
I0314 12:02:51.742480 16588 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0314 12:03:06.301386 16588 solver.cpp:228] Iteration 6400, loss = 0.469625
I0314 12:03:06.301386 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:03:06.301386 16588 solver.cpp:244]     Train net output #1: loss = 0.469625 (* 1 = 0.469625 loss)
I0314 12:03:06.301386 16588 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0314 12:03:20.785651 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_6500.caffemodel
I0314 12:03:20.804680 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_6500.solverstate
I0314 12:03:20.810680 16588 solver.cpp:337] Iteration 6500, Testing net (#0)
I0314 12:03:20.810680 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:03:25.618731 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7249
I0314 12:03:25.618731 16588 solver.cpp:404]     Test net output #1: loss = 0.852282 (* 1 = 0.852282 loss)
I0314 12:03:25.672232 16588 solver.cpp:228] Iteration 6500, loss = 0.458431
I0314 12:03:25.672232 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:03:25.672232 16588 solver.cpp:244]     Train net output #1: loss = 0.458431 (* 1 = 0.458431 loss)
I0314 12:03:25.672730 16588 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0314 12:03:39.997503 16588 solver.cpp:228] Iteration 6600, loss = 0.543396
I0314 12:03:39.997503 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 12:03:39.997503 16588 solver.cpp:244]     Train net output #1: loss = 0.543396 (* 1 = 0.543396 loss)
I0314 12:03:39.998008 16588 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0314 12:03:54.557720 16588 solver.cpp:228] Iteration 6700, loss = 0.504903
I0314 12:03:54.557720 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:03:54.557720 16588 solver.cpp:244]     Train net output #1: loss = 0.504903 (* 1 = 0.504903 loss)
I0314 12:03:54.557720 16588 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0314 12:04:09.228591 16588 solver.cpp:228] Iteration 6800, loss = 0.471356
I0314 12:04:09.228591 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:04:09.228591 16588 solver.cpp:244]     Train net output #1: loss = 0.471356 (* 1 = 0.471356 loss)
I0314 12:04:09.228591 16588 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0314 12:04:23.913247 16588 solver.cpp:228] Iteration 6900, loss = 0.444869
I0314 12:04:23.913247 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:04:23.913247 16588 solver.cpp:244]     Train net output #1: loss = 0.444869 (* 1 = 0.444869 loss)
I0314 12:04:23.913247 16588 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0314 12:04:38.510030 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_7000.caffemodel
I0314 12:04:38.548529 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_7000.solverstate
I0314 12:04:38.555030 16588 solver.cpp:337] Iteration 7000, Testing net (#0)
I0314 12:04:38.555030 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:04:43.507985 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6848
I0314 12:04:43.507985 16588 solver.cpp:404]     Test net output #1: loss = 0.929766 (* 1 = 0.929766 loss)
I0314 12:04:43.559001 16588 solver.cpp:228] Iteration 7000, loss = 0.466627
I0314 12:04:43.559001 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:04:43.559001 16588 solver.cpp:244]     Train net output #1: loss = 0.466627 (* 1 = 0.466627 loss)
I0314 12:04:43.559001 16588 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0314 12:04:57.784337 16588 solver.cpp:228] Iteration 7100, loss = 0.414137
I0314 12:04:57.784337 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:04:57.784337 16588 solver.cpp:244]     Train net output #1: loss = 0.414137 (* 1 = 0.414137 loss)
I0314 12:04:57.784337 16588 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0314 12:05:12.423404 16588 solver.cpp:228] Iteration 7200, loss = 0.538728
I0314 12:05:12.423404 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:05:12.423404 16588 solver.cpp:244]     Train net output #1: loss = 0.538728 (* 1 = 0.538728 loss)
I0314 12:05:12.423404 16588 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0314 12:05:27.156535 16588 solver.cpp:228] Iteration 7300, loss = 0.443106
I0314 12:05:27.157035 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:05:27.157035 16588 solver.cpp:244]     Train net output #1: loss = 0.443106 (* 1 = 0.443106 loss)
I0314 12:05:27.157035 16588 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0314 12:05:41.728255 16588 solver.cpp:228] Iteration 7400, loss = 0.370298
I0314 12:05:41.728255 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:05:41.728255 16588 solver.cpp:244]     Train net output #1: loss = 0.370298 (* 1 = 0.370298 loss)
I0314 12:05:41.728255 16588 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0314 12:05:56.424831 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_7500.caffemodel
I0314 12:05:56.445852 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_7500.solverstate
I0314 12:05:56.452838 16588 solver.cpp:337] Iteration 7500, Testing net (#0)
I0314 12:05:56.452838 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:06:01.378690 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7344
I0314 12:06:01.378690 16588 solver.cpp:404]     Test net output #1: loss = 0.798972 (* 1 = 0.798972 loss)
I0314 12:06:01.432689 16588 solver.cpp:228] Iteration 7500, loss = 0.398677
I0314 12:06:01.433189 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:06:01.433189 16588 solver.cpp:244]     Train net output #1: loss = 0.398677 (* 1 = 0.398677 loss)
I0314 12:06:01.433189 16588 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0314 12:06:15.706688 16588 solver.cpp:228] Iteration 7600, loss = 0.446252
I0314 12:06:15.706688 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:06:15.706688 16588 solver.cpp:244]     Train net output #1: loss = 0.446252 (* 1 = 0.446252 loss)
I0314 12:06:15.706688 16588 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0314 12:06:30.347656 16588 solver.cpp:228] Iteration 7700, loss = 0.572897
I0314 12:06:30.347656 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:06:30.347656 16588 solver.cpp:244]     Train net output #1: loss = 0.572897 (* 1 = 0.572897 loss)
I0314 12:06:30.347656 16588 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0314 12:06:44.750468 16588 solver.cpp:228] Iteration 7800, loss = 0.492935
I0314 12:06:44.750468 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:06:44.750468 16588 solver.cpp:244]     Train net output #1: loss = 0.492935 (* 1 = 0.492935 loss)
I0314 12:06:44.750468 16588 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0314 12:06:59.267935 16588 solver.cpp:228] Iteration 7900, loss = 0.429577
I0314 12:06:59.267935 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:06:59.267935 16588 solver.cpp:244]     Train net output #1: loss = 0.429577 (* 1 = 0.429577 loss)
I0314 12:06:59.267935 16588 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0314 12:07:13.757697 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_8000.caffemodel
I0314 12:07:13.794698 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_8000.solverstate
I0314 12:07:13.801198 16588 solver.cpp:337] Iteration 8000, Testing net (#0)
I0314 12:07:13.801198 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:07:18.914207 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7036
I0314 12:07:18.914207 16588 solver.cpp:404]     Test net output #1: loss = 0.952072 (* 1 = 0.952072 loss)
I0314 12:07:18.977221 16588 solver.cpp:228] Iteration 8000, loss = 0.415262
I0314 12:07:18.977723 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:07:18.977723 16588 solver.cpp:244]     Train net output #1: loss = 0.415262 (* 1 = 0.415262 loss)
I0314 12:07:18.977723 16588 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0314 12:07:33.372606 16588 solver.cpp:228] Iteration 8100, loss = 0.660252
I0314 12:07:33.372606 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 12:07:33.372606 16588 solver.cpp:244]     Train net output #1: loss = 0.660252 (* 1 = 0.660252 loss)
I0314 12:07:33.372606 16588 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0314 12:07:48.509105 16588 solver.cpp:228] Iteration 8200, loss = 0.499747
I0314 12:07:48.509105 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:07:48.509105 16588 solver.cpp:244]     Train net output #1: loss = 0.499747 (* 1 = 0.499747 loss)
I0314 12:07:48.509105 16588 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0314 12:08:03.624759 16588 solver.cpp:228] Iteration 8300, loss = 0.529265
I0314 12:08:03.624759 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:08:03.624759 16588 solver.cpp:244]     Train net output #1: loss = 0.529265 (* 1 = 0.529265 loss)
I0314 12:08:03.624759 16588 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0314 12:08:18.745468 16588 solver.cpp:228] Iteration 8400, loss = 0.424122
I0314 12:08:18.745468 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:08:18.745468 16588 solver.cpp:244]     Train net output #1: loss = 0.424122 (* 1 = 0.424122 loss)
I0314 12:08:18.745468 16588 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0314 12:08:33.306109 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_8500.caffemodel
I0314 12:08:33.344645 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_8500.solverstate
I0314 12:08:33.351145 16588 solver.cpp:337] Iteration 8500, Testing net (#0)
I0314 12:08:33.351644 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:08:38.493147 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7535
I0314 12:08:38.493649 16588 solver.cpp:404]     Test net output #1: loss = 0.734711 (* 1 = 0.734711 loss)
I0314 12:08:38.545645 16588 solver.cpp:228] Iteration 8500, loss = 0.404899
I0314 12:08:38.545645 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:08:38.546145 16588 solver.cpp:244]     Train net output #1: loss = 0.404899 (* 1 = 0.404899 loss)
I0314 12:08:38.546145 16588 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0314 12:08:53.111215 16588 solver.cpp:228] Iteration 8600, loss = 0.445095
I0314 12:08:53.111215 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:08:53.111215 16588 solver.cpp:244]     Train net output #1: loss = 0.445095 (* 1 = 0.445095 loss)
I0314 12:08:53.111215 16588 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0314 12:09:08.682833 16588 solver.cpp:228] Iteration 8700, loss = 0.565193
I0314 12:09:08.683334 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0314 12:09:08.683334 16588 solver.cpp:244]     Train net output #1: loss = 0.565193 (* 1 = 0.565193 loss)
I0314 12:09:08.683334 16588 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0314 12:09:23.836978 16588 solver.cpp:228] Iteration 8800, loss = 0.444124
I0314 12:09:23.836978 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:09:23.836978 16588 solver.cpp:244]     Train net output #1: loss = 0.444124 (* 1 = 0.444124 loss)
I0314 12:09:23.836978 16588 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0314 12:09:39.179651 16588 solver.cpp:228] Iteration 8900, loss = 0.297976
I0314 12:09:39.179651 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 12:09:39.180146 16588 solver.cpp:244]     Train net output #1: loss = 0.297976 (* 1 = 0.297976 loss)
I0314 12:09:39.180146 16588 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0314 12:09:53.814921 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_9000.caffemodel
I0314 12:09:53.837438 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_9000.solverstate
I0314 12:09:53.843439 16588 solver.cpp:337] Iteration 9000, Testing net (#0)
I0314 12:09:53.843940 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:09:58.661520 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7481
I0314 12:09:58.661520 16588 solver.cpp:404]     Test net output #1: loss = 0.718994 (* 1 = 0.718994 loss)
I0314 12:09:58.690517 16588 solver.cpp:228] Iteration 9000, loss = 0.362379
I0314 12:09:58.690517 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:09:58.690517 16588 solver.cpp:244]     Train net output #1: loss = 0.362379 (* 1 = 0.362379 loss)
I0314 12:09:58.690517 16588 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0314 12:10:12.936010 16588 solver.cpp:228] Iteration 9100, loss = 0.488744
I0314 12:10:12.936010 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:10:12.936010 16588 solver.cpp:244]     Train net output #1: loss = 0.488744 (* 1 = 0.488744 loss)
I0314 12:10:12.936010 16588 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0314 12:10:27.519209 16588 solver.cpp:228] Iteration 9200, loss = 0.550188
I0314 12:10:27.519209 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:10:27.519209 16588 solver.cpp:244]     Train net output #1: loss = 0.550188 (* 1 = 0.550188 loss)
I0314 12:10:27.519209 16588 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0314 12:10:42.076521 16588 solver.cpp:228] Iteration 9300, loss = 0.562406
I0314 12:10:42.076521 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0314 12:10:42.076521 16588 solver.cpp:244]     Train net output #1: loss = 0.562406 (* 1 = 0.562406 loss)
I0314 12:10:42.076521 16588 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0314 12:10:56.598613 16588 solver.cpp:228] Iteration 9400, loss = 0.441478
I0314 12:10:56.598613 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:10:56.598613 16588 solver.cpp:244]     Train net output #1: loss = 0.441478 (* 1 = 0.441478 loss)
I0314 12:10:56.598613 16588 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0314 12:11:11.032353 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_9500.caffemodel
I0314 12:11:11.069913 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_9500.solverstate
I0314 12:11:11.076434 16588 solver.cpp:337] Iteration 9500, Testing net (#0)
I0314 12:11:11.076434 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:11:15.856227 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7039
I0314 12:11:15.856227 16588 solver.cpp:404]     Test net output #1: loss = 0.880568 (* 1 = 0.880568 loss)
I0314 12:11:15.910226 16588 solver.cpp:228] Iteration 9500, loss = 0.503144
I0314 12:11:15.910226 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:11:15.910226 16588 solver.cpp:244]     Train net output #1: loss = 0.503144 (* 1 = 0.503144 loss)
I0314 12:11:15.910226 16588 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0314 12:11:30.106866 16588 solver.cpp:228] Iteration 9600, loss = 0.365562
I0314 12:11:30.106866 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:11:30.106866 16588 solver.cpp:244]     Train net output #1: loss = 0.365562 (* 1 = 0.365562 loss)
I0314 12:11:30.106866 16588 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0314 12:11:44.618506 16588 solver.cpp:228] Iteration 9700, loss = 0.544093
I0314 12:11:44.618506 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:11:44.618506 16588 solver.cpp:244]     Train net output #1: loss = 0.544093 (* 1 = 0.544093 loss)
I0314 12:11:44.618506 16588 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0314 12:11:59.174970 16588 solver.cpp:228] Iteration 9800, loss = 0.504789
I0314 12:11:59.175470 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:11:59.175470 16588 solver.cpp:244]     Train net output #1: loss = 0.504789 (* 1 = 0.504789 loss)
I0314 12:11:59.175470 16588 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0314 12:12:13.719614 16588 solver.cpp:228] Iteration 9900, loss = 0.377312
I0314 12:12:13.719614 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:12:13.719614 16588 solver.cpp:244]     Train net output #1: loss = 0.377312 (* 1 = 0.377312 loss)
I0314 12:12:13.719614 16588 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0314 12:12:28.194674 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_10000.caffemodel
I0314 12:12:28.232173 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_10000.solverstate
I0314 12:12:28.238674 16588 solver.cpp:337] Iteration 10000, Testing net (#0)
I0314 12:12:28.238674 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:12:33.039496 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7269
I0314 12:12:33.039496 16588 solver.cpp:404]     Test net output #1: loss = 0.82222 (* 1 = 0.82222 loss)
I0314 12:12:33.089499 16588 solver.cpp:228] Iteration 10000, loss = 0.411802
I0314 12:12:33.089499 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:12:33.089499 16588 solver.cpp:244]     Train net output #1: loss = 0.411802 (* 1 = 0.411802 loss)
I0314 12:12:33.089499 16588 sgd_solver.cpp:106] Iteration 10000, lr = 0.1
I0314 12:12:47.347592 16588 solver.cpp:228] Iteration 10100, loss = 0.532737
I0314 12:12:47.347592 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:12:47.347592 16588 solver.cpp:244]     Train net output #1: loss = 0.532737 (* 1 = 0.532737 loss)
I0314 12:12:47.347592 16588 sgd_solver.cpp:106] Iteration 10100, lr = 0.1
I0314 12:13:01.869194 16588 solver.cpp:228] Iteration 10200, loss = 0.487928
I0314 12:13:01.869194 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:13:01.869194 16588 solver.cpp:244]     Train net output #1: loss = 0.487928 (* 1 = 0.487928 loss)
I0314 12:13:01.869693 16588 sgd_solver.cpp:106] Iteration 10200, lr = 0.1
I0314 12:13:16.470405 16588 solver.cpp:228] Iteration 10300, loss = 0.480875
I0314 12:13:16.470405 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:13:16.470906 16588 solver.cpp:244]     Train net output #1: loss = 0.480875 (* 1 = 0.480875 loss)
I0314 12:13:16.470906 16588 sgd_solver.cpp:106] Iteration 10300, lr = 0.1
I0314 12:13:30.951849 16588 solver.cpp:228] Iteration 10400, loss = 0.416556
I0314 12:13:30.951849 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:13:30.951849 16588 solver.cpp:244]     Train net output #1: loss = 0.416556 (* 1 = 0.416556 loss)
I0314 12:13:30.951849 16588 sgd_solver.cpp:106] Iteration 10400, lr = 0.1
I0314 12:13:45.467342 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_10500.caffemodel
I0314 12:13:45.491842 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_10500.solverstate
I0314 12:13:45.498344 16588 solver.cpp:337] Iteration 10500, Testing net (#0)
I0314 12:13:45.498344 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:13:50.295976 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6526
I0314 12:13:50.295976 16588 solver.cpp:404]     Test net output #1: loss = 1.02609 (* 1 = 1.02609 loss)
I0314 12:13:50.346012 16588 solver.cpp:228] Iteration 10500, loss = 0.472727
I0314 12:13:50.346012 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:13:50.346012 16588 solver.cpp:244]     Train net output #1: loss = 0.472727 (* 1 = 0.472727 loss)
I0314 12:13:50.346513 16588 sgd_solver.cpp:106] Iteration 10500, lr = 0.1
I0314 12:14:04.603287 16588 solver.cpp:228] Iteration 10600, loss = 0.365655
I0314 12:14:04.603287 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:14:04.603287 16588 solver.cpp:244]     Train net output #1: loss = 0.365655 (* 1 = 0.365655 loss)
I0314 12:14:04.603287 16588 sgd_solver.cpp:106] Iteration 10600, lr = 0.1
I0314 12:14:19.130403 16588 solver.cpp:228] Iteration 10700, loss = 0.502341
I0314 12:14:19.130403 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:14:19.130403 16588 solver.cpp:244]     Train net output #1: loss = 0.502341 (* 1 = 0.502341 loss)
I0314 12:14:19.130403 16588 sgd_solver.cpp:106] Iteration 10700, lr = 0.1
I0314 12:14:33.625229 16588 solver.cpp:228] Iteration 10800, loss = 0.391877
I0314 12:14:33.625229 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:14:33.625229 16588 solver.cpp:244]     Train net output #1: loss = 0.391877 (* 1 = 0.391877 loss)
I0314 12:14:33.625229 16588 sgd_solver.cpp:106] Iteration 10800, lr = 0.1
I0314 12:14:48.189720 16588 solver.cpp:228] Iteration 10900, loss = 0.356521
I0314 12:14:48.189720 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:14:48.189720 16588 solver.cpp:244]     Train net output #1: loss = 0.356521 (* 1 = 0.356521 loss)
I0314 12:14:48.189720 16588 sgd_solver.cpp:106] Iteration 10900, lr = 0.1
I0314 12:15:02.660392 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_11000.caffemodel
I0314 12:15:02.697893 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_11000.solverstate
I0314 12:15:02.704391 16588 solver.cpp:337] Iteration 11000, Testing net (#0)
I0314 12:15:02.704391 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:15:07.617823 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7572
I0314 12:15:07.617823 16588 solver.cpp:404]     Test net output #1: loss = 0.73028 (* 1 = 0.73028 loss)
I0314 12:15:07.666823 16588 solver.cpp:228] Iteration 11000, loss = 0.411661
I0314 12:15:07.666823 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:15:07.666823 16588 solver.cpp:244]     Train net output #1: loss = 0.411661 (* 1 = 0.411661 loss)
I0314 12:15:07.666823 16588 sgd_solver.cpp:106] Iteration 11000, lr = 0.1
I0314 12:15:21.878769 16588 solver.cpp:228] Iteration 11100, loss = 0.480239
I0314 12:15:21.878769 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:15:21.878769 16588 solver.cpp:244]     Train net output #1: loss = 0.480239 (* 1 = 0.480239 loss)
I0314 12:15:21.878769 16588 sgd_solver.cpp:106] Iteration 11100, lr = 0.1
I0314 12:15:36.453197 16588 solver.cpp:228] Iteration 11200, loss = 0.503144
I0314 12:15:36.453696 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:15:36.453696 16588 solver.cpp:244]     Train net output #1: loss = 0.503144 (* 1 = 0.503144 loss)
I0314 12:15:36.453696 16588 sgd_solver.cpp:106] Iteration 11200, lr = 0.1
I0314 12:15:50.963870 16588 solver.cpp:228] Iteration 11300, loss = 0.452179
I0314 12:15:50.963870 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:15:50.963870 16588 solver.cpp:244]     Train net output #1: loss = 0.452179 (* 1 = 0.452179 loss)
I0314 12:15:50.963870 16588 sgd_solver.cpp:106] Iteration 11300, lr = 0.1
I0314 12:16:05.501793 16588 solver.cpp:228] Iteration 11400, loss = 0.355004
I0314 12:16:05.502293 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:16:05.502293 16588 solver.cpp:244]     Train net output #1: loss = 0.355004 (* 1 = 0.355004 loss)
I0314 12:16:05.502293 16588 sgd_solver.cpp:106] Iteration 11400, lr = 0.1
I0314 12:16:19.963095 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_11500.caffemodel
I0314 12:16:19.999131 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_11500.solverstate
I0314 12:16:20.006130 16588 solver.cpp:337] Iteration 11500, Testing net (#0)
I0314 12:16:20.006130 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:16:24.859729 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7133
I0314 12:16:24.860229 16588 solver.cpp:404]     Test net output #1: loss = 0.884034 (* 1 = 0.884034 loss)
I0314 12:16:24.909229 16588 solver.cpp:228] Iteration 11500, loss = 0.355342
I0314 12:16:24.909229 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:16:24.909229 16588 solver.cpp:244]     Train net output #1: loss = 0.355342 (* 1 = 0.355342 loss)
I0314 12:16:24.909729 16588 sgd_solver.cpp:106] Iteration 11500, lr = 0.1
I0314 12:16:39.207918 16588 solver.cpp:228] Iteration 11600, loss = 0.456107
I0314 12:16:39.208919 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:16:39.208919 16588 solver.cpp:244]     Train net output #1: loss = 0.456107 (* 1 = 0.456107 loss)
I0314 12:16:39.208919 16588 sgd_solver.cpp:106] Iteration 11600, lr = 0.1
I0314 12:16:53.712718 16588 solver.cpp:228] Iteration 11700, loss = 0.484432
I0314 12:16:53.712718 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:16:53.712718 16588 solver.cpp:244]     Train net output #1: loss = 0.484432 (* 1 = 0.484432 loss)
I0314 12:16:53.712718 16588 sgd_solver.cpp:106] Iteration 11700, lr = 0.1
I0314 12:17:08.266594 16588 solver.cpp:228] Iteration 11800, loss = 0.45371
I0314 12:17:08.266594 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:17:08.266594 16588 solver.cpp:244]     Train net output #1: loss = 0.45371 (* 1 = 0.45371 loss)
I0314 12:17:08.266594 16588 sgd_solver.cpp:106] Iteration 11800, lr = 0.1
I0314 12:17:22.886088 16588 solver.cpp:228] Iteration 11900, loss = 0.42294
I0314 12:17:22.886088 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:17:22.886088 16588 solver.cpp:244]     Train net output #1: loss = 0.42294 (* 1 = 0.42294 loss)
I0314 12:17:22.886088 16588 sgd_solver.cpp:106] Iteration 11900, lr = 0.1
I0314 12:17:37.389896 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_12000.caffemodel
I0314 12:17:37.426897 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_12000.solverstate
I0314 12:17:37.433895 16588 solver.cpp:337] Iteration 12000, Testing net (#0)
I0314 12:17:37.433895 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:17:42.339673 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6001
I0314 12:17:42.340173 16588 solver.cpp:404]     Test net output #1: loss = 1.46918 (* 1 = 1.46918 loss)
I0314 12:17:42.382670 16588 solver.cpp:228] Iteration 12000, loss = 0.398201
I0314 12:17:42.382670 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:17:42.382670 16588 solver.cpp:244]     Train net output #1: loss = 0.398201 (* 1 = 0.398201 loss)
I0314 12:17:42.382670 16588 sgd_solver.cpp:106] Iteration 12000, lr = 0.1
I0314 12:17:56.677176 16588 solver.cpp:228] Iteration 12100, loss = 0.43311
I0314 12:17:56.677678 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:17:56.677678 16588 solver.cpp:244]     Train net output #1: loss = 0.43311 (* 1 = 0.43311 loss)
I0314 12:17:56.677678 16588 sgd_solver.cpp:106] Iteration 12100, lr = 0.1
I0314 12:18:11.152868 16588 solver.cpp:228] Iteration 12200, loss = 0.581491
I0314 12:18:11.152868 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:18:11.152868 16588 solver.cpp:244]     Train net output #1: loss = 0.581491 (* 1 = 0.581491 loss)
I0314 12:18:11.152868 16588 sgd_solver.cpp:106] Iteration 12200, lr = 0.1
I0314 12:18:25.768525 16588 solver.cpp:228] Iteration 12300, loss = 0.478832
I0314 12:18:25.768525 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:18:25.768525 16588 solver.cpp:244]     Train net output #1: loss = 0.478832 (* 1 = 0.478832 loss)
I0314 12:18:25.768525 16588 sgd_solver.cpp:106] Iteration 12300, lr = 0.1
I0314 12:18:40.128636 16588 solver.cpp:228] Iteration 12400, loss = 0.454604
I0314 12:18:40.129135 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:18:40.129135 16588 solver.cpp:244]     Train net output #1: loss = 0.454604 (* 1 = 0.454604 loss)
I0314 12:18:40.129135 16588 sgd_solver.cpp:106] Iteration 12400, lr = 0.1
I0314 12:18:54.338716 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_12500.caffemodel
I0314 12:18:54.377215 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_12500.solverstate
I0314 12:18:54.384732 16588 solver.cpp:337] Iteration 12500, Testing net (#0)
I0314 12:18:54.384732 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:18:59.032279 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6985
I0314 12:18:59.032279 16588 solver.cpp:404]     Test net output #1: loss = 0.972685 (* 1 = 0.972685 loss)
I0314 12:18:59.075779 16588 solver.cpp:228] Iteration 12500, loss = 0.479269
I0314 12:18:59.075779 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:18:59.075779 16588 solver.cpp:244]     Train net output #1: loss = 0.479269 (* 1 = 0.479269 loss)
I0314 12:18:59.075779 16588 sgd_solver.cpp:106] Iteration 12500, lr = 0.1
I0314 12:19:12.740990 16588 solver.cpp:228] Iteration 12600, loss = 0.409281
I0314 12:19:12.740990 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:19:12.740990 16588 solver.cpp:244]     Train net output #1: loss = 0.409281 (* 1 = 0.409281 loss)
I0314 12:19:12.740990 16588 sgd_solver.cpp:106] Iteration 12600, lr = 0.1
I0314 12:19:26.934571 16588 solver.cpp:228] Iteration 12700, loss = 0.503664
I0314 12:19:26.935071 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:19:26.935071 16588 solver.cpp:244]     Train net output #1: loss = 0.503664 (* 1 = 0.503664 loss)
I0314 12:19:26.935071 16588 sgd_solver.cpp:106] Iteration 12700, lr = 0.1
I0314 12:19:41.169641 16588 solver.cpp:228] Iteration 12800, loss = 0.437495
I0314 12:19:41.169641 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:19:41.169641 16588 solver.cpp:244]     Train net output #1: loss = 0.437495 (* 1 = 0.437495 loss)
I0314 12:19:41.169641 16588 sgd_solver.cpp:106] Iteration 12800, lr = 0.1
I0314 12:19:55.073815 16588 solver.cpp:228] Iteration 12900, loss = 0.432703
I0314 12:19:55.073815 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:19:55.073815 16588 solver.cpp:244]     Train net output #1: loss = 0.432703 (* 1 = 0.432703 loss)
I0314 12:19:55.073815 16588 sgd_solver.cpp:106] Iteration 12900, lr = 0.1
I0314 12:20:08.996317 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_13000.caffemodel
I0314 12:20:09.015817 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_13000.solverstate
I0314 12:20:09.022817 16588 solver.cpp:337] Iteration 13000, Testing net (#0)
I0314 12:20:09.022817 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:20:13.639686 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6598
I0314 12:20:13.640187 16588 solver.cpp:404]     Test net output #1: loss = 1.10259 (* 1 = 1.10259 loss)
I0314 12:20:13.688186 16588 solver.cpp:228] Iteration 13000, loss = 0.353004
I0314 12:20:13.688186 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:20:13.688186 16588 solver.cpp:244]     Train net output #1: loss = 0.353004 (* 1 = 0.353004 loss)
I0314 12:20:13.688186 16588 sgd_solver.cpp:106] Iteration 13000, lr = 0.1
I0314 12:20:27.297679 16588 solver.cpp:228] Iteration 13100, loss = 0.439888
I0314 12:20:27.298182 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:20:27.298182 16588 solver.cpp:244]     Train net output #1: loss = 0.439888 (* 1 = 0.439888 loss)
I0314 12:20:27.298182 16588 sgd_solver.cpp:106] Iteration 13100, lr = 0.1
I0314 12:20:41.274374 16588 solver.cpp:228] Iteration 13200, loss = 0.494105
I0314 12:20:41.274374 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:20:41.274374 16588 solver.cpp:244]     Train net output #1: loss = 0.494105 (* 1 = 0.494105 loss)
I0314 12:20:41.274374 16588 sgd_solver.cpp:106] Iteration 13200, lr = 0.1
I0314 12:20:55.294908 16588 solver.cpp:228] Iteration 13300, loss = 0.458817
I0314 12:20:55.294908 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:20:55.294908 16588 solver.cpp:244]     Train net output #1: loss = 0.458817 (* 1 = 0.458817 loss)
I0314 12:20:55.294908 16588 sgd_solver.cpp:106] Iteration 13300, lr = 0.1
I0314 12:21:09.319404 16588 solver.cpp:228] Iteration 13400, loss = 0.406577
I0314 12:21:09.319905 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:21:09.319905 16588 solver.cpp:244]     Train net output #1: loss = 0.406577 (* 1 = 0.406577 loss)
I0314 12:21:09.319905 16588 sgd_solver.cpp:106] Iteration 13400, lr = 0.1
I0314 12:21:23.162554 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_13500.caffemodel
I0314 12:21:23.197053 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_13500.solverstate
I0314 12:21:23.204053 16588 solver.cpp:337] Iteration 13500, Testing net (#0)
I0314 12:21:23.204053 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:21:27.991056 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7554
I0314 12:21:27.991056 16588 solver.cpp:404]     Test net output #1: loss = 0.723092 (* 1 = 0.723092 loss)
I0314 12:21:28.034554 16588 solver.cpp:228] Iteration 13500, loss = 0.420233
I0314 12:21:28.034554 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:21:28.034554 16588 solver.cpp:244]     Train net output #1: loss = 0.420233 (* 1 = 0.420233 loss)
I0314 12:21:28.034554 16588 sgd_solver.cpp:106] Iteration 13500, lr = 0.1
I0314 12:21:41.518863 16588 solver.cpp:228] Iteration 13600, loss = 0.423931
I0314 12:21:41.519363 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:21:41.519363 16588 solver.cpp:244]     Train net output #1: loss = 0.423931 (* 1 = 0.423931 loss)
I0314 12:21:41.519363 16588 sgd_solver.cpp:106] Iteration 13600, lr = 0.1
I0314 12:21:55.566571 16588 solver.cpp:228] Iteration 13700, loss = 0.60487
I0314 12:21:55.566571 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0314 12:21:55.566571 16588 solver.cpp:244]     Train net output #1: loss = 0.60487 (* 1 = 0.60487 loss)
I0314 12:21:55.566571 16588 sgd_solver.cpp:106] Iteration 13700, lr = 0.1
I0314 12:22:10.177738 16588 solver.cpp:228] Iteration 13800, loss = 0.399289
I0314 12:22:10.177738 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:22:10.177738 16588 solver.cpp:244]     Train net output #1: loss = 0.399289 (* 1 = 0.399289 loss)
I0314 12:22:10.177738 16588 sgd_solver.cpp:106] Iteration 13800, lr = 0.1
I0314 12:22:24.834156 16588 solver.cpp:228] Iteration 13900, loss = 0.354862
I0314 12:22:24.834156 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:22:24.834156 16588 solver.cpp:244]     Train net output #1: loss = 0.354862 (* 1 = 0.354862 loss)
I0314 12:22:24.834656 16588 sgd_solver.cpp:106] Iteration 13900, lr = 0.1
I0314 12:22:39.609181 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_14000.caffemodel
I0314 12:22:39.648680 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_14000.solverstate
I0314 12:22:39.655702 16588 solver.cpp:337] Iteration 14000, Testing net (#0)
I0314 12:22:39.655702 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:22:44.591080 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6912
I0314 12:22:44.591080 16588 solver.cpp:404]     Test net output #1: loss = 0.979388 (* 1 = 0.979388 loss)
I0314 12:22:44.646313 16588 solver.cpp:228] Iteration 14000, loss = 0.406868
I0314 12:22:44.646313 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:22:44.646313 16588 solver.cpp:244]     Train net output #1: loss = 0.406868 (* 1 = 0.406868 loss)
I0314 12:22:44.646313 16588 sgd_solver.cpp:106] Iteration 14000, lr = 0.1
I0314 12:22:59.057991 16588 solver.cpp:228] Iteration 14100, loss = 0.390035
I0314 12:22:59.058480 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:22:59.058480 16588 solver.cpp:244]     Train net output #1: loss = 0.390035 (* 1 = 0.390035 loss)
I0314 12:22:59.058480 16588 sgd_solver.cpp:106] Iteration 14100, lr = 0.1
I0314 12:23:13.922842 16588 solver.cpp:228] Iteration 14200, loss = 0.574376
I0314 12:23:13.922842 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:23:13.922842 16588 solver.cpp:244]     Train net output #1: loss = 0.574376 (* 1 = 0.574376 loss)
I0314 12:23:13.922842 16588 sgd_solver.cpp:106] Iteration 14200, lr = 0.1
I0314 12:23:28.697083 16588 solver.cpp:228] Iteration 14300, loss = 0.449535
I0314 12:23:28.697083 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:23:28.697083 16588 solver.cpp:244]     Train net output #1: loss = 0.449535 (* 1 = 0.449535 loss)
I0314 12:23:28.697083 16588 sgd_solver.cpp:106] Iteration 14300, lr = 0.1
I0314 12:23:43.394183 16588 solver.cpp:228] Iteration 14400, loss = 0.504833
I0314 12:23:43.394183 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:23:43.394183 16588 solver.cpp:244]     Train net output #1: loss = 0.504833 (* 1 = 0.504833 loss)
I0314 12:23:43.394183 16588 sgd_solver.cpp:106] Iteration 14400, lr = 0.1
I0314 12:23:57.944481 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_14500.caffemodel
I0314 12:23:57.979979 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_14500.solverstate
I0314 12:23:57.986479 16588 solver.cpp:337] Iteration 14500, Testing net (#0)
I0314 12:23:57.986979 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:24:02.971177 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7399
I0314 12:24:02.971177 16588 solver.cpp:404]     Test net output #1: loss = 0.798932 (* 1 = 0.798932 loss)
I0314 12:24:03.017176 16588 solver.cpp:228] Iteration 14500, loss = 0.381981
I0314 12:24:03.017678 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:24:03.017678 16588 solver.cpp:244]     Train net output #1: loss = 0.381981 (* 1 = 0.381981 loss)
I0314 12:24:03.017678 16588 sgd_solver.cpp:106] Iteration 14500, lr = 0.1
I0314 12:24:17.320889 16588 solver.cpp:228] Iteration 14600, loss = 0.421953
I0314 12:24:17.321388 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:24:17.321388 16588 solver.cpp:244]     Train net output #1: loss = 0.421953 (* 1 = 0.421953 loss)
I0314 12:24:17.321388 16588 sgd_solver.cpp:106] Iteration 14600, lr = 0.1
I0314 12:24:31.947571 16588 solver.cpp:228] Iteration 14700, loss = 0.517551
I0314 12:24:31.947571 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:24:31.947571 16588 solver.cpp:244]     Train net output #1: loss = 0.517551 (* 1 = 0.517551 loss)
I0314 12:24:31.947571 16588 sgd_solver.cpp:106] Iteration 14700, lr = 0.1
I0314 12:24:46.573364 16588 solver.cpp:228] Iteration 14800, loss = 0.409044
I0314 12:24:46.573364 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:24:46.573364 16588 solver.cpp:244]     Train net output #1: loss = 0.409044 (* 1 = 0.409044 loss)
I0314 12:24:46.573364 16588 sgd_solver.cpp:106] Iteration 14800, lr = 0.1
I0314 12:25:01.316957 16588 solver.cpp:228] Iteration 14900, loss = 0.360181
I0314 12:25:01.316957 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 12:25:01.316957 16588 solver.cpp:244]     Train net output #1: loss = 0.360181 (* 1 = 0.360181 loss)
I0314 12:25:01.316957 16588 sgd_solver.cpp:106] Iteration 14900, lr = 0.1
I0314 12:25:16.051483 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_15000.caffemodel
I0314 12:25:16.079485 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_15000.solverstate
I0314 12:25:16.089985 16588 solver.cpp:337] Iteration 15000, Testing net (#0)
I0314 12:25:16.090486 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:25:21.174484 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7615
I0314 12:25:21.174484 16588 solver.cpp:404]     Test net output #1: loss = 0.707916 (* 1 = 0.707916 loss)
I0314 12:25:21.224984 16588 solver.cpp:228] Iteration 15000, loss = 0.385671
I0314 12:25:21.224984 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:25:21.224984 16588 solver.cpp:244]     Train net output #1: loss = 0.385671 (* 1 = 0.385671 loss)
I0314 12:25:21.224984 16588 sgd_solver.cpp:106] Iteration 15000, lr = 0.1
I0314 12:25:35.702340 16588 solver.cpp:228] Iteration 15100, loss = 0.353367
I0314 12:25:35.702340 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:25:35.702340 16588 solver.cpp:244]     Train net output #1: loss = 0.353367 (* 1 = 0.353367 loss)
I0314 12:25:35.702340 16588 sgd_solver.cpp:106] Iteration 15100, lr = 0.1
I0314 12:25:50.342144 16588 solver.cpp:228] Iteration 15200, loss = 0.555765
I0314 12:25:50.342144 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:25:50.342144 16588 solver.cpp:244]     Train net output #1: loss = 0.555765 (* 1 = 0.555765 loss)
I0314 12:25:50.342144 16588 sgd_solver.cpp:106] Iteration 15200, lr = 0.1
I0314 12:26:05.000744 16588 solver.cpp:228] Iteration 15300, loss = 0.385588
I0314 12:26:05.000744 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:26:05.000744 16588 solver.cpp:244]     Train net output #1: loss = 0.385588 (* 1 = 0.385588 loss)
I0314 12:26:05.000744 16588 sgd_solver.cpp:106] Iteration 15300, lr = 0.1
I0314 12:26:19.767038 16588 solver.cpp:228] Iteration 15400, loss = 0.352072
I0314 12:26:19.767038 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 12:26:19.767038 16588 solver.cpp:244]     Train net output #1: loss = 0.352072 (* 1 = 0.352072 loss)
I0314 12:26:19.767038 16588 sgd_solver.cpp:106] Iteration 15400, lr = 0.1
I0314 12:26:34.592582 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_15500.caffemodel
I0314 12:26:34.615083 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_15500.solverstate
I0314 12:26:34.623085 16588 solver.cpp:337] Iteration 15500, Testing net (#0)
I0314 12:26:34.623085 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:26:39.815582 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7644
I0314 12:26:39.815582 16588 solver.cpp:404]     Test net output #1: loss = 0.703096 (* 1 = 0.703096 loss)
I0314 12:26:39.858582 16588 solver.cpp:228] Iteration 15500, loss = 0.328053
I0314 12:26:39.859083 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 12:26:39.859083 16588 solver.cpp:244]     Train net output #1: loss = 0.328053 (* 1 = 0.328053 loss)
I0314 12:26:39.859083 16588 sgd_solver.cpp:106] Iteration 15500, lr = 0.1
I0314 12:26:54.252077 16588 solver.cpp:228] Iteration 15600, loss = 0.330866
I0314 12:26:54.252077 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:26:54.252077 16588 solver.cpp:244]     Train net output #1: loss = 0.330866 (* 1 = 0.330866 loss)
I0314 12:26:54.252077 16588 sgd_solver.cpp:106] Iteration 15600, lr = 0.1
I0314 12:27:09.257711 16588 solver.cpp:228] Iteration 15700, loss = 0.516884
I0314 12:27:09.257711 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:27:09.257711 16588 solver.cpp:244]     Train net output #1: loss = 0.516884 (* 1 = 0.516884 loss)
I0314 12:27:09.258211 16588 sgd_solver.cpp:106] Iteration 15700, lr = 0.1
I0314 12:27:24.303457 16588 solver.cpp:228] Iteration 15800, loss = 0.481922
I0314 12:27:24.303956 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:27:24.303956 16588 solver.cpp:244]     Train net output #1: loss = 0.481922 (* 1 = 0.481922 loss)
I0314 12:27:24.303956 16588 sgd_solver.cpp:106] Iteration 15800, lr = 0.1
I0314 12:27:39.118885 16588 solver.cpp:228] Iteration 15900, loss = 0.346732
I0314 12:27:39.118885 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:27:39.118885 16588 solver.cpp:244]     Train net output #1: loss = 0.346732 (* 1 = 0.346732 loss)
I0314 12:27:39.118885 16588 sgd_solver.cpp:106] Iteration 15900, lr = 0.1
I0314 12:27:54.094513 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_16000.caffemodel
I0314 12:27:54.133011 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_16000.solverstate
I0314 12:27:54.139511 16588 solver.cpp:337] Iteration 16000, Testing net (#0)
I0314 12:27:54.140012 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:27:59.396013 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7274
I0314 12:27:59.396013 16588 solver.cpp:404]     Test net output #1: loss = 0.852458 (* 1 = 0.852458 loss)
I0314 12:27:59.435513 16588 solver.cpp:228] Iteration 16000, loss = 0.368316
I0314 12:27:59.435513 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:27:59.435513 16588 solver.cpp:244]     Train net output #1: loss = 0.368316 (* 1 = 0.368316 loss)
I0314 12:27:59.436012 16588 sgd_solver.cpp:106] Iteration 16000, lr = 0.1
I0314 12:28:14.215589 16588 solver.cpp:228] Iteration 16100, loss = 0.36069
I0314 12:28:14.215589 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:28:14.215589 16588 solver.cpp:244]     Train net output #1: loss = 0.36069 (* 1 = 0.36069 loss)
I0314 12:28:14.215589 16588 sgd_solver.cpp:106] Iteration 16100, lr = 0.1
I0314 12:28:29.253556 16588 solver.cpp:228] Iteration 16200, loss = 0.588269
I0314 12:28:29.253556 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.76
I0314 12:28:29.253556 16588 solver.cpp:244]     Train net output #1: loss = 0.588269 (* 1 = 0.588269 loss)
I0314 12:28:29.253556 16588 sgd_solver.cpp:106] Iteration 16200, lr = 0.1
I0314 12:28:44.459622 16588 solver.cpp:228] Iteration 16300, loss = 0.434738
I0314 12:28:44.459622 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:28:44.460122 16588 solver.cpp:244]     Train net output #1: loss = 0.434738 (* 1 = 0.434738 loss)
I0314 12:28:44.460122 16588 sgd_solver.cpp:106] Iteration 16300, lr = 0.1
I0314 12:28:59.879619 16588 solver.cpp:228] Iteration 16400, loss = 0.356159
I0314 12:28:59.879619 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 12:28:59.879619 16588 solver.cpp:244]     Train net output #1: loss = 0.356159 (* 1 = 0.356159 loss)
I0314 12:28:59.879619 16588 sgd_solver.cpp:106] Iteration 16400, lr = 0.1
I0314 12:29:14.896200 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_16500.caffemodel
I0314 12:29:14.915700 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_16500.solverstate
I0314 12:29:14.922201 16588 solver.cpp:337] Iteration 16500, Testing net (#0)
I0314 12:29:14.922201 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:29:19.867492 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7902
I0314 12:29:19.867492 16588 solver.cpp:404]     Test net output #1: loss = 0.626035 (* 1 = 0.626035 loss)
I0314 12:29:19.920502 16588 solver.cpp:228] Iteration 16500, loss = 0.299577
I0314 12:29:19.920502 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0314 12:29:19.920502 16588 solver.cpp:244]     Train net output #1: loss = 0.299577 (* 1 = 0.299577 loss)
I0314 12:29:19.920502 16588 sgd_solver.cpp:106] Iteration 16500, lr = 0.1
I0314 12:29:34.147748 16588 solver.cpp:228] Iteration 16600, loss = 0.418827
I0314 12:29:34.147748 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:29:34.147748 16588 solver.cpp:244]     Train net output #1: loss = 0.418827 (* 1 = 0.418827 loss)
I0314 12:29:34.148252 16588 sgd_solver.cpp:106] Iteration 16600, lr = 0.1
I0314 12:29:48.806494 16588 solver.cpp:228] Iteration 16700, loss = 0.426104
I0314 12:29:48.806494 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:29:48.806494 16588 solver.cpp:244]     Train net output #1: loss = 0.426104 (* 1 = 0.426104 loss)
I0314 12:29:48.806494 16588 sgd_solver.cpp:106] Iteration 16700, lr = 0.1
I0314 12:30:03.586285 16588 solver.cpp:228] Iteration 16800, loss = 0.438956
I0314 12:30:03.586285 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:30:03.586285 16588 solver.cpp:244]     Train net output #1: loss = 0.438956 (* 1 = 0.438956 loss)
I0314 12:30:03.586285 16588 sgd_solver.cpp:106] Iteration 16800, lr = 0.1
I0314 12:30:18.234426 16588 solver.cpp:228] Iteration 16900, loss = 0.346905
I0314 12:30:18.234426 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:30:18.234426 16588 solver.cpp:244]     Train net output #1: loss = 0.346905 (* 1 = 0.346905 loss)
I0314 12:30:18.234426 16588 sgd_solver.cpp:106] Iteration 16900, lr = 0.1
I0314 12:30:32.860743 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_17000.caffemodel
I0314 12:30:32.900743 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_17000.solverstate
I0314 12:30:32.906744 16588 solver.cpp:337] Iteration 17000, Testing net (#0)
I0314 12:30:32.906744 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:30:37.849272 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7053
I0314 12:30:37.849272 16588 solver.cpp:404]     Test net output #1: loss = 0.90314 (* 1 = 0.90314 loss)
I0314 12:30:37.887272 16588 solver.cpp:228] Iteration 17000, loss = 0.329052
I0314 12:30:37.887272 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:30:37.887272 16588 solver.cpp:244]     Train net output #1: loss = 0.329052 (* 1 = 0.329052 loss)
I0314 12:30:37.887272 16588 sgd_solver.cpp:106] Iteration 17000, lr = 0.1
I0314 12:30:52.196336 16588 solver.cpp:228] Iteration 17100, loss = 0.386674
I0314 12:30:52.196836 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:30:52.196836 16588 solver.cpp:244]     Train net output #1: loss = 0.386674 (* 1 = 0.386674 loss)
I0314 12:30:52.196836 16588 sgd_solver.cpp:106] Iteration 17100, lr = 0.1
I0314 12:31:06.941427 16588 solver.cpp:228] Iteration 17200, loss = 0.589212
I0314 12:31:06.941427 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:31:06.941427 16588 solver.cpp:244]     Train net output #1: loss = 0.589212 (* 1 = 0.589212 loss)
I0314 12:31:06.941427 16588 sgd_solver.cpp:106] Iteration 17200, lr = 0.1
I0314 12:31:21.781332 16588 solver.cpp:228] Iteration 17300, loss = 0.37303
I0314 12:31:21.781831 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0314 12:31:21.781831 16588 solver.cpp:244]     Train net output #1: loss = 0.37303 (* 1 = 0.37303 loss)
I0314 12:31:21.781831 16588 sgd_solver.cpp:106] Iteration 17300, lr = 0.1
I0314 12:31:36.515229 16588 solver.cpp:228] Iteration 17400, loss = 0.333091
I0314 12:31:36.515729 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:31:36.515729 16588 solver.cpp:244]     Train net output #1: loss = 0.333091 (* 1 = 0.333091 loss)
I0314 12:31:36.515729 16588 sgd_solver.cpp:106] Iteration 17400, lr = 0.1
I0314 12:31:51.120117 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_17500.caffemodel
I0314 12:31:51.157609 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_17500.solverstate
I0314 12:31:51.164609 16588 solver.cpp:337] Iteration 17500, Testing net (#0)
I0314 12:31:51.164609 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:31:56.179220 16588 solver.cpp:404]     Test net output #0: accuracy = 0.697
I0314 12:31:56.179220 16588 solver.cpp:404]     Test net output #1: loss = 0.934673 (* 1 = 0.934673 loss)
I0314 12:31:56.234220 16588 solver.cpp:228] Iteration 17500, loss = 0.46573
I0314 12:31:56.234220 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:31:56.234220 16588 solver.cpp:244]     Train net output #1: loss = 0.46573 (* 1 = 0.46573 loss)
I0314 12:31:56.234220 16588 sgd_solver.cpp:106] Iteration 17500, lr = 0.1
I0314 12:32:10.572526 16588 solver.cpp:228] Iteration 17600, loss = 0.503904
I0314 12:32:10.572526 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 12:32:10.572526 16588 solver.cpp:244]     Train net output #1: loss = 0.503904 (* 1 = 0.503904 loss)
I0314 12:32:10.572526 16588 sgd_solver.cpp:106] Iteration 17600, lr = 0.1
I0314 12:32:25.234499 16588 solver.cpp:228] Iteration 17700, loss = 0.495541
I0314 12:32:25.234499 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:32:25.234499 16588 solver.cpp:244]     Train net output #1: loss = 0.495541 (* 1 = 0.495541 loss)
I0314 12:32:25.234499 16588 sgd_solver.cpp:106] Iteration 17700, lr = 0.1
I0314 12:32:39.827710 16588 solver.cpp:228] Iteration 17800, loss = 0.497628
I0314 12:32:39.827710 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:32:39.827710 16588 solver.cpp:244]     Train net output #1: loss = 0.497628 (* 1 = 0.497628 loss)
I0314 12:32:39.827710 16588 sgd_solver.cpp:106] Iteration 17800, lr = 0.1
I0314 12:32:54.494395 16588 solver.cpp:228] Iteration 17900, loss = 0.436915
I0314 12:32:54.494395 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:32:54.494395 16588 solver.cpp:244]     Train net output #1: loss = 0.436915 (* 1 = 0.436915 loss)
I0314 12:32:54.494395 16588 sgd_solver.cpp:106] Iteration 17900, lr = 0.1
I0314 12:33:09.061664 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_18000.caffemodel
I0314 12:33:09.103664 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_18000.solverstate
I0314 12:33:09.111166 16588 solver.cpp:337] Iteration 18000, Testing net (#0)
I0314 12:33:09.111166 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:33:14.152179 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7558
I0314 12:33:14.152179 16588 solver.cpp:404]     Test net output #1: loss = 0.724377 (* 1 = 0.724377 loss)
I0314 12:33:14.202680 16588 solver.cpp:228] Iteration 18000, loss = 0.397262
I0314 12:33:14.202680 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:33:14.202680 16588 solver.cpp:244]     Train net output #1: loss = 0.397262 (* 1 = 0.397262 loss)
I0314 12:33:14.202680 16588 sgd_solver.cpp:106] Iteration 18000, lr = 0.1
I0314 12:33:28.597569 16588 solver.cpp:228] Iteration 18100, loss = 0.427628
I0314 12:33:28.597569 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:33:28.597569 16588 solver.cpp:244]     Train net output #1: loss = 0.427628 (* 1 = 0.427628 loss)
I0314 12:33:28.597569 16588 sgd_solver.cpp:106] Iteration 18100, lr = 0.1
I0314 12:33:43.645992 16588 solver.cpp:228] Iteration 18200, loss = 0.456133
I0314 12:33:43.645992 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:33:43.645992 16588 solver.cpp:244]     Train net output #1: loss = 0.456133 (* 1 = 0.456133 loss)
I0314 12:33:43.645992 16588 sgd_solver.cpp:106] Iteration 18200, lr = 0.1
I0314 12:33:58.471417 16588 solver.cpp:228] Iteration 18300, loss = 0.461989
I0314 12:33:58.471417 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:33:58.471417 16588 solver.cpp:244]     Train net output #1: loss = 0.461989 (* 1 = 0.461989 loss)
I0314 12:33:58.471417 16588 sgd_solver.cpp:106] Iteration 18300, lr = 0.1
I0314 12:34:13.246556 16588 solver.cpp:228] Iteration 18400, loss = 0.354685
I0314 12:34:13.247045 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 12:34:13.247045 16588 solver.cpp:244]     Train net output #1: loss = 0.354684 (* 1 = 0.354684 loss)
I0314 12:34:13.247045 16588 sgd_solver.cpp:106] Iteration 18400, lr = 0.1
I0314 12:34:27.876842 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_18500.caffemodel
I0314 12:34:27.914345 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_18500.solverstate
I0314 12:34:27.920842 16588 solver.cpp:337] Iteration 18500, Testing net (#0)
I0314 12:34:27.920842 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:34:32.829943 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7411
I0314 12:34:32.829943 16588 solver.cpp:404]     Test net output #1: loss = 0.791665 (* 1 = 0.791665 loss)
I0314 12:34:32.879938 16588 solver.cpp:228] Iteration 18500, loss = 0.427799
I0314 12:34:32.879938 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:34:32.879938 16588 solver.cpp:244]     Train net output #1: loss = 0.427799 (* 1 = 0.427799 loss)
I0314 12:34:32.879938 16588 sgd_solver.cpp:106] Iteration 18500, lr = 0.1
I0314 12:34:47.060849 16588 solver.cpp:228] Iteration 18600, loss = 0.357088
I0314 12:34:47.060849 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:34:47.060849 16588 solver.cpp:244]     Train net output #1: loss = 0.357088 (* 1 = 0.357088 loss)
I0314 12:34:47.060849 16588 sgd_solver.cpp:106] Iteration 18600, lr = 0.1
I0314 12:35:01.742272 16588 solver.cpp:228] Iteration 18700, loss = 0.546521
I0314 12:35:01.742272 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:35:01.742272 16588 solver.cpp:244]     Train net output #1: loss = 0.546521 (* 1 = 0.546521 loss)
I0314 12:35:01.742272 16588 sgd_solver.cpp:106] Iteration 18700, lr = 0.1
I0314 12:35:16.438097 16588 solver.cpp:228] Iteration 18800, loss = 0.430643
I0314 12:35:16.438097 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:35:16.438097 16588 solver.cpp:244]     Train net output #1: loss = 0.430643 (* 1 = 0.430643 loss)
I0314 12:35:16.438097 16588 sgd_solver.cpp:106] Iteration 18800, lr = 0.1
I0314 12:35:31.285418 16588 solver.cpp:228] Iteration 18900, loss = 0.353362
I0314 12:35:31.285418 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:35:31.285418 16588 solver.cpp:244]     Train net output #1: loss = 0.353362 (* 1 = 0.353362 loss)
I0314 12:35:31.285418 16588 sgd_solver.cpp:106] Iteration 18900, lr = 0.1
I0314 12:35:46.132102 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_19000.caffemodel
I0314 12:35:46.152099 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_19000.solverstate
I0314 12:35:46.158099 16588 solver.cpp:337] Iteration 19000, Testing net (#0)
I0314 12:35:46.158599 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:35:51.129819 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6799
I0314 12:35:51.130321 16588 solver.cpp:404]     Test net output #1: loss = 0.950917 (* 1 = 0.950917 loss)
I0314 12:35:51.172319 16588 solver.cpp:228] Iteration 19000, loss = 0.392346
I0314 12:35:51.172319 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:35:51.172319 16588 solver.cpp:244]     Train net output #1: loss = 0.392346 (* 1 = 0.392346 loss)
I0314 12:35:51.172319 16588 sgd_solver.cpp:106] Iteration 19000, lr = 0.1
I0314 12:36:05.627696 16588 solver.cpp:228] Iteration 19100, loss = 0.372805
I0314 12:36:05.627696 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:36:05.627696 16588 solver.cpp:244]     Train net output #1: loss = 0.372804 (* 1 = 0.372804 loss)
I0314 12:36:05.627696 16588 sgd_solver.cpp:106] Iteration 19100, lr = 0.1
I0314 12:36:20.331346 16588 solver.cpp:228] Iteration 19200, loss = 0.59946
I0314 12:36:20.331346 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:36:20.331346 16588 solver.cpp:244]     Train net output #1: loss = 0.59946 (* 1 = 0.59946 loss)
I0314 12:36:20.331346 16588 sgd_solver.cpp:106] Iteration 19200, lr = 0.1
I0314 12:36:35.114567 16588 solver.cpp:228] Iteration 19300, loss = 0.44264
I0314 12:36:35.114567 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:36:35.114567 16588 solver.cpp:244]     Train net output #1: loss = 0.44264 (* 1 = 0.44264 loss)
I0314 12:36:35.114567 16588 sgd_solver.cpp:106] Iteration 19300, lr = 0.1
I0314 12:36:49.768884 16588 solver.cpp:228] Iteration 19400, loss = 0.35293
I0314 12:36:49.768884 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:36:49.768884 16588 solver.cpp:244]     Train net output #1: loss = 0.35293 (* 1 = 0.35293 loss)
I0314 12:36:49.768884 16588 sgd_solver.cpp:106] Iteration 19400, lr = 0.1
I0314 12:37:04.463562 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_19500.caffemodel
I0314 12:37:04.503056 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_19500.solverstate
I0314 12:37:04.510056 16588 solver.cpp:337] Iteration 19500, Testing net (#0)
I0314 12:37:04.510056 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:37:09.462736 16588 solver.cpp:404]     Test net output #0: accuracy = 0.717
I0314 12:37:09.462736 16588 solver.cpp:404]     Test net output #1: loss = 0.90863 (* 1 = 0.90863 loss)
I0314 12:37:09.513737 16588 solver.cpp:228] Iteration 19500, loss = 0.352359
I0314 12:37:09.513737 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:37:09.513737 16588 solver.cpp:244]     Train net output #1: loss = 0.352359 (* 1 = 0.352359 loss)
I0314 12:37:09.513737 16588 sgd_solver.cpp:106] Iteration 19500, lr = 0.1
I0314 12:37:23.932117 16588 solver.cpp:228] Iteration 19600, loss = 0.435503
I0314 12:37:23.932117 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:37:23.932117 16588 solver.cpp:244]     Train net output #1: loss = 0.435503 (* 1 = 0.435503 loss)
I0314 12:37:23.932117 16588 sgd_solver.cpp:106] Iteration 19600, lr = 0.1
I0314 12:37:38.675045 16588 solver.cpp:228] Iteration 19700, loss = 0.578915
I0314 12:37:38.675045 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0314 12:37:38.675045 16588 solver.cpp:244]     Train net output #1: loss = 0.578915 (* 1 = 0.578915 loss)
I0314 12:37:38.675045 16588 sgd_solver.cpp:106] Iteration 19700, lr = 0.1
I0314 12:37:53.299142 16588 solver.cpp:228] Iteration 19800, loss = 0.444436
I0314 12:37:53.299142 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:37:53.299142 16588 solver.cpp:244]     Train net output #1: loss = 0.444436 (* 1 = 0.444436 loss)
I0314 12:37:53.299142 16588 sgd_solver.cpp:106] Iteration 19800, lr = 0.1
I0314 12:38:07.989529 16588 solver.cpp:228] Iteration 19900, loss = 0.311548
I0314 12:38:07.989529 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:38:07.989529 16588 solver.cpp:244]     Train net output #1: loss = 0.311548 (* 1 = 0.311548 loss)
I0314 12:38:07.989529 16588 sgd_solver.cpp:106] Iteration 19900, lr = 0.1
I0314 12:38:22.738157 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_20000.caffemodel
I0314 12:38:22.785156 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_20000.solverstate
I0314 12:38:22.792657 16588 solver.cpp:337] Iteration 20000, Testing net (#0)
I0314 12:38:22.792657 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:38:27.729699 16588 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0314 12:38:27.729699 16588 solver.cpp:404]     Test net output #1: loss = 0.70981 (* 1 = 0.70981 loss)
I0314 12:38:27.784699 16588 solver.cpp:228] Iteration 20000, loss = 0.3331
I0314 12:38:27.784699 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:38:27.784699 16588 solver.cpp:244]     Train net output #1: loss = 0.3331 (* 1 = 0.3331 loss)
I0314 12:38:27.784699 16588 sgd_solver.cpp:106] Iteration 20000, lr = 0.1
I0314 12:38:41.968981 16588 solver.cpp:228] Iteration 20100, loss = 0.429547
I0314 12:38:41.969482 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:38:41.969482 16588 solver.cpp:244]     Train net output #1: loss = 0.429547 (* 1 = 0.429547 loss)
I0314 12:38:41.969482 16588 sgd_solver.cpp:106] Iteration 20100, lr = 0.1
I0314 12:38:56.666837 16588 solver.cpp:228] Iteration 20200, loss = 0.539428
I0314 12:38:56.666837 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:38:56.666837 16588 solver.cpp:244]     Train net output #1: loss = 0.539428 (* 1 = 0.539428 loss)
I0314 12:38:56.666837 16588 sgd_solver.cpp:106] Iteration 20200, lr = 0.1
I0314 12:39:11.479990 16588 solver.cpp:228] Iteration 20300, loss = 0.433467
I0314 12:39:11.480489 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:39:11.480489 16588 solver.cpp:244]     Train net output #1: loss = 0.433467 (* 1 = 0.433467 loss)
I0314 12:39:11.480489 16588 sgd_solver.cpp:106] Iteration 20300, lr = 0.1
I0314 12:39:26.275063 16588 solver.cpp:228] Iteration 20400, loss = 0.363278
I0314 12:39:26.275063 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:39:26.275063 16588 solver.cpp:244]     Train net output #1: loss = 0.363278 (* 1 = 0.363278 loss)
I0314 12:39:26.275063 16588 sgd_solver.cpp:106] Iteration 20400, lr = 0.1
I0314 12:39:40.977012 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_20500.caffemodel
I0314 12:39:40.997512 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_20500.solverstate
I0314 12:39:41.004511 16588 solver.cpp:337] Iteration 20500, Testing net (#0)
I0314 12:39:41.004511 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:39:46.003684 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6774
I0314 12:39:46.003684 16588 solver.cpp:404]     Test net output #1: loss = 1.08139 (* 1 = 1.08139 loss)
I0314 12:39:46.034689 16588 solver.cpp:228] Iteration 20500, loss = 0.465696
I0314 12:39:46.034689 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:39:46.034689 16588 solver.cpp:244]     Train net output #1: loss = 0.465696 (* 1 = 0.465696 loss)
I0314 12:39:46.034689 16588 sgd_solver.cpp:106] Iteration 20500, lr = 0.1
I0314 12:40:00.206682 16588 solver.cpp:228] Iteration 20600, loss = 0.404622
I0314 12:40:00.206682 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:40:00.206682 16588 solver.cpp:244]     Train net output #1: loss = 0.404622 (* 1 = 0.404622 loss)
I0314 12:40:00.206682 16588 sgd_solver.cpp:106] Iteration 20600, lr = 0.1
I0314 12:40:14.749035 16588 solver.cpp:228] Iteration 20700, loss = 0.436964
I0314 12:40:14.749547 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:40:14.749547 16588 solver.cpp:244]     Train net output #1: loss = 0.436964 (* 1 = 0.436964 loss)
I0314 12:40:14.749547 16588 sgd_solver.cpp:106] Iteration 20700, lr = 0.1
I0314 12:40:29.348181 16588 solver.cpp:228] Iteration 20800, loss = 0.517751
I0314 12:40:29.348181 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:40:29.348181 16588 solver.cpp:244]     Train net output #1: loss = 0.517751 (* 1 = 0.517751 loss)
I0314 12:40:29.348181 16588 sgd_solver.cpp:106] Iteration 20800, lr = 0.1
I0314 12:40:43.813228 16588 solver.cpp:228] Iteration 20900, loss = 0.301708
I0314 12:40:43.813729 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 12:40:43.813729 16588 solver.cpp:244]     Train net output #1: loss = 0.301708 (* 1 = 0.301708 loss)
I0314 12:40:43.813729 16588 sgd_solver.cpp:106] Iteration 20900, lr = 0.1
I0314 12:40:58.041254 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_21000.caffemodel
I0314 12:40:58.079752 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_21000.solverstate
I0314 12:40:58.086751 16588 solver.cpp:337] Iteration 21000, Testing net (#0)
I0314 12:40:58.087251 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:41:03.279225 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7807
I0314 12:41:03.279225 16588 solver.cpp:404]     Test net output #1: loss = 0.665463 (* 1 = 0.665463 loss)
I0314 12:41:03.353729 16588 solver.cpp:228] Iteration 21000, loss = 0.386084
I0314 12:41:03.353729 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:41:03.353729 16588 solver.cpp:244]     Train net output #1: loss = 0.386084 (* 1 = 0.386084 loss)
I0314 12:41:03.353729 16588 sgd_solver.cpp:106] Iteration 21000, lr = 0.1
I0314 12:41:16.915848 16588 solver.cpp:228] Iteration 21100, loss = 0.441442
I0314 12:41:16.915848 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:41:16.915848 16588 solver.cpp:244]     Train net output #1: loss = 0.441442 (* 1 = 0.441442 loss)
I0314 12:41:16.915848 16588 sgd_solver.cpp:106] Iteration 21100, lr = 0.1
I0314 12:41:30.585157 16588 solver.cpp:228] Iteration 21200, loss = 0.576534
I0314 12:41:30.585157 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:41:30.585157 16588 solver.cpp:244]     Train net output #1: loss = 0.576534 (* 1 = 0.576534 loss)
I0314 12:41:30.585157 16588 sgd_solver.cpp:106] Iteration 21200, lr = 0.1
I0314 12:41:44.520635 16588 solver.cpp:228] Iteration 21300, loss = 0.445223
I0314 12:41:44.520635 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:41:44.520635 16588 solver.cpp:244]     Train net output #1: loss = 0.445223 (* 1 = 0.445223 loss)
I0314 12:41:44.520635 16588 sgd_solver.cpp:106] Iteration 21300, lr = 0.1
I0314 12:41:58.434321 16588 solver.cpp:228] Iteration 21400, loss = 0.336705
I0314 12:41:58.434321 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:41:58.434321 16588 solver.cpp:244]     Train net output #1: loss = 0.336705 (* 1 = 0.336705 loss)
I0314 12:41:58.434321 16588 sgd_solver.cpp:106] Iteration 21400, lr = 0.1
I0314 12:42:12.217569 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_21500.caffemodel
I0314 12:42:12.254570 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_21500.solverstate
I0314 12:42:12.261570 16588 solver.cpp:337] Iteration 21500, Testing net (#0)
I0314 12:42:12.261570 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:42:17.015569 16588 solver.cpp:404]     Test net output #0: accuracy = 0.694
I0314 12:42:17.015569 16588 solver.cpp:404]     Test net output #1: loss = 0.971972 (* 1 = 0.971972 loss)
I0314 12:42:17.048069 16588 solver.cpp:228] Iteration 21500, loss = 0.319959
I0314 12:42:17.048069 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:42:17.048069 16588 solver.cpp:244]     Train net output #1: loss = 0.319959 (* 1 = 0.319959 loss)
I0314 12:42:17.048069 16588 sgd_solver.cpp:106] Iteration 21500, lr = 0.1
I0314 12:42:30.569878 16588 solver.cpp:228] Iteration 21600, loss = 0.422996
I0314 12:42:30.569878 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:42:30.569878 16588 solver.cpp:244]     Train net output #1: loss = 0.422996 (* 1 = 0.422996 loss)
I0314 12:42:30.569878 16588 sgd_solver.cpp:106] Iteration 21600, lr = 0.1
I0314 12:42:44.430553 16588 solver.cpp:228] Iteration 21700, loss = 0.47238
I0314 12:42:44.430553 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:42:44.430553 16588 solver.cpp:244]     Train net output #1: loss = 0.47238 (* 1 = 0.47238 loss)
I0314 12:42:44.430553 16588 sgd_solver.cpp:106] Iteration 21700, lr = 0.1
I0314 12:42:58.430788 16588 solver.cpp:228] Iteration 21800, loss = 0.431422
I0314 12:42:58.430788 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:42:58.430788 16588 solver.cpp:244]     Train net output #1: loss = 0.431422 (* 1 = 0.431422 loss)
I0314 12:42:58.430788 16588 sgd_solver.cpp:106] Iteration 21800, lr = 0.1
I0314 12:43:12.482127 16588 solver.cpp:228] Iteration 21900, loss = 0.385992
I0314 12:43:12.482127 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:43:12.482127 16588 solver.cpp:244]     Train net output #1: loss = 0.385992 (* 1 = 0.385992 loss)
I0314 12:43:12.482127 16588 sgd_solver.cpp:106] Iteration 21900, lr = 0.1
I0314 12:43:26.446988 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_22000.caffemodel
I0314 12:43:26.483489 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_22000.solverstate
I0314 12:43:26.490489 16588 solver.cpp:337] Iteration 22000, Testing net (#0)
I0314 12:43:26.490489 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:43:31.142488 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6815
I0314 12:43:31.142488 16588 solver.cpp:404]     Test net output #1: loss = 1.07087 (* 1 = 1.07087 loss)
I0314 12:43:31.212488 16588 solver.cpp:228] Iteration 22000, loss = 0.406464
I0314 12:43:31.212488 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:43:31.212488 16588 solver.cpp:244]     Train net output #1: loss = 0.406464 (* 1 = 0.406464 loss)
I0314 12:43:31.212488 16588 sgd_solver.cpp:106] Iteration 22000, lr = 0.1
I0314 12:43:44.706018 16588 solver.cpp:228] Iteration 22100, loss = 0.455811
I0314 12:43:44.706018 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0314 12:43:44.706018 16588 solver.cpp:244]     Train net output #1: loss = 0.455811 (* 1 = 0.455811 loss)
I0314 12:43:44.706018 16588 sgd_solver.cpp:106] Iteration 22100, lr = 0.1
I0314 12:43:58.693830 16588 solver.cpp:228] Iteration 22200, loss = 0.385192
I0314 12:43:58.694329 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:43:58.694329 16588 solver.cpp:244]     Train net output #1: loss = 0.385191 (* 1 = 0.385191 loss)
I0314 12:43:58.694329 16588 sgd_solver.cpp:106] Iteration 22200, lr = 0.1
I0314 12:44:12.551143 16588 solver.cpp:228] Iteration 22300, loss = 0.419684
I0314 12:44:12.551143 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:44:12.551643 16588 solver.cpp:244]     Train net output #1: loss = 0.419684 (* 1 = 0.419684 loss)
I0314 12:44:12.551643 16588 sgd_solver.cpp:106] Iteration 22300, lr = 0.1
I0314 12:44:26.409387 16588 solver.cpp:228] Iteration 22400, loss = 0.343771
I0314 12:44:26.409387 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:44:26.409387 16588 solver.cpp:244]     Train net output #1: loss = 0.343771 (* 1 = 0.343771 loss)
I0314 12:44:26.409387 16588 sgd_solver.cpp:106] Iteration 22400, lr = 0.1
I0314 12:44:40.308462 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_22500.caffemodel
I0314 12:44:40.344462 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_22500.solverstate
I0314 12:44:40.350963 16588 solver.cpp:337] Iteration 22500, Testing net (#0)
I0314 12:44:40.351464 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:44:45.168463 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7951
I0314 12:44:45.168463 16588 solver.cpp:404]     Test net output #1: loss = 0.61982 (* 1 = 0.61982 loss)
I0314 12:44:45.209964 16588 solver.cpp:228] Iteration 22500, loss = 0.384709
I0314 12:44:45.209964 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:44:45.209964 16588 solver.cpp:244]     Train net output #1: loss = 0.384709 (* 1 = 0.384709 loss)
I0314 12:44:45.210464 16588 sgd_solver.cpp:106] Iteration 22500, lr = 0.1
I0314 12:44:58.770594 16588 solver.cpp:228] Iteration 22600, loss = 0.453162
I0314 12:44:58.770594 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:44:58.770594 16588 solver.cpp:244]     Train net output #1: loss = 0.453162 (* 1 = 0.453162 loss)
I0314 12:44:58.770594 16588 sgd_solver.cpp:106] Iteration 22600, lr = 0.1
I0314 12:45:12.633033 16588 solver.cpp:228] Iteration 22700, loss = 0.476163
I0314 12:45:12.633033 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:45:12.633033 16588 solver.cpp:244]     Train net output #1: loss = 0.476163 (* 1 = 0.476163 loss)
I0314 12:45:12.633033 16588 sgd_solver.cpp:106] Iteration 22700, lr = 0.1
I0314 12:45:26.575645 16588 solver.cpp:228] Iteration 22800, loss = 0.399271
I0314 12:45:26.575645 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:45:26.575645 16588 solver.cpp:244]     Train net output #1: loss = 0.399271 (* 1 = 0.399271 loss)
I0314 12:45:26.575645 16588 sgd_solver.cpp:106] Iteration 22800, lr = 0.1
I0314 12:45:40.625922 16588 solver.cpp:228] Iteration 22900, loss = 0.341349
I0314 12:45:40.625922 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 12:45:40.625922 16588 solver.cpp:244]     Train net output #1: loss = 0.341349 (* 1 = 0.341349 loss)
I0314 12:45:40.625922 16588 sgd_solver.cpp:106] Iteration 22900, lr = 0.1
I0314 12:45:54.625018 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_23000.caffemodel
I0314 12:45:54.644629 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_23000.solverstate
I0314 12:45:54.651131 16588 solver.cpp:337] Iteration 23000, Testing net (#0)
I0314 12:45:54.651131 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:45:59.415705 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7556
I0314 12:45:59.415705 16588 solver.cpp:404]     Test net output #1: loss = 0.740039 (* 1 = 0.740039 loss)
I0314 12:45:59.459205 16588 solver.cpp:228] Iteration 23000, loss = 0.393184
I0314 12:45:59.459205 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:45:59.459205 16588 solver.cpp:244]     Train net output #1: loss = 0.393184 (* 1 = 0.393184 loss)
I0314 12:45:59.459205 16588 sgd_solver.cpp:106] Iteration 23000, lr = 0.1
I0314 12:46:12.834215 16588 solver.cpp:228] Iteration 23100, loss = 0.42374
I0314 12:46:12.834215 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:46:12.834728 16588 solver.cpp:244]     Train net output #1: loss = 0.42374 (* 1 = 0.42374 loss)
I0314 12:46:12.834728 16588 sgd_solver.cpp:106] Iteration 23100, lr = 0.1
I0314 12:46:26.885059 16588 solver.cpp:228] Iteration 23200, loss = 0.547899
I0314 12:46:26.885059 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 12:46:26.885059 16588 solver.cpp:244]     Train net output #1: loss = 0.547899 (* 1 = 0.547899 loss)
I0314 12:46:26.885059 16588 sgd_solver.cpp:106] Iteration 23200, lr = 0.1
I0314 12:46:40.754312 16588 solver.cpp:228] Iteration 23300, loss = 0.341234
I0314 12:46:40.754312 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:46:40.754312 16588 solver.cpp:244]     Train net output #1: loss = 0.341234 (* 1 = 0.341234 loss)
I0314 12:46:40.754312 16588 sgd_solver.cpp:106] Iteration 23300, lr = 0.1
I0314 12:46:54.713835 16588 solver.cpp:228] Iteration 23400, loss = 0.30313
I0314 12:46:54.713835 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:46:54.713835 16588 solver.cpp:244]     Train net output #1: loss = 0.30313 (* 1 = 0.30313 loss)
I0314 12:46:54.713835 16588 sgd_solver.cpp:106] Iteration 23400, lr = 0.1
I0314 12:47:08.698107 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_23500.caffemodel
I0314 12:47:08.717608 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_23500.solverstate
I0314 12:47:08.724608 16588 solver.cpp:337] Iteration 23500, Testing net (#0)
I0314 12:47:08.724608 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:47:13.505154 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6715
I0314 12:47:13.505655 16588 solver.cpp:404]     Test net output #1: loss = 1.10343 (* 1 = 1.10343 loss)
I0314 12:47:13.541144 16588 solver.cpp:228] Iteration 23500, loss = 0.265204
I0314 12:47:13.541144 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0314 12:47:13.541144 16588 solver.cpp:244]     Train net output #1: loss = 0.265204 (* 1 = 0.265204 loss)
I0314 12:47:13.541144 16588 sgd_solver.cpp:106] Iteration 23500, lr = 0.1
I0314 12:47:27.158826 16588 solver.cpp:228] Iteration 23600, loss = 0.452796
I0314 12:47:27.158826 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:47:27.159325 16588 solver.cpp:244]     Train net output #1: loss = 0.452796 (* 1 = 0.452796 loss)
I0314 12:47:27.159325 16588 sgd_solver.cpp:106] Iteration 23600, lr = 0.1
I0314 12:47:41.181735 16588 solver.cpp:228] Iteration 23700, loss = 0.484761
I0314 12:47:41.181735 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:47:41.182235 16588 solver.cpp:244]     Train net output #1: loss = 0.484761 (* 1 = 0.484761 loss)
I0314 12:47:41.182235 16588 sgd_solver.cpp:106] Iteration 23700, lr = 0.1
I0314 12:47:55.210269 16588 solver.cpp:228] Iteration 23800, loss = 0.499914
I0314 12:47:55.210769 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:47:55.210769 16588 solver.cpp:244]     Train net output #1: loss = 0.499914 (* 1 = 0.499914 loss)
I0314 12:47:55.210769 16588 sgd_solver.cpp:106] Iteration 23800, lr = 0.1
I0314 12:48:09.590306 16588 solver.cpp:228] Iteration 23900, loss = 0.338091
I0314 12:48:09.590306 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:48:09.590306 16588 solver.cpp:244]     Train net output #1: loss = 0.338091 (* 1 = 0.338091 loss)
I0314 12:48:09.590306 16588 sgd_solver.cpp:106] Iteration 23900, lr = 0.1
I0314 12:48:24.054960 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_24000.caffemodel
I0314 12:48:24.076463 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_24000.solverstate
I0314 12:48:24.085460 16588 solver.cpp:337] Iteration 24000, Testing net (#0)
I0314 12:48:24.085460 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:48:29.120959 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7183
I0314 12:48:29.121476 16588 solver.cpp:404]     Test net output #1: loss = 0.900165 (* 1 = 0.900165 loss)
I0314 12:48:29.186462 16588 solver.cpp:228] Iteration 24000, loss = 0.401018
I0314 12:48:29.186462 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:48:29.186462 16588 solver.cpp:244]     Train net output #1: loss = 0.401018 (* 1 = 0.401018 loss)
I0314 12:48:29.186462 16588 sgd_solver.cpp:106] Iteration 24000, lr = 0.1
I0314 12:48:43.255038 16588 solver.cpp:228] Iteration 24100, loss = 0.428993
I0314 12:48:43.255038 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:48:43.255038 16588 solver.cpp:244]     Train net output #1: loss = 0.428993 (* 1 = 0.428993 loss)
I0314 12:48:43.255038 16588 sgd_solver.cpp:106] Iteration 24100, lr = 0.1
I0314 12:48:57.683722 16588 solver.cpp:228] Iteration 24200, loss = 0.387806
I0314 12:48:57.683722 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 12:48:57.683722 16588 solver.cpp:244]     Train net output #1: loss = 0.387806 (* 1 = 0.387806 loss)
I0314 12:48:57.683722 16588 sgd_solver.cpp:106] Iteration 24200, lr = 0.1
I0314 12:49:12.201277 16588 solver.cpp:228] Iteration 24300, loss = 0.30119
I0314 12:49:12.201776 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:49:12.201776 16588 solver.cpp:244]     Train net output #1: loss = 0.301189 (* 1 = 0.301189 loss)
I0314 12:49:12.201776 16588 sgd_solver.cpp:106] Iteration 24300, lr = 0.1
I0314 12:49:26.485139 16588 solver.cpp:228] Iteration 24400, loss = 0.341993
I0314 12:49:26.485139 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:49:26.485139 16588 solver.cpp:244]     Train net output #1: loss = 0.341993 (* 1 = 0.341993 loss)
I0314 12:49:26.485139 16588 sgd_solver.cpp:106] Iteration 24400, lr = 0.1
I0314 12:49:40.467981 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_24500.caffemodel
I0314 12:49:40.485965 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_24500.solverstate
I0314 12:49:40.492971 16588 solver.cpp:337] Iteration 24500, Testing net (#0)
I0314 12:49:40.492971 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:49:45.230464 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7829
I0314 12:49:45.230464 16588 solver.cpp:404]     Test net output #1: loss = 0.639379 (* 1 = 0.639379 loss)
I0314 12:49:45.268463 16588 solver.cpp:228] Iteration 24500, loss = 0.400455
I0314 12:49:45.268963 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:49:45.268963 16588 solver.cpp:244]     Train net output #1: loss = 0.400455 (* 1 = 0.400455 loss)
I0314 12:49:45.268963 16588 sgd_solver.cpp:106] Iteration 24500, lr = 0.1
I0314 12:49:58.716866 16588 solver.cpp:228] Iteration 24600, loss = 0.421358
I0314 12:49:58.716866 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:49:58.716866 16588 solver.cpp:244]     Train net output #1: loss = 0.421358 (* 1 = 0.421358 loss)
I0314 12:49:58.716866 16588 sgd_solver.cpp:106] Iteration 24600, lr = 0.1
I0314 12:50:12.850060 16588 solver.cpp:228] Iteration 24700, loss = 0.466367
I0314 12:50:12.850551 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:50:12.850551 16588 solver.cpp:244]     Train net output #1: loss = 0.466367 (* 1 = 0.466367 loss)
I0314 12:50:12.850551 16588 sgd_solver.cpp:106] Iteration 24700, lr = 0.1
I0314 12:50:26.976307 16588 solver.cpp:228] Iteration 24800, loss = 0.458072
I0314 12:50:26.976307 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:50:26.976307 16588 solver.cpp:244]     Train net output #1: loss = 0.458072 (* 1 = 0.458072 loss)
I0314 12:50:26.976307 16588 sgd_solver.cpp:106] Iteration 24800, lr = 0.1
I0314 12:50:40.902251 16588 solver.cpp:228] Iteration 24900, loss = 0.346051
I0314 12:50:40.902251 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:50:40.902251 16588 solver.cpp:244]     Train net output #1: loss = 0.346051 (* 1 = 0.346051 loss)
I0314 12:50:40.902251 16588 sgd_solver.cpp:106] Iteration 24900, lr = 0.1
I0314 12:50:55.153177 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_25000.caffemodel
I0314 12:50:55.191676 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_25000.solverstate
I0314 12:50:55.198176 16588 solver.cpp:337] Iteration 25000, Testing net (#0)
I0314 12:50:55.198678 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:50:59.994630 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7974
I0314 12:50:59.994630 16588 solver.cpp:404]     Test net output #1: loss = 0.607633 (* 1 = 0.607633 loss)
I0314 12:51:00.030638 16588 solver.cpp:228] Iteration 25000, loss = 0.44415
I0314 12:51:00.030638 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:51:00.030638 16588 solver.cpp:244]     Train net output #1: loss = 0.44415 (* 1 = 0.44415 loss)
I0314 12:51:00.030638 16588 sgd_solver.cpp:106] Iteration 25000, lr = 0.1
I0314 12:51:14.210188 16588 solver.cpp:228] Iteration 25100, loss = 0.472984
I0314 12:51:14.210188 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:51:14.210688 16588 solver.cpp:244]     Train net output #1: loss = 0.472984 (* 1 = 0.472984 loss)
I0314 12:51:14.210688 16588 sgd_solver.cpp:106] Iteration 25100, lr = 0.1
I0314 12:51:28.752487 16588 solver.cpp:228] Iteration 25200, loss = 0.60864
I0314 12:51:28.752487 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 12:51:28.752487 16588 solver.cpp:244]     Train net output #1: loss = 0.60864 (* 1 = 0.60864 loss)
I0314 12:51:28.752487 16588 sgd_solver.cpp:106] Iteration 25200, lr = 0.1
I0314 12:51:43.427289 16588 solver.cpp:228] Iteration 25300, loss = 0.356512
I0314 12:51:43.427289 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:51:43.427289 16588 solver.cpp:244]     Train net output #1: loss = 0.356512 (* 1 = 0.356512 loss)
I0314 12:51:43.427289 16588 sgd_solver.cpp:106] Iteration 25300, lr = 0.1
I0314 12:51:58.074887 16588 solver.cpp:228] Iteration 25400, loss = 0.315964
I0314 12:51:58.074887 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:51:58.074887 16588 solver.cpp:244]     Train net output #1: loss = 0.315964 (* 1 = 0.315964 loss)
I0314 12:51:58.074887 16588 sgd_solver.cpp:106] Iteration 25400, lr = 0.1
I0314 12:52:12.771190 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_25500.caffemodel
I0314 12:52:12.808691 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_25500.solverstate
I0314 12:52:12.814190 16588 solver.cpp:337] Iteration 25500, Testing net (#0)
I0314 12:52:12.814190 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:52:17.684129 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7506
I0314 12:52:17.684129 16588 solver.cpp:404]     Test net output #1: loss = 0.757874 (* 1 = 0.757874 loss)
I0314 12:52:17.736621 16588 solver.cpp:228] Iteration 25500, loss = 0.385674
I0314 12:52:17.736621 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 12:52:17.736621 16588 solver.cpp:244]     Train net output #1: loss = 0.385674 (* 1 = 0.385674 loss)
I0314 12:52:17.736621 16588 sgd_solver.cpp:106] Iteration 25500, lr = 0.1
I0314 12:52:32.331923 16588 solver.cpp:228] Iteration 25600, loss = 0.356132
I0314 12:52:32.331923 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:52:32.331923 16588 solver.cpp:244]     Train net output #1: loss = 0.356132 (* 1 = 0.356132 loss)
I0314 12:52:32.331923 16588 sgd_solver.cpp:106] Iteration 25600, lr = 0.1
I0314 12:52:47.441978 16588 solver.cpp:228] Iteration 25700, loss = 0.422222
I0314 12:52:47.441978 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:52:47.441978 16588 solver.cpp:244]     Train net output #1: loss = 0.422222 (* 1 = 0.422222 loss)
I0314 12:52:47.441978 16588 sgd_solver.cpp:106] Iteration 25700, lr = 0.1
I0314 12:53:02.485043 16588 solver.cpp:228] Iteration 25800, loss = 0.501288
I0314 12:53:02.485043 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 12:53:02.485043 16588 solver.cpp:244]     Train net output #1: loss = 0.501288 (* 1 = 0.501288 loss)
I0314 12:53:02.485043 16588 sgd_solver.cpp:106] Iteration 25800, lr = 0.1
I0314 12:53:17.459229 16588 solver.cpp:228] Iteration 25900, loss = 0.284423
I0314 12:53:17.459229 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0314 12:53:17.459229 16588 solver.cpp:244]     Train net output #1: loss = 0.284423 (* 1 = 0.284423 loss)
I0314 12:53:17.459229 16588 sgd_solver.cpp:106] Iteration 25900, lr = 0.1
I0314 12:53:32.028059 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_26000.caffemodel
I0314 12:53:32.067559 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_26000.solverstate
I0314 12:53:32.074059 16588 solver.cpp:337] Iteration 26000, Testing net (#0)
I0314 12:53:32.074059 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:53:37.092227 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7529
I0314 12:53:37.092227 16588 solver.cpp:404]     Test net output #1: loss = 0.783918 (* 1 = 0.783918 loss)
I0314 12:53:37.168227 16588 solver.cpp:228] Iteration 26000, loss = 0.314366
I0314 12:53:37.168227 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:53:37.168227 16588 solver.cpp:244]     Train net output #1: loss = 0.314366 (* 1 = 0.314366 loss)
I0314 12:53:37.168227 16588 sgd_solver.cpp:106] Iteration 26000, lr = 0.1
I0314 12:53:51.327375 16588 solver.cpp:228] Iteration 26100, loss = 0.416469
I0314 12:53:51.327375 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:53:51.327375 16588 solver.cpp:244]     Train net output #1: loss = 0.416468 (* 1 = 0.416468 loss)
I0314 12:53:51.327875 16588 sgd_solver.cpp:106] Iteration 26100, lr = 0.1
I0314 12:54:06.182045 16588 solver.cpp:228] Iteration 26200, loss = 0.541318
I0314 12:54:06.182045 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:54:06.182045 16588 solver.cpp:244]     Train net output #1: loss = 0.541317 (* 1 = 0.541317 loss)
I0314 12:54:06.182045 16588 sgd_solver.cpp:106] Iteration 26200, lr = 0.1
I0314 12:54:20.852236 16588 solver.cpp:228] Iteration 26300, loss = 0.312125
I0314 12:54:20.852236 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:54:20.852236 16588 solver.cpp:244]     Train net output #1: loss = 0.312125 (* 1 = 0.312125 loss)
I0314 12:54:20.852236 16588 sgd_solver.cpp:106] Iteration 26300, lr = 0.1
I0314 12:54:35.488308 16588 solver.cpp:228] Iteration 26400, loss = 0.388919
I0314 12:54:35.488308 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:54:35.488308 16588 solver.cpp:244]     Train net output #1: loss = 0.388919 (* 1 = 0.388919 loss)
I0314 12:54:35.488308 16588 sgd_solver.cpp:106] Iteration 26400, lr = 0.1
I0314 12:54:50.035708 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_26500.caffemodel
I0314 12:54:50.057711 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_26500.solverstate
I0314 12:54:50.064209 16588 solver.cpp:337] Iteration 26500, Testing net (#0)
I0314 12:54:50.064209 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:54:54.959221 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7188
I0314 12:54:54.959221 16588 solver.cpp:404]     Test net output #1: loss = 0.851753 (* 1 = 0.851753 loss)
I0314 12:54:55.002708 16588 solver.cpp:228] Iteration 26500, loss = 0.358441
I0314 12:54:55.002708 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:54:55.003208 16588 solver.cpp:244]     Train net output #1: loss = 0.358441 (* 1 = 0.358441 loss)
I0314 12:54:55.003208 16588 sgd_solver.cpp:106] Iteration 26500, lr = 0.1
I0314 12:55:09.270334 16588 solver.cpp:228] Iteration 26600, loss = 0.401748
I0314 12:55:09.270334 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:55:09.270334 16588 solver.cpp:244]     Train net output #1: loss = 0.401748 (* 1 = 0.401748 loss)
I0314 12:55:09.270334 16588 sgd_solver.cpp:106] Iteration 26600, lr = 0.1
I0314 12:55:23.998544 16588 solver.cpp:228] Iteration 26700, loss = 0.494063
I0314 12:55:23.998544 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:55:23.998544 16588 solver.cpp:244]     Train net output #1: loss = 0.494063 (* 1 = 0.494063 loss)
I0314 12:55:23.998544 16588 sgd_solver.cpp:106] Iteration 26700, lr = 0.1
I0314 12:55:38.633668 16588 solver.cpp:228] Iteration 26800, loss = 0.468019
I0314 12:55:38.633668 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:55:38.633668 16588 solver.cpp:244]     Train net output #1: loss = 0.468018 (* 1 = 0.468018 loss)
I0314 12:55:38.633668 16588 sgd_solver.cpp:106] Iteration 26800, lr = 0.1
I0314 12:55:53.582207 16588 solver.cpp:228] Iteration 26900, loss = 0.294677
I0314 12:55:53.582207 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:55:53.582207 16588 solver.cpp:244]     Train net output #1: loss = 0.294677 (* 1 = 0.294677 loss)
I0314 12:55:53.582207 16588 sgd_solver.cpp:106] Iteration 26900, lr = 0.1
I0314 12:56:08.218683 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_27000.caffemodel
I0314 12:56:08.256680 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_27000.solverstate
I0314 12:56:08.263185 16588 solver.cpp:337] Iteration 27000, Testing net (#0)
I0314 12:56:08.263185 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:56:13.212241 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6509
I0314 12:56:13.212241 16588 solver.cpp:404]     Test net output #1: loss = 1.06794 (* 1 = 1.06794 loss)
I0314 12:56:13.255738 16588 solver.cpp:228] Iteration 27000, loss = 0.315954
I0314 12:56:13.255738 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0314 12:56:13.255738 16588 solver.cpp:244]     Train net output #1: loss = 0.315954 (* 1 = 0.315954 loss)
I0314 12:56:13.255738 16588 sgd_solver.cpp:106] Iteration 27000, lr = 0.1
I0314 12:56:27.546115 16588 solver.cpp:228] Iteration 27100, loss = 0.368423
I0314 12:56:27.546613 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:56:27.546613 16588 solver.cpp:244]     Train net output #1: loss = 0.368423 (* 1 = 0.368423 loss)
I0314 12:56:27.546613 16588 sgd_solver.cpp:106] Iteration 27100, lr = 0.1
I0314 12:56:42.232326 16588 solver.cpp:228] Iteration 27200, loss = 0.58146
I0314 12:56:42.232326 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 12:56:42.232326 16588 solver.cpp:244]     Train net output #1: loss = 0.58146 (* 1 = 0.58146 loss)
I0314 12:56:42.232326 16588 sgd_solver.cpp:106] Iteration 27200, lr = 0.1
I0314 12:56:56.788888 16588 solver.cpp:228] Iteration 27300, loss = 0.403965
I0314 12:56:56.788888 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:56:56.788888 16588 solver.cpp:244]     Train net output #1: loss = 0.403965 (* 1 = 0.403965 loss)
I0314 12:56:56.788888 16588 sgd_solver.cpp:106] Iteration 27300, lr = 0.1
I0314 12:57:11.682111 16588 solver.cpp:228] Iteration 27400, loss = 0.384335
I0314 12:57:11.682610 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 12:57:11.682610 16588 solver.cpp:244]     Train net output #1: loss = 0.384334 (* 1 = 0.384334 loss)
I0314 12:57:11.682610 16588 sgd_solver.cpp:106] Iteration 27400, lr = 0.1
I0314 12:57:26.250951 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_27500.caffemodel
I0314 12:57:26.288950 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_27500.solverstate
I0314 12:57:26.294952 16588 solver.cpp:337] Iteration 27500, Testing net (#0)
I0314 12:57:26.294952 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:57:31.376296 16588 solver.cpp:404]     Test net output #0: accuracy = 0.676
I0314 12:57:31.376296 16588 solver.cpp:404]     Test net output #1: loss = 1.00777 (* 1 = 1.00777 loss)
I0314 12:57:31.425319 16588 solver.cpp:228] Iteration 27500, loss = 0.339696
I0314 12:57:31.425319 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 12:57:31.425319 16588 solver.cpp:244]     Train net output #1: loss = 0.339696 (* 1 = 0.339696 loss)
I0314 12:57:31.425319 16588 sgd_solver.cpp:106] Iteration 27500, lr = 0.1
I0314 12:57:45.595734 16588 solver.cpp:228] Iteration 27600, loss = 0.396794
I0314 12:57:45.595734 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:57:45.595734 16588 solver.cpp:244]     Train net output #1: loss = 0.396794 (* 1 = 0.396794 loss)
I0314 12:57:45.595734 16588 sgd_solver.cpp:106] Iteration 27600, lr = 0.1
I0314 12:58:00.162955 16588 solver.cpp:228] Iteration 27700, loss = 0.516909
I0314 12:58:00.162955 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 12:58:00.162955 16588 solver.cpp:244]     Train net output #1: loss = 0.516909 (* 1 = 0.516909 loss)
I0314 12:58:00.162955 16588 sgd_solver.cpp:106] Iteration 27700, lr = 0.1
I0314 12:58:14.778559 16588 solver.cpp:228] Iteration 27800, loss = 0.463163
I0314 12:58:14.778559 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:58:14.778559 16588 solver.cpp:244]     Train net output #1: loss = 0.463162 (* 1 = 0.463162 loss)
I0314 12:58:14.778559 16588 sgd_solver.cpp:106] Iteration 27800, lr = 0.1
I0314 12:58:29.299638 16588 solver.cpp:228] Iteration 27900, loss = 0.373465
I0314 12:58:29.299638 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 12:58:29.299638 16588 solver.cpp:244]     Train net output #1: loss = 0.373465 (* 1 = 0.373465 loss)
I0314 12:58:29.299638 16588 sgd_solver.cpp:106] Iteration 27900, lr = 0.1
I0314 12:58:43.805203 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_28000.caffemodel
I0314 12:58:43.843202 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_28000.solverstate
I0314 12:58:43.849712 16588 solver.cpp:337] Iteration 28000, Testing net (#0)
I0314 12:58:43.849712 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 12:58:48.697897 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7327
I0314 12:58:48.697897 16588 solver.cpp:404]     Test net output #1: loss = 0.824103 (* 1 = 0.824103 loss)
I0314 12:58:48.767902 16588 solver.cpp:228] Iteration 28000, loss = 0.352775
I0314 12:58:48.767902 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:58:48.767902 16588 solver.cpp:244]     Train net output #1: loss = 0.352774 (* 1 = 0.352774 loss)
I0314 12:58:48.767902 16588 sgd_solver.cpp:106] Iteration 28000, lr = 0.1
I0314 12:59:02.933709 16588 solver.cpp:228] Iteration 28100, loss = 0.353543
I0314 12:59:02.934717 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 12:59:02.934717 16588 solver.cpp:244]     Train net output #1: loss = 0.353543 (* 1 = 0.353543 loss)
I0314 12:59:02.934717 16588 sgd_solver.cpp:106] Iteration 28100, lr = 0.1
I0314 12:59:17.491510 16588 solver.cpp:228] Iteration 28200, loss = 0.427296
I0314 12:59:17.491510 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 12:59:17.491510 16588 solver.cpp:244]     Train net output #1: loss = 0.427296 (* 1 = 0.427296 loss)
I0314 12:59:17.491510 16588 sgd_solver.cpp:106] Iteration 28200, lr = 0.1
I0314 12:59:32.321774 16588 solver.cpp:228] Iteration 28300, loss = 0.424144
I0314 12:59:32.321774 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 12:59:32.321774 16588 solver.cpp:244]     Train net output #1: loss = 0.424143 (* 1 = 0.424143 loss)
I0314 12:59:32.321774 16588 sgd_solver.cpp:106] Iteration 28300, lr = 0.1
I0314 12:59:46.964417 16588 solver.cpp:228] Iteration 28400, loss = 0.329881
I0314 12:59:46.964417 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 12:59:46.964417 16588 solver.cpp:244]     Train net output #1: loss = 0.329881 (* 1 = 0.329881 loss)
I0314 12:59:46.964417 16588 sgd_solver.cpp:106] Iteration 28400, lr = 0.1
I0314 13:00:01.659728 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_28500.caffemodel
I0314 13:00:01.680728 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_28500.solverstate
I0314 13:00:01.687733 16588 solver.cpp:337] Iteration 28500, Testing net (#0)
I0314 13:00:01.687733 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:00:06.736500 16588 solver.cpp:404]     Test net output #0: accuracy = 0.691
I0314 13:00:06.736500 16588 solver.cpp:404]     Test net output #1: loss = 0.941599 (* 1 = 0.941599 loss)
I0314 13:00:06.780499 16588 solver.cpp:228] Iteration 28500, loss = 0.500483
I0314 13:00:06.780499 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:00:06.780499 16588 solver.cpp:244]     Train net output #1: loss = 0.500483 (* 1 = 0.500483 loss)
I0314 13:00:06.780499 16588 sgd_solver.cpp:106] Iteration 28500, lr = 0.1
I0314 13:00:21.115847 16588 solver.cpp:228] Iteration 28600, loss = 0.35557
I0314 13:00:21.115847 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:00:21.115847 16588 solver.cpp:244]     Train net output #1: loss = 0.355569 (* 1 = 0.355569 loss)
I0314 13:00:21.115847 16588 sgd_solver.cpp:106] Iteration 28600, lr = 0.1
I0314 13:00:35.938594 16588 solver.cpp:228] Iteration 28700, loss = 0.461876
I0314 13:00:35.938594 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:00:35.938594 16588 solver.cpp:244]     Train net output #1: loss = 0.461876 (* 1 = 0.461876 loss)
I0314 13:00:35.938594 16588 sgd_solver.cpp:106] Iteration 28700, lr = 0.1
I0314 13:00:50.808814 16588 solver.cpp:228] Iteration 28800, loss = 0.432706
I0314 13:00:50.808814 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:00:50.808814 16588 solver.cpp:244]     Train net output #1: loss = 0.432706 (* 1 = 0.432706 loss)
I0314 13:00:50.808814 16588 sgd_solver.cpp:106] Iteration 28800, lr = 0.1
I0314 13:01:06.063184 16588 solver.cpp:228] Iteration 28900, loss = 0.302114
I0314 13:01:06.063184 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:01:06.063184 16588 solver.cpp:244]     Train net output #1: loss = 0.302114 (* 1 = 0.302114 loss)
I0314 13:01:06.063184 16588 sgd_solver.cpp:106] Iteration 28900, lr = 0.1
I0314 13:01:20.725827 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_29000.caffemodel
I0314 13:01:20.764328 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_29000.solverstate
I0314 13:01:20.771328 16588 solver.cpp:337] Iteration 29000, Testing net (#0)
I0314 13:01:20.771328 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:01:25.625442 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7379
I0314 13:01:25.625442 16588 solver.cpp:404]     Test net output #1: loss = 0.794965 (* 1 = 0.794965 loss)
I0314 13:01:25.690475 16588 solver.cpp:228] Iteration 29000, loss = 0.347327
I0314 13:01:25.690974 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:01:25.690974 16588 solver.cpp:244]     Train net output #1: loss = 0.347327 (* 1 = 0.347327 loss)
I0314 13:01:25.690974 16588 sgd_solver.cpp:106] Iteration 29000, lr = 0.1
I0314 13:01:39.796396 16588 solver.cpp:228] Iteration 29100, loss = 0.431941
I0314 13:01:39.796396 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 13:01:39.796396 16588 solver.cpp:244]     Train net output #1: loss = 0.431941 (* 1 = 0.431941 loss)
I0314 13:01:39.796396 16588 sgd_solver.cpp:106] Iteration 29100, lr = 0.1
I0314 13:01:54.273563 16588 solver.cpp:228] Iteration 29200, loss = 0.446058
I0314 13:01:54.274065 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:01:54.274065 16588 solver.cpp:244]     Train net output #1: loss = 0.446058 (* 1 = 0.446058 loss)
I0314 13:01:54.274065 16588 sgd_solver.cpp:106] Iteration 29200, lr = 0.1
I0314 13:02:08.917114 16588 solver.cpp:228] Iteration 29300, loss = 0.416278
I0314 13:02:08.917114 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:02:08.917114 16588 solver.cpp:244]     Train net output #1: loss = 0.416278 (* 1 = 0.416278 loss)
I0314 13:02:08.917114 16588 sgd_solver.cpp:106] Iteration 29300, lr = 0.1
I0314 13:02:23.511574 16588 solver.cpp:228] Iteration 29400, loss = 0.268992
I0314 13:02:23.511574 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:02:23.511574 16588 solver.cpp:244]     Train net output #1: loss = 0.268992 (* 1 = 0.268992 loss)
I0314 13:02:23.511574 16588 sgd_solver.cpp:106] Iteration 29400, lr = 0.1
I0314 13:02:37.961892 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_29500.caffemodel
I0314 13:02:37.999893 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_29500.solverstate
I0314 13:02:38.005895 16588 solver.cpp:337] Iteration 29500, Testing net (#0)
I0314 13:02:38.005895 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:02:42.900091 16588 solver.cpp:404]     Test net output #0: accuracy = 0.5968
I0314 13:02:42.900091 16588 solver.cpp:404]     Test net output #1: loss = 1.56391 (* 1 = 1.56391 loss)
I0314 13:02:42.952600 16588 solver.cpp:228] Iteration 29500, loss = 0.434638
I0314 13:02:42.952600 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:02:42.952600 16588 solver.cpp:244]     Train net output #1: loss = 0.434637 (* 1 = 0.434637 loss)
I0314 13:02:42.952600 16588 sgd_solver.cpp:106] Iteration 29500, lr = 0.1
I0314 13:02:57.098281 16588 solver.cpp:228] Iteration 29600, loss = 0.385184
I0314 13:02:57.098281 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:02:57.098281 16588 solver.cpp:244]     Train net output #1: loss = 0.385184 (* 1 = 0.385184 loss)
I0314 13:02:57.098281 16588 sgd_solver.cpp:106] Iteration 29600, lr = 0.1
I0314 13:03:11.591164 16588 solver.cpp:228] Iteration 29700, loss = 0.581607
I0314 13:03:11.591164 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0314 13:03:11.591164 16588 solver.cpp:244]     Train net output #1: loss = 0.581607 (* 1 = 0.581607 loss)
I0314 13:03:11.591164 16588 sgd_solver.cpp:106] Iteration 29700, lr = 0.1
I0314 13:03:26.158722 16588 solver.cpp:228] Iteration 29800, loss = 0.419088
I0314 13:03:26.158722 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:03:26.158722 16588 solver.cpp:244]     Train net output #1: loss = 0.419087 (* 1 = 0.419087 loss)
I0314 13:03:26.158722 16588 sgd_solver.cpp:106] Iteration 29800, lr = 0.1
I0314 13:03:40.643497 16588 solver.cpp:228] Iteration 29900, loss = 0.441052
I0314 13:03:40.643497 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:03:40.643497 16588 solver.cpp:244]     Train net output #1: loss = 0.441052 (* 1 = 0.441052 loss)
I0314 13:03:40.643497 16588 sgd_solver.cpp:106] Iteration 29900, lr = 0.1
I0314 13:03:55.180099 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_30000.caffemodel
I0314 13:03:55.202101 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_30000.solverstate
I0314 13:03:55.209106 16588 solver.cpp:337] Iteration 30000, Testing net (#0)
I0314 13:03:55.209106 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:04:00.161317 16588 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0314 13:04:00.161317 16588 solver.cpp:404]     Test net output #1: loss = 0.770266 (* 1 = 0.770266 loss)
I0314 13:04:00.220324 16588 solver.cpp:228] Iteration 30000, loss = 0.392716
I0314 13:04:00.220324 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:04:00.220324 16588 solver.cpp:244]     Train net output #1: loss = 0.392716 (* 1 = 0.392716 loss)
I0314 13:04:00.220324 16588 sgd_solver.cpp:106] Iteration 30000, lr = 0.1
I0314 13:04:14.255522 16588 solver.cpp:228] Iteration 30100, loss = 0.500314
I0314 13:04:14.255522 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:04:14.255522 16588 solver.cpp:244]     Train net output #1: loss = 0.500314 (* 1 = 0.500314 loss)
I0314 13:04:14.255522 16588 sgd_solver.cpp:106] Iteration 30100, lr = 0.1
I0314 13:04:29.220155 16588 solver.cpp:228] Iteration 30200, loss = 0.46451
I0314 13:04:29.220155 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:04:29.220155 16588 solver.cpp:244]     Train net output #1: loss = 0.46451 (* 1 = 0.46451 loss)
I0314 13:04:29.220155 16588 sgd_solver.cpp:106] Iteration 30200, lr = 0.1
I0314 13:04:44.026149 16588 solver.cpp:228] Iteration 30300, loss = 0.412024
I0314 13:04:44.026149 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:04:44.026149 16588 solver.cpp:244]     Train net output #1: loss = 0.412024 (* 1 = 0.412024 loss)
I0314 13:04:44.026149 16588 sgd_solver.cpp:106] Iteration 30300, lr = 0.1
I0314 13:04:58.715375 16588 solver.cpp:228] Iteration 30400, loss = 0.284455
I0314 13:04:58.715375 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:04:58.715375 16588 solver.cpp:244]     Train net output #1: loss = 0.284455 (* 1 = 0.284455 loss)
I0314 13:04:58.715375 16588 sgd_solver.cpp:106] Iteration 30400, lr = 0.1
I0314 13:05:13.299240 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_30500.caffemodel
I0314 13:05:13.338245 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_30500.solverstate
I0314 13:05:13.344245 16588 solver.cpp:337] Iteration 30500, Testing net (#0)
I0314 13:05:13.344245 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:05:18.144723 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7382
I0314 13:05:18.144723 16588 solver.cpp:404]     Test net output #1: loss = 0.81188 (* 1 = 0.81188 loss)
I0314 13:05:18.180407 16588 solver.cpp:228] Iteration 30500, loss = 0.376595
I0314 13:05:18.180407 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:05:18.180407 16588 solver.cpp:244]     Train net output #1: loss = 0.376595 (* 1 = 0.376595 loss)
I0314 13:05:18.180407 16588 sgd_solver.cpp:106] Iteration 30500, lr = 0.1
I0314 13:05:32.352159 16588 solver.cpp:228] Iteration 30600, loss = 0.447672
I0314 13:05:32.352659 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:05:32.352659 16588 solver.cpp:244]     Train net output #1: loss = 0.447672 (* 1 = 0.447672 loss)
I0314 13:05:32.352659 16588 sgd_solver.cpp:106] Iteration 30600, lr = 0.1
I0314 13:05:46.900347 16588 solver.cpp:228] Iteration 30700, loss = 0.420257
I0314 13:05:46.900347 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:05:46.900347 16588 solver.cpp:244]     Train net output #1: loss = 0.420257 (* 1 = 0.420257 loss)
I0314 13:05:46.900347 16588 sgd_solver.cpp:106] Iteration 30700, lr = 0.1
I0314 13:06:01.546706 16588 solver.cpp:228] Iteration 30800, loss = 0.399951
I0314 13:06:01.546706 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:06:01.546706 16588 solver.cpp:244]     Train net output #1: loss = 0.399951 (* 1 = 0.399951 loss)
I0314 13:06:01.546706 16588 sgd_solver.cpp:106] Iteration 30800, lr = 0.1
I0314 13:06:16.252362 16588 solver.cpp:228] Iteration 30900, loss = 0.367574
I0314 13:06:16.252362 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:06:16.252362 16588 solver.cpp:244]     Train net output #1: loss = 0.367573 (* 1 = 0.367573 loss)
I0314 13:06:16.252362 16588 sgd_solver.cpp:106] Iteration 30900, lr = 0.1
I0314 13:06:31.061660 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_31000.caffemodel
I0314 13:06:31.103163 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_31000.solverstate
I0314 13:06:31.115660 16588 solver.cpp:337] Iteration 31000, Testing net (#0)
I0314 13:06:31.115660 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:06:36.070374 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6993
I0314 13:06:36.070374 16588 solver.cpp:404]     Test net output #1: loss = 0.967878 (* 1 = 0.967878 loss)
I0314 13:06:36.114471 16588 solver.cpp:228] Iteration 31000, loss = 0.309636
I0314 13:06:36.114471 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0314 13:06:36.114471 16588 solver.cpp:244]     Train net output #1: loss = 0.309636 (* 1 = 0.309636 loss)
I0314 13:06:36.114471 16588 sgd_solver.cpp:106] Iteration 31000, lr = 0.1
I0314 13:06:50.491816 16588 solver.cpp:228] Iteration 31100, loss = 0.537719
I0314 13:06:50.491816 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:06:50.491816 16588 solver.cpp:244]     Train net output #1: loss = 0.537719 (* 1 = 0.537719 loss)
I0314 13:06:50.491816 16588 sgd_solver.cpp:106] Iteration 31100, lr = 0.1
I0314 13:07:05.080615 16588 solver.cpp:228] Iteration 31200, loss = 0.511068
I0314 13:07:05.080615 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:07:05.080615 16588 solver.cpp:244]     Train net output #1: loss = 0.511068 (* 1 = 0.511068 loss)
I0314 13:07:05.080615 16588 sgd_solver.cpp:106] Iteration 31200, lr = 0.1
I0314 13:07:19.772639 16588 solver.cpp:228] Iteration 31300, loss = 0.398282
I0314 13:07:19.773638 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:07:19.773638 16588 solver.cpp:244]     Train net output #1: loss = 0.398282 (* 1 = 0.398282 loss)
I0314 13:07:19.773638 16588 sgd_solver.cpp:106] Iteration 31300, lr = 0.1
I0314 13:07:34.403007 16588 solver.cpp:228] Iteration 31400, loss = 0.319583
I0314 13:07:34.403007 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:07:34.403007 16588 solver.cpp:244]     Train net output #1: loss = 0.319583 (* 1 = 0.319583 loss)
I0314 13:07:34.403007 16588 sgd_solver.cpp:106] Iteration 31400, lr = 0.1
I0314 13:07:49.030071 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_31500.caffemodel
I0314 13:07:49.068069 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_31500.solverstate
I0314 13:07:49.075069 16588 solver.cpp:337] Iteration 31500, Testing net (#0)
I0314 13:07:49.075069 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:07:53.934898 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7347
I0314 13:07:53.934898 16588 solver.cpp:404]     Test net output #1: loss = 0.819779 (* 1 = 0.819779 loss)
I0314 13:07:53.990906 16588 solver.cpp:228] Iteration 31500, loss = 0.378519
I0314 13:07:53.990906 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:07:53.990906 16588 solver.cpp:244]     Train net output #1: loss = 0.378519 (* 1 = 0.378519 loss)
I0314 13:07:53.990906 16588 sgd_solver.cpp:106] Iteration 31500, lr = 0.1
I0314 13:08:08.130247 16588 solver.cpp:228] Iteration 31600, loss = 0.312277
I0314 13:08:08.130247 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:08:08.130247 16588 solver.cpp:244]     Train net output #1: loss = 0.312277 (* 1 = 0.312277 loss)
I0314 13:08:08.130247 16588 sgd_solver.cpp:106] Iteration 31600, lr = 0.1
I0314 13:08:22.748296 16588 solver.cpp:228] Iteration 31700, loss = 0.523237
I0314 13:08:22.748296 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:08:22.748296 16588 solver.cpp:244]     Train net output #1: loss = 0.523237 (* 1 = 0.523237 loss)
I0314 13:08:22.748296 16588 sgd_solver.cpp:106] Iteration 31700, lr = 0.1
I0314 13:08:37.310245 16588 solver.cpp:228] Iteration 31800, loss = 0.478928
I0314 13:08:37.310245 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:08:37.310245 16588 solver.cpp:244]     Train net output #1: loss = 0.478928 (* 1 = 0.478928 loss)
I0314 13:08:37.310245 16588 sgd_solver.cpp:106] Iteration 31800, lr = 0.1
I0314 13:08:51.814267 16588 solver.cpp:228] Iteration 31900, loss = 0.347995
I0314 13:08:51.814267 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:08:51.814267 16588 solver.cpp:244]     Train net output #1: loss = 0.347995 (* 1 = 0.347995 loss)
I0314 13:08:51.814267 16588 sgd_solver.cpp:106] Iteration 31900, lr = 0.1
I0314 13:09:06.303572 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_32000.caffemodel
I0314 13:09:06.343572 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_32000.solverstate
I0314 13:09:06.349572 16588 solver.cpp:337] Iteration 32000, Testing net (#0)
I0314 13:09:06.350072 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:09:11.198189 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7725
I0314 13:09:11.198189 16588 solver.cpp:404]     Test net output #1: loss = 0.682214 (* 1 = 0.682214 loss)
I0314 13:09:11.234181 16588 solver.cpp:228] Iteration 32000, loss = 0.347527
I0314 13:09:11.234181 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0314 13:09:11.234181 16588 solver.cpp:244]     Train net output #1: loss = 0.347527 (* 1 = 0.347527 loss)
I0314 13:09:11.234181 16588 sgd_solver.cpp:106] Iteration 32000, lr = 0.1
I0314 13:09:25.433527 16588 solver.cpp:228] Iteration 32100, loss = 0.353782
I0314 13:09:25.433527 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:09:25.433527 16588 solver.cpp:244]     Train net output #1: loss = 0.353782 (* 1 = 0.353782 loss)
I0314 13:09:25.433527 16588 sgd_solver.cpp:106] Iteration 32100, lr = 0.1
I0314 13:09:40.108759 16588 solver.cpp:228] Iteration 32200, loss = 0.498966
I0314 13:09:40.108759 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:09:40.108759 16588 solver.cpp:244]     Train net output #1: loss = 0.498965 (* 1 = 0.498965 loss)
I0314 13:09:40.108759 16588 sgd_solver.cpp:106] Iteration 32200, lr = 0.1
I0314 13:09:54.609084 16588 solver.cpp:228] Iteration 32300, loss = 0.395313
I0314 13:09:54.609084 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:09:54.609084 16588 solver.cpp:244]     Train net output #1: loss = 0.395313 (* 1 = 0.395313 loss)
I0314 13:09:54.609084 16588 sgd_solver.cpp:106] Iteration 32300, lr = 0.1
I0314 13:10:09.367069 16588 solver.cpp:228] Iteration 32400, loss = 0.378068
I0314 13:10:09.367069 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:10:09.367069 16588 solver.cpp:244]     Train net output #1: loss = 0.378067 (* 1 = 0.378067 loss)
I0314 13:10:09.367069 16588 sgd_solver.cpp:106] Iteration 32400, lr = 0.1
I0314 13:10:23.887840 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_32500.caffemodel
I0314 13:10:23.927841 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_32500.solverstate
I0314 13:10:23.937845 16588 solver.cpp:337] Iteration 32500, Testing net (#0)
I0314 13:10:23.937845 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:10:28.967866 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7911
I0314 13:10:28.967866 16588 solver.cpp:404]     Test net output #1: loss = 0.618845 (* 1 = 0.618845 loss)
I0314 13:10:29.008477 16588 solver.cpp:228] Iteration 32500, loss = 0.297661
I0314 13:10:29.008477 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:10:29.008477 16588 solver.cpp:244]     Train net output #1: loss = 0.29766 (* 1 = 0.29766 loss)
I0314 13:10:29.008477 16588 sgd_solver.cpp:106] Iteration 32500, lr = 0.1
I0314 13:10:43.240768 16588 solver.cpp:228] Iteration 32600, loss = 0.392203
I0314 13:10:43.240768 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:10:43.240768 16588 solver.cpp:244]     Train net output #1: loss = 0.392203 (* 1 = 0.392203 loss)
I0314 13:10:43.240768 16588 sgd_solver.cpp:106] Iteration 32600, lr = 0.1
I0314 13:10:57.851342 16588 solver.cpp:228] Iteration 32700, loss = 0.56167
I0314 13:10:57.851342 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:10:57.851342 16588 solver.cpp:244]     Train net output #1: loss = 0.561669 (* 1 = 0.561669 loss)
I0314 13:10:57.851342 16588 sgd_solver.cpp:106] Iteration 32700, lr = 0.1
I0314 13:11:12.634148 16588 solver.cpp:228] Iteration 32800, loss = 0.472749
I0314 13:11:12.634148 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:11:12.635149 16588 solver.cpp:244]     Train net output #1: loss = 0.472749 (* 1 = 0.472749 loss)
I0314 13:11:12.635149 16588 sgd_solver.cpp:106] Iteration 32800, lr = 0.1
I0314 13:11:27.238540 16588 solver.cpp:228] Iteration 32900, loss = 0.37172
I0314 13:11:27.238540 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:11:27.238540 16588 solver.cpp:244]     Train net output #1: loss = 0.371719 (* 1 = 0.371719 loss)
I0314 13:11:27.238540 16588 sgd_solver.cpp:106] Iteration 32900, lr = 0.1
I0314 13:11:41.697592 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_33000.caffemodel
I0314 13:11:41.735589 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_33000.solverstate
I0314 13:11:41.742588 16588 solver.cpp:337] Iteration 33000, Testing net (#0)
I0314 13:11:41.742588 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:11:46.528434 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7487
I0314 13:11:46.528434 16588 solver.cpp:404]     Test net output #1: loss = 0.755602 (* 1 = 0.755602 loss)
I0314 13:11:46.577436 16588 solver.cpp:228] Iteration 33000, loss = 0.392762
I0314 13:11:46.577436 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:11:46.577436 16588 solver.cpp:244]     Train net output #1: loss = 0.392762 (* 1 = 0.392762 loss)
I0314 13:11:46.577436 16588 sgd_solver.cpp:106] Iteration 33000, lr = 0.1
I0314 13:12:01.032872 16588 solver.cpp:228] Iteration 33100, loss = 0.500631
I0314 13:12:01.032872 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 13:12:01.032872 16588 solver.cpp:244]     Train net output #1: loss = 0.500631 (* 1 = 0.500631 loss)
I0314 13:12:01.032872 16588 sgd_solver.cpp:106] Iteration 33100, lr = 0.1
I0314 13:12:15.925541 16588 solver.cpp:228] Iteration 33200, loss = 0.549627
I0314 13:12:15.925541 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:12:15.925541 16588 solver.cpp:244]     Train net output #1: loss = 0.549627 (* 1 = 0.549627 loss)
I0314 13:12:15.925541 16588 sgd_solver.cpp:106] Iteration 33200, lr = 0.1
I0314 13:12:30.597738 16588 solver.cpp:228] Iteration 33300, loss = 0.459356
I0314 13:12:30.597738 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:12:30.597738 16588 solver.cpp:244]     Train net output #1: loss = 0.459356 (* 1 = 0.459356 loss)
I0314 13:12:30.597738 16588 sgd_solver.cpp:106] Iteration 33300, lr = 0.1
I0314 13:12:45.167448 16588 solver.cpp:228] Iteration 33400, loss = 0.455592
I0314 13:12:45.167448 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:12:45.167448 16588 solver.cpp:244]     Train net output #1: loss = 0.455592 (* 1 = 0.455592 loss)
I0314 13:12:45.167448 16588 sgd_solver.cpp:106] Iteration 33400, lr = 0.1
I0314 13:12:59.620123 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_33500.caffemodel
I0314 13:12:59.638624 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_33500.solverstate
I0314 13:12:59.646129 16588 solver.cpp:337] Iteration 33500, Testing net (#0)
I0314 13:12:59.646129 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:13:04.528318 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7176
I0314 13:13:04.528318 16588 solver.cpp:404]     Test net output #1: loss = 0.885435 (* 1 = 0.885435 loss)
I0314 13:13:04.568315 16588 solver.cpp:228] Iteration 33500, loss = 0.346762
I0314 13:13:04.568315 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:13:04.568315 16588 solver.cpp:244]     Train net output #1: loss = 0.346762 (* 1 = 0.346762 loss)
I0314 13:13:04.568315 16588 sgd_solver.cpp:106] Iteration 33500, lr = 0.1
I0314 13:13:18.638330 16588 solver.cpp:228] Iteration 33600, loss = 0.578981
I0314 13:13:18.638330 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:13:18.638330 16588 solver.cpp:244]     Train net output #1: loss = 0.578981 (* 1 = 0.578981 loss)
I0314 13:13:18.638330 16588 sgd_solver.cpp:106] Iteration 33600, lr = 0.1
I0314 13:13:33.176347 16588 solver.cpp:228] Iteration 33700, loss = 0.453961
I0314 13:13:33.176347 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:13:33.176347 16588 solver.cpp:244]     Train net output #1: loss = 0.453961 (* 1 = 0.453961 loss)
I0314 13:13:33.176347 16588 sgd_solver.cpp:106] Iteration 33700, lr = 0.1
I0314 13:13:47.706071 16588 solver.cpp:228] Iteration 33800, loss = 0.416873
I0314 13:13:47.706071 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:13:47.706071 16588 solver.cpp:244]     Train net output #1: loss = 0.416873 (* 1 = 0.416873 loss)
I0314 13:13:47.706071 16588 sgd_solver.cpp:106] Iteration 33800, lr = 0.1
I0314 13:14:02.303328 16588 solver.cpp:228] Iteration 33900, loss = 0.414686
I0314 13:14:02.303328 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:14:02.303328 16588 solver.cpp:244]     Train net output #1: loss = 0.414685 (* 1 = 0.414685 loss)
I0314 13:14:02.303328 16588 sgd_solver.cpp:106] Iteration 33900, lr = 0.1
I0314 13:14:16.768016 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_34000.caffemodel
I0314 13:14:16.803019 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_34000.solverstate
I0314 13:14:16.809520 16588 solver.cpp:337] Iteration 34000, Testing net (#0)
I0314 13:14:16.809520 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:14:21.533803 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7651
I0314 13:14:21.533803 16588 solver.cpp:404]     Test net output #1: loss = 0.70888 (* 1 = 0.70888 loss)
I0314 13:14:21.584316 16588 solver.cpp:228] Iteration 34000, loss = 0.351722
I0314 13:14:21.584316 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:14:21.584316 16588 solver.cpp:244]     Train net output #1: loss = 0.351722 (* 1 = 0.351722 loss)
I0314 13:14:21.584316 16588 sgd_solver.cpp:106] Iteration 34000, lr = 0.1
I0314 13:14:35.838366 16588 solver.cpp:228] Iteration 34100, loss = 0.423075
I0314 13:14:35.838366 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:14:35.838366 16588 solver.cpp:244]     Train net output #1: loss = 0.423075 (* 1 = 0.423075 loss)
I0314 13:14:35.838366 16588 sgd_solver.cpp:106] Iteration 34100, lr = 0.1
I0314 13:14:50.329838 16588 solver.cpp:228] Iteration 34200, loss = 0.46703
I0314 13:14:50.329838 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:14:50.329838 16588 solver.cpp:244]     Train net output #1: loss = 0.46703 (* 1 = 0.46703 loss)
I0314 13:14:50.329838 16588 sgd_solver.cpp:106] Iteration 34200, lr = 0.1
I0314 13:15:04.797446 16588 solver.cpp:228] Iteration 34300, loss = 0.40523
I0314 13:15:04.797446 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:15:04.797446 16588 solver.cpp:244]     Train net output #1: loss = 0.40523 (* 1 = 0.40523 loss)
I0314 13:15:04.797446 16588 sgd_solver.cpp:106] Iteration 34300, lr = 0.1
I0314 13:15:19.171195 16588 solver.cpp:228] Iteration 34400, loss = 0.494973
I0314 13:15:19.171195 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 13:15:19.171195 16588 solver.cpp:244]     Train net output #1: loss = 0.494973 (* 1 = 0.494973 loss)
I0314 13:15:19.171195 16588 sgd_solver.cpp:106] Iteration 34400, lr = 0.1
I0314 13:15:33.590212 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_34500.caffemodel
I0314 13:15:33.620216 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_34500.solverstate
I0314 13:15:33.636240 16588 solver.cpp:337] Iteration 34500, Testing net (#0)
I0314 13:15:33.636240 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:15:38.521821 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7183
I0314 13:15:38.521821 16588 solver.cpp:404]     Test net output #1: loss = 0.836016 (* 1 = 0.836016 loss)
I0314 13:15:38.561822 16588 solver.cpp:228] Iteration 34500, loss = 0.406354
I0314 13:15:38.561822 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:15:38.561822 16588 solver.cpp:244]     Train net output #1: loss = 0.406354 (* 1 = 0.406354 loss)
I0314 13:15:38.561822 16588 sgd_solver.cpp:106] Iteration 34500, lr = 0.1
I0314 13:15:52.705297 16588 solver.cpp:228] Iteration 34600, loss = 0.497939
I0314 13:15:52.705297 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:15:52.705297 16588 solver.cpp:244]     Train net output #1: loss = 0.497939 (* 1 = 0.497939 loss)
I0314 13:15:52.705297 16588 sgd_solver.cpp:106] Iteration 34600, lr = 0.1
I0314 13:16:07.285706 16588 solver.cpp:228] Iteration 34700, loss = 0.413065
I0314 13:16:07.285706 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:16:07.285706 16588 solver.cpp:244]     Train net output #1: loss = 0.413065 (* 1 = 0.413065 loss)
I0314 13:16:07.285706 16588 sgd_solver.cpp:106] Iteration 34700, lr = 0.1
I0314 13:16:21.720726 16588 solver.cpp:228] Iteration 34800, loss = 0.319013
I0314 13:16:21.720726 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0314 13:16:21.720726 16588 solver.cpp:244]     Train net output #1: loss = 0.319012 (* 1 = 0.319012 loss)
I0314 13:16:21.720726 16588 sgd_solver.cpp:106] Iteration 34800, lr = 0.1
I0314 13:16:36.255468 16588 solver.cpp:228] Iteration 34900, loss = 0.399164
I0314 13:16:36.255468 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:16:36.255468 16588 solver.cpp:244]     Train net output #1: loss = 0.399164 (* 1 = 0.399164 loss)
I0314 13:16:36.255468 16588 sgd_solver.cpp:106] Iteration 34900, lr = 0.1
I0314 13:16:50.721392 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_35000.caffemodel
I0314 13:16:50.759392 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_35000.solverstate
I0314 13:16:50.765892 16588 solver.cpp:337] Iteration 35000, Testing net (#0)
I0314 13:16:50.765892 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:16:55.571137 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7296
I0314 13:16:55.571137 16588 solver.cpp:404]     Test net output #1: loss = 0.852012 (* 1 = 0.852012 loss)
I0314 13:16:55.631165 16588 solver.cpp:228] Iteration 35000, loss = 0.393153
I0314 13:16:55.631165 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:16:55.631165 16588 solver.cpp:244]     Train net output #1: loss = 0.393153 (* 1 = 0.393153 loss)
I0314 13:16:55.631165 16588 sgd_solver.cpp:106] Iteration 35000, lr = 0.1
I0314 13:17:09.743253 16588 solver.cpp:228] Iteration 35100, loss = 0.416719
I0314 13:17:09.743253 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:17:09.743253 16588 solver.cpp:244]     Train net output #1: loss = 0.416719 (* 1 = 0.416719 loss)
I0314 13:17:09.743253 16588 sgd_solver.cpp:106] Iteration 35100, lr = 0.1
I0314 13:17:24.287190 16588 solver.cpp:228] Iteration 35200, loss = 0.485945
I0314 13:17:24.287190 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:17:24.287190 16588 solver.cpp:244]     Train net output #1: loss = 0.485945 (* 1 = 0.485945 loss)
I0314 13:17:24.287190 16588 sgd_solver.cpp:106] Iteration 35200, lr = 0.1
I0314 13:17:38.812124 16588 solver.cpp:228] Iteration 35300, loss = 0.435367
I0314 13:17:38.812124 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:17:38.812124 16588 solver.cpp:244]     Train net output #1: loss = 0.435367 (* 1 = 0.435367 loss)
I0314 13:17:38.812124 16588 sgd_solver.cpp:106] Iteration 35300, lr = 0.1
I0314 13:17:53.303751 16588 solver.cpp:228] Iteration 35400, loss = 0.379018
I0314 13:17:53.303751 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:17:53.303751 16588 solver.cpp:244]     Train net output #1: loss = 0.379018 (* 1 = 0.379018 loss)
I0314 13:17:53.303751 16588 sgd_solver.cpp:106] Iteration 35400, lr = 0.1
I0314 13:18:07.819934 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_35500.caffemodel
I0314 13:18:07.856932 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_35500.solverstate
I0314 13:18:07.864434 16588 solver.cpp:337] Iteration 35500, Testing net (#0)
I0314 13:18:07.864434 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:18:12.704771 16588 solver.cpp:404]     Test net output #0: accuracy = 0.63
I0314 13:18:12.704771 16588 solver.cpp:404]     Test net output #1: loss = 1.11054 (* 1 = 1.11054 loss)
I0314 13:18:12.777245 16588 solver.cpp:228] Iteration 35500, loss = 0.387007
I0314 13:18:12.777245 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:18:12.777245 16588 solver.cpp:244]     Train net output #1: loss = 0.387007 (* 1 = 0.387007 loss)
I0314 13:18:12.777245 16588 sgd_solver.cpp:106] Iteration 35500, lr = 0.1
I0314 13:18:26.813822 16588 solver.cpp:228] Iteration 35600, loss = 0.476439
I0314 13:18:26.813822 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:18:26.813822 16588 solver.cpp:244]     Train net output #1: loss = 0.476438 (* 1 = 0.476438 loss)
I0314 13:18:26.813822 16588 sgd_solver.cpp:106] Iteration 35600, lr = 0.1
I0314 13:18:41.298585 16588 solver.cpp:228] Iteration 35700, loss = 0.549973
I0314 13:18:41.298585 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.77
I0314 13:18:41.298585 16588 solver.cpp:244]     Train net output #1: loss = 0.549973 (* 1 = 0.549973 loss)
I0314 13:18:41.298585 16588 sgd_solver.cpp:106] Iteration 35700, lr = 0.1
I0314 13:18:55.753865 16588 solver.cpp:228] Iteration 35800, loss = 0.416733
I0314 13:18:55.753865 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:18:55.753865 16588 solver.cpp:244]     Train net output #1: loss = 0.416733 (* 1 = 0.416733 loss)
I0314 13:18:55.753865 16588 sgd_solver.cpp:106] Iteration 35800, lr = 0.1
I0314 13:19:10.267318 16588 solver.cpp:228] Iteration 35900, loss = 0.438269
I0314 13:19:10.267318 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:19:10.267318 16588 solver.cpp:244]     Train net output #1: loss = 0.438269 (* 1 = 0.438269 loss)
I0314 13:19:10.267318 16588 sgd_solver.cpp:106] Iteration 35900, lr = 0.1
I0314 13:19:24.768852 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_36000.caffemodel
I0314 13:19:24.807363 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_36000.solverstate
I0314 13:19:24.807363 16588 solver.cpp:337] Iteration 36000, Testing net (#0)
I0314 13:19:24.807363 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:19:29.610062 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6502
I0314 13:19:29.610062 16588 solver.cpp:404]     Test net output #1: loss = 1.08808 (* 1 = 1.08808 loss)
I0314 13:19:29.660065 16588 solver.cpp:228] Iteration 36000, loss = 0.364766
I0314 13:19:29.660065 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:19:29.660065 16588 solver.cpp:244]     Train net output #1: loss = 0.364766 (* 1 = 0.364766 loss)
I0314 13:19:29.660065 16588 sgd_solver.cpp:106] Iteration 36000, lr = 0.1
I0314 13:19:43.802620 16588 solver.cpp:228] Iteration 36100, loss = 0.41268
I0314 13:19:43.802620 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:19:43.802620 16588 solver.cpp:244]     Train net output #1: loss = 0.41268 (* 1 = 0.41268 loss)
I0314 13:19:43.802620 16588 sgd_solver.cpp:106] Iteration 36100, lr = 0.1
I0314 13:19:58.342355 16588 solver.cpp:228] Iteration 36200, loss = 0.515696
I0314 13:19:58.342355 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:19:58.342355 16588 solver.cpp:244]     Train net output #1: loss = 0.515696 (* 1 = 0.515696 loss)
I0314 13:19:58.342355 16588 sgd_solver.cpp:106] Iteration 36200, lr = 0.1
I0314 13:20:12.887639 16588 solver.cpp:228] Iteration 36300, loss = 0.417835
I0314 13:20:12.887639 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:20:12.887639 16588 solver.cpp:244]     Train net output #1: loss = 0.417835 (* 1 = 0.417835 loss)
I0314 13:20:12.887639 16588 sgd_solver.cpp:106] Iteration 36300, lr = 0.1
I0314 13:20:27.302992 16588 solver.cpp:228] Iteration 36400, loss = 0.400175
I0314 13:20:27.302992 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:20:27.302992 16588 solver.cpp:244]     Train net output #1: loss = 0.400175 (* 1 = 0.400175 loss)
I0314 13:20:27.302992 16588 sgd_solver.cpp:106] Iteration 36400, lr = 0.1
I0314 13:20:41.781757 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_36500.caffemodel
I0314 13:20:41.818755 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_36500.solverstate
I0314 13:20:41.824256 16588 solver.cpp:337] Iteration 36500, Testing net (#0)
I0314 13:20:41.824755 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:20:46.600044 16588 solver.cpp:404]     Test net output #0: accuracy = 0.725
I0314 13:20:46.600044 16588 solver.cpp:404]     Test net output #1: loss = 0.827984 (* 1 = 0.827984 loss)
I0314 13:20:46.660044 16588 solver.cpp:228] Iteration 36500, loss = 0.382068
I0314 13:20:46.660044 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:20:46.660044 16588 solver.cpp:244]     Train net output #1: loss = 0.382068 (* 1 = 0.382068 loss)
I0314 13:20:46.660044 16588 sgd_solver.cpp:106] Iteration 36500, lr = 0.1
I0314 13:21:00.838883 16588 solver.cpp:228] Iteration 36600, loss = 0.420307
I0314 13:21:00.838883 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:21:00.838883 16588 solver.cpp:244]     Train net output #1: loss = 0.420307 (* 1 = 0.420307 loss)
I0314 13:21:00.838883 16588 sgd_solver.cpp:106] Iteration 36600, lr = 0.1
I0314 13:21:15.349135 16588 solver.cpp:228] Iteration 36700, loss = 0.413628
I0314 13:21:15.349135 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:21:15.349135 16588 solver.cpp:244]     Train net output #1: loss = 0.413628 (* 1 = 0.413628 loss)
I0314 13:21:15.349135 16588 sgd_solver.cpp:106] Iteration 36700, lr = 0.1
I0314 13:21:29.855562 16588 solver.cpp:228] Iteration 36800, loss = 0.508751
I0314 13:21:29.855562 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:21:29.855562 16588 solver.cpp:244]     Train net output #1: loss = 0.50875 (* 1 = 0.50875 loss)
I0314 13:21:29.855562 16588 sgd_solver.cpp:106] Iteration 36800, lr = 0.1
I0314 13:21:44.384274 16588 solver.cpp:228] Iteration 36900, loss = 0.356116
I0314 13:21:44.384773 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:21:44.384773 16588 solver.cpp:244]     Train net output #1: loss = 0.356116 (* 1 = 0.356116 loss)
I0314 13:21:44.384773 16588 sgd_solver.cpp:106] Iteration 36900, lr = 0.1
I0314 13:21:58.852104 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_37000.caffemodel
I0314 13:21:58.886103 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_37000.solverstate
I0314 13:21:58.894111 16588 solver.cpp:337] Iteration 37000, Testing net (#0)
I0314 13:21:58.894111 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:22:03.676231 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7057
I0314 13:22:03.676231 16588 solver.cpp:404]     Test net output #1: loss = 0.952863 (* 1 = 0.952863 loss)
I0314 13:22:03.726758 16588 solver.cpp:228] Iteration 37000, loss = 0.397586
I0314 13:22:03.726758 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:22:03.726758 16588 solver.cpp:244]     Train net output #1: loss = 0.397585 (* 1 = 0.397585 loss)
I0314 13:22:03.726758 16588 sgd_solver.cpp:106] Iteration 37000, lr = 0.1
I0314 13:22:17.899153 16588 solver.cpp:228] Iteration 37100, loss = 0.457418
I0314 13:22:17.899653 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:22:17.899653 16588 solver.cpp:244]     Train net output #1: loss = 0.457417 (* 1 = 0.457417 loss)
I0314 13:22:17.899653 16588 sgd_solver.cpp:106] Iteration 37100, lr = 0.1
I0314 13:22:32.400681 16588 solver.cpp:228] Iteration 37200, loss = 0.521556
I0314 13:22:32.400681 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:22:32.400681 16588 solver.cpp:244]     Train net output #1: loss = 0.521556 (* 1 = 0.521556 loss)
I0314 13:22:32.400681 16588 sgd_solver.cpp:106] Iteration 37200, lr = 0.1
I0314 13:22:46.927431 16588 solver.cpp:228] Iteration 37300, loss = 0.369979
I0314 13:22:46.927431 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:22:46.927431 16588 solver.cpp:244]     Train net output #1: loss = 0.369979 (* 1 = 0.369979 loss)
I0314 13:22:46.927431 16588 sgd_solver.cpp:106] Iteration 37300, lr = 0.1
I0314 13:23:01.495270 16588 solver.cpp:228] Iteration 37400, loss = 0.305545
I0314 13:23:01.495270 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0314 13:23:01.495270 16588 solver.cpp:244]     Train net output #1: loss = 0.305545 (* 1 = 0.305545 loss)
I0314 13:23:01.495270 16588 sgd_solver.cpp:106] Iteration 37400, lr = 0.1
I0314 13:23:15.905773 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_37500.caffemodel
I0314 13:23:15.946771 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_37500.solverstate
I0314 13:23:15.953271 16588 solver.cpp:337] Iteration 37500, Testing net (#0)
I0314 13:23:15.953271 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:23:20.728704 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7344
I0314 13:23:20.728704 16588 solver.cpp:404]     Test net output #1: loss = 0.830414 (* 1 = 0.830414 loss)
I0314 13:23:20.808301 16588 solver.cpp:228] Iteration 37500, loss = 0.33371
I0314 13:23:20.808301 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:23:20.808301 16588 solver.cpp:244]     Train net output #1: loss = 0.33371 (* 1 = 0.33371 loss)
I0314 13:23:20.808301 16588 sgd_solver.cpp:106] Iteration 37500, lr = 0.1
I0314 13:23:34.811518 16588 solver.cpp:228] Iteration 37600, loss = 0.343251
I0314 13:23:34.811518 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:23:34.811518 16588 solver.cpp:244]     Train net output #1: loss = 0.343251 (* 1 = 0.343251 loss)
I0314 13:23:34.811518 16588 sgd_solver.cpp:106] Iteration 37600, lr = 0.1
I0314 13:23:49.316402 16588 solver.cpp:228] Iteration 37700, loss = 0.497065
I0314 13:23:49.316402 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:23:49.316402 16588 solver.cpp:244]     Train net output #1: loss = 0.497065 (* 1 = 0.497065 loss)
I0314 13:23:49.316402 16588 sgd_solver.cpp:106] Iteration 37700, lr = 0.1
I0314 13:24:03.845927 16588 solver.cpp:228] Iteration 37800, loss = 0.364943
I0314 13:24:03.845927 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:24:03.845927 16588 solver.cpp:244]     Train net output #1: loss = 0.364942 (* 1 = 0.364942 loss)
I0314 13:24:03.845927 16588 sgd_solver.cpp:106] Iteration 37800, lr = 0.1
I0314 13:24:18.422674 16588 solver.cpp:228] Iteration 37900, loss = 0.293585
I0314 13:24:18.422674 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:24:18.422674 16588 solver.cpp:244]     Train net output #1: loss = 0.293585 (* 1 = 0.293585 loss)
I0314 13:24:18.422674 16588 sgd_solver.cpp:106] Iteration 37900, lr = 0.1
I0314 13:24:32.826508 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_38000.caffemodel
I0314 13:24:32.856531 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_38000.solverstate
I0314 13:24:32.866533 16588 solver.cpp:337] Iteration 38000, Testing net (#0)
I0314 13:24:32.866533 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:24:37.601387 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7297
I0314 13:24:37.601387 16588 solver.cpp:404]     Test net output #1: loss = 0.814522 (* 1 = 0.814522 loss)
I0314 13:24:37.670884 16588 solver.cpp:228] Iteration 38000, loss = 0.311236
I0314 13:24:37.670884 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:24:37.670884 16588 solver.cpp:244]     Train net output #1: loss = 0.311235 (* 1 = 0.311235 loss)
I0314 13:24:37.670884 16588 sgd_solver.cpp:106] Iteration 38000, lr = 0.1
I0314 13:24:51.864672 16588 solver.cpp:228] Iteration 38100, loss = 0.358527
I0314 13:24:51.864672 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:24:51.864672 16588 solver.cpp:244]     Train net output #1: loss = 0.358527 (* 1 = 0.358527 loss)
I0314 13:24:51.864672 16588 sgd_solver.cpp:106] Iteration 38100, lr = 0.1
I0314 13:25:06.418913 16588 solver.cpp:228] Iteration 38200, loss = 0.488891
I0314 13:25:06.418913 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:25:06.418913 16588 solver.cpp:244]     Train net output #1: loss = 0.488891 (* 1 = 0.488891 loss)
I0314 13:25:06.418913 16588 sgd_solver.cpp:106] Iteration 38200, lr = 0.1
I0314 13:25:20.943909 16588 solver.cpp:228] Iteration 38300, loss = 0.420566
I0314 13:25:20.943909 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:25:20.943909 16588 solver.cpp:244]     Train net output #1: loss = 0.420566 (* 1 = 0.420566 loss)
I0314 13:25:20.943909 16588 sgd_solver.cpp:106] Iteration 38300, lr = 0.1
I0314 13:25:35.460669 16588 solver.cpp:228] Iteration 38400, loss = 0.222634
I0314 13:25:35.460669 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 13:25:35.460669 16588 solver.cpp:244]     Train net output #1: loss = 0.222634 (* 1 = 0.222634 loss)
I0314 13:25:35.460669 16588 sgd_solver.cpp:106] Iteration 38400, lr = 0.1
I0314 13:25:49.914921 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_38500.caffemodel
I0314 13:25:49.951921 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_38500.solverstate
I0314 13:25:49.958421 16588 solver.cpp:337] Iteration 38500, Testing net (#0)
I0314 13:25:49.958421 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:25:54.766345 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7722
I0314 13:25:54.766345 16588 solver.cpp:404]     Test net output #1: loss = 0.684873 (* 1 = 0.684873 loss)
I0314 13:25:54.809844 16588 solver.cpp:228] Iteration 38500, loss = 0.415062
I0314 13:25:54.809844 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:25:54.809844 16588 solver.cpp:244]     Train net output #1: loss = 0.415062 (* 1 = 0.415062 loss)
I0314 13:25:54.809844 16588 sgd_solver.cpp:106] Iteration 38500, lr = 0.1
I0314 13:26:08.922448 16588 solver.cpp:228] Iteration 38600, loss = 0.480715
I0314 13:26:08.922448 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:26:08.922448 16588 solver.cpp:244]     Train net output #1: loss = 0.480715 (* 1 = 0.480715 loss)
I0314 13:26:08.922448 16588 sgd_solver.cpp:106] Iteration 38600, lr = 0.1
I0314 13:26:23.421839 16588 solver.cpp:228] Iteration 38700, loss = 0.431661
I0314 13:26:23.421839 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:26:23.421839 16588 solver.cpp:244]     Train net output #1: loss = 0.431661 (* 1 = 0.431661 loss)
I0314 13:26:23.421839 16588 sgd_solver.cpp:106] Iteration 38700, lr = 0.1
I0314 13:26:38.010913 16588 solver.cpp:228] Iteration 38800, loss = 0.354392
I0314 13:26:38.010913 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:26:38.010913 16588 solver.cpp:244]     Train net output #1: loss = 0.354392 (* 1 = 0.354392 loss)
I0314 13:26:38.010913 16588 sgd_solver.cpp:106] Iteration 38800, lr = 0.1
I0314 13:26:52.472923 16588 solver.cpp:228] Iteration 38900, loss = 0.321492
I0314 13:26:52.472923 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:26:52.472923 16588 solver.cpp:244]     Train net output #1: loss = 0.321492 (* 1 = 0.321492 loss)
I0314 13:26:52.472923 16588 sgd_solver.cpp:106] Iteration 38900, lr = 0.1
I0314 13:27:06.922572 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_39000.caffemodel
I0314 13:27:06.962574 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_39000.solverstate
I0314 13:27:06.972574 16588 solver.cpp:337] Iteration 39000, Testing net (#0)
I0314 13:27:06.972574 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:27:11.743589 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6396
I0314 13:27:11.743589 16588 solver.cpp:404]     Test net output #1: loss = 1.18499 (* 1 = 1.18499 loss)
I0314 13:27:11.793591 16588 solver.cpp:228] Iteration 39000, loss = 0.387867
I0314 13:27:11.793591 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:27:11.793591 16588 solver.cpp:244]     Train net output #1: loss = 0.387867 (* 1 = 0.387867 loss)
I0314 13:27:11.793591 16588 sgd_solver.cpp:106] Iteration 39000, lr = 0.1
I0314 13:27:25.959424 16588 solver.cpp:228] Iteration 39100, loss = 0.477739
I0314 13:27:25.959424 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:27:25.959424 16588 solver.cpp:244]     Train net output #1: loss = 0.477739 (* 1 = 0.477739 loss)
I0314 13:27:25.959424 16588 sgd_solver.cpp:106] Iteration 39100, lr = 0.1
I0314 13:27:40.464464 16588 solver.cpp:228] Iteration 39200, loss = 0.419996
I0314 13:27:40.464964 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:27:40.464964 16588 solver.cpp:244]     Train net output #1: loss = 0.419996 (* 1 = 0.419996 loss)
I0314 13:27:40.464964 16588 sgd_solver.cpp:106] Iteration 39200, lr = 0.1
I0314 13:27:54.948997 16588 solver.cpp:228] Iteration 39300, loss = 0.437493
I0314 13:27:54.948997 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:27:54.948997 16588 solver.cpp:244]     Train net output #1: loss = 0.437493 (* 1 = 0.437493 loss)
I0314 13:27:54.948997 16588 sgd_solver.cpp:106] Iteration 39300, lr = 0.1
I0314 13:28:09.430683 16588 solver.cpp:228] Iteration 39400, loss = 0.321468
I0314 13:28:09.430683 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:28:09.430683 16588 solver.cpp:244]     Train net output #1: loss = 0.321468 (* 1 = 0.321468 loss)
I0314 13:28:09.430683 16588 sgd_solver.cpp:106] Iteration 39400, lr = 0.1
I0314 13:28:23.840719 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_39500.caffemodel
I0314 13:28:23.878219 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_39500.solverstate
I0314 13:28:23.884719 16588 solver.cpp:337] Iteration 39500, Testing net (#0)
I0314 13:28:23.884719 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:28:28.669147 16588 solver.cpp:404]     Test net output #0: accuracy = 0.709
I0314 13:28:28.669147 16588 solver.cpp:404]     Test net output #1: loss = 0.924701 (* 1 = 0.924701 loss)
I0314 13:28:28.719151 16588 solver.cpp:228] Iteration 39500, loss = 0.365246
I0314 13:28:28.719151 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:28:28.719151 16588 solver.cpp:244]     Train net output #1: loss = 0.365246 (* 1 = 0.365246 loss)
I0314 13:28:28.719151 16588 sgd_solver.cpp:106] Iteration 39500, lr = 0.1
I0314 13:28:42.892853 16588 solver.cpp:228] Iteration 39600, loss = 0.43449
I0314 13:28:42.893353 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:28:42.893353 16588 solver.cpp:244]     Train net output #1: loss = 0.43449 (* 1 = 0.43449 loss)
I0314 13:28:42.893353 16588 sgd_solver.cpp:106] Iteration 39600, lr = 0.1
I0314 13:28:57.459421 16588 solver.cpp:228] Iteration 39700, loss = 0.397321
I0314 13:28:57.459421 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:28:57.459421 16588 solver.cpp:244]     Train net output #1: loss = 0.397321 (* 1 = 0.397321 loss)
I0314 13:28:57.459421 16588 sgd_solver.cpp:106] Iteration 39700, lr = 0.1
I0314 13:29:11.971360 16588 solver.cpp:228] Iteration 39800, loss = 0.590346
I0314 13:29:11.971360 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 13:29:11.971360 16588 solver.cpp:244]     Train net output #1: loss = 0.590345 (* 1 = 0.590345 loss)
I0314 13:29:11.971360 16588 sgd_solver.cpp:106] Iteration 39800, lr = 0.1
I0314 13:29:26.493973 16588 solver.cpp:228] Iteration 39900, loss = 0.371339
I0314 13:29:26.493973 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:29:26.493973 16588 solver.cpp:244]     Train net output #1: loss = 0.371338 (* 1 = 0.371338 loss)
I0314 13:29:26.493973 16588 sgd_solver.cpp:106] Iteration 39900, lr = 0.1
I0314 13:29:40.907176 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_40000.caffemodel
I0314 13:29:40.943682 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_40000.solverstate
I0314 13:29:40.947183 16588 solver.cpp:337] Iteration 40000, Testing net (#0)
I0314 13:29:40.947183 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:29:45.852728 16588 solver.cpp:404]     Test net output #0: accuracy = 0.736
I0314 13:29:45.852728 16588 solver.cpp:404]     Test net output #1: loss = 0.840469 (* 1 = 0.840469 loss)
I0314 13:29:45.893718 16588 solver.cpp:228] Iteration 40000, loss = 0.464781
I0314 13:29:45.894198 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:29:45.894198 16588 solver.cpp:244]     Train net output #1: loss = 0.464781 (* 1 = 0.464781 loss)
I0314 13:29:45.894198 16588 sgd_solver.cpp:106] Iteration 40000, lr = 0.1
I0314 13:29:59.987607 16588 solver.cpp:228] Iteration 40100, loss = 0.572733
I0314 13:29:59.987607 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 13:29:59.987607 16588 solver.cpp:244]     Train net output #1: loss = 0.572733 (* 1 = 0.572733 loss)
I0314 13:29:59.987607 16588 sgd_solver.cpp:106] Iteration 40100, lr = 0.1
I0314 13:30:14.543659 16588 solver.cpp:228] Iteration 40200, loss = 0.435057
I0314 13:30:14.543659 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:30:14.543659 16588 solver.cpp:244]     Train net output #1: loss = 0.435057 (* 1 = 0.435057 loss)
I0314 13:30:14.543659 16588 sgd_solver.cpp:106] Iteration 40200, lr = 0.1
I0314 13:30:29.050812 16588 solver.cpp:228] Iteration 40300, loss = 0.483141
I0314 13:30:29.050812 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:30:29.050812 16588 solver.cpp:244]     Train net output #1: loss = 0.483141 (* 1 = 0.483141 loss)
I0314 13:30:29.050812 16588 sgd_solver.cpp:106] Iteration 40300, lr = 0.1
I0314 13:30:43.523381 16588 solver.cpp:228] Iteration 40400, loss = 0.245654
I0314 13:30:43.523381 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:30:43.523381 16588 solver.cpp:244]     Train net output #1: loss = 0.245654 (* 1 = 0.245654 loss)
I0314 13:30:43.523381 16588 sgd_solver.cpp:106] Iteration 40400, lr = 0.1
I0314 13:30:57.961745 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_40500.caffemodel
I0314 13:30:57.998769 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_40500.solverstate
I0314 13:30:58.005270 16588 solver.cpp:337] Iteration 40500, Testing net (#0)
I0314 13:30:58.005270 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:31:02.777166 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7096
I0314 13:31:02.777166 16588 solver.cpp:404]     Test net output #1: loss = 0.845729 (* 1 = 0.845729 loss)
I0314 13:31:02.817167 16588 solver.cpp:228] Iteration 40500, loss = 0.417405
I0314 13:31:02.817167 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:31:02.817167 16588 solver.cpp:244]     Train net output #1: loss = 0.417404 (* 1 = 0.417404 loss)
I0314 13:31:02.817167 16588 sgd_solver.cpp:106] Iteration 40500, lr = 0.1
I0314 13:31:16.866449 16588 solver.cpp:228] Iteration 40600, loss = 0.367422
I0314 13:31:16.866449 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:31:16.866449 16588 solver.cpp:244]     Train net output #1: loss = 0.367422 (* 1 = 0.367422 loss)
I0314 13:31:16.866449 16588 sgd_solver.cpp:106] Iteration 40600, lr = 0.1
I0314 13:31:31.361675 16588 solver.cpp:228] Iteration 40700, loss = 0.483424
I0314 13:31:31.361675 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:31:31.362175 16588 solver.cpp:244]     Train net output #1: loss = 0.483424 (* 1 = 0.483424 loss)
I0314 13:31:31.362175 16588 sgd_solver.cpp:106] Iteration 40700, lr = 0.1
I0314 13:31:45.922389 16588 solver.cpp:228] Iteration 40800, loss = 0.377927
I0314 13:31:45.922389 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:31:45.922389 16588 solver.cpp:244]     Train net output #1: loss = 0.377927 (* 1 = 0.377927 loss)
I0314 13:31:45.922389 16588 sgd_solver.cpp:106] Iteration 40800, lr = 0.1
I0314 13:32:00.428755 16588 solver.cpp:228] Iteration 40900, loss = 0.334712
I0314 13:32:00.428755 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:32:00.429256 16588 solver.cpp:244]     Train net output #1: loss = 0.334711 (* 1 = 0.334711 loss)
I0314 13:32:00.429256 16588 sgd_solver.cpp:106] Iteration 40900, lr = 0.1
I0314 13:32:14.880995 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_41000.caffemodel
I0314 13:32:14.917495 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_41000.solverstate
I0314 13:32:14.923995 16588 solver.cpp:337] Iteration 41000, Testing net (#0)
I0314 13:32:14.923995 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:32:19.771111 16588 solver.cpp:404]     Test net output #0: accuracy = 0.701
I0314 13:32:19.771111 16588 solver.cpp:404]     Test net output #1: loss = 0.945367 (* 1 = 0.945367 loss)
I0314 13:32:19.826611 16588 solver.cpp:228] Iteration 41000, loss = 0.362448
I0314 13:32:19.826611 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:32:19.826611 16588 solver.cpp:244]     Train net output #1: loss = 0.362448 (* 1 = 0.362448 loss)
I0314 13:32:19.826611 16588 sgd_solver.cpp:106] Iteration 41000, lr = 0.1
I0314 13:32:33.894534 16588 solver.cpp:228] Iteration 41100, loss = 0.397702
I0314 13:32:33.894534 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:32:33.895035 16588 solver.cpp:244]     Train net output #1: loss = 0.397701 (* 1 = 0.397701 loss)
I0314 13:32:33.895035 16588 sgd_solver.cpp:106] Iteration 41100, lr = 0.1
I0314 13:32:48.416956 16588 solver.cpp:228] Iteration 41200, loss = 0.442378
I0314 13:32:48.416956 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:32:48.416956 16588 solver.cpp:244]     Train net output #1: loss = 0.442378 (* 1 = 0.442378 loss)
I0314 13:32:48.416956 16588 sgd_solver.cpp:106] Iteration 41200, lr = 0.1
I0314 13:33:02.896211 16588 solver.cpp:228] Iteration 41300, loss = 0.502263
I0314 13:33:02.896711 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:33:02.896711 16588 solver.cpp:244]     Train net output #1: loss = 0.502263 (* 1 = 0.502263 loss)
I0314 13:33:02.896711 16588 sgd_solver.cpp:106] Iteration 41300, lr = 0.1
I0314 13:33:17.454342 16588 solver.cpp:228] Iteration 41400, loss = 0.333041
I0314 13:33:17.454342 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:33:17.454342 16588 solver.cpp:244]     Train net output #1: loss = 0.333041 (* 1 = 0.333041 loss)
I0314 13:33:17.454342 16588 sgd_solver.cpp:106] Iteration 41400, lr = 0.1
I0314 13:33:31.942759 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_41500.caffemodel
I0314 13:33:31.978780 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_41500.solverstate
I0314 13:33:31.984282 16588 solver.cpp:337] Iteration 41500, Testing net (#0)
I0314 13:33:31.984282 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:33:36.751026 16588 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0314 13:33:36.751026 16588 solver.cpp:404]     Test net output #1: loss = 0.71196 (* 1 = 0.71196 loss)
I0314 13:33:36.791028 16588 solver.cpp:228] Iteration 41500, loss = 0.328472
I0314 13:33:36.791028 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:33:36.791028 16588 solver.cpp:244]     Train net output #1: loss = 0.328472 (* 1 = 0.328472 loss)
I0314 13:33:36.791028 16588 sgd_solver.cpp:106] Iteration 41500, lr = 0.1
I0314 13:33:50.791316 16588 solver.cpp:228] Iteration 41600, loss = 0.413646
I0314 13:33:50.791316 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:33:50.791316 16588 solver.cpp:244]     Train net output #1: loss = 0.413646 (* 1 = 0.413646 loss)
I0314 13:33:50.791316 16588 sgd_solver.cpp:106] Iteration 41600, lr = 0.1
I0314 13:34:05.320827 16588 solver.cpp:228] Iteration 41700, loss = 0.357177
I0314 13:34:05.320827 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:34:05.320827 16588 solver.cpp:244]     Train net output #1: loss = 0.357177 (* 1 = 0.357177 loss)
I0314 13:34:05.320827 16588 sgd_solver.cpp:106] Iteration 41700, lr = 0.1
I0314 13:34:19.785725 16588 solver.cpp:228] Iteration 41800, loss = 0.424612
I0314 13:34:19.785725 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:34:19.785725 16588 solver.cpp:244]     Train net output #1: loss = 0.424611 (* 1 = 0.424611 loss)
I0314 13:34:19.785725 16588 sgd_solver.cpp:106] Iteration 41800, lr = 0.1
I0314 13:34:34.323194 16588 solver.cpp:228] Iteration 41900, loss = 0.366087
I0314 13:34:34.323194 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:34:34.323194 16588 solver.cpp:244]     Train net output #1: loss = 0.366087 (* 1 = 0.366087 loss)
I0314 13:34:34.323194 16588 sgd_solver.cpp:106] Iteration 41900, lr = 0.1
I0314 13:34:48.733649 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_42000.caffemodel
I0314 13:34:48.751651 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_42000.solverstate
I0314 13:34:48.758149 16588 solver.cpp:337] Iteration 42000, Testing net (#0)
I0314 13:34:48.758149 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:34:53.561565 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7455
I0314 13:34:53.561565 16588 solver.cpp:404]     Test net output #1: loss = 0.770411 (* 1 = 0.770411 loss)
I0314 13:34:53.631069 16588 solver.cpp:228] Iteration 42000, loss = 0.324393
I0314 13:34:53.631069 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:34:53.631069 16588 solver.cpp:244]     Train net output #1: loss = 0.324393 (* 1 = 0.324393 loss)
I0314 13:34:53.631069 16588 sgd_solver.cpp:106] Iteration 42000, lr = 0.1
I0314 13:35:07.711777 16588 solver.cpp:228] Iteration 42100, loss = 0.385766
I0314 13:35:07.711777 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:35:07.711777 16588 solver.cpp:244]     Train net output #1: loss = 0.385766 (* 1 = 0.385766 loss)
I0314 13:35:07.711777 16588 sgd_solver.cpp:106] Iteration 42100, lr = 0.1
I0314 13:35:22.184952 16588 solver.cpp:228] Iteration 42200, loss = 0.563072
I0314 13:35:22.184952 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:35:22.184952 16588 solver.cpp:244]     Train net output #1: loss = 0.563071 (* 1 = 0.563071 loss)
I0314 13:35:22.184952 16588 sgd_solver.cpp:106] Iteration 42200, lr = 0.1
I0314 13:35:36.708446 16588 solver.cpp:228] Iteration 42300, loss = 0.413863
I0314 13:35:36.708446 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:35:36.708446 16588 solver.cpp:244]     Train net output #1: loss = 0.413863 (* 1 = 0.413863 loss)
I0314 13:35:36.708446 16588 sgd_solver.cpp:106] Iteration 42300, lr = 0.1
I0314 13:35:51.257704 16588 solver.cpp:228] Iteration 42400, loss = 0.361382
I0314 13:35:51.257704 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:35:51.257704 16588 solver.cpp:244]     Train net output #1: loss = 0.361382 (* 1 = 0.361382 loss)
I0314 13:35:51.257704 16588 sgd_solver.cpp:106] Iteration 42400, lr = 0.1
I0314 13:36:05.684332 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_42500.caffemodel
I0314 13:36:05.722333 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_42500.solverstate
I0314 13:36:05.728833 16588 solver.cpp:337] Iteration 42500, Testing net (#0)
I0314 13:36:05.728833 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:36:10.518296 16588 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0314 13:36:10.518296 16588 solver.cpp:404]     Test net output #1: loss = 0.728149 (* 1 = 0.728149 loss)
I0314 13:36:10.574300 16588 solver.cpp:228] Iteration 42500, loss = 0.426256
I0314 13:36:10.574300 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:36:10.574300 16588 solver.cpp:244]     Train net output #1: loss = 0.426256 (* 1 = 0.426256 loss)
I0314 13:36:10.574300 16588 sgd_solver.cpp:106] Iteration 42500, lr = 0.1
I0314 13:36:24.709379 16588 solver.cpp:228] Iteration 42600, loss = 0.339274
I0314 13:36:24.709379 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:36:24.709379 16588 solver.cpp:244]     Train net output #1: loss = 0.339274 (* 1 = 0.339274 loss)
I0314 13:36:24.709379 16588 sgd_solver.cpp:106] Iteration 42600, lr = 0.1
I0314 13:36:39.234849 16588 solver.cpp:228] Iteration 42700, loss = 0.403501
I0314 13:36:39.234849 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:36:39.234849 16588 solver.cpp:244]     Train net output #1: loss = 0.403501 (* 1 = 0.403501 loss)
I0314 13:36:39.234849 16588 sgd_solver.cpp:106] Iteration 42700, lr = 0.1
I0314 13:36:53.760195 16588 solver.cpp:228] Iteration 42800, loss = 0.477854
I0314 13:36:53.760195 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:36:53.760195 16588 solver.cpp:244]     Train net output #1: loss = 0.477853 (* 1 = 0.477853 loss)
I0314 13:36:53.760195 16588 sgd_solver.cpp:106] Iteration 42800, lr = 0.1
I0314 13:37:08.269819 16588 solver.cpp:228] Iteration 42900, loss = 0.32091
I0314 13:37:08.269819 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:37:08.269819 16588 solver.cpp:244]     Train net output #1: loss = 0.32091 (* 1 = 0.32091 loss)
I0314 13:37:08.269819 16588 sgd_solver.cpp:106] Iteration 42900, lr = 0.1
I0314 13:37:22.763190 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_43000.caffemodel
I0314 13:37:22.800689 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_43000.solverstate
I0314 13:37:22.806689 16588 solver.cpp:337] Iteration 43000, Testing net (#0)
I0314 13:37:22.806689 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:37:27.591296 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6804
I0314 13:37:27.591796 16588 solver.cpp:404]     Test net output #1: loss = 1.05984 (* 1 = 1.05984 loss)
I0314 13:37:27.645297 16588 solver.cpp:228] Iteration 43000, loss = 0.455022
I0314 13:37:27.645297 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:37:27.645297 16588 solver.cpp:244]     Train net output #1: loss = 0.455022 (* 1 = 0.455022 loss)
I0314 13:37:27.645297 16588 sgd_solver.cpp:106] Iteration 43000, lr = 0.1
I0314 13:37:41.856638 16588 solver.cpp:228] Iteration 43100, loss = 0.490852
I0314 13:37:41.856638 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 13:37:41.856638 16588 solver.cpp:244]     Train net output #1: loss = 0.490851 (* 1 = 0.490851 loss)
I0314 13:37:41.856638 16588 sgd_solver.cpp:106] Iteration 43100, lr = 0.1
I0314 13:37:56.341110 16588 solver.cpp:228] Iteration 43200, loss = 0.408815
I0314 13:37:56.341110 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:37:56.341110 16588 solver.cpp:244]     Train net output #1: loss = 0.408815 (* 1 = 0.408815 loss)
I0314 13:37:56.341110 16588 sgd_solver.cpp:106] Iteration 43200, lr = 0.1
I0314 13:38:10.828446 16588 solver.cpp:228] Iteration 43300, loss = 0.35121
I0314 13:38:10.828446 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:38:10.828446 16588 solver.cpp:244]     Train net output #1: loss = 0.35121 (* 1 = 0.35121 loss)
I0314 13:38:10.828446 16588 sgd_solver.cpp:106] Iteration 43300, lr = 0.1
I0314 13:38:25.401137 16588 solver.cpp:228] Iteration 43400, loss = 0.290791
I0314 13:38:25.401137 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:38:25.401137 16588 solver.cpp:244]     Train net output #1: loss = 0.29079 (* 1 = 0.29079 loss)
I0314 13:38:25.401638 16588 sgd_solver.cpp:106] Iteration 43400, lr = 0.1
I0314 13:38:39.848783 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_43500.caffemodel
I0314 13:38:39.872776 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_43500.solverstate
I0314 13:38:39.879276 16588 solver.cpp:337] Iteration 43500, Testing net (#0)
I0314 13:38:39.879276 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:38:44.921195 16588 solver.cpp:404]     Test net output #0: accuracy = 0.6299
I0314 13:38:44.921195 16588 solver.cpp:404]     Test net output #1: loss = 1.13597 (* 1 = 1.13597 loss)
I0314 13:38:44.951197 16588 solver.cpp:228] Iteration 43500, loss = 0.376105
I0314 13:38:44.951197 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:38:44.951197 16588 solver.cpp:244]     Train net output #1: loss = 0.376105 (* 1 = 0.376105 loss)
I0314 13:38:44.951197 16588 sgd_solver.cpp:106] Iteration 43500, lr = 0.1
I0314 13:38:59.205124 16588 solver.cpp:228] Iteration 43600, loss = 0.407215
I0314 13:38:59.205124 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:38:59.205124 16588 solver.cpp:244]     Train net output #1: loss = 0.407214 (* 1 = 0.407214 loss)
I0314 13:38:59.205124 16588 sgd_solver.cpp:106] Iteration 43600, lr = 0.1
I0314 13:39:14.012030 16588 solver.cpp:228] Iteration 43700, loss = 0.385827
I0314 13:39:14.012030 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:39:14.012030 16588 solver.cpp:244]     Train net output #1: loss = 0.385827 (* 1 = 0.385827 loss)
I0314 13:39:14.012030 16588 sgd_solver.cpp:106] Iteration 43700, lr = 0.1
I0314 13:39:28.677398 16588 solver.cpp:228] Iteration 43800, loss = 0.457831
I0314 13:39:28.677398 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:39:28.677398 16588 solver.cpp:244]     Train net output #1: loss = 0.457831 (* 1 = 0.457831 loss)
I0314 13:39:28.677898 16588 sgd_solver.cpp:106] Iteration 43800, lr = 0.1
I0314 13:39:43.255059 16588 solver.cpp:228] Iteration 43900, loss = 0.339411
I0314 13:39:43.255059 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0314 13:39:43.255059 16588 solver.cpp:244]     Train net output #1: loss = 0.339411 (* 1 = 0.339411 loss)
I0314 13:39:43.255059 16588 sgd_solver.cpp:106] Iteration 43900, lr = 0.1
I0314 13:39:57.866520 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_44000.caffemodel
I0314 13:39:57.905020 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_44000.solverstate
I0314 13:39:57.911020 16588 solver.cpp:337] Iteration 44000, Testing net (#0)
I0314 13:39:57.911020 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:40:02.857322 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7049
I0314 13:40:02.857322 16588 solver.cpp:404]     Test net output #1: loss = 0.912893 (* 1 = 0.912893 loss)
I0314 13:40:02.907322 16588 solver.cpp:228] Iteration 44000, loss = 0.374114
I0314 13:40:02.907322 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:40:02.907322 16588 solver.cpp:244]     Train net output #1: loss = 0.374113 (* 1 = 0.374113 loss)
I0314 13:40:02.907322 16588 sgd_solver.cpp:106] Iteration 44000, lr = 0.1
I0314 13:40:17.012465 16588 solver.cpp:228] Iteration 44100, loss = 0.466145
I0314 13:40:17.012465 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:40:17.012465 16588 solver.cpp:244]     Train net output #1: loss = 0.466145 (* 1 = 0.466145 loss)
I0314 13:40:17.012465 16588 sgd_solver.cpp:106] Iteration 44100, lr = 0.1
I0314 13:40:31.743402 16588 solver.cpp:228] Iteration 44200, loss = 0.493423
I0314 13:40:31.743402 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:40:31.743402 16588 solver.cpp:244]     Train net output #1: loss = 0.493423 (* 1 = 0.493423 loss)
I0314 13:40:31.743402 16588 sgd_solver.cpp:106] Iteration 44200, lr = 0.1
I0314 13:40:46.456249 16588 solver.cpp:228] Iteration 44300, loss = 0.434331
I0314 13:40:46.456249 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:40:46.456249 16588 solver.cpp:244]     Train net output #1: loss = 0.43433 (* 1 = 0.43433 loss)
I0314 13:40:46.456249 16588 sgd_solver.cpp:106] Iteration 44300, lr = 0.1
I0314 13:41:01.115133 16588 solver.cpp:228] Iteration 44400, loss = 0.293128
I0314 13:41:01.115133 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:41:01.115133 16588 solver.cpp:244]     Train net output #1: loss = 0.293128 (* 1 = 0.293128 loss)
I0314 13:41:01.115133 16588 sgd_solver.cpp:106] Iteration 44400, lr = 0.1
I0314 13:41:15.735893 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_44500.caffemodel
I0314 13:41:15.820904 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_44500.solverstate
I0314 13:41:15.827904 16588 solver.cpp:337] Iteration 44500, Testing net (#0)
I0314 13:41:15.827904 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:41:20.832561 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7662
I0314 13:41:20.833564 16588 solver.cpp:404]     Test net output #1: loss = 0.740636 (* 1 = 0.740636 loss)
I0314 13:41:20.880069 16588 solver.cpp:228] Iteration 44500, loss = 0.319654
I0314 13:41:20.880069 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:41:20.880069 16588 solver.cpp:244]     Train net output #1: loss = 0.319654 (* 1 = 0.319654 loss)
I0314 13:41:20.880069 16588 sgd_solver.cpp:106] Iteration 44500, lr = 0.1
I0314 13:41:35.556795 16588 solver.cpp:228] Iteration 44600, loss = 0.381972
I0314 13:41:35.556795 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:41:35.556795 16588 solver.cpp:244]     Train net output #1: loss = 0.381972 (* 1 = 0.381972 loss)
I0314 13:41:35.556795 16588 sgd_solver.cpp:106] Iteration 44600, lr = 0.1
I0314 13:41:50.509554 16588 solver.cpp:228] Iteration 44700, loss = 0.435407
I0314 13:41:50.510054 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:41:50.510054 16588 solver.cpp:244]     Train net output #1: loss = 0.435407 (* 1 = 0.435407 loss)
I0314 13:41:50.510054 16588 sgd_solver.cpp:106] Iteration 44700, lr = 0.1
I0314 13:42:05.495432 16588 solver.cpp:228] Iteration 44800, loss = 0.422641
I0314 13:42:05.495432 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:42:05.495432 16588 solver.cpp:244]     Train net output #1: loss = 0.422641 (* 1 = 0.422641 loss)
I0314 13:42:05.495432 16588 sgd_solver.cpp:106] Iteration 44800, lr = 0.1
I0314 13:42:20.175779 16588 solver.cpp:228] Iteration 44900, loss = 0.321944
I0314 13:42:20.175779 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:42:20.175779 16588 solver.cpp:244]     Train net output #1: loss = 0.321944 (* 1 = 0.321944 loss)
I0314 13:42:20.175779 16588 sgd_solver.cpp:106] Iteration 44900, lr = 0.1
I0314 13:42:34.738469 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_45000.caffemodel
I0314 13:42:34.775952 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_45000.solverstate
I0314 13:42:34.782452 16588 solver.cpp:337] Iteration 45000, Testing net (#0)
I0314 13:42:34.782452 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:42:39.694550 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7126
I0314 13:42:39.694550 16588 solver.cpp:404]     Test net output #1: loss = 0.857661 (* 1 = 0.857661 loss)
I0314 13:42:39.741050 16588 solver.cpp:228] Iteration 45000, loss = 0.274405
I0314 13:42:39.741050 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:42:39.741050 16588 solver.cpp:244]     Train net output #1: loss = 0.274404 (* 1 = 0.274404 loss)
I0314 13:42:39.741050 16588 sgd_solver.cpp:106] Iteration 45000, lr = 0.1
I0314 13:42:54.082208 16588 solver.cpp:228] Iteration 45100, loss = 0.401306
I0314 13:42:54.082208 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:42:54.082710 16588 solver.cpp:244]     Train net output #1: loss = 0.401306 (* 1 = 0.401306 loss)
I0314 13:42:54.082710 16588 sgd_solver.cpp:106] Iteration 45100, lr = 0.1
I0314 13:43:08.880297 16588 solver.cpp:228] Iteration 45200, loss = 0.499778
I0314 13:43:08.880796 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 13:43:08.880796 16588 solver.cpp:244]     Train net output #1: loss = 0.499777 (* 1 = 0.499777 loss)
I0314 13:43:08.880796 16588 sgd_solver.cpp:106] Iteration 45200, lr = 0.1
I0314 13:43:23.536481 16588 solver.cpp:228] Iteration 45300, loss = 0.454684
I0314 13:43:23.536981 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:43:23.536981 16588 solver.cpp:244]     Train net output #1: loss = 0.454684 (* 1 = 0.454684 loss)
I0314 13:43:23.536981 16588 sgd_solver.cpp:106] Iteration 45300, lr = 0.1
I0314 13:43:38.061512 16588 solver.cpp:228] Iteration 45400, loss = 0.321458
I0314 13:43:38.061512 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:43:38.061512 16588 solver.cpp:244]     Train net output #1: loss = 0.321458 (* 1 = 0.321458 loss)
I0314 13:43:38.061512 16588 sgd_solver.cpp:106] Iteration 45400, lr = 0.1
I0314 13:43:52.592144 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_45500.caffemodel
I0314 13:43:52.627146 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_45500.solverstate
I0314 13:43:52.633646 16588 solver.cpp:337] Iteration 45500, Testing net (#0)
I0314 13:43:52.634146 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:43:57.566154 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7754
I0314 13:43:57.566154 16588 solver.cpp:404]     Test net output #1: loss = 0.666632 (* 1 = 0.666632 loss)
I0314 13:43:57.641170 16588 solver.cpp:228] Iteration 45500, loss = 0.298613
I0314 13:43:57.641170 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:43:57.641170 16588 solver.cpp:244]     Train net output #1: loss = 0.298613 (* 1 = 0.298613 loss)
I0314 13:43:57.641170 16588 sgd_solver.cpp:106] Iteration 45500, lr = 0.1
I0314 13:44:11.826287 16588 solver.cpp:228] Iteration 45600, loss = 0.456111
I0314 13:44:11.826287 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 13:44:11.826287 16588 solver.cpp:244]     Train net output #1: loss = 0.456111 (* 1 = 0.456111 loss)
I0314 13:44:11.826287 16588 sgd_solver.cpp:106] Iteration 45600, lr = 0.1
I0314 13:44:26.376821 16588 solver.cpp:228] Iteration 45700, loss = 0.489305
I0314 13:44:26.376821 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:44:26.376821 16588 solver.cpp:244]     Train net output #1: loss = 0.489304 (* 1 = 0.489304 loss)
I0314 13:44:26.376821 16588 sgd_solver.cpp:106] Iteration 45700, lr = 0.1
I0314 13:44:41.210561 16588 solver.cpp:228] Iteration 45800, loss = 0.35648
I0314 13:44:41.210561 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:44:41.210561 16588 solver.cpp:244]     Train net output #1: loss = 0.35648 (* 1 = 0.35648 loss)
I0314 13:44:41.210561 16588 sgd_solver.cpp:106] Iteration 45800, lr = 0.1
I0314 13:44:56.036981 16588 solver.cpp:228] Iteration 45900, loss = 0.307514
I0314 13:44:56.036981 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0314 13:44:56.036981 16588 solver.cpp:244]     Train net output #1: loss = 0.307514 (* 1 = 0.307514 loss)
I0314 13:44:56.036981 16588 sgd_solver.cpp:106] Iteration 45900, lr = 0.1
I0314 13:45:10.711586 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_46000.caffemodel
I0314 13:45:10.750087 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_46000.solverstate
I0314 13:45:10.756587 16588 solver.cpp:337] Iteration 46000, Testing net (#0)
I0314 13:45:10.756587 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:45:15.773088 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7432
I0314 13:45:15.773088 16588 solver.cpp:404]     Test net output #1: loss = 0.799842 (* 1 = 0.799842 loss)
I0314 13:45:15.823101 16588 solver.cpp:228] Iteration 46000, loss = 0.355031
I0314 13:45:15.823101 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:45:15.823101 16588 solver.cpp:244]     Train net output #1: loss = 0.35503 (* 1 = 0.35503 loss)
I0314 13:45:15.823101 16588 sgd_solver.cpp:106] Iteration 46000, lr = 0.1
I0314 13:45:30.017381 16588 solver.cpp:228] Iteration 46100, loss = 0.404697
I0314 13:45:30.017381 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:45:30.017891 16588 solver.cpp:244]     Train net output #1: loss = 0.404697 (* 1 = 0.404697 loss)
I0314 13:45:30.017891 16588 sgd_solver.cpp:106] Iteration 46100, lr = 0.1
I0314 13:45:44.848155 16588 solver.cpp:228] Iteration 46200, loss = 0.390053
I0314 13:45:44.848155 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:45:44.848155 16588 solver.cpp:244]     Train net output #1: loss = 0.390053 (* 1 = 0.390053 loss)
I0314 13:45:44.848155 16588 sgd_solver.cpp:106] Iteration 46200, lr = 0.1
I0314 13:45:59.438879 16588 solver.cpp:228] Iteration 46300, loss = 0.410252
I0314 13:45:59.438879 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:45:59.438879 16588 solver.cpp:244]     Train net output #1: loss = 0.410252 (* 1 = 0.410252 loss)
I0314 13:45:59.438879 16588 sgd_solver.cpp:106] Iteration 46300, lr = 0.1
I0314 13:46:14.058140 16588 solver.cpp:228] Iteration 46400, loss = 0.250994
I0314 13:46:14.058140 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0314 13:46:14.058140 16588 solver.cpp:244]     Train net output #1: loss = 0.250994 (* 1 = 0.250994 loss)
I0314 13:46:14.058140 16588 sgd_solver.cpp:106] Iteration 46400, lr = 0.1
I0314 13:46:28.696370 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_46500.caffemodel
I0314 13:46:28.736368 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_46500.solverstate
I0314 13:46:28.742869 16588 solver.cpp:337] Iteration 46500, Testing net (#0)
I0314 13:46:28.742869 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:46:33.684870 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7816
I0314 13:46:33.684870 16588 solver.cpp:404]     Test net output #1: loss = 0.663479 (* 1 = 0.663479 loss)
I0314 13:46:33.754369 16588 solver.cpp:228] Iteration 46500, loss = 0.299867
I0314 13:46:33.754369 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0314 13:46:33.754369 16588 solver.cpp:244]     Train net output #1: loss = 0.299866 (* 1 = 0.299866 loss)
I0314 13:46:33.754369 16588 sgd_solver.cpp:106] Iteration 46500, lr = 0.1
I0314 13:46:48.067528 16588 solver.cpp:228] Iteration 46600, loss = 0.493278
I0314 13:46:48.068029 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:46:48.068029 16588 solver.cpp:244]     Train net output #1: loss = 0.493278 (* 1 = 0.493278 loss)
I0314 13:46:48.068029 16588 sgd_solver.cpp:106] Iteration 46600, lr = 0.1
I0314 13:47:02.918655 16588 solver.cpp:228] Iteration 46700, loss = 0.49503
I0314 13:47:02.918655 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:47:02.918655 16588 solver.cpp:244]     Train net output #1: loss = 0.495029 (* 1 = 0.495029 loss)
I0314 13:47:02.918655 16588 sgd_solver.cpp:106] Iteration 46700, lr = 0.1
I0314 13:47:17.509949 16588 solver.cpp:228] Iteration 46800, loss = 0.445973
I0314 13:47:17.509949 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:47:17.509949 16588 solver.cpp:244]     Train net output #1: loss = 0.445973 (* 1 = 0.445973 loss)
I0314 13:47:17.509949 16588 sgd_solver.cpp:106] Iteration 46800, lr = 0.1
I0314 13:47:32.262990 16588 solver.cpp:228] Iteration 46900, loss = 0.347895
I0314 13:47:32.262990 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:47:32.262990 16588 solver.cpp:244]     Train net output #1: loss = 0.347895 (* 1 = 0.347895 loss)
I0314 13:47:32.262990 16588 sgd_solver.cpp:106] Iteration 46900, lr = 0.1
I0314 13:47:46.830451 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_47000.caffemodel
I0314 13:47:46.868451 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_47000.solverstate
I0314 13:47:46.875452 16588 solver.cpp:337] Iteration 47000, Testing net (#0)
I0314 13:47:46.875452 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:47:51.815022 16588 solver.cpp:404]     Test net output #0: accuracy = 0.539
I0314 13:47:51.815022 16588 solver.cpp:404]     Test net output #1: loss = 1.96419 (* 1 = 1.96419 loss)
I0314 13:47:51.901522 16588 solver.cpp:228] Iteration 47000, loss = 0.358429
I0314 13:47:51.901522 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:47:51.901522 16588 solver.cpp:244]     Train net output #1: loss = 0.358429 (* 1 = 0.358429 loss)
I0314 13:47:51.901522 16588 sgd_solver.cpp:106] Iteration 47000, lr = 0.1
I0314 13:48:06.332887 16588 solver.cpp:228] Iteration 47100, loss = 0.480515
I0314 13:48:06.332887 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:48:06.332887 16588 solver.cpp:244]     Train net output #1: loss = 0.480514 (* 1 = 0.480514 loss)
I0314 13:48:06.332887 16588 sgd_solver.cpp:106] Iteration 47100, lr = 0.1
I0314 13:48:20.936203 16588 solver.cpp:228] Iteration 47200, loss = 0.381036
I0314 13:48:20.936203 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:48:20.936203 16588 solver.cpp:244]     Train net output #1: loss = 0.381035 (* 1 = 0.381035 loss)
I0314 13:48:20.936203 16588 sgd_solver.cpp:106] Iteration 47200, lr = 0.1
I0314 13:48:35.636118 16588 solver.cpp:228] Iteration 47300, loss = 0.318559
I0314 13:48:35.636118 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:48:35.636118 16588 solver.cpp:244]     Train net output #1: loss = 0.318559 (* 1 = 0.318559 loss)
I0314 13:48:35.636118 16588 sgd_solver.cpp:106] Iteration 47300, lr = 0.1
I0314 13:48:50.528764 16588 solver.cpp:228] Iteration 47400, loss = 0.287186
I0314 13:48:50.528764 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:48:50.528764 16588 solver.cpp:244]     Train net output #1: loss = 0.287186 (* 1 = 0.287186 loss)
I0314 13:48:50.528764 16588 sgd_solver.cpp:106] Iteration 47400, lr = 0.1
I0314 13:49:05.273026 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_47500.caffemodel
I0314 13:49:05.307025 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_47500.solverstate
I0314 13:49:05.313032 16588 solver.cpp:337] Iteration 47500, Testing net (#0)
I0314 13:49:05.313032 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:49:10.479524 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7609
I0314 13:49:10.479524 16588 solver.cpp:404]     Test net output #1: loss = 0.708941 (* 1 = 0.708941 loss)
I0314 13:49:10.524030 16588 solver.cpp:228] Iteration 47500, loss = 0.321938
I0314 13:49:10.524030 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:49:10.524526 16588 solver.cpp:244]     Train net output #1: loss = 0.321938 (* 1 = 0.321938 loss)
I0314 13:49:10.524526 16588 sgd_solver.cpp:106] Iteration 47500, lr = 0.1
I0314 13:49:25.037125 16588 solver.cpp:228] Iteration 47600, loss = 0.482809
I0314 13:49:25.037125 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 13:49:25.037125 16588 solver.cpp:244]     Train net output #1: loss = 0.482809 (* 1 = 0.482809 loss)
I0314 13:49:25.037125 16588 sgd_solver.cpp:106] Iteration 47600, lr = 0.1
I0314 13:49:39.851217 16588 solver.cpp:228] Iteration 47700, loss = 0.410582
I0314 13:49:39.851708 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:49:39.851708 16588 solver.cpp:244]     Train net output #1: loss = 0.410582 (* 1 = 0.410582 loss)
I0314 13:49:39.851708 16588 sgd_solver.cpp:106] Iteration 47700, lr = 0.1
I0314 13:49:54.789551 16588 solver.cpp:228] Iteration 47800, loss = 0.395843
I0314 13:49:54.789551 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:49:54.789551 16588 solver.cpp:244]     Train net output #1: loss = 0.395843 (* 1 = 0.395843 loss)
I0314 13:49:54.789551 16588 sgd_solver.cpp:106] Iteration 47800, lr = 0.1
I0314 13:50:09.760659 16588 solver.cpp:228] Iteration 47900, loss = 0.345331
I0314 13:50:09.761158 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:50:09.761158 16588 solver.cpp:244]     Train net output #1: loss = 0.34533 (* 1 = 0.34533 loss)
I0314 13:50:09.761158 16588 sgd_solver.cpp:106] Iteration 47900, lr = 0.1
I0314 13:50:24.558307 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_48000.caffemodel
I0314 13:50:24.596304 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_48000.solverstate
I0314 13:50:24.602804 16588 solver.cpp:337] Iteration 48000, Testing net (#0)
I0314 13:50:24.602804 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:50:29.985883 16588 solver.cpp:404]     Test net output #0: accuracy = 0.707
I0314 13:50:29.985883 16588 solver.cpp:404]     Test net output #1: loss = 0.939345 (* 1 = 0.939345 loss)
I0314 13:50:30.036900 16588 solver.cpp:228] Iteration 48000, loss = 0.440091
I0314 13:50:30.037400 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:50:30.037400 16588 solver.cpp:244]     Train net output #1: loss = 0.440091 (* 1 = 0.440091 loss)
I0314 13:50:30.037400 16588 sgd_solver.cpp:106] Iteration 48000, lr = 0.1
I0314 13:50:44.565016 16588 solver.cpp:228] Iteration 48100, loss = 0.422029
I0314 13:50:44.565516 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:50:44.565516 16588 solver.cpp:244]     Train net output #1: loss = 0.422029 (* 1 = 0.422029 loss)
I0314 13:50:44.565516 16588 sgd_solver.cpp:106] Iteration 48100, lr = 0.1
I0314 13:50:59.397953 16588 solver.cpp:228] Iteration 48200, loss = 0.408272
I0314 13:50:59.398452 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:50:59.398452 16588 solver.cpp:244]     Train net output #1: loss = 0.408272 (* 1 = 0.408272 loss)
I0314 13:50:59.398452 16588 sgd_solver.cpp:106] Iteration 48200, lr = 0.1
I0314 13:51:14.354545 16588 solver.cpp:228] Iteration 48300, loss = 0.346874
I0314 13:51:14.355046 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0314 13:51:14.355046 16588 solver.cpp:244]     Train net output #1: loss = 0.346874 (* 1 = 0.346874 loss)
I0314 13:51:14.355046 16588 sgd_solver.cpp:106] Iteration 48300, lr = 0.1
I0314 13:51:29.503183 16588 solver.cpp:228] Iteration 48400, loss = 0.363242
I0314 13:51:29.503183 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:51:29.503183 16588 solver.cpp:244]     Train net output #1: loss = 0.363242 (* 1 = 0.363242 loss)
I0314 13:51:29.503183 16588 sgd_solver.cpp:106] Iteration 48400, lr = 0.1
I0314 13:51:44.529816 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_48500.caffemodel
I0314 13:51:44.564316 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_48500.solverstate
I0314 13:51:44.570816 16588 solver.cpp:337] Iteration 48500, Testing net (#0)
I0314 13:51:44.570816 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:51:49.861850 16588 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0314 13:51:49.861850 16588 solver.cpp:404]     Test net output #1: loss = 0.747582 (* 1 = 0.747582 loss)
I0314 13:51:49.902845 16588 solver.cpp:228] Iteration 48500, loss = 0.338422
I0314 13:51:49.902845 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:51:49.902845 16588 solver.cpp:244]     Train net output #1: loss = 0.338422 (* 1 = 0.338422 loss)
I0314 13:51:49.902845 16588 sgd_solver.cpp:106] Iteration 48500, lr = 0.1
I0314 13:52:04.767689 16588 solver.cpp:228] Iteration 48600, loss = 0.468095
I0314 13:52:04.767689 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0314 13:52:04.767689 16588 solver.cpp:244]     Train net output #1: loss = 0.468095 (* 1 = 0.468095 loss)
I0314 13:52:04.767689 16588 sgd_solver.cpp:106] Iteration 48600, lr = 0.1
I0314 13:52:19.507480 16588 solver.cpp:228] Iteration 48700, loss = 0.574918
I0314 13:52:19.507480 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0314 13:52:19.507480 16588 solver.cpp:244]     Train net output #1: loss = 0.574918 (* 1 = 0.574918 loss)
I0314 13:52:19.507480 16588 sgd_solver.cpp:106] Iteration 48700, lr = 0.1
I0314 13:52:34.251799 16588 solver.cpp:228] Iteration 48800, loss = 0.486757
I0314 13:52:34.251799 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0314 13:52:34.251799 16588 solver.cpp:244]     Train net output #1: loss = 0.486757 (* 1 = 0.486757 loss)
I0314 13:52:34.251799 16588 sgd_solver.cpp:106] Iteration 48800, lr = 0.1
I0314 13:52:49.225252 16588 solver.cpp:228] Iteration 48900, loss = 0.340675
I0314 13:52:49.225252 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:52:49.225754 16588 solver.cpp:244]     Train net output #1: loss = 0.340674 (* 1 = 0.340674 loss)
I0314 13:52:49.225754 16588 sgd_solver.cpp:106] Iteration 48900, lr = 0.1
I0314 13:53:04.130023 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_49000.caffemodel
I0314 13:53:04.168006 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_49000.solverstate
I0314 13:53:04.174507 16588 solver.cpp:337] Iteration 49000, Testing net (#0)
I0314 13:53:04.174507 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:53:09.133021 16588 solver.cpp:404]     Test net output #0: accuracy = 0.5203
I0314 13:53:09.133021 16588 solver.cpp:404]     Test net output #1: loss = 1.67448 (* 1 = 1.67448 loss)
I0314 13:53:09.209507 16588 solver.cpp:228] Iteration 49000, loss = 0.374302
I0314 13:53:09.209507 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:53:09.209507 16588 solver.cpp:244]     Train net output #1: loss = 0.374302 (* 1 = 0.374302 loss)
I0314 13:53:09.209507 16588 sgd_solver.cpp:106] Iteration 49000, lr = 0.1
I0314 13:53:23.381219 16588 solver.cpp:228] Iteration 49100, loss = 0.437813
I0314 13:53:23.381719 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:53:23.381719 16588 solver.cpp:244]     Train net output #1: loss = 0.437813 (* 1 = 0.437813 loss)
I0314 13:53:23.381719 16588 sgd_solver.cpp:106] Iteration 49100, lr = 0.1
I0314 13:53:38.441732 16588 solver.cpp:228] Iteration 49200, loss = 0.465727
I0314 13:53:38.441732 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0314 13:53:38.441732 16588 solver.cpp:244]     Train net output #1: loss = 0.465727 (* 1 = 0.465727 loss)
I0314 13:53:38.441732 16588 sgd_solver.cpp:106] Iteration 49200, lr = 0.1
I0314 13:53:53.444540 16588 solver.cpp:228] Iteration 49300, loss = 0.372538
I0314 13:53:53.445055 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0314 13:53:53.445055 16588 solver.cpp:244]     Train net output #1: loss = 0.372538 (* 1 = 0.372538 loss)
I0314 13:53:53.445055 16588 sgd_solver.cpp:106] Iteration 49300, lr = 0.1
I0314 13:54:08.184744 16588 solver.cpp:228] Iteration 49400, loss = 0.312682
I0314 13:54:08.184744 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:54:08.184744 16588 solver.cpp:244]     Train net output #1: loss = 0.312682 (* 1 = 0.312682 loss)
I0314 13:54:08.184744 16588 sgd_solver.cpp:106] Iteration 49400, lr = 0.1
I0314 13:54:22.846560 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_49500.caffemodel
I0314 13:54:22.885576 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_49500.solverstate
I0314 13:54:22.892065 16588 solver.cpp:337] Iteration 49500, Testing net (#0)
I0314 13:54:22.892065 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:54:27.952950 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7104
I0314 13:54:27.952950 16588 solver.cpp:404]     Test net output #1: loss = 0.909277 (* 1 = 0.909277 loss)
I0314 13:54:27.992947 16588 solver.cpp:228] Iteration 49500, loss = 0.298761
I0314 13:54:27.993449 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:54:27.993449 16588 solver.cpp:244]     Train net output #1: loss = 0.298761 (* 1 = 0.298761 loss)
I0314 13:54:27.993449 16588 sgd_solver.cpp:106] Iteration 49500, lr = 0.1
I0314 13:54:42.543543 16588 solver.cpp:228] Iteration 49600, loss = 0.500375
I0314 13:54:42.543543 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0314 13:54:42.543543 16588 solver.cpp:244]     Train net output #1: loss = 0.500375 (* 1 = 0.500375 loss)
I0314 13:54:42.543543 16588 sgd_solver.cpp:106] Iteration 49600, lr = 0.1
I0314 13:54:57.197540 16588 solver.cpp:228] Iteration 49700, loss = 0.339334
I0314 13:54:57.197540 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0314 13:54:57.197540 16588 solver.cpp:244]     Train net output #1: loss = 0.339334 (* 1 = 0.339334 loss)
I0314 13:54:57.197540 16588 sgd_solver.cpp:106] Iteration 49700, lr = 0.1
I0314 13:55:11.973556 16588 solver.cpp:228] Iteration 49800, loss = 0.47627
I0314 13:55:11.973556 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0314 13:55:11.973556 16588 solver.cpp:244]     Train net output #1: loss = 0.47627 (* 1 = 0.47627 loss)
I0314 13:55:11.973556 16588 sgd_solver.cpp:106] Iteration 49800, lr = 0.1
I0314 13:55:26.740561 16588 solver.cpp:228] Iteration 49900, loss = 0.365499
I0314 13:55:26.740561 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:55:26.740561 16588 solver.cpp:244]     Train net output #1: loss = 0.365499 (* 1 = 0.365499 loss)
I0314 13:55:26.740561 16588 sgd_solver.cpp:106] Iteration 49900, lr = 0.1
I0314 13:55:41.240186 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_50000.caffemodel
I0314 13:55:41.280189 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_50000.solverstate
I0314 13:55:41.286690 16588 solver.cpp:337] Iteration 50000, Testing net (#0)
I0314 13:55:41.286690 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:55:46.055207 16588 solver.cpp:404]     Test net output #0: accuracy = 0.7386
I0314 13:55:46.055707 16588 solver.cpp:404]     Test net output #1: loss = 0.807534 (* 1 = 0.807534 loss)
I0314 13:55:46.106686 16588 solver.cpp:228] Iteration 50000, loss = 0.297292
I0314 13:55:46.107187 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0314 13:55:46.107187 16588 solver.cpp:244]     Train net output #1: loss = 0.297292 (* 1 = 0.297292 loss)
I0314 13:55:46.107187 16588 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I0314 13:55:46.107187 16588 sgd_solver.cpp:106] Iteration 50000, lr = 0.01
I0314 13:56:00.269539 16588 solver.cpp:228] Iteration 50100, loss = 0.27459
I0314 13:56:00.269539 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:56:00.269539 16588 solver.cpp:244]     Train net output #1: loss = 0.27459 (* 1 = 0.27459 loss)
I0314 13:56:00.269539 16588 sgd_solver.cpp:106] Iteration 50100, lr = 0.01
I0314 13:56:14.898602 16588 solver.cpp:228] Iteration 50200, loss = 0.364915
I0314 13:56:14.898602 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0314 13:56:14.898602 16588 solver.cpp:244]     Train net output #1: loss = 0.364915 (* 1 = 0.364915 loss)
I0314 13:56:14.898602 16588 sgd_solver.cpp:106] Iteration 50200, lr = 0.01
I0314 13:56:29.530616 16588 solver.cpp:228] Iteration 50300, loss = 0.201677
I0314 13:56:29.530616 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 13:56:29.530616 16588 solver.cpp:244]     Train net output #1: loss = 0.201677 (* 1 = 0.201677 loss)
I0314 13:56:29.530616 16588 sgd_solver.cpp:106] Iteration 50300, lr = 0.01
I0314 13:56:44.139268 16588 solver.cpp:228] Iteration 50400, loss = 0.117148
I0314 13:56:44.139268 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 13:56:44.139268 16588 solver.cpp:244]     Train net output #1: loss = 0.117148 (* 1 = 0.117148 loss)
I0314 13:56:44.139268 16588 sgd_solver.cpp:106] Iteration 50400, lr = 0.01
I0314 13:56:58.601146 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_50500.caffemodel
I0314 13:56:58.638648 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_50500.solverstate
I0314 13:56:58.645148 16588 solver.cpp:337] Iteration 50500, Testing net (#0)
I0314 13:56:58.645148 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:57:03.701198 16588 solver.cpp:404]     Test net output #0: accuracy = 0.88
I0314 13:57:03.701198 16588 solver.cpp:404]     Test net output #1: loss = 0.350169 (* 1 = 0.350169 loss)
I0314 13:57:03.749198 16588 solver.cpp:228] Iteration 50500, loss = 0.20461
I0314 13:57:03.749698 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0314 13:57:03.749698 16588 solver.cpp:244]     Train net output #1: loss = 0.204609 (* 1 = 0.204609 loss)
I0314 13:57:03.749698 16588 sgd_solver.cpp:106] Iteration 50500, lr = 0.01
I0314 13:57:17.994117 16588 solver.cpp:228] Iteration 50600, loss = 0.209389
I0314 13:57:17.994616 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0314 13:57:17.994616 16588 solver.cpp:244]     Train net output #1: loss = 0.209389 (* 1 = 0.209389 loss)
I0314 13:57:17.994616 16588 sgd_solver.cpp:106] Iteration 50600, lr = 0.01
I0314 13:57:33.155814 16588 solver.cpp:228] Iteration 50700, loss = 0.277103
I0314 13:57:33.155814 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0314 13:57:33.155814 16588 solver.cpp:244]     Train net output #1: loss = 0.277103 (* 1 = 0.277103 loss)
I0314 13:57:33.155814 16588 sgd_solver.cpp:106] Iteration 50700, lr = 0.01
I0314 13:57:47.761713 16588 solver.cpp:228] Iteration 50800, loss = 0.126568
I0314 13:57:47.761713 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 13:57:47.761713 16588 solver.cpp:244]     Train net output #1: loss = 0.126568 (* 1 = 0.126568 loss)
I0314 13:57:47.761713 16588 sgd_solver.cpp:106] Iteration 50800, lr = 0.01
I0314 13:58:02.456492 16588 solver.cpp:228] Iteration 50900, loss = 0.0946866
I0314 13:58:02.456492 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 13:58:02.456492 16588 solver.cpp:244]     Train net output #1: loss = 0.0946864 (* 1 = 0.0946864 loss)
I0314 13:58:02.456492 16588 sgd_solver.cpp:106] Iteration 50900, lr = 0.01
I0314 13:58:17.311525 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_51000.caffemodel
I0314 13:58:17.350523 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_51000.solverstate
I0314 13:58:17.360523 16588 solver.cpp:337] Iteration 51000, Testing net (#0)
I0314 13:58:17.360523 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:58:22.581677 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8848
I0314 13:58:22.582176 16588 solver.cpp:404]     Test net output #1: loss = 0.339646 (* 1 = 0.339646 loss)
I0314 13:58:22.625663 16588 solver.cpp:228] Iteration 51000, loss = 0.194929
I0314 13:58:22.625663 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 13:58:22.625663 16588 solver.cpp:244]     Train net output #1: loss = 0.194929 (* 1 = 0.194929 loss)
I0314 13:58:22.625663 16588 sgd_solver.cpp:106] Iteration 51000, lr = 0.01
I0314 13:58:36.898900 16588 solver.cpp:228] Iteration 51100, loss = 0.201287
I0314 13:58:36.898900 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0314 13:58:36.899399 16588 solver.cpp:244]     Train net output #1: loss = 0.201286 (* 1 = 0.201286 loss)
I0314 13:58:36.899399 16588 sgd_solver.cpp:106] Iteration 51100, lr = 0.01
I0314 13:58:51.815740 16588 solver.cpp:228] Iteration 51200, loss = 0.252609
I0314 13:58:51.815740 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0314 13:58:51.815740 16588 solver.cpp:244]     Train net output #1: loss = 0.252608 (* 1 = 0.252608 loss)
I0314 13:58:51.815740 16588 sgd_solver.cpp:106] Iteration 51200, lr = 0.01
I0314 13:59:06.608898 16588 solver.cpp:228] Iteration 51300, loss = 0.137495
I0314 13:59:06.609398 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 13:59:06.609398 16588 solver.cpp:244]     Train net output #1: loss = 0.137495 (* 1 = 0.137495 loss)
I0314 13:59:06.609398 16588 sgd_solver.cpp:106] Iteration 51300, lr = 0.01
I0314 13:59:21.407889 16588 solver.cpp:228] Iteration 51400, loss = 0.0916213
I0314 13:59:21.407889 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 13:59:21.407889 16588 solver.cpp:244]     Train net output #1: loss = 0.0916212 (* 1 = 0.0916212 loss)
I0314 13:59:21.407889 16588 sgd_solver.cpp:106] Iteration 51400, lr = 0.01
I0314 13:59:36.115125 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_51500.caffemodel
I0314 13:59:36.153125 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_51500.solverstate
I0314 13:59:36.160624 16588 solver.cpp:337] Iteration 51500, Testing net (#0)
I0314 13:59:36.160624 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 13:59:41.238165 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8848
I0314 13:59:41.238165 16588 solver.cpp:404]     Test net output #1: loss = 0.340949 (* 1 = 0.340949 loss)
I0314 13:59:41.308158 16588 solver.cpp:228] Iteration 51500, loss = 0.146237
I0314 13:59:41.308158 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 13:59:41.308158 16588 solver.cpp:244]     Train net output #1: loss = 0.146237 (* 1 = 0.146237 loss)
I0314 13:59:41.308158 16588 sgd_solver.cpp:106] Iteration 51500, lr = 0.01
I0314 13:59:55.660837 16588 solver.cpp:228] Iteration 51600, loss = 0.130283
I0314 13:59:55.661337 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 13:59:55.661337 16588 solver.cpp:244]     Train net output #1: loss = 0.130283 (* 1 = 0.130283 loss)
I0314 13:59:55.661337 16588 sgd_solver.cpp:106] Iteration 51600, lr = 0.01
I0314 14:00:10.608187 16588 solver.cpp:228] Iteration 51700, loss = 0.20779
I0314 14:00:10.608187 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 14:00:10.608687 16588 solver.cpp:244]     Train net output #1: loss = 0.20779 (* 1 = 0.20779 loss)
I0314 14:00:10.608687 16588 sgd_solver.cpp:106] Iteration 51700, lr = 0.01
I0314 14:00:25.517874 16588 solver.cpp:228] Iteration 51800, loss = 0.11698
I0314 14:00:25.517874 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:00:25.517874 16588 solver.cpp:244]     Train net output #1: loss = 0.11698 (* 1 = 0.11698 loss)
I0314 14:00:25.517874 16588 sgd_solver.cpp:106] Iteration 51800, lr = 0.01
I0314 14:00:40.290009 16588 solver.cpp:228] Iteration 51900, loss = 0.0665967
I0314 14:00:40.290009 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:00:40.290009 16588 solver.cpp:244]     Train net output #1: loss = 0.0665965 (* 1 = 0.0665965 loss)
I0314 14:00:40.290009 16588 sgd_solver.cpp:106] Iteration 51900, lr = 0.01
I0314 14:00:55.232808 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_52000.caffemodel
I0314 14:00:55.254808 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_52000.solverstate
I0314 14:00:55.261809 16588 solver.cpp:337] Iteration 52000, Testing net (#0)
I0314 14:00:55.261809 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:01:00.604256 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8865
I0314 14:01:00.604256 16588 solver.cpp:404]     Test net output #1: loss = 0.340061 (* 1 = 0.340061 loss)
I0314 14:01:00.647759 16588 solver.cpp:228] Iteration 52000, loss = 0.1221
I0314 14:01:00.647759 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:01:00.647759 16588 solver.cpp:244]     Train net output #1: loss = 0.122099 (* 1 = 0.122099 loss)
I0314 14:01:00.647759 16588 sgd_solver.cpp:106] Iteration 52000, lr = 0.01
I0314 14:01:14.899421 16588 solver.cpp:228] Iteration 52100, loss = 0.129684
I0314 14:01:14.899421 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 14:01:14.899421 16588 solver.cpp:244]     Train net output #1: loss = 0.129684 (* 1 = 0.129684 loss)
I0314 14:01:14.899421 16588 sgd_solver.cpp:106] Iteration 52100, lr = 0.01
I0314 14:01:29.713610 16588 solver.cpp:228] Iteration 52200, loss = 0.18519
I0314 14:01:29.713610 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 14:01:29.713610 16588 solver.cpp:244]     Train net output #1: loss = 0.18519 (* 1 = 0.18519 loss)
I0314 14:01:29.713610 16588 sgd_solver.cpp:106] Iteration 52200, lr = 0.01
I0314 14:01:44.371090 16588 solver.cpp:228] Iteration 52300, loss = 0.127918
I0314 14:01:44.371589 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:01:44.371589 16588 solver.cpp:244]     Train net output #1: loss = 0.127918 (* 1 = 0.127918 loss)
I0314 14:01:44.371589 16588 sgd_solver.cpp:106] Iteration 52300, lr = 0.01
I0314 14:01:58.356186 16588 solver.cpp:228] Iteration 52400, loss = 0.0613878
I0314 14:01:58.356186 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:01:58.356186 16588 solver.cpp:244]     Train net output #1: loss = 0.0613877 (* 1 = 0.0613877 loss)
I0314 14:01:58.356186 16588 sgd_solver.cpp:106] Iteration 52400, lr = 0.01
I0314 14:02:12.081632 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_52500.caffemodel
I0314 14:02:12.122130 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_52500.solverstate
I0314 14:02:12.128630 16588 solver.cpp:337] Iteration 52500, Testing net (#0)
I0314 14:02:12.129130 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:02:16.796190 16588 solver.cpp:404]     Test net output #0: accuracy = 0.887
I0314 14:02:16.796190 16588 solver.cpp:404]     Test net output #1: loss = 0.34989 (* 1 = 0.34989 loss)
I0314 14:02:16.829690 16588 solver.cpp:228] Iteration 52500, loss = 0.147732
I0314 14:02:16.829690 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0314 14:02:16.829690 16588 solver.cpp:244]     Train net output #1: loss = 0.147732 (* 1 = 0.147732 loss)
I0314 14:02:16.829690 16588 sgd_solver.cpp:106] Iteration 52500, lr = 0.01
I0314 14:02:30.929703 16588 solver.cpp:228] Iteration 52600, loss = 0.171682
I0314 14:02:30.929703 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:02:30.929703 16588 solver.cpp:244]     Train net output #1: loss = 0.171682 (* 1 = 0.171682 loss)
I0314 14:02:30.930202 16588 sgd_solver.cpp:106] Iteration 52600, lr = 0.01
I0314 14:02:45.863600 16588 solver.cpp:228] Iteration 52700, loss = 0.153233
I0314 14:02:45.863600 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 14:02:45.863600 16588 solver.cpp:244]     Train net output #1: loss = 0.153233 (* 1 = 0.153233 loss)
I0314 14:02:45.863600 16588 sgd_solver.cpp:106] Iteration 52700, lr = 0.01
I0314 14:03:00.796649 16588 solver.cpp:228] Iteration 52800, loss = 0.0821454
I0314 14:03:00.796649 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:03:00.796649 16588 solver.cpp:244]     Train net output #1: loss = 0.0821454 (* 1 = 0.0821454 loss)
I0314 14:03:00.796649 16588 sgd_solver.cpp:106] Iteration 52800, lr = 0.01
I0314 14:03:15.797540 16588 solver.cpp:228] Iteration 52900, loss = 0.0569807
I0314 14:03:15.797540 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:03:15.797540 16588 solver.cpp:244]     Train net output #1: loss = 0.0569806 (* 1 = 0.0569806 loss)
I0314 14:03:15.797540 16588 sgd_solver.cpp:106] Iteration 52900, lr = 0.01
I0314 14:03:30.657158 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_53000.caffemodel
I0314 14:03:30.676139 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_53000.solverstate
I0314 14:03:30.682157 16588 solver.cpp:337] Iteration 53000, Testing net (#0)
I0314 14:03:30.682157 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:03:35.662441 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8898
I0314 14:03:35.662441 16588 solver.cpp:404]     Test net output #1: loss = 0.350138 (* 1 = 0.350138 loss)
I0314 14:03:35.697954 16588 solver.cpp:228] Iteration 53000, loss = 0.0936295
I0314 14:03:35.697954 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:03:35.697954 16588 solver.cpp:244]     Train net output #1: loss = 0.0936294 (* 1 = 0.0936294 loss)
I0314 14:03:35.697954 16588 sgd_solver.cpp:106] Iteration 53000, lr = 0.01
I0314 14:03:49.934015 16588 solver.cpp:228] Iteration 53100, loss = 0.139486
I0314 14:03:49.934015 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:03:49.934015 16588 solver.cpp:244]     Train net output #1: loss = 0.139486 (* 1 = 0.139486 loss)
I0314 14:03:49.934015 16588 sgd_solver.cpp:106] Iteration 53100, lr = 0.01
I0314 14:04:04.490931 16588 solver.cpp:228] Iteration 53200, loss = 0.168183
I0314 14:04:04.491430 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:04:04.491430 16588 solver.cpp:244]     Train net output #1: loss = 0.168182 (* 1 = 0.168182 loss)
I0314 14:04:04.491430 16588 sgd_solver.cpp:106] Iteration 53200, lr = 0.01
I0314 14:04:19.063215 16588 solver.cpp:228] Iteration 53300, loss = 0.0764146
I0314 14:04:19.063215 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:04:19.063215 16588 solver.cpp:244]     Train net output #1: loss = 0.0764145 (* 1 = 0.0764145 loss)
I0314 14:04:19.063215 16588 sgd_solver.cpp:106] Iteration 53300, lr = 0.01
I0314 14:04:33.568650 16588 solver.cpp:228] Iteration 53400, loss = 0.0448834
I0314 14:04:33.568650 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:04:33.568650 16588 solver.cpp:244]     Train net output #1: loss = 0.0448833 (* 1 = 0.0448833 loss)
I0314 14:04:33.568650 16588 sgd_solver.cpp:106] Iteration 53400, lr = 0.01
I0314 14:04:48.021606 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_53500.caffemodel
I0314 14:04:48.063107 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_53500.solverstate
I0314 14:04:48.070107 16588 solver.cpp:337] Iteration 53500, Testing net (#0)
I0314 14:04:48.070107 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:04:52.963814 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8863
I0314 14:04:52.963814 16588 solver.cpp:404]     Test net output #1: loss = 0.357491 (* 1 = 0.357491 loss)
I0314 14:04:53.020310 16588 solver.cpp:228] Iteration 53500, loss = 0.0844292
I0314 14:04:53.020310 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:04:53.020310 16588 solver.cpp:244]     Train net output #1: loss = 0.0844292 (* 1 = 0.0844292 loss)
I0314 14:04:53.020310 16588 sgd_solver.cpp:106] Iteration 53500, lr = 0.01
I0314 14:05:07.106631 16588 solver.cpp:228] Iteration 53600, loss = 0.121685
I0314 14:05:07.106631 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:05:07.106631 16588 solver.cpp:244]     Train net output #1: loss = 0.121685 (* 1 = 0.121685 loss)
I0314 14:05:07.106631 16588 sgd_solver.cpp:106] Iteration 53600, lr = 0.01
I0314 14:05:21.657248 16588 solver.cpp:228] Iteration 53700, loss = 0.148673
I0314 14:05:21.657248 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 14:05:21.657248 16588 solver.cpp:244]     Train net output #1: loss = 0.148673 (* 1 = 0.148673 loss)
I0314 14:05:21.657248 16588 sgd_solver.cpp:106] Iteration 53700, lr = 0.01
I0314 14:05:36.180150 16588 solver.cpp:228] Iteration 53800, loss = 0.113494
I0314 14:05:36.180150 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:05:36.180150 16588 solver.cpp:244]     Train net output #1: loss = 0.113494 (* 1 = 0.113494 loss)
I0314 14:05:36.180150 16588 sgd_solver.cpp:106] Iteration 53800, lr = 0.01
I0314 14:05:50.695447 16588 solver.cpp:228] Iteration 53900, loss = 0.036585
I0314 14:05:50.695447 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:05:50.695447 16588 solver.cpp:244]     Train net output #1: loss = 0.036585 (* 1 = 0.036585 loss)
I0314 14:05:50.695447 16588 sgd_solver.cpp:106] Iteration 53900, lr = 0.01
I0314 14:06:05.163233 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_54000.caffemodel
I0314 14:06:05.183230 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_54000.solverstate
I0314 14:06:05.189230 16588 solver.cpp:337] Iteration 54000, Testing net (#0)
I0314 14:06:05.189230 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:06:09.969566 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8896
I0314 14:06:09.969566 16588 solver.cpp:404]     Test net output #1: loss = 0.364691 (* 1 = 0.364691 loss)
I0314 14:06:10.050082 16588 solver.cpp:228] Iteration 54000, loss = 0.0977239
I0314 14:06:10.050082 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:06:10.050082 16588 solver.cpp:244]     Train net output #1: loss = 0.0977239 (* 1 = 0.0977239 loss)
I0314 14:06:10.050082 16588 sgd_solver.cpp:106] Iteration 54000, lr = 0.01
I0314 14:06:24.162698 16588 solver.cpp:228] Iteration 54100, loss = 0.0781674
I0314 14:06:24.162698 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:06:24.162698 16588 solver.cpp:244]     Train net output #1: loss = 0.0781674 (* 1 = 0.0781674 loss)
I0314 14:06:24.162698 16588 sgd_solver.cpp:106] Iteration 54100, lr = 0.01
I0314 14:06:38.660310 16588 solver.cpp:228] Iteration 54200, loss = 0.116031
I0314 14:06:38.660310 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:06:38.660310 16588 solver.cpp:244]     Train net output #1: loss = 0.116031 (* 1 = 0.116031 loss)
I0314 14:06:38.660310 16588 sgd_solver.cpp:106] Iteration 54200, lr = 0.01
I0314 14:06:53.220129 16588 solver.cpp:228] Iteration 54300, loss = 0.0741054
I0314 14:06:53.220129 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:06:53.220129 16588 solver.cpp:244]     Train net output #1: loss = 0.0741054 (* 1 = 0.0741054 loss)
I0314 14:06:53.220129 16588 sgd_solver.cpp:106] Iteration 54300, lr = 0.01
I0314 14:07:07.794661 16588 solver.cpp:228] Iteration 54400, loss = 0.0390704
I0314 14:07:07.794661 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:07:07.794661 16588 solver.cpp:244]     Train net output #1: loss = 0.0390704 (* 1 = 0.0390704 loss)
I0314 14:07:07.794661 16588 sgd_solver.cpp:106] Iteration 54400, lr = 0.01
I0314 14:07:22.283293 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_54500.caffemodel
I0314 14:07:22.321794 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_54500.solverstate
I0314 14:07:22.328294 16588 solver.cpp:337] Iteration 54500, Testing net (#0)
I0314 14:07:22.328294 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:07:27.156481 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8884
I0314 14:07:27.156975 16588 solver.cpp:404]     Test net output #1: loss = 0.378308 (* 1 = 0.378308 loss)
I0314 14:07:27.233491 16588 solver.cpp:228] Iteration 54500, loss = 0.067753
I0314 14:07:27.233491 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:07:27.233491 16588 solver.cpp:244]     Train net output #1: loss = 0.067753 (* 1 = 0.067753 loss)
I0314 14:07:27.233491 16588 sgd_solver.cpp:106] Iteration 54500, lr = 0.01
I0314 14:07:41.377010 16588 solver.cpp:228] Iteration 54600, loss = 0.0619321
I0314 14:07:41.377010 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:07:41.377010 16588 solver.cpp:244]     Train net output #1: loss = 0.0619321 (* 1 = 0.0619321 loss)
I0314 14:07:41.377010 16588 sgd_solver.cpp:106] Iteration 54600, lr = 0.01
I0314 14:07:55.929493 16588 solver.cpp:228] Iteration 54700, loss = 0.110975
I0314 14:07:55.929493 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:07:55.929493 16588 solver.cpp:244]     Train net output #1: loss = 0.110975 (* 1 = 0.110975 loss)
I0314 14:07:55.929493 16588 sgd_solver.cpp:106] Iteration 54700, lr = 0.01
I0314 14:08:10.404703 16588 solver.cpp:228] Iteration 54800, loss = 0.0687156
I0314 14:08:10.404703 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:08:10.404703 16588 solver.cpp:244]     Train net output #1: loss = 0.0687156 (* 1 = 0.0687156 loss)
I0314 14:08:10.404703 16588 sgd_solver.cpp:106] Iteration 54800, lr = 0.01
I0314 14:08:24.977073 16588 solver.cpp:228] Iteration 54900, loss = 0.0354183
I0314 14:08:24.977073 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:08:24.977073 16588 solver.cpp:244]     Train net output #1: loss = 0.0354184 (* 1 = 0.0354184 loss)
I0314 14:08:24.977073 16588 sgd_solver.cpp:106] Iteration 54900, lr = 0.01
I0314 14:08:39.438978 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_55000.caffemodel
I0314 14:08:39.478513 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_55000.solverstate
I0314 14:08:39.488612 16588 solver.cpp:337] Iteration 55000, Testing net (#0)
I0314 14:08:39.488612 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:08:44.313802 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8873
I0314 14:08:44.313802 16588 solver.cpp:404]     Test net output #1: loss = 0.387713 (* 1 = 0.387713 loss)
I0314 14:08:44.359308 16588 solver.cpp:228] Iteration 55000, loss = 0.104629
I0314 14:08:44.359308 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:08:44.359308 16588 solver.cpp:244]     Train net output #1: loss = 0.104629 (* 1 = 0.104629 loss)
I0314 14:08:44.359308 16588 sgd_solver.cpp:106] Iteration 55000, lr = 0.01
I0314 14:08:58.509702 16588 solver.cpp:228] Iteration 55100, loss = 0.0536929
I0314 14:08:58.509702 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:08:58.509702 16588 solver.cpp:244]     Train net output #1: loss = 0.053693 (* 1 = 0.053693 loss)
I0314 14:08:58.509702 16588 sgd_solver.cpp:106] Iteration 55100, lr = 0.01
I0314 14:09:13.070201 16588 solver.cpp:228] Iteration 55200, loss = 0.0741305
I0314 14:09:13.070201 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:09:13.070703 16588 solver.cpp:244]     Train net output #1: loss = 0.0741306 (* 1 = 0.0741306 loss)
I0314 14:09:13.070703 16588 sgd_solver.cpp:106] Iteration 55200, lr = 0.01
I0314 14:09:27.520663 16588 solver.cpp:228] Iteration 55300, loss = 0.0371422
I0314 14:09:27.521165 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:09:27.521165 16588 solver.cpp:244]     Train net output #1: loss = 0.0371423 (* 1 = 0.0371423 loss)
I0314 14:09:27.521165 16588 sgd_solver.cpp:106] Iteration 55300, lr = 0.01
I0314 14:09:42.033573 16588 solver.cpp:228] Iteration 55400, loss = 0.0300623
I0314 14:09:42.033573 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:09:42.033573 16588 solver.cpp:244]     Train net output #1: loss = 0.0300624 (* 1 = 0.0300624 loss)
I0314 14:09:42.033573 16588 sgd_solver.cpp:106] Iteration 55400, lr = 0.01
I0314 14:09:56.413393 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_55500.caffemodel
I0314 14:09:56.450892 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_55500.solverstate
I0314 14:09:56.457392 16588 solver.cpp:337] Iteration 55500, Testing net (#0)
I0314 14:09:56.457392 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:10:01.284152 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8842
I0314 14:10:01.284152 16588 solver.cpp:404]     Test net output #1: loss = 0.406793 (* 1 = 0.406793 loss)
I0314 14:10:01.342358 16588 solver.cpp:228] Iteration 55500, loss = 0.0515089
I0314 14:10:01.342358 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:10:01.342358 16588 solver.cpp:244]     Train net output #1: loss = 0.051509 (* 1 = 0.051509 loss)
I0314 14:10:01.342358 16588 sgd_solver.cpp:106] Iteration 55500, lr = 0.01
I0314 14:10:15.468971 16588 solver.cpp:228] Iteration 55600, loss = 0.0979013
I0314 14:10:15.468971 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:10:15.468971 16588 solver.cpp:244]     Train net output #1: loss = 0.0979014 (* 1 = 0.0979014 loss)
I0314 14:10:15.468971 16588 sgd_solver.cpp:106] Iteration 55600, lr = 0.01
I0314 14:10:30.003574 16588 solver.cpp:228] Iteration 55700, loss = 0.119305
I0314 14:10:30.003574 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:10:30.003574 16588 solver.cpp:244]     Train net output #1: loss = 0.119305 (* 1 = 0.119305 loss)
I0314 14:10:30.003574 16588 sgd_solver.cpp:106] Iteration 55700, lr = 0.01
I0314 14:10:44.541692 16588 solver.cpp:228] Iteration 55800, loss = 0.0693609
I0314 14:10:44.541692 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:10:44.541692 16588 solver.cpp:244]     Train net output #1: loss = 0.069361 (* 1 = 0.069361 loss)
I0314 14:10:44.541692 16588 sgd_solver.cpp:106] Iteration 55800, lr = 0.01
I0314 14:10:59.035024 16588 solver.cpp:228] Iteration 55900, loss = 0.0335817
I0314 14:10:59.035024 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:10:59.035024 16588 solver.cpp:244]     Train net output #1: loss = 0.0335817 (* 1 = 0.0335817 loss)
I0314 14:10:59.035024 16588 sgd_solver.cpp:106] Iteration 55900, lr = 0.01
I0314 14:11:13.542898 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_56000.caffemodel
I0314 14:11:13.581898 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_56000.solverstate
I0314 14:11:13.587882 16588 solver.cpp:337] Iteration 56000, Testing net (#0)
I0314 14:11:13.587882 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:11:18.372079 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8872
I0314 14:11:18.372079 16588 solver.cpp:404]     Test net output #1: loss = 0.403663 (* 1 = 0.403663 loss)
I0314 14:11:18.432085 16588 solver.cpp:228] Iteration 56000, loss = 0.0485533
I0314 14:11:18.432085 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:11:18.432085 16588 solver.cpp:244]     Train net output #1: loss = 0.0485533 (* 1 = 0.0485533 loss)
I0314 14:11:18.432085 16588 sgd_solver.cpp:106] Iteration 56000, lr = 0.01
I0314 14:11:32.640189 16588 solver.cpp:228] Iteration 56100, loss = 0.0499261
I0314 14:11:32.640189 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:11:32.640189 16588 solver.cpp:244]     Train net output #1: loss = 0.0499262 (* 1 = 0.0499262 loss)
I0314 14:11:32.640189 16588 sgd_solver.cpp:106] Iteration 56100, lr = 0.01
I0314 14:11:47.172520 16588 solver.cpp:228] Iteration 56200, loss = 0.0668676
I0314 14:11:47.172520 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:11:47.172520 16588 solver.cpp:244]     Train net output #1: loss = 0.0668677 (* 1 = 0.0668677 loss)
I0314 14:11:47.172520 16588 sgd_solver.cpp:106] Iteration 56200, lr = 0.01
I0314 14:12:01.704432 16588 solver.cpp:228] Iteration 56300, loss = 0.0283535
I0314 14:12:01.704432 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:12:01.704432 16588 solver.cpp:244]     Train net output #1: loss = 0.0283536 (* 1 = 0.0283536 loss)
I0314 14:12:01.704432 16588 sgd_solver.cpp:106] Iteration 56300, lr = 0.01
I0314 14:12:16.246597 16588 solver.cpp:228] Iteration 56400, loss = 0.0187425
I0314 14:12:16.246597 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:12:16.246597 16588 solver.cpp:244]     Train net output #1: loss = 0.0187426 (* 1 = 0.0187426 loss)
I0314 14:12:16.246597 16588 sgd_solver.cpp:106] Iteration 56400, lr = 0.01
I0314 14:12:30.750689 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_56500.caffemodel
I0314 14:12:30.790693 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_56500.solverstate
I0314 14:12:30.800698 16588 solver.cpp:337] Iteration 56500, Testing net (#0)
I0314 14:12:30.800698 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:12:35.543467 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8862
I0314 14:12:35.543467 16588 solver.cpp:404]     Test net output #1: loss = 0.415207 (* 1 = 0.415207 loss)
I0314 14:12:35.623472 16588 solver.cpp:228] Iteration 56500, loss = 0.0575162
I0314 14:12:35.623472 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:12:35.623472 16588 solver.cpp:244]     Train net output #1: loss = 0.0575163 (* 1 = 0.0575163 loss)
I0314 14:12:35.623472 16588 sgd_solver.cpp:106] Iteration 56500, lr = 0.01
I0314 14:12:49.646385 16588 solver.cpp:228] Iteration 56600, loss = 0.0281276
I0314 14:12:49.646885 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:12:49.646885 16588 solver.cpp:244]     Train net output #1: loss = 0.0281277 (* 1 = 0.0281277 loss)
I0314 14:12:49.646885 16588 sgd_solver.cpp:106] Iteration 56600, lr = 0.01
I0314 14:13:04.209000 16588 solver.cpp:228] Iteration 56700, loss = 0.068213
I0314 14:13:04.209000 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:13:04.209000 16588 solver.cpp:244]     Train net output #1: loss = 0.0682131 (* 1 = 0.0682131 loss)
I0314 14:13:04.209000 16588 sgd_solver.cpp:106] Iteration 56700, lr = 0.01
I0314 14:13:18.741982 16588 solver.cpp:228] Iteration 56800, loss = 0.0350252
I0314 14:13:18.741982 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:13:18.741982 16588 solver.cpp:244]     Train net output #1: loss = 0.0350253 (* 1 = 0.0350253 loss)
I0314 14:13:18.741982 16588 sgd_solver.cpp:106] Iteration 56800, lr = 0.01
I0314 14:13:33.324295 16588 solver.cpp:228] Iteration 56900, loss = 0.0237742
I0314 14:13:33.324295 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:13:33.324295 16588 solver.cpp:244]     Train net output #1: loss = 0.0237743 (* 1 = 0.0237743 loss)
I0314 14:13:33.324295 16588 sgd_solver.cpp:106] Iteration 56900, lr = 0.01
I0314 14:13:47.742756 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_57000.caffemodel
I0314 14:13:47.780758 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_57000.solverstate
I0314 14:13:47.787267 16588 solver.cpp:337] Iteration 57000, Testing net (#0)
I0314 14:13:47.787267 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:13:52.580644 16588 solver.cpp:404]     Test net output #0: accuracy = 0.882
I0314 14:13:52.580644 16588 solver.cpp:404]     Test net output #1: loss = 0.426281 (* 1 = 0.426281 loss)
I0314 14:13:52.641149 16588 solver.cpp:228] Iteration 57000, loss = 0.0643791
I0314 14:13:52.641149 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:13:52.641149 16588 solver.cpp:244]     Train net output #1: loss = 0.0643792 (* 1 = 0.0643792 loss)
I0314 14:13:52.641149 16588 sgd_solver.cpp:106] Iteration 57000, lr = 0.01
I0314 14:14:06.799923 16588 solver.cpp:228] Iteration 57100, loss = 0.0758908
I0314 14:14:06.799923 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:14:06.799923 16588 solver.cpp:244]     Train net output #1: loss = 0.0758909 (* 1 = 0.0758909 loss)
I0314 14:14:06.799923 16588 sgd_solver.cpp:106] Iteration 57100, lr = 0.01
I0314 14:14:21.248044 16588 solver.cpp:228] Iteration 57200, loss = 0.0445662
I0314 14:14:21.248044 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:14:21.248044 16588 solver.cpp:244]     Train net output #1: loss = 0.0445663 (* 1 = 0.0445663 loss)
I0314 14:14:21.248044 16588 sgd_solver.cpp:106] Iteration 57200, lr = 0.01
I0314 14:14:35.723521 16588 solver.cpp:228] Iteration 57300, loss = 0.0456655
I0314 14:14:35.723521 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:14:35.723521 16588 solver.cpp:244]     Train net output #1: loss = 0.0456655 (* 1 = 0.0456655 loss)
I0314 14:14:35.723521 16588 sgd_solver.cpp:106] Iteration 57300, lr = 0.01
I0314 14:14:50.206416 16588 solver.cpp:228] Iteration 57400, loss = 0.0141361
I0314 14:14:50.206920 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:14:50.206920 16588 solver.cpp:244]     Train net output #1: loss = 0.0141362 (* 1 = 0.0141362 loss)
I0314 14:14:50.206920 16588 sgd_solver.cpp:106] Iteration 57400, lr = 0.01
I0314 14:15:04.623369 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_57500.caffemodel
I0314 14:15:04.663873 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_57500.solverstate
I0314 14:15:04.673877 16588 solver.cpp:337] Iteration 57500, Testing net (#0)
I0314 14:15:04.673877 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:15:09.495151 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8729
I0314 14:15:09.495151 16588 solver.cpp:404]     Test net output #1: loss = 0.449258 (* 1 = 0.449258 loss)
I0314 14:15:09.545158 16588 solver.cpp:228] Iteration 57500, loss = 0.0505899
I0314 14:15:09.545158 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:15:09.545158 16588 solver.cpp:244]     Train net output #1: loss = 0.0505899 (* 1 = 0.0505899 loss)
I0314 14:15:09.545158 16588 sgd_solver.cpp:106] Iteration 57500, lr = 0.01
I0314 14:15:23.645151 16588 solver.cpp:228] Iteration 57600, loss = 0.0712251
I0314 14:15:23.645151 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:15:23.645151 16588 solver.cpp:244]     Train net output #1: loss = 0.0712252 (* 1 = 0.0712252 loss)
I0314 14:15:23.645151 16588 sgd_solver.cpp:106] Iteration 57600, lr = 0.01
I0314 14:15:38.118665 16588 solver.cpp:228] Iteration 57700, loss = 0.0740761
I0314 14:15:38.119165 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:15:38.119165 16588 solver.cpp:244]     Train net output #1: loss = 0.0740762 (* 1 = 0.0740762 loss)
I0314 14:15:38.119165 16588 sgd_solver.cpp:106] Iteration 57700, lr = 0.01
I0314 14:15:52.685313 16588 solver.cpp:228] Iteration 57800, loss = 0.0382199
I0314 14:15:52.685313 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:15:52.685313 16588 solver.cpp:244]     Train net output #1: loss = 0.03822 (* 1 = 0.03822 loss)
I0314 14:15:52.685313 16588 sgd_solver.cpp:106] Iteration 57800, lr = 0.01
I0314 14:16:07.168853 16588 solver.cpp:228] Iteration 57900, loss = 0.040287
I0314 14:16:07.168853 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:16:07.168853 16588 solver.cpp:244]     Train net output #1: loss = 0.0402871 (* 1 = 0.0402871 loss)
I0314 14:16:07.168853 16588 sgd_solver.cpp:106] Iteration 57900, lr = 0.01
I0314 14:16:21.612732 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_58000.caffemodel
I0314 14:16:21.653734 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_58000.solverstate
I0314 14:16:21.660233 16588 solver.cpp:337] Iteration 58000, Testing net (#0)
I0314 14:16:21.660233 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:16:26.473371 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8682
I0314 14:16:26.473371 16588 solver.cpp:404]     Test net output #1: loss = 0.494854 (* 1 = 0.494854 loss)
I0314 14:16:26.522878 16588 solver.cpp:228] Iteration 58000, loss = 0.0521061
I0314 14:16:26.522878 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:16:26.522878 16588 solver.cpp:244]     Train net output #1: loss = 0.0521062 (* 1 = 0.0521062 loss)
I0314 14:16:26.522878 16588 sgd_solver.cpp:106] Iteration 58000, lr = 0.01
I0314 14:16:40.553251 16588 solver.cpp:228] Iteration 58100, loss = 0.0261993
I0314 14:16:40.553251 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:16:40.553251 16588 solver.cpp:244]     Train net output #1: loss = 0.0261994 (* 1 = 0.0261994 loss)
I0314 14:16:40.553251 16588 sgd_solver.cpp:106] Iteration 58100, lr = 0.01
I0314 14:16:55.070996 16588 solver.cpp:228] Iteration 58200, loss = 0.0353489
I0314 14:16:55.070996 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:16:55.070996 16588 solver.cpp:244]     Train net output #1: loss = 0.0353489 (* 1 = 0.0353489 loss)
I0314 14:16:55.071494 16588 sgd_solver.cpp:106] Iteration 58200, lr = 0.01
I0314 14:17:09.628257 16588 solver.cpp:228] Iteration 58300, loss = 0.0353823
I0314 14:17:09.628257 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:17:09.628257 16588 solver.cpp:244]     Train net output #1: loss = 0.0353824 (* 1 = 0.0353824 loss)
I0314 14:17:09.628257 16588 sgd_solver.cpp:106] Iteration 58300, lr = 0.01
I0314 14:17:24.128334 16588 solver.cpp:228] Iteration 58400, loss = 0.0221364
I0314 14:17:24.128844 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:17:24.128844 16588 solver.cpp:244]     Train net output #1: loss = 0.0221364 (* 1 = 0.0221364 loss)
I0314 14:17:24.128844 16588 sgd_solver.cpp:106] Iteration 58400, lr = 0.01
I0314 14:17:38.543170 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_58500.caffemodel
I0314 14:17:38.581670 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_58500.solverstate
I0314 14:17:38.588173 16588 solver.cpp:337] Iteration 58500, Testing net (#0)
I0314 14:17:38.588173 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:17:43.341962 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8761
I0314 14:17:43.341962 16588 solver.cpp:404]     Test net output #1: loss = 0.46252 (* 1 = 0.46252 loss)
I0314 14:17:43.423446 16588 solver.cpp:228] Iteration 58500, loss = 0.0589283
I0314 14:17:43.423446 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:17:43.423446 16588 solver.cpp:244]     Train net output #1: loss = 0.0589284 (* 1 = 0.0589284 loss)
I0314 14:17:43.423446 16588 sgd_solver.cpp:106] Iteration 58500, lr = 0.01
I0314 14:17:57.625738 16588 solver.cpp:228] Iteration 58600, loss = 0.0219782
I0314 14:17:57.625738 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:17:57.625738 16588 solver.cpp:244]     Train net output #1: loss = 0.0219782 (* 1 = 0.0219782 loss)
I0314 14:17:57.625738 16588 sgd_solver.cpp:106] Iteration 58600, lr = 0.01
I0314 14:18:12.104661 16588 solver.cpp:228] Iteration 58700, loss = 0.0295779
I0314 14:18:12.105161 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:18:12.105161 16588 solver.cpp:244]     Train net output #1: loss = 0.0295779 (* 1 = 0.0295779 loss)
I0314 14:18:12.105161 16588 sgd_solver.cpp:106] Iteration 58700, lr = 0.01
I0314 14:18:26.613889 16588 solver.cpp:228] Iteration 58800, loss = 0.0459765
I0314 14:18:26.613889 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:18:26.613889 16588 solver.cpp:244]     Train net output #1: loss = 0.0459765 (* 1 = 0.0459765 loss)
I0314 14:18:26.613889 16588 sgd_solver.cpp:106] Iteration 58800, lr = 0.01
I0314 14:18:41.169279 16588 solver.cpp:228] Iteration 58900, loss = 0.0187715
I0314 14:18:41.169279 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:18:41.169279 16588 solver.cpp:244]     Train net output #1: loss = 0.0187715 (* 1 = 0.0187715 loss)
I0314 14:18:41.169279 16588 sgd_solver.cpp:106] Iteration 58900, lr = 0.01
I0314 14:18:55.598083 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_59000.caffemodel
I0314 14:18:55.635082 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_59000.solverstate
I0314 14:18:55.641589 16588 solver.cpp:337] Iteration 59000, Testing net (#0)
I0314 14:18:55.641589 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:19:00.437942 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8788
I0314 14:19:00.437942 16588 solver.cpp:404]     Test net output #1: loss = 0.470433 (* 1 = 0.470433 loss)
I0314 14:19:00.497966 16588 solver.cpp:228] Iteration 59000, loss = 0.0384675
I0314 14:19:00.497966 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:19:00.497966 16588 solver.cpp:244]     Train net output #1: loss = 0.0384674 (* 1 = 0.0384674 loss)
I0314 14:19:00.497966 16588 sgd_solver.cpp:106] Iteration 59000, lr = 0.01
I0314 14:19:14.636766 16588 solver.cpp:228] Iteration 59100, loss = 0.0922344
I0314 14:19:14.636766 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:19:14.636766 16588 solver.cpp:244]     Train net output #1: loss = 0.0922344 (* 1 = 0.0922344 loss)
I0314 14:19:14.636766 16588 sgd_solver.cpp:106] Iteration 59100, lr = 0.01
I0314 14:19:29.059732 16588 solver.cpp:228] Iteration 59200, loss = 0.0426047
I0314 14:19:29.059732 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:19:29.059732 16588 solver.cpp:244]     Train net output #1: loss = 0.0426047 (* 1 = 0.0426047 loss)
I0314 14:19:29.059732 16588 sgd_solver.cpp:106] Iteration 59200, lr = 0.01
I0314 14:19:43.582950 16588 solver.cpp:228] Iteration 59300, loss = 0.0358573
I0314 14:19:43.582950 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:19:43.582950 16588 solver.cpp:244]     Train net output #1: loss = 0.0358572 (* 1 = 0.0358572 loss)
I0314 14:19:43.582950 16588 sgd_solver.cpp:106] Iteration 59300, lr = 0.01
I0314 14:19:58.128953 16588 solver.cpp:228] Iteration 59400, loss = 0.0251321
I0314 14:19:58.128953 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:19:58.128953 16588 solver.cpp:244]     Train net output #1: loss = 0.0251321 (* 1 = 0.0251321 loss)
I0314 14:19:58.128953 16588 sgd_solver.cpp:106] Iteration 59400, lr = 0.01
I0314 14:20:12.534651 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_59500.caffemodel
I0314 14:20:12.571652 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_59500.solverstate
I0314 14:20:12.578152 16588 solver.cpp:337] Iteration 59500, Testing net (#0)
I0314 14:20:12.578654 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:20:17.409883 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8769
I0314 14:20:17.409883 16588 solver.cpp:404]     Test net output #1: loss = 0.46554 (* 1 = 0.46554 loss)
I0314 14:20:17.450951 16588 solver.cpp:228] Iteration 59500, loss = 0.0572665
I0314 14:20:17.450951 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:20:17.450951 16588 solver.cpp:244]     Train net output #1: loss = 0.0572664 (* 1 = 0.0572664 loss)
I0314 14:20:17.450951 16588 sgd_solver.cpp:106] Iteration 59500, lr = 0.01
I0314 14:20:31.597389 16588 solver.cpp:228] Iteration 59600, loss = 0.0439839
I0314 14:20:31.597389 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:20:31.597890 16588 solver.cpp:244]     Train net output #1: loss = 0.0439838 (* 1 = 0.0439838 loss)
I0314 14:20:31.597890 16588 sgd_solver.cpp:106] Iteration 59600, lr = 0.01
I0314 14:20:46.101451 16588 solver.cpp:228] Iteration 59700, loss = 0.0478246
I0314 14:20:46.101451 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:20:46.101451 16588 solver.cpp:244]     Train net output #1: loss = 0.0478246 (* 1 = 0.0478246 loss)
I0314 14:20:46.101451 16588 sgd_solver.cpp:106] Iteration 59700, lr = 0.01
I0314 14:21:00.625336 16588 solver.cpp:228] Iteration 59800, loss = 0.0634294
I0314 14:21:00.625336 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:21:00.625336 16588 solver.cpp:244]     Train net output #1: loss = 0.0634293 (* 1 = 0.0634293 loss)
I0314 14:21:00.625336 16588 sgd_solver.cpp:106] Iteration 59800, lr = 0.01
I0314 14:21:15.051482 16588 solver.cpp:228] Iteration 59900, loss = 0.0368722
I0314 14:21:15.051482 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:21:15.051482 16588 solver.cpp:244]     Train net output #1: loss = 0.0368721 (* 1 = 0.0368721 loss)
I0314 14:21:15.051482 16588 sgd_solver.cpp:106] Iteration 59900, lr = 0.01
I0314 14:21:29.521489 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_60000.caffemodel
I0314 14:21:29.561511 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_60000.solverstate
I0314 14:21:29.567493 16588 solver.cpp:337] Iteration 60000, Testing net (#0)
I0314 14:21:29.567493 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:21:34.358481 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8758
I0314 14:21:34.358481 16588 solver.cpp:404]     Test net output #1: loss = 0.46611 (* 1 = 0.46611 loss)
I0314 14:21:34.418491 16588 solver.cpp:228] Iteration 60000, loss = 0.0435776
I0314 14:21:34.418491 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:21:34.418491 16588 solver.cpp:244]     Train net output #1: loss = 0.0435776 (* 1 = 0.0435776 loss)
I0314 14:21:34.418491 16588 sgd_solver.cpp:106] Iteration 60000, lr = 0.01
I0314 14:21:48.509982 16588 solver.cpp:228] Iteration 60100, loss = 0.0756365
I0314 14:21:48.509982 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:21:48.509982 16588 solver.cpp:244]     Train net output #1: loss = 0.0756364 (* 1 = 0.0756364 loss)
I0314 14:21:48.509982 16588 sgd_solver.cpp:106] Iteration 60100, lr = 0.01
I0314 14:22:03.018309 16588 solver.cpp:228] Iteration 60200, loss = 0.12385
I0314 14:22:03.018309 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:22:03.018309 16588 solver.cpp:244]     Train net output #1: loss = 0.12385 (* 1 = 0.12385 loss)
I0314 14:22:03.018309 16588 sgd_solver.cpp:106] Iteration 60200, lr = 0.01
I0314 14:22:17.566777 16588 solver.cpp:228] Iteration 60300, loss = 0.0300377
I0314 14:22:17.566777 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:22:17.566777 16588 solver.cpp:244]     Train net output #1: loss = 0.0300376 (* 1 = 0.0300376 loss)
I0314 14:22:17.566777 16588 sgd_solver.cpp:106] Iteration 60300, lr = 0.01
I0314 14:22:32.076378 16588 solver.cpp:228] Iteration 60400, loss = 0.0139362
I0314 14:22:32.076378 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:22:32.076378 16588 solver.cpp:244]     Train net output #1: loss = 0.0139362 (* 1 = 0.0139362 loss)
I0314 14:22:32.076378 16588 sgd_solver.cpp:106] Iteration 60400, lr = 0.01
I0314 14:22:46.499454 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_60500.caffemodel
I0314 14:22:46.537453 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_60500.solverstate
I0314 14:22:46.543958 16588 solver.cpp:337] Iteration 60500, Testing net (#0)
I0314 14:22:46.543958 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:22:51.311581 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8771
I0314 14:22:51.311581 16588 solver.cpp:404]     Test net output #1: loss = 0.46693 (* 1 = 0.46693 loss)
I0314 14:22:51.371083 16588 solver.cpp:228] Iteration 60500, loss = 0.051585
I0314 14:22:51.371083 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:22:51.371083 16588 solver.cpp:244]     Train net output #1: loss = 0.051585 (* 1 = 0.051585 loss)
I0314 14:22:51.371083 16588 sgd_solver.cpp:106] Iteration 60500, lr = 0.01
I0314 14:23:05.605563 16588 solver.cpp:228] Iteration 60600, loss = 0.0308952
I0314 14:23:05.605563 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:23:05.605563 16588 solver.cpp:244]     Train net output #1: loss = 0.0308951 (* 1 = 0.0308951 loss)
I0314 14:23:05.605563 16588 sgd_solver.cpp:106] Iteration 60600, lr = 0.01
I0314 14:23:20.058192 16588 solver.cpp:228] Iteration 60700, loss = 0.0548652
I0314 14:23:20.058192 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:23:20.058192 16588 solver.cpp:244]     Train net output #1: loss = 0.0548652 (* 1 = 0.0548652 loss)
I0314 14:23:20.058192 16588 sgd_solver.cpp:106] Iteration 60700, lr = 0.01
I0314 14:23:34.545034 16588 solver.cpp:228] Iteration 60800, loss = 0.0978552
I0314 14:23:34.545034 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:23:34.545034 16588 solver.cpp:244]     Train net output #1: loss = 0.0978551 (* 1 = 0.0978551 loss)
I0314 14:23:34.545034 16588 sgd_solver.cpp:106] Iteration 60800, lr = 0.01
I0314 14:23:49.078824 16588 solver.cpp:228] Iteration 60900, loss = 0.0529435
I0314 14:23:49.078824 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:23:49.078824 16588 solver.cpp:244]     Train net output #1: loss = 0.0529434 (* 1 = 0.0529434 loss)
I0314 14:23:49.078824 16588 sgd_solver.cpp:106] Iteration 60900, lr = 0.01
I0314 14:24:03.527319 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_61000.caffemodel
I0314 14:24:03.563819 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_61000.solverstate
I0314 14:24:03.570322 16588 solver.cpp:337] Iteration 61000, Testing net (#0)
I0314 14:24:03.570322 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:24:08.343765 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8726
I0314 14:24:08.343765 16588 solver.cpp:404]     Test net output #1: loss = 0.472232 (* 1 = 0.472232 loss)
I0314 14:24:08.403281 16588 solver.cpp:228] Iteration 61000, loss = 0.119849
I0314 14:24:08.403281 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:24:08.403281 16588 solver.cpp:244]     Train net output #1: loss = 0.119849 (* 1 = 0.119849 loss)
I0314 14:24:08.403281 16588 sgd_solver.cpp:106] Iteration 61000, lr = 0.01
I0314 14:24:22.403530 16588 solver.cpp:228] Iteration 61100, loss = 0.0412435
I0314 14:24:22.403530 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:24:22.403530 16588 solver.cpp:244]     Train net output #1: loss = 0.0412434 (* 1 = 0.0412434 loss)
I0314 14:24:22.404031 16588 sgd_solver.cpp:106] Iteration 61100, lr = 0.01
I0314 14:24:36.936091 16588 solver.cpp:228] Iteration 61200, loss = 0.0385878
I0314 14:24:36.936091 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:24:36.936091 16588 solver.cpp:244]     Train net output #1: loss = 0.0385877 (* 1 = 0.0385877 loss)
I0314 14:24:36.936091 16588 sgd_solver.cpp:106] Iteration 61200, lr = 0.01
I0314 14:24:51.515218 16588 solver.cpp:228] Iteration 61300, loss = 0.0470904
I0314 14:24:51.515218 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:24:51.515218 16588 solver.cpp:244]     Train net output #1: loss = 0.0470903 (* 1 = 0.0470903 loss)
I0314 14:24:51.515218 16588 sgd_solver.cpp:106] Iteration 61300, lr = 0.01
I0314 14:25:06.005198 16588 solver.cpp:228] Iteration 61400, loss = 0.0235666
I0314 14:25:06.005198 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:25:06.005198 16588 solver.cpp:244]     Train net output #1: loss = 0.0235666 (* 1 = 0.0235666 loss)
I0314 14:25:06.005198 16588 sgd_solver.cpp:106] Iteration 61400, lr = 0.01
I0314 14:25:20.470329 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_61500.caffemodel
I0314 14:25:20.505326 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_61500.solverstate
I0314 14:25:20.511839 16588 solver.cpp:337] Iteration 61500, Testing net (#0)
I0314 14:25:20.511839 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:25:25.276537 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8718
I0314 14:25:25.276537 16588 solver.cpp:404]     Test net output #1: loss = 0.469698 (* 1 = 0.469698 loss)
I0314 14:25:25.344548 16588 solver.cpp:228] Iteration 61500, loss = 0.0248417
I0314 14:25:25.344548 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:25:25.344548 16588 solver.cpp:244]     Train net output #1: loss = 0.0248417 (* 1 = 0.0248417 loss)
I0314 14:25:25.344548 16588 sgd_solver.cpp:106] Iteration 61500, lr = 0.01
I0314 14:25:39.356205 16588 solver.cpp:228] Iteration 61600, loss = 0.0300582
I0314 14:25:39.356205 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:25:39.356205 16588 solver.cpp:244]     Train net output #1: loss = 0.0300582 (* 1 = 0.0300582 loss)
I0314 14:25:39.356205 16588 sgd_solver.cpp:106] Iteration 61600, lr = 0.01
I0314 14:25:53.869361 16588 solver.cpp:228] Iteration 61700, loss = 0.0972762
I0314 14:25:53.869361 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 14:25:53.869361 16588 solver.cpp:244]     Train net output #1: loss = 0.0972762 (* 1 = 0.0972762 loss)
I0314 14:25:53.869361 16588 sgd_solver.cpp:106] Iteration 61700, lr = 0.01
I0314 14:26:08.396330 16588 solver.cpp:228] Iteration 61800, loss = 0.078556
I0314 14:26:08.396330 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:26:08.396330 16588 solver.cpp:244]     Train net output #1: loss = 0.0785559 (* 1 = 0.0785559 loss)
I0314 14:26:08.396330 16588 sgd_solver.cpp:106] Iteration 61800, lr = 0.01
I0314 14:26:22.947295 16588 solver.cpp:228] Iteration 61900, loss = 0.0221423
I0314 14:26:22.947295 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:26:22.947295 16588 solver.cpp:244]     Train net output #1: loss = 0.0221423 (* 1 = 0.0221423 loss)
I0314 14:26:22.947295 16588 sgd_solver.cpp:106] Iteration 61900, lr = 0.01
I0314 14:26:37.347157 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_62000.caffemodel
I0314 14:26:37.384153 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_62000.solverstate
I0314 14:26:37.390653 16588 solver.cpp:337] Iteration 62000, Testing net (#0)
I0314 14:26:37.390653 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:26:42.231734 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8598
I0314 14:26:42.231734 16588 solver.cpp:404]     Test net output #1: loss = 0.529371 (* 1 = 0.529371 loss)
I0314 14:26:42.291738 16588 solver.cpp:228] Iteration 62000, loss = 0.0554583
I0314 14:26:42.291738 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:26:42.291738 16588 solver.cpp:244]     Train net output #1: loss = 0.0554582 (* 1 = 0.0554582 loss)
I0314 14:26:42.291738 16588 sgd_solver.cpp:106] Iteration 62000, lr = 0.01
I0314 14:26:56.384506 16588 solver.cpp:228] Iteration 62100, loss = 0.0332663
I0314 14:26:56.384506 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:26:56.384506 16588 solver.cpp:244]     Train net output #1: loss = 0.0332662 (* 1 = 0.0332662 loss)
I0314 14:26:56.384506 16588 sgd_solver.cpp:106] Iteration 62100, lr = 0.01
I0314 14:27:10.879830 16588 solver.cpp:228] Iteration 62200, loss = 0.121303
I0314 14:27:10.879830 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 14:27:10.880337 16588 solver.cpp:244]     Train net output #1: loss = 0.121303 (* 1 = 0.121303 loss)
I0314 14:27:10.880337 16588 sgd_solver.cpp:106] Iteration 62200, lr = 0.01
I0314 14:27:25.428594 16588 solver.cpp:228] Iteration 62300, loss = 0.0595299
I0314 14:27:25.428594 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:27:25.428594 16588 solver.cpp:244]     Train net output #1: loss = 0.05953 (* 1 = 0.05953 loss)
I0314 14:27:25.428594 16588 sgd_solver.cpp:106] Iteration 62300, lr = 0.01
I0314 14:27:39.950970 16588 solver.cpp:228] Iteration 62400, loss = 0.066041
I0314 14:27:39.950970 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:27:39.950970 16588 solver.cpp:244]     Train net output #1: loss = 0.0660411 (* 1 = 0.0660411 loss)
I0314 14:27:39.950970 16588 sgd_solver.cpp:106] Iteration 62400, lr = 0.01
I0314 14:27:54.338372 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_62500.caffemodel
I0314 14:27:54.375871 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_62500.solverstate
I0314 14:27:54.382370 16588 solver.cpp:337] Iteration 62500, Testing net (#0)
I0314 14:27:54.382370 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:27:59.231415 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8623
I0314 14:27:59.231415 16588 solver.cpp:404]     Test net output #1: loss = 0.543718 (* 1 = 0.543718 loss)
I0314 14:27:59.273921 16588 solver.cpp:228] Iteration 62500, loss = 0.150791
I0314 14:27:59.273921 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 14:27:59.273921 16588 solver.cpp:244]     Train net output #1: loss = 0.150791 (* 1 = 0.150791 loss)
I0314 14:27:59.273921 16588 sgd_solver.cpp:106] Iteration 62500, lr = 0.01
I0314 14:28:13.358965 16588 solver.cpp:228] Iteration 62600, loss = 0.0748447
I0314 14:28:13.358965 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:28:13.358965 16588 solver.cpp:244]     Train net output #1: loss = 0.0748448 (* 1 = 0.0748448 loss)
I0314 14:28:13.358965 16588 sgd_solver.cpp:106] Iteration 62600, lr = 0.01
I0314 14:28:27.813753 16588 solver.cpp:228] Iteration 62700, loss = 0.0696697
I0314 14:28:27.813753 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:28:27.813753 16588 solver.cpp:244]     Train net output #1: loss = 0.0696698 (* 1 = 0.0696698 loss)
I0314 14:28:27.813753 16588 sgd_solver.cpp:106] Iteration 62700, lr = 0.01
I0314 14:28:42.293618 16588 solver.cpp:228] Iteration 62800, loss = 0.108846
I0314 14:28:42.293618 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:28:42.293618 16588 solver.cpp:244]     Train net output #1: loss = 0.108846 (* 1 = 0.108846 loss)
I0314 14:28:42.293618 16588 sgd_solver.cpp:106] Iteration 62800, lr = 0.01
I0314 14:28:56.804257 16588 solver.cpp:228] Iteration 62900, loss = 0.0441089
I0314 14:28:56.804759 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:28:56.804759 16588 solver.cpp:244]     Train net output #1: loss = 0.044109 (* 1 = 0.044109 loss)
I0314 14:28:56.804759 16588 sgd_solver.cpp:106] Iteration 62900, lr = 0.01
I0314 14:29:11.294100 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_63000.caffemodel
I0314 14:29:11.332597 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_63000.solverstate
I0314 14:29:11.338596 16588 solver.cpp:337] Iteration 63000, Testing net (#0)
I0314 14:29:11.338596 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:29:16.123739 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8768
I0314 14:29:16.123739 16588 solver.cpp:404]     Test net output #1: loss = 0.462715 (* 1 = 0.462715 loss)
I0314 14:29:16.195240 16588 solver.cpp:228] Iteration 63000, loss = 0.0807242
I0314 14:29:16.195240 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:29:16.195240 16588 solver.cpp:244]     Train net output #1: loss = 0.0807243 (* 1 = 0.0807243 loss)
I0314 14:29:16.195756 16588 sgd_solver.cpp:106] Iteration 63000, lr = 0.01
I0314 14:29:30.241394 16588 solver.cpp:228] Iteration 63100, loss = 0.0565304
I0314 14:29:30.241394 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:29:30.241394 16588 solver.cpp:244]     Train net output #1: loss = 0.0565305 (* 1 = 0.0565305 loss)
I0314 14:29:30.241394 16588 sgd_solver.cpp:106] Iteration 63100, lr = 0.01
I0314 14:29:44.819286 16588 solver.cpp:228] Iteration 63200, loss = 0.0774152
I0314 14:29:44.819286 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:29:44.819286 16588 solver.cpp:244]     Train net output #1: loss = 0.0774153 (* 1 = 0.0774153 loss)
I0314 14:29:44.819286 16588 sgd_solver.cpp:106] Iteration 63200, lr = 0.01
I0314 14:29:59.318507 16588 solver.cpp:228] Iteration 63300, loss = 0.0795368
I0314 14:29:59.318507 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:29:59.318507 16588 solver.cpp:244]     Train net output #1: loss = 0.0795369 (* 1 = 0.0795369 loss)
I0314 14:29:59.318507 16588 sgd_solver.cpp:106] Iteration 63300, lr = 0.01
I0314 14:30:13.825145 16588 solver.cpp:228] Iteration 63400, loss = 0.0362443
I0314 14:30:13.825145 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:30:13.825145 16588 solver.cpp:244]     Train net output #1: loss = 0.0362444 (* 1 = 0.0362444 loss)
I0314 14:30:13.825145 16588 sgd_solver.cpp:106] Iteration 63400, lr = 0.01
I0314 14:30:28.289821 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_63500.caffemodel
I0314 14:30:28.329838 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_63500.solverstate
I0314 14:30:28.335824 16588 solver.cpp:337] Iteration 63500, Testing net (#0)
I0314 14:30:28.335824 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:30:33.098879 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8749
I0314 14:30:33.098879 16588 solver.cpp:404]     Test net output #1: loss = 0.458913 (* 1 = 0.458913 loss)
I0314 14:30:33.164878 16588 solver.cpp:228] Iteration 63500, loss = 0.0694134
I0314 14:30:33.164878 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:30:33.164878 16588 solver.cpp:244]     Train net output #1: loss = 0.0694136 (* 1 = 0.0694136 loss)
I0314 14:30:33.164878 16588 sgd_solver.cpp:106] Iteration 63500, lr = 0.01
I0314 14:30:47.251226 16588 solver.cpp:228] Iteration 63600, loss = 0.075233
I0314 14:30:47.251226 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:30:47.251226 16588 solver.cpp:244]     Train net output #1: loss = 0.0752332 (* 1 = 0.0752332 loss)
I0314 14:30:47.251226 16588 sgd_solver.cpp:106] Iteration 63600, lr = 0.01
I0314 14:31:01.787461 16588 solver.cpp:228] Iteration 63700, loss = 0.0411878
I0314 14:31:01.787461 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:31:01.787461 16588 solver.cpp:244]     Train net output #1: loss = 0.041188 (* 1 = 0.041188 loss)
I0314 14:31:01.787461 16588 sgd_solver.cpp:106] Iteration 63700, lr = 0.01
I0314 14:31:16.253525 16588 solver.cpp:228] Iteration 63800, loss = 0.0438428
I0314 14:31:16.253525 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:31:16.253525 16588 solver.cpp:244]     Train net output #1: loss = 0.0438429 (* 1 = 0.0438429 loss)
I0314 14:31:16.253525 16588 sgd_solver.cpp:106] Iteration 63800, lr = 0.01
I0314 14:31:30.737015 16588 solver.cpp:228] Iteration 63900, loss = 0.036096
I0314 14:31:30.737015 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:31:30.737015 16588 solver.cpp:244]     Train net output #1: loss = 0.0360961 (* 1 = 0.0360961 loss)
I0314 14:31:30.737015 16588 sgd_solver.cpp:106] Iteration 63900, lr = 0.01
I0314 14:31:45.125452 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_64000.caffemodel
I0314 14:31:45.159972 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_64000.solverstate
I0314 14:31:45.165953 16588 solver.cpp:337] Iteration 64000, Testing net (#0)
I0314 14:31:45.165953 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:31:49.879717 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8454
I0314 14:31:49.879717 16588 solver.cpp:404]     Test net output #1: loss = 0.598829 (* 1 = 0.598829 loss)
I0314 14:31:49.929718 16588 solver.cpp:228] Iteration 64000, loss = 0.0416866
I0314 14:31:49.929718 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:31:49.929718 16588 solver.cpp:244]     Train net output #1: loss = 0.0416867 (* 1 = 0.0416867 loss)
I0314 14:31:49.929718 16588 sgd_solver.cpp:106] Iteration 64000, lr = 0.01
I0314 14:32:04.054167 16588 solver.cpp:228] Iteration 64100, loss = 0.0412362
I0314 14:32:04.054167 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:32:04.054167 16588 solver.cpp:244]     Train net output #1: loss = 0.0412364 (* 1 = 0.0412364 loss)
I0314 14:32:04.054167 16588 sgd_solver.cpp:106] Iteration 64100, lr = 0.01
I0314 14:32:18.521162 16588 solver.cpp:228] Iteration 64200, loss = 0.0647372
I0314 14:32:18.521162 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:32:18.521162 16588 solver.cpp:244]     Train net output #1: loss = 0.0647373 (* 1 = 0.0647373 loss)
I0314 14:32:18.521162 16588 sgd_solver.cpp:106] Iteration 64200, lr = 0.01
I0314 14:32:33.073796 16588 solver.cpp:228] Iteration 64300, loss = 0.0754366
I0314 14:32:33.073796 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:32:33.073796 16588 solver.cpp:244]     Train net output #1: loss = 0.0754368 (* 1 = 0.0754368 loss)
I0314 14:32:33.073796 16588 sgd_solver.cpp:106] Iteration 64300, lr = 0.01
I0314 14:32:47.638429 16588 solver.cpp:228] Iteration 64400, loss = 0.0685883
I0314 14:32:47.638429 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:32:47.638429 16588 solver.cpp:244]     Train net output #1: loss = 0.0685884 (* 1 = 0.0685884 loss)
I0314 14:32:47.638429 16588 sgd_solver.cpp:106] Iteration 64400, lr = 0.01
I0314 14:33:02.095129 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_64500.caffemodel
I0314 14:33:02.132628 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_64500.solverstate
I0314 14:33:02.138628 16588 solver.cpp:337] Iteration 64500, Testing net (#0)
I0314 14:33:02.139128 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:33:06.906194 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8744
I0314 14:33:06.906194 16588 solver.cpp:404]     Test net output #1: loss = 0.467729 (* 1 = 0.467729 loss)
I0314 14:33:06.966238 16588 solver.cpp:228] Iteration 64500, loss = 0.0429041
I0314 14:33:06.966238 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:33:06.966238 16588 solver.cpp:244]     Train net output #1: loss = 0.0429042 (* 1 = 0.0429042 loss)
I0314 14:33:06.966238 16588 sgd_solver.cpp:106] Iteration 64500, lr = 0.01
I0314 14:33:21.090582 16588 solver.cpp:228] Iteration 64600, loss = 0.0494654
I0314 14:33:21.090582 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:33:21.090582 16588 solver.cpp:244]     Train net output #1: loss = 0.0494655 (* 1 = 0.0494655 loss)
I0314 14:33:21.090582 16588 sgd_solver.cpp:106] Iteration 64600, lr = 0.01
I0314 14:33:35.636462 16588 solver.cpp:228] Iteration 64700, loss = 0.103299
I0314 14:33:35.636462 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:33:35.636462 16588 solver.cpp:244]     Train net output #1: loss = 0.103299 (* 1 = 0.103299 loss)
I0314 14:33:35.636462 16588 sgd_solver.cpp:106] Iteration 64700, lr = 0.01
I0314 14:33:50.162292 16588 solver.cpp:228] Iteration 64800, loss = 0.0636037
I0314 14:33:50.162292 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:33:50.162292 16588 solver.cpp:244]     Train net output #1: loss = 0.0636038 (* 1 = 0.0636038 loss)
I0314 14:33:50.162292 16588 sgd_solver.cpp:106] Iteration 64800, lr = 0.01
I0314 14:34:04.661794 16588 solver.cpp:228] Iteration 64900, loss = 0.0625656
I0314 14:34:04.661794 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:34:04.661794 16588 solver.cpp:244]     Train net output #1: loss = 0.0625657 (* 1 = 0.0625657 loss)
I0314 14:34:04.661794 16588 sgd_solver.cpp:106] Iteration 64900, lr = 0.01
I0314 14:34:19.080816 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_65000.caffemodel
I0314 14:34:19.124294 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_65000.solverstate
I0314 14:34:19.130794 16588 solver.cpp:337] Iteration 65000, Testing net (#0)
I0314 14:34:19.130794 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:34:23.999821 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8486
I0314 14:34:23.999821 16588 solver.cpp:404]     Test net output #1: loss = 0.590249 (* 1 = 0.590249 loss)
I0314 14:34:24.042835 16588 solver.cpp:228] Iteration 65000, loss = 0.0644044
I0314 14:34:24.042835 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:34:24.042835 16588 solver.cpp:244]     Train net output #1: loss = 0.0644045 (* 1 = 0.0644045 loss)
I0314 14:34:24.042835 16588 sgd_solver.cpp:106] Iteration 65000, lr = 0.01
I0314 14:34:38.233821 16588 solver.cpp:228] Iteration 65100, loss = 0.111281
I0314 14:34:38.233821 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:34:38.233821 16588 solver.cpp:244]     Train net output #1: loss = 0.111281 (* 1 = 0.111281 loss)
I0314 14:34:38.233821 16588 sgd_solver.cpp:106] Iteration 65100, lr = 0.01
I0314 14:34:52.767978 16588 solver.cpp:228] Iteration 65200, loss = 0.0364578
I0314 14:34:52.768478 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:34:52.768478 16588 solver.cpp:244]     Train net output #1: loss = 0.0364579 (* 1 = 0.0364579 loss)
I0314 14:34:52.768478 16588 sgd_solver.cpp:106] Iteration 65200, lr = 0.01
I0314 14:35:07.263626 16588 solver.cpp:228] Iteration 65300, loss = 0.0648417
I0314 14:35:07.263626 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:35:07.263626 16588 solver.cpp:244]     Train net output #1: loss = 0.0648418 (* 1 = 0.0648418 loss)
I0314 14:35:07.263626 16588 sgd_solver.cpp:106] Iteration 65300, lr = 0.01
I0314 14:35:21.826181 16588 solver.cpp:228] Iteration 65400, loss = 0.0184665
I0314 14:35:21.826181 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:35:21.826181 16588 solver.cpp:244]     Train net output #1: loss = 0.0184665 (* 1 = 0.0184665 loss)
I0314 14:35:21.826181 16588 sgd_solver.cpp:106] Iteration 65400, lr = 0.01
I0314 14:35:36.236208 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_65500.caffemodel
I0314 14:35:36.273210 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_65500.solverstate
I0314 14:35:36.279711 16588 solver.cpp:337] Iteration 65500, Testing net (#0)
I0314 14:35:36.279711 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:35:41.036281 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8717
I0314 14:35:41.036281 16588 solver.cpp:404]     Test net output #1: loss = 0.477006 (* 1 = 0.477006 loss)
I0314 14:35:41.056282 16588 solver.cpp:228] Iteration 65500, loss = 0.100053
I0314 14:35:41.056282 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:35:41.056282 16588 solver.cpp:244]     Train net output #1: loss = 0.100053 (* 1 = 0.100053 loss)
I0314 14:35:41.056282 16588 sgd_solver.cpp:106] Iteration 65500, lr = 0.01
I0314 14:35:55.226572 16588 solver.cpp:228] Iteration 65600, loss = 0.0557535
I0314 14:35:55.226572 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:35:55.227072 16588 solver.cpp:244]     Train net output #1: loss = 0.0557535 (* 1 = 0.0557535 loss)
I0314 14:35:55.227072 16588 sgd_solver.cpp:106] Iteration 65600, lr = 0.01
I0314 14:36:09.794425 16588 solver.cpp:228] Iteration 65700, loss = 0.0926894
I0314 14:36:09.794425 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 14:36:09.794425 16588 solver.cpp:244]     Train net output #1: loss = 0.0926895 (* 1 = 0.0926895 loss)
I0314 14:36:09.794425 16588 sgd_solver.cpp:106] Iteration 65700, lr = 0.01
I0314 14:36:24.318877 16588 solver.cpp:228] Iteration 65800, loss = 0.0644734
I0314 14:36:24.318877 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:36:24.318877 16588 solver.cpp:244]     Train net output #1: loss = 0.0644735 (* 1 = 0.0644735 loss)
I0314 14:36:24.318877 16588 sgd_solver.cpp:106] Iteration 65800, lr = 0.01
I0314 14:36:38.756400 16588 solver.cpp:228] Iteration 65900, loss = 0.0398488
I0314 14:36:38.756400 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:36:38.756400 16588 solver.cpp:244]     Train net output #1: loss = 0.0398489 (* 1 = 0.0398489 loss)
I0314 14:36:38.756400 16588 sgd_solver.cpp:106] Iteration 65900, lr = 0.01
I0314 14:36:53.241441 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_66000.caffemodel
I0314 14:36:53.278442 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_66000.solverstate
I0314 14:36:53.284940 16588 solver.cpp:337] Iteration 66000, Testing net (#0)
I0314 14:36:53.284940 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:36:58.156024 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8649
I0314 14:36:58.156024 16588 solver.cpp:404]     Test net output #1: loss = 0.503561 (* 1 = 0.503561 loss)
I0314 14:36:58.196024 16588 solver.cpp:228] Iteration 66000, loss = 0.0680504
I0314 14:36:58.196024 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:36:58.196024 16588 solver.cpp:244]     Train net output #1: loss = 0.0680506 (* 1 = 0.0680506 loss)
I0314 14:36:58.196024 16588 sgd_solver.cpp:106] Iteration 66000, lr = 0.01
I0314 14:37:12.349565 16588 solver.cpp:228] Iteration 66100, loss = 0.050653
I0314 14:37:12.349565 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:37:12.349565 16588 solver.cpp:244]     Train net output #1: loss = 0.0506532 (* 1 = 0.0506532 loss)
I0314 14:37:12.349565 16588 sgd_solver.cpp:106] Iteration 66100, lr = 0.01
I0314 14:37:26.842273 16588 solver.cpp:228] Iteration 66200, loss = 0.0716383
I0314 14:37:26.842273 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:37:26.842273 16588 solver.cpp:244]     Train net output #1: loss = 0.0716384 (* 1 = 0.0716384 loss)
I0314 14:37:26.842273 16588 sgd_solver.cpp:106] Iteration 66200, lr = 0.01
I0314 14:37:41.361258 16588 solver.cpp:228] Iteration 66300, loss = 0.0662149
I0314 14:37:41.361757 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:37:41.361757 16588 solver.cpp:244]     Train net output #1: loss = 0.066215 (* 1 = 0.066215 loss)
I0314 14:37:41.361757 16588 sgd_solver.cpp:106] Iteration 66300, lr = 0.01
I0314 14:37:55.892063 16588 solver.cpp:228] Iteration 66400, loss = 0.0738747
I0314 14:37:55.892063 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:37:55.892063 16588 solver.cpp:244]     Train net output #1: loss = 0.0738748 (* 1 = 0.0738748 loss)
I0314 14:37:55.892063 16588 sgd_solver.cpp:106] Iteration 66400, lr = 0.01
I0314 14:38:10.302798 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_66500.caffemodel
I0314 14:38:10.340297 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_66500.solverstate
I0314 14:38:10.346797 16588 solver.cpp:337] Iteration 66500, Testing net (#0)
I0314 14:38:10.346797 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:38:15.188949 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8638
I0314 14:38:15.188949 16588 solver.cpp:404]     Test net output #1: loss = 0.513358 (* 1 = 0.513358 loss)
I0314 14:38:15.230453 16588 solver.cpp:228] Iteration 66500, loss = 0.0850238
I0314 14:38:15.230453 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:38:15.230453 16588 solver.cpp:244]     Train net output #1: loss = 0.0850239 (* 1 = 0.0850239 loss)
I0314 14:38:15.230453 16588 sgd_solver.cpp:106] Iteration 66500, lr = 0.01
I0314 14:38:29.395670 16588 solver.cpp:228] Iteration 66600, loss = 0.0728545
I0314 14:38:29.395670 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:38:29.395670 16588 solver.cpp:244]     Train net output #1: loss = 0.0728547 (* 1 = 0.0728547 loss)
I0314 14:38:29.395670 16588 sgd_solver.cpp:106] Iteration 66600, lr = 0.01
I0314 14:38:43.865839 16588 solver.cpp:228] Iteration 66700, loss = 0.0798288
I0314 14:38:43.865839 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:38:43.865839 16588 solver.cpp:244]     Train net output #1: loss = 0.079829 (* 1 = 0.079829 loss)
I0314 14:38:43.865839 16588 sgd_solver.cpp:106] Iteration 66700, lr = 0.01
I0314 14:38:58.367662 16588 solver.cpp:228] Iteration 66800, loss = 0.0934061
I0314 14:38:58.367662 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:38:58.367662 16588 solver.cpp:244]     Train net output #1: loss = 0.0934063 (* 1 = 0.0934063 loss)
I0314 14:38:58.367662 16588 sgd_solver.cpp:106] Iteration 66800, lr = 0.01
I0314 14:39:12.906854 16588 solver.cpp:228] Iteration 66900, loss = 0.038893
I0314 14:39:12.906854 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:39:12.906854 16588 solver.cpp:244]     Train net output #1: loss = 0.0388932 (* 1 = 0.0388932 loss)
I0314 14:39:12.906854 16588 sgd_solver.cpp:106] Iteration 66900, lr = 0.01
I0314 14:39:27.361914 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_67000.caffemodel
I0314 14:39:27.399914 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_67000.solverstate
I0314 14:39:27.405915 16588 solver.cpp:337] Iteration 67000, Testing net (#0)
I0314 14:39:27.405915 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:39:32.217991 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8589
I0314 14:39:32.217991 16588 solver.cpp:404]     Test net output #1: loss = 0.561444 (* 1 = 0.561444 loss)
I0314 14:39:32.283993 16588 solver.cpp:228] Iteration 67000, loss = 0.0725792
I0314 14:39:32.283993 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:39:32.283993 16588 solver.cpp:244]     Train net output #1: loss = 0.0725794 (* 1 = 0.0725794 loss)
I0314 14:39:32.283993 16588 sgd_solver.cpp:106] Iteration 67000, lr = 0.01
I0314 14:39:46.363310 16588 solver.cpp:228] Iteration 67100, loss = 0.0337948
I0314 14:39:46.363310 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:39:46.363310 16588 solver.cpp:244]     Train net output #1: loss = 0.033795 (* 1 = 0.033795 loss)
I0314 14:39:46.363310 16588 sgd_solver.cpp:106] Iteration 67100, lr = 0.01
I0314 14:40:00.808775 16588 solver.cpp:228] Iteration 67200, loss = 0.0677499
I0314 14:40:00.808775 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:40:00.808775 16588 solver.cpp:244]     Train net output #1: loss = 0.06775 (* 1 = 0.06775 loss)
I0314 14:40:00.808775 16588 sgd_solver.cpp:106] Iteration 67200, lr = 0.01
I0314 14:40:15.274672 16588 solver.cpp:228] Iteration 67300, loss = 0.0385874
I0314 14:40:15.274672 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:40:15.274672 16588 solver.cpp:244]     Train net output #1: loss = 0.0385875 (* 1 = 0.0385875 loss)
I0314 14:40:15.274672 16588 sgd_solver.cpp:106] Iteration 67300, lr = 0.01
I0314 14:40:29.824443 16588 solver.cpp:228] Iteration 67400, loss = 0.0116429
I0314 14:40:29.824443 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:40:29.824443 16588 solver.cpp:244]     Train net output #1: loss = 0.0116431 (* 1 = 0.0116431 loss)
I0314 14:40:29.824443 16588 sgd_solver.cpp:106] Iteration 67400, lr = 0.01
I0314 14:40:44.193590 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_67500.caffemodel
I0314 14:40:44.211578 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_67500.solverstate
I0314 14:40:44.217577 16588 solver.cpp:337] Iteration 67500, Testing net (#0)
I0314 14:40:44.217577 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:40:49.079382 16588 solver.cpp:404]     Test net output #0: accuracy = 0.871
I0314 14:40:49.079382 16588 solver.cpp:404]     Test net output #1: loss = 0.468949 (* 1 = 0.468949 loss)
I0314 14:40:49.116384 16588 solver.cpp:228] Iteration 67500, loss = 0.0889257
I0314 14:40:49.116881 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 14:40:49.116881 16588 solver.cpp:244]     Train net output #1: loss = 0.0889259 (* 1 = 0.0889259 loss)
I0314 14:40:49.116881 16588 sgd_solver.cpp:106] Iteration 67500, lr = 0.01
I0314 14:41:03.300135 16588 solver.cpp:228] Iteration 67600, loss = 0.076619
I0314 14:41:03.300135 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:41:03.300135 16588 solver.cpp:244]     Train net output #1: loss = 0.0766192 (* 1 = 0.0766192 loss)
I0314 14:41:03.300135 16588 sgd_solver.cpp:106] Iteration 67600, lr = 0.01
I0314 14:41:17.819170 16588 solver.cpp:228] Iteration 67700, loss = 0.0659617
I0314 14:41:17.819170 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:41:17.819170 16588 solver.cpp:244]     Train net output #1: loss = 0.0659619 (* 1 = 0.0659619 loss)
I0314 14:41:17.819170 16588 sgd_solver.cpp:106] Iteration 67700, lr = 0.01
I0314 14:41:32.261281 16588 solver.cpp:228] Iteration 67800, loss = 0.119816
I0314 14:41:32.261281 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:41:32.261281 16588 solver.cpp:244]     Train net output #1: loss = 0.119816 (* 1 = 0.119816 loss)
I0314 14:41:32.261780 16588 sgd_solver.cpp:106] Iteration 67800, lr = 0.01
I0314 14:41:46.782204 16588 solver.cpp:228] Iteration 67900, loss = 0.0307481
I0314 14:41:46.782204 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:41:46.782704 16588 solver.cpp:244]     Train net output #1: loss = 0.0307482 (* 1 = 0.0307482 loss)
I0314 14:41:46.782704 16588 sgd_solver.cpp:106] Iteration 67900, lr = 0.01
I0314 14:42:01.149024 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_68000.caffemodel
I0314 14:42:01.184022 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_68000.solverstate
I0314 14:42:01.190523 16588 solver.cpp:337] Iteration 68000, Testing net (#0)
I0314 14:42:01.191023 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:42:05.970655 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8563
I0314 14:42:05.970655 16588 solver.cpp:404]     Test net output #1: loss = 0.537371 (* 1 = 0.537371 loss)
I0314 14:42:06.020172 16588 solver.cpp:228] Iteration 68000, loss = 0.0577435
I0314 14:42:06.020172 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:42:06.020172 16588 solver.cpp:244]     Train net output #1: loss = 0.0577437 (* 1 = 0.0577437 loss)
I0314 14:42:06.020172 16588 sgd_solver.cpp:106] Iteration 68000, lr = 0.01
I0314 14:42:20.046473 16588 solver.cpp:228] Iteration 68100, loss = 0.0216287
I0314 14:42:20.046473 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:42:20.046473 16588 solver.cpp:244]     Train net output #1: loss = 0.0216288 (* 1 = 0.0216288 loss)
I0314 14:42:20.046473 16588 sgd_solver.cpp:106] Iteration 68100, lr = 0.01
I0314 14:42:34.466212 16588 solver.cpp:228] Iteration 68200, loss = 0.0626583
I0314 14:42:34.466212 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:42:34.466212 16588 solver.cpp:244]     Train net output #1: loss = 0.0626585 (* 1 = 0.0626585 loss)
I0314 14:42:34.466212 16588 sgd_solver.cpp:106] Iteration 68200, lr = 0.01
I0314 14:42:49.284204 16588 solver.cpp:228] Iteration 68300, loss = 0.0268623
I0314 14:42:49.284204 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:42:49.284204 16588 solver.cpp:244]     Train net output #1: loss = 0.0268624 (* 1 = 0.0268624 loss)
I0314 14:42:49.284204 16588 sgd_solver.cpp:106] Iteration 68300, lr = 0.01
I0314 14:43:03.990249 16588 solver.cpp:228] Iteration 68400, loss = 0.0325559
I0314 14:43:03.990249 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:43:03.990249 16588 solver.cpp:244]     Train net output #1: loss = 0.032556 (* 1 = 0.032556 loss)
I0314 14:43:03.990249 16588 sgd_solver.cpp:106] Iteration 68400, lr = 0.01
I0314 14:43:18.472802 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_68500.caffemodel
I0314 14:43:18.509302 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_68500.solverstate
I0314 14:43:18.515803 16588 solver.cpp:337] Iteration 68500, Testing net (#0)
I0314 14:43:18.515803 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:43:23.292985 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8632
I0314 14:43:23.292985 16588 solver.cpp:404]     Test net output #1: loss = 0.510775 (* 1 = 0.510775 loss)
I0314 14:43:23.369537 16588 solver.cpp:228] Iteration 68500, loss = 0.0412535
I0314 14:43:23.369537 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:43:23.369537 16588 solver.cpp:244]     Train net output #1: loss = 0.0412537 (* 1 = 0.0412537 loss)
I0314 14:43:23.369537 16588 sgd_solver.cpp:106] Iteration 68500, lr = 0.01
I0314 14:43:37.612083 16588 solver.cpp:228] Iteration 68600, loss = 0.0638249
I0314 14:43:37.612582 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:43:37.612582 16588 solver.cpp:244]     Train net output #1: loss = 0.063825 (* 1 = 0.063825 loss)
I0314 14:43:37.612582 16588 sgd_solver.cpp:106] Iteration 68600, lr = 0.01
I0314 14:43:52.118602 16588 solver.cpp:228] Iteration 68700, loss = 0.0431409
I0314 14:43:52.118602 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:43:52.118602 16588 solver.cpp:244]     Train net output #1: loss = 0.043141 (* 1 = 0.043141 loss)
I0314 14:43:52.118602 16588 sgd_solver.cpp:106] Iteration 68700, lr = 0.01
I0314 14:44:06.739346 16588 solver.cpp:228] Iteration 68800, loss = 0.0530967
I0314 14:44:06.739346 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:44:06.739346 16588 solver.cpp:244]     Train net output #1: loss = 0.0530968 (* 1 = 0.0530968 loss)
I0314 14:44:06.739346 16588 sgd_solver.cpp:106] Iteration 68800, lr = 0.01
I0314 14:44:21.182708 16588 solver.cpp:228] Iteration 68900, loss = 0.0455023
I0314 14:44:21.182708 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:44:21.182708 16588 solver.cpp:244]     Train net output #1: loss = 0.0455025 (* 1 = 0.0455025 loss)
I0314 14:44:21.182708 16588 sgd_solver.cpp:106] Iteration 68900, lr = 0.01
I0314 14:44:35.823781 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_69000.caffemodel
I0314 14:44:35.864781 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_69000.solverstate
I0314 14:44:35.870802 16588 solver.cpp:337] Iteration 69000, Testing net (#0)
I0314 14:44:35.870802 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:44:40.743703 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8727
I0314 14:44:40.743703 16588 solver.cpp:404]     Test net output #1: loss = 0.45623 (* 1 = 0.45623 loss)
I0314 14:44:40.825204 16588 solver.cpp:228] Iteration 69000, loss = 0.077231
I0314 14:44:40.825204 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:44:40.825204 16588 solver.cpp:244]     Train net output #1: loss = 0.0772311 (* 1 = 0.0772311 loss)
I0314 14:44:40.825204 16588 sgd_solver.cpp:106] Iteration 69000, lr = 0.01
I0314 14:44:55.060750 16588 solver.cpp:228] Iteration 69100, loss = 0.0932448
I0314 14:44:55.060750 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:44:55.060750 16588 solver.cpp:244]     Train net output #1: loss = 0.0932449 (* 1 = 0.0932449 loss)
I0314 14:44:55.060750 16588 sgd_solver.cpp:106] Iteration 69100, lr = 0.01
I0314 14:45:09.830265 16588 solver.cpp:228] Iteration 69200, loss = 0.0969034
I0314 14:45:09.830265 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:45:09.830265 16588 solver.cpp:244]     Train net output #1: loss = 0.0969035 (* 1 = 0.0969035 loss)
I0314 14:45:09.830265 16588 sgd_solver.cpp:106] Iteration 69200, lr = 0.01
I0314 14:45:24.522372 16588 solver.cpp:228] Iteration 69300, loss = 0.0743005
I0314 14:45:24.522372 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:45:24.522372 16588 solver.cpp:244]     Train net output #1: loss = 0.0743007 (* 1 = 0.0743007 loss)
I0314 14:45:24.522372 16588 sgd_solver.cpp:106] Iteration 69300, lr = 0.01
I0314 14:45:39.301328 16588 solver.cpp:228] Iteration 69400, loss = 0.0244652
I0314 14:45:39.301328 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:45:39.301328 16588 solver.cpp:244]     Train net output #1: loss = 0.0244654 (* 1 = 0.0244654 loss)
I0314 14:45:39.301328 16588 sgd_solver.cpp:106] Iteration 69400, lr = 0.01
I0314 14:45:53.955301 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_69500.caffemodel
I0314 14:45:53.994801 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_69500.solverstate
I0314 14:45:54.001302 16588 solver.cpp:337] Iteration 69500, Testing net (#0)
I0314 14:45:54.001302 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:45:58.846524 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8607
I0314 14:45:58.846524 16588 solver.cpp:404]     Test net output #1: loss = 0.545535 (* 1 = 0.545535 loss)
I0314 14:45:58.906550 16588 solver.cpp:228] Iteration 69500, loss = 0.0491999
I0314 14:45:58.906550 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:45:58.906550 16588 solver.cpp:244]     Train net output #1: loss = 0.0492001 (* 1 = 0.0492001 loss)
I0314 14:45:58.906550 16588 sgd_solver.cpp:106] Iteration 69500, lr = 0.01
I0314 14:46:13.239744 16588 solver.cpp:228] Iteration 69600, loss = 0.0359483
I0314 14:46:13.239744 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:46:13.239744 16588 solver.cpp:244]     Train net output #1: loss = 0.0359484 (* 1 = 0.0359484 loss)
I0314 14:46:13.239744 16588 sgd_solver.cpp:106] Iteration 69600, lr = 0.01
I0314 14:46:27.939612 16588 solver.cpp:228] Iteration 69700, loss = 0.0455055
I0314 14:46:27.939612 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:46:27.939612 16588 solver.cpp:244]     Train net output #1: loss = 0.0455056 (* 1 = 0.0455056 loss)
I0314 14:46:27.939612 16588 sgd_solver.cpp:106] Iteration 69700, lr = 0.01
I0314 14:46:42.819671 16588 solver.cpp:228] Iteration 69800, loss = 0.0741714
I0314 14:46:42.819671 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 14:46:42.819671 16588 solver.cpp:244]     Train net output #1: loss = 0.0741715 (* 1 = 0.0741715 loss)
I0314 14:46:42.819671 16588 sgd_solver.cpp:106] Iteration 69800, lr = 0.01
I0314 14:46:57.444989 16588 solver.cpp:228] Iteration 69900, loss = 0.0704755
I0314 14:46:57.444989 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:46:57.444989 16588 solver.cpp:244]     Train net output #1: loss = 0.0704756 (* 1 = 0.0704756 loss)
I0314 14:46:57.444989 16588 sgd_solver.cpp:106] Iteration 69900, lr = 0.01
I0314 14:47:11.915604 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_70000.caffemodel
I0314 14:47:11.930603 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_70000.solverstate
I0314 14:47:11.936107 16588 solver.cpp:337] Iteration 70000, Testing net (#0)
I0314 14:47:11.936107 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:47:16.807658 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8601
I0314 14:47:16.807658 16588 solver.cpp:404]     Test net output #1: loss = 0.540016 (* 1 = 0.540016 loss)
I0314 14:47:16.877679 16588 solver.cpp:228] Iteration 70000, loss = 0.105432
I0314 14:47:16.877679 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 14:47:16.877679 16588 solver.cpp:244]     Train net output #1: loss = 0.105432 (* 1 = 0.105432 loss)
I0314 14:47:16.877679 16588 sgd_solver.cpp:106] Iteration 70000, lr = 0.01
I0314 14:47:31.028012 16588 solver.cpp:228] Iteration 70100, loss = 0.0532086
I0314 14:47:31.028012 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:47:31.028012 16588 solver.cpp:244]     Train net output #1: loss = 0.0532087 (* 1 = 0.0532087 loss)
I0314 14:47:31.028012 16588 sgd_solver.cpp:106] Iteration 70100, lr = 0.01
I0314 14:47:45.620230 16588 solver.cpp:228] Iteration 70200, loss = 0.0587035
I0314 14:47:45.620230 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:47:45.620230 16588 solver.cpp:244]     Train net output #1: loss = 0.0587036 (* 1 = 0.0587036 loss)
I0314 14:47:45.620230 16588 sgd_solver.cpp:106] Iteration 70200, lr = 0.01
I0314 14:48:00.211258 16588 solver.cpp:228] Iteration 70300, loss = 0.116633
I0314 14:48:00.211258 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:48:00.211258 16588 solver.cpp:244]     Train net output #1: loss = 0.116633 (* 1 = 0.116633 loss)
I0314 14:48:00.211258 16588 sgd_solver.cpp:106] Iteration 70300, lr = 0.01
I0314 14:48:14.756482 16588 solver.cpp:228] Iteration 70400, loss = 0.0295604
I0314 14:48:14.756983 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:48:14.756983 16588 solver.cpp:244]     Train net output #1: loss = 0.0295605 (* 1 = 0.0295605 loss)
I0314 14:48:14.756983 16588 sgd_solver.cpp:106] Iteration 70400, lr = 0.01
I0314 14:48:29.311182 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_70500.caffemodel
I0314 14:48:29.347681 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_70500.solverstate
I0314 14:48:29.354181 16588 solver.cpp:337] Iteration 70500, Testing net (#0)
I0314 14:48:29.354181 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:48:34.370239 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8672
I0314 14:48:34.370239 16588 solver.cpp:404]     Test net output #1: loss = 0.528524 (* 1 = 0.528524 loss)
I0314 14:48:34.420240 16588 solver.cpp:228] Iteration 70500, loss = 0.0679756
I0314 14:48:34.420240 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:48:34.420240 16588 solver.cpp:244]     Train net output #1: loss = 0.0679758 (* 1 = 0.0679758 loss)
I0314 14:48:34.420240 16588 sgd_solver.cpp:106] Iteration 70500, lr = 0.01
I0314 14:48:48.712986 16588 solver.cpp:228] Iteration 70600, loss = 0.0695806
I0314 14:48:48.712986 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:48:48.712986 16588 solver.cpp:244]     Train net output #1: loss = 0.0695808 (* 1 = 0.0695808 loss)
I0314 14:48:48.712986 16588 sgd_solver.cpp:106] Iteration 70600, lr = 0.01
I0314 14:49:03.061640 16588 solver.cpp:228] Iteration 70700, loss = 0.104599
I0314 14:49:03.061640 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:49:03.061640 16588 solver.cpp:244]     Train net output #1: loss = 0.104599 (* 1 = 0.104599 loss)
I0314 14:49:03.061640 16588 sgd_solver.cpp:106] Iteration 70700, lr = 0.01
I0314 14:49:17.834836 16588 solver.cpp:228] Iteration 70800, loss = 0.0497406
I0314 14:49:17.834836 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:49:17.834836 16588 solver.cpp:244]     Train net output #1: loss = 0.0497408 (* 1 = 0.0497408 loss)
I0314 14:49:17.834836 16588 sgd_solver.cpp:106] Iteration 70800, lr = 0.01
I0314 14:49:32.484833 16588 solver.cpp:228] Iteration 70900, loss = 0.0588965
I0314 14:49:32.484833 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:49:32.484833 16588 solver.cpp:244]     Train net output #1: loss = 0.0588966 (* 1 = 0.0588966 loss)
I0314 14:49:32.484833 16588 sgd_solver.cpp:106] Iteration 70900, lr = 0.01
I0314 14:49:48.468479 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_71000.caffemodel
I0314 14:49:48.513480 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_71000.solverstate
I0314 14:49:48.520481 16588 solver.cpp:337] Iteration 71000, Testing net (#0)
I0314 14:49:48.520481 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:49:54.313961 16588 solver.cpp:404]     Test net output #0: accuracy = 0.866499
I0314 14:49:54.313961 16588 solver.cpp:404]     Test net output #1: loss = 0.502575 (* 1 = 0.502575 loss)
I0314 14:49:54.357465 16588 solver.cpp:228] Iteration 71000, loss = 0.0908691
I0314 14:49:54.357465 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:49:54.357465 16588 solver.cpp:244]     Train net output #1: loss = 0.0908692 (* 1 = 0.0908692 loss)
I0314 14:49:54.357465 16588 sgd_solver.cpp:106] Iteration 71000, lr = 0.01
I0314 14:50:09.585820 16588 solver.cpp:228] Iteration 71100, loss = 0.0352577
I0314 14:50:09.585820 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:50:09.585820 16588 solver.cpp:244]     Train net output #1: loss = 0.0352579 (* 1 = 0.0352579 loss)
I0314 14:50:09.585820 16588 sgd_solver.cpp:106] Iteration 71100, lr = 0.01
I0314 14:50:25.636245 16588 solver.cpp:228] Iteration 71200, loss = 0.124248
I0314 14:50:25.636245 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 14:50:25.636245 16588 solver.cpp:244]     Train net output #1: loss = 0.124248 (* 1 = 0.124248 loss)
I0314 14:50:25.636245 16588 sgd_solver.cpp:106] Iteration 71200, lr = 0.01
I0314 14:50:41.506456 16588 solver.cpp:228] Iteration 71300, loss = 0.0401689
I0314 14:50:41.506955 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:50:41.506955 16588 solver.cpp:244]     Train net output #1: loss = 0.040169 (* 1 = 0.040169 loss)
I0314 14:50:41.506955 16588 sgd_solver.cpp:106] Iteration 71300, lr = 0.01
I0314 14:50:57.315285 16588 solver.cpp:228] Iteration 71400, loss = 0.0418957
I0314 14:50:57.315285 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:50:57.315285 16588 solver.cpp:244]     Train net output #1: loss = 0.0418958 (* 1 = 0.0418958 loss)
I0314 14:50:57.315285 16588 sgd_solver.cpp:106] Iteration 71400, lr = 0.01
I0314 14:51:12.320052 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_71500.caffemodel
I0314 14:51:12.339051 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_71500.solverstate
I0314 14:51:12.345052 16588 solver.cpp:337] Iteration 71500, Testing net (#0)
I0314 14:51:12.345052 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:51:17.444504 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8611
I0314 14:51:17.444504 16588 solver.cpp:404]     Test net output #1: loss = 0.513212 (* 1 = 0.513212 loss)
I0314 14:51:17.539552 16588 solver.cpp:228] Iteration 71500, loss = 0.0360748
I0314 14:51:17.539552 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:51:17.539552 16588 solver.cpp:244]     Train net output #1: loss = 0.036075 (* 1 = 0.036075 loss)
I0314 14:51:17.539552 16588 sgd_solver.cpp:106] Iteration 71500, lr = 0.01
I0314 14:51:31.925657 16588 solver.cpp:228] Iteration 71600, loss = 0.0217172
I0314 14:51:31.925657 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:51:31.925657 16588 solver.cpp:244]     Train net output #1: loss = 0.0217173 (* 1 = 0.0217173 loss)
I0314 14:51:31.925657 16588 sgd_solver.cpp:106] Iteration 71600, lr = 0.01
I0314 14:51:46.650003 16588 solver.cpp:228] Iteration 71700, loss = 0.0274492
I0314 14:51:46.650003 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:51:46.650003 16588 solver.cpp:244]     Train net output #1: loss = 0.0274493 (* 1 = 0.0274493 loss)
I0314 14:51:46.650003 16588 sgd_solver.cpp:106] Iteration 71700, lr = 0.01
I0314 14:52:01.554209 16588 solver.cpp:228] Iteration 71800, loss = 0.0384428
I0314 14:52:01.554209 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:52:01.554209 16588 solver.cpp:244]     Train net output #1: loss = 0.038443 (* 1 = 0.038443 loss)
I0314 14:52:01.554209 16588 sgd_solver.cpp:106] Iteration 71800, lr = 0.01
I0314 14:52:16.693393 16588 solver.cpp:228] Iteration 71900, loss = 0.0379904
I0314 14:52:16.693393 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:52:16.693393 16588 solver.cpp:244]     Train net output #1: loss = 0.0379906 (* 1 = 0.0379906 loss)
I0314 14:52:16.693393 16588 sgd_solver.cpp:106] Iteration 71900, lr = 0.01
I0314 14:52:31.320425 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_72000.caffemodel
I0314 14:52:31.361104 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_72000.solverstate
I0314 14:52:31.366103 16588 solver.cpp:337] Iteration 72000, Testing net (#0)
I0314 14:52:31.366103 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:52:36.338992 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8429
I0314 14:52:36.338992 16588 solver.cpp:404]     Test net output #1: loss = 0.59145 (* 1 = 0.59145 loss)
I0314 14:52:36.374979 16588 solver.cpp:228] Iteration 72000, loss = 0.137622
I0314 14:52:36.374979 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 14:52:36.374979 16588 solver.cpp:244]     Train net output #1: loss = 0.137622 (* 1 = 0.137622 loss)
I0314 14:52:36.374979 16588 sgd_solver.cpp:106] Iteration 72000, lr = 0.01
I0314 14:52:50.712280 16588 solver.cpp:228] Iteration 72100, loss = 0.0655661
I0314 14:52:50.712280 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:52:50.712280 16588 solver.cpp:244]     Train net output #1: loss = 0.0655663 (* 1 = 0.0655663 loss)
I0314 14:52:50.712280 16588 sgd_solver.cpp:106] Iteration 72100, lr = 0.01
I0314 14:53:05.882683 16588 solver.cpp:228] Iteration 72200, loss = 0.0585985
I0314 14:53:05.882683 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:53:05.882683 16588 solver.cpp:244]     Train net output #1: loss = 0.0585987 (* 1 = 0.0585987 loss)
I0314 14:53:05.882683 16588 sgd_solver.cpp:106] Iteration 72200, lr = 0.01
I0314 14:53:21.316844 16588 solver.cpp:228] Iteration 72300, loss = 0.0983138
I0314 14:53:21.316844 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:53:21.316844 16588 solver.cpp:244]     Train net output #1: loss = 0.098314 (* 1 = 0.098314 loss)
I0314 14:53:21.316844 16588 sgd_solver.cpp:106] Iteration 72300, lr = 0.01
I0314 14:53:36.733713 16588 solver.cpp:228] Iteration 72400, loss = 0.0215021
I0314 14:53:36.734213 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:53:36.734213 16588 solver.cpp:244]     Train net output #1: loss = 0.0215022 (* 1 = 0.0215022 loss)
I0314 14:53:36.734213 16588 sgd_solver.cpp:106] Iteration 72400, lr = 0.01
I0314 14:53:51.755776 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_72500.caffemodel
I0314 14:53:51.795776 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_72500.solverstate
I0314 14:53:51.802289 16588 solver.cpp:337] Iteration 72500, Testing net (#0)
I0314 14:53:51.802289 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:53:57.091277 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8652
I0314 14:53:57.091277 16588 solver.cpp:404]     Test net output #1: loss = 0.516448 (* 1 = 0.516448 loss)
I0314 14:53:57.144275 16588 solver.cpp:228] Iteration 72500, loss = 0.110973
I0314 14:53:57.144275 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 14:53:57.144275 16588 solver.cpp:244]     Train net output #1: loss = 0.110974 (* 1 = 0.110974 loss)
I0314 14:53:57.144275 16588 sgd_solver.cpp:106] Iteration 72500, lr = 0.01
I0314 14:54:11.640173 16588 solver.cpp:228] Iteration 72600, loss = 0.0388848
I0314 14:54:11.640173 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:54:11.640173 16588 solver.cpp:244]     Train net output #1: loss = 0.038885 (* 1 = 0.038885 loss)
I0314 14:54:11.640173 16588 sgd_solver.cpp:106] Iteration 72600, lr = 0.01
I0314 14:54:27.077580 16588 solver.cpp:228] Iteration 72700, loss = 0.0356449
I0314 14:54:27.077580 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:54:27.077580 16588 solver.cpp:244]     Train net output #1: loss = 0.0356452 (* 1 = 0.0356452 loss)
I0314 14:54:27.077580 16588 sgd_solver.cpp:106] Iteration 72700, lr = 0.01
I0314 14:54:42.490149 16588 solver.cpp:228] Iteration 72800, loss = 0.0758039
I0314 14:54:42.490649 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:54:42.490649 16588 solver.cpp:244]     Train net output #1: loss = 0.0758041 (* 1 = 0.0758041 loss)
I0314 14:54:42.490649 16588 sgd_solver.cpp:106] Iteration 72800, lr = 0.01
I0314 14:54:57.704254 16588 solver.cpp:228] Iteration 72900, loss = 0.0343305
I0314 14:54:57.704254 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:54:57.704254 16588 solver.cpp:244]     Train net output #1: loss = 0.0343307 (* 1 = 0.0343307 loss)
I0314 14:54:57.704254 16588 sgd_solver.cpp:106] Iteration 72900, lr = 0.01
I0314 14:55:13.231622 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_73000.caffemodel
I0314 14:55:13.270622 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_73000.solverstate
I0314 14:55:13.277622 16588 solver.cpp:337] Iteration 73000, Testing net (#0)
I0314 14:55:13.277622 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:55:18.657156 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8579
I0314 14:55:18.657156 16588 solver.cpp:404]     Test net output #1: loss = 0.529799 (* 1 = 0.529799 loss)
I0314 14:55:18.705157 16588 solver.cpp:228] Iteration 73000, loss = 0.0639742
I0314 14:55:18.705157 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:55:18.705157 16588 solver.cpp:244]     Train net output #1: loss = 0.0639745 (* 1 = 0.0639745 loss)
I0314 14:55:18.705157 16588 sgd_solver.cpp:106] Iteration 73000, lr = 0.01
I0314 14:55:33.177795 16588 solver.cpp:228] Iteration 73100, loss = 0.0776673
I0314 14:55:33.177795 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:55:33.177795 16588 solver.cpp:244]     Train net output #1: loss = 0.0776675 (* 1 = 0.0776675 loss)
I0314 14:55:33.177795 16588 sgd_solver.cpp:106] Iteration 73100, lr = 0.01
I0314 14:55:48.662943 16588 solver.cpp:228] Iteration 73200, loss = 0.0550269
I0314 14:55:48.662943 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:55:48.662943 16588 solver.cpp:244]     Train net output #1: loss = 0.0550271 (* 1 = 0.0550271 loss)
I0314 14:55:48.662943 16588 sgd_solver.cpp:106] Iteration 73200, lr = 0.01
I0314 14:56:03.771733 16588 solver.cpp:228] Iteration 73300, loss = 0.0519439
I0314 14:56:03.771733 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:56:03.771733 16588 solver.cpp:244]     Train net output #1: loss = 0.0519441 (* 1 = 0.0519441 loss)
I0314 14:56:03.771733 16588 sgd_solver.cpp:106] Iteration 73300, lr = 0.01
I0314 14:56:19.109045 16588 solver.cpp:228] Iteration 73400, loss = 0.012152
I0314 14:56:19.109045 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:56:19.109045 16588 solver.cpp:244]     Train net output #1: loss = 0.0121522 (* 1 = 0.0121522 loss)
I0314 14:56:19.109045 16588 sgd_solver.cpp:106] Iteration 73400, lr = 0.01
I0314 14:56:34.309033 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_73500.caffemodel
I0314 14:56:34.328534 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_73500.solverstate
I0314 14:56:34.335536 16588 solver.cpp:337] Iteration 73500, Testing net (#0)
I0314 14:56:34.336055 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:56:39.572289 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8591
I0314 14:56:39.572789 16588 solver.cpp:404]     Test net output #1: loss = 0.51775 (* 1 = 0.51775 loss)
I0314 14:56:39.641798 16588 solver.cpp:228] Iteration 73500, loss = 0.0645867
I0314 14:56:39.641798 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:56:39.641798 16588 solver.cpp:244]     Train net output #1: loss = 0.064587 (* 1 = 0.064587 loss)
I0314 14:56:39.641798 16588 sgd_solver.cpp:106] Iteration 73500, lr = 0.01
I0314 14:56:54.736662 16588 solver.cpp:228] Iteration 73600, loss = 0.0321937
I0314 14:56:54.736662 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:56:54.736662 16588 solver.cpp:244]     Train net output #1: loss = 0.0321939 (* 1 = 0.0321939 loss)
I0314 14:56:54.736662 16588 sgd_solver.cpp:106] Iteration 73600, lr = 0.01
I0314 14:57:10.238824 16588 solver.cpp:228] Iteration 73700, loss = 0.0618041
I0314 14:57:10.239325 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 14:57:10.239325 16588 solver.cpp:244]     Train net output #1: loss = 0.0618043 (* 1 = 0.0618043 loss)
I0314 14:57:10.239325 16588 sgd_solver.cpp:106] Iteration 73700, lr = 0.01
I0314 14:57:25.694030 16588 solver.cpp:228] Iteration 73800, loss = 0.10172
I0314 14:57:25.694030 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:57:25.694030 16588 solver.cpp:244]     Train net output #1: loss = 0.10172 (* 1 = 0.10172 loss)
I0314 14:57:25.694030 16588 sgd_solver.cpp:106] Iteration 73800, lr = 0.01
I0314 14:57:40.866529 16588 solver.cpp:228] Iteration 73900, loss = 0.0197406
I0314 14:57:40.867032 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:57:40.867032 16588 solver.cpp:244]     Train net output #1: loss = 0.0197408 (* 1 = 0.0197408 loss)
I0314 14:57:40.867032 16588 sgd_solver.cpp:106] Iteration 73900, lr = 0.01
I0314 14:57:55.948148 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_74000.caffemodel
I0314 14:57:55.969148 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_74000.solverstate
I0314 14:57:55.975648 16588 solver.cpp:337] Iteration 74000, Testing net (#0)
I0314 14:57:55.975648 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:58:01.210149 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8712
I0314 14:58:01.210649 16588 solver.cpp:404]     Test net output #1: loss = 0.481896 (* 1 = 0.481896 loss)
I0314 14:58:01.253149 16588 solver.cpp:228] Iteration 74000, loss = 0.0510749
I0314 14:58:01.253648 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:58:01.253648 16588 solver.cpp:244]     Train net output #1: loss = 0.0510751 (* 1 = 0.0510751 loss)
I0314 14:58:01.253648 16588 sgd_solver.cpp:106] Iteration 74000, lr = 0.01
I0314 14:58:15.906664 16588 solver.cpp:228] Iteration 74100, loss = 0.0180607
I0314 14:58:15.906664 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 14:58:15.906664 16588 solver.cpp:244]     Train net output #1: loss = 0.018061 (* 1 = 0.018061 loss)
I0314 14:58:15.906664 16588 sgd_solver.cpp:106] Iteration 74100, lr = 0.01
I0314 14:58:31.412987 16588 solver.cpp:228] Iteration 74200, loss = 0.0582312
I0314 14:58:31.413487 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:58:31.413487 16588 solver.cpp:244]     Train net output #1: loss = 0.0582314 (* 1 = 0.0582314 loss)
I0314 14:58:31.413487 16588 sgd_solver.cpp:106] Iteration 74200, lr = 0.01
I0314 14:58:46.610157 16588 solver.cpp:228] Iteration 74300, loss = 0.0437541
I0314 14:58:46.610157 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:58:46.610157 16588 solver.cpp:244]     Train net output #1: loss = 0.0437543 (* 1 = 0.0437543 loss)
I0314 14:58:46.610157 16588 sgd_solver.cpp:106] Iteration 74300, lr = 0.01
I0314 14:59:01.914970 16588 solver.cpp:228] Iteration 74400, loss = 0.0412119
I0314 14:59:01.915480 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:59:01.915480 16588 solver.cpp:244]     Train net output #1: loss = 0.0412121 (* 1 = 0.0412121 loss)
I0314 14:59:01.915480 16588 sgd_solver.cpp:106] Iteration 74400, lr = 0.01
I0314 14:59:17.138965 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_74500.caffemodel
I0314 14:59:17.178967 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_74500.solverstate
I0314 14:59:17.184986 16588 solver.cpp:337] Iteration 74500, Testing net (#0)
I0314 14:59:17.185482 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 14:59:22.536466 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8657
I0314 14:59:22.536466 16588 solver.cpp:404]     Test net output #1: loss = 0.496071 (* 1 = 0.496071 loss)
I0314 14:59:22.579965 16588 solver.cpp:228] Iteration 74500, loss = 0.0486391
I0314 14:59:22.579965 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:59:22.580466 16588 solver.cpp:244]     Train net output #1: loss = 0.0486393 (* 1 = 0.0486393 loss)
I0314 14:59:22.580466 16588 sgd_solver.cpp:106] Iteration 74500, lr = 0.01
I0314 14:59:37.474220 16588 solver.cpp:228] Iteration 74600, loss = 0.0461755
I0314 14:59:37.474220 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 14:59:37.474220 16588 solver.cpp:244]     Train net output #1: loss = 0.0461757 (* 1 = 0.0461757 loss)
I0314 14:59:37.474220 16588 sgd_solver.cpp:106] Iteration 74600, lr = 0.01
I0314 14:59:52.738502 16588 solver.cpp:228] Iteration 74700, loss = 0.0361086
I0314 14:59:52.738502 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 14:59:52.738502 16588 solver.cpp:244]     Train net output #1: loss = 0.0361088 (* 1 = 0.0361088 loss)
I0314 14:59:52.738502 16588 sgd_solver.cpp:106] Iteration 74700, lr = 0.01
I0314 15:00:08.587831 16588 solver.cpp:228] Iteration 74800, loss = 0.0481673
I0314 15:00:08.587831 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:00:08.587831 16588 solver.cpp:244]     Train net output #1: loss = 0.0481674 (* 1 = 0.0481674 loss)
I0314 15:00:08.587831 16588 sgd_solver.cpp:106] Iteration 74800, lr = 0.01
I0314 15:00:23.718442 16588 solver.cpp:228] Iteration 74900, loss = 0.06242
I0314 15:00:23.718442 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:00:23.718442 16588 solver.cpp:244]     Train net output #1: loss = 0.0624202 (* 1 = 0.0624202 loss)
I0314 15:00:23.718442 16588 sgd_solver.cpp:106] Iteration 74900, lr = 0.01
I0314 15:00:38.728178 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_75000.caffemodel
I0314 15:00:38.755673 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_75000.solverstate
I0314 15:00:38.763173 16588 solver.cpp:337] Iteration 75000, Testing net (#0)
I0314 15:00:38.763173 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:00:44.138320 16588 solver.cpp:404]     Test net output #0: accuracy = 0.861
I0314 15:00:44.138320 16588 solver.cpp:404]     Test net output #1: loss = 0.526384 (* 1 = 0.526384 loss)
I0314 15:00:44.182818 16588 solver.cpp:228] Iteration 75000, loss = 0.060022
I0314 15:00:44.182818 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:00:44.182818 16588 solver.cpp:244]     Train net output #1: loss = 0.0600222 (* 1 = 0.0600222 loss)
I0314 15:00:44.182818 16588 sgd_solver.cpp:106] Iteration 75000, lr = 0.01
I0314 15:00:58.907178 16588 solver.cpp:228] Iteration 75100, loss = 0.0577416
I0314 15:00:58.907178 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:00:58.907178 16588 solver.cpp:244]     Train net output #1: loss = 0.0577418 (* 1 = 0.0577418 loss)
I0314 15:00:58.907178 16588 sgd_solver.cpp:106] Iteration 75100, lr = 0.01
I0314 15:01:14.054394 16588 solver.cpp:228] Iteration 75200, loss = 0.0361974
I0314 15:01:14.054394 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:01:14.054394 16588 solver.cpp:244]     Train net output #1: loss = 0.0361976 (* 1 = 0.0361976 loss)
I0314 15:01:14.054394 16588 sgd_solver.cpp:106] Iteration 75200, lr = 0.01
I0314 15:01:29.307394 16588 solver.cpp:228] Iteration 75300, loss = 0.0959118
I0314 15:01:29.307394 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:01:29.307394 16588 solver.cpp:244]     Train net output #1: loss = 0.095912 (* 1 = 0.095912 loss)
I0314 15:01:29.307394 16588 sgd_solver.cpp:106] Iteration 75300, lr = 0.01
I0314 15:01:45.033396 16588 solver.cpp:228] Iteration 75400, loss = 0.123528
I0314 15:01:45.033396 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:01:45.033396 16588 solver.cpp:244]     Train net output #1: loss = 0.123528 (* 1 = 0.123528 loss)
I0314 15:01:45.033396 16588 sgd_solver.cpp:106] Iteration 75400, lr = 0.01
I0314 15:02:00.218472 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_75500.caffemodel
I0314 15:02:00.257472 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_75500.solverstate
I0314 15:02:00.267488 16588 solver.cpp:337] Iteration 75500, Testing net (#0)
I0314 15:02:00.267488 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:02:05.419849 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8381
I0314 15:02:05.419849 16588 solver.cpp:404]     Test net output #1: loss = 0.609836 (* 1 = 0.609836 loss)
I0314 15:02:05.478848 16588 solver.cpp:228] Iteration 75500, loss = 0.0559173
I0314 15:02:05.478848 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:02:05.478848 16588 solver.cpp:244]     Train net output #1: loss = 0.0559175 (* 1 = 0.0559175 loss)
I0314 15:02:05.478848 16588 sgd_solver.cpp:106] Iteration 75500, lr = 0.01
I0314 15:02:20.139417 16588 solver.cpp:228] Iteration 75600, loss = 0.049842
I0314 15:02:20.139417 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:02:20.139417 16588 solver.cpp:244]     Train net output #1: loss = 0.0498421 (* 1 = 0.0498421 loss)
I0314 15:02:20.139417 16588 sgd_solver.cpp:106] Iteration 75600, lr = 0.01
I0314 15:02:35.183190 16588 solver.cpp:228] Iteration 75700, loss = 0.0687552
I0314 15:02:35.183691 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:02:35.183691 16588 solver.cpp:244]     Train net output #1: loss = 0.0687554 (* 1 = 0.0687554 loss)
I0314 15:02:35.183691 16588 sgd_solver.cpp:106] Iteration 75700, lr = 0.01
I0314 15:02:50.170495 16588 solver.cpp:228] Iteration 75800, loss = 0.0681911
I0314 15:02:50.170495 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:02:50.170495 16588 solver.cpp:244]     Train net output #1: loss = 0.0681912 (* 1 = 0.0681912 loss)
I0314 15:02:50.170495 16588 sgd_solver.cpp:106] Iteration 75800, lr = 0.01
I0314 15:03:05.202721 16588 solver.cpp:228] Iteration 75900, loss = 0.0358853
I0314 15:03:05.202721 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:03:05.202721 16588 solver.cpp:244]     Train net output #1: loss = 0.0358854 (* 1 = 0.0358854 loss)
I0314 15:03:05.202721 16588 sgd_solver.cpp:106] Iteration 75900, lr = 0.01
I0314 15:03:20.077890 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_76000.caffemodel
I0314 15:03:20.115895 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_76000.solverstate
I0314 15:03:20.121898 16588 solver.cpp:337] Iteration 76000, Testing net (#0)
I0314 15:03:20.121898 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:03:25.348371 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8526
I0314 15:03:25.348371 16588 solver.cpp:404]     Test net output #1: loss = 0.559192 (* 1 = 0.559192 loss)
I0314 15:03:25.398381 16588 solver.cpp:228] Iteration 76000, loss = 0.0675026
I0314 15:03:25.398381 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:03:25.398381 16588 solver.cpp:244]     Train net output #1: loss = 0.0675028 (* 1 = 0.0675028 loss)
I0314 15:03:25.398381 16588 sgd_solver.cpp:106] Iteration 76000, lr = 0.01
I0314 15:03:40.005715 16588 solver.cpp:228] Iteration 76100, loss = 0.0511967
I0314 15:03:40.006711 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:03:40.006711 16588 solver.cpp:244]     Train net output #1: loss = 0.0511969 (* 1 = 0.0511969 loss)
I0314 15:03:40.006711 16588 sgd_solver.cpp:106] Iteration 76100, lr = 0.01
I0314 15:03:55.033751 16588 solver.cpp:228] Iteration 76200, loss = 0.0363711
I0314 15:03:55.033751 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:03:55.033751 16588 solver.cpp:244]     Train net output #1: loss = 0.0363712 (* 1 = 0.0363712 loss)
I0314 15:03:55.033751 16588 sgd_solver.cpp:106] Iteration 76200, lr = 0.01
I0314 15:04:10.246031 16588 solver.cpp:228] Iteration 76300, loss = 0.0335027
I0314 15:04:10.246031 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:04:10.246031 16588 solver.cpp:244]     Train net output #1: loss = 0.0335028 (* 1 = 0.0335028 loss)
I0314 15:04:10.246031 16588 sgd_solver.cpp:106] Iteration 76300, lr = 0.01
I0314 15:04:25.185212 16588 solver.cpp:228] Iteration 76400, loss = 0.0364549
I0314 15:04:25.185212 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:04:25.185212 16588 solver.cpp:244]     Train net output #1: loss = 0.0364551 (* 1 = 0.0364551 loss)
I0314 15:04:25.185212 16588 sgd_solver.cpp:106] Iteration 76400, lr = 0.01
I0314 15:04:40.102617 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_76500.caffemodel
I0314 15:04:40.126616 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_76500.solverstate
I0314 15:04:40.132632 16588 solver.cpp:337] Iteration 76500, Testing net (#0)
I0314 15:04:40.132632 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:04:45.430150 16588 solver.cpp:404]     Test net output #0: accuracy = 0.866
I0314 15:04:45.430150 16588 solver.cpp:404]     Test net output #1: loss = 0.503628 (* 1 = 0.503628 loss)
I0314 15:04:45.482177 16588 solver.cpp:228] Iteration 76500, loss = 0.0188329
I0314 15:04:45.482177 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:04:45.482177 16588 solver.cpp:244]     Train net output #1: loss = 0.018833 (* 1 = 0.018833 loss)
I0314 15:04:45.482177 16588 sgd_solver.cpp:106] Iteration 76500, lr = 0.01
I0314 15:05:00.003724 16588 solver.cpp:228] Iteration 76600, loss = 0.0453287
I0314 15:05:00.003724 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:05:00.003724 16588 solver.cpp:244]     Train net output #1: loss = 0.0453288 (* 1 = 0.0453288 loss)
I0314 15:05:00.003724 16588 sgd_solver.cpp:106] Iteration 76600, lr = 0.01
I0314 15:05:15.038885 16588 solver.cpp:228] Iteration 76700, loss = 0.0560508
I0314 15:05:15.039386 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:05:15.039386 16588 solver.cpp:244]     Train net output #1: loss = 0.0560509 (* 1 = 0.0560509 loss)
I0314 15:05:15.039386 16588 sgd_solver.cpp:106] Iteration 76700, lr = 0.01
I0314 15:05:30.051918 16588 solver.cpp:228] Iteration 76800, loss = 0.126535
I0314 15:05:30.051918 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:05:30.051918 16588 solver.cpp:244]     Train net output #1: loss = 0.126535 (* 1 = 0.126535 loss)
I0314 15:05:30.051918 16588 sgd_solver.cpp:106] Iteration 76800, lr = 0.01
I0314 15:05:45.112660 16588 solver.cpp:228] Iteration 76900, loss = 0.0459044
I0314 15:05:45.112660 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:05:45.112660 16588 solver.cpp:244]     Train net output #1: loss = 0.0459045 (* 1 = 0.0459045 loss)
I0314 15:05:45.112660 16588 sgd_solver.cpp:106] Iteration 76900, lr = 0.01
I0314 15:06:00.026208 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_77000.caffemodel
I0314 15:06:00.050953 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_77000.solverstate
I0314 15:06:00.056974 16588 solver.cpp:337] Iteration 77000, Testing net (#0)
I0314 15:06:00.056974 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:06:05.324398 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8616
I0314 15:06:05.324398 16588 solver.cpp:404]     Test net output #1: loss = 0.524796 (* 1 = 0.524796 loss)
I0314 15:06:05.379408 16588 solver.cpp:228] Iteration 77000, loss = 0.0621646
I0314 15:06:05.379408 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:06:05.379408 16588 solver.cpp:244]     Train net output #1: loss = 0.0621647 (* 1 = 0.0621647 loss)
I0314 15:06:05.379408 16588 sgd_solver.cpp:106] Iteration 77000, lr = 0.01
I0314 15:06:19.926645 16588 solver.cpp:228] Iteration 77100, loss = 0.0320204
I0314 15:06:19.926645 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:06:19.926645 16588 solver.cpp:244]     Train net output #1: loss = 0.0320204 (* 1 = 0.0320204 loss)
I0314 15:06:19.926645 16588 sgd_solver.cpp:106] Iteration 77100, lr = 0.01
I0314 15:06:35.132040 16588 solver.cpp:228] Iteration 77200, loss = 0.0743222
I0314 15:06:35.132040 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:06:35.132040 16588 solver.cpp:244]     Train net output #1: loss = 0.0743223 (* 1 = 0.0743223 loss)
I0314 15:06:35.132040 16588 sgd_solver.cpp:106] Iteration 77200, lr = 0.01
I0314 15:06:50.118487 16588 solver.cpp:228] Iteration 77300, loss = 0.083566
I0314 15:06:50.118487 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 15:06:50.118487 16588 solver.cpp:244]     Train net output #1: loss = 0.083566 (* 1 = 0.083566 loss)
I0314 15:06:50.118487 16588 sgd_solver.cpp:106] Iteration 77300, lr = 0.01
I0314 15:07:05.311830 16588 solver.cpp:228] Iteration 77400, loss = 0.09028
I0314 15:07:05.311830 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:07:05.311830 16588 solver.cpp:244]     Train net output #1: loss = 0.0902801 (* 1 = 0.0902801 loss)
I0314 15:07:05.311830 16588 sgd_solver.cpp:106] Iteration 77400, lr = 0.01
I0314 15:07:20.465250 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_77500.caffemodel
I0314 15:07:20.485905 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_77500.solverstate
I0314 15:07:20.491927 16588 solver.cpp:337] Iteration 77500, Testing net (#0)
I0314 15:07:20.491927 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:07:25.656030 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8578
I0314 15:07:25.656030 16588 solver.cpp:404]     Test net output #1: loss = 0.563591 (* 1 = 0.563591 loss)
I0314 15:07:25.693756 16588 solver.cpp:228] Iteration 77500, loss = 0.157924
I0314 15:07:25.693756 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:07:25.693756 16588 solver.cpp:244]     Train net output #1: loss = 0.157924 (* 1 = 0.157924 loss)
I0314 15:07:25.693756 16588 sgd_solver.cpp:106] Iteration 77500, lr = 0.01
I0314 15:07:40.166437 16588 solver.cpp:228] Iteration 77600, loss = 0.0304959
I0314 15:07:40.166437 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:07:40.166437 16588 solver.cpp:244]     Train net output #1: loss = 0.030496 (* 1 = 0.030496 loss)
I0314 15:07:40.166437 16588 sgd_solver.cpp:106] Iteration 77600, lr = 0.01
I0314 15:07:55.739481 16588 solver.cpp:228] Iteration 77700, loss = 0.0345207
I0314 15:07:55.739481 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:07:55.739481 16588 solver.cpp:244]     Train net output #1: loss = 0.0345207 (* 1 = 0.0345207 loss)
I0314 15:07:55.739481 16588 sgd_solver.cpp:106] Iteration 77700, lr = 0.01
I0314 15:08:10.961511 16588 solver.cpp:228] Iteration 77800, loss = 0.0826976
I0314 15:08:10.961511 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:08:10.961511 16588 solver.cpp:244]     Train net output #1: loss = 0.0826976 (* 1 = 0.0826976 loss)
I0314 15:08:10.961511 16588 sgd_solver.cpp:106] Iteration 77800, lr = 0.01
I0314 15:08:26.267158 16588 solver.cpp:228] Iteration 77900, loss = 0.0618981
I0314 15:08:26.267158 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:08:26.267158 16588 solver.cpp:244]     Train net output #1: loss = 0.0618981 (* 1 = 0.0618981 loss)
I0314 15:08:26.267158 16588 sgd_solver.cpp:106] Iteration 77900, lr = 0.01
I0314 15:08:41.084728 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_78000.caffemodel
I0314 15:08:41.123726 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_78000.solverstate
I0314 15:08:41.130726 16588 solver.cpp:337] Iteration 78000, Testing net (#0)
I0314 15:08:41.130726 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:08:46.289248 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8696
I0314 15:08:46.290248 16588 solver.cpp:404]     Test net output #1: loss = 0.483381 (* 1 = 0.483381 loss)
I0314 15:08:46.346249 16588 solver.cpp:228] Iteration 78000, loss = 0.130811
I0314 15:08:46.346249 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 15:08:46.346249 16588 solver.cpp:244]     Train net output #1: loss = 0.130811 (* 1 = 0.130811 loss)
I0314 15:08:46.346249 16588 sgd_solver.cpp:106] Iteration 78000, lr = 0.01
I0314 15:09:00.902420 16588 solver.cpp:228] Iteration 78100, loss = 0.0705867
I0314 15:09:00.902420 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:09:00.902420 16588 solver.cpp:244]     Train net output #1: loss = 0.0705867 (* 1 = 0.0705867 loss)
I0314 15:09:00.902420 16588 sgd_solver.cpp:106] Iteration 78100, lr = 0.01
I0314 15:09:15.779752 16588 solver.cpp:228] Iteration 78200, loss = 0.0500754
I0314 15:09:15.779752 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:09:15.779752 16588 solver.cpp:244]     Train net output #1: loss = 0.0500754 (* 1 = 0.0500754 loss)
I0314 15:09:15.779752 16588 sgd_solver.cpp:106] Iteration 78200, lr = 0.01
I0314 15:09:30.821291 16588 solver.cpp:228] Iteration 78300, loss = 0.0662116
I0314 15:09:30.821291 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:09:30.821291 16588 solver.cpp:244]     Train net output #1: loss = 0.0662116 (* 1 = 0.0662116 loss)
I0314 15:09:30.821291 16588 sgd_solver.cpp:106] Iteration 78300, lr = 0.01
I0314 15:09:46.003367 16588 solver.cpp:228] Iteration 78400, loss = 0.0473485
I0314 15:09:46.003367 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:09:46.003367 16588 solver.cpp:244]     Train net output #1: loss = 0.0473485 (* 1 = 0.0473485 loss)
I0314 15:09:46.003367 16588 sgd_solver.cpp:106] Iteration 78400, lr = 0.01
I0314 15:10:00.892895 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_78500.caffemodel
I0314 15:10:00.913897 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_78500.solverstate
I0314 15:10:00.920894 16588 solver.cpp:337] Iteration 78500, Testing net (#0)
I0314 15:10:00.920894 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:10:06.086526 16588 solver.cpp:404]     Test net output #0: accuracy = 0.86
I0314 15:10:06.086526 16588 solver.cpp:404]     Test net output #1: loss = 0.545621 (* 1 = 0.545621 loss)
I0314 15:10:06.131523 16588 solver.cpp:228] Iteration 78500, loss = 0.0849998
I0314 15:10:06.131523 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:10:06.131523 16588 solver.cpp:244]     Train net output #1: loss = 0.0849998 (* 1 = 0.0849998 loss)
I0314 15:10:06.131523 16588 sgd_solver.cpp:106] Iteration 78500, lr = 0.01
I0314 15:10:20.483820 16588 solver.cpp:228] Iteration 78600, loss = 0.0542203
I0314 15:10:20.484820 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:10:20.484820 16588 solver.cpp:244]     Train net output #1: loss = 0.0542202 (* 1 = 0.0542202 loss)
I0314 15:10:20.484820 16588 sgd_solver.cpp:106] Iteration 78600, lr = 0.01
I0314 15:10:35.853852 16588 solver.cpp:228] Iteration 78700, loss = 0.105717
I0314 15:10:35.853852 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:10:35.853852 16588 solver.cpp:244]     Train net output #1: loss = 0.105717 (* 1 = 0.105717 loss)
I0314 15:10:35.853852 16588 sgd_solver.cpp:106] Iteration 78700, lr = 0.01
I0314 15:10:51.190470 16588 solver.cpp:228] Iteration 78800, loss = 0.0652614
I0314 15:10:51.190470 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:10:51.190470 16588 solver.cpp:244]     Train net output #1: loss = 0.0652614 (* 1 = 0.0652614 loss)
I0314 15:10:51.190470 16588 sgd_solver.cpp:106] Iteration 78800, lr = 0.01
I0314 15:11:06.632720 16588 solver.cpp:228] Iteration 78900, loss = 0.0309459
I0314 15:11:06.632720 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:11:06.632720 16588 solver.cpp:244]     Train net output #1: loss = 0.0309459 (* 1 = 0.0309459 loss)
I0314 15:11:06.632720 16588 sgd_solver.cpp:106] Iteration 78900, lr = 0.01
I0314 15:11:21.878870 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_79000.caffemodel
I0314 15:11:21.917870 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_79000.solverstate
I0314 15:11:21.923868 16588 solver.cpp:337] Iteration 79000, Testing net (#0)
I0314 15:11:21.923868 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:11:27.268021 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8611
I0314 15:11:27.268021 16588 solver.cpp:404]     Test net output #1: loss = 0.543416 (* 1 = 0.543416 loss)
I0314 15:11:27.298130 16588 solver.cpp:228] Iteration 79000, loss = 0.0359433
I0314 15:11:27.298130 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:11:27.298130 16588 solver.cpp:244]     Train net output #1: loss = 0.0359433 (* 1 = 0.0359433 loss)
I0314 15:11:27.298130 16588 sgd_solver.cpp:106] Iteration 79000, lr = 0.01
I0314 15:11:41.755862 16588 solver.cpp:228] Iteration 79100, loss = 0.036803
I0314 15:11:41.755862 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:11:41.755862 16588 solver.cpp:244]     Train net output #1: loss = 0.036803 (* 1 = 0.036803 loss)
I0314 15:11:41.755862 16588 sgd_solver.cpp:106] Iteration 79100, lr = 0.01
I0314 15:11:57.001960 16588 solver.cpp:228] Iteration 79200, loss = 0.0555772
I0314 15:11:57.001960 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:11:57.001960 16588 solver.cpp:244]     Train net output #1: loss = 0.0555771 (* 1 = 0.0555771 loss)
I0314 15:11:57.001960 16588 sgd_solver.cpp:106] Iteration 79200, lr = 0.01
I0314 15:12:12.392243 16588 solver.cpp:228] Iteration 79300, loss = 0.0953511
I0314 15:12:12.392243 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:12:12.392243 16588 solver.cpp:244]     Train net output #1: loss = 0.0953511 (* 1 = 0.0953511 loss)
I0314 15:12:12.392243 16588 sgd_solver.cpp:106] Iteration 79300, lr = 0.01
I0314 15:12:27.342165 16588 solver.cpp:228] Iteration 79400, loss = 0.0228047
I0314 15:12:27.342165 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:12:27.342165 16588 solver.cpp:244]     Train net output #1: loss = 0.0228047 (* 1 = 0.0228047 loss)
I0314 15:12:27.342165 16588 sgd_solver.cpp:106] Iteration 79400, lr = 0.01
I0314 15:12:42.177992 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_79500.caffemodel
I0314 15:12:42.218989 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_79500.solverstate
I0314 15:12:42.227494 16588 solver.cpp:337] Iteration 79500, Testing net (#0)
I0314 15:12:42.227494 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:12:47.824110 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8379
I0314 15:12:47.824110 16588 solver.cpp:404]     Test net output #1: loss = 0.646875 (* 1 = 0.646875 loss)
I0314 15:12:47.894613 16588 solver.cpp:228] Iteration 79500, loss = 0.0584967
I0314 15:12:47.894613 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:12:47.894613 16588 solver.cpp:244]     Train net output #1: loss = 0.0584966 (* 1 = 0.0584966 loss)
I0314 15:12:47.894613 16588 sgd_solver.cpp:106] Iteration 79500, lr = 0.01
I0314 15:13:02.522281 16588 solver.cpp:228] Iteration 79600, loss = 0.0938859
I0314 15:13:02.522281 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:13:02.522281 16588 solver.cpp:244]     Train net output #1: loss = 0.0938859 (* 1 = 0.0938859 loss)
I0314 15:13:02.522281 16588 sgd_solver.cpp:106] Iteration 79600, lr = 0.01
I0314 15:13:17.958894 16588 solver.cpp:228] Iteration 79700, loss = 0.05577
I0314 15:13:17.959873 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:13:17.959873 16588 solver.cpp:244]     Train net output #1: loss = 0.05577 (* 1 = 0.05577 loss)
I0314 15:13:17.959873 16588 sgd_solver.cpp:106] Iteration 79700, lr = 0.01
I0314 15:13:33.041426 16588 solver.cpp:228] Iteration 79800, loss = 0.0489639
I0314 15:13:33.041926 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:13:33.041926 16588 solver.cpp:244]     Train net output #1: loss = 0.0489639 (* 1 = 0.0489639 loss)
I0314 15:13:33.041926 16588 sgd_solver.cpp:106] Iteration 79800, lr = 0.01
I0314 15:13:47.363802 16588 solver.cpp:228] Iteration 79900, loss = 0.0577277
I0314 15:13:47.363802 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:13:47.363802 16588 solver.cpp:244]     Train net output #1: loss = 0.0577276 (* 1 = 0.0577276 loss)
I0314 15:13:47.363802 16588 sgd_solver.cpp:106] Iteration 79900, lr = 0.01
I0314 15:14:01.834645 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_80000.caffemodel
I0314 15:14:01.873143 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_80000.solverstate
I0314 15:14:01.880143 16588 solver.cpp:337] Iteration 80000, Testing net (#0)
I0314 15:14:01.880643 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:14:06.954669 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8628
I0314 15:14:06.954669 16588 solver.cpp:404]     Test net output #1: loss = 0.521957 (* 1 = 0.521957 loss)
I0314 15:14:06.991669 16588 solver.cpp:228] Iteration 80000, loss = 0.0423681
I0314 15:14:06.991669 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:14:06.991669 16588 solver.cpp:244]     Train net output #1: loss = 0.042368 (* 1 = 0.042368 loss)
I0314 15:14:06.991669 16588 sgd_solver.cpp:106] Iteration 80000, lr = 0.01
I0314 15:14:21.224702 16588 solver.cpp:228] Iteration 80100, loss = 0.0387772
I0314 15:14:21.224702 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:14:21.224702 16588 solver.cpp:244]     Train net output #1: loss = 0.0387771 (* 1 = 0.0387771 loss)
I0314 15:14:21.224702 16588 sgd_solver.cpp:106] Iteration 80100, lr = 0.01
I0314 15:14:35.501410 16588 solver.cpp:228] Iteration 80200, loss = 0.0846852
I0314 15:14:35.501410 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:14:35.501410 16588 solver.cpp:244]     Train net output #1: loss = 0.0846851 (* 1 = 0.0846851 loss)
I0314 15:14:35.501410 16588 sgd_solver.cpp:106] Iteration 80200, lr = 0.01
I0314 15:14:49.779832 16588 solver.cpp:228] Iteration 80300, loss = 0.101769
I0314 15:14:49.779832 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:14:49.780331 16588 solver.cpp:244]     Train net output #1: loss = 0.101769 (* 1 = 0.101769 loss)
I0314 15:14:49.780331 16588 sgd_solver.cpp:106] Iteration 80300, lr = 0.01
I0314 15:15:04.494467 16588 solver.cpp:228] Iteration 80400, loss = 0.0346824
I0314 15:15:04.494966 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:15:04.494966 16588 solver.cpp:244]     Train net output #1: loss = 0.0346823 (* 1 = 0.0346823 loss)
I0314 15:15:04.494966 16588 sgd_solver.cpp:106] Iteration 80400, lr = 0.01
I0314 15:15:18.905191 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_80500.caffemodel
I0314 15:15:18.942190 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_80500.solverstate
I0314 15:15:18.949692 16588 solver.cpp:337] Iteration 80500, Testing net (#0)
I0314 15:15:18.949692 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:15:24.053190 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8634
I0314 15:15:24.053190 16588 solver.cpp:404]     Test net output #1: loss = 0.505506 (* 1 = 0.505506 loss)
I0314 15:15:24.120190 16588 solver.cpp:228] Iteration 80500, loss = 0.0804709
I0314 15:15:24.120190 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:15:24.120190 16588 solver.cpp:244]     Train net output #1: loss = 0.0804708 (* 1 = 0.0804708 loss)
I0314 15:15:24.120190 16588 sgd_solver.cpp:106] Iteration 80500, lr = 0.01
I0314 15:15:38.185281 16588 solver.cpp:228] Iteration 80600, loss = 0.0536767
I0314 15:15:38.185777 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:15:38.185777 16588 solver.cpp:244]     Train net output #1: loss = 0.0536766 (* 1 = 0.0536766 loss)
I0314 15:15:38.185777 16588 sgd_solver.cpp:106] Iteration 80600, lr = 0.01
I0314 15:15:52.867614 16588 solver.cpp:228] Iteration 80700, loss = 0.0424218
I0314 15:15:52.867614 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:15:52.867614 16588 solver.cpp:244]     Train net output #1: loss = 0.0424216 (* 1 = 0.0424216 loss)
I0314 15:15:52.867614 16588 sgd_solver.cpp:106] Iteration 80700, lr = 0.01
I0314 15:16:07.135855 16588 solver.cpp:228] Iteration 80800, loss = 0.0670569
I0314 15:16:07.135855 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:16:07.135855 16588 solver.cpp:244]     Train net output #1: loss = 0.0670568 (* 1 = 0.0670568 loss)
I0314 15:16:07.135855 16588 sgd_solver.cpp:106] Iteration 80800, lr = 0.01
I0314 15:16:21.928397 16588 solver.cpp:228] Iteration 80900, loss = 0.0325976
I0314 15:16:21.928397 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:16:21.928397 16588 solver.cpp:244]     Train net output #1: loss = 0.0325975 (* 1 = 0.0325975 loss)
I0314 15:16:21.928397 16588 sgd_solver.cpp:106] Iteration 80900, lr = 0.01
I0314 15:16:36.328579 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_81000.caffemodel
I0314 15:16:36.370579 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_81000.solverstate
I0314 15:16:36.380079 16588 solver.cpp:337] Iteration 81000, Testing net (#0)
I0314 15:16:36.380079 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:16:41.561040 16588 solver.cpp:404]     Test net output #0: accuracy = 0.853
I0314 15:16:41.561040 16588 solver.cpp:404]     Test net output #1: loss = 0.551646 (* 1 = 0.551646 loss)
I0314 15:16:41.626039 16588 solver.cpp:228] Iteration 81000, loss = 0.0983534
I0314 15:16:41.626039 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:16:41.626039 16588 solver.cpp:244]     Train net output #1: loss = 0.0983533 (* 1 = 0.0983533 loss)
I0314 15:16:41.626039 16588 sgd_solver.cpp:106] Iteration 81000, lr = 0.01
I0314 15:16:55.745064 16588 solver.cpp:228] Iteration 81100, loss = 0.0806858
I0314 15:16:55.745556 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:16:55.745556 16588 solver.cpp:244]     Train net output #1: loss = 0.0806857 (* 1 = 0.0806857 loss)
I0314 15:16:55.745556 16588 sgd_solver.cpp:106] Iteration 81100, lr = 0.01
I0314 15:17:10.202082 16588 solver.cpp:228] Iteration 81200, loss = 0.0461654
I0314 15:17:10.202581 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:17:10.202581 16588 solver.cpp:244]     Train net output #1: loss = 0.0461652 (* 1 = 0.0461652 loss)
I0314 15:17:10.202581 16588 sgd_solver.cpp:106] Iteration 81200, lr = 0.01
I0314 15:17:24.928632 16588 solver.cpp:228] Iteration 81300, loss = 0.0846066
I0314 15:17:24.928632 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:17:24.928632 16588 solver.cpp:244]     Train net output #1: loss = 0.0846064 (* 1 = 0.0846064 loss)
I0314 15:17:24.928632 16588 sgd_solver.cpp:106] Iteration 81300, lr = 0.01
I0314 15:17:39.464807 16588 solver.cpp:228] Iteration 81400, loss = 0.0348877
I0314 15:17:39.464807 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:17:39.464807 16588 solver.cpp:244]     Train net output #1: loss = 0.0348876 (* 1 = 0.0348876 loss)
I0314 15:17:39.464807 16588 sgd_solver.cpp:106] Iteration 81400, lr = 0.01
I0314 15:17:54.014068 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_81500.caffemodel
I0314 15:17:54.055069 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_81500.solverstate
I0314 15:17:54.062069 16588 solver.cpp:337] Iteration 81500, Testing net (#0)
I0314 15:17:54.062069 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:17:59.154069 16588 solver.cpp:404]     Test net output #0: accuracy = 0.835
I0314 15:17:59.154069 16588 solver.cpp:404]     Test net output #1: loss = 0.625984 (* 1 = 0.625984 loss)
I0314 15:17:59.197572 16588 solver.cpp:228] Iteration 81500, loss = 0.0609709
I0314 15:17:59.197572 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:17:59.197572 16588 solver.cpp:244]     Train net output #1: loss = 0.0609708 (* 1 = 0.0609708 loss)
I0314 15:17:59.197572 16588 sgd_solver.cpp:106] Iteration 81500, lr = 0.01
I0314 15:18:13.153035 16588 solver.cpp:228] Iteration 81600, loss = 0.142101
I0314 15:18:13.153035 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 15:18:13.153035 16588 solver.cpp:244]     Train net output #1: loss = 0.142101 (* 1 = 0.142101 loss)
I0314 15:18:13.153035 16588 sgd_solver.cpp:106] Iteration 81600, lr = 0.01
I0314 15:18:27.624100 16588 solver.cpp:228] Iteration 81700, loss = 0.0604715
I0314 15:18:27.624100 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:18:27.624100 16588 solver.cpp:244]     Train net output #1: loss = 0.0604714 (* 1 = 0.0604714 loss)
I0314 15:18:27.624100 16588 sgd_solver.cpp:106] Iteration 81700, lr = 0.01
I0314 15:18:42.230640 16588 solver.cpp:228] Iteration 81800, loss = 0.047135
I0314 15:18:42.230640 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:18:42.230640 16588 solver.cpp:244]     Train net output #1: loss = 0.0471348 (* 1 = 0.0471348 loss)
I0314 15:18:42.230640 16588 sgd_solver.cpp:106] Iteration 81800, lr = 0.01
I0314 15:18:57.056460 16588 solver.cpp:228] Iteration 81900, loss = 0.051715
I0314 15:18:57.056460 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:18:57.056460 16588 solver.cpp:244]     Train net output #1: loss = 0.0517148 (* 1 = 0.0517148 loss)
I0314 15:18:57.056460 16588 sgd_solver.cpp:106] Iteration 81900, lr = 0.01
I0314 15:19:11.764621 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_82000.caffemodel
I0314 15:19:11.801620 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_82000.solverstate
I0314 15:19:11.808621 16588 solver.cpp:337] Iteration 82000, Testing net (#0)
I0314 15:19:11.808621 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:19:17.005789 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8605
I0314 15:19:17.005789 16588 solver.cpp:404]     Test net output #1: loss = 0.533723 (* 1 = 0.533723 loss)
I0314 15:19:17.059412 16588 solver.cpp:228] Iteration 82000, loss = 0.0648501
I0314 15:19:17.059412 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:19:17.059412 16588 solver.cpp:244]     Train net output #1: loss = 0.0648499 (* 1 = 0.0648499 loss)
I0314 15:19:17.059412 16588 sgd_solver.cpp:106] Iteration 82000, lr = 0.01
I0314 15:19:31.296572 16588 solver.cpp:228] Iteration 82100, loss = 0.0216485
I0314 15:19:31.296572 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:19:31.296572 16588 solver.cpp:244]     Train net output #1: loss = 0.0216483 (* 1 = 0.0216483 loss)
I0314 15:19:31.296572 16588 sgd_solver.cpp:106] Iteration 82100, lr = 0.01
I0314 15:19:45.859930 16588 solver.cpp:228] Iteration 82200, loss = 0.052419
I0314 15:19:45.859930 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:19:45.859930 16588 solver.cpp:244]     Train net output #1: loss = 0.0524189 (* 1 = 0.0524189 loss)
I0314 15:19:45.859930 16588 sgd_solver.cpp:106] Iteration 82200, lr = 0.01
I0314 15:20:00.378105 16588 solver.cpp:228] Iteration 82300, loss = 0.0550973
I0314 15:20:00.378105 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:20:00.378105 16588 solver.cpp:244]     Train net output #1: loss = 0.0550971 (* 1 = 0.0550971 loss)
I0314 15:20:00.378105 16588 sgd_solver.cpp:106] Iteration 82300, lr = 0.01
I0314 15:20:14.954519 16588 solver.cpp:228] Iteration 82400, loss = 0.0405506
I0314 15:20:14.954519 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:20:14.954519 16588 solver.cpp:244]     Train net output #1: loss = 0.0405505 (* 1 = 0.0405505 loss)
I0314 15:20:14.954519 16588 sgd_solver.cpp:106] Iteration 82400, lr = 0.01
I0314 15:20:29.500047 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_82500.caffemodel
I0314 15:20:29.544036 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_82500.solverstate
I0314 15:20:29.549537 16588 solver.cpp:337] Iteration 82500, Testing net (#0)
I0314 15:20:29.549537 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:20:34.421571 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8651
I0314 15:20:34.421571 16588 solver.cpp:404]     Test net output #1: loss = 0.515166 (* 1 = 0.515166 loss)
I0314 15:20:34.471617 16588 solver.cpp:228] Iteration 82500, loss = 0.0606909
I0314 15:20:34.471617 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:20:34.471617 16588 solver.cpp:244]     Train net output #1: loss = 0.0606908 (* 1 = 0.0606908 loss)
I0314 15:20:34.471617 16588 sgd_solver.cpp:106] Iteration 82500, lr = 0.01
I0314 15:20:48.626936 16588 solver.cpp:228] Iteration 82600, loss = 0.0820847
I0314 15:20:48.626936 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:20:48.626936 16588 solver.cpp:244]     Train net output #1: loss = 0.0820846 (* 1 = 0.0820846 loss)
I0314 15:20:48.626936 16588 sgd_solver.cpp:106] Iteration 82600, lr = 0.01
I0314 15:21:03.197623 16588 solver.cpp:228] Iteration 82700, loss = 0.0429749
I0314 15:21:03.197623 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:21:03.197623 16588 solver.cpp:244]     Train net output #1: loss = 0.0429749 (* 1 = 0.0429749 loss)
I0314 15:21:03.197623 16588 sgd_solver.cpp:106] Iteration 82700, lr = 0.01
I0314 15:21:17.704375 16588 solver.cpp:228] Iteration 82800, loss = 0.0746112
I0314 15:21:17.704871 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:21:17.704871 16588 solver.cpp:244]     Train net output #1: loss = 0.0746111 (* 1 = 0.0746111 loss)
I0314 15:21:17.704871 16588 sgd_solver.cpp:106] Iteration 82800, lr = 0.01
I0314 15:21:32.289762 16588 solver.cpp:228] Iteration 82900, loss = 0.057231
I0314 15:21:32.289762 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:21:32.289762 16588 solver.cpp:244]     Train net output #1: loss = 0.0572309 (* 1 = 0.0572309 loss)
I0314 15:21:32.289762 16588 sgd_solver.cpp:106] Iteration 82900, lr = 0.01
I0314 15:21:46.749356 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_83000.caffemodel
I0314 15:21:46.789361 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_83000.solverstate
I0314 15:21:46.789361 16588 solver.cpp:337] Iteration 83000, Testing net (#0)
I0314 15:21:46.789361 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:21:51.681406 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8643
I0314 15:21:51.681406 16588 solver.cpp:404]     Test net output #1: loss = 0.521595 (* 1 = 0.521595 loss)
I0314 15:21:51.720906 16588 solver.cpp:228] Iteration 83000, loss = 0.0562069
I0314 15:21:51.720906 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:21:51.720906 16588 solver.cpp:244]     Train net output #1: loss = 0.0562068 (* 1 = 0.0562068 loss)
I0314 15:21:51.720906 16588 sgd_solver.cpp:106] Iteration 83000, lr = 0.01
I0314 15:22:05.930788 16588 solver.cpp:228] Iteration 83100, loss = 0.0839452
I0314 15:22:05.930788 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:22:05.930788 16588 solver.cpp:244]     Train net output #1: loss = 0.0839452 (* 1 = 0.0839452 loss)
I0314 15:22:05.930788 16588 sgd_solver.cpp:106] Iteration 83100, lr = 0.01
I0314 15:22:20.500963 16588 solver.cpp:228] Iteration 83200, loss = 0.0393817
I0314 15:22:20.500963 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:22:20.500963 16588 solver.cpp:244]     Train net output #1: loss = 0.0393817 (* 1 = 0.0393817 loss)
I0314 15:22:20.500963 16588 sgd_solver.cpp:106] Iteration 83200, lr = 0.01
I0314 15:22:35.064976 16588 solver.cpp:228] Iteration 83300, loss = 0.086054
I0314 15:22:35.064976 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:22:35.064976 16588 solver.cpp:244]     Train net output #1: loss = 0.086054 (* 1 = 0.086054 loss)
I0314 15:22:35.064976 16588 sgd_solver.cpp:106] Iteration 83300, lr = 0.01
I0314 15:22:49.657630 16588 solver.cpp:228] Iteration 83400, loss = 0.0238267
I0314 15:22:49.657630 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:22:49.657630 16588 solver.cpp:244]     Train net output #1: loss = 0.0238266 (* 1 = 0.0238266 loss)
I0314 15:22:49.657630 16588 sgd_solver.cpp:106] Iteration 83400, lr = 0.01
I0314 15:23:04.083981 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_83500.caffemodel
I0314 15:23:04.124501 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_83500.solverstate
I0314 15:23:04.132481 16588 solver.cpp:337] Iteration 83500, Testing net (#0)
I0314 15:23:04.132481 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:23:08.919975 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8578
I0314 15:23:08.919975 16588 solver.cpp:404]     Test net output #1: loss = 0.565342 (* 1 = 0.565342 loss)
I0314 15:23:08.980484 16588 solver.cpp:228] Iteration 83500, loss = 0.0960415
I0314 15:23:08.980484 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:23:08.980484 16588 solver.cpp:244]     Train net output #1: loss = 0.0960414 (* 1 = 0.0960414 loss)
I0314 15:23:08.980484 16588 sgd_solver.cpp:106] Iteration 83500, lr = 0.01
I0314 15:23:23.227607 16588 solver.cpp:228] Iteration 83600, loss = 0.0845704
I0314 15:23:23.227607 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:23:23.227607 16588 solver.cpp:244]     Train net output #1: loss = 0.0845703 (* 1 = 0.0845703 loss)
I0314 15:23:23.227607 16588 sgd_solver.cpp:106] Iteration 83600, lr = 0.01
I0314 15:23:37.796026 16588 solver.cpp:228] Iteration 83700, loss = 0.0779376
I0314 15:23:37.797046 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:23:37.797046 16588 solver.cpp:244]     Train net output #1: loss = 0.0779375 (* 1 = 0.0779375 loss)
I0314 15:23:37.797046 16588 sgd_solver.cpp:106] Iteration 83700, lr = 0.01
I0314 15:23:52.347018 16588 solver.cpp:228] Iteration 83800, loss = 0.051776
I0314 15:23:52.347519 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:23:52.347519 16588 solver.cpp:244]     Train net output #1: loss = 0.0517759 (* 1 = 0.0517759 loss)
I0314 15:23:52.347519 16588 sgd_solver.cpp:106] Iteration 83800, lr = 0.01
I0314 15:24:06.843308 16588 solver.cpp:228] Iteration 83900, loss = 0.0500284
I0314 15:24:06.843308 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:24:06.843308 16588 solver.cpp:244]     Train net output #1: loss = 0.0500283 (* 1 = 0.0500283 loss)
I0314 15:24:06.843308 16588 sgd_solver.cpp:106] Iteration 83900, lr = 0.01
I0314 15:24:21.286101 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_84000.caffemodel
I0314 15:24:21.316107 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_84000.solverstate
I0314 15:24:21.332114 16588 solver.cpp:337] Iteration 84000, Testing net (#0)
I0314 15:24:21.332114 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:24:26.165501 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8653
I0314 15:24:26.165501 16588 solver.cpp:404]     Test net output #1: loss = 0.500664 (* 1 = 0.500664 loss)
I0314 15:24:26.234496 16588 solver.cpp:228] Iteration 84000, loss = 0.0252993
I0314 15:24:26.234496 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:24:26.234496 16588 solver.cpp:244]     Train net output #1: loss = 0.0252992 (* 1 = 0.0252992 loss)
I0314 15:24:26.234496 16588 sgd_solver.cpp:106] Iteration 84000, lr = 0.01
I0314 15:24:40.403270 16588 solver.cpp:228] Iteration 84100, loss = 0.0682256
I0314 15:24:40.403270 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:24:40.403270 16588 solver.cpp:244]     Train net output #1: loss = 0.0682255 (* 1 = 0.0682255 loss)
I0314 15:24:40.403270 16588 sgd_solver.cpp:106] Iteration 84100, lr = 0.01
I0314 15:24:54.905804 16588 solver.cpp:228] Iteration 84200, loss = 0.11314
I0314 15:24:54.905804 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:24:54.905804 16588 solver.cpp:244]     Train net output #1: loss = 0.11314 (* 1 = 0.11314 loss)
I0314 15:24:54.905804 16588 sgd_solver.cpp:106] Iteration 84200, lr = 0.01
I0314 15:25:09.437285 16588 solver.cpp:228] Iteration 84300, loss = 0.0290802
I0314 15:25:09.437285 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:25:09.437285 16588 solver.cpp:244]     Train net output #1: loss = 0.0290801 (* 1 = 0.0290801 loss)
I0314 15:25:09.437285 16588 sgd_solver.cpp:106] Iteration 84300, lr = 0.01
I0314 15:25:23.836480 16588 solver.cpp:228] Iteration 84400, loss = 0.0309084
I0314 15:25:23.836480 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:25:23.836480 16588 solver.cpp:244]     Train net output #1: loss = 0.0309083 (* 1 = 0.0309083 loss)
I0314 15:25:23.836480 16588 sgd_solver.cpp:106] Iteration 84400, lr = 0.01
I0314 15:25:38.305862 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_84500.caffemodel
I0314 15:25:38.342394 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_84500.solverstate
I0314 15:25:38.348896 16588 solver.cpp:337] Iteration 84500, Testing net (#0)
I0314 15:25:38.349395 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:25:43.275101 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8505
I0314 15:25:43.275101 16588 solver.cpp:404]     Test net output #1: loss = 0.590811 (* 1 = 0.590811 loss)
I0314 15:25:43.325610 16588 solver.cpp:228] Iteration 84500, loss = 0.0409268
I0314 15:25:43.325610 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:25:43.325610 16588 solver.cpp:244]     Train net output #1: loss = 0.0409267 (* 1 = 0.0409267 loss)
I0314 15:25:43.325610 16588 sgd_solver.cpp:106] Iteration 84500, lr = 0.01
I0314 15:25:57.496907 16588 solver.cpp:228] Iteration 84600, loss = 0.0639694
I0314 15:25:57.496907 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:25:57.496907 16588 solver.cpp:244]     Train net output #1: loss = 0.0639692 (* 1 = 0.0639692 loss)
I0314 15:25:57.497407 16588 sgd_solver.cpp:106] Iteration 84600, lr = 0.01
I0314 15:26:11.996429 16588 solver.cpp:228] Iteration 84700, loss = 0.0494093
I0314 15:26:11.996429 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:26:11.996429 16588 solver.cpp:244]     Train net output #1: loss = 0.0494092 (* 1 = 0.0494092 loss)
I0314 15:26:11.996429 16588 sgd_solver.cpp:106] Iteration 84700, lr = 0.01
I0314 15:26:26.519152 16588 solver.cpp:228] Iteration 84800, loss = 0.0497968
I0314 15:26:26.519152 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:26:26.519152 16588 solver.cpp:244]     Train net output #1: loss = 0.0497967 (* 1 = 0.0497967 loss)
I0314 15:26:26.519152 16588 sgd_solver.cpp:106] Iteration 84800, lr = 0.01
I0314 15:26:41.049227 16588 solver.cpp:228] Iteration 84900, loss = 0.0790395
I0314 15:26:41.049227 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:26:41.049227 16588 solver.cpp:244]     Train net output #1: loss = 0.0790393 (* 1 = 0.0790393 loss)
I0314 15:26:41.049227 16588 sgd_solver.cpp:106] Iteration 84900, lr = 0.01
I0314 15:26:55.509289 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_85000.caffemodel
I0314 15:26:55.545289 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_85000.solverstate
I0314 15:26:55.552289 16588 solver.cpp:337] Iteration 85000, Testing net (#0)
I0314 15:26:55.552289 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:27:00.387171 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8576
I0314 15:27:00.387171 16588 solver.cpp:404]     Test net output #1: loss = 0.535728 (* 1 = 0.535728 loss)
I0314 15:27:00.426684 16588 solver.cpp:228] Iteration 85000, loss = 0.0616765
I0314 15:27:00.426684 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:27:00.426684 16588 solver.cpp:244]     Train net output #1: loss = 0.0616763 (* 1 = 0.0616763 loss)
I0314 15:27:00.426684 16588 sgd_solver.cpp:106] Iteration 85000, lr = 0.01
I0314 15:27:14.522114 16588 solver.cpp:228] Iteration 85100, loss = 0.0689132
I0314 15:27:14.522114 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:27:14.522114 16588 solver.cpp:244]     Train net output #1: loss = 0.0689131 (* 1 = 0.0689131 loss)
I0314 15:27:14.522114 16588 sgd_solver.cpp:106] Iteration 85100, lr = 0.01
I0314 15:27:29.002041 16588 solver.cpp:228] Iteration 85200, loss = 0.0377896
I0314 15:27:29.002041 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:27:29.002041 16588 solver.cpp:244]     Train net output #1: loss = 0.0377894 (* 1 = 0.0377894 loss)
I0314 15:27:29.002041 16588 sgd_solver.cpp:106] Iteration 85200, lr = 0.01
I0314 15:27:43.538908 16588 solver.cpp:228] Iteration 85300, loss = 0.0784511
I0314 15:27:43.538908 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:27:43.538908 16588 solver.cpp:244]     Train net output #1: loss = 0.078451 (* 1 = 0.078451 loss)
I0314 15:27:43.538908 16588 sgd_solver.cpp:106] Iteration 85300, lr = 0.01
I0314 15:27:58.071411 16588 solver.cpp:228] Iteration 85400, loss = 0.0345264
I0314 15:27:58.071912 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:27:58.071912 16588 solver.cpp:244]     Train net output #1: loss = 0.0345263 (* 1 = 0.0345263 loss)
I0314 15:27:58.071912 16588 sgd_solver.cpp:106] Iteration 85400, lr = 0.01
I0314 15:28:12.494961 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_85500.caffemodel
I0314 15:28:12.529482 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_85500.solverstate
I0314 15:28:12.535475 16588 solver.cpp:337] Iteration 85500, Testing net (#0)
I0314 15:28:12.535475 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:28:17.238163 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8672
I0314 15:28:17.238163 16588 solver.cpp:404]     Test net output #1: loss = 0.484802 (* 1 = 0.484802 loss)
I0314 15:28:17.297686 16588 solver.cpp:228] Iteration 85500, loss = 0.0341083
I0314 15:28:17.297686 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:28:17.297686 16588 solver.cpp:244]     Train net output #1: loss = 0.0341082 (* 1 = 0.0341082 loss)
I0314 15:28:17.297686 16588 sgd_solver.cpp:106] Iteration 85500, lr = 0.01
I0314 15:28:31.420806 16588 solver.cpp:228] Iteration 85600, loss = 0.0476326
I0314 15:28:31.420806 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:28:31.420806 16588 solver.cpp:244]     Train net output #1: loss = 0.0476324 (* 1 = 0.0476324 loss)
I0314 15:28:31.420806 16588 sgd_solver.cpp:106] Iteration 85600, lr = 0.01
I0314 15:28:45.926787 16588 solver.cpp:228] Iteration 85700, loss = 0.0323929
I0314 15:28:45.926787 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:28:45.926787 16588 solver.cpp:244]     Train net output #1: loss = 0.0323927 (* 1 = 0.0323927 loss)
I0314 15:28:45.926787 16588 sgd_solver.cpp:106] Iteration 85700, lr = 0.01
I0314 15:29:00.448465 16588 solver.cpp:228] Iteration 85800, loss = 0.0436789
I0314 15:29:00.448465 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:29:00.448465 16588 solver.cpp:244]     Train net output #1: loss = 0.0436787 (* 1 = 0.0436787 loss)
I0314 15:29:00.448465 16588 sgd_solver.cpp:106] Iteration 85800, lr = 0.01
I0314 15:29:14.949939 16588 solver.cpp:228] Iteration 85900, loss = 0.0342339
I0314 15:29:14.949939 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:29:14.949939 16588 solver.cpp:244]     Train net output #1: loss = 0.0342337 (* 1 = 0.0342337 loss)
I0314 15:29:14.949939 16588 sgd_solver.cpp:106] Iteration 85900, lr = 0.01
I0314 15:29:29.397147 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_86000.caffemodel
I0314 15:29:29.436627 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_86000.solverstate
I0314 15:29:29.442128 16588 solver.cpp:337] Iteration 86000, Testing net (#0)
I0314 15:29:29.442626 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:29:34.138304 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8653
I0314 15:29:34.138304 16588 solver.cpp:404]     Test net output #1: loss = 0.503792 (* 1 = 0.503792 loss)
I0314 15:29:34.181823 16588 solver.cpp:228] Iteration 86000, loss = 0.0552451
I0314 15:29:34.181823 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:29:34.181823 16588 solver.cpp:244]     Train net output #1: loss = 0.0552449 (* 1 = 0.0552449 loss)
I0314 15:29:34.181823 16588 sgd_solver.cpp:106] Iteration 86000, lr = 0.01
I0314 15:29:48.352874 16588 solver.cpp:228] Iteration 86100, loss = 0.0666435
I0314 15:29:48.352874 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:29:48.352874 16588 solver.cpp:244]     Train net output #1: loss = 0.0666432 (* 1 = 0.0666432 loss)
I0314 15:29:48.352874 16588 sgd_solver.cpp:106] Iteration 86100, lr = 0.01
I0314 15:30:02.891455 16588 solver.cpp:228] Iteration 86200, loss = 0.0534918
I0314 15:30:02.891455 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:30:02.891455 16588 solver.cpp:244]     Train net output #1: loss = 0.0534916 (* 1 = 0.0534916 loss)
I0314 15:30:02.891455 16588 sgd_solver.cpp:106] Iteration 86200, lr = 0.01
I0314 15:30:17.463980 16588 solver.cpp:228] Iteration 86300, loss = 0.024066
I0314 15:30:17.463980 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:30:17.463980 16588 solver.cpp:244]     Train net output #1: loss = 0.0240658 (* 1 = 0.0240658 loss)
I0314 15:30:17.463980 16588 sgd_solver.cpp:106] Iteration 86300, lr = 0.01
I0314 15:30:31.963191 16588 solver.cpp:228] Iteration 86400, loss = 0.0706915
I0314 15:30:31.963191 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:30:31.963191 16588 solver.cpp:244]     Train net output #1: loss = 0.0706913 (* 1 = 0.0706913 loss)
I0314 15:30:31.963191 16588 sgd_solver.cpp:106] Iteration 86400, lr = 0.01
I0314 15:30:46.386013 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_86500.caffemodel
I0314 15:30:46.424013 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_86500.solverstate
I0314 15:30:46.430513 16588 solver.cpp:337] Iteration 86500, Testing net (#0)
I0314 15:30:46.430513 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:30:51.250037 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8689
I0314 15:30:51.250037 16588 solver.cpp:404]     Test net output #1: loss = 0.495148 (* 1 = 0.495148 loss)
I0314 15:30:51.290052 16588 solver.cpp:228] Iteration 86500, loss = 0.0727672
I0314 15:30:51.290052 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:30:51.290052 16588 solver.cpp:244]     Train net output #1: loss = 0.0727671 (* 1 = 0.0727671 loss)
I0314 15:30:51.290052 16588 sgd_solver.cpp:106] Iteration 86500, lr = 0.01
I0314 15:31:05.403863 16588 solver.cpp:228] Iteration 86600, loss = 0.0797466
I0314 15:31:05.403863 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:31:05.403863 16588 solver.cpp:244]     Train net output #1: loss = 0.0797464 (* 1 = 0.0797464 loss)
I0314 15:31:05.403863 16588 sgd_solver.cpp:106] Iteration 86600, lr = 0.01
I0314 15:31:19.902073 16588 solver.cpp:228] Iteration 86700, loss = 0.0551017
I0314 15:31:19.902073 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:31:19.902073 16588 solver.cpp:244]     Train net output #1: loss = 0.0551015 (* 1 = 0.0551015 loss)
I0314 15:31:19.902073 16588 sgd_solver.cpp:106] Iteration 86700, lr = 0.01
I0314 15:31:34.366061 16588 solver.cpp:228] Iteration 86800, loss = 0.0906275
I0314 15:31:34.366061 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:31:34.366061 16588 solver.cpp:244]     Train net output #1: loss = 0.0906273 (* 1 = 0.0906273 loss)
I0314 15:31:34.366061 16588 sgd_solver.cpp:106] Iteration 86800, lr = 0.01
I0314 15:31:48.875432 16588 solver.cpp:228] Iteration 86900, loss = 0.0304185
I0314 15:31:48.875432 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:31:48.875432 16588 solver.cpp:244]     Train net output #1: loss = 0.0304183 (* 1 = 0.0304183 loss)
I0314 15:31:48.875432 16588 sgd_solver.cpp:106] Iteration 86900, lr = 0.01
I0314 15:32:03.269021 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_87000.caffemodel
I0314 15:32:03.288018 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_87000.solverstate
I0314 15:32:03.294518 16588 solver.cpp:337] Iteration 87000, Testing net (#0)
I0314 15:32:03.294518 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:32:08.142798 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8573
I0314 15:32:08.142798 16588 solver.cpp:404]     Test net output #1: loss = 0.561813 (* 1 = 0.561813 loss)
I0314 15:32:08.172808 16588 solver.cpp:228] Iteration 87000, loss = 0.0124152
I0314 15:32:08.172808 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:32:08.172808 16588 solver.cpp:244]     Train net output #1: loss = 0.012415 (* 1 = 0.012415 loss)
I0314 15:32:08.172808 16588 sgd_solver.cpp:106] Iteration 87000, lr = 0.01
I0314 15:32:22.253226 16588 solver.cpp:228] Iteration 87100, loss = 0.0631703
I0314 15:32:22.253226 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:32:22.253226 16588 solver.cpp:244]     Train net output #1: loss = 0.0631701 (* 1 = 0.0631701 loss)
I0314 15:32:22.253226 16588 sgd_solver.cpp:106] Iteration 87100, lr = 0.01
I0314 15:32:36.803814 16588 solver.cpp:228] Iteration 87200, loss = 0.0315025
I0314 15:32:36.803814 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:32:36.804316 16588 solver.cpp:244]     Train net output #1: loss = 0.0315022 (* 1 = 0.0315022 loss)
I0314 15:32:36.804316 16588 sgd_solver.cpp:106] Iteration 87200, lr = 0.01
I0314 15:32:51.388782 16588 solver.cpp:228] Iteration 87300, loss = 0.069417
I0314 15:32:51.388782 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:32:51.388782 16588 solver.cpp:244]     Train net output #1: loss = 0.0694168 (* 1 = 0.0694168 loss)
I0314 15:32:51.388782 16588 sgd_solver.cpp:106] Iteration 87300, lr = 0.01
I0314 15:33:05.835119 16588 solver.cpp:228] Iteration 87400, loss = 0.0304556
I0314 15:33:05.835119 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:33:05.835119 16588 solver.cpp:244]     Train net output #1: loss = 0.0304554 (* 1 = 0.0304554 loss)
I0314 15:33:05.835119 16588 sgd_solver.cpp:106] Iteration 87400, lr = 0.01
I0314 15:33:20.272320 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_87500.caffemodel
I0314 15:33:20.299331 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_87500.solverstate
I0314 15:33:20.309329 16588 solver.cpp:337] Iteration 87500, Testing net (#0)
I0314 15:33:20.309329 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:33:25.070688 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8627
I0314 15:33:25.070688 16588 solver.cpp:404]     Test net output #1: loss = 0.514328 (* 1 = 0.514328 loss)
I0314 15:33:25.116569 16588 solver.cpp:228] Iteration 87500, loss = 0.0963501
I0314 15:33:25.116569 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:33:25.116569 16588 solver.cpp:244]     Train net output #1: loss = 0.0963499 (* 1 = 0.0963499 loss)
I0314 15:33:25.116569 16588 sgd_solver.cpp:106] Iteration 87500, lr = 0.01
I0314 15:33:39.283835 16588 solver.cpp:228] Iteration 87600, loss = 0.0350564
I0314 15:33:39.283835 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:33:39.283835 16588 solver.cpp:244]     Train net output #1: loss = 0.0350562 (* 1 = 0.0350562 loss)
I0314 15:33:39.283835 16588 sgd_solver.cpp:106] Iteration 87600, lr = 0.01
I0314 15:33:53.785428 16588 solver.cpp:228] Iteration 87700, loss = 0.0558529
I0314 15:33:53.785428 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:33:53.785428 16588 solver.cpp:244]     Train net output #1: loss = 0.0558527 (* 1 = 0.0558527 loss)
I0314 15:33:53.785428 16588 sgd_solver.cpp:106] Iteration 87700, lr = 0.01
I0314 15:34:08.327440 16588 solver.cpp:228] Iteration 87800, loss = 0.090297
I0314 15:34:08.327440 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:34:08.327440 16588 solver.cpp:244]     Train net output #1: loss = 0.0902968 (* 1 = 0.0902968 loss)
I0314 15:34:08.327440 16588 sgd_solver.cpp:106] Iteration 87800, lr = 0.01
I0314 15:34:22.778512 16588 solver.cpp:228] Iteration 87900, loss = 0.0700754
I0314 15:34:22.778512 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:34:22.778512 16588 solver.cpp:244]     Train net output #1: loss = 0.0700752 (* 1 = 0.0700752 loss)
I0314 15:34:22.778512 16588 sgd_solver.cpp:106] Iteration 87900, lr = 0.01
I0314 15:34:37.201222 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_88000.caffemodel
I0314 15:34:37.238723 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_88000.solverstate
I0314 15:34:37.245220 16588 solver.cpp:337] Iteration 88000, Testing net (#0)
I0314 15:34:37.245220 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:34:41.972527 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8641
I0314 15:34:41.972527 16588 solver.cpp:404]     Test net output #1: loss = 0.507647 (* 1 = 0.507647 loss)
I0314 15:34:42.056530 16588 solver.cpp:228] Iteration 88000, loss = 0.0583922
I0314 15:34:42.056530 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:34:42.056530 16588 solver.cpp:244]     Train net output #1: loss = 0.058392 (* 1 = 0.058392 loss)
I0314 15:34:42.056530 16588 sgd_solver.cpp:106] Iteration 88000, lr = 0.01
I0314 15:34:56.187665 16588 solver.cpp:228] Iteration 88100, loss = 0.0217479
I0314 15:34:56.187665 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:34:56.187665 16588 solver.cpp:244]     Train net output #1: loss = 0.0217477 (* 1 = 0.0217477 loss)
I0314 15:34:56.187665 16588 sgd_solver.cpp:106] Iteration 88100, lr = 0.01
I0314 15:35:10.679850 16588 solver.cpp:228] Iteration 88200, loss = 0.0334507
I0314 15:35:10.679850 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:35:10.679850 16588 solver.cpp:244]     Train net output #1: loss = 0.0334505 (* 1 = 0.0334505 loss)
I0314 15:35:10.679850 16588 sgd_solver.cpp:106] Iteration 88200, lr = 0.01
I0314 15:35:25.196202 16588 solver.cpp:228] Iteration 88300, loss = 0.0711187
I0314 15:35:25.196202 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:35:25.196202 16588 solver.cpp:244]     Train net output #1: loss = 0.0711185 (* 1 = 0.0711185 loss)
I0314 15:35:25.196202 16588 sgd_solver.cpp:106] Iteration 88300, lr = 0.01
I0314 15:35:39.741236 16588 solver.cpp:228] Iteration 88400, loss = 0.0770397
I0314 15:35:39.741236 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:35:39.741736 16588 solver.cpp:244]     Train net output #1: loss = 0.0770395 (* 1 = 0.0770395 loss)
I0314 15:35:39.741736 16588 sgd_solver.cpp:106] Iteration 88400, lr = 0.01
I0314 15:35:54.150703 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_88500.caffemodel
I0314 15:35:54.189203 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_88500.solverstate
I0314 15:35:54.195701 16588 solver.cpp:337] Iteration 88500, Testing net (#0)
I0314 15:35:54.195701 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:35:59.070308 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8616
I0314 15:35:59.070806 16588 solver.cpp:404]     Test net output #1: loss = 0.513292 (* 1 = 0.513292 loss)
I0314 15:35:59.126809 16588 solver.cpp:228] Iteration 88500, loss = 0.0771046
I0314 15:35:59.126809 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:35:59.126809 16588 solver.cpp:244]     Train net output #1: loss = 0.0771044 (* 1 = 0.0771044 loss)
I0314 15:35:59.126809 16588 sgd_solver.cpp:106] Iteration 88500, lr = 0.01
I0314 15:36:13.300313 16588 solver.cpp:228] Iteration 88600, loss = 0.123897
I0314 15:36:13.300313 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:36:13.300313 16588 solver.cpp:244]     Train net output #1: loss = 0.123897 (* 1 = 0.123897 loss)
I0314 15:36:13.300313 16588 sgd_solver.cpp:106] Iteration 88600, lr = 0.01
I0314 15:36:27.794526 16588 solver.cpp:228] Iteration 88700, loss = 0.0378145
I0314 15:36:27.794526 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:36:27.794526 16588 solver.cpp:244]     Train net output #1: loss = 0.0378143 (* 1 = 0.0378143 loss)
I0314 15:36:27.794526 16588 sgd_solver.cpp:106] Iteration 88700, lr = 0.01
I0314 15:36:42.247495 16588 solver.cpp:228] Iteration 88800, loss = 0.101568
I0314 15:36:42.247980 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0314 15:36:42.247980 16588 solver.cpp:244]     Train net output #1: loss = 0.101568 (* 1 = 0.101568 loss)
I0314 15:36:42.247980 16588 sgd_solver.cpp:106] Iteration 88800, lr = 0.01
I0314 15:36:56.734904 16588 solver.cpp:228] Iteration 88900, loss = 0.020478
I0314 15:36:56.734904 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:36:56.734904 16588 solver.cpp:244]     Train net output #1: loss = 0.0204778 (* 1 = 0.0204778 loss)
I0314 15:36:56.734904 16588 sgd_solver.cpp:106] Iteration 88900, lr = 0.01
I0314 15:37:11.173403 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_89000.caffemodel
I0314 15:37:11.207424 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_89000.solverstate
I0314 15:37:11.213403 16588 solver.cpp:337] Iteration 89000, Testing net (#0)
I0314 15:37:11.213403 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:37:16.112082 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8515
I0314 15:37:16.112082 16588 solver.cpp:404]     Test net output #1: loss = 0.562426 (* 1 = 0.562426 loss)
I0314 15:37:16.152079 16588 solver.cpp:228] Iteration 89000, loss = 0.0688306
I0314 15:37:16.152079 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:37:16.152079 16588 solver.cpp:244]     Train net output #1: loss = 0.0688304 (* 1 = 0.0688304 loss)
I0314 15:37:16.152079 16588 sgd_solver.cpp:106] Iteration 89000, lr = 0.01
I0314 15:37:30.310091 16588 solver.cpp:228] Iteration 89100, loss = 0.0440405
I0314 15:37:30.310091 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:37:30.310091 16588 solver.cpp:244]     Train net output #1: loss = 0.0440403 (* 1 = 0.0440403 loss)
I0314 15:37:30.310091 16588 sgd_solver.cpp:106] Iteration 89100, lr = 0.01
I0314 15:37:44.835702 16588 solver.cpp:228] Iteration 89200, loss = 0.075768
I0314 15:37:44.835702 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:37:44.835702 16588 solver.cpp:244]     Train net output #1: loss = 0.0757678 (* 1 = 0.0757678 loss)
I0314 15:37:44.835702 16588 sgd_solver.cpp:106] Iteration 89200, lr = 0.01
I0314 15:37:59.266176 16588 solver.cpp:228] Iteration 89300, loss = 0.0349483
I0314 15:37:59.266676 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:37:59.266676 16588 solver.cpp:244]     Train net output #1: loss = 0.0349481 (* 1 = 0.0349481 loss)
I0314 15:37:59.266676 16588 sgd_solver.cpp:106] Iteration 89300, lr = 0.01
I0314 15:38:13.850759 16588 solver.cpp:228] Iteration 89400, loss = 0.0140577
I0314 15:38:13.850759 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:38:13.850759 16588 solver.cpp:244]     Train net output #1: loss = 0.0140575 (* 1 = 0.0140575 loss)
I0314 15:38:13.850759 16588 sgd_solver.cpp:106] Iteration 89400, lr = 0.01
I0314 15:38:28.237315 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_89500.caffemodel
I0314 15:38:28.273816 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_89500.solverstate
I0314 15:38:28.280315 16588 solver.cpp:337] Iteration 89500, Testing net (#0)
I0314 15:38:28.280315 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:38:33.117676 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8549
I0314 15:38:33.117676 16588 solver.cpp:404]     Test net output #1: loss = 0.553459 (* 1 = 0.553459 loss)
I0314 15:38:33.167682 16588 solver.cpp:228] Iteration 89500, loss = 0.107472
I0314 15:38:33.167682 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:38:33.167682 16588 solver.cpp:244]     Train net output #1: loss = 0.107472 (* 1 = 0.107472 loss)
I0314 15:38:33.167682 16588 sgd_solver.cpp:106] Iteration 89500, lr = 0.01
I0314 15:38:47.260069 16588 solver.cpp:228] Iteration 89600, loss = 0.0849732
I0314 15:38:47.260069 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:38:47.260069 16588 solver.cpp:244]     Train net output #1: loss = 0.084973 (* 1 = 0.084973 loss)
I0314 15:38:47.260069 16588 sgd_solver.cpp:106] Iteration 89600, lr = 0.01
I0314 15:39:01.759682 16588 solver.cpp:228] Iteration 89700, loss = 0.0476717
I0314 15:39:01.759682 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:39:01.759682 16588 solver.cpp:244]     Train net output #1: loss = 0.0476715 (* 1 = 0.0476715 loss)
I0314 15:39:01.759682 16588 sgd_solver.cpp:106] Iteration 89700, lr = 0.01
I0314 15:39:16.200028 16588 solver.cpp:228] Iteration 89800, loss = 0.0460754
I0314 15:39:16.200028 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:39:16.200028 16588 solver.cpp:244]     Train net output #1: loss = 0.0460752 (* 1 = 0.0460752 loss)
I0314 15:39:16.200028 16588 sgd_solver.cpp:106] Iteration 89800, lr = 0.01
I0314 15:39:30.721544 16588 solver.cpp:228] Iteration 89900, loss = 0.0499172
I0314 15:39:30.721544 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:39:30.721544 16588 solver.cpp:244]     Train net output #1: loss = 0.0499171 (* 1 = 0.0499171 loss)
I0314 15:39:30.721544 16588 sgd_solver.cpp:106] Iteration 89900, lr = 0.01
I0314 15:39:45.145028 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_90000.caffemodel
I0314 15:39:45.174552 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_90000.solverstate
I0314 15:39:45.184556 16588 solver.cpp:337] Iteration 90000, Testing net (#0)
I0314 15:39:45.184556 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:39:50.027348 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8645
I0314 15:39:50.027348 16588 solver.cpp:404]     Test net output #1: loss = 0.516874 (* 1 = 0.516874 loss)
I0314 15:39:50.071362 16588 solver.cpp:228] Iteration 90000, loss = 0.109688
I0314 15:39:50.071362 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:39:50.071362 16588 solver.cpp:244]     Train net output #1: loss = 0.109688 (* 1 = 0.109688 loss)
I0314 15:39:50.071362 16588 sgd_solver.cpp:106] Iteration 90000, lr = 0.01
I0314 15:40:04.236505 16588 solver.cpp:228] Iteration 90100, loss = 0.0818946
I0314 15:40:04.236505 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:40:04.236505 16588 solver.cpp:244]     Train net output #1: loss = 0.0818944 (* 1 = 0.0818944 loss)
I0314 15:40:04.236505 16588 sgd_solver.cpp:106] Iteration 90100, lr = 0.01
I0314 15:40:18.618015 16588 solver.cpp:228] Iteration 90200, loss = 0.0620613
I0314 15:40:18.618015 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:40:18.618015 16588 solver.cpp:244]     Train net output #1: loss = 0.0620611 (* 1 = 0.0620611 loss)
I0314 15:40:18.618015 16588 sgd_solver.cpp:106] Iteration 90200, lr = 0.01
I0314 15:40:33.048053 16588 solver.cpp:228] Iteration 90300, loss = 0.0489828
I0314 15:40:33.048053 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:40:33.048053 16588 solver.cpp:244]     Train net output #1: loss = 0.0489827 (* 1 = 0.0489827 loss)
I0314 15:40:33.048053 16588 sgd_solver.cpp:106] Iteration 90300, lr = 0.01
I0314 15:40:47.535996 16588 solver.cpp:228] Iteration 90400, loss = 0.0137752
I0314 15:40:47.535996 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:40:47.535996 16588 solver.cpp:244]     Train net output #1: loss = 0.013775 (* 1 = 0.013775 loss)
I0314 15:40:47.535996 16588 sgd_solver.cpp:106] Iteration 90400, lr = 0.01
I0314 15:41:01.936182 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_90500.caffemodel
I0314 15:41:01.975682 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_90500.solverstate
I0314 15:41:01.982182 16588 solver.cpp:337] Iteration 90500, Testing net (#0)
I0314 15:41:01.982682 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:41:06.792748 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8458
I0314 15:41:06.792748 16588 solver.cpp:404]     Test net output #1: loss = 0.595979 (* 1 = 0.595979 loss)
I0314 15:41:06.852242 16588 solver.cpp:228] Iteration 90500, loss = 0.0687071
I0314 15:41:06.852242 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:41:06.852242 16588 solver.cpp:244]     Train net output #1: loss = 0.0687069 (* 1 = 0.0687069 loss)
I0314 15:41:06.852743 16588 sgd_solver.cpp:106] Iteration 90500, lr = 0.01
I0314 15:41:20.822774 16588 solver.cpp:228] Iteration 90600, loss = 0.0315766
I0314 15:41:20.822774 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:41:20.822774 16588 solver.cpp:244]     Train net output #1: loss = 0.0315764 (* 1 = 0.0315764 loss)
I0314 15:41:20.822774 16588 sgd_solver.cpp:106] Iteration 90600, lr = 0.01
I0314 15:41:35.271262 16588 solver.cpp:228] Iteration 90700, loss = 0.0484668
I0314 15:41:35.271262 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:41:35.271262 16588 solver.cpp:244]     Train net output #1: loss = 0.0484667 (* 1 = 0.0484667 loss)
I0314 15:41:35.271262 16588 sgd_solver.cpp:106] Iteration 90700, lr = 0.01
I0314 15:41:49.724290 16588 solver.cpp:228] Iteration 90800, loss = 0.0554885
I0314 15:41:49.724290 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:41:49.724290 16588 solver.cpp:244]     Train net output #1: loss = 0.0554884 (* 1 = 0.0554884 loss)
I0314 15:41:49.724290 16588 sgd_solver.cpp:106] Iteration 90800, lr = 0.01
I0314 15:42:04.183521 16588 solver.cpp:228] Iteration 90900, loss = 0.0339062
I0314 15:42:04.183521 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:42:04.183521 16588 solver.cpp:244]     Train net output #1: loss = 0.033906 (* 1 = 0.033906 loss)
I0314 15:42:04.183521 16588 sgd_solver.cpp:106] Iteration 90900, lr = 0.01
I0314 15:42:18.580301 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_91000.caffemodel
I0314 15:42:18.619801 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_91000.solverstate
I0314 15:42:18.625810 16588 solver.cpp:337] Iteration 91000, Testing net (#0)
I0314 15:42:18.625810 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:42:23.465435 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8475
I0314 15:42:23.465435 16588 solver.cpp:404]     Test net output #1: loss = 0.572335 (* 1 = 0.572335 loss)
I0314 15:42:23.513978 16588 solver.cpp:228] Iteration 91000, loss = 0.048228
I0314 15:42:23.513978 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:42:23.513978 16588 solver.cpp:244]     Train net output #1: loss = 0.0482279 (* 1 = 0.0482279 loss)
I0314 15:42:23.513978 16588 sgd_solver.cpp:106] Iteration 91000, lr = 0.01
I0314 15:42:37.527958 16588 solver.cpp:228] Iteration 91100, loss = 0.0710874
I0314 15:42:37.527958 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:42:37.527958 16588 solver.cpp:244]     Train net output #1: loss = 0.0710872 (* 1 = 0.0710872 loss)
I0314 15:42:37.527958 16588 sgd_solver.cpp:106] Iteration 91100, lr = 0.01
I0314 15:42:52.040681 16588 solver.cpp:228] Iteration 91200, loss = 0.0383687
I0314 15:42:52.040681 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:42:52.040681 16588 solver.cpp:244]     Train net output #1: loss = 0.0383685 (* 1 = 0.0383685 loss)
I0314 15:42:52.040681 16588 sgd_solver.cpp:106] Iteration 91200, lr = 0.01
I0314 15:43:06.553050 16588 solver.cpp:228] Iteration 91300, loss = 0.0740093
I0314 15:43:06.553555 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:43:06.553555 16588 solver.cpp:244]     Train net output #1: loss = 0.0740092 (* 1 = 0.0740092 loss)
I0314 15:43:06.553555 16588 sgd_solver.cpp:106] Iteration 91300, lr = 0.01
I0314 15:43:21.022761 16588 solver.cpp:228] Iteration 91400, loss = 0.0389725
I0314 15:43:21.022761 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:43:21.022761 16588 solver.cpp:244]     Train net output #1: loss = 0.0389723 (* 1 = 0.0389723 loss)
I0314 15:43:21.022761 16588 sgd_solver.cpp:106] Iteration 91400, lr = 0.01
I0314 15:43:35.444052 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_91500.caffemodel
I0314 15:43:35.478552 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_91500.solverstate
I0314 15:43:35.484053 16588 solver.cpp:337] Iteration 91500, Testing net (#0)
I0314 15:43:35.484553 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:43:40.292605 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8603
I0314 15:43:40.292605 16588 solver.cpp:404]     Test net output #1: loss = 0.519048 (* 1 = 0.519048 loss)
I0314 15:43:40.348603 16588 solver.cpp:228] Iteration 91500, loss = 0.0969157
I0314 15:43:40.348603 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:43:40.348603 16588 solver.cpp:244]     Train net output #1: loss = 0.0969155 (* 1 = 0.0969155 loss)
I0314 15:43:40.348603 16588 sgd_solver.cpp:106] Iteration 91500, lr = 0.01
I0314 15:43:54.475877 16588 solver.cpp:228] Iteration 91600, loss = 0.0220094
I0314 15:43:54.475877 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:43:54.475877 16588 solver.cpp:244]     Train net output #1: loss = 0.0220092 (* 1 = 0.0220092 loss)
I0314 15:43:54.475877 16588 sgd_solver.cpp:106] Iteration 91600, lr = 0.01
I0314 15:44:09.000401 16588 solver.cpp:228] Iteration 91700, loss = 0.0492594
I0314 15:44:09.000401 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:44:09.000401 16588 solver.cpp:244]     Train net output #1: loss = 0.0492593 (* 1 = 0.0492593 loss)
I0314 15:44:09.000401 16588 sgd_solver.cpp:106] Iteration 91700, lr = 0.01
I0314 15:44:23.470413 16588 solver.cpp:228] Iteration 91800, loss = 0.0865135
I0314 15:44:23.470413 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:44:23.470413 16588 solver.cpp:244]     Train net output #1: loss = 0.0865134 (* 1 = 0.0865134 loss)
I0314 15:44:23.470413 16588 sgd_solver.cpp:106] Iteration 91800, lr = 0.01
I0314 15:44:37.950948 16588 solver.cpp:228] Iteration 91900, loss = 0.0552743
I0314 15:44:37.950948 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:44:37.950948 16588 solver.cpp:244]     Train net output #1: loss = 0.0552741 (* 1 = 0.0552741 loss)
I0314 15:44:37.950948 16588 sgd_solver.cpp:106] Iteration 91900, lr = 0.01
I0314 15:44:52.408685 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_92000.caffemodel
I0314 15:44:52.445683 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_92000.solverstate
I0314 15:44:52.452183 16588 solver.cpp:337] Iteration 92000, Testing net (#0)
I0314 15:44:52.452183 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:44:57.313750 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8358
I0314 15:44:57.313750 16588 solver.cpp:404]     Test net output #1: loss = 0.635157 (* 1 = 0.635157 loss)
I0314 15:44:57.363318 16588 solver.cpp:228] Iteration 92000, loss = 0.0736956
I0314 15:44:57.363318 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:44:57.363318 16588 solver.cpp:244]     Train net output #1: loss = 0.0736955 (* 1 = 0.0736955 loss)
I0314 15:44:57.363318 16588 sgd_solver.cpp:106] Iteration 92000, lr = 0.01
I0314 15:45:11.402065 16588 solver.cpp:228] Iteration 92100, loss = 0.0224845
I0314 15:45:11.402065 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:45:11.402065 16588 solver.cpp:244]     Train net output #1: loss = 0.0224843 (* 1 = 0.0224843 loss)
I0314 15:45:11.402065 16588 sgd_solver.cpp:106] Iteration 92100, lr = 0.01
I0314 15:45:25.898574 16588 solver.cpp:228] Iteration 92200, loss = 0.0681343
I0314 15:45:25.898574 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:45:25.898574 16588 solver.cpp:244]     Train net output #1: loss = 0.0681342 (* 1 = 0.0681342 loss)
I0314 15:45:25.898574 16588 sgd_solver.cpp:106] Iteration 92200, lr = 0.01
I0314 15:45:40.362938 16588 solver.cpp:228] Iteration 92300, loss = 0.0460078
I0314 15:45:40.362938 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:45:40.362938 16588 solver.cpp:244]     Train net output #1: loss = 0.0460077 (* 1 = 0.0460077 loss)
I0314 15:45:40.362938 16588 sgd_solver.cpp:106] Iteration 92300, lr = 0.01
I0314 15:45:54.833870 16588 solver.cpp:228] Iteration 92400, loss = 0.0539185
I0314 15:45:54.833870 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:45:54.833870 16588 solver.cpp:244]     Train net output #1: loss = 0.0539183 (* 1 = 0.0539183 loss)
I0314 15:45:54.833870 16588 sgd_solver.cpp:106] Iteration 92400, lr = 0.01
I0314 15:46:09.307147 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_92500.caffemodel
I0314 15:46:09.346087 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_92500.solverstate
I0314 15:46:09.351586 16588 solver.cpp:337] Iteration 92500, Testing net (#0)
I0314 15:46:09.352087 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:46:14.215037 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8694
I0314 15:46:14.215037 16588 solver.cpp:404]     Test net output #1: loss = 0.490914 (* 1 = 0.490914 loss)
I0314 15:46:14.256520 16588 solver.cpp:228] Iteration 92500, loss = 0.102647
I0314 15:46:14.256520 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:46:14.256520 16588 solver.cpp:244]     Train net output #1: loss = 0.102647 (* 1 = 0.102647 loss)
I0314 15:46:14.257007 16588 sgd_solver.cpp:106] Iteration 92500, lr = 0.01
I0314 15:46:28.422489 16588 solver.cpp:228] Iteration 92600, loss = 0.146453
I0314 15:46:28.422489 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0314 15:46:28.422489 16588 solver.cpp:244]     Train net output #1: loss = 0.146453 (* 1 = 0.146453 loss)
I0314 15:46:28.422489 16588 sgd_solver.cpp:106] Iteration 92600, lr = 0.01
I0314 15:46:42.819620 16588 solver.cpp:228] Iteration 92700, loss = 0.0543983
I0314 15:46:42.819620 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:46:42.819620 16588 solver.cpp:244]     Train net output #1: loss = 0.0543981 (* 1 = 0.0543981 loss)
I0314 15:46:42.819620 16588 sgd_solver.cpp:106] Iteration 92700, lr = 0.01
I0314 15:46:57.292264 16588 solver.cpp:228] Iteration 92800, loss = 0.155076
I0314 15:46:57.292264 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:46:57.292264 16588 solver.cpp:244]     Train net output #1: loss = 0.155076 (* 1 = 0.155076 loss)
I0314 15:46:57.292264 16588 sgd_solver.cpp:106] Iteration 92800, lr = 0.01
I0314 15:47:11.767356 16588 solver.cpp:228] Iteration 92900, loss = 0.0354312
I0314 15:47:11.767356 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:47:11.767356 16588 solver.cpp:244]     Train net output #1: loss = 0.035431 (* 1 = 0.035431 loss)
I0314 15:47:11.767356 16588 sgd_solver.cpp:106] Iteration 92900, lr = 0.01
I0314 15:47:26.200495 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_93000.caffemodel
I0314 15:47:26.240483 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_93000.solverstate
I0314 15:47:26.240483 16588 solver.cpp:337] Iteration 93000, Testing net (#0)
I0314 15:47:26.240483 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:47:31.051934 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8621
I0314 15:47:31.051934 16588 solver.cpp:404]     Test net output #1: loss = 0.492854 (* 1 = 0.492854 loss)
I0314 15:47:31.101966 16588 solver.cpp:228] Iteration 93000, loss = 0.0595338
I0314 15:47:31.101966 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:47:31.101966 16588 solver.cpp:244]     Train net output #1: loss = 0.0595337 (* 1 = 0.0595337 loss)
I0314 15:47:31.101966 16588 sgd_solver.cpp:106] Iteration 93000, lr = 0.01
I0314 15:47:45.214503 16588 solver.cpp:228] Iteration 93100, loss = 0.0607244
I0314 15:47:45.214503 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:47:45.214503 16588 solver.cpp:244]     Train net output #1: loss = 0.0607243 (* 1 = 0.0607243 loss)
I0314 15:47:45.214503 16588 sgd_solver.cpp:106] Iteration 93100, lr = 0.01
I0314 15:47:59.646944 16588 solver.cpp:228] Iteration 93200, loss = 0.081249
I0314 15:47:59.646944 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:47:59.646944 16588 solver.cpp:244]     Train net output #1: loss = 0.0812488 (* 1 = 0.0812488 loss)
I0314 15:47:59.646944 16588 sgd_solver.cpp:106] Iteration 93200, lr = 0.01
I0314 15:48:14.147104 16588 solver.cpp:228] Iteration 93300, loss = 0.0341638
I0314 15:48:14.147104 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:48:14.147104 16588 solver.cpp:244]     Train net output #1: loss = 0.0341637 (* 1 = 0.0341637 loss)
I0314 15:48:14.147104 16588 sgd_solver.cpp:106] Iteration 93300, lr = 0.01
I0314 15:48:28.663192 16588 solver.cpp:228] Iteration 93400, loss = 0.0210517
I0314 15:48:28.663192 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:48:28.663192 16588 solver.cpp:244]     Train net output #1: loss = 0.0210516 (* 1 = 0.0210516 loss)
I0314 15:48:28.663192 16588 sgd_solver.cpp:106] Iteration 93400, lr = 0.01
I0314 15:48:43.076200 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_93500.caffemodel
I0314 15:48:43.108204 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_93500.solverstate
I0314 15:48:43.118204 16588 solver.cpp:337] Iteration 93500, Testing net (#0)
I0314 15:48:43.118204 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:48:47.920054 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8566
I0314 15:48:47.920054 16588 solver.cpp:404]     Test net output #1: loss = 0.559471 (* 1 = 0.559471 loss)
I0314 15:48:47.980562 16588 solver.cpp:228] Iteration 93500, loss = 0.115571
I0314 15:48:47.980562 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:48:47.980562 16588 solver.cpp:244]     Train net output #1: loss = 0.115571 (* 1 = 0.115571 loss)
I0314 15:48:47.980562 16588 sgd_solver.cpp:106] Iteration 93500, lr = 0.01
I0314 15:49:02.044216 16588 solver.cpp:228] Iteration 93600, loss = 0.075439
I0314 15:49:02.044216 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:49:02.044216 16588 solver.cpp:244]     Train net output #1: loss = 0.0754389 (* 1 = 0.0754389 loss)
I0314 15:49:02.044216 16588 sgd_solver.cpp:106] Iteration 93600, lr = 0.01
I0314 15:49:16.506644 16588 solver.cpp:228] Iteration 93700, loss = 0.0539435
I0314 15:49:16.506644 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:49:16.506644 16588 solver.cpp:244]     Train net output #1: loss = 0.0539434 (* 1 = 0.0539434 loss)
I0314 15:49:16.506644 16588 sgd_solver.cpp:106] Iteration 93700, lr = 0.01
I0314 15:49:31.024428 16588 solver.cpp:228] Iteration 93800, loss = 0.0449016
I0314 15:49:31.024428 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:49:31.024428 16588 solver.cpp:244]     Train net output #1: loss = 0.0449015 (* 1 = 0.0449015 loss)
I0314 15:49:31.024428 16588 sgd_solver.cpp:106] Iteration 93800, lr = 0.01
I0314 15:49:45.490926 16588 solver.cpp:228] Iteration 93900, loss = 0.0918536
I0314 15:49:45.490926 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:49:45.490926 16588 solver.cpp:244]     Train net output #1: loss = 0.0918535 (* 1 = 0.0918535 loss)
I0314 15:49:45.490926 16588 sgd_solver.cpp:106] Iteration 93900, lr = 0.01
I0314 15:49:59.931217 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_94000.caffemodel
I0314 15:49:59.972216 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_94000.solverstate
I0314 15:49:59.977716 16588 solver.cpp:337] Iteration 94000, Testing net (#0)
I0314 15:49:59.978216 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:50:04.813773 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8698
I0314 15:50:04.813773 16588 solver.cpp:404]     Test net output #1: loss = 0.50324 (* 1 = 0.50324 loss)
I0314 15:50:04.863775 16588 solver.cpp:228] Iteration 94000, loss = 0.0274226
I0314 15:50:04.863775 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:50:04.863775 16588 solver.cpp:244]     Train net output #1: loss = 0.0274225 (* 1 = 0.0274225 loss)
I0314 15:50:04.863775 16588 sgd_solver.cpp:106] Iteration 94000, lr = 0.01
I0314 15:50:18.983388 16588 solver.cpp:228] Iteration 94100, loss = 0.0438334
I0314 15:50:18.983388 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:50:18.983388 16588 solver.cpp:244]     Train net output #1: loss = 0.0438333 (* 1 = 0.0438333 loss)
I0314 15:50:18.983388 16588 sgd_solver.cpp:106] Iteration 94100, lr = 0.01
I0314 15:50:33.409839 16588 solver.cpp:228] Iteration 94200, loss = 0.0673035
I0314 15:50:33.409839 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:50:33.409839 16588 solver.cpp:244]     Train net output #1: loss = 0.0673034 (* 1 = 0.0673034 loss)
I0314 15:50:33.409839 16588 sgd_solver.cpp:106] Iteration 94200, lr = 0.01
I0314 15:50:47.951110 16588 solver.cpp:228] Iteration 94300, loss = 0.0976292
I0314 15:50:47.951110 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:50:47.951110 16588 solver.cpp:244]     Train net output #1: loss = 0.0976291 (* 1 = 0.0976291 loss)
I0314 15:50:47.951110 16588 sgd_solver.cpp:106] Iteration 94300, lr = 0.01
I0314 15:51:02.434834 16588 solver.cpp:228] Iteration 94400, loss = 0.0299429
I0314 15:51:02.435354 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:51:02.435354 16588 solver.cpp:244]     Train net output #1: loss = 0.0299428 (* 1 = 0.0299428 loss)
I0314 15:51:02.435354 16588 sgd_solver.cpp:106] Iteration 94400, lr = 0.01
I0314 15:51:16.898622 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_94500.caffemodel
I0314 15:51:16.934118 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_94500.solverstate
I0314 15:51:16.941118 16588 solver.cpp:337] Iteration 94500, Testing net (#0)
I0314 15:51:16.941118 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:51:21.738224 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8286
I0314 15:51:21.738224 16588 solver.cpp:404]     Test net output #1: loss = 0.699703 (* 1 = 0.699703 loss)
I0314 15:51:21.808233 16588 solver.cpp:228] Iteration 94500, loss = 0.121589
I0314 15:51:21.808233 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:51:21.808233 16588 solver.cpp:244]     Train net output #1: loss = 0.121589 (* 1 = 0.121589 loss)
I0314 15:51:21.808233 16588 sgd_solver.cpp:106] Iteration 94500, lr = 0.01
I0314 15:51:35.897071 16588 solver.cpp:228] Iteration 94600, loss = 0.0523676
I0314 15:51:35.897071 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:51:35.897071 16588 solver.cpp:244]     Train net output #1: loss = 0.0523675 (* 1 = 0.0523675 loss)
I0314 15:51:35.897071 16588 sgd_solver.cpp:106] Iteration 94600, lr = 0.01
I0314 15:51:50.377526 16588 solver.cpp:228] Iteration 94700, loss = 0.077551
I0314 15:51:50.377526 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0314 15:51:50.377526 16588 solver.cpp:244]     Train net output #1: loss = 0.077551 (* 1 = 0.077551 loss)
I0314 15:51:50.377526 16588 sgd_solver.cpp:106] Iteration 94700, lr = 0.01
I0314 15:52:04.860100 16588 solver.cpp:228] Iteration 94800, loss = 0.101104
I0314 15:52:04.860100 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0314 15:52:04.860100 16588 solver.cpp:244]     Train net output #1: loss = 0.101104 (* 1 = 0.101104 loss)
I0314 15:52:04.860100 16588 sgd_solver.cpp:106] Iteration 94800, lr = 0.01
I0314 15:52:19.350893 16588 solver.cpp:228] Iteration 94900, loss = 0.0174224
I0314 15:52:19.350893 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:52:19.350893 16588 solver.cpp:244]     Train net output #1: loss = 0.0174223 (* 1 = 0.0174223 loss)
I0314 15:52:19.350893 16588 sgd_solver.cpp:106] Iteration 94900, lr = 0.01
I0314 15:52:33.765126 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_95000.caffemodel
I0314 15:52:33.804626 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_95000.solverstate
I0314 15:52:33.811126 16588 solver.cpp:337] Iteration 95000, Testing net (#0)
I0314 15:52:33.811126 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:52:38.600134 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8729
I0314 15:52:38.600134 16588 solver.cpp:404]     Test net output #1: loss = 0.47604 (* 1 = 0.47604 loss)
I0314 15:52:38.649130 16588 solver.cpp:228] Iteration 95000, loss = 0.0156055
I0314 15:52:38.649130 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:52:38.649130 16588 solver.cpp:244]     Train net output #1: loss = 0.0156054 (* 1 = 0.0156054 loss)
I0314 15:52:38.649130 16588 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I0314 15:52:38.649130 16588 sgd_solver.cpp:106] Iteration 95000, lr = 0.001
I0314 15:52:52.725299 16588 solver.cpp:228] Iteration 95100, loss = 0.0835314
I0314 15:52:52.725299 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0314 15:52:52.725299 16588 solver.cpp:244]     Train net output #1: loss = 0.0835313 (* 1 = 0.0835313 loss)
I0314 15:52:52.725299 16588 sgd_solver.cpp:106] Iteration 95100, lr = 0.001
I0314 15:53:07.246284 16588 solver.cpp:228] Iteration 95200, loss = 0.0282996
I0314 15:53:07.246284 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:53:07.246284 16588 solver.cpp:244]     Train net output #1: loss = 0.0282995 (* 1 = 0.0282995 loss)
I0314 15:53:07.246284 16588 sgd_solver.cpp:106] Iteration 95200, lr = 0.001
I0314 15:53:21.730046 16588 solver.cpp:228] Iteration 95300, loss = 0.0243766
I0314 15:53:21.730545 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:53:21.730545 16588 solver.cpp:244]     Train net output #1: loss = 0.0243765 (* 1 = 0.0243765 loss)
I0314 15:53:21.730545 16588 sgd_solver.cpp:106] Iteration 95300, lr = 0.001
I0314 15:53:36.249423 16588 solver.cpp:228] Iteration 95400, loss = 0.0199735
I0314 15:53:36.249423 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:53:36.249423 16588 solver.cpp:244]     Train net output #1: loss = 0.0199734 (* 1 = 0.0199734 loss)
I0314 15:53:36.249423 16588 sgd_solver.cpp:106] Iteration 95400, lr = 0.001
I0314 15:53:50.654206 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_95500.caffemodel
I0314 15:53:50.691206 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_95500.solverstate
I0314 15:53:50.697207 16588 solver.cpp:337] Iteration 95500, Testing net (#0)
I0314 15:53:50.697207 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:53:55.564079 16588 solver.cpp:404]     Test net output #0: accuracy = 0.89
I0314 15:53:55.564079 16588 solver.cpp:404]     Test net output #1: loss = 0.399234 (* 1 = 0.399234 loss)
I0314 15:53:55.608266 16588 solver.cpp:228] Iteration 95500, loss = 0.00875422
I0314 15:53:55.608266 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:53:55.608266 16588 solver.cpp:244]     Train net output #1: loss = 0.00875413 (* 1 = 0.00875413 loss)
I0314 15:53:55.608266 16588 sgd_solver.cpp:106] Iteration 95500, lr = 0.001
I0314 15:54:09.801050 16588 solver.cpp:228] Iteration 95600, loss = 0.034485
I0314 15:54:09.801553 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:54:09.801553 16588 solver.cpp:244]     Train net output #1: loss = 0.0344849 (* 1 = 0.0344849 loss)
I0314 15:54:09.801553 16588 sgd_solver.cpp:106] Iteration 95600, lr = 0.001
I0314 15:54:24.301065 16588 solver.cpp:228] Iteration 95700, loss = 0.00670505
I0314 15:54:24.301065 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:54:24.301065 16588 solver.cpp:244]     Train net output #1: loss = 0.00670496 (* 1 = 0.00670496 loss)
I0314 15:54:24.301065 16588 sgd_solver.cpp:106] Iteration 95700, lr = 0.001
I0314 15:54:38.811143 16588 solver.cpp:228] Iteration 95800, loss = 0.011542
I0314 15:54:38.811143 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:54:38.811143 16588 solver.cpp:244]     Train net output #1: loss = 0.0115419 (* 1 = 0.0115419 loss)
I0314 15:54:38.811143 16588 sgd_solver.cpp:106] Iteration 95800, lr = 0.001
I0314 15:54:53.191710 16588 solver.cpp:228] Iteration 95900, loss = 0.00722737
I0314 15:54:53.191710 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:54:53.191710 16588 solver.cpp:244]     Train net output #1: loss = 0.00722727 (* 1 = 0.00722727 loss)
I0314 15:54:53.191710 16588 sgd_solver.cpp:106] Iteration 95900, lr = 0.001
I0314 15:55:07.613493 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_96000.caffemodel
I0314 15:55:07.650146 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_96000.solverstate
I0314 15:55:07.657145 16588 solver.cpp:337] Iteration 96000, Testing net (#0)
I0314 15:55:07.657145 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:55:12.475813 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8905
I0314 15:55:12.476310 16588 solver.cpp:404]     Test net output #1: loss = 0.394779 (* 1 = 0.394779 loss)
I0314 15:55:12.526309 16588 solver.cpp:228] Iteration 96000, loss = 0.0112144
I0314 15:55:12.526309 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:55:12.526309 16588 solver.cpp:244]     Train net output #1: loss = 0.0112143 (* 1 = 0.0112143 loss)
I0314 15:55:12.526309 16588 sgd_solver.cpp:106] Iteration 96000, lr = 0.001
I0314 15:55:26.711297 16588 solver.cpp:228] Iteration 96100, loss = 0.0149854
I0314 15:55:26.711297 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:55:26.711297 16588 solver.cpp:244]     Train net output #1: loss = 0.0149853 (* 1 = 0.0149853 loss)
I0314 15:55:26.711297 16588 sgd_solver.cpp:106] Iteration 96100, lr = 0.001
I0314 15:55:41.194924 16588 solver.cpp:228] Iteration 96200, loss = 0.00592462
I0314 15:55:41.194924 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:55:41.194924 16588 solver.cpp:244]     Train net output #1: loss = 0.00592452 (* 1 = 0.00592452 loss)
I0314 15:55:41.194924 16588 sgd_solver.cpp:106] Iteration 96200, lr = 0.001
I0314 15:55:55.686837 16588 solver.cpp:228] Iteration 96300, loss = 0.00833483
I0314 15:55:55.686837 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:55:55.686837 16588 solver.cpp:244]     Train net output #1: loss = 0.00833472 (* 1 = 0.00833472 loss)
I0314 15:55:55.686837 16588 sgd_solver.cpp:106] Iteration 96300, lr = 0.001
I0314 15:56:10.191210 16588 solver.cpp:228] Iteration 96400, loss = 0.00635732
I0314 15:56:10.191210 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:56:10.191210 16588 solver.cpp:244]     Train net output #1: loss = 0.00635722 (* 1 = 0.00635722 loss)
I0314 15:56:10.191210 16588 sgd_solver.cpp:106] Iteration 96400, lr = 0.001
I0314 15:56:24.581743 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_96500.caffemodel
I0314 15:56:24.610750 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_96500.solverstate
I0314 15:56:24.620750 16588 solver.cpp:337] Iteration 96500, Testing net (#0)
I0314 15:56:24.620750 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:56:29.409272 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8916
I0314 15:56:29.409272 16588 solver.cpp:404]     Test net output #1: loss = 0.393425 (* 1 = 0.393425 loss)
I0314 15:56:29.456274 16588 solver.cpp:228] Iteration 96500, loss = 0.00836978
I0314 15:56:29.456274 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:56:29.456274 16588 solver.cpp:244]     Train net output #1: loss = 0.00836969 (* 1 = 0.00836969 loss)
I0314 15:56:29.456274 16588 sgd_solver.cpp:106] Iteration 96500, lr = 0.001
I0314 15:56:43.683261 16588 solver.cpp:228] Iteration 96600, loss = 0.0203682
I0314 15:56:43.683261 16588 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0314 15:56:43.683261 16588 solver.cpp:244]     Train net output #1: loss = 0.0203681 (* 1 = 0.0203681 loss)
I0314 15:56:43.683261 16588 sgd_solver.cpp:106] Iteration 96600, lr = 0.001
I0314 15:56:58.141544 16588 solver.cpp:228] Iteration 96700, loss = 0.016724
I0314 15:56:58.141544 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:56:58.141544 16588 solver.cpp:244]     Train net output #1: loss = 0.0167239 (* 1 = 0.0167239 loss)
I0314 15:56:58.141544 16588 sgd_solver.cpp:106] Iteration 96700, lr = 0.001
I0314 15:57:12.627384 16588 solver.cpp:228] Iteration 96800, loss = 0.010551
I0314 15:57:12.627384 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:57:12.627384 16588 solver.cpp:244]     Train net output #1: loss = 0.0105509 (* 1 = 0.0105509 loss)
I0314 15:57:12.627384 16588 sgd_solver.cpp:106] Iteration 96800, lr = 0.001
I0314 15:57:27.132344 16588 solver.cpp:228] Iteration 96900, loss = 0.00560059
I0314 15:57:27.132344 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:57:27.132344 16588 solver.cpp:244]     Train net output #1: loss = 0.00560051 (* 1 = 0.00560051 loss)
I0314 15:57:27.132344 16588 sgd_solver.cpp:106] Iteration 96900, lr = 0.001
I0314 15:57:41.571616 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_97000.caffemodel
I0314 15:57:41.601598 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_97000.solverstate
I0314 15:57:41.611621 16588 solver.cpp:337] Iteration 97000, Testing net (#0)
I0314 15:57:41.611621 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:57:46.414793 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8936
I0314 15:57:46.414793 16588 solver.cpp:404]     Test net output #1: loss = 0.391856 (* 1 = 0.391856 loss)
I0314 15:57:46.474311 16588 solver.cpp:228] Iteration 97000, loss = 0.0101353
I0314 15:57:46.474311 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:57:46.474311 16588 solver.cpp:244]     Train net output #1: loss = 0.0101352 (* 1 = 0.0101352 loss)
I0314 15:57:46.474311 16588 sgd_solver.cpp:106] Iteration 97000, lr = 0.001
I0314 15:58:00.619609 16588 solver.cpp:228] Iteration 97100, loss = 0.0172985
I0314 15:58:00.619609 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:58:00.619609 16588 solver.cpp:244]     Train net output #1: loss = 0.0172984 (* 1 = 0.0172984 loss)
I0314 15:58:00.619609 16588 sgd_solver.cpp:106] Iteration 97100, lr = 0.001
I0314 15:58:15.034338 16588 solver.cpp:228] Iteration 97200, loss = 0.0072466
I0314 15:58:15.034338 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:58:15.034338 16588 solver.cpp:244]     Train net output #1: loss = 0.00724652 (* 1 = 0.00724652 loss)
I0314 15:58:15.034338 16588 sgd_solver.cpp:106] Iteration 97200, lr = 0.001
I0314 15:58:29.498597 16588 solver.cpp:228] Iteration 97300, loss = 0.00612863
I0314 15:58:29.499097 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:58:29.499097 16588 solver.cpp:244]     Train net output #1: loss = 0.00612855 (* 1 = 0.00612855 loss)
I0314 15:58:29.499097 16588 sgd_solver.cpp:106] Iteration 97300, lr = 0.001
I0314 15:58:43.927120 16588 solver.cpp:228] Iteration 97400, loss = 0.00573071
I0314 15:58:43.927120 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:58:43.927120 16588 solver.cpp:244]     Train net output #1: loss = 0.00573062 (* 1 = 0.00573062 loss)
I0314 15:58:43.927120 16588 sgd_solver.cpp:106] Iteration 97400, lr = 0.001
I0314 15:58:58.339213 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_97500.caffemodel
I0314 15:58:58.374214 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_97500.solverstate
I0314 15:58:58.380214 16588 solver.cpp:337] Iteration 97500, Testing net (#0)
I0314 15:58:58.380214 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 15:59:03.254664 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8935
I0314 15:59:03.254664 16588 solver.cpp:404]     Test net output #1: loss = 0.391201 (* 1 = 0.391201 loss)
I0314 15:59:03.304667 16588 solver.cpp:228] Iteration 97500, loss = 0.00658049
I0314 15:59:03.304667 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:59:03.304667 16588 solver.cpp:244]     Train net output #1: loss = 0.0065804 (* 1 = 0.0065804 loss)
I0314 15:59:03.304667 16588 sgd_solver.cpp:106] Iteration 97500, lr = 0.001
I0314 15:59:17.513677 16588 solver.cpp:228] Iteration 97600, loss = 0.0090023
I0314 15:59:17.514178 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:59:17.514178 16588 solver.cpp:244]     Train net output #1: loss = 0.0090022 (* 1 = 0.0090022 loss)
I0314 15:59:17.514178 16588 sgd_solver.cpp:106] Iteration 97600, lr = 0.001
I0314 15:59:32.001878 16588 solver.cpp:228] Iteration 97700, loss = 0.010556
I0314 15:59:32.001878 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:59:32.001878 16588 solver.cpp:244]     Train net output #1: loss = 0.0105559 (* 1 = 0.0105559 loss)
I0314 15:59:32.001878 16588 sgd_solver.cpp:106] Iteration 97700, lr = 0.001
I0314 15:59:46.442859 16588 solver.cpp:228] Iteration 97800, loss = 0.00728201
I0314 15:59:46.442859 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 15:59:46.442859 16588 solver.cpp:244]     Train net output #1: loss = 0.00728191 (* 1 = 0.00728191 loss)
I0314 15:59:46.442859 16588 sgd_solver.cpp:106] Iteration 97800, lr = 0.001
I0314 16:00:00.947304 16588 solver.cpp:228] Iteration 97900, loss = 0.0055304
I0314 16:00:00.947304 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:00:00.947304 16588 solver.cpp:244]     Train net output #1: loss = 0.0055303 (* 1 = 0.0055303 loss)
I0314 16:00:00.947304 16588 sgd_solver.cpp:106] Iteration 97900, lr = 0.001
I0314 16:00:15.344769 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_98000.caffemodel
I0314 16:00:15.382266 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_98000.solverstate
I0314 16:00:15.388766 16588 solver.cpp:337] Iteration 98000, Testing net (#0)
I0314 16:00:15.388766 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:00:20.183012 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8928
I0314 16:00:20.183012 16588 solver.cpp:404]     Test net output #1: loss = 0.392122 (* 1 = 0.392122 loss)
I0314 16:00:20.213593 16588 solver.cpp:228] Iteration 98000, loss = 0.00585913
I0314 16:00:20.213593 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:00:20.214094 16588 solver.cpp:244]     Train net output #1: loss = 0.00585904 (* 1 = 0.00585904 loss)
I0314 16:00:20.214094 16588 sgd_solver.cpp:106] Iteration 98000, lr = 0.001
I0314 16:00:34.320340 16588 solver.cpp:228] Iteration 98100, loss = 0.00938073
I0314 16:00:34.320340 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:00:34.320340 16588 solver.cpp:244]     Train net output #1: loss = 0.00938063 (* 1 = 0.00938063 loss)
I0314 16:00:34.320340 16588 sgd_solver.cpp:106] Iteration 98100, lr = 0.001
I0314 16:00:48.772552 16588 solver.cpp:228] Iteration 98200, loss = 0.00556934
I0314 16:00:48.773051 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:00:48.773051 16588 solver.cpp:244]     Train net output #1: loss = 0.00556924 (* 1 = 0.00556924 loss)
I0314 16:00:48.773051 16588 sgd_solver.cpp:106] Iteration 98200, lr = 0.001
I0314 16:01:03.253984 16588 solver.cpp:228] Iteration 98300, loss = 0.00510724
I0314 16:01:03.253984 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:01:03.253984 16588 solver.cpp:244]     Train net output #1: loss = 0.00510714 (* 1 = 0.00510714 loss)
I0314 16:01:03.253984 16588 sgd_solver.cpp:106] Iteration 98300, lr = 0.001
I0314 16:01:17.696617 16588 solver.cpp:228] Iteration 98400, loss = 0.0063522
I0314 16:01:17.696617 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:01:17.696617 16588 solver.cpp:244]     Train net output #1: loss = 0.0063521 (* 1 = 0.0063521 loss)
I0314 16:01:17.696617 16588 sgd_solver.cpp:106] Iteration 98400, lr = 0.001
I0314 16:01:32.188612 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_98500.caffemodel
I0314 16:01:32.223109 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_98500.solverstate
I0314 16:01:32.229110 16588 solver.cpp:337] Iteration 98500, Testing net (#0)
I0314 16:01:32.229110 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:01:37.028188 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8947
I0314 16:01:37.028188 16588 solver.cpp:404]     Test net output #1: loss = 0.392078 (* 1 = 0.392078 loss)
I0314 16:01:37.057189 16588 solver.cpp:228] Iteration 98500, loss = 0.00487332
I0314 16:01:37.057189 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:01:37.057189 16588 solver.cpp:244]     Train net output #1: loss = 0.00487322 (* 1 = 0.00487322 loss)
I0314 16:01:37.057189 16588 sgd_solver.cpp:106] Iteration 98500, lr = 0.001
I0314 16:01:51.061298 16588 solver.cpp:228] Iteration 98600, loss = 0.00843388
I0314 16:01:51.061298 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:01:51.061799 16588 solver.cpp:244]     Train net output #1: loss = 0.00843379 (* 1 = 0.00843379 loss)
I0314 16:01:51.061799 16588 sgd_solver.cpp:106] Iteration 98600, lr = 0.001
I0314 16:02:05.524581 16588 solver.cpp:228] Iteration 98700, loss = 0.00628226
I0314 16:02:05.524581 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:02:05.524581 16588 solver.cpp:244]     Train net output #1: loss = 0.00628216 (* 1 = 0.00628216 loss)
I0314 16:02:05.524581 16588 sgd_solver.cpp:106] Iteration 98700, lr = 0.001
I0314 16:02:20.059440 16588 solver.cpp:228] Iteration 98800, loss = 0.00604576
I0314 16:02:20.059440 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:02:20.059440 16588 solver.cpp:244]     Train net output #1: loss = 0.00604566 (* 1 = 0.00604566 loss)
I0314 16:02:20.059440 16588 sgd_solver.cpp:106] Iteration 98800, lr = 0.001
I0314 16:02:34.544256 16588 solver.cpp:228] Iteration 98900, loss = 0.00437533
I0314 16:02:34.544256 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:02:34.544256 16588 solver.cpp:244]     Train net output #1: loss = 0.00437523 (* 1 = 0.00437523 loss)
I0314 16:02:34.544256 16588 sgd_solver.cpp:106] Iteration 98900, lr = 0.001
I0314 16:02:48.924542 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_99000.caffemodel
I0314 16:02:48.945042 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_99000.solverstate
I0314 16:02:48.951042 16588 solver.cpp:337] Iteration 99000, Testing net (#0)
I0314 16:02:48.951042 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:02:53.789116 16588 solver.cpp:404]     Test net output #0: accuracy = 0.894
I0314 16:02:53.789116 16588 solver.cpp:404]     Test net output #1: loss = 0.392032 (* 1 = 0.392032 loss)
I0314 16:02:53.859124 16588 solver.cpp:228] Iteration 99000, loss = 0.00639613
I0314 16:02:53.859124 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:02:53.859124 16588 solver.cpp:244]     Train net output #1: loss = 0.00639603 (* 1 = 0.00639603 loss)
I0314 16:02:53.859124 16588 sgd_solver.cpp:106] Iteration 99000, lr = 0.001
I0314 16:03:08.023007 16588 solver.cpp:228] Iteration 99100, loss = 0.0066535
I0314 16:03:08.023007 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:03:08.023007 16588 solver.cpp:244]     Train net output #1: loss = 0.0066534 (* 1 = 0.0066534 loss)
I0314 16:03:08.023007 16588 sgd_solver.cpp:106] Iteration 99100, lr = 0.001
I0314 16:03:22.432303 16588 solver.cpp:228] Iteration 99200, loss = 0.00823769
I0314 16:03:22.432303 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:03:22.432303 16588 solver.cpp:244]     Train net output #1: loss = 0.00823759 (* 1 = 0.00823759 loss)
I0314 16:03:22.432303 16588 sgd_solver.cpp:106] Iteration 99200, lr = 0.001
I0314 16:03:36.907879 16588 solver.cpp:228] Iteration 99300, loss = 0.00699899
I0314 16:03:36.907879 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:03:36.907879 16588 solver.cpp:244]     Train net output #1: loss = 0.00699889 (* 1 = 0.00699889 loss)
I0314 16:03:36.907879 16588 sgd_solver.cpp:106] Iteration 99300, lr = 0.001
I0314 16:03:51.362752 16588 solver.cpp:228] Iteration 99400, loss = 0.00763265
I0314 16:03:51.362752 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:03:51.362752 16588 solver.cpp:244]     Train net output #1: loss = 0.00763255 (* 1 = 0.00763255 loss)
I0314 16:03:51.362752 16588 sgd_solver.cpp:106] Iteration 99400, lr = 0.001
I0314 16:04:05.736894 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_99500.caffemodel
I0314 16:04:05.775394 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_99500.solverstate
I0314 16:04:05.781394 16588 solver.cpp:337] Iteration 99500, Testing net (#0)
I0314 16:04:05.781895 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:04:10.477382 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8942
I0314 16:04:10.477382 16588 solver.cpp:404]     Test net output #1: loss = 0.39286 (* 1 = 0.39286 loss)
I0314 16:04:10.526387 16588 solver.cpp:228] Iteration 99500, loss = 0.00388334
I0314 16:04:10.526387 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:04:10.526387 16588 solver.cpp:244]     Train net output #1: loss = 0.00388325 (* 1 = 0.00388325 loss)
I0314 16:04:10.526387 16588 sgd_solver.cpp:106] Iteration 99500, lr = 0.001
I0314 16:04:24.673602 16588 solver.cpp:228] Iteration 99600, loss = 0.00808875
I0314 16:04:24.673602 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:04:24.674103 16588 solver.cpp:244]     Train net output #1: loss = 0.00808865 (* 1 = 0.00808865 loss)
I0314 16:04:24.674103 16588 sgd_solver.cpp:106] Iteration 99600, lr = 0.001
I0314 16:04:39.246031 16588 solver.cpp:228] Iteration 99700, loss = 0.00579957
I0314 16:04:39.246031 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:04:39.246031 16588 solver.cpp:244]     Train net output #1: loss = 0.00579947 (* 1 = 0.00579947 loss)
I0314 16:04:39.246031 16588 sgd_solver.cpp:106] Iteration 99700, lr = 0.001
I0314 16:04:53.660501 16588 solver.cpp:228] Iteration 99800, loss = 0.0040931
I0314 16:04:53.660501 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:04:53.660501 16588 solver.cpp:244]     Train net output #1: loss = 0.004093 (* 1 = 0.004093 loss)
I0314 16:04:53.660501 16588 sgd_solver.cpp:106] Iteration 99800, lr = 0.001
I0314 16:05:08.143052 16588 solver.cpp:228] Iteration 99900, loss = 0.00524722
I0314 16:05:08.143052 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:05:08.143052 16588 solver.cpp:244]     Train net output #1: loss = 0.00524712 (* 1 = 0.00524712 loss)
I0314 16:05:08.143052 16588 sgd_solver.cpp:106] Iteration 99900, lr = 0.001
I0314 16:05:22.523223 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_100000.caffemodel
I0314 16:05:22.562222 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_100000.solverstate
I0314 16:05:22.568737 16588 solver.cpp:337] Iteration 100000, Testing net (#0)
I0314 16:05:22.568737 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:05:27.315403 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8937
I0314 16:05:27.315403 16588 solver.cpp:404]     Test net output #1: loss = 0.392205 (* 1 = 0.392205 loss)
I0314 16:05:27.365396 16588 solver.cpp:228] Iteration 100000, loss = 0.00569093
I0314 16:05:27.365396 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:05:27.365396 16588 solver.cpp:244]     Train net output #1: loss = 0.00569084 (* 1 = 0.00569084 loss)
I0314 16:05:27.365396 16588 sgd_solver.cpp:106] Iteration 100000, lr = 0.001
I0314 16:05:41.565014 16588 solver.cpp:228] Iteration 100100, loss = 0.00873581
I0314 16:05:41.565014 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:05:41.565014 16588 solver.cpp:244]     Train net output #1: loss = 0.00873571 (* 1 = 0.00873571 loss)
I0314 16:05:41.565014 16588 sgd_solver.cpp:106] Iteration 100100, lr = 0.001
I0314 16:05:55.959528 16588 solver.cpp:228] Iteration 100200, loss = 0.00435039
I0314 16:05:55.959528 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:05:55.959528 16588 solver.cpp:244]     Train net output #1: loss = 0.00435029 (* 1 = 0.00435029 loss)
I0314 16:05:55.959528 16588 sgd_solver.cpp:106] Iteration 100200, lr = 0.001
I0314 16:06:10.423844 16588 solver.cpp:228] Iteration 100300, loss = 0.00336399
I0314 16:06:10.423844 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:06:10.423844 16588 solver.cpp:244]     Train net output #1: loss = 0.00336389 (* 1 = 0.00336389 loss)
I0314 16:06:10.423844 16588 sgd_solver.cpp:106] Iteration 100300, lr = 0.001
I0314 16:06:24.899791 16588 solver.cpp:228] Iteration 100400, loss = 0.00307177
I0314 16:06:24.899791 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:06:24.899791 16588 solver.cpp:244]     Train net output #1: loss = 0.00307167 (* 1 = 0.00307167 loss)
I0314 16:06:24.899791 16588 sgd_solver.cpp:106] Iteration 100400, lr = 0.001
I0314 16:06:39.344594 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_100500.caffemodel
I0314 16:06:39.382094 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_100500.solverstate
I0314 16:06:39.389096 16588 solver.cpp:337] Iteration 100500, Testing net (#0)
I0314 16:06:39.389096 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:06:44.184005 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8937
I0314 16:06:44.184005 16588 solver.cpp:404]     Test net output #1: loss = 0.392284 (* 1 = 0.392284 loss)
I0314 16:06:44.242094 16588 solver.cpp:228] Iteration 100500, loss = 0.00560342
I0314 16:06:44.242094 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:06:44.242094 16588 solver.cpp:244]     Train net output #1: loss = 0.00560332 (* 1 = 0.00560332 loss)
I0314 16:06:44.242094 16588 sgd_solver.cpp:106] Iteration 100500, lr = 0.001
I0314 16:06:58.262228 16588 solver.cpp:228] Iteration 100600, loss = 0.00674718
I0314 16:06:58.262228 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:06:58.262228 16588 solver.cpp:244]     Train net output #1: loss = 0.00674708 (* 1 = 0.00674708 loss)
I0314 16:06:58.262228 16588 sgd_solver.cpp:106] Iteration 100600, lr = 0.001
I0314 16:07:12.732146 16588 solver.cpp:228] Iteration 100700, loss = 0.00468245
I0314 16:07:12.732146 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:07:12.732146 16588 solver.cpp:244]     Train net output #1: loss = 0.00468235 (* 1 = 0.00468235 loss)
I0314 16:07:12.732146 16588 sgd_solver.cpp:106] Iteration 100700, lr = 0.001
I0314 16:07:27.179268 16588 solver.cpp:228] Iteration 100800, loss = 0.00334391
I0314 16:07:27.179268 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:07:27.179268 16588 solver.cpp:244]     Train net output #1: loss = 0.00334381 (* 1 = 0.00334381 loss)
I0314 16:07:27.179268 16588 sgd_solver.cpp:106] Iteration 100800, lr = 0.001
I0314 16:07:41.635866 16588 solver.cpp:228] Iteration 100900, loss = 0.00541959
I0314 16:07:41.635866 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:07:41.635866 16588 solver.cpp:244]     Train net output #1: loss = 0.00541949 (* 1 = 0.00541949 loss)
I0314 16:07:41.635866 16588 sgd_solver.cpp:106] Iteration 100900, lr = 0.001
I0314 16:07:56.052346 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_101000.caffemodel
I0314 16:07:56.087846 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_101000.solverstate
I0314 16:07:56.095346 16588 solver.cpp:337] Iteration 101000, Testing net (#0)
I0314 16:07:56.095346 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:08:00.868247 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8936
I0314 16:08:00.868247 16588 solver.cpp:404]     Test net output #1: loss = 0.391448 (* 1 = 0.391448 loss)
I0314 16:08:00.924747 16588 solver.cpp:228] Iteration 101000, loss = 0.00383474
I0314 16:08:00.924747 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:08:00.924747 16588 solver.cpp:244]     Train net output #1: loss = 0.00383464 (* 1 = 0.00383464 loss)
I0314 16:08:00.924747 16588 sgd_solver.cpp:106] Iteration 101000, lr = 0.001
I0314 16:08:15.069475 16588 solver.cpp:228] Iteration 101100, loss = 0.0076157
I0314 16:08:15.069475 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:08:15.069475 16588 solver.cpp:244]     Train net output #1: loss = 0.0076156 (* 1 = 0.0076156 loss)
I0314 16:08:15.069475 16588 sgd_solver.cpp:106] Iteration 101100, lr = 0.001
I0314 16:08:29.479111 16588 solver.cpp:228] Iteration 101200, loss = 0.00669063
I0314 16:08:29.479111 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:08:29.479111 16588 solver.cpp:244]     Train net output #1: loss = 0.00669053 (* 1 = 0.00669053 loss)
I0314 16:08:29.479111 16588 sgd_solver.cpp:106] Iteration 101200, lr = 0.001
I0314 16:08:43.871882 16588 solver.cpp:228] Iteration 101300, loss = 0.00530573
I0314 16:08:43.871882 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:08:43.871882 16588 solver.cpp:244]     Train net output #1: loss = 0.00530564 (* 1 = 0.00530564 loss)
I0314 16:08:43.871882 16588 sgd_solver.cpp:106] Iteration 101300, lr = 0.001
I0314 16:08:58.293694 16588 solver.cpp:228] Iteration 101400, loss = 0.00413694
I0314 16:08:58.293694 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:08:58.293694 16588 solver.cpp:244]     Train net output #1: loss = 0.00413684 (* 1 = 0.00413684 loss)
I0314 16:08:58.293694 16588 sgd_solver.cpp:106] Iteration 101400, lr = 0.001
I0314 16:09:12.668722 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_101500.caffemodel
I0314 16:09:12.688725 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_101500.solverstate
I0314 16:09:12.688725 16588 solver.cpp:337] Iteration 101500, Testing net (#0)
I0314 16:09:12.688725 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:09:17.510944 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8938
I0314 16:09:17.510944 16588 solver.cpp:404]     Test net output #1: loss = 0.3902 (* 1 = 0.3902 loss)
I0314 16:09:17.571004 16588 solver.cpp:228] Iteration 101500, loss = 0.00496655
I0314 16:09:17.571004 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:09:17.571004 16588 solver.cpp:244]     Train net output #1: loss = 0.00496644 (* 1 = 0.00496644 loss)
I0314 16:09:17.571004 16588 sgd_solver.cpp:106] Iteration 101500, lr = 0.001
I0314 16:09:31.618463 16588 solver.cpp:228] Iteration 101600, loss = 0.00644721
I0314 16:09:31.618463 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:09:31.618463 16588 solver.cpp:244]     Train net output #1: loss = 0.0064471 (* 1 = 0.0064471 loss)
I0314 16:09:31.618463 16588 sgd_solver.cpp:106] Iteration 101600, lr = 0.001
I0314 16:09:46.112354 16588 solver.cpp:228] Iteration 101700, loss = 0.00399251
I0314 16:09:46.112859 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:09:46.112859 16588 solver.cpp:244]     Train net output #1: loss = 0.00399241 (* 1 = 0.00399241 loss)
I0314 16:09:46.112859 16588 sgd_solver.cpp:106] Iteration 101700, lr = 0.001
I0314 16:10:00.625597 16588 solver.cpp:228] Iteration 101800, loss = 0.00407371
I0314 16:10:00.625597 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:10:00.625597 16588 solver.cpp:244]     Train net output #1: loss = 0.00407361 (* 1 = 0.00407361 loss)
I0314 16:10:00.625597 16588 sgd_solver.cpp:106] Iteration 101800, lr = 0.001
I0314 16:10:15.104746 16588 solver.cpp:228] Iteration 101900, loss = 0.00275804
I0314 16:10:15.105247 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:10:15.105247 16588 solver.cpp:244]     Train net output #1: loss = 0.00275794 (* 1 = 0.00275794 loss)
I0314 16:10:15.105247 16588 sgd_solver.cpp:106] Iteration 101900, lr = 0.001
I0314 16:10:29.538532 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_102000.caffemodel
I0314 16:10:29.577530 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_102000.solverstate
I0314 16:10:29.583030 16588 solver.cpp:337] Iteration 102000, Testing net (#0)
I0314 16:10:29.583030 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:10:34.373190 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8944
I0314 16:10:34.373190 16588 solver.cpp:404]     Test net output #1: loss = 0.391074 (* 1 = 0.391074 loss)
I0314 16:10:34.413692 16588 solver.cpp:228] Iteration 102000, loss = 0.00549601
I0314 16:10:34.413692 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:10:34.413692 16588 solver.cpp:244]     Train net output #1: loss = 0.0054959 (* 1 = 0.0054959 loss)
I0314 16:10:34.413692 16588 sgd_solver.cpp:106] Iteration 102000, lr = 0.001
I0314 16:10:48.510346 16588 solver.cpp:228] Iteration 102100, loss = 0.00579079
I0314 16:10:48.510346 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:10:48.510346 16588 solver.cpp:244]     Train net output #1: loss = 0.00579068 (* 1 = 0.00579068 loss)
I0314 16:10:48.510346 16588 sgd_solver.cpp:106] Iteration 102100, lr = 0.001
I0314 16:11:03.007650 16588 solver.cpp:228] Iteration 102200, loss = 0.00502377
I0314 16:11:03.007650 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:11:03.007650 16588 solver.cpp:244]     Train net output #1: loss = 0.00502367 (* 1 = 0.00502367 loss)
I0314 16:11:03.007650 16588 sgd_solver.cpp:106] Iteration 102200, lr = 0.001
I0314 16:11:17.576557 16588 solver.cpp:228] Iteration 102300, loss = 0.00337086
I0314 16:11:17.576557 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:11:17.576557 16588 solver.cpp:244]     Train net output #1: loss = 0.00337076 (* 1 = 0.00337076 loss)
I0314 16:11:17.576557 16588 sgd_solver.cpp:106] Iteration 102300, lr = 0.001
I0314 16:11:32.035312 16588 solver.cpp:228] Iteration 102400, loss = 0.00543891
I0314 16:11:32.035312 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:11:32.035312 16588 solver.cpp:244]     Train net output #1: loss = 0.0054388 (* 1 = 0.0054388 loss)
I0314 16:11:32.035312 16588 sgd_solver.cpp:106] Iteration 102400, lr = 0.001
I0314 16:11:46.440147 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_102500.caffemodel
I0314 16:11:46.476148 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_102500.solverstate
I0314 16:11:46.483149 16588 solver.cpp:337] Iteration 102500, Testing net (#0)
I0314 16:11:46.483149 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:11:51.284525 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8949
I0314 16:11:51.284525 16588 solver.cpp:404]     Test net output #1: loss = 0.389976 (* 1 = 0.389976 loss)
I0314 16:11:51.334132 16588 solver.cpp:228] Iteration 102500, loss = 0.00577269
I0314 16:11:51.334132 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:11:51.334132 16588 solver.cpp:244]     Train net output #1: loss = 0.00577259 (* 1 = 0.00577259 loss)
I0314 16:11:51.334132 16588 sgd_solver.cpp:106] Iteration 102500, lr = 0.001
I0314 16:12:05.396955 16588 solver.cpp:228] Iteration 102600, loss = 0.00642736
I0314 16:12:05.396955 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:12:05.396955 16588 solver.cpp:244]     Train net output #1: loss = 0.00642726 (* 1 = 0.00642726 loss)
I0314 16:12:05.396955 16588 sgd_solver.cpp:106] Iteration 102600, lr = 0.001
I0314 16:12:19.866394 16588 solver.cpp:228] Iteration 102700, loss = 0.00436897
I0314 16:12:19.866895 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:12:19.866895 16588 solver.cpp:244]     Train net output #1: loss = 0.00436887 (* 1 = 0.00436887 loss)
I0314 16:12:19.866895 16588 sgd_solver.cpp:106] Iteration 102700, lr = 0.001
I0314 16:12:34.337734 16588 solver.cpp:228] Iteration 102800, loss = 0.00266571
I0314 16:12:34.337734 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:12:34.337734 16588 solver.cpp:244]     Train net output #1: loss = 0.00266561 (* 1 = 0.00266561 loss)
I0314 16:12:34.337734 16588 sgd_solver.cpp:106] Iteration 102800, lr = 0.001
I0314 16:12:48.733340 16588 solver.cpp:228] Iteration 102900, loss = 0.00249475
I0314 16:12:48.733340 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:12:48.733340 16588 solver.cpp:244]     Train net output #1: loss = 0.00249465 (* 1 = 0.00249465 loss)
I0314 16:12:48.733340 16588 sgd_solver.cpp:106] Iteration 102900, lr = 0.001
I0314 16:13:03.140638 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_103000.caffemodel
I0314 16:13:03.177639 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_103000.solverstate
I0314 16:13:03.184137 16588 solver.cpp:337] Iteration 103000, Testing net (#0)
I0314 16:13:03.184137 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:13:08.005216 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8942
I0314 16:13:08.005718 16588 solver.cpp:404]     Test net output #1: loss = 0.389949 (* 1 = 0.389949 loss)
I0314 16:13:08.058720 16588 solver.cpp:228] Iteration 103000, loss = 0.00454628
I0314 16:13:08.058720 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:13:08.058720 16588 solver.cpp:244]     Train net output #1: loss = 0.00454618 (* 1 = 0.00454618 loss)
I0314 16:13:08.058720 16588 sgd_solver.cpp:106] Iteration 103000, lr = 0.001
I0314 16:13:22.337334 16588 solver.cpp:228] Iteration 103100, loss = 0.00584633
I0314 16:13:22.337334 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:13:22.337334 16588 solver.cpp:244]     Train net output #1: loss = 0.00584623 (* 1 = 0.00584623 loss)
I0314 16:13:22.337334 16588 sgd_solver.cpp:106] Iteration 103100, lr = 0.001
I0314 16:13:36.786815 16588 solver.cpp:228] Iteration 103200, loss = 0.00374413
I0314 16:13:36.786815 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:13:36.786815 16588 solver.cpp:244]     Train net output #1: loss = 0.00374403 (* 1 = 0.00374403 loss)
I0314 16:13:36.786815 16588 sgd_solver.cpp:106] Iteration 103200, lr = 0.001
I0314 16:13:51.228909 16588 solver.cpp:228] Iteration 103300, loss = 0.003841
I0314 16:13:51.228909 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:13:51.228909 16588 solver.cpp:244]     Train net output #1: loss = 0.0038409 (* 1 = 0.0038409 loss)
I0314 16:13:51.228909 16588 sgd_solver.cpp:106] Iteration 103300, lr = 0.001
I0314 16:14:05.736675 16588 solver.cpp:228] Iteration 103400, loss = 0.00434875
I0314 16:14:05.736675 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:14:05.736675 16588 solver.cpp:244]     Train net output #1: loss = 0.00434864 (* 1 = 0.00434864 loss)
I0314 16:14:05.736675 16588 sgd_solver.cpp:106] Iteration 103400, lr = 0.001
I0314 16:14:20.140702 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_103500.caffemodel
I0314 16:14:20.158700 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_103500.solverstate
I0314 16:14:20.165200 16588 solver.cpp:337] Iteration 103500, Testing net (#0)
I0314 16:14:20.165700 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:14:24.999744 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8948
I0314 16:14:24.999744 16588 solver.cpp:404]     Test net output #1: loss = 0.389977 (* 1 = 0.389977 loss)
I0314 16:14:25.045241 16588 solver.cpp:228] Iteration 103500, loss = 0.00387526
I0314 16:14:25.045241 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:14:25.045241 16588 solver.cpp:244]     Train net output #1: loss = 0.00387516 (* 1 = 0.00387516 loss)
I0314 16:14:25.045241 16588 sgd_solver.cpp:106] Iteration 103500, lr = 0.001
I0314 16:14:39.235045 16588 solver.cpp:228] Iteration 103600, loss = 0.00647397
I0314 16:14:39.235045 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:14:39.235045 16588 solver.cpp:244]     Train net output #1: loss = 0.00647386 (* 1 = 0.00647386 loss)
I0314 16:14:39.235045 16588 sgd_solver.cpp:106] Iteration 103600, lr = 0.001
I0314 16:14:53.609778 16588 solver.cpp:228] Iteration 103700, loss = 0.00374813
I0314 16:14:53.609778 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:14:53.609778 16588 solver.cpp:244]     Train net output #1: loss = 0.00374803 (* 1 = 0.00374803 loss)
I0314 16:14:53.609778 16588 sgd_solver.cpp:106] Iteration 103700, lr = 0.001
I0314 16:15:08.058190 16588 solver.cpp:228] Iteration 103800, loss = 0.00527956
I0314 16:15:08.058190 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:15:08.058190 16588 solver.cpp:244]     Train net output #1: loss = 0.00527945 (* 1 = 0.00527945 loss)
I0314 16:15:08.058190 16588 sgd_solver.cpp:106] Iteration 103800, lr = 0.001
I0314 16:15:22.525766 16588 solver.cpp:228] Iteration 103900, loss = 0.00469732
I0314 16:15:22.525766 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:15:22.525766 16588 solver.cpp:244]     Train net output #1: loss = 0.00469722 (* 1 = 0.00469722 loss)
I0314 16:15:22.525766 16588 sgd_solver.cpp:106] Iteration 103900, lr = 0.001
I0314 16:15:36.954516 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_104000.caffemodel
I0314 16:15:36.991516 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_104000.solverstate
I0314 16:15:36.998016 16588 solver.cpp:337] Iteration 104000, Testing net (#0)
I0314 16:15:36.998016 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:15:41.856470 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8948
I0314 16:15:41.856470 16588 solver.cpp:404]     Test net output #1: loss = 0.389716 (* 1 = 0.389716 loss)
I0314 16:15:41.916975 16588 solver.cpp:228] Iteration 104000, loss = 0.00551398
I0314 16:15:41.916975 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:15:41.916975 16588 solver.cpp:244]     Train net output #1: loss = 0.00551388 (* 1 = 0.00551388 loss)
I0314 16:15:41.916975 16588 sgd_solver.cpp:106] Iteration 104000, lr = 0.001
I0314 16:15:56.224911 16588 solver.cpp:228] Iteration 104100, loss = 0.00701657
I0314 16:15:56.224911 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:15:56.224911 16588 solver.cpp:244]     Train net output #1: loss = 0.00701647 (* 1 = 0.00701647 loss)
I0314 16:15:56.224911 16588 sgd_solver.cpp:106] Iteration 104100, lr = 0.001
I0314 16:16:10.570946 16588 solver.cpp:228] Iteration 104200, loss = 0.00509384
I0314 16:16:10.570946 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:16:10.570946 16588 solver.cpp:244]     Train net output #1: loss = 0.00509374 (* 1 = 0.00509374 loss)
I0314 16:16:10.570946 16588 sgd_solver.cpp:106] Iteration 104200, lr = 0.001
I0314 16:16:25.081571 16588 solver.cpp:228] Iteration 104300, loss = 0.00495884
I0314 16:16:25.081571 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:16:25.082057 16588 solver.cpp:244]     Train net output #1: loss = 0.00495874 (* 1 = 0.00495874 loss)
I0314 16:16:25.082057 16588 sgd_solver.cpp:106] Iteration 104300, lr = 0.001
I0314 16:16:39.477958 16588 solver.cpp:228] Iteration 104400, loss = 0.00349247
I0314 16:16:39.477958 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:16:39.477958 16588 solver.cpp:244]     Train net output #1: loss = 0.00349236 (* 1 = 0.00349236 loss)
I0314 16:16:39.477958 16588 sgd_solver.cpp:106] Iteration 104400, lr = 0.001
I0314 16:16:53.875244 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_104500.caffemodel
I0314 16:16:53.910244 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_104500.solverstate
I0314 16:16:53.916244 16588 solver.cpp:337] Iteration 104500, Testing net (#0)
I0314 16:16:53.916244 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:16:58.730099 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8947
I0314 16:16:58.730099 16588 solver.cpp:404]     Test net output #1: loss = 0.388719 (* 1 = 0.388719 loss)
I0314 16:16:58.800099 16588 solver.cpp:228] Iteration 104500, loss = 0.0049784
I0314 16:16:58.800099 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:16:58.800099 16588 solver.cpp:244]     Train net output #1: loss = 0.00497829 (* 1 = 0.00497829 loss)
I0314 16:16:58.800099 16588 sgd_solver.cpp:106] Iteration 104500, lr = 0.001
I0314 16:17:13.104763 16588 solver.cpp:228] Iteration 104600, loss = 0.00441001
I0314 16:17:13.104763 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:17:13.104763 16588 solver.cpp:244]     Train net output #1: loss = 0.00440991 (* 1 = 0.00440991 loss)
I0314 16:17:13.104763 16588 sgd_solver.cpp:106] Iteration 104600, lr = 0.001
I0314 16:17:27.465090 16588 solver.cpp:228] Iteration 104700, loss = 0.00459437
I0314 16:17:27.465090 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:17:27.465090 16588 solver.cpp:244]     Train net output #1: loss = 0.00459427 (* 1 = 0.00459427 loss)
I0314 16:17:27.465090 16588 sgd_solver.cpp:106] Iteration 104700, lr = 0.001
I0314 16:17:41.875687 16588 solver.cpp:228] Iteration 104800, loss = 0.00251507
I0314 16:17:41.875687 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:17:41.875687 16588 solver.cpp:244]     Train net output #1: loss = 0.00251497 (* 1 = 0.00251497 loss)
I0314 16:17:41.875687 16588 sgd_solver.cpp:106] Iteration 104800, lr = 0.001
I0314 16:17:56.317595 16588 solver.cpp:228] Iteration 104900, loss = 0.00315274
I0314 16:17:56.317595 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:17:56.317595 16588 solver.cpp:244]     Train net output #1: loss = 0.00315264 (* 1 = 0.00315264 loss)
I0314 16:17:56.317595 16588 sgd_solver.cpp:106] Iteration 104900, lr = 0.001
I0314 16:18:10.738431 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_105000.caffemodel
I0314 16:18:10.775931 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_105000.solverstate
I0314 16:18:10.782431 16588 solver.cpp:337] Iteration 105000, Testing net (#0)
I0314 16:18:10.782431 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:18:15.754562 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8951
I0314 16:18:15.754562 16588 solver.cpp:404]     Test net output #1: loss = 0.387948 (* 1 = 0.387948 loss)
I0314 16:18:15.806062 16588 solver.cpp:228] Iteration 105000, loss = 0.00331487
I0314 16:18:15.806062 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:18:15.806062 16588 solver.cpp:244]     Train net output #1: loss = 0.00331477 (* 1 = 0.00331477 loss)
I0314 16:18:15.806062 16588 sgd_solver.cpp:106] Iteration 105000, lr = 0.001
I0314 16:18:29.972592 16588 solver.cpp:228] Iteration 105100, loss = 0.00499803
I0314 16:18:29.972592 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:18:29.972592 16588 solver.cpp:244]     Train net output #1: loss = 0.00499793 (* 1 = 0.00499793 loss)
I0314 16:18:29.972592 16588 sgd_solver.cpp:106] Iteration 105100, lr = 0.001
I0314 16:18:44.458139 16588 solver.cpp:228] Iteration 105200, loss = 0.0038315
I0314 16:18:44.458139 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:18:44.458139 16588 solver.cpp:244]     Train net output #1: loss = 0.0038314 (* 1 = 0.0038314 loss)
I0314 16:18:44.458139 16588 sgd_solver.cpp:106] Iteration 105200, lr = 0.001
I0314 16:18:58.914466 16588 solver.cpp:228] Iteration 105300, loss = 0.00499944
I0314 16:18:58.914466 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:18:58.914466 16588 solver.cpp:244]     Train net output #1: loss = 0.00499934 (* 1 = 0.00499934 loss)
I0314 16:18:58.914466 16588 sgd_solver.cpp:106] Iteration 105300, lr = 0.001
I0314 16:19:13.362140 16588 solver.cpp:228] Iteration 105400, loss = 0.00199272
I0314 16:19:13.362140 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:19:13.362140 16588 solver.cpp:244]     Train net output #1: loss = 0.00199262 (* 1 = 0.00199262 loss)
I0314 16:19:13.362140 16588 sgd_solver.cpp:106] Iteration 105400, lr = 0.001
I0314 16:19:27.773983 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_105500.caffemodel
I0314 16:19:27.811503 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_105500.solverstate
I0314 16:19:27.817003 16588 solver.cpp:337] Iteration 105500, Testing net (#0)
I0314 16:19:27.817003 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:19:32.650599 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8948
I0314 16:19:32.650599 16588 solver.cpp:404]     Test net output #1: loss = 0.387918 (* 1 = 0.387918 loss)
I0314 16:19:32.701122 16588 solver.cpp:228] Iteration 105500, loss = 0.00393676
I0314 16:19:32.701122 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:19:32.701122 16588 solver.cpp:244]     Train net output #1: loss = 0.00393665 (* 1 = 0.00393665 loss)
I0314 16:19:32.701122 16588 sgd_solver.cpp:106] Iteration 105500, lr = 0.001
I0314 16:19:46.905382 16588 solver.cpp:228] Iteration 105600, loss = 0.00688669
I0314 16:19:46.905382 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:19:46.905382 16588 solver.cpp:244]     Train net output #1: loss = 0.00688659 (* 1 = 0.00688659 loss)
I0314 16:19:46.905382 16588 sgd_solver.cpp:106] Iteration 105600, lr = 0.001
I0314 16:20:01.324970 16588 solver.cpp:228] Iteration 105700, loss = 0.00466223
I0314 16:20:01.324970 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:20:01.324970 16588 solver.cpp:244]     Train net output #1: loss = 0.00466213 (* 1 = 0.00466213 loss)
I0314 16:20:01.324970 16588 sgd_solver.cpp:106] Iteration 105700, lr = 0.001
I0314 16:20:15.754477 16588 solver.cpp:228] Iteration 105800, loss = 0.00361115
I0314 16:20:15.754477 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:20:15.754477 16588 solver.cpp:244]     Train net output #1: loss = 0.00361104 (* 1 = 0.00361104 loss)
I0314 16:20:15.754477 16588 sgd_solver.cpp:106] Iteration 105800, lr = 0.001
I0314 16:20:30.218770 16588 solver.cpp:228] Iteration 105900, loss = 0.0039478
I0314 16:20:30.218770 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:20:30.218770 16588 solver.cpp:244]     Train net output #1: loss = 0.0039477 (* 1 = 0.0039477 loss)
I0314 16:20:30.218770 16588 sgd_solver.cpp:106] Iteration 105900, lr = 0.001
I0314 16:20:44.550967 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_106000.caffemodel
I0314 16:20:44.585469 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_106000.solverstate
I0314 16:20:44.591467 16588 solver.cpp:337] Iteration 106000, Testing net (#0)
I0314 16:20:44.591967 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:20:49.342810 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8938
I0314 16:20:49.342810 16588 solver.cpp:404]     Test net output #1: loss = 0.386903 (* 1 = 0.386903 loss)
I0314 16:20:49.403816 16588 solver.cpp:228] Iteration 106000, loss = 0.00362467
I0314 16:20:49.403816 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:20:49.403816 16588 solver.cpp:244]     Train net output #1: loss = 0.00362456 (* 1 = 0.00362456 loss)
I0314 16:20:49.403816 16588 sgd_solver.cpp:106] Iteration 106000, lr = 0.001
I0314 16:21:03.663731 16588 solver.cpp:228] Iteration 106100, loss = 0.00688752
I0314 16:21:03.663731 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:21:03.663731 16588 solver.cpp:244]     Train net output #1: loss = 0.00688742 (* 1 = 0.00688742 loss)
I0314 16:21:03.663731 16588 sgd_solver.cpp:106] Iteration 106100, lr = 0.001
I0314 16:21:18.060664 16588 solver.cpp:228] Iteration 106200, loss = 0.00535288
I0314 16:21:18.060664 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:21:18.060664 16588 solver.cpp:244]     Train net output #1: loss = 0.00535278 (* 1 = 0.00535278 loss)
I0314 16:21:18.060664 16588 sgd_solver.cpp:106] Iteration 106200, lr = 0.001
I0314 16:21:32.523774 16588 solver.cpp:228] Iteration 106300, loss = 0.00374212
I0314 16:21:32.524273 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:21:32.524273 16588 solver.cpp:244]     Train net output #1: loss = 0.00374201 (* 1 = 0.00374201 loss)
I0314 16:21:32.524273 16588 sgd_solver.cpp:106] Iteration 106300, lr = 0.001
I0314 16:21:46.989311 16588 solver.cpp:228] Iteration 106400, loss = 0.00379272
I0314 16:21:46.989810 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:21:46.989810 16588 solver.cpp:244]     Train net output #1: loss = 0.00379261 (* 1 = 0.00379261 loss)
I0314 16:21:46.989810 16588 sgd_solver.cpp:106] Iteration 106400, lr = 0.001
I0314 16:22:01.377144 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_106500.caffemodel
I0314 16:22:01.415144 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_106500.solverstate
I0314 16:22:01.421645 16588 solver.cpp:337] Iteration 106500, Testing net (#0)
I0314 16:22:01.421645 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:22:06.248512 16588 solver.cpp:404]     Test net output #0: accuracy = 0.895
I0314 16:22:06.248512 16588 solver.cpp:404]     Test net output #1: loss = 0.386803 (* 1 = 0.386803 loss)
I0314 16:22:06.308514 16588 solver.cpp:228] Iteration 106500, loss = 0.00413942
I0314 16:22:06.308514 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:22:06.308514 16588 solver.cpp:244]     Train net output #1: loss = 0.00413932 (* 1 = 0.00413932 loss)
I0314 16:22:06.308514 16588 sgd_solver.cpp:106] Iteration 106500, lr = 0.001
I0314 16:22:20.439515 16588 solver.cpp:228] Iteration 106600, loss = 0.0057399
I0314 16:22:20.439515 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:22:20.439515 16588 solver.cpp:244]     Train net output #1: loss = 0.00573979 (* 1 = 0.00573979 loss)
I0314 16:22:20.439515 16588 sgd_solver.cpp:106] Iteration 106600, lr = 0.001
I0314 16:22:34.742547 16588 solver.cpp:228] Iteration 106700, loss = 0.00565244
I0314 16:22:34.742547 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:22:34.742547 16588 solver.cpp:244]     Train net output #1: loss = 0.00565233 (* 1 = 0.00565233 loss)
I0314 16:22:34.742547 16588 sgd_solver.cpp:106] Iteration 106700, lr = 0.001
I0314 16:22:49.128283 16588 solver.cpp:228] Iteration 106800, loss = 0.00417776
I0314 16:22:49.128283 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:22:49.128283 16588 solver.cpp:244]     Train net output #1: loss = 0.00417766 (* 1 = 0.00417766 loss)
I0314 16:22:49.128283 16588 sgd_solver.cpp:106] Iteration 106800, lr = 0.001
I0314 16:23:03.602972 16588 solver.cpp:228] Iteration 106900, loss = 0.00409724
I0314 16:23:03.602972 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:23:03.602972 16588 solver.cpp:244]     Train net output #1: loss = 0.00409713 (* 1 = 0.00409713 loss)
I0314 16:23:03.602972 16588 sgd_solver.cpp:106] Iteration 106900, lr = 0.001
I0314 16:23:18.008383 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_107000.caffemodel
I0314 16:23:18.045383 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_107000.solverstate
I0314 16:23:18.051883 16588 solver.cpp:337] Iteration 107000, Testing net (#0)
I0314 16:23:18.051883 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:23:22.900235 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8946
I0314 16:23:22.900235 16588 solver.cpp:404]     Test net output #1: loss = 0.386596 (* 1 = 0.386596 loss)
I0314 16:23:22.967237 16588 solver.cpp:228] Iteration 107000, loss = 0.0030369
I0314 16:23:22.967237 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:23:22.967237 16588 solver.cpp:244]     Train net output #1: loss = 0.00303679 (* 1 = 0.00303679 loss)
I0314 16:23:22.967237 16588 sgd_solver.cpp:106] Iteration 107000, lr = 0.001
I0314 16:23:37.155024 16588 solver.cpp:228] Iteration 107100, loss = 0.00562546
I0314 16:23:37.155524 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:23:37.155524 16588 solver.cpp:244]     Train net output #1: loss = 0.00562535 (* 1 = 0.00562535 loss)
I0314 16:23:37.155524 16588 sgd_solver.cpp:106] Iteration 107100, lr = 0.001
I0314 16:23:51.595844 16588 solver.cpp:228] Iteration 107200, loss = 0.00590505
I0314 16:23:51.595844 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:23:51.595844 16588 solver.cpp:244]     Train net output #1: loss = 0.00590495 (* 1 = 0.00590495 loss)
I0314 16:23:51.595844 16588 sgd_solver.cpp:106] Iteration 107200, lr = 0.001
I0314 16:24:06.070710 16588 solver.cpp:228] Iteration 107300, loss = 0.00398465
I0314 16:24:06.071210 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:24:06.071210 16588 solver.cpp:244]     Train net output #1: loss = 0.00398454 (* 1 = 0.00398454 loss)
I0314 16:24:06.071210 16588 sgd_solver.cpp:106] Iteration 107300, lr = 0.001
I0314 16:24:20.522240 16588 solver.cpp:228] Iteration 107400, loss = 0.00409566
I0314 16:24:20.522240 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:24:20.522240 16588 solver.cpp:244]     Train net output #1: loss = 0.00409555 (* 1 = 0.00409555 loss)
I0314 16:24:20.522240 16588 sgd_solver.cpp:106] Iteration 107400, lr = 0.001
I0314 16:24:34.926295 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_107500.caffemodel
I0314 16:24:34.956296 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_107500.solverstate
I0314 16:24:34.966297 16588 solver.cpp:337] Iteration 107500, Testing net (#0)
I0314 16:24:34.966297 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:24:39.827369 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8946
I0314 16:24:39.827369 16588 solver.cpp:404]     Test net output #1: loss = 0.385678 (* 1 = 0.385678 loss)
I0314 16:24:39.876945 16588 solver.cpp:228] Iteration 107500, loss = 0.00416815
I0314 16:24:39.876945 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:24:39.876945 16588 solver.cpp:244]     Train net output #1: loss = 0.00416804 (* 1 = 0.00416804 loss)
I0314 16:24:39.876945 16588 sgd_solver.cpp:106] Iteration 107500, lr = 0.001
I0314 16:24:54.079408 16588 solver.cpp:228] Iteration 107600, loss = 0.00487524
I0314 16:24:54.079408 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:24:54.079408 16588 solver.cpp:244]     Train net output #1: loss = 0.00487513 (* 1 = 0.00487513 loss)
I0314 16:24:54.079408 16588 sgd_solver.cpp:106] Iteration 107600, lr = 0.001
I0314 16:25:08.554579 16588 solver.cpp:228] Iteration 107700, loss = 0.00298568
I0314 16:25:08.554579 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:25:08.554579 16588 solver.cpp:244]     Train net output #1: loss = 0.00298558 (* 1 = 0.00298558 loss)
I0314 16:25:08.554579 16588 sgd_solver.cpp:106] Iteration 107700, lr = 0.001
I0314 16:25:22.964604 16588 solver.cpp:228] Iteration 107800, loss = 0.00501847
I0314 16:25:22.964604 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:25:22.964604 16588 solver.cpp:244]     Train net output #1: loss = 0.00501836 (* 1 = 0.00501836 loss)
I0314 16:25:22.964604 16588 sgd_solver.cpp:106] Iteration 107800, lr = 0.001
I0314 16:25:37.418743 16588 solver.cpp:228] Iteration 107900, loss = 0.00366623
I0314 16:25:37.418743 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:25:37.418743 16588 solver.cpp:244]     Train net output #1: loss = 0.00366612 (* 1 = 0.00366612 loss)
I0314 16:25:37.418743 16588 sgd_solver.cpp:106] Iteration 107900, lr = 0.001
I0314 16:25:51.805475 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_108000.caffemodel
I0314 16:25:51.845523 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_108000.solverstate
I0314 16:25:51.851024 16588 solver.cpp:337] Iteration 108000, Testing net (#0)
I0314 16:25:51.851526 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:25:56.745991 16588 solver.cpp:404]     Test net output #0: accuracy = 0.894
I0314 16:25:56.745991 16588 solver.cpp:404]     Test net output #1: loss = 0.386116 (* 1 = 0.386116 loss)
I0314 16:25:56.802512 16588 solver.cpp:228] Iteration 108000, loss = 0.00323652
I0314 16:25:56.802512 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:25:56.802512 16588 solver.cpp:244]     Train net output #1: loss = 0.00323642 (* 1 = 0.00323642 loss)
I0314 16:25:56.802512 16588 sgd_solver.cpp:106] Iteration 108000, lr = 0.001
I0314 16:26:11.206352 16588 solver.cpp:228] Iteration 108100, loss = 0.00445703
I0314 16:26:11.206352 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:26:11.206352 16588 solver.cpp:244]     Train net output #1: loss = 0.00445693 (* 1 = 0.00445693 loss)
I0314 16:26:11.206352 16588 sgd_solver.cpp:106] Iteration 108100, lr = 0.001
I0314 16:26:25.649021 16588 solver.cpp:228] Iteration 108200, loss = 0.00476209
I0314 16:26:25.649021 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:26:25.649021 16588 solver.cpp:244]     Train net output #1: loss = 0.00476199 (* 1 = 0.00476199 loss)
I0314 16:26:25.649021 16588 sgd_solver.cpp:106] Iteration 108200, lr = 0.001
I0314 16:26:40.061880 16588 solver.cpp:228] Iteration 108300, loss = 0.0033348
I0314 16:26:40.061880 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:26:40.061880 16588 solver.cpp:244]     Train net output #1: loss = 0.0033347 (* 1 = 0.0033347 loss)
I0314 16:26:40.061880 16588 sgd_solver.cpp:106] Iteration 108300, lr = 0.001
I0314 16:26:54.505221 16588 solver.cpp:228] Iteration 108400, loss = 0.00271625
I0314 16:26:54.505221 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:26:54.505722 16588 solver.cpp:244]     Train net output #1: loss = 0.00271615 (* 1 = 0.00271615 loss)
I0314 16:26:54.505722 16588 sgd_solver.cpp:106] Iteration 108400, lr = 0.001
I0314 16:27:08.948722 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_108500.caffemodel
I0314 16:27:08.984220 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_108500.solverstate
I0314 16:27:08.990721 16588 solver.cpp:337] Iteration 108500, Testing net (#0)
I0314 16:27:08.990721 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:27:13.794057 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8944
I0314 16:27:13.794057 16588 solver.cpp:404]     Test net output #1: loss = 0.385312 (* 1 = 0.385312 loss)
I0314 16:27:13.849057 16588 solver.cpp:228] Iteration 108500, loss = 0.00336454
I0314 16:27:13.849057 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:27:13.849057 16588 solver.cpp:244]     Train net output #1: loss = 0.00336443 (* 1 = 0.00336443 loss)
I0314 16:27:13.849057 16588 sgd_solver.cpp:106] Iteration 108500, lr = 0.001
I0314 16:27:28.084857 16588 solver.cpp:228] Iteration 108600, loss = 0.00473728
I0314 16:27:28.084857 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:27:28.084857 16588 solver.cpp:244]     Train net output #1: loss = 0.00473718 (* 1 = 0.00473718 loss)
I0314 16:27:28.084857 16588 sgd_solver.cpp:106] Iteration 108600, lr = 0.001
I0314 16:27:42.467290 16588 solver.cpp:228] Iteration 108700, loss = 0.00504705
I0314 16:27:42.467290 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:27:42.467290 16588 solver.cpp:244]     Train net output #1: loss = 0.00504694 (* 1 = 0.00504694 loss)
I0314 16:27:42.467290 16588 sgd_solver.cpp:106] Iteration 108700, lr = 0.001
I0314 16:27:56.922647 16588 solver.cpp:228] Iteration 108800, loss = 0.00430814
I0314 16:27:56.922647 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:27:56.922647 16588 solver.cpp:244]     Train net output #1: loss = 0.00430804 (* 1 = 0.00430804 loss)
I0314 16:27:56.922647 16588 sgd_solver.cpp:106] Iteration 108800, lr = 0.001
I0314 16:28:11.386096 16588 solver.cpp:228] Iteration 108900, loss = 0.00334047
I0314 16:28:11.386096 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:28:11.386096 16588 solver.cpp:244]     Train net output #1: loss = 0.00334037 (* 1 = 0.00334037 loss)
I0314 16:28:11.386096 16588 sgd_solver.cpp:106] Iteration 108900, lr = 0.001
I0314 16:28:25.831645 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_109000.caffemodel
I0314 16:28:25.871207 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_109000.solverstate
I0314 16:28:25.871207 16588 solver.cpp:337] Iteration 109000, Testing net (#0)
I0314 16:28:25.871207 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:28:30.754406 16588 solver.cpp:404]     Test net output #0: accuracy = 0.895
I0314 16:28:30.754406 16588 solver.cpp:404]     Test net output #1: loss = 0.384589 (* 1 = 0.384589 loss)
I0314 16:28:30.804409 16588 solver.cpp:228] Iteration 109000, loss = 0.00411992
I0314 16:28:30.804409 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:28:30.804409 16588 solver.cpp:244]     Train net output #1: loss = 0.00411981 (* 1 = 0.00411981 loss)
I0314 16:28:30.804409 16588 sgd_solver.cpp:106] Iteration 109000, lr = 0.001
I0314 16:28:45.067659 16588 solver.cpp:228] Iteration 109100, loss = 0.00611708
I0314 16:28:45.067659 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:28:45.067659 16588 solver.cpp:244]     Train net output #1: loss = 0.00611698 (* 1 = 0.00611698 loss)
I0314 16:28:45.067659 16588 sgd_solver.cpp:106] Iteration 109100, lr = 0.001
I0314 16:28:59.519054 16588 solver.cpp:228] Iteration 109200, loss = 0.00426726
I0314 16:28:59.519054 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:28:59.519054 16588 solver.cpp:244]     Train net output #1: loss = 0.00426715 (* 1 = 0.00426715 loss)
I0314 16:28:59.519054 16588 sgd_solver.cpp:106] Iteration 109200, lr = 0.001
I0314 16:29:13.962985 16588 solver.cpp:228] Iteration 109300, loss = 0.00331472
I0314 16:29:13.963485 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:29:13.963485 16588 solver.cpp:244]     Train net output #1: loss = 0.00331462 (* 1 = 0.00331462 loss)
I0314 16:29:13.963485 16588 sgd_solver.cpp:106] Iteration 109300, lr = 0.001
I0314 16:29:28.454388 16588 solver.cpp:228] Iteration 109400, loss = 0.00394059
I0314 16:29:28.454388 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:29:28.454388 16588 solver.cpp:244]     Train net output #1: loss = 0.00394049 (* 1 = 0.00394049 loss)
I0314 16:29:28.454388 16588 sgd_solver.cpp:106] Iteration 109400, lr = 0.001
I0314 16:29:42.901990 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_109500.caffemodel
I0314 16:29:42.939489 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_109500.solverstate
I0314 16:29:42.945989 16588 solver.cpp:337] Iteration 109500, Testing net (#0)
I0314 16:29:42.945989 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:29:47.790527 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8948
I0314 16:29:47.790527 16588 solver.cpp:404]     Test net output #1: loss = 0.384296 (* 1 = 0.384296 loss)
I0314 16:29:47.850539 16588 solver.cpp:228] Iteration 109500, loss = 0.00320038
I0314 16:29:47.850539 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:29:47.850539 16588 solver.cpp:244]     Train net output #1: loss = 0.00320027 (* 1 = 0.00320027 loss)
I0314 16:29:47.850539 16588 sgd_solver.cpp:106] Iteration 109500, lr = 0.001
I0314 16:30:02.034164 16588 solver.cpp:228] Iteration 109600, loss = 0.00421588
I0314 16:30:02.034164 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:30:02.034164 16588 solver.cpp:244]     Train net output #1: loss = 0.00421578 (* 1 = 0.00421578 loss)
I0314 16:30:02.034164 16588 sgd_solver.cpp:106] Iteration 109600, lr = 0.001
I0314 16:30:16.488528 16588 solver.cpp:228] Iteration 109700, loss = 0.00383097
I0314 16:30:16.489027 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:30:16.489027 16588 solver.cpp:244]     Train net output #1: loss = 0.00383086 (* 1 = 0.00383086 loss)
I0314 16:30:16.489027 16588 sgd_solver.cpp:106] Iteration 109700, lr = 0.001
I0314 16:30:30.967166 16588 solver.cpp:228] Iteration 109800, loss = 0.00391274
I0314 16:30:30.967666 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:30:30.967666 16588 solver.cpp:244]     Train net output #1: loss = 0.00391264 (* 1 = 0.00391264 loss)
I0314 16:30:30.967666 16588 sgd_solver.cpp:106] Iteration 109800, lr = 0.001
I0314 16:30:45.376616 16588 solver.cpp:228] Iteration 109900, loss = 0.00385842
I0314 16:30:45.376616 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:30:45.376616 16588 solver.cpp:244]     Train net output #1: loss = 0.00385831 (* 1 = 0.00385831 loss)
I0314 16:30:45.376616 16588 sgd_solver.cpp:106] Iteration 109900, lr = 0.001
I0314 16:30:59.739492 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_110000.caffemodel
I0314 16:30:59.775492 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_110000.solverstate
I0314 16:30:59.782492 16588 solver.cpp:337] Iteration 110000, Testing net (#0)
I0314 16:30:59.782492 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:31:04.640336 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8952
I0314 16:31:04.640336 16588 solver.cpp:404]     Test net output #1: loss = 0.383775 (* 1 = 0.383775 loss)
I0314 16:31:04.692852 16588 solver.cpp:228] Iteration 110000, loss = 0.00369275
I0314 16:31:04.692852 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:31:04.692852 16588 solver.cpp:244]     Train net output #1: loss = 0.00369264 (* 1 = 0.00369264 loss)
I0314 16:31:04.692852 16588 sgd_solver.cpp:106] Iteration 110000, lr = 0.001
I0314 16:31:18.846240 16588 solver.cpp:228] Iteration 110100, loss = 0.0047871
I0314 16:31:18.846240 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:31:18.846240 16588 solver.cpp:244]     Train net output #1: loss = 0.00478699 (* 1 = 0.00478699 loss)
I0314 16:31:18.846240 16588 sgd_solver.cpp:106] Iteration 110100, lr = 0.001
I0314 16:31:33.316673 16588 solver.cpp:228] Iteration 110200, loss = 0.00473541
I0314 16:31:33.316673 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:31:33.316673 16588 solver.cpp:244]     Train net output #1: loss = 0.00473531 (* 1 = 0.00473531 loss)
I0314 16:31:33.316673 16588 sgd_solver.cpp:106] Iteration 110200, lr = 0.001
I0314 16:31:47.820003 16588 solver.cpp:228] Iteration 110300, loss = 0.00504839
I0314 16:31:47.820003 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:31:47.820003 16588 solver.cpp:244]     Train net output #1: loss = 0.00504829 (* 1 = 0.00504829 loss)
I0314 16:31:47.820003 16588 sgd_solver.cpp:106] Iteration 110300, lr = 0.001
I0314 16:32:02.316666 16588 solver.cpp:228] Iteration 110400, loss = 0.0025067
I0314 16:32:02.316666 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:32:02.316666 16588 solver.cpp:244]     Train net output #1: loss = 0.0025066 (* 1 = 0.0025066 loss)
I0314 16:32:02.316666 16588 sgd_solver.cpp:106] Iteration 110400, lr = 0.001
I0314 16:32:16.738868 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_110500.caffemodel
I0314 16:32:16.780866 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_110500.solverstate
I0314 16:32:16.789868 16588 solver.cpp:337] Iteration 110500, Testing net (#0)
I0314 16:32:16.789868 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:32:21.925246 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8953
I0314 16:32:21.925246 16588 solver.cpp:404]     Test net output #1: loss = 0.383827 (* 1 = 0.383827 loss)
I0314 16:32:21.970909 16588 solver.cpp:228] Iteration 110500, loss = 0.00445322
I0314 16:32:21.970909 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:32:21.970909 16588 solver.cpp:244]     Train net output #1: loss = 0.00445312 (* 1 = 0.00445312 loss)
I0314 16:32:21.970909 16588 sgd_solver.cpp:106] Iteration 110500, lr = 0.001
I0314 16:32:36.566741 16588 solver.cpp:228] Iteration 110600, loss = 0.00528522
I0314 16:32:36.566741 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:32:36.566741 16588 solver.cpp:244]     Train net output #1: loss = 0.00528512 (* 1 = 0.00528512 loss)
I0314 16:32:36.566741 16588 sgd_solver.cpp:106] Iteration 110600, lr = 0.001
I0314 16:32:51.095571 16588 solver.cpp:228] Iteration 110700, loss = 0.00497175
I0314 16:32:51.095571 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:32:51.095571 16588 solver.cpp:244]     Train net output #1: loss = 0.00497164 (* 1 = 0.00497164 loss)
I0314 16:32:51.095571 16588 sgd_solver.cpp:106] Iteration 110700, lr = 0.001
I0314 16:33:05.716236 16588 solver.cpp:228] Iteration 110800, loss = 0.00259607
I0314 16:33:05.716236 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:33:05.716236 16588 solver.cpp:244]     Train net output #1: loss = 0.00259597 (* 1 = 0.00259597 loss)
I0314 16:33:05.716236 16588 sgd_solver.cpp:106] Iteration 110800, lr = 0.001
I0314 16:33:20.418299 16588 solver.cpp:228] Iteration 110900, loss = 0.00368827
I0314 16:33:20.418299 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:33:20.418800 16588 solver.cpp:244]     Train net output #1: loss = 0.00368816 (* 1 = 0.00368816 loss)
I0314 16:33:20.418800 16588 sgd_solver.cpp:106] Iteration 110900, lr = 0.001
I0314 16:33:35.024562 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_111000.caffemodel
I0314 16:33:35.065062 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_111000.solverstate
I0314 16:33:35.071563 16588 solver.cpp:337] Iteration 111000, Testing net (#0)
I0314 16:33:35.071563 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:33:39.913087 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8944
I0314 16:33:39.913591 16588 solver.cpp:404]     Test net output #1: loss = 0.383458 (* 1 = 0.383458 loss)
I0314 16:33:39.972589 16588 solver.cpp:228] Iteration 111000, loss = 0.00345402
I0314 16:33:39.972589 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:33:39.972589 16588 solver.cpp:244]     Train net output #1: loss = 0.00345391 (* 1 = 0.00345391 loss)
I0314 16:33:39.972589 16588 sgd_solver.cpp:106] Iteration 111000, lr = 0.001
I0314 16:33:55.631886 16588 solver.cpp:228] Iteration 111100, loss = 0.00427902
I0314 16:33:55.631886 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:33:55.631886 16588 solver.cpp:244]     Train net output #1: loss = 0.00427891 (* 1 = 0.00427891 loss)
I0314 16:33:55.631886 16588 sgd_solver.cpp:106] Iteration 111100, lr = 0.001
I0314 16:34:11.161178 16588 solver.cpp:228] Iteration 111200, loss = 0.00396055
I0314 16:34:11.161178 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:34:11.161178 16588 solver.cpp:244]     Train net output #1: loss = 0.00396044 (* 1 = 0.00396044 loss)
I0314 16:34:11.161178 16588 sgd_solver.cpp:106] Iteration 111200, lr = 0.001
I0314 16:34:26.122680 16588 solver.cpp:228] Iteration 111300, loss = 0.004113
I0314 16:34:26.122680 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:34:26.122680 16588 solver.cpp:244]     Train net output #1: loss = 0.0041129 (* 1 = 0.0041129 loss)
I0314 16:34:26.122680 16588 sgd_solver.cpp:106] Iteration 111300, lr = 0.001
I0314 16:34:41.043272 16588 solver.cpp:228] Iteration 111400, loss = 0.00321971
I0314 16:34:41.043272 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:34:41.043272 16588 solver.cpp:244]     Train net output #1: loss = 0.0032196 (* 1 = 0.0032196 loss)
I0314 16:34:41.043272 16588 sgd_solver.cpp:106] Iteration 111400, lr = 0.001
I0314 16:34:55.628746 16588 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_slim_baseline_iter_111500.caffemodel
I0314 16:34:55.666245 16588 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_slim_baseline_iter_111500.solverstate
I0314 16:34:55.672749 16588 solver.cpp:337] Iteration 111500, Testing net (#0)
I0314 16:34:55.672749 16588 net.cpp:693] Ignoring source layer accuracy_training
I0314 16:35:00.583614 16588 solver.cpp:404]     Test net output #0: accuracy = 0.8952
I0314 16:35:00.583614 16588 solver.cpp:404]     Test net output #1: loss = 0.382943 (* 1 = 0.382943 loss)
I0314 16:35:00.636626 16588 solver.cpp:228] Iteration 111500, loss = 0.00447401
I0314 16:35:00.636626 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:35:00.636626 16588 solver.cpp:244]     Train net output #1: loss = 0.0044739 (* 1 = 0.0044739 loss)
I0314 16:35:00.636626 16588 sgd_solver.cpp:106] Iteration 111500, lr = 0.001
I0314 16:35:14.867204 16588 solver.cpp:228] Iteration 111600, loss = 0.00391977
I0314 16:35:14.867204 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:35:14.867204 16588 solver.cpp:244]     Train net output #1: loss = 0.00391966 (* 1 = 0.00391966 loss)
I0314 16:35:14.867204 16588 sgd_solver.cpp:106] Iteration 111600, lr = 0.001
I0314 16:35:29.396214 16588 solver.cpp:228] Iteration 111700, loss = 0.00517181
I0314 16:35:29.396214 16588 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0314 16:35:29.396214 16588 solver.cpp:244]     Train net output #1: loss = 0.0051^C