
G:\Caffe\examples\cifar100>REM go to the caffe root 

G:\Caffe\examples\cifar100>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar100/fcifar100_full_relu_solver_bn.prototxt --snapshot=examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_90000.solverstate 
I1120 18:22:45.120879  1516 caffe.cpp:219] Using GPUs 0
I1120 18:22:45.296589  1516 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1120 18:22:45.590008  1516 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1120 18:22:45.605006  1516 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1120 18:22:45.606006  1516 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1120 18:22:45.619026  1516 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1120 18:22:45.619026  1516 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1120 18:22:45.619026  1516 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1120 18:22:45.620025  1516 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_13L_Simple_NoGrpCon_Drp_1M"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 60
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "conv1"
  top: "conv1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "conv1_0"
  top: "conv1_0"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "conv2"
  top: "conv2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "conv2_1"
  top: "conv2_1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 85
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "pool2_1"
  top: "pool2_1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 85
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv3"
  top: "conv3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "drop6_1"
  type: "Dropout"
  bottom: "conv3_1"
  top: "conv3_1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "conv4"
  top: "conv4"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "drop8"
  type: "Dropout"
  bottom: "conv4_1"
  top: "conv4_1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 110
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "pool4_2"
  top: "pool4_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 117
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "drop10"
  type: "Dropout"
  bottom: "conv4_0"
  top: "conv4_0"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 150
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "drop11"
  type: "Dropout"
  bottom: "conv11"
  top: "conv11"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "poolcp6"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "poolcp6"
  bottom: "label"
  top: "loss"
}
I1120 18:22:45.620025  1516 layer_factory.cpp:58] Creating layer cifar
I1120 18:22:45.642025  1516 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1120 18:22:45.651028  1516 net.cpp:84] Creating Layer cifar
I1120 18:22:45.651028  1516 net.cpp:380] cifar -> data
I1120 18:22:45.651028  1516 net.cpp:380] cifar -> label
I1120 18:22:45.652006  1516 data_layer.cpp:45] output data size: 100,3,32,32
I1120 18:22:45.657006  1516 net.cpp:122] Setting up cifar
I1120 18:22:45.657006  1516 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1120 18:22:45.657006  1516 net.cpp:129] Top shape: 100 (100)
I1120 18:22:45.657006  1516 net.cpp:137] Memory required for data: 1229200
I1120 18:22:45.657006  1516 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1120 18:22:45.657006  1516 net.cpp:84] Creating Layer label_cifar_1_split
I1120 18:22:45.657006  1516 net.cpp:406] label_cifar_1_split <- label
I1120 18:22:45.657006  1516 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1120 18:22:45.657006  1516 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1120 18:22:45.657006  1516 net.cpp:122] Setting up label_cifar_1_split
I1120 18:22:45.657006  1516 net.cpp:129] Top shape: 100 (100)
I1120 18:22:45.657006  1516 net.cpp:129] Top shape: 100 (100)
I1120 18:22:45.657006  1516 net.cpp:137] Memory required for data: 1230000
I1120 18:22:45.657006  1516 layer_factory.cpp:58] Creating layer conv1
I1120 18:22:45.657006  1516 net.cpp:84] Creating Layer conv1
I1120 18:22:45.657006  1516 net.cpp:406] conv1 <- data
I1120 18:22:45.657006  1516 net.cpp:380] conv1 -> conv1
I1120 18:22:45.658011 16604 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1120 18:22:45.894103  1516 net.cpp:122] Setting up conv1
I1120 18:22:45.894103  1516 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1120 18:22:45.894103  1516 net.cpp:137] Memory required for data: 25806000
I1120 18:22:45.894103  1516 layer_factory.cpp:58] Creating layer bn1
I1120 18:22:45.894103  1516 net.cpp:84] Creating Layer bn1
I1120 18:22:45.894103  1516 net.cpp:406] bn1 <- conv1
I1120 18:22:45.894103  1516 net.cpp:367] bn1 -> conv1 (in-place)
I1120 18:22:45.894103  1516 net.cpp:122] Setting up bn1
I1120 18:22:45.894103  1516 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1120 18:22:45.894103  1516 net.cpp:137] Memory required for data: 50382000
I1120 18:22:45.894103  1516 layer_factory.cpp:58] Creating layer scale1
I1120 18:22:45.894103  1516 net.cpp:84] Creating Layer scale1
I1120 18:22:45.894103  1516 net.cpp:406] scale1 <- conv1
I1120 18:22:45.894103  1516 net.cpp:367] scale1 -> conv1 (in-place)
I1120 18:22:45.894103  1516 layer_factory.cpp:58] Creating layer scale1
I1120 18:22:45.894103  1516 net.cpp:122] Setting up scale1
I1120 18:22:45.894103  1516 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1120 18:22:45.894103  1516 net.cpp:137] Memory required for data: 74958000
I1120 18:22:45.894103  1516 layer_factory.cpp:58] Creating layer relu1
I1120 18:22:45.894103  1516 net.cpp:84] Creating Layer relu1
I1120 18:22:45.894103  1516 net.cpp:406] relu1 <- conv1
I1120 18:22:45.894103  1516 net.cpp:367] relu1 -> conv1 (in-place)
I1120 18:22:45.895104  1516 net.cpp:122] Setting up relu1
I1120 18:22:45.895104  1516 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1120 18:22:45.895104  1516 net.cpp:137] Memory required for data: 99534000
I1120 18:22:45.895104  1516 layer_factory.cpp:58] Creating layer drop1
I1120 18:22:45.895104  1516 net.cpp:84] Creating Layer drop1
I1120 18:22:45.895104  1516 net.cpp:406] drop1 <- conv1
I1120 18:22:45.895104  1516 net.cpp:367] drop1 -> conv1 (in-place)
I1120 18:22:45.895104  1516 net.cpp:122] Setting up drop1
I1120 18:22:45.895104  1516 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1120 18:22:45.895104  1516 net.cpp:137] Memory required for data: 124110000
I1120 18:22:45.895104  1516 layer_factory.cpp:58] Creating layer conv1_0
I1120 18:22:45.895104  1516 net.cpp:84] Creating Layer conv1_0
I1120 18:22:45.895104  1516 net.cpp:406] conv1_0 <- conv1
I1120 18:22:45.895104  1516 net.cpp:380] conv1_0 -> conv1_0
I1120 18:22:45.897121  1516 net.cpp:122] Setting up conv1_0
I1120 18:22:45.897121  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.897121  1516 net.cpp:137] Memory required for data: 156878000
I1120 18:22:45.897121  1516 layer_factory.cpp:58] Creating layer bn1_0
I1120 18:22:45.897121  1516 net.cpp:84] Creating Layer bn1_0
I1120 18:22:45.897121  1516 net.cpp:406] bn1_0 <- conv1_0
I1120 18:22:45.897121  1516 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1120 18:22:45.897121  1516 net.cpp:122] Setting up bn1_0
I1120 18:22:45.897121  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.897121  1516 net.cpp:137] Memory required for data: 189646000
I1120 18:22:45.897121  1516 layer_factory.cpp:58] Creating layer scale1_0
I1120 18:22:45.897121  1516 net.cpp:84] Creating Layer scale1_0
I1120 18:22:45.897121  1516 net.cpp:406] scale1_0 <- conv1_0
I1120 18:22:45.897121  1516 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1120 18:22:45.897121  1516 layer_factory.cpp:58] Creating layer scale1_0
I1120 18:22:45.897121  1516 net.cpp:122] Setting up scale1_0
I1120 18:22:45.897121  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.897121  1516 net.cpp:137] Memory required for data: 222414000
I1120 18:22:45.897121  1516 layer_factory.cpp:58] Creating layer relu1_0
I1120 18:22:45.897121  1516 net.cpp:84] Creating Layer relu1_0
I1120 18:22:45.897121  1516 net.cpp:406] relu1_0 <- conv1_0
I1120 18:22:45.897121  1516 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1120 18:22:45.898114  1516 net.cpp:122] Setting up relu1_0
I1120 18:22:45.898114  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.898114  1516 net.cpp:137] Memory required for data: 255182000
I1120 18:22:45.898114  1516 layer_factory.cpp:58] Creating layer drop2
I1120 18:22:45.898114  1516 net.cpp:84] Creating Layer drop2
I1120 18:22:45.898114  1516 net.cpp:406] drop2 <- conv1_0
I1120 18:22:45.898114  1516 net.cpp:367] drop2 -> conv1_0 (in-place)
I1120 18:22:45.898114  1516 net.cpp:122] Setting up drop2
I1120 18:22:45.898114  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.898114  1516 net.cpp:137] Memory required for data: 287950000
I1120 18:22:45.898114  1516 layer_factory.cpp:58] Creating layer conv2
I1120 18:22:45.898114  1516 net.cpp:84] Creating Layer conv2
I1120 18:22:45.898114  1516 net.cpp:406] conv2 <- conv1_0
I1120 18:22:45.898114  1516 net.cpp:380] conv2 -> conv2
I1120 18:22:45.899103  1516 net.cpp:122] Setting up conv2
I1120 18:22:45.899103  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.899103  1516 net.cpp:137] Memory required for data: 320718000
I1120 18:22:45.899103  1516 layer_factory.cpp:58] Creating layer bn2
I1120 18:22:45.899103  1516 net.cpp:84] Creating Layer bn2
I1120 18:22:45.899103  1516 net.cpp:406] bn2 <- conv2
I1120 18:22:45.899103  1516 net.cpp:367] bn2 -> conv2 (in-place)
I1120 18:22:45.899103  1516 net.cpp:122] Setting up bn2
I1120 18:22:45.899103  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.899103  1516 net.cpp:137] Memory required for data: 353486000
I1120 18:22:45.899103  1516 layer_factory.cpp:58] Creating layer scale2
I1120 18:22:45.899103  1516 net.cpp:84] Creating Layer scale2
I1120 18:22:45.899103  1516 net.cpp:406] scale2 <- conv2
I1120 18:22:45.899103  1516 net.cpp:367] scale2 -> conv2 (in-place)
I1120 18:22:45.900120  1516 layer_factory.cpp:58] Creating layer scale2
I1120 18:22:45.900120  1516 net.cpp:122] Setting up scale2
I1120 18:22:45.900120  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.900120  1516 net.cpp:137] Memory required for data: 386254000
I1120 18:22:45.900120  1516 layer_factory.cpp:58] Creating layer relu2
I1120 18:22:45.900120  1516 net.cpp:84] Creating Layer relu2
I1120 18:22:45.900120  1516 net.cpp:406] relu2 <- conv2
I1120 18:22:45.900120  1516 net.cpp:367] relu2 -> conv2 (in-place)
I1120 18:22:45.900120  1516 net.cpp:122] Setting up relu2
I1120 18:22:45.900120  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.900120  1516 net.cpp:137] Memory required for data: 419022000
I1120 18:22:45.900120  1516 layer_factory.cpp:58] Creating layer drop3
I1120 18:22:45.900120  1516 net.cpp:84] Creating Layer drop3
I1120 18:22:45.900120  1516 net.cpp:406] drop3 <- conv2
I1120 18:22:45.900120  1516 net.cpp:367] drop3 -> conv2 (in-place)
I1120 18:22:45.900120  1516 net.cpp:122] Setting up drop3
I1120 18:22:45.900120  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.900120  1516 net.cpp:137] Memory required for data: 451790000
I1120 18:22:45.900120  1516 layer_factory.cpp:58] Creating layer conv2_1
I1120 18:22:45.900120  1516 net.cpp:84] Creating Layer conv2_1
I1120 18:22:45.900120  1516 net.cpp:406] conv2_1 <- conv2
I1120 18:22:45.900120  1516 net.cpp:380] conv2_1 -> conv2_1
I1120 18:22:45.902101  1516 net.cpp:122] Setting up conv2_1
I1120 18:22:45.902101  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.902101  1516 net.cpp:137] Memory required for data: 484558000
I1120 18:22:45.902101  1516 layer_factory.cpp:58] Creating layer bn2_1
I1120 18:22:45.902101  1516 net.cpp:84] Creating Layer bn2_1
I1120 18:22:45.902101  1516 net.cpp:406] bn2_1 <- conv2_1
I1120 18:22:45.902101  1516 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1120 18:22:45.902101  1516 net.cpp:122] Setting up bn2_1
I1120 18:22:45.902101  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.902101  1516 net.cpp:137] Memory required for data: 517326000
I1120 18:22:45.902101  1516 layer_factory.cpp:58] Creating layer scale2_1
I1120 18:22:45.902101  1516 net.cpp:84] Creating Layer scale2_1
I1120 18:22:45.902101  1516 net.cpp:406] scale2_1 <- conv2_1
I1120 18:22:45.902101  1516 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1120 18:22:45.902101  1516 layer_factory.cpp:58] Creating layer scale2_1
I1120 18:22:45.902101  1516 net.cpp:122] Setting up scale2_1
I1120 18:22:45.902101  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.902101  1516 net.cpp:137] Memory required for data: 550094000
I1120 18:22:45.902101  1516 layer_factory.cpp:58] Creating layer relu2_1
I1120 18:22:45.902101  1516 net.cpp:84] Creating Layer relu2_1
I1120 18:22:45.902101  1516 net.cpp:406] relu2_1 <- conv2_1
I1120 18:22:45.902101  1516 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1120 18:22:45.902101  1516 net.cpp:122] Setting up relu2_1
I1120 18:22:45.902101  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.902101  1516 net.cpp:137] Memory required for data: 582862000
I1120 18:22:45.902101  1516 layer_factory.cpp:58] Creating layer drop4
I1120 18:22:45.902101  1516 net.cpp:84] Creating Layer drop4
I1120 18:22:45.902101  1516 net.cpp:406] drop4 <- conv2_1
I1120 18:22:45.902101  1516 net.cpp:367] drop4 -> conv2_1 (in-place)
I1120 18:22:45.902101  1516 net.cpp:122] Setting up drop4
I1120 18:22:45.902101  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.902101  1516 net.cpp:137] Memory required for data: 615630000
I1120 18:22:45.902101  1516 layer_factory.cpp:58] Creating layer conv2_2
I1120 18:22:45.902101  1516 net.cpp:84] Creating Layer conv2_2
I1120 18:22:45.902101  1516 net.cpp:406] conv2_2 <- conv2_1
I1120 18:22:45.902101  1516 net.cpp:380] conv2_2 -> conv2_2
I1120 18:22:45.904103  1516 net.cpp:122] Setting up conv2_2
I1120 18:22:45.904103  1516 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1120 18:22:45.904103  1516 net.cpp:137] Memory required for data: 650446000
I1120 18:22:45.904103  1516 layer_factory.cpp:58] Creating layer bn2_2
I1120 18:22:45.904103  1516 net.cpp:84] Creating Layer bn2_2
I1120 18:22:45.904103  1516 net.cpp:406] bn2_2 <- conv2_2
I1120 18:22:45.904103  1516 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1120 18:22:45.904103  1516 net.cpp:122] Setting up bn2_2
I1120 18:22:45.904103  1516 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1120 18:22:45.904103  1516 net.cpp:137] Memory required for data: 685262000
I1120 18:22:45.904103  1516 layer_factory.cpp:58] Creating layer scale2_2
I1120 18:22:45.904103  1516 net.cpp:84] Creating Layer scale2_2
I1120 18:22:45.904103  1516 net.cpp:406] scale2_2 <- conv2_2
I1120 18:22:45.904103  1516 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1120 18:22:45.904103  1516 layer_factory.cpp:58] Creating layer scale2_2
I1120 18:22:45.904103  1516 net.cpp:122] Setting up scale2_2
I1120 18:22:45.904103  1516 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1120 18:22:45.904103  1516 net.cpp:137] Memory required for data: 720078000
I1120 18:22:45.904103  1516 layer_factory.cpp:58] Creating layer relu2_2
I1120 18:22:45.904103  1516 net.cpp:84] Creating Layer relu2_2
I1120 18:22:45.904103  1516 net.cpp:406] relu2_2 <- conv2_2
I1120 18:22:45.904103  1516 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1120 18:22:45.905102  1516 net.cpp:122] Setting up relu2_2
I1120 18:22:45.905102  1516 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1120 18:22:45.905102  1516 net.cpp:137] Memory required for data: 754894000
I1120 18:22:45.905102  1516 layer_factory.cpp:58] Creating layer pool2_1
I1120 18:22:45.905102  1516 net.cpp:84] Creating Layer pool2_1
I1120 18:22:45.905102  1516 net.cpp:406] pool2_1 <- conv2_2
I1120 18:22:45.905102  1516 net.cpp:380] pool2_1 -> pool2_1
I1120 18:22:45.905102  1516 net.cpp:122] Setting up pool2_1
I1120 18:22:45.905102  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.905102  1516 net.cpp:137] Memory required for data: 763598000
I1120 18:22:45.905102  1516 layer_factory.cpp:58] Creating layer drop5
I1120 18:22:45.905102  1516 net.cpp:84] Creating Layer drop5
I1120 18:22:45.905102  1516 net.cpp:406] drop5 <- pool2_1
I1120 18:22:45.905102  1516 net.cpp:367] drop5 -> pool2_1 (in-place)
I1120 18:22:45.905102  1516 net.cpp:122] Setting up drop5
I1120 18:22:45.905102  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.905102  1516 net.cpp:137] Memory required for data: 772302000
I1120 18:22:45.905102  1516 layer_factory.cpp:58] Creating layer conv3
I1120 18:22:45.905102  1516 net.cpp:84] Creating Layer conv3
I1120 18:22:45.905102  1516 net.cpp:406] conv3 <- pool2_1
I1120 18:22:45.905102  1516 net.cpp:380] conv3 -> conv3
I1120 18:22:45.906102  1516 net.cpp:122] Setting up conv3
I1120 18:22:45.906102  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.906102  1516 net.cpp:137] Memory required for data: 781006000
I1120 18:22:45.906102  1516 layer_factory.cpp:58] Creating layer bn3
I1120 18:22:45.906102  1516 net.cpp:84] Creating Layer bn3
I1120 18:22:45.906102  1516 net.cpp:406] bn3 <- conv3
I1120 18:22:45.906102  1516 net.cpp:367] bn3 -> conv3 (in-place)
I1120 18:22:45.907102  1516 net.cpp:122] Setting up bn3
I1120 18:22:45.907102  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.907102  1516 net.cpp:137] Memory required for data: 789710000
I1120 18:22:45.907102  1516 layer_factory.cpp:58] Creating layer scale3
I1120 18:22:45.907102  1516 net.cpp:84] Creating Layer scale3
I1120 18:22:45.907102  1516 net.cpp:406] scale3 <- conv3
I1120 18:22:45.907102  1516 net.cpp:367] scale3 -> conv3 (in-place)
I1120 18:22:45.907102  1516 layer_factory.cpp:58] Creating layer scale3
I1120 18:22:45.907102  1516 net.cpp:122] Setting up scale3
I1120 18:22:45.907102  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.907102  1516 net.cpp:137] Memory required for data: 798414000
I1120 18:22:45.907102  1516 layer_factory.cpp:58] Creating layer relu3
I1120 18:22:45.907102  1516 net.cpp:84] Creating Layer relu3
I1120 18:22:45.907102  1516 net.cpp:406] relu3 <- conv3
I1120 18:22:45.907102  1516 net.cpp:367] relu3 -> conv3 (in-place)
I1120 18:22:45.907102  1516 net.cpp:122] Setting up relu3
I1120 18:22:45.907102  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.907102  1516 net.cpp:137] Memory required for data: 807118000
I1120 18:22:45.907102  1516 layer_factory.cpp:58] Creating layer drop6
I1120 18:22:45.907102  1516 net.cpp:84] Creating Layer drop6
I1120 18:22:45.907102  1516 net.cpp:406] drop6 <- conv3
I1120 18:22:45.907102  1516 net.cpp:367] drop6 -> conv3 (in-place)
I1120 18:22:45.907102  1516 net.cpp:122] Setting up drop6
I1120 18:22:45.907102  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.907102  1516 net.cpp:137] Memory required for data: 815822000
I1120 18:22:45.907102  1516 layer_factory.cpp:58] Creating layer conv3_1
I1120 18:22:45.907102  1516 net.cpp:84] Creating Layer conv3_1
I1120 18:22:45.907102  1516 net.cpp:406] conv3_1 <- conv3
I1120 18:22:45.907102  1516 net.cpp:380] conv3_1 -> conv3_1
I1120 18:22:45.909102  1516 net.cpp:122] Setting up conv3_1
I1120 18:22:45.909102  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.909102  1516 net.cpp:137] Memory required for data: 825038000
I1120 18:22:45.909102  1516 layer_factory.cpp:58] Creating layer bn3_1
I1120 18:22:45.909102  1516 net.cpp:84] Creating Layer bn3_1
I1120 18:22:45.909102  1516 net.cpp:406] bn3_1 <- conv3_1
I1120 18:22:45.909102  1516 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1120 18:22:45.909102  1516 net.cpp:122] Setting up bn3_1
I1120 18:22:45.909102  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.909102  1516 net.cpp:137] Memory required for data: 834254000
I1120 18:22:45.909102  1516 layer_factory.cpp:58] Creating layer scale3_1
I1120 18:22:45.909102  1516 net.cpp:84] Creating Layer scale3_1
I1120 18:22:45.909102  1516 net.cpp:406] scale3_1 <- conv3_1
I1120 18:22:45.909102  1516 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1120 18:22:45.909102  1516 layer_factory.cpp:58] Creating layer scale3_1
I1120 18:22:45.909102  1516 net.cpp:122] Setting up scale3_1
I1120 18:22:45.909102  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.909102  1516 net.cpp:137] Memory required for data: 843470000
I1120 18:22:45.909102  1516 layer_factory.cpp:58] Creating layer relu3_1
I1120 18:22:45.909102  1516 net.cpp:84] Creating Layer relu3_1
I1120 18:22:45.909102  1516 net.cpp:406] relu3_1 <- conv3_1
I1120 18:22:45.909102  1516 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1120 18:22:45.910100  1516 net.cpp:122] Setting up relu3_1
I1120 18:22:45.910100  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.910100  1516 net.cpp:137] Memory required for data: 852686000
I1120 18:22:45.910100  1516 layer_factory.cpp:58] Creating layer drop6_1
I1120 18:22:45.910100  1516 net.cpp:84] Creating Layer drop6_1
I1120 18:22:45.910100  1516 net.cpp:406] drop6_1 <- conv3_1
I1120 18:22:45.910100  1516 net.cpp:367] drop6_1 -> conv3_1 (in-place)
I1120 18:22:45.910100  1516 net.cpp:122] Setting up drop6_1
I1120 18:22:45.910100  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.910100  1516 net.cpp:137] Memory required for data: 861902000
I1120 18:22:45.910100  1516 layer_factory.cpp:58] Creating layer conv4
I1120 18:22:45.910100  1516 net.cpp:84] Creating Layer conv4
I1120 18:22:45.910100  1516 net.cpp:406] conv4 <- conv3_1
I1120 18:22:45.910100  1516 net.cpp:380] conv4 -> conv4
I1120 18:22:45.911103  1516 net.cpp:122] Setting up conv4
I1120 18:22:45.911103  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.911103  1516 net.cpp:137] Memory required for data: 871118000
I1120 18:22:45.911103  1516 layer_factory.cpp:58] Creating layer bn4
I1120 18:22:45.911103  1516 net.cpp:84] Creating Layer bn4
I1120 18:22:45.911103  1516 net.cpp:406] bn4 <- conv4
I1120 18:22:45.911103  1516 net.cpp:367] bn4 -> conv4 (in-place)
I1120 18:22:45.912104  1516 net.cpp:122] Setting up bn4
I1120 18:22:45.912104  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.912104  1516 net.cpp:137] Memory required for data: 880334000
I1120 18:22:45.912104  1516 layer_factory.cpp:58] Creating layer scale4
I1120 18:22:45.912104  1516 net.cpp:84] Creating Layer scale4
I1120 18:22:45.912104  1516 net.cpp:406] scale4 <- conv4
I1120 18:22:45.912104  1516 net.cpp:367] scale4 -> conv4 (in-place)
I1120 18:22:45.912104  1516 layer_factory.cpp:58] Creating layer scale4
I1120 18:22:45.912104  1516 net.cpp:122] Setting up scale4
I1120 18:22:45.912104  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.912104  1516 net.cpp:137] Memory required for data: 889550000
I1120 18:22:45.912104  1516 layer_factory.cpp:58] Creating layer relu4
I1120 18:22:45.912104  1516 net.cpp:84] Creating Layer relu4
I1120 18:22:45.912104  1516 net.cpp:406] relu4 <- conv4
I1120 18:22:45.912104  1516 net.cpp:367] relu4 -> conv4 (in-place)
I1120 18:22:45.912104  1516 net.cpp:122] Setting up relu4
I1120 18:22:45.912104  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.912104  1516 net.cpp:137] Memory required for data: 898766000
I1120 18:22:45.912104  1516 layer_factory.cpp:58] Creating layer drop7
I1120 18:22:45.912104  1516 net.cpp:84] Creating Layer drop7
I1120 18:22:45.912104  1516 net.cpp:406] drop7 <- conv4
I1120 18:22:45.912104  1516 net.cpp:367] drop7 -> conv4 (in-place)
I1120 18:22:45.912104  1516 net.cpp:122] Setting up drop7
I1120 18:22:45.912104  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.912104  1516 net.cpp:137] Memory required for data: 907982000
I1120 18:22:45.912104  1516 layer_factory.cpp:58] Creating layer conv4_1
I1120 18:22:45.912104  1516 net.cpp:84] Creating Layer conv4_1
I1120 18:22:45.912104  1516 net.cpp:406] conv4_1 <- conv4
I1120 18:22:45.912104  1516 net.cpp:380] conv4_1 -> conv4_1
I1120 18:22:45.914103  1516 net.cpp:122] Setting up conv4_1
I1120 18:22:45.914103  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.914103  1516 net.cpp:137] Memory required for data: 917198000
I1120 18:22:45.914103  1516 layer_factory.cpp:58] Creating layer bn4_1
I1120 18:22:45.914103  1516 net.cpp:84] Creating Layer bn4_1
I1120 18:22:45.914103  1516 net.cpp:406] bn4_1 <- conv4_1
I1120 18:22:45.914103  1516 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1120 18:22:45.914103  1516 net.cpp:122] Setting up bn4_1
I1120 18:22:45.914103  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.914103  1516 net.cpp:137] Memory required for data: 926414000
I1120 18:22:45.914103  1516 layer_factory.cpp:58] Creating layer scale4_1
I1120 18:22:45.914103  1516 net.cpp:84] Creating Layer scale4_1
I1120 18:22:45.914103  1516 net.cpp:406] scale4_1 <- conv4_1
I1120 18:22:45.914103  1516 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1120 18:22:45.914103  1516 layer_factory.cpp:58] Creating layer scale4_1
I1120 18:22:45.914103  1516 net.cpp:122] Setting up scale4_1
I1120 18:22:45.914103  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.914103  1516 net.cpp:137] Memory required for data: 935630000
I1120 18:22:45.914103  1516 layer_factory.cpp:58] Creating layer relu4_1
I1120 18:22:45.914103  1516 net.cpp:84] Creating Layer relu4_1
I1120 18:22:45.914103  1516 net.cpp:406] relu4_1 <- conv4_1
I1120 18:22:45.914103  1516 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1120 18:22:45.914103  1516 net.cpp:122] Setting up relu4_1
I1120 18:22:45.914103  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.914103  1516 net.cpp:137] Memory required for data: 944846000
I1120 18:22:45.914103  1516 layer_factory.cpp:58] Creating layer drop8
I1120 18:22:45.914103  1516 net.cpp:84] Creating Layer drop8
I1120 18:22:45.914103  1516 net.cpp:406] drop8 <- conv4_1
I1120 18:22:45.914103  1516 net.cpp:367] drop8 -> conv4_1 (in-place)
I1120 18:22:45.914103  1516 net.cpp:122] Setting up drop8
I1120 18:22:45.914103  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.914103  1516 net.cpp:137] Memory required for data: 954062000
I1120 18:22:45.915120  1516 layer_factory.cpp:58] Creating layer conv4_2
I1120 18:22:45.915120  1516 net.cpp:84] Creating Layer conv4_2
I1120 18:22:45.915120  1516 net.cpp:406] conv4_2 <- conv4_1
I1120 18:22:45.915120  1516 net.cpp:380] conv4_2 -> conv4_2
I1120 18:22:45.916105  1516 net.cpp:122] Setting up conv4_2
I1120 18:22:45.916105  1516 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1120 18:22:45.916105  1516 net.cpp:137] Memory required for data: 965326000
I1120 18:22:45.916105  1516 layer_factory.cpp:58] Creating layer bn4_2
I1120 18:22:45.916105  1516 net.cpp:84] Creating Layer bn4_2
I1120 18:22:45.916105  1516 net.cpp:406] bn4_2 <- conv4_2
I1120 18:22:45.916105  1516 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1120 18:22:45.916105  1516 net.cpp:122] Setting up bn4_2
I1120 18:22:45.917120  1516 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1120 18:22:45.917120  1516 net.cpp:137] Memory required for data: 976590000
I1120 18:22:45.917120  1516 layer_factory.cpp:58] Creating layer scale4_2
I1120 18:22:45.917120  1516 net.cpp:84] Creating Layer scale4_2
I1120 18:22:45.917120  1516 net.cpp:406] scale4_2 <- conv4_2
I1120 18:22:45.917120  1516 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1120 18:22:45.917120  1516 layer_factory.cpp:58] Creating layer scale4_2
I1120 18:22:45.917120  1516 net.cpp:122] Setting up scale4_2
I1120 18:22:45.917120  1516 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1120 18:22:45.917120  1516 net.cpp:137] Memory required for data: 987854000
I1120 18:22:45.917120  1516 layer_factory.cpp:58] Creating layer relu4_2
I1120 18:22:45.917120  1516 net.cpp:84] Creating Layer relu4_2
I1120 18:22:45.917120  1516 net.cpp:406] relu4_2 <- conv4_2
I1120 18:22:45.917120  1516 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1120 18:22:45.917120  1516 net.cpp:122] Setting up relu4_2
I1120 18:22:45.917120  1516 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1120 18:22:45.917120  1516 net.cpp:137] Memory required for data: 999118000
I1120 18:22:45.917120  1516 layer_factory.cpp:58] Creating layer pool4_2
I1120 18:22:45.917120  1516 net.cpp:84] Creating Layer pool4_2
I1120 18:22:45.917120  1516 net.cpp:406] pool4_2 <- conv4_2
I1120 18:22:45.917120  1516 net.cpp:380] pool4_2 -> pool4_2
I1120 18:22:45.917120  1516 net.cpp:122] Setting up pool4_2
I1120 18:22:45.917120  1516 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1120 18:22:45.917120  1516 net.cpp:137] Memory required for data: 1001934000
I1120 18:22:45.917120  1516 layer_factory.cpp:58] Creating layer drop9
I1120 18:22:45.917120  1516 net.cpp:84] Creating Layer drop9
I1120 18:22:45.917120  1516 net.cpp:406] drop9 <- pool4_2
I1120 18:22:45.917120  1516 net.cpp:367] drop9 -> pool4_2 (in-place)
I1120 18:22:45.917120  1516 net.cpp:122] Setting up drop9
I1120 18:22:45.917120  1516 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1120 18:22:45.917120  1516 net.cpp:137] Memory required for data: 1004750000
I1120 18:22:45.917120  1516 layer_factory.cpp:58] Creating layer conv4_0
I1120 18:22:45.917120  1516 net.cpp:84] Creating Layer conv4_0
I1120 18:22:45.917120  1516 net.cpp:406] conv4_0 <- pool4_2
I1120 18:22:45.917120  1516 net.cpp:380] conv4_0 -> conv4_0
I1120 18:22:45.919121  1516 net.cpp:122] Setting up conv4_0
I1120 18:22:45.919121  1516 net.cpp:129] Top shape: 100 117 8 8 (748800)
I1120 18:22:45.919121  1516 net.cpp:137] Memory required for data: 1007745200
I1120 18:22:45.919121  1516 layer_factory.cpp:58] Creating layer bn4_0
I1120 18:22:45.919121  1516 net.cpp:84] Creating Layer bn4_0
I1120 18:22:45.919121  1516 net.cpp:406] bn4_0 <- conv4_0
I1120 18:22:45.919121  1516 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1120 18:22:45.919121  1516 net.cpp:122] Setting up bn4_0
I1120 18:22:45.919121  1516 net.cpp:129] Top shape: 100 117 8 8 (748800)
I1120 18:22:45.919121  1516 net.cpp:137] Memory required for data: 1010740400
I1120 18:22:45.919121  1516 layer_factory.cpp:58] Creating layer scale4_0
I1120 18:22:45.919121  1516 net.cpp:84] Creating Layer scale4_0
I1120 18:22:45.919121  1516 net.cpp:406] scale4_0 <- conv4_0
I1120 18:22:45.919121  1516 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1120 18:22:45.919121  1516 layer_factory.cpp:58] Creating layer scale4_0
I1120 18:22:45.919121  1516 net.cpp:122] Setting up scale4_0
I1120 18:22:45.920120  1516 net.cpp:129] Top shape: 100 117 8 8 (748800)
I1120 18:22:45.920120  1516 net.cpp:137] Memory required for data: 1013735600
I1120 18:22:45.920120  1516 layer_factory.cpp:58] Creating layer relu4_0
I1120 18:22:45.920120  1516 net.cpp:84] Creating Layer relu4_0
I1120 18:22:45.920120  1516 net.cpp:406] relu4_0 <- conv4_0
I1120 18:22:45.920120  1516 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1120 18:22:45.920120  1516 net.cpp:122] Setting up relu4_0
I1120 18:22:45.920120  1516 net.cpp:129] Top shape: 100 117 8 8 (748800)
I1120 18:22:45.920120  1516 net.cpp:137] Memory required for data: 1016730800
I1120 18:22:45.920120  1516 layer_factory.cpp:58] Creating layer drop10
I1120 18:22:45.920120  1516 net.cpp:84] Creating Layer drop10
I1120 18:22:45.920120  1516 net.cpp:406] drop10 <- conv4_0
I1120 18:22:45.920120  1516 net.cpp:367] drop10 -> conv4_0 (in-place)
I1120 18:22:45.920120  1516 net.cpp:122] Setting up drop10
I1120 18:22:45.920120  1516 net.cpp:129] Top shape: 100 117 8 8 (748800)
I1120 18:22:45.920120  1516 net.cpp:137] Memory required for data: 1019726000
I1120 18:22:45.920120  1516 layer_factory.cpp:58] Creating layer conv11
I1120 18:22:45.920120  1516 net.cpp:84] Creating Layer conv11
I1120 18:22:45.920120  1516 net.cpp:406] conv11 <- conv4_0
I1120 18:22:45.920120  1516 net.cpp:380] conv11 -> conv11
I1120 18:22:45.922106  1516 net.cpp:122] Setting up conv11
I1120 18:22:45.922106  1516 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1120 18:22:45.922106  1516 net.cpp:137] Memory required for data: 1023566000
I1120 18:22:45.922106  1516 layer_factory.cpp:58] Creating layer bn_conv11
I1120 18:22:45.922106  1516 net.cpp:84] Creating Layer bn_conv11
I1120 18:22:45.922106  1516 net.cpp:406] bn_conv11 <- conv11
I1120 18:22:45.922106  1516 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1120 18:22:45.922106  1516 net.cpp:122] Setting up bn_conv11
I1120 18:22:45.922106  1516 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1120 18:22:45.922106  1516 net.cpp:137] Memory required for data: 1027406000
I1120 18:22:45.922106  1516 layer_factory.cpp:58] Creating layer scale_conv11
I1120 18:22:45.922106  1516 net.cpp:84] Creating Layer scale_conv11
I1120 18:22:45.922106  1516 net.cpp:406] scale_conv11 <- conv11
I1120 18:22:45.922106  1516 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1120 18:22:45.922106  1516 layer_factory.cpp:58] Creating layer scale_conv11
I1120 18:22:45.922106  1516 net.cpp:122] Setting up scale_conv11
I1120 18:22:45.922106  1516 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1120 18:22:45.922106  1516 net.cpp:137] Memory required for data: 1031246000
I1120 18:22:45.922106  1516 layer_factory.cpp:58] Creating layer relu_conv11
I1120 18:22:45.923116  1516 net.cpp:84] Creating Layer relu_conv11
I1120 18:22:45.923116  1516 net.cpp:406] relu_conv11 <- conv11
I1120 18:22:45.923116  1516 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1120 18:22:45.923116  1516 net.cpp:122] Setting up relu_conv11
I1120 18:22:45.923116  1516 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1120 18:22:45.923116  1516 net.cpp:137] Memory required for data: 1035086000
I1120 18:22:45.923116  1516 layer_factory.cpp:58] Creating layer drop11
I1120 18:22:45.923116  1516 net.cpp:84] Creating Layer drop11
I1120 18:22:45.923116  1516 net.cpp:406] drop11 <- conv11
I1120 18:22:45.923116  1516 net.cpp:367] drop11 -> conv11 (in-place)
I1120 18:22:45.923116  1516 net.cpp:122] Setting up drop11
I1120 18:22:45.923116  1516 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1120 18:22:45.923116  1516 net.cpp:137] Memory required for data: 1038926000
I1120 18:22:45.923116  1516 layer_factory.cpp:58] Creating layer conv12
I1120 18:22:45.923116  1516 net.cpp:84] Creating Layer conv12
I1120 18:22:45.923116  1516 net.cpp:406] conv12 <- conv11
I1120 18:22:45.923116  1516 net.cpp:380] conv12 -> conv12
I1120 18:22:45.925122  1516 net.cpp:122] Setting up conv12
I1120 18:22:45.925122  1516 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1120 18:22:45.925122  1516 net.cpp:137] Memory required for data: 1041486000
I1120 18:22:45.925122  1516 layer_factory.cpp:58] Creating layer bn_conv12
I1120 18:22:45.925122  1516 net.cpp:84] Creating Layer bn_conv12
I1120 18:22:45.925122  1516 net.cpp:406] bn_conv12 <- conv12
I1120 18:22:45.925122  1516 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1120 18:22:45.925122  1516 net.cpp:122] Setting up bn_conv12
I1120 18:22:45.925122  1516 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1120 18:22:45.925122  1516 net.cpp:137] Memory required for data: 1044046000
I1120 18:22:45.926113  1516 layer_factory.cpp:58] Creating layer scale_conv12
I1120 18:22:45.926113  1516 net.cpp:84] Creating Layer scale_conv12
I1120 18:22:45.926113  1516 net.cpp:406] scale_conv12 <- conv12
I1120 18:22:45.926113  1516 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1120 18:22:45.926113  1516 layer_factory.cpp:58] Creating layer scale_conv12
I1120 18:22:45.926113  1516 net.cpp:122] Setting up scale_conv12
I1120 18:22:45.926113  1516 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1120 18:22:45.926113  1516 net.cpp:137] Memory required for data: 1046606000
I1120 18:22:45.926113  1516 layer_factory.cpp:58] Creating layer relu_conv12
I1120 18:22:45.926113  1516 net.cpp:84] Creating Layer relu_conv12
I1120 18:22:45.926113  1516 net.cpp:406] relu_conv12 <- conv12
I1120 18:22:45.926113  1516 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1120 18:22:45.926113  1516 net.cpp:122] Setting up relu_conv12
I1120 18:22:45.926113  1516 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1120 18:22:45.926113  1516 net.cpp:137] Memory required for data: 1049166000
I1120 18:22:45.926113  1516 layer_factory.cpp:58] Creating layer poolcp6
I1120 18:22:45.926113  1516 net.cpp:84] Creating Layer poolcp6
I1120 18:22:45.926113  1516 net.cpp:406] poolcp6 <- conv12
I1120 18:22:45.926113  1516 net.cpp:380] poolcp6 -> poolcp6
I1120 18:22:45.926113  1516 net.cpp:122] Setting up poolcp6
I1120 18:22:45.926113  1516 net.cpp:129] Top shape: 100 100 1 1 (10000)
I1120 18:22:45.926113  1516 net.cpp:137] Memory required for data: 1049206000
I1120 18:22:45.926113  1516 layer_factory.cpp:58] Creating layer poolcp6_poolcp6_0_split
I1120 18:22:45.926113  1516 net.cpp:84] Creating Layer poolcp6_poolcp6_0_split
I1120 18:22:45.926113  1516 net.cpp:406] poolcp6_poolcp6_0_split <- poolcp6
I1120 18:22:45.926113  1516 net.cpp:380] poolcp6_poolcp6_0_split -> poolcp6_poolcp6_0_split_0
I1120 18:22:45.926113  1516 net.cpp:380] poolcp6_poolcp6_0_split -> poolcp6_poolcp6_0_split_1
I1120 18:22:45.926113  1516 net.cpp:122] Setting up poolcp6_poolcp6_0_split
I1120 18:22:45.926113  1516 net.cpp:129] Top shape: 100 100 1 1 (10000)
I1120 18:22:45.926113  1516 net.cpp:129] Top shape: 100 100 1 1 (10000)
I1120 18:22:45.926113  1516 net.cpp:137] Memory required for data: 1049286000
I1120 18:22:45.926113  1516 layer_factory.cpp:58] Creating layer accuracy_training
I1120 18:22:45.926113  1516 net.cpp:84] Creating Layer accuracy_training
I1120 18:22:45.926113  1516 net.cpp:406] accuracy_training <- poolcp6_poolcp6_0_split_0
I1120 18:22:45.926113  1516 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1120 18:22:45.926113  1516 net.cpp:380] accuracy_training -> accuracy_training
I1120 18:22:45.926113  1516 net.cpp:122] Setting up accuracy_training
I1120 18:22:45.926113  1516 net.cpp:129] Top shape: (1)
I1120 18:22:45.926113  1516 net.cpp:137] Memory required for data: 1049286004
I1120 18:22:45.926113  1516 layer_factory.cpp:58] Creating layer loss
I1120 18:22:45.926113  1516 net.cpp:84] Creating Layer loss
I1120 18:22:45.926113  1516 net.cpp:406] loss <- poolcp6_poolcp6_0_split_1
I1120 18:22:45.926113  1516 net.cpp:406] loss <- label_cifar_1_split_1
I1120 18:22:45.926113  1516 net.cpp:380] loss -> loss
I1120 18:22:45.926113  1516 layer_factory.cpp:58] Creating layer loss
I1120 18:22:45.927116  1516 net.cpp:122] Setting up loss
I1120 18:22:45.927116  1516 net.cpp:129] Top shape: (1)
I1120 18:22:45.927116  1516 net.cpp:132]     with loss weight 1
I1120 18:22:45.927116  1516 net.cpp:137] Memory required for data: 1049286008
I1120 18:22:45.928102  1516 net.cpp:198] loss needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:200] accuracy_training does not need backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] poolcp6_poolcp6_0_split needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] poolcp6 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu_conv12 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale_conv12 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn_conv12 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv12 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop11 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu_conv11 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale_conv11 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn_conv11 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv11 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop10 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu4_0 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale4_0 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn4_0 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv4_0 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop9 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] pool4_2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu4_2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale4_2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn4_2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv4_2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop8 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu4_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale4_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn4_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv4_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop7 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu4 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale4 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn4 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv4 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop6_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu3_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale3_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn3_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv3_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop6 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu3 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale3 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn3 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv3 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop5 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] pool2_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu2_2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale2_2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn2_2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv2_2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop4 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu2_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale2_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn2_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv2_1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop3 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop2 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu1_0 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale1_0 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn1_0 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv1_0 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] drop1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] relu1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] scale1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] bn1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:198] conv1 needs backward computation.
I1120 18:22:45.928102  1516 net.cpp:200] label_cifar_1_split does not need backward computation.
I1120 18:22:45.928102  1516 net.cpp:200] cifar does not need backward computation.
I1120 18:22:45.928102  1516 net.cpp:242] This network produces output accuracy_training
I1120 18:22:45.928102  1516 net.cpp:242] This network produces output loss
I1120 18:22:45.928102  1516 net.cpp:255] Network initialization done.
I1120 18:22:45.929113  1516 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1120 18:22:45.929113  1516 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1120 18:22:45.929113  1516 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1120 18:22:45.929113  1516 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1120 18:22:45.929113  1516 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_13L_Simple_NoGrpCon_Drp_1M"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 60
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "conv1"
  top: "conv1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "conv1_0"
  top: "conv1_0"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "conv2"
  top: "conv2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "conv2_1"
  top: "conv2_1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 85
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "pool2_1"
  top: "pool2_1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 85
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv3"
  top: "conv3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "drop6_1"
  type: "Dropout"
  bottom: "conv3_1"
  top: "conv3_1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "conv4"
  top: "conv4"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "drop8"
  type: "Dropout"
  bottom: "conv4_1"
  top: "conv4_1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 110
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "pool4_2"
  top: "pool4_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 117
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "drop10"
  type: "Dropout"
  bottom: "conv4_0"
  top: "conv4_0"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 150
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "drop11"
  type: "Dropout"
  bottom: "conv11"
  top: "conv11"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "poolcp6"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "poolcp6"
  bottom: "label"
  top: "loss"
}
I1120 18:22:45.930114  1516 layer_factory.cpp:58] Creating layer cifar
I1120 18:22:45.935129  1516 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1120 18:22:45.936117  1516 net.cpp:84] Creating Layer cifar
I1120 18:22:45.936117  1516 net.cpp:380] cifar -> data
I1120 18:22:45.936117  1516 net.cpp:380] cifar -> label
I1120 18:22:45.936117  1516 data_layer.cpp:45] output data size: 100,3,32,32
I1120 18:22:45.942117  1516 net.cpp:122] Setting up cifar
I1120 18:22:45.942117  1516 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1120 18:22:45.942117  1516 net.cpp:129] Top shape: 100 (100)
I1120 18:22:45.942117  1516 net.cpp:137] Memory required for data: 1229200
I1120 18:22:45.942117  1516 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1120 18:22:45.942117  1516 net.cpp:84] Creating Layer label_cifar_1_split
I1120 18:22:45.942117  1516 net.cpp:406] label_cifar_1_split <- label
I1120 18:22:45.943117  1516 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1120 18:22:45.943117  1516 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1120 18:22:45.943117  1516 net.cpp:122] Setting up label_cifar_1_split
I1120 18:22:45.943117  1516 net.cpp:129] Top shape: 100 (100)
I1120 18:22:45.943117  1516 net.cpp:129] Top shape: 100 (100)
I1120 18:22:45.943117  1516 net.cpp:137] Memory required for data: 1230000
I1120 18:22:45.943117  1516 layer_factory.cpp:58] Creating layer conv1
I1120 18:22:45.943117  1516 net.cpp:84] Creating Layer conv1
I1120 18:22:45.943117  1516 net.cpp:406] conv1 <- data
I1120 18:22:45.943117  1516 net.cpp:380] conv1 -> conv1
I1120 18:22:45.943117 14992 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1120 18:22:45.944113  1516 net.cpp:122] Setting up conv1
I1120 18:22:45.944113  1516 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1120 18:22:45.944113  1516 net.cpp:137] Memory required for data: 25806000
I1120 18:22:45.944113  1516 layer_factory.cpp:58] Creating layer bn1
I1120 18:22:45.944113  1516 net.cpp:84] Creating Layer bn1
I1120 18:22:45.944113  1516 net.cpp:406] bn1 <- conv1
I1120 18:22:45.944113  1516 net.cpp:367] bn1 -> conv1 (in-place)
I1120 18:22:45.945103  1516 net.cpp:122] Setting up bn1
I1120 18:22:45.945103  1516 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1120 18:22:45.945103  1516 net.cpp:137] Memory required for data: 50382000
I1120 18:22:45.945103  1516 layer_factory.cpp:58] Creating layer scale1
I1120 18:22:45.945103  1516 net.cpp:84] Creating Layer scale1
I1120 18:22:45.945103  1516 net.cpp:406] scale1 <- conv1
I1120 18:22:45.945103  1516 net.cpp:367] scale1 -> conv1 (in-place)
I1120 18:22:45.945103  1516 layer_factory.cpp:58] Creating layer scale1
I1120 18:22:45.945103  1516 net.cpp:122] Setting up scale1
I1120 18:22:45.945103  1516 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1120 18:22:45.945103  1516 net.cpp:137] Memory required for data: 74958000
I1120 18:22:45.945103  1516 layer_factory.cpp:58] Creating layer relu1
I1120 18:22:45.945103  1516 net.cpp:84] Creating Layer relu1
I1120 18:22:45.945103  1516 net.cpp:406] relu1 <- conv1
I1120 18:22:45.945103  1516 net.cpp:367] relu1 -> conv1 (in-place)
I1120 18:22:45.945103  1516 net.cpp:122] Setting up relu1
I1120 18:22:45.945103  1516 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1120 18:22:45.945103  1516 net.cpp:137] Memory required for data: 99534000
I1120 18:22:45.945103  1516 layer_factory.cpp:58] Creating layer drop1
I1120 18:22:45.945103  1516 net.cpp:84] Creating Layer drop1
I1120 18:22:45.945103  1516 net.cpp:406] drop1 <- conv1
I1120 18:22:45.945103  1516 net.cpp:367] drop1 -> conv1 (in-place)
I1120 18:22:45.945103  1516 net.cpp:122] Setting up drop1
I1120 18:22:45.945103  1516 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1120 18:22:45.945103  1516 net.cpp:137] Memory required for data: 124110000
I1120 18:22:45.945103  1516 layer_factory.cpp:58] Creating layer conv1_0
I1120 18:22:45.945103  1516 net.cpp:84] Creating Layer conv1_0
I1120 18:22:45.945103  1516 net.cpp:406] conv1_0 <- conv1
I1120 18:22:45.945103  1516 net.cpp:380] conv1_0 -> conv1_0
I1120 18:22:45.947113  1516 net.cpp:122] Setting up conv1_0
I1120 18:22:45.947113  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.947113  1516 net.cpp:137] Memory required for data: 156878000
I1120 18:22:45.947113  1516 layer_factory.cpp:58] Creating layer bn1_0
I1120 18:22:45.947113  1516 net.cpp:84] Creating Layer bn1_0
I1120 18:22:45.947113  1516 net.cpp:406] bn1_0 <- conv1_0
I1120 18:22:45.947113  1516 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1120 18:22:45.947113  1516 net.cpp:122] Setting up bn1_0
I1120 18:22:45.947113  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.947113  1516 net.cpp:137] Memory required for data: 189646000
I1120 18:22:45.947113  1516 layer_factory.cpp:58] Creating layer scale1_0
I1120 18:22:45.947113  1516 net.cpp:84] Creating Layer scale1_0
I1120 18:22:45.947113  1516 net.cpp:406] scale1_0 <- conv1_0
I1120 18:22:45.947113  1516 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1120 18:22:45.948112  1516 layer_factory.cpp:58] Creating layer scale1_0
I1120 18:22:45.948112  1516 net.cpp:122] Setting up scale1_0
I1120 18:22:45.948112  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.948112  1516 net.cpp:137] Memory required for data: 222414000
I1120 18:22:45.948112  1516 layer_factory.cpp:58] Creating layer relu1_0
I1120 18:22:45.948112  1516 net.cpp:84] Creating Layer relu1_0
I1120 18:22:45.948112  1516 net.cpp:406] relu1_0 <- conv1_0
I1120 18:22:45.948112  1516 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1120 18:22:45.948112  1516 net.cpp:122] Setting up relu1_0
I1120 18:22:45.948112  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.948112  1516 net.cpp:137] Memory required for data: 255182000
I1120 18:22:45.948112  1516 layer_factory.cpp:58] Creating layer drop2
I1120 18:22:45.948112  1516 net.cpp:84] Creating Layer drop2
I1120 18:22:45.948112  1516 net.cpp:406] drop2 <- conv1_0
I1120 18:22:45.948112  1516 net.cpp:367] drop2 -> conv1_0 (in-place)
I1120 18:22:45.948112  1516 net.cpp:122] Setting up drop2
I1120 18:22:45.948112  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.948112  1516 net.cpp:137] Memory required for data: 287950000
I1120 18:22:45.948112  1516 layer_factory.cpp:58] Creating layer conv2
I1120 18:22:45.948112  1516 net.cpp:84] Creating Layer conv2
I1120 18:22:45.948112  1516 net.cpp:406] conv2 <- conv1_0
I1120 18:22:45.948112  1516 net.cpp:380] conv2 -> conv2
I1120 18:22:45.950114  1516 net.cpp:122] Setting up conv2
I1120 18:22:45.950114  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.950114  1516 net.cpp:137] Memory required for data: 320718000
I1120 18:22:45.950114  1516 layer_factory.cpp:58] Creating layer bn2
I1120 18:22:45.950114  1516 net.cpp:84] Creating Layer bn2
I1120 18:22:45.950114  1516 net.cpp:406] bn2 <- conv2
I1120 18:22:45.950114  1516 net.cpp:367] bn2 -> conv2 (in-place)
I1120 18:22:45.950114  1516 net.cpp:122] Setting up bn2
I1120 18:22:45.950114  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.950114  1516 net.cpp:137] Memory required for data: 353486000
I1120 18:22:45.950114  1516 layer_factory.cpp:58] Creating layer scale2
I1120 18:22:45.950114  1516 net.cpp:84] Creating Layer scale2
I1120 18:22:45.950114  1516 net.cpp:406] scale2 <- conv2
I1120 18:22:45.950114  1516 net.cpp:367] scale2 -> conv2 (in-place)
I1120 18:22:45.950114  1516 layer_factory.cpp:58] Creating layer scale2
I1120 18:22:45.950114  1516 net.cpp:122] Setting up scale2
I1120 18:22:45.950114  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.950114  1516 net.cpp:137] Memory required for data: 386254000
I1120 18:22:45.950114  1516 layer_factory.cpp:58] Creating layer relu2
I1120 18:22:45.951115  1516 net.cpp:84] Creating Layer relu2
I1120 18:22:45.951115  1516 net.cpp:406] relu2 <- conv2
I1120 18:22:45.951115  1516 net.cpp:367] relu2 -> conv2 (in-place)
I1120 18:22:45.951115  1516 net.cpp:122] Setting up relu2
I1120 18:22:45.951115  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.951115  1516 net.cpp:137] Memory required for data: 419022000
I1120 18:22:45.951115  1516 layer_factory.cpp:58] Creating layer drop3
I1120 18:22:45.951115  1516 net.cpp:84] Creating Layer drop3
I1120 18:22:45.951115  1516 net.cpp:406] drop3 <- conv2
I1120 18:22:45.951115  1516 net.cpp:367] drop3 -> conv2 (in-place)
I1120 18:22:45.951115  1516 net.cpp:122] Setting up drop3
I1120 18:22:45.951115  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.951115  1516 net.cpp:137] Memory required for data: 451790000
I1120 18:22:45.951115  1516 layer_factory.cpp:58] Creating layer conv2_1
I1120 18:22:45.951115  1516 net.cpp:84] Creating Layer conv2_1
I1120 18:22:45.951115  1516 net.cpp:406] conv2_1 <- conv2
I1120 18:22:45.951115  1516 net.cpp:380] conv2_1 -> conv2_1
I1120 18:22:45.953105  1516 net.cpp:122] Setting up conv2_1
I1120 18:22:45.953105  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.953105  1516 net.cpp:137] Memory required for data: 484558000
I1120 18:22:45.953105  1516 layer_factory.cpp:58] Creating layer bn2_1
I1120 18:22:45.953105  1516 net.cpp:84] Creating Layer bn2_1
I1120 18:22:45.953105  1516 net.cpp:406] bn2_1 <- conv2_1
I1120 18:22:45.953105  1516 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1120 18:22:45.953105  1516 net.cpp:122] Setting up bn2_1
I1120 18:22:45.953105  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.953105  1516 net.cpp:137] Memory required for data: 517326000
I1120 18:22:45.953105  1516 layer_factory.cpp:58] Creating layer scale2_1
I1120 18:22:45.953105  1516 net.cpp:84] Creating Layer scale2_1
I1120 18:22:45.953105  1516 net.cpp:406] scale2_1 <- conv2_1
I1120 18:22:45.953105  1516 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1120 18:22:45.953105  1516 layer_factory.cpp:58] Creating layer scale2_1
I1120 18:22:45.954113  1516 net.cpp:122] Setting up scale2_1
I1120 18:22:45.954113  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.954113  1516 net.cpp:137] Memory required for data: 550094000
I1120 18:22:45.954113  1516 layer_factory.cpp:58] Creating layer relu2_1
I1120 18:22:45.954113  1516 net.cpp:84] Creating Layer relu2_1
I1120 18:22:45.954113  1516 net.cpp:406] relu2_1 <- conv2_1
I1120 18:22:45.954113  1516 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1120 18:22:45.954113  1516 net.cpp:122] Setting up relu2_1
I1120 18:22:45.954113  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.954113  1516 net.cpp:137] Memory required for data: 582862000
I1120 18:22:45.954113  1516 layer_factory.cpp:58] Creating layer drop4
I1120 18:22:45.954113  1516 net.cpp:84] Creating Layer drop4
I1120 18:22:45.954113  1516 net.cpp:406] drop4 <- conv2_1
I1120 18:22:45.954113  1516 net.cpp:367] drop4 -> conv2_1 (in-place)
I1120 18:22:45.954113  1516 net.cpp:122] Setting up drop4
I1120 18:22:45.954113  1516 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1120 18:22:45.954113  1516 net.cpp:137] Memory required for data: 615630000
I1120 18:22:45.954113  1516 layer_factory.cpp:58] Creating layer conv2_2
I1120 18:22:45.954113  1516 net.cpp:84] Creating Layer conv2_2
I1120 18:22:45.954113  1516 net.cpp:406] conv2_2 <- conv2_1
I1120 18:22:45.954113  1516 net.cpp:380] conv2_2 -> conv2_2
I1120 18:22:45.956104  1516 net.cpp:122] Setting up conv2_2
I1120 18:22:45.956104  1516 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1120 18:22:45.956104  1516 net.cpp:137] Memory required for data: 650446000
I1120 18:22:45.956104  1516 layer_factory.cpp:58] Creating layer bn2_2
I1120 18:22:45.956104  1516 net.cpp:84] Creating Layer bn2_2
I1120 18:22:45.956104  1516 net.cpp:406] bn2_2 <- conv2_2
I1120 18:22:45.956104  1516 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1120 18:22:45.956104  1516 net.cpp:122] Setting up bn2_2
I1120 18:22:45.956104  1516 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1120 18:22:45.956104  1516 net.cpp:137] Memory required for data: 685262000
I1120 18:22:45.956104  1516 layer_factory.cpp:58] Creating layer scale2_2
I1120 18:22:45.956104  1516 net.cpp:84] Creating Layer scale2_2
I1120 18:22:45.956104  1516 net.cpp:406] scale2_2 <- conv2_2
I1120 18:22:45.956104  1516 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1120 18:22:45.957118  1516 layer_factory.cpp:58] Creating layer scale2_2
I1120 18:22:45.957118  1516 net.cpp:122] Setting up scale2_2
I1120 18:22:45.957118  1516 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1120 18:22:45.957118  1516 net.cpp:137] Memory required for data: 720078000
I1120 18:22:45.957118  1516 layer_factory.cpp:58] Creating layer relu2_2
I1120 18:22:45.957118  1516 net.cpp:84] Creating Layer relu2_2
I1120 18:22:45.957118  1516 net.cpp:406] relu2_2 <- conv2_2
I1120 18:22:45.957118  1516 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1120 18:22:45.957118  1516 net.cpp:122] Setting up relu2_2
I1120 18:22:45.957118  1516 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1120 18:22:45.957118  1516 net.cpp:137] Memory required for data: 754894000
I1120 18:22:45.957118  1516 layer_factory.cpp:58] Creating layer pool2_1
I1120 18:22:45.957118  1516 net.cpp:84] Creating Layer pool2_1
I1120 18:22:45.957118  1516 net.cpp:406] pool2_1 <- conv2_2
I1120 18:22:45.957118  1516 net.cpp:380] pool2_1 -> pool2_1
I1120 18:22:45.957118  1516 net.cpp:122] Setting up pool2_1
I1120 18:22:45.957118  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.957118  1516 net.cpp:137] Memory required for data: 763598000
I1120 18:22:45.957118  1516 layer_factory.cpp:58] Creating layer drop5
I1120 18:22:45.957118  1516 net.cpp:84] Creating Layer drop5
I1120 18:22:45.957118  1516 net.cpp:406] drop5 <- pool2_1
I1120 18:22:45.957118  1516 net.cpp:367] drop5 -> pool2_1 (in-place)
I1120 18:22:45.957118  1516 net.cpp:122] Setting up drop5
I1120 18:22:45.957118  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.957118  1516 net.cpp:137] Memory required for data: 772302000
I1120 18:22:45.957118  1516 layer_factory.cpp:58] Creating layer conv3
I1120 18:22:45.957118  1516 net.cpp:84] Creating Layer conv3
I1120 18:22:45.957118  1516 net.cpp:406] conv3 <- pool2_1
I1120 18:22:45.957118  1516 net.cpp:380] conv3 -> conv3
I1120 18:22:45.960114  1516 net.cpp:122] Setting up conv3
I1120 18:22:45.960114  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.960114  1516 net.cpp:137] Memory required for data: 781006000
I1120 18:22:45.960114  1516 layer_factory.cpp:58] Creating layer bn3
I1120 18:22:45.960114  1516 net.cpp:84] Creating Layer bn3
I1120 18:22:45.960114  1516 net.cpp:406] bn3 <- conv3
I1120 18:22:45.960114  1516 net.cpp:367] bn3 -> conv3 (in-place)
I1120 18:22:45.960114  1516 net.cpp:122] Setting up bn3
I1120 18:22:45.960114  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.960114  1516 net.cpp:137] Memory required for data: 789710000
I1120 18:22:45.960114  1516 layer_factory.cpp:58] Creating layer scale3
I1120 18:22:45.960114  1516 net.cpp:84] Creating Layer scale3
I1120 18:22:45.960114  1516 net.cpp:406] scale3 <- conv3
I1120 18:22:45.960114  1516 net.cpp:367] scale3 -> conv3 (in-place)
I1120 18:22:45.960114  1516 layer_factory.cpp:58] Creating layer scale3
I1120 18:22:45.960114  1516 net.cpp:122] Setting up scale3
I1120 18:22:45.960114  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.960114  1516 net.cpp:137] Memory required for data: 798414000
I1120 18:22:45.960114  1516 layer_factory.cpp:58] Creating layer relu3
I1120 18:22:45.960114  1516 net.cpp:84] Creating Layer relu3
I1120 18:22:45.960114  1516 net.cpp:406] relu3 <- conv3
I1120 18:22:45.960114  1516 net.cpp:367] relu3 -> conv3 (in-place)
I1120 18:22:45.960114  1516 net.cpp:122] Setting up relu3
I1120 18:22:45.960114  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.960114  1516 net.cpp:137] Memory required for data: 807118000
I1120 18:22:45.960114  1516 layer_factory.cpp:58] Creating layer drop6
I1120 18:22:45.961112  1516 net.cpp:84] Creating Layer drop6
I1120 18:22:45.961112  1516 net.cpp:406] drop6 <- conv3
I1120 18:22:45.961112  1516 net.cpp:367] drop6 -> conv3 (in-place)
I1120 18:22:45.961112  1516 net.cpp:122] Setting up drop6
I1120 18:22:45.961112  1516 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1120 18:22:45.961112  1516 net.cpp:137] Memory required for data: 815822000
I1120 18:22:45.961112  1516 layer_factory.cpp:58] Creating layer conv3_1
I1120 18:22:45.961112  1516 net.cpp:84] Creating Layer conv3_1
I1120 18:22:45.961112  1516 net.cpp:406] conv3_1 <- conv3
I1120 18:22:45.961112  1516 net.cpp:380] conv3_1 -> conv3_1
I1120 18:22:45.962118  1516 net.cpp:122] Setting up conv3_1
I1120 18:22:45.962118  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.962118  1516 net.cpp:137] Memory required for data: 825038000
I1120 18:22:45.962118  1516 layer_factory.cpp:58] Creating layer bn3_1
I1120 18:22:45.963114  1516 net.cpp:84] Creating Layer bn3_1
I1120 18:22:45.963114  1516 net.cpp:406] bn3_1 <- conv3_1
I1120 18:22:45.963114  1516 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1120 18:22:45.963114  1516 net.cpp:122] Setting up bn3_1
I1120 18:22:45.963114  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.963114  1516 net.cpp:137] Memory required for data: 834254000
I1120 18:22:45.963114  1516 layer_factory.cpp:58] Creating layer scale3_1
I1120 18:22:45.963114  1516 net.cpp:84] Creating Layer scale3_1
I1120 18:22:45.963114  1516 net.cpp:406] scale3_1 <- conv3_1
I1120 18:22:45.963114  1516 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1120 18:22:45.963114  1516 layer_factory.cpp:58] Creating layer scale3_1
I1120 18:22:45.963114  1516 net.cpp:122] Setting up scale3_1
I1120 18:22:45.963114  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.963114  1516 net.cpp:137] Memory required for data: 843470000
I1120 18:22:45.963114  1516 layer_factory.cpp:58] Creating layer relu3_1
I1120 18:22:45.963114  1516 net.cpp:84] Creating Layer relu3_1
I1120 18:22:45.963114  1516 net.cpp:406] relu3_1 <- conv3_1
I1120 18:22:45.963114  1516 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1120 18:22:45.963114  1516 net.cpp:122] Setting up relu3_1
I1120 18:22:45.963114  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.963114  1516 net.cpp:137] Memory required for data: 852686000
I1120 18:22:45.963114  1516 layer_factory.cpp:58] Creating layer drop6_1
I1120 18:22:45.963114  1516 net.cpp:84] Creating Layer drop6_1
I1120 18:22:45.963114  1516 net.cpp:406] drop6_1 <- conv3_1
I1120 18:22:45.963114  1516 net.cpp:367] drop6_1 -> conv3_1 (in-place)
I1120 18:22:45.963114  1516 net.cpp:122] Setting up drop6_1
I1120 18:22:45.963114  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.963114  1516 net.cpp:137] Memory required for data: 861902000
I1120 18:22:45.963114  1516 layer_factory.cpp:58] Creating layer conv4
I1120 18:22:45.963114  1516 net.cpp:84] Creating Layer conv4
I1120 18:22:45.963114  1516 net.cpp:406] conv4 <- conv3_1
I1120 18:22:45.963114  1516 net.cpp:380] conv4 -> conv4
I1120 18:22:45.965113  1516 net.cpp:122] Setting up conv4
I1120 18:22:45.965113  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.965113  1516 net.cpp:137] Memory required for data: 871118000
I1120 18:22:45.965113  1516 layer_factory.cpp:58] Creating layer bn4
I1120 18:22:45.965113  1516 net.cpp:84] Creating Layer bn4
I1120 18:22:45.965113  1516 net.cpp:406] bn4 <- conv4
I1120 18:22:45.965113  1516 net.cpp:367] bn4 -> conv4 (in-place)
I1120 18:22:45.965113  1516 net.cpp:122] Setting up bn4
I1120 18:22:45.965113  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.965113  1516 net.cpp:137] Memory required for data: 880334000
I1120 18:22:45.965113  1516 layer_factory.cpp:58] Creating layer scale4
I1120 18:22:45.965113  1516 net.cpp:84] Creating Layer scale4
I1120 18:22:45.965113  1516 net.cpp:406] scale4 <- conv4
I1120 18:22:45.965113  1516 net.cpp:367] scale4 -> conv4 (in-place)
I1120 18:22:45.965113  1516 layer_factory.cpp:58] Creating layer scale4
I1120 18:22:45.965113  1516 net.cpp:122] Setting up scale4
I1120 18:22:45.966114  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.966114  1516 net.cpp:137] Memory required for data: 889550000
I1120 18:22:45.966114  1516 layer_factory.cpp:58] Creating layer relu4
I1120 18:22:45.966114  1516 net.cpp:84] Creating Layer relu4
I1120 18:22:45.966114  1516 net.cpp:406] relu4 <- conv4
I1120 18:22:45.966114  1516 net.cpp:367] relu4 -> conv4 (in-place)
I1120 18:22:45.966114  1516 net.cpp:122] Setting up relu4
I1120 18:22:45.966114  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.966114  1516 net.cpp:137] Memory required for data: 898766000
I1120 18:22:45.966114  1516 layer_factory.cpp:58] Creating layer drop7
I1120 18:22:45.966114  1516 net.cpp:84] Creating Layer drop7
I1120 18:22:45.966114  1516 net.cpp:406] drop7 <- conv4
I1120 18:22:45.966114  1516 net.cpp:367] drop7 -> conv4 (in-place)
I1120 18:22:45.966114  1516 net.cpp:122] Setting up drop7
I1120 18:22:45.966114  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.966114  1516 net.cpp:137] Memory required for data: 907982000
I1120 18:22:45.966114  1516 layer_factory.cpp:58] Creating layer conv4_1
I1120 18:22:45.966114  1516 net.cpp:84] Creating Layer conv4_1
I1120 18:22:45.966114  1516 net.cpp:406] conv4_1 <- conv4
I1120 18:22:45.966114  1516 net.cpp:380] conv4_1 -> conv4_1
I1120 18:22:45.968101  1516 net.cpp:122] Setting up conv4_1
I1120 18:22:45.968101  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.968101  1516 net.cpp:137] Memory required for data: 917198000
I1120 18:22:45.968101  1516 layer_factory.cpp:58] Creating layer bn4_1
I1120 18:22:45.968101  1516 net.cpp:84] Creating Layer bn4_1
I1120 18:22:45.968101  1516 net.cpp:406] bn4_1 <- conv4_1
I1120 18:22:45.968101  1516 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1120 18:22:45.968101  1516 net.cpp:122] Setting up bn4_1
I1120 18:22:45.968101  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.968101  1516 net.cpp:137] Memory required for data: 926414000
I1120 18:22:45.968101  1516 layer_factory.cpp:58] Creating layer scale4_1
I1120 18:22:45.968101  1516 net.cpp:84] Creating Layer scale4_1
I1120 18:22:45.968101  1516 net.cpp:406] scale4_1 <- conv4_1
I1120 18:22:45.968101  1516 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1120 18:22:45.968101  1516 layer_factory.cpp:58] Creating layer scale4_1
I1120 18:22:45.968101  1516 net.cpp:122] Setting up scale4_1
I1120 18:22:45.968101  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.968101  1516 net.cpp:137] Memory required for data: 935630000
I1120 18:22:45.968101  1516 layer_factory.cpp:58] Creating layer relu4_1
I1120 18:22:45.968101  1516 net.cpp:84] Creating Layer relu4_1
I1120 18:22:45.968101  1516 net.cpp:406] relu4_1 <- conv4_1
I1120 18:22:45.968101  1516 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1120 18:22:45.969101  1516 net.cpp:122] Setting up relu4_1
I1120 18:22:45.969101  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.969101  1516 net.cpp:137] Memory required for data: 944846000
I1120 18:22:45.969101  1516 layer_factory.cpp:58] Creating layer drop8
I1120 18:22:45.969101  1516 net.cpp:84] Creating Layer drop8
I1120 18:22:45.969101  1516 net.cpp:406] drop8 <- conv4_1
I1120 18:22:45.969101  1516 net.cpp:367] drop8 -> conv4_1 (in-place)
I1120 18:22:45.969101  1516 net.cpp:122] Setting up drop8
I1120 18:22:45.969101  1516 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1120 18:22:45.969101  1516 net.cpp:137] Memory required for data: 954062000
I1120 18:22:45.969101  1516 layer_factory.cpp:58] Creating layer conv4_2
I1120 18:22:45.969101  1516 net.cpp:84] Creating Layer conv4_2
I1120 18:22:45.969101  1516 net.cpp:406] conv4_2 <- conv4_1
I1120 18:22:45.969101  1516 net.cpp:380] conv4_2 -> conv4_2
I1120 18:22:45.970618  1516 net.cpp:122] Setting up conv4_2
I1120 18:22:45.970618  1516 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1120 18:22:45.970618  1516 net.cpp:137] Memory required for data: 965326000
I1120 18:22:45.970618  1516 layer_factory.cpp:58] Creating layer bn4_2
I1120 18:22:45.970618  1516 net.cpp:84] Creating Layer bn4_2
I1120 18:22:45.970618  1516 net.cpp:406] bn4_2 <- conv4_2
I1120 18:22:45.970618  1516 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1120 18:22:45.971128  1516 net.cpp:122] Setting up bn4_2
I1120 18:22:45.971128  1516 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1120 18:22:45.971128  1516 net.cpp:137] Memory required for data: 976590000
I1120 18:22:45.971128  1516 layer_factory.cpp:58] Creating layer scale4_2
I1120 18:22:45.971128  1516 net.cpp:84] Creating Layer scale4_2
I1120 18:22:45.971128  1516 net.cpp:406] scale4_2 <- conv4_2
I1120 18:22:45.971128  1516 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1120 18:22:45.971128  1516 layer_factory.cpp:58] Creating layer scale4_2
I1120 18:22:45.971128  1516 net.cpp:122] Setting up scale4_2
I1120 18:22:45.971128  1516 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1120 18:22:45.971128  1516 net.cpp:137] Memory required for data: 987854000
I1120 18:22:45.971128  1516 layer_factory.cpp:58] Creating layer relu4_2
I1120 18:22:45.971128  1516 net.cpp:84] Creating Layer relu4_2
I1120 18:22:45.971128  1516 net.cpp:406] relu4_2 <- conv4_2
I1120 18:22:45.971128  1516 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1120 18:22:45.971628  1516 net.cpp:122] Setting up relu4_2
I1120 18:22:45.971628  1516 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1120 18:22:45.971628  1516 net.cpp:137] Memory required for data: 999118000
I1120 18:22:45.971628  1516 layer_factory.cpp:58] Creating layer pool4_2
I1120 18:22:45.971628  1516 net.cpp:84] Creating Layer pool4_2
I1120 18:22:45.971628  1516 net.cpp:406] pool4_2 <- conv4_2
I1120 18:22:45.971628  1516 net.cpp:380] pool4_2 -> pool4_2
I1120 18:22:45.971628  1516 net.cpp:122] Setting up pool4_2
I1120 18:22:45.971628  1516 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1120 18:22:45.971628  1516 net.cpp:137] Memory required for data: 1001934000
I1120 18:22:45.971628  1516 layer_factory.cpp:58] Creating layer drop9
I1120 18:22:45.971628  1516 net.cpp:84] Creating Layer drop9
I1120 18:22:45.971628  1516 net.cpp:406] drop9 <- pool4_2
I1120 18:22:45.971628  1516 net.cpp:367] drop9 -> pool4_2 (in-place)
I1120 18:22:45.971628  1516 net.cpp:122] Setting up drop9
I1120 18:22:45.971628  1516 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1120 18:22:45.971628  1516 net.cpp:137] Memory required for data: 1004750000
I1120 18:22:45.971628  1516 layer_factory.cpp:58] Creating layer conv4_0
I1120 18:22:45.971628  1516 net.cpp:84] Creating Layer conv4_0
I1120 18:22:45.971628  1516 net.cpp:406] conv4_0 <- pool4_2
I1120 18:22:45.971628  1516 net.cpp:380] conv4_0 -> conv4_0
I1120 18:22:45.974119  1516 net.cpp:122] Setting up conv4_0
I1120 18:22:45.974119  1516 net.cpp:129] Top shape: 100 117 8 8 (748800)
I1120 18:22:45.974119  1516 net.cpp:137] Memory required for data: 1007745200
I1120 18:22:45.974119  1516 layer_factory.cpp:58] Creating layer bn4_0
I1120 18:22:45.974119  1516 net.cpp:84] Creating Layer bn4_0
I1120 18:22:45.974119  1516 net.cpp:406] bn4_0 <- conv4_0
I1120 18:22:45.974119  1516 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1120 18:22:45.974119  1516 net.cpp:122] Setting up bn4_0
I1120 18:22:45.974119  1516 net.cpp:129] Top shape: 100 117 8 8 (748800)
I1120 18:22:45.974119  1516 net.cpp:137] Memory required for data: 1010740400
I1120 18:22:45.974119  1516 layer_factory.cpp:58] Creating layer scale4_0
I1120 18:22:45.974119  1516 net.cpp:84] Creating Layer scale4_0
I1120 18:22:45.974119  1516 net.cpp:406] scale4_0 <- conv4_0
I1120 18:22:45.974119  1516 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1120 18:22:45.974119  1516 layer_factory.cpp:58] Creating layer scale4_0
I1120 18:22:45.974119  1516 net.cpp:122] Setting up scale4_0
I1120 18:22:45.974618  1516 net.cpp:129] Top shape: 100 117 8 8 (748800)
I1120 18:22:45.974618  1516 net.cpp:137] Memory required for data: 1013735600
I1120 18:22:45.974618  1516 layer_factory.cpp:58] Creating layer relu4_0
I1120 18:22:45.974618  1516 net.cpp:84] Creating Layer relu4_0
I1120 18:22:45.974618  1516 net.cpp:406] relu4_0 <- conv4_0
I1120 18:22:45.974618  1516 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1120 18:22:45.974618  1516 net.cpp:122] Setting up relu4_0
I1120 18:22:45.974618  1516 net.cpp:129] Top shape: 100 117 8 8 (748800)
I1120 18:22:45.974618  1516 net.cpp:137] Memory required for data: 1016730800
I1120 18:22:45.974618  1516 layer_factory.cpp:58] Creating layer drop10
I1120 18:22:45.974618  1516 net.cpp:84] Creating Layer drop10
I1120 18:22:45.974618  1516 net.cpp:406] drop10 <- conv4_0
I1120 18:22:45.974618  1516 net.cpp:367] drop10 -> conv4_0 (in-place)
I1120 18:22:45.974618  1516 net.cpp:122] Setting up drop10
I1120 18:22:45.974618  1516 net.cpp:129] Top shape: 100 117 8 8 (748800)
I1120 18:22:45.974618  1516 net.cpp:137] Memory required for data: 1019726000
I1120 18:22:45.974618  1516 layer_factory.cpp:58] Creating layer conv11
I1120 18:22:45.974618  1516 net.cpp:84] Creating Layer conv11
I1120 18:22:45.974618  1516 net.cpp:406] conv11 <- conv4_0
I1120 18:22:45.974618  1516 net.cpp:380] conv11 -> conv11
I1120 18:22:45.977118  1516 net.cpp:122] Setting up conv11
I1120 18:22:45.977118  1516 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1120 18:22:45.977118  1516 net.cpp:137] Memory required for data: 1023566000
I1120 18:22:45.977118  1516 layer_factory.cpp:58] Creating layer bn_conv11
I1120 18:22:45.977118  1516 net.cpp:84] Creating Layer bn_conv11
I1120 18:22:45.977118  1516 net.cpp:406] bn_conv11 <- conv11
I1120 18:22:45.977118  1516 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1120 18:22:45.977118  1516 net.cpp:122] Setting up bn_conv11
I1120 18:22:45.977118  1516 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1120 18:22:45.977118  1516 net.cpp:137] Memory required for data: 1027406000
I1120 18:22:45.977118  1516 layer_factory.cpp:58] Creating layer scale_conv11
I1120 18:22:45.977118  1516 net.cpp:84] Creating Layer scale_conv11
I1120 18:22:45.977118  1516 net.cpp:406] scale_conv11 <- conv11
I1120 18:22:45.977118  1516 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1120 18:22:45.977118  1516 layer_factory.cpp:58] Creating layer scale_conv11
I1120 18:22:45.977618  1516 net.cpp:122] Setting up scale_conv11
I1120 18:22:45.977618  1516 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1120 18:22:45.977618  1516 net.cpp:137] Memory required for data: 1031246000
I1120 18:22:45.977618  1516 layer_factory.cpp:58] Creating layer relu_conv11
I1120 18:22:45.977618  1516 net.cpp:84] Creating Layer relu_conv11
I1120 18:22:45.977618  1516 net.cpp:406] relu_conv11 <- conv11
I1120 18:22:45.977618  1516 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1120 18:22:45.977618  1516 net.cpp:122] Setting up relu_conv11
I1120 18:22:45.977618  1516 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1120 18:22:45.977618  1516 net.cpp:137] Memory required for data: 1035086000
I1120 18:22:45.977618  1516 layer_factory.cpp:58] Creating layer drop11
I1120 18:22:45.977618  1516 net.cpp:84] Creating Layer drop11
I1120 18:22:45.977618  1516 net.cpp:406] drop11 <- conv11
I1120 18:22:45.977618  1516 net.cpp:367] drop11 -> conv11 (in-place)
I1120 18:22:45.978118  1516 net.cpp:122] Setting up drop11
I1120 18:22:45.978118  1516 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1120 18:22:45.978118  1516 net.cpp:137] Memory required for data: 1038926000
I1120 18:22:45.978118  1516 layer_factory.cpp:58] Creating layer conv12
I1120 18:22:45.978118  1516 net.cpp:84] Creating Layer conv12
I1120 18:22:45.978118  1516 net.cpp:406] conv12 <- conv11
I1120 18:22:45.978118  1516 net.cpp:380] conv12 -> conv12
I1120 18:22:45.980118  1516 net.cpp:122] Setting up conv12
I1120 18:22:45.980118  1516 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1120 18:22:45.980118  1516 net.cpp:137] Memory required for data: 1041486000
I1120 18:22:45.980118  1516 layer_factory.cpp:58] Creating layer bn_conv12
I1120 18:22:45.980118  1516 net.cpp:84] Creating Layer bn_conv12
I1120 18:22:45.980118  1516 net.cpp:406] bn_conv12 <- conv12
I1120 18:22:45.980118  1516 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1120 18:22:45.980118  1516 net.cpp:122] Setting up bn_conv12
I1120 18:22:45.980118  1516 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1120 18:22:45.980618  1516 net.cpp:137] Memory required for data: 1044046000
I1120 18:22:45.980618  1516 layer_factory.cpp:58] Creating layer scale_conv12
I1120 18:22:45.980618  1516 net.cpp:84] Creating Layer scale_conv12
I1120 18:22:45.980618  1516 net.cpp:406] scale_conv12 <- conv12
I1120 18:22:45.980618  1516 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1120 18:22:45.980618  1516 layer_factory.cpp:58] Creating layer scale_conv12
I1120 18:22:45.980618  1516 net.cpp:122] Setting up scale_conv12
I1120 18:22:45.980618  1516 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1120 18:22:45.980618  1516 net.cpp:137] Memory required for data: 1046606000
I1120 18:22:45.980618  1516 layer_factory.cpp:58] Creating layer relu_conv12
I1120 18:22:45.980618  1516 net.cpp:84] Creating Layer relu_conv12
I1120 18:22:45.980618  1516 net.cpp:406] relu_conv12 <- conv12
I1120 18:22:45.980618  1516 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1120 18:22:45.980618  1516 net.cpp:122] Setting up relu_conv12
I1120 18:22:45.980618  1516 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1120 18:22:45.980618  1516 net.cpp:137] Memory required for data: 1049166000
I1120 18:22:45.980618  1516 layer_factory.cpp:58] Creating layer poolcp6
I1120 18:22:45.980618  1516 net.cpp:84] Creating Layer poolcp6
I1120 18:22:45.981118  1516 net.cpp:406] poolcp6 <- conv12
I1120 18:22:45.981118  1516 net.cpp:380] poolcp6 -> poolcp6
I1120 18:22:45.981118  1516 net.cpp:122] Setting up poolcp6
I1120 18:22:45.981118  1516 net.cpp:129] Top shape: 100 100 1 1 (10000)
I1120 18:22:45.981118  1516 net.cpp:137] Memory required for data: 1049206000
I1120 18:22:45.981118  1516 layer_factory.cpp:58] Creating layer poolcp6_poolcp6_0_split
I1120 18:22:45.981118  1516 net.cpp:84] Creating Layer poolcp6_poolcp6_0_split
I1120 18:22:45.981118  1516 net.cpp:406] poolcp6_poolcp6_0_split <- poolcp6
I1120 18:22:45.981118  1516 net.cpp:380] poolcp6_poolcp6_0_split -> poolcp6_poolcp6_0_split_0
I1120 18:22:45.981118  1516 net.cpp:380] poolcp6_poolcp6_0_split -> poolcp6_poolcp6_0_split_1
I1120 18:22:45.981118  1516 net.cpp:122] Setting up poolcp6_poolcp6_0_split
I1120 18:22:45.981118  1516 net.cpp:129] Top shape: 100 100 1 1 (10000)
I1120 18:22:45.981118  1516 net.cpp:129] Top shape: 100 100 1 1 (10000)
I1120 18:22:45.981118  1516 net.cpp:137] Memory required for data: 1049286000
I1120 18:22:45.981118  1516 layer_factory.cpp:58] Creating layer accuracy
I1120 18:22:45.981118  1516 net.cpp:84] Creating Layer accuracy
I1120 18:22:45.981118  1516 net.cpp:406] accuracy <- poolcp6_poolcp6_0_split_0
I1120 18:22:45.981118  1516 net.cpp:406] accuracy <- label_cifar_1_split_0
I1120 18:22:45.981118  1516 net.cpp:380] accuracy -> accuracy
I1120 18:22:45.981118  1516 net.cpp:122] Setting up accuracy
I1120 18:22:45.981118  1516 net.cpp:129] Top shape: (1)
I1120 18:22:45.981118  1516 net.cpp:137] Memory required for data: 1049286004
I1120 18:22:45.981118  1516 layer_factory.cpp:58] Creating layer loss
I1120 18:22:45.981118  1516 net.cpp:84] Creating Layer loss
I1120 18:22:45.981118  1516 net.cpp:406] loss <- poolcp6_poolcp6_0_split_1
I1120 18:22:45.981118  1516 net.cpp:406] loss <- label_cifar_1_split_1
I1120 18:22:45.981118  1516 net.cpp:380] loss -> loss
I1120 18:22:45.981118  1516 layer_factory.cpp:58] Creating layer loss
I1120 18:22:45.981616  1516 net.cpp:122] Setting up loss
I1120 18:22:45.981616  1516 net.cpp:129] Top shape: (1)
I1120 18:22:45.981616  1516 net.cpp:132]     with loss weight 1
I1120 18:22:45.981616  1516 net.cpp:137] Memory required for data: 1049286008
I1120 18:22:45.981616  1516 net.cpp:198] loss needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:200] accuracy does not need backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] poolcp6_poolcp6_0_split needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] poolcp6 needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] relu_conv12 needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] scale_conv12 needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] bn_conv12 needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] conv12 needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] drop11 needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] relu_conv11 needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] scale_conv11 needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] bn_conv11 needs backward computation.
I1120 18:22:45.981616  1516 net.cpp:198] conv11 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop10 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu4_0 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale4_0 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn4_0 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv4_0 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop9 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] pool4_2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu4_2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale4_2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn4_2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv4_2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop8 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu4_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale4_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn4_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv4_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop7 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu4 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale4 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn4 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv4 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop6_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu3_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale3_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn3_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv3_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop6 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu3 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale3 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn3 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv3 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop5 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] pool2_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu2_2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale2_2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn2_2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv2_2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop4 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu2_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale2_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn2_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv2_1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop3 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop2 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu1_0 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale1_0 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn1_0 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv1_0 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] drop1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] relu1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] scale1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] bn1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:198] conv1 needs backward computation.
I1120 18:22:45.982117  1516 net.cpp:200] label_cifar_1_split does not need backward computation.
I1120 18:22:45.982117  1516 net.cpp:200] cifar does not need backward computation.
I1120 18:22:45.982117  1516 net.cpp:242] This network produces output accuracy
I1120 18:22:45.982117  1516 net.cpp:242] This network produces output loss
I1120 18:22:45.982117  1516 net.cpp:255] Network initialization done.
I1120 18:22:45.982617  1516 solver.cpp:56] Solver scaffolding done.
I1120 18:22:45.986119  1516 caffe.cpp:243] Resuming from examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_90000.solverstate
I1120 18:22:46.050137  1516 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_90000.caffemodel
I1120 18:22:46.050137  1516 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1120 18:22:46.051138  1516 sgd_solver.cpp:318] SGDSolver: restoring history
I1120 18:22:46.057137  1516 caffe.cpp:249] Starting Optimization
I1120 18:22:46.057137  1516 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_13L_Simple_NoGrpCon_Drp_1M
I1120 18:22:46.057137  1516 solver.cpp:273] Learning Rate Policy: multistep
I1120 18:22:46.060132  1516 solver.cpp:330] Iteration 90000, Testing net (#0)
I1120 18:22:46.062139  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:22:48.385787 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:22:48.476045  1516 solver.cpp:397]     Test net output #0: accuracy = 0.652
I1120 18:22:48.476045  1516 solver.cpp:397]     Test net output #1: loss = 1.35288 (* 1 = 1.35288 loss)
I1120 18:22:48.691527  1516 solver.cpp:218] Iteration 90000 (34185.7 iter/s, 2.63268s/100 iters), loss = 1.02886
I1120 18:22:48.691527  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1120 18:22:48.691527  1516 solver.cpp:237]     Train net output #1: loss = 1.02886 (* 1 = 1.02886 loss)
I1120 18:22:48.691527  1516 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1120 18:22:58.383668  1516 solver.cpp:218] Iteration 90100 (10.318 iter/s, 9.69184s/100 iters), loss = 1.16008
I1120 18:22:58.383668  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1120 18:22:58.383668  1516 solver.cpp:237]     Train net output #1: loss = 1.16008 (* 1 = 1.16008 loss)
I1120 18:22:58.383668  1516 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1120 18:23:08.244698  1516 solver.cpp:218] Iteration 90200 (10.1418 iter/s, 9.86014s/100 iters), loss = 0.952661
I1120 18:23:08.244698  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1120 18:23:08.244698  1516 solver.cpp:237]     Train net output #1: loss = 0.952661 (* 1 = 0.952661 loss)
I1120 18:23:08.244698  1516 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1120 18:23:18.144974  1516 solver.cpp:218] Iteration 90300 (10.1012 iter/s, 9.89982s/100 iters), loss = 1.21438
I1120 18:23:18.144974  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1120 18:23:18.144974  1516 solver.cpp:237]     Train net output #1: loss = 1.21438 (* 1 = 1.21438 loss)
I1120 18:23:18.144974  1516 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1120 18:23:27.946882  1516 solver.cpp:218] Iteration 90400 (10.2027 iter/s, 9.80136s/100 iters), loss = 0.940234
I1120 18:23:27.946882  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1120 18:23:27.946882  1516 solver.cpp:237]     Train net output #1: loss = 0.940234 (* 1 = 0.940234 loss)
I1120 18:23:27.946882  1516 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1120 18:23:37.134127 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:23:37.515628  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_90500.caffemodel
I1120 18:23:37.544127  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_90500.solverstate
I1120 18:23:37.555626  1516 solver.cpp:330] Iteration 90500, Testing net (#0)
I1120 18:23:37.555626  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:23:39.825656 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:23:39.918658  1516 solver.cpp:397]     Test net output #0: accuracy = 0.6381
I1120 18:23:39.918658  1516 solver.cpp:397]     Test net output #1: loss = 1.42755 (* 1 = 1.42755 loss)
I1120 18:23:40.011670  1516 solver.cpp:218] Iteration 90500 (8.28893 iter/s, 12.0643s/100 iters), loss = 0.879149
I1120 18:23:40.012171  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 18:23:40.012171  1516 solver.cpp:237]     Train net output #1: loss = 0.879149 (* 1 = 0.879149 loss)
I1120 18:23:40.012171  1516 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1120 18:23:49.661451  1516 solver.cpp:218] Iteration 90600 (10.3635 iter/s, 9.64926s/100 iters), loss = 1.0743
I1120 18:23:49.661451  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1120 18:23:49.661451  1516 solver.cpp:237]     Train net output #1: loss = 1.0743 (* 1 = 1.0743 loss)
I1120 18:23:49.661451  1516 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1120 18:23:59.368476  1516 solver.cpp:218] Iteration 90700 (10.302 iter/s, 9.70688s/100 iters), loss = 0.820625
I1120 18:23:59.368476  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1120 18:23:59.368476  1516 solver.cpp:237]     Train net output #1: loss = 0.820625 (* 1 = 0.820625 loss)
I1120 18:23:59.368476  1516 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1120 18:24:09.010957  1516 solver.cpp:218] Iteration 90800 (10.3723 iter/s, 9.64108s/100 iters), loss = 1.14156
I1120 18:24:09.010957  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1120 18:24:09.010957  1516 solver.cpp:237]     Train net output #1: loss = 1.14156 (* 1 = 1.14156 loss)
I1120 18:24:09.010957  1516 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1120 18:24:18.661600  1516 solver.cpp:218] Iteration 90900 (10.3617 iter/s, 9.6509s/100 iters), loss = 1.19403
I1120 18:24:18.661600  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1120 18:24:18.661600  1516 solver.cpp:237]     Train net output #1: loss = 1.19403 (* 1 = 1.19403 loss)
I1120 18:24:18.661600  1516 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1120 18:24:27.853494 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:24:28.235533  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_91000.caffemodel
I1120 18:24:28.261528  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_91000.solverstate
I1120 18:24:28.273528  1516 solver.cpp:330] Iteration 91000, Testing net (#0)
I1120 18:24:28.273528  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:24:30.537690 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:24:30.628700  1516 solver.cpp:397]     Test net output #0: accuracy = 0.6457
I1120 18:24:30.628700  1516 solver.cpp:397]     Test net output #1: loss = 1.39922 (* 1 = 1.39922 loss)
I1120 18:24:30.724700  1516 solver.cpp:218] Iteration 91000 (8.29064 iter/s, 12.0618s/100 iters), loss = 0.821687
I1120 18:24:30.724700  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 18:24:30.724700  1516 solver.cpp:237]     Train net output #1: loss = 0.821687 (* 1 = 0.821687 loss)
I1120 18:24:30.724700  1516 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1120 18:24:40.368500  1516 solver.cpp:218] Iteration 91100 (10.3691 iter/s, 9.64402s/100 iters), loss = 0.917867
I1120 18:24:40.368500  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1120 18:24:40.368500  1516 solver.cpp:237]     Train net output #1: loss = 0.917867 (* 1 = 0.917867 loss)
I1120 18:24:40.368500  1516 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1120 18:24:50.023317  1516 solver.cpp:218] Iteration 91200 (10.3589 iter/s, 9.6535s/100 iters), loss = 0.889918
I1120 18:24:50.023317  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1120 18:24:50.023317  1516 solver.cpp:237]     Train net output #1: loss = 0.889918 (* 1 = 0.889918 loss)
I1120 18:24:50.023317  1516 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1120 18:24:59.679102  1516 solver.cpp:218] Iteration 91300 (10.3571 iter/s, 9.65521s/100 iters), loss = 0.877242
I1120 18:24:59.679102  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1120 18:24:59.679102  1516 solver.cpp:237]     Train net output #1: loss = 0.877242 (* 1 = 0.877242 loss)
I1120 18:24:59.679102  1516 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1120 18:25:09.433773  1516 solver.cpp:218] Iteration 91400 (10.2519 iter/s, 9.75428s/100 iters), loss = 1.11111
I1120 18:25:09.433773  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1120 18:25:09.433773  1516 solver.cpp:237]     Train net output #1: loss = 1.11111 (* 1 = 1.11111 loss)
I1120 18:25:09.433773  1516 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1120 18:25:18.631909 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:25:19.011639  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_91500.caffemodel
I1120 18:25:19.038650  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_91500.solverstate
I1120 18:25:19.049681  1516 solver.cpp:330] Iteration 91500, Testing net (#0)
I1120 18:25:19.049681  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:25:21.308142 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:25:21.398325  1516 solver.cpp:397]     Test net output #0: accuracy = 0.6565
I1120 18:25:21.398325  1516 solver.cpp:397]     Test net output #1: loss = 1.33889 (* 1 = 1.33889 loss)
I1120 18:25:21.492869  1516 solver.cpp:218] Iteration 91500 (8.29279 iter/s, 12.0587s/100 iters), loss = 0.889388
I1120 18:25:21.492869  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1120 18:25:21.492869  1516 solver.cpp:237]     Train net output #1: loss = 0.889388 (* 1 = 0.889388 loss)
I1120 18:25:21.492869  1516 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1120 18:25:31.143805  1516 solver.cpp:218] Iteration 91600 (10.3617 iter/s, 9.65095s/100 iters), loss = 0.872496
I1120 18:25:31.144806  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1120 18:25:31.144806  1516 solver.cpp:237]     Train net output #1: loss = 0.872496 (* 1 = 0.872496 loss)
I1120 18:25:31.144806  1516 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1120 18:25:40.807138  1516 solver.cpp:218] Iteration 91700 (10.3492 iter/s, 9.66259s/100 iters), loss = 0.732581
I1120 18:25:40.807138  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 18:25:40.807138  1516 solver.cpp:237]     Train net output #1: loss = 0.732581 (* 1 = 0.732581 loss)
I1120 18:25:40.807138  1516 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1120 18:25:50.498966  1516 solver.cpp:218] Iteration 91800 (10.3191 iter/s, 9.69074s/100 iters), loss = 1.07319
I1120 18:25:50.498966  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1120 18:25:50.498966  1516 solver.cpp:237]     Train net output #1: loss = 1.07319 (* 1 = 1.07319 loss)
I1120 18:25:50.498966  1516 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1120 18:26:00.200126  1516 solver.cpp:218] Iteration 91900 (10.3089 iter/s, 9.70034s/100 iters), loss = 1.15228
I1120 18:26:00.200126  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1120 18:26:00.200126  1516 solver.cpp:237]     Train net output #1: loss = 1.15228 (* 1 = 1.15228 loss)
I1120 18:26:00.200126  1516 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1120 18:26:09.416769 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:26:09.801810  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_92000.caffemodel
I1120 18:26:09.827816  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_92000.solverstate
I1120 18:26:09.839815  1516 solver.cpp:330] Iteration 92000, Testing net (#0)
I1120 18:26:09.839815  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:26:12.113971 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:26:12.205976  1516 solver.cpp:397]     Test net output #0: accuracy = 0.6464
I1120 18:26:12.205976  1516 solver.cpp:397]     Test net output #1: loss = 1.36762 (* 1 = 1.36762 loss)
I1120 18:26:12.300477  1516 solver.cpp:218] Iteration 92000 (8.26466 iter/s, 12.0997s/100 iters), loss = 0.796196
I1120 18:26:12.300477  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1120 18:26:12.300477  1516 solver.cpp:237]     Train net output #1: loss = 0.796196 (* 1 = 0.796196 loss)
I1120 18:26:12.300477  1516 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1120 18:26:21.995872  1516 solver.cpp:218] Iteration 92100 (10.3147 iter/s, 9.69489s/100 iters), loss = 1.01092
I1120 18:26:21.995872  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1120 18:26:21.995872  1516 solver.cpp:237]     Train net output #1: loss = 1.01092 (* 1 = 1.01092 loss)
I1120 18:26:21.995872  1516 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1120 18:26:31.735457  1516 solver.cpp:218] Iteration 92200 (10.2681 iter/s, 9.73891s/100 iters), loss = 1.02893
I1120 18:26:31.735457  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1120 18:26:31.735457  1516 solver.cpp:237]     Train net output #1: loss = 1.02893 (* 1 = 1.02893 loss)
I1120 18:26:31.735457  1516 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1120 18:26:41.424391  1516 solver.cpp:218] Iteration 92300 (10.3216 iter/s, 9.6884s/100 iters), loss = 1.21982
I1120 18:26:41.424391  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1120 18:26:41.424391  1516 solver.cpp:237]     Train net output #1: loss = 1.21982 (* 1 = 1.21982 loss)
I1120 18:26:41.424391  1516 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1120 18:26:51.106453  1516 solver.cpp:218] Iteration 92400 (10.329 iter/s, 9.68151s/100 iters), loss = 0.971713
I1120 18:26:51.106453  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1120 18:26:51.106453  1516 solver.cpp:237]     Train net output #1: loss = 0.971713 (* 1 = 0.971713 loss)
I1120 18:26:51.106453  1516 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1120 18:27:00.280728 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:27:00.660778  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_92500.caffemodel
I1120 18:27:00.686779  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_92500.solverstate
I1120 18:27:00.699282  1516 solver.cpp:330] Iteration 92500, Testing net (#0)
I1120 18:27:00.699282  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:27:02.959926 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:27:03.050935  1516 solver.cpp:397]     Test net output #0: accuracy = 0.6462
I1120 18:27:03.050935  1516 solver.cpp:397]     Test net output #1: loss = 1.37163 (* 1 = 1.37163 loss)
I1120 18:27:03.144937  1516 solver.cpp:218] Iteration 92500 (8.3072 iter/s, 12.0377s/100 iters), loss = 0.852554
I1120 18:27:03.144937  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 18:27:03.144937  1516 solver.cpp:237]     Train net output #1: loss = 0.852554 (* 1 = 0.852554 loss)
I1120 18:27:03.144937  1516 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1120 18:27:12.798288  1516 solver.cpp:218] Iteration 92600 (10.3597 iter/s, 9.65282s/100 iters), loss = 0.982131
I1120 18:27:12.798288  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1120 18:27:12.798288  1516 solver.cpp:237]     Train net output #1: loss = 0.982131 (* 1 = 0.982131 loss)
I1120 18:27:12.798288  1516 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1120 18:27:22.449523  1516 solver.cpp:218] Iteration 92700 (10.3612 iter/s, 9.65144s/100 iters), loss = 0.877448
I1120 18:27:22.450525  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1120 18:27:22.450525  1516 solver.cpp:237]     Train net output #1: loss = 0.877448 (* 1 = 0.877448 loss)
I1120 18:27:22.450525  1516 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1120 18:27:32.131243  1516 solver.cpp:218] Iteration 92800 (10.3299 iter/s, 9.68066s/100 iters), loss = 0.912355
I1120 18:27:32.131243  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1120 18:27:32.131243  1516 solver.cpp:237]     Train net output #1: loss = 0.912355 (* 1 = 0.912355 loss)
I1120 18:27:32.131243  1516 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1120 18:27:41.799427  1516 solver.cpp:218] Iteration 92900 (10.3441 iter/s, 9.66738s/100 iters), loss = 1.0625
I1120 18:27:41.799427  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1120 18:27:41.799427  1516 solver.cpp:237]     Train net output #1: loss = 1.0625 (* 1 = 1.0625 loss)
I1120 18:27:41.799427  1516 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1120 18:27:50.990238 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:27:51.372256  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_93000.caffemodel
I1120 18:27:51.398259  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_93000.solverstate
I1120 18:27:51.409260  1516 solver.cpp:330] Iteration 93000, Testing net (#0)
I1120 18:27:51.409260  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:27:53.674921 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:27:53.765422  1516 solver.cpp:397]     Test net output #0: accuracy = 0.6439
I1120 18:27:53.765422  1516 solver.cpp:397]     Test net output #1: loss = 1.40722 (* 1 = 1.40722 loss)
I1120 18:27:53.859444  1516 solver.cpp:218] Iteration 93000 (8.2921 iter/s, 12.0597s/100 iters), loss = 0.993747
I1120 18:27:53.859444  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 18:27:53.859444  1516 solver.cpp:237]     Train net output #1: loss = 0.993747 (* 1 = 0.993747 loss)
I1120 18:27:53.859444  1516 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1120 18:28:03.546216  1516 solver.cpp:218] Iteration 93100 (10.3239 iter/s, 9.68629s/100 iters), loss = 1.09492
I1120 18:28:03.546216  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1120 18:28:03.546216  1516 solver.cpp:237]     Train net output #1: loss = 1.09492 (* 1 = 1.09492 loss)
I1120 18:28:03.546216  1516 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1120 18:28:13.312199  1516 solver.cpp:218] Iteration 93200 (10.2401 iter/s, 9.76556s/100 iters), loss = 0.868558
I1120 18:28:13.312199  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1120 18:28:13.312199  1516 solver.cpp:237]     Train net output #1: loss = 0.868558 (* 1 = 0.868558 loss)
I1120 18:28:13.312199  1516 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1120 18:28:23.122597  1516 solver.cpp:218] Iteration 93300 (10.1943 iter/s, 9.80945s/100 iters), loss = 1.03901
I1120 18:28:23.122597  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1120 18:28:23.122597  1516 solver.cpp:237]     Train net output #1: loss = 1.03901 (* 1 = 1.03901 loss)
I1120 18:28:23.122597  1516 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1120 18:28:32.947666  1516 solver.cpp:218] Iteration 93400 (10.1782 iter/s, 9.82495s/100 iters), loss = 1.00509
I1120 18:28:32.948668  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1120 18:28:32.948668  1516 solver.cpp:237]     Train net output #1: loss = 1.00509 (* 1 = 1.00509 loss)
I1120 18:28:32.948668  1516 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1120 18:28:42.306366 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:28:42.689904  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_93500.caffemodel
I1120 18:28:42.718410  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_93500.solverstate
I1120 18:28:42.730409  1516 solver.cpp:330] Iteration 93500, Testing net (#0)
I1120 18:28:42.730409  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:28:45.040617 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:28:45.131654  1516 solver.cpp:397]     Test net output #0: accuracy = 0.6627
I1120 18:28:45.131654  1516 solver.cpp:397]     Test net output #1: loss = 1.30165 (* 1 = 1.30165 loss)
I1120 18:28:45.224645  1516 solver.cpp:218] Iteration 93500 (8.1461 iter/s, 12.2758s/100 iters), loss = 0.770574
I1120 18:28:45.224645  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:28:45.224645  1516 solver.cpp:237]     Train net output #1: loss = 0.770574 (* 1 = 0.770574 loss)
I1120 18:28:45.224645  1516 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1120 18:28:54.953543  1516 solver.cpp:218] Iteration 93600 (10.2789 iter/s, 9.72865s/100 iters), loss = 0.927503
I1120 18:28:54.953543  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1120 18:28:54.953543  1516 solver.cpp:237]     Train net output #1: loss = 0.927503 (* 1 = 0.927503 loss)
I1120 18:28:54.953543  1516 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1120 18:29:04.700120  1516 solver.cpp:218] Iteration 93700 (10.2613 iter/s, 9.74537s/100 iters), loss = 0.7745
I1120 18:29:04.700120  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:29:04.700120  1516 solver.cpp:237]     Train net output #1: loss = 0.7745 (* 1 = 0.7745 loss)
I1120 18:29:04.700120  1516 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1120 18:29:14.401492  1516 solver.cpp:218] Iteration 93800 (10.3086 iter/s, 9.70068s/100 iters), loss = 1.21494
I1120 18:29:14.401492  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1120 18:29:14.401492  1516 solver.cpp:237]     Train net output #1: loss = 1.21494 (* 1 = 1.21494 loss)
I1120 18:29:14.401492  1516 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1120 18:29:24.148722  1516 solver.cpp:218] Iteration 93900 (10.2595 iter/s, 9.7471s/100 iters), loss = 1.12475
I1120 18:29:24.148722  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1120 18:29:24.148722  1516 solver.cpp:237]     Train net output #1: loss = 1.12475 (* 1 = 1.12475 loss)
I1120 18:29:24.148722  1516 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1120 18:29:33.415783 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:29:33.795819  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_94000.caffemodel
I1120 18:29:33.822824  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_94000.solverstate
I1120 18:29:33.834826  1516 solver.cpp:330] Iteration 94000, Testing net (#0)
I1120 18:29:33.834826  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:29:36.098079 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:29:36.189083  1516 solver.cpp:397]     Test net output #0: accuracy = 0.6349
I1120 18:29:36.189083  1516 solver.cpp:397]     Test net output #1: loss = 1.44256 (* 1 = 1.44256 loss)
I1120 18:29:36.283089  1516 solver.cpp:218] Iteration 94000 (8.24151 iter/s, 12.1337s/100 iters), loss = 0.9106
I1120 18:29:36.283089  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:29:36.283089  1516 solver.cpp:237]     Train net output #1: loss = 0.9106 (* 1 = 0.9106 loss)
I1120 18:29:36.283089  1516 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1120 18:29:46.032618  1516 solver.cpp:218] Iteration 94100 (10.2569 iter/s, 9.74952s/100 iters), loss = 0.921173
I1120 18:29:46.033619  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1120 18:29:46.033619  1516 solver.cpp:237]     Train net output #1: loss = 0.921173 (* 1 = 0.921173 loss)
I1120 18:29:46.033619  1516 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1120 18:29:55.771608  1516 solver.cpp:218] Iteration 94200 (10.2699 iter/s, 9.73723s/100 iters), loss = 0.839218
I1120 18:29:55.771608  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:29:55.771608  1516 solver.cpp:237]     Train net output #1: loss = 0.839218 (* 1 = 0.839218 loss)
I1120 18:29:55.771608  1516 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1120 18:30:05.507400  1516 solver.cpp:218] Iteration 94300 (10.2712 iter/s, 9.73593s/100 iters), loss = 1.28651
I1120 18:30:05.507400  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1120 18:30:05.507400  1516 solver.cpp:237]     Train net output #1: loss = 1.28651 (* 1 = 1.28651 loss)
I1120 18:30:05.507400  1516 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1120 18:30:15.216014  1516 solver.cpp:218] Iteration 94400 (10.3014 iter/s, 9.70745s/100 iters), loss = 1.12558
I1120 18:30:15.216014  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1120 18:30:15.216014  1516 solver.cpp:237]     Train net output #1: loss = 1.12558 (* 1 = 1.12558 loss)
I1120 18:30:15.216014  1516 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1120 18:30:24.474838 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:30:24.854359  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_94500.caffemodel
I1120 18:30:24.879369  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_94500.solverstate
I1120 18:30:24.890368  1516 solver.cpp:330] Iteration 94500, Testing net (#0)
I1120 18:30:24.890368  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:30:27.159504 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:30:27.253512  1516 solver.cpp:397]     Test net output #0: accuracy = 0.6515
I1120 18:30:27.253512  1516 solver.cpp:397]     Test net output #1: loss = 1.35574 (* 1 = 1.35574 loss)
I1120 18:30:27.349519  1516 solver.cpp:218] Iteration 94500 (8.24145 iter/s, 12.1338s/100 iters), loss = 0.805612
I1120 18:30:27.350520  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:30:27.350520  1516 solver.cpp:237]     Train net output #1: loss = 0.805612 (* 1 = 0.805612 loss)
I1120 18:30:27.350520  1516 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1120 18:30:37.074908  1516 solver.cpp:218] Iteration 94600 (10.2836 iter/s, 9.72419s/100 iters), loss = 1.06212
I1120 18:30:37.074908  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1120 18:30:37.074908  1516 solver.cpp:237]     Train net output #1: loss = 1.06212 (* 1 = 1.06212 loss)
I1120 18:30:37.074908  1516 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1120 18:30:46.812335  1516 solver.cpp:218] Iteration 94700 (10.2701 iter/s, 9.73696s/100 iters), loss = 0.885613
I1120 18:30:46.812335  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1120 18:30:46.812335  1516 solver.cpp:237]     Train net output #1: loss = 0.885613 (* 1 = 0.885613 loss)
I1120 18:30:46.812335  1516 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1120 18:30:56.563388  1516 solver.cpp:218] Iteration 94800 (10.2562 iter/s, 9.75018s/100 iters), loss = 1.09044
I1120 18:30:56.563388  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1120 18:30:56.563388  1516 solver.cpp:237]     Train net output #1: loss = 1.09044 (* 1 = 1.09044 loss)
I1120 18:30:56.563388  1516 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1120 18:31:06.228215  1516 solver.cpp:218] Iteration 94900 (10.3467 iter/s, 9.66493s/100 iters), loss = 1.19929
I1120 18:31:06.228215  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1120 18:31:06.228215  1516 solver.cpp:237]     Train net output #1: loss = 1.19929 (* 1 = 1.19929 loss)
I1120 18:31:06.228215  1516 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1120 18:31:15.608880 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:31:15.990205  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_95000.caffemodel
I1120 18:31:16.017205  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_95000.solverstate
I1120 18:31:16.028205  1516 solver.cpp:330] Iteration 95000, Testing net (#0)
I1120 18:31:16.028205  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:31:18.289345 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:31:18.380347  1516 solver.cpp:397]     Test net output #0: accuracy = 0.6589
I1120 18:31:18.380347  1516 solver.cpp:397]     Test net output #1: loss = 1.34977 (* 1 = 1.34977 loss)
I1120 18:31:18.474367  1516 solver.cpp:218] Iteration 95000 (8.16636 iter/s, 12.2454s/100 iters), loss = 0.858658
I1120 18:31:18.474367  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:31:18.474367  1516 solver.cpp:237]     Train net output #1: loss = 0.858658 (* 1 = 0.858658 loss)
I1120 18:31:18.474367  1516 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1120 18:31:18.474367  1516 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1120 18:31:28.136217  1516 solver.cpp:218] Iteration 95100 (10.3508 iter/s, 9.66111s/100 iters), loss = 0.86946
I1120 18:31:28.136217  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1120 18:31:28.136217  1516 solver.cpp:237]     Train net output #1: loss = 0.86946 (* 1 = 0.86946 loss)
I1120 18:31:28.136217  1516 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1120 18:31:37.882319  1516 solver.cpp:218] Iteration 95200 (10.2609 iter/s, 9.7457s/100 iters), loss = 0.696184
I1120 18:31:37.882319  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:31:37.882319  1516 solver.cpp:237]     Train net output #1: loss = 0.696184 (* 1 = 0.696184 loss)
I1120 18:31:37.882319  1516 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1120 18:31:47.671046  1516 solver.cpp:218] Iteration 95300 (10.2171 iter/s, 9.78753s/100 iters), loss = 0.828621
I1120 18:31:47.671046  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:31:47.671046  1516 solver.cpp:237]     Train net output #1: loss = 0.828621 (* 1 = 0.828621 loss)
I1120 18:31:47.671046  1516 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1120 18:31:57.505874  1516 solver.cpp:218] Iteration 95400 (10.1685 iter/s, 9.83426s/100 iters), loss = 0.843118
I1120 18:31:57.505874  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1120 18:31:57.505874  1516 solver.cpp:237]     Train net output #1: loss = 0.843118 (* 1 = 0.843118 loss)
I1120 18:31:57.505874  1516 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1120 18:32:06.785867 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:32:07.166884  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_95500.caffemodel
I1120 18:32:07.191885  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_95500.solverstate
I1120 18:32:07.202884  1516 solver.cpp:330] Iteration 95500, Testing net (#0)
I1120 18:32:07.203886  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:32:09.480044 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:32:09.574059  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7244
I1120 18:32:09.574059  1516 solver.cpp:397]     Test net output #1: loss = 1.0467 (* 1 = 1.0467 loss)
I1120 18:32:09.672055  1516 solver.cpp:218] Iteration 95500 (8.21982 iter/s, 12.1657s/100 iters), loss = 0.684026
I1120 18:32:09.672055  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 18:32:09.672055  1516 solver.cpp:237]     Train net output #1: loss = 0.684026 (* 1 = 0.684026 loss)
I1120 18:32:09.672055  1516 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1120 18:32:19.599064  1516 solver.cpp:218] Iteration 95600 (10.0735 iter/s, 9.92707s/100 iters), loss = 0.641211
I1120 18:32:19.599064  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:32:19.599064  1516 solver.cpp:237]     Train net output #1: loss = 0.641211 (* 1 = 0.641211 loss)
I1120 18:32:19.599064  1516 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1120 18:32:29.605563  1516 solver.cpp:218] Iteration 95700 (9.99454 iter/s, 10.0055s/100 iters), loss = 0.636341
I1120 18:32:29.605563  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:32:29.605563  1516 solver.cpp:237]     Train net output #1: loss = 0.636341 (* 1 = 0.636341 loss)
I1120 18:32:29.605563  1516 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1120 18:32:39.693686  1516 solver.cpp:218] Iteration 95800 (9.91285 iter/s, 10.0879s/100 iters), loss = 0.675649
I1120 18:32:39.693686  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:32:39.693686  1516 solver.cpp:237]     Train net output #1: loss = 0.675649 (* 1 = 0.675649 loss)
I1120 18:32:39.693686  1516 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1120 18:32:49.823673  1516 solver.cpp:218] Iteration 95900 (9.87265 iter/s, 10.129s/100 iters), loss = 0.891423
I1120 18:32:49.823673  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1120 18:32:49.823673  1516 solver.cpp:237]     Train net output #1: loss = 0.891423 (* 1 = 0.891423 loss)
I1120 18:32:49.823673  1516 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1120 18:32:59.511730 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:32:59.914763  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_96000.caffemodel
I1120 18:32:59.943763  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_96000.solverstate
I1120 18:32:59.955763  1516 solver.cpp:330] Iteration 96000, Testing net (#0)
I1120 18:32:59.955763  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:33:02.322942 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:33:02.417949  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7263
I1120 18:33:02.417949  1516 solver.cpp:397]     Test net output #1: loss = 1.04137 (* 1 = 1.04137 loss)
I1120 18:33:02.516969  1516 solver.cpp:218] Iteration 96000 (7.87841 iter/s, 12.6929s/100 iters), loss = 0.617939
I1120 18:33:02.517977  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:33:02.517977  1516 solver.cpp:237]     Train net output #1: loss = 0.617939 (* 1 = 0.617939 loss)
I1120 18:33:02.517977  1516 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1120 18:33:12.524900  1516 solver.cpp:218] Iteration 96100 (9.99314 iter/s, 10.0069s/100 iters), loss = 0.66907
I1120 18:33:12.524900  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:33:12.524900  1516 solver.cpp:237]     Train net output #1: loss = 0.66907 (* 1 = 0.66907 loss)
I1120 18:33:12.524900  1516 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1120 18:33:22.352679  1516 solver.cpp:218] Iteration 96200 (10.1763 iter/s, 9.82671s/100 iters), loss = 0.679525
I1120 18:33:22.352679  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:33:22.352679  1516 solver.cpp:237]     Train net output #1: loss = 0.679525 (* 1 = 0.679525 loss)
I1120 18:33:22.352679  1516 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1120 18:33:32.179496  1516 solver.cpp:218] Iteration 96300 (10.1763 iter/s, 9.82679s/100 iters), loss = 0.734588
I1120 18:33:32.179496  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:33:32.179496  1516 solver.cpp:237]     Train net output #1: loss = 0.734588 (* 1 = 0.734588 loss)
I1120 18:33:32.179496  1516 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1120 18:33:42.006445  1516 solver.cpp:218] Iteration 96400 (10.1771 iter/s, 9.826s/100 iters), loss = 0.794796
I1120 18:33:42.006445  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 18:33:42.006445  1516 solver.cpp:237]     Train net output #1: loss = 0.794796 (* 1 = 0.794796 loss)
I1120 18:33:42.006445  1516 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1120 18:33:51.358338 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:33:51.745364  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_96500.caffemodel
I1120 18:33:51.771378  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_96500.solverstate
I1120 18:33:51.783382  1516 solver.cpp:330] Iteration 96500, Testing net (#0)
I1120 18:33:51.783382  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:33:54.089637 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:33:54.182641  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7284
I1120 18:33:54.182641  1516 solver.cpp:397]     Test net output #1: loss = 1.03473 (* 1 = 1.03473 loss)
I1120 18:33:54.278144  1516 solver.cpp:218] Iteration 96500 (8.14937 iter/s, 12.2709s/100 iters), loss = 0.680099
I1120 18:33:54.278144  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1120 18:33:54.278144  1516 solver.cpp:237]     Train net output #1: loss = 0.680099 (* 1 = 0.680099 loss)
I1120 18:33:54.278144  1516 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1120 18:34:04.107887  1516 solver.cpp:218] Iteration 96600 (10.1734 iter/s, 9.82959s/100 iters), loss = 0.751223
I1120 18:34:04.107887  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:34:04.108887  1516 solver.cpp:237]     Train net output #1: loss = 0.751223 (* 1 = 0.751223 loss)
I1120 18:34:04.108887  1516 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1120 18:34:13.941633  1516 solver.cpp:218] Iteration 96700 (10.1705 iter/s, 9.83234s/100 iters), loss = 0.625191
I1120 18:34:13.941633  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:34:13.941633  1516 solver.cpp:237]     Train net output #1: loss = 0.625191 (* 1 = 0.625191 loss)
I1120 18:34:13.941633  1516 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1120 18:34:23.771030  1516 solver.cpp:218] Iteration 96800 (10.1741 iter/s, 9.82884s/100 iters), loss = 0.781153
I1120 18:34:23.771030  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:34:23.771030  1516 solver.cpp:237]     Train net output #1: loss = 0.781153 (* 1 = 0.781153 loss)
I1120 18:34:23.771030  1516 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1120 18:34:33.593034  1516 solver.cpp:218] Iteration 96900 (10.1818 iter/s, 9.82146s/100 iters), loss = 0.73534
I1120 18:34:33.593034  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:34:33.593034  1516 solver.cpp:237]     Train net output #1: loss = 0.73534 (* 1 = 0.73534 loss)
I1120 18:34:33.593034  1516 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1120 18:34:42.924741 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:34:43.314808  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_97000.caffemodel
I1120 18:34:43.344804  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_97000.solverstate
I1120 18:34:43.355803  1516 solver.cpp:330] Iteration 97000, Testing net (#0)
I1120 18:34:43.355803  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:34:45.661953 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:34:45.754956  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7284
I1120 18:34:45.754956  1516 solver.cpp:397]     Test net output #1: loss = 1.03849 (* 1 = 1.03849 loss)
I1120 18:34:45.849963  1516 solver.cpp:218] Iteration 97000 (8.15875 iter/s, 12.2568s/100 iters), loss = 0.689791
I1120 18:34:45.849963  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:34:45.849963  1516 solver.cpp:237]     Train net output #1: loss = 0.689791 (* 1 = 0.689791 loss)
I1120 18:34:45.849963  1516 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1120 18:34:55.677845  1516 solver.cpp:218] Iteration 97100 (10.1763 iter/s, 9.82671s/100 iters), loss = 0.800445
I1120 18:34:55.677845  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 18:34:55.677845  1516 solver.cpp:237]     Train net output #1: loss = 0.800445 (* 1 = 0.800445 loss)
I1120 18:34:55.677845  1516 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1120 18:35:05.511783  1516 solver.cpp:218] Iteration 97200 (10.1692 iter/s, 9.83362s/100 iters), loss = 0.532601
I1120 18:35:05.511783  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:35:05.511783  1516 solver.cpp:237]     Train net output #1: loss = 0.532601 (* 1 = 0.532601 loss)
I1120 18:35:05.511783  1516 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1120 18:35:15.339565  1516 solver.cpp:218] Iteration 97300 (10.1753 iter/s, 9.82777s/100 iters), loss = 0.738818
I1120 18:35:15.339565  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 18:35:15.339565  1516 solver.cpp:237]     Train net output #1: loss = 0.738818 (* 1 = 0.738818 loss)
I1120 18:35:15.340564  1516 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1120 18:35:25.177922  1516 solver.cpp:218] Iteration 97400 (10.1657 iter/s, 9.83698s/100 iters), loss = 0.810123
I1120 18:35:25.177922  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 18:35:25.177922  1516 solver.cpp:237]     Train net output #1: loss = 0.810123 (* 1 = 0.810123 loss)
I1120 18:35:25.177922  1516 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1120 18:35:34.524446 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:35:34.909487  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_97500.caffemodel
I1120 18:35:34.934486  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_97500.solverstate
I1120 18:35:34.946486  1516 solver.cpp:330] Iteration 97500, Testing net (#0)
I1120 18:35:34.946486  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:35:37.251641 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:35:37.344645  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7291
I1120 18:35:37.344645  1516 solver.cpp:397]     Test net output #1: loss = 1.03382 (* 1 = 1.03382 loss)
I1120 18:35:37.439651  1516 solver.cpp:218] Iteration 97500 (8.15538 iter/s, 12.2618s/100 iters), loss = 0.712825
I1120 18:35:37.439651  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:35:37.439651  1516 solver.cpp:237]     Train net output #1: loss = 0.712825 (* 1 = 0.712825 loss)
I1120 18:35:37.439651  1516 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1120 18:35:47.266932  1516 solver.cpp:218] Iteration 97600 (10.1771 iter/s, 9.82596s/100 iters), loss = 0.793125
I1120 18:35:47.266932  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 18:35:47.266932  1516 solver.cpp:237]     Train net output #1: loss = 0.793125 (* 1 = 0.793125 loss)
I1120 18:35:47.266932  1516 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1120 18:35:57.094460  1516 solver.cpp:218] Iteration 97700 (10.1758 iter/s, 9.82728s/100 iters), loss = 0.56512
I1120 18:35:57.094460  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:35:57.094460  1516 solver.cpp:237]     Train net output #1: loss = 0.56512 (* 1 = 0.56512 loss)
I1120 18:35:57.094460  1516 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1120 18:36:06.921082  1516 solver.cpp:218] Iteration 97800 (10.1771 iter/s, 9.82597s/100 iters), loss = 0.747056
I1120 18:36:06.921581  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1120 18:36:06.921581  1516 solver.cpp:237]     Train net output #1: loss = 0.747056 (* 1 = 0.747056 loss)
I1120 18:36:06.921581  1516 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1120 18:36:16.737231  1516 solver.cpp:218] Iteration 97900 (10.1881 iter/s, 9.81539s/100 iters), loss = 0.723105
I1120 18:36:16.737231  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:36:16.737231  1516 solver.cpp:237]     Train net output #1: loss = 0.723105 (* 1 = 0.723105 loss)
I1120 18:36:16.737231  1516 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1120 18:36:26.074086 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:36:26.461117  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_98000.caffemodel
I1120 18:36:26.488612  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_98000.solverstate
I1120 18:36:26.500118  1516 solver.cpp:330] Iteration 98000, Testing net (#0)
I1120 18:36:26.500118  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:36:28.802255 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:36:28.895757  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7272
I1120 18:36:28.895757  1516 solver.cpp:397]     Test net output #1: loss = 1.03182 (* 1 = 1.03182 loss)
I1120 18:36:28.991264  1516 solver.cpp:218] Iteration 98000 (8.16115 iter/s, 12.2532s/100 iters), loss = 0.574461
I1120 18:36:28.991264  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:36:28.991264  1516 solver.cpp:237]     Train net output #1: loss = 0.574461 (* 1 = 0.574461 loss)
I1120 18:36:28.991264  1516 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1120 18:36:38.814340  1516 solver.cpp:218] Iteration 98100 (10.1807 iter/s, 9.82254s/100 iters), loss = 0.694286
I1120 18:36:38.814340  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:36:38.814340  1516 solver.cpp:237]     Train net output #1: loss = 0.694286 (* 1 = 0.694286 loss)
I1120 18:36:38.814340  1516 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1120 18:36:48.635185  1516 solver.cpp:218] Iteration 98200 (10.1824 iter/s, 9.82085s/100 iters), loss = 0.537669
I1120 18:36:48.635185  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:36:48.635185  1516 solver.cpp:237]     Train net output #1: loss = 0.537669 (* 1 = 0.537669 loss)
I1120 18:36:48.635185  1516 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1120 18:36:58.459091  1516 solver.cpp:218] Iteration 98300 (10.18 iter/s, 9.82317s/100 iters), loss = 0.756463
I1120 18:36:58.459091  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1120 18:36:58.459091  1516 solver.cpp:237]     Train net output #1: loss = 0.756463 (* 1 = 0.756463 loss)
I1120 18:36:58.459091  1516 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1120 18:37:08.277595  1516 solver.cpp:218] Iteration 98400 (10.1853 iter/s, 9.81811s/100 iters), loss = 0.616007
I1120 18:37:08.277595  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:37:08.277595  1516 solver.cpp:237]     Train net output #1: loss = 0.616007 (* 1 = 0.616007 loss)
I1120 18:37:08.277595  1516 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1120 18:37:17.616657 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:37:18.002676  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_98500.caffemodel
I1120 18:37:18.027680  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_98500.solverstate
I1120 18:37:18.039680  1516 solver.cpp:330] Iteration 98500, Testing net (#0)
I1120 18:37:18.039680  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:37:20.341845 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:37:20.434870  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7278
I1120 18:37:20.434870  1516 solver.cpp:397]     Test net output #1: loss = 1.03199 (* 1 = 1.03199 loss)
I1120 18:37:20.529872  1516 solver.cpp:218] Iteration 98500 (8.1625 iter/s, 12.2511s/100 iters), loss = 0.620736
I1120 18:37:20.529872  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:37:20.529872  1516 solver.cpp:237]     Train net output #1: loss = 0.620736 (* 1 = 0.620736 loss)
I1120 18:37:20.529872  1516 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1120 18:37:30.352813  1516 solver.cpp:218] Iteration 98600 (10.1805 iter/s, 9.82272s/100 iters), loss = 0.728907
I1120 18:37:30.352813  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:37:30.352813  1516 solver.cpp:237]     Train net output #1: loss = 0.728907 (* 1 = 0.728907 loss)
I1120 18:37:30.352813  1516 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1120 18:37:40.176595  1516 solver.cpp:218] Iteration 98700 (10.18 iter/s, 9.82319s/100 iters), loss = 0.6843
I1120 18:37:40.176595  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:37:40.176595  1516 solver.cpp:237]     Train net output #1: loss = 0.6843 (* 1 = 0.6843 loss)
I1120 18:37:40.176595  1516 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1120 18:37:50.002537  1516 solver.cpp:218] Iteration 98800 (10.1782 iter/s, 9.82492s/100 iters), loss = 0.767371
I1120 18:37:50.002537  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1120 18:37:50.002537  1516 solver.cpp:237]     Train net output #1: loss = 0.767371 (* 1 = 0.767371 loss)
I1120 18:37:50.002537  1516 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1120 18:37:59.829633  1516 solver.cpp:218] Iteration 98900 (10.1767 iter/s, 9.82641s/100 iters), loss = 0.689978
I1120 18:37:59.829633  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:37:59.829633  1516 solver.cpp:237]     Train net output #1: loss = 0.689978 (* 1 = 0.689978 loss)
I1120 18:37:59.829633  1516 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1120 18:38:09.167317 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:38:09.557373  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_99000.caffemodel
I1120 18:38:09.583384  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_99000.solverstate
I1120 18:38:09.595407  1516 solver.cpp:330] Iteration 99000, Testing net (#0)
I1120 18:38:09.595407  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:38:11.898056 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:38:11.989558  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7308
I1120 18:38:11.989558  1516 solver.cpp:397]     Test net output #1: loss = 1.02623 (* 1 = 1.02623 loss)
I1120 18:38:12.084568  1516 solver.cpp:218] Iteration 99000 (8.15989 iter/s, 12.2551s/100 iters), loss = 0.616229
I1120 18:38:12.084568  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:38:12.084568  1516 solver.cpp:237]     Train net output #1: loss = 0.616229 (* 1 = 0.616229 loss)
I1120 18:38:12.084568  1516 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1120 18:38:21.912402  1516 solver.cpp:218] Iteration 99100 (10.1758 iter/s, 9.82721s/100 iters), loss = 0.720633
I1120 18:38:21.912402  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:38:21.912402  1516 solver.cpp:237]     Train net output #1: loss = 0.720633 (* 1 = 0.720633 loss)
I1120 18:38:21.912402  1516 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1120 18:38:31.736279  1516 solver.cpp:218] Iteration 99200 (10.1805 iter/s, 9.82271s/100 iters), loss = 0.615624
I1120 18:38:31.736279  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:38:31.736279  1516 solver.cpp:237]     Train net output #1: loss = 0.615624 (* 1 = 0.615624 loss)
I1120 18:38:31.736279  1516 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1120 18:38:41.560860  1516 solver.cpp:218] Iteration 99300 (10.179 iter/s, 9.82419s/100 iters), loss = 0.743429
I1120 18:38:41.560860  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 18:38:41.560860  1516 solver.cpp:237]     Train net output #1: loss = 0.743429 (* 1 = 0.743429 loss)
I1120 18:38:41.560860  1516 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1120 18:38:51.383823  1516 solver.cpp:218] Iteration 99400 (10.1811 iter/s, 9.82212s/100 iters), loss = 0.744237
I1120 18:38:51.383823  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:38:51.383823  1516 solver.cpp:237]     Train net output #1: loss = 0.744237 (* 1 = 0.744237 loss)
I1120 18:38:51.383823  1516 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1120 18:39:00.722663 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:39:01.110193  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_99500.caffemodel
I1120 18:39:01.137697  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_99500.solverstate
I1120 18:39:01.149698  1516 solver.cpp:330] Iteration 99500, Testing net (#0)
I1120 18:39:01.149698  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:39:03.451817 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:39:03.544822  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7289
I1120 18:39:03.544822  1516 solver.cpp:397]     Test net output #1: loss = 1.03363 (* 1 = 1.03363 loss)
I1120 18:39:03.639827  1516 solver.cpp:218] Iteration 99500 (8.15953 iter/s, 12.2556s/100 iters), loss = 0.518552
I1120 18:39:03.639827  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:39:03.639827  1516 solver.cpp:237]     Train net output #1: loss = 0.518552 (* 1 = 0.518552 loss)
I1120 18:39:03.639827  1516 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1120 18:39:13.457670  1516 solver.cpp:218] Iteration 99600 (10.1856 iter/s, 9.81774s/100 iters), loss = 0.648645
I1120 18:39:13.457670  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:39:13.457670  1516 solver.cpp:237]     Train net output #1: loss = 0.648645 (* 1 = 0.648645 loss)
I1120 18:39:13.457670  1516 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1120 18:39:23.314576  1516 solver.cpp:218] Iteration 99700 (10.1463 iter/s, 9.85585s/100 iters), loss = 0.617166
I1120 18:39:23.314576  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:39:23.314576  1516 solver.cpp:237]     Train net output #1: loss = 0.617166 (* 1 = 0.617166 loss)
I1120 18:39:23.314576  1516 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1120 18:39:33.274780  1516 solver.cpp:218] Iteration 99800 (10.0409 iter/s, 9.95922s/100 iters), loss = 0.716086
I1120 18:39:33.274780  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 18:39:33.274780  1516 solver.cpp:237]     Train net output #1: loss = 0.716086 (* 1 = 0.716086 loss)
I1120 18:39:33.274780  1516 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1120 18:39:43.260269  1516 solver.cpp:218] Iteration 99900 (10.0152 iter/s, 9.98482s/100 iters), loss = 0.83448
I1120 18:39:43.260269  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1120 18:39:43.260269  1516 solver.cpp:237]     Train net output #1: loss = 0.83448 (* 1 = 0.83448 loss)
I1120 18:39:43.260269  1516 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1120 18:39:52.703773 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:39:53.100795  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_100000.caffemodel
I1120 18:39:53.128795  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_100000.solverstate
I1120 18:39:53.140795  1516 solver.cpp:330] Iteration 100000, Testing net (#0)
I1120 18:39:53.140795  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:39:55.456974 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:39:55.549980  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7306
I1120 18:39:55.549980  1516 solver.cpp:397]     Test net output #1: loss = 1.03454 (* 1 = 1.03454 loss)
I1120 18:39:55.644991  1516 solver.cpp:218] Iteration 100000 (8.07481 iter/s, 12.3842s/100 iters), loss = 0.548116
I1120 18:39:55.644991  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:39:55.644991  1516 solver.cpp:237]     Train net output #1: loss = 0.548116 (* 1 = 0.548116 loss)
I1120 18:39:55.644991  1516 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1120 18:40:05.510972  1516 solver.cpp:218] Iteration 100100 (10.1365 iter/s, 9.86532s/100 iters), loss = 0.643
I1120 18:40:05.510972  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:40:05.510972  1516 solver.cpp:237]     Train net output #1: loss = 0.643 (* 1 = 0.643 loss)
I1120 18:40:05.510972  1516 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1120 18:40:15.347841  1516 solver.cpp:218] Iteration 100200 (10.1668 iter/s, 9.83593s/100 iters), loss = 0.624653
I1120 18:40:15.347841  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 18:40:15.347841  1516 solver.cpp:237]     Train net output #1: loss = 0.624653 (* 1 = 0.624653 loss)
I1120 18:40:15.347841  1516 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1120 18:40:25.104710  1516 solver.cpp:218] Iteration 100300 (10.2498 iter/s, 9.75627s/100 iters), loss = 0.74559
I1120 18:40:25.104710  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:40:25.104710  1516 solver.cpp:237]     Train net output #1: loss = 0.74559 (* 1 = 0.74559 loss)
I1120 18:40:25.104710  1516 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1120 18:40:34.859645  1516 solver.cpp:218] Iteration 100400 (10.2511 iter/s, 9.75504s/100 iters), loss = 0.699084
I1120 18:40:34.859645  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:40:34.859645  1516 solver.cpp:237]     Train net output #1: loss = 0.699084 (* 1 = 0.699084 loss)
I1120 18:40:34.860646  1516 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1120 18:40:44.152360 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:40:44.542392  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_100500.caffemodel
I1120 18:40:44.569396  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_100500.solverstate
I1120 18:40:44.581396  1516 solver.cpp:330] Iteration 100500, Testing net (#0)
I1120 18:40:44.582396  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:40:46.856853 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:40:46.948357  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7331
I1120 18:40:46.948357  1516 solver.cpp:397]     Test net output #1: loss = 1.03828 (* 1 = 1.03828 loss)
I1120 18:40:47.042376  1516 solver.cpp:218] Iteration 100500 (8.20932 iter/s, 12.1813s/100 iters), loss = 0.551464
I1120 18:40:47.042376  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:40:47.042376  1516 solver.cpp:237]     Train net output #1: loss = 0.551464 (* 1 = 0.551464 loss)
I1120 18:40:47.042376  1516 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1120 18:40:56.867763  1516 solver.cpp:218] Iteration 100600 (10.1783 iter/s, 9.82484s/100 iters), loss = 0.744245
I1120 18:40:56.867763  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:40:56.867763  1516 solver.cpp:237]     Train net output #1: loss = 0.744245 (* 1 = 0.744245 loss)
I1120 18:40:56.867763  1516 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1120 18:41:06.836063  1516 solver.cpp:218] Iteration 100700 (10.0325 iter/s, 9.96762s/100 iters), loss = 0.703649
I1120 18:41:06.836063  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1120 18:41:06.836063  1516 solver.cpp:237]     Train net output #1: loss = 0.703649 (* 1 = 0.703649 loss)
I1120 18:41:06.836063  1516 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1120 18:41:16.811528  1516 solver.cpp:218] Iteration 100800 (10.0247 iter/s, 9.97539s/100 iters), loss = 0.719326
I1120 18:41:16.811528  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1120 18:41:16.811528  1516 solver.cpp:237]     Train net output #1: loss = 0.719326 (* 1 = 0.719326 loss)
I1120 18:41:16.811528  1516 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1120 18:41:26.925340  1516 solver.cpp:218] Iteration 100900 (9.88847 iter/s, 10.1128s/100 iters), loss = 0.787991
I1120 18:41:26.925340  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1120 18:41:26.925340  1516 solver.cpp:237]     Train net output #1: loss = 0.787991 (* 1 = 0.787991 loss)
I1120 18:41:26.925340  1516 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1120 18:41:36.594548 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:41:37.000062  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_101000.caffemodel
I1120 18:41:37.029564  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_101000.solverstate
I1120 18:41:37.042560  1516 solver.cpp:330] Iteration 101000, Testing net (#0)
I1120 18:41:37.042560  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:41:39.407615 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:41:39.501600  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7332
I1120 18:41:39.502100  1516 solver.cpp:397]     Test net output #1: loss = 1.0332 (* 1 = 1.0332 loss)
I1120 18:41:39.601102  1516 solver.cpp:218] Iteration 101000 (7.88958 iter/s, 12.6749s/100 iters), loss = 0.518828
I1120 18:41:39.601102  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:41:39.601102  1516 solver.cpp:237]     Train net output #1: loss = 0.518828 (* 1 = 0.518828 loss)
I1120 18:41:39.601102  1516 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1120 18:41:49.768132  1516 solver.cpp:218] Iteration 101100 (9.83644 iter/s, 10.1663s/100 iters), loss = 0.525041
I1120 18:41:49.768132  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:41:49.768132  1516 solver.cpp:237]     Train net output #1: loss = 0.525041 (* 1 = 0.525041 loss)
I1120 18:41:49.768132  1516 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1120 18:41:59.923848  1516 solver.cpp:218] Iteration 101200 (9.84703 iter/s, 10.1553s/100 iters), loss = 0.61336
I1120 18:41:59.923848  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:41:59.923848  1516 solver.cpp:237]     Train net output #1: loss = 0.61336 (* 1 = 0.61336 loss)
I1120 18:41:59.923848  1516 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1120 18:42:09.891278  1516 solver.cpp:218] Iteration 101300 (10.0333 iter/s, 9.96677s/100 iters), loss = 0.658046
I1120 18:42:09.891278  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:42:09.891278  1516 solver.cpp:237]     Train net output #1: loss = 0.658046 (* 1 = 0.658046 loss)
I1120 18:42:09.891278  1516 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1120 18:42:19.818342  1516 solver.cpp:218] Iteration 101400 (10.0741 iter/s, 9.92642s/100 iters), loss = 0.65119
I1120 18:42:19.818342  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:42:19.818342  1516 solver.cpp:237]     Train net output #1: loss = 0.65119 (* 1 = 0.65119 loss)
I1120 18:42:19.818342  1516 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1120 18:42:29.269029 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:42:29.661038  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_101500.caffemodel
I1120 18:42:29.687530  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_101500.solverstate
I1120 18:42:29.699529  1516 solver.cpp:330] Iteration 101500, Testing net (#0)
I1120 18:42:29.699529  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:42:32.021045 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:42:32.114047  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7304
I1120 18:42:32.114047  1516 solver.cpp:397]     Test net output #1: loss = 1.0384 (* 1 = 1.0384 loss)
I1120 18:42:32.210546  1516 solver.cpp:218] Iteration 101500 (8.06993 iter/s, 12.3917s/100 iters), loss = 0.51156
I1120 18:42:32.211045  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:42:32.211045  1516 solver.cpp:237]     Train net output #1: loss = 0.51156 (* 1 = 0.51156 loss)
I1120 18:42:32.211045  1516 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1120 18:42:42.148756  1516 solver.cpp:218] Iteration 101600 (10.0629 iter/s, 9.93751s/100 iters), loss = 0.705169
I1120 18:42:42.149253  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 18:42:42.149253  1516 solver.cpp:237]     Train net output #1: loss = 0.705169 (* 1 = 0.705169 loss)
I1120 18:42:42.149253  1516 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1120 18:42:52.127480  1516 solver.cpp:218] Iteration 101700 (10.0223 iter/s, 9.97779s/100 iters), loss = 0.5218
I1120 18:42:52.127480  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:42:52.127480  1516 solver.cpp:237]     Train net output #1: loss = 0.5218 (* 1 = 0.5218 loss)
I1120 18:42:52.127480  1516 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1120 18:43:02.284574  1516 solver.cpp:218] Iteration 101800 (9.84584 iter/s, 10.1566s/100 iters), loss = 0.627777
I1120 18:43:02.284574  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:43:02.284574  1516 solver.cpp:237]     Train net output #1: loss = 0.627777 (* 1 = 0.627777 loss)
I1120 18:43:02.284574  1516 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1120 18:43:12.442874  1516 solver.cpp:218] Iteration 101900 (9.84491 iter/s, 10.1575s/100 iters), loss = 0.663016
I1120 18:43:12.442874  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:43:12.442874  1516 solver.cpp:237]     Train net output #1: loss = 0.663016 (* 1 = 0.663016 loss)
I1120 18:43:12.442874  1516 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1120 18:43:22.084695 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:43:22.490186  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_102000.caffemodel
I1120 18:43:22.523185  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_102000.solverstate
I1120 18:43:22.538180  1516 solver.cpp:330] Iteration 102000, Testing net (#0)
I1120 18:43:22.538180  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:43:24.895184 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:43:24.989684  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7317
I1120 18:43:24.990188  1516 solver.cpp:397]     Test net output #1: loss = 1.03588 (* 1 = 1.03588 loss)
I1120 18:43:25.088182  1516 solver.cpp:218] Iteration 102000 (7.90849 iter/s, 12.6446s/100 iters), loss = 0.52063
I1120 18:43:25.088182  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:43:25.088182  1516 solver.cpp:237]     Train net output #1: loss = 0.52063 (* 1 = 0.52063 loss)
I1120 18:43:25.088182  1516 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1120 18:43:35.245383  1516 solver.cpp:218] Iteration 102100 (9.84612 iter/s, 10.1563s/100 iters), loss = 0.779034
I1120 18:43:35.245383  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1120 18:43:35.245383  1516 solver.cpp:237]     Train net output #1: loss = 0.779034 (* 1 = 0.779034 loss)
I1120 18:43:35.245383  1516 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1120 18:43:45.402935  1516 solver.cpp:218] Iteration 102200 (9.84571 iter/s, 10.1567s/100 iters), loss = 0.469694
I1120 18:43:45.402935  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:43:45.402935  1516 solver.cpp:237]     Train net output #1: loss = 0.469694 (* 1 = 0.469694 loss)
I1120 18:43:45.402935  1516 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1120 18:43:55.558197  1516 solver.cpp:218] Iteration 102300 (9.84754 iter/s, 10.1548s/100 iters), loss = 0.586612
I1120 18:43:55.558197  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:43:55.558197  1516 solver.cpp:237]     Train net output #1: loss = 0.586612 (* 1 = 0.586612 loss)
I1120 18:43:55.558197  1516 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1120 18:44:05.713168  1516 solver.cpp:218] Iteration 102400 (9.84803 iter/s, 10.1543s/100 iters), loss = 0.649524
I1120 18:44:05.713168  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:44:05.713168  1516 solver.cpp:237]     Train net output #1: loss = 0.649524 (* 1 = 0.649524 loss)
I1120 18:44:05.713168  1516 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1120 18:44:15.362655 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:44:15.764600  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_102500.caffemodel
I1120 18:44:15.791101  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_102500.solverstate
I1120 18:44:15.803100  1516 solver.cpp:330] Iteration 102500, Testing net (#0)
I1120 18:44:15.803100  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:44:18.156707 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:44:18.251209  1516 solver.cpp:397]     Test net output #0: accuracy = 0.73
I1120 18:44:18.251708  1516 solver.cpp:397]     Test net output #1: loss = 1.04259 (* 1 = 1.04259 loss)
I1120 18:44:18.351222  1516 solver.cpp:218] Iteration 102500 (7.91322 iter/s, 12.6371s/100 iters), loss = 0.595181
I1120 18:44:18.351222  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:44:18.351222  1516 solver.cpp:237]     Train net output #1: loss = 0.595181 (* 1 = 0.595181 loss)
I1120 18:44:18.351222  1516 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1120 18:44:28.491873  1516 solver.cpp:218] Iteration 102600 (9.86168 iter/s, 10.1403s/100 iters), loss = 0.668219
I1120 18:44:28.491873  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:44:28.491873  1516 solver.cpp:237]     Train net output #1: loss = 0.668219 (* 1 = 0.668219 loss)
I1120 18:44:28.491873  1516 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1120 18:44:38.631388  1516 solver.cpp:218] Iteration 102700 (9.86288 iter/s, 10.139s/100 iters), loss = 0.610858
I1120 18:44:38.631889  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:44:38.631889  1516 solver.cpp:237]     Train net output #1: loss = 0.610858 (* 1 = 0.610858 loss)
I1120 18:44:38.631889  1516 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1120 18:44:48.768857  1516 solver.cpp:218] Iteration 102800 (9.86517 iter/s, 10.1367s/100 iters), loss = 0.560394
I1120 18:44:48.768857  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 18:44:48.769356  1516 solver.cpp:237]     Train net output #1: loss = 0.560394 (* 1 = 0.560394 loss)
I1120 18:44:48.769356  1516 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1120 18:44:58.918948  1516 solver.cpp:218] Iteration 102900 (9.85273 iter/s, 10.1495s/100 iters), loss = 0.691767
I1120 18:44:58.919447  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:44:58.919447  1516 solver.cpp:237]     Train net output #1: loss = 0.691767 (* 1 = 0.691767 loss)
I1120 18:44:58.919447  1516 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1120 18:45:08.563807 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:45:08.964809  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_103000.caffemodel
I1120 18:45:08.991808  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_103000.solverstate
I1120 18:45:09.003808  1516 solver.cpp:330] Iteration 103000, Testing net (#0)
I1120 18:45:09.003808  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:45:11.361845 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:45:11.456843  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7317
I1120 18:45:11.456843  1516 solver.cpp:397]     Test net output #1: loss = 1.04032 (* 1 = 1.04032 loss)
I1120 18:45:11.554858  1516 solver.cpp:218] Iteration 103000 (7.91441 iter/s, 12.6352s/100 iters), loss = 0.633367
I1120 18:45:11.554858  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:45:11.554858  1516 solver.cpp:237]     Train net output #1: loss = 0.633367 (* 1 = 0.633367 loss)
I1120 18:45:11.554858  1516 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1120 18:45:21.697384  1516 solver.cpp:218] Iteration 103100 (9.86002 iter/s, 10.142s/100 iters), loss = 0.610893
I1120 18:45:21.697384  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:45:21.697384  1516 solver.cpp:237]     Train net output #1: loss = 0.610893 (* 1 = 0.610893 loss)
I1120 18:45:21.697384  1516 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1120 18:45:31.837401  1516 solver.cpp:218] Iteration 103200 (9.8625 iter/s, 10.1394s/100 iters), loss = 0.552278
I1120 18:45:31.837901  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:45:31.837901  1516 solver.cpp:237]     Train net output #1: loss = 0.552278 (* 1 = 0.552278 loss)
I1120 18:45:31.837901  1516 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1120 18:45:41.988225  1516 solver.cpp:218] Iteration 103300 (9.85249 iter/s, 10.1497s/100 iters), loss = 0.650314
I1120 18:45:41.988225  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:45:41.988225  1516 solver.cpp:237]     Train net output #1: loss = 0.650314 (* 1 = 0.650314 loss)
I1120 18:45:41.988225  1516 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1120 18:45:52.140019  1516 solver.cpp:218] Iteration 103400 (9.85141 iter/s, 10.1508s/100 iters), loss = 0.705799
I1120 18:45:52.140019  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:45:52.140019  1516 solver.cpp:237]     Train net output #1: loss = 0.705799 (* 1 = 0.705799 loss)
I1120 18:45:52.140019  1516 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1120 18:46:01.794587 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:46:02.195087  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_103500.caffemodel
I1120 18:46:02.223587  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_103500.solverstate
I1120 18:46:02.236587  1516 solver.cpp:330] Iteration 103500, Testing net (#0)
I1120 18:46:02.236587  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:46:04.588587 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:46:04.682587  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7323
I1120 18:46:04.682587  1516 solver.cpp:397]     Test net output #1: loss = 1.03792 (* 1 = 1.03792 loss)
I1120 18:46:04.780586  1516 solver.cpp:218] Iteration 103500 (7.9113 iter/s, 12.6401s/100 iters), loss = 0.540078
I1120 18:46:04.781087  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:46:04.781087  1516 solver.cpp:237]     Train net output #1: loss = 0.540078 (* 1 = 0.540078 loss)
I1120 18:46:04.781087  1516 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1120 18:46:14.932477  1516 solver.cpp:218] Iteration 103600 (9.85132 iter/s, 10.1509s/100 iters), loss = 0.579856
I1120 18:46:14.932477  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:46:14.932477  1516 solver.cpp:237]     Train net output #1: loss = 0.579856 (* 1 = 0.579856 loss)
I1120 18:46:14.932477  1516 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1120 18:46:25.087093  1516 solver.cpp:218] Iteration 103700 (9.84866 iter/s, 10.1537s/100 iters), loss = 0.517286
I1120 18:46:25.087093  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:46:25.087093  1516 solver.cpp:237]     Train net output #1: loss = 0.517286 (* 1 = 0.517286 loss)
I1120 18:46:25.087093  1516 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1120 18:46:35.259254  1516 solver.cpp:218] Iteration 103800 (9.8311 iter/s, 10.1718s/100 iters), loss = 0.700993
I1120 18:46:35.259254  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:46:35.259254  1516 solver.cpp:237]     Train net output #1: loss = 0.700993 (* 1 = 0.700993 loss)
I1120 18:46:35.259254  1516 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1120 18:46:45.417765  1516 solver.cpp:218] Iteration 103900 (9.84472 iter/s, 10.1577s/100 iters), loss = 0.791121
I1120 18:46:45.417765  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1120 18:46:45.417765  1516 solver.cpp:237]     Train net output #1: loss = 0.791121 (* 1 = 0.791121 loss)
I1120 18:46:45.417765  1516 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1120 18:46:55.091861 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:46:55.491360  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_104000.caffemodel
I1120 18:46:55.519361  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_104000.solverstate
I1120 18:46:55.531361  1516 solver.cpp:330] Iteration 104000, Testing net (#0)
I1120 18:46:55.531361  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:46:57.881361 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:46:57.975370  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7312
I1120 18:46:57.975862  1516 solver.cpp:397]     Test net output #1: loss = 1.04643 (* 1 = 1.04643 loss)
I1120 18:46:58.073860  1516 solver.cpp:218] Iteration 104000 (7.9019 iter/s, 12.6552s/100 iters), loss = 0.443007
I1120 18:46:58.073860  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 18:46:58.073860  1516 solver.cpp:237]     Train net output #1: loss = 0.443007 (* 1 = 0.443007 loss)
I1120 18:46:58.073860  1516 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1120 18:47:08.218708  1516 solver.cpp:218] Iteration 104100 (9.85776 iter/s, 10.1443s/100 iters), loss = 0.727891
I1120 18:47:08.218708  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1120 18:47:08.218708  1516 solver.cpp:237]     Train net output #1: loss = 0.727891 (* 1 = 0.727891 loss)
I1120 18:47:08.218708  1516 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1120 18:47:18.367923  1516 solver.cpp:218] Iteration 104200 (9.85371 iter/s, 10.1485s/100 iters), loss = 0.502248
I1120 18:47:18.367923  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:47:18.367923  1516 solver.cpp:237]     Train net output #1: loss = 0.502248 (* 1 = 0.502248 loss)
I1120 18:47:18.367923  1516 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1120 18:47:28.517865  1516 solver.cpp:218] Iteration 104300 (9.85298 iter/s, 10.1492s/100 iters), loss = 0.598074
I1120 18:47:28.517865  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:47:28.518365  1516 solver.cpp:237]     Train net output #1: loss = 0.598074 (* 1 = 0.598074 loss)
I1120 18:47:28.518365  1516 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1120 18:47:38.669636  1516 solver.cpp:218] Iteration 104400 (9.85163 iter/s, 10.1506s/100 iters), loss = 0.51153
I1120 18:47:38.669636  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:47:38.669636  1516 solver.cpp:237]     Train net output #1: loss = 0.51153 (* 1 = 0.51153 loss)
I1120 18:47:38.669636  1516 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1120 18:47:48.316048 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:47:48.716045  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_104500.caffemodel
I1120 18:47:48.750545  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_104500.solverstate
I1120 18:47:48.762544  1516 solver.cpp:330] Iteration 104500, Testing net (#0)
I1120 18:47:48.763046  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:47:51.113584 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:47:51.208094  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7303
I1120 18:47:51.208094  1516 solver.cpp:397]     Test net output #1: loss = 1.04415 (* 1 = 1.04415 loss)
I1120 18:47:51.306661  1516 solver.cpp:218] Iteration 104500 (7.91356 iter/s, 12.6365s/100 iters), loss = 0.536678
I1120 18:47:51.306661  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:47:51.306661  1516 solver.cpp:237]     Train net output #1: loss = 0.536678 (* 1 = 0.536678 loss)
I1120 18:47:51.306661  1516 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1120 18:48:01.451733  1516 solver.cpp:218] Iteration 104600 (9.85782 iter/s, 10.1442s/100 iters), loss = 0.681587
I1120 18:48:01.451733  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:48:01.451733  1516 solver.cpp:237]     Train net output #1: loss = 0.681587 (* 1 = 0.681587 loss)
I1120 18:48:01.451733  1516 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1120 18:48:11.594488  1516 solver.cpp:218] Iteration 104700 (9.85969 iter/s, 10.1423s/100 iters), loss = 0.478062
I1120 18:48:11.594488  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:48:11.594488  1516 solver.cpp:237]     Train net output #1: loss = 0.478062 (* 1 = 0.478062 loss)
I1120 18:48:11.594488  1516 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1120 18:48:21.749438  1516 solver.cpp:218] Iteration 104800 (9.84828 iter/s, 10.1541s/100 iters), loss = 0.654065
I1120 18:48:21.749438  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:48:21.749438  1516 solver.cpp:237]     Train net output #1: loss = 0.654065 (* 1 = 0.654065 loss)
I1120 18:48:21.749438  1516 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1120 18:48:31.892966  1516 solver.cpp:218] Iteration 104900 (9.85905 iter/s, 10.143s/100 iters), loss = 0.579863
I1120 18:48:31.892966  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:48:31.892966  1516 solver.cpp:237]     Train net output #1: loss = 0.579863 (* 1 = 0.579863 loss)
I1120 18:48:31.892966  1516 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1120 18:48:41.549566 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:48:41.950065  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_105000.caffemodel
I1120 18:48:41.978067  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_105000.solverstate
I1120 18:48:41.990566  1516 solver.cpp:330] Iteration 105000, Testing net (#0)
I1120 18:48:41.990566  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:48:44.343065 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:48:44.436575  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7321
I1120 18:48:44.436575  1516 solver.cpp:397]     Test net output #1: loss = 1.03939 (* 1 = 1.03939 loss)
I1120 18:48:44.535567  1516 solver.cpp:218] Iteration 105000 (7.91019 iter/s, 12.6419s/100 iters), loss = 0.570409
I1120 18:48:44.535567  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:48:44.535567  1516 solver.cpp:237]     Train net output #1: loss = 0.570409 (* 1 = 0.570409 loss)
I1120 18:48:44.535567  1516 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1120 18:48:54.686223  1516 solver.cpp:218] Iteration 105100 (9.85213 iter/s, 10.1501s/100 iters), loss = 0.61763
I1120 18:48:54.686223  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:48:54.686223  1516 solver.cpp:237]     Train net output #1: loss = 0.61763 (* 1 = 0.61763 loss)
I1120 18:48:54.686223  1516 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1120 18:49:04.736421  1516 solver.cpp:218] Iteration 105200 (9.95066 iter/s, 10.0496s/100 iters), loss = 0.579299
I1120 18:49:04.736421  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:49:04.736421  1516 solver.cpp:237]     Train net output #1: loss = 0.579299 (* 1 = 0.579299 loss)
I1120 18:49:04.736421  1516 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1120 18:49:14.769454  1516 solver.cpp:218] Iteration 105300 (9.9679 iter/s, 10.0322s/100 iters), loss = 0.512498
I1120 18:49:14.769454  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:49:14.769454  1516 solver.cpp:237]     Train net output #1: loss = 0.512498 (* 1 = 0.512498 loss)
I1120 18:49:14.769454  1516 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1120 18:49:24.824522  1516 solver.cpp:218] Iteration 105400 (9.94578 iter/s, 10.0545s/100 iters), loss = 0.548862
I1120 18:49:24.825023  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:49:24.825023  1516 solver.cpp:237]     Train net output #1: loss = 0.548862 (* 1 = 0.548862 loss)
I1120 18:49:24.825023  1516 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1120 18:49:34.353351 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:49:34.751852  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_105500.caffemodel
I1120 18:49:34.780351  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_105500.solverstate
I1120 18:49:34.793350  1516 solver.cpp:330] Iteration 105500, Testing net (#0)
I1120 18:49:34.793350  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:49:37.125872 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:49:37.219372  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7324
I1120 18:49:37.219372  1516 solver.cpp:397]     Test net output #1: loss = 1.04042 (* 1 = 1.04042 loss)
I1120 18:49:37.317378  1516 solver.cpp:218] Iteration 105500 (8.00515 iter/s, 12.492s/100 iters), loss = 0.489039
I1120 18:49:37.317378  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:49:37.317378  1516 solver.cpp:237]     Train net output #1: loss = 0.489039 (* 1 = 0.489039 loss)
I1120 18:49:37.317378  1516 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1120 18:49:47.356389  1516 solver.cpp:218] Iteration 105600 (9.96155 iter/s, 10.0386s/100 iters), loss = 0.553236
I1120 18:49:47.356889  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:49:47.356889  1516 solver.cpp:237]     Train net output #1: loss = 0.553236 (* 1 = 0.553236 loss)
I1120 18:49:47.356889  1516 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1120 18:49:57.438745  1516 solver.cpp:218] Iteration 105700 (9.91925 iter/s, 10.0814s/100 iters), loss = 0.43674
I1120 18:49:57.438745  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:49:57.438745  1516 solver.cpp:237]     Train net output #1: loss = 0.43674 (* 1 = 0.43674 loss)
I1120 18:49:57.438745  1516 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1120 18:50:07.512046  1516 solver.cpp:218] Iteration 105800 (9.92806 iter/s, 10.0725s/100 iters), loss = 0.603057
I1120 18:50:07.512046  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:50:07.512046  1516 solver.cpp:237]     Train net output #1: loss = 0.603057 (* 1 = 0.603057 loss)
I1120 18:50:07.512046  1516 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1120 18:50:17.517383  1516 solver.cpp:218] Iteration 105900 (9.99529 iter/s, 10.0047s/100 iters), loss = 0.585433
I1120 18:50:17.517383  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:50:17.517383  1516 solver.cpp:237]     Train net output #1: loss = 0.585433 (* 1 = 0.585433 loss)
I1120 18:50:17.517383  1516 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1120 18:50:26.968005 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:50:27.359489  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_106000.caffemodel
I1120 18:50:27.384989  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_106000.solverstate
I1120 18:50:27.396497  1516 solver.cpp:330] Iteration 106000, Testing net (#0)
I1120 18:50:27.396497  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:50:29.706102 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:50:29.798588  1516 solver.cpp:397]     Test net output #0: accuracy = 0.731
I1120 18:50:29.798588  1516 solver.cpp:397]     Test net output #1: loss = 1.04847 (* 1 = 1.04847 loss)
I1120 18:50:29.895597  1516 solver.cpp:218] Iteration 106000 (8.07903 iter/s, 12.3777s/100 iters), loss = 0.506501
I1120 18:50:29.895597  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:50:29.895597  1516 solver.cpp:237]     Train net output #1: loss = 0.506501 (* 1 = 0.506501 loss)
I1120 18:50:29.895597  1516 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1120 18:50:39.828075  1516 solver.cpp:218] Iteration 106100 (10.069 iter/s, 9.93151s/100 iters), loss = 0.565015
I1120 18:50:39.828075  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:50:39.828075  1516 solver.cpp:237]     Train net output #1: loss = 0.565015 (* 1 = 0.565015 loss)
I1120 18:50:39.828075  1516 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1120 18:50:49.762075  1516 solver.cpp:218] Iteration 106200 (10.0669 iter/s, 9.93353s/100 iters), loss = 0.477769
I1120 18:50:49.762075  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 18:50:49.762075  1516 solver.cpp:237]     Train net output #1: loss = 0.477769 (* 1 = 0.477769 loss)
I1120 18:50:49.762075  1516 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1120 18:50:59.693203  1516 solver.cpp:218] Iteration 106300 (10.0696 iter/s, 9.93087s/100 iters), loss = 0.719954
I1120 18:50:59.693203  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:50:59.693203  1516 solver.cpp:237]     Train net output #1: loss = 0.719954 (* 1 = 0.719954 loss)
I1120 18:50:59.693691  1516 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1120 18:51:09.716868  1516 solver.cpp:218] Iteration 106400 (9.97728 iter/s, 10.0228s/100 iters), loss = 0.711118
I1120 18:51:09.716868  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:51:09.716868  1516 solver.cpp:237]     Train net output #1: loss = 0.711118 (* 1 = 0.711118 loss)
I1120 18:51:09.716868  1516 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1120 18:51:19.279970 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:51:19.676970  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_106500.caffemodel
I1120 18:51:19.709470  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_106500.solverstate
I1120 18:51:19.764968  1516 solver.cpp:330] Iteration 106500, Testing net (#0)
I1120 18:51:19.764968  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:51:22.094534 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:51:22.188020  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7334
I1120 18:51:22.188020  1516 solver.cpp:397]     Test net output #1: loss = 1.04708 (* 1 = 1.04708 loss)
I1120 18:51:22.286530  1516 solver.cpp:218] Iteration 106500 (7.95612 iter/s, 12.5689s/100 iters), loss = 0.538467
I1120 18:51:22.286530  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:51:22.286530  1516 solver.cpp:237]     Train net output #1: loss = 0.538467 (* 1 = 0.538467 loss)
I1120 18:51:22.286530  1516 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1120 18:51:32.336882  1516 solver.cpp:218] Iteration 106600 (9.95048 iter/s, 10.0498s/100 iters), loss = 0.692628
I1120 18:51:32.336882  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:51:32.336882  1516 solver.cpp:237]     Train net output #1: loss = 0.692628 (* 1 = 0.692628 loss)
I1120 18:51:32.336882  1516 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1120 18:51:42.401880  1516 solver.cpp:218] Iteration 106700 (9.93598 iter/s, 10.0644s/100 iters), loss = 0.434832
I1120 18:51:42.401880  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 18:51:42.401880  1516 solver.cpp:237]     Train net output #1: loss = 0.434832 (* 1 = 0.434832 loss)
I1120 18:51:42.401880  1516 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1120 18:51:52.419853  1516 solver.cpp:218] Iteration 106800 (9.98258 iter/s, 10.0175s/100 iters), loss = 0.536064
I1120 18:51:52.419853  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:51:52.419853  1516 solver.cpp:237]     Train net output #1: loss = 0.536064 (* 1 = 0.536064 loss)
I1120 18:51:52.419853  1516 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1120 18:52:02.438540  1516 solver.cpp:218] Iteration 106900 (9.98198 iter/s, 10.0181s/100 iters), loss = 0.63236
I1120 18:52:02.438540  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:52:02.438540  1516 solver.cpp:237]     Train net output #1: loss = 0.63236 (* 1 = 0.63236 loss)
I1120 18:52:02.438540  1516 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1120 18:52:11.954082 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:52:12.348570  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_107000.caffemodel
I1120 18:52:12.374071  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_107000.solverstate
I1120 18:52:12.386071  1516 solver.cpp:330] Iteration 107000, Testing net (#0)
I1120 18:52:12.386579  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:52:14.720082 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:52:14.814070  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7303
I1120 18:52:14.814070  1516 solver.cpp:397]     Test net output #1: loss = 1.04865 (* 1 = 1.04865 loss)
I1120 18:52:14.911586  1516 solver.cpp:218] Iteration 107000 (8.01762 iter/s, 12.4725s/100 iters), loss = 0.549554
I1120 18:52:14.911586  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:52:14.911586  1516 solver.cpp:237]     Train net output #1: loss = 0.549554 (* 1 = 0.549554 loss)
I1120 18:52:14.911586  1516 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1120 18:52:24.976516  1516 solver.cpp:218] Iteration 107100 (9.93626 iter/s, 10.0641s/100 iters), loss = 0.648453
I1120 18:52:24.976516  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:52:24.976516  1516 solver.cpp:237]     Train net output #1: loss = 0.648453 (* 1 = 0.648453 loss)
I1120 18:52:24.976516  1516 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1120 18:52:35.009258  1516 solver.cpp:218] Iteration 107200 (9.96806 iter/s, 10.032s/100 iters), loss = 0.531842
I1120 18:52:35.009258  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:52:35.009258  1516 solver.cpp:237]     Train net output #1: loss = 0.531842 (* 1 = 0.531842 loss)
I1120 18:52:35.009258  1516 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1120 18:52:44.972120  1516 solver.cpp:218] Iteration 107300 (10.0379 iter/s, 9.96227s/100 iters), loss = 0.656554
I1120 18:52:44.972120  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:52:44.972120  1516 solver.cpp:237]     Train net output #1: loss = 0.656554 (* 1 = 0.656554 loss)
I1120 18:52:44.972120  1516 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1120 18:52:54.801870  1516 solver.cpp:218] Iteration 107400 (10.1736 iter/s, 9.8294s/100 iters), loss = 0.699933
I1120 18:52:54.802371  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:52:54.802371  1516 solver.cpp:237]     Train net output #1: loss = 0.699933 (* 1 = 0.699933 loss)
I1120 18:52:54.802371  1516 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1120 18:53:04.160167 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:53:04.548185  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_107500.caffemodel
I1120 18:53:04.575186  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_107500.solverstate
I1120 18:53:04.587185  1516 solver.cpp:330] Iteration 107500, Testing net (#0)
I1120 18:53:04.587185  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:53:06.892344 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:53:06.985348  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7319
I1120 18:53:06.985348  1516 solver.cpp:397]     Test net output #1: loss = 1.05303 (* 1 = 1.05303 loss)
I1120 18:53:07.080369  1516 solver.cpp:218] Iteration 107500 (8.14455 iter/s, 12.2782s/100 iters), loss = 0.478539
I1120 18:53:07.080369  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:53:07.080369  1516 solver.cpp:237]     Train net output #1: loss = 0.478539 (* 1 = 0.478539 loss)
I1120 18:53:07.080369  1516 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1120 18:53:17.000885  1516 solver.cpp:218] Iteration 107600 (10.0814 iter/s, 9.91922s/100 iters), loss = 0.582149
I1120 18:53:17.000885  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:53:17.000885  1516 solver.cpp:237]     Train net output #1: loss = 0.582149 (* 1 = 0.582149 loss)
I1120 18:53:17.000885  1516 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1120 18:53:27.009348  1516 solver.cpp:218] Iteration 107700 (9.99168 iter/s, 10.0083s/100 iters), loss = 0.476685
I1120 18:53:27.009848  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:53:27.009848  1516 solver.cpp:237]     Train net output #1: loss = 0.476685 (* 1 = 0.476685 loss)
I1120 18:53:27.009848  1516 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1120 18:53:37.038162  1516 solver.cpp:218] Iteration 107800 (9.97215 iter/s, 10.0279s/100 iters), loss = 0.5577
I1120 18:53:37.038162  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:53:37.038162  1516 solver.cpp:237]     Train net output #1: loss = 0.5577 (* 1 = 0.5577 loss)
I1120 18:53:37.038162  1516 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1120 18:53:47.038462  1516 solver.cpp:218] Iteration 107900 (10.0004 iter/s, 9.99961s/100 iters), loss = 0.528048
I1120 18:53:47.038462  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:53:47.038462  1516 solver.cpp:237]     Train net output #1: loss = 0.528048 (* 1 = 0.528048 loss)
I1120 18:53:47.038462  1516 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1120 18:53:56.547015 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:53:56.942517  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_108000.caffemodel
I1120 18:53:56.969017  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_108000.solverstate
I1120 18:53:56.981022  1516 solver.cpp:330] Iteration 108000, Testing net (#0)
I1120 18:53:56.981022  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:53:59.319015 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:53:59.413017  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7292
I1120 18:53:59.413017  1516 solver.cpp:397]     Test net output #1: loss = 1.04868 (* 1 = 1.04868 loss)
I1120 18:53:59.510514  1516 solver.cpp:218] Iteration 108000 (8.01836 iter/s, 12.4714s/100 iters), loss = 0.514651
I1120 18:53:59.510514  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:53:59.510514  1516 solver.cpp:237]     Train net output #1: loss = 0.514651 (* 1 = 0.514651 loss)
I1120 18:53:59.510514  1516 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1120 18:54:09.521653  1516 solver.cpp:218] Iteration 108100 (9.9895 iter/s, 10.0105s/100 iters), loss = 0.550793
I1120 18:54:09.521653  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:54:09.521653  1516 solver.cpp:237]     Train net output #1: loss = 0.550793 (* 1 = 0.550793 loss)
I1120 18:54:09.521653  1516 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1120 18:54:19.538496  1516 solver.cpp:218] Iteration 108200 (9.98393 iter/s, 10.0161s/100 iters), loss = 0.653282
I1120 18:54:19.538496  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:54:19.538496  1516 solver.cpp:237]     Train net output #1: loss = 0.653282 (* 1 = 0.653282 loss)
I1120 18:54:19.538496  1516 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1120 18:54:29.539610  1516 solver.cpp:218] Iteration 108300 (9.9994 iter/s, 10.0006s/100 iters), loss = 0.756347
I1120 18:54:29.539610  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:54:29.539610  1516 solver.cpp:237]     Train net output #1: loss = 0.756347 (* 1 = 0.756347 loss)
I1120 18:54:29.539610  1516 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1120 18:54:39.537569  1516 solver.cpp:218] Iteration 108400 (10.0026 iter/s, 9.99741s/100 iters), loss = 0.598311
I1120 18:54:39.538069  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:54:39.538069  1516 solver.cpp:237]     Train net output #1: loss = 0.598311 (* 1 = 0.598311 loss)
I1120 18:54:39.538069  1516 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1120 18:54:49.047067 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:54:49.443066  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_108500.caffemodel
I1120 18:54:49.471567  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_108500.solverstate
I1120 18:54:49.484067  1516 solver.cpp:330] Iteration 108500, Testing net (#0)
I1120 18:54:49.484067  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:54:51.820066 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:54:51.914567  1516 solver.cpp:397]     Test net output #0: accuracy = 0.73
I1120 18:54:51.914567  1516 solver.cpp:397]     Test net output #1: loss = 1.05678 (* 1 = 1.05678 loss)
I1120 18:54:52.011567  1516 solver.cpp:218] Iteration 108500 (8.01741 iter/s, 12.4729s/100 iters), loss = 0.605797
I1120 18:54:52.011567  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:54:52.011567  1516 solver.cpp:237]     Train net output #1: loss = 0.605797 (* 1 = 0.605797 loss)
I1120 18:54:52.011567  1516 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1120 18:55:02.041553  1516 solver.cpp:218] Iteration 108600 (9.97033 iter/s, 10.0298s/100 iters), loss = 0.584419
I1120 18:55:02.041553  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:55:02.042053  1516 solver.cpp:237]     Train net output #1: loss = 0.584419 (* 1 = 0.584419 loss)
I1120 18:55:02.042053  1516 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1120 18:55:12.039640  1516 solver.cpp:218] Iteration 108700 (10.0026 iter/s, 9.99744s/100 iters), loss = 0.53316
I1120 18:55:12.040140  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:55:12.040140  1516 solver.cpp:237]     Train net output #1: loss = 0.53316 (* 1 = 0.53316 loss)
I1120 18:55:12.040140  1516 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1120 18:55:22.044714  1516 solver.cpp:218] Iteration 108800 (9.99588 iter/s, 10.0041s/100 iters), loss = 0.58357
I1120 18:55:22.044714  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:55:22.044714  1516 solver.cpp:237]     Train net output #1: loss = 0.58357 (* 1 = 0.58357 loss)
I1120 18:55:22.044714  1516 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1120 18:55:32.043455  1516 solver.cpp:218] Iteration 108900 (10.0016 iter/s, 9.99844s/100 iters), loss = 0.640786
I1120 18:55:32.043957  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:55:32.043957  1516 solver.cpp:237]     Train net output #1: loss = 0.640786 (* 1 = 0.640786 loss)
I1120 18:55:32.043957  1516 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1120 18:55:41.556979 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:55:41.949468  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_109000.caffemodel
I1120 18:55:41.974968  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_109000.solverstate
I1120 18:55:41.986471  1516 solver.cpp:330] Iteration 109000, Testing net (#0)
I1120 18:55:41.986471  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:55:44.322469 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:55:44.416486  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7309
I1120 18:55:44.416486  1516 solver.cpp:397]     Test net output #1: loss = 1.05748 (* 1 = 1.05748 loss)
I1120 18:55:44.513479  1516 solver.cpp:218] Iteration 109000 (8.01986 iter/s, 12.469s/100 iters), loss = 0.506804
I1120 18:55:44.513479  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:55:44.513479  1516 solver.cpp:237]     Train net output #1: loss = 0.506804 (* 1 = 0.506804 loss)
I1120 18:55:44.513479  1516 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1120 18:55:54.537140  1516 solver.cpp:218] Iteration 109100 (9.97704 iter/s, 10.023s/100 iters), loss = 0.683817
I1120 18:55:54.537140  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:55:54.537140  1516 solver.cpp:237]     Train net output #1: loss = 0.683817 (* 1 = 0.683817 loss)
I1120 18:55:54.537140  1516 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1120 18:56:04.537094  1516 solver.cpp:218] Iteration 109200 (10.0007 iter/s, 9.99932s/100 iters), loss = 0.468238
I1120 18:56:04.537094  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:56:04.537606  1516 solver.cpp:237]     Train net output #1: loss = 0.468238 (* 1 = 0.468238 loss)
I1120 18:56:04.537606  1516 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1120 18:56:14.567641  1516 solver.cpp:218] Iteration 109300 (9.9703 iter/s, 10.0298s/100 iters), loss = 0.572593
I1120 18:56:14.567641  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:56:14.567641  1516 solver.cpp:237]     Train net output #1: loss = 0.572593 (* 1 = 0.572593 loss)
I1120 18:56:14.567641  1516 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1120 18:56:24.625639  1516 solver.cpp:218] Iteration 109400 (9.94314 iter/s, 10.0572s/100 iters), loss = 0.598948
I1120 18:56:24.625639  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:56:24.625639  1516 solver.cpp:237]     Train net output #1: loss = 0.598948 (* 1 = 0.598948 loss)
I1120 18:56:24.625639  1516 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1120 18:56:34.145768 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:56:34.540267  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_109500.caffemodel
I1120 18:56:34.567767  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_109500.solverstate
I1120 18:56:34.580271  1516 solver.cpp:330] Iteration 109500, Testing net (#0)
I1120 18:56:34.580271  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:56:36.911767 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:56:37.005769  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7311
I1120 18:56:37.005769  1516 solver.cpp:397]     Test net output #1: loss = 1.06086 (* 1 = 1.06086 loss)
I1120 18:56:37.102766  1516 solver.cpp:218] Iteration 109500 (8.01513 iter/s, 12.4764s/100 iters), loss = 0.552395
I1120 18:56:37.102766  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 18:56:37.102766  1516 solver.cpp:237]     Train net output #1: loss = 0.552395 (* 1 = 0.552395 loss)
I1120 18:56:37.102766  1516 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1120 18:56:47.110766  1516 solver.cpp:218] Iteration 109600 (9.99263 iter/s, 10.0074s/100 iters), loss = 0.643482
I1120 18:56:47.110766  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:56:47.110766  1516 solver.cpp:237]     Train net output #1: loss = 0.643482 (* 1 = 0.643482 loss)
I1120 18:56:47.110766  1516 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1120 18:56:57.128267  1516 solver.cpp:218] Iteration 109700 (9.98323 iter/s, 10.0168s/100 iters), loss = 0.465619
I1120 18:56:57.128267  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:56:57.128267  1516 solver.cpp:237]     Train net output #1: loss = 0.465619 (* 1 = 0.465619 loss)
I1120 18:56:57.128267  1516 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1120 18:57:07.142132  1516 solver.cpp:218] Iteration 109800 (9.98672 iter/s, 10.0133s/100 iters), loss = 0.711024
I1120 18:57:07.142132  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:57:07.142132  1516 solver.cpp:237]     Train net output #1: loss = 0.711024 (* 1 = 0.711024 loss)
I1120 18:57:07.142132  1516 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1120 18:57:17.146236  1516 solver.cpp:218] Iteration 109900 (9.99666 iter/s, 10.0033s/100 iters), loss = 0.593532
I1120 18:57:17.146236  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 18:57:17.146236  1516 solver.cpp:237]     Train net output #1: loss = 0.593532 (* 1 = 0.593532 loss)
I1120 18:57:17.146236  1516 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1120 18:57:26.651990 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:57:27.048455  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_110000.caffemodel
I1120 18:57:27.075455  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_110000.solverstate
I1120 18:57:27.086956  1516 solver.cpp:330] Iteration 110000, Testing net (#0)
I1120 18:57:27.086956  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:57:29.418970 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:57:29.511958  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7339
I1120 18:57:29.511958  1516 solver.cpp:397]     Test net output #1: loss = 1.04809 (* 1 = 1.04809 loss)
I1120 18:57:29.608966  1516 solver.cpp:218] Iteration 110000 (8.02422 iter/s, 12.4623s/100 iters), loss = 0.478016
I1120 18:57:29.608966  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:57:29.608966  1516 solver.cpp:237]     Train net output #1: loss = 0.478016 (* 1 = 0.478016 loss)
I1120 18:57:29.608966  1516 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1120 18:57:39.617494  1516 solver.cpp:218] Iteration 110100 (9.99207 iter/s, 10.0079s/100 iters), loss = 0.691466
I1120 18:57:39.617494  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 18:57:39.617494  1516 solver.cpp:237]     Train net output #1: loss = 0.691466 (* 1 = 0.691466 loss)
I1120 18:57:39.617494  1516 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1120 18:57:49.616639  1516 solver.cpp:218] Iteration 110200 (10.0014 iter/s, 9.99856s/100 iters), loss = 0.548023
I1120 18:57:49.616639  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 18:57:49.617125  1516 solver.cpp:237]     Train net output #1: loss = 0.548023 (* 1 = 0.548023 loss)
I1120 18:57:49.617125  1516 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1120 18:57:59.645807  1516 solver.cpp:218] Iteration 110300 (9.97192 iter/s, 10.0282s/100 iters), loss = 0.534802
I1120 18:57:59.645807  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 18:57:59.645807  1516 solver.cpp:237]     Train net output #1: loss = 0.534802 (* 1 = 0.534802 loss)
I1120 18:57:59.645807  1516 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1120 18:58:09.662343  1516 solver.cpp:218] Iteration 110400 (9.98385 iter/s, 10.0162s/100 iters), loss = 0.753089
I1120 18:58:09.662343  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 18:58:09.662343  1516 solver.cpp:237]     Train net output #1: loss = 0.753089 (* 1 = 0.753089 loss)
I1120 18:58:09.662343  1516 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1120 18:58:19.178607 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:58:19.574091  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_110500.caffemodel
I1120 18:58:19.602607  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_110500.solverstate
I1120 18:58:19.614101  1516 solver.cpp:330] Iteration 110500, Testing net (#0)
I1120 18:58:19.614101  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:58:21.946590 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:58:22.040594  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7343
I1120 18:58:22.040594  1516 solver.cpp:397]     Test net output #1: loss = 1.05038 (* 1 = 1.05038 loss)
I1120 18:58:22.137589  1516 solver.cpp:218] Iteration 110500 (8.01628 iter/s, 12.4746s/100 iters), loss = 0.495655
I1120 18:58:22.138090  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 18:58:22.138090  1516 solver.cpp:237]     Train net output #1: loss = 0.495655 (* 1 = 0.495655 loss)
I1120 18:58:22.138090  1516 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1120 18:58:32.137907  1516 solver.cpp:218] Iteration 110600 (10.0006 iter/s, 9.99936s/100 iters), loss = 0.598544
I1120 18:58:32.137907  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:58:32.137907  1516 solver.cpp:237]     Train net output #1: loss = 0.598544 (* 1 = 0.598544 loss)
I1120 18:58:32.137907  1516 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1120 18:58:42.146973  1516 solver.cpp:218] Iteration 110700 (9.99142 iter/s, 10.0086s/100 iters), loss = 0.565869
I1120 18:58:42.146973  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 18:58:42.146973  1516 solver.cpp:237]     Train net output #1: loss = 0.565869 (* 1 = 0.565869 loss)
I1120 18:58:42.146973  1516 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1120 18:58:52.164898  1516 solver.cpp:218] Iteration 110800 (9.98288 iter/s, 10.0171s/100 iters), loss = 0.587371
I1120 18:58:52.164898  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:58:52.164898  1516 solver.cpp:237]     Train net output #1: loss = 0.587371 (* 1 = 0.587371 loss)
I1120 18:58:52.164898  1516 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1120 18:59:02.171535  1516 solver.cpp:218] Iteration 110900 (9.99399 iter/s, 10.006s/100 iters), loss = 0.612033
I1120 18:59:02.171535  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:59:02.171535  1516 solver.cpp:237]     Train net output #1: loss = 0.612033 (* 1 = 0.612033 loss)
I1120 18:59:02.171535  1516 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1120 18:59:11.681134 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:59:12.078140  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_111000.caffemodel
I1120 18:59:12.104634  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_111000.solverstate
I1120 18:59:12.116133  1516 solver.cpp:330] Iteration 111000, Testing net (#0)
I1120 18:59:12.116133  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 18:59:14.448134 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 18:59:14.542136  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7315
I1120 18:59:14.542136  1516 solver.cpp:397]     Test net output #1: loss = 1.05732 (* 1 = 1.05732 loss)
I1120 18:59:14.638633  1516 solver.cpp:218] Iteration 111000 (8.02154 iter/s, 12.4664s/100 iters), loss = 0.597897
I1120 18:59:14.638633  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:59:14.638633  1516 solver.cpp:237]     Train net output #1: loss = 0.597897 (* 1 = 0.597897 loss)
I1120 18:59:14.638633  1516 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1120 18:59:24.639744  1516 solver.cpp:218] Iteration 111100 (9.99961 iter/s, 10.0004s/100 iters), loss = 0.576177
I1120 18:59:24.639744  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:59:24.639744  1516 solver.cpp:237]     Train net output #1: loss = 0.576177 (* 1 = 0.576177 loss)
I1120 18:59:24.639744  1516 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1120 18:59:34.649245  1516 solver.cpp:218] Iteration 111200 (9.99119 iter/s, 10.0088s/100 iters), loss = 0.644921
I1120 18:59:34.649245  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 18:59:34.649245  1516 solver.cpp:237]     Train net output #1: loss = 0.644921 (* 1 = 0.644921 loss)
I1120 18:59:34.649245  1516 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1120 18:59:44.568174  1516 solver.cpp:218] Iteration 111300 (10.0827 iter/s, 9.91798s/100 iters), loss = 0.524988
I1120 18:59:44.568174  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 18:59:44.568174  1516 solver.cpp:237]     Train net output #1: loss = 0.524988 (* 1 = 0.524988 loss)
I1120 18:59:44.568174  1516 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1120 18:59:54.498703  1516 solver.cpp:218] Iteration 111400 (10.0702 iter/s, 9.9303s/100 iters), loss = 0.596915
I1120 18:59:54.498703  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 18:59:54.498703  1516 solver.cpp:237]     Train net output #1: loss = 0.596915 (* 1 = 0.596915 loss)
I1120 18:59:54.498703  1516 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1120 19:00:03.958346 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:00:04.349869  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_111500.caffemodel
I1120 19:00:04.377368  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_111500.solverstate
I1120 19:00:04.389868  1516 solver.cpp:330] Iteration 111500, Testing net (#0)
I1120 19:00:04.389868  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:00:06.685570 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:00:06.776576  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7329
I1120 19:00:06.776576  1516 solver.cpp:397]     Test net output #1: loss = 1.05279 (* 1 = 1.05279 loss)
I1120 19:00:06.874121  1516 solver.cpp:218] Iteration 111500 (8.0808 iter/s, 12.375s/100 iters), loss = 0.488511
I1120 19:00:06.874121  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:00:06.874121  1516 solver.cpp:237]     Train net output #1: loss = 0.488511 (* 1 = 0.488511 loss)
I1120 19:00:06.874121  1516 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1120 19:00:16.677640  1516 solver.cpp:218] Iteration 111600 (10.2013 iter/s, 9.80266s/100 iters), loss = 0.62148
I1120 19:00:16.677640  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:00:16.677640  1516 solver.cpp:237]     Train net output #1: loss = 0.62148 (* 1 = 0.62148 loss)
I1120 19:00:16.678140  1516 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1120 19:00:26.478139  1516 solver.cpp:218] Iteration 111700 (10.2045 iter/s, 9.79955s/100 iters), loss = 0.444085
I1120 19:00:26.478139  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:00:26.478139  1516 solver.cpp:237]     Train net output #1: loss = 0.444085 (* 1 = 0.444085 loss)
I1120 19:00:26.478139  1516 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1120 19:00:36.296622  1516 solver.cpp:218] Iteration 111800 (10.1852 iter/s, 9.81815s/100 iters), loss = 0.563451
I1120 19:00:36.296622  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:00:36.296622  1516 solver.cpp:237]     Train net output #1: loss = 0.563451 (* 1 = 0.563451 loss)
I1120 19:00:36.296622  1516 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1120 19:00:46.096346  1516 solver.cpp:218] Iteration 111900 (10.2052 iter/s, 9.79894s/100 iters), loss = 0.640346
I1120 19:00:46.096346  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:00:46.096346  1516 solver.cpp:237]     Train net output #1: loss = 0.640346 (* 1 = 0.640346 loss)
I1120 19:00:46.096346  1516 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1120 19:00:55.408097 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:00:55.794606  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_112000.caffemodel
I1120 19:00:55.825598  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_112000.solverstate
I1120 19:00:55.837600  1516 solver.cpp:330] Iteration 112000, Testing net (#0)
I1120 19:00:55.838100  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:00:58.127612 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:00:58.218610  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7312
I1120 19:00:58.218610  1516 solver.cpp:397]     Test net output #1: loss = 1.05669 (* 1 = 1.05669 loss)
I1120 19:00:58.314102  1516 solver.cpp:218] Iteration 112000 (8.18525 iter/s, 12.2171s/100 iters), loss = 0.550897
I1120 19:00:58.314102  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:00:58.314102  1516 solver.cpp:237]     Train net output #1: loss = 0.550897 (* 1 = 0.550897 loss)
I1120 19:00:58.314102  1516 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1120 19:01:08.097827  1516 solver.cpp:218] Iteration 112100 (10.2216 iter/s, 9.78323s/100 iters), loss = 0.647989
I1120 19:01:08.097827  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 19:01:08.097827  1516 solver.cpp:237]     Train net output #1: loss = 0.647989 (* 1 = 0.647989 loss)
I1120 19:01:08.097827  1516 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1120 19:01:17.906486  1516 solver.cpp:218] Iteration 112200 (10.1955 iter/s, 9.80823s/100 iters), loss = 0.541597
I1120 19:01:17.906486  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:01:17.906486  1516 solver.cpp:237]     Train net output #1: loss = 0.541597 (* 1 = 0.541597 loss)
I1120 19:01:17.906486  1516 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1120 19:01:27.690655  1516 solver.cpp:218] Iteration 112300 (10.2214 iter/s, 9.78336s/100 iters), loss = 0.509921
I1120 19:01:27.690655  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:01:27.690655  1516 solver.cpp:237]     Train net output #1: loss = 0.509921 (* 1 = 0.509921 loss)
I1120 19:01:27.690655  1516 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1120 19:01:37.518167  1516 solver.cpp:218] Iteration 112400 (10.1761 iter/s, 9.82697s/100 iters), loss = 0.60945
I1120 19:01:37.518167  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:01:37.518167  1516 solver.cpp:237]     Train net output #1: loss = 0.60945 (* 1 = 0.60945 loss)
I1120 19:01:37.518167  1516 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1120 19:01:46.978657 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:01:47.367656  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_112500.caffemodel
I1120 19:01:47.393657  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_112500.solverstate
I1120 19:01:47.405158  1516 solver.cpp:330] Iteration 112500, Testing net (#0)
I1120 19:01:47.405158  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:01:49.705665 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:01:49.798156  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7326
I1120 19:01:49.798156  1516 solver.cpp:397]     Test net output #1: loss = 1.06011 (* 1 = 1.06011 loss)
I1120 19:01:49.894675  1516 solver.cpp:218] Iteration 112500 (8.08038 iter/s, 12.3757s/100 iters), loss = 0.578799
I1120 19:01:49.894675  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:01:49.894675  1516 solver.cpp:237]     Train net output #1: loss = 0.578799 (* 1 = 0.578799 loss)
I1120 19:01:49.894675  1516 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1120 19:01:59.760632  1516 solver.cpp:218] Iteration 112600 (10.1363 iter/s, 9.86548s/100 iters), loss = 0.759191
I1120 19:01:59.760632  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:01:59.760632  1516 solver.cpp:237]     Train net output #1: loss = 0.759191 (* 1 = 0.759191 loss)
I1120 19:01:59.760632  1516 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1120 19:02:09.573130  1516 solver.cpp:218] Iteration 112700 (10.1915 iter/s, 9.81209s/100 iters), loss = 0.46043
I1120 19:02:09.573130  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:02:09.573130  1516 solver.cpp:237]     Train net output #1: loss = 0.46043 (* 1 = 0.46043 loss)
I1120 19:02:09.573130  1516 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1120 19:02:19.380820  1516 solver.cpp:218] Iteration 112800 (10.1967 iter/s, 9.80711s/100 iters), loss = 0.600607
I1120 19:02:19.380820  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:02:19.380820  1516 solver.cpp:237]     Train net output #1: loss = 0.600607 (* 1 = 0.600607 loss)
I1120 19:02:19.380820  1516 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1120 19:02:29.194321  1516 solver.cpp:218] Iteration 112900 (10.1906 iter/s, 9.81295s/100 iters), loss = 0.689611
I1120 19:02:29.194321  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:02:29.194321  1516 solver.cpp:237]     Train net output #1: loss = 0.689611 (* 1 = 0.689611 loss)
I1120 19:02:29.194321  1516 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1120 19:02:38.522508 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:02:38.909008  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_113000.caffemodel
I1120 19:02:38.935022  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_113000.solverstate
I1120 19:02:38.947006  1516 solver.cpp:330] Iteration 113000, Testing net (#0)
I1120 19:02:38.947006  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:02:41.242009 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:02:41.333523  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7333
I1120 19:02:41.333523  1516 solver.cpp:397]     Test net output #1: loss = 1.05811 (* 1 = 1.05811 loss)
I1120 19:02:41.429518  1516 solver.cpp:218] Iteration 113000 (8.17382 iter/s, 12.2342s/100 iters), loss = 0.565275
I1120 19:02:41.429518  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:02:41.429518  1516 solver.cpp:237]     Train net output #1: loss = 0.565275 (* 1 = 0.565275 loss)
I1120 19:02:41.429518  1516 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1120 19:02:51.236261  1516 solver.cpp:218] Iteration 113100 (10.1976 iter/s, 9.8062s/100 iters), loss = 0.622777
I1120 19:02:51.236261  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:02:51.236261  1516 solver.cpp:237]     Train net output #1: loss = 0.622777 (* 1 = 0.622777 loss)
I1120 19:02:51.236261  1516 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1120 19:03:01.035022  1516 solver.cpp:218] Iteration 113200 (10.2056 iter/s, 9.7985s/100 iters), loss = 0.457532
I1120 19:03:01.035022  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:03:01.035523  1516 solver.cpp:237]     Train net output #1: loss = 0.457532 (* 1 = 0.457532 loss)
I1120 19:03:01.035523  1516 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1120 19:03:10.841023  1516 solver.cpp:218] Iteration 113300 (10.199 iter/s, 9.80487s/100 iters), loss = 0.628875
I1120 19:03:10.841023  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:03:10.841023  1516 solver.cpp:237]     Train net output #1: loss = 0.628875 (* 1 = 0.628875 loss)
I1120 19:03:10.841023  1516 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1120 19:03:20.640771  1516 solver.cpp:218] Iteration 113400 (10.2048 iter/s, 9.79928s/100 iters), loss = 0.510982
I1120 19:03:20.640771  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:03:20.640771  1516 solver.cpp:237]     Train net output #1: loss = 0.510982 (* 1 = 0.510982 loss)
I1120 19:03:20.640771  1516 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1120 19:03:29.957491 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:03:30.340977  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_113500.caffemodel
I1120 19:03:30.366977  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_113500.solverstate
I1120 19:03:30.378492  1516 solver.cpp:330] Iteration 113500, Testing net (#0)
I1120 19:03:30.378978  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:03:32.666992 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:03:32.758976  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7335
I1120 19:03:32.758976  1516 solver.cpp:397]     Test net output #1: loss = 1.06106 (* 1 = 1.06106 loss)
I1120 19:03:32.853487  1516 solver.cpp:218] Iteration 113500 (8.18841 iter/s, 12.2124s/100 iters), loss = 0.475943
I1120 19:03:32.853487  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:03:32.853487  1516 solver.cpp:237]     Train net output #1: loss = 0.475943 (* 1 = 0.475943 loss)
I1120 19:03:32.853487  1516 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1120 19:03:42.653275  1516 solver.cpp:218] Iteration 113600 (10.2052 iter/s, 9.7989s/100 iters), loss = 0.54164
I1120 19:03:42.653275  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:03:42.653275  1516 solver.cpp:237]     Train net output #1: loss = 0.54164 (* 1 = 0.54164 loss)
I1120 19:03:42.653275  1516 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1120 19:03:52.482774  1516 solver.cpp:218] Iteration 113700 (10.174 iter/s, 9.82894s/100 iters), loss = 0.555731
I1120 19:03:52.482774  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:03:52.482774  1516 solver.cpp:237]     Train net output #1: loss = 0.555731 (* 1 = 0.555731 loss)
I1120 19:03:52.482774  1516 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1120 19:04:02.288969  1516 solver.cpp:218] Iteration 113800 (10.1978 iter/s, 9.80602s/100 iters), loss = 0.680982
I1120 19:04:02.289468  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1120 19:04:02.289468  1516 solver.cpp:237]     Train net output #1: loss = 0.680982 (* 1 = 0.680982 loss)
I1120 19:04:02.289468  1516 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1120 19:04:12.102085  1516 solver.cpp:218] Iteration 113900 (10.1914 iter/s, 9.81221s/100 iters), loss = 0.649668
I1120 19:04:12.102085  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:04:12.102085  1516 solver.cpp:237]     Train net output #1: loss = 0.649668 (* 1 = 0.649668 loss)
I1120 19:04:12.102085  1516 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1120 19:04:21.429730 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:04:21.817220  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_114000.caffemodel
I1120 19:04:21.843731  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_114000.solverstate
I1120 19:04:21.855244  1516 solver.cpp:330] Iteration 114000, Testing net (#0)
I1120 19:04:21.855244  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:04:24.153214 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:04:24.245230  1516 solver.cpp:397]     Test net output #0: accuracy = 0.733
I1120 19:04:24.245230  1516 solver.cpp:397]     Test net output #1: loss = 1.06707 (* 1 = 1.06707 loss)
I1120 19:04:24.340226  1516 solver.cpp:218] Iteration 114000 (8.17143 iter/s, 12.2378s/100 iters), loss = 0.447775
I1120 19:04:24.340226  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:04:24.340226  1516 solver.cpp:237]     Train net output #1: loss = 0.447775 (* 1 = 0.447775 loss)
I1120 19:04:24.340725  1516 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1120 19:04:34.147456  1516 solver.cpp:218] Iteration 114100 (10.1975 iter/s, 9.80633s/100 iters), loss = 0.536229
I1120 19:04:34.147456  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:04:34.147456  1516 solver.cpp:237]     Train net output #1: loss = 0.536229 (* 1 = 0.536229 loss)
I1120 19:04:34.147456  1516 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1120 19:04:43.946977  1516 solver.cpp:218] Iteration 114200 (10.2047 iter/s, 9.79939s/100 iters), loss = 0.582066
I1120 19:04:43.947477  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:04:43.947477  1516 solver.cpp:237]     Train net output #1: loss = 0.582066 (* 1 = 0.582066 loss)
I1120 19:04:43.947477  1516 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1120 19:04:53.747972  1516 solver.cpp:218] Iteration 114300 (10.204 iter/s, 9.8001s/100 iters), loss = 0.461653
I1120 19:04:53.747972  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:04:53.747972  1516 solver.cpp:237]     Train net output #1: loss = 0.461653 (* 1 = 0.461653 loss)
I1120 19:04:53.747972  1516 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1120 19:05:03.532241  1516 solver.cpp:218] Iteration 114400 (10.2208 iter/s, 9.78397s/100 iters), loss = 0.645127
I1120 19:05:03.532742  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:05:03.532742  1516 solver.cpp:237]     Train net output #1: loss = 0.645127 (* 1 = 0.645127 loss)
I1120 19:05:03.532742  1516 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1120 19:05:12.832350 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:05:13.218849  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_114500.caffemodel
I1120 19:05:13.245848  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_114500.solverstate
I1120 19:05:13.257349  1516 solver.cpp:330] Iteration 114500, Testing net (#0)
I1120 19:05:13.257349  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:05:15.547864 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:05:15.640350  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7302
I1120 19:05:15.640350  1516 solver.cpp:397]     Test net output #1: loss = 1.07585 (* 1 = 1.07585 loss)
I1120 19:05:15.734860  1516 solver.cpp:218] Iteration 114500 (8.19547 iter/s, 12.2019s/100 iters), loss = 0.574802
I1120 19:05:15.734860  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:05:15.734860  1516 solver.cpp:237]     Train net output #1: loss = 0.574802 (* 1 = 0.574802 loss)
I1120 19:05:15.734860  1516 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1120 19:05:25.523866  1516 solver.cpp:218] Iteration 114600 (10.2165 iter/s, 9.78813s/100 iters), loss = 0.654215
I1120 19:05:25.523866  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:05:25.523866  1516 solver.cpp:237]     Train net output #1: loss = 0.654215 (* 1 = 0.654215 loss)
I1120 19:05:25.523866  1516 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1120 19:05:35.314678  1516 solver.cpp:218] Iteration 114700 (10.214 iter/s, 9.79047s/100 iters), loss = 0.433906
I1120 19:05:35.314678  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:05:35.314678  1516 solver.cpp:237]     Train net output #1: loss = 0.433906 (* 1 = 0.433906 loss)
I1120 19:05:35.314678  1516 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1120 19:05:45.108409  1516 solver.cpp:218] Iteration 114800 (10.2115 iter/s, 9.79284s/100 iters), loss = 0.502195
I1120 19:05:45.108409  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:05:45.108409  1516 solver.cpp:237]     Train net output #1: loss = 0.502195 (* 1 = 0.502195 loss)
I1120 19:05:45.108409  1516 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1120 19:05:54.912410  1516 solver.cpp:218] Iteration 114900 (10.2004 iter/s, 9.80353s/100 iters), loss = 0.580606
I1120 19:05:54.912410  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:05:54.912410  1516 solver.cpp:237]     Train net output #1: loss = 0.580606 (* 1 = 0.580606 loss)
I1120 19:05:54.912410  1516 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1120 19:06:04.230587 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:06:04.617089  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_115000.caffemodel
I1120 19:06:04.643587  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_115000.solverstate
I1120 19:06:04.655588  1516 solver.cpp:330] Iteration 115000, Testing net (#0)
I1120 19:06:04.655588  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:06:06.948586 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:06:07.041087  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7306
I1120 19:06:07.041087  1516 solver.cpp:397]     Test net output #1: loss = 1.074 (* 1 = 1.074 loss)
I1120 19:06:07.136087  1516 solver.cpp:218] Iteration 115000 (8.18115 iter/s, 12.2232s/100 iters), loss = 0.449785
I1120 19:06:07.136087  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:06:07.136087  1516 solver.cpp:237]     Train net output #1: loss = 0.449785 (* 1 = 0.449785 loss)
I1120 19:06:07.136087  1516 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1120 19:06:16.942874  1516 solver.cpp:218] Iteration 115100 (10.1979 iter/s, 9.80597s/100 iters), loss = 0.584984
I1120 19:06:16.942874  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:06:16.942874  1516 solver.cpp:237]     Train net output #1: loss = 0.584984 (* 1 = 0.584984 loss)
I1120 19:06:16.942874  1516 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1120 19:06:26.752374  1516 solver.cpp:218] Iteration 115200 (10.1947 iter/s, 9.80904s/100 iters), loss = 0.485033
I1120 19:06:26.752374  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:06:26.752374  1516 solver.cpp:237]     Train net output #1: loss = 0.485033 (* 1 = 0.485033 loss)
I1120 19:06:26.752876  1516 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1120 19:06:36.558310  1516 solver.cpp:218] Iteration 115300 (10.1987 iter/s, 9.80521s/100 iters), loss = 0.603451
I1120 19:06:36.558310  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:06:36.558310  1516 solver.cpp:237]     Train net output #1: loss = 0.603451 (* 1 = 0.603451 loss)
I1120 19:06:36.558310  1516 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1120 19:06:46.366808  1516 solver.cpp:218] Iteration 115400 (10.1961 iter/s, 9.80771s/100 iters), loss = 0.49966
I1120 19:06:46.366808  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:06:46.366808  1516 solver.cpp:237]     Train net output #1: loss = 0.49966 (* 1 = 0.49966 loss)
I1120 19:06:46.366808  1516 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1120 19:06:55.679846 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:06:56.066344  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_115500.caffemodel
I1120 19:06:56.093344  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_115500.solverstate
I1120 19:06:56.104854  1516 solver.cpp:330] Iteration 115500, Testing net (#0)
I1120 19:06:56.105343  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:06:58.393859 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:06:58.485354  1516 solver.cpp:397]     Test net output #0: accuracy = 0.733
I1120 19:06:58.485354  1516 solver.cpp:397]     Test net output #1: loss = 1.0672 (* 1 = 1.0672 loss)
I1120 19:06:58.580862  1516 solver.cpp:218] Iteration 115500 (8.18765 iter/s, 12.2135s/100 iters), loss = 0.500547
I1120 19:06:58.580862  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:06:58.580862  1516 solver.cpp:237]     Train net output #1: loss = 0.500547 (* 1 = 0.500547 loss)
I1120 19:06:58.580862  1516 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1120 19:07:08.377956  1516 solver.cpp:218] Iteration 115600 (10.2075 iter/s, 9.7967s/100 iters), loss = 0.633935
I1120 19:07:08.378453  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:07:08.378453  1516 solver.cpp:237]     Train net output #1: loss = 0.633935 (* 1 = 0.633935 loss)
I1120 19:07:08.378453  1516 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1120 19:07:18.207692  1516 solver.cpp:218] Iteration 115700 (10.174 iter/s, 9.82901s/100 iters), loss = 0.521103
I1120 19:07:18.207692  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:07:18.207692  1516 solver.cpp:237]     Train net output #1: loss = 0.521103 (* 1 = 0.521103 loss)
I1120 19:07:18.207692  1516 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1120 19:07:28.044786  1516 solver.cpp:218] Iteration 115800 (10.1661 iter/s, 9.83665s/100 iters), loss = 0.639032
I1120 19:07:28.045286  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:07:28.045286  1516 solver.cpp:237]     Train net output #1: loss = 0.639032 (* 1 = 0.639032 loss)
I1120 19:07:28.045286  1516 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1120 19:07:37.885437  1516 solver.cpp:218] Iteration 115900 (10.1626 iter/s, 9.84004s/100 iters), loss = 0.633045
I1120 19:07:37.885937  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:07:37.885937  1516 solver.cpp:237]     Train net output #1: loss = 0.633045 (* 1 = 0.633045 loss)
I1120 19:07:37.885937  1516 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1120 19:07:47.267494 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:07:47.657493  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_116000.caffemodel
I1120 19:07:47.684993  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_116000.solverstate
I1120 19:07:47.696493  1516 solver.cpp:330] Iteration 116000, Testing net (#0)
I1120 19:07:47.696493  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:07:50.000993 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:07:50.091994  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7304
I1120 19:07:50.092494  1516 solver.cpp:397]     Test net output #1: loss = 1.0762 (* 1 = 1.0762 loss)
I1120 19:07:50.186992  1516 solver.cpp:218] Iteration 116000 (8.12955 iter/s, 12.3008s/100 iters), loss = 0.429109
I1120 19:07:50.187492  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1120 19:07:50.187492  1516 solver.cpp:237]     Train net output #1: loss = 0.429109 (* 1 = 0.429109 loss)
I1120 19:07:50.187492  1516 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1120 19:07:59.982565  1516 solver.cpp:218] Iteration 116100 (10.2096 iter/s, 9.79468s/100 iters), loss = 0.681783
I1120 19:07:59.982565  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:07:59.982565  1516 solver.cpp:237]     Train net output #1: loss = 0.681783 (* 1 = 0.681783 loss)
I1120 19:07:59.982565  1516 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1120 19:08:09.795977  1516 solver.cpp:218] Iteration 116200 (10.1904 iter/s, 9.81316s/100 iters), loss = 0.511983
I1120 19:08:09.796489  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:08:09.796489  1516 solver.cpp:237]     Train net output #1: loss = 0.511983 (* 1 = 0.511983 loss)
I1120 19:08:09.796489  1516 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1120 19:08:19.597854  1516 solver.cpp:218] Iteration 116300 (10.2032 iter/s, 9.80085s/100 iters), loss = 0.589583
I1120 19:08:19.597854  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:08:19.597854  1516 solver.cpp:237]     Train net output #1: loss = 0.589583 (* 1 = 0.589583 loss)
I1120 19:08:19.597854  1516 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1120 19:08:29.409370  1516 solver.cpp:218] Iteration 116400 (10.1927 iter/s, 9.8109s/100 iters), loss = 0.642147
I1120 19:08:29.409370  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:08:29.409370  1516 solver.cpp:237]     Train net output #1: loss = 0.642147 (* 1 = 0.642147 loss)
I1120 19:08:29.409370  1516 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1120 19:08:38.720258 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:08:39.104766  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_116500.caffemodel
I1120 19:08:39.130257  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_116500.solverstate
I1120 19:08:39.141758  1516 solver.cpp:330] Iteration 116500, Testing net (#0)
I1120 19:08:39.141758  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:08:41.435303 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:08:41.528307  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7291
I1120 19:08:41.528307  1516 solver.cpp:397]     Test net output #1: loss = 1.07796 (* 1 = 1.07796 loss)
I1120 19:08:41.623314  1516 solver.cpp:218] Iteration 116500 (8.18775 iter/s, 12.2134s/100 iters), loss = 0.479922
I1120 19:08:41.623314  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:08:41.623314  1516 solver.cpp:237]     Train net output #1: loss = 0.479922 (* 1 = 0.479922 loss)
I1120 19:08:41.623314  1516 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1120 19:08:51.412858  1516 solver.cpp:218] Iteration 116600 (10.2153 iter/s, 9.78927s/100 iters), loss = 0.535781
I1120 19:08:51.412858  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:08:51.412858  1516 solver.cpp:237]     Train net output #1: loss = 0.535781 (* 1 = 0.535781 loss)
I1120 19:08:51.412858  1516 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1120 19:09:01.214391  1516 solver.cpp:218] Iteration 116700 (10.203 iter/s, 9.80106s/100 iters), loss = 0.472656
I1120 19:09:01.214892  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:09:01.214892  1516 solver.cpp:237]     Train net output #1: loss = 0.472656 (* 1 = 0.472656 loss)
I1120 19:09:01.214892  1516 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1120 19:09:11.018440  1516 solver.cpp:218] Iteration 116800 (10.201 iter/s, 9.80296s/100 iters), loss = 0.737476
I1120 19:09:11.018440  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:09:11.018440  1516 solver.cpp:237]     Train net output #1: loss = 0.737476 (* 1 = 0.737476 loss)
I1120 19:09:11.018440  1516 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1120 19:09:20.825963  1516 solver.cpp:218] Iteration 116900 (10.1966 iter/s, 9.80724s/100 iters), loss = 0.554323
I1120 19:09:20.825963  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:09:20.825963  1516 solver.cpp:237]     Train net output #1: loss = 0.554323 (* 1 = 0.554323 loss)
I1120 19:09:20.825963  1516 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1120 19:09:30.141965 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:09:30.530464  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_117000.caffemodel
I1120 19:09:30.558465  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_117000.solverstate
I1120 19:09:30.569965  1516 solver.cpp:330] Iteration 117000, Testing net (#0)
I1120 19:09:30.569965  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:09:32.865463 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:09:32.957465  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7308
I1120 19:09:32.957465  1516 solver.cpp:397]     Test net output #1: loss = 1.0714 (* 1 = 1.0714 loss)
I1120 19:09:33.052964  1516 solver.cpp:218] Iteration 117000 (8.17923 iter/s, 12.2261s/100 iters), loss = 0.490704
I1120 19:09:33.052964  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:09:33.052964  1516 solver.cpp:237]     Train net output #1: loss = 0.490704 (* 1 = 0.490704 loss)
I1120 19:09:33.052964  1516 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1120 19:09:42.861239  1516 solver.cpp:218] Iteration 117100 (10.1961 iter/s, 9.80765s/100 iters), loss = 0.51226
I1120 19:09:42.861239  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:09:42.861239  1516 solver.cpp:237]     Train net output #1: loss = 0.51226 (* 1 = 0.51226 loss)
I1120 19:09:42.861239  1516 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1120 19:09:52.656870  1516 solver.cpp:218] Iteration 117200 (10.2088 iter/s, 9.79546s/100 iters), loss = 0.453782
I1120 19:09:52.657361  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:09:52.657361  1516 solver.cpp:237]     Train net output #1: loss = 0.453782 (* 1 = 0.453782 loss)
I1120 19:09:52.657361  1516 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1120 19:10:02.480468  1516 solver.cpp:218] Iteration 117300 (10.1802 iter/s, 9.82299s/100 iters), loss = 0.606686
I1120 19:10:02.480967  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:10:02.480967  1516 solver.cpp:237]     Train net output #1: loss = 0.606686 (* 1 = 0.606686 loss)
I1120 19:10:02.480967  1516 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1120 19:10:12.270853  1516 solver.cpp:218] Iteration 117400 (10.2148 iter/s, 9.7897s/100 iters), loss = 0.633448
I1120 19:10:12.270853  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:10:12.270853  1516 solver.cpp:237]     Train net output #1: loss = 0.633448 (* 1 = 0.633448 loss)
I1120 19:10:12.270853  1516 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1120 19:10:21.581660 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:10:21.968660  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_117500.caffemodel
I1120 19:10:21.995160  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_117500.solverstate
I1120 19:10:22.006176  1516 solver.cpp:330] Iteration 117500, Testing net (#0)
I1120 19:10:22.006660  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:10:24.299160 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:10:24.391671  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7329
I1120 19:10:24.391671  1516 solver.cpp:397]     Test net output #1: loss = 1.06581 (* 1 = 1.06581 loss)
I1120 19:10:24.486173  1516 solver.cpp:218] Iteration 117500 (8.18691 iter/s, 12.2146s/100 iters), loss = 0.44202
I1120 19:10:24.486173  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:10:24.486173  1516 solver.cpp:237]     Train net output #1: loss = 0.44202 (* 1 = 0.44202 loss)
I1120 19:10:24.486173  1516 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1120 19:10:34.276912  1516 solver.cpp:218] Iteration 117600 (10.2142 iter/s, 9.79025s/100 iters), loss = 0.625794
I1120 19:10:34.276912  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:10:34.276912  1516 solver.cpp:237]     Train net output #1: loss = 0.625794 (* 1 = 0.625794 loss)
I1120 19:10:34.276912  1516 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1120 19:10:44.076360  1516 solver.cpp:218] Iteration 117700 (10.2052 iter/s, 9.79895s/100 iters), loss = 0.504293
I1120 19:10:44.076859  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:10:44.076859  1516 solver.cpp:237]     Train net output #1: loss = 0.504293 (* 1 = 0.504293 loss)
I1120 19:10:44.076859  1516 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1120 19:10:53.890354  1516 solver.cpp:218] Iteration 117800 (10.1906 iter/s, 9.813s/100 iters), loss = 0.673937
I1120 19:10:53.890354  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 19:10:53.890354  1516 solver.cpp:237]     Train net output #1: loss = 0.673937 (* 1 = 0.673937 loss)
I1120 19:10:53.890354  1516 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1120 19:11:03.720890  1516 solver.cpp:218] Iteration 117900 (10.1728 iter/s, 9.83015s/100 iters), loss = 0.755716
I1120 19:11:03.720890  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 19:11:03.720890  1516 solver.cpp:237]     Train net output #1: loss = 0.755716 (* 1 = 0.755716 loss)
I1120 19:11:03.720890  1516 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1120 19:11:13.037878 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:11:13.426519  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_118000.caffemodel
I1120 19:11:13.459019  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_118000.solverstate
I1120 19:11:13.471024  1516 solver.cpp:330] Iteration 118000, Testing net (#0)
I1120 19:11:13.471024  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:11:15.763520 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:11:15.856523  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7343
I1120 19:11:15.856523  1516 solver.cpp:397]     Test net output #1: loss = 1.07116 (* 1 = 1.07116 loss)
I1120 19:11:15.951299  1516 solver.cpp:218] Iteration 118000 (8.17678 iter/s, 12.2297s/100 iters), loss = 0.514046
I1120 19:11:15.951299  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:11:15.951299  1516 solver.cpp:237]     Train net output #1: loss = 0.514046 (* 1 = 0.514046 loss)
I1120 19:11:15.951299  1516 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1120 19:11:25.756714  1516 solver.cpp:218] Iteration 118100 (10.1989 iter/s, 9.80498s/100 iters), loss = 0.525977
I1120 19:11:25.756714  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:11:25.757215  1516 solver.cpp:237]     Train net output #1: loss = 0.525977 (* 1 = 0.525977 loss)
I1120 19:11:25.757215  1516 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1120 19:11:35.564784  1516 solver.cpp:218] Iteration 118200 (10.1966 iter/s, 9.80723s/100 iters), loss = 0.476631
I1120 19:11:35.564784  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:11:35.564784  1516 solver.cpp:237]     Train net output #1: loss = 0.476631 (* 1 = 0.476631 loss)
I1120 19:11:35.564784  1516 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1120 19:11:45.368212  1516 solver.cpp:218] Iteration 118300 (10.2013 iter/s, 9.80265s/100 iters), loss = 0.484599
I1120 19:11:45.368212  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:11:45.368212  1516 solver.cpp:237]     Train net output #1: loss = 0.484599 (* 1 = 0.484599 loss)
I1120 19:11:45.368212  1516 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1120 19:11:55.171772  1516 solver.cpp:218] Iteration 118400 (10.201 iter/s, 9.80296s/100 iters), loss = 0.635051
I1120 19:11:55.171772  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:11:55.171772  1516 solver.cpp:237]     Train net output #1: loss = 0.635051 (* 1 = 0.635051 loss)
I1120 19:11:55.171772  1516 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1120 19:12:04.475873 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:12:04.863874  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_118500.caffemodel
I1120 19:12:04.889376  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_118500.solverstate
I1120 19:12:04.900876  1516 solver.cpp:330] Iteration 118500, Testing net (#0)
I1120 19:12:04.900876  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:12:07.187376 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:12:07.279376  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7314
I1120 19:12:07.279376  1516 solver.cpp:397]     Test net output #1: loss = 1.07508 (* 1 = 1.07508 loss)
I1120 19:12:07.374374  1516 solver.cpp:218] Iteration 118500 (8.19548 iter/s, 12.2018s/100 iters), loss = 0.457766
I1120 19:12:07.374374  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:12:07.374374  1516 solver.cpp:237]     Train net output #1: loss = 0.457766 (* 1 = 0.457766 loss)
I1120 19:12:07.374374  1516 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1120 19:12:17.148924  1516 solver.cpp:218] Iteration 118600 (10.2313 iter/s, 9.7739s/100 iters), loss = 0.570069
I1120 19:12:17.148924  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:12:17.148924  1516 solver.cpp:237]     Train net output #1: loss = 0.570069 (* 1 = 0.570069 loss)
I1120 19:12:17.148924  1516 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1120 19:12:26.933172  1516 solver.cpp:218] Iteration 118700 (10.221 iter/s, 9.78379s/100 iters), loss = 0.507992
I1120 19:12:26.933172  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:12:26.933172  1516 solver.cpp:237]     Train net output #1: loss = 0.507992 (* 1 = 0.507992 loss)
I1120 19:12:26.933172  1516 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1120 19:12:36.729149  1516 solver.cpp:218] Iteration 118800 (10.2089 iter/s, 9.79537s/100 iters), loss = 0.608212
I1120 19:12:36.729149  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:12:36.729149  1516 solver.cpp:237]     Train net output #1: loss = 0.608212 (* 1 = 0.608212 loss)
I1120 19:12:36.729149  1516 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1120 19:12:46.527889  1516 solver.cpp:218] Iteration 118900 (10.2058 iter/s, 9.79837s/100 iters), loss = 0.635161
I1120 19:12:46.527889  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:12:46.527889  1516 solver.cpp:237]     Train net output #1: loss = 0.635161 (* 1 = 0.635161 loss)
I1120 19:12:46.527889  1516 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1120 19:12:55.836628 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:12:56.223618  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_119000.caffemodel
I1120 19:12:56.250617  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_119000.solverstate
I1120 19:12:56.262121  1516 solver.cpp:330] Iteration 119000, Testing net (#0)
I1120 19:12:56.262121  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:12:58.557632 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:12:58.649636  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7314
I1120 19:12:58.649636  1516 solver.cpp:397]     Test net output #1: loss = 1.07678 (* 1 = 1.07678 loss)
I1120 19:12:58.745127  1516 solver.cpp:218] Iteration 119000 (8.18571 iter/s, 12.2164s/100 iters), loss = 0.615957
I1120 19:12:58.745127  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:12:58.745127  1516 solver.cpp:237]     Train net output #1: loss = 0.615957 (* 1 = 0.615957 loss)
I1120 19:12:58.745127  1516 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1120 19:13:08.544875  1516 solver.cpp:218] Iteration 119100 (10.2046 iter/s, 9.79949s/100 iters), loss = 0.486515
I1120 19:13:08.545377  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:13:08.545377  1516 solver.cpp:237]     Train net output #1: loss = 0.486515 (* 1 = 0.486515 loss)
I1120 19:13:08.545377  1516 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1120 19:13:18.396999  1516 solver.cpp:218] Iteration 119200 (10.1512 iter/s, 9.85109s/100 iters), loss = 0.453811
I1120 19:13:18.396999  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:13:18.396999  1516 solver.cpp:237]     Train net output #1: loss = 0.453811 (* 1 = 0.453811 loss)
I1120 19:13:18.396999  1516 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1120 19:13:28.205299  1516 solver.cpp:218] Iteration 119300 (10.1959 iter/s, 9.8079s/100 iters), loss = 0.59001
I1120 19:13:28.205299  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:13:28.205299  1516 solver.cpp:237]     Train net output #1: loss = 0.59001 (* 1 = 0.59001 loss)
I1120 19:13:28.205299  1516 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1120 19:13:38.014910  1516 solver.cpp:218] Iteration 119400 (10.1948 iter/s, 9.80891s/100 iters), loss = 0.647285
I1120 19:13:38.014910  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 19:13:38.014910  1516 solver.cpp:237]     Train net output #1: loss = 0.647285 (* 1 = 0.647285 loss)
I1120 19:13:38.014910  1516 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1120 19:13:47.338986 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:13:47.724992  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_119500.caffemodel
I1120 19:13:47.750985  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_119500.solverstate
I1120 19:13:47.762986  1516 solver.cpp:330] Iteration 119500, Testing net (#0)
I1120 19:13:47.763485  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:13:50.057494 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:13:50.150002  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7338
I1120 19:13:50.150002  1516 solver.cpp:397]     Test net output #1: loss = 1.07116 (* 1 = 1.07116 loss)
I1120 19:13:50.245493  1516 solver.cpp:218] Iteration 119500 (8.17641 iter/s, 12.2303s/100 iters), loss = 0.626506
I1120 19:13:50.245995  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:13:50.245995  1516 solver.cpp:237]     Train net output #1: loss = 0.626506 (* 1 = 0.626506 loss)
I1120 19:13:50.245995  1516 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1120 19:14:00.054522  1516 solver.cpp:218] Iteration 119600 (10.1956 iter/s, 9.80812s/100 iters), loss = 0.482391
I1120 19:14:00.054522  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:14:00.054522  1516 solver.cpp:237]     Train net output #1: loss = 0.482391 (* 1 = 0.482391 loss)
I1120 19:14:00.054522  1516 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1120 19:14:09.863523  1516 solver.cpp:218] Iteration 119700 (10.1953 iter/s, 9.80846s/100 iters), loss = 0.493925
I1120 19:14:09.863523  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:14:09.863523  1516 solver.cpp:237]     Train net output #1: loss = 0.493925 (* 1 = 0.493925 loss)
I1120 19:14:09.863523  1516 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1120 19:14:19.673044  1516 solver.cpp:218] Iteration 119800 (10.1949 iter/s, 9.80884s/100 iters), loss = 0.645403
I1120 19:14:19.673044  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:14:19.673044  1516 solver.cpp:237]     Train net output #1: loss = 0.645403 (* 1 = 0.645403 loss)
I1120 19:14:19.673044  1516 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1120 19:14:29.476529  1516 solver.cpp:218] Iteration 119900 (10.2009 iter/s, 9.80305s/100 iters), loss = 0.581812
I1120 19:14:29.476529  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:14:29.476529  1516 solver.cpp:237]     Train net output #1: loss = 0.581812 (* 1 = 0.581812 loss)
I1120 19:14:29.476529  1516 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1120 19:14:38.787639 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:14:39.176651  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_120000.caffemodel
I1120 19:14:39.203158  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_120000.solverstate
I1120 19:14:39.214658  1516 solver.cpp:330] Iteration 120000, Testing net (#0)
I1120 19:14:39.214658  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:14:41.513706 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:14:41.605207  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7314
I1120 19:14:41.605727  1516 solver.cpp:397]     Test net output #1: loss = 1.08188 (* 1 = 1.08188 loss)
I1120 19:14:41.701222  1516 solver.cpp:218] Iteration 120000 (8.18081 iter/s, 12.2237s/100 iters), loss = 0.567459
I1120 19:14:41.701222  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:14:41.701222  1516 solver.cpp:237]     Train net output #1: loss = 0.567459 (* 1 = 0.567459 loss)
I1120 19:14:41.701222  1516 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1120 19:14:51.501708  1516 solver.cpp:218] Iteration 120100 (10.204 iter/s, 9.80005s/100 iters), loss = 0.634265
I1120 19:14:51.501708  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:14:51.501708  1516 solver.cpp:237]     Train net output #1: loss = 0.634265 (* 1 = 0.634265 loss)
I1120 19:14:51.501708  1516 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1120 19:15:01.306850  1516 solver.cpp:218] Iteration 120200 (10.1996 iter/s, 9.80434s/100 iters), loss = 0.526452
I1120 19:15:01.306850  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:15:01.306850  1516 solver.cpp:237]     Train net output #1: loss = 0.526452 (* 1 = 0.526452 loss)
I1120 19:15:01.306850  1516 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1120 19:15:11.100692  1516 solver.cpp:218] Iteration 120300 (10.2112 iter/s, 9.79313s/100 iters), loss = 0.618237
I1120 19:15:11.100692  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:15:11.100692  1516 solver.cpp:237]     Train net output #1: loss = 0.618237 (* 1 = 0.618237 loss)
I1120 19:15:11.100692  1516 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1120 19:15:20.903726  1516 solver.cpp:218] Iteration 120400 (10.2011 iter/s, 9.80282s/100 iters), loss = 0.625195
I1120 19:15:20.903726  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:15:20.903726  1516 solver.cpp:237]     Train net output #1: loss = 0.625195 (* 1 = 0.625195 loss)
I1120 19:15:20.904228  1516 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1120 19:15:30.224324 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:15:30.613824  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_120500.caffemodel
I1120 19:15:30.640825  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_120500.solverstate
I1120 19:15:30.652325  1516 solver.cpp:330] Iteration 120500, Testing net (#0)
I1120 19:15:30.652325  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:15:32.942824 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:15:33.035341  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7301
I1120 19:15:33.035835  1516 solver.cpp:397]     Test net output #1: loss = 1.08052 (* 1 = 1.08052 loss)
I1120 19:15:33.130823  1516 solver.cpp:218] Iteration 120500 (8.17913 iter/s, 12.2262s/100 iters), loss = 0.454716
I1120 19:15:33.130823  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:15:33.130823  1516 solver.cpp:237]     Train net output #1: loss = 0.454716 (* 1 = 0.454716 loss)
I1120 19:15:33.130823  1516 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1120 19:15:42.988314  1516 solver.cpp:218] Iteration 120600 (10.1449 iter/s, 9.85713s/100 iters), loss = 0.65361
I1120 19:15:42.988821  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:15:42.988821  1516 solver.cpp:237]     Train net output #1: loss = 0.65361 (* 1 = 0.65361 loss)
I1120 19:15:42.988821  1516 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1120 19:15:52.825033  1516 solver.cpp:218] Iteration 120700 (10.1669 iter/s, 9.83582s/100 iters), loss = 0.441257
I1120 19:15:52.825033  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:15:52.825033  1516 solver.cpp:237]     Train net output #1: loss = 0.441257 (* 1 = 0.441257 loss)
I1120 19:15:52.825033  1516 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1120 19:16:02.673413  1516 solver.cpp:218] Iteration 120800 (10.155 iter/s, 9.84741s/100 iters), loss = 0.658603
I1120 19:16:02.673413  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:16:02.673413  1516 solver.cpp:237]     Train net output #1: loss = 0.658603 (* 1 = 0.658603 loss)
I1120 19:16:02.673413  1516 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1120 19:16:12.519090  1516 solver.cpp:218] Iteration 120900 (10.1571 iter/s, 9.84532s/100 iters), loss = 0.526741
I1120 19:16:12.519090  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:16:12.519090  1516 solver.cpp:237]     Train net output #1: loss = 0.526741 (* 1 = 0.526741 loss)
I1120 19:16:12.519090  1516 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1120 19:16:21.881640 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:16:22.270145  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_121000.caffemodel
I1120 19:16:22.298640  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_121000.solverstate
I1120 19:16:22.311142  1516 solver.cpp:330] Iteration 121000, Testing net (#0)
I1120 19:16:22.311142  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:16:24.617163 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:16:24.710155  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7308
I1120 19:16:24.710155  1516 solver.cpp:397]     Test net output #1: loss = 1.08319 (* 1 = 1.08319 loss)
I1120 19:16:24.805171  1516 solver.cpp:218] Iteration 121000 (8.13965 iter/s, 12.2855s/100 iters), loss = 0.542413
I1120 19:16:24.805171  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:16:24.805671  1516 solver.cpp:237]     Train net output #1: loss = 0.542413 (* 1 = 0.542413 loss)
I1120 19:16:24.805671  1516 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1120 19:16:34.602244  1516 solver.cpp:218] Iteration 121100 (10.2078 iter/s, 9.79646s/100 iters), loss = 0.489249
I1120 19:16:34.602244  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:16:34.602244  1516 solver.cpp:237]     Train net output #1: loss = 0.489249 (* 1 = 0.489249 loss)
I1120 19:16:34.602244  1516 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1120 19:16:44.406744  1516 solver.cpp:218] Iteration 121200 (10.2003 iter/s, 9.80359s/100 iters), loss = 0.478371
I1120 19:16:44.406744  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:16:44.406744  1516 solver.cpp:237]     Train net output #1: loss = 0.478371 (* 1 = 0.478371 loss)
I1120 19:16:44.406744  1516 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1120 19:16:54.209245  1516 solver.cpp:218] Iteration 121300 (10.2021 iter/s, 9.80195s/100 iters), loss = 0.548226
I1120 19:16:54.209245  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:16:54.209245  1516 solver.cpp:237]     Train net output #1: loss = 0.548226 (* 1 = 0.548226 loss)
I1120 19:16:54.209245  1516 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1120 19:17:04.006672  1516 solver.cpp:218] Iteration 121400 (10.2071 iter/s, 9.79707s/100 iters), loss = 0.571495
I1120 19:17:04.006672  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:17:04.006672  1516 solver.cpp:237]     Train net output #1: loss = 0.571495 (* 1 = 0.571495 loss)
I1120 19:17:04.006672  1516 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1120 19:17:13.331490 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:17:13.718989  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_121500.caffemodel
I1120 19:17:13.743989  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_121500.solverstate
I1120 19:17:13.755991  1516 solver.cpp:330] Iteration 121500, Testing net (#0)
I1120 19:17:13.755991  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:17:16.049489 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:17:16.141489  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7318
I1120 19:17:16.141489  1516 solver.cpp:397]     Test net output #1: loss = 1.08795 (* 1 = 1.08795 loss)
I1120 19:17:16.236990  1516 solver.cpp:218] Iteration 121500 (8.17699 iter/s, 12.2294s/100 iters), loss = 0.519635
I1120 19:17:16.236990  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:17:16.236990  1516 solver.cpp:237]     Train net output #1: loss = 0.519635 (* 1 = 0.519635 loss)
I1120 19:17:16.236990  1516 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1120 19:17:26.041909  1516 solver.cpp:218] Iteration 121600 (10.1993 iter/s, 9.80464s/100 iters), loss = 0.579499
I1120 19:17:26.041909  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:17:26.041909  1516 solver.cpp:237]     Train net output #1: loss = 0.579499 (* 1 = 0.579499 loss)
I1120 19:17:26.041909  1516 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1120 19:17:35.844409  1516 solver.cpp:218] Iteration 121700 (10.2022 iter/s, 9.80182s/100 iters), loss = 0.557693
I1120 19:17:35.844409  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:17:35.844409  1516 solver.cpp:237]     Train net output #1: loss = 0.557693 (* 1 = 0.557693 loss)
I1120 19:17:35.844409  1516 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1120 19:17:45.642767  1516 solver.cpp:218] Iteration 121800 (10.2063 iter/s, 9.7979s/100 iters), loss = 0.619597
I1120 19:17:45.642767  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 19:17:45.642767  1516 solver.cpp:237]     Train net output #1: loss = 0.619597 (* 1 = 0.619597 loss)
I1120 19:17:45.642767  1516 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1120 19:17:55.434154  1516 solver.cpp:218] Iteration 121900 (10.2139 iter/s, 9.79054s/100 iters), loss = 0.750716
I1120 19:17:55.434154  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 19:17:55.434154  1516 solver.cpp:237]     Train net output #1: loss = 0.750716 (* 1 = 0.750716 loss)
I1120 19:17:55.434154  1516 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1120 19:18:04.753832 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:18:05.138833  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_122000.caffemodel
I1120 19:18:05.166817  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_122000.solverstate
I1120 19:18:05.177817  1516 solver.cpp:330] Iteration 122000, Testing net (#0)
I1120 19:18:05.177817  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:18:07.466317 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:18:07.558317  1516 solver.cpp:397]     Test net output #0: accuracy = 0.73
I1120 19:18:07.558317  1516 solver.cpp:397]     Test net output #1: loss = 1.08128 (* 1 = 1.08128 loss)
I1120 19:18:07.653333  1516 solver.cpp:218] Iteration 122000 (8.18408 iter/s, 12.2188s/100 iters), loss = 0.518939
I1120 19:18:07.653832  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:18:07.653832  1516 solver.cpp:237]     Train net output #1: loss = 0.518939 (* 1 = 0.518939 loss)
I1120 19:18:07.653832  1516 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1120 19:18:17.458456  1516 solver.cpp:218] Iteration 122100 (10.1997 iter/s, 9.80419s/100 iters), loss = 0.611973
I1120 19:18:17.458456  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 19:18:17.458456  1516 solver.cpp:237]     Train net output #1: loss = 0.611973 (* 1 = 0.611973 loss)
I1120 19:18:17.458456  1516 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1120 19:18:27.264456  1516 solver.cpp:218] Iteration 122200 (10.198 iter/s, 9.80585s/100 iters), loss = 0.514702
I1120 19:18:27.264957  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:18:27.264957  1516 solver.cpp:237]     Train net output #1: loss = 0.514702 (* 1 = 0.514702 loss)
I1120 19:18:27.264957  1516 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1120 19:18:37.064265  1516 solver.cpp:218] Iteration 122300 (10.2052 iter/s, 9.79892s/100 iters), loss = 0.481798
I1120 19:18:37.064265  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:18:37.064265  1516 solver.cpp:237]     Train net output #1: loss = 0.481798 (* 1 = 0.481798 loss)
I1120 19:18:37.064265  1516 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1120 19:18:46.866241  1516 solver.cpp:218] Iteration 122400 (10.2025 iter/s, 9.80149s/100 iters), loss = 0.56266
I1120 19:18:46.866241  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:18:46.866241  1516 solver.cpp:237]     Train net output #1: loss = 0.56266 (* 1 = 0.56266 loss)
I1120 19:18:46.866241  1516 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1120 19:18:56.187662 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:18:56.576161  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_122500.caffemodel
I1120 19:18:56.602680  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_122500.solverstate
I1120 19:18:56.614181  1516 solver.cpp:330] Iteration 122500, Testing net (#0)
I1120 19:18:56.614181  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:18:58.910662 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:18:59.003162  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7285
I1120 19:18:59.003662  1516 solver.cpp:397]     Test net output #1: loss = 1.09196 (* 1 = 1.09196 loss)
I1120 19:18:59.098161  1516 solver.cpp:218] Iteration 122500 (8.17563 iter/s, 12.2315s/100 iters), loss = 0.487262
I1120 19:18:59.098662  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:18:59.098662  1516 solver.cpp:237]     Train net output #1: loss = 0.487262 (* 1 = 0.487262 loss)
I1120 19:18:59.098662  1516 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1120 19:19:08.901907  1516 solver.cpp:218] Iteration 122600 (10.2011 iter/s, 9.80285s/100 iters), loss = 0.533125
I1120 19:19:08.901907  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:19:08.901907  1516 solver.cpp:237]     Train net output #1: loss = 0.533125 (* 1 = 0.533125 loss)
I1120 19:19:08.901907  1516 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1120 19:19:18.695469  1516 solver.cpp:218] Iteration 122700 (10.2116 iter/s, 9.79281s/100 iters), loss = 0.627211
I1120 19:19:18.695469  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:19:18.695469  1516 solver.cpp:237]     Train net output #1: loss = 0.627211 (* 1 = 0.627211 loss)
I1120 19:19:18.695469  1516 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1120 19:19:28.486367  1516 solver.cpp:218] Iteration 122800 (10.2138 iter/s, 9.79063s/100 iters), loss = 0.631703
I1120 19:19:28.486877  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:19:28.486877  1516 solver.cpp:237]     Train net output #1: loss = 0.631703 (* 1 = 0.631703 loss)
I1120 19:19:28.486877  1516 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1120 19:19:38.286367  1516 solver.cpp:218] Iteration 122900 (10.205 iter/s, 9.79908s/100 iters), loss = 0.658737
I1120 19:19:38.286367  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:19:38.286367  1516 solver.cpp:237]     Train net output #1: loss = 0.658737 (* 1 = 0.658737 loss)
I1120 19:19:38.286367  1516 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1120 19:19:47.597188 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:19:47.986189  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_123000.caffemodel
I1120 19:19:48.013190  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_123000.solverstate
I1120 19:19:48.024693  1516 solver.cpp:330] Iteration 123000, Testing net (#0)
I1120 19:19:48.024693  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:19:50.320694 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:19:50.412192  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7338
I1120 19:19:50.412192  1516 solver.cpp:397]     Test net output #1: loss = 1.08077 (* 1 = 1.08077 loss)
I1120 19:19:50.508184  1516 solver.cpp:218] Iteration 123000 (8.18247 iter/s, 12.2212s/100 iters), loss = 0.398137
I1120 19:19:50.508184  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:19:50.508184  1516 solver.cpp:237]     Train net output #1: loss = 0.398137 (* 1 = 0.398137 loss)
I1120 19:19:50.508184  1516 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1120 19:20:00.258983  1516 solver.cpp:218] Iteration 123100 (10.2564 iter/s, 9.75004s/100 iters), loss = 0.647409
I1120 19:20:00.258983  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:20:00.258983  1516 solver.cpp:237]     Train net output #1: loss = 0.647409 (* 1 = 0.647409 loss)
I1120 19:20:00.258983  1516 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1120 19:20:09.940467  1516 solver.cpp:218] Iteration 123200 (10.3295 iter/s, 9.68099s/100 iters), loss = 0.482556
I1120 19:20:09.940467  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:20:09.940467  1516 solver.cpp:237]     Train net output #1: loss = 0.482556 (* 1 = 0.482556 loss)
I1120 19:20:09.940467  1516 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1120 19:20:19.590626  1516 solver.cpp:218] Iteration 123300 (10.3622 iter/s, 9.65046s/100 iters), loss = 0.509966
I1120 19:20:19.591626  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:20:19.591626  1516 solver.cpp:237]     Train net output #1: loss = 0.509966 (* 1 = 0.509966 loss)
I1120 19:20:19.591626  1516 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1120 19:20:29.233361  1516 solver.cpp:218] Iteration 123400 (10.3715 iter/s, 9.64182s/100 iters), loss = 0.594525
I1120 19:20:29.233361  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:20:29.233361  1516 solver.cpp:237]     Train net output #1: loss = 0.594525 (* 1 = 0.594525 loss)
I1120 19:20:29.233361  1516 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1120 19:20:38.401062 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:20:38.782585  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_123500.caffemodel
I1120 19:20:38.809087  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_123500.solverstate
I1120 19:20:38.821086  1516 solver.cpp:330] Iteration 123500, Testing net (#0)
I1120 19:20:38.821086  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:20:41.079311 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:20:41.170346  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7297
I1120 19:20:41.170346  1516 solver.cpp:397]     Test net output #1: loss = 1.09395 (* 1 = 1.09395 loss)
I1120 19:20:41.263332  1516 solver.cpp:218] Iteration 123500 (8.31286 iter/s, 12.0296s/100 iters), loss = 0.406213
I1120 19:20:41.263332  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:20:41.263332  1516 solver.cpp:237]     Train net output #1: loss = 0.406213 (* 1 = 0.406213 loss)
I1120 19:20:41.263332  1516 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1120 19:20:50.911054  1516 solver.cpp:218] Iteration 123600 (10.3661 iter/s, 9.64686s/100 iters), loss = 0.616795
I1120 19:20:50.911054  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:20:50.911054  1516 solver.cpp:237]     Train net output #1: loss = 0.616795 (* 1 = 0.616795 loss)
I1120 19:20:50.911054  1516 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1120 19:21:00.557842  1516 solver.cpp:218] Iteration 123700 (10.3668 iter/s, 9.64613s/100 iters), loss = 0.568974
I1120 19:21:00.557842  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:21:00.557842  1516 solver.cpp:237]     Train net output #1: loss = 0.568974 (* 1 = 0.568974 loss)
I1120 19:21:00.557842  1516 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1120 19:21:10.204139  1516 solver.cpp:218] Iteration 123800 (10.3675 iter/s, 9.64556s/100 iters), loss = 0.544784
I1120 19:21:10.204139  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:21:10.204139  1516 solver.cpp:237]     Train net output #1: loss = 0.544784 (* 1 = 0.544784 loss)
I1120 19:21:10.204139  1516 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1120 19:21:19.869920  1516 solver.cpp:218] Iteration 123900 (10.3462 iter/s, 9.66542s/100 iters), loss = 0.583881
I1120 19:21:19.869920  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:21:19.869920  1516 solver.cpp:237]     Train net output #1: loss = 0.583881 (* 1 = 0.583881 loss)
I1120 19:21:19.869920  1516 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1120 19:21:29.122109 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:21:29.507140  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_124000.caffemodel
I1120 19:21:29.533141  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_124000.solverstate
I1120 19:21:29.545645  1516 solver.cpp:330] Iteration 124000, Testing net (#0)
I1120 19:21:29.545645  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:21:31.824281 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:21:31.915287  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7281
I1120 19:21:31.915287  1516 solver.cpp:397]     Test net output #1: loss = 1.09611 (* 1 = 1.09611 loss)
I1120 19:21:32.010291  1516 solver.cpp:218] Iteration 124000 (8.23739 iter/s, 12.1398s/100 iters), loss = 0.46149
I1120 19:21:32.010291  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:21:32.010291  1516 solver.cpp:237]     Train net output #1: loss = 0.46149 (* 1 = 0.46149 loss)
I1120 19:21:32.010291  1516 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1120 19:21:41.667117  1516 solver.cpp:218] Iteration 124100 (10.3561 iter/s, 9.65615s/100 iters), loss = 0.544482
I1120 19:21:41.667117  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:21:41.667117  1516 solver.cpp:237]     Train net output #1: loss = 0.544482 (* 1 = 0.544482 loss)
I1120 19:21:41.667117  1516 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1120 19:21:51.316824  1516 solver.cpp:218] Iteration 124200 (10.3632 iter/s, 9.64949s/100 iters), loss = 0.595407
I1120 19:21:51.316824  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:21:51.316824  1516 solver.cpp:237]     Train net output #1: loss = 0.595407 (* 1 = 0.595407 loss)
I1120 19:21:51.316824  1516 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1120 19:22:00.958631  1516 solver.cpp:218] Iteration 124300 (10.372 iter/s, 9.6413s/100 iters), loss = 0.54809
I1120 19:22:00.958631  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:22:00.958631  1516 solver.cpp:237]     Train net output #1: loss = 0.54809 (* 1 = 0.54809 loss)
I1120 19:22:00.958631  1516 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1120 19:22:10.601439  1516 solver.cpp:218] Iteration 124400 (10.3707 iter/s, 9.64254s/100 iters), loss = 0.534623
I1120 19:22:10.601439  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:22:10.601439  1516 solver.cpp:237]     Train net output #1: loss = 0.534623 (* 1 = 0.534623 loss)
I1120 19:22:10.601439  1516 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1120 19:22:19.769093 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:22:20.148119  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_124500.caffemodel
I1120 19:22:20.174123  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_124500.solverstate
I1120 19:22:20.185123  1516 solver.cpp:330] Iteration 124500, Testing net (#0)
I1120 19:22:20.185123  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:22:22.441138 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:22:22.530669  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7312
I1120 19:22:22.530669  1516 solver.cpp:397]     Test net output #1: loss = 1.08356 (* 1 = 1.08356 loss)
I1120 19:22:22.624660  1516 solver.cpp:218] Iteration 124500 (8.31805 iter/s, 12.0221s/100 iters), loss = 0.481565
I1120 19:22:22.624660  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:22:22.624660  1516 solver.cpp:237]     Train net output #1: loss = 0.481565 (* 1 = 0.481565 loss)
I1120 19:22:22.624660  1516 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1120 19:22:32.271658  1516 solver.cpp:218] Iteration 124600 (10.3663 iter/s, 9.6466s/100 iters), loss = 0.584597
I1120 19:22:32.271658  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:22:32.271658  1516 solver.cpp:237]     Train net output #1: loss = 0.584597 (* 1 = 0.584597 loss)
I1120 19:22:32.271658  1516 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1120 19:22:41.921438  1516 solver.cpp:218] Iteration 124700 (10.3629 iter/s, 9.64978s/100 iters), loss = 0.440514
I1120 19:22:41.921438  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:22:41.922425  1516 solver.cpp:237]     Train net output #1: loss = 0.440514 (* 1 = 0.440514 loss)
I1120 19:22:41.922425  1516 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1120 19:22:51.566953  1516 solver.cpp:218] Iteration 124800 (10.3683 iter/s, 9.64479s/100 iters), loss = 0.561241
I1120 19:22:51.566953  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:22:51.566953  1516 solver.cpp:237]     Train net output #1: loss = 0.561241 (* 1 = 0.561241 loss)
I1120 19:22:51.566953  1516 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1120 19:23:01.211484  1516 solver.cpp:218] Iteration 124900 (10.3697 iter/s, 9.64346s/100 iters), loss = 0.486366
I1120 19:23:01.211484  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:23:01.211484  1516 solver.cpp:237]     Train net output #1: loss = 0.486366 (* 1 = 0.486366 loss)
I1120 19:23:01.211484  1516 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1120 19:23:10.383186 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:23:10.765216  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_125000.caffemodel
I1120 19:23:10.792217  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_125000.solverstate
I1120 19:23:10.803216  1516 solver.cpp:330] Iteration 125000, Testing net (#0)
I1120 19:23:10.803216  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:23:13.063714 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:23:13.153718  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7313
I1120 19:23:13.154719  1516 solver.cpp:397]     Test net output #1: loss = 1.08832 (* 1 = 1.08832 loss)
I1120 19:23:13.248220  1516 solver.cpp:218] Iteration 125000 (8.30828 iter/s, 12.0362s/100 iters), loss = 0.38657
I1120 19:23:13.248220  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:23:13.248220  1516 solver.cpp:237]     Train net output #1: loss = 0.38657 (* 1 = 0.38657 loss)
I1120 19:23:13.248220  1516 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1120 19:23:22.896495  1516 solver.cpp:218] Iteration 125100 (10.3652 iter/s, 9.64762s/100 iters), loss = 0.578794
I1120 19:23:22.896495  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:23:22.896495  1516 solver.cpp:237]     Train net output #1: loss = 0.578794 (* 1 = 0.578794 loss)
I1120 19:23:22.896495  1516 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1120 19:23:32.543215  1516 solver.cpp:218] Iteration 125200 (10.3669 iter/s, 9.64607s/100 iters), loss = 0.501209
I1120 19:23:32.543215  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:23:32.543215  1516 solver.cpp:237]     Train net output #1: loss = 0.501209 (* 1 = 0.501209 loss)
I1120 19:23:32.543215  1516 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1120 19:23:42.238324  1516 solver.cpp:218] Iteration 125300 (10.3147 iter/s, 9.69495s/100 iters), loss = 0.643856
I1120 19:23:42.238324  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:23:42.238826  1516 solver.cpp:237]     Train net output #1: loss = 0.643856 (* 1 = 0.643856 loss)
I1120 19:23:42.238826  1516 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1120 19:23:52.038823  1516 solver.cpp:218] Iteration 125400 (10.2042 iter/s, 9.7999s/100 iters), loss = 0.720495
I1120 19:23:52.039324  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 19:23:52.039324  1516 solver.cpp:237]     Train net output #1: loss = 0.720495 (* 1 = 0.720495 loss)
I1120 19:23:52.039324  1516 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1120 19:24:01.358325 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:24:01.746824  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_125500.caffemodel
I1120 19:24:01.772325  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_125500.solverstate
I1120 19:24:01.783825  1516 solver.cpp:330] Iteration 125500, Testing net (#0)
I1120 19:24:01.783825  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:24:04.079824 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:24:04.170825  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7298
I1120 19:24:04.170825  1516 solver.cpp:397]     Test net output #1: loss = 1.09626 (* 1 = 1.09626 loss)
I1120 19:24:04.265825  1516 solver.cpp:218] Iteration 125500 (8.17904 iter/s, 12.2264s/100 iters), loss = 0.440858
I1120 19:24:04.266324  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:24:04.266324  1516 solver.cpp:237]     Train net output #1: loss = 0.440858 (* 1 = 0.440858 loss)
I1120 19:24:04.266324  1516 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1120 19:24:14.062459  1516 solver.cpp:218] Iteration 125600 (10.2085 iter/s, 9.79577s/100 iters), loss = 0.494798
I1120 19:24:14.062459  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:24:14.062459  1516 solver.cpp:237]     Train net output #1: loss = 0.494798 (* 1 = 0.494798 loss)
I1120 19:24:14.062459  1516 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1120 19:24:23.852258  1516 solver.cpp:218] Iteration 125700 (10.2156 iter/s, 9.78892s/100 iters), loss = 0.516221
I1120 19:24:23.852258  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:24:23.852258  1516 solver.cpp:237]     Train net output #1: loss = 0.516221 (* 1 = 0.516221 loss)
I1120 19:24:23.852258  1516 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1120 19:24:33.654794  1516 solver.cpp:218] Iteration 125800 (10.2019 iter/s, 9.80214s/100 iters), loss = 0.51401
I1120 19:24:33.654794  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:24:33.654794  1516 solver.cpp:237]     Train net output #1: loss = 0.51401 (* 1 = 0.51401 loss)
I1120 19:24:33.654794  1516 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1120 19:24:43.470779  1516 solver.cpp:218] Iteration 125900 (10.1879 iter/s, 9.81554s/100 iters), loss = 0.749899
I1120 19:24:43.470779  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 19:24:43.470779  1516 solver.cpp:237]     Train net output #1: loss = 0.749899 (* 1 = 0.749899 loss)
I1120 19:24:43.470779  1516 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1120 19:24:52.803325 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:24:53.190325  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_126000.caffemodel
I1120 19:24:53.216325  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_126000.solverstate
I1120 19:24:53.227825  1516 solver.cpp:330] Iteration 126000, Testing net (#0)
I1120 19:24:53.227825  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:24:55.528839 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:24:55.621335  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7361
I1120 19:24:55.621335  1516 solver.cpp:397]     Test net output #1: loss = 1.08379 (* 1 = 1.08379 loss)
I1120 19:24:55.715878  1516 solver.cpp:218] Iteration 126000 (8.16703 iter/s, 12.2443s/100 iters), loss = 0.484103
I1120 19:24:55.715878  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:24:55.715878  1516 solver.cpp:237]     Train net output #1: loss = 0.484103 (* 1 = 0.484103 loss)
I1120 19:24:55.715878  1516 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1120 19:25:05.528231  1516 solver.cpp:218] Iteration 126100 (10.1918 iter/s, 9.81178s/100 iters), loss = 0.628423
I1120 19:25:05.528231  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:25:05.528231  1516 solver.cpp:237]     Train net output #1: loss = 0.628423 (* 1 = 0.628423 loss)
I1120 19:25:05.528231  1516 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1120 19:25:15.329924  1516 solver.cpp:218] Iteration 126200 (10.2029 iter/s, 9.80113s/100 iters), loss = 0.505857
I1120 19:25:15.329924  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:25:15.330435  1516 solver.cpp:237]     Train net output #1: loss = 0.505857 (* 1 = 0.505857 loss)
I1120 19:25:15.330435  1516 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1120 19:25:25.142424  1516 solver.cpp:218] Iteration 126300 (10.1918 iter/s, 9.81183s/100 iters), loss = 0.559761
I1120 19:25:25.142424  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:25:25.142424  1516 solver.cpp:237]     Train net output #1: loss = 0.559761 (* 1 = 0.559761 loss)
I1120 19:25:25.142925  1516 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1120 19:25:34.943917  1516 solver.cpp:218] Iteration 126400 (10.2032 iter/s, 9.80088s/100 iters), loss = 0.648471
I1120 19:25:34.943917  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:25:34.943917  1516 solver.cpp:237]     Train net output #1: loss = 0.648471 (* 1 = 0.648471 loss)
I1120 19:25:34.943917  1516 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1120 19:25:44.273916 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:25:44.661911  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_126500.caffemodel
I1120 19:25:44.688423  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_126500.solverstate
I1120 19:25:44.699923  1516 solver.cpp:330] Iteration 126500, Testing net (#0)
I1120 19:25:44.699923  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:25:46.994926 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:25:47.087417  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7259
I1120 19:25:47.087417  1516 solver.cpp:397]     Test net output #1: loss = 1.10298 (* 1 = 1.10298 loss)
I1120 19:25:47.182417  1516 solver.cpp:218] Iteration 126500 (8.17155 iter/s, 12.2376s/100 iters), loss = 0.544264
I1120 19:25:47.182417  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:25:47.182417  1516 solver.cpp:237]     Train net output #1: loss = 0.544264 (* 1 = 0.544264 loss)
I1120 19:25:47.182417  1516 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1120 19:25:56.996242  1516 solver.cpp:218] Iteration 126600 (10.1901 iter/s, 9.81341s/100 iters), loss = 0.578207
I1120 19:25:56.996242  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 19:25:56.996242  1516 solver.cpp:237]     Train net output #1: loss = 0.578207 (* 1 = 0.578207 loss)
I1120 19:25:56.996242  1516 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1120 19:26:06.805305  1516 solver.cpp:218] Iteration 126700 (10.1952 iter/s, 9.80851s/100 iters), loss = 0.463354
I1120 19:26:06.805305  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:26:06.805305  1516 solver.cpp:237]     Train net output #1: loss = 0.463354 (* 1 = 0.463354 loss)
I1120 19:26:06.805305  1516 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1120 19:26:16.606431  1516 solver.cpp:218] Iteration 126800 (10.2038 iter/s, 9.80024s/100 iters), loss = 0.529677
I1120 19:26:16.606431  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:26:16.606431  1516 solver.cpp:237]     Train net output #1: loss = 0.529677 (* 1 = 0.529677 loss)
I1120 19:26:16.606431  1516 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1120 19:26:26.417431  1516 solver.cpp:218] Iteration 126900 (10.1931 iter/s, 9.81058s/100 iters), loss = 0.556901
I1120 19:26:26.417431  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:26:26.417431  1516 solver.cpp:237]     Train net output #1: loss = 0.556901 (* 1 = 0.556901 loss)
I1120 19:26:26.417431  1516 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1120 19:26:35.739882 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:26:36.126381  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_127000.caffemodel
I1120 19:26:36.152881  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_127000.solverstate
I1120 19:26:36.164382  1516 solver.cpp:330] Iteration 127000, Testing net (#0)
I1120 19:26:36.164382  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:26:38.457881 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:26:38.550381  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7301
I1120 19:26:38.550881  1516 solver.cpp:397]     Test net output #1: loss = 1.09531 (* 1 = 1.09531 loss)
I1120 19:26:38.645381  1516 solver.cpp:218] Iteration 127000 (8.17831 iter/s, 12.2275s/100 iters), loss = 0.467348
I1120 19:26:38.645381  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:26:38.645381  1516 solver.cpp:237]     Train net output #1: loss = 0.467348 (* 1 = 0.467348 loss)
I1120 19:26:38.645381  1516 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1120 19:26:48.453516  1516 solver.cpp:218] Iteration 127100 (10.1963 iter/s, 9.8075s/100 iters), loss = 0.664281
I1120 19:26:48.453516  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 19:26:48.453516  1516 solver.cpp:237]     Train net output #1: loss = 0.664281 (* 1 = 0.664281 loss)
I1120 19:26:48.453516  1516 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1120 19:26:58.271929  1516 solver.cpp:218] Iteration 127200 (10.1857 iter/s, 9.81773s/100 iters), loss = 0.489724
I1120 19:26:58.271929  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:26:58.271929  1516 solver.cpp:237]     Train net output #1: loss = 0.489724 (* 1 = 0.489724 loss)
I1120 19:26:58.271929  1516 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1120 19:27:08.086824  1516 solver.cpp:218] Iteration 127300 (10.1892 iter/s, 9.81429s/100 iters), loss = 0.559958
I1120 19:27:08.086824  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:27:08.086824  1516 solver.cpp:237]     Train net output #1: loss = 0.559958 (* 1 = 0.559958 loss)
I1120 19:27:08.086824  1516 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1120 19:27:17.888207  1516 solver.cpp:218] Iteration 127400 (10.2032 iter/s, 9.80083s/100 iters), loss = 0.675369
I1120 19:27:17.888207  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:27:17.888207  1516 solver.cpp:237]     Train net output #1: loss = 0.675369 (* 1 = 0.675369 loss)
I1120 19:27:17.888207  1516 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1120 19:27:27.207841 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:27:27.595341  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_127500.caffemodel
I1120 19:27:27.622841  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_127500.solverstate
I1120 19:27:27.634841  1516 solver.cpp:330] Iteration 127500, Testing net (#0)
I1120 19:27:27.634841  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:27:29.927841 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:27:30.020342  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7253
I1120 19:27:30.020342  1516 solver.cpp:397]     Test net output #1: loss = 1.10454 (* 1 = 1.10454 loss)
I1120 19:27:30.116340  1516 solver.cpp:218] Iteration 127500 (8.17828 iter/s, 12.2275s/100 iters), loss = 0.427495
I1120 19:27:30.116340  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:27:30.116340  1516 solver.cpp:237]     Train net output #1: loss = 0.427495 (* 1 = 0.427495 loss)
I1120 19:27:30.116340  1516 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1120 19:27:39.956390  1516 solver.cpp:218] Iteration 127600 (10.1634 iter/s, 9.83927s/100 iters), loss = 0.53856
I1120 19:27:39.956390  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:27:39.956390  1516 solver.cpp:237]     Train net output #1: loss = 0.53856 (* 1 = 0.53856 loss)
I1120 19:27:39.956390  1516 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1120 19:27:49.783063  1516 solver.cpp:218] Iteration 127700 (10.1765 iter/s, 9.82652s/100 iters), loss = 0.493238
I1120 19:27:49.783063  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:27:49.783563  1516 solver.cpp:237]     Train net output #1: loss = 0.493238 (* 1 = 0.493238 loss)
I1120 19:27:49.783563  1516 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1120 19:27:59.589292  1516 solver.cpp:218] Iteration 127800 (10.1983 iter/s, 9.80553s/100 iters), loss = 0.56311
I1120 19:27:59.589292  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:27:59.589292  1516 solver.cpp:237]     Train net output #1: loss = 0.56311 (* 1 = 0.56311 loss)
I1120 19:27:59.589292  1516 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1120 19:28:09.430999  1516 solver.cpp:218] Iteration 127900 (10.1613 iter/s, 9.84122s/100 iters), loss = 0.524684
I1120 19:28:09.430999  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:28:09.430999  1516 solver.cpp:237]     Train net output #1: loss = 0.524684 (* 1 = 0.524684 loss)
I1120 19:28:09.431500  1516 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1120 19:28:18.792605 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:28:19.181372  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_128000.caffemodel
I1120 19:28:19.208372  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_128000.solverstate
I1120 19:28:19.219873  1516 solver.cpp:330] Iteration 128000, Testing net (#0)
I1120 19:28:19.219873  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:28:21.524871 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:28:21.616372  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7264
I1120 19:28:21.616372  1516 solver.cpp:397]     Test net output #1: loss = 1.09724 (* 1 = 1.09724 loss)
I1120 19:28:21.712371  1516 solver.cpp:218] Iteration 128000 (8.14296 iter/s, 12.2806s/100 iters), loss = 0.525725
I1120 19:28:21.712371  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:28:21.712371  1516 solver.cpp:237]     Train net output #1: loss = 0.525725 (* 1 = 0.525725 loss)
I1120 19:28:21.712371  1516 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1120 19:28:31.561105  1516 solver.cpp:218] Iteration 128100 (10.1545 iter/s, 9.84788s/100 iters), loss = 0.744218
I1120 19:28:31.561105  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1120 19:28:31.561105  1516 solver.cpp:237]     Train net output #1: loss = 0.744218 (* 1 = 0.744218 loss)
I1120 19:28:31.561105  1516 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1120 19:28:41.386267  1516 solver.cpp:218] Iteration 128200 (10.1784 iter/s, 9.82471s/100 iters), loss = 0.55272
I1120 19:28:41.386267  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:28:41.386267  1516 solver.cpp:237]     Train net output #1: loss = 0.55272 (* 1 = 0.55272 loss)
I1120 19:28:41.386267  1516 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1120 19:28:51.191151  1516 solver.cpp:218] Iteration 128300 (10.1997 iter/s, 9.80424s/100 iters), loss = 0.632975
I1120 19:28:51.191151  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:28:51.191151  1516 solver.cpp:237]     Train net output #1: loss = 0.632975 (* 1 = 0.632975 loss)
I1120 19:28:51.191151  1516 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1120 19:29:01.015697  1516 solver.cpp:218] Iteration 128400 (10.179 iter/s, 9.82417s/100 iters), loss = 0.562444
I1120 19:29:01.015697  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:29:01.015697  1516 solver.cpp:237]     Train net output #1: loss = 0.562444 (* 1 = 0.562444 loss)
I1120 19:29:01.015697  1516 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1120 19:29:10.342532 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:29:10.729532  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_128500.caffemodel
I1120 19:29:10.756533  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_128500.solverstate
I1120 19:29:10.768532  1516 solver.cpp:330] Iteration 128500, Testing net (#0)
I1120 19:29:10.768532  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:29:13.060575 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:29:13.152575  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7298
I1120 19:29:13.152575  1516 solver.cpp:397]     Test net output #1: loss = 1.09423 (* 1 = 1.09423 loss)
I1120 19:29:13.248585  1516 solver.cpp:218] Iteration 128500 (8.17509 iter/s, 12.2323s/100 iters), loss = 0.517916
I1120 19:29:13.248585  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:29:13.248585  1516 solver.cpp:237]     Train net output #1: loss = 0.517916 (* 1 = 0.517916 loss)
I1120 19:29:13.248585  1516 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1120 19:29:23.038550  1516 solver.cpp:218] Iteration 128600 (10.215 iter/s, 9.78949s/100 iters), loss = 0.627882
I1120 19:29:23.039050  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:29:23.039050  1516 solver.cpp:237]     Train net output #1: loss = 0.627882 (* 1 = 0.627882 loss)
I1120 19:29:23.039050  1516 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1120 19:29:32.837901  1516 solver.cpp:218] Iteration 128700 (10.2055 iter/s, 9.79868s/100 iters), loss = 0.504733
I1120 19:29:32.837901  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:29:32.837901  1516 solver.cpp:237]     Train net output #1: loss = 0.504733 (* 1 = 0.504733 loss)
I1120 19:29:32.837901  1516 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1120 19:29:42.646008  1516 solver.cpp:218] Iteration 128800 (10.1962 iter/s, 9.80759s/100 iters), loss = 0.464192
I1120 19:29:42.646509  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:29:42.646509  1516 solver.cpp:237]     Train net output #1: loss = 0.464192 (* 1 = 0.464192 loss)
I1120 19:29:42.646509  1516 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1120 19:29:52.448009  1516 solver.cpp:218] Iteration 128900 (10.2029 iter/s, 9.80112s/100 iters), loss = 0.655198
I1120 19:29:52.448009  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:29:52.448009  1516 solver.cpp:237]     Train net output #1: loss = 0.655198 (* 1 = 0.655198 loss)
I1120 19:29:52.448009  1516 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1120 19:30:01.792510 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:30:02.182509  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_129000.caffemodel
I1120 19:30:02.209009  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_129000.solverstate
I1120 19:30:02.220516  1516 solver.cpp:330] Iteration 129000, Testing net (#0)
I1120 19:30:02.220516  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:30:04.515509 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:30:04.607509  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7303
I1120 19:30:04.607509  1516 solver.cpp:397]     Test net output #1: loss = 1.09155 (* 1 = 1.09155 loss)
I1120 19:30:04.703008  1516 solver.cpp:218] Iteration 129000 (8.16042 iter/s, 12.2543s/100 iters), loss = 0.420262
I1120 19:30:04.703008  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:30:04.703008  1516 solver.cpp:237]     Train net output #1: loss = 0.420262 (* 1 = 0.420262 loss)
I1120 19:30:04.703008  1516 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1120 19:30:14.501420  1516 solver.cpp:218] Iteration 129100 (10.2062 iter/s, 9.79794s/100 iters), loss = 0.495527
I1120 19:30:14.501420  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:30:14.501420  1516 solver.cpp:237]     Train net output #1: loss = 0.495527 (* 1 = 0.495527 loss)
I1120 19:30:14.501420  1516 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1120 19:30:24.308495  1516 solver.cpp:218] Iteration 129200 (10.1976 iter/s, 9.80621s/100 iters), loss = 0.501962
I1120 19:30:24.308495  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:30:24.308495  1516 solver.cpp:237]     Train net output #1: loss = 0.501962 (* 1 = 0.501962 loss)
I1120 19:30:24.308495  1516 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1120 19:30:34.108813  1516 solver.cpp:218] Iteration 129300 (10.2039 iter/s, 9.80013s/100 iters), loss = 0.490932
I1120 19:30:34.109303  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:30:34.109303  1516 solver.cpp:237]     Train net output #1: loss = 0.490932 (* 1 = 0.490932 loss)
I1120 19:30:34.109303  1516 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1120 19:30:43.907649  1516 solver.cpp:218] Iteration 129400 (10.2062 iter/s, 9.79799s/100 iters), loss = 0.569856
I1120 19:30:43.907649  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:30:43.907649  1516 solver.cpp:237]     Train net output #1: loss = 0.569856 (* 1 = 0.569856 loss)
I1120 19:30:43.907649  1516 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1120 19:30:53.220471 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:30:53.605458  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_129500.caffemodel
I1120 19:30:53.631469  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_129500.solverstate
I1120 19:30:53.642956  1516 solver.cpp:330] Iteration 129500, Testing net (#0)
I1120 19:30:53.642956  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:30:55.933970 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:30:56.025966  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7294
I1120 19:30:56.025966  1516 solver.cpp:397]     Test net output #1: loss = 1.10108 (* 1 = 1.10108 loss)
I1120 19:30:56.121970  1516 solver.cpp:218] Iteration 129500 (8.18754 iter/s, 12.2137s/100 iters), loss = 0.375779
I1120 19:30:56.121970  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:30:56.121970  1516 solver.cpp:237]     Train net output #1: loss = 0.375779 (* 1 = 0.375779 loss)
I1120 19:30:56.121970  1516 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1120 19:31:05.929006  1516 solver.cpp:218] Iteration 129600 (10.1972 iter/s, 9.80663s/100 iters), loss = 0.608271
I1120 19:31:05.929006  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:31:05.929507  1516 solver.cpp:237]     Train net output #1: loss = 0.608271 (* 1 = 0.608271 loss)
I1120 19:31:05.929507  1516 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1120 19:31:15.737301  1516 solver.cpp:218] Iteration 129700 (10.1962 iter/s, 9.80756s/100 iters), loss = 0.530638
I1120 19:31:15.737301  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:31:15.737301  1516 solver.cpp:237]     Train net output #1: loss = 0.530638 (* 1 = 0.530638 loss)
I1120 19:31:15.737301  1516 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1120 19:31:25.530726  1516 solver.cpp:218] Iteration 129800 (10.2115 iter/s, 9.79287s/100 iters), loss = 0.450748
I1120 19:31:25.530726  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:31:25.530726  1516 solver.cpp:237]     Train net output #1: loss = 0.450748 (* 1 = 0.450748 loss)
I1120 19:31:25.530726  1516 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1120 19:31:35.327005  1516 solver.cpp:218] Iteration 129900 (10.2086 iter/s, 9.79567s/100 iters), loss = 0.69025
I1120 19:31:35.327005  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 19:31:35.327005  1516 solver.cpp:237]     Train net output #1: loss = 0.69025 (* 1 = 0.69025 loss)
I1120 19:31:35.327005  1516 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1120 19:31:44.642026 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:31:45.029026  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_130000.caffemodel
I1120 19:31:45.056025  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_130000.solverstate
I1120 19:31:45.067025  1516 solver.cpp:330] Iteration 130000, Testing net (#0)
I1120 19:31:45.067528  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:31:47.360024 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:31:47.452525  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7307
I1120 19:31:47.452525  1516 solver.cpp:397]     Test net output #1: loss = 1.10114 (* 1 = 1.10114 loss)
I1120 19:31:47.547524  1516 solver.cpp:218] Iteration 130000 (8.18339 iter/s, 12.2199s/100 iters), loss = 0.529438
I1120 19:31:47.547524  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:31:47.547524  1516 solver.cpp:237]     Train net output #1: loss = 0.529438 (* 1 = 0.529438 loss)
I1120 19:31:47.547524  1516 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1120 19:31:57.351979  1516 solver.cpp:218] Iteration 130100 (10.2003 iter/s, 9.8036s/100 iters), loss = 0.532145
I1120 19:31:57.351979  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:31:57.351979  1516 solver.cpp:237]     Train net output #1: loss = 0.532145 (* 1 = 0.532145 loss)
I1120 19:31:57.351979  1516 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1120 19:32:07.142475  1516 solver.cpp:218] Iteration 130200 (10.2142 iter/s, 9.7903s/100 iters), loss = 0.499812
I1120 19:32:07.142974  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:32:07.142974  1516 solver.cpp:237]     Train net output #1: loss = 0.499812 (* 1 = 0.499812 loss)
I1120 19:32:07.142974  1516 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1120 19:32:16.947278  1516 solver.cpp:218] Iteration 130300 (10.2001 iter/s, 9.80382s/100 iters), loss = 0.624795
I1120 19:32:16.947278  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:32:16.947278  1516 solver.cpp:237]     Train net output #1: loss = 0.624795 (* 1 = 0.624795 loss)
I1120 19:32:16.947278  1516 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1120 19:32:26.753636  1516 solver.cpp:218] Iteration 130400 (10.1978 iter/s, 9.80606s/100 iters), loss = 0.535548
I1120 19:32:26.753636  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:32:26.753636  1516 solver.cpp:237]     Train net output #1: loss = 0.535548 (* 1 = 0.535548 loss)
I1120 19:32:26.753636  1516 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1120 19:32:36.061460 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:32:36.448446  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_130500.caffemodel
I1120 19:32:36.475445  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_130500.solverstate
I1120 19:32:36.486945  1516 solver.cpp:330] Iteration 130500, Testing net (#0)
I1120 19:32:36.486945  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:32:38.777446 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:32:38.869446  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7292
I1120 19:32:38.869446  1516 solver.cpp:397]     Test net output #1: loss = 1.10064 (* 1 = 1.10064 loss)
I1120 19:32:38.963954  1516 solver.cpp:218] Iteration 130500 (8.19027 iter/s, 12.2096s/100 iters), loss = 0.481781
I1120 19:32:38.963954  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:32:38.963954  1516 solver.cpp:237]     Train net output #1: loss = 0.481781 (* 1 = 0.481781 loss)
I1120 19:32:38.963954  1516 sgd_solver.cpp:105] Iteration 130500, lr = 0.001
I1120 19:32:48.764787  1516 solver.cpp:218] Iteration 130600 (10.2036 iter/s, 9.80046s/100 iters), loss = 0.611187
I1120 19:32:48.764787  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:32:48.764787  1516 solver.cpp:237]     Train net output #1: loss = 0.611187 (* 1 = 0.611187 loss)
I1120 19:32:48.765290  1516 sgd_solver.cpp:105] Iteration 130600, lr = 0.001
I1120 19:32:58.563293  1516 solver.cpp:218] Iteration 130700 (10.2065 iter/s, 9.79769s/100 iters), loss = 0.485509
I1120 19:32:58.563293  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:32:58.563293  1516 solver.cpp:237]     Train net output #1: loss = 0.485509 (* 1 = 0.485509 loss)
I1120 19:32:58.563293  1516 sgd_solver.cpp:105] Iteration 130700, lr = 0.001
I1120 19:33:08.354646  1516 solver.cpp:218] Iteration 130800 (10.2136 iter/s, 9.79085s/100 iters), loss = 0.52291
I1120 19:33:08.354646  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:33:08.354646  1516 solver.cpp:237]     Train net output #1: loss = 0.52291 (* 1 = 0.52291 loss)
I1120 19:33:08.354646  1516 sgd_solver.cpp:105] Iteration 130800, lr = 0.001
I1120 19:33:18.153439  1516 solver.cpp:218] Iteration 130900 (10.2061 iter/s, 9.79801s/100 iters), loss = 0.686889
I1120 19:33:18.153439  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:33:18.153439  1516 solver.cpp:237]     Train net output #1: loss = 0.686889 (* 1 = 0.686889 loss)
I1120 19:33:18.153439  1516 sgd_solver.cpp:105] Iteration 130900, lr = 0.001
I1120 19:33:27.460801 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:33:27.848850  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_131000.caffemodel
I1120 19:33:27.875849  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_131000.solverstate
I1120 19:33:27.887349  1516 solver.cpp:330] Iteration 131000, Testing net (#0)
I1120 19:33:27.887349  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:33:30.179364 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:33:30.271356  1516 solver.cpp:397]     Test net output #0: accuracy = 0.729
I1120 19:33:30.271356  1516 solver.cpp:397]     Test net output #1: loss = 1.10407 (* 1 = 1.10407 loss)
I1120 19:33:30.365859  1516 solver.cpp:218] Iteration 131000 (8.18886 iter/s, 12.2117s/100 iters), loss = 0.439834
I1120 19:33:30.365859  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:33:30.365859  1516 solver.cpp:237]     Train net output #1: loss = 0.439834 (* 1 = 0.439834 loss)
I1120 19:33:30.365859  1516 sgd_solver.cpp:105] Iteration 131000, lr = 0.001
I1120 19:33:40.176790  1516 solver.cpp:218] Iteration 131100 (10.1931 iter/s, 9.81056s/100 iters), loss = 0.577511
I1120 19:33:40.176790  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:33:40.176790  1516 solver.cpp:237]     Train net output #1: loss = 0.577511 (* 1 = 0.577511 loss)
I1120 19:33:40.176790  1516 sgd_solver.cpp:105] Iteration 131100, lr = 0.001
I1120 19:33:49.982869  1516 solver.cpp:218] Iteration 131200 (10.1984 iter/s, 9.80546s/100 iters), loss = 0.485319
I1120 19:33:49.983369  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:33:49.983369  1516 solver.cpp:237]     Train net output #1: loss = 0.485319 (* 1 = 0.485319 loss)
I1120 19:33:49.983369  1516 sgd_solver.cpp:105] Iteration 131200, lr = 0.001
I1120 19:33:59.796423  1516 solver.cpp:218] Iteration 131300 (10.1908 iter/s, 9.81273s/100 iters), loss = 0.614399
I1120 19:33:59.796423  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:33:59.796423  1516 solver.cpp:237]     Train net output #1: loss = 0.614399 (* 1 = 0.614399 loss)
I1120 19:33:59.796423  1516 sgd_solver.cpp:105] Iteration 131300, lr = 0.001
I1120 19:34:09.666476  1516 solver.cpp:218] Iteration 131400 (10.1323 iter/s, 9.86942s/100 iters), loss = 0.51578
I1120 19:34:09.666476  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:34:09.666476  1516 solver.cpp:237]     Train net output #1: loss = 0.51578 (* 1 = 0.51578 loss)
I1120 19:34:09.666476  1516 sgd_solver.cpp:105] Iteration 131400, lr = 0.001
I1120 19:34:18.987629 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:34:19.374130  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_131500.caffemodel
I1120 19:34:19.400629  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_131500.solverstate
I1120 19:34:19.412631  1516 solver.cpp:330] Iteration 131500, Testing net (#0)
I1120 19:34:19.413130  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:34:21.707129 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:34:21.799129  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7265
I1120 19:34:21.799129  1516 solver.cpp:397]     Test net output #1: loss = 1.11299 (* 1 = 1.11299 loss)
I1120 19:34:21.894129  1516 solver.cpp:218] Iteration 131500 (8.17862 iter/s, 12.227s/100 iters), loss = 0.440901
I1120 19:34:21.894129  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:34:21.894129  1516 solver.cpp:237]     Train net output #1: loss = 0.440901 (* 1 = 0.440901 loss)
I1120 19:34:21.894129  1516 sgd_solver.cpp:105] Iteration 131500, lr = 0.001
I1120 19:34:31.695399  1516 solver.cpp:218] Iteration 131600 (10.2036 iter/s, 9.80048s/100 iters), loss = 0.584958
I1120 19:34:31.695399  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:34:31.695399  1516 solver.cpp:237]     Train net output #1: loss = 0.584958 (* 1 = 0.584958 loss)
I1120 19:34:31.695399  1516 sgd_solver.cpp:105] Iteration 131600, lr = 0.001
I1120 19:34:41.487478  1516 solver.cpp:218] Iteration 131700 (10.2129 iter/s, 9.79159s/100 iters), loss = 0.500926
I1120 19:34:41.487478  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:34:41.487478  1516 solver.cpp:237]     Train net output #1: loss = 0.500926 (* 1 = 0.500926 loss)
I1120 19:34:41.487478  1516 sgd_solver.cpp:105] Iteration 131700, lr = 0.001
I1120 19:34:51.270618  1516 solver.cpp:218] Iteration 131800 (10.2219 iter/s, 9.78288s/100 iters), loss = 0.711617
I1120 19:34:51.271109  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 19:34:51.271109  1516 solver.cpp:237]     Train net output #1: loss = 0.711617 (* 1 = 0.711617 loss)
I1120 19:34:51.271109  1516 sgd_solver.cpp:105] Iteration 131800, lr = 0.001
I1120 19:35:01.065909  1516 solver.cpp:218] Iteration 131900 (10.21 iter/s, 9.79427s/100 iters), loss = 0.474422
I1120 19:35:01.065909  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:35:01.065909  1516 solver.cpp:237]     Train net output #1: loss = 0.474422 (* 1 = 0.474422 loss)
I1120 19:35:01.065909  1516 sgd_solver.cpp:105] Iteration 131900, lr = 0.001
I1120 19:35:10.379302 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:35:10.765306  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_132000.caffemodel
I1120 19:35:10.791801  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_132000.solverstate
I1120 19:35:10.803297  1516 solver.cpp:330] Iteration 132000, Testing net (#0)
I1120 19:35:10.803807  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:35:13.099802 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:35:13.192302  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7312
I1120 19:35:13.192302  1516 solver.cpp:397]     Test net output #1: loss = 1.09671 (* 1 = 1.09671 loss)
I1120 19:35:13.287287  1516 solver.cpp:218] Iteration 132000 (8.18272 iter/s, 12.2209s/100 iters), loss = 0.423221
I1120 19:35:13.287287  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:35:13.287287  1516 solver.cpp:237]     Train net output #1: loss = 0.423221 (* 1 = 0.423221 loss)
I1120 19:35:13.287287  1516 sgd_solver.cpp:105] Iteration 132000, lr = 0.001
I1120 19:35:23.088371  1516 solver.cpp:218] Iteration 132100 (10.2032 iter/s, 9.8008s/100 iters), loss = 0.556092
I1120 19:35:23.088371  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:35:23.088872  1516 solver.cpp:237]     Train net output #1: loss = 0.556092 (* 1 = 0.556092 loss)
I1120 19:35:23.088872  1516 sgd_solver.cpp:105] Iteration 132100, lr = 0.001
I1120 19:35:32.892371  1516 solver.cpp:218] Iteration 132200 (10.2007 iter/s, 9.80321s/100 iters), loss = 0.534223
I1120 19:35:32.892371  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:35:32.892371  1516 solver.cpp:237]     Train net output #1: loss = 0.534223 (* 1 = 0.534223 loss)
I1120 19:35:32.892371  1516 sgd_solver.cpp:105] Iteration 132200, lr = 0.001
I1120 19:35:42.693917  1516 solver.cpp:218] Iteration 132300 (10.2028 iter/s, 9.80122s/100 iters), loss = 0.501061
I1120 19:35:42.694408  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:35:42.694408  1516 solver.cpp:237]     Train net output #1: loss = 0.501061 (* 1 = 0.501061 loss)
I1120 19:35:42.694408  1516 sgd_solver.cpp:105] Iteration 132300, lr = 0.001
I1120 19:35:52.497408  1516 solver.cpp:218] Iteration 132400 (10.2015 iter/s, 9.80251s/100 iters), loss = 0.548152
I1120 19:35:52.497408  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:35:52.497408  1516 solver.cpp:237]     Train net output #1: loss = 0.548152 (* 1 = 0.548152 loss)
I1120 19:35:52.497408  1516 sgd_solver.cpp:105] Iteration 132400, lr = 0.001
I1120 19:36:01.831542 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:36:02.217542  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_132500.caffemodel
I1120 19:36:02.245543  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_132500.solverstate
I1120 19:36:02.257043  1516 solver.cpp:330] Iteration 132500, Testing net (#0)
I1120 19:36:02.257043  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:36:04.551043 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:36:04.643543  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7257
I1120 19:36:04.643543  1516 solver.cpp:397]     Test net output #1: loss = 1.11518 (* 1 = 1.11518 loss)
I1120 19:36:04.738543  1516 solver.cpp:218] Iteration 132500 (8.1694 iter/s, 12.2408s/100 iters), loss = 0.462337
I1120 19:36:04.738543  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:36:04.739042  1516 solver.cpp:237]     Train net output #1: loss = 0.462337 (* 1 = 0.462337 loss)
I1120 19:36:04.739042  1516 sgd_solver.cpp:105] Iteration 132500, lr = 0.001
I1120 19:36:14.539547  1516 solver.cpp:218] Iteration 132600 (10.2038 iter/s, 9.80029s/100 iters), loss = 0.517954
I1120 19:36:14.539547  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:36:14.539547  1516 solver.cpp:237]     Train net output #1: loss = 0.517954 (* 1 = 0.517954 loss)
I1120 19:36:14.539547  1516 sgd_solver.cpp:105] Iteration 132600, lr = 0.001
I1120 19:36:24.328826  1516 solver.cpp:218] Iteration 132700 (10.2161 iter/s, 9.78845s/100 iters), loss = 0.50423
I1120 19:36:24.328826  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:36:24.328826  1516 solver.cpp:237]     Train net output #1: loss = 0.50423 (* 1 = 0.50423 loss)
I1120 19:36:24.328826  1516 sgd_solver.cpp:105] Iteration 132700, lr = 0.001
I1120 19:36:34.130403  1516 solver.cpp:218] Iteration 132800 (10.2028 iter/s, 9.80124s/100 iters), loss = 0.573295
I1120 19:36:34.130403  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:36:34.130904  1516 solver.cpp:237]     Train net output #1: loss = 0.573295 (* 1 = 0.573295 loss)
I1120 19:36:34.130904  1516 sgd_solver.cpp:105] Iteration 132800, lr = 0.001
I1120 19:36:43.934696  1516 solver.cpp:218] Iteration 132900 (10.2003 iter/s, 9.80364s/100 iters), loss = 0.524283
I1120 19:36:43.935186  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:36:43.935186  1516 solver.cpp:237]     Train net output #1: loss = 0.524283 (* 1 = 0.524283 loss)
I1120 19:36:43.935186  1516 sgd_solver.cpp:105] Iteration 132900, lr = 0.001
I1120 19:36:53.248301 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:36:53.635810  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_133000.caffemodel
I1120 19:36:53.662307  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_133000.solverstate
I1120 19:36:53.673808  1516 solver.cpp:330] Iteration 133000, Testing net (#0)
I1120 19:36:53.673808  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:36:55.971307 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:36:56.063292  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7273
I1120 19:36:56.063292  1516 solver.cpp:397]     Test net output #1: loss = 1.09732 (* 1 = 1.09732 loss)
I1120 19:36:56.158802  1516 solver.cpp:218] Iteration 133000 (8.18125 iter/s, 12.2231s/100 iters), loss = 0.476978
I1120 19:36:56.158802  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:36:56.158802  1516 solver.cpp:237]     Train net output #1: loss = 0.476978 (* 1 = 0.476978 loss)
I1120 19:36:56.158802  1516 sgd_solver.cpp:105] Iteration 133000, lr = 0.001
I1120 19:37:05.973302  1516 solver.cpp:218] Iteration 133100 (10.1895 iter/s, 9.814s/100 iters), loss = 0.543071
I1120 19:37:05.973302  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:37:05.973302  1516 solver.cpp:237]     Train net output #1: loss = 0.543071 (* 1 = 0.543071 loss)
I1120 19:37:05.973302  1516 sgd_solver.cpp:105] Iteration 133100, lr = 0.001
I1120 19:37:15.781328  1516 solver.cpp:218] Iteration 133200 (10.1962 iter/s, 9.80761s/100 iters), loss = 0.499116
I1120 19:37:15.781328  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:37:15.781328  1516 solver.cpp:237]     Train net output #1: loss = 0.499116 (* 1 = 0.499116 loss)
I1120 19:37:15.781328  1516 sgd_solver.cpp:105] Iteration 133200, lr = 0.001
I1120 19:37:25.571236  1516 solver.cpp:218] Iteration 133300 (10.2152 iter/s, 9.78938s/100 iters), loss = 0.547679
I1120 19:37:25.571236  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:37:25.571236  1516 solver.cpp:237]     Train net output #1: loss = 0.547679 (* 1 = 0.547679 loss)
I1120 19:37:25.571746  1516 sgd_solver.cpp:105] Iteration 133300, lr = 0.001
I1120 19:37:35.363698  1516 solver.cpp:218] Iteration 133400 (10.213 iter/s, 9.79147s/100 iters), loss = 0.515193
I1120 19:37:35.363698  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:37:35.363698  1516 solver.cpp:237]     Train net output #1: loss = 0.515193 (* 1 = 0.515193 loss)
I1120 19:37:35.363698  1516 sgd_solver.cpp:105] Iteration 133400, lr = 0.001
I1120 19:37:44.679543 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:37:45.066041  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_133500.caffemodel
I1120 19:37:45.092041  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_133500.solverstate
I1120 19:37:45.103540  1516 solver.cpp:330] Iteration 133500, Testing net (#0)
I1120 19:37:45.103540  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:37:47.395040 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:37:47.487041  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7272
I1120 19:37:47.487041  1516 solver.cpp:397]     Test net output #1: loss = 1.10019 (* 1 = 1.10019 loss)
I1120 19:37:47.583051  1516 solver.cpp:218] Iteration 133500 (8.18409 iter/s, 12.2188s/100 iters), loss = 0.40717
I1120 19:37:47.583051  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:37:47.583051  1516 solver.cpp:237]     Train net output #1: loss = 0.40717 (* 1 = 0.40717 loss)
I1120 19:37:47.583051  1516 sgd_solver.cpp:105] Iteration 133500, lr = 0.001
I1120 19:37:57.384002  1516 solver.cpp:218] Iteration 133600 (10.2037 iter/s, 9.80037s/100 iters), loss = 0.564175
I1120 19:37:57.384002  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:37:57.384002  1516 solver.cpp:237]     Train net output #1: loss = 0.564175 (* 1 = 0.564175 loss)
I1120 19:37:57.384002  1516 sgd_solver.cpp:105] Iteration 133600, lr = 0.001
I1120 19:38:07.186502  1516 solver.cpp:218] Iteration 133700 (10.2025 iter/s, 9.80151s/100 iters), loss = 0.461363
I1120 19:38:07.186502  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:38:07.186502  1516 solver.cpp:237]     Train net output #1: loss = 0.461363 (* 1 = 0.461363 loss)
I1120 19:38:07.186502  1516 sgd_solver.cpp:105] Iteration 133700, lr = 0.001
I1120 19:38:16.993002  1516 solver.cpp:218] Iteration 133800 (10.1976 iter/s, 9.80627s/100 iters), loss = 0.540638
I1120 19:38:16.993002  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:38:16.993002  1516 solver.cpp:237]     Train net output #1: loss = 0.540638 (* 1 = 0.540638 loss)
I1120 19:38:16.993002  1516 sgd_solver.cpp:105] Iteration 133800, lr = 0.001
I1120 19:38:26.794504  1516 solver.cpp:218] Iteration 133900 (10.2031 iter/s, 9.80096s/100 iters), loss = 0.551947
I1120 19:38:26.794504  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:38:26.794504  1516 solver.cpp:237]     Train net output #1: loss = 0.551947 (* 1 = 0.551947 loss)
I1120 19:38:26.794504  1516 sgd_solver.cpp:105] Iteration 133900, lr = 0.001
I1120 19:38:36.120005 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:38:36.506006  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_134000.caffemodel
I1120 19:38:36.531505  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_134000.solverstate
I1120 19:38:36.544014  1516 solver.cpp:330] Iteration 134000, Testing net (#0)
I1120 19:38:36.544014  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:38:38.839004 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:38:38.930012  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7281
I1120 19:38:38.930012  1516 solver.cpp:397]     Test net output #1: loss = 1.12074 (* 1 = 1.12074 loss)
I1120 19:38:39.025004  1516 solver.cpp:218] Iteration 134000 (8.17673 iter/s, 12.2298s/100 iters), loss = 0.575562
I1120 19:38:39.025004  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:38:39.025004  1516 solver.cpp:237]     Train net output #1: loss = 0.575562 (* 1 = 0.575562 loss)
I1120 19:38:39.025004  1516 sgd_solver.cpp:105] Iteration 134000, lr = 0.001
I1120 19:38:48.828505  1516 solver.cpp:218] Iteration 134100 (10.201 iter/s, 9.80292s/100 iters), loss = 0.603845
I1120 19:38:48.828505  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:38:48.828505  1516 solver.cpp:237]     Train net output #1: loss = 0.603845 (* 1 = 0.603845 loss)
I1120 19:38:48.828505  1516 sgd_solver.cpp:105] Iteration 134100, lr = 0.001
I1120 19:38:58.631841  1516 solver.cpp:218] Iteration 134200 (10.2012 iter/s, 9.80277s/100 iters), loss = 0.333954
I1120 19:38:58.631841  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1120 19:38:58.631841  1516 solver.cpp:237]     Train net output #1: loss = 0.333954 (* 1 = 0.333954 loss)
I1120 19:38:58.631841  1516 sgd_solver.cpp:105] Iteration 134200, lr = 0.001
I1120 19:39:08.430536  1516 solver.cpp:218] Iteration 134300 (10.2059 iter/s, 9.7983s/100 iters), loss = 0.534217
I1120 19:39:08.431036  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:39:08.431036  1516 solver.cpp:237]     Train net output #1: loss = 0.534217 (* 1 = 0.534217 loss)
I1120 19:39:08.431036  1516 sgd_solver.cpp:105] Iteration 134300, lr = 0.001
I1120 19:39:18.234536  1516 solver.cpp:218] Iteration 134400 (10.2008 iter/s, 9.8032s/100 iters), loss = 0.676604
I1120 19:39:18.234536  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 19:39:18.234536  1516 solver.cpp:237]     Train net output #1: loss = 0.676604 (* 1 = 0.676604 loss)
I1120 19:39:18.234536  1516 sgd_solver.cpp:105] Iteration 134400, lr = 0.001
I1120 19:39:27.559536 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:39:27.949038  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_134500.caffemodel
I1120 19:39:27.976536  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_134500.solverstate
I1120 19:39:27.988536  1516 solver.cpp:330] Iteration 134500, Testing net (#0)
I1120 19:39:27.988536  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:39:30.281036 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:39:30.372537  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7278
I1120 19:39:30.372537  1516 solver.cpp:397]     Test net output #1: loss = 1.11165 (* 1 = 1.11165 loss)
I1120 19:39:30.467536  1516 solver.cpp:218] Iteration 134500 (8.17509 iter/s, 12.2323s/100 iters), loss = 0.359993
I1120 19:39:30.467536  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:39:30.467536  1516 solver.cpp:237]     Train net output #1: loss = 0.359993 (* 1 = 0.359993 loss)
I1120 19:39:30.467536  1516 sgd_solver.cpp:105] Iteration 134500, lr = 0.001
I1120 19:39:40.270536  1516 solver.cpp:218] Iteration 134600 (10.2015 iter/s, 9.8025s/100 iters), loss = 0.45354
I1120 19:39:40.270536  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:39:40.270536  1516 solver.cpp:237]     Train net output #1: loss = 0.45354 (* 1 = 0.45354 loss)
I1120 19:39:40.270536  1516 sgd_solver.cpp:105] Iteration 134600, lr = 0.001
I1120 19:39:50.063102  1516 solver.cpp:218] Iteration 134700 (10.2126 iter/s, 9.7918s/100 iters), loss = 0.441876
I1120 19:39:50.063102  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:39:50.063102  1516 solver.cpp:237]     Train net output #1: loss = 0.441876 (* 1 = 0.441876 loss)
I1120 19:39:50.063102  1516 sgd_solver.cpp:105] Iteration 134700, lr = 0.001
I1120 19:39:59.858225  1516 solver.cpp:218] Iteration 134800 (10.2094 iter/s, 9.7949s/100 iters), loss = 0.550488
I1120 19:39:59.858225  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:39:59.858225  1516 solver.cpp:237]     Train net output #1: loss = 0.550488 (* 1 = 0.550488 loss)
I1120 19:39:59.858225  1516 sgd_solver.cpp:105] Iteration 134800, lr = 0.001
I1120 19:40:09.673490  1516 solver.cpp:218] Iteration 134900 (10.1887 iter/s, 9.81478s/100 iters), loss = 0.685292
I1120 19:40:09.673990  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:40:09.673990  1516 solver.cpp:237]     Train net output #1: loss = 0.685292 (* 1 = 0.685292 loss)
I1120 19:40:09.673990  1516 sgd_solver.cpp:105] Iteration 134900, lr = 0.001
I1120 19:40:18.993235 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:40:19.377238  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_135000.caffemodel
I1120 19:40:19.404234  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_135000.solverstate
I1120 19:40:19.415235  1516 solver.cpp:330] Iteration 135000, Testing net (#0)
I1120 19:40:19.415735  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:40:21.709735 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:40:21.801734  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7264
I1120 19:40:21.801734  1516 solver.cpp:397]     Test net output #1: loss = 1.11789 (* 1 = 1.11789 loss)
I1120 19:40:21.897234  1516 solver.cpp:218] Iteration 135000 (8.18138 iter/s, 12.2229s/100 iters), loss = 0.359086
I1120 19:40:21.897234  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:40:21.897234  1516 solver.cpp:237]     Train net output #1: loss = 0.359086 (* 1 = 0.359086 loss)
I1120 19:40:21.897234  1516 sgd_solver.cpp:105] Iteration 135000, lr = 0.001
I1120 19:40:31.695734  1516 solver.cpp:218] Iteration 135100 (10.2063 iter/s, 9.79785s/100 iters), loss = 0.563403
I1120 19:40:31.695734  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:40:31.695734  1516 solver.cpp:237]     Train net output #1: loss = 0.563403 (* 1 = 0.563403 loss)
I1120 19:40:31.695734  1516 sgd_solver.cpp:105] Iteration 135100, lr = 0.001
I1120 19:40:41.499234  1516 solver.cpp:218] Iteration 135200 (10.201 iter/s, 9.80293s/100 iters), loss = 0.509008
I1120 19:40:41.499234  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:40:41.499234  1516 solver.cpp:237]     Train net output #1: loss = 0.509008 (* 1 = 0.509008 loss)
I1120 19:40:41.499234  1516 sgd_solver.cpp:105] Iteration 135200, lr = 0.001
I1120 19:40:51.302147  1516 solver.cpp:218] Iteration 135300 (10.2016 iter/s, 9.80236s/100 iters), loss = 0.487416
I1120 19:40:51.302147  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:40:51.302147  1516 solver.cpp:237]     Train net output #1: loss = 0.487416 (* 1 = 0.487416 loss)
I1120 19:40:51.302147  1516 sgd_solver.cpp:105] Iteration 135300, lr = 0.001
I1120 19:41:01.101646  1516 solver.cpp:218] Iteration 135400 (10.2051 iter/s, 9.79906s/100 iters), loss = 0.581729
I1120 19:41:01.101646  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:41:01.101646  1516 solver.cpp:237]     Train net output #1: loss = 0.581729 (* 1 = 0.581729 loss)
I1120 19:41:01.101646  1516 sgd_solver.cpp:105] Iteration 135400, lr = 0.001
I1120 19:41:10.422147 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:41:10.810145  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_135500.caffemodel
I1120 19:41:10.837648  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_135500.solverstate
I1120 19:41:10.848647  1516 solver.cpp:330] Iteration 135500, Testing net (#0)
I1120 19:41:10.849148  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:41:13.140646 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:41:13.232148  1516 solver.cpp:397]     Test net output #0: accuracy = 0.73
I1120 19:41:13.232148  1516 solver.cpp:397]     Test net output #1: loss = 1.11453 (* 1 = 1.11453 loss)
I1120 19:41:13.328145  1516 solver.cpp:218] Iteration 135500 (8.17967 iter/s, 12.2254s/100 iters), loss = 0.365404
I1120 19:41:13.328145  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1120 19:41:13.328145  1516 solver.cpp:237]     Train net output #1: loss = 0.365404 (* 1 = 0.365404 loss)
I1120 19:41:13.328145  1516 sgd_solver.cpp:105] Iteration 135500, lr = 0.001
I1120 19:41:23.136145  1516 solver.cpp:218] Iteration 135600 (10.1963 iter/s, 9.80745s/100 iters), loss = 0.418904
I1120 19:41:23.136145  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:41:23.136145  1516 solver.cpp:237]     Train net output #1: loss = 0.418904 (* 1 = 0.418904 loss)
I1120 19:41:23.136145  1516 sgd_solver.cpp:105] Iteration 135600, lr = 0.001
I1120 19:41:32.933290  1516 solver.cpp:218] Iteration 135700 (10.2074 iter/s, 9.79681s/100 iters), loss = 0.384577
I1120 19:41:32.933290  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:41:32.933290  1516 solver.cpp:237]     Train net output #1: loss = 0.384577 (* 1 = 0.384577 loss)
I1120 19:41:32.933290  1516 sgd_solver.cpp:105] Iteration 135700, lr = 0.001
I1120 19:41:42.721856  1516 solver.cpp:218] Iteration 135800 (10.2168 iter/s, 9.78784s/100 iters), loss = 0.534112
I1120 19:41:42.721856  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:41:42.721856  1516 solver.cpp:237]     Train net output #1: loss = 0.534112 (* 1 = 0.534112 loss)
I1120 19:41:42.721856  1516 sgd_solver.cpp:105] Iteration 135800, lr = 0.001
I1120 19:41:52.519502  1516 solver.cpp:218] Iteration 135900 (10.207 iter/s, 9.79724s/100 iters), loss = 0.590263
I1120 19:41:52.520002  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:41:52.520002  1516 solver.cpp:237]     Train net output #1: loss = 0.590263 (* 1 = 0.590263 loss)
I1120 19:41:52.520002  1516 sgd_solver.cpp:105] Iteration 135900, lr = 0.001
I1120 19:42:01.840503 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:42:02.228502  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_136000.caffemodel
I1120 19:42:02.256502  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_136000.solverstate
I1120 19:42:02.268002  1516 solver.cpp:330] Iteration 136000, Testing net (#0)
I1120 19:42:02.268502  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:42:04.561002 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:42:04.654012  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7276
I1120 19:42:04.654012  1516 solver.cpp:397]     Test net output #1: loss = 1.115 (* 1 = 1.115 loss)
I1120 19:42:04.749501  1516 solver.cpp:218] Iteration 136000 (8.17729 iter/s, 12.229s/100 iters), loss = 0.409799
I1120 19:42:04.749501  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:42:04.749501  1516 solver.cpp:237]     Train net output #1: loss = 0.409799 (* 1 = 0.409799 loss)
I1120 19:42:04.749501  1516 sgd_solver.cpp:105] Iteration 136000, lr = 0.001
I1120 19:42:14.552783  1516 solver.cpp:218] Iteration 136100 (10.201 iter/s, 9.803s/100 iters), loss = 0.528667
I1120 19:42:14.552783  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:42:14.552783  1516 solver.cpp:237]     Train net output #1: loss = 0.528667 (* 1 = 0.528667 loss)
I1120 19:42:14.552783  1516 sgd_solver.cpp:105] Iteration 136100, lr = 0.001
I1120 19:42:24.359783  1516 solver.cpp:218] Iteration 136200 (10.1973 iter/s, 9.80653s/100 iters), loss = 0.470493
I1120 19:42:24.360283  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:42:24.360283  1516 solver.cpp:237]     Train net output #1: loss = 0.470493 (* 1 = 0.470493 loss)
I1120 19:42:24.360283  1516 sgd_solver.cpp:105] Iteration 136200, lr = 0.001
I1120 19:42:34.172783  1516 solver.cpp:218] Iteration 136300 (10.1915 iter/s, 9.81213s/100 iters), loss = 0.504537
I1120 19:42:34.172783  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:42:34.172783  1516 solver.cpp:237]     Train net output #1: loss = 0.504537 (* 1 = 0.504537 loss)
I1120 19:42:34.172783  1516 sgd_solver.cpp:105] Iteration 136300, lr = 0.001
I1120 19:42:43.978782  1516 solver.cpp:218] Iteration 136400 (10.1984 iter/s, 9.8055s/100 iters), loss = 0.619072
I1120 19:42:43.978782  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:42:43.978782  1516 solver.cpp:237]     Train net output #1: loss = 0.619072 (* 1 = 0.619072 loss)
I1120 19:42:43.978782  1516 sgd_solver.cpp:105] Iteration 136400, lr = 0.001
I1120 19:42:53.299654 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:42:53.688153  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_136500.caffemodel
I1120 19:42:53.715653  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_136500.solverstate
I1120 19:42:53.728157  1516 solver.cpp:330] Iteration 136500, Testing net (#0)
I1120 19:42:53.728157  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:42:56.020653 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:42:56.112154  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7281
I1120 19:42:56.112653  1516 solver.cpp:397]     Test net output #1: loss = 1.11126 (* 1 = 1.11126 loss)
I1120 19:42:56.207679  1516 solver.cpp:218] Iteration 136500 (8.17793 iter/s, 12.228s/100 iters), loss = 0.471105
I1120 19:42:56.207679  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:42:56.207679  1516 solver.cpp:237]     Train net output #1: loss = 0.471105 (* 1 = 0.471105 loss)
I1120 19:42:56.207679  1516 sgd_solver.cpp:105] Iteration 136500, lr = 0.001
I1120 19:43:06.000689  1516 solver.cpp:218] Iteration 136600 (10.2117 iter/s, 9.79272s/100 iters), loss = 0.508527
I1120 19:43:06.001180  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:43:06.001180  1516 solver.cpp:237]     Train net output #1: loss = 0.508527 (* 1 = 0.508527 loss)
I1120 19:43:06.001180  1516 sgd_solver.cpp:105] Iteration 136600, lr = 0.001
I1120 19:43:15.679893  1516 solver.cpp:218] Iteration 136700 (10.3324 iter/s, 9.67831s/100 iters), loss = 0.42826
I1120 19:43:15.679893  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:43:15.679893  1516 solver.cpp:237]     Train net output #1: loss = 0.42826 (* 1 = 0.42826 loss)
I1120 19:43:15.679893  1516 sgd_solver.cpp:105] Iteration 136700, lr = 0.001
I1120 19:43:25.337121  1516 solver.cpp:218] Iteration 136800 (10.3552 iter/s, 9.65701s/100 iters), loss = 0.590062
I1120 19:43:25.337623  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:43:25.337623  1516 solver.cpp:237]     Train net output #1: loss = 0.590062 (* 1 = 0.590062 loss)
I1120 19:43:25.337623  1516 sgd_solver.cpp:105] Iteration 136800, lr = 0.001
I1120 19:43:34.998540  1516 solver.cpp:218] Iteration 136900 (10.3512 iter/s, 9.66073s/100 iters), loss = 0.514987
I1120 19:43:34.998540  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:43:34.998540  1516 solver.cpp:237]     Train net output #1: loss = 0.514987 (* 1 = 0.514987 loss)
I1120 19:43:34.998540  1516 sgd_solver.cpp:105] Iteration 136900, lr = 0.001
I1120 19:43:44.165271 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:43:44.547288  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_137000.caffemodel
I1120 19:43:44.572794  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_137000.solverstate
I1120 19:43:44.584298  1516 solver.cpp:330] Iteration 137000, Testing net (#0)
I1120 19:43:44.584298  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:43:46.846455 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:43:46.938462  1516 solver.cpp:397]     Test net output #0: accuracy = 0.73
I1120 19:43:46.938462  1516 solver.cpp:397]     Test net output #1: loss = 1.11016 (* 1 = 1.11016 loss)
I1120 19:43:47.033455  1516 solver.cpp:218] Iteration 137000 (8.30963 iter/s, 12.0342s/100 iters), loss = 0.460348
I1120 19:43:47.033455  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:43:47.033455  1516 solver.cpp:237]     Train net output #1: loss = 0.460348 (* 1 = 0.460348 loss)
I1120 19:43:47.033455  1516 sgd_solver.cpp:105] Iteration 137000, lr = 0.001
I1120 19:43:56.830822  1516 solver.cpp:218] Iteration 137100 (10.2075 iter/s, 9.79675s/100 iters), loss = 0.552432
I1120 19:43:56.830822  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:43:56.830822  1516 solver.cpp:237]     Train net output #1: loss = 0.552432 (* 1 = 0.552432 loss)
I1120 19:43:56.830822  1516 sgd_solver.cpp:105] Iteration 137100, lr = 0.001
I1120 19:44:06.626332  1516 solver.cpp:218] Iteration 137200 (10.2093 iter/s, 9.79499s/100 iters), loss = 0.473545
I1120 19:44:06.626332  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:44:06.626332  1516 solver.cpp:237]     Train net output #1: loss = 0.473545 (* 1 = 0.473545 loss)
I1120 19:44:06.626332  1516 sgd_solver.cpp:105] Iteration 137200, lr = 0.001
I1120 19:44:16.427520  1516 solver.cpp:218] Iteration 137300 (10.2037 iter/s, 9.80038s/100 iters), loss = 0.454427
I1120 19:44:16.427520  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:44:16.427520  1516 solver.cpp:237]     Train net output #1: loss = 0.454427 (* 1 = 0.454427 loss)
I1120 19:44:16.427520  1516 sgd_solver.cpp:105] Iteration 137300, lr = 0.001
I1120 19:44:26.230751  1516 solver.cpp:218] Iteration 137400 (10.2012 iter/s, 9.8028s/100 iters), loss = 0.555628
I1120 19:44:26.230751  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:44:26.230751  1516 solver.cpp:237]     Train net output #1: loss = 0.555628 (* 1 = 0.555628 loss)
I1120 19:44:26.230751  1516 sgd_solver.cpp:105] Iteration 137400, lr = 0.001
I1120 19:44:35.588111 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:44:35.974612  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_137500.caffemodel
I1120 19:44:36.001611  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_137500.solverstate
I1120 19:44:36.013111  1516 solver.cpp:330] Iteration 137500, Testing net (#0)
I1120 19:44:36.013111  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:44:38.306113 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:44:38.398111  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7303
I1120 19:44:38.398612  1516 solver.cpp:397]     Test net output #1: loss = 1.12032 (* 1 = 1.12032 loss)
I1120 19:44:38.494110  1516 solver.cpp:218] Iteration 137500 (8.15472 iter/s, 12.2628s/100 iters), loss = 0.438019
I1120 19:44:38.494110  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:44:38.494110  1516 solver.cpp:237]     Train net output #1: loss = 0.438019 (* 1 = 0.438019 loss)
I1120 19:44:38.494110  1516 sgd_solver.cpp:105] Iteration 137500, lr = 0.001
I1120 19:44:48.301734  1516 solver.cpp:218] Iteration 137600 (10.1967 iter/s, 9.80711s/100 iters), loss = 0.555569
I1120 19:44:48.302242  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:44:48.302242  1516 solver.cpp:237]     Train net output #1: loss = 0.555569 (* 1 = 0.555569 loss)
I1120 19:44:48.302242  1516 sgd_solver.cpp:105] Iteration 137600, lr = 0.001
I1120 19:44:58.170264  1516 solver.cpp:218] Iteration 137700 (10.1339 iter/s, 9.86783s/100 iters), loss = 0.496438
I1120 19:44:58.170264  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:44:58.170264  1516 solver.cpp:237]     Train net output #1: loss = 0.496438 (* 1 = 0.496438 loss)
I1120 19:44:58.170264  1516 sgd_solver.cpp:105] Iteration 137700, lr = 0.001
I1120 19:45:08.051429  1516 solver.cpp:218] Iteration 137800 (10.1208 iter/s, 9.88061s/100 iters), loss = 0.591854
I1120 19:45:08.051429  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:45:08.051429  1516 solver.cpp:237]     Train net output #1: loss = 0.591854 (* 1 = 0.591854 loss)
I1120 19:45:08.051429  1516 sgd_solver.cpp:105] Iteration 137800, lr = 0.001
I1120 19:45:17.854545  1516 solver.cpp:218] Iteration 137900 (10.2015 iter/s, 9.8025s/100 iters), loss = 0.62077
I1120 19:45:17.854545  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:45:17.854545  1516 solver.cpp:237]     Train net output #1: loss = 0.62077 (* 1 = 0.62077 loss)
I1120 19:45:17.854545  1516 sgd_solver.cpp:105] Iteration 137900, lr = 0.001
I1120 19:45:27.041769 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:45:27.420694  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_138000.caffemodel
I1120 19:45:27.446198  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_138000.solverstate
I1120 19:45:27.457212  1516 solver.cpp:330] Iteration 138000, Testing net (#0)
I1120 19:45:27.457212  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:45:29.734169 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:45:29.826180  1516 solver.cpp:397]     Test net output #0: accuracy = 0.728
I1120 19:45:29.826180  1516 solver.cpp:397]     Test net output #1: loss = 1.12109 (* 1 = 1.12109 loss)
I1120 19:45:29.920215  1516 solver.cpp:218] Iteration 138000 (8.28845 iter/s, 12.065s/100 iters), loss = 0.386167
I1120 19:45:29.920215  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:45:29.920215  1516 solver.cpp:237]     Train net output #1: loss = 0.386167 (* 1 = 0.386167 loss)
I1120 19:45:29.920215  1516 sgd_solver.cpp:105] Iteration 138000, lr = 0.001
I1120 19:45:39.688202  1516 solver.cpp:218] Iteration 138100 (10.2381 iter/s, 9.76748s/100 iters), loss = 0.51513
I1120 19:45:39.688202  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:45:39.688202  1516 solver.cpp:237]     Train net output #1: loss = 0.51513 (* 1 = 0.51513 loss)
I1120 19:45:39.688202  1516 sgd_solver.cpp:105] Iteration 138100, lr = 0.001
I1120 19:45:49.488199  1516 solver.cpp:218] Iteration 138200 (10.204 iter/s, 9.80009s/100 iters), loss = 0.468745
I1120 19:45:49.489186  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:45:49.489186  1516 solver.cpp:237]     Train net output #1: loss = 0.468745 (* 1 = 0.468745 loss)
I1120 19:45:49.489186  1516 sgd_solver.cpp:105] Iteration 138200, lr = 0.001
I1120 19:45:59.132709  1516 solver.cpp:218] Iteration 138300 (10.37 iter/s, 9.64316s/100 iters), loss = 0.635313
I1120 19:45:59.132709  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:45:59.132709  1516 solver.cpp:237]     Train net output #1: loss = 0.635313 (* 1 = 0.635313 loss)
I1120 19:45:59.132709  1516 sgd_solver.cpp:105] Iteration 138300, lr = 0.001
I1120 19:46:08.870689  1516 solver.cpp:218] Iteration 138400 (10.2698 iter/s, 9.73726s/100 iters), loss = 0.565917
I1120 19:46:08.870689  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:46:08.870689  1516 solver.cpp:237]     Train net output #1: loss = 0.565917 (* 1 = 0.565917 loss)
I1120 19:46:08.870689  1516 sgd_solver.cpp:105] Iteration 138400, lr = 0.001
I1120 19:46:18.140625 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:46:18.534667  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_138500.caffemodel
I1120 19:46:18.564672  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_138500.solverstate
I1120 19:46:18.575690  1516 solver.cpp:330] Iteration 138500, Testing net (#0)
I1120 19:46:18.575690  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:46:20.862838 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:46:20.954354  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7265
I1120 19:46:20.954354  1516 solver.cpp:397]     Test net output #1: loss = 1.12498 (* 1 = 1.12498 loss)
I1120 19:46:21.047847  1516 solver.cpp:218] Iteration 138500 (8.21189 iter/s, 12.1775s/100 iters), loss = 0.387544
I1120 19:46:21.048848  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:46:21.048848  1516 solver.cpp:237]     Train net output #1: loss = 0.387544 (* 1 = 0.387544 loss)
I1120 19:46:21.048848  1516 sgd_solver.cpp:105] Iteration 138500, lr = 0.001
I1120 19:46:30.868866  1516 solver.cpp:218] Iteration 138600 (10.1834 iter/s, 9.81987s/100 iters), loss = 0.489002
I1120 19:46:30.869367  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:46:30.869367  1516 solver.cpp:237]     Train net output #1: loss = 0.489002 (* 1 = 0.489002 loss)
I1120 19:46:30.869367  1516 sgd_solver.cpp:105] Iteration 138600, lr = 0.001
I1120 19:46:40.537756  1516 solver.cpp:218] Iteration 138700 (10.343 iter/s, 9.66833s/100 iters), loss = 0.518313
I1120 19:46:40.537756  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:46:40.537756  1516 solver.cpp:237]     Train net output #1: loss = 0.518313 (* 1 = 0.518313 loss)
I1120 19:46:40.537756  1516 sgd_solver.cpp:105] Iteration 138700, lr = 0.001
I1120 19:46:50.247252  1516 solver.cpp:218] Iteration 138800 (10.3 iter/s, 9.70877s/100 iters), loss = 0.580243
I1120 19:46:50.247252  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:46:50.247252  1516 solver.cpp:237]     Train net output #1: loss = 0.580243 (* 1 = 0.580243 loss)
I1120 19:46:50.247252  1516 sgd_solver.cpp:105] Iteration 138800, lr = 0.001
I1120 19:46:59.910742  1516 solver.cpp:218] Iteration 138900 (10.3483 iter/s, 9.66345s/100 iters), loss = 0.498691
I1120 19:46:59.910742  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:46:59.910742  1516 solver.cpp:237]     Train net output #1: loss = 0.498691 (* 1 = 0.498691 loss)
I1120 19:46:59.910742  1516 sgd_solver.cpp:105] Iteration 138900, lr = 0.001
I1120 19:47:09.216945 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:47:09.596979  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_139000.caffemodel
I1120 19:47:09.622979  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_139000.solverstate
I1120 19:47:09.634980  1516 solver.cpp:330] Iteration 139000, Testing net (#0)
I1120 19:47:09.634980  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:47:11.895197 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:47:11.986203  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7275
I1120 19:47:11.986203  1516 solver.cpp:397]     Test net output #1: loss = 1.12008 (* 1 = 1.12008 loss)
I1120 19:47:12.079210  1516 solver.cpp:218] Iteration 139000 (8.21831 iter/s, 12.168s/100 iters), loss = 0.423703
I1120 19:47:12.079210  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:47:12.079210  1516 solver.cpp:237]     Train net output #1: loss = 0.423703 (* 1 = 0.423703 loss)
I1120 19:47:12.079210  1516 sgd_solver.cpp:105] Iteration 139000, lr = 0.001
I1120 19:47:21.721911  1516 solver.cpp:218] Iteration 139100 (10.3715 iter/s, 9.64181s/100 iters), loss = 0.576701
I1120 19:47:21.721911  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:47:21.721911  1516 solver.cpp:237]     Train net output #1: loss = 0.576701 (* 1 = 0.576701 loss)
I1120 19:47:21.721911  1516 sgd_solver.cpp:105] Iteration 139100, lr = 0.001
I1120 19:47:31.367621  1516 solver.cpp:218] Iteration 139200 (10.3678 iter/s, 9.64525s/100 iters), loss = 0.429554
I1120 19:47:31.367621  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:47:31.367621  1516 solver.cpp:237]     Train net output #1: loss = 0.429554 (* 1 = 0.429554 loss)
I1120 19:47:31.367621  1516 sgd_solver.cpp:105] Iteration 139200, lr = 0.001
I1120 19:47:41.007395  1516 solver.cpp:218] Iteration 139300 (10.374 iter/s, 9.63953s/100 iters), loss = 0.527658
I1120 19:47:41.007395  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:47:41.007395  1516 solver.cpp:237]     Train net output #1: loss = 0.527658 (* 1 = 0.527658 loss)
I1120 19:47:41.008394  1516 sgd_solver.cpp:105] Iteration 139300, lr = 0.001
I1120 19:47:50.653122  1516 solver.cpp:218] Iteration 139400 (10.3686 iter/s, 9.64448s/100 iters), loss = 0.500588
I1120 19:47:50.653122  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:47:50.653122  1516 solver.cpp:237]     Train net output #1: loss = 0.500588 (* 1 = 0.500588 loss)
I1120 19:47:50.653122  1516 sgd_solver.cpp:105] Iteration 139400, lr = 0.001
I1120 19:47:59.847800 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:48:00.228823  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_139500.caffemodel
I1120 19:48:00.255322  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_139500.solverstate
I1120 19:48:00.266822  1516 solver.cpp:330] Iteration 139500, Testing net (#0)
I1120 19:48:00.266822  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:48:02.527976 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:48:02.618979  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7316
I1120 19:48:02.618979  1516 solver.cpp:397]     Test net output #1: loss = 1.11772 (* 1 = 1.11772 loss)
I1120 19:48:02.712985  1516 solver.cpp:218] Iteration 139500 (8.29232 iter/s, 12.0594s/100 iters), loss = 0.533314
I1120 19:48:02.712985  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:48:02.712985  1516 solver.cpp:237]     Train net output #1: loss = 0.533314 (* 1 = 0.533314 loss)
I1120 19:48:02.712985  1516 sgd_solver.cpp:105] Iteration 139500, lr = 0.001
I1120 19:48:12.432919  1516 solver.cpp:218] Iteration 139600 (10.2885 iter/s, 9.71963s/100 iters), loss = 0.431453
I1120 19:48:12.432919  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:48:12.432919  1516 solver.cpp:237]     Train net output #1: loss = 0.431453 (* 1 = 0.431453 loss)
I1120 19:48:12.432919  1516 sgd_solver.cpp:105] Iteration 139600, lr = 0.001
I1120 19:48:22.113859  1516 solver.cpp:218] Iteration 139700 (10.3298 iter/s, 9.68075s/100 iters), loss = 0.540458
I1120 19:48:22.114861  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:48:22.114861  1516 solver.cpp:237]     Train net output #1: loss = 0.540458 (* 1 = 0.540458 loss)
I1120 19:48:22.114861  1516 sgd_solver.cpp:105] Iteration 139700, lr = 0.001
I1120 19:48:31.762553  1516 solver.cpp:218] Iteration 139800 (10.3658 iter/s, 9.64707s/100 iters), loss = 0.556825
I1120 19:48:31.762553  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:48:31.762553  1516 solver.cpp:237]     Train net output #1: loss = 0.556825 (* 1 = 0.556825 loss)
I1120 19:48:31.762553  1516 sgd_solver.cpp:105] Iteration 139800, lr = 0.001
I1120 19:48:41.411485  1516 solver.cpp:218] Iteration 139900 (10.3639 iter/s, 9.64886s/100 iters), loss = 0.627066
I1120 19:48:41.411485  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 19:48:41.411485  1516 solver.cpp:237]     Train net output #1: loss = 0.627066 (* 1 = 0.627066 loss)
I1120 19:48:41.411485  1516 sgd_solver.cpp:105] Iteration 139900, lr = 0.001
I1120 19:48:50.582221 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:48:50.964237  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_140000.caffemodel
I1120 19:48:50.990252  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_140000.solverstate
I1120 19:48:51.001253  1516 solver.cpp:330] Iteration 140000, Testing net (#0)
I1120 19:48:51.002254  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:48:53.260421 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:48:53.351433  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7265
I1120 19:48:53.351433  1516 solver.cpp:397]     Test net output #1: loss = 1.12648 (* 1 = 1.12648 loss)
I1120 19:48:53.444428  1516 solver.cpp:218] Iteration 140000 (8.31085 iter/s, 12.0325s/100 iters), loss = 0.509773
I1120 19:48:53.444428  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:48:53.444428  1516 solver.cpp:237]     Train net output #1: loss = 0.509772 (* 1 = 0.509772 loss)
I1120 19:48:53.444428  1516 sgd_solver.cpp:105] Iteration 140000, lr = 0.001
I1120 19:49:03.109249  1516 solver.cpp:218] Iteration 140100 (10.3479 iter/s, 9.66382s/100 iters), loss = 0.517888
I1120 19:49:03.109249  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:49:03.109249  1516 solver.cpp:237]     Train net output #1: loss = 0.517888 (* 1 = 0.517888 loss)
I1120 19:49:03.109249  1516 sgd_solver.cpp:105] Iteration 140100, lr = 0.001
I1120 19:49:12.752935  1516 solver.cpp:218] Iteration 140200 (10.37 iter/s, 9.6432s/100 iters), loss = 0.430931
I1120 19:49:12.752935  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:49:12.752935  1516 solver.cpp:237]     Train net output #1: loss = 0.430931 (* 1 = 0.430931 loss)
I1120 19:49:12.752935  1516 sgd_solver.cpp:105] Iteration 140200, lr = 0.001
I1120 19:49:22.402823  1516 solver.cpp:218] Iteration 140300 (10.3634 iter/s, 9.64934s/100 iters), loss = 0.469772
I1120 19:49:22.402823  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:49:22.402823  1516 solver.cpp:237]     Train net output #1: loss = 0.469772 (* 1 = 0.469772 loss)
I1120 19:49:22.402823  1516 sgd_solver.cpp:105] Iteration 140300, lr = 0.001
I1120 19:49:32.077317  1516 solver.cpp:218] Iteration 140400 (10.3371 iter/s, 9.67387s/100 iters), loss = 0.503165
I1120 19:49:32.077317  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:49:32.077317  1516 solver.cpp:237]     Train net output #1: loss = 0.503165 (* 1 = 0.503165 loss)
I1120 19:49:32.077317  1516 sgd_solver.cpp:105] Iteration 140400, lr = 0.001
I1120 19:49:41.367254 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:49:41.746771  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_140500.caffemodel
I1120 19:49:41.773275  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_140500.solverstate
I1120 19:49:41.784782  1516 solver.cpp:330] Iteration 140500, Testing net (#0)
I1120 19:49:41.784782  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:49:44.046928 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:49:44.137933  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7272
I1120 19:49:44.137933  1516 solver.cpp:397]     Test net output #1: loss = 1.12504 (* 1 = 1.12504 loss)
I1120 19:49:44.231937  1516 solver.cpp:218] Iteration 140500 (8.22767 iter/s, 12.1541s/100 iters), loss = 0.489007
I1120 19:49:44.231937  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:49:44.231937  1516 solver.cpp:237]     Train net output #1: loss = 0.489006 (* 1 = 0.489006 loss)
I1120 19:49:44.231937  1516 sgd_solver.cpp:105] Iteration 140500, lr = 0.001
I1120 19:49:53.879637  1516 solver.cpp:218] Iteration 140600 (10.3657 iter/s, 9.6472s/100 iters), loss = 0.539575
I1120 19:49:53.879637  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:49:53.879637  1516 solver.cpp:237]     Train net output #1: loss = 0.539575 (* 1 = 0.539575 loss)
I1120 19:49:53.879637  1516 sgd_solver.cpp:105] Iteration 140600, lr = 0.001
I1120 19:50:03.558523  1516 solver.cpp:218] Iteration 140700 (10.3323 iter/s, 9.67841s/100 iters), loss = 0.430802
I1120 19:50:03.558523  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:50:03.558523  1516 solver.cpp:237]     Train net output #1: loss = 0.430802 (* 1 = 0.430802 loss)
I1120 19:50:03.558523  1516 sgd_solver.cpp:105] Iteration 140700, lr = 0.001
I1120 19:50:13.217258  1516 solver.cpp:218] Iteration 140800 (10.3533 iter/s, 9.65877s/100 iters), loss = 0.445295
I1120 19:50:13.217258  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:50:13.217258  1516 solver.cpp:237]     Train net output #1: loss = 0.445295 (* 1 = 0.445295 loss)
I1120 19:50:13.217258  1516 sgd_solver.cpp:105] Iteration 140800, lr = 0.001
I1120 19:50:22.918759  1516 solver.cpp:218] Iteration 140900 (10.3086 iter/s, 9.70064s/100 iters), loss = 0.498674
I1120 19:50:22.918759  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1120 19:50:22.918759  1516 solver.cpp:237]     Train net output #1: loss = 0.498674 (* 1 = 0.498674 loss)
I1120 19:50:22.918759  1516 sgd_solver.cpp:105] Iteration 140900, lr = 0.001
I1120 19:50:32.087765 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:50:32.466936  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_141000.caffemodel
I1120 19:50:32.491935  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_141000.solverstate
I1120 19:50:32.503939  1516 solver.cpp:330] Iteration 141000, Testing net (#0)
I1120 19:50:32.503939  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:50:34.764528 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:50:34.855569  1516 solver.cpp:397]     Test net output #0: accuracy = 0.728
I1120 19:50:34.855569  1516 solver.cpp:397]     Test net output #1: loss = 1.11604 (* 1 = 1.11604 loss)
I1120 19:50:34.949604  1516 solver.cpp:218] Iteration 141000 (8.3128 iter/s, 12.0296s/100 iters), loss = 0.439431
I1120 19:50:34.949604  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:50:34.949604  1516 solver.cpp:237]     Train net output #1: loss = 0.439431 (* 1 = 0.439431 loss)
I1120 19:50:34.949604  1516 sgd_solver.cpp:105] Iteration 141000, lr = 0.001
I1120 19:50:44.590544  1516 solver.cpp:218] Iteration 141100 (10.3728 iter/s, 9.6406s/100 iters), loss = 0.408441
I1120 19:50:44.590544  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:50:44.590544  1516 solver.cpp:237]     Train net output #1: loss = 0.408441 (* 1 = 0.408441 loss)
I1120 19:50:44.590544  1516 sgd_solver.cpp:105] Iteration 141100, lr = 0.001
I1120 19:50:54.230362  1516 solver.cpp:218] Iteration 141200 (10.3736 iter/s, 9.63983s/100 iters), loss = 0.430041
I1120 19:50:54.230362  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:50:54.230362  1516 solver.cpp:237]     Train net output #1: loss = 0.430041 (* 1 = 0.430041 loss)
I1120 19:50:54.230362  1516 sgd_solver.cpp:105] Iteration 141200, lr = 0.001
I1120 19:51:03.925223  1516 solver.cpp:218] Iteration 141300 (10.3158 iter/s, 9.69388s/100 iters), loss = 0.461768
I1120 19:51:03.925223  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:51:03.925223  1516 solver.cpp:237]     Train net output #1: loss = 0.461768 (* 1 = 0.461768 loss)
I1120 19:51:03.925223  1516 sgd_solver.cpp:105] Iteration 141300, lr = 0.001
I1120 19:51:13.577026  1516 solver.cpp:218] Iteration 141400 (10.3614 iter/s, 9.65119s/100 iters), loss = 0.457664
I1120 19:51:13.577026  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:51:13.577026  1516 solver.cpp:237]     Train net output #1: loss = 0.457664 (* 1 = 0.457664 loss)
I1120 19:51:13.577026  1516 sgd_solver.cpp:105] Iteration 141400, lr = 0.001
I1120 19:51:22.756350 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:51:23.135493  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_141500.caffemodel
I1120 19:51:23.162498  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_141500.solverstate
I1120 19:51:23.173498  1516 solver.cpp:330] Iteration 141500, Testing net (#0)
I1120 19:51:23.173498  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:51:25.434412 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:51:25.525429  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7272
I1120 19:51:25.525429  1516 solver.cpp:397]     Test net output #1: loss = 1.11714 (* 1 = 1.11714 loss)
I1120 19:51:25.618947  1516 solver.cpp:218] Iteration 141500 (8.30457 iter/s, 12.0416s/100 iters), loss = 0.473885
I1120 19:51:25.619452  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:51:25.619452  1516 solver.cpp:237]     Train net output #1: loss = 0.473885 (* 1 = 0.473885 loss)
I1120 19:51:25.619452  1516 sgd_solver.cpp:105] Iteration 141500, lr = 0.001
I1120 19:51:35.280426  1516 solver.cpp:218] Iteration 141600 (10.351 iter/s, 9.66095s/100 iters), loss = 0.628428
I1120 19:51:35.280426  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:51:35.280426  1516 solver.cpp:237]     Train net output #1: loss = 0.628428 (* 1 = 0.628428 loss)
I1120 19:51:35.280426  1516 sgd_solver.cpp:105] Iteration 141600, lr = 0.001
I1120 19:51:44.936622  1516 solver.cpp:218] Iteration 141700 (10.3565 iter/s, 9.65579s/100 iters), loss = 0.378664
I1120 19:51:44.936622  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:51:44.936622  1516 solver.cpp:237]     Train net output #1: loss = 0.378663 (* 1 = 0.378663 loss)
I1120 19:51:44.936622  1516 sgd_solver.cpp:105] Iteration 141700, lr = 0.001
I1120 19:51:54.589987  1516 solver.cpp:218] Iteration 141800 (10.3603 iter/s, 9.65226s/100 iters), loss = 0.458782
I1120 19:51:54.589987  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:51:54.589987  1516 solver.cpp:237]     Train net output #1: loss = 0.458782 (* 1 = 0.458782 loss)
I1120 19:51:54.589987  1516 sgd_solver.cpp:105] Iteration 141800, lr = 0.001
I1120 19:52:04.234800  1516 solver.cpp:218] Iteration 141900 (10.3689 iter/s, 9.64427s/100 iters), loss = 0.5945
I1120 19:52:04.234800  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:52:04.234800  1516 solver.cpp:237]     Train net output #1: loss = 0.5945 (* 1 = 0.5945 loss)
I1120 19:52:04.234800  1516 sgd_solver.cpp:105] Iteration 141900, lr = 0.001
I1120 19:52:13.429497 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:52:13.810811  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_142000.caffemodel
I1120 19:52:13.837316  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_142000.solverstate
I1120 19:52:13.848817  1516 solver.cpp:330] Iteration 142000, Testing net (#0)
I1120 19:52:13.848817  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:52:16.134680 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:52:16.224730  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7271
I1120 19:52:16.224730  1516 solver.cpp:397]     Test net output #1: loss = 1.11777 (* 1 = 1.11777 loss)
I1120 19:52:16.318764  1516 solver.cpp:218] Iteration 142000 (8.27564 iter/s, 12.0837s/100 iters), loss = 0.444341
I1120 19:52:16.318764  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:52:16.318764  1516 solver.cpp:237]     Train net output #1: loss = 0.444341 (* 1 = 0.444341 loss)
I1120 19:52:16.318764  1516 sgd_solver.cpp:105] Iteration 142000, lr = 0.001
I1120 19:52:26.012658  1516 solver.cpp:218] Iteration 142100 (10.3167 iter/s, 9.69304s/100 iters), loss = 0.467465
I1120 19:52:26.012658  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:52:26.012658  1516 solver.cpp:237]     Train net output #1: loss = 0.467465 (* 1 = 0.467465 loss)
I1120 19:52:26.012658  1516 sgd_solver.cpp:105] Iteration 142100, lr = 0.001
I1120 19:52:35.696054  1516 solver.cpp:218] Iteration 142200 (10.3276 iter/s, 9.68275s/100 iters), loss = 0.584267
I1120 19:52:35.696054  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:52:35.696054  1516 solver.cpp:237]     Train net output #1: loss = 0.584267 (* 1 = 0.584267 loss)
I1120 19:52:35.696054  1516 sgd_solver.cpp:105] Iteration 142200, lr = 0.001
I1120 19:52:45.355299  1516 solver.cpp:218] Iteration 142300 (10.3534 iter/s, 9.65867s/100 iters), loss = 0.583335
I1120 19:52:45.355299  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:52:45.355299  1516 solver.cpp:237]     Train net output #1: loss = 0.583335 (* 1 = 0.583335 loss)
I1120 19:52:45.355299  1516 sgd_solver.cpp:105] Iteration 142300, lr = 0.001
I1120 19:52:55.007098  1516 solver.cpp:218] Iteration 142400 (10.3614 iter/s, 9.65122s/100 iters), loss = 0.550136
I1120 19:52:55.007098  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:52:55.007098  1516 solver.cpp:237]     Train net output #1: loss = 0.550136 (* 1 = 0.550136 loss)
I1120 19:52:55.007098  1516 sgd_solver.cpp:105] Iteration 142400, lr = 0.001
I1120 19:53:04.274830 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:53:04.655853  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_142500.caffemodel
I1120 19:53:04.682852  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_142500.solverstate
I1120 19:53:04.693851  1516 solver.cpp:330] Iteration 142500, Testing net (#0)
I1120 19:53:04.693851  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:53:06.952306 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:53:07.042306  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7285
I1120 19:53:07.042306  1516 solver.cpp:397]     Test net output #1: loss = 1.11974 (* 1 = 1.11974 loss)
I1120 19:53:07.136312  1516 solver.cpp:218] Iteration 142500 (8.24448 iter/s, 12.1293s/100 iters), loss = 0.431552
I1120 19:53:07.136312  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:53:07.136312  1516 solver.cpp:237]     Train net output #1: loss = 0.431552 (* 1 = 0.431552 loss)
I1120 19:53:07.136312  1516 sgd_solver.cpp:105] Iteration 142500, lr = 0.001
I1120 19:53:16.778112  1516 solver.cpp:218] Iteration 142600 (10.3725 iter/s, 9.64087s/100 iters), loss = 0.472864
I1120 19:53:16.778112  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:53:16.778112  1516 solver.cpp:237]     Train net output #1: loss = 0.472864 (* 1 = 0.472864 loss)
I1120 19:53:16.778112  1516 sgd_solver.cpp:105] Iteration 142600, lr = 0.001
I1120 19:53:26.422030  1516 solver.cpp:218] Iteration 142700 (10.3691 iter/s, 9.64406s/100 iters), loss = 0.355755
I1120 19:53:26.423030  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:53:26.423030  1516 solver.cpp:237]     Train net output #1: loss = 0.355755 (* 1 = 0.355755 loss)
I1120 19:53:26.423030  1516 sgd_solver.cpp:105] Iteration 142700, lr = 0.001
I1120 19:53:36.105841  1516 solver.cpp:218] Iteration 142800 (10.328 iter/s, 9.68245s/100 iters), loss = 0.563053
I1120 19:53:36.105841  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:53:36.105841  1516 solver.cpp:237]     Train net output #1: loss = 0.563053 (* 1 = 0.563053 loss)
I1120 19:53:36.105841  1516 sgd_solver.cpp:105] Iteration 142800, lr = 0.001
I1120 19:53:45.753609  1516 solver.cpp:218] Iteration 142900 (10.3658 iter/s, 9.64709s/100 iters), loss = 0.481564
I1120 19:53:45.753609  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:53:45.753609  1516 solver.cpp:237]     Train net output #1: loss = 0.481563 (* 1 = 0.481563 loss)
I1120 19:53:45.753609  1516 sgd_solver.cpp:105] Iteration 142900, lr = 0.001
I1120 19:53:55.049427 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:53:55.439450  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_143000.caffemodel
I1120 19:53:55.467453  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_143000.solverstate
I1120 19:53:55.478456  1516 solver.cpp:330] Iteration 143000, Testing net (#0)
I1120 19:53:55.478456  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:53:57.748633 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:53:57.842640  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7288
I1120 19:53:57.843641  1516 solver.cpp:397]     Test net output #1: loss = 1.12536 (* 1 = 1.12536 loss)
I1120 19:53:57.939678  1516 solver.cpp:218] Iteration 143000 (8.20652 iter/s, 12.1854s/100 iters), loss = 0.504951
I1120 19:53:57.939678  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:53:57.939678  1516 solver.cpp:237]     Train net output #1: loss = 0.504951 (* 1 = 0.504951 loss)
I1120 19:53:57.939678  1516 sgd_solver.cpp:105] Iteration 143000, lr = 0.001
I1120 19:54:07.640460  1516 solver.cpp:218] Iteration 143100 (10.3085 iter/s, 9.70069s/100 iters), loss = 0.513593
I1120 19:54:07.640460  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:54:07.640460  1516 solver.cpp:237]     Train net output #1: loss = 0.513593 (* 1 = 0.513593 loss)
I1120 19:54:07.640460  1516 sgd_solver.cpp:105] Iteration 143100, lr = 0.001
I1120 19:54:17.278690  1516 solver.cpp:218] Iteration 143200 (10.3762 iter/s, 9.63742s/100 iters), loss = 0.520758
I1120 19:54:17.278690  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:54:17.278690  1516 solver.cpp:237]     Train net output #1: loss = 0.520758 (* 1 = 0.520758 loss)
I1120 19:54:17.278690  1516 sgd_solver.cpp:105] Iteration 143200, lr = 0.001
I1120 19:54:26.918023  1516 solver.cpp:218] Iteration 143300 (10.3741 iter/s, 9.63935s/100 iters), loss = 0.477826
I1120 19:54:26.918023  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:54:26.918023  1516 solver.cpp:237]     Train net output #1: loss = 0.477826 (* 1 = 0.477826 loss)
I1120 19:54:26.918023  1516 sgd_solver.cpp:105] Iteration 143300, lr = 0.001
I1120 19:54:36.560802  1516 solver.cpp:218] Iteration 143400 (10.371 iter/s, 9.64224s/100 iters), loss = 0.537169
I1120 19:54:36.560802  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:54:36.560802  1516 solver.cpp:237]     Train net output #1: loss = 0.537169 (* 1 = 0.537169 loss)
I1120 19:54:36.560802  1516 sgd_solver.cpp:105] Iteration 143400, lr = 0.001
I1120 19:54:45.730500 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:54:46.108525  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_143500.caffemodel
I1120 19:54:46.134526  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_143500.solverstate
I1120 19:54:46.145527  1516 solver.cpp:330] Iteration 143500, Testing net (#0)
I1120 19:54:46.145527  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:54:48.408581 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:54:48.499583  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7245
I1120 19:54:48.499583  1516 solver.cpp:397]     Test net output #1: loss = 1.12449 (* 1 = 1.12449 loss)
I1120 19:54:48.593581  1516 solver.cpp:218] Iteration 143500 (8.31149 iter/s, 12.0315s/100 iters), loss = 0.389687
I1120 19:54:48.593581  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:54:48.593581  1516 solver.cpp:237]     Train net output #1: loss = 0.389687 (* 1 = 0.389687 loss)
I1120 19:54:48.593581  1516 sgd_solver.cpp:105] Iteration 143500, lr = 0.001
I1120 19:54:58.317430  1516 solver.cpp:218] Iteration 143600 (10.2844 iter/s, 9.72345s/100 iters), loss = 0.420399
I1120 19:54:58.317430  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:54:58.317930  1516 solver.cpp:237]     Train net output #1: loss = 0.420399 (* 1 = 0.420399 loss)
I1120 19:54:58.317930  1516 sgd_solver.cpp:105] Iteration 143600, lr = 0.001
I1120 19:55:07.961731  1516 solver.cpp:218] Iteration 143700 (10.3696 iter/s, 9.64359s/100 iters), loss = 0.434673
I1120 19:55:07.961731  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:55:07.961731  1516 solver.cpp:237]     Train net output #1: loss = 0.434673 (* 1 = 0.434673 loss)
I1120 19:55:07.961731  1516 sgd_solver.cpp:105] Iteration 143700, lr = 0.001
I1120 19:55:17.609987  1516 solver.cpp:218] Iteration 143800 (10.3653 iter/s, 9.64762s/100 iters), loss = 0.57271
I1120 19:55:17.609987  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:55:17.609987  1516 solver.cpp:237]     Train net output #1: loss = 0.57271 (* 1 = 0.57271 loss)
I1120 19:55:17.609987  1516 sgd_solver.cpp:105] Iteration 143800, lr = 0.001
I1120 19:55:27.266221  1516 solver.cpp:218] Iteration 143900 (10.3563 iter/s, 9.65597s/100 iters), loss = 0.625368
I1120 19:55:27.266221  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 19:55:27.266221  1516 solver.cpp:237]     Train net output #1: loss = 0.625368 (* 1 = 0.625368 loss)
I1120 19:55:27.266221  1516 sgd_solver.cpp:105] Iteration 143900, lr = 0.001
I1120 19:55:36.582324 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:55:36.965366  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_144000.caffemodel
I1120 19:55:36.992367  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_144000.solverstate
I1120 19:55:37.003366  1516 solver.cpp:330] Iteration 144000, Testing net (#0)
I1120 19:55:37.003366  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:55:39.275478 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:55:39.367489  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7259
I1120 19:55:39.367489  1516 solver.cpp:397]     Test net output #1: loss = 1.12896 (* 1 = 1.12896 loss)
I1120 19:55:39.461521  1516 solver.cpp:218] Iteration 144000 (8.20055 iter/s, 12.1943s/100 iters), loss = 0.345472
I1120 19:55:39.461521  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:55:39.461521  1516 solver.cpp:237]     Train net output #1: loss = 0.345472 (* 1 = 0.345472 loss)
I1120 19:55:39.461521  1516 sgd_solver.cpp:105] Iteration 144000, lr = 0.001
I1120 19:55:49.237534  1516 solver.cpp:218] Iteration 144100 (10.229 iter/s, 9.77616s/100 iters), loss = 0.553226
I1120 19:55:49.237534  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:55:49.237534  1516 solver.cpp:237]     Train net output #1: loss = 0.553226 (* 1 = 0.553226 loss)
I1120 19:55:49.237534  1516 sgd_solver.cpp:105] Iteration 144100, lr = 0.001
I1120 19:55:59.087441  1516 solver.cpp:218] Iteration 144200 (10.1532 iter/s, 9.8491s/100 iters), loss = 0.375337
I1120 19:55:59.087441  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:55:59.087441  1516 solver.cpp:237]     Train net output #1: loss = 0.375337 (* 1 = 0.375337 loss)
I1120 19:55:59.087441  1516 sgd_solver.cpp:105] Iteration 144200, lr = 0.001
I1120 19:56:08.855712  1516 solver.cpp:218] Iteration 144300 (10.238 iter/s, 9.76753s/100 iters), loss = 0.50667
I1120 19:56:08.855712  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:56:08.855712  1516 solver.cpp:237]     Train net output #1: loss = 0.50667 (* 1 = 0.50667 loss)
I1120 19:56:08.855712  1516 sgd_solver.cpp:105] Iteration 144300, lr = 0.001
I1120 19:56:18.585927  1516 solver.cpp:218] Iteration 144400 (10.2776 iter/s, 9.72989s/100 iters), loss = 0.517586
I1120 19:56:18.585927  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 19:56:18.585927  1516 solver.cpp:237]     Train net output #1: loss = 0.517585 (* 1 = 0.517585 loss)
I1120 19:56:18.585927  1516 sgd_solver.cpp:105] Iteration 144400, lr = 0.001
I1120 19:56:27.885720 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:56:28.267760  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_144500.caffemodel
I1120 19:56:28.292759  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_144500.solverstate
I1120 19:56:28.303759  1516 solver.cpp:330] Iteration 144500, Testing net (#0)
I1120 19:56:28.303759  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:56:30.569926 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:56:30.660931  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7255
I1120 19:56:30.660931  1516 solver.cpp:397]     Test net output #1: loss = 1.13435 (* 1 = 1.13435 loss)
I1120 19:56:30.754935  1516 solver.cpp:218] Iteration 144500 (8.21837 iter/s, 12.1679s/100 iters), loss = 0.362771
I1120 19:56:30.754935  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1120 19:56:30.754935  1516 solver.cpp:237]     Train net output #1: loss = 0.362771 (* 1 = 0.362771 loss)
I1120 19:56:30.754935  1516 sgd_solver.cpp:105] Iteration 144500, lr = 0.001
I1120 19:56:40.432302  1516 solver.cpp:218] Iteration 144600 (10.3337 iter/s, 9.67705s/100 iters), loss = 0.57371
I1120 19:56:40.432302  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:56:40.432302  1516 solver.cpp:237]     Train net output #1: loss = 0.57371 (* 1 = 0.57371 loss)
I1120 19:56:40.432302  1516 sgd_solver.cpp:105] Iteration 144600, lr = 0.001
I1120 19:56:50.119141  1516 solver.cpp:218] Iteration 144700 (10.3242 iter/s, 9.68599s/100 iters), loss = 0.45029
I1120 19:56:50.119141  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:56:50.119141  1516 solver.cpp:237]     Train net output #1: loss = 0.45029 (* 1 = 0.45029 loss)
I1120 19:56:50.119141  1516 sgd_solver.cpp:105] Iteration 144700, lr = 0.001
I1120 19:56:59.921205  1516 solver.cpp:218] Iteration 144800 (10.2021 iter/s, 9.80193s/100 iters), loss = 0.616383
I1120 19:56:59.921205  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:56:59.921205  1516 solver.cpp:237]     Train net output #1: loss = 0.616383 (* 1 = 0.616383 loss)
I1120 19:56:59.921205  1516 sgd_solver.cpp:105] Iteration 144800, lr = 0.001
I1120 19:57:09.592525  1516 solver.cpp:218] Iteration 144900 (10.34 iter/s, 9.67115s/100 iters), loss = 0.560471
I1120 19:57:09.592525  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:57:09.592525  1516 solver.cpp:237]     Train net output #1: loss = 0.560471 (* 1 = 0.560471 loss)
I1120 19:57:09.592525  1516 sgd_solver.cpp:105] Iteration 144900, lr = 0.001
I1120 19:57:18.821218 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:57:19.199260  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_145000.caffemodel
I1120 19:57:19.226261  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_145000.solverstate
I1120 19:57:19.237262  1516 solver.cpp:330] Iteration 145000, Testing net (#0)
I1120 19:57:19.237262  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:57:21.551487 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:57:21.643494  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7261
I1120 19:57:21.643494  1516 solver.cpp:397]     Test net output #1: loss = 1.13743 (* 1 = 1.13743 loss)
I1120 19:57:21.740500  1516 solver.cpp:218] Iteration 145000 (8.23283 iter/s, 12.1465s/100 iters), loss = 0.421256
I1120 19:57:21.740500  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:57:21.740500  1516 solver.cpp:237]     Train net output #1: loss = 0.421256 (* 1 = 0.421256 loss)
I1120 19:57:21.740500  1516 sgd_solver.cpp:105] Iteration 145000, lr = 0.001
I1120 19:57:31.426415  1516 solver.cpp:218] Iteration 145100 (10.3243 iter/s, 9.68591s/100 iters), loss = 0.553316
I1120 19:57:31.426415  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 19:57:31.426415  1516 solver.cpp:237]     Train net output #1: loss = 0.553316 (* 1 = 0.553316 loss)
I1120 19:57:31.426415  1516 sgd_solver.cpp:105] Iteration 145100, lr = 0.001
I1120 19:57:41.114307  1516 solver.cpp:218] Iteration 145200 (10.3226 iter/s, 9.68748s/100 iters), loss = 0.417846
I1120 19:57:41.114307  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:57:41.114307  1516 solver.cpp:237]     Train net output #1: loss = 0.417846 (* 1 = 0.417846 loss)
I1120 19:57:41.114307  1516 sgd_solver.cpp:105] Iteration 145200, lr = 0.001
I1120 19:57:50.982386  1516 solver.cpp:218] Iteration 145300 (10.1347 iter/s, 9.86709s/100 iters), loss = 0.615389
I1120 19:57:50.982386  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:57:50.982386  1516 solver.cpp:237]     Train net output #1: loss = 0.615389 (* 1 = 0.615389 loss)
I1120 19:57:50.982386  1516 sgd_solver.cpp:105] Iteration 145300, lr = 0.001
I1120 19:58:00.831352  1516 solver.cpp:218] Iteration 145400 (10.1535 iter/s, 9.84878s/100 iters), loss = 0.473481
I1120 19:58:00.832352  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:58:00.832352  1516 solver.cpp:237]     Train net output #1: loss = 0.473481 (* 1 = 0.473481 loss)
I1120 19:58:00.832352  1516 sgd_solver.cpp:105] Iteration 145400, lr = 0.001
I1120 19:58:10.180194 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:58:10.568264  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_145500.caffemodel
I1120 19:58:10.597263  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_145500.solverstate
I1120 19:58:10.609264  1516 solver.cpp:330] Iteration 145500, Testing net (#0)
I1120 19:58:10.609264  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:58:12.915791 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:58:13.007817  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7302
I1120 19:58:13.007817  1516 solver.cpp:397]     Test net output #1: loss = 1.13101 (* 1 = 1.13101 loss)
I1120 19:58:13.101466  1516 solver.cpp:218] Iteration 145500 (8.1504 iter/s, 12.2693s/100 iters), loss = 0.415451
I1120 19:58:13.101466  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 19:58:13.101466  1516 solver.cpp:237]     Train net output #1: loss = 0.415451 (* 1 = 0.415451 loss)
I1120 19:58:13.101466  1516 sgd_solver.cpp:105] Iteration 145500, lr = 0.001
I1120 19:58:22.938009  1516 solver.cpp:218] Iteration 145600 (10.1669 iter/s, 9.83585s/100 iters), loss = 0.536572
I1120 19:58:22.938009  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:58:22.938009  1516 solver.cpp:237]     Train net output #1: loss = 0.536572 (* 1 = 0.536572 loss)
I1120 19:58:22.938009  1516 sgd_solver.cpp:105] Iteration 145600, lr = 0.001
I1120 19:58:32.823549  1516 solver.cpp:218] Iteration 145700 (10.1161 iter/s, 9.88522s/100 iters), loss = 0.35031
I1120 19:58:32.823549  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:58:32.823549  1516 solver.cpp:237]     Train net output #1: loss = 0.35031 (* 1 = 0.35031 loss)
I1120 19:58:32.823549  1516 sgd_solver.cpp:105] Iteration 145700, lr = 0.001
I1120 19:58:42.741030  1516 solver.cpp:218] Iteration 145800 (10.0841 iter/s, 9.91665s/100 iters), loss = 0.493552
I1120 19:58:42.741030  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 19:58:42.741030  1516 solver.cpp:237]     Train net output #1: loss = 0.493552 (* 1 = 0.493552 loss)
I1120 19:58:42.741030  1516 sgd_solver.cpp:105] Iteration 145800, lr = 0.001
I1120 19:58:52.490672  1516 solver.cpp:218] Iteration 145900 (10.2574 iter/s, 9.74904s/100 iters), loss = 0.459239
I1120 19:58:52.490672  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 19:58:52.490672  1516 solver.cpp:237]     Train net output #1: loss = 0.459239 (* 1 = 0.459239 loss)
I1120 19:58:52.490672  1516 sgd_solver.cpp:105] Iteration 145900, lr = 0.001
I1120 19:59:01.756453 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:59:02.135494  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_146000.caffemodel
I1120 19:59:02.161998  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_146000.solverstate
I1120 19:59:02.172998  1516 solver.cpp:330] Iteration 146000, Testing net (#0)
I1120 19:59:02.172998  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:59:04.434672 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:59:04.525705  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7262
I1120 19:59:04.525705  1516 solver.cpp:397]     Test net output #1: loss = 1.12783 (* 1 = 1.12783 loss)
I1120 19:59:04.619715  1516 solver.cpp:218] Iteration 146000 (8.24491 iter/s, 12.1287s/100 iters), loss = 0.416945
I1120 19:59:04.619715  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 19:59:04.620715  1516 solver.cpp:237]     Train net output #1: loss = 0.416945 (* 1 = 0.416945 loss)
I1120 19:59:04.620715  1516 sgd_solver.cpp:105] Iteration 146000, lr = 0.001
I1120 19:59:14.308715  1516 solver.cpp:218] Iteration 146100 (10.3226 iter/s, 9.6875s/100 iters), loss = 0.510141
I1120 19:59:14.308715  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 19:59:14.308715  1516 solver.cpp:237]     Train net output #1: loss = 0.510141 (* 1 = 0.510141 loss)
I1120 19:59:14.308715  1516 sgd_solver.cpp:105] Iteration 146100, lr = 0.001
I1120 19:59:24.155738  1516 solver.cpp:218] Iteration 146200 (10.1553 iter/s, 9.8471s/100 iters), loss = 0.367341
I1120 19:59:24.155738  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 19:59:24.155738  1516 solver.cpp:237]     Train net output #1: loss = 0.367341 (* 1 = 0.367341 loss)
I1120 19:59:24.155738  1516 sgd_solver.cpp:105] Iteration 146200, lr = 0.001
I1120 19:59:33.998733  1516 solver.cpp:218] Iteration 146300 (10.1608 iter/s, 9.84174s/100 iters), loss = 0.424322
I1120 19:59:33.998733  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:59:33.998733  1516 solver.cpp:237]     Train net output #1: loss = 0.424321 (* 1 = 0.424321 loss)
I1120 19:59:33.998733  1516 sgd_solver.cpp:105] Iteration 146300, lr = 0.001
I1120 19:59:43.704254  1516 solver.cpp:218] Iteration 146400 (10.3036 iter/s, 9.70531s/100 iters), loss = 0.604755
I1120 19:59:43.704254  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 19:59:43.704254  1516 solver.cpp:237]     Train net output #1: loss = 0.604755 (* 1 = 0.604755 loss)
I1120 19:59:43.704254  1516 sgd_solver.cpp:105] Iteration 146400, lr = 0.001
I1120 19:59:52.982934 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:59:53.375548  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_146500.caffemodel
I1120 19:59:53.401060  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_146500.solverstate
I1120 19:59:53.412060  1516 solver.cpp:330] Iteration 146500, Testing net (#0)
I1120 19:59:53.413060  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 19:59:55.729161 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 19:59:55.822176  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7233
I1120 19:59:55.822176  1516 solver.cpp:397]     Test net output #1: loss = 1.13777 (* 1 = 1.13777 loss)
I1120 19:59:55.919189  1516 solver.cpp:218] Iteration 146500 (8.18703 iter/s, 12.2144s/100 iters), loss = 0.41254
I1120 19:59:55.919189  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 19:59:55.919189  1516 solver.cpp:237]     Train net output #1: loss = 0.412539 (* 1 = 0.412539 loss)
I1120 19:59:55.919189  1516 sgd_solver.cpp:105] Iteration 146500, lr = 0.001
I1120 20:00:05.688544  1516 solver.cpp:218] Iteration 146600 (10.2363 iter/s, 9.76915s/100 iters), loss = 0.600732
I1120 20:00:05.688544  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:00:05.689545  1516 solver.cpp:237]     Train net output #1: loss = 0.600732 (* 1 = 0.600732 loss)
I1120 20:00:05.689545  1516 sgd_solver.cpp:105] Iteration 146600, lr = 0.001
I1120 20:00:15.471659  1516 solver.cpp:218] Iteration 146700 (10.2228 iter/s, 9.78203s/100 iters), loss = 0.349064
I1120 20:00:15.471659  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1120 20:00:15.472160  1516 solver.cpp:237]     Train net output #1: loss = 0.349064 (* 1 = 0.349064 loss)
I1120 20:00:15.472160  1516 sgd_solver.cpp:105] Iteration 146700, lr = 0.001
I1120 20:00:25.158495  1516 solver.cpp:218] Iteration 146800 (10.3237 iter/s, 9.68648s/100 iters), loss = 0.435523
I1120 20:00:25.158495  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:00:25.158495  1516 solver.cpp:237]     Train net output #1: loss = 0.435523 (* 1 = 0.435523 loss)
I1120 20:00:25.158495  1516 sgd_solver.cpp:105] Iteration 146800, lr = 0.001
I1120 20:00:34.834314  1516 solver.cpp:218] Iteration 146900 (10.336 iter/s, 9.67496s/100 iters), loss = 0.579141
I1120 20:00:34.834314  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:00:34.834314  1516 solver.cpp:237]     Train net output #1: loss = 0.579141 (* 1 = 0.579141 loss)
I1120 20:00:34.834314  1516 sgd_solver.cpp:105] Iteration 146900, lr = 0.001
I1120 20:00:44.156008 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:00:44.535099  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_147000.caffemodel
I1120 20:00:44.563089  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_147000.solverstate
I1120 20:00:44.574095  1516 solver.cpp:330] Iteration 147000, Testing net (#0)
I1120 20:00:44.574594  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:00:46.839251 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:00:46.931259  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7271
I1120 20:00:46.931259  1516 solver.cpp:397]     Test net output #1: loss = 1.14062 (* 1 = 1.14062 loss)
I1120 20:00:47.025264  1516 solver.cpp:218] Iteration 147000 (8.20329 iter/s, 12.1902s/100 iters), loss = 0.416323
I1120 20:00:47.025264  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:00:47.025264  1516 solver.cpp:237]     Train net output #1: loss = 0.416323 (* 1 = 0.416323 loss)
I1120 20:00:47.025264  1516 sgd_solver.cpp:105] Iteration 147000, lr = 0.001
I1120 20:00:56.727797  1516 solver.cpp:218] Iteration 147100 (10.3073 iter/s, 9.70187s/100 iters), loss = 0.490281
I1120 20:00:56.727797  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:00:56.727797  1516 solver.cpp:237]     Train net output #1: loss = 0.490281 (* 1 = 0.490281 loss)
I1120 20:00:56.727797  1516 sgd_solver.cpp:105] Iteration 147100, lr = 0.001
I1120 20:01:06.550258  1516 solver.cpp:218] Iteration 147200 (10.1809 iter/s, 9.82233s/100 iters), loss = 0.460361
I1120 20:01:06.550258  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:01:06.550258  1516 solver.cpp:237]     Train net output #1: loss = 0.460361 (* 1 = 0.460361 loss)
I1120 20:01:06.550258  1516 sgd_solver.cpp:105] Iteration 147200, lr = 0.001
I1120 20:01:16.363770  1516 solver.cpp:218] Iteration 147300 (10.1906 iter/s, 9.81298s/100 iters), loss = 0.499863
I1120 20:01:16.363770  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:01:16.363770  1516 solver.cpp:237]     Train net output #1: loss = 0.499863 (* 1 = 0.499863 loss)
I1120 20:01:16.363770  1516 sgd_solver.cpp:105] Iteration 147300, lr = 0.001
I1120 20:01:26.070686  1516 solver.cpp:218] Iteration 147400 (10.3032 iter/s, 9.70573s/100 iters), loss = 0.493865
I1120 20:01:26.070686  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:01:26.070686  1516 solver.cpp:237]     Train net output #1: loss = 0.493865 (* 1 = 0.493865 loss)
I1120 20:01:26.070686  1516 sgd_solver.cpp:105] Iteration 147400, lr = 0.001
I1120 20:01:35.293490 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:01:35.685534  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_147500.caffemodel
I1120 20:01:35.712538  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_147500.solverstate
I1120 20:01:35.723538  1516 solver.cpp:330] Iteration 147500, Testing net (#0)
I1120 20:01:35.723538  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:01:38.033852 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:01:38.123857  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7284
I1120 20:01:38.123857  1516 solver.cpp:397]     Test net output #1: loss = 1.14226 (* 1 = 1.14226 loss)
I1120 20:01:38.217859  1516 solver.cpp:218] Iteration 147500 (8.23284 iter/s, 12.1465s/100 iters), loss = 0.513233
I1120 20:01:38.217859  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:01:38.217859  1516 solver.cpp:237]     Train net output #1: loss = 0.513233 (* 1 = 0.513233 loss)
I1120 20:01:38.217859  1516 sgd_solver.cpp:105] Iteration 147500, lr = 0.001
I1120 20:01:48.023012  1516 solver.cpp:218] Iteration 147600 (10.1989 iter/s, 9.80499s/100 iters), loss = 0.611147
I1120 20:01:48.023012  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:01:48.023012  1516 solver.cpp:237]     Train net output #1: loss = 0.611147 (* 1 = 0.611147 loss)
I1120 20:01:48.023012  1516 sgd_solver.cpp:105] Iteration 147600, lr = 0.001
I1120 20:01:57.741853  1516 solver.cpp:218] Iteration 147700 (10.2901 iter/s, 9.7181s/100 iters), loss = 0.447846
I1120 20:01:57.741853  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:01:57.741853  1516 solver.cpp:237]     Train net output #1: loss = 0.447846 (* 1 = 0.447846 loss)
I1120 20:01:57.741853  1516 sgd_solver.cpp:105] Iteration 147700, lr = 0.001
I1120 20:02:07.538915  1516 solver.cpp:218] Iteration 147800 (10.2074 iter/s, 9.79679s/100 iters), loss = 0.571844
I1120 20:02:07.538915  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 20:02:07.538915  1516 solver.cpp:237]     Train net output #1: loss = 0.571844 (* 1 = 0.571844 loss)
I1120 20:02:07.538915  1516 sgd_solver.cpp:105] Iteration 147800, lr = 0.001
I1120 20:02:17.338835  1516 solver.cpp:218] Iteration 147900 (10.2051 iter/s, 9.79904s/100 iters), loss = 0.453404
I1120 20:02:17.338835  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:02:17.338835  1516 solver.cpp:237]     Train net output #1: loss = 0.453404 (* 1 = 0.453404 loss)
I1120 20:02:17.338835  1516 sgd_solver.cpp:105] Iteration 147900, lr = 0.001
I1120 20:02:26.666664 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:02:27.047782  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_148000.caffemodel
I1120 20:02:27.074770  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_148000.solverstate
I1120 20:02:27.086278  1516 solver.cpp:330] Iteration 148000, Testing net (#0)
I1120 20:02:27.086278  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:02:29.349465 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:02:29.443136  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7261
I1120 20:02:29.443136  1516 solver.cpp:397]     Test net output #1: loss = 1.13375 (* 1 = 1.13375 loss)
I1120 20:02:29.540678  1516 solver.cpp:218] Iteration 148000 (8.19629 iter/s, 12.2006s/100 iters), loss = 0.545402
I1120 20:02:29.540678  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:02:29.540678  1516 solver.cpp:237]     Train net output #1: loss = 0.545402 (* 1 = 0.545402 loss)
I1120 20:02:29.540678  1516 sgd_solver.cpp:105] Iteration 148000, lr = 0.001
I1120 20:02:39.378211  1516 solver.cpp:218] Iteration 148100 (10.1653 iter/s, 9.83737s/100 iters), loss = 0.64021
I1120 20:02:39.378211  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 20:02:39.378211  1516 solver.cpp:237]     Train net output #1: loss = 0.64021 (* 1 = 0.64021 loss)
I1120 20:02:39.378211  1516 sgd_solver.cpp:105] Iteration 148100, lr = 0.001
I1120 20:02:49.063802  1516 solver.cpp:218] Iteration 148200 (10.326 iter/s, 9.68433s/100 iters), loss = 0.450801
I1120 20:02:49.063802  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:02:49.063802  1516 solver.cpp:237]     Train net output #1: loss = 0.450801 (* 1 = 0.450801 loss)
I1120 20:02:49.063802  1516 sgd_solver.cpp:105] Iteration 148200, lr = 0.001
I1120 20:02:58.869663  1516 solver.cpp:218] Iteration 148300 (10.1989 iter/s, 9.805s/100 iters), loss = 0.571711
I1120 20:02:58.869663  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 20:02:58.869663  1516 solver.cpp:237]     Train net output #1: loss = 0.571711 (* 1 = 0.571711 loss)
I1120 20:02:58.869663  1516 sgd_solver.cpp:105] Iteration 148300, lr = 0.001
I1120 20:03:08.723870  1516 solver.cpp:218] Iteration 148400 (10.1478 iter/s, 9.85435s/100 iters), loss = 0.476974
I1120 20:03:08.723870  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:03:08.723870  1516 solver.cpp:237]     Train net output #1: loss = 0.476974 (* 1 = 0.476974 loss)
I1120 20:03:08.723870  1516 sgd_solver.cpp:105] Iteration 148400, lr = 0.001
I1120 20:03:17.956573 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:03:18.337608  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_148500.caffemodel
I1120 20:03:18.363600  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_148500.solverstate
I1120 20:03:18.375609  1516 solver.cpp:330] Iteration 148500, Testing net (#0)
I1120 20:03:18.375609  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:03:20.636724 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:03:20.727732  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7257
I1120 20:03:20.727732  1516 solver.cpp:397]     Test net output #1: loss = 1.14279 (* 1 = 1.14279 loss)
I1120 20:03:20.821738  1516 solver.cpp:218] Iteration 148500 (8.26659 iter/s, 12.0969s/100 iters), loss = 0.401669
I1120 20:03:20.821738  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:03:20.821738  1516 solver.cpp:237]     Train net output #1: loss = 0.401669 (* 1 = 0.401669 loss)
I1120 20:03:20.821738  1516 sgd_solver.cpp:105] Iteration 148500, lr = 0.001
I1120 20:03:30.637224  1516 solver.cpp:218] Iteration 148600 (10.1885 iter/s, 9.81497s/100 iters), loss = 0.508782
I1120 20:03:30.637224  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:03:30.637224  1516 solver.cpp:237]     Train net output #1: loss = 0.508782 (* 1 = 0.508782 loss)
I1120 20:03:30.637224  1516 sgd_solver.cpp:105] Iteration 148600, lr = 0.001
I1120 20:03:40.301933  1516 solver.cpp:218] Iteration 148700 (10.3476 iter/s, 9.66409s/100 iters), loss = 0.434964
I1120 20:03:40.301933  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:03:40.302433  1516 solver.cpp:237]     Train net output #1: loss = 0.434964 (* 1 = 0.434964 loss)
I1120 20:03:40.302433  1516 sgd_solver.cpp:105] Iteration 148700, lr = 0.001
I1120 20:03:49.965934  1516 solver.cpp:218] Iteration 148800 (10.3484 iter/s, 9.66335s/100 iters), loss = 0.494264
I1120 20:03:49.965934  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:03:49.965934  1516 solver.cpp:237]     Train net output #1: loss = 0.494264 (* 1 = 0.494264 loss)
I1120 20:03:49.965934  1516 sgd_solver.cpp:105] Iteration 148800, lr = 0.001
I1120 20:03:59.684948  1516 solver.cpp:218] Iteration 148900 (10.2898 iter/s, 9.71839s/100 iters), loss = 0.645569
I1120 20:03:59.684948  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 20:03:59.684948  1516 solver.cpp:237]     Train net output #1: loss = 0.645568 (* 1 = 0.645568 loss)
I1120 20:03:59.684948  1516 sgd_solver.cpp:105] Iteration 148900, lr = 0.001
I1120 20:04:08.994097 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:04:09.379127  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_149000.caffemodel
I1120 20:04:09.406129  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_149000.solverstate
I1120 20:04:09.452147  1516 solver.cpp:330] Iteration 149000, Testing net (#0)
I1120 20:04:09.452147  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:04:11.760247 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:04:11.852746  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7275
I1120 20:04:11.852746  1516 solver.cpp:397]     Test net output #1: loss = 1.14479 (* 1 = 1.14479 loss)
I1120 20:04:11.949765  1516 solver.cpp:218] Iteration 149000 (8.1534 iter/s, 12.2648s/100 iters), loss = 0.505012
I1120 20:04:11.950765  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:04:11.950765  1516 solver.cpp:237]     Train net output #1: loss = 0.505012 (* 1 = 0.505012 loss)
I1120 20:04:11.950765  1516 sgd_solver.cpp:105] Iteration 149000, lr = 0.001
I1120 20:04:21.709777  1516 solver.cpp:218] Iteration 149100 (10.2475 iter/s, 9.75851s/100 iters), loss = 0.492464
I1120 20:04:21.709777  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:04:21.709777  1516 solver.cpp:237]     Train net output #1: loss = 0.492464 (* 1 = 0.492464 loss)
I1120 20:04:21.709777  1516 sgd_solver.cpp:105] Iteration 149100, lr = 0.001
I1120 20:04:31.561725  1516 solver.cpp:218] Iteration 149200 (10.1501 iter/s, 9.85208s/100 iters), loss = 0.413509
I1120 20:04:31.561725  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:04:31.561725  1516 solver.cpp:237]     Train net output #1: loss = 0.413509 (* 1 = 0.413509 loss)
I1120 20:04:31.562726  1516 sgd_solver.cpp:105] Iteration 149200, lr = 0.001
I1120 20:04:41.265614  1516 solver.cpp:218] Iteration 149300 (10.3062 iter/s, 9.70291s/100 iters), loss = 0.594553
I1120 20:04:41.265614  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 20:04:41.265614  1516 solver.cpp:237]     Train net output #1: loss = 0.594552 (* 1 = 0.594552 loss)
I1120 20:04:41.265614  1516 sgd_solver.cpp:105] Iteration 149300, lr = 0.001
I1120 20:04:50.911229  1516 solver.cpp:218] Iteration 149400 (10.368 iter/s, 9.64504s/100 iters), loss = 0.623266
I1120 20:04:50.911229  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1120 20:04:50.911229  1516 solver.cpp:237]     Train net output #1: loss = 0.623266 (* 1 = 0.623266 loss)
I1120 20:04:50.911229  1516 sgd_solver.cpp:105] Iteration 149400, lr = 0.001
I1120 20:05:00.162431 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:05:00.555454  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_149500.caffemodel
I1120 20:05:00.582453  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_149500.solverstate
I1120 20:05:00.594455  1516 solver.cpp:330] Iteration 149500, Testing net (#0)
I1120 20:05:00.594455  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:05:02.861639 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:05:02.952646  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7275
I1120 20:05:02.952646  1516 solver.cpp:397]     Test net output #1: loss = 1.13496 (* 1 = 1.13496 loss)
I1120 20:05:03.046648  1516 solver.cpp:218] Iteration 149500 (8.24071 iter/s, 12.1349s/100 iters), loss = 0.511084
I1120 20:05:03.046648  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:05:03.046648  1516 solver.cpp:237]     Train net output #1: loss = 0.511084 (* 1 = 0.511084 loss)
I1120 20:05:03.046648  1516 sgd_solver.cpp:105] Iteration 149500, lr = 0.001
I1120 20:05:12.803445  1516 solver.cpp:218] Iteration 149600 (10.2502 iter/s, 9.75592s/100 iters), loss = 0.463541
I1120 20:05:12.803445  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:05:12.803445  1516 solver.cpp:237]     Train net output #1: loss = 0.463541 (* 1 = 0.463541 loss)
I1120 20:05:12.803445  1516 sgd_solver.cpp:105] Iteration 149600, lr = 0.001
I1120 20:05:22.582504  1516 solver.cpp:218] Iteration 149700 (10.2259 iter/s, 9.77905s/100 iters), loss = 0.404304
I1120 20:05:22.582504  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:05:22.582504  1516 solver.cpp:237]     Train net output #1: loss = 0.404304 (* 1 = 0.404304 loss)
I1120 20:05:22.582504  1516 sgd_solver.cpp:105] Iteration 149700, lr = 0.001
I1120 20:05:32.427381  1516 solver.cpp:218] Iteration 149800 (10.1588 iter/s, 9.84371s/100 iters), loss = 0.588665
I1120 20:05:32.427381  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:05:32.427381  1516 solver.cpp:237]     Train net output #1: loss = 0.588665 (* 1 = 0.588665 loss)
I1120 20:05:32.427381  1516 sgd_solver.cpp:105] Iteration 149800, lr = 0.001
I1120 20:05:42.236174  1516 solver.cpp:218] Iteration 149900 (10.1953 iter/s, 9.80843s/100 iters), loss = 0.558691
I1120 20:05:42.236174  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:05:42.236174  1516 solver.cpp:237]     Train net output #1: loss = 0.558691 (* 1 = 0.558691 loss)
I1120 20:05:42.236174  1516 sgd_solver.cpp:105] Iteration 149900, lr = 0.001
I1120 20:05:51.608083 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:05:51.999106  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_150000.caffemodel
I1120 20:05:52.027107  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_150000.solverstate
I1120 20:05:52.039105  1516 solver.cpp:330] Iteration 150000, Testing net (#0)
I1120 20:05:52.040107  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:05:54.323324 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:05:54.417330  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7283
I1120 20:05:54.417330  1516 solver.cpp:397]     Test net output #1: loss = 1.14132 (* 1 = 1.14132 loss)
I1120 20:05:54.513334  1516 solver.cpp:218] Iteration 150000 (8.14585 iter/s, 12.2762s/100 iters), loss = 0.396946
I1120 20:05:54.513334  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:05:54.513334  1516 solver.cpp:237]     Train net output #1: loss = 0.396946 (* 1 = 0.396946 loss)
I1120 20:05:54.513334  1516 sgd_solver.cpp:105] Iteration 150000, lr = 0.001
I1120 20:06:04.242712  1516 solver.cpp:218] Iteration 150100 (10.2788 iter/s, 9.72874s/100 iters), loss = 0.581912
I1120 20:06:04.242712  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:06:04.242712  1516 solver.cpp:237]     Train net output #1: loss = 0.581912 (* 1 = 0.581912 loss)
I1120 20:06:04.242712  1516 sgd_solver.cpp:105] Iteration 150100, lr = 0.001
I1120 20:06:13.928578  1516 solver.cpp:218] Iteration 150200 (10.3246 iter/s, 9.68556s/100 iters), loss = 0.41838
I1120 20:06:13.928578  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:06:13.928578  1516 solver.cpp:237]     Train net output #1: loss = 0.41838 (* 1 = 0.41838 loss)
I1120 20:06:13.928578  1516 sgd_solver.cpp:105] Iteration 150200, lr = 0.001
I1120 20:06:23.614200  1516 solver.cpp:218] Iteration 150300 (10.3252 iter/s, 9.68509s/100 iters), loss = 0.486498
I1120 20:06:23.614200  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:06:23.614200  1516 solver.cpp:237]     Train net output #1: loss = 0.486498 (* 1 = 0.486498 loss)
I1120 20:06:23.615211  1516 sgd_solver.cpp:105] Iteration 150300, lr = 0.001
I1120 20:06:33.306987  1516 solver.cpp:218] Iteration 150400 (10.3178 iter/s, 9.69201s/100 iters), loss = 0.556638
I1120 20:06:33.306987  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:06:33.306987  1516 solver.cpp:237]     Train net output #1: loss = 0.556638 (* 1 = 0.556638 loss)
I1120 20:06:33.306987  1516 sgd_solver.cpp:105] Iteration 150400, lr = 0.001
I1120 20:06:42.496800 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:06:42.875828  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_150500.caffemodel
I1120 20:06:42.903827  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_150500.solverstate
I1120 20:06:42.915827  1516 solver.cpp:330] Iteration 150500, Testing net (#0)
I1120 20:06:42.915827  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:06:45.181993 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:06:45.274046  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7245
I1120 20:06:45.274046  1516 solver.cpp:397]     Test net output #1: loss = 1.14834 (* 1 = 1.14834 loss)
I1120 20:06:45.368033  1516 solver.cpp:218] Iteration 150500 (8.29192 iter/s, 12.0599s/100 iters), loss = 0.341189
I1120 20:06:45.368033  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1120 20:06:45.368033  1516 solver.cpp:237]     Train net output #1: loss = 0.341189 (* 1 = 0.341189 loss)
I1120 20:06:45.368033  1516 sgd_solver.cpp:105] Iteration 150500, lr = 0.001
I1120 20:06:55.177513  1516 solver.cpp:218] Iteration 150600 (10.1943 iter/s, 9.80942s/100 iters), loss = 0.599001
I1120 20:06:55.177513  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 20:06:55.177513  1516 solver.cpp:237]     Train net output #1: loss = 0.599001 (* 1 = 0.599001 loss)
I1120 20:06:55.177513  1516 sgd_solver.cpp:105] Iteration 150600, lr = 0.001
I1120 20:07:04.846815  1516 solver.cpp:218] Iteration 150700 (10.3429 iter/s, 9.66849s/100 iters), loss = 0.309645
I1120 20:07:04.846815  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:07:04.846815  1516 solver.cpp:237]     Train net output #1: loss = 0.309645 (* 1 = 0.309645 loss)
I1120 20:07:04.846815  1516 sgd_solver.cpp:105] Iteration 150700, lr = 0.001
I1120 20:07:14.500093  1516 solver.cpp:218] Iteration 150800 (10.3601 iter/s, 9.65242s/100 iters), loss = 0.532837
I1120 20:07:14.500093  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:07:14.500093  1516 solver.cpp:237]     Train net output #1: loss = 0.532837 (* 1 = 0.532837 loss)
I1120 20:07:14.500093  1516 sgd_solver.cpp:105] Iteration 150800, lr = 0.001
I1120 20:07:24.268162  1516 solver.cpp:218] Iteration 150900 (10.2378 iter/s, 9.7677s/100 iters), loss = 0.481697
I1120 20:07:24.268162  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:07:24.268162  1516 solver.cpp:237]     Train net output #1: loss = 0.481697 (* 1 = 0.481697 loss)
I1120 20:07:24.268162  1516 sgd_solver.cpp:105] Iteration 150900, lr = 0.001
I1120 20:07:33.637549 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:07:34.024461  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_151000.caffemodel
I1120 20:07:34.051483  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_151000.solverstate
I1120 20:07:34.063486  1516 solver.cpp:330] Iteration 151000, Testing net (#0)
I1120 20:07:34.063486  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:07:36.351455 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:07:36.442559  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7274
I1120 20:07:36.442559  1516 solver.cpp:397]     Test net output #1: loss = 1.14663 (* 1 = 1.14663 loss)
I1120 20:07:36.537081  1516 solver.cpp:218] Iteration 151000 (8.15091 iter/s, 12.2686s/100 iters), loss = 0.32549
I1120 20:07:36.537081  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:07:36.537081  1516 solver.cpp:237]     Train net output #1: loss = 0.32549 (* 1 = 0.32549 loss)
I1120 20:07:36.537081  1516 sgd_solver.cpp:105] Iteration 151000, lr = 0.001
I1120 20:07:46.388753  1516 solver.cpp:218] Iteration 151100 (10.1514 iter/s, 9.85085s/100 iters), loss = 0.512668
I1120 20:07:46.388753  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 20:07:46.388753  1516 solver.cpp:237]     Train net output #1: loss = 0.512668 (* 1 = 0.512668 loss)
I1120 20:07:46.388753  1516 sgd_solver.cpp:105] Iteration 151100, lr = 0.001
I1120 20:07:56.124500  1516 solver.cpp:218] Iteration 151200 (10.2718 iter/s, 9.73542s/100 iters), loss = 0.379713
I1120 20:07:56.124500  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:07:56.124500  1516 solver.cpp:237]     Train net output #1: loss = 0.379712 (* 1 = 0.379712 loss)
I1120 20:07:56.124500  1516 sgd_solver.cpp:105] Iteration 151200, lr = 0.001
I1120 20:08:05.935230  1516 solver.cpp:218] Iteration 151300 (10.1938 iter/s, 9.80993s/100 iters), loss = 0.607789
I1120 20:08:05.935230  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 20:08:05.935230  1516 solver.cpp:237]     Train net output #1: loss = 0.607788 (* 1 = 0.607788 loss)
I1120 20:08:05.935230  1516 sgd_solver.cpp:105] Iteration 151300, lr = 0.001
I1120 20:08:15.734882  1516 solver.cpp:218] Iteration 151400 (10.2051 iter/s, 9.79899s/100 iters), loss = 0.488307
I1120 20:08:15.734882  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:08:15.734882  1516 solver.cpp:237]     Train net output #1: loss = 0.488306 (* 1 = 0.488306 loss)
I1120 20:08:15.734882  1516 sgd_solver.cpp:105] Iteration 151400, lr = 0.001
I1120 20:08:24.899314 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:08:25.280445  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_151500.caffemodel
I1120 20:08:25.305447  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_151500.solverstate
I1120 20:08:25.320463  1516 solver.cpp:330] Iteration 151500, Testing net (#0)
I1120 20:08:25.320463  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:08:27.582963 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:08:27.673977  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7274
I1120 20:08:27.673977  1516 solver.cpp:397]     Test net output #1: loss = 1.14116 (* 1 = 1.14116 loss)
I1120 20:08:27.767971  1516 solver.cpp:218] Iteration 151500 (8.31062 iter/s, 12.0328s/100 iters), loss = 0.360929
I1120 20:08:27.768471  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:08:27.768471  1516 solver.cpp:237]     Train net output #1: loss = 0.360929 (* 1 = 0.360929 loss)
I1120 20:08:27.768471  1516 sgd_solver.cpp:105] Iteration 151500, lr = 0.001
I1120 20:08:37.465663  1516 solver.cpp:218] Iteration 151600 (10.3126 iter/s, 9.69691s/100 iters), loss = 0.54277
I1120 20:08:37.465663  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:08:37.465663  1516 solver.cpp:237]     Train net output #1: loss = 0.54277 (* 1 = 0.54277 loss)
I1120 20:08:37.465663  1516 sgd_solver.cpp:105] Iteration 151600, lr = 0.001
I1120 20:08:47.190280  1516 solver.cpp:218] Iteration 151700 (10.283 iter/s, 9.72476s/100 iters), loss = 0.443456
I1120 20:08:47.190280  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:08:47.190280  1516 solver.cpp:237]     Train net output #1: loss = 0.443455 (* 1 = 0.443455 loss)
I1120 20:08:47.191282  1516 sgd_solver.cpp:105] Iteration 151700, lr = 0.001
I1120 20:08:56.928989  1516 solver.cpp:218] Iteration 151800 (10.2691 iter/s, 9.73799s/100 iters), loss = 0.515365
I1120 20:08:56.928989  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:08:56.928989  1516 solver.cpp:237]     Train net output #1: loss = 0.515365 (* 1 = 0.515365 loss)
I1120 20:08:56.928989  1516 sgd_solver.cpp:105] Iteration 151800, lr = 0.001
I1120 20:09:06.708637  1516 solver.cpp:218] Iteration 151900 (10.2268 iter/s, 9.77825s/100 iters), loss = 0.695378
I1120 20:09:06.708637  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:09:06.708637  1516 solver.cpp:237]     Train net output #1: loss = 0.695378 (* 1 = 0.695378 loss)
I1120 20:09:06.708637  1516 sgd_solver.cpp:105] Iteration 151900, lr = 0.001
I1120 20:09:15.958719 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:09:16.351469  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_152000.caffemodel
I1120 20:09:16.378496  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_152000.solverstate
I1120 20:09:16.390009  1516 solver.cpp:330] Iteration 152000, Testing net (#0)
I1120 20:09:16.390009  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:09:18.653112 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:09:18.744161  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7284
I1120 20:09:18.744161  1516 solver.cpp:397]     Test net output #1: loss = 1.14151 (* 1 = 1.14151 loss)
I1120 20:09:18.838755  1516 solver.cpp:218] Iteration 152000 (8.24429 iter/s, 12.1296s/100 iters), loss = 0.375135
I1120 20:09:18.838755  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1120 20:09:18.838755  1516 solver.cpp:237]     Train net output #1: loss = 0.375135 (* 1 = 0.375135 loss)
I1120 20:09:18.838755  1516 sgd_solver.cpp:105] Iteration 152000, lr = 0.001
I1120 20:09:28.639214  1516 solver.cpp:218] Iteration 152100 (10.2043 iter/s, 9.7998s/100 iters), loss = 0.537157
I1120 20:09:28.639214  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:09:28.639214  1516 solver.cpp:237]     Train net output #1: loss = 0.537156 (* 1 = 0.537156 loss)
I1120 20:09:28.639214  1516 sgd_solver.cpp:105] Iteration 152100, lr = 0.001
I1120 20:09:38.312964  1516 solver.cpp:218] Iteration 152200 (10.3379 iter/s, 9.67317s/100 iters), loss = 0.381035
I1120 20:09:38.312964  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:09:38.312964  1516 solver.cpp:237]     Train net output #1: loss = 0.381035 (* 1 = 0.381035 loss)
I1120 20:09:38.312964  1516 sgd_solver.cpp:105] Iteration 152200, lr = 0.001
I1120 20:09:47.962812  1516 solver.cpp:218] Iteration 152300 (10.3632 iter/s, 9.6495s/100 iters), loss = 0.592856
I1120 20:09:47.962812  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:09:47.962812  1516 solver.cpp:237]     Train net output #1: loss = 0.592856 (* 1 = 0.592856 loss)
I1120 20:09:47.962812  1516 sgd_solver.cpp:105] Iteration 152300, lr = 0.001
I1120 20:09:57.682500  1516 solver.cpp:218] Iteration 152400 (10.2891 iter/s, 9.71898s/100 iters), loss = 0.695119
I1120 20:09:57.682500  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1120 20:09:57.682500  1516 solver.cpp:237]     Train net output #1: loss = 0.695119 (* 1 = 0.695119 loss)
I1120 20:09:57.682500  1516 sgd_solver.cpp:105] Iteration 152400, lr = 0.001
I1120 20:10:07.002557 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:10:07.395133  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_152500.caffemodel
I1120 20:10:07.422654  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_152500.solverstate
I1120 20:10:07.434669  1516 solver.cpp:330] Iteration 152500, Testing net (#0)
I1120 20:10:07.434669  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:10:09.739817 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:10:09.833830  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7241
I1120 20:10:09.833830  1516 solver.cpp:397]     Test net output #1: loss = 1.1582 (* 1 = 1.1582 loss)
I1120 20:10:09.927834  1516 solver.cpp:218] Iteration 152500 (8.16656 iter/s, 12.2451s/100 iters), loss = 0.464332
I1120 20:10:09.927834  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:10:09.927834  1516 solver.cpp:237]     Train net output #1: loss = 0.464332 (* 1 = 0.464332 loss)
I1120 20:10:09.927834  1516 sgd_solver.cpp:105] Iteration 152500, lr = 0.001
I1120 20:10:19.581636  1516 solver.cpp:218] Iteration 152600 (10.3593 iter/s, 9.65318s/100 iters), loss = 0.468274
I1120 20:10:19.581636  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:10:19.581636  1516 solver.cpp:237]     Train net output #1: loss = 0.468274 (* 1 = 0.468274 loss)
I1120 20:10:19.581636  1516 sgd_solver.cpp:105] Iteration 152600, lr = 0.001
I1120 20:10:29.326638  1516 solver.cpp:218] Iteration 152700 (10.2622 iter/s, 9.74448s/100 iters), loss = 0.328897
I1120 20:10:29.326638  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:10:29.326638  1516 solver.cpp:237]     Train net output #1: loss = 0.328897 (* 1 = 0.328897 loss)
I1120 20:10:29.326638  1516 sgd_solver.cpp:105] Iteration 152700, lr = 0.001
I1120 20:10:39.092497  1516 solver.cpp:218] Iteration 152800 (10.2404 iter/s, 9.76525s/100 iters), loss = 0.586461
I1120 20:10:39.092497  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:10:39.092497  1516 solver.cpp:237]     Train net output #1: loss = 0.58646 (* 1 = 0.58646 loss)
I1120 20:10:39.092497  1516 sgd_solver.cpp:105] Iteration 152800, lr = 0.001
I1120 20:10:48.802398  1516 solver.cpp:218] Iteration 152900 (10.2997 iter/s, 9.70901s/100 iters), loss = 0.703244
I1120 20:10:48.802398  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1120 20:10:48.802398  1516 solver.cpp:237]     Train net output #1: loss = 0.703244 (* 1 = 0.703244 loss)
I1120 20:10:48.802398  1516 sgd_solver.cpp:105] Iteration 152900, lr = 0.001
I1120 20:10:58.018832 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:10:58.402359  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_153000.caffemodel
I1120 20:10:58.433869  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_153000.solverstate
I1120 20:10:58.445878  1516 solver.cpp:330] Iteration 153000, Testing net (#0)
I1120 20:10:58.445878  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:11:00.711591 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:11:00.802597  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7249
I1120 20:11:00.802597  1516 solver.cpp:397]     Test net output #1: loss = 1.15066 (* 1 = 1.15066 loss)
I1120 20:11:00.896106  1516 solver.cpp:218] Iteration 153000 (8.26912 iter/s, 12.0932s/100 iters), loss = 0.352083
I1120 20:11:00.896106  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:11:00.896106  1516 solver.cpp:237]     Train net output #1: loss = 0.352083 (* 1 = 0.352083 loss)
I1120 20:11:00.896106  1516 sgd_solver.cpp:46] MultiStep Status: Iteration 153000, step = 3
I1120 20:11:00.896106  1516 sgd_solver.cpp:105] Iteration 153000, lr = 0.0001
I1120 20:11:10.556206  1516 solver.cpp:218] Iteration 153100 (10.3521 iter/s, 9.65987s/100 iters), loss = 0.516677
I1120 20:11:10.556206  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:11:10.556206  1516 solver.cpp:237]     Train net output #1: loss = 0.516677 (* 1 = 0.516677 loss)
I1120 20:11:10.556206  1516 sgd_solver.cpp:105] Iteration 153100, lr = 0.0001
I1120 20:11:20.221226  1516 solver.cpp:218] Iteration 153200 (10.3479 iter/s, 9.66383s/100 iters), loss = 0.291657
I1120 20:11:20.221226  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1120 20:11:20.221226  1516 solver.cpp:237]     Train net output #1: loss = 0.291657 (* 1 = 0.291657 loss)
I1120 20:11:20.221226  1516 sgd_solver.cpp:105] Iteration 153200, lr = 0.0001
I1120 20:11:29.882995  1516 solver.cpp:218] Iteration 153300 (10.3506 iter/s, 9.66125s/100 iters), loss = 0.421842
I1120 20:11:29.882995  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:11:29.882995  1516 solver.cpp:237]     Train net output #1: loss = 0.421842 (* 1 = 0.421842 loss)
I1120 20:11:29.882995  1516 sgd_solver.cpp:105] Iteration 153300, lr = 0.0001
I1120 20:11:39.570989  1516 solver.cpp:218] Iteration 153400 (10.3228 iter/s, 9.68731s/100 iters), loss = 0.470433
I1120 20:11:39.570989  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:11:39.570989  1516 solver.cpp:237]     Train net output #1: loss = 0.470433 (* 1 = 0.470433 loss)
I1120 20:11:39.570989  1516 sgd_solver.cpp:105] Iteration 153400, lr = 0.0001
I1120 20:11:48.752773 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:11:49.129796  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_153500.caffemodel
I1120 20:11:49.155797  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_153500.solverstate
I1120 20:11:49.168798  1516 solver.cpp:330] Iteration 153500, Testing net (#0)
I1120 20:11:49.168798  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:11:51.437880 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:11:51.528887  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7337
I1120 20:11:51.528887  1516 solver.cpp:397]     Test net output #1: loss = 1.11964 (* 1 = 1.11964 loss)
I1120 20:11:51.621888  1516 solver.cpp:218] Iteration 153500 (8.2983 iter/s, 12.0507s/100 iters), loss = 0.464667
I1120 20:11:51.621888  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:11:51.621888  1516 solver.cpp:237]     Train net output #1: loss = 0.464667 (* 1 = 0.464667 loss)
I1120 20:11:51.621888  1516 sgd_solver.cpp:105] Iteration 153500, lr = 0.0001
I1120 20:12:01.295786  1516 solver.cpp:218] Iteration 153600 (10.3382 iter/s, 9.67288s/100 iters), loss = 0.617447
I1120 20:12:01.295786  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 20:12:01.295786  1516 solver.cpp:237]     Train net output #1: loss = 0.617447 (* 1 = 0.617447 loss)
I1120 20:12:01.295786  1516 sgd_solver.cpp:105] Iteration 153600, lr = 0.0001
I1120 20:12:10.952466  1516 solver.cpp:218] Iteration 153700 (10.3559 iter/s, 9.65635s/100 iters), loss = 0.464855
I1120 20:12:10.952466  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:12:10.952466  1516 solver.cpp:237]     Train net output #1: loss = 0.464855 (* 1 = 0.464855 loss)
I1120 20:12:10.952466  1516 sgd_solver.cpp:105] Iteration 153700, lr = 0.0001
I1120 20:12:20.636412  1516 solver.cpp:218] Iteration 153800 (10.3265 iter/s, 9.68386s/100 iters), loss = 0.488748
I1120 20:12:20.636412  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:12:20.636412  1516 solver.cpp:237]     Train net output #1: loss = 0.488748 (* 1 = 0.488748 loss)
I1120 20:12:20.636412  1516 sgd_solver.cpp:105] Iteration 153800, lr = 0.0001
I1120 20:12:30.343051  1516 solver.cpp:218] Iteration 153900 (10.3029 iter/s, 9.70605s/100 iters), loss = 0.516104
I1120 20:12:30.344053  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 20:12:30.344053  1516 solver.cpp:237]     Train net output #1: loss = 0.516104 (* 1 = 0.516104 loss)
I1120 20:12:30.344053  1516 sgd_solver.cpp:105] Iteration 153900, lr = 0.0001
I1120 20:12:39.553797 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:12:39.936817  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_154000.caffemodel
I1120 20:12:39.963817  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_154000.solverstate
I1120 20:12:39.976817  1516 solver.cpp:330] Iteration 154000, Testing net (#0)
I1120 20:12:39.976817  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:12:42.245967 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:12:42.337985  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7333
I1120 20:12:42.337985  1516 solver.cpp:397]     Test net output #1: loss = 1.11222 (* 1 = 1.11222 loss)
I1120 20:12:42.431979  1516 solver.cpp:218] Iteration 154000 (8.27269 iter/s, 12.088s/100 iters), loss = 0.411233
I1120 20:12:42.431979  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:12:42.431979  1516 solver.cpp:237]     Train net output #1: loss = 0.411233 (* 1 = 0.411233 loss)
I1120 20:12:42.431979  1516 sgd_solver.cpp:105] Iteration 154000, lr = 0.0001
I1120 20:12:52.131896  1516 solver.cpp:218] Iteration 154100 (10.3102 iter/s, 9.69917s/100 iters), loss = 0.528205
I1120 20:12:52.131896  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 20:12:52.131896  1516 solver.cpp:237]     Train net output #1: loss = 0.528205 (* 1 = 0.528205 loss)
I1120 20:12:52.131896  1516 sgd_solver.cpp:105] Iteration 154100, lr = 0.0001
I1120 20:13:01.804901  1516 solver.cpp:218] Iteration 154200 (10.3386 iter/s, 9.67246s/100 iters), loss = 0.397626
I1120 20:13:01.804901  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:13:01.804901  1516 solver.cpp:237]     Train net output #1: loss = 0.397626 (* 1 = 0.397626 loss)
I1120 20:13:01.804901  1516 sgd_solver.cpp:105] Iteration 154200, lr = 0.0001
I1120 20:13:11.487766  1516 solver.cpp:218] Iteration 154300 (10.3283 iter/s, 9.68216s/100 iters), loss = 0.520503
I1120 20:13:11.487766  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:13:11.487766  1516 solver.cpp:237]     Train net output #1: loss = 0.520502 (* 1 = 0.520502 loss)
I1120 20:13:11.487766  1516 sgd_solver.cpp:105] Iteration 154300, lr = 0.0001
I1120 20:13:21.321974  1516 solver.cpp:218] Iteration 154400 (10.1694 iter/s, 9.83339s/100 iters), loss = 0.476547
I1120 20:13:21.321974  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:13:21.321974  1516 solver.cpp:237]     Train net output #1: loss = 0.476546 (* 1 = 0.476546 loss)
I1120 20:13:21.321974  1516 sgd_solver.cpp:105] Iteration 154400, lr = 0.0001
I1120 20:13:30.556607 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:13:30.941021  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_154500.caffemodel
I1120 20:13:30.968022  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_154500.solverstate
I1120 20:13:30.981525  1516 solver.cpp:330] Iteration 154500, Testing net (#0)
I1120 20:13:30.982025  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:13:33.255216 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:13:33.346221  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7334
I1120 20:13:33.346221  1516 solver.cpp:397]     Test net output #1: loss = 1.11293 (* 1 = 1.11293 loss)
I1120 20:13:33.440237  1516 solver.cpp:218] Iteration 154500 (8.25236 iter/s, 12.1177s/100 iters), loss = 0.389562
I1120 20:13:33.440237  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:13:33.440237  1516 solver.cpp:237]     Train net output #1: loss = 0.389562 (* 1 = 0.389562 loss)
I1120 20:13:33.440237  1516 sgd_solver.cpp:105] Iteration 154500, lr = 0.0001
I1120 20:13:43.124079  1516 solver.cpp:218] Iteration 154600 (10.327 iter/s, 9.6834s/100 iters), loss = 0.461178
I1120 20:13:43.124079  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:13:43.124079  1516 solver.cpp:237]     Train net output #1: loss = 0.461178 (* 1 = 0.461178 loss)
I1120 20:13:43.124079  1516 sgd_solver.cpp:105] Iteration 154600, lr = 0.0001
I1120 20:13:52.862952  1516 solver.cpp:218] Iteration 154700 (10.269 iter/s, 9.73801s/100 iters), loss = 0.405344
I1120 20:13:52.862952  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:13:52.862952  1516 solver.cpp:237]     Train net output #1: loss = 0.405344 (* 1 = 0.405344 loss)
I1120 20:13:52.862952  1516 sgd_solver.cpp:105] Iteration 154700, lr = 0.0001
I1120 20:14:02.569836  1516 solver.cpp:218] Iteration 154800 (10.3019 iter/s, 9.70691s/100 iters), loss = 0.571454
I1120 20:14:02.569836  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:14:02.569836  1516 solver.cpp:237]     Train net output #1: loss = 0.571454 (* 1 = 0.571454 loss)
I1120 20:14:02.569836  1516 sgd_solver.cpp:105] Iteration 154800, lr = 0.0001
I1120 20:14:12.304977  1516 solver.cpp:218] Iteration 154900 (10.2723 iter/s, 9.73493s/100 iters), loss = 0.447742
I1120 20:14:12.305977  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:14:12.305977  1516 solver.cpp:237]     Train net output #1: loss = 0.447741 (* 1 = 0.447741 loss)
I1120 20:14:12.305977  1516 sgd_solver.cpp:105] Iteration 154900, lr = 0.0001
I1120 20:14:21.522939 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:14:21.902963  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_155000.caffemodel
I1120 20:14:21.928963  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_155000.solverstate
I1120 20:14:21.940963  1516 solver.cpp:330] Iteration 155000, Testing net (#0)
I1120 20:14:21.940963  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:14:24.202095 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:14:24.293102  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7339
I1120 20:14:24.293102  1516 solver.cpp:397]     Test net output #1: loss = 1.11203 (* 1 = 1.11203 loss)
I1120 20:14:24.387106  1516 solver.cpp:218] Iteration 155000 (8.27756 iter/s, 12.0808s/100 iters), loss = 0.333098
I1120 20:14:24.387106  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:14:24.387106  1516 solver.cpp:237]     Train net output #1: loss = 0.333098 (* 1 = 0.333098 loss)
I1120 20:14:24.387106  1516 sgd_solver.cpp:105] Iteration 155000, lr = 0.0001
I1120 20:14:34.030856  1516 solver.cpp:218] Iteration 155100 (10.3701 iter/s, 9.64309s/100 iters), loss = 0.424935
I1120 20:14:34.030856  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:14:34.030856  1516 solver.cpp:237]     Train net output #1: loss = 0.424935 (* 1 = 0.424935 loss)
I1120 20:14:34.030856  1516 sgd_solver.cpp:105] Iteration 155100, lr = 0.0001
I1120 20:14:43.676862  1516 solver.cpp:218] Iteration 155200 (10.3675 iter/s, 9.64549s/100 iters), loss = 0.286893
I1120 20:14:43.676862  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1120 20:14:43.676862  1516 solver.cpp:237]     Train net output #1: loss = 0.286893 (* 1 = 0.286893 loss)
I1120 20:14:43.676862  1516 sgd_solver.cpp:105] Iteration 155200, lr = 0.0001
I1120 20:14:53.324527  1516 solver.cpp:218] Iteration 155300 (10.3655 iter/s, 9.64741s/100 iters), loss = 0.497924
I1120 20:14:53.324527  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:14:53.324527  1516 solver.cpp:237]     Train net output #1: loss = 0.497924 (* 1 = 0.497924 loss)
I1120 20:14:53.324527  1516 sgd_solver.cpp:105] Iteration 155300, lr = 0.0001
I1120 20:15:02.980592  1516 solver.cpp:218] Iteration 155400 (10.3564 iter/s, 9.65584s/100 iters), loss = 0.568891
I1120 20:15:02.980592  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:15:02.980592  1516 solver.cpp:237]     Train net output #1: loss = 0.568891 (* 1 = 0.568891 loss)
I1120 20:15:02.980592  1516 sgd_solver.cpp:105] Iteration 155400, lr = 0.0001
I1120 20:15:12.184357 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:15:12.566399  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_155500.caffemodel
I1120 20:15:12.594395  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_155500.solverstate
I1120 20:15:12.605394  1516 solver.cpp:330] Iteration 155500, Testing net (#0)
I1120 20:15:12.605394  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:15:14.872607 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:15:14.963618  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7343
I1120 20:15:14.963618  1516 solver.cpp:397]     Test net output #1: loss = 1.1105 (* 1 = 1.1105 loss)
I1120 20:15:15.057615  1516 solver.cpp:218] Iteration 155500 (8.28097 iter/s, 12.0759s/100 iters), loss = 0.375215
I1120 20:15:15.057615  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:15:15.057615  1516 solver.cpp:237]     Train net output #1: loss = 0.375214 (* 1 = 0.375214 loss)
I1120 20:15:15.057615  1516 sgd_solver.cpp:105] Iteration 155500, lr = 0.0001
I1120 20:15:24.840821  1516 solver.cpp:218] Iteration 155600 (10.222 iter/s, 9.78283s/100 iters), loss = 0.45362
I1120 20:15:24.840821  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:15:24.840821  1516 solver.cpp:237]     Train net output #1: loss = 0.45362 (* 1 = 0.45362 loss)
I1120 20:15:24.840821  1516 sgd_solver.cpp:105] Iteration 155600, lr = 0.0001
I1120 20:15:34.614204  1516 solver.cpp:218] Iteration 155700 (10.2329 iter/s, 9.77236s/100 iters), loss = 0.358308
I1120 20:15:34.614204  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:15:34.614204  1516 solver.cpp:237]     Train net output #1: loss = 0.358308 (* 1 = 0.358308 loss)
I1120 20:15:34.614204  1516 sgd_solver.cpp:105] Iteration 155700, lr = 0.0001
I1120 20:15:44.322433  1516 solver.cpp:218] Iteration 155800 (10.3011 iter/s, 9.70774s/100 iters), loss = 0.488332
I1120 20:15:44.322433  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:15:44.322433  1516 solver.cpp:237]     Train net output #1: loss = 0.488332 (* 1 = 0.488332 loss)
I1120 20:15:44.322433  1516 sgd_solver.cpp:105] Iteration 155800, lr = 0.0001
I1120 20:15:54.090286  1516 solver.cpp:218] Iteration 155900 (10.2376 iter/s, 9.76788s/100 iters), loss = 0.531104
I1120 20:15:54.090286  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:15:54.090286  1516 solver.cpp:237]     Train net output #1: loss = 0.531104 (* 1 = 0.531104 loss)
I1120 20:15:54.090286  1516 sgd_solver.cpp:105] Iteration 155900, lr = 0.0001
I1120 20:16:03.309836 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:16:03.691869  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_156000.caffemodel
I1120 20:16:03.720868  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_156000.solverstate
I1120 20:16:03.734380  1516 solver.cpp:330] Iteration 156000, Testing net (#0)
I1120 20:16:03.734380  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:16:06.001052 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:16:06.092059  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7343
I1120 20:16:06.092059  1516 solver.cpp:397]     Test net output #1: loss = 1.10807 (* 1 = 1.10807 loss)
I1120 20:16:06.186065  1516 solver.cpp:218] Iteration 156000 (8.26824 iter/s, 12.0945s/100 iters), loss = 0.319617
I1120 20:16:06.186065  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1120 20:16:06.186065  1516 solver.cpp:237]     Train net output #1: loss = 0.319617 (* 1 = 0.319617 loss)
I1120 20:16:06.186065  1516 sgd_solver.cpp:105] Iteration 156000, lr = 0.0001
I1120 20:16:15.924904  1516 solver.cpp:218] Iteration 156100 (10.268 iter/s, 9.73901s/100 iters), loss = 0.440359
I1120 20:16:15.925904  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:16:15.925904  1516 solver.cpp:237]     Train net output #1: loss = 0.440359 (* 1 = 0.440359 loss)
I1120 20:16:15.925904  1516 sgd_solver.cpp:105] Iteration 156100, lr = 0.0001
I1120 20:16:25.667821  1516 solver.cpp:218] Iteration 156200 (10.2652 iter/s, 9.74168s/100 iters), loss = 0.391158
I1120 20:16:25.667821  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:16:25.667821  1516 solver.cpp:237]     Train net output #1: loss = 0.391157 (* 1 = 0.391157 loss)
I1120 20:16:25.667821  1516 sgd_solver.cpp:105] Iteration 156200, lr = 0.0001
I1120 20:16:35.351001  1516 solver.cpp:218] Iteration 156300 (10.3276 iter/s, 9.68278s/100 iters), loss = 0.34326
I1120 20:16:35.351502  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:16:35.351502  1516 solver.cpp:237]     Train net output #1: loss = 0.343259 (* 1 = 0.343259 loss)
I1120 20:16:35.351502  1516 sgd_solver.cpp:105] Iteration 156300, lr = 0.0001
I1120 20:16:45.006749  1516 solver.cpp:218] Iteration 156400 (10.3569 iter/s, 9.65543s/100 iters), loss = 0.466738
I1120 20:16:45.006749  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:16:45.006749  1516 solver.cpp:237]     Train net output #1: loss = 0.466738 (* 1 = 0.466738 loss)
I1120 20:16:45.006749  1516 sgd_solver.cpp:105] Iteration 156400, lr = 0.0001
I1120 20:16:54.240561 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:16:54.623579  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_156500.caffemodel
I1120 20:16:54.651587  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_156500.solverstate
I1120 20:16:54.662591  1516 solver.cpp:330] Iteration 156500, Testing net (#0)
I1120 20:16:54.662591  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:16:56.936758 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:16:57.026762  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7332
I1120 20:16:57.026762  1516 solver.cpp:397]     Test net output #1: loss = 1.11021 (* 1 = 1.11021 loss)
I1120 20:16:57.120765  1516 solver.cpp:218] Iteration 156500 (8.25548 iter/s, 12.1132s/100 iters), loss = 0.434024
I1120 20:16:57.120765  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:16:57.120765  1516 solver.cpp:237]     Train net output #1: loss = 0.434024 (* 1 = 0.434024 loss)
I1120 20:16:57.120765  1516 sgd_solver.cpp:105] Iteration 156500, lr = 0.0001
I1120 20:17:06.822510  1516 solver.cpp:218] Iteration 156600 (10.3082 iter/s, 9.70105s/100 iters), loss = 0.530881
I1120 20:17:06.822510  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:17:06.822510  1516 solver.cpp:237]     Train net output #1: loss = 0.530881 (* 1 = 0.530881 loss)
I1120 20:17:06.822510  1516 sgd_solver.cpp:105] Iteration 156600, lr = 0.0001
I1120 20:17:16.513339  1516 solver.cpp:218] Iteration 156700 (10.3198 iter/s, 9.69008s/100 iters), loss = 0.405879
I1120 20:17:16.513339  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:17:16.513339  1516 solver.cpp:237]     Train net output #1: loss = 0.405878 (* 1 = 0.405878 loss)
I1120 20:17:16.513339  1516 sgd_solver.cpp:105] Iteration 156700, lr = 0.0001
I1120 20:17:26.246379  1516 solver.cpp:218] Iteration 156800 (10.2746 iter/s, 9.73272s/100 iters), loss = 0.532241
I1120 20:17:26.246881  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:17:26.246881  1516 solver.cpp:237]     Train net output #1: loss = 0.532241 (* 1 = 0.532241 loss)
I1120 20:17:26.246881  1516 sgd_solver.cpp:105] Iteration 156800, lr = 0.0001
I1120 20:17:35.971765  1516 solver.cpp:218] Iteration 156900 (10.2826 iter/s, 9.72515s/100 iters), loss = 0.534514
I1120 20:17:35.971765  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 20:17:35.971765  1516 solver.cpp:237]     Train net output #1: loss = 0.534514 (* 1 = 0.534514 loss)
I1120 20:17:35.971765  1516 sgd_solver.cpp:105] Iteration 156900, lr = 0.0001
I1120 20:17:45.279063 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:17:45.658088  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_157000.caffemodel
I1120 20:17:45.684083  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_157000.solverstate
I1120 20:17:45.695083  1516 solver.cpp:330] Iteration 157000, Testing net (#0)
I1120 20:17:45.695083  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:17:47.954223 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:17:48.045769  1516 solver.cpp:397]     Test net output #0: accuracy = 0.734
I1120 20:17:48.045769  1516 solver.cpp:397]     Test net output #1: loss = 1.10879 (* 1 = 1.10879 loss)
I1120 20:17:48.139262  1516 solver.cpp:218] Iteration 157000 (8.21935 iter/s, 12.1664s/100 iters), loss = 0.384268
I1120 20:17:48.139262  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:17:48.139262  1516 solver.cpp:237]     Train net output #1: loss = 0.384268 (* 1 = 0.384268 loss)
I1120 20:17:48.139262  1516 sgd_solver.cpp:105] Iteration 157000, lr = 0.0001
I1120 20:17:57.781996  1516 solver.cpp:218] Iteration 157100 (10.371 iter/s, 9.64223s/100 iters), loss = 0.532753
I1120 20:17:57.781996  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:17:57.781996  1516 solver.cpp:237]     Train net output #1: loss = 0.532753 (* 1 = 0.532753 loss)
I1120 20:17:57.781996  1516 sgd_solver.cpp:105] Iteration 157100, lr = 0.0001
I1120 20:18:07.440734  1516 solver.cpp:218] Iteration 157200 (10.3542 iter/s, 9.65794s/100 iters), loss = 0.328149
I1120 20:18:07.440734  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1120 20:18:07.440734  1516 solver.cpp:237]     Train net output #1: loss = 0.328149 (* 1 = 0.328149 loss)
I1120 20:18:07.440734  1516 sgd_solver.cpp:105] Iteration 157200, lr = 0.0001
I1120 20:18:17.105109  1516 solver.cpp:218] Iteration 157300 (10.3473 iter/s, 9.66438s/100 iters), loss = 0.346415
I1120 20:18:17.105109  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:18:17.105109  1516 solver.cpp:237]     Train net output #1: loss = 0.346415 (* 1 = 0.346415 loss)
I1120 20:18:17.105109  1516 sgd_solver.cpp:105] Iteration 157300, lr = 0.0001
I1120 20:18:26.800818  1516 solver.cpp:218] Iteration 157400 (10.3144 iter/s, 9.69516s/100 iters), loss = 0.4787
I1120 20:18:26.800818  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:18:26.800818  1516 solver.cpp:237]     Train net output #1: loss = 0.478699 (* 1 = 0.478699 loss)
I1120 20:18:26.800818  1516 sgd_solver.cpp:105] Iteration 157400, lr = 0.0001
I1120 20:18:35.971559 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:18:36.349575  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_157500.caffemodel
I1120 20:18:36.377615  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_157500.solverstate
I1120 20:18:36.388612  1516 solver.cpp:330] Iteration 157500, Testing net (#0)
I1120 20:18:36.389611  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:18:38.646816 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:18:38.737826  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7323
I1120 20:18:38.737826  1516 solver.cpp:397]     Test net output #1: loss = 1.1066 (* 1 = 1.1066 loss)
I1120 20:18:38.831827  1516 solver.cpp:218] Iteration 157500 (8.31262 iter/s, 12.0299s/100 iters), loss = 0.42254
I1120 20:18:38.831827  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:18:38.831827  1516 solver.cpp:237]     Train net output #1: loss = 0.42254 (* 1 = 0.42254 loss)
I1120 20:18:38.831827  1516 sgd_solver.cpp:105] Iteration 157500, lr = 0.0001
I1120 20:18:48.538637  1516 solver.cpp:218] Iteration 157600 (10.3024 iter/s, 9.70645s/100 iters), loss = 0.474644
I1120 20:18:48.538637  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:18:48.538637  1516 solver.cpp:237]     Train net output #1: loss = 0.474644 (* 1 = 0.474644 loss)
I1120 20:18:48.538637  1516 sgd_solver.cpp:105] Iteration 157600, lr = 0.0001
I1120 20:18:58.220767  1516 solver.cpp:218] Iteration 157700 (10.3289 iter/s, 9.68161s/100 iters), loss = 0.312411
I1120 20:18:58.220767  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1120 20:18:58.220767  1516 solver.cpp:237]     Train net output #1: loss = 0.312411 (* 1 = 0.312411 loss)
I1120 20:18:58.220767  1516 sgd_solver.cpp:105] Iteration 157700, lr = 0.0001
I1120 20:19:07.871520  1516 solver.cpp:218] Iteration 157800 (10.3623 iter/s, 9.65032s/100 iters), loss = 0.435769
I1120 20:19:07.871520  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:19:07.871520  1516 solver.cpp:237]     Train net output #1: loss = 0.435769 (* 1 = 0.435769 loss)
I1120 20:19:07.871520  1516 sgd_solver.cpp:105] Iteration 157800, lr = 0.0001
I1120 20:19:17.514298  1516 solver.cpp:218] Iteration 157900 (10.3704 iter/s, 9.64282s/100 iters), loss = 0.496591
I1120 20:19:17.515300  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:19:17.515300  1516 solver.cpp:237]     Train net output #1: loss = 0.496591 (* 1 = 0.496591 loss)
I1120 20:19:17.515300  1516 sgd_solver.cpp:105] Iteration 157900, lr = 0.0001
I1120 20:19:26.687117 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:19:27.067137  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_158000.caffemodel
I1120 20:19:27.094141  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_158000.solverstate
I1120 20:19:27.106142  1516 solver.cpp:330] Iteration 158000, Testing net (#0)
I1120 20:19:27.107141  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:19:29.365772 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:19:29.456282  1516 solver.cpp:397]     Test net output #0: accuracy = 0.733
I1120 20:19:29.456282  1516 solver.cpp:397]     Test net output #1: loss = 1.10821 (* 1 = 1.10821 loss)
I1120 20:19:29.550279  1516 solver.cpp:218] Iteration 158000 (8.30953 iter/s, 12.0344s/100 iters), loss = 0.312273
I1120 20:19:29.550279  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1120 20:19:29.550279  1516 solver.cpp:237]     Train net output #1: loss = 0.312273 (* 1 = 0.312273 loss)
I1120 20:19:29.550279  1516 sgd_solver.cpp:105] Iteration 158000, lr = 0.0001
I1120 20:19:39.219588  1516 solver.cpp:218] Iteration 158100 (10.3426 iter/s, 9.66875s/100 iters), loss = 0.417447
I1120 20:19:39.219588  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:19:39.219588  1516 solver.cpp:237]     Train net output #1: loss = 0.417447 (* 1 = 0.417447 loss)
I1120 20:19:39.219588  1516 sgd_solver.cpp:105] Iteration 158100, lr = 0.0001
I1120 20:19:48.952277  1516 solver.cpp:218] Iteration 158200 (10.2747 iter/s, 9.73268s/100 iters), loss = 0.423081
I1120 20:19:48.952277  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:19:48.952277  1516 solver.cpp:237]     Train net output #1: loss = 0.42308 (* 1 = 0.42308 loss)
I1120 20:19:48.952277  1516 sgd_solver.cpp:105] Iteration 158200, lr = 0.0001
I1120 20:19:58.611798  1516 solver.cpp:218] Iteration 158300 (10.3535 iter/s, 9.6586s/100 iters), loss = 0.431658
I1120 20:19:58.611798  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:19:58.611798  1516 solver.cpp:237]     Train net output #1: loss = 0.431658 (* 1 = 0.431658 loss)
I1120 20:19:58.611798  1516 sgd_solver.cpp:105] Iteration 158300, lr = 0.0001
I1120 20:20:08.301823  1516 solver.cpp:218] Iteration 158400 (10.3205 iter/s, 9.68944s/100 iters), loss = 0.439174
I1120 20:20:08.301823  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:20:08.301823  1516 solver.cpp:237]     Train net output #1: loss = 0.439174 (* 1 = 0.439174 loss)
I1120 20:20:08.301823  1516 sgd_solver.cpp:105] Iteration 158400, lr = 0.0001
I1120 20:20:17.473533 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:20:17.859566  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_158500.caffemodel
I1120 20:20:17.887578  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_158500.solverstate
I1120 20:20:17.898577  1516 solver.cpp:330] Iteration 158500, Testing net (#0)
I1120 20:20:17.898577  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:20:20.159728 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:20:20.249732  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7343
I1120 20:20:20.249732  1516 solver.cpp:397]     Test net output #1: loss = 1.10928 (* 1 = 1.10928 loss)
I1120 20:20:20.343739  1516 solver.cpp:218] Iteration 158500 (8.30453 iter/s, 12.0416s/100 iters), loss = 0.323032
I1120 20:20:20.343739  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:20:20.343739  1516 solver.cpp:237]     Train net output #1: loss = 0.323031 (* 1 = 0.323031 loss)
I1120 20:20:20.343739  1516 sgd_solver.cpp:105] Iteration 158500, lr = 0.0001
I1120 20:20:29.986040  1516 solver.cpp:218] Iteration 158600 (10.3721 iter/s, 9.64127s/100 iters), loss = 0.436239
I1120 20:20:29.986040  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:20:29.986040  1516 solver.cpp:237]     Train net output #1: loss = 0.436239 (* 1 = 0.436239 loss)
I1120 20:20:29.986040  1516 sgd_solver.cpp:105] Iteration 158600, lr = 0.0001
I1120 20:20:39.674129  1516 solver.cpp:218] Iteration 158700 (10.3221 iter/s, 9.68797s/100 iters), loss = 0.379544
I1120 20:20:39.674645  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:20:39.674645  1516 solver.cpp:237]     Train net output #1: loss = 0.379543 (* 1 = 0.379543 loss)
I1120 20:20:39.674645  1516 sgd_solver.cpp:105] Iteration 158700, lr = 0.0001
I1120 20:20:49.392381  1516 solver.cpp:218] Iteration 158800 (10.2903 iter/s, 9.71788s/100 iters), loss = 0.459957
I1120 20:20:49.392381  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 20:20:49.392381  1516 solver.cpp:237]     Train net output #1: loss = 0.459957 (* 1 = 0.459957 loss)
I1120 20:20:49.392381  1516 sgd_solver.cpp:105] Iteration 158800, lr = 0.0001
I1120 20:20:59.100343  1516 solver.cpp:218] Iteration 158900 (10.3019 iter/s, 9.70699s/100 iters), loss = 0.385691
I1120 20:20:59.100343  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:20:59.100343  1516 solver.cpp:237]     Train net output #1: loss = 0.38569 (* 1 = 0.38569 loss)
I1120 20:20:59.100343  1516 sgd_solver.cpp:105] Iteration 158900, lr = 0.0001
I1120 20:21:08.316483 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:21:08.710500  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_159000.caffemodel
I1120 20:21:08.736500  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_159000.solverstate
I1120 20:21:08.747503  1516 solver.cpp:330] Iteration 159000, Testing net (#0)
I1120 20:21:08.747503  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:21:11.017653 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:21:11.108659  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7343
I1120 20:21:11.108659  1516 solver.cpp:397]     Test net output #1: loss = 1.10816 (* 1 = 1.10816 loss)
I1120 20:21:11.201661  1516 solver.cpp:218] Iteration 159000 (8.26361 iter/s, 12.1013s/100 iters), loss = 0.34201
I1120 20:21:11.201661  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:21:11.201661  1516 solver.cpp:237]     Train net output #1: loss = 0.342009 (* 1 = 0.342009 loss)
I1120 20:21:11.201661  1516 sgd_solver.cpp:105] Iteration 159000, lr = 0.0001
I1120 20:21:20.885258  1516 solver.cpp:218] Iteration 159100 (10.3278 iter/s, 9.68262s/100 iters), loss = 0.345666
I1120 20:21:20.885258  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:21:20.885258  1516 solver.cpp:237]     Train net output #1: loss = 0.345666 (* 1 = 0.345666 loss)
I1120 20:21:20.885258  1516 sgd_solver.cpp:105] Iteration 159100, lr = 0.0001
I1120 20:21:30.591516  1516 solver.cpp:218] Iteration 159200 (10.3034 iter/s, 9.70558s/100 iters), loss = 0.43584
I1120 20:21:30.591516  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:21:30.591516  1516 solver.cpp:237]     Train net output #1: loss = 0.435839 (* 1 = 0.435839 loss)
I1120 20:21:30.591516  1516 sgd_solver.cpp:105] Iteration 159200, lr = 0.0001
I1120 20:21:40.313346  1516 solver.cpp:218] Iteration 159300 (10.2861 iter/s, 9.72182s/100 iters), loss = 0.416656
I1120 20:21:40.313346  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:21:40.313346  1516 solver.cpp:237]     Train net output #1: loss = 0.416656 (* 1 = 0.416656 loss)
I1120 20:21:40.314347  1516 sgd_solver.cpp:105] Iteration 159300, lr = 0.0001
I1120 20:21:50.027842  1516 solver.cpp:218] Iteration 159400 (10.2951 iter/s, 9.71335s/100 iters), loss = 0.491201
I1120 20:21:50.027842  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:21:50.027842  1516 solver.cpp:237]     Train net output #1: loss = 0.4912 (* 1 = 0.4912 loss)
I1120 20:21:50.027842  1516 sgd_solver.cpp:105] Iteration 159400, lr = 0.0001
I1120 20:21:59.199653 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:21:59.582700  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_159500.caffemodel
I1120 20:21:59.610702  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_159500.solverstate
I1120 20:21:59.621701  1516 solver.cpp:330] Iteration 159500, Testing net (#0)
I1120 20:21:59.622719  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:22:01.898887 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:22:01.989892  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7341
I1120 20:22:01.989892  1516 solver.cpp:397]     Test net output #1: loss = 1.10789 (* 1 = 1.10789 loss)
I1120 20:22:02.083894  1516 solver.cpp:218] Iteration 159500 (8.29529 iter/s, 12.055s/100 iters), loss = 0.2974
I1120 20:22:02.083894  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1120 20:22:02.083894  1516 solver.cpp:237]     Train net output #1: loss = 0.2974 (* 1 = 0.2974 loss)
I1120 20:22:02.083894  1516 sgd_solver.cpp:105] Iteration 159500, lr = 0.0001
I1120 20:22:11.786876  1516 solver.cpp:218] Iteration 159600 (10.3065 iter/s, 9.70257s/100 iters), loss = 0.451964
I1120 20:22:11.786876  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:22:11.786876  1516 solver.cpp:237]     Train net output #1: loss = 0.451964 (* 1 = 0.451964 loss)
I1120 20:22:11.786876  1516 sgd_solver.cpp:105] Iteration 159600, lr = 0.0001
I1120 20:22:21.685371  1516 solver.cpp:218] Iteration 159700 (10.1035 iter/s, 9.89754s/100 iters), loss = 0.367783
I1120 20:22:21.685371  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:22:21.685371  1516 solver.cpp:237]     Train net output #1: loss = 0.367783 (* 1 = 0.367783 loss)
I1120 20:22:21.685371  1516 sgd_solver.cpp:105] Iteration 159700, lr = 0.0001
I1120 20:22:31.519812  1516 solver.cpp:218] Iteration 159800 (10.1684 iter/s, 9.83436s/100 iters), loss = 0.475179
I1120 20:22:31.519812  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:22:31.519812  1516 solver.cpp:237]     Train net output #1: loss = 0.475179 (* 1 = 0.475179 loss)
I1120 20:22:31.519812  1516 sgd_solver.cpp:105] Iteration 159800, lr = 0.0001
I1120 20:22:41.432062  1516 solver.cpp:218] Iteration 159900 (10.0894 iter/s, 9.91137s/100 iters), loss = 0.402453
I1120 20:22:41.432062  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:22:41.432062  1516 solver.cpp:237]     Train net output #1: loss = 0.402453 (* 1 = 0.402453 loss)
I1120 20:22:41.432062  1516 sgd_solver.cpp:105] Iteration 159900, lr = 0.0001
I1120 20:22:50.743885 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:22:51.135871  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_160000.caffemodel
I1120 20:22:51.163872  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_160000.solverstate
I1120 20:22:51.179872  1516 solver.cpp:330] Iteration 160000, Testing net (#0)
I1120 20:22:51.180876  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:22:53.464495 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:22:53.557503  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7339
I1120 20:22:53.557503  1516 solver.cpp:397]     Test net output #1: loss = 1.10724 (* 1 = 1.10724 loss)
I1120 20:22:53.651536  1516 solver.cpp:218] Iteration 160000 (8.18381 iter/s, 12.2193s/100 iters), loss = 0.360534
I1120 20:22:53.652537  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:22:53.652537  1516 solver.cpp:237]     Train net output #1: loss = 0.360534 (* 1 = 0.360534 loss)
I1120 20:22:53.652537  1516 sgd_solver.cpp:105] Iteration 160000, lr = 0.0001
I1120 20:23:03.510056  1516 solver.cpp:218] Iteration 160100 (10.1451 iter/s, 9.85695s/100 iters), loss = 0.362797
I1120 20:23:03.510056  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:23:03.510056  1516 solver.cpp:237]     Train net output #1: loss = 0.362797 (* 1 = 0.362797 loss)
I1120 20:23:03.510056  1516 sgd_solver.cpp:105] Iteration 160100, lr = 0.0001
I1120 20:23:13.265609  1516 solver.cpp:218] Iteration 160200 (10.2507 iter/s, 9.75545s/100 iters), loss = 0.228199
I1120 20:23:13.265609  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1120 20:23:13.265609  1516 solver.cpp:237]     Train net output #1: loss = 0.228199 (* 1 = 0.228199 loss)
I1120 20:23:13.265609  1516 sgd_solver.cpp:105] Iteration 160200, lr = 0.0001
I1120 20:23:23.032477  1516 solver.cpp:218] Iteration 160300 (10.2393 iter/s, 9.76629s/100 iters), loss = 0.369337
I1120 20:23:23.032477  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:23:23.032477  1516 solver.cpp:237]     Train net output #1: loss = 0.369337 (* 1 = 0.369337 loss)
I1120 20:23:23.032477  1516 sgd_solver.cpp:105] Iteration 160300, lr = 0.0001
I1120 20:23:32.720305  1516 solver.cpp:218] Iteration 160400 (10.3226 iter/s, 9.68745s/100 iters), loss = 0.541955
I1120 20:23:32.720305  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:23:32.720305  1516 solver.cpp:237]     Train net output #1: loss = 0.541955 (* 1 = 0.541955 loss)
I1120 20:23:32.720305  1516 sgd_solver.cpp:105] Iteration 160400, lr = 0.0001
I1120 20:23:41.917636 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:23:42.299823  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_160500.caffemodel
I1120 20:23:42.330823  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_160500.solverstate
I1120 20:23:42.342839  1516 solver.cpp:330] Iteration 160500, Testing net (#0)
I1120 20:23:42.342839  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:23:44.633038 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:23:44.724038  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7338
I1120 20:23:44.724038  1516 solver.cpp:397]     Test net output #1: loss = 1.10667 (* 1 = 1.10667 loss)
I1120 20:23:44.818075  1516 solver.cpp:218] Iteration 160500 (8.26662 iter/s, 12.0968s/100 iters), loss = 0.45483
I1120 20:23:44.818075  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:23:44.818075  1516 solver.cpp:237]     Train net output #1: loss = 0.45483 (* 1 = 0.45483 loss)
I1120 20:23:44.818075  1516 sgd_solver.cpp:105] Iteration 160500, lr = 0.0001
I1120 20:23:54.570399  1516 solver.cpp:218] Iteration 160600 (10.2548 iter/s, 9.75157s/100 iters), loss = 0.5472
I1120 20:23:54.570399  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:23:54.570399  1516 solver.cpp:237]     Train net output #1: loss = 0.547199 (* 1 = 0.547199 loss)
I1120 20:23:54.570399  1516 sgd_solver.cpp:105] Iteration 160600, lr = 0.0001
I1120 20:24:04.267441  1516 solver.cpp:218] Iteration 160700 (10.3126 iter/s, 9.69692s/100 iters), loss = 0.304989
I1120 20:24:04.267441  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:24:04.267441  1516 solver.cpp:237]     Train net output #1: loss = 0.304988 (* 1 = 0.304988 loss)
I1120 20:24:04.267441  1516 sgd_solver.cpp:105] Iteration 160700, lr = 0.0001
I1120 20:24:13.944468  1516 solver.cpp:218] Iteration 160800 (10.3349 iter/s, 9.67596s/100 iters), loss = 0.403998
I1120 20:24:13.944468  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:24:13.944468  1516 solver.cpp:237]     Train net output #1: loss = 0.403997 (* 1 = 0.403997 loss)
I1120 20:24:13.944468  1516 sgd_solver.cpp:105] Iteration 160800, lr = 0.0001
I1120 20:24:23.694576  1516 solver.cpp:218] Iteration 160900 (10.2565 iter/s, 9.74995s/100 iters), loss = 0.52286
I1120 20:24:23.694576  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:24:23.695075  1516 solver.cpp:237]     Train net output #1: loss = 0.52286 (* 1 = 0.52286 loss)
I1120 20:24:23.695075  1516 sgd_solver.cpp:105] Iteration 160900, lr = 0.0001
I1120 20:24:32.902984 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:24:33.283558  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_161000.caffemodel
I1120 20:24:33.311066  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_161000.solverstate
I1120 20:24:33.323576  1516 solver.cpp:330] Iteration 161000, Testing net (#0)
I1120 20:24:33.323576  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:24:35.596400 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:24:35.687427  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7338
I1120 20:24:35.687427  1516 solver.cpp:397]     Test net output #1: loss = 1.10754 (* 1 = 1.10754 loss)
I1120 20:24:35.781458  1516 solver.cpp:218] Iteration 161000 (8.27411 iter/s, 12.0859s/100 iters), loss = 0.400814
I1120 20:24:35.781458  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1120 20:24:35.781458  1516 solver.cpp:237]     Train net output #1: loss = 0.400814 (* 1 = 0.400814 loss)
I1120 20:24:35.781458  1516 sgd_solver.cpp:105] Iteration 161000, lr = 0.0001
I1120 20:24:45.538429  1516 solver.cpp:218] Iteration 161100 (10.2492 iter/s, 9.75682s/100 iters), loss = 0.367838
I1120 20:24:45.538429  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:24:45.538429  1516 solver.cpp:237]     Train net output #1: loss = 0.367838 (* 1 = 0.367838 loss)
I1120 20:24:45.538429  1516 sgd_solver.cpp:105] Iteration 161100, lr = 0.0001
I1120 20:24:55.273814  1516 solver.cpp:218] Iteration 161200 (10.273 iter/s, 9.73426s/100 iters), loss = 0.371429
I1120 20:24:55.273814  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:24:55.273814  1516 solver.cpp:237]     Train net output #1: loss = 0.371429 (* 1 = 0.371429 loss)
I1120 20:24:55.273814  1516 sgd_solver.cpp:105] Iteration 161200, lr = 0.0001
I1120 20:25:04.922147  1516 solver.cpp:218] Iteration 161300 (10.3642 iter/s, 9.64861s/100 iters), loss = 0.487895
I1120 20:25:04.923147  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:25:04.923147  1516 solver.cpp:237]     Train net output #1: loss = 0.487895 (* 1 = 0.487895 loss)
I1120 20:25:04.923147  1516 sgd_solver.cpp:105] Iteration 161300, lr = 0.0001
I1120 20:25:14.669564  1516 solver.cpp:218] Iteration 161400 (10.2604 iter/s, 9.74619s/100 iters), loss = 0.492129
I1120 20:25:14.669564  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:25:14.669564  1516 solver.cpp:237]     Train net output #1: loss = 0.492128 (* 1 = 0.492128 loss)
I1120 20:25:14.669564  1516 sgd_solver.cpp:105] Iteration 161400, lr = 0.0001
I1120 20:25:23.842484 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:25:24.224524  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_161500.caffemodel
I1120 20:25:24.251021  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_161500.solverstate
I1120 20:25:24.262539  1516 solver.cpp:330] Iteration 161500, Testing net (#0)
I1120 20:25:24.262539  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:25:26.524698 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:25:26.615705  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7342
I1120 20:25:26.615705  1516 solver.cpp:397]     Test net output #1: loss = 1.10722 (* 1 = 1.10722 loss)
I1120 20:25:26.709709  1516 solver.cpp:218] Iteration 161500 (8.30614 iter/s, 12.0393s/100 iters), loss = 0.377673
I1120 20:25:26.709709  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:25:26.709709  1516 solver.cpp:237]     Train net output #1: loss = 0.377673 (* 1 = 0.377673 loss)
I1120 20:25:26.709709  1516 sgd_solver.cpp:105] Iteration 161500, lr = 0.0001
I1120 20:25:36.371587  1516 solver.cpp:218] Iteration 161600 (10.35 iter/s, 9.66182s/100 iters), loss = 0.458467
I1120 20:25:36.371587  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:25:36.371587  1516 solver.cpp:237]     Train net output #1: loss = 0.458467 (* 1 = 0.458467 loss)
I1120 20:25:36.371587  1516 sgd_solver.cpp:105] Iteration 161600, lr = 0.0001
I1120 20:25:46.036336  1516 solver.cpp:218] Iteration 161700 (10.3472 iter/s, 9.66442s/100 iters), loss = 0.326578
I1120 20:25:46.036336  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1120 20:25:46.036336  1516 solver.cpp:237]     Train net output #1: loss = 0.326578 (* 1 = 0.326578 loss)
I1120 20:25:46.036336  1516 sgd_solver.cpp:105] Iteration 161700, lr = 0.0001
I1120 20:25:55.688104  1516 solver.cpp:218] Iteration 161800 (10.3617 iter/s, 9.65097s/100 iters), loss = 0.412597
I1120 20:25:55.688104  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:25:55.688104  1516 solver.cpp:237]     Train net output #1: loss = 0.412597 (* 1 = 0.412597 loss)
I1120 20:25:55.688104  1516 sgd_solver.cpp:105] Iteration 161800, lr = 0.0001
I1120 20:26:05.337924  1516 solver.cpp:218] Iteration 161900 (10.3635 iter/s, 9.64921s/100 iters), loss = 0.493875
I1120 20:26:05.337924  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:26:05.337924  1516 solver.cpp:237]     Train net output #1: loss = 0.493875 (* 1 = 0.493875 loss)
I1120 20:26:05.337924  1516 sgd_solver.cpp:105] Iteration 161900, lr = 0.0001
I1120 20:26:14.515662 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:26:14.895689  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_162000.caffemodel
I1120 20:26:14.922688  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_162000.solverstate
I1120 20:26:14.934689  1516 solver.cpp:330] Iteration 162000, Testing net (#0)
I1120 20:26:14.934689  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:26:17.195839 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:26:17.286855  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7348
I1120 20:26:17.286855  1516 solver.cpp:397]     Test net output #1: loss = 1.10465 (* 1 = 1.10465 loss)
I1120 20:26:17.380858  1516 solver.cpp:218] Iteration 162000 (8.30401 iter/s, 12.0424s/100 iters), loss = 0.448517
I1120 20:26:17.380858  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:26:17.380858  1516 solver.cpp:237]     Train net output #1: loss = 0.448517 (* 1 = 0.448517 loss)
I1120 20:26:17.380858  1516 sgd_solver.cpp:105] Iteration 162000, lr = 0.0001
I1120 20:26:27.035616  1516 solver.cpp:218] Iteration 162100 (10.3581 iter/s, 9.65431s/100 iters), loss = 0.463596
I1120 20:26:27.035616  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 20:26:27.035616  1516 solver.cpp:237]     Train net output #1: loss = 0.463596 (* 1 = 0.463596 loss)
I1120 20:26:27.035616  1516 sgd_solver.cpp:105] Iteration 162100, lr = 0.0001
I1120 20:26:36.695575  1516 solver.cpp:218] Iteration 162200 (10.3529 iter/s, 9.65917s/100 iters), loss = 0.384285
I1120 20:26:36.695575  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:26:36.695575  1516 solver.cpp:237]     Train net output #1: loss = 0.384284 (* 1 = 0.384284 loss)
I1120 20:26:36.695575  1516 sgd_solver.cpp:105] Iteration 162200, lr = 0.0001
I1120 20:26:46.348845  1516 solver.cpp:218] Iteration 162300 (10.3593 iter/s, 9.65314s/100 iters), loss = 0.535299
I1120 20:26:46.348845  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:26:46.348845  1516 solver.cpp:237]     Train net output #1: loss = 0.535299 (* 1 = 0.535299 loss)
I1120 20:26:46.348845  1516 sgd_solver.cpp:105] Iteration 162300, lr = 0.0001
I1120 20:26:56.127430  1516 solver.cpp:218] Iteration 162400 (10.2267 iter/s, 9.7783s/100 iters), loss = 0.535475
I1120 20:26:56.127430  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1120 20:26:56.128432  1516 solver.cpp:237]     Train net output #1: loss = 0.535475 (* 1 = 0.535475 loss)
I1120 20:26:56.128432  1516 sgd_solver.cpp:105] Iteration 162400, lr = 0.0001
I1120 20:27:05.559288 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:27:05.945320  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_162500.caffemodel
I1120 20:27:05.976326  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_162500.solverstate
I1120 20:27:05.988348  1516 solver.cpp:330] Iteration 162500, Testing net (#0)
I1120 20:27:05.988348  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:27:08.253458 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:27:08.343464  1516 solver.cpp:397]     Test net output #0: accuracy = 0.735
I1120 20:27:08.343464  1516 solver.cpp:397]     Test net output #1: loss = 1.108 (* 1 = 1.108 loss)
I1120 20:27:08.437480  1516 solver.cpp:218] Iteration 162500 (8.12406 iter/s, 12.3091s/100 iters), loss = 0.368248
I1120 20:27:08.437480  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:27:08.437480  1516 solver.cpp:237]     Train net output #1: loss = 0.368248 (* 1 = 0.368248 loss)
I1120 20:27:08.437480  1516 sgd_solver.cpp:105] Iteration 162500, lr = 0.0001
I1120 20:27:18.087218  1516 solver.cpp:218] Iteration 162600 (10.3636 iter/s, 9.64914s/100 iters), loss = 0.481214
I1120 20:27:18.087218  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:27:18.087218  1516 solver.cpp:237]     Train net output #1: loss = 0.481213 (* 1 = 0.481213 loss)
I1120 20:27:18.087218  1516 sgd_solver.cpp:105] Iteration 162600, lr = 0.0001
I1120 20:27:27.742117  1516 solver.cpp:218] Iteration 162700 (10.358 iter/s, 9.65434s/100 iters), loss = 0.366599
I1120 20:27:27.742117  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:27:27.742117  1516 solver.cpp:237]     Train net output #1: loss = 0.366599 (* 1 = 0.366599 loss)
I1120 20:27:27.742117  1516 sgd_solver.cpp:105] Iteration 162700, lr = 0.0001
I1120 20:27:37.433060  1516 solver.cpp:218] Iteration 162800 (10.3193 iter/s, 9.69056s/100 iters), loss = 0.464547
I1120 20:27:37.433060  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1120 20:27:37.433060  1516 solver.cpp:237]     Train net output #1: loss = 0.464547 (* 1 = 0.464547 loss)
I1120 20:27:37.433060  1516 sgd_solver.cpp:105] Iteration 162800, lr = 0.0001
I1120 20:27:47.132668  1516 solver.cpp:218] Iteration 162900 (10.3109 iter/s, 9.6985s/100 iters), loss = 0.529505
I1120 20:27:47.132668  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1120 20:27:47.132668  1516 solver.cpp:237]     Train net output #1: loss = 0.529505 (* 1 = 0.529505 loss)
I1120 20:27:47.132668  1516 sgd_solver.cpp:105] Iteration 162900, lr = 0.0001
I1120 20:27:56.348170 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:27:56.734200  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_163000.caffemodel
I1120 20:27:56.759202  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_163000.solverstate
I1120 20:27:56.771704  1516 solver.cpp:330] Iteration 163000, Testing net (#0)
I1120 20:27:56.771704  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:27:59.045372 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:27:59.136379  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7345
I1120 20:27:59.136379  1516 solver.cpp:397]     Test net output #1: loss = 1.10597 (* 1 = 1.10597 loss)
I1120 20:27:59.229384  1516 solver.cpp:218] Iteration 163000 (8.26661 iter/s, 12.0969s/100 iters), loss = 0.325495
I1120 20:27:59.229384  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1120 20:27:59.230386  1516 solver.cpp:237]     Train net output #1: loss = 0.325495 (* 1 = 0.325495 loss)
I1120 20:27:59.230386  1516 sgd_solver.cpp:105] Iteration 163000, lr = 0.0001
I1120 20:28:08.916265  1516 solver.cpp:218] Iteration 163100 (10.3241 iter/s, 9.68609s/100 iters), loss = 0.439241
I1120 20:28:08.916265  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:28:08.916265  1516 solver.cpp:237]     Train net output #1: loss = 0.439241 (* 1 = 0.439241 loss)
I1120 20:28:08.916265  1516 sgd_solver.cpp:105] Iteration 163100, lr = 0.0001
I1120 20:28:18.629102  1516 solver.cpp:218] Iteration 163200 (10.2963 iter/s, 9.71221s/100 iters), loss = 0.353835
I1120 20:28:18.629102  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:28:18.629102  1516 solver.cpp:237]     Train net output #1: loss = 0.353835 (* 1 = 0.353835 loss)
I1120 20:28:18.629102  1516 sgd_solver.cpp:105] Iteration 163200, lr = 0.0001
I1120 20:28:28.316710  1516 solver.cpp:218] Iteration 163300 (10.3233 iter/s, 9.68679s/100 iters), loss = 0.547148
I1120 20:28:28.316710  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1120 20:28:28.316710  1516 solver.cpp:237]     Train net output #1: loss = 0.547147 (* 1 = 0.547147 loss)
I1120 20:28:28.316710  1516 sgd_solver.cpp:105] Iteration 163300, lr = 0.0001
I1120 20:28:37.989964  1516 solver.cpp:218] Iteration 163400 (10.3388 iter/s, 9.67232s/100 iters), loss = 0.447636
I1120 20:28:37.989964  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1120 20:28:37.989964  1516 solver.cpp:237]     Train net output #1: loss = 0.447636 (* 1 = 0.447636 loss)
I1120 20:28:37.989964  1516 sgd_solver.cpp:105] Iteration 163400, lr = 0.0001
I1120 20:28:47.364536 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:28:47.755563  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_163500.caffemodel
I1120 20:28:47.783067  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_163500.solverstate
I1120 20:28:47.795568  1516 solver.cpp:330] Iteration 163500, Testing net (#0)
I1120 20:28:47.795568  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:28:50.109813 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:28:50.203825  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7359
I1120 20:28:50.203825  1516 solver.cpp:397]     Test net output #1: loss = 1.10614 (* 1 = 1.10614 loss)
I1120 20:28:50.299863  1516 solver.cpp:218] Iteration 163500 (8.12365 iter/s, 12.3097s/100 iters), loss = 0.375161
I1120 20:28:50.299863  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1120 20:28:50.299863  1516 solver.cpp:237]     Train net output #1: loss = 0.375161 (* 1 = 0.375161 loss)
I1120 20:28:50.299863  1516 sgd_solver.cpp:105] Iteration 163500, lr = 0.0001
I1120 20:29:00.203945  1516 solver.cpp:218] Iteration 163600 (10.0974 iter/s, 9.90351s/100 iters), loss = 0.432734
I1120 20:29:00.203945  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:29:00.203945  1516 solver.cpp:237]     Train net output #1: loss = 0.432734 (* 1 = 0.432734 loss)
I1120 20:29:00.203945  1516 sgd_solver.cpp:105] Iteration 163600, lr = 0.0001
I1120 20:29:10.110177  1516 solver.cpp:218] Iteration 163700 (10.0955 iter/s, 9.90541s/100 iters), loss = 0.340143
I1120 20:29:10.110177  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1120 20:29:10.110177  1516 solver.cpp:237]     Train net output #1: loss = 0.340143 (* 1 = 0.340143 loss)
I1120 20:29:10.110177  1516 sgd_solver.cpp:105] Iteration 163700, lr = 0.0001
I1120 20:29:20.003599  1516 solver.cpp:218] Iteration 163800 (10.1084 iter/s, 9.89271s/100 iters), loss = 0.380621
I1120 20:29:20.003599  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:29:20.003599  1516 solver.cpp:237]     Train net output #1: loss = 0.380621 (* 1 = 0.380621 loss)
I1120 20:29:20.003599  1516 sgd_solver.cpp:105] Iteration 163800, lr = 0.0001
I1120 20:29:29.881217  1516 solver.cpp:218] Iteration 163900 (10.1242 iter/s, 9.8773s/100 iters), loss = 0.586047
I1120 20:29:29.881217  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:29:29.881217  1516 solver.cpp:237]     Train net output #1: loss = 0.586047 (* 1 = 0.586047 loss)
I1120 20:29:29.881217  1516 sgd_solver.cpp:105] Iteration 163900, lr = 0.0001
I1120 20:29:39.304569 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:29:39.694121  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_164000.caffemodel
I1120 20:29:39.721127  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_164000.solverstate
I1120 20:29:39.732128  1516 solver.cpp:330] Iteration 164000, Testing net (#0)
I1120 20:29:39.732128  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:29:42.038305 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:29:42.129309  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7355
I1120 20:29:42.129309  1516 solver.cpp:397]     Test net output #1: loss = 1.10781 (* 1 = 1.10781 loss)
I1120 20:29:42.224323  1516 solver.cpp:218] Iteration 164000 (8.10241 iter/s, 12.342s/100 iters), loss = 0.394257
I1120 20:29:42.224323  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:29:42.224323  1516 solver.cpp:237]     Train net output #1: loss = 0.394257 (* 1 = 0.394257 loss)
I1120 20:29:42.224323  1516 sgd_solver.cpp:105] Iteration 164000, lr = 0.0001
I1120 20:29:51.893103  1516 solver.cpp:218] Iteration 164100 (10.3428 iter/s, 9.66852s/100 iters), loss = 0.592438
I1120 20:29:51.893103  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1120 20:29:51.893103  1516 solver.cpp:237]     Train net output #1: loss = 0.592438 (* 1 = 0.592438 loss)
I1120 20:29:51.893103  1516 sgd_solver.cpp:105] Iteration 164100, lr = 0.0001
I1120 20:30:01.607867  1516 solver.cpp:218] Iteration 164200 (10.2947 iter/s, 9.71378s/100 iters), loss = 0.391947
I1120 20:30:01.607867  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:30:01.607867  1516 solver.cpp:237]     Train net output #1: loss = 0.391947 (* 1 = 0.391947 loss)
I1120 20:30:01.607867  1516 sgd_solver.cpp:105] Iteration 164200, lr = 0.0001
I1120 20:30:11.281050  1516 solver.cpp:218] Iteration 164300 (10.3382 iter/s, 9.67283s/100 iters), loss = 0.434884
I1120 20:30:11.281050  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:30:11.281050  1516 solver.cpp:237]     Train net output #1: loss = 0.434884 (* 1 = 0.434884 loss)
I1120 20:30:11.281050  1516 sgd_solver.cpp:105] Iteration 164300, lr = 0.0001
I1120 20:30:20.925856  1516 solver.cpp:218] Iteration 164400 (10.3687 iter/s, 9.6444s/100 iters), loss = 0.488475
I1120 20:30:20.925856  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:30:20.925856  1516 solver.cpp:237]     Train net output #1: loss = 0.488474 (* 1 = 0.488474 loss)
I1120 20:30:20.925856  1516 sgd_solver.cpp:105] Iteration 164400, lr = 0.0001
I1120 20:30:30.110643 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:30:30.490666  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_164500.caffemodel
I1120 20:30:30.517674  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_164500.solverstate
I1120 20:30:30.528676  1516 solver.cpp:330] Iteration 164500, Testing net (#0)
I1120 20:30:30.528676  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:30:32.787839 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:30:32.881850  1516 solver.cpp:397]     Test net output #0: accuracy = 0.734
I1120 20:30:32.881850  1516 solver.cpp:397]     Test net output #1: loss = 1.10719 (* 1 = 1.10719 loss)
I1120 20:30:32.977852  1516 solver.cpp:218] Iteration 164500 (8.29742 iter/s, 12.0519s/100 iters), loss = 0.312638
I1120 20:30:32.978853  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:30:32.978853  1516 solver.cpp:237]     Train net output #1: loss = 0.312638 (* 1 = 0.312638 loss)
I1120 20:30:32.978853  1516 sgd_solver.cpp:105] Iteration 164500, lr = 0.0001
I1120 20:30:42.652802  1516 solver.cpp:218] Iteration 164600 (10.3368 iter/s, 9.6742s/100 iters), loss = 0.385972
I1120 20:30:42.652802  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1120 20:30:42.652802  1516 solver.cpp:237]     Train net output #1: loss = 0.385972 (* 1 = 0.385972 loss)
I1120 20:30:42.652802  1516 sgd_solver.cpp:105] Iteration 164600, lr = 0.0001
I1120 20:30:52.306638  1516 solver.cpp:218] Iteration 164700 (10.3596 iter/s, 9.65285s/100 iters), loss = 0.307892
I1120 20:30:52.306638  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:30:52.306638  1516 solver.cpp:237]     Train net output #1: loss = 0.307892 (* 1 = 0.307892 loss)
I1120 20:30:52.306638  1516 sgd_solver.cpp:105] Iteration 164700, lr = 0.0001
I1120 20:31:01.966418  1516 solver.cpp:218] Iteration 164800 (10.353 iter/s, 9.65907s/100 iters), loss = 0.553124
I1120 20:31:01.966418  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1120 20:31:01.966418  1516 solver.cpp:237]     Train net output #1: loss = 0.553124 (* 1 = 0.553124 loss)
I1120 20:31:01.966418  1516 sgd_solver.cpp:105] Iteration 164800, lr = 0.0001
I1120 20:31:11.751046  1516 solver.cpp:218] Iteration 164900 (10.2207 iter/s, 9.78411s/100 iters), loss = 0.449324
I1120 20:31:11.751046  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:31:11.751046  1516 solver.cpp:237]     Train net output #1: loss = 0.449324 (* 1 = 0.449324 loss)
I1120 20:31:11.751046  1516 sgd_solver.cpp:105] Iteration 164900, lr = 0.0001
I1120 20:31:20.927866 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:31:21.306995  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_165000.caffemodel
I1120 20:31:21.336689  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_165000.solverstate
I1120 20:31:21.348695  1516 solver.cpp:330] Iteration 165000, Testing net (#0)
I1120 20:31:21.348695  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:31:23.627148 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:31:23.717718  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7334
I1120 20:31:23.717718  1516 solver.cpp:397]     Test net output #1: loss = 1.11164 (* 1 = 1.11164 loss)
I1120 20:31:23.810747  1516 solver.cpp:218] Iteration 165000 (8.29217 iter/s, 12.0596s/100 iters), loss = 0.364468
I1120 20:31:23.810747  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:31:23.810747  1516 solver.cpp:237]     Train net output #1: loss = 0.364468 (* 1 = 0.364468 loss)
I1120 20:31:23.811748  1516 sgd_solver.cpp:105] Iteration 165000, lr = 0.0001
I1120 20:31:33.541206  1516 solver.cpp:218] Iteration 165100 (10.2785 iter/s, 9.72909s/100 iters), loss = 0.469223
I1120 20:31:33.541206  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1120 20:31:33.541206  1516 solver.cpp:237]     Train net output #1: loss = 0.469223 (* 1 = 0.469223 loss)
I1120 20:31:33.541206  1516 sgd_solver.cpp:105] Iteration 165100, lr = 0.0001
I1120 20:31:43.224504  1516 solver.cpp:218] Iteration 165200 (10.3273 iter/s, 9.68309s/100 iters), loss = 0.31006
I1120 20:31:43.225004  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1120 20:31:43.225004  1516 solver.cpp:237]     Train net output #1: loss = 0.31006 (* 1 = 0.31006 loss)
I1120 20:31:43.225004  1516 sgd_solver.cpp:105] Iteration 165200, lr = 0.0001
I1120 20:31:52.987262  1516 solver.cpp:218] Iteration 165300 (10.2432 iter/s, 9.76259s/100 iters), loss = 0.433201
I1120 20:31:52.987262  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1120 20:31:52.987262  1516 solver.cpp:237]     Train net output #1: loss = 0.4332 (* 1 = 0.4332 loss)
I1120 20:31:52.987262  1516 sgd_solver.cpp:105] Iteration 165300, lr = 0.0001
I1120 20:32:02.673840  1516 solver.cpp:218] Iteration 165400 (10.3246 iter/s, 9.6856s/100 iters), loss = 0.635329
I1120 20:32:02.673840  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1120 20:32:02.673840  1516 solver.cpp:237]     Train net output #1: loss = 0.635329 (* 1 = 0.635329 loss)
I1120 20:32:02.673840  1516 sgd_solver.cpp:105] Iteration 165400, lr = 0.0001
I1120 20:32:11.903715 16604 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:32:12.284772  1516 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_165500.caffemodel
I1120 20:32:12.311776  1516 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/CIFAR100_Slim_1M_drp_FCN_iter_165500.solverstate
I1120 20:32:12.324779  1516 solver.cpp:330] Iteration 165500, Testing net (#0)
I1120 20:32:12.324779  1516 net.cpp:676] Ignoring source layer accuracy_training
I1120 20:32:14.609104 14992 data_layer.cpp:73] Restarting data prefetching from start.
I1120 20:32:14.700101  1516 solver.cpp:397]     Test net output #0: accuracy = 0.7343
I1120 20:32:14.700101  1516 solver.cpp:397]     Test net output #1: loss = 1.11096 (* 1 = 1.11096 loss)
I1120 20:32:14.796087  1516 solver.cpp:218] Iteration 165500 (8.24976 iter/s, 12.1216s/100 iters), loss = 0.38478
I1120 20:32:14.796087  1516 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1120 20:32:14.796087  1516 solver.cpp:237]     Train net output #1: loss = 0.384779 (* 1 = 0.3847