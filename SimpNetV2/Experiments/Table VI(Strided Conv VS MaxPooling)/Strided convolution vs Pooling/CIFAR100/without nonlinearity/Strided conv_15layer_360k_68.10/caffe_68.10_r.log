
G:\Caffe\examples\cifar100>REM go to the caffe root 

G:\Caffe\examples\cifar100>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar100/fcifar100_full_relu_solver_bn.prototxt --snapshot=examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_90000.solverstate 
I1107 22:48:49.982863 19164 caffe.cpp:219] Using GPUs 0
I1107 22:48:50.160243 19164 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1107 22:48:50.447749 19164 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1107 22:48:50.463749 19164 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1107 22:48:50.464753 19164 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1107 22:48:50.489835 19164 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1107 22:48:50.489835 19164 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1107 22:48:50.489835 19164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1107 22:48:50.490809 19164 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV1_360k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "pool2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "pool4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1107 22:48:50.543815 19164 layer_factory.cpp:58] Creating layer cifar
I1107 22:48:50.550804 19164 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1107 22:48:50.551820 19164 net.cpp:84] Creating Layer cifar
I1107 22:48:50.551820 19164 net.cpp:380] cifar -> data
I1107 22:48:50.551820 19164 net.cpp:380] cifar -> label
I1107 22:48:50.552798 19164 data_layer.cpp:45] output data size: 100,3,32,32
I1107 22:48:50.563807 19164 net.cpp:122] Setting up cifar
I1107 22:48:50.563807 19164 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1107 22:48:50.563807 19164 net.cpp:129] Top shape: 100 (100)
I1107 22:48:50.563807 19164 net.cpp:137] Memory required for data: 1229200
I1107 22:48:50.563807 19164 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1107 22:48:50.563807 19164 net.cpp:84] Creating Layer label_cifar_1_split
I1107 22:48:50.563807 19164 net.cpp:406] label_cifar_1_split <- label
I1107 22:48:50.563807 19164 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1107 22:48:50.563807 19164 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1107 22:48:50.563807 19164 net.cpp:122] Setting up label_cifar_1_split
I1107 22:48:50.563807 19164 net.cpp:129] Top shape: 100 (100)
I1107 22:48:50.563807 19164 net.cpp:129] Top shape: 100 (100)
I1107 22:48:50.563807 19164 net.cpp:137] Memory required for data: 1230000
I1107 22:48:50.563807 19164 layer_factory.cpp:58] Creating layer conv1
I1107 22:48:50.563807 19164 net.cpp:84] Creating Layer conv1
I1107 22:48:50.563807 19164 net.cpp:406] conv1 <- data
I1107 22:48:50.563807 19164 net.cpp:380] conv1 -> conv1
I1107 22:48:50.565811 11928 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1107 22:48:50.807879 19164 net.cpp:122] Setting up conv1
I1107 22:48:50.807879 19164 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 22:48:50.807879 19164 net.cpp:137] Memory required for data: 13518000
I1107 22:48:50.807879 19164 layer_factory.cpp:58] Creating layer bn1
I1107 22:48:50.807879 19164 net.cpp:84] Creating Layer bn1
I1107 22:48:50.807879 19164 net.cpp:406] bn1 <- conv1
I1107 22:48:50.808878 19164 net.cpp:367] bn1 -> conv1 (in-place)
I1107 22:48:50.808878 19164 net.cpp:122] Setting up bn1
I1107 22:48:50.808878 19164 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 22:48:50.808878 19164 net.cpp:137] Memory required for data: 25806000
I1107 22:48:50.808878 19164 layer_factory.cpp:58] Creating layer scale1
I1107 22:48:50.808878 19164 net.cpp:84] Creating Layer scale1
I1107 22:48:50.808878 19164 net.cpp:406] scale1 <- conv1
I1107 22:48:50.808878 19164 net.cpp:367] scale1 -> conv1 (in-place)
I1107 22:48:50.808878 19164 layer_factory.cpp:58] Creating layer scale1
I1107 22:48:50.808878 19164 net.cpp:122] Setting up scale1
I1107 22:48:50.808878 19164 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 22:48:50.808878 19164 net.cpp:137] Memory required for data: 38094000
I1107 22:48:50.808878 19164 layer_factory.cpp:58] Creating layer relu1
I1107 22:48:50.808878 19164 net.cpp:84] Creating Layer relu1
I1107 22:48:50.808878 19164 net.cpp:406] relu1 <- conv1
I1107 22:48:50.808878 19164 net.cpp:367] relu1 -> conv1 (in-place)
I1107 22:48:50.808878 19164 net.cpp:122] Setting up relu1
I1107 22:48:50.808878 19164 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 22:48:50.808878 19164 net.cpp:137] Memory required for data: 50382000
I1107 22:48:50.808878 19164 layer_factory.cpp:58] Creating layer conv1_0
I1107 22:48:50.808878 19164 net.cpp:84] Creating Layer conv1_0
I1107 22:48:50.808878 19164 net.cpp:406] conv1_0 <- conv1
I1107 22:48:50.808878 19164 net.cpp:380] conv1_0 -> conv1_0
I1107 22:48:50.810878 19164 net.cpp:122] Setting up conv1_0
I1107 22:48:50.810878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.810878 19164 net.cpp:137] Memory required for data: 66766000
I1107 22:48:50.810878 19164 layer_factory.cpp:58] Creating layer bn1_0
I1107 22:48:50.810878 19164 net.cpp:84] Creating Layer bn1_0
I1107 22:48:50.810878 19164 net.cpp:406] bn1_0 <- conv1_0
I1107 22:48:50.810878 19164 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1107 22:48:50.810878 19164 net.cpp:122] Setting up bn1_0
I1107 22:48:50.810878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.810878 19164 net.cpp:137] Memory required for data: 83150000
I1107 22:48:50.810878 19164 layer_factory.cpp:58] Creating layer scale1_0
I1107 22:48:50.810878 19164 net.cpp:84] Creating Layer scale1_0
I1107 22:48:50.810878 19164 net.cpp:406] scale1_0 <- conv1_0
I1107 22:48:50.810878 19164 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1107 22:48:50.810878 19164 layer_factory.cpp:58] Creating layer scale1_0
I1107 22:48:50.810878 19164 net.cpp:122] Setting up scale1_0
I1107 22:48:50.810878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.810878 19164 net.cpp:137] Memory required for data: 99534000
I1107 22:48:50.810878 19164 layer_factory.cpp:58] Creating layer relu1_0
I1107 22:48:50.810878 19164 net.cpp:84] Creating Layer relu1_0
I1107 22:48:50.810878 19164 net.cpp:406] relu1_0 <- conv1_0
I1107 22:48:50.810878 19164 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1107 22:48:50.811879 19164 net.cpp:122] Setting up relu1_0
I1107 22:48:50.811879 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.811879 19164 net.cpp:137] Memory required for data: 115918000
I1107 22:48:50.811879 19164 layer_factory.cpp:58] Creating layer conv2
I1107 22:48:50.811879 19164 net.cpp:84] Creating Layer conv2
I1107 22:48:50.811879 19164 net.cpp:406] conv2 <- conv1_0
I1107 22:48:50.811879 19164 net.cpp:380] conv2 -> conv2
I1107 22:48:50.811879 19164 net.cpp:122] Setting up conv2
I1107 22:48:50.811879 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.811879 19164 net.cpp:137] Memory required for data: 132302000
I1107 22:48:50.811879 19164 layer_factory.cpp:58] Creating layer bn2
I1107 22:48:50.811879 19164 net.cpp:84] Creating Layer bn2
I1107 22:48:50.811879 19164 net.cpp:406] bn2 <- conv2
I1107 22:48:50.812878 19164 net.cpp:367] bn2 -> conv2 (in-place)
I1107 22:48:50.812878 19164 net.cpp:122] Setting up bn2
I1107 22:48:50.812878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.812878 19164 net.cpp:137] Memory required for data: 148686000
I1107 22:48:50.812878 19164 layer_factory.cpp:58] Creating layer scale2
I1107 22:48:50.812878 19164 net.cpp:84] Creating Layer scale2
I1107 22:48:50.812878 19164 net.cpp:406] scale2 <- conv2
I1107 22:48:50.812878 19164 net.cpp:367] scale2 -> conv2 (in-place)
I1107 22:48:50.812878 19164 layer_factory.cpp:58] Creating layer scale2
I1107 22:48:50.812878 19164 net.cpp:122] Setting up scale2
I1107 22:48:50.812878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.812878 19164 net.cpp:137] Memory required for data: 165070000
I1107 22:48:50.812878 19164 layer_factory.cpp:58] Creating layer relu2
I1107 22:48:50.812878 19164 net.cpp:84] Creating Layer relu2
I1107 22:48:50.812878 19164 net.cpp:406] relu2 <- conv2
I1107 22:48:50.812878 19164 net.cpp:367] relu2 -> conv2 (in-place)
I1107 22:48:50.812878 19164 net.cpp:122] Setting up relu2
I1107 22:48:50.812878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.812878 19164 net.cpp:137] Memory required for data: 181454000
I1107 22:48:50.812878 19164 layer_factory.cpp:58] Creating layer conv2_1
I1107 22:48:50.812878 19164 net.cpp:84] Creating Layer conv2_1
I1107 22:48:50.812878 19164 net.cpp:406] conv2_1 <- conv2
I1107 22:48:50.812878 19164 net.cpp:380] conv2_1 -> conv2_1
I1107 22:48:50.813879 19164 net.cpp:122] Setting up conv2_1
I1107 22:48:50.814878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.814878 19164 net.cpp:137] Memory required for data: 197838000
I1107 22:48:50.814878 19164 layer_factory.cpp:58] Creating layer bn2_1
I1107 22:48:50.814878 19164 net.cpp:84] Creating Layer bn2_1
I1107 22:48:50.814878 19164 net.cpp:406] bn2_1 <- conv2_1
I1107 22:48:50.814878 19164 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1107 22:48:50.814878 19164 net.cpp:122] Setting up bn2_1
I1107 22:48:50.814878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.814878 19164 net.cpp:137] Memory required for data: 214222000
I1107 22:48:50.814878 19164 layer_factory.cpp:58] Creating layer scale2_1
I1107 22:48:50.814878 19164 net.cpp:84] Creating Layer scale2_1
I1107 22:48:50.814878 19164 net.cpp:406] scale2_1 <- conv2_1
I1107 22:48:50.814878 19164 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1107 22:48:50.814878 19164 layer_factory.cpp:58] Creating layer scale2_1
I1107 22:48:50.814878 19164 net.cpp:122] Setting up scale2_1
I1107 22:48:50.814878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.814878 19164 net.cpp:137] Memory required for data: 230606000
I1107 22:48:50.814878 19164 layer_factory.cpp:58] Creating layer relu2_1
I1107 22:48:50.814878 19164 net.cpp:84] Creating Layer relu2_1
I1107 22:48:50.814878 19164 net.cpp:406] relu2_1 <- conv2_1
I1107 22:48:50.814878 19164 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1107 22:48:50.814878 19164 net.cpp:122] Setting up relu2_1
I1107 22:48:50.814878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.814878 19164 net.cpp:137] Memory required for data: 246990000
I1107 22:48:50.814878 19164 layer_factory.cpp:58] Creating layer conv2_2
I1107 22:48:50.814878 19164 net.cpp:84] Creating Layer conv2_2
I1107 22:48:50.814878 19164 net.cpp:406] conv2_2 <- conv2_1
I1107 22:48:50.814878 19164 net.cpp:380] conv2_2 -> conv2_2
I1107 22:48:50.816887 19164 net.cpp:122] Setting up conv2_2
I1107 22:48:50.816887 19164 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 22:48:50.816887 19164 net.cpp:137] Memory required for data: 267470000
I1107 22:48:50.816887 19164 layer_factory.cpp:58] Creating layer bn2_2
I1107 22:48:50.816887 19164 net.cpp:84] Creating Layer bn2_2
I1107 22:48:50.816887 19164 net.cpp:406] bn2_2 <- conv2_2
I1107 22:48:50.816887 19164 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1107 22:48:50.816887 19164 net.cpp:122] Setting up bn2_2
I1107 22:48:50.816887 19164 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 22:48:50.816887 19164 net.cpp:137] Memory required for data: 287950000
I1107 22:48:50.816887 19164 layer_factory.cpp:58] Creating layer scale2_2
I1107 22:48:50.816887 19164 net.cpp:84] Creating Layer scale2_2
I1107 22:48:50.816887 19164 net.cpp:406] scale2_2 <- conv2_2
I1107 22:48:50.816887 19164 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1107 22:48:50.816887 19164 layer_factory.cpp:58] Creating layer scale2_2
I1107 22:48:50.816887 19164 net.cpp:122] Setting up scale2_2
I1107 22:48:50.816887 19164 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 22:48:50.816887 19164 net.cpp:137] Memory required for data: 308430000
I1107 22:48:50.816887 19164 layer_factory.cpp:58] Creating layer relu2_2
I1107 22:48:50.816887 19164 net.cpp:84] Creating Layer relu2_2
I1107 22:48:50.816887 19164 net.cpp:406] relu2_2 <- conv2_2
I1107 22:48:50.816887 19164 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1107 22:48:50.816887 19164 net.cpp:122] Setting up relu2_2
I1107 22:48:50.816887 19164 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 22:48:50.816887 19164 net.cpp:137] Memory required for data: 328910000
I1107 22:48:50.816887 19164 layer_factory.cpp:58] Creating layer pool2_1
I1107 22:48:50.816887 19164 net.cpp:84] Creating Layer pool2_1
I1107 22:48:50.816887 19164 net.cpp:406] pool2_1 <- conv2_2
I1107 22:48:50.816887 19164 net.cpp:380] pool2_1 -> pool2_1
I1107 22:48:50.818879 19164 net.cpp:122] Setting up pool2_1
I1107 22:48:50.818879 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.818879 19164 net.cpp:137] Memory required for data: 334030000
I1107 22:48:50.818879 19164 layer_factory.cpp:58] Creating layer conv3
I1107 22:48:50.818879 19164 net.cpp:84] Creating Layer conv3
I1107 22:48:50.818879 19164 net.cpp:406] conv3 <- pool2_1
I1107 22:48:50.818879 19164 net.cpp:380] conv3 -> conv3
I1107 22:48:50.819878 19164 net.cpp:122] Setting up conv3
I1107 22:48:50.819878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.819878 19164 net.cpp:137] Memory required for data: 339150000
I1107 22:48:50.819878 19164 layer_factory.cpp:58] Creating layer bn3
I1107 22:48:50.819878 19164 net.cpp:84] Creating Layer bn3
I1107 22:48:50.819878 19164 net.cpp:406] bn3 <- conv3
I1107 22:48:50.819878 19164 net.cpp:367] bn3 -> conv3 (in-place)
I1107 22:48:50.819878 19164 net.cpp:122] Setting up bn3
I1107 22:48:50.819878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.819878 19164 net.cpp:137] Memory required for data: 344270000
I1107 22:48:50.819878 19164 layer_factory.cpp:58] Creating layer scale3
I1107 22:48:50.819878 19164 net.cpp:84] Creating Layer scale3
I1107 22:48:50.819878 19164 net.cpp:406] scale3 <- conv3
I1107 22:48:50.819878 19164 net.cpp:367] scale3 -> conv3 (in-place)
I1107 22:48:50.819878 19164 layer_factory.cpp:58] Creating layer scale3
I1107 22:48:50.820878 19164 net.cpp:122] Setting up scale3
I1107 22:48:50.820878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.820878 19164 net.cpp:137] Memory required for data: 349390000
I1107 22:48:50.820878 19164 layer_factory.cpp:58] Creating layer relu3
I1107 22:48:50.820878 19164 net.cpp:84] Creating Layer relu3
I1107 22:48:50.820878 19164 net.cpp:406] relu3 <- conv3
I1107 22:48:50.820878 19164 net.cpp:367] relu3 -> conv3 (in-place)
I1107 22:48:50.820878 19164 net.cpp:122] Setting up relu3
I1107 22:48:50.820878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.820878 19164 net.cpp:137] Memory required for data: 354510000
I1107 22:48:50.820878 19164 layer_factory.cpp:58] Creating layer conv3_1
I1107 22:48:50.820878 19164 net.cpp:84] Creating Layer conv3_1
I1107 22:48:50.820878 19164 net.cpp:406] conv3_1 <- conv3
I1107 22:48:50.820878 19164 net.cpp:380] conv3_1 -> conv3_1
I1107 22:48:50.821887 19164 net.cpp:122] Setting up conv3_1
I1107 22:48:50.821887 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.821887 19164 net.cpp:137] Memory required for data: 359630000
I1107 22:48:50.821887 19164 layer_factory.cpp:58] Creating layer bn3_1
I1107 22:48:50.821887 19164 net.cpp:84] Creating Layer bn3_1
I1107 22:48:50.821887 19164 net.cpp:406] bn3_1 <- conv3_1
I1107 22:48:50.821887 19164 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1107 22:48:50.821887 19164 net.cpp:122] Setting up bn3_1
I1107 22:48:50.821887 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.821887 19164 net.cpp:137] Memory required for data: 364750000
I1107 22:48:50.821887 19164 layer_factory.cpp:58] Creating layer scale3_1
I1107 22:48:50.821887 19164 net.cpp:84] Creating Layer scale3_1
I1107 22:48:50.821887 19164 net.cpp:406] scale3_1 <- conv3_1
I1107 22:48:50.821887 19164 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1107 22:48:50.821887 19164 layer_factory.cpp:58] Creating layer scale3_1
I1107 22:48:50.822878 19164 net.cpp:122] Setting up scale3_1
I1107 22:48:50.822878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.822878 19164 net.cpp:137] Memory required for data: 369870000
I1107 22:48:50.822878 19164 layer_factory.cpp:58] Creating layer relu3_1
I1107 22:48:50.822878 19164 net.cpp:84] Creating Layer relu3_1
I1107 22:48:50.822878 19164 net.cpp:406] relu3_1 <- conv3_1
I1107 22:48:50.822878 19164 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1107 22:48:50.822878 19164 net.cpp:122] Setting up relu3_1
I1107 22:48:50.822878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.822878 19164 net.cpp:137] Memory required for data: 374990000
I1107 22:48:50.822878 19164 layer_factory.cpp:58] Creating layer conv4
I1107 22:48:50.822878 19164 net.cpp:84] Creating Layer conv4
I1107 22:48:50.822878 19164 net.cpp:406] conv4 <- conv3_1
I1107 22:48:50.822878 19164 net.cpp:380] conv4 -> conv4
I1107 22:48:50.823879 19164 net.cpp:122] Setting up conv4
I1107 22:48:50.823879 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.823879 19164 net.cpp:137] Memory required for data: 380110000
I1107 22:48:50.823879 19164 layer_factory.cpp:58] Creating layer bn4
I1107 22:48:50.823879 19164 net.cpp:84] Creating Layer bn4
I1107 22:48:50.823879 19164 net.cpp:406] bn4 <- conv4
I1107 22:48:50.823879 19164 net.cpp:367] bn4 -> conv4 (in-place)
I1107 22:48:50.823879 19164 net.cpp:122] Setting up bn4
I1107 22:48:50.823879 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.823879 19164 net.cpp:137] Memory required for data: 385230000
I1107 22:48:50.823879 19164 layer_factory.cpp:58] Creating layer scale4
I1107 22:48:50.823879 19164 net.cpp:84] Creating Layer scale4
I1107 22:48:50.823879 19164 net.cpp:406] scale4 <- conv4
I1107 22:48:50.823879 19164 net.cpp:367] scale4 -> conv4 (in-place)
I1107 22:48:50.823879 19164 layer_factory.cpp:58] Creating layer scale4
I1107 22:48:50.823879 19164 net.cpp:122] Setting up scale4
I1107 22:48:50.823879 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.823879 19164 net.cpp:137] Memory required for data: 390350000
I1107 22:48:50.823879 19164 layer_factory.cpp:58] Creating layer relu4
I1107 22:48:50.823879 19164 net.cpp:84] Creating Layer relu4
I1107 22:48:50.823879 19164 net.cpp:406] relu4 <- conv4
I1107 22:48:50.823879 19164 net.cpp:367] relu4 -> conv4 (in-place)
I1107 22:48:50.824879 19164 net.cpp:122] Setting up relu4
I1107 22:48:50.824879 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.824879 19164 net.cpp:137] Memory required for data: 395470000
I1107 22:48:50.824879 19164 layer_factory.cpp:58] Creating layer conv4_1
I1107 22:48:50.824879 19164 net.cpp:84] Creating Layer conv4_1
I1107 22:48:50.824879 19164 net.cpp:406] conv4_1 <- conv4
I1107 22:48:50.824879 19164 net.cpp:380] conv4_1 -> conv4_1
I1107 22:48:50.825878 19164 net.cpp:122] Setting up conv4_1
I1107 22:48:50.825878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.825878 19164 net.cpp:137] Memory required for data: 400590000
I1107 22:48:50.825878 19164 layer_factory.cpp:58] Creating layer bn4_1
I1107 22:48:50.825878 19164 net.cpp:84] Creating Layer bn4_1
I1107 22:48:50.825878 19164 net.cpp:406] bn4_1 <- conv4_1
I1107 22:48:50.825878 19164 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1107 22:48:50.825878 19164 net.cpp:122] Setting up bn4_1
I1107 22:48:50.825878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.825878 19164 net.cpp:137] Memory required for data: 405710000
I1107 22:48:50.825878 19164 layer_factory.cpp:58] Creating layer scale4_1
I1107 22:48:50.825878 19164 net.cpp:84] Creating Layer scale4_1
I1107 22:48:50.825878 19164 net.cpp:406] scale4_1 <- conv4_1
I1107 22:48:50.825878 19164 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1107 22:48:50.825878 19164 layer_factory.cpp:58] Creating layer scale4_1
I1107 22:48:50.825878 19164 net.cpp:122] Setting up scale4_1
I1107 22:48:50.825878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.825878 19164 net.cpp:137] Memory required for data: 410830000
I1107 22:48:50.825878 19164 layer_factory.cpp:58] Creating layer relu4_1
I1107 22:48:50.825878 19164 net.cpp:84] Creating Layer relu4_1
I1107 22:48:50.825878 19164 net.cpp:406] relu4_1 <- conv4_1
I1107 22:48:50.825878 19164 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1107 22:48:50.826881 19164 net.cpp:122] Setting up relu4_1
I1107 22:48:50.826881 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.826881 19164 net.cpp:137] Memory required for data: 415950000
I1107 22:48:50.826881 19164 layer_factory.cpp:58] Creating layer conv4_2
I1107 22:48:50.826881 19164 net.cpp:84] Creating Layer conv4_2
I1107 22:48:50.826881 19164 net.cpp:406] conv4_2 <- conv4_1
I1107 22:48:50.826881 19164 net.cpp:380] conv4_2 -> conv4_2
I1107 22:48:50.827879 19164 net.cpp:122] Setting up conv4_2
I1107 22:48:50.827879 19164 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 22:48:50.827879 19164 net.cpp:137] Memory required for data: 421889200
I1107 22:48:50.827879 19164 layer_factory.cpp:58] Creating layer bn4_2
I1107 22:48:50.827879 19164 net.cpp:84] Creating Layer bn4_2
I1107 22:48:50.827879 19164 net.cpp:406] bn4_2 <- conv4_2
I1107 22:48:50.827879 19164 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1107 22:48:50.827879 19164 net.cpp:122] Setting up bn4_2
I1107 22:48:50.827879 19164 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 22:48:50.827879 19164 net.cpp:137] Memory required for data: 427828400
I1107 22:48:50.827879 19164 layer_factory.cpp:58] Creating layer scale4_2
I1107 22:48:50.827879 19164 net.cpp:84] Creating Layer scale4_2
I1107 22:48:50.827879 19164 net.cpp:406] scale4_2 <- conv4_2
I1107 22:48:50.827879 19164 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1107 22:48:50.827879 19164 layer_factory.cpp:58] Creating layer scale4_2
I1107 22:48:50.827879 19164 net.cpp:122] Setting up scale4_2
I1107 22:48:50.827879 19164 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 22:48:50.827879 19164 net.cpp:137] Memory required for data: 433767600
I1107 22:48:50.827879 19164 layer_factory.cpp:58] Creating layer relu4_2
I1107 22:48:50.827879 19164 net.cpp:84] Creating Layer relu4_2
I1107 22:48:50.827879 19164 net.cpp:406] relu4_2 <- conv4_2
I1107 22:48:50.827879 19164 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1107 22:48:50.828878 19164 net.cpp:122] Setting up relu4_2
I1107 22:48:50.828878 19164 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 22:48:50.828878 19164 net.cpp:137] Memory required for data: 439706800
I1107 22:48:50.828878 19164 layer_factory.cpp:58] Creating layer pool4_2
I1107 22:48:50.828878 19164 net.cpp:84] Creating Layer pool4_2
I1107 22:48:50.828878 19164 net.cpp:406] pool4_2 <- conv4_2
I1107 22:48:50.828878 19164 net.cpp:380] pool4_2 -> pool4_2
I1107 22:48:50.829879 19164 net.cpp:122] Setting up pool4_2
I1107 22:48:50.829879 19164 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 22:48:50.829879 19164 net.cpp:137] Memory required for data: 441191600
I1107 22:48:50.829879 19164 layer_factory.cpp:58] Creating layer conv4_0
I1107 22:48:50.829879 19164 net.cpp:84] Creating Layer conv4_0
I1107 22:48:50.829879 19164 net.cpp:406] conv4_0 <- pool4_2
I1107 22:48:50.829879 19164 net.cpp:380] conv4_0 -> conv4_0
I1107 22:48:50.830878 19164 net.cpp:122] Setting up conv4_0
I1107 22:48:50.830878 19164 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 22:48:50.830878 19164 net.cpp:137] Memory required for data: 442676400
I1107 22:48:50.830878 19164 layer_factory.cpp:58] Creating layer bn4_0
I1107 22:48:50.830878 19164 net.cpp:84] Creating Layer bn4_0
I1107 22:48:50.830878 19164 net.cpp:406] bn4_0 <- conv4_0
I1107 22:48:50.830878 19164 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1107 22:48:50.830878 19164 net.cpp:122] Setting up bn4_0
I1107 22:48:50.830878 19164 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 22:48:50.830878 19164 net.cpp:137] Memory required for data: 444161200
I1107 22:48:50.830878 19164 layer_factory.cpp:58] Creating layer scale4_0
I1107 22:48:50.830878 19164 net.cpp:84] Creating Layer scale4_0
I1107 22:48:50.830878 19164 net.cpp:406] scale4_0 <- conv4_0
I1107 22:48:50.830878 19164 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1107 22:48:50.830878 19164 layer_factory.cpp:58] Creating layer scale4_0
I1107 22:48:50.831878 19164 net.cpp:122] Setting up scale4_0
I1107 22:48:50.831878 19164 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 22:48:50.831878 19164 net.cpp:137] Memory required for data: 445646000
I1107 22:48:50.831878 19164 layer_factory.cpp:58] Creating layer relu4_0
I1107 22:48:50.831878 19164 net.cpp:84] Creating Layer relu4_0
I1107 22:48:50.831878 19164 net.cpp:406] relu4_0 <- conv4_0
I1107 22:48:50.831878 19164 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1107 22:48:50.831878 19164 net.cpp:122] Setting up relu4_0
I1107 22:48:50.831878 19164 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 22:48:50.831878 19164 net.cpp:137] Memory required for data: 447130800
I1107 22:48:50.831878 19164 layer_factory.cpp:58] Creating layer conv11
I1107 22:48:50.831878 19164 net.cpp:84] Creating Layer conv11
I1107 22:48:50.831878 19164 net.cpp:406] conv11 <- conv4_0
I1107 22:48:50.831878 19164 net.cpp:380] conv11 -> conv11
I1107 22:48:50.832880 19164 net.cpp:122] Setting up conv11
I1107 22:48:50.832880 19164 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 22:48:50.832880 19164 net.cpp:137] Memory required for data: 448922800
I1107 22:48:50.832880 19164 layer_factory.cpp:58] Creating layer bn_conv11
I1107 22:48:50.832880 19164 net.cpp:84] Creating Layer bn_conv11
I1107 22:48:50.832880 19164 net.cpp:406] bn_conv11 <- conv11
I1107 22:48:50.832880 19164 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1107 22:48:50.832880 19164 net.cpp:122] Setting up bn_conv11
I1107 22:48:50.832880 19164 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 22:48:50.832880 19164 net.cpp:137] Memory required for data: 450714800
I1107 22:48:50.832880 19164 layer_factory.cpp:58] Creating layer scale_conv11
I1107 22:48:50.832880 19164 net.cpp:84] Creating Layer scale_conv11
I1107 22:48:50.832880 19164 net.cpp:406] scale_conv11 <- conv11
I1107 22:48:50.832880 19164 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1107 22:48:50.832880 19164 layer_factory.cpp:58] Creating layer scale_conv11
I1107 22:48:50.833878 19164 net.cpp:122] Setting up scale_conv11
I1107 22:48:50.833878 19164 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 22:48:50.833878 19164 net.cpp:137] Memory required for data: 452506800
I1107 22:48:50.833878 19164 layer_factory.cpp:58] Creating layer relu_conv11
I1107 22:48:50.833878 19164 net.cpp:84] Creating Layer relu_conv11
I1107 22:48:50.833878 19164 net.cpp:406] relu_conv11 <- conv11
I1107 22:48:50.833878 19164 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1107 22:48:50.833878 19164 net.cpp:122] Setting up relu_conv11
I1107 22:48:50.833878 19164 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 22:48:50.833878 19164 net.cpp:137] Memory required for data: 454298800
I1107 22:48:50.833878 19164 layer_factory.cpp:58] Creating layer conv12
I1107 22:48:50.833878 19164 net.cpp:84] Creating Layer conv12
I1107 22:48:50.833878 19164 net.cpp:406] conv12 <- conv11
I1107 22:48:50.833878 19164 net.cpp:380] conv12 -> conv12
I1107 22:48:50.834878 19164 net.cpp:122] Setting up conv12
I1107 22:48:50.835880 19164 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 22:48:50.835880 19164 net.cpp:137] Memory required for data: 456602800
I1107 22:48:50.835880 19164 layer_factory.cpp:58] Creating layer bn_conv12
I1107 22:48:50.835880 19164 net.cpp:84] Creating Layer bn_conv12
I1107 22:48:50.835880 19164 net.cpp:406] bn_conv12 <- conv12
I1107 22:48:50.835880 19164 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1107 22:48:50.835880 19164 net.cpp:122] Setting up bn_conv12
I1107 22:48:50.835880 19164 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 22:48:50.835880 19164 net.cpp:137] Memory required for data: 458906800
I1107 22:48:50.835880 19164 layer_factory.cpp:58] Creating layer scale_conv12
I1107 22:48:50.835880 19164 net.cpp:84] Creating Layer scale_conv12
I1107 22:48:50.835880 19164 net.cpp:406] scale_conv12 <- conv12
I1107 22:48:50.835880 19164 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1107 22:48:50.835880 19164 layer_factory.cpp:58] Creating layer scale_conv12
I1107 22:48:50.835880 19164 net.cpp:122] Setting up scale_conv12
I1107 22:48:50.835880 19164 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 22:48:50.835880 19164 net.cpp:137] Memory required for data: 461210800
I1107 22:48:50.835880 19164 layer_factory.cpp:58] Creating layer relu_conv12
I1107 22:48:50.835880 19164 net.cpp:84] Creating Layer relu_conv12
I1107 22:48:50.835880 19164 net.cpp:406] relu_conv12 <- conv12
I1107 22:48:50.835880 19164 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1107 22:48:50.835880 19164 net.cpp:122] Setting up relu_conv12
I1107 22:48:50.835880 19164 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 22:48:50.835880 19164 net.cpp:137] Memory required for data: 463514800
I1107 22:48:50.835880 19164 layer_factory.cpp:58] Creating layer poolcp6
I1107 22:48:50.835880 19164 net.cpp:84] Creating Layer poolcp6
I1107 22:48:50.835880 19164 net.cpp:406] poolcp6 <- conv12
I1107 22:48:50.835880 19164 net.cpp:380] poolcp6 -> poolcp6
I1107 22:48:50.835880 19164 net.cpp:122] Setting up poolcp6
I1107 22:48:50.835880 19164 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1107 22:48:50.835880 19164 net.cpp:137] Memory required for data: 463550800
I1107 22:48:50.835880 19164 layer_factory.cpp:58] Creating layer ip1
I1107 22:48:50.835880 19164 net.cpp:84] Creating Layer ip1
I1107 22:48:50.835880 19164 net.cpp:406] ip1 <- poolcp6
I1107 22:48:50.835880 19164 net.cpp:380] ip1 -> ip1
I1107 22:48:50.835880 19164 net.cpp:122] Setting up ip1
I1107 22:48:50.835880 19164 net.cpp:129] Top shape: 100 100 (10000)
I1107 22:48:50.836879 19164 net.cpp:137] Memory required for data: 463590800
I1107 22:48:50.836879 19164 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1107 22:48:50.836879 19164 net.cpp:84] Creating Layer ip1_ip1_0_split
I1107 22:48:50.836879 19164 net.cpp:406] ip1_ip1_0_split <- ip1
I1107 22:48:50.836879 19164 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1107 22:48:50.836879 19164 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1107 22:48:50.836879 19164 net.cpp:122] Setting up ip1_ip1_0_split
I1107 22:48:50.836879 19164 net.cpp:129] Top shape: 100 100 (10000)
I1107 22:48:50.836879 19164 net.cpp:129] Top shape: 100 100 (10000)
I1107 22:48:50.836879 19164 net.cpp:137] Memory required for data: 463670800
I1107 22:48:50.836879 19164 layer_factory.cpp:58] Creating layer accuracy_training
I1107 22:48:50.836879 19164 net.cpp:84] Creating Layer accuracy_training
I1107 22:48:50.836879 19164 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1107 22:48:50.836879 19164 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1107 22:48:50.836879 19164 net.cpp:380] accuracy_training -> accuracy_training
I1107 22:48:50.836879 19164 net.cpp:122] Setting up accuracy_training
I1107 22:48:50.836879 19164 net.cpp:129] Top shape: (1)
I1107 22:48:50.836879 19164 net.cpp:137] Memory required for data: 463670804
I1107 22:48:50.836879 19164 layer_factory.cpp:58] Creating layer loss
I1107 22:48:50.836879 19164 net.cpp:84] Creating Layer loss
I1107 22:48:50.836879 19164 net.cpp:406] loss <- ip1_ip1_0_split_1
I1107 22:48:50.836879 19164 net.cpp:406] loss <- label_cifar_1_split_1
I1107 22:48:50.836879 19164 net.cpp:380] loss -> loss
I1107 22:48:50.836879 19164 layer_factory.cpp:58] Creating layer loss
I1107 22:48:50.836879 19164 net.cpp:122] Setting up loss
I1107 22:48:50.836879 19164 net.cpp:129] Top shape: (1)
I1107 22:48:50.836879 19164 net.cpp:132]     with loss weight 1
I1107 22:48:50.836879 19164 net.cpp:137] Memory required for data: 463670808
I1107 22:48:50.836879 19164 net.cpp:198] loss needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:200] accuracy_training does not need backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] ip1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] poolcp6 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu_conv12 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale_conv12 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn_conv12 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv12 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu_conv11 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale_conv11 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn_conv11 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv11 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu4_0 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale4_0 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn4_0 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv4_0 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] pool4_2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu4_2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale4_2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn4_2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv4_2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu4_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale4_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn4_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv4_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu4 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale4 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn4 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv4 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu3_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale3_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn3_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv3_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu3 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale3 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn3 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv3 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] pool2_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu2_2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale2_2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn2_2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv2_2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu2_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale2_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn2_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv2_1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv2 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu1_0 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale1_0 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn1_0 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv1_0 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] relu1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] scale1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] bn1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:198] conv1 needs backward computation.
I1107 22:48:50.836879 19164 net.cpp:200] label_cifar_1_split does not need backward computation.
I1107 22:48:50.836879 19164 net.cpp:200] cifar does not need backward computation.
I1107 22:48:50.836879 19164 net.cpp:242] This network produces output accuracy_training
I1107 22:48:50.836879 19164 net.cpp:242] This network produces output loss
I1107 22:48:50.836879 19164 net.cpp:255] Network initialization done.
I1107 22:48:50.837878 19164 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1107 22:48:50.837878 19164 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1107 22:48:50.837878 19164 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1107 22:48:50.837878 19164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1107 22:48:50.838878 19164 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV1_360k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "pool2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "pool4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1107 22:48:50.838878 19164 layer_factory.cpp:58] Creating layer cifar
I1107 22:48:50.841878 19164 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1107 22:48:50.841878 19164 net.cpp:84] Creating Layer cifar
I1107 22:48:50.841878 19164 net.cpp:380] cifar -> data
I1107 22:48:50.841878 19164 net.cpp:380] cifar -> label
I1107 22:48:50.841878 19164 data_layer.cpp:45] output data size: 100,3,32,32
I1107 22:48:50.848877 19164 net.cpp:122] Setting up cifar
I1107 22:48:50.848877 19164 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1107 22:48:50.848877 19164 net.cpp:129] Top shape: 100 (100)
I1107 22:48:50.848877 19164 net.cpp:137] Memory required for data: 1229200
I1107 22:48:50.848877 19164 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1107 22:48:50.848877 19164 net.cpp:84] Creating Layer label_cifar_1_split
I1107 22:48:50.848877 19164 net.cpp:406] label_cifar_1_split <- label
I1107 22:48:50.848877 19164 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1107 22:48:50.848877 19164 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1107 22:48:50.848877 19164 net.cpp:122] Setting up label_cifar_1_split
I1107 22:48:50.848877 19164 net.cpp:129] Top shape: 100 (100)
I1107 22:48:50.848877 19164 net.cpp:129] Top shape: 100 (100)
I1107 22:48:50.848877 19164 net.cpp:137] Memory required for data: 1230000
I1107 22:48:50.848877 19164 layer_factory.cpp:58] Creating layer conv1
I1107 22:48:50.848877 19164 net.cpp:84] Creating Layer conv1
I1107 22:48:50.848877 19164 net.cpp:406] conv1 <- data
I1107 22:48:50.848877 19164 net.cpp:380] conv1 -> conv1
I1107 22:48:50.850878 17616 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1107 22:48:50.850878 19164 net.cpp:122] Setting up conv1
I1107 22:48:50.850878 19164 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 22:48:50.850878 19164 net.cpp:137] Memory required for data: 13518000
I1107 22:48:50.850878 19164 layer_factory.cpp:58] Creating layer bn1
I1107 22:48:50.850878 19164 net.cpp:84] Creating Layer bn1
I1107 22:48:50.850878 19164 net.cpp:406] bn1 <- conv1
I1107 22:48:50.850878 19164 net.cpp:367] bn1 -> conv1 (in-place)
I1107 22:48:50.851878 19164 net.cpp:122] Setting up bn1
I1107 22:48:50.851878 19164 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 22:48:50.851878 19164 net.cpp:137] Memory required for data: 25806000
I1107 22:48:50.851878 19164 layer_factory.cpp:58] Creating layer scale1
I1107 22:48:50.851878 19164 net.cpp:84] Creating Layer scale1
I1107 22:48:50.851878 19164 net.cpp:406] scale1 <- conv1
I1107 22:48:50.851878 19164 net.cpp:367] scale1 -> conv1 (in-place)
I1107 22:48:50.851878 19164 layer_factory.cpp:58] Creating layer scale1
I1107 22:48:50.851878 19164 net.cpp:122] Setting up scale1
I1107 22:48:50.851878 19164 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 22:48:50.851878 19164 net.cpp:137] Memory required for data: 38094000
I1107 22:48:50.851878 19164 layer_factory.cpp:58] Creating layer relu1
I1107 22:48:50.851878 19164 net.cpp:84] Creating Layer relu1
I1107 22:48:50.851878 19164 net.cpp:406] relu1 <- conv1
I1107 22:48:50.851878 19164 net.cpp:367] relu1 -> conv1 (in-place)
I1107 22:48:50.851878 19164 net.cpp:122] Setting up relu1
I1107 22:48:50.851878 19164 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 22:48:50.851878 19164 net.cpp:137] Memory required for data: 50382000
I1107 22:48:50.851878 19164 layer_factory.cpp:58] Creating layer conv1_0
I1107 22:48:50.851878 19164 net.cpp:84] Creating Layer conv1_0
I1107 22:48:50.851878 19164 net.cpp:406] conv1_0 <- conv1
I1107 22:48:50.851878 19164 net.cpp:380] conv1_0 -> conv1_0
I1107 22:48:50.853878 19164 net.cpp:122] Setting up conv1_0
I1107 22:48:50.853878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.853878 19164 net.cpp:137] Memory required for data: 66766000
I1107 22:48:50.853878 19164 layer_factory.cpp:58] Creating layer bn1_0
I1107 22:48:50.853878 19164 net.cpp:84] Creating Layer bn1_0
I1107 22:48:50.853878 19164 net.cpp:406] bn1_0 <- conv1_0
I1107 22:48:50.853878 19164 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1107 22:48:50.853878 19164 net.cpp:122] Setting up bn1_0
I1107 22:48:50.853878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.853878 19164 net.cpp:137] Memory required for data: 83150000
I1107 22:48:50.853878 19164 layer_factory.cpp:58] Creating layer scale1_0
I1107 22:48:50.853878 19164 net.cpp:84] Creating Layer scale1_0
I1107 22:48:50.853878 19164 net.cpp:406] scale1_0 <- conv1_0
I1107 22:48:50.853878 19164 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1107 22:48:50.853878 19164 layer_factory.cpp:58] Creating layer scale1_0
I1107 22:48:50.853878 19164 net.cpp:122] Setting up scale1_0
I1107 22:48:50.853878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.853878 19164 net.cpp:137] Memory required for data: 99534000
I1107 22:48:50.853878 19164 layer_factory.cpp:58] Creating layer relu1_0
I1107 22:48:50.853878 19164 net.cpp:84] Creating Layer relu1_0
I1107 22:48:50.853878 19164 net.cpp:406] relu1_0 <- conv1_0
I1107 22:48:50.853878 19164 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1107 22:48:50.853878 19164 net.cpp:122] Setting up relu1_0
I1107 22:48:50.853878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.853878 19164 net.cpp:137] Memory required for data: 115918000
I1107 22:48:50.853878 19164 layer_factory.cpp:58] Creating layer conv2
I1107 22:48:50.853878 19164 net.cpp:84] Creating Layer conv2
I1107 22:48:50.853878 19164 net.cpp:406] conv2 <- conv1_0
I1107 22:48:50.853878 19164 net.cpp:380] conv2 -> conv2
I1107 22:48:50.854879 19164 net.cpp:122] Setting up conv2
I1107 22:48:50.855878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.855878 19164 net.cpp:137] Memory required for data: 132302000
I1107 22:48:50.855878 19164 layer_factory.cpp:58] Creating layer bn2
I1107 22:48:50.855878 19164 net.cpp:84] Creating Layer bn2
I1107 22:48:50.855878 19164 net.cpp:406] bn2 <- conv2
I1107 22:48:50.855878 19164 net.cpp:367] bn2 -> conv2 (in-place)
I1107 22:48:50.855878 19164 net.cpp:122] Setting up bn2
I1107 22:48:50.855878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.855878 19164 net.cpp:137] Memory required for data: 148686000
I1107 22:48:50.855878 19164 layer_factory.cpp:58] Creating layer scale2
I1107 22:48:50.855878 19164 net.cpp:84] Creating Layer scale2
I1107 22:48:50.855878 19164 net.cpp:406] scale2 <- conv2
I1107 22:48:50.855878 19164 net.cpp:367] scale2 -> conv2 (in-place)
I1107 22:48:50.855878 19164 layer_factory.cpp:58] Creating layer scale2
I1107 22:48:50.855878 19164 net.cpp:122] Setting up scale2
I1107 22:48:50.855878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.855878 19164 net.cpp:137] Memory required for data: 165070000
I1107 22:48:50.855878 19164 layer_factory.cpp:58] Creating layer relu2
I1107 22:48:50.855878 19164 net.cpp:84] Creating Layer relu2
I1107 22:48:50.855878 19164 net.cpp:406] relu2 <- conv2
I1107 22:48:50.855878 19164 net.cpp:367] relu2 -> conv2 (in-place)
I1107 22:48:50.855878 19164 net.cpp:122] Setting up relu2
I1107 22:48:50.855878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.855878 19164 net.cpp:137] Memory required for data: 181454000
I1107 22:48:50.855878 19164 layer_factory.cpp:58] Creating layer conv2_1
I1107 22:48:50.855878 19164 net.cpp:84] Creating Layer conv2_1
I1107 22:48:50.855878 19164 net.cpp:406] conv2_1 <- conv2
I1107 22:48:50.855878 19164 net.cpp:380] conv2_1 -> conv2_1
I1107 22:48:50.857878 19164 net.cpp:122] Setting up conv2_1
I1107 22:48:50.857878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.857878 19164 net.cpp:137] Memory required for data: 197838000
I1107 22:48:50.857878 19164 layer_factory.cpp:58] Creating layer bn2_1
I1107 22:48:50.857878 19164 net.cpp:84] Creating Layer bn2_1
I1107 22:48:50.857878 19164 net.cpp:406] bn2_1 <- conv2_1
I1107 22:48:50.857878 19164 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1107 22:48:50.857878 19164 net.cpp:122] Setting up bn2_1
I1107 22:48:50.857878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.857878 19164 net.cpp:137] Memory required for data: 214222000
I1107 22:48:50.857878 19164 layer_factory.cpp:58] Creating layer scale2_1
I1107 22:48:50.857878 19164 net.cpp:84] Creating Layer scale2_1
I1107 22:48:50.857878 19164 net.cpp:406] scale2_1 <- conv2_1
I1107 22:48:50.857878 19164 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1107 22:48:50.857878 19164 layer_factory.cpp:58] Creating layer scale2_1
I1107 22:48:50.857878 19164 net.cpp:122] Setting up scale2_1
I1107 22:48:50.857878 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.857878 19164 net.cpp:137] Memory required for data: 230606000
I1107 22:48:50.857878 19164 layer_factory.cpp:58] Creating layer relu2_1
I1107 22:48:50.857878 19164 net.cpp:84] Creating Layer relu2_1
I1107 22:48:50.858880 19164 net.cpp:406] relu2_1 <- conv2_1
I1107 22:48:50.858880 19164 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1107 22:48:50.858880 19164 net.cpp:122] Setting up relu2_1
I1107 22:48:50.858880 19164 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 22:48:50.858880 19164 net.cpp:137] Memory required for data: 246990000
I1107 22:48:50.858880 19164 layer_factory.cpp:58] Creating layer conv2_2
I1107 22:48:50.858880 19164 net.cpp:84] Creating Layer conv2_2
I1107 22:48:50.858880 19164 net.cpp:406] conv2_2 <- conv2_1
I1107 22:48:50.858880 19164 net.cpp:380] conv2_2 -> conv2_2
I1107 22:48:50.859879 19164 net.cpp:122] Setting up conv2_2
I1107 22:48:50.859879 19164 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 22:48:50.859879 19164 net.cpp:137] Memory required for data: 267470000
I1107 22:48:50.859879 19164 layer_factory.cpp:58] Creating layer bn2_2
I1107 22:48:50.859879 19164 net.cpp:84] Creating Layer bn2_2
I1107 22:48:50.859879 19164 net.cpp:406] bn2_2 <- conv2_2
I1107 22:48:50.859879 19164 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1107 22:48:50.859879 19164 net.cpp:122] Setting up bn2_2
I1107 22:48:50.859879 19164 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 22:48:50.859879 19164 net.cpp:137] Memory required for data: 287950000
I1107 22:48:50.859879 19164 layer_factory.cpp:58] Creating layer scale2_2
I1107 22:48:50.859879 19164 net.cpp:84] Creating Layer scale2_2
I1107 22:48:50.859879 19164 net.cpp:406] scale2_2 <- conv2_2
I1107 22:48:50.859879 19164 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1107 22:48:50.859879 19164 layer_factory.cpp:58] Creating layer scale2_2
I1107 22:48:50.860879 19164 net.cpp:122] Setting up scale2_2
I1107 22:48:50.860879 19164 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 22:48:50.860879 19164 net.cpp:137] Memory required for data: 308430000
I1107 22:48:50.860879 19164 layer_factory.cpp:58] Creating layer relu2_2
I1107 22:48:50.860879 19164 net.cpp:84] Creating Layer relu2_2
I1107 22:48:50.860879 19164 net.cpp:406] relu2_2 <- conv2_2
I1107 22:48:50.860879 19164 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1107 22:48:50.860879 19164 net.cpp:122] Setting up relu2_2
I1107 22:48:50.860879 19164 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 22:48:50.860879 19164 net.cpp:137] Memory required for data: 328910000
I1107 22:48:50.860879 19164 layer_factory.cpp:58] Creating layer pool2_1
I1107 22:48:50.860879 19164 net.cpp:84] Creating Layer pool2_1
I1107 22:48:50.860879 19164 net.cpp:406] pool2_1 <- conv2_2
I1107 22:48:50.860879 19164 net.cpp:380] pool2_1 -> pool2_1
I1107 22:48:50.861878 19164 net.cpp:122] Setting up pool2_1
I1107 22:48:50.861878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.861878 19164 net.cpp:137] Memory required for data: 334030000
I1107 22:48:50.861878 19164 layer_factory.cpp:58] Creating layer conv3
I1107 22:48:50.861878 19164 net.cpp:84] Creating Layer conv3
I1107 22:48:50.861878 19164 net.cpp:406] conv3 <- pool2_1
I1107 22:48:50.861878 19164 net.cpp:380] conv3 -> conv3
I1107 22:48:50.863878 19164 net.cpp:122] Setting up conv3
I1107 22:48:50.863878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.863878 19164 net.cpp:137] Memory required for data: 339150000
I1107 22:48:50.863878 19164 layer_factory.cpp:58] Creating layer bn3
I1107 22:48:50.863878 19164 net.cpp:84] Creating Layer bn3
I1107 22:48:50.863878 19164 net.cpp:406] bn3 <- conv3
I1107 22:48:50.863878 19164 net.cpp:367] bn3 -> conv3 (in-place)
I1107 22:48:50.863878 19164 net.cpp:122] Setting up bn3
I1107 22:48:50.863878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.863878 19164 net.cpp:137] Memory required for data: 344270000
I1107 22:48:50.863878 19164 layer_factory.cpp:58] Creating layer scale3
I1107 22:48:50.863878 19164 net.cpp:84] Creating Layer scale3
I1107 22:48:50.863878 19164 net.cpp:406] scale3 <- conv3
I1107 22:48:50.863878 19164 net.cpp:367] scale3 -> conv3 (in-place)
I1107 22:48:50.863878 19164 layer_factory.cpp:58] Creating layer scale3
I1107 22:48:50.863878 19164 net.cpp:122] Setting up scale3
I1107 22:48:50.863878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.863878 19164 net.cpp:137] Memory required for data: 349390000
I1107 22:48:50.863878 19164 layer_factory.cpp:58] Creating layer relu3
I1107 22:48:50.863878 19164 net.cpp:84] Creating Layer relu3
I1107 22:48:50.863878 19164 net.cpp:406] relu3 <- conv3
I1107 22:48:50.863878 19164 net.cpp:367] relu3 -> conv3 (in-place)
I1107 22:48:50.863878 19164 net.cpp:122] Setting up relu3
I1107 22:48:50.863878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.863878 19164 net.cpp:137] Memory required for data: 354510000
I1107 22:48:50.863878 19164 layer_factory.cpp:58] Creating layer conv3_1
I1107 22:48:50.863878 19164 net.cpp:84] Creating Layer conv3_1
I1107 22:48:50.863878 19164 net.cpp:406] conv3_1 <- conv3
I1107 22:48:50.863878 19164 net.cpp:380] conv3_1 -> conv3_1
I1107 22:48:50.865878 19164 net.cpp:122] Setting up conv3_1
I1107 22:48:50.865878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.865878 19164 net.cpp:137] Memory required for data: 359630000
I1107 22:48:50.865878 19164 layer_factory.cpp:58] Creating layer bn3_1
I1107 22:48:50.865878 19164 net.cpp:84] Creating Layer bn3_1
I1107 22:48:50.865878 19164 net.cpp:406] bn3_1 <- conv3_1
I1107 22:48:50.865878 19164 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1107 22:48:50.865878 19164 net.cpp:122] Setting up bn3_1
I1107 22:48:50.865878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.865878 19164 net.cpp:137] Memory required for data: 364750000
I1107 22:48:50.865878 19164 layer_factory.cpp:58] Creating layer scale3_1
I1107 22:48:50.865878 19164 net.cpp:84] Creating Layer scale3_1
I1107 22:48:50.865878 19164 net.cpp:406] scale3_1 <- conv3_1
I1107 22:48:50.865878 19164 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1107 22:48:50.865878 19164 layer_factory.cpp:58] Creating layer scale3_1
I1107 22:48:50.865878 19164 net.cpp:122] Setting up scale3_1
I1107 22:48:50.865878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.865878 19164 net.cpp:137] Memory required for data: 369870000
I1107 22:48:50.865878 19164 layer_factory.cpp:58] Creating layer relu3_1
I1107 22:48:50.865878 19164 net.cpp:84] Creating Layer relu3_1
I1107 22:48:50.865878 19164 net.cpp:406] relu3_1 <- conv3_1
I1107 22:48:50.865878 19164 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1107 22:48:50.865878 19164 net.cpp:122] Setting up relu3_1
I1107 22:48:50.865878 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.865878 19164 net.cpp:137] Memory required for data: 374990000
I1107 22:48:50.865878 19164 layer_factory.cpp:58] Creating layer conv4
I1107 22:48:50.865878 19164 net.cpp:84] Creating Layer conv4
I1107 22:48:50.865878 19164 net.cpp:406] conv4 <- conv3_1
I1107 22:48:50.865878 19164 net.cpp:380] conv4 -> conv4
I1107 22:48:50.867879 19164 net.cpp:122] Setting up conv4
I1107 22:48:50.867879 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.867879 19164 net.cpp:137] Memory required for data: 380110000
I1107 22:48:50.867879 19164 layer_factory.cpp:58] Creating layer bn4
I1107 22:48:50.867879 19164 net.cpp:84] Creating Layer bn4
I1107 22:48:50.867879 19164 net.cpp:406] bn4 <- conv4
I1107 22:48:50.867879 19164 net.cpp:367] bn4 -> conv4 (in-place)
I1107 22:48:50.867879 19164 net.cpp:122] Setting up bn4
I1107 22:48:50.867879 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.867879 19164 net.cpp:137] Memory required for data: 385230000
I1107 22:48:50.867879 19164 layer_factory.cpp:58] Creating layer scale4
I1107 22:48:50.867879 19164 net.cpp:84] Creating Layer scale4
I1107 22:48:50.867879 19164 net.cpp:406] scale4 <- conv4
I1107 22:48:50.867879 19164 net.cpp:367] scale4 -> conv4 (in-place)
I1107 22:48:50.867879 19164 layer_factory.cpp:58] Creating layer scale4
I1107 22:48:50.867879 19164 net.cpp:122] Setting up scale4
I1107 22:48:50.867879 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.867879 19164 net.cpp:137] Memory required for data: 390350000
I1107 22:48:50.867879 19164 layer_factory.cpp:58] Creating layer relu4
I1107 22:48:50.867879 19164 net.cpp:84] Creating Layer relu4
I1107 22:48:50.867879 19164 net.cpp:406] relu4 <- conv4
I1107 22:48:50.868382 19164 net.cpp:367] relu4 -> conv4 (in-place)
I1107 22:48:50.868382 19164 net.cpp:122] Setting up relu4
I1107 22:48:50.868382 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.868382 19164 net.cpp:137] Memory required for data: 395470000
I1107 22:48:50.868382 19164 layer_factory.cpp:58] Creating layer conv4_1
I1107 22:48:50.868382 19164 net.cpp:84] Creating Layer conv4_1
I1107 22:48:50.868382 19164 net.cpp:406] conv4_1 <- conv4
I1107 22:48:50.868382 19164 net.cpp:380] conv4_1 -> conv4_1
I1107 22:48:50.869884 19164 net.cpp:122] Setting up conv4_1
I1107 22:48:50.869884 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.869884 19164 net.cpp:137] Memory required for data: 400590000
I1107 22:48:50.869884 19164 layer_factory.cpp:58] Creating layer bn4_1
I1107 22:48:50.869884 19164 net.cpp:84] Creating Layer bn4_1
I1107 22:48:50.869884 19164 net.cpp:406] bn4_1 <- conv4_1
I1107 22:48:50.869884 19164 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1107 22:48:50.869884 19164 net.cpp:122] Setting up bn4_1
I1107 22:48:50.869884 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.869884 19164 net.cpp:137] Memory required for data: 405710000
I1107 22:48:50.869884 19164 layer_factory.cpp:58] Creating layer scale4_1
I1107 22:48:50.869884 19164 net.cpp:84] Creating Layer scale4_1
I1107 22:48:50.869884 19164 net.cpp:406] scale4_1 <- conv4_1
I1107 22:48:50.869884 19164 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1107 22:48:50.869884 19164 layer_factory.cpp:58] Creating layer scale4_1
I1107 22:48:50.869884 19164 net.cpp:122] Setting up scale4_1
I1107 22:48:50.870383 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.870383 19164 net.cpp:137] Memory required for data: 410830000
I1107 22:48:50.870383 19164 layer_factory.cpp:58] Creating layer relu4_1
I1107 22:48:50.870383 19164 net.cpp:84] Creating Layer relu4_1
I1107 22:48:50.870383 19164 net.cpp:406] relu4_1 <- conv4_1
I1107 22:48:50.870383 19164 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1107 22:48:50.870383 19164 net.cpp:122] Setting up relu4_1
I1107 22:48:50.870383 19164 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 22:48:50.870383 19164 net.cpp:137] Memory required for data: 415950000
I1107 22:48:50.870383 19164 layer_factory.cpp:58] Creating layer conv4_2
I1107 22:48:50.870383 19164 net.cpp:84] Creating Layer conv4_2
I1107 22:48:50.870383 19164 net.cpp:406] conv4_2 <- conv4_1
I1107 22:48:50.870383 19164 net.cpp:380] conv4_2 -> conv4_2
I1107 22:48:50.871882 19164 net.cpp:122] Setting up conv4_2
I1107 22:48:50.871882 19164 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 22:48:50.871882 19164 net.cpp:137] Memory required for data: 421889200
I1107 22:48:50.871882 19164 layer_factory.cpp:58] Creating layer bn4_2
I1107 22:48:50.871882 19164 net.cpp:84] Creating Layer bn4_2
I1107 22:48:50.871882 19164 net.cpp:406] bn4_2 <- conv4_2
I1107 22:48:50.871882 19164 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1107 22:48:50.872383 19164 net.cpp:122] Setting up bn4_2
I1107 22:48:50.872383 19164 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 22:48:50.872383 19164 net.cpp:137] Memory required for data: 427828400
I1107 22:48:50.872383 19164 layer_factory.cpp:58] Creating layer scale4_2
I1107 22:48:50.872383 19164 net.cpp:84] Creating Layer scale4_2
I1107 22:48:50.872383 19164 net.cpp:406] scale4_2 <- conv4_2
I1107 22:48:50.872383 19164 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1107 22:48:50.872383 19164 layer_factory.cpp:58] Creating layer scale4_2
I1107 22:48:50.872383 19164 net.cpp:122] Setting up scale4_2
I1107 22:48:50.872383 19164 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 22:48:50.872383 19164 net.cpp:137] Memory required for data: 433767600
I1107 22:48:50.872383 19164 layer_factory.cpp:58] Creating layer relu4_2
I1107 22:48:50.872383 19164 net.cpp:84] Creating Layer relu4_2
I1107 22:48:50.872383 19164 net.cpp:406] relu4_2 <- conv4_2
I1107 22:48:50.872383 19164 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1107 22:48:50.872383 19164 net.cpp:122] Setting up relu4_2
I1107 22:48:50.872383 19164 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 22:48:50.872383 19164 net.cpp:137] Memory required for data: 439706800
I1107 22:48:50.872383 19164 layer_factory.cpp:58] Creating layer pool4_2
I1107 22:48:50.872383 19164 net.cpp:84] Creating Layer pool4_2
I1107 22:48:50.872383 19164 net.cpp:406] pool4_2 <- conv4_2
I1107 22:48:50.872884 19164 net.cpp:380] pool4_2 -> pool4_2
I1107 22:48:50.873883 19164 net.cpp:122] Setting up pool4_2
I1107 22:48:50.873883 19164 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 22:48:50.873883 19164 net.cpp:137] Memory required for data: 441191600
I1107 22:48:50.873883 19164 layer_factory.cpp:58] Creating layer conv4_0
I1107 22:48:50.873883 19164 net.cpp:84] Creating Layer conv4_0
I1107 22:48:50.873883 19164 net.cpp:406] conv4_0 <- pool4_2
I1107 22:48:50.873883 19164 net.cpp:380] conv4_0 -> conv4_0
I1107 22:48:50.875883 19164 net.cpp:122] Setting up conv4_0
I1107 22:48:50.875883 19164 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 22:48:50.875883 19164 net.cpp:137] Memory required for data: 442676400
I1107 22:48:50.875883 19164 layer_factory.cpp:58] Creating layer bn4_0
I1107 22:48:50.875883 19164 net.cpp:84] Creating Layer bn4_0
I1107 22:48:50.875883 19164 net.cpp:406] bn4_0 <- conv4_0
I1107 22:48:50.875883 19164 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1107 22:48:50.875883 19164 net.cpp:122] Setting up bn4_0
I1107 22:48:50.875883 19164 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 22:48:50.875883 19164 net.cpp:137] Memory required for data: 444161200
I1107 22:48:50.875883 19164 layer_factory.cpp:58] Creating layer scale4_0
I1107 22:48:50.875883 19164 net.cpp:84] Creating Layer scale4_0
I1107 22:48:50.875883 19164 net.cpp:406] scale4_0 <- conv4_0
I1107 22:48:50.875883 19164 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1107 22:48:50.875883 19164 layer_factory.cpp:58] Creating layer scale4_0
I1107 22:48:50.875883 19164 net.cpp:122] Setting up scale4_0
I1107 22:48:50.875883 19164 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 22:48:50.875883 19164 net.cpp:137] Memory required for data: 445646000
I1107 22:48:50.875883 19164 layer_factory.cpp:58] Creating layer relu4_0
I1107 22:48:50.875883 19164 net.cpp:84] Creating Layer relu4_0
I1107 22:48:50.875883 19164 net.cpp:406] relu4_0 <- conv4_0
I1107 22:48:50.875883 19164 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1107 22:48:50.876382 19164 net.cpp:122] Setting up relu4_0
I1107 22:48:50.876382 19164 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 22:48:50.876382 19164 net.cpp:137] Memory required for data: 447130800
I1107 22:48:50.876382 19164 layer_factory.cpp:58] Creating layer conv11
I1107 22:48:50.876382 19164 net.cpp:84] Creating Layer conv11
I1107 22:48:50.876382 19164 net.cpp:406] conv11 <- conv4_0
I1107 22:48:50.876382 19164 net.cpp:380] conv11 -> conv11
I1107 22:48:50.877883 19164 net.cpp:122] Setting up conv11
I1107 22:48:50.877883 19164 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 22:48:50.877883 19164 net.cpp:137] Memory required for data: 448922800
I1107 22:48:50.877883 19164 layer_factory.cpp:58] Creating layer bn_conv11
I1107 22:48:50.877883 19164 net.cpp:84] Creating Layer bn_conv11
I1107 22:48:50.877883 19164 net.cpp:406] bn_conv11 <- conv11
I1107 22:48:50.877883 19164 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1107 22:48:50.878383 19164 net.cpp:122] Setting up bn_conv11
I1107 22:48:50.878383 19164 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 22:48:50.878383 19164 net.cpp:137] Memory required for data: 450714800
I1107 22:48:50.878383 19164 layer_factory.cpp:58] Creating layer scale_conv11
I1107 22:48:50.878383 19164 net.cpp:84] Creating Layer scale_conv11
I1107 22:48:50.878383 19164 net.cpp:406] scale_conv11 <- conv11
I1107 22:48:50.878383 19164 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1107 22:48:50.878383 19164 layer_factory.cpp:58] Creating layer scale_conv11
I1107 22:48:50.878383 19164 net.cpp:122] Setting up scale_conv11
I1107 22:48:50.878383 19164 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 22:48:50.878383 19164 net.cpp:137] Memory required for data: 452506800
I1107 22:48:50.878383 19164 layer_factory.cpp:58] Creating layer relu_conv11
I1107 22:48:50.878383 19164 net.cpp:84] Creating Layer relu_conv11
I1107 22:48:50.878383 19164 net.cpp:406] relu_conv11 <- conv11
I1107 22:48:50.878383 19164 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1107 22:48:50.878383 19164 net.cpp:122] Setting up relu_conv11
I1107 22:48:50.878383 19164 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 22:48:50.878883 19164 net.cpp:137] Memory required for data: 454298800
I1107 22:48:50.878883 19164 layer_factory.cpp:58] Creating layer conv12
I1107 22:48:50.878883 19164 net.cpp:84] Creating Layer conv12
I1107 22:48:50.878883 19164 net.cpp:406] conv12 <- conv11
I1107 22:48:50.878883 19164 net.cpp:380] conv12 -> conv12
I1107 22:48:50.880386 19164 net.cpp:122] Setting up conv12
I1107 22:48:50.880386 19164 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 22:48:50.880386 19164 net.cpp:137] Memory required for data: 456602800
I1107 22:48:50.880386 19164 layer_factory.cpp:58] Creating layer bn_conv12
I1107 22:48:50.880386 19164 net.cpp:84] Creating Layer bn_conv12
I1107 22:48:50.880386 19164 net.cpp:406] bn_conv12 <- conv12
I1107 22:48:50.880386 19164 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1107 22:48:50.880883 19164 net.cpp:122] Setting up bn_conv12
I1107 22:48:50.880883 19164 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 22:48:50.880883 19164 net.cpp:137] Memory required for data: 458906800
I1107 22:48:50.880883 19164 layer_factory.cpp:58] Creating layer scale_conv12
I1107 22:48:50.880883 19164 net.cpp:84] Creating Layer scale_conv12
I1107 22:48:50.880883 19164 net.cpp:406] scale_conv12 <- conv12
I1107 22:48:50.880883 19164 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1107 22:48:50.880883 19164 layer_factory.cpp:58] Creating layer scale_conv12
I1107 22:48:50.880883 19164 net.cpp:122] Setting up scale_conv12
I1107 22:48:50.880883 19164 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 22:48:50.880883 19164 net.cpp:137] Memory required for data: 461210800
I1107 22:48:50.880883 19164 layer_factory.cpp:58] Creating layer relu_conv12
I1107 22:48:50.880883 19164 net.cpp:84] Creating Layer relu_conv12
I1107 22:48:50.880883 19164 net.cpp:406] relu_conv12 <- conv12
I1107 22:48:50.880883 19164 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1107 22:48:50.881382 19164 net.cpp:122] Setting up relu_conv12
I1107 22:48:50.881382 19164 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 22:48:50.881382 19164 net.cpp:137] Memory required for data: 463514800
I1107 22:48:50.881382 19164 layer_factory.cpp:58] Creating layer poolcp6
I1107 22:48:50.881382 19164 net.cpp:84] Creating Layer poolcp6
I1107 22:48:50.881382 19164 net.cpp:406] poolcp6 <- conv12
I1107 22:48:50.881382 19164 net.cpp:380] poolcp6 -> poolcp6
I1107 22:48:50.881382 19164 net.cpp:122] Setting up poolcp6
I1107 22:48:50.881382 19164 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1107 22:48:50.881382 19164 net.cpp:137] Memory required for data: 463550800
I1107 22:48:50.881382 19164 layer_factory.cpp:58] Creating layer ip1
I1107 22:48:50.881382 19164 net.cpp:84] Creating Layer ip1
I1107 22:48:50.881382 19164 net.cpp:406] ip1 <- poolcp6
I1107 22:48:50.881382 19164 net.cpp:380] ip1 -> ip1
I1107 22:48:50.881883 19164 net.cpp:122] Setting up ip1
I1107 22:48:50.881883 19164 net.cpp:129] Top shape: 100 100 (10000)
I1107 22:48:50.881883 19164 net.cpp:137] Memory required for data: 463590800
I1107 22:48:50.881883 19164 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1107 22:48:50.881883 19164 net.cpp:84] Creating Layer ip1_ip1_0_split
I1107 22:48:50.881883 19164 net.cpp:406] ip1_ip1_0_split <- ip1
I1107 22:48:50.881883 19164 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1107 22:48:50.881883 19164 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1107 22:48:50.881883 19164 net.cpp:122] Setting up ip1_ip1_0_split
I1107 22:48:50.881883 19164 net.cpp:129] Top shape: 100 100 (10000)
I1107 22:48:50.881883 19164 net.cpp:129] Top shape: 100 100 (10000)
I1107 22:48:50.881883 19164 net.cpp:137] Memory required for data: 463670800
I1107 22:48:50.881883 19164 layer_factory.cpp:58] Creating layer accuracy
I1107 22:48:50.881883 19164 net.cpp:84] Creating Layer accuracy
I1107 22:48:50.881883 19164 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1107 22:48:50.881883 19164 net.cpp:406] accuracy <- label_cifar_1_split_0
I1107 22:48:50.881883 19164 net.cpp:380] accuracy -> accuracy
I1107 22:48:50.881883 19164 net.cpp:122] Setting up accuracy
I1107 22:48:50.881883 19164 net.cpp:129] Top shape: (1)
I1107 22:48:50.881883 19164 net.cpp:137] Memory required for data: 463670804
I1107 22:48:50.881883 19164 layer_factory.cpp:58] Creating layer loss
I1107 22:48:50.881883 19164 net.cpp:84] Creating Layer loss
I1107 22:48:50.881883 19164 net.cpp:406] loss <- ip1_ip1_0_split_1
I1107 22:48:50.881883 19164 net.cpp:406] loss <- label_cifar_1_split_1
I1107 22:48:50.881883 19164 net.cpp:380] loss -> loss
I1107 22:48:50.881883 19164 layer_factory.cpp:58] Creating layer loss
I1107 22:48:50.882884 19164 net.cpp:122] Setting up loss
I1107 22:48:50.882884 19164 net.cpp:129] Top shape: (1)
I1107 22:48:50.882884 19164 net.cpp:132]     with loss weight 1
I1107 22:48:50.882884 19164 net.cpp:137] Memory required for data: 463670808
I1107 22:48:50.882884 19164 net.cpp:198] loss needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:200] accuracy does not need backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] ip1 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] poolcp6 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] relu_conv12 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] scale_conv12 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] bn_conv12 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] conv12 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] relu_conv11 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] scale_conv11 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] bn_conv11 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] conv11 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] relu4_0 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] scale4_0 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] bn4_0 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] conv4_0 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] pool4_2 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] relu4_2 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] scale4_2 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] bn4_2 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] conv4_2 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] relu4_1 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] scale4_1 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] bn4_1 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] conv4_1 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] relu4 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] scale4 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] bn4 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] conv4 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] relu3_1 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] scale3_1 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] bn3_1 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] conv3_1 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] relu3 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] scale3 needs backward computation.
I1107 22:48:50.882884 19164 net.cpp:198] bn3 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] conv3 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] pool2_1 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] relu2_2 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] scale2_2 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] bn2_2 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] conv2_2 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] relu2_1 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] scale2_1 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] bn2_1 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] conv2_1 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] relu2 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] scale2 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] bn2 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] conv2 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] relu1_0 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] scale1_0 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] bn1_0 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] conv1_0 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] relu1 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] scale1 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] bn1 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:198] conv1 needs backward computation.
I1107 22:48:50.883385 19164 net.cpp:200] label_cifar_1_split does not need backward computation.
I1107 22:48:50.883385 19164 net.cpp:200] cifar does not need backward computation.
I1107 22:48:50.883385 19164 net.cpp:242] This network produces output accuracy
I1107 22:48:50.883385 19164 net.cpp:242] This network produces output loss
I1107 22:48:50.883385 19164 net.cpp:255] Network initialization done.
I1107 22:48:50.883385 19164 solver.cpp:56] Solver scaffolding done.
I1107 22:48:50.887892 19164 caffe.cpp:243] Resuming from examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_90000.solverstate
I1107 22:48:52.193614 19164 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_90000.caffemodel
I1107 22:48:52.193614 19164 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1107 22:48:52.193614 19164 sgd_solver.cpp:318] SGDSolver: restoring history
I1107 22:48:52.197635 19164 caffe.cpp:249] Starting Optimization
I1107 22:48:52.197635 19164 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV1_360k
I1107 22:48:52.197635 19164 solver.cpp:273] Learning Rate Policy: multistep
I1107 22:48:52.199650 19164 solver.cpp:330] Iteration 90000, Testing net (#0)
I1107 22:48:52.201658 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:48:53.551147 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:48:53.601467 19164 solver.cpp:397]     Test net output #0: accuracy = 0.5752
I1107 22:48:53.601467 19164 solver.cpp:397]     Test net output #1: loss = 1.61927 (* 1 = 1.61927 loss)
I1107 22:48:53.702616 19164 solver.cpp:218] Iteration 90000 (59841.9 iter/s, 1.50396s/100 iters), loss = 0.64054
I1107 22:48:53.702616 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:48:53.702616 19164 solver.cpp:237]     Train net output #1: loss = 0.64054 (* 1 = 0.64054 loss)
I1107 22:48:53.702616 19164 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1107 22:48:59.618839 19164 solver.cpp:218] Iteration 90100 (16.9047 iter/s, 5.9155s/100 iters), loss = 0.718844
I1107 22:48:59.618839 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1107 22:48:59.618839 19164 solver.cpp:237]     Train net output #1: loss = 0.718844 (* 1 = 0.718844 loss)
I1107 22:48:59.618839 19164 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1107 22:49:05.532856 19164 solver.cpp:218] Iteration 90200 (16.9081 iter/s, 5.91434s/100 iters), loss = 0.676726
I1107 22:49:05.532856 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:49:05.532856 19164 solver.cpp:237]     Train net output #1: loss = 0.676726 (* 1 = 0.676726 loss)
I1107 22:49:05.532856 19164 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1107 22:49:11.465313 19164 solver.cpp:218] Iteration 90300 (16.8582 iter/s, 5.93183s/100 iters), loss = 0.845066
I1107 22:49:11.465313 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1107 22:49:11.465313 19164 solver.cpp:237]     Train net output #1: loss = 0.845066 (* 1 = 0.845066 loss)
I1107 22:49:11.465313 19164 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1107 22:49:17.381028 19164 solver.cpp:218] Iteration 90400 (16.9057 iter/s, 5.91517s/100 iters), loss = 0.96835
I1107 22:49:17.381028 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1107 22:49:17.381028 19164 solver.cpp:237]     Train net output #1: loss = 0.96835 (* 1 = 0.96835 loss)
I1107 22:49:17.381028 19164 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1107 22:49:22.998409 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:49:23.230424 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_90500.caffemodel
I1107 22:49:23.246423 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_90500.solverstate
I1107 22:49:23.251425 19164 solver.cpp:330] Iteration 90500, Testing net (#0)
I1107 22:49:23.251425 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:49:24.540562 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:49:24.591565 19164 solver.cpp:397]     Test net output #0: accuracy = 0.569
I1107 22:49:24.591565 19164 solver.cpp:397]     Test net output #1: loss = 1.70491 (* 1 = 1.70491 loss)
I1107 22:49:24.647514 19164 solver.cpp:218] Iteration 90500 (13.762 iter/s, 7.26639s/100 iters), loss = 0.656544
I1107 22:49:24.648530 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1107 22:49:24.648530 19164 solver.cpp:237]     Train net output #1: loss = 0.656544 (* 1 = 0.656544 loss)
I1107 22:49:24.648530 19164 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1107 22:49:30.542918 19164 solver.cpp:218] Iteration 90600 (16.9649 iter/s, 5.89453s/100 iters), loss = 0.587891
I1107 22:49:30.542918 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 22:49:30.542918 19164 solver.cpp:237]     Train net output #1: loss = 0.587891 (* 1 = 0.587891 loss)
I1107 22:49:30.542918 19164 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1107 22:49:36.451416 19164 solver.cpp:218] Iteration 90700 (16.9259 iter/s, 5.90809s/100 iters), loss = 0.67596
I1107 22:49:36.451416 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 22:49:36.451416 19164 solver.cpp:237]     Train net output #1: loss = 0.67596 (* 1 = 0.67596 loss)
I1107 22:49:36.451416 19164 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1107 22:49:42.358840 19164 solver.cpp:218] Iteration 90800 (16.9283 iter/s, 5.90726s/100 iters), loss = 0.910125
I1107 22:49:42.358840 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1107 22:49:42.358840 19164 solver.cpp:237]     Train net output #1: loss = 0.910125 (* 1 = 0.910125 loss)
I1107 22:49:42.358840 19164 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1107 22:49:48.260212 19164 solver.cpp:218] Iteration 90900 (16.9472 iter/s, 5.90069s/100 iters), loss = 1.00203
I1107 22:49:48.260212 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1107 22:49:48.260212 19164 solver.cpp:237]     Train net output #1: loss = 1.00203 (* 1 = 1.00203 loss)
I1107 22:49:48.260212 19164 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1107 22:49:53.884614 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:49:54.118127 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_91000.caffemodel
I1107 22:49:54.132630 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_91000.solverstate
I1107 22:49:54.138631 19164 solver.cpp:330] Iteration 91000, Testing net (#0)
I1107 22:49:54.138631 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:49:55.428781 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:49:55.479779 19164 solver.cpp:397]     Test net output #0: accuracy = 0.5755
I1107 22:49:55.479779 19164 solver.cpp:397]     Test net output #1: loss = 1.63307 (* 1 = 1.63307 loss)
I1107 22:49:55.535809 19164 solver.cpp:218] Iteration 91000 (13.7451 iter/s, 7.27531s/100 iters), loss = 0.637198
I1107 22:49:55.535809 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:49:55.535809 19164 solver.cpp:237]     Train net output #1: loss = 0.637198 (* 1 = 0.637198 loss)
I1107 22:49:55.535809 19164 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1107 22:50:01.509817 19164 solver.cpp:218] Iteration 91100 (16.7418 iter/s, 5.97307s/100 iters), loss = 0.745989
I1107 22:50:01.509817 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1107 22:50:01.509817 19164 solver.cpp:237]     Train net output #1: loss = 0.745989 (* 1 = 0.745989 loss)
I1107 22:50:01.509817 19164 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1107 22:50:07.441721 19164 solver.cpp:218] Iteration 91200 (16.859 iter/s, 5.93155s/100 iters), loss = 0.676078
I1107 22:50:07.441721 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:50:07.441721 19164 solver.cpp:237]     Train net output #1: loss = 0.676078 (* 1 = 0.676078 loss)
I1107 22:50:07.441721 19164 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1107 22:50:13.352605 19164 solver.cpp:218] Iteration 91300 (16.918 iter/s, 5.91085s/100 iters), loss = 0.71284
I1107 22:50:13.352605 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1107 22:50:13.352605 19164 solver.cpp:237]     Train net output #1: loss = 0.71284 (* 1 = 0.71284 loss)
I1107 22:50:13.352605 19164 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1107 22:50:19.317878 19164 solver.cpp:218] Iteration 91400 (16.7653 iter/s, 5.96471s/100 iters), loss = 0.858301
I1107 22:50:19.318379 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1107 22:50:19.318379 19164 solver.cpp:237]     Train net output #1: loss = 0.858301 (* 1 = 0.858301 loss)
I1107 22:50:19.318379 19164 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1107 22:50:25.016763 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:50:25.254865 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_91500.caffemodel
I1107 22:50:25.270870 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_91500.solverstate
I1107 22:50:25.276850 19164 solver.cpp:330] Iteration 91500, Testing net (#0)
I1107 22:50:25.276850 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:50:26.588943 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:50:26.640959 19164 solver.cpp:397]     Test net output #0: accuracy = 0.5444
I1107 22:50:26.640959 19164 solver.cpp:397]     Test net output #1: loss = 1.85776 (* 1 = 1.85776 loss)
I1107 22:50:26.697949 19164 solver.cpp:218] Iteration 91500 (13.5507 iter/s, 7.3797s/100 iters), loss = 0.676236
I1107 22:50:26.697949 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:50:26.697949 19164 solver.cpp:237]     Train net output #1: loss = 0.676236 (* 1 = 0.676236 loss)
I1107 22:50:26.697949 19164 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1107 22:50:32.610333 19164 solver.cpp:218] Iteration 91600 (16.9156 iter/s, 5.91171s/100 iters), loss = 0.771032
I1107 22:50:32.610333 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1107 22:50:32.610333 19164 solver.cpp:237]     Train net output #1: loss = 0.771032 (* 1 = 0.771032 loss)
I1107 22:50:32.610333 19164 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1107 22:50:38.552789 19164 solver.cpp:218] Iteration 91700 (16.8285 iter/s, 5.94229s/100 iters), loss = 0.618929
I1107 22:50:38.552789 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 22:50:38.552789 19164 solver.cpp:237]     Train net output #1: loss = 0.618929 (* 1 = 0.618929 loss)
I1107 22:50:38.552789 19164 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1107 22:50:44.581758 19164 solver.cpp:218] Iteration 91800 (16.5885 iter/s, 6.02828s/100 iters), loss = 0.77483
I1107 22:50:44.581758 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:50:44.581758 19164 solver.cpp:237]     Train net output #1: loss = 0.77483 (* 1 = 0.77483 loss)
I1107 22:50:44.581758 19164 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1107 22:50:50.576798 19164 solver.cpp:218] Iteration 91900 (16.6817 iter/s, 5.99458s/100 iters), loss = 0.837554
I1107 22:50:50.576798 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1107 22:50:50.576798 19164 solver.cpp:237]     Train net output #1: loss = 0.837554 (* 1 = 0.837554 loss)
I1107 22:50:50.576798 19164 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1107 22:50:56.237152 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:50:56.471169 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_92000.caffemodel
I1107 22:50:56.485671 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_92000.solverstate
I1107 22:50:56.490176 19164 solver.cpp:330] Iteration 92000, Testing net (#0)
I1107 22:50:56.490176 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:50:57.778820 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:50:57.829324 19164 solver.cpp:397]     Test net output #0: accuracy = 0.5823
I1107 22:50:57.829324 19164 solver.cpp:397]     Test net output #1: loss = 1.60753 (* 1 = 1.60753 loss)
I1107 22:50:57.887329 19164 solver.cpp:218] Iteration 92000 (13.6798 iter/s, 7.31003s/100 iters), loss = 0.651667
I1107 22:50:57.887329 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:50:57.887329 19164 solver.cpp:237]     Train net output #1: loss = 0.651667 (* 1 = 0.651667 loss)
I1107 22:50:57.887329 19164 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1107 22:51:03.979893 19164 solver.cpp:218] Iteration 92100 (16.4153 iter/s, 6.09188s/100 iters), loss = 0.629196
I1107 22:51:03.979893 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1107 22:51:03.979893 19164 solver.cpp:237]     Train net output #1: loss = 0.629196 (* 1 = 0.629196 loss)
I1107 22:51:03.979893 19164 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1107 22:51:10.020594 19164 solver.cpp:218] Iteration 92200 (16.5544 iter/s, 6.0407s/100 iters), loss = 0.702022
I1107 22:51:10.020594 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 22:51:10.020594 19164 solver.cpp:237]     Train net output #1: loss = 0.702022 (* 1 = 0.702022 loss)
I1107 22:51:10.020594 19164 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1107 22:51:16.093351 19164 solver.cpp:218] Iteration 92300 (16.469 iter/s, 6.07202s/100 iters), loss = 0.825203
I1107 22:51:16.093351 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1107 22:51:16.093351 19164 solver.cpp:237]     Train net output #1: loss = 0.825203 (* 1 = 0.825203 loss)
I1107 22:51:16.093351 19164 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1107 22:51:22.199442 19164 solver.cpp:218] Iteration 92400 (16.3778 iter/s, 6.10581s/100 iters), loss = 0.778089
I1107 22:51:22.199442 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:51:22.199442 19164 solver.cpp:237]     Train net output #1: loss = 0.778089 (* 1 = 0.778089 loss)
I1107 22:51:22.199442 19164 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1107 22:51:27.851809 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:51:28.086338 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_92500.caffemodel
I1107 22:51:28.102833 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_92500.solverstate
I1107 22:51:28.107833 19164 solver.cpp:330] Iteration 92500, Testing net (#0)
I1107 22:51:28.107833 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:51:29.411989 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:51:29.462988 19164 solver.cpp:397]     Test net output #0: accuracy = 0.5958
I1107 22:51:29.462988 19164 solver.cpp:397]     Test net output #1: loss = 1.54355 (* 1 = 1.54355 loss)
I1107 22:51:29.519996 19164 solver.cpp:218] Iteration 92500 (13.6621 iter/s, 7.31951s/100 iters), loss = 0.62112
I1107 22:51:29.519996 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 22:51:29.519996 19164 solver.cpp:237]     Train net output #1: loss = 0.62112 (* 1 = 0.62112 loss)
I1107 22:51:29.519996 19164 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1107 22:51:35.458411 19164 solver.cpp:218] Iteration 92600 (16.8408 iter/s, 5.93794s/100 iters), loss = 0.770799
I1107 22:51:35.458411 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:51:35.458411 19164 solver.cpp:237]     Train net output #1: loss = 0.770799 (* 1 = 0.770799 loss)
I1107 22:51:35.458411 19164 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1107 22:51:41.404148 19164 solver.cpp:218] Iteration 92700 (16.8195 iter/s, 5.94547s/100 iters), loss = 0.64756
I1107 22:51:41.404148 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1107 22:51:41.404148 19164 solver.cpp:237]     Train net output #1: loss = 0.64756 (* 1 = 0.64756 loss)
I1107 22:51:41.404148 19164 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1107 22:51:47.306416 19164 solver.cpp:218] Iteration 92800 (16.9439 iter/s, 5.90184s/100 iters), loss = 0.797171
I1107 22:51:47.306416 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1107 22:51:47.306416 19164 solver.cpp:237]     Train net output #1: loss = 0.797171 (* 1 = 0.797171 loss)
I1107 22:51:47.306416 19164 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1107 22:51:53.196486 19164 solver.cpp:218] Iteration 92900 (16.9794 iter/s, 5.8895s/100 iters), loss = 0.788568
I1107 22:51:53.196486 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1107 22:51:53.196486 19164 solver.cpp:237]     Train net output #1: loss = 0.788568 (* 1 = 0.788568 loss)
I1107 22:51:53.196486 19164 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1107 22:51:58.801903 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:51:59.033913 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_93000.caffemodel
I1107 22:51:59.047914 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_93000.solverstate
I1107 22:51:59.051913 19164 solver.cpp:330] Iteration 93000, Testing net (#0)
I1107 22:51:59.051913 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:52:00.340050 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:52:00.390553 19164 solver.cpp:397]     Test net output #0: accuracy = 0.5789
I1107 22:52:00.390553 19164 solver.cpp:397]     Test net output #1: loss = 1.63938 (* 1 = 1.63938 loss)
I1107 22:52:00.447054 19164 solver.cpp:218] Iteration 93000 (13.7927 iter/s, 7.25022s/100 iters), loss = 0.705896
I1107 22:52:00.447054 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1107 22:52:00.447054 19164 solver.cpp:237]     Train net output #1: loss = 0.705896 (* 1 = 0.705896 loss)
I1107 22:52:00.447054 19164 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1107 22:52:06.337426 19164 solver.cpp:218] Iteration 93100 (16.9771 iter/s, 5.89028s/100 iters), loss = 0.763094
I1107 22:52:06.337426 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1107 22:52:06.337426 19164 solver.cpp:237]     Train net output #1: loss = 0.763094 (* 1 = 0.763094 loss)
I1107 22:52:06.337426 19164 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1107 22:52:12.242857 19164 solver.cpp:218] Iteration 93200 (16.9357 iter/s, 5.9047s/100 iters), loss = 0.633516
I1107 22:52:12.242857 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 22:52:12.242857 19164 solver.cpp:237]     Train net output #1: loss = 0.633516 (* 1 = 0.633516 loss)
I1107 22:52:12.242857 19164 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1107 22:52:18.160202 19164 solver.cpp:218] Iteration 93300 (16.9002 iter/s, 5.91709s/100 iters), loss = 0.772123
I1107 22:52:18.160202 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1107 22:52:18.160202 19164 solver.cpp:237]     Train net output #1: loss = 0.772123 (* 1 = 0.772123 loss)
I1107 22:52:18.160202 19164 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1107 22:52:24.065093 19164 solver.cpp:218] Iteration 93400 (16.9369 iter/s, 5.90425s/100 iters), loss = 0.827126
I1107 22:52:24.065093 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1107 22:52:24.065093 19164 solver.cpp:237]     Train net output #1: loss = 0.827126 (* 1 = 0.827126 loss)
I1107 22:52:24.065093 19164 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1107 22:52:29.681952 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:52:29.913962 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_93500.caffemodel
I1107 22:52:29.928963 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_93500.solverstate
I1107 22:52:29.933964 19164 solver.cpp:330] Iteration 93500, Testing net (#0)
I1107 22:52:29.933964 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:52:31.223084 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:52:31.273128 19164 solver.cpp:397]     Test net output #0: accuracy = 0.5851
I1107 22:52:31.274130 19164 solver.cpp:397]     Test net output #1: loss = 1.61209 (* 1 = 1.61209 loss)
I1107 22:52:31.330109 19164 solver.cpp:218] Iteration 93500 (13.7645 iter/s, 7.26505s/100 iters), loss = 0.565154
I1107 22:52:31.330109 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:52:31.330109 19164 solver.cpp:237]     Train net output #1: loss = 0.565154 (* 1 = 0.565154 loss)
I1107 22:52:31.330109 19164 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1107 22:52:37.232523 19164 solver.cpp:218] Iteration 93600 (16.9453 iter/s, 5.90135s/100 iters), loss = 0.676617
I1107 22:52:37.232523 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 22:52:37.232523 19164 solver.cpp:237]     Train net output #1: loss = 0.676617 (* 1 = 0.676617 loss)
I1107 22:52:37.232523 19164 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1107 22:52:43.155249 19164 solver.cpp:218] Iteration 93700 (16.8851 iter/s, 5.92238s/100 iters), loss = 0.456382
I1107 22:52:43.155249 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:52:43.155249 19164 solver.cpp:237]     Train net output #1: loss = 0.456382 (* 1 = 0.456382 loss)
I1107 22:52:43.155249 19164 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1107 22:52:49.089639 19164 solver.cpp:218] Iteration 93800 (16.8504 iter/s, 5.93457s/100 iters), loss = 0.802036
I1107 22:52:49.089639 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1107 22:52:49.089639 19164 solver.cpp:237]     Train net output #1: loss = 0.802036 (* 1 = 0.802036 loss)
I1107 22:52:49.089639 19164 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1107 22:52:55.046442 19164 solver.cpp:218] Iteration 93900 (16.7902 iter/s, 5.95586s/100 iters), loss = 0.954834
I1107 22:52:55.046442 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1107 22:52:55.046442 19164 solver.cpp:237]     Train net output #1: loss = 0.954834 (* 1 = 0.954834 loss)
I1107 22:52:55.046442 19164 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1107 22:53:00.668560 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:53:00.905083 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_94000.caffemodel
I1107 22:53:00.921078 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_94000.solverstate
I1107 22:53:00.926079 19164 solver.cpp:330] Iteration 94000, Testing net (#0)
I1107 22:53:00.926079 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:53:02.222375 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:53:02.273880 19164 solver.cpp:397]     Test net output #0: accuracy = 0.5569
I1107 22:53:02.273880 19164 solver.cpp:397]     Test net output #1: loss = 1.76121 (* 1 = 1.76121 loss)
I1107 22:53:02.330382 19164 solver.cpp:218] Iteration 94000 (13.7292 iter/s, 7.28377s/100 iters), loss = 0.691517
I1107 22:53:02.330382 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:53:02.330382 19164 solver.cpp:237]     Train net output #1: loss = 0.691517 (* 1 = 0.691517 loss)
I1107 22:53:02.330382 19164 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1107 22:53:08.275279 19164 solver.cpp:218] Iteration 94100 (16.824 iter/s, 5.94387s/100 iters), loss = 0.611659
I1107 22:53:08.275279 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 22:53:08.275279 19164 solver.cpp:237]     Train net output #1: loss = 0.611659 (* 1 = 0.611659 loss)
I1107 22:53:08.275279 19164 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1107 22:53:14.203631 19164 solver.cpp:218] Iteration 94200 (16.8703 iter/s, 5.92759s/100 iters), loss = 0.588912
I1107 22:53:14.203631 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:53:14.203631 19164 solver.cpp:237]     Train net output #1: loss = 0.588912 (* 1 = 0.588912 loss)
I1107 22:53:14.203631 19164 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1107 22:53:20.179139 19164 solver.cpp:218] Iteration 94300 (16.7346 iter/s, 5.97563s/100 iters), loss = 0.796602
I1107 22:53:20.179139 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1107 22:53:20.179139 19164 solver.cpp:237]     Train net output #1: loss = 0.796602 (* 1 = 0.796602 loss)
I1107 22:53:20.179139 19164 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1107 22:53:26.130566 19164 solver.cpp:218] Iteration 94400 (16.804 iter/s, 5.95097s/100 iters), loss = 0.794298
I1107 22:53:26.130566 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1107 22:53:26.130566 19164 solver.cpp:237]     Train net output #1: loss = 0.794298 (* 1 = 0.794298 loss)
I1107 22:53:26.130566 19164 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1107 22:53:31.799504 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:53:32.035570 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_94500.caffemodel
I1107 22:53:32.053570 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_94500.solverstate
I1107 22:53:32.058571 19164 solver.cpp:330] Iteration 94500, Testing net (#0)
I1107 22:53:32.058571 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:53:33.380100 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:53:33.433140 19164 solver.cpp:397]     Test net output #0: accuracy = 0.5721
I1107 22:53:33.433140 19164 solver.cpp:397]     Test net output #1: loss = 1.69021 (* 1 = 1.69021 loss)
I1107 22:53:33.491137 19164 solver.cpp:218] Iteration 94500 (13.5863 iter/s, 7.36038s/100 iters), loss = 0.697456
I1107 22:53:33.491137 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 22:53:33.491137 19164 solver.cpp:237]     Train net output #1: loss = 0.697456 (* 1 = 0.697456 loss)
I1107 22:53:33.491137 19164 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1107 22:53:39.438210 19164 solver.cpp:218] Iteration 94600 (16.8186 iter/s, 5.9458s/100 iters), loss = 0.627524
I1107 22:53:39.438210 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:53:39.438210 19164 solver.cpp:237]     Train net output #1: loss = 0.627524 (* 1 = 0.627524 loss)
I1107 22:53:39.438210 19164 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1107 22:53:45.354687 19164 solver.cpp:218] Iteration 94700 (16.9016 iter/s, 5.91659s/100 iters), loss = 0.614087
I1107 22:53:45.354687 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1107 22:53:45.354687 19164 solver.cpp:237]     Train net output #1: loss = 0.614087 (* 1 = 0.614087 loss)
I1107 22:53:45.354687 19164 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1107 22:53:51.344406 19164 solver.cpp:218] Iteration 94800 (16.6967 iter/s, 5.9892s/100 iters), loss = 0.819797
I1107 22:53:51.344406 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1107 22:53:51.344406 19164 solver.cpp:237]     Train net output #1: loss = 0.819797 (* 1 = 0.819797 loss)
I1107 22:53:51.344406 19164 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1107 22:53:57.305860 19164 solver.cpp:218] Iteration 94900 (16.7752 iter/s, 5.96116s/100 iters), loss = 0.744071
I1107 22:53:57.305860 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1107 22:53:57.305860 19164 solver.cpp:237]     Train net output #1: loss = 0.744071 (* 1 = 0.744071 loss)
I1107 22:53:57.305860 19164 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1107 22:54:02.970285 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:54:03.203294 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_95000.caffemodel
I1107 22:54:03.218796 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_95000.solverstate
I1107 22:54:03.223796 19164 solver.cpp:330] Iteration 95000, Testing net (#0)
I1107 22:54:03.223796 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:54:04.532449 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:54:04.583448 19164 solver.cpp:397]     Test net output #0: accuracy = 0.5804
I1107 22:54:04.583448 19164 solver.cpp:397]     Test net output #1: loss = 1.6545 (* 1 = 1.6545 loss)
I1107 22:54:04.640453 19164 solver.cpp:218] Iteration 95000 (13.6357 iter/s, 7.33371s/100 iters), loss = 0.684205
I1107 22:54:04.640453 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:54:04.640453 19164 solver.cpp:237]     Train net output #1: loss = 0.684205 (* 1 = 0.684205 loss)
I1107 22:54:04.640453 19164 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1107 22:54:04.640453 19164 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1107 22:54:10.576966 19164 solver.cpp:218] Iteration 95100 (16.8446 iter/s, 5.93661s/100 iters), loss = 0.610985
I1107 22:54:10.576966 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:54:10.576966 19164 solver.cpp:237]     Train net output #1: loss = 0.610985 (* 1 = 0.610985 loss)
I1107 22:54:10.576966 19164 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1107 22:54:16.527490 19164 solver.cpp:218] Iteration 95200 (16.8089 iter/s, 5.94922s/100 iters), loss = 0.475459
I1107 22:54:16.527490 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:54:16.527490 19164 solver.cpp:237]     Train net output #1: loss = 0.475459 (* 1 = 0.475459 loss)
I1107 22:54:16.527490 19164 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1107 22:54:22.503365 19164 solver.cpp:218] Iteration 95300 (16.7334 iter/s, 5.97609s/100 iters), loss = 0.676247
I1107 22:54:22.503365 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 22:54:22.503365 19164 solver.cpp:237]     Train net output #1: loss = 0.676247 (* 1 = 0.676247 loss)
I1107 22:54:22.503365 19164 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1107 22:54:28.508854 19164 solver.cpp:218] Iteration 95400 (16.6546 iter/s, 6.00435s/100 iters), loss = 0.550197
I1107 22:54:28.508854 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:54:28.508854 19164 solver.cpp:237]     Train net output #1: loss = 0.550197 (* 1 = 0.550197 loss)
I1107 22:54:28.508854 19164 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1107 22:54:34.205638 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:54:34.438678 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_95500.caffemodel
I1107 22:54:34.453678 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_95500.solverstate
I1107 22:54:34.458679 19164 solver.cpp:330] Iteration 95500, Testing net (#0)
I1107 22:54:34.458679 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:54:35.782837 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:54:35.834841 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6724
I1107 22:54:35.834841 19164 solver.cpp:397]     Test net output #1: loss = 1.20308 (* 1 = 1.20308 loss)
I1107 22:54:35.891847 19164 solver.cpp:218] Iteration 95500 (13.5445 iter/s, 7.38308s/100 iters), loss = 0.514168
I1107 22:54:35.891847 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:54:35.891847 19164 solver.cpp:237]     Train net output #1: loss = 0.514168 (* 1 = 0.514168 loss)
I1107 22:54:35.891847 19164 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1107 22:54:41.823266 19164 solver.cpp:218] Iteration 95600 (16.8626 iter/s, 5.9303s/100 iters), loss = 0.586387
I1107 22:54:41.823266 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1107 22:54:41.823266 19164 solver.cpp:237]     Train net output #1: loss = 0.586387 (* 1 = 0.586387 loss)
I1107 22:54:41.823266 19164 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1107 22:54:47.769733 19164 solver.cpp:218] Iteration 95700 (16.8173 iter/s, 5.94627s/100 iters), loss = 0.47712
I1107 22:54:47.769733 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 22:54:47.769733 19164 solver.cpp:237]     Train net output #1: loss = 0.47712 (* 1 = 0.47712 loss)
I1107 22:54:47.769733 19164 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1107 22:54:53.716183 19164 solver.cpp:218] Iteration 95800 (16.8182 iter/s, 5.94594s/100 iters), loss = 0.610181
I1107 22:54:53.716183 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:54:53.716183 19164 solver.cpp:237]     Train net output #1: loss = 0.610181 (* 1 = 0.610181 loss)
I1107 22:54:53.716183 19164 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1107 22:54:59.641585 19164 solver.cpp:218] Iteration 95900 (16.8785 iter/s, 5.9247s/100 iters), loss = 0.618228
I1107 22:54:59.641585 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 22:54:59.641585 19164 solver.cpp:237]     Train net output #1: loss = 0.618228 (* 1 = 0.618228 loss)
I1107 22:54:59.641585 19164 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1107 22:55:05.297435 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:55:05.529947 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_96000.caffemodel
I1107 22:55:05.548948 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_96000.solverstate
I1107 22:55:05.553947 19164 solver.cpp:330] Iteration 96000, Testing net (#0)
I1107 22:55:05.553947 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:55:06.845043 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:55:06.896549 19164 solver.cpp:397]     Test net output #0: accuracy = 0.676
I1107 22:55:06.896549 19164 solver.cpp:397]     Test net output #1: loss = 1.19977 (* 1 = 1.19977 loss)
I1107 22:55:06.953047 19164 solver.cpp:218] Iteration 96000 (13.6772 iter/s, 7.31142s/100 iters), loss = 0.533385
I1107 22:55:06.953047 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:55:06.953047 19164 solver.cpp:237]     Train net output #1: loss = 0.533385 (* 1 = 0.533385 loss)
I1107 22:55:06.953047 19164 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1107 22:55:12.864456 19164 solver.cpp:218] Iteration 96100 (16.9171 iter/s, 5.91119s/100 iters), loss = 0.504114
I1107 22:55:12.864456 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:55:12.864456 19164 solver.cpp:237]     Train net output #1: loss = 0.504114 (* 1 = 0.504114 loss)
I1107 22:55:12.864456 19164 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1107 22:55:18.775825 19164 solver.cpp:218] Iteration 96200 (16.9177 iter/s, 5.91097s/100 iters), loss = 0.436896
I1107 22:55:18.775825 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:55:18.775825 19164 solver.cpp:237]     Train net output #1: loss = 0.436896 (* 1 = 0.436896 loss)
I1107 22:55:18.775825 19164 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1107 22:55:24.690182 19164 solver.cpp:218] Iteration 96300 (16.9099 iter/s, 5.91369s/100 iters), loss = 0.569707
I1107 22:55:24.690182 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 22:55:24.690182 19164 solver.cpp:237]     Train net output #1: loss = 0.569707 (* 1 = 0.569707 loss)
I1107 22:55:24.690182 19164 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1107 22:55:30.603549 19164 solver.cpp:218] Iteration 96400 (16.913 iter/s, 5.91262s/100 iters), loss = 0.56026
I1107 22:55:30.603549 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:55:30.603549 19164 solver.cpp:237]     Train net output #1: loss = 0.56026 (* 1 = 0.56026 loss)
I1107 22:55:30.603549 19164 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1107 22:55:36.232950 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:55:36.466964 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_96500.caffemodel
I1107 22:55:36.481963 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_96500.solverstate
I1107 22:55:36.486964 19164 solver.cpp:330] Iteration 96500, Testing net (#0)
I1107 22:55:36.486964 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:55:37.777068 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:55:37.828071 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6751
I1107 22:55:37.828071 19164 solver.cpp:397]     Test net output #1: loss = 1.19674 (* 1 = 1.19674 loss)
I1107 22:55:37.885071 19164 solver.cpp:218] Iteration 96500 (13.7339 iter/s, 7.28127s/100 iters), loss = 0.547668
I1107 22:55:37.885071 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 22:55:37.885071 19164 solver.cpp:237]     Train net output #1: loss = 0.547668 (* 1 = 0.547668 loss)
I1107 22:55:37.885071 19164 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1107 22:55:43.794126 19164 solver.cpp:218] Iteration 96600 (16.9257 iter/s, 5.90818s/100 iters), loss = 0.499307
I1107 22:55:43.794126 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:55:43.794126 19164 solver.cpp:237]     Train net output #1: loss = 0.499307 (* 1 = 0.499307 loss)
I1107 22:55:43.794126 19164 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1107 22:55:49.738047 19164 solver.cpp:218] Iteration 96700 (16.8241 iter/s, 5.94386s/100 iters), loss = 0.378789
I1107 22:55:49.738047 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:55:49.738047 19164 solver.cpp:237]     Train net output #1: loss = 0.378789 (* 1 = 0.378789 loss)
I1107 22:55:49.738047 19164 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1107 22:55:55.681435 19164 solver.cpp:218] Iteration 96800 (16.8256 iter/s, 5.94331s/100 iters), loss = 0.518423
I1107 22:55:55.681435 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:55:55.681435 19164 solver.cpp:237]     Train net output #1: loss = 0.518423 (* 1 = 0.518423 loss)
I1107 22:55:55.681435 19164 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1107 22:56:01.605725 19164 solver.cpp:218] Iteration 96900 (16.8824 iter/s, 5.92332s/100 iters), loss = 0.53219
I1107 22:56:01.605725 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 22:56:01.605725 19164 solver.cpp:237]     Train net output #1: loss = 0.53219 (* 1 = 0.53219 loss)
I1107 22:56:01.605725 19164 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1107 22:56:07.270133 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:56:07.504148 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_97000.caffemodel
I1107 22:56:07.518153 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_97000.solverstate
I1107 22:56:07.523154 19164 solver.cpp:330] Iteration 97000, Testing net (#0)
I1107 22:56:07.523154 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:56:08.824301 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:56:08.875299 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6781
I1107 22:56:08.875299 19164 solver.cpp:397]     Test net output #1: loss = 1.19903 (* 1 = 1.19903 loss)
I1107 22:56:08.933305 19164 solver.cpp:218] Iteration 97000 (13.6465 iter/s, 7.32789s/100 iters), loss = 0.543097
I1107 22:56:08.933305 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:56:08.934306 19164 solver.cpp:237]     Train net output #1: loss = 0.543097 (* 1 = 0.543097 loss)
I1107 22:56:08.934306 19164 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1107 22:56:14.878844 19164 solver.cpp:218] Iteration 97100 (16.8227 iter/s, 5.94436s/100 iters), loss = 0.528842
I1107 22:56:14.878844 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:56:14.878844 19164 solver.cpp:237]     Train net output #1: loss = 0.528842 (* 1 = 0.528842 loss)
I1107 22:56:14.878844 19164 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1107 22:56:20.822289 19164 solver.cpp:218] Iteration 97200 (16.8267 iter/s, 5.94294s/100 iters), loss = 0.414468
I1107 22:56:20.822289 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:56:20.822289 19164 solver.cpp:237]     Train net output #1: loss = 0.414468 (* 1 = 0.414468 loss)
I1107 22:56:20.822289 19164 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1107 22:56:26.782724 19164 solver.cpp:218] Iteration 97300 (16.7784 iter/s, 5.96006s/100 iters), loss = 0.559251
I1107 22:56:26.782724 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:56:26.782724 19164 solver.cpp:237]     Train net output #1: loss = 0.559251 (* 1 = 0.559251 loss)
I1107 22:56:26.782724 19164 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1107 22:56:32.767226 19164 solver.cpp:218] Iteration 97400 (16.7094 iter/s, 5.98465s/100 iters), loss = 0.561733
I1107 22:56:32.767226 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 22:56:32.767226 19164 solver.cpp:237]     Train net output #1: loss = 0.561733 (* 1 = 0.561733 loss)
I1107 22:56:32.767226 19164 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1107 22:56:38.520705 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:56:38.754725 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_97500.caffemodel
I1107 22:56:38.771733 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_97500.solverstate
I1107 22:56:38.777725 19164 solver.cpp:330] Iteration 97500, Testing net (#0)
I1107 22:56:38.777725 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:56:40.080984 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:56:40.131992 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6778
I1107 22:56:40.131992 19164 solver.cpp:397]     Test net output #1: loss = 1.19227 (* 1 = 1.19227 loss)
I1107 22:56:40.188989 19164 solver.cpp:218] Iteration 97500 (13.4761 iter/s, 7.42053s/100 iters), loss = 0.504521
I1107 22:56:40.188989 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:56:40.188989 19164 solver.cpp:237]     Train net output #1: loss = 0.504521 (* 1 = 0.504521 loss)
I1107 22:56:40.188989 19164 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1107 22:56:46.132392 19164 solver.cpp:218] Iteration 97600 (16.8253 iter/s, 5.94342s/100 iters), loss = 0.573441
I1107 22:56:46.132392 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:56:46.132392 19164 solver.cpp:237]     Train net output #1: loss = 0.573441 (* 1 = 0.573441 loss)
I1107 22:56:46.132392 19164 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1107 22:56:52.073782 19164 solver.cpp:218] Iteration 97700 (16.8335 iter/s, 5.94054s/100 iters), loss = 0.359748
I1107 22:56:52.073782 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:56:52.073782 19164 solver.cpp:237]     Train net output #1: loss = 0.359748 (* 1 = 0.359748 loss)
I1107 22:56:52.073782 19164 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1107 22:56:57.980872 19164 solver.cpp:218] Iteration 97800 (16.9283 iter/s, 5.90728s/100 iters), loss = 0.526337
I1107 22:56:57.980872 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 22:56:57.980872 19164 solver.cpp:237]     Train net output #1: loss = 0.526337 (* 1 = 0.526337 loss)
I1107 22:56:57.980872 19164 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1107 22:57:03.899271 19164 solver.cpp:218] Iteration 97900 (16.898 iter/s, 5.91785s/100 iters), loss = 0.576061
I1107 22:57:03.899271 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:57:03.899271 19164 solver.cpp:237]     Train net output #1: loss = 0.576061 (* 1 = 0.576061 loss)
I1107 22:57:03.899271 19164 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1107 22:57:09.576736 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:57:09.809753 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_98000.caffemodel
I1107 22:57:09.824753 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_98000.solverstate
I1107 22:57:09.829753 19164 solver.cpp:330] Iteration 98000, Testing net (#0)
I1107 22:57:09.829753 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:57:11.124867 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:57:11.175873 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6797
I1107 22:57:11.175873 19164 solver.cpp:397]     Test net output #1: loss = 1.19706 (* 1 = 1.19706 loss)
I1107 22:57:11.232373 19164 solver.cpp:218] Iteration 98000 (13.6385 iter/s, 7.33216s/100 iters), loss = 0.451202
I1107 22:57:11.232373 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:57:11.232373 19164 solver.cpp:237]     Train net output #1: loss = 0.451202 (* 1 = 0.451202 loss)
I1107 22:57:11.232373 19164 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1107 22:57:17.205327 19164 solver.cpp:218] Iteration 98100 (16.7411 iter/s, 5.97332s/100 iters), loss = 0.527443
I1107 22:57:17.205327 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:57:17.205327 19164 solver.cpp:237]     Train net output #1: loss = 0.527443 (* 1 = 0.527443 loss)
I1107 22:57:17.205327 19164 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1107 22:57:23.157788 19164 solver.cpp:218] Iteration 98200 (16.8016 iter/s, 5.95182s/100 iters), loss = 0.360056
I1107 22:57:23.157788 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:57:23.157788 19164 solver.cpp:237]     Train net output #1: loss = 0.360056 (* 1 = 0.360056 loss)
I1107 22:57:23.157788 19164 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1107 22:57:29.090227 19164 solver.cpp:218] Iteration 98300 (16.8566 iter/s, 5.9324s/100 iters), loss = 0.45615
I1107 22:57:29.091228 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:57:29.091228 19164 solver.cpp:237]     Train net output #1: loss = 0.45615 (* 1 = 0.45615 loss)
I1107 22:57:29.091228 19164 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1107 22:57:35.011621 19164 solver.cpp:218] Iteration 98400 (16.8904 iter/s, 5.92054s/100 iters), loss = 0.531977
I1107 22:57:35.011621 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 22:57:35.011621 19164 solver.cpp:237]     Train net output #1: loss = 0.531977 (* 1 = 0.531977 loss)
I1107 22:57:35.011621 19164 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1107 22:57:40.675053 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:57:40.910075 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_98500.caffemodel
I1107 22:57:40.927078 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_98500.solverstate
I1107 22:57:40.932075 19164 solver.cpp:330] Iteration 98500, Testing net (#0)
I1107 22:57:40.932075 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:57:42.232161 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:57:42.282176 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6778
I1107 22:57:42.282176 19164 solver.cpp:397]     Test net output #1: loss = 1.19983 (* 1 = 1.19983 loss)
I1107 22:57:42.339679 19164 solver.cpp:218] Iteration 98500 (13.6477 iter/s, 7.32725s/100 iters), loss = 0.481606
I1107 22:57:42.339679 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:57:42.339679 19164 solver.cpp:237]     Train net output #1: loss = 0.481606 (* 1 = 0.481606 loss)
I1107 22:57:42.339679 19164 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1107 22:57:48.296593 19164 solver.cpp:218] Iteration 98600 (16.7864 iter/s, 5.95721s/100 iters), loss = 0.417594
I1107 22:57:48.296593 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:57:48.297595 19164 solver.cpp:237]     Train net output #1: loss = 0.417594 (* 1 = 0.417594 loss)
I1107 22:57:48.297595 19164 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1107 22:57:54.236484 19164 solver.cpp:218] Iteration 98700 (16.8392 iter/s, 5.93854s/100 iters), loss = 0.334966
I1107 22:57:54.236484 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:57:54.236484 19164 solver.cpp:237]     Train net output #1: loss = 0.334966 (* 1 = 0.334966 loss)
I1107 22:57:54.236484 19164 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1107 22:58:00.198734 19164 solver.cpp:218] Iteration 98800 (16.7731 iter/s, 5.96193s/100 iters), loss = 0.552922
I1107 22:58:00.198734 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 22:58:00.198734 19164 solver.cpp:237]     Train net output #1: loss = 0.552922 (* 1 = 0.552922 loss)
I1107 22:58:00.198734 19164 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1107 22:58:06.131006 19164 solver.cpp:218] Iteration 98900 (16.8559 iter/s, 5.93263s/100 iters), loss = 0.513239
I1107 22:58:06.131006 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:58:06.132005 19164 solver.cpp:237]     Train net output #1: loss = 0.513239 (* 1 = 0.513239 loss)
I1107 22:58:06.132005 19164 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1107 22:58:11.787446 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:58:12.021453 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_99000.caffemodel
I1107 22:58:12.036957 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_99000.solverstate
I1107 22:58:12.041956 19164 solver.cpp:330] Iteration 99000, Testing net (#0)
I1107 22:58:12.041956 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:58:13.334532 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:58:13.384537 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6783
I1107 22:58:13.384537 19164 solver.cpp:397]     Test net output #1: loss = 1.19954 (* 1 = 1.19954 loss)
I1107 22:58:13.441540 19164 solver.cpp:218] Iteration 99000 (13.6807 iter/s, 7.30955s/100 iters), loss = 0.462161
I1107 22:58:13.441540 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:58:13.441540 19164 solver.cpp:237]     Train net output #1: loss = 0.462161 (* 1 = 0.462161 loss)
I1107 22:58:13.442040 19164 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1107 22:58:19.367938 19164 solver.cpp:218] Iteration 99100 (16.8758 iter/s, 5.92564s/100 iters), loss = 0.439825
I1107 22:58:19.367938 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:58:19.367938 19164 solver.cpp:237]     Train net output #1: loss = 0.439825 (* 1 = 0.439825 loss)
I1107 22:58:19.367938 19164 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1107 22:58:25.302359 19164 solver.cpp:218] Iteration 99200 (16.8517 iter/s, 5.93411s/100 iters), loss = 0.286889
I1107 22:58:25.302359 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:58:25.302359 19164 solver.cpp:237]     Train net output #1: loss = 0.286889 (* 1 = 0.286889 loss)
I1107 22:58:25.302359 19164 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1107 22:58:31.299813 19164 solver.cpp:218] Iteration 99300 (16.673 iter/s, 5.99772s/100 iters), loss = 0.417342
I1107 22:58:31.300813 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:58:31.300813 19164 solver.cpp:237]     Train net output #1: loss = 0.417342 (* 1 = 0.417342 loss)
I1107 22:58:31.300813 19164 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1107 22:58:37.244755 19164 solver.cpp:218] Iteration 99400 (16.8248 iter/s, 5.94362s/100 iters), loss = 0.437871
I1107 22:58:37.244755 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 22:58:37.244755 19164 solver.cpp:237]     Train net output #1: loss = 0.437871 (* 1 = 0.437871 loss)
I1107 22:58:37.244755 19164 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1107 22:58:42.945034 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:58:43.176558 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_99500.caffemodel
I1107 22:58:43.191558 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_99500.solverstate
I1107 22:58:43.196559 19164 solver.cpp:330] Iteration 99500, Testing net (#0)
I1107 22:58:43.196559 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:58:44.492655 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:58:44.543704 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6774
I1107 22:58:44.543704 19164 solver.cpp:397]     Test net output #1: loss = 1.20211 (* 1 = 1.20211 loss)
I1107 22:58:44.600684 19164 solver.cpp:218] Iteration 99500 (13.5952 iter/s, 7.35552s/100 iters), loss = 0.395243
I1107 22:58:44.600684 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:58:44.600684 19164 solver.cpp:237]     Train net output #1: loss = 0.395243 (* 1 = 0.395243 loss)
I1107 22:58:44.600684 19164 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1107 22:58:50.568251 19164 solver.cpp:218] Iteration 99600 (16.7569 iter/s, 5.96768s/100 iters), loss = 0.416443
I1107 22:58:50.568251 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:58:50.568251 19164 solver.cpp:237]     Train net output #1: loss = 0.416443 (* 1 = 0.416443 loss)
I1107 22:58:50.568251 19164 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1107 22:58:56.513626 19164 solver.cpp:218] Iteration 99700 (16.8205 iter/s, 5.94514s/100 iters), loss = 0.449713
I1107 22:58:56.513626 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:58:56.513626 19164 solver.cpp:237]     Train net output #1: loss = 0.449713 (* 1 = 0.449713 loss)
I1107 22:58:56.513626 19164 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1107 22:59:02.419996 19164 solver.cpp:218] Iteration 99800 (16.9332 iter/s, 5.90556s/100 iters), loss = 0.454214
I1107 22:59:02.419996 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:59:02.419996 19164 solver.cpp:237]     Train net output #1: loss = 0.454214 (* 1 = 0.454214 loss)
I1107 22:59:02.419996 19164 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1107 22:59:08.364475 19164 solver.cpp:218] Iteration 99900 (16.8234 iter/s, 5.94409s/100 iters), loss = 0.552958
I1107 22:59:08.364475 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:59:08.364475 19164 solver.cpp:237]     Train net output #1: loss = 0.552958 (* 1 = 0.552958 loss)
I1107 22:59:08.364475 19164 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1107 22:59:14.042958 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:59:14.278975 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_100000.caffemodel
I1107 22:59:14.293978 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_100000.solverstate
I1107 22:59:14.299976 19164 solver.cpp:330] Iteration 100000, Testing net (#0)
I1107 22:59:14.299976 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:59:15.615085 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:59:15.666088 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6795
I1107 22:59:15.666088 19164 solver.cpp:397]     Test net output #1: loss = 1.21083 (* 1 = 1.21083 loss)
I1107 22:59:15.723093 19164 solver.cpp:218] Iteration 100000 (13.5904 iter/s, 7.35815s/100 iters), loss = 0.344882
I1107 22:59:15.723093 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:59:15.723093 19164 solver.cpp:237]     Train net output #1: loss = 0.344882 (* 1 = 0.344882 loss)
I1107 22:59:15.723093 19164 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1107 22:59:21.646512 19164 solver.cpp:218] Iteration 100100 (16.8841 iter/s, 5.92272s/100 iters), loss = 0.491078
I1107 22:59:21.646512 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:59:21.646512 19164 solver.cpp:237]     Train net output #1: loss = 0.491078 (* 1 = 0.491078 loss)
I1107 22:59:21.646512 19164 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1107 22:59:27.567905 19164 solver.cpp:218] Iteration 100200 (16.8895 iter/s, 5.92085s/100 iters), loss = 0.373064
I1107 22:59:27.567905 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:59:27.567905 19164 solver.cpp:237]     Train net output #1: loss = 0.373064 (* 1 = 0.373064 loss)
I1107 22:59:27.567905 19164 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1107 22:59:33.491293 19164 solver.cpp:218] Iteration 100300 (16.8827 iter/s, 5.92323s/100 iters), loss = 0.473268
I1107 22:59:33.491293 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 22:59:33.491293 19164 solver.cpp:237]     Train net output #1: loss = 0.473268 (* 1 = 0.473268 loss)
I1107 22:59:33.491293 19164 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1107 22:59:39.412703 19164 solver.cpp:218] Iteration 100400 (16.8881 iter/s, 5.92132s/100 iters), loss = 0.478906
I1107 22:59:39.412703 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:59:39.412703 19164 solver.cpp:237]     Train net output #1: loss = 0.478906 (* 1 = 0.478906 loss)
I1107 22:59:39.412703 19164 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1107 22:59:45.045125 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:59:45.278138 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_100500.caffemodel
I1107 22:59:45.292140 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_100500.solverstate
I1107 22:59:45.297138 19164 solver.cpp:330] Iteration 100500, Testing net (#0)
I1107 22:59:45.297138 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:59:46.587236 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:59:46.638238 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6782
I1107 22:59:46.638238 19164 solver.cpp:397]     Test net output #1: loss = 1.21073 (* 1 = 1.21073 loss)
I1107 22:59:46.694242 19164 solver.cpp:218] Iteration 100500 (13.7347 iter/s, 7.28081s/100 iters), loss = 0.499194
I1107 22:59:46.694242 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:59:46.694242 19164 solver.cpp:237]     Train net output #1: loss = 0.499194 (* 1 = 0.499194 loss)
I1107 22:59:46.694242 19164 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1107 22:59:52.583133 19164 solver.cpp:218] Iteration 100600 (16.9827 iter/s, 5.88836s/100 iters), loss = 0.468729
I1107 22:59:52.583133 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:59:52.583133 19164 solver.cpp:237]     Train net output #1: loss = 0.468729 (* 1 = 0.468729 loss)
I1107 22:59:52.583133 19164 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1107 22:59:58.504988 19164 solver.cpp:218] Iteration 100700 (16.8879 iter/s, 5.9214s/100 iters), loss = 0.391136
I1107 22:59:58.504988 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:59:58.504988 19164 solver.cpp:237]     Train net output #1: loss = 0.391136 (* 1 = 0.391136 loss)
I1107 22:59:58.504988 19164 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1107 23:00:04.480404 19164 solver.cpp:218] Iteration 100800 (16.7358 iter/s, 5.97521s/100 iters), loss = 0.40913
I1107 23:00:04.480404 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 23:00:04.480404 19164 solver.cpp:237]     Train net output #1: loss = 0.40913 (* 1 = 0.40913 loss)
I1107 23:00:04.480404 19164 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1107 23:00:10.443109 19164 solver.cpp:218] Iteration 100900 (16.773 iter/s, 5.96195s/100 iters), loss = 0.485865
I1107 23:00:10.443109 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 23:00:10.443109 19164 solver.cpp:237]     Train net output #1: loss = 0.485865 (* 1 = 0.485865 loss)
I1107 23:00:10.443109 19164 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1107 23:00:16.072837 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:00:16.306860 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_101000.caffemodel
I1107 23:00:16.324861 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_101000.solverstate
I1107 23:00:16.329859 19164 solver.cpp:330] Iteration 101000, Testing net (#0)
I1107 23:00:16.329859 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:00:17.624992 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:00:17.674996 19164 solver.cpp:397]     Test net output #0: accuracy = 0.68
I1107 23:00:17.675997 19164 solver.cpp:397]     Test net output #1: loss = 1.21079 (* 1 = 1.21079 loss)
I1107 23:00:17.731997 19164 solver.cpp:218] Iteration 101000 (13.7192 iter/s, 7.28907s/100 iters), loss = 0.416855
I1107 23:00:17.731997 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:00:17.731997 19164 solver.cpp:237]     Train net output #1: loss = 0.416855 (* 1 = 0.416855 loss)
I1107 23:00:17.731997 19164 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1107 23:00:23.671378 19164 solver.cpp:218] Iteration 101100 (16.8388 iter/s, 5.93868s/100 iters), loss = 0.441295
I1107 23:00:23.671378 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:00:23.671378 19164 solver.cpp:237]     Train net output #1: loss = 0.441295 (* 1 = 0.441295 loss)
I1107 23:00:23.671378 19164 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1107 23:00:29.621742 19164 solver.cpp:218] Iteration 101200 (16.8081 iter/s, 5.9495s/100 iters), loss = 0.405407
I1107 23:00:29.621742 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:00:29.621742 19164 solver.cpp:237]     Train net output #1: loss = 0.405407 (* 1 = 0.405407 loss)
I1107 23:00:29.621742 19164 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1107 23:00:35.534142 19164 solver.cpp:218] Iteration 101300 (16.9127 iter/s, 5.91272s/100 iters), loss = 0.404898
I1107 23:00:35.534142 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:00:35.534142 19164 solver.cpp:237]     Train net output #1: loss = 0.404898 (* 1 = 0.404898 loss)
I1107 23:00:35.534142 19164 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1107 23:00:41.455495 19164 solver.cpp:218] Iteration 101400 (16.8891 iter/s, 5.92098s/100 iters), loss = 0.426935
I1107 23:00:41.455495 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:00:41.455495 19164 solver.cpp:237]     Train net output #1: loss = 0.426935 (* 1 = 0.426935 loss)
I1107 23:00:41.455495 19164 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1107 23:00:47.089830 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:00:47.322839 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_101500.caffemodel
I1107 23:00:47.337838 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_101500.solverstate
I1107 23:00:47.342839 19164 solver.cpp:330] Iteration 101500, Testing net (#0)
I1107 23:00:47.342839 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:00:48.628929 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:00:48.679940 19164 solver.cpp:397]     Test net output #0: accuracy = 0.672
I1107 23:00:48.679940 19164 solver.cpp:397]     Test net output #1: loss = 1.22813 (* 1 = 1.22813 loss)
I1107 23:00:48.735932 19164 solver.cpp:218] Iteration 101500 (13.7373 iter/s, 7.27944s/100 iters), loss = 0.38013
I1107 23:00:48.735932 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:00:48.735932 19164 solver.cpp:237]     Train net output #1: loss = 0.38013 (* 1 = 0.38013 loss)
I1107 23:00:48.735932 19164 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1107 23:00:54.650369 19164 solver.cpp:218] Iteration 101600 (16.9078 iter/s, 5.91443s/100 iters), loss = 0.478629
I1107 23:00:54.650369 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:00:54.650369 19164 solver.cpp:237]     Train net output #1: loss = 0.478629 (* 1 = 0.478629 loss)
I1107 23:00:54.650369 19164 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1107 23:01:00.555982 19164 solver.cpp:218] Iteration 101700 (16.9347 iter/s, 5.90505s/100 iters), loss = 0.376166
I1107 23:01:00.555982 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:01:00.555982 19164 solver.cpp:237]     Train net output #1: loss = 0.376166 (* 1 = 0.376166 loss)
I1107 23:01:00.555982 19164 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1107 23:01:06.503392 19164 solver.cpp:218] Iteration 101800 (16.8154 iter/s, 5.94692s/100 iters), loss = 0.431175
I1107 23:01:06.503392 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:01:06.503392 19164 solver.cpp:237]     Train net output #1: loss = 0.431175 (* 1 = 0.431175 loss)
I1107 23:01:06.503392 19164 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1107 23:01:12.432798 19164 solver.cpp:218] Iteration 101900 (16.8656 iter/s, 5.92924s/100 iters), loss = 0.437142
I1107 23:01:12.432798 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 23:01:12.432798 19164 solver.cpp:237]     Train net output #1: loss = 0.437142 (* 1 = 0.437142 loss)
I1107 23:01:12.432798 19164 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1107 23:01:18.091473 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:01:18.325628 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_102000.caffemodel
I1107 23:01:18.340627 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_102000.solverstate
I1107 23:01:18.345628 19164 solver.cpp:330] Iteration 102000, Testing net (#0)
I1107 23:01:18.345628 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:01:19.632392 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:01:19.683411 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6792
I1107 23:01:19.683411 19164 solver.cpp:397]     Test net output #1: loss = 1.20812 (* 1 = 1.20812 loss)
I1107 23:01:19.740418 19164 solver.cpp:218] Iteration 102000 (13.6861 iter/s, 7.30666s/100 iters), loss = 0.38941
I1107 23:01:19.740418 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:01:19.740418 19164 solver.cpp:237]     Train net output #1: loss = 0.38941 (* 1 = 0.38941 loss)
I1107 23:01:19.740418 19164 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1107 23:01:25.743324 19164 solver.cpp:218] Iteration 102100 (16.6604 iter/s, 6.00227s/100 iters), loss = 0.37733
I1107 23:01:25.743324 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:01:25.743324 19164 solver.cpp:237]     Train net output #1: loss = 0.37733 (* 1 = 0.37733 loss)
I1107 23:01:25.743324 19164 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1107 23:01:31.709885 19164 solver.cpp:218] Iteration 102200 (16.7604 iter/s, 5.96645s/100 iters), loss = 0.342701
I1107 23:01:31.709885 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:01:31.709885 19164 solver.cpp:237]     Train net output #1: loss = 0.342701 (* 1 = 0.342701 loss)
I1107 23:01:31.709885 19164 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1107 23:01:37.657975 19164 solver.cpp:218] Iteration 102300 (16.8125 iter/s, 5.94796s/100 iters), loss = 0.438578
I1107 23:01:37.657975 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:01:37.657975 19164 solver.cpp:237]     Train net output #1: loss = 0.438578 (* 1 = 0.438578 loss)
I1107 23:01:37.657975 19164 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1107 23:01:43.590421 19164 solver.cpp:218] Iteration 102400 (16.8587 iter/s, 5.93164s/100 iters), loss = 0.466311
I1107 23:01:43.590421 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:01:43.590421 19164 solver.cpp:237]     Train net output #1: loss = 0.466311 (* 1 = 0.466311 loss)
I1107 23:01:43.590421 19164 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1107 23:01:49.205780 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:01:49.437793 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_102500.caffemodel
I1107 23:01:49.455793 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_102500.solverstate
I1107 23:01:49.461794 19164 solver.cpp:330] Iteration 102500, Testing net (#0)
I1107 23:01:49.461794 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:01:50.753945 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:01:50.804980 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6782
I1107 23:01:50.804980 19164 solver.cpp:397]     Test net output #1: loss = 1.2205 (* 1 = 1.2205 loss)
I1107 23:01:50.861968 19164 solver.cpp:218] Iteration 102500 (13.7534 iter/s, 7.27091s/100 iters), loss = 0.409578
I1107 23:01:50.861968 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:01:50.861968 19164 solver.cpp:237]     Train net output #1: loss = 0.409578 (* 1 = 0.409578 loss)
I1107 23:01:50.861968 19164 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1107 23:01:56.782441 19164 solver.cpp:218] Iteration 102600 (16.8917 iter/s, 5.92008s/100 iters), loss = 0.459071
I1107 23:01:56.782441 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:01:56.782441 19164 solver.cpp:237]     Train net output #1: loss = 0.459071 (* 1 = 0.459071 loss)
I1107 23:01:56.782441 19164 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1107 23:02:02.753162 19164 solver.cpp:218] Iteration 102700 (16.7486 iter/s, 5.97064s/100 iters), loss = 0.371158
I1107 23:02:02.753162 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:02:02.753162 19164 solver.cpp:237]     Train net output #1: loss = 0.371158 (* 1 = 0.371158 loss)
I1107 23:02:02.753162 19164 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1107 23:02:08.682523 19164 solver.cpp:218] Iteration 102800 (16.8676 iter/s, 5.92851s/100 iters), loss = 0.433988
I1107 23:02:08.682523 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:02:08.682523 19164 solver.cpp:237]     Train net output #1: loss = 0.433988 (* 1 = 0.433988 loss)
I1107 23:02:08.682523 19164 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1107 23:02:14.608886 19164 solver.cpp:218] Iteration 102900 (16.875 iter/s, 5.92591s/100 iters), loss = 0.454267
I1107 23:02:14.608886 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:02:14.608886 19164 solver.cpp:237]     Train net output #1: loss = 0.454267 (* 1 = 0.454267 loss)
I1107 23:02:14.608886 19164 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1107 23:02:20.278764 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:02:20.517277 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_103000.caffemodel
I1107 23:02:20.535276 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_103000.solverstate
I1107 23:02:20.540277 19164 solver.cpp:330] Iteration 103000, Testing net (#0)
I1107 23:02:20.541277 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:02:21.843389 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:02:21.894387 19164 solver.cpp:397]     Test net output #0: accuracy = 0.678
I1107 23:02:21.894387 19164 solver.cpp:397]     Test net output #1: loss = 1.22119 (* 1 = 1.22119 loss)
I1107 23:02:21.950387 19164 solver.cpp:218] Iteration 103000 (13.6211 iter/s, 7.34157s/100 iters), loss = 0.400585
I1107 23:02:21.950387 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:02:21.950387 19164 solver.cpp:237]     Train net output #1: loss = 0.400585 (* 1 = 0.400585 loss)
I1107 23:02:21.950387 19164 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1107 23:02:27.936141 19164 solver.cpp:218] Iteration 103100 (16.7078 iter/s, 5.98524s/100 iters), loss = 0.414197
I1107 23:02:27.936141 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:02:27.936141 19164 solver.cpp:237]     Train net output #1: loss = 0.414197 (* 1 = 0.414197 loss)
I1107 23:02:27.936141 19164 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1107 23:02:33.924016 19164 solver.cpp:218] Iteration 103200 (16.7007 iter/s, 5.98777s/100 iters), loss = 0.319687
I1107 23:02:33.924016 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 23:02:33.924016 19164 solver.cpp:237]     Train net output #1: loss = 0.319687 (* 1 = 0.319687 loss)
I1107 23:02:33.924016 19164 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1107 23:02:39.890558 19164 solver.cpp:218] Iteration 103300 (16.7634 iter/s, 5.96539s/100 iters), loss = 0.500377
I1107 23:02:39.890558 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:02:39.890558 19164 solver.cpp:237]     Train net output #1: loss = 0.500377 (* 1 = 0.500377 loss)
I1107 23:02:39.890558 19164 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1107 23:02:45.830023 19164 solver.cpp:218] Iteration 103400 (16.8359 iter/s, 5.93968s/100 iters), loss = 0.436212
I1107 23:02:45.830023 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:02:45.830023 19164 solver.cpp:237]     Train net output #1: loss = 0.436212 (* 1 = 0.436212 loss)
I1107 23:02:45.830023 19164 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1107 23:02:51.448426 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:02:51.679935 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_103500.caffemodel
I1107 23:02:51.694439 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_103500.solverstate
I1107 23:02:51.699440 19164 solver.cpp:330] Iteration 103500, Testing net (#0)
I1107 23:02:51.699440 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:02:52.989269 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:02:53.039770 19164 solver.cpp:397]     Test net output #0: accuracy = 0.681
I1107 23:02:53.039770 19164 solver.cpp:397]     Test net output #1: loss = 1.21759 (* 1 = 1.21759 loss)
I1107 23:02:53.096774 19164 solver.cpp:218] Iteration 103500 (13.7624 iter/s, 7.26615s/100 iters), loss = 0.36369
I1107 23:02:53.096774 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:02:53.096774 19164 solver.cpp:237]     Train net output #1: loss = 0.36369 (* 1 = 0.36369 loss)
I1107 23:02:53.096774 19164 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1107 23:02:59.002184 19164 solver.cpp:218] Iteration 103600 (16.9351 iter/s, 5.90491s/100 iters), loss = 0.472945
I1107 23:02:59.002184 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:02:59.002184 19164 solver.cpp:237]     Train net output #1: loss = 0.472945 (* 1 = 0.472945 loss)
I1107 23:02:59.002184 19164 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1107 23:03:04.931558 19164 solver.cpp:218] Iteration 103700 (16.8667 iter/s, 5.92883s/100 iters), loss = 0.383878
I1107 23:03:04.931558 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:03:04.931558 19164 solver.cpp:237]     Train net output #1: loss = 0.383878 (* 1 = 0.383878 loss)
I1107 23:03:04.931558 19164 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1107 23:03:10.869809 19164 solver.cpp:218] Iteration 103800 (16.8404 iter/s, 5.93811s/100 iters), loss = 0.422262
I1107 23:03:10.869809 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:03:10.870810 19164 solver.cpp:237]     Train net output #1: loss = 0.422262 (* 1 = 0.422262 loss)
I1107 23:03:10.870810 19164 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1107 23:03:16.832798 19164 solver.cpp:218] Iteration 103900 (16.7715 iter/s, 5.96251s/100 iters), loss = 0.436971
I1107 23:03:16.833798 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:03:16.833798 19164 solver.cpp:237]     Train net output #1: loss = 0.436971 (* 1 = 0.436971 loss)
I1107 23:03:16.833798 19164 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1107 23:03:22.496186 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:03:22.730202 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_104000.caffemodel
I1107 23:03:22.744202 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_104000.solverstate
I1107 23:03:22.748201 19164 solver.cpp:330] Iteration 104000, Testing net (#0)
I1107 23:03:22.749203 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:03:24.038411 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:03:24.088917 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6755
I1107 23:03:24.088917 19164 solver.cpp:397]     Test net output #1: loss = 1.23006 (* 1 = 1.23006 loss)
I1107 23:03:24.145417 19164 solver.cpp:218] Iteration 104000 (13.6776 iter/s, 7.31124s/100 iters), loss = 0.429344
I1107 23:03:24.145417 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:03:24.145417 19164 solver.cpp:237]     Train net output #1: loss = 0.429344 (* 1 = 0.429344 loss)
I1107 23:03:24.145417 19164 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1107 23:03:30.060135 19164 solver.cpp:218] Iteration 104100 (16.9085 iter/s, 5.91419s/100 iters), loss = 0.390805
I1107 23:03:30.060135 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:03:30.060135 19164 solver.cpp:237]     Train net output #1: loss = 0.390805 (* 1 = 0.390805 loss)
I1107 23:03:30.060135 19164 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1107 23:03:35.980548 19164 solver.cpp:218] Iteration 104200 (16.8895 iter/s, 5.92083s/100 iters), loss = 0.343085
I1107 23:03:35.980548 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:03:35.981549 19164 solver.cpp:237]     Train net output #1: loss = 0.343085 (* 1 = 0.343085 loss)
I1107 23:03:35.981549 19164 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1107 23:03:41.905012 19164 solver.cpp:218] Iteration 104300 (16.8833 iter/s, 5.92301s/100 iters), loss = 0.510864
I1107 23:03:41.905012 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 23:03:41.905012 19164 solver.cpp:237]     Train net output #1: loss = 0.510864 (* 1 = 0.510864 loss)
I1107 23:03:41.905012 19164 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1107 23:03:47.858408 19164 solver.cpp:218] Iteration 104400 (16.7969 iter/s, 5.95349s/100 iters), loss = 0.394467
I1107 23:03:47.858408 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:03:47.858408 19164 solver.cpp:237]     Train net output #1: loss = 0.394467 (* 1 = 0.394467 loss)
I1107 23:03:47.858408 19164 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1107 23:03:53.530841 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:03:53.764853 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_104500.caffemodel
I1107 23:03:53.778853 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_104500.solverstate
I1107 23:03:53.783854 19164 solver.cpp:330] Iteration 104500, Testing net (#0)
I1107 23:03:53.783854 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:03:55.084002 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:03:55.135504 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6796
I1107 23:03:55.135504 19164 solver.cpp:397]     Test net output #1: loss = 1.22319 (* 1 = 1.22319 loss)
I1107 23:03:55.192008 19164 solver.cpp:218] Iteration 104500 (13.6375 iter/s, 7.33271s/100 iters), loss = 0.325584
I1107 23:03:55.192008 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 23:03:55.192008 19164 solver.cpp:237]     Train net output #1: loss = 0.325584 (* 1 = 0.325584 loss)
I1107 23:03:55.192008 19164 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1107 23:04:01.177620 19164 solver.cpp:218] Iteration 104600 (16.7064 iter/s, 5.98574s/100 iters), loss = 0.459731
I1107 23:04:01.177620 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:04:01.177620 19164 solver.cpp:237]     Train net output #1: loss = 0.459731 (* 1 = 0.459731 loss)
I1107 23:04:01.177620 19164 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1107 23:04:07.115118 19164 solver.cpp:218] Iteration 104700 (16.8432 iter/s, 5.93713s/100 iters), loss = 0.356547
I1107 23:04:07.115118 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:04:07.115118 19164 solver.cpp:237]     Train net output #1: loss = 0.356547 (* 1 = 0.356547 loss)
I1107 23:04:07.115118 19164 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1107 23:04:13.052259 19164 solver.cpp:218] Iteration 104800 (16.8465 iter/s, 5.93595s/100 iters), loss = 0.448839
I1107 23:04:13.052259 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:04:13.052259 19164 solver.cpp:237]     Train net output #1: loss = 0.448839 (* 1 = 0.448839 loss)
I1107 23:04:13.052259 19164 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1107 23:04:19.033273 19164 solver.cpp:218] Iteration 104900 (16.7207 iter/s, 5.98063s/100 iters), loss = 0.367759
I1107 23:04:19.033273 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:04:19.033273 19164 solver.cpp:237]     Train net output #1: loss = 0.367759 (* 1 = 0.367759 loss)
I1107 23:04:19.033273 19164 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1107 23:04:24.730463 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:04:24.964383 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_105000.caffemodel
I1107 23:04:24.979383 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_105000.solverstate
I1107 23:04:24.984383 19164 solver.cpp:330] Iteration 105000, Testing net (#0)
I1107 23:04:24.984383 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:04:26.281209 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:04:26.332721 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6796
I1107 23:04:26.332721 19164 solver.cpp:397]     Test net output #1: loss = 1.2261 (* 1 = 1.2261 loss)
I1107 23:04:26.389242 19164 solver.cpp:218] Iteration 105000 (13.5947 iter/s, 7.35581s/100 iters), loss = 0.34022
I1107 23:04:26.389242 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 23:04:26.389242 19164 solver.cpp:237]     Train net output #1: loss = 0.34022 (* 1 = 0.34022 loss)
I1107 23:04:26.389242 19164 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1107 23:04:32.347793 19164 solver.cpp:218] Iteration 105100 (16.784 iter/s, 5.95804s/100 iters), loss = 0.362049
I1107 23:04:32.347793 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:04:32.347793 19164 solver.cpp:237]     Train net output #1: loss = 0.36205 (* 1 = 0.36205 loss)
I1107 23:04:32.347793 19164 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1107 23:04:38.296185 19164 solver.cpp:218] Iteration 105200 (16.8112 iter/s, 5.94841s/100 iters), loss = 0.331639
I1107 23:04:38.296185 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:04:38.296185 19164 solver.cpp:237]     Train net output #1: loss = 0.331639 (* 1 = 0.331639 loss)
I1107 23:04:38.296185 19164 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1107 23:04:44.242576 19164 solver.cpp:218] Iteration 105300 (16.8178 iter/s, 5.94607s/100 iters), loss = 0.37581
I1107 23:04:44.242576 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:04:44.242576 19164 solver.cpp:237]     Train net output #1: loss = 0.37581 (* 1 = 0.37581 loss)
I1107 23:04:44.242576 19164 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1107 23:04:50.198423 19164 solver.cpp:218] Iteration 105400 (16.793 iter/s, 5.95488s/100 iters), loss = 0.458554
I1107 23:04:50.198423 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:04:50.198423 19164 solver.cpp:237]     Train net output #1: loss = 0.458555 (* 1 = 0.458555 loss)
I1107 23:04:50.198423 19164 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1107 23:04:55.881860 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:04:56.114872 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_105500.caffemodel
I1107 23:04:56.128875 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_105500.solverstate
I1107 23:04:56.133875 19164 solver.cpp:330] Iteration 105500, Testing net (#0)
I1107 23:04:56.133875 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:04:57.440402 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:04:57.491401 19164 solver.cpp:397]     Test net output #0: accuracy = 0.677
I1107 23:04:57.491401 19164 solver.cpp:397]     Test net output #1: loss = 1.24085 (* 1 = 1.24085 loss)
I1107 23:04:57.548405 19164 solver.cpp:218] Iteration 105500 (13.6062 iter/s, 7.34957s/100 iters), loss = 0.399883
I1107 23:04:57.548405 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:04:57.548405 19164 solver.cpp:237]     Train net output #1: loss = 0.399883 (* 1 = 0.399883 loss)
I1107 23:04:57.548405 19164 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1107 23:05:03.493794 19164 solver.cpp:218] Iteration 105600 (16.8214 iter/s, 5.94482s/100 iters), loss = 0.426518
I1107 23:05:03.493794 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:05:03.493794 19164 solver.cpp:237]     Train net output #1: loss = 0.426518 (* 1 = 0.426518 loss)
I1107 23:05:03.493794 19164 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1107 23:05:09.404014 19164 solver.cpp:218] Iteration 105700 (16.9206 iter/s, 5.90996s/100 iters), loss = 0.301059
I1107 23:05:09.404014 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 23:05:09.404014 19164 solver.cpp:237]     Train net output #1: loss = 0.301059 (* 1 = 0.301059 loss)
I1107 23:05:09.404014 19164 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1107 23:05:15.357767 19164 solver.cpp:218] Iteration 105800 (16.7956 iter/s, 5.95394s/100 iters), loss = 0.369216
I1107 23:05:15.357767 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:05:15.358768 19164 solver.cpp:237]     Train net output #1: loss = 0.369216 (* 1 = 0.369216 loss)
I1107 23:05:15.358768 19164 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1107 23:05:21.296207 19164 solver.cpp:218] Iteration 105900 (16.8432 iter/s, 5.93712s/100 iters), loss = 0.48037
I1107 23:05:21.296207 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:05:21.296207 19164 solver.cpp:237]     Train net output #1: loss = 0.48037 (* 1 = 0.48037 loss)
I1107 23:05:21.296207 19164 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1107 23:05:26.956671 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:05:27.188683 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_106000.caffemodel
I1107 23:05:27.203682 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_106000.solverstate
I1107 23:05:27.208683 19164 solver.cpp:330] Iteration 106000, Testing net (#0)
I1107 23:05:27.208683 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:05:28.508782 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:05:28.559792 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6746
I1107 23:05:28.559792 19164 solver.cpp:397]     Test net output #1: loss = 1.23562 (* 1 = 1.23562 loss)
I1107 23:05:28.616287 19164 solver.cpp:218] Iteration 106000 (13.6619 iter/s, 7.31964s/100 iters), loss = 0.325191
I1107 23:05:28.616287 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:05:28.616287 19164 solver.cpp:237]     Train net output #1: loss = 0.325191 (* 1 = 0.325191 loss)
I1107 23:05:28.616287 19164 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1107 23:05:34.634292 19164 solver.cpp:218] Iteration 106100 (16.6166 iter/s, 6.01807s/100 iters), loss = 0.414188
I1107 23:05:34.634292 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:05:34.634292 19164 solver.cpp:237]     Train net output #1: loss = 0.414188 (* 1 = 0.414188 loss)
I1107 23:05:34.634292 19164 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1107 23:05:40.592774 19164 solver.cpp:218] Iteration 106200 (16.7828 iter/s, 5.95848s/100 iters), loss = 0.301882
I1107 23:05:40.593775 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 23:05:40.593775 19164 solver.cpp:237]     Train net output #1: loss = 0.301882 (* 1 = 0.301882 loss)
I1107 23:05:40.593775 19164 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1107 23:05:46.522580 19164 solver.cpp:218] Iteration 106300 (16.8677 iter/s, 5.92848s/100 iters), loss = 0.381183
I1107 23:05:46.522580 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:05:46.522580 19164 solver.cpp:237]     Train net output #1: loss = 0.381183 (* 1 = 0.381183 loss)
I1107 23:05:46.522580 19164 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1107 23:05:52.532024 19164 solver.cpp:218] Iteration 106400 (16.6398 iter/s, 6.00968s/100 iters), loss = 0.45622
I1107 23:05:52.532024 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:05:52.532024 19164 solver.cpp:237]     Train net output #1: loss = 0.45622 (* 1 = 0.45622 loss)
I1107 23:05:52.532024 19164 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1107 23:05:58.183260 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:05:58.415288 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_106500.caffemodel
I1107 23:05:58.430287 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_106500.solverstate
I1107 23:05:58.434288 19164 solver.cpp:330] Iteration 106500, Testing net (#0)
I1107 23:05:58.435288 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:05:59.726418 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:05:59.776429 19164 solver.cpp:397]     Test net output #0: accuracy = 0.675
I1107 23:05:59.776429 19164 solver.cpp:397]     Test net output #1: loss = 1.24381 (* 1 = 1.24381 loss)
I1107 23:05:59.833426 19164 solver.cpp:218] Iteration 106500 (13.6986 iter/s, 7.30003s/100 iters), loss = 0.408721
I1107 23:05:59.833426 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:05:59.833426 19164 solver.cpp:237]     Train net output #1: loss = 0.408722 (* 1 = 0.408722 loss)
I1107 23:05:59.833426 19164 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1107 23:06:05.918978 19164 solver.cpp:218] Iteration 106600 (16.4334 iter/s, 6.08518s/100 iters), loss = 0.473755
I1107 23:06:05.918978 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:06:05.918978 19164 solver.cpp:237]     Train net output #1: loss = 0.473755 (* 1 = 0.473755 loss)
I1107 23:06:05.918978 19164 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1107 23:06:11.927283 19164 solver.cpp:218] Iteration 106700 (16.6456 iter/s, 6.00758s/100 iters), loss = 0.27302
I1107 23:06:11.927283 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 23:06:11.927283 19164 solver.cpp:237]     Train net output #1: loss = 0.27302 (* 1 = 0.27302 loss)
I1107 23:06:11.927283 19164 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1107 23:06:17.935025 19164 solver.cpp:218] Iteration 106800 (16.6459 iter/s, 6.00749s/100 iters), loss = 0.480716
I1107 23:06:17.935025 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:06:17.935025 19164 solver.cpp:237]     Train net output #1: loss = 0.480716 (* 1 = 0.480716 loss)
I1107 23:06:17.935025 19164 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1107 23:06:23.941731 19164 solver.cpp:218] Iteration 106900 (16.6489 iter/s, 6.00642s/100 iters), loss = 0.419706
I1107 23:06:23.941731 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:06:23.941731 19164 solver.cpp:237]     Train net output #1: loss = 0.419706 (* 1 = 0.419706 loss)
I1107 23:06:23.941731 19164 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1107 23:06:29.660233 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:06:29.895232 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_107000.caffemodel
I1107 23:06:29.910732 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_107000.solverstate
I1107 23:06:29.915732 19164 solver.cpp:330] Iteration 107000, Testing net (#0)
I1107 23:06:29.915732 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:06:31.225733 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:06:31.277232 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6785
I1107 23:06:31.277232 19164 solver.cpp:397]     Test net output #1: loss = 1.24186 (* 1 = 1.24186 loss)
I1107 23:06:31.334781 19164 solver.cpp:218] Iteration 107000 (13.5271 iter/s, 7.39258s/100 iters), loss = 0.415804
I1107 23:06:31.334781 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:06:31.334781 19164 solver.cpp:237]     Train net output #1: loss = 0.415804 (* 1 = 0.415804 loss)
I1107 23:06:31.335281 19164 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1107 23:06:37.337998 19164 solver.cpp:218] Iteration 107100 (16.659 iter/s, 6.00277s/100 iters), loss = 0.383199
I1107 23:06:37.338500 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:06:37.338500 19164 solver.cpp:237]     Train net output #1: loss = 0.383199 (* 1 = 0.383199 loss)
I1107 23:06:37.338500 19164 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1107 23:06:43.361479 19164 solver.cpp:218] Iteration 107200 (16.6044 iter/s, 6.02251s/100 iters), loss = 0.306542
I1107 23:06:43.361479 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:06:43.361479 19164 solver.cpp:237]     Train net output #1: loss = 0.306543 (* 1 = 0.306543 loss)
I1107 23:06:43.361479 19164 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1107 23:06:49.346940 19164 solver.cpp:218] Iteration 107300 (16.7076 iter/s, 5.98529s/100 iters), loss = 0.503608
I1107 23:06:49.346940 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:06:49.346940 19164 solver.cpp:237]     Train net output #1: loss = 0.503608 (* 1 = 0.503608 loss)
I1107 23:06:49.346940 19164 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1107 23:06:55.342511 19164 solver.cpp:218] Iteration 107400 (16.6802 iter/s, 5.99513s/100 iters), loss = 0.429388
I1107 23:06:55.342511 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:06:55.342511 19164 solver.cpp:237]     Train net output #1: loss = 0.429388 (* 1 = 0.429388 loss)
I1107 23:06:55.342511 19164 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1107 23:07:01.022512 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:07:01.257014 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_107500.caffemodel
I1107 23:07:01.271013 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_107500.solverstate
I1107 23:07:01.276513 19164 solver.cpp:330] Iteration 107500, Testing net (#0)
I1107 23:07:01.276513 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:07:02.586513 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:07:02.637013 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6782
I1107 23:07:02.637013 19164 solver.cpp:397]     Test net output #1: loss = 1.23089 (* 1 = 1.23089 loss)
I1107 23:07:02.693511 19164 solver.cpp:218] Iteration 107500 (13.6046 iter/s, 7.35047s/100 iters), loss = 0.301348
I1107 23:07:02.693511 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 23:07:02.693511 19164 solver.cpp:237]     Train net output #1: loss = 0.301348 (* 1 = 0.301348 loss)
I1107 23:07:02.693511 19164 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1107 23:07:08.663225 19164 solver.cpp:218] Iteration 107600 (16.752 iter/s, 5.96944s/100 iters), loss = 0.419033
I1107 23:07:08.663725 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:07:08.663725 19164 solver.cpp:237]     Train net output #1: loss = 0.419033 (* 1 = 0.419033 loss)
I1107 23:07:08.663725 19164 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1107 23:07:14.600075 19164 solver.cpp:218] Iteration 107700 (16.8464 iter/s, 5.93599s/100 iters), loss = 0.336476
I1107 23:07:14.600075 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:07:14.600075 19164 solver.cpp:237]     Train net output #1: loss = 0.336476 (* 1 = 0.336476 loss)
I1107 23:07:14.600075 19164 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1107 23:07:20.627570 19164 solver.cpp:218] Iteration 107800 (16.5909 iter/s, 6.02738s/100 iters), loss = 0.397656
I1107 23:07:20.627570 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:07:20.627570 19164 solver.cpp:237]     Train net output #1: loss = 0.397656 (* 1 = 0.397656 loss)
I1107 23:07:20.627570 19164 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1107 23:07:26.665082 19164 solver.cpp:218] Iteration 107900 (16.5631 iter/s, 6.03751s/100 iters), loss = 0.429355
I1107 23:07:26.665082 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:07:26.665082 19164 solver.cpp:237]     Train net output #1: loss = 0.429356 (* 1 = 0.429356 loss)
I1107 23:07:26.665082 19164 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1107 23:07:32.349453 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:07:32.584468 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_108000.caffemodel
I1107 23:07:32.599468 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_108000.solverstate
I1107 23:07:32.604472 19164 solver.cpp:330] Iteration 108000, Testing net (#0)
I1107 23:07:32.604472 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:07:33.897586 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:07:33.948639 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6757
I1107 23:07:33.948639 19164 solver.cpp:397]     Test net output #1: loss = 1.23842 (* 1 = 1.23842 loss)
I1107 23:07:34.005620 19164 solver.cpp:218] Iteration 108000 (13.6254 iter/s, 7.33921s/100 iters), loss = 0.37445
I1107 23:07:34.005620 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:07:34.005620 19164 solver.cpp:237]     Train net output #1: loss = 0.37445 (* 1 = 0.37445 loss)
I1107 23:07:34.005620 19164 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1107 23:07:39.931077 19164 solver.cpp:218] Iteration 108100 (16.8763 iter/s, 5.92548s/100 iters), loss = 0.407437
I1107 23:07:39.931077 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:07:39.931077 19164 solver.cpp:237]     Train net output #1: loss = 0.407437 (* 1 = 0.407437 loss)
I1107 23:07:39.931077 19164 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1107 23:07:45.838435 19164 solver.cpp:218] Iteration 108200 (16.9302 iter/s, 5.9066s/100 iters), loss = 0.270659
I1107 23:07:45.838435 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 23:07:45.838435 19164 solver.cpp:237]     Train net output #1: loss = 0.270659 (* 1 = 0.270659 loss)
I1107 23:07:45.838435 19164 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1107 23:07:51.740838 19164 solver.cpp:218] Iteration 108300 (16.943 iter/s, 5.90214s/100 iters), loss = 0.422538
I1107 23:07:51.740838 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:07:51.740838 19164 solver.cpp:237]     Train net output #1: loss = 0.422538 (* 1 = 0.422538 loss)
I1107 23:07:51.740838 19164 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1107 23:07:57.642246 19164 solver.cpp:218] Iteration 108400 (16.9473 iter/s, 5.90065s/100 iters), loss = 0.427777
I1107 23:07:57.642246 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:07:57.642246 19164 solver.cpp:237]     Train net output #1: loss = 0.427777 (* 1 = 0.427777 loss)
I1107 23:07:57.642246 19164 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1107 23:08:03.255615 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:08:03.489624 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_108500.caffemodel
I1107 23:08:03.504127 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_108500.solverstate
I1107 23:08:03.509129 19164 solver.cpp:330] Iteration 108500, Testing net (#0)
I1107 23:08:03.509129 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:08:04.797768 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:08:04.848783 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6737
I1107 23:08:04.848783 19164 solver.cpp:397]     Test net output #1: loss = 1.24512 (* 1 = 1.24512 loss)
I1107 23:08:04.905786 19164 solver.cpp:218] Iteration 108500 (13.7683 iter/s, 7.26305s/100 iters), loss = 0.307611
I1107 23:08:04.905786 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 23:08:04.905786 19164 solver.cpp:237]     Train net output #1: loss = 0.307611 (* 1 = 0.307611 loss)
I1107 23:08:04.905786 19164 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1107 23:08:10.814164 19164 solver.cpp:218] Iteration 108600 (16.9244 iter/s, 5.90861s/100 iters), loss = 0.362074
I1107 23:08:10.814164 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:08:10.814164 19164 solver.cpp:237]     Train net output #1: loss = 0.362074 (* 1 = 0.362074 loss)
I1107 23:08:10.814164 19164 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1107 23:08:16.723073 19164 solver.cpp:218] Iteration 108700 (16.9265 iter/s, 5.90791s/100 iters), loss = 0.311969
I1107 23:08:16.723073 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:08:16.723073 19164 solver.cpp:237]     Train net output #1: loss = 0.311969 (* 1 = 0.311969 loss)
I1107 23:08:16.723073 19164 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1107 23:08:22.635946 19164 solver.cpp:218] Iteration 108800 (16.9137 iter/s, 5.91236s/100 iters), loss = 0.377219
I1107 23:08:22.635946 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:08:22.635946 19164 solver.cpp:237]     Train net output #1: loss = 0.377219 (* 1 = 0.377219 loss)
I1107 23:08:22.635946 19164 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1107 23:08:28.549506 19164 solver.cpp:218] Iteration 108900 (16.9097 iter/s, 5.91377s/100 iters), loss = 0.435698
I1107 23:08:28.549506 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:08:28.549506 19164 solver.cpp:237]     Train net output #1: loss = 0.435698 (* 1 = 0.435698 loss)
I1107 23:08:28.549506 19164 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1107 23:08:34.161002 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:08:34.393025 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_109000.caffemodel
I1107 23:08:34.408026 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_109000.solverstate
I1107 23:08:34.413027 19164 solver.cpp:330] Iteration 109000, Testing net (#0)
I1107 23:08:34.413027 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:08:35.703137 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:08:35.753152 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6783
I1107 23:08:35.753152 19164 solver.cpp:397]     Test net output #1: loss = 1.25163 (* 1 = 1.25163 loss)
I1107 23:08:35.810142 19164 solver.cpp:218] Iteration 109000 (13.7747 iter/s, 7.25969s/100 iters), loss = 0.354038
I1107 23:08:35.810142 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 23:08:35.810142 19164 solver.cpp:237]     Train net output #1: loss = 0.354038 (* 1 = 0.354038 loss)
I1107 23:08:35.810142 19164 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1107 23:08:41.745630 19164 solver.cpp:218] Iteration 109100 (16.8487 iter/s, 5.93519s/100 iters), loss = 0.400401
I1107 23:08:41.745630 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:08:41.745630 19164 solver.cpp:237]     Train net output #1: loss = 0.400402 (* 1 = 0.400402 loss)
I1107 23:08:41.745630 19164 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1107 23:08:47.655037 19164 solver.cpp:218] Iteration 109200 (16.9233 iter/s, 5.90901s/100 iters), loss = 0.270841
I1107 23:08:47.655037 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 23:08:47.655037 19164 solver.cpp:237]     Train net output #1: loss = 0.270841 (* 1 = 0.270841 loss)
I1107 23:08:47.655037 19164 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1107 23:08:53.561445 19164 solver.cpp:218] Iteration 109300 (16.9313 iter/s, 5.90623s/100 iters), loss = 0.35207
I1107 23:08:53.561445 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:08:53.561445 19164 solver.cpp:237]     Train net output #1: loss = 0.35207 (* 1 = 0.35207 loss)
I1107 23:08:53.561445 19164 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1107 23:08:59.471305 19164 solver.cpp:218] Iteration 109400 (16.9233 iter/s, 5.909s/100 iters), loss = 0.42304
I1107 23:08:59.471305 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 23:08:59.471305 19164 solver.cpp:237]     Train net output #1: loss = 0.42304 (* 1 = 0.42304 loss)
I1107 23:08:59.471305 19164 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1107 23:09:05.088196 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:09:05.320204 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_109500.caffemodel
I1107 23:09:05.335206 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_109500.solverstate
I1107 23:09:05.340205 19164 solver.cpp:330] Iteration 109500, Testing net (#0)
I1107 23:09:05.340205 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:09:06.629361 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:09:06.679867 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6791
I1107 23:09:06.679867 19164 solver.cpp:397]     Test net output #1: loss = 1.25158 (* 1 = 1.25158 loss)
I1107 23:09:06.736368 19164 solver.cpp:218] Iteration 109500 (13.7635 iter/s, 7.26558s/100 iters), loss = 0.326209
I1107 23:09:06.737368 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:09:06.737368 19164 solver.cpp:237]     Train net output #1: loss = 0.326209 (* 1 = 0.326209 loss)
I1107 23:09:06.737368 19164 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1107 23:09:12.640727 19164 solver.cpp:218] Iteration 109600 (16.9381 iter/s, 5.90384s/100 iters), loss = 0.423903
I1107 23:09:12.640727 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:09:12.640727 19164 solver.cpp:237]     Train net output #1: loss = 0.423903 (* 1 = 0.423903 loss)
I1107 23:09:12.640727 19164 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1107 23:09:18.548187 19164 solver.cpp:218] Iteration 109700 (16.9307 iter/s, 5.90644s/100 iters), loss = 0.287077
I1107 23:09:18.548187 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:09:18.548187 19164 solver.cpp:237]     Train net output #1: loss = 0.287077 (* 1 = 0.287077 loss)
I1107 23:09:18.548187 19164 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1107 23:09:24.462611 19164 solver.cpp:218] Iteration 109800 (16.9096 iter/s, 5.91381s/100 iters), loss = 0.42258
I1107 23:09:24.462611 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:09:24.462611 19164 solver.cpp:237]     Train net output #1: loss = 0.42258 (* 1 = 0.42258 loss)
I1107 23:09:24.462611 19164 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1107 23:09:30.370998 19164 solver.cpp:218] Iteration 109900 (16.9256 iter/s, 5.90822s/100 iters), loss = 0.410973
I1107 23:09:30.370998 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:09:30.370998 19164 solver.cpp:237]     Train net output #1: loss = 0.410973 (* 1 = 0.410973 loss)
I1107 23:09:30.370998 19164 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1107 23:09:36.010409 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:09:36.243172 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_110000.caffemodel
I1107 23:09:36.258172 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_110000.solverstate
I1107 23:09:36.263171 19164 solver.cpp:330] Iteration 110000, Testing net (#0)
I1107 23:09:36.263171 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:09:37.554280 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:09:37.604295 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6709
I1107 23:09:37.604295 19164 solver.cpp:397]     Test net output #1: loss = 1.25727 (* 1 = 1.25727 loss)
I1107 23:09:37.661306 19164 solver.cpp:218] Iteration 110000 (13.717 iter/s, 7.29023s/100 iters), loss = 0.26939
I1107 23:09:37.661306 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 23:09:37.661306 19164 solver.cpp:237]     Train net output #1: loss = 0.26939 (* 1 = 0.26939 loss)
I1107 23:09:37.661306 19164 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1107 23:09:43.559842 19164 solver.cpp:218] Iteration 110100 (16.9537 iter/s, 5.89841s/100 iters), loss = 0.480086
I1107 23:09:43.559842 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 23:09:43.559842 19164 solver.cpp:237]     Train net output #1: loss = 0.480086 (* 1 = 0.480086 loss)
I1107 23:09:43.559842 19164 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1107 23:09:49.445776 19164 solver.cpp:218] Iteration 110200 (16.9935 iter/s, 5.88462s/100 iters), loss = 0.307674
I1107 23:09:49.445776 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 23:09:49.445776 19164 solver.cpp:237]     Train net output #1: loss = 0.307674 (* 1 = 0.307674 loss)
I1107 23:09:49.445776 19164 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1107 23:09:55.340137 19164 solver.cpp:218] Iteration 110300 (16.966 iter/s, 5.89415s/100 iters), loss = 0.441573
I1107 23:09:55.340137 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:09:55.340137 19164 solver.cpp:237]     Train net output #1: loss = 0.441573 (* 1 = 0.441573 loss)
I1107 23:09:55.340137 19164 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1107 23:10:01.260881 19164 solver.cpp:218] Iteration 110400 (16.8907 iter/s, 5.92041s/100 iters), loss = 0.399228
I1107 23:10:01.260881 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:10:01.260881 19164 solver.cpp:237]     Train net output #1: loss = 0.399228 (* 1 = 0.399228 loss)
I1107 23:10:01.260881 19164 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1107 23:10:06.882331 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:10:07.113340 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_110500.caffemodel
I1107 23:10:07.128343 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_110500.solverstate
I1107 23:10:07.133344 19164 solver.cpp:330] Iteration 110500, Testing net (#0)
I1107 23:10:07.133344 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:10:08.423123 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:10:08.473631 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6754
I1107 23:10:08.473631 19164 solver.cpp:397]     Test net output #1: loss = 1.26341 (* 1 = 1.26341 loss)
I1107 23:10:08.531129 19164 solver.cpp:218] Iteration 110500 (13.7558 iter/s, 7.26965s/100 iters), loss = 0.355223
I1107 23:10:08.531630 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:10:08.531630 19164 solver.cpp:237]     Train net output #1: loss = 0.355224 (* 1 = 0.355224 loss)
I1107 23:10:08.531630 19164 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1107 23:10:14.436092 19164 solver.cpp:218] Iteration 110600 (16.9372 iter/s, 5.90415s/100 iters), loss = 0.319604
I1107 23:10:14.436092 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:10:14.436092 19164 solver.cpp:237]     Train net output #1: loss = 0.319604 (* 1 = 0.319604 loss)
I1107 23:10:14.436092 19164 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1107 23:10:20.350690 19164 solver.cpp:218] Iteration 110700 (16.9074 iter/s, 5.91456s/100 iters), loss = 0.340572
I1107 23:10:20.350690 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:10:20.350690 19164 solver.cpp:237]     Train net output #1: loss = 0.340573 (* 1 = 0.340573 loss)
I1107 23:10:20.350690 19164 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1107 23:10:26.261148 19164 solver.cpp:218] Iteration 110800 (16.9198 iter/s, 5.91022s/100 iters), loss = 0.405977
I1107 23:10:26.261148 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 23:10:26.261148 19164 solver.cpp:237]     Train net output #1: loss = 0.405978 (* 1 = 0.405978 loss)
I1107 23:10:26.261148 19164 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1107 23:10:32.170613 19164 solver.cpp:218] Iteration 110900 (16.9244 iter/s, 5.90864s/100 iters), loss = 0.476988
I1107 23:10:32.170613 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 23:10:32.170613 19164 solver.cpp:237]     Train net output #1: loss = 0.476988 (* 1 = 0.476988 loss)
I1107 23:10:32.170613 19164 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1107 23:10:37.785012 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:10:38.019027 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_111000.caffemodel
I1107 23:10:38.035037 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_111000.solverstate
I1107 23:10:38.040027 19164 solver.cpp:330] Iteration 111000, Testing net (#0)
I1107 23:10:38.040027 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:10:39.330118 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:10:39.380125 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6776
I1107 23:10:39.380125 19164 solver.cpp:397]     Test net output #1: loss = 1.25516 (* 1 = 1.25516 loss)
I1107 23:10:39.436122 19164 solver.cpp:218] Iteration 111000 (13.7634 iter/s, 7.26563s/100 iters), loss = 0.315566
I1107 23:10:39.436122 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 23:10:39.436122 19164 solver.cpp:237]     Train net output #1: loss = 0.315566 (* 1 = 0.315566 loss)
I1107 23:10:39.436122 19164 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1107 23:10:45.340495 19164 solver.cpp:218] Iteration 111100 (16.939 iter/s, 5.90352s/100 iters), loss = 0.35387
I1107 23:10:45.340495 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 23:10:45.340495 19164 solver.cpp:237]     Train net output #1: loss = 0.35387 (* 1 = 0.35387 loss)
I1107 23:10:45.340495 19164 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1107 23:10:51.250896 19164 solver.cpp:218] Iteration 111200 (16.9197 iter/s, 5.91026s/100 iters), loss = 0.304126
I1107 23:10:51.250896 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 23:10:51.250896 19164 solver.cpp:237]     Train net output #1: loss = 0.304126 (* 1 = 0.304126 loss)
I1107 23:10:51.250896 19164 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1107 23:10:57.150324 19164 solver.cpp:218] Iteration 111300 (16.9537 iter/s, 5.89841s/100 iters), loss = 0.363886
I1107 23:10:57.150324 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:10:57.150324 19164 solver.cpp:237]     Train net output #1: loss = 0.363886 (* 1 = 0.363886 loss)
I1107 23:10:57.150324 19164 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1107 23:11:03.048707 19164 solver.cpp:218] Iteration 111400 (16.9545 iter/s, 5.89812s/100 iters), loss = 0.427178
I1107 23:11:03.048707 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:11:03.048707 19164 solver.cpp:237]     Train net output #1: loss = 0.427179 (* 1 = 0.427179 loss)
I1107 23:11:03.048707 19164 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1107 23:11:08.665096 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:11:08.897119 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_111500.caffemodel
I1107 23:11:08.913120 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_111500.solverstate
I1107 23:11:08.918119 19164 solver.cpp:330] Iteration 111500, Testing net (#0)
I1107 23:11:08.918119 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:11:10.205230 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:11:10.256229 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6769
I1107 23:11:10.256229 19164 solver.cpp:397]     Test net output #1: loss = 1.26127 (* 1 = 1.26127 loss)
I1107 23:11:10.312238 19164 solver.cpp:218] Iteration 111500 (13.7675 iter/s, 7.26347s/100 iters), loss = 0.373549
I1107 23:11:10.312238 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:11:10.312238 19164 solver.cpp:237]     Train net output #1: loss = 0.373549 (* 1 = 0.373549 loss)
I1107 23:11:10.312238 19164 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1107 23:11:16.216564 19164 solver.cpp:218] Iteration 111600 (16.9395 iter/s, 5.90336s/100 iters), loss = 0.370609
I1107 23:11:16.216564 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 23:11:16.216564 19164 solver.cpp:237]     Train net output #1: loss = 0.370609 (* 1 = 0.370609 loss)
I1107 23:11:16.216564 19164 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1107 23:11:22.117918 19164 solver.cpp:218] Iteration 111700 (16.9464 iter/s, 5.90097s/100 iters), loss = 0.310176
I1107 23:11:22.117918 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:11:22.117918 19164 solver.cpp:237]     Train net output #1: loss = 0.310176 (* 1 = 0.310176 loss)
I1107 23:11:22.117918 19164 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1107 23:11:28.017300 19164 solver.cpp:218] Iteration 111800 (16.9514 iter/s, 5.89921s/100 iters), loss = 0.371691
I1107 23:11:28.017300 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:11:28.017300 19164 solver.cpp:237]     Train net output #1: loss = 0.371691 (* 1 = 0.371691 loss)
I1107 23:11:28.017300 19164 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1107 23:11:33.922659 19164 solver.cpp:218] Iteration 111900 (16.9345 iter/s, 5.90511s/100 iters), loss = 0.462165
I1107 23:11:33.922659 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 23:11:33.922659 19164 solver.cpp:237]     Train net output #1: loss = 0.462165 (* 1 = 0.462165 loss)
I1107 23:11:33.922659 19164 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1107 23:11:39.537488 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:11:39.770510 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_112000.caffemodel
I1107 23:11:39.786509 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_112000.solverstate
I1107 23:11:39.790509 19164 solver.cpp:330] Iteration 112000, Testing net (#0)
I1107 23:11:39.790509 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:11:41.080637 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:11:41.131640 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6736
I1107 23:11:41.132140 19164 solver.cpp:397]     Test net output #1: loss = 1.25947 (* 1 = 1.25947 loss)
I1107 23:11:41.187644 19164 solver.cpp:218] Iteration 112000 (13.7659 iter/s, 7.26434s/100 iters), loss = 0.33352
I1107 23:11:41.187644 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:11:41.187644 19164 solver.cpp:237]     Train net output #1: loss = 0.33352 (* 1 = 0.33352 loss)
I1107 23:11:41.187644 19164 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1107 23:11:47.109030 19164 solver.cpp:218] Iteration 112100 (16.8889 iter/s, 5.92105s/100 iters), loss = 0.334115
I1107 23:11:47.109030 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:11:47.109030 19164 solver.cpp:237]     Train net output #1: loss = 0.334115 (* 1 = 0.334115 loss)
I1107 23:11:47.109030 19164 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1107 23:11:53.022554 19164 solver.cpp:218] Iteration 112200 (16.9131 iter/s, 5.91259s/100 iters), loss = 0.30325
I1107 23:11:53.022554 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 23:11:53.022554 19164 solver.cpp:237]     Train net output #1: loss = 0.30325 (* 1 = 0.30325 loss)
I1107 23:11:53.022554 19164 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1107 23:11:59.027586 19164 solver.cpp:218] Iteration 112300 (16.6539 iter/s, 6.0046s/100 iters), loss = 0.42199
I1107 23:11:59.027586 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:11:59.027586 19164 solver.cpp:237]     Train net output #1: loss = 0.42199 (* 1 = 0.42199 loss)
I1107 23:11:59.027586 19164 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1107 23:12:04.976948 19164 solver.cpp:218] Iteration 112400 (16.8075 iter/s, 5.94971s/100 iters), loss = 0.423592
I1107 23:12:04.976948 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:12:04.976948 19164 solver.cpp:237]     Train net output #1: loss = 0.423592 (* 1 = 0.423592 loss)
I1107 23:12:04.977948 19164 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1107 23:12:10.647368 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:12:10.888372 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_112500.caffemodel
I1107 23:12:10.903373 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_112500.solverstate
I1107 23:12:10.908372 19164 solver.cpp:330] Iteration 112500, Testing net (#0)
I1107 23:12:10.908372 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:12:12.233485 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:12:12.284487 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6757
I1107 23:12:12.284487 19164 solver.cpp:397]     Test net output #1: loss = 1.26956 (* 1 = 1.26956 loss)
I1107 23:12:12.341490 19164 solver.cpp:218] Iteration 112500 (13.5803 iter/s, 7.36358s/100 iters), loss = 0.345309
I1107 23:12:12.341490 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:12:12.341490 19164 solver.cpp:237]     Train net output #1: loss = 0.345309 (* 1 = 0.345309 loss)
I1107 23:12:12.341490 19164 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1107 23:12:18.312525 19164 solver.cpp:218] Iteration 112600 (16.7487 iter/s, 5.9706s/100 iters), loss = 0.366722
I1107 23:12:18.312525 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:12:18.312525 19164 solver.cpp:237]     Train net output #1: loss = 0.366722 (* 1 = 0.366722 loss)
I1107 23:12:18.312525 19164 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1107 23:12:24.242146 19164 solver.cpp:218] Iteration 112700 (16.8675 iter/s, 5.92855s/100 iters), loss = 0.308543
I1107 23:12:24.242146 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:12:24.242146 19164 solver.cpp:237]     Train net output #1: loss = 0.308543 (* 1 = 0.308543 loss)
I1107 23:12:24.242146 19164 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1107 23:12:30.224745 19164 solver.cpp:218] Iteration 112800 (16.7152 iter/s, 5.98259s/100 iters), loss = 0.393054
I1107 23:12:30.224745 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:12:30.224745 19164 solver.cpp:237]     Train net output #1: loss = 0.393054 (* 1 = 0.393054 loss)
I1107 23:12:30.224745 19164 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1107 23:12:36.159157 19164 solver.cpp:218] Iteration 112900 (16.851 iter/s, 5.93436s/100 iters), loss = 0.43574
I1107 23:12:36.160158 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 23:12:36.160158 19164 solver.cpp:237]     Train net output #1: loss = 0.43574 (* 1 = 0.43574 loss)
I1107 23:12:36.160158 19164 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1107 23:12:41.806596 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:12:42.039609 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_113000.caffemodel
I1107 23:12:42.053612 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_113000.solverstate
I1107 23:12:42.058614 19164 solver.cpp:330] Iteration 113000, Testing net (#0)
I1107 23:12:42.058614 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:12:43.347735 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:12:43.397735 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6726
I1107 23:12:43.397735 19164 solver.cpp:397]     Test net output #1: loss = 1.26611 (* 1 = 1.26611 loss)
I1107 23:12:43.454741 19164 solver.cpp:218] Iteration 113000 (13.7087 iter/s, 7.29464s/100 iters), loss = 0.340282
I1107 23:12:43.454741 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 23:12:43.454741 19164 solver.cpp:237]     Train net output #1: loss = 0.340283 (* 1 = 0.340283 loss)
I1107 23:12:43.454741 19164 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1107 23:12:49.377182 19164 solver.cpp:218] Iteration 113100 (16.887 iter/s, 5.92172s/100 iters), loss = 0.417245
I1107 23:12:49.377182 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:12:49.377182 19164 solver.cpp:237]     Train net output #1: loss = 0.417245 (* 1 = 0.417245 loss)
I1107 23:12:49.377182 19164 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1107 23:12:55.287598 19164 solver.cpp:218] Iteration 113200 (16.9207 iter/s, 5.90991s/100 iters), loss = 0.2641
I1107 23:12:55.287598 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 23:12:55.287598 19164 solver.cpp:237]     Train net output #1: loss = 0.2641 (* 1 = 0.2641 loss)
I1107 23:12:55.287598 19164 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1107 23:13:01.216044 19164 solver.cpp:218] Iteration 113300 (16.8665 iter/s, 5.9289s/100 iters), loss = 0.472625
I1107 23:13:01.216044 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 23:13:01.216044 19164 solver.cpp:237]     Train net output #1: loss = 0.472625 (* 1 = 0.472625 loss)
I1107 23:13:01.216044 19164 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1107 23:13:07.149472 19164 solver.cpp:218] Iteration 113400 (16.8552 iter/s, 5.93288s/100 iters), loss = 0.392934
I1107 23:13:07.149472 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:13:07.149472 19164 solver.cpp:237]     Train net output #1: loss = 0.392934 (* 1 = 0.392934 loss)
I1107 23:13:07.149472 19164 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1107 23:13:12.780858 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:13:13.021878 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_113500.caffemodel
I1107 23:13:13.036878 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_113500.solverstate
I1107 23:13:13.041878 19164 solver.cpp:330] Iteration 113500, Testing net (#0)
I1107 23:13:13.041878 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:13:14.333058 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:13:14.384057 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6703
I1107 23:13:14.384057 19164 solver.cpp:397]     Test net output #1: loss = 1.27075 (* 1 = 1.27075 loss)
I1107 23:13:14.442039 19164 solver.cpp:218] Iteration 113500 (13.7148 iter/s, 7.29138s/100 iters), loss = 0.309079
I1107 23:13:14.442039 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 23:13:14.442039 19164 solver.cpp:237]     Train net output #1: loss = 0.309079 (* 1 = 0.309079 loss)
I1107 23:13:14.442039 19164 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1107 23:13:20.351824 19164 solver.cpp:218] Iteration 113600 (16.9217 iter/s, 5.90959s/100 iters), loss = 0.426966
I1107 23:13:20.351824 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:13:20.351824 19164 solver.cpp:237]     Train net output #1: loss = 0.426966 (* 1 = 0.426966 loss)
I1107 23:13:20.351824 19164 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1107 23:13:26.315239 19164 solver.cpp:218] Iteration 113700 (16.7712 iter/s, 5.9626s/100 iters), loss = 0.287285
I1107 23:13:26.315239 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:13:26.315239 19164 solver.cpp:237]     Train net output #1: loss = 0.287285 (* 1 = 0.287285 loss)
I1107 23:13:26.315239 19164 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1107 23:13:32.233647 19164 solver.cpp:218] Iteration 113800 (16.8963 iter/s, 5.91847s/100 iters), loss = 0.308373
I1107 23:13:32.233647 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:13:32.233647 19164 solver.cpp:237]     Train net output #1: loss = 0.308373 (* 1 = 0.308373 loss)
I1107 23:13:32.233647 19164 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1107 23:13:38.196173 19164 solver.cpp:218] Iteration 113900 (16.7738 iter/s, 5.96166s/100 iters), loss = 0.402603
I1107 23:13:38.196173 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:13:38.196173 19164 solver.cpp:237]     Train net output #1: loss = 0.402603 (* 1 = 0.402603 loss)
I1107 23:13:38.196173 19164 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1107 23:13:43.812500 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:13:44.043268 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_114000.caffemodel
I1107 23:13:44.058276 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_114000.solverstate
I1107 23:13:44.063277 19164 solver.cpp:330] Iteration 114000, Testing net (#0)
I1107 23:13:44.063277 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:13:45.351172 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:13:45.402173 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6738
I1107 23:13:45.402173 19164 solver.cpp:397]     Test net output #1: loss = 1.28044 (* 1 = 1.28044 loss)
I1107 23:13:45.458211 19164 solver.cpp:218] Iteration 114000 (13.7696 iter/s, 7.26235s/100 iters), loss = 0.292964
I1107 23:13:45.459216 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 23:13:45.459216 19164 solver.cpp:237]     Train net output #1: loss = 0.292964 (* 1 = 0.292964 loss)
I1107 23:13:45.459216 19164 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1107 23:13:51.370329 19164 solver.cpp:218] Iteration 114100 (16.9177 iter/s, 5.91096s/100 iters), loss = 0.30087
I1107 23:13:51.370329 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 23:13:51.370329 19164 solver.cpp:237]     Train net output #1: loss = 0.30087 (* 1 = 0.30087 loss)
I1107 23:13:51.370329 19164 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1107 23:13:57.284732 19164 solver.cpp:218] Iteration 114200 (16.9095 iter/s, 5.91385s/100 iters), loss = 0.276983
I1107 23:13:57.284732 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 23:13:57.284732 19164 solver.cpp:237]     Train net output #1: loss = 0.276983 (* 1 = 0.276983 loss)
I1107 23:13:57.284732 19164 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1107 23:14:03.191148 19164 solver.cpp:218] Iteration 114300 (16.9307 iter/s, 5.90643s/100 iters), loss = 0.349047
I1107 23:14:03.191148 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:14:03.191148 19164 solver.cpp:237]     Train net output #1: loss = 0.349047 (* 1 = 0.349047 loss)
I1107 23:14:03.191148 19164 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1107 23:14:09.099566 19164 solver.cpp:218] Iteration 114400 (16.9256 iter/s, 5.90821s/100 iters), loss = 0.354601
I1107 23:14:09.099566 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:14:09.099566 19164 solver.cpp:237]     Train net output #1: loss = 0.354601 (* 1 = 0.354601 loss)
I1107 23:14:09.099566 19164 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1107 23:14:14.756933 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:14:14.988942 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_114500.caffemodel
I1107 23:14:15.003943 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_114500.solverstate
I1107 23:14:15.008945 19164 solver.cpp:330] Iteration 114500, Testing net (#0)
I1107 23:14:15.008945 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:14:16.296085 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:14:16.347102 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6756
I1107 23:14:16.347102 19164 solver.cpp:397]     Test net output #1: loss = 1.27027 (* 1 = 1.27027 loss)
I1107 23:14:16.404103 19164 solver.cpp:218] Iteration 114500 (13.6918 iter/s, 7.30364s/100 iters), loss = 0.317536
I1107 23:14:16.404103 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 23:14:16.404103 19164 solver.cpp:237]     Train net output #1: loss = 0.317536 (* 1 = 0.317536 loss)
I1107 23:14:16.404103 19164 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1107 23:14:22.385596 19164 solver.cpp:218] Iteration 114600 (16.7184 iter/s, 5.98142s/100 iters), loss = 0.40775
I1107 23:14:22.385596 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:14:22.385596 19164 solver.cpp:237]     Train net output #1: loss = 0.407751 (* 1 = 0.407751 loss)
I1107 23:14:22.385596 19164 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1107 23:14:28.318055 19164 solver.cpp:218] Iteration 114700 (16.8595 iter/s, 5.93139s/100 iters), loss = 0.243745
I1107 23:14:28.318055 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 23:14:28.318055 19164 solver.cpp:237]     Train net output #1: loss = 0.243745 (* 1 = 0.243745 loss)
I1107 23:14:28.318055 19164 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1107 23:14:34.231472 19164 solver.cpp:218] Iteration 114800 (16.9118 iter/s, 5.91304s/100 iters), loss = 0.419708
I1107 23:14:34.231472 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:14:34.231472 19164 solver.cpp:237]     Train net output #1: loss = 0.419708 (* 1 = 0.419708 loss)
I1107 23:14:34.231472 19164 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1107 23:14:40.144837 19164 solver.cpp:218] Iteration 114900 (16.9115 iter/s, 5.91315s/100 iters), loss = 0.417477
I1107 23:14:40.144837 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 23:14:40.144837 19164 solver.cpp:237]     Train net output #1: loss = 0.417477 (* 1 = 0.417477 loss)
I1107 23:14:40.144837 19164 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1107 23:14:45.765249 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:14:45.997259 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_115000.caffemodel
I1107 23:14:46.012763 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_115000.solverstate
I1107 23:14:46.017263 19164 solver.cpp:330] Iteration 115000, Testing net (#0)
I1107 23:14:46.017263 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:14:47.306403 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:14:47.357412 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6755
I1107 23:14:47.357412 19164 solver.cpp:397]     Test net output #1: loss = 1.27242 (* 1 = 1.27242 loss)
I1107 23:14:47.413914 19164 solver.cpp:218] Iteration 115000 (13.7579 iter/s, 7.26857s/100 iters), loss = 0.287102
I1107 23:14:47.414415 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 23:14:47.414415 19164 solver.cpp:237]     Train net output #1: loss = 0.287102 (* 1 = 0.287102 loss)
I1107 23:14:47.414415 19164 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1107 23:14:53.322811 19164 solver.cpp:218] Iteration 115100 (16.9251 iter/s, 5.90837s/100 iters), loss = 0.345245
I1107 23:14:53.322811 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:14:53.322811 19164 solver.cpp:237]     Train net output #1: loss = 0.345245 (* 1 = 0.345245 loss)
I1107 23:14:53.322811 19164 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1107 23:14:59.236196 19164 solver.cpp:218] Iteration 115200 (16.9121 iter/s, 5.91294s/100 iters), loss = 0.223791
I1107 23:14:59.236196 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 23:14:59.236196 19164 solver.cpp:237]     Train net output #1: loss = 0.223791 (* 1 = 0.223791 loss)
I1107 23:14:59.236196 19164 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1107 23:15:05.146596 19164 solver.cpp:218] Iteration 115300 (16.9208 iter/s, 5.90988s/100 iters), loss = 0.361337
I1107 23:15:05.146596 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 23:15:05.146596 19164 solver.cpp:237]     Train net output #1: loss = 0.361337 (* 1 = 0.361337 loss)
I1107 23:15:05.146596 19164 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1107 23:15:11.057005 19164 solver.cpp:218] Iteration 115400 (16.9186 iter/s, 5.91064s/100 iters), loss = 0.359263
I1107 23:15:11.057005 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:15:11.057005 19164 solver.cpp:237]     Train net output #1: loss = 0.359263 (* 1 = 0.359263 loss)
I1107 23:15:11.057005 19164 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1107 23:15:16.679425 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:15:16.912436 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_115500.caffemodel
I1107 23:15:16.926437 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_115500.solverstate
I1107 23:15:16.931437 19164 solver.cpp:330] Iteration 115500, Testing net (#0)
I1107 23:15:16.931437 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:15:18.220535 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:15:18.271540 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6735
I1107 23:15:18.271540 19164 solver.cpp:397]     Test net output #1: loss = 1.28743 (* 1 = 1.28743 loss)
I1107 23:15:18.328537 19164 solver.cpp:218] Iteration 115500 (13.7547 iter/s, 7.27023s/100 iters), loss = 0.323544
I1107 23:15:18.328537 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 23:15:18.328537 19164 solver.cpp:237]     Train net output #1: loss = 0.323545 (* 1 = 0.323545 loss)
I1107 23:15:18.328537 19164 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1107 23:15:24.235896 19164 solver.cpp:218] Iteration 115600 (16.9267 iter/s, 5.90783s/100 iters), loss = 0.365196
I1107 23:15:24.236896 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:15:24.236896 19164 solver.cpp:237]     Train net output #1: loss = 0.365196 (* 1 = 0.365196 loss)
I1107 23:15:24.236896 19164 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1107 23:15:30.139314 19164 solver.cpp:218] Iteration 115700 (16.9406 iter/s, 5.90299s/100 iters), loss = 0.251622
I1107 23:15:30.140314 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 23:15:30.140314 19164 solver.cpp:237]     Train net output #1: loss = 0.251622 (* 1 = 0.251622 loss)
I1107 23:15:30.140314 19164 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1107 23:15:36.044682 19164 solver.cpp:218] Iteration 115800 (16.9354 iter/s, 5.9048s/100 iters), loss = 0.342483
I1107 23:15:36.044682 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:15:36.044682 19164 solver.cpp:237]     Train net output #1: loss = 0.342483 (* 1 = 0.342483 loss)
I1107 23:15:36.044682 19164 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1107 23:15:41.952064 19164 solver.cpp:218] Iteration 115900 (16.9295 iter/s, 5.90685s/100 iters), loss = 0.411872
I1107 23:15:41.952064 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:15:41.952064 19164 solver.cpp:237]     Train net output #1: loss = 0.411872 (* 1 = 0.411872 loss)
I1107 23:15:41.952064 19164 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1107 23:15:47.575903 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:15:47.808414 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_116000.caffemodel
I1107 23:15:47.822414 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_116000.solverstate
I1107 23:15:47.827414 19164 solver.cpp:330] Iteration 116000, Testing net (#0)
I1107 23:15:47.827414 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:15:49.116690 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:15:49.167721 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6745
I1107 23:15:49.167721 19164 solver.cpp:397]     Test net output #1: loss = 1.28724 (* 1 = 1.28724 loss)
I1107 23:15:49.224709 19164 solver.cpp:218] Iteration 116000 (13.7516 iter/s, 7.27188s/100 iters), loss = 0.395692
I1107 23:15:49.224709 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:15:49.224709 19164 solver.cpp:237]     Train net output #1: loss = 0.395692 (* 1 = 0.395692 loss)
I1107 23:15:49.224709 19164 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1107 23:15:55.125059 19164 solver.cpp:218] Iteration 116100 (16.9487 iter/s, 5.90015s/100 iters), loss = 0.38451
I1107 23:15:55.125059 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:15:55.125059 19164 solver.cpp:237]     Train net output #1: loss = 0.38451 (* 1 = 0.38451 loss)
I1107 23:15:55.125059 19164 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1107 23:16:01.025406 19164 solver.cpp:218] Iteration 116200 (16.9494 iter/s, 5.89992s/100 iters), loss = 0.318471
I1107 23:16:01.025406 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 23:16:01.025406 19164 solver.cpp:237]     Train net output #1: loss = 0.318471 (* 1 = 0.318471 loss)
I1107 23:16:01.025406 19164 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1107 23:16:06.926848 19164 solver.cpp:218] Iteration 116300 (16.9458 iter/s, 5.90115s/100 iters), loss = 0.374523
I1107 23:16:06.926848 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 23:16:06.926848 19164 solver.cpp:237]     Train net output #1: loss = 0.374523 (* 1 = 0.374523 loss)
I1107 23:16:06.926848 19164 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1107 23:16:12.821251 19164 solver.cpp:218] Iteration 116400 (16.9666 iter/s, 5.89393s/100 iters), loss = 0.384232
I1107 23:16:12.821251 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 23:16:12.821251 19164 solver.cpp:237]     Train net output #1: loss = 0.384232 (* 1 = 0.384232 loss)
I1107 23:16:12.821251 19164 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1107 23:16:18.448591 11928 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:16:18.680605 19164 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_116500.caffemodel
I1107 23:16:18.695608 19164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_116500.solverstate
I1107 23:16:18.700608 19164 solver.cpp:330] Iteration 116500, Testing net (#0)
I1107 23:16:18.700608 19164 net.cpp:676] Ignoring source layer accuracy_training
I1107 23:16:19.989763 17616 data_layer.cpp:73] Restarting data prefetching from start.
I1107 23:16:20.040771 19164 solver.cpp:397]     Test net output #0: accuracy = 0.6722
I1107 23:16:20.040771 19164 solver.cpp:397]     Test net output #1: loss = 1.29297 (* 1 = 1.29297 loss)
I1107 23:16:20.097779 19164 solver.cpp:218] Iteration 116500 (13.7438 iter/s, 7.27601s/100 iters), loss = 0.291442
I1107 23:16:20.097779 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 23:16:20.097779 19164 solver.cpp:237]     Train net output #1: loss = 0.291442 (* 1 = 0.291442 loss)
I1107 23:16:20.097779 19164 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1107 23:16:25.993122 19164 solver.cpp:218] Iteration 116600 (16.9636 iter/s, 5.89498s/100 iters), loss = 0.434584
I1107 23:16:25.993122 19164 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 23:16:25.993122 19164 solver.cpp:237]     Train net output #1: loss = 0.434584 (* 1 = 0.434584 loss)
I1107 23:16:25.993122 19164 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1107 23:16:31.902525 19164 solver.cpp:218] Iteration 116700 (16.9234 iter/s, 5.90899s/100 iters), loss = 0.224215
I1107 23:16:31.9025