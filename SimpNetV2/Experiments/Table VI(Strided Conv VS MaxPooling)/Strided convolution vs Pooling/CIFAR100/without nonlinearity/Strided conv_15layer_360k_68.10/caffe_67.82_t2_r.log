
G:\Caffe\examples\cifar100>REM go to the caffe root 

G:\Caffe\examples\cifar100>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar100/fcifar100_full_relu_solver_bn.prototxt --snapshot=examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_90000.solverstate 
I1210 20:39:19.582118  8872 caffe.cpp:219] Using GPUs 0
I1210 20:39:19.755134  8872 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1210 20:39:20.065258  8872 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 20:39:20.084244  8872 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1210 20:39:20.085247  8872 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 20:39:20.085247  8872 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 20:39:20.085247  8872 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1210 20:39:20.086243  8872 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1210 20:39:20.086243  8872 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV1_360k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "pool2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "pool4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1210 20:39:20.087244  8872 layer_factory.cpp:58] Creating layer cifar
I1210 20:39:20.093258  8872 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1210 20:39:20.093258  8872 net.cpp:84] Creating Layer cifar
I1210 20:39:20.093258  8872 net.cpp:380] cifar -> data
I1210 20:39:20.093258  8872 net.cpp:380] cifar -> label
I1210 20:39:20.094259  8872 data_layer.cpp:45] output data size: 100,3,32,32
I1210 20:39:20.099258  8872 net.cpp:122] Setting up cifar
I1210 20:39:20.099258  8872 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1210 20:39:20.100260  8872 net.cpp:129] Top shape: 100 (100)
I1210 20:39:20.100260  8872 net.cpp:137] Memory required for data: 1229200
I1210 20:39:20.100260  8872 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1210 20:39:20.100260  8872 net.cpp:84] Creating Layer label_cifar_1_split
I1210 20:39:20.100260  8872 net.cpp:406] label_cifar_1_split <- label
I1210 20:39:20.100260  8872 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1210 20:39:20.100260  8872 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1210 20:39:20.100260  8872 net.cpp:122] Setting up label_cifar_1_split
I1210 20:39:20.100260  8872 net.cpp:129] Top shape: 100 (100)
I1210 20:39:20.100260  8872 net.cpp:129] Top shape: 100 (100)
I1210 20:39:20.100260  8872 net.cpp:137] Memory required for data: 1230000
I1210 20:39:20.100260  8872 layer_factory.cpp:58] Creating layer conv1
I1210 20:39:20.100260  8872 net.cpp:84] Creating Layer conv1
I1210 20:39:20.100260  8872 net.cpp:406] conv1 <- data
I1210 20:39:20.100260  8872 net.cpp:380] conv1 -> conv1
I1210 20:39:20.101263  1444 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 20:39:20.373349  8872 net.cpp:122] Setting up conv1
I1210 20:39:20.373349  8872 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 20:39:20.373349  8872 net.cpp:137] Memory required for data: 13518000
I1210 20:39:20.373349  8872 layer_factory.cpp:58] Creating layer bn1
I1210 20:39:20.373349  8872 net.cpp:84] Creating Layer bn1
I1210 20:39:20.373349  8872 net.cpp:406] bn1 <- conv1
I1210 20:39:20.373349  8872 net.cpp:367] bn1 -> conv1 (in-place)
I1210 20:39:20.373349  8872 net.cpp:122] Setting up bn1
I1210 20:39:20.373349  8872 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 20:39:20.373349  8872 net.cpp:137] Memory required for data: 25806000
I1210 20:39:20.373349  8872 layer_factory.cpp:58] Creating layer scale1
I1210 20:39:20.373349  8872 net.cpp:84] Creating Layer scale1
I1210 20:39:20.373349  8872 net.cpp:406] scale1 <- conv1
I1210 20:39:20.373349  8872 net.cpp:367] scale1 -> conv1 (in-place)
I1210 20:39:20.373349  8872 layer_factory.cpp:58] Creating layer scale1
I1210 20:39:20.373349  8872 net.cpp:122] Setting up scale1
I1210 20:39:20.373349  8872 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 20:39:20.373349  8872 net.cpp:137] Memory required for data: 38094000
I1210 20:39:20.373349  8872 layer_factory.cpp:58] Creating layer relu1
I1210 20:39:20.373349  8872 net.cpp:84] Creating Layer relu1
I1210 20:39:20.373349  8872 net.cpp:406] relu1 <- conv1
I1210 20:39:20.373349  8872 net.cpp:367] relu1 -> conv1 (in-place)
I1210 20:39:20.373349  8872 net.cpp:122] Setting up relu1
I1210 20:39:20.373349  8872 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 20:39:20.373349  8872 net.cpp:137] Memory required for data: 50382000
I1210 20:39:20.373349  8872 layer_factory.cpp:58] Creating layer conv1_0
I1210 20:39:20.373349  8872 net.cpp:84] Creating Layer conv1_0
I1210 20:39:20.373349  8872 net.cpp:406] conv1_0 <- conv1
I1210 20:39:20.373349  8872 net.cpp:380] conv1_0 -> conv1_0
I1210 20:39:20.375349  8872 net.cpp:122] Setting up conv1_0
I1210 20:39:20.375349  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.375349  8872 net.cpp:137] Memory required for data: 66766000
I1210 20:39:20.375349  8872 layer_factory.cpp:58] Creating layer bn1_0
I1210 20:39:20.375349  8872 net.cpp:84] Creating Layer bn1_0
I1210 20:39:20.375349  8872 net.cpp:406] bn1_0 <- conv1_0
I1210 20:39:20.375349  8872 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1210 20:39:20.376348  8872 net.cpp:122] Setting up bn1_0
I1210 20:39:20.376348  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.376348  8872 net.cpp:137] Memory required for data: 83150000
I1210 20:39:20.376348  8872 layer_factory.cpp:58] Creating layer scale1_0
I1210 20:39:20.376348  8872 net.cpp:84] Creating Layer scale1_0
I1210 20:39:20.376348  8872 net.cpp:406] scale1_0 <- conv1_0
I1210 20:39:20.376348  8872 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1210 20:39:20.376348  8872 layer_factory.cpp:58] Creating layer scale1_0
I1210 20:39:20.376348  8872 net.cpp:122] Setting up scale1_0
I1210 20:39:20.376348  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.376348  8872 net.cpp:137] Memory required for data: 99534000
I1210 20:39:20.376348  8872 layer_factory.cpp:58] Creating layer relu1_0
I1210 20:39:20.376348  8872 net.cpp:84] Creating Layer relu1_0
I1210 20:39:20.376348  8872 net.cpp:406] relu1_0 <- conv1_0
I1210 20:39:20.376348  8872 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1210 20:39:20.376348  8872 net.cpp:122] Setting up relu1_0
I1210 20:39:20.376348  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.376348  8872 net.cpp:137] Memory required for data: 115918000
I1210 20:39:20.376348  8872 layer_factory.cpp:58] Creating layer conv2
I1210 20:39:20.376348  8872 net.cpp:84] Creating Layer conv2
I1210 20:39:20.376348  8872 net.cpp:406] conv2 <- conv1_0
I1210 20:39:20.376348  8872 net.cpp:380] conv2 -> conv2
I1210 20:39:20.377348  8872 net.cpp:122] Setting up conv2
I1210 20:39:20.377348  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.377348  8872 net.cpp:137] Memory required for data: 132302000
I1210 20:39:20.377348  8872 layer_factory.cpp:58] Creating layer bn2
I1210 20:39:20.377348  8872 net.cpp:84] Creating Layer bn2
I1210 20:39:20.377348  8872 net.cpp:406] bn2 <- conv2
I1210 20:39:20.377348  8872 net.cpp:367] bn2 -> conv2 (in-place)
I1210 20:39:20.377348  8872 net.cpp:122] Setting up bn2
I1210 20:39:20.377348  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.377348  8872 net.cpp:137] Memory required for data: 148686000
I1210 20:39:20.377348  8872 layer_factory.cpp:58] Creating layer scale2
I1210 20:39:20.377348  8872 net.cpp:84] Creating Layer scale2
I1210 20:39:20.377348  8872 net.cpp:406] scale2 <- conv2
I1210 20:39:20.377348  8872 net.cpp:367] scale2 -> conv2 (in-place)
I1210 20:39:20.377348  8872 layer_factory.cpp:58] Creating layer scale2
I1210 20:39:20.378345  8872 net.cpp:122] Setting up scale2
I1210 20:39:20.378345  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.378345  8872 net.cpp:137] Memory required for data: 165070000
I1210 20:39:20.378345  8872 layer_factory.cpp:58] Creating layer relu2
I1210 20:39:20.378345  8872 net.cpp:84] Creating Layer relu2
I1210 20:39:20.378345  8872 net.cpp:406] relu2 <- conv2
I1210 20:39:20.378345  8872 net.cpp:367] relu2 -> conv2 (in-place)
I1210 20:39:20.378345  8872 net.cpp:122] Setting up relu2
I1210 20:39:20.378345  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.378345  8872 net.cpp:137] Memory required for data: 181454000
I1210 20:39:20.378345  8872 layer_factory.cpp:58] Creating layer conv2_1
I1210 20:39:20.378345  8872 net.cpp:84] Creating Layer conv2_1
I1210 20:39:20.378345  8872 net.cpp:406] conv2_1 <- conv2
I1210 20:39:20.378345  8872 net.cpp:380] conv2_1 -> conv2_1
I1210 20:39:20.379333  8872 net.cpp:122] Setting up conv2_1
I1210 20:39:20.379333  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.379333  8872 net.cpp:137] Memory required for data: 197838000
I1210 20:39:20.379333  8872 layer_factory.cpp:58] Creating layer bn2_1
I1210 20:39:20.379333  8872 net.cpp:84] Creating Layer bn2_1
I1210 20:39:20.379333  8872 net.cpp:406] bn2_1 <- conv2_1
I1210 20:39:20.379333  8872 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1210 20:39:20.379333  8872 net.cpp:122] Setting up bn2_1
I1210 20:39:20.379333  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.379333  8872 net.cpp:137] Memory required for data: 214222000
I1210 20:39:20.379333  8872 layer_factory.cpp:58] Creating layer scale2_1
I1210 20:39:20.379333  8872 net.cpp:84] Creating Layer scale2_1
I1210 20:39:20.379333  8872 net.cpp:406] scale2_1 <- conv2_1
I1210 20:39:20.379333  8872 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1210 20:39:20.380344  8872 layer_factory.cpp:58] Creating layer scale2_1
I1210 20:39:20.380344  8872 net.cpp:122] Setting up scale2_1
I1210 20:39:20.380344  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.380344  8872 net.cpp:137] Memory required for data: 230606000
I1210 20:39:20.380344  8872 layer_factory.cpp:58] Creating layer relu2_1
I1210 20:39:20.380344  8872 net.cpp:84] Creating Layer relu2_1
I1210 20:39:20.380344  8872 net.cpp:406] relu2_1 <- conv2_1
I1210 20:39:20.380344  8872 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1210 20:39:20.380344  8872 net.cpp:122] Setting up relu2_1
I1210 20:39:20.380344  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.380344  8872 net.cpp:137] Memory required for data: 246990000
I1210 20:39:20.380344  8872 layer_factory.cpp:58] Creating layer conv2_2
I1210 20:39:20.380344  8872 net.cpp:84] Creating Layer conv2_2
I1210 20:39:20.380344  8872 net.cpp:406] conv2_2 <- conv2_1
I1210 20:39:20.380344  8872 net.cpp:380] conv2_2 -> conv2_2
I1210 20:39:20.382339  8872 net.cpp:122] Setting up conv2_2
I1210 20:39:20.382339  8872 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 20:39:20.382339  8872 net.cpp:137] Memory required for data: 267470000
I1210 20:39:20.382339  8872 layer_factory.cpp:58] Creating layer bn2_2
I1210 20:39:20.382339  8872 net.cpp:84] Creating Layer bn2_2
I1210 20:39:20.382339  8872 net.cpp:406] bn2_2 <- conv2_2
I1210 20:39:20.382339  8872 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1210 20:39:20.382339  8872 net.cpp:122] Setting up bn2_2
I1210 20:39:20.382339  8872 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 20:39:20.382339  8872 net.cpp:137] Memory required for data: 287950000
I1210 20:39:20.382339  8872 layer_factory.cpp:58] Creating layer scale2_2
I1210 20:39:20.382339  8872 net.cpp:84] Creating Layer scale2_2
I1210 20:39:20.382339  8872 net.cpp:406] scale2_2 <- conv2_2
I1210 20:39:20.382339  8872 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1210 20:39:20.382339  8872 layer_factory.cpp:58] Creating layer scale2_2
I1210 20:39:20.382339  8872 net.cpp:122] Setting up scale2_2
I1210 20:39:20.382339  8872 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 20:39:20.383348  8872 net.cpp:137] Memory required for data: 308430000
I1210 20:39:20.383348  8872 layer_factory.cpp:58] Creating layer relu2_2
I1210 20:39:20.383348  8872 net.cpp:84] Creating Layer relu2_2
I1210 20:39:20.383348  8872 net.cpp:406] relu2_2 <- conv2_2
I1210 20:39:20.383348  8872 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1210 20:39:20.383348  8872 net.cpp:122] Setting up relu2_2
I1210 20:39:20.383348  8872 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 20:39:20.383348  8872 net.cpp:137] Memory required for data: 328910000
I1210 20:39:20.383348  8872 layer_factory.cpp:58] Creating layer pool2_1
I1210 20:39:20.383348  8872 net.cpp:84] Creating Layer pool2_1
I1210 20:39:20.383348  8872 net.cpp:406] pool2_1 <- conv2_2
I1210 20:39:20.383348  8872 net.cpp:380] pool2_1 -> pool2_1
I1210 20:39:20.384344  8872 net.cpp:122] Setting up pool2_1
I1210 20:39:20.384344  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.384344  8872 net.cpp:137] Memory required for data: 334030000
I1210 20:39:20.384344  8872 layer_factory.cpp:58] Creating layer conv3
I1210 20:39:20.384344  8872 net.cpp:84] Creating Layer conv3
I1210 20:39:20.384344  8872 net.cpp:406] conv3 <- pool2_1
I1210 20:39:20.384344  8872 net.cpp:380] conv3 -> conv3
I1210 20:39:20.386344  8872 net.cpp:122] Setting up conv3
I1210 20:39:20.386344  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.386344  8872 net.cpp:137] Memory required for data: 339150000
I1210 20:39:20.386344  8872 layer_factory.cpp:58] Creating layer bn3
I1210 20:39:20.386344  8872 net.cpp:84] Creating Layer bn3
I1210 20:39:20.386344  8872 net.cpp:406] bn3 <- conv3
I1210 20:39:20.386344  8872 net.cpp:367] bn3 -> conv3 (in-place)
I1210 20:39:20.386344  8872 net.cpp:122] Setting up bn3
I1210 20:39:20.386344  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.386344  8872 net.cpp:137] Memory required for data: 344270000
I1210 20:39:20.386344  8872 layer_factory.cpp:58] Creating layer scale3
I1210 20:39:20.386344  8872 net.cpp:84] Creating Layer scale3
I1210 20:39:20.386344  8872 net.cpp:406] scale3 <- conv3
I1210 20:39:20.386344  8872 net.cpp:367] scale3 -> conv3 (in-place)
I1210 20:39:20.386344  8872 layer_factory.cpp:58] Creating layer scale3
I1210 20:39:20.386344  8872 net.cpp:122] Setting up scale3
I1210 20:39:20.386344  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.386344  8872 net.cpp:137] Memory required for data: 349390000
I1210 20:39:20.386344  8872 layer_factory.cpp:58] Creating layer relu3
I1210 20:39:20.386344  8872 net.cpp:84] Creating Layer relu3
I1210 20:39:20.386344  8872 net.cpp:406] relu3 <- conv3
I1210 20:39:20.386344  8872 net.cpp:367] relu3 -> conv3 (in-place)
I1210 20:39:20.387346  8872 net.cpp:122] Setting up relu3
I1210 20:39:20.387346  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.387346  8872 net.cpp:137] Memory required for data: 354510000
I1210 20:39:20.387346  8872 layer_factory.cpp:58] Creating layer conv3_1
I1210 20:39:20.387346  8872 net.cpp:84] Creating Layer conv3_1
I1210 20:39:20.387346  8872 net.cpp:406] conv3_1 <- conv3
I1210 20:39:20.387346  8872 net.cpp:380] conv3_1 -> conv3_1
I1210 20:39:20.388345  8872 net.cpp:122] Setting up conv3_1
I1210 20:39:20.388345  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.388345  8872 net.cpp:137] Memory required for data: 359630000
I1210 20:39:20.388345  8872 layer_factory.cpp:58] Creating layer bn3_1
I1210 20:39:20.388345  8872 net.cpp:84] Creating Layer bn3_1
I1210 20:39:20.388345  8872 net.cpp:406] bn3_1 <- conv3_1
I1210 20:39:20.388345  8872 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1210 20:39:20.388345  8872 net.cpp:122] Setting up bn3_1
I1210 20:39:20.388345  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.388345  8872 net.cpp:137] Memory required for data: 364750000
I1210 20:39:20.388345  8872 layer_factory.cpp:58] Creating layer scale3_1
I1210 20:39:20.388345  8872 net.cpp:84] Creating Layer scale3_1
I1210 20:39:20.388345  8872 net.cpp:406] scale3_1 <- conv3_1
I1210 20:39:20.388345  8872 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1210 20:39:20.388345  8872 layer_factory.cpp:58] Creating layer scale3_1
I1210 20:39:20.389343  8872 net.cpp:122] Setting up scale3_1
I1210 20:39:20.389343  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.389343  8872 net.cpp:137] Memory required for data: 369870000
I1210 20:39:20.389343  8872 layer_factory.cpp:58] Creating layer relu3_1
I1210 20:39:20.389343  8872 net.cpp:84] Creating Layer relu3_1
I1210 20:39:20.389343  8872 net.cpp:406] relu3_1 <- conv3_1
I1210 20:39:20.389343  8872 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1210 20:39:20.389343  8872 net.cpp:122] Setting up relu3_1
I1210 20:39:20.389343  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.389343  8872 net.cpp:137] Memory required for data: 374990000
I1210 20:39:20.389343  8872 layer_factory.cpp:58] Creating layer conv4
I1210 20:39:20.389343  8872 net.cpp:84] Creating Layer conv4
I1210 20:39:20.389343  8872 net.cpp:406] conv4 <- conv3_1
I1210 20:39:20.389343  8872 net.cpp:380] conv4 -> conv4
I1210 20:39:20.390358  8872 net.cpp:122] Setting up conv4
I1210 20:39:20.390358  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.390358  8872 net.cpp:137] Memory required for data: 380110000
I1210 20:39:20.390358  8872 layer_factory.cpp:58] Creating layer bn4
I1210 20:39:20.390358  8872 net.cpp:84] Creating Layer bn4
I1210 20:39:20.390358  8872 net.cpp:406] bn4 <- conv4
I1210 20:39:20.390358  8872 net.cpp:367] bn4 -> conv4 (in-place)
I1210 20:39:20.390358  8872 net.cpp:122] Setting up bn4
I1210 20:39:20.390358  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.390358  8872 net.cpp:137] Memory required for data: 385230000
I1210 20:39:20.390358  8872 layer_factory.cpp:58] Creating layer scale4
I1210 20:39:20.390358  8872 net.cpp:84] Creating Layer scale4
I1210 20:39:20.390358  8872 net.cpp:406] scale4 <- conv4
I1210 20:39:20.390358  8872 net.cpp:367] scale4 -> conv4 (in-place)
I1210 20:39:20.390358  8872 layer_factory.cpp:58] Creating layer scale4
I1210 20:39:20.391345  8872 net.cpp:122] Setting up scale4
I1210 20:39:20.391345  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.391345  8872 net.cpp:137] Memory required for data: 390350000
I1210 20:39:20.391345  8872 layer_factory.cpp:58] Creating layer relu4
I1210 20:39:20.391345  8872 net.cpp:84] Creating Layer relu4
I1210 20:39:20.391345  8872 net.cpp:406] relu4 <- conv4
I1210 20:39:20.391345  8872 net.cpp:367] relu4 -> conv4 (in-place)
I1210 20:39:20.391345  8872 net.cpp:122] Setting up relu4
I1210 20:39:20.391345  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.391345  8872 net.cpp:137] Memory required for data: 395470000
I1210 20:39:20.391345  8872 layer_factory.cpp:58] Creating layer conv4_1
I1210 20:39:20.391345  8872 net.cpp:84] Creating Layer conv4_1
I1210 20:39:20.391345  8872 net.cpp:406] conv4_1 <- conv4
I1210 20:39:20.391345  8872 net.cpp:380] conv4_1 -> conv4_1
I1210 20:39:20.392355  8872 net.cpp:122] Setting up conv4_1
I1210 20:39:20.392355  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.392355  8872 net.cpp:137] Memory required for data: 400590000
I1210 20:39:20.392355  8872 layer_factory.cpp:58] Creating layer bn4_1
I1210 20:39:20.392355  8872 net.cpp:84] Creating Layer bn4_1
I1210 20:39:20.392355  8872 net.cpp:406] bn4_1 <- conv4_1
I1210 20:39:20.392355  8872 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1210 20:39:20.392355  8872 net.cpp:122] Setting up bn4_1
I1210 20:39:20.392355  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.392355  8872 net.cpp:137] Memory required for data: 405710000
I1210 20:39:20.392355  8872 layer_factory.cpp:58] Creating layer scale4_1
I1210 20:39:20.392355  8872 net.cpp:84] Creating Layer scale4_1
I1210 20:39:20.392355  8872 net.cpp:406] scale4_1 <- conv4_1
I1210 20:39:20.392355  8872 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1210 20:39:20.392355  8872 layer_factory.cpp:58] Creating layer scale4_1
I1210 20:39:20.392355  8872 net.cpp:122] Setting up scale4_1
I1210 20:39:20.392355  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.392355  8872 net.cpp:137] Memory required for data: 410830000
I1210 20:39:20.392355  8872 layer_factory.cpp:58] Creating layer relu4_1
I1210 20:39:20.393344  8872 net.cpp:84] Creating Layer relu4_1
I1210 20:39:20.393344  8872 net.cpp:406] relu4_1 <- conv4_1
I1210 20:39:20.393344  8872 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1210 20:39:20.393344  8872 net.cpp:122] Setting up relu4_1
I1210 20:39:20.393344  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.393344  8872 net.cpp:137] Memory required for data: 415950000
I1210 20:39:20.393344  8872 layer_factory.cpp:58] Creating layer conv4_2
I1210 20:39:20.393344  8872 net.cpp:84] Creating Layer conv4_2
I1210 20:39:20.393344  8872 net.cpp:406] conv4_2 <- conv4_1
I1210 20:39:20.393344  8872 net.cpp:380] conv4_2 -> conv4_2
I1210 20:39:20.394340  8872 net.cpp:122] Setting up conv4_2
I1210 20:39:20.394340  8872 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 20:39:20.394340  8872 net.cpp:137] Memory required for data: 421889200
I1210 20:39:20.394340  8872 layer_factory.cpp:58] Creating layer bn4_2
I1210 20:39:20.394340  8872 net.cpp:84] Creating Layer bn4_2
I1210 20:39:20.394340  8872 net.cpp:406] bn4_2 <- conv4_2
I1210 20:39:20.394340  8872 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1210 20:39:20.394340  8872 net.cpp:122] Setting up bn4_2
I1210 20:39:20.394340  8872 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 20:39:20.394340  8872 net.cpp:137] Memory required for data: 427828400
I1210 20:39:20.394340  8872 layer_factory.cpp:58] Creating layer scale4_2
I1210 20:39:20.394340  8872 net.cpp:84] Creating Layer scale4_2
I1210 20:39:20.395344  8872 net.cpp:406] scale4_2 <- conv4_2
I1210 20:39:20.395344  8872 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1210 20:39:20.395344  8872 layer_factory.cpp:58] Creating layer scale4_2
I1210 20:39:20.395344  8872 net.cpp:122] Setting up scale4_2
I1210 20:39:20.395344  8872 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 20:39:20.395344  8872 net.cpp:137] Memory required for data: 433767600
I1210 20:39:20.395344  8872 layer_factory.cpp:58] Creating layer relu4_2
I1210 20:39:20.395344  8872 net.cpp:84] Creating Layer relu4_2
I1210 20:39:20.395344  8872 net.cpp:406] relu4_2 <- conv4_2
I1210 20:39:20.395344  8872 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1210 20:39:20.395344  8872 net.cpp:122] Setting up relu4_2
I1210 20:39:20.395344  8872 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 20:39:20.395344  8872 net.cpp:137] Memory required for data: 439706800
I1210 20:39:20.395344  8872 layer_factory.cpp:58] Creating layer pool4_2
I1210 20:39:20.395344  8872 net.cpp:84] Creating Layer pool4_2
I1210 20:39:20.395344  8872 net.cpp:406] pool4_2 <- conv4_2
I1210 20:39:20.395344  8872 net.cpp:380] pool4_2 -> pool4_2
I1210 20:39:20.396348  8872 net.cpp:122] Setting up pool4_2
I1210 20:39:20.396348  8872 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 20:39:20.396348  8872 net.cpp:137] Memory required for data: 441191600
I1210 20:39:20.396348  8872 layer_factory.cpp:58] Creating layer conv4_0
I1210 20:39:20.396348  8872 net.cpp:84] Creating Layer conv4_0
I1210 20:39:20.396348  8872 net.cpp:406] conv4_0 <- pool4_2
I1210 20:39:20.396348  8872 net.cpp:380] conv4_0 -> conv4_0
I1210 20:39:20.398344  8872 net.cpp:122] Setting up conv4_0
I1210 20:39:20.398344  8872 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 20:39:20.398344  8872 net.cpp:137] Memory required for data: 442676400
I1210 20:39:20.398344  8872 layer_factory.cpp:58] Creating layer bn4_0
I1210 20:39:20.398344  8872 net.cpp:84] Creating Layer bn4_0
I1210 20:39:20.398344  8872 net.cpp:406] bn4_0 <- conv4_0
I1210 20:39:20.398344  8872 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1210 20:39:20.398344  8872 net.cpp:122] Setting up bn4_0
I1210 20:39:20.398344  8872 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 20:39:20.398344  8872 net.cpp:137] Memory required for data: 444161200
I1210 20:39:20.398344  8872 layer_factory.cpp:58] Creating layer scale4_0
I1210 20:39:20.398344  8872 net.cpp:84] Creating Layer scale4_0
I1210 20:39:20.398344  8872 net.cpp:406] scale4_0 <- conv4_0
I1210 20:39:20.398344  8872 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1210 20:39:20.398344  8872 layer_factory.cpp:58] Creating layer scale4_0
I1210 20:39:20.398344  8872 net.cpp:122] Setting up scale4_0
I1210 20:39:20.398344  8872 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 20:39:20.398344  8872 net.cpp:137] Memory required for data: 445646000
I1210 20:39:20.398344  8872 layer_factory.cpp:58] Creating layer relu4_0
I1210 20:39:20.398344  8872 net.cpp:84] Creating Layer relu4_0
I1210 20:39:20.398344  8872 net.cpp:406] relu4_0 <- conv4_0
I1210 20:39:20.398344  8872 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1210 20:39:20.398344  8872 net.cpp:122] Setting up relu4_0
I1210 20:39:20.398344  8872 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 20:39:20.398344  8872 net.cpp:137] Memory required for data: 447130800
I1210 20:39:20.398344  8872 layer_factory.cpp:58] Creating layer conv11
I1210 20:39:20.398344  8872 net.cpp:84] Creating Layer conv11
I1210 20:39:20.398344  8872 net.cpp:406] conv11 <- conv4_0
I1210 20:39:20.398344  8872 net.cpp:380] conv11 -> conv11
I1210 20:39:20.400344  8872 net.cpp:122] Setting up conv11
I1210 20:39:20.400344  8872 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 20:39:20.400344  8872 net.cpp:137] Memory required for data: 448922800
I1210 20:39:20.400344  8872 layer_factory.cpp:58] Creating layer bn_conv11
I1210 20:39:20.400344  8872 net.cpp:84] Creating Layer bn_conv11
I1210 20:39:20.400344  8872 net.cpp:406] bn_conv11 <- conv11
I1210 20:39:20.400344  8872 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1210 20:39:20.400344  8872 net.cpp:122] Setting up bn_conv11
I1210 20:39:20.400344  8872 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 20:39:20.400344  8872 net.cpp:137] Memory required for data: 450714800
I1210 20:39:20.401338  8872 layer_factory.cpp:58] Creating layer scale_conv11
I1210 20:39:20.401338  8872 net.cpp:84] Creating Layer scale_conv11
I1210 20:39:20.401338  8872 net.cpp:406] scale_conv11 <- conv11
I1210 20:39:20.401338  8872 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1210 20:39:20.401338  8872 layer_factory.cpp:58] Creating layer scale_conv11
I1210 20:39:20.401338  8872 net.cpp:122] Setting up scale_conv11
I1210 20:39:20.401338  8872 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 20:39:20.401338  8872 net.cpp:137] Memory required for data: 452506800
I1210 20:39:20.401338  8872 layer_factory.cpp:58] Creating layer relu_conv11
I1210 20:39:20.401338  8872 net.cpp:84] Creating Layer relu_conv11
I1210 20:39:20.401338  8872 net.cpp:406] relu_conv11 <- conv11
I1210 20:39:20.401338  8872 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1210 20:39:20.401338  8872 net.cpp:122] Setting up relu_conv11
I1210 20:39:20.401338  8872 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 20:39:20.401338  8872 net.cpp:137] Memory required for data: 454298800
I1210 20:39:20.401338  8872 layer_factory.cpp:58] Creating layer conv12
I1210 20:39:20.401338  8872 net.cpp:84] Creating Layer conv12
I1210 20:39:20.401338  8872 net.cpp:406] conv12 <- conv11
I1210 20:39:20.401338  8872 net.cpp:380] conv12 -> conv12
I1210 20:39:20.403344  8872 net.cpp:122] Setting up conv12
I1210 20:39:20.403344  8872 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 20:39:20.403344  8872 net.cpp:137] Memory required for data: 456602800
I1210 20:39:20.403344  8872 layer_factory.cpp:58] Creating layer bn_conv12
I1210 20:39:20.403344  8872 net.cpp:84] Creating Layer bn_conv12
I1210 20:39:20.403344  8872 net.cpp:406] bn_conv12 <- conv12
I1210 20:39:20.403344  8872 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1210 20:39:20.403344  8872 net.cpp:122] Setting up bn_conv12
I1210 20:39:20.403344  8872 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 20:39:20.403344  8872 net.cpp:137] Memory required for data: 458906800
I1210 20:39:20.403344  8872 layer_factory.cpp:58] Creating layer scale_conv12
I1210 20:39:20.403344  8872 net.cpp:84] Creating Layer scale_conv12
I1210 20:39:20.403344  8872 net.cpp:406] scale_conv12 <- conv12
I1210 20:39:20.403344  8872 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1210 20:39:20.403344  8872 layer_factory.cpp:58] Creating layer scale_conv12
I1210 20:39:20.403344  8872 net.cpp:122] Setting up scale_conv12
I1210 20:39:20.403344  8872 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 20:39:20.403344  8872 net.cpp:137] Memory required for data: 461210800
I1210 20:39:20.403344  8872 layer_factory.cpp:58] Creating layer relu_conv12
I1210 20:39:20.403344  8872 net.cpp:84] Creating Layer relu_conv12
I1210 20:39:20.403344  8872 net.cpp:406] relu_conv12 <- conv12
I1210 20:39:20.403344  8872 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1210 20:39:20.404345  8872 net.cpp:122] Setting up relu_conv12
I1210 20:39:20.404345  8872 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 20:39:20.404345  8872 net.cpp:137] Memory required for data: 463514800
I1210 20:39:20.404345  8872 layer_factory.cpp:58] Creating layer poolcp6
I1210 20:39:20.404345  8872 net.cpp:84] Creating Layer poolcp6
I1210 20:39:20.404345  8872 net.cpp:406] poolcp6 <- conv12
I1210 20:39:20.404345  8872 net.cpp:380] poolcp6 -> poolcp6
I1210 20:39:20.404345  8872 net.cpp:122] Setting up poolcp6
I1210 20:39:20.404345  8872 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1210 20:39:20.404345  8872 net.cpp:137] Memory required for data: 463550800
I1210 20:39:20.404345  8872 layer_factory.cpp:58] Creating layer ip1
I1210 20:39:20.404345  8872 net.cpp:84] Creating Layer ip1
I1210 20:39:20.404345  8872 net.cpp:406] ip1 <- poolcp6
I1210 20:39:20.404345  8872 net.cpp:380] ip1 -> ip1
I1210 20:39:20.404345  8872 net.cpp:122] Setting up ip1
I1210 20:39:20.404345  8872 net.cpp:129] Top shape: 100 100 (10000)
I1210 20:39:20.404345  8872 net.cpp:137] Memory required for data: 463590800
I1210 20:39:20.404345  8872 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1210 20:39:20.404345  8872 net.cpp:84] Creating Layer ip1_ip1_0_split
I1210 20:39:20.404345  8872 net.cpp:406] ip1_ip1_0_split <- ip1
I1210 20:39:20.404345  8872 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1210 20:39:20.404345  8872 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1210 20:39:20.404345  8872 net.cpp:122] Setting up ip1_ip1_0_split
I1210 20:39:20.404345  8872 net.cpp:129] Top shape: 100 100 (10000)
I1210 20:39:20.404345  8872 net.cpp:129] Top shape: 100 100 (10000)
I1210 20:39:20.404345  8872 net.cpp:137] Memory required for data: 463670800
I1210 20:39:20.404345  8872 layer_factory.cpp:58] Creating layer accuracy_training
I1210 20:39:20.404345  8872 net.cpp:84] Creating Layer accuracy_training
I1210 20:39:20.404345  8872 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1210 20:39:20.404345  8872 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1210 20:39:20.404345  8872 net.cpp:380] accuracy_training -> accuracy_training
I1210 20:39:20.404345  8872 net.cpp:122] Setting up accuracy_training
I1210 20:39:20.404345  8872 net.cpp:129] Top shape: (1)
I1210 20:39:20.404345  8872 net.cpp:137] Memory required for data: 463670804
I1210 20:39:20.404345  8872 layer_factory.cpp:58] Creating layer loss
I1210 20:39:20.404345  8872 net.cpp:84] Creating Layer loss
I1210 20:39:20.404345  8872 net.cpp:406] loss <- ip1_ip1_0_split_1
I1210 20:39:20.404345  8872 net.cpp:406] loss <- label_cifar_1_split_1
I1210 20:39:20.404345  8872 net.cpp:380] loss -> loss
I1210 20:39:20.405344  8872 layer_factory.cpp:58] Creating layer loss
I1210 20:39:20.405344  8872 net.cpp:122] Setting up loss
I1210 20:39:20.405344  8872 net.cpp:129] Top shape: (1)
I1210 20:39:20.405344  8872 net.cpp:132]     with loss weight 1
I1210 20:39:20.405344  8872 net.cpp:137] Memory required for data: 463670808
I1210 20:39:20.405344  8872 net.cpp:198] loss needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:200] accuracy_training does not need backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] ip1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] poolcp6 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu_conv12 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale_conv12 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn_conv12 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv12 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu_conv11 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale_conv11 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn_conv11 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv11 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu4_0 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale4_0 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn4_0 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv4_0 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] pool4_2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu4_2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale4_2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn4_2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv4_2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu4_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale4_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn4_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv4_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu4 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale4 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn4 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv4 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu3_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale3_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn3_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv3_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu3 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale3 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn3 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv3 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] pool2_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu2_2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale2_2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn2_2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv2_2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu2_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale2_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn2_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv2_1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv2 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu1_0 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale1_0 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn1_0 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv1_0 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] relu1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] scale1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] bn1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:198] conv1 needs backward computation.
I1210 20:39:20.405344  8872 net.cpp:200] label_cifar_1_split does not need backward computation.
I1210 20:39:20.405344  8872 net.cpp:200] cifar does not need backward computation.
I1210 20:39:20.405344  8872 net.cpp:242] This network produces output accuracy_training
I1210 20:39:20.405344  8872 net.cpp:242] This network produces output loss
I1210 20:39:20.405344  8872 net.cpp:255] Network initialization done.
I1210 20:39:20.406340  8872 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 20:39:20.406340  8872 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 20:39:20.406340  8872 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1210 20:39:20.406340  8872 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1210 20:39:20.407344  8872 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV1_360k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "pool2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "pool4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1210 20:39:20.407344  8872 layer_factory.cpp:58] Creating layer cifar
I1210 20:39:20.410346  8872 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1210 20:39:20.410346  8872 net.cpp:84] Creating Layer cifar
I1210 20:39:20.410346  8872 net.cpp:380] cifar -> data
I1210 20:39:20.410346  8872 net.cpp:380] cifar -> label
I1210 20:39:20.410346  8872 data_layer.cpp:45] output data size: 100,3,32,32
I1210 20:39:20.420348  8872 net.cpp:122] Setting up cifar
I1210 20:39:20.420348  8872 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1210 20:39:20.420348  8872 net.cpp:129] Top shape: 100 (100)
I1210 20:39:20.420348  8872 net.cpp:137] Memory required for data: 1229200
I1210 20:39:20.420348  8872 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1210 20:39:20.420348  8872 net.cpp:84] Creating Layer label_cifar_1_split
I1210 20:39:20.420348  8872 net.cpp:406] label_cifar_1_split <- label
I1210 20:39:20.420348  8872 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1210 20:39:20.420348  8872 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1210 20:39:20.420348  8872 net.cpp:122] Setting up label_cifar_1_split
I1210 20:39:20.420348  8872 net.cpp:129] Top shape: 100 (100)
I1210 20:39:20.420348  8872 net.cpp:129] Top shape: 100 (100)
I1210 20:39:20.420348  8872 net.cpp:137] Memory required for data: 1230000
I1210 20:39:20.420348  8872 layer_factory.cpp:58] Creating layer conv1
I1210 20:39:20.420348  8872 net.cpp:84] Creating Layer conv1
I1210 20:39:20.420348  8872 net.cpp:406] conv1 <- data
I1210 20:39:20.420348  8872 net.cpp:380] conv1 -> conv1
I1210 20:39:20.421329 20088 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 20:39:20.422835  8872 net.cpp:122] Setting up conv1
I1210 20:39:20.422835  8872 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 20:39:20.422835  8872 net.cpp:137] Memory required for data: 13518000
I1210 20:39:20.422835  8872 layer_factory.cpp:58] Creating layer bn1
I1210 20:39:20.422835  8872 net.cpp:84] Creating Layer bn1
I1210 20:39:20.422835  8872 net.cpp:406] bn1 <- conv1
I1210 20:39:20.422835  8872 net.cpp:367] bn1 -> conv1 (in-place)
I1210 20:39:20.422835  8872 net.cpp:122] Setting up bn1
I1210 20:39:20.422835  8872 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 20:39:20.422835  8872 net.cpp:137] Memory required for data: 25806000
I1210 20:39:20.422835  8872 layer_factory.cpp:58] Creating layer scale1
I1210 20:39:20.422835  8872 net.cpp:84] Creating Layer scale1
I1210 20:39:20.422835  8872 net.cpp:406] scale1 <- conv1
I1210 20:39:20.422835  8872 net.cpp:367] scale1 -> conv1 (in-place)
I1210 20:39:20.423334  8872 layer_factory.cpp:58] Creating layer scale1
I1210 20:39:20.423334  8872 net.cpp:122] Setting up scale1
I1210 20:39:20.423334  8872 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 20:39:20.423334  8872 net.cpp:137] Memory required for data: 38094000
I1210 20:39:20.423334  8872 layer_factory.cpp:58] Creating layer relu1
I1210 20:39:20.423334  8872 net.cpp:84] Creating Layer relu1
I1210 20:39:20.423334  8872 net.cpp:406] relu1 <- conv1
I1210 20:39:20.423334  8872 net.cpp:367] relu1 -> conv1 (in-place)
I1210 20:39:20.423334  8872 net.cpp:122] Setting up relu1
I1210 20:39:20.423334  8872 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 20:39:20.423334  8872 net.cpp:137] Memory required for data: 50382000
I1210 20:39:20.423334  8872 layer_factory.cpp:58] Creating layer conv1_0
I1210 20:39:20.423334  8872 net.cpp:84] Creating Layer conv1_0
I1210 20:39:20.423334  8872 net.cpp:406] conv1_0 <- conv1
I1210 20:39:20.423844  8872 net.cpp:380] conv1_0 -> conv1_0
I1210 20:39:20.424834  8872 net.cpp:122] Setting up conv1_0
I1210 20:39:20.424834  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.424834  8872 net.cpp:137] Memory required for data: 66766000
I1210 20:39:20.424834  8872 layer_factory.cpp:58] Creating layer bn1_0
I1210 20:39:20.425334  8872 net.cpp:84] Creating Layer bn1_0
I1210 20:39:20.425334  8872 net.cpp:406] bn1_0 <- conv1_0
I1210 20:39:20.425334  8872 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1210 20:39:20.425334  8872 net.cpp:122] Setting up bn1_0
I1210 20:39:20.425334  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.425334  8872 net.cpp:137] Memory required for data: 83150000
I1210 20:39:20.425334  8872 layer_factory.cpp:58] Creating layer scale1_0
I1210 20:39:20.425334  8872 net.cpp:84] Creating Layer scale1_0
I1210 20:39:20.425334  8872 net.cpp:406] scale1_0 <- conv1_0
I1210 20:39:20.425334  8872 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1210 20:39:20.425834  8872 layer_factory.cpp:58] Creating layer scale1_0
I1210 20:39:20.425834  8872 net.cpp:122] Setting up scale1_0
I1210 20:39:20.425834  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.425834  8872 net.cpp:137] Memory required for data: 99534000
I1210 20:39:20.425834  8872 layer_factory.cpp:58] Creating layer relu1_0
I1210 20:39:20.425834  8872 net.cpp:84] Creating Layer relu1_0
I1210 20:39:20.425834  8872 net.cpp:406] relu1_0 <- conv1_0
I1210 20:39:20.425834  8872 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1210 20:39:20.425834  8872 net.cpp:122] Setting up relu1_0
I1210 20:39:20.425834  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.425834  8872 net.cpp:137] Memory required for data: 115918000
I1210 20:39:20.425834  8872 layer_factory.cpp:58] Creating layer conv2
I1210 20:39:20.425834  8872 net.cpp:84] Creating Layer conv2
I1210 20:39:20.425834  8872 net.cpp:406] conv2 <- conv1_0
I1210 20:39:20.425834  8872 net.cpp:380] conv2 -> conv2
I1210 20:39:20.427335  8872 net.cpp:122] Setting up conv2
I1210 20:39:20.427335  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.427335  8872 net.cpp:137] Memory required for data: 132302000
I1210 20:39:20.427335  8872 layer_factory.cpp:58] Creating layer bn2
I1210 20:39:20.427335  8872 net.cpp:84] Creating Layer bn2
I1210 20:39:20.427335  8872 net.cpp:406] bn2 <- conv2
I1210 20:39:20.427335  8872 net.cpp:367] bn2 -> conv2 (in-place)
I1210 20:39:20.427834  8872 net.cpp:122] Setting up bn2
I1210 20:39:20.427834  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.427834  8872 net.cpp:137] Memory required for data: 148686000
I1210 20:39:20.427834  8872 layer_factory.cpp:58] Creating layer scale2
I1210 20:39:20.427834  8872 net.cpp:84] Creating Layer scale2
I1210 20:39:20.427834  8872 net.cpp:406] scale2 <- conv2
I1210 20:39:20.427834  8872 net.cpp:367] scale2 -> conv2 (in-place)
I1210 20:39:20.427834  8872 layer_factory.cpp:58] Creating layer scale2
I1210 20:39:20.427834  8872 net.cpp:122] Setting up scale2
I1210 20:39:20.427834  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.427834  8872 net.cpp:137] Memory required for data: 165070000
I1210 20:39:20.427834  8872 layer_factory.cpp:58] Creating layer relu2
I1210 20:39:20.427834  8872 net.cpp:84] Creating Layer relu2
I1210 20:39:20.427834  8872 net.cpp:406] relu2 <- conv2
I1210 20:39:20.427834  8872 net.cpp:367] relu2 -> conv2 (in-place)
I1210 20:39:20.428334  8872 net.cpp:122] Setting up relu2
I1210 20:39:20.428334  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.428334  8872 net.cpp:137] Memory required for data: 181454000
I1210 20:39:20.428334  8872 layer_factory.cpp:58] Creating layer conv2_1
I1210 20:39:20.428334  8872 net.cpp:84] Creating Layer conv2_1
I1210 20:39:20.428334  8872 net.cpp:406] conv2_1 <- conv2
I1210 20:39:20.428334  8872 net.cpp:380] conv2_1 -> conv2_1
I1210 20:39:20.429834  8872 net.cpp:122] Setting up conv2_1
I1210 20:39:20.429834  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.429834  8872 net.cpp:137] Memory required for data: 197838000
I1210 20:39:20.429834  8872 layer_factory.cpp:58] Creating layer bn2_1
I1210 20:39:20.429834  8872 net.cpp:84] Creating Layer bn2_1
I1210 20:39:20.429834  8872 net.cpp:406] bn2_1 <- conv2_1
I1210 20:39:20.429834  8872 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1210 20:39:20.429834  8872 net.cpp:122] Setting up bn2_1
I1210 20:39:20.429834  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.429834  8872 net.cpp:137] Memory required for data: 214222000
I1210 20:39:20.429834  8872 layer_factory.cpp:58] Creating layer scale2_1
I1210 20:39:20.429834  8872 net.cpp:84] Creating Layer scale2_1
I1210 20:39:20.429834  8872 net.cpp:406] scale2_1 <- conv2_1
I1210 20:39:20.429834  8872 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1210 20:39:20.429834  8872 layer_factory.cpp:58] Creating layer scale2_1
I1210 20:39:20.430335  8872 net.cpp:122] Setting up scale2_1
I1210 20:39:20.430335  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.430335  8872 net.cpp:137] Memory required for data: 230606000
I1210 20:39:20.430335  8872 layer_factory.cpp:58] Creating layer relu2_1
I1210 20:39:20.430335  8872 net.cpp:84] Creating Layer relu2_1
I1210 20:39:20.430335  8872 net.cpp:406] relu2_1 <- conv2_1
I1210 20:39:20.430335  8872 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1210 20:39:20.430835  8872 net.cpp:122] Setting up relu2_1
I1210 20:39:20.430835  8872 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 20:39:20.430835  8872 net.cpp:137] Memory required for data: 246990000
I1210 20:39:20.430835  8872 layer_factory.cpp:58] Creating layer conv2_2
I1210 20:39:20.430835  8872 net.cpp:84] Creating Layer conv2_2
I1210 20:39:20.430835  8872 net.cpp:406] conv2_2 <- conv2_1
I1210 20:39:20.430835  8872 net.cpp:380] conv2_2 -> conv2_2
I1210 20:39:20.432834  8872 net.cpp:122] Setting up conv2_2
I1210 20:39:20.432834  8872 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 20:39:20.432834  8872 net.cpp:137] Memory required for data: 267470000
I1210 20:39:20.432834  8872 layer_factory.cpp:58] Creating layer bn2_2
I1210 20:39:20.432834  8872 net.cpp:84] Creating Layer bn2_2
I1210 20:39:20.432834  8872 net.cpp:406] bn2_2 <- conv2_2
I1210 20:39:20.432834  8872 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1210 20:39:20.433336  8872 net.cpp:122] Setting up bn2_2
I1210 20:39:20.433336  8872 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 20:39:20.433336  8872 net.cpp:137] Memory required for data: 287950000
I1210 20:39:20.433336  8872 layer_factory.cpp:58] Creating layer scale2_2
I1210 20:39:20.433336  8872 net.cpp:84] Creating Layer scale2_2
I1210 20:39:20.433336  8872 net.cpp:406] scale2_2 <- conv2_2
I1210 20:39:20.433336  8872 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1210 20:39:20.433336  8872 layer_factory.cpp:58] Creating layer scale2_2
I1210 20:39:20.433336  8872 net.cpp:122] Setting up scale2_2
I1210 20:39:20.433336  8872 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 20:39:20.433336  8872 net.cpp:137] Memory required for data: 308430000
I1210 20:39:20.433336  8872 layer_factory.cpp:58] Creating layer relu2_2
I1210 20:39:20.433336  8872 net.cpp:84] Creating Layer relu2_2
I1210 20:39:20.433336  8872 net.cpp:406] relu2_2 <- conv2_2
I1210 20:39:20.433336  8872 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1210 20:39:20.433840  8872 net.cpp:122] Setting up relu2_2
I1210 20:39:20.433840  8872 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 20:39:20.433840  8872 net.cpp:137] Memory required for data: 328910000
I1210 20:39:20.433840  8872 layer_factory.cpp:58] Creating layer pool2_1
I1210 20:39:20.433840  8872 net.cpp:84] Creating Layer pool2_1
I1210 20:39:20.433840  8872 net.cpp:406] pool2_1 <- conv2_2
I1210 20:39:20.433840  8872 net.cpp:380] pool2_1 -> pool2_1
I1210 20:39:20.435835  8872 net.cpp:122] Setting up pool2_1
I1210 20:39:20.435835  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.435835  8872 net.cpp:137] Memory required for data: 334030000
I1210 20:39:20.435835  8872 layer_factory.cpp:58] Creating layer conv3
I1210 20:39:20.435835  8872 net.cpp:84] Creating Layer conv3
I1210 20:39:20.435835  8872 net.cpp:406] conv3 <- pool2_1
I1210 20:39:20.435835  8872 net.cpp:380] conv3 -> conv3
I1210 20:39:20.437361  8872 net.cpp:122] Setting up conv3
I1210 20:39:20.437361  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.437361  8872 net.cpp:137] Memory required for data: 339150000
I1210 20:39:20.437361  8872 layer_factory.cpp:58] Creating layer bn3
I1210 20:39:20.437361  8872 net.cpp:84] Creating Layer bn3
I1210 20:39:20.437361  8872 net.cpp:406] bn3 <- conv3
I1210 20:39:20.437361  8872 net.cpp:367] bn3 -> conv3 (in-place)
I1210 20:39:20.437361  8872 net.cpp:122] Setting up bn3
I1210 20:39:20.437361  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.437361  8872 net.cpp:137] Memory required for data: 344270000
I1210 20:39:20.437361  8872 layer_factory.cpp:58] Creating layer scale3
I1210 20:39:20.437361  8872 net.cpp:84] Creating Layer scale3
I1210 20:39:20.437361  8872 net.cpp:406] scale3 <- conv3
I1210 20:39:20.437361  8872 net.cpp:367] scale3 -> conv3 (in-place)
I1210 20:39:20.437361  8872 layer_factory.cpp:58] Creating layer scale3
I1210 20:39:20.437853  8872 net.cpp:122] Setting up scale3
I1210 20:39:20.437853  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.437853  8872 net.cpp:137] Memory required for data: 349390000
I1210 20:39:20.437853  8872 layer_factory.cpp:58] Creating layer relu3
I1210 20:39:20.437853  8872 net.cpp:84] Creating Layer relu3
I1210 20:39:20.437853  8872 net.cpp:406] relu3 <- conv3
I1210 20:39:20.437853  8872 net.cpp:367] relu3 -> conv3 (in-place)
I1210 20:39:20.437853  8872 net.cpp:122] Setting up relu3
I1210 20:39:20.437853  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.437853  8872 net.cpp:137] Memory required for data: 354510000
I1210 20:39:20.437853  8872 layer_factory.cpp:58] Creating layer conv3_1
I1210 20:39:20.437853  8872 net.cpp:84] Creating Layer conv3_1
I1210 20:39:20.437853  8872 net.cpp:406] conv3_1 <- conv3
I1210 20:39:20.437853  8872 net.cpp:380] conv3_1 -> conv3_1
I1210 20:39:20.439374  8872 net.cpp:122] Setting up conv3_1
I1210 20:39:20.439374  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.439374  8872 net.cpp:137] Memory required for data: 359630000
I1210 20:39:20.439374  8872 layer_factory.cpp:58] Creating layer bn3_1
I1210 20:39:20.439374  8872 net.cpp:84] Creating Layer bn3_1
I1210 20:39:20.439374  8872 net.cpp:406] bn3_1 <- conv3_1
I1210 20:39:20.439374  8872 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1210 20:39:20.439374  8872 net.cpp:122] Setting up bn3_1
I1210 20:39:20.439374  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.439374  8872 net.cpp:137] Memory required for data: 364750000
I1210 20:39:20.439374  8872 layer_factory.cpp:58] Creating layer scale3_1
I1210 20:39:20.439374  8872 net.cpp:84] Creating Layer scale3_1
I1210 20:39:20.439374  8872 net.cpp:406] scale3_1 <- conv3_1
I1210 20:39:20.439374  8872 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1210 20:39:20.439374  8872 layer_factory.cpp:58] Creating layer scale3_1
I1210 20:39:20.439374  8872 net.cpp:122] Setting up scale3_1
I1210 20:39:20.439374  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.439374  8872 net.cpp:137] Memory required for data: 369870000
I1210 20:39:20.439374  8872 layer_factory.cpp:58] Creating layer relu3_1
I1210 20:39:20.439374  8872 net.cpp:84] Creating Layer relu3_1
I1210 20:39:20.439374  8872 net.cpp:406] relu3_1 <- conv3_1
I1210 20:39:20.439374  8872 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1210 20:39:20.439374  8872 net.cpp:122] Setting up relu3_1
I1210 20:39:20.439374  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.439374  8872 net.cpp:137] Memory required for data: 374990000
I1210 20:39:20.439374  8872 layer_factory.cpp:58] Creating layer conv4
I1210 20:39:20.439374  8872 net.cpp:84] Creating Layer conv4
I1210 20:39:20.439374  8872 net.cpp:406] conv4 <- conv3_1
I1210 20:39:20.439374  8872 net.cpp:380] conv4 -> conv4
I1210 20:39:20.441382  8872 net.cpp:122] Setting up conv4
I1210 20:39:20.441382  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.441382  8872 net.cpp:137] Memory required for data: 380110000
I1210 20:39:20.441382  8872 layer_factory.cpp:58] Creating layer bn4
I1210 20:39:20.441382  8872 net.cpp:84] Creating Layer bn4
I1210 20:39:20.441382  8872 net.cpp:406] bn4 <- conv4
I1210 20:39:20.441382  8872 net.cpp:367] bn4 -> conv4 (in-place)
I1210 20:39:20.441382  8872 net.cpp:122] Setting up bn4
I1210 20:39:20.441382  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.441382  8872 net.cpp:137] Memory required for data: 385230000
I1210 20:39:20.441382  8872 layer_factory.cpp:58] Creating layer scale4
I1210 20:39:20.441382  8872 net.cpp:84] Creating Layer scale4
I1210 20:39:20.441382  8872 net.cpp:406] scale4 <- conv4
I1210 20:39:20.441382  8872 net.cpp:367] scale4 -> conv4 (in-place)
I1210 20:39:20.441382  8872 layer_factory.cpp:58] Creating layer scale4
I1210 20:39:20.441382  8872 net.cpp:122] Setting up scale4
I1210 20:39:20.441382  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.441382  8872 net.cpp:137] Memory required for data: 390350000
I1210 20:39:20.442370  8872 layer_factory.cpp:58] Creating layer relu4
I1210 20:39:20.442370  8872 net.cpp:84] Creating Layer relu4
I1210 20:39:20.442370  8872 net.cpp:406] relu4 <- conv4
I1210 20:39:20.442370  8872 net.cpp:367] relu4 -> conv4 (in-place)
I1210 20:39:20.442370  8872 net.cpp:122] Setting up relu4
I1210 20:39:20.442370  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.442370  8872 net.cpp:137] Memory required for data: 395470000
I1210 20:39:20.442370  8872 layer_factory.cpp:58] Creating layer conv4_1
I1210 20:39:20.442370  8872 net.cpp:84] Creating Layer conv4_1
I1210 20:39:20.442370  8872 net.cpp:406] conv4_1 <- conv4
I1210 20:39:20.442370  8872 net.cpp:380] conv4_1 -> conv4_1
I1210 20:39:20.443384  8872 net.cpp:122] Setting up conv4_1
I1210 20:39:20.443384  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.443384  8872 net.cpp:137] Memory required for data: 400590000
I1210 20:39:20.443384  8872 layer_factory.cpp:58] Creating layer bn4_1
I1210 20:39:20.443384  8872 net.cpp:84] Creating Layer bn4_1
I1210 20:39:20.443384  8872 net.cpp:406] bn4_1 <- conv4_1
I1210 20:39:20.443384  8872 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1210 20:39:20.443384  8872 net.cpp:122] Setting up bn4_1
I1210 20:39:20.443384  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.443384  8872 net.cpp:137] Memory required for data: 405710000
I1210 20:39:20.443384  8872 layer_factory.cpp:58] Creating layer scale4_1
I1210 20:39:20.443384  8872 net.cpp:84] Creating Layer scale4_1
I1210 20:39:20.443384  8872 net.cpp:406] scale4_1 <- conv4_1
I1210 20:39:20.443384  8872 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1210 20:39:20.443384  8872 layer_factory.cpp:58] Creating layer scale4_1
I1210 20:39:20.443384  8872 net.cpp:122] Setting up scale4_1
I1210 20:39:20.443384  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.443384  8872 net.cpp:137] Memory required for data: 410830000
I1210 20:39:20.443384  8872 layer_factory.cpp:58] Creating layer relu4_1
I1210 20:39:20.443384  8872 net.cpp:84] Creating Layer relu4_1
I1210 20:39:20.443384  8872 net.cpp:406] relu4_1 <- conv4_1
I1210 20:39:20.443384  8872 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1210 20:39:20.444370  8872 net.cpp:122] Setting up relu4_1
I1210 20:39:20.444370  8872 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 20:39:20.444370  8872 net.cpp:137] Memory required for data: 415950000
I1210 20:39:20.444370  8872 layer_factory.cpp:58] Creating layer conv4_2
I1210 20:39:20.444370  8872 net.cpp:84] Creating Layer conv4_2
I1210 20:39:20.444370  8872 net.cpp:406] conv4_2 <- conv4_1
I1210 20:39:20.444370  8872 net.cpp:380] conv4_2 -> conv4_2
I1210 20:39:20.445370  8872 net.cpp:122] Setting up conv4_2
I1210 20:39:20.445370  8872 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 20:39:20.445370  8872 net.cpp:137] Memory required for data: 421889200
I1210 20:39:20.445370  8872 layer_factory.cpp:58] Creating layer bn4_2
I1210 20:39:20.445370  8872 net.cpp:84] Creating Layer bn4_2
I1210 20:39:20.445370  8872 net.cpp:406] bn4_2 <- conv4_2
I1210 20:39:20.445370  8872 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1210 20:39:20.446370  8872 net.cpp:122] Setting up bn4_2
I1210 20:39:20.446370  8872 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 20:39:20.446370  8872 net.cpp:137] Memory required for data: 427828400
I1210 20:39:20.446370  8872 layer_factory.cpp:58] Creating layer scale4_2
I1210 20:39:20.446370  8872 net.cpp:84] Creating Layer scale4_2
I1210 20:39:20.446370  8872 net.cpp:406] scale4_2 <- conv4_2
I1210 20:39:20.446370  8872 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1210 20:39:20.446370  8872 layer_factory.cpp:58] Creating layer scale4_2
I1210 20:39:20.446370  8872 net.cpp:122] Setting up scale4_2
I1210 20:39:20.446370  8872 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 20:39:20.446370  8872 net.cpp:137] Memory required for data: 433767600
I1210 20:39:20.446370  8872 layer_factory.cpp:58] Creating layer relu4_2
I1210 20:39:20.446370  8872 net.cpp:84] Creating Layer relu4_2
I1210 20:39:20.446370  8872 net.cpp:406] relu4_2 <- conv4_2
I1210 20:39:20.446370  8872 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1210 20:39:20.446370  8872 net.cpp:122] Setting up relu4_2
I1210 20:39:20.446370  8872 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 20:39:20.446370  8872 net.cpp:137] Memory required for data: 439706800
I1210 20:39:20.446370  8872 layer_factory.cpp:58] Creating layer pool4_2
I1210 20:39:20.446370  8872 net.cpp:84] Creating Layer pool4_2
I1210 20:39:20.446370  8872 net.cpp:406] pool4_2 <- conv4_2
I1210 20:39:20.446370  8872 net.cpp:380] pool4_2 -> pool4_2
I1210 20:39:20.447371  8872 net.cpp:122] Setting up pool4_2
I1210 20:39:20.447371  8872 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 20:39:20.447371  8872 net.cpp:137] Memory required for data: 441191600
I1210 20:39:20.447371  8872 layer_factory.cpp:58] Creating layer conv4_0
I1210 20:39:20.447371  8872 net.cpp:84] Creating Layer conv4_0
I1210 20:39:20.447371  8872 net.cpp:406] conv4_0 <- pool4_2
I1210 20:39:20.447371  8872 net.cpp:380] conv4_0 -> conv4_0
I1210 20:39:20.449374  8872 net.cpp:122] Setting up conv4_0
I1210 20:39:20.449374  8872 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 20:39:20.449374  8872 net.cpp:137] Memory required for data: 442676400
I1210 20:39:20.449374  8872 layer_factory.cpp:58] Creating layer bn4_0
I1210 20:39:20.449374  8872 net.cpp:84] Creating Layer bn4_0
I1210 20:39:20.449374  8872 net.cpp:406] bn4_0 <- conv4_0
I1210 20:39:20.449374  8872 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1210 20:39:20.450371  8872 net.cpp:122] Setting up bn4_0
I1210 20:39:20.450371  8872 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 20:39:20.450371  8872 net.cpp:137] Memory required for data: 444161200
I1210 20:39:20.450371  8872 layer_factory.cpp:58] Creating layer scale4_0
I1210 20:39:20.450371  8872 net.cpp:84] Creating Layer scale4_0
I1210 20:39:20.450371  8872 net.cpp:406] scale4_0 <- conv4_0
I1210 20:39:20.450371  8872 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1210 20:39:20.450371  8872 layer_factory.cpp:58] Creating layer scale4_0
I1210 20:39:20.450371  8872 net.cpp:122] Setting up scale4_0
I1210 20:39:20.450371  8872 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 20:39:20.450371  8872 net.cpp:137] Memory required for data: 445646000
I1210 20:39:20.450371  8872 layer_factory.cpp:58] Creating layer relu4_0
I1210 20:39:20.450371  8872 net.cpp:84] Creating Layer relu4_0
I1210 20:39:20.450371  8872 net.cpp:406] relu4_0 <- conv4_0
I1210 20:39:20.450371  8872 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1210 20:39:20.450371  8872 net.cpp:122] Setting up relu4_0
I1210 20:39:20.450371  8872 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 20:39:20.450371  8872 net.cpp:137] Memory required for data: 447130800
I1210 20:39:20.451355  8872 layer_factory.cpp:58] Creating layer conv11
I1210 20:39:20.451355  8872 net.cpp:84] Creating Layer conv11
I1210 20:39:20.451355  8872 net.cpp:406] conv11 <- conv4_0
I1210 20:39:20.451355  8872 net.cpp:380] conv11 -> conv11
I1210 20:39:20.453357  8872 net.cpp:122] Setting up conv11
I1210 20:39:20.453357  8872 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 20:39:20.453357  8872 net.cpp:137] Memory required for data: 448922800
I1210 20:39:20.453357  8872 layer_factory.cpp:58] Creating layer bn_conv11
I1210 20:39:20.453357  8872 net.cpp:84] Creating Layer bn_conv11
I1210 20:39:20.453357  8872 net.cpp:406] bn_conv11 <- conv11
I1210 20:39:20.453357  8872 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1210 20:39:20.453357  8872 net.cpp:122] Setting up bn_conv11
I1210 20:39:20.453357  8872 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 20:39:20.453357  8872 net.cpp:137] Memory required for data: 450714800
I1210 20:39:20.453357  8872 layer_factory.cpp:58] Creating layer scale_conv11
I1210 20:39:20.453357  8872 net.cpp:84] Creating Layer scale_conv11
I1210 20:39:20.453357  8872 net.cpp:406] scale_conv11 <- conv11
I1210 20:39:20.453357  8872 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1210 20:39:20.453357  8872 layer_factory.cpp:58] Creating layer scale_conv11
I1210 20:39:20.453357  8872 net.cpp:122] Setting up scale_conv11
I1210 20:39:20.453357  8872 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 20:39:20.453357  8872 net.cpp:137] Memory required for data: 452506800
I1210 20:39:20.453357  8872 layer_factory.cpp:58] Creating layer relu_conv11
I1210 20:39:20.453357  8872 net.cpp:84] Creating Layer relu_conv11
I1210 20:39:20.453357  8872 net.cpp:406] relu_conv11 <- conv11
I1210 20:39:20.453357  8872 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1210 20:39:20.454357  8872 net.cpp:122] Setting up relu_conv11
I1210 20:39:20.454357  8872 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 20:39:20.454357  8872 net.cpp:137] Memory required for data: 454298800
I1210 20:39:20.454357  8872 layer_factory.cpp:58] Creating layer conv12
I1210 20:39:20.454357  8872 net.cpp:84] Creating Layer conv12
I1210 20:39:20.454357  8872 net.cpp:406] conv12 <- conv11
I1210 20:39:20.454357  8872 net.cpp:380] conv12 -> conv12
I1210 20:39:20.455358  8872 net.cpp:122] Setting up conv12
I1210 20:39:20.455358  8872 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 20:39:20.455358  8872 net.cpp:137] Memory required for data: 456602800
I1210 20:39:20.455358  8872 layer_factory.cpp:58] Creating layer bn_conv12
I1210 20:39:20.455358  8872 net.cpp:84] Creating Layer bn_conv12
I1210 20:39:20.455358  8872 net.cpp:406] bn_conv12 <- conv12
I1210 20:39:20.455358  8872 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1210 20:39:20.456356  8872 net.cpp:122] Setting up bn_conv12
I1210 20:39:20.456356  8872 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 20:39:20.456356  8872 net.cpp:137] Memory required for data: 458906800
I1210 20:39:20.456356  8872 layer_factory.cpp:58] Creating layer scale_conv12
I1210 20:39:20.456356  8872 net.cpp:84] Creating Layer scale_conv12
I1210 20:39:20.456356  8872 net.cpp:406] scale_conv12 <- conv12
I1210 20:39:20.456356  8872 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1210 20:39:20.456356  8872 layer_factory.cpp:58] Creating layer scale_conv12
I1210 20:39:20.456356  8872 net.cpp:122] Setting up scale_conv12
I1210 20:39:20.456356  8872 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 20:39:20.456356  8872 net.cpp:137] Memory required for data: 461210800
I1210 20:39:20.456356  8872 layer_factory.cpp:58] Creating layer relu_conv12
I1210 20:39:20.456356  8872 net.cpp:84] Creating Layer relu_conv12
I1210 20:39:20.456356  8872 net.cpp:406] relu_conv12 <- conv12
I1210 20:39:20.456356  8872 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1210 20:39:20.456356  8872 net.cpp:122] Setting up relu_conv12
I1210 20:39:20.456356  8872 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 20:39:20.456356  8872 net.cpp:137] Memory required for data: 463514800
I1210 20:39:20.456356  8872 layer_factory.cpp:58] Creating layer poolcp6
I1210 20:39:20.456356  8872 net.cpp:84] Creating Layer poolcp6
I1210 20:39:20.456356  8872 net.cpp:406] poolcp6 <- conv12
I1210 20:39:20.456356  8872 net.cpp:380] poolcp6 -> poolcp6
I1210 20:39:20.456356  8872 net.cpp:122] Setting up poolcp6
I1210 20:39:20.456356  8872 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1210 20:39:20.456356  8872 net.cpp:137] Memory required for data: 463550800
I1210 20:39:20.456356  8872 layer_factory.cpp:58] Creating layer ip1
I1210 20:39:20.456356  8872 net.cpp:84] Creating Layer ip1
I1210 20:39:20.456356  8872 net.cpp:406] ip1 <- poolcp6
I1210 20:39:20.456356  8872 net.cpp:380] ip1 -> ip1
I1210 20:39:20.457355  8872 net.cpp:122] Setting up ip1
I1210 20:39:20.457355  8872 net.cpp:129] Top shape: 100 100 (10000)
I1210 20:39:20.457355  8872 net.cpp:137] Memory required for data: 463590800
I1210 20:39:20.457355  8872 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1210 20:39:20.457355  8872 net.cpp:84] Creating Layer ip1_ip1_0_split
I1210 20:39:20.457355  8872 net.cpp:406] ip1_ip1_0_split <- ip1
I1210 20:39:20.457355  8872 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1210 20:39:20.457355  8872 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1210 20:39:20.457355  8872 net.cpp:122] Setting up ip1_ip1_0_split
I1210 20:39:20.457355  8872 net.cpp:129] Top shape: 100 100 (10000)
I1210 20:39:20.457355  8872 net.cpp:129] Top shape: 100 100 (10000)
I1210 20:39:20.457355  8872 net.cpp:137] Memory required for data: 463670800
I1210 20:39:20.457355  8872 layer_factory.cpp:58] Creating layer accuracy
I1210 20:39:20.457355  8872 net.cpp:84] Creating Layer accuracy
I1210 20:39:20.457355  8872 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1210 20:39:20.457355  8872 net.cpp:406] accuracy <- label_cifar_1_split_0
I1210 20:39:20.457355  8872 net.cpp:380] accuracy -> accuracy
I1210 20:39:20.457355  8872 net.cpp:122] Setting up accuracy
I1210 20:39:20.457355  8872 net.cpp:129] Top shape: (1)
I1210 20:39:20.457355  8872 net.cpp:137] Memory required for data: 463670804
I1210 20:39:20.457355  8872 layer_factory.cpp:58] Creating layer loss
I1210 20:39:20.457355  8872 net.cpp:84] Creating Layer loss
I1210 20:39:20.457355  8872 net.cpp:406] loss <- ip1_ip1_0_split_1
I1210 20:39:20.457355  8872 net.cpp:406] loss <- label_cifar_1_split_1
I1210 20:39:20.457355  8872 net.cpp:380] loss -> loss
I1210 20:39:20.457355  8872 layer_factory.cpp:58] Creating layer loss
I1210 20:39:20.457355  8872 net.cpp:122] Setting up loss
I1210 20:39:20.457355  8872 net.cpp:129] Top shape: (1)
I1210 20:39:20.457355  8872 net.cpp:132]     with loss weight 1
I1210 20:39:20.457355  8872 net.cpp:137] Memory required for data: 463670808
I1210 20:39:20.457355  8872 net.cpp:198] loss needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:200] accuracy does not need backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] ip1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] poolcp6 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu_conv12 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale_conv12 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn_conv12 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv12 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu_conv11 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale_conv11 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn_conv11 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv11 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu4_0 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale4_0 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn4_0 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv4_0 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] pool4_2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu4_2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale4_2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn4_2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv4_2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu4_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale4_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn4_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv4_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu4 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale4 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn4 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv4 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu3_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale3_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn3_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv3_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu3 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale3 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn3 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv3 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] pool2_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu2_2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale2_2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn2_2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv2_2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu2_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale2_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn2_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv2_1 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] scale2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] bn2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] conv2 needs backward computation.
I1210 20:39:20.457355  8872 net.cpp:198] relu1_0 needs backward computation.
I1210 20:39:20.458356  8872 net.cpp:198] scale1_0 needs backward computation.
I1210 20:39:20.458356  8872 net.cpp:198] bn1_0 needs backward computation.
I1210 20:39:20.458356  8872 net.cpp:198] conv1_0 needs backward computation.
I1210 20:39:20.458356  8872 net.cpp:198] relu1 needs backward computation.
I1210 20:39:20.458356  8872 net.cpp:198] scale1 needs backward computation.
I1210 20:39:20.458356  8872 net.cpp:198] bn1 needs backward computation.
I1210 20:39:20.458356  8872 net.cpp:198] conv1 needs backward computation.
I1210 20:39:20.458356  8872 net.cpp:200] label_cifar_1_split does not need backward computation.
I1210 20:39:20.458356  8872 net.cpp:200] cifar does not need backward computation.
I1210 20:39:20.458356  8872 net.cpp:242] This network produces output accuracy
I1210 20:39:20.458356  8872 net.cpp:242] This network produces output loss
I1210 20:39:20.458356  8872 net.cpp:255] Network initialization done.
I1210 20:39:20.458356  8872 solver.cpp:56] Solver scaffolding done.
I1210 20:39:20.462368  8872 caffe.cpp:243] Resuming from examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_90000.solverstate
I1210 20:39:20.466363  8872 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_90000.caffemodel
I1210 20:39:20.466363  8872 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 20:39:20.466363  8872 sgd_solver.cpp:318] SGDSolver: restoring history
I1210 20:39:20.470371  8872 caffe.cpp:249] Starting Optimization
I1210 20:39:20.470371  8872 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV1_360k
I1210 20:39:20.470371  8872 solver.cpp:273] Learning Rate Policy: multistep
I1210 20:39:20.472370  8872 solver.cpp:330] Iteration 90000, Testing net (#0)
I1210 20:39:20.474370  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:39:21.830960 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:39:21.883963  8872 solver.cpp:397]     Test net output #0: accuracy = 0.5569
I1210 20:39:21.883963  8872 solver.cpp:397]     Test net output #1: loss = 1.78659 (* 1 = 1.78659 loss)
I1210 20:39:21.996006  8872 solver.cpp:218] Iteration 90000 (59005 iter/s, 1.52529s/100 iters), loss = 0.843073
I1210 20:39:21.996006  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 20:39:21.996006  8872 solver.cpp:237]     Train net output #1: loss = 0.843073 (* 1 = 0.843073 loss)
I1210 20:39:21.996006  8872 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1210 20:39:27.992275  8872 solver.cpp:218] Iteration 90100 (16.6798 iter/s, 5.99528s/100 iters), loss = 0.738146
I1210 20:39:27.992275  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 20:39:27.992275  8872 solver.cpp:237]     Train net output #1: loss = 0.738146 (* 1 = 0.738146 loss)
I1210 20:39:27.992275  8872 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1210 20:39:33.928930  8872 solver.cpp:218] Iteration 90200 (16.8472 iter/s, 5.93572s/100 iters), loss = 0.587295
I1210 20:39:33.928930  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:39:33.928930  8872 solver.cpp:237]     Train net output #1: loss = 0.587295 (* 1 = 0.587295 loss)
I1210 20:39:33.928930  8872 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1210 20:39:39.920563  8872 solver.cpp:218] Iteration 90300 (16.691 iter/s, 5.99126s/100 iters), loss = 0.904541
I1210 20:39:39.920563  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 20:39:39.920563  8872 solver.cpp:237]     Train net output #1: loss = 0.904541 (* 1 = 0.904541 loss)
I1210 20:39:39.920563  8872 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1210 20:39:46.044821  8872 solver.cpp:218] Iteration 90400 (16.3283 iter/s, 6.12435s/100 iters), loss = 0.869737
I1210 20:39:46.045823  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 20:39:46.045823  8872 solver.cpp:237]     Train net output #1: loss = 0.869737 (* 1 = 0.869737 loss)
I1210 20:39:46.045823  8872 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1210 20:39:51.718605  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:39:51.954628  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_90500.caffemodel
I1210 20:39:51.970628  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_90500.solverstate
I1210 20:39:51.975625  8872 solver.cpp:330] Iteration 90500, Testing net (#0)
I1210 20:39:51.975625  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:39:53.282742 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:39:53.333786  8872 solver.cpp:397]     Test net output #0: accuracy = 0.579
I1210 20:39:53.333786  8872 solver.cpp:397]     Test net output #1: loss = 1.68198 (* 1 = 1.68198 loss)
I1210 20:39:53.392289  8872 solver.cpp:218] Iteration 90500 (13.6127 iter/s, 7.34611s/100 iters), loss = 0.756398
I1210 20:39:53.392289  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 20:39:53.392289  8872 solver.cpp:237]     Train net output #1: loss = 0.756398 (* 1 = 0.756398 loss)
I1210 20:39:53.392289  8872 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1210 20:39:59.349270  8872 solver.cpp:218] Iteration 90600 (16.7878 iter/s, 5.9567s/100 iters), loss = 0.732433
I1210 20:39:59.349270  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 20:39:59.349270  8872 solver.cpp:237]     Train net output #1: loss = 0.732433 (* 1 = 0.732433 loss)
I1210 20:39:59.349270  8872 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1210 20:40:05.301008  8872 solver.cpp:218] Iteration 90700 (16.803 iter/s, 5.95132s/100 iters), loss = 0.54472
I1210 20:40:05.301008  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:40:05.301008  8872 solver.cpp:237]     Train net output #1: loss = 0.54472 (* 1 = 0.54472 loss)
I1210 20:40:05.301008  8872 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1210 20:40:11.321518  8872 solver.cpp:218] Iteration 90800 (16.6122 iter/s, 6.01968s/100 iters), loss = 0.896698
I1210 20:40:11.321518  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 20:40:11.321518  8872 solver.cpp:237]     Train net output #1: loss = 0.896698 (* 1 = 0.896698 loss)
I1210 20:40:11.321518  8872 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1210 20:40:17.260042  8872 solver.cpp:218] Iteration 90900 (16.8404 iter/s, 5.93811s/100 iters), loss = 0.918634
I1210 20:40:17.260042  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 20:40:17.260042  8872 solver.cpp:237]     Train net output #1: loss = 0.918634 (* 1 = 0.918634 loss)
I1210 20:40:17.260042  8872 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1210 20:40:22.880430  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:40:23.112947  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_91000.caffemodel
I1210 20:40:23.127452  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_91000.solverstate
I1210 20:40:23.132452  8872 solver.cpp:330] Iteration 91000, Testing net (#0)
I1210 20:40:23.132452  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:40:24.433558 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:40:24.484561  8872 solver.cpp:397]     Test net output #0: accuracy = 0.5713
I1210 20:40:24.484561  8872 solver.cpp:397]     Test net output #1: loss = 1.74503 (* 1 = 1.74503 loss)
I1210 20:40:24.540562  8872 solver.cpp:218] Iteration 91000 (13.7351 iter/s, 7.28062s/100 iters), loss = 0.804513
I1210 20:40:24.540562  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 20:40:24.540562  8872 solver.cpp:237]     Train net output #1: loss = 0.804513 (* 1 = 0.804513 loss)
I1210 20:40:24.540562  8872 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1210 20:40:30.515036  8872 solver.cpp:218] Iteration 91100 (16.74 iter/s, 5.9737s/100 iters), loss = 0.716856
I1210 20:40:30.515036  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 20:40:30.515036  8872 solver.cpp:237]     Train net output #1: loss = 0.716856 (* 1 = 0.716856 loss)
I1210 20:40:30.515036  8872 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1210 20:40:36.659082  8872 solver.cpp:218] Iteration 91200 (16.278 iter/s, 6.14325s/100 iters), loss = 0.587291
I1210 20:40:36.659082  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:40:36.659082  8872 solver.cpp:237]     Train net output #1: loss = 0.587291 (* 1 = 0.587291 loss)
I1210 20:40:36.659082  8872 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1210 20:40:42.722836  8872 solver.cpp:218] Iteration 91300 (16.4918 iter/s, 6.06362s/100 iters), loss = 0.770588
I1210 20:40:42.722836  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 20:40:42.722836  8872 solver.cpp:237]     Train net output #1: loss = 0.770588 (* 1 = 0.770588 loss)
I1210 20:40:42.722836  8872 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1210 20:40:48.783993  8872 solver.cpp:218] Iteration 91400 (16.5 iter/s, 6.06059s/100 iters), loss = 0.838521
I1210 20:40:48.783993  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 20:40:48.783993  8872 solver.cpp:237]     Train net output #1: loss = 0.838521 (* 1 = 0.838521 loss)
I1210 20:40:48.783993  8872 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1210 20:40:54.543355  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:40:54.782356  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_91500.caffemodel
I1210 20:40:54.799856  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_91500.solverstate
I1210 20:40:54.804857  8872 solver.cpp:330] Iteration 91500, Testing net (#0)
I1210 20:40:54.804857  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:40:56.126857 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:40:56.179358  8872 solver.cpp:397]     Test net output #0: accuracy = 0.5949
I1210 20:40:56.179358  8872 solver.cpp:397]     Test net output #1: loss = 1.57505 (* 1 = 1.57505 loss)
I1210 20:40:56.238855  8872 solver.cpp:218] Iteration 91500 (13.4154 iter/s, 7.45411s/100 iters), loss = 0.699414
I1210 20:40:56.238855  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 20:40:56.238855  8872 solver.cpp:237]     Train net output #1: loss = 0.699414 (* 1 = 0.699414 loss)
I1210 20:40:56.238855  8872 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1210 20:41:02.300956  8872 solver.cpp:218] Iteration 91600 (16.4965 iter/s, 6.06189s/100 iters), loss = 0.734378
I1210 20:41:02.300956  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 20:41:02.301460  8872 solver.cpp:237]     Train net output #1: loss = 0.734378 (* 1 = 0.734378 loss)
I1210 20:41:02.301460  8872 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1210 20:41:08.370626  8872 solver.cpp:218] Iteration 91700 (16.477 iter/s, 6.06905s/100 iters), loss = 0.640439
I1210 20:41:08.371126  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 20:41:08.371126  8872 solver.cpp:237]     Train net output #1: loss = 0.640439 (* 1 = 0.640439 loss)
I1210 20:41:08.371126  8872 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1210 20:41:14.430685  8872 solver.cpp:218] Iteration 91800 (16.5031 iter/s, 6.05946s/100 iters), loss = 0.930364
I1210 20:41:14.430685  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 20:41:14.430685  8872 solver.cpp:237]     Train net output #1: loss = 0.930364 (* 1 = 0.930364 loss)
I1210 20:41:14.430685  8872 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1210 20:41:20.496371  8872 solver.cpp:218] Iteration 91900 (16.4874 iter/s, 6.06525s/100 iters), loss = 0.853084
I1210 20:41:20.496371  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 20:41:20.496371  8872 solver.cpp:237]     Train net output #1: loss = 0.853084 (* 1 = 0.853084 loss)
I1210 20:41:20.496371  8872 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1210 20:41:26.257858  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:41:26.496358  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_92000.caffemodel
I1210 20:41:26.512861  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_92000.solverstate
I1210 20:41:26.518357  8872 solver.cpp:330] Iteration 92000, Testing net (#0)
I1210 20:41:26.518357  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:41:27.837859 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:41:27.889878  8872 solver.cpp:397]     Test net output #0: accuracy = 0.5614
I1210 20:41:27.889878  8872 solver.cpp:397]     Test net output #1: loss = 1.74326 (* 1 = 1.74326 loss)
I1210 20:41:27.947373  8872 solver.cpp:218] Iteration 92000 (13.4219 iter/s, 7.45052s/100 iters), loss = 0.732314
I1210 20:41:27.947873  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 20:41:27.947873  8872 solver.cpp:237]     Train net output #1: loss = 0.732314 (* 1 = 0.732314 loss)
I1210 20:41:27.947873  8872 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1210 20:41:33.987949  8872 solver.cpp:218] Iteration 92100 (16.5566 iter/s, 6.0399s/100 iters), loss = 0.787228
I1210 20:41:33.987949  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 20:41:33.987949  8872 solver.cpp:237]     Train net output #1: loss = 0.787228 (* 1 = 0.787228 loss)
I1210 20:41:33.987949  8872 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1210 20:41:40.047881  8872 solver.cpp:218] Iteration 92200 (16.5031 iter/s, 6.05949s/100 iters), loss = 0.623066
I1210 20:41:40.047881  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:41:40.047881  8872 solver.cpp:237]     Train net output #1: loss = 0.623066 (* 1 = 0.623066 loss)
I1210 20:41:40.047881  8872 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1210 20:41:46.095667  8872 solver.cpp:218] Iteration 92300 (16.5369 iter/s, 6.04707s/100 iters), loss = 0.836569
I1210 20:41:46.095667  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 20:41:46.095667  8872 solver.cpp:237]     Train net output #1: loss = 0.836569 (* 1 = 0.836569 loss)
I1210 20:41:46.095667  8872 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1210 20:41:52.160431  8872 solver.cpp:218] Iteration 92400 (16.4903 iter/s, 6.06417s/100 iters), loss = 0.829746
I1210 20:41:52.160431  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 20:41:52.160431  8872 solver.cpp:237]     Train net output #1: loss = 0.829746 (* 1 = 0.829746 loss)
I1210 20:41:52.160431  8872 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1210 20:41:57.923094  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:41:58.162243  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_92500.caffemodel
I1210 20:41:58.179239  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_92500.solverstate
I1210 20:41:58.185240  8872 solver.cpp:330] Iteration 92500, Testing net (#0)
I1210 20:41:58.185240  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:41:59.514242 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:41:59.566740  8872 solver.cpp:397]     Test net output #0: accuracy = 0.5981
I1210 20:41:59.566740  8872 solver.cpp:397]     Test net output #1: loss = 1.53611 (* 1 = 1.53611 loss)
I1210 20:41:59.624240  8872 solver.cpp:218] Iteration 92500 (13.3989 iter/s, 7.46332s/100 iters), loss = 0.671349
I1210 20:41:59.624240  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 20:41:59.624240  8872 solver.cpp:237]     Train net output #1: loss = 0.671349 (* 1 = 0.671349 loss)
I1210 20:41:59.624240  8872 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1210 20:42:05.683151  8872 solver.cpp:218] Iteration 92600 (16.5051 iter/s, 6.05873s/100 iters), loss = 0.782829
I1210 20:42:05.683151  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 20:42:05.683151  8872 solver.cpp:237]     Train net output #1: loss = 0.782829 (* 1 = 0.782829 loss)
I1210 20:42:05.683151  8872 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1210 20:42:11.747650  8872 solver.cpp:218] Iteration 92700 (16.4918 iter/s, 6.06363s/100 iters), loss = 0.63907
I1210 20:42:11.747650  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 20:42:11.747650  8872 solver.cpp:237]     Train net output #1: loss = 0.63907 (* 1 = 0.63907 loss)
I1210 20:42:11.747650  8872 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1210 20:42:17.814704  8872 solver.cpp:218] Iteration 92800 (16.4833 iter/s, 6.06674s/100 iters), loss = 0.924968
I1210 20:42:17.814704  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 20:42:17.814704  8872 solver.cpp:237]     Train net output #1: loss = 0.924968 (* 1 = 0.924968 loss)
I1210 20:42:17.814704  8872 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1210 20:42:23.874629  8872 solver.cpp:218] Iteration 92900 (16.5035 iter/s, 6.05932s/100 iters), loss = 0.773381
I1210 20:42:23.874629  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 20:42:23.874629  8872 solver.cpp:237]     Train net output #1: loss = 0.773381 (* 1 = 0.773381 loss)
I1210 20:42:23.874629  8872 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1210 20:42:29.642556  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:42:29.882036  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_93000.caffemodel
I1210 20:42:29.898556  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_93000.solverstate
I1210 20:42:29.903556  8872 solver.cpp:330] Iteration 93000, Testing net (#0)
I1210 20:42:29.903556  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:42:31.231536 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:42:31.282536  8872 solver.cpp:397]     Test net output #0: accuracy = 0.565
I1210 20:42:31.282536  8872 solver.cpp:397]     Test net output #1: loss = 1.75167 (* 1 = 1.75167 loss)
I1210 20:42:31.340046  8872 solver.cpp:218] Iteration 93000 (13.3961 iter/s, 7.46486s/100 iters), loss = 0.739153
I1210 20:42:31.340046  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 20:42:31.340046  8872 solver.cpp:237]     Train net output #1: loss = 0.739153 (* 1 = 0.739153 loss)
I1210 20:42:31.340046  8872 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1210 20:42:37.397658  8872 solver.cpp:218] Iteration 93100 (16.5089 iter/s, 6.05735s/100 iters), loss = 0.734018
I1210 20:42:37.397658  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 20:42:37.398159  8872 solver.cpp:237]     Train net output #1: loss = 0.734018 (* 1 = 0.734018 loss)
I1210 20:42:37.398159  8872 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1210 20:42:43.473223  8872 solver.cpp:218] Iteration 93200 (16.4612 iter/s, 6.0749s/100 iters), loss = 0.67842
I1210 20:42:43.473223  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 20:42:43.473736  8872 solver.cpp:237]     Train net output #1: loss = 0.67842 (* 1 = 0.67842 loss)
I1210 20:42:43.473736  8872 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1210 20:42:49.508172  8872 solver.cpp:218] Iteration 93300 (16.5729 iter/s, 6.03395s/100 iters), loss = 0.877955
I1210 20:42:49.508172  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 20:42:49.508172  8872 solver.cpp:237]     Train net output #1: loss = 0.877955 (* 1 = 0.877955 loss)
I1210 20:42:49.508172  8872 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1210 20:42:55.562256  8872 solver.cpp:218] Iteration 93400 (16.5188 iter/s, 6.05371s/100 iters), loss = 0.883445
I1210 20:42:55.562757  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 20:42:55.562757  8872 solver.cpp:237]     Train net output #1: loss = 0.883445 (* 1 = 0.883445 loss)
I1210 20:42:55.562757  8872 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1210 20:43:01.320758  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:43:01.556704  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_93500.caffemodel
I1210 20:43:01.574702  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_93500.solverstate
I1210 20:43:01.579706  8872 solver.cpp:330] Iteration 93500, Testing net (#0)
I1210 20:43:01.579706  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:43:02.903204 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:43:02.954205  8872 solver.cpp:397]     Test net output #0: accuracy = 0.5572
I1210 20:43:02.954205  8872 solver.cpp:397]     Test net output #1: loss = 1.75027 (* 1 = 1.75027 loss)
I1210 20:43:03.012203  8872 solver.cpp:218] Iteration 93500 (13.4244 iter/s, 7.44915s/100 iters), loss = 0.636998
I1210 20:43:03.012203  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 20:43:03.012203  8872 solver.cpp:237]     Train net output #1: loss = 0.636998 (* 1 = 0.636998 loss)
I1210 20:43:03.012203  8872 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1210 20:43:09.064380  8872 solver.cpp:218] Iteration 93600 (16.5245 iter/s, 6.0516s/100 iters), loss = 0.648379
I1210 20:43:09.064380  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 20:43:09.064380  8872 solver.cpp:237]     Train net output #1: loss = 0.648379 (* 1 = 0.648379 loss)
I1210 20:43:09.064380  8872 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1210 20:43:15.117878  8872 solver.cpp:218] Iteration 93700 (16.5209 iter/s, 6.05295s/100 iters), loss = 0.631727
I1210 20:43:15.117878  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 20:43:15.117878  8872 solver.cpp:237]     Train net output #1: loss = 0.631727 (* 1 = 0.631727 loss)
I1210 20:43:15.117878  8872 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1210 20:43:21.149394  8872 solver.cpp:218] Iteration 93800 (16.5815 iter/s, 6.03083s/100 iters), loss = 0.751851
I1210 20:43:21.149394  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 20:43:21.149394  8872 solver.cpp:237]     Train net output #1: loss = 0.751851 (* 1 = 0.751851 loss)
I1210 20:43:21.149394  8872 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1210 20:43:27.189507  8872 solver.cpp:218] Iteration 93900 (16.5566 iter/s, 6.03988s/100 iters), loss = 1.03033
I1210 20:43:27.189507  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 20:43:27.189507  8872 solver.cpp:237]     Train net output #1: loss = 1.03033 (* 1 = 1.03033 loss)
I1210 20:43:27.189507  8872 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1210 20:43:32.937243  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:43:33.174242  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_94000.caffemodel
I1210 20:43:33.190739  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_94000.solverstate
I1210 20:43:33.195740  8872 solver.cpp:330] Iteration 94000, Testing net (#0)
I1210 20:43:33.195740  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:43:34.518781 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:43:34.570272  8872 solver.cpp:397]     Test net output #0: accuracy = 0.535
I1210 20:43:34.570772  8872 solver.cpp:397]     Test net output #1: loss = 1.89756 (* 1 = 1.89756 loss)
I1210 20:43:34.627771  8872 solver.cpp:218] Iteration 94000 (13.4448 iter/s, 7.43782s/100 iters), loss = 0.728334
I1210 20:43:34.627771  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 20:43:34.628273  8872 solver.cpp:237]     Train net output #1: loss = 0.728334 (* 1 = 0.728334 loss)
I1210 20:43:34.628273  8872 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1210 20:43:40.669070  8872 solver.cpp:218] Iteration 94100 (16.5551 iter/s, 6.04045s/100 iters), loss = 0.686014
I1210 20:43:40.669070  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 20:43:40.669070  8872 solver.cpp:237]     Train net output #1: loss = 0.686014 (* 1 = 0.686014 loss)
I1210 20:43:40.669070  8872 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1210 20:43:46.709071  8872 solver.cpp:218] Iteration 94200 (16.5579 iter/s, 6.03942s/100 iters), loss = 0.656491
I1210 20:43:46.709071  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 20:43:46.709071  8872 solver.cpp:237]     Train net output #1: loss = 0.656491 (* 1 = 0.656491 loss)
I1210 20:43:46.709071  8872 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1210 20:43:52.745105  8872 solver.cpp:218] Iteration 94300 (16.5684 iter/s, 6.0356s/100 iters), loss = 0.844902
I1210 20:43:52.745105  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 20:43:52.745105  8872 solver.cpp:237]     Train net output #1: loss = 0.844902 (* 1 = 0.844902 loss)
I1210 20:43:52.745105  8872 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1210 20:43:58.789476  8872 solver.cpp:218] Iteration 94400 (16.5458 iter/s, 6.04384s/100 iters), loss = 0.768226
I1210 20:43:58.789476  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 20:43:58.789476  8872 solver.cpp:237]     Train net output #1: loss = 0.768226 (* 1 = 0.768226 loss)
I1210 20:43:58.789476  8872 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1210 20:44:04.548022  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:44:04.787021  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_94500.caffemodel
I1210 20:44:04.804522  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_94500.solverstate
I1210 20:44:04.809521  8872 solver.cpp:330] Iteration 94500, Testing net (#0)
I1210 20:44:04.809521  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:44:06.135556 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:44:06.188055  8872 solver.cpp:397]     Test net output #0: accuracy = 0.5535
I1210 20:44:06.188055  8872 solver.cpp:397]     Test net output #1: loss = 1.78499 (* 1 = 1.78499 loss)
I1210 20:44:06.245055  8872 solver.cpp:218] Iteration 94500 (13.4134 iter/s, 7.45523s/100 iters), loss = 0.770405
I1210 20:44:06.245055  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 20:44:06.245055  8872 solver.cpp:237]     Train net output #1: loss = 0.770405 (* 1 = 0.770405 loss)
I1210 20:44:06.245055  8872 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1210 20:44:12.290632  8872 solver.cpp:218] Iteration 94600 (16.542 iter/s, 6.04521s/100 iters), loss = 0.755162
I1210 20:44:12.290632  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 20:44:12.290632  8872 solver.cpp:237]     Train net output #1: loss = 0.755162 (* 1 = 0.755162 loss)
I1210 20:44:12.290632  8872 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1210 20:44:18.332631  8872 solver.cpp:218] Iteration 94700 (16.553 iter/s, 6.04121s/100 iters), loss = 0.557053
I1210 20:44:18.332631  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:44:18.332631  8872 solver.cpp:237]     Train net output #1: loss = 0.557053 (* 1 = 0.557053 loss)
I1210 20:44:18.332631  8872 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1210 20:44:24.371430  8872 solver.cpp:218] Iteration 94800 (16.5603 iter/s, 6.03855s/100 iters), loss = 0.924954
I1210 20:44:24.371430  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 20:44:24.371430  8872 solver.cpp:237]     Train net output #1: loss = 0.924954 (* 1 = 0.924954 loss)
I1210 20:44:24.371938  8872 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1210 20:44:30.415081  8872 solver.cpp:218] Iteration 94900 (16.5485 iter/s, 6.04285s/100 iters), loss = 0.794596
I1210 20:44:30.415081  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 20:44:30.415081  8872 solver.cpp:237]     Train net output #1: loss = 0.794596 (* 1 = 0.794596 loss)
I1210 20:44:30.415081  8872 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1210 20:44:36.158363  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:44:36.396878  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_95000.caffemodel
I1210 20:44:36.413877  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_95000.solverstate
I1210 20:44:36.419379  8872 solver.cpp:330] Iteration 95000, Testing net (#0)
I1210 20:44:36.419379  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:44:37.740878 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:44:37.792879  8872 solver.cpp:397]     Test net output #0: accuracy = 0.5765
I1210 20:44:37.793380  8872 solver.cpp:397]     Test net output #1: loss = 1.60761 (* 1 = 1.60761 loss)
I1210 20:44:37.851894  8872 solver.cpp:218] Iteration 95000 (13.4473 iter/s, 7.43641s/100 iters), loss = 0.791799
I1210 20:44:37.851894  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 20:44:37.851894  8872 solver.cpp:237]     Train net output #1: loss = 0.791799 (* 1 = 0.791799 loss)
I1210 20:44:37.851894  8872 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1210 20:44:37.851894  8872 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1210 20:44:43.892860  8872 solver.cpp:218] Iteration 95100 (16.5549 iter/s, 6.04051s/100 iters), loss = 0.766294
I1210 20:44:43.892860  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 20:44:43.892860  8872 solver.cpp:237]     Train net output #1: loss = 0.766294 (* 1 = 0.766294 loss)
I1210 20:44:43.893362  8872 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1210 20:44:49.923280  8872 solver.cpp:218] Iteration 95200 (16.5837 iter/s, 6.03001s/100 iters), loss = 0.525379
I1210 20:44:49.923780  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 20:44:49.923780  8872 solver.cpp:237]     Train net output #1: loss = 0.525379 (* 1 = 0.525379 loss)
I1210 20:44:49.923780  8872 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1210 20:44:55.958739  8872 solver.cpp:218] Iteration 95300 (16.5704 iter/s, 6.03486s/100 iters), loss = 0.701479
I1210 20:44:55.958739  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 20:44:55.958739  8872 solver.cpp:237]     Train net output #1: loss = 0.701479 (* 1 = 0.701479 loss)
I1210 20:44:55.958739  8872 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1210 20:45:01.994243  8872 solver.cpp:218] Iteration 95400 (16.5706 iter/s, 6.03477s/100 iters), loss = 0.603815
I1210 20:45:01.994243  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 20:45:01.994243  8872 solver.cpp:237]     Train net output #1: loss = 0.603815 (* 1 = 0.603815 loss)
I1210 20:45:01.994243  8872 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1210 20:45:07.736824  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:45:07.976824  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_95500.caffemodel
I1210 20:45:07.993320  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_95500.solverstate
I1210 20:45:07.998319  8872 solver.cpp:330] Iteration 95500, Testing net (#0)
I1210 20:45:07.998319  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:45:09.334823 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:45:09.386323  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6747
I1210 20:45:09.386323  8872 solver.cpp:397]     Test net output #1: loss = 1.19319 (* 1 = 1.19319 loss)
I1210 20:45:09.444821  8872 solver.cpp:218] Iteration 95500 (13.4227 iter/s, 7.45005s/100 iters), loss = 0.561223
I1210 20:45:09.444821  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 20:45:09.444821  8872 solver.cpp:237]     Train net output #1: loss = 0.561223 (* 1 = 0.561223 loss)
I1210 20:45:09.444821  8872 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1210 20:45:15.481199  8872 solver.cpp:218] Iteration 95600 (16.5674 iter/s, 6.03596s/100 iters), loss = 0.534561
I1210 20:45:15.481199  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:45:15.481199  8872 solver.cpp:237]     Train net output #1: loss = 0.534561 (* 1 = 0.534561 loss)
I1210 20:45:15.481199  8872 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1210 20:45:21.503757  8872 solver.cpp:218] Iteration 95700 (16.6051 iter/s, 6.02223s/100 iters), loss = 0.528326
I1210 20:45:21.503757  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:45:21.503757  8872 solver.cpp:237]     Train net output #1: loss = 0.528326 (* 1 = 0.528326 loss)
I1210 20:45:21.503757  8872 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1210 20:45:27.544322  8872 solver.cpp:218] Iteration 95800 (16.556 iter/s, 6.04012s/100 iters), loss = 0.574966
I1210 20:45:27.544822  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:45:27.544822  8872 solver.cpp:237]     Train net output #1: loss = 0.574966 (* 1 = 0.574966 loss)
I1210 20:45:27.544822  8872 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1210 20:45:33.580406  8872 solver.cpp:218] Iteration 95900 (16.5683 iter/s, 6.03562s/100 iters), loss = 0.595524
I1210 20:45:33.580907  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 20:45:33.580907  8872 solver.cpp:237]     Train net output #1: loss = 0.595524 (* 1 = 0.595524 loss)
I1210 20:45:33.580907  8872 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1210 20:45:39.319279  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:45:39.557485  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_96000.caffemodel
I1210 20:45:39.573985  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_96000.solverstate
I1210 20:45:39.578985  8872 solver.cpp:330] Iteration 96000, Testing net (#0)
I1210 20:45:39.578985  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:45:40.903010 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:45:40.954509  8872 solver.cpp:397]     Test net output #0: accuracy = 0.677
I1210 20:45:40.954509  8872 solver.cpp:397]     Test net output #1: loss = 1.17917 (* 1 = 1.17917 loss)
I1210 20:45:41.012007  8872 solver.cpp:218] Iteration 96000 (13.4571 iter/s, 7.43103s/100 iters), loss = 0.592791
I1210 20:45:41.012007  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:45:41.012007  8872 solver.cpp:237]     Train net output #1: loss = 0.592791 (* 1 = 0.592791 loss)
I1210 20:45:41.012007  8872 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1210 20:45:47.053535  8872 solver.cpp:218] Iteration 96100 (16.5536 iter/s, 6.04097s/100 iters), loss = 0.638427
I1210 20:45:47.053535  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 20:45:47.053535  8872 solver.cpp:237]     Train net output #1: loss = 0.638427 (* 1 = 0.638427 loss)
I1210 20:45:47.053535  8872 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1210 20:45:53.085278  8872 solver.cpp:218] Iteration 96200 (16.581 iter/s, 6.03099s/100 iters), loss = 0.414217
I1210 20:45:53.085278  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:45:53.085278  8872 solver.cpp:237]     Train net output #1: loss = 0.414217 (* 1 = 0.414217 loss)
I1210 20:45:53.085278  8872 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1210 20:45:59.131471  8872 solver.cpp:218] Iteration 96300 (16.5408 iter/s, 6.04565s/100 iters), loss = 0.665447
I1210 20:45:59.131471  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:45:59.131471  8872 solver.cpp:237]     Train net output #1: loss = 0.665447 (* 1 = 0.665447 loss)
I1210 20:45:59.131471  8872 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1210 20:46:05.174249  8872 solver.cpp:218] Iteration 96400 (16.5504 iter/s, 6.04214s/100 iters), loss = 0.543227
I1210 20:46:05.174249  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:46:05.174249  8872 solver.cpp:237]     Train net output #1: loss = 0.543227 (* 1 = 0.543227 loss)
I1210 20:46:05.174249  8872 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1210 20:46:10.931370  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:46:11.168860  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_96500.caffemodel
I1210 20:46:11.184362  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_96500.solverstate
I1210 20:46:11.188859  8872 solver.cpp:330] Iteration 96500, Testing net (#0)
I1210 20:46:11.189360  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:46:12.513860 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:46:12.565362  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6747
I1210 20:46:12.565362  8872 solver.cpp:397]     Test net output #1: loss = 1.19022 (* 1 = 1.19022 loss)
I1210 20:46:12.621860  8872 solver.cpp:218] Iteration 96500 (13.4281 iter/s, 7.44709s/100 iters), loss = 0.598407
I1210 20:46:12.621860  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 20:46:12.621860  8872 solver.cpp:237]     Train net output #1: loss = 0.598407 (* 1 = 0.598407 loss)
I1210 20:46:12.621860  8872 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1210 20:46:18.672859  8872 solver.cpp:218] Iteration 96600 (16.5273 iter/s, 6.0506s/100 iters), loss = 0.559632
I1210 20:46:18.672859  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:46:18.672859  8872 solver.cpp:237]     Train net output #1: loss = 0.559632 (* 1 = 0.559632 loss)
I1210 20:46:18.672859  8872 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1210 20:46:24.722616  8872 solver.cpp:218] Iteration 96700 (16.5303 iter/s, 6.04951s/100 iters), loss = 0.408309
I1210 20:46:24.723116  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:46:24.723116  8872 solver.cpp:237]     Train net output #1: loss = 0.408309 (* 1 = 0.408309 loss)
I1210 20:46:24.723116  8872 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1210 20:46:30.765820  8872 solver.cpp:218] Iteration 96800 (16.5494 iter/s, 6.04253s/100 iters), loss = 0.551485
I1210 20:46:30.765820  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:46:30.765820  8872 solver.cpp:237]     Train net output #1: loss = 0.551485 (* 1 = 0.551485 loss)
I1210 20:46:30.765820  8872 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1210 20:46:36.801512  8872 solver.cpp:218] Iteration 96900 (16.5691 iter/s, 6.03535s/100 iters), loss = 0.596729
I1210 20:46:36.801512  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 20:46:36.801512  8872 solver.cpp:237]     Train net output #1: loss = 0.596729 (* 1 = 0.596729 loss)
I1210 20:46:36.801512  8872 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1210 20:46:42.544073  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:46:42.780073  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_97000.caffemodel
I1210 20:46:42.797070  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_97000.solverstate
I1210 20:46:42.802084  8872 solver.cpp:330] Iteration 97000, Testing net (#0)
I1210 20:46:42.802084  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:46:44.125584 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:46:44.178083  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6754
I1210 20:46:44.178083  8872 solver.cpp:397]     Test net output #1: loss = 1.18935 (* 1 = 1.18935 loss)
I1210 20:46:44.235589  8872 solver.cpp:218] Iteration 97000 (13.4528 iter/s, 7.43338s/100 iters), loss = 0.503563
I1210 20:46:44.235589  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:46:44.235589  8872 solver.cpp:237]     Train net output #1: loss = 0.503563 (* 1 = 0.503563 loss)
I1210 20:46:44.235589  8872 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1210 20:46:50.269290  8872 solver.cpp:218] Iteration 97100 (16.5749 iter/s, 6.03323s/100 iters), loss = 0.573815
I1210 20:46:50.269290  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 20:46:50.269290  8872 solver.cpp:237]     Train net output #1: loss = 0.573815 (* 1 = 0.573815 loss)
I1210 20:46:50.269290  8872 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1210 20:46:56.311879  8872 solver.cpp:218] Iteration 97200 (16.5503 iter/s, 6.04218s/100 iters), loss = 0.341437
I1210 20:46:56.311879  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 20:46:56.312381  8872 solver.cpp:237]     Train net output #1: loss = 0.341437 (* 1 = 0.341437 loss)
I1210 20:46:56.312381  8872 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1210 20:47:02.357379  8872 solver.cpp:218] Iteration 97300 (16.5436 iter/s, 6.04463s/100 iters), loss = 0.498804
I1210 20:47:02.357379  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:47:02.357379  8872 solver.cpp:237]     Train net output #1: loss = 0.498804 (* 1 = 0.498804 loss)
I1210 20:47:02.357379  8872 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1210 20:47:08.393379  8872 solver.cpp:218] Iteration 97400 (16.5678 iter/s, 6.03582s/100 iters), loss = 0.522561
I1210 20:47:08.393379  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:47:08.393379  8872 solver.cpp:237]     Train net output #1: loss = 0.522561 (* 1 = 0.522561 loss)
I1210 20:47:08.393379  8872 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1210 20:47:14.142880  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:47:14.380380  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_97500.caffemodel
I1210 20:47:14.394881  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_97500.solverstate
I1210 20:47:14.399879  8872 solver.cpp:330] Iteration 97500, Testing net (#0)
I1210 20:47:14.399879  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:47:15.724882 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:47:15.776381  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6756
I1210 20:47:15.776381  8872 solver.cpp:397]     Test net output #1: loss = 1.19186 (* 1 = 1.19186 loss)
I1210 20:47:15.833879  8872 solver.cpp:218] Iteration 97500 (13.4407 iter/s, 7.44008s/100 iters), loss = 0.501469
I1210 20:47:15.834379  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:47:15.834379  8872 solver.cpp:237]     Train net output #1: loss = 0.501469 (* 1 = 0.501469 loss)
I1210 20:47:15.834379  8872 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1210 20:47:21.912879  8872 solver.cpp:218] Iteration 97600 (16.4515 iter/s, 6.07846s/100 iters), loss = 0.511241
I1210 20:47:21.912879  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:47:21.912879  8872 solver.cpp:237]     Train net output #1: loss = 0.511241 (* 1 = 0.511241 loss)
I1210 20:47:21.912879  8872 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1210 20:47:27.989262  8872 solver.cpp:218] Iteration 97700 (16.459 iter/s, 6.07572s/100 iters), loss = 0.381973
I1210 20:47:27.989262  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 20:47:27.989262  8872 solver.cpp:237]     Train net output #1: loss = 0.381973 (* 1 = 0.381973 loss)
I1210 20:47:27.989262  8872 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1210 20:47:34.088412  8872 solver.cpp:218] Iteration 97800 (16.3979 iter/s, 6.09835s/100 iters), loss = 0.547305
I1210 20:47:34.088412  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:47:34.088412  8872 solver.cpp:237]     Train net output #1: loss = 0.547305 (* 1 = 0.547305 loss)
I1210 20:47:34.088412  8872 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1210 20:47:40.129910  8872 solver.cpp:218] Iteration 97900 (16.5534 iter/s, 6.04106s/100 iters), loss = 0.613601
I1210 20:47:40.129910  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 20:47:40.129910  8872 solver.cpp:237]     Train net output #1: loss = 0.613601 (* 1 = 0.613601 loss)
I1210 20:47:40.129910  8872 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1210 20:47:45.862776  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:47:46.101202  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_98000.caffemodel
I1210 20:47:46.123256  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_98000.solverstate
I1210 20:47:46.128255  8872 solver.cpp:330] Iteration 98000, Testing net (#0)
I1210 20:47:46.128255  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:47:47.449254 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:47:47.500769  8872 solver.cpp:397]     Test net output #0: accuracy = 0.677
I1210 20:47:47.501268  8872 solver.cpp:397]     Test net output #1: loss = 1.19606 (* 1 = 1.19606 loss)
I1210 20:47:47.558254  8872 solver.cpp:218] Iteration 98000 (13.4622 iter/s, 7.42818s/100 iters), loss = 0.510458
I1210 20:47:47.558755  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 20:47:47.558755  8872 solver.cpp:237]     Train net output #1: loss = 0.510458 (* 1 = 0.510458 loss)
I1210 20:47:47.558755  8872 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1210 20:47:53.589404  8872 solver.cpp:218] Iteration 98100 (16.5832 iter/s, 6.0302s/100 iters), loss = 0.529642
I1210 20:47:53.589404  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:47:53.589404  8872 solver.cpp:237]     Train net output #1: loss = 0.529642 (* 1 = 0.529642 loss)
I1210 20:47:53.589404  8872 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1210 20:47:59.634860  8872 solver.cpp:218] Iteration 98200 (16.5417 iter/s, 6.04532s/100 iters), loss = 0.352974
I1210 20:47:59.635361  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:47:59.635361  8872 solver.cpp:237]     Train net output #1: loss = 0.352974 (* 1 = 0.352974 loss)
I1210 20:47:59.635361  8872 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1210 20:48:05.674914  8872 solver.cpp:218] Iteration 98300 (16.5578 iter/s, 6.03946s/100 iters), loss = 0.518968
I1210 20:48:05.674914  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:48:05.674914  8872 solver.cpp:237]     Train net output #1: loss = 0.518968 (* 1 = 0.518968 loss)
I1210 20:48:05.674914  8872 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1210 20:48:11.718415  8872 solver.cpp:218] Iteration 98400 (16.5487 iter/s, 6.04276s/100 iters), loss = 0.594783
I1210 20:48:11.718415  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 20:48:11.718415  8872 solver.cpp:237]     Train net output #1: loss = 0.594783 (* 1 = 0.594783 loss)
I1210 20:48:11.718415  8872 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1210 20:48:17.456684  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:48:17.694025  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_98500.caffemodel
I1210 20:48:17.711024  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_98500.solverstate
I1210 20:48:17.716024  8872 solver.cpp:330] Iteration 98500, Testing net (#0)
I1210 20:48:17.716524  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:48:19.040526 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:48:19.092527  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6741
I1210 20:48:19.092527  8872 solver.cpp:397]     Test net output #1: loss = 1.19646 (* 1 = 1.19646 loss)
I1210 20:48:19.150526  8872 solver.cpp:218] Iteration 98500 (13.4562 iter/s, 7.43149s/100 iters), loss = 0.518703
I1210 20:48:19.150526  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:48:19.150526  8872 solver.cpp:237]     Train net output #1: loss = 0.518703 (* 1 = 0.518703 loss)
I1210 20:48:19.150526  8872 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1210 20:48:25.189026  8872 solver.cpp:218] Iteration 98600 (16.5617 iter/s, 6.03804s/100 iters), loss = 0.443126
I1210 20:48:25.189026  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:48:25.189026  8872 solver.cpp:237]     Train net output #1: loss = 0.443126 (* 1 = 0.443126 loss)
I1210 20:48:25.189026  8872 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1210 20:48:31.229524  8872 solver.cpp:218] Iteration 98700 (16.5557 iter/s, 6.0402s/100 iters), loss = 0.366622
I1210 20:48:31.229524  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:48:31.229524  8872 solver.cpp:237]     Train net output #1: loss = 0.366622 (* 1 = 0.366622 loss)
I1210 20:48:31.229524  8872 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1210 20:48:37.278386  8872 solver.cpp:218] Iteration 98800 (16.5336 iter/s, 6.04828s/100 iters), loss = 0.506148
I1210 20:48:37.278386  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:48:37.278386  8872 solver.cpp:237]     Train net output #1: loss = 0.506148 (* 1 = 0.506148 loss)
I1210 20:48:37.278386  8872 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1210 20:48:43.312712  8872 solver.cpp:218] Iteration 98900 (16.5735 iter/s, 6.03373s/100 iters), loss = 0.494702
I1210 20:48:43.312712  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 20:48:43.312712  8872 solver.cpp:237]     Train net output #1: loss = 0.494702 (* 1 = 0.494702 loss)
I1210 20:48:43.312712  8872 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1210 20:48:49.055677  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:48:49.291687  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_99000.caffemodel
I1210 20:48:49.309177  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_99000.solverstate
I1210 20:48:49.314177  8872 solver.cpp:330] Iteration 99000, Testing net (#0)
I1210 20:48:49.314177  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:48:50.636188 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:48:50.688186  8872 solver.cpp:397]     Test net output #0: accuracy = 0.676
I1210 20:48:50.688186  8872 solver.cpp:397]     Test net output #1: loss = 1.19377 (* 1 = 1.19377 loss)
I1210 20:48:50.744686  8872 solver.cpp:218] Iteration 99000 (13.456 iter/s, 7.43165s/100 iters), loss = 0.449609
I1210 20:48:50.744686  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:48:50.744686  8872 solver.cpp:237]     Train net output #1: loss = 0.449609 (* 1 = 0.449609 loss)
I1210 20:48:50.744686  8872 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1210 20:48:56.780686  8872 solver.cpp:218] Iteration 99100 (16.5681 iter/s, 6.03571s/100 iters), loss = 0.42938
I1210 20:48:56.780686  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:48:56.780686  8872 solver.cpp:237]     Train net output #1: loss = 0.42938 (* 1 = 0.42938 loss)
I1210 20:48:56.780686  8872 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1210 20:49:02.818199  8872 solver.cpp:218] Iteration 99200 (16.5651 iter/s, 6.03679s/100 iters), loss = 0.374159
I1210 20:49:02.818199  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 20:49:02.818199  8872 solver.cpp:237]     Train net output #1: loss = 0.374159 (* 1 = 0.374159 loss)
I1210 20:49:02.818199  8872 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1210 20:49:08.853416  8872 solver.cpp:218] Iteration 99300 (16.5706 iter/s, 6.03479s/100 iters), loss = 0.462124
I1210 20:49:08.853416  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 20:49:08.853416  8872 solver.cpp:237]     Train net output #1: loss = 0.462124 (* 1 = 0.462124 loss)
I1210 20:49:08.853416  8872 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1210 20:49:14.894009  8872 solver.cpp:218] Iteration 99400 (16.5555 iter/s, 6.04029s/100 iters), loss = 0.418451
I1210 20:49:14.894009  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:49:14.894009  8872 solver.cpp:237]     Train net output #1: loss = 0.418451 (* 1 = 0.418451 loss)
I1210 20:49:14.894009  8872 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1210 20:49:20.643151  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:49:20.884153  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_99500.caffemodel
I1210 20:49:20.901665  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_99500.solverstate
I1210 20:49:20.906649  8872 solver.cpp:330] Iteration 99500, Testing net (#0)
I1210 20:49:20.906649  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:49:22.234748 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:49:22.287235  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6782
I1210 20:49:22.287235  8872 solver.cpp:397]     Test net output #1: loss = 1.19798 (* 1 = 1.19798 loss)
I1210 20:49:22.344231  8872 solver.cpp:218] Iteration 99500 (13.4233 iter/s, 7.44973s/100 iters), loss = 0.457961
I1210 20:49:22.344231  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:49:22.344733  8872 solver.cpp:237]     Train net output #1: loss = 0.457961 (* 1 = 0.457961 loss)
I1210 20:49:22.344733  8872 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1210 20:49:28.391289  8872 solver.cpp:218] Iteration 99600 (16.5383 iter/s, 6.04658s/100 iters), loss = 0.462467
I1210 20:49:28.391777  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:49:28.391777  8872 solver.cpp:237]     Train net output #1: loss = 0.462467 (* 1 = 0.462467 loss)
I1210 20:49:28.391777  8872 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1210 20:49:34.441732  8872 solver.cpp:218] Iteration 99700 (16.5304 iter/s, 6.04946s/100 iters), loss = 0.380049
I1210 20:49:34.441732  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:49:34.441732  8872 solver.cpp:237]     Train net output #1: loss = 0.380049 (* 1 = 0.380049 loss)
I1210 20:49:34.441732  8872 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1210 20:49:40.472024  8872 solver.cpp:218] Iteration 99800 (16.5836 iter/s, 6.03006s/100 iters), loss = 0.505236
I1210 20:49:40.472024  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:49:40.472024  8872 solver.cpp:237]     Train net output #1: loss = 0.505236 (* 1 = 0.505236 loss)
I1210 20:49:40.472024  8872 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1210 20:49:46.520908  8872 solver.cpp:218] Iteration 99900 (16.534 iter/s, 6.04815s/100 iters), loss = 0.468868
I1210 20:49:46.520908  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:49:46.520908  8872 solver.cpp:237]     Train net output #1: loss = 0.468868 (* 1 = 0.468868 loss)
I1210 20:49:46.520908  8872 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1210 20:49:52.264825  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:49:52.501822  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_100000.caffemodel
I1210 20:49:52.517321  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_100000.solverstate
I1210 20:49:52.521822  8872 solver.cpp:330] Iteration 100000, Testing net (#0)
I1210 20:49:52.521822  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:49:53.843372 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:49:53.896374  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6732
I1210 20:49:53.896374  8872 solver.cpp:397]     Test net output #1: loss = 1.20486 (* 1 = 1.20486 loss)
I1210 20:49:53.953373  8872 solver.cpp:218] Iteration 100000 (13.4553 iter/s, 7.43202s/100 iters), loss = 0.426649
I1210 20:49:53.953373  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 20:49:53.953373  8872 solver.cpp:237]     Train net output #1: loss = 0.426649 (* 1 = 0.426649 loss)
I1210 20:49:53.953373  8872 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1210 20:50:00.009259  8872 solver.cpp:218] Iteration 100100 (16.5136 iter/s, 6.05563s/100 iters), loss = 0.51828
I1210 20:50:00.009259  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:50:00.009759  8872 solver.cpp:237]     Train net output #1: loss = 0.51828 (* 1 = 0.51828 loss)
I1210 20:50:00.009759  8872 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1210 20:50:06.090313  8872 solver.cpp:218] Iteration 100200 (16.4469 iter/s, 6.08018s/100 iters), loss = 0.349384
I1210 20:50:06.090313  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 20:50:06.090313  8872 solver.cpp:237]     Train net output #1: loss = 0.349384 (* 1 = 0.349384 loss)
I1210 20:50:06.090313  8872 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1210 20:50:12.157341  8872 solver.cpp:218] Iteration 100300 (16.4832 iter/s, 6.06677s/100 iters), loss = 0.468469
I1210 20:50:12.157341  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:50:12.157842  8872 solver.cpp:237]     Train net output #1: loss = 0.468469 (* 1 = 0.468469 loss)
I1210 20:50:12.157842  8872 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1210 20:50:18.210172  8872 solver.cpp:218] Iteration 100400 (16.5231 iter/s, 6.05215s/100 iters), loss = 0.511324
I1210 20:50:18.210172  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:50:18.210652  8872 solver.cpp:237]     Train net output #1: loss = 0.511324 (* 1 = 0.511324 loss)
I1210 20:50:18.210652  8872 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1210 20:50:23.953796  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:50:24.192287  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_100500.caffemodel
I1210 20:50:24.209288  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_100500.solverstate
I1210 20:50:24.214287  8872 solver.cpp:330] Iteration 100500, Testing net (#0)
I1210 20:50:24.214287  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:50:25.539288 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:50:25.590787  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6752
I1210 20:50:25.590787  8872 solver.cpp:397]     Test net output #1: loss = 1.19986 (* 1 = 1.19986 loss)
I1210 20:50:25.649287  8872 solver.cpp:218] Iteration 100500 (13.4443 iter/s, 7.43808s/100 iters), loss = 0.46475
I1210 20:50:25.649287  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:50:25.649287  8872 solver.cpp:237]     Train net output #1: loss = 0.46475 (* 1 = 0.46475 loss)
I1210 20:50:25.649287  8872 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1210 20:50:31.681339  8872 solver.cpp:218] Iteration 100600 (16.5784 iter/s, 6.03193s/100 iters), loss = 0.483375
I1210 20:50:31.681339  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:50:31.681339  8872 solver.cpp:237]     Train net output #1: loss = 0.483375 (* 1 = 0.483375 loss)
I1210 20:50:31.681339  8872 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1210 20:50:37.724530  8872 solver.cpp:218] Iteration 100700 (16.5498 iter/s, 6.04238s/100 iters), loss = 0.334566
I1210 20:50:37.724530  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 20:50:37.724530  8872 solver.cpp:237]     Train net output #1: loss = 0.334566 (* 1 = 0.334566 loss)
I1210 20:50:37.724530  8872 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1210 20:50:43.689744  8872 solver.cpp:218] Iteration 100800 (16.7649 iter/s, 5.96484s/100 iters), loss = 0.486832
I1210 20:50:43.689744  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:50:43.689744  8872 solver.cpp:237]     Train net output #1: loss = 0.486832 (* 1 = 0.486832 loss)
I1210 20:50:43.689744  8872 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1210 20:50:49.679445  8872 solver.cpp:218] Iteration 100900 (16.6961 iter/s, 5.98943s/100 iters), loss = 0.460124
I1210 20:50:49.679445  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:50:49.679445  8872 solver.cpp:237]     Train net output #1: loss = 0.460124 (* 1 = 0.460124 loss)
I1210 20:50:49.679445  8872 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1210 20:50:55.372594  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:50:55.607597  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_101000.caffemodel
I1210 20:50:55.624598  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_101000.solverstate
I1210 20:50:55.630594  8872 solver.cpp:330] Iteration 101000, Testing net (#0)
I1210 20:50:55.630594  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:50:56.939841 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:50:56.990844  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6745
I1210 20:50:56.990844  8872 solver.cpp:397]     Test net output #1: loss = 1.21342 (* 1 = 1.21342 loss)
I1210 20:50:57.047840  8872 solver.cpp:218] Iteration 101000 (13.5729 iter/s, 7.36764s/100 iters), loss = 0.484097
I1210 20:50:57.047840  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:50:57.047840  8872 solver.cpp:237]     Train net output #1: loss = 0.484097 (* 1 = 0.484097 loss)
I1210 20:50:57.047840  8872 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1210 20:51:03.163852  8872 solver.cpp:218] Iteration 101100 (16.3516 iter/s, 6.11561s/100 iters), loss = 0.475292
I1210 20:51:03.163852  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:51:03.163852  8872 solver.cpp:237]     Train net output #1: loss = 0.475292 (* 1 = 0.475292 loss)
I1210 20:51:03.163852  8872 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1210 20:51:09.201432  8872 solver.cpp:218] Iteration 101200 (16.5643 iter/s, 6.03706s/100 iters), loss = 0.373298
I1210 20:51:09.201432  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 20:51:09.201432  8872 solver.cpp:237]     Train net output #1: loss = 0.373298 (* 1 = 0.373298 loss)
I1210 20:51:09.201432  8872 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1210 20:51:15.238770  8872 solver.cpp:218] Iteration 101300 (16.5654 iter/s, 6.03668s/100 iters), loss = 0.475358
I1210 20:51:15.238770  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:51:15.238770  8872 solver.cpp:237]     Train net output #1: loss = 0.475358 (* 1 = 0.475358 loss)
I1210 20:51:15.238770  8872 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1210 20:51:21.268625  8872 solver.cpp:218] Iteration 101400 (16.5847 iter/s, 6.02966s/100 iters), loss = 0.494388
I1210 20:51:21.268625  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 20:51:21.268625  8872 solver.cpp:237]     Train net output #1: loss = 0.494388 (* 1 = 0.494388 loss)
I1210 20:51:21.268625  8872 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1210 20:51:27.006358  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:51:27.244372  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_101500.caffemodel
I1210 20:51:27.261873  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_101500.solverstate
I1210 20:51:27.266368  8872 solver.cpp:330] Iteration 101500, Testing net (#0)
I1210 20:51:27.266868  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:51:28.593857 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:51:28.644856  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6719
I1210 20:51:28.644856  8872 solver.cpp:397]     Test net output #1: loss = 1.21788 (* 1 = 1.21788 loss)
I1210 20:51:28.702363  8872 solver.cpp:218] Iteration 101500 (13.4531 iter/s, 7.43324s/100 iters), loss = 0.412347
I1210 20:51:28.702363  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:51:28.702363  8872 solver.cpp:237]     Train net output #1: loss = 0.412347 (* 1 = 0.412347 loss)
I1210 20:51:28.702363  8872 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1210 20:51:34.741389  8872 solver.cpp:218] Iteration 101600 (16.5606 iter/s, 6.03843s/100 iters), loss = 0.515714
I1210 20:51:34.741389  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:51:34.741389  8872 solver.cpp:237]     Train net output #1: loss = 0.515714 (* 1 = 0.515714 loss)
I1210 20:51:34.741389  8872 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1210 20:51:40.780604  8872 solver.cpp:218] Iteration 101700 (16.5591 iter/s, 6.03897s/100 iters), loss = 0.343094
I1210 20:51:40.780604  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 20:51:40.781105  8872 solver.cpp:237]     Train net output #1: loss = 0.343094 (* 1 = 0.343094 loss)
I1210 20:51:40.781105  8872 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1210 20:51:46.806087  8872 solver.cpp:218] Iteration 101800 (16.5984 iter/s, 6.02468s/100 iters), loss = 0.480318
I1210 20:51:46.806087  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:51:46.806087  8872 solver.cpp:237]     Train net output #1: loss = 0.480318 (* 1 = 0.480318 loss)
I1210 20:51:46.806087  8872 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1210 20:51:52.847586  8872 solver.cpp:218] Iteration 101900 (16.5531 iter/s, 6.04117s/100 iters), loss = 0.528185
I1210 20:51:52.847586  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:51:52.847586  8872 solver.cpp:237]     Train net output #1: loss = 0.528185 (* 1 = 0.528185 loss)
I1210 20:51:52.847586  8872 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1210 20:51:58.601662  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:51:58.838162  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_102000.caffemodel
I1210 20:51:58.855162  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_102000.solverstate
I1210 20:51:58.859663  8872 solver.cpp:330] Iteration 102000, Testing net (#0)
I1210 20:51:58.859663  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:52:00.183162 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:52:00.236162  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6717
I1210 20:52:00.236162  8872 solver.cpp:397]     Test net output #1: loss = 1.21898 (* 1 = 1.21898 loss)
I1210 20:52:00.293161  8872 solver.cpp:218] Iteration 102000 (13.4322 iter/s, 7.44482s/100 iters), loss = 0.402601
I1210 20:52:00.293161  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 20:52:00.293161  8872 solver.cpp:237]     Train net output #1: loss = 0.402601 (* 1 = 0.402601 loss)
I1210 20:52:00.293161  8872 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1210 20:52:06.334975  8872 solver.cpp:218] Iteration 102100 (16.5517 iter/s, 6.04169s/100 iters), loss = 0.449777
I1210 20:52:06.335475  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:52:06.335475  8872 solver.cpp:237]     Train net output #1: loss = 0.449777 (* 1 = 0.449777 loss)
I1210 20:52:06.335475  8872 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1210 20:52:12.374517  8872 solver.cpp:218] Iteration 102200 (16.5588 iter/s, 6.03908s/100 iters), loss = 0.317751
I1210 20:52:12.374517  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 20:52:12.375018  8872 solver.cpp:237]     Train net output #1: loss = 0.317751 (* 1 = 0.317751 loss)
I1210 20:52:12.375018  8872 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1210 20:52:18.406764  8872 solver.cpp:218] Iteration 102300 (16.5796 iter/s, 6.03151s/100 iters), loss = 0.435061
I1210 20:52:18.406764  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 20:52:18.406764  8872 solver.cpp:237]     Train net output #1: loss = 0.435061 (* 1 = 0.435061 loss)
I1210 20:52:18.406764  8872 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1210 20:52:24.449312  8872 solver.cpp:218] Iteration 102400 (16.5504 iter/s, 6.04215s/100 iters), loss = 0.478003
I1210 20:52:24.449312  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:52:24.449312  8872 solver.cpp:237]     Train net output #1: loss = 0.478003 (* 1 = 0.478003 loss)
I1210 20:52:24.449312  8872 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1210 20:52:30.186350  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:52:30.424350  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_102500.caffemodel
I1210 20:52:30.441849  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_102500.solverstate
I1210 20:52:30.446851  8872 solver.cpp:330] Iteration 102500, Testing net (#0)
I1210 20:52:30.446851  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:52:31.771850 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:52:31.823349  8872 solver.cpp:397]     Test net output #0: accuracy = 0.674
I1210 20:52:31.823349  8872 solver.cpp:397]     Test net output #1: loss = 1.22035 (* 1 = 1.22035 loss)
I1210 20:52:31.882849  8872 solver.cpp:218] Iteration 102500 (13.4539 iter/s, 7.43276s/100 iters), loss = 0.416914
I1210 20:52:31.882849  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:52:31.882849  8872 solver.cpp:237]     Train net output #1: loss = 0.416914 (* 1 = 0.416914 loss)
I1210 20:52:31.882849  8872 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1210 20:52:37.919867  8872 solver.cpp:218] Iteration 102600 (16.5654 iter/s, 6.03668s/100 iters), loss = 0.485412
I1210 20:52:37.919867  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:52:37.919867  8872 solver.cpp:237]     Train net output #1: loss = 0.485412 (* 1 = 0.485412 loss)
I1210 20:52:37.919867  8872 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1210 20:52:43.949102  8872 solver.cpp:218] Iteration 102700 (16.5872 iter/s, 6.02876s/100 iters), loss = 0.318284
I1210 20:52:43.949102  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 20:52:43.949102  8872 solver.cpp:237]     Train net output #1: loss = 0.318284 (* 1 = 0.318284 loss)
I1210 20:52:43.949102  8872 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1210 20:52:49.980931  8872 solver.cpp:218] Iteration 102800 (16.5801 iter/s, 6.03133s/100 iters), loss = 0.459979
I1210 20:52:49.980931  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:52:49.980931  8872 solver.cpp:237]     Train net output #1: loss = 0.459979 (* 1 = 0.459979 loss)
I1210 20:52:49.980931  8872 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1210 20:52:56.026231  8872 solver.cpp:218] Iteration 102900 (16.5434 iter/s, 6.04471s/100 iters), loss = 0.494858
I1210 20:52:56.026231  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:52:56.026231  8872 solver.cpp:237]     Train net output #1: loss = 0.494858 (* 1 = 0.494858 loss)
I1210 20:52:56.026231  8872 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1210 20:53:01.764595  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:53:02.000097  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_103000.caffemodel
I1210 20:53:02.016098  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_103000.solverstate
I1210 20:53:02.022598  8872 solver.cpp:330] Iteration 103000, Testing net (#0)
I1210 20:53:02.022598  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:53:03.344099 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:53:03.396096  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6699
I1210 20:53:03.396096  8872 solver.cpp:397]     Test net output #1: loss = 1.23432 (* 1 = 1.23432 loss)
I1210 20:53:03.453598  8872 solver.cpp:218] Iteration 103000 (13.4643 iter/s, 7.42705s/100 iters), loss = 0.384117
I1210 20:53:03.453598  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 20:53:03.453598  8872 solver.cpp:237]     Train net output #1: loss = 0.384117 (* 1 = 0.384117 loss)
I1210 20:53:03.453598  8872 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1210 20:53:09.499986  8872 solver.cpp:218] Iteration 103100 (16.5404 iter/s, 6.04581s/100 iters), loss = 0.375668
I1210 20:53:09.499986  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 20:53:09.499986  8872 solver.cpp:237]     Train net output #1: loss = 0.375668 (* 1 = 0.375668 loss)
I1210 20:53:09.499986  8872 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1210 20:53:15.544955  8872 solver.cpp:218] Iteration 103200 (16.5439 iter/s, 6.04451s/100 iters), loss = 0.382321
I1210 20:53:15.544955  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:53:15.544955  8872 solver.cpp:237]     Train net output #1: loss = 0.382321 (* 1 = 0.382321 loss)
I1210 20:53:15.544955  8872 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1210 20:53:21.578085  8872 solver.cpp:218] Iteration 103300 (16.5771 iter/s, 6.03242s/100 iters), loss = 0.513287
I1210 20:53:21.578085  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:53:21.578085  8872 solver.cpp:237]     Train net output #1: loss = 0.513287 (* 1 = 0.513287 loss)
I1210 20:53:21.578085  8872 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1210 20:53:27.616941  8872 solver.cpp:218] Iteration 103400 (16.5607 iter/s, 6.03839s/100 iters), loss = 0.409515
I1210 20:53:27.616941  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:53:27.616941  8872 solver.cpp:237]     Train net output #1: loss = 0.409515 (* 1 = 0.409515 loss)
I1210 20:53:27.616941  8872 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1210 20:53:33.355485  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:53:33.593472  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_103500.caffemodel
I1210 20:53:33.610467  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_103500.solverstate
I1210 20:53:33.615970  8872 solver.cpp:330] Iteration 103500, Testing net (#0)
I1210 20:53:33.615970  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:53:34.935986 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:53:34.987476  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6711
I1210 20:53:34.987476  8872 solver.cpp:397]     Test net output #1: loss = 1.23151 (* 1 = 1.23151 loss)
I1210 20:53:35.044968  8872 solver.cpp:218] Iteration 103500 (13.4632 iter/s, 7.42768s/100 iters), loss = 0.428728
I1210 20:53:35.045469  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 20:53:35.045469  8872 solver.cpp:237]     Train net output #1: loss = 0.428728 (* 1 = 0.428728 loss)
I1210 20:53:35.045469  8872 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1210 20:53:41.076073  8872 solver.cpp:218] Iteration 103600 (16.5822 iter/s, 6.03057s/100 iters), loss = 0.457199
I1210 20:53:41.076073  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:53:41.076073  8872 solver.cpp:237]     Train net output #1: loss = 0.457199 (* 1 = 0.457199 loss)
I1210 20:53:41.076073  8872 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1210 20:53:47.126075  8872 solver.cpp:218] Iteration 103700 (16.53 iter/s, 6.04962s/100 iters), loss = 0.347187
I1210 20:53:47.126574  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 20:53:47.126574  8872 solver.cpp:237]     Train net output #1: loss = 0.347187 (* 1 = 0.347187 loss)
I1210 20:53:47.126574  8872 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1210 20:53:53.167212  8872 solver.cpp:218] Iteration 103800 (16.5555 iter/s, 6.04028s/100 iters), loss = 0.481072
I1210 20:53:53.167212  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:53:53.167212  8872 solver.cpp:237]     Train net output #1: loss = 0.481072 (* 1 = 0.481072 loss)
I1210 20:53:53.167212  8872 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1210 20:53:59.238308  8872 solver.cpp:218] Iteration 103900 (16.4725 iter/s, 6.07073s/100 iters), loss = 0.438507
I1210 20:53:59.238308  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:53:59.238308  8872 solver.cpp:237]     Train net output #1: loss = 0.438507 (* 1 = 0.438507 loss)
I1210 20:53:59.238308  8872 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1210 20:54:04.992841  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:54:05.232842  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_104000.caffemodel
I1210 20:54:05.253841  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_104000.solverstate
I1210 20:54:05.259841  8872 solver.cpp:330] Iteration 104000, Testing net (#0)
I1210 20:54:05.259841  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:54:06.590840 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:54:06.642840  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6716
I1210 20:54:06.642840  8872 solver.cpp:397]     Test net output #1: loss = 1.22483 (* 1 = 1.22483 loss)
I1210 20:54:06.699350  8872 solver.cpp:218] Iteration 104000 (13.4035 iter/s, 7.46074s/100 iters), loss = 0.390351
I1210 20:54:06.699848  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 20:54:06.699848  8872 solver.cpp:237]     Train net output #1: loss = 0.390351 (* 1 = 0.390351 loss)
I1210 20:54:06.699848  8872 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1210 20:54:12.744841  8872 solver.cpp:218] Iteration 104100 (16.5435 iter/s, 6.04466s/100 iters), loss = 0.5104
I1210 20:54:12.744841  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:54:12.744841  8872 solver.cpp:237]     Train net output #1: loss = 0.5104 (* 1 = 0.5104 loss)
I1210 20:54:12.744841  8872 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1210 20:54:18.782719  8872 solver.cpp:218] Iteration 104200 (16.5637 iter/s, 6.03731s/100 iters), loss = 0.398113
I1210 20:54:18.782719  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 20:54:18.782719  8872 solver.cpp:237]     Train net output #1: loss = 0.398113 (* 1 = 0.398113 loss)
I1210 20:54:18.782719  8872 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1210 20:54:24.827219  8872 solver.cpp:218] Iteration 104300 (16.5452 iter/s, 6.04404s/100 iters), loss = 0.462389
I1210 20:54:24.827219  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:54:24.827219  8872 solver.cpp:237]     Train net output #1: loss = 0.462389 (* 1 = 0.462389 loss)
I1210 20:54:24.827219  8872 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1210 20:54:30.866329  8872 solver.cpp:218] Iteration 104400 (16.5602 iter/s, 6.03856s/100 iters), loss = 0.386009
I1210 20:54:30.866329  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:54:30.866329  8872 solver.cpp:237]     Train net output #1: loss = 0.386009 (* 1 = 0.386009 loss)
I1210 20:54:30.866329  8872 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1210 20:54:36.607771  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:54:36.845772  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_104500.caffemodel
I1210 20:54:36.861768  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_104500.solverstate
I1210 20:54:36.866259  8872 solver.cpp:330] Iteration 104500, Testing net (#0)
I1210 20:54:36.866259  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:54:38.190260 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:54:38.243268  8872 solver.cpp:397]     Test net output #0: accuracy = 0.671
I1210 20:54:38.243268  8872 solver.cpp:397]     Test net output #1: loss = 1.23325 (* 1 = 1.23325 loss)
I1210 20:54:38.301261  8872 solver.cpp:218] Iteration 104500 (13.4505 iter/s, 7.43466s/100 iters), loss = 0.415026
I1210 20:54:38.301261  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:54:38.301261  8872 solver.cpp:237]     Train net output #1: loss = 0.415026 (* 1 = 0.415026 loss)
I1210 20:54:38.301261  8872 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1210 20:54:44.331794  8872 solver.cpp:218] Iteration 104600 (16.5845 iter/s, 6.02972s/100 iters), loss = 0.42702
I1210 20:54:44.331794  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:54:44.331794  8872 solver.cpp:237]     Train net output #1: loss = 0.42702 (* 1 = 0.42702 loss)
I1210 20:54:44.331794  8872 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1210 20:54:50.363823  8872 solver.cpp:218] Iteration 104700 (16.5791 iter/s, 6.03168s/100 iters), loss = 0.287484
I1210 20:54:50.363823  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 20:54:50.363823  8872 solver.cpp:237]     Train net output #1: loss = 0.287484 (* 1 = 0.287484 loss)
I1210 20:54:50.363823  8872 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1210 20:54:56.407060  8872 solver.cpp:218] Iteration 104800 (16.549 iter/s, 6.04265s/100 iters), loss = 0.483462
I1210 20:54:56.407060  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:54:56.407060  8872 solver.cpp:237]     Train net output #1: loss = 0.483462 (* 1 = 0.483462 loss)
I1210 20:54:56.407060  8872 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1210 20:55:02.446357  8872 solver.cpp:218] Iteration 104900 (16.5586 iter/s, 6.03916s/100 iters), loss = 0.42964
I1210 20:55:02.446357  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:55:02.446357  8872 solver.cpp:237]     Train net output #1: loss = 0.42964 (* 1 = 0.42964 loss)
I1210 20:55:02.446357  8872 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1210 20:55:08.191857  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:55:08.431857  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_105000.caffemodel
I1210 20:55:08.451858  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_105000.solverstate
I1210 20:55:08.456858  8872 solver.cpp:330] Iteration 105000, Testing net (#0)
I1210 20:55:08.456858  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:55:09.779856 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:55:09.831857  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6718
I1210 20:55:09.831857  8872 solver.cpp:397]     Test net output #1: loss = 1.23749 (* 1 = 1.23749 loss)
I1210 20:55:09.890357  8872 solver.cpp:218] Iteration 105000 (13.4351 iter/s, 7.4432s/100 iters), loss = 0.420584
I1210 20:55:09.890357  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:55:09.890357  8872 solver.cpp:237]     Train net output #1: loss = 0.420584 (* 1 = 0.420584 loss)
I1210 20:55:09.890357  8872 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1210 20:55:15.924366  8872 solver.cpp:218] Iteration 105100 (16.574 iter/s, 6.03355s/100 iters), loss = 0.392377
I1210 20:55:15.924366  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:55:15.924366  8872 solver.cpp:237]     Train net output #1: loss = 0.392377 (* 1 = 0.392377 loss)
I1210 20:55:15.924366  8872 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1210 20:55:21.957026  8872 solver.cpp:218] Iteration 105200 (16.5783 iter/s, 6.03199s/100 iters), loss = 0.325201
I1210 20:55:21.957026  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 20:55:21.957026  8872 solver.cpp:237]     Train net output #1: loss = 0.325201 (* 1 = 0.325201 loss)
I1210 20:55:21.957026  8872 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1210 20:55:28.003063  8872 solver.cpp:218] Iteration 105300 (16.5412 iter/s, 6.04549s/100 iters), loss = 0.470503
I1210 20:55:28.003063  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:55:28.003063  8872 solver.cpp:237]     Train net output #1: loss = 0.470503 (* 1 = 0.470503 loss)
I1210 20:55:28.003063  8872 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1210 20:55:34.042104  8872 solver.cpp:218] Iteration 105400 (16.5595 iter/s, 6.03884s/100 iters), loss = 0.470226
I1210 20:55:34.042104  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 20:55:34.042104  8872 solver.cpp:237]     Train net output #1: loss = 0.470226 (* 1 = 0.470226 loss)
I1210 20:55:34.042104  8872 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1210 20:55:39.793604  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:55:40.030606  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_105500.caffemodel
I1210 20:55:40.050109  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_105500.solverstate
I1210 20:55:40.055105  8872 solver.cpp:330] Iteration 105500, Testing net (#0)
I1210 20:55:40.055105  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:55:41.378605 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:55:41.431105  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6735
I1210 20:55:41.431105  8872 solver.cpp:397]     Test net output #1: loss = 1.22616 (* 1 = 1.22616 loss)
I1210 20:55:41.488104  8872 solver.cpp:218] Iteration 105500 (13.4315 iter/s, 7.4452s/100 iters), loss = 0.458809
I1210 20:55:41.488104  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:55:41.488104  8872 solver.cpp:237]     Train net output #1: loss = 0.458809 (* 1 = 0.458809 loss)
I1210 20:55:41.488104  8872 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1210 20:55:47.525714  8872 solver.cpp:218] Iteration 105600 (16.5642 iter/s, 6.03713s/100 iters), loss = 0.410668
I1210 20:55:47.525714  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 20:55:47.525714  8872 solver.cpp:237]     Train net output #1: loss = 0.410668 (* 1 = 0.410668 loss)
I1210 20:55:47.525714  8872 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1210 20:55:53.563603  8872 solver.cpp:218] Iteration 105700 (16.5633 iter/s, 6.03743s/100 iters), loss = 0.326372
I1210 20:55:53.563603  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 20:55:53.563603  8872 solver.cpp:237]     Train net output #1: loss = 0.326372 (* 1 = 0.326372 loss)
I1210 20:55:53.563603  8872 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1210 20:55:59.605831  8872 solver.cpp:218] Iteration 105800 (16.551 iter/s, 6.04191s/100 iters), loss = 0.438795
I1210 20:55:59.605831  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:55:59.605831  8872 solver.cpp:237]     Train net output #1: loss = 0.438795 (* 1 = 0.438795 loss)
I1210 20:55:59.605831  8872 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1210 20:56:05.640944  8872 solver.cpp:218] Iteration 105900 (16.5713 iter/s, 6.03453s/100 iters), loss = 0.470491
I1210 20:56:05.640944  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:56:05.640944  8872 solver.cpp:237]     Train net output #1: loss = 0.470491 (* 1 = 0.470491 loss)
I1210 20:56:05.640944  8872 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1210 20:56:11.376045  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:56:11.614545  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_106000.caffemodel
I1210 20:56:11.632545  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_106000.solverstate
I1210 20:56:11.637545  8872 solver.cpp:330] Iteration 106000, Testing net (#0)
I1210 20:56:11.637545  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:56:12.970052 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:56:13.021554  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6714
I1210 20:56:13.021554  8872 solver.cpp:397]     Test net output #1: loss = 1.23281 (* 1 = 1.23281 loss)
I1210 20:56:13.079552  8872 solver.cpp:218] Iteration 106000 (13.4443 iter/s, 7.43812s/100 iters), loss = 0.457675
I1210 20:56:13.079552  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:56:13.079552  8872 solver.cpp:237]     Train net output #1: loss = 0.457675 (* 1 = 0.457675 loss)
I1210 20:56:13.079552  8872 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1210 20:56:19.114450  8872 solver.cpp:218] Iteration 106100 (16.5715 iter/s, 6.03444s/100 iters), loss = 0.4014
I1210 20:56:19.114450  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:56:19.114450  8872 solver.cpp:237]     Train net output #1: loss = 0.4014 (* 1 = 0.4014 loss)
I1210 20:56:19.114450  8872 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1210 20:56:25.157151  8872 solver.cpp:218] Iteration 106200 (16.5501 iter/s, 6.04224s/100 iters), loss = 0.332534
I1210 20:56:25.157151  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 20:56:25.157151  8872 solver.cpp:237]     Train net output #1: loss = 0.332534 (* 1 = 0.332534 loss)
I1210 20:56:25.157151  8872 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1210 20:56:31.190668  8872 solver.cpp:218] Iteration 106300 (16.5754 iter/s, 6.03303s/100 iters), loss = 0.419475
I1210 20:56:31.190668  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:56:31.190668  8872 solver.cpp:237]     Train net output #1: loss = 0.419475 (* 1 = 0.419475 loss)
I1210 20:56:31.190668  8872 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1210 20:56:37.233669  8872 solver.cpp:218] Iteration 106400 (16.5489 iter/s, 6.04271s/100 iters), loss = 0.485098
I1210 20:56:37.233669  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:56:37.233669  8872 solver.cpp:237]     Train net output #1: loss = 0.485098 (* 1 = 0.485098 loss)
I1210 20:56:37.234169  8872 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1210 20:56:42.977039  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:56:43.214040  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_106500.caffemodel
I1210 20:56:43.230540  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_106500.solverstate
I1210 20:56:43.235041  8872 solver.cpp:330] Iteration 106500, Testing net (#0)
I1210 20:56:43.235041  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:56:44.556052 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:56:44.609040  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6734
I1210 20:56:44.609040  8872 solver.cpp:397]     Test net output #1: loss = 1.23422 (* 1 = 1.23422 loss)
I1210 20:56:44.667040  8872 solver.cpp:218] Iteration 106500 (13.4542 iter/s, 7.43262s/100 iters), loss = 0.349934
I1210 20:56:44.667040  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:56:44.667040  8872 solver.cpp:237]     Train net output #1: loss = 0.349934 (* 1 = 0.349934 loss)
I1210 20:56:44.667040  8872 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1210 20:56:50.706100  8872 solver.cpp:218] Iteration 106600 (16.5596 iter/s, 6.03881s/100 iters), loss = 0.44399
I1210 20:56:50.706100  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 20:56:50.706603  8872 solver.cpp:237]     Train net output #1: loss = 0.44399 (* 1 = 0.44399 loss)
I1210 20:56:50.706603  8872 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1210 20:56:56.738607  8872 solver.cpp:218] Iteration 106700 (16.5781 iter/s, 6.03204s/100 iters), loss = 0.273852
I1210 20:56:56.739109  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 20:56:56.739109  8872 solver.cpp:237]     Train net output #1: loss = 0.273852 (* 1 = 0.273852 loss)
I1210 20:56:56.739109  8872 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1210 20:57:02.771607  8872 solver.cpp:218] Iteration 106800 (16.5777 iter/s, 6.03219s/100 iters), loss = 0.447607
I1210 20:57:02.771607  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:57:02.771607  8872 solver.cpp:237]     Train net output #1: loss = 0.447607 (* 1 = 0.447607 loss)
I1210 20:57:02.771607  8872 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1210 20:57:08.812108  8872 solver.cpp:218] Iteration 106900 (16.5554 iter/s, 6.04031s/100 iters), loss = 0.397162
I1210 20:57:08.812608  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:57:08.812608  8872 solver.cpp:237]     Train net output #1: loss = 0.397162 (* 1 = 0.397162 loss)
I1210 20:57:08.812608  8872 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1210 20:57:14.592640  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:57:14.830130  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_107000.caffemodel
I1210 20:57:14.847131  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_107000.solverstate
I1210 20:57:14.852131  8872 solver.cpp:330] Iteration 107000, Testing net (#0)
I1210 20:57:14.852131  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:57:16.177631 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:57:16.228638  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6698
I1210 20:57:16.228638  8872 solver.cpp:397]     Test net output #1: loss = 1.25449 (* 1 = 1.25449 loss)
I1210 20:57:16.288130  8872 solver.cpp:218] Iteration 107000 (13.3775 iter/s, 7.47524s/100 iters), loss = 0.439272
I1210 20:57:16.288130  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:57:16.288130  8872 solver.cpp:237]     Train net output #1: loss = 0.439272 (* 1 = 0.439272 loss)
I1210 20:57:16.288130  8872 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1210 20:57:22.324321  8872 solver.cpp:218] Iteration 107100 (16.5681 iter/s, 6.03569s/100 iters), loss = 0.536685
I1210 20:57:22.324321  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 20:57:22.324321  8872 solver.cpp:237]     Train net output #1: loss = 0.536685 (* 1 = 0.536685 loss)
I1210 20:57:22.324321  8872 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1210 20:57:28.385363  8872 solver.cpp:218] Iteration 107200 (16.5002 iter/s, 6.06051s/100 iters), loss = 0.245853
I1210 20:57:28.385363  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 20:57:28.385363  8872 solver.cpp:237]     Train net output #1: loss = 0.245853 (* 1 = 0.245853 loss)
I1210 20:57:28.385363  8872 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1210 20:57:34.419376  8872 solver.cpp:218] Iteration 107300 (16.5738 iter/s, 6.03363s/100 iters), loss = 0.457094
I1210 20:57:34.419376  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:57:34.419376  8872 solver.cpp:237]     Train net output #1: loss = 0.457094 (* 1 = 0.457094 loss)
I1210 20:57:34.419376  8872 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1210 20:57:40.452394  8872 solver.cpp:218] Iteration 107400 (16.5774 iter/s, 6.03231s/100 iters), loss = 0.524814
I1210 20:57:40.452394  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 20:57:40.452394  8872 solver.cpp:237]     Train net output #1: loss = 0.524814 (* 1 = 0.524814 loss)
I1210 20:57:40.452394  8872 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1210 20:57:46.199470  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:57:46.437954  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_107500.caffemodel
I1210 20:57:46.452955  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_107500.solverstate
I1210 20:57:46.457955  8872 solver.cpp:330] Iteration 107500, Testing net (#0)
I1210 20:57:46.458454  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:57:47.779026 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:57:47.831018  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6746
I1210 20:57:47.831018  8872 solver.cpp:397]     Test net output #1: loss = 1.23686 (* 1 = 1.23686 loss)
I1210 20:57:47.887526  8872 solver.cpp:218] Iteration 107500 (13.45 iter/s, 7.43494s/100 iters), loss = 0.40033
I1210 20:57:47.888031  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 20:57:47.888031  8872 solver.cpp:237]     Train net output #1: loss = 0.40033 (* 1 = 0.40033 loss)
I1210 20:57:47.888031  8872 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1210 20:57:53.926123  8872 solver.cpp:218] Iteration 107600 (16.5617 iter/s, 6.03804s/100 iters), loss = 0.441195
I1210 20:57:53.926625  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 20:57:53.926625  8872 solver.cpp:237]     Train net output #1: loss = 0.441195 (* 1 = 0.441195 loss)
I1210 20:57:53.926625  8872 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1210 20:57:59.955916  8872 solver.cpp:218] Iteration 107700 (16.587 iter/s, 6.02881s/100 iters), loss = 0.299958
I1210 20:57:59.955916  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 20:57:59.955916  8872 solver.cpp:237]     Train net output #1: loss = 0.299958 (* 1 = 0.299958 loss)
I1210 20:57:59.955916  8872 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1210 20:58:05.989647  8872 solver.cpp:218] Iteration 107800 (16.5743 iter/s, 6.03345s/100 iters), loss = 0.377384
I1210 20:58:05.989647  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:58:05.989647  8872 solver.cpp:237]     Train net output #1: loss = 0.377384 (* 1 = 0.377384 loss)
I1210 20:58:05.989647  8872 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1210 20:58:12.033396  8872 solver.cpp:218] Iteration 107900 (16.5479 iter/s, 6.04308s/100 iters), loss = 0.473195
I1210 20:58:12.033396  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:58:12.033396  8872 solver.cpp:237]     Train net output #1: loss = 0.473195 (* 1 = 0.473195 loss)
I1210 20:58:12.033396  8872 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1210 20:58:17.769886  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:58:18.008019  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_108000.caffemodel
I1210 20:58:18.025521  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_108000.solverstate
I1210 20:58:18.031518  8872 solver.cpp:330] Iteration 108000, Testing net (#0)
I1210 20:58:18.031518  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:58:19.354019 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:58:19.405519  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6696
I1210 20:58:19.406019  8872 solver.cpp:397]     Test net output #1: loss = 1.24203 (* 1 = 1.24203 loss)
I1210 20:58:19.462524  8872 solver.cpp:218] Iteration 108000 (13.4613 iter/s, 7.42869s/100 iters), loss = 0.368084
I1210 20:58:19.462524  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:58:19.462524  8872 solver.cpp:237]     Train net output #1: loss = 0.368084 (* 1 = 0.368084 loss)
I1210 20:58:19.462524  8872 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1210 20:58:25.501018  8872 solver.cpp:218] Iteration 108100 (16.5617 iter/s, 6.03802s/100 iters), loss = 0.4581
I1210 20:58:25.501018  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:58:25.501018  8872 solver.cpp:237]     Train net output #1: loss = 0.4581 (* 1 = 0.4581 loss)
I1210 20:58:25.501018  8872 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1210 20:58:31.535055  8872 solver.cpp:218] Iteration 108200 (16.5744 iter/s, 6.03338s/100 iters), loss = 0.289002
I1210 20:58:31.535055  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 20:58:31.535055  8872 solver.cpp:237]     Train net output #1: loss = 0.289002 (* 1 = 0.289002 loss)
I1210 20:58:31.535055  8872 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1210 20:58:37.557893  8872 solver.cpp:218] Iteration 108300 (16.6038 iter/s, 6.02272s/100 iters), loss = 0.401213
I1210 20:58:37.558394  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:58:37.558394  8872 solver.cpp:237]     Train net output #1: loss = 0.401213 (* 1 = 0.401213 loss)
I1210 20:58:37.558394  8872 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1210 20:58:43.589903  8872 solver.cpp:218] Iteration 108400 (16.5809 iter/s, 6.03102s/100 iters), loss = 0.460341
I1210 20:58:43.589903  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 20:58:43.589903  8872 solver.cpp:237]     Train net output #1: loss = 0.460341 (* 1 = 0.460341 loss)
I1210 20:58:43.589903  8872 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1210 20:58:49.328917  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:58:49.566917  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_108500.caffemodel
I1210 20:58:49.582916  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_108500.solverstate
I1210 20:58:49.587915  8872 solver.cpp:330] Iteration 108500, Testing net (#0)
I1210 20:58:49.587915  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:58:50.911417 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:58:50.963918  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6693
I1210 20:58:50.963918  8872 solver.cpp:397]     Test net output #1: loss = 1.24902 (* 1 = 1.24902 loss)
I1210 20:58:51.020417  8872 solver.cpp:218] Iteration 108500 (13.4586 iter/s, 7.43019s/100 iters), loss = 0.459219
I1210 20:58:51.020918  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 20:58:51.020918  8872 solver.cpp:237]     Train net output #1: loss = 0.459219 (* 1 = 0.459219 loss)
I1210 20:58:51.020918  8872 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1210 20:58:57.052677  8872 solver.cpp:218] Iteration 108600 (16.5796 iter/s, 6.0315s/100 iters), loss = 0.447659
I1210 20:58:57.052677  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:58:57.052677  8872 solver.cpp:237]     Train net output #1: loss = 0.447659 (* 1 = 0.447659 loss)
I1210 20:58:57.052677  8872 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1210 20:59:03.090617  8872 solver.cpp:218] Iteration 108700 (16.5639 iter/s, 6.03724s/100 iters), loss = 0.295314
I1210 20:59:03.090617  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 20:59:03.090617  8872 solver.cpp:237]     Train net output #1: loss = 0.295314 (* 1 = 0.295314 loss)
I1210 20:59:03.090617  8872 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1210 20:59:09.135159  8872 solver.cpp:218] Iteration 108800 (16.5455 iter/s, 6.04395s/100 iters), loss = 0.440709
I1210 20:59:09.135159  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:59:09.135159  8872 solver.cpp:237]     Train net output #1: loss = 0.440709 (* 1 = 0.440709 loss)
I1210 20:59:09.135159  8872 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1210 20:59:15.191361  8872 solver.cpp:218] Iteration 108900 (16.5129 iter/s, 6.05588s/100 iters), loss = 0.472675
I1210 20:59:15.191361  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:59:15.191361  8872 solver.cpp:237]     Train net output #1: loss = 0.472675 (* 1 = 0.472675 loss)
I1210 20:59:15.191361  8872 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1210 20:59:20.934849  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:59:21.174399  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_109000.caffemodel
I1210 20:59:21.191399  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_109000.solverstate
I1210 20:59:21.196399  8872 solver.cpp:330] Iteration 109000, Testing net (#0)
I1210 20:59:21.196399  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:59:22.519398 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:59:22.570900  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6681
I1210 20:59:22.570900  8872 solver.cpp:397]     Test net output #1: loss = 1.2568 (* 1 = 1.2568 loss)
I1210 20:59:22.629899  8872 solver.cpp:218] Iteration 109000 (13.4444 iter/s, 7.43804s/100 iters), loss = 0.362025
I1210 20:59:22.629899  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 20:59:22.629899  8872 solver.cpp:237]     Train net output #1: loss = 0.362025 (* 1 = 0.362025 loss)
I1210 20:59:22.629899  8872 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1210 20:59:28.664899  8872 solver.cpp:218] Iteration 109100 (16.5709 iter/s, 6.03467s/100 iters), loss = 0.46432
I1210 20:59:28.664899  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 20:59:28.664899  8872 solver.cpp:237]     Train net output #1: loss = 0.46432 (* 1 = 0.46432 loss)
I1210 20:59:28.664899  8872 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1210 20:59:34.697624  8872 solver.cpp:218] Iteration 109200 (16.578 iter/s, 6.03208s/100 iters), loss = 0.322238
I1210 20:59:34.697624  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 20:59:34.697624  8872 solver.cpp:237]     Train net output #1: loss = 0.322238 (* 1 = 0.322238 loss)
I1210 20:59:34.697624  8872 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1210 20:59:40.735440  8872 solver.cpp:218] Iteration 109300 (16.5629 iter/s, 6.03759s/100 iters), loss = 0.44101
I1210 20:59:40.735940  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:59:40.735940  8872 solver.cpp:237]     Train net output #1: loss = 0.44101 (* 1 = 0.44101 loss)
I1210 20:59:40.735940  8872 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1210 20:59:46.786631  8872 solver.cpp:218] Iteration 109400 (16.5273 iter/s, 6.0506s/100 iters), loss = 0.451139
I1210 20:59:46.786631  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:59:46.786631  8872 solver.cpp:237]     Train net output #1: loss = 0.451139 (* 1 = 0.451139 loss)
I1210 20:59:46.786631  8872 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1210 20:59:52.532132  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:59:52.770632  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_109500.caffemodel
I1210 20:59:52.790633  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_109500.solverstate
I1210 20:59:52.796135  8872 solver.cpp:330] Iteration 109500, Testing net (#0)
I1210 20:59:52.796135  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 20:59:54.119632 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 20:59:54.171633  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6681
I1210 20:59:54.171633  8872 solver.cpp:397]     Test net output #1: loss = 1.26558 (* 1 = 1.26558 loss)
I1210 20:59:54.229130  8872 solver.cpp:218] Iteration 109500 (13.4378 iter/s, 7.44172s/100 iters), loss = 0.381689
I1210 20:59:54.229130  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 20:59:54.229130  8872 solver.cpp:237]     Train net output #1: loss = 0.381689 (* 1 = 0.381689 loss)
I1210 20:59:54.229130  8872 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1210 21:00:00.277631  8872 solver.cpp:218] Iteration 109600 (16.5345 iter/s, 6.04798s/100 iters), loss = 0.424767
I1210 21:00:00.277631  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:00:00.277631  8872 solver.cpp:237]     Train net output #1: loss = 0.424768 (* 1 = 0.424768 loss)
I1210 21:00:00.277631  8872 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1210 21:00:06.347743  8872 solver.cpp:218] Iteration 109700 (16.4751 iter/s, 6.06976s/100 iters), loss = 0.320447
I1210 21:00:06.347743  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:00:06.347743  8872 solver.cpp:237]     Train net output #1: loss = 0.320447 (* 1 = 0.320447 loss)
I1210 21:00:06.347743  8872 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1210 21:00:12.391125  8872 solver.cpp:218] Iteration 109800 (16.5487 iter/s, 6.04278s/100 iters), loss = 0.371419
I1210 21:00:12.391125  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:00:12.391125  8872 solver.cpp:237]     Train net output #1: loss = 0.371419 (* 1 = 0.371419 loss)
I1210 21:00:12.391125  8872 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1210 21:00:18.427170  8872 solver.cpp:218] Iteration 109900 (16.568 iter/s, 6.03572s/100 iters), loss = 0.478853
I1210 21:00:18.427170  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:00:18.427170  8872 solver.cpp:237]     Train net output #1: loss = 0.478853 (* 1 = 0.478853 loss)
I1210 21:00:18.427170  8872 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1210 21:00:24.175441  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:00:24.414942  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_110000.caffemodel
I1210 21:00:24.430440  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_110000.solverstate
I1210 21:00:24.435438  8872 solver.cpp:330] Iteration 110000, Testing net (#0)
I1210 21:00:24.435438  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:00:25.757493 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:00:25.809492  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6697
I1210 21:00:25.809492  8872 solver.cpp:397]     Test net output #1: loss = 1.25812 (* 1 = 1.25812 loss)
I1210 21:00:25.866997  8872 solver.cpp:218] Iteration 110000 (13.4422 iter/s, 7.43925s/100 iters), loss = 0.281248
I1210 21:00:25.866997  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:00:25.866997  8872 solver.cpp:237]     Train net output #1: loss = 0.281248 (* 1 = 0.281248 loss)
I1210 21:00:25.867493  8872 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1210 21:00:31.901928  8872 solver.cpp:218] Iteration 110100 (16.5721 iter/s, 6.03424s/100 iters), loss = 0.408932
I1210 21:00:31.901928  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:00:31.901928  8872 solver.cpp:237]     Train net output #1: loss = 0.408932 (* 1 = 0.408932 loss)
I1210 21:00:31.901928  8872 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1210 21:00:37.943627  8872 solver.cpp:218] Iteration 110200 (16.5533 iter/s, 6.04111s/100 iters), loss = 0.342714
I1210 21:00:37.943627  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:00:37.943627  8872 solver.cpp:237]     Train net output #1: loss = 0.342715 (* 1 = 0.342715 loss)
I1210 21:00:37.943627  8872 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1210 21:00:43.994627  8872 solver.cpp:218] Iteration 110300 (16.5271 iter/s, 6.05066s/100 iters), loss = 0.464453
I1210 21:00:43.994627  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:00:43.994627  8872 solver.cpp:237]     Train net output #1: loss = 0.464453 (* 1 = 0.464453 loss)
I1210 21:00:43.994627  8872 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1210 21:00:50.039127  8872 solver.cpp:218] Iteration 110400 (16.5462 iter/s, 6.04369s/100 iters), loss = 0.429153
I1210 21:00:50.039127  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 21:00:50.039127  8872 solver.cpp:237]     Train net output #1: loss = 0.429153 (* 1 = 0.429153 loss)
I1210 21:00:50.039127  8872 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1210 21:00:55.775866  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:00:56.013365  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_110500.caffemodel
I1210 21:00:56.031363  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_110500.solverstate
I1210 21:00:56.036864  8872 solver.cpp:330] Iteration 110500, Testing net (#0)
I1210 21:00:56.037364  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:00:57.361865 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:00:57.413877  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6695
I1210 21:00:57.414378  8872 solver.cpp:397]     Test net output #1: loss = 1.25864 (* 1 = 1.25864 loss)
I1210 21:00:57.471377  8872 solver.cpp:218] Iteration 110500 (13.4558 iter/s, 7.43173s/100 iters), loss = 0.334705
I1210 21:00:57.471377  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:00:57.471377  8872 solver.cpp:237]     Train net output #1: loss = 0.334706 (* 1 = 0.334706 loss)
I1210 21:00:57.471377  8872 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1210 21:01:03.520556  8872 solver.cpp:218] Iteration 110600 (16.5325 iter/s, 6.0487s/100 iters), loss = 0.442322
I1210 21:01:03.520556  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:01:03.520556  8872 solver.cpp:237]     Train net output #1: loss = 0.442322 (* 1 = 0.442322 loss)
I1210 21:01:03.520556  8872 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1210 21:01:09.561985  8872 solver.cpp:218] Iteration 110700 (16.5524 iter/s, 6.04143s/100 iters), loss = 0.353273
I1210 21:01:09.562485  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:01:09.562485  8872 solver.cpp:237]     Train net output #1: loss = 0.353273 (* 1 = 0.353273 loss)
I1210 21:01:09.562485  8872 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1210 21:01:15.592981  8872 solver.cpp:218] Iteration 110800 (16.5828 iter/s, 6.03033s/100 iters), loss = 0.362415
I1210 21:01:15.592981  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:01:15.592981  8872 solver.cpp:237]     Train net output #1: loss = 0.362415 (* 1 = 0.362415 loss)
I1210 21:01:15.592981  8872 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1210 21:01:21.621894  8872 solver.cpp:218] Iteration 110900 (16.5884 iter/s, 6.0283s/100 iters), loss = 0.412433
I1210 21:01:21.621894  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:01:21.621894  8872 solver.cpp:237]     Train net output #1: loss = 0.412433 (* 1 = 0.412433 loss)
I1210 21:01:21.621894  8872 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1210 21:01:27.368113  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:01:27.606114  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_111000.caffemodel
I1210 21:01:27.622611  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_111000.solverstate
I1210 21:01:27.628113  8872 solver.cpp:330] Iteration 111000, Testing net (#0)
I1210 21:01:27.628113  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:01:28.950660 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:01:29.002161  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6699
I1210 21:01:29.002161  8872 solver.cpp:397]     Test net output #1: loss = 1.26048 (* 1 = 1.26048 loss)
I1210 21:01:29.060160  8872 solver.cpp:218] Iteration 111000 (13.4451 iter/s, 7.43767s/100 iters), loss = 0.384046
I1210 21:01:29.060160  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:01:29.060160  8872 solver.cpp:237]     Train net output #1: loss = 0.384046 (* 1 = 0.384046 loss)
I1210 21:01:29.060160  8872 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1210 21:01:35.100925  8872 solver.cpp:218] Iteration 111100 (16.5552 iter/s, 6.0404s/100 iters), loss = 0.352788
I1210 21:01:35.100925  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:01:35.100925  8872 solver.cpp:237]     Train net output #1: loss = 0.352788 (* 1 = 0.352788 loss)
I1210 21:01:35.100925  8872 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1210 21:01:41.205970  8872 solver.cpp:218] Iteration 111200 (16.3799 iter/s, 6.10504s/100 iters), loss = 0.25662
I1210 21:01:41.206967  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:01:41.206967  8872 solver.cpp:237]     Train net output #1: loss = 0.25662 (* 1 = 0.25662 loss)
I1210 21:01:41.206967  8872 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1210 21:01:47.503468  8872 solver.cpp:218] Iteration 111300 (15.8823 iter/s, 6.29634s/100 iters), loss = 0.33495
I1210 21:01:47.503468  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:01:47.503468  8872 solver.cpp:237]     Train net output #1: loss = 0.33495 (* 1 = 0.33495 loss)
I1210 21:01:47.503468  8872 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1210 21:01:53.447556  8872 solver.cpp:218] Iteration 111400 (16.8254 iter/s, 5.94339s/100 iters), loss = 0.486247
I1210 21:01:53.447556  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:01:53.447556  8872 solver.cpp:237]     Train net output #1: loss = 0.486247 (* 1 = 0.486247 loss)
I1210 21:01:53.447556  8872 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1210 21:01:59.163496  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:01:59.404410  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_111500.caffemodel
I1210 21:01:59.420413  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_111500.solverstate
I1210 21:01:59.426409  8872 solver.cpp:330] Iteration 111500, Testing net (#0)
I1210 21:01:59.426409  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:02:00.764012 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:02:00.805788  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6694
I1210 21:02:00.805788  8872 solver.cpp:397]     Test net output #1: loss = 1.2647 (* 1 = 1.2647 loss)
I1210 21:02:00.862788  8872 solver.cpp:218] Iteration 111500 (13.4865 iter/s, 7.41482s/100 iters), loss = 0.315734
I1210 21:02:00.862788  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:02:00.862788  8872 solver.cpp:237]     Train net output #1: loss = 0.315734 (* 1 = 0.315734 loss)
I1210 21:02:00.862788  8872 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1210 21:02:06.871561  8872 solver.cpp:218] Iteration 111600 (16.644 iter/s, 6.00819s/100 iters), loss = 0.341486
I1210 21:02:06.871561  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:02:06.871561  8872 solver.cpp:237]     Train net output #1: loss = 0.341486 (* 1 = 0.341486 loss)
I1210 21:02:06.871561  8872 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1210 21:02:12.838533  8872 solver.cpp:218] Iteration 111700 (16.7599 iter/s, 5.96663s/100 iters), loss = 0.306981
I1210 21:02:12.838533  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:02:12.838533  8872 solver.cpp:237]     Train net output #1: loss = 0.306981 (* 1 = 0.306981 loss)
I1210 21:02:12.838533  8872 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1210 21:02:18.771311  8872 solver.cpp:218] Iteration 111800 (16.8563 iter/s, 5.93249s/100 iters), loss = 0.417832
I1210 21:02:18.771311  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:02:18.771311  8872 solver.cpp:237]     Train net output #1: loss = 0.417832 (* 1 = 0.417832 loss)
I1210 21:02:18.771311  8872 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1210 21:02:24.734807  8872 solver.cpp:218] Iteration 111900 (16.7709 iter/s, 5.96269s/100 iters), loss = 0.444341
I1210 21:02:24.734807  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 21:02:24.734807  8872 solver.cpp:237]     Train net output #1: loss = 0.444341 (* 1 = 0.444341 loss)
I1210 21:02:24.734807  8872 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1210 21:02:30.420799  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:02:30.667326  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_112000.caffemodel
I1210 21:02:30.689332  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_112000.solverstate
I1210 21:02:30.697335  8872 solver.cpp:330] Iteration 112000, Testing net (#0)
I1210 21:02:30.697335  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:02:32.022946 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:02:32.073962  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6684
I1210 21:02:32.073962  8872 solver.cpp:397]     Test net output #1: loss = 1.26457 (* 1 = 1.26457 loss)
I1210 21:02:32.131983  8872 solver.cpp:218] Iteration 112000 (13.519 iter/s, 7.39698s/100 iters), loss = 0.35734
I1210 21:02:32.131983  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:02:32.131983  8872 solver.cpp:237]     Train net output #1: loss = 0.35734 (* 1 = 0.35734 loss)
I1210 21:02:32.131983  8872 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1210 21:02:38.143730  8872 solver.cpp:218] Iteration 112100 (16.6364 iter/s, 6.01093s/100 iters), loss = 0.373875
I1210 21:02:38.143730  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:02:38.143730  8872 solver.cpp:237]     Train net output #1: loss = 0.373875 (* 1 = 0.373875 loss)
I1210 21:02:38.143730  8872 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1210 21:02:44.252672  8872 solver.cpp:218] Iteration 112200 (16.3696 iter/s, 6.10887s/100 iters), loss = 0.351977
I1210 21:02:44.252672  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:02:44.252672  8872 solver.cpp:237]     Train net output #1: loss = 0.351977 (* 1 = 0.351977 loss)
I1210 21:02:44.252672  8872 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1210 21:02:50.336467  8872 solver.cpp:218] Iteration 112300 (16.4384 iter/s, 6.08333s/100 iters), loss = 0.396303
I1210 21:02:50.336467  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:02:50.336467  8872 solver.cpp:237]     Train net output #1: loss = 0.396303 (* 1 = 0.396303 loss)
I1210 21:02:50.336467  8872 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1210 21:02:56.336205  8872 solver.cpp:218] Iteration 112400 (16.669 iter/s, 5.99917s/100 iters), loss = 0.43174
I1210 21:02:56.336205  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:02:56.336205  8872 solver.cpp:237]     Train net output #1: loss = 0.43174 (* 1 = 0.43174 loss)
I1210 21:02:56.336205  8872 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1210 21:03:02.029011  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:03:02.268007  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_112500.caffemodel
I1210 21:03:02.287509  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_112500.solverstate
I1210 21:03:02.292508  8872 solver.cpp:330] Iteration 112500, Testing net (#0)
I1210 21:03:02.292508  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:03:03.617092 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:03:03.670100  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6688
I1210 21:03:03.670100  8872 solver.cpp:397]     Test net output #1: loss = 1.27346 (* 1 = 1.27346 loss)
I1210 21:03:03.728113  8872 solver.cpp:218] Iteration 112500 (13.5284 iter/s, 7.39184s/100 iters), loss = 0.396944
I1210 21:03:03.729115  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:03:03.729115  8872 solver.cpp:237]     Train net output #1: loss = 0.396944 (* 1 = 0.396944 loss)
I1210 21:03:03.729115  8872 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1210 21:03:09.822132  8872 solver.cpp:218] Iteration 112600 (16.4137 iter/s, 6.09249s/100 iters), loss = 0.457236
I1210 21:03:09.822132  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:03:09.822132  8872 solver.cpp:237]     Train net output #1: loss = 0.457236 (* 1 = 0.457236 loss)
I1210 21:03:09.822132  8872 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1210 21:03:15.907371  8872 solver.cpp:218] Iteration 112700 (16.4345 iter/s, 6.08478s/100 iters), loss = 0.319881
I1210 21:03:15.907371  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:03:15.907371  8872 solver.cpp:237]     Train net output #1: loss = 0.319881 (* 1 = 0.319881 loss)
I1210 21:03:15.907371  8872 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1210 21:03:21.967859  8872 solver.cpp:218] Iteration 112800 (16.5013 iter/s, 6.06013s/100 iters), loss = 0.446755
I1210 21:03:21.967859  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:03:21.967859  8872 solver.cpp:237]     Train net output #1: loss = 0.446755 (* 1 = 0.446755 loss)
I1210 21:03:21.967859  8872 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1210 21:03:28.163823  8872 solver.cpp:218] Iteration 112900 (16.1411 iter/s, 6.19535s/100 iters), loss = 0.390345
I1210 21:03:28.163823  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:03:28.163823  8872 solver.cpp:237]     Train net output #1: loss = 0.390345 (* 1 = 0.390345 loss)
I1210 21:03:28.163823  8872 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1210 21:03:34.027156  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:03:34.261160  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_113000.caffemodel
I1210 21:03:34.278164  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_113000.solverstate
I1210 21:03:34.283165  8872 solver.cpp:330] Iteration 113000, Testing net (#0)
I1210 21:03:34.283165  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:03:35.597295 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:03:35.649296  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6654
I1210 21:03:35.649296  8872 solver.cpp:397]     Test net output #1: loss = 1.27105 (* 1 = 1.27105 loss)
I1210 21:03:35.705305  8872 solver.cpp:218] Iteration 113000 (13.2612 iter/s, 7.5408s/100 iters), loss = 0.324743
I1210 21:03:35.705305  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:03:35.705305  8872 solver.cpp:237]     Train net output #1: loss = 0.324743 (* 1 = 0.324743 loss)
I1210 21:03:35.705305  8872 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1210 21:03:41.759851  8872 solver.cpp:218] Iteration 113100 (16.5184 iter/s, 6.05386s/100 iters), loss = 0.450677
I1210 21:03:41.759851  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:03:41.759851  8872 solver.cpp:237]     Train net output #1: loss = 0.450677 (* 1 = 0.450677 loss)
I1210 21:03:41.759851  8872 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1210 21:03:47.779705  8872 solver.cpp:218] Iteration 113200 (16.6125 iter/s, 6.01957s/100 iters), loss = 0.25722
I1210 21:03:47.780205  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 21:03:47.780205  8872 solver.cpp:237]     Train net output #1: loss = 0.25722 (* 1 = 0.25722 loss)
I1210 21:03:47.780205  8872 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1210 21:03:53.862749  8872 solver.cpp:218] Iteration 113300 (16.4415 iter/s, 6.08217s/100 iters), loss = 0.421547
I1210 21:03:53.862749  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:03:53.862749  8872 solver.cpp:237]     Train net output #1: loss = 0.421547 (* 1 = 0.421547 loss)
I1210 21:03:53.862749  8872 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1210 21:03:59.860273  8872 solver.cpp:218] Iteration 113400 (16.6749 iter/s, 5.99704s/100 iters), loss = 0.473892
I1210 21:03:59.860273  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:03:59.860273  8872 solver.cpp:237]     Train net output #1: loss = 0.473892 (* 1 = 0.473892 loss)
I1210 21:03:59.860273  8872 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1210 21:04:05.547732  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:04:05.781250  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_113500.caffemodel
I1210 21:04:05.797755  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_113500.solverstate
I1210 21:04:05.801754  8872 solver.cpp:330] Iteration 113500, Testing net (#0)
I1210 21:04:05.801754  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:04:07.109869 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:04:07.160868  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6686
I1210 21:04:07.160868  8872 solver.cpp:397]     Test net output #1: loss = 1.27548 (* 1 = 1.27548 loss)
I1210 21:04:07.216873  8872 solver.cpp:218] Iteration 113500 (13.5928 iter/s, 7.35685s/100 iters), loss = 0.362689
I1210 21:04:07.217875  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:04:07.217875  8872 solver.cpp:237]     Train net output #1: loss = 0.362689 (* 1 = 0.362689 loss)
I1210 21:04:07.217875  8872 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1210 21:04:13.160334  8872 solver.cpp:218] Iteration 113600 (16.829 iter/s, 5.94211s/100 iters), loss = 0.399976
I1210 21:04:13.160334  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:04:13.160334  8872 solver.cpp:237]     Train net output #1: loss = 0.399976 (* 1 = 0.399976 loss)
I1210 21:04:13.160334  8872 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1210 21:04:19.098754  8872 solver.cpp:218] Iteration 113700 (16.84 iter/s, 5.93825s/100 iters), loss = 0.241732
I1210 21:04:19.098754  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:04:19.098754  8872 solver.cpp:237]     Train net output #1: loss = 0.241732 (* 1 = 0.241732 loss)
I1210 21:04:19.098754  8872 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1210 21:04:25.092304  8872 solver.cpp:218] Iteration 113800 (16.6841 iter/s, 5.99374s/100 iters), loss = 0.4111
I1210 21:04:25.093304  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:04:25.093304  8872 solver.cpp:237]     Train net output #1: loss = 0.4111 (* 1 = 0.4111 loss)
I1210 21:04:25.093304  8872 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1210 21:04:31.254992  8872 solver.cpp:218] Iteration 113900 (16.2288 iter/s, 6.16189s/100 iters), loss = 0.357724
I1210 21:04:31.254992  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:04:31.254992  8872 solver.cpp:237]     Train net output #1: loss = 0.357724 (* 1 = 0.357724 loss)
I1210 21:04:31.254992  8872 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1210 21:04:37.042649  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:04:37.277671  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_114000.caffemodel
I1210 21:04:37.292672  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_114000.solverstate
I1210 21:04:37.297672  8872 solver.cpp:330] Iteration 114000, Testing net (#0)
I1210 21:04:37.297672  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:04:38.616827 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:04:38.668834  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6673
I1210 21:04:38.668834  8872 solver.cpp:397]     Test net output #1: loss = 1.27653 (* 1 = 1.27653 loss)
I1210 21:04:38.729846  8872 solver.cpp:218] Iteration 114000 (13.3802 iter/s, 7.47375s/100 iters), loss = 0.331786
I1210 21:04:38.729846  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:04:38.729846  8872 solver.cpp:237]     Train net output #1: loss = 0.331786 (* 1 = 0.331786 loss)
I1210 21:04:38.729846  8872 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1210 21:04:44.903776  8872 solver.cpp:218] Iteration 114100 (16.1977 iter/s, 6.17373s/100 iters), loss = 0.35035
I1210 21:04:44.903776  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:04:44.903776  8872 solver.cpp:237]     Train net output #1: loss = 0.35035 (* 1 = 0.35035 loss)
I1210 21:04:44.903776  8872 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1210 21:04:51.081113  8872 solver.cpp:218] Iteration 114200 (16.1894 iter/s, 6.17686s/100 iters), loss = 0.304757
I1210 21:04:51.081113  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:04:51.081113  8872 solver.cpp:237]     Train net output #1: loss = 0.304757 (* 1 = 0.304757 loss)
I1210 21:04:51.081113  8872 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1210 21:04:57.128542  8872 solver.cpp:218] Iteration 114300 (16.5393 iter/s, 6.04619s/100 iters), loss = 0.360947
I1210 21:04:57.128542  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:04:57.128542  8872 solver.cpp:237]     Train net output #1: loss = 0.360947 (* 1 = 0.360947 loss)
I1210 21:04:57.128542  8872 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1210 21:05:03.347925  8872 solver.cpp:218] Iteration 114400 (16.0798 iter/s, 6.21898s/100 iters), loss = 0.331706
I1210 21:05:03.347925  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:05:03.347925  8872 solver.cpp:237]     Train net output #1: loss = 0.331706 (* 1 = 0.331706 loss)
I1210 21:05:03.347925  8872 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1210 21:05:09.131069  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:05:09.368093  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_114500.caffemodel
I1210 21:05:09.387090  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_114500.solverstate
I1210 21:05:09.394089  8872 solver.cpp:330] Iteration 114500, Testing net (#0)
I1210 21:05:09.395090  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:05:10.744643 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:05:10.796142  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6663
I1210 21:05:10.796142  8872 solver.cpp:397]     Test net output #1: loss = 1.27046 (* 1 = 1.27046 loss)
I1210 21:05:10.852155  8872 solver.cpp:218] Iteration 114500 (13.327 iter/s, 7.50357s/100 iters), loss = 0.331789
I1210 21:05:10.852155  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:05:10.852155  8872 solver.cpp:237]     Train net output #1: loss = 0.331789 (* 1 = 0.331789 loss)
I1210 21:05:10.852155  8872 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1210 21:05:17.084592  8872 solver.cpp:218] Iteration 114600 (16.0467 iter/s, 6.23182s/100 iters), loss = 0.449475
I1210 21:05:17.084592  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:05:17.084592  8872 solver.cpp:237]     Train net output #1: loss = 0.449475 (* 1 = 0.449475 loss)
I1210 21:05:17.084592  8872 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1210 21:05:23.149446  8872 solver.cpp:218] Iteration 114700 (16.4896 iter/s, 6.06445s/100 iters), loss = 0.24997
I1210 21:05:23.149446  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:05:23.149446  8872 solver.cpp:237]     Train net output #1: loss = 0.24997 (* 1 = 0.24997 loss)
I1210 21:05:23.149446  8872 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1210 21:05:29.370569  8872 solver.cpp:218] Iteration 114800 (16.0753 iter/s, 6.22074s/100 iters), loss = 0.423983
I1210 21:05:29.370569  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:05:29.370569  8872 solver.cpp:237]     Train net output #1: loss = 0.423983 (* 1 = 0.423983 loss)
I1210 21:05:29.370569  8872 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1210 21:05:35.516379  8872 solver.cpp:218] Iteration 114900 (16.2738 iter/s, 6.14486s/100 iters), loss = 0.451911
I1210 21:05:35.516379  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:05:35.516379  8872 solver.cpp:237]     Train net output #1: loss = 0.451911 (* 1 = 0.451911 loss)
I1210 21:05:35.516379  8872 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1210 21:05:41.227279  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:05:41.464118  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_115000.caffemodel
I1210 21:05:41.481102  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_115000.solverstate
I1210 21:05:41.486114  8872 solver.cpp:330] Iteration 115000, Testing net (#0)
I1210 21:05:41.486114  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:05:42.802093 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:05:42.852593  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6704
I1210 21:05:42.852593  8872 solver.cpp:397]     Test net output #1: loss = 1.27036 (* 1 = 1.27036 loss)
I1210 21:05:42.909606  8872 solver.cpp:218] Iteration 115000 (13.527 iter/s, 7.39262s/100 iters), loss = 0.379246
I1210 21:05:42.909606  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:05:42.909606  8872 solver.cpp:237]     Train net output #1: loss = 0.379246 (* 1 = 0.379246 loss)
I1210 21:05:42.909606  8872 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1210 21:05:49.226323  8872 solver.cpp:218] Iteration 115100 (15.8316 iter/s, 6.31648s/100 iters), loss = 0.397723
I1210 21:05:49.226824  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:05:49.226824  8872 solver.cpp:237]     Train net output #1: loss = 0.397723 (* 1 = 0.397723 loss)
I1210 21:05:49.226824  8872 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1210 21:05:55.319175  8872 solver.cpp:218] Iteration 115200 (16.4128 iter/s, 6.09282s/100 iters), loss = 0.281698
I1210 21:05:55.320175  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:05:55.320175  8872 solver.cpp:237]     Train net output #1: loss = 0.281698 (* 1 = 0.281698 loss)
I1210 21:05:55.320175  8872 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1210 21:06:01.519189  8872 solver.cpp:218] Iteration 115300 (16.1316 iter/s, 6.199s/100 iters), loss = 0.412246
I1210 21:06:01.519189  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:06:01.519189  8872 solver.cpp:237]     Train net output #1: loss = 0.412246 (* 1 = 0.412246 loss)
I1210 21:06:01.519189  8872 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1210 21:06:07.497526  8872 solver.cpp:218] Iteration 115400 (16.7301 iter/s, 5.97726s/100 iters), loss = 0.41728
I1210 21:06:07.497526  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:06:07.497526  8872 solver.cpp:237]     Train net output #1: loss = 0.41728 (* 1 = 0.41728 loss)
I1210 21:06:07.497526  8872 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1210 21:06:13.380820  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:06:13.613829  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_115500.caffemodel
I1210 21:06:13.629348  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_115500.solverstate
I1210 21:06:13.634335  8872 solver.cpp:330] Iteration 115500, Testing net (#0)
I1210 21:06:13.634335  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:06:14.948982 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:06:14.999997  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6691
I1210 21:06:14.999997  8872 solver.cpp:397]     Test net output #1: loss = 1.27425 (* 1 = 1.27425 loss)
I1210 21:06:15.058023  8872 solver.cpp:218] Iteration 115500 (13.2274 iter/s, 7.56005s/100 iters), loss = 0.375465
I1210 21:06:15.058023  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:06:15.058023  8872 solver.cpp:237]     Train net output #1: loss = 0.375465 (* 1 = 0.375465 loss)
I1210 21:06:15.058023  8872 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1210 21:06:21.082022  8872 solver.cpp:218] Iteration 115600 (16.602 iter/s, 6.02338s/100 iters), loss = 0.405996
I1210 21:06:21.082022  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:06:21.082022  8872 solver.cpp:237]     Train net output #1: loss = 0.405996 (* 1 = 0.405996 loss)
I1210 21:06:21.082022  8872 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1210 21:06:27.156875  8872 solver.cpp:218] Iteration 115700 (16.4604 iter/s, 6.07519s/100 iters), loss = 0.323914
I1210 21:06:27.157878  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:06:27.157878  8872 solver.cpp:237]     Train net output #1: loss = 0.323914 (* 1 = 0.323914 loss)
I1210 21:06:27.157878  8872 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1210 21:06:33.396673  8872 solver.cpp:218] Iteration 115800 (16.0293 iter/s, 6.23856s/100 iters), loss = 0.379506
I1210 21:06:33.396673  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:06:33.396673  8872 solver.cpp:237]     Train net output #1: loss = 0.379506 (* 1 = 0.379506 loss)
I1210 21:06:33.396673  8872 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1210 21:06:39.517340  8872 solver.cpp:218] Iteration 115900 (16.3401 iter/s, 6.11993s/100 iters), loss = 0.339371
I1210 21:06:39.517340  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:06:39.517340  8872 solver.cpp:237]     Train net output #1: loss = 0.339371 (* 1 = 0.339371 loss)
I1210 21:06:39.517340  8872 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1210 21:06:45.384428  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:06:45.620437  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_116000.caffemodel
I1210 21:06:45.637441  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_116000.solverstate
I1210 21:06:45.642441  8872 solver.cpp:330] Iteration 116000, Testing net (#0)
I1210 21:06:45.642441  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:06:46.978468 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:06:47.030971  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6682
I1210 21:06:47.030971  8872 solver.cpp:397]     Test net output #1: loss = 1.28815 (* 1 = 1.28815 loss)
I1210 21:06:47.089968  8872 solver.cpp:218] Iteration 116000 (13.2064 iter/s, 7.5721s/100 iters), loss = 0.341265
I1210 21:06:47.089968  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:06:47.089968  8872 solver.cpp:237]     Train net output #1: loss = 0.341265 (* 1 = 0.341265 loss)
I1210 21:06:47.089968  8872 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1210 21:06:53.120739  8872 solver.cpp:218] Iteration 116100 (16.5828 iter/s, 6.03033s/100 iters), loss = 0.42471
I1210 21:06:53.120739  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:06:53.120739  8872 solver.cpp:237]     Train net output #1: loss = 0.42471 (* 1 = 0.42471 loss)
I1210 21:06:53.120739  8872 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1210 21:06:59.360280  8872 solver.cpp:218] Iteration 116200 (16.0289 iter/s, 6.23873s/100 iters), loss = 0.323653
I1210 21:06:59.360280  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:06:59.360280  8872 solver.cpp:237]     Train net output #1: loss = 0.323653 (* 1 = 0.323653 loss)
I1210 21:06:59.360280  8872 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1210 21:07:05.330195  8872 solver.cpp:218] Iteration 116300 (16.7518 iter/s, 5.96949s/100 iters), loss = 0.354034
I1210 21:07:05.330195  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:07:05.330195  8872 solver.cpp:237]     Train net output #1: loss = 0.354034 (* 1 = 0.354034 loss)
I1210 21:07:05.330195  8872 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1210 21:07:11.598947  8872 solver.cpp:218] Iteration 116400 (15.9528 iter/s, 6.2685s/100 iters), loss = 0.488884
I1210 21:07:11.598947  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:07:11.598947  8872 solver.cpp:237]     Train net output #1: loss = 0.488884 (* 1 = 0.488884 loss)
I1210 21:07:11.598947  8872 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1210 21:07:17.301568  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:07:17.543226  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_116500.caffemodel
I1210 21:07:17.560223  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_116500.solverstate
I1210 21:07:17.564726  8872 solver.cpp:330] Iteration 116500, Testing net (#0)
I1210 21:07:17.565227  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:07:18.963285 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:07:19.014789  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6652
I1210 21:07:19.014789  8872 solver.cpp:397]     Test net output #1: loss = 1.28905 (* 1 = 1.28905 loss)
I1210 21:07:19.074790  8872 solver.cpp:218] Iteration 116500 (13.3777 iter/s, 7.47514s/100 iters), loss = 0.32929
I1210 21:07:19.074790  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:07:19.074790  8872 solver.cpp:237]     Train net output #1: loss = 0.32929 (* 1 = 0.32929 loss)
I1210 21:07:19.074790  8872 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1210 21:07:25.130575  8872 solver.cpp:218] Iteration 116600 (16.513 iter/s, 6.05583s/100 iters), loss = 0.404419
I1210 21:07:25.130575  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:07:25.130575  8872 solver.cpp:237]     Train net output #1: loss = 0.404419 (* 1 = 0.404419 loss)
I1210 21:07:25.130575  8872 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1210 21:07:31.147686  8872 solver.cpp:218] Iteration 116700 (16.6219 iter/s, 6.01616s/100 iters), loss = 0.206229
I1210 21:07:31.147686  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:07:31.147686  8872 solver.cpp:237]     Train net output #1: loss = 0.206229 (* 1 = 0.206229 loss)
I1210 21:07:31.147686  8872 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1210 21:07:37.321038  8872 solver.cpp:218] Iteration 116800 (16.2 iter/s, 6.17282s/100 iters), loss = 0.399925
I1210 21:07:37.321537  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:07:37.321537  8872 solver.cpp:237]     Train net output #1: loss = 0.399925 (* 1 = 0.399925 loss)
I1210 21:07:37.321537  8872 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1210 21:07:43.352046  8872 solver.cpp:218] Iteration 116900 (16.5833 iter/s, 6.03017s/100 iters), loss = 0.305083
I1210 21:07:43.352046  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:07:43.352046  8872 solver.cpp:237]     Train net output #1: loss = 0.305083 (* 1 = 0.305083 loss)
I1210 21:07:43.352046  8872 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1210 21:07:49.247205  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:07:49.482221  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_117000.caffemodel
I1210 21:07:49.497222  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_117000.solverstate
I1210 21:07:49.502220  8872 solver.cpp:330] Iteration 117000, Testing net (#0)
I1210 21:07:49.502220  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:07:50.825997 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:07:50.876996  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6668
I1210 21:07:50.876996  8872 solver.cpp:397]     Test net output #1: loss = 1.28176 (* 1 = 1.28176 loss)
I1210 21:07:50.934505  8872 solver.cpp:218] Iteration 117000 (13.1891 iter/s, 7.58201s/100 iters), loss = 0.369696
I1210 21:07:50.934505  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:07:50.934505  8872 solver.cpp:237]     Train net output #1: loss = 0.369696 (* 1 = 0.369696 loss)
I1210 21:07:50.934505  8872 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1210 21:07:57.034926  8872 solver.cpp:218] Iteration 117100 (16.3922 iter/s, 6.10047s/100 iters), loss = 0.401281
I1210 21:07:57.035925  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:07:57.035925  8872 solver.cpp:237]     Train net output #1: loss = 0.401281 (* 1 = 0.401281 loss)
I1210 21:07:57.035925  8872 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1210 21:08:02.961469  8872 solver.cpp:218] Iteration 117200 (16.8768 iter/s, 5.9253s/100 iters), loss = 0.339598
I1210 21:08:02.961469  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:08:02.961469  8872 solver.cpp:237]     Train net output #1: loss = 0.339598 (* 1 = 0.339598 loss)
I1210 21:08:02.961971  8872 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1210 21:08:08.913832  8872 solver.cpp:218] Iteration 117300 (16.8021 iter/s, 5.95163s/100 iters), loss = 0.456358
I1210 21:08:08.913832  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:08:08.913832  8872 solver.cpp:237]     Train net output #1: loss = 0.456358 (* 1 = 0.456358 loss)
I1210 21:08:08.913832  8872 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1210 21:08:14.839294  8872 solver.cpp:218] Iteration 117400 (16.8775 iter/s, 5.92504s/100 iters), loss = 0.402292
I1210 21:08:14.839294  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:08:14.839294  8872 solver.cpp:237]     Train net output #1: loss = 0.402292 (* 1 = 0.402292 loss)
I1210 21:08:14.839294  8872 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1210 21:08:20.501732  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:08:20.733743  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_117500.caffemodel
I1210 21:08:20.750744  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_117500.solverstate
I1210 21:08:20.754743  8872 solver.cpp:330] Iteration 117500, Testing net (#0)
I1210 21:08:20.754743  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:08:22.077870 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:08:22.127882  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6689
I1210 21:08:22.128871  8872 solver.cpp:397]     Test net output #1: loss = 1.28932 (* 1 = 1.28932 loss)
I1210 21:08:22.184875  8872 solver.cpp:218] Iteration 117500 (13.6148 iter/s, 7.34497s/100 iters), loss = 0.335694
I1210 21:08:22.184875  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:08:22.184875  8872 solver.cpp:237]     Train net output #1: loss = 0.335694 (* 1 = 0.335694 loss)
I1210 21:08:22.184875  8872 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1210 21:08:28.158880  8872 solver.cpp:218] Iteration 117600 (16.7403 iter/s, 5.97359s/100 iters), loss = 0.453445
I1210 21:08:28.158880  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:08:28.158880  8872 solver.cpp:237]     Train net output #1: loss = 0.453445 (* 1 = 0.453445 loss)
I1210 21:08:28.158880  8872 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1210 21:08:34.093842  8872 solver.cpp:218] Iteration 117700 (16.8502 iter/s, 5.93465s/100 iters), loss = 0.248652
I1210 21:08:34.093842  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 21:08:34.093842  8872 solver.cpp:237]     Train net output #1: loss = 0.248651 (* 1 = 0.248651 loss)
I1210 21:08:34.093842  8872 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1210 21:08:40.018334  8872 solver.cpp:218] Iteration 117800 (16.8788 iter/s, 5.92459s/100 iters), loss = 0.406347
I1210 21:08:40.019340  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:08:40.019340  8872 solver.cpp:237]     Train net output #1: loss = 0.406347 (* 1 = 0.406347 loss)
I1210 21:08:40.019340  8872 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1210 21:08:45.949776  8872 solver.cpp:218] Iteration 117900 (16.8637 iter/s, 5.92988s/100 iters), loss = 0.394948
I1210 21:08:45.949776  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:08:45.949776  8872 solver.cpp:237]     Train net output #1: loss = 0.394948 (* 1 = 0.394948 loss)
I1210 21:08:45.949776  8872 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1210 21:08:51.571712  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:08:51.803213  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_118000.caffemodel
I1210 21:08:51.819213  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_118000.solverstate
I1210 21:08:51.824214  8872 solver.cpp:330] Iteration 118000, Testing net (#0)
I1210 21:08:51.824214  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:08:53.123788 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:08:53.174293  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6646
I1210 21:08:53.174293  8872 solver.cpp:397]     Test net output #1: loss = 1.309 (* 1 = 1.309 loss)
I1210 21:08:53.231308  8872 solver.cpp:218] Iteration 118000 (13.7343 iter/s, 7.28106s/100 iters), loss = 0.361579
I1210 21:08:53.231308  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:08:53.231308  8872 solver.cpp:237]     Train net output #1: loss = 0.361579 (* 1 = 0.361579 loss)
I1210 21:08:53.231308  8872 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1210 21:08:59.148804  8872 solver.cpp:218] Iteration 118100 (16.8996 iter/s, 5.91728s/100 iters), loss = 0.367497
I1210 21:08:59.148804  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:08:59.148804  8872 solver.cpp:237]     Train net output #1: loss = 0.367497 (* 1 = 0.367497 loss)
I1210 21:08:59.148804  8872 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1210 21:09:05.066247  8872 solver.cpp:218] Iteration 118200 (16.9015 iter/s, 5.91662s/100 iters), loss = 0.254912
I1210 21:09:05.066247  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:09:05.066247  8872 solver.cpp:237]     Train net output #1: loss = 0.254912 (* 1 = 0.254912 loss)
I1210 21:09:05.066247  8872 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1210 21:09:10.964648  8872 solver.cpp:218] Iteration 118300 (16.9546 iter/s, 5.89811s/100 iters), loss = 0.351174
I1210 21:09:10.964648  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:09:10.964648  8872 solver.cpp:237]     Train net output #1: loss = 0.351174 (* 1 = 0.351174 loss)
I1210 21:09:10.964648  8872 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1210 21:09:16.870432  8872 solver.cpp:218] Iteration 118400 (16.9328 iter/s, 5.9057s/100 iters), loss = 0.405838
I1210 21:09:16.870432  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:09:16.870432  8872 solver.cpp:237]     Train net output #1: loss = 0.405838 (* 1 = 0.405838 loss)
I1210 21:09:16.870432  8872 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1210 21:09:22.507871  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:09:22.739907  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_118500.caffemodel
I1210 21:09:22.756907  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_118500.solverstate
I1210 21:09:22.761907  8872 solver.cpp:330] Iteration 118500, Testing net (#0)
I1210 21:09:22.761907  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:09:24.064010 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:09:24.114511  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6692
I1210 21:09:24.114511  8872 solver.cpp:397]     Test net output #1: loss = 1.28764 (* 1 = 1.28764 loss)
I1210 21:09:24.171015  8872 solver.cpp:218] Iteration 118500 (13.6991 iter/s, 7.29976s/100 iters), loss = 0.307032
I1210 21:09:24.171015  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:09:24.171015  8872 solver.cpp:237]     Train net output #1: loss = 0.307032 (* 1 = 0.307032 loss)
I1210 21:09:24.171015  8872 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1210 21:09:30.102536  8872 solver.cpp:218] Iteration 118600 (16.861 iter/s, 5.93083s/100 iters), loss = 0.369183
I1210 21:09:30.102536  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:09:30.102536  8872 solver.cpp:237]     Train net output #1: loss = 0.369183 (* 1 = 0.369183 loss)
I1210 21:09:30.102536  8872 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1210 21:09:36.018517  8872 solver.cpp:218] Iteration 118700 (16.905 iter/s, 5.91541s/100 iters), loss = 0.281633
I1210 21:09:36.018517  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:09:36.018517  8872 solver.cpp:237]     Train net output #1: loss = 0.281633 (* 1 = 0.281633 loss)
I1210 21:09:36.019017  8872 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1210 21:09:41.938482  8872 solver.cpp:218] Iteration 118800 (16.8929 iter/s, 5.91966s/100 iters), loss = 0.362815
I1210 21:09:41.938482  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:09:41.938482  8872 solver.cpp:237]     Train net output #1: loss = 0.362815 (* 1 = 0.362815 loss)
I1210 21:09:41.938482  8872 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1210 21:09:47.848973  8872 solver.cpp:218] Iteration 118900 (16.9213 iter/s, 5.90973s/100 iters), loss = 0.44454
I1210 21:09:47.848973  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:09:47.848973  8872 solver.cpp:237]     Train net output #1: loss = 0.44454 (* 1 = 0.44454 loss)
I1210 21:09:47.848973  8872 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1210 21:09:53.486296  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:09:53.718310  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_119000.caffemodel
I1210 21:09:53.735316  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_119000.solverstate
I1210 21:09:53.740317  8872 solver.cpp:330] Iteration 119000, Testing net (#0)
I1210 21:09:53.740317  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:09:55.046427 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:09:55.098428  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6661
I1210 21:09:55.098428  8872 solver.cpp:397]     Test net output #1: loss = 1.29494 (* 1 = 1.29494 loss)
I1210 21:09:55.154433  8872 solver.cpp:218] Iteration 119000 (13.6883 iter/s, 7.30553s/100 iters), loss = 0.341669
I1210 21:09:55.154433  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:09:55.155434  8872 solver.cpp:237]     Train net output #1: loss = 0.341669 (* 1 = 0.341669 loss)
I1210 21:09:55.155434  8872 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1210 21:10:01.100891  8872 solver.cpp:218] Iteration 119100 (16.8185 iter/s, 5.94583s/100 iters), loss = 0.36747
I1210 21:10:01.100891  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 21:10:01.100891  8872 solver.cpp:237]     Train net output #1: loss = 0.36747 (* 1 = 0.36747 loss)
I1210 21:10:01.100891  8872 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1210 21:10:07.028556  8872 solver.cpp:218] Iteration 119200 (16.8712 iter/s, 5.92727s/100 iters), loss = 0.259962
I1210 21:10:07.028556  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:10:07.028556  8872 solver.cpp:237]     Train net output #1: loss = 0.259962 (* 1 = 0.259962 loss)
I1210 21:10:07.028556  8872 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1210 21:10:12.957165  8872 solver.cpp:218] Iteration 119300 (16.871 iter/s, 5.92735s/100 iters), loss = 0.399818
I1210 21:10:12.957165  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:10:12.957165  8872 solver.cpp:237]     Train net output #1: loss = 0.399818 (* 1 = 0.399818 loss)
I1210 21:10:12.957165  8872 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1210 21:10:18.879731  8872 solver.cpp:218] Iteration 119400 (16.8848 iter/s, 5.92248s/100 iters), loss = 0.419134
I1210 21:10:18.879731  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:10:18.879731  8872 solver.cpp:237]     Train net output #1: loss = 0.419134 (* 1 = 0.419134 loss)
I1210 21:10:18.879731  8872 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1210 21:10:24.529213  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:10:24.760227  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_119500.caffemodel
I1210 21:10:24.777233  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_119500.solverstate
I1210 21:10:24.781733  8872 solver.cpp:330] Iteration 119500, Testing net (#0)
I1210 21:10:24.781733  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:10:26.083356 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:10:26.133358  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6672
I1210 21:10:26.134359  8872 solver.cpp:397]     Test net output #1: loss = 1.29696 (* 1 = 1.29696 loss)
I1210 21:10:26.189363  8872 solver.cpp:218] Iteration 119500 (13.6817 iter/s, 7.30905s/100 iters), loss = 0.327994
I1210 21:10:26.189363  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:10:26.189363  8872 solver.cpp:237]     Train net output #1: loss = 0.327994 (* 1 = 0.327994 loss)
I1210 21:10:26.189363  8872 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1210 21:10:32.105597  8872 solver.cpp:218] Iteration 119600 (16.9041 iter/s, 5.91573s/100 iters), loss = 0.365278
I1210 21:10:32.105597  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:10:32.105597  8872 solver.cpp:237]     Train net output #1: loss = 0.365278 (* 1 = 0.365278 loss)
I1210 21:10:32.105597  8872 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1210 21:10:38.034132  8872 solver.cpp:218] Iteration 119700 (16.8697 iter/s, 5.92778s/100 iters), loss = 0.286059
I1210 21:10:38.034132  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:10:38.034132  8872 solver.cpp:237]     Train net output #1: loss = 0.286059 (* 1 = 0.286059 loss)
I1210 21:10:38.034132  8872 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1210 21:10:44.035902  8872 solver.cpp:218] Iteration 119800 (16.6629 iter/s, 6.00136s/100 iters), loss = 0.40753
I1210 21:10:44.035902  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:10:44.035902  8872 solver.cpp:237]     Train net output #1: loss = 0.407529 (* 1 = 0.407529 loss)
I1210 21:10:44.035902  8872 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1210 21:10:50.152900  8872 solver.cpp:218] Iteration 119900 (16.3501 iter/s, 6.11617s/100 iters), loss = 0.434097
I1210 21:10:50.152900  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:10:50.152900  8872 solver.cpp:237]     Train net output #1: loss = 0.434097 (* 1 = 0.434097 loss)
I1210 21:10:50.152900  8872 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1210 21:10:55.956400  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:10:56.198400  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_120000.caffemodel
I1210 21:10:56.215900  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_120000.solverstate
I1210 21:10:56.220401  8872 solver.cpp:330] Iteration 120000, Testing net (#0)
I1210 21:10:56.220909  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:10:57.547399 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:10:57.598901  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6675
I1210 21:10:57.598901  8872 solver.cpp:397]     Test net output #1: loss = 1.29871 (* 1 = 1.29871 loss)
I1210 21:10:57.657901  8872 solver.cpp:218] Iteration 120000 (13.3251 iter/s, 7.50464s/100 iters), loss = 0.287215
I1210 21:10:57.657901  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:10:57.657901  8872 solver.cpp:237]     Train net output #1: loss = 0.287215 (* 1 = 0.287215 loss)
I1210 21:10:57.657901  8872 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1210 21:11:03.737399  8872 solver.cpp:218] Iteration 120100 (16.4508 iter/s, 6.07874s/100 iters), loss = 0.31953
I1210 21:11:03.737399  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:11:03.737399  8872 solver.cpp:237]     Train net output #1: loss = 0.31953 (* 1 = 0.31953 loss)
I1210 21:11:03.737399  8872 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1210 21:11:09.827900  8872 solver.cpp:218] Iteration 120200 (16.4205 iter/s, 6.08996s/100 iters), loss = 0.262279
I1210 21:11:09.827900  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:11:09.827900  8872 solver.cpp:237]     Train net output #1: loss = 0.262279 (* 1 = 0.262279 loss)
I1210 21:11:09.827900  8872 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1210 21:11:15.913899  8872 solver.cpp:218] Iteration 120300 (16.4319 iter/s, 6.08573s/100 iters), loss = 0.395121
I1210 21:11:15.913899  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:11:15.913899  8872 solver.cpp:237]     Train net output #1: loss = 0.395121 (* 1 = 0.395121 loss)
I1210 21:11:15.913899  8872 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1210 21:11:21.946400  8872 solver.cpp:218] Iteration 120400 (16.5791 iter/s, 6.0317s/100 iters), loss = 0.457627
I1210 21:11:21.946400  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:11:21.946400  8872 solver.cpp:237]     Train net output #1: loss = 0.457627 (* 1 = 0.457627 loss)
I1210 21:11:21.946400  8872 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1210 21:11:27.579730  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:11:27.811244  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_120500.caffemodel
I1210 21:11:27.828244  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_120500.solverstate
I1210 21:11:27.832244  8872 solver.cpp:330] Iteration 120500, Testing net (#0)
I1210 21:11:27.832244  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:11:29.136354 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:11:29.186861  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6656
I1210 21:11:29.186861  8872 solver.cpp:397]     Test net output #1: loss = 1.29347 (* 1 = 1.29347 loss)
I1210 21:11:29.243362  8872 solver.cpp:218] Iteration 120500 (13.7038 iter/s, 7.29725s/100 iters), loss = 0.37393
I1210 21:11:29.243362  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:11:29.243362  8872 solver.cpp:237]     Train net output #1: loss = 0.37393 (* 1 = 0.37393 loss)
I1210 21:11:29.243362  8872 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1210 21:11:35.169870  8872 solver.cpp:218] Iteration 120600 (16.8757 iter/s, 5.92567s/100 iters), loss = 0.458107
I1210 21:11:35.169870  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:11:35.169870  8872 solver.cpp:237]     Train net output #1: loss = 0.458107 (* 1 = 0.458107 loss)
I1210 21:11:35.169870  8872 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1210 21:11:41.129475  8872 solver.cpp:218] Iteration 120700 (16.7819 iter/s, 5.95881s/100 iters), loss = 0.231462
I1210 21:11:41.129475  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 21:11:41.129475  8872 solver.cpp:237]     Train net output #1: loss = 0.231462 (* 1 = 0.231462 loss)
I1210 21:11:41.129475  8872 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1210 21:11:47.082187  8872 solver.cpp:218] Iteration 120800 (16.7997 iter/s, 5.95249s/100 iters), loss = 0.373822
I1210 21:11:47.082187  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:11:47.082187  8872 solver.cpp:237]     Train net output #1: loss = 0.373822 (* 1 = 0.373822 loss)
I1210 21:11:47.082187  8872 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1210 21:11:53.045142  8872 solver.cpp:218] Iteration 120900 (16.7703 iter/s, 5.96292s/100 iters), loss = 0.342195
I1210 21:11:53.045142  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:11:53.045142  8872 solver.cpp:237]     Train net output #1: loss = 0.342195 (* 1 = 0.342195 loss)
I1210 21:11:53.045142  8872 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1210 21:11:58.732084  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:11:58.971083  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_121000.caffemodel
I1210 21:11:58.987582  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_121000.solverstate
I1210 21:11:58.993083  8872 solver.cpp:330] Iteration 121000, Testing net (#0)
I1210 21:11:58.993083  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:12:00.319584 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:12:00.372083  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6699
I1210 21:12:00.372083  8872 solver.cpp:397]     Test net output #1: loss = 1.28603 (* 1 = 1.28603 loss)
I1210 21:12:00.431082  8872 solver.cpp:218] Iteration 121000 (13.5411 iter/s, 7.3849s/100 iters), loss = 0.353925
I1210 21:12:00.431082  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:12:00.431082  8872 solver.cpp:237]     Train net output #1: loss = 0.353925 (* 1 = 0.353925 loss)
I1210 21:12:00.431082  8872 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1210 21:12:06.509590  8872 solver.cpp:218] Iteration 121100 (16.4527 iter/s, 6.07803s/100 iters), loss = 0.387154
I1210 21:12:06.509590  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:12:06.509590  8872 solver.cpp:237]     Train net output #1: loss = 0.387154 (* 1 = 0.387154 loss)
I1210 21:12:06.509590  8872 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1210 21:12:12.594107  8872 solver.cpp:218] Iteration 121200 (16.4367 iter/s, 6.08396s/100 iters), loss = 0.362071
I1210 21:12:12.594107  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:12:12.594107  8872 solver.cpp:237]     Train net output #1: loss = 0.36207 (* 1 = 0.36207 loss)
I1210 21:12:12.594107  8872 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1210 21:12:18.518486  8872 solver.cpp:218] Iteration 121300 (16.8809 iter/s, 5.92385s/100 iters), loss = 0.364734
I1210 21:12:18.518486  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:12:18.518486  8872 solver.cpp:237]     Train net output #1: loss = 0.364734 (* 1 = 0.364734 loss)
I1210 21:12:18.518486  8872 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1210 21:12:24.457486  8872 solver.cpp:218] Iteration 121400 (16.8397 iter/s, 5.93834s/100 iters), loss = 0.442151
I1210 21:12:24.457486  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:12:24.457486  8872 solver.cpp:237]     Train net output #1: loss = 0.442151 (* 1 = 0.442151 loss)
I1210 21:12:24.457486  8872 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1210 21:12:30.086457  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:12:30.318470  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_121500.caffemodel
I1210 21:12:30.333469  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_121500.solverstate
I1210 21:12:30.338469  8872 solver.cpp:330] Iteration 121500, Testing net (#0)
I1210 21:12:30.338469  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:12:31.643558 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:12:31.695566  8872 solver.cpp:397]     Test net output #0: accuracy = 0.666
I1210 21:12:31.695566  8872 solver.cpp:397]     Test net output #1: loss = 1.31553 (* 1 = 1.31553 loss)
I1210 21:12:31.752564  8872 solver.cpp:218] Iteration 121500 (13.7083 iter/s, 7.29487s/100 iters), loss = 0.370954
I1210 21:12:31.752564  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:12:31.752564  8872 solver.cpp:237]     Train net output #1: loss = 0.370954 (* 1 = 0.370954 loss)
I1210 21:12:31.752564  8872 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1210 21:12:37.680135  8872 solver.cpp:218] Iteration 121600 (16.8709 iter/s, 5.92736s/100 iters), loss = 0.338499
I1210 21:12:37.680135  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:12:37.680135  8872 solver.cpp:237]     Train net output #1: loss = 0.338499 (* 1 = 0.338499 loss)
I1210 21:12:37.680135  8872 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1210 21:12:43.614653  8872 solver.cpp:218] Iteration 121700 (16.8521 iter/s, 5.93397s/100 iters), loss = 0.328504
I1210 21:12:43.614653  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:12:43.614653  8872 solver.cpp:237]     Train net output #1: loss = 0.328503 (* 1 = 0.328503 loss)
I1210 21:12:43.614653  8872 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1210 21:12:49.557200  8872 solver.cpp:218] Iteration 121800 (16.8297 iter/s, 5.94189s/100 iters), loss = 0.386431
I1210 21:12:49.557200  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:12:49.557200  8872 solver.cpp:237]     Train net output #1: loss = 0.386431 (* 1 = 0.386431 loss)
I1210 21:12:49.557200  8872 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1210 21:12:55.489848  8872 solver.cpp:218] Iteration 121900 (16.857 iter/s, 5.93226s/100 iters), loss = 0.363193
I1210 21:12:55.489848  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:12:55.489848  8872 solver.cpp:237]     Train net output #1: loss = 0.363193 (* 1 = 0.363193 loss)
I1210 21:12:55.489848  8872 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1210 21:13:01.194133  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:13:01.428130  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_122000.caffemodel
I1210 21:13:01.444131  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_122000.solverstate
I1210 21:13:01.449131  8872 solver.cpp:330] Iteration 122000, Testing net (#0)
I1210 21:13:01.449131  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:13:02.763558 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:13:02.815063  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6661
I1210 21:13:02.815063  8872 solver.cpp:397]     Test net output #1: loss = 1.30891 (* 1 = 1.30891 loss)
I1210 21:13:02.873080  8872 solver.cpp:218] Iteration 122000 (13.5459 iter/s, 7.38229s/100 iters), loss = 0.330192
I1210 21:13:02.873080  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:13:02.873080  8872 solver.cpp:237]     Train net output #1: loss = 0.330192 (* 1 = 0.330192 loss)
I1210 21:13:02.873080  8872 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1210 21:13:08.993010  8872 solver.cpp:218] Iteration 122100 (16.3403 iter/s, 6.11985s/100 iters), loss = 0.391842
I1210 21:13:08.993010  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:13:08.993010  8872 solver.cpp:237]     Train net output #1: loss = 0.391842 (* 1 = 0.391842 loss)
I1210 21:13:08.993010  8872 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1210 21:13:15.000525  8872 solver.cpp:218] Iteration 122200 (16.6488 iter/s, 6.00642s/100 iters), loss = 0.333162
I1210 21:13:15.000525  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:13:15.000525  8872 solver.cpp:237]     Train net output #1: loss = 0.333162 (* 1 = 0.333162 loss)
I1210 21:13:15.000525  8872 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1210 21:13:20.951017  8872 solver.cpp:218] Iteration 122300 (16.8062 iter/s, 5.95017s/100 iters), loss = 0.402861
I1210 21:13:20.951017  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:13:20.951017  8872 solver.cpp:237]     Train net output #1: loss = 0.402861 (* 1 = 0.402861 loss)
I1210 21:13:20.951017  8872 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1210 21:13:26.915628  8872 solver.cpp:218] Iteration 122400 (16.7657 iter/s, 5.96456s/100 iters), loss = 0.321062
I1210 21:13:26.915628  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:13:26.915628  8872 solver.cpp:237]     Train net output #1: loss = 0.321062 (* 1 = 0.321062 loss)
I1210 21:13:26.915628  8872 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1210 21:13:32.673143  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:13:32.907166  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_122500.caffemodel
I1210 21:13:32.924166  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_122500.solverstate
I1210 21:13:32.929167  8872 solver.cpp:330] Iteration 122500, Testing net (#0)
I1210 21:13:32.929167  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:13:34.244263 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:13:34.295766  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6678
I1210 21:13:34.295766  8872 solver.cpp:397]     Test net output #1: loss = 1.29654 (* 1 = 1.29654 loss)
I1210 21:13:34.352268  8872 solver.cpp:218] Iteration 122500 (13.4493 iter/s, 7.43534s/100 iters), loss = 0.349804
I1210 21:13:34.352268  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:13:34.352268  8872 solver.cpp:237]     Train net output #1: loss = 0.349804 (* 1 = 0.349804 loss)
I1210 21:13:34.352268  8872 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1210 21:13:40.351949  8872 solver.cpp:218] Iteration 122600 (16.6677 iter/s, 5.99962s/100 iters), loss = 0.361578
I1210 21:13:40.352450  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:13:40.352450  8872 solver.cpp:237]     Train net output #1: loss = 0.361578 (* 1 = 0.361578 loss)
I1210 21:13:40.352450  8872 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1210 21:13:46.307417  8872 solver.cpp:218] Iteration 122700 (16.7914 iter/s, 5.95543s/100 iters), loss = 0.355465
I1210 21:13:46.307417  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:13:46.307417  8872 solver.cpp:237]     Train net output #1: loss = 0.355465 (* 1 = 0.355465 loss)
I1210 21:13:46.307417  8872 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1210 21:13:52.259364  8872 solver.cpp:218] Iteration 122800 (16.8045 iter/s, 5.95079s/100 iters), loss = 0.324736
I1210 21:13:52.259364  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:13:52.259364  8872 solver.cpp:237]     Train net output #1: loss = 0.324736 (* 1 = 0.324736 loss)
I1210 21:13:52.259364  8872 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1210 21:13:58.225441  8872 solver.cpp:218] Iteration 122900 (16.762 iter/s, 5.96588s/100 iters), loss = 0.398315
I1210 21:13:58.225441  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:13:58.225441  8872 solver.cpp:237]     Train net output #1: loss = 0.398315 (* 1 = 0.398315 loss)
I1210 21:13:58.225441  8872 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1210 21:14:03.895908  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:14:04.131925  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_123000.caffemodel
I1210 21:14:04.147925  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_123000.solverstate
I1210 21:14:04.152930  8872 solver.cpp:330] Iteration 123000, Testing net (#0)
I1210 21:14:04.152930  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:14:05.460023 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:14:05.511026  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6662
I1210 21:14:05.511026  8872 solver.cpp:397]     Test net output #1: loss = 1.31029 (* 1 = 1.31029 loss)
I1210 21:14:05.567039  8872 solver.cpp:218] Iteration 123000 (13.6221 iter/s, 7.34101s/100 iters), loss = 0.391017
I1210 21:14:05.567039  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:14:05.567039  8872 solver.cpp:237]     Train net output #1: loss = 0.391017 (* 1 = 0.391017 loss)
I1210 21:14:05.567039  8872 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1210 21:14:11.519487  8872 solver.cpp:218] Iteration 123100 (16.8026 iter/s, 5.95146s/100 iters), loss = 0.295709
I1210 21:14:11.519487  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:14:11.519487  8872 solver.cpp:237]     Train net output #1: loss = 0.295709 (* 1 = 0.295709 loss)
I1210 21:14:11.519487  8872 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1210 21:14:17.484917  8872 solver.cpp:218] Iteration 123200 (16.7622 iter/s, 5.9658s/100 iters), loss = 0.291052
I1210 21:14:17.484917  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:14:17.484917  8872 solver.cpp:237]     Train net output #1: loss = 0.291052 (* 1 = 0.291052 loss)
I1210 21:14:17.484917  8872 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1210 21:14:23.447376  8872 solver.cpp:218] Iteration 123300 (16.7737 iter/s, 5.96173s/100 iters), loss = 0.339416
I1210 21:14:23.447376  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:14:23.447376  8872 solver.cpp:237]     Train net output #1: loss = 0.339416 (* 1 = 0.339416 loss)
I1210 21:14:23.447376  8872 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1210 21:14:29.490064  8872 solver.cpp:218] Iteration 123400 (16.5513 iter/s, 6.04181s/100 iters), loss = 0.363601
I1210 21:14:29.490064  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:14:29.490064  8872 solver.cpp:237]     Train net output #1: loss = 0.363601 (* 1 = 0.363601 loss)
I1210 21:14:29.490064  8872 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1210 21:14:35.181625  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:14:35.414640  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_123500.caffemodel
I1210 21:14:35.431643  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_123500.solverstate
I1210 21:14:35.436144  8872 solver.cpp:330] Iteration 123500, Testing net (#0)
I1210 21:14:35.436144  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:14:36.743741 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:14:36.796742  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6649
I1210 21:14:36.796742  8872 solver.cpp:397]     Test net output #1: loss = 1.32205 (* 1 = 1.32205 loss)
I1210 21:14:36.852746  8872 solver.cpp:218] Iteration 123500 (13.5831 iter/s, 7.36211s/100 iters), loss = 0.327658
I1210 21:14:36.852746  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:14:36.852746  8872 solver.cpp:237]     Train net output #1: loss = 0.327658 (* 1 = 0.327658 loss)
I1210 21:14:36.852746  8872 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1210 21:14:42.805280  8872 solver.cpp:218] Iteration 123600 (16.7994 iter/s, 5.95258s/100 iters), loss = 0.407075
I1210 21:14:42.806280  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:14:42.806280  8872 solver.cpp:237]     Train net output #1: loss = 0.407075 (* 1 = 0.407075 loss)
I1210 21:14:42.806280  8872 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1210 21:14:48.755800  8872 solver.cpp:218] Iteration 123700 (16.8088 iter/s, 5.94925s/100 iters), loss = 0.250146
I1210 21:14:48.755800  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:14:48.755800  8872 solver.cpp:237]     Train net output #1: loss = 0.250146 (* 1 = 0.250146 loss)
I1210 21:14:48.755800  8872 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1210 21:14:54.779433  8872 solver.cpp:218] Iteration 123800 (16.6002 iter/s, 6.02401s/100 iters), loss = 0.346337
I1210 21:14:54.780434  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:14:54.780434  8872 solver.cpp:237]     Train net output #1: loss = 0.346337 (* 1 = 0.346337 loss)
I1210 21:14:54.780434  8872 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1210 21:15:00.761996  8872 solver.cpp:218] Iteration 123900 (16.7183 iter/s, 5.98147s/100 iters), loss = 0.348986
I1210 21:15:00.761996  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:15:00.761996  8872 solver.cpp:237]     Train net output #1: loss = 0.348986 (* 1 = 0.348986 loss)
I1210 21:15:00.761996  8872 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1210 21:15:06.522583  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:15:06.759605  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_124000.caffemodel
I1210 21:15:06.776605  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_124000.solverstate
I1210 21:15:06.781606  8872 solver.cpp:330] Iteration 124000, Testing net (#0)
I1210 21:15:06.781606  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:15:08.103765 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:15:08.156774  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6657
I1210 21:15:08.156774  8872 solver.cpp:397]     Test net output #1: loss = 1.31856 (* 1 = 1.31856 loss)
I1210 21:15:08.217774  8872 solver.cpp:218] Iteration 124000 (13.4135 iter/s, 7.45519s/100 iters), loss = 0.343716
I1210 21:15:08.217774  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:15:08.217774  8872 solver.cpp:237]     Train net output #1: loss = 0.343716 (* 1 = 0.343716 loss)
I1210 21:15:08.217774  8872 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1210 21:15:14.245373  8872 solver.cpp:218] Iteration 124100 (16.5923 iter/s, 6.02691s/100 iters), loss = 0.333365
I1210 21:15:14.245373  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:15:14.245373  8872 solver.cpp:237]     Train net output #1: loss = 0.333365 (* 1 = 0.333365 loss)
I1210 21:15:14.245373  8872 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1210 21:15:20.313916  8872 solver.cpp:218] Iteration 124200 (16.4808 iter/s, 6.06767s/100 iters), loss = 0.282677
I1210 21:15:20.313916  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:15:20.313916  8872 solver.cpp:237]     Train net output #1: loss = 0.282677 (* 1 = 0.282677 loss)
I1210 21:15:20.313916  8872 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1210 21:15:26.313442  8872 solver.cpp:218] Iteration 124300 (16.6683 iter/s, 5.9994s/100 iters), loss = 0.355047
I1210 21:15:26.313442  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:15:26.313442  8872 solver.cpp:237]     Train net output #1: loss = 0.355047 (* 1 = 0.355047 loss)
I1210 21:15:26.313442  8872 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1210 21:15:32.368351  8872 solver.cpp:218] Iteration 124400 (16.5154 iter/s, 6.05497s/100 iters), loss = 0.386422
I1210 21:15:32.369351  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:15:32.369351  8872 solver.cpp:237]     Train net output #1: loss = 0.386422 (* 1 = 0.386422 loss)
I1210 21:15:32.369351  8872 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1210 21:15:38.066002  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:15:38.300025  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_124500.caffemodel
I1210 21:15:38.317025  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_124500.solverstate
I1210 21:15:38.322031  8872 solver.cpp:330] Iteration 124500, Testing net (#0)
I1210 21:15:38.322532  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:15:39.634656 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:15:39.685160  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6652
I1210 21:15:39.685160  8872 solver.cpp:397]     Test net output #1: loss = 1.31535 (* 1 = 1.31535 loss)
I1210 21:15:39.741165  8872 solver.cpp:218] Iteration 124500 (13.5656 iter/s, 7.37156s/100 iters), loss = 0.370711
I1210 21:15:39.741165  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:15:39.741165  8872 solver.cpp:237]     Train net output #1: loss = 0.370711 (* 1 = 0.370711 loss)
I1210 21:15:39.741165  8872 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1210 21:15:45.691758  8872 solver.cpp:218] Iteration 124600 (16.805 iter/s, 5.95061s/100 iters), loss = 0.318472
I1210 21:15:45.691758  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 21:15:45.691758  8872 solver.cpp:237]     Train net output #1: loss = 0.318472 (* 1 = 0.318472 loss)
I1210 21:15:45.691758  8872 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1210 21:15:51.640246  8872 solver.cpp:218] Iteration 124700 (16.8116 iter/s, 5.94829s/100 iters), loss = 0.282539
I1210 21:15:51.640246  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:15:51.640246  8872 solver.cpp:237]     Train net output #1: loss = 0.282539 (* 1 = 0.282539 loss)
I1210 21:15:51.641247  8872 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1210 21:15:57.625548  8872 solver.cpp:218] Iteration 124800 (16.7106 iter/s, 5.98422s/100 iters), loss = 0.342661
I1210 21:15:57.625548  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:15:57.625548  8872 solver.cpp:237]     Train net output #1: loss = 0.342661 (* 1 = 0.342661 loss)
I1210 21:15:57.625548  8872 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1210 21:16:03.590595  8872 solver.cpp:218] Iteration 124900 (16.7667 iter/s, 5.96419s/100 iters), loss = 0.35929
I1210 21:16:03.590595  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:16:03.590595  8872 solver.cpp:237]     Train net output #1: loss = 0.35929 (* 1 = 0.35929 loss)
I1210 21:16:03.590595  8872 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1210 21:16:09.304424  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:16:09.538951  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_125000.caffemodel
I1210 21:16:09.554456  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_125000.solverstate
I1210 21:16:09.559455  8872 solver.cpp:330] Iteration 125000, Testing net (#0)
I1210 21:16:09.559455  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:16:10.871587 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:16:10.923588  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6652
I1210 21:16:10.923588  8872 solver.cpp:397]     Test net output #1: loss = 1.3319 (* 1 = 1.3319 loss)
I1210 21:16:10.979602  8872 solver.cpp:218] Iteration 125000 (13.5335 iter/s, 7.38907s/100 iters), loss = 0.310739
I1210 21:16:10.979602  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:16:10.979602  8872 solver.cpp:237]     Train net output #1: loss = 0.310739 (* 1 = 0.310739 loss)
I1210 21:16:10.979602  8872 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1210 21:16:17.058323  8872 solver.cpp:218] Iteration 125100 (16.4539 iter/s, 6.07758s/100 iters), loss = 0.390955
I1210 21:16:17.058323  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:16:17.058323  8872 solver.cpp:237]     Train net output #1: loss = 0.390955 (* 1 = 0.390955 loss)
I1210 21:16:17.058323  8872 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1210 21:16:23.127939  8872 solver.cpp:218] Iteration 125200 (16.4765 iter/s, 6.06926s/100 iters), loss = 0.281335
I1210 21:16:23.127939  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:16:23.127939  8872 solver.cpp:237]     Train net output #1: loss = 0.281335 (* 1 = 0.281335 loss)
I1210 21:16:23.127939  8872 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1210 21:16:29.287503  8872 solver.cpp:218] Iteration 125300 (16.2351 iter/s, 6.15949s/100 iters), loss = 0.423032
I1210 21:16:29.287503  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:16:29.287503  8872 solver.cpp:237]     Train net output #1: loss = 0.423032 (* 1 = 0.423032 loss)
I1210 21:16:29.287503  8872 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1210 21:16:35.251132  8872 solver.cpp:218] Iteration 125400 (16.7688 iter/s, 5.96345s/100 iters), loss = 0.45233
I1210 21:16:35.251132  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:16:35.251132  8872 solver.cpp:237]     Train net output #1: loss = 0.45233 (* 1 = 0.45233 loss)
I1210 21:16:35.251132  8872 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1210 21:16:40.905585  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:16:41.153630  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_125500.caffemodel
I1210 21:16:41.169631  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_125500.solverstate
I1210 21:16:41.174628  8872 solver.cpp:330] Iteration 125500, Testing net (#0)
I1210 21:16:41.174628  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:16:42.498711 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:16:42.551723  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6653
I1210 21:16:42.551723  8872 solver.cpp:397]     Test net output #1: loss = 1.33768 (* 1 = 1.33768 loss)
I1210 21:16:42.607720  8872 solver.cpp:218] Iteration 125500 (13.5941 iter/s, 7.35612s/100 iters), loss = 0.325373
I1210 21:16:42.607720  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:16:42.607720  8872 solver.cpp:237]     Train net output #1: loss = 0.325373 (* 1 = 0.325373 loss)
I1210 21:16:42.607720  8872 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1210 21:16:48.670377  8872 solver.cpp:218] Iteration 125600 (16.4962 iter/s, 6.06201s/100 iters), loss = 0.326158
I1210 21:16:48.670377  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:16:48.670377  8872 solver.cpp:237]     Train net output #1: loss = 0.326158 (* 1 = 0.326158 loss)
I1210 21:16:48.670377  8872 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1210 21:16:54.656980  8872 solver.cpp:218] Iteration 125700 (16.7052 iter/s, 5.98616s/100 iters), loss = 0.330059
I1210 21:16:54.656980  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:16:54.656980  8872 solver.cpp:237]     Train net output #1: loss = 0.330059 (* 1 = 0.330059 loss)
I1210 21:16:54.656980  8872 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1210 21:17:00.731631  8872 solver.cpp:218] Iteration 125800 (16.4643 iter/s, 6.07375s/100 iters), loss = 0.407124
I1210 21:17:00.732132  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:17:00.732132  8872 solver.cpp:237]     Train net output #1: loss = 0.407124 (* 1 = 0.407124 loss)
I1210 21:17:00.732132  8872 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1210 21:17:06.890669  8872 solver.cpp:218] Iteration 125900 (16.238 iter/s, 6.15841s/100 iters), loss = 0.31205
I1210 21:17:06.890669  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:17:06.890669  8872 solver.cpp:237]     Train net output #1: loss = 0.31205 (* 1 = 0.31205 loss)
I1210 21:17:06.890669  8872 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1210 21:17:12.639616  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:17:12.879644  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_126000.caffemodel
I1210 21:17:12.896644  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_126000.solverstate
I1210 21:17:12.901651  8872 solver.cpp:330] Iteration 126000, Testing net (#0)
I1210 21:17:12.901651  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:17:14.236245 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:17:14.288750  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6647
I1210 21:17:14.288750  8872 solver.cpp:397]     Test net output #1: loss = 1.32284 (* 1 = 1.32284 loss)
I1210 21:17:14.346751  8872 solver.cpp:218] Iteration 126000 (13.4126 iter/s, 7.45565s/100 iters), loss = 0.343965
I1210 21:17:14.347252  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:17:14.347252  8872 solver.cpp:237]     Train net output #1: loss = 0.343965 (* 1 = 0.343965 loss)
I1210 21:17:14.347252  8872 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1210 21:17:20.424329  8872 solver.cpp:218] Iteration 126100 (16.455 iter/s, 6.07717s/100 iters), loss = 0.370655
I1210 21:17:20.424329  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:17:20.424329  8872 solver.cpp:237]     Train net output #1: loss = 0.370655 (* 1 = 0.370655 loss)
I1210 21:17:20.424329  8872 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1210 21:17:26.515923  8872 solver.cpp:218] Iteration 126200 (16.4179 iter/s, 6.09091s/100 iters), loss = 0.198662
I1210 21:17:26.515923  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:17:26.515923  8872 solver.cpp:237]     Train net output #1: loss = 0.198662 (* 1 = 0.198662 loss)
I1210 21:17:26.515923  8872 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1210 21:17:32.556479  8872 solver.cpp:218] Iteration 126300 (16.5555 iter/s, 6.04028s/100 iters), loss = 0.401478
I1210 21:17:32.556479  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 21:17:32.556479  8872 solver.cpp:237]     Train net output #1: loss = 0.401478 (* 1 = 0.401478 loss)
I1210 21:17:32.556479  8872 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1210 21:17:38.528996  8872 solver.cpp:218] Iteration 126400 (16.7449 iter/s, 5.97196s/100 iters), loss = 0.37433
I1210 21:17:38.528996  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:17:38.528996  8872 solver.cpp:237]     Train net output #1: loss = 0.37433 (* 1 = 0.37433 loss)
I1210 21:17:38.528996  8872 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1210 21:17:44.250339  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:17:44.489361  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_126500.caffemodel
I1210 21:17:44.505359  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_126500.solverstate
I1210 21:17:44.511360  8872 solver.cpp:330] Iteration 126500, Testing net (#0)
I1210 21:17:44.511360  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:17:45.849999 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:17:45.901502  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6686
I1210 21:17:45.901502  8872 solver.cpp:397]     Test net output #1: loss = 1.31353 (* 1 = 1.31353 loss)
I1210 21:17:45.958505  8872 solver.cpp:218] Iteration 126500 (13.4615 iter/s, 7.42859s/100 iters), loss = 0.307104
I1210 21:17:45.958505  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:17:45.958505  8872 solver.cpp:237]     Train net output #1: loss = 0.307104 (* 1 = 0.307104 loss)
I1210 21:17:45.958505  8872 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1210 21:17:51.950754  8872 solver.cpp:218] Iteration 126600 (16.6901 iter/s, 5.99157s/100 iters), loss = 0.32045
I1210 21:17:51.950754  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:17:51.950754  8872 solver.cpp:237]     Train net output #1: loss = 0.32045 (* 1 = 0.32045 loss)
I1210 21:17:51.950754  8872 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1210 21:17:57.914885  8872 solver.cpp:218] Iteration 126700 (16.7679 iter/s, 5.96379s/100 iters), loss = 0.301892
I1210 21:17:57.914885  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:17:57.914885  8872 solver.cpp:237]     Train net output #1: loss = 0.301892 (* 1 = 0.301892 loss)
I1210 21:17:57.914885  8872 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1210 21:18:03.968725  8872 solver.cpp:218] Iteration 126800 (16.5205 iter/s, 6.05309s/100 iters), loss = 0.34572
I1210 21:18:03.968725  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:18:03.968725  8872 solver.cpp:237]     Train net output #1: loss = 0.34572 (* 1 = 0.34572 loss)
I1210 21:18:03.968725  8872 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1210 21:18:10.142045  8872 solver.cpp:218] Iteration 126900 (16.1993 iter/s, 6.17311s/100 iters), loss = 0.340748
I1210 21:18:10.142045  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:18:10.142045  8872 solver.cpp:237]     Train net output #1: loss = 0.340748 (* 1 = 0.340748 loss)
I1210 21:18:10.142045  8872 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1210 21:18:15.864269  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:18:16.098276  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_127000.caffemodel
I1210 21:18:16.115275  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_127000.solverstate
I1210 21:18:16.120277  8872 solver.cpp:330] Iteration 127000, Testing net (#0)
I1210 21:18:16.120277  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:18:17.433042 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:18:17.484045  8872 solver.cpp:397]     Test net output #0: accuracy = 0.667
I1210 21:18:17.484045  8872 solver.cpp:397]     Test net output #1: loss = 1.31109 (* 1 = 1.31109 loss)
I1210 21:18:17.540554  8872 solver.cpp:218] Iteration 127000 (13.5172 iter/s, 7.39798s/100 iters), loss = 0.40921
I1210 21:18:17.540554  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:18:17.540554  8872 solver.cpp:237]     Train net output #1: loss = 0.40921 (* 1 = 0.40921 loss)
I1210 21:18:17.540554  8872 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1210 21:18:23.448185  8872 solver.cpp:218] Iteration 127100 (16.927 iter/s, 5.90773s/100 iters), loss = 0.306002
I1210 21:18:23.449185  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:18:23.449185  8872 solver.cpp:237]     Train net output #1: loss = 0.306002 (* 1 = 0.306002 loss)
I1210 21:18:23.449185  8872 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1210 21:18:29.439730  8872 solver.cpp:218] Iteration 127200 (16.692 iter/s, 5.9909s/100 iters), loss = 0.250138
I1210 21:18:29.439730  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 21:18:29.439730  8872 solver.cpp:237]     Train net output #1: loss = 0.250138 (* 1 = 0.250138 loss)
I1210 21:18:29.439730  8872 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1210 21:18:35.370779  8872 solver.cpp:218] Iteration 127300 (16.8637 iter/s, 5.9299s/100 iters), loss = 0.320607
I1210 21:18:35.370779  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:18:35.370779  8872 solver.cpp:237]     Train net output #1: loss = 0.320607 (* 1 = 0.320607 loss)
I1210 21:18:35.370779  8872 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1210 21:18:41.385121  8872 solver.cpp:218] Iteration 127400 (16.6288 iter/s, 6.01367s/100 iters), loss = 0.438874
I1210 21:18:41.385121  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:18:41.385121  8872 solver.cpp:237]     Train net output #1: loss = 0.438874 (* 1 = 0.438874 loss)
I1210 21:18:41.385121  8872 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1210 21:18:47.030594  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:18:47.280647  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_127500.caffemodel
I1210 21:18:47.297648  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_127500.solverstate
I1210 21:18:47.301645  8872 solver.cpp:330] Iteration 127500, Testing net (#0)
I1210 21:18:47.301645  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:18:48.613746 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:18:48.665248  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6672
I1210 21:18:48.665248  8872 solver.cpp:397]     Test net output #1: loss = 1.32428 (* 1 = 1.32428 loss)
I1210 21:18:48.721750  8872 solver.cpp:218] Iteration 127500 (13.6302 iter/s, 7.33666s/100 iters), loss = 0.339295
I1210 21:18:48.721750  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:18:48.721750  8872 solver.cpp:237]     Train net output #1: loss = 0.339295 (* 1 = 0.339295 loss)
I1210 21:18:48.721750  8872 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1210 21:18:54.680269  8872 solver.cpp:218] Iteration 127600 (16.7846 iter/s, 5.95784s/100 iters), loss = 0.302904
I1210 21:18:54.680269  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 21:18:54.680269  8872 solver.cpp:237]     Train net output #1: loss = 0.302904 (* 1 = 0.302904 loss)
I1210 21:18:54.680269  8872 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1210 21:19:00.635694  8872 solver.cpp:218] Iteration 127700 (16.7914 iter/s, 5.95544s/100 iters), loss = 0.225592
I1210 21:19:00.635694  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 21:19:00.635694  8872 solver.cpp:237]     Train net output #1: loss = 0.225592 (* 1 = 0.225592 loss)
I1210 21:19:00.635694  8872 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1210 21:19:06.572602  8872 solver.cpp:218] Iteration 127800 (16.8469 iter/s, 5.93581s/100 iters), loss = 0.36718
I1210 21:19:06.572602  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:19:06.572602  8872 solver.cpp:237]     Train net output #1: loss = 0.36718 (* 1 = 0.36718 loss)
I1210 21:19:06.572602  8872 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1210 21:19:12.515755  8872 solver.cpp:218] Iteration 127900 (16.8267 iter/s, 5.94292s/100 iters), loss = 0.299235
I1210 21:19:12.515755  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:19:12.515755  8872 solver.cpp:237]     Train net output #1: loss = 0.299235 (* 1 = 0.299235 loss)
I1210 21:19:12.515755  8872 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1210 21:19:18.169139  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:19:18.403173  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_128000.caffemodel
I1210 21:19:18.419173  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_128000.solverstate
I1210 21:19:18.424173  8872 solver.cpp:330] Iteration 128000, Testing net (#0)
I1210 21:19:18.424173  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:19:19.730381 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:19:19.781383  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6644
I1210 21:19:19.781383  8872 solver.cpp:397]     Test net output #1: loss = 1.34003 (* 1 = 1.34003 loss)
I1210 21:19:19.837388  8872 solver.cpp:218] Iteration 128000 (13.658 iter/s, 7.32172s/100 iters), loss = 0.300088
I1210 21:19:19.837388  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:19:19.838389  8872 solver.cpp:237]     Train net output #1: loss = 0.300088 (* 1 = 0.300088 loss)
I1210 21:19:19.838389  8872 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1210 21:19:25.796944  8872 solver.cpp:218] Iteration 128100 (16.7824 iter/s, 5.95861s/100 iters), loss = 0.324849
I1210 21:19:25.796944  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:19:25.796944  8872 solver.cpp:237]     Train net output #1: loss = 0.324849 (* 1 = 0.324849 loss)
I1210 21:19:25.796944  8872 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1210 21:19:31.745340  8872 solver.cpp:218] Iteration 128200 (16.8127 iter/s, 5.94787s/100 iters), loss = 0.287509
I1210 21:19:31.745340  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:19:31.745340  8872 solver.cpp:237]     Train net output #1: loss = 0.287509 (* 1 = 0.287509 loss)
I1210 21:19:31.745340  8872 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1210 21:19:37.683266  8872 solver.cpp:218] Iteration 128300 (16.8422 iter/s, 5.93748s/100 iters), loss = 0.384168
I1210 21:19:37.683266  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:19:37.683266  8872 solver.cpp:237]     Train net output #1: loss = 0.384168 (* 1 = 0.384168 loss)
I1210 21:19:37.683266  8872 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1210 21:19:43.611549  8872 solver.cpp:218] Iteration 128400 (16.8694 iter/s, 5.92789s/100 iters), loss = 0.405898
I1210 21:19:43.611549  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:19:43.611549  8872 solver.cpp:237]     Train net output #1: loss = 0.405898 (* 1 = 0.405898 loss)
I1210 21:19:43.611549  8872 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1210 21:19:49.233986  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:19:49.468998  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_128500.caffemodel
I1210 21:19:49.486006  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_128500.solverstate
I1210 21:19:49.491013  8872 solver.cpp:330] Iteration 128500, Testing net (#0)
I1210 21:19:49.491013  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:19:50.794108 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:19:50.845108  8872 solver.cpp:397]     Test net output #0: accuracy = 0.667
I1210 21:19:50.845108  8872 solver.cpp:397]     Test net output #1: loss = 1.33011 (* 1 = 1.33011 loss)
I1210 21:19:50.902114  8872 solver.cpp:218] Iteration 128500 (13.7181 iter/s, 7.28962s/100 iters), loss = 0.34333
I1210 21:19:50.902114  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:19:50.902114  8872 solver.cpp:237]     Train net output #1: loss = 0.34333 (* 1 = 0.34333 loss)
I1210 21:19:50.902114  8872 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1210 21:19:56.867529  8872 solver.cpp:218] Iteration 128600 (16.7634 iter/s, 5.96538s/100 iters), loss = 0.34147
I1210 21:19:56.867529  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:19:56.867529  8872 solver.cpp:237]     Train net output #1: loss = 0.34147 (* 1 = 0.34147 loss)
I1210 21:19:56.867529  8872 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1210 21:20:02.866896  8872 solver.cpp:218] Iteration 128700 (16.6707 iter/s, 5.99854s/100 iters), loss = 0.257776
I1210 21:20:02.866896  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 21:20:02.866896  8872 solver.cpp:237]     Train net output #1: loss = 0.257776 (* 1 = 0.257776 loss)
I1210 21:20:02.866896  8872 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1210 21:20:08.826242  8872 solver.cpp:218] Iteration 128800 (16.7813 iter/s, 5.95901s/100 iters), loss = 0.390026
I1210 21:20:08.826242  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 21:20:08.826242  8872 solver.cpp:237]     Train net output #1: loss = 0.390026 (* 1 = 0.390026 loss)
I1210 21:20:08.826242  8872 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1210 21:20:14.781688  8872 solver.cpp:218] Iteration 128900 (16.7934 iter/s, 5.95471s/100 iters), loss = 0.344295
I1210 21:20:14.781688  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:20:14.781688  8872 solver.cpp:237]     Train net output #1: loss = 0.344295 (* 1 = 0.344295 loss)
I1210 21:20:14.781688  8872 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1210 21:20:20.432749  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:20:20.666919  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_129000.caffemodel
I1210 21:20:20.683923  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_129000.solverstate
I1210 21:20:20.688422  8872 solver.cpp:330] Iteration 129000, Testing net (#0)
I1210 21:20:20.688422  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:20:21.993057 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:20:22.044059  8872 solver.cpp:397]     Test net output #0: accuracy = 0.664
I1210 21:20:22.044059  8872 solver.cpp:397]     Test net output #1: loss = 1.34141 (* 1 = 1.34141 loss)
I1210 21:20:22.104063  8872 solver.cpp:218] Iteration 129000 (13.6571 iter/s, 7.32222s/100 iters), loss = 0.272753
I1210 21:20:22.104063  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:20:22.104063  8872 solver.cpp:237]     Train net output #1: loss = 0.272753 (* 1 = 0.272753 loss)
I1210 21:20:22.104063  8872 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1210 21:20:28.047571  8872 solver.cpp:218] Iteration 129100 (16.8266 iter/s, 5.94298s/100 iters), loss = 0.314338
I1210 21:20:28.047571  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:20:28.047571  8872 solver.cpp:237]     Train net output #1: loss = 0.314337 (* 1 = 0.314337 loss)
I1210 21:20:28.047571  8872 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1210 21:20:33.999941  8872 solver.cpp:218] Iteration 129200 (16.8029 iter/s, 5.95136s/100 iters), loss = 0.225945
I1210 21:20:33.999941  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 21:20:33.999941  8872 solver.cpp:237]     Train net output #1: loss = 0.225945 (* 1 = 0.225945 loss)
I1210 21:20:33.999941  8872 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1210 21:20:39.943928  8872 solver.cpp:218] Iteration 129300 (16.8237 iter/s, 5.94401s/100 iters), loss = 0.349191
I1210 21:20:39.943928  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:20:39.943928  8872 solver.cpp:237]     Train net output #1: loss = 0.349191 (* 1 = 0.349191 loss)
I1210 21:20:39.943928  8872 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1210 21:20:45.875010  8872 solver.cpp:218] Iteration 129400 (16.8623 iter/s, 5.93041s/100 iters), loss = 0.331002
I1210 21:20:45.875010  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:20:45.875010  8872 solver.cpp:237]     Train net output #1: loss = 0.331002 (* 1 = 0.331002 loss)
I1210 21:20:45.875010  8872 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1210 21:20:51.529911  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:20:51.763690  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_129500.caffemodel
I1210 21:20:51.779687  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_129500.solverstate
I1210 21:20:51.784692  8872 solver.cpp:330] Iteration 129500, Testing net (#0)
I1210 21:20:51.784692  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:20:53.093142 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:20:53.144148  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6625
I1210 21:20:53.144148  8872 solver.cpp:397]     Test net output #1: loss = 1.3465 (* 1 = 1.3465 loss)
I1210 21:20:53.200155  8872 solver.cpp:218] Iteration 129500 (13.6528 iter/s, 7.3245s/100 iters), loss = 0.313056
I1210 21:20:53.200155  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 21:20:53.200155  8872 solver.cpp:237]     Train net output #1: loss = 0.313056 (* 1 = 0.313056 loss)
I1210 21:20:53.200155  8872 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1210 21:20:59.164913  8872 solver.cpp:218] Iteration 129600 (16.7651 iter/s, 5.96477s/100 iters), loss = 0.331199
I1210 21:20:59.164913  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:20:59.164913  8872 solver.cpp:237]     Train net output #1: loss = 0.331199 (* 1 = 0.331199 loss)
I1210 21:20:59.164913  8872 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1210 21:21:05.120970  8872 solver.cpp:218] Iteration 129700 (16.7914 iter/s, 5.95543s/100 iters), loss = 0.327455
I1210 21:21:05.120970  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:21:05.120970  8872 solver.cpp:237]     Train net output #1: loss = 0.327455 (* 1 = 0.327455 loss)
I1210 21:21:05.120970  8872 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1210 21:21:11.054903  8872 solver.cpp:218] Iteration 129800 (16.854 iter/s, 5.93331s/100 iters), loss = 0.326483
I1210 21:21:11.054903  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:21:11.054903  8872 solver.cpp:237]     Train net output #1: loss = 0.326482 (* 1 = 0.326482 loss)
I1210 21:21:11.054903  8872 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1210 21:21:16.997876  8872 solver.cpp:218] Iteration 129900 (16.8279 iter/s, 5.9425s/100 iters), loss = 0.460198
I1210 21:21:16.997876  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:21:16.997876  8872 solver.cpp:237]     Train net output #1: loss = 0.460198 (* 1 = 0.460198 loss)
I1210 21:21:16.997876  8872 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1210 21:21:22.635556  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:21:22.870111  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_130000.caffemodel
I1210 21:21:22.886118  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_130000.solverstate
I1210 21:21:22.891113  8872 solver.cpp:330] Iteration 130000, Testing net (#0)
I1210 21:21:22.891113  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:21:24.194416 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:21:24.245024  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6592
I1210 21:21:24.245024  8872 solver.cpp:397]     Test net output #1: loss = 1.35854 (* 1 = 1.35854 loss)
I1210 21:21:24.301025  8872 solver.cpp:218] Iteration 130000 (13.693 iter/s, 7.303s/100 iters), loss = 0.366876
I1210 21:21:24.301025  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:21:24.301025  8872 solver.cpp:237]     Train net output #1: loss = 0.366876 (* 1 = 0.366876 loss)
I1210 21:21:24.301025  8872 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1210 21:21:30.234936  8872 solver.cpp:218] Iteration 130100 (16.8532 iter/s, 5.93358s/100 iters), loss = 0.290045
I1210 21:21:30.234936  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:21:30.234936  8872 solver.cpp:237]     Train net output #1: loss = 0.290045 (* 1 = 0.290045 loss)
I1210 21:21:30.234936  8872 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1210 21:21:36.208375  8872 solver.cpp:218] Iteration 130200 (16.7422 iter/s, 5.97292s/100 iters), loss = 0.292409
I1210 21:21:36.208375  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:21:36.208375  8872 solver.cpp:237]     Train net output #1: loss = 0.292409 (* 1 = 0.292409 loss)
I1210 21:21:36.208375  8872 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1210 21:21:42.256148  8872 solver.cpp:218] Iteration 130300 (16.5378 iter/s, 6.04677s/100 iters), loss = 0.384885
I1210 21:21:42.256148  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 21:21:42.256148  8872 solver.cpp:237]     Train net output #1: loss = 0.384885 (* 1 = 0.384885 loss)
I1210 21:21:42.256148  8872 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1210 21:21:48.201638  8872 solver.cpp:218] Iteration 130400 (16.821 iter/s, 5.94494s/100 iters), loss = 0.339255
I1210 21:21:48.201638  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:21:48.201638  8872 solver.cpp:237]     Train net output #1: loss = 0.339255 (* 1 = 0.339255 loss)
I1210 21:21:48.201638  8872 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1210 21:21:53.856091  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:21:54.093107  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_130500.caffemodel
I1210 21:21:54.107108  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_130500.solverstate
I1210 21:21:54.112107  8872 solver.cpp:330] Iteration 130500, Testing net (#0)
I1210 21:21:54.112107  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:21:55.415231 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:21:55.466236  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6688
I1210 21:21:55.466236  8872 solver.cpp:397]     Test net output #1: loss = 1.32658 (* 1 = 1.32658 loss)
I1210 21:21:55.522740  8872 solver.cpp:218] Iteration 130500 (13.6599 iter/s, 7.32068s/100 iters), loss = 0.261299
I1210 21:21:55.522740  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:21:55.522740  8872 solver.cpp:237]     Train net output #1: loss = 0.261298 (* 1 = 0.261298 loss)
I1210 21:21:55.522740  8872 sgd_solver.cpp:105] Iteration 130500, lr = 0.001
I1210 21:22:01.592911  8872 solver.cpp:218] Iteration 130600 (16.4738 iter/s, 6.07023s/100 iters), loss = 0.314901
I1210 21:22:01.592911  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:22:01.593910  8872 solver.cpp:237]     Train net output #1: loss = 0.314901 (* 1 = 0.314901 loss)
I1210 21:22:01.593910  8872 sgd_solver.cpp:105] Iteration 130600, lr = 0.001
I1210 21:22:07.598693  8872 solver.cpp:218] Iteration 130700 (16.6533 iter/s, 6.00481s/100 iters), loss = 0.251378
I1210 21:22:07.598693  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:22:07.598693  8872 solver.cpp:237]     Train net output #1: loss = 0.251378 (* 1 = 0.251378 loss)
I1210 21:22:07.598693  8872 sgd_solver.cpp:105] Iteration 130700, lr = 0.001
I1210 21:22:13.556337  8872 solver.cpp:218] Iteration 130800 (16.7852 iter/s, 5.95763s/100 iters), loss = 0.343519
I1210 21:22:13.557337  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:22:13.557337  8872 solver.cpp:237]     Train net output #1: loss = 0.343519 (* 1 = 0.343519 loss)
I1210 21:22:13.557337  8872 sgd_solver.cpp:105] Iteration 130800, lr = 0.001
I1210 21:22:19.562021  8872 solver.cpp:218] Iteration 130900 (16.6533 iter/s, 6.00481s/100 iters), loss = 0.393592
I1210 21:22:19.562021  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:22:19.562021  8872 solver.cpp:237]     Train net output #1: loss = 0.393592 (* 1 = 0.393592 loss)
I1210 21:22:19.562021  8872 sgd_solver.cpp:105] Iteration 130900, lr = 0.001
I1210 21:22:25.252744  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:22:25.486263  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_131000.caffemodel
I1210 21:22:25.501766  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_131000.solverstate
I1210 21:22:25.506767  8872 solver.cpp:330] Iteration 131000, Testing net (#0)
I1210 21:22:25.506767  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:22:26.811900 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:22:26.862900  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6643
I1210 21:22:26.862900  8872 solver.cpp:397]     Test net output #1: loss = 1.34396 (* 1 = 1.34396 loss)
I1210 21:22:26.919908  8872 solver.cpp:218] Iteration 131000 (13.5917 iter/s, 7.35741s/100 iters), loss = 0.336132
I1210 21:22:26.919908  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 21:22:26.919908  8872 solver.cpp:237]     Train net output #1: loss = 0.336132 (* 1 = 0.336132 loss)
I1210 21:22:26.919908  8872 sgd_solver.cpp:105] Iteration 131000, lr = 0.001
I1210 21:22:32.842347  8872 solver.cpp:218] Iteration 131100 (16.8854 iter/s, 5.92228s/100 iters), loss = 0.254208
I1210 21:22:32.842347  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 21:22:32.843348  8872 solver.cpp:237]     Train net output #1: loss = 0.254208 (* 1 = 0.254208 loss)
I1210 21:22:32.843348  8872 sgd_solver.cpp:105] Iteration 131100, lr = 0.001
I1210 21:22:38.779582  8872 solver.cpp:218] Iteration 131200 (16.8462 iter/s, 5.93605s/100 iters), loss = 0.282608
I1210 21:22:38.779582  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:22:38.779582  8872 solver.cpp:237]     Train net output #1: loss = 0.282608 (* 1 = 0.282608 loss)
I1210 21:22:38.779582  8872 sgd_solver.cpp:105] Iteration 131200, lr = 0.001
I1210 21:22:44.723762  8872 solver.cpp:218] Iteration 131300 (16.8237 iter/s, 5.94399s/100 iters), loss = 0.324619
I1210 21:22:44.723762  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 21:22:44.723762  8872 solver.cpp:237]     Train net output #1: loss = 0.324619 (* 1 = 0.324619 loss)
I1210 21:22:44.723762  8872 sgd_solver.cpp:105] Iteration 131300, lr = 0.001
I1210 21:22:50.686547  8872 solver.cpp:218] Iteration 131400 (16.773 iter/s, 5.96195s/100 iters), loss = 0.379474
I1210 21:22:50.686547  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 21:22:50.686547  8872 solver.cpp:237]     Train net output #1: loss = 0.379474 (* 1 = 0.379474 loss)
I1210 21:22:50.686547  8872 sgd_solver.cpp:105] Iteration 131400, lr = 0.001
I1210 21:22:56.328953  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:22:56.563964  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_131500.caffemodel
I1210 21:22:56.579964  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_131500.solverstate
I1210 21:22:56.584964  8872 solver.cpp:330] Iteration 131500, Testing net (#0)
I1210 21:22:56.584964  8872 net.cpp:676] Ignoring source layer accuracy_training
I1210 21:22:57.887070 20088 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:22:57.938076  8872 solver.cpp:397]     Test net output #0: accuracy = 0.6615
I1210 21:22:57.938076  8872 solver.cpp:397]     Test net output #1: loss = 1.34133 (* 1 = 1.34133 loss)
I1210 21:22:57.995075  8872 solver.cpp:218] Iteration 131500 (13.6835 iter/s, 7.30808s/100 iters), loss = 0.318352
I1210 21:22:57.995075  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:22:57.995075  8872 solver.cpp:237]     Train net output #1: loss = 0.318352 (* 1 = 0.318352 loss)
I1210 21:22:57.995075  8872 sgd_solver.cpp:105] Iteration 131500, lr = 0.001
I1210 21:23:03.939529  8872 solver.cpp:218] Iteration 131600 (16.8223 iter/s, 5.9445s/100 iters), loss = 0.300013
I1210 21:23:03.939529  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 21:23:03.939529  8872 solver.cpp:237]     Train net output #1: loss = 0.300013 (* 1 = 0.300013 loss)
I1210 21:23:03.939529  8872 sgd_solver.cpp:105] Iteration 131600, lr = 0.001
I1210 21:23:09.870008  8872 solver.cpp:218] Iteration 131700 (16.8629 iter/s, 5.93016s/100 iters), loss = 0.231425
I1210 21:23:09.871009  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 21:23:09.871009  8872 solver.cpp:237]     Train net output #1: loss = 0.231425 (* 1 = 0.231425 loss)
I1210 21:23:09.871009  8872 sgd_solver.cpp:105] Iteration 131700, lr = 0.001
I1210 21:23:15.801316  8872 solver.cpp:218] Iteration 131800 (16.8615 iter/s, 5.93065s/100 iters), loss = 0.384545
I1210 21:23:15.801316  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 21:23:15.801316  8872 solver.cpp:237]     Train net output #1: loss = 0.384545 (* 1 = 0.384545 loss)
I1210 21:23:15.801316  8872 sgd_solver.cpp:105] Iteration 131800, lr = 0.001
I1210 21:23:21.738737  8872 solver.cpp:218] Iteration 131900 (16.8458 iter/s, 5.9362s/100 iters), loss = 0.380818
I1210 21:23:21.738737  8872 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 21:23:21.738737  8872 solver.cpp:237]     Train net output #1: loss = 0.380818 (* 1 = 0.380818 loss)
I1210 21:23:21.738737  8872 sgd_solver.cpp:105] Iteration 131900, lr = 0.001
I1210 21:23:27.397467  1444 data_layer.cpp:73] Restarting data prefetching from start.
I1210 21:23:27.630484  8872 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_132000.caffemodel
I1210 21:23:27.646484  8872 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_iter_