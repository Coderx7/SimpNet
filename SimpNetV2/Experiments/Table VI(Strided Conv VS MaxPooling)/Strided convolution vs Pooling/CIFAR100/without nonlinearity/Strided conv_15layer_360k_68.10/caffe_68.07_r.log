
G:\Caffe\examples\cifar100>REM go to the caffe root 

G:\Caffe\examples\cifar100>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar100/fcifar100_full_relu_solver_bn.prototxt --snapshot=examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_90000.solverstate 
I1107 21:48:25.493261 18604 caffe.cpp:219] Using GPUs 0
I1107 21:48:25.652413 18604 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1107 21:48:25.945119 18604 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1107 21:48:25.963115 18604 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1107 21:48:25.964117 18604 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1107 21:48:26.074784 18604 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1107 21:48:26.074784 18604 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1107 21:48:26.074784 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1107 21:48:26.075783 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1107 21:48:26.075783 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1107 21:48:26.075783 18604 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1107 21:48:26.075783 18604 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV1_360k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "pool2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "pool4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1107 21:48:26.145184 18604 layer_factory.cpp:58] Creating layer cifar
I1107 21:48:26.148182 18604 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1107 21:48:26.148182 18604 net.cpp:84] Creating Layer cifar
I1107 21:48:26.148182 18604 net.cpp:380] cifar -> data
I1107 21:48:26.148182 18604 net.cpp:380] cifar -> label
I1107 21:48:26.149183 18604 data_layer.cpp:45] output data size: 100,3,32,32
I1107 21:48:26.159574 18604 net.cpp:122] Setting up cifar
I1107 21:48:26.159574 18604 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1107 21:48:26.159574 18604 net.cpp:129] Top shape: 100 (100)
I1107 21:48:26.159574 18604 net.cpp:137] Memory required for data: 1229200
I1107 21:48:26.159574 18604 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1107 21:48:26.159574 18604 net.cpp:84] Creating Layer label_cifar_1_split
I1107 21:48:26.159574 18604 net.cpp:406] label_cifar_1_split <- label
I1107 21:48:26.159574 18604 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1107 21:48:26.159574 18604 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1107 21:48:26.159574 18604 net.cpp:122] Setting up label_cifar_1_split
I1107 21:48:26.159574 18604 net.cpp:129] Top shape: 100 (100)
I1107 21:48:26.159574 18604 net.cpp:129] Top shape: 100 (100)
I1107 21:48:26.159574 18604 net.cpp:137] Memory required for data: 1230000
I1107 21:48:26.159574 18604 layer_factory.cpp:58] Creating layer conv1
I1107 21:48:26.159574 18604 net.cpp:84] Creating Layer conv1
I1107 21:48:26.159574 18604 net.cpp:406] conv1 <- data
I1107 21:48:26.159574 18604 net.cpp:380] conv1 -> conv1
I1107 21:48:26.160581  9388 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1107 21:48:26.400617 18604 net.cpp:122] Setting up conv1
I1107 21:48:26.400617 18604 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 21:48:26.400617 18604 net.cpp:137] Memory required for data: 13518000
I1107 21:48:26.400617 18604 layer_factory.cpp:58] Creating layer bn1
I1107 21:48:26.400617 18604 net.cpp:84] Creating Layer bn1
I1107 21:48:26.400617 18604 net.cpp:406] bn1 <- conv1
I1107 21:48:26.400617 18604 net.cpp:367] bn1 -> conv1 (in-place)
I1107 21:48:26.400617 18604 net.cpp:122] Setting up bn1
I1107 21:48:26.400617 18604 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 21:48:26.400617 18604 net.cpp:137] Memory required for data: 25806000
I1107 21:48:26.400617 18604 layer_factory.cpp:58] Creating layer scale1
I1107 21:48:26.400617 18604 net.cpp:84] Creating Layer scale1
I1107 21:48:26.400617 18604 net.cpp:406] scale1 <- conv1
I1107 21:48:26.400617 18604 net.cpp:367] scale1 -> conv1 (in-place)
I1107 21:48:26.400617 18604 layer_factory.cpp:58] Creating layer scale1
I1107 21:48:26.400617 18604 net.cpp:122] Setting up scale1
I1107 21:48:26.400617 18604 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 21:48:26.400617 18604 net.cpp:137] Memory required for data: 38094000
I1107 21:48:26.400617 18604 layer_factory.cpp:58] Creating layer relu1
I1107 21:48:26.400617 18604 net.cpp:84] Creating Layer relu1
I1107 21:48:26.400617 18604 net.cpp:406] relu1 <- conv1
I1107 21:48:26.400617 18604 net.cpp:367] relu1 -> conv1 (in-place)
I1107 21:48:26.400617 18604 net.cpp:122] Setting up relu1
I1107 21:48:26.400617 18604 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 21:48:26.400617 18604 net.cpp:137] Memory required for data: 50382000
I1107 21:48:26.401618 18604 layer_factory.cpp:58] Creating layer conv1_0
I1107 21:48:26.401618 18604 net.cpp:84] Creating Layer conv1_0
I1107 21:48:26.401618 18604 net.cpp:406] conv1_0 <- conv1
I1107 21:48:26.401618 18604 net.cpp:380] conv1_0 -> conv1_0
I1107 21:48:26.402618 18604 net.cpp:122] Setting up conv1_0
I1107 21:48:26.402618 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.402618 18604 net.cpp:137] Memory required for data: 66766000
I1107 21:48:26.402618 18604 layer_factory.cpp:58] Creating layer bn1_0
I1107 21:48:26.402618 18604 net.cpp:84] Creating Layer bn1_0
I1107 21:48:26.402618 18604 net.cpp:406] bn1_0 <- conv1_0
I1107 21:48:26.402618 18604 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1107 21:48:26.402618 18604 net.cpp:122] Setting up bn1_0
I1107 21:48:26.402618 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.402618 18604 net.cpp:137] Memory required for data: 83150000
I1107 21:48:26.402618 18604 layer_factory.cpp:58] Creating layer scale1_0
I1107 21:48:26.402618 18604 net.cpp:84] Creating Layer scale1_0
I1107 21:48:26.402618 18604 net.cpp:406] scale1_0 <- conv1_0
I1107 21:48:26.402618 18604 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1107 21:48:26.402618 18604 layer_factory.cpp:58] Creating layer scale1_0
I1107 21:48:26.402618 18604 net.cpp:122] Setting up scale1_0
I1107 21:48:26.402618 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.403617 18604 net.cpp:137] Memory required for data: 99534000
I1107 21:48:26.403617 18604 layer_factory.cpp:58] Creating layer relu1_0
I1107 21:48:26.403617 18604 net.cpp:84] Creating Layer relu1_0
I1107 21:48:26.403617 18604 net.cpp:406] relu1_0 <- conv1_0
I1107 21:48:26.403617 18604 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1107 21:48:26.403617 18604 net.cpp:122] Setting up relu1_0
I1107 21:48:26.403617 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.403617 18604 net.cpp:137] Memory required for data: 115918000
I1107 21:48:26.403617 18604 layer_factory.cpp:58] Creating layer conv2
I1107 21:48:26.403617 18604 net.cpp:84] Creating Layer conv2
I1107 21:48:26.403617 18604 net.cpp:406] conv2 <- conv1_0
I1107 21:48:26.403617 18604 net.cpp:380] conv2 -> conv2
I1107 21:48:26.404618 18604 net.cpp:122] Setting up conv2
I1107 21:48:26.404618 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.404618 18604 net.cpp:137] Memory required for data: 132302000
I1107 21:48:26.404618 18604 layer_factory.cpp:58] Creating layer bn2
I1107 21:48:26.404618 18604 net.cpp:84] Creating Layer bn2
I1107 21:48:26.404618 18604 net.cpp:406] bn2 <- conv2
I1107 21:48:26.404618 18604 net.cpp:367] bn2 -> conv2 (in-place)
I1107 21:48:26.404618 18604 net.cpp:122] Setting up bn2
I1107 21:48:26.404618 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.404618 18604 net.cpp:137] Memory required for data: 148686000
I1107 21:48:26.404618 18604 layer_factory.cpp:58] Creating layer scale2
I1107 21:48:26.404618 18604 net.cpp:84] Creating Layer scale2
I1107 21:48:26.404618 18604 net.cpp:406] scale2 <- conv2
I1107 21:48:26.404618 18604 net.cpp:367] scale2 -> conv2 (in-place)
I1107 21:48:26.404618 18604 layer_factory.cpp:58] Creating layer scale2
I1107 21:48:26.404618 18604 net.cpp:122] Setting up scale2
I1107 21:48:26.404618 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.404618 18604 net.cpp:137] Memory required for data: 165070000
I1107 21:48:26.404618 18604 layer_factory.cpp:58] Creating layer relu2
I1107 21:48:26.404618 18604 net.cpp:84] Creating Layer relu2
I1107 21:48:26.404618 18604 net.cpp:406] relu2 <- conv2
I1107 21:48:26.404618 18604 net.cpp:367] relu2 -> conv2 (in-place)
I1107 21:48:26.405617 18604 net.cpp:122] Setting up relu2
I1107 21:48:26.405617 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.405617 18604 net.cpp:137] Memory required for data: 181454000
I1107 21:48:26.405617 18604 layer_factory.cpp:58] Creating layer conv2_1
I1107 21:48:26.405617 18604 net.cpp:84] Creating Layer conv2_1
I1107 21:48:26.405617 18604 net.cpp:406] conv2_1 <- conv2
I1107 21:48:26.405617 18604 net.cpp:380] conv2_1 -> conv2_1
I1107 21:48:26.406617 18604 net.cpp:122] Setting up conv2_1
I1107 21:48:26.406617 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.406617 18604 net.cpp:137] Memory required for data: 197838000
I1107 21:48:26.406617 18604 layer_factory.cpp:58] Creating layer bn2_1
I1107 21:48:26.406617 18604 net.cpp:84] Creating Layer bn2_1
I1107 21:48:26.406617 18604 net.cpp:406] bn2_1 <- conv2_1
I1107 21:48:26.406617 18604 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1107 21:48:26.406617 18604 net.cpp:122] Setting up bn2_1
I1107 21:48:26.406617 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.406617 18604 net.cpp:137] Memory required for data: 214222000
I1107 21:48:26.406617 18604 layer_factory.cpp:58] Creating layer scale2_1
I1107 21:48:26.406617 18604 net.cpp:84] Creating Layer scale2_1
I1107 21:48:26.406617 18604 net.cpp:406] scale2_1 <- conv2_1
I1107 21:48:26.406617 18604 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1107 21:48:26.406617 18604 layer_factory.cpp:58] Creating layer scale2_1
I1107 21:48:26.406617 18604 net.cpp:122] Setting up scale2_1
I1107 21:48:26.406617 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.406617 18604 net.cpp:137] Memory required for data: 230606000
I1107 21:48:26.406617 18604 layer_factory.cpp:58] Creating layer relu2_1
I1107 21:48:26.406617 18604 net.cpp:84] Creating Layer relu2_1
I1107 21:48:26.406617 18604 net.cpp:406] relu2_1 <- conv2_1
I1107 21:48:26.406617 18604 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1107 21:48:26.406617 18604 net.cpp:122] Setting up relu2_1
I1107 21:48:26.406617 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.406617 18604 net.cpp:137] Memory required for data: 246990000
I1107 21:48:26.407618 18604 layer_factory.cpp:58] Creating layer conv2_2
I1107 21:48:26.407618 18604 net.cpp:84] Creating Layer conv2_2
I1107 21:48:26.407618 18604 net.cpp:406] conv2_2 <- conv2_1
I1107 21:48:26.407618 18604 net.cpp:380] conv2_2 -> conv2_2
I1107 21:48:26.408617 18604 net.cpp:122] Setting up conv2_2
I1107 21:48:26.408617 18604 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 21:48:26.408617 18604 net.cpp:137] Memory required for data: 267470000
I1107 21:48:26.408617 18604 layer_factory.cpp:58] Creating layer bn2_2
I1107 21:48:26.408617 18604 net.cpp:84] Creating Layer bn2_2
I1107 21:48:26.408617 18604 net.cpp:406] bn2_2 <- conv2_2
I1107 21:48:26.408617 18604 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1107 21:48:26.409617 18604 net.cpp:122] Setting up bn2_2
I1107 21:48:26.409617 18604 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 21:48:26.409617 18604 net.cpp:137] Memory required for data: 287950000
I1107 21:48:26.409617 18604 layer_factory.cpp:58] Creating layer scale2_2
I1107 21:48:26.409617 18604 net.cpp:84] Creating Layer scale2_2
I1107 21:48:26.409617 18604 net.cpp:406] scale2_2 <- conv2_2
I1107 21:48:26.409617 18604 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1107 21:48:26.409617 18604 layer_factory.cpp:58] Creating layer scale2_2
I1107 21:48:26.409617 18604 net.cpp:122] Setting up scale2_2
I1107 21:48:26.409617 18604 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 21:48:26.409617 18604 net.cpp:137] Memory required for data: 308430000
I1107 21:48:26.409617 18604 layer_factory.cpp:58] Creating layer relu2_2
I1107 21:48:26.409617 18604 net.cpp:84] Creating Layer relu2_2
I1107 21:48:26.409617 18604 net.cpp:406] relu2_2 <- conv2_2
I1107 21:48:26.409617 18604 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1107 21:48:26.409617 18604 net.cpp:122] Setting up relu2_2
I1107 21:48:26.409617 18604 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 21:48:26.409617 18604 net.cpp:137] Memory required for data: 328910000
I1107 21:48:26.409617 18604 layer_factory.cpp:58] Creating layer pool2_1
I1107 21:48:26.409617 18604 net.cpp:84] Creating Layer pool2_1
I1107 21:48:26.409617 18604 net.cpp:406] pool2_1 <- conv2_2
I1107 21:48:26.409617 18604 net.cpp:380] pool2_1 -> pool2_1
I1107 21:48:26.410617 18604 net.cpp:122] Setting up pool2_1
I1107 21:48:26.410617 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.410617 18604 net.cpp:137] Memory required for data: 334030000
I1107 21:48:26.410617 18604 layer_factory.cpp:58] Creating layer conv3
I1107 21:48:26.410617 18604 net.cpp:84] Creating Layer conv3
I1107 21:48:26.410617 18604 net.cpp:406] conv3 <- pool2_1
I1107 21:48:26.410617 18604 net.cpp:380] conv3 -> conv3
I1107 21:48:26.412617 18604 net.cpp:122] Setting up conv3
I1107 21:48:26.412617 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.412617 18604 net.cpp:137] Memory required for data: 339150000
I1107 21:48:26.412617 18604 layer_factory.cpp:58] Creating layer bn3
I1107 21:48:26.412617 18604 net.cpp:84] Creating Layer bn3
I1107 21:48:26.412617 18604 net.cpp:406] bn3 <- conv3
I1107 21:48:26.412617 18604 net.cpp:367] bn3 -> conv3 (in-place)
I1107 21:48:26.412617 18604 net.cpp:122] Setting up bn3
I1107 21:48:26.412617 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.412617 18604 net.cpp:137] Memory required for data: 344270000
I1107 21:48:26.412617 18604 layer_factory.cpp:58] Creating layer scale3
I1107 21:48:26.412617 18604 net.cpp:84] Creating Layer scale3
I1107 21:48:26.412617 18604 net.cpp:406] scale3 <- conv3
I1107 21:48:26.412617 18604 net.cpp:367] scale3 -> conv3 (in-place)
I1107 21:48:26.412617 18604 layer_factory.cpp:58] Creating layer scale3
I1107 21:48:26.412617 18604 net.cpp:122] Setting up scale3
I1107 21:48:26.412617 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.412617 18604 net.cpp:137] Memory required for data: 349390000
I1107 21:48:26.412617 18604 layer_factory.cpp:58] Creating layer relu3
I1107 21:48:26.412617 18604 net.cpp:84] Creating Layer relu3
I1107 21:48:26.412617 18604 net.cpp:406] relu3 <- conv3
I1107 21:48:26.412617 18604 net.cpp:367] relu3 -> conv3 (in-place)
I1107 21:48:26.412617 18604 net.cpp:122] Setting up relu3
I1107 21:48:26.412617 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.412617 18604 net.cpp:137] Memory required for data: 354510000
I1107 21:48:26.412617 18604 layer_factory.cpp:58] Creating layer conv3_1
I1107 21:48:26.412617 18604 net.cpp:84] Creating Layer conv3_1
I1107 21:48:26.412617 18604 net.cpp:406] conv3_1 <- conv3
I1107 21:48:26.412617 18604 net.cpp:380] conv3_1 -> conv3_1
I1107 21:48:26.414121 18604 net.cpp:122] Setting up conv3_1
I1107 21:48:26.414121 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.414121 18604 net.cpp:137] Memory required for data: 359630000
I1107 21:48:26.414121 18604 layer_factory.cpp:58] Creating layer bn3_1
I1107 21:48:26.414121 18604 net.cpp:84] Creating Layer bn3_1
I1107 21:48:26.414121 18604 net.cpp:406] bn3_1 <- conv3_1
I1107 21:48:26.414121 18604 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1107 21:48:26.414621 18604 net.cpp:122] Setting up bn3_1
I1107 21:48:26.414621 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.414621 18604 net.cpp:137] Memory required for data: 364750000
I1107 21:48:26.414621 18604 layer_factory.cpp:58] Creating layer scale3_1
I1107 21:48:26.414621 18604 net.cpp:84] Creating Layer scale3_1
I1107 21:48:26.414621 18604 net.cpp:406] scale3_1 <- conv3_1
I1107 21:48:26.414621 18604 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1107 21:48:26.414621 18604 layer_factory.cpp:58] Creating layer scale3_1
I1107 21:48:26.414621 18604 net.cpp:122] Setting up scale3_1
I1107 21:48:26.414621 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.414621 18604 net.cpp:137] Memory required for data: 369870000
I1107 21:48:26.414621 18604 layer_factory.cpp:58] Creating layer relu3_1
I1107 21:48:26.414621 18604 net.cpp:84] Creating Layer relu3_1
I1107 21:48:26.414621 18604 net.cpp:406] relu3_1 <- conv3_1
I1107 21:48:26.414621 18604 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1107 21:48:26.415122 18604 net.cpp:122] Setting up relu3_1
I1107 21:48:26.415122 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.415122 18604 net.cpp:137] Memory required for data: 374990000
I1107 21:48:26.415122 18604 layer_factory.cpp:58] Creating layer conv4
I1107 21:48:26.415122 18604 net.cpp:84] Creating Layer conv4
I1107 21:48:26.415122 18604 net.cpp:406] conv4 <- conv3_1
I1107 21:48:26.415122 18604 net.cpp:380] conv4 -> conv4
I1107 21:48:26.416627 18604 net.cpp:122] Setting up conv4
I1107 21:48:26.416627 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.416627 18604 net.cpp:137] Memory required for data: 380110000
I1107 21:48:26.416627 18604 layer_factory.cpp:58] Creating layer bn4
I1107 21:48:26.416627 18604 net.cpp:84] Creating Layer bn4
I1107 21:48:26.416627 18604 net.cpp:406] bn4 <- conv4
I1107 21:48:26.416627 18604 net.cpp:367] bn4 -> conv4 (in-place)
I1107 21:48:26.416627 18604 net.cpp:122] Setting up bn4
I1107 21:48:26.416627 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.416627 18604 net.cpp:137] Memory required for data: 385230000
I1107 21:48:26.416627 18604 layer_factory.cpp:58] Creating layer scale4
I1107 21:48:26.417122 18604 net.cpp:84] Creating Layer scale4
I1107 21:48:26.417122 18604 net.cpp:406] scale4 <- conv4
I1107 21:48:26.417122 18604 net.cpp:367] scale4 -> conv4 (in-place)
I1107 21:48:26.417122 18604 layer_factory.cpp:58] Creating layer scale4
I1107 21:48:26.417122 18604 net.cpp:122] Setting up scale4
I1107 21:48:26.417122 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.417122 18604 net.cpp:137] Memory required for data: 390350000
I1107 21:48:26.417122 18604 layer_factory.cpp:58] Creating layer relu4
I1107 21:48:26.417122 18604 net.cpp:84] Creating Layer relu4
I1107 21:48:26.417122 18604 net.cpp:406] relu4 <- conv4
I1107 21:48:26.417122 18604 net.cpp:367] relu4 -> conv4 (in-place)
I1107 21:48:26.417623 18604 net.cpp:122] Setting up relu4
I1107 21:48:26.417623 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.417623 18604 net.cpp:137] Memory required for data: 395470000
I1107 21:48:26.417623 18604 layer_factory.cpp:58] Creating layer conv4_1
I1107 21:48:26.417623 18604 net.cpp:84] Creating Layer conv4_1
I1107 21:48:26.417623 18604 net.cpp:406] conv4_1 <- conv4
I1107 21:48:26.417623 18604 net.cpp:380] conv4_1 -> conv4_1
I1107 21:48:26.418622 18604 net.cpp:122] Setting up conv4_1
I1107 21:48:26.418622 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.418622 18604 net.cpp:137] Memory required for data: 400590000
I1107 21:48:26.418622 18604 layer_factory.cpp:58] Creating layer bn4_1
I1107 21:48:26.418622 18604 net.cpp:84] Creating Layer bn4_1
I1107 21:48:26.418622 18604 net.cpp:406] bn4_1 <- conv4_1
I1107 21:48:26.418622 18604 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1107 21:48:26.419121 18604 net.cpp:122] Setting up bn4_1
I1107 21:48:26.419121 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.419121 18604 net.cpp:137] Memory required for data: 405710000
I1107 21:48:26.419121 18604 layer_factory.cpp:58] Creating layer scale4_1
I1107 21:48:26.419121 18604 net.cpp:84] Creating Layer scale4_1
I1107 21:48:26.419121 18604 net.cpp:406] scale4_1 <- conv4_1
I1107 21:48:26.419121 18604 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1107 21:48:26.419121 18604 layer_factory.cpp:58] Creating layer scale4_1
I1107 21:48:26.419121 18604 net.cpp:122] Setting up scale4_1
I1107 21:48:26.419121 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.419121 18604 net.cpp:137] Memory required for data: 410830000
I1107 21:48:26.419121 18604 layer_factory.cpp:58] Creating layer relu4_1
I1107 21:48:26.419121 18604 net.cpp:84] Creating Layer relu4_1
I1107 21:48:26.419121 18604 net.cpp:406] relu4_1 <- conv4_1
I1107 21:48:26.419121 18604 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1107 21:48:26.419622 18604 net.cpp:122] Setting up relu4_1
I1107 21:48:26.419622 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.419622 18604 net.cpp:137] Memory required for data: 415950000
I1107 21:48:26.419622 18604 layer_factory.cpp:58] Creating layer conv4_2
I1107 21:48:26.419622 18604 net.cpp:84] Creating Layer conv4_2
I1107 21:48:26.419622 18604 net.cpp:406] conv4_2 <- conv4_1
I1107 21:48:26.419622 18604 net.cpp:380] conv4_2 -> conv4_2
I1107 21:48:26.421121 18604 net.cpp:122] Setting up conv4_2
I1107 21:48:26.421121 18604 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 21:48:26.421121 18604 net.cpp:137] Memory required for data: 421889200
I1107 21:48:26.421121 18604 layer_factory.cpp:58] Creating layer bn4_2
I1107 21:48:26.421121 18604 net.cpp:84] Creating Layer bn4_2
I1107 21:48:26.421121 18604 net.cpp:406] bn4_2 <- conv4_2
I1107 21:48:26.421121 18604 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1107 21:48:26.421121 18604 net.cpp:122] Setting up bn4_2
I1107 21:48:26.421622 18604 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 21:48:26.421622 18604 net.cpp:137] Memory required for data: 427828400
I1107 21:48:26.421622 18604 layer_factory.cpp:58] Creating layer scale4_2
I1107 21:48:26.421622 18604 net.cpp:84] Creating Layer scale4_2
I1107 21:48:26.421622 18604 net.cpp:406] scale4_2 <- conv4_2
I1107 21:48:26.421622 18604 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1107 21:48:26.421622 18604 layer_factory.cpp:58] Creating layer scale4_2
I1107 21:48:26.421622 18604 net.cpp:122] Setting up scale4_2
I1107 21:48:26.421622 18604 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 21:48:26.421622 18604 net.cpp:137] Memory required for data: 433767600
I1107 21:48:26.421622 18604 layer_factory.cpp:58] Creating layer relu4_2
I1107 21:48:26.421622 18604 net.cpp:84] Creating Layer relu4_2
I1107 21:48:26.421622 18604 net.cpp:406] relu4_2 <- conv4_2
I1107 21:48:26.421622 18604 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1107 21:48:26.422122 18604 net.cpp:122] Setting up relu4_2
I1107 21:48:26.422122 18604 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 21:48:26.422122 18604 net.cpp:137] Memory required for data: 439706800
I1107 21:48:26.422122 18604 layer_factory.cpp:58] Creating layer pool4_2
I1107 21:48:26.422122 18604 net.cpp:84] Creating Layer pool4_2
I1107 21:48:26.422122 18604 net.cpp:406] pool4_2 <- conv4_2
I1107 21:48:26.422122 18604 net.cpp:380] pool4_2 -> pool4_2
I1107 21:48:26.423123 18604 net.cpp:122] Setting up pool4_2
I1107 21:48:26.423123 18604 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 21:48:26.423123 18604 net.cpp:137] Memory required for data: 441191600
I1107 21:48:26.423123 18604 layer_factory.cpp:58] Creating layer conv4_0
I1107 21:48:26.423621 18604 net.cpp:84] Creating Layer conv4_0
I1107 21:48:26.423621 18604 net.cpp:406] conv4_0 <- pool4_2
I1107 21:48:26.423621 18604 net.cpp:380] conv4_0 -> conv4_0
I1107 21:48:26.424621 18604 net.cpp:122] Setting up conv4_0
I1107 21:48:26.424621 18604 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 21:48:26.424621 18604 net.cpp:137] Memory required for data: 442676400
I1107 21:48:26.424621 18604 layer_factory.cpp:58] Creating layer bn4_0
I1107 21:48:26.424621 18604 net.cpp:84] Creating Layer bn4_0
I1107 21:48:26.424621 18604 net.cpp:406] bn4_0 <- conv4_0
I1107 21:48:26.424621 18604 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1107 21:48:26.424621 18604 net.cpp:122] Setting up bn4_0
I1107 21:48:26.424621 18604 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 21:48:26.424621 18604 net.cpp:137] Memory required for data: 444161200
I1107 21:48:26.424621 18604 layer_factory.cpp:58] Creating layer scale4_0
I1107 21:48:26.424621 18604 net.cpp:84] Creating Layer scale4_0
I1107 21:48:26.424621 18604 net.cpp:406] scale4_0 <- conv4_0
I1107 21:48:26.424621 18604 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1107 21:48:26.424621 18604 layer_factory.cpp:58] Creating layer scale4_0
I1107 21:48:26.425122 18604 net.cpp:122] Setting up scale4_0
I1107 21:48:26.425122 18604 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 21:48:26.425122 18604 net.cpp:137] Memory required for data: 445646000
I1107 21:48:26.425122 18604 layer_factory.cpp:58] Creating layer relu4_0
I1107 21:48:26.425122 18604 net.cpp:84] Creating Layer relu4_0
I1107 21:48:26.425122 18604 net.cpp:406] relu4_0 <- conv4_0
I1107 21:48:26.425122 18604 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1107 21:48:26.425122 18604 net.cpp:122] Setting up relu4_0
I1107 21:48:26.425122 18604 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 21:48:26.425122 18604 net.cpp:137] Memory required for data: 447130800
I1107 21:48:26.425122 18604 layer_factory.cpp:58] Creating layer conv11
I1107 21:48:26.425122 18604 net.cpp:84] Creating Layer conv11
I1107 21:48:26.425122 18604 net.cpp:406] conv11 <- conv4_0
I1107 21:48:26.425122 18604 net.cpp:380] conv11 -> conv11
I1107 21:48:26.427121 18604 net.cpp:122] Setting up conv11
I1107 21:48:26.427121 18604 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 21:48:26.427121 18604 net.cpp:137] Memory required for data: 448922800
I1107 21:48:26.427121 18604 layer_factory.cpp:58] Creating layer bn_conv11
I1107 21:48:26.427121 18604 net.cpp:84] Creating Layer bn_conv11
I1107 21:48:26.427121 18604 net.cpp:406] bn_conv11 <- conv11
I1107 21:48:26.427121 18604 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1107 21:48:26.427621 18604 net.cpp:122] Setting up bn_conv11
I1107 21:48:26.427621 18604 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 21:48:26.427621 18604 net.cpp:137] Memory required for data: 450714800
I1107 21:48:26.427621 18604 layer_factory.cpp:58] Creating layer scale_conv11
I1107 21:48:26.427621 18604 net.cpp:84] Creating Layer scale_conv11
I1107 21:48:26.427621 18604 net.cpp:406] scale_conv11 <- conv11
I1107 21:48:26.427621 18604 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1107 21:48:26.427621 18604 layer_factory.cpp:58] Creating layer scale_conv11
I1107 21:48:26.427621 18604 net.cpp:122] Setting up scale_conv11
I1107 21:48:26.427621 18604 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 21:48:26.427621 18604 net.cpp:137] Memory required for data: 452506800
I1107 21:48:26.427621 18604 layer_factory.cpp:58] Creating layer relu_conv11
I1107 21:48:26.427621 18604 net.cpp:84] Creating Layer relu_conv11
I1107 21:48:26.427621 18604 net.cpp:406] relu_conv11 <- conv11
I1107 21:48:26.427621 18604 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1107 21:48:26.428122 18604 net.cpp:122] Setting up relu_conv11
I1107 21:48:26.428122 18604 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 21:48:26.428122 18604 net.cpp:137] Memory required for data: 454298800
I1107 21:48:26.428122 18604 layer_factory.cpp:58] Creating layer conv12
I1107 21:48:26.428122 18604 net.cpp:84] Creating Layer conv12
I1107 21:48:26.428122 18604 net.cpp:406] conv12 <- conv11
I1107 21:48:26.428122 18604 net.cpp:380] conv12 -> conv12
I1107 21:48:26.429621 18604 net.cpp:122] Setting up conv12
I1107 21:48:26.429621 18604 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 21:48:26.429621 18604 net.cpp:137] Memory required for data: 456602800
I1107 21:48:26.429621 18604 layer_factory.cpp:58] Creating layer bn_conv12
I1107 21:48:26.429621 18604 net.cpp:84] Creating Layer bn_conv12
I1107 21:48:26.429621 18604 net.cpp:406] bn_conv12 <- conv12
I1107 21:48:26.429621 18604 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1107 21:48:26.429621 18604 net.cpp:122] Setting up bn_conv12
I1107 21:48:26.429621 18604 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 21:48:26.429621 18604 net.cpp:137] Memory required for data: 458906800
I1107 21:48:26.429621 18604 layer_factory.cpp:58] Creating layer scale_conv12
I1107 21:48:26.429621 18604 net.cpp:84] Creating Layer scale_conv12
I1107 21:48:26.429621 18604 net.cpp:406] scale_conv12 <- conv12
I1107 21:48:26.429621 18604 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1107 21:48:26.429621 18604 layer_factory.cpp:58] Creating layer scale_conv12
I1107 21:48:26.429621 18604 net.cpp:122] Setting up scale_conv12
I1107 21:48:26.429621 18604 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 21:48:26.429621 18604 net.cpp:137] Memory required for data: 461210800
I1107 21:48:26.429621 18604 layer_factory.cpp:58] Creating layer relu_conv12
I1107 21:48:26.429621 18604 net.cpp:84] Creating Layer relu_conv12
I1107 21:48:26.429621 18604 net.cpp:406] relu_conv12 <- conv12
I1107 21:48:26.429621 18604 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1107 21:48:26.429621 18604 net.cpp:122] Setting up relu_conv12
I1107 21:48:26.429621 18604 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 21:48:26.429621 18604 net.cpp:137] Memory required for data: 463514800
I1107 21:48:26.429621 18604 layer_factory.cpp:58] Creating layer poolcp6
I1107 21:48:26.429621 18604 net.cpp:84] Creating Layer poolcp6
I1107 21:48:26.429621 18604 net.cpp:406] poolcp6 <- conv12
I1107 21:48:26.429621 18604 net.cpp:380] poolcp6 -> poolcp6
I1107 21:48:26.429621 18604 net.cpp:122] Setting up poolcp6
I1107 21:48:26.429621 18604 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1107 21:48:26.429621 18604 net.cpp:137] Memory required for data: 463550800
I1107 21:48:26.429621 18604 layer_factory.cpp:58] Creating layer ip1
I1107 21:48:26.429621 18604 net.cpp:84] Creating Layer ip1
I1107 21:48:26.429621 18604 net.cpp:406] ip1 <- poolcp6
I1107 21:48:26.429621 18604 net.cpp:380] ip1 -> ip1
I1107 21:48:26.430626 18604 net.cpp:122] Setting up ip1
I1107 21:48:26.430626 18604 net.cpp:129] Top shape: 100 100 (10000)
I1107 21:48:26.430626 18604 net.cpp:137] Memory required for data: 463590800
I1107 21:48:26.430626 18604 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1107 21:48:26.430626 18604 net.cpp:84] Creating Layer ip1_ip1_0_split
I1107 21:48:26.430626 18604 net.cpp:406] ip1_ip1_0_split <- ip1
I1107 21:48:26.430626 18604 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1107 21:48:26.430626 18604 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1107 21:48:26.430626 18604 net.cpp:122] Setting up ip1_ip1_0_split
I1107 21:48:26.430626 18604 net.cpp:129] Top shape: 100 100 (10000)
I1107 21:48:26.430626 18604 net.cpp:129] Top shape: 100 100 (10000)
I1107 21:48:26.430626 18604 net.cpp:137] Memory required for data: 463670800
I1107 21:48:26.430626 18604 layer_factory.cpp:58] Creating layer accuracy_training
I1107 21:48:26.430626 18604 net.cpp:84] Creating Layer accuracy_training
I1107 21:48:26.430626 18604 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1107 21:48:26.430626 18604 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1107 21:48:26.430626 18604 net.cpp:380] accuracy_training -> accuracy_training
I1107 21:48:26.430626 18604 net.cpp:122] Setting up accuracy_training
I1107 21:48:26.430626 18604 net.cpp:129] Top shape: (1)
I1107 21:48:26.430626 18604 net.cpp:137] Memory required for data: 463670804
I1107 21:48:26.430626 18604 layer_factory.cpp:58] Creating layer loss
I1107 21:48:26.430626 18604 net.cpp:84] Creating Layer loss
I1107 21:48:26.430626 18604 net.cpp:406] loss <- ip1_ip1_0_split_1
I1107 21:48:26.430626 18604 net.cpp:406] loss <- label_cifar_1_split_1
I1107 21:48:26.430626 18604 net.cpp:380] loss -> loss
I1107 21:48:26.430626 18604 layer_factory.cpp:58] Creating layer loss
I1107 21:48:26.430626 18604 net.cpp:122] Setting up loss
I1107 21:48:26.430626 18604 net.cpp:129] Top shape: (1)
I1107 21:48:26.430626 18604 net.cpp:132]     with loss weight 1
I1107 21:48:26.430626 18604 net.cpp:137] Memory required for data: 463670808
I1107 21:48:26.430626 18604 net.cpp:198] loss needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:200] accuracy_training does not need backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] ip1 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] poolcp6 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] relu_conv12 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] scale_conv12 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] bn_conv12 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] conv12 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] relu_conv11 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] scale_conv11 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] bn_conv11 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] conv11 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] relu4_0 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] scale4_0 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] bn4_0 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] conv4_0 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] pool4_2 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] relu4_2 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] scale4_2 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] bn4_2 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] conv4_2 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] relu4_1 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] scale4_1 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] bn4_1 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] conv4_1 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] relu4 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] scale4 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] bn4 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] conv4 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] relu3_1 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] scale3_1 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] bn3_1 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] conv3_1 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] relu3 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] scale3 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] bn3 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] conv3 needs backward computation.
I1107 21:48:26.430626 18604 net.cpp:198] pool2_1 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] relu2_2 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] scale2_2 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] bn2_2 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] conv2_2 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] relu2_1 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] scale2_1 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] bn2_1 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] conv2_1 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] relu2 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] scale2 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] bn2 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] conv2 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] relu1_0 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] scale1_0 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] bn1_0 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] conv1_0 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] relu1 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] scale1 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] bn1 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:198] conv1 needs backward computation.
I1107 21:48:26.431627 18604 net.cpp:200] label_cifar_1_split does not need backward computation.
I1107 21:48:26.431627 18604 net.cpp:200] cifar does not need backward computation.
I1107 21:48:26.431627 18604 net.cpp:242] This network produces output accuracy_training
I1107 21:48:26.431627 18604 net.cpp:242] This network produces output loss
I1107 21:48:26.431627 18604 net.cpp:255] Network initialization done.
I1107 21:48:26.431627 18604 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1107 21:48:26.431627 18604 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1107 21:48:26.431627 18604 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1107 21:48:26.431627 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1107 21:48:26.431627 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1107 21:48:26.431627 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1107 21:48:26.431627 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1107 21:48:26.431627 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1107 21:48:26.431627 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1107 21:48:26.432626 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1107 21:48:26.432626 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1107 21:48:26.432626 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1107 21:48:26.432626 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1107 21:48:26.432626 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1107 21:48:26.432626 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1107 21:48:26.432626 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1107 21:48:26.432626 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1107 21:48:26.432626 18604 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1107 21:48:26.432626 18604 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV1_360k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "pool2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "pool4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1107 21:48:26.432626 18604 layer_factory.cpp:58] Creating layer cifar
I1107 21:48:26.437626 18604 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1107 21:48:26.437626 18604 net.cpp:84] Creating Layer cifar
I1107 21:48:26.438627 18604 net.cpp:380] cifar -> data
I1107 21:48:26.438627 18604 net.cpp:380] cifar -> label
I1107 21:48:26.438627 18604 data_layer.cpp:45] output data size: 100,3,32,32
I1107 21:48:26.445626 18604 net.cpp:122] Setting up cifar
I1107 21:48:26.445626 18604 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1107 21:48:26.445626 18604 net.cpp:129] Top shape: 100 (100)
I1107 21:48:26.445626 18604 net.cpp:137] Memory required for data: 1229200
I1107 21:48:26.445626 18604 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1107 21:48:26.445626 18604 net.cpp:84] Creating Layer label_cifar_1_split
I1107 21:48:26.445626 18604 net.cpp:406] label_cifar_1_split <- label
I1107 21:48:26.445626 18604 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1107 21:48:26.445626 18604 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1107 21:48:26.445626 18604 net.cpp:122] Setting up label_cifar_1_split
I1107 21:48:26.445626 18604 net.cpp:129] Top shape: 100 (100)
I1107 21:48:26.445626 18604 net.cpp:129] Top shape: 100 (100)
I1107 21:48:26.445626 18604 net.cpp:137] Memory required for data: 1230000
I1107 21:48:26.446626 18604 layer_factory.cpp:58] Creating layer conv1
I1107 21:48:26.446626 18604 net.cpp:84] Creating Layer conv1
I1107 21:48:26.446626 18604 net.cpp:406] conv1 <- data
I1107 21:48:26.446626 18604 net.cpp:380] conv1 -> conv1
I1107 21:48:26.448626 18016 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1107 21:48:26.448626 18604 net.cpp:122] Setting up conv1
I1107 21:48:26.448626 18604 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 21:48:26.448626 18604 net.cpp:137] Memory required for data: 13518000
I1107 21:48:26.448626 18604 layer_factory.cpp:58] Creating layer bn1
I1107 21:48:26.448626 18604 net.cpp:84] Creating Layer bn1
I1107 21:48:26.448626 18604 net.cpp:406] bn1 <- conv1
I1107 21:48:26.448626 18604 net.cpp:367] bn1 -> conv1 (in-place)
I1107 21:48:26.448626 18604 net.cpp:122] Setting up bn1
I1107 21:48:26.448626 18604 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 21:48:26.448626 18604 net.cpp:137] Memory required for data: 25806000
I1107 21:48:26.448626 18604 layer_factory.cpp:58] Creating layer scale1
I1107 21:48:26.448626 18604 net.cpp:84] Creating Layer scale1
I1107 21:48:26.448626 18604 net.cpp:406] scale1 <- conv1
I1107 21:48:26.448626 18604 net.cpp:367] scale1 -> conv1 (in-place)
I1107 21:48:26.448626 18604 layer_factory.cpp:58] Creating layer scale1
I1107 21:48:26.448626 18604 net.cpp:122] Setting up scale1
I1107 21:48:26.448626 18604 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 21:48:26.448626 18604 net.cpp:137] Memory required for data: 38094000
I1107 21:48:26.448626 18604 layer_factory.cpp:58] Creating layer relu1
I1107 21:48:26.448626 18604 net.cpp:84] Creating Layer relu1
I1107 21:48:26.448626 18604 net.cpp:406] relu1 <- conv1
I1107 21:48:26.448626 18604 net.cpp:367] relu1 -> conv1 (in-place)
I1107 21:48:26.449628 18604 net.cpp:122] Setting up relu1
I1107 21:48:26.449628 18604 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1107 21:48:26.449628 18604 net.cpp:137] Memory required for data: 50382000
I1107 21:48:26.449628 18604 layer_factory.cpp:58] Creating layer conv1_0
I1107 21:48:26.449628 18604 net.cpp:84] Creating Layer conv1_0
I1107 21:48:26.449628 18604 net.cpp:406] conv1_0 <- conv1
I1107 21:48:26.449628 18604 net.cpp:380] conv1_0 -> conv1_0
I1107 21:48:26.450626 18604 net.cpp:122] Setting up conv1_0
I1107 21:48:26.450626 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.450626 18604 net.cpp:137] Memory required for data: 66766000
I1107 21:48:26.450626 18604 layer_factory.cpp:58] Creating layer bn1_0
I1107 21:48:26.450626 18604 net.cpp:84] Creating Layer bn1_0
I1107 21:48:26.450626 18604 net.cpp:406] bn1_0 <- conv1_0
I1107 21:48:26.450626 18604 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1107 21:48:26.450626 18604 net.cpp:122] Setting up bn1_0
I1107 21:48:26.450626 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.450626 18604 net.cpp:137] Memory required for data: 83150000
I1107 21:48:26.450626 18604 layer_factory.cpp:58] Creating layer scale1_0
I1107 21:48:26.450626 18604 net.cpp:84] Creating Layer scale1_0
I1107 21:48:26.450626 18604 net.cpp:406] scale1_0 <- conv1_0
I1107 21:48:26.450626 18604 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1107 21:48:26.450626 18604 layer_factory.cpp:58] Creating layer scale1_0
I1107 21:48:26.451627 18604 net.cpp:122] Setting up scale1_0
I1107 21:48:26.451627 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.451627 18604 net.cpp:137] Memory required for data: 99534000
I1107 21:48:26.451627 18604 layer_factory.cpp:58] Creating layer relu1_0
I1107 21:48:26.451627 18604 net.cpp:84] Creating Layer relu1_0
I1107 21:48:26.451627 18604 net.cpp:406] relu1_0 <- conv1_0
I1107 21:48:26.451627 18604 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1107 21:48:26.451627 18604 net.cpp:122] Setting up relu1_0
I1107 21:48:26.451627 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.451627 18604 net.cpp:137] Memory required for data: 115918000
I1107 21:48:26.451627 18604 layer_factory.cpp:58] Creating layer conv2
I1107 21:48:26.451627 18604 net.cpp:84] Creating Layer conv2
I1107 21:48:26.451627 18604 net.cpp:406] conv2 <- conv1_0
I1107 21:48:26.451627 18604 net.cpp:380] conv2 -> conv2
I1107 21:48:26.452626 18604 net.cpp:122] Setting up conv2
I1107 21:48:26.452626 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.452626 18604 net.cpp:137] Memory required for data: 132302000
I1107 21:48:26.452626 18604 layer_factory.cpp:58] Creating layer bn2
I1107 21:48:26.452626 18604 net.cpp:84] Creating Layer bn2
I1107 21:48:26.452626 18604 net.cpp:406] bn2 <- conv2
I1107 21:48:26.452626 18604 net.cpp:367] bn2 -> conv2 (in-place)
I1107 21:48:26.452626 18604 net.cpp:122] Setting up bn2
I1107 21:48:26.452626 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.452626 18604 net.cpp:137] Memory required for data: 148686000
I1107 21:48:26.452626 18604 layer_factory.cpp:58] Creating layer scale2
I1107 21:48:26.452626 18604 net.cpp:84] Creating Layer scale2
I1107 21:48:26.452626 18604 net.cpp:406] scale2 <- conv2
I1107 21:48:26.452626 18604 net.cpp:367] scale2 -> conv2 (in-place)
I1107 21:48:26.453626 18604 layer_factory.cpp:58] Creating layer scale2
I1107 21:48:26.453626 18604 net.cpp:122] Setting up scale2
I1107 21:48:26.453626 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.453626 18604 net.cpp:137] Memory required for data: 165070000
I1107 21:48:26.453626 18604 layer_factory.cpp:58] Creating layer relu2
I1107 21:48:26.453626 18604 net.cpp:84] Creating Layer relu2
I1107 21:48:26.453626 18604 net.cpp:406] relu2 <- conv2
I1107 21:48:26.453626 18604 net.cpp:367] relu2 -> conv2 (in-place)
I1107 21:48:26.453626 18604 net.cpp:122] Setting up relu2
I1107 21:48:26.453626 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.453626 18604 net.cpp:137] Memory required for data: 181454000
I1107 21:48:26.453626 18604 layer_factory.cpp:58] Creating layer conv2_1
I1107 21:48:26.453626 18604 net.cpp:84] Creating Layer conv2_1
I1107 21:48:26.453626 18604 net.cpp:406] conv2_1 <- conv2
I1107 21:48:26.453626 18604 net.cpp:380] conv2_1 -> conv2_1
I1107 21:48:26.454635 18604 net.cpp:122] Setting up conv2_1
I1107 21:48:26.454635 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.454635 18604 net.cpp:137] Memory required for data: 197838000
I1107 21:48:26.454635 18604 layer_factory.cpp:58] Creating layer bn2_1
I1107 21:48:26.454635 18604 net.cpp:84] Creating Layer bn2_1
I1107 21:48:26.454635 18604 net.cpp:406] bn2_1 <- conv2_1
I1107 21:48:26.454635 18604 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1107 21:48:26.454635 18604 net.cpp:122] Setting up bn2_1
I1107 21:48:26.454635 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.454635 18604 net.cpp:137] Memory required for data: 214222000
I1107 21:48:26.454635 18604 layer_factory.cpp:58] Creating layer scale2_1
I1107 21:48:26.455626 18604 net.cpp:84] Creating Layer scale2_1
I1107 21:48:26.455626 18604 net.cpp:406] scale2_1 <- conv2_1
I1107 21:48:26.455626 18604 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1107 21:48:26.455626 18604 layer_factory.cpp:58] Creating layer scale2_1
I1107 21:48:26.455626 18604 net.cpp:122] Setting up scale2_1
I1107 21:48:26.455626 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.455626 18604 net.cpp:137] Memory required for data: 230606000
I1107 21:48:26.455626 18604 layer_factory.cpp:58] Creating layer relu2_1
I1107 21:48:26.455626 18604 net.cpp:84] Creating Layer relu2_1
I1107 21:48:26.455626 18604 net.cpp:406] relu2_1 <- conv2_1
I1107 21:48:26.455626 18604 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1107 21:48:26.455626 18604 net.cpp:122] Setting up relu2_1
I1107 21:48:26.455626 18604 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1107 21:48:26.455626 18604 net.cpp:137] Memory required for data: 246990000
I1107 21:48:26.455626 18604 layer_factory.cpp:58] Creating layer conv2_2
I1107 21:48:26.455626 18604 net.cpp:84] Creating Layer conv2_2
I1107 21:48:26.455626 18604 net.cpp:406] conv2_2 <- conv2_1
I1107 21:48:26.455626 18604 net.cpp:380] conv2_2 -> conv2_2
I1107 21:48:26.457626 18604 net.cpp:122] Setting up conv2_2
I1107 21:48:26.457626 18604 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 21:48:26.457626 18604 net.cpp:137] Memory required for data: 267470000
I1107 21:48:26.457626 18604 layer_factory.cpp:58] Creating layer bn2_2
I1107 21:48:26.457626 18604 net.cpp:84] Creating Layer bn2_2
I1107 21:48:26.457626 18604 net.cpp:406] bn2_2 <- conv2_2
I1107 21:48:26.457626 18604 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1107 21:48:26.457626 18604 net.cpp:122] Setting up bn2_2
I1107 21:48:26.457626 18604 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 21:48:26.457626 18604 net.cpp:137] Memory required for data: 287950000
I1107 21:48:26.457626 18604 layer_factory.cpp:58] Creating layer scale2_2
I1107 21:48:26.457626 18604 net.cpp:84] Creating Layer scale2_2
I1107 21:48:26.457626 18604 net.cpp:406] scale2_2 <- conv2_2
I1107 21:48:26.457626 18604 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1107 21:48:26.457626 18604 layer_factory.cpp:58] Creating layer scale2_2
I1107 21:48:26.457626 18604 net.cpp:122] Setting up scale2_2
I1107 21:48:26.457626 18604 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 21:48:26.457626 18604 net.cpp:137] Memory required for data: 308430000
I1107 21:48:26.457626 18604 layer_factory.cpp:58] Creating layer relu2_2
I1107 21:48:26.457626 18604 net.cpp:84] Creating Layer relu2_2
I1107 21:48:26.457626 18604 net.cpp:406] relu2_2 <- conv2_2
I1107 21:48:26.457626 18604 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1107 21:48:26.457626 18604 net.cpp:122] Setting up relu2_2
I1107 21:48:26.457626 18604 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1107 21:48:26.457626 18604 net.cpp:137] Memory required for data: 328910000
I1107 21:48:26.457626 18604 layer_factory.cpp:58] Creating layer pool2_1
I1107 21:48:26.457626 18604 net.cpp:84] Creating Layer pool2_1
I1107 21:48:26.457626 18604 net.cpp:406] pool2_1 <- conv2_2
I1107 21:48:26.457626 18604 net.cpp:380] pool2_1 -> pool2_1
I1107 21:48:26.459626 18604 net.cpp:122] Setting up pool2_1
I1107 21:48:26.459626 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.459626 18604 net.cpp:137] Memory required for data: 334030000
I1107 21:48:26.459626 18604 layer_factory.cpp:58] Creating layer conv3
I1107 21:48:26.459626 18604 net.cpp:84] Creating Layer conv3
I1107 21:48:26.459626 18604 net.cpp:406] conv3 <- pool2_1
I1107 21:48:26.459626 18604 net.cpp:380] conv3 -> conv3
I1107 21:48:26.460626 18604 net.cpp:122] Setting up conv3
I1107 21:48:26.460626 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.460626 18604 net.cpp:137] Memory required for data: 339150000
I1107 21:48:26.460626 18604 layer_factory.cpp:58] Creating layer bn3
I1107 21:48:26.460626 18604 net.cpp:84] Creating Layer bn3
I1107 21:48:26.460626 18604 net.cpp:406] bn3 <- conv3
I1107 21:48:26.460626 18604 net.cpp:367] bn3 -> conv3 (in-place)
I1107 21:48:26.460626 18604 net.cpp:122] Setting up bn3
I1107 21:48:26.460626 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.461627 18604 net.cpp:137] Memory required for data: 344270000
I1107 21:48:26.461627 18604 layer_factory.cpp:58] Creating layer scale3
I1107 21:48:26.461627 18604 net.cpp:84] Creating Layer scale3
I1107 21:48:26.461627 18604 net.cpp:406] scale3 <- conv3
I1107 21:48:26.461627 18604 net.cpp:367] scale3 -> conv3 (in-place)
I1107 21:48:26.461627 18604 layer_factory.cpp:58] Creating layer scale3
I1107 21:48:26.461627 18604 net.cpp:122] Setting up scale3
I1107 21:48:26.461627 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.461627 18604 net.cpp:137] Memory required for data: 349390000
I1107 21:48:26.461627 18604 layer_factory.cpp:58] Creating layer relu3
I1107 21:48:26.461627 18604 net.cpp:84] Creating Layer relu3
I1107 21:48:26.461627 18604 net.cpp:406] relu3 <- conv3
I1107 21:48:26.461627 18604 net.cpp:367] relu3 -> conv3 (in-place)
I1107 21:48:26.461627 18604 net.cpp:122] Setting up relu3
I1107 21:48:26.461627 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.461627 18604 net.cpp:137] Memory required for data: 354510000
I1107 21:48:26.461627 18604 layer_factory.cpp:58] Creating layer conv3_1
I1107 21:48:26.461627 18604 net.cpp:84] Creating Layer conv3_1
I1107 21:48:26.461627 18604 net.cpp:406] conv3_1 <- conv3
I1107 21:48:26.461627 18604 net.cpp:380] conv3_1 -> conv3_1
I1107 21:48:26.462626 18604 net.cpp:122] Setting up conv3_1
I1107 21:48:26.462626 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.462626 18604 net.cpp:137] Memory required for data: 359630000
I1107 21:48:26.462626 18604 layer_factory.cpp:58] Creating layer bn3_1
I1107 21:48:26.462626 18604 net.cpp:84] Creating Layer bn3_1
I1107 21:48:26.462626 18604 net.cpp:406] bn3_1 <- conv3_1
I1107 21:48:26.462626 18604 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1107 21:48:26.462626 18604 net.cpp:122] Setting up bn3_1
I1107 21:48:26.462626 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.462626 18604 net.cpp:137] Memory required for data: 364750000
I1107 21:48:26.462626 18604 layer_factory.cpp:58] Creating layer scale3_1
I1107 21:48:26.462626 18604 net.cpp:84] Creating Layer scale3_1
I1107 21:48:26.462626 18604 net.cpp:406] scale3_1 <- conv3_1
I1107 21:48:26.462626 18604 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1107 21:48:26.462626 18604 layer_factory.cpp:58] Creating layer scale3_1
I1107 21:48:26.463626 18604 net.cpp:122] Setting up scale3_1
I1107 21:48:26.463626 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.463626 18604 net.cpp:137] Memory required for data: 369870000
I1107 21:48:26.463626 18604 layer_factory.cpp:58] Creating layer relu3_1
I1107 21:48:26.463626 18604 net.cpp:84] Creating Layer relu3_1
I1107 21:48:26.463626 18604 net.cpp:406] relu3_1 <- conv3_1
I1107 21:48:26.463626 18604 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1107 21:48:26.463626 18604 net.cpp:122] Setting up relu3_1
I1107 21:48:26.463626 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.463626 18604 net.cpp:137] Memory required for data: 374990000
I1107 21:48:26.463626 18604 layer_factory.cpp:58] Creating layer conv4
I1107 21:48:26.463626 18604 net.cpp:84] Creating Layer conv4
I1107 21:48:26.463626 18604 net.cpp:406] conv4 <- conv3_1
I1107 21:48:26.463626 18604 net.cpp:380] conv4 -> conv4
I1107 21:48:26.464627 18604 net.cpp:122] Setting up conv4
I1107 21:48:26.464627 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.464627 18604 net.cpp:137] Memory required for data: 380110000
I1107 21:48:26.464627 18604 layer_factory.cpp:58] Creating layer bn4
I1107 21:48:26.464627 18604 net.cpp:84] Creating Layer bn4
I1107 21:48:26.464627 18604 net.cpp:406] bn4 <- conv4
I1107 21:48:26.464627 18604 net.cpp:367] bn4 -> conv4 (in-place)
I1107 21:48:26.465626 18604 net.cpp:122] Setting up bn4
I1107 21:48:26.465626 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.465626 18604 net.cpp:137] Memory required for data: 385230000
I1107 21:48:26.465626 18604 layer_factory.cpp:58] Creating layer scale4
I1107 21:48:26.465626 18604 net.cpp:84] Creating Layer scale4
I1107 21:48:26.465626 18604 net.cpp:406] scale4 <- conv4
I1107 21:48:26.465626 18604 net.cpp:367] scale4 -> conv4 (in-place)
I1107 21:48:26.465626 18604 layer_factory.cpp:58] Creating layer scale4
I1107 21:48:26.465626 18604 net.cpp:122] Setting up scale4
I1107 21:48:26.465626 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.465626 18604 net.cpp:137] Memory required for data: 390350000
I1107 21:48:26.465626 18604 layer_factory.cpp:58] Creating layer relu4
I1107 21:48:26.465626 18604 net.cpp:84] Creating Layer relu4
I1107 21:48:26.465626 18604 net.cpp:406] relu4 <- conv4
I1107 21:48:26.465626 18604 net.cpp:367] relu4 -> conv4 (in-place)
I1107 21:48:26.465626 18604 net.cpp:122] Setting up relu4
I1107 21:48:26.465626 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.465626 18604 net.cpp:137] Memory required for data: 395470000
I1107 21:48:26.465626 18604 layer_factory.cpp:58] Creating layer conv4_1
I1107 21:48:26.465626 18604 net.cpp:84] Creating Layer conv4_1
I1107 21:48:26.465626 18604 net.cpp:406] conv4_1 <- conv4
I1107 21:48:26.465626 18604 net.cpp:380] conv4_1 -> conv4_1
I1107 21:48:26.466627 18604 net.cpp:122] Setting up conv4_1
I1107 21:48:26.466627 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.466627 18604 net.cpp:137] Memory required for data: 400590000
I1107 21:48:26.466627 18604 layer_factory.cpp:58] Creating layer bn4_1
I1107 21:48:26.466627 18604 net.cpp:84] Creating Layer bn4_1
I1107 21:48:26.466627 18604 net.cpp:406] bn4_1 <- conv4_1
I1107 21:48:26.466627 18604 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1107 21:48:26.467627 18604 net.cpp:122] Setting up bn4_1
I1107 21:48:26.467627 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.467627 18604 net.cpp:137] Memory required for data: 405710000
I1107 21:48:26.467627 18604 layer_factory.cpp:58] Creating layer scale4_1
I1107 21:48:26.467627 18604 net.cpp:84] Creating Layer scale4_1
I1107 21:48:26.467627 18604 net.cpp:406] scale4_1 <- conv4_1
I1107 21:48:26.467627 18604 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1107 21:48:26.467627 18604 layer_factory.cpp:58] Creating layer scale4_1
I1107 21:48:26.467627 18604 net.cpp:122] Setting up scale4_1
I1107 21:48:26.467627 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.467627 18604 net.cpp:137] Memory required for data: 410830000
I1107 21:48:26.467627 18604 layer_factory.cpp:58] Creating layer relu4_1
I1107 21:48:26.467627 18604 net.cpp:84] Creating Layer relu4_1
I1107 21:48:26.467627 18604 net.cpp:406] relu4_1 <- conv4_1
I1107 21:48:26.467627 18604 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1107 21:48:26.467627 18604 net.cpp:122] Setting up relu4_1
I1107 21:48:26.467627 18604 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1107 21:48:26.467627 18604 net.cpp:137] Memory required for data: 415950000
I1107 21:48:26.467627 18604 layer_factory.cpp:58] Creating layer conv4_2
I1107 21:48:26.467627 18604 net.cpp:84] Creating Layer conv4_2
I1107 21:48:26.467627 18604 net.cpp:406] conv4_2 <- conv4_1
I1107 21:48:26.467627 18604 net.cpp:380] conv4_2 -> conv4_2
I1107 21:48:26.468626 18604 net.cpp:122] Setting up conv4_2
I1107 21:48:26.468626 18604 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 21:48:26.468626 18604 net.cpp:137] Memory required for data: 421889200
I1107 21:48:26.468626 18604 layer_factory.cpp:58] Creating layer bn4_2
I1107 21:48:26.469626 18604 net.cpp:84] Creating Layer bn4_2
I1107 21:48:26.469626 18604 net.cpp:406] bn4_2 <- conv4_2
I1107 21:48:26.469626 18604 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1107 21:48:26.469626 18604 net.cpp:122] Setting up bn4_2
I1107 21:48:26.469626 18604 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 21:48:26.469626 18604 net.cpp:137] Memory required for data: 427828400
I1107 21:48:26.469626 18604 layer_factory.cpp:58] Creating layer scale4_2
I1107 21:48:26.469626 18604 net.cpp:84] Creating Layer scale4_2
I1107 21:48:26.469626 18604 net.cpp:406] scale4_2 <- conv4_2
I1107 21:48:26.469626 18604 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1107 21:48:26.469626 18604 layer_factory.cpp:58] Creating layer scale4_2
I1107 21:48:26.469626 18604 net.cpp:122] Setting up scale4_2
I1107 21:48:26.469626 18604 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 21:48:26.469626 18604 net.cpp:137] Memory required for data: 433767600
I1107 21:48:26.469626 18604 layer_factory.cpp:58] Creating layer relu4_2
I1107 21:48:26.469626 18604 net.cpp:84] Creating Layer relu4_2
I1107 21:48:26.469626 18604 net.cpp:406] relu4_2 <- conv4_2
I1107 21:48:26.469626 18604 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1107 21:48:26.469626 18604 net.cpp:122] Setting up relu4_2
I1107 21:48:26.469626 18604 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1107 21:48:26.469626 18604 net.cpp:137] Memory required for data: 439706800
I1107 21:48:26.469626 18604 layer_factory.cpp:58] Creating layer pool4_2
I1107 21:48:26.469626 18604 net.cpp:84] Creating Layer pool4_2
I1107 21:48:26.469626 18604 net.cpp:406] pool4_2 <- conv4_2
I1107 21:48:26.469626 18604 net.cpp:380] pool4_2 -> pool4_2
I1107 21:48:26.470626 18604 net.cpp:122] Setting up pool4_2
I1107 21:48:26.470626 18604 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 21:48:26.470626 18604 net.cpp:137] Memory required for data: 441191600
I1107 21:48:26.471626 18604 layer_factory.cpp:58] Creating layer conv4_0
I1107 21:48:26.471626 18604 net.cpp:84] Creating Layer conv4_0
I1107 21:48:26.471626 18604 net.cpp:406] conv4_0 <- pool4_2
I1107 21:48:26.471626 18604 net.cpp:380] conv4_0 -> conv4_0
I1107 21:48:26.472626 18604 net.cpp:122] Setting up conv4_0
I1107 21:48:26.472626 18604 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 21:48:26.472626 18604 net.cpp:137] Memory required for data: 442676400
I1107 21:48:26.472626 18604 layer_factory.cpp:58] Creating layer bn4_0
I1107 21:48:26.472626 18604 net.cpp:84] Creating Layer bn4_0
I1107 21:48:26.472626 18604 net.cpp:406] bn4_0 <- conv4_0
I1107 21:48:26.472626 18604 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1107 21:48:26.473626 18604 net.cpp:122] Setting up bn4_0
I1107 21:48:26.473626 18604 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 21:48:26.473626 18604 net.cpp:137] Memory required for data: 444161200
I1107 21:48:26.473626 18604 layer_factory.cpp:58] Creating layer scale4_0
I1107 21:48:26.473626 18604 net.cpp:84] Creating Layer scale4_0
I1107 21:48:26.473626 18604 net.cpp:406] scale4_0 <- conv4_0
I1107 21:48:26.473626 18604 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1107 21:48:26.473626 18604 layer_factory.cpp:58] Creating layer scale4_0
I1107 21:48:26.473626 18604 net.cpp:122] Setting up scale4_0
I1107 21:48:26.473626 18604 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 21:48:26.473626 18604 net.cpp:137] Memory required for data: 445646000
I1107 21:48:26.473626 18604 layer_factory.cpp:58] Creating layer relu4_0
I1107 21:48:26.473626 18604 net.cpp:84] Creating Layer relu4_0
I1107 21:48:26.473626 18604 net.cpp:406] relu4_0 <- conv4_0
I1107 21:48:26.473626 18604 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1107 21:48:26.473626 18604 net.cpp:122] Setting up relu4_0
I1107 21:48:26.473626 18604 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1107 21:48:26.473626 18604 net.cpp:137] Memory required for data: 447130800
I1107 21:48:26.473626 18604 layer_factory.cpp:58] Creating layer conv11
I1107 21:48:26.473626 18604 net.cpp:84] Creating Layer conv11
I1107 21:48:26.473626 18604 net.cpp:406] conv11 <- conv4_0
I1107 21:48:26.473626 18604 net.cpp:380] conv11 -> conv11
I1107 21:48:26.475626 18604 net.cpp:122] Setting up conv11
I1107 21:48:26.475626 18604 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 21:48:26.475626 18604 net.cpp:137] Memory required for data: 448922800
I1107 21:48:26.475626 18604 layer_factory.cpp:58] Creating layer bn_conv11
I1107 21:48:26.475626 18604 net.cpp:84] Creating Layer bn_conv11
I1107 21:48:26.475626 18604 net.cpp:406] bn_conv11 <- conv11
I1107 21:48:26.475626 18604 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1107 21:48:26.475626 18604 net.cpp:122] Setting up bn_conv11
I1107 21:48:26.475626 18604 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 21:48:26.475626 18604 net.cpp:137] Memory required for data: 450714800
I1107 21:48:26.475626 18604 layer_factory.cpp:58] Creating layer scale_conv11
I1107 21:48:26.475626 18604 net.cpp:84] Creating Layer scale_conv11
I1107 21:48:26.475626 18604 net.cpp:406] scale_conv11 <- conv11
I1107 21:48:26.475626 18604 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1107 21:48:26.475626 18604 layer_factory.cpp:58] Creating layer scale_conv11
I1107 21:48:26.475626 18604 net.cpp:122] Setting up scale_conv11
I1107 21:48:26.475626 18604 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 21:48:26.475626 18604 net.cpp:137] Memory required for data: 452506800
I1107 21:48:26.475626 18604 layer_factory.cpp:58] Creating layer relu_conv11
I1107 21:48:26.475626 18604 net.cpp:84] Creating Layer relu_conv11
I1107 21:48:26.475626 18604 net.cpp:406] relu_conv11 <- conv11
I1107 21:48:26.475626 18604 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1107 21:48:26.475626 18604 net.cpp:122] Setting up relu_conv11
I1107 21:48:26.475626 18604 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1107 21:48:26.475626 18604 net.cpp:137] Memory required for data: 454298800
I1107 21:48:26.475626 18604 layer_factory.cpp:58] Creating layer conv12
I1107 21:48:26.475626 18604 net.cpp:84] Creating Layer conv12
I1107 21:48:26.475626 18604 net.cpp:406] conv12 <- conv11
I1107 21:48:26.475626 18604 net.cpp:380] conv12 -> conv12
I1107 21:48:26.478628 18604 net.cpp:122] Setting up conv12
I1107 21:48:26.478628 18604 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 21:48:26.478628 18604 net.cpp:137] Memory required for data: 456602800
I1107 21:48:26.478628 18604 layer_factory.cpp:58] Creating layer bn_conv12
I1107 21:48:26.478628 18604 net.cpp:84] Creating Layer bn_conv12
I1107 21:48:26.478628 18604 net.cpp:406] bn_conv12 <- conv12
I1107 21:48:26.478628 18604 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1107 21:48:26.478628 18604 net.cpp:122] Setting up bn_conv12
I1107 21:48:26.478628 18604 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 21:48:26.478628 18604 net.cpp:137] Memory required for data: 458906800
I1107 21:48:26.478628 18604 layer_factory.cpp:58] Creating layer scale_conv12
I1107 21:48:26.478628 18604 net.cpp:84] Creating Layer scale_conv12
I1107 21:48:26.478628 18604 net.cpp:406] scale_conv12 <- conv12
I1107 21:48:26.478628 18604 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1107 21:48:26.478628 18604 layer_factory.cpp:58] Creating layer scale_conv12
I1107 21:48:26.478628 18604 net.cpp:122] Setting up scale_conv12
I1107 21:48:26.478628 18604 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 21:48:26.478628 18604 net.cpp:137] Memory required for data: 461210800
I1107 21:48:26.478628 18604 layer_factory.cpp:58] Creating layer relu_conv12
I1107 21:48:26.479626 18604 net.cpp:84] Creating Layer relu_conv12
I1107 21:48:26.479626 18604 net.cpp:406] relu_conv12 <- conv12
I1107 21:48:26.479626 18604 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1107 21:48:26.479626 18604 net.cpp:122] Setting up relu_conv12
I1107 21:48:26.479626 18604 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1107 21:48:26.479626 18604 net.cpp:137] Memory required for data: 463514800
I1107 21:48:26.479626 18604 layer_factory.cpp:58] Creating layer poolcp6
I1107 21:48:26.479626 18604 net.cpp:84] Creating Layer poolcp6
I1107 21:48:26.479626 18604 net.cpp:406] poolcp6 <- conv12
I1107 21:48:26.479626 18604 net.cpp:380] poolcp6 -> poolcp6
I1107 21:48:26.479626 18604 net.cpp:122] Setting up poolcp6
I1107 21:48:26.479626 18604 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1107 21:48:26.479626 18604 net.cpp:137] Memory required for data: 463550800
I1107 21:48:26.479626 18604 layer_factory.cpp:58] Creating layer ip1
I1107 21:48:26.479626 18604 net.cpp:84] Creating Layer ip1
I1107 21:48:26.479626 18604 net.cpp:406] ip1 <- poolcp6
I1107 21:48:26.479626 18604 net.cpp:380] ip1 -> ip1
I1107 21:48:26.479626 18604 net.cpp:122] Setting up ip1
I1107 21:48:26.479626 18604 net.cpp:129] Top shape: 100 100 (10000)
I1107 21:48:26.479626 18604 net.cpp:137] Memory required for data: 463590800
I1107 21:48:26.479626 18604 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1107 21:48:26.479626 18604 net.cpp:84] Creating Layer ip1_ip1_0_split
I1107 21:48:26.479626 18604 net.cpp:406] ip1_ip1_0_split <- ip1
I1107 21:48:26.479626 18604 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1107 21:48:26.479626 18604 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1107 21:48:26.479626 18604 net.cpp:122] Setting up ip1_ip1_0_split
I1107 21:48:26.479626 18604 net.cpp:129] Top shape: 100 100 (10000)
I1107 21:48:26.479626 18604 net.cpp:129] Top shape: 100 100 (10000)
I1107 21:48:26.479626 18604 net.cpp:137] Memory required for data: 463670800
I1107 21:48:26.479626 18604 layer_factory.cpp:58] Creating layer accuracy
I1107 21:48:26.479626 18604 net.cpp:84] Creating Layer accuracy
I1107 21:48:26.479626 18604 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1107 21:48:26.479626 18604 net.cpp:406] accuracy <- label_cifar_1_split_0
I1107 21:48:26.479626 18604 net.cpp:380] accuracy -> accuracy
I1107 21:48:26.479626 18604 net.cpp:122] Setting up accuracy
I1107 21:48:26.479626 18604 net.cpp:129] Top shape: (1)
I1107 21:48:26.479626 18604 net.cpp:137] Memory required for data: 463670804
I1107 21:48:26.479626 18604 layer_factory.cpp:58] Creating layer loss
I1107 21:48:26.479626 18604 net.cpp:84] Creating Layer loss
I1107 21:48:26.479626 18604 net.cpp:406] loss <- ip1_ip1_0_split_1
I1107 21:48:26.479626 18604 net.cpp:406] loss <- label_cifar_1_split_1
I1107 21:48:26.479626 18604 net.cpp:380] loss -> loss
I1107 21:48:26.479626 18604 layer_factory.cpp:58] Creating layer loss
I1107 21:48:26.480635 18604 net.cpp:122] Setting up loss
I1107 21:48:26.480635 18604 net.cpp:129] Top shape: (1)
I1107 21:48:26.480635 18604 net.cpp:132]     with loss weight 1
I1107 21:48:26.480635 18604 net.cpp:137] Memory required for data: 463670808
I1107 21:48:26.480635 18604 net.cpp:198] loss needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:200] accuracy does not need backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] ip1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] poolcp6 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu_conv12 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale_conv12 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn_conv12 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv12 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu_conv11 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale_conv11 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn_conv11 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv11 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu4_0 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale4_0 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn4_0 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv4_0 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] pool4_2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu4_2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale4_2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn4_2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv4_2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu4_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale4_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn4_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv4_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu4 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale4 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn4 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv4 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu3_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale3_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn3_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv3_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu3 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale3 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn3 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv3 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] pool2_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu2_2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale2_2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn2_2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv2_2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu2_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale2_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn2_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv2_1 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv2 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu1_0 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] scale1_0 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] bn1_0 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] conv1_0 needs backward computation.
I1107 21:48:26.480635 18604 net.cpp:198] relu1 needs backward computation.
I1107 21:48:26.481626 18604 net.cpp:198] scale1 needs backward computation.
I1107 21:48:26.481626 18604 net.cpp:198] bn1 needs backward computation.
I1107 21:48:26.481626 18604 net.cpp:198] conv1 needs backward computation.
I1107 21:48:26.481626 18604 net.cpp:200] label_cifar_1_split does not need backward computation.
I1107 21:48:26.481626 18604 net.cpp:200] cifar does not need backward computation.
I1107 21:48:26.481626 18604 net.cpp:242] This network produces output accuracy
I1107 21:48:26.481626 18604 net.cpp:242] This network produces output loss
I1107 21:48:26.481626 18604 net.cpp:255] Network initialization done.
I1107 21:48:26.481626 18604 solver.cpp:56] Solver scaffolding done.
I1107 21:48:26.485627 18604 caffe.cpp:243] Resuming from examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_90000.solverstate
I1107 21:48:26.489629 18604 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_90000.caffemodel
I1107 21:48:26.489629 18604 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1107 21:48:26.489629 18604 sgd_solver.cpp:318] SGDSolver: restoring history
I1107 21:48:26.493626 18604 caffe.cpp:249] Starting Optimization
I1107 21:48:26.493626 18604 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV1_360k
I1107 21:48:26.493626 18604 solver.cpp:273] Learning Rate Policy: multistep
I1107 21:48:26.496628 18604 solver.cpp:330] Iteration 90000, Testing net (#0)
I1107 21:48:26.498627 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:48:27.842748 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:48:27.893749 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5752
I1107 21:48:27.893749 18604 solver.cpp:397]     Test net output #1: loss = 1.61927 (* 1 = 1.61927 loss)
I1107 21:48:27.994770 18604 solver.cpp:218] Iteration 90000 (60019.9 iter/s, 1.4995s/100 iters), loss = 0.64054
I1107 21:48:27.994770 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:48:27.994770 18604 solver.cpp:237]     Train net output #1: loss = 0.64054 (* 1 = 0.64054 loss)
I1107 21:48:27.994770 18604 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1107 21:48:33.839187 18604 solver.cpp:218] Iteration 90100 (17.1108 iter/s, 5.84428s/100 iters), loss = 0.816855
I1107 21:48:33.839187 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1107 21:48:33.839187 18604 solver.cpp:237]     Train net output #1: loss = 0.816855 (* 1 = 0.816855 loss)
I1107 21:48:33.839187 18604 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1107 21:48:39.672565 18604 solver.cpp:218] Iteration 90200 (17.1425 iter/s, 5.83344s/100 iters), loss = 0.617609
I1107 21:48:39.672565 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 21:48:39.672565 18604 solver.cpp:237]     Train net output #1: loss = 0.617609 (* 1 = 0.617609 loss)
I1107 21:48:39.672565 18604 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1107 21:48:45.510044 18604 solver.cpp:218] Iteration 90300 (17.1331 iter/s, 5.83665s/100 iters), loss = 0.898022
I1107 21:48:45.510044 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1107 21:48:45.510044 18604 solver.cpp:237]     Train net output #1: loss = 0.898022 (* 1 = 0.898022 loss)
I1107 21:48:45.510044 18604 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1107 21:48:51.366479 18604 solver.cpp:218] Iteration 90400 (17.0755 iter/s, 5.85635s/100 iters), loss = 1.05209
I1107 21:48:51.366479 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1107 21:48:51.366479 18604 solver.cpp:237]     Train net output #1: loss = 1.05209 (* 1 = 1.05209 loss)
I1107 21:48:51.366479 18604 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1107 21:48:56.938932  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:48:57.169945 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_90500.caffemodel
I1107 21:48:57.185946 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_90500.solverstate
I1107 21:48:57.190946 18604 solver.cpp:330] Iteration 90500, Testing net (#0)
I1107 21:48:57.190946 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:48:58.480046 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:48:58.530550 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5672
I1107 21:48:58.530550 18604 solver.cpp:397]     Test net output #1: loss = 1.67912 (* 1 = 1.67912 loss)
I1107 21:48:58.586053 18604 solver.cpp:218] Iteration 90500 (13.8522 iter/s, 7.21908s/100 iters), loss = 0.686357
I1107 21:48:58.586053 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1107 21:48:58.586053 18604 solver.cpp:237]     Train net output #1: loss = 0.686357 (* 1 = 0.686357 loss)
I1107 21:48:58.586053 18604 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1107 21:49:04.430949 18604 solver.cpp:218] Iteration 90600 (17.1112 iter/s, 5.84411s/100 iters), loss = 0.640416
I1107 21:49:04.430949 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 21:49:04.430949 18604 solver.cpp:237]     Train net output #1: loss = 0.640416 (* 1 = 0.640416 loss)
I1107 21:49:04.430949 18604 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1107 21:49:10.281888 18604 solver.cpp:218] Iteration 90700 (17.0927 iter/s, 5.85044s/100 iters), loss = 0.672101
I1107 21:49:10.281888 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1107 21:49:10.281888 18604 solver.cpp:237]     Train net output #1: loss = 0.672101 (* 1 = 0.672101 loss)
I1107 21:49:10.281888 18604 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1107 21:49:16.128818 18604 solver.cpp:218] Iteration 90800 (17.1034 iter/s, 5.84678s/100 iters), loss = 0.908448
I1107 21:49:16.128818 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1107 21:49:16.128818 18604 solver.cpp:237]     Train net output #1: loss = 0.908448 (* 1 = 0.908448 loss)
I1107 21:49:16.128818 18604 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1107 21:49:21.982625 18604 solver.cpp:218] Iteration 90900 (17.0838 iter/s, 5.8535s/100 iters), loss = 0.913268
I1107 21:49:21.982625 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1107 21:49:21.982625 18604 solver.cpp:237]     Train net output #1: loss = 0.913268 (* 1 = 0.913268 loss)
I1107 21:49:21.982625 18604 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1107 21:49:27.553026  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:49:27.784036 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_91000.caffemodel
I1107 21:49:27.800036 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_91000.solverstate
I1107 21:49:27.805037 18604 solver.cpp:330] Iteration 91000, Testing net (#0)
I1107 21:49:27.805037 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:49:29.094122 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:49:29.145133 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5871
I1107 21:49:29.145133 18604 solver.cpp:397]     Test net output #1: loss = 1.57485 (* 1 = 1.57485 loss)
I1107 21:49:29.201133 18604 solver.cpp:218] Iteration 91000 (13.854 iter/s, 7.21811s/100 iters), loss = 0.695992
I1107 21:49:29.201133 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:49:29.201133 18604 solver.cpp:237]     Train net output #1: loss = 0.695992 (* 1 = 0.695992 loss)
I1107 21:49:29.201133 18604 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1107 21:49:35.057541 18604 solver.cpp:218] Iteration 91100 (17.0776 iter/s, 5.85564s/100 iters), loss = 0.78082
I1107 21:49:35.057541 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1107 21:49:35.057541 18604 solver.cpp:237]     Train net output #1: loss = 0.78082 (* 1 = 0.78082 loss)
I1107 21:49:35.057541 18604 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1107 21:49:40.907002 18604 solver.cpp:218] Iteration 91200 (17.097 iter/s, 5.84897s/100 iters), loss = 0.601498
I1107 21:49:40.907002 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:49:40.907002 18604 solver.cpp:237]     Train net output #1: loss = 0.601498 (* 1 = 0.601498 loss)
I1107 21:49:40.907002 18604 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1107 21:49:46.772440 18604 solver.cpp:218] Iteration 91300 (17.0487 iter/s, 5.86557s/100 iters), loss = 0.714486
I1107 21:49:46.772440 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 21:49:46.772440 18604 solver.cpp:237]     Train net output #1: loss = 0.714486 (* 1 = 0.714486 loss)
I1107 21:49:46.772440 18604 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1107 21:49:52.632338 18604 solver.cpp:218] Iteration 91400 (17.0673 iter/s, 5.85915s/100 iters), loss = 0.800265
I1107 21:49:52.632338 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1107 21:49:52.632338 18604 solver.cpp:237]     Train net output #1: loss = 0.800265 (* 1 = 0.800265 loss)
I1107 21:49:52.632338 18604 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1107 21:49:58.204203  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:49:58.435220 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_91500.caffemodel
I1107 21:49:58.449219 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_91500.solverstate
I1107 21:49:58.454219 18604 solver.cpp:330] Iteration 91500, Testing net (#0)
I1107 21:49:58.454219 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:49:59.742346 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:49:59.792349 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5767
I1107 21:49:59.792349 18604 solver.cpp:397]     Test net output #1: loss = 1.65561 (* 1 = 1.65561 loss)
I1107 21:49:59.848350 18604 solver.cpp:218] Iteration 91500 (13.8577 iter/s, 7.21619s/100 iters), loss = 0.755775
I1107 21:49:59.848350 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 21:49:59.848350 18604 solver.cpp:237]     Train net output #1: loss = 0.755775 (* 1 = 0.755775 loss)
I1107 21:49:59.848350 18604 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1107 21:50:05.739800 18604 solver.cpp:218] Iteration 91600 (16.9772 iter/s, 5.89025s/100 iters), loss = 0.752272
I1107 21:50:05.739800 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1107 21:50:05.739800 18604 solver.cpp:237]     Train net output #1: loss = 0.752272 (* 1 = 0.752272 loss)
I1107 21:50:05.739800 18604 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1107 21:50:11.581166 18604 solver.cpp:218] Iteration 91700 (17.1195 iter/s, 5.84131s/100 iters), loss = 0.611048
I1107 21:50:11.581166 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 21:50:11.581166 18604 solver.cpp:237]     Train net output #1: loss = 0.611048 (* 1 = 0.611048 loss)
I1107 21:50:11.581166 18604 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1107 21:50:17.423534 18604 solver.cpp:218] Iteration 91800 (17.116 iter/s, 5.84249s/100 iters), loss = 0.689156
I1107 21:50:17.424535 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 21:50:17.424535 18604 solver.cpp:237]     Train net output #1: loss = 0.689156 (* 1 = 0.689156 loss)
I1107 21:50:17.424535 18604 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1107 21:50:23.262375 18604 solver.cpp:218] Iteration 91900 (17.1301 iter/s, 5.83769s/100 iters), loss = 0.775904
I1107 21:50:23.262375 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1107 21:50:23.262375 18604 solver.cpp:237]     Train net output #1: loss = 0.775904 (* 1 = 0.775904 loss)
I1107 21:50:23.262375 18604 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1107 21:50:28.817231  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:50:29.049240 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_92000.caffemodel
I1107 21:50:29.063246 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_92000.solverstate
I1107 21:50:29.068246 18604 solver.cpp:330] Iteration 92000, Testing net (#0)
I1107 21:50:29.068246 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:50:30.356324 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:50:30.407330 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5754
I1107 21:50:30.407330 18604 solver.cpp:397]     Test net output #1: loss = 1.67647 (* 1 = 1.67647 loss)
I1107 21:50:30.463335 18604 solver.cpp:218] Iteration 92000 (13.8883 iter/s, 7.2003s/100 iters), loss = 0.525095
I1107 21:50:30.463335 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:50:30.463335 18604 solver.cpp:237]     Train net output #1: loss = 0.525095 (* 1 = 0.525095 loss)
I1107 21:50:30.463335 18604 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1107 21:50:36.315696 18604 solver.cpp:218] Iteration 92100 (17.0877 iter/s, 5.85216s/100 iters), loss = 0.713338
I1107 21:50:36.315696 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1107 21:50:36.315696 18604 solver.cpp:237]     Train net output #1: loss = 0.713338 (* 1 = 0.713338 loss)
I1107 21:50:36.315696 18604 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1107 21:50:42.174036 18604 solver.cpp:218] Iteration 92200 (17.071 iter/s, 5.85788s/100 iters), loss = 0.576178
I1107 21:50:42.174036 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:50:42.174036 18604 solver.cpp:237]     Train net output #1: loss = 0.576178 (* 1 = 0.576178 loss)
I1107 21:50:42.174036 18604 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1107 21:50:48.026409 18604 solver.cpp:218] Iteration 92300 (17.0868 iter/s, 5.85248s/100 iters), loss = 0.784234
I1107 21:50:48.026409 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1107 21:50:48.026409 18604 solver.cpp:237]     Train net output #1: loss = 0.784234 (* 1 = 0.784234 loss)
I1107 21:50:48.026409 18604 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1107 21:50:53.877259 18604 solver.cpp:218] Iteration 92400 (17.0946 iter/s, 5.84979s/100 iters), loss = 0.752894
I1107 21:50:53.877259 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 21:50:53.877259 18604 solver.cpp:237]     Train net output #1: loss = 0.752894 (* 1 = 0.752894 loss)
I1107 21:50:53.877259 18604 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1107 21:50:59.445147  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:50:59.675662 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_92500.caffemodel
I1107 21:50:59.691167 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_92500.solverstate
I1107 21:50:59.696168 18604 solver.cpp:330] Iteration 92500, Testing net (#0)
I1107 21:50:59.696168 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:51:00.985247 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:51:01.036247 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5877
I1107 21:51:01.037247 18604 solver.cpp:397]     Test net output #1: loss = 1.59447 (* 1 = 1.59447 loss)
I1107 21:51:01.092252 18604 solver.cpp:218] Iteration 92500 (13.8602 iter/s, 7.21493s/100 iters), loss = 0.678692
I1107 21:51:01.092252 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 21:51:01.092252 18604 solver.cpp:237]     Train net output #1: loss = 0.678692 (* 1 = 0.678692 loss)
I1107 21:51:01.092252 18604 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1107 21:51:06.947666 18604 solver.cpp:218] Iteration 92600 (17.0791 iter/s, 5.8551s/100 iters), loss = 0.660037
I1107 21:51:06.947666 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1107 21:51:06.947666 18604 solver.cpp:237]     Train net output #1: loss = 0.660037 (* 1 = 0.660037 loss)
I1107 21:51:06.947666 18604 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1107 21:51:12.807024 18604 solver.cpp:218] Iteration 92700 (17.0676 iter/s, 5.85907s/100 iters), loss = 0.658459
I1107 21:51:12.807024 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 21:51:12.807024 18604 solver.cpp:237]     Train net output #1: loss = 0.658459 (* 1 = 0.658459 loss)
I1107 21:51:12.807024 18604 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1107 21:51:18.663414 18604 solver.cpp:218] Iteration 92800 (17.0777 iter/s, 5.8556s/100 iters), loss = 0.779269
I1107 21:51:18.663414 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1107 21:51:18.663414 18604 solver.cpp:237]     Train net output #1: loss = 0.779269 (* 1 = 0.779269 loss)
I1107 21:51:18.663414 18604 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1107 21:51:24.515830 18604 solver.cpp:218] Iteration 92900 (17.0882 iter/s, 5.852s/100 iters), loss = 0.865581
I1107 21:51:24.515830 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1107 21:51:24.515830 18604 solver.cpp:237]     Train net output #1: loss = 0.865581 (* 1 = 0.865581 loss)
I1107 21:51:24.515830 18604 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1107 21:51:30.087208  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:51:30.319211 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_93000.caffemodel
I1107 21:51:30.334210 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_93000.solverstate
I1107 21:51:30.338209 18604 solver.cpp:330] Iteration 93000, Testing net (#0)
I1107 21:51:30.339210 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:51:31.627316 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:51:31.677822 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5872
I1107 21:51:31.677822 18604 solver.cpp:397]     Test net output #1: loss = 1.60361 (* 1 = 1.60361 loss)
I1107 21:51:31.733323 18604 solver.cpp:218] Iteration 93000 (13.8554 iter/s, 7.21738s/100 iters), loss = 0.755711
I1107 21:51:31.733323 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1107 21:51:31.733323 18604 solver.cpp:237]     Train net output #1: loss = 0.755711 (* 1 = 0.755711 loss)
I1107 21:51:31.733323 18604 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1107 21:51:37.578212 18604 solver.cpp:218] Iteration 93100 (17.1115 iter/s, 5.84401s/100 iters), loss = 0.73462
I1107 21:51:37.578212 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1107 21:51:37.578212 18604 solver.cpp:237]     Train net output #1: loss = 0.73462 (* 1 = 0.73462 loss)
I1107 21:51:37.578212 18604 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1107 21:51:43.418305 18604 solver.cpp:218] Iteration 93200 (17.1251 iter/s, 5.83938s/100 iters), loss = 0.624105
I1107 21:51:43.418305 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 21:51:43.418305 18604 solver.cpp:237]     Train net output #1: loss = 0.624105 (* 1 = 0.624105 loss)
I1107 21:51:43.418305 18604 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1107 21:51:49.270298 18604 solver.cpp:218] Iteration 93300 (17.0892 iter/s, 5.85163s/100 iters), loss = 0.851869
I1107 21:51:49.270298 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1107 21:51:49.270298 18604 solver.cpp:237]     Train net output #1: loss = 0.851869 (* 1 = 0.851869 loss)
I1107 21:51:49.270298 18604 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1107 21:51:55.121196 18604 solver.cpp:218] Iteration 93400 (17.0918 iter/s, 5.85076s/100 iters), loss = 0.800319
I1107 21:51:55.121196 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1107 21:51:55.121196 18604 solver.cpp:237]     Train net output #1: loss = 0.800319 (* 1 = 0.800319 loss)
I1107 21:51:55.121196 18604 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1107 21:52:00.688603  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:52:00.919615 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_93500.caffemodel
I1107 21:52:00.935616 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_93500.solverstate
I1107 21:52:00.939615 18604 solver.cpp:330] Iteration 93500, Testing net (#0)
I1107 21:52:00.939615 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:52:02.228801 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:52:02.279806 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5894
I1107 21:52:02.279806 18604 solver.cpp:397]     Test net output #1: loss = 1.58499 (* 1 = 1.58499 loss)
I1107 21:52:02.335809 18604 solver.cpp:218] Iteration 93500 (13.8614 iter/s, 7.21426s/100 iters), loss = 0.557147
I1107 21:52:02.335809 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:52:02.335809 18604 solver.cpp:237]     Train net output #1: loss = 0.557147 (* 1 = 0.557147 loss)
I1107 21:52:02.335809 18604 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1107 21:52:08.194242 18604 solver.cpp:218] Iteration 93600 (17.07 iter/s, 5.85822s/100 iters), loss = 0.745998
I1107 21:52:08.194242 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1107 21:52:08.194242 18604 solver.cpp:237]     Train net output #1: loss = 0.745998 (* 1 = 0.745998 loss)
I1107 21:52:08.194242 18604 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1107 21:52:14.055640 18604 solver.cpp:218] Iteration 93700 (17.0629 iter/s, 5.86066s/100 iters), loss = 0.456288
I1107 21:52:14.055640 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 21:52:14.055640 18604 solver.cpp:237]     Train net output #1: loss = 0.456288 (* 1 = 0.456288 loss)
I1107 21:52:14.055640 18604 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1107 21:52:19.910010 18604 solver.cpp:218] Iteration 93800 (17.0817 iter/s, 5.85422s/100 iters), loss = 0.811291
I1107 21:52:19.910010 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1107 21:52:19.910010 18604 solver.cpp:237]     Train net output #1: loss = 0.811291 (* 1 = 0.811291 loss)
I1107 21:52:19.910010 18604 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1107 21:52:25.757436 18604 solver.cpp:218] Iteration 93900 (17.1055 iter/s, 5.84608s/100 iters), loss = 0.795656
I1107 21:52:25.757436 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1107 21:52:25.757436 18604 solver.cpp:237]     Train net output #1: loss = 0.795656 (* 1 = 0.795656 loss)
I1107 21:52:25.757436 18604 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1107 21:52:31.337848  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:52:31.568859 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_94000.caffemodel
I1107 21:52:31.585865 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_94000.solverstate
I1107 21:52:31.590868 18604 solver.cpp:330] Iteration 94000, Testing net (#0)
I1107 21:52:31.590868 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:52:32.881453 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:52:32.931957 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5809
I1107 21:52:32.931957 18604 solver.cpp:397]     Test net output #1: loss = 1.61521 (* 1 = 1.61521 loss)
I1107 21:52:32.987959 18604 solver.cpp:218] Iteration 94000 (13.831 iter/s, 7.23013s/100 iters), loss = 0.664586
I1107 21:52:32.987959 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:52:32.987959 18604 solver.cpp:237]     Train net output #1: loss = 0.664586 (* 1 = 0.664586 loss)
I1107 21:52:32.987959 18604 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1107 21:52:38.840318 18604 solver.cpp:218] Iteration 94100 (17.0858 iter/s, 5.85283s/100 iters), loss = 0.672883
I1107 21:52:38.840318 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:52:38.840318 18604 solver.cpp:237]     Train net output #1: loss = 0.672883 (* 1 = 0.672883 loss)
I1107 21:52:38.840318 18604 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1107 21:52:44.688696 18604 solver.cpp:218] Iteration 94200 (17.1005 iter/s, 5.84777s/100 iters), loss = 0.645131
I1107 21:52:44.688696 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 21:52:44.688696 18604 solver.cpp:237]     Train net output #1: loss = 0.645131 (* 1 = 0.645131 loss)
I1107 21:52:44.688696 18604 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1107 21:52:50.540078 18604 solver.cpp:218] Iteration 94300 (17.0924 iter/s, 5.85056s/100 iters), loss = 0.744932
I1107 21:52:50.540078 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1107 21:52:50.540078 18604 solver.cpp:237]     Train net output #1: loss = 0.744932 (* 1 = 0.744932 loss)
I1107 21:52:50.540078 18604 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1107 21:52:56.401438 18604 solver.cpp:218] Iteration 94400 (17.0617 iter/s, 5.86109s/100 iters), loss = 0.756247
I1107 21:52:56.401438 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1107 21:52:56.401438 18604 solver.cpp:237]     Train net output #1: loss = 0.756247 (* 1 = 0.756247 loss)
I1107 21:52:56.401438 18604 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1107 21:53:01.970793  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:53:02.202822 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_94500.caffemodel
I1107 21:53:02.218813 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_94500.solverstate
I1107 21:53:02.224813 18604 solver.cpp:330] Iteration 94500, Testing net (#0)
I1107 21:53:02.224813 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:53:03.516890 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:53:03.566893 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5755
I1107 21:53:03.566893 18604 solver.cpp:397]     Test net output #1: loss = 1.65296 (* 1 = 1.65296 loss)
I1107 21:53:03.623898 18604 solver.cpp:218] Iteration 94500 (13.8474 iter/s, 7.22158s/100 iters), loss = 0.570867
I1107 21:53:03.623898 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 21:53:03.623898 18604 solver.cpp:237]     Train net output #1: loss = 0.570867 (* 1 = 0.570867 loss)
I1107 21:53:03.623898 18604 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1107 21:53:09.481292 18604 solver.cpp:218] Iteration 94600 (17.072 iter/s, 5.85754s/100 iters), loss = 0.663757
I1107 21:53:09.481292 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:53:09.481292 18604 solver.cpp:237]     Train net output #1: loss = 0.663757 (* 1 = 0.663757 loss)
I1107 21:53:09.481292 18604 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1107 21:53:15.335734 18604 solver.cpp:218] Iteration 94700 (17.0832 iter/s, 5.85371s/100 iters), loss = 0.62851
I1107 21:53:15.335734 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 21:53:15.335734 18604 solver.cpp:237]     Train net output #1: loss = 0.62851 (* 1 = 0.62851 loss)
I1107 21:53:15.335734 18604 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1107 21:53:21.190172 18604 solver.cpp:218] Iteration 94800 (17.082 iter/s, 5.8541s/100 iters), loss = 0.754113
I1107 21:53:21.190172 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1107 21:53:21.190172 18604 solver.cpp:237]     Train net output #1: loss = 0.754113 (* 1 = 0.754113 loss)
I1107 21:53:21.190172 18604 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1107 21:53:27.053536 18604 solver.cpp:218] Iteration 94900 (17.0546 iter/s, 5.86354s/100 iters), loss = 0.848585
I1107 21:53:27.054538 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1107 21:53:27.054538 18604 solver.cpp:237]     Train net output #1: loss = 0.848585 (* 1 = 0.848585 loss)
I1107 21:53:27.054538 18604 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1107 21:53:32.634883  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:53:32.865906 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_95000.caffemodel
I1107 21:53:32.881906 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_95000.solverstate
I1107 21:53:32.885905 18604 solver.cpp:330] Iteration 95000, Testing net (#0)
I1107 21:53:32.885905 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:53:34.178014 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:53:34.229013 18604 solver.cpp:397]     Test net output #0: accuracy = 0.5899
I1107 21:53:34.229013 18604 solver.cpp:397]     Test net output #1: loss = 1.60831 (* 1 = 1.60831 loss)
I1107 21:53:34.285018 18604 solver.cpp:218] Iteration 95000 (13.8303 iter/s, 7.23051s/100 iters), loss = 0.684598
I1107 21:53:34.285018 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1107 21:53:34.285018 18604 solver.cpp:237]     Train net output #1: loss = 0.684598 (* 1 = 0.684598 loss)
I1107 21:53:34.285018 18604 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1107 21:53:34.285018 18604 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1107 21:53:40.149888 18604 solver.cpp:218] Iteration 95100 (17.0534 iter/s, 5.86392s/100 iters), loss = 0.683127
I1107 21:53:40.149888 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1107 21:53:40.149888 18604 solver.cpp:237]     Train net output #1: loss = 0.683127 (* 1 = 0.683127 loss)
I1107 21:53:40.149888 18604 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1107 21:53:46.015722 18604 solver.cpp:218] Iteration 95200 (17.0473 iter/s, 5.86604s/100 iters), loss = 0.505421
I1107 21:53:46.015722 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 21:53:46.015722 18604 solver.cpp:237]     Train net output #1: loss = 0.505421 (* 1 = 0.505421 loss)
I1107 21:53:46.015722 18604 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1107 21:53:51.878135 18604 solver.cpp:218] Iteration 95300 (17.0588 iter/s, 5.86208s/100 iters), loss = 0.640949
I1107 21:53:51.878135 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:53:51.878135 18604 solver.cpp:237]     Train net output #1: loss = 0.640949 (* 1 = 0.640949 loss)
I1107 21:53:51.878135 18604 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1107 21:53:57.746528 18604 solver.cpp:218] Iteration 95400 (17.0424 iter/s, 5.8677s/100 iters), loss = 0.595214
I1107 21:53:57.747030 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 21:53:57.747030 18604 solver.cpp:237]     Train net output #1: loss = 0.595214 (* 1 = 0.595214 loss)
I1107 21:53:57.747030 18604 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1107 21:54:03.324893  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:54:03.555907 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_95500.caffemodel
I1107 21:54:03.569908 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_95500.solverstate
I1107 21:54:03.574908 18604 solver.cpp:330] Iteration 95500, Testing net (#0)
I1107 21:54:03.574908 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:54:04.866993 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:54:04.917994 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6735
I1107 21:54:04.917994 18604 solver.cpp:397]     Test net output #1: loss = 1.19519 (* 1 = 1.19519 loss)
I1107 21:54:04.973999 18604 solver.cpp:218] Iteration 95500 (13.837 iter/s, 7.22701s/100 iters), loss = 0.484507
I1107 21:54:04.973999 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 21:54:04.973999 18604 solver.cpp:237]     Train net output #1: loss = 0.484507 (* 1 = 0.484507 loss)
I1107 21:54:04.973999 18604 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1107 21:54:10.837386 18604 solver.cpp:218] Iteration 95600 (17.0571 iter/s, 5.86267s/100 iters), loss = 0.607825
I1107 21:54:10.837386 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1107 21:54:10.837386 18604 solver.cpp:237]     Train net output #1: loss = 0.607825 (* 1 = 0.607825 loss)
I1107 21:54:10.837386 18604 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1107 21:54:16.705808 18604 solver.cpp:218] Iteration 95700 (17.0411 iter/s, 5.86815s/100 iters), loss = 0.487893
I1107 21:54:16.705808 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:54:16.705808 18604 solver.cpp:237]     Train net output #1: loss = 0.487893 (* 1 = 0.487893 loss)
I1107 21:54:16.705808 18604 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1107 21:54:22.569202 18604 solver.cpp:218] Iteration 95800 (17.0549 iter/s, 5.86341s/100 iters), loss = 0.580939
I1107 21:54:22.569202 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1107 21:54:22.569202 18604 solver.cpp:237]     Train net output #1: loss = 0.580939 (* 1 = 0.580939 loss)
I1107 21:54:22.569202 18604 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1107 21:54:28.429584 18604 solver.cpp:218] Iteration 95900 (17.0647 iter/s, 5.86004s/100 iters), loss = 0.642085
I1107 21:54:28.429584 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 21:54:28.429584 18604 solver.cpp:237]     Train net output #1: loss = 0.642085 (* 1 = 0.642085 loss)
I1107 21:54:28.429584 18604 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1107 21:54:34.007967  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:54:34.239485 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_96000.caffemodel
I1107 21:54:34.258991 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_96000.solverstate
I1107 21:54:34.263991 18604 solver.cpp:330] Iteration 96000, Testing net (#0)
I1107 21:54:34.263991 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:54:35.556092 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:54:35.606092 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6763
I1107 21:54:35.606092 18604 solver.cpp:397]     Test net output #1: loss = 1.18939 (* 1 = 1.18939 loss)
I1107 21:54:35.663095 18604 solver.cpp:218] Iteration 96000 (13.8253 iter/s, 7.23314s/100 iters), loss = 0.475936
I1107 21:54:35.663095 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 21:54:35.663095 18604 solver.cpp:237]     Train net output #1: loss = 0.475936 (* 1 = 0.475936 loss)
I1107 21:54:35.663095 18604 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1107 21:54:41.546367 18604 solver.cpp:218] Iteration 96100 (16.999 iter/s, 5.88268s/100 iters), loss = 0.523659
I1107 21:54:41.546367 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 21:54:41.546367 18604 solver.cpp:237]     Train net output #1: loss = 0.523659 (* 1 = 0.523659 loss)
I1107 21:54:41.546367 18604 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1107 21:54:47.414783 18604 solver.cpp:218] Iteration 96200 (17.043 iter/s, 5.86752s/100 iters), loss = 0.472913
I1107 21:54:47.414783 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:54:47.414783 18604 solver.cpp:237]     Train net output #1: loss = 0.472913 (* 1 = 0.472913 loss)
I1107 21:54:47.414783 18604 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1107 21:54:53.288161 18604 solver.cpp:218] Iteration 96300 (17.0264 iter/s, 5.87322s/100 iters), loss = 0.604158
I1107 21:54:53.288161 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1107 21:54:53.288161 18604 solver.cpp:237]     Train net output #1: loss = 0.604158 (* 1 = 0.604158 loss)
I1107 21:54:53.288161 18604 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1107 21:54:59.163542 18604 solver.cpp:218] Iteration 96400 (17.0218 iter/s, 5.8748s/100 iters), loss = 0.521816
I1107 21:54:59.163542 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 21:54:59.163542 18604 solver.cpp:237]     Train net output #1: loss = 0.521816 (* 1 = 0.521816 loss)
I1107 21:54:59.163542 18604 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1107 21:55:04.745909  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:55:04.975919 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_96500.caffemodel
I1107 21:55:04.990917 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_96500.solverstate
I1107 21:55:04.995921 18604 solver.cpp:330] Iteration 96500, Testing net (#0)
I1107 21:55:04.995921 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:55:06.289055 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:55:06.341065 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6772
I1107 21:55:06.341065 18604 solver.cpp:397]     Test net output #1: loss = 1.18939 (* 1 = 1.18939 loss)
I1107 21:55:06.397562 18604 solver.cpp:218] Iteration 96500 (13.8246 iter/s, 7.2335s/100 iters), loss = 0.54608
I1107 21:55:06.397562 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1107 21:55:06.397562 18604 solver.cpp:237]     Train net output #1: loss = 0.54608 (* 1 = 0.54608 loss)
I1107 21:55:06.397562 18604 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1107 21:55:12.268424 18604 solver.cpp:218] Iteration 96600 (17.0348 iter/s, 5.87032s/100 iters), loss = 0.550242
I1107 21:55:12.268424 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 21:55:12.268424 18604 solver.cpp:237]     Train net output #1: loss = 0.550242 (* 1 = 0.550242 loss)
I1107 21:55:12.268424 18604 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1107 21:55:18.152848 18604 solver.cpp:218] Iteration 96700 (16.9942 iter/s, 5.88437s/100 iters), loss = 0.401791
I1107 21:55:18.152848 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:55:18.152848 18604 solver.cpp:237]     Train net output #1: loss = 0.401791 (* 1 = 0.401791 loss)
I1107 21:55:18.152848 18604 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1107 21:55:24.032330 18604 solver.cpp:218] Iteration 96800 (17.0105 iter/s, 5.87872s/100 iters), loss = 0.509381
I1107 21:55:24.032330 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:55:24.032330 18604 solver.cpp:237]     Train net output #1: loss = 0.509381 (* 1 = 0.509381 loss)
I1107 21:55:24.032330 18604 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1107 21:55:29.919765 18604 solver.cpp:218] Iteration 96900 (16.9863 iter/s, 5.88711s/100 iters), loss = 0.530378
I1107 21:55:29.919765 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 21:55:29.919765 18604 solver.cpp:237]     Train net output #1: loss = 0.530378 (* 1 = 0.530378 loss)
I1107 21:55:29.919765 18604 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1107 21:55:35.507150  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:55:35.740662 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_97000.caffemodel
I1107 21:55:35.757167 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_97000.solverstate
I1107 21:55:35.761167 18604 solver.cpp:330] Iteration 97000, Testing net (#0)
I1107 21:55:35.761167 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:55:37.056244 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:55:37.107245 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6797
I1107 21:55:37.107245 18604 solver.cpp:397]     Test net output #1: loss = 1.18871 (* 1 = 1.18871 loss)
I1107 21:55:37.164249 18604 solver.cpp:218] Iteration 97000 (13.8046 iter/s, 7.24399s/100 iters), loss = 0.512109
I1107 21:55:37.164249 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:55:37.164249 18604 solver.cpp:237]     Train net output #1: loss = 0.512109 (* 1 = 0.512109 loss)
I1107 21:55:37.164249 18604 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1107 21:55:43.055675 18604 solver.cpp:218] Iteration 97100 (16.9752 iter/s, 5.89095s/100 iters), loss = 0.571717
I1107 21:55:43.055675 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 21:55:43.055675 18604 solver.cpp:237]     Train net output #1: loss = 0.571717 (* 1 = 0.571717 loss)
I1107 21:55:43.055675 18604 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1107 21:55:48.930032 18604 solver.cpp:218] Iteration 97200 (17.0223 iter/s, 5.87465s/100 iters), loss = 0.428774
I1107 21:55:48.931033 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 21:55:48.931033 18604 solver.cpp:237]     Train net output #1: loss = 0.428774 (* 1 = 0.428774 loss)
I1107 21:55:48.931033 18604 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1107 21:55:54.791425 18604 solver.cpp:218] Iteration 97300 (17.0625 iter/s, 5.8608s/100 iters), loss = 0.5236
I1107 21:55:54.791425 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 21:55:54.791425 18604 solver.cpp:237]     Train net output #1: loss = 0.5236 (* 1 = 0.5236 loss)
I1107 21:55:54.791425 18604 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1107 21:56:00.661824 18604 solver.cpp:218] Iteration 97400 (17.0357 iter/s, 5.87003s/100 iters), loss = 0.55823
I1107 21:56:00.661824 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1107 21:56:00.661824 18604 solver.cpp:237]     Train net output #1: loss = 0.55823 (* 1 = 0.55823 loss)
I1107 21:56:00.662824 18604 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1107 21:56:06.246732  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:56:06.478245 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_97500.caffemodel
I1107 21:56:06.494243 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_97500.solverstate
I1107 21:56:06.499244 18604 solver.cpp:330] Iteration 97500, Testing net (#0)
I1107 21:56:06.499244 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:56:07.789381 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:56:07.841385 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6775
I1107 21:56:07.841385 18604 solver.cpp:397]     Test net output #1: loss = 1.19206 (* 1 = 1.19206 loss)
I1107 21:56:07.897387 18604 solver.cpp:218] Iteration 97500 (13.8222 iter/s, 7.23473s/100 iters), loss = 0.486605
I1107 21:56:07.897387 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 21:56:07.897387 18604 solver.cpp:237]     Train net output #1: loss = 0.486605 (* 1 = 0.486605 loss)
I1107 21:56:07.897387 18604 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1107 21:56:13.765880 18604 solver.cpp:218] Iteration 97600 (17.0403 iter/s, 5.86845s/100 iters), loss = 0.537479
I1107 21:56:13.765880 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 21:56:13.765880 18604 solver.cpp:237]     Train net output #1: loss = 0.537479 (* 1 = 0.537479 loss)
I1107 21:56:13.765880 18604 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1107 21:56:19.638715 18604 solver.cpp:218] Iteration 97700 (17.0311 iter/s, 5.87159s/100 iters), loss = 0.376798
I1107 21:56:19.638715 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 21:56:19.638715 18604 solver.cpp:237]     Train net output #1: loss = 0.376798 (* 1 = 0.376798 loss)
I1107 21:56:19.638715 18604 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1107 21:56:25.516296 18604 solver.cpp:218] Iteration 97800 (17.0146 iter/s, 5.87729s/100 iters), loss = 0.548167
I1107 21:56:25.516296 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 21:56:25.516296 18604 solver.cpp:237]     Train net output #1: loss = 0.548167 (* 1 = 0.548167 loss)
I1107 21:56:25.516296 18604 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1107 21:56:31.387703 18604 solver.cpp:218] Iteration 97900 (17.033 iter/s, 5.87096s/100 iters), loss = 0.629069
I1107 21:56:31.387703 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:56:31.387703 18604 solver.cpp:237]     Train net output #1: loss = 0.629069 (* 1 = 0.629069 loss)
I1107 21:56:31.387703 18604 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1107 21:56:36.963085  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:56:37.194099 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_98000.caffemodel
I1107 21:56:37.208101 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_98000.solverstate
I1107 21:56:37.213100 18604 solver.cpp:330] Iteration 98000, Testing net (#0)
I1107 21:56:37.213100 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:56:38.505194 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:56:38.555699 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6769
I1107 21:56:38.555699 18604 solver.cpp:397]     Test net output #1: loss = 1.1904 (* 1 = 1.1904 loss)
I1107 21:56:38.611202 18604 solver.cpp:218] Iteration 98000 (13.8431 iter/s, 7.2238s/100 iters), loss = 0.43196
I1107 21:56:38.612202 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 21:56:38.612202 18604 solver.cpp:237]     Train net output #1: loss = 0.43196 (* 1 = 0.43196 loss)
I1107 21:56:38.612202 18604 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1107 21:56:44.491508 18604 solver.cpp:218] Iteration 98100 (17.0098 iter/s, 5.87895s/100 iters), loss = 0.484715
I1107 21:56:44.491508 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:56:44.491508 18604 solver.cpp:237]     Train net output #1: loss = 0.484715 (* 1 = 0.484715 loss)
I1107 21:56:44.491508 18604 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1107 21:56:50.368672 18604 solver.cpp:218] Iteration 98200 (17.0141 iter/s, 5.87748s/100 iters), loss = 0.364951
I1107 21:56:50.368672 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 21:56:50.368672 18604 solver.cpp:237]     Train net output #1: loss = 0.364951 (* 1 = 0.364951 loss)
I1107 21:56:50.368672 18604 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1107 21:56:56.238080 18604 solver.cpp:218] Iteration 98300 (17.039 iter/s, 5.86889s/100 iters), loss = 0.473632
I1107 21:56:56.238080 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 21:56:56.238080 18604 solver.cpp:237]     Train net output #1: loss = 0.473632 (* 1 = 0.473632 loss)
I1107 21:56:56.238080 18604 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1107 21:57:02.105442 18604 solver.cpp:218] Iteration 98400 (17.0455 iter/s, 5.86664s/100 iters), loss = 0.557517
I1107 21:57:02.105442 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 21:57:02.105442 18604 solver.cpp:237]     Train net output #1: loss = 0.557517 (* 1 = 0.557517 loss)
I1107 21:57:02.105442 18604 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1107 21:57:07.684746  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:57:07.915766 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_98500.caffemodel
I1107 21:57:07.929766 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_98500.solverstate
I1107 21:57:07.934765 18604 solver.cpp:330] Iteration 98500, Testing net (#0)
I1107 21:57:07.934765 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:57:09.225845 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:57:09.276845 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6782
I1107 21:57:09.276845 18604 solver.cpp:397]     Test net output #1: loss = 1.19822 (* 1 = 1.19822 loss)
I1107 21:57:09.332850 18604 solver.cpp:218] Iteration 98500 (13.8363 iter/s, 7.22736s/100 iters), loss = 0.496573
I1107 21:57:09.332850 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:57:09.332850 18604 solver.cpp:237]     Train net output #1: loss = 0.496573 (* 1 = 0.496573 loss)
I1107 21:57:09.332850 18604 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1107 21:57:15.202234 18604 solver.cpp:218] Iteration 98600 (17.0407 iter/s, 5.86832s/100 iters), loss = 0.504016
I1107 21:57:15.202234 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:57:15.202234 18604 solver.cpp:237]     Train net output #1: loss = 0.504016 (* 1 = 0.504016 loss)
I1107 21:57:15.202234 18604 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1107 21:57:21.078610 18604 solver.cpp:218] Iteration 98700 (17.0166 iter/s, 5.87663s/100 iters), loss = 0.371675
I1107 21:57:21.078610 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 21:57:21.078610 18604 solver.cpp:237]     Train net output #1: loss = 0.371675 (* 1 = 0.371675 loss)
I1107 21:57:21.078610 18604 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1107 21:57:26.953029 18604 solver.cpp:218] Iteration 98800 (17.0249 iter/s, 5.87377s/100 iters), loss = 0.573819
I1107 21:57:26.953029 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 21:57:26.953029 18604 solver.cpp:237]     Train net output #1: loss = 0.573819 (* 1 = 0.573819 loss)
I1107 21:57:26.953029 18604 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1107 21:57:32.829409 18604 solver.cpp:218] Iteration 98900 (17.0196 iter/s, 5.87558s/100 iters), loss = 0.538839
I1107 21:57:32.829409 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 21:57:32.829409 18604 solver.cpp:237]     Train net output #1: loss = 0.538839 (* 1 = 0.538839 loss)
I1107 21:57:32.829409 18604 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1107 21:57:38.417821  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:57:38.649830 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_99000.caffemodel
I1107 21:57:38.663830 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_99000.solverstate
I1107 21:57:38.668830 18604 solver.cpp:330] Iteration 99000, Testing net (#0)
I1107 21:57:38.668830 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:57:39.961930 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:57:40.011935 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6763
I1107 21:57:40.011935 18604 solver.cpp:397]     Test net output #1: loss = 1.20415 (* 1 = 1.20415 loss)
I1107 21:57:40.068935 18604 solver.cpp:218] Iteration 99000 (13.8142 iter/s, 7.23894s/100 iters), loss = 0.453561
I1107 21:57:40.068935 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 21:57:40.068935 18604 solver.cpp:237]     Train net output #1: loss = 0.453561 (* 1 = 0.453561 loss)
I1107 21:57:40.068935 18604 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1107 21:57:45.943315 18604 solver.cpp:218] Iteration 99100 (17.0234 iter/s, 5.87426s/100 iters), loss = 0.401261
I1107 21:57:45.943315 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 21:57:45.943315 18604 solver.cpp:237]     Train net output #1: loss = 0.401261 (* 1 = 0.401261 loss)
I1107 21:57:45.943315 18604 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1107 21:57:51.820981 18604 solver.cpp:218] Iteration 99200 (17.0148 iter/s, 5.87724s/100 iters), loss = 0.317608
I1107 21:57:51.820981 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 21:57:51.820981 18604 solver.cpp:237]     Train net output #1: loss = 0.317608 (* 1 = 0.317608 loss)
I1107 21:57:51.820981 18604 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1107 21:57:57.688668 18604 solver.cpp:218] Iteration 99300 (17.0445 iter/s, 5.86698s/100 iters), loss = 0.419454
I1107 21:57:57.688668 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:57:57.688668 18604 solver.cpp:237]     Train net output #1: loss = 0.419454 (* 1 = 0.419454 loss)
I1107 21:57:57.688668 18604 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1107 21:58:03.553529 18604 solver.cpp:218] Iteration 99400 (17.0513 iter/s, 5.86464s/100 iters), loss = 0.411361
I1107 21:58:03.553529 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 21:58:03.553529 18604 solver.cpp:237]     Train net output #1: loss = 0.411361 (* 1 = 0.411361 loss)
I1107 21:58:03.553529 18604 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1107 21:58:09.132894  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:58:09.363909 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_99500.caffemodel
I1107 21:58:09.378908 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_99500.solverstate
I1107 21:58:09.383908 18604 solver.cpp:330] Iteration 99500, Testing net (#0)
I1107 21:58:09.383908 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:58:10.673990 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:58:10.724994 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6807
I1107 21:58:10.724994 18604 solver.cpp:397]     Test net output #1: loss = 1.19792 (* 1 = 1.19792 loss)
I1107 21:58:10.780993 18604 solver.cpp:218] Iteration 99500 (13.8364 iter/s, 7.22733s/100 iters), loss = 0.419405
I1107 21:58:10.780993 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 21:58:10.780993 18604 solver.cpp:237]     Train net output #1: loss = 0.419405 (* 1 = 0.419405 loss)
I1107 21:58:10.780993 18604 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1107 21:58:16.656370 18604 solver.cpp:218] Iteration 99600 (17.0224 iter/s, 5.87462s/100 iters), loss = 0.466263
I1107 21:58:16.656370 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:58:16.656370 18604 solver.cpp:237]     Train net output #1: loss = 0.466263 (* 1 = 0.466263 loss)
I1107 21:58:16.656370 18604 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1107 21:58:22.530777 18604 solver.cpp:218] Iteration 99700 (17.0247 iter/s, 5.87382s/100 iters), loss = 0.479993
I1107 21:58:22.530777 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 21:58:22.530777 18604 solver.cpp:237]     Train net output #1: loss = 0.479993 (* 1 = 0.479993 loss)
I1107 21:58:22.530777 18604 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1107 21:58:28.402154 18604 solver.cpp:218] Iteration 99800 (17.0322 iter/s, 5.87124s/100 iters), loss = 0.478596
I1107 21:58:28.402154 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 21:58:28.402154 18604 solver.cpp:237]     Train net output #1: loss = 0.478596 (* 1 = 0.478596 loss)
I1107 21:58:28.402154 18604 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1107 21:58:34.273538 18604 solver.cpp:218] Iteration 99900 (17.0316 iter/s, 5.87145s/100 iters), loss = 0.505986
I1107 21:58:34.273538 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 21:58:34.273538 18604 solver.cpp:237]     Train net output #1: loss = 0.505986 (* 1 = 0.505986 loss)
I1107 21:58:34.273538 18604 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1107 21:58:39.853888  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:58:40.084898 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_100000.caffemodel
I1107 21:58:40.100904 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_100000.solverstate
I1107 21:58:40.105404 18604 solver.cpp:330] Iteration 100000, Testing net (#0)
I1107 21:58:40.105404 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:58:41.398504 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:58:41.449018 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6788
I1107 21:58:41.449018 18604 solver.cpp:397]     Test net output #1: loss = 1.20099 (* 1 = 1.20099 loss)
I1107 21:58:41.505508 18604 solver.cpp:218] Iteration 100000 (13.8293 iter/s, 7.23104s/100 iters), loss = 0.362925
I1107 21:58:41.505508 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 21:58:41.505508 18604 solver.cpp:237]     Train net output #1: loss = 0.362925 (* 1 = 0.362925 loss)
I1107 21:58:41.505508 18604 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1107 21:58:47.369623 18604 solver.cpp:218] Iteration 100100 (17.0529 iter/s, 5.86412s/100 iters), loss = 0.476447
I1107 21:58:47.369623 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 21:58:47.369623 18604 solver.cpp:237]     Train net output #1: loss = 0.476447 (* 1 = 0.476447 loss)
I1107 21:58:47.369623 18604 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1107 21:58:53.239882 18604 solver.cpp:218] Iteration 100200 (17.037 iter/s, 5.86959s/100 iters), loss = 0.361665
I1107 21:58:53.239882 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 21:58:53.239882 18604 solver.cpp:237]     Train net output #1: loss = 0.361665 (* 1 = 0.361665 loss)
I1107 21:58:53.239882 18604 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1107 21:58:59.109474 18604 solver.cpp:218] Iteration 100300 (17.037 iter/s, 5.86959s/100 iters), loss = 0.459384
I1107 21:58:59.110474 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:58:59.110474 18604 solver.cpp:237]     Train net output #1: loss = 0.459384 (* 1 = 0.459384 loss)
I1107 21:58:59.110474 18604 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1107 21:59:04.974575 18604 solver.cpp:218] Iteration 100400 (17.0527 iter/s, 5.86417s/100 iters), loss = 0.482779
I1107 21:59:04.974575 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 21:59:04.974575 18604 solver.cpp:237]     Train net output #1: loss = 0.482779 (* 1 = 0.482779 loss)
I1107 21:59:04.974575 18604 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1107 21:59:10.555358  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:59:10.786401 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_100500.caffemodel
I1107 21:59:10.801892 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_100500.solverstate
I1107 21:59:10.806910 18604 solver.cpp:330] Iteration 100500, Testing net (#0)
I1107 21:59:10.806910 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:59:12.098242 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:59:12.147748 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6778
I1107 21:59:12.147748 18604 solver.cpp:397]     Test net output #1: loss = 1.20655 (* 1 = 1.20655 loss)
I1107 21:59:12.204257 18604 solver.cpp:218] Iteration 100500 (13.8326 iter/s, 7.22929s/100 iters), loss = 0.489562
I1107 21:59:12.204757 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 21:59:12.204757 18604 solver.cpp:237]     Train net output #1: loss = 0.489562 (* 1 = 0.489562 loss)
I1107 21:59:12.204757 18604 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1107 21:59:18.071444 18604 solver.cpp:218] Iteration 100600 (17.0448 iter/s, 5.86689s/100 iters), loss = 0.454962
I1107 21:59:18.071444 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:59:18.071444 18604 solver.cpp:237]     Train net output #1: loss = 0.454962 (* 1 = 0.454962 loss)
I1107 21:59:18.071444 18604 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1107 21:59:23.941382 18604 solver.cpp:218] Iteration 100700 (17.0373 iter/s, 5.86947s/100 iters), loss = 0.370726
I1107 21:59:23.941382 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 21:59:23.941382 18604 solver.cpp:237]     Train net output #1: loss = 0.370726 (* 1 = 0.370726 loss)
I1107 21:59:23.941382 18604 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1107 21:59:29.806694 18604 solver.cpp:218] Iteration 100800 (17.0514 iter/s, 5.86463s/100 iters), loss = 0.459775
I1107 21:59:29.806694 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 21:59:29.806694 18604 solver.cpp:237]     Train net output #1: loss = 0.459775 (* 1 = 0.459775 loss)
I1107 21:59:29.806694 18604 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1107 21:59:35.676071 18604 solver.cpp:218] Iteration 100900 (17.0394 iter/s, 5.86874s/100 iters), loss = 0.472101
I1107 21:59:35.676071 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 21:59:35.676071 18604 solver.cpp:237]     Train net output #1: loss = 0.472101 (* 1 = 0.472101 loss)
I1107 21:59:35.676071 18604 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1107 21:59:41.253453  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:59:41.485465 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_101000.caffemodel
I1107 21:59:41.500463 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_101000.solverstate
I1107 21:59:41.504966 18604 solver.cpp:330] Iteration 101000, Testing net (#0)
I1107 21:59:41.505466 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 21:59:42.796566 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 21:59:42.847571 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6743
I1107 21:59:42.847571 18604 solver.cpp:397]     Test net output #1: loss = 1.21969 (* 1 = 1.21969 loss)
I1107 21:59:42.904073 18604 solver.cpp:218] Iteration 101000 (13.8353 iter/s, 7.22787s/100 iters), loss = 0.434677
I1107 21:59:42.904073 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 21:59:42.904073 18604 solver.cpp:237]     Train net output #1: loss = 0.434677 (* 1 = 0.434677 loss)
I1107 21:59:42.904073 18604 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1107 21:59:48.777930 18604 solver.cpp:218] Iteration 101100 (17.0255 iter/s, 5.87355s/100 iters), loss = 0.422149
I1107 21:59:48.777930 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 21:59:48.777930 18604 solver.cpp:237]     Train net output #1: loss = 0.422149 (* 1 = 0.422149 loss)
I1107 21:59:48.777930 18604 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1107 21:59:54.641297 18604 solver.cpp:218] Iteration 101200 (17.0562 iter/s, 5.86296s/100 iters), loss = 0.441373
I1107 21:59:54.641297 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 21:59:54.641297 18604 solver.cpp:237]     Train net output #1: loss = 0.441373 (* 1 = 0.441373 loss)
I1107 21:59:54.641297 18604 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1107 22:00:00.514215 18604 solver.cpp:218] Iteration 101300 (17.0295 iter/s, 5.87215s/100 iters), loss = 0.423712
I1107 22:00:00.514215 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:00:00.514215 18604 solver.cpp:237]     Train net output #1: loss = 0.423712 (* 1 = 0.423712 loss)
I1107 22:00:00.514215 18604 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1107 22:00:06.409175 18604 solver.cpp:218] Iteration 101400 (16.9645 iter/s, 5.89467s/100 iters), loss = 0.470516
I1107 22:00:06.409175 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:00:06.409175 18604 solver.cpp:237]     Train net output #1: loss = 0.470516 (* 1 = 0.470516 loss)
I1107 22:00:06.409175 18604 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1107 22:00:11.996523  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:00:12.227541 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_101500.caffemodel
I1107 22:00:12.242542 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_101500.solverstate
I1107 22:00:12.247542 18604 solver.cpp:330] Iteration 101500, Testing net (#0)
I1107 22:00:12.247542 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:00:13.538621 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:00:13.589622 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6747
I1107 22:00:13.589622 18604 solver.cpp:397]     Test net output #1: loss = 1.21581 (* 1 = 1.21581 loss)
I1107 22:00:13.645627 18604 solver.cpp:218] Iteration 101500 (13.8191 iter/s, 7.23634s/100 iters), loss = 0.385551
I1107 22:00:13.645627 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:00:13.645627 18604 solver.cpp:237]     Train net output #1: loss = 0.385551 (* 1 = 0.385551 loss)
I1107 22:00:13.645627 18604 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1107 22:00:19.504037 18604 solver.cpp:218] Iteration 101600 (17.0723 iter/s, 5.85744s/100 iters), loss = 0.502266
I1107 22:00:19.504037 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:00:19.504037 18604 solver.cpp:237]     Train net output #1: loss = 0.502266 (* 1 = 0.502266 loss)
I1107 22:00:19.504037 18604 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1107 22:00:25.366428 18604 solver.cpp:218] Iteration 101700 (17.057 iter/s, 5.86269s/100 iters), loss = 0.357095
I1107 22:00:25.366428 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:00:25.366428 18604 solver.cpp:237]     Train net output #1: loss = 0.357095 (* 1 = 0.357095 loss)
I1107 22:00:25.366428 18604 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1107 22:00:31.237862 18604 solver.cpp:218] Iteration 101800 (17.0352 iter/s, 5.8702s/100 iters), loss = 0.433687
I1107 22:00:31.237862 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:00:31.237862 18604 solver.cpp:237]     Train net output #1: loss = 0.433687 (* 1 = 0.433687 loss)
I1107 22:00:31.237862 18604 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1107 22:00:37.101235 18604 solver.cpp:218] Iteration 101900 (17.0548 iter/s, 5.86345s/100 iters), loss = 0.481966
I1107 22:00:37.101235 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:00:37.101235 18604 solver.cpp:237]     Train net output #1: loss = 0.481966 (* 1 = 0.481966 loss)
I1107 22:00:37.101235 18604 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1107 22:00:42.679662  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:00:42.911183 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_102000.caffemodel
I1107 22:00:42.926688 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_102000.solverstate
I1107 22:00:42.931689 18604 solver.cpp:330] Iteration 102000, Testing net (#0)
I1107 22:00:42.931689 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:00:44.223803 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:00:44.273803 18604 solver.cpp:397]     Test net output #0: accuracy = 0.679
I1107 22:00:44.273803 18604 solver.cpp:397]     Test net output #1: loss = 1.21337 (* 1 = 1.21337 loss)
I1107 22:00:44.330812 18604 solver.cpp:218] Iteration 102000 (13.8336 iter/s, 7.22875s/100 iters), loss = 0.371839
I1107 22:00:44.330812 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:00:44.330812 18604 solver.cpp:237]     Train net output #1: loss = 0.371839 (* 1 = 0.371839 loss)
I1107 22:00:44.330812 18604 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1107 22:00:50.198190 18604 solver.cpp:218] Iteration 102100 (17.0428 iter/s, 5.86759s/100 iters), loss = 0.441607
I1107 22:00:50.198190 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:00:50.198190 18604 solver.cpp:237]     Train net output #1: loss = 0.441607 (* 1 = 0.441607 loss)
I1107 22:00:50.198190 18604 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1107 22:00:56.078590 18604 solver.cpp:218] Iteration 102200 (17.0071 iter/s, 5.8799s/100 iters), loss = 0.321409
I1107 22:00:56.078590 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:00:56.078590 18604 solver.cpp:237]     Train net output #1: loss = 0.321409 (* 1 = 0.321409 loss)
I1107 22:00:56.078590 18604 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1107 22:01:01.999065 18604 solver.cpp:218] Iteration 102300 (16.8914 iter/s, 5.92018s/100 iters), loss = 0.4389
I1107 22:01:01.999065 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:01:01.999065 18604 solver.cpp:237]     Train net output #1: loss = 0.4389 (* 1 = 0.4389 loss)
I1107 22:01:01.999065 18604 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1107 22:01:08.172941 18604 solver.cpp:218] Iteration 102400 (16.1998 iter/s, 6.17293s/100 iters), loss = 0.510709
I1107 22:01:08.172941 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:01:08.172941 18604 solver.cpp:237]     Train net output #1: loss = 0.510709 (* 1 = 0.510709 loss)
I1107 22:01:08.172941 18604 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1107 22:01:13.956234  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:01:14.193246 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_102500.caffemodel
I1107 22:01:14.209246 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_102500.solverstate
I1107 22:01:14.215247 18604 solver.cpp:330] Iteration 102500, Testing net (#0)
I1107 22:01:14.215247 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:01:15.528365 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:01:15.579368 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6779
I1107 22:01:15.579368 18604 solver.cpp:397]     Test net output #1: loss = 1.2182 (* 1 = 1.2182 loss)
I1107 22:01:15.635373 18604 solver.cpp:218] Iteration 102500 (13.4011 iter/s, 7.46209s/100 iters), loss = 0.36756
I1107 22:01:15.635874 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:01:15.635874 18604 solver.cpp:237]     Train net output #1: loss = 0.36756 (* 1 = 0.36756 loss)
I1107 22:01:15.635874 18604 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1107 22:01:21.525264 18604 solver.cpp:218] Iteration 102600 (16.9803 iter/s, 5.88918s/100 iters), loss = 0.457672
I1107 22:01:21.525264 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:01:21.525264 18604 solver.cpp:237]     Train net output #1: loss = 0.457672 (* 1 = 0.457672 loss)
I1107 22:01:21.525264 18604 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1107 22:01:27.442193 18604 solver.cpp:218] Iteration 102700 (16.9023 iter/s, 5.91634s/100 iters), loss = 0.289371
I1107 22:01:27.442193 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:01:27.442193 18604 solver.cpp:237]     Train net output #1: loss = 0.289371 (* 1 = 0.289371 loss)
I1107 22:01:27.442193 18604 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1107 22:01:33.378162 18604 solver.cpp:218] Iteration 102800 (16.8472 iter/s, 5.93571s/100 iters), loss = 0.462401
I1107 22:01:33.378162 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:01:33.378162 18604 solver.cpp:237]     Train net output #1: loss = 0.462401 (* 1 = 0.462401 loss)
I1107 22:01:33.378162 18604 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1107 22:01:39.378654 18604 solver.cpp:218] Iteration 102900 (16.6672 iter/s, 5.99983s/100 iters), loss = 0.427923
I1107 22:01:39.378654 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:01:39.378654 18604 solver.cpp:237]     Train net output #1: loss = 0.427923 (* 1 = 0.427923 loss)
I1107 22:01:39.378654 18604 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1107 22:01:44.992508  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:01:45.224519 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_103000.caffemodel
I1107 22:01:45.240520 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_103000.solverstate
I1107 22:01:45.245520 18604 solver.cpp:330] Iteration 103000, Testing net (#0)
I1107 22:01:45.245520 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:01:46.543607 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:01:46.594611 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6773
I1107 22:01:46.594611 18604 solver.cpp:397]     Test net output #1: loss = 1.22426 (* 1 = 1.22426 loss)
I1107 22:01:46.651612 18604 solver.cpp:218] Iteration 103000 (13.7494 iter/s, 7.27306s/100 iters), loss = 0.45322
I1107 22:01:46.651612 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:01:46.651612 18604 solver.cpp:237]     Train net output #1: loss = 0.45322 (* 1 = 0.45322 loss)
I1107 22:01:46.651612 18604 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1107 22:01:52.555991 18604 solver.cpp:218] Iteration 103100 (16.9392 iter/s, 5.90347s/100 iters), loss = 0.430187
I1107 22:01:52.555991 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:01:52.555991 18604 solver.cpp:237]     Train net output #1: loss = 0.430187 (* 1 = 0.430187 loss)
I1107 22:01:52.555991 18604 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1107 22:01:58.454391 18604 solver.cpp:218] Iteration 103200 (16.955 iter/s, 5.89796s/100 iters), loss = 0.370023
I1107 22:01:58.454391 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:01:58.454391 18604 solver.cpp:237]     Train net output #1: loss = 0.370023 (* 1 = 0.370023 loss)
I1107 22:01:58.454391 18604 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1107 22:02:04.355917 18604 solver.cpp:218] Iteration 103300 (16.9453 iter/s, 5.90134s/100 iters), loss = 0.480928
I1107 22:02:04.355917 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:02:04.355917 18604 solver.cpp:237]     Train net output #1: loss = 0.480928 (* 1 = 0.480928 loss)
I1107 22:02:04.355917 18604 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1107 22:02:10.247360 18604 solver.cpp:218] Iteration 103400 (16.9738 iter/s, 5.89143s/100 iters), loss = 0.451654
I1107 22:02:10.247360 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:02:10.247360 18604 solver.cpp:237]     Train net output #1: loss = 0.451654 (* 1 = 0.451654 loss)
I1107 22:02:10.247360 18604 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1107 22:02:15.852754  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:02:16.085791 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_103500.caffemodel
I1107 22:02:16.100791 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_103500.solverstate
I1107 22:02:16.105792 18604 solver.cpp:330] Iteration 103500, Testing net (#0)
I1107 22:02:16.105792 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:02:17.404873 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:02:17.455873 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6767
I1107 22:02:17.455873 18604 solver.cpp:397]     Test net output #1: loss = 1.21627 (* 1 = 1.21627 loss)
I1107 22:02:17.511878 18604 solver.cpp:218] Iteration 103500 (13.767 iter/s, 7.26375s/100 iters), loss = 0.404706
I1107 22:02:17.511878 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:02:17.511878 18604 solver.cpp:237]     Train net output #1: loss = 0.404706 (* 1 = 0.404706 loss)
I1107 22:02:17.511878 18604 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1107 22:02:23.411494 18604 solver.cpp:218] Iteration 103600 (16.9528 iter/s, 5.89874s/100 iters), loss = 0.476467
I1107 22:02:23.411494 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:02:23.411494 18604 solver.cpp:237]     Train net output #1: loss = 0.476467 (* 1 = 0.476467 loss)
I1107 22:02:23.411494 18604 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1107 22:02:29.307961 18604 solver.cpp:218] Iteration 103700 (16.96 iter/s, 5.89623s/100 iters), loss = 0.394884
I1107 22:02:29.307961 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:02:29.307961 18604 solver.cpp:237]     Train net output #1: loss = 0.394884 (* 1 = 0.394884 loss)
I1107 22:02:29.307961 18604 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1107 22:02:35.205397 18604 solver.cpp:218] Iteration 103800 (16.9573 iter/s, 5.89718s/100 iters), loss = 0.432225
I1107 22:02:35.205397 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:02:35.205397 18604 solver.cpp:237]     Train net output #1: loss = 0.432225 (* 1 = 0.432225 loss)
I1107 22:02:35.205397 18604 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1107 22:02:41.103878 18604 solver.cpp:218] Iteration 103900 (16.9549 iter/s, 5.89801s/100 iters), loss = 0.473349
I1107 22:02:41.103878 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:02:41.103878 18604 solver.cpp:237]     Train net output #1: loss = 0.473349 (* 1 = 0.473349 loss)
I1107 22:02:41.103878 18604 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1107 22:02:46.712961  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:02:46.942997 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_104000.caffemodel
I1107 22:02:46.959995 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_104000.solverstate
I1107 22:02:46.964998 18604 solver.cpp:330] Iteration 104000, Testing net (#0)
I1107 22:02:46.964998 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:02:48.263481 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:02:48.314501 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6772
I1107 22:02:48.315502 18604 solver.cpp:397]     Test net output #1: loss = 1.22511 (* 1 = 1.22511 loss)
I1107 22:02:48.371500 18604 solver.cpp:218] Iteration 104000 (13.7603 iter/s, 7.26727s/100 iters), loss = 0.428147
I1107 22:02:48.371500 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:02:48.372000 18604 solver.cpp:237]     Train net output #1: loss = 0.428147 (* 1 = 0.428147 loss)
I1107 22:02:48.372000 18604 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1107 22:02:54.334350 18604 solver.cpp:218] Iteration 104100 (16.7704 iter/s, 5.9629s/100 iters), loss = 0.395694
I1107 22:02:54.334350 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:02:54.334350 18604 solver.cpp:237]     Train net output #1: loss = 0.395694 (* 1 = 0.395694 loss)
I1107 22:02:54.334350 18604 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1107 22:03:00.208595 18604 solver.cpp:218] Iteration 104200 (17.0264 iter/s, 5.87322s/100 iters), loss = 0.36318
I1107 22:03:00.208595 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:03:00.208595 18604 solver.cpp:237]     Train net output #1: loss = 0.36318 (* 1 = 0.36318 loss)
I1107 22:03:00.208595 18604 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1107 22:03:06.145146 18604 solver.cpp:218] Iteration 104300 (16.8466 iter/s, 5.93592s/100 iters), loss = 0.492685
I1107 22:03:06.145146 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:03:06.145146 18604 solver.cpp:237]     Train net output #1: loss = 0.492685 (* 1 = 0.492685 loss)
I1107 22:03:06.145146 18604 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1107 22:03:12.140170 18604 solver.cpp:218] Iteration 104400 (16.6808 iter/s, 5.99491s/100 iters), loss = 0.417667
I1107 22:03:12.140671 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:03:12.140671 18604 solver.cpp:237]     Train net output #1: loss = 0.417667 (* 1 = 0.417667 loss)
I1107 22:03:12.140671 18604 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1107 22:03:17.723564  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:03:17.955580 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_104500.caffemodel
I1107 22:03:17.970579 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_104500.solverstate
I1107 22:03:17.975580 18604 solver.cpp:330] Iteration 104500, Testing net (#0)
I1107 22:03:17.975580 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:03:19.281674 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:03:19.335677 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6747
I1107 22:03:19.335677 18604 solver.cpp:397]     Test net output #1: loss = 1.22502 (* 1 = 1.22502 loss)
I1107 22:03:19.392679 18604 solver.cpp:218] Iteration 104500 (13.7899 iter/s, 7.25167s/100 iters), loss = 0.351363
I1107 22:03:19.392679 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:03:19.392679 18604 solver.cpp:237]     Train net output #1: loss = 0.351363 (* 1 = 0.351363 loss)
I1107 22:03:19.392679 18604 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1107 22:03:25.328057 18604 solver.cpp:218] Iteration 104600 (16.8493 iter/s, 5.93495s/100 iters), loss = 0.484146
I1107 22:03:25.328057 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:03:25.328057 18604 solver.cpp:237]     Train net output #1: loss = 0.484146 (* 1 = 0.484146 loss)
I1107 22:03:25.328057 18604 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1107 22:03:31.221518 18604 solver.cpp:218] Iteration 104700 (16.9669 iter/s, 5.89382s/100 iters), loss = 0.349573
I1107 22:03:31.221518 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:03:31.221518 18604 solver.cpp:237]     Train net output #1: loss = 0.349573 (* 1 = 0.349573 loss)
I1107 22:03:31.221518 18604 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1107 22:03:37.110929 18604 solver.cpp:218] Iteration 104800 (16.9811 iter/s, 5.8889s/100 iters), loss = 0.455994
I1107 22:03:37.110929 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 22:03:37.110929 18604 solver.cpp:237]     Train net output #1: loss = 0.455994 (* 1 = 0.455994 loss)
I1107 22:03:37.110929 18604 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1107 22:03:42.997397 18604 solver.cpp:218] Iteration 104900 (16.9908 iter/s, 5.88554s/100 iters), loss = 0.391685
I1107 22:03:42.997397 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:03:42.997397 18604 solver.cpp:237]     Train net output #1: loss = 0.391685 (* 1 = 0.391685 loss)
I1107 22:03:42.997397 18604 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1107 22:03:48.593770  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:03:48.827780 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_105000.caffemodel
I1107 22:03:48.842783 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_105000.solverstate
I1107 22:03:48.846783 18604 solver.cpp:330] Iteration 105000, Testing net (#0)
I1107 22:03:48.846783 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:03:50.143872 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:03:50.194875 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6771
I1107 22:03:50.194875 18604 solver.cpp:397]     Test net output #1: loss = 1.22409 (* 1 = 1.22409 loss)
I1107 22:03:50.249882 18604 solver.cpp:218] Iteration 105000 (13.788 iter/s, 7.25267s/100 iters), loss = 0.324774
I1107 22:03:50.249882 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:03:50.250883 18604 solver.cpp:237]     Train net output #1: loss = 0.324774 (* 1 = 0.324774 loss)
I1107 22:03:50.250883 18604 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1107 22:03:56.152608 18604 solver.cpp:218] Iteration 105100 (16.9448 iter/s, 5.90152s/100 iters), loss = 0.376602
I1107 22:03:56.152608 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:03:56.152608 18604 solver.cpp:237]     Train net output #1: loss = 0.376602 (* 1 = 0.376602 loss)
I1107 22:03:56.152608 18604 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1107 22:04:02.062011 18604 solver.cpp:218] Iteration 105200 (16.9235 iter/s, 5.90893s/100 iters), loss = 0.328867
I1107 22:04:02.062011 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:04:02.062011 18604 solver.cpp:237]     Train net output #1: loss = 0.328867 (* 1 = 0.328867 loss)
I1107 22:04:02.062011 18604 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1107 22:04:07.954260 18604 solver.cpp:218] Iteration 105300 (16.9702 iter/s, 5.89269s/100 iters), loss = 0.383025
I1107 22:04:07.955260 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:04:07.955260 18604 solver.cpp:237]     Train net output #1: loss = 0.383025 (* 1 = 0.383025 loss)
I1107 22:04:07.955260 18604 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1107 22:04:13.855667 18604 solver.cpp:218] Iteration 105400 (16.9466 iter/s, 5.90089s/100 iters), loss = 0.473329
I1107 22:04:13.855667 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:04:13.855667 18604 solver.cpp:237]     Train net output #1: loss = 0.473329 (* 1 = 0.473329 loss)
I1107 22:04:13.855667 18604 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1107 22:04:19.460058  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:04:19.692086 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_105500.caffemodel
I1107 22:04:19.708086 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_105500.solverstate
I1107 22:04:19.713086 18604 solver.cpp:330] Iteration 105500, Testing net (#0)
I1107 22:04:19.713086 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:04:21.009192 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:04:21.060192 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6727
I1107 22:04:21.060192 18604 solver.cpp:397]     Test net output #1: loss = 1.25414 (* 1 = 1.25414 loss)
I1107 22:04:21.117199 18604 solver.cpp:218] Iteration 105500 (13.7726 iter/s, 7.26078s/100 iters), loss = 0.351135
I1107 22:04:21.117199 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:04:21.117199 18604 solver.cpp:237]     Train net output #1: loss = 0.351135 (* 1 = 0.351135 loss)
I1107 22:04:21.117199 18604 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1107 22:04:27.002578 18604 solver.cpp:218] Iteration 105600 (16.9936 iter/s, 5.88457s/100 iters), loss = 0.438234
I1107 22:04:27.002578 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:04:27.002578 18604 solver.cpp:237]     Train net output #1: loss = 0.438234 (* 1 = 0.438234 loss)
I1107 22:04:27.002578 18604 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1107 22:04:32.929029 18604 solver.cpp:218] Iteration 105700 (16.8737 iter/s, 5.92637s/100 iters), loss = 0.299478
I1107 22:04:32.929029 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:04:32.929029 18604 solver.cpp:237]     Train net output #1: loss = 0.299478 (* 1 = 0.299478 loss)
I1107 22:04:32.929029 18604 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1107 22:04:38.887598 18604 solver.cpp:218] Iteration 105800 (16.7851 iter/s, 5.95767s/100 iters), loss = 0.383116
I1107 22:04:38.887598 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:04:38.887598 18604 solver.cpp:237]     Train net output #1: loss = 0.383116 (* 1 = 0.383116 loss)
I1107 22:04:38.887598 18604 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1107 22:04:44.753408 18604 solver.cpp:218] Iteration 105900 (17.0472 iter/s, 5.86607s/100 iters), loss = 0.504127
I1107 22:04:44.753408 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:04:44.753408 18604 solver.cpp:237]     Train net output #1: loss = 0.504127 (* 1 = 0.504127 loss)
I1107 22:04:44.753408 18604 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1107 22:04:50.365819  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:04:50.596848 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_106000.caffemodel
I1107 22:04:50.610846 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_106000.solverstate
I1107 22:04:50.614848 18604 solver.cpp:330] Iteration 106000, Testing net (#0)
I1107 22:04:50.614848 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:04:51.907938 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:04:51.958938 18604 solver.cpp:397]     Test net output #0: accuracy = 0.674
I1107 22:04:51.958938 18604 solver.cpp:397]     Test net output #1: loss = 1.24836 (* 1 = 1.24836 loss)
I1107 22:04:52.013942 18604 solver.cpp:218] Iteration 106000 (13.774 iter/s, 7.26008s/100 iters), loss = 0.353154
I1107 22:04:52.013942 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:04:52.013942 18604 solver.cpp:237]     Train net output #1: loss = 0.353154 (* 1 = 0.353154 loss)
I1107 22:04:52.013942 18604 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1107 22:04:57.957453 18604 solver.cpp:218] Iteration 106100 (16.8259 iter/s, 5.94323s/100 iters), loss = 0.40523
I1107 22:04:57.957453 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:04:57.957453 18604 solver.cpp:237]     Train net output #1: loss = 0.40523 (* 1 = 0.40523 loss)
I1107 22:04:57.957453 18604 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1107 22:05:03.861901 18604 solver.cpp:218] Iteration 106200 (16.9382 iter/s, 5.9038s/100 iters), loss = 0.269069
I1107 22:05:03.861901 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:05:03.861901 18604 solver.cpp:237]     Train net output #1: loss = 0.269069 (* 1 = 0.269069 loss)
I1107 22:05:03.861901 18604 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1107 22:05:09.881460 18604 solver.cpp:218] Iteration 106300 (16.6151 iter/s, 6.01862s/100 iters), loss = 0.389873
I1107 22:05:09.881460 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:05:09.881460 18604 solver.cpp:237]     Train net output #1: loss = 0.389873 (* 1 = 0.389873 loss)
I1107 22:05:09.881460 18604 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1107 22:05:15.926070 18604 solver.cpp:218] Iteration 106400 (16.5428 iter/s, 6.04493s/100 iters), loss = 0.439984
I1107 22:05:15.927072 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:05:15.927072 18604 solver.cpp:237]     Train net output #1: loss = 0.439984 (* 1 = 0.439984 loss)
I1107 22:05:15.927072 18604 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1107 22:05:21.606618  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:05:21.837630 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_106500.caffemodel
I1107 22:05:21.853631 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_106500.solverstate
I1107 22:05:21.858631 18604 solver.cpp:330] Iteration 106500, Testing net (#0)
I1107 22:05:21.858631 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:05:23.152768 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:05:23.203784 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6718
I1107 22:05:23.203784 18604 solver.cpp:397]     Test net output #1: loss = 1.25132 (* 1 = 1.25132 loss)
I1107 22:05:23.259783 18604 solver.cpp:218] Iteration 106500 (13.6374 iter/s, 7.33277s/100 iters), loss = 0.374889
I1107 22:05:23.259783 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:05:23.259783 18604 solver.cpp:237]     Train net output #1: loss = 0.374889 (* 1 = 0.374889 loss)
I1107 22:05:23.259783 18604 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1107 22:05:29.139866 18604 solver.cpp:218] Iteration 106600 (17.0085 iter/s, 5.8794s/100 iters), loss = 0.496041
I1107 22:05:29.139866 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:05:29.139866 18604 solver.cpp:237]     Train net output #1: loss = 0.496041 (* 1 = 0.496041 loss)
I1107 22:05:29.139866 18604 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1107 22:05:35.020472 18604 solver.cpp:218] Iteration 106700 (17.0063 iter/s, 5.88017s/100 iters), loss = 0.250741
I1107 22:05:35.020472 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:05:35.020472 18604 solver.cpp:237]     Train net output #1: loss = 0.250741 (* 1 = 0.250741 loss)
I1107 22:05:35.020472 18604 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1107 22:05:40.902868 18604 solver.cpp:218] Iteration 106800 (17.0012 iter/s, 5.88193s/100 iters), loss = 0.482648
I1107 22:05:40.902868 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:05:40.902868 18604 solver.cpp:237]     Train net output #1: loss = 0.482648 (* 1 = 0.482648 loss)
I1107 22:05:40.902868 18604 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1107 22:05:46.780289 18604 solver.cpp:218] Iteration 106900 (17.0145 iter/s, 5.87735s/100 iters), loss = 0.443968
I1107 22:05:46.780289 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:05:46.780289 18604 solver.cpp:237]     Train net output #1: loss = 0.443968 (* 1 = 0.443968 loss)
I1107 22:05:46.780289 18604 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1107 22:05:52.361703  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:05:52.591728 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_107000.caffemodel
I1107 22:05:52.606729 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_107000.solverstate
I1107 22:05:52.611728 18604 solver.cpp:330] Iteration 107000, Testing net (#0)
I1107 22:05:52.611728 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:05:53.902828 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:05:53.953836 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6741
I1107 22:05:53.953836 18604 solver.cpp:397]     Test net output #1: loss = 1.23994 (* 1 = 1.23994 loss)
I1107 22:05:54.009835 18604 solver.cpp:218] Iteration 107000 (13.8324 iter/s, 7.22942s/100 iters), loss = 0.475988
I1107 22:05:54.010835 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:05:54.010835 18604 solver.cpp:237]     Train net output #1: loss = 0.475988 (* 1 = 0.475988 loss)
I1107 22:05:54.010835 18604 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1107 22:05:59.897277 18604 solver.cpp:218] Iteration 107100 (16.988 iter/s, 5.8865s/100 iters), loss = 0.374023
I1107 22:05:59.897277 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:05:59.897277 18604 solver.cpp:237]     Train net output #1: loss = 0.374023 (* 1 = 0.374023 loss)
I1107 22:05:59.897277 18604 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1107 22:06:05.824779 18604 solver.cpp:218] Iteration 107200 (16.8708 iter/s, 5.92738s/100 iters), loss = 0.330104
I1107 22:06:05.824779 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:06:05.824779 18604 solver.cpp:237]     Train net output #1: loss = 0.330104 (* 1 = 0.330104 loss)
I1107 22:06:05.824779 18604 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1107 22:06:11.838431 18604 solver.cpp:218] Iteration 107300 (16.6316 iter/s, 6.01265s/100 iters), loss = 0.46232
I1107 22:06:11.838431 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:06:11.838932 18604 solver.cpp:237]     Train net output #1: loss = 0.46232 (* 1 = 0.46232 loss)
I1107 22:06:11.838932 18604 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1107 22:06:17.736892 18604 solver.cpp:218] Iteration 107400 (16.9561 iter/s, 5.89758s/100 iters), loss = 0.487536
I1107 22:06:17.736892 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 22:06:17.736892 18604 solver.cpp:237]     Train net output #1: loss = 0.487536 (* 1 = 0.487536 loss)
I1107 22:06:17.736892 18604 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1107 22:06:23.353294  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:06:23.586308 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_107500.caffemodel
I1107 22:06:23.602308 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_107500.solverstate
I1107 22:06:23.606309 18604 solver.cpp:330] Iteration 107500, Testing net (#0)
I1107 22:06:23.606309 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:06:24.899163 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:06:24.949208 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6753
I1107 22:06:24.949208 18604 solver.cpp:397]     Test net output #1: loss = 1.23448 (* 1 = 1.23448 loss)
I1107 22:06:25.006192 18604 solver.cpp:218] Iteration 107500 (13.7568 iter/s, 7.26911s/100 iters), loss = 0.306687
I1107 22:06:25.006192 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:06:25.006192 18604 solver.cpp:237]     Train net output #1: loss = 0.306686 (* 1 = 0.306686 loss)
I1107 22:06:25.006192 18604 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1107 22:06:30.913625 18604 solver.cpp:218] Iteration 107600 (16.929 iter/s, 5.90701s/100 iters), loss = 0.425185
I1107 22:06:30.913625 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:06:30.913625 18604 solver.cpp:237]     Train net output #1: loss = 0.425185 (* 1 = 0.425185 loss)
I1107 22:06:30.913625 18604 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1107 22:06:36.940153 18604 solver.cpp:218] Iteration 107700 (16.594 iter/s, 6.02626s/100 iters), loss = 0.345325
I1107 22:06:36.940153 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:06:36.940153 18604 solver.cpp:237]     Train net output #1: loss = 0.345325 (* 1 = 0.345325 loss)
I1107 22:06:36.940153 18604 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1107 22:06:43.006079 18604 solver.cpp:218] Iteration 107800 (16.4875 iter/s, 6.06519s/100 iters), loss = 0.431279
I1107 22:06:43.006079 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:06:43.006079 18604 solver.cpp:237]     Train net output #1: loss = 0.431279 (* 1 = 0.431279 loss)
I1107 22:06:43.006079 18604 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1107 22:06:49.014140 18604 solver.cpp:218] Iteration 107900 (16.6463 iter/s, 6.00734s/100 iters), loss = 0.401552
I1107 22:06:49.014140 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:06:49.014140 18604 solver.cpp:237]     Train net output #1: loss = 0.401552 (* 1 = 0.401552 loss)
I1107 22:06:49.014140 18604 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1107 22:06:54.676548  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:06:54.908064 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_108000.caffemodel
I1107 22:06:54.924566 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_108000.solverstate
I1107 22:06:54.928565 18604 solver.cpp:330] Iteration 108000, Testing net (#0)
I1107 22:06:54.928565 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:06:56.235697 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:06:56.288697 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6734
I1107 22:06:56.288697 18604 solver.cpp:397]     Test net output #1: loss = 1.23687 (* 1 = 1.23687 loss)
I1107 22:06:56.347715 18604 solver.cpp:218] Iteration 108000 (13.6361 iter/s, 7.33345s/100 iters), loss = 0.388829
I1107 22:06:56.347715 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:06:56.347715 18604 solver.cpp:237]     Train net output #1: loss = 0.388829 (* 1 = 0.388829 loss)
I1107 22:06:56.347715 18604 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1107 22:07:02.375353 18604 solver.cpp:218] Iteration 108100 (16.5929 iter/s, 6.02667s/100 iters), loss = 0.416414
I1107 22:07:02.375353 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:07:02.375353 18604 solver.cpp:237]     Train net output #1: loss = 0.416414 (* 1 = 0.416414 loss)
I1107 22:07:02.375353 18604 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1107 22:07:08.391912 18604 solver.cpp:218] Iteration 108200 (16.6206 iter/s, 6.01663s/100 iters), loss = 0.300256
I1107 22:07:08.391912 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:07:08.391912 18604 solver.cpp:237]     Train net output #1: loss = 0.300256 (* 1 = 0.300256 loss)
I1107 22:07:08.391912 18604 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1107 22:07:14.353397 18604 solver.cpp:218] Iteration 108300 (16.7761 iter/s, 5.96087s/100 iters), loss = 0.433132
I1107 22:07:14.353397 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:07:14.353397 18604 solver.cpp:237]     Train net output #1: loss = 0.433132 (* 1 = 0.433132 loss)
I1107 22:07:14.353397 18604 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1107 22:07:20.324980 18604 solver.cpp:218] Iteration 108400 (16.7493 iter/s, 5.97041s/100 iters), loss = 0.445462
I1107 22:07:20.324980 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:07:20.324980 18604 solver.cpp:237]     Train net output #1: loss = 0.445462 (* 1 = 0.445462 loss)
I1107 22:07:20.324980 18604 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1107 22:07:25.972471  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:07:26.204514 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_108500.caffemodel
I1107 22:07:26.220518 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_108500.solverstate
I1107 22:07:26.225518 18604 solver.cpp:330] Iteration 108500, Testing net (#0)
I1107 22:07:26.225518 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:07:27.538666 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:07:27.589666 18604 solver.cpp:397]     Test net output #0: accuracy = 0.672
I1107 22:07:27.589666 18604 solver.cpp:397]     Test net output #1: loss = 1.2503 (* 1 = 1.2503 loss)
I1107 22:07:27.647670 18604 solver.cpp:218] Iteration 108500 (13.6571 iter/s, 7.32222s/100 iters), loss = 0.308916
I1107 22:07:27.647670 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:07:27.647670 18604 solver.cpp:237]     Train net output #1: loss = 0.308916 (* 1 = 0.308916 loss)
I1107 22:07:27.647670 18604 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1107 22:07:33.583137 18604 solver.cpp:218] Iteration 108600 (16.8481 iter/s, 5.93538s/100 iters), loss = 0.381589
I1107 22:07:33.583137 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:07:33.583137 18604 solver.cpp:237]     Train net output #1: loss = 0.381589 (* 1 = 0.381589 loss)
I1107 22:07:33.583137 18604 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1107 22:07:39.536617 18604 solver.cpp:218] Iteration 108700 (16.7995 iter/s, 5.95255s/100 iters), loss = 0.339792
I1107 22:07:39.536617 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:07:39.536617 18604 solver.cpp:237]     Train net output #1: loss = 0.339792 (* 1 = 0.339792 loss)
I1107 22:07:39.536617 18604 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1107 22:07:45.450376 18604 solver.cpp:218] Iteration 108800 (16.9105 iter/s, 5.91349s/100 iters), loss = 0.413887
I1107 22:07:45.450376 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:07:45.450376 18604 solver.cpp:237]     Train net output #1: loss = 0.413886 (* 1 = 0.413886 loss)
I1107 22:07:45.450376 18604 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1107 22:07:51.380282 18604 solver.cpp:218] Iteration 108900 (16.8651 iter/s, 5.92939s/100 iters), loss = 0.461494
I1107 22:07:51.380282 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:07:51.380282 18604 solver.cpp:237]     Train net output #1: loss = 0.461494 (* 1 = 0.461494 loss)
I1107 22:07:51.380282 18604 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1107 22:07:56.995976  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:07:57.230991 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_109000.caffemodel
I1107 22:07:57.250998 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_109000.solverstate
I1107 22:07:57.255997 18604 solver.cpp:330] Iteration 109000, Testing net (#0)
I1107 22:07:57.255997 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:07:58.558082 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:07:58.609083 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6741
I1107 22:07:58.609083 18604 solver.cpp:397]     Test net output #1: loss = 1.25513 (* 1 = 1.25513 loss)
I1107 22:07:58.666086 18604 solver.cpp:218] Iteration 109000 (13.7252 iter/s, 7.28588s/100 iters), loss = 0.327096
I1107 22:07:58.666086 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:07:58.666086 18604 solver.cpp:237]     Train net output #1: loss = 0.327096 (* 1 = 0.327096 loss)
I1107 22:07:58.666086 18604 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1107 22:08:04.624783 18604 solver.cpp:218] Iteration 109100 (16.784 iter/s, 5.95805s/100 iters), loss = 0.396685
I1107 22:08:04.624783 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:08:04.624783 18604 solver.cpp:237]     Train net output #1: loss = 0.396685 (* 1 = 0.396685 loss)
I1107 22:08:04.624783 18604 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1107 22:08:10.587164 18604 solver.cpp:218] Iteration 109200 (16.774 iter/s, 5.9616s/100 iters), loss = 0.298535
I1107 22:08:10.587164 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:08:10.587164 18604 solver.cpp:237]     Train net output #1: loss = 0.298535 (* 1 = 0.298535 loss)
I1107 22:08:10.587164 18604 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1107 22:08:16.482538 18604 solver.cpp:218] Iteration 109300 (16.9625 iter/s, 5.89536s/100 iters), loss = 0.394141
I1107 22:08:16.482538 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:08:16.482538 18604 solver.cpp:237]     Train net output #1: loss = 0.394141 (* 1 = 0.394141 loss)
I1107 22:08:16.482538 18604 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1107 22:08:22.395948 18604 solver.cpp:218] Iteration 109400 (16.9135 iter/s, 5.91245s/100 iters), loss = 0.398192
I1107 22:08:22.395948 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:08:22.395948 18604 solver.cpp:237]     Train net output #1: loss = 0.398192 (* 1 = 0.398192 loss)
I1107 22:08:22.395948 18604 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1107 22:08:28.001296  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:08:28.231305 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_109500.caffemodel
I1107 22:08:28.247309 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_109500.solverstate
I1107 22:08:28.251809 18604 solver.cpp:330] Iteration 109500, Testing net (#0)
I1107 22:08:28.251809 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:08:29.547423 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:08:29.598431 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6714
I1107 22:08:29.598431 18604 solver.cpp:397]     Test net output #1: loss = 1.25814 (* 1 = 1.25814 loss)
I1107 22:08:29.655429 18604 solver.cpp:218] Iteration 109500 (13.7763 iter/s, 7.25884s/100 iters), loss = 0.320145
I1107 22:08:29.655429 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:08:29.655429 18604 solver.cpp:237]     Train net output #1: loss = 0.320145 (* 1 = 0.320145 loss)
I1107 22:08:29.655429 18604 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1107 22:08:35.608896 18604 solver.cpp:218] Iteration 109600 (16.7975 iter/s, 5.95327s/100 iters), loss = 0.408149
I1107 22:08:35.608896 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:08:35.608896 18604 solver.cpp:237]     Train net output #1: loss = 0.408149 (* 1 = 0.408149 loss)
I1107 22:08:35.608896 18604 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1107 22:08:41.491264 18604 solver.cpp:218] Iteration 109700 (16.9993 iter/s, 5.8826s/100 iters), loss = 0.298558
I1107 22:08:41.492264 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:08:41.492264 18604 solver.cpp:237]     Train net output #1: loss = 0.298558 (* 1 = 0.298558 loss)
I1107 22:08:41.492264 18604 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1107 22:08:47.494771 18604 solver.cpp:218] Iteration 109800 (16.6604 iter/s, 6.00226s/100 iters), loss = 0.419704
I1107 22:08:47.494771 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:08:47.494771 18604 solver.cpp:237]     Train net output #1: loss = 0.419704 (* 1 = 0.419704 loss)
I1107 22:08:47.494771 18604 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1107 22:08:53.519470 18604 solver.cpp:218] Iteration 109900 (16.5995 iter/s, 6.02429s/100 iters), loss = 0.461096
I1107 22:08:53.519470 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:08:53.519470 18604 solver.cpp:237]     Train net output #1: loss = 0.461096 (* 1 = 0.461096 loss)
I1107 22:08:53.519470 18604 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1107 22:08:59.297996  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:08:59.534021 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_110000.caffemodel
I1107 22:08:59.549026 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_110000.solverstate
I1107 22:08:59.554028 18604 solver.cpp:330] Iteration 110000, Testing net (#0)
I1107 22:08:59.554028 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:09:00.861182 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:09:00.911181 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6724
I1107 22:09:00.911181 18604 solver.cpp:397]     Test net output #1: loss = 1.25446 (* 1 = 1.25446 loss)
I1107 22:09:00.968194 18604 solver.cpp:218] Iteration 110000 (13.4257 iter/s, 7.44842s/100 iters), loss = 0.299077
I1107 22:09:00.968194 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:09:00.968194 18604 solver.cpp:237]     Train net output #1: loss = 0.299077 (* 1 = 0.299077 loss)
I1107 22:09:00.968194 18604 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1107 22:09:06.972630 18604 solver.cpp:218] Iteration 110100 (16.655 iter/s, 6.00419s/100 iters), loss = 0.452587
I1107 22:09:06.972630 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:09:06.972630 18604 solver.cpp:237]     Train net output #1: loss = 0.452587 (* 1 = 0.452587 loss)
I1107 22:09:06.972630 18604 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1107 22:09:12.978924 18604 solver.cpp:218] Iteration 110200 (16.6517 iter/s, 6.00538s/100 iters), loss = 0.334192
I1107 22:09:12.978924 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:09:12.978924 18604 solver.cpp:237]     Train net output #1: loss = 0.334192 (* 1 = 0.334192 loss)
I1107 22:09:12.978924 18604 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1107 22:09:19.065492 18604 solver.cpp:218] Iteration 110300 (16.432 iter/s, 6.08569s/100 iters), loss = 0.418694
I1107 22:09:19.065492 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:09:19.065492 18604 solver.cpp:237]     Train net output #1: loss = 0.418694 (* 1 = 0.418694 loss)
I1107 22:09:19.065492 18604 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1107 22:09:25.074740 18604 solver.cpp:218] Iteration 110400 (16.6409 iter/s, 6.0093s/100 iters), loss = 0.453278
I1107 22:09:25.074740 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:09:25.074740 18604 solver.cpp:237]     Train net output #1: loss = 0.453278 (* 1 = 0.453278 loss)
I1107 22:09:25.074740 18604 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1107 22:09:30.807703  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:09:31.041718 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_110500.caffemodel
I1107 22:09:31.056722 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_110500.solverstate
I1107 22:09:31.061722 18604 solver.cpp:330] Iteration 110500, Testing net (#0)
I1107 22:09:31.061722 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:09:32.353835 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:09:32.404830 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6758
I1107 22:09:32.404830 18604 solver.cpp:397]     Test net output #1: loss = 1.26262 (* 1 = 1.26262 loss)
I1107 22:09:32.461834 18604 solver.cpp:218] Iteration 110500 (13.5377 iter/s, 7.38678s/100 iters), loss = 0.351884
I1107 22:09:32.461834 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:09:32.461834 18604 solver.cpp:237]     Train net output #1: loss = 0.351884 (* 1 = 0.351884 loss)
I1107 22:09:32.461834 18604 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1107 22:09:38.365231 18604 solver.cpp:218] Iteration 110600 (16.9417 iter/s, 5.90261s/100 iters), loss = 0.336684
I1107 22:09:38.365231 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:09:38.365231 18604 solver.cpp:237]     Train net output #1: loss = 0.336684 (* 1 = 0.336684 loss)
I1107 22:09:38.365231 18604 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1107 22:09:44.265678 18604 solver.cpp:218] Iteration 110700 (16.9499 iter/s, 5.89974s/100 iters), loss = 0.302056
I1107 22:09:44.265678 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:09:44.265678 18604 solver.cpp:237]     Train net output #1: loss = 0.302055 (* 1 = 0.302055 loss)
I1107 22:09:44.265678 18604 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1107 22:09:50.155032 18604 solver.cpp:218] Iteration 110800 (16.9788 iter/s, 5.88969s/100 iters), loss = 0.399851
I1107 22:09:50.155032 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:09:50.155032 18604 solver.cpp:237]     Train net output #1: loss = 0.399851 (* 1 = 0.399851 loss)
I1107 22:09:50.155032 18604 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1107 22:09:56.056475 18604 solver.cpp:218] Iteration 110900 (16.9479 iter/s, 5.90043s/100 iters), loss = 0.490995
I1107 22:09:56.056475 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1107 22:09:56.056475 18604 solver.cpp:237]     Train net output #1: loss = 0.490995 (* 1 = 0.490995 loss)
I1107 22:09:56.056475 18604 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1107 22:10:01.711082  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:10:01.942596 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_111000.caffemodel
I1107 22:10:01.958103 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_111000.solverstate
I1107 22:10:01.962105 18604 solver.cpp:330] Iteration 111000, Testing net (#0)
I1107 22:10:01.962105 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:10:03.257249 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:10:03.309248 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6712
I1107 22:10:03.309248 18604 solver.cpp:397]     Test net output #1: loss = 1.26507 (* 1 = 1.26507 loss)
I1107 22:10:03.366252 18604 solver.cpp:218] Iteration 111000 (13.681 iter/s, 7.30942s/100 iters), loss = 0.289806
I1107 22:10:03.366252 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:10:03.366252 18604 solver.cpp:237]     Train net output #1: loss = 0.289806 (* 1 = 0.289806 loss)
I1107 22:10:03.366252 18604 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1107 22:10:09.282683 18604 solver.cpp:218] Iteration 111100 (16.9023 iter/s, 5.91635s/100 iters), loss = 0.390615
I1107 22:10:09.282683 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:10:09.282683 18604 solver.cpp:237]     Train net output #1: loss = 0.390615 (* 1 = 0.390615 loss)
I1107 22:10:09.282683 18604 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1107 22:10:15.205145 18604 solver.cpp:218] Iteration 111200 (16.888 iter/s, 5.92138s/100 iters), loss = 0.317016
I1107 22:10:15.205145 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:10:15.205145 18604 solver.cpp:237]     Train net output #1: loss = 0.317016 (* 1 = 0.317016 loss)
I1107 22:10:15.205145 18604 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1107 22:10:21.240831 18604 solver.cpp:218] Iteration 111300 (16.5693 iter/s, 6.03527s/100 iters), loss = 0.334611
I1107 22:10:21.240831 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:10:21.240831 18604 solver.cpp:237]     Train net output #1: loss = 0.334611 (* 1 = 0.334611 loss)
I1107 22:10:21.240831 18604 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1107 22:10:27.254361 18604 solver.cpp:218] Iteration 111400 (16.6294 iter/s, 6.01345s/100 iters), loss = 0.426377
I1107 22:10:27.254361 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:10:27.254361 18604 solver.cpp:237]     Train net output #1: loss = 0.426377 (* 1 = 0.426377 loss)
I1107 22:10:27.254361 18604 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1107 22:10:32.932981  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:10:33.164567 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_111500.caffemodel
I1107 22:10:33.179567 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_111500.solverstate
I1107 22:10:33.184568 18604 solver.cpp:330] Iteration 111500, Testing net (#0)
I1107 22:10:33.184568 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:10:34.486412 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:10:34.537418 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6728
I1107 22:10:34.537418 18604 solver.cpp:397]     Test net output #1: loss = 1.25969 (* 1 = 1.25969 loss)
I1107 22:10:34.593924 18604 solver.cpp:218] Iteration 111500 (13.6261 iter/s, 7.33888s/100 iters), loss = 0.313789
I1107 22:10:34.593924 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:10:34.593924 18604 solver.cpp:237]     Train net output #1: loss = 0.313789 (* 1 = 0.313789 loss)
I1107 22:10:34.593924 18604 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1107 22:10:40.578349 18604 solver.cpp:218] Iteration 111600 (16.711 iter/s, 5.98407s/100 iters), loss = 0.353881
I1107 22:10:40.578349 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:10:40.578349 18604 solver.cpp:237]     Train net output #1: loss = 0.353881 (* 1 = 0.353881 loss)
I1107 22:10:40.578349 18604 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1107 22:10:46.610877 18604 solver.cpp:218] Iteration 111700 (16.5782 iter/s, 6.03203s/100 iters), loss = 0.293533
I1107 22:10:46.610877 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:10:46.610877 18604 solver.cpp:237]     Train net output #1: loss = 0.293533 (* 1 = 0.293533 loss)
I1107 22:10:46.610877 18604 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1107 22:10:52.511332 18604 solver.cpp:218] Iteration 111800 (16.9502 iter/s, 5.89963s/100 iters), loss = 0.369502
I1107 22:10:52.511332 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:10:52.511332 18604 solver.cpp:237]     Train net output #1: loss = 0.369502 (* 1 = 0.369502 loss)
I1107 22:10:52.511332 18604 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1107 22:10:58.394732 18604 solver.cpp:218] Iteration 111900 (16.998 iter/s, 5.88304s/100 iters), loss = 0.496328
I1107 22:10:58.394732 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1107 22:10:58.394732 18604 solver.cpp:237]     Train net output #1: loss = 0.496328 (* 1 = 0.496328 loss)
I1107 22:10:58.394732 18604 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1107 22:11:04.010144  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:11:04.243170 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_112000.caffemodel
I1107 22:11:04.259169 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_112000.solverstate
I1107 22:11:04.264170 18604 solver.cpp:330] Iteration 112000, Testing net (#0)
I1107 22:11:04.264170 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:11:05.578405 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:11:05.629412 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6719
I1107 22:11:05.629412 18604 solver.cpp:397]     Test net output #1: loss = 1.26651 (* 1 = 1.26651 loss)
I1107 22:11:05.686411 18604 solver.cpp:218] Iteration 112000 (13.7149 iter/s, 7.29132s/100 iters), loss = 0.327119
I1107 22:11:05.686411 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:11:05.686411 18604 solver.cpp:237]     Train net output #1: loss = 0.327119 (* 1 = 0.327119 loss)
I1107 22:11:05.686411 18604 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1107 22:11:11.683796 18604 solver.cpp:218] Iteration 112100 (16.674 iter/s, 5.99735s/100 iters), loss = 0.35036
I1107 22:11:11.683796 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:11:11.683796 18604 solver.cpp:237]     Train net output #1: loss = 0.35036 (* 1 = 0.35036 loss)
I1107 22:11:11.683796 18604 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1107 22:11:17.756327 18604 solver.cpp:218] Iteration 112200 (16.4686 iter/s, 6.07218s/100 iters), loss = 0.324579
I1107 22:11:17.756327 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:11:17.756327 18604 solver.cpp:237]     Train net output #1: loss = 0.324579 (* 1 = 0.324579 loss)
I1107 22:11:17.756327 18604 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1107 22:11:23.743787 18604 solver.cpp:218] Iteration 112300 (16.7038 iter/s, 5.98667s/100 iters), loss = 0.452095
I1107 22:11:23.743787 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:11:23.743787 18604 solver.cpp:237]     Train net output #1: loss = 0.452095 (* 1 = 0.452095 loss)
I1107 22:11:23.743787 18604 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1107 22:11:29.727008 18604 solver.cpp:218] Iteration 112400 (16.714 iter/s, 5.983s/100 iters), loss = 0.476283
I1107 22:11:29.727008 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1107 22:11:29.727008 18604 solver.cpp:237]     Train net output #1: loss = 0.476283 (* 1 = 0.476283 loss)
I1107 22:11:29.727008 18604 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1107 22:11:35.410574  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:11:35.642580 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_112500.caffemodel
I1107 22:11:35.658581 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_112500.solverstate
I1107 22:11:35.663081 18604 solver.cpp:330] Iteration 112500, Testing net (#0)
I1107 22:11:35.663581 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:11:36.964162 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:11:37.015172 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6731
I1107 22:11:37.015172 18604 solver.cpp:397]     Test net output #1: loss = 1.27071 (* 1 = 1.27071 loss)
I1107 22:11:37.072181 18604 solver.cpp:218] Iteration 112500 (13.6161 iter/s, 7.34426s/100 iters), loss = 0.339279
I1107 22:11:37.072181 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:11:37.072181 18604 solver.cpp:237]     Train net output #1: loss = 0.339279 (* 1 = 0.339279 loss)
I1107 22:11:37.072181 18604 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1107 22:11:43.056711 18604 solver.cpp:218] Iteration 112600 (16.7098 iter/s, 5.98451s/100 iters), loss = 0.395511
I1107 22:11:43.056711 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:11:43.056711 18604 solver.cpp:237]     Train net output #1: loss = 0.395511 (* 1 = 0.395511 loss)
I1107 22:11:43.056711 18604 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1107 22:11:48.942109 18604 solver.cpp:218] Iteration 112700 (16.9916 iter/s, 5.88526s/100 iters), loss = 0.291772
I1107 22:11:48.943110 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:11:48.943110 18604 solver.cpp:237]     Train net output #1: loss = 0.291772 (* 1 = 0.291772 loss)
I1107 22:11:48.943110 18604 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1107 22:11:54.871541 18604 solver.cpp:218] Iteration 112800 (16.868 iter/s, 5.92837s/100 iters), loss = 0.404471
I1107 22:11:54.871541 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:11:54.871541 18604 solver.cpp:237]     Train net output #1: loss = 0.404471 (* 1 = 0.404471 loss)
I1107 22:11:54.871541 18604 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1107 22:12:00.771961 18604 solver.cpp:218] Iteration 112900 (16.9482 iter/s, 5.90034s/100 iters), loss = 0.469608
I1107 22:12:00.771961 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:12:00.771961 18604 solver.cpp:237]     Train net output #1: loss = 0.469608 (* 1 = 0.469608 loss)
I1107 22:12:00.771961 18604 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1107 22:12:06.457816  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:12:06.693099 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_113000.caffemodel
I1107 22:12:06.709095 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_113000.solverstate
I1107 22:12:06.714098 18604 solver.cpp:330] Iteration 113000, Testing net (#0)
I1107 22:12:06.714098 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:12:08.024919 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:12:08.076453 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6739
I1107 22:12:08.076453 18604 solver.cpp:397]     Test net output #1: loss = 1.2547 (* 1 = 1.2547 loss)
I1107 22:12:08.132455 18604 solver.cpp:218] Iteration 113000 (13.5862 iter/s, 7.3604s/100 iters), loss = 0.310005
I1107 22:12:08.133455 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:12:08.133455 18604 solver.cpp:237]     Train net output #1: loss = 0.310005 (* 1 = 0.310005 loss)
I1107 22:12:08.133455 18604 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1107 22:12:14.173298 18604 solver.cpp:218] Iteration 113100 (16.5575 iter/s, 6.03957s/100 iters), loss = 0.414977
I1107 22:12:14.173298 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:12:14.173298 18604 solver.cpp:237]     Train net output #1: loss = 0.414977 (* 1 = 0.414977 loss)
I1107 22:12:14.173298 18604 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1107 22:12:20.171525 18604 solver.cpp:218] Iteration 113200 (16.6708 iter/s, 5.99853s/100 iters), loss = 0.266323
I1107 22:12:20.171525 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:12:20.171525 18604 solver.cpp:237]     Train net output #1: loss = 0.266323 (* 1 = 0.266323 loss)
I1107 22:12:20.171525 18604 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1107 22:12:26.175544 18604 solver.cpp:218] Iteration 113300 (16.6592 iter/s, 6.00268s/100 iters), loss = 0.458214
I1107 22:12:26.175544 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:12:26.175544 18604 solver.cpp:237]     Train net output #1: loss = 0.458214 (* 1 = 0.458214 loss)
I1107 22:12:26.175544 18604 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1107 22:12:32.234827 18604 solver.cpp:218] Iteration 113400 (16.5032 iter/s, 6.05943s/100 iters), loss = 0.400858
I1107 22:12:32.234827 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:12:32.234827 18604 solver.cpp:237]     Train net output #1: loss = 0.400858 (* 1 = 0.400858 loss)
I1107 22:12:32.234827 18604 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1107 22:12:37.965672  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:12:38.196682 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_113500.caffemodel
I1107 22:12:38.215688 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_113500.solverstate
I1107 22:12:38.220695 18604 solver.cpp:330] Iteration 113500, Testing net (#0)
I1107 22:12:38.220695 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:12:39.514345 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:12:39.564847 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6736
I1107 22:12:39.564847 18604 solver.cpp:397]     Test net output #1: loss = 1.26826 (* 1 = 1.26826 loss)
I1107 22:12:39.621852 18604 solver.cpp:218] Iteration 113500 (13.5395 iter/s, 7.38581s/100 iters), loss = 0.278898
I1107 22:12:39.621852 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:12:39.621852 18604 solver.cpp:237]     Train net output #1: loss = 0.278898 (* 1 = 0.278898 loss)
I1107 22:12:39.621852 18604 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1107 22:12:45.507325 18604 solver.cpp:218] Iteration 113600 (16.9918 iter/s, 5.8852s/100 iters), loss = 0.409667
I1107 22:12:45.507325 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:12:45.507325 18604 solver.cpp:237]     Train net output #1: loss = 0.409667 (* 1 = 0.409667 loss)
I1107 22:12:45.507325 18604 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1107 22:12:51.450222 18604 solver.cpp:218] Iteration 113700 (16.8265 iter/s, 5.94302s/100 iters), loss = 0.297437
I1107 22:12:51.450222 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:12:51.450222 18604 solver.cpp:237]     Train net output #1: loss = 0.297437 (* 1 = 0.297437 loss)
I1107 22:12:51.450222 18604 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1107 22:12:57.350869 18604 solver.cpp:218] Iteration 113800 (16.9498 iter/s, 5.89977s/100 iters), loss = 0.308915
I1107 22:12:57.350869 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:12:57.350869 18604 solver.cpp:237]     Train net output #1: loss = 0.308915 (* 1 = 0.308915 loss)
I1107 22:12:57.350869 18604 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1107 22:13:03.244371 18604 solver.cpp:218] Iteration 113900 (16.9687 iter/s, 5.8932s/100 iters), loss = 0.388508
I1107 22:13:03.244371 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:13:03.244371 18604 solver.cpp:237]     Train net output #1: loss = 0.388508 (* 1 = 0.388508 loss)
I1107 22:13:03.244371 18604 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1107 22:13:08.847113  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:13:09.081198 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_114000.caffemodel
I1107 22:13:09.096179 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_114000.solverstate
I1107 22:13:09.101194 18604 solver.cpp:330] Iteration 114000, Testing net (#0)
I1107 22:13:09.101194 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:13:10.396724 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:13:10.447751 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6699
I1107 22:13:10.447751 18604 solver.cpp:397]     Test net output #1: loss = 1.28152 (* 1 = 1.28152 loss)
I1107 22:13:10.503764 18604 solver.cpp:218] Iteration 114000 (13.7754 iter/s, 7.2593s/100 iters), loss = 0.325418
I1107 22:13:10.503764 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:13:10.503764 18604 solver.cpp:237]     Train net output #1: loss = 0.325418 (* 1 = 0.325418 loss)
I1107 22:13:10.503764 18604 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1107 22:13:16.419085 18604 solver.cpp:218] Iteration 114100 (16.9077 iter/s, 5.91448s/100 iters), loss = 0.322125
I1107 22:13:16.419085 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:13:16.419085 18604 solver.cpp:237]     Train net output #1: loss = 0.322125 (* 1 = 0.322125 loss)
I1107 22:13:16.419085 18604 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1107 22:13:22.323501 18604 solver.cpp:218] Iteration 114200 (16.9382 iter/s, 5.90381s/100 iters), loss = 0.316261
I1107 22:13:22.323501 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:13:22.323501 18604 solver.cpp:237]     Train net output #1: loss = 0.316261 (* 1 = 0.316261 loss)
I1107 22:13:22.323501 18604 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1107 22:13:28.226456 18604 solver.cpp:218] Iteration 114300 (16.9405 iter/s, 5.90301s/100 iters), loss = 0.403589
I1107 22:13:28.226456 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:13:28.226456 18604 solver.cpp:237]     Train net output #1: loss = 0.403589 (* 1 = 0.403589 loss)
I1107 22:13:28.226456 18604 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1107 22:13:34.121865 18604 solver.cpp:218] Iteration 114400 (16.9638 iter/s, 5.89492s/100 iters), loss = 0.399679
I1107 22:13:34.121865 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:13:34.121865 18604 solver.cpp:237]     Train net output #1: loss = 0.399679 (* 1 = 0.399679 loss)
I1107 22:13:34.121865 18604 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1107 22:13:39.716233  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:13:39.947249 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_114500.caffemodel
I1107 22:13:39.963249 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_114500.solverstate
I1107 22:13:39.968250 18604 solver.cpp:330] Iteration 114500, Testing net (#0)
I1107 22:13:39.968250 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:13:41.263342 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:13:41.314342 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6732
I1107 22:13:41.314342 18604 solver.cpp:397]     Test net output #1: loss = 1.27407 (* 1 = 1.27407 loss)
I1107 22:13:41.371347 18604 solver.cpp:218] Iteration 114500 (13.7952 iter/s, 7.24892s/100 iters), loss = 0.33661
I1107 22:13:41.371347 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:13:41.371347 18604 solver.cpp:237]     Train net output #1: loss = 0.33661 (* 1 = 0.33661 loss)
I1107 22:13:41.371347 18604 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1107 22:13:47.262766 18604 solver.cpp:218] Iteration 114600 (16.9765 iter/s, 5.89049s/100 iters), loss = 0.417014
I1107 22:13:47.262766 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:13:47.262766 18604 solver.cpp:237]     Train net output #1: loss = 0.417014 (* 1 = 0.417014 loss)
I1107 22:13:47.262766 18604 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1107 22:13:53.152220 18604 solver.cpp:218] Iteration 114700 (16.9799 iter/s, 5.8893s/100 iters), loss = 0.258533
I1107 22:13:53.152220 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:13:53.152220 18604 solver.cpp:237]     Train net output #1: loss = 0.258533 (* 1 = 0.258533 loss)
I1107 22:13:53.152220 18604 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1107 22:13:59.061722 18604 solver.cpp:218] Iteration 114800 (16.9236 iter/s, 5.90891s/100 iters), loss = 0.374056
I1107 22:13:59.061722 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:13:59.061722 18604 solver.cpp:237]     Train net output #1: loss = 0.374055 (* 1 = 0.374055 loss)
I1107 22:13:59.061722 18604 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1107 22:14:04.955220 18604 solver.cpp:218] Iteration 114900 (16.9689 iter/s, 5.89314s/100 iters), loss = 0.401287
I1107 22:14:04.955220 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:14:04.955220 18604 solver.cpp:237]     Train net output #1: loss = 0.401287 (* 1 = 0.401287 loss)
I1107 22:14:04.955220 18604 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1107 22:14:10.561681  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:14:10.794710 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_115000.caffemodel
I1107 22:14:10.808706 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_115000.solverstate
I1107 22:14:10.814705 18604 solver.cpp:330] Iteration 115000, Testing net (#0)
I1107 22:14:10.814705 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:14:12.108791 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:14:12.160799 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6709
I1107 22:14:12.160799 18604 solver.cpp:397]     Test net output #1: loss = 1.27096 (* 1 = 1.27096 loss)
I1107 22:14:12.217798 18604 solver.cpp:218] Iteration 115000 (13.7705 iter/s, 7.26192s/100 iters), loss = 0.294959
I1107 22:14:12.217798 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:14:12.217798 18604 solver.cpp:237]     Train net output #1: loss = 0.294959 (* 1 = 0.294959 loss)
I1107 22:14:12.217798 18604 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1107 22:14:18.136693 18604 solver.cpp:218] Iteration 115100 (16.8958 iter/s, 5.91863s/100 iters), loss = 0.355035
I1107 22:14:18.136693 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:14:18.136693 18604 solver.cpp:237]     Train net output #1: loss = 0.355035 (* 1 = 0.355035 loss)
I1107 22:14:18.136693 18604 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1107 22:14:24.050565 18604 solver.cpp:218] Iteration 115200 (16.9109 iter/s, 5.91334s/100 iters), loss = 0.214362
I1107 22:14:24.050565 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1107 22:14:24.050565 18604 solver.cpp:237]     Train net output #1: loss = 0.214362 (* 1 = 0.214362 loss)
I1107 22:14:24.050565 18604 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1107 22:14:29.998991 18604 solver.cpp:218] Iteration 115300 (16.8126 iter/s, 5.94794s/100 iters), loss = 0.43083
I1107 22:14:29.998991 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:14:29.998991 18604 solver.cpp:237]     Train net output #1: loss = 0.43083 (* 1 = 0.43083 loss)
I1107 22:14:29.998991 18604 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1107 22:14:35.906419 18604 solver.cpp:218] Iteration 115400 (16.9288 iter/s, 5.90708s/100 iters), loss = 0.346877
I1107 22:14:35.906419 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:14:35.906419 18604 solver.cpp:237]     Train net output #1: loss = 0.346877 (* 1 = 0.346877 loss)
I1107 22:14:35.906419 18604 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1107 22:14:41.494807  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:14:41.726821 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_115500.caffemodel
I1107 22:14:41.743324 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_115500.solverstate
I1107 22:14:41.748325 18604 solver.cpp:330] Iteration 115500, Testing net (#0)
I1107 22:14:41.748325 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:14:43.044409 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:14:43.095912 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6716
I1107 22:14:43.095912 18604 solver.cpp:397]     Test net output #1: loss = 1.27779 (* 1 = 1.27779 loss)
I1107 22:14:43.151917 18604 solver.cpp:218] Iteration 115500 (13.8017 iter/s, 7.2455s/100 iters), loss = 0.346436
I1107 22:14:43.151917 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:14:43.151917 18604 solver.cpp:237]     Train net output #1: loss = 0.346436 (* 1 = 0.346436 loss)
I1107 22:14:43.151917 18604 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1107 22:14:49.030293 18604 solver.cpp:218] Iteration 115600 (17.0128 iter/s, 5.87794s/100 iters), loss = 0.359537
I1107 22:14:49.030293 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:14:49.030293 18604 solver.cpp:237]     Train net output #1: loss = 0.359537 (* 1 = 0.359537 loss)
I1107 22:14:49.030293 18604 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1107 22:14:54.915697 18604 solver.cpp:218] Iteration 115700 (16.9937 iter/s, 5.88454s/100 iters), loss = 0.253874
I1107 22:14:54.915697 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:14:54.915697 18604 solver.cpp:237]     Train net output #1: loss = 0.253874 (* 1 = 0.253874 loss)
I1107 22:14:54.915697 18604 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1107 22:15:00.795168 18604 solver.cpp:218] Iteration 115800 (17.0088 iter/s, 5.87931s/100 iters), loss = 0.344758
I1107 22:15:00.795168 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:15:00.795168 18604 solver.cpp:237]     Train net output #1: loss = 0.344758 (* 1 = 0.344758 loss)
I1107 22:15:00.795168 18604 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1107 22:15:06.701791 18604 solver.cpp:218] Iteration 115900 (16.9328 iter/s, 5.9057s/100 iters), loss = 0.411484
I1107 22:15:06.701791 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:15:06.701791 18604 solver.cpp:237]     Train net output #1: loss = 0.411484 (* 1 = 0.411484 loss)
I1107 22:15:06.701791 18604 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1107 22:15:12.312228  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:15:12.543738 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_116000.caffemodel
I1107 22:15:12.559244 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_116000.solverstate
I1107 22:15:12.564244 18604 solver.cpp:330] Iteration 116000, Testing net (#0)
I1107 22:15:12.564244 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:15:13.861353 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:15:13.911355 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6745
I1107 22:15:13.912354 18604 solver.cpp:397]     Test net output #1: loss = 1.2768 (* 1 = 1.2768 loss)
I1107 22:15:13.968361 18604 solver.cpp:218] Iteration 116000 (13.7617 iter/s, 7.26652s/100 iters), loss = 0.431776
I1107 22:15:13.968361 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:15:13.968361 18604 solver.cpp:237]     Train net output #1: loss = 0.431776 (* 1 = 0.431776 loss)
I1107 22:15:13.968361 18604 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1107 22:15:19.869802 18604 solver.cpp:218] Iteration 116100 (16.9463 iter/s, 5.90098s/100 iters), loss = 0.374129
I1107 22:15:19.869802 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:15:19.869802 18604 solver.cpp:237]     Train net output #1: loss = 0.374129 (* 1 = 0.374129 loss)
I1107 22:15:19.869802 18604 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1107 22:15:25.772280 18604 solver.cpp:218] Iteration 116200 (16.9434 iter/s, 5.902s/100 iters), loss = 0.31945
I1107 22:15:25.772280 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:15:25.772280 18604 solver.cpp:237]     Train net output #1: loss = 0.31945 (* 1 = 0.31945 loss)
I1107 22:15:25.772280 18604 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1107 22:15:31.669986 18604 solver.cpp:218] Iteration 116300 (16.9574 iter/s, 5.89713s/100 iters), loss = 0.411872
I1107 22:15:31.669986 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:15:31.669986 18604 solver.cpp:237]     Train net output #1: loss = 0.411872 (* 1 = 0.411872 loss)
I1107 22:15:31.669986 18604 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1107 22:15:37.589929 18604 solver.cpp:218] Iteration 116400 (16.8937 iter/s, 5.91938s/100 iters), loss = 0.367315
I1107 22:15:37.589929 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:15:37.589929 18604 solver.cpp:237]     Train net output #1: loss = 0.367315 (* 1 = 0.367315 loss)
I1107 22:15:37.589929 18604 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1107 22:15:43.191385  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:15:43.424906 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_116500.caffemodel
I1107 22:15:43.441905 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_116500.solverstate
I1107 22:15:43.445904 18604 solver.cpp:330] Iteration 116500, Testing net (#0)
I1107 22:15:43.445904 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:15:44.746007 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:15:44.797510 18604 solver.cpp:397]     Test net output #0: accuracy = 0.672
I1107 22:15:44.797510 18604 solver.cpp:397]     Test net output #1: loss = 1.28162 (* 1 = 1.28162 loss)
I1107 22:15:44.855013 18604 solver.cpp:218] Iteration 116500 (13.7652 iter/s, 7.26471s/100 iters), loss = 0.293621
I1107 22:15:44.855013 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:15:44.855013 18604 solver.cpp:237]     Train net output #1: loss = 0.293621 (* 1 = 0.293621 loss)
I1107 22:15:44.855013 18604 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1107 22:15:50.761484 18604 solver.cpp:218] Iteration 116600 (16.9328 iter/s, 5.90569s/100 iters), loss = 0.450557
I1107 22:15:50.761484 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:15:50.761484 18604 solver.cpp:237]     Train net output #1: loss = 0.450557 (* 1 = 0.450557 loss)
I1107 22:15:50.761484 18604 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1107 22:15:56.646908 18604 solver.cpp:218] Iteration 116700 (16.9924 iter/s, 5.88497s/100 iters), loss = 0.236208
I1107 22:15:56.646908 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:15:56.646908 18604 solver.cpp:237]     Train net output #1: loss = 0.236208 (* 1 = 0.236208 loss)
I1107 22:15:56.646908 18604 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1107 22:16:02.535866 18604 solver.cpp:218] Iteration 116800 (16.9822 iter/s, 5.88852s/100 iters), loss = 0.3901
I1107 22:16:02.535866 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:16:02.535866 18604 solver.cpp:237]     Train net output #1: loss = 0.3901 (* 1 = 0.3901 loss)
I1107 22:16:02.535866 18604 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1107 22:16:08.422821 18604 solver.cpp:218] Iteration 116900 (16.9875 iter/s, 5.88668s/100 iters), loss = 0.344886
I1107 22:16:08.422821 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:16:08.423321 18604 solver.cpp:237]     Train net output #1: loss = 0.344886 (* 1 = 0.344886 loss)
I1107 22:16:08.423321 18604 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1107 22:16:14.081248  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:16:14.316282 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_117000.caffemodel
I1107 22:16:14.333781 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_117000.solverstate
I1107 22:16:14.338285 18604 solver.cpp:330] Iteration 117000, Testing net (#0)
I1107 22:16:14.338285 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:16:15.636888 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:16:15.687386 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6709
I1107 22:16:15.688388 18604 solver.cpp:397]     Test net output #1: loss = 1.28455 (* 1 = 1.28455 loss)
I1107 22:16:15.745393 18604 solver.cpp:218] Iteration 117000 (13.6571 iter/s, 7.32222s/100 iters), loss = 0.361169
I1107 22:16:15.745393 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:16:15.745393 18604 solver.cpp:237]     Train net output #1: loss = 0.361169 (* 1 = 0.361169 loss)
I1107 22:16:15.745393 18604 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1107 22:16:21.678866 18604 solver.cpp:218] Iteration 117100 (16.8539 iter/s, 5.93335s/100 iters), loss = 0.305739
I1107 22:16:21.678866 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:16:21.678866 18604 solver.cpp:237]     Train net output #1: loss = 0.305739 (* 1 = 0.305739 loss)
I1107 22:16:21.678866 18604 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1107 22:16:27.586314 18604 solver.cpp:218] Iteration 117200 (16.9305 iter/s, 5.90652s/100 iters), loss = 0.330738
I1107 22:16:27.586314 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:16:27.586314 18604 solver.cpp:237]     Train net output #1: loss = 0.330738 (* 1 = 0.330738 loss)
I1107 22:16:27.586314 18604 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1107 22:16:33.485620 18604 solver.cpp:218] Iteration 117300 (16.9525 iter/s, 5.89882s/100 iters), loss = 0.421258
I1107 22:16:33.485620 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:16:33.485620 18604 solver.cpp:237]     Train net output #1: loss = 0.421258 (* 1 = 0.421258 loss)
I1107 22:16:33.485620 18604 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1107 22:16:39.388078 18604 solver.cpp:218] Iteration 117400 (16.9429 iter/s, 5.90218s/100 iters), loss = 0.479506
I1107 22:16:39.388078 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:16:39.388078 18604 solver.cpp:237]     Train net output #1: loss = 0.479506 (* 1 = 0.479506 loss)
I1107 22:16:39.388078 18604 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1107 22:16:45.009528  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:16:45.240542 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_117500.caffemodel
I1107 22:16:45.255542 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_117500.solverstate
I1107 22:16:45.260543 18604 solver.cpp:330] Iteration 117500, Testing net (#0)
I1107 22:16:45.260543 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:16:46.561661 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:16:46.613162 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6697
I1107 22:16:46.613162 18604 solver.cpp:397]     Test net output #1: loss = 1.29428 (* 1 = 1.29428 loss)
I1107 22:16:46.670663 18604 solver.cpp:218] Iteration 117500 (13.7329 iter/s, 7.28178s/100 iters), loss = 0.255464
I1107 22:16:46.670663 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:16:46.670663 18604 solver.cpp:237]     Train net output #1: loss = 0.255464 (* 1 = 0.255464 loss)
I1107 22:16:46.670663 18604 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1107 22:16:52.647011 18604 solver.cpp:218] Iteration 117600 (16.7339 iter/s, 5.97591s/100 iters), loss = 0.381875
I1107 22:16:52.647011 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:16:52.647011 18604 solver.cpp:237]     Train net output #1: loss = 0.381875 (* 1 = 0.381875 loss)
I1107 22:16:52.647011 18604 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1107 22:16:58.571466 18604 solver.cpp:218] Iteration 117700 (16.8788 iter/s, 5.92459s/100 iters), loss = 0.270755
I1107 22:16:58.571466 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:16:58.571466 18604 solver.cpp:237]     Train net output #1: loss = 0.270755 (* 1 = 0.270755 loss)
I1107 22:16:58.571466 18604 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1107 22:17:04.498414 18604 solver.cpp:218] Iteration 117800 (16.8748 iter/s, 5.92599s/100 iters), loss = 0.350157
I1107 22:17:04.498414 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:17:04.498414 18604 solver.cpp:237]     Train net output #1: loss = 0.350157 (* 1 = 0.350157 loss)
I1107 22:17:04.498414 18604 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1107 22:17:10.387769 18604 solver.cpp:218] Iteration 117900 (16.9793 iter/s, 5.88952s/100 iters), loss = 0.431024
I1107 22:17:10.387769 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:17:10.387769 18604 solver.cpp:237]     Train net output #1: loss = 0.431024 (* 1 = 0.431024 loss)
I1107 22:17:10.387769 18604 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1107 22:17:15.996224  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:17:16.227242 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_118000.caffemodel
I1107 22:17:16.242242 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_118000.solverstate
I1107 22:17:16.246243 18604 solver.cpp:330] Iteration 118000, Testing net (#0)
I1107 22:17:16.246243 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:17:17.543392 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:17:17.595129 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6733
I1107 22:17:17.595129 18604 solver.cpp:397]     Test net output #1: loss = 1.2868 (* 1 = 1.2868 loss)
I1107 22:17:17.651129 18604 solver.cpp:218] Iteration 118000 (13.7693 iter/s, 7.26255s/100 iters), loss = 0.263802
I1107 22:17:17.651129 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:17:17.651129 18604 solver.cpp:237]     Train net output #1: loss = 0.263801 (* 1 = 0.263801 loss)
I1107 22:17:17.651129 18604 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1107 22:17:23.524001 18604 solver.cpp:218] Iteration 118100 (17.029 iter/s, 5.87234s/100 iters), loss = 0.377687
I1107 22:17:23.524001 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:17:23.524001 18604 solver.cpp:237]     Train net output #1: loss = 0.377687 (* 1 = 0.377687 loss)
I1107 22:17:23.524001 18604 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1107 22:17:29.413416 18604 solver.cpp:218] Iteration 118200 (16.9815 iter/s, 5.88875s/100 iters), loss = 0.268909
I1107 22:17:29.413416 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:17:29.413416 18604 solver.cpp:237]     Train net output #1: loss = 0.268909 (* 1 = 0.268909 loss)
I1107 22:17:29.413416 18604 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1107 22:17:35.310827 18604 solver.cpp:218] Iteration 118300 (16.9561 iter/s, 5.89757s/100 iters), loss = 0.348153
I1107 22:17:35.310827 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:17:35.310827 18604 solver.cpp:237]     Train net output #1: loss = 0.348153 (* 1 = 0.348153 loss)
I1107 22:17:35.310827 18604 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1107 22:17:41.187203 18604 solver.cpp:218] Iteration 118400 (17.0199 iter/s, 5.87546s/100 iters), loss = 0.38559
I1107 22:17:41.187203 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:17:41.187203 18604 solver.cpp:237]     Train net output #1: loss = 0.38559 (* 1 = 0.38559 loss)
I1107 22:17:41.187203 18604 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1107 22:17:46.773571  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:17:47.004582 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_118500.caffemodel
I1107 22:17:47.019582 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_118500.solverstate
I1107 22:17:47.024581 18604 solver.cpp:330] Iteration 118500, Testing net (#0)
I1107 22:17:47.024581 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:17:48.318667 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:17:48.368166 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6718
I1107 22:17:48.368166 18604 solver.cpp:397]     Test net output #1: loss = 1.29164 (* 1 = 1.29164 loss)
I1107 22:17:48.424669 18604 solver.cpp:218] Iteration 118500 (13.8185 iter/s, 7.23666s/100 iters), loss = 0.29739
I1107 22:17:48.424669 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:17:48.424669 18604 solver.cpp:237]     Train net output #1: loss = 0.29739 (* 1 = 0.29739 loss)
I1107 22:17:48.424669 18604 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1107 22:17:54.298061 18604 solver.cpp:218] Iteration 118600 (17.0251 iter/s, 5.8737s/100 iters), loss = 0.284722
I1107 22:17:54.298061 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:17:54.298061 18604 solver.cpp:237]     Train net output #1: loss = 0.284722 (* 1 = 0.284722 loss)
I1107 22:17:54.298061 18604 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1107 22:18:00.183503 18604 solver.cpp:218] Iteration 118700 (16.9947 iter/s, 5.88418s/100 iters), loss = 0.328537
I1107 22:18:00.183503 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:18:00.183503 18604 solver.cpp:237]     Train net output #1: loss = 0.328537 (* 1 = 0.328537 loss)
I1107 22:18:00.183503 18604 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1107 22:18:06.089896 18604 solver.cpp:218] Iteration 118800 (16.9315 iter/s, 5.90615s/100 iters), loss = 0.284293
I1107 22:18:06.089896 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:18:06.089896 18604 solver.cpp:237]     Train net output #1: loss = 0.284293 (* 1 = 0.284293 loss)
I1107 22:18:06.089896 18604 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1107 22:18:11.987295 18604 solver.cpp:218] Iteration 118900 (16.9556 iter/s, 5.89777s/100 iters), loss = 0.409994
I1107 22:18:11.988296 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:18:11.988296 18604 solver.cpp:237]     Train net output #1: loss = 0.409994 (* 1 = 0.409994 loss)
I1107 22:18:11.988296 18604 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1107 22:18:17.579809  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:18:17.809872 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_119000.caffemodel
I1107 22:18:17.825875 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_119000.solverstate
I1107 22:18:17.830860 18604 solver.cpp:330] Iteration 119000, Testing net (#0)
I1107 22:18:17.830860 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:18:19.124670 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:18:19.175676 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6717
I1107 22:18:19.175676 18604 solver.cpp:397]     Test net output #1: loss = 1.29165 (* 1 = 1.29165 loss)
I1107 22:18:19.230690 18604 solver.cpp:218] Iteration 119000 (13.8068 iter/s, 7.24282s/100 iters), loss = 0.305272
I1107 22:18:19.230690 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:18:19.230690 18604 solver.cpp:237]     Train net output #1: loss = 0.305272 (* 1 = 0.305272 loss)
I1107 22:18:19.230690 18604 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1107 22:18:25.111809 18604 solver.cpp:218] Iteration 119100 (17.0067 iter/s, 5.88004s/100 iters), loss = 0.328616
I1107 22:18:25.111809 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:18:25.111809 18604 solver.cpp:237]     Train net output #1: loss = 0.328616 (* 1 = 0.328616 loss)
I1107 22:18:25.111809 18604 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1107 22:18:31.002327 18604 solver.cpp:218] Iteration 119200 (16.9771 iter/s, 5.8903s/100 iters), loss = 0.207841
I1107 22:18:31.002327 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:18:31.002327 18604 solver.cpp:237]     Train net output #1: loss = 0.207841 (* 1 = 0.207841 loss)
I1107 22:18:31.002327 18604 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1107 22:18:36.911844 18604 solver.cpp:218] Iteration 119300 (16.9218 iter/s, 5.90953s/100 iters), loss = 0.306655
I1107 22:18:36.911844 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:18:36.911844 18604 solver.cpp:237]     Train net output #1: loss = 0.306655 (* 1 = 0.306655 loss)
I1107 22:18:36.911844 18604 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1107 22:18:42.801511 18604 solver.cpp:218] Iteration 119400 (16.9799 iter/s, 5.88932s/100 iters), loss = 0.384536
I1107 22:18:42.802511 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:18:42.802511 18604 solver.cpp:237]     Train net output #1: loss = 0.384536 (* 1 = 0.384536 loss)
I1107 22:18:42.802511 18604 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1107 22:18:48.402292  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:18:48.633302 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_119500.caffemodel
I1107 22:18:48.649302 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_119500.solverstate
I1107 22:18:48.654304 18604 solver.cpp:330] Iteration 119500, Testing net (#0)
I1107 22:18:48.654304 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:18:49.952400 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:18:50.003417 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6749
I1107 22:18:50.003417 18604 solver.cpp:397]     Test net output #1: loss = 1.27522 (* 1 = 1.27522 loss)
I1107 22:18:50.060408 18604 solver.cpp:218] Iteration 119500 (13.7784 iter/s, 7.25772s/100 iters), loss = 0.32722
I1107 22:18:50.060408 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:18:50.060408 18604 solver.cpp:237]     Train net output #1: loss = 0.32722 (* 1 = 0.32722 loss)
I1107 22:18:50.060408 18604 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1107 22:18:55.966440 18604 solver.cpp:218] Iteration 119600 (16.9334 iter/s, 5.90547s/100 iters), loss = 0.360719
I1107 22:18:55.966440 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:18:55.966440 18604 solver.cpp:237]     Train net output #1: loss = 0.360719 (* 1 = 0.360719 loss)
I1107 22:18:55.966440 18604 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1107 22:19:01.861348 18604 solver.cpp:218] Iteration 119700 (16.9632 iter/s, 5.89511s/100 iters), loss = 0.27572
I1107 22:19:01.861348 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:19:01.861348 18604 solver.cpp:237]     Train net output #1: loss = 0.27572 (* 1 = 0.27572 loss)
I1107 22:19:01.861348 18604 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1107 22:19:07.740770 18604 solver.cpp:218] Iteration 119800 (17.0107 iter/s, 5.87865s/100 iters), loss = 0.348978
I1107 22:19:07.740770 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:19:07.740770 18604 solver.cpp:237]     Train net output #1: loss = 0.348978 (* 1 = 0.348978 loss)
I1107 22:19:07.740770 18604 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1107 22:19:13.632194 18604 solver.cpp:218] Iteration 119900 (16.9753 iter/s, 5.89092s/100 iters), loss = 0.441701
I1107 22:19:13.632194 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:19:13.632194 18604 solver.cpp:237]     Train net output #1: loss = 0.441701 (* 1 = 0.441701 loss)
I1107 22:19:13.632194 18604 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1107 22:19:19.234586  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:19:19.467104 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_120000.caffemodel
I1107 22:19:19.484616 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_120000.solverstate
I1107 22:19:19.489612 18604 solver.cpp:330] Iteration 120000, Testing net (#0)
I1107 22:19:19.490613 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:19:20.785694 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:19:20.836695 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6717
I1107 22:19:20.836695 18604 solver.cpp:397]     Test net output #1: loss = 1.29383 (* 1 = 1.29383 loss)
I1107 22:19:20.892724 18604 solver.cpp:218] Iteration 120000 (13.7733 iter/s, 7.26041s/100 iters), loss = 0.303995
I1107 22:19:20.892724 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:19:20.892724 18604 solver.cpp:237]     Train net output #1: loss = 0.303995 (* 1 = 0.303995 loss)
I1107 22:19:20.892724 18604 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1107 22:19:26.774400 18604 solver.cpp:218] Iteration 120100 (17.0054 iter/s, 5.88047s/100 iters), loss = 0.243818
I1107 22:19:26.774400 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:19:26.774400 18604 solver.cpp:237]     Train net output #1: loss = 0.243818 (* 1 = 0.243818 loss)
I1107 22:19:26.774400 18604 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1107 22:19:32.698868 18604 solver.cpp:218] Iteration 120200 (16.8801 iter/s, 5.92415s/100 iters), loss = 0.276115
I1107 22:19:32.698868 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:19:32.698868 18604 solver.cpp:237]     Train net output #1: loss = 0.276114 (* 1 = 0.276114 loss)
I1107 22:19:32.698868 18604 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1107 22:19:38.612279 18604 solver.cpp:218] Iteration 120300 (16.911 iter/s, 5.91333s/100 iters), loss = 0.383317
I1107 22:19:38.612279 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:19:38.612279 18604 solver.cpp:237]     Train net output #1: loss = 0.383317 (* 1 = 0.383317 loss)
I1107 22:19:38.612279 18604 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1107 22:19:44.498734 18604 solver.cpp:218] Iteration 120400 (16.9897 iter/s, 5.88592s/100 iters), loss = 0.460772
I1107 22:19:44.498734 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:19:44.498734 18604 solver.cpp:237]     Train net output #1: loss = 0.460772 (* 1 = 0.460772 loss)
I1107 22:19:44.498734 18604 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1107 22:19:50.116164  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:19:50.351184 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_120500.caffemodel
I1107 22:19:50.365183 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_120500.solverstate
I1107 22:19:50.370191 18604 solver.cpp:330] Iteration 120500, Testing net (#0)
I1107 22:19:50.370191 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:19:51.672355 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:19:51.723359 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6715
I1107 22:19:51.723359 18604 solver.cpp:397]     Test net output #1: loss = 1.2958 (* 1 = 1.2958 loss)
I1107 22:19:51.779861 18604 solver.cpp:218] Iteration 120500 (13.7355 iter/s, 7.28042s/100 iters), loss = 0.271746
I1107 22:19:51.779861 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:19:51.779861 18604 solver.cpp:237]     Train net output #1: loss = 0.271746 (* 1 = 0.271746 loss)
I1107 22:19:51.779861 18604 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1107 22:19:57.675781 18604 solver.cpp:218] Iteration 120600 (16.9617 iter/s, 5.89565s/100 iters), loss = 0.279614
I1107 22:19:57.675781 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:19:57.676277 18604 solver.cpp:237]     Train net output #1: loss = 0.279614 (* 1 = 0.279614 loss)
I1107 22:19:57.676277 18604 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1107 22:20:03.608410 18604 solver.cpp:218] Iteration 120700 (16.8569 iter/s, 5.93229s/100 iters), loss = 0.288476
I1107 22:20:03.608410 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:20:03.608410 18604 solver.cpp:237]     Train net output #1: loss = 0.288476 (* 1 = 0.288476 loss)
I1107 22:20:03.608410 18604 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1107 22:20:09.522878 18604 solver.cpp:218] Iteration 120800 (16.9101 iter/s, 5.91361s/100 iters), loss = 0.366834
I1107 22:20:09.522878 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:20:09.522878 18604 solver.cpp:237]     Train net output #1: loss = 0.366834 (* 1 = 0.366834 loss)
I1107 22:20:09.522878 18604 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1107 22:20:15.424314 18604 solver.cpp:218] Iteration 120900 (16.9451 iter/s, 5.90142s/100 iters), loss = 0.392917
I1107 22:20:15.424314 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:20:15.424314 18604 solver.cpp:237]     Train net output #1: loss = 0.392917 (* 1 = 0.392917 loss)
I1107 22:20:15.424314 18604 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1107 22:20:21.049728  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:20:21.280758 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_121000.caffemodel
I1107 22:20:21.295765 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_121000.solverstate
I1107 22:20:21.300765 18604 solver.cpp:330] Iteration 121000, Testing net (#0)
I1107 22:20:21.300765 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:20:22.597870 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:20:22.648874 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6701
I1107 22:20:22.648874 18604 solver.cpp:397]     Test net output #1: loss = 1.29689 (* 1 = 1.29689 loss)
I1107 22:20:22.704877 18604 solver.cpp:218] Iteration 121000 (13.7357 iter/s, 7.2803s/100 iters), loss = 0.285291
I1107 22:20:22.704877 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:20:22.704877 18604 solver.cpp:237]     Train net output #1: loss = 0.285291 (* 1 = 0.285291 loss)
I1107 22:20:22.704877 18604 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1107 22:20:28.608281 18604 solver.cpp:218] Iteration 121100 (16.9401 iter/s, 5.90314s/100 iters), loss = 0.354381
I1107 22:20:28.608281 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:20:28.608281 18604 solver.cpp:237]     Train net output #1: loss = 0.354381 (* 1 = 0.354381 loss)
I1107 22:20:28.608281 18604 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1107 22:20:34.512805 18604 solver.cpp:218] Iteration 121200 (16.9393 iter/s, 5.90342s/100 iters), loss = 0.265103
I1107 22:20:34.512805 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:20:34.512805 18604 solver.cpp:237]     Train net output #1: loss = 0.265103 (* 1 = 0.265103 loss)
I1107 22:20:34.512805 18604 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1107 22:20:40.416182 18604 solver.cpp:218] Iteration 121300 (16.9389 iter/s, 5.90356s/100 iters), loss = 0.361123
I1107 22:20:40.416182 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:20:40.416182 18604 solver.cpp:237]     Train net output #1: loss = 0.361123 (* 1 = 0.361123 loss)
I1107 22:20:40.416182 18604 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1107 22:20:46.317610 18604 solver.cpp:218] Iteration 121400 (16.948 iter/s, 5.90039s/100 iters), loss = 0.380093
I1107 22:20:46.317610 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:20:46.317610 18604 solver.cpp:237]     Train net output #1: loss = 0.380093 (* 1 = 0.380093 loss)
I1107 22:20:46.317610 18604 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1107 22:20:51.911015  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:20:52.145031 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_121500.caffemodel
I1107 22:20:52.165030 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_121500.solverstate
I1107 22:20:52.170030 18604 solver.cpp:330] Iteration 121500, Testing net (#0)
I1107 22:20:52.170030 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:20:53.477619 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:20:53.528123 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6702
I1107 22:20:53.528123 18604 solver.cpp:397]     Test net output #1: loss = 1.30301 (* 1 = 1.30301 loss)
I1107 22:20:53.585125 18604 solver.cpp:218] Iteration 121500 (13.7612 iter/s, 7.26681s/100 iters), loss = 0.353931
I1107 22:20:53.585125 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:20:53.585125 18604 solver.cpp:237]     Train net output #1: loss = 0.353931 (* 1 = 0.353931 loss)
I1107 22:20:53.585125 18604 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1107 22:20:59.490849 18604 solver.cpp:218] Iteration 121600 (16.932 iter/s, 5.90597s/100 iters), loss = 0.330555
I1107 22:20:59.490849 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:20:59.490849 18604 solver.cpp:237]     Train net output #1: loss = 0.330555 (* 1 = 0.330555 loss)
I1107 22:20:59.491852 18604 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1107 22:21:05.401283 18604 solver.cpp:218] Iteration 121700 (16.9227 iter/s, 5.90922s/100 iters), loss = 0.259549
I1107 22:21:05.401283 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:21:05.401283 18604 solver.cpp:237]     Train net output #1: loss = 0.259549 (* 1 = 0.259549 loss)
I1107 22:21:05.401283 18604 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1107 22:21:11.319680 18604 solver.cpp:218] Iteration 121800 (16.8953 iter/s, 5.91879s/100 iters), loss = 0.414438
I1107 22:21:11.320680 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:21:11.320680 18604 solver.cpp:237]     Train net output #1: loss = 0.414438 (* 1 = 0.414438 loss)
I1107 22:21:11.320680 18604 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1107 22:21:17.232940 18604 solver.cpp:218] Iteration 121900 (16.9152 iter/s, 5.91184s/100 iters), loss = 0.387018
I1107 22:21:17.232940 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:21:17.232940 18604 solver.cpp:237]     Train net output #1: loss = 0.387018 (* 1 = 0.387018 loss)
I1107 22:21:17.232940 18604 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1107 22:21:22.848613  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:21:23.081624 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_122000.caffemodel
I1107 22:21:23.095628 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_122000.solverstate
I1107 22:21:23.099627 18604 solver.cpp:330] Iteration 122000, Testing net (#0)
I1107 22:21:23.099627 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:21:24.392206 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:21:24.443709 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6703
I1107 22:21:24.443709 18604 solver.cpp:397]     Test net output #1: loss = 1.30659 (* 1 = 1.30659 loss)
I1107 22:21:24.499712 18604 solver.cpp:218] Iteration 122000 (13.7623 iter/s, 7.26624s/100 iters), loss = 0.29212
I1107 22:21:24.499712 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:21:24.499712 18604 solver.cpp:237]     Train net output #1: loss = 0.29212 (* 1 = 0.29212 loss)
I1107 22:21:24.499712 18604 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1107 22:21:30.405139 18604 solver.cpp:218] Iteration 122100 (16.9333 iter/s, 5.90552s/100 iters), loss = 0.301966
I1107 22:21:30.405139 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:21:30.405139 18604 solver.cpp:237]     Train net output #1: loss = 0.301966 (* 1 = 0.301966 loss)
I1107 22:21:30.405139 18604 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1107 22:21:36.304605 18604 solver.cpp:218] Iteration 122200 (16.9519 iter/s, 5.89903s/100 iters), loss = 0.28914
I1107 22:21:36.304605 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:21:36.304605 18604 solver.cpp:237]     Train net output #1: loss = 0.28914 (* 1 = 0.28914 loss)
I1107 22:21:36.304605 18604 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1107 22:21:42.202059 18604 solver.cpp:218] Iteration 122300 (16.9594 iter/s, 5.89642s/100 iters), loss = 0.361952
I1107 22:21:42.202059 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:21:42.202059 18604 solver.cpp:237]     Train net output #1: loss = 0.361952 (* 1 = 0.361952 loss)
I1107 22:21:42.202059 18604 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1107 22:21:48.100508 18604 solver.cpp:218] Iteration 122400 (16.9521 iter/s, 5.89899s/100 iters), loss = 0.368666
I1107 22:21:48.101510 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:21:48.101510 18604 solver.cpp:237]     Train net output #1: loss = 0.368666 (* 1 = 0.368666 loss)
I1107 22:21:48.101510 18604 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1107 22:21:53.705135  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:21:53.938144 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_122500.caffemodel
I1107 22:21:53.954650 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_122500.solverstate
I1107 22:21:53.959151 18604 solver.cpp:330] Iteration 122500, Testing net (#0)
I1107 22:21:53.959151 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:21:55.258260 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:21:55.308261 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6731
I1107 22:21:55.308261 18604 solver.cpp:397]     Test net output #1: loss = 1.30123 (* 1 = 1.30123 loss)
I1107 22:21:55.364766 18604 solver.cpp:218] Iteration 122500 (13.768 iter/s, 7.2632s/100 iters), loss = 0.283779
I1107 22:21:55.364766 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:21:55.364766 18604 solver.cpp:237]     Train net output #1: loss = 0.283779 (* 1 = 0.283779 loss)
I1107 22:21:55.364766 18604 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1107 22:22:01.263192 18604 solver.cpp:218] Iteration 122600 (16.9556 iter/s, 5.89775s/100 iters), loss = 0.263596
I1107 22:22:01.263192 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1107 22:22:01.263192 18604 solver.cpp:237]     Train net output #1: loss = 0.263596 (* 1 = 0.263596 loss)
I1107 22:22:01.263192 18604 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1107 22:22:07.138073 18604 solver.cpp:218] Iteration 122700 (17.022 iter/s, 5.87474s/100 iters), loss = 0.251239
I1107 22:22:07.138073 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:22:07.138073 18604 solver.cpp:237]     Train net output #1: loss = 0.251239 (* 1 = 0.251239 loss)
I1107 22:22:07.138073 18604 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1107 22:22:13.028494 18604 solver.cpp:218] Iteration 122800 (16.9787 iter/s, 5.88973s/100 iters), loss = 0.308994
I1107 22:22:13.028494 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:22:13.028494 18604 solver.cpp:237]     Train net output #1: loss = 0.308994 (* 1 = 0.308994 loss)
I1107 22:22:13.028494 18604 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1107 22:22:18.944931 18604 solver.cpp:218] Iteration 122900 (16.904 iter/s, 5.91575s/100 iters), loss = 0.353917
I1107 22:22:18.944931 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:22:18.944931 18604 solver.cpp:237]     Train net output #1: loss = 0.353917 (* 1 = 0.353917 loss)
I1107 22:22:18.944931 18604 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1107 22:22:24.557348  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:22:24.789360 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_123000.caffemodel
I1107 22:22:24.803360 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_123000.solverstate
I1107 22:22:24.808359 18604 solver.cpp:330] Iteration 123000, Testing net (#0)
I1107 22:22:24.808359 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:22:26.101440 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:22:26.152943 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6693
I1107 22:22:26.152943 18604 solver.cpp:397]     Test net output #1: loss = 1.31224 (* 1 = 1.31224 loss)
I1107 22:22:26.208446 18604 solver.cpp:218] Iteration 123000 (13.7666 iter/s, 7.26398s/100 iters), loss = 0.33549
I1107 22:22:26.209446 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:22:26.209446 18604 solver.cpp:237]     Train net output #1: loss = 0.33549 (* 1 = 0.33549 loss)
I1107 22:22:26.209446 18604 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1107 22:22:32.093834 18604 solver.cpp:218] Iteration 123100 (16.9933 iter/s, 5.88466s/100 iters), loss = 0.352419
I1107 22:22:32.093834 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:22:32.093834 18604 solver.cpp:237]     Train net output #1: loss = 0.352419 (* 1 = 0.352419 loss)
I1107 22:22:32.093834 18604 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1107 22:22:37.987236 18604 solver.cpp:218] Iteration 123200 (16.9702 iter/s, 5.89268s/100 iters), loss = 0.292658
I1107 22:22:37.987236 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:22:37.987236 18604 solver.cpp:237]     Train net output #1: loss = 0.292658 (* 1 = 0.292658 loss)
I1107 22:22:37.987236 18604 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1107 22:22:43.907676 18604 solver.cpp:218] Iteration 123300 (16.893 iter/s, 5.91961s/100 iters), loss = 0.4025
I1107 22:22:43.907676 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:22:43.907676 18604 solver.cpp:237]     Train net output #1: loss = 0.4025 (* 1 = 0.4025 loss)
I1107 22:22:43.907676 18604 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1107 22:22:49.819152 18604 solver.cpp:218] Iteration 123400 (16.9167 iter/s, 5.91133s/100 iters), loss = 0.399462
I1107 22:22:49.819152 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:22:49.819152 18604 solver.cpp:237]     Train net output #1: loss = 0.399461 (* 1 = 0.399461 loss)
I1107 22:22:49.819152 18604 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1107 22:22:55.429539  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:22:55.662552 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_123500.caffemodel
I1107 22:22:55.678556 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_123500.solverstate
I1107 22:22:55.683557 18604 solver.cpp:330] Iteration 123500, Testing net (#0)
I1107 22:22:55.683557 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:22:56.980643 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:22:57.031642 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6742
I1107 22:22:57.031642 18604 solver.cpp:397]     Test net output #1: loss = 1.29688 (* 1 = 1.29688 loss)
I1107 22:22:57.087647 18604 solver.cpp:218] Iteration 123500 (13.7594 iter/s, 7.26778s/100 iters), loss = 0.288578
I1107 22:22:57.087647 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:22:57.087647 18604 solver.cpp:237]     Train net output #1: loss = 0.288578 (* 1 = 0.288578 loss)
I1107 22:22:57.087647 18604 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1107 22:23:02.998913 18604 solver.cpp:218] Iteration 123600 (16.9182 iter/s, 5.9108s/100 iters), loss = 0.36204
I1107 22:23:02.998913 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:23:02.998913 18604 solver.cpp:237]     Train net output #1: loss = 0.36204 (* 1 = 0.36204 loss)
I1107 22:23:02.998913 18604 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1107 22:23:08.932926 18604 solver.cpp:218] Iteration 123700 (16.8514 iter/s, 5.93421s/100 iters), loss = 0.254722
I1107 22:23:08.932926 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:23:08.932926 18604 solver.cpp:237]     Train net output #1: loss = 0.254721 (* 1 = 0.254721 loss)
I1107 22:23:08.932926 18604 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1107 22:23:14.801683 18604 solver.cpp:218] Iteration 123800 (17.0405 iter/s, 5.86836s/100 iters), loss = 0.347079
I1107 22:23:14.801683 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:23:14.801683 18604 solver.cpp:237]     Train net output #1: loss = 0.347079 (* 1 = 0.347079 loss)
I1107 22:23:14.801683 18604 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1107 22:23:20.693116 18604 solver.cpp:218] Iteration 123900 (16.977 iter/s, 5.89033s/100 iters), loss = 0.433242
I1107 22:23:20.693116 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:23:20.693116 18604 solver.cpp:237]     Train net output #1: loss = 0.433242 (* 1 = 0.433242 loss)
I1107 22:23:20.693116 18604 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1107 22:23:26.285519  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:23:26.518544 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_124000.caffemodel
I1107 22:23:26.535544 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_124000.solverstate
I1107 22:23:26.540544 18604 solver.cpp:330] Iteration 124000, Testing net (#0)
I1107 22:23:26.540544 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:23:27.834692 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:23:27.885689 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6697
I1107 22:23:27.885689 18604 solver.cpp:397]     Test net output #1: loss = 1.32474 (* 1 = 1.32474 loss)
I1107 22:23:27.942689 18604 solver.cpp:218] Iteration 124000 (13.7952 iter/s, 7.24892s/100 iters), loss = 0.275476
I1107 22:23:27.942689 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:23:27.942689 18604 solver.cpp:237]     Train net output #1: loss = 0.275476 (* 1 = 0.275476 loss)
I1107 22:23:27.942689 18604 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1107 22:23:33.841068 18604 solver.cpp:218] Iteration 124100 (16.9544 iter/s, 5.89816s/100 iters), loss = 0.300872
I1107 22:23:33.841068 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:23:33.841068 18604 solver.cpp:237]     Train net output #1: loss = 0.300872 (* 1 = 0.300872 loss)
I1107 22:23:33.841068 18604 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1107 22:23:39.783569 18604 solver.cpp:218] Iteration 124200 (16.8298 iter/s, 5.94186s/100 iters), loss = 0.332523
I1107 22:23:39.783569 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:23:39.783569 18604 solver.cpp:237]     Train net output #1: loss = 0.332523 (* 1 = 0.332523 loss)
I1107 22:23:39.783569 18604 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1107 22:23:45.699857 18604 solver.cpp:218] Iteration 124300 (16.902 iter/s, 5.91646s/100 iters), loss = 0.252724
I1107 22:23:45.699857 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:23:45.699857 18604 solver.cpp:237]     Train net output #1: loss = 0.252724 (* 1 = 0.252724 loss)
I1107 22:23:45.699857 18604 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1107 22:23:51.639395 18604 solver.cpp:218] Iteration 124400 (16.837 iter/s, 5.9393s/100 iters), loss = 0.37269
I1107 22:23:51.639395 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:23:51.639395 18604 solver.cpp:237]     Train net output #1: loss = 0.37269 (* 1 = 0.37269 loss)
I1107 22:23:51.639395 18604 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1107 22:23:57.320339  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:23:57.554349 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_124500.caffemodel
I1107 22:23:57.570853 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_124500.solverstate
I1107 22:23:57.575853 18604 solver.cpp:330] Iteration 124500, Testing net (#0)
I1107 22:23:57.575853 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:23:58.873944 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:23:58.924453 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6717
I1107 22:23:58.924453 18604 solver.cpp:397]     Test net output #1: loss = 1.31403 (* 1 = 1.31403 loss)
I1107 22:23:58.982456 18604 solver.cpp:218] Iteration 124500 (13.6207 iter/s, 7.34175s/100 iters), loss = 0.331772
I1107 22:23:58.982456 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:23:58.982456 18604 solver.cpp:237]     Train net output #1: loss = 0.331772 (* 1 = 0.331772 loss)
I1107 22:23:58.982456 18604 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1107 22:24:04.891994 18604 solver.cpp:218] Iteration 124600 (16.9227 iter/s, 5.90923s/100 iters), loss = 0.284026
I1107 22:24:04.891994 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:24:04.891994 18604 solver.cpp:237]     Train net output #1: loss = 0.284026 (* 1 = 0.284026 loss)
I1107 22:24:04.891994 18604 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1107 22:24:10.813374 18604 solver.cpp:218] Iteration 124700 (16.8883 iter/s, 5.92125s/100 iters), loss = 0.238102
I1107 22:24:10.813374 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:24:10.813374 18604 solver.cpp:237]     Train net output #1: loss = 0.238102 (* 1 = 0.238102 loss)
I1107 22:24:10.813374 18604 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1107 22:24:16.723734 18604 solver.cpp:218] Iteration 124800 (16.9223 iter/s, 5.90938s/100 iters), loss = 0.375504
I1107 22:24:16.723734 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:24:16.723734 18604 solver.cpp:237]     Train net output #1: loss = 0.375504 (* 1 = 0.375504 loss)
I1107 22:24:16.723734 18604 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1107 22:24:22.608153 18604 solver.cpp:218] Iteration 124900 (16.9952 iter/s, 5.884s/100 iters), loss = 0.347853
I1107 22:24:22.608153 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:24:22.608153 18604 solver.cpp:237]     Train net output #1: loss = 0.347853 (* 1 = 0.347853 loss)
I1107 22:24:22.608153 18604 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1107 22:24:28.242071  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:24:28.478087 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_125000.caffemodel
I1107 22:24:28.493089 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_125000.solverstate
I1107 22:24:28.498090 18604 solver.cpp:330] Iteration 125000, Testing net (#0)
I1107 22:24:28.498090 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:24:29.810180 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:24:29.862192 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6644
I1107 22:24:29.862192 18604 solver.cpp:397]     Test net output #1: loss = 1.33085 (* 1 = 1.33085 loss)
I1107 22:24:29.920204 18604 solver.cpp:218] Iteration 125000 (13.6765 iter/s, 7.31181s/100 iters), loss = 0.300528
I1107 22:24:29.920204 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:24:29.920204 18604 solver.cpp:237]     Train net output #1: loss = 0.300528 (* 1 = 0.300528 loss)
I1107 22:24:29.920204 18604 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1107 22:24:35.844115 18604 solver.cpp:218] Iteration 125100 (16.8823 iter/s, 5.92337s/100 iters), loss = 0.29353
I1107 22:24:35.844115 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:24:35.844115 18604 solver.cpp:237]     Train net output #1: loss = 0.29353 (* 1 = 0.29353 loss)
I1107 22:24:35.844115 18604 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1107 22:24:41.758997 18604 solver.cpp:218] Iteration 125200 (16.9081 iter/s, 5.91434s/100 iters), loss = 0.31489
I1107 22:24:41.758997 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:24:41.758997 18604 solver.cpp:237]     Train net output #1: loss = 0.31489 (* 1 = 0.31489 loss)
I1107 22:24:41.758997 18604 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1107 22:24:47.670380 18604 solver.cpp:218] Iteration 125300 (16.9159 iter/s, 5.91158s/100 iters), loss = 0.31166
I1107 22:24:47.670380 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:24:47.670380 18604 solver.cpp:237]     Train net output #1: loss = 0.31166 (* 1 = 0.31166 loss)
I1107 22:24:47.670380 18604 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1107 22:24:53.594833 18604 solver.cpp:218] Iteration 125400 (16.8827 iter/s, 5.92323s/100 iters), loss = 0.383281
I1107 22:24:53.594833 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:24:53.594833 18604 solver.cpp:237]     Train net output #1: loss = 0.383281 (* 1 = 0.383281 loss)
I1107 22:24:53.594833 18604 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1107 22:24:59.182024  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:24:59.413033 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_125500.caffemodel
I1107 22:24:59.427032 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_125500.solverstate
I1107 22:24:59.432032 18604 solver.cpp:330] Iteration 125500, Testing net (#0)
I1107 22:24:59.432032 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:25:00.724120 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:25:00.776140 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6632
I1107 22:25:00.776140 18604 solver.cpp:397]     Test net output #1: loss = 1.32812 (* 1 = 1.32812 loss)
I1107 22:25:00.832139 18604 solver.cpp:218] Iteration 125500 (13.8174 iter/s, 7.23727s/100 iters), loss = 0.273213
I1107 22:25:00.832139 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:25:00.832139 18604 solver.cpp:237]     Train net output #1: loss = 0.273212 (* 1 = 0.273212 loss)
I1107 22:25:00.832139 18604 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1107 22:25:06.712537 18604 solver.cpp:218] Iteration 125600 (17.0081 iter/s, 5.87956s/100 iters), loss = 0.311822
I1107 22:25:06.712537 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:25:06.712537 18604 solver.cpp:237]     Train net output #1: loss = 0.311822 (* 1 = 0.311822 loss)
I1107 22:25:06.712537 18604 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1107 22:25:12.590955 18604 solver.cpp:218] Iteration 125700 (17.0105 iter/s, 5.87871s/100 iters), loss = 0.222437
I1107 22:25:12.590955 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:25:12.590955 18604 solver.cpp:237]     Train net output #1: loss = 0.222437 (* 1 = 0.222437 loss)
I1107 22:25:12.590955 18604 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1107 22:25:18.509356 18604 solver.cpp:218] Iteration 125800 (16.897 iter/s, 5.91822s/100 iters), loss = 0.305088
I1107 22:25:18.510356 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:25:18.510356 18604 solver.cpp:237]     Train net output #1: loss = 0.305088 (* 1 = 0.305088 loss)
I1107 22:25:18.510356 18604 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1107 22:25:24.470672 18604 solver.cpp:218] Iteration 125900 (16.7786 iter/s, 5.95996s/100 iters), loss = 0.375279
I1107 22:25:24.470672 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:25:24.470672 18604 solver.cpp:237]     Train net output #1: loss = 0.375279 (* 1 = 0.375279 loss)
I1107 22:25:24.470672 18604 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1107 22:25:30.070076  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:25:30.301090 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_126000.caffemodel
I1107 22:25:30.320091 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_126000.solverstate
I1107 22:25:30.325091 18604 solver.cpp:330] Iteration 126000, Testing net (#0)
I1107 22:25:30.325091 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:25:31.622223 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:25:31.673241 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6699
I1107 22:25:31.673241 18604 solver.cpp:397]     Test net output #1: loss = 1.31065 (* 1 = 1.31065 loss)
I1107 22:25:31.729240 18604 solver.cpp:218] Iteration 126000 (13.777 iter/s, 7.25847s/100 iters), loss = 0.325629
I1107 22:25:31.729240 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:25:31.729240 18604 solver.cpp:237]     Train net output #1: loss = 0.325629 (* 1 = 0.325629 loss)
I1107 22:25:31.729240 18604 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1107 22:25:37.650202 18604 solver.cpp:218] Iteration 126100 (16.8907 iter/s, 5.92041s/100 iters), loss = 0.336167
I1107 22:25:37.650701 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:25:37.650701 18604 solver.cpp:237]     Train net output #1: loss = 0.336167 (* 1 = 0.336167 loss)
I1107 22:25:37.650701 18604 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1107 22:25:43.572116 18604 solver.cpp:218] Iteration 126200 (16.8877 iter/s, 5.92147s/100 iters), loss = 0.198796
I1107 22:25:43.572116 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:25:43.572116 18604 solver.cpp:237]     Train net output #1: loss = 0.198796 (* 1 = 0.198796 loss)
I1107 22:25:43.572116 18604 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1107 22:25:49.465049 18604 solver.cpp:218] Iteration 126300 (16.9693 iter/s, 5.89299s/100 iters), loss = 0.388716
I1107 22:25:49.465049 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1107 22:25:49.465049 18604 solver.cpp:237]     Train net output #1: loss = 0.388716 (* 1 = 0.388716 loss)
I1107 22:25:49.465049 18604 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1107 22:25:55.367708 18604 solver.cpp:218] Iteration 126400 (16.9444 iter/s, 5.90166s/100 iters), loss = 0.354025
I1107 22:25:55.367708 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:25:55.367708 18604 solver.cpp:237]     Train net output #1: loss = 0.354025 (* 1 = 0.354025 loss)
I1107 22:25:55.367708 18604 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1107 22:26:00.982031  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:26:01.216120 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_126500.caffemodel
I1107 22:26:01.232118 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_126500.solverstate
I1107 22:26:01.237116 18604 solver.cpp:330] Iteration 126500, Testing net (#0)
I1107 22:26:01.237116 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:26:02.540210 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:26:02.590217 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6663
I1107 22:26:02.590217 18604 solver.cpp:397]     Test net output #1: loss = 1.32987 (* 1 = 1.32987 loss)
I1107 22:26:02.648216 18604 solver.cpp:218] Iteration 126500 (13.7369 iter/s, 7.27968s/100 iters), loss = 0.228288
I1107 22:26:02.648216 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:26:02.648216 18604 solver.cpp:237]     Train net output #1: loss = 0.228288 (* 1 = 0.228288 loss)
I1107 22:26:02.648216 18604 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1107 22:26:08.566365 18604 solver.cpp:218] Iteration 126600 (16.8984 iter/s, 5.91774s/100 iters), loss = 0.291486
I1107 22:26:08.566365 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:26:08.566365 18604 solver.cpp:237]     Train net output #1: loss = 0.291485 (* 1 = 0.291485 loss)
I1107 22:26:08.566365 18604 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1107 22:26:14.441311 18604 solver.cpp:218] Iteration 126700 (17.0223 iter/s, 5.87465s/100 iters), loss = 0.240087
I1107 22:26:14.441311 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:26:14.441311 18604 solver.cpp:237]     Train net output #1: loss = 0.240087 (* 1 = 0.240087 loss)
I1107 22:26:14.441311 18604 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1107 22:26:20.328789 18604 solver.cpp:218] Iteration 126800 (16.986 iter/s, 5.88721s/100 iters), loss = 0.301049
I1107 22:26:20.328789 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:26:20.328789 18604 solver.cpp:237]     Train net output #1: loss = 0.301048 (* 1 = 0.301048 loss)
I1107 22:26:20.328789 18604 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1107 22:26:26.213678 18604 solver.cpp:218] Iteration 126900 (16.9947 iter/s, 5.8842s/100 iters), loss = 0.33617
I1107 22:26:26.213678 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:26:26.213678 18604 solver.cpp:237]     Train net output #1: loss = 0.33617 (* 1 = 0.33617 loss)
I1107 22:26:26.213678 18604 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1107 22:26:31.803035  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:26:32.035055 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_127000.caffemodel
I1107 22:26:32.051046 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_127000.solverstate
I1107 22:26:32.056046 18604 solver.cpp:330] Iteration 127000, Testing net (#0)
I1107 22:26:32.056046 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:26:33.356147 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:26:33.407165 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6718
I1107 22:26:33.407165 18604 solver.cpp:397]     Test net output #1: loss = 1.31369 (* 1 = 1.31369 loss)
I1107 22:26:33.463155 18604 solver.cpp:218] Iteration 127000 (13.7949 iter/s, 7.24903s/100 iters), loss = 0.323815
I1107 22:26:33.463155 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:26:33.463155 18604 solver.cpp:237]     Train net output #1: loss = 0.323815 (* 1 = 0.323815 loss)
I1107 22:26:33.463155 18604 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1107 22:26:39.363617 18604 solver.cpp:218] Iteration 127100 (16.9475 iter/s, 5.90056s/100 iters), loss = 0.311763
I1107 22:26:39.363617 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:26:39.363617 18604 solver.cpp:237]     Train net output #1: loss = 0.311763 (* 1 = 0.311763 loss)
I1107 22:26:39.363617 18604 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1107 22:26:45.241094 18604 solver.cpp:218] Iteration 127200 (17.0154 iter/s, 5.87703s/100 iters), loss = 0.254633
I1107 22:26:45.241094 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:26:45.241094 18604 solver.cpp:237]     Train net output #1: loss = 0.254633 (* 1 = 0.254633 loss)
I1107 22:26:45.241094 18604 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1107 22:26:51.122267 18604 solver.cpp:218] Iteration 127300 (17.0048 iter/s, 5.88069s/100 iters), loss = 0.332588
I1107 22:26:51.122267 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:26:51.122267 18604 solver.cpp:237]     Train net output #1: loss = 0.332588 (* 1 = 0.332588 loss)
I1107 22:26:51.122267 18604 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1107 22:26:57.005556 18604 solver.cpp:218] Iteration 127400 (16.9976 iter/s, 5.88317s/100 iters), loss = 0.306463
I1107 22:26:57.005556 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:26:57.005556 18604 solver.cpp:237]     Train net output #1: loss = 0.306463 (* 1 = 0.306463 loss)
I1107 22:26:57.005556 18604 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1107 22:27:02.593941  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:27:02.825459 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_127500.caffemodel
I1107 22:27:02.839958 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_127500.solverstate
I1107 22:27:02.844962 18604 solver.cpp:330] Iteration 127500, Testing net (#0)
I1107 22:27:02.844962 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:27:04.139060 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:27:04.189062 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6712
I1107 22:27:04.189062 18604 solver.cpp:397]     Test net output #1: loss = 1.32558 (* 1 = 1.32558 loss)
I1107 22:27:04.245066 18604 solver.cpp:218] Iteration 127500 (13.8138 iter/s, 7.23911s/100 iters), loss = 0.295473
I1107 22:27:04.245066 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:27:04.246068 18604 solver.cpp:237]     Train net output #1: loss = 0.295473 (* 1 = 0.295473 loss)
I1107 22:27:04.246068 18604 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1107 22:27:10.131978 18604 solver.cpp:218] Iteration 127600 (16.9899 iter/s, 5.88586s/100 iters), loss = 0.303196
I1107 22:27:10.131978 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:27:10.131978 18604 solver.cpp:237]     Train net output #1: loss = 0.303195 (* 1 = 0.303195 loss)
I1107 22:27:10.131978 18604 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1107 22:27:16.036470 18604 solver.cpp:218] Iteration 127700 (16.9379 iter/s, 5.9039s/100 iters), loss = 0.230401
I1107 22:27:16.036470 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:27:16.036470 18604 solver.cpp:237]     Train net output #1: loss = 0.230401 (* 1 = 0.230401 loss)
I1107 22:27:16.036470 18604 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1107 22:27:21.948583 18604 solver.cpp:218] Iteration 127800 (16.9153 iter/s, 5.9118s/100 iters), loss = 0.329731
I1107 22:27:21.948583 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:27:21.948583 18604 solver.cpp:237]     Train net output #1: loss = 0.329731 (* 1 = 0.329731 loss)
I1107 22:27:21.948583 18604 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1107 22:27:27.885015 18604 solver.cpp:218] Iteration 127900 (16.8471 iter/s, 5.93576s/100 iters), loss = 0.331146
I1107 22:27:27.885015 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:27:27.885015 18604 solver.cpp:237]     Train net output #1: loss = 0.331145 (* 1 = 0.331145 loss)
I1107 22:27:27.885015 18604 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1107 22:27:33.506090  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:27:33.738617 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_128000.caffemodel
I1107 22:27:33.752120 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_128000.solverstate
I1107 22:27:33.757122 18604 solver.cpp:330] Iteration 128000, Testing net (#0)
I1107 22:27:33.757122 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:27:35.053244 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:27:35.103245 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6644
I1107 22:27:35.103245 18604 solver.cpp:397]     Test net output #1: loss = 1.31673 (* 1 = 1.31673 loss)
I1107 22:27:35.159250 18604 solver.cpp:218] Iteration 128000 (13.7474 iter/s, 7.27409s/100 iters), loss = 0.243746
I1107 22:27:35.159250 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:27:35.159250 18604 solver.cpp:237]     Train net output #1: loss = 0.243746 (* 1 = 0.243746 loss)
I1107 22:27:35.159250 18604 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1107 22:27:41.079705 18604 solver.cpp:218] Iteration 128100 (16.8925 iter/s, 5.91977s/100 iters), loss = 0.331102
I1107 22:27:41.079705 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:27:41.079705 18604 solver.cpp:237]     Train net output #1: loss = 0.331102 (* 1 = 0.331102 loss)
I1107 22:27:41.079705 18604 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1107 22:27:46.984143 18604 solver.cpp:218] Iteration 128200 (16.9351 iter/s, 5.90491s/100 iters), loss = 0.270446
I1107 22:27:46.985143 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:27:46.985143 18604 solver.cpp:237]     Train net output #1: loss = 0.270445 (* 1 = 0.270445 loss)
I1107 22:27:46.985143 18604 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1107 22:27:52.902529 18604 solver.cpp:218] Iteration 128300 (16.898 iter/s, 5.91787s/100 iters), loss = 0.30449
I1107 22:27:52.902529 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:27:52.903528 18604 solver.cpp:237]     Train net output #1: loss = 0.30449 (* 1 = 0.30449 loss)
I1107 22:27:52.903528 18604 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1107 22:27:58.875123 18604 solver.cpp:218] Iteration 128400 (16.7458 iter/s, 5.97166s/100 iters), loss = 0.332413
I1107 22:27:58.875123 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:27:58.875123 18604 solver.cpp:237]     Train net output #1: loss = 0.332413 (* 1 = 0.332413 loss)
I1107 22:27:58.875123 18604 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1107 22:28:04.491540  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:28:04.724553 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_128500.caffemodel
I1107 22:28:04.740553 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_128500.solverstate
I1107 22:28:04.744552 18604 solver.cpp:330] Iteration 128500, Testing net (#0)
I1107 22:28:04.744552 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:28:06.047646 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:28:06.100651 18604 solver.cpp:397]     Test net output #0: accuracy = 0.668
I1107 22:28:06.100651 18604 solver.cpp:397]     Test net output #1: loss = 1.32762 (* 1 = 1.32762 loss)
I1107 22:28:06.159157 18604 solver.cpp:218] Iteration 128500 (13.7302 iter/s, 7.28324s/100 iters), loss = 0.258859
I1107 22:28:06.159157 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:28:06.159157 18604 solver.cpp:237]     Train net output #1: loss = 0.258859 (* 1 = 0.258859 loss)
I1107 22:28:06.159157 18604 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1107 22:28:12.067580 18604 solver.cpp:218] Iteration 128600 (16.9267 iter/s, 5.90784s/100 iters), loss = 0.275609
I1107 22:28:12.067580 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:28:12.067580 18604 solver.cpp:237]     Train net output #1: loss = 0.275609 (* 1 = 0.275609 loss)
I1107 22:28:12.067580 18604 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1107 22:28:17.953954 18604 solver.cpp:218] Iteration 128700 (16.9892 iter/s, 5.8861s/100 iters), loss = 0.214285
I1107 22:28:17.953954 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:28:17.953954 18604 solver.cpp:237]     Train net output #1: loss = 0.214285 (* 1 = 0.214285 loss)
I1107 22:28:17.953954 18604 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1107 22:28:23.847872 18604 solver.cpp:218] Iteration 128800 (16.9664 iter/s, 5.89402s/100 iters), loss = 0.359594
I1107 22:28:23.847872 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:28:23.847872 18604 solver.cpp:237]     Train net output #1: loss = 0.359594 (* 1 = 0.359594 loss)
I1107 22:28:23.847872 18604 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1107 22:28:29.734230 18604 solver.cpp:218] Iteration 128900 (16.9907 iter/s, 5.88559s/100 iters), loss = 0.425523
I1107 22:28:29.734230 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:28:29.734230 18604 solver.cpp:237]     Train net output #1: loss = 0.425523 (* 1 = 0.425523 loss)
I1107 22:28:29.734230 18604 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1107 22:28:35.333595  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:28:35.567109 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_129000.caffemodel
I1107 22:28:35.581614 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_129000.solverstate
I1107 22:28:35.586613 18604 solver.cpp:330] Iteration 129000, Testing net (#0)
I1107 22:28:35.586613 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:28:36.882735 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:28:36.935734 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6715
I1107 22:28:36.935734 18604 solver.cpp:397]     Test net output #1: loss = 1.30878 (* 1 = 1.30878 loss)
I1107 22:28:36.996742 18604 solver.cpp:218] Iteration 129000 (13.7707 iter/s, 7.26179s/100 iters), loss = 0.212174
I1107 22:28:36.996742 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:28:36.996742 18604 solver.cpp:237]     Train net output #1: loss = 0.212174 (* 1 = 0.212174 loss)
I1107 22:28:36.996742 18604 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1107 22:28:42.932401 18604 solver.cpp:218] Iteration 129100 (16.8482 iter/s, 5.93534s/100 iters), loss = 0.328054
I1107 22:28:42.932401 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:28:42.932401 18604 solver.cpp:237]     Train net output #1: loss = 0.328054 (* 1 = 0.328054 loss)
I1107 22:28:42.932401 18604 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1107 22:28:48.868813 18604 solver.cpp:218] Iteration 129200 (16.8468 iter/s, 5.93583s/100 iters), loss = 0.234777
I1107 22:28:48.868813 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:28:48.868813 18604 solver.cpp:237]     Train net output #1: loss = 0.234776 (* 1 = 0.234776 loss)
I1107 22:28:48.868813 18604 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1107 22:28:54.733428 18604 solver.cpp:218] Iteration 129300 (17.0506 iter/s, 5.86491s/100 iters), loss = 0.331448
I1107 22:28:54.733428 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:28:54.733428 18604 solver.cpp:237]     Train net output #1: loss = 0.331448 (* 1 = 0.331448 loss)
I1107 22:28:54.733428 18604 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1107 22:29:00.611814 18604 solver.cpp:218] Iteration 129400 (17.0124 iter/s, 5.87808s/100 iters), loss = 0.364562
I1107 22:29:00.611814 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:29:00.611814 18604 solver.cpp:237]     Train net output #1: loss = 0.364562 (* 1 = 0.364562 loss)
I1107 22:29:00.611814 18604 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1107 22:29:06.203174  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:29:06.435174 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_129500.caffemodel
I1107 22:29:06.451174 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_129500.solverstate
I1107 22:29:06.455174 18604 solver.cpp:330] Iteration 129500, Testing net (#0)
I1107 22:29:06.455174 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:29:07.746275 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:29:07.797292 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6649
I1107 22:29:07.797292 18604 solver.cpp:397]     Test net output #1: loss = 1.35318 (* 1 = 1.35318 loss)
I1107 22:29:07.853291 18604 solver.cpp:218] Iteration 129500 (13.8104 iter/s, 7.24092s/100 iters), loss = 0.243564
I1107 22:29:07.853291 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:29:07.853291 18604 solver.cpp:237]     Train net output #1: loss = 0.243564 (* 1 = 0.243564 loss)
I1107 22:29:07.853291 18604 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1107 22:29:13.731672 18604 solver.cpp:218] Iteration 129600 (17.0126 iter/s, 5.87798s/100 iters), loss = 0.32465
I1107 22:29:13.731672 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:29:13.731672 18604 solver.cpp:237]     Train net output #1: loss = 0.32465 (* 1 = 0.32465 loss)
I1107 22:29:13.731672 18604 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1107 22:29:19.608059 18604 solver.cpp:218] Iteration 129700 (17.02 iter/s, 5.87543s/100 iters), loss = 0.23137
I1107 22:29:19.608059 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:29:19.608059 18604 solver.cpp:237]     Train net output #1: loss = 0.23137 (* 1 = 0.23137 loss)
I1107 22:29:19.608059 18604 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1107 22:29:25.485630 18604 solver.cpp:218] Iteration 129800 (17.0133 iter/s, 5.87776s/100 iters), loss = 0.326686
I1107 22:29:25.485630 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:29:25.485630 18604 solver.cpp:237]     Train net output #1: loss = 0.326685 (* 1 = 0.326685 loss)
I1107 22:29:25.485630 18604 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1107 22:29:31.360467 18604 solver.cpp:218] Iteration 129900 (17.0238 iter/s, 5.87413s/100 iters), loss = 0.437664
I1107 22:29:31.360967 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:29:31.360967 18604 solver.cpp:237]     Train net output #1: loss = 0.437664 (* 1 = 0.437664 loss)
I1107 22:29:31.360967 18604 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1107 22:29:36.952304  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:29:37.183320 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_130000.caffemodel
I1107 22:29:37.200320 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_130000.solverstate
I1107 22:29:37.205320 18604 solver.cpp:330] Iteration 130000, Testing net (#0)
I1107 22:29:37.205320 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:29:38.503435 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:29:38.554430 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6681
I1107 22:29:38.554430 18604 solver.cpp:397]     Test net output #1: loss = 1.33572 (* 1 = 1.33572 loss)
I1107 22:29:38.610440 18604 solver.cpp:218] Iteration 130000 (13.7939 iter/s, 7.24959s/100 iters), loss = 0.225694
I1107 22:29:38.610440 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:29:38.610440 18604 solver.cpp:237]     Train net output #1: loss = 0.225694 (* 1 = 0.225694 loss)
I1107 22:29:38.610440 18604 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1107 22:29:44.608837 18604 solver.cpp:218] Iteration 130100 (16.6714 iter/s, 5.99829s/100 iters), loss = 0.380134
I1107 22:29:44.608837 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:29:44.608837 18604 solver.cpp:237]     Train net output #1: loss = 0.380134 (* 1 = 0.380134 loss)
I1107 22:29:44.608837 18604 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1107 22:29:50.558285 18604 solver.cpp:218] Iteration 130200 (16.8105 iter/s, 5.94868s/100 iters), loss = 0.196753
I1107 22:29:50.558285 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:29:50.558285 18604 solver.cpp:237]     Train net output #1: loss = 0.196753 (* 1 = 0.196753 loss)
I1107 22:29:50.558285 18604 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1107 22:29:56.502939 18604 solver.cpp:218] Iteration 130300 (16.8243 iter/s, 5.94378s/100 iters), loss = 0.298521
I1107 22:29:56.502939 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:29:56.502939 18604 solver.cpp:237]     Train net output #1: loss = 0.298521 (* 1 = 0.298521 loss)
I1107 22:29:56.502939 18604 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1107 22:30:02.434387 18604 solver.cpp:218] Iteration 130400 (16.8596 iter/s, 5.93134s/100 iters), loss = 0.398675
I1107 22:30:02.434387 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:30:02.434387 18604 solver.cpp:237]     Train net output #1: loss = 0.398675 (* 1 = 0.398675 loss)
I1107 22:30:02.434387 18604 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1107 22:30:08.094185  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:30:08.325230 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_130500.caffemodel
I1107 22:30:08.340214 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_130500.solverstate
I1107 22:30:08.345214 18604 solver.cpp:330] Iteration 130500, Testing net (#0)
I1107 22:30:08.345214 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:30:09.638784 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:30:09.690814 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6682
I1107 22:30:09.690814 18604 solver.cpp:397]     Test net output #1: loss = 1.34029 (* 1 = 1.34029 loss)
I1107 22:30:09.746812 18604 solver.cpp:218] Iteration 130500 (13.6754 iter/s, 7.31238s/100 iters), loss = 0.23078
I1107 22:30:09.746812 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:30:09.746812 18604 solver.cpp:237]     Train net output #1: loss = 0.23078 (* 1 = 0.23078 loss)
I1107 22:30:09.746812 18604 sgd_solver.cpp:105] Iteration 130500, lr = 0.001
I1107 22:30:15.631604 18604 solver.cpp:218] Iteration 130600 (16.9956 iter/s, 5.88389s/100 iters), loss = 0.261573
I1107 22:30:15.631604 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:30:15.631604 18604 solver.cpp:237]     Train net output #1: loss = 0.261573 (* 1 = 0.261573 loss)
I1107 22:30:15.631604 18604 sgd_solver.cpp:105] Iteration 130600, lr = 0.001
I1107 22:30:21.529573 18604 solver.cpp:218] Iteration 130700 (16.956 iter/s, 5.89761s/100 iters), loss = 0.201674
I1107 22:30:21.530074 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:30:21.530074 18604 solver.cpp:237]     Train net output #1: loss = 0.201674 (* 1 = 0.201674 loss)
I1107 22:30:21.530074 18604 sgd_solver.cpp:105] Iteration 130700, lr = 0.001
I1107 22:30:27.476536 18604 solver.cpp:218] Iteration 130800 (16.816 iter/s, 5.94672s/100 iters), loss = 0.299143
I1107 22:30:27.476536 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:30:27.476536 18604 solver.cpp:237]     Train net output #1: loss = 0.299143 (* 1 = 0.299143 loss)
I1107 22:30:27.476536 18604 sgd_solver.cpp:105] Iteration 130800, lr = 0.001
I1107 22:30:33.385946 18604 solver.cpp:218] Iteration 130900 (16.9249 iter/s, 5.90844s/100 iters), loss = 0.333557
I1107 22:30:33.385946 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:30:33.385946 18604 solver.cpp:237]     Train net output #1: loss = 0.333557 (* 1 = 0.333557 loss)
I1107 22:30:33.385946 18604 sgd_solver.cpp:105] Iteration 130900, lr = 0.001
I1107 22:30:39.026360  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:30:39.267388 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_131000.caffemodel
I1107 22:30:39.282387 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_131000.solverstate
I1107 22:30:39.287387 18604 solver.cpp:330] Iteration 131000, Testing net (#0)
I1107 22:30:39.287387 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:30:40.616539 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:30:40.669546 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6686
I1107 22:30:40.669546 18604 solver.cpp:397]     Test net output #1: loss = 1.33141 (* 1 = 1.33141 loss)
I1107 22:30:40.728049 18604 solver.cpp:218] Iteration 131000 (13.6202 iter/s, 7.34201s/100 iters), loss = 0.302388
I1107 22:30:40.728550 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:30:40.728550 18604 solver.cpp:237]     Train net output #1: loss = 0.302388 (* 1 = 0.302388 loss)
I1107 22:30:40.728550 18604 sgd_solver.cpp:105] Iteration 131000, lr = 0.001
I1107 22:30:46.681977 18604 solver.cpp:218] Iteration 131100 (16.7959 iter/s, 5.95385s/100 iters), loss = 0.275711
I1107 22:30:46.682976 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:30:46.682976 18604 solver.cpp:237]     Train net output #1: loss = 0.275711 (* 1 = 0.275711 loss)
I1107 22:30:46.682976 18604 sgd_solver.cpp:105] Iteration 131100, lr = 0.001
I1107 22:30:52.621481 18604 solver.cpp:218] Iteration 131200 (16.8398 iter/s, 5.93833s/100 iters), loss = 0.243978
I1107 22:30:52.621481 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:30:52.621481 18604 solver.cpp:237]     Train net output #1: loss = 0.243978 (* 1 = 0.243978 loss)
I1107 22:30:52.621481 18604 sgd_solver.cpp:105] Iteration 131200, lr = 0.001
I1107 22:30:58.533373 18604 solver.cpp:218] Iteration 131300 (16.9147 iter/s, 5.91201s/100 iters), loss = 0.374341
I1107 22:30:58.533373 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:30:58.533373 18604 solver.cpp:237]     Train net output #1: loss = 0.374341 (* 1 = 0.374341 loss)
I1107 22:30:58.533373 18604 sgd_solver.cpp:105] Iteration 131300, lr = 0.001
I1107 22:31:04.472170 18604 solver.cpp:218] Iteration 131400 (16.8407 iter/s, 5.93801s/100 iters), loss = 0.409096
I1107 22:31:04.472170 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:31:04.472170 18604 solver.cpp:237]     Train net output #1: loss = 0.409096 (* 1 = 0.409096 loss)
I1107 22:31:04.472170 18604 sgd_solver.cpp:105] Iteration 131400, lr = 0.001
I1107 22:31:10.127697  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:31:10.360720 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_131500.caffemodel
I1107 22:31:10.376720 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_131500.solverstate
I1107 22:31:10.380720 18604 solver.cpp:330] Iteration 131500, Testing net (#0)
I1107 22:31:10.380720 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:31:11.677894 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:31:11.728899 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6708
I1107 22:31:11.728899 18604 solver.cpp:397]     Test net output #1: loss = 1.3302 (* 1 = 1.3302 loss)
I1107 22:31:11.784896 18604 solver.cpp:218] Iteration 131500 (13.6763 iter/s, 7.31194s/100 iters), loss = 0.328019
I1107 22:31:11.784896 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:31:11.784896 18604 solver.cpp:237]     Train net output #1: loss = 0.328019 (* 1 = 0.328019 loss)
I1107 22:31:11.784896 18604 sgd_solver.cpp:105] Iteration 131500, lr = 0.001
I1107 22:31:17.685519 18604 solver.cpp:218] Iteration 131600 (16.948 iter/s, 5.9004s/100 iters), loss = 0.308869
I1107 22:31:17.685519 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:31:17.685519 18604 solver.cpp:237]     Train net output #1: loss = 0.308869 (* 1 = 0.308869 loss)
I1107 22:31:17.685519 18604 sgd_solver.cpp:105] Iteration 131600, lr = 0.001
I1107 22:31:23.634948 18604 solver.cpp:218] Iteration 131700 (16.81 iter/s, 5.94885s/100 iters), loss = 0.25784
I1107 22:31:23.634948 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:31:23.634948 18604 solver.cpp:237]     Train net output #1: loss = 0.25784 (* 1 = 0.25784 loss)
I1107 22:31:23.634948 18604 sgd_solver.cpp:105] Iteration 131700, lr = 0.001
I1107 22:31:29.616394 18604 solver.cpp:218] Iteration 131800 (16.7192 iter/s, 5.98113s/100 iters), loss = 0.335462
I1107 22:31:29.616394 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:31:29.616394 18604 solver.cpp:237]     Train net output #1: loss = 0.335461 (* 1 = 0.335461 loss)
I1107 22:31:29.616394 18604 sgd_solver.cpp:105] Iteration 131800, lr = 0.001
I1107 22:31:35.495898 18604 solver.cpp:218] Iteration 131900 (17.0103 iter/s, 5.87878s/100 iters), loss = 0.340739
I1107 22:31:35.495898 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:31:35.495898 18604 solver.cpp:237]     Train net output #1: loss = 0.340739 (* 1 = 0.340739 loss)
I1107 22:31:35.495898 18604 sgd_solver.cpp:105] Iteration 131900, lr = 0.001
I1107 22:31:41.101604  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:31:41.332242 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_132000.caffemodel
I1107 22:31:41.347240 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_132000.solverstate
I1107 22:31:41.351240 18604 solver.cpp:330] Iteration 132000, Testing net (#0)
I1107 22:31:41.351240 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:31:42.647115 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:31:42.697113 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6689
I1107 22:31:42.698112 18604 solver.cpp:397]     Test net output #1: loss = 1.33998 (* 1 = 1.33998 loss)
I1107 22:31:42.754133 18604 solver.cpp:218] Iteration 132000 (13.778 iter/s, 7.25797s/100 iters), loss = 0.244202
I1107 22:31:42.754133 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:31:42.754133 18604 solver.cpp:237]     Train net output #1: loss = 0.244202 (* 1 = 0.244202 loss)
I1107 22:31:42.754133 18604 sgd_solver.cpp:105] Iteration 132000, lr = 0.001
I1107 22:31:48.646155 18604 solver.cpp:218] Iteration 132100 (16.9729 iter/s, 5.89176s/100 iters), loss = 0.300983
I1107 22:31:48.646155 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:31:48.646155 18604 solver.cpp:237]     Train net output #1: loss = 0.300982 (* 1 = 0.300982 loss)
I1107 22:31:48.646155 18604 sgd_solver.cpp:105] Iteration 132100, lr = 0.001
I1107 22:31:54.539630 18604 solver.cpp:218] Iteration 132200 (16.9691 iter/s, 5.89305s/100 iters), loss = 0.248569
I1107 22:31:54.539630 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:31:54.539630 18604 solver.cpp:237]     Train net output #1: loss = 0.248569 (* 1 = 0.248569 loss)
I1107 22:31:54.539630 18604 sgd_solver.cpp:105] Iteration 132200, lr = 0.001
I1107 22:32:00.445072 18604 solver.cpp:218] Iteration 132300 (16.9346 iter/s, 5.90507s/100 iters), loss = 0.347638
I1107 22:32:00.445072 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:32:00.445072 18604 solver.cpp:237]     Train net output #1: loss = 0.347638 (* 1 = 0.347638 loss)
I1107 22:32:00.445072 18604 sgd_solver.cpp:105] Iteration 132300, lr = 0.001
I1107 22:32:06.420375 18604 solver.cpp:218] Iteration 132400 (16.7374 iter/s, 5.97464s/100 iters), loss = 0.353593
I1107 22:32:06.420375 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:32:06.420375 18604 solver.cpp:237]     Train net output #1: loss = 0.353593 (* 1 = 0.353593 loss)
I1107 22:32:06.420375 18604 sgd_solver.cpp:105] Iteration 132400, lr = 0.001
I1107 22:32:12.090232  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:32:12.323251 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_132500.caffemodel
I1107 22:32:12.339251 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_132500.solverstate
I1107 22:32:12.344251 18604 solver.cpp:330] Iteration 132500, Testing net (#0)
I1107 22:32:12.344251 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:32:13.639400 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:32:13.690405 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6683
I1107 22:32:13.690405 18604 solver.cpp:397]     Test net output #1: loss = 1.34352 (* 1 = 1.34352 loss)
I1107 22:32:13.746404 18604 solver.cpp:218] Iteration 132500 (13.6503 iter/s, 7.32586s/100 iters), loss = 0.229346
I1107 22:32:13.746404 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:32:13.746404 18604 solver.cpp:237]     Train net output #1: loss = 0.229346 (* 1 = 0.229346 loss)
I1107 22:32:13.746404 18604 sgd_solver.cpp:105] Iteration 132500, lr = 0.001
I1107 22:32:19.642844 18604 solver.cpp:218] Iteration 132600 (16.9602 iter/s, 5.89617s/100 iters), loss = 0.282771
I1107 22:32:19.642844 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:32:19.642844 18604 solver.cpp:237]     Train net output #1: loss = 0.282771 (* 1 = 0.282771 loss)
I1107 22:32:19.642844 18604 sgd_solver.cpp:105] Iteration 132600, lr = 0.001
I1107 22:32:25.530200 18604 solver.cpp:218] Iteration 132700 (16.9864 iter/s, 5.88705s/100 iters), loss = 0.191914
I1107 22:32:25.530200 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:32:25.530200 18604 solver.cpp:237]     Train net output #1: loss = 0.191914 (* 1 = 0.191914 loss)
I1107 22:32:25.530200 18604 sgd_solver.cpp:105] Iteration 132700, lr = 0.001
I1107 22:32:31.420567 18604 solver.cpp:218] Iteration 132800 (16.9791 iter/s, 5.88961s/100 iters), loss = 0.359579
I1107 22:32:31.420567 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:32:31.420567 18604 solver.cpp:237]     Train net output #1: loss = 0.359579 (* 1 = 0.359579 loss)
I1107 22:32:31.420567 18604 sgd_solver.cpp:105] Iteration 132800, lr = 0.001
I1107 22:32:37.312744 18604 solver.cpp:218] Iteration 132900 (16.9751 iter/s, 5.89099s/100 iters), loss = 0.280877
I1107 22:32:37.312744 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:32:37.312744 18604 solver.cpp:237]     Train net output #1: loss = 0.280876 (* 1 = 0.280876 loss)
I1107 22:32:37.312744 18604 sgd_solver.cpp:105] Iteration 132900, lr = 0.001
I1107 22:32:42.919126  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:32:43.150637 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_133000.caffemodel
I1107 22:32:43.166637 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_133000.solverstate
I1107 22:32:43.171636 18604 solver.cpp:330] Iteration 133000, Testing net (#0)
I1107 22:32:43.171636 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:32:44.465914 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:32:44.516916 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6669
I1107 22:32:44.517416 18604 solver.cpp:397]     Test net output #1: loss = 1.33034 (* 1 = 1.33034 loss)
I1107 22:32:44.572918 18604 solver.cpp:218] Iteration 133000 (13.7746 iter/s, 7.25974s/100 iters), loss = 0.309753
I1107 22:32:44.572918 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:32:44.572918 18604 solver.cpp:237]     Train net output #1: loss = 0.309753 (* 1 = 0.309753 loss)
I1107 22:32:44.572918 18604 sgd_solver.cpp:105] Iteration 133000, lr = 0.001
I1107 22:32:50.456331 18604 solver.cpp:218] Iteration 133100 (16.9966 iter/s, 5.88352s/100 iters), loss = 0.314502
I1107 22:32:50.456331 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:32:50.456331 18604 solver.cpp:237]     Train net output #1: loss = 0.314502 (* 1 = 0.314502 loss)
I1107 22:32:50.456331 18604 sgd_solver.cpp:105] Iteration 133100, lr = 0.001
I1107 22:32:56.392796 18604 solver.cpp:218] Iteration 133200 (16.8479 iter/s, 5.93545s/100 iters), loss = 0.223575
I1107 22:32:56.392796 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:32:56.392796 18604 solver.cpp:237]     Train net output #1: loss = 0.223575 (* 1 = 0.223575 loss)
I1107 22:32:56.392796 18604 sgd_solver.cpp:105] Iteration 133200, lr = 0.001
I1107 22:33:02.313652 18604 solver.cpp:218] Iteration 133300 (16.8911 iter/s, 5.92027s/100 iters), loss = 0.383532
I1107 22:33:02.313652 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:33:02.313652 18604 solver.cpp:237]     Train net output #1: loss = 0.383531 (* 1 = 0.383531 loss)
I1107 22:33:02.313652 18604 sgd_solver.cpp:105] Iteration 133300, lr = 0.001
I1107 22:33:08.237149 18604 solver.cpp:218] Iteration 133400 (16.8811 iter/s, 5.92379s/100 iters), loss = 0.351028
I1107 22:33:08.238148 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:33:08.238148 18604 solver.cpp:237]     Train net output #1: loss = 0.351028 (* 1 = 0.351028 loss)
I1107 22:33:08.238148 18604 sgd_solver.cpp:105] Iteration 133400, lr = 0.001
I1107 22:33:13.856055  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:33:14.088572 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_133500.caffemodel
I1107 22:33:14.103572 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_133500.solverstate
I1107 22:33:14.107571 18604 solver.cpp:330] Iteration 133500, Testing net (#0)
I1107 22:33:14.107571 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:33:15.411676 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:33:15.464685 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6689
I1107 22:33:15.464685 18604 solver.cpp:397]     Test net output #1: loss = 1.35223 (* 1 = 1.35223 loss)
I1107 22:33:15.523705 18604 solver.cpp:218] Iteration 133500 (13.7255 iter/s, 7.28568s/100 iters), loss = 0.246319
I1107 22:33:15.523705 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:33:15.523705 18604 solver.cpp:237]     Train net output #1: loss = 0.246319 (* 1 = 0.246319 loss)
I1107 22:33:15.523705 18604 sgd_solver.cpp:105] Iteration 133500, lr = 0.001
I1107 22:33:21.434209 18604 solver.cpp:218] Iteration 133600 (16.9217 iter/s, 5.90957s/100 iters), loss = 0.311811
I1107 22:33:21.434209 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:33:21.434209 18604 solver.cpp:237]     Train net output #1: loss = 0.311811 (* 1 = 0.311811 loss)
I1107 22:33:21.434209 18604 sgd_solver.cpp:105] Iteration 133600, lr = 0.001
I1107 22:33:27.356083 18604 solver.cpp:218] Iteration 133700 (16.8871 iter/s, 5.92167s/100 iters), loss = 0.296324
I1107 22:33:27.356083 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:33:27.356083 18604 solver.cpp:237]     Train net output #1: loss = 0.296324 (* 1 = 0.296324 loss)
I1107 22:33:27.356083 18604 sgd_solver.cpp:105] Iteration 133700, lr = 0.001
I1107 22:33:33.261054 18604 solver.cpp:218] Iteration 133800 (16.9358 iter/s, 5.90467s/100 iters), loss = 0.299121
I1107 22:33:33.261054 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:33:33.261054 18604 solver.cpp:237]     Train net output #1: loss = 0.299121 (* 1 = 0.299121 loss)
I1107 22:33:33.261054 18604 sgd_solver.cpp:105] Iteration 133800, lr = 0.001
I1107 22:33:39.171490 18604 solver.cpp:218] Iteration 133900 (16.9201 iter/s, 5.91012s/100 iters), loss = 0.340336
I1107 22:33:39.171490 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:33:39.171490 18604 solver.cpp:237]     Train net output #1: loss = 0.340336 (* 1 = 0.340336 loss)
I1107 22:33:39.171490 18604 sgd_solver.cpp:105] Iteration 133900, lr = 0.001
I1107 22:33:44.797153  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:33:45.028177 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_134000.caffemodel
I1107 22:33:45.048171 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_134000.solverstate
I1107 22:33:45.053675 18604 solver.cpp:330] Iteration 134000, Testing net (#0)
I1107 22:33:45.053675 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:33:46.348254 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:33:46.399268 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6661
I1107 22:33:46.399268 18604 solver.cpp:397]     Test net output #1: loss = 1.34952 (* 1 = 1.34952 loss)
I1107 22:33:46.455761 18604 solver.cpp:218] Iteration 134000 (13.7297 iter/s, 7.28348s/100 iters), loss = 0.221735
I1107 22:33:46.455761 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:33:46.455761 18604 solver.cpp:237]     Train net output #1: loss = 0.221735 (* 1 = 0.221735 loss)
I1107 22:33:46.455761 18604 sgd_solver.cpp:105] Iteration 134000, lr = 0.001
I1107 22:33:52.339601 18604 solver.cpp:218] Iteration 134100 (16.996 iter/s, 5.88373s/100 iters), loss = 0.330382
I1107 22:33:52.339601 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:33:52.339601 18604 solver.cpp:237]     Train net output #1: loss = 0.330382 (* 1 = 0.330382 loss)
I1107 22:33:52.339601 18604 sgd_solver.cpp:105] Iteration 134100, lr = 0.001
I1107 22:33:58.268555 18604 solver.cpp:218] Iteration 134200 (16.868 iter/s, 5.92839s/100 iters), loss = 0.195055
I1107 22:33:58.268555 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:33:58.268555 18604 solver.cpp:237]     Train net output #1: loss = 0.195055 (* 1 = 0.195055 loss)
I1107 22:33:58.268555 18604 sgd_solver.cpp:105] Iteration 134200, lr = 0.001
I1107 22:34:04.161504 18604 solver.cpp:218] Iteration 134300 (16.9709 iter/s, 5.89244s/100 iters), loss = 0.322052
I1107 22:34:04.161504 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:34:04.161504 18604 solver.cpp:237]     Train net output #1: loss = 0.322052 (* 1 = 0.322052 loss)
I1107 22:34:04.161504 18604 sgd_solver.cpp:105] Iteration 134300, lr = 0.001
I1107 22:34:10.067440 18604 solver.cpp:218] Iteration 134400 (16.9338 iter/s, 5.90536s/100 iters), loss = 0.375092
I1107 22:34:10.067440 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:34:10.067440 18604 solver.cpp:237]     Train net output #1: loss = 0.375092 (* 1 = 0.375092 loss)
I1107 22:34:10.067440 18604 sgd_solver.cpp:105] Iteration 134400, lr = 0.001
I1107 22:34:15.705310  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:34:15.938503 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_134500.caffemodel
I1107 22:34:15.952500 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_134500.solverstate
I1107 22:34:15.957500 18604 solver.cpp:330] Iteration 134500, Testing net (#0)
I1107 22:34:15.957500 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:34:17.254350 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:34:17.304360 18604 solver.cpp:397]     Test net output #0: accuracy = 0.667
I1107 22:34:17.304360 18604 solver.cpp:397]     Test net output #1: loss = 1.34989 (* 1 = 1.34989 loss)
I1107 22:34:17.362360 18604 solver.cpp:218] Iteration 134500 (13.7093 iter/s, 7.29432s/100 iters), loss = 0.256915
I1107 22:34:17.362360 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:34:17.362360 18604 solver.cpp:237]     Train net output #1: loss = 0.256915 (* 1 = 0.256915 loss)
I1107 22:34:17.362360 18604 sgd_solver.cpp:105] Iteration 134500, lr = 0.001
I1107 22:34:23.248086 18604 solver.cpp:218] Iteration 134600 (16.9901 iter/s, 5.8858s/100 iters), loss = 0.345525
I1107 22:34:23.248086 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:34:23.248086 18604 solver.cpp:237]     Train net output #1: loss = 0.345525 (* 1 = 0.345525 loss)
I1107 22:34:23.248086 18604 sgd_solver.cpp:105] Iteration 134600, lr = 0.001
I1107 22:34:29.126621 18604 solver.cpp:218] Iteration 134700 (17.0119 iter/s, 5.87824s/100 iters), loss = 0.212806
I1107 22:34:29.126621 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:34:29.126621 18604 solver.cpp:237]     Train net output #1: loss = 0.212806 (* 1 = 0.212806 loss)
I1107 22:34:29.126621 18604 sgd_solver.cpp:105] Iteration 134700, lr = 0.001
I1107 22:34:35.002239 18604 solver.cpp:218] Iteration 134800 (17.0223 iter/s, 5.87466s/100 iters), loss = 0.285163
I1107 22:34:35.002239 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:34:35.002239 18604 solver.cpp:237]     Train net output #1: loss = 0.285163 (* 1 = 0.285163 loss)
I1107 22:34:35.002239 18604 sgd_solver.cpp:105] Iteration 134800, lr = 0.001
I1107 22:34:40.926669 18604 solver.cpp:218] Iteration 134900 (16.8793 iter/s, 5.92441s/100 iters), loss = 0.346052
I1107 22:34:40.926669 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:34:40.926669 18604 solver.cpp:237]     Train net output #1: loss = 0.346052 (* 1 = 0.346052 loss)
I1107 22:34:40.926669 18604 sgd_solver.cpp:105] Iteration 134900, lr = 0.001
I1107 22:34:46.540099  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:34:46.772613 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_135000.caffemodel
I1107 22:34:46.788115 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_135000.solverstate
I1107 22:34:46.793125 18604 solver.cpp:330] Iteration 135000, Testing net (#0)
I1107 22:34:46.793125 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:34:48.086194 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:34:48.137194 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6639
I1107 22:34:48.137194 18604 solver.cpp:397]     Test net output #1: loss = 1.35326 (* 1 = 1.35326 loss)
I1107 22:34:48.193198 18604 solver.cpp:218] Iteration 135000 (13.7634 iter/s, 7.26566s/100 iters), loss = 0.279705
I1107 22:34:48.193198 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:34:48.193198 18604 solver.cpp:237]     Train net output #1: loss = 0.279704 (* 1 = 0.279704 loss)
I1107 22:34:48.193198 18604 sgd_solver.cpp:105] Iteration 135000, lr = 0.001
I1107 22:34:54.106608 18604 solver.cpp:218] Iteration 135100 (16.9117 iter/s, 5.91307s/100 iters), loss = 0.280313
I1107 22:34:54.106608 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:34:54.106608 18604 solver.cpp:237]     Train net output #1: loss = 0.280313 (* 1 = 0.280313 loss)
I1107 22:34:54.106608 18604 sgd_solver.cpp:105] Iteration 135100, lr = 0.001
I1107 22:35:00.039434 18604 solver.cpp:218] Iteration 135200 (16.8562 iter/s, 5.93252s/100 iters), loss = 0.243792
I1107 22:35:00.039434 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:35:00.039434 18604 solver.cpp:237]     Train net output #1: loss = 0.243792 (* 1 = 0.243792 loss)
I1107 22:35:00.039932 18604 sgd_solver.cpp:105] Iteration 135200, lr = 0.001
I1107 22:35:05.932929 18604 solver.cpp:218] Iteration 135300 (16.9701 iter/s, 5.89272s/100 iters), loss = 0.297795
I1107 22:35:05.932929 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:35:05.932929 18604 solver.cpp:237]     Train net output #1: loss = 0.297795 (* 1 = 0.297795 loss)
I1107 22:35:05.932929 18604 sgd_solver.cpp:105] Iteration 135300, lr = 0.001
I1107 22:35:11.867497 18604 solver.cpp:218] Iteration 135400 (16.8506 iter/s, 5.93451s/100 iters), loss = 0.340681
I1107 22:35:11.867497 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:35:11.867497 18604 solver.cpp:237]     Train net output #1: loss = 0.34068 (* 1 = 0.34068 loss)
I1107 22:35:11.867497 18604 sgd_solver.cpp:105] Iteration 135400, lr = 0.001
I1107 22:35:17.502652  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:35:17.734274 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_135500.caffemodel
I1107 22:35:17.749280 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_135500.solverstate
I1107 22:35:17.753270 18604 solver.cpp:330] Iteration 135500, Testing net (#0)
I1107 22:35:17.754276 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:35:19.047665 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:35:19.098666 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6693
I1107 22:35:19.098666 18604 solver.cpp:397]     Test net output #1: loss = 1.35026 (* 1 = 1.35026 loss)
I1107 22:35:19.155689 18604 solver.cpp:218] Iteration 135500 (13.7222 iter/s, 7.28748s/100 iters), loss = 0.207966
I1107 22:35:19.155689 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:35:19.155689 18604 solver.cpp:237]     Train net output #1: loss = 0.207966 (* 1 = 0.207966 loss)
I1107 22:35:19.155689 18604 sgd_solver.cpp:105] Iteration 135500, lr = 0.001
I1107 22:35:25.071929 18604 solver.cpp:218] Iteration 135600 (16.9042 iter/s, 5.91569s/100 iters), loss = 0.303816
I1107 22:35:25.071929 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:35:25.071929 18604 solver.cpp:237]     Train net output #1: loss = 0.303816 (* 1 = 0.303816 loss)
I1107 22:35:25.071929 18604 sgd_solver.cpp:105] Iteration 135600, lr = 0.001
I1107 22:35:31.034456 18604 solver.cpp:218] Iteration 135700 (16.7711 iter/s, 5.96265s/100 iters), loss = 0.232283
I1107 22:35:31.034456 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:35:31.034456 18604 solver.cpp:237]     Train net output #1: loss = 0.232283 (* 1 = 0.232283 loss)
I1107 22:35:31.034456 18604 sgd_solver.cpp:105] Iteration 135700, lr = 0.001
I1107 22:35:36.958963 18604 solver.cpp:218] Iteration 135800 (16.88 iter/s, 5.92416s/100 iters), loss = 0.349775
I1107 22:35:36.958963 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:35:36.958963 18604 solver.cpp:237]     Train net output #1: loss = 0.349774 (* 1 = 0.349774 loss)
I1107 22:35:36.958963 18604 sgd_solver.cpp:105] Iteration 135800, lr = 0.001
I1107 22:35:42.959514 18604 solver.cpp:218] Iteration 135900 (16.6659 iter/s, 6.00029s/100 iters), loss = 0.415391
I1107 22:35:42.959514 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1107 22:35:42.959514 18604 solver.cpp:237]     Train net output #1: loss = 0.415391 (* 1 = 0.415391 loss)
I1107 22:35:42.960515 18604 sgd_solver.cpp:105] Iteration 135900, lr = 0.001
I1107 22:35:48.657034  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:35:48.892045 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_136000.caffemodel
I1107 22:35:48.908051 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_136000.solverstate
I1107 22:35:48.913552 18604 solver.cpp:330] Iteration 136000, Testing net (#0)
I1107 22:35:48.913552 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:35:50.218180 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:35:50.269182 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6626
I1107 22:35:50.269182 18604 solver.cpp:397]     Test net output #1: loss = 1.35276 (* 1 = 1.35276 loss)
I1107 22:35:50.326189 18604 solver.cpp:218] Iteration 136000 (13.5765 iter/s, 7.36564s/100 iters), loss = 0.259921
I1107 22:35:50.326189 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:35:50.326189 18604 solver.cpp:237]     Train net output #1: loss = 0.259921 (* 1 = 0.259921 loss)
I1107 22:35:50.326189 18604 sgd_solver.cpp:105] Iteration 136000, lr = 0.001
I1107 22:35:56.297758 18604 solver.cpp:218] Iteration 136100 (16.747 iter/s, 5.97122s/100 iters), loss = 0.349538
I1107 22:35:56.297758 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:35:56.297758 18604 solver.cpp:237]     Train net output #1: loss = 0.349538 (* 1 = 0.349538 loss)
I1107 22:35:56.297758 18604 sgd_solver.cpp:105] Iteration 136100, lr = 0.001
I1107 22:36:02.219657 18604 solver.cpp:218] Iteration 136200 (16.8888 iter/s, 5.92109s/100 iters), loss = 0.218867
I1107 22:36:02.219657 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:36:02.219657 18604 solver.cpp:237]     Train net output #1: loss = 0.218867 (* 1 = 0.218867 loss)
I1107 22:36:02.219657 18604 sgd_solver.cpp:105] Iteration 136200, lr = 0.001
I1107 22:36:08.184537 18604 solver.cpp:218] Iteration 136300 (16.7642 iter/s, 5.9651s/100 iters), loss = 0.267053
I1107 22:36:08.184537 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:36:08.184537 18604 solver.cpp:237]     Train net output #1: loss = 0.267053 (* 1 = 0.267053 loss)
I1107 22:36:08.184537 18604 sgd_solver.cpp:105] Iteration 136300, lr = 0.001
I1107 22:36:14.101517 18604 solver.cpp:218] Iteration 136400 (16.902 iter/s, 5.91645s/100 iters), loss = 0.328355
I1107 22:36:14.101517 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:36:14.101517 18604 solver.cpp:237]     Train net output #1: loss = 0.328355 (* 1 = 0.328355 loss)
I1107 22:36:14.101517 18604 sgd_solver.cpp:105] Iteration 136400, lr = 0.001
I1107 22:36:19.723619  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:36:19.955199 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_136500.caffemodel
I1107 22:36:19.969202 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_136500.solverstate
I1107 22:36:19.974201 18604 solver.cpp:330] Iteration 136500, Testing net (#0)
I1107 22:36:19.974201 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:36:21.272269 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:36:21.324275 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6635
I1107 22:36:21.324275 18604 solver.cpp:397]     Test net output #1: loss = 1.35162 (* 1 = 1.35162 loss)
I1107 22:36:21.380280 18604 solver.cpp:218] Iteration 136500 (13.7391 iter/s, 7.2785s/100 iters), loss = 0.268664
I1107 22:36:21.380280 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:36:21.380280 18604 solver.cpp:237]     Train net output #1: loss = 0.268664 (* 1 = 0.268664 loss)
I1107 22:36:21.380280 18604 sgd_solver.cpp:105] Iteration 136500, lr = 0.001
I1107 22:36:27.262794 18604 solver.cpp:218] Iteration 136600 (17.002 iter/s, 5.88164s/100 iters), loss = 0.306883
I1107 22:36:27.262794 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:36:27.262794 18604 solver.cpp:237]     Train net output #1: loss = 0.306883 (* 1 = 0.306883 loss)
I1107 22:36:27.262794 18604 sgd_solver.cpp:105] Iteration 136600, lr = 0.001
I1107 22:36:33.153266 18604 solver.cpp:218] Iteration 136700 (16.9783 iter/s, 5.88986s/100 iters), loss = 0.208126
I1107 22:36:33.153266 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:36:33.153266 18604 solver.cpp:237]     Train net output #1: loss = 0.208126 (* 1 = 0.208126 loss)
I1107 22:36:33.153266 18604 sgd_solver.cpp:105] Iteration 136700, lr = 0.001
I1107 22:36:39.046545 18604 solver.cpp:218] Iteration 136800 (16.9681 iter/s, 5.89341s/100 iters), loss = 0.386767
I1107 22:36:39.046545 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:36:39.046545 18604 solver.cpp:237]     Train net output #1: loss = 0.386766 (* 1 = 0.386766 loss)
I1107 22:36:39.046545 18604 sgd_solver.cpp:105] Iteration 136800, lr = 0.001
I1107 22:36:44.923570 18604 solver.cpp:218] Iteration 136900 (17.0178 iter/s, 5.87621s/100 iters), loss = 0.318478
I1107 22:36:44.923570 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:36:44.923570 18604 solver.cpp:237]     Train net output #1: loss = 0.318478 (* 1 = 0.318478 loss)
I1107 22:36:44.923570 18604 sgd_solver.cpp:105] Iteration 136900, lr = 0.001
I1107 22:36:50.519093  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:36:50.752105 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_137000.caffemodel
I1107 22:36:50.766605 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_137000.solverstate
I1107 22:36:50.771605 18604 solver.cpp:330] Iteration 137000, Testing net (#0)
I1107 22:36:50.771605 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:36:52.076114 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:36:52.128124 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6635
I1107 22:36:52.128124 18604 solver.cpp:397]     Test net output #1: loss = 1.36666 (* 1 = 1.36666 loss)
I1107 22:36:52.184123 18604 solver.cpp:218] Iteration 137000 (13.7736 iter/s, 7.26028s/100 iters), loss = 0.20404
I1107 22:36:52.184123 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:36:52.184123 18604 solver.cpp:237]     Train net output #1: loss = 0.20404 (* 1 = 0.20404 loss)
I1107 22:36:52.184123 18604 sgd_solver.cpp:105] Iteration 137000, lr = 0.001
I1107 22:36:58.061511 18604 solver.cpp:218] Iteration 137100 (17.0152 iter/s, 5.8771s/100 iters), loss = 0.326064
I1107 22:36:58.061511 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:36:58.061511 18604 solver.cpp:237]     Train net output #1: loss = 0.326063 (* 1 = 0.326063 loss)
I1107 22:36:58.061511 18604 sgd_solver.cpp:105] Iteration 137100, lr = 0.001
I1107 22:37:03.932633 18604 solver.cpp:218] Iteration 137200 (17.0329 iter/s, 5.87098s/100 iters), loss = 0.244769
I1107 22:37:03.932633 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:37:03.932633 18604 solver.cpp:237]     Train net output #1: loss = 0.244768 (* 1 = 0.244768 loss)
I1107 22:37:03.932633 18604 sgd_solver.cpp:105] Iteration 137200, lr = 0.001
I1107 22:37:09.846226 18604 solver.cpp:218] Iteration 137300 (16.9137 iter/s, 5.91238s/100 iters), loss = 0.270425
I1107 22:37:09.846226 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:37:09.846226 18604 solver.cpp:237]     Train net output #1: loss = 0.270425 (* 1 = 0.270425 loss)
I1107 22:37:09.846226 18604 sgd_solver.cpp:105] Iteration 137300, lr = 0.001
I1107 22:37:15.747700 18604 solver.cpp:218] Iteration 137400 (16.9457 iter/s, 5.9012s/100 iters), loss = 0.33911
I1107 22:37:15.747700 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:37:15.747700 18604 solver.cpp:237]     Train net output #1: loss = 0.33911 (* 1 = 0.33911 loss)
I1107 22:37:15.747700 18604 sgd_solver.cpp:105] Iteration 137400, lr = 0.001
I1107 22:37:21.397213  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:37:21.633234 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_137500.caffemodel
I1107 22:37:21.648737 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_137500.solverstate
I1107 22:37:21.653239 18604 solver.cpp:330] Iteration 137500, Testing net (#0)
I1107 22:37:21.653738 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:37:22.957363 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:37:23.007366 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6622
I1107 22:37:23.007366 18604 solver.cpp:397]     Test net output #1: loss = 1.36111 (* 1 = 1.36111 loss)
I1107 22:37:23.064368 18604 solver.cpp:218] Iteration 137500 (13.6674 iter/s, 7.31666s/100 iters), loss = 0.258524
I1107 22:37:23.064368 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:37:23.064368 18604 solver.cpp:237]     Train net output #1: loss = 0.258524 (* 1 = 0.258524 loss)
I1107 22:37:23.064368 18604 sgd_solver.cpp:105] Iteration 137500, lr = 0.001
I1107 22:37:28.988430 18604 solver.cpp:218] Iteration 137600 (16.8835 iter/s, 5.92296s/100 iters), loss = 0.244083
I1107 22:37:28.988430 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:37:28.988430 18604 solver.cpp:237]     Train net output #1: loss = 0.244083 (* 1 = 0.244083 loss)
I1107 22:37:28.988430 18604 sgd_solver.cpp:105] Iteration 137600, lr = 0.001
I1107 22:37:34.914289 18604 solver.cpp:218] Iteration 137700 (16.8754 iter/s, 5.92579s/100 iters), loss = 0.190061
I1107 22:37:34.914289 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:37:34.914289 18604 solver.cpp:237]     Train net output #1: loss = 0.190061 (* 1 = 0.190061 loss)
I1107 22:37:34.914289 18604 sgd_solver.cpp:105] Iteration 137700, lr = 0.001
I1107 22:37:40.820737 18604 solver.cpp:218] Iteration 137800 (16.9334 iter/s, 5.90547s/100 iters), loss = 0.309536
I1107 22:37:40.820737 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:37:40.820737 18604 solver.cpp:237]     Train net output #1: loss = 0.309536 (* 1 = 0.309536 loss)
I1107 22:37:40.820737 18604 sgd_solver.cpp:105] Iteration 137800, lr = 0.001
I1107 22:37:46.744807 18604 solver.cpp:218] Iteration 137900 (16.8803 iter/s, 5.92406s/100 iters), loss = 0.419837
I1107 22:37:46.744807 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:37:46.744807 18604 solver.cpp:237]     Train net output #1: loss = 0.419836 (* 1 = 0.419836 loss)
I1107 22:37:46.744807 18604 sgd_solver.cpp:105] Iteration 137900, lr = 0.001
I1107 22:37:52.388260  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:37:52.619285 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_138000.caffemodel
I1107 22:37:52.634285 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_138000.solverstate
I1107 22:37:52.638284 18604 solver.cpp:330] Iteration 138000, Testing net (#0)
I1107 22:37:52.639286 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:37:53.943408 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:37:53.994413 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6653
I1107 22:37:53.994413 18604 solver.cpp:397]     Test net output #1: loss = 1.37461 (* 1 = 1.37461 loss)
I1107 22:37:54.050925 18604 solver.cpp:218] Iteration 138000 (13.6887 iter/s, 7.30531s/100 iters), loss = 0.291633
I1107 22:37:54.050925 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:37:54.050925 18604 solver.cpp:237]     Train net output #1: loss = 0.291633 (* 1 = 0.291633 loss)
I1107 22:37:54.050925 18604 sgd_solver.cpp:105] Iteration 138000, lr = 0.001
I1107 22:37:59.945915 18604 solver.cpp:218] Iteration 138100 (16.9628 iter/s, 5.89524s/100 iters), loss = 0.354488
I1107 22:37:59.945915 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:37:59.945915 18604 solver.cpp:237]     Train net output #1: loss = 0.354488 (* 1 = 0.354488 loss)
I1107 22:37:59.945915 18604 sgd_solver.cpp:105] Iteration 138100, lr = 0.001
I1107 22:38:05.856840 18604 solver.cpp:218] Iteration 138200 (16.921 iter/s, 5.90983s/100 iters), loss = 0.233661
I1107 22:38:05.856840 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:38:05.856840 18604 solver.cpp:237]     Train net output #1: loss = 0.233661 (* 1 = 0.233661 loss)
I1107 22:38:05.856840 18604 sgd_solver.cpp:105] Iteration 138200, lr = 0.001
I1107 22:38:11.767877 18604 solver.cpp:218] Iteration 138300 (16.9172 iter/s, 5.91114s/100 iters), loss = 0.310186
I1107 22:38:11.767877 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:38:11.767877 18604 solver.cpp:237]     Train net output #1: loss = 0.310186 (* 1 = 0.310186 loss)
I1107 22:38:11.767877 18604 sgd_solver.cpp:105] Iteration 138300, lr = 0.001
I1107 22:38:17.672003 18604 solver.cpp:218] Iteration 138400 (16.9386 iter/s, 5.90368s/100 iters), loss = 0.31171
I1107 22:38:17.672003 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:38:17.672003 18604 solver.cpp:237]     Train net output #1: loss = 0.31171 (* 1 = 0.31171 loss)
I1107 22:38:17.672003 18604 sgd_solver.cpp:105] Iteration 138400, lr = 0.001
I1107 22:38:23.268767  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:38:23.499806 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_138500.caffemodel
I1107 22:38:23.515825 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_138500.solverstate
I1107 22:38:23.520807 18604 solver.cpp:330] Iteration 138500, Testing net (#0)
I1107 22:38:23.520807 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:38:24.821149 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:38:24.872658 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6663
I1107 22:38:24.872658 18604 solver.cpp:397]     Test net output #1: loss = 1.35147 (* 1 = 1.35147 loss)
I1107 22:38:24.930837 18604 solver.cpp:218] Iteration 138500 (13.7783 iter/s, 7.25778s/100 iters), loss = 0.26133
I1107 22:38:24.930837 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:38:24.930837 18604 solver.cpp:237]     Train net output #1: loss = 0.261329 (* 1 = 0.261329 loss)
I1107 22:38:24.930837 18604 sgd_solver.cpp:105] Iteration 138500, lr = 0.001
I1107 22:38:30.891911 18604 solver.cpp:218] Iteration 138600 (16.7758 iter/s, 5.96096s/100 iters), loss = 0.298085
I1107 22:38:30.891911 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:38:30.891911 18604 solver.cpp:237]     Train net output #1: loss = 0.298085 (* 1 = 0.298085 loss)
I1107 22:38:30.891911 18604 sgd_solver.cpp:105] Iteration 138600, lr = 0.001
I1107 22:38:36.843024 18604 solver.cpp:218] Iteration 138700 (16.8051 iter/s, 5.95056s/100 iters), loss = 0.287521
I1107 22:38:36.843024 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:38:36.843024 18604 solver.cpp:237]     Train net output #1: loss = 0.287521 (* 1 = 0.287521 loss)
I1107 22:38:36.843024 18604 sgd_solver.cpp:105] Iteration 138700, lr = 0.001
I1107 22:38:42.746187 18604 solver.cpp:218] Iteration 138800 (16.9418 iter/s, 5.90257s/100 iters), loss = 0.323297
I1107 22:38:42.746187 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:38:42.746187 18604 solver.cpp:237]     Train net output #1: loss = 0.323297 (* 1 = 0.323297 loss)
I1107 22:38:42.746187 18604 sgd_solver.cpp:105] Iteration 138800, lr = 0.001
I1107 22:38:48.608647 18604 solver.cpp:218] Iteration 138900 (17.0595 iter/s, 5.86184s/100 iters), loss = 0.250322
I1107 22:38:48.608647 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:38:48.608647 18604 solver.cpp:237]     Train net output #1: loss = 0.250322 (* 1 = 0.250322 loss)
I1107 22:38:48.608647 18604 sgd_solver.cpp:105] Iteration 138900, lr = 0.001
I1107 22:38:54.184984  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:38:54.415868 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_139000.caffemodel
I1107 22:38:54.431866 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_139000.solverstate
I1107 22:38:54.435868 18604 solver.cpp:330] Iteration 139000, Testing net (#0)
I1107 22:38:54.436868 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:38:55.727198 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:38:55.778704 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6658
I1107 22:38:55.778704 18604 solver.cpp:397]     Test net output #1: loss = 1.36418 (* 1 = 1.36418 loss)
I1107 22:38:55.834450 18604 solver.cpp:218] Iteration 139000 (13.8385 iter/s, 7.2262s/100 iters), loss = 0.20117
I1107 22:38:55.834450 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:38:55.834450 18604 solver.cpp:237]     Train net output #1: loss = 0.201169 (* 1 = 0.201169 loss)
I1107 22:38:55.835451 18604 sgd_solver.cpp:105] Iteration 139000, lr = 0.001
I1107 22:39:01.700649 18604 solver.cpp:218] Iteration 139100 (17.0493 iter/s, 5.86533s/100 iters), loss = 0.403113
I1107 22:39:01.700649 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:39:01.700649 18604 solver.cpp:237]     Train net output #1: loss = 0.403113 (* 1 = 0.403113 loss)
I1107 22:39:01.700649 18604 sgd_solver.cpp:105] Iteration 139100, lr = 0.001
I1107 22:39:07.569224 18604 solver.cpp:218] Iteration 139200 (17.0409 iter/s, 5.86824s/100 iters), loss = 0.196193
I1107 22:39:07.569224 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:39:07.569224 18604 solver.cpp:237]     Train net output #1: loss = 0.196193 (* 1 = 0.196193 loss)
I1107 22:39:07.569224 18604 sgd_solver.cpp:105] Iteration 139200, lr = 0.001
I1107 22:39:13.441143 18604 solver.cpp:218] Iteration 139300 (17.0307 iter/s, 5.87175s/100 iters), loss = 0.280499
I1107 22:39:13.441143 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:39:13.441143 18604 solver.cpp:237]     Train net output #1: loss = 0.280498 (* 1 = 0.280498 loss)
I1107 22:39:13.441143 18604 sgd_solver.cpp:105] Iteration 139300, lr = 0.001
I1107 22:39:19.323802 18604 solver.cpp:218] Iteration 139400 (17.0005 iter/s, 5.88217s/100 iters), loss = 0.294505
I1107 22:39:19.323802 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:39:19.323802 18604 solver.cpp:237]     Train net output #1: loss = 0.294505 (* 1 = 0.294505 loss)
I1107 22:39:19.323802 18604 sgd_solver.cpp:105] Iteration 139400, lr = 0.001
I1107 22:39:24.913774  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:39:25.144827 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_139500.caffemodel
I1107 22:39:25.158828 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_139500.solverstate
I1107 22:39:25.163828 18604 solver.cpp:330] Iteration 139500, Testing net (#0)
I1107 22:39:25.163828 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:39:26.457262 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:39:26.508297 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6652
I1107 22:39:26.508297 18604 solver.cpp:397]     Test net output #1: loss = 1.3614 (* 1 = 1.3614 loss)
I1107 22:39:26.564292 18604 solver.cpp:218] Iteration 139500 (13.8132 iter/s, 7.23943s/100 iters), loss = 0.236156
I1107 22:39:26.564292 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:39:26.564292 18604 solver.cpp:237]     Train net output #1: loss = 0.236156 (* 1 = 0.236156 loss)
I1107 22:39:26.564292 18604 sgd_solver.cpp:105] Iteration 139500, lr = 0.001
I1107 22:39:32.443852 18604 solver.cpp:218] Iteration 139600 (17.0073 iter/s, 5.87983s/100 iters), loss = 0.243317
I1107 22:39:32.443852 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:39:32.443852 18604 solver.cpp:237]     Train net output #1: loss = 0.243317 (* 1 = 0.243317 loss)
I1107 22:39:32.443852 18604 sgd_solver.cpp:105] Iteration 139600, lr = 0.001
I1107 22:39:38.315182 18604 solver.cpp:218] Iteration 139700 (17.0345 iter/s, 5.87045s/100 iters), loss = 0.210427
I1107 22:39:38.315182 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:39:38.315182 18604 solver.cpp:237]     Train net output #1: loss = 0.210427 (* 1 = 0.210427 loss)
I1107 22:39:38.315182 18604 sgd_solver.cpp:105] Iteration 139700, lr = 0.001
I1107 22:39:44.183065 18604 solver.cpp:218] Iteration 139800 (17.0436 iter/s, 5.86729s/100 iters), loss = 0.370976
I1107 22:39:44.183065 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:39:44.183065 18604 solver.cpp:237]     Train net output #1: loss = 0.370976 (* 1 = 0.370976 loss)
I1107 22:39:44.183065 18604 sgd_solver.cpp:105] Iteration 139800, lr = 0.001
I1107 22:39:50.073596 18604 solver.cpp:218] Iteration 139900 (16.9782 iter/s, 5.88991s/100 iters), loss = 0.236085
I1107 22:39:50.073596 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:39:50.073596 18604 solver.cpp:237]     Train net output #1: loss = 0.236084 (* 1 = 0.236084 loss)
I1107 22:39:50.073596 18604 sgd_solver.cpp:105] Iteration 139900, lr = 0.001
I1107 22:39:55.659158  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:39:55.890214 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_140000.caffemodel
I1107 22:39:55.904732 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_140000.solverstate
I1107 22:39:55.909252 18604 solver.cpp:330] Iteration 140000, Testing net (#0)
I1107 22:39:55.909252 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:39:57.204634 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:39:57.254650 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6651
I1107 22:39:57.254650 18604 solver.cpp:397]     Test net output #1: loss = 1.37706 (* 1 = 1.37706 loss)
I1107 22:39:57.310591 18604 solver.cpp:218] Iteration 140000 (13.8181 iter/s, 7.23689s/100 iters), loss = 0.23082
I1107 22:39:57.310591 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:39:57.310591 18604 solver.cpp:237]     Train net output #1: loss = 0.23082 (* 1 = 0.23082 loss)
I1107 22:39:57.310591 18604 sgd_solver.cpp:105] Iteration 140000, lr = 0.001
I1107 22:40:03.230509 18604 solver.cpp:218] Iteration 140100 (16.894 iter/s, 5.91928s/100 iters), loss = 0.284216
I1107 22:40:03.230509 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:40:03.230509 18604 solver.cpp:237]     Train net output #1: loss = 0.284216 (* 1 = 0.284216 loss)
I1107 22:40:03.230509 18604 sgd_solver.cpp:105] Iteration 140100, lr = 0.001
I1107 22:40:09.094440 18604 solver.cpp:218] Iteration 140200 (17.0543 iter/s, 5.86364s/100 iters), loss = 0.175334
I1107 22:40:09.094440 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:40:09.094440 18604 solver.cpp:237]     Train net output #1: loss = 0.175334 (* 1 = 0.175334 loss)
I1107 22:40:09.094440 18604 sgd_solver.cpp:105] Iteration 140200, lr = 0.001
I1107 22:40:14.948838 18604 solver.cpp:218] Iteration 140300 (17.0835 iter/s, 5.8536s/100 iters), loss = 0.31708
I1107 22:40:14.948838 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:40:14.948838 18604 solver.cpp:237]     Train net output #1: loss = 0.31708 (* 1 = 0.31708 loss)
I1107 22:40:14.948838 18604 sgd_solver.cpp:105] Iteration 140300, lr = 0.001
I1107 22:40:20.817251 18604 solver.cpp:218] Iteration 140400 (17.0412 iter/s, 5.86813s/100 iters), loss = 0.384196
I1107 22:40:20.817251 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:40:20.817251 18604 solver.cpp:237]     Train net output #1: loss = 0.384196 (* 1 = 0.384196 loss)
I1107 22:40:20.817251 18604 sgd_solver.cpp:105] Iteration 140400, lr = 0.001
I1107 22:40:26.412639  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:40:26.643668 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_140500.caffemodel
I1107 22:40:26.662669 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_140500.solverstate
I1107 22:40:26.667671 18604 solver.cpp:330] Iteration 140500, Testing net (#0)
I1107 22:40:26.667671 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:40:27.960763 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:40:28.010762 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6656
I1107 22:40:28.010762 18604 solver.cpp:397]     Test net output #1: loss = 1.3661 (* 1 = 1.3661 loss)
I1107 22:40:28.067770 18604 solver.cpp:218] Iteration 140500 (13.7929 iter/s, 7.25011s/100 iters), loss = 0.19839
I1107 22:40:28.067770 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:40:28.067770 18604 solver.cpp:237]     Train net output #1: loss = 0.198389 (* 1 = 0.198389 loss)
I1107 22:40:28.067770 18604 sgd_solver.cpp:105] Iteration 140500, lr = 0.001
I1107 22:40:33.936183 18604 solver.cpp:218] Iteration 140600 (17.0414 iter/s, 5.86807s/100 iters), loss = 0.34339
I1107 22:40:33.936183 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:40:33.936683 18604 solver.cpp:237]     Train net output #1: loss = 0.343389 (* 1 = 0.343389 loss)
I1107 22:40:33.936683 18604 sgd_solver.cpp:105] Iteration 140600, lr = 0.001
I1107 22:40:39.838536 18604 solver.cpp:218] Iteration 140700 (16.9443 iter/s, 5.9017s/100 iters), loss = 0.214127
I1107 22:40:39.838536 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:40:39.838536 18604 solver.cpp:237]     Train net output #1: loss = 0.214127 (* 1 = 0.214127 loss)
I1107 22:40:39.838536 18604 sgd_solver.cpp:105] Iteration 140700, lr = 0.001
I1107 22:40:45.706910 18604 solver.cpp:218] Iteration 140800 (17.04 iter/s, 5.86855s/100 iters), loss = 0.266636
I1107 22:40:45.706910 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:40:45.706910 18604 solver.cpp:237]     Train net output #1: loss = 0.266636 (* 1 = 0.266636 loss)
I1107 22:40:45.706910 18604 sgd_solver.cpp:105] Iteration 140800, lr = 0.001
I1107 22:40:51.569825 18604 solver.cpp:218] Iteration 140900 (17.0594 iter/s, 5.86187s/100 iters), loss = 0.321731
I1107 22:40:51.569825 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:40:51.569825 18604 solver.cpp:237]     Train net output #1: loss = 0.32173 (* 1 = 0.32173 loss)
I1107 22:40:51.569825 18604 sgd_solver.cpp:105] Iteration 140900, lr = 0.001
I1107 22:40:57.141700  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:40:57.372717 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_141000.caffemodel
I1107 22:40:57.388718 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_141000.solverstate
I1107 22:40:57.392717 18604 solver.cpp:330] Iteration 141000, Testing net (#0)
I1107 22:40:57.392717 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:40:58.686800 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:40:58.737804 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6636
I1107 22:40:58.737804 18604 solver.cpp:397]     Test net output #1: loss = 1.3805 (* 1 = 1.3805 loss)
I1107 22:40:58.794807 18604 solver.cpp:218] Iteration 141000 (13.8419 iter/s, 7.22444s/100 iters), loss = 0.245912
I1107 22:40:58.794807 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:40:58.794807 18604 solver.cpp:237]     Train net output #1: loss = 0.245912 (* 1 = 0.245912 loss)
I1107 22:40:58.794807 18604 sgd_solver.cpp:105] Iteration 141000, lr = 0.001
I1107 22:41:04.676223 18604 solver.cpp:218] Iteration 141100 (17.0016 iter/s, 5.88181s/100 iters), loss = 0.323715
I1107 22:41:04.676223 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:41:04.676223 18604 solver.cpp:237]     Train net output #1: loss = 0.323715 (* 1 = 0.323715 loss)
I1107 22:41:04.676223 18604 sgd_solver.cpp:105] Iteration 141100, lr = 0.001
I1107 22:41:10.555644 18604 solver.cpp:218] Iteration 141200 (17.0101 iter/s, 5.87885s/100 iters), loss = 0.233688
I1107 22:41:10.555644 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:41:10.555644 18604 solver.cpp:237]     Train net output #1: loss = 0.233688 (* 1 = 0.233688 loss)
I1107 22:41:10.555644 18604 sgd_solver.cpp:105] Iteration 141200, lr = 0.001
I1107 22:41:16.430089 18604 solver.cpp:218] Iteration 141300 (17.0242 iter/s, 5.87401s/100 iters), loss = 0.318839
I1107 22:41:16.430089 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:41:16.430089 18604 solver.cpp:237]     Train net output #1: loss = 0.318838 (* 1 = 0.318838 loss)
I1107 22:41:16.430089 18604 sgd_solver.cpp:105] Iteration 141300, lr = 0.001
I1107 22:41:22.387521 18604 solver.cpp:218] Iteration 141400 (16.7869 iter/s, 5.95703s/100 iters), loss = 0.327717
I1107 22:41:22.387521 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:41:22.387521 18604 solver.cpp:237]     Train net output #1: loss = 0.327717 (* 1 = 0.327717 loss)
I1107 22:41:22.387521 18604 sgd_solver.cpp:105] Iteration 141400, lr = 0.001
I1107 22:41:27.972885  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:41:28.208906 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_141500.caffemodel
I1107 22:41:28.224898 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_141500.solverstate
I1107 22:41:28.229898 18604 solver.cpp:330] Iteration 141500, Testing net (#0)
I1107 22:41:28.229898 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:41:29.526001 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:41:29.577008 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6618
I1107 22:41:29.577008 18604 solver.cpp:397]     Test net output #1: loss = 1.38931 (* 1 = 1.38931 loss)
I1107 22:41:29.633007 18604 solver.cpp:218] Iteration 141500 (13.8029 iter/s, 7.24485s/100 iters), loss = 0.209407
I1107 22:41:29.633007 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:41:29.633007 18604 solver.cpp:237]     Train net output #1: loss = 0.209407 (* 1 = 0.209407 loss)
I1107 22:41:29.633007 18604 sgd_solver.cpp:105] Iteration 141500, lr = 0.001
I1107 22:41:35.536418 18604 solver.cpp:218] Iteration 141600 (16.9401 iter/s, 5.90315s/100 iters), loss = 0.264178
I1107 22:41:35.536418 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:41:35.536418 18604 solver.cpp:237]     Train net output #1: loss = 0.264178 (* 1 = 0.264178 loss)
I1107 22:41:35.536418 18604 sgd_solver.cpp:105] Iteration 141600, lr = 0.001
I1107 22:41:41.493844 18604 solver.cpp:218] Iteration 141700 (16.7873 iter/s, 5.95688s/100 iters), loss = 0.190856
I1107 22:41:41.493844 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:41:41.493844 18604 solver.cpp:237]     Train net output #1: loss = 0.190856 (* 1 = 0.190856 loss)
I1107 22:41:41.493844 18604 sgd_solver.cpp:105] Iteration 141700, lr = 0.001
I1107 22:41:47.446297 18604 solver.cpp:218] Iteration 141800 (16.8007 iter/s, 5.95213s/100 iters), loss = 0.29277
I1107 22:41:47.446297 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:41:47.446297 18604 solver.cpp:237]     Train net output #1: loss = 0.292769 (* 1 = 0.292769 loss)
I1107 22:41:47.446297 18604 sgd_solver.cpp:105] Iteration 141800, lr = 0.001
I1107 22:41:53.364521 18604 solver.cpp:218] Iteration 141900 (16.8989 iter/s, 5.91755s/100 iters), loss = 0.337095
I1107 22:41:53.365020 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:41:53.365020 18604 solver.cpp:237]     Train net output #1: loss = 0.337095 (* 1 = 0.337095 loss)
I1107 22:41:53.365020 18604 sgd_solver.cpp:105] Iteration 141900, lr = 0.001
I1107 22:41:58.982982  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:41:59.216001 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_142000.caffemodel
I1107 22:41:59.231003 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_142000.solverstate
I1107 22:41:59.236004 18604 solver.cpp:330] Iteration 142000, Testing net (#0)
I1107 22:41:59.236004 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:42:00.537909 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:42:00.589916 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6654
I1107 22:42:00.589916 18604 solver.cpp:397]     Test net output #1: loss = 1.37669 (* 1 = 1.37669 loss)
I1107 22:42:00.646919 18604 solver.cpp:218] Iteration 142000 (13.7333 iter/s, 7.28157s/100 iters), loss = 0.225776
I1107 22:42:00.646919 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:42:00.646919 18604 solver.cpp:237]     Train net output #1: loss = 0.225776 (* 1 = 0.225776 loss)
I1107 22:42:00.646919 18604 sgd_solver.cpp:105] Iteration 142000, lr = 0.001
I1107 22:42:06.555896 18604 solver.cpp:218] Iteration 142100 (16.9239 iter/s, 5.9088s/100 iters), loss = 0.307525
I1107 22:42:06.555896 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:42:06.555896 18604 solver.cpp:237]     Train net output #1: loss = 0.307525 (* 1 = 0.307525 loss)
I1107 22:42:06.555896 18604 sgd_solver.cpp:105] Iteration 142100, lr = 0.001
I1107 22:42:12.466897 18604 solver.cpp:218] Iteration 142200 (16.9194 iter/s, 5.91037s/100 iters), loss = 0.199107
I1107 22:42:12.466897 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:42:12.466897 18604 solver.cpp:237]     Train net output #1: loss = 0.199107 (* 1 = 0.199107 loss)
I1107 22:42:12.466897 18604 sgd_solver.cpp:105] Iteration 142200, lr = 0.001
I1107 22:42:18.340876 18604 solver.cpp:218] Iteration 142300 (17.0233 iter/s, 5.87431s/100 iters), loss = 0.290468
I1107 22:42:18.340876 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:42:18.340876 18604 solver.cpp:237]     Train net output #1: loss = 0.290468 (* 1 = 0.290468 loss)
I1107 22:42:18.340876 18604 sgd_solver.cpp:105] Iteration 142300, lr = 0.001
I1107 22:42:24.235333 18604 solver.cpp:218] Iteration 142400 (16.967 iter/s, 5.89381s/100 iters), loss = 0.343551
I1107 22:42:24.235333 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:42:24.235333 18604 solver.cpp:237]     Train net output #1: loss = 0.343551 (* 1 = 0.343551 loss)
I1107 22:42:24.235333 18604 sgd_solver.cpp:105] Iteration 142400, lr = 0.001
I1107 22:42:29.838707  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:42:30.070221 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_142500.caffemodel
I1107 22:42:30.084728 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_142500.solverstate
I1107 22:42:30.088726 18604 solver.cpp:330] Iteration 142500, Testing net (#0)
I1107 22:42:30.089727 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:42:31.421849 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:42:31.474354 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6629
I1107 22:42:31.474354 18604 solver.cpp:397]     Test net output #1: loss = 1.36054 (* 1 = 1.36054 loss)
I1107 22:42:31.532858 18604 solver.cpp:218] Iteration 142500 (13.7047 iter/s, 7.29675s/100 iters), loss = 0.215491
I1107 22:42:31.532858 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:42:31.532858 18604 solver.cpp:237]     Train net output #1: loss = 0.21549 (* 1 = 0.21549 loss)
I1107 22:42:31.532858 18604 sgd_solver.cpp:105] Iteration 142500, lr = 0.001
I1107 22:42:37.465365 18604 solver.cpp:218] Iteration 142600 (16.8586 iter/s, 5.9317s/100 iters), loss = 0.262451
I1107 22:42:37.465365 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:42:37.465365 18604 solver.cpp:237]     Train net output #1: loss = 0.262451 (* 1 = 0.262451 loss)
I1107 22:42:37.465365 18604 sgd_solver.cpp:105] Iteration 142600, lr = 0.001
I1107 22:42:43.411804 18604 solver.cpp:218] Iteration 142700 (16.8182 iter/s, 5.94594s/100 iters), loss = 0.202453
I1107 22:42:43.411804 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:42:43.411804 18604 solver.cpp:237]     Train net output #1: loss = 0.202453 (* 1 = 0.202453 loss)
I1107 22:42:43.411804 18604 sgd_solver.cpp:105] Iteration 142700, lr = 0.001
I1107 22:42:49.339712 18604 solver.cpp:218] Iteration 142800 (16.8698 iter/s, 5.92774s/100 iters), loss = 0.299377
I1107 22:42:49.340214 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:42:49.340214 18604 solver.cpp:237]     Train net output #1: loss = 0.299377 (* 1 = 0.299377 loss)
I1107 22:42:49.340214 18604 sgd_solver.cpp:105] Iteration 142800, lr = 0.001
I1107 22:42:55.272678 18604 solver.cpp:218] Iteration 142900 (16.857 iter/s, 5.93227s/100 iters), loss = 0.309075
I1107 22:42:55.272678 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:42:55.272678 18604 solver.cpp:237]     Train net output #1: loss = 0.309075 (* 1 = 0.309075 loss)
I1107 22:42:55.272678 18604 sgd_solver.cpp:105] Iteration 142900, lr = 0.001
I1107 22:43:00.849066  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:43:01.081076 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_143000.caffemodel
I1107 22:43:01.097077 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_143000.solverstate
I1107 22:43:01.102077 18604 solver.cpp:330] Iteration 143000, Testing net (#0)
I1107 22:43:01.102077 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:43:02.395193 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:43:02.446696 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6597
I1107 22:43:02.446696 18604 solver.cpp:397]     Test net output #1: loss = 1.39794 (* 1 = 1.39794 loss)
I1107 22:43:02.503197 18604 solver.cpp:218] Iteration 143000 (13.8312 iter/s, 7.23003s/100 iters), loss = 0.209922
I1107 22:43:02.503197 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:43:02.503197 18604 solver.cpp:237]     Train net output #1: loss = 0.209921 (* 1 = 0.209921 loss)
I1107 22:43:02.503197 18604 sgd_solver.cpp:105] Iteration 143000, lr = 0.001
I1107 22:43:08.415570 18604 solver.cpp:218] Iteration 143100 (16.913 iter/s, 5.91261s/100 iters), loss = 0.267807
I1107 22:43:08.415570 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:43:08.415570 18604 solver.cpp:237]     Train net output #1: loss = 0.267807 (* 1 = 0.267807 loss)
I1107 22:43:08.415570 18604 sgd_solver.cpp:105] Iteration 143100, lr = 0.001
I1107 22:43:14.325996 18604 solver.cpp:218] Iteration 143200 (16.921 iter/s, 5.90982s/100 iters), loss = 0.282964
I1107 22:43:14.325996 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:43:14.325996 18604 solver.cpp:237]     Train net output #1: loss = 0.282964 (* 1 = 0.282964 loss)
I1107 22:43:14.325996 18604 sgd_solver.cpp:105] Iteration 143200, lr = 0.001
I1107 22:43:20.244937 18604 solver.cpp:218] Iteration 143300 (16.8977 iter/s, 5.91796s/100 iters), loss = 0.248984
I1107 22:43:20.244937 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:43:20.244937 18604 solver.cpp:237]     Train net output #1: loss = 0.248984 (* 1 = 0.248984 loss)
I1107 22:43:20.244937 18604 sgd_solver.cpp:105] Iteration 143300, lr = 0.001
I1107 22:43:26.183897 18604 solver.cpp:218] Iteration 143400 (16.8392 iter/s, 5.93854s/100 iters), loss = 0.294008
I1107 22:43:26.183897 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:43:26.183897 18604 solver.cpp:237]     Train net output #1: loss = 0.294008 (* 1 = 0.294008 loss)
I1107 22:43:26.183897 18604 sgd_solver.cpp:105] Iteration 143400, lr = 0.001
I1107 22:43:31.797276  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:43:32.030346 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_143500.caffemodel
I1107 22:43:32.044852 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_143500.solverstate
I1107 22:43:32.049350 18604 solver.cpp:330] Iteration 143500, Testing net (#0)
I1107 22:43:32.049851 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:43:33.346791 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:43:33.397806 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6655
I1107 22:43:33.397806 18604 solver.cpp:397]     Test net output #1: loss = 1.36456 (* 1 = 1.36456 loss)
I1107 22:43:33.454821 18604 solver.cpp:218] Iteration 143500 (13.7541 iter/s, 7.27054s/100 iters), loss = 0.171627
I1107 22:43:33.454821 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:43:33.454821 18604 solver.cpp:237]     Train net output #1: loss = 0.171627 (* 1 = 0.171627 loss)
I1107 22:43:33.454821 18604 sgd_solver.cpp:105] Iteration 143500, lr = 0.001
I1107 22:43:39.378051 18604 solver.cpp:218] Iteration 143600 (16.8816 iter/s, 5.92362s/100 iters), loss = 0.259903
I1107 22:43:39.378051 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:43:39.378051 18604 solver.cpp:237]     Train net output #1: loss = 0.259903 (* 1 = 0.259903 loss)
I1107 22:43:39.378051 18604 sgd_solver.cpp:105] Iteration 143600, lr = 0.001
I1107 22:43:45.300622 18604 solver.cpp:218] Iteration 143700 (16.8857 iter/s, 5.92216s/100 iters), loss = 0.227141
I1107 22:43:45.300622 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:43:45.300622 18604 solver.cpp:237]     Train net output #1: loss = 0.227141 (* 1 = 0.227141 loss)
I1107 22:43:45.301623 18604 sgd_solver.cpp:105] Iteration 143700, lr = 0.001
I1107 22:43:51.220340 18604 solver.cpp:218] Iteration 143800 (16.894 iter/s, 5.91925s/100 iters), loss = 0.264456
I1107 22:43:51.220340 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:43:51.220340 18604 solver.cpp:237]     Train net output #1: loss = 0.264456 (* 1 = 0.264456 loss)
I1107 22:43:51.220340 18604 sgd_solver.cpp:105] Iteration 143800, lr = 0.001
I1107 22:43:57.137874 18604 solver.cpp:218] Iteration 143900 (16.9019 iter/s, 5.91649s/100 iters), loss = 0.296406
I1107 22:43:57.137874 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:43:57.137874 18604 solver.cpp:237]     Train net output #1: loss = 0.296406 (* 1 = 0.296406 loss)
I1107 22:43:57.137874 18604 sgd_solver.cpp:105] Iteration 143900, lr = 0.001
I1107 22:44:02.772336  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:44:03.005352 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_144000.caffemodel
I1107 22:44:03.019348 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_144000.solverstate
I1107 22:44:03.024350 18604 solver.cpp:330] Iteration 144000, Testing net (#0)
I1107 22:44:03.024350 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:44:04.320477 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:44:04.370476 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6644
I1107 22:44:04.370476 18604 solver.cpp:397]     Test net output #1: loss = 1.36846 (* 1 = 1.36846 loss)
I1107 22:44:04.426476 18604 solver.cpp:218] Iteration 144000 (13.7202 iter/s, 7.28853s/100 iters), loss = 0.189592
I1107 22:44:04.426476 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:44:04.426476 18604 solver.cpp:237]     Train net output #1: loss = 0.189592 (* 1 = 0.189592 loss)
I1107 22:44:04.426476 18604 sgd_solver.cpp:105] Iteration 144000, lr = 0.001
I1107 22:44:10.342958 18604 solver.cpp:218] Iteration 144100 (16.9049 iter/s, 5.91546s/100 iters), loss = 0.285074
I1107 22:44:10.342958 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:44:10.342958 18604 solver.cpp:237]     Train net output #1: loss = 0.285073 (* 1 = 0.285073 loss)
I1107 22:44:10.342958 18604 sgd_solver.cpp:105] Iteration 144100, lr = 0.001
I1107 22:44:16.264688 18604 solver.cpp:218] Iteration 144200 (16.8879 iter/s, 5.92141s/100 iters), loss = 0.235331
I1107 22:44:16.264688 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1107 22:44:16.264688 18604 solver.cpp:237]     Train net output #1: loss = 0.23533 (* 1 = 0.23533 loss)
I1107 22:44:16.264688 18604 sgd_solver.cpp:105] Iteration 144200, lr = 0.001
I1107 22:44:22.157716 18604 solver.cpp:218] Iteration 144300 (16.9698 iter/s, 5.89283s/100 iters), loss = 0.351968
I1107 22:44:22.157716 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:44:22.157716 18604 solver.cpp:237]     Train net output #1: loss = 0.351968 (* 1 = 0.351968 loss)
I1107 22:44:22.157716 18604 sgd_solver.cpp:105] Iteration 144300, lr = 0.001
I1107 22:44:28.067163 18604 solver.cpp:218] Iteration 144400 (16.9237 iter/s, 5.90886s/100 iters), loss = 0.274561
I1107 22:44:28.067163 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:44:28.067163 18604 solver.cpp:237]     Train net output #1: loss = 0.274561 (* 1 = 0.274561 loss)
I1107 22:44:28.067163 18604 sgd_solver.cpp:105] Iteration 144400, lr = 0.001
I1107 22:44:33.687583  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:44:33.921598 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_144500.caffemodel
I1107 22:44:33.936599 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_144500.solverstate
I1107 22:44:33.941598 18604 solver.cpp:330] Iteration 144500, Testing net (#0)
I1107 22:44:33.941598 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:44:35.241698 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:44:35.293715 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6658
I1107 22:44:35.293715 18604 solver.cpp:397]     Test net output #1: loss = 1.36691 (* 1 = 1.36691 loss)
I1107 22:44:35.350718 18604 solver.cpp:218] Iteration 144500 (13.7302 iter/s, 7.28321s/100 iters), loss = 0.19759
I1107 22:44:35.350718 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1107 22:44:35.350718 18604 solver.cpp:237]     Train net output #1: loss = 0.19759 (* 1 = 0.19759 loss)
I1107 22:44:35.350718 18604 sgd_solver.cpp:105] Iteration 144500, lr = 0.001
I1107 22:44:41.257128 18604 solver.cpp:218] Iteration 144600 (16.9323 iter/s, 5.90586s/100 iters), loss = 0.300466
I1107 22:44:41.257128 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:44:41.257128 18604 solver.cpp:237]     Train net output #1: loss = 0.300466 (* 1 = 0.300466 loss)
I1107 22:44:41.257128 18604 sgd_solver.cpp:105] Iteration 144600, lr = 0.001
I1107 22:44:47.175626 18604 solver.cpp:218] Iteration 144700 (16.8977 iter/s, 5.91796s/100 iters), loss = 0.162463
I1107 22:44:47.175626 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1107 22:44:47.175626 18604 solver.cpp:237]     Train net output #1: loss = 0.162463 (* 1 = 0.162463 loss)
I1107 22:44:47.175626 18604 sgd_solver.cpp:105] Iteration 144700, lr = 0.001
I1107 22:44:53.085096 18604 solver.cpp:218] Iteration 144800 (16.9217 iter/s, 5.90957s/100 iters), loss = 0.241454
I1107 22:44:53.085096 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:44:53.085096 18604 solver.cpp:237]     Train net output #1: loss = 0.241454 (* 1 = 0.241454 loss)
I1107 22:44:53.085096 18604 sgd_solver.cpp:105] Iteration 144800, lr = 0.001
I1107 22:44:58.985517 18604 solver.cpp:218] Iteration 144900 (16.9517 iter/s, 5.89911s/100 iters), loss = 0.35708
I1107 22:44:58.985517 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:44:58.985517 18604 solver.cpp:237]     Train net output #1: loss = 0.35708 (* 1 = 0.35708 loss)
I1107 22:44:58.985517 18604 sgd_solver.cpp:105] Iteration 144900, lr = 0.001
I1107 22:45:04.593933  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:45:04.825947 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_145000.caffemodel
I1107 22:45:04.841946 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_145000.solverstate
I1107 22:45:04.845947 18604 solver.cpp:330] Iteration 145000, Testing net (#0)
I1107 22:45:04.845947 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:45:06.144042 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:45:06.195058 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6627
I1107 22:45:06.195058 18604 solver.cpp:397]     Test net output #1: loss = 1.37827 (* 1 = 1.37827 loss)
I1107 22:45:06.251049 18604 solver.cpp:218] Iteration 145000 (13.764 iter/s, 7.26534s/100 iters), loss = 0.306285
I1107 22:45:06.251049 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1107 22:45:06.251049 18604 solver.cpp:237]     Train net output #1: loss = 0.306285 (* 1 = 0.306285 loss)
I1107 22:45:06.251049 18604 sgd_solver.cpp:105] Iteration 145000, lr = 0.001
I1107 22:45:12.162531 18604 solver.cpp:218] Iteration 145100 (16.9174 iter/s, 5.91109s/100 iters), loss = 0.372006
I1107 22:45:12.163033 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1107 22:45:12.163033 18604 solver.cpp:237]     Train net output #1: loss = 0.372006 (* 1 = 0.372006 loss)
I1107 22:45:12.163033 18604 sgd_solver.cpp:105] Iteration 145100, lr = 0.001
I1107 22:45:18.060958 18604 solver.cpp:218] Iteration 145200 (16.9538 iter/s, 5.89838s/100 iters), loss = 0.218777
I1107 22:45:18.060958 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:45:18.060958 18604 solver.cpp:237]     Train net output #1: loss = 0.218777 (* 1 = 0.218777 loss)
I1107 22:45:18.060958 18604 sgd_solver.cpp:105] Iteration 145200, lr = 0.001
I1107 22:45:23.939373 18604 solver.cpp:218] Iteration 145300 (17.0148 iter/s, 5.87724s/100 iters), loss = 0.302483
I1107 22:45:23.939373 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:45:23.939373 18604 solver.cpp:237]     Train net output #1: loss = 0.302483 (* 1 = 0.302483 loss)
I1107 22:45:23.939373 18604 sgd_solver.cpp:105] Iteration 145300, lr = 0.001
I1107 22:45:29.822805 18604 solver.cpp:218] Iteration 145400 (16.9972 iter/s, 5.88333s/100 iters), loss = 0.313016
I1107 22:45:29.822805 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1107 22:45:29.822805 18604 solver.cpp:237]     Train net output #1: loss = 0.313016 (* 1 = 0.313016 loss)
I1107 22:45:29.822805 18604 sgd_solver.cpp:105] Iteration 145400, lr = 0.001
I1107 22:45:35.421705  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:45:35.653221 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_145500.caffemodel
I1107 22:45:35.669222 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_145500.solverstate
I1107 22:45:35.674221 18604 solver.cpp:330] Iteration 145500, Testing net (#0)
I1107 22:45:35.674221 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:45:36.966380 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:45:37.016391 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6622
I1107 22:45:37.016391 18604 solver.cpp:397]     Test net output #1: loss = 1.38941 (* 1 = 1.38941 loss)
I1107 22:45:37.072391 18604 solver.cpp:218] Iteration 145500 (13.7945 iter/s, 7.24928s/100 iters), loss = 0.236156
I1107 22:45:37.072391 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:45:37.072391 18604 solver.cpp:237]     Train net output #1: loss = 0.236156 (* 1 = 0.236156 loss)
I1107 22:45:37.072391 18604 sgd_solver.cpp:105] Iteration 145500, lr = 0.001
I1107 22:45:42.972919 18604 solver.cpp:218] Iteration 145600 (16.949 iter/s, 5.90005s/100 iters), loss = 0.3248
I1107 22:45:42.972919 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:45:42.972919 18604 solver.cpp:237]     Train net output #1: loss = 0.3248 (* 1 = 0.3248 loss)
I1107 22:45:42.972919 18604 sgd_solver.cpp:105] Iteration 145600, lr = 0.001
I1107 22:45:48.891474 18604 solver.cpp:218] Iteration 145700 (16.896 iter/s, 5.91856s/100 iters), loss = 0.189204
I1107 22:45:48.891474 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1107 22:45:48.891474 18604 solver.cpp:237]     Train net output #1: loss = 0.189204 (* 1 = 0.189204 loss)
I1107 22:45:48.891474 18604 sgd_solver.cpp:105] Iteration 145700, lr = 0.001
I1107 22:45:54.829555 18604 solver.cpp:218] Iteration 145800 (16.8431 iter/s, 5.93715s/100 iters), loss = 0.253528
I1107 22:45:54.829555 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:45:54.829555 18604 solver.cpp:237]     Train net output #1: loss = 0.253527 (* 1 = 0.253527 loss)
I1107 22:45:54.829555 18604 sgd_solver.cpp:105] Iteration 145800, lr = 0.001
I1107 22:46:00.732003 18604 solver.cpp:218] Iteration 145900 (16.9437 iter/s, 5.9019s/100 iters), loss = 0.298009
I1107 22:46:00.732003 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:46:00.732003 18604 solver.cpp:237]     Train net output #1: loss = 0.298009 (* 1 = 0.298009 loss)
I1107 22:46:00.732003 18604 sgd_solver.cpp:105] Iteration 145900, lr = 0.001
I1107 22:46:06.336020  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:46:06.568037 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_146000.caffemodel
I1107 22:46:06.584038 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_146000.solverstate
I1107 22:46:06.589037 18604 solver.cpp:330] Iteration 146000, Testing net (#0)
I1107 22:46:06.589037 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:46:07.886128 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:46:07.937631 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6605
I1107 22:46:07.937631 18604 solver.cpp:397]     Test net output #1: loss = 1.38124 (* 1 = 1.38124 loss)
I1107 22:46:07.995136 18604 solver.cpp:218] Iteration 146000 (13.7681 iter/s, 7.26315s/100 iters), loss = 0.203912
I1107 22:46:07.995136 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1107 22:46:07.995136 18604 solver.cpp:237]     Train net output #1: loss = 0.203912 (* 1 = 0.203912 loss)
I1107 22:46:07.995136 18604 sgd_solver.cpp:105] Iteration 146000, lr = 0.001
I1107 22:46:13.899626 18604 solver.cpp:218] Iteration 146100 (16.9394 iter/s, 5.9034s/100 iters), loss = 0.296789
I1107 22:46:13.899626 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:46:13.899626 18604 solver.cpp:237]     Train net output #1: loss = 0.296788 (* 1 = 0.296788 loss)
I1107 22:46:13.899626 18604 sgd_solver.cpp:105] Iteration 146100, lr = 0.001
I1107 22:46:19.804020 18604 solver.cpp:218] Iteration 146200 (16.9368 iter/s, 5.9043s/100 iters), loss = 0.231244
I1107 22:46:19.804020 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1107 22:46:19.804020 18604 solver.cpp:237]     Train net output #1: loss = 0.231244 (* 1 = 0.231244 loss)
I1107 22:46:19.804020 18604 sgd_solver.cpp:105] Iteration 146200, lr = 0.001
I1107 22:46:25.699453 18604 solver.cpp:218] Iteration 146300 (16.9635 iter/s, 5.89501s/100 iters), loss = 0.324497
I1107 22:46:25.699453 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:46:25.699453 18604 solver.cpp:237]     Train net output #1: loss = 0.324497 (* 1 = 0.324497 loss)
I1107 22:46:25.699453 18604 sgd_solver.cpp:105] Iteration 146300, lr = 0.001
I1107 22:46:31.617929 18604 solver.cpp:218] Iteration 146400 (16.8974 iter/s, 5.91808s/100 iters), loss = 0.370503
I1107 22:46:31.617929 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1107 22:46:31.617929 18604 solver.cpp:237]     Train net output #1: loss = 0.370503 (* 1 = 0.370503 loss)
I1107 22:46:31.617929 18604 sgd_solver.cpp:105] Iteration 146400, lr = 0.001
I1107 22:46:37.218302  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:46:37.450335 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_146500.caffemodel
I1107 22:46:37.466334 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_146500.solverstate
I1107 22:46:37.471335 18604 solver.cpp:330] Iteration 146500, Testing net (#0)
I1107 22:46:37.471335 18604 net.cpp:676] Ignoring source layer accuracy_training
I1107 22:46:38.771447 18016 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:46:38.822445 18604 solver.cpp:397]     Test net output #0: accuracy = 0.6609
I1107 22:46:38.822445 18604 solver.cpp:397]     Test net output #1: loss = 1.38544 (* 1 = 1.38544 loss)
I1107 22:46:38.878454 18604 solver.cpp:218] Iteration 146500 (13.7735 iter/s, 7.26032s/100 iters), loss = 0.207267
I1107 22:46:38.878454 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1107 22:46:38.878454 18604 solver.cpp:237]     Train net output #1: loss = 0.207267 (* 1 = 0.207267 loss)
I1107 22:46:38.878454 18604 sgd_solver.cpp:105] Iteration 146500, lr = 0.001
I1107 22:46:44.781877 18604 solver.cpp:218] Iteration 146600 (16.9424 iter/s, 5.90235s/100 iters), loss = 0.228743
I1107 22:46:44.781877 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1107 22:46:44.781877 18604 solver.cpp:237]     Train net output #1: loss = 0.228743 (* 1 = 0.228743 loss)
I1107 22:46:44.781877 18604 sgd_solver.cpp:105] Iteration 146600, lr = 0.001
I1107 22:46:50.741647 18604 solver.cpp:218] Iteration 146700 (16.7793 iter/s, 5.95971s/100 iters), loss = 0.222141
I1107 22:46:50.741647 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1107 22:46:50.741647 18604 solver.cpp:237]     Train net output #1: loss = 0.222141 (* 1 = 0.222141 loss)
I1107 22:46:50.741647 18604 sgd_solver.cpp:105] Iteration 146700, lr = 0.001
I1107 22:46:56.755142 18604 solver.cpp:218] Iteration 146800 (16.6306 iter/s, 6.01303s/100 iters), loss = 0.306061
I1107 22:46:56.755142 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1107 22:46:56.755142 18604 solver.cpp:237]     Train net output #1: loss = 0.30606 (* 1 = 0.30606 loss)
I1107 22:46:56.755142 18604 sgd_solver.cpp:105] Iteration 146800, lr = 0.001
I1107 22:47:02.682528 18604 solver.cpp:218] Iteration 146900 (16.8717 iter/s, 5.92708s/100 iters), loss = 0.267517
I1107 22:47:02.682528 18604 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1107 22:47:02.682528 18604 solver.cpp:237]     Train net output #1: loss = 0.267517 (* 1 = 0.267517 loss)
I1107 22:47:02.682528 18604 sgd_solver.cpp:105] Iteration 146900, lr = 0.001
I1107 22:47:08.352470  9388 data_layer.cpp:73] Restarting data prefetching from start.
I1107 22:47:08.587121 18604 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_147000.caffemodel
I1107 22:47:08.603103 18604 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_iter_147000.solverstate
