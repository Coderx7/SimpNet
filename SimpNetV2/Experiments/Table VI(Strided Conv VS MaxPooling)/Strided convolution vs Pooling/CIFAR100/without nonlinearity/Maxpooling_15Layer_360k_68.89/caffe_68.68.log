I1210 12:09:02.440004 10416 caffe.cpp:219] Using GPUs 0
I1210 12:09:02.621639 10416 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1210 12:09:02.924703 10416 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 12:09:02.942203 10416 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1210 12:09:02.942703 10416 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 12:09:02.943711 10416 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 12:09:02.943711 10416 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1210 12:09:02.943711 10416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1210 12:09:02.944203 10416 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_v2_360k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "newconv_added1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "newconv_added1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "newconv_added1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "added_new_conv2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "added_new_conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "added_new_conv2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1210 12:09:02.969744 10416 layer_factory.cpp:58] Creating layer cifar
I1210 12:09:02.972762 10416 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1210 12:09:02.973762 10416 net.cpp:84] Creating Layer cifar
I1210 12:09:02.973762 10416 net.cpp:380] cifar -> data
I1210 12:09:02.973762 10416 net.cpp:380] cifar -> label
I1210 12:09:02.973762 10416 data_layer.cpp:45] output data size: 100,3,32,32
I1210 12:09:02.980749 10416 net.cpp:122] Setting up cifar
I1210 12:09:02.980749 10416 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1210 12:09:02.980749 10416 net.cpp:129] Top shape: 100 (100)
I1210 12:09:02.980749 10416 net.cpp:137] Memory required for data: 1229200
I1210 12:09:02.980749 10416 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1210 12:09:02.980749 10416 net.cpp:84] Creating Layer label_cifar_1_split
I1210 12:09:02.980749 10416 net.cpp:406] label_cifar_1_split <- label
I1210 12:09:02.980749 10416 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1210 12:09:02.980749 10416 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1210 12:09:02.980749 10416 net.cpp:122] Setting up label_cifar_1_split
I1210 12:09:02.980749 10416 net.cpp:129] Top shape: 100 (100)
I1210 12:09:02.980749 10416 net.cpp:129] Top shape: 100 (100)
I1210 12:09:02.980749 10416 net.cpp:137] Memory required for data: 1230000
I1210 12:09:02.980749 10416 layer_factory.cpp:58] Creating layer conv1
I1210 12:09:02.980749 10416 net.cpp:84] Creating Layer conv1
I1210 12:09:02.980749 10416 net.cpp:406] conv1 <- data
I1210 12:09:02.980749 10416 net.cpp:380] conv1 -> conv1
I1210 12:09:02.981747  7104 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 12:09:03.230619 10416 net.cpp:122] Setting up conv1
I1210 12:09:03.230619 10416 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 12:09:03.230619 10416 net.cpp:137] Memory required for data: 13518000
I1210 12:09:03.230619 10416 layer_factory.cpp:58] Creating layer bn1
I1210 12:09:03.230619 10416 net.cpp:84] Creating Layer bn1
I1210 12:09:03.230619 10416 net.cpp:406] bn1 <- conv1
I1210 12:09:03.230619 10416 net.cpp:367] bn1 -> conv1 (in-place)
I1210 12:09:03.230619 10416 net.cpp:122] Setting up bn1
I1210 12:09:03.230619 10416 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 12:09:03.230619 10416 net.cpp:137] Memory required for data: 25806000
I1210 12:09:03.230619 10416 layer_factory.cpp:58] Creating layer scale1
I1210 12:09:03.230619 10416 net.cpp:84] Creating Layer scale1
I1210 12:09:03.230619 10416 net.cpp:406] scale1 <- conv1
I1210 12:09:03.230619 10416 net.cpp:367] scale1 -> conv1 (in-place)
I1210 12:09:03.230619 10416 layer_factory.cpp:58] Creating layer scale1
I1210 12:09:03.230619 10416 net.cpp:122] Setting up scale1
I1210 12:09:03.230619 10416 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 12:09:03.230619 10416 net.cpp:137] Memory required for data: 38094000
I1210 12:09:03.230619 10416 layer_factory.cpp:58] Creating layer relu1
I1210 12:09:03.230619 10416 net.cpp:84] Creating Layer relu1
I1210 12:09:03.230619 10416 net.cpp:406] relu1 <- conv1
I1210 12:09:03.230619 10416 net.cpp:367] relu1 -> conv1 (in-place)
I1210 12:09:03.231616 10416 net.cpp:122] Setting up relu1
I1210 12:09:03.231616 10416 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 12:09:03.231616 10416 net.cpp:137] Memory required for data: 50382000
I1210 12:09:03.231616 10416 layer_factory.cpp:58] Creating layer conv1_0
I1210 12:09:03.231616 10416 net.cpp:84] Creating Layer conv1_0
I1210 12:09:03.231616 10416 net.cpp:406] conv1_0 <- conv1
I1210 12:09:03.231616 10416 net.cpp:380] conv1_0 -> conv1_0
I1210 12:09:03.233623 10416 net.cpp:122] Setting up conv1_0
I1210 12:09:03.233623 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.233623 10416 net.cpp:137] Memory required for data: 66766000
I1210 12:09:03.233623 10416 layer_factory.cpp:58] Creating layer bn1_0
I1210 12:09:03.233623 10416 net.cpp:84] Creating Layer bn1_0
I1210 12:09:03.233623 10416 net.cpp:406] bn1_0 <- conv1_0
I1210 12:09:03.233623 10416 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1210 12:09:03.233623 10416 net.cpp:122] Setting up bn1_0
I1210 12:09:03.233623 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.233623 10416 net.cpp:137] Memory required for data: 83150000
I1210 12:09:03.233623 10416 layer_factory.cpp:58] Creating layer scale1_0
I1210 12:09:03.233623 10416 net.cpp:84] Creating Layer scale1_0
I1210 12:09:03.233623 10416 net.cpp:406] scale1_0 <- conv1_0
I1210 12:09:03.233623 10416 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1210 12:09:03.233623 10416 layer_factory.cpp:58] Creating layer scale1_0
I1210 12:09:03.233623 10416 net.cpp:122] Setting up scale1_0
I1210 12:09:03.233623 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.233623 10416 net.cpp:137] Memory required for data: 99534000
I1210 12:09:03.233623 10416 layer_factory.cpp:58] Creating layer relu1_0
I1210 12:09:03.233623 10416 net.cpp:84] Creating Layer relu1_0
I1210 12:09:03.233623 10416 net.cpp:406] relu1_0 <- conv1_0
I1210 12:09:03.233623 10416 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1210 12:09:03.234617 10416 net.cpp:122] Setting up relu1_0
I1210 12:09:03.234617 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.234617 10416 net.cpp:137] Memory required for data: 115918000
I1210 12:09:03.234617 10416 layer_factory.cpp:58] Creating layer conv2
I1210 12:09:03.234617 10416 net.cpp:84] Creating Layer conv2
I1210 12:09:03.234617 10416 net.cpp:406] conv2 <- conv1_0
I1210 12:09:03.234617 10416 net.cpp:380] conv2 -> conv2
I1210 12:09:03.235621 10416 net.cpp:122] Setting up conv2
I1210 12:09:03.235621 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.235621 10416 net.cpp:137] Memory required for data: 132302000
I1210 12:09:03.235621 10416 layer_factory.cpp:58] Creating layer bn2
I1210 12:09:03.235621 10416 net.cpp:84] Creating Layer bn2
I1210 12:09:03.235621 10416 net.cpp:406] bn2 <- conv2
I1210 12:09:03.235621 10416 net.cpp:367] bn2 -> conv2 (in-place)
I1210 12:09:03.235621 10416 net.cpp:122] Setting up bn2
I1210 12:09:03.235621 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.235621 10416 net.cpp:137] Memory required for data: 148686000
I1210 12:09:03.235621 10416 layer_factory.cpp:58] Creating layer scale2
I1210 12:09:03.235621 10416 net.cpp:84] Creating Layer scale2
I1210 12:09:03.235621 10416 net.cpp:406] scale2 <- conv2
I1210 12:09:03.235621 10416 net.cpp:367] scale2 -> conv2 (in-place)
I1210 12:09:03.236624 10416 layer_factory.cpp:58] Creating layer scale2
I1210 12:09:03.236624 10416 net.cpp:122] Setting up scale2
I1210 12:09:03.236624 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.236624 10416 net.cpp:137] Memory required for data: 165070000
I1210 12:09:03.236624 10416 layer_factory.cpp:58] Creating layer relu2
I1210 12:09:03.236624 10416 net.cpp:84] Creating Layer relu2
I1210 12:09:03.236624 10416 net.cpp:406] relu2 <- conv2
I1210 12:09:03.236624 10416 net.cpp:367] relu2 -> conv2 (in-place)
I1210 12:09:03.236624 10416 net.cpp:122] Setting up relu2
I1210 12:09:03.236624 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.236624 10416 net.cpp:137] Memory required for data: 181454000
I1210 12:09:03.236624 10416 layer_factory.cpp:58] Creating layer conv2_1
I1210 12:09:03.236624 10416 net.cpp:84] Creating Layer conv2_1
I1210 12:09:03.236624 10416 net.cpp:406] conv2_1 <- conv2
I1210 12:09:03.236624 10416 net.cpp:380] conv2_1 -> conv2_1
I1210 12:09:03.237619 10416 net.cpp:122] Setting up conv2_1
I1210 12:09:03.237619 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.237619 10416 net.cpp:137] Memory required for data: 197838000
I1210 12:09:03.237619 10416 layer_factory.cpp:58] Creating layer bn2_1
I1210 12:09:03.237619 10416 net.cpp:84] Creating Layer bn2_1
I1210 12:09:03.237619 10416 net.cpp:406] bn2_1 <- conv2_1
I1210 12:09:03.237619 10416 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1210 12:09:03.238634 10416 net.cpp:122] Setting up bn2_1
I1210 12:09:03.238634 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.238634 10416 net.cpp:137] Memory required for data: 214222000
I1210 12:09:03.238634 10416 layer_factory.cpp:58] Creating layer scale2_1
I1210 12:09:03.238634 10416 net.cpp:84] Creating Layer scale2_1
I1210 12:09:03.238634 10416 net.cpp:406] scale2_1 <- conv2_1
I1210 12:09:03.238634 10416 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1210 12:09:03.238634 10416 layer_factory.cpp:58] Creating layer scale2_1
I1210 12:09:03.238634 10416 net.cpp:122] Setting up scale2_1
I1210 12:09:03.238634 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.238634 10416 net.cpp:137] Memory required for data: 230606000
I1210 12:09:03.238634 10416 layer_factory.cpp:58] Creating layer relu2_1
I1210 12:09:03.238634 10416 net.cpp:84] Creating Layer relu2_1
I1210 12:09:03.238634 10416 net.cpp:406] relu2_1 <- conv2_1
I1210 12:09:03.238634 10416 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1210 12:09:03.238634 10416 net.cpp:122] Setting up relu2_1
I1210 12:09:03.238634 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.238634 10416 net.cpp:137] Memory required for data: 246990000
I1210 12:09:03.238634 10416 layer_factory.cpp:58] Creating layer conv2_2
I1210 12:09:03.238634 10416 net.cpp:84] Creating Layer conv2_2
I1210 12:09:03.238634 10416 net.cpp:406] conv2_2 <- conv2_1
I1210 12:09:03.238634 10416 net.cpp:380] conv2_2 -> conv2_2
I1210 12:09:03.240631 10416 net.cpp:122] Setting up conv2_2
I1210 12:09:03.240631 10416 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 12:09:03.240631 10416 net.cpp:137] Memory required for data: 267470000
I1210 12:09:03.240631 10416 layer_factory.cpp:58] Creating layer bn2_2
I1210 12:09:03.240631 10416 net.cpp:84] Creating Layer bn2_2
I1210 12:09:03.240631 10416 net.cpp:406] bn2_2 <- conv2_2
I1210 12:09:03.240631 10416 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1210 12:09:03.240631 10416 net.cpp:122] Setting up bn2_2
I1210 12:09:03.240631 10416 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 12:09:03.240631 10416 net.cpp:137] Memory required for data: 287950000
I1210 12:09:03.240631 10416 layer_factory.cpp:58] Creating layer scale2_2
I1210 12:09:03.240631 10416 net.cpp:84] Creating Layer scale2_2
I1210 12:09:03.240631 10416 net.cpp:406] scale2_2 <- conv2_2
I1210 12:09:03.240631 10416 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1210 12:09:03.240631 10416 layer_factory.cpp:58] Creating layer scale2_2
I1210 12:09:03.241629 10416 net.cpp:122] Setting up scale2_2
I1210 12:09:03.241629 10416 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 12:09:03.241629 10416 net.cpp:137] Memory required for data: 308430000
I1210 12:09:03.241629 10416 layer_factory.cpp:58] Creating layer relu2_2
I1210 12:09:03.241629 10416 net.cpp:84] Creating Layer relu2_2
I1210 12:09:03.241629 10416 net.cpp:406] relu2_2 <- conv2_2
I1210 12:09:03.241629 10416 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1210 12:09:03.242154 10416 net.cpp:122] Setting up relu2_2
I1210 12:09:03.242154 10416 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 12:09:03.242154 10416 net.cpp:137] Memory required for data: 328910000
I1210 12:09:03.242154 10416 layer_factory.cpp:58] Creating layer newconv_added1
I1210 12:09:03.242154 10416 net.cpp:84] Creating Layer newconv_added1
I1210 12:09:03.242154 10416 net.cpp:406] newconv_added1 <- conv2_2
I1210 12:09:03.242154 10416 net.cpp:380] newconv_added1 -> newconv_added1
I1210 12:09:03.243654 10416 net.cpp:122] Setting up newconv_added1
I1210 12:09:03.243654 10416 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 12:09:03.243654 10416 net.cpp:137] Memory required for data: 349390000
I1210 12:09:03.243654 10416 layer_factory.cpp:58] Creating layer pool2_1
I1210 12:09:03.243654 10416 net.cpp:84] Creating Layer pool2_1
I1210 12:09:03.243654 10416 net.cpp:406] pool2_1 <- newconv_added1
I1210 12:09:03.243654 10416 net.cpp:380] pool2_1 -> pool2_1
I1210 12:09:03.243654 10416 net.cpp:122] Setting up pool2_1
I1210 12:09:03.243654 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.243654 10416 net.cpp:137] Memory required for data: 354510000
I1210 12:09:03.243654 10416 layer_factory.cpp:58] Creating layer conv3
I1210 12:09:03.243654 10416 net.cpp:84] Creating Layer conv3
I1210 12:09:03.243654 10416 net.cpp:406] conv3 <- pool2_1
I1210 12:09:03.243654 10416 net.cpp:380] conv3 -> conv3
I1210 12:09:03.245154 10416 net.cpp:122] Setting up conv3
I1210 12:09:03.245154 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.245154 10416 net.cpp:137] Memory required for data: 359630000
I1210 12:09:03.245154 10416 layer_factory.cpp:58] Creating layer bn3
I1210 12:09:03.245154 10416 net.cpp:84] Creating Layer bn3
I1210 12:09:03.245154 10416 net.cpp:406] bn3 <- conv3
I1210 12:09:03.245154 10416 net.cpp:367] bn3 -> conv3 (in-place)
I1210 12:09:03.245654 10416 net.cpp:122] Setting up bn3
I1210 12:09:03.245654 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.245654 10416 net.cpp:137] Memory required for data: 364750000
I1210 12:09:03.245654 10416 layer_factory.cpp:58] Creating layer scale3
I1210 12:09:03.245654 10416 net.cpp:84] Creating Layer scale3
I1210 12:09:03.245654 10416 net.cpp:406] scale3 <- conv3
I1210 12:09:03.245654 10416 net.cpp:367] scale3 -> conv3 (in-place)
I1210 12:09:03.245654 10416 layer_factory.cpp:58] Creating layer scale3
I1210 12:09:03.245654 10416 net.cpp:122] Setting up scale3
I1210 12:09:03.245654 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.245654 10416 net.cpp:137] Memory required for data: 369870000
I1210 12:09:03.245654 10416 layer_factory.cpp:58] Creating layer relu3
I1210 12:09:03.245654 10416 net.cpp:84] Creating Layer relu3
I1210 12:09:03.245654 10416 net.cpp:406] relu3 <- conv3
I1210 12:09:03.245654 10416 net.cpp:367] relu3 -> conv3 (in-place)
I1210 12:09:03.246153 10416 net.cpp:122] Setting up relu3
I1210 12:09:03.246153 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.246153 10416 net.cpp:137] Memory required for data: 374990000
I1210 12:09:03.246153 10416 layer_factory.cpp:58] Creating layer conv3_1
I1210 12:09:03.246153 10416 net.cpp:84] Creating Layer conv3_1
I1210 12:09:03.246153 10416 net.cpp:406] conv3_1 <- conv3
I1210 12:09:03.246153 10416 net.cpp:380] conv3_1 -> conv3_1
I1210 12:09:03.247148 10416 net.cpp:122] Setting up conv3_1
I1210 12:09:03.247650 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.247650 10416 net.cpp:137] Memory required for data: 380110000
I1210 12:09:03.247650 10416 layer_factory.cpp:58] Creating layer bn3_1
I1210 12:09:03.247650 10416 net.cpp:84] Creating Layer bn3_1
I1210 12:09:03.247650 10416 net.cpp:406] bn3_1 <- conv3_1
I1210 12:09:03.247650 10416 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1210 12:09:03.247650 10416 net.cpp:122] Setting up bn3_1
I1210 12:09:03.247650 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.247650 10416 net.cpp:137] Memory required for data: 385230000
I1210 12:09:03.247650 10416 layer_factory.cpp:58] Creating layer scale3_1
I1210 12:09:03.247650 10416 net.cpp:84] Creating Layer scale3_1
I1210 12:09:03.247650 10416 net.cpp:406] scale3_1 <- conv3_1
I1210 12:09:03.247650 10416 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1210 12:09:03.247650 10416 layer_factory.cpp:58] Creating layer scale3_1
I1210 12:09:03.247650 10416 net.cpp:122] Setting up scale3_1
I1210 12:09:03.247650 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.247650 10416 net.cpp:137] Memory required for data: 390350000
I1210 12:09:03.247650 10416 layer_factory.cpp:58] Creating layer relu3_1
I1210 12:09:03.247650 10416 net.cpp:84] Creating Layer relu3_1
I1210 12:09:03.247650 10416 net.cpp:406] relu3_1 <- conv3_1
I1210 12:09:03.247650 10416 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1210 12:09:03.248145 10416 net.cpp:122] Setting up relu3_1
I1210 12:09:03.248145 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.248145 10416 net.cpp:137] Memory required for data: 395470000
I1210 12:09:03.248145 10416 layer_factory.cpp:58] Creating layer conv4
I1210 12:09:03.248145 10416 net.cpp:84] Creating Layer conv4
I1210 12:09:03.248145 10416 net.cpp:406] conv4 <- conv3_1
I1210 12:09:03.248145 10416 net.cpp:380] conv4 -> conv4
I1210 12:09:03.249145 10416 net.cpp:122] Setting up conv4
I1210 12:09:03.249145 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.249645 10416 net.cpp:137] Memory required for data: 400590000
I1210 12:09:03.249645 10416 layer_factory.cpp:58] Creating layer bn4
I1210 12:09:03.249645 10416 net.cpp:84] Creating Layer bn4
I1210 12:09:03.249645 10416 net.cpp:406] bn4 <- conv4
I1210 12:09:03.249645 10416 net.cpp:367] bn4 -> conv4 (in-place)
I1210 12:09:03.249645 10416 net.cpp:122] Setting up bn4
I1210 12:09:03.249645 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.249645 10416 net.cpp:137] Memory required for data: 405710000
I1210 12:09:03.249645 10416 layer_factory.cpp:58] Creating layer scale4
I1210 12:09:03.249645 10416 net.cpp:84] Creating Layer scale4
I1210 12:09:03.249645 10416 net.cpp:406] scale4 <- conv4
I1210 12:09:03.249645 10416 net.cpp:367] scale4 -> conv4 (in-place)
I1210 12:09:03.249645 10416 layer_factory.cpp:58] Creating layer scale4
I1210 12:09:03.249645 10416 net.cpp:122] Setting up scale4
I1210 12:09:03.249645 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.249645 10416 net.cpp:137] Memory required for data: 410830000
I1210 12:09:03.249645 10416 layer_factory.cpp:58] Creating layer relu4
I1210 12:09:03.249645 10416 net.cpp:84] Creating Layer relu4
I1210 12:09:03.249645 10416 net.cpp:406] relu4 <- conv4
I1210 12:09:03.250145 10416 net.cpp:367] relu4 -> conv4 (in-place)
I1210 12:09:03.250145 10416 net.cpp:122] Setting up relu4
I1210 12:09:03.250145 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.250145 10416 net.cpp:137] Memory required for data: 415950000
I1210 12:09:03.250145 10416 layer_factory.cpp:58] Creating layer conv4_1
I1210 12:09:03.250145 10416 net.cpp:84] Creating Layer conv4_1
I1210 12:09:03.250145 10416 net.cpp:406] conv4_1 <- conv4
I1210 12:09:03.250145 10416 net.cpp:380] conv4_1 -> conv4_1
I1210 12:09:03.251644 10416 net.cpp:122] Setting up conv4_1
I1210 12:09:03.251644 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.251644 10416 net.cpp:137] Memory required for data: 421070000
I1210 12:09:03.251644 10416 layer_factory.cpp:58] Creating layer bn4_1
I1210 12:09:03.251644 10416 net.cpp:84] Creating Layer bn4_1
I1210 12:09:03.251644 10416 net.cpp:406] bn4_1 <- conv4_1
I1210 12:09:03.251644 10416 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1210 12:09:03.251644 10416 net.cpp:122] Setting up bn4_1
I1210 12:09:03.251644 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.251644 10416 net.cpp:137] Memory required for data: 426190000
I1210 12:09:03.251644 10416 layer_factory.cpp:58] Creating layer scale4_1
I1210 12:09:03.251644 10416 net.cpp:84] Creating Layer scale4_1
I1210 12:09:03.251644 10416 net.cpp:406] scale4_1 <- conv4_1
I1210 12:09:03.251644 10416 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1210 12:09:03.251644 10416 layer_factory.cpp:58] Creating layer scale4_1
I1210 12:09:03.252146 10416 net.cpp:122] Setting up scale4_1
I1210 12:09:03.252146 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.252146 10416 net.cpp:137] Memory required for data: 431310000
I1210 12:09:03.252146 10416 layer_factory.cpp:58] Creating layer relu4_1
I1210 12:09:03.252146 10416 net.cpp:84] Creating Layer relu4_1
I1210 12:09:03.252146 10416 net.cpp:406] relu4_1 <- conv4_1
I1210 12:09:03.252146 10416 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1210 12:09:03.252146 10416 net.cpp:122] Setting up relu4_1
I1210 12:09:03.252146 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.252146 10416 net.cpp:137] Memory required for data: 436430000
I1210 12:09:03.252146 10416 layer_factory.cpp:58] Creating layer conv4_2
I1210 12:09:03.252146 10416 net.cpp:84] Creating Layer conv4_2
I1210 12:09:03.252146 10416 net.cpp:406] conv4_2 <- conv4_1
I1210 12:09:03.252146 10416 net.cpp:380] conv4_2 -> conv4_2
I1210 12:09:03.253651 10416 net.cpp:122] Setting up conv4_2
I1210 12:09:03.253651 10416 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 12:09:03.253651 10416 net.cpp:137] Memory required for data: 442369200
I1210 12:09:03.253651 10416 layer_factory.cpp:58] Creating layer bn4_2
I1210 12:09:03.253651 10416 net.cpp:84] Creating Layer bn4_2
I1210 12:09:03.253651 10416 net.cpp:406] bn4_2 <- conv4_2
I1210 12:09:03.253651 10416 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1210 12:09:03.253651 10416 net.cpp:122] Setting up bn4_2
I1210 12:09:03.253651 10416 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 12:09:03.253651 10416 net.cpp:137] Memory required for data: 448308400
I1210 12:09:03.253651 10416 layer_factory.cpp:58] Creating layer scale4_2
I1210 12:09:03.253651 10416 net.cpp:84] Creating Layer scale4_2
I1210 12:09:03.253651 10416 net.cpp:406] scale4_2 <- conv4_2
I1210 12:09:03.253651 10416 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1210 12:09:03.253651 10416 layer_factory.cpp:58] Creating layer scale4_2
I1210 12:09:03.254145 10416 net.cpp:122] Setting up scale4_2
I1210 12:09:03.254145 10416 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 12:09:03.254145 10416 net.cpp:137] Memory required for data: 454247600
I1210 12:09:03.254145 10416 layer_factory.cpp:58] Creating layer relu4_2
I1210 12:09:03.254145 10416 net.cpp:84] Creating Layer relu4_2
I1210 12:09:03.254145 10416 net.cpp:406] relu4_2 <- conv4_2
I1210 12:09:03.254145 10416 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1210 12:09:03.254145 10416 net.cpp:122] Setting up relu4_2
I1210 12:09:03.254145 10416 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 12:09:03.254145 10416 net.cpp:137] Memory required for data: 460186800
I1210 12:09:03.254145 10416 layer_factory.cpp:58] Creating layer added_new_conv2
I1210 12:09:03.254145 10416 net.cpp:84] Creating Layer added_new_conv2
I1210 12:09:03.254145 10416 net.cpp:406] added_new_conv2 <- conv4_2
I1210 12:09:03.254145 10416 net.cpp:380] added_new_conv2 -> added_new_conv2
I1210 12:09:03.256146 10416 net.cpp:122] Setting up added_new_conv2
I1210 12:09:03.256146 10416 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 12:09:03.256146 10416 net.cpp:137] Memory required for data: 466126000
I1210 12:09:03.256146 10416 layer_factory.cpp:58] Creating layer pool4_2
I1210 12:09:03.256146 10416 net.cpp:84] Creating Layer pool4_2
I1210 12:09:03.256146 10416 net.cpp:406] pool4_2 <- added_new_conv2
I1210 12:09:03.256146 10416 net.cpp:380] pool4_2 -> pool4_2
I1210 12:09:03.256146 10416 net.cpp:122] Setting up pool4_2
I1210 12:09:03.256146 10416 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 12:09:03.256146 10416 net.cpp:137] Memory required for data: 467610800
I1210 12:09:03.256146 10416 layer_factory.cpp:58] Creating layer conv4_0
I1210 12:09:03.256146 10416 net.cpp:84] Creating Layer conv4_0
I1210 12:09:03.256146 10416 net.cpp:406] conv4_0 <- pool4_2
I1210 12:09:03.256146 10416 net.cpp:380] conv4_0 -> conv4_0
I1210 12:09:03.257647 10416 net.cpp:122] Setting up conv4_0
I1210 12:09:03.257647 10416 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 12:09:03.257647 10416 net.cpp:137] Memory required for data: 469095600
I1210 12:09:03.257647 10416 layer_factory.cpp:58] Creating layer bn4_0
I1210 12:09:03.257647 10416 net.cpp:84] Creating Layer bn4_0
I1210 12:09:03.257647 10416 net.cpp:406] bn4_0 <- conv4_0
I1210 12:09:03.257647 10416 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1210 12:09:03.257647 10416 net.cpp:122] Setting up bn4_0
I1210 12:09:03.257647 10416 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 12:09:03.257647 10416 net.cpp:137] Memory required for data: 470580400
I1210 12:09:03.257647 10416 layer_factory.cpp:58] Creating layer scale4_0
I1210 12:09:03.257647 10416 net.cpp:84] Creating Layer scale4_0
I1210 12:09:03.257647 10416 net.cpp:406] scale4_0 <- conv4_0
I1210 12:09:03.257647 10416 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1210 12:09:03.257647 10416 layer_factory.cpp:58] Creating layer scale4_0
I1210 12:09:03.257647 10416 net.cpp:122] Setting up scale4_0
I1210 12:09:03.257647 10416 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 12:09:03.257647 10416 net.cpp:137] Memory required for data: 472065200
I1210 12:09:03.257647 10416 layer_factory.cpp:58] Creating layer relu4_0
I1210 12:09:03.257647 10416 net.cpp:84] Creating Layer relu4_0
I1210 12:09:03.257647 10416 net.cpp:406] relu4_0 <- conv4_0
I1210 12:09:03.257647 10416 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1210 12:09:03.257647 10416 net.cpp:122] Setting up relu4_0
I1210 12:09:03.257647 10416 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 12:09:03.257647 10416 net.cpp:137] Memory required for data: 473550000
I1210 12:09:03.257647 10416 layer_factory.cpp:58] Creating layer conv11
I1210 12:09:03.257647 10416 net.cpp:84] Creating Layer conv11
I1210 12:09:03.257647 10416 net.cpp:406] conv11 <- conv4_0
I1210 12:09:03.257647 10416 net.cpp:380] conv11 -> conv11
I1210 12:09:03.259658 10416 net.cpp:122] Setting up conv11
I1210 12:09:03.259658 10416 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 12:09:03.259658 10416 net.cpp:137] Memory required for data: 475342000
I1210 12:09:03.259658 10416 layer_factory.cpp:58] Creating layer bn_conv11
I1210 12:09:03.259658 10416 net.cpp:84] Creating Layer bn_conv11
I1210 12:09:03.259658 10416 net.cpp:406] bn_conv11 <- conv11
I1210 12:09:03.259658 10416 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1210 12:09:03.259658 10416 net.cpp:122] Setting up bn_conv11
I1210 12:09:03.259658 10416 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 12:09:03.259658 10416 net.cpp:137] Memory required for data: 477134000
I1210 12:09:03.259658 10416 layer_factory.cpp:58] Creating layer scale_conv11
I1210 12:09:03.259658 10416 net.cpp:84] Creating Layer scale_conv11
I1210 12:09:03.259658 10416 net.cpp:406] scale_conv11 <- conv11
I1210 12:09:03.259658 10416 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1210 12:09:03.259658 10416 layer_factory.cpp:58] Creating layer scale_conv11
I1210 12:09:03.259658 10416 net.cpp:122] Setting up scale_conv11
I1210 12:09:03.259658 10416 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 12:09:03.259658 10416 net.cpp:137] Memory required for data: 478926000
I1210 12:09:03.259658 10416 layer_factory.cpp:58] Creating layer relu_conv11
I1210 12:09:03.259658 10416 net.cpp:84] Creating Layer relu_conv11
I1210 12:09:03.259658 10416 net.cpp:406] relu_conv11 <- conv11
I1210 12:09:03.259658 10416 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1210 12:09:03.260658 10416 net.cpp:122] Setting up relu_conv11
I1210 12:09:03.260658 10416 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 12:09:03.260658 10416 net.cpp:137] Memory required for data: 480718000
I1210 12:09:03.260658 10416 layer_factory.cpp:58] Creating layer conv12
I1210 12:09:03.260658 10416 net.cpp:84] Creating Layer conv12
I1210 12:09:03.260658 10416 net.cpp:406] conv12 <- conv11
I1210 12:09:03.260658 10416 net.cpp:380] conv12 -> conv12
I1210 12:09:03.261658 10416 net.cpp:122] Setting up conv12
I1210 12:09:03.261658 10416 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 12:09:03.261658 10416 net.cpp:137] Memory required for data: 483022000
I1210 12:09:03.262660 10416 layer_factory.cpp:58] Creating layer bn_conv12
I1210 12:09:03.262660 10416 net.cpp:84] Creating Layer bn_conv12
I1210 12:09:03.262660 10416 net.cpp:406] bn_conv12 <- conv12
I1210 12:09:03.262660 10416 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1210 12:09:03.262660 10416 net.cpp:122] Setting up bn_conv12
I1210 12:09:03.262660 10416 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 12:09:03.262660 10416 net.cpp:137] Memory required for data: 485326000
I1210 12:09:03.262660 10416 layer_factory.cpp:58] Creating layer scale_conv12
I1210 12:09:03.262660 10416 net.cpp:84] Creating Layer scale_conv12
I1210 12:09:03.262660 10416 net.cpp:406] scale_conv12 <- conv12
I1210 12:09:03.262660 10416 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1210 12:09:03.262660 10416 layer_factory.cpp:58] Creating layer scale_conv12
I1210 12:09:03.262660 10416 net.cpp:122] Setting up scale_conv12
I1210 12:09:03.262660 10416 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 12:09:03.262660 10416 net.cpp:137] Memory required for data: 487630000
I1210 12:09:03.262660 10416 layer_factory.cpp:58] Creating layer relu_conv12
I1210 12:09:03.262660 10416 net.cpp:84] Creating Layer relu_conv12
I1210 12:09:03.262660 10416 net.cpp:406] relu_conv12 <- conv12
I1210 12:09:03.262660 10416 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1210 12:09:03.263658 10416 net.cpp:122] Setting up relu_conv12
I1210 12:09:03.263658 10416 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 12:09:03.263658 10416 net.cpp:137] Memory required for data: 489934000
I1210 12:09:03.263658 10416 layer_factory.cpp:58] Creating layer poolcp6
I1210 12:09:03.263658 10416 net.cpp:84] Creating Layer poolcp6
I1210 12:09:03.263658 10416 net.cpp:406] poolcp6 <- conv12
I1210 12:09:03.263658 10416 net.cpp:380] poolcp6 -> poolcp6
I1210 12:09:03.263658 10416 net.cpp:122] Setting up poolcp6
I1210 12:09:03.263658 10416 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1210 12:09:03.263658 10416 net.cpp:137] Memory required for data: 489970000
I1210 12:09:03.263658 10416 layer_factory.cpp:58] Creating layer ip1
I1210 12:09:03.263658 10416 net.cpp:84] Creating Layer ip1
I1210 12:09:03.263658 10416 net.cpp:406] ip1 <- poolcp6
I1210 12:09:03.263658 10416 net.cpp:380] ip1 -> ip1
I1210 12:09:03.263658 10416 net.cpp:122] Setting up ip1
I1210 12:09:03.263658 10416 net.cpp:129] Top shape: 100 100 (10000)
I1210 12:09:03.263658 10416 net.cpp:137] Memory required for data: 490010000
I1210 12:09:03.263658 10416 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1210 12:09:03.263658 10416 net.cpp:84] Creating Layer ip1_ip1_0_split
I1210 12:09:03.263658 10416 net.cpp:406] ip1_ip1_0_split <- ip1
I1210 12:09:03.263658 10416 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1210 12:09:03.263658 10416 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1210 12:09:03.263658 10416 net.cpp:122] Setting up ip1_ip1_0_split
I1210 12:09:03.263658 10416 net.cpp:129] Top shape: 100 100 (10000)
I1210 12:09:03.263658 10416 net.cpp:129] Top shape: 100 100 (10000)
I1210 12:09:03.263658 10416 net.cpp:137] Memory required for data: 490090000
I1210 12:09:03.263658 10416 layer_factory.cpp:58] Creating layer accuracy_training
I1210 12:09:03.263658 10416 net.cpp:84] Creating Layer accuracy_training
I1210 12:09:03.263658 10416 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1210 12:09:03.263658 10416 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1210 12:09:03.263658 10416 net.cpp:380] accuracy_training -> accuracy_training
I1210 12:09:03.263658 10416 net.cpp:122] Setting up accuracy_training
I1210 12:09:03.263658 10416 net.cpp:129] Top shape: (1)
I1210 12:09:03.263658 10416 net.cpp:137] Memory required for data: 490090004
I1210 12:09:03.263658 10416 layer_factory.cpp:58] Creating layer loss
I1210 12:09:03.263658 10416 net.cpp:84] Creating Layer loss
I1210 12:09:03.263658 10416 net.cpp:406] loss <- ip1_ip1_0_split_1
I1210 12:09:03.263658 10416 net.cpp:406] loss <- label_cifar_1_split_1
I1210 12:09:03.263658 10416 net.cpp:380] loss -> loss
I1210 12:09:03.263658 10416 layer_factory.cpp:58] Creating layer loss
I1210 12:09:03.263658 10416 net.cpp:122] Setting up loss
I1210 12:09:03.264664 10416 net.cpp:129] Top shape: (1)
I1210 12:09:03.264664 10416 net.cpp:132]     with loss weight 1
I1210 12:09:03.264664 10416 net.cpp:137] Memory required for data: 490090008
I1210 12:09:03.264664 10416 net.cpp:198] loss needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:200] accuracy_training does not need backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] ip1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] poolcp6 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu_conv12 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale_conv12 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn_conv12 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv12 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu_conv11 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale_conv11 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn_conv11 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv11 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu4_0 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale4_0 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn4_0 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv4_0 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] pool4_2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] added_new_conv2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu4_2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale4_2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn4_2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv4_2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu4_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale4_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn4_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv4_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu4 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale4 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn4 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv4 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu3_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale3_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn3_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv3_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu3 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale3 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn3 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv3 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] pool2_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] newconv_added1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu2_2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale2_2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn2_2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv2_2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu2_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale2_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn2_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv2_1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv2 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu1_0 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale1_0 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn1_0 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv1_0 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] relu1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] scale1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] bn1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:198] conv1 needs backward computation.
I1210 12:09:03.264664 10416 net.cpp:200] label_cifar_1_split does not need backward computation.
I1210 12:09:03.264664 10416 net.cpp:200] cifar does not need backward computation.
I1210 12:09:03.264664 10416 net.cpp:242] This network produces output accuracy_training
I1210 12:09:03.264664 10416 net.cpp:242] This network produces output loss
I1210 12:09:03.264664 10416 net.cpp:255] Network initialization done.
I1210 12:09:03.265666 10416 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 12:09:03.265666 10416 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 12:09:03.265666 10416 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1210 12:09:03.265666 10416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1210 12:09:03.265666 10416 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_v2_360k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "newconv_added1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "newconv_added1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "newconv_added1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "added_new_conv2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "added_new_conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "added_new_conv2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1210 12:09:03.265666 10416 layer_factory.cpp:58] Creating layer cifar
I1210 12:09:03.271647 10416 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1210 12:09:03.272657 10416 net.cpp:84] Creating Layer cifar
I1210 12:09:03.272657 10416 net.cpp:380] cifar -> data
I1210 12:09:03.272657 10416 net.cpp:380] cifar -> label
I1210 12:09:03.272657 10416 data_layer.cpp:45] output data size: 100,3,32,32
I1210 12:09:03.279657 10416 net.cpp:122] Setting up cifar
I1210 12:09:03.279657 10416 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1210 12:09:03.279657 10416 net.cpp:129] Top shape: 100 (100)
I1210 12:09:03.279657 10416 net.cpp:137] Memory required for data: 1229200
I1210 12:09:03.279657 10416 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1210 12:09:03.279657 10416 net.cpp:84] Creating Layer label_cifar_1_split
I1210 12:09:03.280658 10416 net.cpp:406] label_cifar_1_split <- label
I1210 12:09:03.280658 10416 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1210 12:09:03.280658 10416 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1210 12:09:03.280658 10416 net.cpp:122] Setting up label_cifar_1_split
I1210 12:09:03.280658 10416 net.cpp:129] Top shape: 100 (100)
I1210 12:09:03.280658 10416 net.cpp:129] Top shape: 100 (100)
I1210 12:09:03.280658 10416 net.cpp:137] Memory required for data: 1230000
I1210 12:09:03.280658 10416 layer_factory.cpp:58] Creating layer conv1
I1210 12:09:03.280658 10416 net.cpp:84] Creating Layer conv1
I1210 12:09:03.280658 10416 net.cpp:406] conv1 <- data
I1210 12:09:03.280658 10416 net.cpp:380] conv1 -> conv1
I1210 12:09:03.281648 10416 net.cpp:122] Setting up conv1
I1210 12:09:03.281648 10416 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 12:09:03.281648 10416 net.cpp:137] Memory required for data: 13518000
I1210 12:09:03.281648 10416 layer_factory.cpp:58] Creating layer bn1
I1210 12:09:03.281648 10416 net.cpp:84] Creating Layer bn1
I1210 12:09:03.281648 10416 net.cpp:406] bn1 <- conv1
I1210 12:09:03.281648  7476 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 12:09:03.281648 10416 net.cpp:367] bn1 -> conv1 (in-place)
I1210 12:09:03.282649 10416 net.cpp:122] Setting up bn1
I1210 12:09:03.282649 10416 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 12:09:03.282649 10416 net.cpp:137] Memory required for data: 25806000
I1210 12:09:03.282649 10416 layer_factory.cpp:58] Creating layer scale1
I1210 12:09:03.282649 10416 net.cpp:84] Creating Layer scale1
I1210 12:09:03.282649 10416 net.cpp:406] scale1 <- conv1
I1210 12:09:03.282649 10416 net.cpp:367] scale1 -> conv1 (in-place)
I1210 12:09:03.282649 10416 layer_factory.cpp:58] Creating layer scale1
I1210 12:09:03.282649 10416 net.cpp:122] Setting up scale1
I1210 12:09:03.282649 10416 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 12:09:03.282649 10416 net.cpp:137] Memory required for data: 38094000
I1210 12:09:03.282649 10416 layer_factory.cpp:58] Creating layer relu1
I1210 12:09:03.282649 10416 net.cpp:84] Creating Layer relu1
I1210 12:09:03.282649 10416 net.cpp:406] relu1 <- conv1
I1210 12:09:03.282649 10416 net.cpp:367] relu1 -> conv1 (in-place)
I1210 12:09:03.283650 10416 net.cpp:122] Setting up relu1
I1210 12:09:03.283650 10416 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 12:09:03.283650 10416 net.cpp:137] Memory required for data: 50382000
I1210 12:09:03.283650 10416 layer_factory.cpp:58] Creating layer conv1_0
I1210 12:09:03.283650 10416 net.cpp:84] Creating Layer conv1_0
I1210 12:09:03.283650 10416 net.cpp:406] conv1_0 <- conv1
I1210 12:09:03.283650 10416 net.cpp:380] conv1_0 -> conv1_0
I1210 12:09:03.284664 10416 net.cpp:122] Setting up conv1_0
I1210 12:09:03.284664 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.284664 10416 net.cpp:137] Memory required for data: 66766000
I1210 12:09:03.284664 10416 layer_factory.cpp:58] Creating layer bn1_0
I1210 12:09:03.284664 10416 net.cpp:84] Creating Layer bn1_0
I1210 12:09:03.284664 10416 net.cpp:406] bn1_0 <- conv1_0
I1210 12:09:03.284664 10416 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1210 12:09:03.284664 10416 net.cpp:122] Setting up bn1_0
I1210 12:09:03.284664 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.284664 10416 net.cpp:137] Memory required for data: 83150000
I1210 12:09:03.284664 10416 layer_factory.cpp:58] Creating layer scale1_0
I1210 12:09:03.284664 10416 net.cpp:84] Creating Layer scale1_0
I1210 12:09:03.284664 10416 net.cpp:406] scale1_0 <- conv1_0
I1210 12:09:03.284664 10416 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1210 12:09:03.284664 10416 layer_factory.cpp:58] Creating layer scale1_0
I1210 12:09:03.285663 10416 net.cpp:122] Setting up scale1_0
I1210 12:09:03.285663 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.285663 10416 net.cpp:137] Memory required for data: 99534000
I1210 12:09:03.285663 10416 layer_factory.cpp:58] Creating layer relu1_0
I1210 12:09:03.285663 10416 net.cpp:84] Creating Layer relu1_0
I1210 12:09:03.285663 10416 net.cpp:406] relu1_0 <- conv1_0
I1210 12:09:03.285663 10416 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1210 12:09:03.285663 10416 net.cpp:122] Setting up relu1_0
I1210 12:09:03.285663 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.285663 10416 net.cpp:137] Memory required for data: 115918000
I1210 12:09:03.285663 10416 layer_factory.cpp:58] Creating layer conv2
I1210 12:09:03.285663 10416 net.cpp:84] Creating Layer conv2
I1210 12:09:03.285663 10416 net.cpp:406] conv2 <- conv1_0
I1210 12:09:03.285663 10416 net.cpp:380] conv2 -> conv2
I1210 12:09:03.287652 10416 net.cpp:122] Setting up conv2
I1210 12:09:03.287652 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.287652 10416 net.cpp:137] Memory required for data: 132302000
I1210 12:09:03.287652 10416 layer_factory.cpp:58] Creating layer bn2
I1210 12:09:03.287652 10416 net.cpp:84] Creating Layer bn2
I1210 12:09:03.287652 10416 net.cpp:406] bn2 <- conv2
I1210 12:09:03.287652 10416 net.cpp:367] bn2 -> conv2 (in-place)
I1210 12:09:03.287652 10416 net.cpp:122] Setting up bn2
I1210 12:09:03.287652 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.287652 10416 net.cpp:137] Memory required for data: 148686000
I1210 12:09:03.287652 10416 layer_factory.cpp:58] Creating layer scale2
I1210 12:09:03.287652 10416 net.cpp:84] Creating Layer scale2
I1210 12:09:03.287652 10416 net.cpp:406] scale2 <- conv2
I1210 12:09:03.287652 10416 net.cpp:367] scale2 -> conv2 (in-place)
I1210 12:09:03.287652 10416 layer_factory.cpp:58] Creating layer scale2
I1210 12:09:03.287652 10416 net.cpp:122] Setting up scale2
I1210 12:09:03.287652 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.287652 10416 net.cpp:137] Memory required for data: 165070000
I1210 12:09:03.287652 10416 layer_factory.cpp:58] Creating layer relu2
I1210 12:09:03.287652 10416 net.cpp:84] Creating Layer relu2
I1210 12:09:03.287652 10416 net.cpp:406] relu2 <- conv2
I1210 12:09:03.287652 10416 net.cpp:367] relu2 -> conv2 (in-place)
I1210 12:09:03.288651 10416 net.cpp:122] Setting up relu2
I1210 12:09:03.288651 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.288651 10416 net.cpp:137] Memory required for data: 181454000
I1210 12:09:03.289649 10416 layer_factory.cpp:58] Creating layer conv2_1
I1210 12:09:03.289649 10416 net.cpp:84] Creating Layer conv2_1
I1210 12:09:03.289649 10416 net.cpp:406] conv2_1 <- conv2
I1210 12:09:03.289649 10416 net.cpp:380] conv2_1 -> conv2_1
I1210 12:09:03.290663 10416 net.cpp:122] Setting up conv2_1
I1210 12:09:03.290663 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.290663 10416 net.cpp:137] Memory required for data: 197838000
I1210 12:09:03.290663 10416 layer_factory.cpp:58] Creating layer bn2_1
I1210 12:09:03.290663 10416 net.cpp:84] Creating Layer bn2_1
I1210 12:09:03.290663 10416 net.cpp:406] bn2_1 <- conv2_1
I1210 12:09:03.290663 10416 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1210 12:09:03.290663 10416 net.cpp:122] Setting up bn2_1
I1210 12:09:03.290663 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.290663 10416 net.cpp:137] Memory required for data: 214222000
I1210 12:09:03.290663 10416 layer_factory.cpp:58] Creating layer scale2_1
I1210 12:09:03.290663 10416 net.cpp:84] Creating Layer scale2_1
I1210 12:09:03.290663 10416 net.cpp:406] scale2_1 <- conv2_1
I1210 12:09:03.290663 10416 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1210 12:09:03.290663 10416 layer_factory.cpp:58] Creating layer scale2_1
I1210 12:09:03.290663 10416 net.cpp:122] Setting up scale2_1
I1210 12:09:03.290663 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.290663 10416 net.cpp:137] Memory required for data: 230606000
I1210 12:09:03.290663 10416 layer_factory.cpp:58] Creating layer relu2_1
I1210 12:09:03.290663 10416 net.cpp:84] Creating Layer relu2_1
I1210 12:09:03.290663 10416 net.cpp:406] relu2_1 <- conv2_1
I1210 12:09:03.290663 10416 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1210 12:09:03.291668 10416 net.cpp:122] Setting up relu2_1
I1210 12:09:03.291668 10416 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 12:09:03.291668 10416 net.cpp:137] Memory required for data: 246990000
I1210 12:09:03.291668 10416 layer_factory.cpp:58] Creating layer conv2_2
I1210 12:09:03.291668 10416 net.cpp:84] Creating Layer conv2_2
I1210 12:09:03.291668 10416 net.cpp:406] conv2_2 <- conv2_1
I1210 12:09:03.291668 10416 net.cpp:380] conv2_2 -> conv2_2
I1210 12:09:03.293665 10416 net.cpp:122] Setting up conv2_2
I1210 12:09:03.293665 10416 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 12:09:03.293665 10416 net.cpp:137] Memory required for data: 267470000
I1210 12:09:03.293665 10416 layer_factory.cpp:58] Creating layer bn2_2
I1210 12:09:03.293665 10416 net.cpp:84] Creating Layer bn2_2
I1210 12:09:03.293665 10416 net.cpp:406] bn2_2 <- conv2_2
I1210 12:09:03.293665 10416 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1210 12:09:03.293665 10416 net.cpp:122] Setting up bn2_2
I1210 12:09:03.293665 10416 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 12:09:03.293665 10416 net.cpp:137] Memory required for data: 287950000
I1210 12:09:03.293665 10416 layer_factory.cpp:58] Creating layer scale2_2
I1210 12:09:03.293665 10416 net.cpp:84] Creating Layer scale2_2
I1210 12:09:03.293665 10416 net.cpp:406] scale2_2 <- conv2_2
I1210 12:09:03.293665 10416 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1210 12:09:03.293665 10416 layer_factory.cpp:58] Creating layer scale2_2
I1210 12:09:03.293665 10416 net.cpp:122] Setting up scale2_2
I1210 12:09:03.293665 10416 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 12:09:03.293665 10416 net.cpp:137] Memory required for data: 308430000
I1210 12:09:03.293665 10416 layer_factory.cpp:58] Creating layer relu2_2
I1210 12:09:03.293665 10416 net.cpp:84] Creating Layer relu2_2
I1210 12:09:03.293665 10416 net.cpp:406] relu2_2 <- conv2_2
I1210 12:09:03.293665 10416 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1210 12:09:03.293665 10416 net.cpp:122] Setting up relu2_2
I1210 12:09:03.293665 10416 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 12:09:03.293665 10416 net.cpp:137] Memory required for data: 328910000
I1210 12:09:03.293665 10416 layer_factory.cpp:58] Creating layer newconv_added1
I1210 12:09:03.293665 10416 net.cpp:84] Creating Layer newconv_added1
I1210 12:09:03.293665 10416 net.cpp:406] newconv_added1 <- conv2_2
I1210 12:09:03.293665 10416 net.cpp:380] newconv_added1 -> newconv_added1
I1210 12:09:03.295663 10416 net.cpp:122] Setting up newconv_added1
I1210 12:09:03.295663 10416 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 12:09:03.295663 10416 net.cpp:137] Memory required for data: 349390000
I1210 12:09:03.295663 10416 layer_factory.cpp:58] Creating layer pool2_1
I1210 12:09:03.295663 10416 net.cpp:84] Creating Layer pool2_1
I1210 12:09:03.295663 10416 net.cpp:406] pool2_1 <- newconv_added1
I1210 12:09:03.295663 10416 net.cpp:380] pool2_1 -> pool2_1
I1210 12:09:03.295663 10416 net.cpp:122] Setting up pool2_1
I1210 12:09:03.295663 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.295663 10416 net.cpp:137] Memory required for data: 354510000
I1210 12:09:03.295663 10416 layer_factory.cpp:58] Creating layer conv3
I1210 12:09:03.295663 10416 net.cpp:84] Creating Layer conv3
I1210 12:09:03.295663 10416 net.cpp:406] conv3 <- pool2_1
I1210 12:09:03.295663 10416 net.cpp:380] conv3 -> conv3
I1210 12:09:03.296664 10416 net.cpp:122] Setting up conv3
I1210 12:09:03.296664 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.296664 10416 net.cpp:137] Memory required for data: 359630000
I1210 12:09:03.296664 10416 layer_factory.cpp:58] Creating layer bn3
I1210 12:09:03.296664 10416 net.cpp:84] Creating Layer bn3
I1210 12:09:03.296664 10416 net.cpp:406] bn3 <- conv3
I1210 12:09:03.296664 10416 net.cpp:367] bn3 -> conv3 (in-place)
I1210 12:09:03.297662 10416 net.cpp:122] Setting up bn3
I1210 12:09:03.297662 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.297662 10416 net.cpp:137] Memory required for data: 364750000
I1210 12:09:03.297662 10416 layer_factory.cpp:58] Creating layer scale3
I1210 12:09:03.297662 10416 net.cpp:84] Creating Layer scale3
I1210 12:09:03.297662 10416 net.cpp:406] scale3 <- conv3
I1210 12:09:03.297662 10416 net.cpp:367] scale3 -> conv3 (in-place)
I1210 12:09:03.297662 10416 layer_factory.cpp:58] Creating layer scale3
I1210 12:09:03.297662 10416 net.cpp:122] Setting up scale3
I1210 12:09:03.297662 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.297662 10416 net.cpp:137] Memory required for data: 369870000
I1210 12:09:03.297662 10416 layer_factory.cpp:58] Creating layer relu3
I1210 12:09:03.297662 10416 net.cpp:84] Creating Layer relu3
I1210 12:09:03.297662 10416 net.cpp:406] relu3 <- conv3
I1210 12:09:03.297662 10416 net.cpp:367] relu3 -> conv3 (in-place)
I1210 12:09:03.297662 10416 net.cpp:122] Setting up relu3
I1210 12:09:03.297662 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.297662 10416 net.cpp:137] Memory required for data: 374990000
I1210 12:09:03.297662 10416 layer_factory.cpp:58] Creating layer conv3_1
I1210 12:09:03.297662 10416 net.cpp:84] Creating Layer conv3_1
I1210 12:09:03.297662 10416 net.cpp:406] conv3_1 <- conv3
I1210 12:09:03.297662 10416 net.cpp:380] conv3_1 -> conv3_1
I1210 12:09:03.299664 10416 net.cpp:122] Setting up conv3_1
I1210 12:09:03.299664 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.299664 10416 net.cpp:137] Memory required for data: 380110000
I1210 12:09:03.299664 10416 layer_factory.cpp:58] Creating layer bn3_1
I1210 12:09:03.299664 10416 net.cpp:84] Creating Layer bn3_1
I1210 12:09:03.299664 10416 net.cpp:406] bn3_1 <- conv3_1
I1210 12:09:03.299664 10416 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1210 12:09:03.299664 10416 net.cpp:122] Setting up bn3_1
I1210 12:09:03.299664 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.299664 10416 net.cpp:137] Memory required for data: 385230000
I1210 12:09:03.299664 10416 layer_factory.cpp:58] Creating layer scale3_1
I1210 12:09:03.299664 10416 net.cpp:84] Creating Layer scale3_1
I1210 12:09:03.299664 10416 net.cpp:406] scale3_1 <- conv3_1
I1210 12:09:03.299664 10416 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1210 12:09:03.299664 10416 layer_factory.cpp:58] Creating layer scale3_1
I1210 12:09:03.299664 10416 net.cpp:122] Setting up scale3_1
I1210 12:09:03.299664 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.299664 10416 net.cpp:137] Memory required for data: 390350000
I1210 12:09:03.299664 10416 layer_factory.cpp:58] Creating layer relu3_1
I1210 12:09:03.299664 10416 net.cpp:84] Creating Layer relu3_1
I1210 12:09:03.299664 10416 net.cpp:406] relu3_1 <- conv3_1
I1210 12:09:03.299664 10416 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1210 12:09:03.299664 10416 net.cpp:122] Setting up relu3_1
I1210 12:09:03.299664 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.299664 10416 net.cpp:137] Memory required for data: 395470000
I1210 12:09:03.299664 10416 layer_factory.cpp:58] Creating layer conv4
I1210 12:09:03.299664 10416 net.cpp:84] Creating Layer conv4
I1210 12:09:03.299664 10416 net.cpp:406] conv4 <- conv3_1
I1210 12:09:03.299664 10416 net.cpp:380] conv4 -> conv4
I1210 12:09:03.300664 10416 net.cpp:122] Setting up conv4
I1210 12:09:03.300664 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.301662 10416 net.cpp:137] Memory required for data: 400590000
I1210 12:09:03.301662 10416 layer_factory.cpp:58] Creating layer bn4
I1210 12:09:03.301662 10416 net.cpp:84] Creating Layer bn4
I1210 12:09:03.301662 10416 net.cpp:406] bn4 <- conv4
I1210 12:09:03.301662 10416 net.cpp:367] bn4 -> conv4 (in-place)
I1210 12:09:03.301662 10416 net.cpp:122] Setting up bn4
I1210 12:09:03.301662 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.301662 10416 net.cpp:137] Memory required for data: 405710000
I1210 12:09:03.301662 10416 layer_factory.cpp:58] Creating layer scale4
I1210 12:09:03.301662 10416 net.cpp:84] Creating Layer scale4
I1210 12:09:03.301662 10416 net.cpp:406] scale4 <- conv4
I1210 12:09:03.301662 10416 net.cpp:367] scale4 -> conv4 (in-place)
I1210 12:09:03.301662 10416 layer_factory.cpp:58] Creating layer scale4
I1210 12:09:03.301662 10416 net.cpp:122] Setting up scale4
I1210 12:09:03.301662 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.301662 10416 net.cpp:137] Memory required for data: 410830000
I1210 12:09:03.301662 10416 layer_factory.cpp:58] Creating layer relu4
I1210 12:09:03.301662 10416 net.cpp:84] Creating Layer relu4
I1210 12:09:03.301662 10416 net.cpp:406] relu4 <- conv4
I1210 12:09:03.301662 10416 net.cpp:367] relu4 -> conv4 (in-place)
I1210 12:09:03.301662 10416 net.cpp:122] Setting up relu4
I1210 12:09:03.301662 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.301662 10416 net.cpp:137] Memory required for data: 415950000
I1210 12:09:03.301662 10416 layer_factory.cpp:58] Creating layer conv4_1
I1210 12:09:03.301662 10416 net.cpp:84] Creating Layer conv4_1
I1210 12:09:03.301662 10416 net.cpp:406] conv4_1 <- conv4
I1210 12:09:03.301662 10416 net.cpp:380] conv4_1 -> conv4_1
I1210 12:09:03.303648 10416 net.cpp:122] Setting up conv4_1
I1210 12:09:03.303648 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.303648 10416 net.cpp:137] Memory required for data: 421070000
I1210 12:09:03.303648 10416 layer_factory.cpp:58] Creating layer bn4_1
I1210 12:09:03.303648 10416 net.cpp:84] Creating Layer bn4_1
I1210 12:09:03.303648 10416 net.cpp:406] bn4_1 <- conv4_1
I1210 12:09:03.303648 10416 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1210 12:09:03.303648 10416 net.cpp:122] Setting up bn4_1
I1210 12:09:03.303648 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.303648 10416 net.cpp:137] Memory required for data: 426190000
I1210 12:09:03.303648 10416 layer_factory.cpp:58] Creating layer scale4_1
I1210 12:09:03.303648 10416 net.cpp:84] Creating Layer scale4_1
I1210 12:09:03.303648 10416 net.cpp:406] scale4_1 <- conv4_1
I1210 12:09:03.303648 10416 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1210 12:09:03.303648 10416 layer_factory.cpp:58] Creating layer scale4_1
I1210 12:09:03.303648 10416 net.cpp:122] Setting up scale4_1
I1210 12:09:03.303648 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.303648 10416 net.cpp:137] Memory required for data: 431310000
I1210 12:09:03.303648 10416 layer_factory.cpp:58] Creating layer relu4_1
I1210 12:09:03.303648 10416 net.cpp:84] Creating Layer relu4_1
I1210 12:09:03.303648 10416 net.cpp:406] relu4_1 <- conv4_1
I1210 12:09:03.303648 10416 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1210 12:09:03.303648 10416 net.cpp:122] Setting up relu4_1
I1210 12:09:03.303648 10416 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 12:09:03.303648 10416 net.cpp:137] Memory required for data: 436430000
I1210 12:09:03.303648 10416 layer_factory.cpp:58] Creating layer conv4_2
I1210 12:09:03.303648 10416 net.cpp:84] Creating Layer conv4_2
I1210 12:09:03.303648 10416 net.cpp:406] conv4_2 <- conv4_1
I1210 12:09:03.303648 10416 net.cpp:380] conv4_2 -> conv4_2
I1210 12:09:03.306668 10416 net.cpp:122] Setting up conv4_2
I1210 12:09:03.306668 10416 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 12:09:03.306668 10416 net.cpp:137] Memory required for data: 442369200
I1210 12:09:03.306668 10416 layer_factory.cpp:58] Creating layer bn4_2
I1210 12:09:03.306668 10416 net.cpp:84] Creating Layer bn4_2
I1210 12:09:03.306668 10416 net.cpp:406] bn4_2 <- conv4_2
I1210 12:09:03.306668 10416 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1210 12:09:03.306668 10416 net.cpp:122] Setting up bn4_2
I1210 12:09:03.306668 10416 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 12:09:03.306668 10416 net.cpp:137] Memory required for data: 448308400
I1210 12:09:03.306668 10416 layer_factory.cpp:58] Creating layer scale4_2
I1210 12:09:03.306668 10416 net.cpp:84] Creating Layer scale4_2
I1210 12:09:03.306668 10416 net.cpp:406] scale4_2 <- conv4_2
I1210 12:09:03.306668 10416 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1210 12:09:03.306668 10416 layer_factory.cpp:58] Creating layer scale4_2
I1210 12:09:03.306668 10416 net.cpp:122] Setting up scale4_2
I1210 12:09:03.306668 10416 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 12:09:03.306668 10416 net.cpp:137] Memory required for data: 454247600
I1210 12:09:03.306668 10416 layer_factory.cpp:58] Creating layer relu4_2
I1210 12:09:03.306668 10416 net.cpp:84] Creating Layer relu4_2
I1210 12:09:03.306668 10416 net.cpp:406] relu4_2 <- conv4_2
I1210 12:09:03.306668 10416 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1210 12:09:03.307668 10416 net.cpp:122] Setting up relu4_2
I1210 12:09:03.307668 10416 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 12:09:03.307668 10416 net.cpp:137] Memory required for data: 460186800
I1210 12:09:03.307668 10416 layer_factory.cpp:58] Creating layer added_new_conv2
I1210 12:09:03.307668 10416 net.cpp:84] Creating Layer added_new_conv2
I1210 12:09:03.307668 10416 net.cpp:406] added_new_conv2 <- conv4_2
I1210 12:09:03.307668 10416 net.cpp:380] added_new_conv2 -> added_new_conv2
I1210 12:09:03.308662 10416 net.cpp:122] Setting up added_new_conv2
I1210 12:09:03.308662 10416 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 12:09:03.308662 10416 net.cpp:137] Memory required for data: 466126000
I1210 12:09:03.308662 10416 layer_factory.cpp:58] Creating layer pool4_2
I1210 12:09:03.308662 10416 net.cpp:84] Creating Layer pool4_2
I1210 12:09:03.308662 10416 net.cpp:406] pool4_2 <- added_new_conv2
I1210 12:09:03.308662 10416 net.cpp:380] pool4_2 -> pool4_2
I1210 12:09:03.308662 10416 net.cpp:122] Setting up pool4_2
I1210 12:09:03.308662 10416 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 12:09:03.308662 10416 net.cpp:137] Memory required for data: 467610800
I1210 12:09:03.308662 10416 layer_factory.cpp:58] Creating layer conv4_0
I1210 12:09:03.308662 10416 net.cpp:84] Creating Layer conv4_0
I1210 12:09:03.308662 10416 net.cpp:406] conv4_0 <- pool4_2
I1210 12:09:03.308662 10416 net.cpp:380] conv4_0 -> conv4_0
I1210 12:09:03.310664 10416 net.cpp:122] Setting up conv4_0
I1210 12:09:03.310664 10416 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 12:09:03.310664 10416 net.cpp:137] Memory required for data: 469095600
I1210 12:09:03.310664 10416 layer_factory.cpp:58] Creating layer bn4_0
I1210 12:09:03.310664 10416 net.cpp:84] Creating Layer bn4_0
I1210 12:09:03.310664 10416 net.cpp:406] bn4_0 <- conv4_0
I1210 12:09:03.310664 10416 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1210 12:09:03.310664 10416 net.cpp:122] Setting up bn4_0
I1210 12:09:03.310664 10416 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 12:09:03.310664 10416 net.cpp:137] Memory required for data: 470580400
I1210 12:09:03.310664 10416 layer_factory.cpp:58] Creating layer scale4_0
I1210 12:09:03.310664 10416 net.cpp:84] Creating Layer scale4_0
I1210 12:09:03.310664 10416 net.cpp:406] scale4_0 <- conv4_0
I1210 12:09:03.310664 10416 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1210 12:09:03.311647 10416 layer_factory.cpp:58] Creating layer scale4_0
I1210 12:09:03.311647 10416 net.cpp:122] Setting up scale4_0
I1210 12:09:03.311647 10416 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 12:09:03.311647 10416 net.cpp:137] Memory required for data: 472065200
I1210 12:09:03.311647 10416 layer_factory.cpp:58] Creating layer relu4_0
I1210 12:09:03.311647 10416 net.cpp:84] Creating Layer relu4_0
I1210 12:09:03.311647 10416 net.cpp:406] relu4_0 <- conv4_0
I1210 12:09:03.311647 10416 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1210 12:09:03.311647 10416 net.cpp:122] Setting up relu4_0
I1210 12:09:03.311647 10416 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 12:09:03.311647 10416 net.cpp:137] Memory required for data: 473550000
I1210 12:09:03.311647 10416 layer_factory.cpp:58] Creating layer conv11
I1210 12:09:03.311647 10416 net.cpp:84] Creating Layer conv11
I1210 12:09:03.311647 10416 net.cpp:406] conv11 <- conv4_0
I1210 12:09:03.311647 10416 net.cpp:380] conv11 -> conv11
I1210 12:09:03.313668 10416 net.cpp:122] Setting up conv11
I1210 12:09:03.313668 10416 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 12:09:03.313668 10416 net.cpp:137] Memory required for data: 475342000
I1210 12:09:03.313668 10416 layer_factory.cpp:58] Creating layer bn_conv11
I1210 12:09:03.313668 10416 net.cpp:84] Creating Layer bn_conv11
I1210 12:09:03.313668 10416 net.cpp:406] bn_conv11 <- conv11
I1210 12:09:03.313668 10416 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1210 12:09:03.313668 10416 net.cpp:122] Setting up bn_conv11
I1210 12:09:03.313668 10416 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 12:09:03.313668 10416 net.cpp:137] Memory required for data: 477134000
I1210 12:09:03.313668 10416 layer_factory.cpp:58] Creating layer scale_conv11
I1210 12:09:03.313668 10416 net.cpp:84] Creating Layer scale_conv11
I1210 12:09:03.313668 10416 net.cpp:406] scale_conv11 <- conv11
I1210 12:09:03.313668 10416 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1210 12:09:03.313668 10416 layer_factory.cpp:58] Creating layer scale_conv11
I1210 12:09:03.313668 10416 net.cpp:122] Setting up scale_conv11
I1210 12:09:03.313668 10416 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 12:09:03.313668 10416 net.cpp:137] Memory required for data: 478926000
I1210 12:09:03.313668 10416 layer_factory.cpp:58] Creating layer relu_conv11
I1210 12:09:03.313668 10416 net.cpp:84] Creating Layer relu_conv11
I1210 12:09:03.313668 10416 net.cpp:406] relu_conv11 <- conv11
I1210 12:09:03.313668 10416 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1210 12:09:03.313668 10416 net.cpp:122] Setting up relu_conv11
I1210 12:09:03.313668 10416 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 12:09:03.313668 10416 net.cpp:137] Memory required for data: 480718000
I1210 12:09:03.313668 10416 layer_factory.cpp:58] Creating layer conv12
I1210 12:09:03.313668 10416 net.cpp:84] Creating Layer conv12
I1210 12:09:03.313668 10416 net.cpp:406] conv12 <- conv11
I1210 12:09:03.313668 10416 net.cpp:380] conv12 -> conv12
I1210 12:09:03.315670 10416 net.cpp:122] Setting up conv12
I1210 12:09:03.315670 10416 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 12:09:03.315670 10416 net.cpp:137] Memory required for data: 483022000
I1210 12:09:03.315670 10416 layer_factory.cpp:58] Creating layer bn_conv12
I1210 12:09:03.315670 10416 net.cpp:84] Creating Layer bn_conv12
I1210 12:09:03.315670 10416 net.cpp:406] bn_conv12 <- conv12
I1210 12:09:03.315670 10416 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1210 12:09:03.315670 10416 net.cpp:122] Setting up bn_conv12
I1210 12:09:03.315670 10416 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 12:09:03.315670 10416 net.cpp:137] Memory required for data: 485326000
I1210 12:09:03.315670 10416 layer_factory.cpp:58] Creating layer scale_conv12
I1210 12:09:03.315670 10416 net.cpp:84] Creating Layer scale_conv12
I1210 12:09:03.315670 10416 net.cpp:406] scale_conv12 <- conv12
I1210 12:09:03.315670 10416 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1210 12:09:03.316663 10416 layer_factory.cpp:58] Creating layer scale_conv12
I1210 12:09:03.316663 10416 net.cpp:122] Setting up scale_conv12
I1210 12:09:03.316663 10416 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 12:09:03.316663 10416 net.cpp:137] Memory required for data: 487630000
I1210 12:09:03.316663 10416 layer_factory.cpp:58] Creating layer relu_conv12
I1210 12:09:03.316663 10416 net.cpp:84] Creating Layer relu_conv12
I1210 12:09:03.316663 10416 net.cpp:406] relu_conv12 <- conv12
I1210 12:09:03.316663 10416 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1210 12:09:03.316663 10416 net.cpp:122] Setting up relu_conv12
I1210 12:09:03.316663 10416 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 12:09:03.316663 10416 net.cpp:137] Memory required for data: 489934000
I1210 12:09:03.316663 10416 layer_factory.cpp:58] Creating layer poolcp6
I1210 12:09:03.316663 10416 net.cpp:84] Creating Layer poolcp6
I1210 12:09:03.316663 10416 net.cpp:406] poolcp6 <- conv12
I1210 12:09:03.316663 10416 net.cpp:380] poolcp6 -> poolcp6
I1210 12:09:03.316663 10416 net.cpp:122] Setting up poolcp6
I1210 12:09:03.316663 10416 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1210 12:09:03.316663 10416 net.cpp:137] Memory required for data: 489970000
I1210 12:09:03.316663 10416 layer_factory.cpp:58] Creating layer ip1
I1210 12:09:03.316663 10416 net.cpp:84] Creating Layer ip1
I1210 12:09:03.316663 10416 net.cpp:406] ip1 <- poolcp6
I1210 12:09:03.316663 10416 net.cpp:380] ip1 -> ip1
I1210 12:09:03.316663 10416 net.cpp:122] Setting up ip1
I1210 12:09:03.316663 10416 net.cpp:129] Top shape: 100 100 (10000)
I1210 12:09:03.316663 10416 net.cpp:137] Memory required for data: 490010000
I1210 12:09:03.316663 10416 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1210 12:09:03.316663 10416 net.cpp:84] Creating Layer ip1_ip1_0_split
I1210 12:09:03.316663 10416 net.cpp:406] ip1_ip1_0_split <- ip1
I1210 12:09:03.316663 10416 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1210 12:09:03.316663 10416 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1210 12:09:03.316663 10416 net.cpp:122] Setting up ip1_ip1_0_split
I1210 12:09:03.316663 10416 net.cpp:129] Top shape: 100 100 (10000)
I1210 12:09:03.316663 10416 net.cpp:129] Top shape: 100 100 (10000)
I1210 12:09:03.316663 10416 net.cpp:137] Memory required for data: 490090000
I1210 12:09:03.316663 10416 layer_factory.cpp:58] Creating layer accuracy
I1210 12:09:03.316663 10416 net.cpp:84] Creating Layer accuracy
I1210 12:09:03.316663 10416 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1210 12:09:03.316663 10416 net.cpp:406] accuracy <- label_cifar_1_split_0
I1210 12:09:03.316663 10416 net.cpp:380] accuracy -> accuracy
I1210 12:09:03.316663 10416 net.cpp:122] Setting up accuracy
I1210 12:09:03.316663 10416 net.cpp:129] Top shape: (1)
I1210 12:09:03.316663 10416 net.cpp:137] Memory required for data: 490090004
I1210 12:09:03.316663 10416 layer_factory.cpp:58] Creating layer loss
I1210 12:09:03.316663 10416 net.cpp:84] Creating Layer loss
I1210 12:09:03.316663 10416 net.cpp:406] loss <- ip1_ip1_0_split_1
I1210 12:09:03.316663 10416 net.cpp:406] loss <- label_cifar_1_split_1
I1210 12:09:03.316663 10416 net.cpp:380] loss -> loss
I1210 12:09:03.316663 10416 layer_factory.cpp:58] Creating layer loss
I1210 12:09:03.317663 10416 net.cpp:122] Setting up loss
I1210 12:09:03.317663 10416 net.cpp:129] Top shape: (1)
I1210 12:09:03.317663 10416 net.cpp:132]     with loss weight 1
I1210 12:09:03.317663 10416 net.cpp:137] Memory required for data: 490090008
I1210 12:09:03.317663 10416 net.cpp:198] loss needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:200] accuracy does not need backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] ip1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] poolcp6 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu_conv12 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale_conv12 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn_conv12 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv12 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu_conv11 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale_conv11 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn_conv11 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv11 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu4_0 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale4_0 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn4_0 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv4_0 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] pool4_2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] added_new_conv2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu4_2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale4_2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn4_2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv4_2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu4_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale4_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn4_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv4_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu4 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale4 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn4 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv4 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu3_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale3_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn3_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv3_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu3 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale3 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn3 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv3 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] pool2_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] newconv_added1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu2_2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale2_2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn2_2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv2_2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu2_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale2_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn2_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv2_1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv2 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu1_0 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale1_0 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn1_0 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv1_0 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] relu1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] scale1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] bn1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:198] conv1 needs backward computation.
I1210 12:09:03.317663 10416 net.cpp:200] label_cifar_1_split does not need backward computation.
I1210 12:09:03.317663 10416 net.cpp:200] cifar does not need backward computation.
I1210 12:09:03.317663 10416 net.cpp:242] This network produces output accuracy
I1210 12:09:03.317663 10416 net.cpp:242] This network produces output loss
I1210 12:09:03.317663 10416 net.cpp:255] Network initialization done.
I1210 12:09:03.317663 10416 solver.cpp:56] Solver scaffolding done.
I1210 12:09:03.322651 10416 caffe.cpp:249] Starting Optimization
I1210 12:09:03.322651 10416 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_v2_360k
I1210 12:09:03.322651 10416 solver.cpp:273] Learning Rate Policy: multistep
I1210 12:09:03.325667 10416 solver.cpp:330] Iteration 0, Testing net (#0)
I1210 12:09:03.327666 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:09:04.759251  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:09:04.812247 10416 solver.cpp:397]     Test net output #0: accuracy = 0.0103
I1210 12:09:04.812247 10416 solver.cpp:397]     Test net output #1: loss = 86.437 (* 1 = 86.437 loss)
I1210 12:09:04.919303 10416 solver.cpp:218] Iteration 0 (0 iter/s, 1.59486s/100 iters), loss = 6.48243
I1210 12:09:04.919303 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.02
I1210 12:09:04.919303 10416 solver.cpp:237]     Train net output #1: loss = 6.48243 (* 1 = 6.48243 loss)
I1210 12:09:04.919303 10416 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1210 12:09:10.747778 10416 solver.cpp:218] Iteration 100 (17.1575 iter/s, 5.82837s/100 iters), loss = 4.41978
I1210 12:09:10.747778 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.04
I1210 12:09:10.747778 10416 solver.cpp:237]     Train net output #1: loss = 4.41978 (* 1 = 4.41978 loss)
I1210 12:09:10.747778 10416 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1210 12:09:16.467068 10416 solver.cpp:218] Iteration 200 (17.4847 iter/s, 5.71928s/100 iters), loss = 4.23659
I1210 12:09:16.467068 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.04
I1210 12:09:16.467068 10416 solver.cpp:237]     Train net output #1: loss = 4.23659 (* 1 = 4.23659 loss)
I1210 12:09:16.467068 10416 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1210 12:09:22.227046 10416 solver.cpp:218] Iteration 300 (17.3646 iter/s, 5.75885s/100 iters), loss = 4.15785
I1210 12:09:22.227046 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I1210 12:09:22.227046 10416 solver.cpp:237]     Train net output #1: loss = 4.15785 (* 1 = 4.15785 loss)
I1210 12:09:22.227046 10416 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1210 12:09:27.970759 10416 solver.cpp:218] Iteration 400 (17.4098 iter/s, 5.7439s/100 iters), loss = 4.22744
I1210 12:09:27.970759 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.05
I1210 12:09:27.970759 10416 solver.cpp:237]     Train net output #1: loss = 4.22744 (* 1 = 4.22744 loss)
I1210 12:09:27.970759 10416 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1210 12:09:33.336119  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:09:33.557626 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_500.caffemodel
I1210 12:09:33.582130 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_500.solverstate
I1210 12:09:33.588130 10416 solver.cpp:330] Iteration 500, Testing net (#0)
I1210 12:09:33.588130 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:09:34.961231  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:09:35.014235 10416 solver.cpp:397]     Test net output #0: accuracy = 0.0417
I1210 12:09:35.015236 10416 solver.cpp:397]     Test net output #1: loss = 4.33164 (* 1 = 4.33164 loss)
I1210 12:09:35.068240 10416 solver.cpp:218] Iteration 500 (14.0906 iter/s, 7.09691s/100 iters), loss = 3.961
I1210 12:09:35.068240 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.09
I1210 12:09:35.068240 10416 solver.cpp:237]     Train net output #1: loss = 3.961 (* 1 = 3.961 loss)
I1210 12:09:35.068240 10416 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1210 12:09:40.710628 10416 solver.cpp:218] Iteration 600 (17.7243 iter/s, 5.64197s/100 iters), loss = 3.82197
I1210 12:09:40.710628 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.07
I1210 12:09:40.710628 10416 solver.cpp:237]     Train net output #1: loss = 3.82197 (* 1 = 3.82197 loss)
I1210 12:09:40.710628 10416 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1210 12:09:46.368026 10416 solver.cpp:218] Iteration 700 (17.6791 iter/s, 5.65639s/100 iters), loss = 3.70958
I1210 12:09:46.368026 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.1
I1210 12:09:46.368026 10416 solver.cpp:237]     Train net output #1: loss = 3.70958 (* 1 = 3.70958 loss)
I1210 12:09:46.368026 10416 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1210 12:09:52.024473 10416 solver.cpp:218] Iteration 800 (17.6812 iter/s, 5.65571s/100 iters), loss = 3.74216
I1210 12:09:52.024473 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.13
I1210 12:09:52.024473 10416 solver.cpp:237]     Train net output #1: loss = 3.74216 (* 1 = 3.74216 loss)
I1210 12:09:52.024473 10416 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1210 12:09:57.685910 10416 solver.cpp:218] Iteration 900 (17.6651 iter/s, 5.66087s/100 iters), loss = 3.84314
I1210 12:09:57.685910 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.1
I1210 12:09:57.685910 10416 solver.cpp:237]     Train net output #1: loss = 3.84314 (* 1 = 3.84314 loss)
I1210 12:09:57.685910 10416 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1210 12:10:03.104228  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:10:03.327745 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_1000.caffemodel
I1210 12:10:03.346253 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_1000.solverstate
I1210 12:10:03.351254 10416 solver.cpp:330] Iteration 1000, Testing net (#0)
I1210 12:10:03.351254 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:10:04.727839  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:10:04.781342 10416 solver.cpp:397]     Test net output #0: accuracy = 0.0982
I1210 12:10:04.781342 10416 solver.cpp:397]     Test net output #1: loss = 4.01385 (* 1 = 4.01385 loss)
I1210 12:10:04.837347 10416 solver.cpp:218] Iteration 1000 (13.9828 iter/s, 7.15165s/100 iters), loss = 3.53887
I1210 12:10:04.837347 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.21
I1210 12:10:04.837347 10416 solver.cpp:237]     Train net output #1: loss = 3.53887 (* 1 = 3.53887 loss)
I1210 12:10:04.837347 10416 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1210 12:10:10.491744 10416 solver.cpp:218] Iteration 1100 (17.6891 iter/s, 5.65318s/100 iters), loss = 3.50863
I1210 12:10:10.491744 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.12
I1210 12:10:10.491744 10416 solver.cpp:237]     Train net output #1: loss = 3.50863 (* 1 = 3.50863 loss)
I1210 12:10:10.491744 10416 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1210 12:10:16.140223 10416 solver.cpp:218] Iteration 1200 (17.704 iter/s, 5.64843s/100 iters), loss = 3.31741
I1210 12:10:16.140223 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.25
I1210 12:10:16.140223 10416 solver.cpp:237]     Train net output #1: loss = 3.31741 (* 1 = 3.31741 loss)
I1210 12:10:16.140223 10416 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1210 12:10:21.792618 10416 solver.cpp:218] Iteration 1300 (17.6934 iter/s, 5.65181s/100 iters), loss = 3.36482
I1210 12:10:21.792618 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.15
I1210 12:10:21.792618 10416 solver.cpp:237]     Train net output #1: loss = 3.36482 (* 1 = 3.36482 loss)
I1210 12:10:21.792618 10416 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1210 12:10:27.438045 10416 solver.cpp:218] Iteration 1400 (17.7154 iter/s, 5.64481s/100 iters), loss = 3.67353
I1210 12:10:27.438045 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.14
I1210 12:10:27.438045 10416 solver.cpp:237]     Train net output #1: loss = 3.67353 (* 1 = 3.67353 loss)
I1210 12:10:27.438045 10416 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1210 12:10:32.821938  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:10:33.044461 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_1500.caffemodel
I1210 12:10:33.059460 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_1500.solverstate
I1210 12:10:33.063460 10416 solver.cpp:330] Iteration 1500, Testing net (#0)
I1210 12:10:33.063460 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:10:34.438593  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:10:34.492594 10416 solver.cpp:397]     Test net output #0: accuracy = 0.1376
I1210 12:10:34.492594 10416 solver.cpp:397]     Test net output #1: loss = 3.7501 (* 1 = 3.7501 loss)
I1210 12:10:34.547598 10416 solver.cpp:218] Iteration 1500 (14.0654 iter/s, 7.10962s/100 iters), loss = 3.26635
I1210 12:10:34.547598 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.22
I1210 12:10:34.547598 10416 solver.cpp:237]     Train net output #1: loss = 3.26635 (* 1 = 3.26635 loss)
I1210 12:10:34.547598 10416 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1210 12:10:40.205027 10416 solver.cpp:218] Iteration 1600 (17.6775 iter/s, 5.6569s/100 iters), loss = 3.20761
I1210 12:10:40.205027 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.17
I1210 12:10:40.205027 10416 solver.cpp:237]     Train net output #1: loss = 3.20761 (* 1 = 3.20761 loss)
I1210 12:10:40.205027 10416 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1210 12:10:45.872406 10416 solver.cpp:218] Iteration 1700 (17.6477 iter/s, 5.66647s/100 iters), loss = 3.02272
I1210 12:10:45.872406 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.24
I1210 12:10:45.872406 10416 solver.cpp:237]     Train net output #1: loss = 3.02272 (* 1 = 3.02272 loss)
I1210 12:10:45.872406 10416 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1210 12:10:51.530743 10416 solver.cpp:218] Iteration 1800 (17.6729 iter/s, 5.65838s/100 iters), loss = 3.16175
I1210 12:10:51.530743 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.19
I1210 12:10:51.530743 10416 solver.cpp:237]     Train net output #1: loss = 3.16175 (* 1 = 3.16175 loss)
I1210 12:10:51.530743 10416 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1210 12:10:57.192087 10416 solver.cpp:218] Iteration 1900 (17.6669 iter/s, 5.66029s/100 iters), loss = 3.28591
I1210 12:10:57.192087 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.18
I1210 12:10:57.192087 10416 solver.cpp:237]     Train net output #1: loss = 3.28591 (* 1 = 3.28591 loss)
I1210 12:10:57.192087 10416 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1210 12:11:02.582471  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:11:02.804491 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_2000.caffemodel
I1210 12:11:02.824494 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_2000.solverstate
I1210 12:11:02.829494 10416 solver.cpp:330] Iteration 2000, Testing net (#0)
I1210 12:11:02.829494 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:11:04.209082  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:11:04.262585 10416 solver.cpp:397]     Test net output #0: accuracy = 0.1344
I1210 12:11:04.262585 10416 solver.cpp:397]     Test net output #1: loss = 3.81197 (* 1 = 3.81197 loss)
I1210 12:11:04.316592 10416 solver.cpp:218] Iteration 2000 (14.036 iter/s, 7.12452s/100 iters), loss = 2.99517
I1210 12:11:04.316592 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1210 12:11:04.316592 10416 solver.cpp:237]     Train net output #1: loss = 2.99517 (* 1 = 2.99517 loss)
I1210 12:11:04.316592 10416 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1210 12:11:09.979038 10416 solver.cpp:218] Iteration 2100 (17.662 iter/s, 5.66188s/100 iters), loss = 2.93009
I1210 12:11:09.979038 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.24
I1210 12:11:09.979038 10416 solver.cpp:237]     Train net output #1: loss = 2.93009 (* 1 = 2.93009 loss)
I1210 12:11:09.979038 10416 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1210 12:11:15.639446 10416 solver.cpp:218] Iteration 2200 (17.6691 iter/s, 5.6596s/100 iters), loss = 2.73401
I1210 12:11:15.639446 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1210 12:11:15.639446 10416 solver.cpp:237]     Train net output #1: loss = 2.73401 (* 1 = 2.73401 loss)
I1210 12:11:15.639446 10416 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1210 12:11:21.300348 10416 solver.cpp:218] Iteration 2300 (17.6653 iter/s, 5.66081s/100 iters), loss = 2.88126
I1210 12:11:21.300348 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1210 12:11:21.300348 10416 solver.cpp:237]     Train net output #1: loss = 2.88126 (* 1 = 2.88126 loss)
I1210 12:11:21.300348 10416 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1210 12:11:26.959228 10416 solver.cpp:218] Iteration 2400 (17.6714 iter/s, 5.65887s/100 iters), loss = 2.98172
I1210 12:11:26.959228 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.24
I1210 12:11:26.959228 10416 solver.cpp:237]     Train net output #1: loss = 2.98172 (* 1 = 2.98172 loss)
I1210 12:11:26.959228 10416 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1210 12:11:32.345592  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:11:32.565605 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_2500.caffemodel
I1210 12:11:32.584604 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_2500.solverstate
I1210 12:11:32.589607 10416 solver.cpp:330] Iteration 2500, Testing net (#0)
I1210 12:11:32.589607 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:11:33.965698  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:11:34.019706 10416 solver.cpp:397]     Test net output #0: accuracy = 0.1571
I1210 12:11:34.019706 10416 solver.cpp:397]     Test net output #1: loss = 3.6299 (* 1 = 3.6299 loss)
I1210 12:11:34.073701 10416 solver.cpp:218] Iteration 2500 (14.0574 iter/s, 7.11367s/100 iters), loss = 2.74766
I1210 12:11:34.073701 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1210 12:11:34.073701 10416 solver.cpp:237]     Train net output #1: loss = 2.74766 (* 1 = 2.74766 loss)
I1210 12:11:34.073701 10416 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1210 12:11:39.739042 10416 solver.cpp:218] Iteration 2600 (17.6521 iter/s, 5.66505s/100 iters), loss = 2.70745
I1210 12:11:39.739042 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1210 12:11:39.739042 10416 solver.cpp:237]     Train net output #1: loss = 2.70745 (* 1 = 2.70745 loss)
I1210 12:11:39.739042 10416 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1210 12:11:45.392431 10416 solver.cpp:218] Iteration 2700 (17.6904 iter/s, 5.65278s/100 iters), loss = 2.45211
I1210 12:11:45.392431 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1210 12:11:45.392431 10416 solver.cpp:237]     Train net output #1: loss = 2.45211 (* 1 = 2.45211 loss)
I1210 12:11:45.392431 10416 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1210 12:11:51.049988 10416 solver.cpp:218] Iteration 2800 (17.6781 iter/s, 5.6567s/100 iters), loss = 2.6674
I1210 12:11:51.049988 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1210 12:11:51.049988 10416 solver.cpp:237]     Train net output #1: loss = 2.6674 (* 1 = 2.6674 loss)
I1210 12:11:51.049988 10416 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1210 12:11:56.695394 10416 solver.cpp:218] Iteration 2900 (17.7125 iter/s, 5.64571s/100 iters), loss = 2.7912
I1210 12:11:56.695394 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.22
I1210 12:11:56.695394 10416 solver.cpp:237]     Train net output #1: loss = 2.7912 (* 1 = 2.7912 loss)
I1210 12:11:56.695394 10416 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1210 12:12:02.082736  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:12:02.305251 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_3000.caffemodel
I1210 12:12:02.323757 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_3000.solverstate
I1210 12:12:02.328759 10416 solver.cpp:330] Iteration 3000, Testing net (#0)
I1210 12:12:02.328759 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:12:03.702841  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:12:03.756844 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2276
I1210 12:12:03.756844 10416 solver.cpp:397]     Test net output #1: loss = 3.1884 (* 1 = 3.1884 loss)
I1210 12:12:03.810345 10416 solver.cpp:218] Iteration 3000 (14.057 iter/s, 7.11388s/100 iters), loss = 2.48167
I1210 12:12:03.810345 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1210 12:12:03.810345 10416 solver.cpp:237]     Train net output #1: loss = 2.48167 (* 1 = 2.48167 loss)
I1210 12:12:03.810345 10416 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1210 12:12:09.468227 10416 solver.cpp:218] Iteration 3100 (17.6746 iter/s, 5.65783s/100 iters), loss = 2.51479
I1210 12:12:09.468227 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1210 12:12:09.468227 10416 solver.cpp:237]     Train net output #1: loss = 2.51479 (* 1 = 2.51479 loss)
I1210 12:12:09.468227 10416 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1210 12:12:15.130650 10416 solver.cpp:218] Iteration 3200 (17.6625 iter/s, 5.66171s/100 iters), loss = 2.38467
I1210 12:12:15.130650 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1210 12:12:15.130650 10416 solver.cpp:237]     Train net output #1: loss = 2.38467 (* 1 = 2.38467 loss)
I1210 12:12:15.130650 10416 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1210 12:12:20.785998 10416 solver.cpp:218] Iteration 3300 (17.6849 iter/s, 5.65455s/100 iters), loss = 2.53607
I1210 12:12:20.785998 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.32
I1210 12:12:20.785998 10416 solver.cpp:237]     Train net output #1: loss = 2.53607 (* 1 = 2.53607 loss)
I1210 12:12:20.785998 10416 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1210 12:12:26.443426 10416 solver.cpp:218] Iteration 3400 (17.6774 iter/s, 5.65696s/100 iters), loss = 2.71114
I1210 12:12:26.443426 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.26
I1210 12:12:26.443426 10416 solver.cpp:237]     Train net output #1: loss = 2.71114 (* 1 = 2.71114 loss)
I1210 12:12:26.443426 10416 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1210 12:12:31.833750  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:12:32.057760 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_3500.caffemodel
I1210 12:12:32.073760 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_3500.solverstate
I1210 12:12:32.077762 10416 solver.cpp:330] Iteration 3500, Testing net (#0)
I1210 12:12:32.077762 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:12:33.453852  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:12:33.510354 10416 solver.cpp:397]     Test net output #0: accuracy = 0.1914
I1210 12:12:33.510354 10416 solver.cpp:397]     Test net output #1: loss = 3.5207 (* 1 = 3.5207 loss)
I1210 12:12:33.563855 10416 solver.cpp:218] Iteration 3500 (14.0447 iter/s, 7.12012s/100 iters), loss = 2.42751
I1210 12:12:33.563855 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1210 12:12:33.563855 10416 solver.cpp:237]     Train net output #1: loss = 2.42751 (* 1 = 2.42751 loss)
I1210 12:12:33.563855 10416 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1210 12:12:39.210747 10416 solver.cpp:218] Iteration 3600 (17.7106 iter/s, 5.64634s/100 iters), loss = 2.31712
I1210 12:12:39.210747 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1210 12:12:39.210747 10416 solver.cpp:237]     Train net output #1: loss = 2.31712 (* 1 = 2.31712 loss)
I1210 12:12:39.210747 10416 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1210 12:12:44.857655 10416 solver.cpp:218] Iteration 3700 (17.7093 iter/s, 5.64677s/100 iters), loss = 2.24322
I1210 12:12:44.857655 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:12:44.857655 10416 solver.cpp:237]     Train net output #1: loss = 2.24322 (* 1 = 2.24322 loss)
I1210 12:12:44.857655 10416 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1210 12:12:50.507055 10416 solver.cpp:218] Iteration 3800 (17.7033 iter/s, 5.64868s/100 iters), loss = 2.41673
I1210 12:12:50.507055 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1210 12:12:50.507055 10416 solver.cpp:237]     Train net output #1: loss = 2.41673 (* 1 = 2.41673 loss)
I1210 12:12:50.507055 10416 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1210 12:12:56.157482 10416 solver.cpp:218] Iteration 3900 (17.698 iter/s, 5.65036s/100 iters), loss = 2.56225
I1210 12:12:56.157482 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1210 12:12:56.157482 10416 solver.cpp:237]     Train net output #1: loss = 2.56225 (* 1 = 2.56225 loss)
I1210 12:12:56.157482 10416 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1210 12:13:01.537850  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:13:01.761859 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_4000.caffemodel
I1210 12:13:01.780859 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_4000.solverstate
I1210 12:13:01.785859 10416 solver.cpp:330] Iteration 4000, Testing net (#0)
I1210 12:13:01.785859 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:13:03.163986  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:13:03.217989 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2795
I1210 12:13:03.217989 10416 solver.cpp:397]     Test net output #1: loss = 2.86146 (* 1 = 2.86146 loss)
I1210 12:13:03.271992 10416 solver.cpp:218] Iteration 4000 (14.0564 iter/s, 7.11417s/100 iters), loss = 2.37682
I1210 12:13:03.271992 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1210 12:13:03.271992 10416 solver.cpp:237]     Train net output #1: loss = 2.37682 (* 1 = 2.37682 loss)
I1210 12:13:03.271992 10416 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1210 12:13:08.912413 10416 solver.cpp:218] Iteration 4100 (17.7324 iter/s, 5.6394s/100 iters), loss = 2.19329
I1210 12:13:08.912413 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1210 12:13:08.912413 10416 solver.cpp:237]     Train net output #1: loss = 2.19329 (* 1 = 2.19329 loss)
I1210 12:13:08.912413 10416 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1210 12:13:14.555836 10416 solver.cpp:218] Iteration 4200 (17.7204 iter/s, 5.64321s/100 iters), loss = 2.04179
I1210 12:13:14.555836 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:13:14.555836 10416 solver.cpp:237]     Train net output #1: loss = 2.04179 (* 1 = 2.04179 loss)
I1210 12:13:14.555836 10416 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1210 12:13:20.206267 10416 solver.cpp:218] Iteration 4300 (17.6999 iter/s, 5.64974s/100 iters), loss = 2.24036
I1210 12:13:20.206267 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:13:20.206267 10416 solver.cpp:237]     Train net output #1: loss = 2.24036 (* 1 = 2.24036 loss)
I1210 12:13:20.206267 10416 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1210 12:13:25.853724 10416 solver.cpp:218] Iteration 4400 (17.7083 iter/s, 5.64707s/100 iters), loss = 2.64373
I1210 12:13:25.853724 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1210 12:13:25.853724 10416 solver.cpp:237]     Train net output #1: loss = 2.64373 (* 1 = 2.64373 loss)
I1210 12:13:25.853724 10416 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1210 12:13:31.223120  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:13:31.447134 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_4500.caffemodel
I1210 12:13:31.466135 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_4500.solverstate
I1210 12:13:31.471134 10416 solver.cpp:330] Iteration 4500, Testing net (#0)
I1210 12:13:31.471134 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:13:32.846240  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:13:32.900246 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2272
I1210 12:13:32.900246 10416 solver.cpp:397]     Test net output #1: loss = 3.59272 (* 1 = 3.59272 loss)
I1210 12:13:32.953249 10416 solver.cpp:218] Iteration 4500 (14.0849 iter/s, 7.09981s/100 iters), loss = 2.30542
I1210 12:13:32.953249 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 12:13:32.953249 10416 solver.cpp:237]     Train net output #1: loss = 2.30542 (* 1 = 2.30542 loss)
I1210 12:13:32.954249 10416 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1210 12:13:38.611140 10416 solver.cpp:218] Iteration 4600 (17.6783 iter/s, 5.65666s/100 iters), loss = 2.2923
I1210 12:13:38.611140 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1210 12:13:38.611140 10416 solver.cpp:237]     Train net output #1: loss = 2.2923 (* 1 = 2.2923 loss)
I1210 12:13:38.611140 10416 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1210 12:13:44.278960 10416 solver.cpp:218] Iteration 4700 (17.6451 iter/s, 5.6673s/100 iters), loss = 2.02071
I1210 12:13:44.278960 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:13:44.278960 10416 solver.cpp:237]     Train net output #1: loss = 2.02071 (* 1 = 2.02071 loss)
I1210 12:13:44.278960 10416 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1210 12:13:49.934404 10416 solver.cpp:218] Iteration 4800 (17.6825 iter/s, 5.65531s/100 iters), loss = 2.19827
I1210 12:13:49.934404 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1210 12:13:49.934404 10416 solver.cpp:237]     Train net output #1: loss = 2.19827 (* 1 = 2.19827 loss)
I1210 12:13:49.934404 10416 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1210 12:13:55.588796 10416 solver.cpp:218] Iteration 4900 (17.6857 iter/s, 5.65427s/100 iters), loss = 2.59275
I1210 12:13:55.588796 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1210 12:13:55.588796 10416 solver.cpp:237]     Train net output #1: loss = 2.59275 (* 1 = 2.59275 loss)
I1210 12:13:55.588796 10416 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1210 12:14:01.003175  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:14:01.229203 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_5000.caffemodel
I1210 12:14:01.256209 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_5000.solverstate
I1210 12:14:01.266209 10416 solver.cpp:330] Iteration 5000, Testing net (#0)
I1210 12:14:01.266209 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:14:02.682778  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:14:02.736778 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2744
I1210 12:14:02.736778 10416 solver.cpp:397]     Test net output #1: loss = 2.94629 (* 1 = 2.94629 loss)
I1210 12:14:02.792778 10416 solver.cpp:218] Iteration 5000 (13.8832 iter/s, 7.20296s/100 iters), loss = 2.24303
I1210 12:14:02.792778 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 12:14:02.792778 10416 solver.cpp:237]     Train net output #1: loss = 2.24303 (* 1 = 2.24303 loss)
I1210 12:14:02.792778 10416 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1210 12:14:08.562304 10416 solver.cpp:218] Iteration 5100 (17.3336 iter/s, 5.76915s/100 iters), loss = 2.20261
I1210 12:14:08.562803 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1210 12:14:08.562803 10416 solver.cpp:237]     Train net output #1: loss = 2.20261 (* 1 = 2.20261 loss)
I1210 12:14:08.562803 10416 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1210 12:14:14.347441 10416 solver.cpp:218] Iteration 5200 (17.288 iter/s, 5.78438s/100 iters), loss = 1.88256
I1210 12:14:14.347441 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:14:14.347441 10416 solver.cpp:237]     Train net output #1: loss = 1.88256 (* 1 = 1.88256 loss)
I1210 12:14:14.347441 10416 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1210 12:14:20.094419 10416 solver.cpp:218] Iteration 5300 (17.4007 iter/s, 5.74689s/100 iters), loss = 2.2216
I1210 12:14:20.094419 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:14:20.094419 10416 solver.cpp:237]     Train net output #1: loss = 2.2216 (* 1 = 2.2216 loss)
I1210 12:14:20.094419 10416 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1210 12:14:25.776064 10416 solver.cpp:218] Iteration 5400 (17.6041 iter/s, 5.6805s/100 iters), loss = 2.30307
I1210 12:14:25.776064 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1210 12:14:25.776064 10416 solver.cpp:237]     Train net output #1: loss = 2.30307 (* 1 = 2.30307 loss)
I1210 12:14:25.776064 10416 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1210 12:14:31.167590  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:14:31.390590 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_5500.caffemodel
I1210 12:14:31.412091 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_5500.solverstate
I1210 12:14:31.417091 10416 solver.cpp:330] Iteration 5500, Testing net (#0)
I1210 12:14:31.417590 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:14:32.795090  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:14:32.850091 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2821
I1210 12:14:32.850091 10416 solver.cpp:397]     Test net output #1: loss = 2.84912 (* 1 = 2.84912 loss)
I1210 12:14:32.903595 10416 solver.cpp:218] Iteration 5500 (14.0314 iter/s, 7.12688s/100 iters), loss = 2.31444
I1210 12:14:32.903595 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 12:14:32.903595 10416 solver.cpp:237]     Train net output #1: loss = 2.31444 (* 1 = 2.31444 loss)
I1210 12:14:32.903595 10416 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1210 12:14:38.583559 10416 solver.cpp:218] Iteration 5600 (17.6073 iter/s, 5.67947s/100 iters), loss = 2.03548
I1210 12:14:38.583559 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1210 12:14:38.583559 10416 solver.cpp:237]     Train net output #1: loss = 2.03548 (* 1 = 2.03548 loss)
I1210 12:14:38.583559 10416 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1210 12:14:44.282009 10416 solver.cpp:218] Iteration 5700 (17.55 iter/s, 5.69801s/100 iters), loss = 1.87271
I1210 12:14:44.282009 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:14:44.282009 10416 solver.cpp:237]     Train net output #1: loss = 1.87271 (* 1 = 1.87271 loss)
I1210 12:14:44.282009 10416 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1210 12:14:49.962383 10416 solver.cpp:218] Iteration 5800 (17.6059 iter/s, 5.67991s/100 iters), loss = 2.0429
I1210 12:14:49.962383 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:14:49.962883 10416 solver.cpp:237]     Train net output #1: loss = 2.0429 (* 1 = 2.0429 loss)
I1210 12:14:49.962883 10416 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1210 12:14:55.677382 10416 solver.cpp:218] Iteration 5900 (17.4996 iter/s, 5.71441s/100 iters), loss = 2.41633
I1210 12:14:55.677382 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1210 12:14:55.677382 10416 solver.cpp:237]     Train net output #1: loss = 2.41633 (* 1 = 2.41633 loss)
I1210 12:14:55.677382 10416 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1210 12:15:01.103884  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:15:01.327883 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_6000.caffemodel
I1210 12:15:01.348883 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_6000.solverstate
I1210 12:15:01.353883 10416 solver.cpp:330] Iteration 6000, Testing net (#0)
I1210 12:15:01.353883 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:15:02.732897  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:15:02.785892 10416 solver.cpp:397]     Test net output #0: accuracy = 0.303
I1210 12:15:02.785892 10416 solver.cpp:397]     Test net output #1: loss = 2.79382 (* 1 = 2.79382 loss)
I1210 12:15:02.839893 10416 solver.cpp:218] Iteration 6000 (13.9627 iter/s, 7.16196s/100 iters), loss = 2.18363
I1210 12:15:02.839893 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 12:15:02.839893 10416 solver.cpp:237]     Train net output #1: loss = 2.18363 (* 1 = 2.18363 loss)
I1210 12:15:02.839893 10416 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1210 12:15:08.524973 10416 solver.cpp:218] Iteration 6100 (17.5921 iter/s, 5.68438s/100 iters), loss = 2.04092
I1210 12:15:08.524973 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1210 12:15:08.524973 10416 solver.cpp:237]     Train net output #1: loss = 2.04092 (* 1 = 2.04092 loss)
I1210 12:15:08.524973 10416 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1210 12:15:14.208067 10416 solver.cpp:218] Iteration 6200 (17.5974 iter/s, 5.68267s/100 iters), loss = 1.63858
I1210 12:15:14.208067 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:15:14.208067 10416 solver.cpp:237]     Train net output #1: loss = 1.63858 (* 1 = 1.63858 loss)
I1210 12:15:14.208067 10416 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1210 12:15:19.873311 10416 solver.cpp:218] Iteration 6300 (17.6535 iter/s, 5.6646s/100 iters), loss = 2.31276
I1210 12:15:19.873311 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1210 12:15:19.873311 10416 solver.cpp:237]     Train net output #1: loss = 2.31276 (* 1 = 2.31276 loss)
I1210 12:15:19.873311 10416 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1210 12:15:25.544986 10416 solver.cpp:218] Iteration 6400 (17.6322 iter/s, 5.67144s/100 iters), loss = 2.27174
I1210 12:15:25.544986 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 12:15:25.544986 10416 solver.cpp:237]     Train net output #1: loss = 2.27174 (* 1 = 2.27174 loss)
I1210 12:15:25.544986 10416 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1210 12:15:30.943718  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:15:31.165724 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_6500.caffemodel
I1210 12:15:31.187224 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_6500.solverstate
I1210 12:15:31.192734 10416 solver.cpp:330] Iteration 6500, Testing net (#0)
I1210 12:15:31.192734 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:15:32.569727  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:15:32.623224 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3308
I1210 12:15:32.623224 10416 solver.cpp:397]     Test net output #1: loss = 2.69563 (* 1 = 2.69563 loss)
I1210 12:15:32.676723 10416 solver.cpp:218] Iteration 6500 (14.0227 iter/s, 7.13129s/100 iters), loss = 2.05685
I1210 12:15:32.676723 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:15:32.676723 10416 solver.cpp:237]     Train net output #1: loss = 2.05685 (* 1 = 2.05685 loss)
I1210 12:15:32.676723 10416 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1210 12:15:38.362299 10416 solver.cpp:218] Iteration 6600 (17.5893 iter/s, 5.68528s/100 iters), loss = 1.91269
I1210 12:15:38.362299 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:15:38.362299 10416 solver.cpp:237]     Train net output #1: loss = 1.91269 (* 1 = 1.91269 loss)
I1210 12:15:38.362299 10416 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1210 12:15:44.037904 10416 solver.cpp:218] Iteration 6700 (17.6206 iter/s, 5.67518s/100 iters), loss = 1.69792
I1210 12:15:44.038403 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:15:44.038403 10416 solver.cpp:237]     Train net output #1: loss = 1.69792 (* 1 = 1.69792 loss)
I1210 12:15:44.038403 10416 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1210 12:15:49.715965 10416 solver.cpp:218] Iteration 6800 (17.6142 iter/s, 5.67723s/100 iters), loss = 2.16603
I1210 12:15:49.715965 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 12:15:49.715965 10416 solver.cpp:237]     Train net output #1: loss = 2.16603 (* 1 = 2.16603 loss)
I1210 12:15:49.715965 10416 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1210 12:15:55.393604 10416 solver.cpp:218] Iteration 6900 (17.6138 iter/s, 5.67736s/100 iters), loss = 2.10094
I1210 12:15:55.393604 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:15:55.394105 10416 solver.cpp:237]     Train net output #1: loss = 2.10094 (* 1 = 2.10094 loss)
I1210 12:15:55.394105 10416 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1210 12:16:00.803643  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:16:01.025643 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_7000.caffemodel
I1210 12:16:01.040643 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_7000.solverstate
I1210 12:16:01.045145 10416 solver.cpp:330] Iteration 7000, Testing net (#0)
I1210 12:16:01.045145 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:16:02.425179  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:16:02.478678 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3225
I1210 12:16:02.478678 10416 solver.cpp:397]     Test net output #1: loss = 2.82651 (* 1 = 2.82651 loss)
I1210 12:16:02.532177 10416 solver.cpp:218] Iteration 7000 (14.0098 iter/s, 7.13784s/100 iters), loss = 2.15507
I1210 12:16:02.532177 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:16:02.532177 10416 solver.cpp:237]     Train net output #1: loss = 2.15507 (* 1 = 2.15507 loss)
I1210 12:16:02.532177 10416 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1210 12:16:08.215457 10416 solver.cpp:218] Iteration 7100 (17.5973 iter/s, 5.68269s/100 iters), loss = 2.08894
I1210 12:16:08.215457 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I1210 12:16:08.215457 10416 solver.cpp:237]     Train net output #1: loss = 2.08894 (* 1 = 2.08894 loss)
I1210 12:16:08.215457 10416 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1210 12:16:13.901721 10416 solver.cpp:218] Iteration 7200 (17.5882 iter/s, 5.68565s/100 iters), loss = 1.72785
I1210 12:16:13.901721 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:16:13.901721 10416 solver.cpp:237]     Train net output #1: loss = 1.72785 (* 1 = 1.72785 loss)
I1210 12:16:13.901721 10416 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1210 12:16:19.581897 10416 solver.cpp:218] Iteration 7300 (17.6054 iter/s, 5.68009s/100 iters), loss = 1.91887
I1210 12:16:19.581897 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:16:19.581897 10416 solver.cpp:237]     Train net output #1: loss = 1.91887 (* 1 = 1.91887 loss)
I1210 12:16:19.581897 10416 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1210 12:16:25.245440 10416 solver.cpp:218] Iteration 7400 (17.6587 iter/s, 5.66293s/100 iters), loss = 2.25403
I1210 12:16:25.245440 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 12:16:25.245440 10416 solver.cpp:237]     Train net output #1: loss = 2.25403 (* 1 = 2.25403 loss)
I1210 12:16:25.245440 10416 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1210 12:16:30.653466  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:16:30.878466 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_7500.caffemodel
I1210 12:16:30.897965 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_7500.solverstate
I1210 12:16:30.903966 10416 solver.cpp:330] Iteration 7500, Testing net (#0)
I1210 12:16:30.903966 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:16:32.280467  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:16:32.335973 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2931
I1210 12:16:32.336972 10416 solver.cpp:397]     Test net output #1: loss = 3.06223 (* 1 = 3.06223 loss)
I1210 12:16:32.390971 10416 solver.cpp:218] Iteration 7500 (13.9952 iter/s, 7.14531s/100 iters), loss = 2.15317
I1210 12:16:32.390971 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:16:32.390971 10416 solver.cpp:237]     Train net output #1: loss = 2.15317 (* 1 = 2.15317 loss)
I1210 12:16:32.390971 10416 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1210 12:16:38.071691 10416 solver.cpp:218] Iteration 7600 (17.606 iter/s, 5.67987s/100 iters), loss = 1.90071
I1210 12:16:38.071691 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1210 12:16:38.071691 10416 solver.cpp:237]     Train net output #1: loss = 1.90071 (* 1 = 1.90071 loss)
I1210 12:16:38.071691 10416 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1210 12:16:43.756402 10416 solver.cpp:218] Iteration 7700 (17.5924 iter/s, 5.68429s/100 iters), loss = 1.71088
I1210 12:16:43.756402 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:16:43.756402 10416 solver.cpp:237]     Train net output #1: loss = 1.71088 (* 1 = 1.71088 loss)
I1210 12:16:43.756402 10416 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1210 12:16:49.439985 10416 solver.cpp:218] Iteration 7800 (17.5959 iter/s, 5.68315s/100 iters), loss = 1.90059
I1210 12:16:49.439985 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:16:49.439985 10416 solver.cpp:237]     Train net output #1: loss = 1.90059 (* 1 = 1.90059 loss)
I1210 12:16:49.439985 10416 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1210 12:16:55.127741 10416 solver.cpp:218] Iteration 7900 (17.5835 iter/s, 5.68715s/100 iters), loss = 2.13003
I1210 12:16:55.127741 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:16:55.127741 10416 solver.cpp:237]     Train net output #1: loss = 2.13003 (* 1 = 2.13003 loss)
I1210 12:16:55.127741 10416 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1210 12:17:00.545768  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:17:00.769269 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_8000.caffemodel
I1210 12:17:00.783768 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_8000.solverstate
I1210 12:17:00.788269 10416 solver.cpp:330] Iteration 8000, Testing net (#0)
I1210 12:17:00.788269 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:17:02.167927  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:17:02.221928 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3632
I1210 12:17:02.221928 10416 solver.cpp:397]     Test net output #1: loss = 2.51551 (* 1 = 2.51551 loss)
I1210 12:17:02.276427 10416 solver.cpp:218] Iteration 8000 (13.9888 iter/s, 7.14855s/100 iters), loss = 1.94477
I1210 12:17:02.276926 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:17:02.276926 10416 solver.cpp:237]     Train net output #1: loss = 1.94477 (* 1 = 1.94477 loss)
I1210 12:17:02.276926 10416 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1210 12:17:07.949378 10416 solver.cpp:218] Iteration 8100 (17.6301 iter/s, 5.67212s/100 iters), loss = 1.8742
I1210 12:17:07.949378 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1210 12:17:07.949378 10416 solver.cpp:237]     Train net output #1: loss = 1.8742 (* 1 = 1.8742 loss)
I1210 12:17:07.949378 10416 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1210 12:17:13.628672 10416 solver.cpp:218] Iteration 8200 (17.6089 iter/s, 5.67895s/100 iters), loss = 1.75108
I1210 12:17:13.628672 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:17:13.628672 10416 solver.cpp:237]     Train net output #1: loss = 1.75108 (* 1 = 1.75108 loss)
I1210 12:17:13.628672 10416 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1210 12:17:19.315748 10416 solver.cpp:218] Iteration 8300 (17.5852 iter/s, 5.6866s/100 iters), loss = 1.98746
I1210 12:17:19.315748 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 12:17:19.315748 10416 solver.cpp:237]     Train net output #1: loss = 1.98746 (* 1 = 1.98746 loss)
I1210 12:17:19.315748 10416 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1210 12:17:24.991837 10416 solver.cpp:218] Iteration 8400 (17.6187 iter/s, 5.67578s/100 iters), loss = 2.25199
I1210 12:17:24.991837 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1210 12:17:24.991837 10416 solver.cpp:237]     Train net output #1: loss = 2.25199 (* 1 = 2.25199 loss)
I1210 12:17:24.991837 10416 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1210 12:17:30.383605  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:17:30.603606 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_8500.caffemodel
I1210 12:17:30.620604 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_8500.solverstate
I1210 12:17:30.625104 10416 solver.cpp:330] Iteration 8500, Testing net (#0)
I1210 12:17:30.625607 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:17:32.003103  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:17:32.056603 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3587
I1210 12:17:32.056603 10416 solver.cpp:397]     Test net output #1: loss = 2.51381 (* 1 = 2.51381 loss)
I1210 12:17:32.109607 10416 solver.cpp:218] Iteration 8500 (14.0504 iter/s, 7.11726s/100 iters), loss = 2.04917
I1210 12:17:32.109607 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:17:32.109607 10416 solver.cpp:237]     Train net output #1: loss = 2.04917 (* 1 = 2.04917 loss)
I1210 12:17:32.109607 10416 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1210 12:17:37.759018 10416 solver.cpp:218] Iteration 8600 (17.7021 iter/s, 5.64905s/100 iters), loss = 1.8238
I1210 12:17:37.759018 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:17:37.759018 10416 solver.cpp:237]     Train net output #1: loss = 1.8238 (* 1 = 1.8238 loss)
I1210 12:17:37.759018 10416 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1210 12:17:43.425545 10416 solver.cpp:218] Iteration 8700 (17.6499 iter/s, 5.66574s/100 iters), loss = 1.61909
I1210 12:17:43.425545 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:17:43.425545 10416 solver.cpp:237]     Train net output #1: loss = 1.61909 (* 1 = 1.61909 loss)
I1210 12:17:43.425545 10416 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1210 12:17:49.088156 10416 solver.cpp:218] Iteration 8800 (17.6603 iter/s, 5.66241s/100 iters), loss = 1.94227
I1210 12:17:49.088156 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:17:49.088156 10416 solver.cpp:237]     Train net output #1: loss = 1.94227 (* 1 = 1.94227 loss)
I1210 12:17:49.088156 10416 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1210 12:17:54.736160 10416 solver.cpp:218] Iteration 8900 (17.7065 iter/s, 5.64764s/100 iters), loss = 2.09138
I1210 12:17:54.736160 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 12:17:54.736160 10416 solver.cpp:237]     Train net output #1: loss = 2.09138 (* 1 = 2.09138 loss)
I1210 12:17:54.736160 10416 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1210 12:18:00.122361  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:18:00.347362 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_9000.caffemodel
I1210 12:18:00.366860 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_9000.solverstate
I1210 12:18:00.371861 10416 solver.cpp:330] Iteration 9000, Testing net (#0)
I1210 12:18:00.372360 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:18:01.742861  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:18:01.798362 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3524
I1210 12:18:01.798362 10416 solver.cpp:397]     Test net output #1: loss = 2.61385 (* 1 = 2.61385 loss)
I1210 12:18:01.851860 10416 solver.cpp:218] Iteration 9000 (14.0547 iter/s, 7.11505s/100 iters), loss = 2.09006
I1210 12:18:01.851860 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:18:01.851860 10416 solver.cpp:237]     Train net output #1: loss = 2.09006 (* 1 = 2.09006 loss)
I1210 12:18:01.851860 10416 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1210 12:18:07.523046 10416 solver.cpp:218] Iteration 9100 (17.6353 iter/s, 5.67044s/100 iters), loss = 1.81174
I1210 12:18:07.523046 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:18:07.523046 10416 solver.cpp:237]     Train net output #1: loss = 1.81174 (* 1 = 1.81174 loss)
I1210 12:18:07.523046 10416 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1210 12:18:13.207094 10416 solver.cpp:218] Iteration 9200 (17.5947 iter/s, 5.68354s/100 iters), loss = 1.55751
I1210 12:18:13.207094 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:18:13.207094 10416 solver.cpp:237]     Train net output #1: loss = 1.55751 (* 1 = 1.55751 loss)
I1210 12:18:13.207094 10416 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1210 12:18:18.878275 10416 solver.cpp:218] Iteration 9300 (17.633 iter/s, 5.67119s/100 iters), loss = 2.06143
I1210 12:18:18.878275 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:18:18.878775 10416 solver.cpp:237]     Train net output #1: loss = 2.06143 (* 1 = 2.06143 loss)
I1210 12:18:18.878775 10416 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1210 12:18:24.568321 10416 solver.cpp:218] Iteration 9400 (17.5763 iter/s, 5.68949s/100 iters), loss = 1.9638
I1210 12:18:24.568321 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:18:24.568321 10416 solver.cpp:237]     Train net output #1: loss = 1.9638 (* 1 = 1.9638 loss)
I1210 12:18:24.568321 10416 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1210 12:18:29.979648  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:18:30.202649 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_9500.caffemodel
I1210 12:18:30.216648 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_9500.solverstate
I1210 12:18:30.221149 10416 solver.cpp:330] Iteration 9500, Testing net (#0)
I1210 12:18:30.221149 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:18:31.594715  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:18:31.648214 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2915
I1210 12:18:31.648214 10416 solver.cpp:397]     Test net output #1: loss = 3.04937 (* 1 = 3.04937 loss)
I1210 12:18:31.703217 10416 solver.cpp:218] Iteration 9500 (14.0167 iter/s, 7.13434s/100 iters), loss = 1.89183
I1210 12:18:31.703217 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:18:31.703217 10416 solver.cpp:237]     Train net output #1: loss = 1.89183 (* 1 = 1.89183 loss)
I1210 12:18:31.703217 10416 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1210 12:18:37.372777 10416 solver.cpp:218] Iteration 9600 (17.639 iter/s, 5.66924s/100 iters), loss = 1.88038
I1210 12:18:37.372777 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:18:37.372777 10416 solver.cpp:237]     Train net output #1: loss = 1.88038 (* 1 = 1.88038 loss)
I1210 12:18:37.372777 10416 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1210 12:18:43.066277 10416 solver.cpp:218] Iteration 9700 (17.5653 iter/s, 5.69305s/100 iters), loss = 1.6367
I1210 12:18:43.066277 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:18:43.066277 10416 solver.cpp:237]     Train net output #1: loss = 1.6367 (* 1 = 1.6367 loss)
I1210 12:18:43.066277 10416 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1210 12:18:48.747797 10416 solver.cpp:218] Iteration 9800 (17.6023 iter/s, 5.68107s/100 iters), loss = 2.00118
I1210 12:18:48.747797 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:18:48.747797 10416 solver.cpp:237]     Train net output #1: loss = 2.00118 (* 1 = 2.00118 loss)
I1210 12:18:48.747797 10416 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1210 12:18:54.426295 10416 solver.cpp:218] Iteration 9900 (17.6115 iter/s, 5.67812s/100 iters), loss = 2.19294
I1210 12:18:54.426295 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:18:54.426795 10416 solver.cpp:237]     Train net output #1: loss = 2.19294 (* 1 = 2.19294 loss)
I1210 12:18:54.426795 10416 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1210 12:18:59.835438  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:19:00.065938 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_10000.caffemodel
I1210 12:19:00.085938 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_10000.solverstate
I1210 12:19:00.090939 10416 solver.cpp:330] Iteration 10000, Testing net (#0)
I1210 12:19:00.091439 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:19:01.466439  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:19:01.520438 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3987
I1210 12:19:01.520438 10416 solver.cpp:397]     Test net output #1: loss = 2.32105 (* 1 = 2.32105 loss)
I1210 12:19:01.576941 10416 solver.cpp:218] Iteration 10000 (13.9861 iter/s, 7.14994s/100 iters), loss = 1.99363
I1210 12:19:01.576941 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:19:01.576941 10416 solver.cpp:237]     Train net output #1: loss = 1.99363 (* 1 = 1.99363 loss)
I1210 12:19:01.576941 10416 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1210 12:19:07.254120 10416 solver.cpp:218] Iteration 10100 (17.6156 iter/s, 5.67677s/100 iters), loss = 1.82892
I1210 12:19:07.254120 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 12:19:07.254120 10416 solver.cpp:237]     Train net output #1: loss = 1.82892 (* 1 = 1.82892 loss)
I1210 12:19:07.254120 10416 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1210 12:19:12.941124 10416 solver.cpp:218] Iteration 10200 (17.5853 iter/s, 5.68656s/100 iters), loss = 1.62051
I1210 12:19:12.941124 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:19:12.941124 10416 solver.cpp:237]     Train net output #1: loss = 1.62051 (* 1 = 1.62051 loss)
I1210 12:19:12.941124 10416 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1210 12:19:18.623926 10416 solver.cpp:218] Iteration 10300 (17.5984 iter/s, 5.68233s/100 iters), loss = 1.90193
I1210 12:19:18.623926 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:19:18.623926 10416 solver.cpp:237]     Train net output #1: loss = 1.90193 (* 1 = 1.90193 loss)
I1210 12:19:18.623926 10416 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1210 12:19:24.303977 10416 solver.cpp:218] Iteration 10400 (17.6066 iter/s, 5.67967s/100 iters), loss = 2.04704
I1210 12:19:24.303977 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:19:24.303977 10416 solver.cpp:237]     Train net output #1: loss = 2.04704 (* 1 = 2.04704 loss)
I1210 12:19:24.303977 10416 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1210 12:19:29.707248  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:19:29.927749 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_10500.caffemodel
I1210 12:19:29.949748 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_10500.solverstate
I1210 12:19:29.954749 10416 solver.cpp:330] Iteration 10500, Testing net (#0)
I1210 12:19:29.955256 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:19:31.332789  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:19:31.386788 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3167
I1210 12:19:31.386788 10416 solver.cpp:397]     Test net output #1: loss = 3.11041 (* 1 = 3.11041 loss)
I1210 12:19:31.440287 10416 solver.cpp:218] Iteration 10500 (14.0143 iter/s, 7.13556s/100 iters), loss = 1.98172
I1210 12:19:31.440287 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:19:31.440287 10416 solver.cpp:237]     Train net output #1: loss = 1.98172 (* 1 = 1.98172 loss)
I1210 12:19:31.440287 10416 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1210 12:19:37.148298 10416 solver.cpp:218] Iteration 10600 (17.5207 iter/s, 5.70754s/100 iters), loss = 1.90039
I1210 12:19:37.148298 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 12:19:37.148298 10416 solver.cpp:237]     Train net output #1: loss = 1.90039 (* 1 = 1.90039 loss)
I1210 12:19:37.148298 10416 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1210 12:19:42.835309 10416 solver.cpp:218] Iteration 10700 (17.5844 iter/s, 5.68687s/100 iters), loss = 1.60676
I1210 12:19:42.835810 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 12:19:42.835810 10416 solver.cpp:237]     Train net output #1: loss = 1.60676 (* 1 = 1.60676 loss)
I1210 12:19:42.835810 10416 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1210 12:19:48.534189 10416 solver.cpp:218] Iteration 10800 (17.5494 iter/s, 5.69819s/100 iters), loss = 1.97821
I1210 12:19:48.534189 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:19:48.534189 10416 solver.cpp:237]     Train net output #1: loss = 1.97821 (* 1 = 1.97821 loss)
I1210 12:19:48.534189 10416 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1210 12:19:54.236189 10416 solver.cpp:218] Iteration 10900 (17.54 iter/s, 5.70124s/100 iters), loss = 2.00635
I1210 12:19:54.236189 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:19:54.236189 10416 solver.cpp:237]     Train net output #1: loss = 2.00635 (* 1 = 2.00635 loss)
I1210 12:19:54.236189 10416 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1210 12:19:59.654690  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:19:59.878690 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_11000.caffemodel
I1210 12:19:59.898190 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_11000.solverstate
I1210 12:19:59.903690 10416 solver.cpp:330] Iteration 11000, Testing net (#0)
I1210 12:19:59.903690 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:20:01.304410  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:20:01.359417 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2925
I1210 12:20:01.359417 10416 solver.cpp:397]     Test net output #1: loss = 3.18486 (* 1 = 3.18486 loss)
I1210 12:20:01.413422 10416 solver.cpp:218] Iteration 11000 (13.9323 iter/s, 7.17754s/100 iters), loss = 2.082
I1210 12:20:01.414422 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:20:01.414422 10416 solver.cpp:237]     Train net output #1: loss = 2.082 (* 1 = 2.082 loss)
I1210 12:20:01.414422 10416 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1210 12:20:07.080052 10416 solver.cpp:218] Iteration 11100 (17.6514 iter/s, 5.66528s/100 iters), loss = 1.80313
I1210 12:20:07.080052 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:20:07.080052 10416 solver.cpp:237]     Train net output #1: loss = 1.80313 (* 1 = 1.80313 loss)
I1210 12:20:07.080052 10416 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1210 12:20:12.753062 10416 solver.cpp:218] Iteration 11200 (17.6283 iter/s, 5.67269s/100 iters), loss = 1.72708
I1210 12:20:12.753062 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:20:12.753062 10416 solver.cpp:237]     Train net output #1: loss = 1.72708 (* 1 = 1.72708 loss)
I1210 12:20:12.753062 10416 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1210 12:20:18.426560 10416 solver.cpp:218] Iteration 11300 (17.6269 iter/s, 5.67316s/100 iters), loss = 1.95842
I1210 12:20:18.426560 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:20:18.426560 10416 solver.cpp:237]     Train net output #1: loss = 1.95842 (* 1 = 1.95842 loss)
I1210 12:20:18.426560 10416 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1210 12:20:24.096061 10416 solver.cpp:218] Iteration 11400 (17.6391 iter/s, 5.66922s/100 iters), loss = 1.99393
I1210 12:20:24.096561 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:20:24.096561 10416 solver.cpp:237]     Train net output #1: loss = 1.99393 (* 1 = 1.99393 loss)
I1210 12:20:24.096561 10416 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1210 12:20:29.485352  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:20:29.707851 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_11500.caffemodel
I1210 12:20:29.726851 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_11500.solverstate
I1210 12:20:29.731853 10416 solver.cpp:330] Iteration 11500, Testing net (#0)
I1210 12:20:29.732352 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:20:31.112865  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:20:31.166869 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3905
I1210 12:20:31.166869 10416 solver.cpp:397]     Test net output #1: loss = 2.4465 (* 1 = 2.4465 loss)
I1210 12:20:31.219874 10416 solver.cpp:218] Iteration 11500 (14.0384 iter/s, 7.1233s/100 iters), loss = 1.99544
I1210 12:20:31.220374 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:20:31.220374 10416 solver.cpp:237]     Train net output #1: loss = 1.99544 (* 1 = 1.99544 loss)
I1210 12:20:31.220374 10416 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1210 12:20:36.907424 10416 solver.cpp:218] Iteration 11600 (17.5836 iter/s, 5.68712s/100 iters), loss = 1.75204
I1210 12:20:36.907924 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:20:36.907924 10416 solver.cpp:237]     Train net output #1: loss = 1.75204 (* 1 = 1.75204 loss)
I1210 12:20:36.907924 10416 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1210 12:20:42.592923 10416 solver.cpp:218] Iteration 11700 (17.5913 iter/s, 5.68463s/100 iters), loss = 1.55283
I1210 12:20:42.592923 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:20:42.592923 10416 solver.cpp:237]     Train net output #1: loss = 1.55283 (* 1 = 1.55283 loss)
I1210 12:20:42.592923 10416 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1210 12:20:48.270054 10416 solver.cpp:218] Iteration 11800 (17.615 iter/s, 5.67697s/100 iters), loss = 2.18981
I1210 12:20:48.270555 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:20:48.270555 10416 solver.cpp:237]     Train net output #1: loss = 2.18981 (* 1 = 2.18981 loss)
I1210 12:20:48.270555 10416 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1210 12:20:53.965565 10416 solver.cpp:218] Iteration 11900 (17.5596 iter/s, 5.6949s/100 iters), loss = 1.9403
I1210 12:20:53.965565 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 12:20:53.965565 10416 solver.cpp:237]     Train net output #1: loss = 1.9403 (* 1 = 1.9403 loss)
I1210 12:20:53.965565 10416 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1210 12:20:59.391175  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:20:59.615671 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_12000.caffemodel
I1210 12:20:59.636672 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_12000.solverstate
I1210 12:20:59.643172 10416 solver.cpp:330] Iteration 12000, Testing net (#0)
I1210 12:20:59.643172 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:21:01.026381  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:21:01.079378 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3768
I1210 12:21:01.079378 10416 solver.cpp:397]     Test net output #1: loss = 2.42839 (* 1 = 2.42839 loss)
I1210 12:21:01.133388 10416 solver.cpp:218] Iteration 12000 (13.9516 iter/s, 7.16761s/100 iters), loss = 1.89167
I1210 12:21:01.133388 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:21:01.133388 10416 solver.cpp:237]     Train net output #1: loss = 1.89167 (* 1 = 1.89167 loss)
I1210 12:21:01.133388 10416 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1210 12:21:06.816433 10416 solver.cpp:218] Iteration 12100 (17.5992 iter/s, 5.68207s/100 iters), loss = 1.79115
I1210 12:21:06.816433 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:21:06.816433 10416 solver.cpp:237]     Train net output #1: loss = 1.79115 (* 1 = 1.79115 loss)
I1210 12:21:06.816433 10416 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1210 12:21:12.502463 10416 solver.cpp:218] Iteration 12200 (17.5872 iter/s, 5.68594s/100 iters), loss = 1.69929
I1210 12:21:12.502463 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:21:12.502463 10416 solver.cpp:237]     Train net output #1: loss = 1.69929 (* 1 = 1.69929 loss)
I1210 12:21:12.502463 10416 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1210 12:21:18.196460 10416 solver.cpp:218] Iteration 12300 (17.5646 iter/s, 5.69328s/100 iters), loss = 1.82661
I1210 12:21:18.196460 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:21:18.196460 10416 solver.cpp:237]     Train net output #1: loss = 1.82661 (* 1 = 1.82661 loss)
I1210 12:21:18.196460 10416 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1210 12:21:23.873462 10416 solver.cpp:218] Iteration 12400 (17.615 iter/s, 5.67699s/100 iters), loss = 1.9824
I1210 12:21:23.873968 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:21:23.873968 10416 solver.cpp:237]     Train net output #1: loss = 1.9824 (* 1 = 1.9824 loss)
I1210 12:21:23.873968 10416 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1210 12:21:29.282536  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:21:29.506525 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_12500.caffemodel
I1210 12:21:29.526026 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_12500.solverstate
I1210 12:21:29.530525 10416 solver.cpp:330] Iteration 12500, Testing net (#0)
I1210 12:21:29.531025 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:21:30.907577  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:21:30.960583 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3629
I1210 12:21:30.960583 10416 solver.cpp:397]     Test net output #1: loss = 2.59916 (* 1 = 2.59916 loss)
I1210 12:21:31.015086 10416 solver.cpp:218] Iteration 12500 (14.0042 iter/s, 7.14069s/100 iters), loss = 2.02536
I1210 12:21:31.015086 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1210 12:21:31.015086 10416 solver.cpp:237]     Train net output #1: loss = 2.02536 (* 1 = 2.02536 loss)
I1210 12:21:31.015086 10416 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1210 12:21:36.713626 10416 solver.cpp:218] Iteration 12600 (17.5491 iter/s, 5.6983s/100 iters), loss = 1.84655
I1210 12:21:36.713626 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:21:36.713626 10416 solver.cpp:237]     Train net output #1: loss = 1.84655 (* 1 = 1.84655 loss)
I1210 12:21:36.713626 10416 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1210 12:21:42.395648 10416 solver.cpp:218] Iteration 12700 (17.6007 iter/s, 5.68161s/100 iters), loss = 1.56383
I1210 12:21:42.395648 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:21:42.395648 10416 solver.cpp:237]     Train net output #1: loss = 1.56383 (* 1 = 1.56383 loss)
I1210 12:21:42.395648 10416 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1210 12:21:48.073127 10416 solver.cpp:218] Iteration 12800 (17.6141 iter/s, 5.67727s/100 iters), loss = 1.92222
I1210 12:21:48.073626 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 12:21:48.073626 10416 solver.cpp:237]     Train net output #1: loss = 1.92222 (* 1 = 1.92222 loss)
I1210 12:21:48.073626 10416 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1210 12:21:53.751720 10416 solver.cpp:218] Iteration 12900 (17.612 iter/s, 5.67795s/100 iters), loss = 1.94938
I1210 12:21:53.751720 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 12:21:53.751720 10416 solver.cpp:237]     Train net output #1: loss = 1.94938 (* 1 = 1.94938 loss)
I1210 12:21:53.751720 10416 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1210 12:21:59.164222  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:21:59.389721 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_13000.caffemodel
I1210 12:21:59.404222 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_13000.solverstate
I1210 12:21:59.408721 10416 solver.cpp:330] Iteration 13000, Testing net (#0)
I1210 12:21:59.409220 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:22:00.784960  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:22:00.838961 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3835
I1210 12:22:00.838961 10416 solver.cpp:397]     Test net output #1: loss = 2.43597 (* 1 = 2.43597 loss)
I1210 12:22:00.891961 10416 solver.cpp:218] Iteration 13000 (14.0059 iter/s, 7.13985s/100 iters), loss = 1.87509
I1210 12:22:00.891961 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:22:00.891961 10416 solver.cpp:237]     Train net output #1: loss = 1.87509 (* 1 = 1.87509 loss)
I1210 12:22:00.891961 10416 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1210 12:22:06.571516 10416 solver.cpp:218] Iteration 13100 (17.6082 iter/s, 5.67918s/100 iters), loss = 1.74307
I1210 12:22:06.572016 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:22:06.572016 10416 solver.cpp:237]     Train net output #1: loss = 1.74307 (* 1 = 1.74307 loss)
I1210 12:22:06.572016 10416 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1210 12:22:12.254747 10416 solver.cpp:218] Iteration 13200 (17.5978 iter/s, 5.68253s/100 iters), loss = 1.53744
I1210 12:22:12.254747 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:22:12.254747 10416 solver.cpp:237]     Train net output #1: loss = 1.53744 (* 1 = 1.53744 loss)
I1210 12:22:12.254747 10416 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1210 12:22:17.932291 10416 solver.cpp:218] Iteration 13300 (17.6145 iter/s, 5.67713s/100 iters), loss = 1.95432
I1210 12:22:17.932291 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:22:17.932291 10416 solver.cpp:237]     Train net output #1: loss = 1.95432 (* 1 = 1.95432 loss)
I1210 12:22:17.932291 10416 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1210 12:22:23.629498 10416 solver.cpp:218] Iteration 13400 (17.554 iter/s, 5.69671s/100 iters), loss = 1.95168
I1210 12:22:23.629498 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:22:23.629498 10416 solver.cpp:237]     Train net output #1: loss = 1.95168 (* 1 = 1.95168 loss)
I1210 12:22:23.629498 10416 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1210 12:22:29.027525  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:22:29.250022 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_13500.caffemodel
I1210 12:22:29.275022 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_13500.solverstate
I1210 12:22:29.280022 10416 solver.cpp:330] Iteration 13500, Testing net (#0)
I1210 12:22:29.280022 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:22:30.656651  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:22:30.710150 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3506
I1210 12:22:30.710649 10416 solver.cpp:397]     Test net output #1: loss = 2.72796 (* 1 = 2.72796 loss)
I1210 12:22:30.764153 10416 solver.cpp:218] Iteration 13500 (14.0167 iter/s, 7.13433s/100 iters), loss = 1.87586
I1210 12:22:30.764153 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:22:30.764650 10416 solver.cpp:237]     Train net output #1: loss = 1.87586 (* 1 = 1.87586 loss)
I1210 12:22:30.764650 10416 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1210 12:22:36.447191 10416 solver.cpp:218] Iteration 13600 (17.5979 iter/s, 5.68249s/100 iters), loss = 1.63905
I1210 12:22:36.447191 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:22:36.447191 10416 solver.cpp:237]     Train net output #1: loss = 1.63905 (* 1 = 1.63905 loss)
I1210 12:22:36.447191 10416 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1210 12:22:42.128052 10416 solver.cpp:218] Iteration 13700 (17.6049 iter/s, 5.68025s/100 iters), loss = 1.51633
I1210 12:22:42.128052 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 12:22:42.128052 10416 solver.cpp:237]     Train net output #1: loss = 1.51633 (* 1 = 1.51633 loss)
I1210 12:22:42.128052 10416 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1210 12:22:47.826710 10416 solver.cpp:218] Iteration 13800 (17.5488 iter/s, 5.69841s/100 iters), loss = 1.87448
I1210 12:22:47.826710 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:22:47.826710 10416 solver.cpp:237]     Train net output #1: loss = 1.87448 (* 1 = 1.87448 loss)
I1210 12:22:47.826710 10416 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1210 12:22:53.516829 10416 solver.cpp:218] Iteration 13900 (17.575 iter/s, 5.68989s/100 iters), loss = 2.06754
I1210 12:22:53.517330 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:22:53.517330 10416 solver.cpp:237]     Train net output #1: loss = 2.06754 (* 1 = 2.06754 loss)
I1210 12:22:53.517330 10416 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1210 12:22:58.926831  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:22:59.148830 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_14000.caffemodel
I1210 12:22:59.168830 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_14000.solverstate
I1210 12:22:59.173830 10416 solver.cpp:330] Iteration 14000, Testing net (#0)
I1210 12:22:59.173830 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:23:00.550829  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:23:00.604831 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2978
I1210 12:23:00.605331 10416 solver.cpp:397]     Test net output #1: loss = 3.23413 (* 1 = 3.23413 loss)
I1210 12:23:00.657831 10416 solver.cpp:218] Iteration 14000 (14.0052 iter/s, 7.1402s/100 iters), loss = 1.90369
I1210 12:23:00.657831 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:23:00.657831 10416 solver.cpp:237]     Train net output #1: loss = 1.90369 (* 1 = 1.90369 loss)
I1210 12:23:00.657831 10416 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1210 12:23:06.335916 10416 solver.cpp:218] Iteration 14100 (17.6129 iter/s, 5.67765s/100 iters), loss = 1.78393
I1210 12:23:06.335916 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 12:23:06.335916 10416 solver.cpp:237]     Train net output #1: loss = 1.78393 (* 1 = 1.78393 loss)
I1210 12:23:06.335916 10416 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1210 12:23:12.007416 10416 solver.cpp:218] Iteration 14200 (17.6336 iter/s, 5.67099s/100 iters), loss = 1.52158
I1210 12:23:12.007416 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:23:12.007416 10416 solver.cpp:237]     Train net output #1: loss = 1.52158 (* 1 = 1.52158 loss)
I1210 12:23:12.007416 10416 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1210 12:23:17.695422 10416 solver.cpp:218] Iteration 14300 (17.5816 iter/s, 5.68777s/100 iters), loss = 1.76368
I1210 12:23:17.695422 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:23:17.695422 10416 solver.cpp:237]     Train net output #1: loss = 1.76368 (* 1 = 1.76368 loss)
I1210 12:23:17.695422 10416 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1210 12:23:23.375929 10416 solver.cpp:218] Iteration 14400 (17.6047 iter/s, 5.68029s/100 iters), loss = 1.93924
I1210 12:23:23.376430 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:23:23.376430 10416 solver.cpp:237]     Train net output #1: loss = 1.93924 (* 1 = 1.93924 loss)
I1210 12:23:23.376430 10416 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1210 12:23:28.785931  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:23:29.010430 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_14500.caffemodel
I1210 12:23:29.030931 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_14500.solverstate
I1210 12:23:29.035431 10416 solver.cpp:330] Iteration 14500, Testing net (#0)
I1210 12:23:29.035930 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:23:30.406505  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:23:30.460510 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3026
I1210 12:23:30.460510 10416 solver.cpp:397]     Test net output #1: loss = 3.20419 (* 1 = 3.20419 loss)
I1210 12:23:30.514508 10416 solver.cpp:218] Iteration 14500 (14.0098 iter/s, 7.13786s/100 iters), loss = 1.80123
I1210 12:23:30.514508 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:23:30.514508 10416 solver.cpp:237]     Train net output #1: loss = 1.80123 (* 1 = 1.80123 loss)
I1210 12:23:30.514508 10416 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1210 12:23:36.180811 10416 solver.cpp:218] Iteration 14600 (17.6496 iter/s, 5.66584s/100 iters), loss = 1.68434
I1210 12:23:36.180811 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:23:36.180811 10416 solver.cpp:237]     Train net output #1: loss = 1.68434 (* 1 = 1.68434 loss)
I1210 12:23:36.180811 10416 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1210 12:23:41.846907 10416 solver.cpp:218] Iteration 14700 (17.6515 iter/s, 5.66523s/100 iters), loss = 1.43212
I1210 12:23:41.846907 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:23:41.846907 10416 solver.cpp:237]     Train net output #1: loss = 1.43212 (* 1 = 1.43212 loss)
I1210 12:23:41.846907 10416 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1210 12:23:47.498116 10416 solver.cpp:218] Iteration 14800 (17.6955 iter/s, 5.65116s/100 iters), loss = 2.01055
I1210 12:23:47.498615 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:23:47.498615 10416 solver.cpp:237]     Train net output #1: loss = 2.01055 (* 1 = 2.01055 loss)
I1210 12:23:47.498615 10416 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1210 12:23:53.157079 10416 solver.cpp:218] Iteration 14900 (17.6734 iter/s, 5.65823s/100 iters), loss = 1.89165
I1210 12:23:53.157079 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:23:53.157079 10416 solver.cpp:237]     Train net output #1: loss = 1.89165 (* 1 = 1.89165 loss)
I1210 12:23:53.157079 10416 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1210 12:23:58.542672  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:23:58.765676 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_15000.caffemodel
I1210 12:23:58.785676 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_15000.solverstate
I1210 12:23:58.790177 10416 solver.cpp:330] Iteration 15000, Testing net (#0)
I1210 12:23:58.790678 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:24:00.168720  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:24:00.221720 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3254
I1210 12:24:00.222221 10416 solver.cpp:397]     Test net output #1: loss = 2.86243 (* 1 = 2.86243 loss)
I1210 12:24:00.275221 10416 solver.cpp:218] Iteration 15000 (14.0494 iter/s, 7.11775s/100 iters), loss = 1.83212
I1210 12:24:00.275221 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:24:00.275221 10416 solver.cpp:237]     Train net output #1: loss = 1.83212 (* 1 = 1.83212 loss)
I1210 12:24:00.275221 10416 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1210 12:24:05.952786 10416 solver.cpp:218] Iteration 15100 (17.6151 iter/s, 5.67693s/100 iters), loss = 1.68411
I1210 12:24:05.952786 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:24:05.952786 10416 solver.cpp:237]     Train net output #1: loss = 1.68411 (* 1 = 1.68411 loss)
I1210 12:24:05.952786 10416 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1210 12:24:11.631307 10416 solver.cpp:218] Iteration 15200 (17.6105 iter/s, 5.67844s/100 iters), loss = 1.46846
I1210 12:24:11.631307 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:24:11.631806 10416 solver.cpp:237]     Train net output #1: loss = 1.46846 (* 1 = 1.46846 loss)
I1210 12:24:11.631806 10416 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1210 12:24:17.294802 10416 solver.cpp:218] Iteration 15300 (17.6594 iter/s, 5.6627s/100 iters), loss = 1.85325
I1210 12:24:17.294802 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:24:17.294802 10416 solver.cpp:237]     Train net output #1: loss = 1.85325 (* 1 = 1.85325 loss)
I1210 12:24:17.294802 10416 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1210 12:24:22.971992 10416 solver.cpp:218] Iteration 15400 (17.6159 iter/s, 5.6767s/100 iters), loss = 1.9528
I1210 12:24:22.971992 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:24:22.971992 10416 solver.cpp:237]     Train net output #1: loss = 1.9528 (* 1 = 1.9528 loss)
I1210 12:24:22.971992 10416 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1210 12:24:28.422044  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:24:28.641062 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_15500.caffemodel
I1210 12:24:28.656061 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_15500.solverstate
I1210 12:24:28.660061 10416 solver.cpp:330] Iteration 15500, Testing net (#0)
I1210 12:24:28.660061 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:24:30.034603  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:24:30.088606 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3331
I1210 12:24:30.088606 10416 solver.cpp:397]     Test net output #1: loss = 2.96968 (* 1 = 2.96968 loss)
I1210 12:24:30.141604 10416 solver.cpp:218] Iteration 15500 (13.9483 iter/s, 7.16931s/100 iters), loss = 1.946
I1210 12:24:30.141604 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:24:30.141604 10416 solver.cpp:237]     Train net output #1: loss = 1.946 (* 1 = 1.946 loss)
I1210 12:24:30.141604 10416 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1210 12:24:35.799703 10416 solver.cpp:218] Iteration 15600 (17.6747 iter/s, 5.6578s/100 iters), loss = 1.77529
I1210 12:24:35.799703 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 12:24:35.799703 10416 solver.cpp:237]     Train net output #1: loss = 1.77529 (* 1 = 1.77529 loss)
I1210 12:24:35.799703 10416 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1210 12:24:41.464704 10416 solver.cpp:218] Iteration 15700 (17.6532 iter/s, 5.66468s/100 iters), loss = 1.58562
I1210 12:24:41.464704 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:24:41.464704 10416 solver.cpp:237]     Train net output #1: loss = 1.58562 (* 1 = 1.58562 loss)
I1210 12:24:41.464704 10416 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1210 12:24:47.118350 10416 solver.cpp:218] Iteration 15800 (17.6884 iter/s, 5.65341s/100 iters), loss = 1.85919
I1210 12:24:47.118350 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:24:47.118350 10416 solver.cpp:237]     Train net output #1: loss = 1.85919 (* 1 = 1.85919 loss)
I1210 12:24:47.118350 10416 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1210 12:24:52.782361 10416 solver.cpp:218] Iteration 15900 (17.6576 iter/s, 5.66329s/100 iters), loss = 1.98469
I1210 12:24:52.782361 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:24:52.782361 10416 solver.cpp:237]     Train net output #1: loss = 1.98469 (* 1 = 1.98469 loss)
I1210 12:24:52.782361 10416 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1210 12:24:58.176863  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:24:58.398860 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_16000.caffemodel
I1210 12:24:58.418861 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_16000.solverstate
I1210 12:24:58.423360 10416 solver.cpp:330] Iteration 16000, Testing net (#0)
I1210 12:24:58.423360 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:24:59.793648  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:24:59.848145 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3285
I1210 12:24:59.848145 10416 solver.cpp:397]     Test net output #1: loss = 2.8819 (* 1 = 2.8819 loss)
I1210 12:24:59.902143 10416 solver.cpp:218] Iteration 16000 (14.0466 iter/s, 7.11918s/100 iters), loss = 1.83023
I1210 12:24:59.902143 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:24:59.902143 10416 solver.cpp:237]     Train net output #1: loss = 1.83023 (* 1 = 1.83023 loss)
I1210 12:24:59.902143 10416 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1210 12:25:05.568644 10416 solver.cpp:218] Iteration 16100 (17.6484 iter/s, 5.66624s/100 iters), loss = 1.85821
I1210 12:25:05.569144 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:25:05.569144 10416 solver.cpp:237]     Train net output #1: loss = 1.85821 (* 1 = 1.85821 loss)
I1210 12:25:05.569144 10416 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1210 12:25:11.219223 10416 solver.cpp:218] Iteration 16200 (17.7001 iter/s, 5.64969s/100 iters), loss = 1.40505
I1210 12:25:11.219223 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:25:11.219223 10416 solver.cpp:237]     Train net output #1: loss = 1.40505 (* 1 = 1.40505 loss)
I1210 12:25:11.219223 10416 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1210 12:25:16.885723 10416 solver.cpp:218] Iteration 16300 (17.6489 iter/s, 5.66609s/100 iters), loss = 1.79679
I1210 12:25:16.885723 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:25:16.885723 10416 solver.cpp:237]     Train net output #1: loss = 1.79679 (* 1 = 1.79679 loss)
I1210 12:25:16.885723 10416 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1210 12:25:22.547359 10416 solver.cpp:218] Iteration 16400 (17.6629 iter/s, 5.66158s/100 iters), loss = 1.96511
I1210 12:25:22.547359 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:25:22.547359 10416 solver.cpp:237]     Train net output #1: loss = 1.96511 (* 1 = 1.96511 loss)
I1210 12:25:22.547359 10416 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1210 12:25:27.927386  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:25:28.149888 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_16500.caffemodel
I1210 12:25:28.163887 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_16500.solverstate
I1210 12:25:28.168885 10416 solver.cpp:330] Iteration 16500, Testing net (#0)
I1210 12:25:28.168885 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:25:29.542935  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:25:29.597435 10416 solver.cpp:397]     Test net output #0: accuracy = 0.4084
I1210 12:25:29.597435 10416 solver.cpp:397]     Test net output #1: loss = 2.3313 (* 1 = 2.3313 loss)
I1210 12:25:29.651437 10416 solver.cpp:218] Iteration 16500 (14.0778 iter/s, 7.10336s/100 iters), loss = 1.89355
I1210 12:25:29.651437 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:25:29.651437 10416 solver.cpp:237]     Train net output #1: loss = 1.89355 (* 1 = 1.89355 loss)
I1210 12:25:29.651437 10416 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1210 12:25:35.318951 10416 solver.cpp:218] Iteration 16600 (17.6453 iter/s, 5.66724s/100 iters), loss = 1.74414
I1210 12:25:35.318951 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:25:35.318951 10416 solver.cpp:237]     Train net output #1: loss = 1.74414 (* 1 = 1.74414 loss)
I1210 12:25:35.318951 10416 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1210 12:25:40.972362 10416 solver.cpp:218] Iteration 16700 (17.6877 iter/s, 5.65366s/100 iters), loss = 1.46352
I1210 12:25:40.973363 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:25:40.973363 10416 solver.cpp:237]     Train net output #1: loss = 1.46352 (* 1 = 1.46352 loss)
I1210 12:25:40.973363 10416 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1210 12:25:46.628387 10416 solver.cpp:218] Iteration 16800 (17.6847 iter/s, 5.65461s/100 iters), loss = 1.79217
I1210 12:25:46.628387 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:25:46.628387 10416 solver.cpp:237]     Train net output #1: loss = 1.79217 (* 1 = 1.79217 loss)
I1210 12:25:46.628387 10416 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1210 12:25:52.285668 10416 solver.cpp:218] Iteration 16900 (17.6771 iter/s, 5.65704s/100 iters), loss = 1.9943
I1210 12:25:52.285668 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:25:52.286172 10416 solver.cpp:237]     Train net output #1: loss = 1.9943 (* 1 = 1.9943 loss)
I1210 12:25:52.286172 10416 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1210 12:25:57.642874  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:25:57.864372 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_17000.caffemodel
I1210 12:25:57.882872 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_17000.solverstate
I1210 12:25:57.887873 10416 solver.cpp:330] Iteration 17000, Testing net (#0)
I1210 12:25:57.887873 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:25:59.260993  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:25:59.314002 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3825
I1210 12:25:59.314002 10416 solver.cpp:397]     Test net output #1: loss = 2.50313 (* 1 = 2.50313 loss)
I1210 12:25:59.367002 10416 solver.cpp:218] Iteration 17000 (14.1222 iter/s, 7.08107s/100 iters), loss = 1.81827
I1210 12:25:59.367002 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:25:59.367002 10416 solver.cpp:237]     Train net output #1: loss = 1.81827 (* 1 = 1.81827 loss)
I1210 12:25:59.367002 10416 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1210 12:26:05.062526 10416 solver.cpp:218] Iteration 17100 (17.5618 iter/s, 5.69419s/100 iters), loss = 1.85037
I1210 12:26:05.062526 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:26:05.062526 10416 solver.cpp:237]     Train net output #1: loss = 1.85037 (* 1 = 1.85037 loss)
I1210 12:26:05.062526 10416 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1210 12:26:10.745025 10416 solver.cpp:218] Iteration 17200 (17.5982 iter/s, 5.6824s/100 iters), loss = 1.51237
I1210 12:26:10.745527 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:26:10.745527 10416 solver.cpp:237]     Train net output #1: loss = 1.51237 (* 1 = 1.51237 loss)
I1210 12:26:10.745527 10416 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1210 12:26:16.428526 10416 solver.cpp:218] Iteration 17300 (17.5972 iter/s, 5.68271s/100 iters), loss = 2.00558
I1210 12:26:16.428526 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1210 12:26:16.428526 10416 solver.cpp:237]     Train net output #1: loss = 2.00558 (* 1 = 2.00558 loss)
I1210 12:26:16.428526 10416 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1210 12:26:22.110025 10416 solver.cpp:218] Iteration 17400 (17.6023 iter/s, 5.68108s/100 iters), loss = 1.85977
I1210 12:26:22.110025 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:26:22.110025 10416 solver.cpp:237]     Train net output #1: loss = 1.85977 (* 1 = 1.85977 loss)
I1210 12:26:22.110025 10416 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1210 12:26:27.505250  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:26:27.727751 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_17500.caffemodel
I1210 12:26:27.742751 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_17500.solverstate
I1210 12:26:27.747251 10416 solver.cpp:330] Iteration 17500, Testing net (#0)
I1210 12:26:27.747251 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:26:29.114893  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:26:29.167397 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3644
I1210 12:26:29.167397 10416 solver.cpp:397]     Test net output #1: loss = 2.6171 (* 1 = 2.6171 loss)
I1210 12:26:29.220398 10416 solver.cpp:218] Iteration 17500 (14.0645 iter/s, 7.1101s/100 iters), loss = 2.0248
I1210 12:26:29.220398 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:26:29.220398 10416 solver.cpp:237]     Train net output #1: loss = 2.0248 (* 1 = 2.0248 loss)
I1210 12:26:29.220398 10416 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1210 12:26:34.891871 10416 solver.cpp:218] Iteration 17600 (17.633 iter/s, 5.67119s/100 iters), loss = 1.77297
I1210 12:26:34.892372 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:26:34.892372 10416 solver.cpp:237]     Train net output #1: loss = 1.77297 (* 1 = 1.77297 loss)
I1210 12:26:34.892372 10416 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1210 12:26:40.552163 10416 solver.cpp:218] Iteration 17700 (17.6678 iter/s, 5.66002s/100 iters), loss = 1.45285
I1210 12:26:40.552163 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:26:40.552163 10416 solver.cpp:237]     Train net output #1: loss = 1.45285 (* 1 = 1.45285 loss)
I1210 12:26:40.552163 10416 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1210 12:26:46.222748 10416 solver.cpp:218] Iteration 17800 (17.6378 iter/s, 5.66963s/100 iters), loss = 1.95224
I1210 12:26:46.222748 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:26:46.222748 10416 solver.cpp:237]     Train net output #1: loss = 1.95224 (* 1 = 1.95224 loss)
I1210 12:26:46.222748 10416 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1210 12:26:51.896940 10416 solver.cpp:218] Iteration 17900 (17.6243 iter/s, 5.674s/100 iters), loss = 1.92148
I1210 12:26:51.896940 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:26:51.896940 10416 solver.cpp:237]     Train net output #1: loss = 1.92148 (* 1 = 1.92148 loss)
I1210 12:26:51.896940 10416 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1210 12:26:57.275372  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:26:57.498872 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_18000.caffemodel
I1210 12:26:57.517871 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_18000.solverstate
I1210 12:26:57.522871 10416 solver.cpp:330] Iteration 18000, Testing net (#0)
I1210 12:26:57.522871 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:26:58.897452  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:26:58.951961 10416 solver.cpp:397]     Test net output #0: accuracy = 0.4194
I1210 12:26:58.951961 10416 solver.cpp:397]     Test net output #1: loss = 2.234 (* 1 = 2.234 loss)
I1210 12:26:59.005461 10416 solver.cpp:218] Iteration 18000 (14.0691 iter/s, 7.10776s/100 iters), loss = 1.70798
I1210 12:26:59.005461 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:26:59.005461 10416 solver.cpp:237]     Train net output #1: loss = 1.70798 (* 1 = 1.70798 loss)
I1210 12:26:59.005461 10416 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1210 12:27:04.652081 10416 solver.cpp:218] Iteration 18100 (17.7105 iter/s, 5.64638s/100 iters), loss = 1.50508
I1210 12:27:04.652081 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:27:04.652081 10416 solver.cpp:237]     Train net output #1: loss = 1.50508 (* 1 = 1.50508 loss)
I1210 12:27:04.652081 10416 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1210 12:27:10.302959 10416 solver.cpp:218] Iteration 18200 (17.6981 iter/s, 5.65032s/100 iters), loss = 1.54652
I1210 12:27:10.302959 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:27:10.302959 10416 solver.cpp:237]     Train net output #1: loss = 1.54652 (* 1 = 1.54652 loss)
I1210 12:27:10.302959 10416 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1210 12:27:15.962828 10416 solver.cpp:218] Iteration 18300 (17.6699 iter/s, 5.65935s/100 iters), loss = 1.95313
I1210 12:27:15.962828 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:27:15.962828 10416 solver.cpp:237]     Train net output #1: loss = 1.95313 (* 1 = 1.95313 loss)
I1210 12:27:15.962828 10416 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1210 12:27:21.628073 10416 solver.cpp:218] Iteration 18400 (17.6519 iter/s, 5.66512s/100 iters), loss = 1.85972
I1210 12:27:21.628073 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:27:21.628073 10416 solver.cpp:237]     Train net output #1: loss = 1.85972 (* 1 = 1.85972 loss)
I1210 12:27:21.628073 10416 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1210 12:27:27.024104  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:27:27.246603 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_18500.caffemodel
I1210 12:27:27.267103 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_18500.solverstate
I1210 12:27:27.272104 10416 solver.cpp:330] Iteration 18500, Testing net (#0)
I1210 12:27:27.272104 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:27:28.647104  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:27:28.701104 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3612
I1210 12:27:28.701104 10416 solver.cpp:397]     Test net output #1: loss = 2.62617 (* 1 = 2.62617 loss)
I1210 12:27:28.754102 10416 solver.cpp:218] Iteration 18500 (14.034 iter/s, 7.12556s/100 iters), loss = 1.69666
I1210 12:27:28.754102 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:27:28.754102 10416 solver.cpp:237]     Train net output #1: loss = 1.69666 (* 1 = 1.69666 loss)
I1210 12:27:28.754102 10416 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1210 12:27:34.406602 10416 solver.cpp:218] Iteration 18600 (17.6934 iter/s, 5.65183s/100 iters), loss = 1.64902
I1210 12:27:34.406602 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:27:34.406602 10416 solver.cpp:237]     Train net output #1: loss = 1.64902 (* 1 = 1.64902 loss)
I1210 12:27:34.406602 10416 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1210 12:27:40.062600 10416 solver.cpp:218] Iteration 18700 (17.6825 iter/s, 5.65532s/100 iters), loss = 1.59431
I1210 12:27:40.062600 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:27:40.062600 10416 solver.cpp:237]     Train net output #1: loss = 1.59431 (* 1 = 1.59431 loss)
I1210 12:27:40.062600 10416 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1210 12:27:45.711663 10416 solver.cpp:218] Iteration 18800 (17.7025 iter/s, 5.64892s/100 iters), loss = 1.92333
I1210 12:27:45.711663 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:27:45.711663 10416 solver.cpp:237]     Train net output #1: loss = 1.92333 (* 1 = 1.92333 loss)
I1210 12:27:45.711663 10416 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1210 12:27:51.365161 10416 solver.cpp:218] Iteration 18900 (17.6903 iter/s, 5.65281s/100 iters), loss = 1.87516
I1210 12:27:51.365161 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:27:51.365161 10416 solver.cpp:237]     Train net output #1: loss = 1.87516 (* 1 = 1.87516 loss)
I1210 12:27:51.365161 10416 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1210 12:27:56.761662  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:27:56.985662 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_19000.caffemodel
I1210 12:27:57.005162 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_19000.solverstate
I1210 12:27:57.010663 10416 solver.cpp:330] Iteration 19000, Testing net (#0)
I1210 12:27:57.010663 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:27:58.381695  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:27:58.435194 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3161
I1210 12:27:58.435194 10416 solver.cpp:397]     Test net output #1: loss = 3.16833 (* 1 = 3.16833 loss)
I1210 12:27:58.490694 10416 solver.cpp:218] Iteration 19000 (14.0343 iter/s, 7.12542s/100 iters), loss = 1.78613
I1210 12:27:58.491194 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:27:58.491194 10416 solver.cpp:237]     Train net output #1: loss = 1.78613 (* 1 = 1.78613 loss)
I1210 12:27:58.491194 10416 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1210 12:28:04.148651 10416 solver.cpp:218] Iteration 19100 (17.676 iter/s, 5.65739s/100 iters), loss = 1.61233
I1210 12:28:04.148651 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:28:04.148651 10416 solver.cpp:237]     Train net output #1: loss = 1.61233 (* 1 = 1.61233 loss)
I1210 12:28:04.148651 10416 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1210 12:28:09.795718 10416 solver.cpp:218] Iteration 19200 (17.7104 iter/s, 5.6464s/100 iters), loss = 1.51743
I1210 12:28:09.795718 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 12:28:09.795718 10416 solver.cpp:237]     Train net output #1: loss = 1.51743 (* 1 = 1.51743 loss)
I1210 12:28:09.795718 10416 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1210 12:28:15.458297 10416 solver.cpp:218] Iteration 19300 (17.66 iter/s, 5.66251s/100 iters), loss = 1.89285
I1210 12:28:15.458798 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:28:15.458798 10416 solver.cpp:237]     Train net output #1: loss = 1.89285 (* 1 = 1.89285 loss)
I1210 12:28:15.458798 10416 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1210 12:28:21.118825 10416 solver.cpp:218] Iteration 19400 (17.6671 iter/s, 5.66024s/100 iters), loss = 2.02906
I1210 12:28:21.118825 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:28:21.118825 10416 solver.cpp:237]     Train net output #1: loss = 2.02906 (* 1 = 2.02906 loss)
I1210 12:28:21.118825 10416 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1210 12:28:26.495633  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:28:26.719135 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_19500.caffemodel
I1210 12:28:26.733134 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_19500.solverstate
I1210 12:28:26.737635 10416 solver.cpp:330] Iteration 19500, Testing net (#0)
I1210 12:28:26.737635 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:28:28.112635  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:28:28.166633 10416 solver.cpp:397]     Test net output #0: accuracy = 0.31
I1210 12:28:28.167134 10416 solver.cpp:397]     Test net output #1: loss = 3.22535 (* 1 = 3.22535 loss)
I1210 12:28:28.221134 10416 solver.cpp:218] Iteration 19500 (14.0813 iter/s, 7.1016s/100 iters), loss = 1.66366
I1210 12:28:28.221134 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:28:28.221134 10416 solver.cpp:237]     Train net output #1: loss = 1.66366 (* 1 = 1.66366 loss)
I1210 12:28:28.221134 10416 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1210 12:28:33.890632 10416 solver.cpp:218] Iteration 19600 (17.6401 iter/s, 5.6689s/100 iters), loss = 1.60387
I1210 12:28:33.890632 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:28:33.890632 10416 solver.cpp:237]     Train net output #1: loss = 1.60387 (* 1 = 1.60387 loss)
I1210 12:28:33.890632 10416 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1210 12:28:39.554535 10416 solver.cpp:218] Iteration 19700 (17.655 iter/s, 5.66412s/100 iters), loss = 1.52328
I1210 12:28:39.554535 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 12:28:39.554535 10416 solver.cpp:237]     Train net output #1: loss = 1.52328 (* 1 = 1.52328 loss)
I1210 12:28:39.554535 10416 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1210 12:28:45.219094 10416 solver.cpp:218] Iteration 19800 (17.6567 iter/s, 5.66356s/100 iters), loss = 1.97375
I1210 12:28:45.219094 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 12:28:45.219094 10416 solver.cpp:237]     Train net output #1: loss = 1.97375 (* 1 = 1.97375 loss)
I1210 12:28:45.219094 10416 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1210 12:28:50.871664 10416 solver.cpp:218] Iteration 19900 (17.6929 iter/s, 5.65197s/100 iters), loss = 1.85654
I1210 12:28:50.871664 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:28:50.871664 10416 solver.cpp:237]     Train net output #1: loss = 1.85654 (* 1 = 1.85654 loss)
I1210 12:28:50.871664 10416 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1210 12:28:56.243661  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:28:56.464663 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_20000.caffemodel
I1210 12:28:56.485162 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_20000.solverstate
I1210 12:28:56.493162 10416 solver.cpp:330] Iteration 20000, Testing net (#0)
I1210 12:28:56.493162 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:28:57.864660  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:28:57.918160 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3351
I1210 12:28:57.918160 10416 solver.cpp:397]     Test net output #1: loss = 2.98151 (* 1 = 2.98151 loss)
I1210 12:28:57.971660 10416 solver.cpp:218] Iteration 20000 (14.0853 iter/s, 7.09961s/100 iters), loss = 1.69246
I1210 12:28:57.971660 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:28:57.971660 10416 solver.cpp:237]     Train net output #1: loss = 1.69246 (* 1 = 1.69246 loss)
I1210 12:28:57.971660 10416 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1210 12:29:03.654814 10416 solver.cpp:218] Iteration 20100 (17.5973 iter/s, 5.68268s/100 iters), loss = 1.89708
I1210 12:29:03.654814 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 12:29:03.654814 10416 solver.cpp:237]     Train net output #1: loss = 1.89708 (* 1 = 1.89708 loss)
I1210 12:29:03.654814 10416 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1210 12:29:09.332901 10416 solver.cpp:218] Iteration 20200 (17.6124 iter/s, 5.67782s/100 iters), loss = 1.38982
I1210 12:29:09.332901 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:29:09.333402 10416 solver.cpp:237]     Train net output #1: loss = 1.38982 (* 1 = 1.38982 loss)
I1210 12:29:09.333402 10416 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1210 12:29:15.004441 10416 solver.cpp:218] Iteration 20300 (17.6344 iter/s, 5.67074s/100 iters), loss = 1.78125
I1210 12:29:15.004441 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:29:15.004441 10416 solver.cpp:237]     Train net output #1: loss = 1.78125 (* 1 = 1.78125 loss)
I1210 12:29:15.004441 10416 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1210 12:29:20.683787 10416 solver.cpp:218] Iteration 20400 (17.6084 iter/s, 5.67911s/100 iters), loss = 1.93514
I1210 12:29:20.683787 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:29:20.683787 10416 solver.cpp:237]     Train net output #1: loss = 1.93514 (* 1 = 1.93514 loss)
I1210 12:29:20.683787 10416 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1210 12:29:26.087450  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:29:26.311950 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_20500.caffemodel
I1210 12:29:26.326949 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_20500.solverstate
I1210 12:29:26.331449 10416 solver.cpp:330] Iteration 20500, Testing net (#0)
I1210 12:29:26.331449 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:29:27.711978  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:29:27.765504 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3282
I1210 12:29:27.765504 10416 solver.cpp:397]     Test net output #1: loss = 2.84499 (* 1 = 2.84499 loss)
I1210 12:29:27.818563 10416 solver.cpp:218] Iteration 20500 (14.0158 iter/s, 7.1348s/100 iters), loss = 1.89735
I1210 12:29:27.818563 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:29:27.818563 10416 solver.cpp:237]     Train net output #1: loss = 1.89735 (* 1 = 1.89735 loss)
I1210 12:29:27.818563 10416 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1210 12:29:33.504303 10416 solver.cpp:218] Iteration 20600 (17.5916 iter/s, 5.68452s/100 iters), loss = 1.69081
I1210 12:29:33.504303 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:29:33.504303 10416 solver.cpp:237]     Train net output #1: loss = 1.69081 (* 1 = 1.69081 loss)
I1210 12:29:33.504303 10416 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1210 12:29:39.169828 10416 solver.cpp:218] Iteration 20700 (17.6519 iter/s, 5.6651s/100 iters), loss = 1.42856
I1210 12:29:39.169828 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 12:29:39.169828 10416 solver.cpp:237]     Train net output #1: loss = 1.42856 (* 1 = 1.42856 loss)
I1210 12:29:39.169828 10416 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1210 12:29:44.834828 10416 solver.cpp:218] Iteration 20800 (17.6528 iter/s, 5.66483s/100 iters), loss = 1.78764
I1210 12:29:44.834828 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:29:44.834828 10416 solver.cpp:237]     Train net output #1: loss = 1.78764 (* 1 = 1.78764 loss)
I1210 12:29:44.834828 10416 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1210 12:29:50.499828 10416 solver.cpp:218] Iteration 20900 (17.6541 iter/s, 5.66441s/100 iters), loss = 1.83229
I1210 12:29:50.499828 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:29:50.499828 10416 solver.cpp:237]     Train net output #1: loss = 1.83229 (* 1 = 1.83229 loss)
I1210 12:29:50.499828 10416 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1210 12:29:55.869828  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:29:56.092829 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_21000.caffemodel
I1210 12:29:56.112329 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_21000.solverstate
I1210 12:29:56.117329 10416 solver.cpp:330] Iteration 21000, Testing net (#0)
I1210 12:29:56.117329 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:29:57.487888  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:29:57.542893 10416 solver.cpp:397]     Test net output #0: accuracy = 0.4088
I1210 12:29:57.542893 10416 solver.cpp:397]     Test net output #1: loss = 2.27403 (* 1 = 2.27403 loss)
I1210 12:29:57.595894 10416 solver.cpp:218] Iteration 21000 (14.0932 iter/s, 7.09561s/100 iters), loss = 1.68336
I1210 12:29:57.595894 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:29:57.595894 10416 solver.cpp:237]     Train net output #1: loss = 1.68336 (* 1 = 1.68336 loss)
I1210 12:29:57.595894 10416 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1210 12:30:03.258339 10416 solver.cpp:218] Iteration 21100 (17.6611 iter/s, 5.66216s/100 iters), loss = 1.6493
I1210 12:30:03.258339 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:30:03.258339 10416 solver.cpp:237]     Train net output #1: loss = 1.6493 (* 1 = 1.6493 loss)
I1210 12:30:03.258339 10416 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1210 12:30:08.928865 10416 solver.cpp:218] Iteration 21200 (17.6382 iter/s, 5.66951s/100 iters), loss = 1.61874
I1210 12:30:08.928865 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:30:08.928865 10416 solver.cpp:237]     Train net output #1: loss = 1.61874 (* 1 = 1.61874 loss)
I1210 12:30:08.928865 10416 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1210 12:30:14.579320 10416 solver.cpp:218] Iteration 21300 (17.6985 iter/s, 5.65019s/100 iters), loss = 1.68845
I1210 12:30:14.579320 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:30:14.579320 10416 solver.cpp:237]     Train net output #1: loss = 1.68845 (* 1 = 1.68845 loss)
I1210 12:30:14.579320 10416 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1210 12:30:20.229777 10416 solver.cpp:218] Iteration 21400 (17.6998 iter/s, 5.64977s/100 iters), loss = 1.83477
I1210 12:30:20.229777 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:30:20.229777 10416 solver.cpp:237]     Train net output #1: loss = 1.83477 (* 1 = 1.83477 loss)
I1210 12:30:20.229777 10416 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1210 12:30:25.589408  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:30:25.811419 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_21500.caffemodel
I1210 12:30:25.830427 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_21500.solverstate
I1210 12:30:25.835418 10416 solver.cpp:330] Iteration 21500, Testing net (#0)
I1210 12:30:25.835418 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:30:27.208549  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:30:27.262051 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3232
I1210 12:30:27.262051 10416 solver.cpp:397]     Test net output #1: loss = 2.78896 (* 1 = 2.78896 loss)
I1210 12:30:27.315554 10416 solver.cpp:218] Iteration 21500 (14.1138 iter/s, 7.08528s/100 iters), loss = 1.71721
I1210 12:30:27.315554 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:30:27.315554 10416 solver.cpp:237]     Train net output #1: loss = 1.71721 (* 1 = 1.71721 loss)
I1210 12:30:27.315554 10416 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1210 12:30:32.958014 10416 solver.cpp:218] Iteration 21600 (17.7224 iter/s, 5.64256s/100 iters), loss = 1.81979
I1210 12:30:32.958014 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:30:32.958014 10416 solver.cpp:237]     Train net output #1: loss = 1.81979 (* 1 = 1.81979 loss)
I1210 12:30:32.958014 10416 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1210 12:30:38.603461 10416 solver.cpp:218] Iteration 21700 (17.7152 iter/s, 5.64487s/100 iters), loss = 1.45355
I1210 12:30:38.603461 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:30:38.603461 10416 solver.cpp:237]     Train net output #1: loss = 1.45355 (* 1 = 1.45355 loss)
I1210 12:30:38.603461 10416 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1210 12:30:44.253934 10416 solver.cpp:218] Iteration 21800 (17.6997 iter/s, 5.64981s/100 iters), loss = 1.77802
I1210 12:30:44.253934 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:30:44.253934 10416 solver.cpp:237]     Train net output #1: loss = 1.77802 (* 1 = 1.77802 loss)
I1210 12:30:44.253934 10416 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1210 12:30:49.908100 10416 solver.cpp:218] Iteration 21900 (17.6876 iter/s, 5.65368s/100 iters), loss = 1.81437
I1210 12:30:49.908100 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 12:30:49.908100 10416 solver.cpp:237]     Train net output #1: loss = 1.81437 (* 1 = 1.81437 loss)
I1210 12:30:49.908100 10416 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1210 12:30:55.272943  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:30:55.494966 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_22000.caffemodel
I1210 12:30:55.513967 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_22000.solverstate
I1210 12:30:55.518966 10416 solver.cpp:330] Iteration 22000, Testing net (#0)
I1210 12:30:55.518966 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:30:56.889700  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:30:56.943696 10416 solver.cpp:397]     Test net output #0: accuracy = 0.4097
I1210 12:30:56.943696 10416 solver.cpp:397]     Test net output #1: loss = 2.26788 (* 1 = 2.26788 loss)
I1210 12:30:56.996697 10416 solver.cpp:218] Iteration 22000 (14.1083 iter/s, 7.08802s/100 iters), loss = 1.856
I1210 12:30:56.996697 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:30:56.996697 10416 solver.cpp:237]     Train net output #1: loss = 1.856 (* 1 = 1.856 loss)
I1210 12:30:56.996697 10416 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1210 12:31:02.674701 10416 solver.cpp:218] Iteration 22100 (17.6138 iter/s, 5.67736s/100 iters), loss = 1.79298
I1210 12:31:02.674701 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:31:02.674701 10416 solver.cpp:237]     Train net output #1: loss = 1.79298 (* 1 = 1.79298 loss)
I1210 12:31:02.674701 10416 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1210 12:31:08.698535 10416 solver.cpp:218] Iteration 22200 (16.6013 iter/s, 6.02362s/100 iters), loss = 1.34471
I1210 12:31:08.698535 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 12:31:08.698535 10416 solver.cpp:237]     Train net output #1: loss = 1.34471 (* 1 = 1.34471 loss)
I1210 12:31:08.698535 10416 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1210 12:31:14.513658 10416 solver.cpp:218] Iteration 22300 (17.1966 iter/s, 5.8151s/100 iters), loss = 1.82302
I1210 12:31:14.513658 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:31:14.513658 10416 solver.cpp:237]     Train net output #1: loss = 1.82302 (* 1 = 1.82302 loss)
I1210 12:31:14.513658 10416 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1210 12:31:20.193544 10416 solver.cpp:218] Iteration 22400 (17.6098 iter/s, 5.67866s/100 iters), loss = 1.95989
I1210 12:31:20.193544 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:31:20.193544 10416 solver.cpp:237]     Train net output #1: loss = 1.95989 (* 1 = 1.95989 loss)
I1210 12:31:20.193544 10416 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1210 12:31:25.610936  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:31:25.836709 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_22500.caffemodel
I1210 12:31:25.856710 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_22500.solverstate
I1210 12:31:25.861728 10416 solver.cpp:330] Iteration 22500, Testing net (#0)
I1210 12:31:25.861728 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:31:27.254106  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:31:27.311108 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3263
I1210 12:31:27.311108 10416 solver.cpp:397]     Test net output #1: loss = 2.95675 (* 1 = 2.95675 loss)
I1210 12:31:27.365123 10416 solver.cpp:218] Iteration 22500 (13.9446 iter/s, 7.17124s/100 iters), loss = 1.75396
I1210 12:31:27.365123 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:31:27.365123 10416 solver.cpp:237]     Train net output #1: loss = 1.75396 (* 1 = 1.75396 loss)
I1210 12:31:27.365123 10416 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1210 12:31:33.039265 10416 solver.cpp:218] Iteration 22600 (17.6254 iter/s, 5.67362s/100 iters), loss = 1.63437
I1210 12:31:33.039265 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:31:33.039265 10416 solver.cpp:237]     Train net output #1: loss = 1.63437 (* 1 = 1.63437 loss)
I1210 12:31:33.039265 10416 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1210 12:31:38.720532 10416 solver.cpp:218] Iteration 22700 (17.6025 iter/s, 5.68103s/100 iters), loss = 1.40397
I1210 12:31:38.720532 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:31:38.720532 10416 solver.cpp:237]     Train net output #1: loss = 1.40397 (* 1 = 1.40397 loss)
I1210 12:31:38.720532 10416 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1210 12:31:44.386838 10416 solver.cpp:218] Iteration 22800 (17.6505 iter/s, 5.66557s/100 iters), loss = 1.80599
I1210 12:31:44.386838 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:31:44.386838 10416 solver.cpp:237]     Train net output #1: loss = 1.80599 (* 1 = 1.80599 loss)
I1210 12:31:44.386838 10416 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1210 12:31:50.051898 10416 solver.cpp:218] Iteration 22900 (17.6544 iter/s, 5.66429s/100 iters), loss = 1.98181
I1210 12:31:50.051898 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:31:50.051898 10416 solver.cpp:237]     Train net output #1: loss = 1.98181 (* 1 = 1.98181 loss)
I1210 12:31:50.051898 10416 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1210 12:31:55.479789  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:31:55.704880 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_23000.caffemodel
I1210 12:31:55.720401 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_23000.solverstate
I1210 12:31:55.724889 10416 solver.cpp:330] Iteration 23000, Testing net (#0)
I1210 12:31:55.724889 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:31:57.107689  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:31:57.160701 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3703
I1210 12:31:57.160701 10416 solver.cpp:397]     Test net output #1: loss = 2.53411 (* 1 = 2.53411 loss)
I1210 12:31:57.217201 10416 solver.cpp:218] Iteration 23000 (13.9566 iter/s, 7.16507s/100 iters), loss = 1.7368
I1210 12:31:57.217201 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:31:57.217201 10416 solver.cpp:237]     Train net output #1: loss = 1.7368 (* 1 = 1.7368 loss)
I1210 12:31:57.217702 10416 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1210 12:32:02.935195 10416 solver.cpp:218] Iteration 23100 (17.4898 iter/s, 5.71762s/100 iters), loss = 1.68038
I1210 12:32:02.935195 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:32:02.935195 10416 solver.cpp:237]     Train net output #1: loss = 1.68038 (* 1 = 1.68038 loss)
I1210 12:32:02.935195 10416 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1210 12:32:08.677333 10416 solver.cpp:218] Iteration 23200 (17.4172 iter/s, 5.74146s/100 iters), loss = 1.39299
I1210 12:32:08.677333 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:32:08.677333 10416 solver.cpp:237]     Train net output #1: loss = 1.39299 (* 1 = 1.39299 loss)
I1210 12:32:08.677333 10416 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1210 12:32:14.397471 10416 solver.cpp:218] Iteration 23300 (17.4837 iter/s, 5.71963s/100 iters), loss = 1.88377
I1210 12:32:14.397471 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:32:14.397471 10416 solver.cpp:237]     Train net output #1: loss = 1.88377 (* 1 = 1.88377 loss)
I1210 12:32:14.397471 10416 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1210 12:32:20.054646 10416 solver.cpp:218] Iteration 23400 (17.6771 iter/s, 5.65703s/100 iters), loss = 1.75524
I1210 12:32:20.054646 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:32:20.054646 10416 solver.cpp:237]     Train net output #1: loss = 1.75524 (* 1 = 1.75524 loss)
I1210 12:32:20.054646 10416 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1210 12:32:25.512308  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:32:25.735851 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_23500.caffemodel
I1210 12:32:25.754354 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_23500.solverstate
I1210 12:32:25.759467 10416 solver.cpp:330] Iteration 23500, Testing net (#0)
I1210 12:32:25.759467 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:32:27.135259  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:32:27.188305 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3796
I1210 12:32:27.188305 10416 solver.cpp:397]     Test net output #1: loss = 2.54737 (* 1 = 2.54737 loss)
I1210 12:32:27.242333 10416 solver.cpp:218] Iteration 23500 (13.9145 iter/s, 7.18677s/100 iters), loss = 1.89174
I1210 12:32:27.242333 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:32:27.242333 10416 solver.cpp:237]     Train net output #1: loss = 1.89174 (* 1 = 1.89174 loss)
I1210 12:32:27.242333 10416 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1210 12:32:32.950366 10416 solver.cpp:218] Iteration 23600 (17.5208 iter/s, 5.70749s/100 iters), loss = 1.71799
I1210 12:32:32.950366 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:32:32.950366 10416 solver.cpp:237]     Train net output #1: loss = 1.71799 (* 1 = 1.71799 loss)
I1210 12:32:32.950366 10416 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1210 12:32:38.632457 10416 solver.cpp:218] Iteration 23700 (17.5993 iter/s, 5.68204s/100 iters), loss = 1.26112
I1210 12:32:38.632457 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 12:32:38.632457 10416 solver.cpp:237]     Train net output #1: loss = 1.26112 (* 1 = 1.26112 loss)
I1210 12:32:38.632457 10416 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1210 12:32:44.311267 10416 solver.cpp:218] Iteration 23800 (17.6106 iter/s, 5.67839s/100 iters), loss = 1.79709
I1210 12:32:44.311267 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:32:44.311267 10416 solver.cpp:237]     Train net output #1: loss = 1.79709 (* 1 = 1.79709 loss)
I1210 12:32:44.311267 10416 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1210 12:32:49.991557 10416 solver.cpp:218] Iteration 23900 (17.6077 iter/s, 5.67934s/100 iters), loss = 1.91998
I1210 12:32:49.991557 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:32:49.991557 10416 solver.cpp:237]     Train net output #1: loss = 1.91998 (* 1 = 1.91998 loss)
I1210 12:32:49.991557 10416 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1210 12:32:55.386752  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:32:55.609989 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_24000.caffemodel
I1210 12:32:55.631002 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_24000.solverstate
I1210 12:32:55.639003 10416 solver.cpp:330] Iteration 24000, Testing net (#0)
I1210 12:32:55.639003 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:32:57.095836  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:32:57.149351 10416 solver.cpp:397]     Test net output #0: accuracy = 0.4121
I1210 12:32:57.149351 10416 solver.cpp:397]     Test net output #1: loss = 2.30834 (* 1 = 2.30834 loss)
I1210 12:32:57.203363 10416 solver.cpp:218] Iteration 24000 (13.8677 iter/s, 7.21101s/100 iters), loss = 1.71668
I1210 12:32:57.203363 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:32:57.203363 10416 solver.cpp:237]     Train net output #1: loss = 1.71668 (* 1 = 1.71668 loss)
I1210 12:32:57.203363 10416 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1210 12:33:02.863423 10416 solver.cpp:218] Iteration 24100 (17.6676 iter/s, 5.66007s/100 iters), loss = 1.75869
I1210 12:33:02.863423 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 12:33:02.863423 10416 solver.cpp:237]     Train net output #1: loss = 1.75869 (* 1 = 1.75869 loss)
I1210 12:33:02.863423 10416 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1210 12:33:08.573868 10416 solver.cpp:218] Iteration 24200 (17.512 iter/s, 5.71036s/100 iters), loss = 1.44381
I1210 12:33:08.573868 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:33:08.573868 10416 solver.cpp:237]     Train net output #1: loss = 1.44381 (* 1 = 1.44381 loss)
I1210 12:33:08.573868 10416 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1210 12:33:14.323308 10416 solver.cpp:218] Iteration 24300 (17.3943 iter/s, 5.74899s/100 iters), loss = 1.90101
I1210 12:33:14.324309 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:33:14.324309 10416 solver.cpp:237]     Train net output #1: loss = 1.90101 (* 1 = 1.90101 loss)
I1210 12:33:14.324309 10416 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1210 12:33:19.997829 10416 solver.cpp:218] Iteration 24400 (17.627 iter/s, 5.67312s/100 iters), loss = 1.805
I1210 12:33:19.997829 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:33:19.997829 10416 solver.cpp:237]     Train net output #1: loss = 1.805 (* 1 = 1.805 loss)
I1210 12:33:19.997829 10416 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1210 12:33:25.410500  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:33:25.631510 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_24500.caffemodel
I1210 12:33:25.646520 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_24500.solverstate
I1210 12:33:25.651523 10416 solver.cpp:330] Iteration 24500, Testing net (#0)
I1210 12:33:25.651523 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:33:27.102470  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:33:27.157487 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3427
I1210 12:33:27.157487 10416 solver.cpp:397]     Test net output #1: loss = 2.79502 (* 1 = 2.79502 loss)
I1210 12:33:27.209491 10416 solver.cpp:218] Iteration 24500 (13.8659 iter/s, 7.21195s/100 iters), loss = 1.73076
I1210 12:33:27.209491 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:33:27.209491 10416 solver.cpp:237]     Train net output #1: loss = 1.73076 (* 1 = 1.73076 loss)
I1210 12:33:27.209491 10416 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1210 12:33:32.897261 10416 solver.cpp:218] Iteration 24600 (17.5833 iter/s, 5.6872s/100 iters), loss = 1.66433
I1210 12:33:32.897261 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:33:32.897261 10416 solver.cpp:237]     Train net output #1: loss = 1.66433 (* 1 = 1.66433 loss)
I1210 12:33:32.897261 10416 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1210 12:33:38.668047 10416 solver.cpp:218] Iteration 24700 (17.3305 iter/s, 5.77019s/100 iters), loss = 1.36062
I1210 12:33:38.668047 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 12:33:38.668047 10416 solver.cpp:237]     Train net output #1: loss = 1.36062 (* 1 = 1.36062 loss)
I1210 12:33:38.668047 10416 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1210 12:33:44.395463 10416 solver.cpp:218] Iteration 24800 (17.4633 iter/s, 5.72628s/100 iters), loss = 1.78231
I1210 12:33:44.395463 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:33:44.395463 10416 solver.cpp:237]     Train net output #1: loss = 1.78231 (* 1 = 1.78231 loss)
I1210 12:33:44.395463 10416 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1210 12:33:50.188393 10416 solver.cpp:218] Iteration 24900 (17.2644 iter/s, 5.79227s/100 iters), loss = 1.84983
I1210 12:33:50.188393 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:33:50.188393 10416 solver.cpp:237]     Train net output #1: loss = 1.84983 (* 1 = 1.84983 loss)
I1210 12:33:50.188393 10416 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1210 12:33:55.648399  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:33:55.873427 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_25000.caffemodel
I1210 12:33:55.894431 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_25000.solverstate
I1210 12:33:55.899435 10416 solver.cpp:330] Iteration 25000, Testing net (#0)
I1210 12:33:55.899435 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:33:57.285527  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:33:57.342532 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3724
I1210 12:33:57.342532 10416 solver.cpp:397]     Test net output #1: loss = 2.50235 (* 1 = 2.50235 loss)
I1210 12:33:57.396549 10416 solver.cpp:218] Iteration 25000 (13.8741 iter/s, 7.20767s/100 iters), loss = 1.68028
I1210 12:33:57.396549 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:33:57.396549 10416 solver.cpp:237]     Train net output #1: loss = 1.68028 (* 1 = 1.68028 loss)
I1210 12:33:57.396549 10416 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1210 12:34:03.110975 10416 solver.cpp:218] Iteration 25100 (17.5011 iter/s, 5.71393s/100 iters), loss = 1.74134
I1210 12:34:03.110975 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 12:34:03.110975 10416 solver.cpp:237]     Train net output #1: loss = 1.74134 (* 1 = 1.74134 loss)
I1210 12:34:03.110975 10416 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1210 12:34:08.828456 10416 solver.cpp:218] Iteration 25200 (17.491 iter/s, 5.71724s/100 iters), loss = 1.37543
I1210 12:34:08.828456 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:34:08.828456 10416 solver.cpp:237]     Train net output #1: loss = 1.37543 (* 1 = 1.37543 loss)
I1210 12:34:08.828456 10416 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1210 12:34:14.565874 10416 solver.cpp:218] Iteration 25300 (17.4305 iter/s, 5.73707s/100 iters), loss = 1.80676
I1210 12:34:14.565874 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:34:14.565874 10416 solver.cpp:237]     Train net output #1: loss = 1.80676 (* 1 = 1.80676 loss)
I1210 12:34:14.565874 10416 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1210 12:34:20.281369 10416 solver.cpp:218] Iteration 25400 (17.4981 iter/s, 5.71492s/100 iters), loss = 1.82091
I1210 12:34:20.281857 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:34:20.281857 10416 solver.cpp:237]     Train net output #1: loss = 1.82091 (* 1 = 1.82091 loss)
I1210 12:34:20.281857 10416 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1210 12:34:25.716758  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:34:25.941773 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_25500.caffemodel
I1210 12:34:25.961773 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_25500.solverstate
I1210 12:34:25.966774 10416 solver.cpp:330] Iteration 25500, Testing net (#0)
I1210 12:34:25.966774 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:34:27.355867  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:34:27.409874 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3041
I1210 12:34:27.409874 10416 solver.cpp:397]     Test net output #1: loss = 3.18127 (* 1 = 3.18127 loss)
I1210 12:34:27.463873 10416 solver.cpp:218] Iteration 25500 (13.9239 iter/s, 7.18188s/100 iters), loss = 1.79336
I1210 12:34:27.463873 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:34:27.463873 10416 solver.cpp:237]     Train net output #1: loss = 1.79336 (* 1 = 1.79336 loss)
I1210 12:34:27.463873 10416 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1210 12:34:33.182281 10416 solver.cpp:218] Iteration 25600 (17.4894 iter/s, 5.71775s/100 iters), loss = 1.66274
I1210 12:34:33.182281 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:34:33.182281 10416 solver.cpp:237]     Train net output #1: loss = 1.66274 (* 1 = 1.66274 loss)
I1210 12:34:33.182281 10416 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1210 12:34:38.896661 10416 solver.cpp:218] Iteration 25700 (17.5011 iter/s, 5.71392s/100 iters), loss = 1.4376
I1210 12:34:38.896661 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:34:38.896661 10416 solver.cpp:237]     Train net output #1: loss = 1.4376 (* 1 = 1.4376 loss)
I1210 12:34:38.896661 10416 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1210 12:34:44.656201 10416 solver.cpp:218] Iteration 25800 (17.3635 iter/s, 5.75922s/100 iters), loss = 1.79871
I1210 12:34:44.656201 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:34:44.656201 10416 solver.cpp:237]     Train net output #1: loss = 1.79871 (* 1 = 1.79871 loss)
I1210 12:34:44.656201 10416 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1210 12:34:50.327666 10416 solver.cpp:218] Iteration 25900 (17.6347 iter/s, 5.67065s/100 iters), loss = 1.82356
I1210 12:34:50.327666 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:34:50.327666 10416 solver.cpp:237]     Train net output #1: loss = 1.82356 (* 1 = 1.82356 loss)
I1210 12:34:50.327666 10416 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1210 12:34:55.740340  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:34:55.964349 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_26000.caffemodel
I1210 12:34:55.982852 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_26000.solverstate
I1210 12:34:55.987854 10416 solver.cpp:330] Iteration 26000, Testing net (#0)
I1210 12:34:55.987854 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:34:57.364862  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:34:57.419867 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3145
I1210 12:34:57.419867 10416 solver.cpp:397]     Test net output #1: loss = 2.93415 (* 1 = 2.93415 loss)
I1210 12:34:57.473867 10416 solver.cpp:218] Iteration 26000 (13.9933 iter/s, 7.14627s/100 iters), loss = 1.78755
I1210 12:34:57.473867 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:34:57.473867 10416 solver.cpp:237]     Train net output #1: loss = 1.78755 (* 1 = 1.78755 loss)
I1210 12:34:57.473867 10416 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1210 12:35:03.192266 10416 solver.cpp:218] Iteration 26100 (17.4882 iter/s, 5.71813s/100 iters), loss = 1.60968
I1210 12:35:03.193258 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:35:03.193258 10416 solver.cpp:237]     Train net output #1: loss = 1.60968 (* 1 = 1.60968 loss)
I1210 12:35:03.193258 10416 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1210 12:35:09.033742 10416 solver.cpp:218] Iteration 26200 (17.1207 iter/s, 5.84087s/100 iters), loss = 1.38215
I1210 12:35:09.033742 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:35:09.033742 10416 solver.cpp:237]     Train net output #1: loss = 1.38215 (* 1 = 1.38215 loss)
I1210 12:35:09.033742 10416 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1210 12:35:14.798173 10416 solver.cpp:218] Iteration 26300 (17.3501 iter/s, 5.76364s/100 iters), loss = 1.96243
I1210 12:35:14.799173 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:35:14.799173 10416 solver.cpp:237]     Train net output #1: loss = 1.96243 (* 1 = 1.96243 loss)
I1210 12:35:14.799173 10416 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1210 12:35:20.601523 10416 solver.cpp:218] Iteration 26400 (17.2357 iter/s, 5.8019s/100 iters), loss = 1.86112
I1210 12:35:20.601523 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:35:20.601523 10416 solver.cpp:237]     Train net output #1: loss = 1.86112 (* 1 = 1.86112 loss)
I1210 12:35:20.601523 10416 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1210 12:35:26.152222  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:35:26.391739 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_26500.caffemodel
I1210 12:35:26.406245 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_26500.solverstate
I1210 12:35:26.411243 10416 solver.cpp:330] Iteration 26500, Testing net (#0)
I1210 12:35:26.411243 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:35:27.803355  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:35:27.858355 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3262
I1210 12:35:27.858355 10416 solver.cpp:397]     Test net output #1: loss = 3.0367 (* 1 = 3.0367 loss)
I1210 12:35:27.912362 10416 solver.cpp:218] Iteration 26500 (13.6786 iter/s, 7.31071s/100 iters), loss = 1.62068
I1210 12:35:27.912362 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:35:27.912362 10416 solver.cpp:237]     Train net output #1: loss = 1.62068 (* 1 = 1.62068 loss)
I1210 12:35:27.912362 10416 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1210 12:35:33.633790 10416 solver.cpp:218] Iteration 26600 (17.4799 iter/s, 5.72086s/100 iters), loss = 1.64318
I1210 12:35:33.633790 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:35:33.633790 10416 solver.cpp:237]     Train net output #1: loss = 1.64318 (* 1 = 1.64318 loss)
I1210 12:35:33.633790 10416 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1210 12:35:39.327080 10416 solver.cpp:218] Iteration 26700 (17.5667 iter/s, 5.6926s/100 iters), loss = 1.40381
I1210 12:35:39.327080 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:35:39.327080 10416 solver.cpp:237]     Train net output #1: loss = 1.40381 (* 1 = 1.40381 loss)
I1210 12:35:39.327080 10416 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1210 12:35:45.097545 10416 solver.cpp:218] Iteration 26800 (17.3297 iter/s, 5.77043s/100 iters), loss = 1.82701
I1210 12:35:45.097545 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:35:45.097545 10416 solver.cpp:237]     Train net output #1: loss = 1.82701 (* 1 = 1.82701 loss)
I1210 12:35:45.097545 10416 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1210 12:35:50.883882 10416 solver.cpp:218] Iteration 26900 (17.2841 iter/s, 5.78565s/100 iters), loss = 1.77974
I1210 12:35:50.883882 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:35:50.883882 10416 solver.cpp:237]     Train net output #1: loss = 1.77974 (* 1 = 1.77974 loss)
I1210 12:35:50.883882 10416 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1210 12:35:56.335099  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:35:56.565620 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_27000.caffemodel
I1210 12:35:56.588621 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_27000.solverstate
I1210 12:35:56.597622 10416 solver.cpp:330] Iteration 27000, Testing net (#0)
I1210 12:35:56.597622 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:35:58.028818  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:35:58.083822 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3546
I1210 12:35:58.083822 10416 solver.cpp:397]     Test net output #1: loss = 2.70949 (* 1 = 2.70949 loss)
I1210 12:35:58.137498 10416 solver.cpp:218] Iteration 27000 (13.7875 iter/s, 7.25297s/100 iters), loss = 1.76253
I1210 12:35:58.137498 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:35:58.137498 10416 solver.cpp:237]     Train net output #1: loss = 1.76253 (* 1 = 1.76253 loss)
I1210 12:35:58.137498 10416 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1210 12:36:03.877565 10416 solver.cpp:218] Iteration 27100 (17.4239 iter/s, 5.73924s/100 iters), loss = 1.54346
I1210 12:36:03.877565 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:36:03.877565 10416 solver.cpp:237]     Train net output #1: loss = 1.54346 (* 1 = 1.54346 loss)
I1210 12:36:03.877565 10416 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1210 12:36:09.600922 10416 solver.cpp:218] Iteration 27200 (17.4719 iter/s, 5.72347s/100 iters), loss = 1.55181
I1210 12:36:09.600922 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:36:09.600922 10416 solver.cpp:237]     Train net output #1: loss = 1.55181 (* 1 = 1.55181 loss)
I1210 12:36:09.600922 10416 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1210 12:36:15.401484 10416 solver.cpp:218] Iteration 27300 (17.2421 iter/s, 5.79976s/100 iters), loss = 1.65866
I1210 12:36:15.401484 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:36:15.401484 10416 solver.cpp:237]     Train net output #1: loss = 1.65866 (* 1 = 1.65866 loss)
I1210 12:36:15.401484 10416 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1210 12:36:21.145139 10416 solver.cpp:218] Iteration 27400 (17.4107 iter/s, 5.7436s/100 iters), loss = 1.87095
I1210 12:36:21.145139 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:36:21.145139 10416 solver.cpp:237]     Train net output #1: loss = 1.87095 (* 1 = 1.87095 loss)
I1210 12:36:21.145139 10416 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1210 12:36:26.556495  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:36:26.778511 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_27500.caffemodel
I1210 12:36:26.797510 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_27500.solverstate
I1210 12:36:26.802511 10416 solver.cpp:330] Iteration 27500, Testing net (#0)
I1210 12:36:26.802511 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:36:28.182665  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:36:28.236171 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3843
I1210 12:36:28.236171 10416 solver.cpp:397]     Test net output #1: loss = 2.44664 (* 1 = 2.44664 loss)
I1210 12:36:28.289675 10416 solver.cpp:218] Iteration 27500 (13.9987 iter/s, 7.14351s/100 iters), loss = 1.63609
I1210 12:36:28.289675 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:36:28.289675 10416 solver.cpp:237]     Train net output #1: loss = 1.63609 (* 1 = 1.63609 loss)
I1210 12:36:28.289675 10416 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1210 12:36:33.984050 10416 solver.cpp:218] Iteration 27600 (17.5605 iter/s, 5.69459s/100 iters), loss = 1.55002
I1210 12:36:33.984050 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:36:33.985051 10416 solver.cpp:237]     Train net output #1: loss = 1.55002 (* 1 = 1.55002 loss)
I1210 12:36:33.985051 10416 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1210 12:36:39.658463 10416 solver.cpp:218] Iteration 27700 (17.6247 iter/s, 5.67386s/100 iters), loss = 1.42085
I1210 12:36:39.658463 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:36:39.658463 10416 solver.cpp:237]     Train net output #1: loss = 1.42085 (* 1 = 1.42085 loss)
I1210 12:36:39.658463 10416 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1210 12:36:45.330454 10416 solver.cpp:218] Iteration 27800 (17.6332 iter/s, 5.67112s/100 iters), loss = 1.77842
I1210 12:36:45.330454 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:36:45.330454 10416 solver.cpp:237]     Train net output #1: loss = 1.77842 (* 1 = 1.77842 loss)
I1210 12:36:45.330454 10416 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1210 12:36:51.001410 10416 solver.cpp:218] Iteration 27900 (17.6337 iter/s, 5.67095s/100 iters), loss = 1.77209
I1210 12:36:51.002411 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:36:51.002411 10416 solver.cpp:237]     Train net output #1: loss = 1.77209 (* 1 = 1.77209 loss)
I1210 12:36:51.002411 10416 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1210 12:36:56.395812  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:36:56.617825 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_28000.caffemodel
I1210 12:36:56.637830 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_28000.solverstate
I1210 12:36:56.641834 10416 solver.cpp:330] Iteration 28000, Testing net (#0)
I1210 12:36:56.641834 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:36:58.016943  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:36:58.071959 10416 solver.cpp:397]     Test net output #0: accuracy = 0.4263
I1210 12:36:58.071959 10416 solver.cpp:397]     Test net output #1: loss = 2.22994 (* 1 = 2.22994 loss)
I1210 12:36:58.127461 10416 solver.cpp:218] Iteration 28000 (14.0356 iter/s, 7.12473s/100 iters), loss = 1.86484
I1210 12:36:58.127461 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:36:58.127461 10416 solver.cpp:237]     Train net output #1: loss = 1.86484 (* 1 = 1.86484 loss)
I1210 12:36:58.127461 10416 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1210 12:37:03.807365 10416 solver.cpp:218] Iteration 28100 (17.6077 iter/s, 5.67935s/100 iters), loss = 1.64603
I1210 12:37:03.807365 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:37:03.807365 10416 solver.cpp:237]     Train net output #1: loss = 1.64603 (* 1 = 1.64603 loss)
I1210 12:37:03.807365 10416 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1210 12:37:09.477787 10416 solver.cpp:218] Iteration 28200 (17.636 iter/s, 5.67021s/100 iters), loss = 1.54503
I1210 12:37:09.477787 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:37:09.477787 10416 solver.cpp:237]     Train net output #1: loss = 1.54503 (* 1 = 1.54503 loss)
I1210 12:37:09.477787 10416 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1210 12:37:15.142979 10416 solver.cpp:218] Iteration 28300 (17.6527 iter/s, 5.66485s/100 iters), loss = 1.78646
I1210 12:37:15.142979 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:37:15.142979 10416 solver.cpp:237]     Train net output #1: loss = 1.78646 (* 1 = 1.78646 loss)
I1210 12:37:15.142979 10416 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1210 12:37:20.812613 10416 solver.cpp:218] Iteration 28400 (17.6396 iter/s, 5.66905s/100 iters), loss = 1.67542
I1210 12:37:20.812613 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:37:20.812613 10416 solver.cpp:237]     Train net output #1: loss = 1.67542 (* 1 = 1.67542 loss)
I1210 12:37:20.812613 10416 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1210 12:37:26.203030  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:37:26.426090 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_28500.caffemodel
I1210 12:37:26.441082 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_28500.solverstate
I1210 12:37:26.446082 10416 solver.cpp:330] Iteration 28500, Testing net (#0)
I1210 12:37:26.446082 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:37:27.823753  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:37:27.877792 10416 solver.cpp:397]     Test net output #0: accuracy = 0.306
I1210 12:37:27.877792 10416 solver.cpp:397]     Test net output #1: loss = 3.0329 (* 1 = 3.0329 loss)
I1210 12:37:27.930796 10416 solver.cpp:218] Iteration 28500 (14.0498 iter/s, 7.11754s/100 iters), loss = 1.60341
I1210 12:37:27.930796 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:37:27.930796 10416 solver.cpp:237]     Train net output #1: loss = 1.60341 (* 1 = 1.60341 loss)
I1210 12:37:27.930796 10416 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1210 12:37:33.581982 10416 solver.cpp:218] Iteration 28600 (17.6966 iter/s, 5.65081s/100 iters), loss = 1.63988
I1210 12:37:33.581982 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:37:33.581982 10416 solver.cpp:237]     Train net output #1: loss = 1.63988 (* 1 = 1.63988 loss)
I1210 12:37:33.581982 10416 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1210 12:37:39.234426 10416 solver.cpp:218] Iteration 28700 (17.6908 iter/s, 5.65266s/100 iters), loss = 1.32665
I1210 12:37:39.234426 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 12:37:39.234426 10416 solver.cpp:237]     Train net output #1: loss = 1.32665 (* 1 = 1.32665 loss)
I1210 12:37:39.234426 10416 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1210 12:37:44.890107 10416 solver.cpp:218] Iteration 28800 (17.683 iter/s, 5.65516s/100 iters), loss = 1.66025
I1210 12:37:44.890107 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:37:44.890107 10416 solver.cpp:237]     Train net output #1: loss = 1.66025 (* 1 = 1.66025 loss)
I1210 12:37:44.890107 10416 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1210 12:37:50.540591 10416 solver.cpp:218] Iteration 28900 (17.7005 iter/s, 5.64955s/100 iters), loss = 1.71176
I1210 12:37:50.540591 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:37:50.540591 10416 solver.cpp:237]     Train net output #1: loss = 1.71176 (* 1 = 1.71176 loss)
I1210 12:37:50.540591 10416 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1210 12:37:55.911967  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:37:56.133980 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_29000.caffemodel
I1210 12:37:56.155983 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_29000.solverstate
I1210 12:37:56.160984 10416 solver.cpp:330] Iteration 29000, Testing net (#0)
I1210 12:37:56.160984 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:37:57.541108  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:37:57.594113 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2983
I1210 12:37:57.594113 10416 solver.cpp:397]     Test net output #1: loss = 3.1753 (* 1 = 3.1753 loss)
I1210 12:37:57.647615 10416 solver.cpp:218] Iteration 29000 (14.0713 iter/s, 7.10664s/100 iters), loss = 1.64078
I1210 12:37:57.648116 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:37:57.648116 10416 solver.cpp:237]     Train net output #1: loss = 1.64078 (* 1 = 1.64078 loss)
I1210 12:37:57.648116 10416 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1210 12:38:03.310521 10416 solver.cpp:218] Iteration 29100 (17.6608 iter/s, 5.66225s/100 iters), loss = 1.5263
I1210 12:38:03.310521 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:38:03.310521 10416 solver.cpp:237]     Train net output #1: loss = 1.5263 (* 1 = 1.5263 loss)
I1210 12:38:03.310521 10416 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1210 12:38:08.967914 10416 solver.cpp:218] Iteration 29200 (17.6752 iter/s, 5.65765s/100 iters), loss = 1.39832
I1210 12:38:08.967914 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:38:08.967914 10416 solver.cpp:237]     Train net output #1: loss = 1.39832 (* 1 = 1.39832 loss)
I1210 12:38:08.967914 10416 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1210 12:38:14.632385 10416 solver.cpp:218] Iteration 29300 (17.6573 iter/s, 5.66337s/100 iters), loss = 1.80176
I1210 12:38:14.632385 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:38:14.632385 10416 solver.cpp:237]     Train net output #1: loss = 1.80176 (* 1 = 1.80176 loss)
I1210 12:38:14.632385 10416 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1210 12:38:20.293777 10416 solver.cpp:218] Iteration 29400 (17.6654 iter/s, 5.66079s/100 iters), loss = 1.87883
I1210 12:38:20.293777 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:38:20.293777 10416 solver.cpp:237]     Train net output #1: loss = 1.87883 (* 1 = 1.87883 loss)
I1210 12:38:20.293777 10416 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1210 12:38:25.676172  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:38:25.897184 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_29500.caffemodel
I1210 12:38:25.912184 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_29500.solverstate
I1210 12:38:25.916184 10416 solver.cpp:330] Iteration 29500, Testing net (#0)
I1210 12:38:25.917186 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:38:27.295308  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:38:27.350312 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3234
I1210 12:38:27.350312 10416 solver.cpp:397]     Test net output #1: loss = 2.8542 (* 1 = 2.8542 loss)
I1210 12:38:27.404330 10416 solver.cpp:218] Iteration 29500 (14.064 iter/s, 7.11033s/100 iters), loss = 1.66442
I1210 12:38:27.404330 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:38:27.404330 10416 solver.cpp:237]     Train net output #1: loss = 1.66442 (* 1 = 1.66442 loss)
I1210 12:38:27.404330 10416 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1210 12:38:33.060694 10416 solver.cpp:218] Iteration 29600 (17.6819 iter/s, 5.6555s/100 iters), loss = 1.74898
I1210 12:38:33.060694 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:38:33.060694 10416 solver.cpp:237]     Train net output #1: loss = 1.74898 (* 1 = 1.74898 loss)
I1210 12:38:33.060694 10416 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1210 12:38:38.703071 10416 solver.cpp:218] Iteration 29700 (17.7233 iter/s, 5.64228s/100 iters), loss = 1.37239
I1210 12:38:38.703071 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 12:38:38.703071 10416 solver.cpp:237]     Train net output #1: loss = 1.37239 (* 1 = 1.37239 loss)
I1210 12:38:38.703071 10416 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1210 12:38:44.354955 10416 solver.cpp:218] Iteration 29800 (17.6947 iter/s, 5.65142s/100 iters), loss = 1.82845
I1210 12:38:44.354955 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:38:44.354955 10416 solver.cpp:237]     Train net output #1: loss = 1.82845 (* 1 = 1.82845 loss)
I1210 12:38:44.354955 10416 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1210 12:38:50.001929 10416 solver.cpp:218] Iteration 29900 (17.7081 iter/s, 5.64713s/100 iters), loss = 1.77234
I1210 12:38:50.002929 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:38:50.002929 10416 solver.cpp:237]     Train net output #1: loss = 1.77234 (* 1 = 1.77234 loss)
I1210 12:38:50.002929 10416 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1210 12:38:55.373381  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:38:55.594406 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_30000.caffemodel
I1210 12:38:55.609407 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_30000.solverstate
I1210 12:38:55.614408 10416 solver.cpp:330] Iteration 30000, Testing net (#0)
I1210 12:38:55.614408 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:38:56.989506  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:38:57.045516 10416 solver.cpp:397]     Test net output #0: accuracy = 0.307
I1210 12:38:57.045516 10416 solver.cpp:397]     Test net output #1: loss = 2.97999 (* 1 = 2.97999 loss)
I1210 12:38:57.099512 10416 solver.cpp:218] Iteration 30000 (14.0921 iter/s, 7.09619s/100 iters), loss = 1.69071
I1210 12:38:57.099512 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:38:57.099512 10416 solver.cpp:237]     Train net output #1: loss = 1.69071 (* 1 = 1.69071 loss)
I1210 12:38:57.099512 10416 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1210 12:39:02.755442 10416 solver.cpp:218] Iteration 30100 (17.6817 iter/s, 5.65555s/100 iters), loss = 1.53312
I1210 12:39:02.755442 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:39:02.755442 10416 solver.cpp:237]     Train net output #1: loss = 1.53312 (* 1 = 1.53312 loss)
I1210 12:39:02.755442 10416 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1210 12:39:08.408426 10416 solver.cpp:218] Iteration 30200 (17.6914 iter/s, 5.65246s/100 iters), loss = 1.35582
I1210 12:39:08.408426 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 12:39:08.408426 10416 solver.cpp:237]     Train net output #1: loss = 1.35582 (* 1 = 1.35582 loss)
I1210 12:39:08.408426 10416 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1210 12:39:14.061852 10416 solver.cpp:218] Iteration 30300 (17.6899 iter/s, 5.65293s/100 iters), loss = 1.91394
I1210 12:39:14.061852 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 12:39:14.061852 10416 solver.cpp:237]     Train net output #1: loss = 1.91394 (* 1 = 1.91394 loss)
I1210 12:39:14.061852 10416 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1210 12:39:19.719213 10416 solver.cpp:218] Iteration 30400 (17.676 iter/s, 5.65738s/100 iters), loss = 1.85031
I1210 12:39:19.719213 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:39:19.719213 10416 solver.cpp:237]     Train net output #1: loss = 1.85031 (* 1 = 1.85031 loss)
I1210 12:39:19.719213 10416 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1210 12:39:25.089622  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:39:25.314635 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_30500.caffemodel
I1210 12:39:25.330636 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_30500.solverstate
I1210 12:39:25.335634 10416 solver.cpp:330] Iteration 30500, Testing net (#0)
I1210 12:39:25.335634 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:39:26.714758  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:39:26.768263 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3864
I1210 12:39:26.768263 10416 solver.cpp:397]     Test net output #1: loss = 2.5237 (* 1 = 2.5237 loss)
I1210 12:39:26.821768 10416 solver.cpp:218] Iteration 30500 (14.0817 iter/s, 7.1014s/100 iters), loss = 1.63206
I1210 12:39:26.821768 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:39:26.821768 10416 solver.cpp:237]     Train net output #1: loss = 1.63206 (* 1 = 1.63206 loss)
I1210 12:39:26.821768 10416 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1210 12:39:32.501145 10416 solver.cpp:218] Iteration 30600 (17.6086 iter/s, 5.67904s/100 iters), loss = 1.57082
I1210 12:39:32.501145 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:39:32.501145 10416 solver.cpp:237]     Train net output #1: loss = 1.57082 (* 1 = 1.57082 loss)
I1210 12:39:32.501145 10416 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1210 12:39:38.181581 10416 solver.cpp:218] Iteration 30700 (17.6045 iter/s, 5.68036s/100 iters), loss = 1.42849
I1210 12:39:38.181581 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 12:39:38.181581 10416 solver.cpp:237]     Train net output #1: loss = 1.42849 (* 1 = 1.42849 loss)
I1210 12:39:38.181581 10416 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1210 12:39:43.849004 10416 solver.cpp:218] Iteration 30800 (17.6455 iter/s, 5.66718s/100 iters), loss = 1.87868
I1210 12:39:43.849004 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:39:43.849004 10416 solver.cpp:237]     Train net output #1: loss = 1.87868 (* 1 = 1.87868 loss)
I1210 12:39:43.849004 10416 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1210 12:39:49.516468 10416 solver.cpp:218] Iteration 30900 (17.6465 iter/s, 5.66686s/100 iters), loss = 1.86547
I1210 12:39:49.516468 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:39:49.516468 10416 solver.cpp:237]     Train net output #1: loss = 1.86547 (* 1 = 1.86547 loss)
I1210 12:39:49.516468 10416 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1210 12:39:54.900066  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:39:55.124095 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_31000.caffemodel
I1210 12:39:55.139096 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_31000.solverstate
I1210 12:39:55.144095 10416 solver.cpp:330] Iteration 31000, Testing net (#0)
I1210 12:39:55.144095 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:39:56.528188  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:39:56.583205 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2882
I1210 12:39:56.583205 10416 solver.cpp:397]     Test net output #1: loss = 3.42463 (* 1 = 3.42463 loss)
I1210 12:39:56.639204 10416 solver.cpp:218] Iteration 31000 (14.0412 iter/s, 7.12188s/100 iters), loss = 1.82993
I1210 12:39:56.639204 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:39:56.639204 10416 solver.cpp:237]     Train net output #1: loss = 1.82993 (* 1 = 1.82993 loss)
I1210 12:39:56.639204 10416 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1210 12:40:02.325747 10416 solver.cpp:218] Iteration 31100 (17.5852 iter/s, 5.68661s/100 iters), loss = 1.67899
I1210 12:40:02.325747 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:40:02.325747 10416 solver.cpp:237]     Train net output #1: loss = 1.67899 (* 1 = 1.67899 loss)
I1210 12:40:02.325747 10416 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1210 12:40:07.999145 10416 solver.cpp:218] Iteration 31200 (17.6289 iter/s, 5.6725s/100 iters), loss = 1.33586
I1210 12:40:07.999145 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 12:40:07.999145 10416 solver.cpp:237]     Train net output #1: loss = 1.33586 (* 1 = 1.33586 loss)
I1210 12:40:07.999145 10416 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1210 12:40:13.672140 10416 solver.cpp:218] Iteration 31300 (17.6279 iter/s, 5.67283s/100 iters), loss = 1.8718
I1210 12:40:13.672140 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:40:13.672140 10416 solver.cpp:237]     Train net output #1: loss = 1.8718 (* 1 = 1.8718 loss)
I1210 12:40:13.672140 10416 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1210 12:40:19.327775 10416 solver.cpp:218] Iteration 31400 (17.6837 iter/s, 5.65493s/100 iters), loss = 1.94695
I1210 12:40:19.327775 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 12:40:19.327775 10416 solver.cpp:237]     Train net output #1: loss = 1.94695 (* 1 = 1.94695 loss)
I1210 12:40:19.327775 10416 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1210 12:40:24.709041  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:40:24.932137 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_31500.caffemodel
I1210 12:40:24.948141 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_31500.solverstate
I1210 12:40:24.952150 10416 solver.cpp:330] Iteration 31500, Testing net (#0)
I1210 12:40:24.952651 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:40:26.330585  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:40:26.383582 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3759
I1210 12:40:26.383582 10416 solver.cpp:397]     Test net output #1: loss = 2.52303 (* 1 = 2.52303 loss)
I1210 12:40:26.437602 10416 solver.cpp:218] Iteration 31500 (14.0658 iter/s, 7.10943s/100 iters), loss = 1.79868
I1210 12:40:26.437602 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:40:26.437602 10416 solver.cpp:237]     Train net output #1: loss = 1.79868 (* 1 = 1.79868 loss)
I1210 12:40:26.437602 10416 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1210 12:40:32.112427 10416 solver.cpp:218] Iteration 31600 (17.6216 iter/s, 5.67486s/100 iters), loss = 1.46298
I1210 12:40:32.112427 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 12:40:32.112427 10416 solver.cpp:237]     Train net output #1: loss = 1.46298 (* 1 = 1.46298 loss)
I1210 12:40:32.112427 10416 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1210 12:40:37.779377 10416 solver.cpp:218] Iteration 31700 (17.6476 iter/s, 5.6665s/100 iters), loss = 1.43316
I1210 12:40:37.779377 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:40:37.779377 10416 solver.cpp:237]     Train net output #1: loss = 1.43316 (* 1 = 1.43316 loss)
I1210 12:40:37.779377 10416 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1210 12:40:43.450289 10416 solver.cpp:218] Iteration 31800 (17.6345 iter/s, 5.67069s/100 iters), loss = 1.80499
I1210 12:40:43.450289 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:40:43.450289 10416 solver.cpp:237]     Train net output #1: loss = 1.80499 (* 1 = 1.80499 loss)
I1210 12:40:43.450289 10416 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1210 12:40:49.119037 10416 solver.cpp:218] Iteration 31900 (17.644 iter/s, 5.66764s/100 iters), loss = 1.67468
I1210 12:40:49.119037 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:40:49.119037 10416 solver.cpp:237]     Train net output #1: loss = 1.67468 (* 1 = 1.67468 loss)
I1210 12:40:49.119037 10416 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1210 12:40:54.504498  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:40:54.727520 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_32000.caffemodel
I1210 12:40:54.745519 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_32000.solverstate
I1210 12:40:54.749519 10416 solver.cpp:330] Iteration 32000, Testing net (#0)
I1210 12:40:54.749519 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:40:56.127092  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:40:56.182116 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3614
I1210 12:40:56.182116 10416 solver.cpp:397]     Test net output #1: loss = 2.66466 (* 1 = 2.66466 loss)
I1210 12:40:56.236109 10416 solver.cpp:218] Iteration 32000 (14.0518 iter/s, 7.11655s/100 iters), loss = 1.68639
I1210 12:40:56.236109 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:40:56.236109 10416 solver.cpp:237]     Train net output #1: loss = 1.68639 (* 1 = 1.68639 loss)
I1210 12:40:56.236109 10416 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1210 12:41:01.884474 10416 solver.cpp:218] Iteration 32100 (17.7055 iter/s, 5.64795s/100 iters), loss = 1.56862
I1210 12:41:01.884474 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:41:01.884474 10416 solver.cpp:237]     Train net output #1: loss = 1.56862 (* 1 = 1.56862 loss)
I1210 12:41:01.884474 10416 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1210 12:41:07.541117 10416 solver.cpp:218] Iteration 32200 (17.679 iter/s, 5.65644s/100 iters), loss = 1.48639
I1210 12:41:07.541117 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:41:07.541117 10416 solver.cpp:237]     Train net output #1: loss = 1.48639 (* 1 = 1.48639 loss)
I1210 12:41:07.541117 10416 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1210 12:41:13.189965 10416 solver.cpp:218] Iteration 32300 (17.704 iter/s, 5.64843s/100 iters), loss = 1.86329
I1210 12:41:13.189965 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:41:13.189965 10416 solver.cpp:237]     Train net output #1: loss = 1.86329 (* 1 = 1.86329 loss)
I1210 12:41:13.189965 10416 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1210 12:41:18.842373 10416 solver.cpp:218] Iteration 32400 (17.6929 iter/s, 5.652s/100 iters), loss = 1.88343
I1210 12:41:18.842373 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:41:18.842373 10416 solver.cpp:237]     Train net output #1: loss = 1.88343 (* 1 = 1.88343 loss)
I1210 12:41:18.842373 10416 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1210 12:41:24.218766  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:41:24.441776 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_32500.caffemodel
I1210 12:41:24.461776 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_32500.solverstate
I1210 12:41:24.466780 10416 solver.cpp:330] Iteration 32500, Testing net (#0)
I1210 12:41:24.466780 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:41:25.844895  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:41:25.898898 10416 solver.cpp:397]     Test net output #0: accuracy = 0.343
I1210 12:41:25.898898 10416 solver.cpp:397]     Test net output #1: loss = 2.80493 (* 1 = 2.80493 loss)
I1210 12:41:25.951898 10416 solver.cpp:218] Iteration 32500 (14.0669 iter/s, 7.1089s/100 iters), loss = 1.6487
I1210 12:41:25.951898 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:41:25.951898 10416 solver.cpp:237]     Train net output #1: loss = 1.6487 (* 1 = 1.6487 loss)
I1210 12:41:25.951898 10416 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1210 12:41:31.612252 10416 solver.cpp:218] Iteration 32600 (17.6659 iter/s, 5.66062s/100 iters), loss = 1.61307
I1210 12:41:31.613255 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:41:31.613255 10416 solver.cpp:237]     Train net output #1: loss = 1.61307 (* 1 = 1.61307 loss)
I1210 12:41:31.613255 10416 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1210 12:41:37.258436 10416 solver.cpp:218] Iteration 32700 (17.7159 iter/s, 5.64465s/100 iters), loss = 1.47844
I1210 12:41:37.258436 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:41:37.258436 10416 solver.cpp:237]     Train net output #1: loss = 1.47844 (* 1 = 1.47844 loss)
I1210 12:41:37.258436 10416 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1210 12:41:42.903312 10416 solver.cpp:218] Iteration 32800 (17.7155 iter/s, 5.64477s/100 iters), loss = 1.79157
I1210 12:41:42.903312 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:41:42.903312 10416 solver.cpp:237]     Train net output #1: loss = 1.79157 (* 1 = 1.79157 loss)
I1210 12:41:42.903312 10416 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1210 12:41:48.567729 10416 solver.cpp:218] Iteration 32900 (17.6542 iter/s, 5.66437s/100 iters), loss = 1.91707
I1210 12:41:48.567729 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:41:48.567729 10416 solver.cpp:237]     Train net output #1: loss = 1.91707 (* 1 = 1.91707 loss)
I1210 12:41:48.567729 10416 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1210 12:41:53.952132  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:41:54.176156 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_33000.caffemodel
I1210 12:41:54.193158 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_33000.solverstate
I1210 12:41:54.198158 10416 solver.cpp:330] Iteration 33000, Testing net (#0)
I1210 12:41:54.198158 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:41:55.580783  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:41:55.633286 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2855
I1210 12:41:55.633286 10416 solver.cpp:397]     Test net output #1: loss = 3.24149 (* 1 = 3.24149 loss)
I1210 12:41:55.687290 10416 solver.cpp:218] Iteration 33000 (14.0476 iter/s, 7.11867s/100 iters), loss = 1.55638
I1210 12:41:55.687290 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:41:55.687290 10416 solver.cpp:237]     Train net output #1: loss = 1.55638 (* 1 = 1.55638 loss)
I1210 12:41:55.687290 10416 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1210 12:42:01.352684 10416 solver.cpp:218] Iteration 33100 (17.6507 iter/s, 5.6655s/100 iters), loss = 1.63208
I1210 12:42:01.352684 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:42:01.352684 10416 solver.cpp:237]     Train net output #1: loss = 1.63208 (* 1 = 1.63208 loss)
I1210 12:42:01.352684 10416 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1210 12:42:07.023058 10416 solver.cpp:218] Iteration 33200 (17.6382 iter/s, 5.66951s/100 iters), loss = 1.43028
I1210 12:42:07.023058 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:42:07.023058 10416 solver.cpp:237]     Train net output #1: loss = 1.43028 (* 1 = 1.43028 loss)
I1210 12:42:07.023058 10416 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1210 12:42:12.692423 10416 solver.cpp:218] Iteration 33300 (17.6414 iter/s, 5.66847s/100 iters), loss = 1.68279
I1210 12:42:12.692423 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:42:12.692423 10416 solver.cpp:237]     Train net output #1: loss = 1.68279 (* 1 = 1.68279 loss)
I1210 12:42:12.692423 10416 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1210 12:42:18.353898 10416 solver.cpp:218] Iteration 33400 (17.6633 iter/s, 5.66145s/100 iters), loss = 1.79529
I1210 12:42:18.353898 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:42:18.353898 10416 solver.cpp:237]     Train net output #1: loss = 1.79529 (* 1 = 1.79529 loss)
I1210 12:42:18.353898 10416 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1210 12:42:23.742308  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:42:23.966318 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_33500.caffemodel
I1210 12:42:23.986824 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_33500.solverstate
I1210 12:42:23.991329 10416 solver.cpp:330] Iteration 33500, Testing net (#0)
I1210 12:42:23.991329 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:42:25.374446  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:42:25.428449 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3996
I1210 12:42:25.428449 10416 solver.cpp:397]     Test net output #1: loss = 2.34884 (* 1 = 2.34884 loss)
I1210 12:42:25.482951 10416 solver.cpp:218] Iteration 33500 (14.0292 iter/s, 7.12801s/100 iters), loss = 1.72565
I1210 12:42:25.482951 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:42:25.482951 10416 solver.cpp:237]     Train net output #1: loss = 1.72565 (* 1 = 1.72565 loss)
I1210 12:42:25.482951 10416 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1210 12:42:31.142901 10416 solver.cpp:218] Iteration 33600 (17.6696 iter/s, 5.65944s/100 iters), loss = 1.66834
I1210 12:42:31.142901 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:42:31.142901 10416 solver.cpp:237]     Train net output #1: loss = 1.66834 (* 1 = 1.66834 loss)
I1210 12:42:31.142901 10416 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1210 12:42:36.795398 10416 solver.cpp:218] Iteration 33700 (17.6918 iter/s, 5.65232s/100 iters), loss = 1.35129
I1210 12:42:36.795398 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:42:36.795398 10416 solver.cpp:237]     Train net output #1: loss = 1.35129 (* 1 = 1.35129 loss)
I1210 12:42:36.795398 10416 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1210 12:42:42.444780 10416 solver.cpp:218] Iteration 33800 (17.703 iter/s, 5.64878s/100 iters), loss = 1.85226
I1210 12:42:42.444780 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 12:42:42.444780 10416 solver.cpp:237]     Train net output #1: loss = 1.85226 (* 1 = 1.85226 loss)
I1210 12:42:42.444780 10416 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1210 12:42:48.103214 10416 solver.cpp:218] Iteration 33900 (17.6745 iter/s, 5.65787s/100 iters), loss = 1.70367
I1210 12:42:48.103214 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:42:48.103214 10416 solver.cpp:237]     Train net output #1: loss = 1.70367 (* 1 = 1.70367 loss)
I1210 12:42:48.103214 10416 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1210 12:42:53.471915  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:42:53.692772 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_34000.caffemodel
I1210 12:42:53.712759 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_34000.solverstate
I1210 12:42:53.717758 10416 solver.cpp:330] Iteration 34000, Testing net (#0)
I1210 12:42:53.717758 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:42:55.094581  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:42:55.150102 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3676
I1210 12:42:55.150102 10416 solver.cpp:397]     Test net output #1: loss = 2.63713 (* 1 = 2.63713 loss)
I1210 12:42:55.204118 10416 solver.cpp:218] Iteration 34000 (14.0836 iter/s, 7.10044s/100 iters), loss = 1.6297
I1210 12:42:55.204118 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:42:55.204118 10416 solver.cpp:237]     Train net output #1: loss = 1.6297 (* 1 = 1.6297 loss)
I1210 12:42:55.204118 10416 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1210 12:43:00.862689 10416 solver.cpp:218] Iteration 34100 (17.6735 iter/s, 5.65817s/100 iters), loss = 1.56359
I1210 12:43:00.862689 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:43:00.862689 10416 solver.cpp:237]     Train net output #1: loss = 1.56359 (* 1 = 1.56359 loss)
I1210 12:43:00.862689 10416 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1210 12:43:06.533102 10416 solver.cpp:218] Iteration 34200 (17.6365 iter/s, 5.67007s/100 iters), loss = 1.50087
I1210 12:43:06.533102 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:43:06.533102 10416 solver.cpp:237]     Train net output #1: loss = 1.50087 (* 1 = 1.50087 loss)
I1210 12:43:06.533622 10416 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1210 12:43:12.196004 10416 solver.cpp:218] Iteration 34300 (17.6591 iter/s, 5.66281s/100 iters), loss = 1.70878
I1210 12:43:12.196004 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:43:12.197000 10416 solver.cpp:237]     Train net output #1: loss = 1.70878 (* 1 = 1.70878 loss)
I1210 12:43:12.197000 10416 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1210 12:43:17.855981 10416 solver.cpp:218] Iteration 34400 (17.6716 iter/s, 5.65879s/100 iters), loss = 1.81535
I1210 12:43:17.855981 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:43:17.855981 10416 solver.cpp:237]     Train net output #1: loss = 1.81535 (* 1 = 1.81535 loss)
I1210 12:43:17.855981 10416 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1210 12:43:23.242463  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:43:23.462976 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_34500.caffemodel
I1210 12:43:23.483976 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_34500.solverstate
I1210 12:43:23.488976 10416 solver.cpp:330] Iteration 34500, Testing net (#0)
I1210 12:43:23.488976 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:43:24.872105  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:43:24.923105 10416 solver.cpp:397]     Test net output #0: accuracy = 0.2598
I1210 12:43:24.923105 10416 solver.cpp:397]     Test net output #1: loss = 3.77008 (* 1 = 3.77008 loss)
I1210 12:43:24.977109 10416 solver.cpp:218] Iteration 34500 (14.0428 iter/s, 7.1211s/100 iters), loss = 1.7894
I1210 12:43:24.977109 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:43:24.977109 10416 solver.cpp:237]     Train net output #1: loss = 1.7894 (* 1 = 1.7894 loss)
I1210 12:43:24.977109 10416 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1210 12:43:30.643512 10416 solver.cpp:218] Iteration 34600 (17.6508 iter/s, 5.66548s/100 iters), loss = 1.62258
I1210 12:43:30.643512 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:43:30.643512 10416 solver.cpp:237]     Train net output #1: loss = 1.62258 (* 1 = 1.62258 loss)
I1210 12:43:30.643512 10416 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1210 12:43:36.308400 10416 solver.cpp:218] Iteration 34700 (17.6533 iter/s, 5.66466s/100 iters), loss = 1.34394
I1210 12:43:36.308400 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:43:36.308400 10416 solver.cpp:237]     Train net output #1: loss = 1.34394 (* 1 = 1.34394 loss)
I1210 12:43:36.308400 10416 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1210 12:43:41.984158 10416 solver.cpp:218] Iteration 34800 (17.622 iter/s, 5.67473s/100 iters), loss = 1.88067
I1210 12:43:41.984158 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:43:41.984158 10416 solver.cpp:237]     Train net output #1: loss = 1.88067 (* 1 = 1.88067 loss)
I1210 12:43:41.984158 10416 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1210 12:43:47.652261 10416 solver.cpp:218] Iteration 34900 (17.6433 iter/s, 5.66789s/100 iters), loss = 1.88302
I1210 12:43:47.652261 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:43:47.652261 10416 solver.cpp:237]     Train net output #1: loss = 1.88302 (* 1 = 1.88302 loss)
I1210 12:43:47.652261 10416 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1210 12:43:53.031651  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:43:53.254717 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_35000.caffemodel
I1210 12:43:53.270717 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_35000.solverstate
I1210 12:43:53.274718 10416 solver.cpp:330] Iteration 35000, Testing net (#0)
I1210 12:43:53.274718 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:43:54.655186  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:43:54.710202 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3877
I1210 12:43:54.710202 10416 solver.cpp:397]     Test net output #1: loss = 2.46047 (* 1 = 2.46047 loss)
I1210 12:43:54.763209 10416 solver.cpp:218] Iteration 35000 (14.0631 iter/s, 7.11083s/100 iters), loss = 1.64143
I1210 12:43:54.763209 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:43:54.763209 10416 solver.cpp:237]     Train net output #1: loss = 1.64143 (* 1 = 1.64143 loss)
I1210 12:43:54.763209 10416 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1210 12:44:00.427228 10416 solver.cpp:218] Iteration 35100 (17.658 iter/s, 5.66316s/100 iters), loss = 1.54377
I1210 12:44:00.427228 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:44:00.427228 10416 solver.cpp:237]     Train net output #1: loss = 1.54377 (* 1 = 1.54377 loss)
I1210 12:44:00.427228 10416 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1210 12:44:06.093201 10416 solver.cpp:218] Iteration 35200 (17.6493 iter/s, 5.66593s/100 iters), loss = 1.45874
I1210 12:44:06.093201 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:44:06.093201 10416 solver.cpp:237]     Train net output #1: loss = 1.45874 (* 1 = 1.45874 loss)
I1210 12:44:06.093201 10416 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1210 12:44:11.758193 10416 solver.cpp:218] Iteration 35300 (17.6554 iter/s, 5.664s/100 iters), loss = 1.83263
I1210 12:44:11.758193 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:44:11.758193 10416 solver.cpp:237]     Train net output #1: loss = 1.83263 (* 1 = 1.83263 loss)
I1210 12:44:11.758193 10416 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1210 12:44:17.435124 10416 solver.cpp:218] Iteration 35400 (17.6174 iter/s, 5.67621s/100 iters), loss = 1.82361
I1210 12:44:17.435124 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:44:17.435124 10416 solver.cpp:237]     Train net output #1: loss = 1.82361 (* 1 = 1.82361 loss)
I1210 12:44:17.435124 10416 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1210 12:44:22.834049  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:44:23.058069 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_35500.caffemodel
I1210 12:44:23.078069 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_35500.solverstate
I1210 12:44:23.083070 10416 solver.cpp:330] Iteration 35500, Testing net (#0)
I1210 12:44:23.083070 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:44:24.461153  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:44:24.515152 10416 solver.cpp:397]     Test net output #0: accuracy = 0.376
I1210 12:44:24.515152 10416 solver.cpp:397]     Test net output #1: loss = 2.5591 (* 1 = 2.5591 loss)
I1210 12:44:24.571159 10416 solver.cpp:218] Iteration 35500 (14.0135 iter/s, 7.13598s/100 iters), loss = 1.59792
I1210 12:44:24.571159 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:44:24.571159 10416 solver.cpp:237]     Train net output #1: loss = 1.59792 (* 1 = 1.59792 loss)
I1210 12:44:24.571159 10416 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1210 12:44:30.219615 10416 solver.cpp:218] Iteration 35600 (17.7041 iter/s, 5.64842s/100 iters), loss = 1.60448
I1210 12:44:30.220616 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:44:30.220616 10416 solver.cpp:237]     Train net output #1: loss = 1.60448 (* 1 = 1.60448 loss)
I1210 12:44:30.220616 10416 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1210 12:44:35.876096 10416 solver.cpp:218] Iteration 35700 (17.6805 iter/s, 5.65596s/100 iters), loss = 1.38547
I1210 12:44:35.877096 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:44:35.877096 10416 solver.cpp:237]     Train net output #1: loss = 1.38547 (* 1 = 1.38547 loss)
I1210 12:44:35.877096 10416 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1210 12:44:41.528607 10416 solver.cpp:218] Iteration 35800 (17.6946 iter/s, 5.65145s/100 iters), loss = 1.74117
I1210 12:44:41.529108 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:44:41.529108 10416 solver.cpp:237]     Train net output #1: loss = 1.74117 (* 1 = 1.74117 loss)
I1210 12:44:41.529108 10416 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1210 12:44:47.177069 10416 solver.cpp:218] Iteration 35900 (17.7042 iter/s, 5.64838s/100 iters), loss = 1.75009
I1210 12:44:47.177069 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:44:47.177069 10416 solver.cpp:237]     Train net output #1: loss = 1.75009 (* 1 = 1.75009 loss)
I1210 12:44:47.177069 10416 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1210 12:44:52.557569  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:44:52.781582 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_36000.caffemodel
I1210 12:44:52.800582 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_36000.solverstate
I1210 12:44:52.805583 10416 solver.cpp:330] Iteration 36000, Testing net (#0)
I1210 12:44:52.805583 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:44:54.187721  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:44:54.242728 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3593
I1210 12:44:54.243729 10416 solver.cpp:397]     Test net output #1: loss = 2.75669 (* 1 = 2.75669 loss)
I1210 12:44:54.296730 10416 solver.cpp:218] Iteration 36000 (14.0477 iter/s, 7.11858s/100 iters), loss = 1.76517
I1210 12:44:54.296730 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:44:54.296730 10416 solver.cpp:237]     Train net output #1: loss = 1.76517 (* 1 = 1.76517 loss)
I1210 12:44:54.296730 10416 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1210 12:44:59.949193 10416 solver.cpp:218] Iteration 36100 (17.6911 iter/s, 5.65255s/100 iters), loss = 1.46362
I1210 12:44:59.949193 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:44:59.949193 10416 solver.cpp:237]     Train net output #1: loss = 1.46362 (* 1 = 1.46362 loss)
I1210 12:44:59.949193 10416 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1210 12:45:05.612656 10416 solver.cpp:218] Iteration 36200 (17.6597 iter/s, 5.6626s/100 iters), loss = 1.39211
I1210 12:45:05.612656 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:45:05.612656 10416 solver.cpp:237]     Train net output #1: loss = 1.39211 (* 1 = 1.39211 loss)
I1210 12:45:05.612656 10416 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1210 12:45:11.271334 10416 solver.cpp:218] Iteration 36300 (17.674 iter/s, 5.65804s/100 iters), loss = 1.85259
I1210 12:45:11.271334 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:45:11.271334 10416 solver.cpp:237]     Train net output #1: loss = 1.85259 (* 1 = 1.85259 loss)
I1210 12:45:11.271334 10416 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1210 12:45:16.941781 10416 solver.cpp:218] Iteration 36400 (17.6365 iter/s, 5.67006s/100 iters), loss = 1.67183
I1210 12:45:16.941781 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:45:16.941781 10416 solver.cpp:237]     Train net output #1: loss = 1.67183 (* 1 = 1.67183 loss)
I1210 12:45:16.941781 10416 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1210 12:45:22.332249  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:45:22.555280 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_36500.caffemodel
I1210 12:45:22.574280 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_36500.solverstate
I1210 12:45:22.579280 10416 solver.cpp:330] Iteration 36500, Testing net (#0)
I1210 12:45:22.579280 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:45:23.958431  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:45:24.011440 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3895
I1210 12:45:24.011440 10416 solver.cpp:397]     Test net output #1: loss = 2.48756 (* 1 = 2.48756 loss)
I1210 12:45:24.065449 10416 solver.cpp:218] Iteration 36500 (14.0389 iter/s, 7.12307s/100 iters), loss = 1.57838
I1210 12:45:24.065449 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:45:24.065449 10416 solver.cpp:237]     Train net output #1: loss = 1.57838 (* 1 = 1.57838 loss)
I1210 12:45:24.065449 10416 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1210 12:45:29.718888 10416 solver.cpp:218] Iteration 36600 (17.6896 iter/s, 5.65304s/100 iters), loss = 1.43125
I1210 12:45:29.718888 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:45:29.718888 10416 solver.cpp:237]     Train net output #1: loss = 1.43125 (* 1 = 1.43125 loss)
I1210 12:45:29.718888 10416 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1210 12:45:35.382776 10416 solver.cpp:218] Iteration 36700 (17.6571 iter/s, 5.66344s/100 iters), loss = 1.30884
I1210 12:45:35.382776 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:45:35.382776 10416 solver.cpp:237]     Train net output #1: loss = 1.30884 (* 1 = 1.30884 loss)
I1210 12:45:35.382776 10416 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1210 12:45:41.049217 10416 solver.cpp:218] Iteration 36800 (17.648 iter/s, 5.66636s/100 iters), loss = 1.74721
I1210 12:45:41.049217 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:45:41.049217 10416 solver.cpp:237]     Train net output #1: loss = 1.74721 (* 1 = 1.74721 loss)
I1210 12:45:41.049217 10416 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1210 12:45:46.705673 10416 solver.cpp:218] Iteration 36900 (17.6822 iter/s, 5.65539s/100 iters), loss = 1.79826
I1210 12:45:46.705673 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:45:46.705673 10416 solver.cpp:237]     Train net output #1: loss = 1.79826 (* 1 = 1.79826 loss)
I1210 12:45:46.705673 10416 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1210 12:45:52.085045  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:45:52.303056 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_37000.caffemodel
I1210 12:45:52.325562 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_37000.solverstate
I1210 12:45:52.333060 10416 solver.cpp:330] Iteration 37000, Testing net (#0)
I1210 12:45:52.333060 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:45:53.707340  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:45:53.761348 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3199
I1210 12:45:53.761348 10416 solver.cpp:397]     Test net output #1: loss = 3.11909 (* 1 = 3.11909 loss)
I1210 12:45:53.814347 10416 solver.cpp:218] Iteration 37000 (14.0672 iter/s, 7.10871s/100 iters), loss = 1.58848
I1210 12:45:53.814347 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 12:45:53.814347 10416 solver.cpp:237]     Train net output #1: loss = 1.58848 (* 1 = 1.58848 loss)
I1210 12:45:53.814347 10416 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1210 12:45:59.482764 10416 solver.cpp:218] Iteration 37100 (17.6448 iter/s, 5.66738s/100 iters), loss = 1.38378
I1210 12:45:59.482764 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:45:59.482764 10416 solver.cpp:237]     Train net output #1: loss = 1.38378 (* 1 = 1.38378 loss)
I1210 12:45:59.482764 10416 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1210 12:46:05.156216 10416 solver.cpp:218] Iteration 37200 (17.627 iter/s, 5.67313s/100 iters), loss = 1.4713
I1210 12:46:05.156216 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:46:05.156216 10416 solver.cpp:237]     Train net output #1: loss = 1.4713 (* 1 = 1.4713 loss)
I1210 12:46:05.156216 10416 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1210 12:46:10.828619 10416 solver.cpp:218] Iteration 37300 (17.6307 iter/s, 5.67191s/100 iters), loss = 1.62238
I1210 12:46:10.828619 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:46:10.828619 10416 solver.cpp:237]     Train net output #1: loss = 1.62238 (* 1 = 1.62238 loss)
I1210 12:46:10.828619 10416 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1210 12:46:16.497068 10416 solver.cpp:218] Iteration 37400 (17.6408 iter/s, 5.66867s/100 iters), loss = 1.76391
I1210 12:46:16.497068 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:46:16.497068 10416 solver.cpp:237]     Train net output #1: loss = 1.76391 (* 1 = 1.76391 loss)
I1210 12:46:16.497068 10416 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1210 12:46:21.887470  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:46:22.110487 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_37500.caffemodel
I1210 12:46:22.129990 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_37500.solverstate
I1210 12:46:22.135490 10416 solver.cpp:330] Iteration 37500, Testing net (#0)
I1210 12:46:22.135490 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:46:23.514580  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:46:23.568584 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3265
I1210 12:46:23.568584 10416 solver.cpp:397]     Test net output #1: loss = 3.02002 (* 1 = 3.02002 loss)
I1210 12:46:23.622586 10416 solver.cpp:218] Iteration 37500 (14.0363 iter/s, 7.12436s/100 iters), loss = 1.55399
I1210 12:46:23.622586 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 12:46:23.622586 10416 solver.cpp:237]     Train net output #1: loss = 1.55399 (* 1 = 1.55399 loss)
I1210 12:46:23.622586 10416 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1210 12:46:29.304020 10416 solver.cpp:218] Iteration 37600 (17.6011 iter/s, 5.68146s/100 iters), loss = 1.5882
I1210 12:46:29.304020 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:46:29.304020 10416 solver.cpp:237]     Train net output #1: loss = 1.5882 (* 1 = 1.5882 loss)
I1210 12:46:29.304020 10416 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1210 12:46:34.985457 10416 solver.cpp:218] Iteration 37700 (17.604 iter/s, 5.68052s/100 iters), loss = 1.42371
I1210 12:46:34.985457 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:46:34.985457 10416 solver.cpp:237]     Train net output #1: loss = 1.42371 (* 1 = 1.42371 loss)
I1210 12:46:34.985457 10416 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1210 12:46:40.661949 10416 solver.cpp:218] Iteration 37800 (17.6171 iter/s, 5.67629s/100 iters), loss = 1.91183
I1210 12:46:40.661949 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:46:40.661949 10416 solver.cpp:237]     Train net output #1: loss = 1.91183 (* 1 = 1.91183 loss)
I1210 12:46:40.661949 10416 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1210 12:46:46.333681 10416 solver.cpp:218] Iteration 37900 (17.6336 iter/s, 5.67098s/100 iters), loss = 1.73932
I1210 12:46:46.333681 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:46:46.333681 10416 solver.cpp:237]     Train net output #1: loss = 1.73932 (* 1 = 1.73932 loss)
I1210 12:46:46.333681 10416 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1210 12:46:51.733844  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:46:51.956359 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_38000.caffemodel
I1210 12:46:51.971359 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_38000.solverstate
I1210 12:46:51.976359 10416 solver.cpp:330] Iteration 38000, Testing net (#0)
I1210 12:46:51.976359 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:46:53.357501  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:46:53.411505 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3462
I1210 12:46:53.412500 10416 solver.cpp:397]     Test net output #1: loss = 2.68438 (* 1 = 2.68438 loss)
I1210 12:46:53.466508 10416 solver.cpp:218] Iteration 38000 (14.0197 iter/s, 7.13285s/100 iters), loss = 1.57346
I1210 12:46:53.466508 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:46:53.466508 10416 solver.cpp:237]     Train net output #1: loss = 1.57346 (* 1 = 1.57346 loss)
I1210 12:46:53.466508 10416 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1210 12:46:59.120005 10416 solver.cpp:218] Iteration 38100 (17.689 iter/s, 5.65324s/100 iters), loss = 1.5429
I1210 12:46:59.121006 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:46:59.121006 10416 solver.cpp:237]     Train net output #1: loss = 1.5429 (* 1 = 1.5429 loss)
I1210 12:46:59.121006 10416 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1210 12:47:04.777446 10416 solver.cpp:218] Iteration 38200 (17.6801 iter/s, 5.65608s/100 iters), loss = 1.4307
I1210 12:47:04.777446 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:47:04.777446 10416 solver.cpp:237]     Train net output #1: loss = 1.4307 (* 1 = 1.4307 loss)
I1210 12:47:04.777446 10416 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1210 12:47:10.440304 10416 solver.cpp:218] Iteration 38300 (17.6594 iter/s, 5.66272s/100 iters), loss = 1.75224
I1210 12:47:10.440304 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:47:10.440304 10416 solver.cpp:237]     Train net output #1: loss = 1.75224 (* 1 = 1.75224 loss)
I1210 12:47:10.440304 10416 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1210 12:47:16.101239 10416 solver.cpp:218] Iteration 38400 (17.6662 iter/s, 5.66051s/100 iters), loss = 1.86627
I1210 12:47:16.101239 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:47:16.101239 10416 solver.cpp:237]     Train net output #1: loss = 1.86627 (* 1 = 1.86627 loss)
I1210 12:47:16.101239 10416 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1210 12:47:21.480656  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:47:21.702668 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_38500.caffemodel
I1210 12:47:21.717667 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_38500.solverstate
I1210 12:47:21.721666 10416 solver.cpp:330] Iteration 38500, Testing net (#0)
I1210 12:47:21.721666 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:47:23.102810  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:47:23.156816 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3497
I1210 12:47:23.156816 10416 solver.cpp:397]     Test net output #1: loss = 2.65765 (* 1 = 2.65765 loss)
I1210 12:47:23.209816 10416 solver.cpp:218] Iteration 38500 (14.0674 iter/s, 7.10862s/100 iters), loss = 1.76829
I1210 12:47:23.210817 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:47:23.210817 10416 solver.cpp:237]     Train net output #1: loss = 1.76829 (* 1 = 1.76829 loss)
I1210 12:47:23.210817 10416 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1210 12:47:28.860273 10416 solver.cpp:218] Iteration 38600 (17.7009 iter/s, 5.64944s/100 iters), loss = 1.58673
I1210 12:47:28.860273 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:47:28.860273 10416 solver.cpp:237]     Train net output #1: loss = 1.58673 (* 1 = 1.58673 loss)
I1210 12:47:28.860273 10416 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1210 12:47:34.518678 10416 solver.cpp:218] Iteration 38700 (17.6726 iter/s, 5.65848s/100 iters), loss = 1.30844
I1210 12:47:34.519678 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:47:34.519678 10416 solver.cpp:237]     Train net output #1: loss = 1.30844 (* 1 = 1.30844 loss)
I1210 12:47:34.519678 10416 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1210 12:47:40.167145 10416 solver.cpp:218] Iteration 38800 (17.7067 iter/s, 5.64757s/100 iters), loss = 1.82315
I1210 12:47:40.167145 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:47:40.167145 10416 solver.cpp:237]     Train net output #1: loss = 1.82315 (* 1 = 1.82315 loss)
I1210 12:47:40.167145 10416 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1210 12:47:45.819572 10416 solver.cpp:218] Iteration 38900 (17.6923 iter/s, 5.65218s/100 iters), loss = 1.86731
I1210 12:47:45.819572 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:47:45.819572 10416 solver.cpp:237]     Train net output #1: loss = 1.86731 (* 1 = 1.86731 loss)
I1210 12:47:45.819572 10416 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1210 12:47:51.203058  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:47:51.425081 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_39000.caffemodel
I1210 12:47:51.440588 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_39000.solverstate
I1210 12:47:51.445092 10416 solver.cpp:330] Iteration 39000, Testing net (#0)
I1210 12:47:51.445092 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:47:52.826203  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:47:52.880209 10416 solver.cpp:397]     Test net output #0: accuracy = 0.365
I1210 12:47:52.880209 10416 solver.cpp:397]     Test net output #1: loss = 2.51278 (* 1 = 2.51278 loss)
I1210 12:47:52.935211 10416 solver.cpp:218] Iteration 39000 (14.0552 iter/s, 7.11482s/100 iters), loss = 1.63966
I1210 12:47:52.935211 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:47:52.935712 10416 solver.cpp:237]     Train net output #1: loss = 1.63966 (* 1 = 1.63966 loss)
I1210 12:47:52.935712 10416 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1210 12:47:58.606673 10416 solver.cpp:218] Iteration 39100 (17.6329 iter/s, 5.67123s/100 iters), loss = 1.45913
I1210 12:47:58.606673 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:47:58.606673 10416 solver.cpp:237]     Train net output #1: loss = 1.45913 (* 1 = 1.45913 loss)
I1210 12:47:58.606673 10416 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1210 12:48:04.278097 10416 solver.cpp:218] Iteration 39200 (17.6351 iter/s, 5.67052s/100 iters), loss = 1.38097
I1210 12:48:04.278097 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:48:04.278097 10416 solver.cpp:237]     Train net output #1: loss = 1.38097 (* 1 = 1.38097 loss)
I1210 12:48:04.278097 10416 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1210 12:48:09.947512 10416 solver.cpp:218] Iteration 39300 (17.6391 iter/s, 5.66922s/100 iters), loss = 1.79082
I1210 12:48:09.947512 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:48:09.947512 10416 solver.cpp:237]     Train net output #1: loss = 1.79082 (* 1 = 1.79082 loss)
I1210 12:48:09.947512 10416 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1210 12:48:15.615907 10416 solver.cpp:218] Iteration 39400 (17.6436 iter/s, 5.66777s/100 iters), loss = 1.84239
I1210 12:48:15.615907 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:48:15.615907 10416 solver.cpp:237]     Train net output #1: loss = 1.84239 (* 1 = 1.84239 loss)
I1210 12:48:15.615907 10416 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1210 12:48:21.017302  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:48:21.240820 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_39500.caffemodel
I1210 12:48:21.258323 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_39500.solverstate
I1210 12:48:21.263324 10416 solver.cpp:330] Iteration 39500, Testing net (#0)
I1210 12:48:21.263324 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:48:22.643898  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:48:22.697399 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3755
I1210 12:48:22.697399 10416 solver.cpp:397]     Test net output #1: loss = 2.55657 (* 1 = 2.55657 loss)
I1210 12:48:22.752404 10416 solver.cpp:218] Iteration 39500 (14.0122 iter/s, 7.13664s/100 iters), loss = 1.68056
I1210 12:48:22.752404 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:48:22.752404 10416 solver.cpp:237]     Train net output #1: loss = 1.68056 (* 1 = 1.68056 loss)
I1210 12:48:22.752404 10416 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1210 12:48:28.396806 10416 solver.cpp:218] Iteration 39600 (17.719 iter/s, 5.64367s/100 iters), loss = 1.52518
I1210 12:48:28.396806 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:48:28.396806 10416 solver.cpp:237]     Train net output #1: loss = 1.52518 (* 1 = 1.52518 loss)
I1210 12:48:28.396806 10416 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1210 12:48:34.053190 10416 solver.cpp:218] Iteration 39700 (17.6813 iter/s, 5.65568s/100 iters), loss = 1.43108
I1210 12:48:34.053190 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 12:48:34.053190 10416 solver.cpp:237]     Train net output #1: loss = 1.43108 (* 1 = 1.43108 loss)
I1210 12:48:34.053190 10416 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1210 12:48:39.702625 10416 solver.cpp:218] Iteration 39800 (17.7031 iter/s, 5.64874s/100 iters), loss = 1.71251
I1210 12:48:39.702625 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:48:39.702625 10416 solver.cpp:237]     Train net output #1: loss = 1.71251 (* 1 = 1.71251 loss)
I1210 12:48:39.702625 10416 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1210 12:48:45.356014 10416 solver.cpp:218] Iteration 39900 (17.6881 iter/s, 5.65351s/100 iters), loss = 1.69809
I1210 12:48:45.356014 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:48:45.356014 10416 solver.cpp:237]     Train net output #1: loss = 1.69809 (* 1 = 1.69809 loss)
I1210 12:48:45.356014 10416 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1210 12:48:50.738082  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:48:50.960598 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_40000.caffemodel
I1210 12:48:50.975599 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_40000.solverstate
I1210 12:48:50.979598 10416 solver.cpp:330] Iteration 40000, Testing net (#0)
I1210 12:48:50.979598 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:48:52.359683  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:48:52.413683 10416 solver.cpp:397]     Test net output #0: accuracy = 0.317
I1210 12:48:52.413683 10416 solver.cpp:397]     Test net output #1: loss = 3.09977 (* 1 = 3.09977 loss)
I1210 12:48:52.467703 10416 solver.cpp:218] Iteration 40000 (14.0629 iter/s, 7.11093s/100 iters), loss = 1.62736
I1210 12:48:52.467703 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:48:52.467703 10416 solver.cpp:237]     Train net output #1: loss = 1.62736 (* 1 = 1.62736 loss)
I1210 12:48:52.467703 10416 sgd_solver.cpp:105] Iteration 40000, lr = 0.1
I1210 12:48:58.116163 10416 solver.cpp:218] Iteration 40100 (17.7041 iter/s, 5.64842s/100 iters), loss = 1.50125
I1210 12:48:58.116163 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:48:58.116163 10416 solver.cpp:237]     Train net output #1: loss = 1.50125 (* 1 = 1.50125 loss)
I1210 12:48:58.116163 10416 sgd_solver.cpp:105] Iteration 40100, lr = 0.1
I1210 12:49:03.775598 10416 solver.cpp:218] Iteration 40200 (17.672 iter/s, 5.65866s/100 iters), loss = 1.30424
I1210 12:49:03.775598 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 12:49:03.775598 10416 solver.cpp:237]     Train net output #1: loss = 1.30424 (* 1 = 1.30424 loss)
I1210 12:49:03.775598 10416 sgd_solver.cpp:105] Iteration 40200, lr = 0.1
I1210 12:49:09.427059 10416 solver.cpp:218] Iteration 40300 (17.6959 iter/s, 5.65104s/100 iters), loss = 1.78441
I1210 12:49:09.427059 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:49:09.427059 10416 solver.cpp:237]     Train net output #1: loss = 1.78441 (* 1 = 1.78441 loss)
I1210 12:49:09.427059 10416 sgd_solver.cpp:105] Iteration 40300, lr = 0.1
I1210 12:49:15.078464 10416 solver.cpp:218] Iteration 40400 (17.6958 iter/s, 5.65104s/100 iters), loss = 1.93319
I1210 12:49:15.078464 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:49:15.078464 10416 solver.cpp:237]     Train net output #1: loss = 1.93319 (* 1 = 1.93319 loss)
I1210 12:49:15.078464 10416 sgd_solver.cpp:105] Iteration 40400, lr = 0.1
I1210 12:49:20.450382  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:49:20.672897 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_40500.caffemodel
I1210 12:49:20.692898 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_40500.solverstate
I1210 12:49:20.697897 10416 solver.cpp:330] Iteration 40500, Testing net (#0)
I1210 12:49:20.697897 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:49:22.080018  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:49:22.134019 10416 solver.cpp:397]     Test net output #0: accuracy = 0.4108
I1210 12:49:22.134019 10416 solver.cpp:397]     Test net output #1: loss = 2.32941 (* 1 = 2.32941 loss)
I1210 12:49:22.187034 10416 solver.cpp:218] Iteration 40500 (14.0677 iter/s, 7.10846s/100 iters), loss = 1.61419
I1210 12:49:22.188035 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:49:22.188035 10416 solver.cpp:237]     Train net output #1: loss = 1.61419 (* 1 = 1.61419 loss)
I1210 12:49:22.188035 10416 sgd_solver.cpp:105] Iteration 40500, lr = 0.1
I1210 12:49:27.831459 10416 solver.cpp:218] Iteration 40600 (17.7207 iter/s, 5.64312s/100 iters), loss = 1.46536
I1210 12:49:27.831459 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:49:27.831459 10416 solver.cpp:237]     Train net output #1: loss = 1.46536 (* 1 = 1.46536 loss)
I1210 12:49:27.831459 10416 sgd_solver.cpp:105] Iteration 40600, lr = 0.1
I1210 12:49:33.489961 10416 solver.cpp:218] Iteration 40700 (17.6742 iter/s, 5.65796s/100 iters), loss = 1.37355
I1210 12:49:33.489961 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 12:49:33.489961 10416 solver.cpp:237]     Train net output #1: loss = 1.37355 (* 1 = 1.37355 loss)
I1210 12:49:33.489961 10416 sgd_solver.cpp:105] Iteration 40700, lr = 0.1
I1210 12:49:39.139375 10416 solver.cpp:218] Iteration 40800 (17.7024 iter/s, 5.64895s/100 iters), loss = 1.70586
I1210 12:49:39.139375 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:49:39.139375 10416 solver.cpp:237]     Train net output #1: loss = 1.70586 (* 1 = 1.70586 loss)
I1210 12:49:39.139375 10416 sgd_solver.cpp:105] Iteration 40800, lr = 0.1
I1210 12:49:44.789836 10416 solver.cpp:218] Iteration 40900 (17.6986 iter/s, 5.65016s/100 iters), loss = 1.90356
I1210 12:49:44.789836 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:49:44.789836 10416 solver.cpp:237]     Train net output #1: loss = 1.90356 (* 1 = 1.90356 loss)
I1210 12:49:44.789836 10416 sgd_solver.cpp:105] Iteration 40900, lr = 0.1
I1210 12:49:50.157234  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:49:50.378245 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_41000.caffemodel
I1210 12:49:50.397245 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_41000.solverstate
I1210 12:49:50.402246 10416 solver.cpp:330] Iteration 41000, Testing net (#0)
I1210 12:49:50.402246 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:49:51.782354  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:49:51.835355 10416 solver.cpp:397]     Test net output #0: accuracy = 0.416
I1210 12:49:51.835355 10416 solver.cpp:397]     Test net output #1: loss = 2.41529 (* 1 = 2.41529 loss)
I1210 12:49:51.889363 10416 solver.cpp:218] Iteration 41000 (14.0859 iter/s, 7.0993s/100 iters), loss = 1.736
I1210 12:49:51.889363 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:49:51.889363 10416 solver.cpp:237]     Train net output #1: loss = 1.736 (* 1 = 1.736 loss)
I1210 12:49:51.889363 10416 sgd_solver.cpp:105] Iteration 41000, lr = 0.1
I1210 12:49:57.548801 10416 solver.cpp:218] Iteration 41100 (17.673 iter/s, 5.65835s/100 iters), loss = 1.50959
I1210 12:49:57.548801 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:49:57.548801 10416 solver.cpp:237]     Train net output #1: loss = 1.50959 (* 1 = 1.50959 loss)
I1210 12:49:57.548801 10416 sgd_solver.cpp:105] Iteration 41100, lr = 0.1
I1210 12:50:03.215308 10416 solver.cpp:218] Iteration 41200 (17.6479 iter/s, 5.66639s/100 iters), loss = 1.43404
I1210 12:50:03.215308 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:50:03.215308 10416 solver.cpp:237]     Train net output #1: loss = 1.43404 (* 1 = 1.43404 loss)
I1210 12:50:03.215308 10416 sgd_solver.cpp:105] Iteration 41200, lr = 0.1
I1210 12:50:08.880738 10416 solver.cpp:218] Iteration 41300 (17.6507 iter/s, 5.6655s/100 iters), loss = 1.85679
I1210 12:50:08.881723 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:50:08.881723 10416 solver.cpp:237]     Train net output #1: loss = 1.85679 (* 1 = 1.85679 loss)
I1210 12:50:08.881723 10416 sgd_solver.cpp:105] Iteration 41300, lr = 0.1
I1210 12:50:14.538130 10416 solver.cpp:218] Iteration 41400 (17.6781 iter/s, 5.65673s/100 iters), loss = 1.91241
I1210 12:50:14.538130 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:50:14.538130 10416 solver.cpp:237]     Train net output #1: loss = 1.91241 (* 1 = 1.91241 loss)
I1210 12:50:14.538130 10416 sgd_solver.cpp:105] Iteration 41400, lr = 0.1
I1210 12:50:19.920518  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:50:20.142539 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_41500.caffemodel
I1210 12:50:20.158545 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_41500.solverstate
I1210 12:50:20.162545 10416 solver.cpp:330] Iteration 41500, Testing net (#0)
I1210 12:50:20.162545 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:50:21.542147  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:50:21.594650 10416 solver.cpp:397]     Test net output #0: accuracy = 0.4191
I1210 12:50:21.594650 10416 solver.cpp:397]     Test net output #1: loss = 2.31336 (* 1 = 2.31336 loss)
I1210 12:50:21.648663 10416 solver.cpp:218] Iteration 41500 (14.0652 iter/s, 7.10974s/100 iters), loss = 1.62161
I1210 12:50:21.648663 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:50:21.648663 10416 solver.cpp:237]     Train net output #1: loss = 1.62161 (* 1 = 1.62161 loss)
I1210 12:50:21.648663 10416 sgd_solver.cpp:105] Iteration 41500, lr = 0.1
I1210 12:50:27.317126 10416 solver.cpp:218] Iteration 41600 (17.6431 iter/s, 5.66795s/100 iters), loss = 1.52124
I1210 12:50:27.317126 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:50:27.317126 10416 solver.cpp:237]     Train net output #1: loss = 1.52124 (* 1 = 1.52124 loss)
I1210 12:50:27.317126 10416 sgd_solver.cpp:105] Iteration 41600, lr = 0.1
I1210 12:50:32.992627 10416 solver.cpp:218] Iteration 41700 (17.6215 iter/s, 5.67488s/100 iters), loss = 1.26368
I1210 12:50:32.992627 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 12:50:32.992627 10416 solver.cpp:237]     Train net output #1: loss = 1.26368 (* 1 = 1.26368 loss)
I1210 12:50:32.992627 10416 sgd_solver.cpp:105] Iteration 41700, lr = 0.1
I1210 12:50:38.671077 10416 solver.cpp:218] Iteration 41800 (17.6124 iter/s, 5.67781s/100 iters), loss = 1.72434
I1210 12:50:38.671077 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:50:38.671077 10416 solver.cpp:237]     Train net output #1: loss = 1.72434 (* 1 = 1.72434 loss)
I1210 12:50:38.671077 10416 sgd_solver.cpp:105] Iteration 41800, lr = 0.1
I1210 12:50:44.354543 10416 solver.cpp:218] Iteration 41900 (17.5959 iter/s, 5.68316s/100 iters), loss = 1.79834
I1210 12:50:44.354543 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:50:44.354543 10416 solver.cpp:237]     Train net output #1: loss = 1.79834 (* 1 = 1.79834 loss)
I1210 12:50:44.354543 10416 sgd_solver.cpp:105] Iteration 41900, lr = 0.1
I1210 12:50:49.751473  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:50:49.973991 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_42000.caffemodel
I1210 12:50:49.988991 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_42000.solverstate
I1210 12:50:49.992990 10416 solver.cpp:330] Iteration 42000, Testing net (#0)
I1210 12:50:49.992990 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:50:51.376106  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:50:51.429105 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3955
I1210 12:50:51.429105 10416 solver.cpp:397]     Test net output #1: loss = 2.4269 (* 1 = 2.4269 loss)
I1210 12:50:51.482110 10416 solver.cpp:218] Iteration 42000 (14.0296 iter/s, 7.12781s/100 iters), loss = 1.75266
I1210 12:50:51.482110 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:50:51.482110 10416 solver.cpp:237]     Train net output #1: loss = 1.75266 (* 1 = 1.75266 loss)
I1210 12:50:51.482110 10416 sgd_solver.cpp:105] Iteration 42000, lr = 0.1
I1210 12:50:57.139561 10416 solver.cpp:218] Iteration 42100 (17.6772 iter/s, 5.65699s/100 iters), loss = 1.62274
I1210 12:50:57.139561 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:50:57.140563 10416 solver.cpp:237]     Train net output #1: loss = 1.62274 (* 1 = 1.62274 loss)
I1210 12:50:57.140563 10416 sgd_solver.cpp:105] Iteration 42100, lr = 0.1
I1210 12:51:02.780982 10416 solver.cpp:218] Iteration 42200 (17.7288 iter/s, 5.64053s/100 iters), loss = 1.22269
I1210 12:51:02.780982 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 12:51:02.780982 10416 solver.cpp:237]     Train net output #1: loss = 1.22269 (* 1 = 1.22269 loss)
I1210 12:51:02.780982 10416 sgd_solver.cpp:105] Iteration 42200, lr = 0.1
I1210 12:51:08.434382 10416 solver.cpp:218] Iteration 42300 (17.6888 iter/s, 5.65331s/100 iters), loss = 1.75331
I1210 12:51:08.435384 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:51:08.435384 10416 solver.cpp:237]     Train net output #1: loss = 1.75331 (* 1 = 1.75331 loss)
I1210 12:51:08.435384 10416 sgd_solver.cpp:105] Iteration 42300, lr = 0.1
I1210 12:51:14.086807 10416 solver.cpp:218] Iteration 42400 (17.6962 iter/s, 5.65094s/100 iters), loss = 1.721
I1210 12:51:14.086807 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:51:14.086807 10416 solver.cpp:237]     Train net output #1: loss = 1.721 (* 1 = 1.721 loss)
I1210 12:51:14.086807 10416 sgd_solver.cpp:105] Iteration 42400, lr = 0.1
I1210 12:51:19.466187  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:51:19.688196 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_42500.caffemodel
I1210 12:51:19.709197 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_42500.solverstate
I1210 12:51:19.714196 10416 solver.cpp:330] Iteration 42500, Testing net (#0)
I1210 12:51:19.714196 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:51:21.097322  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:51:21.150324 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3464
I1210 12:51:21.150324 10416 solver.cpp:397]     Test net output #1: loss = 2.60735 (* 1 = 2.60735 loss)
I1210 12:51:21.204327 10416 solver.cpp:218] Iteration 42500 (14.0497 iter/s, 7.11759s/100 iters), loss = 1.59734
I1210 12:51:21.204327 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:51:21.204327 10416 solver.cpp:237]     Train net output #1: loss = 1.59734 (* 1 = 1.59734 loss)
I1210 12:51:21.204327 10416 sgd_solver.cpp:105] Iteration 42500, lr = 0.1
I1210 12:51:26.870786 10416 solver.cpp:218] Iteration 42600 (17.6504 iter/s, 5.66561s/100 iters), loss = 1.61245
I1210 12:51:26.870786 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:51:26.870786 10416 solver.cpp:237]     Train net output #1: loss = 1.61245 (* 1 = 1.61245 loss)
I1210 12:51:26.870786 10416 sgd_solver.cpp:105] Iteration 42600, lr = 0.1
I1210 12:51:32.534230 10416 solver.cpp:218] Iteration 42700 (17.6565 iter/s, 5.66363s/100 iters), loss = 1.22132
I1210 12:51:32.535230 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 12:51:32.535230 10416 solver.cpp:237]     Train net output #1: loss = 1.22132 (* 1 = 1.22132 loss)
I1210 12:51:32.535230 10416 sgd_solver.cpp:105] Iteration 42700, lr = 0.1
I1210 12:51:38.194633 10416 solver.cpp:218] Iteration 42800 (17.6691 iter/s, 5.65961s/100 iters), loss = 1.74639
I1210 12:51:38.194633 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:51:38.194633 10416 solver.cpp:237]     Train net output #1: loss = 1.74639 (* 1 = 1.74639 loss)
I1210 12:51:38.194633 10416 sgd_solver.cpp:105] Iteration 42800, lr = 0.1
I1210 12:51:43.852016 10416 solver.cpp:218] Iteration 42900 (17.6789 iter/s, 5.65647s/100 iters), loss = 1.80449
I1210 12:51:43.852016 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:51:43.852016 10416 solver.cpp:237]     Train net output #1: loss = 1.80449 (* 1 = 1.80449 loss)
I1210 12:51:43.852016 10416 sgd_solver.cpp:105] Iteration 42900, lr = 0.1
I1210 12:51:49.238384  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:51:49.464406 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_43000.caffemodel
I1210 12:51:49.483407 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_43000.solverstate
I1210 12:51:49.488406 10416 solver.cpp:330] Iteration 43000, Testing net (#0)
I1210 12:51:49.488406 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:51:50.870509  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:51:50.924510 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3418
I1210 12:51:50.924510 10416 solver.cpp:397]     Test net output #1: loss = 2.74999 (* 1 = 2.74999 loss)
I1210 12:51:50.980515 10416 solver.cpp:218] Iteration 43000 (14.0292 iter/s, 7.128s/100 iters), loss = 1.63322
I1210 12:51:50.980515 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:51:50.980515 10416 solver.cpp:237]     Train net output #1: loss = 1.63322 (* 1 = 1.63322 loss)
I1210 12:51:50.980515 10416 sgd_solver.cpp:105] Iteration 43000, lr = 0.1
I1210 12:51:56.635928 10416 solver.cpp:218] Iteration 43100 (17.6836 iter/s, 5.65495s/100 iters), loss = 1.45918
I1210 12:51:56.635928 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:51:56.635928 10416 solver.cpp:237]     Train net output #1: loss = 1.45918 (* 1 = 1.45918 loss)
I1210 12:51:56.635928 10416 sgd_solver.cpp:105] Iteration 43100, lr = 0.1
I1210 12:52:02.290366 10416 solver.cpp:218] Iteration 43200 (17.6858 iter/s, 5.65424s/100 iters), loss = 1.42254
I1210 12:52:02.290366 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:52:02.290366 10416 solver.cpp:237]     Train net output #1: loss = 1.42254 (* 1 = 1.42254 loss)
I1210 12:52:02.290366 10416 sgd_solver.cpp:105] Iteration 43200, lr = 0.1
I1210 12:52:07.946789 10416 solver.cpp:218] Iteration 43300 (17.679 iter/s, 5.65643s/100 iters), loss = 1.7306
I1210 12:52:07.947795 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:52:07.947795 10416 solver.cpp:237]     Train net output #1: loss = 1.7306 (* 1 = 1.7306 loss)
I1210 12:52:07.947795 10416 sgd_solver.cpp:105] Iteration 43300, lr = 0.1
I1210 12:52:13.608165 10416 solver.cpp:218] Iteration 43400 (17.6654 iter/s, 5.66078s/100 iters), loss = 1.72429
I1210 12:52:13.609164 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:52:13.609164 10416 solver.cpp:237]     Train net output #1: loss = 1.72429 (* 1 = 1.72429 loss)
I1210 12:52:13.609164 10416 sgd_solver.cpp:105] Iteration 43400, lr = 0.1
I1210 12:52:18.984557  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:52:19.205571 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_43500.caffemodel
I1210 12:52:19.220571 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_43500.solverstate
I1210 12:52:19.224570 10416 solver.cpp:330] Iteration 43500, Testing net (#0)
I1210 12:52:19.225571 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:52:20.599653  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:52:20.657156 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3966
I1210 12:52:20.657156 10416 solver.cpp:397]     Test net output #1: loss = 2.445 (* 1 = 2.445 loss)
I1210 12:52:20.710659 10416 solver.cpp:218] Iteration 43500 (14.0814 iter/s, 7.10157s/100 iters), loss = 1.53675
I1210 12:52:20.710659 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:52:20.710659 10416 solver.cpp:237]     Train net output #1: loss = 1.53675 (* 1 = 1.53675 loss)
I1210 12:52:20.710659 10416 sgd_solver.cpp:105] Iteration 43500, lr = 0.1
I1210 12:52:26.375051 10416 solver.cpp:218] Iteration 43600 (17.6552 iter/s, 5.66405s/100 iters), loss = 1.56962
I1210 12:52:26.375051 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:52:26.375051 10416 solver.cpp:237]     Train net output #1: loss = 1.56962 (* 1 = 1.56962 loss)
I1210 12:52:26.375051 10416 sgd_solver.cpp:105] Iteration 43600, lr = 0.1
I1210 12:52:32.044265 10416 solver.cpp:218] Iteration 43700 (17.6397 iter/s, 5.66903s/100 iters), loss = 1.32561
I1210 12:52:32.044265 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:52:32.044265 10416 solver.cpp:237]     Train net output #1: loss = 1.32561 (* 1 = 1.32561 loss)
I1210 12:52:32.044265 10416 sgd_solver.cpp:105] Iteration 43700, lr = 0.1
I1210 12:52:37.711647 10416 solver.cpp:218] Iteration 43800 (17.646 iter/s, 5.66702s/100 iters), loss = 1.76949
I1210 12:52:37.712646 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:52:37.712646 10416 solver.cpp:237]     Train net output #1: loss = 1.76949 (* 1 = 1.76949 loss)
I1210 12:52:37.712646 10416 sgd_solver.cpp:105] Iteration 43800, lr = 0.1
I1210 12:52:43.389025 10416 solver.cpp:218] Iteration 43900 (17.6153 iter/s, 5.67687s/100 iters), loss = 1.95009
I1210 12:52:43.390027 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:52:43.390027 10416 solver.cpp:237]     Train net output #1: loss = 1.95009 (* 1 = 1.95009 loss)
I1210 12:52:43.390027 10416 sgd_solver.cpp:105] Iteration 43900, lr = 0.1
I1210 12:52:48.786375  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:52:49.007385 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_44000.caffemodel
I1210 12:52:49.024389 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_44000.solverstate
I1210 12:52:49.030386 10416 solver.cpp:330] Iteration 44000, Testing net (#0)
I1210 12:52:49.030386 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:52:50.413506  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:52:50.466020 10416 solver.cpp:397]     Test net output #0: accuracy = 0.4038
I1210 12:52:50.466020 10416 solver.cpp:397]     Test net output #1: loss = 2.40345 (* 1 = 2.40345 loss)
I1210 12:52:50.519524 10416 solver.cpp:218] Iteration 44000 (14.0256 iter/s, 7.12983s/100 iters), loss = 1.6724
I1210 12:52:50.519524 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:52:50.519524 10416 solver.cpp:237]     Train net output #1: loss = 1.6724 (* 1 = 1.6724 loss)
I1210 12:52:50.519524 10416 sgd_solver.cpp:105] Iteration 44000, lr = 0.1
I1210 12:52:56.173045 10416 solver.cpp:218] Iteration 44100 (17.689 iter/s, 5.65322s/100 iters), loss = 1.60541
I1210 12:52:56.174046 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:52:56.174046 10416 solver.cpp:237]     Train net output #1: loss = 1.60541 (* 1 = 1.60541 loss)
I1210 12:52:56.174046 10416 sgd_solver.cpp:105] Iteration 44100, lr = 0.1
I1210 12:53:01.820549 10416 solver.cpp:218] Iteration 44200 (17.7094 iter/s, 5.64673s/100 iters), loss = 1.33464
I1210 12:53:01.820549 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:53:01.820549 10416 solver.cpp:237]     Train net output #1: loss = 1.33464 (* 1 = 1.33464 loss)
I1210 12:53:01.820549 10416 sgd_solver.cpp:105] Iteration 44200, lr = 0.1
I1210 12:53:07.467471 10416 solver.cpp:218] Iteration 44300 (17.7114 iter/s, 5.64609s/100 iters), loss = 1.76382
I1210 12:53:07.467471 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:53:07.467471 10416 solver.cpp:237]     Train net output #1: loss = 1.76382 (* 1 = 1.76382 loss)
I1210 12:53:07.467471 10416 sgd_solver.cpp:105] Iteration 44300, lr = 0.1
I1210 12:53:13.124368 10416 solver.cpp:218] Iteration 44400 (17.6777 iter/s, 5.65686s/100 iters), loss = 1.81511
I1210 12:53:13.124368 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:53:13.124368 10416 solver.cpp:237]     Train net output #1: loss = 1.81511 (* 1 = 1.81511 loss)
I1210 12:53:13.124368 10416 sgd_solver.cpp:105] Iteration 44400, lr = 0.1
I1210 12:53:18.503739  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:53:18.726749 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_44500.caffemodel
I1210 12:53:18.741750 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_44500.solverstate
I1210 12:53:18.746750 10416 solver.cpp:330] Iteration 44500, Testing net (#0)
I1210 12:53:18.746750 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:53:20.127868  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:53:20.182878 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3802
I1210 12:53:20.182878 10416 solver.cpp:397]     Test net output #1: loss = 2.60662 (* 1 = 2.60662 loss)
I1210 12:53:20.238878 10416 solver.cpp:218] Iteration 44500 (14.058 iter/s, 7.11338s/100 iters), loss = 1.51928
I1210 12:53:20.238878 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:53:20.238878 10416 solver.cpp:237]     Train net output #1: loss = 1.51928 (* 1 = 1.51928 loss)
I1210 12:53:20.238878 10416 sgd_solver.cpp:105] Iteration 44500, lr = 0.1
I1210 12:53:25.911262 10416 solver.cpp:218] Iteration 44600 (17.6284 iter/s, 5.67268s/100 iters), loss = 1.47412
I1210 12:53:25.911262 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:53:25.911262 10416 solver.cpp:237]     Train net output #1: loss = 1.47412 (* 1 = 1.47412 loss)
I1210 12:53:25.911262 10416 sgd_solver.cpp:105] Iteration 44600, lr = 0.1
I1210 12:53:31.580657 10416 solver.cpp:218] Iteration 44700 (17.6403 iter/s, 5.66883s/100 iters), loss = 1.24915
I1210 12:53:31.580657 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:53:31.580657 10416 solver.cpp:237]     Train net output #1: loss = 1.24915 (* 1 = 1.24915 loss)
I1210 12:53:31.580657 10416 sgd_solver.cpp:105] Iteration 44700, lr = 0.1
I1210 12:53:37.255560 10416 solver.cpp:218] Iteration 44800 (17.6243 iter/s, 5.67398s/100 iters), loss = 1.7439
I1210 12:53:37.255560 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:53:37.255560 10416 solver.cpp:237]     Train net output #1: loss = 1.7439 (* 1 = 1.7439 loss)
I1210 12:53:37.255560 10416 sgd_solver.cpp:105] Iteration 44800, lr = 0.1
I1210 12:53:42.936530 10416 solver.cpp:218] Iteration 44900 (17.6023 iter/s, 5.68107s/100 iters), loss = 1.78891
I1210 12:53:42.936530 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:53:42.936530 10416 solver.cpp:237]     Train net output #1: loss = 1.78891 (* 1 = 1.78891 loss)
I1210 12:53:42.936530 10416 sgd_solver.cpp:105] Iteration 44900, lr = 0.1
I1210 12:53:48.337903  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:53:48.561419 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_45000.caffemodel
I1210 12:53:48.575923 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_45000.solverstate
I1210 12:53:48.580924 10416 solver.cpp:330] Iteration 45000, Testing net (#0)
I1210 12:53:48.580924 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:53:49.962548  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:53:50.015065 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3218
I1210 12:53:50.015065 10416 solver.cpp:397]     Test net output #1: loss = 3.05611 (* 1 = 3.05611 loss)
I1210 12:53:50.070061 10416 solver.cpp:218] Iteration 45000 (14.0198 iter/s, 7.13276s/100 iters), loss = 1.72176
I1210 12:53:50.070562 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:53:50.070562 10416 solver.cpp:237]     Train net output #1: loss = 1.72176 (* 1 = 1.72176 loss)
I1210 12:53:50.070562 10416 sgd_solver.cpp:105] Iteration 45000, lr = 0.1
I1210 12:53:55.749478 10416 solver.cpp:218] Iteration 45100 (17.6094 iter/s, 5.67878s/100 iters), loss = 1.51975
I1210 12:53:55.749478 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:53:55.749979 10416 solver.cpp:237]     Train net output #1: loss = 1.51975 (* 1 = 1.51975 loss)
I1210 12:53:55.749979 10416 sgd_solver.cpp:105] Iteration 45100, lr = 0.1
I1210 12:54:01.423015 10416 solver.cpp:218] Iteration 45200 (17.6273 iter/s, 5.67303s/100 iters), loss = 1.24633
I1210 12:54:01.423015 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 12:54:01.423015 10416 solver.cpp:237]     Train net output #1: loss = 1.24633 (* 1 = 1.24633 loss)
I1210 12:54:01.423015 10416 sgd_solver.cpp:105] Iteration 45200, lr = 0.1
I1210 12:54:07.103480 10416 solver.cpp:218] Iteration 45300 (17.6055 iter/s, 5.68004s/100 iters), loss = 1.78757
I1210 12:54:07.103480 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:54:07.103480 10416 solver.cpp:237]     Train net output #1: loss = 1.78757 (* 1 = 1.78757 loss)
I1210 12:54:07.103480 10416 sgd_solver.cpp:105] Iteration 45300, lr = 0.1
I1210 12:54:12.781919 10416 solver.cpp:218] Iteration 45400 (17.6128 iter/s, 5.6777s/100 iters), loss = 1.80866
I1210 12:54:12.781919 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 12:54:12.781919 10416 solver.cpp:237]     Train net output #1: loss = 1.80866 (* 1 = 1.80866 loss)
I1210 12:54:12.781919 10416 sgd_solver.cpp:105] Iteration 45400, lr = 0.1
I1210 12:54:18.185310  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:54:18.409324 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_45500.caffemodel
I1210 12:54:18.428324 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_45500.solverstate
I1210 12:54:18.433326 10416 solver.cpp:330] Iteration 45500, Testing net (#0)
I1210 12:54:18.433326 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:54:19.817435  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:54:19.872442 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3639
I1210 12:54:19.872442 10416 solver.cpp:397]     Test net output #1: loss = 2.8045 (* 1 = 2.8045 loss)
I1210 12:54:19.925441 10416 solver.cpp:218] Iteration 45500 (13.9979 iter/s, 7.14392s/100 iters), loss = 1.64383
I1210 12:54:19.926441 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:54:19.926441 10416 solver.cpp:237]     Train net output #1: loss = 1.64383 (* 1 = 1.64383 loss)
I1210 12:54:19.926441 10416 sgd_solver.cpp:105] Iteration 45500, lr = 0.1
I1210 12:54:25.593866 10416 solver.cpp:218] Iteration 45600 (17.6441 iter/s, 5.66762s/100 iters), loss = 1.46547
I1210 12:54:25.593866 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:54:25.593866 10416 solver.cpp:237]     Train net output #1: loss = 1.46547 (* 1 = 1.46547 loss)
I1210 12:54:25.593866 10416 sgd_solver.cpp:105] Iteration 45600, lr = 0.1
I1210 12:54:31.270366 10416 solver.cpp:218] Iteration 45700 (17.6179 iter/s, 5.67603s/100 iters), loss = 1.28857
I1210 12:54:31.270366 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 12:54:31.270366 10416 solver.cpp:237]     Train net output #1: loss = 1.28857 (* 1 = 1.28857 loss)
I1210 12:54:31.270366 10416 sgd_solver.cpp:105] Iteration 45700, lr = 0.1
I1210 12:54:36.936383 10416 solver.cpp:218] Iteration 45800 (17.6498 iter/s, 5.66578s/100 iters), loss = 1.80631
I1210 12:54:36.936383 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:54:36.936383 10416 solver.cpp:237]     Train net output #1: loss = 1.80631 (* 1 = 1.80631 loss)
I1210 12:54:36.936383 10416 sgd_solver.cpp:105] Iteration 45800, lr = 0.1
I1210 12:54:42.600157 10416 solver.cpp:218] Iteration 45900 (17.6575 iter/s, 5.6633s/100 iters), loss = 1.75302
I1210 12:54:42.600157 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:54:42.600157 10416 solver.cpp:237]     Train net output #1: loss = 1.75302 (* 1 = 1.75302 loss)
I1210 12:54:42.600157 10416 sgd_solver.cpp:105] Iteration 45900, lr = 0.1
I1210 12:54:47.990156  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:54:48.211716 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_46000.caffemodel
I1210 12:54:48.226719 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_46000.solverstate
I1210 12:54:48.231722 10416 solver.cpp:330] Iteration 46000, Testing net (#0)
I1210 12:54:48.231722 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:54:49.611629  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:54:49.665761 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3525
I1210 12:54:49.665761 10416 solver.cpp:397]     Test net output #1: loss = 2.85277 (* 1 = 2.85277 loss)
I1210 12:54:49.718775 10416 solver.cpp:218] Iteration 46000 (14.0491 iter/s, 7.11791s/100 iters), loss = 1.57138
I1210 12:54:49.718775 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:54:49.718775 10416 solver.cpp:237]     Train net output #1: loss = 1.57138 (* 1 = 1.57138 loss)
I1210 12:54:49.718775 10416 sgd_solver.cpp:105] Iteration 46000, lr = 0.1
I1210 12:54:55.410091 10416 solver.cpp:218] Iteration 46100 (17.5737 iter/s, 5.69033s/100 iters), loss = 1.44276
I1210 12:54:55.410091 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:54:55.410091 10416 solver.cpp:237]     Train net output #1: loss = 1.44276 (* 1 = 1.44276 loss)
I1210 12:54:55.410091 10416 sgd_solver.cpp:105] Iteration 46100, lr = 0.1
I1210 12:55:01.090934 10416 solver.cpp:218] Iteration 46200 (17.6044 iter/s, 5.68039s/100 iters), loss = 1.36729
I1210 12:55:01.090934 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:55:01.090934 10416 solver.cpp:237]     Train net output #1: loss = 1.36729 (* 1 = 1.36729 loss)
I1210 12:55:01.090934 10416 sgd_solver.cpp:105] Iteration 46200, lr = 0.1
I1210 12:55:06.769873 10416 solver.cpp:218] Iteration 46300 (17.6094 iter/s, 5.67879s/100 iters), loss = 1.67685
I1210 12:55:06.769873 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 12:55:06.769873 10416 solver.cpp:237]     Train net output #1: loss = 1.67685 (* 1 = 1.67685 loss)
I1210 12:55:06.769873 10416 sgd_solver.cpp:105] Iteration 46300, lr = 0.1
I1210 12:55:12.459462 10416 solver.cpp:218] Iteration 46400 (17.5777 iter/s, 5.68902s/100 iters), loss = 1.90554
I1210 12:55:12.459462 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:55:12.459462 10416 solver.cpp:237]     Train net output #1: loss = 1.90554 (* 1 = 1.90554 loss)
I1210 12:55:12.459462 10416 sgd_solver.cpp:105] Iteration 46400, lr = 0.1
I1210 12:55:17.867539  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:55:18.089856 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_46500.caffemodel
I1210 12:55:18.108844 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_46500.solverstate
I1210 12:55:18.113844 10416 solver.cpp:330] Iteration 46500, Testing net (#0)
I1210 12:55:18.113844 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:55:19.495113  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:55:19.549113 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3416
I1210 12:55:19.549113 10416 solver.cpp:397]     Test net output #1: loss = 2.72176 (* 1 = 2.72176 loss)
I1210 12:55:19.603633 10416 solver.cpp:218] Iteration 46500 (13.9984 iter/s, 7.14366s/100 iters), loss = 1.68337
I1210 12:55:19.603633 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:55:19.603633 10416 solver.cpp:237]     Train net output #1: loss = 1.68337 (* 1 = 1.68337 loss)
I1210 12:55:19.603633 10416 sgd_solver.cpp:105] Iteration 46500, lr = 0.1
I1210 12:55:25.258119 10416 solver.cpp:218] Iteration 46600 (17.6858 iter/s, 5.65425s/100 iters), loss = 1.48486
I1210 12:55:25.258119 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:55:25.258119 10416 solver.cpp:237]     Train net output #1: loss = 1.48486 (* 1 = 1.48486 loss)
I1210 12:55:25.258119 10416 sgd_solver.cpp:105] Iteration 46600, lr = 0.1
I1210 12:55:30.899144 10416 solver.cpp:218] Iteration 46700 (17.7276 iter/s, 5.64093s/100 iters), loss = 1.4012
I1210 12:55:30.899144 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:55:30.899144 10416 solver.cpp:237]     Train net output #1: loss = 1.4012 (* 1 = 1.4012 loss)
I1210 12:55:30.899144 10416 sgd_solver.cpp:105] Iteration 46700, lr = 0.1
I1210 12:55:36.548020 10416 solver.cpp:218] Iteration 46800 (17.7037 iter/s, 5.64852s/100 iters), loss = 1.67932
I1210 12:55:36.548020 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:55:36.548020 10416 solver.cpp:237]     Train net output #1: loss = 1.67932 (* 1 = 1.67932 loss)
I1210 12:55:36.548020 10416 sgd_solver.cpp:105] Iteration 46800, lr = 0.1
I1210 12:55:42.193410 10416 solver.cpp:218] Iteration 46900 (17.7165 iter/s, 5.64447s/100 iters), loss = 1.9363
I1210 12:55:42.193410 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:55:42.193410 10416 solver.cpp:237]     Train net output #1: loss = 1.9363 (* 1 = 1.9363 loss)
I1210 12:55:42.193410 10416 sgd_solver.cpp:105] Iteration 46900, lr = 0.1
I1210 12:55:47.568850  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:55:47.790871 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_47000.caffemodel
I1210 12:55:47.808871 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_47000.solverstate
I1210 12:55:47.813871 10416 solver.cpp:330] Iteration 47000, Testing net (#0)
I1210 12:55:47.813871 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:55:49.193295  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:55:49.248296 10416 solver.cpp:397]     Test net output #0: accuracy = 0.353
I1210 12:55:49.248296 10416 solver.cpp:397]     Test net output #1: loss = 2.7766 (* 1 = 2.7766 loss)
I1210 12:55:49.303298 10416 solver.cpp:218] Iteration 47000 (14.0657 iter/s, 7.1095s/100 iters), loss = 1.63255
I1210 12:55:49.303298 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:55:49.303298 10416 solver.cpp:237]     Train net output #1: loss = 1.63255 (* 1 = 1.63255 loss)
I1210 12:55:49.303298 10416 sgd_solver.cpp:105] Iteration 47000, lr = 0.1
I1210 12:55:54.970692 10416 solver.cpp:218] Iteration 47100 (17.6459 iter/s, 5.66703s/100 iters), loss = 1.48042
I1210 12:55:54.970692 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:55:54.970692 10416 solver.cpp:237]     Train net output #1: loss = 1.48042 (* 1 = 1.48042 loss)
I1210 12:55:54.970692 10416 sgd_solver.cpp:105] Iteration 47100, lr = 0.1
I1210 12:56:00.628082 10416 solver.cpp:218] Iteration 47200 (17.6769 iter/s, 5.65709s/100 iters), loss = 1.36536
I1210 12:56:00.628082 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 12:56:00.628082 10416 solver.cpp:237]     Train net output #1: loss = 1.36536 (* 1 = 1.36536 loss)
I1210 12:56:00.628082 10416 sgd_solver.cpp:105] Iteration 47200, lr = 0.1
I1210 12:56:06.302471 10416 solver.cpp:218] Iteration 47300 (17.6244 iter/s, 5.67395s/100 iters), loss = 1.92005
I1210 12:56:06.302471 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:56:06.302471 10416 solver.cpp:237]     Train net output #1: loss = 1.92005 (* 1 = 1.92005 loss)
I1210 12:56:06.302471 10416 sgd_solver.cpp:105] Iteration 47300, lr = 0.1
I1210 12:56:11.969846 10416 solver.cpp:218] Iteration 47400 (17.6466 iter/s, 5.66681s/100 iters), loss = 1.85937
I1210 12:56:11.969846 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 12:56:11.969846 10416 solver.cpp:237]     Train net output #1: loss = 1.85937 (* 1 = 1.85937 loss)
I1210 12:56:11.969846 10416 sgd_solver.cpp:105] Iteration 47400, lr = 0.1
I1210 12:56:17.369194  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:56:17.593209 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_47500.caffemodel
I1210 12:56:17.613209 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_47500.solverstate
I1210 12:56:17.617208 10416 solver.cpp:330] Iteration 47500, Testing net (#0)
I1210 12:56:17.617208 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:56:18.997293  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:56:19.052294 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3515
I1210 12:56:19.052294 10416 solver.cpp:397]     Test net output #1: loss = 2.68436 (* 1 = 2.68436 loss)
I1210 12:56:19.105298 10416 solver.cpp:218] Iteration 47500 (14.0152 iter/s, 7.13509s/100 iters), loss = 1.63051
I1210 12:56:19.105298 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:56:19.105298 10416 solver.cpp:237]     Train net output #1: loss = 1.63051 (* 1 = 1.63051 loss)
I1210 12:56:19.105298 10416 sgd_solver.cpp:105] Iteration 47500, lr = 0.1
I1210 12:56:24.772735 10416 solver.cpp:218] Iteration 47600 (17.6476 iter/s, 5.66649s/100 iters), loss = 1.53162
I1210 12:56:24.772735 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 12:56:24.772735 10416 solver.cpp:237]     Train net output #1: loss = 1.53162 (* 1 = 1.53162 loss)
I1210 12:56:24.772735 10416 sgd_solver.cpp:105] Iteration 47600, lr = 0.1
I1210 12:56:30.442131 10416 solver.cpp:218] Iteration 47700 (17.6399 iter/s, 5.66896s/100 iters), loss = 1.32039
I1210 12:56:30.442131 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 12:56:30.442131 10416 solver.cpp:237]     Train net output #1: loss = 1.32039 (* 1 = 1.32039 loss)
I1210 12:56:30.442131 10416 sgd_solver.cpp:105] Iteration 47700, lr = 0.1
I1210 12:56:36.099547 10416 solver.cpp:218] Iteration 47800 (17.6754 iter/s, 5.65758s/100 iters), loss = 1.87223
I1210 12:56:36.100548 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:56:36.100548 10416 solver.cpp:237]     Train net output #1: loss = 1.87223 (* 1 = 1.87223 loss)
I1210 12:56:36.100548 10416 sgd_solver.cpp:105] Iteration 47800, lr = 0.1
I1210 12:56:41.769012 10416 solver.cpp:218] Iteration 47900 (17.6402 iter/s, 5.66888s/100 iters), loss = 1.81418
I1210 12:56:41.769012 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:56:41.769012 10416 solver.cpp:237]     Train net output #1: loss = 1.81418 (* 1 = 1.81418 loss)
I1210 12:56:41.769012 10416 sgd_solver.cpp:105] Iteration 47900, lr = 0.1
I1210 12:56:47.171422  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:56:47.393437 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_48000.caffemodel
I1210 12:56:47.412436 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_48000.solverstate
I1210 12:56:47.417940 10416 solver.cpp:330] Iteration 48000, Testing net (#0)
I1210 12:56:47.417940 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:56:48.800539  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:56:48.855543 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3849
I1210 12:56:48.855543 10416 solver.cpp:397]     Test net output #1: loss = 2.41248 (* 1 = 2.41248 loss)
I1210 12:56:48.910558 10416 solver.cpp:218] Iteration 48000 (14.0046 iter/s, 7.1405s/100 iters), loss = 1.57836
I1210 12:56:48.910558 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:56:48.910558 10416 solver.cpp:237]     Train net output #1: loss = 1.57836 (* 1 = 1.57836 loss)
I1210 12:56:48.910558 10416 sgd_solver.cpp:105] Iteration 48000, lr = 0.1
I1210 12:56:54.592066 10416 solver.cpp:218] Iteration 48100 (17.6022 iter/s, 5.68112s/100 iters), loss = 1.56672
I1210 12:56:54.592066 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 12:56:54.592066 10416 solver.cpp:237]     Train net output #1: loss = 1.56672 (* 1 = 1.56672 loss)
I1210 12:56:54.592066 10416 sgd_solver.cpp:105] Iteration 48100, lr = 0.1
I1210 12:57:00.272563 10416 solver.cpp:218] Iteration 48200 (17.6034 iter/s, 5.68072s/100 iters), loss = 1.44374
I1210 12:57:00.273551 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:57:00.273551 10416 solver.cpp:237]     Train net output #1: loss = 1.44374 (* 1 = 1.44374 loss)
I1210 12:57:00.273551 10416 sgd_solver.cpp:105] Iteration 48200, lr = 0.1
I1210 12:57:05.946971 10416 solver.cpp:218] Iteration 48300 (17.6265 iter/s, 5.67328s/100 iters), loss = 1.83948
I1210 12:57:05.946971 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 12:57:05.946971 10416 solver.cpp:237]     Train net output #1: loss = 1.83948 (* 1 = 1.83948 loss)
I1210 12:57:05.946971 10416 sgd_solver.cpp:105] Iteration 48300, lr = 0.1
I1210 12:57:11.630388 10416 solver.cpp:218] Iteration 48400 (17.5969 iter/s, 5.68282s/100 iters), loss = 1.75443
I1210 12:57:11.630388 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:57:11.630388 10416 solver.cpp:237]     Train net output #1: loss = 1.75443 (* 1 = 1.75443 loss)
I1210 12:57:11.630388 10416 sgd_solver.cpp:105] Iteration 48400, lr = 0.1
I1210 12:57:17.034970  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:57:17.255986 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_48500.caffemodel
I1210 12:57:17.273986 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_48500.solverstate
I1210 12:57:17.277986 10416 solver.cpp:330] Iteration 48500, Testing net (#0)
I1210 12:57:17.277986 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:57:18.658088  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:57:18.712088 10416 solver.cpp:397]     Test net output #0: accuracy = 0.432
I1210 12:57:18.712088 10416 solver.cpp:397]     Test net output #1: loss = 2.24324 (* 1 = 2.24324 loss)
I1210 12:57:18.765094 10416 solver.cpp:218] Iteration 48500 (14.0156 iter/s, 7.13493s/100 iters), loss = 1.54078
I1210 12:57:18.765094 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 12:57:18.765094 10416 solver.cpp:237]     Train net output #1: loss = 1.54078 (* 1 = 1.54078 loss)
I1210 12:57:18.765094 10416 sgd_solver.cpp:105] Iteration 48500, lr = 0.1
I1210 12:57:24.456571 10416 solver.cpp:218] Iteration 48600 (17.5738 iter/s, 5.69029s/100 iters), loss = 1.36483
I1210 12:57:24.456571 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 12:57:24.456571 10416 solver.cpp:237]     Train net output #1: loss = 1.36483 (* 1 = 1.36483 loss)
I1210 12:57:24.456571 10416 sgd_solver.cpp:105] Iteration 48600, lr = 0.1
I1210 12:57:30.146090 10416 solver.cpp:218] Iteration 48700 (17.5778 iter/s, 5.68899s/100 iters), loss = 1.37307
I1210 12:57:30.146090 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:57:30.146090 10416 solver.cpp:237]     Train net output #1: loss = 1.37307 (* 1 = 1.37307 loss)
I1210 12:57:30.146090 10416 sgd_solver.cpp:105] Iteration 48700, lr = 0.1
I1210 12:57:35.831498 10416 solver.cpp:218] Iteration 48800 (17.5893 iter/s, 5.68528s/100 iters), loss = 1.76308
I1210 12:57:35.831498 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 12:57:35.831498 10416 solver.cpp:237]     Train net output #1: loss = 1.76308 (* 1 = 1.76308 loss)
I1210 12:57:35.831498 10416 sgd_solver.cpp:105] Iteration 48800, lr = 0.1
I1210 12:57:41.514261 10416 solver.cpp:218] Iteration 48900 (17.5994 iter/s, 5.682s/100 iters), loss = 1.9121
I1210 12:57:41.514261 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:57:41.514261 10416 solver.cpp:237]     Train net output #1: loss = 1.9121 (* 1 = 1.9121 loss)
I1210 12:57:41.514261 10416 sgd_solver.cpp:105] Iteration 48900, lr = 0.1
I1210 12:57:46.922199  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:57:47.145722 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_49000.caffemodel
I1210 12:57:47.162722 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_49000.solverstate
I1210 12:57:47.167723 10416 solver.cpp:330] Iteration 49000, Testing net (#0)
I1210 12:57:47.167723 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:57:48.553823  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:57:48.606823 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3428
I1210 12:57:48.607825 10416 solver.cpp:397]     Test net output #1: loss = 2.74489 (* 1 = 2.74489 loss)
I1210 12:57:48.660828 10416 solver.cpp:218] Iteration 49000 (13.9932 iter/s, 7.14635s/100 iters), loss = 1.74078
I1210 12:57:48.660828 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:57:48.660828 10416 solver.cpp:237]     Train net output #1: loss = 1.74078 (* 1 = 1.74078 loss)
I1210 12:57:48.660828 10416 sgd_solver.cpp:105] Iteration 49000, lr = 0.1
I1210 12:57:54.323741 10416 solver.cpp:218] Iteration 49100 (17.6601 iter/s, 5.66248s/100 iters), loss = 1.4807
I1210 12:57:54.323741 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:57:54.323741 10416 solver.cpp:237]     Train net output #1: loss = 1.4807 (* 1 = 1.4807 loss)
I1210 12:57:54.323741 10416 sgd_solver.cpp:105] Iteration 49100, lr = 0.1
I1210 12:57:59.982967 10416 solver.cpp:218] Iteration 49200 (17.6721 iter/s, 5.65865s/100 iters), loss = 1.28789
I1210 12:57:59.982967 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 12:57:59.982967 10416 solver.cpp:237]     Train net output #1: loss = 1.28789 (* 1 = 1.28789 loss)
I1210 12:57:59.982967 10416 sgd_solver.cpp:105] Iteration 49200, lr = 0.1
I1210 12:58:05.653653 10416 solver.cpp:218] Iteration 49300 (17.6339 iter/s, 5.67088s/100 iters), loss = 1.82458
I1210 12:58:05.653653 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 12:58:05.653653 10416 solver.cpp:237]     Train net output #1: loss = 1.82458 (* 1 = 1.82458 loss)
I1210 12:58:05.653653 10416 sgd_solver.cpp:105] Iteration 49300, lr = 0.1
I1210 12:58:11.315634 10416 solver.cpp:218] Iteration 49400 (17.6638 iter/s, 5.6613s/100 iters), loss = 1.73592
I1210 12:58:11.315634 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:58:11.315634 10416 solver.cpp:237]     Train net output #1: loss = 1.73592 (* 1 = 1.73592 loss)
I1210 12:58:11.315634 10416 sgd_solver.cpp:105] Iteration 49400, lr = 0.1
I1210 12:58:16.697594  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:58:16.919620 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_49500.caffemodel
I1210 12:58:16.934625 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_49500.solverstate
I1210 12:58:16.939124 10416 solver.cpp:330] Iteration 49500, Testing net (#0)
I1210 12:58:16.939124 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:58:18.321728  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:58:18.376737 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3599
I1210 12:58:18.376737 10416 solver.cpp:397]     Test net output #1: loss = 2.73687 (* 1 = 2.73687 loss)
I1210 12:58:18.430738 10416 solver.cpp:218] Iteration 49500 (14.057 iter/s, 7.11391s/100 iters), loss = 1.66389
I1210 12:58:18.430738 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 12:58:18.430738 10416 solver.cpp:237]     Train net output #1: loss = 1.66389 (* 1 = 1.66389 loss)
I1210 12:58:18.430738 10416 sgd_solver.cpp:105] Iteration 49500, lr = 0.1
I1210 12:58:24.092140 10416 solver.cpp:218] Iteration 49600 (17.6636 iter/s, 5.66136s/100 iters), loss = 1.44421
I1210 12:58:24.092140 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 12:58:24.092140 10416 solver.cpp:237]     Train net output #1: loss = 1.44421 (* 1 = 1.44421 loss)
I1210 12:58:24.092140 10416 sgd_solver.cpp:105] Iteration 49600, lr = 0.1
I1210 12:58:29.771621 10416 solver.cpp:218] Iteration 49700 (17.6085 iter/s, 5.67908s/100 iters), loss = 1.35114
I1210 12:58:29.771621 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 12:58:29.771621 10416 solver.cpp:237]     Train net output #1: loss = 1.35114 (* 1 = 1.35114 loss)
I1210 12:58:29.771621 10416 sgd_solver.cpp:105] Iteration 49700, lr = 0.1
I1210 12:58:35.438550 10416 solver.cpp:218] Iteration 49800 (17.6492 iter/s, 5.66598s/100 iters), loss = 1.71152
I1210 12:58:35.438550 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:58:35.438550 10416 solver.cpp:237]     Train net output #1: loss = 1.71152 (* 1 = 1.71152 loss)
I1210 12:58:35.438550 10416 sgd_solver.cpp:105] Iteration 49800, lr = 0.1
I1210 12:58:41.106454 10416 solver.cpp:218] Iteration 49900 (17.6426 iter/s, 5.6681s/100 iters), loss = 1.8259
I1210 12:58:41.106454 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 12:58:41.106454 10416 solver.cpp:237]     Train net output #1: loss = 1.8259 (* 1 = 1.8259 loss)
I1210 12:58:41.106454 10416 sgd_solver.cpp:105] Iteration 49900, lr = 0.1
I1210 12:58:46.502949  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:58:46.722961 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_50000.caffemodel
I1210 12:58:46.738966 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_50000.solverstate
I1210 12:58:46.743966 10416 solver.cpp:330] Iteration 50000, Testing net (#0)
I1210 12:58:46.743966 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:58:48.151139  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:58:48.205149 10416 solver.cpp:397]     Test net output #0: accuracy = 0.3523
I1210 12:58:48.205149 10416 solver.cpp:397]     Test net output #1: loss = 2.77275 (* 1 = 2.77275 loss)
I1210 12:58:48.259155 10416 solver.cpp:218] Iteration 50000 (13.9826 iter/s, 7.15174s/100 iters), loss = 1.53879
I1210 12:58:48.259155 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 12:58:48.259155 10416 solver.cpp:237]     Train net output #1: loss = 1.53879 (* 1 = 1.53879 loss)
I1210 12:58:48.259155 10416 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I1210 12:58:48.259155 10416 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1210 12:58:53.950088 10416 solver.cpp:218] Iteration 50100 (17.5741 iter/s, 5.69019s/100 iters), loss = 1.17366
I1210 12:58:53.950088 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 12:58:53.950088 10416 solver.cpp:237]     Train net output #1: loss = 1.17366 (* 1 = 1.17366 loss)
I1210 12:58:53.950088 10416 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1210 12:58:59.634102 10416 solver.cpp:218] Iteration 50200 (17.5925 iter/s, 5.68425s/100 iters), loss = 0.998632
I1210 12:58:59.634102 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 12:58:59.634102 10416 solver.cpp:237]     Train net output #1: loss = 0.998632 (* 1 = 0.998632 loss)
I1210 12:58:59.634102 10416 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1210 12:59:05.328583 10416 solver.cpp:218] Iteration 50300 (17.5619 iter/s, 5.69414s/100 iters), loss = 1.2074
I1210 12:59:05.328583 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 12:59:05.328583 10416 solver.cpp:237]     Train net output #1: loss = 1.2074 (* 1 = 1.2074 loss)
I1210 12:59:05.328583 10416 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1210 12:59:11.009084 10416 solver.cpp:218] Iteration 50400 (17.6053 iter/s, 5.68011s/100 iters), loss = 1.22579
I1210 12:59:11.009084 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 12:59:11.009084 10416 solver.cpp:237]     Train net output #1: loss = 1.22579 (* 1 = 1.22579 loss)
I1210 12:59:11.009084 10416 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1210 12:59:16.401504  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:59:16.625514 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_50500.caffemodel
I1210 12:59:16.645016 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_50500.solverstate
I1210 12:59:16.650017 10416 solver.cpp:330] Iteration 50500, Testing net (#0)
I1210 12:59:16.650017 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:59:18.031903  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:59:18.086908 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6348
I1210 12:59:18.086908 10416 solver.cpp:397]     Test net output #1: loss = 1.27853 (* 1 = 1.27853 loss)
I1210 12:59:18.141412 10416 solver.cpp:218] Iteration 50500 (14.0229 iter/s, 7.13119s/100 iters), loss = 1.19098
I1210 12:59:18.141412 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 12:59:18.141412 10416 solver.cpp:237]     Train net output #1: loss = 1.19098 (* 1 = 1.19098 loss)
I1210 12:59:18.141412 10416 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1210 12:59:23.824306 10416 solver.cpp:218] Iteration 50600 (17.5969 iter/s, 5.68283s/100 iters), loss = 1.11288
I1210 12:59:23.824306 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 12:59:23.824306 10416 solver.cpp:237]     Train net output #1: loss = 1.11288 (* 1 = 1.11288 loss)
I1210 12:59:23.824306 10416 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1210 12:59:29.506764 10416 solver.cpp:218] Iteration 50700 (17.5979 iter/s, 5.6825s/100 iters), loss = 0.934635
I1210 12:59:29.507764 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 12:59:29.507764 10416 solver.cpp:237]     Train net output #1: loss = 0.934635 (* 1 = 0.934635 loss)
I1210 12:59:29.507764 10416 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1210 12:59:35.185250 10416 solver.cpp:218] Iteration 50800 (17.6129 iter/s, 5.67767s/100 iters), loss = 1.13251
I1210 12:59:35.185250 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 12:59:35.185250 10416 solver.cpp:237]     Train net output #1: loss = 1.13251 (* 1 = 1.13251 loss)
I1210 12:59:35.185250 10416 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1210 12:59:40.874681 10416 solver.cpp:218] Iteration 50900 (17.5785 iter/s, 5.68876s/100 iters), loss = 1.14896
I1210 12:59:40.874681 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 12:59:40.874681 10416 solver.cpp:237]     Train net output #1: loss = 1.14896 (* 1 = 1.14896 loss)
I1210 12:59:40.874681 10416 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1210 12:59:46.280222  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:59:46.503249 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_51000.caffemodel
I1210 12:59:46.522249 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_51000.solverstate
I1210 12:59:46.526249 10416 solver.cpp:330] Iteration 51000, Testing net (#0)
I1210 12:59:46.526249 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 12:59:47.909348  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 12:59:47.962373 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6355
I1210 12:59:47.962373 10416 solver.cpp:397]     Test net output #1: loss = 1.25735 (* 1 = 1.25735 loss)
I1210 12:59:48.016371 10416 solver.cpp:218] Iteration 51000 (14.0041 iter/s, 7.14077s/100 iters), loss = 1.03764
I1210 12:59:48.016371 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 12:59:48.016371 10416 solver.cpp:237]     Train net output #1: loss = 1.03764 (* 1 = 1.03764 loss)
I1210 12:59:48.016371 10416 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1210 12:59:53.690804 10416 solver.cpp:218] Iteration 51100 (17.6246 iter/s, 5.67388s/100 iters), loss = 1.03127
I1210 12:59:53.690804 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 12:59:53.690804 10416 solver.cpp:237]     Train net output #1: loss = 1.03127 (* 1 = 1.03127 loss)
I1210 12:59:53.690804 10416 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1210 12:59:59.376567 10416 solver.cpp:218] Iteration 51200 (17.5868 iter/s, 5.68609s/100 iters), loss = 0.839689
I1210 12:59:59.376567 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 12:59:59.376567 10416 solver.cpp:237]     Train net output #1: loss = 0.839689 (* 1 = 0.839689 loss)
I1210 12:59:59.376567 10416 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1210 13:00:05.079057 10416 solver.cpp:218] Iteration 51300 (17.5381 iter/s, 5.70189s/100 iters), loss = 0.945756
I1210 13:00:05.079057 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:00:05.079057 10416 solver.cpp:237]     Train net output #1: loss = 0.945756 (* 1 = 0.945756 loss)
I1210 13:00:05.079057 10416 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1210 13:00:10.763487 10416 solver.cpp:218] Iteration 51400 (17.5936 iter/s, 5.68389s/100 iters), loss = 1.14694
I1210 13:00:10.763487 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 13:00:10.763487 10416 solver.cpp:237]     Train net output #1: loss = 1.14694 (* 1 = 1.14694 loss)
I1210 13:00:10.763487 10416 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1210 13:00:16.164904  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:00:16.386940 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_51500.caffemodel
I1210 13:00:16.405941 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_51500.solverstate
I1210 13:00:16.410940 10416 solver.cpp:330] Iteration 51500, Testing net (#0)
I1210 13:00:16.410940 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:00:17.793401  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:00:17.848402 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6362
I1210 13:00:17.848402 10416 solver.cpp:397]     Test net output #1: loss = 1.25812 (* 1 = 1.25812 loss)
I1210 13:00:17.901419 10416 solver.cpp:218] Iteration 51500 (14.0116 iter/s, 7.13692s/100 iters), loss = 1.01059
I1210 13:00:17.901419 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:00:17.901419 10416 solver.cpp:237]     Train net output #1: loss = 1.01059 (* 1 = 1.01059 loss)
I1210 13:00:17.901419 10416 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1210 13:00:23.560930 10416 solver.cpp:218] Iteration 51600 (17.6701 iter/s, 5.65928s/100 iters), loss = 0.889901
I1210 13:00:23.560930 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:00:23.560930 10416 solver.cpp:237]     Train net output #1: loss = 0.889901 (* 1 = 0.889901 loss)
I1210 13:00:23.560930 10416 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1210 13:00:29.231338 10416 solver.cpp:218] Iteration 51700 (17.6386 iter/s, 5.66937s/100 iters), loss = 0.776094
I1210 13:00:29.231338 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:00:29.231338 10416 solver.cpp:237]     Train net output #1: loss = 0.776094 (* 1 = 0.776094 loss)
I1210 13:00:29.231338 10416 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1210 13:00:34.897732 10416 solver.cpp:218] Iteration 51800 (17.6493 iter/s, 5.66595s/100 iters), loss = 1.06472
I1210 13:00:34.897732 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 13:00:34.897732 10416 solver.cpp:237]     Train net output #1: loss = 1.06472 (* 1 = 1.06472 loss)
I1210 13:00:34.897732 10416 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1210 13:00:40.555199 10416 solver.cpp:218] Iteration 51900 (17.676 iter/s, 5.6574s/100 iters), loss = 1.1025
I1210 13:00:40.555199 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:00:40.555199 10416 solver.cpp:237]     Train net output #1: loss = 1.1025 (* 1 = 1.1025 loss)
I1210 13:00:40.555199 10416 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1210 13:00:45.941560  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:00:46.162502 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_52000.caffemodel
I1210 13:00:46.177500 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_52000.solverstate
I1210 13:00:46.182500 10416 solver.cpp:330] Iteration 52000, Testing net (#0)
I1210 13:00:46.182500 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:00:47.565624  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:00:47.618624 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6408
I1210 13:00:47.618624 10416 solver.cpp:397]     Test net output #1: loss = 1.24895 (* 1 = 1.24895 loss)
I1210 13:00:47.671629 10416 solver.cpp:218] Iteration 52000 (14.052 iter/s, 7.11641s/100 iters), loss = 0.886608
I1210 13:00:47.671629 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:00:47.671629 10416 solver.cpp:237]     Train net output #1: loss = 0.886608 (* 1 = 0.886608 loss)
I1210 13:00:47.672629 10416 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1210 13:00:53.330039 10416 solver.cpp:218] Iteration 52100 (17.6765 iter/s, 5.65724s/100 iters), loss = 0.938734
I1210 13:00:53.330039 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:00:53.330039 10416 solver.cpp:237]     Train net output #1: loss = 0.938734 (* 1 = 0.938734 loss)
I1210 13:00:53.330039 10416 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1210 13:00:58.985458 10416 solver.cpp:218] Iteration 52200 (17.681 iter/s, 5.65577s/100 iters), loss = 0.750826
I1210 13:00:58.986459 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:00:58.986459 10416 solver.cpp:237]     Train net output #1: loss = 0.750826 (* 1 = 0.750826 loss)
I1210 13:00:58.986459 10416 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1210 13:01:04.650368 10416 solver.cpp:218] Iteration 52300 (17.6565 iter/s, 5.66364s/100 iters), loss = 1.00517
I1210 13:01:04.650368 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:01:04.650368 10416 solver.cpp:237]     Train net output #1: loss = 1.00517 (* 1 = 1.00517 loss)
I1210 13:01:04.650368 10416 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1210 13:01:10.313298 10416 solver.cpp:218] Iteration 52400 (17.6582 iter/s, 5.66311s/100 iters), loss = 1.03211
I1210 13:01:10.313298 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:01:10.313298 10416 solver.cpp:237]     Train net output #1: loss = 1.03211 (* 1 = 1.03211 loss)
I1210 13:01:10.313298 10416 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1210 13:01:15.708711  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:01:15.932723 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_52500.caffemodel
I1210 13:01:15.952229 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_52500.solverstate
I1210 13:01:15.957228 10416 solver.cpp:330] Iteration 52500, Testing net (#0)
I1210 13:01:15.957228 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:01:17.342845  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:01:17.395850 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6477
I1210 13:01:17.395850 10416 solver.cpp:397]     Test net output #1: loss = 1.23552 (* 1 = 1.23552 loss)
I1210 13:01:17.451354 10416 solver.cpp:218] Iteration 52500 (14.0116 iter/s, 7.13693s/100 iters), loss = 0.921992
I1210 13:01:17.451354 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:01:17.451354 10416 solver.cpp:237]     Train net output #1: loss = 0.921992 (* 1 = 0.921992 loss)
I1210 13:01:17.451354 10416 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1210 13:01:23.122261 10416 solver.cpp:218] Iteration 52600 (17.635 iter/s, 5.67056s/100 iters), loss = 0.946816
I1210 13:01:23.122261 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:01:23.122261 10416 solver.cpp:237]     Train net output #1: loss = 0.946816 (* 1 = 0.946816 loss)
I1210 13:01:23.122261 10416 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1210 13:01:28.813249 10416 solver.cpp:218] Iteration 52700 (17.5728 iter/s, 5.6906s/100 iters), loss = 0.747789
I1210 13:01:28.813249 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:01:28.813249 10416 solver.cpp:237]     Train net output #1: loss = 0.747789 (* 1 = 0.747789 loss)
I1210 13:01:28.813249 10416 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1210 13:01:34.493883 10416 solver.cpp:218] Iteration 52800 (17.6037 iter/s, 5.68062s/100 iters), loss = 0.996814
I1210 13:01:34.493883 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 13:01:34.493883 10416 solver.cpp:237]     Train net output #1: loss = 0.996814 (* 1 = 0.996814 loss)
I1210 13:01:34.493883 10416 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1210 13:01:40.169875 10416 solver.cpp:218] Iteration 52900 (17.6199 iter/s, 5.67541s/100 iters), loss = 1.08842
I1210 13:01:40.169875 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 13:01:40.169875 10416 solver.cpp:237]     Train net output #1: loss = 1.08842 (* 1 = 1.08842 loss)
I1210 13:01:40.169875 10416 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1210 13:01:45.560658  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:01:45.782832 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_53000.caffemodel
I1210 13:01:45.796818 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_53000.solverstate
I1210 13:01:45.801836 10416 solver.cpp:330] Iteration 53000, Testing net (#0)
I1210 13:01:45.801836 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:01:47.186096  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:01:47.240079 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6476
I1210 13:01:47.240079 10416 solver.cpp:397]     Test net output #1: loss = 1.22366 (* 1 = 1.22366 loss)
I1210 13:01:47.293884 10416 solver.cpp:218] Iteration 53000 (14.0387 iter/s, 7.12317s/100 iters), loss = 0.815904
I1210 13:01:47.293884 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:01:47.293884 10416 solver.cpp:237]     Train net output #1: loss = 0.815904 (* 1 = 0.815904 loss)
I1210 13:01:47.293884 10416 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1210 13:01:52.960669 10416 solver.cpp:218] Iteration 53100 (17.6478 iter/s, 5.66644s/100 iters), loss = 0.882032
I1210 13:01:52.960669 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:01:52.960669 10416 solver.cpp:237]     Train net output #1: loss = 0.882032 (* 1 = 0.882032 loss)
I1210 13:01:52.960669 10416 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1210 13:01:58.638586 10416 solver.cpp:218] Iteration 53200 (17.6126 iter/s, 5.67774s/100 iters), loss = 0.687124
I1210 13:01:58.638586 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:01:58.638586 10416 solver.cpp:237]     Train net output #1: loss = 0.687124 (* 1 = 0.687124 loss)
I1210 13:01:58.638586 10416 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1210 13:02:04.304004 10416 solver.cpp:218] Iteration 53300 (17.6531 iter/s, 5.66473s/100 iters), loss = 0.84349
I1210 13:02:04.304004 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:02:04.304004 10416 solver.cpp:237]     Train net output #1: loss = 0.84349 (* 1 = 0.84349 loss)
I1210 13:02:04.304004 10416 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1210 13:02:09.967520 10416 solver.cpp:218] Iteration 53400 (17.6587 iter/s, 5.66294s/100 iters), loss = 0.989397
I1210 13:02:09.967520 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:02:09.967520 10416 solver.cpp:237]     Train net output #1: loss = 0.989397 (* 1 = 0.989397 loss)
I1210 13:02:09.967520 10416 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1210 13:02:15.347434  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:02:15.569085 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_53500.caffemodel
I1210 13:02:15.584568 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_53500.solverstate
I1210 13:02:15.588569 10416 solver.cpp:330] Iteration 53500, Testing net (#0)
I1210 13:02:15.588569 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:02:16.968132  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:02:17.023779 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6434
I1210 13:02:17.023779 10416 solver.cpp:397]     Test net output #1: loss = 1.23146 (* 1 = 1.23146 loss)
I1210 13:02:17.078297 10416 solver.cpp:218] Iteration 53500 (14.0642 iter/s, 7.11024s/100 iters), loss = 0.818394
I1210 13:02:17.078297 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:02:17.078297 10416 solver.cpp:237]     Train net output #1: loss = 0.818394 (* 1 = 0.818394 loss)
I1210 13:02:17.078297 10416 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1210 13:02:22.761858 10416 solver.cpp:218] Iteration 53600 (17.5938 iter/s, 5.68383s/100 iters), loss = 0.804743
I1210 13:02:22.761858 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:02:22.761858 10416 solver.cpp:237]     Train net output #1: loss = 0.804743 (* 1 = 0.804743 loss)
I1210 13:02:22.761858 10416 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1210 13:02:28.448863 10416 solver.cpp:218] Iteration 53700 (17.5873 iter/s, 5.68592s/100 iters), loss = 0.648738
I1210 13:02:28.448863 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:02:28.448863 10416 solver.cpp:237]     Train net output #1: loss = 0.648738 (* 1 = 0.648738 loss)
I1210 13:02:28.448863 10416 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1210 13:02:34.133632 10416 solver.cpp:218] Iteration 53800 (17.5911 iter/s, 5.68469s/100 iters), loss = 0.966987
I1210 13:02:34.133632 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 13:02:34.133632 10416 solver.cpp:237]     Train net output #1: loss = 0.966987 (* 1 = 0.966987 loss)
I1210 13:02:34.133632 10416 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1210 13:02:39.813061 10416 solver.cpp:218] Iteration 53900 (17.6089 iter/s, 5.67894s/100 iters), loss = 1.06862
I1210 13:02:39.813061 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:02:39.813061 10416 solver.cpp:237]     Train net output #1: loss = 1.06862 (* 1 = 1.06862 loss)
I1210 13:02:39.813061 10416 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1210 13:02:45.212520  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:02:45.436545 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_54000.caffemodel
I1210 13:02:45.452553 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_54000.solverstate
I1210 13:02:45.456550 10416 solver.cpp:330] Iteration 54000, Testing net (#0)
I1210 13:02:45.456550 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:02:46.837671  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:02:46.890672 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6439
I1210 13:02:46.890672 10416 solver.cpp:397]     Test net output #1: loss = 1.24136 (* 1 = 1.24136 loss)
I1210 13:02:46.946679 10416 solver.cpp:218] Iteration 54000 (14.0196 iter/s, 7.13288s/100 iters), loss = 0.812249
I1210 13:02:46.946679 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:02:46.946679 10416 solver.cpp:237]     Train net output #1: loss = 0.812249 (* 1 = 0.812249 loss)
I1210 13:02:46.946679 10416 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1210 13:02:52.622146 10416 solver.cpp:218] Iteration 54100 (17.6203 iter/s, 5.67529s/100 iters), loss = 0.852092
I1210 13:02:52.622146 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:02:52.622146 10416 solver.cpp:237]     Train net output #1: loss = 0.852092 (* 1 = 0.852092 loss)
I1210 13:02:52.622146 10416 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1210 13:02:58.303951 10416 solver.cpp:218] Iteration 54200 (17.6025 iter/s, 5.68102s/100 iters), loss = 0.72137
I1210 13:02:58.303951 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:02:58.303951 10416 solver.cpp:237]     Train net output #1: loss = 0.72137 (* 1 = 0.72137 loss)
I1210 13:02:58.303951 10416 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1210 13:03:03.985973 10416 solver.cpp:218] Iteration 54300 (17.5982 iter/s, 5.68242s/100 iters), loss = 0.910279
I1210 13:03:03.985973 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:03:03.986974 10416 solver.cpp:237]     Train net output #1: loss = 0.910279 (* 1 = 0.910279 loss)
I1210 13:03:03.986974 10416 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1210 13:03:09.659415 10416 solver.cpp:218] Iteration 54400 (17.6278 iter/s, 5.67287s/100 iters), loss = 0.982645
I1210 13:03:09.659415 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:03:09.659415 10416 solver.cpp:237]     Train net output #1: loss = 0.982645 (* 1 = 0.982645 loss)
I1210 13:03:09.659415 10416 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1210 13:03:15.056149  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:03:15.279206 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_54500.caffemodel
I1210 13:03:15.298205 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_54500.solverstate
I1210 13:03:15.303205 10416 solver.cpp:330] Iteration 54500, Testing net (#0)
I1210 13:03:15.303205 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:03:16.687319  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:03:16.740321 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6284
I1210 13:03:16.740321 10416 solver.cpp:397]     Test net output #1: loss = 1.30022 (* 1 = 1.30022 loss)
I1210 13:03:16.794323 10416 solver.cpp:218] Iteration 54500 (14.0171 iter/s, 7.13415s/100 iters), loss = 0.748908
I1210 13:03:16.794323 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:03:16.794323 10416 solver.cpp:237]     Train net output #1: loss = 0.748908 (* 1 = 0.748908 loss)
I1210 13:03:16.794323 10416 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1210 13:03:22.486984 10416 solver.cpp:218] Iteration 54600 (17.5696 iter/s, 5.69165s/100 iters), loss = 0.826241
I1210 13:03:22.486984 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:03:22.486984 10416 solver.cpp:237]     Train net output #1: loss = 0.826241 (* 1 = 0.826241 loss)
I1210 13:03:22.486984 10416 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1210 13:03:28.173701 10416 solver.cpp:218] Iteration 54700 (17.5847 iter/s, 5.68675s/100 iters), loss = 0.826384
I1210 13:03:28.173701 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:03:28.173701 10416 solver.cpp:237]     Train net output #1: loss = 0.826384 (* 1 = 0.826384 loss)
I1210 13:03:28.173701 10416 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1210 13:03:33.853350 10416 solver.cpp:218] Iteration 54800 (17.6091 iter/s, 5.67888s/100 iters), loss = 1.0092
I1210 13:03:33.853350 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 13:03:33.853350 10416 solver.cpp:237]     Train net output #1: loss = 1.0092 (* 1 = 1.0092 loss)
I1210 13:03:33.853350 10416 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1210 13:03:39.541568 10416 solver.cpp:218] Iteration 54900 (17.5808 iter/s, 5.68802s/100 iters), loss = 0.959445
I1210 13:03:39.541568 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 13:03:39.541568 10416 solver.cpp:237]     Train net output #1: loss = 0.959445 (* 1 = 0.959445 loss)
I1210 13:03:39.542070 10416 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1210 13:03:44.947062  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:03:45.170086 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_55000.caffemodel
I1210 13:03:45.191087 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_55000.solverstate
I1210 13:03:45.196084 10416 solver.cpp:330] Iteration 55000, Testing net (#0)
I1210 13:03:45.196084 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:03:46.579216  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:03:46.634228 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6393
I1210 13:03:46.634228 10416 solver.cpp:397]     Test net output #1: loss = 1.27915 (* 1 = 1.27915 loss)
I1210 13:03:46.688225 10416 solver.cpp:218] Iteration 55000 (13.9941 iter/s, 7.14588s/100 iters), loss = 0.772137
I1210 13:03:46.688225 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:03:46.688225 10416 solver.cpp:237]     Train net output #1: loss = 0.772137 (* 1 = 0.772137 loss)
I1210 13:03:46.688225 10416 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1210 13:03:52.363268 10416 solver.cpp:218] Iteration 55100 (17.6221 iter/s, 5.67469s/100 iters), loss = 0.809817
I1210 13:03:52.363268 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:03:52.363268 10416 solver.cpp:237]     Train net output #1: loss = 0.809817 (* 1 = 0.809817 loss)
I1210 13:03:52.363268 10416 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1210 13:03:58.010519 10416 solver.cpp:218] Iteration 55200 (17.7091 iter/s, 5.64683s/100 iters), loss = 0.654045
I1210 13:03:58.010519 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:03:58.010519 10416 solver.cpp:237]     Train net output #1: loss = 0.654045 (* 1 = 0.654045 loss)
I1210 13:03:58.010519 10416 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1210 13:04:03.688515 10416 solver.cpp:218] Iteration 55300 (17.6115 iter/s, 5.67812s/100 iters), loss = 0.907512
I1210 13:04:03.689517 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 13:04:03.689517 10416 solver.cpp:237]     Train net output #1: loss = 0.907512 (* 1 = 0.907512 loss)
I1210 13:04:03.689517 10416 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1210 13:04:09.355028 10416 solver.cpp:218] Iteration 55400 (17.6504 iter/s, 5.66561s/100 iters), loss = 0.97475
I1210 13:04:09.355028 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:04:09.355028 10416 solver.cpp:237]     Train net output #1: loss = 0.97475 (* 1 = 0.97475 loss)
I1210 13:04:09.355028 10416 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1210 13:04:14.742446  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:04:14.965456 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_55500.caffemodel
I1210 13:04:14.981456 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_55500.solverstate
I1210 13:04:14.985456 10416 solver.cpp:330] Iteration 55500, Testing net (#0)
I1210 13:04:14.985456 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:04:16.371608  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:04:16.425602 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6435
I1210 13:04:16.425602 10416 solver.cpp:397]     Test net output #1: loss = 1.24724 (* 1 = 1.24724 loss)
I1210 13:04:16.479604 10416 solver.cpp:218] Iteration 55500 (14.0369 iter/s, 7.1241s/100 iters), loss = 0.778349
I1210 13:04:16.479604 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:04:16.479604 10416 solver.cpp:237]     Train net output #1: loss = 0.778349 (* 1 = 0.778349 loss)
I1210 13:04:16.479604 10416 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1210 13:04:22.156013 10416 solver.cpp:218] Iteration 55600 (17.6184 iter/s, 5.67587s/100 iters), loss = 0.917101
I1210 13:04:22.156013 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:04:22.156013 10416 solver.cpp:237]     Train net output #1: loss = 0.917101 (* 1 = 0.917101 loss)
I1210 13:04:22.156013 10416 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1210 13:04:27.830436 10416 solver.cpp:218] Iteration 55700 (17.6227 iter/s, 5.6745s/100 iters), loss = 0.666402
I1210 13:04:27.831437 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:04:27.831437 10416 solver.cpp:237]     Train net output #1: loss = 0.666402 (* 1 = 0.666402 loss)
I1210 13:04:27.831437 10416 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1210 13:04:33.500897 10416 solver.cpp:218] Iteration 55800 (17.6395 iter/s, 5.66911s/100 iters), loss = 0.888177
I1210 13:04:33.500897 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:04:33.500897 10416 solver.cpp:237]     Train net output #1: loss = 0.888177 (* 1 = 0.888177 loss)
I1210 13:04:33.500897 10416 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1210 13:04:39.182324 10416 solver.cpp:218] Iteration 55900 (17.602 iter/s, 5.68116s/100 iters), loss = 1.06285
I1210 13:04:39.182324 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 13:04:39.182324 10416 solver.cpp:237]     Train net output #1: loss = 1.06285 (* 1 = 1.06285 loss)
I1210 13:04:39.182324 10416 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1210 13:04:44.579743  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:04:44.802749 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_56000.caffemodel
I1210 13:04:44.818253 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_56000.solverstate
I1210 13:04:44.822752 10416 solver.cpp:330] Iteration 56000, Testing net (#0)
I1210 13:04:44.822752 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:04:46.205860  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:04:46.259865 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6397
I1210 13:04:46.259865 10416 solver.cpp:397]     Test net output #1: loss = 1.27762 (* 1 = 1.27762 loss)
I1210 13:04:46.313870 10416 solver.cpp:218] Iteration 56000 (14.0233 iter/s, 7.13099s/100 iters), loss = 0.743674
I1210 13:04:46.313870 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:04:46.313870 10416 solver.cpp:237]     Train net output #1: loss = 0.743674 (* 1 = 0.743674 loss)
I1210 13:04:46.313870 10416 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1210 13:04:51.994268 10416 solver.cpp:218] Iteration 56100 (17.6042 iter/s, 5.68048s/100 iters), loss = 0.79267
I1210 13:04:51.994268 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:04:51.994268 10416 solver.cpp:237]     Train net output #1: loss = 0.79267 (* 1 = 0.79267 loss)
I1210 13:04:51.994268 10416 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1210 13:04:57.659729 10416 solver.cpp:218] Iteration 56200 (17.6518 iter/s, 5.66516s/100 iters), loss = 0.68354
I1210 13:04:57.659729 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:04:57.659729 10416 solver.cpp:237]     Train net output #1: loss = 0.68354 (* 1 = 0.68354 loss)
I1210 13:04:57.660728 10416 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1210 13:05:03.334147 10416 solver.cpp:218] Iteration 56300 (17.6249 iter/s, 5.6738s/100 iters), loss = 0.932538
I1210 13:05:03.334147 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 13:05:03.334147 10416 solver.cpp:237]     Train net output #1: loss = 0.932538 (* 1 = 0.932538 loss)
I1210 13:05:03.334147 10416 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1210 13:05:09.017208 10416 solver.cpp:218] Iteration 56400 (17.5993 iter/s, 5.68205s/100 iters), loss = 0.884007
I1210 13:05:09.017208 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:05:09.017208 10416 solver.cpp:237]     Train net output #1: loss = 0.884007 (* 1 = 0.884007 loss)
I1210 13:05:09.017208 10416 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1210 13:05:14.427173  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:05:14.652189 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_56500.caffemodel
I1210 13:05:14.671187 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_56500.solverstate
I1210 13:05:14.676188 10416 solver.cpp:330] Iteration 56500, Testing net (#0)
I1210 13:05:14.676188 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:05:16.060343  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:05:16.115344 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6342
I1210 13:05:16.115344 10416 solver.cpp:397]     Test net output #1: loss = 1.31025 (* 1 = 1.31025 loss)
I1210 13:05:16.169345 10416 solver.cpp:218] Iteration 56500 (13.9814 iter/s, 7.15237s/100 iters), loss = 0.772693
I1210 13:05:16.169345 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:05:16.169345 10416 solver.cpp:237]     Train net output #1: loss = 0.772693 (* 1 = 0.772693 loss)
I1210 13:05:16.169345 10416 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1210 13:05:21.843669 10416 solver.cpp:218] Iteration 56600 (17.6255 iter/s, 5.6736s/100 iters), loss = 0.766653
I1210 13:05:21.843669 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:05:21.843669 10416 solver.cpp:237]     Train net output #1: loss = 0.766653 (* 1 = 0.766653 loss)
I1210 13:05:21.843669 10416 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1210 13:05:27.516110 10416 solver.cpp:218] Iteration 56700 (17.6307 iter/s, 5.67191s/100 iters), loss = 0.685723
I1210 13:05:27.516611 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:05:27.516611 10416 solver.cpp:237]     Train net output #1: loss = 0.685723 (* 1 = 0.685723 loss)
I1210 13:05:27.516611 10416 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1210 13:05:33.187567 10416 solver.cpp:218] Iteration 56800 (17.6323 iter/s, 5.67142s/100 iters), loss = 0.856558
I1210 13:05:33.187567 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:05:33.187567 10416 solver.cpp:237]     Train net output #1: loss = 0.856558 (* 1 = 0.856558 loss)
I1210 13:05:33.188568 10416 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1210 13:05:38.871989 10416 solver.cpp:218] Iteration 56900 (17.595 iter/s, 5.68342s/100 iters), loss = 1.00087
I1210 13:05:38.871989 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:05:38.871989 10416 solver.cpp:237]     Train net output #1: loss = 1.00087 (* 1 = 1.00087 loss)
I1210 13:05:38.871989 10416 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1210 13:05:44.274332  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:05:44.496343 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_57000.caffemodel
I1210 13:05:44.512343 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_57000.solverstate
I1210 13:05:44.516847 10416 solver.cpp:330] Iteration 57000, Testing net (#0)
I1210 13:05:44.516847 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:05:45.899422  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:05:45.955435 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6273
I1210 13:05:45.955435 10416 solver.cpp:397]     Test net output #1: loss = 1.3278 (* 1 = 1.3278 loss)
I1210 13:05:46.009435 10416 solver.cpp:218] Iteration 57000 (14.0112 iter/s, 7.13716s/100 iters), loss = 0.811993
I1210 13:05:46.009435 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:05:46.009435 10416 solver.cpp:237]     Train net output #1: loss = 0.811993 (* 1 = 0.811993 loss)
I1210 13:05:46.009435 10416 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1210 13:05:51.695878 10416 solver.cpp:218] Iteration 57100 (17.5887 iter/s, 5.68547s/100 iters), loss = 0.800125
I1210 13:05:51.695878 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:05:51.695878 10416 solver.cpp:237]     Train net output #1: loss = 0.800125 (* 1 = 0.800125 loss)
I1210 13:05:51.695878 10416 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1210 13:05:57.391270 10416 solver.cpp:218] Iteration 57200 (17.5576 iter/s, 5.69553s/100 iters), loss = 0.756052
I1210 13:05:57.391270 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:05:57.391270 10416 solver.cpp:237]     Train net output #1: loss = 0.756052 (* 1 = 0.756052 loss)
I1210 13:05:57.391270 10416 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1210 13:06:03.085711 10416 solver.cpp:218] Iteration 57300 (17.5639 iter/s, 5.69351s/100 iters), loss = 0.890899
I1210 13:06:03.085711 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:06:03.085711 10416 solver.cpp:237]     Train net output #1: loss = 0.890899 (* 1 = 0.890899 loss)
I1210 13:06:03.085711 10416 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1210 13:06:08.775144 10416 solver.cpp:218] Iteration 57400 (17.5783 iter/s, 5.68882s/100 iters), loss = 1.00039
I1210 13:06:08.775144 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:06:08.775144 10416 solver.cpp:237]     Train net output #1: loss = 1.00039 (* 1 = 1.00039 loss)
I1210 13:06:08.775144 10416 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1210 13:06:14.188730  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:06:14.414741 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_57500.caffemodel
I1210 13:06:14.430246 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_57500.solverstate
I1210 13:06:14.434751 10416 solver.cpp:330] Iteration 57500, Testing net (#0)
I1210 13:06:14.434751 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:06:15.818351  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:06:15.871857 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6205
I1210 13:06:15.871857 10416 solver.cpp:397]     Test net output #1: loss = 1.36474 (* 1 = 1.36474 loss)
I1210 13:06:15.925359 10416 solver.cpp:218] Iteration 57500 (13.9868 iter/s, 7.14959s/100 iters), loss = 0.746796
I1210 13:06:15.925359 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:06:15.925359 10416 solver.cpp:237]     Train net output #1: loss = 0.746796 (* 1 = 0.746796 loss)
I1210 13:06:15.925359 10416 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1210 13:06:21.604369 10416 solver.cpp:218] Iteration 57600 (17.6096 iter/s, 5.67873s/100 iters), loss = 0.826644
I1210 13:06:21.604369 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:06:21.604369 10416 solver.cpp:237]     Train net output #1: loss = 0.826644 (* 1 = 0.826644 loss)
I1210 13:06:21.604369 10416 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1210 13:06:27.285818 10416 solver.cpp:218] Iteration 57700 (17.6016 iter/s, 5.68131s/100 iters), loss = 0.706268
I1210 13:06:27.285818 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:06:27.285818 10416 solver.cpp:237]     Train net output #1: loss = 0.706268 (* 1 = 0.706268 loss)
I1210 13:06:27.285818 10416 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1210 13:06:32.966981 10416 solver.cpp:218] Iteration 57800 (17.6041 iter/s, 5.6805s/100 iters), loss = 0.871644
I1210 13:06:32.966981 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:06:32.966981 10416 solver.cpp:237]     Train net output #1: loss = 0.871644 (* 1 = 0.871644 loss)
I1210 13:06:32.966981 10416 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1210 13:06:38.644726 10416 solver.cpp:218] Iteration 57900 (17.614 iter/s, 5.6773s/100 iters), loss = 0.964806
I1210 13:06:38.644726 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:06:38.644726 10416 solver.cpp:237]     Train net output #1: loss = 0.964806 (* 1 = 0.964806 loss)
I1210 13:06:38.644726 10416 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1210 13:06:44.049348  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:06:44.274360 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_58000.caffemodel
I1210 13:06:44.292361 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_58000.solverstate
I1210 13:06:44.297360 10416 solver.cpp:330] Iteration 58000, Testing net (#0)
I1210 13:06:44.297360 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:06:45.680457  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:06:45.734961 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6174
I1210 13:06:45.734961 10416 solver.cpp:397]     Test net output #1: loss = 1.38166 (* 1 = 1.38166 loss)
I1210 13:06:45.789463 10416 solver.cpp:218] Iteration 58000 (13.9965 iter/s, 7.14466s/100 iters), loss = 0.776865
I1210 13:06:45.789463 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:06:45.789463 10416 solver.cpp:237]     Train net output #1: loss = 0.776865 (* 1 = 0.776865 loss)
I1210 13:06:45.789463 10416 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1210 13:06:51.454919 10416 solver.cpp:218] Iteration 58100 (17.6526 iter/s, 5.66487s/100 iters), loss = 0.802033
I1210 13:06:51.454919 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:06:51.454919 10416 solver.cpp:237]     Train net output #1: loss = 0.802033 (* 1 = 0.802033 loss)
I1210 13:06:51.454919 10416 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1210 13:06:57.129844 10416 solver.cpp:218] Iteration 58200 (17.6241 iter/s, 5.67403s/100 iters), loss = 0.756047
I1210 13:06:57.129844 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:06:57.129844 10416 solver.cpp:237]     Train net output #1: loss = 0.756047 (* 1 = 0.756047 loss)
I1210 13:06:57.129844 10416 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1210 13:07:02.797798 10416 solver.cpp:218] Iteration 58300 (17.6447 iter/s, 5.66743s/100 iters), loss = 0.845159
I1210 13:07:02.797798 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:07:02.797798 10416 solver.cpp:237]     Train net output #1: loss = 0.845159 (* 1 = 0.845159 loss)
I1210 13:07:02.797798 10416 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1210 13:07:08.464331 10416 solver.cpp:218] Iteration 58400 (17.647 iter/s, 5.66668s/100 iters), loss = 0.945046
I1210 13:07:08.464331 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 13:07:08.464331 10416 solver.cpp:237]     Train net output #1: loss = 0.945046 (* 1 = 0.945046 loss)
I1210 13:07:08.464331 10416 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1210 13:07:13.846761  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:07:14.071781 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_58500.caffemodel
I1210 13:07:14.090783 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_58500.solverstate
I1210 13:07:14.095783 10416 solver.cpp:330] Iteration 58500, Testing net (#0)
I1210 13:07:14.096783 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:07:15.483872  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:07:15.536876 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6141
I1210 13:07:15.536876 10416 solver.cpp:397]     Test net output #1: loss = 1.4196 (* 1 = 1.4196 loss)
I1210 13:07:15.589879 10416 solver.cpp:218] Iteration 58500 (14.0348 iter/s, 7.12514s/100 iters), loss = 0.675539
I1210 13:07:15.589879 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:07:15.589879 10416 solver.cpp:237]     Train net output #1: loss = 0.675539 (* 1 = 0.675539 loss)
I1210 13:07:15.589879 10416 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1210 13:07:21.257344 10416 solver.cpp:218] Iteration 58600 (17.6477 iter/s, 5.66648s/100 iters), loss = 0.877434
I1210 13:07:21.257344 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:07:21.257344 10416 solver.cpp:237]     Train net output #1: loss = 0.877434 (* 1 = 0.877434 loss)
I1210 13:07:21.257344 10416 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1210 13:07:26.921793 10416 solver.cpp:218] Iteration 58700 (17.6555 iter/s, 5.66396s/100 iters), loss = 0.656173
I1210 13:07:26.921793 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:07:26.921793 10416 solver.cpp:237]     Train net output #1: loss = 0.656173 (* 1 = 0.656173 loss)
I1210 13:07:26.921793 10416 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1210 13:07:32.592329 10416 solver.cpp:218] Iteration 58800 (17.6376 iter/s, 5.6697s/100 iters), loss = 0.853421
I1210 13:07:32.592329 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:07:32.592329 10416 solver.cpp:237]     Train net output #1: loss = 0.853421 (* 1 = 0.853421 loss)
I1210 13:07:32.592329 10416 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1210 13:07:38.263870 10416 solver.cpp:218] Iteration 58900 (17.6311 iter/s, 5.67179s/100 iters), loss = 1.02371
I1210 13:07:38.263870 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:07:38.263870 10416 solver.cpp:237]     Train net output #1: loss = 1.02371 (* 1 = 1.02371 loss)
I1210 13:07:38.263870 10416 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1210 13:07:43.652120  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:07:43.875124 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_59000.caffemodel
I1210 13:07:43.896123 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_59000.solverstate
I1210 13:07:43.900123 10416 solver.cpp:330] Iteration 59000, Testing net (#0)
I1210 13:07:43.900123 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:07:45.286219  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:07:45.338222 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6213
I1210 13:07:45.338222 10416 solver.cpp:397]     Test net output #1: loss = 1.37598 (* 1 = 1.37598 loss)
I1210 13:07:45.394224 10416 solver.cpp:218] Iteration 59000 (14.0259 iter/s, 7.12965s/100 iters), loss = 0.704045
I1210 13:07:45.394224 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:07:45.394224 10416 solver.cpp:237]     Train net output #1: loss = 0.704045 (* 1 = 0.704045 loss)
I1210 13:07:45.394224 10416 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1210 13:07:51.056604 10416 solver.cpp:218] Iteration 59100 (17.6607 iter/s, 5.6623s/100 iters), loss = 0.82439
I1210 13:07:51.056604 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:07:51.056604 10416 solver.cpp:237]     Train net output #1: loss = 0.82439 (* 1 = 0.82439 loss)
I1210 13:07:51.056604 10416 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1210 13:07:56.720002 10416 solver.cpp:218] Iteration 59200 (17.6603 iter/s, 5.6624s/100 iters), loss = 0.655078
I1210 13:07:56.720002 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:07:56.720002 10416 solver.cpp:237]     Train net output #1: loss = 0.655078 (* 1 = 0.655078 loss)
I1210 13:07:56.720002 10416 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1210 13:08:02.394424 10416 solver.cpp:218] Iteration 59300 (17.6238 iter/s, 5.67414s/100 iters), loss = 0.836975
I1210 13:08:02.394424 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:08:02.394424 10416 solver.cpp:237]     Train net output #1: loss = 0.836975 (* 1 = 0.836975 loss)
I1210 13:08:02.394424 10416 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1210 13:08:08.068820 10416 solver.cpp:218] Iteration 59400 (17.6235 iter/s, 5.67423s/100 iters), loss = 0.953807
I1210 13:08:08.068820 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:08:08.068820 10416 solver.cpp:237]     Train net output #1: loss = 0.953807 (* 1 = 0.953807 loss)
I1210 13:08:08.068820 10416 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1210 13:08:13.462229  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:08:13.687242 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_59500.caffemodel
I1210 13:08:13.707242 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_59500.solverstate
I1210 13:08:13.711242 10416 solver.cpp:330] Iteration 59500, Testing net (#0)
I1210 13:08:13.712242 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:08:15.096369  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:08:15.149374 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6153
I1210 13:08:15.149374 10416 solver.cpp:397]     Test net output #1: loss = 1.38485 (* 1 = 1.38485 loss)
I1210 13:08:15.202373 10416 solver.cpp:218] Iteration 59500 (14.0191 iter/s, 7.1331s/100 iters), loss = 0.758128
I1210 13:08:15.203374 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:08:15.203374 10416 solver.cpp:237]     Train net output #1: loss = 0.758128 (* 1 = 0.758128 loss)
I1210 13:08:15.203374 10416 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1210 13:08:20.874743 10416 solver.cpp:218] Iteration 59600 (17.633 iter/s, 5.67119s/100 iters), loss = 0.89076
I1210 13:08:20.874743 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:08:20.874743 10416 solver.cpp:237]     Train net output #1: loss = 0.89076 (* 1 = 0.89076 loss)
I1210 13:08:20.874743 10416 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1210 13:08:26.541163 10416 solver.cpp:218] Iteration 59700 (17.649 iter/s, 5.66604s/100 iters), loss = 0.623881
I1210 13:08:26.541163 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:08:26.541163 10416 solver.cpp:237]     Train net output #1: loss = 0.623881 (* 1 = 0.623881 loss)
I1210 13:08:26.541163 10416 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1210 13:08:32.211551 10416 solver.cpp:218] Iteration 59800 (17.6349 iter/s, 5.67056s/100 iters), loss = 0.883473
I1210 13:08:32.212551 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:08:32.212551 10416 solver.cpp:237]     Train net output #1: loss = 0.883473 (* 1 = 0.883473 loss)
I1210 13:08:32.212551 10416 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1210 13:08:37.879963 10416 solver.cpp:218] Iteration 59900 (17.6441 iter/s, 5.66763s/100 iters), loss = 0.873742
I1210 13:08:37.879963 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:08:37.879963 10416 solver.cpp:237]     Train net output #1: loss = 0.873742 (* 1 = 0.873742 loss)
I1210 13:08:37.879963 10416 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1210 13:08:43.274507  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:08:43.497517 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_60000.caffemodel
I1210 13:08:43.513516 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_60000.solverstate
I1210 13:08:43.518518 10416 solver.cpp:330] Iteration 60000, Testing net (#0)
I1210 13:08:43.518518 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:08:44.903605  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:08:44.956620 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6179
I1210 13:08:44.956620 10416 solver.cpp:397]     Test net output #1: loss = 1.3868 (* 1 = 1.3868 loss)
I1210 13:08:45.012620 10416 solver.cpp:218] Iteration 60000 (14.0213 iter/s, 7.13202s/100 iters), loss = 0.697208
I1210 13:08:45.012620 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:08:45.012620 10416 solver.cpp:237]     Train net output #1: loss = 0.697208 (* 1 = 0.697208 loss)
I1210 13:08:45.012620 10416 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1210 13:08:50.678040 10416 solver.cpp:218] Iteration 60100 (17.6525 iter/s, 5.66491s/100 iters), loss = 0.815073
I1210 13:08:50.678040 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:08:50.678040 10416 solver.cpp:237]     Train net output #1: loss = 0.815073 (* 1 = 0.815073 loss)
I1210 13:08:50.678040 10416 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1210 13:08:56.324484 10416 solver.cpp:218] Iteration 60200 (17.712 iter/s, 5.64589s/100 iters), loss = 0.693812
I1210 13:08:56.324484 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:08:56.324484 10416 solver.cpp:237]     Train net output #1: loss = 0.693812 (* 1 = 0.693812 loss)
I1210 13:08:56.324484 10416 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1210 13:09:01.978945 10416 solver.cpp:218] Iteration 60300 (17.6857 iter/s, 5.6543s/100 iters), loss = 0.815939
I1210 13:09:01.978945 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:09:01.978945 10416 solver.cpp:237]     Train net output #1: loss = 0.815939 (* 1 = 0.815939 loss)
I1210 13:09:01.978945 10416 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1210 13:09:07.650760 10416 solver.cpp:218] Iteration 60400 (17.6336 iter/s, 5.67098s/100 iters), loss = 0.949733
I1210 13:09:07.650760 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:09:07.650760 10416 solver.cpp:237]     Train net output #1: loss = 0.949733 (* 1 = 0.949733 loss)
I1210 13:09:07.650760 10416 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1210 13:09:13.043655  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:09:13.264678 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_60500.caffemodel
I1210 13:09:13.284677 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_60500.solverstate
I1210 13:09:13.289679 10416 solver.cpp:330] Iteration 60500, Testing net (#0)
I1210 13:09:13.289679 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:09:14.673794  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:09:14.728785 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6104
I1210 13:09:14.728785 10416 solver.cpp:397]     Test net output #1: loss = 1.45667 (* 1 = 1.45667 loss)
I1210 13:09:14.782793 10416 solver.cpp:218] Iteration 60500 (14.0229 iter/s, 7.1312s/100 iters), loss = 0.821617
I1210 13:09:14.782793 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:09:14.782793 10416 solver.cpp:237]     Train net output #1: loss = 0.821617 (* 1 = 0.821617 loss)
I1210 13:09:14.782793 10416 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1210 13:09:20.467550 10416 solver.cpp:218] Iteration 60600 (17.5903 iter/s, 5.68495s/100 iters), loss = 0.760797
I1210 13:09:20.467550 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:09:20.467550 10416 solver.cpp:237]     Train net output #1: loss = 0.760797 (* 1 = 0.760797 loss)
I1210 13:09:20.467550 10416 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1210 13:09:26.153007 10416 solver.cpp:218] Iteration 60700 (17.5909 iter/s, 5.68475s/100 iters), loss = 0.727755
I1210 13:09:26.153507 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:09:26.153507 10416 solver.cpp:237]     Train net output #1: loss = 0.727755 (* 1 = 0.727755 loss)
I1210 13:09:26.153507 10416 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1210 13:09:31.841723 10416 solver.cpp:218] Iteration 60800 (17.5802 iter/s, 5.68822s/100 iters), loss = 0.810536
I1210 13:09:31.841723 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:09:31.841723 10416 solver.cpp:237]     Train net output #1: loss = 0.810536 (* 1 = 0.810536 loss)
I1210 13:09:31.841723 10416 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1210 13:09:37.539146 10416 solver.cpp:218] Iteration 60900 (17.5524 iter/s, 5.69722s/100 iters), loss = 0.959284
I1210 13:09:37.539146 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:09:37.539146 10416 solver.cpp:237]     Train net output #1: loss = 0.959284 (* 1 = 0.959284 loss)
I1210 13:09:37.539146 10416 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1210 13:09:42.946542  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:09:43.171561 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_61000.caffemodel
I1210 13:09:43.190562 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_61000.solverstate
I1210 13:09:43.196563 10416 solver.cpp:330] Iteration 61000, Testing net (#0)
I1210 13:09:43.196563 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:09:44.582664  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:09:44.636663 10416 solver.cpp:397]     Test net output #0: accuracy = 0.607
I1210 13:09:44.636663 10416 solver.cpp:397]     Test net output #1: loss = 1.45246 (* 1 = 1.45246 loss)
I1210 13:09:44.689669 10416 solver.cpp:218] Iteration 61000 (13.9862 iter/s, 7.14992s/100 iters), loss = 0.77294
I1210 13:09:44.689669 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:09:44.689669 10416 solver.cpp:237]     Train net output #1: loss = 0.77294 (* 1 = 0.77294 loss)
I1210 13:09:44.689669 10416 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1210 13:09:50.366024 10416 solver.cpp:218] Iteration 61100 (17.6196 iter/s, 5.67551s/100 iters), loss = 0.910859
I1210 13:09:50.366024 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 13:09:50.366024 10416 solver.cpp:237]     Train net output #1: loss = 0.910859 (* 1 = 0.910859 loss)
I1210 13:09:50.366024 10416 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1210 13:09:56.044431 10416 solver.cpp:218] Iteration 61200 (17.6123 iter/s, 5.67784s/100 iters), loss = 0.75762
I1210 13:09:56.044431 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:09:56.044431 10416 solver.cpp:237]     Train net output #1: loss = 0.75762 (* 1 = 0.75762 loss)
I1210 13:09:56.044431 10416 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1210 13:10:01.721993 10416 solver.cpp:218] Iteration 61300 (17.6127 iter/s, 5.67771s/100 iters), loss = 0.937515
I1210 13:10:01.721993 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:10:01.721993 10416 solver.cpp:237]     Train net output #1: loss = 0.937515 (* 1 = 0.937515 loss)
I1210 13:10:01.721993 10416 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1210 13:10:07.390652 10416 solver.cpp:218] Iteration 61400 (17.6429 iter/s, 5.66802s/100 iters), loss = 1.00956
I1210 13:10:07.391654 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:10:07.391654 10416 solver.cpp:237]     Train net output #1: loss = 1.00956 (* 1 = 1.00956 loss)
I1210 13:10:07.391654 10416 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1210 13:10:12.803027  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:10:13.026048 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_61500.caffemodel
I1210 13:10:13.042052 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_61500.solverstate
I1210 13:10:13.048049 10416 solver.cpp:330] Iteration 61500, Testing net (#0)
I1210 13:10:13.048049 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:10:14.431155  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:10:14.485160 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6115
I1210 13:10:14.485160 10416 solver.cpp:397]     Test net output #1: loss = 1.46282 (* 1 = 1.46282 loss)
I1210 13:10:14.541159 10416 solver.cpp:218] Iteration 61500 (13.9866 iter/s, 7.14968s/100 iters), loss = 0.699967
I1210 13:10:14.541159 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:10:14.541159 10416 solver.cpp:237]     Train net output #1: loss = 0.699967 (* 1 = 0.699967 loss)
I1210 13:10:14.541159 10416 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1210 13:10:20.200237 10416 solver.cpp:218] Iteration 61600 (17.6731 iter/s, 5.65831s/100 iters), loss = 0.767529
I1210 13:10:20.200237 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:10:20.200237 10416 solver.cpp:237]     Train net output #1: loss = 0.767529 (* 1 = 0.767529 loss)
I1210 13:10:20.200237 10416 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1210 13:10:25.867127 10416 solver.cpp:218] Iteration 61700 (17.6471 iter/s, 5.66666s/100 iters), loss = 0.595786
I1210 13:10:25.867615 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:10:25.867615 10416 solver.cpp:237]     Train net output #1: loss = 0.595786 (* 1 = 0.595786 loss)
I1210 13:10:25.867615 10416 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1210 13:10:31.539130 10416 solver.cpp:218] Iteration 61800 (17.6333 iter/s, 5.67108s/100 iters), loss = 0.859152
I1210 13:10:31.539130 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:10:31.539130 10416 solver.cpp:237]     Train net output #1: loss = 0.859152 (* 1 = 0.859152 loss)
I1210 13:10:31.539130 10416 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1210 13:10:37.215589 10416 solver.cpp:218] Iteration 61900 (17.6157 iter/s, 5.67676s/100 iters), loss = 0.953516
I1210 13:10:37.215589 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:10:37.215589 10416 solver.cpp:237]     Train net output #1: loss = 0.953516 (* 1 = 0.953516 loss)
I1210 13:10:37.215589 10416 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1210 13:10:42.612949  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:10:42.835963 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_62000.caffemodel
I1210 13:10:42.856966 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_62000.solverstate
I1210 13:10:42.861966 10416 solver.cpp:330] Iteration 62000, Testing net (#0)
I1210 13:10:42.861966 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:10:44.248070  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:10:44.302088 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6016
I1210 13:10:44.302088 10416 solver.cpp:397]     Test net output #1: loss = 1.48489 (* 1 = 1.48489 loss)
I1210 13:10:44.356078 10416 solver.cpp:218] Iteration 62000 (14.0069 iter/s, 7.13934s/100 iters), loss = 0.728598
I1210 13:10:44.356078 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:10:44.356078 10416 solver.cpp:237]     Train net output #1: loss = 0.728598 (* 1 = 0.728598 loss)
I1210 13:10:44.356078 10416 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1210 13:10:50.026500 10416 solver.cpp:218] Iteration 62100 (17.6348 iter/s, 5.6706s/100 iters), loss = 0.844751
I1210 13:10:50.026500 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:10:50.026500 10416 solver.cpp:237]     Train net output #1: loss = 0.844751 (* 1 = 0.844751 loss)
I1210 13:10:50.026500 10416 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1210 13:10:55.701926 10416 solver.cpp:218] Iteration 62200 (17.6225 iter/s, 5.67457s/100 iters), loss = 0.662035
I1210 13:10:55.701926 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:10:55.701926 10416 solver.cpp:237]     Train net output #1: loss = 0.662035 (* 1 = 0.662035 loss)
I1210 13:10:55.701926 10416 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1210 13:11:01.372364 10416 solver.cpp:218] Iteration 62300 (17.6371 iter/s, 5.66988s/100 iters), loss = 0.877533
I1210 13:11:01.372364 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:11:01.372364 10416 solver.cpp:237]     Train net output #1: loss = 0.877533 (* 1 = 0.877533 loss)
I1210 13:11:01.372364 10416 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1210 13:11:07.046782 10416 solver.cpp:218] Iteration 62400 (17.6222 iter/s, 5.67466s/100 iters), loss = 0.931852
I1210 13:11:07.047781 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 13:11:07.047781 10416 solver.cpp:237]     Train net output #1: loss = 0.931852 (* 1 = 0.931852 loss)
I1210 13:11:07.047781 10416 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1210 13:11:12.449196  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:11:12.672214 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_62500.caffemodel
I1210 13:11:12.692214 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_62500.solverstate
I1210 13:11:12.698213 10416 solver.cpp:330] Iteration 62500, Testing net (#0)
I1210 13:11:12.698213 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:11:14.095335  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:11:14.150334 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6141
I1210 13:11:14.150334 10416 solver.cpp:397]     Test net output #1: loss = 1.40356 (* 1 = 1.40356 loss)
I1210 13:11:14.204339 10416 solver.cpp:218] Iteration 62500 (13.9728 iter/s, 7.15679s/100 iters), loss = 0.618557
I1210 13:11:14.204339 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:11:14.204339 10416 solver.cpp:237]     Train net output #1: loss = 0.618557 (* 1 = 0.618557 loss)
I1210 13:11:14.204339 10416 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1210 13:11:19.873796 10416 solver.cpp:218] Iteration 62600 (17.6404 iter/s, 5.66879s/100 iters), loss = 0.769162
I1210 13:11:19.873796 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:11:19.873796 10416 solver.cpp:237]     Train net output #1: loss = 0.769162 (* 1 = 0.769162 loss)
I1210 13:11:19.873796 10416 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1210 13:11:25.535279 10416 solver.cpp:218] Iteration 62700 (17.6648 iter/s, 5.66097s/100 iters), loss = 0.583541
I1210 13:11:25.535279 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:11:25.535279 10416 solver.cpp:237]     Train net output #1: loss = 0.583541 (* 1 = 0.583541 loss)
I1210 13:11:25.535279 10416 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1210 13:11:31.204692 10416 solver.cpp:218] Iteration 62800 (17.6407 iter/s, 5.66871s/100 iters), loss = 0.975093
I1210 13:11:31.204692 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:11:31.204692 10416 solver.cpp:237]     Train net output #1: loss = 0.975093 (* 1 = 0.975093 loss)
I1210 13:11:31.204692 10416 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1210 13:11:36.868635 10416 solver.cpp:218] Iteration 62900 (17.658 iter/s, 5.66315s/100 iters), loss = 1.03518
I1210 13:11:36.868635 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:11:36.868635 10416 solver.cpp:237]     Train net output #1: loss = 1.03518 (* 1 = 1.03518 loss)
I1210 13:11:36.868635 10416 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1210 13:11:42.267035  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:11:42.487550 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_63000.caffemodel
I1210 13:11:42.507550 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_63000.solverstate
I1210 13:11:42.512549 10416 solver.cpp:330] Iteration 63000, Testing net (#0)
I1210 13:11:42.512549 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:11:43.895494  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:11:43.949494 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6208
I1210 13:11:43.949494 10416 solver.cpp:397]     Test net output #1: loss = 1.37589 (* 1 = 1.37589 loss)
I1210 13:11:44.003501 10416 solver.cpp:218] Iteration 63000 (14.016 iter/s, 7.13472s/100 iters), loss = 0.686281
I1210 13:11:44.003501 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:11:44.003501 10416 solver.cpp:237]     Train net output #1: loss = 0.686281 (* 1 = 0.686281 loss)
I1210 13:11:44.003501 10416 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1210 13:11:49.689954 10416 solver.cpp:218] Iteration 63100 (17.5873 iter/s, 5.68593s/100 iters), loss = 0.774099
I1210 13:11:49.689954 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:11:49.689954 10416 solver.cpp:237]     Train net output #1: loss = 0.774099 (* 1 = 0.774099 loss)
I1210 13:11:49.689954 10416 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1210 13:11:55.382436 10416 solver.cpp:218] Iteration 63200 (17.5692 iter/s, 5.69179s/100 iters), loss = 0.692787
I1210 13:11:55.382436 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:11:55.382436 10416 solver.cpp:237]     Train net output #1: loss = 0.692787 (* 1 = 0.692787 loss)
I1210 13:11:55.382436 10416 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1210 13:12:01.063876 10416 solver.cpp:218] Iteration 63300 (17.6033 iter/s, 5.68075s/100 iters), loss = 0.82447
I1210 13:12:01.063876 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:12:01.063876 10416 solver.cpp:237]     Train net output #1: loss = 0.82447 (* 1 = 0.82447 loss)
I1210 13:12:01.063876 10416 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1210 13:12:06.748365 10416 solver.cpp:218] Iteration 63400 (17.5932 iter/s, 5.68401s/100 iters), loss = 0.974693
I1210 13:12:06.748365 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:12:06.748365 10416 solver.cpp:237]     Train net output #1: loss = 0.974693 (* 1 = 0.974693 loss)
I1210 13:12:06.748365 10416 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1210 13:12:12.153782  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:12:12.376806 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_63500.caffemodel
I1210 13:12:12.395805 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_63500.solverstate
I1210 13:12:12.400805 10416 solver.cpp:330] Iteration 63500, Testing net (#0)
I1210 13:12:12.400805 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:12:13.782910  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:12:13.836910 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5788
I1210 13:12:13.836910 10416 solver.cpp:397]     Test net output #1: loss = 1.5684 (* 1 = 1.5684 loss)
I1210 13:12:13.890918 10416 solver.cpp:218] Iteration 63500 (14.0015 iter/s, 7.14211s/100 iters), loss = 0.825296
I1210 13:12:13.890918 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:12:13.890918 10416 solver.cpp:237]     Train net output #1: loss = 0.825296 (* 1 = 0.825296 loss)
I1210 13:12:13.890918 10416 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1210 13:12:19.582398 10416 solver.cpp:218] Iteration 63600 (17.5716 iter/s, 5.69099s/100 iters), loss = 0.815753
I1210 13:12:19.582398 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:12:19.582398 10416 solver.cpp:237]     Train net output #1: loss = 0.815753 (* 1 = 0.815753 loss)
I1210 13:12:19.582398 10416 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1210 13:12:25.275884 10416 solver.cpp:218] Iteration 63700 (17.5655 iter/s, 5.69297s/100 iters), loss = 0.66737
I1210 13:12:25.275884 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:12:25.275884 10416 solver.cpp:237]     Train net output #1: loss = 0.66737 (* 1 = 0.66737 loss)
I1210 13:12:25.275884 10416 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1210 13:12:30.971884 10416 solver.cpp:218] Iteration 63800 (17.5582 iter/s, 5.69535s/100 iters), loss = 0.763482
I1210 13:12:30.971884 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:12:30.971884 10416 solver.cpp:237]     Train net output #1: loss = 0.763482 (* 1 = 0.763482 loss)
I1210 13:12:30.971884 10416 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1210 13:12:36.661016 10416 solver.cpp:218] Iteration 63900 (17.578 iter/s, 5.68894s/100 iters), loss = 1.00478
I1210 13:12:36.661016 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 13:12:36.661016 10416 solver.cpp:237]     Train net output #1: loss = 1.00478 (* 1 = 1.00478 loss)
I1210 13:12:36.661016 10416 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1210 13:12:42.077461  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:12:42.301476 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_64000.caffemodel
I1210 13:12:42.320477 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_64000.solverstate
I1210 13:12:42.325477 10416 solver.cpp:330] Iteration 64000, Testing net (#0)
I1210 13:12:42.325477 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:12:43.709584  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:12:43.764086 10416 solver.cpp:397]     Test net output #0: accuracy = 0.607
I1210 13:12:43.764086 10416 solver.cpp:397]     Test net output #1: loss = 1.42459 (* 1 = 1.42459 loss)
I1210 13:12:43.817589 10416 solver.cpp:218] Iteration 64000 (13.9742 iter/s, 7.15605s/100 iters), loss = 0.803263
I1210 13:12:43.817589 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:12:43.817589 10416 solver.cpp:237]     Train net output #1: loss = 0.803263 (* 1 = 0.803263 loss)
I1210 13:12:43.817589 10416 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1210 13:12:49.504976 10416 solver.cpp:218] Iteration 64100 (17.5833 iter/s, 5.68722s/100 iters), loss = 0.844755
I1210 13:12:49.504976 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:12:49.504976 10416 solver.cpp:237]     Train net output #1: loss = 0.844755 (* 1 = 0.844755 loss)
I1210 13:12:49.504976 10416 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1210 13:12:55.181422 10416 solver.cpp:218] Iteration 64200 (17.6182 iter/s, 5.67595s/100 iters), loss = 0.683103
I1210 13:12:55.181422 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:12:55.181422 10416 solver.cpp:237]     Train net output #1: loss = 0.683103 (* 1 = 0.683103 loss)
I1210 13:12:55.181422 10416 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1210 13:13:00.851801 10416 solver.cpp:218] Iteration 64300 (17.6359 iter/s, 5.67025s/100 iters), loss = 0.838427
I1210 13:13:00.852804 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:13:00.852804 10416 solver.cpp:237]     Train net output #1: loss = 0.838427 (* 1 = 0.838427 loss)
I1210 13:13:00.852804 10416 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1210 13:13:06.529913 10416 solver.cpp:218] Iteration 64400 (17.6154 iter/s, 5.67686s/100 iters), loss = 0.98815
I1210 13:13:06.529913 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:13:06.529913 10416 solver.cpp:237]     Train net output #1: loss = 0.98815 (* 1 = 0.98815 loss)
I1210 13:13:06.529913 10416 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1210 13:13:11.936177  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:13:12.160239 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_64500.caffemodel
I1210 13:13:12.177234 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_64500.solverstate
I1210 13:13:12.182235 10416 solver.cpp:330] Iteration 64500, Testing net (#0)
I1210 13:13:12.182235 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:13:13.573385  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:13:13.627409 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5872
I1210 13:13:13.627409 10416 solver.cpp:397]     Test net output #1: loss = 1.5662 (* 1 = 1.5662 loss)
I1210 13:13:13.681398 10416 solver.cpp:218] Iteration 64500 (13.9837 iter/s, 7.15119s/100 iters), loss = 0.656836
I1210 13:13:13.681900 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:13:13.681900 10416 solver.cpp:237]     Train net output #1: loss = 0.656836 (* 1 = 0.656836 loss)
I1210 13:13:13.681900 10416 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1210 13:13:19.388105 10416 solver.cpp:218] Iteration 64600 (17.5252 iter/s, 5.70608s/100 iters), loss = 0.860954
I1210 13:13:19.388105 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:13:19.388105 10416 solver.cpp:237]     Train net output #1: loss = 0.860954 (* 1 = 0.860954 loss)
I1210 13:13:19.388105 10416 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1210 13:13:25.122406 10416 solver.cpp:218] Iteration 64700 (17.4409 iter/s, 5.73364s/100 iters), loss = 0.728539
I1210 13:13:25.122406 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:13:25.122406 10416 solver.cpp:237]     Train net output #1: loss = 0.728539 (* 1 = 0.728539 loss)
I1210 13:13:25.122406 10416 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1210 13:13:30.827394 10416 solver.cpp:218] Iteration 64800 (17.5279 iter/s, 5.7052s/100 iters), loss = 0.928244
I1210 13:13:30.827394 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:13:30.827394 10416 solver.cpp:237]     Train net output #1: loss = 0.928244 (* 1 = 0.928244 loss)
I1210 13:13:30.827394 10416 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1210 13:13:36.593631 10416 solver.cpp:218] Iteration 64900 (17.3456 iter/s, 5.76514s/100 iters), loss = 0.955647
I1210 13:13:36.593631 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:13:36.593631 10416 solver.cpp:237]     Train net output #1: loss = 0.955647 (* 1 = 0.955647 loss)
I1210 13:13:36.593631 10416 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1210 13:13:42.049185  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:13:42.271203 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_65000.caffemodel
I1210 13:13:42.291718 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_65000.solverstate
I1210 13:13:42.296206 10416 solver.cpp:330] Iteration 65000, Testing net (#0)
I1210 13:13:42.296206 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:13:43.683857  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:13:43.737903 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6115
I1210 13:13:43.737903 10416 solver.cpp:397]     Test net output #1: loss = 1.43809 (* 1 = 1.43809 loss)
I1210 13:13:43.791409 10416 solver.cpp:218] Iteration 65000 (13.894 iter/s, 7.19735s/100 iters), loss = 0.707032
I1210 13:13:43.791409 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:13:43.791409 10416 solver.cpp:237]     Train net output #1: loss = 0.707032 (* 1 = 0.707032 loss)
I1210 13:13:43.791409 10416 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1210 13:13:49.451467 10416 solver.cpp:218] Iteration 65100 (17.6694 iter/s, 5.6595s/100 iters), loss = 0.822285
I1210 13:13:49.451467 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:13:49.451467 10416 solver.cpp:237]     Train net output #1: loss = 0.822285 (* 1 = 0.822285 loss)
I1210 13:13:49.451467 10416 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1210 13:13:55.113656 10416 solver.cpp:218] Iteration 65200 (17.6603 iter/s, 5.6624s/100 iters), loss = 0.53008
I1210 13:13:55.114656 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 13:13:55.114656 10416 solver.cpp:237]     Train net output #1: loss = 0.53008 (* 1 = 0.53008 loss)
I1210 13:13:55.114656 10416 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1210 13:14:00.770375 10416 solver.cpp:218] Iteration 65300 (17.681 iter/s, 5.6558s/100 iters), loss = 0.81762
I1210 13:14:00.770375 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:14:00.770375 10416 solver.cpp:237]     Train net output #1: loss = 0.81762 (* 1 = 0.81762 loss)
I1210 13:14:00.770375 10416 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1210 13:14:06.435969 10416 solver.cpp:218] Iteration 65400 (17.6519 iter/s, 5.6651s/100 iters), loss = 1.02218
I1210 13:14:06.435969 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:14:06.435969 10416 solver.cpp:237]     Train net output #1: loss = 1.02218 (* 1 = 1.02218 loss)
I1210 13:14:06.435969 10416 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1210 13:14:11.829324  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:14:12.051344 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_65500.caffemodel
I1210 13:14:12.068344 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_65500.solverstate
I1210 13:14:12.074344 10416 solver.cpp:330] Iteration 65500, Testing net (#0)
I1210 13:14:12.074344 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:14:13.456456  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:14:13.510957 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5994
I1210 13:14:13.510957 10416 solver.cpp:397]     Test net output #1: loss = 1.52747 (* 1 = 1.52747 loss)
I1210 13:14:13.563464 10416 solver.cpp:218] Iteration 65500 (14.0309 iter/s, 7.12714s/100 iters), loss = 0.717969
I1210 13:14:13.563464 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:14:13.563464 10416 solver.cpp:237]     Train net output #1: loss = 0.71797 (* 1 = 0.71797 loss)
I1210 13:14:13.563464 10416 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1210 13:14:19.236960 10416 solver.cpp:218] Iteration 65600 (17.6277 iter/s, 5.6729s/100 iters), loss = 0.777968
I1210 13:14:19.236960 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:14:19.236960 10416 solver.cpp:237]     Train net output #1: loss = 0.777968 (* 1 = 0.777968 loss)
I1210 13:14:19.236960 10416 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1210 13:14:24.903980 10416 solver.cpp:218] Iteration 65700 (17.6482 iter/s, 5.6663s/100 iters), loss = 0.643131
I1210 13:14:24.904479 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:14:24.904479 10416 solver.cpp:237]     Train net output #1: loss = 0.643131 (* 1 = 0.643131 loss)
I1210 13:14:24.904479 10416 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1210 13:14:30.578914 10416 solver.cpp:218] Iteration 65800 (17.6233 iter/s, 5.67431s/100 iters), loss = 0.80452
I1210 13:14:30.578914 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:14:30.578914 10416 solver.cpp:237]     Train net output #1: loss = 0.80452 (* 1 = 0.80452 loss)
I1210 13:14:30.578914 10416 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1210 13:14:36.261381 10416 solver.cpp:218] Iteration 65900 (17.6007 iter/s, 5.6816s/100 iters), loss = 1.28526
I1210 13:14:36.261381 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 13:14:36.261381 10416 solver.cpp:237]     Train net output #1: loss = 1.28526 (* 1 = 1.28526 loss)
I1210 13:14:36.261381 10416 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1210 13:14:41.668822  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:14:41.891832 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_66000.caffemodel
I1210 13:14:41.912834 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_66000.solverstate
I1210 13:14:41.916838 10416 solver.cpp:330] Iteration 66000, Testing net (#0)
I1210 13:14:41.917840 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:14:43.299440  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:14:43.353948 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5771
I1210 13:14:43.353948 10416 solver.cpp:397]     Test net output #1: loss = 1.6293 (* 1 = 1.6293 loss)
I1210 13:14:43.407958 10416 solver.cpp:218] Iteration 66000 (13.9938 iter/s, 7.14603s/100 iters), loss = 0.671615
I1210 13:14:43.407958 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:14:43.407958 10416 solver.cpp:237]     Train net output #1: loss = 0.671615 (* 1 = 0.671615 loss)
I1210 13:14:43.407958 10416 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1210 13:14:49.080328 10416 solver.cpp:218] Iteration 66100 (17.6297 iter/s, 5.67223s/100 iters), loss = 0.68452
I1210 13:14:49.080328 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:14:49.080328 10416 solver.cpp:237]     Train net output #1: loss = 0.68452 (* 1 = 0.68452 loss)
I1210 13:14:49.080328 10416 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1210 13:14:54.775759 10416 solver.cpp:218] Iteration 66200 (17.5594 iter/s, 5.69496s/100 iters), loss = 0.643317
I1210 13:14:54.775759 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:14:54.775759 10416 solver.cpp:237]     Train net output #1: loss = 0.643317 (* 1 = 0.643317 loss)
I1210 13:14:54.775759 10416 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1210 13:15:00.460134 10416 solver.cpp:218] Iteration 66300 (17.5922 iter/s, 5.68434s/100 iters), loss = 0.827023
I1210 13:15:00.460134 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:15:00.460134 10416 solver.cpp:237]     Train net output #1: loss = 0.827023 (* 1 = 0.827023 loss)
I1210 13:15:00.460134 10416 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1210 13:15:06.154542 10416 solver.cpp:218] Iteration 66400 (17.5635 iter/s, 5.69362s/100 iters), loss = 0.978438
I1210 13:15:06.154542 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:15:06.154542 10416 solver.cpp:237]     Train net output #1: loss = 0.978438 (* 1 = 0.978438 loss)
I1210 13:15:06.154542 10416 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1210 13:15:11.565893  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:15:11.789903 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_66500.caffemodel
I1210 13:15:11.809907 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_66500.solverstate
I1210 13:15:11.815407 10416 solver.cpp:330] Iteration 66500, Testing net (#0)
I1210 13:15:11.815407 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:15:13.197202  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:15:13.251215 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5538
I1210 13:15:13.251215 10416 solver.cpp:397]     Test net output #1: loss = 1.71196 (* 1 = 1.71196 loss)
I1210 13:15:13.305212 10416 solver.cpp:218] Iteration 66500 (13.9858 iter/s, 7.15011s/100 iters), loss = 0.679451
I1210 13:15:13.305212 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:15:13.305212 10416 solver.cpp:237]     Train net output #1: loss = 0.679451 (* 1 = 0.679451 loss)
I1210 13:15:13.305212 10416 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1210 13:15:18.975582 10416 solver.cpp:218] Iteration 66600 (17.6378 iter/s, 5.66965s/100 iters), loss = 0.782515
I1210 13:15:18.975582 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:15:18.975582 10416 solver.cpp:237]     Train net output #1: loss = 0.782515 (* 1 = 0.782515 loss)
I1210 13:15:18.975582 10416 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1210 13:15:24.650964 10416 solver.cpp:218] Iteration 66700 (17.6189 iter/s, 5.67571s/100 iters), loss = 0.639618
I1210 13:15:24.651964 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:15:24.651964 10416 solver.cpp:237]     Train net output #1: loss = 0.639618 (* 1 = 0.639618 loss)
I1210 13:15:24.651964 10416 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1210 13:15:30.326377 10416 solver.cpp:218] Iteration 66800 (17.6217 iter/s, 5.67482s/100 iters), loss = 0.85795
I1210 13:15:30.326377 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:15:30.326377 10416 solver.cpp:237]     Train net output #1: loss = 0.857951 (* 1 = 0.857951 loss)
I1210 13:15:30.326377 10416 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1210 13:15:35.987782 10416 solver.cpp:218] Iteration 66900 (17.6667 iter/s, 5.66036s/100 iters), loss = 0.920799
I1210 13:15:35.987782 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:15:35.987782 10416 solver.cpp:237]     Train net output #1: loss = 0.920799 (* 1 = 0.920799 loss)
I1210 13:15:35.987782 10416 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1210 13:15:41.370194  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:15:41.592206 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_67000.caffemodel
I1210 13:15:41.613708 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_67000.solverstate
I1210 13:15:41.619212 10416 solver.cpp:330] Iteration 67000, Testing net (#0)
I1210 13:15:41.619212 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:15:43.000329  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:15:43.055337 10416 solver.cpp:397]     Test net output #0: accuracy = 0.574
I1210 13:15:43.055337 10416 solver.cpp:397]     Test net output #1: loss = 1.65537 (* 1 = 1.65537 loss)
I1210 13:15:43.108371 10416 solver.cpp:218] Iteration 67000 (14.0451 iter/s, 7.11991s/100 iters), loss = 0.568994
I1210 13:15:43.108371 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:15:43.108371 10416 solver.cpp:237]     Train net output #1: loss = 0.568994 (* 1 = 0.568994 loss)
I1210 13:15:43.108371 10416 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1210 13:15:48.768754 10416 solver.cpp:218] Iteration 67100 (17.6674 iter/s, 5.66014s/100 iters), loss = 0.798986
I1210 13:15:48.768754 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:15:48.768754 10416 solver.cpp:237]     Train net output #1: loss = 0.798986 (* 1 = 0.798986 loss)
I1210 13:15:48.768754 10416 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1210 13:15:54.427160 10416 solver.cpp:218] Iteration 67200 (17.6728 iter/s, 5.65842s/100 iters), loss = 0.600514
I1210 13:15:54.427160 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:15:54.427160 10416 solver.cpp:237]     Train net output #1: loss = 0.600514 (* 1 = 0.600514 loss)
I1210 13:15:54.427160 10416 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1210 13:16:00.105068 10416 solver.cpp:218] Iteration 67300 (17.6151 iter/s, 5.67693s/100 iters), loss = 0.926495
I1210 13:16:00.105068 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:16:00.105068 10416 solver.cpp:237]     Train net output #1: loss = 0.926495 (* 1 = 0.926495 loss)
I1210 13:16:00.105068 10416 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1210 13:16:05.789000 10416 solver.cpp:218] Iteration 67400 (17.5948 iter/s, 5.68351s/100 iters), loss = 0.978206
I1210 13:16:05.789000 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 13:16:05.789000 10416 solver.cpp:237]     Train net output #1: loss = 0.978206 (* 1 = 0.978206 loss)
I1210 13:16:05.789000 10416 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1210 13:16:11.194414  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:16:11.417430 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_67500.caffemodel
I1210 13:16:11.436434 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_67500.solverstate
I1210 13:16:11.441433 10416 solver.cpp:330] Iteration 67500, Testing net (#0)
I1210 13:16:11.441433 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:16:12.824579  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:16:12.878578 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5821
I1210 13:16:12.878578 10416 solver.cpp:397]     Test net output #1: loss = 1.55554 (* 1 = 1.55554 loss)
I1210 13:16:12.932585 10416 solver.cpp:218] Iteration 67500 (13.9993 iter/s, 7.14322s/100 iters), loss = 0.708787
I1210 13:16:12.932585 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:16:12.932585 10416 solver.cpp:237]     Train net output #1: loss = 0.708787 (* 1 = 0.708787 loss)
I1210 13:16:12.932585 10416 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1210 13:16:18.602063 10416 solver.cpp:218] Iteration 67600 (17.6388 iter/s, 5.66931s/100 iters), loss = 0.671013
I1210 13:16:18.602063 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:16:18.602063 10416 solver.cpp:237]     Train net output #1: loss = 0.671013 (* 1 = 0.671013 loss)
I1210 13:16:18.602063 10416 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1210 13:16:24.269549 10416 solver.cpp:218] Iteration 67700 (17.6461 iter/s, 5.66696s/100 iters), loss = 0.70207
I1210 13:16:24.269549 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:16:24.269549 10416 solver.cpp:237]     Train net output #1: loss = 0.70207 (* 1 = 0.70207 loss)
I1210 13:16:24.269549 10416 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1210 13:16:29.936975 10416 solver.cpp:218] Iteration 67800 (17.6467 iter/s, 5.66678s/100 iters), loss = 0.832453
I1210 13:16:29.936975 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:16:29.936975 10416 solver.cpp:237]     Train net output #1: loss = 0.832453 (* 1 = 0.832453 loss)
I1210 13:16:29.936975 10416 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1210 13:16:35.596436 10416 solver.cpp:218] Iteration 67900 (17.6713 iter/s, 5.65889s/100 iters), loss = 0.988061
I1210 13:16:35.596436 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:16:35.596436 10416 solver.cpp:237]     Train net output #1: loss = 0.988061 (* 1 = 0.988061 loss)
I1210 13:16:35.596436 10416 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1210 13:16:40.983860  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:16:41.205878 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_68000.caffemodel
I1210 13:16:41.224890 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_68000.solverstate
I1210 13:16:41.229889 10416 solver.cpp:330] Iteration 68000, Testing net (#0)
I1210 13:16:41.229889 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:16:42.615504  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:16:42.669008 10416 solver.cpp:397]     Test net output #0: accuracy = 0.596
I1210 13:16:42.669008 10416 solver.cpp:397]     Test net output #1: loss = 1.52445 (* 1 = 1.52445 loss)
I1210 13:16:42.722510 10416 solver.cpp:218] Iteration 68000 (14.0335 iter/s, 7.12583s/100 iters), loss = 0.595093
I1210 13:16:42.723011 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:16:42.723011 10416 solver.cpp:237]     Train net output #1: loss = 0.595093 (* 1 = 0.595093 loss)
I1210 13:16:42.723011 10416 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1210 13:16:48.408941 10416 solver.cpp:218] Iteration 68100 (17.588 iter/s, 5.68571s/100 iters), loss = 0.753499
I1210 13:16:48.408941 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:16:48.408941 10416 solver.cpp:237]     Train net output #1: loss = 0.7535 (* 1 = 0.7535 loss)
I1210 13:16:48.408941 10416 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1210 13:16:54.100929 10416 solver.cpp:218] Iteration 68200 (17.5677 iter/s, 5.69226s/100 iters), loss = 0.575435
I1210 13:16:54.100929 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:16:54.100929 10416 solver.cpp:237]     Train net output #1: loss = 0.575435 (* 1 = 0.575435 loss)
I1210 13:16:54.101929 10416 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1210 13:16:59.787338 10416 solver.cpp:218] Iteration 68300 (17.589 iter/s, 5.68537s/100 iters), loss = 0.872121
I1210 13:16:59.787338 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:16:59.787338 10416 solver.cpp:237]     Train net output #1: loss = 0.872122 (* 1 = 0.872122 loss)
I1210 13:16:59.787338 10416 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1210 13:17:05.482729 10416 solver.cpp:218] Iteration 68400 (17.5576 iter/s, 5.69555s/100 iters), loss = 0.805376
I1210 13:17:05.482729 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:17:05.483731 10416 solver.cpp:237]     Train net output #1: loss = 0.805376 (* 1 = 0.805376 loss)
I1210 13:17:05.483731 10416 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1210 13:17:10.891994  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:17:11.115519 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_68500.caffemodel
I1210 13:17:11.135025 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_68500.solverstate
I1210 13:17:11.140024 10416 solver.cpp:330] Iteration 68500, Testing net (#0)
I1210 13:17:11.140024 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:17:12.524109  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:17:12.578111 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6075
I1210 13:17:12.578111 10416 solver.cpp:397]     Test net output #1: loss = 1.49536 (* 1 = 1.49536 loss)
I1210 13:17:12.631115 10416 solver.cpp:218] Iteration 68500 (13.9919 iter/s, 7.14702s/100 iters), loss = 0.644155
I1210 13:17:12.631115 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:17:12.631115 10416 solver.cpp:237]     Train net output #1: loss = 0.644156 (* 1 = 0.644156 loss)
I1210 13:17:12.631115 10416 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1210 13:17:18.312989 10416 solver.cpp:218] Iteration 68600 (17.6007 iter/s, 5.6816s/100 iters), loss = 0.721959
I1210 13:17:18.312989 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:17:18.312989 10416 solver.cpp:237]     Train net output #1: loss = 0.721959 (* 1 = 0.721959 loss)
I1210 13:17:18.312989 10416 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1210 13:17:23.997207 10416 solver.cpp:218] Iteration 68700 (17.5945 iter/s, 5.6836s/100 iters), loss = 0.741324
I1210 13:17:23.997207 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:17:23.997207 10416 solver.cpp:237]     Train net output #1: loss = 0.741324 (* 1 = 0.741324 loss)
I1210 13:17:23.997207 10416 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1210 13:17:29.682624 10416 solver.cpp:218] Iteration 68800 (17.5879 iter/s, 5.68573s/100 iters), loss = 0.783086
I1210 13:17:29.682624 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:17:29.682624 10416 solver.cpp:237]     Train net output #1: loss = 0.783086 (* 1 = 0.783086 loss)
I1210 13:17:29.682624 10416 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1210 13:17:35.372035 10416 solver.cpp:218] Iteration 68900 (17.5785 iter/s, 5.68878s/100 iters), loss = 0.82754
I1210 13:17:35.372035 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:17:35.372035 10416 solver.cpp:237]     Train net output #1: loss = 0.827541 (* 1 = 0.827541 loss)
I1210 13:17:35.372035 10416 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1210 13:17:40.788395  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:17:41.012912 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_69000.caffemodel
I1210 13:17:41.030418 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_69000.solverstate
I1210 13:17:41.035418 10416 solver.cpp:330] Iteration 69000, Testing net (#0)
I1210 13:17:41.035418 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:17:42.420064  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:17:42.474570 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5754
I1210 13:17:42.474570 10416 solver.cpp:397]     Test net output #1: loss = 1.65046 (* 1 = 1.65046 loss)
I1210 13:17:42.528573 10416 solver.cpp:218] Iteration 69000 (13.9751 iter/s, 7.1556s/100 iters), loss = 0.608416
I1210 13:17:42.528573 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:17:42.528573 10416 solver.cpp:237]     Train net output #1: loss = 0.608416 (* 1 = 0.608416 loss)
I1210 13:17:42.528573 10416 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1210 13:17:48.209036 10416 solver.cpp:218] Iteration 69100 (17.6057 iter/s, 5.67999s/100 iters), loss = 0.761145
I1210 13:17:48.209036 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:17:48.209036 10416 solver.cpp:237]     Train net output #1: loss = 0.761145 (* 1 = 0.761145 loss)
I1210 13:17:48.209036 10416 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1210 13:17:53.894500 10416 solver.cpp:218] Iteration 69200 (17.5908 iter/s, 5.6848s/100 iters), loss = 0.689586
I1210 13:17:53.894500 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:17:53.894500 10416 solver.cpp:237]     Train net output #1: loss = 0.689586 (* 1 = 0.689586 loss)
I1210 13:17:53.894500 10416 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1210 13:17:59.577942 10416 solver.cpp:218] Iteration 69300 (17.5957 iter/s, 5.68319s/100 iters), loss = 0.862348
I1210 13:17:59.577942 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:17:59.577942 10416 solver.cpp:237]     Train net output #1: loss = 0.862348 (* 1 = 0.862348 loss)
I1210 13:17:59.577942 10416 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1210 13:18:05.261392 10416 solver.cpp:218] Iteration 69400 (17.5942 iter/s, 5.68369s/100 iters), loss = 0.801705
I1210 13:18:05.261392 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:18:05.262393 10416 solver.cpp:237]     Train net output #1: loss = 0.801705 (* 1 = 0.801705 loss)
I1210 13:18:05.262393 10416 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1210 13:18:10.666805  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:18:10.890813 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_69500.caffemodel
I1210 13:18:10.909812 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_69500.solverstate
I1210 13:18:10.915817 10416 solver.cpp:330] Iteration 69500, Testing net (#0)
I1210 13:18:10.915817 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:18:12.299917  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:18:12.353924 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6008
I1210 13:18:12.353924 10416 solver.cpp:397]     Test net output #1: loss = 1.50677 (* 1 = 1.50677 loss)
I1210 13:18:12.406924 10416 solver.cpp:218] Iteration 69500 (13.9957 iter/s, 7.14504s/100 iters), loss = 0.652289
I1210 13:18:12.407923 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:18:12.407923 10416 solver.cpp:237]     Train net output #1: loss = 0.652289 (* 1 = 0.652289 loss)
I1210 13:18:12.407923 10416 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1210 13:18:18.088313 10416 solver.cpp:218] Iteration 69600 (17.6054 iter/s, 5.68007s/100 iters), loss = 0.774725
I1210 13:18:18.088313 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:18:18.088313 10416 solver.cpp:237]     Train net output #1: loss = 0.774725 (* 1 = 0.774725 loss)
I1210 13:18:18.088313 10416 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1210 13:18:23.769770 10416 solver.cpp:218] Iteration 69700 (17.6018 iter/s, 5.68125s/100 iters), loss = 0.664476
I1210 13:18:23.769770 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:18:23.769770 10416 solver.cpp:237]     Train net output #1: loss = 0.664476 (* 1 = 0.664476 loss)
I1210 13:18:23.769770 10416 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1210 13:18:29.458212 10416 solver.cpp:218] Iteration 69800 (17.5792 iter/s, 5.68853s/100 iters), loss = 0.854544
I1210 13:18:29.458212 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:18:29.458212 10416 solver.cpp:237]     Train net output #1: loss = 0.854544 (* 1 = 0.854544 loss)
I1210 13:18:29.458212 10416 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1210 13:18:35.140619 10416 solver.cpp:218] Iteration 69900 (17.6006 iter/s, 5.68161s/100 iters), loss = 0.905671
I1210 13:18:35.141119 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:18:35.141119 10416 solver.cpp:237]     Train net output #1: loss = 0.905671 (* 1 = 0.905671 loss)
I1210 13:18:35.141119 10416 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1210 13:18:40.535982  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:18:40.759997 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_70000.caffemodel
I1210 13:18:40.778997 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_70000.solverstate
I1210 13:18:40.783998 10416 solver.cpp:330] Iteration 70000, Testing net (#0)
I1210 13:18:40.783998 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:18:42.167112  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:18:42.222116 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5583
I1210 13:18:42.222116 10416 solver.cpp:397]     Test net output #1: loss = 1.71346 (* 1 = 1.71346 loss)
I1210 13:18:42.276120 10416 solver.cpp:218] Iteration 70000 (14.0146 iter/s, 7.13543s/100 iters), loss = 0.772912
I1210 13:18:42.277120 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:18:42.277120 10416 solver.cpp:237]     Train net output #1: loss = 0.772912 (* 1 = 0.772912 loss)
I1210 13:18:42.277120 10416 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1210 13:18:47.961580 10416 solver.cpp:218] Iteration 70100 (17.5929 iter/s, 5.68412s/100 iters), loss = 0.762984
I1210 13:18:47.961580 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:18:47.961580 10416 solver.cpp:237]     Train net output #1: loss = 0.762984 (* 1 = 0.762984 loss)
I1210 13:18:47.961580 10416 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1210 13:18:53.647147 10416 solver.cpp:218] Iteration 70200 (17.5877 iter/s, 5.68579s/100 iters), loss = 0.635058
I1210 13:18:53.647147 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:18:53.647147 10416 solver.cpp:237]     Train net output #1: loss = 0.635058 (* 1 = 0.635058 loss)
I1210 13:18:53.647147 10416 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1210 13:18:59.337345 10416 solver.cpp:218] Iteration 70300 (17.5747 iter/s, 5.68999s/100 iters), loss = 0.806008
I1210 13:18:59.338346 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:18:59.338346 10416 solver.cpp:237]     Train net output #1: loss = 0.806008 (* 1 = 0.806008 loss)
I1210 13:18:59.338346 10416 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1210 13:19:05.024345 10416 solver.cpp:218] Iteration 70400 (17.5876 iter/s, 5.68583s/100 iters), loss = 1.01678
I1210 13:19:05.024345 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:19:05.024345 10416 solver.cpp:237]     Train net output #1: loss = 1.01678 (* 1 = 1.01678 loss)
I1210 13:19:05.024345 10416 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1210 13:19:10.425348  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:19:10.644937 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_70500.caffemodel
I1210 13:19:10.659930 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_70500.solverstate
I1210 13:19:10.664935 10416 solver.cpp:330] Iteration 70500, Testing net (#0)
I1210 13:19:10.664935 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:19:12.046257  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:19:12.100262 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5774
I1210 13:19:12.101263 10416 solver.cpp:397]     Test net output #1: loss = 1.6183 (* 1 = 1.6183 loss)
I1210 13:19:12.156304 10416 solver.cpp:218] Iteration 70500 (14.0223 iter/s, 7.13148s/100 iters), loss = 0.714035
I1210 13:19:12.156304 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:19:12.156304 10416 solver.cpp:237]     Train net output #1: loss = 0.714035 (* 1 = 0.714035 loss)
I1210 13:19:12.156304 10416 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1210 13:19:17.837888 10416 solver.cpp:218] Iteration 70600 (17.6029 iter/s, 5.68089s/100 iters), loss = 0.772166
I1210 13:19:17.837888 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:19:17.837888 10416 solver.cpp:237]     Train net output #1: loss = 0.772166 (* 1 = 0.772166 loss)
I1210 13:19:17.837888 10416 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1210 13:19:23.522150 10416 solver.cpp:218] Iteration 70700 (17.5937 iter/s, 5.68384s/100 iters), loss = 0.611042
I1210 13:19:23.522673 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:19:23.522673 10416 solver.cpp:237]     Train net output #1: loss = 0.611042 (* 1 = 0.611042 loss)
I1210 13:19:23.522673 10416 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1210 13:19:29.211933 10416 solver.cpp:218] Iteration 70800 (17.5775 iter/s, 5.68909s/100 iters), loss = 1.03012
I1210 13:19:29.211933 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 13:19:29.211933 10416 solver.cpp:237]     Train net output #1: loss = 1.03012 (* 1 = 1.03012 loss)
I1210 13:19:29.211933 10416 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1210 13:19:34.900388 10416 solver.cpp:218] Iteration 70900 (17.5813 iter/s, 5.68787s/100 iters), loss = 0.879223
I1210 13:19:34.900388 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:19:34.900388 10416 solver.cpp:237]     Train net output #1: loss = 0.879223 (* 1 = 0.879223 loss)
I1210 13:19:34.900388 10416 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1210 13:19:40.307840  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:19:40.530858 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_71000.caffemodel
I1210 13:19:40.549861 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_71000.solverstate
I1210 13:19:40.554862 10416 solver.cpp:330] Iteration 71000, Testing net (#0)
I1210 13:19:40.554862 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:19:41.939497  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:19:41.993000 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5858
I1210 13:19:41.993000 10416 solver.cpp:397]     Test net output #1: loss = 1.61041 (* 1 = 1.61041 loss)
I1210 13:19:42.049008 10416 solver.cpp:218] Iteration 71000 (13.99 iter/s, 7.14796s/100 iters), loss = 0.635133
I1210 13:19:42.049008 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:19:42.049008 10416 solver.cpp:237]     Train net output #1: loss = 0.635133 (* 1 = 0.635133 loss)
I1210 13:19:42.049008 10416 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1210 13:19:47.725420 10416 solver.cpp:218] Iteration 71100 (17.617 iter/s, 5.67633s/100 iters), loss = 0.657347
I1210 13:19:47.725921 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:19:47.725921 10416 solver.cpp:237]     Train net output #1: loss = 0.657347 (* 1 = 0.657347 loss)
I1210 13:19:47.725921 10416 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1210 13:19:53.398875 10416 solver.cpp:218] Iteration 71200 (17.6279 iter/s, 5.67281s/100 iters), loss = 0.650677
I1210 13:19:53.398875 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:19:53.398875 10416 solver.cpp:237]     Train net output #1: loss = 0.650677 (* 1 = 0.650677 loss)
I1210 13:19:53.398875 10416 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1210 13:19:59.071194 10416 solver.cpp:218] Iteration 71300 (17.6319 iter/s, 5.67154s/100 iters), loss = 0.769636
I1210 13:19:59.071194 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:19:59.071194 10416 solver.cpp:237]     Train net output #1: loss = 0.769636 (* 1 = 0.769636 loss)
I1210 13:19:59.071194 10416 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1210 13:20:04.773772 10416 solver.cpp:218] Iteration 71400 (17.5362 iter/s, 5.70247s/100 iters), loss = 0.923039
I1210 13:20:04.773772 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:20:04.773772 10416 solver.cpp:237]     Train net output #1: loss = 0.923039 (* 1 = 0.923039 loss)
I1210 13:20:04.773772 10416 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1210 13:20:10.178206  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:20:10.401219 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_71500.caffemodel
I1210 13:20:10.421722 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_71500.solverstate
I1210 13:20:10.427228 10416 solver.cpp:330] Iteration 71500, Testing net (#0)
I1210 13:20:10.428227 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:20:11.815330  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:20:11.869334 10416 solver.cpp:397]     Test net output #0: accuracy = 0.585
I1210 13:20:11.869334 10416 solver.cpp:397]     Test net output #1: loss = 1.5789 (* 1 = 1.5789 loss)
I1210 13:20:11.923339 10416 solver.cpp:218] Iteration 71500 (13.9874 iter/s, 7.1493s/100 iters), loss = 0.63022
I1210 13:20:11.923339 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:20:11.923339 10416 solver.cpp:237]     Train net output #1: loss = 0.63022 (* 1 = 0.63022 loss)
I1210 13:20:11.923339 10416 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1210 13:20:17.603807 10416 solver.cpp:218] Iteration 71600 (17.6056 iter/s, 5.68002s/100 iters), loss = 0.693585
I1210 13:20:17.603807 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:20:17.603807 10416 solver.cpp:237]     Train net output #1: loss = 0.693585 (* 1 = 0.693585 loss)
I1210 13:20:17.603807 10416 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1210 13:20:23.280269 10416 solver.cpp:218] Iteration 71700 (17.6188 iter/s, 5.67577s/100 iters), loss = 0.619916
I1210 13:20:23.280269 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:20:23.280269 10416 solver.cpp:237]     Train net output #1: loss = 0.619916 (* 1 = 0.619916 loss)
I1210 13:20:23.280269 10416 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1210 13:20:28.958706 10416 solver.cpp:218] Iteration 71800 (17.6128 iter/s, 5.6777s/100 iters), loss = 0.831067
I1210 13:20:28.958706 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:20:28.958706 10416 solver.cpp:237]     Train net output #1: loss = 0.831067 (* 1 = 0.831067 loss)
I1210 13:20:28.958706 10416 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1210 13:20:34.644183 10416 solver.cpp:218] Iteration 71900 (17.5899 iter/s, 5.68508s/100 iters), loss = 0.938407
I1210 13:20:34.644183 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:20:34.644183 10416 solver.cpp:237]     Train net output #1: loss = 0.938407 (* 1 = 0.938407 loss)
I1210 13:20:34.644183 10416 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1210 13:20:40.047596  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:20:40.271611 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_72000.caffemodel
I1210 13:20:40.290611 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_72000.solverstate
I1210 13:20:40.296612 10416 solver.cpp:330] Iteration 72000, Testing net (#0)
I1210 13:20:40.296612 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:20:41.680703  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:20:41.733711 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5786
I1210 13:20:41.733711 10416 solver.cpp:397]     Test net output #1: loss = 1.63625 (* 1 = 1.63625 loss)
I1210 13:20:41.787710 10416 solver.cpp:218] Iteration 72000 (13.9986 iter/s, 7.14359s/100 iters), loss = 0.79621
I1210 13:20:41.787710 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:20:41.788712 10416 solver.cpp:237]     Train net output #1: loss = 0.79621 (* 1 = 0.79621 loss)
I1210 13:20:41.788712 10416 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1210 13:20:47.478104 10416 solver.cpp:218] Iteration 72100 (17.5767 iter/s, 5.68934s/100 iters), loss = 0.720545
I1210 13:20:47.478104 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:20:47.478104 10416 solver.cpp:237]     Train net output #1: loss = 0.720545 (* 1 = 0.720545 loss)
I1210 13:20:47.478104 10416 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1210 13:20:53.160562 10416 solver.cpp:218] Iteration 72200 (17.5996 iter/s, 5.68194s/100 iters), loss = 0.69303
I1210 13:20:53.160562 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:20:53.160562 10416 solver.cpp:237]     Train net output #1: loss = 0.69303 (* 1 = 0.69303 loss)
I1210 13:20:53.160562 10416 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1210 13:20:58.845962 10416 solver.cpp:218] Iteration 72300 (17.5899 iter/s, 5.68508s/100 iters), loss = 0.841421
I1210 13:20:58.845962 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:20:58.845962 10416 solver.cpp:237]     Train net output #1: loss = 0.841422 (* 1 = 0.841422 loss)
I1210 13:20:58.845962 10416 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1210 13:21:04.532269 10416 solver.cpp:218] Iteration 72400 (17.5869 iter/s, 5.68606s/100 iters), loss = 0.805662
I1210 13:21:04.532269 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:21:04.532269 10416 solver.cpp:237]     Train net output #1: loss = 0.805662 (* 1 = 0.805662 loss)
I1210 13:21:04.532269 10416 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1210 13:21:09.922617  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:21:10.146633 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_72500.caffemodel
I1210 13:21:10.165633 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_72500.solverstate
I1210 13:21:10.170634 10416 solver.cpp:330] Iteration 72500, Testing net (#0)
I1210 13:21:10.170634 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:21:11.557739  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:21:11.611750 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5865
I1210 13:21:11.612241 10416 solver.cpp:397]     Test net output #1: loss = 1.56516 (* 1 = 1.56516 loss)
I1210 13:21:11.664741 10416 solver.cpp:218] Iteration 72500 (14.0218 iter/s, 7.13177s/100 iters), loss = 0.680532
I1210 13:21:11.664741 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:21:11.664741 10416 solver.cpp:237]     Train net output #1: loss = 0.680532 (* 1 = 0.680532 loss)
I1210 13:21:11.664741 10416 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1210 13:21:17.332146 10416 solver.cpp:218] Iteration 72600 (17.6456 iter/s, 5.66714s/100 iters), loss = 0.772167
I1210 13:21:17.332146 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:21:17.332146 10416 solver.cpp:237]     Train net output #1: loss = 0.772167 (* 1 = 0.772167 loss)
I1210 13:21:17.332146 10416 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1210 13:21:23.000569 10416 solver.cpp:218] Iteration 72700 (17.6444 iter/s, 5.66751s/100 iters), loss = 0.615485
I1210 13:21:23.000569 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:21:23.000569 10416 solver.cpp:237]     Train net output #1: loss = 0.615485 (* 1 = 0.615485 loss)
I1210 13:21:23.000569 10416 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1210 13:21:28.668048 10416 solver.cpp:218] Iteration 72800 (17.6433 iter/s, 5.66786s/100 iters), loss = 0.898508
I1210 13:21:28.669049 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 13:21:28.669049 10416 solver.cpp:237]     Train net output #1: loss = 0.898508 (* 1 = 0.898508 loss)
I1210 13:21:28.669049 10416 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1210 13:21:34.331492 10416 solver.cpp:218] Iteration 72900 (17.66 iter/s, 5.66251s/100 iters), loss = 0.751489
I1210 13:21:34.331492 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:21:34.331492 10416 solver.cpp:237]     Train net output #1: loss = 0.751489 (* 1 = 0.751489 loss)
I1210 13:21:34.331492 10416 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1210 13:21:39.722380  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:21:39.943897 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_73000.caffemodel
I1210 13:21:39.964897 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_73000.solverstate
I1210 13:21:39.969897 10416 solver.cpp:330] Iteration 73000, Testing net (#0)
I1210 13:21:39.969897 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:21:41.353030  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:21:41.407030 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6042
I1210 13:21:41.407030 10416 solver.cpp:397]     Test net output #1: loss = 1.47884 (* 1 = 1.47884 loss)
I1210 13:21:41.461038 10416 solver.cpp:218] Iteration 73000 (14.0281 iter/s, 7.12854s/100 iters), loss = 0.701306
I1210 13:21:41.461038 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:21:41.461038 10416 solver.cpp:237]     Train net output #1: loss = 0.701306 (* 1 = 0.701306 loss)
I1210 13:21:41.461038 10416 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1210 13:21:47.139492 10416 solver.cpp:218] Iteration 73100 (17.6108 iter/s, 5.67832s/100 iters), loss = 0.733912
I1210 13:21:47.139492 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:21:47.139492 10416 solver.cpp:237]     Train net output #1: loss = 0.733912 (* 1 = 0.733912 loss)
I1210 13:21:47.139492 10416 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1210 13:21:52.827100 10416 solver.cpp:218] Iteration 73200 (17.584 iter/s, 5.68699s/100 iters), loss = 0.683771
I1210 13:21:52.827100 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:21:52.827100 10416 solver.cpp:237]     Train net output #1: loss = 0.683771 (* 1 = 0.683771 loss)
I1210 13:21:52.827100 10416 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1210 13:21:58.503540 10416 solver.cpp:218] Iteration 73300 (17.616 iter/s, 5.67665s/100 iters), loss = 0.902448
I1210 13:21:58.503540 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:21:58.503540 10416 solver.cpp:237]     Train net output #1: loss = 0.902448 (* 1 = 0.902448 loss)
I1210 13:21:58.503540 10416 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1210 13:22:04.178910 10416 solver.cpp:218] Iteration 73400 (17.621 iter/s, 5.67504s/100 iters), loss = 0.901182
I1210 13:22:04.178910 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:22:04.178910 10416 solver.cpp:237]     Train net output #1: loss = 0.901183 (* 1 = 0.901183 loss)
I1210 13:22:04.179910 10416 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1210 13:22:09.574319  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:22:09.797338 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_73500.caffemodel
I1210 13:22:09.816843 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_73500.solverstate
I1210 13:22:09.822844 10416 solver.cpp:330] Iteration 73500, Testing net (#0)
I1210 13:22:09.822844 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:22:11.204496  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:22:11.259325 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5757
I1210 13:22:11.259325 10416 solver.cpp:397]     Test net output #1: loss = 1.6068 (* 1 = 1.6068 loss)
I1210 13:22:11.313323 10416 solver.cpp:218] Iteration 73500 (14.0191 iter/s, 7.13315s/100 iters), loss = 0.697876
I1210 13:22:11.313323 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:22:11.313323 10416 solver.cpp:237]     Train net output #1: loss = 0.697877 (* 1 = 0.697877 loss)
I1210 13:22:11.313323 10416 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1210 13:22:16.980245 10416 solver.cpp:218] Iteration 73600 (17.6453 iter/s, 5.66723s/100 iters), loss = 0.699543
I1210 13:22:16.980245 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:22:16.980245 10416 solver.cpp:237]     Train net output #1: loss = 0.699544 (* 1 = 0.699544 loss)
I1210 13:22:16.980245 10416 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1210 13:22:22.646806 10416 solver.cpp:218] Iteration 73700 (17.6502 iter/s, 5.66566s/100 iters), loss = 0.650938
I1210 13:22:22.646806 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:22:22.646806 10416 solver.cpp:237]     Train net output #1: loss = 0.650938 (* 1 = 0.650938 loss)
I1210 13:22:22.646806 10416 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1210 13:22:28.320726 10416 solver.cpp:218] Iteration 73800 (17.6277 iter/s, 5.67288s/100 iters), loss = 0.910881
I1210 13:22:28.320726 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:22:28.320726 10416 solver.cpp:237]     Train net output #1: loss = 0.910881 (* 1 = 0.910881 loss)
I1210 13:22:28.320726 10416 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1210 13:22:33.980676 10416 solver.cpp:218] Iteration 73900 (17.6693 iter/s, 5.65954s/100 iters), loss = 0.883382
I1210 13:22:33.980676 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:22:33.980676 10416 solver.cpp:237]     Train net output #1: loss = 0.883382 (* 1 = 0.883382 loss)
I1210 13:22:33.980676 10416 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1210 13:22:39.379096  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:22:39.601109 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_74000.caffemodel
I1210 13:22:39.621110 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_74000.solverstate
I1210 13:22:39.626111 10416 solver.cpp:330] Iteration 74000, Testing net (#0)
I1210 13:22:39.626111 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:22:41.010231  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:22:41.065235 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5997
I1210 13:22:41.065235 10416 solver.cpp:397]     Test net output #1: loss = 1.51606 (* 1 = 1.51606 loss)
I1210 13:22:41.120239 10416 solver.cpp:218] Iteration 74000 (14.0078 iter/s, 7.13888s/100 iters), loss = 0.722647
I1210 13:22:41.120239 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:22:41.120239 10416 solver.cpp:237]     Train net output #1: loss = 0.722648 (* 1 = 0.722648 loss)
I1210 13:22:41.120239 10416 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1210 13:22:46.801110 10416 solver.cpp:218] Iteration 74100 (17.605 iter/s, 5.68021s/100 iters), loss = 0.773717
I1210 13:22:46.801110 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:22:46.801110 10416 solver.cpp:237]     Train net output #1: loss = 0.773718 (* 1 = 0.773718 loss)
I1210 13:22:46.801110 10416 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1210 13:22:52.484135 10416 solver.cpp:218] Iteration 74200 (17.5966 iter/s, 5.68292s/100 iters), loss = 0.664781
I1210 13:22:52.484135 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:22:52.484135 10416 solver.cpp:237]     Train net output #1: loss = 0.664781 (* 1 = 0.664781 loss)
I1210 13:22:52.484135 10416 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1210 13:22:58.161587 10416 solver.cpp:218] Iteration 74300 (17.6137 iter/s, 5.67739s/100 iters), loss = 0.838477
I1210 13:22:58.161587 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:22:58.161587 10416 solver.cpp:237]     Train net output #1: loss = 0.838478 (* 1 = 0.838478 loss)
I1210 13:22:58.161587 10416 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1210 13:23:03.834277 10416 solver.cpp:218] Iteration 74400 (17.6315 iter/s, 5.67166s/100 iters), loss = 0.821541
I1210 13:23:03.834277 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:23:03.834277 10416 solver.cpp:237]     Train net output #1: loss = 0.821541 (* 1 = 0.821541 loss)
I1210 13:23:03.834277 10416 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1210 13:23:09.235671  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:23:09.458765 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_74500.caffemodel
I1210 13:23:09.474782 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_74500.solverstate
I1210 13:23:09.479782 10416 solver.cpp:330] Iteration 74500, Testing net (#0)
I1210 13:23:09.479782 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:23:10.856946  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:23:10.911469 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6012
I1210 13:23:10.911469 10416 solver.cpp:397]     Test net output #1: loss = 1.47471 (* 1 = 1.47471 loss)
I1210 13:23:10.964507 10416 solver.cpp:218] Iteration 74500 (14.0245 iter/s, 7.13039s/100 iters), loss = 0.616509
I1210 13:23:10.965507 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:23:10.965507 10416 solver.cpp:237]     Train net output #1: loss = 0.616509 (* 1 = 0.616509 loss)
I1210 13:23:10.965507 10416 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1210 13:23:16.627513 10416 solver.cpp:218] Iteration 74600 (17.6628 iter/s, 5.66162s/100 iters), loss = 0.598462
I1210 13:23:16.627513 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:23:16.627513 10416 solver.cpp:237]     Train net output #1: loss = 0.598462 (* 1 = 0.598462 loss)
I1210 13:23:16.627513 10416 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1210 13:23:22.293334 10416 solver.cpp:218] Iteration 74700 (17.6487 iter/s, 5.66614s/100 iters), loss = 0.563884
I1210 13:23:22.293334 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:23:22.293334 10416 solver.cpp:237]     Train net output #1: loss = 0.563884 (* 1 = 0.563884 loss)
I1210 13:23:22.293334 10416 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1210 13:23:27.959832 10416 solver.cpp:218] Iteration 74800 (17.6511 iter/s, 5.66538s/100 iters), loss = 0.862782
I1210 13:23:27.959832 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:23:27.959832 10416 solver.cpp:237]     Train net output #1: loss = 0.862782 (* 1 = 0.862782 loss)
I1210 13:23:27.959832 10416 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1210 13:23:33.615370 10416 solver.cpp:218] Iteration 74900 (17.681 iter/s, 5.65578s/100 iters), loss = 0.923977
I1210 13:23:33.615370 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:23:33.615370 10416 solver.cpp:237]     Train net output #1: loss = 0.923978 (* 1 = 0.923978 loss)
I1210 13:23:33.615370 10416 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1210 13:23:38.997949  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:23:39.221042 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_75000.caffemodel
I1210 13:23:39.240037 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_75000.solverstate
I1210 13:23:39.245043 10416 solver.cpp:330] Iteration 75000, Testing net (#0)
I1210 13:23:39.245043 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:23:40.627894  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:23:40.681417 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5779
I1210 13:23:40.681417 10416 solver.cpp:397]     Test net output #1: loss = 1.62767 (* 1 = 1.62767 loss)
I1210 13:23:40.734417 10416 solver.cpp:218] Iteration 75000 (14.0482 iter/s, 7.11836s/100 iters), loss = 0.566349
I1210 13:23:40.734417 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:23:40.734417 10416 solver.cpp:237]     Train net output #1: loss = 0.566349 (* 1 = 0.566349 loss)
I1210 13:23:40.734417 10416 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1210 13:23:46.406399 10416 solver.cpp:218] Iteration 75100 (17.6311 iter/s, 5.67179s/100 iters), loss = 0.711963
I1210 13:23:46.406399 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:23:46.406399 10416 solver.cpp:237]     Train net output #1: loss = 0.711963 (* 1 = 0.711963 loss)
I1210 13:23:46.406399 10416 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1210 13:23:52.075453 10416 solver.cpp:218] Iteration 75200 (17.6425 iter/s, 5.66814s/100 iters), loss = 0.666616
I1210 13:23:52.075953 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:23:52.075953 10416 solver.cpp:237]     Train net output #1: loss = 0.666616 (* 1 = 0.666616 loss)
I1210 13:23:52.075953 10416 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1210 13:23:57.762308 10416 solver.cpp:218] Iteration 75300 (17.587 iter/s, 5.68601s/100 iters), loss = 0.916908
I1210 13:23:57.762308 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:23:57.762308 10416 solver.cpp:237]     Train net output #1: loss = 0.916909 (* 1 = 0.916909 loss)
I1210 13:23:57.762308 10416 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1210 13:24:03.437644 10416 solver.cpp:218] Iteration 75400 (17.6199 iter/s, 5.67541s/100 iters), loss = 0.876523
I1210 13:24:03.437644 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:24:03.437644 10416 solver.cpp:237]     Train net output #1: loss = 0.876523 (* 1 = 0.876523 loss)
I1210 13:24:03.437644 10416 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1210 13:24:08.834411  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:24:09.056532 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_75500.caffemodel
I1210 13:24:09.075042 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_75500.solverstate
I1210 13:24:09.080055 10416 solver.cpp:330] Iteration 75500, Testing net (#0)
I1210 13:24:09.080055 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:24:10.456156  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:24:10.510185 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5966
I1210 13:24:10.510185 10416 solver.cpp:397]     Test net output #1: loss = 1.54898 (* 1 = 1.54898 loss)
I1210 13:24:10.564198 10416 solver.cpp:218] Iteration 75500 (14.0323 iter/s, 7.1264s/100 iters), loss = 0.657535
I1210 13:24:10.564198 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:24:10.564198 10416 solver.cpp:237]     Train net output #1: loss = 0.657535 (* 1 = 0.657535 loss)
I1210 13:24:10.564198 10416 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1210 13:24:16.221401 10416 solver.cpp:218] Iteration 75600 (17.6799 iter/s, 5.65614s/100 iters), loss = 0.701099
I1210 13:24:16.221401 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:24:16.221401 10416 solver.cpp:237]     Train net output #1: loss = 0.701099 (* 1 = 0.701099 loss)
I1210 13:24:16.221401 10416 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1210 13:24:21.878479 10416 solver.cpp:218] Iteration 75700 (17.6787 iter/s, 5.65653s/100 iters), loss = 0.592728
I1210 13:24:21.878479 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:24:21.878479 10416 solver.cpp:237]     Train net output #1: loss = 0.592728 (* 1 = 0.592728 loss)
I1210 13:24:21.878479 10416 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1210 13:24:27.537042 10416 solver.cpp:218] Iteration 75800 (17.6742 iter/s, 5.65795s/100 iters), loss = 0.891096
I1210 13:24:27.537042 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:24:27.537042 10416 solver.cpp:237]     Train net output #1: loss = 0.891096 (* 1 = 0.891096 loss)
I1210 13:24:27.537042 10416 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1210 13:24:33.200484 10416 solver.cpp:218] Iteration 75900 (17.6588 iter/s, 5.6629s/100 iters), loss = 0.785129
I1210 13:24:33.200484 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:24:33.200484 10416 solver.cpp:237]     Train net output #1: loss = 0.785129 (* 1 = 0.785129 loss)
I1210 13:24:33.200484 10416 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1210 13:24:38.593860  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:24:38.817870 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_76000.caffemodel
I1210 13:24:38.837870 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_76000.solverstate
I1210 13:24:38.841871 10416 solver.cpp:330] Iteration 76000, Testing net (#0)
I1210 13:24:38.842871 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:24:40.227999  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:24:40.282001 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5803
I1210 13:24:40.282001 10416 solver.cpp:397]     Test net output #1: loss = 1.59657 (* 1 = 1.59657 loss)
I1210 13:24:40.335003 10416 solver.cpp:218] Iteration 76000 (14.0158 iter/s, 7.13481s/100 iters), loss = 0.623379
I1210 13:24:40.336012 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:24:40.336012 10416 solver.cpp:237]     Train net output #1: loss = 0.623379 (* 1 = 0.623379 loss)
I1210 13:24:40.336012 10416 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1210 13:24:45.994386 10416 solver.cpp:218] Iteration 76100 (17.6736 iter/s, 5.65816s/100 iters), loss = 0.852051
I1210 13:24:45.994386 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:24:45.994386 10416 solver.cpp:237]     Train net output #1: loss = 0.852051 (* 1 = 0.852051 loss)
I1210 13:24:45.994386 10416 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1210 13:24:51.643795 10416 solver.cpp:218] Iteration 76200 (17.7029 iter/s, 5.64879s/100 iters), loss = 0.558628
I1210 13:24:51.643795 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:24:51.643795 10416 solver.cpp:237]     Train net output #1: loss = 0.558628 (* 1 = 0.558628 loss)
I1210 13:24:51.643795 10416 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1210 13:24:57.299290 10416 solver.cpp:218] Iteration 76300 (17.6812 iter/s, 5.65574s/100 iters), loss = 0.792109
I1210 13:24:57.299290 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:24:57.299290 10416 solver.cpp:237]     Train net output #1: loss = 0.792109 (* 1 = 0.792109 loss)
I1210 13:24:57.299290 10416 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1210 13:25:02.959769 10416 solver.cpp:218] Iteration 76400 (17.6696 iter/s, 5.65945s/100 iters), loss = 0.816186
I1210 13:25:02.959769 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:25:02.959769 10416 solver.cpp:237]     Train net output #1: loss = 0.816186 (* 1 = 0.816186 loss)
I1210 13:25:02.959769 10416 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1210 13:25:08.349189  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:25:08.572204 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_76500.caffemodel
I1210 13:25:08.591707 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_76500.solverstate
I1210 13:25:08.596210 10416 solver.cpp:330] Iteration 76500, Testing net (#0)
I1210 13:25:08.596210 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:25:09.982822  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:25:10.037326 10416 solver.cpp:397]     Test net output #0: accuracy = 0.581
I1210 13:25:10.037326 10416 solver.cpp:397]     Test net output #1: loss = 1.6031 (* 1 = 1.6031 loss)
I1210 13:25:10.092330 10416 solver.cpp:218] Iteration 76500 (14.0213 iter/s, 7.13198s/100 iters), loss = 0.67812
I1210 13:25:10.092330 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:25:10.092330 10416 solver.cpp:237]     Train net output #1: loss = 0.67812 (* 1 = 0.67812 loss)
I1210 13:25:10.092330 10416 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1210 13:25:15.779778 10416 solver.cpp:218] Iteration 76600 (17.5842 iter/s, 5.68693s/100 iters), loss = 0.774449
I1210 13:25:15.779778 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:25:15.779778 10416 solver.cpp:237]     Train net output #1: loss = 0.774449 (* 1 = 0.774449 loss)
I1210 13:25:15.779778 10416 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1210 13:25:21.461314 10416 solver.cpp:218] Iteration 76700 (17.602 iter/s, 5.68118s/100 iters), loss = 0.690835
I1210 13:25:21.461314 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:25:21.461314 10416 solver.cpp:237]     Train net output #1: loss = 0.690835 (* 1 = 0.690835 loss)
I1210 13:25:21.461314 10416 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1210 13:25:27.140569 10416 solver.cpp:218] Iteration 76800 (17.6078 iter/s, 5.67929s/100 iters), loss = 0.701438
I1210 13:25:27.140569 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:25:27.141571 10416 solver.cpp:237]     Train net output #1: loss = 0.701438 (* 1 = 0.701438 loss)
I1210 13:25:27.141571 10416 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1210 13:25:32.818972 10416 solver.cpp:218] Iteration 76900 (17.613 iter/s, 5.67762s/100 iters), loss = 0.918631
I1210 13:25:32.818972 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:25:32.818972 10416 solver.cpp:237]     Train net output #1: loss = 0.918631 (* 1 = 0.918631 loss)
I1210 13:25:32.818972 10416 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1210 13:25:38.198326  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:25:38.423337 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_77000.caffemodel
I1210 13:25:38.442337 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_77000.solverstate
I1210 13:25:38.447337 10416 solver.cpp:330] Iteration 77000, Testing net (#0)
I1210 13:25:38.447337 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:25:39.830430  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:25:39.884445 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5854
I1210 13:25:39.884445 10416 solver.cpp:397]     Test net output #1: loss = 1.54521 (* 1 = 1.54521 loss)
I1210 13:25:39.938436 10416 solver.cpp:218] Iteration 77000 (14.0466 iter/s, 7.11914s/100 iters), loss = 0.573503
I1210 13:25:39.938436 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:25:39.938436 10416 solver.cpp:237]     Train net output #1: loss = 0.573503 (* 1 = 0.573503 loss)
I1210 13:25:39.938436 10416 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1210 13:25:45.600914 10416 solver.cpp:218] Iteration 77100 (17.6618 iter/s, 5.66193s/100 iters), loss = 0.764353
I1210 13:25:45.600914 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:25:45.600914 10416 solver.cpp:237]     Train net output #1: loss = 0.764353 (* 1 = 0.764353 loss)
I1210 13:25:45.600914 10416 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1210 13:25:51.270357 10416 solver.cpp:218] Iteration 77200 (17.6415 iter/s, 5.66846s/100 iters), loss = 0.590999
I1210 13:25:51.270357 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:25:51.270357 10416 solver.cpp:237]     Train net output #1: loss = 0.590999 (* 1 = 0.590999 loss)
I1210 13:25:51.270357 10416 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1210 13:25:56.929765 10416 solver.cpp:218] Iteration 77300 (17.6712 iter/s, 5.65894s/100 iters), loss = 0.857106
I1210 13:25:56.929765 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:25:56.929765 10416 solver.cpp:237]     Train net output #1: loss = 0.857106 (* 1 = 0.857106 loss)
I1210 13:25:56.929765 10416 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1210 13:26:02.592166 10416 solver.cpp:218] Iteration 77400 (17.6595 iter/s, 5.66267s/100 iters), loss = 0.820606
I1210 13:26:02.592166 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:26:02.592166 10416 solver.cpp:237]     Train net output #1: loss = 0.820606 (* 1 = 0.820606 loss)
I1210 13:26:02.592166 10416 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1210 13:26:07.984529  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:26:08.206552 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_77500.caffemodel
I1210 13:26:08.222550 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_77500.solverstate
I1210 13:26:08.227551 10416 solver.cpp:330] Iteration 77500, Testing net (#0)
I1210 13:26:08.227551 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:26:09.612661  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:26:09.667162 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5952
I1210 13:26:09.667162 10416 solver.cpp:397]     Test net output #1: loss = 1.51274 (* 1 = 1.51274 loss)
I1210 13:26:09.721665 10416 solver.cpp:218] Iteration 77500 (14.0274 iter/s, 7.12891s/100 iters), loss = 0.567369
I1210 13:26:09.721665 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:26:09.721665 10416 solver.cpp:237]     Train net output #1: loss = 0.567369 (* 1 = 0.567369 loss)
I1210 13:26:09.721665 10416 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1210 13:26:15.410114 10416 solver.cpp:218] Iteration 77600 (17.5812 iter/s, 5.68791s/100 iters), loss = 0.62834
I1210 13:26:15.410114 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:26:15.410114 10416 solver.cpp:237]     Train net output #1: loss = 0.62834 (* 1 = 0.62834 loss)
I1210 13:26:15.410114 10416 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1210 13:26:21.089587 10416 solver.cpp:218] Iteration 77700 (17.6091 iter/s, 5.67888s/100 iters), loss = 0.594474
I1210 13:26:21.089587 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:26:21.089587 10416 solver.cpp:237]     Train net output #1: loss = 0.594474 (* 1 = 0.594474 loss)
I1210 13:26:21.089587 10416 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1210 13:26:26.764333 10416 solver.cpp:218] Iteration 77800 (17.623 iter/s, 5.67442s/100 iters), loss = 0.868085
I1210 13:26:26.764333 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:26:26.764333 10416 solver.cpp:237]     Train net output #1: loss = 0.868085 (* 1 = 0.868085 loss)
I1210 13:26:26.764333 10416 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1210 13:26:32.455127 10416 solver.cpp:218] Iteration 77900 (17.5738 iter/s, 5.69028s/100 iters), loss = 0.824008
I1210 13:26:32.455127 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:26:32.455127 10416 solver.cpp:237]     Train net output #1: loss = 0.824008 (* 1 = 0.824008 loss)
I1210 13:26:32.455127 10416 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1210 13:26:37.872992  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:26:38.097509 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_78000.caffemodel
I1210 13:26:38.115509 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_78000.solverstate
I1210 13:26:38.120509 10416 solver.cpp:330] Iteration 78000, Testing net (#0)
I1210 13:26:38.120509 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:26:39.502629  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:26:39.555629 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5826
I1210 13:26:39.555629 10416 solver.cpp:397]     Test net output #1: loss = 1.57336 (* 1 = 1.57336 loss)
I1210 13:26:39.611639 10416 solver.cpp:218] Iteration 78000 (13.974 iter/s, 7.15613s/100 iters), loss = 0.663884
I1210 13:26:39.611639 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:26:39.611639 10416 solver.cpp:237]     Train net output #1: loss = 0.663884 (* 1 = 0.663884 loss)
I1210 13:26:39.611639 10416 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1210 13:26:45.284569 10416 solver.cpp:218] Iteration 78100 (17.6291 iter/s, 5.67244s/100 iters), loss = 0.682263
I1210 13:26:45.285069 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:26:45.285069 10416 solver.cpp:237]     Train net output #1: loss = 0.682263 (* 1 = 0.682263 loss)
I1210 13:26:45.285069 10416 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1210 13:26:50.975565 10416 solver.cpp:218] Iteration 78200 (17.5738 iter/s, 5.6903s/100 iters), loss = 0.546465
I1210 13:26:50.975565 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:26:50.975565 10416 solver.cpp:237]     Train net output #1: loss = 0.546465 (* 1 = 0.546465 loss)
I1210 13:26:50.975565 10416 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1210 13:26:56.651999 10416 solver.cpp:218] Iteration 78300 (17.6167 iter/s, 5.67644s/100 iters), loss = 0.895836
I1210 13:26:56.651999 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:26:56.651999 10416 solver.cpp:237]     Train net output #1: loss = 0.895836 (* 1 = 0.895836 loss)
I1210 13:26:56.651999 10416 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1210 13:27:02.330402 10416 solver.cpp:218] Iteration 78400 (17.6128 iter/s, 5.6777s/100 iters), loss = 0.945025
I1210 13:27:02.330402 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 13:27:02.330402 10416 solver.cpp:237]     Train net output #1: loss = 0.945025 (* 1 = 0.945025 loss)
I1210 13:27:02.330402 10416 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1210 13:27:07.723875  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:27:07.946914 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_78500.caffemodel
I1210 13:27:07.961915 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_78500.solverstate
I1210 13:27:07.966915 10416 solver.cpp:330] Iteration 78500, Testing net (#0)
I1210 13:27:07.966915 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:27:09.354063  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:27:09.408071 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5798
I1210 13:27:09.408071 10416 solver.cpp:397]     Test net output #1: loss = 1.65421 (* 1 = 1.65421 loss)
I1210 13:27:09.462069 10416 solver.cpp:218] Iteration 78500 (14.0222 iter/s, 7.13157s/100 iters), loss = 0.680688
I1210 13:27:09.462069 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:27:09.462069 10416 solver.cpp:237]     Train net output #1: loss = 0.680688 (* 1 = 0.680688 loss)
I1210 13:27:09.462069 10416 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1210 13:27:15.142532 10416 solver.cpp:218] Iteration 78600 (17.6053 iter/s, 5.68012s/100 iters), loss = 0.798679
I1210 13:27:15.142532 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:27:15.143532 10416 solver.cpp:237]     Train net output #1: loss = 0.798679 (* 1 = 0.798679 loss)
I1210 13:27:15.143532 10416 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1210 13:27:20.816002 10416 solver.cpp:218] Iteration 78700 (17.6275 iter/s, 5.67296s/100 iters), loss = 0.545408
I1210 13:27:20.816002 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:27:20.816002 10416 solver.cpp:237]     Train net output #1: loss = 0.545408 (* 1 = 0.545408 loss)
I1210 13:27:20.816002 10416 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1210 13:27:26.493427 10416 solver.cpp:218] Iteration 78800 (17.6154 iter/s, 5.67685s/100 iters), loss = 0.803395
I1210 13:27:26.493427 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:27:26.493427 10416 solver.cpp:237]     Train net output #1: loss = 0.803395 (* 1 = 0.803395 loss)
I1210 13:27:26.493427 10416 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1210 13:27:32.179419 10416 solver.cpp:218] Iteration 78900 (17.5897 iter/s, 5.68514s/100 iters), loss = 0.756628
I1210 13:27:32.179419 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:27:32.179419 10416 solver.cpp:237]     Train net output #1: loss = 0.756628 (* 1 = 0.756628 loss)
I1210 13:27:32.179419 10416 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1210 13:27:37.591306  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:27:37.812317 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_79000.caffemodel
I1210 13:27:37.832317 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_79000.solverstate
I1210 13:27:37.838327 10416 solver.cpp:330] Iteration 79000, Testing net (#0)
I1210 13:27:37.838327 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:27:39.222465  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:27:39.275967 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5678
I1210 13:27:39.276468 10416 solver.cpp:397]     Test net output #1: loss = 1.67772 (* 1 = 1.67772 loss)
I1210 13:27:39.330469 10416 solver.cpp:218] Iteration 79000 (13.985 iter/s, 7.15053s/100 iters), loss = 0.656905
I1210 13:27:39.330469 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:27:39.330469 10416 solver.cpp:237]     Train net output #1: loss = 0.656905 (* 1 = 0.656905 loss)
I1210 13:27:39.330469 10416 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1210 13:27:45.013873 10416 solver.cpp:218] Iteration 79100 (17.5959 iter/s, 5.68315s/100 iters), loss = 0.729521
I1210 13:27:45.013873 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:27:45.013873 10416 solver.cpp:237]     Train net output #1: loss = 0.729521 (* 1 = 0.729521 loss)
I1210 13:27:45.013873 10416 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1210 13:27:50.692314 10416 solver.cpp:218] Iteration 79200 (17.611 iter/s, 5.67827s/100 iters), loss = 0.637093
I1210 13:27:50.692314 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:27:50.692314 10416 solver.cpp:237]     Train net output #1: loss = 0.637093 (* 1 = 0.637093 loss)
I1210 13:27:50.692314 10416 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1210 13:27:56.375725 10416 solver.cpp:218] Iteration 79300 (17.598 iter/s, 5.68246s/100 iters), loss = 0.743647
I1210 13:27:56.375725 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:27:56.375725 10416 solver.cpp:237]     Train net output #1: loss = 0.743647 (* 1 = 0.743647 loss)
I1210 13:27:56.375725 10416 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1210 13:28:02.061151 10416 solver.cpp:218] Iteration 79400 (17.5907 iter/s, 5.68484s/100 iters), loss = 0.840266
I1210 13:28:02.061151 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:28:02.061151 10416 solver.cpp:237]     Train net output #1: loss = 0.840266 (* 1 = 0.840266 loss)
I1210 13:28:02.061151 10416 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1210 13:28:07.466614  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:28:07.689640 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_79500.caffemodel
I1210 13:28:07.709643 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_79500.solverstate
I1210 13:28:07.714644 10416 solver.cpp:330] Iteration 79500, Testing net (#0)
I1210 13:28:07.714644 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:28:09.100783  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:28:09.152783 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5132
I1210 13:28:09.152783 10416 solver.cpp:397]     Test net output #1: loss = 2.07099 (* 1 = 2.07099 loss)
I1210 13:28:09.206790 10416 solver.cpp:218] Iteration 79500 (13.995 iter/s, 7.14542s/100 iters), loss = 0.68021
I1210 13:28:09.206790 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:28:09.206790 10416 solver.cpp:237]     Train net output #1: loss = 0.68021 (* 1 = 0.68021 loss)
I1210 13:28:09.206790 10416 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1210 13:28:14.880246 10416 solver.cpp:218] Iteration 79600 (17.6276 iter/s, 5.67292s/100 iters), loss = 0.682591
I1210 13:28:14.880246 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:28:14.880246 10416 solver.cpp:237]     Train net output #1: loss = 0.682591 (* 1 = 0.682591 loss)
I1210 13:28:14.880246 10416 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1210 13:28:20.571691 10416 solver.cpp:218] Iteration 79700 (17.5709 iter/s, 5.69122s/100 iters), loss = 0.650023
I1210 13:28:20.571691 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:28:20.571691 10416 solver.cpp:237]     Train net output #1: loss = 0.650023 (* 1 = 0.650023 loss)
I1210 13:28:20.571691 10416 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1210 13:28:26.251070 10416 solver.cpp:218] Iteration 79800 (17.6087 iter/s, 5.67902s/100 iters), loss = 0.831893
I1210 13:28:26.252079 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 13:28:26.252079 10416 solver.cpp:237]     Train net output #1: loss = 0.831893 (* 1 = 0.831893 loss)
I1210 13:28:26.252079 10416 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1210 13:28:31.925457 10416 solver.cpp:218] Iteration 79900 (17.6245 iter/s, 5.67391s/100 iters), loss = 0.823744
I1210 13:28:31.926456 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:28:31.926456 10416 solver.cpp:237]     Train net output #1: loss = 0.823744 (* 1 = 0.823744 loss)
I1210 13:28:31.926456 10416 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1210 13:28:37.324823  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:28:37.550827 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_80000.caffemodel
I1210 13:28:37.569834 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_80000.solverstate
I1210 13:28:37.574826 10416 solver.cpp:330] Iteration 80000, Testing net (#0)
I1210 13:28:37.574826 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:28:38.960929  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:28:39.013934 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5689
I1210 13:28:39.013934 10416 solver.cpp:397]     Test net output #1: loss = 1.71021 (* 1 = 1.71021 loss)
I1210 13:28:39.069936 10416 solver.cpp:218] Iteration 80000 (13.999 iter/s, 7.14337s/100 iters), loss = 0.677117
I1210 13:28:39.069936 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:28:39.069936 10416 solver.cpp:237]     Train net output #1: loss = 0.677117 (* 1 = 0.677117 loss)
I1210 13:28:39.069936 10416 sgd_solver.cpp:105] Iteration 80000, lr = 0.01
I1210 13:28:44.734302 10416 solver.cpp:218] Iteration 80100 (17.6538 iter/s, 5.66451s/100 iters), loss = 0.669085
I1210 13:28:44.735302 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:28:44.735302 10416 solver.cpp:237]     Train net output #1: loss = 0.669085 (* 1 = 0.669085 loss)
I1210 13:28:44.735302 10416 sgd_solver.cpp:105] Iteration 80100, lr = 0.01
I1210 13:28:50.410718 10416 solver.cpp:218] Iteration 80200 (17.6207 iter/s, 5.67515s/100 iters), loss = 0.545386
I1210 13:28:50.410718 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:28:50.410718 10416 solver.cpp:237]     Train net output #1: loss = 0.545386 (* 1 = 0.545386 loss)
I1210 13:28:50.410718 10416 sgd_solver.cpp:105] Iteration 80200, lr = 0.01
I1210 13:28:56.071024 10416 solver.cpp:218] Iteration 80300 (17.6661 iter/s, 5.66056s/100 iters), loss = 0.849203
I1210 13:28:56.071024 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:28:56.071024 10416 solver.cpp:237]     Train net output #1: loss = 0.849203 (* 1 = 0.849203 loss)
I1210 13:28:56.071024 10416 sgd_solver.cpp:105] Iteration 80300, lr = 0.01
I1210 13:29:01.742557 10416 solver.cpp:218] Iteration 80400 (17.6346 iter/s, 5.67068s/100 iters), loss = 0.788358
I1210 13:29:01.742557 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:29:01.742557 10416 solver.cpp:237]     Train net output #1: loss = 0.788358 (* 1 = 0.788358 loss)
I1210 13:29:01.742557 10416 sgd_solver.cpp:105] Iteration 80400, lr = 0.01
I1210 13:29:07.120100  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:29:07.344120 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_80500.caffemodel
I1210 13:29:07.357120 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_80500.solverstate
I1210 13:29:07.362120 10416 solver.cpp:330] Iteration 80500, Testing net (#0)
I1210 13:29:07.362120 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:29:08.744249  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:29:08.798250 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5993
I1210 13:29:08.798250 10416 solver.cpp:397]     Test net output #1: loss = 1.51097 (* 1 = 1.51097 loss)
I1210 13:29:08.851255 10416 solver.cpp:218] Iteration 80500 (14.0677 iter/s, 7.1085s/100 iters), loss = 0.565879
I1210 13:29:08.851255 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:29:08.851255 10416 solver.cpp:237]     Train net output #1: loss = 0.565879 (* 1 = 0.565879 loss)
I1210 13:29:08.851255 10416 sgd_solver.cpp:105] Iteration 80500, lr = 0.01
I1210 13:29:14.536710 10416 solver.cpp:218] Iteration 80600 (17.5907 iter/s, 5.68482s/100 iters), loss = 0.896624
I1210 13:29:14.536710 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 13:29:14.536710 10416 solver.cpp:237]     Train net output #1: loss = 0.896624 (* 1 = 0.896624 loss)
I1210 13:29:14.536710 10416 sgd_solver.cpp:105] Iteration 80600, lr = 0.01
I1210 13:29:20.224134 10416 solver.cpp:218] Iteration 80700 (17.5857 iter/s, 5.68643s/100 iters), loss = 0.681135
I1210 13:29:20.224134 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:29:20.224134 10416 solver.cpp:237]     Train net output #1: loss = 0.681135 (* 1 = 0.681135 loss)
I1210 13:29:20.224134 10416 sgd_solver.cpp:105] Iteration 80700, lr = 0.01
I1210 13:29:25.915495 10416 solver.cpp:218] Iteration 80800 (17.572 iter/s, 5.69087s/100 iters), loss = 0.707746
I1210 13:29:25.915495 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:29:25.915495 10416 solver.cpp:237]     Train net output #1: loss = 0.707746 (* 1 = 0.707746 loss)
I1210 13:29:25.915495 10416 sgd_solver.cpp:105] Iteration 80800, lr = 0.01
I1210 13:29:31.603854 10416 solver.cpp:218] Iteration 80900 (17.5799 iter/s, 5.6883s/100 iters), loss = 0.871727
I1210 13:29:31.603854 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:29:31.603854 10416 solver.cpp:237]     Train net output #1: loss = 0.871727 (* 1 = 0.871727 loss)
I1210 13:29:31.603854 10416 sgd_solver.cpp:105] Iteration 80900, lr = 0.01
I1210 13:29:37.015219  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:29:37.238240 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_81000.caffemodel
I1210 13:29:37.257239 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_81000.solverstate
I1210 13:29:37.263239 10416 solver.cpp:330] Iteration 81000, Testing net (#0)
I1210 13:29:37.263239 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:29:38.648350  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:29:38.703356 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5536
I1210 13:29:38.703356 10416 solver.cpp:397]     Test net output #1: loss = 1.73694 (* 1 = 1.73694 loss)
I1210 13:29:38.757356 10416 solver.cpp:218] Iteration 81000 (13.9796 iter/s, 7.15328s/100 iters), loss = 0.764022
I1210 13:29:38.757356 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:29:38.757356 10416 solver.cpp:237]     Train net output #1: loss = 0.764022 (* 1 = 0.764022 loss)
I1210 13:29:38.757356 10416 sgd_solver.cpp:105] Iteration 81000, lr = 0.01
I1210 13:29:44.435796 10416 solver.cpp:218] Iteration 81100 (17.6141 iter/s, 5.67726s/100 iters), loss = 0.864751
I1210 13:29:44.435796 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:29:44.435796 10416 solver.cpp:237]     Train net output #1: loss = 0.864751 (* 1 = 0.864751 loss)
I1210 13:29:44.435796 10416 sgd_solver.cpp:105] Iteration 81100, lr = 0.01
I1210 13:29:50.120184 10416 solver.cpp:218] Iteration 81200 (17.5932 iter/s, 5.684s/100 iters), loss = 0.648088
I1210 13:29:50.120184 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:29:50.120184 10416 solver.cpp:237]     Train net output #1: loss = 0.648088 (* 1 = 0.648088 loss)
I1210 13:29:50.120184 10416 sgd_solver.cpp:105] Iteration 81200, lr = 0.01
I1210 13:29:55.805572 10416 solver.cpp:218] Iteration 81300 (17.5885 iter/s, 5.68552s/100 iters), loss = 0.768442
I1210 13:29:55.805572 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:29:55.805572 10416 solver.cpp:237]     Train net output #1: loss = 0.768442 (* 1 = 0.768442 loss)
I1210 13:29:55.805572 10416 sgd_solver.cpp:105] Iteration 81300, lr = 0.01
I1210 13:30:01.509027 10416 solver.cpp:218] Iteration 81400 (17.5342 iter/s, 5.70316s/100 iters), loss = 0.820228
I1210 13:30:01.509027 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:30:01.509027 10416 solver.cpp:237]     Train net output #1: loss = 0.820228 (* 1 = 0.820228 loss)
I1210 13:30:01.509027 10416 sgd_solver.cpp:105] Iteration 81400, lr = 0.01
I1210 13:30:06.917459  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:30:07.139957 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_81500.caffemodel
I1210 13:30:07.154453 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_81500.solverstate
I1210 13:30:07.159456 10416 solver.cpp:330] Iteration 81500, Testing net (#0)
I1210 13:30:07.159456 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:30:08.546042  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:30:08.600548 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5999
I1210 13:30:08.600548 10416 solver.cpp:397]     Test net output #1: loss = 1.50014 (* 1 = 1.50014 loss)
I1210 13:30:08.656042 10416 solver.cpp:218] Iteration 81500 (13.9942 iter/s, 7.1458s/100 iters), loss = 0.55006
I1210 13:30:08.656042 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 13:30:08.656042 10416 solver.cpp:237]     Train net output #1: loss = 0.55006 (* 1 = 0.55006 loss)
I1210 13:30:08.656042 10416 sgd_solver.cpp:105] Iteration 81500, lr = 0.01
I1210 13:30:14.338985 10416 solver.cpp:218] Iteration 81600 (17.5974 iter/s, 5.68264s/100 iters), loss = 0.666987
I1210 13:30:14.338985 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:30:14.338985 10416 solver.cpp:237]     Train net output #1: loss = 0.666987 (* 1 = 0.666987 loss)
I1210 13:30:14.338985 10416 sgd_solver.cpp:105] Iteration 81600, lr = 0.01
I1210 13:30:20.022904 10416 solver.cpp:218] Iteration 81700 (17.5946 iter/s, 5.68355s/100 iters), loss = 0.562569
I1210 13:30:20.023403 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:30:20.023403 10416 solver.cpp:237]     Train net output #1: loss = 0.562569 (* 1 = 0.562569 loss)
I1210 13:30:20.023403 10416 sgd_solver.cpp:105] Iteration 81700, lr = 0.01
I1210 13:30:25.704860 10416 solver.cpp:218] Iteration 81800 (17.6005 iter/s, 5.68164s/100 iters), loss = 0.781708
I1210 13:30:25.704860 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:30:25.704860 10416 solver.cpp:237]     Train net output #1: loss = 0.781708 (* 1 = 0.781708 loss)
I1210 13:30:25.704860 10416 sgd_solver.cpp:105] Iteration 81800, lr = 0.01
I1210 13:30:31.387357 10416 solver.cpp:218] Iteration 81900 (17.5989 iter/s, 5.68218s/100 iters), loss = 0.849266
I1210 13:30:31.388358 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:30:31.388358 10416 solver.cpp:237]     Train net output #1: loss = 0.849266 (* 1 = 0.849266 loss)
I1210 13:30:31.388358 10416 sgd_solver.cpp:105] Iteration 81900, lr = 0.01
I1210 13:30:36.800746  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:30:37.023268 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_82000.caffemodel
I1210 13:30:37.039775 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_82000.solverstate
I1210 13:30:37.045773 10416 solver.cpp:330] Iteration 82000, Testing net (#0)
I1210 13:30:37.045773 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:30:38.429894  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:30:38.482898 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5668
I1210 13:30:38.482898 10416 solver.cpp:397]     Test net output #1: loss = 1.75453 (* 1 = 1.75453 loss)
I1210 13:30:38.536901 10416 solver.cpp:218] Iteration 82000 (13.9896 iter/s, 7.14816s/100 iters), loss = 0.712371
I1210 13:30:38.536901 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:30:38.536901 10416 solver.cpp:237]     Train net output #1: loss = 0.712371 (* 1 = 0.712371 loss)
I1210 13:30:38.536901 10416 sgd_solver.cpp:105] Iteration 82000, lr = 0.01
I1210 13:30:44.214366 10416 solver.cpp:218] Iteration 82100 (17.613 iter/s, 5.67763s/100 iters), loss = 0.800246
I1210 13:30:44.215368 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:30:44.215368 10416 solver.cpp:237]     Train net output #1: loss = 0.800246 (* 1 = 0.800246 loss)
I1210 13:30:44.215368 10416 sgd_solver.cpp:105] Iteration 82100, lr = 0.01
I1210 13:30:49.905869 10416 solver.cpp:218] Iteration 82200 (17.574 iter/s, 5.69023s/100 iters), loss = 0.604064
I1210 13:30:49.905869 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:30:49.905869 10416 solver.cpp:237]     Train net output #1: loss = 0.604064 (* 1 = 0.604064 loss)
I1210 13:30:49.905869 10416 sgd_solver.cpp:105] Iteration 82200, lr = 0.01
I1210 13:30:55.581306 10416 solver.cpp:218] Iteration 82300 (17.6206 iter/s, 5.67518s/100 iters), loss = 0.864061
I1210 13:30:55.581306 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:30:55.581306 10416 solver.cpp:237]     Train net output #1: loss = 0.864061 (* 1 = 0.864061 loss)
I1210 13:30:55.581306 10416 sgd_solver.cpp:105] Iteration 82300, lr = 0.01
I1210 13:31:01.261747 10416 solver.cpp:218] Iteration 82400 (17.6063 iter/s, 5.67978s/100 iters), loss = 0.736692
I1210 13:31:01.261747 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:31:01.261747 10416 solver.cpp:237]     Train net output #1: loss = 0.736692 (* 1 = 0.736692 loss)
I1210 13:31:01.261747 10416 sgd_solver.cpp:105] Iteration 82400, lr = 0.01
I1210 13:31:06.659188  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:31:06.882200 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_82500.caffemodel
I1210 13:31:06.903200 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_82500.solverstate
I1210 13:31:06.908200 10416 solver.cpp:330] Iteration 82500, Testing net (#0)
I1210 13:31:06.908200 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:31:08.295333  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:31:08.347339 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5944
I1210 13:31:08.347339 10416 solver.cpp:397]     Test net output #1: loss = 1.55301 (* 1 = 1.55301 loss)
I1210 13:31:08.400338 10416 solver.cpp:218] Iteration 82500 (14.0088 iter/s, 7.13837s/100 iters), loss = 0.648797
I1210 13:31:08.400338 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:31:08.400338 10416 solver.cpp:237]     Train net output #1: loss = 0.648797 (* 1 = 0.648797 loss)
I1210 13:31:08.400338 10416 sgd_solver.cpp:105] Iteration 82500, lr = 0.01
I1210 13:31:14.068766 10416 solver.cpp:218] Iteration 82600 (17.6418 iter/s, 5.66836s/100 iters), loss = 0.69902
I1210 13:31:14.068766 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:31:14.068766 10416 solver.cpp:237]     Train net output #1: loss = 0.69902 (* 1 = 0.69902 loss)
I1210 13:31:14.068766 10416 sgd_solver.cpp:105] Iteration 82600, lr = 0.01
I1210 13:31:19.725234 10416 solver.cpp:218] Iteration 82700 (17.6811 iter/s, 5.65576s/100 iters), loss = 0.589756
I1210 13:31:19.725234 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:31:19.725736 10416 solver.cpp:237]     Train net output #1: loss = 0.589756 (* 1 = 0.589756 loss)
I1210 13:31:19.725736 10416 sgd_solver.cpp:105] Iteration 82700, lr = 0.01
I1210 13:31:25.411700 10416 solver.cpp:218] Iteration 82800 (17.5868 iter/s, 5.68609s/100 iters), loss = 0.73422
I1210 13:31:25.411700 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:31:25.411700 10416 solver.cpp:237]     Train net output #1: loss = 0.73422 (* 1 = 0.73422 loss)
I1210 13:31:25.411700 10416 sgd_solver.cpp:105] Iteration 82800, lr = 0.01
I1210 13:31:31.086161 10416 solver.cpp:218] Iteration 82900 (17.6246 iter/s, 5.6739s/100 iters), loss = 0.76808
I1210 13:31:31.086161 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:31:31.086161 10416 solver.cpp:237]     Train net output #1: loss = 0.76808 (* 1 = 0.76808 loss)
I1210 13:31:31.086161 10416 sgd_solver.cpp:105] Iteration 82900, lr = 0.01
I1210 13:31:36.493571  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:31:36.717584 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_83000.caffemodel
I1210 13:31:36.737088 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_83000.solverstate
I1210 13:31:36.741588 10416 solver.cpp:330] Iteration 83000, Testing net (#0)
I1210 13:31:36.741588 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:31:38.125690  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:31:38.180697 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5782
I1210 13:31:38.180697 10416 solver.cpp:397]     Test net output #1: loss = 1.63986 (* 1 = 1.63986 loss)
I1210 13:31:38.235699 10416 solver.cpp:218] Iteration 83000 (13.9879 iter/s, 7.14902s/100 iters), loss = 0.669484
I1210 13:31:38.235699 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:31:38.235699 10416 solver.cpp:237]     Train net output #1: loss = 0.669484 (* 1 = 0.669484 loss)
I1210 13:31:38.235699 10416 sgd_solver.cpp:105] Iteration 83000, lr = 0.01
I1210 13:31:43.917135 10416 solver.cpp:218] Iteration 83100 (17.6018 iter/s, 5.68123s/100 iters), loss = 0.740034
I1210 13:31:43.917135 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:31:43.917135 10416 solver.cpp:237]     Train net output #1: loss = 0.740034 (* 1 = 0.740034 loss)
I1210 13:31:43.917135 10416 sgd_solver.cpp:105] Iteration 83100, lr = 0.01
I1210 13:31:49.613543 10416 solver.cpp:218] Iteration 83200 (17.556 iter/s, 5.69607s/100 iters), loss = 0.724613
I1210 13:31:49.613543 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:31:49.613543 10416 solver.cpp:237]     Train net output #1: loss = 0.724613 (* 1 = 0.724613 loss)
I1210 13:31:49.613543 10416 sgd_solver.cpp:105] Iteration 83200, lr = 0.01
I1210 13:31:55.297977 10416 solver.cpp:218] Iteration 83300 (17.5933 iter/s, 5.68399s/100 iters), loss = 0.88089
I1210 13:31:55.297977 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:31:55.297977 10416 solver.cpp:237]     Train net output #1: loss = 0.88089 (* 1 = 0.88089 loss)
I1210 13:31:55.297977 10416 sgd_solver.cpp:105] Iteration 83300, lr = 0.01
I1210 13:32:00.972394 10416 solver.cpp:218] Iteration 83400 (17.6259 iter/s, 5.67349s/100 iters), loss = 0.858699
I1210 13:32:00.972394 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:32:00.972394 10416 solver.cpp:237]     Train net output #1: loss = 0.858699 (* 1 = 0.858699 loss)
I1210 13:32:00.972394 10416 sgd_solver.cpp:105] Iteration 83400, lr = 0.01
I1210 13:32:06.376828  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:32:06.600841 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_83500.caffemodel
I1210 13:32:06.616840 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_83500.solverstate
I1210 13:32:06.621840 10416 solver.cpp:330] Iteration 83500, Testing net (#0)
I1210 13:32:06.621840 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:32:08.002960  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:32:08.057962 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5999
I1210 13:32:08.057962 10416 solver.cpp:397]     Test net output #1: loss = 1.52152 (* 1 = 1.52152 loss)
I1210 13:32:08.113962 10416 solver.cpp:218] Iteration 83500 (14.0038 iter/s, 7.1409s/100 iters), loss = 0.610954
I1210 13:32:08.113962 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:32:08.113962 10416 solver.cpp:237]     Train net output #1: loss = 0.610954 (* 1 = 0.610954 loss)
I1210 13:32:08.113962 10416 sgd_solver.cpp:105] Iteration 83500, lr = 0.01
I1210 13:32:13.791344 10416 solver.cpp:218] Iteration 83600 (17.6149 iter/s, 5.677s/100 iters), loss = 0.701787
I1210 13:32:13.791344 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:32:13.791344 10416 solver.cpp:237]     Train net output #1: loss = 0.701787 (* 1 = 0.701787 loss)
I1210 13:32:13.791344 10416 sgd_solver.cpp:105] Iteration 83600, lr = 0.01
I1210 13:32:19.480787 10416 solver.cpp:218] Iteration 83700 (17.577 iter/s, 5.68924s/100 iters), loss = 0.68996
I1210 13:32:19.480787 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:32:19.480787 10416 solver.cpp:237]     Train net output #1: loss = 0.68996 (* 1 = 0.68996 loss)
I1210 13:32:19.480787 10416 sgd_solver.cpp:105] Iteration 83700, lr = 0.01
I1210 13:32:25.177217 10416 solver.cpp:218] Iteration 83800 (17.5571 iter/s, 5.69571s/100 iters), loss = 0.83562
I1210 13:32:25.177217 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:32:25.177217 10416 solver.cpp:237]     Train net output #1: loss = 0.83562 (* 1 = 0.83562 loss)
I1210 13:32:25.177217 10416 sgd_solver.cpp:105] Iteration 83800, lr = 0.01
I1210 13:32:30.864608 10416 solver.cpp:218] Iteration 83900 (17.585 iter/s, 5.68665s/100 iters), loss = 0.746983
I1210 13:32:30.864608 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:32:30.864608 10416 solver.cpp:237]     Train net output #1: loss = 0.746983 (* 1 = 0.746983 loss)
I1210 13:32:30.864608 10416 sgd_solver.cpp:105] Iteration 83900, lr = 0.01
I1210 13:32:36.266016  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:32:36.487030 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_84000.caffemodel
I1210 13:32:36.509030 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_84000.solverstate
I1210 13:32:36.513029 10416 solver.cpp:330] Iteration 84000, Testing net (#0)
I1210 13:32:36.513029 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:32:37.894148  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:32:37.948155 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5776
I1210 13:32:37.948155 10416 solver.cpp:397]     Test net output #1: loss = 1.67887 (* 1 = 1.67887 loss)
I1210 13:32:38.002154 10416 solver.cpp:218] Iteration 84000 (14.0102 iter/s, 7.13767s/100 iters), loss = 0.661461
I1210 13:32:38.002154 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:32:38.002154 10416 solver.cpp:237]     Train net output #1: loss = 0.661461 (* 1 = 0.661461 loss)
I1210 13:32:38.002154 10416 sgd_solver.cpp:105] Iteration 84000, lr = 0.01
I1210 13:32:43.674582 10416 solver.cpp:218] Iteration 84100 (17.6311 iter/s, 5.6718s/100 iters), loss = 0.74491
I1210 13:32:43.674582 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:32:43.674582 10416 solver.cpp:237]     Train net output #1: loss = 0.74491 (* 1 = 0.74491 loss)
I1210 13:32:43.674582 10416 sgd_solver.cpp:105] Iteration 84100, lr = 0.01
I1210 13:32:49.344991 10416 solver.cpp:218] Iteration 84200 (17.6374 iter/s, 5.66979s/100 iters), loss = 0.506735
I1210 13:32:49.344991 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:32:49.344991 10416 solver.cpp:237]     Train net output #1: loss = 0.506735 (* 1 = 0.506735 loss)
I1210 13:32:49.344991 10416 sgd_solver.cpp:105] Iteration 84200, lr = 0.01
I1210 13:32:55.009395 10416 solver.cpp:218] Iteration 84300 (17.6549 iter/s, 5.66415s/100 iters), loss = 1.01675
I1210 13:32:55.009395 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:32:55.009395 10416 solver.cpp:237]     Train net output #1: loss = 1.01675 (* 1 = 1.01675 loss)
I1210 13:32:55.009395 10416 sgd_solver.cpp:105] Iteration 84300, lr = 0.01
I1210 13:33:00.672927 10416 solver.cpp:218] Iteration 84400 (17.6594 iter/s, 5.66272s/100 iters), loss = 0.870345
I1210 13:33:00.672927 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:33:00.672927 10416 solver.cpp:237]     Train net output #1: loss = 0.870345 (* 1 = 0.870345 loss)
I1210 13:33:00.672927 10416 sgd_solver.cpp:105] Iteration 84400, lr = 0.01
I1210 13:33:06.067442  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:33:06.289456 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_84500.caffemodel
I1210 13:33:06.309456 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_84500.solverstate
I1210 13:33:06.314457 10416 solver.cpp:330] Iteration 84500, Testing net (#0)
I1210 13:33:06.314457 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:33:07.700585  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:33:07.754590 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5833
I1210 13:33:07.754590 10416 solver.cpp:397]     Test net output #1: loss = 1.63959 (* 1 = 1.63959 loss)
I1210 13:33:07.808589 10416 solver.cpp:218] Iteration 84500 (14.0149 iter/s, 7.13524s/100 iters), loss = 0.716806
I1210 13:33:07.808589 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:33:07.808589 10416 solver.cpp:237]     Train net output #1: loss = 0.716806 (* 1 = 0.716806 loss)
I1210 13:33:07.808589 10416 sgd_solver.cpp:105] Iteration 84500, lr = 0.01
I1210 13:33:13.477998 10416 solver.cpp:218] Iteration 84600 (17.638 iter/s, 5.66957s/100 iters), loss = 0.70693
I1210 13:33:13.477998 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:33:13.477998 10416 solver.cpp:237]     Train net output #1: loss = 0.70693 (* 1 = 0.70693 loss)
I1210 13:33:13.477998 10416 sgd_solver.cpp:105] Iteration 84600, lr = 0.01
I1210 13:33:19.146946 10416 solver.cpp:218] Iteration 84700 (17.6437 iter/s, 5.66776s/100 iters), loss = 0.540404
I1210 13:33:19.146946 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:33:19.146946 10416 solver.cpp:237]     Train net output #1: loss = 0.540404 (* 1 = 0.540404 loss)
I1210 13:33:19.146946 10416 sgd_solver.cpp:105] Iteration 84700, lr = 0.01
I1210 13:33:24.811758 10416 solver.cpp:218] Iteration 84800 (17.6527 iter/s, 5.66485s/100 iters), loss = 0.86285
I1210 13:33:24.811758 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:33:24.811758 10416 solver.cpp:237]     Train net output #1: loss = 0.86285 (* 1 = 0.86285 loss)
I1210 13:33:24.811758 10416 sgd_solver.cpp:105] Iteration 84800, lr = 0.01
I1210 13:33:30.479281 10416 solver.cpp:218] Iteration 84900 (17.647 iter/s, 5.66667s/100 iters), loss = 0.895172
I1210 13:33:30.479281 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:33:30.479281 10416 solver.cpp:237]     Train net output #1: loss = 0.895172 (* 1 = 0.895172 loss)
I1210 13:33:30.479281 10416 sgd_solver.cpp:105] Iteration 84900, lr = 0.01
I1210 13:33:35.860947  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:33:36.085980 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_85000.caffemodel
I1210 13:33:36.102982 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_85000.solverstate
I1210 13:33:36.109980 10416 solver.cpp:330] Iteration 85000, Testing net (#0)
I1210 13:33:36.109980 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:33:37.494362  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:33:37.548362 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5667
I1210 13:33:37.548362 10416 solver.cpp:397]     Test net output #1: loss = 1.71388 (* 1 = 1.71388 loss)
I1210 13:33:37.601372 10416 solver.cpp:218] Iteration 85000 (14.0415 iter/s, 7.12174s/100 iters), loss = 0.690028
I1210 13:33:37.601372 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:33:37.601372 10416 solver.cpp:237]     Train net output #1: loss = 0.690028 (* 1 = 0.690028 loss)
I1210 13:33:37.601372 10416 sgd_solver.cpp:105] Iteration 85000, lr = 0.01
I1210 13:33:43.282408 10416 solver.cpp:218] Iteration 85100 (17.6041 iter/s, 5.6805s/100 iters), loss = 0.661556
I1210 13:33:43.282408 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:33:43.282408 10416 solver.cpp:237]     Train net output #1: loss = 0.661556 (* 1 = 0.661556 loss)
I1210 13:33:43.282408 10416 sgd_solver.cpp:105] Iteration 85100, lr = 0.01
I1210 13:33:48.963697 10416 solver.cpp:218] Iteration 85200 (17.6011 iter/s, 5.68145s/100 iters), loss = 0.632239
I1210 13:33:48.963697 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:33:48.964696 10416 solver.cpp:237]     Train net output #1: loss = 0.632239 (* 1 = 0.632239 loss)
I1210 13:33:48.964696 10416 sgd_solver.cpp:105] Iteration 85200, lr = 0.01
I1210 13:33:54.637019 10416 solver.cpp:218] Iteration 85300 (17.6295 iter/s, 5.67232s/100 iters), loss = 0.777138
I1210 13:33:54.637019 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:33:54.637019 10416 solver.cpp:237]     Train net output #1: loss = 0.777138 (* 1 = 0.777138 loss)
I1210 13:33:54.637019 10416 sgd_solver.cpp:105] Iteration 85300, lr = 0.01
I1210 13:34:00.315608 10416 solver.cpp:218] Iteration 85400 (17.61 iter/s, 5.6786s/100 iters), loss = 0.777633
I1210 13:34:00.315608 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:34:00.315608 10416 solver.cpp:237]     Train net output #1: loss = 0.777633 (* 1 = 0.777633 loss)
I1210 13:34:00.315608 10416 sgd_solver.cpp:105] Iteration 85400, lr = 0.01
I1210 13:34:05.714565  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:34:05.938668 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_85500.caffemodel
I1210 13:34:05.953672 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_85500.solverstate
I1210 13:34:05.958173 10416 solver.cpp:330] Iteration 85500, Testing net (#0)
I1210 13:34:05.958173 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:34:07.341964  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:34:07.395973 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5969
I1210 13:34:07.395973 10416 solver.cpp:397]     Test net output #1: loss = 1.56131 (* 1 = 1.56131 loss)
I1210 13:34:07.450979 10416 solver.cpp:218] Iteration 85500 (14.017 iter/s, 7.13419s/100 iters), loss = 0.706659
I1210 13:34:07.450979 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:34:07.450979 10416 solver.cpp:237]     Train net output #1: loss = 0.706659 (* 1 = 0.706659 loss)
I1210 13:34:07.450979 10416 sgd_solver.cpp:105] Iteration 85500, lr = 0.01
I1210 13:34:13.132007 10416 solver.cpp:218] Iteration 85600 (17.602 iter/s, 5.68118s/100 iters), loss = 0.690148
I1210 13:34:13.132007 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:34:13.132007 10416 solver.cpp:237]     Train net output #1: loss = 0.690148 (* 1 = 0.690148 loss)
I1210 13:34:13.132007 10416 sgd_solver.cpp:105] Iteration 85600, lr = 0.01
I1210 13:34:18.823443 10416 solver.cpp:218] Iteration 85700 (17.5721 iter/s, 5.69083s/100 iters), loss = 0.465433
I1210 13:34:18.823443 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:34:18.823443 10416 solver.cpp:237]     Train net output #1: loss = 0.465433 (* 1 = 0.465433 loss)
I1210 13:34:18.823443 10416 sgd_solver.cpp:105] Iteration 85700, lr = 0.01
I1210 13:34:24.497913 10416 solver.cpp:218] Iteration 85800 (17.6234 iter/s, 5.67426s/100 iters), loss = 0.940875
I1210 13:34:24.497913 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:34:24.497913 10416 solver.cpp:237]     Train net output #1: loss = 0.940875 (* 1 = 0.940875 loss)
I1210 13:34:24.497913 10416 sgd_solver.cpp:105] Iteration 85800, lr = 0.01
I1210 13:34:30.176389 10416 solver.cpp:218] Iteration 85900 (17.6113 iter/s, 5.67818s/100 iters), loss = 0.711454
I1210 13:34:30.176389 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:34:30.176389 10416 solver.cpp:237]     Train net output #1: loss = 0.711454 (* 1 = 0.711454 loss)
I1210 13:34:30.176389 10416 sgd_solver.cpp:105] Iteration 85900, lr = 0.01
I1210 13:34:35.572870  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:34:35.794879 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_86000.caffemodel
I1210 13:34:35.814878 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_86000.solverstate
I1210 13:34:35.819880 10416 solver.cpp:330] Iteration 86000, Testing net (#0)
I1210 13:34:35.819880 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:34:37.202025  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:34:37.257030 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5743
I1210 13:34:37.257030 10416 solver.cpp:397]     Test net output #1: loss = 1.69417 (* 1 = 1.69417 loss)
I1210 13:34:37.310031 10416 solver.cpp:218] Iteration 86000 (14.0195 iter/s, 7.13294s/100 iters), loss = 0.561807
I1210 13:34:37.310031 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:34:37.310031 10416 solver.cpp:237]     Train net output #1: loss = 0.561807 (* 1 = 0.561807 loss)
I1210 13:34:37.310031 10416 sgd_solver.cpp:105] Iteration 86000, lr = 0.01
I1210 13:34:42.998510 10416 solver.cpp:218] Iteration 86100 (17.581 iter/s, 5.68795s/100 iters), loss = 0.933878
I1210 13:34:42.998510 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:34:42.998510 10416 solver.cpp:237]     Train net output #1: loss = 0.933878 (* 1 = 0.933878 loss)
I1210 13:34:42.998510 10416 sgd_solver.cpp:105] Iteration 86100, lr = 0.01
I1210 13:34:48.700222 10416 solver.cpp:218] Iteration 86200 (17.5406 iter/s, 5.70107s/100 iters), loss = 0.632762
I1210 13:34:48.700222 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:34:48.700222 10416 solver.cpp:237]     Train net output #1: loss = 0.632762 (* 1 = 0.632762 loss)
I1210 13:34:48.700222 10416 sgd_solver.cpp:105] Iteration 86200, lr = 0.01
I1210 13:34:54.398627 10416 solver.cpp:218] Iteration 86300 (17.5515 iter/s, 5.69752s/100 iters), loss = 0.76755
I1210 13:34:54.398627 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:34:54.398627 10416 solver.cpp:237]     Train net output #1: loss = 0.76755 (* 1 = 0.76755 loss)
I1210 13:34:54.398627 10416 sgd_solver.cpp:105] Iteration 86300, lr = 0.01
I1210 13:35:00.087044 10416 solver.cpp:218] Iteration 86400 (17.5814 iter/s, 5.68782s/100 iters), loss = 1.06705
I1210 13:35:00.087044 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:35:00.087044 10416 solver.cpp:237]     Train net output #1: loss = 1.06705 (* 1 = 1.06705 loss)
I1210 13:35:00.087044 10416 sgd_solver.cpp:105] Iteration 86400, lr = 0.01
I1210 13:35:05.494475  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:35:05.716486 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_86500.caffemodel
I1210 13:35:05.735487 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_86500.solverstate
I1210 13:35:05.740486 10416 solver.cpp:330] Iteration 86500, Testing net (#0)
I1210 13:35:05.740486 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:35:07.123615  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:35:07.178622 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5695
I1210 13:35:07.178622 10416 solver.cpp:397]     Test net output #1: loss = 1.65609 (* 1 = 1.65609 loss)
I1210 13:35:07.232621 10416 solver.cpp:218] Iteration 86500 (13.9959 iter/s, 7.14496s/100 iters), loss = 0.518249
I1210 13:35:07.232621 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:35:07.232621 10416 solver.cpp:237]     Train net output #1: loss = 0.518249 (* 1 = 0.518249 loss)
I1210 13:35:07.232621 10416 sgd_solver.cpp:105] Iteration 86500, lr = 0.01
I1210 13:35:12.906076 10416 solver.cpp:218] Iteration 86600 (17.6253 iter/s, 5.67368s/100 iters), loss = 0.73544
I1210 13:35:12.906076 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:35:12.906076 10416 solver.cpp:237]     Train net output #1: loss = 0.73544 (* 1 = 0.73544 loss)
I1210 13:35:12.906076 10416 sgd_solver.cpp:105] Iteration 86600, lr = 0.01
I1210 13:35:18.569562 10416 solver.cpp:218] Iteration 86700 (17.6608 iter/s, 5.66227s/100 iters), loss = 0.627039
I1210 13:35:18.569562 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:35:18.569562 10416 solver.cpp:237]     Train net output #1: loss = 0.627039 (* 1 = 0.627039 loss)
I1210 13:35:18.569562 10416 sgd_solver.cpp:105] Iteration 86700, lr = 0.01
I1210 13:35:24.234984 10416 solver.cpp:218] Iteration 86800 (17.6526 iter/s, 5.66488s/100 iters), loss = 0.845111
I1210 13:35:24.234984 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:35:24.234984 10416 solver.cpp:237]     Train net output #1: loss = 0.845111 (* 1 = 0.845111 loss)
I1210 13:35:24.234984 10416 sgd_solver.cpp:105] Iteration 86800, lr = 0.01
I1210 13:35:29.908432 10416 solver.cpp:218] Iteration 86900 (17.6282 iter/s, 5.67274s/100 iters), loss = 0.933228
I1210 13:35:29.908432 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:35:29.908432 10416 solver.cpp:237]     Train net output #1: loss = 0.933228 (* 1 = 0.933228 loss)
I1210 13:35:29.908432 10416 sgd_solver.cpp:105] Iteration 86900, lr = 0.01
I1210 13:35:35.300844  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:35:35.523857 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_87000.caffemodel
I1210 13:35:35.543856 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_87000.solverstate
I1210 13:35:35.548856 10416 solver.cpp:330] Iteration 87000, Testing net (#0)
I1210 13:35:35.548856 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:35:36.931973  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:35:36.985980 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5887
I1210 13:35:36.986980 10416 solver.cpp:397]     Test net output #1: loss = 1.60876 (* 1 = 1.60876 loss)
I1210 13:35:37.039980 10416 solver.cpp:218] Iteration 87000 (14.023 iter/s, 7.13116s/100 iters), loss = 0.664533
I1210 13:35:37.039980 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:35:37.039980 10416 solver.cpp:237]     Train net output #1: loss = 0.664533 (* 1 = 0.664533 loss)
I1210 13:35:37.039980 10416 sgd_solver.cpp:105] Iteration 87000, lr = 0.01
I1210 13:35:42.707401 10416 solver.cpp:218] Iteration 87100 (17.6447 iter/s, 5.66741s/100 iters), loss = 0.666662
I1210 13:35:42.707401 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:35:42.707401 10416 solver.cpp:237]     Train net output #1: loss = 0.666662 (* 1 = 0.666662 loss)
I1210 13:35:42.707401 10416 sgd_solver.cpp:105] Iteration 87100, lr = 0.01
I1210 13:35:48.370298 10416 solver.cpp:218] Iteration 87200 (17.6613 iter/s, 5.6621s/100 iters), loss = 0.518255
I1210 13:35:48.370298 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:35:48.370298 10416 solver.cpp:237]     Train net output #1: loss = 0.518255 (* 1 = 0.518255 loss)
I1210 13:35:48.370298 10416 sgd_solver.cpp:105] Iteration 87200, lr = 0.01
I1210 13:35:54.041211 10416 solver.cpp:218] Iteration 87300 (17.6348 iter/s, 5.6706s/100 iters), loss = 0.795091
I1210 13:35:54.041211 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:35:54.041211 10416 solver.cpp:237]     Train net output #1: loss = 0.795091 (* 1 = 0.795091 loss)
I1210 13:35:54.041211 10416 sgd_solver.cpp:105] Iteration 87300, lr = 0.01
I1210 13:35:59.703688 10416 solver.cpp:218] Iteration 87400 (17.6617 iter/s, 5.66198s/100 iters), loss = 0.859919
I1210 13:35:59.703688 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:35:59.703688 10416 solver.cpp:237]     Train net output #1: loss = 0.859919 (* 1 = 0.859919 loss)
I1210 13:35:59.703688 10416 sgd_solver.cpp:105] Iteration 87400, lr = 0.01
I1210 13:36:05.090091  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:36:05.313100 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_87500.caffemodel
I1210 13:36:05.333101 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_87500.solverstate
I1210 13:36:05.338100 10416 solver.cpp:330] Iteration 87500, Testing net (#0)
I1210 13:36:05.338100 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:36:06.719204  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:36:06.774729 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5696
I1210 13:36:06.774729 10416 solver.cpp:397]     Test net output #1: loss = 1.67611 (* 1 = 1.67611 loss)
I1210 13:36:06.828238 10416 solver.cpp:218] Iteration 87500 (14.0371 iter/s, 7.12399s/100 iters), loss = 0.620718
I1210 13:36:06.828238 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:36:06.828238 10416 solver.cpp:237]     Train net output #1: loss = 0.620718 (* 1 = 0.620718 loss)
I1210 13:36:06.828238 10416 sgd_solver.cpp:105] Iteration 87500, lr = 0.01
I1210 13:36:12.492621 10416 solver.cpp:218] Iteration 87600 (17.6544 iter/s, 5.66433s/100 iters), loss = 0.608136
I1210 13:36:12.492621 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:36:12.492621 10416 solver.cpp:237]     Train net output #1: loss = 0.608136 (* 1 = 0.608136 loss)
I1210 13:36:12.492621 10416 sgd_solver.cpp:105] Iteration 87600, lr = 0.01
I1210 13:36:18.160044 10416 solver.cpp:218] Iteration 87700 (17.6483 iter/s, 5.66625s/100 iters), loss = 0.545046
I1210 13:36:18.160044 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:36:18.160044 10416 solver.cpp:237]     Train net output #1: loss = 0.545046 (* 1 = 0.545046 loss)
I1210 13:36:18.160044 10416 sgd_solver.cpp:105] Iteration 87700, lr = 0.01
I1210 13:36:23.816438 10416 solver.cpp:218] Iteration 87800 (17.6796 iter/s, 5.65625s/100 iters), loss = 0.810471
I1210 13:36:23.816438 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:36:23.816438 10416 solver.cpp:237]     Train net output #1: loss = 0.810471 (* 1 = 0.810471 loss)
I1210 13:36:23.816438 10416 sgd_solver.cpp:105] Iteration 87800, lr = 0.01
I1210 13:36:29.477816 10416 solver.cpp:218] Iteration 87900 (17.666 iter/s, 5.66058s/100 iters), loss = 0.960529
I1210 13:36:29.477816 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:36:29.477816 10416 solver.cpp:237]     Train net output #1: loss = 0.960529 (* 1 = 0.960529 loss)
I1210 13:36:29.477816 10416 sgd_solver.cpp:105] Iteration 87900, lr = 0.01
I1210 13:36:34.858181  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:36:35.082195 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_88000.caffemodel
I1210 13:36:35.098194 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_88000.solverstate
I1210 13:36:35.102195 10416 solver.cpp:330] Iteration 88000, Testing net (#0)
I1210 13:36:35.102195 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:36:36.485316  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:36:36.538316 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5639
I1210 13:36:36.538316 10416 solver.cpp:397]     Test net output #1: loss = 1.7404 (* 1 = 1.7404 loss)
I1210 13:36:36.592321 10416 solver.cpp:218] Iteration 88000 (14.0552 iter/s, 7.11478s/100 iters), loss = 0.54467
I1210 13:36:36.592321 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:36:36.592321 10416 solver.cpp:237]     Train net output #1: loss = 0.54467 (* 1 = 0.54467 loss)
I1210 13:36:36.592321 10416 sgd_solver.cpp:105] Iteration 88000, lr = 0.01
I1210 13:36:42.270225 10416 solver.cpp:218] Iteration 88100 (17.6157 iter/s, 5.67676s/100 iters), loss = 0.732378
I1210 13:36:42.270225 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:36:42.270225 10416 solver.cpp:237]     Train net output #1: loss = 0.732378 (* 1 = 0.732378 loss)
I1210 13:36:42.270225 10416 sgd_solver.cpp:105] Iteration 88100, lr = 0.01
I1210 13:36:47.944970 10416 solver.cpp:218] Iteration 88200 (17.6213 iter/s, 5.67494s/100 iters), loss = 0.591517
I1210 13:36:47.944970 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:36:47.944970 10416 solver.cpp:237]     Train net output #1: loss = 0.591517 (* 1 = 0.591517 loss)
I1210 13:36:47.944970 10416 sgd_solver.cpp:105] Iteration 88200, lr = 0.01
I1210 13:36:53.622323 10416 solver.cpp:218] Iteration 88300 (17.6166 iter/s, 5.67645s/100 iters), loss = 0.710473
I1210 13:36:53.622323 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:36:53.622323 10416 solver.cpp:237]     Train net output #1: loss = 0.710473 (* 1 = 0.710473 loss)
I1210 13:36:53.622323 10416 sgd_solver.cpp:105] Iteration 88300, lr = 0.01
I1210 13:36:59.292242 10416 solver.cpp:218] Iteration 88400 (17.6386 iter/s, 5.66939s/100 iters), loss = 0.951759
I1210 13:36:59.292242 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 13:36:59.292242 10416 solver.cpp:237]     Train net output #1: loss = 0.951759 (* 1 = 0.951759 loss)
I1210 13:36:59.292242 10416 sgd_solver.cpp:105] Iteration 88400, lr = 0.01
I1210 13:37:04.683261  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:37:04.906934 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_88500.caffemodel
I1210 13:37:04.925943 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_88500.solverstate
I1210 13:37:04.930938 10416 solver.cpp:330] Iteration 88500, Testing net (#0)
I1210 13:37:04.930938 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:37:06.312564  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:37:06.368576 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5667
I1210 13:37:06.368576 10416 solver.cpp:397]     Test net output #1: loss = 1.76537 (* 1 = 1.76537 loss)
I1210 13:37:06.422614 10416 solver.cpp:218] Iteration 88500 (14.0259 iter/s, 7.12968s/100 iters), loss = 0.724061
I1210 13:37:06.422614 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:37:06.422614 10416 solver.cpp:237]     Train net output #1: loss = 0.724061 (* 1 = 0.724061 loss)
I1210 13:37:06.422614 10416 sgd_solver.cpp:105] Iteration 88500, lr = 0.01
I1210 13:37:12.105358 10416 solver.cpp:218] Iteration 88600 (17.5984 iter/s, 5.68233s/100 iters), loss = 0.641841
I1210 13:37:12.105358 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:37:12.105358 10416 solver.cpp:237]     Train net output #1: loss = 0.641841 (* 1 = 0.641841 loss)
I1210 13:37:12.105358 10416 sgd_solver.cpp:105] Iteration 88600, lr = 0.01
I1210 13:37:17.796757 10416 solver.cpp:218] Iteration 88700 (17.5703 iter/s, 5.69141s/100 iters), loss = 0.611275
I1210 13:37:17.796757 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:37:17.796757 10416 solver.cpp:237]     Train net output #1: loss = 0.611275 (* 1 = 0.611275 loss)
I1210 13:37:17.796757 10416 sgd_solver.cpp:105] Iteration 88700, lr = 0.01
I1210 13:37:23.479429 10416 solver.cpp:218] Iteration 88800 (17.5996 iter/s, 5.68194s/100 iters), loss = 0.837582
I1210 13:37:23.479931 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:37:23.479931 10416 solver.cpp:237]     Train net output #1: loss = 0.837582 (* 1 = 0.837582 loss)
I1210 13:37:23.479931 10416 sgd_solver.cpp:105] Iteration 88800, lr = 0.01
I1210 13:37:29.169661 10416 solver.cpp:218] Iteration 88900 (17.5754 iter/s, 5.68977s/100 iters), loss = 0.756174
I1210 13:37:29.169661 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:37:29.169661 10416 solver.cpp:237]     Train net output #1: loss = 0.756174 (* 1 = 0.756174 loss)
I1210 13:37:29.169661 10416 sgd_solver.cpp:105] Iteration 88900, lr = 0.01
I1210 13:37:34.582027  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:37:34.805049 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_89000.caffemodel
I1210 13:37:34.822049 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_89000.solverstate
I1210 13:37:34.827049 10416 solver.cpp:330] Iteration 89000, Testing net (#0)
I1210 13:37:34.827049 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:37:36.212139  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:37:36.266137 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5896
I1210 13:37:36.266137 10416 solver.cpp:397]     Test net output #1: loss = 1.5869 (* 1 = 1.5869 loss)
I1210 13:37:36.321146 10416 solver.cpp:218] Iteration 89000 (13.9833 iter/s, 7.1514s/100 iters), loss = 0.676021
I1210 13:37:36.321146 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:37:36.321146 10416 solver.cpp:237]     Train net output #1: loss = 0.676021 (* 1 = 0.676021 loss)
I1210 13:37:36.321146 10416 sgd_solver.cpp:105] Iteration 89000, lr = 0.01
I1210 13:37:42.000563 10416 solver.cpp:218] Iteration 89100 (17.6097 iter/s, 5.67869s/100 iters), loss = 0.664273
I1210 13:37:42.000563 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:37:42.000563 10416 solver.cpp:237]     Train net output #1: loss = 0.664273 (* 1 = 0.664273 loss)
I1210 13:37:42.000563 10416 sgd_solver.cpp:105] Iteration 89100, lr = 0.01
I1210 13:37:47.690001 10416 solver.cpp:218] Iteration 89200 (17.5783 iter/s, 5.68882s/100 iters), loss = 0.638107
I1210 13:37:47.690001 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:37:47.690001 10416 solver.cpp:237]     Train net output #1: loss = 0.638107 (* 1 = 0.638107 loss)
I1210 13:37:47.690001 10416 sgd_solver.cpp:105] Iteration 89200, lr = 0.01
I1210 13:37:53.360442 10416 solver.cpp:218] Iteration 89300 (17.6372 iter/s, 5.66985s/100 iters), loss = 0.766713
I1210 13:37:53.360442 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:37:53.360442 10416 solver.cpp:237]     Train net output #1: loss = 0.766713 (* 1 = 0.766713 loss)
I1210 13:37:53.360442 10416 sgd_solver.cpp:105] Iteration 89300, lr = 0.01
I1210 13:37:59.045833 10416 solver.cpp:218] Iteration 89400 (17.5895 iter/s, 5.6852s/100 iters), loss = 0.978575
I1210 13:37:59.045833 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:37:59.045833 10416 solver.cpp:237]     Train net output #1: loss = 0.978575 (* 1 = 0.978575 loss)
I1210 13:37:59.045833 10416 sgd_solver.cpp:105] Iteration 89400, lr = 0.01
I1210 13:38:04.448205  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:38:04.669229 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_89500.caffemodel
I1210 13:38:04.687732 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_89500.solverstate
I1210 13:38:04.693236 10416 solver.cpp:330] Iteration 89500, Testing net (#0)
I1210 13:38:04.693236 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:38:06.077358  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:38:06.130362 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5822
I1210 13:38:06.130362 10416 solver.cpp:397]     Test net output #1: loss = 1.70973 (* 1 = 1.70973 loss)
I1210 13:38:06.184876 10416 solver.cpp:218] Iteration 89500 (14.0089 iter/s, 7.13832s/100 iters), loss = 0.601244
I1210 13:38:06.184876 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:38:06.184876 10416 solver.cpp:237]     Train net output #1: loss = 0.601244 (* 1 = 0.601244 loss)
I1210 13:38:06.184876 10416 sgd_solver.cpp:105] Iteration 89500, lr = 0.01
I1210 13:38:11.864791 10416 solver.cpp:218] Iteration 89600 (17.6074 iter/s, 5.67943s/100 iters), loss = 0.622636
I1210 13:38:11.864791 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:38:11.864791 10416 solver.cpp:237]     Train net output #1: loss = 0.622636 (* 1 = 0.622636 loss)
I1210 13:38:11.864791 10416 sgd_solver.cpp:105] Iteration 89600, lr = 0.01
I1210 13:38:17.554240 10416 solver.cpp:218] Iteration 89700 (17.5761 iter/s, 5.68953s/100 iters), loss = 0.598645
I1210 13:38:17.554240 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:38:17.554240 10416 solver.cpp:237]     Train net output #1: loss = 0.598645 (* 1 = 0.598645 loss)
I1210 13:38:17.554240 10416 sgd_solver.cpp:105] Iteration 89700, lr = 0.01
I1210 13:38:23.238636 10416 solver.cpp:218] Iteration 89800 (17.5956 iter/s, 5.68325s/100 iters), loss = 0.889842
I1210 13:38:23.238636 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:38:23.238636 10416 solver.cpp:237]     Train net output #1: loss = 0.889842 (* 1 = 0.889842 loss)
I1210 13:38:23.238636 10416 sgd_solver.cpp:105] Iteration 89800, lr = 0.01
I1210 13:38:28.918015 10416 solver.cpp:218] Iteration 89900 (17.608 iter/s, 5.67924s/100 iters), loss = 0.878761
I1210 13:38:28.918015 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 13:38:28.918015 10416 solver.cpp:237]     Train net output #1: loss = 0.878761 (* 1 = 0.878761 loss)
I1210 13:38:28.918015 10416 sgd_solver.cpp:105] Iteration 89900, lr = 0.01
I1210 13:38:34.322410  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:38:34.546422 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90000.caffemodel
I1210 13:38:34.566422 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90000.solverstate
I1210 13:38:34.571424 10416 solver.cpp:330] Iteration 90000, Testing net (#0)
I1210 13:38:34.571424 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:38:35.955523  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:38:36.010527 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5871
I1210 13:38:36.010527 10416 solver.cpp:397]     Test net output #1: loss = 1.66452 (* 1 = 1.66452 loss)
I1210 13:38:36.065528 10416 solver.cpp:218] Iteration 90000 (13.9925 iter/s, 7.14671s/100 iters), loss = 0.662251
I1210 13:38:36.065528 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:38:36.065528 10416 solver.cpp:237]     Train net output #1: loss = 0.662251 (* 1 = 0.662251 loss)
I1210 13:38:36.065528 10416 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1210 13:38:41.739907 10416 solver.cpp:218] Iteration 90100 (17.6243 iter/s, 5.67398s/100 iters), loss = 0.731857
I1210 13:38:41.739907 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:38:41.739907 10416 solver.cpp:237]     Train net output #1: loss = 0.731857 (* 1 = 0.731857 loss)
I1210 13:38:41.739907 10416 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1210 13:38:47.405338 10416 solver.cpp:218] Iteration 90200 (17.6508 iter/s, 5.66548s/100 iters), loss = 0.559828
I1210 13:38:47.405338 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:38:47.405338 10416 solver.cpp:237]     Train net output #1: loss = 0.559828 (* 1 = 0.559828 loss)
I1210 13:38:47.405338 10416 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1210 13:38:53.071741 10416 solver.cpp:218] Iteration 90300 (17.65 iter/s, 5.66574s/100 iters), loss = 0.710321
I1210 13:38:53.071741 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 13:38:53.071741 10416 solver.cpp:237]     Train net output #1: loss = 0.710321 (* 1 = 0.710321 loss)
I1210 13:38:53.071741 10416 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1210 13:38:58.746155 10416 solver.cpp:218] Iteration 90400 (17.6241 iter/s, 5.67405s/100 iters), loss = 0.816368
I1210 13:38:58.746155 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:38:58.746155 10416 solver.cpp:237]     Train net output #1: loss = 0.816368 (* 1 = 0.816368 loss)
I1210 13:38:58.746155 10416 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1210 13:39:04.134548  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:39:04.357559 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90500.caffemodel
I1210 13:39:04.377562 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90500.solverstate
I1210 13:39:04.382062 10416 solver.cpp:330] Iteration 90500, Testing net (#0)
I1210 13:39:04.382563 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:39:05.763671  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:39:05.819682 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5806
I1210 13:39:05.819682 10416 solver.cpp:397]     Test net output #1: loss = 1.63377 (* 1 = 1.63377 loss)
I1210 13:39:05.872681 10416 solver.cpp:218] Iteration 90500 (14.0326 iter/s, 7.12626s/100 iters), loss = 0.604689
I1210 13:39:05.872681 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:39:05.872681 10416 solver.cpp:237]     Train net output #1: loss = 0.604689 (* 1 = 0.604689 loss)
I1210 13:39:05.872681 10416 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1210 13:39:11.540081 10416 solver.cpp:218] Iteration 90600 (17.6457 iter/s, 5.66709s/100 iters), loss = 0.689547
I1210 13:39:11.541069 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:39:11.541069 10416 solver.cpp:237]     Train net output #1: loss = 0.689547 (* 1 = 0.689547 loss)
I1210 13:39:11.541069 10416 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1210 13:39:17.204531 10416 solver.cpp:218] Iteration 90700 (17.657 iter/s, 5.66347s/100 iters), loss = 0.49639
I1210 13:39:17.204531 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:39:17.204531 10416 solver.cpp:237]     Train net output #1: loss = 0.49639 (* 1 = 0.49639 loss)
I1210 13:39:17.204531 10416 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1210 13:39:22.878886 10416 solver.cpp:218] Iteration 90800 (17.6254 iter/s, 5.67364s/100 iters), loss = 0.722954
I1210 13:39:22.878886 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:39:22.878886 10416 solver.cpp:237]     Train net output #1: loss = 0.722954 (* 1 = 0.722954 loss)
I1210 13:39:22.878886 10416 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1210 13:39:28.545403 10416 solver.cpp:218] Iteration 90900 (17.647 iter/s, 5.66669s/100 iters), loss = 0.880945
I1210 13:39:28.545403 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:39:28.545403 10416 solver.cpp:237]     Train net output #1: loss = 0.880945 (* 1 = 0.880945 loss)
I1210 13:39:28.545403 10416 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1210 13:39:33.934767  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:39:34.154778 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91000.caffemodel
I1210 13:39:34.170779 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91000.solverstate
I1210 13:39:34.174778 10416 solver.cpp:330] Iteration 91000, Testing net (#0)
I1210 13:39:34.174778 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:39:35.558897  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:39:35.612902 10416 solver.cpp:397]     Test net output #0: accuracy = 0.581
I1210 13:39:35.612902 10416 solver.cpp:397]     Test net output #1: loss = 1.59524 (* 1 = 1.59524 loss)
I1210 13:39:35.666901 10416 solver.cpp:218] Iteration 91000 (14.043 iter/s, 7.12098s/100 iters), loss = 0.705522
I1210 13:39:35.666901 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:39:35.666901 10416 solver.cpp:237]     Train net output #1: loss = 0.705522 (* 1 = 0.705522 loss)
I1210 13:39:35.666901 10416 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1210 13:39:41.348251 10416 solver.cpp:218] Iteration 91100 (17.6034 iter/s, 5.68071s/100 iters), loss = 0.741604
I1210 13:39:41.348251 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:39:41.348251 10416 solver.cpp:237]     Train net output #1: loss = 0.741604 (* 1 = 0.741604 loss)
I1210 13:39:41.348251 10416 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1210 13:39:47.022655 10416 solver.cpp:218] Iteration 91200 (17.6252 iter/s, 5.6737s/100 iters), loss = 0.502701
I1210 13:39:47.022655 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:39:47.022655 10416 solver.cpp:237]     Train net output #1: loss = 0.502701 (* 1 = 0.502701 loss)
I1210 13:39:47.022655 10416 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1210 13:39:52.717602 10416 solver.cpp:218] Iteration 91300 (17.5611 iter/s, 5.69441s/100 iters), loss = 0.746331
I1210 13:39:52.717602 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:39:52.717602 10416 solver.cpp:237]     Train net output #1: loss = 0.746331 (* 1 = 0.746331 loss)
I1210 13:39:52.717602 10416 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1210 13:39:58.405877 10416 solver.cpp:218] Iteration 91400 (17.58 iter/s, 5.68828s/100 iters), loss = 0.746693
I1210 13:39:58.405877 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:39:58.406878 10416 solver.cpp:237]     Train net output #1: loss = 0.746693 (* 1 = 0.746693 loss)
I1210 13:39:58.406878 10416 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1210 13:40:03.831394  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:40:04.056407 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91500.caffemodel
I1210 13:40:04.072417 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91500.solverstate
I1210 13:40:04.077406 10416 solver.cpp:330] Iteration 91500, Testing net (#0)
I1210 13:40:04.077406 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:40:05.461516  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:40:05.513520 10416 solver.cpp:397]     Test net output #0: accuracy = 0.542
I1210 13:40:05.514521 10416 solver.cpp:397]     Test net output #1: loss = 1.89329 (* 1 = 1.89329 loss)
I1210 13:40:05.567520 10416 solver.cpp:218] Iteration 91500 (13.9652 iter/s, 7.16068s/100 iters), loss = 0.616941
I1210 13:40:05.567520 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:40:05.567520 10416 solver.cpp:237]     Train net output #1: loss = 0.616941 (* 1 = 0.616941 loss)
I1210 13:40:05.567520 10416 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1210 13:40:11.237931 10416 solver.cpp:218] Iteration 91600 (17.6373 iter/s, 5.66979s/100 iters), loss = 0.752577
I1210 13:40:11.237931 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:40:11.237931 10416 solver.cpp:237]     Train net output #1: loss = 0.752577 (* 1 = 0.752577 loss)
I1210 13:40:11.237931 10416 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1210 13:40:16.919317 10416 solver.cpp:218] Iteration 91700 (17.602 iter/s, 5.68118s/100 iters), loss = 0.501064
I1210 13:40:16.919317 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:40:16.919317 10416 solver.cpp:237]     Train net output #1: loss = 0.501064 (* 1 = 0.501064 loss)
I1210 13:40:16.919317 10416 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1210 13:40:22.597682 10416 solver.cpp:218] Iteration 91800 (17.613 iter/s, 5.67763s/100 iters), loss = 0.787895
I1210 13:40:22.597682 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 13:40:22.597682 10416 solver.cpp:237]     Train net output #1: loss = 0.787895 (* 1 = 0.787895 loss)
I1210 13:40:22.597682 10416 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1210 13:40:28.278077 10416 solver.cpp:218] Iteration 91900 (17.6037 iter/s, 5.68063s/100 iters), loss = 0.698505
I1210 13:40:28.278077 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:40:28.278077 10416 solver.cpp:237]     Train net output #1: loss = 0.698505 (* 1 = 0.698505 loss)
I1210 13:40:28.278077 10416 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1210 13:40:33.671433  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:40:33.892452 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92000.caffemodel
I1210 13:40:33.907459 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92000.solverstate
I1210 13:40:33.911458 10416 solver.cpp:330] Iteration 92000, Testing net (#0)
I1210 13:40:33.911458 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:40:35.297562  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:40:35.351565 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6049
I1210 13:40:35.352566 10416 solver.cpp:397]     Test net output #1: loss = 1.51661 (* 1 = 1.51661 loss)
I1210 13:40:35.405570 10416 solver.cpp:218] Iteration 92000 (14.0323 iter/s, 7.12641s/100 iters), loss = 0.676919
I1210 13:40:35.405570 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:40:35.405570 10416 solver.cpp:237]     Train net output #1: loss = 0.676919 (* 1 = 0.676919 loss)
I1210 13:40:35.405570 10416 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1210 13:40:41.081935 10416 solver.cpp:218] Iteration 92100 (17.618 iter/s, 5.67601s/100 iters), loss = 0.617325
I1210 13:40:41.081935 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:40:41.081935 10416 solver.cpp:237]     Train net output #1: loss = 0.617325 (* 1 = 0.617325 loss)
I1210 13:40:41.081935 10416 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1210 13:40:46.755581 10416 solver.cpp:218] Iteration 92200 (17.6281 iter/s, 5.67277s/100 iters), loss = 0.546335
I1210 13:40:46.755581 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:40:46.755581 10416 solver.cpp:237]     Train net output #1: loss = 0.546335 (* 1 = 0.546335 loss)
I1210 13:40:46.755581 10416 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1210 13:40:52.418781 10416 solver.cpp:218] Iteration 92300 (17.6578 iter/s, 5.66322s/100 iters), loss = 0.742777
I1210 13:40:52.418781 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:40:52.418781 10416 solver.cpp:237]     Train net output #1: loss = 0.742777 (* 1 = 0.742777 loss)
I1210 13:40:52.418781 10416 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1210 13:40:58.077320 10416 solver.cpp:218] Iteration 92400 (17.6752 iter/s, 5.65764s/100 iters), loss = 0.752397
I1210 13:40:58.077320 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:40:58.077320 10416 solver.cpp:237]     Train net output #1: loss = 0.752397 (* 1 = 0.752397 loss)
I1210 13:40:58.077320 10416 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1210 13:41:03.464622  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:41:03.684695 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92500.caffemodel
I1210 13:41:03.701181 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92500.solverstate
I1210 13:41:03.706682 10416 solver.cpp:330] Iteration 92500, Testing net (#0)
I1210 13:41:03.706682 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:41:05.091761  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:41:05.145316 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5869
I1210 13:41:05.145316 10416 solver.cpp:397]     Test net output #1: loss = 1.58521 (* 1 = 1.58521 loss)
I1210 13:41:05.199306 10416 solver.cpp:218] Iteration 92500 (14.0416 iter/s, 7.12168s/100 iters), loss = 0.576203
I1210 13:41:05.199306 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:41:05.199306 10416 solver.cpp:237]     Train net output #1: loss = 0.576203 (* 1 = 0.576203 loss)
I1210 13:41:05.199306 10416 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1210 13:41:10.860235 10416 solver.cpp:218] Iteration 92600 (17.6663 iter/s, 5.66048s/100 iters), loss = 0.716802
I1210 13:41:10.860235 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:41:10.860235 10416 solver.cpp:237]     Train net output #1: loss = 0.716802 (* 1 = 0.716802 loss)
I1210 13:41:10.860235 10416 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1210 13:41:16.515780 10416 solver.cpp:218] Iteration 92700 (17.6831 iter/s, 5.65513s/100 iters), loss = 0.577052
I1210 13:41:16.515780 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:41:16.515780 10416 solver.cpp:237]     Train net output #1: loss = 0.577052 (* 1 = 0.577052 loss)
I1210 13:41:16.515780 10416 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1210 13:41:22.172770 10416 solver.cpp:218] Iteration 92800 (17.6794 iter/s, 5.65631s/100 iters), loss = 0.802731
I1210 13:41:22.172770 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:41:22.172770 10416 solver.cpp:237]     Train net output #1: loss = 0.802731 (* 1 = 0.802731 loss)
I1210 13:41:22.172770 10416 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1210 13:41:27.828492 10416 solver.cpp:218] Iteration 92900 (17.6834 iter/s, 5.65503s/100 iters), loss = 0.938966
I1210 13:41:27.828492 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:41:27.828492 10416 solver.cpp:237]     Train net output #1: loss = 0.938966 (* 1 = 0.938966 loss)
I1210 13:41:27.828492 10416 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1210 13:41:33.204450  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:41:33.428544 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93000.caffemodel
I1210 13:41:33.444550 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93000.solverstate
I1210 13:41:33.449532 10416 solver.cpp:330] Iteration 93000, Testing net (#0)
I1210 13:41:33.449532 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:41:34.833032  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:41:34.886036 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5878
I1210 13:41:34.886036 10416 solver.cpp:397]     Test net output #1: loss = 1.59196 (* 1 = 1.59196 loss)
I1210 13:41:34.940052 10416 solver.cpp:218] Iteration 93000 (14.0617 iter/s, 7.1115s/100 iters), loss = 0.53234
I1210 13:41:34.940052 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 13:41:34.940052 10416 solver.cpp:237]     Train net output #1: loss = 0.53234 (* 1 = 0.53234 loss)
I1210 13:41:34.940052 10416 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1210 13:41:40.615794 10416 solver.cpp:218] Iteration 93100 (17.6207 iter/s, 5.67515s/100 iters), loss = 0.67028
I1210 13:41:40.616283 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:41:40.616283 10416 solver.cpp:237]     Train net output #1: loss = 0.67028 (* 1 = 0.67028 loss)
I1210 13:41:40.616283 10416 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1210 13:41:46.282228 10416 solver.cpp:218] Iteration 93200 (17.6503 iter/s, 5.66561s/100 iters), loss = 0.501594
I1210 13:41:46.282228 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:41:46.282228 10416 solver.cpp:237]     Train net output #1: loss = 0.501594 (* 1 = 0.501594 loss)
I1210 13:41:46.282228 10416 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1210 13:41:51.957638 10416 solver.cpp:218] Iteration 93300 (17.6204 iter/s, 5.67524s/100 iters), loss = 0.731991
I1210 13:41:51.957638 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:41:51.957638 10416 solver.cpp:237]     Train net output #1: loss = 0.731991 (* 1 = 0.731991 loss)
I1210 13:41:51.957638 10416 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1210 13:41:57.626091 10416 solver.cpp:218] Iteration 93400 (17.6425 iter/s, 5.66814s/100 iters), loss = 0.88343
I1210 13:41:57.626091 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:41:57.626091 10416 solver.cpp:237]     Train net output #1: loss = 0.88343 (* 1 = 0.88343 loss)
I1210 13:41:57.626091 10416 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1210 13:42:03.028442  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:42:03.248459 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93500.caffemodel
I1210 13:42:03.268461 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93500.solverstate
I1210 13:42:03.273459 10416 solver.cpp:330] Iteration 93500, Testing net (#0)
I1210 13:42:03.273459 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:42:04.659575  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:42:04.713585 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5755
I1210 13:42:04.713585 10416 solver.cpp:397]     Test net output #1: loss = 1.64383 (* 1 = 1.64383 loss)
I1210 13:42:04.767591 10416 solver.cpp:218] Iteration 93500 (14.0034 iter/s, 7.14114s/100 iters), loss = 0.532431
I1210 13:42:04.767591 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:42:04.767591 10416 solver.cpp:237]     Train net output #1: loss = 0.532431 (* 1 = 0.532431 loss)
I1210 13:42:04.767591 10416 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1210 13:42:10.448992 10416 solver.cpp:218] Iteration 93600 (17.6036 iter/s, 5.68067s/100 iters), loss = 0.704466
I1210 13:42:10.448992 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:42:10.448992 10416 solver.cpp:237]     Train net output #1: loss = 0.704466 (* 1 = 0.704466 loss)
I1210 13:42:10.448992 10416 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1210 13:42:16.135489 10416 solver.cpp:218] Iteration 93700 (17.5866 iter/s, 5.68614s/100 iters), loss = 0.49591
I1210 13:42:16.135489 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:42:16.135489 10416 solver.cpp:237]     Train net output #1: loss = 0.49591 (* 1 = 0.49591 loss)
I1210 13:42:16.135489 10416 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1210 13:42:21.815945 10416 solver.cpp:218] Iteration 93800 (17.6064 iter/s, 5.67976s/100 iters), loss = 0.758659
I1210 13:42:21.815945 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 13:42:21.815945 10416 solver.cpp:237]     Train net output #1: loss = 0.758659 (* 1 = 0.758659 loss)
I1210 13:42:21.815945 10416 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1210 13:42:27.494386 10416 solver.cpp:218] Iteration 93900 (17.6101 iter/s, 5.67854s/100 iters), loss = 0.795899
I1210 13:42:27.494386 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:42:27.494386 10416 solver.cpp:237]     Train net output #1: loss = 0.795899 (* 1 = 0.795899 loss)
I1210 13:42:27.495385 10416 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1210 13:42:32.905848  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:42:33.131889 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94000.caffemodel
I1210 13:42:33.146889 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94000.solverstate
I1210 13:42:33.151893 10416 solver.cpp:330] Iteration 94000, Testing net (#0)
I1210 13:42:33.151893 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:42:34.537029  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:42:34.592033 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5884
I1210 13:42:34.592033 10416 solver.cpp:397]     Test net output #1: loss = 1.56222 (* 1 = 1.56222 loss)
I1210 13:42:34.645035 10416 solver.cpp:218] Iteration 94000 (13.9866 iter/s, 7.14969s/100 iters), loss = 0.637607
I1210 13:42:34.645035 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:42:34.645035 10416 solver.cpp:237]     Train net output #1: loss = 0.637607 (* 1 = 0.637607 loss)
I1210 13:42:34.645035 10416 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1210 13:42:40.316077 10416 solver.cpp:218] Iteration 94100 (17.636 iter/s, 5.67024s/100 iters), loss = 0.718188
I1210 13:42:40.316077 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:42:40.316077 10416 solver.cpp:237]     Train net output #1: loss = 0.718188 (* 1 = 0.718188 loss)
I1210 13:42:40.316077 10416 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1210 13:42:45.991011 10416 solver.cpp:218] Iteration 94200 (17.62 iter/s, 5.67536s/100 iters), loss = 0.51251
I1210 13:42:45.991011 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:42:45.992012 10416 solver.cpp:237]     Train net output #1: loss = 0.51251 (* 1 = 0.51251 loss)
I1210 13:42:45.992012 10416 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1210 13:42:51.660424 10416 solver.cpp:218] Iteration 94300 (17.6413 iter/s, 5.66853s/100 iters), loss = 0.699467
I1210 13:42:51.660424 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:42:51.660424 10416 solver.cpp:237]     Train net output #1: loss = 0.699467 (* 1 = 0.699467 loss)
I1210 13:42:51.660424 10416 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1210 13:42:57.330830 10416 solver.cpp:218] Iteration 94400 (17.6361 iter/s, 5.67018s/100 iters), loss = 0.747769
I1210 13:42:57.330830 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 13:42:57.330830 10416 solver.cpp:237]     Train net output #1: loss = 0.747769 (* 1 = 0.747769 loss)
I1210 13:42:57.330830 10416 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1210 13:43:02.725739  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:43:02.949251 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94500.caffemodel
I1210 13:43:02.968251 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94500.solverstate
I1210 13:43:02.973251 10416 solver.cpp:330] Iteration 94500, Testing net (#0)
I1210 13:43:02.973251 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:43:04.358345  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:43:04.412346 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5417
I1210 13:43:04.412346 10416 solver.cpp:397]     Test net output #1: loss = 1.82742 (* 1 = 1.82742 loss)
I1210 13:43:04.466351 10416 solver.cpp:218] Iteration 94500 (14.0168 iter/s, 7.13432s/100 iters), loss = 0.614068
I1210 13:43:04.466351 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:43:04.466351 10416 solver.cpp:237]     Train net output #1: loss = 0.614068 (* 1 = 0.614068 loss)
I1210 13:43:04.466351 10416 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1210 13:43:10.123302 10416 solver.cpp:218] Iteration 94600 (17.6788 iter/s, 5.65651s/100 iters), loss = 0.727331
I1210 13:43:10.123302 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:43:10.123302 10416 solver.cpp:237]     Train net output #1: loss = 0.727331 (* 1 = 0.727331 loss)
I1210 13:43:10.123302 10416 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1210 13:43:15.786191 10416 solver.cpp:218] Iteration 94700 (17.6584 iter/s, 5.66302s/100 iters), loss = 0.565202
I1210 13:43:15.786191 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:43:15.786191 10416 solver.cpp:237]     Train net output #1: loss = 0.565202 (* 1 = 0.565202 loss)
I1210 13:43:15.786191 10416 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1210 13:43:21.456622 10416 solver.cpp:218] Iteration 94800 (17.6383 iter/s, 5.66947s/100 iters), loss = 0.745926
I1210 13:43:21.456622 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 13:43:21.456622 10416 solver.cpp:237]     Train net output #1: loss = 0.745926 (* 1 = 0.745926 loss)
I1210 13:43:21.456622 10416 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1210 13:43:27.126097 10416 solver.cpp:218] Iteration 94900 (17.64 iter/s, 5.66894s/100 iters), loss = 0.79642
I1210 13:43:27.126097 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 13:43:27.126097 10416 solver.cpp:237]     Train net output #1: loss = 0.79642 (* 1 = 0.79642 loss)
I1210 13:43:27.126097 10416 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1210 13:43:32.511539  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:43:32.732553 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95000.caffemodel
I1210 13:43:32.751556 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95000.solverstate
I1210 13:43:32.756556 10416 solver.cpp:330] Iteration 95000, Testing net (#0)
I1210 13:43:32.756556 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:43:34.141674  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:43:34.193671 10416 solver.cpp:397]     Test net output #0: accuracy = 0.5835
I1210 13:43:34.194672 10416 solver.cpp:397]     Test net output #1: loss = 1.64704 (* 1 = 1.64704 loss)
I1210 13:43:34.247678 10416 solver.cpp:218] Iteration 95000 (14.0415 iter/s, 7.12175s/100 iters), loss = 0.680649
I1210 13:43:34.247678 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:43:34.247678 10416 solver.cpp:237]     Train net output #1: loss = 0.680649 (* 1 = 0.680649 loss)
I1210 13:43:34.247678 10416 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1210 13:43:34.247678 10416 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1210 13:43:39.916110 10416 solver.cpp:218] Iteration 95100 (17.6426 iter/s, 5.66809s/100 iters), loss = 0.80188
I1210 13:43:39.916110 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 13:43:39.916110 10416 solver.cpp:237]     Train net output #1: loss = 0.80188 (* 1 = 0.80188 loss)
I1210 13:43:39.917112 10416 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1210 13:43:45.573551 10416 solver.cpp:218] Iteration 95200 (17.6792 iter/s, 5.65638s/100 iters), loss = 0.423108
I1210 13:43:45.573551 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:43:45.573551 10416 solver.cpp:237]     Train net output #1: loss = 0.423108 (* 1 = 0.423108 loss)
I1210 13:43:45.573551 10416 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1210 13:43:51.238965 10416 solver.cpp:218] Iteration 95300 (17.6512 iter/s, 5.66535s/100 iters), loss = 0.529133
I1210 13:43:51.238965 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 13:43:51.238965 10416 solver.cpp:237]     Train net output #1: loss = 0.529133 (* 1 = 0.529133 loss)
I1210 13:43:51.238965 10416 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1210 13:43:56.906682 10416 solver.cpp:218] Iteration 95400 (17.6473 iter/s, 5.66659s/100 iters), loss = 0.585984
I1210 13:43:56.906682 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 13:43:56.906682 10416 solver.cpp:237]     Train net output #1: loss = 0.585984 (* 1 = 0.585984 loss)
I1210 13:43:56.906682 10416 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1210 13:44:02.298005  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:44:02.522020 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95500.caffemodel
I1210 13:44:02.538020 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95500.solverstate
I1210 13:44:02.543021 10416 solver.cpp:330] Iteration 95500, Testing net (#0)
I1210 13:44:02.543021 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:44:03.926148  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:44:03.980144 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6772
I1210 13:44:03.980144 10416 solver.cpp:397]     Test net output #1: loss = 1.17206 (* 1 = 1.17206 loss)
I1210 13:44:04.035158 10416 solver.cpp:218] Iteration 95500 (14.0285 iter/s, 7.12834s/100 iters), loss = 0.501303
I1210 13:44:04.035158 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:44:04.035158 10416 solver.cpp:237]     Train net output #1: loss = 0.501303 (* 1 = 0.501303 loss)
I1210 13:44:04.035158 10416 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1210 13:44:09.720554 10416 solver.cpp:218] Iteration 95600 (17.5893 iter/s, 5.68527s/100 iters), loss = 0.545183
I1210 13:44:09.720554 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 13:44:09.720554 10416 solver.cpp:237]     Train net output #1: loss = 0.545183 (* 1 = 0.545183 loss)
I1210 13:44:09.720554 10416 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1210 13:44:15.408941 10416 solver.cpp:218] Iteration 95700 (17.5814 iter/s, 5.68782s/100 iters), loss = 0.424254
I1210 13:44:15.408941 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:44:15.408941 10416 solver.cpp:237]     Train net output #1: loss = 0.424254 (* 1 = 0.424254 loss)
I1210 13:44:15.408941 10416 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1210 13:44:21.091334 10416 solver.cpp:218] Iteration 95800 (17.6004 iter/s, 5.68168s/100 iters), loss = 0.563271
I1210 13:44:21.091334 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:44:21.091831 10416 solver.cpp:237]     Train net output #1: loss = 0.563271 (* 1 = 0.563271 loss)
I1210 13:44:21.091831 10416 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1210 13:44:26.772707 10416 solver.cpp:218] Iteration 95900 (17.6043 iter/s, 5.68043s/100 iters), loss = 0.586629
I1210 13:44:26.772707 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:44:26.772707 10416 solver.cpp:237]     Train net output #1: loss = 0.586629 (* 1 = 0.586629 loss)
I1210 13:44:26.772707 10416 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1210 13:44:32.172086  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:44:32.395102 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96000.caffemodel
I1210 13:44:32.417106 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96000.solverstate
I1210 13:44:32.422106 10416 solver.cpp:330] Iteration 96000, Testing net (#0)
I1210 13:44:32.422106 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:44:33.803191  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:44:33.857193 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6802
I1210 13:44:33.857193 10416 solver.cpp:397]     Test net output #1: loss = 1.17215 (* 1 = 1.17215 loss)
I1210 13:44:33.911201 10416 solver.cpp:218] Iteration 96000 (14.0082 iter/s, 7.13868s/100 iters), loss = 0.465314
I1210 13:44:33.911201 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:44:33.911201 10416 solver.cpp:237]     Train net output #1: loss = 0.465314 (* 1 = 0.465314 loss)
I1210 13:44:33.911201 10416 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1210 13:44:39.582659 10416 solver.cpp:218] Iteration 96100 (17.6333 iter/s, 5.67108s/100 iters), loss = 0.540618
I1210 13:44:39.582659 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:44:39.582659 10416 solver.cpp:237]     Train net output #1: loss = 0.540618 (* 1 = 0.540618 loss)
I1210 13:44:39.582659 10416 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1210 13:44:45.256044 10416 solver.cpp:218] Iteration 96200 (17.6297 iter/s, 5.67224s/100 iters), loss = 0.365708
I1210 13:44:45.256044 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:44:45.256044 10416 solver.cpp:237]     Train net output #1: loss = 0.365708 (* 1 = 0.365708 loss)
I1210 13:44:45.256044 10416 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1210 13:44:50.923439 10416 solver.cpp:218] Iteration 96300 (17.646 iter/s, 5.667s/100 iters), loss = 0.498313
I1210 13:44:50.923439 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:44:50.923439 10416 solver.cpp:237]     Train net output #1: loss = 0.498313 (* 1 = 0.498313 loss)
I1210 13:44:50.923439 10416 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1210 13:44:56.577921 10416 solver.cpp:218] Iteration 96400 (17.6867 iter/s, 5.65397s/100 iters), loss = 0.473066
I1210 13:44:56.577921 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:44:56.577921 10416 solver.cpp:237]     Train net output #1: loss = 0.473066 (* 1 = 0.473066 loss)
I1210 13:44:56.577921 10416 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1210 13:45:01.960522  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:45:02.185535 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96500.caffemodel
I1210 13:45:02.205037 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96500.solverstate
I1210 13:45:02.209539 10416 solver.cpp:330] Iteration 96500, Testing net (#0)
I1210 13:45:02.209539 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:45:03.591629  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:45:03.645634 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6826
I1210 13:45:03.645634 10416 solver.cpp:397]     Test net output #1: loss = 1.16561 (* 1 = 1.16561 loss)
I1210 13:45:03.699163 10416 solver.cpp:218] Iteration 96500 (14.0432 iter/s, 7.12087s/100 iters), loss = 0.505911
I1210 13:45:03.699163 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:45:03.699163 10416 solver.cpp:237]     Train net output #1: loss = 0.505911 (* 1 = 0.505911 loss)
I1210 13:45:03.699163 10416 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1210 13:45:09.379106 10416 solver.cpp:218] Iteration 96600 (17.6077 iter/s, 5.67934s/100 iters), loss = 0.531101
I1210 13:45:09.379106 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:45:09.379106 10416 solver.cpp:237]     Train net output #1: loss = 0.531101 (* 1 = 0.531101 loss)
I1210 13:45:09.379106 10416 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1210 13:45:15.059520 10416 solver.cpp:218] Iteration 96700 (17.6047 iter/s, 5.68029s/100 iters), loss = 0.349385
I1210 13:45:15.059520 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:45:15.059520 10416 solver.cpp:237]     Train net output #1: loss = 0.349385 (* 1 = 0.349385 loss)
I1210 13:45:15.059520 10416 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1210 13:45:20.731982 10416 solver.cpp:218] Iteration 96800 (17.6298 iter/s, 5.6722s/100 iters), loss = 0.520285
I1210 13:45:20.731982 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:45:20.732985 10416 solver.cpp:237]     Train net output #1: loss = 0.520285 (* 1 = 0.520285 loss)
I1210 13:45:20.732985 10416 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1210 13:45:26.401950 10416 solver.cpp:218] Iteration 96900 (17.6406 iter/s, 5.66874s/100 iters), loss = 0.433946
I1210 13:45:26.401950 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:45:26.401950 10416 solver.cpp:237]     Train net output #1: loss = 0.433946 (* 1 = 0.433946 loss)
I1210 13:45:26.401950 10416 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1210 13:45:31.807332  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:45:32.031847 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97000.caffemodel
I1210 13:45:32.048847 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97000.solverstate
I1210 13:45:32.054847 10416 solver.cpp:330] Iteration 97000, Testing net (#0)
I1210 13:45:32.054847 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:45:33.437953  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:45:33.490957 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6814
I1210 13:45:33.490957 10416 solver.cpp:397]     Test net output #1: loss = 1.16894 (* 1 = 1.16894 loss)
I1210 13:45:33.545538 10416 solver.cpp:218] Iteration 97000 (13.9983 iter/s, 7.14373s/100 iters), loss = 0.424931
I1210 13:45:33.545538 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:45:33.545538 10416 solver.cpp:237]     Train net output #1: loss = 0.424931 (* 1 = 0.424931 loss)
I1210 13:45:33.546551 10416 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1210 13:45:39.221495 10416 solver.cpp:218] Iteration 97100 (17.6223 iter/s, 5.67463s/100 iters), loss = 0.420758
I1210 13:45:39.221495 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 13:45:39.221495 10416 solver.cpp:237]     Train net output #1: loss = 0.420758 (* 1 = 0.420758 loss)
I1210 13:45:39.221495 10416 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1210 13:45:44.893887 10416 solver.cpp:218] Iteration 97200 (17.6281 iter/s, 5.67276s/100 iters), loss = 0.316691
I1210 13:45:44.893887 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 13:45:44.893887 10416 solver.cpp:237]     Train net output #1: loss = 0.316691 (* 1 = 0.316691 loss)
I1210 13:45:44.893887 10416 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1210 13:45:50.564304 10416 solver.cpp:218] Iteration 97300 (17.6391 iter/s, 5.66922s/100 iters), loss = 0.548966
I1210 13:45:50.564304 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:45:50.564304 10416 solver.cpp:237]     Train net output #1: loss = 0.548966 (* 1 = 0.548966 loss)
I1210 13:45:50.564304 10416 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1210 13:45:56.249713 10416 solver.cpp:218] Iteration 97400 (17.5907 iter/s, 5.68482s/100 iters), loss = 0.562297
I1210 13:45:56.249713 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:45:56.249713 10416 solver.cpp:237]     Train net output #1: loss = 0.562297 (* 1 = 0.562297 loss)
I1210 13:45:56.249713 10416 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1210 13:46:01.656204  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:46:01.880216 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97500.caffemodel
I1210 13:46:01.896216 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97500.solverstate
I1210 13:46:01.901721 10416 solver.cpp:330] Iteration 97500, Testing net (#0)
I1210 13:46:01.901721 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:46:03.283301  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:46:03.337307 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6817
I1210 13:46:03.337307 10416 solver.cpp:397]     Test net output #1: loss = 1.17525 (* 1 = 1.17525 loss)
I1210 13:46:03.391306 10416 solver.cpp:218] Iteration 97500 (14.0032 iter/s, 7.14123s/100 iters), loss = 0.441489
I1210 13:46:03.391306 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:46:03.391306 10416 solver.cpp:237]     Train net output #1: loss = 0.441489 (* 1 = 0.441489 loss)
I1210 13:46:03.391306 10416 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1210 13:46:09.061712 10416 solver.cpp:218] Iteration 97600 (17.6351 iter/s, 5.67049s/100 iters), loss = 0.484444
I1210 13:46:09.061712 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:46:09.061712 10416 solver.cpp:237]     Train net output #1: loss = 0.484444 (* 1 = 0.484444 loss)
I1210 13:46:09.061712 10416 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1210 13:46:14.739081 10416 solver.cpp:218] Iteration 97700 (17.6171 iter/s, 5.6763s/100 iters), loss = 0.328655
I1210 13:46:14.739081 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:46:14.739081 10416 solver.cpp:237]     Train net output #1: loss = 0.328655 (* 1 = 0.328655 loss)
I1210 13:46:14.739081 10416 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1210 13:46:20.423470 10416 solver.cpp:218] Iteration 97800 (17.5922 iter/s, 5.68434s/100 iters), loss = 0.486629
I1210 13:46:20.423470 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:46:20.423470 10416 solver.cpp:237]     Train net output #1: loss = 0.486629 (* 1 = 0.486629 loss)
I1210 13:46:20.423470 10416 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1210 13:46:26.101438 10416 solver.cpp:218] Iteration 97900 (17.6134 iter/s, 5.6775s/100 iters), loss = 0.500089
I1210 13:46:26.101939 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:46:26.101939 10416 solver.cpp:237]     Train net output #1: loss = 0.500089 (* 1 = 0.500089 loss)
I1210 13:46:26.101939 10416 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1210 13:46:31.495471  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:46:31.717492 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98000.caffemodel
I1210 13:46:31.734496 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98000.solverstate
I1210 13:46:31.739497 10416 solver.cpp:330] Iteration 98000, Testing net (#0)
I1210 13:46:31.740497 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:46:33.124610  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:46:33.179607 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6824
I1210 13:46:33.179607 10416 solver.cpp:397]     Test net output #1: loss = 1.18371 (* 1 = 1.18371 loss)
I1210 13:46:33.233613 10416 solver.cpp:218] Iteration 98000 (14.0211 iter/s, 7.1321s/100 iters), loss = 0.408659
I1210 13:46:33.233613 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:46:33.233613 10416 solver.cpp:237]     Train net output #1: loss = 0.408659 (* 1 = 0.408659 loss)
I1210 13:46:33.234614 10416 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1210 13:46:38.909001 10416 solver.cpp:218] Iteration 98100 (17.6237 iter/s, 5.67418s/100 iters), loss = 0.500311
I1210 13:46:38.909001 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:46:38.909001 10416 solver.cpp:237]     Train net output #1: loss = 0.500311 (* 1 = 0.500311 loss)
I1210 13:46:38.909001 10416 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1210 13:46:44.578372 10416 solver.cpp:218] Iteration 98200 (17.6404 iter/s, 5.66882s/100 iters), loss = 0.32606
I1210 13:46:44.578372 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 13:46:44.578372 10416 solver.cpp:237]     Train net output #1: loss = 0.32606 (* 1 = 0.32606 loss)
I1210 13:46:44.578372 10416 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1210 13:46:50.249783 10416 solver.cpp:218] Iteration 98300 (17.6312 iter/s, 5.67178s/100 iters), loss = 0.479848
I1210 13:46:50.250784 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:46:50.250784 10416 solver.cpp:237]     Train net output #1: loss = 0.479848 (* 1 = 0.479848 loss)
I1210 13:46:50.250784 10416 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1210 13:46:55.920222 10416 solver.cpp:218] Iteration 98400 (17.6395 iter/s, 5.66909s/100 iters), loss = 0.530982
I1210 13:46:55.920222 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:46:55.920222 10416 solver.cpp:237]     Train net output #1: loss = 0.530982 (* 1 = 0.530982 loss)
I1210 13:46:55.920222 10416 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1210 13:47:01.315141  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:47:01.536659 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98500.caffemodel
I1210 13:47:01.550658 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98500.solverstate
I1210 13:47:01.555660 10416 solver.cpp:330] Iteration 98500, Testing net (#0)
I1210 13:47:01.555660 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:47:02.935789  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:47:02.989789 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6854
I1210 13:47:02.989789 10416 solver.cpp:397]     Test net output #1: loss = 1.17201 (* 1 = 1.17201 loss)
I1210 13:47:03.043802 10416 solver.cpp:218] Iteration 98500 (14.0382 iter/s, 7.1234s/100 iters), loss = 0.359593
I1210 13:47:03.043802 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 13:47:03.043802 10416 solver.cpp:237]     Train net output #1: loss = 0.359593 (* 1 = 0.359593 loss)
I1210 13:47:03.043802 10416 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1210 13:47:08.704169 10416 solver.cpp:218] Iteration 98600 (17.6696 iter/s, 5.65944s/100 iters), loss = 0.46692
I1210 13:47:08.704169 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:47:08.704169 10416 solver.cpp:237]     Train net output #1: loss = 0.46692 (* 1 = 0.46692 loss)
I1210 13:47:08.704169 10416 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1210 13:47:14.361598 10416 solver.cpp:218] Iteration 98700 (17.6754 iter/s, 5.65757s/100 iters), loss = 0.361598
I1210 13:47:14.361598 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:47:14.361598 10416 solver.cpp:237]     Train net output #1: loss = 0.361598 (* 1 = 0.361598 loss)
I1210 13:47:14.361598 10416 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1210 13:47:20.025041 10416 solver.cpp:218] Iteration 98800 (17.6605 iter/s, 5.66234s/100 iters), loss = 0.502009
I1210 13:47:20.025041 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 13:47:20.025041 10416 solver.cpp:237]     Train net output #1: loss = 0.502009 (* 1 = 0.502009 loss)
I1210 13:47:20.025041 10416 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1210 13:47:25.688494 10416 solver.cpp:218] Iteration 98900 (17.6578 iter/s, 5.66322s/100 iters), loss = 0.410889
I1210 13:47:25.688494 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:47:25.688494 10416 solver.cpp:237]     Train net output #1: loss = 0.410889 (* 1 = 0.410889 loss)
I1210 13:47:25.688494 10416 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1210 13:47:31.069926  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:47:31.292937 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99000.caffemodel
I1210 13:47:31.312443 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99000.solverstate
I1210 13:47:31.317441 10416 solver.cpp:330] Iteration 99000, Testing net (#0)
I1210 13:47:31.317441 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:47:32.697269  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:47:32.752275 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6847
I1210 13:47:32.752275 10416 solver.cpp:397]     Test net output #1: loss = 1.17821 (* 1 = 1.17821 loss)
I1210 13:47:32.805275 10416 solver.cpp:218] Iteration 99000 (14.0519 iter/s, 7.11647s/100 iters), loss = 0.402333
I1210 13:47:32.805275 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 13:47:32.805275 10416 solver.cpp:237]     Train net output #1: loss = 0.402333 (* 1 = 0.402333 loss)
I1210 13:47:32.805275 10416 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1210 13:47:38.485420 10416 solver.cpp:218] Iteration 99100 (17.6073 iter/s, 5.67948s/100 iters), loss = 0.511971
I1210 13:47:38.485420 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 13:47:38.485420 10416 solver.cpp:237]     Train net output #1: loss = 0.511971 (* 1 = 0.511971 loss)
I1210 13:47:38.485420 10416 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1210 13:47:44.159258 10416 solver.cpp:218] Iteration 99200 (17.6256 iter/s, 5.67356s/100 iters), loss = 0.329513
I1210 13:47:44.159258 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:47:44.159258 10416 solver.cpp:237]     Train net output #1: loss = 0.329513 (* 1 = 0.329513 loss)
I1210 13:47:44.159258 10416 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1210 13:47:49.821425 10416 solver.cpp:218] Iteration 99300 (17.6631 iter/s, 5.66153s/100 iters), loss = 0.484258
I1210 13:47:49.821425 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:47:49.821425 10416 solver.cpp:237]     Train net output #1: loss = 0.484258 (* 1 = 0.484258 loss)
I1210 13:47:49.821425 10416 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1210 13:47:55.485136 10416 solver.cpp:218] Iteration 99400 (17.6582 iter/s, 5.66311s/100 iters), loss = 0.481438
I1210 13:47:55.485136 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:47:55.485136 10416 solver.cpp:237]     Train net output #1: loss = 0.481438 (* 1 = 0.481438 loss)
I1210 13:47:55.485136 10416 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1210 13:48:00.893452  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:48:01.118685 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99500.caffemodel
I1210 13:48:01.136234 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99500.solverstate
I1210 13:48:01.141235 10416 solver.cpp:330] Iteration 99500, Testing net (#0)
I1210 13:48:01.141235 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:48:02.521178  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:48:02.574781 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6868
I1210 13:48:02.574781 10416 solver.cpp:397]     Test net output #1: loss = 1.17933 (* 1 = 1.17933 loss)
I1210 13:48:02.630796 10416 solver.cpp:218] Iteration 99500 (13.9957 iter/s, 7.14504s/100 iters), loss = 0.437832
I1210 13:48:02.630796 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:48:02.630796 10416 solver.cpp:237]     Train net output #1: loss = 0.437832 (* 1 = 0.437832 loss)
I1210 13:48:02.630796 10416 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1210 13:48:08.301817 10416 solver.cpp:218] Iteration 99600 (17.6349 iter/s, 5.67056s/100 iters), loss = 0.445393
I1210 13:48:08.301817 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:48:08.301817 10416 solver.cpp:237]     Train net output #1: loss = 0.445393 (* 1 = 0.445393 loss)
I1210 13:48:08.301817 10416 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1210 13:48:13.983973 10416 solver.cpp:218] Iteration 99700 (17.5983 iter/s, 5.68236s/100 iters), loss = 0.263173
I1210 13:48:13.983973 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 13:48:13.983973 10416 solver.cpp:237]     Train net output #1: loss = 0.263173 (* 1 = 0.263173 loss)
I1210 13:48:13.983973 10416 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1210 13:48:19.667879 10416 solver.cpp:218] Iteration 99800 (17.5957 iter/s, 5.6832s/100 iters), loss = 0.466307
I1210 13:48:19.667879 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:48:19.667879 10416 solver.cpp:237]     Train net output #1: loss = 0.466307 (* 1 = 0.466307 loss)
I1210 13:48:19.667879 10416 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1210 13:48:25.342021 10416 solver.cpp:218] Iteration 99900 (17.6252 iter/s, 5.67368s/100 iters), loss = 0.513735
I1210 13:48:25.342521 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:48:25.342521 10416 solver.cpp:237]     Train net output #1: loss = 0.513735 (* 1 = 0.513735 loss)
I1210 13:48:25.342521 10416 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1210 13:48:30.734505  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:48:30.957547 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100000.caffemodel
I1210 13:48:30.977550 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100000.solverstate
I1210 13:48:30.982547 10416 solver.cpp:330] Iteration 100000, Testing net (#0)
I1210 13:48:30.982547 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:48:32.365072  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:48:32.418057 10416 solver.cpp:397]     Test net output #0: accuracy = 0.685
I1210 13:48:32.418057 10416 solver.cpp:397]     Test net output #1: loss = 1.17773 (* 1 = 1.17773 loss)
I1210 13:48:32.472101 10416 solver.cpp:218] Iteration 100000 (14.0262 iter/s, 7.12953s/100 iters), loss = 0.416596
I1210 13:48:32.472101 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:48:32.472101 10416 solver.cpp:237]     Train net output #1: loss = 0.416596 (* 1 = 0.416596 loss)
I1210 13:48:32.472101 10416 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1210 13:48:38.160578 10416 solver.cpp:218] Iteration 100100 (17.5795 iter/s, 5.68845s/100 iters), loss = 0.421117
I1210 13:48:38.160578 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:48:38.160578 10416 solver.cpp:237]     Train net output #1: loss = 0.421117 (* 1 = 0.421117 loss)
I1210 13:48:38.160578 10416 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1210 13:48:43.837990 10416 solver.cpp:218] Iteration 100200 (17.616 iter/s, 5.67667s/100 iters), loss = 0.342001
I1210 13:48:43.838490 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:48:43.838490 10416 solver.cpp:237]     Train net output #1: loss = 0.342001 (* 1 = 0.342001 loss)
I1210 13:48:43.838490 10416 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1210 13:48:49.509546 10416 solver.cpp:218] Iteration 100300 (17.6323 iter/s, 5.6714s/100 iters), loss = 0.509035
I1210 13:48:49.509546 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:48:49.509546 10416 solver.cpp:237]     Train net output #1: loss = 0.509035 (* 1 = 0.509035 loss)
I1210 13:48:49.509546 10416 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1210 13:48:55.182085 10416 solver.cpp:218] Iteration 100400 (17.6296 iter/s, 5.67227s/100 iters), loss = 0.475715
I1210 13:48:55.183085 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:48:55.183085 10416 solver.cpp:237]     Train net output #1: loss = 0.475715 (* 1 = 0.475715 loss)
I1210 13:48:55.183085 10416 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1210 13:49:00.576203  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:49:00.801242 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100500.caffemodel
I1210 13:49:00.821231 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100500.solverstate
I1210 13:49:00.826232 10416 solver.cpp:330] Iteration 100500, Testing net (#0)
I1210 13:49:00.826232 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:49:02.209018  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:49:02.262010 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6835
I1210 13:49:02.262010 10416 solver.cpp:397]     Test net output #1: loss = 1.18932 (* 1 = 1.18932 loss)
I1210 13:49:02.315011 10416 solver.cpp:218] Iteration 100500 (14.0212 iter/s, 7.13207s/100 iters), loss = 0.399162
I1210 13:49:02.315011 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:49:02.315011 10416 solver.cpp:237]     Train net output #1: loss = 0.399162 (* 1 = 0.399162 loss)
I1210 13:49:02.315011 10416 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1210 13:49:07.997802 10416 solver.cpp:218] Iteration 100600 (17.599 iter/s, 5.68215s/100 iters), loss = 0.480234
I1210 13:49:07.997802 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:49:07.997802 10416 solver.cpp:237]     Train net output #1: loss = 0.480234 (* 1 = 0.480234 loss)
I1210 13:49:07.997802 10416 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1210 13:49:13.688028 10416 solver.cpp:218] Iteration 100700 (17.5757 iter/s, 5.68967s/100 iters), loss = 0.269882
I1210 13:49:13.688028 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 13:49:13.688028 10416 solver.cpp:237]     Train net output #1: loss = 0.269882 (* 1 = 0.269882 loss)
I1210 13:49:13.688028 10416 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1210 13:49:19.375511 10416 solver.cpp:218] Iteration 100800 (17.5837 iter/s, 5.68707s/100 iters), loss = 0.515456
I1210 13:49:19.375511 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:49:19.375511 10416 solver.cpp:237]     Train net output #1: loss = 0.515456 (* 1 = 0.515456 loss)
I1210 13:49:19.375511 10416 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1210 13:49:25.072033 10416 solver.cpp:218] Iteration 100900 (17.5562 iter/s, 5.696s/100 iters), loss = 0.443944
I1210 13:49:25.072033 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:49:25.072033 10416 solver.cpp:237]     Train net output #1: loss = 0.443944 (* 1 = 0.443944 loss)
I1210 13:49:25.072033 10416 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1210 13:49:30.485425  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:49:30.709439 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101000.caffemodel
I1210 13:49:30.729439 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101000.solverstate
I1210 13:49:30.734441 10416 solver.cpp:330] Iteration 101000, Testing net (#0)
I1210 13:49:30.734441 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:49:32.119563  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:49:32.173568 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6822
I1210 13:49:32.173568 10416 solver.cpp:397]     Test net output #1: loss = 1.18785 (* 1 = 1.18785 loss)
I1210 13:49:32.226567 10416 solver.cpp:218] Iteration 101000 (13.9778 iter/s, 7.15421s/100 iters), loss = 0.389798
I1210 13:49:32.226567 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 13:49:32.226567 10416 solver.cpp:237]     Train net output #1: loss = 0.389798 (* 1 = 0.389798 loss)
I1210 13:49:32.226567 10416 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1210 13:49:37.895020 10416 solver.cpp:218] Iteration 101100 (17.6438 iter/s, 5.66771s/100 iters), loss = 0.566794
I1210 13:49:37.895020 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 13:49:37.895020 10416 solver.cpp:237]     Train net output #1: loss = 0.566794 (* 1 = 0.566794 loss)
I1210 13:49:37.895020 10416 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1210 13:49:43.561955 10416 solver.cpp:218] Iteration 101200 (17.6476 iter/s, 5.6665s/100 iters), loss = 0.30431
I1210 13:49:43.561955 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 13:49:43.561955 10416 solver.cpp:237]     Train net output #1: loss = 0.30431 (* 1 = 0.30431 loss)
I1210 13:49:43.561955 10416 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1210 13:49:49.233906 10416 solver.cpp:218] Iteration 101300 (17.6313 iter/s, 5.67174s/100 iters), loss = 0.39717
I1210 13:49:49.233906 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:49:49.233906 10416 solver.cpp:237]     Train net output #1: loss = 0.39717 (* 1 = 0.39717 loss)
I1210 13:49:49.233906 10416 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1210 13:49:54.885339 10416 solver.cpp:218] Iteration 101400 (17.6951 iter/s, 5.65127s/100 iters), loss = 0.475016
I1210 13:49:54.885339 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:49:54.885339 10416 solver.cpp:237]     Train net output #1: loss = 0.475016 (* 1 = 0.475016 loss)
I1210 13:49:54.885339 10416 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1210 13:50:00.274149  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:50:00.500768 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101500.caffemodel
I1210 13:50:00.519767 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101500.solverstate
I1210 13:50:00.523767 10416 solver.cpp:330] Iteration 101500, Testing net (#0)
I1210 13:50:00.523767 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:50:01.927942  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:50:01.967947 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6821
I1210 13:50:01.967947 10416 solver.cpp:397]     Test net output #1: loss = 1.19499 (* 1 = 1.19499 loss)
I1210 13:50:02.022959 10416 solver.cpp:218] Iteration 101500 (14.0114 iter/s, 7.13705s/100 iters), loss = 0.377645
I1210 13:50:02.022959 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:50:02.022959 10416 solver.cpp:237]     Train net output #1: loss = 0.377645 (* 1 = 0.377645 loss)
I1210 13:50:02.022959 10416 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1210 13:50:07.703400 10416 solver.cpp:218] Iteration 101600 (17.6066 iter/s, 5.67968s/100 iters), loss = 0.411184
I1210 13:50:07.703400 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:50:07.703400 10416 solver.cpp:237]     Train net output #1: loss = 0.411184 (* 1 = 0.411184 loss)
I1210 13:50:07.703400 10416 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1210 13:50:13.382892 10416 solver.cpp:218] Iteration 101700 (17.6077 iter/s, 5.67933s/100 iters), loss = 0.305241
I1210 13:50:13.382892 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:50:13.382892 10416 solver.cpp:237]     Train net output #1: loss = 0.305241 (* 1 = 0.305241 loss)
I1210 13:50:13.382892 10416 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1210 13:50:19.072345 10416 solver.cpp:218] Iteration 101800 (17.5774 iter/s, 5.68911s/100 iters), loss = 0.387793
I1210 13:50:19.072345 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:50:19.072345 10416 solver.cpp:237]     Train net output #1: loss = 0.387793 (* 1 = 0.387793 loss)
I1210 13:50:19.072345 10416 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1210 13:50:24.755803 10416 solver.cpp:218] Iteration 101900 (17.5974 iter/s, 5.68264s/100 iters), loss = 0.484099
I1210 13:50:24.756306 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:50:24.756306 10416 solver.cpp:237]     Train net output #1: loss = 0.484099 (* 1 = 0.484099 loss)
I1210 13:50:24.756306 10416 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1210 13:50:30.169733  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:50:30.392258 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102000.caffemodel
I1210 13:50:30.406258 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102000.solverstate
I1210 13:50:30.411258 10416 solver.cpp:330] Iteration 102000, Testing net (#0)
I1210 13:50:30.411258 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:50:31.794379  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:50:31.849378 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6813
I1210 13:50:31.849378 10416 solver.cpp:397]     Test net output #1: loss = 1.19608 (* 1 = 1.19608 loss)
I1210 13:50:31.903389 10416 solver.cpp:218] Iteration 102000 (13.9915 iter/s, 7.1472s/100 iters), loss = 0.379783
I1210 13:50:31.903389 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:50:31.903389 10416 solver.cpp:237]     Train net output #1: loss = 0.379783 (* 1 = 0.379783 loss)
I1210 13:50:31.903389 10416 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1210 13:50:37.597169 10416 solver.cpp:218] Iteration 102100 (17.5648 iter/s, 5.69319s/100 iters), loss = 0.436365
I1210 13:50:37.597169 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:50:37.597169 10416 solver.cpp:237]     Train net output #1: loss = 0.436365 (* 1 = 0.436365 loss)
I1210 13:50:37.597169 10416 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1210 13:50:43.278625 10416 solver.cpp:218] Iteration 102200 (17.6015 iter/s, 5.68132s/100 iters), loss = 0.337955
I1210 13:50:43.278625 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:50:43.278625 10416 solver.cpp:237]     Train net output #1: loss = 0.337955 (* 1 = 0.337955 loss)
I1210 13:50:43.278625 10416 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1210 13:50:48.970585 10416 solver.cpp:218] Iteration 102300 (17.572 iter/s, 5.69086s/100 iters), loss = 0.447749
I1210 13:50:48.970585 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:50:48.970585 10416 solver.cpp:237]     Train net output #1: loss = 0.447749 (* 1 = 0.447749 loss)
I1210 13:50:48.970585 10416 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1210 13:50:54.652593 10416 solver.cpp:218] Iteration 102400 (17.5997 iter/s, 5.6819s/100 iters), loss = 0.418112
I1210 13:50:54.652593 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:50:54.652593 10416 solver.cpp:237]     Train net output #1: loss = 0.418112 (* 1 = 0.418112 loss)
I1210 13:50:54.652593 10416 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1210 13:51:00.065019  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:51:00.289031 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102500.caffemodel
I1210 13:51:00.309031 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102500.solverstate
I1210 13:51:00.314033 10416 solver.cpp:330] Iteration 102500, Testing net (#0)
I1210 13:51:00.314033 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:51:01.699180  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:51:01.753180 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6835
I1210 13:51:01.753180 10416 solver.cpp:397]     Test net output #1: loss = 1.19659 (* 1 = 1.19659 loss)
I1210 13:51:01.806185 10416 solver.cpp:218] Iteration 102500 (13.9793 iter/s, 7.15342s/100 iters), loss = 0.430869
I1210 13:51:01.806185 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:51:01.806185 10416 solver.cpp:237]     Train net output #1: loss = 0.430869 (* 1 = 0.430869 loss)
I1210 13:51:01.806185 10416 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1210 13:51:07.485615 10416 solver.cpp:218] Iteration 102600 (17.6091 iter/s, 5.67887s/100 iters), loss = 0.396987
I1210 13:51:07.485615 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:51:07.485615 10416 solver.cpp:237]     Train net output #1: loss = 0.396987 (* 1 = 0.396987 loss)
I1210 13:51:07.485615 10416 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1210 13:51:13.162021 10416 solver.cpp:218] Iteration 102700 (17.6201 iter/s, 5.67534s/100 iters), loss = 0.282219
I1210 13:51:13.162021 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 13:51:13.162021 10416 solver.cpp:237]     Train net output #1: loss = 0.282219 (* 1 = 0.282219 loss)
I1210 13:51:13.162021 10416 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1210 13:51:18.831403 10416 solver.cpp:218] Iteration 102800 (17.637 iter/s, 5.6699s/100 iters), loss = 0.408235
I1210 13:51:18.832404 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:51:18.832404 10416 solver.cpp:237]     Train net output #1: loss = 0.408235 (* 1 = 0.408235 loss)
I1210 13:51:18.832404 10416 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1210 13:51:24.507812 10416 solver.cpp:218] Iteration 102900 (17.6183 iter/s, 5.67591s/100 iters), loss = 0.462078
I1210 13:51:24.507812 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:51:24.507812 10416 solver.cpp:237]     Train net output #1: loss = 0.462078 (* 1 = 0.462078 loss)
I1210 13:51:24.507812 10416 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1210 13:51:29.904194  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:51:30.129209 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103000.caffemodel
I1210 13:51:30.143208 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103000.solverstate
I1210 13:51:30.148210 10416 solver.cpp:330] Iteration 103000, Testing net (#0)
I1210 13:51:30.148210 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:51:31.531301  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:51:31.586308 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6819
I1210 13:51:31.586308 10416 solver.cpp:397]     Test net output #1: loss = 1.2094 (* 1 = 1.2094 loss)
I1210 13:51:31.639307 10416 solver.cpp:218] Iteration 103000 (14.0237 iter/s, 7.13079s/100 iters), loss = 0.414153
I1210 13:51:31.639307 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:51:31.639307 10416 solver.cpp:237]     Train net output #1: loss = 0.414153 (* 1 = 0.414153 loss)
I1210 13:51:31.639307 10416 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1210 13:51:37.299685 10416 solver.cpp:218] Iteration 103100 (17.67 iter/s, 5.65931s/100 iters), loss = 0.412158
I1210 13:51:37.299685 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:51:37.299685 10416 solver.cpp:237]     Train net output #1: loss = 0.412158 (* 1 = 0.412158 loss)
I1210 13:51:37.299685 10416 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1210 13:51:42.958109 10416 solver.cpp:218] Iteration 103200 (17.6726 iter/s, 5.65848s/100 iters), loss = 0.278504
I1210 13:51:42.958109 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 13:51:42.958109 10416 solver.cpp:237]     Train net output #1: loss = 0.278504 (* 1 = 0.278504 loss)
I1210 13:51:42.958109 10416 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1210 13:51:48.628564 10416 solver.cpp:218] Iteration 103300 (17.6377 iter/s, 5.66968s/100 iters), loss = 0.445502
I1210 13:51:48.628564 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:51:48.628564 10416 solver.cpp:237]     Train net output #1: loss = 0.445502 (* 1 = 0.445502 loss)
I1210 13:51:48.628564 10416 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1210 13:51:54.341092 10416 solver.cpp:218] Iteration 103400 (17.5074 iter/s, 5.71186s/100 iters), loss = 0.465231
I1210 13:51:54.341092 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:51:54.341092 10416 solver.cpp:237]     Train net output #1: loss = 0.465231 (* 1 = 0.465231 loss)
I1210 13:51:54.341092 10416 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1210 13:51:59.765539  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:51:59.993561 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103500.caffemodel
I1210 13:52:00.010560 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103500.solverstate
I1210 13:52:00.014559 10416 solver.cpp:330] Iteration 103500, Testing net (#0)
I1210 13:52:00.014559 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:52:01.424854  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:52:01.479856 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6807
I1210 13:52:01.479856 10416 solver.cpp:397]     Test net output #1: loss = 1.21107 (* 1 = 1.21107 loss)
I1210 13:52:01.534863 10416 solver.cpp:218] Iteration 103500 (13.9005 iter/s, 7.19399s/100 iters), loss = 0.357108
I1210 13:52:01.534863 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:52:01.534863 10416 solver.cpp:237]     Train net output #1: loss = 0.357108 (* 1 = 0.357108 loss)
I1210 13:52:01.534863 10416 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1210 13:52:07.258373 10416 solver.cpp:218] Iteration 103600 (17.4731 iter/s, 5.72307s/100 iters), loss = 0.433176
I1210 13:52:07.258373 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:52:07.259371 10416 solver.cpp:237]     Train net output #1: loss = 0.433176 (* 1 = 0.433176 loss)
I1210 13:52:07.259371 10416 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1210 13:52:12.983860 10416 solver.cpp:218] Iteration 103700 (17.4699 iter/s, 5.72413s/100 iters), loss = 0.306091
I1210 13:52:12.983860 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 13:52:12.983860 10416 solver.cpp:237]     Train net output #1: loss = 0.306091 (* 1 = 0.306091 loss)
I1210 13:52:12.983860 10416 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1210 13:52:18.687415 10416 solver.cpp:218] Iteration 103800 (17.5324 iter/s, 5.70374s/100 iters), loss = 0.400966
I1210 13:52:18.687415 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:52:18.687415 10416 solver.cpp:237]     Train net output #1: loss = 0.400966 (* 1 = 0.400966 loss)
I1210 13:52:18.687415 10416 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1210 13:52:24.409428 10416 solver.cpp:218] Iteration 103900 (17.479 iter/s, 5.72114s/100 iters), loss = 0.467952
I1210 13:52:24.409930 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 13:52:24.409930 10416 solver.cpp:237]     Train net output #1: loss = 0.467952 (* 1 = 0.467952 loss)
I1210 13:52:24.409930 10416 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1210 13:52:29.836395  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:52:30.061414 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104000.caffemodel
I1210 13:52:30.081416 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104000.solverstate
I1210 13:52:30.086416 10416 solver.cpp:330] Iteration 104000, Testing net (#0)
I1210 13:52:30.086416 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:52:31.468536  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:52:31.523542 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6785
I1210 13:52:31.523542 10416 solver.cpp:397]     Test net output #1: loss = 1.21472 (* 1 = 1.21472 loss)
I1210 13:52:31.577582 10416 solver.cpp:218] Iteration 104000 (13.9524 iter/s, 7.16722s/100 iters), loss = 0.318987
I1210 13:52:31.577582 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:52:31.577582 10416 solver.cpp:237]     Train net output #1: loss = 0.318987 (* 1 = 0.318987 loss)
I1210 13:52:31.577582 10416 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1210 13:52:37.307090 10416 solver.cpp:218] Iteration 104100 (17.455 iter/s, 5.72903s/100 iters), loss = 0.397793
I1210 13:52:37.307090 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:52:37.307090 10416 solver.cpp:237]     Train net output #1: loss = 0.397793 (* 1 = 0.397793 loss)
I1210 13:52:37.307090 10416 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1210 13:52:43.005893 10416 solver.cpp:218] Iteration 104200 (17.5472 iter/s, 5.6989s/100 iters), loss = 0.258754
I1210 13:52:43.005893 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 13:52:43.005893 10416 solver.cpp:237]     Train net output #1: loss = 0.258754 (* 1 = 0.258754 loss)
I1210 13:52:43.005893 10416 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1210 13:52:48.674307 10416 solver.cpp:218] Iteration 104300 (17.6424 iter/s, 5.66816s/100 iters), loss = 0.416308
I1210 13:52:48.674307 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:52:48.674307 10416 solver.cpp:237]     Train net output #1: loss = 0.416308 (* 1 = 0.416308 loss)
I1210 13:52:48.674307 10416 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1210 13:52:54.359827 10416 solver.cpp:218] Iteration 104400 (17.591 iter/s, 5.68474s/100 iters), loss = 0.396667
I1210 13:52:54.359827 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:52:54.359827 10416 solver.cpp:237]     Train net output #1: loss = 0.396667 (* 1 = 0.396667 loss)
I1210 13:52:54.359827 10416 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1210 13:52:59.826725  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:53:00.047236 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104500.caffemodel
I1210 13:53:00.063236 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104500.solverstate
I1210 13:53:00.068236 10416 solver.cpp:330] Iteration 104500, Testing net (#0)
I1210 13:53:00.068236 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:53:01.458345  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:53:01.511345 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6795
I1210 13:53:01.511345 10416 solver.cpp:397]     Test net output #1: loss = 1.21064 (* 1 = 1.21064 loss)
I1210 13:53:01.565351 10416 solver.cpp:218] Iteration 104500 (13.8798 iter/s, 7.20471s/100 iters), loss = 0.416861
I1210 13:53:01.565351 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:53:01.565351 10416 solver.cpp:237]     Train net output #1: loss = 0.416861 (* 1 = 0.416861 loss)
I1210 13:53:01.565351 10416 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1210 13:53:07.278228 10416 solver.cpp:218] Iteration 104600 (17.5048 iter/s, 5.71273s/100 iters), loss = 0.413359
I1210 13:53:07.278228 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:53:07.278228 10416 solver.cpp:237]     Train net output #1: loss = 0.413359 (* 1 = 0.413359 loss)
I1210 13:53:07.278228 10416 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1210 13:53:12.963695 10416 solver.cpp:218] Iteration 104700 (17.5904 iter/s, 5.68491s/100 iters), loss = 0.251954
I1210 13:53:12.963695 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 13:53:12.963695 10416 solver.cpp:237]     Train net output #1: loss = 0.251954 (* 1 = 0.251954 loss)
I1210 13:53:12.963695 10416 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1210 13:53:18.647249 10416 solver.cpp:218] Iteration 104800 (17.5952 iter/s, 5.68336s/100 iters), loss = 0.322186
I1210 13:53:18.647249 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 13:53:18.647249 10416 solver.cpp:237]     Train net output #1: loss = 0.322186 (* 1 = 0.322186 loss)
I1210 13:53:18.647249 10416 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1210 13:53:24.331044 10416 solver.cpp:218] Iteration 104900 (17.5965 iter/s, 5.68294s/100 iters), loss = 0.415965
I1210 13:53:24.331044 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 13:53:24.331044 10416 solver.cpp:237]     Train net output #1: loss = 0.415965 (* 1 = 0.415965 loss)
I1210 13:53:24.331044 10416 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1210 13:53:29.730445  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:53:29.956459 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105000.caffemodel
I1210 13:53:29.975458 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105000.solverstate
I1210 13:53:29.980459 10416 solver.cpp:330] Iteration 105000, Testing net (#0)
I1210 13:53:29.980459 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:53:31.368607  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:53:31.421604 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6815
I1210 13:53:31.421604 10416 solver.cpp:397]     Test net output #1: loss = 1.20748 (* 1 = 1.20748 loss)
I1210 13:53:31.475617 10416 solver.cpp:218] Iteration 105000 (13.9978 iter/s, 7.14396s/100 iters), loss = 0.363464
I1210 13:53:31.475617 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:53:31.475617 10416 solver.cpp:237]     Train net output #1: loss = 0.363464 (* 1 = 0.363464 loss)
I1210 13:53:31.475617 10416 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1210 13:53:37.143075 10416 solver.cpp:218] Iteration 105100 (17.6466 iter/s, 5.66682s/100 iters), loss = 0.388165
I1210 13:53:37.143075 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:53:37.143075 10416 solver.cpp:237]     Train net output #1: loss = 0.388165 (* 1 = 0.388165 loss)
I1210 13:53:37.143075 10416 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1210 13:53:42.861625 10416 solver.cpp:218] Iteration 105200 (17.4876 iter/s, 5.71834s/100 iters), loss = 0.220883
I1210 13:53:42.861625 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 13:53:42.861625 10416 solver.cpp:237]     Train net output #1: loss = 0.220883 (* 1 = 0.220883 loss)
I1210 13:53:42.861625 10416 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1210 13:53:48.619894 10416 solver.cpp:218] Iteration 105300 (17.369 iter/s, 5.7574s/100 iters), loss = 0.507502
I1210 13:53:48.619894 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:53:48.619894 10416 solver.cpp:237]     Train net output #1: loss = 0.507502 (* 1 = 0.507502 loss)
I1210 13:53:48.619894 10416 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1210 13:53:54.365783 10416 solver.cpp:218] Iteration 105400 (17.4039 iter/s, 5.74584s/100 iters), loss = 0.445046
I1210 13:53:54.365783 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:53:54.365783 10416 solver.cpp:237]     Train net output #1: loss = 0.445046 (* 1 = 0.445046 loss)
I1210 13:53:54.365783 10416 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1210 13:53:59.803222  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:54:00.028241 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105500.caffemodel
I1210 13:54:00.045243 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105500.solverstate
I1210 13:54:00.050242 10416 solver.cpp:330] Iteration 105500, Testing net (#0)
I1210 13:54:00.050242 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:54:01.439359  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:54:01.493190 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6784
I1210 13:54:01.494191 10416 solver.cpp:397]     Test net output #1: loss = 1.22658 (* 1 = 1.22658 loss)
I1210 13:54:01.547190 10416 solver.cpp:218] Iteration 105500 (13.927 iter/s, 7.18031s/100 iters), loss = 0.327756
I1210 13:54:01.547190 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 13:54:01.547190 10416 solver.cpp:237]     Train net output #1: loss = 0.327756 (* 1 = 0.327756 loss)
I1210 13:54:01.547190 10416 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1210 13:54:07.261162 10416 solver.cpp:218] Iteration 105600 (17.5031 iter/s, 5.71327s/100 iters), loss = 0.390231
I1210 13:54:07.261162 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:54:07.261162 10416 solver.cpp:237]     Train net output #1: loss = 0.390231 (* 1 = 0.390231 loss)
I1210 13:54:07.261162 10416 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1210 13:54:12.973979 10416 solver.cpp:218] Iteration 105700 (17.5034 iter/s, 5.71318s/100 iters), loss = 0.272129
I1210 13:54:12.973979 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 13:54:12.973979 10416 solver.cpp:237]     Train net output #1: loss = 0.272129 (* 1 = 0.272129 loss)
I1210 13:54:12.973979 10416 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1210 13:54:18.734833 10416 solver.cpp:218] Iteration 105800 (17.3613 iter/s, 5.75994s/100 iters), loss = 0.401649
I1210 13:54:18.734833 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:54:18.734833 10416 solver.cpp:237]     Train net output #1: loss = 0.401649 (* 1 = 0.401649 loss)
I1210 13:54:18.734833 10416 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1210 13:54:24.492174 10416 solver.cpp:218] Iteration 105900 (17.3718 iter/s, 5.75647s/100 iters), loss = 0.469838
I1210 13:54:24.492174 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 13:54:24.492174 10416 solver.cpp:237]     Train net output #1: loss = 0.469838 (* 1 = 0.469838 loss)
I1210 13:54:24.492174 10416 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1210 13:54:29.923176  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:54:30.149193 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106000.caffemodel
I1210 13:54:30.163192 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106000.solverstate
I1210 13:54:30.168193 10416 solver.cpp:330] Iteration 106000, Testing net (#0)
I1210 13:54:30.168193 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:54:31.552305  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:54:31.606317 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6805
I1210 13:54:31.606317 10416 solver.cpp:397]     Test net output #1: loss = 1.20758 (* 1 = 1.20758 loss)
I1210 13:54:31.660315 10416 solver.cpp:218] Iteration 106000 (13.9514 iter/s, 7.16773s/100 iters), loss = 0.320488
I1210 13:54:31.660315 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 13:54:31.660315 10416 solver.cpp:237]     Train net output #1: loss = 0.320488 (* 1 = 0.320488 loss)
I1210 13:54:31.660315 10416 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1210 13:54:37.380897 10416 solver.cpp:218] Iteration 106100 (17.4815 iter/s, 5.72034s/100 iters), loss = 0.429582
I1210 13:54:37.381402 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:54:37.381402 10416 solver.cpp:237]     Train net output #1: loss = 0.429582 (* 1 = 0.429582 loss)
I1210 13:54:37.381402 10416 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1210 13:54:43.087441 10416 solver.cpp:218] Iteration 106200 (17.5258 iter/s, 5.70587s/100 iters), loss = 0.291568
I1210 13:54:43.087441 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:54:43.087944 10416 solver.cpp:237]     Train net output #1: loss = 0.291568 (* 1 = 0.291568 loss)
I1210 13:54:43.087944 10416 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1210 13:54:48.797994 10416 solver.cpp:218] Iteration 106300 (17.5129 iter/s, 5.71009s/100 iters), loss = 0.399795
I1210 13:54:48.797994 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:54:48.797994 10416 solver.cpp:237]     Train net output #1: loss = 0.399795 (* 1 = 0.399795 loss)
I1210 13:54:48.797994 10416 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1210 13:54:54.508527 10416 solver.cpp:218] Iteration 106400 (17.5131 iter/s, 5.71002s/100 iters), loss = 0.46339
I1210 13:54:54.508527 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:54:54.508527 10416 solver.cpp:237]     Train net output #1: loss = 0.46339 (* 1 = 0.46339 loss)
I1210 13:54:54.508527 10416 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1210 13:54:59.936949  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:55:00.161962 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106500.caffemodel
I1210 13:55:00.178961 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106500.solverstate
I1210 13:55:00.184473 10416 solver.cpp:330] Iteration 106500, Testing net (#0)
I1210 13:55:00.184969 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:55:01.573077  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:55:01.626083 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6816
I1210 13:55:01.626083 10416 solver.cpp:397]     Test net output #1: loss = 1.21677 (* 1 = 1.21677 loss)
I1210 13:55:01.680083 10416 solver.cpp:218] Iteration 106500 (13.9438 iter/s, 7.17165s/100 iters), loss = 0.323102
I1210 13:55:01.681082 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:55:01.681082 10416 solver.cpp:237]     Train net output #1: loss = 0.323102 (* 1 = 0.323102 loss)
I1210 13:55:01.681082 10416 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1210 13:55:07.387516 10416 solver.cpp:218] Iteration 106600 (17.5246 iter/s, 5.70627s/100 iters), loss = 0.361743
I1210 13:55:07.387516 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:55:07.387516 10416 solver.cpp:237]     Train net output #1: loss = 0.361743 (* 1 = 0.361743 loss)
I1210 13:55:07.387516 10416 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1210 13:55:13.113240 10416 solver.cpp:218] Iteration 106700 (17.467 iter/s, 5.72509s/100 iters), loss = 0.247093
I1210 13:55:13.113240 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 13:55:13.113240 10416 solver.cpp:237]     Train net output #1: loss = 0.247093 (* 1 = 0.247093 loss)
I1210 13:55:13.113240 10416 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1210 13:55:18.859822 10416 solver.cpp:218] Iteration 106800 (17.4024 iter/s, 5.74635s/100 iters), loss = 0.3847
I1210 13:55:18.859822 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:55:18.859822 10416 solver.cpp:237]     Train net output #1: loss = 0.3847 (* 1 = 0.3847 loss)
I1210 13:55:18.859822 10416 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1210 13:55:24.572228 10416 solver.cpp:218] Iteration 106900 (17.507 iter/s, 5.712s/100 iters), loss = 0.390974
I1210 13:55:24.572228 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:55:24.572228 10416 solver.cpp:237]     Train net output #1: loss = 0.390974 (* 1 = 0.390974 loss)
I1210 13:55:24.572228 10416 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1210 13:55:30.044589  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:55:30.270602 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107000.caffemodel
I1210 13:55:30.291607 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107000.solverstate
I1210 13:55:30.296607 10416 solver.cpp:330] Iteration 107000, Testing net (#0)
I1210 13:55:30.297106 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:55:31.695206  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:55:31.749711 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6777
I1210 13:55:31.749711 10416 solver.cpp:397]     Test net output #1: loss = 1.22616 (* 1 = 1.22616 loss)
I1210 13:55:31.803714 10416 solver.cpp:218] Iteration 107000 (13.8296 iter/s, 7.23085s/100 iters), loss = 0.260389
I1210 13:55:31.803714 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:55:31.803714 10416 solver.cpp:237]     Train net output #1: loss = 0.260389 (* 1 = 0.260389 loss)
I1210 13:55:31.803714 10416 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1210 13:55:37.519134 10416 solver.cpp:218] Iteration 107100 (17.4987 iter/s, 5.7147s/100 iters), loss = 0.38065
I1210 13:55:37.519134 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:55:37.519134 10416 solver.cpp:237]     Train net output #1: loss = 0.38065 (* 1 = 0.38065 loss)
I1210 13:55:37.519134 10416 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1210 13:55:43.212730 10416 solver.cpp:218] Iteration 107200 (17.5637 iter/s, 5.69357s/100 iters), loss = 0.274486
I1210 13:55:43.212730 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:55:43.212730 10416 solver.cpp:237]     Train net output #1: loss = 0.274486 (* 1 = 0.274486 loss)
I1210 13:55:43.212730 10416 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1210 13:55:48.900425 10416 solver.cpp:218] Iteration 107300 (17.5851 iter/s, 5.68664s/100 iters), loss = 0.385603
I1210 13:55:48.900425 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:55:48.900425 10416 solver.cpp:237]     Train net output #1: loss = 0.385603 (* 1 = 0.385603 loss)
I1210 13:55:48.900425 10416 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1210 13:55:54.590379 10416 solver.cpp:218] Iteration 107400 (17.5757 iter/s, 5.68968s/100 iters), loss = 0.341264
I1210 13:55:54.590379 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:55:54.590379 10416 solver.cpp:237]     Train net output #1: loss = 0.341264 (* 1 = 0.341264 loss)
I1210 13:55:54.590379 10416 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1210 13:56:00.007797  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:56:00.234818 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107500.caffemodel
I1210 13:56:00.251821 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107500.solverstate
I1210 13:56:00.255820 10416 solver.cpp:330] Iteration 107500, Testing net (#0)
I1210 13:56:00.256819 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:56:01.642946  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:56:01.696949 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6779
I1210 13:56:01.696949 10416 solver.cpp:397]     Test net output #1: loss = 1.22936 (* 1 = 1.22936 loss)
I1210 13:56:01.749949 10416 solver.cpp:218] Iteration 107500 (13.9686 iter/s, 7.1589s/100 iters), loss = 0.30646
I1210 13:56:01.749949 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 13:56:01.749949 10416 solver.cpp:237]     Train net output #1: loss = 0.30646 (* 1 = 0.30646 loss)
I1210 13:56:01.749949 10416 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1210 13:56:07.424392 10416 solver.cpp:218] Iteration 107600 (17.6227 iter/s, 5.67451s/100 iters), loss = 0.370149
I1210 13:56:07.425385 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:56:07.425385 10416 solver.cpp:237]     Train net output #1: loss = 0.370149 (* 1 = 0.370149 loss)
I1210 13:56:07.425385 10416 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1210 13:56:13.196887 10416 solver.cpp:218] Iteration 107700 (17.328 iter/s, 5.77102s/100 iters), loss = 0.249063
I1210 13:56:13.196887 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 13:56:13.196887 10416 solver.cpp:237]     Train net output #1: loss = 0.249063 (* 1 = 0.249063 loss)
I1210 13:56:13.196887 10416 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1210 13:56:19.178690 10416 solver.cpp:218] Iteration 107800 (16.7172 iter/s, 5.98187s/100 iters), loss = 0.377587
I1210 13:56:19.178690 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:56:19.178690 10416 solver.cpp:237]     Train net output #1: loss = 0.377587 (* 1 = 0.377587 loss)
I1210 13:56:19.178690 10416 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1210 13:56:24.940464 10416 solver.cpp:218] Iteration 107900 (17.3572 iter/s, 5.76128s/100 iters), loss = 0.367387
I1210 13:56:24.940464 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 13:56:24.940464 10416 solver.cpp:237]     Train net output #1: loss = 0.367387 (* 1 = 0.367387 loss)
I1210 13:56:24.940464 10416 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1210 13:56:30.464363  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:56:30.688372 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108000.caffemodel
I1210 13:56:30.708374 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108000.solverstate
I1210 13:56:30.714380 10416 solver.cpp:330] Iteration 108000, Testing net (#0)
I1210 13:56:30.714380 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:56:32.123498  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:56:32.178503 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6805
I1210 13:56:32.178503 10416 solver.cpp:397]     Test net output #1: loss = 1.22367 (* 1 = 1.22367 loss)
I1210 13:56:32.235514 10416 solver.cpp:218] Iteration 108000 (13.7085 iter/s, 7.29473s/100 iters), loss = 0.355683
I1210 13:56:32.235514 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:56:32.235514 10416 solver.cpp:237]     Train net output #1: loss = 0.355683 (* 1 = 0.355683 loss)
I1210 13:56:32.235514 10416 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1210 13:56:38.018604 10416 solver.cpp:218] Iteration 108100 (17.2959 iter/s, 5.7817s/100 iters), loss = 0.399753
I1210 13:56:38.018604 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 13:56:38.018604 10416 solver.cpp:237]     Train net output #1: loss = 0.399753 (* 1 = 0.399753 loss)
I1210 13:56:38.018604 10416 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1210 13:56:43.777626 10416 solver.cpp:218] Iteration 108200 (17.3641 iter/s, 5.759s/100 iters), loss = 0.317557
I1210 13:56:43.778625 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:56:43.778625 10416 solver.cpp:237]     Train net output #1: loss = 0.317557 (* 1 = 0.317557 loss)
I1210 13:56:43.778625 10416 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1210 13:56:49.598367 10416 solver.cpp:218] Iteration 108300 (17.1844 iter/s, 5.81923s/100 iters), loss = 0.329853
I1210 13:56:49.598367 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:56:49.598367 10416 solver.cpp:237]     Train net output #1: loss = 0.329853 (* 1 = 0.329853 loss)
I1210 13:56:49.598367 10416 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1210 13:56:55.291882 10416 solver.cpp:218] Iteration 108400 (17.5639 iter/s, 5.69351s/100 iters), loss = 0.338331
I1210 13:56:55.291882 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 13:56:55.291882 10416 solver.cpp:237]     Train net output #1: loss = 0.338331 (* 1 = 0.338331 loss)
I1210 13:56:55.291882 10416 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1210 13:57:00.700325  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:57:00.924839 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108500.caffemodel
I1210 13:57:00.941342 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108500.solverstate
I1210 13:57:00.947343 10416 solver.cpp:330] Iteration 108500, Testing net (#0)
I1210 13:57:00.947343 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:57:02.350450  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:57:02.405448 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6788
I1210 13:57:02.405448 10416 solver.cpp:397]     Test net output #1: loss = 1.22804 (* 1 = 1.22804 loss)
I1210 13:57:02.458456 10416 solver.cpp:218] Iteration 108500 (13.9548 iter/s, 7.16602s/100 iters), loss = 0.296011
I1210 13:57:02.458456 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 13:57:02.458456 10416 solver.cpp:237]     Train net output #1: loss = 0.296011 (* 1 = 0.296011 loss)
I1210 13:57:02.458456 10416 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1210 13:57:08.231071 10416 solver.cpp:218] Iteration 108600 (17.3258 iter/s, 5.77175s/100 iters), loss = 0.38619
I1210 13:57:08.231071 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:57:08.231071 10416 solver.cpp:237]     Train net output #1: loss = 0.38619 (* 1 = 0.38619 loss)
I1210 13:57:08.231071 10416 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1210 13:57:14.019549 10416 solver.cpp:218] Iteration 108700 (17.277 iter/s, 5.78803s/100 iters), loss = 0.231901
I1210 13:57:14.019549 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 13:57:14.020050 10416 solver.cpp:237]     Train net output #1: loss = 0.231901 (* 1 = 0.231901 loss)
I1210 13:57:14.020050 10416 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1210 13:57:19.847339 10416 solver.cpp:218] Iteration 108800 (17.1624 iter/s, 5.82668s/100 iters), loss = 0.308456
I1210 13:57:19.847339 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:57:19.847339 10416 solver.cpp:237]     Train net output #1: loss = 0.308456 (* 1 = 0.308456 loss)
I1210 13:57:19.847339 10416 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1210 13:57:25.617902 10416 solver.cpp:218] Iteration 108900 (17.3297 iter/s, 5.77044s/100 iters), loss = 0.386416
I1210 13:57:25.617902 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:57:25.617902 10416 solver.cpp:237]     Train net output #1: loss = 0.386416 (* 1 = 0.386416 loss)
I1210 13:57:25.617902 10416 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1210 13:57:31.036362  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:57:31.260385 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109000.caffemodel
I1210 13:57:31.281384 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109000.solverstate
I1210 13:57:31.286386 10416 solver.cpp:330] Iteration 109000, Testing net (#0)
I1210 13:57:31.286386 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:57:32.675518  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:57:32.730026 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6795
I1210 13:57:32.730026 10416 solver.cpp:397]     Test net output #1: loss = 1.23136 (* 1 = 1.23136 loss)
I1210 13:57:32.783529 10416 solver.cpp:218] Iteration 109000 (13.9563 iter/s, 7.1652s/100 iters), loss = 0.338816
I1210 13:57:32.783529 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:57:32.783529 10416 solver.cpp:237]     Train net output #1: loss = 0.338816 (* 1 = 0.338816 loss)
I1210 13:57:32.783529 10416 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1210 13:57:38.479009 10416 solver.cpp:218] Iteration 109100 (17.5577 iter/s, 5.6955s/100 iters), loss = 0.367629
I1210 13:57:38.480001 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:57:38.480001 10416 solver.cpp:237]     Train net output #1: loss = 0.367629 (* 1 = 0.367629 loss)
I1210 13:57:38.480001 10416 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1210 13:57:44.178571 10416 solver.cpp:218] Iteration 109200 (17.5477 iter/s, 5.69877s/100 iters), loss = 0.258037
I1210 13:57:44.178571 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 13:57:44.178571 10416 solver.cpp:237]     Train net output #1: loss = 0.258037 (* 1 = 0.258037 loss)
I1210 13:57:44.178571 10416 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1210 13:57:49.871459 10416 solver.cpp:218] Iteration 109300 (17.5682 iter/s, 5.6921s/100 iters), loss = 0.391513
I1210 13:57:49.871459 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:57:49.871459 10416 solver.cpp:237]     Train net output #1: loss = 0.391513 (* 1 = 0.391513 loss)
I1210 13:57:49.871459 10416 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1210 13:57:55.570065 10416 solver.cpp:218] Iteration 109400 (17.5494 iter/s, 5.69821s/100 iters), loss = 0.391538
I1210 13:57:55.570065 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 13:57:55.570065 10416 solver.cpp:237]     Train net output #1: loss = 0.391538 (* 1 = 0.391538 loss)
I1210 13:57:55.570065 10416 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1210 13:58:00.983721  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:58:01.207748 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109500.caffemodel
I1210 13:58:01.226253 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109500.solverstate
I1210 13:58:01.231254 10416 solver.cpp:330] Iteration 109500, Testing net (#0)
I1210 13:58:01.231254 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:58:02.618891  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:58:02.672900 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6782
I1210 13:58:02.672900 10416 solver.cpp:397]     Test net output #1: loss = 1.23038 (* 1 = 1.23038 loss)
I1210 13:58:02.726929 10416 solver.cpp:218] Iteration 109500 (13.9741 iter/s, 7.1561s/100 iters), loss = 0.403557
I1210 13:58:02.726929 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:58:02.726929 10416 solver.cpp:237]     Train net output #1: loss = 0.403557 (* 1 = 0.403557 loss)
I1210 13:58:02.726929 10416 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1210 13:58:08.415657 10416 solver.cpp:218] Iteration 109600 (17.5798 iter/s, 5.68833s/100 iters), loss = 0.294819
I1210 13:58:08.415657 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:58:08.415657 10416 solver.cpp:237]     Train net output #1: loss = 0.294819 (* 1 = 0.294819 loss)
I1210 13:58:08.415657 10416 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1210 13:58:14.120121 10416 solver.cpp:218] Iteration 109700 (17.5312 iter/s, 5.70412s/100 iters), loss = 0.209325
I1210 13:58:14.120121 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 13:58:14.120121 10416 solver.cpp:237]     Train net output #1: loss = 0.209325 (* 1 = 0.209325 loss)
I1210 13:58:14.120121 10416 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1210 13:58:19.810974 10416 solver.cpp:218] Iteration 109800 (17.5728 iter/s, 5.6906s/100 iters), loss = 0.360769
I1210 13:58:19.810974 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:58:19.810974 10416 solver.cpp:237]     Train net output #1: loss = 0.360769 (* 1 = 0.360769 loss)
I1210 13:58:19.810974 10416 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1210 13:58:25.520926 10416 solver.cpp:218] Iteration 109900 (17.5162 iter/s, 5.709s/100 iters), loss = 0.454406
I1210 13:58:25.520926 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:58:25.520926 10416 solver.cpp:237]     Train net output #1: loss = 0.454406 (* 1 = 0.454406 loss)
I1210 13:58:25.520926 10416 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1210 13:58:30.938387  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:58:31.160416 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110000.caffemodel
I1210 13:58:31.180416 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110000.solverstate
I1210 13:58:31.186416 10416 solver.cpp:330] Iteration 110000, Testing net (#0)
I1210 13:58:31.186416 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:58:32.570545  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:58:32.624548 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6755
I1210 13:58:32.624548 10416 solver.cpp:397]     Test net output #1: loss = 1.25097 (* 1 = 1.25097 loss)
I1210 13:58:32.677551 10416 solver.cpp:218] Iteration 110000 (13.973 iter/s, 7.15666s/100 iters), loss = 0.350105
I1210 13:58:32.677551 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:58:32.677551 10416 solver.cpp:237]     Train net output #1: loss = 0.350105 (* 1 = 0.350105 loss)
I1210 13:58:32.677551 10416 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1210 13:58:38.353029 10416 solver.cpp:218] Iteration 110100 (17.621 iter/s, 5.67503s/100 iters), loss = 0.367417
I1210 13:58:38.353029 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:58:38.353029 10416 solver.cpp:237]     Train net output #1: loss = 0.367417 (* 1 = 0.367417 loss)
I1210 13:58:38.353029 10416 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1210 13:58:44.037474 10416 solver.cpp:218] Iteration 110200 (17.5951 iter/s, 5.68339s/100 iters), loss = 0.342585
I1210 13:58:44.037474 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:58:44.037474 10416 solver.cpp:237]     Train net output #1: loss = 0.342585 (* 1 = 0.342585 loss)
I1210 13:58:44.037474 10416 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1210 13:58:49.714006 10416 solver.cpp:218] Iteration 110300 (17.6171 iter/s, 5.6763s/100 iters), loss = 0.381086
I1210 13:58:49.714006 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 13:58:49.714006 10416 solver.cpp:237]     Train net output #1: loss = 0.381086 (* 1 = 0.381086 loss)
I1210 13:58:49.714006 10416 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1210 13:58:55.402478 10416 solver.cpp:218] Iteration 110400 (17.5806 iter/s, 5.6881s/100 iters), loss = 0.366475
I1210 13:58:55.402478 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:58:55.402478 10416 solver.cpp:237]     Train net output #1: loss = 0.366475 (* 1 = 0.366475 loss)
I1210 13:58:55.402478 10416 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1210 13:59:00.814894  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:59:01.039415 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110500.caffemodel
I1210 13:59:01.061921 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110500.solverstate
I1210 13:59:01.066922 10416 solver.cpp:330] Iteration 110500, Testing net (#0)
I1210 13:59:01.067921 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:59:02.454008  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:59:02.506006 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6791
I1210 13:59:02.507007 10416 solver.cpp:397]     Test net output #1: loss = 1.24712 (* 1 = 1.24712 loss)
I1210 13:59:02.560014 10416 solver.cpp:218] Iteration 110500 (13.9722 iter/s, 7.15709s/100 iters), loss = 0.326142
I1210 13:59:02.560014 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:59:02.560014 10416 solver.cpp:237]     Train net output #1: loss = 0.326142 (* 1 = 0.326142 loss)
I1210 13:59:02.560014 10416 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1210 13:59:08.238457 10416 solver.cpp:218] Iteration 110600 (17.6116 iter/s, 5.67807s/100 iters), loss = 0.385188
I1210 13:59:08.238958 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 13:59:08.238958 10416 solver.cpp:237]     Train net output #1: loss = 0.385188 (* 1 = 0.385188 loss)
I1210 13:59:08.238958 10416 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1210 13:59:13.907873 10416 solver.cpp:218] Iteration 110700 (17.6403 iter/s, 5.66883s/100 iters), loss = 0.221987
I1210 13:59:13.907873 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 13:59:13.907873 10416 solver.cpp:237]     Train net output #1: loss = 0.221987 (* 1 = 0.221987 loss)
I1210 13:59:13.907873 10416 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1210 13:59:19.578398 10416 solver.cpp:218] Iteration 110800 (17.6345 iter/s, 5.67071s/100 iters), loss = 0.420384
I1210 13:59:19.578398 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 13:59:19.579399 10416 solver.cpp:237]     Train net output #1: loss = 0.420384 (* 1 = 0.420384 loss)
I1210 13:59:19.579399 10416 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1210 13:59:25.260923 10416 solver.cpp:218] Iteration 110900 (17.6011 iter/s, 5.68146s/100 iters), loss = 0.418602
I1210 13:59:25.260923 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:59:25.260923 10416 solver.cpp:237]     Train net output #1: loss = 0.418602 (* 1 = 0.418602 loss)
I1210 13:59:25.260923 10416 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1210 13:59:30.677400  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:59:30.900424 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111000.caffemodel
I1210 13:59:30.916424 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111000.solverstate
I1210 13:59:30.922423 10416 solver.cpp:330] Iteration 111000, Testing net (#0)
I1210 13:59:30.922423 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 13:59:32.306556  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 13:59:32.360560 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6759
I1210 13:59:32.360560 10416 solver.cpp:397]     Test net output #1: loss = 1.24517 (* 1 = 1.24517 loss)
I1210 13:59:32.415560 10416 solver.cpp:218] Iteration 111000 (13.978 iter/s, 7.15412s/100 iters), loss = 0.313966
I1210 13:59:32.415560 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 13:59:32.415560 10416 solver.cpp:237]     Train net output #1: loss = 0.313966 (* 1 = 0.313966 loss)
I1210 13:59:32.415560 10416 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1210 13:59:38.105993 10416 solver.cpp:218] Iteration 111100 (17.5742 iter/s, 5.69015s/100 iters), loss = 0.36567
I1210 13:59:38.105993 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 13:59:38.105993 10416 solver.cpp:237]     Train net output #1: loss = 0.36567 (* 1 = 0.36567 loss)
I1210 13:59:38.105993 10416 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1210 13:59:43.791405 10416 solver.cpp:218] Iteration 111200 (17.5913 iter/s, 5.68464s/100 iters), loss = 0.365837
I1210 13:59:43.791405 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 13:59:43.791405 10416 solver.cpp:237]     Train net output #1: loss = 0.365837 (* 1 = 0.365837 loss)
I1210 13:59:43.791405 10416 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1210 13:59:49.478871 10416 solver.cpp:218] Iteration 111300 (17.5829 iter/s, 5.68736s/100 iters), loss = 0.45081
I1210 13:59:49.478871 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 13:59:49.478871 10416 solver.cpp:237]     Train net output #1: loss = 0.45081 (* 1 = 0.45081 loss)
I1210 13:59:49.478871 10416 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1210 13:59:55.162281 10416 solver.cpp:218] Iteration 111400 (17.5956 iter/s, 5.68324s/100 iters), loss = 0.407169
I1210 13:59:55.162281 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 13:59:55.162281 10416 solver.cpp:237]     Train net output #1: loss = 0.407169 (* 1 = 0.407169 loss)
I1210 13:59:55.162281 10416 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1210 14:00:00.568745  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:00:00.792846 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111500.caffemodel
I1210 14:00:00.812846 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111500.solverstate
I1210 14:00:00.816846 10416 solver.cpp:330] Iteration 111500, Testing net (#0)
I1210 14:00:00.816846 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:00:02.212025  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:00:02.267030 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6741
I1210 14:00:02.267030 10416 solver.cpp:397]     Test net output #1: loss = 1.23894 (* 1 = 1.23894 loss)
I1210 14:00:02.321032 10416 solver.cpp:218] Iteration 111500 (13.9709 iter/s, 7.15776s/100 iters), loss = 0.310633
I1210 14:00:02.321032 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:00:02.321032 10416 solver.cpp:237]     Train net output #1: loss = 0.310633 (* 1 = 0.310633 loss)
I1210 14:00:02.321032 10416 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1210 14:00:08.000514 10416 solver.cpp:218] Iteration 111600 (17.6082 iter/s, 5.67917s/100 iters), loss = 0.392158
I1210 14:00:08.000514 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:00:08.000514 10416 solver.cpp:237]     Train net output #1: loss = 0.392158 (* 1 = 0.392158 loss)
I1210 14:00:08.000514 10416 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1210 14:00:13.680922 10416 solver.cpp:218] Iteration 111700 (17.6051 iter/s, 5.68018s/100 iters), loss = 0.250816
I1210 14:00:13.680922 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:00:13.680922 10416 solver.cpp:237]     Train net output #1: loss = 0.250816 (* 1 = 0.250816 loss)
I1210 14:00:13.680922 10416 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1210 14:00:19.359333 10416 solver.cpp:218] Iteration 111800 (17.6112 iter/s, 5.67822s/100 iters), loss = 0.327864
I1210 14:00:19.359333 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:00:19.359333 10416 solver.cpp:237]     Train net output #1: loss = 0.327864 (* 1 = 0.327864 loss)
I1210 14:00:19.359333 10416 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1210 14:00:25.046253 10416 solver.cpp:218] Iteration 111900 (17.5884 iter/s, 5.68555s/100 iters), loss = 0.487765
I1210 14:00:25.046253 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:00:25.046253 10416 solver.cpp:237]     Train net output #1: loss = 0.487765 (* 1 = 0.487765 loss)
I1210 14:00:25.046253 10416 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1210 14:00:30.451128  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:00:30.673137 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112000.caffemodel
I1210 14:00:30.692137 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112000.solverstate
I1210 14:00:30.697137 10416 solver.cpp:330] Iteration 112000, Testing net (#0)
I1210 14:00:30.697137 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:00:32.086247  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:00:32.139750 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6759
I1210 14:00:32.139750 10416 solver.cpp:397]     Test net output #1: loss = 1.24931 (* 1 = 1.24931 loss)
I1210 14:00:32.193251 10416 solver.cpp:218] Iteration 112000 (13.9917 iter/s, 7.14709s/100 iters), loss = 0.326374
I1210 14:00:32.193251 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:00:32.193251 10416 solver.cpp:237]     Train net output #1: loss = 0.326374 (* 1 = 0.326374 loss)
I1210 14:00:32.193251 10416 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1210 14:00:37.888653 10416 solver.cpp:218] Iteration 112100 (17.5594 iter/s, 5.69494s/100 iters), loss = 0.396505
I1210 14:00:37.888653 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:00:37.888653 10416 solver.cpp:237]     Train net output #1: loss = 0.396505 (* 1 = 0.396505 loss)
I1210 14:00:37.888653 10416 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1210 14:00:43.583055 10416 solver.cpp:218] Iteration 112200 (17.5631 iter/s, 5.69377s/100 iters), loss = 0.269227
I1210 14:00:43.583055 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:00:43.583055 10416 solver.cpp:237]     Train net output #1: loss = 0.269227 (* 1 = 0.269227 loss)
I1210 14:00:43.583055 10416 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1210 14:00:49.292672 10416 solver.cpp:218] Iteration 112300 (17.515 iter/s, 5.70941s/100 iters), loss = 0.391733
I1210 14:00:49.292672 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:00:49.292672 10416 solver.cpp:237]     Train net output #1: loss = 0.391733 (* 1 = 0.391733 loss)
I1210 14:00:49.292672 10416 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1210 14:00:55.060209 10416 solver.cpp:218] Iteration 112400 (17.3387 iter/s, 5.76746s/100 iters), loss = 0.40385
I1210 14:00:55.061209 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:00:55.061209 10416 solver.cpp:237]     Train net output #1: loss = 0.40385 (* 1 = 0.40385 loss)
I1210 14:00:55.061209 10416 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1210 14:01:00.589706  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:01:00.818719 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112500.caffemodel
I1210 14:01:00.835225 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112500.solverstate
I1210 14:01:00.840226 10416 solver.cpp:330] Iteration 112500, Testing net (#0)
I1210 14:01:00.840226 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:01:02.263857  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:01:02.317854 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6763
I1210 14:01:02.317854 10416 solver.cpp:397]     Test net output #1: loss = 1.24959 (* 1 = 1.24959 loss)
I1210 14:01:02.372864 10416 solver.cpp:218] Iteration 112500 (13.6776 iter/s, 7.31122s/100 iters), loss = 0.353014
I1210 14:01:02.372864 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:01:02.372864 10416 solver.cpp:237]     Train net output #1: loss = 0.353014 (* 1 = 0.353014 loss)
I1210 14:01:02.372864 10416 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1210 14:01:08.181365 10416 solver.cpp:218] Iteration 112600 (17.2182 iter/s, 5.80779s/100 iters), loss = 0.367766
I1210 14:01:08.181365 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:01:08.181365 10416 solver.cpp:237]     Train net output #1: loss = 0.367766 (* 1 = 0.367766 loss)
I1210 14:01:08.181365 10416 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1210 14:01:13.996879 10416 solver.cpp:218] Iteration 112700 (17.1969 iter/s, 5.81499s/100 iters), loss = 0.316175
I1210 14:01:13.996879 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:01:13.996879 10416 solver.cpp:237]     Train net output #1: loss = 0.316175 (* 1 = 0.316175 loss)
I1210 14:01:13.996879 10416 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1210 14:01:19.761307 10416 solver.cpp:218] Iteration 112800 (17.3484 iter/s, 5.76421s/100 iters), loss = 0.302782
I1210 14:01:19.761307 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:01:19.761307 10416 solver.cpp:237]     Train net output #1: loss = 0.302782 (* 1 = 0.302782 loss)
I1210 14:01:19.761307 10416 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1210 14:01:25.433668 10416 solver.cpp:218] Iteration 112900 (17.6302 iter/s, 5.6721s/100 iters), loss = 0.394791
I1210 14:01:25.433668 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:01:25.433668 10416 solver.cpp:237]     Train net output #1: loss = 0.394791 (* 1 = 0.394791 loss)
I1210 14:01:25.433668 10416 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1210 14:01:30.837561  7104 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:01:31.069087 10416 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_113000.caffemodel
I1210 14:01:31.085088 10416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_113000.solverstate
I1210 14:01:31.091087 10416 solver.cpp:330] Iteration 113000, Testing net (#0)
I1210 14:01:31.091087 10416 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:01:32.484427  7476 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:01:32.539429 10416 solver.cpp:397]     Test net output #0: accuracy = 0.6788
I1210 14:01:32.539429 10416 solver.cpp:397]     Test net output #1: loss = 1.24637 (* 1 = 1.24637 loss)
I1210 14:01:32.593432 10416 solver.cpp:218] Iteration 113000 (13.9674 iter/s, 7.15955s/100 iters), loss = 0.294109
I1210 14:01:32.593432 10416 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:01:32.593432 10416 solver.cpp:237]     Train net output #1: loss = 0.294109 (* 1 = 0.294109 loss)
I1210 14:01:32.593432 