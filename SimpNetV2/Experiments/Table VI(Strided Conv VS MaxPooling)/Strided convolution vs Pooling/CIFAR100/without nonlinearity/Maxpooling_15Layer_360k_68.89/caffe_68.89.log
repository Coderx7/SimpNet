I1210 15:23:36.766216 15772 caffe.cpp:219] Using GPUs 0
I1210 15:23:36.944241 15772 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1210 15:23:37.252373 15772 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 15:23:37.269378 15772 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1210 15:23:37.269378 15772 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 15:23:37.270380 15772 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 15:23:37.270380 15772 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1210 15:23:37.270380 15772 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1210 15:23:37.271379 15772 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_v2_360k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "newconv_added1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "newconv_added1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "newconv_added1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "added_new_conv2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "added_new_conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "added_new_conv2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1210 15:23:37.296378 15772 layer_factory.cpp:58] Creating layer cifar
I1210 15:23:37.299379 15772 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1210 15:23:37.299379 15772 net.cpp:84] Creating Layer cifar
I1210 15:23:37.299379 15772 net.cpp:380] cifar -> data
I1210 15:23:37.299379 15772 net.cpp:380] cifar -> label
I1210 15:23:37.300379 15772 data_layer.cpp:45] output data size: 100,3,32,32
I1210 15:23:37.306390 15772 net.cpp:122] Setting up cifar
I1210 15:23:37.306390 15772 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1210 15:23:37.306390 15772 net.cpp:129] Top shape: 100 (100)
I1210 15:23:37.306390 15772 net.cpp:137] Memory required for data: 1229200
I1210 15:23:37.306390 15772 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1210 15:23:37.306390 15772 net.cpp:84] Creating Layer label_cifar_1_split
I1210 15:23:37.306390 15772 net.cpp:406] label_cifar_1_split <- label
I1210 15:23:37.306390 15772 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1210 15:23:37.306390 15772 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1210 15:23:37.306390 15772 net.cpp:122] Setting up label_cifar_1_split
I1210 15:23:37.306390 15772 net.cpp:129] Top shape: 100 (100)
I1210 15:23:37.306390 15772 net.cpp:129] Top shape: 100 (100)
I1210 15:23:37.306390 15772 net.cpp:137] Memory required for data: 1230000
I1210 15:23:37.306390 15772 layer_factory.cpp:58] Creating layer conv1
I1210 15:23:37.306390 15772 net.cpp:84] Creating Layer conv1
I1210 15:23:37.306390 15772 net.cpp:406] conv1 <- data
I1210 15:23:37.306390 15772 net.cpp:380] conv1 -> conv1
I1210 15:23:37.310385 18600 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 15:23:37.560909 15772 net.cpp:122] Setting up conv1
I1210 15:23:37.560909 15772 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 15:23:37.560909 15772 net.cpp:137] Memory required for data: 13518000
I1210 15:23:37.560909 15772 layer_factory.cpp:58] Creating layer bn1
I1210 15:23:37.560909 15772 net.cpp:84] Creating Layer bn1
I1210 15:23:37.560909 15772 net.cpp:406] bn1 <- conv1
I1210 15:23:37.560909 15772 net.cpp:367] bn1 -> conv1 (in-place)
I1210 15:23:37.561409 15772 net.cpp:122] Setting up bn1
I1210 15:23:37.561409 15772 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 15:23:37.561409 15772 net.cpp:137] Memory required for data: 25806000
I1210 15:23:37.561409 15772 layer_factory.cpp:58] Creating layer scale1
I1210 15:23:37.561409 15772 net.cpp:84] Creating Layer scale1
I1210 15:23:37.561409 15772 net.cpp:406] scale1 <- conv1
I1210 15:23:37.561409 15772 net.cpp:367] scale1 -> conv1 (in-place)
I1210 15:23:37.561409 15772 layer_factory.cpp:58] Creating layer scale1
I1210 15:23:37.561409 15772 net.cpp:122] Setting up scale1
I1210 15:23:37.561409 15772 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 15:23:37.561409 15772 net.cpp:137] Memory required for data: 38094000
I1210 15:23:37.561409 15772 layer_factory.cpp:58] Creating layer relu1
I1210 15:23:37.561409 15772 net.cpp:84] Creating Layer relu1
I1210 15:23:37.561409 15772 net.cpp:406] relu1 <- conv1
I1210 15:23:37.561409 15772 net.cpp:367] relu1 -> conv1 (in-place)
I1210 15:23:37.561909 15772 net.cpp:122] Setting up relu1
I1210 15:23:37.561909 15772 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 15:23:37.561909 15772 net.cpp:137] Memory required for data: 50382000
I1210 15:23:37.561909 15772 layer_factory.cpp:58] Creating layer conv1_0
I1210 15:23:37.561909 15772 net.cpp:84] Creating Layer conv1_0
I1210 15:23:37.561909 15772 net.cpp:406] conv1_0 <- conv1
I1210 15:23:37.561909 15772 net.cpp:380] conv1_0 -> conv1_0
I1210 15:23:37.563410 15772 net.cpp:122] Setting up conv1_0
I1210 15:23:37.563410 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.563410 15772 net.cpp:137] Memory required for data: 66766000
I1210 15:23:37.563410 15772 layer_factory.cpp:58] Creating layer bn1_0
I1210 15:23:37.563410 15772 net.cpp:84] Creating Layer bn1_0
I1210 15:23:37.563410 15772 net.cpp:406] bn1_0 <- conv1_0
I1210 15:23:37.563410 15772 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1210 15:23:37.563410 15772 net.cpp:122] Setting up bn1_0
I1210 15:23:37.563410 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.563410 15772 net.cpp:137] Memory required for data: 83150000
I1210 15:23:37.563410 15772 layer_factory.cpp:58] Creating layer scale1_0
I1210 15:23:37.563410 15772 net.cpp:84] Creating Layer scale1_0
I1210 15:23:37.563910 15772 net.cpp:406] scale1_0 <- conv1_0
I1210 15:23:37.563910 15772 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1210 15:23:37.563910 15772 layer_factory.cpp:58] Creating layer scale1_0
I1210 15:23:37.563910 15772 net.cpp:122] Setting up scale1_0
I1210 15:23:37.563910 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.563910 15772 net.cpp:137] Memory required for data: 99534000
I1210 15:23:37.563910 15772 layer_factory.cpp:58] Creating layer relu1_0
I1210 15:23:37.563910 15772 net.cpp:84] Creating Layer relu1_0
I1210 15:23:37.563910 15772 net.cpp:406] relu1_0 <- conv1_0
I1210 15:23:37.563910 15772 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1210 15:23:37.563910 15772 net.cpp:122] Setting up relu1_0
I1210 15:23:37.563910 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.563910 15772 net.cpp:137] Memory required for data: 115918000
I1210 15:23:37.563910 15772 layer_factory.cpp:58] Creating layer conv2
I1210 15:23:37.563910 15772 net.cpp:84] Creating Layer conv2
I1210 15:23:37.563910 15772 net.cpp:406] conv2 <- conv1_0
I1210 15:23:37.564409 15772 net.cpp:380] conv2 -> conv2
I1210 15:23:37.564409 15772 net.cpp:122] Setting up conv2
I1210 15:23:37.565413 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.565413 15772 net.cpp:137] Memory required for data: 132302000
I1210 15:23:37.565413 15772 layer_factory.cpp:58] Creating layer bn2
I1210 15:23:37.565413 15772 net.cpp:84] Creating Layer bn2
I1210 15:23:37.565413 15772 net.cpp:406] bn2 <- conv2
I1210 15:23:37.565413 15772 net.cpp:367] bn2 -> conv2 (in-place)
I1210 15:23:37.565413 15772 net.cpp:122] Setting up bn2
I1210 15:23:37.565413 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.565413 15772 net.cpp:137] Memory required for data: 148686000
I1210 15:23:37.565413 15772 layer_factory.cpp:58] Creating layer scale2
I1210 15:23:37.565413 15772 net.cpp:84] Creating Layer scale2
I1210 15:23:37.565413 15772 net.cpp:406] scale2 <- conv2
I1210 15:23:37.565413 15772 net.cpp:367] scale2 -> conv2 (in-place)
I1210 15:23:37.565413 15772 layer_factory.cpp:58] Creating layer scale2
I1210 15:23:37.565413 15772 net.cpp:122] Setting up scale2
I1210 15:23:37.565413 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.565413 15772 net.cpp:137] Memory required for data: 165070000
I1210 15:23:37.565413 15772 layer_factory.cpp:58] Creating layer relu2
I1210 15:23:37.565413 15772 net.cpp:84] Creating Layer relu2
I1210 15:23:37.565413 15772 net.cpp:406] relu2 <- conv2
I1210 15:23:37.565413 15772 net.cpp:367] relu2 -> conv2 (in-place)
I1210 15:23:37.565413 15772 net.cpp:122] Setting up relu2
I1210 15:23:37.565413 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.565413 15772 net.cpp:137] Memory required for data: 181454000
I1210 15:23:37.565413 15772 layer_factory.cpp:58] Creating layer conv2_1
I1210 15:23:37.565413 15772 net.cpp:84] Creating Layer conv2_1
I1210 15:23:37.565413 15772 net.cpp:406] conv2_1 <- conv2
I1210 15:23:37.565413 15772 net.cpp:380] conv2_1 -> conv2_1
I1210 15:23:37.566413 15772 net.cpp:122] Setting up conv2_1
I1210 15:23:37.566413 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.566413 15772 net.cpp:137] Memory required for data: 197838000
I1210 15:23:37.566413 15772 layer_factory.cpp:58] Creating layer bn2_1
I1210 15:23:37.566413 15772 net.cpp:84] Creating Layer bn2_1
I1210 15:23:37.566413 15772 net.cpp:406] bn2_1 <- conv2_1
I1210 15:23:37.566413 15772 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1210 15:23:37.567414 15772 net.cpp:122] Setting up bn2_1
I1210 15:23:37.567414 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.567414 15772 net.cpp:137] Memory required for data: 214222000
I1210 15:23:37.567414 15772 layer_factory.cpp:58] Creating layer scale2_1
I1210 15:23:37.567414 15772 net.cpp:84] Creating Layer scale2_1
I1210 15:23:37.567414 15772 net.cpp:406] scale2_1 <- conv2_1
I1210 15:23:37.567414 15772 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1210 15:23:37.567414 15772 layer_factory.cpp:58] Creating layer scale2_1
I1210 15:23:37.567414 15772 net.cpp:122] Setting up scale2_1
I1210 15:23:37.567414 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.567414 15772 net.cpp:137] Memory required for data: 230606000
I1210 15:23:37.567414 15772 layer_factory.cpp:58] Creating layer relu2_1
I1210 15:23:37.567414 15772 net.cpp:84] Creating Layer relu2_1
I1210 15:23:37.567414 15772 net.cpp:406] relu2_1 <- conv2_1
I1210 15:23:37.567414 15772 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1210 15:23:37.567414 15772 net.cpp:122] Setting up relu2_1
I1210 15:23:37.567414 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.567414 15772 net.cpp:137] Memory required for data: 246990000
I1210 15:23:37.567414 15772 layer_factory.cpp:58] Creating layer conv2_2
I1210 15:23:37.567414 15772 net.cpp:84] Creating Layer conv2_2
I1210 15:23:37.567414 15772 net.cpp:406] conv2_2 <- conv2_1
I1210 15:23:37.567414 15772 net.cpp:380] conv2_2 -> conv2_2
I1210 15:23:37.569413 15772 net.cpp:122] Setting up conv2_2
I1210 15:23:37.569413 15772 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 15:23:37.569413 15772 net.cpp:137] Memory required for data: 267470000
I1210 15:23:37.569413 15772 layer_factory.cpp:58] Creating layer bn2_2
I1210 15:23:37.569413 15772 net.cpp:84] Creating Layer bn2_2
I1210 15:23:37.569413 15772 net.cpp:406] bn2_2 <- conv2_2
I1210 15:23:37.569413 15772 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1210 15:23:37.569413 15772 net.cpp:122] Setting up bn2_2
I1210 15:23:37.569413 15772 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 15:23:37.569413 15772 net.cpp:137] Memory required for data: 287950000
I1210 15:23:37.569413 15772 layer_factory.cpp:58] Creating layer scale2_2
I1210 15:23:37.569413 15772 net.cpp:84] Creating Layer scale2_2
I1210 15:23:37.569413 15772 net.cpp:406] scale2_2 <- conv2_2
I1210 15:23:37.569413 15772 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1210 15:23:37.569413 15772 layer_factory.cpp:58] Creating layer scale2_2
I1210 15:23:37.569413 15772 net.cpp:122] Setting up scale2_2
I1210 15:23:37.569413 15772 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 15:23:37.569413 15772 net.cpp:137] Memory required for data: 308430000
I1210 15:23:37.569413 15772 layer_factory.cpp:58] Creating layer relu2_2
I1210 15:23:37.569413 15772 net.cpp:84] Creating Layer relu2_2
I1210 15:23:37.569413 15772 net.cpp:406] relu2_2 <- conv2_2
I1210 15:23:37.569413 15772 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1210 15:23:37.570418 15772 net.cpp:122] Setting up relu2_2
I1210 15:23:37.570418 15772 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 15:23:37.570418 15772 net.cpp:137] Memory required for data: 328910000
I1210 15:23:37.570418 15772 layer_factory.cpp:58] Creating layer newconv_added1
I1210 15:23:37.570418 15772 net.cpp:84] Creating Layer newconv_added1
I1210 15:23:37.570418 15772 net.cpp:406] newconv_added1 <- conv2_2
I1210 15:23:37.570418 15772 net.cpp:380] newconv_added1 -> newconv_added1
I1210 15:23:37.572414 15772 net.cpp:122] Setting up newconv_added1
I1210 15:23:37.572414 15772 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 15:23:37.572414 15772 net.cpp:137] Memory required for data: 349390000
I1210 15:23:37.572414 15772 layer_factory.cpp:58] Creating layer pool2_1
I1210 15:23:37.572414 15772 net.cpp:84] Creating Layer pool2_1
I1210 15:23:37.572414 15772 net.cpp:406] pool2_1 <- newconv_added1
I1210 15:23:37.572414 15772 net.cpp:380] pool2_1 -> pool2_1
I1210 15:23:37.572414 15772 net.cpp:122] Setting up pool2_1
I1210 15:23:37.572414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.572414 15772 net.cpp:137] Memory required for data: 354510000
I1210 15:23:37.572414 15772 layer_factory.cpp:58] Creating layer conv3
I1210 15:23:37.572414 15772 net.cpp:84] Creating Layer conv3
I1210 15:23:37.572414 15772 net.cpp:406] conv3 <- pool2_1
I1210 15:23:37.572414 15772 net.cpp:380] conv3 -> conv3
I1210 15:23:37.573413 15772 net.cpp:122] Setting up conv3
I1210 15:23:37.573413 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.573413 15772 net.cpp:137] Memory required for data: 359630000
I1210 15:23:37.573413 15772 layer_factory.cpp:58] Creating layer bn3
I1210 15:23:37.573413 15772 net.cpp:84] Creating Layer bn3
I1210 15:23:37.573413 15772 net.cpp:406] bn3 <- conv3
I1210 15:23:37.573413 15772 net.cpp:367] bn3 -> conv3 (in-place)
I1210 15:23:37.574414 15772 net.cpp:122] Setting up bn3
I1210 15:23:37.574414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.574414 15772 net.cpp:137] Memory required for data: 364750000
I1210 15:23:37.574414 15772 layer_factory.cpp:58] Creating layer scale3
I1210 15:23:37.574414 15772 net.cpp:84] Creating Layer scale3
I1210 15:23:37.574414 15772 net.cpp:406] scale3 <- conv3
I1210 15:23:37.574414 15772 net.cpp:367] scale3 -> conv3 (in-place)
I1210 15:23:37.574414 15772 layer_factory.cpp:58] Creating layer scale3
I1210 15:23:37.574414 15772 net.cpp:122] Setting up scale3
I1210 15:23:37.574414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.574414 15772 net.cpp:137] Memory required for data: 369870000
I1210 15:23:37.574414 15772 layer_factory.cpp:58] Creating layer relu3
I1210 15:23:37.574414 15772 net.cpp:84] Creating Layer relu3
I1210 15:23:37.574414 15772 net.cpp:406] relu3 <- conv3
I1210 15:23:37.574414 15772 net.cpp:367] relu3 -> conv3 (in-place)
I1210 15:23:37.574414 15772 net.cpp:122] Setting up relu3
I1210 15:23:37.574414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.574414 15772 net.cpp:137] Memory required for data: 374990000
I1210 15:23:37.574414 15772 layer_factory.cpp:58] Creating layer conv3_1
I1210 15:23:37.574414 15772 net.cpp:84] Creating Layer conv3_1
I1210 15:23:37.574414 15772 net.cpp:406] conv3_1 <- conv3
I1210 15:23:37.574414 15772 net.cpp:380] conv3_1 -> conv3_1
I1210 15:23:37.575414 15772 net.cpp:122] Setting up conv3_1
I1210 15:23:37.575414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.575414 15772 net.cpp:137] Memory required for data: 380110000
I1210 15:23:37.575414 15772 layer_factory.cpp:58] Creating layer bn3_1
I1210 15:23:37.575414 15772 net.cpp:84] Creating Layer bn3_1
I1210 15:23:37.575414 15772 net.cpp:406] bn3_1 <- conv3_1
I1210 15:23:37.575414 15772 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1210 15:23:37.576414 15772 net.cpp:122] Setting up bn3_1
I1210 15:23:37.576414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.576414 15772 net.cpp:137] Memory required for data: 385230000
I1210 15:23:37.576414 15772 layer_factory.cpp:58] Creating layer scale3_1
I1210 15:23:37.576414 15772 net.cpp:84] Creating Layer scale3_1
I1210 15:23:37.576414 15772 net.cpp:406] scale3_1 <- conv3_1
I1210 15:23:37.576414 15772 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1210 15:23:37.576414 15772 layer_factory.cpp:58] Creating layer scale3_1
I1210 15:23:37.576414 15772 net.cpp:122] Setting up scale3_1
I1210 15:23:37.576414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.576414 15772 net.cpp:137] Memory required for data: 390350000
I1210 15:23:37.576414 15772 layer_factory.cpp:58] Creating layer relu3_1
I1210 15:23:37.576414 15772 net.cpp:84] Creating Layer relu3_1
I1210 15:23:37.576414 15772 net.cpp:406] relu3_1 <- conv3_1
I1210 15:23:37.576414 15772 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1210 15:23:37.576414 15772 net.cpp:122] Setting up relu3_1
I1210 15:23:37.576414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.576414 15772 net.cpp:137] Memory required for data: 395470000
I1210 15:23:37.576414 15772 layer_factory.cpp:58] Creating layer conv4
I1210 15:23:37.576414 15772 net.cpp:84] Creating Layer conv4
I1210 15:23:37.576414 15772 net.cpp:406] conv4 <- conv3_1
I1210 15:23:37.576414 15772 net.cpp:380] conv4 -> conv4
I1210 15:23:37.577414 15772 net.cpp:122] Setting up conv4
I1210 15:23:37.578414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.578414 15772 net.cpp:137] Memory required for data: 400590000
I1210 15:23:37.578414 15772 layer_factory.cpp:58] Creating layer bn4
I1210 15:23:37.578414 15772 net.cpp:84] Creating Layer bn4
I1210 15:23:37.578414 15772 net.cpp:406] bn4 <- conv4
I1210 15:23:37.578414 15772 net.cpp:367] bn4 -> conv4 (in-place)
I1210 15:23:37.578414 15772 net.cpp:122] Setting up bn4
I1210 15:23:37.578414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.578414 15772 net.cpp:137] Memory required for data: 405710000
I1210 15:23:37.578414 15772 layer_factory.cpp:58] Creating layer scale4
I1210 15:23:37.578414 15772 net.cpp:84] Creating Layer scale4
I1210 15:23:37.578414 15772 net.cpp:406] scale4 <- conv4
I1210 15:23:37.578414 15772 net.cpp:367] scale4 -> conv4 (in-place)
I1210 15:23:37.578414 15772 layer_factory.cpp:58] Creating layer scale4
I1210 15:23:37.578414 15772 net.cpp:122] Setting up scale4
I1210 15:23:37.578414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.578414 15772 net.cpp:137] Memory required for data: 410830000
I1210 15:23:37.578414 15772 layer_factory.cpp:58] Creating layer relu4
I1210 15:23:37.578414 15772 net.cpp:84] Creating Layer relu4
I1210 15:23:37.578414 15772 net.cpp:406] relu4 <- conv4
I1210 15:23:37.578414 15772 net.cpp:367] relu4 -> conv4 (in-place)
I1210 15:23:37.578414 15772 net.cpp:122] Setting up relu4
I1210 15:23:37.578414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.578414 15772 net.cpp:137] Memory required for data: 415950000
I1210 15:23:37.578414 15772 layer_factory.cpp:58] Creating layer conv4_1
I1210 15:23:37.578414 15772 net.cpp:84] Creating Layer conv4_1
I1210 15:23:37.578414 15772 net.cpp:406] conv4_1 <- conv4
I1210 15:23:37.578414 15772 net.cpp:380] conv4_1 -> conv4_1
I1210 15:23:37.580415 15772 net.cpp:122] Setting up conv4_1
I1210 15:23:37.580415 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.580415 15772 net.cpp:137] Memory required for data: 421070000
I1210 15:23:37.580415 15772 layer_factory.cpp:58] Creating layer bn4_1
I1210 15:23:37.580415 15772 net.cpp:84] Creating Layer bn4_1
I1210 15:23:37.580415 15772 net.cpp:406] bn4_1 <- conv4_1
I1210 15:23:37.580415 15772 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1210 15:23:37.580415 15772 net.cpp:122] Setting up bn4_1
I1210 15:23:37.580415 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.580415 15772 net.cpp:137] Memory required for data: 426190000
I1210 15:23:37.580415 15772 layer_factory.cpp:58] Creating layer scale4_1
I1210 15:23:37.580415 15772 net.cpp:84] Creating Layer scale4_1
I1210 15:23:37.580415 15772 net.cpp:406] scale4_1 <- conv4_1
I1210 15:23:37.580415 15772 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1210 15:23:37.580415 15772 layer_factory.cpp:58] Creating layer scale4_1
I1210 15:23:37.580415 15772 net.cpp:122] Setting up scale4_1
I1210 15:23:37.580415 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.580415 15772 net.cpp:137] Memory required for data: 431310000
I1210 15:23:37.580415 15772 layer_factory.cpp:58] Creating layer relu4_1
I1210 15:23:37.580415 15772 net.cpp:84] Creating Layer relu4_1
I1210 15:23:37.580415 15772 net.cpp:406] relu4_1 <- conv4_1
I1210 15:23:37.580415 15772 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1210 15:23:37.580415 15772 net.cpp:122] Setting up relu4_1
I1210 15:23:37.580415 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.580415 15772 net.cpp:137] Memory required for data: 436430000
I1210 15:23:37.580415 15772 layer_factory.cpp:58] Creating layer conv4_2
I1210 15:23:37.580415 15772 net.cpp:84] Creating Layer conv4_2
I1210 15:23:37.580415 15772 net.cpp:406] conv4_2 <- conv4_1
I1210 15:23:37.580415 15772 net.cpp:380] conv4_2 -> conv4_2
I1210 15:23:37.582414 15772 net.cpp:122] Setting up conv4_2
I1210 15:23:37.582414 15772 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 15:23:37.582414 15772 net.cpp:137] Memory required for data: 442369200
I1210 15:23:37.582414 15772 layer_factory.cpp:58] Creating layer bn4_2
I1210 15:23:37.582414 15772 net.cpp:84] Creating Layer bn4_2
I1210 15:23:37.582414 15772 net.cpp:406] bn4_2 <- conv4_2
I1210 15:23:37.582414 15772 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1210 15:23:37.582414 15772 net.cpp:122] Setting up bn4_2
I1210 15:23:37.582414 15772 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 15:23:37.582414 15772 net.cpp:137] Memory required for data: 448308400
I1210 15:23:37.582414 15772 layer_factory.cpp:58] Creating layer scale4_2
I1210 15:23:37.582414 15772 net.cpp:84] Creating Layer scale4_2
I1210 15:23:37.582414 15772 net.cpp:406] scale4_2 <- conv4_2
I1210 15:23:37.582414 15772 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1210 15:23:37.582414 15772 layer_factory.cpp:58] Creating layer scale4_2
I1210 15:23:37.582414 15772 net.cpp:122] Setting up scale4_2
I1210 15:23:37.582414 15772 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 15:23:37.582414 15772 net.cpp:137] Memory required for data: 454247600
I1210 15:23:37.582414 15772 layer_factory.cpp:58] Creating layer relu4_2
I1210 15:23:37.582414 15772 net.cpp:84] Creating Layer relu4_2
I1210 15:23:37.582414 15772 net.cpp:406] relu4_2 <- conv4_2
I1210 15:23:37.582414 15772 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1210 15:23:37.582414 15772 net.cpp:122] Setting up relu4_2
I1210 15:23:37.582414 15772 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 15:23:37.582414 15772 net.cpp:137] Memory required for data: 460186800
I1210 15:23:37.582414 15772 layer_factory.cpp:58] Creating layer added_new_conv2
I1210 15:23:37.582414 15772 net.cpp:84] Creating Layer added_new_conv2
I1210 15:23:37.582414 15772 net.cpp:406] added_new_conv2 <- conv4_2
I1210 15:23:37.582414 15772 net.cpp:380] added_new_conv2 -> added_new_conv2
I1210 15:23:37.584414 15772 net.cpp:122] Setting up added_new_conv2
I1210 15:23:37.584414 15772 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 15:23:37.584414 15772 net.cpp:137] Memory required for data: 466126000
I1210 15:23:37.584414 15772 layer_factory.cpp:58] Creating layer pool4_2
I1210 15:23:37.584414 15772 net.cpp:84] Creating Layer pool4_2
I1210 15:23:37.584414 15772 net.cpp:406] pool4_2 <- added_new_conv2
I1210 15:23:37.584414 15772 net.cpp:380] pool4_2 -> pool4_2
I1210 15:23:37.584414 15772 net.cpp:122] Setting up pool4_2
I1210 15:23:37.584414 15772 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 15:23:37.584414 15772 net.cpp:137] Memory required for data: 467610800
I1210 15:23:37.584414 15772 layer_factory.cpp:58] Creating layer conv4_0
I1210 15:23:37.584414 15772 net.cpp:84] Creating Layer conv4_0
I1210 15:23:37.584414 15772 net.cpp:406] conv4_0 <- pool4_2
I1210 15:23:37.584414 15772 net.cpp:380] conv4_0 -> conv4_0
I1210 15:23:37.585414 15772 net.cpp:122] Setting up conv4_0
I1210 15:23:37.585414 15772 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 15:23:37.585414 15772 net.cpp:137] Memory required for data: 469095600
I1210 15:23:37.585414 15772 layer_factory.cpp:58] Creating layer bn4_0
I1210 15:23:37.585414 15772 net.cpp:84] Creating Layer bn4_0
I1210 15:23:37.585414 15772 net.cpp:406] bn4_0 <- conv4_0
I1210 15:23:37.585414 15772 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1210 15:23:37.586414 15772 net.cpp:122] Setting up bn4_0
I1210 15:23:37.586414 15772 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 15:23:37.586414 15772 net.cpp:137] Memory required for data: 470580400
I1210 15:23:37.586414 15772 layer_factory.cpp:58] Creating layer scale4_0
I1210 15:23:37.586414 15772 net.cpp:84] Creating Layer scale4_0
I1210 15:23:37.586414 15772 net.cpp:406] scale4_0 <- conv4_0
I1210 15:23:37.586414 15772 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1210 15:23:37.586414 15772 layer_factory.cpp:58] Creating layer scale4_0
I1210 15:23:37.586414 15772 net.cpp:122] Setting up scale4_0
I1210 15:23:37.586414 15772 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 15:23:37.586414 15772 net.cpp:137] Memory required for data: 472065200
I1210 15:23:37.586414 15772 layer_factory.cpp:58] Creating layer relu4_0
I1210 15:23:37.586414 15772 net.cpp:84] Creating Layer relu4_0
I1210 15:23:37.586414 15772 net.cpp:406] relu4_0 <- conv4_0
I1210 15:23:37.586414 15772 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1210 15:23:37.586414 15772 net.cpp:122] Setting up relu4_0
I1210 15:23:37.586414 15772 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 15:23:37.587415 15772 net.cpp:137] Memory required for data: 473550000
I1210 15:23:37.587415 15772 layer_factory.cpp:58] Creating layer conv11
I1210 15:23:37.587415 15772 net.cpp:84] Creating Layer conv11
I1210 15:23:37.587415 15772 net.cpp:406] conv11 <- conv4_0
I1210 15:23:37.587415 15772 net.cpp:380] conv11 -> conv11
I1210 15:23:37.588415 15772 net.cpp:122] Setting up conv11
I1210 15:23:37.589414 15772 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 15:23:37.589414 15772 net.cpp:137] Memory required for data: 475342000
I1210 15:23:37.589414 15772 layer_factory.cpp:58] Creating layer bn_conv11
I1210 15:23:37.589414 15772 net.cpp:84] Creating Layer bn_conv11
I1210 15:23:37.589414 15772 net.cpp:406] bn_conv11 <- conv11
I1210 15:23:37.589414 15772 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1210 15:23:37.589414 15772 net.cpp:122] Setting up bn_conv11
I1210 15:23:37.589414 15772 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 15:23:37.589414 15772 net.cpp:137] Memory required for data: 477134000
I1210 15:23:37.589414 15772 layer_factory.cpp:58] Creating layer scale_conv11
I1210 15:23:37.589414 15772 net.cpp:84] Creating Layer scale_conv11
I1210 15:23:37.589414 15772 net.cpp:406] scale_conv11 <- conv11
I1210 15:23:37.589414 15772 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1210 15:23:37.589414 15772 layer_factory.cpp:58] Creating layer scale_conv11
I1210 15:23:37.589414 15772 net.cpp:122] Setting up scale_conv11
I1210 15:23:37.589414 15772 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 15:23:37.589414 15772 net.cpp:137] Memory required for data: 478926000
I1210 15:23:37.589414 15772 layer_factory.cpp:58] Creating layer relu_conv11
I1210 15:23:37.589414 15772 net.cpp:84] Creating Layer relu_conv11
I1210 15:23:37.589414 15772 net.cpp:406] relu_conv11 <- conv11
I1210 15:23:37.589414 15772 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1210 15:23:37.589414 15772 net.cpp:122] Setting up relu_conv11
I1210 15:23:37.589414 15772 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 15:23:37.589414 15772 net.cpp:137] Memory required for data: 480718000
I1210 15:23:37.589414 15772 layer_factory.cpp:58] Creating layer conv12
I1210 15:23:37.590415 15772 net.cpp:84] Creating Layer conv12
I1210 15:23:37.590415 15772 net.cpp:406] conv12 <- conv11
I1210 15:23:37.590415 15772 net.cpp:380] conv12 -> conv12
I1210 15:23:37.591414 15772 net.cpp:122] Setting up conv12
I1210 15:23:37.591414 15772 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 15:23:37.591414 15772 net.cpp:137] Memory required for data: 483022000
I1210 15:23:37.591414 15772 layer_factory.cpp:58] Creating layer bn_conv12
I1210 15:23:37.591414 15772 net.cpp:84] Creating Layer bn_conv12
I1210 15:23:37.591414 15772 net.cpp:406] bn_conv12 <- conv12
I1210 15:23:37.591414 15772 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1210 15:23:37.591414 15772 net.cpp:122] Setting up bn_conv12
I1210 15:23:37.591414 15772 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 15:23:37.591414 15772 net.cpp:137] Memory required for data: 485326000
I1210 15:23:37.591414 15772 layer_factory.cpp:58] Creating layer scale_conv12
I1210 15:23:37.591414 15772 net.cpp:84] Creating Layer scale_conv12
I1210 15:23:37.591414 15772 net.cpp:406] scale_conv12 <- conv12
I1210 15:23:37.591414 15772 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1210 15:23:37.591414 15772 layer_factory.cpp:58] Creating layer scale_conv12
I1210 15:23:37.591414 15772 net.cpp:122] Setting up scale_conv12
I1210 15:23:37.591414 15772 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 15:23:37.591414 15772 net.cpp:137] Memory required for data: 487630000
I1210 15:23:37.591414 15772 layer_factory.cpp:58] Creating layer relu_conv12
I1210 15:23:37.591414 15772 net.cpp:84] Creating Layer relu_conv12
I1210 15:23:37.591414 15772 net.cpp:406] relu_conv12 <- conv12
I1210 15:23:37.591414 15772 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1210 15:23:37.592414 15772 net.cpp:122] Setting up relu_conv12
I1210 15:23:37.592414 15772 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 15:23:37.592414 15772 net.cpp:137] Memory required for data: 489934000
I1210 15:23:37.592414 15772 layer_factory.cpp:58] Creating layer poolcp6
I1210 15:23:37.592414 15772 net.cpp:84] Creating Layer poolcp6
I1210 15:23:37.592414 15772 net.cpp:406] poolcp6 <- conv12
I1210 15:23:37.592414 15772 net.cpp:380] poolcp6 -> poolcp6
I1210 15:23:37.592414 15772 net.cpp:122] Setting up poolcp6
I1210 15:23:37.592414 15772 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1210 15:23:37.592414 15772 net.cpp:137] Memory required for data: 489970000
I1210 15:23:37.592414 15772 layer_factory.cpp:58] Creating layer ip1
I1210 15:23:37.592414 15772 net.cpp:84] Creating Layer ip1
I1210 15:23:37.592414 15772 net.cpp:406] ip1 <- poolcp6
I1210 15:23:37.592414 15772 net.cpp:380] ip1 -> ip1
I1210 15:23:37.592414 15772 net.cpp:122] Setting up ip1
I1210 15:23:37.592414 15772 net.cpp:129] Top shape: 100 100 (10000)
I1210 15:23:37.592414 15772 net.cpp:137] Memory required for data: 490010000
I1210 15:23:37.592414 15772 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1210 15:23:37.592414 15772 net.cpp:84] Creating Layer ip1_ip1_0_split
I1210 15:23:37.592414 15772 net.cpp:406] ip1_ip1_0_split <- ip1
I1210 15:23:37.592414 15772 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1210 15:23:37.592414 15772 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1210 15:23:37.592414 15772 net.cpp:122] Setting up ip1_ip1_0_split
I1210 15:23:37.592414 15772 net.cpp:129] Top shape: 100 100 (10000)
I1210 15:23:37.592414 15772 net.cpp:129] Top shape: 100 100 (10000)
I1210 15:23:37.592414 15772 net.cpp:137] Memory required for data: 490090000
I1210 15:23:37.592414 15772 layer_factory.cpp:58] Creating layer accuracy_training
I1210 15:23:37.592414 15772 net.cpp:84] Creating Layer accuracy_training
I1210 15:23:37.592414 15772 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1210 15:23:37.592414 15772 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1210 15:23:37.592414 15772 net.cpp:380] accuracy_training -> accuracy_training
I1210 15:23:37.592414 15772 net.cpp:122] Setting up accuracy_training
I1210 15:23:37.592414 15772 net.cpp:129] Top shape: (1)
I1210 15:23:37.592414 15772 net.cpp:137] Memory required for data: 490090004
I1210 15:23:37.592414 15772 layer_factory.cpp:58] Creating layer loss
I1210 15:23:37.592414 15772 net.cpp:84] Creating Layer loss
I1210 15:23:37.592414 15772 net.cpp:406] loss <- ip1_ip1_0_split_1
I1210 15:23:37.592414 15772 net.cpp:406] loss <- label_cifar_1_split_1
I1210 15:23:37.592414 15772 net.cpp:380] loss -> loss
I1210 15:23:37.592414 15772 layer_factory.cpp:58] Creating layer loss
I1210 15:23:37.593415 15772 net.cpp:122] Setting up loss
I1210 15:23:37.593415 15772 net.cpp:129] Top shape: (1)
I1210 15:23:37.593415 15772 net.cpp:132]     with loss weight 1
I1210 15:23:37.593415 15772 net.cpp:137] Memory required for data: 490090008
I1210 15:23:37.593415 15772 net.cpp:198] loss needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:200] accuracy_training does not need backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] ip1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] poolcp6 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu_conv12 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale_conv12 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn_conv12 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv12 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu_conv11 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale_conv11 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn_conv11 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv11 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu4_0 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale4_0 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn4_0 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv4_0 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] pool4_2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] added_new_conv2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu4_2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale4_2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn4_2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv4_2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu4_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale4_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn4_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv4_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu4 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale4 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn4 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv4 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu3_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale3_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn3_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv3_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu3 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale3 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn3 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv3 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] pool2_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] newconv_added1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu2_2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale2_2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn2_2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv2_2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu2_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale2_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn2_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv2_1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv2 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu1_0 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale1_0 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn1_0 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv1_0 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] relu1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] scale1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] bn1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:198] conv1 needs backward computation.
I1210 15:23:37.593415 15772 net.cpp:200] label_cifar_1_split does not need backward computation.
I1210 15:23:37.593415 15772 net.cpp:200] cifar does not need backward computation.
I1210 15:23:37.593415 15772 net.cpp:242] This network produces output accuracy_training
I1210 15:23:37.593415 15772 net.cpp:242] This network produces output loss
I1210 15:23:37.593415 15772 net.cpp:255] Network initialization done.
I1210 15:23:37.594414 15772 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 15:23:37.594414 15772 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 15:23:37.594414 15772 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1210 15:23:37.594414 15772 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1210 15:23:37.595414 15772 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_v2_360k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "newconv_added1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "newconv_added1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "newconv_added1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "added_new_conv2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "added_new_conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "added_new_conv2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1210 15:23:37.595414 15772 layer_factory.cpp:58] Creating layer cifar
I1210 15:23:37.600414 15772 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1210 15:23:37.600414 15772 net.cpp:84] Creating Layer cifar
I1210 15:23:37.600414 15772 net.cpp:380] cifar -> data
I1210 15:23:37.601419 15772 net.cpp:380] cifar -> label
I1210 15:23:37.601419 15772 data_layer.cpp:45] output data size: 100,3,32,32
I1210 15:23:37.609413 15772 net.cpp:122] Setting up cifar
I1210 15:23:37.609413 15772 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1210 15:23:37.609413 15772 net.cpp:129] Top shape: 100 (100)
I1210 15:23:37.609413 15772 net.cpp:137] Memory required for data: 1229200
I1210 15:23:37.609413 15772 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1210 15:23:37.609413 15772 net.cpp:84] Creating Layer label_cifar_1_split
I1210 15:23:37.609413 15772 net.cpp:406] label_cifar_1_split <- label
I1210 15:23:37.609413 15772 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1210 15:23:37.609413 15772 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1210 15:23:37.609413 15772 net.cpp:122] Setting up label_cifar_1_split
I1210 15:23:37.609413 15772 net.cpp:129] Top shape: 100 (100)
I1210 15:23:37.609413 15772 net.cpp:129] Top shape: 100 (100)
I1210 15:23:37.609413 15772 net.cpp:137] Memory required for data: 1230000
I1210 15:23:37.609413 15772 layer_factory.cpp:58] Creating layer conv1
I1210 15:23:37.609413 15772 net.cpp:84] Creating Layer conv1
I1210 15:23:37.609413 15772 net.cpp:406] conv1 <- data
I1210 15:23:37.609413 15772 net.cpp:380] conv1 -> conv1
I1210 15:23:37.611414 10416 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 15:23:37.611414 15772 net.cpp:122] Setting up conv1
I1210 15:23:37.611414 15772 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 15:23:37.611414 15772 net.cpp:137] Memory required for data: 13518000
I1210 15:23:37.611414 15772 layer_factory.cpp:58] Creating layer bn1
I1210 15:23:37.611414 15772 net.cpp:84] Creating Layer bn1
I1210 15:23:37.611414 15772 net.cpp:406] bn1 <- conv1
I1210 15:23:37.611414 15772 net.cpp:367] bn1 -> conv1 (in-place)
I1210 15:23:37.612414 15772 net.cpp:122] Setting up bn1
I1210 15:23:37.612414 15772 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 15:23:37.612414 15772 net.cpp:137] Memory required for data: 25806000
I1210 15:23:37.612414 15772 layer_factory.cpp:58] Creating layer scale1
I1210 15:23:37.612414 15772 net.cpp:84] Creating Layer scale1
I1210 15:23:37.612414 15772 net.cpp:406] scale1 <- conv1
I1210 15:23:37.612414 15772 net.cpp:367] scale1 -> conv1 (in-place)
I1210 15:23:37.612414 15772 layer_factory.cpp:58] Creating layer scale1
I1210 15:23:37.612414 15772 net.cpp:122] Setting up scale1
I1210 15:23:37.612414 15772 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 15:23:37.612414 15772 net.cpp:137] Memory required for data: 38094000
I1210 15:23:37.612414 15772 layer_factory.cpp:58] Creating layer relu1
I1210 15:23:37.612414 15772 net.cpp:84] Creating Layer relu1
I1210 15:23:37.612414 15772 net.cpp:406] relu1 <- conv1
I1210 15:23:37.612414 15772 net.cpp:367] relu1 -> conv1 (in-place)
I1210 15:23:37.612414 15772 net.cpp:122] Setting up relu1
I1210 15:23:37.612414 15772 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 15:23:37.612414 15772 net.cpp:137] Memory required for data: 50382000
I1210 15:23:37.612414 15772 layer_factory.cpp:58] Creating layer conv1_0
I1210 15:23:37.612414 15772 net.cpp:84] Creating Layer conv1_0
I1210 15:23:37.612414 15772 net.cpp:406] conv1_0 <- conv1
I1210 15:23:37.612414 15772 net.cpp:380] conv1_0 -> conv1_0
I1210 15:23:37.613415 15772 net.cpp:122] Setting up conv1_0
I1210 15:23:37.613415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.613415 15772 net.cpp:137] Memory required for data: 66766000
I1210 15:23:37.614415 15772 layer_factory.cpp:58] Creating layer bn1_0
I1210 15:23:37.614415 15772 net.cpp:84] Creating Layer bn1_0
I1210 15:23:37.614415 15772 net.cpp:406] bn1_0 <- conv1_0
I1210 15:23:37.614415 15772 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1210 15:23:37.614415 15772 net.cpp:122] Setting up bn1_0
I1210 15:23:37.614415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.614415 15772 net.cpp:137] Memory required for data: 83150000
I1210 15:23:37.614415 15772 layer_factory.cpp:58] Creating layer scale1_0
I1210 15:23:37.614415 15772 net.cpp:84] Creating Layer scale1_0
I1210 15:23:37.614415 15772 net.cpp:406] scale1_0 <- conv1_0
I1210 15:23:37.614415 15772 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1210 15:23:37.614415 15772 layer_factory.cpp:58] Creating layer scale1_0
I1210 15:23:37.614415 15772 net.cpp:122] Setting up scale1_0
I1210 15:23:37.614415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.614415 15772 net.cpp:137] Memory required for data: 99534000
I1210 15:23:37.614415 15772 layer_factory.cpp:58] Creating layer relu1_0
I1210 15:23:37.614415 15772 net.cpp:84] Creating Layer relu1_0
I1210 15:23:37.614415 15772 net.cpp:406] relu1_0 <- conv1_0
I1210 15:23:37.614415 15772 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1210 15:23:37.614415 15772 net.cpp:122] Setting up relu1_0
I1210 15:23:37.614415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.614415 15772 net.cpp:137] Memory required for data: 115918000
I1210 15:23:37.614415 15772 layer_factory.cpp:58] Creating layer conv2
I1210 15:23:37.614415 15772 net.cpp:84] Creating Layer conv2
I1210 15:23:37.614415 15772 net.cpp:406] conv2 <- conv1_0
I1210 15:23:37.614415 15772 net.cpp:380] conv2 -> conv2
I1210 15:23:37.616415 15772 net.cpp:122] Setting up conv2
I1210 15:23:37.616415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.616415 15772 net.cpp:137] Memory required for data: 132302000
I1210 15:23:37.616415 15772 layer_factory.cpp:58] Creating layer bn2
I1210 15:23:37.616415 15772 net.cpp:84] Creating Layer bn2
I1210 15:23:37.616415 15772 net.cpp:406] bn2 <- conv2
I1210 15:23:37.616415 15772 net.cpp:367] bn2 -> conv2 (in-place)
I1210 15:23:37.616415 15772 net.cpp:122] Setting up bn2
I1210 15:23:37.616415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.616415 15772 net.cpp:137] Memory required for data: 148686000
I1210 15:23:37.616415 15772 layer_factory.cpp:58] Creating layer scale2
I1210 15:23:37.616415 15772 net.cpp:84] Creating Layer scale2
I1210 15:23:37.616415 15772 net.cpp:406] scale2 <- conv2
I1210 15:23:37.616415 15772 net.cpp:367] scale2 -> conv2 (in-place)
I1210 15:23:37.616415 15772 layer_factory.cpp:58] Creating layer scale2
I1210 15:23:37.616415 15772 net.cpp:122] Setting up scale2
I1210 15:23:37.616415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.616415 15772 net.cpp:137] Memory required for data: 165070000
I1210 15:23:37.616415 15772 layer_factory.cpp:58] Creating layer relu2
I1210 15:23:37.616415 15772 net.cpp:84] Creating Layer relu2
I1210 15:23:37.617414 15772 net.cpp:406] relu2 <- conv2
I1210 15:23:37.617414 15772 net.cpp:367] relu2 -> conv2 (in-place)
I1210 15:23:37.617414 15772 net.cpp:122] Setting up relu2
I1210 15:23:37.617414 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.617414 15772 net.cpp:137] Memory required for data: 181454000
I1210 15:23:37.617414 15772 layer_factory.cpp:58] Creating layer conv2_1
I1210 15:23:37.617414 15772 net.cpp:84] Creating Layer conv2_1
I1210 15:23:37.617414 15772 net.cpp:406] conv2_1 <- conv2
I1210 15:23:37.617414 15772 net.cpp:380] conv2_1 -> conv2_1
I1210 15:23:37.618418 15772 net.cpp:122] Setting up conv2_1
I1210 15:23:37.619415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.619415 15772 net.cpp:137] Memory required for data: 197838000
I1210 15:23:37.619415 15772 layer_factory.cpp:58] Creating layer bn2_1
I1210 15:23:37.619415 15772 net.cpp:84] Creating Layer bn2_1
I1210 15:23:37.619415 15772 net.cpp:406] bn2_1 <- conv2_1
I1210 15:23:37.619415 15772 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1210 15:23:37.619415 15772 net.cpp:122] Setting up bn2_1
I1210 15:23:37.619415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.619415 15772 net.cpp:137] Memory required for data: 214222000
I1210 15:23:37.619415 15772 layer_factory.cpp:58] Creating layer scale2_1
I1210 15:23:37.619415 15772 net.cpp:84] Creating Layer scale2_1
I1210 15:23:37.619415 15772 net.cpp:406] scale2_1 <- conv2_1
I1210 15:23:37.619415 15772 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1210 15:23:37.619415 15772 layer_factory.cpp:58] Creating layer scale2_1
I1210 15:23:37.619415 15772 net.cpp:122] Setting up scale2_1
I1210 15:23:37.619415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.619415 15772 net.cpp:137] Memory required for data: 230606000
I1210 15:23:37.619415 15772 layer_factory.cpp:58] Creating layer relu2_1
I1210 15:23:37.619415 15772 net.cpp:84] Creating Layer relu2_1
I1210 15:23:37.619415 15772 net.cpp:406] relu2_1 <- conv2_1
I1210 15:23:37.619415 15772 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1210 15:23:37.620415 15772 net.cpp:122] Setting up relu2_1
I1210 15:23:37.620415 15772 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 15:23:37.620415 15772 net.cpp:137] Memory required for data: 246990000
I1210 15:23:37.620415 15772 layer_factory.cpp:58] Creating layer conv2_2
I1210 15:23:37.620415 15772 net.cpp:84] Creating Layer conv2_2
I1210 15:23:37.620415 15772 net.cpp:406] conv2_2 <- conv2_1
I1210 15:23:37.620415 15772 net.cpp:380] conv2_2 -> conv2_2
I1210 15:23:37.622413 15772 net.cpp:122] Setting up conv2_2
I1210 15:23:37.622413 15772 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 15:23:37.622413 15772 net.cpp:137] Memory required for data: 267470000
I1210 15:23:37.622413 15772 layer_factory.cpp:58] Creating layer bn2_2
I1210 15:23:37.622413 15772 net.cpp:84] Creating Layer bn2_2
I1210 15:23:37.622413 15772 net.cpp:406] bn2_2 <- conv2_2
I1210 15:23:37.622413 15772 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1210 15:23:37.622413 15772 net.cpp:122] Setting up bn2_2
I1210 15:23:37.622413 15772 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 15:23:37.622413 15772 net.cpp:137] Memory required for data: 287950000
I1210 15:23:37.622413 15772 layer_factory.cpp:58] Creating layer scale2_2
I1210 15:23:37.622413 15772 net.cpp:84] Creating Layer scale2_2
I1210 15:23:37.622413 15772 net.cpp:406] scale2_2 <- conv2_2
I1210 15:23:37.622413 15772 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1210 15:23:37.622413 15772 layer_factory.cpp:58] Creating layer scale2_2
I1210 15:23:37.622413 15772 net.cpp:122] Setting up scale2_2
I1210 15:23:37.622413 15772 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 15:23:37.622413 15772 net.cpp:137] Memory required for data: 308430000
I1210 15:23:37.622413 15772 layer_factory.cpp:58] Creating layer relu2_2
I1210 15:23:37.622413 15772 net.cpp:84] Creating Layer relu2_2
I1210 15:23:37.622413 15772 net.cpp:406] relu2_2 <- conv2_2
I1210 15:23:37.622413 15772 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1210 15:23:37.622413 15772 net.cpp:122] Setting up relu2_2
I1210 15:23:37.622413 15772 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 15:23:37.622413 15772 net.cpp:137] Memory required for data: 328910000
I1210 15:23:37.622413 15772 layer_factory.cpp:58] Creating layer newconv_added1
I1210 15:23:37.622413 15772 net.cpp:84] Creating Layer newconv_added1
I1210 15:23:37.622413 15772 net.cpp:406] newconv_added1 <- conv2_2
I1210 15:23:37.623414 15772 net.cpp:380] newconv_added1 -> newconv_added1
I1210 15:23:37.624414 15772 net.cpp:122] Setting up newconv_added1
I1210 15:23:37.624414 15772 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 15:23:37.624414 15772 net.cpp:137] Memory required for data: 349390000
I1210 15:23:37.624414 15772 layer_factory.cpp:58] Creating layer pool2_1
I1210 15:23:37.624414 15772 net.cpp:84] Creating Layer pool2_1
I1210 15:23:37.624414 15772 net.cpp:406] pool2_1 <- newconv_added1
I1210 15:23:37.624414 15772 net.cpp:380] pool2_1 -> pool2_1
I1210 15:23:37.624414 15772 net.cpp:122] Setting up pool2_1
I1210 15:23:37.624414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.624414 15772 net.cpp:137] Memory required for data: 354510000
I1210 15:23:37.624414 15772 layer_factory.cpp:58] Creating layer conv3
I1210 15:23:37.624414 15772 net.cpp:84] Creating Layer conv3
I1210 15:23:37.624414 15772 net.cpp:406] conv3 <- pool2_1
I1210 15:23:37.624414 15772 net.cpp:380] conv3 -> conv3
I1210 15:23:37.626423 15772 net.cpp:122] Setting up conv3
I1210 15:23:37.626423 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.626423 15772 net.cpp:137] Memory required for data: 359630000
I1210 15:23:37.626423 15772 layer_factory.cpp:58] Creating layer bn3
I1210 15:23:37.626423 15772 net.cpp:84] Creating Layer bn3
I1210 15:23:37.626423 15772 net.cpp:406] bn3 <- conv3
I1210 15:23:37.626423 15772 net.cpp:367] bn3 -> conv3 (in-place)
I1210 15:23:37.626423 15772 net.cpp:122] Setting up bn3
I1210 15:23:37.626423 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.626423 15772 net.cpp:137] Memory required for data: 364750000
I1210 15:23:37.626423 15772 layer_factory.cpp:58] Creating layer scale3
I1210 15:23:37.626423 15772 net.cpp:84] Creating Layer scale3
I1210 15:23:37.626423 15772 net.cpp:406] scale3 <- conv3
I1210 15:23:37.626423 15772 net.cpp:367] scale3 -> conv3 (in-place)
I1210 15:23:37.626423 15772 layer_factory.cpp:58] Creating layer scale3
I1210 15:23:37.626423 15772 net.cpp:122] Setting up scale3
I1210 15:23:37.626423 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.626423 15772 net.cpp:137] Memory required for data: 369870000
I1210 15:23:37.627426 15772 layer_factory.cpp:58] Creating layer relu3
I1210 15:23:37.627426 15772 net.cpp:84] Creating Layer relu3
I1210 15:23:37.627426 15772 net.cpp:406] relu3 <- conv3
I1210 15:23:37.627426 15772 net.cpp:367] relu3 -> conv3 (in-place)
I1210 15:23:37.627426 15772 net.cpp:122] Setting up relu3
I1210 15:23:37.627426 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.627426 15772 net.cpp:137] Memory required for data: 374990000
I1210 15:23:37.627426 15772 layer_factory.cpp:58] Creating layer conv3_1
I1210 15:23:37.627426 15772 net.cpp:84] Creating Layer conv3_1
I1210 15:23:37.627426 15772 net.cpp:406] conv3_1 <- conv3
I1210 15:23:37.627426 15772 net.cpp:380] conv3_1 -> conv3_1
I1210 15:23:37.629415 15772 net.cpp:122] Setting up conv3_1
I1210 15:23:37.629415 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.629415 15772 net.cpp:137] Memory required for data: 380110000
I1210 15:23:37.629415 15772 layer_factory.cpp:58] Creating layer bn3_1
I1210 15:23:37.629415 15772 net.cpp:84] Creating Layer bn3_1
I1210 15:23:37.629415 15772 net.cpp:406] bn3_1 <- conv3_1
I1210 15:23:37.629415 15772 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1210 15:23:37.629415 15772 net.cpp:122] Setting up bn3_1
I1210 15:23:37.629415 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.629415 15772 net.cpp:137] Memory required for data: 385230000
I1210 15:23:37.629415 15772 layer_factory.cpp:58] Creating layer scale3_1
I1210 15:23:37.629415 15772 net.cpp:84] Creating Layer scale3_1
I1210 15:23:37.629415 15772 net.cpp:406] scale3_1 <- conv3_1
I1210 15:23:37.629415 15772 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1210 15:23:37.629415 15772 layer_factory.cpp:58] Creating layer scale3_1
I1210 15:23:37.629415 15772 net.cpp:122] Setting up scale3_1
I1210 15:23:37.629415 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.629415 15772 net.cpp:137] Memory required for data: 390350000
I1210 15:23:37.629415 15772 layer_factory.cpp:58] Creating layer relu3_1
I1210 15:23:37.629415 15772 net.cpp:84] Creating Layer relu3_1
I1210 15:23:37.629415 15772 net.cpp:406] relu3_1 <- conv3_1
I1210 15:23:37.629415 15772 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1210 15:23:37.629415 15772 net.cpp:122] Setting up relu3_1
I1210 15:23:37.629415 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.629415 15772 net.cpp:137] Memory required for data: 395470000
I1210 15:23:37.629415 15772 layer_factory.cpp:58] Creating layer conv4
I1210 15:23:37.629415 15772 net.cpp:84] Creating Layer conv4
I1210 15:23:37.629415 15772 net.cpp:406] conv4 <- conv3_1
I1210 15:23:37.629415 15772 net.cpp:380] conv4 -> conv4
I1210 15:23:37.630414 15772 net.cpp:122] Setting up conv4
I1210 15:23:37.631414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.631414 15772 net.cpp:137] Memory required for data: 400590000
I1210 15:23:37.631414 15772 layer_factory.cpp:58] Creating layer bn4
I1210 15:23:37.631414 15772 net.cpp:84] Creating Layer bn4
I1210 15:23:37.631414 15772 net.cpp:406] bn4 <- conv4
I1210 15:23:37.631414 15772 net.cpp:367] bn4 -> conv4 (in-place)
I1210 15:23:37.631414 15772 net.cpp:122] Setting up bn4
I1210 15:23:37.631414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.631414 15772 net.cpp:137] Memory required for data: 405710000
I1210 15:23:37.631414 15772 layer_factory.cpp:58] Creating layer scale4
I1210 15:23:37.631414 15772 net.cpp:84] Creating Layer scale4
I1210 15:23:37.631414 15772 net.cpp:406] scale4 <- conv4
I1210 15:23:37.631414 15772 net.cpp:367] scale4 -> conv4 (in-place)
I1210 15:23:37.631414 15772 layer_factory.cpp:58] Creating layer scale4
I1210 15:23:37.631414 15772 net.cpp:122] Setting up scale4
I1210 15:23:37.631414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.631414 15772 net.cpp:137] Memory required for data: 410830000
I1210 15:23:37.631414 15772 layer_factory.cpp:58] Creating layer relu4
I1210 15:23:37.631414 15772 net.cpp:84] Creating Layer relu4
I1210 15:23:37.631414 15772 net.cpp:406] relu4 <- conv4
I1210 15:23:37.631414 15772 net.cpp:367] relu4 -> conv4 (in-place)
I1210 15:23:37.631414 15772 net.cpp:122] Setting up relu4
I1210 15:23:37.631414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.631414 15772 net.cpp:137] Memory required for data: 415950000
I1210 15:23:37.631414 15772 layer_factory.cpp:58] Creating layer conv4_1
I1210 15:23:37.631414 15772 net.cpp:84] Creating Layer conv4_1
I1210 15:23:37.631414 15772 net.cpp:406] conv4_1 <- conv4
I1210 15:23:37.631414 15772 net.cpp:380] conv4_1 -> conv4_1
I1210 15:23:37.633414 15772 net.cpp:122] Setting up conv4_1
I1210 15:23:37.633414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.633414 15772 net.cpp:137] Memory required for data: 421070000
I1210 15:23:37.633414 15772 layer_factory.cpp:58] Creating layer bn4_1
I1210 15:23:37.633414 15772 net.cpp:84] Creating Layer bn4_1
I1210 15:23:37.633414 15772 net.cpp:406] bn4_1 <- conv4_1
I1210 15:23:37.633414 15772 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1210 15:23:37.633414 15772 net.cpp:122] Setting up bn4_1
I1210 15:23:37.633414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.633414 15772 net.cpp:137] Memory required for data: 426190000
I1210 15:23:37.633414 15772 layer_factory.cpp:58] Creating layer scale4_1
I1210 15:23:37.633414 15772 net.cpp:84] Creating Layer scale4_1
I1210 15:23:37.633414 15772 net.cpp:406] scale4_1 <- conv4_1
I1210 15:23:37.633414 15772 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1210 15:23:37.633414 15772 layer_factory.cpp:58] Creating layer scale4_1
I1210 15:23:37.633414 15772 net.cpp:122] Setting up scale4_1
I1210 15:23:37.633414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.633414 15772 net.cpp:137] Memory required for data: 431310000
I1210 15:23:37.633414 15772 layer_factory.cpp:58] Creating layer relu4_1
I1210 15:23:37.633414 15772 net.cpp:84] Creating Layer relu4_1
I1210 15:23:37.633414 15772 net.cpp:406] relu4_1 <- conv4_1
I1210 15:23:37.633414 15772 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1210 15:23:37.633414 15772 net.cpp:122] Setting up relu4_1
I1210 15:23:37.633414 15772 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 15:23:37.633414 15772 net.cpp:137] Memory required for data: 436430000
I1210 15:23:37.633414 15772 layer_factory.cpp:58] Creating layer conv4_2
I1210 15:23:37.633414 15772 net.cpp:84] Creating Layer conv4_2
I1210 15:23:37.633414 15772 net.cpp:406] conv4_2 <- conv4_1
I1210 15:23:37.633414 15772 net.cpp:380] conv4_2 -> conv4_2
I1210 15:23:37.635414 15772 net.cpp:122] Setting up conv4_2
I1210 15:23:37.635414 15772 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 15:23:37.635414 15772 net.cpp:137] Memory required for data: 442369200
I1210 15:23:37.635414 15772 layer_factory.cpp:58] Creating layer bn4_2
I1210 15:23:37.635414 15772 net.cpp:84] Creating Layer bn4_2
I1210 15:23:37.635414 15772 net.cpp:406] bn4_2 <- conv4_2
I1210 15:23:37.635414 15772 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1210 15:23:37.636415 15772 net.cpp:122] Setting up bn4_2
I1210 15:23:37.636415 15772 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 15:23:37.636415 15772 net.cpp:137] Memory required for data: 448308400
I1210 15:23:37.636415 15772 layer_factory.cpp:58] Creating layer scale4_2
I1210 15:23:37.636415 15772 net.cpp:84] Creating Layer scale4_2
I1210 15:23:37.636415 15772 net.cpp:406] scale4_2 <- conv4_2
I1210 15:23:37.636415 15772 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1210 15:23:37.636415 15772 layer_factory.cpp:58] Creating layer scale4_2
I1210 15:23:37.636415 15772 net.cpp:122] Setting up scale4_2
I1210 15:23:37.636415 15772 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 15:23:37.636415 15772 net.cpp:137] Memory required for data: 454247600
I1210 15:23:37.636415 15772 layer_factory.cpp:58] Creating layer relu4_2
I1210 15:23:37.636415 15772 net.cpp:84] Creating Layer relu4_2
I1210 15:23:37.636415 15772 net.cpp:406] relu4_2 <- conv4_2
I1210 15:23:37.636415 15772 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1210 15:23:37.637416 15772 net.cpp:122] Setting up relu4_2
I1210 15:23:37.637416 15772 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 15:23:37.637416 15772 net.cpp:137] Memory required for data: 460186800
I1210 15:23:37.637416 15772 layer_factory.cpp:58] Creating layer added_new_conv2
I1210 15:23:37.637416 15772 net.cpp:84] Creating Layer added_new_conv2
I1210 15:23:37.637416 15772 net.cpp:406] added_new_conv2 <- conv4_2
I1210 15:23:37.637416 15772 net.cpp:380] added_new_conv2 -> added_new_conv2
I1210 15:23:37.638414 15772 net.cpp:122] Setting up added_new_conv2
I1210 15:23:37.638414 15772 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 15:23:37.638414 15772 net.cpp:137] Memory required for data: 466126000
I1210 15:23:37.638414 15772 layer_factory.cpp:58] Creating layer pool4_2
I1210 15:23:37.638414 15772 net.cpp:84] Creating Layer pool4_2
I1210 15:23:37.638414 15772 net.cpp:406] pool4_2 <- added_new_conv2
I1210 15:23:37.638414 15772 net.cpp:380] pool4_2 -> pool4_2
I1210 15:23:37.638414 15772 net.cpp:122] Setting up pool4_2
I1210 15:23:37.638414 15772 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 15:23:37.638414 15772 net.cpp:137] Memory required for data: 467610800
I1210 15:23:37.638414 15772 layer_factory.cpp:58] Creating layer conv4_0
I1210 15:23:37.638414 15772 net.cpp:84] Creating Layer conv4_0
I1210 15:23:37.638414 15772 net.cpp:406] conv4_0 <- pool4_2
I1210 15:23:37.638414 15772 net.cpp:380] conv4_0 -> conv4_0
I1210 15:23:37.640413 15772 net.cpp:122] Setting up conv4_0
I1210 15:23:37.640413 15772 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 15:23:37.640413 15772 net.cpp:137] Memory required for data: 469095600
I1210 15:23:37.640413 15772 layer_factory.cpp:58] Creating layer bn4_0
I1210 15:23:37.640413 15772 net.cpp:84] Creating Layer bn4_0
I1210 15:23:37.640413 15772 net.cpp:406] bn4_0 <- conv4_0
I1210 15:23:37.640413 15772 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1210 15:23:37.641414 15772 net.cpp:122] Setting up bn4_0
I1210 15:23:37.641414 15772 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 15:23:37.641414 15772 net.cpp:137] Memory required for data: 470580400
I1210 15:23:37.641414 15772 layer_factory.cpp:58] Creating layer scale4_0
I1210 15:23:37.641414 15772 net.cpp:84] Creating Layer scale4_0
I1210 15:23:37.641414 15772 net.cpp:406] scale4_0 <- conv4_0
I1210 15:23:37.641414 15772 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1210 15:23:37.641414 15772 layer_factory.cpp:58] Creating layer scale4_0
I1210 15:23:37.641414 15772 net.cpp:122] Setting up scale4_0
I1210 15:23:37.641414 15772 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 15:23:37.641414 15772 net.cpp:137] Memory required for data: 472065200
I1210 15:23:37.641414 15772 layer_factory.cpp:58] Creating layer relu4_0
I1210 15:23:37.641414 15772 net.cpp:84] Creating Layer relu4_0
I1210 15:23:37.641414 15772 net.cpp:406] relu4_0 <- conv4_0
I1210 15:23:37.641414 15772 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1210 15:23:37.641414 15772 net.cpp:122] Setting up relu4_0
I1210 15:23:37.641414 15772 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 15:23:37.641414 15772 net.cpp:137] Memory required for data: 473550000
I1210 15:23:37.641414 15772 layer_factory.cpp:58] Creating layer conv11
I1210 15:23:37.641414 15772 net.cpp:84] Creating Layer conv11
I1210 15:23:37.641414 15772 net.cpp:406] conv11 <- conv4_0
I1210 15:23:37.641414 15772 net.cpp:380] conv11 -> conv11
I1210 15:23:37.643414 15772 net.cpp:122] Setting up conv11
I1210 15:23:37.643414 15772 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 15:23:37.643414 15772 net.cpp:137] Memory required for data: 475342000
I1210 15:23:37.643414 15772 layer_factory.cpp:58] Creating layer bn_conv11
I1210 15:23:37.643414 15772 net.cpp:84] Creating Layer bn_conv11
I1210 15:23:37.643414 15772 net.cpp:406] bn_conv11 <- conv11
I1210 15:23:37.643414 15772 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1210 15:23:37.643414 15772 net.cpp:122] Setting up bn_conv11
I1210 15:23:37.643414 15772 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 15:23:37.643414 15772 net.cpp:137] Memory required for data: 477134000
I1210 15:23:37.643414 15772 layer_factory.cpp:58] Creating layer scale_conv11
I1210 15:23:37.643414 15772 net.cpp:84] Creating Layer scale_conv11
I1210 15:23:37.643414 15772 net.cpp:406] scale_conv11 <- conv11
I1210 15:23:37.643414 15772 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1210 15:23:37.643414 15772 layer_factory.cpp:58] Creating layer scale_conv11
I1210 15:23:37.643414 15772 net.cpp:122] Setting up scale_conv11
I1210 15:23:37.643414 15772 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 15:23:37.643414 15772 net.cpp:137] Memory required for data: 478926000
I1210 15:23:37.643414 15772 layer_factory.cpp:58] Creating layer relu_conv11
I1210 15:23:37.643414 15772 net.cpp:84] Creating Layer relu_conv11
I1210 15:23:37.643414 15772 net.cpp:406] relu_conv11 <- conv11
I1210 15:23:37.643414 15772 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1210 15:23:37.644414 15772 net.cpp:122] Setting up relu_conv11
I1210 15:23:37.644414 15772 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 15:23:37.644414 15772 net.cpp:137] Memory required for data: 480718000
I1210 15:23:37.644414 15772 layer_factory.cpp:58] Creating layer conv12
I1210 15:23:37.644414 15772 net.cpp:84] Creating Layer conv12
I1210 15:23:37.644414 15772 net.cpp:406] conv12 <- conv11
I1210 15:23:37.644414 15772 net.cpp:380] conv12 -> conv12
I1210 15:23:37.645414 15772 net.cpp:122] Setting up conv12
I1210 15:23:37.645414 15772 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 15:23:37.645414 15772 net.cpp:137] Memory required for data: 483022000
I1210 15:23:37.645414 15772 layer_factory.cpp:58] Creating layer bn_conv12
I1210 15:23:37.645414 15772 net.cpp:84] Creating Layer bn_conv12
I1210 15:23:37.645414 15772 net.cpp:406] bn_conv12 <- conv12
I1210 15:23:37.645414 15772 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1210 15:23:37.646414 15772 net.cpp:122] Setting up bn_conv12
I1210 15:23:37.646414 15772 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 15:23:37.646414 15772 net.cpp:137] Memory required for data: 485326000
I1210 15:23:37.646414 15772 layer_factory.cpp:58] Creating layer scale_conv12
I1210 15:23:37.646414 15772 net.cpp:84] Creating Layer scale_conv12
I1210 15:23:37.646414 15772 net.cpp:406] scale_conv12 <- conv12
I1210 15:23:37.646414 15772 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1210 15:23:37.646414 15772 layer_factory.cpp:58] Creating layer scale_conv12
I1210 15:23:37.646414 15772 net.cpp:122] Setting up scale_conv12
I1210 15:23:37.646414 15772 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 15:23:37.646414 15772 net.cpp:137] Memory required for data: 487630000
I1210 15:23:37.646414 15772 layer_factory.cpp:58] Creating layer relu_conv12
I1210 15:23:37.646414 15772 net.cpp:84] Creating Layer relu_conv12
I1210 15:23:37.646414 15772 net.cpp:406] relu_conv12 <- conv12
I1210 15:23:37.646414 15772 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1210 15:23:37.646414 15772 net.cpp:122] Setting up relu_conv12
I1210 15:23:37.646414 15772 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 15:23:37.646414 15772 net.cpp:137] Memory required for data: 489934000
I1210 15:23:37.646414 15772 layer_factory.cpp:58] Creating layer poolcp6
I1210 15:23:37.646414 15772 net.cpp:84] Creating Layer poolcp6
I1210 15:23:37.646414 15772 net.cpp:406] poolcp6 <- conv12
I1210 15:23:37.646414 15772 net.cpp:380] poolcp6 -> poolcp6
I1210 15:23:37.646414 15772 net.cpp:122] Setting up poolcp6
I1210 15:23:37.646414 15772 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1210 15:23:37.646414 15772 net.cpp:137] Memory required for data: 489970000
I1210 15:23:37.646414 15772 layer_factory.cpp:58] Creating layer ip1
I1210 15:23:37.646414 15772 net.cpp:84] Creating Layer ip1
I1210 15:23:37.646414 15772 net.cpp:406] ip1 <- poolcp6
I1210 15:23:37.646414 15772 net.cpp:380] ip1 -> ip1
I1210 15:23:37.646414 15772 net.cpp:122] Setting up ip1
I1210 15:23:37.646414 15772 net.cpp:129] Top shape: 100 100 (10000)
I1210 15:23:37.646414 15772 net.cpp:137] Memory required for data: 490010000
I1210 15:23:37.646414 15772 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1210 15:23:37.646414 15772 net.cpp:84] Creating Layer ip1_ip1_0_split
I1210 15:23:37.646414 15772 net.cpp:406] ip1_ip1_0_split <- ip1
I1210 15:23:37.646414 15772 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1210 15:23:37.646414 15772 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1210 15:23:37.646414 15772 net.cpp:122] Setting up ip1_ip1_0_split
I1210 15:23:37.646414 15772 net.cpp:129] Top shape: 100 100 (10000)
I1210 15:23:37.646414 15772 net.cpp:129] Top shape: 100 100 (10000)
I1210 15:23:37.646414 15772 net.cpp:137] Memory required for data: 490090000
I1210 15:23:37.646414 15772 layer_factory.cpp:58] Creating layer accuracy
I1210 15:23:37.646414 15772 net.cpp:84] Creating Layer accuracy
I1210 15:23:37.646414 15772 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1210 15:23:37.646414 15772 net.cpp:406] accuracy <- label_cifar_1_split_0
I1210 15:23:37.646414 15772 net.cpp:380] accuracy -> accuracy
I1210 15:23:37.646414 15772 net.cpp:122] Setting up accuracy
I1210 15:23:37.646414 15772 net.cpp:129] Top shape: (1)
I1210 15:23:37.647414 15772 net.cpp:137] Memory required for data: 490090004
I1210 15:23:37.647414 15772 layer_factory.cpp:58] Creating layer loss
I1210 15:23:37.647414 15772 net.cpp:84] Creating Layer loss
I1210 15:23:37.647414 15772 net.cpp:406] loss <- ip1_ip1_0_split_1
I1210 15:23:37.647414 15772 net.cpp:406] loss <- label_cifar_1_split_1
I1210 15:23:37.647414 15772 net.cpp:380] loss -> loss
I1210 15:23:37.647414 15772 layer_factory.cpp:58] Creating layer loss
I1210 15:23:37.647414 15772 net.cpp:122] Setting up loss
I1210 15:23:37.647414 15772 net.cpp:129] Top shape: (1)
I1210 15:23:37.647414 15772 net.cpp:132]     with loss weight 1
I1210 15:23:37.647414 15772 net.cpp:137] Memory required for data: 490090008
I1210 15:23:37.647414 15772 net.cpp:198] loss needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:200] accuracy does not need backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] ip1 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] poolcp6 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] relu_conv12 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] scale_conv12 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] bn_conv12 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] conv12 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] relu_conv11 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] scale_conv11 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] bn_conv11 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] conv11 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] relu4_0 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] scale4_0 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] bn4_0 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] conv4_0 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] pool4_2 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] added_new_conv2 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] relu4_2 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] scale4_2 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] bn4_2 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] conv4_2 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] relu4_1 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] scale4_1 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] bn4_1 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] conv4_1 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] relu4 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] scale4 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] bn4 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] conv4 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] relu3_1 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] scale3_1 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] bn3_1 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] conv3_1 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] relu3 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] scale3 needs backward computation.
I1210 15:23:37.647414 15772 net.cpp:198] bn3 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] conv3 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] pool2_1 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] newconv_added1 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] relu2_2 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] scale2_2 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] bn2_2 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] conv2_2 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] relu2_1 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] scale2_1 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] bn2_1 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] conv2_1 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] relu2 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] scale2 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] bn2 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] conv2 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] relu1_0 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] scale1_0 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] bn1_0 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] conv1_0 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] relu1 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] scale1 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] bn1 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:198] conv1 needs backward computation.
I1210 15:23:37.648416 15772 net.cpp:200] label_cifar_1_split does not need backward computation.
I1210 15:23:37.648416 15772 net.cpp:200] cifar does not need backward computation.
I1210 15:23:37.648416 15772 net.cpp:242] This network produces output accuracy
I1210 15:23:37.648416 15772 net.cpp:242] This network produces output loss
I1210 15:23:37.648416 15772 net.cpp:255] Network initialization done.
I1210 15:23:37.648416 15772 solver.cpp:56] Solver scaffolding done.
I1210 15:23:37.653421 15772 caffe.cpp:249] Starting Optimization
I1210 15:23:37.653421 15772 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_v2_360k
I1210 15:23:37.653421 15772 solver.cpp:273] Learning Rate Policy: multistep
I1210 15:23:37.656421 15772 solver.cpp:330] Iteration 0, Testing net (#0)
I1210 15:23:37.658424 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:23:39.091552 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:23:39.145552 15772 solver.cpp:397]     Test net output #0: accuracy = 0.0103
I1210 15:23:39.145552 15772 solver.cpp:397]     Test net output #1: loss = 86.437 (* 1 = 86.437 loss)
I1210 15:23:39.250064 15772 solver.cpp:218] Iteration 0 (-nan iter/s, 1.59556s/100 iters), loss = 6.48243
I1210 15:23:39.250567 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.02
I1210 15:23:39.250567 15772 solver.cpp:237]     Train net output #1: loss = 6.48243 (* 1 = 6.48243 loss)
I1210 15:23:39.250567 15772 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1210 15:23:44.871052 15772 solver.cpp:218] Iteration 100 (17.7911 iter/s, 5.62078s/100 iters), loss = 4.38872
I1210 15:23:44.871052 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.02
I1210 15:23:44.871052 15772 solver.cpp:237]     Train net output #1: loss = 4.38872 (* 1 = 4.38872 loss)
I1210 15:23:44.871052 15772 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1210 15:23:50.513567 15772 solver.cpp:218] Iteration 200 (17.724 iter/s, 5.64207s/100 iters), loss = 4.31282
I1210 15:23:50.513567 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.06
I1210 15:23:50.513567 15772 solver.cpp:237]     Train net output #1: loss = 4.31282 (* 1 = 4.31282 loss)
I1210 15:23:50.514569 15772 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1210 15:23:56.119076 15772 solver.cpp:218] Iteration 300 (17.8431 iter/s, 5.60441s/100 iters), loss = 4.2085
I1210 15:23:56.119076 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.04
I1210 15:23:56.119076 15772 solver.cpp:237]     Train net output #1: loss = 4.2085 (* 1 = 4.2085 loss)
I1210 15:23:56.119076 15772 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1210 15:24:01.727592 15772 solver.cpp:218] Iteration 400 (17.8313 iter/s, 5.60811s/100 iters), loss = 4.30355
I1210 15:24:01.727592 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.03
I1210 15:24:01.727592 15772 solver.cpp:237]     Train net output #1: loss = 4.30355 (* 1 = 4.30355 loss)
I1210 15:24:01.727592 15772 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1210 15:24:07.047142 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:24:07.269173 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_500.caffemodel
I1210 15:24:07.292174 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_500.solverstate
I1210 15:24:07.297175 15772 solver.cpp:330] Iteration 500, Testing net (#0)
I1210 15:24:07.297175 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:24:08.669276 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:24:08.724285 15772 solver.cpp:397]     Test net output #0: accuracy = 0.0508
I1210 15:24:08.724285 15772 solver.cpp:397]     Test net output #1: loss = 4.28309 (* 1 = 4.28309 loss)
I1210 15:24:08.778283 15772 solver.cpp:218] Iteration 500 (14.183 iter/s, 7.05068s/100 iters), loss = 3.96356
I1210 15:24:08.778283 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I1210 15:24:08.778283 15772 solver.cpp:237]     Train net output #1: loss = 3.96356 (* 1 = 3.96356 loss)
I1210 15:24:08.778283 15772 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1210 15:24:14.386214 15772 solver.cpp:218] Iteration 600 (17.8333 iter/s, 5.6075s/100 iters), loss = 3.8586
I1210 15:24:14.386214 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.02
I1210 15:24:14.386214 15772 solver.cpp:237]     Train net output #1: loss = 3.8586 (* 1 = 3.8586 loss)
I1210 15:24:14.386214 15772 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1210 15:24:19.985589 15772 solver.cpp:218] Iteration 700 (17.8627 iter/s, 5.59827s/100 iters), loss = 3.6776
I1210 15:24:19.985589 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I1210 15:24:19.985589 15772 solver.cpp:237]     Train net output #1: loss = 3.6776 (* 1 = 3.6776 loss)
I1210 15:24:19.985589 15772 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1210 15:24:25.581990 15772 solver.cpp:218] Iteration 800 (17.8701 iter/s, 5.59594s/100 iters), loss = 3.6435
I1210 15:24:25.581990 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.13
I1210 15:24:25.581990 15772 solver.cpp:237]     Train net output #1: loss = 3.6435 (* 1 = 3.6435 loss)
I1210 15:24:25.581990 15772 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1210 15:24:31.213778 15772 solver.cpp:218] Iteration 900 (17.758 iter/s, 5.63128s/100 iters), loss = 3.81345
I1210 15:24:31.213778 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.1
I1210 15:24:31.213778 15772 solver.cpp:237]     Train net output #1: loss = 3.81345 (* 1 = 3.81345 loss)
I1210 15:24:31.213778 15772 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1210 15:24:36.544813 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:24:36.764832 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_1000.caffemodel
I1210 15:24:36.782831 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_1000.solverstate
I1210 15:24:36.786833 15772 solver.cpp:330] Iteration 1000, Testing net (#0)
I1210 15:24:36.786833 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:24:38.155972 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:24:38.209477 15772 solver.cpp:397]     Test net output #0: accuracy = 0.0649
I1210 15:24:38.209477 15772 solver.cpp:397]     Test net output #1: loss = 4.16606 (* 1 = 4.16606 loss)
I1210 15:24:38.262984 15772 solver.cpp:218] Iteration 1000 (14.1863 iter/s, 7.04908s/100 iters), loss = 3.6222
I1210 15:24:38.262984 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.15
I1210 15:24:38.262984 15772 solver.cpp:237]     Train net output #1: loss = 3.6222 (* 1 = 3.6222 loss)
I1210 15:24:38.262984 15772 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1210 15:24:44.021546 15772 solver.cpp:218] Iteration 1100 (17.3669 iter/s, 5.75808s/100 iters), loss = 3.48845
I1210 15:24:44.021546 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.14
I1210 15:24:44.021546 15772 solver.cpp:237]     Train net output #1: loss = 3.48845 (* 1 = 3.48845 loss)
I1210 15:24:44.022047 15772 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1210 15:24:49.796406 15772 solver.cpp:218] Iteration 1200 (17.3205 iter/s, 5.77352s/100 iters), loss = 3.32372
I1210 15:24:49.796406 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.19
I1210 15:24:49.796406 15772 solver.cpp:237]     Train net output #1: loss = 3.32372 (* 1 = 3.32372 loss)
I1210 15:24:49.796406 15772 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1210 15:24:55.465962 15772 solver.cpp:218] Iteration 1300 (17.6384 iter/s, 5.66946s/100 iters), loss = 3.4075
I1210 15:24:55.465962 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.15
I1210 15:24:55.465962 15772 solver.cpp:237]     Train net output #1: loss = 3.4075 (* 1 = 3.4075 loss)
I1210 15:24:55.465962 15772 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1210 15:25:01.180236 15772 solver.cpp:218] Iteration 1400 (17.5021 iter/s, 5.7136s/100 iters), loss = 3.40709
I1210 15:25:01.180236 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.16
I1210 15:25:01.180236 15772 solver.cpp:237]     Train net output #1: loss = 3.40709 (* 1 = 3.40709 loss)
I1210 15:25:01.180236 15772 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1210 15:25:06.576531 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:25:06.799618 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_1500.caffemodel
I1210 15:25:06.813619 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_1500.solverstate
I1210 15:25:06.818614 15772 solver.cpp:330] Iteration 1500, Testing net (#0)
I1210 15:25:06.818614 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:25:08.197120 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:25:08.251194 15772 solver.cpp:397]     Test net output #0: accuracy = 0.1146
I1210 15:25:08.251194 15772 solver.cpp:397]     Test net output #1: loss = 3.90896 (* 1 = 3.90896 loss)
I1210 15:25:08.305176 15772 solver.cpp:218] Iteration 1500 (14.0357 iter/s, 7.1247s/100 iters), loss = 3.02341
I1210 15:25:08.305176 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.28
I1210 15:25:08.305176 15772 solver.cpp:237]     Train net output #1: loss = 3.02341 (* 1 = 3.02341 loss)
I1210 15:25:08.305176 15772 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1210 15:25:13.960512 15772 solver.cpp:218] Iteration 1600 (17.6835 iter/s, 5.655s/100 iters), loss = 3.14893
I1210 15:25:13.960512 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.22
I1210 15:25:13.960512 15772 solver.cpp:237]     Train net output #1: loss = 3.14893 (* 1 = 3.14893 loss)
I1210 15:25:13.960512 15772 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1210 15:25:19.611812 15772 solver.cpp:218] Iteration 1700 (17.6992 iter/s, 5.64998s/100 iters), loss = 3.03514
I1210 15:25:19.611812 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.22
I1210 15:25:19.611812 15772 solver.cpp:237]     Train net output #1: loss = 3.03514 (* 1 = 3.03514 loss)
I1210 15:25:19.611812 15772 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1210 15:25:25.290307 15772 solver.cpp:218] Iteration 1800 (17.6113 iter/s, 5.67818s/100 iters), loss = 3.16276
I1210 15:25:25.290307 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.23
I1210 15:25:25.290307 15772 solver.cpp:237]     Train net output #1: loss = 3.16276 (* 1 = 3.16276 loss)
I1210 15:25:25.290307 15772 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1210 15:25:30.972754 15772 solver.cpp:218] Iteration 1900 (17.5984 iter/s, 5.68233s/100 iters), loss = 3.26749
I1210 15:25:30.972754 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.2
I1210 15:25:30.972754 15772 solver.cpp:237]     Train net output #1: loss = 3.26749 (* 1 = 3.26749 loss)
I1210 15:25:30.972754 15772 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1210 15:25:36.352392 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:25:36.577051 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_2000.caffemodel
I1210 15:25:36.592072 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_2000.solverstate
I1210 15:25:36.597051 15772 solver.cpp:330] Iteration 2000, Testing net (#0)
I1210 15:25:36.597051 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:25:37.968844 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:25:38.022827 15772 solver.cpp:397]     Test net output #0: accuracy = 0.1193
I1210 15:25:38.022827 15772 solver.cpp:397]     Test net output #1: loss = 4.12338 (* 1 = 4.12338 loss)
I1210 15:25:38.076853 15772 solver.cpp:218] Iteration 2000 (14.0789 iter/s, 7.10281s/100 iters), loss = 2.79221
I1210 15:25:38.076853 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.26
I1210 15:25:38.076853 15772 solver.cpp:237]     Train net output #1: loss = 2.79221 (* 1 = 2.79221 loss)
I1210 15:25:38.076853 15772 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1210 15:25:43.767911 15772 solver.cpp:218] Iteration 2100 (17.5707 iter/s, 5.6913s/100 iters), loss = 2.89655
I1210 15:25:43.767911 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1210 15:25:43.767911 15772 solver.cpp:237]     Train net output #1: loss = 2.89655 (* 1 = 2.89655 loss)
I1210 15:25:43.767911 15772 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1210 15:25:49.433120 15772 solver.cpp:218] Iteration 2200 (17.6554 iter/s, 5.664s/100 iters), loss = 2.73633
I1210 15:25:49.433120 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.24
I1210 15:25:49.433120 15772 solver.cpp:237]     Train net output #1: loss = 2.73633 (* 1 = 2.73633 loss)
I1210 15:25:49.433120 15772 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1210 15:25:55.100949 15772 solver.cpp:218] Iteration 2300 (17.643 iter/s, 5.66798s/100 iters), loss = 2.92216
I1210 15:25:55.100949 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.24
I1210 15:25:55.100949 15772 solver.cpp:237]     Train net output #1: loss = 2.92216 (* 1 = 2.92216 loss)
I1210 15:25:55.100949 15772 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1210 15:26:00.821748 15772 solver.cpp:218] Iteration 2400 (17.4828 iter/s, 5.7199s/100 iters), loss = 2.84599
I1210 15:26:00.821748 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.26
I1210 15:26:00.821748 15772 solver.cpp:237]     Train net output #1: loss = 2.84599 (* 1 = 2.84599 loss)
I1210 15:26:00.821748 15772 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1210 15:26:06.235296 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:26:06.458811 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_2500.caffemodel
I1210 15:26:06.474316 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_2500.solverstate
I1210 15:26:06.479316 15772 solver.cpp:330] Iteration 2500, Testing net (#0)
I1210 15:26:06.479316 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:26:07.855444 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:26:07.908450 15772 solver.cpp:397]     Test net output #0: accuracy = 0.1535
I1210 15:26:07.908450 15772 solver.cpp:397]     Test net output #1: loss = 3.61696 (* 1 = 3.61696 loss)
I1210 15:26:07.962951 15772 solver.cpp:218] Iteration 2500 (14.0042 iter/s, 7.14073s/100 iters), loss = 2.57631
I1210 15:26:07.962951 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.32
I1210 15:26:07.962951 15772 solver.cpp:237]     Train net output #1: loss = 2.57631 (* 1 = 2.57631 loss)
I1210 15:26:07.962951 15772 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1210 15:26:13.626955 15772 solver.cpp:218] Iteration 2600 (17.6551 iter/s, 5.66409s/100 iters), loss = 2.65032
I1210 15:26:13.626955 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1210 15:26:13.626955 15772 solver.cpp:237]     Train net output #1: loss = 2.65032 (* 1 = 2.65032 loss)
I1210 15:26:13.626955 15772 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1210 15:26:19.307807 15772 solver.cpp:218] Iteration 2700 (17.6058 iter/s, 5.67994s/100 iters), loss = 2.39415
I1210 15:26:19.307807 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1210 15:26:19.307807 15772 solver.cpp:237]     Train net output #1: loss = 2.39415 (* 1 = 2.39415 loss)
I1210 15:26:19.307807 15772 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1210 15:26:24.972299 15772 solver.cpp:218] Iteration 2800 (17.6539 iter/s, 5.66446s/100 iters), loss = 2.74427
I1210 15:26:24.972299 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1210 15:26:24.972299 15772 solver.cpp:237]     Train net output #1: loss = 2.74427 (* 1 = 2.74427 loss)
I1210 15:26:24.972299 15772 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1210 15:26:30.640810 15772 solver.cpp:218] Iteration 2900 (17.645 iter/s, 5.66733s/100 iters), loss = 2.67818
I1210 15:26:30.640810 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.28
I1210 15:26:30.640810 15772 solver.cpp:237]     Train net output #1: loss = 2.67818 (* 1 = 2.67818 loss)
I1210 15:26:30.640810 15772 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1210 15:26:36.035377 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:26:36.257385 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_3000.caffemodel
I1210 15:26:36.276386 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_3000.solverstate
I1210 15:26:36.281385 15772 solver.cpp:330] Iteration 3000, Testing net (#0)
I1210 15:26:36.281385 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:26:37.660524 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:26:37.713522 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2619
I1210 15:26:37.713522 15772 solver.cpp:397]     Test net output #1: loss = 2.88201 (* 1 = 2.88201 loss)
I1210 15:26:37.767534 15772 solver.cpp:218] Iteration 3000 (14.0318 iter/s, 7.12666s/100 iters), loss = 2.55956
I1210 15:26:37.767534 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1210 15:26:37.767534 15772 solver.cpp:237]     Train net output #1: loss = 2.55956 (* 1 = 2.55956 loss)
I1210 15:26:37.767534 15772 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1210 15:26:43.496292 15772 solver.cpp:218] Iteration 3100 (17.4572 iter/s, 5.72828s/100 iters), loss = 2.55556
I1210 15:26:43.496292 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.32
I1210 15:26:43.496292 15772 solver.cpp:237]     Train net output #1: loss = 2.55556 (* 1 = 2.55556 loss)
I1210 15:26:43.496292 15772 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1210 15:26:49.204390 15772 solver.cpp:218] Iteration 3200 (17.5221 iter/s, 5.70708s/100 iters), loss = 2.19637
I1210 15:26:49.204390 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 15:26:49.204390 15772 solver.cpp:237]     Train net output #1: loss = 2.19637 (* 1 = 2.19637 loss)
I1210 15:26:49.204390 15772 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1210 15:26:54.870896 15772 solver.cpp:218] Iteration 3300 (17.6475 iter/s, 5.66651s/100 iters), loss = 2.48573
I1210 15:26:54.870896 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1210 15:26:54.870896 15772 solver.cpp:237]     Train net output #1: loss = 2.48573 (* 1 = 2.48573 loss)
I1210 15:26:54.870896 15772 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1210 15:27:00.534709 15772 solver.cpp:218] Iteration 3400 (17.6593 iter/s, 5.66273s/100 iters), loss = 2.56514
I1210 15:27:00.534709 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1210 15:27:00.534709 15772 solver.cpp:237]     Train net output #1: loss = 2.56514 (* 1 = 2.56514 loss)
I1210 15:27:00.534709 15772 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1210 15:27:05.912921 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:27:06.137449 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_3500.caffemodel
I1210 15:27:06.151952 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_3500.solverstate
I1210 15:27:06.156952 15772 solver.cpp:330] Iteration 3500, Testing net (#0)
I1210 15:27:06.156952 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:27:07.529065 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:27:07.584069 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3122
I1210 15:27:07.584069 15772 solver.cpp:397]     Test net output #1: loss = 2.64669 (* 1 = 2.64669 loss)
I1210 15:27:07.638070 15772 solver.cpp:218] Iteration 3500 (14.0788 iter/s, 7.10287s/100 iters), loss = 2.35419
I1210 15:27:07.638070 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1210 15:27:07.638070 15772 solver.cpp:237]     Train net output #1: loss = 2.35419 (* 1 = 2.35419 loss)
I1210 15:27:07.638070 15772 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1210 15:27:13.291620 15772 solver.cpp:218] Iteration 3600 (17.6894 iter/s, 5.65311s/100 iters), loss = 2.35253
I1210 15:27:13.291620 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1210 15:27:13.291620 15772 solver.cpp:237]     Train net output #1: loss = 2.35253 (* 1 = 2.35253 loss)
I1210 15:27:13.291620 15772 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1210 15:27:18.986294 15772 solver.cpp:218] Iteration 3700 (17.5596 iter/s, 5.6949s/100 iters), loss = 2.03601
I1210 15:27:18.986294 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:27:18.986294 15772 solver.cpp:237]     Train net output #1: loss = 2.03601 (* 1 = 2.03601 loss)
I1210 15:27:18.986294 15772 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1210 15:27:24.689494 15772 solver.cpp:218] Iteration 3800 (17.5372 iter/s, 5.70217s/100 iters), loss = 2.49709
I1210 15:27:24.689494 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1210 15:27:24.689494 15772 solver.cpp:237]     Train net output #1: loss = 2.49709 (* 1 = 2.49709 loss)
I1210 15:27:24.689494 15772 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1210 15:27:30.375627 15772 solver.cpp:218] Iteration 3900 (17.5884 iter/s, 5.68556s/100 iters), loss = 2.42468
I1210 15:27:30.375627 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1210 15:27:30.375627 15772 solver.cpp:237]     Train net output #1: loss = 2.42468 (* 1 = 2.42468 loss)
I1210 15:27:30.375627 15772 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1210 15:27:35.781123 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:27:36.005133 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_4000.caffemodel
I1210 15:27:36.027138 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_4000.solverstate
I1210 15:27:36.032150 15772 solver.cpp:330] Iteration 4000, Testing net (#0)
I1210 15:27:36.032649 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:27:37.416265 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:27:37.470283 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3135
I1210 15:27:37.470283 15772 solver.cpp:397]     Test net output #1: loss = 2.66264 (* 1 = 2.66264 loss)
I1210 15:27:37.525282 15772 solver.cpp:218] Iteration 4000 (13.9876 iter/s, 7.14918s/100 iters), loss = 2.37142
I1210 15:27:37.525282 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1210 15:27:37.525282 15772 solver.cpp:237]     Train net output #1: loss = 2.37142 (* 1 = 2.37142 loss)
I1210 15:27:37.525282 15772 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1210 15:27:43.205847 15772 solver.cpp:218] Iteration 4100 (17.604 iter/s, 5.68051s/100 iters), loss = 2.24166
I1210 15:27:43.205847 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1210 15:27:43.205847 15772 solver.cpp:237]     Train net output #1: loss = 2.24166 (* 1 = 2.24166 loss)
I1210 15:27:43.205847 15772 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1210 15:27:48.888602 15772 solver.cpp:218] Iteration 4200 (17.5994 iter/s, 5.68201s/100 iters), loss = 1.91934
I1210 15:27:48.888602 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:27:48.888602 15772 solver.cpp:237]     Train net output #1: loss = 1.91934 (* 1 = 1.91934 loss)
I1210 15:27:48.888602 15772 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1210 15:27:54.577456 15772 solver.cpp:218] Iteration 4300 (17.5797 iter/s, 5.68838s/100 iters), loss = 2.27319
I1210 15:27:54.577456 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 15:27:54.577456 15772 solver.cpp:237]     Train net output #1: loss = 2.27319 (* 1 = 2.27319 loss)
I1210 15:27:54.577456 15772 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1210 15:28:00.260057 15772 solver.cpp:218] Iteration 4400 (17.5969 iter/s, 5.68281s/100 iters), loss = 2.43767
I1210 15:28:00.261044 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1210 15:28:00.261044 15772 solver.cpp:237]     Train net output #1: loss = 2.43767 (* 1 = 2.43767 loss)
I1210 15:28:00.261044 15772 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1210 15:28:05.632870 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:28:05.855900 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_4500.caffemodel
I1210 15:28:05.869899 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_4500.solverstate
I1210 15:28:05.874900 15772 solver.cpp:330] Iteration 4500, Testing net (#0)
I1210 15:28:05.874900 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:28:07.250262 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:28:07.303266 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3047
I1210 15:28:07.303266 15772 solver.cpp:397]     Test net output #1: loss = 2.7561 (* 1 = 2.7561 loss)
I1210 15:28:07.357272 15772 solver.cpp:218] Iteration 4500 (14.0914 iter/s, 7.09654s/100 iters), loss = 2.2287
I1210 15:28:07.357272 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1210 15:28:07.357272 15772 solver.cpp:237]     Train net output #1: loss = 2.2287 (* 1 = 2.2287 loss)
I1210 15:28:07.357272 15772 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1210 15:28:13.048473 15772 solver.cpp:218] Iteration 4600 (17.5739 iter/s, 5.69025s/100 iters), loss = 2.17342
I1210 15:28:13.048473 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1210 15:28:13.048473 15772 solver.cpp:237]     Train net output #1: loss = 2.17342 (* 1 = 2.17342 loss)
I1210 15:28:13.048473 15772 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1210 15:28:18.716553 15772 solver.cpp:218] Iteration 4700 (17.6427 iter/s, 5.66805s/100 iters), loss = 1.97976
I1210 15:28:18.716553 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:28:18.716553 15772 solver.cpp:237]     Train net output #1: loss = 1.97976 (* 1 = 1.97976 loss)
I1210 15:28:18.716553 15772 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1210 15:28:24.386093 15772 solver.cpp:218] Iteration 4800 (17.6397 iter/s, 5.66903s/100 iters), loss = 2.36371
I1210 15:28:24.386093 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1210 15:28:24.386093 15772 solver.cpp:237]     Train net output #1: loss = 2.36371 (* 1 = 2.36371 loss)
I1210 15:28:24.386093 15772 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1210 15:28:30.051021 15772 solver.cpp:218] Iteration 4900 (17.656 iter/s, 5.66378s/100 iters), loss = 2.44774
I1210 15:28:30.051021 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1210 15:28:30.051021 15772 solver.cpp:237]     Train net output #1: loss = 2.44774 (* 1 = 2.44774 loss)
I1210 15:28:30.051021 15772 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1210 15:28:35.439497 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:28:35.661010 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_5000.caffemodel
I1210 15:28:35.676012 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_5000.solverstate
I1210 15:28:35.680011 15772 solver.cpp:330] Iteration 5000, Testing net (#0)
I1210 15:28:35.680011 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:28:37.065176 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:28:37.118178 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2942
I1210 15:28:37.118178 15772 solver.cpp:397]     Test net output #1: loss = 2.8439 (* 1 = 2.8439 loss)
I1210 15:28:37.172183 15772 solver.cpp:218] Iteration 5000 (14.0437 iter/s, 7.12065s/100 iters), loss = 2.19962
I1210 15:28:37.172183 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:28:37.172183 15772 solver.cpp:237]     Train net output #1: loss = 2.19962 (* 1 = 2.19962 loss)
I1210 15:28:37.172183 15772 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1210 15:28:42.821655 15772 solver.cpp:218] Iteration 5100 (17.7005 iter/s, 5.64956s/100 iters), loss = 2.09075
I1210 15:28:42.821655 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1210 15:28:42.821655 15772 solver.cpp:237]     Train net output #1: loss = 2.09075 (* 1 = 2.09075 loss)
I1210 15:28:42.821655 15772 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1210 15:28:48.474184 15772 solver.cpp:218] Iteration 5200 (17.692 iter/s, 5.65226s/100 iters), loss = 1.76569
I1210 15:28:48.474184 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:28:48.474184 15772 solver.cpp:237]     Train net output #1: loss = 1.76569 (* 1 = 1.76569 loss)
I1210 15:28:48.474184 15772 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1210 15:28:54.126780 15772 solver.cpp:218] Iteration 5300 (17.6915 iter/s, 5.65242s/100 iters), loss = 2.35301
I1210 15:28:54.127779 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1210 15:28:54.127779 15772 solver.cpp:237]     Train net output #1: loss = 2.35301 (* 1 = 2.35301 loss)
I1210 15:28:54.127779 15772 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1210 15:28:59.773316 15772 solver.cpp:218] Iteration 5400 (17.7117 iter/s, 5.646s/100 iters), loss = 2.38359
I1210 15:28:59.773316 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1210 15:28:59.773316 15772 solver.cpp:237]     Train net output #1: loss = 2.38359 (* 1 = 2.38359 loss)
I1210 15:28:59.773316 15772 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1210 15:29:05.147330 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:29:05.366847 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_5500.caffemodel
I1210 15:29:05.381847 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_5500.solverstate
I1210 15:29:05.386848 15772 solver.cpp:330] Iteration 5500, Testing net (#0)
I1210 15:29:05.386848 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:29:06.757982 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:29:06.812012 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3185
I1210 15:29:06.812012 15772 solver.cpp:397]     Test net output #1: loss = 2.74637 (* 1 = 2.74637 loss)
I1210 15:29:06.865991 15772 solver.cpp:218] Iteration 5500 (14.1015 iter/s, 7.09142s/100 iters), loss = 2.02193
I1210 15:29:06.865991 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 15:29:06.865991 15772 solver.cpp:237]     Train net output #1: loss = 2.02193 (* 1 = 2.02193 loss)
I1210 15:29:06.865991 15772 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1210 15:29:12.520421 15772 solver.cpp:218] Iteration 5600 (17.6856 iter/s, 5.65432s/100 iters), loss = 1.98856
I1210 15:29:12.520421 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 15:29:12.520421 15772 solver.cpp:237]     Train net output #1: loss = 1.98856 (* 1 = 1.98856 loss)
I1210 15:29:12.520421 15772 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1210 15:29:18.163977 15772 solver.cpp:218] Iteration 5700 (17.7206 iter/s, 5.64316s/100 iters), loss = 1.75966
I1210 15:29:18.163977 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:29:18.163977 15772 solver.cpp:237]     Train net output #1: loss = 1.75966 (* 1 = 1.75966 loss)
I1210 15:29:18.163977 15772 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1210 15:29:23.813455 15772 solver.cpp:218] Iteration 5800 (17.7032 iter/s, 5.6487s/100 iters), loss = 2.0576
I1210 15:29:23.813455 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 15:29:23.813455 15772 solver.cpp:237]     Train net output #1: loss = 2.0576 (* 1 = 2.0576 loss)
I1210 15:29:23.813455 15772 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1210 15:29:29.468719 15772 solver.cpp:218] Iteration 5900 (17.6826 iter/s, 5.65528s/100 iters), loss = 2.32274
I1210 15:29:29.468719 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1210 15:29:29.468719 15772 solver.cpp:237]     Train net output #1: loss = 2.32274 (* 1 = 2.32274 loss)
I1210 15:29:29.468719 15772 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1210 15:29:34.843169 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:29:35.066190 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_6000.caffemodel
I1210 15:29:35.081192 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_6000.solverstate
I1210 15:29:35.086190 15772 solver.cpp:330] Iteration 6000, Testing net (#0)
I1210 15:29:35.086190 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:29:36.458907 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:29:36.512419 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3107
I1210 15:29:36.512419 15772 solver.cpp:397]     Test net output #1: loss = 2.86612 (* 1 = 2.86612 loss)
I1210 15:29:36.566423 15772 solver.cpp:218] Iteration 6000 (14.0915 iter/s, 7.09648s/100 iters), loss = 2.03236
I1210 15:29:36.566423 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 15:29:36.566423 15772 solver.cpp:237]     Train net output #1: loss = 2.03236 (* 1 = 2.03236 loss)
I1210 15:29:36.566423 15772 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1210 15:29:42.217865 15772 solver.cpp:218] Iteration 6100 (17.6957 iter/s, 5.65108s/100 iters), loss = 1.97882
I1210 15:29:42.217865 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1210 15:29:42.217865 15772 solver.cpp:237]     Train net output #1: loss = 1.97882 (* 1 = 1.97882 loss)
I1210 15:29:42.217865 15772 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1210 15:29:47.887413 15772 solver.cpp:218] Iteration 6200 (17.6383 iter/s, 5.66948s/100 iters), loss = 1.80624
I1210 15:29:47.887413 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:29:47.887413 15772 solver.cpp:237]     Train net output #1: loss = 1.80624 (* 1 = 1.80624 loss)
I1210 15:29:47.887413 15772 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1210 15:29:53.597283 15772 solver.cpp:218] Iteration 6300 (17.5164 iter/s, 5.70894s/100 iters), loss = 2.23393
I1210 15:29:53.597283 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1210 15:29:53.597283 15772 solver.cpp:237]     Train net output #1: loss = 2.23393 (* 1 = 2.23393 loss)
I1210 15:29:53.597283 15772 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1210 15:29:59.325490 15772 solver.cpp:218] Iteration 6400 (17.4581 iter/s, 5.72801s/100 iters), loss = 2.23317
I1210 15:29:59.325490 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 15:29:59.325490 15772 solver.cpp:237]     Train net output #1: loss = 2.23317 (* 1 = 2.23317 loss)
I1210 15:29:59.325490 15772 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1210 15:30:04.735978 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:30:04.959635 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_6500.caffemodel
I1210 15:30:04.974710 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_6500.solverstate
I1210 15:30:04.979710 15772 solver.cpp:330] Iteration 6500, Testing net (#0)
I1210 15:30:04.979710 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:30:06.358871 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:30:06.412161 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3447
I1210 15:30:06.412161 15772 solver.cpp:397]     Test net output #1: loss = 2.56336 (* 1 = 2.56336 loss)
I1210 15:30:06.465658 15772 solver.cpp:218] Iteration 6500 (14.0062 iter/s, 7.13968s/100 iters), loss = 2.02599
I1210 15:30:06.465658 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:30:06.466158 15772 solver.cpp:237]     Train net output #1: loss = 2.02599 (* 1 = 2.02599 loss)
I1210 15:30:06.466158 15772 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1210 15:30:12.137033 15772 solver.cpp:218] Iteration 6600 (17.6327 iter/s, 5.67128s/100 iters), loss = 2.09102
I1210 15:30:12.137033 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1210 15:30:12.137033 15772 solver.cpp:237]     Train net output #1: loss = 2.09102 (* 1 = 2.09102 loss)
I1210 15:30:12.137033 15772 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1210 15:30:17.790673 15772 solver.cpp:218] Iteration 6700 (17.6896 iter/s, 5.65302s/100 iters), loss = 1.75425
I1210 15:30:17.790673 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:30:17.790673 15772 solver.cpp:237]     Train net output #1: loss = 1.75425 (* 1 = 1.75425 loss)
I1210 15:30:17.790673 15772 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1210 15:30:23.440114 15772 solver.cpp:218] Iteration 6800 (17.7027 iter/s, 5.64886s/100 iters), loss = 2.02771
I1210 15:30:23.440114 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:30:23.440114 15772 solver.cpp:237]     Train net output #1: loss = 2.02771 (* 1 = 2.02771 loss)
I1210 15:30:23.440114 15772 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1210 15:30:29.119700 15772 solver.cpp:218] Iteration 6900 (17.6095 iter/s, 5.67876s/100 iters), loss = 2.18333
I1210 15:30:29.119700 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 15:30:29.119700 15772 solver.cpp:237]     Train net output #1: loss = 2.18333 (* 1 = 2.18333 loss)
I1210 15:30:29.119700 15772 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1210 15:30:34.529295 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:30:34.753307 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_7000.caffemodel
I1210 15:30:34.769810 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_7000.solverstate
I1210 15:30:34.774325 15772 solver.cpp:330] Iteration 7000, Testing net (#0)
I1210 15:30:34.774325 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:30:36.152429 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:30:36.206437 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3163
I1210 15:30:36.206437 15772 solver.cpp:397]     Test net output #1: loss = 2.74616 (* 1 = 2.74616 loss)
I1210 15:30:36.261940 15772 solver.cpp:218] Iteration 7000 (14.0022 iter/s, 7.14174s/100 iters), loss = 1.98606
I1210 15:30:36.261940 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:30:36.261940 15772 solver.cpp:237]     Train net output #1: loss = 1.98606 (* 1 = 1.98606 loss)
I1210 15:30:36.262441 15772 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1210 15:30:41.940151 15772 solver.cpp:218] Iteration 7100 (17.6127 iter/s, 5.67772s/100 iters), loss = 1.93323
I1210 15:30:41.940151 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 15:30:41.940151 15772 solver.cpp:237]     Train net output #1: loss = 1.93323 (* 1 = 1.93323 loss)
I1210 15:30:41.940151 15772 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1210 15:30:47.594604 15772 solver.cpp:218] Iteration 7200 (17.6876 iter/s, 5.65367s/100 iters), loss = 1.65055
I1210 15:30:47.594604 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 15:30:47.594604 15772 solver.cpp:237]     Train net output #1: loss = 1.65055 (* 1 = 1.65055 loss)
I1210 15:30:47.594604 15772 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1210 15:30:53.269423 15772 solver.cpp:218] Iteration 7300 (17.6222 iter/s, 5.67466s/100 iters), loss = 2.01552
I1210 15:30:53.269423 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 15:30:53.269423 15772 solver.cpp:237]     Train net output #1: loss = 2.01552 (* 1 = 2.01552 loss)
I1210 15:30:53.269423 15772 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1210 15:30:58.930965 15772 solver.cpp:218] Iteration 7400 (17.6627 iter/s, 5.66164s/100 iters), loss = 2.22574
I1210 15:30:58.930965 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 15:30:58.931965 15772 solver.cpp:237]     Train net output #1: loss = 2.22574 (* 1 = 2.22574 loss)
I1210 15:30:58.931965 15772 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1210 15:31:04.341857 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:31:04.563868 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_7500.caffemodel
I1210 15:31:04.578375 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_7500.solverstate
I1210 15:31:04.583376 15772 solver.cpp:330] Iteration 7500, Testing net (#0)
I1210 15:31:04.583376 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:31:05.969859 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:31:06.024873 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3339
I1210 15:31:06.024873 15772 solver.cpp:397]     Test net output #1: loss = 2.71262 (* 1 = 2.71262 loss)
I1210 15:31:06.078872 15772 solver.cpp:218] Iteration 7500 (13.9925 iter/s, 7.1467s/100 iters), loss = 2.21945
I1210 15:31:06.078872 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:31:06.078872 15772 solver.cpp:237]     Train net output #1: loss = 2.21945 (* 1 = 2.21945 loss)
I1210 15:31:06.078872 15772 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1210 15:31:11.725703 15772 solver.cpp:218] Iteration 7600 (17.7105 iter/s, 5.64637s/100 iters), loss = 1.94524
I1210 15:31:11.725703 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 15:31:11.725703 15772 solver.cpp:237]     Train net output #1: loss = 1.94524 (* 1 = 1.94524 loss)
I1210 15:31:11.725703 15772 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1210 15:31:17.360489 15772 solver.cpp:218] Iteration 7700 (17.7474 iter/s, 5.63462s/100 iters), loss = 1.79287
I1210 15:31:17.360489 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:31:17.360489 15772 solver.cpp:237]     Train net output #1: loss = 1.79287 (* 1 = 1.79287 loss)
I1210 15:31:17.360489 15772 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1210 15:31:23.042227 15772 solver.cpp:218] Iteration 7800 (17.6006 iter/s, 5.68161s/100 iters), loss = 2.05368
I1210 15:31:23.042227 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:31:23.042227 15772 solver.cpp:237]     Train net output #1: loss = 2.05368 (* 1 = 2.05368 loss)
I1210 15:31:23.042227 15772 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1210 15:31:28.766669 15772 solver.cpp:218] Iteration 7900 (17.4707 iter/s, 5.72387s/100 iters), loss = 2.08913
I1210 15:31:28.766669 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:31:28.766669 15772 solver.cpp:237]     Train net output #1: loss = 2.08913 (* 1 = 2.08913 loss)
I1210 15:31:28.766669 15772 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1210 15:31:34.219888 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:31:34.447928 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_8000.caffemodel
I1210 15:31:34.463914 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_8000.solverstate
I1210 15:31:34.468914 15772 solver.cpp:330] Iteration 8000, Testing net (#0)
I1210 15:31:34.468914 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:31:35.874084 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:31:35.927100 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3594
I1210 15:31:35.927100 15772 solver.cpp:397]     Test net output #1: loss = 2.57737 (* 1 = 2.57737 loss)
I1210 15:31:35.981101 15772 solver.cpp:218] Iteration 8000 (13.8631 iter/s, 7.21339s/100 iters), loss = 1.97092
I1210 15:31:35.981101 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:31:35.981101 15772 solver.cpp:237]     Train net output #1: loss = 1.97092 (* 1 = 1.97092 loss)
I1210 15:31:35.981101 15772 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1210 15:31:41.683738 15772 solver.cpp:218] Iteration 8100 (17.5367 iter/s, 5.70232s/100 iters), loss = 1.85289
I1210 15:31:41.684244 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:31:41.684244 15772 solver.cpp:237]     Train net output #1: loss = 1.85289 (* 1 = 1.85289 loss)
I1210 15:31:41.684244 15772 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1210 15:31:47.387128 15772 solver.cpp:218] Iteration 8200 (17.535 iter/s, 5.70289s/100 iters), loss = 1.70892
I1210 15:31:47.387622 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:31:47.387622 15772 solver.cpp:237]     Train net output #1: loss = 1.70892 (* 1 = 1.70892 loss)
I1210 15:31:47.387622 15772 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1210 15:31:53.160789 15772 solver.cpp:218] Iteration 8300 (17.321 iter/s, 5.77335s/100 iters), loss = 2.06722
I1210 15:31:53.160789 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:31:53.160789 15772 solver.cpp:237]     Train net output #1: loss = 2.06722 (* 1 = 2.06722 loss)
I1210 15:31:53.160789 15772 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1210 15:31:58.876528 15772 solver.cpp:218] Iteration 8400 (17.4972 iter/s, 5.7152s/100 iters), loss = 1.9186
I1210 15:31:58.876528 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:31:58.876528 15772 solver.cpp:237]     Train net output #1: loss = 1.9186 (* 1 = 1.9186 loss)
I1210 15:31:58.876528 15772 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1210 15:32:04.496312 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:32:04.722334 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_8500.caffemodel
I1210 15:32:04.744341 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_8500.solverstate
I1210 15:32:04.751335 15772 solver.cpp:330] Iteration 8500, Testing net (#0)
I1210 15:32:04.751335 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:32:06.149480 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:32:06.204489 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3542
I1210 15:32:06.205492 15772 solver.cpp:397]     Test net output #1: loss = 2.64207 (* 1 = 2.64207 loss)
I1210 15:32:06.258489 15772 solver.cpp:218] Iteration 8500 (13.5477 iter/s, 7.38131s/100 iters), loss = 2.00863
I1210 15:32:06.258489 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:32:06.258489 15772 solver.cpp:237]     Train net output #1: loss = 2.00863 (* 1 = 2.00863 loss)
I1210 15:32:06.258489 15772 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1210 15:32:11.950985 15772 solver.cpp:218] Iteration 8600 (17.5691 iter/s, 5.6918s/100 iters), loss = 1.83197
I1210 15:32:11.950985 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 15:32:11.950985 15772 solver.cpp:237]     Train net output #1: loss = 1.83197 (* 1 = 1.83197 loss)
I1210 15:32:11.950985 15772 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1210 15:32:17.658969 15772 solver.cpp:218] Iteration 8700 (17.5217 iter/s, 5.70722s/100 iters), loss = 1.6556
I1210 15:32:17.658969 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:32:17.658969 15772 solver.cpp:237]     Train net output #1: loss = 1.6556 (* 1 = 1.6556 loss)
I1210 15:32:17.658969 15772 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1210 15:32:23.353950 15772 solver.cpp:218] Iteration 8800 (17.5608 iter/s, 5.69449s/100 iters), loss = 1.9356
I1210 15:32:23.353950 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:32:23.353950 15772 solver.cpp:237]     Train net output #1: loss = 1.9356 (* 1 = 1.9356 loss)
I1210 15:32:23.353950 15772 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1210 15:32:29.009371 15772 solver.cpp:218] Iteration 8900 (17.6832 iter/s, 5.65509s/100 iters), loss = 2.08904
I1210 15:32:29.009371 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 15:32:29.009371 15772 solver.cpp:237]     Train net output #1: loss = 2.08904 (* 1 = 2.08904 loss)
I1210 15:32:29.009371 15772 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1210 15:32:34.377802 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:32:34.598839 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_9000.caffemodel
I1210 15:32:34.612838 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_9000.solverstate
I1210 15:32:34.617841 15772 solver.cpp:330] Iteration 9000, Testing net (#0)
I1210 15:32:34.617841 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:32:35.986454 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:32:36.041452 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3303
I1210 15:32:36.041452 15772 solver.cpp:397]     Test net output #1: loss = 2.82647 (* 1 = 2.82647 loss)
I1210 15:32:36.095960 15772 solver.cpp:218] Iteration 9000 (14.1123 iter/s, 7.08604s/100 iters), loss = 1.83765
I1210 15:32:36.095960 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:32:36.095960 15772 solver.cpp:237]     Train net output #1: loss = 1.83765 (* 1 = 1.83765 loss)
I1210 15:32:36.095960 15772 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1210 15:32:41.739413 15772 solver.cpp:218] Iteration 9100 (17.7192 iter/s, 5.6436s/100 iters), loss = 1.82085
I1210 15:32:41.739413 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 15:32:41.740414 15772 solver.cpp:237]     Train net output #1: loss = 1.82085 (* 1 = 1.82085 loss)
I1210 15:32:41.740414 15772 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1210 15:32:47.420912 15772 solver.cpp:218] Iteration 9200 (17.6022 iter/s, 5.6811s/100 iters), loss = 1.61036
I1210 15:32:47.421912 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 15:32:47.421912 15772 solver.cpp:237]     Train net output #1: loss = 1.61036 (* 1 = 1.61036 loss)
I1210 15:32:47.421912 15772 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1210 15:32:53.093834 15772 solver.cpp:218] Iteration 9300 (17.6311 iter/s, 5.67178s/100 iters), loss = 1.9085
I1210 15:32:53.093834 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:32:53.093834 15772 solver.cpp:237]     Train net output #1: loss = 1.9085 (* 1 = 1.9085 loss)
I1210 15:32:53.093834 15772 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1210 15:32:58.803302 15772 solver.cpp:218] Iteration 9400 (17.5165 iter/s, 5.7089s/100 iters), loss = 2.08567
I1210 15:32:58.803302 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:32:58.803302 15772 solver.cpp:237]     Train net output #1: loss = 2.08567 (* 1 = 2.08567 loss)
I1210 15:32:58.803302 15772 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1210 15:33:04.215754 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:33:04.441792 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_9500.caffemodel
I1210 15:33:04.462790 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_9500.solverstate
I1210 15:33:04.468291 15772 solver.cpp:330] Iteration 9500, Testing net (#0)
I1210 15:33:04.468291 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:33:05.875910 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:33:05.931910 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3029
I1210 15:33:05.931910 15772 solver.cpp:397]     Test net output #1: loss = 2.83558 (* 1 = 2.83558 loss)
I1210 15:33:05.987915 15772 solver.cpp:218] Iteration 9500 (13.9184 iter/s, 7.18474s/100 iters), loss = 1.96535
I1210 15:33:05.987915 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:33:05.987915 15772 solver.cpp:237]     Train net output #1: loss = 1.96535 (* 1 = 1.96535 loss)
I1210 15:33:05.987915 15772 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1210 15:33:11.668155 15772 solver.cpp:218] Iteration 9600 (17.6077 iter/s, 5.67932s/100 iters), loss = 1.79638
I1210 15:33:11.668155 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:33:11.668155 15772 solver.cpp:237]     Train net output #1: loss = 1.79638 (* 1 = 1.79638 loss)
I1210 15:33:11.668155 15772 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1210 15:33:17.313140 15772 solver.cpp:218] Iteration 9700 (17.716 iter/s, 5.64461s/100 iters), loss = 1.66561
I1210 15:33:17.313140 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:33:17.313140 15772 solver.cpp:237]     Train net output #1: loss = 1.66561 (* 1 = 1.66561 loss)
I1210 15:33:17.313140 15772 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1210 15:33:22.962615 15772 solver.cpp:218] Iteration 9800 (17.7028 iter/s, 5.64882s/100 iters), loss = 1.93903
I1210 15:33:22.962615 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:33:22.962615 15772 solver.cpp:237]     Train net output #1: loss = 1.93903 (* 1 = 1.93903 loss)
I1210 15:33:22.962615 15772 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1210 15:33:28.606117 15772 solver.cpp:218] Iteration 9900 (17.7216 iter/s, 5.64283s/100 iters), loss = 2.1412
I1210 15:33:28.606117 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1210 15:33:28.606117 15772 solver.cpp:237]     Train net output #1: loss = 2.1412 (* 1 = 2.1412 loss)
I1210 15:33:28.606117 15772 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1210 15:33:33.977531 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:33:34.199544 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_10000.caffemodel
I1210 15:33:34.214545 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_10000.solverstate
I1210 15:33:34.219544 15772 solver.cpp:330] Iteration 10000, Testing net (#0)
I1210 15:33:34.219544 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:33:35.590668 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:33:35.645676 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3166
I1210 15:33:35.645676 15772 solver.cpp:397]     Test net output #1: loss = 2.91781 (* 1 = 2.91781 loss)
I1210 15:33:35.700685 15772 solver.cpp:218] Iteration 10000 (14.0963 iter/s, 7.09408s/100 iters), loss = 1.86529
I1210 15:33:35.700685 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:33:35.700685 15772 solver.cpp:237]     Train net output #1: loss = 1.86529 (* 1 = 1.86529 loss)
I1210 15:33:35.700685 15772 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1210 15:33:41.339174 15772 solver.cpp:218] Iteration 10100 (17.7352 iter/s, 5.63851s/100 iters), loss = 1.76593
I1210 15:33:41.339174 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 15:33:41.339174 15772 solver.cpp:237]     Train net output #1: loss = 1.76593 (* 1 = 1.76593 loss)
I1210 15:33:41.339174 15772 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1210 15:33:46.984593 15772 solver.cpp:218] Iteration 10200 (17.7164 iter/s, 5.64449s/100 iters), loss = 1.4431
I1210 15:33:46.984593 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 15:33:46.984593 15772 solver.cpp:237]     Train net output #1: loss = 1.4431 (* 1 = 1.4431 loss)
I1210 15:33:46.984593 15772 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1210 15:33:52.635013 15772 solver.cpp:218] Iteration 10300 (17.6983 iter/s, 5.65027s/100 iters), loss = 1.96567
I1210 15:33:52.635013 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:33:52.635013 15772 solver.cpp:237]     Train net output #1: loss = 1.96567 (* 1 = 1.96567 loss)
I1210 15:33:52.635013 15772 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1210 15:33:58.280422 15772 solver.cpp:218] Iteration 10400 (17.7155 iter/s, 5.64476s/100 iters), loss = 2.20604
I1210 15:33:58.280422 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1210 15:33:58.280422 15772 solver.cpp:237]     Train net output #1: loss = 2.20604 (* 1 = 2.20604 loss)
I1210 15:33:58.280422 15772 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1210 15:34:03.649883 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:34:03.873399 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_10500.caffemodel
I1210 15:34:03.888905 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_10500.solverstate
I1210 15:34:03.893904 15772 solver.cpp:330] Iteration 10500, Testing net (#0)
I1210 15:34:03.893904 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:34:05.267516 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:34:05.323019 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2775
I1210 15:34:05.323019 15772 solver.cpp:397]     Test net output #1: loss = 3.57887 (* 1 = 3.57887 loss)
I1210 15:34:05.376520 15772 solver.cpp:218] Iteration 10500 (14.0934 iter/s, 7.09552s/100 iters), loss = 1.88301
I1210 15:34:05.376520 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:34:05.376520 15772 solver.cpp:237]     Train net output #1: loss = 1.88301 (* 1 = 1.88301 loss)
I1210 15:34:05.376520 15772 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1210 15:34:11.023442 15772 solver.cpp:218] Iteration 10600 (17.7082 iter/s, 5.64711s/100 iters), loss = 1.72564
I1210 15:34:11.024442 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:34:11.024442 15772 solver.cpp:237]     Train net output #1: loss = 1.72564 (* 1 = 1.72564 loss)
I1210 15:34:11.024442 15772 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1210 15:34:16.669724 15772 solver.cpp:218] Iteration 10700 (17.7142 iter/s, 5.64518s/100 iters), loss = 1.61043
I1210 15:34:16.669724 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:34:16.669724 15772 solver.cpp:237]     Train net output #1: loss = 1.61043 (* 1 = 1.61043 loss)
I1210 15:34:16.669724 15772 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1210 15:34:22.311143 15772 solver.cpp:218] Iteration 10800 (17.7263 iter/s, 5.64133s/100 iters), loss = 1.98579
I1210 15:34:22.311143 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:34:22.311143 15772 solver.cpp:237]     Train net output #1: loss = 1.98579 (* 1 = 1.98579 loss)
I1210 15:34:22.311143 15772 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1210 15:34:27.964617 15772 solver.cpp:218] Iteration 10900 (17.691 iter/s, 5.6526s/100 iters), loss = 1.90131
I1210 15:34:27.964617 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:34:27.964617 15772 solver.cpp:237]     Train net output #1: loss = 1.90131 (* 1 = 1.90131 loss)
I1210 15:34:27.964617 15772 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1210 15:34:33.331183 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:34:33.554198 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_11000.caffemodel
I1210 15:34:33.568197 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_11000.solverstate
I1210 15:34:33.573199 15772 solver.cpp:330] Iteration 11000, Testing net (#0)
I1210 15:34:33.573199 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:34:34.943302 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:34:34.998304 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3287
I1210 15:34:34.998304 15772 solver.cpp:397]     Test net output #1: loss = 2.78494 (* 1 = 2.78494 loss)
I1210 15:34:35.051318 15772 solver.cpp:218] Iteration 11000 (14.1112 iter/s, 7.08657s/100 iters), loss = 1.93246
I1210 15:34:35.051318 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:34:35.051318 15772 solver.cpp:237]     Train net output #1: loss = 1.93246 (* 1 = 1.93246 loss)
I1210 15:34:35.051318 15772 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1210 15:34:40.690753 15772 solver.cpp:218] Iteration 11100 (17.7353 iter/s, 5.63847s/100 iters), loss = 1.59821
I1210 15:34:40.690753 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:34:40.690753 15772 solver.cpp:237]     Train net output #1: loss = 1.59821 (* 1 = 1.59821 loss)
I1210 15:34:40.690753 15772 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1210 15:34:46.329265 15772 solver.cpp:218] Iteration 11200 (17.737 iter/s, 5.63794s/100 iters), loss = 1.51039
I1210 15:34:46.329265 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 15:34:46.329265 15772 solver.cpp:237]     Train net output #1: loss = 1.51039 (* 1 = 1.51039 loss)
I1210 15:34:46.329265 15772 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1210 15:34:51.967705 15772 solver.cpp:218] Iteration 11300 (17.7364 iter/s, 5.63812s/100 iters), loss = 1.9076
I1210 15:34:51.967705 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:34:51.967705 15772 solver.cpp:237]     Train net output #1: loss = 1.9076 (* 1 = 1.9076 loss)
I1210 15:34:51.967705 15772 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1210 15:34:57.617090 15772 solver.cpp:218] Iteration 11400 (17.7013 iter/s, 5.64931s/100 iters), loss = 1.95867
I1210 15:34:57.617090 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:34:57.617090 15772 solver.cpp:237]     Train net output #1: loss = 1.95867 (* 1 = 1.95867 loss)
I1210 15:34:57.617090 15772 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1210 15:35:02.984488 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:35:03.208503 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_11500.caffemodel
I1210 15:35:03.223503 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_11500.solverstate
I1210 15:35:03.227504 15772 solver.cpp:330] Iteration 11500, Testing net (#0)
I1210 15:35:03.227504 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:35:04.598590 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:35:04.653597 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3827
I1210 15:35:04.653597 15772 solver.cpp:397]     Test net output #1: loss = 2.44779 (* 1 = 2.44779 loss)
I1210 15:35:04.708611 15772 solver.cpp:218] Iteration 11500 (14.1035 iter/s, 7.09044s/100 iters), loss = 1.88819
I1210 15:35:04.708611 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:35:04.708611 15772 solver.cpp:237]     Train net output #1: loss = 1.88819 (* 1 = 1.88819 loss)
I1210 15:35:04.708611 15772 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1210 15:35:10.336068 15772 solver.cpp:218] Iteration 11600 (17.7715 iter/s, 5.62699s/100 iters), loss = 1.7607
I1210 15:35:10.336068 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:35:10.336068 15772 solver.cpp:237]     Train net output #1: loss = 1.7607 (* 1 = 1.7607 loss)
I1210 15:35:10.336068 15772 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1210 15:35:15.973522 15772 solver.cpp:218] Iteration 11700 (17.7394 iter/s, 5.63716s/100 iters), loss = 1.44258
I1210 15:35:15.973522 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 15:35:15.973522 15772 solver.cpp:237]     Train net output #1: loss = 1.44258 (* 1 = 1.44258 loss)
I1210 15:35:15.973522 15772 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1210 15:35:21.605327 15772 solver.cpp:218] Iteration 11800 (17.7583 iter/s, 5.63118s/100 iters), loss = 2.09607
I1210 15:35:21.605327 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:35:21.605327 15772 solver.cpp:237]     Train net output #1: loss = 2.09607 (* 1 = 2.09607 loss)
I1210 15:35:21.605327 15772 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1210 15:35:27.242290 15772 solver.cpp:218] Iteration 11900 (17.7429 iter/s, 5.63607s/100 iters), loss = 2.00748
I1210 15:35:27.242290 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:35:27.242290 15772 solver.cpp:237]     Train net output #1: loss = 2.00748 (* 1 = 2.00748 loss)
I1210 15:35:27.242290 15772 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1210 15:35:32.607228 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:35:32.830248 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_12000.caffemodel
I1210 15:35:32.844753 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_12000.solverstate
I1210 15:35:32.849755 15772 solver.cpp:330] Iteration 12000, Testing net (#0)
I1210 15:35:32.849755 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:35:34.222470 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:35:34.276474 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3501
I1210 15:35:34.276474 15772 solver.cpp:397]     Test net output #1: loss = 2.58672 (* 1 = 2.58672 loss)
I1210 15:35:34.330474 15772 solver.cpp:218] Iteration 12000 (14.1081 iter/s, 7.08815s/100 iters), loss = 1.9402
I1210 15:35:34.330474 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:35:34.330474 15772 solver.cpp:237]     Train net output #1: loss = 1.9402 (* 1 = 1.9402 loss)
I1210 15:35:34.330474 15772 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1210 15:35:39.976954 15772 solver.cpp:218] Iteration 12100 (17.7134 iter/s, 5.64544s/100 iters), loss = 1.64202
I1210 15:35:39.976954 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:35:39.976954 15772 solver.cpp:237]     Train net output #1: loss = 1.64202 (* 1 = 1.64202 loss)
I1210 15:35:39.976954 15772 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1210 15:35:45.625361 15772 solver.cpp:218] Iteration 12200 (17.703 iter/s, 5.64877s/100 iters), loss = 1.47943
I1210 15:35:45.625361 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 15:35:45.625361 15772 solver.cpp:237]     Train net output #1: loss = 1.47943 (* 1 = 1.47943 loss)
I1210 15:35:45.625361 15772 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1210 15:35:51.278869 15772 solver.cpp:218] Iteration 12300 (17.692 iter/s, 5.65227s/100 iters), loss = 1.93242
I1210 15:35:51.278869 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 15:35:51.278869 15772 solver.cpp:237]     Train net output #1: loss = 1.93242 (* 1 = 1.93242 loss)
I1210 15:35:51.278869 15772 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1210 15:35:56.931283 15772 solver.cpp:218] Iteration 12400 (17.6902 iter/s, 5.65283s/100 iters), loss = 1.95043
I1210 15:35:56.932284 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:35:56.932284 15772 solver.cpp:237]     Train net output #1: loss = 1.95043 (* 1 = 1.95043 loss)
I1210 15:35:56.932284 15772 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1210 15:36:02.305655 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:36:02.529904 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_12500.caffemodel
I1210 15:36:02.543411 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_12500.solverstate
I1210 15:36:02.548411 15772 solver.cpp:330] Iteration 12500, Testing net (#0)
I1210 15:36:02.548411 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:36:03.914929 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:36:03.967960 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3409
I1210 15:36:03.967960 15772 solver.cpp:397]     Test net output #1: loss = 2.70039 (* 1 = 2.70039 loss)
I1210 15:36:04.022954 15772 solver.cpp:218] Iteration 12500 (14.1029 iter/s, 7.09073s/100 iters), loss = 1.96532
I1210 15:36:04.022954 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:36:04.022954 15772 solver.cpp:237]     Train net output #1: loss = 1.96532 (* 1 = 1.96532 loss)
I1210 15:36:04.022954 15772 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1210 15:36:09.663305 15772 solver.cpp:218] Iteration 12600 (17.7314 iter/s, 5.63971s/100 iters), loss = 1.74348
I1210 15:36:09.663305 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:36:09.663305 15772 solver.cpp:237]     Train net output #1: loss = 1.74348 (* 1 = 1.74348 loss)
I1210 15:36:09.663305 15772 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1210 15:36:15.299347 15772 solver.cpp:218] Iteration 12700 (17.7455 iter/s, 5.63523s/100 iters), loss = 1.54889
I1210 15:36:15.299347 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 15:36:15.299347 15772 solver.cpp:237]     Train net output #1: loss = 1.54889 (* 1 = 1.54889 loss)
I1210 15:36:15.299347 15772 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1210 15:36:20.925899 15772 solver.cpp:218] Iteration 12800 (17.7737 iter/s, 5.62629s/100 iters), loss = 1.85686
I1210 15:36:20.925899 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:36:20.925899 15772 solver.cpp:237]     Train net output #1: loss = 1.85686 (* 1 = 1.85686 loss)
I1210 15:36:20.925899 15772 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1210 15:36:26.554705 15772 solver.cpp:218] Iteration 12900 (17.7677 iter/s, 5.6282s/100 iters), loss = 1.91696
I1210 15:36:26.554705 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:36:26.554705 15772 solver.cpp:237]     Train net output #1: loss = 1.91696 (* 1 = 1.91696 loss)
I1210 15:36:26.554705 15772 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1210 15:36:31.915557 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:36:32.138906 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_13000.caffemodel
I1210 15:36:32.155906 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_13000.solverstate
I1210 15:36:32.160419 15772 solver.cpp:330] Iteration 13000, Testing net (#0)
I1210 15:36:32.160917 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:36:33.530064 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:36:33.584094 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3256
I1210 15:36:33.584094 15772 solver.cpp:397]     Test net output #1: loss = 2.83328 (* 1 = 2.83328 loss)
I1210 15:36:33.639094 15772 solver.cpp:218] Iteration 13000 (14.1164 iter/s, 7.08394s/100 iters), loss = 1.81079
I1210 15:36:33.639094 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:36:33.639094 15772 solver.cpp:237]     Train net output #1: loss = 1.81079 (* 1 = 1.81079 loss)
I1210 15:36:33.639094 15772 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1210 15:36:39.295191 15772 solver.cpp:218] Iteration 13100 (17.6819 iter/s, 5.65551s/100 iters), loss = 1.6769
I1210 15:36:39.295191 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:36:39.295191 15772 solver.cpp:237]     Train net output #1: loss = 1.6769 (* 1 = 1.6769 loss)
I1210 15:36:39.295191 15772 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1210 15:36:44.952561 15772 solver.cpp:218] Iteration 13200 (17.675 iter/s, 5.6577s/100 iters), loss = 1.52731
I1210 15:36:44.953564 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 15:36:44.953564 15772 solver.cpp:237]     Train net output #1: loss = 1.52731 (* 1 = 1.52731 loss)
I1210 15:36:44.953564 15772 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1210 15:36:50.605041 15772 solver.cpp:218] Iteration 13300 (17.6935 iter/s, 5.65179s/100 iters), loss = 1.80604
I1210 15:36:50.606040 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:36:50.606040 15772 solver.cpp:237]     Train net output #1: loss = 1.80604 (* 1 = 1.80604 loss)
I1210 15:36:50.606040 15772 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1210 15:36:56.257495 15772 solver.cpp:218] Iteration 13400 (17.695 iter/s, 5.65133s/100 iters), loss = 1.93563
I1210 15:36:56.257495 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:36:56.257495 15772 solver.cpp:237]     Train net output #1: loss = 1.93563 (* 1 = 1.93563 loss)
I1210 15:36:56.257495 15772 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1210 15:37:01.633999 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:37:01.857024 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_13500.caffemodel
I1210 15:37:01.872515 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_13500.solverstate
I1210 15:37:01.877526 15772 solver.cpp:330] Iteration 13500, Testing net (#0)
I1210 15:37:01.877526 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:37:03.248049 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:37:03.302057 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3967
I1210 15:37:03.302057 15772 solver.cpp:397]     Test net output #1: loss = 2.34037 (* 1 = 2.34037 loss)
I1210 15:37:03.357058 15772 solver.cpp:218] Iteration 13500 (14.0852 iter/s, 7.09963s/100 iters), loss = 2.00689
I1210 15:37:03.357058 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:37:03.357058 15772 solver.cpp:237]     Train net output #1: loss = 2.00689 (* 1 = 2.00689 loss)
I1210 15:37:03.357058 15772 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1210 15:37:09.012459 15772 solver.cpp:218] Iteration 13600 (17.6836 iter/s, 5.65495s/100 iters), loss = 1.5844
I1210 15:37:09.012459 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:37:09.012459 15772 solver.cpp:237]     Train net output #1: loss = 1.5844 (* 1 = 1.5844 loss)
I1210 15:37:09.012459 15772 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1210 15:37:14.667901 15772 solver.cpp:218] Iteration 13700 (17.6847 iter/s, 5.65462s/100 iters), loss = 1.52877
I1210 15:37:14.668401 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 15:37:14.668401 15772 solver.cpp:237]     Train net output #1: loss = 1.52877 (* 1 = 1.52877 loss)
I1210 15:37:14.668401 15772 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1210 15:37:20.320329 15772 solver.cpp:218] Iteration 13800 (17.6924 iter/s, 5.65214s/100 iters), loss = 1.86619
I1210 15:37:20.320329 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:37:20.320329 15772 solver.cpp:237]     Train net output #1: loss = 1.86619 (* 1 = 1.86619 loss)
I1210 15:37:20.320329 15772 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1210 15:37:25.974290 15772 solver.cpp:218] Iteration 13900 (17.6902 iter/s, 5.65286s/100 iters), loss = 1.96754
I1210 15:37:25.974290 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 15:37:25.974290 15772 solver.cpp:237]     Train net output #1: loss = 1.96754 (* 1 = 1.96754 loss)
I1210 15:37:25.974290 15772 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1210 15:37:31.346436 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:37:31.568696 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_14000.caffemodel
I1210 15:37:31.582687 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_14000.solverstate
I1210 15:37:31.587692 15772 solver.cpp:330] Iteration 14000, Testing net (#0)
I1210 15:37:31.587692 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:37:32.957621 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:37:33.011848 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3544
I1210 15:37:33.011848 15772 solver.cpp:397]     Test net output #1: loss = 2.64667 (* 1 = 2.64667 loss)
I1210 15:37:33.066366 15772 solver.cpp:218] Iteration 14000 (14.1006 iter/s, 7.0919s/100 iters), loss = 1.89408
I1210 15:37:33.066366 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:37:33.066366 15772 solver.cpp:237]     Train net output #1: loss = 1.89408 (* 1 = 1.89408 loss)
I1210 15:37:33.066867 15772 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1210 15:37:38.700425 15772 solver.cpp:218] Iteration 14100 (17.7496 iter/s, 5.63392s/100 iters), loss = 1.54665
I1210 15:37:38.700425 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:37:38.700425 15772 solver.cpp:237]     Train net output #1: loss = 1.54665 (* 1 = 1.54665 loss)
I1210 15:37:38.700425 15772 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1210 15:37:44.341938 15772 solver.cpp:218] Iteration 14200 (17.7277 iter/s, 5.6409s/100 iters), loss = 1.5629
I1210 15:37:44.341938 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 15:37:44.341938 15772 solver.cpp:237]     Train net output #1: loss = 1.5629 (* 1 = 1.5629 loss)
I1210 15:37:44.341938 15772 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1210 15:37:49.970060 15772 solver.cpp:218] Iteration 14300 (17.7706 iter/s, 5.62726s/100 iters), loss = 1.8489
I1210 15:37:49.970060 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:37:49.970060 15772 solver.cpp:237]     Train net output #1: loss = 1.8489 (* 1 = 1.8489 loss)
I1210 15:37:49.970060 15772 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1210 15:37:55.604549 15772 solver.cpp:218] Iteration 14400 (17.7474 iter/s, 5.63463s/100 iters), loss = 1.97926
I1210 15:37:55.604549 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:37:55.604549 15772 solver.cpp:237]     Train net output #1: loss = 1.97926 (* 1 = 1.97926 loss)
I1210 15:37:55.604549 15772 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1210 15:38:00.974433 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:38:01.196959 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_14500.caffemodel
I1210 15:38:01.211959 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_14500.solverstate
I1210 15:38:01.216960 15772 solver.cpp:330] Iteration 14500, Testing net (#0)
I1210 15:38:01.216960 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:38:02.586120 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:38:02.639119 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3881
I1210 15:38:02.640120 15772 solver.cpp:397]     Test net output #1: loss = 2.39799 (* 1 = 2.39799 loss)
I1210 15:38:02.694142 15772 solver.cpp:218] Iteration 14500 (14.1062 iter/s, 7.08906s/100 iters), loss = 1.76341
I1210 15:38:02.694142 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:38:02.694142 15772 solver.cpp:237]     Train net output #1: loss = 1.76341 (* 1 = 1.76341 loss)
I1210 15:38:02.694142 15772 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1210 15:38:08.325553 15772 solver.cpp:218] Iteration 14600 (17.7599 iter/s, 5.63067s/100 iters), loss = 1.67331
I1210 15:38:08.325553 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:38:08.325553 15772 solver.cpp:237]     Train net output #1: loss = 1.67331 (* 1 = 1.67331 loss)
I1210 15:38:08.325553 15772 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1210 15:38:13.958183 15772 solver.cpp:218] Iteration 14700 (17.7563 iter/s, 5.63179s/100 iters), loss = 1.54264
I1210 15:38:13.958183 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:38:13.958183 15772 solver.cpp:237]     Train net output #1: loss = 1.54264 (* 1 = 1.54264 loss)
I1210 15:38:13.958183 15772 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1210 15:38:19.579646 15772 solver.cpp:218] Iteration 14800 (17.7887 iter/s, 5.62155s/100 iters), loss = 1.98637
I1210 15:38:19.579646 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:38:19.579646 15772 solver.cpp:237]     Train net output #1: loss = 1.98637 (* 1 = 1.98637 loss)
I1210 15:38:19.579646 15772 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1210 15:38:25.206130 15772 solver.cpp:218] Iteration 14900 (17.7762 iter/s, 5.6255s/100 iters), loss = 1.93943
I1210 15:38:25.206130 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 15:38:25.206130 15772 solver.cpp:237]     Train net output #1: loss = 1.93943 (* 1 = 1.93943 loss)
I1210 15:38:25.206130 15772 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1210 15:38:30.565044 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:38:30.786557 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_15000.caffemodel
I1210 15:38:30.801558 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_15000.solverstate
I1210 15:38:30.805557 15772 solver.cpp:330] Iteration 15000, Testing net (#0)
I1210 15:38:30.805557 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:38:32.178469 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:38:32.231984 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2976
I1210 15:38:32.231984 15772 solver.cpp:397]     Test net output #1: loss = 3.0512 (* 1 = 3.0512 loss)
I1210 15:38:32.284976 15772 solver.cpp:218] Iteration 15000 (14.1261 iter/s, 7.07909s/100 iters), loss = 1.86414
I1210 15:38:32.284976 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:38:32.284976 15772 solver.cpp:237]     Train net output #1: loss = 1.86414 (* 1 = 1.86414 loss)
I1210 15:38:32.284976 15772 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1210 15:38:37.915361 15772 solver.cpp:218] Iteration 15100 (17.7621 iter/s, 5.62997s/100 iters), loss = 1.65474
I1210 15:38:37.915361 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:38:37.915361 15772 solver.cpp:237]     Train net output #1: loss = 1.65474 (* 1 = 1.65474 loss)
I1210 15:38:37.915361 15772 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1210 15:38:43.542779 15772 solver.cpp:218] Iteration 15200 (17.773 iter/s, 5.62652s/100 iters), loss = 1.49234
I1210 15:38:43.542779 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 15:38:43.542779 15772 solver.cpp:237]     Train net output #1: loss = 1.49234 (* 1 = 1.49234 loss)
I1210 15:38:43.542779 15772 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1210 15:38:49.167160 15772 solver.cpp:218] Iteration 15300 (17.7808 iter/s, 5.62406s/100 iters), loss = 1.72464
I1210 15:38:49.167160 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:38:49.167160 15772 solver.cpp:237]     Train net output #1: loss = 1.72464 (* 1 = 1.72464 loss)
I1210 15:38:49.167660 15772 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1210 15:38:54.789741 15772 solver.cpp:218] Iteration 15400 (17.7866 iter/s, 5.62221s/100 iters), loss = 1.78129
I1210 15:38:54.789741 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:38:54.789741 15772 solver.cpp:237]     Train net output #1: loss = 1.78129 (* 1 = 1.78129 loss)
I1210 15:38:54.789741 15772 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1210 15:39:00.134119 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:39:00.355129 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_15500.caffemodel
I1210 15:39:00.371632 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_15500.solverstate
I1210 15:39:00.376633 15772 solver.cpp:330] Iteration 15500, Testing net (#0)
I1210 15:39:00.376633 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:39:01.742207 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:39:01.797211 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3369
I1210 15:39:01.797211 15772 solver.cpp:397]     Test net output #1: loss = 2.71503 (* 1 = 2.71503 loss)
I1210 15:39:01.850210 15772 solver.cpp:218] Iteration 15500 (14.1635 iter/s, 7.06038s/100 iters), loss = 1.80408
I1210 15:39:01.850210 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:39:01.850210 15772 solver.cpp:237]     Train net output #1: loss = 1.80408 (* 1 = 1.80408 loss)
I1210 15:39:01.850210 15772 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1210 15:39:07.468122 15772 solver.cpp:218] Iteration 15600 (17.8038 iter/s, 5.61679s/100 iters), loss = 1.63186
I1210 15:39:07.468122 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:39:07.468122 15772 solver.cpp:237]     Train net output #1: loss = 1.63186 (* 1 = 1.63186 loss)
I1210 15:39:07.468122 15772 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1210 15:39:13.089705 15772 solver.cpp:218] Iteration 15700 (17.7873 iter/s, 5.62199s/100 iters), loss = 1.49636
I1210 15:39:13.090706 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:39:13.090706 15772 solver.cpp:237]     Train net output #1: loss = 1.49636 (* 1 = 1.49636 loss)
I1210 15:39:13.090706 15772 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1210 15:39:18.704949 15772 solver.cpp:218] Iteration 15800 (17.8125 iter/s, 5.61403s/100 iters), loss = 1.87214
I1210 15:39:18.704949 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:39:18.704949 15772 solver.cpp:237]     Train net output #1: loss = 1.87214 (* 1 = 1.87214 loss)
I1210 15:39:18.704949 15772 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1210 15:39:24.331893 15772 solver.cpp:218] Iteration 15900 (17.7725 iter/s, 5.62667s/100 iters), loss = 1.82405
I1210 15:39:24.331893 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:39:24.331893 15772 solver.cpp:237]     Train net output #1: loss = 1.82405 (* 1 = 1.82405 loss)
I1210 15:39:24.331893 15772 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1210 15:39:29.688328 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:39:29.911339 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_16000.caffemodel
I1210 15:39:29.925843 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_16000.solverstate
I1210 15:39:29.930342 15772 solver.cpp:330] Iteration 16000, Testing net (#0)
I1210 15:39:29.930342 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:39:31.297472 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:39:31.351483 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3423
I1210 15:39:31.351483 15772 solver.cpp:397]     Test net output #1: loss = 2.73737 (* 1 = 2.73737 loss)
I1210 15:39:31.404482 15772 solver.cpp:218] Iteration 16000 (14.1397 iter/s, 7.0723s/100 iters), loss = 1.76255
I1210 15:39:31.404482 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:39:31.404482 15772 solver.cpp:237]     Train net output #1: loss = 1.76255 (* 1 = 1.76255 loss)
I1210 15:39:31.404482 15772 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1210 15:39:37.042027 15772 solver.cpp:218] Iteration 16100 (17.7409 iter/s, 5.63668s/100 iters), loss = 1.67079
I1210 15:39:37.042027 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:39:37.042027 15772 solver.cpp:237]     Train net output #1: loss = 1.67079 (* 1 = 1.67079 loss)
I1210 15:39:37.042027 15772 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1210 15:39:42.681488 15772 solver.cpp:218] Iteration 16200 (17.7319 iter/s, 5.63954s/100 iters), loss = 1.37611
I1210 15:39:42.681488 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 15:39:42.681488 15772 solver.cpp:237]     Train net output #1: loss = 1.37611 (* 1 = 1.37611 loss)
I1210 15:39:42.682488 15772 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1210 15:39:48.316938 15772 solver.cpp:218] Iteration 16300 (17.7483 iter/s, 5.63436s/100 iters), loss = 1.91009
I1210 15:39:48.316938 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:39:48.316938 15772 solver.cpp:237]     Train net output #1: loss = 1.91009 (* 1 = 1.91009 loss)
I1210 15:39:48.316938 15772 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1210 15:39:53.945389 15772 solver.cpp:218] Iteration 16400 (17.7667 iter/s, 5.62852s/100 iters), loss = 1.97236
I1210 15:39:53.945389 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:39:53.945389 15772 solver.cpp:237]     Train net output #1: loss = 1.97236 (* 1 = 1.97236 loss)
I1210 15:39:53.945389 15772 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1210 15:39:59.304811 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:39:59.527326 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_16500.caffemodel
I1210 15:39:59.541826 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_16500.solverstate
I1210 15:39:59.545830 15772 solver.cpp:330] Iteration 16500, Testing net (#0)
I1210 15:39:59.546830 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:40:00.924994 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:40:00.979501 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2936
I1210 15:40:00.979501 15772 solver.cpp:397]     Test net output #1: loss = 3.12033 (* 1 = 3.12033 loss)
I1210 15:40:01.033004 15772 solver.cpp:218] Iteration 16500 (14.1105 iter/s, 7.08692s/100 iters), loss = 1.82477
I1210 15:40:01.033004 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:40:01.033004 15772 solver.cpp:237]     Train net output #1: loss = 1.82477 (* 1 = 1.82477 loss)
I1210 15:40:01.033004 15772 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1210 15:40:06.677853 15772 solver.cpp:218] Iteration 16600 (17.7182 iter/s, 5.64393s/100 iters), loss = 1.73474
I1210 15:40:06.677853 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:40:06.677853 15772 solver.cpp:237]     Train net output #1: loss = 1.73474 (* 1 = 1.73474 loss)
I1210 15:40:06.677853 15772 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1210 15:40:12.302901 15772 solver.cpp:218] Iteration 16700 (17.7777 iter/s, 5.62504s/100 iters), loss = 1.42478
I1210 15:40:12.302901 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 15:40:12.302901 15772 solver.cpp:237]     Train net output #1: loss = 1.42478 (* 1 = 1.42478 loss)
I1210 15:40:12.302901 15772 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1210 15:40:17.926362 15772 solver.cpp:218] Iteration 16800 (17.7835 iter/s, 5.6232s/100 iters), loss = 1.9594
I1210 15:40:17.926362 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:40:17.926362 15772 solver.cpp:237]     Train net output #1: loss = 1.9594 (* 1 = 1.9594 loss)
I1210 15:40:17.926362 15772 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1210 15:40:23.554751 15772 solver.cpp:218] Iteration 16900 (17.771 iter/s, 5.62714s/100 iters), loss = 1.78482
I1210 15:40:23.554751 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:40:23.554751 15772 solver.cpp:237]     Train net output #1: loss = 1.78482 (* 1 = 1.78482 loss)
I1210 15:40:23.554751 15772 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1210 15:40:28.903156 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:40:29.125167 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_17000.caffemodel
I1210 15:40:29.141167 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_17000.solverstate
I1210 15:40:29.146169 15772 solver.cpp:330] Iteration 17000, Testing net (#0)
I1210 15:40:29.146169 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:40:30.515264 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:40:30.568765 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3556
I1210 15:40:30.568765 15772 solver.cpp:397]     Test net output #1: loss = 2.5999 (* 1 = 2.5999 loss)
I1210 15:40:30.622268 15772 solver.cpp:218] Iteration 17000 (14.1506 iter/s, 7.06684s/100 iters), loss = 1.85977
I1210 15:40:30.622268 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:40:30.622268 15772 solver.cpp:237]     Train net output #1: loss = 1.85977 (* 1 = 1.85977 loss)
I1210 15:40:30.622268 15772 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1210 15:40:36.245769 15772 solver.cpp:218] Iteration 17100 (17.7838 iter/s, 5.6231s/100 iters), loss = 1.70845
I1210 15:40:36.245769 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:40:36.245769 15772 solver.cpp:237]     Train net output #1: loss = 1.70845 (* 1 = 1.70845 loss)
I1210 15:40:36.245769 15772 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1210 15:40:41.878691 15772 solver.cpp:218] Iteration 17200 (17.7542 iter/s, 5.63245s/100 iters), loss = 1.59934
I1210 15:40:41.878691 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:40:41.878691 15772 solver.cpp:237]     Train net output #1: loss = 1.59934 (* 1 = 1.59934 loss)
I1210 15:40:41.878691 15772 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1210 15:40:47.507633 15772 solver.cpp:218] Iteration 17300 (17.7649 iter/s, 5.62909s/100 iters), loss = 1.88437
I1210 15:40:47.507633 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:40:47.507633 15772 solver.cpp:237]     Train net output #1: loss = 1.88437 (* 1 = 1.88437 loss)
I1210 15:40:47.507633 15772 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1210 15:40:53.133044 15772 solver.cpp:218] Iteration 17400 (17.7798 iter/s, 5.62435s/100 iters), loss = 1.84638
I1210 15:40:53.133044 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:40:53.133044 15772 solver.cpp:237]     Train net output #1: loss = 1.84638 (* 1 = 1.84638 loss)
I1210 15:40:53.133044 15772 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1210 15:40:58.485430 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:40:58.707445 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_17500.caffemodel
I1210 15:40:58.721444 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_17500.solverstate
I1210 15:40:58.726445 15772 solver.cpp:330] Iteration 17500, Testing net (#0)
I1210 15:40:58.726445 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:41:00.095561 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:41:00.149561 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3073
I1210 15:41:00.149561 15772 solver.cpp:397]     Test net output #1: loss = 3.01469 (* 1 = 3.01469 loss)
I1210 15:41:00.204574 15772 solver.cpp:218] Iteration 17500 (14.142 iter/s, 7.07112s/100 iters), loss = 1.94263
I1210 15:41:00.204574 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:41:00.204574 15772 solver.cpp:237]     Train net output #1: loss = 1.94263 (* 1 = 1.94263 loss)
I1210 15:41:00.204574 15772 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1210 15:41:05.827981 15772 solver.cpp:218] Iteration 17600 (17.7837 iter/s, 5.62313s/100 iters), loss = 1.62542
I1210 15:41:05.827981 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:41:05.827981 15772 solver.cpp:237]     Train net output #1: loss = 1.62542 (* 1 = 1.62542 loss)
I1210 15:41:05.827981 15772 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1210 15:41:11.452378 15772 solver.cpp:218] Iteration 17700 (17.7822 iter/s, 5.62361s/100 iters), loss = 1.58291
I1210 15:41:11.452378 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:41:11.452378 15772 solver.cpp:237]     Train net output #1: loss = 1.58291 (* 1 = 1.58291 loss)
I1210 15:41:11.452378 15772 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1210 15:41:17.086282 15772 solver.cpp:218] Iteration 17800 (17.7506 iter/s, 5.6336s/100 iters), loss = 1.84693
I1210 15:41:17.086282 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:41:17.086282 15772 solver.cpp:237]     Train net output #1: loss = 1.84693 (* 1 = 1.84693 loss)
I1210 15:41:17.086282 15772 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1210 15:41:22.717252 15772 solver.cpp:218] Iteration 17900 (17.7603 iter/s, 5.63054s/100 iters), loss = 1.90065
I1210 15:41:22.717252 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 15:41:22.717252 15772 solver.cpp:237]     Train net output #1: loss = 1.90065 (* 1 = 1.90065 loss)
I1210 15:41:22.717252 15772 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1210 15:41:28.070614 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:41:28.291632 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_18000.caffemodel
I1210 15:41:28.306633 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_18000.solverstate
I1210 15:41:28.310633 15772 solver.cpp:330] Iteration 18000, Testing net (#0)
I1210 15:41:28.310633 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:41:29.679754 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:41:29.732758 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3837
I1210 15:41:29.732758 15772 solver.cpp:397]     Test net output #1: loss = 2.40564 (* 1 = 2.40564 loss)
I1210 15:41:29.786759 15772 solver.cpp:218] Iteration 18000 (14.1465 iter/s, 7.06886s/100 iters), loss = 1.81636
I1210 15:41:29.786759 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:41:29.786759 15772 solver.cpp:237]     Train net output #1: loss = 1.81636 (* 1 = 1.81636 loss)
I1210 15:41:29.786759 15772 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1210 15:41:35.413249 15772 solver.cpp:218] Iteration 18100 (17.774 iter/s, 5.62621s/100 iters), loss = 1.57434
I1210 15:41:35.413249 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:41:35.413249 15772 solver.cpp:237]     Train net output #1: loss = 1.57434 (* 1 = 1.57434 loss)
I1210 15:41:35.413249 15772 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1210 15:41:41.030082 15772 solver.cpp:218] Iteration 18200 (17.8026 iter/s, 5.61714s/100 iters), loss = 1.52693
I1210 15:41:41.031095 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:41:41.031095 15772 solver.cpp:237]     Train net output #1: loss = 1.52693 (* 1 = 1.52693 loss)
I1210 15:41:41.031095 15772 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1210 15:41:46.651816 15772 solver.cpp:218] Iteration 18300 (17.7928 iter/s, 5.62025s/100 iters), loss = 1.85772
I1210 15:41:46.651816 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:41:46.651816 15772 solver.cpp:237]     Train net output #1: loss = 1.85772 (* 1 = 1.85772 loss)
I1210 15:41:46.651816 15772 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1210 15:41:52.266276 15772 solver.cpp:218] Iteration 18400 (17.8097 iter/s, 5.61493s/100 iters), loss = 1.79782
I1210 15:41:52.267276 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:41:52.267276 15772 solver.cpp:237]     Train net output #1: loss = 1.79782 (* 1 = 1.79782 loss)
I1210 15:41:52.267276 15772 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1210 15:41:57.605049 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:41:57.826170 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_18500.caffemodel
I1210 15:41:57.842171 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_18500.solverstate
I1210 15:41:57.847172 15772 solver.cpp:330] Iteration 18500, Testing net (#0)
I1210 15:41:57.847172 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:41:59.217823 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:41:59.271824 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3529
I1210 15:41:59.271824 15772 solver.cpp:397]     Test net output #1: loss = 2.79234 (* 1 = 2.79234 loss)
I1210 15:41:59.324947 15772 solver.cpp:218] Iteration 18500 (14.1682 iter/s, 7.05807s/100 iters), loss = 1.76853
I1210 15:41:59.324947 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:41:59.324947 15772 solver.cpp:237]     Train net output #1: loss = 1.76853 (* 1 = 1.76853 loss)
I1210 15:41:59.324947 15772 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1210 15:42:04.953639 15772 solver.cpp:218] Iteration 18600 (17.7702 iter/s, 5.62739s/100 iters), loss = 1.64672
I1210 15:42:04.953639 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:42:04.953639 15772 solver.cpp:237]     Train net output #1: loss = 1.64672 (* 1 = 1.64672 loss)
I1210 15:42:04.953639 15772 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1210 15:42:10.588436 15772 solver.cpp:218] Iteration 18700 (17.7481 iter/s, 5.6344s/100 iters), loss = 1.54298
I1210 15:42:10.588436 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 15:42:10.588436 15772 solver.cpp:237]     Train net output #1: loss = 1.54298 (* 1 = 1.54298 loss)
I1210 15:42:10.588436 15772 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1210 15:42:16.224963 15772 solver.cpp:218] Iteration 18800 (17.7415 iter/s, 5.6365s/100 iters), loss = 1.97623
I1210 15:42:16.224963 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:42:16.224963 15772 solver.cpp:237]     Train net output #1: loss = 1.97623 (* 1 = 1.97623 loss)
I1210 15:42:16.224963 15772 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1210 15:42:21.867369 15772 solver.cpp:218] Iteration 18900 (17.7256 iter/s, 5.64157s/100 iters), loss = 1.84254
I1210 15:42:21.867369 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:42:21.867369 15772 solver.cpp:237]     Train net output #1: loss = 1.84254 (* 1 = 1.84254 loss)
I1210 15:42:21.867369 15772 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1210 15:42:27.237736 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:42:27.458760 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_19000.caffemodel
I1210 15:42:27.474759 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_19000.solverstate
I1210 15:42:27.479760 15772 solver.cpp:330] Iteration 19000, Testing net (#0)
I1210 15:42:27.479760 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:42:28.850895 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:42:28.905401 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2934
I1210 15:42:28.905401 15772 solver.cpp:397]     Test net output #1: loss = 3.1438 (* 1 = 3.1438 loss)
I1210 15:42:28.959908 15772 solver.cpp:218] Iteration 19000 (14.0997 iter/s, 7.09234s/100 iters), loss = 1.76428
I1210 15:42:28.959908 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:42:28.959908 15772 solver.cpp:237]     Train net output #1: loss = 1.76428 (* 1 = 1.76428 loss)
I1210 15:42:28.959908 15772 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1210 15:42:34.598815 15772 solver.cpp:218] Iteration 19100 (17.7361 iter/s, 5.63822s/100 iters), loss = 1.67031
I1210 15:42:34.598815 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:42:34.598815 15772 solver.cpp:237]     Train net output #1: loss = 1.67031 (* 1 = 1.67031 loss)
I1210 15:42:34.598815 15772 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1210 15:42:40.248783 15772 solver.cpp:218] Iteration 19200 (17.7002 iter/s, 5.64965s/100 iters), loss = 1.43115
I1210 15:42:40.248783 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 15:42:40.248783 15772 solver.cpp:237]     Train net output #1: loss = 1.43115 (* 1 = 1.43115 loss)
I1210 15:42:40.248783 15772 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1210 15:42:45.890272 15772 solver.cpp:218] Iteration 19300 (17.7263 iter/s, 5.64134s/100 iters), loss = 1.96658
I1210 15:42:45.890272 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:42:45.890272 15772 solver.cpp:237]     Train net output #1: loss = 1.96658 (* 1 = 1.96658 loss)
I1210 15:42:45.890272 15772 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1210 15:42:51.533771 15772 solver.cpp:218] Iteration 19400 (17.7205 iter/s, 5.64318s/100 iters), loss = 1.82089
I1210 15:42:51.533771 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:42:51.533771 15772 solver.cpp:237]     Train net output #1: loss = 1.82089 (* 1 = 1.82089 loss)
I1210 15:42:51.533771 15772 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1210 15:42:56.901213 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:42:57.123229 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_19500.caffemodel
I1210 15:42:57.137230 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_19500.solverstate
I1210 15:42:57.142231 15772 solver.cpp:330] Iteration 19500, Testing net (#0)
I1210 15:42:57.142231 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:42:58.516779 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:42:58.568779 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3006
I1210 15:42:58.568779 15772 solver.cpp:397]     Test net output #1: loss = 2.9785 (* 1 = 2.9785 loss)
I1210 15:42:58.624788 15772 solver.cpp:218] Iteration 19500 (14.1046 iter/s, 7.0899s/100 iters), loss = 1.80045
I1210 15:42:58.624788 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:42:58.624788 15772 solver.cpp:237]     Train net output #1: loss = 1.80045 (* 1 = 1.80045 loss)
I1210 15:42:58.624788 15772 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1210 15:43:04.265290 15772 solver.cpp:218] Iteration 19600 (17.7306 iter/s, 5.63997s/100 iters), loss = 1.65646
I1210 15:43:04.265290 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:43:04.265290 15772 solver.cpp:237]     Train net output #1: loss = 1.65646 (* 1 = 1.65646 loss)
I1210 15:43:04.265290 15772 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1210 15:43:09.908229 15772 solver.cpp:218] Iteration 19700 (17.7217 iter/s, 5.64278s/100 iters), loss = 1.40231
I1210 15:43:09.908730 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 15:43:09.908730 15772 solver.cpp:237]     Train net output #1: loss = 1.40231 (* 1 = 1.40231 loss)
I1210 15:43:09.908730 15772 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1210 15:43:15.546180 15772 solver.cpp:218] Iteration 19800 (17.7395 iter/s, 5.63715s/100 iters), loss = 1.91901
I1210 15:43:15.546180 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:43:15.546180 15772 solver.cpp:237]     Train net output #1: loss = 1.91901 (* 1 = 1.91901 loss)
I1210 15:43:15.546180 15772 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1210 15:43:21.172950 15772 solver.cpp:218] Iteration 19900 (17.7724 iter/s, 5.62671s/100 iters), loss = 1.88203
I1210 15:43:21.172950 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:43:21.172950 15772 solver.cpp:237]     Train net output #1: loss = 1.88203 (* 1 = 1.88203 loss)
I1210 15:43:21.172950 15772 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1210 15:43:26.545462 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:43:26.765472 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_20000.caffemodel
I1210 15:43:26.780472 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_20000.solverstate
I1210 15:43:26.784473 15772 solver.cpp:330] Iteration 20000, Testing net (#0)
I1210 15:43:26.784473 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:43:28.156621 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:43:28.210134 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3619
I1210 15:43:28.210134 15772 solver.cpp:397]     Test net output #1: loss = 2.59806 (* 1 = 2.59806 loss)
I1210 15:43:28.265646 15772 solver.cpp:218] Iteration 20000 (14.1005 iter/s, 7.09197s/100 iters), loss = 1.75363
I1210 15:43:28.265646 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:43:28.265646 15772 solver.cpp:237]     Train net output #1: loss = 1.75363 (* 1 = 1.75363 loss)
I1210 15:43:28.265646 15772 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1210 15:43:33.924278 15772 solver.cpp:218] Iteration 20100 (17.674 iter/s, 5.65804s/100 iters), loss = 1.83922
I1210 15:43:33.924278 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:43:33.924278 15772 solver.cpp:237]     Train net output #1: loss = 1.83922 (* 1 = 1.83922 loss)
I1210 15:43:33.924278 15772 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1210 15:43:39.579746 15772 solver.cpp:218] Iteration 20200 (17.6819 iter/s, 5.65551s/100 iters), loss = 1.53433
I1210 15:43:39.579746 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:43:39.579746 15772 solver.cpp:237]     Train net output #1: loss = 1.53433 (* 1 = 1.53433 loss)
I1210 15:43:39.579746 15772 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1210 15:43:45.240202 15772 solver.cpp:218] Iteration 20300 (17.6679 iter/s, 5.65997s/100 iters), loss = 1.89522
I1210 15:43:45.240202 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:43:45.240202 15772 solver.cpp:237]     Train net output #1: loss = 1.89522 (* 1 = 1.89522 loss)
I1210 15:43:45.240202 15772 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1210 15:43:50.888494 15772 solver.cpp:218] Iteration 20400 (17.7066 iter/s, 5.6476s/100 iters), loss = 2.01373
I1210 15:43:50.888494 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:43:50.888494 15772 solver.cpp:237]     Train net output #1: loss = 2.01373 (* 1 = 2.01373 loss)
I1210 15:43:50.888494 15772 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1210 15:43:56.256542 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:43:56.480073 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_20500.caffemodel
I1210 15:43:56.496071 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_20500.solverstate
I1210 15:43:56.500087 15772 solver.cpp:330] Iteration 20500, Testing net (#0)
I1210 15:43:56.500087 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:43:57.869335 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:43:57.923835 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3156
I1210 15:43:57.923835 15772 solver.cpp:397]     Test net output #1: loss = 2.97227 (* 1 = 2.97227 loss)
I1210 15:43:57.976850 15772 solver.cpp:218] Iteration 20500 (14.1078 iter/s, 7.08827s/100 iters), loss = 1.86139
I1210 15:43:57.976850 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:43:57.976850 15772 solver.cpp:237]     Train net output #1: loss = 1.86139 (* 1 = 1.86139 loss)
I1210 15:43:57.976850 15772 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1210 15:44:03.616080 15772 solver.cpp:218] Iteration 20600 (17.7366 iter/s, 5.63805s/100 iters), loss = 1.69087
I1210 15:44:03.616080 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:44:03.616080 15772 solver.cpp:237]     Train net output #1: loss = 1.69087 (* 1 = 1.69087 loss)
I1210 15:44:03.616080 15772 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1210 15:44:09.265022 15772 solver.cpp:218] Iteration 20700 (17.7038 iter/s, 5.6485s/100 iters), loss = 1.38904
I1210 15:44:09.265022 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 15:44:09.265022 15772 solver.cpp:237]     Train net output #1: loss = 1.38904 (* 1 = 1.38904 loss)
I1210 15:44:09.265022 15772 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1210 15:44:14.921367 15772 solver.cpp:218] Iteration 20800 (17.6808 iter/s, 5.65585s/100 iters), loss = 1.82497
I1210 15:44:14.921367 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:44:14.921367 15772 solver.cpp:237]     Train net output #1: loss = 1.82497 (* 1 = 1.82497 loss)
I1210 15:44:14.921367 15772 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1210 15:44:20.576503 15772 solver.cpp:218] Iteration 20900 (17.6851 iter/s, 5.65448s/100 iters), loss = 1.98908
I1210 15:44:20.576503 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:44:20.576503 15772 solver.cpp:237]     Train net output #1: loss = 1.98908 (* 1 = 1.98908 loss)
I1210 15:44:20.576503 15772 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1210 15:44:25.939515 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:44:26.162051 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_21000.caffemodel
I1210 15:44:26.176568 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_21000.solverstate
I1210 15:44:26.180567 15772 solver.cpp:330] Iteration 21000, Testing net (#0)
I1210 15:44:26.180567 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:44:27.548382 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:44:27.603916 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3613
I1210 15:44:27.603916 15772 solver.cpp:397]     Test net output #1: loss = 2.72719 (* 1 = 2.72719 loss)
I1210 15:44:27.657917 15772 solver.cpp:218] Iteration 21000 (14.1222 iter/s, 7.08107s/100 iters), loss = 1.67512
I1210 15:44:27.657917 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:44:27.657917 15772 solver.cpp:237]     Train net output #1: loss = 1.67512 (* 1 = 1.67512 loss)
I1210 15:44:27.657917 15772 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1210 15:44:33.304651 15772 solver.cpp:218] Iteration 21100 (17.7084 iter/s, 5.64703s/100 iters), loss = 1.80588
I1210 15:44:33.304651 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:44:33.304651 15772 solver.cpp:237]     Train net output #1: loss = 1.80588 (* 1 = 1.80588 loss)
I1210 15:44:33.304651 15772 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1210 15:44:38.950459 15772 solver.cpp:218] Iteration 21200 (17.715 iter/s, 5.64495s/100 iters), loss = 1.68929
I1210 15:44:38.950459 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:44:38.950459 15772 solver.cpp:237]     Train net output #1: loss = 1.68929 (* 1 = 1.68929 loss)
I1210 15:44:38.950459 15772 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1210 15:44:44.597014 15772 solver.cpp:218] Iteration 21300 (17.7116 iter/s, 5.64601s/100 iters), loss = 1.87872
I1210 15:44:44.597014 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:44:44.597014 15772 solver.cpp:237]     Train net output #1: loss = 1.87872 (* 1 = 1.87872 loss)
I1210 15:44:44.597014 15772 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1210 15:44:50.248682 15772 solver.cpp:218] Iteration 21400 (17.6966 iter/s, 5.65081s/100 iters), loss = 1.81242
I1210 15:44:50.248682 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:44:50.248682 15772 solver.cpp:237]     Train net output #1: loss = 1.81242 (* 1 = 1.81242 loss)
I1210 15:44:50.248682 15772 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1210 15:44:55.613453 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:44:55.837462 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_21500.caffemodel
I1210 15:44:55.850463 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_21500.solverstate
I1210 15:44:55.855463 15772 solver.cpp:330] Iteration 21500, Testing net (#0)
I1210 15:44:55.855463 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:44:57.227592 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:44:57.281594 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3241
I1210 15:44:57.281594 15772 solver.cpp:397]     Test net output #1: loss = 2.88067 (* 1 = 2.88067 loss)
I1210 15:44:57.334596 15772 solver.cpp:218] Iteration 21500 (14.1116 iter/s, 7.08635s/100 iters), loss = 1.79589
I1210 15:44:57.335602 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:44:57.335602 15772 solver.cpp:237]     Train net output #1: loss = 1.79589 (* 1 = 1.79589 loss)
I1210 15:44:57.335602 15772 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1210 15:45:02.972630 15772 solver.cpp:218] Iteration 21600 (17.7404 iter/s, 5.63685s/100 iters), loss = 1.58036
I1210 15:45:02.972630 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:45:02.973132 15772 solver.cpp:237]     Train net output #1: loss = 1.58036 (* 1 = 1.58036 loss)
I1210 15:45:02.973132 15772 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1210 15:45:08.612538 15772 solver.cpp:218] Iteration 21700 (17.731 iter/s, 5.63984s/100 iters), loss = 1.38968
I1210 15:45:08.612538 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 15:45:08.612538 15772 solver.cpp:237]     Train net output #1: loss = 1.38968 (* 1 = 1.38968 loss)
I1210 15:45:08.612538 15772 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1210 15:45:14.259950 15772 solver.cpp:218] Iteration 21800 (17.7104 iter/s, 5.6464s/100 iters), loss = 1.82709
I1210 15:45:14.259950 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:45:14.259950 15772 solver.cpp:237]     Train net output #1: loss = 1.82709 (* 1 = 1.82709 loss)
I1210 15:45:14.259950 15772 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1210 15:45:19.891526 15772 solver.cpp:218] Iteration 21900 (17.7563 iter/s, 5.63181s/100 iters), loss = 1.68893
I1210 15:45:19.891526 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:45:19.891526 15772 solver.cpp:237]     Train net output #1: loss = 1.68893 (* 1 = 1.68893 loss)
I1210 15:45:19.892527 15772 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1210 15:45:25.244987 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:45:25.467999 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_22000.caffemodel
I1210 15:45:25.484005 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_22000.solverstate
I1210 15:45:25.488505 15772 solver.cpp:330] Iteration 22000, Testing net (#0)
I1210 15:45:25.488505 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:45:26.859141 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:45:26.914151 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3992
I1210 15:45:26.914151 15772 solver.cpp:397]     Test net output #1: loss = 2.31632 (* 1 = 2.31632 loss)
I1210 15:45:26.968152 15772 solver.cpp:218] Iteration 22000 (14.133 iter/s, 7.07564s/100 iters), loss = 1.68224
I1210 15:45:26.968152 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:45:26.968152 15772 solver.cpp:237]     Train net output #1: loss = 1.68224 (* 1 = 1.68224 loss)
I1210 15:45:26.968152 15772 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1210 15:45:32.619565 15772 solver.cpp:218] Iteration 22100 (17.6965 iter/s, 5.65084s/100 iters), loss = 1.59873
I1210 15:45:32.619565 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:45:32.619565 15772 solver.cpp:237]     Train net output #1: loss = 1.59873 (* 1 = 1.59873 loss)
I1210 15:45:32.619565 15772 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1210 15:45:38.268007 15772 solver.cpp:218] Iteration 22200 (17.7047 iter/s, 5.64823s/100 iters), loss = 1.4872
I1210 15:45:38.268007 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:45:38.268007 15772 solver.cpp:237]     Train net output #1: loss = 1.4872 (* 1 = 1.4872 loss)
I1210 15:45:38.268007 15772 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1210 15:45:43.910390 15772 solver.cpp:218] Iteration 22300 (17.7255 iter/s, 5.6416s/100 iters), loss = 1.8957
I1210 15:45:43.910390 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:45:43.910390 15772 solver.cpp:237]     Train net output #1: loss = 1.8957 (* 1 = 1.8957 loss)
I1210 15:45:43.910390 15772 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1210 15:45:49.563359 15772 solver.cpp:218] Iteration 22400 (17.6912 iter/s, 5.65253s/100 iters), loss = 1.9286
I1210 15:45:49.563359 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:45:49.563359 15772 solver.cpp:237]     Train net output #1: loss = 1.9286 (* 1 = 1.9286 loss)
I1210 15:45:49.563359 15772 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1210 15:45:54.925817 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:45:55.148865 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_22500.caffemodel
I1210 15:45:55.164849 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_22500.solverstate
I1210 15:45:55.169863 15772 solver.cpp:330] Iteration 22500, Testing net (#0)
I1210 15:45:55.169863 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:45:56.542950 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:45:56.594949 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3987
I1210 15:45:56.594949 15772 solver.cpp:397]     Test net output #1: loss = 2.27441 (* 1 = 2.27441 loss)
I1210 15:45:56.648954 15772 solver.cpp:218] Iteration 22500 (14.1142 iter/s, 7.08508s/100 iters), loss = 1.89155
I1210 15:45:56.648954 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 15:45:56.648954 15772 solver.cpp:237]     Train net output #1: loss = 1.89155 (* 1 = 1.89155 loss)
I1210 15:45:56.648954 15772 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1210 15:46:02.307417 15772 solver.cpp:218] Iteration 22600 (17.6743 iter/s, 5.65795s/100 iters), loss = 1.6519
I1210 15:46:02.307417 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:46:02.307417 15772 solver.cpp:237]     Train net output #1: loss = 1.6519 (* 1 = 1.6519 loss)
I1210 15:46:02.307417 15772 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1210 15:46:07.956815 15772 solver.cpp:218] Iteration 22700 (17.7006 iter/s, 5.64954s/100 iters), loss = 1.48588
I1210 15:46:07.956815 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 15:46:07.956815 15772 solver.cpp:237]     Train net output #1: loss = 1.48588 (* 1 = 1.48588 loss)
I1210 15:46:07.956815 15772 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1210 15:46:13.599277 15772 solver.cpp:218] Iteration 22800 (17.7235 iter/s, 5.64222s/100 iters), loss = 1.8859
I1210 15:46:13.599277 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:46:13.599277 15772 solver.cpp:237]     Train net output #1: loss = 1.8859 (* 1 = 1.8859 loss)
I1210 15:46:13.599277 15772 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1210 15:46:19.236709 15772 solver.cpp:218] Iteration 22900 (17.7398 iter/s, 5.63705s/100 iters), loss = 1.99546
I1210 15:46:19.236709 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:46:19.236709 15772 solver.cpp:237]     Train net output #1: loss = 1.99546 (* 1 = 1.99546 loss)
I1210 15:46:19.236709 15772 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1210 15:46:24.606113 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:46:24.829130 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_23000.caffemodel
I1210 15:46:24.843130 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_23000.solverstate
I1210 15:46:24.847131 15772 solver.cpp:330] Iteration 23000, Testing net (#0)
I1210 15:46:24.847131 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:46:26.219710 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:46:26.274217 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3908
I1210 15:46:26.274217 15772 solver.cpp:397]     Test net output #1: loss = 2.33005 (* 1 = 2.33005 loss)
I1210 15:46:26.328217 15772 solver.cpp:218] Iteration 23000 (14.1024 iter/s, 7.09099s/100 iters), loss = 1.67014
I1210 15:46:26.328217 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:46:26.328217 15772 solver.cpp:237]     Train net output #1: loss = 1.67014 (* 1 = 1.67014 loss)
I1210 15:46:26.328217 15772 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1210 15:46:31.985622 15772 solver.cpp:218] Iteration 23100 (17.6789 iter/s, 5.65645s/100 iters), loss = 1.49013
I1210 15:46:31.985622 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:46:31.985622 15772 solver.cpp:237]     Train net output #1: loss = 1.49013 (* 1 = 1.49013 loss)
I1210 15:46:31.985622 15772 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1210 15:46:37.636045 15772 solver.cpp:218] Iteration 23200 (17.6977 iter/s, 5.65044s/100 iters), loss = 1.50595
I1210 15:46:37.636045 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:46:37.636045 15772 solver.cpp:237]     Train net output #1: loss = 1.50595 (* 1 = 1.50595 loss)
I1210 15:46:37.636045 15772 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1210 15:46:43.274588 15772 solver.cpp:218] Iteration 23300 (17.7381 iter/s, 5.63757s/100 iters), loss = 1.81468
I1210 15:46:43.274588 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:46:43.274588 15772 solver.cpp:237]     Train net output #1: loss = 1.81468 (* 1 = 1.81468 loss)
I1210 15:46:43.274588 15772 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1210 15:46:48.910681 15772 solver.cpp:218] Iteration 23400 (17.7421 iter/s, 5.6363s/100 iters), loss = 1.80434
I1210 15:46:48.911671 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:46:48.911671 15772 solver.cpp:237]     Train net output #1: loss = 1.80434 (* 1 = 1.80434 loss)
I1210 15:46:48.911671 15772 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1210 15:46:54.272848 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:46:54.494859 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_23500.caffemodel
I1210 15:46:54.509860 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_23500.solverstate
I1210 15:46:54.514366 15772 solver.cpp:330] Iteration 23500, Testing net (#0)
I1210 15:46:54.514366 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:46:55.882563 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:46:55.938573 15772 solver.cpp:397]     Test net output #0: accuracy = 0.41
I1210 15:46:55.938573 15772 solver.cpp:397]     Test net output #1: loss = 2.30114 (* 1 = 2.30114 loss)
I1210 15:46:55.991574 15772 solver.cpp:218] Iteration 23500 (14.124 iter/s, 7.08014s/100 iters), loss = 1.72947
I1210 15:46:55.991574 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:46:55.991574 15772 solver.cpp:237]     Train net output #1: loss = 1.72947 (* 1 = 1.72947 loss)
I1210 15:46:55.991574 15772 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1210 15:47:01.635181 15772 solver.cpp:218] Iteration 23600 (17.7196 iter/s, 5.64346s/100 iters), loss = 1.507
I1210 15:47:01.636188 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:47:01.636188 15772 solver.cpp:237]     Train net output #1: loss = 1.507 (* 1 = 1.507 loss)
I1210 15:47:01.636188 15772 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1210 15:47:07.271688 15772 solver.cpp:218] Iteration 23700 (17.7446 iter/s, 5.63551s/100 iters), loss = 1.5152
I1210 15:47:07.271688 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 15:47:07.271688 15772 solver.cpp:237]     Train net output #1: loss = 1.5152 (* 1 = 1.5152 loss)
I1210 15:47:07.271688 15772 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1210 15:47:12.916348 15772 solver.cpp:218] Iteration 23800 (17.7186 iter/s, 5.64379s/100 iters), loss = 1.90073
I1210 15:47:12.916348 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:47:12.916348 15772 solver.cpp:237]     Train net output #1: loss = 1.90073 (* 1 = 1.90073 loss)
I1210 15:47:12.916348 15772 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1210 15:47:18.560890 15772 solver.cpp:218] Iteration 23900 (17.715 iter/s, 5.64493s/100 iters), loss = 1.62169
I1210 15:47:18.560890 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:47:18.560890 15772 solver.cpp:237]     Train net output #1: loss = 1.62169 (* 1 = 1.62169 loss)
I1210 15:47:18.560890 15772 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1210 15:47:23.929342 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:47:24.150362 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_24000.caffemodel
I1210 15:47:24.165362 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_24000.solverstate
I1210 15:47:24.170362 15772 solver.cpp:330] Iteration 24000, Testing net (#0)
I1210 15:47:24.170362 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:47:25.543529 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:47:25.598531 15772 solver.cpp:397]     Test net output #0: accuracy = 0.399
I1210 15:47:25.598531 15772 solver.cpp:397]     Test net output #1: loss = 2.3686 (* 1 = 2.3686 loss)
I1210 15:47:25.651538 15772 solver.cpp:218] Iteration 24000 (14.1049 iter/s, 7.08975s/100 iters), loss = 1.63794
I1210 15:47:25.651538 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:47:25.651538 15772 solver.cpp:237]     Train net output #1: loss = 1.63794 (* 1 = 1.63794 loss)
I1210 15:47:25.651538 15772 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1210 15:47:31.294976 15772 solver.cpp:218] Iteration 24100 (17.7203 iter/s, 5.64325s/100 iters), loss = 1.55808
I1210 15:47:31.294976 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:47:31.294976 15772 solver.cpp:237]     Train net output #1: loss = 1.55808 (* 1 = 1.55808 loss)
I1210 15:47:31.294976 15772 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1210 15:47:36.939687 15772 solver.cpp:218] Iteration 24200 (17.7189 iter/s, 5.6437s/100 iters), loss = 1.44685
I1210 15:47:36.939687 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:47:36.939687 15772 solver.cpp:237]     Train net output #1: loss = 1.44685 (* 1 = 1.44685 loss)
I1210 15:47:36.939687 15772 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1210 15:47:42.574435 15772 solver.cpp:218] Iteration 24300 (17.7482 iter/s, 5.63438s/100 iters), loss = 1.96954
I1210 15:47:42.574435 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:47:42.574435 15772 solver.cpp:237]     Train net output #1: loss = 1.96954 (* 1 = 1.96954 loss)
I1210 15:47:42.574435 15772 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1210 15:47:48.228464 15772 solver.cpp:218] Iteration 24400 (17.6888 iter/s, 5.6533s/100 iters), loss = 1.6552
I1210 15:47:48.228464 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:47:48.228464 15772 solver.cpp:237]     Train net output #1: loss = 1.6552 (* 1 = 1.6552 loss)
I1210 15:47:48.228464 15772 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1210 15:47:53.595466 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:47:53.816478 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_24500.caffemodel
I1210 15:47:53.832481 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_24500.solverstate
I1210 15:47:53.837487 15772 solver.cpp:330] Iteration 24500, Testing net (#0)
I1210 15:47:53.837487 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:47:55.208638 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:47:55.264648 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3543
I1210 15:47:55.264648 15772 solver.cpp:397]     Test net output #1: loss = 2.64545 (* 1 = 2.64545 loss)
I1210 15:47:55.317652 15772 solver.cpp:218] Iteration 24500 (14.1064 iter/s, 7.08898s/100 iters), loss = 1.65377
I1210 15:47:55.317652 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:47:55.317652 15772 solver.cpp:237]     Train net output #1: loss = 1.65377 (* 1 = 1.65377 loss)
I1210 15:47:55.317652 15772 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1210 15:48:00.948086 15772 solver.cpp:218] Iteration 24600 (17.7631 iter/s, 5.62964s/100 iters), loss = 1.8079
I1210 15:48:00.948086 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:48:00.948086 15772 solver.cpp:237]     Train net output #1: loss = 1.8079 (* 1 = 1.8079 loss)
I1210 15:48:00.948086 15772 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1210 15:48:06.589514 15772 solver.cpp:218] Iteration 24700 (17.7246 iter/s, 5.64187s/100 iters), loss = 1.60064
I1210 15:48:06.590513 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:48:06.590513 15772 solver.cpp:237]     Train net output #1: loss = 1.60064 (* 1 = 1.60064 loss)
I1210 15:48:06.590513 15772 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1210 15:48:12.229801 15772 solver.cpp:218] Iteration 24800 (17.7332 iter/s, 5.63915s/100 iters), loss = 1.87279
I1210 15:48:12.229801 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:48:12.229801 15772 solver.cpp:237]     Train net output #1: loss = 1.87279 (* 1 = 1.87279 loss)
I1210 15:48:12.229801 15772 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1210 15:48:17.868183 15772 solver.cpp:218] Iteration 24900 (17.7365 iter/s, 5.63809s/100 iters), loss = 1.66437
I1210 15:48:17.868183 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:48:17.868183 15772 solver.cpp:237]     Train net output #1: loss = 1.66437 (* 1 = 1.66437 loss)
I1210 15:48:17.868183 15772 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1210 15:48:23.221580 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:48:23.441594 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_25000.caffemodel
I1210 15:48:23.456594 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_25000.solverstate
I1210 15:48:23.460593 15772 solver.cpp:330] Iteration 25000, Testing net (#0)
I1210 15:48:23.460593 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:48:24.831720 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:48:24.884711 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2982
I1210 15:48:24.884711 15772 solver.cpp:397]     Test net output #1: loss = 3.25803 (* 1 = 3.25803 loss)
I1210 15:48:24.940718 15772 solver.cpp:218] Iteration 25000 (14.14 iter/s, 7.07214s/100 iters), loss = 1.64051
I1210 15:48:24.940718 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 15:48:24.940718 15772 solver.cpp:237]     Train net output #1: loss = 1.64051 (* 1 = 1.64051 loss)
I1210 15:48:24.940718 15772 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1210 15:48:30.604081 15772 solver.cpp:218] Iteration 25100 (17.6604 iter/s, 5.66237s/100 iters), loss = 1.67115
I1210 15:48:30.604081 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:48:30.604081 15772 solver.cpp:237]     Train net output #1: loss = 1.67115 (* 1 = 1.67115 loss)
I1210 15:48:30.604081 15772 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1210 15:48:36.260494 15772 solver.cpp:218] Iteration 25200 (17.6783 iter/s, 5.65665s/100 iters), loss = 1.40311
I1210 15:48:36.260494 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 15:48:36.260494 15772 solver.cpp:237]     Train net output #1: loss = 1.40311 (* 1 = 1.40311 loss)
I1210 15:48:36.260494 15772 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1210 15:48:41.912045 15772 solver.cpp:218] Iteration 25300 (17.6965 iter/s, 5.65084s/100 iters), loss = 1.78683
I1210 15:48:41.912045 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:48:41.912045 15772 solver.cpp:237]     Train net output #1: loss = 1.78683 (* 1 = 1.78683 loss)
I1210 15:48:41.912045 15772 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1210 15:48:47.575603 15772 solver.cpp:218] Iteration 25400 (17.6569 iter/s, 5.66351s/100 iters), loss = 1.69356
I1210 15:48:47.576601 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:48:47.576601 15772 solver.cpp:237]     Train net output #1: loss = 1.69356 (* 1 = 1.69356 loss)
I1210 15:48:47.576601 15772 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1210 15:48:52.952472 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:48:53.174046 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_25500.caffemodel
I1210 15:48:53.189026 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_25500.solverstate
I1210 15:48:53.194028 15772 solver.cpp:330] Iteration 25500, Testing net (#0)
I1210 15:48:53.194028 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:48:54.562492 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:48:54.617287 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3467
I1210 15:48:54.617287 15772 solver.cpp:397]     Test net output #1: loss = 2.74468 (* 1 = 2.74468 loss)
I1210 15:48:54.671281 15772 solver.cpp:218] Iteration 25500 (14.0943 iter/s, 7.09504s/100 iters), loss = 1.67519
I1210 15:48:54.671281 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:48:54.671281 15772 solver.cpp:237]     Train net output #1: loss = 1.67519 (* 1 = 1.67519 loss)
I1210 15:48:54.671281 15772 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1210 15:49:00.318794 15772 solver.cpp:218] Iteration 25600 (17.7107 iter/s, 5.64631s/100 iters), loss = 1.74378
I1210 15:49:00.318794 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:49:00.318794 15772 solver.cpp:237]     Train net output #1: loss = 1.74378 (* 1 = 1.74378 loss)
I1210 15:49:00.318794 15772 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1210 15:49:05.957438 15772 solver.cpp:218] Iteration 25700 (17.7343 iter/s, 5.63878s/100 iters), loss = 1.3736
I1210 15:49:05.957438 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 15:49:05.957438 15772 solver.cpp:237]     Train net output #1: loss = 1.3736 (* 1 = 1.3736 loss)
I1210 15:49:05.957438 15772 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1210 15:49:11.600950 15772 solver.cpp:218] Iteration 25800 (17.7205 iter/s, 5.64317s/100 iters), loss = 1.90908
I1210 15:49:11.600950 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:49:11.600950 15772 solver.cpp:237]     Train net output #1: loss = 1.90908 (* 1 = 1.90908 loss)
I1210 15:49:11.600950 15772 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1210 15:49:17.249414 15772 solver.cpp:218] Iteration 25900 (17.707 iter/s, 5.64748s/100 iters), loss = 1.75407
I1210 15:49:17.249414 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 15:49:17.249414 15772 solver.cpp:237]     Train net output #1: loss = 1.75407 (* 1 = 1.75407 loss)
I1210 15:49:17.249414 15772 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1210 15:49:22.619874 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:49:22.840891 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_26000.caffemodel
I1210 15:49:22.855891 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_26000.solverstate
I1210 15:49:22.859891 15772 solver.cpp:330] Iteration 26000, Testing net (#0)
I1210 15:49:22.859891 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:49:24.235049 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:49:24.290050 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2768
I1210 15:49:24.291050 15772 solver.cpp:397]     Test net output #1: loss = 3.31267 (* 1 = 3.31267 loss)
I1210 15:49:24.344055 15772 solver.cpp:218] Iteration 26000 (14.0956 iter/s, 7.09442s/100 iters), loss = 1.63977
I1210 15:49:24.344055 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:49:24.344055 15772 solver.cpp:237]     Train net output #1: loss = 1.63977 (* 1 = 1.63977 loss)
I1210 15:49:24.344055 15772 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1210 15:49:29.978518 15772 solver.cpp:218] Iteration 26100 (17.7504 iter/s, 5.63368s/100 iters), loss = 1.51155
I1210 15:49:29.978518 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:49:29.978518 15772 solver.cpp:237]     Train net output #1: loss = 1.51155 (* 1 = 1.51155 loss)
I1210 15:49:29.978518 15772 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1210 15:49:35.612448 15772 solver.cpp:218] Iteration 26200 (17.7506 iter/s, 5.6336s/100 iters), loss = 1.32509
I1210 15:49:35.612448 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 15:49:35.612448 15772 solver.cpp:237]     Train net output #1: loss = 1.32509 (* 1 = 1.32509 loss)
I1210 15:49:35.612448 15772 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1210 15:49:41.252384 15772 solver.cpp:218] Iteration 26300 (17.7318 iter/s, 5.63958s/100 iters), loss = 1.82763
I1210 15:49:41.252384 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:49:41.252384 15772 solver.cpp:237]     Train net output #1: loss = 1.82763 (* 1 = 1.82763 loss)
I1210 15:49:41.252384 15772 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1210 15:49:46.895804 15772 solver.cpp:218] Iteration 26400 (17.7204 iter/s, 5.64323s/100 iters), loss = 1.72224
I1210 15:49:46.895804 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:49:46.895804 15772 solver.cpp:237]     Train net output #1: loss = 1.72224 (* 1 = 1.72224 loss)
I1210 15:49:46.895804 15772 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1210 15:49:52.258239 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:49:52.479255 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_26500.caffemodel
I1210 15:49:52.493255 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_26500.solverstate
I1210 15:49:52.498256 15772 solver.cpp:330] Iteration 26500, Testing net (#0)
I1210 15:49:52.498256 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:49:53.866350 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:49:53.921355 15772 solver.cpp:397]     Test net output #0: accuracy = 0.417
I1210 15:49:53.921355 15772 solver.cpp:397]     Test net output #1: loss = 2.2834 (* 1 = 2.2834 loss)
I1210 15:49:53.976366 15772 solver.cpp:218] Iteration 26500 (14.1254 iter/s, 7.07943s/100 iters), loss = 1.55736
I1210 15:49:53.976366 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:49:53.976366 15772 solver.cpp:237]     Train net output #1: loss = 1.55736 (* 1 = 1.55736 loss)
I1210 15:49:53.976366 15772 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1210 15:49:59.610880 15772 solver.cpp:218] Iteration 26600 (17.7486 iter/s, 5.63425s/100 iters), loss = 1.60172
I1210 15:49:59.611382 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:49:59.611382 15772 solver.cpp:237]     Train net output #1: loss = 1.60172 (* 1 = 1.60172 loss)
I1210 15:49:59.611382 15772 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1210 15:50:05.268920 15772 solver.cpp:218] Iteration 26700 (17.6767 iter/s, 5.65717s/100 iters), loss = 1.49317
I1210 15:50:05.268920 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 15:50:05.268920 15772 solver.cpp:237]     Train net output #1: loss = 1.49317 (* 1 = 1.49317 loss)
I1210 15:50:05.268920 15772 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1210 15:50:10.904525 15772 solver.cpp:218] Iteration 26800 (17.7434 iter/s, 5.6359s/100 iters), loss = 1.79588
I1210 15:50:10.904525 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:50:10.904525 15772 solver.cpp:237]     Train net output #1: loss = 1.79588 (* 1 = 1.79588 loss)
I1210 15:50:10.904525 15772 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1210 15:50:16.547978 15772 solver.cpp:218] Iteration 26900 (17.7236 iter/s, 5.64219s/100 iters), loss = 1.68871
I1210 15:50:16.547978 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:50:16.547978 15772 solver.cpp:237]     Train net output #1: loss = 1.68871 (* 1 = 1.68871 loss)
I1210 15:50:16.547978 15772 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1210 15:50:21.914407 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:50:22.138428 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_27000.caffemodel
I1210 15:50:22.156428 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_27000.solverstate
I1210 15:50:22.161437 15772 solver.cpp:330] Iteration 27000, Testing net (#0)
I1210 15:50:22.161437 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:50:23.531546 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:50:23.585551 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3377
I1210 15:50:23.585551 15772 solver.cpp:397]     Test net output #1: loss = 2.82873 (* 1 = 2.82873 loss)
I1210 15:50:23.639575 15772 solver.cpp:218] Iteration 27000 (14.1009 iter/s, 7.09175s/100 iters), loss = 1.71909
I1210 15:50:23.639575 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:50:23.639575 15772 solver.cpp:237]     Train net output #1: loss = 1.71909 (* 1 = 1.71909 loss)
I1210 15:50:23.639575 15772 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1210 15:50:29.281796 15772 solver.cpp:218] Iteration 27100 (17.7275 iter/s, 5.64094s/100 iters), loss = 1.71055
I1210 15:50:29.281796 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:50:29.281796 15772 solver.cpp:237]     Train net output #1: loss = 1.71055 (* 1 = 1.71055 loss)
I1210 15:50:29.281796 15772 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1210 15:50:34.921531 15772 solver.cpp:218] Iteration 27200 (17.7314 iter/s, 5.63971s/100 iters), loss = 1.53507
I1210 15:50:34.921531 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:50:34.921531 15772 solver.cpp:237]     Train net output #1: loss = 1.53507 (* 1 = 1.53507 loss)
I1210 15:50:34.921531 15772 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1210 15:50:40.624183 15772 solver.cpp:218] Iteration 27300 (17.5376 iter/s, 5.70204s/100 iters), loss = 1.79578
I1210 15:50:40.624183 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:50:40.624183 15772 solver.cpp:237]     Train net output #1: loss = 1.79578 (* 1 = 1.79578 loss)
I1210 15:50:40.624183 15772 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1210 15:50:46.274019 15772 solver.cpp:218] Iteration 27400 (17.7004 iter/s, 5.64959s/100 iters), loss = 1.83366
I1210 15:50:46.274519 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:50:46.274519 15772 solver.cpp:237]     Train net output #1: loss = 1.83366 (* 1 = 1.83366 loss)
I1210 15:50:46.274519 15772 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1210 15:50:51.642918 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:50:51.866933 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_27500.caffemodel
I1210 15:50:51.881438 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_27500.solverstate
I1210 15:50:51.885939 15772 solver.cpp:330] Iteration 27500, Testing net (#0)
I1210 15:50:51.885939 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:50:53.258071 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:50:53.313099 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3355
I1210 15:50:53.314093 15772 solver.cpp:397]     Test net output #1: loss = 2.88863 (* 1 = 2.88863 loss)
I1210 15:50:53.367091 15772 solver.cpp:218] Iteration 27500 (14.0987 iter/s, 7.09285s/100 iters), loss = 1.55235
I1210 15:50:53.367091 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:50:53.367091 15772 solver.cpp:237]     Train net output #1: loss = 1.55235 (* 1 = 1.55235 loss)
I1210 15:50:53.367091 15772 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1210 15:50:59.006513 15772 solver.cpp:218] Iteration 27600 (17.734 iter/s, 5.63889s/100 iters), loss = 1.56415
I1210 15:50:59.006513 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:50:59.006513 15772 solver.cpp:237]     Train net output #1: loss = 1.56415 (* 1 = 1.56415 loss)
I1210 15:50:59.006513 15772 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1210 15:51:04.655966 15772 solver.cpp:218] Iteration 27700 (17.7033 iter/s, 5.64866s/100 iters), loss = 1.316
I1210 15:51:04.655966 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 15:51:04.655966 15772 solver.cpp:237]     Train net output #1: loss = 1.316 (* 1 = 1.316 loss)
I1210 15:51:04.655966 15772 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1210 15:51:10.309458 15772 solver.cpp:218] Iteration 27800 (17.69 iter/s, 5.65292s/100 iters), loss = 1.91221
I1210 15:51:10.309458 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:51:10.309458 15772 solver.cpp:237]     Train net output #1: loss = 1.91221 (* 1 = 1.91221 loss)
I1210 15:51:10.309458 15772 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1210 15:51:15.961006 15772 solver.cpp:218] Iteration 27900 (17.694 iter/s, 5.65163s/100 iters), loss = 1.82293
I1210 15:51:15.961006 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:51:15.961006 15772 solver.cpp:237]     Train net output #1: loss = 1.82293 (* 1 = 1.82293 loss)
I1210 15:51:15.961006 15772 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1210 15:51:21.330400 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:51:21.554415 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_28000.caffemodel
I1210 15:51:21.569414 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_28000.solverstate
I1210 15:51:21.573415 15772 solver.cpp:330] Iteration 28000, Testing net (#0)
I1210 15:51:21.573415 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:51:22.945561 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:51:22.999568 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3394
I1210 15:51:22.999568 15772 solver.cpp:397]     Test net output #1: loss = 2.77375 (* 1 = 2.77375 loss)
I1210 15:51:23.052567 15772 solver.cpp:218] Iteration 28000 (14.1025 iter/s, 7.09096s/100 iters), loss = 1.77157
I1210 15:51:23.052567 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:51:23.052567 15772 solver.cpp:237]     Train net output #1: loss = 1.77157 (* 1 = 1.77157 loss)
I1210 15:51:23.052567 15772 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1210 15:51:28.706167 15772 solver.cpp:218] Iteration 28100 (17.6897 iter/s, 5.65302s/100 iters), loss = 1.68126
I1210 15:51:28.706167 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:51:28.706167 15772 solver.cpp:237]     Train net output #1: loss = 1.68126 (* 1 = 1.68126 loss)
I1210 15:51:28.706167 15772 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1210 15:51:34.359638 15772 solver.cpp:218] Iteration 28200 (17.6886 iter/s, 5.65336s/100 iters), loss = 1.44088
I1210 15:51:34.359638 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:51:34.359638 15772 solver.cpp:237]     Train net output #1: loss = 1.44088 (* 1 = 1.44088 loss)
I1210 15:51:34.359638 15772 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1210 15:51:40.023092 15772 solver.cpp:218] Iteration 28300 (17.6603 iter/s, 5.6624s/100 iters), loss = 1.72226
I1210 15:51:40.023092 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:51:40.023092 15772 solver.cpp:237]     Train net output #1: loss = 1.72226 (* 1 = 1.72226 loss)
I1210 15:51:40.023092 15772 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1210 15:51:45.679028 15772 solver.cpp:218] Iteration 28400 (17.6825 iter/s, 5.6553s/100 iters), loss = 1.92098
I1210 15:51:45.679028 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:51:45.679028 15772 solver.cpp:237]     Train net output #1: loss = 1.92098 (* 1 = 1.92098 loss)
I1210 15:51:45.679028 15772 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1210 15:51:51.051059 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:51:51.274705 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_28500.caffemodel
I1210 15:51:51.289710 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_28500.solverstate
I1210 15:51:51.294210 15772 solver.cpp:330] Iteration 28500, Testing net (#0)
I1210 15:51:51.294210 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:51:52.667021 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:51:52.720531 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2967
I1210 15:51:52.720531 15772 solver.cpp:397]     Test net output #1: loss = 3.14468 (* 1 = 3.14468 loss)
I1210 15:51:52.774547 15772 solver.cpp:218] Iteration 28500 (14.0943 iter/s, 7.09507s/100 iters), loss = 1.56987
I1210 15:51:52.774547 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:51:52.774547 15772 solver.cpp:237]     Train net output #1: loss = 1.56987 (* 1 = 1.56987 loss)
I1210 15:51:52.774547 15772 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1210 15:51:58.429766 15772 solver.cpp:218] Iteration 28600 (17.6824 iter/s, 5.65534s/100 iters), loss = 1.6009
I1210 15:51:58.430768 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:51:58.430768 15772 solver.cpp:237]     Train net output #1: loss = 1.6009 (* 1 = 1.6009 loss)
I1210 15:51:58.430768 15772 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1210 15:52:04.066527 15772 solver.cpp:218] Iteration 28700 (17.7449 iter/s, 5.63541s/100 iters), loss = 1.39328
I1210 15:52:04.066527 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 15:52:04.066527 15772 solver.cpp:237]     Train net output #1: loss = 1.39328 (* 1 = 1.39328 loss)
I1210 15:52:04.066527 15772 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1210 15:52:09.709025 15772 solver.cpp:218] Iteration 28800 (17.7235 iter/s, 5.64223s/100 iters), loss = 1.72967
I1210 15:52:09.709025 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:52:09.709025 15772 solver.cpp:237]     Train net output #1: loss = 1.72967 (* 1 = 1.72967 loss)
I1210 15:52:09.709025 15772 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1210 15:52:15.358235 15772 solver.cpp:218] Iteration 28900 (17.7037 iter/s, 5.64854s/100 iters), loss = 1.77201
I1210 15:52:15.358235 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:52:15.358235 15772 solver.cpp:237]     Train net output #1: loss = 1.77201 (* 1 = 1.77201 loss)
I1210 15:52:15.358235 15772 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1210 15:52:20.722978 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:52:20.946485 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_29000.caffemodel
I1210 15:52:20.959985 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_29000.solverstate
I1210 15:52:20.965019 15772 solver.cpp:330] Iteration 29000, Testing net (#0)
I1210 15:52:20.965019 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:52:22.336230 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:52:22.389235 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3595
I1210 15:52:22.390238 15772 solver.cpp:397]     Test net output #1: loss = 2.65135 (* 1 = 2.65135 loss)
I1210 15:52:22.443236 15772 solver.cpp:218] Iteration 29000 (14.1153 iter/s, 7.0845s/100 iters), loss = 1.77235
I1210 15:52:22.443236 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:52:22.443236 15772 solver.cpp:237]     Train net output #1: loss = 1.77235 (* 1 = 1.77235 loss)
I1210 15:52:22.443236 15772 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1210 15:52:28.082779 15772 solver.cpp:218] Iteration 29100 (17.7337 iter/s, 5.63899s/100 iters), loss = 1.6076
I1210 15:52:28.082779 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:52:28.082779 15772 solver.cpp:237]     Train net output #1: loss = 1.6076 (* 1 = 1.6076 loss)
I1210 15:52:28.082779 15772 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1210 15:52:33.701258 15772 solver.cpp:218] Iteration 29200 (17.7994 iter/s, 5.61818s/100 iters), loss = 1.39099
I1210 15:52:33.701258 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 15:52:33.701258 15772 solver.cpp:237]     Train net output #1: loss = 1.39099 (* 1 = 1.39099 loss)
I1210 15:52:33.701258 15772 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1210 15:52:39.331758 15772 solver.cpp:218] Iteration 29300 (17.7625 iter/s, 5.62983s/100 iters), loss = 1.71977
I1210 15:52:39.331758 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:52:39.331758 15772 solver.cpp:237]     Train net output #1: loss = 1.71977 (* 1 = 1.71977 loss)
I1210 15:52:39.331758 15772 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1210 15:52:44.968025 15772 solver.cpp:218] Iteration 29400 (17.7438 iter/s, 5.63576s/100 iters), loss = 1.72925
I1210 15:52:44.968025 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:52:44.968025 15772 solver.cpp:237]     Train net output #1: loss = 1.72925 (* 1 = 1.72925 loss)
I1210 15:52:44.968025 15772 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1210 15:52:50.327699 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:52:50.549710 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_29500.caffemodel
I1210 15:52:50.565711 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_29500.solverstate
I1210 15:52:50.569710 15772 solver.cpp:330] Iteration 29500, Testing net (#0)
I1210 15:52:50.569710 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:52:51.943799 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:52:51.997807 15772 solver.cpp:397]     Test net output #0: accuracy = 0.278
I1210 15:52:51.997807 15772 solver.cpp:397]     Test net output #1: loss = 3.33306 (* 1 = 3.33306 loss)
I1210 15:52:52.050810 15772 solver.cpp:218] Iteration 29500 (14.1197 iter/s, 7.08229s/100 iters), loss = 1.6147
I1210 15:52:52.050810 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:52:52.050810 15772 solver.cpp:237]     Train net output #1: loss = 1.6147 (* 1 = 1.6147 loss)
I1210 15:52:52.050810 15772 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1210 15:52:57.697296 15772 solver.cpp:218] Iteration 29600 (17.7117 iter/s, 5.64598s/100 iters), loss = 1.53329
I1210 15:52:57.697296 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:52:57.697296 15772 solver.cpp:237]     Train net output #1: loss = 1.53329 (* 1 = 1.53329 loss)
I1210 15:52:57.697296 15772 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1210 15:53:03.326845 15772 solver.cpp:218] Iteration 29700 (17.7622 iter/s, 5.62994s/100 iters), loss = 1.49518
I1210 15:53:03.327847 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 15:53:03.327847 15772 solver.cpp:237]     Train net output #1: loss = 1.49518 (* 1 = 1.49518 loss)
I1210 15:53:03.327847 15772 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1210 15:53:08.963466 15772 solver.cpp:218] Iteration 29800 (17.7444 iter/s, 5.63558s/100 iters), loss = 1.85375
I1210 15:53:08.963466 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:53:08.963466 15772 solver.cpp:237]     Train net output #1: loss = 1.85375 (* 1 = 1.85375 loss)
I1210 15:53:08.963466 15772 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1210 15:53:14.601224 15772 solver.cpp:218] Iteration 29900 (17.7398 iter/s, 5.63705s/100 iters), loss = 1.82501
I1210 15:53:14.601224 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:53:14.601224 15772 solver.cpp:237]     Train net output #1: loss = 1.82501 (* 1 = 1.82501 loss)
I1210 15:53:14.601224 15772 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1210 15:53:19.980006 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:53:20.203021 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_30000.caffemodel
I1210 15:53:20.230037 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_30000.solverstate
I1210 15:53:20.235038 15772 solver.cpp:330] Iteration 30000, Testing net (#0)
I1210 15:53:20.235038 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:53:21.608621 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:53:21.662125 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3473
I1210 15:53:21.662125 15772 solver.cpp:397]     Test net output #1: loss = 2.79765 (* 1 = 2.79765 loss)
I1210 15:53:21.716128 15772 solver.cpp:218] Iteration 30000 (14.0556 iter/s, 7.11459s/100 iters), loss = 1.55791
I1210 15:53:21.716128 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:53:21.716128 15772 solver.cpp:237]     Train net output #1: loss = 1.55791 (* 1 = 1.55791 loss)
I1210 15:53:21.716128 15772 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1210 15:53:27.360607 15772 solver.cpp:218] Iteration 30100 (17.7164 iter/s, 5.64448s/100 iters), loss = 1.61887
I1210 15:53:27.360607 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:53:27.360607 15772 solver.cpp:237]     Train net output #1: loss = 1.61887 (* 1 = 1.61887 loss)
I1210 15:53:27.360607 15772 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1210 15:53:33.025079 15772 solver.cpp:218] Iteration 30200 (17.655 iter/s, 5.66411s/100 iters), loss = 1.5715
I1210 15:53:33.025079 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:53:33.025079 15772 solver.cpp:237]     Train net output #1: loss = 1.5715 (* 1 = 1.5715 loss)
I1210 15:53:33.025079 15772 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1210 15:53:38.679067 15772 solver.cpp:218] Iteration 30300 (17.6883 iter/s, 5.65346s/100 iters), loss = 1.88352
I1210 15:53:38.679067 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:53:38.679067 15772 solver.cpp:237]     Train net output #1: loss = 1.88352 (* 1 = 1.88352 loss)
I1210 15:53:38.679067 15772 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1210 15:53:44.328755 15772 solver.cpp:218] Iteration 30400 (17.7021 iter/s, 5.64903s/100 iters), loss = 1.81373
I1210 15:53:44.328755 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:53:44.328755 15772 solver.cpp:237]     Train net output #1: loss = 1.81373 (* 1 = 1.81373 loss)
I1210 15:53:44.328755 15772 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1210 15:53:49.693481 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:53:49.917665 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_30500.caffemodel
I1210 15:53:49.971210 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_30500.solverstate
I1210 15:53:49.975209 15772 solver.cpp:330] Iteration 30500, Testing net (#0)
I1210 15:53:49.975209 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:53:51.348176 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:53:51.401186 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2879
I1210 15:53:51.401186 15772 solver.cpp:397]     Test net output #1: loss = 3.58175 (* 1 = 3.58175 loss)
I1210 15:53:51.454182 15772 solver.cpp:218] Iteration 30500 (14.0357 iter/s, 7.1247s/100 iters), loss = 1.81808
I1210 15:53:51.454182 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:53:51.454182 15772 solver.cpp:237]     Train net output #1: loss = 1.81808 (* 1 = 1.81808 loss)
I1210 15:53:51.454182 15772 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1210 15:53:57.090137 15772 solver.cpp:218] Iteration 30600 (17.7431 iter/s, 5.63599s/100 iters), loss = 1.48061
I1210 15:53:57.091136 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:53:57.091136 15772 solver.cpp:237]     Train net output #1: loss = 1.48061 (* 1 = 1.48061 loss)
I1210 15:53:57.091136 15772 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1210 15:54:02.732748 15772 solver.cpp:218] Iteration 30700 (17.7257 iter/s, 5.64152s/100 iters), loss = 1.38017
I1210 15:54:02.732748 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 15:54:02.732748 15772 solver.cpp:237]     Train net output #1: loss = 1.38017 (* 1 = 1.38017 loss)
I1210 15:54:02.732748 15772 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1210 15:54:08.383231 15772 solver.cpp:218] Iteration 30800 (17.6972 iter/s, 5.6506s/100 iters), loss = 1.64688
I1210 15:54:08.383231 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:54:08.383231 15772 solver.cpp:237]     Train net output #1: loss = 1.64688 (* 1 = 1.64688 loss)
I1210 15:54:08.384232 15772 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1210 15:54:14.021675 15772 solver.cpp:218] Iteration 30900 (17.7398 iter/s, 5.63703s/100 iters), loss = 1.85383
I1210 15:54:14.021675 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:54:14.021675 15772 solver.cpp:237]     Train net output #1: loss = 1.85383 (* 1 = 1.85383 loss)
I1210 15:54:14.021675 15772 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1210 15:54:19.383242 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:54:19.606253 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_31000.caffemodel
I1210 15:54:19.620254 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_31000.solverstate
I1210 15:54:19.624253 15772 solver.cpp:330] Iteration 31000, Testing net (#0)
I1210 15:54:19.624253 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:54:20.997359 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:54:21.051358 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3632
I1210 15:54:21.051358 15772 solver.cpp:397]     Test net output #1: loss = 2.71608 (* 1 = 2.71608 loss)
I1210 15:54:21.104370 15772 solver.cpp:218] Iteration 31000 (14.1193 iter/s, 7.08253s/100 iters), loss = 1.68545
I1210 15:54:21.104370 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:54:21.104370 15772 solver.cpp:237]     Train net output #1: loss = 1.68545 (* 1 = 1.68545 loss)
I1210 15:54:21.104370 15772 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1210 15:54:26.741765 15772 solver.cpp:218] Iteration 31100 (17.7404 iter/s, 5.63685s/100 iters), loss = 1.46511
I1210 15:54:26.741765 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:54:26.741765 15772 solver.cpp:237]     Train net output #1: loss = 1.46511 (* 1 = 1.46511 loss)
I1210 15:54:26.741765 15772 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1210 15:54:32.374220 15772 solver.cpp:218] Iteration 31200 (17.7559 iter/s, 5.63193s/100 iters), loss = 1.42318
I1210 15:54:32.374220 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 15:54:32.374220 15772 solver.cpp:237]     Train net output #1: loss = 1.42318 (* 1 = 1.42318 loss)
I1210 15:54:32.374220 15772 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1210 15:54:38.002653 15772 solver.cpp:218] Iteration 31300 (17.7681 iter/s, 5.62805s/100 iters), loss = 1.89833
I1210 15:54:38.002653 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:54:38.002653 15772 solver.cpp:237]     Train net output #1: loss = 1.89833 (* 1 = 1.89833 loss)
I1210 15:54:38.002653 15772 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1210 15:54:43.631315 15772 solver.cpp:218] Iteration 31400 (17.7683 iter/s, 5.628s/100 iters), loss = 1.66538
I1210 15:54:43.631315 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:54:43.631315 15772 solver.cpp:237]     Train net output #1: loss = 1.66538 (* 1 = 1.66538 loss)
I1210 15:54:43.631315 15772 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1210 15:54:48.991878 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:54:49.213898 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_31500.caffemodel
I1210 15:54:49.253404 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_31500.solverstate
I1210 15:54:49.257905 15772 solver.cpp:330] Iteration 31500, Testing net (#0)
I1210 15:54:49.257905 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:54:50.632058 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:54:50.685065 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3471
I1210 15:54:50.685065 15772 solver.cpp:397]     Test net output #1: loss = 2.73038 (* 1 = 2.73038 loss)
I1210 15:54:50.738065 15772 solver.cpp:218] Iteration 31500 (14.0712 iter/s, 7.1067s/100 iters), loss = 1.63939
I1210 15:54:50.738065 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:54:50.738065 15772 solver.cpp:237]     Train net output #1: loss = 1.63939 (* 1 = 1.63939 loss)
I1210 15:54:50.738065 15772 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1210 15:54:56.371991 15772 solver.cpp:218] Iteration 31600 (17.7524 iter/s, 5.63303s/100 iters), loss = 1.65561
I1210 15:54:56.371991 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:54:56.371991 15772 solver.cpp:237]     Train net output #1: loss = 1.65561 (* 1 = 1.65561 loss)
I1210 15:54:56.371991 15772 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1210 15:55:02.009346 15772 solver.cpp:218] Iteration 31700 (17.7409 iter/s, 5.63671s/100 iters), loss = 1.46817
I1210 15:55:02.009346 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:55:02.009346 15772 solver.cpp:237]     Train net output #1: loss = 1.46817 (* 1 = 1.46817 loss)
I1210 15:55:02.009346 15772 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1210 15:55:07.641185 15772 solver.cpp:218] Iteration 31800 (17.7555 iter/s, 5.63206s/100 iters), loss = 1.86319
I1210 15:55:07.641185 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:55:07.641185 15772 solver.cpp:237]     Train net output #1: loss = 1.86319 (* 1 = 1.86319 loss)
I1210 15:55:07.641185 15772 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1210 15:55:13.284984 15772 solver.cpp:218] Iteration 31900 (17.7218 iter/s, 5.64276s/100 iters), loss = 1.70052
I1210 15:55:13.284984 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:55:13.284984 15772 solver.cpp:237]     Train net output #1: loss = 1.70052 (* 1 = 1.70052 loss)
I1210 15:55:13.284984 15772 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1210 15:55:18.655076 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:55:18.878077 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_32000.caffemodel
I1210 15:55:18.892077 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_32000.solverstate
I1210 15:55:18.896577 15772 solver.cpp:330] Iteration 32000, Testing net (#0)
I1210 15:55:18.896577 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:55:20.269733 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:55:20.323740 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3584
I1210 15:55:20.323740 15772 solver.cpp:397]     Test net output #1: loss = 2.60318 (* 1 = 2.60318 loss)
I1210 15:55:20.377741 15772 solver.cpp:218] Iteration 32000 (14.0992 iter/s, 7.09258s/100 iters), loss = 1.65701
I1210 15:55:20.377741 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:55:20.377741 15772 solver.cpp:237]     Train net output #1: loss = 1.65701 (* 1 = 1.65701 loss)
I1210 15:55:20.377741 15772 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1210 15:55:26.010049 15772 solver.cpp:218] Iteration 32100 (17.7563 iter/s, 5.63181s/100 iters), loss = 1.65715
I1210 15:55:26.010049 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:55:26.010049 15772 solver.cpp:237]     Train net output #1: loss = 1.65715 (* 1 = 1.65715 loss)
I1210 15:55:26.010049 15772 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1210 15:55:31.641017 15772 solver.cpp:218] Iteration 32200 (17.7618 iter/s, 5.63007s/100 iters), loss = 1.54435
I1210 15:55:31.641017 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:55:31.641017 15772 solver.cpp:237]     Train net output #1: loss = 1.54435 (* 1 = 1.54435 loss)
I1210 15:55:31.641017 15772 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1210 15:55:37.263933 15772 solver.cpp:218] Iteration 32300 (17.7837 iter/s, 5.62312s/100 iters), loss = 1.90023
I1210 15:55:37.263933 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:55:37.263933 15772 solver.cpp:237]     Train net output #1: loss = 1.90023 (* 1 = 1.90023 loss)
I1210 15:55:37.263933 15772 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1210 15:55:42.887634 15772 solver.cpp:218] Iteration 32400 (17.7841 iter/s, 5.623s/100 iters), loss = 1.68052
I1210 15:55:42.887634 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:55:42.887634 15772 solver.cpp:237]     Train net output #1: loss = 1.68052 (* 1 = 1.68052 loss)
I1210 15:55:42.887634 15772 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1210 15:55:48.253787 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:55:48.474807 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_32500.caffemodel
I1210 15:55:48.512805 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_32500.solverstate
I1210 15:55:48.518316 15772 solver.cpp:330] Iteration 32500, Testing net (#0)
I1210 15:55:48.518316 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:55:49.890951 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:55:49.945960 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2939
I1210 15:55:49.945960 15772 solver.cpp:397]     Test net output #1: loss = 2.88594 (* 1 = 2.88594 loss)
I1210 15:55:49.998973 15772 solver.cpp:218] Iteration 32500 (14.0641 iter/s, 7.11029s/100 iters), loss = 1.69726
I1210 15:55:49.998973 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:55:49.998973 15772 solver.cpp:237]     Train net output #1: loss = 1.69726 (* 1 = 1.69726 loss)
I1210 15:55:49.998973 15772 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1210 15:55:55.648394 15772 solver.cpp:218] Iteration 32600 (17.702 iter/s, 5.64908s/100 iters), loss = 1.59539
I1210 15:55:55.648394 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:55:55.648394 15772 solver.cpp:237]     Train net output #1: loss = 1.59539 (* 1 = 1.59539 loss)
I1210 15:55:55.648394 15772 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1210 15:56:01.295833 15772 solver.cpp:218] Iteration 32700 (17.7075 iter/s, 5.64732s/100 iters), loss = 1.54724
I1210 15:56:01.295833 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 15:56:01.295833 15772 solver.cpp:237]     Train net output #1: loss = 1.54724 (* 1 = 1.54724 loss)
I1210 15:56:01.295833 15772 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1210 15:56:06.937350 15772 solver.cpp:218] Iteration 32800 (17.727 iter/s, 5.64111s/100 iters), loss = 1.9647
I1210 15:56:06.937350 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:56:06.937350 15772 solver.cpp:237]     Train net output #1: loss = 1.9647 (* 1 = 1.9647 loss)
I1210 15:56:06.937350 15772 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1210 15:56:12.578279 15772 solver.cpp:218] Iteration 32900 (17.7302 iter/s, 5.6401s/100 iters), loss = 1.95226
I1210 15:56:12.578279 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:56:12.578279 15772 solver.cpp:237]     Train net output #1: loss = 1.95226 (* 1 = 1.95226 loss)
I1210 15:56:12.578279 15772 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1210 15:56:17.947939 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:56:18.171964 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_33000.caffemodel
I1210 15:56:18.185964 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_33000.solverstate
I1210 15:56:18.189965 15772 solver.cpp:330] Iteration 33000, Testing net (#0)
I1210 15:56:18.190965 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:56:19.563115 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:56:19.619115 15772 solver.cpp:397]     Test net output #0: accuracy = 0.4096
I1210 15:56:19.619115 15772 solver.cpp:397]     Test net output #1: loss = 2.29981 (* 1 = 2.29981 loss)
I1210 15:56:19.672122 15772 solver.cpp:218] Iteration 33000 (14.0981 iter/s, 7.09317s/100 iters), loss = 1.53047
I1210 15:56:19.672122 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 15:56:19.672122 15772 solver.cpp:237]     Train net output #1: loss = 1.53047 (* 1 = 1.53047 loss)
I1210 15:56:19.672122 15772 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1210 15:56:25.320560 15772 solver.cpp:218] Iteration 33100 (17.7049 iter/s, 5.64815s/100 iters), loss = 1.52415
I1210 15:56:25.320560 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:56:25.320560 15772 solver.cpp:237]     Train net output #1: loss = 1.52415 (* 1 = 1.52415 loss)
I1210 15:56:25.320560 15772 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1210 15:56:30.970005 15772 solver.cpp:218] Iteration 33200 (17.7002 iter/s, 5.64966s/100 iters), loss = 1.4055
I1210 15:56:30.970005 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 15:56:30.971006 15772 solver.cpp:237]     Train net output #1: loss = 1.4055 (* 1 = 1.4055 loss)
I1210 15:56:30.971006 15772 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1210 15:56:36.625841 15772 solver.cpp:218] Iteration 33300 (17.6848 iter/s, 5.65458s/100 iters), loss = 1.78207
I1210 15:56:36.625841 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:56:36.625841 15772 solver.cpp:237]     Train net output #1: loss = 1.78207 (* 1 = 1.78207 loss)
I1210 15:56:36.625841 15772 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1210 15:56:42.277977 15772 solver.cpp:218] Iteration 33400 (17.6925 iter/s, 5.65212s/100 iters), loss = 1.61116
I1210 15:56:42.277977 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:56:42.277977 15772 solver.cpp:237]     Train net output #1: loss = 1.61116 (* 1 = 1.61116 loss)
I1210 15:56:42.277977 15772 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1210 15:56:47.652686 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:56:47.875701 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_33500.caffemodel
I1210 15:56:47.911701 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_33500.solverstate
I1210 15:56:47.916702 15772 solver.cpp:330] Iteration 33500, Testing net (#0)
I1210 15:56:47.916702 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:56:49.286823 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:56:49.340857 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3503
I1210 15:56:49.340857 15772 solver.cpp:397]     Test net output #1: loss = 2.82053 (* 1 = 2.82053 loss)
I1210 15:56:49.394860 15772 solver.cpp:218] Iteration 33500 (14.0527 iter/s, 7.11606s/100 iters), loss = 1.60423
I1210 15:56:49.394860 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 15:56:49.394860 15772 solver.cpp:237]     Train net output #1: loss = 1.60423 (* 1 = 1.60423 loss)
I1210 15:56:49.394860 15772 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1210 15:56:55.049363 15772 solver.cpp:218] Iteration 33600 (17.6865 iter/s, 5.65405s/100 iters), loss = 1.78276
I1210 15:56:55.049363 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:56:55.049363 15772 solver.cpp:237]     Train net output #1: loss = 1.78276 (* 1 = 1.78276 loss)
I1210 15:56:55.049363 15772 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1210 15:57:00.700835 15772 solver.cpp:218] Iteration 33700 (17.6946 iter/s, 5.65144s/100 iters), loss = 1.53536
I1210 15:57:00.700835 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:57:00.700835 15772 solver.cpp:237]     Train net output #1: loss = 1.53536 (* 1 = 1.53536 loss)
I1210 15:57:00.700835 15772 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1210 15:57:06.360321 15772 solver.cpp:218] Iteration 33800 (17.6724 iter/s, 5.65853s/100 iters), loss = 1.86315
I1210 15:57:06.360321 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 15:57:06.360321 15772 solver.cpp:237]     Train net output #1: loss = 1.86315 (* 1 = 1.86315 loss)
I1210 15:57:06.360321 15772 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1210 15:57:11.996778 15772 solver.cpp:218] Iteration 33900 (17.7423 iter/s, 5.63624s/100 iters), loss = 1.7964
I1210 15:57:11.996778 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:57:11.996778 15772 solver.cpp:237]     Train net output #1: loss = 1.7964 (* 1 = 1.7964 loss)
I1210 15:57:11.996778 15772 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1210 15:57:17.376384 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:57:17.597394 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_34000.caffemodel
I1210 15:57:17.612395 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_34000.solverstate
I1210 15:57:17.616394 15772 solver.cpp:330] Iteration 34000, Testing net (#0)
I1210 15:57:17.616394 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:57:18.987514 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:57:19.042531 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3374
I1210 15:57:19.042531 15772 solver.cpp:397]     Test net output #1: loss = 2.8292 (* 1 = 2.8292 loss)
I1210 15:57:19.097534 15772 solver.cpp:218] Iteration 34000 (14.0843 iter/s, 7.1001s/100 iters), loss = 1.64583
I1210 15:57:19.097534 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:57:19.097534 15772 solver.cpp:237]     Train net output #1: loss = 1.64583 (* 1 = 1.64583 loss)
I1210 15:57:19.097534 15772 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1210 15:57:24.747979 15772 solver.cpp:218] Iteration 34100 (17.699 iter/s, 5.65004s/100 iters), loss = 1.45894
I1210 15:57:24.747979 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:57:24.747979 15772 solver.cpp:237]     Train net output #1: loss = 1.45894 (* 1 = 1.45894 loss)
I1210 15:57:24.747979 15772 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1210 15:57:30.395699 15772 solver.cpp:218] Iteration 34200 (17.7064 iter/s, 5.64768s/100 iters), loss = 1.36211
I1210 15:57:30.395699 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 15:57:30.395699 15772 solver.cpp:237]     Train net output #1: loss = 1.36211 (* 1 = 1.36211 loss)
I1210 15:57:30.395699 15772 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1210 15:57:36.045126 15772 solver.cpp:218] Iteration 34300 (17.7025 iter/s, 5.64892s/100 iters), loss = 1.81528
I1210 15:57:36.045126 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 15:57:36.045126 15772 solver.cpp:237]     Train net output #1: loss = 1.81528 (* 1 = 1.81528 loss)
I1210 15:57:36.045126 15772 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1210 15:57:41.701618 15772 solver.cpp:218] Iteration 34400 (17.6809 iter/s, 5.65582s/100 iters), loss = 1.86089
I1210 15:57:41.701618 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:57:41.701618 15772 solver.cpp:237]     Train net output #1: loss = 1.86089 (* 1 = 1.86089 loss)
I1210 15:57:41.701618 15772 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1210 15:57:47.074036 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:57:47.295048 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_34500.caffemodel
I1210 15:57:47.355072 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_34500.solverstate
I1210 15:57:47.359071 15772 solver.cpp:330] Iteration 34500, Testing net (#0)
I1210 15:57:47.359071 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:57:48.731283 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:57:48.784289 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2637
I1210 15:57:48.784289 15772 solver.cpp:397]     Test net output #1: loss = 3.69841 (* 1 = 3.69841 loss)
I1210 15:57:48.838290 15772 solver.cpp:218] Iteration 34500 (14.0134 iter/s, 7.13603s/100 iters), loss = 1.77885
I1210 15:57:48.838290 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:57:48.838290 15772 solver.cpp:237]     Train net output #1: loss = 1.77885 (* 1 = 1.77885 loss)
I1210 15:57:48.838290 15772 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1210 15:57:54.480721 15772 solver.cpp:218] Iteration 34600 (17.7251 iter/s, 5.64172s/100 iters), loss = 1.59976
I1210 15:57:54.480721 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 15:57:54.480721 15772 solver.cpp:237]     Train net output #1: loss = 1.59976 (* 1 = 1.59976 loss)
I1210 15:57:54.480721 15772 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1210 15:58:00.116158 15772 solver.cpp:218] Iteration 34700 (17.7443 iter/s, 5.63562s/100 iters), loss = 1.43144
I1210 15:58:00.116158 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 15:58:00.116158 15772 solver.cpp:237]     Train net output #1: loss = 1.43144 (* 1 = 1.43144 loss)
I1210 15:58:00.116158 15772 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1210 15:58:05.754611 15772 solver.cpp:218] Iteration 34800 (17.7369 iter/s, 5.63797s/100 iters), loss = 1.76884
I1210 15:58:05.754611 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:58:05.754611 15772 solver.cpp:237]     Train net output #1: loss = 1.76884 (* 1 = 1.76884 loss)
I1210 15:58:05.754611 15772 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1210 15:58:11.380041 15772 solver.cpp:218] Iteration 34900 (17.7773 iter/s, 5.62515s/100 iters), loss = 1.72089
I1210 15:58:11.380041 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:58:11.380041 15772 solver.cpp:237]     Train net output #1: loss = 1.72089 (* 1 = 1.72089 loss)
I1210 15:58:11.380041 15772 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1210 15:58:16.739974 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:58:16.961489 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_35000.caffemodel
I1210 15:58:16.975489 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_35000.solverstate
I1210 15:58:16.979490 15772 solver.cpp:330] Iteration 35000, Testing net (#0)
I1210 15:58:16.979490 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:58:18.352599 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:58:18.406599 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3692
I1210 15:58:18.406599 15772 solver.cpp:397]     Test net output #1: loss = 2.61859 (* 1 = 2.61859 loss)
I1210 15:58:18.459604 15772 solver.cpp:218] Iteration 35000 (14.1262 iter/s, 7.07905s/100 iters), loss = 1.572
I1210 15:58:18.459604 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 15:58:18.459604 15772 solver.cpp:237]     Train net output #1: loss = 1.572 (* 1 = 1.572 loss)
I1210 15:58:18.459604 15772 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1210 15:58:24.117233 15772 solver.cpp:218] Iteration 35100 (17.6769 iter/s, 5.65711s/100 iters), loss = 1.54668
I1210 15:58:24.117233 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 15:58:24.117233 15772 solver.cpp:237]     Train net output #1: loss = 1.54668 (* 1 = 1.54668 loss)
I1210 15:58:24.117233 15772 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1210 15:58:29.767663 15772 solver.cpp:218] Iteration 35200 (17.7 iter/s, 5.64973s/100 iters), loss = 1.65257
I1210 15:58:29.767663 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 15:58:29.767663 15772 solver.cpp:237]     Train net output #1: loss = 1.65257 (* 1 = 1.65257 loss)
I1210 15:58:29.767663 15772 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1210 15:58:35.420116 15772 solver.cpp:218] Iteration 35300 (17.6924 iter/s, 5.65214s/100 iters), loss = 1.93365
I1210 15:58:35.420116 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:58:35.420116 15772 solver.cpp:237]     Train net output #1: loss = 1.93365 (* 1 = 1.93365 loss)
I1210 15:58:35.420116 15772 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1210 15:58:41.076753 15772 solver.cpp:218] Iteration 35400 (17.6819 iter/s, 5.65549s/100 iters), loss = 1.76038
I1210 15:58:41.076753 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 15:58:41.076753 15772 solver.cpp:237]     Train net output #1: loss = 1.76038 (* 1 = 1.76038 loss)
I1210 15:58:41.076753 15772 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1210 15:58:46.449214 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:58:46.669241 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_35500.caffemodel
I1210 15:58:46.711241 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_35500.solverstate
I1210 15:58:46.716241 15772 solver.cpp:330] Iteration 35500, Testing net (#0)
I1210 15:58:46.716241 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:58:48.087366 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:58:48.141870 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3692
I1210 15:58:48.141870 15772 solver.cpp:397]     Test net output #1: loss = 2.58403 (* 1 = 2.58403 loss)
I1210 15:58:48.195371 15772 solver.cpp:218] Iteration 35500 (14.0489 iter/s, 7.11797s/100 iters), loss = 1.54118
I1210 15:58:48.195371 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 15:58:48.195371 15772 solver.cpp:237]     Train net output #1: loss = 1.54118 (* 1 = 1.54118 loss)
I1210 15:58:48.195371 15772 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1210 15:58:53.835356 15772 solver.cpp:218] Iteration 35600 (17.732 iter/s, 5.63952s/100 iters), loss = 1.59074
I1210 15:58:53.835356 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:58:53.835356 15772 solver.cpp:237]     Train net output #1: loss = 1.59074 (* 1 = 1.59074 loss)
I1210 15:58:53.835356 15772 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1210 15:58:59.475329 15772 solver.cpp:218] Iteration 35700 (17.7297 iter/s, 5.64024s/100 iters), loss = 1.38374
I1210 15:58:59.475329 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 15:58:59.475329 15772 solver.cpp:237]     Train net output #1: loss = 1.38374 (* 1 = 1.38374 loss)
I1210 15:58:59.475329 15772 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1210 15:59:05.122385 15772 solver.cpp:218] Iteration 35800 (17.7109 iter/s, 5.64624s/100 iters), loss = 1.81034
I1210 15:59:05.122385 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 15:59:05.122385 15772 solver.cpp:237]     Train net output #1: loss = 1.81034 (* 1 = 1.81034 loss)
I1210 15:59:05.122385 15772 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1210 15:59:10.759804 15772 solver.cpp:218] Iteration 35900 (17.7414 iter/s, 5.63652s/100 iters), loss = 1.80642
I1210 15:59:10.759804 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 15:59:10.759804 15772 solver.cpp:237]     Train net output #1: loss = 1.80642 (* 1 = 1.80642 loss)
I1210 15:59:10.759804 15772 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1210 15:59:16.120223 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:59:16.343276 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_36000.caffemodel
I1210 15:59:16.357272 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_36000.solverstate
I1210 15:59:16.362284 15772 solver.cpp:330] Iteration 36000, Testing net (#0)
I1210 15:59:16.362284 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:59:17.732401 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:59:17.785413 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3387
I1210 15:59:17.785413 15772 solver.cpp:397]     Test net output #1: loss = 2.99953 (* 1 = 2.99953 loss)
I1210 15:59:17.839416 15772 solver.cpp:218] Iteration 36000 (14.1253 iter/s, 7.07948s/100 iters), loss = 1.73058
I1210 15:59:17.839916 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 15:59:17.839916 15772 solver.cpp:237]     Train net output #1: loss = 1.73058 (* 1 = 1.73058 loss)
I1210 15:59:17.839916 15772 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1210 15:59:23.488916 15772 solver.cpp:218] Iteration 36100 (17.7029 iter/s, 5.6488s/100 iters), loss = 1.56807
I1210 15:59:23.488916 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 15:59:23.488916 15772 solver.cpp:237]     Train net output #1: loss = 1.56807 (* 1 = 1.56807 loss)
I1210 15:59:23.488916 15772 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1210 15:59:29.136505 15772 solver.cpp:218] Iteration 36200 (17.7064 iter/s, 5.64766s/100 iters), loss = 1.2791
I1210 15:59:29.136505 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 15:59:29.136505 15772 solver.cpp:237]     Train net output #1: loss = 1.2791 (* 1 = 1.2791 loss)
I1210 15:59:29.136505 15772 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1210 15:59:34.779973 15772 solver.cpp:218] Iteration 36300 (17.7217 iter/s, 5.64281s/100 iters), loss = 1.85409
I1210 15:59:34.779973 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 15:59:34.779973 15772 solver.cpp:237]     Train net output #1: loss = 1.85409 (* 1 = 1.85409 loss)
I1210 15:59:34.779973 15772 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1210 15:59:40.435457 15772 solver.cpp:218] Iteration 36400 (17.684 iter/s, 5.65484s/100 iters), loss = 1.68256
I1210 15:59:40.435457 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 15:59:40.435457 15772 solver.cpp:237]     Train net output #1: loss = 1.68256 (* 1 = 1.68256 loss)
I1210 15:59:40.435457 15772 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1210 15:59:45.808869 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:59:46.028880 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_36500.caffemodel
I1210 15:59:46.045384 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_36500.solverstate
I1210 15:59:46.051383 15772 solver.cpp:330] Iteration 36500, Testing net (#0)
I1210 15:59:46.051383 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 15:59:47.422019 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 15:59:47.476022 15772 solver.cpp:397]     Test net output #0: accuracy = 0.4396
I1210 15:59:47.476022 15772 solver.cpp:397]     Test net output #1: loss = 2.22278 (* 1 = 2.22278 loss)
I1210 15:59:47.530021 15772 solver.cpp:218] Iteration 36500 (14.0954 iter/s, 7.09451s/100 iters), loss = 1.62235
I1210 15:59:47.530021 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 15:59:47.530021 15772 solver.cpp:237]     Train net output #1: loss = 1.62235 (* 1 = 1.62235 loss)
I1210 15:59:47.530021 15772 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1210 15:59:53.167484 15772 solver.cpp:218] Iteration 36600 (17.7392 iter/s, 5.63724s/100 iters), loss = 1.4809
I1210 15:59:53.167484 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 15:59:53.168469 15772 solver.cpp:237]     Train net output #1: loss = 1.4809 (* 1 = 1.4809 loss)
I1210 15:59:53.168469 15772 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1210 15:59:58.795898 15772 solver.cpp:218] Iteration 36700 (17.77 iter/s, 5.62748s/100 iters), loss = 1.41427
I1210 15:59:58.795898 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 15:59:58.795898 15772 solver.cpp:237]     Train net output #1: loss = 1.41427 (* 1 = 1.41427 loss)
I1210 15:59:58.795898 15772 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1210 16:00:04.453446 15772 solver.cpp:218] Iteration 36800 (17.6777 iter/s, 5.65685s/100 iters), loss = 1.89283
I1210 16:00:04.453446 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 16:00:04.453446 15772 solver.cpp:237]     Train net output #1: loss = 1.89283 (* 1 = 1.89283 loss)
I1210 16:00:04.453446 15772 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1210 16:00:10.094020 15772 solver.cpp:218] Iteration 36900 (17.7293 iter/s, 5.64038s/100 iters), loss = 1.81626
I1210 16:00:10.094020 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 16:00:10.094020 15772 solver.cpp:237]     Train net output #1: loss = 1.81626 (* 1 = 1.81626 loss)
I1210 16:00:10.094020 15772 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1210 16:00:15.453410 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:00:15.675669 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_37000.caffemodel
I1210 16:00:15.689669 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_37000.solverstate
I1210 16:00:15.694674 15772 solver.cpp:330] Iteration 37000, Testing net (#0)
I1210 16:00:15.694674 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:00:17.064229 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:00:17.117244 15772 solver.cpp:397]     Test net output #0: accuracy = 0.41
I1210 16:00:17.117244 15772 solver.cpp:397]     Test net output #1: loss = 2.31435 (* 1 = 2.31435 loss)
I1210 16:00:17.170783 15772 solver.cpp:218] Iteration 37000 (14.1311 iter/s, 7.07657s/100 iters), loss = 1.47031
I1210 16:00:17.170783 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 16:00:17.170783 15772 solver.cpp:237]     Train net output #1: loss = 1.47031 (* 1 = 1.47031 loss)
I1210 16:00:17.170783 15772 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1210 16:00:22.808118 15772 solver.cpp:218] Iteration 37100 (17.74 iter/s, 5.63697s/100 iters), loss = 1.60382
I1210 16:00:22.808118 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 16:00:22.808118 15772 solver.cpp:237]     Train net output #1: loss = 1.60382 (* 1 = 1.60382 loss)
I1210 16:00:22.808118 15772 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1210 16:00:28.446190 15772 solver.cpp:218] Iteration 37200 (17.7399 iter/s, 5.637s/100 iters), loss = 1.44437
I1210 16:00:28.446190 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 16:00:28.446190 15772 solver.cpp:237]     Train net output #1: loss = 1.44437 (* 1 = 1.44437 loss)
I1210 16:00:28.446190 15772 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1210 16:00:34.083608 15772 solver.cpp:218] Iteration 37300 (17.7391 iter/s, 5.63727s/100 iters), loss = 1.83538
I1210 16:00:34.083608 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 16:00:34.083608 15772 solver.cpp:237]     Train net output #1: loss = 1.83538 (* 1 = 1.83538 loss)
I1210 16:00:34.083608 15772 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1210 16:00:39.719043 15772 solver.cpp:218] Iteration 37400 (17.7465 iter/s, 5.63492s/100 iters), loss = 1.81899
I1210 16:00:39.719043 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:00:39.719043 15772 solver.cpp:237]     Train net output #1: loss = 1.81899 (* 1 = 1.81899 loss)
I1210 16:00:39.719043 15772 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1210 16:00:45.086500 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:00:45.307512 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_37500.caffemodel
I1210 16:00:45.321512 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_37500.solverstate
I1210 16:00:45.325511 15772 solver.cpp:330] Iteration 37500, Testing net (#0)
I1210 16:00:45.325511 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:00:46.697624 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:00:46.750629 15772 solver.cpp:397]     Test net output #0: accuracy = 0.348
I1210 16:00:46.751631 15772 solver.cpp:397]     Test net output #1: loss = 2.85743 (* 1 = 2.85743 loss)
I1210 16:00:46.804630 15772 solver.cpp:218] Iteration 37500 (14.1141 iter/s, 7.08513s/100 iters), loss = 1.56634
I1210 16:00:46.804630 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:00:46.804630 15772 solver.cpp:237]     Train net output #1: loss = 1.56634 (* 1 = 1.56634 loss)
I1210 16:00:46.804630 15772 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1210 16:00:52.455078 15772 solver.cpp:218] Iteration 37600 (17.6998 iter/s, 5.64979s/100 iters), loss = 1.54967
I1210 16:00:52.455078 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 16:00:52.455078 15772 solver.cpp:237]     Train net output #1: loss = 1.54967 (* 1 = 1.54967 loss)
I1210 16:00:52.455078 15772 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1210 16:00:58.099709 15772 solver.cpp:218] Iteration 37700 (17.7163 iter/s, 5.64452s/100 iters), loss = 1.3464
I1210 16:00:58.099709 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 16:00:58.099709 15772 solver.cpp:237]     Train net output #1: loss = 1.3464 (* 1 = 1.3464 loss)
I1210 16:00:58.099709 15772 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1210 16:01:03.752351 15772 solver.cpp:218] Iteration 37800 (17.6917 iter/s, 5.65236s/100 iters), loss = 1.85518
I1210 16:01:03.752351 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 16:01:03.752351 15772 solver.cpp:237]     Train net output #1: loss = 1.85518 (* 1 = 1.85518 loss)
I1210 16:01:03.752351 15772 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1210 16:01:09.405808 15772 solver.cpp:218] Iteration 37900 (17.6888 iter/s, 5.65331s/100 iters), loss = 1.61371
I1210 16:01:09.406810 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:01:09.406810 15772 solver.cpp:237]     Train net output #1: loss = 1.61371 (* 1 = 1.61371 loss)
I1210 16:01:09.406810 15772 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1210 16:01:14.783226 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:01:15.006234 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_38000.caffemodel
I1210 16:01:15.020243 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_38000.solverstate
I1210 16:01:15.040252 15772 solver.cpp:330] Iteration 38000, Testing net (#0)
I1210 16:01:15.040252 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:01:16.409348 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:01:16.463357 15772 solver.cpp:397]     Test net output #0: accuracy = 0.389
I1210 16:01:16.463357 15772 solver.cpp:397]     Test net output #1: loss = 2.35362 (* 1 = 2.35362 loss)
I1210 16:01:16.516356 15772 solver.cpp:218] Iteration 38000 (14.0655 iter/s, 7.10959s/100 iters), loss = 1.61664
I1210 16:01:16.516356 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 16:01:16.516356 15772 solver.cpp:237]     Train net output #1: loss = 1.61664 (* 1 = 1.61664 loss)
I1210 16:01:16.516356 15772 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1210 16:01:22.163818 15772 solver.cpp:218] Iteration 38100 (17.7069 iter/s, 5.64752s/100 iters), loss = 1.69244
I1210 16:01:22.164819 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 16:01:22.164819 15772 solver.cpp:237]     Train net output #1: loss = 1.69244 (* 1 = 1.69244 loss)
I1210 16:01:22.164819 15772 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1210 16:01:27.804652 15772 solver.cpp:218] Iteration 38200 (17.7309 iter/s, 5.63986s/100 iters), loss = 1.49828
I1210 16:01:27.804652 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 16:01:27.804652 15772 solver.cpp:237]     Train net output #1: loss = 1.49828 (* 1 = 1.49828 loss)
I1210 16:01:27.804652 15772 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1210 16:01:33.440654 15772 solver.cpp:218] Iteration 38300 (17.7463 iter/s, 5.63497s/100 iters), loss = 1.83466
I1210 16:01:33.440654 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:01:33.440654 15772 solver.cpp:237]     Train net output #1: loss = 1.83466 (* 1 = 1.83466 loss)
I1210 16:01:33.440654 15772 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1210 16:01:39.073743 15772 solver.cpp:218] Iteration 38400 (17.7519 iter/s, 5.6332s/100 iters), loss = 1.81541
I1210 16:01:39.073743 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 16:01:39.073743 15772 solver.cpp:237]     Train net output #1: loss = 1.81541 (* 1 = 1.81541 loss)
I1210 16:01:39.073743 15772 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1210 16:01:44.444679 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:01:44.666193 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_38500.caffemodel
I1210 16:01:44.681195 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_38500.solverstate
I1210 16:01:44.685194 15772 solver.cpp:330] Iteration 38500, Testing net (#0)
I1210 16:01:44.686194 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:01:46.058344 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:01:46.112342 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3242
I1210 16:01:46.112342 15772 solver.cpp:397]     Test net output #1: loss = 2.87602 (* 1 = 2.87602 loss)
I1210 16:01:46.165349 15772 solver.cpp:218] Iteration 38500 (14.1024 iter/s, 7.09097s/100 iters), loss = 1.72289
I1210 16:01:46.165349 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:01:46.165349 15772 solver.cpp:237]     Train net output #1: loss = 1.72289 (* 1 = 1.72289 loss)
I1210 16:01:46.165349 15772 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1210 16:01:51.799788 15772 solver.cpp:218] Iteration 38600 (17.7478 iter/s, 5.6345s/100 iters), loss = 1.58505
I1210 16:01:51.799788 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 16:01:51.800789 15772 solver.cpp:237]     Train net output #1: loss = 1.58505 (* 1 = 1.58505 loss)
I1210 16:01:51.800789 15772 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1210 16:01:57.444706 15772 solver.cpp:218] Iteration 38700 (17.7191 iter/s, 5.64361s/100 iters), loss = 1.48021
I1210 16:01:57.444706 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 16:01:57.444706 15772 solver.cpp:237]     Train net output #1: loss = 1.48021 (* 1 = 1.48021 loss)
I1210 16:01:57.444706 15772 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1210 16:02:03.092703 15772 solver.cpp:218] Iteration 38800 (17.7039 iter/s, 5.64847s/100 iters), loss = 1.76391
I1210 16:02:03.093705 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 16:02:03.093705 15772 solver.cpp:237]     Train net output #1: loss = 1.76391 (* 1 = 1.76391 loss)
I1210 16:02:03.093705 15772 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1210 16:02:08.731135 15772 solver.cpp:218] Iteration 38900 (17.7397 iter/s, 5.63708s/100 iters), loss = 1.86591
I1210 16:02:08.731135 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 16:02:08.731135 15772 solver.cpp:237]     Train net output #1: loss = 1.86591 (* 1 = 1.86591 loss)
I1210 16:02:08.731135 15772 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1210 16:02:14.101805 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:02:14.323815 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_39000.caffemodel
I1210 16:02:14.338816 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_39000.solverstate
I1210 16:02:14.343817 15772 solver.cpp:330] Iteration 39000, Testing net (#0)
I1210 16:02:14.343817 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:02:15.716954 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:02:15.770963 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3147
I1210 16:02:15.770963 15772 solver.cpp:397]     Test net output #1: loss = 2.96918 (* 1 = 2.96918 loss)
I1210 16:02:15.823962 15772 solver.cpp:218] Iteration 39000 (14.0986 iter/s, 7.09289s/100 iters), loss = 1.57697
I1210 16:02:15.823962 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:02:15.823962 15772 solver.cpp:237]     Train net output #1: loss = 1.57697 (* 1 = 1.57697 loss)
I1210 16:02:15.823962 15772 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1210 16:02:21.471580 15772 solver.cpp:218] Iteration 39100 (17.7093 iter/s, 5.64676s/100 iters), loss = 1.68438
I1210 16:02:21.471580 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 16:02:21.471580 15772 solver.cpp:237]     Train net output #1: loss = 1.68438 (* 1 = 1.68438 loss)
I1210 16:02:21.471580 15772 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1210 16:02:27.114107 15772 solver.cpp:218] Iteration 39200 (17.7232 iter/s, 5.64234s/100 iters), loss = 1.41046
I1210 16:02:27.114107 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 16:02:27.114107 15772 solver.cpp:237]     Train net output #1: loss = 1.41046 (* 1 = 1.41046 loss)
I1210 16:02:27.114107 15772 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1210 16:02:32.761642 15772 solver.cpp:218] Iteration 39300 (17.7099 iter/s, 5.64654s/100 iters), loss = 1.79
I1210 16:02:32.761642 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 16:02:32.761642 15772 solver.cpp:237]     Train net output #1: loss = 1.79 (* 1 = 1.79 loss)
I1210 16:02:32.761642 15772 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1210 16:02:38.407114 15772 solver.cpp:218] Iteration 39400 (17.712 iter/s, 5.6459s/100 iters), loss = 1.73692
I1210 16:02:38.408114 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 16:02:38.408114 15772 solver.cpp:237]     Train net output #1: loss = 1.73692 (* 1 = 1.73692 loss)
I1210 16:02:38.408114 15772 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1210 16:02:43.779080 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:02:44.002089 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_39500.caffemodel
I1210 16:02:44.015089 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_39500.solverstate
I1210 16:02:44.020095 15772 solver.cpp:330] Iteration 39500, Testing net (#0)
I1210 16:02:44.021096 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:02:45.394209 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:02:45.447212 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3419
I1210 16:02:45.447212 15772 solver.cpp:397]     Test net output #1: loss = 2.80698 (* 1 = 2.80698 loss)
I1210 16:02:45.500211 15772 solver.cpp:218] Iteration 39500 (14.0999 iter/s, 7.09223s/100 iters), loss = 1.70125
I1210 16:02:45.500211 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:02:45.500211 15772 solver.cpp:237]     Train net output #1: loss = 1.70125 (* 1 = 1.70125 loss)
I1210 16:02:45.500211 15772 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1210 16:02:51.141798 15772 solver.cpp:218] Iteration 39600 (17.7287 iter/s, 5.64058s/100 iters), loss = 1.54095
I1210 16:02:51.141798 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:02:51.141798 15772 solver.cpp:237]     Train net output #1: loss = 1.54095 (* 1 = 1.54095 loss)
I1210 16:02:51.141798 15772 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1210 16:02:56.794296 15772 solver.cpp:218] Iteration 39700 (17.6905 iter/s, 5.65274s/100 iters), loss = 1.43757
I1210 16:02:56.794296 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 16:02:56.794296 15772 solver.cpp:237]     Train net output #1: loss = 1.43757 (* 1 = 1.43757 loss)
I1210 16:02:56.794296 15772 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1210 16:03:02.436599 15772 solver.cpp:218] Iteration 39800 (17.7268 iter/s, 5.64119s/100 iters), loss = 1.73251
I1210 16:03:02.436599 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 16:03:02.436599 15772 solver.cpp:237]     Train net output #1: loss = 1.73251 (* 1 = 1.73251 loss)
I1210 16:03:02.436599 15772 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1210 16:03:08.072165 15772 solver.cpp:218] Iteration 39900 (17.745 iter/s, 5.6354s/100 iters), loss = 1.72841
I1210 16:03:08.072165 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:03:08.072165 15772 solver.cpp:237]     Train net output #1: loss = 1.72841 (* 1 = 1.72841 loss)
I1210 16:03:08.072165 15772 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1210 16:03:13.425326 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:03:13.647922 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_40000.caffemodel
I1210 16:03:13.661926 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_40000.solverstate
I1210 16:03:13.689944 15772 solver.cpp:330] Iteration 40000, Testing net (#0)
I1210 16:03:13.689944 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:03:15.058578 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:03:15.112591 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3913
I1210 16:03:15.112591 15772 solver.cpp:397]     Test net output #1: loss = 2.36846 (* 1 = 2.36846 loss)
I1210 16:03:15.165637 15772 solver.cpp:218] Iteration 40000 (14.0982 iter/s, 7.09312s/100 iters), loss = 1.68964
I1210 16:03:15.165637 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:03:15.165637 15772 solver.cpp:237]     Train net output #1: loss = 1.68964 (* 1 = 1.68964 loss)
I1210 16:03:15.165637 15772 sgd_solver.cpp:105] Iteration 40000, lr = 0.1
I1210 16:03:20.796077 15772 solver.cpp:218] Iteration 40100 (17.7602 iter/s, 5.63057s/100 iters), loss = 1.5043
I1210 16:03:20.797078 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 16:03:20.797078 15772 solver.cpp:237]     Train net output #1: loss = 1.5043 (* 1 = 1.5043 loss)
I1210 16:03:20.797078 15772 sgd_solver.cpp:105] Iteration 40100, lr = 0.1
I1210 16:03:26.424765 15772 solver.cpp:218] Iteration 40200 (17.7701 iter/s, 5.62742s/100 iters), loss = 1.37988
I1210 16:03:26.424765 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:03:26.424765 15772 solver.cpp:237]     Train net output #1: loss = 1.37988 (* 1 = 1.37988 loss)
I1210 16:03:26.424765 15772 sgd_solver.cpp:105] Iteration 40200, lr = 0.1
I1210 16:03:32.065256 15772 solver.cpp:218] Iteration 40300 (17.7297 iter/s, 5.64024s/100 iters), loss = 1.77618
I1210 16:03:32.065256 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 16:03:32.065256 15772 solver.cpp:237]     Train net output #1: loss = 1.77618 (* 1 = 1.77618 loss)
I1210 16:03:32.065256 15772 sgd_solver.cpp:105] Iteration 40300, lr = 0.1
I1210 16:03:37.703660 15772 solver.cpp:218] Iteration 40400 (17.7358 iter/s, 5.63831s/100 iters), loss = 1.88029
I1210 16:03:37.703660 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:03:37.703660 15772 solver.cpp:237]     Train net output #1: loss = 1.88029 (* 1 = 1.88029 loss)
I1210 16:03:37.703660 15772 sgd_solver.cpp:105] Iteration 40400, lr = 0.1
I1210 16:03:43.061055 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:03:43.284066 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_40500.caffemodel
I1210 16:03:43.299065 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_40500.solverstate
I1210 16:03:43.304075 15772 solver.cpp:330] Iteration 40500, Testing net (#0)
I1210 16:03:43.304075 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:03:44.674142 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:03:44.728143 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3439
I1210 16:03:44.728143 15772 solver.cpp:397]     Test net output #1: loss = 2.71067 (* 1 = 2.71067 loss)
I1210 16:03:44.781152 15772 solver.cpp:218] Iteration 40500 (14.1308 iter/s, 7.07673s/100 iters), loss = 1.62195
I1210 16:03:44.781152 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 16:03:44.781152 15772 solver.cpp:237]     Train net output #1: loss = 1.62195 (* 1 = 1.62195 loss)
I1210 16:03:44.781152 15772 sgd_solver.cpp:105] Iteration 40500, lr = 0.1
I1210 16:03:50.417593 15772 solver.cpp:218] Iteration 40600 (17.7433 iter/s, 5.63595s/100 iters), loss = 1.61451
I1210 16:03:50.417593 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 16:03:50.417593 15772 solver.cpp:237]     Train net output #1: loss = 1.61451 (* 1 = 1.61451 loss)
I1210 16:03:50.417593 15772 sgd_solver.cpp:105] Iteration 40600, lr = 0.1
I1210 16:03:56.059000 15772 solver.cpp:218] Iteration 40700 (17.728 iter/s, 5.6408s/100 iters), loss = 1.38774
I1210 16:03:56.059000 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:03:56.059000 15772 solver.cpp:237]     Train net output #1: loss = 1.38774 (* 1 = 1.38774 loss)
I1210 16:03:56.059000 15772 sgd_solver.cpp:105] Iteration 40700, lr = 0.1
I1210 16:04:01.695761 15772 solver.cpp:218] Iteration 40800 (17.7409 iter/s, 5.63668s/100 iters), loss = 1.97416
I1210 16:04:01.695761 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 16:04:01.695761 15772 solver.cpp:237]     Train net output #1: loss = 1.97416 (* 1 = 1.97416 loss)
I1210 16:04:01.695761 15772 sgd_solver.cpp:105] Iteration 40800, lr = 0.1
I1210 16:04:07.329252 15772 solver.cpp:218] Iteration 40900 (17.7519 iter/s, 5.63321s/100 iters), loss = 1.74273
I1210 16:04:07.330252 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:04:07.330252 15772 solver.cpp:237]     Train net output #1: loss = 1.74273 (* 1 = 1.74273 loss)
I1210 16:04:07.330252 15772 sgd_solver.cpp:105] Iteration 40900, lr = 0.1
I1210 16:04:12.688603 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:04:12.909621 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_41000.caffemodel
I1210 16:04:12.924620 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_41000.solverstate
I1210 16:04:12.928620 15772 solver.cpp:330] Iteration 41000, Testing net (#0)
I1210 16:04:12.928620 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:04:14.302762 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:04:14.356766 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3439
I1210 16:04:14.356766 15772 solver.cpp:397]     Test net output #1: loss = 2.9362 (* 1 = 2.9362 loss)
I1210 16:04:14.409770 15772 solver.cpp:218] Iteration 41000 (14.1258 iter/s, 7.07924s/100 iters), loss = 1.73853
I1210 16:04:14.409770 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:04:14.409770 15772 solver.cpp:237]     Train net output #1: loss = 1.73853 (* 1 = 1.73853 loss)
I1210 16:04:14.409770 15772 sgd_solver.cpp:105] Iteration 41000, lr = 0.1
I1210 16:04:20.058600 15772 solver.cpp:218] Iteration 41100 (17.7048 iter/s, 5.64817s/100 iters), loss = 1.5671
I1210 16:04:20.058600 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 16:04:20.058600 15772 solver.cpp:237]     Train net output #1: loss = 1.5671 (* 1 = 1.5671 loss)
I1210 16:04:20.058600 15772 sgd_solver.cpp:105] Iteration 41100, lr = 0.1
I1210 16:04:25.713516 15772 solver.cpp:218] Iteration 41200 (17.6851 iter/s, 5.65447s/100 iters), loss = 1.44682
I1210 16:04:25.713516 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 16:04:25.713516 15772 solver.cpp:237]     Train net output #1: loss = 1.44682 (* 1 = 1.44682 loss)
I1210 16:04:25.713516 15772 sgd_solver.cpp:105] Iteration 41200, lr = 0.1
I1210 16:04:31.362949 15772 solver.cpp:218] Iteration 41300 (17.7019 iter/s, 5.64912s/100 iters), loss = 1.98483
I1210 16:04:31.362949 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 16:04:31.362949 15772 solver.cpp:237]     Train net output #1: loss = 1.98483 (* 1 = 1.98483 loss)
I1210 16:04:31.362949 15772 sgd_solver.cpp:105] Iteration 41300, lr = 0.1
I1210 16:04:37.014403 15772 solver.cpp:218] Iteration 41400 (17.6961 iter/s, 5.65097s/100 iters), loss = 1.66781
I1210 16:04:37.014403 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 16:04:37.014403 15772 solver.cpp:237]     Train net output #1: loss = 1.66781 (* 1 = 1.66781 loss)
I1210 16:04:37.014403 15772 sgd_solver.cpp:105] Iteration 41400, lr = 0.1
I1210 16:04:42.386806 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:04:42.609819 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_41500.caffemodel
I1210 16:04:42.623821 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_41500.solverstate
I1210 16:04:42.628821 15772 solver.cpp:330] Iteration 41500, Testing net (#0)
I1210 16:04:42.628821 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:04:43.997946 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:04:44.052961 15772 solver.cpp:397]     Test net output #0: accuracy = 0.299
I1210 16:04:44.052961 15772 solver.cpp:397]     Test net output #1: loss = 3.05159 (* 1 = 3.05159 loss)
I1210 16:04:44.105964 15772 solver.cpp:218] Iteration 41500 (14.1007 iter/s, 7.09184s/100 iters), loss = 1.92208
I1210 16:04:44.106964 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 16:04:44.106964 15772 solver.cpp:237]     Train net output #1: loss = 1.92208 (* 1 = 1.92208 loss)
I1210 16:04:44.106964 15772 sgd_solver.cpp:105] Iteration 41500, lr = 0.1
I1210 16:04:49.744382 15772 solver.cpp:218] Iteration 41600 (17.7382 iter/s, 5.63754s/100 iters), loss = 1.53241
I1210 16:04:49.744382 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:04:49.744382 15772 solver.cpp:237]     Train net output #1: loss = 1.53241 (* 1 = 1.53241 loss)
I1210 16:04:49.744382 15772 sgd_solver.cpp:105] Iteration 41600, lr = 0.1
I1210 16:04:55.394847 15772 solver.cpp:218] Iteration 41700 (17.698 iter/s, 5.65036s/100 iters), loss = 1.53011
I1210 16:04:55.394847 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:04:55.394847 15772 solver.cpp:237]     Train net output #1: loss = 1.53011 (* 1 = 1.53011 loss)
I1210 16:04:55.394847 15772 sgd_solver.cpp:105] Iteration 41700, lr = 0.1
I1210 16:05:01.041261 15772 solver.cpp:218] Iteration 41800 (17.7144 iter/s, 5.64514s/100 iters), loss = 1.907
I1210 16:05:01.041261 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 16:05:01.041261 15772 solver.cpp:237]     Train net output #1: loss = 1.907 (* 1 = 1.907 loss)
I1210 16:05:01.041261 15772 sgd_solver.cpp:105] Iteration 41800, lr = 0.1
I1210 16:05:06.681000 15772 solver.cpp:218] Iteration 41900 (17.731 iter/s, 5.63984s/100 iters), loss = 1.75678
I1210 16:05:06.681000 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:05:06.681000 15772 solver.cpp:237]     Train net output #1: loss = 1.75678 (* 1 = 1.75678 loss)
I1210 16:05:06.681000 15772 sgd_solver.cpp:105] Iteration 41900, lr = 0.1
I1210 16:05:12.054261 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:05:12.276319 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_42000.caffemodel
I1210 16:05:12.290319 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_42000.solverstate
I1210 16:05:12.323320 15772 solver.cpp:330] Iteration 42000, Testing net (#0)
I1210 16:05:12.323320 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:05:13.696436 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:05:13.749938 15772 solver.cpp:397]     Test net output #0: accuracy = 0.4432
I1210 16:05:13.749938 15772 solver.cpp:397]     Test net output #1: loss = 2.11702 (* 1 = 2.11702 loss)
I1210 16:05:13.803441 15772 solver.cpp:218] Iteration 42000 (14.0425 iter/s, 7.12126s/100 iters), loss = 1.66116
I1210 16:05:13.803441 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:05:13.803441 15772 solver.cpp:237]     Train net output #1: loss = 1.66116 (* 1 = 1.66116 loss)
I1210 16:05:13.803441 15772 sgd_solver.cpp:105] Iteration 42000, lr = 0.1
I1210 16:05:19.444896 15772 solver.cpp:218] Iteration 42100 (17.7273 iter/s, 5.64103s/100 iters), loss = 1.55699
I1210 16:05:19.444896 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:05:19.444896 15772 solver.cpp:237]     Train net output #1: loss = 1.55699 (* 1 = 1.55699 loss)
I1210 16:05:19.444896 15772 sgd_solver.cpp:105] Iteration 42100, lr = 0.1
I1210 16:05:25.080325 15772 solver.cpp:218] Iteration 42200 (17.7463 iter/s, 5.63499s/100 iters), loss = 1.52091
I1210 16:05:25.080325 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 16:05:25.080325 15772 solver.cpp:237]     Train net output #1: loss = 1.52091 (* 1 = 1.52091 loss)
I1210 16:05:25.080325 15772 sgd_solver.cpp:105] Iteration 42200, lr = 0.1
I1210 16:05:30.712993 15772 solver.cpp:218] Iteration 42300 (17.753 iter/s, 5.63285s/100 iters), loss = 1.68977
I1210 16:05:30.712993 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 16:05:30.712993 15772 solver.cpp:237]     Train net output #1: loss = 1.68977 (* 1 = 1.68977 loss)
I1210 16:05:30.712993 15772 sgd_solver.cpp:105] Iteration 42300, lr = 0.1
I1210 16:05:36.356956 15772 solver.cpp:218] Iteration 42400 (17.7208 iter/s, 5.6431s/100 iters), loss = 1.80511
I1210 16:05:36.356956 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:05:36.356956 15772 solver.cpp:237]     Train net output #1: loss = 1.80511 (* 1 = 1.80511 loss)
I1210 16:05:36.356956 15772 sgd_solver.cpp:105] Iteration 42400, lr = 0.1
I1210 16:05:41.705054 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:05:41.929548 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_42500.caffemodel
I1210 16:05:41.945544 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_42500.solverstate
I1210 16:05:41.949558 15772 solver.cpp:330] Iteration 42500, Testing net (#0)
I1210 16:05:41.949558 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:05:43.322481 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:05:43.376516 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2687
I1210 16:05:43.376516 15772 solver.cpp:397]     Test net output #1: loss = 3.55469 (* 1 = 3.55469 loss)
I1210 16:05:43.430517 15772 solver.cpp:218] Iteration 42500 (14.1383 iter/s, 7.07301s/100 iters), loss = 1.55741
I1210 16:05:43.430517 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 16:05:43.430517 15772 solver.cpp:237]     Train net output #1: loss = 1.55741 (* 1 = 1.55741 loss)
I1210 16:05:43.430517 15772 sgd_solver.cpp:105] Iteration 42500, lr = 0.1
I1210 16:05:49.061453 15772 solver.cpp:218] Iteration 42600 (17.76 iter/s, 5.63064s/100 iters), loss = 1.72076
I1210 16:05:49.061453 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 16:05:49.061954 15772 solver.cpp:237]     Train net output #1: loss = 1.72076 (* 1 = 1.72076 loss)
I1210 16:05:49.061954 15772 sgd_solver.cpp:105] Iteration 42600, lr = 0.1
I1210 16:05:54.697962 15772 solver.cpp:218] Iteration 42700 (17.7442 iter/s, 5.63564s/100 iters), loss = 1.4088
I1210 16:05:54.697962 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:05:54.697962 15772 solver.cpp:237]     Train net output #1: loss = 1.4088 (* 1 = 1.4088 loss)
I1210 16:05:54.697962 15772 sgd_solver.cpp:105] Iteration 42700, lr = 0.1
I1210 16:06:00.333171 15772 solver.cpp:218] Iteration 42800 (17.747 iter/s, 5.63477s/100 iters), loss = 1.79687
I1210 16:06:00.333171 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 16:06:00.333171 15772 solver.cpp:237]     Train net output #1: loss = 1.79687 (* 1 = 1.79687 loss)
I1210 16:06:00.333171 15772 sgd_solver.cpp:105] Iteration 42800, lr = 0.1
I1210 16:06:05.965173 15772 solver.cpp:218] Iteration 42900 (17.7573 iter/s, 5.63149s/100 iters), loss = 1.84637
I1210 16:06:05.965173 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 16:06:05.965173 15772 solver.cpp:237]     Train net output #1: loss = 1.84637 (* 1 = 1.84637 loss)
I1210 16:06:05.965173 15772 sgd_solver.cpp:105] Iteration 42900, lr = 0.1
I1210 16:06:11.332537 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:06:11.555548 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_43000.caffemodel
I1210 16:06:11.569551 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_43000.solverstate
I1210 16:06:11.574053 15772 solver.cpp:330] Iteration 43000, Testing net (#0)
I1210 16:06:11.574053 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:06:12.944635 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:06:12.998638 15772 solver.cpp:397]     Test net output #0: accuracy = 0.386
I1210 16:06:12.999640 15772 solver.cpp:397]     Test net output #1: loss = 2.5373 (* 1 = 2.5373 loss)
I1210 16:06:13.052639 15772 solver.cpp:218] Iteration 43000 (14.1095 iter/s, 7.08744s/100 iters), loss = 1.61483
I1210 16:06:13.052639 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:06:13.052639 15772 solver.cpp:237]     Train net output #1: loss = 1.61483 (* 1 = 1.61483 loss)
I1210 16:06:13.052639 15772 sgd_solver.cpp:105] Iteration 43000, lr = 0.1
I1210 16:06:18.697154 15772 solver.cpp:218] Iteration 43100 (17.7187 iter/s, 5.64375s/100 iters), loss = 1.58344
I1210 16:06:18.697154 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 16:06:18.697154 15772 solver.cpp:237]     Train net output #1: loss = 1.58344 (* 1 = 1.58344 loss)
I1210 16:06:18.697154 15772 sgd_solver.cpp:105] Iteration 43100, lr = 0.1
I1210 16:06:24.346629 15772 solver.cpp:218] Iteration 43200 (17.7018 iter/s, 5.64914s/100 iters), loss = 1.33411
I1210 16:06:24.346629 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 16:06:24.346629 15772 solver.cpp:237]     Train net output #1: loss = 1.33411 (* 1 = 1.33411 loss)
I1210 16:06:24.346629 15772 sgd_solver.cpp:105] Iteration 43200, lr = 0.1
I1210 16:06:29.999109 15772 solver.cpp:218] Iteration 43300 (17.691 iter/s, 5.6526s/100 iters), loss = 1.76406
I1210 16:06:30.000109 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 16:06:30.000109 15772 solver.cpp:237]     Train net output #1: loss = 1.76406 (* 1 = 1.76406 loss)
I1210 16:06:30.000109 15772 sgd_solver.cpp:105] Iteration 43300, lr = 0.1
I1210 16:06:35.648535 15772 solver.cpp:218] Iteration 43400 (17.704 iter/s, 5.64843s/100 iters), loss = 1.74759
I1210 16:06:35.648535 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 16:06:35.648535 15772 solver.cpp:237]     Train net output #1: loss = 1.74759 (* 1 = 1.74759 loss)
I1210 16:06:35.648535 15772 sgd_solver.cpp:105] Iteration 43400, lr = 0.1
I1210 16:06:41.009899 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:06:41.230913 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_43500.caffemodel
I1210 16:06:41.245913 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_43500.solverstate
I1210 16:06:41.249913 15772 solver.cpp:330] Iteration 43500, Testing net (#0)
I1210 16:06:41.249913 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:06:42.621029 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:06:42.677031 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3509
I1210 16:06:42.677031 15772 solver.cpp:397]     Test net output #1: loss = 2.68693 (* 1 = 2.68693 loss)
I1210 16:06:42.729033 15772 solver.cpp:218] Iteration 43500 (14.1235 iter/s, 7.08039s/100 iters), loss = 1.6968
I1210 16:06:42.729033 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 16:06:42.729033 15772 solver.cpp:237]     Train net output #1: loss = 1.6968 (* 1 = 1.6968 loss)
I1210 16:06:42.730042 15772 sgd_solver.cpp:105] Iteration 43500, lr = 0.1
I1210 16:06:48.373632 15772 solver.cpp:218] Iteration 43600 (17.7194 iter/s, 5.64354s/100 iters), loss = 1.57737
I1210 16:06:48.374133 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:06:48.374133 15772 solver.cpp:237]     Train net output #1: loss = 1.57737 (* 1 = 1.57737 loss)
I1210 16:06:48.374133 15772 sgd_solver.cpp:105] Iteration 43600, lr = 0.1
I1210 16:06:54.011083 15772 solver.cpp:218] Iteration 43700 (17.7398 iter/s, 5.63703s/100 iters), loss = 1.46752
I1210 16:06:54.011083 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 16:06:54.011083 15772 solver.cpp:237]     Train net output #1: loss = 1.46752 (* 1 = 1.46752 loss)
I1210 16:06:54.011083 15772 sgd_solver.cpp:105] Iteration 43700, lr = 0.1
I1210 16:06:59.645555 15772 solver.cpp:218] Iteration 43800 (17.7502 iter/s, 5.63373s/100 iters), loss = 1.99339
I1210 16:06:59.645555 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 16:06:59.645555 15772 solver.cpp:237]     Train net output #1: loss = 1.99339 (* 1 = 1.99339 loss)
I1210 16:06:59.645555 15772 sgd_solver.cpp:105] Iteration 43800, lr = 0.1
I1210 16:07:05.293946 15772 solver.cpp:218] Iteration 43900 (17.7048 iter/s, 5.64819s/100 iters), loss = 1.75298
I1210 16:07:05.293946 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:07:05.293946 15772 solver.cpp:237]     Train net output #1: loss = 1.75298 (* 1 = 1.75298 loss)
I1210 16:07:05.293946 15772 sgd_solver.cpp:105] Iteration 43900, lr = 0.1
I1210 16:07:10.664906 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:07:10.886929 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_44000.caffemodel
I1210 16:07:10.902930 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_44000.solverstate
I1210 16:07:10.907930 15772 solver.cpp:330] Iteration 44000, Testing net (#0)
I1210 16:07:10.907930 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:07:12.280531 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:07:12.335036 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3397
I1210 16:07:12.335036 15772 solver.cpp:397]     Test net output #1: loss = 2.67681 (* 1 = 2.67681 loss)
I1210 16:07:12.388069 15772 solver.cpp:218] Iteration 44000 (14.0972 iter/s, 7.0936s/100 iters), loss = 1.72747
I1210 16:07:12.388069 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 16:07:12.388069 15772 solver.cpp:237]     Train net output #1: loss = 1.72747 (* 1 = 1.72747 loss)
I1210 16:07:12.388069 15772 sgd_solver.cpp:105] Iteration 44000, lr = 0.1
I1210 16:07:18.024644 15772 solver.cpp:218] Iteration 44100 (17.7414 iter/s, 5.63655s/100 iters), loss = 1.55976
I1210 16:07:18.024644 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:07:18.024644 15772 solver.cpp:237]     Train net output #1: loss = 1.55976 (* 1 = 1.55976 loss)
I1210 16:07:18.024644 15772 sgd_solver.cpp:105] Iteration 44100, lr = 0.1
I1210 16:07:23.678570 15772 solver.cpp:218] Iteration 44200 (17.6909 iter/s, 5.65263s/100 iters), loss = 1.58373
I1210 16:07:23.678570 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 16:07:23.678570 15772 solver.cpp:237]     Train net output #1: loss = 1.58373 (* 1 = 1.58373 loss)
I1210 16:07:23.678570 15772 sgd_solver.cpp:105] Iteration 44200, lr = 0.1
I1210 16:07:29.319615 15772 solver.cpp:218] Iteration 44300 (17.7266 iter/s, 5.64124s/100 iters), loss = 1.86682
I1210 16:07:29.319615 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 16:07:29.319615 15772 solver.cpp:237]     Train net output #1: loss = 1.86682 (* 1 = 1.86682 loss)
I1210 16:07:29.319615 15772 sgd_solver.cpp:105] Iteration 44300, lr = 0.1
I1210 16:07:34.969115 15772 solver.cpp:218] Iteration 44400 (17.7025 iter/s, 5.64892s/100 iters), loss = 1.76348
I1210 16:07:34.969115 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 16:07:34.969115 15772 solver.cpp:237]     Train net output #1: loss = 1.76348 (* 1 = 1.76348 loss)
I1210 16:07:34.969115 15772 sgd_solver.cpp:105] Iteration 44400, lr = 0.1
I1210 16:07:40.350580 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:07:40.572592 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_44500.caffemodel
I1210 16:07:40.587095 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_44500.solverstate
I1210 16:07:40.591599 15772 solver.cpp:330] Iteration 44500, Testing net (#0)
I1210 16:07:40.591599 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:07:41.963655 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:07:42.019671 15772 solver.cpp:397]     Test net output #0: accuracy = 0.4179
I1210 16:07:42.019671 15772 solver.cpp:397]     Test net output #1: loss = 2.30751 (* 1 = 2.30751 loss)
I1210 16:07:42.073671 15772 solver.cpp:218] Iteration 44500 (14.0764 iter/s, 7.10407s/100 iters), loss = 1.54094
I1210 16:07:42.073671 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:07:42.073671 15772 solver.cpp:237]     Train net output #1: loss = 1.54094 (* 1 = 1.54094 loss)
I1210 16:07:42.073671 15772 sgd_solver.cpp:105] Iteration 44500, lr = 0.1
I1210 16:07:47.721133 15772 solver.cpp:218] Iteration 44600 (17.7092 iter/s, 5.64678s/100 iters), loss = 1.5722
I1210 16:07:47.721133 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:07:47.721133 15772 solver.cpp:237]     Train net output #1: loss = 1.5722 (* 1 = 1.5722 loss)
I1210 16:07:47.721133 15772 sgd_solver.cpp:105] Iteration 44600, lr = 0.1
I1210 16:07:53.374563 15772 solver.cpp:218] Iteration 44700 (17.6913 iter/s, 5.65248s/100 iters), loss = 1.5331
I1210 16:07:53.374563 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 16:07:53.374563 15772 solver.cpp:237]     Train net output #1: loss = 1.5331 (* 1 = 1.5331 loss)
I1210 16:07:53.374563 15772 sgd_solver.cpp:105] Iteration 44700, lr = 0.1
I1210 16:07:59.022034 15772 solver.cpp:218] Iteration 44800 (17.7085 iter/s, 5.647s/100 iters), loss = 1.84151
I1210 16:07:59.022034 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 16:07:59.022034 15772 solver.cpp:237]     Train net output #1: loss = 1.84151 (* 1 = 1.84151 loss)
I1210 16:07:59.022034 15772 sgd_solver.cpp:105] Iteration 44800, lr = 0.1
I1210 16:08:04.685421 15772 solver.cpp:218] Iteration 44900 (17.6575 iter/s, 5.6633s/100 iters), loss = 1.613
I1210 16:08:04.685421 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 16:08:04.685421 15772 solver.cpp:237]     Train net output #1: loss = 1.613 (* 1 = 1.613 loss)
I1210 16:08:04.685421 15772 sgd_solver.cpp:105] Iteration 44900, lr = 0.1
I1210 16:08:10.065819 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:08:10.288846 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_45000.caffemodel
I1210 16:08:10.303849 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_45000.solverstate
I1210 16:08:10.308851 15772 solver.cpp:330] Iteration 45000, Testing net (#0)
I1210 16:08:10.308851 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:08:11.678937 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:08:11.732950 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3931
I1210 16:08:11.732950 15772 solver.cpp:397]     Test net output #1: loss = 2.4452 (* 1 = 2.4452 loss)
I1210 16:08:11.785949 15772 solver.cpp:218] Iteration 45000 (14.0847 iter/s, 7.09988s/100 iters), loss = 1.59644
I1210 16:08:11.785949 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 16:08:11.785949 15772 solver.cpp:237]     Train net output #1: loss = 1.59644 (* 1 = 1.59644 loss)
I1210 16:08:11.785949 15772 sgd_solver.cpp:105] Iteration 45000, lr = 0.1
I1210 16:08:17.434381 15772 solver.cpp:218] Iteration 45100 (17.7041 iter/s, 5.64839s/100 iters), loss = 1.51931
I1210 16:08:17.434381 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 16:08:17.434381 15772 solver.cpp:237]     Train net output #1: loss = 1.51931 (* 1 = 1.51931 loss)
I1210 16:08:17.434381 15772 sgd_solver.cpp:105] Iteration 45100, lr = 0.1
I1210 16:08:23.076851 15772 solver.cpp:218] Iteration 45200 (17.7252 iter/s, 5.64169s/100 iters), loss = 1.43945
I1210 16:08:23.076851 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 16:08:23.076851 15772 solver.cpp:237]     Train net output #1: loss = 1.43945 (* 1 = 1.43945 loss)
I1210 16:08:23.076851 15772 sgd_solver.cpp:105] Iteration 45200, lr = 0.1
I1210 16:08:28.720315 15772 solver.cpp:218] Iteration 45300 (17.7215 iter/s, 5.64285s/100 iters), loss = 1.80854
I1210 16:08:28.720315 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 16:08:28.720315 15772 solver.cpp:237]     Train net output #1: loss = 1.80854 (* 1 = 1.80854 loss)
I1210 16:08:28.720315 15772 sgd_solver.cpp:105] Iteration 45300, lr = 0.1
I1210 16:08:34.362716 15772 solver.cpp:218] Iteration 45400 (17.7226 iter/s, 5.64252s/100 iters), loss = 1.81873
I1210 16:08:34.362716 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:08:34.363718 15772 solver.cpp:237]     Train net output #1: loss = 1.81873 (* 1 = 1.81873 loss)
I1210 16:08:34.363718 15772 sgd_solver.cpp:105] Iteration 45400, lr = 0.1
I1210 16:08:39.722091 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:08:39.945104 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_45500.caffemodel
I1210 16:08:39.961104 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_45500.solverstate
I1210 16:08:39.966104 15772 solver.cpp:330] Iteration 45500, Testing net (#0)
I1210 16:08:39.966104 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:08:41.338198 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:08:41.391196 15772 solver.cpp:397]     Test net output #0: accuracy = 0.2736
I1210 16:08:41.391196 15772 solver.cpp:397]     Test net output #1: loss = 3.46582 (* 1 = 3.46582 loss)
I1210 16:08:41.444200 15772 solver.cpp:218] Iteration 45500 (14.1232 iter/s, 7.08053s/100 iters), loss = 1.68364
I1210 16:08:41.444200 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 16:08:41.444200 15772 solver.cpp:237]     Train net output #1: loss = 1.68364 (* 1 = 1.68364 loss)
I1210 16:08:41.444200 15772 sgd_solver.cpp:105] Iteration 45500, lr = 0.1
I1210 16:08:47.083645 15772 solver.cpp:218] Iteration 45600 (17.733 iter/s, 5.63921s/100 iters), loss = 1.63718
I1210 16:08:47.083645 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:08:47.083645 15772 solver.cpp:237]     Train net output #1: loss = 1.63718 (* 1 = 1.63718 loss)
I1210 16:08:47.083645 15772 sgd_solver.cpp:105] Iteration 45600, lr = 0.1
I1210 16:08:52.727046 15772 solver.cpp:218] Iteration 45700 (17.723 iter/s, 5.6424s/100 iters), loss = 1.48974
I1210 16:08:52.727046 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 16:08:52.727046 15772 solver.cpp:237]     Train net output #1: loss = 1.48974 (* 1 = 1.48974 loss)
I1210 16:08:52.727046 15772 sgd_solver.cpp:105] Iteration 45700, lr = 0.1
I1210 16:08:58.361492 15772 solver.cpp:218] Iteration 45800 (17.7496 iter/s, 5.63392s/100 iters), loss = 1.65253
I1210 16:08:58.361492 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 16:08:58.361492 15772 solver.cpp:237]     Train net output #1: loss = 1.65253 (* 1 = 1.65253 loss)
I1210 16:08:58.361492 15772 sgd_solver.cpp:105] Iteration 45800, lr = 0.1
I1210 16:09:04.002919 15772 solver.cpp:218] Iteration 45900 (17.727 iter/s, 5.64112s/100 iters), loss = 1.82875
I1210 16:09:04.002919 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:09:04.002919 15772 solver.cpp:237]     Train net output #1: loss = 1.82875 (* 1 = 1.82875 loss)
I1210 16:09:04.002919 15772 sgd_solver.cpp:105] Iteration 45900, lr = 0.1
I1210 16:09:09.365372 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:09:09.586374 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_46000.caffemodel
I1210 16:09:09.601878 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_46000.solverstate
I1210 16:09:09.606379 15772 solver.cpp:330] Iteration 46000, Testing net (#0)
I1210 16:09:09.606379 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:09:10.974480 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:09:11.029497 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3583
I1210 16:09:11.029497 15772 solver.cpp:397]     Test net output #1: loss = 2.76115 (* 1 = 2.76115 loss)
I1210 16:09:11.083497 15772 solver.cpp:218] Iteration 46000 (14.1243 iter/s, 7.07999s/100 iters), loss = 1.5706
I1210 16:09:11.083497 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:09:11.083497 15772 solver.cpp:237]     Train net output #1: loss = 1.5706 (* 1 = 1.5706 loss)
I1210 16:09:11.083497 15772 sgd_solver.cpp:105] Iteration 46000, lr = 0.1
I1210 16:09:16.732975 15772 solver.cpp:218] Iteration 46100 (17.6996 iter/s, 5.64983s/100 iters), loss = 1.58554
I1210 16:09:16.732975 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:09:16.732975 15772 solver.cpp:237]     Train net output #1: loss = 1.58554 (* 1 = 1.58554 loss)
I1210 16:09:16.732975 15772 sgd_solver.cpp:105] Iteration 46100, lr = 0.1
I1210 16:09:22.387542 15772 solver.cpp:218] Iteration 46200 (17.6866 iter/s, 5.65398s/100 iters), loss = 1.30086
I1210 16:09:22.387542 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 16:09:22.387542 15772 solver.cpp:237]     Train net output #1: loss = 1.30086 (* 1 = 1.30086 loss)
I1210 16:09:22.387542 15772 sgd_solver.cpp:105] Iteration 46200, lr = 0.1
I1210 16:09:28.030916 15772 solver.cpp:218] Iteration 46300 (17.7209 iter/s, 5.64304s/100 iters), loss = 1.96583
I1210 16:09:28.030916 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 16:09:28.030916 15772 solver.cpp:237]     Train net output #1: loss = 1.96583 (* 1 = 1.96583 loss)
I1210 16:09:28.030916 15772 sgd_solver.cpp:105] Iteration 46300, lr = 0.1
I1210 16:09:33.677420 15772 solver.cpp:218] Iteration 46400 (17.7119 iter/s, 5.64591s/100 iters), loss = 1.78117
I1210 16:09:33.677420 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 16:09:33.677420 15772 solver.cpp:237]     Train net output #1: loss = 1.78117 (* 1 = 1.78117 loss)
I1210 16:09:33.677420 15772 sgd_solver.cpp:105] Iteration 46400, lr = 0.1
I1210 16:09:39.053820 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:09:39.274809 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_46500.caffemodel
I1210 16:09:39.289809 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_46500.solverstate
I1210 16:09:39.293809 15772 solver.cpp:330] Iteration 46500, Testing net (#0)
I1210 16:09:39.293809 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:09:40.667929 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:09:40.721933 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3013
I1210 16:09:40.721933 15772 solver.cpp:397]     Test net output #1: loss = 3.06055 (* 1 = 3.06055 loss)
I1210 16:09:40.775933 15772 solver.cpp:218] Iteration 46500 (14.0898 iter/s, 7.09732s/100 iters), loss = 1.65012
I1210 16:09:40.775933 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:09:40.775933 15772 solver.cpp:237]     Train net output #1: loss = 1.65012 (* 1 = 1.65012 loss)
I1210 16:09:40.775933 15772 sgd_solver.cpp:105] Iteration 46500, lr = 0.1
I1210 16:09:46.423426 15772 solver.cpp:218] Iteration 46600 (17.7074 iter/s, 5.64735s/100 iters), loss = 1.4391
I1210 16:09:46.423426 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 16:09:46.423426 15772 solver.cpp:237]     Train net output #1: loss = 1.4391 (* 1 = 1.4391 loss)
I1210 16:09:46.423426 15772 sgd_solver.cpp:105] Iteration 46600, lr = 0.1
I1210 16:09:52.059864 15772 solver.cpp:218] Iteration 46700 (17.742 iter/s, 5.63635s/100 iters), loss = 1.35191
I1210 16:09:52.059864 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 16:09:52.059864 15772 solver.cpp:237]     Train net output #1: loss = 1.35191 (* 1 = 1.35191 loss)
I1210 16:09:52.059864 15772 sgd_solver.cpp:105] Iteration 46700, lr = 0.1
I1210 16:09:57.695454 15772 solver.cpp:218] Iteration 46800 (17.7478 iter/s, 5.63452s/100 iters), loss = 1.76014
I1210 16:09:57.695454 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:09:57.695454 15772 solver.cpp:237]     Train net output #1: loss = 1.76014 (* 1 = 1.76014 loss)
I1210 16:09:57.695454 15772 sgd_solver.cpp:105] Iteration 46800, lr = 0.1
I1210 16:10:03.364081 15772 solver.cpp:218] Iteration 46900 (17.6423 iter/s, 5.66819s/100 iters), loss = 1.68191
I1210 16:10:03.364081 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:10:03.364081 15772 solver.cpp:237]     Train net output #1: loss = 1.68191 (* 1 = 1.68191 loss)
I1210 16:10:03.364081 15772 sgd_solver.cpp:105] Iteration 46900, lr = 0.1
I1210 16:10:08.725620 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:10:08.947636 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_47000.caffemodel
I1210 16:10:08.962637 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_47000.solverstate
I1210 16:10:08.966636 15772 solver.cpp:330] Iteration 47000, Testing net (#0)
I1210 16:10:08.966636 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:10:10.337741 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:10:10.392745 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3368
I1210 16:10:10.392745 15772 solver.cpp:397]     Test net output #1: loss = 3.03814 (* 1 = 3.03814 loss)
I1210 16:10:10.445780 15772 solver.cpp:218] Iteration 47000 (14.1216 iter/s, 7.08135s/100 iters), loss = 1.51458
I1210 16:10:10.445780 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:10:10.445780 15772 solver.cpp:237]     Train net output #1: loss = 1.51458 (* 1 = 1.51458 loss)
I1210 16:10:10.445780 15772 sgd_solver.cpp:105] Iteration 47000, lr = 0.1
I1210 16:10:16.090430 15772 solver.cpp:218] Iteration 47100 (17.7155 iter/s, 5.64476s/100 iters), loss = 1.48003
I1210 16:10:16.090430 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:10:16.090430 15772 solver.cpp:237]     Train net output #1: loss = 1.48003 (* 1 = 1.48003 loss)
I1210 16:10:16.090430 15772 sgd_solver.cpp:105] Iteration 47100, lr = 0.1
I1210 16:10:21.724828 15772 solver.cpp:218] Iteration 47200 (17.7515 iter/s, 5.63334s/100 iters), loss = 1.38387
I1210 16:10:21.724828 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 16:10:21.724828 15772 solver.cpp:237]     Train net output #1: loss = 1.38387 (* 1 = 1.38387 loss)
I1210 16:10:21.724828 15772 sgd_solver.cpp:105] Iteration 47200, lr = 0.1
I1210 16:10:27.375692 15772 solver.cpp:218] Iteration 47300 (17.6955 iter/s, 5.65115s/100 iters), loss = 1.79289
I1210 16:10:27.376693 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 16:10:27.376693 15772 solver.cpp:237]     Train net output #1: loss = 1.79289 (* 1 = 1.79289 loss)
I1210 16:10:27.376693 15772 sgd_solver.cpp:105] Iteration 47300, lr = 0.1
I1210 16:10:33.033586 15772 solver.cpp:218] Iteration 47400 (17.6792 iter/s, 5.65637s/100 iters), loss = 1.92376
I1210 16:10:33.033586 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 16:10:33.033586 15772 solver.cpp:237]     Train net output #1: loss = 1.92376 (* 1 = 1.92376 loss)
I1210 16:10:33.033586 15772 sgd_solver.cpp:105] Iteration 47400, lr = 0.1
I1210 16:10:38.406556 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:10:38.627566 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_47500.caffemodel
I1210 16:10:38.642069 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_47500.solverstate
I1210 16:10:38.646570 15772 solver.cpp:330] Iteration 47500, Testing net (#0)
I1210 16:10:38.647070 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:10:40.019701 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:10:40.072707 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3661
I1210 16:10:40.073709 15772 solver.cpp:397]     Test net output #1: loss = 2.59594 (* 1 = 2.59594 loss)
I1210 16:10:40.127710 15772 solver.cpp:218] Iteration 47500 (14.0974 iter/s, 7.09349s/100 iters), loss = 1.55989
I1210 16:10:40.127710 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:10:40.127710 15772 solver.cpp:237]     Train net output #1: loss = 1.55989 (* 1 = 1.55989 loss)
I1210 16:10:40.127710 15772 sgd_solver.cpp:105] Iteration 47500, lr = 0.1
I1210 16:10:45.768148 15772 solver.cpp:218] Iteration 47600 (17.7289 iter/s, 5.6405s/100 iters), loss = 1.49181
I1210 16:10:45.768148 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:10:45.768148 15772 solver.cpp:237]     Train net output #1: loss = 1.49181 (* 1 = 1.49181 loss)
I1210 16:10:45.768148 15772 sgd_solver.cpp:105] Iteration 47600, lr = 0.1
I1210 16:10:51.408535 15772 solver.cpp:218] Iteration 47700 (17.7296 iter/s, 5.64029s/100 iters), loss = 1.45788
I1210 16:10:51.408535 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:10:51.408535 15772 solver.cpp:237]     Train net output #1: loss = 1.45788 (* 1 = 1.45788 loss)
I1210 16:10:51.408535 15772 sgd_solver.cpp:105] Iteration 47700, lr = 0.1
I1210 16:10:57.044167 15772 solver.cpp:218] Iteration 47800 (17.7483 iter/s, 5.63434s/100 iters), loss = 1.74936
I1210 16:10:57.044167 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 16:10:57.044167 15772 solver.cpp:237]     Train net output #1: loss = 1.74936 (* 1 = 1.74936 loss)
I1210 16:10:57.044167 15772 sgd_solver.cpp:105] Iteration 47800, lr = 0.1
I1210 16:11:02.682008 15772 solver.cpp:218] Iteration 47900 (17.7365 iter/s, 5.63811s/100 iters), loss = 1.80098
I1210 16:11:02.682008 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:11:02.682008 15772 solver.cpp:237]     Train net output #1: loss = 1.80098 (* 1 = 1.80098 loss)
I1210 16:11:02.682008 15772 sgd_solver.cpp:105] Iteration 47900, lr = 0.1
I1210 16:11:08.042677 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:11:08.262380 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_48000.caffemodel
I1210 16:11:08.299381 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_48000.solverstate
I1210 16:11:08.304381 15772 solver.cpp:330] Iteration 48000, Testing net (#0)
I1210 16:11:08.304381 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:11:09.674809 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:11:09.728806 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3707
I1210 16:11:09.728806 15772 solver.cpp:397]     Test net output #1: loss = 2.68553 (* 1 = 2.68553 loss)
I1210 16:11:09.782361 15772 solver.cpp:218] Iteration 48000 (14.0852 iter/s, 7.09964s/100 iters), loss = 1.61023
I1210 16:11:09.782361 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 16:11:09.782361 15772 solver.cpp:237]     Train net output #1: loss = 1.61023 (* 1 = 1.61023 loss)
I1210 16:11:09.782361 15772 sgd_solver.cpp:105] Iteration 48000, lr = 0.1
I1210 16:11:15.412017 15772 solver.cpp:218] Iteration 48100 (17.7645 iter/s, 5.62921s/100 iters), loss = 1.52671
I1210 16:11:15.412017 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 16:11:15.412017 15772 solver.cpp:237]     Train net output #1: loss = 1.52671 (* 1 = 1.52671 loss)
I1210 16:11:15.412017 15772 sgd_solver.cpp:105] Iteration 48100, lr = 0.1
I1210 16:11:21.062532 15772 solver.cpp:218] Iteration 48200 (17.7006 iter/s, 5.64952s/100 iters), loss = 1.33065
I1210 16:11:21.062532 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 16:11:21.062532 15772 solver.cpp:237]     Train net output #1: loss = 1.33065 (* 1 = 1.33065 loss)
I1210 16:11:21.062532 15772 sgd_solver.cpp:105] Iteration 48200, lr = 0.1
I1210 16:11:26.704957 15772 solver.cpp:218] Iteration 48300 (17.7231 iter/s, 5.64236s/100 iters), loss = 1.84313
I1210 16:11:26.704957 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 16:11:26.704957 15772 solver.cpp:237]     Train net output #1: loss = 1.84313 (* 1 = 1.84313 loss)
I1210 16:11:26.704957 15772 sgd_solver.cpp:105] Iteration 48300, lr = 0.1
I1210 16:11:32.350373 15772 solver.cpp:218] Iteration 48400 (17.7158 iter/s, 5.64469s/100 iters), loss = 1.74037
I1210 16:11:32.350373 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:11:32.350373 15772 solver.cpp:237]     Train net output #1: loss = 1.74037 (* 1 = 1.74037 loss)
I1210 16:11:32.350373 15772 sgd_solver.cpp:105] Iteration 48400, lr = 0.1
I1210 16:11:37.716864 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:11:37.939877 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_48500.caffemodel
I1210 16:11:37.954881 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_48500.solverstate
I1210 16:11:37.959882 15772 solver.cpp:330] Iteration 48500, Testing net (#0)
I1210 16:11:37.959882 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:11:39.329957 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:11:39.384963 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3785
I1210 16:11:39.384963 15772 solver.cpp:397]     Test net output #1: loss = 2.4922 (* 1 = 2.4922 loss)
I1210 16:11:39.437963 15772 solver.cpp:218] Iteration 48500 (14.1092 iter/s, 7.08756s/100 iters), loss = 1.53643
I1210 16:11:39.437963 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 16:11:39.437963 15772 solver.cpp:237]     Train net output #1: loss = 1.53643 (* 1 = 1.53643 loss)
I1210 16:11:39.437963 15772 sgd_solver.cpp:105] Iteration 48500, lr = 0.1
I1210 16:11:45.075433 15772 solver.cpp:218] Iteration 48600 (17.7394 iter/s, 5.63716s/100 iters), loss = 1.52471
I1210 16:11:45.075433 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:11:45.075433 15772 solver.cpp:237]     Train net output #1: loss = 1.52471 (* 1 = 1.52471 loss)
I1210 16:11:45.075433 15772 sgd_solver.cpp:105] Iteration 48600, lr = 0.1
I1210 16:11:50.723933 15772 solver.cpp:218] Iteration 48700 (17.7057 iter/s, 5.6479s/100 iters), loss = 1.45053
I1210 16:11:50.723933 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 16:11:50.723933 15772 solver.cpp:237]     Train net output #1: loss = 1.45053 (* 1 = 1.45053 loss)
I1210 16:11:50.723933 15772 sgd_solver.cpp:105] Iteration 48700, lr = 0.1
I1210 16:11:56.363380 15772 solver.cpp:218] Iteration 48800 (17.7337 iter/s, 5.639s/100 iters), loss = 1.86328
I1210 16:11:56.363881 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 16:11:56.363881 15772 solver.cpp:237]     Train net output #1: loss = 1.86328 (* 1 = 1.86328 loss)
I1210 16:11:56.363881 15772 sgd_solver.cpp:105] Iteration 48800, lr = 0.1
I1210 16:12:02.003795 15772 solver.cpp:218] Iteration 48900 (17.731 iter/s, 5.63984s/100 iters), loss = 1.77463
I1210 16:12:02.003795 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 16:12:02.003795 15772 solver.cpp:237]     Train net output #1: loss = 1.77463 (* 1 = 1.77463 loss)
I1210 16:12:02.003795 15772 sgd_solver.cpp:105] Iteration 48900, lr = 0.1
I1210 16:12:07.363718 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:12:07.585234 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_49000.caffemodel
I1210 16:12:07.624234 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_49000.solverstate
I1210 16:12:07.629235 15772 solver.cpp:330] Iteration 49000, Testing net (#0)
I1210 16:12:07.629235 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:12:09.001354 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:12:09.056360 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3798
I1210 16:12:09.056360 15772 solver.cpp:397]     Test net output #1: loss = 2.53879 (* 1 = 2.53879 loss)
I1210 16:12:09.110378 15772 solver.cpp:218] Iteration 49000 (14.0722 iter/s, 7.1062s/100 iters), loss = 1.74285
I1210 16:12:09.110378 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 16:12:09.110378 15772 solver.cpp:237]     Train net output #1: loss = 1.74285 (* 1 = 1.74285 loss)
I1210 16:12:09.110378 15772 sgd_solver.cpp:105] Iteration 49000, lr = 0.1
I1210 16:12:14.763423 15772 solver.cpp:218] Iteration 49100 (17.691 iter/s, 5.65261s/100 iters), loss = 1.70303
I1210 16:12:14.763423 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 16:12:14.763423 15772 solver.cpp:237]     Train net output #1: loss = 1.70303 (* 1 = 1.70303 loss)
I1210 16:12:14.763423 15772 sgd_solver.cpp:105] Iteration 49100, lr = 0.1
I1210 16:12:20.406293 15772 solver.cpp:218] Iteration 49200 (17.7221 iter/s, 5.64267s/100 iters), loss = 1.45356
I1210 16:12:20.406293 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 16:12:20.406293 15772 solver.cpp:237]     Train net output #1: loss = 1.45356 (* 1 = 1.45356 loss)
I1210 16:12:20.406293 15772 sgd_solver.cpp:105] Iteration 49200, lr = 0.1
I1210 16:12:26.051498 15772 solver.cpp:218] Iteration 49300 (17.7147 iter/s, 5.64503s/100 iters), loss = 1.79469
I1210 16:12:26.051498 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 16:12:26.051498 15772 solver.cpp:237]     Train net output #1: loss = 1.79469 (* 1 = 1.79469 loss)
I1210 16:12:26.051498 15772 sgd_solver.cpp:105] Iteration 49300, lr = 0.1
I1210 16:12:31.695397 15772 solver.cpp:218] Iteration 49400 (17.7217 iter/s, 5.64278s/100 iters), loss = 1.9479
I1210 16:12:31.695397 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 16:12:31.695397 15772 solver.cpp:237]     Train net output #1: loss = 1.9479 (* 1 = 1.9479 loss)
I1210 16:12:31.695397 15772 sgd_solver.cpp:105] Iteration 49400, lr = 0.1
I1210 16:12:37.066550 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:12:37.289073 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_49500.caffemodel
I1210 16:12:37.303073 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_49500.solverstate
I1210 16:12:37.308074 15772 solver.cpp:330] Iteration 49500, Testing net (#0)
I1210 16:12:37.308074 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:12:38.682207 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:12:38.735211 15772 solver.cpp:397]     Test net output #0: accuracy = 0.3471
I1210 16:12:38.735211 15772 solver.cpp:397]     Test net output #1: loss = 2.73102 (* 1 = 2.73102 loss)
I1210 16:12:38.789216 15772 solver.cpp:218] Iteration 49500 (14.0971 iter/s, 7.09368s/100 iters), loss = 1.78491
I1210 16:12:38.789216 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 16:12:38.789216 15772 solver.cpp:237]     Train net output #1: loss = 1.78491 (* 1 = 1.78491 loss)
I1210 16:12:38.789216 15772 sgd_solver.cpp:105] Iteration 49500, lr = 0.1
I1210 16:12:44.429630 15772 solver.cpp:218] Iteration 49600 (17.7302 iter/s, 5.64008s/100 iters), loss = 1.53141
I1210 16:12:44.429630 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:12:44.429630 15772 solver.cpp:237]     Train net output #1: loss = 1.53141 (* 1 = 1.53141 loss)
I1210 16:12:44.429630 15772 sgd_solver.cpp:105] Iteration 49600, lr = 0.1
I1210 16:12:50.069011 15772 solver.cpp:218] Iteration 49700 (17.7354 iter/s, 5.63845s/100 iters), loss = 1.387
I1210 16:12:50.069011 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 16:12:50.069011 15772 solver.cpp:237]     Train net output #1: loss = 1.387 (* 1 = 1.387 loss)
I1210 16:12:50.069011 15772 sgd_solver.cpp:105] Iteration 49700, lr = 0.1
I1210 16:12:55.717521 15772 solver.cpp:218] Iteration 49800 (17.7054 iter/s, 5.64798s/100 iters), loss = 1.8211
I1210 16:12:55.717521 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 16:12:55.717521 15772 solver.cpp:237]     Train net output #1: loss = 1.8211 (* 1 = 1.8211 loss)
I1210 16:12:55.717521 15772 sgd_solver.cpp:105] Iteration 49800, lr = 0.1
I1210 16:13:01.361990 15772 solver.cpp:218] Iteration 49900 (17.7188 iter/s, 5.64374s/100 iters), loss = 1.79674
I1210 16:13:01.361990 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 16:13:01.361990 15772 solver.cpp:237]     Train net output #1: loss = 1.79674 (* 1 = 1.79674 loss)
I1210 16:13:01.361990 15772 sgd_solver.cpp:105] Iteration 49900, lr = 0.1
I1210 16:13:06.726415 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:13:06.947425 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_50000.caffemodel
I1210 16:13:06.990447 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_50000.solverstate
I1210 16:13:06.996446 15772 solver.cpp:330] Iteration 50000, Testing net (#0)
I1210 16:13:06.996446 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:13:08.371628 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:13:08.424633 15772 solver.cpp:397]     Test net output #0: accuracy = 0.4038
I1210 16:13:08.424633 15772 solver.cpp:397]     Test net output #1: loss = 2.34912 (* 1 = 2.34912 loss)
I1210 16:13:08.479133 15772 solver.cpp:218] Iteration 50000 (14.0515 iter/s, 7.11668s/100 iters), loss = 1.64527
I1210 16:13:08.479133 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 16:13:08.479133 15772 solver.cpp:237]     Train net output #1: loss = 1.64527 (* 1 = 1.64527 loss)
I1210 16:13:08.479133 15772 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I1210 16:13:08.479133 15772 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1210 16:13:14.117043 15772 solver.cpp:218] Iteration 50100 (17.7358 iter/s, 5.63832s/100 iters), loss = 1.1805
I1210 16:13:14.117043 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 16:13:14.118043 15772 solver.cpp:237]     Train net output #1: loss = 1.1805 (* 1 = 1.1805 loss)
I1210 16:13:14.118043 15772 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1210 16:13:19.758482 15772 solver.cpp:218] Iteration 50200 (17.7284 iter/s, 5.64068s/100 iters), loss = 1.03765
I1210 16:13:19.758482 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:13:19.758482 15772 solver.cpp:237]     Train net output #1: loss = 1.03765 (* 1 = 1.03765 loss)
I1210 16:13:19.758482 15772 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1210 16:13:25.398891 15772 solver.cpp:218] Iteration 50300 (17.7306 iter/s, 5.63998s/100 iters), loss = 1.28773
I1210 16:13:25.398891 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 16:13:25.398891 15772 solver.cpp:237]     Train net output #1: loss = 1.28773 (* 1 = 1.28773 loss)
I1210 16:13:25.398891 15772 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1210 16:13:31.035369 15772 solver.cpp:218] Iteration 50400 (17.7422 iter/s, 5.63628s/100 iters), loss = 1.18313
I1210 16:13:31.036368 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 16:13:31.036368 15772 solver.cpp:237]     Train net output #1: loss = 1.18313 (* 1 = 1.18313 loss)
I1210 16:13:31.036368 15772 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1210 16:13:36.394841 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:13:36.617859 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_50500.caffemodel
I1210 16:13:36.632859 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_50500.solverstate
I1210 16:13:36.637858 15772 solver.cpp:330] Iteration 50500, Testing net (#0)
I1210 16:13:36.637858 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:13:38.007964 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:13:38.062971 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6302
I1210 16:13:38.062971 15772 solver.cpp:397]     Test net output #1: loss = 1.29652 (* 1 = 1.29652 loss)
I1210 16:13:38.115965 15772 solver.cpp:218] Iteration 50500 (14.1244 iter/s, 7.07995s/100 iters), loss = 1.08824
I1210 16:13:38.115965 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 16:13:38.115965 15772 solver.cpp:237]     Train net output #1: loss = 1.08824 (* 1 = 1.08824 loss)
I1210 16:13:38.115965 15772 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1210 16:13:43.764395 15772 solver.cpp:218] Iteration 50600 (17.7063 iter/s, 5.64771s/100 iters), loss = 1.08621
I1210 16:13:43.764395 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:13:43.764395 15772 solver.cpp:237]     Train net output #1: loss = 1.08621 (* 1 = 1.08621 loss)
I1210 16:13:43.764395 15772 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1210 16:13:49.418799 15772 solver.cpp:218] Iteration 50700 (17.6886 iter/s, 5.65336s/100 iters), loss = 0.913206
I1210 16:13:49.418799 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:13:49.418799 15772 solver.cpp:237]     Train net output #1: loss = 0.913206 (* 1 = 0.913206 loss)
I1210 16:13:49.418799 15772 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1210 16:13:55.072149 15772 solver.cpp:218] Iteration 50800 (17.6897 iter/s, 5.653s/100 iters), loss = 1.14892
I1210 16:13:55.072149 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 16:13:55.072149 15772 solver.cpp:237]     Train net output #1: loss = 1.14892 (* 1 = 1.14892 loss)
I1210 16:13:55.072149 15772 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1210 16:14:00.724521 15772 solver.cpp:218] Iteration 50900 (17.693 iter/s, 5.65196s/100 iters), loss = 1.08604
I1210 16:14:00.724521 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:14:00.724521 15772 solver.cpp:237]     Train net output #1: loss = 1.08604 (* 1 = 1.08604 loss)
I1210 16:14:00.724521 15772 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1210 16:14:06.094959 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:14:06.317981 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_51000.caffemodel
I1210 16:14:06.358979 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_51000.solverstate
I1210 16:14:06.362979 15772 solver.cpp:330] Iteration 51000, Testing net (#0)
I1210 16:14:06.362979 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:14:07.735110 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:14:07.788611 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6428
I1210 16:14:07.788611 15772 solver.cpp:397]     Test net output #1: loss = 1.24568 (* 1 = 1.24568 loss)
I1210 16:14:07.843116 15772 solver.cpp:218] Iteration 51000 (14.0487 iter/s, 7.11811s/100 iters), loss = 0.912424
I1210 16:14:07.843116 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:14:07.843116 15772 solver.cpp:237]     Train net output #1: loss = 0.912424 (* 1 = 0.912424 loss)
I1210 16:14:07.843116 15772 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1210 16:14:13.489070 15772 solver.cpp:218] Iteration 51100 (17.7142 iter/s, 5.64518s/100 iters), loss = 1.10292
I1210 16:14:13.489070 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 16:14:13.489070 15772 solver.cpp:237]     Train net output #1: loss = 1.10292 (* 1 = 1.10292 loss)
I1210 16:14:13.489070 15772 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1210 16:14:19.139065 15772 solver.cpp:218] Iteration 51200 (17.6978 iter/s, 5.65043s/100 iters), loss = 0.921549
I1210 16:14:19.140065 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:14:19.140065 15772 solver.cpp:237]     Train net output #1: loss = 0.921549 (* 1 = 0.921549 loss)
I1210 16:14:19.140065 15772 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1210 16:14:24.789469 15772 solver.cpp:218] Iteration 51300 (17.7018 iter/s, 5.64915s/100 iters), loss = 1.04246
I1210 16:14:24.789469 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 16:14:24.789469 15772 solver.cpp:237]     Train net output #1: loss = 1.04246 (* 1 = 1.04246 loss)
I1210 16:14:24.789469 15772 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1210 16:14:30.434978 15772 solver.cpp:218] Iteration 51400 (17.7145 iter/s, 5.6451s/100 iters), loss = 1.0481
I1210 16:14:30.434978 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 16:14:30.434978 15772 solver.cpp:237]     Train net output #1: loss = 1.0481 (* 1 = 1.0481 loss)
I1210 16:14:30.434978 15772 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1210 16:14:35.805531 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:14:36.027561 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_51500.caffemodel
I1210 16:14:36.047565 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_51500.solverstate
I1210 16:14:36.052559 15772 solver.cpp:330] Iteration 51500, Testing net (#0)
I1210 16:14:36.053557 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:14:37.421664 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:14:37.475664 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6381
I1210 16:14:37.475664 15772 solver.cpp:397]     Test net output #1: loss = 1.25124 (* 1 = 1.25124 loss)
I1210 16:14:37.528668 15772 solver.cpp:218] Iteration 51500 (14.0966 iter/s, 7.09391s/100 iters), loss = 0.850656
I1210 16:14:37.528668 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:14:37.528668 15772 solver.cpp:237]     Train net output #1: loss = 0.850656 (* 1 = 0.850656 loss)
I1210 16:14:37.528668 15772 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1210 16:14:43.165112 15772 solver.cpp:218] Iteration 51600 (17.7452 iter/s, 5.63533s/100 iters), loss = 1.0117
I1210 16:14:43.165112 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 16:14:43.165112 15772 solver.cpp:237]     Train net output #1: loss = 1.0117 (* 1 = 1.0117 loss)
I1210 16:14:43.165112 15772 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1210 16:14:48.802749 15772 solver.cpp:218] Iteration 51700 (17.737 iter/s, 5.63793s/100 iters), loss = 0.844722
I1210 16:14:48.802749 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:14:48.802749 15772 solver.cpp:237]     Train net output #1: loss = 0.844722 (* 1 = 0.844722 loss)
I1210 16:14:48.802749 15772 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1210 16:14:54.441123 15772 solver.cpp:218] Iteration 51800 (17.7376 iter/s, 5.63773s/100 iters), loss = 1.07221
I1210 16:14:54.441123 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 16:14:54.441123 15772 solver.cpp:237]     Train net output #1: loss = 1.07221 (* 1 = 1.07221 loss)
I1210 16:14:54.441123 15772 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1210 16:15:00.082612 15772 solver.cpp:218] Iteration 51900 (17.7279 iter/s, 5.64081s/100 iters), loss = 1.16794
I1210 16:15:00.082612 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 16:15:00.082612 15772 solver.cpp:237]     Train net output #1: loss = 1.16794 (* 1 = 1.16794 loss)
I1210 16:15:00.082612 15772 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1210 16:15:05.438423 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:15:05.660465 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_52000.caffemodel
I1210 16:15:05.699481 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_52000.solverstate
I1210 16:15:05.703990 15772 solver.cpp:330] Iteration 52000, Testing net (#0)
I1210 16:15:05.703990 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:15:07.075006 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:15:07.129029 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6447
I1210 16:15:07.129029 15772 solver.cpp:397]     Test net output #1: loss = 1.23837 (* 1 = 1.23837 loss)
I1210 16:15:07.182027 15772 solver.cpp:218] Iteration 52000 (14.0867 iter/s, 7.09892s/100 iters), loss = 0.802891
I1210 16:15:07.182027 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:15:07.182027 15772 solver.cpp:237]     Train net output #1: loss = 0.802891 (* 1 = 0.802891 loss)
I1210 16:15:07.182027 15772 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1210 16:15:12.826910 15772 solver.cpp:218] Iteration 52100 (17.7159 iter/s, 5.64463s/100 iters), loss = 0.933731
I1210 16:15:12.827909 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:15:12.827909 15772 solver.cpp:237]     Train net output #1: loss = 0.933731 (* 1 = 0.933731 loss)
I1210 16:15:12.827909 15772 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1210 16:15:18.472363 15772 solver.cpp:218] Iteration 52200 (17.717 iter/s, 5.64431s/100 iters), loss = 0.840275
I1210 16:15:18.472363 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:15:18.472363 15772 solver.cpp:237]     Train net output #1: loss = 0.840275 (* 1 = 0.840275 loss)
I1210 16:15:18.472363 15772 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1210 16:15:24.111799 15772 solver.cpp:218] Iteration 52300 (17.7317 iter/s, 5.63962s/100 iters), loss = 1.13793
I1210 16:15:24.111799 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 16:15:24.111799 15772 solver.cpp:237]     Train net output #1: loss = 1.13793 (* 1 = 1.13793 loss)
I1210 16:15:24.111799 15772 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1210 16:15:29.753206 15772 solver.cpp:218] Iteration 52400 (17.7278 iter/s, 5.64086s/100 iters), loss = 0.995862
I1210 16:15:29.753206 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:15:29.753206 15772 solver.cpp:237]     Train net output #1: loss = 0.995862 (* 1 = 0.995862 loss)
I1210 16:15:29.754206 15772 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1210 16:15:35.116114 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:15:35.339202 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_52500.caffemodel
I1210 16:15:35.355204 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_52500.solverstate
I1210 16:15:35.359200 15772 solver.cpp:330] Iteration 52500, Testing net (#0)
I1210 16:15:35.359200 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:15:36.730408 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:15:36.783413 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6484
I1210 16:15:36.783413 15772 solver.cpp:397]     Test net output #1: loss = 1.23311 (* 1 = 1.23311 loss)
I1210 16:15:36.836418 15772 solver.cpp:218] Iteration 52500 (14.1196 iter/s, 7.08236s/100 iters), loss = 0.831286
I1210 16:15:36.836418 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:15:36.836418 15772 solver.cpp:237]     Train net output #1: loss = 0.831286 (* 1 = 0.831286 loss)
I1210 16:15:36.836418 15772 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1210 16:15:42.471519 15772 solver.cpp:218] Iteration 52600 (17.746 iter/s, 5.63507s/100 iters), loss = 0.969725
I1210 16:15:42.471519 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:15:42.471519 15772 solver.cpp:237]     Train net output #1: loss = 0.969725 (* 1 = 0.969725 loss)
I1210 16:15:42.472519 15772 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1210 16:15:48.111884 15772 solver.cpp:218] Iteration 52700 (17.7335 iter/s, 5.63905s/100 iters), loss = 0.858452
I1210 16:15:48.111884 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:15:48.111884 15772 solver.cpp:237]     Train net output #1: loss = 0.858452 (* 1 = 0.858452 loss)
I1210 16:15:48.111884 15772 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1210 16:15:53.758322 15772 solver.cpp:218] Iteration 52800 (17.7119 iter/s, 5.64593s/100 iters), loss = 0.962414
I1210 16:15:53.758322 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:15:53.758322 15772 solver.cpp:237]     Train net output #1: loss = 0.962414 (* 1 = 0.962414 loss)
I1210 16:15:53.758322 15772 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1210 16:15:59.406258 15772 solver.cpp:218] Iteration 52900 (17.7065 iter/s, 5.64765s/100 iters), loss = 0.960914
I1210 16:15:59.406258 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:15:59.406258 15772 solver.cpp:237]     Train net output #1: loss = 0.960914 (* 1 = 0.960914 loss)
I1210 16:15:59.406258 15772 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1210 16:16:04.774150 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:16:04.995160 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_53000.caffemodel
I1210 16:16:05.036193 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_53000.solverstate
I1210 16:16:05.041193 15772 solver.cpp:330] Iteration 53000, Testing net (#0)
I1210 16:16:05.041193 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:16:06.415829 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:16:06.469332 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6399
I1210 16:16:06.469332 15772 solver.cpp:397]     Test net output #1: loss = 1.26971 (* 1 = 1.26971 loss)
I1210 16:16:06.522336 15772 solver.cpp:218] Iteration 53000 (14.053 iter/s, 7.11589s/100 iters), loss = 0.80736
I1210 16:16:06.522336 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:16:06.522336 15772 solver.cpp:237]     Train net output #1: loss = 0.80736 (* 1 = 0.80736 loss)
I1210 16:16:06.522336 15772 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1210 16:16:12.161753 15772 solver.cpp:218] Iteration 53100 (17.7344 iter/s, 5.63877s/100 iters), loss = 0.906248
I1210 16:16:12.161753 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:16:12.161753 15772 solver.cpp:237]     Train net output #1: loss = 0.906248 (* 1 = 0.906248 loss)
I1210 16:16:12.161753 15772 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1210 16:16:17.805631 15772 solver.cpp:218] Iteration 53200 (17.7199 iter/s, 5.64336s/100 iters), loss = 0.817494
I1210 16:16:17.805631 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:16:17.805631 15772 solver.cpp:237]     Train net output #1: loss = 0.817494 (* 1 = 0.817494 loss)
I1210 16:16:17.805631 15772 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1210 16:16:23.444602 15772 solver.cpp:218] Iteration 53300 (17.7351 iter/s, 5.63853s/100 iters), loss = 0.905961
I1210 16:16:23.444602 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:16:23.444602 15772 solver.cpp:237]     Train net output #1: loss = 0.905961 (* 1 = 0.905961 loss)
I1210 16:16:23.444602 15772 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1210 16:16:29.084028 15772 solver.cpp:218] Iteration 53400 (17.7329 iter/s, 5.63923s/100 iters), loss = 1.03827
I1210 16:16:29.084028 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 16:16:29.084028 15772 solver.cpp:237]     Train net output #1: loss = 1.03827 (* 1 = 1.03827 loss)
I1210 16:16:29.084028 15772 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1210 16:16:34.442476 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:16:34.663496 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_53500.caffemodel
I1210 16:16:34.677495 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_53500.solverstate
I1210 16:16:34.682493 15772 solver.cpp:330] Iteration 53500, Testing net (#0)
I1210 16:16:34.682493 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:16:36.053624 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:16:36.107128 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6428
I1210 16:16:36.107128 15772 solver.cpp:397]     Test net output #1: loss = 1.25081 (* 1 = 1.25081 loss)
I1210 16:16:36.160627 15772 solver.cpp:218] Iteration 53500 (14.1327 iter/s, 7.07581s/100 iters), loss = 0.838599
I1210 16:16:36.160627 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:16:36.160627 15772 solver.cpp:237]     Train net output #1: loss = 0.838599 (* 1 = 0.838599 loss)
I1210 16:16:36.160627 15772 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1210 16:16:41.812103 15772 solver.cpp:218] Iteration 53600 (17.6958 iter/s, 5.65107s/100 iters), loss = 0.799828
I1210 16:16:41.812604 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:16:41.812604 15772 solver.cpp:237]     Train net output #1: loss = 0.799828 (* 1 = 0.799828 loss)
I1210 16:16:41.812604 15772 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1210 16:16:47.453354 15772 solver.cpp:218] Iteration 53700 (17.727 iter/s, 5.64112s/100 iters), loss = 0.76548
I1210 16:16:47.453354 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:16:47.453354 15772 solver.cpp:237]     Train net output #1: loss = 0.76548 (* 1 = 0.76548 loss)
I1210 16:16:47.453354 15772 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1210 16:16:53.098346 15772 solver.cpp:218] Iteration 53800 (17.7163 iter/s, 5.64451s/100 iters), loss = 0.998905
I1210 16:16:53.098346 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:16:53.098346 15772 solver.cpp:237]     Train net output #1: loss = 0.998905 (* 1 = 0.998905 loss)
I1210 16:16:53.098346 15772 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1210 16:16:58.742795 15772 solver.cpp:218] Iteration 53900 (17.7181 iter/s, 5.64396s/100 iters), loss = 0.96939
I1210 16:16:58.742795 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:16:58.742795 15772 solver.cpp:237]     Train net output #1: loss = 0.96939 (* 1 = 0.96939 loss)
I1210 16:16:58.742795 15772 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1210 16:17:04.106226 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:17:04.330263 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_54000.caffemodel
I1210 16:17:04.367245 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_54000.solverstate
I1210 16:17:04.372246 15772 solver.cpp:330] Iteration 54000, Testing net (#0)
I1210 16:17:04.372246 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:17:05.744330 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:17:05.797329 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6447
I1210 16:17:05.797329 15772 solver.cpp:397]     Test net output #1: loss = 1.24347 (* 1 = 1.24347 loss)
I1210 16:17:05.851343 15772 solver.cpp:218] Iteration 54000 (14.07 iter/s, 7.10734s/100 iters), loss = 0.819994
I1210 16:17:05.851343 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:17:05.851343 15772 solver.cpp:237]     Train net output #1: loss = 0.819994 (* 1 = 0.819994 loss)
I1210 16:17:05.851343 15772 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1210 16:17:11.500800 15772 solver.cpp:218] Iteration 54100 (17.6998 iter/s, 5.64978s/100 iters), loss = 0.893581
I1210 16:17:11.500800 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:17:11.500800 15772 solver.cpp:237]     Train net output #1: loss = 0.893581 (* 1 = 0.893581 loss)
I1210 16:17:11.500800 15772 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1210 16:17:17.151247 15772 solver.cpp:218] Iteration 54200 (17.6995 iter/s, 5.64988s/100 iters), loss = 0.846222
I1210 16:17:17.151247 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:17:17.151247 15772 solver.cpp:237]     Train net output #1: loss = 0.846222 (* 1 = 0.846222 loss)
I1210 16:17:17.151247 15772 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1210 16:17:22.794203 15772 solver.cpp:218] Iteration 54300 (17.7241 iter/s, 5.64204s/100 iters), loss = 0.944317
I1210 16:17:22.794203 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:17:22.794203 15772 solver.cpp:237]     Train net output #1: loss = 0.944317 (* 1 = 0.944317 loss)
I1210 16:17:22.794203 15772 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1210 16:17:28.440811 15772 solver.cpp:218] Iteration 54400 (17.7113 iter/s, 5.64611s/100 iters), loss = 0.983646
I1210 16:17:28.440811 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:17:28.440811 15772 solver.cpp:237]     Train net output #1: loss = 0.983646 (* 1 = 0.983646 loss)
I1210 16:17:28.440811 15772 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1210 16:17:33.806360 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:17:34.028373 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_54500.caffemodel
I1210 16:17:34.042376 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_54500.solverstate
I1210 16:17:34.047376 15772 solver.cpp:330] Iteration 54500, Testing net (#0)
I1210 16:17:34.047376 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:17:35.419452 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:17:35.473457 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6366
I1210 16:17:35.473457 15772 solver.cpp:397]     Test net output #1: loss = 1.28798 (* 1 = 1.28798 loss)
I1210 16:17:35.526957 15772 solver.cpp:218] Iteration 54500 (14.1131 iter/s, 7.08561s/100 iters), loss = 0.643507
I1210 16:17:35.526957 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:17:35.526957 15772 solver.cpp:237]     Train net output #1: loss = 0.643507 (* 1 = 0.643507 loss)
I1210 16:17:35.526957 15772 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1210 16:17:41.169944 15772 solver.cpp:218] Iteration 54600 (17.7206 iter/s, 5.64314s/100 iters), loss = 0.892392
I1210 16:17:41.169944 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:17:41.169944 15772 solver.cpp:237]     Train net output #1: loss = 0.892392 (* 1 = 0.892392 loss)
I1210 16:17:41.169944 15772 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1210 16:17:46.797360 15772 solver.cpp:218] Iteration 54700 (17.772 iter/s, 5.62684s/100 iters), loss = 0.699483
I1210 16:17:46.797360 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:17:46.797360 15772 solver.cpp:237]     Train net output #1: loss = 0.699483 (* 1 = 0.699483 loss)
I1210 16:17:46.797360 15772 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1210 16:17:52.436825 15772 solver.cpp:218] Iteration 54800 (17.7346 iter/s, 5.6387s/100 iters), loss = 1.06567
I1210 16:17:52.436825 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 16:17:52.436825 15772 solver.cpp:237]     Train net output #1: loss = 1.06567 (* 1 = 1.06567 loss)
I1210 16:17:52.436825 15772 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1210 16:17:58.073359 15772 solver.cpp:218] Iteration 54900 (17.741 iter/s, 5.63665s/100 iters), loss = 1.00187
I1210 16:17:58.073359 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:17:58.073359 15772 solver.cpp:237]     Train net output #1: loss = 1.00187 (* 1 = 1.00187 loss)
I1210 16:17:58.073359 15772 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1210 16:18:03.438797 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:18:03.659821 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_55000.caffemodel
I1210 16:18:03.673821 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_55000.solverstate
I1210 16:18:03.678820 15772 solver.cpp:330] Iteration 55000, Testing net (#0)
I1210 16:18:03.678820 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:18:05.049948 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:18:05.103947 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6484
I1210 16:18:05.103947 15772 solver.cpp:397]     Test net output #1: loss = 1.23784 (* 1 = 1.23784 loss)
I1210 16:18:05.157951 15772 solver.cpp:218] Iteration 55000 (14.1172 iter/s, 7.08358s/100 iters), loss = 0.661632
I1210 16:18:05.157951 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 16:18:05.157951 15772 solver.cpp:237]     Train net output #1: loss = 0.661632 (* 1 = 0.661632 loss)
I1210 16:18:05.157951 15772 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1210 16:18:10.802372 15772 solver.cpp:218] Iteration 55100 (17.7181 iter/s, 5.64394s/100 iters), loss = 0.889197
I1210 16:18:10.802372 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:18:10.802372 15772 solver.cpp:237]     Train net output #1: loss = 0.889197 (* 1 = 0.889197 loss)
I1210 16:18:10.802372 15772 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1210 16:18:16.452770 15772 solver.cpp:218] Iteration 55200 (17.6993 iter/s, 5.64993s/100 iters), loss = 0.725176
I1210 16:18:16.452770 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:18:16.452770 15772 solver.cpp:237]     Train net output #1: loss = 0.725176 (* 1 = 0.725176 loss)
I1210 16:18:16.452770 15772 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1210 16:18:22.100301 15772 solver.cpp:218] Iteration 55300 (17.7059 iter/s, 5.64783s/100 iters), loss = 0.888967
I1210 16:18:22.101300 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:18:22.101300 15772 solver.cpp:237]     Train net output #1: loss = 0.888967 (* 1 = 0.888967 loss)
I1210 16:18:22.101300 15772 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1210 16:18:27.748900 15772 solver.cpp:218] Iteration 55400 (17.7051 iter/s, 5.64808s/100 iters), loss = 0.928546
I1210 16:18:27.749900 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:18:27.749900 15772 solver.cpp:237]     Train net output #1: loss = 0.928546 (* 1 = 0.928546 loss)
I1210 16:18:27.749900 15772 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1210 16:18:33.119385 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:18:33.342406 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_55500.caffemodel
I1210 16:18:33.357406 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_55500.solverstate
I1210 16:18:33.362407 15772 solver.cpp:330] Iteration 55500, Testing net (#0)
I1210 16:18:33.362407 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:18:34.733568 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:18:34.786569 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6381
I1210 16:18:34.787570 15772 solver.cpp:397]     Test net output #1: loss = 1.29463 (* 1 = 1.29463 loss)
I1210 16:18:34.840574 15772 solver.cpp:218] Iteration 55500 (14.1022 iter/s, 7.09109s/100 iters), loss = 0.703319
I1210 16:18:34.840574 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:18:34.840574 15772 solver.cpp:237]     Train net output #1: loss = 0.703319 (* 1 = 0.703319 loss)
I1210 16:18:34.840574 15772 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1210 16:18:40.497056 15772 solver.cpp:218] Iteration 55600 (17.6815 iter/s, 5.65562s/100 iters), loss = 0.839791
I1210 16:18:40.497056 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:18:40.497056 15772 solver.cpp:237]     Train net output #1: loss = 0.839791 (* 1 = 0.839791 loss)
I1210 16:18:40.497056 15772 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1210 16:18:46.147593 15772 solver.cpp:218] Iteration 55700 (17.6995 iter/s, 5.64989s/100 iters), loss = 0.698307
I1210 16:18:46.147593 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:18:46.147593 15772 solver.cpp:237]     Train net output #1: loss = 0.698307 (* 1 = 0.698307 loss)
I1210 16:18:46.147593 15772 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1210 16:18:51.801339 15772 solver.cpp:218] Iteration 55800 (17.6904 iter/s, 5.65279s/100 iters), loss = 0.864094
I1210 16:18:51.801339 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:18:51.801339 15772 solver.cpp:237]     Train net output #1: loss = 0.864094 (* 1 = 0.864094 loss)
I1210 16:18:51.801339 15772 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1210 16:18:57.451910 15772 solver.cpp:218] Iteration 55900 (17.6964 iter/s, 5.65086s/100 iters), loss = 0.911447
I1210 16:18:57.451910 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:18:57.451910 15772 solver.cpp:237]     Train net output #1: loss = 0.911447 (* 1 = 0.911447 loss)
I1210 16:18:57.451910 15772 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1210 16:19:02.822598 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:19:03.044242 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_56000.caffemodel
I1210 16:19:03.060236 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_56000.solverstate
I1210 16:19:03.065235 15772 solver.cpp:330] Iteration 56000, Testing net (#0)
I1210 16:19:03.065235 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:19:04.436149 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:19:04.489665 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6375
I1210 16:19:04.489665 15772 solver.cpp:397]     Test net output #1: loss = 1.2959 (* 1 = 1.2959 loss)
I1210 16:19:04.543292 15772 solver.cpp:218] Iteration 56000 (14.1039 iter/s, 7.09023s/100 iters), loss = 0.761418
I1210 16:19:04.543292 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:19:04.543292 15772 solver.cpp:237]     Train net output #1: loss = 0.761418 (* 1 = 0.761418 loss)
I1210 16:19:04.543292 15772 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1210 16:19:10.189496 15772 solver.cpp:218] Iteration 56100 (17.7116 iter/s, 5.64601s/100 iters), loss = 0.836633
I1210 16:19:10.189496 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:19:10.189496 15772 solver.cpp:237]     Train net output #1: loss = 0.836633 (* 1 = 0.836633 loss)
I1210 16:19:10.189496 15772 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1210 16:19:15.849932 15772 solver.cpp:218] Iteration 56200 (17.6679 iter/s, 5.65998s/100 iters), loss = 0.726566
I1210 16:19:15.849932 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:19:15.849932 15772 solver.cpp:237]     Train net output #1: loss = 0.726566 (* 1 = 0.726566 loss)
I1210 16:19:15.849932 15772 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1210 16:19:21.494535 15772 solver.cpp:218] Iteration 56300 (17.7167 iter/s, 5.6444s/100 iters), loss = 0.87116
I1210 16:19:21.494535 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:19:21.494535 15772 solver.cpp:237]     Train net output #1: loss = 0.87116 (* 1 = 0.87116 loss)
I1210 16:19:21.494535 15772 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1210 16:19:27.131898 15772 solver.cpp:218] Iteration 56400 (17.7397 iter/s, 5.63706s/100 iters), loss = 0.949831
I1210 16:19:27.131898 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:19:27.131898 15772 solver.cpp:237]     Train net output #1: loss = 0.949831 (* 1 = 0.949831 loss)
I1210 16:19:27.131898 15772 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1210 16:19:32.494760 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:19:32.714146 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_56500.caffemodel
I1210 16:19:32.732144 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_56500.solverstate
I1210 16:19:32.736145 15772 solver.cpp:330] Iteration 56500, Testing net (#0)
I1210 16:19:32.736145 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:19:34.105432 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:19:34.159024 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6384
I1210 16:19:34.159024 15772 solver.cpp:397]     Test net output #1: loss = 1.293 (* 1 = 1.293 loss)
I1210 16:19:34.212033 15772 solver.cpp:218] Iteration 56500 (14.1248 iter/s, 7.07973s/100 iters), loss = 0.82258
I1210 16:19:34.212033 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:19:34.212033 15772 solver.cpp:237]     Train net output #1: loss = 0.82258 (* 1 = 0.82258 loss)
I1210 16:19:34.212033 15772 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1210 16:19:39.840095 15772 solver.cpp:218] Iteration 56600 (17.7699 iter/s, 5.62748s/100 iters), loss = 0.850443
I1210 16:19:39.840095 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:19:39.840095 15772 solver.cpp:237]     Train net output #1: loss = 0.850443 (* 1 = 0.850443 loss)
I1210 16:19:39.840095 15772 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1210 16:19:45.470059 15772 solver.cpp:218] Iteration 56700 (17.7628 iter/s, 5.62974s/100 iters), loss = 0.652085
I1210 16:19:45.470059 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:19:45.470059 15772 solver.cpp:237]     Train net output #1: loss = 0.652085 (* 1 = 0.652085 loss)
I1210 16:19:45.470059 15772 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1210 16:19:51.112534 15772 solver.cpp:218] Iteration 56800 (17.7256 iter/s, 5.64157s/100 iters), loss = 0.874176
I1210 16:19:51.112534 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:19:51.112534 15772 solver.cpp:237]     Train net output #1: loss = 0.874176 (* 1 = 0.874176 loss)
I1210 16:19:51.112534 15772 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1210 16:19:56.746004 15772 solver.cpp:218] Iteration 56900 (17.7525 iter/s, 5.63302s/100 iters), loss = 0.904353
I1210 16:19:56.746004 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:19:56.746505 15772 solver.cpp:237]     Train net output #1: loss = 0.904353 (* 1 = 0.904353 loss)
I1210 16:19:56.746505 15772 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1210 16:20:02.125497 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:20:02.347535 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_57000.caffemodel
I1210 16:20:02.401540 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_57000.solverstate
I1210 16:20:02.406540 15772 solver.cpp:330] Iteration 57000, Testing net (#0)
I1210 16:20:02.406540 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:20:03.777693 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:20:03.831706 15772 solver.cpp:397]     Test net output #0: accuracy = 0.64
I1210 16:20:03.831706 15772 solver.cpp:397]     Test net output #1: loss = 1.29143 (* 1 = 1.29143 loss)
I1210 16:20:03.884657 15772 solver.cpp:218] Iteration 57000 (14.0089 iter/s, 7.1383s/100 iters), loss = 0.764601
I1210 16:20:03.884657 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:20:03.884657 15772 solver.cpp:237]     Train net output #1: loss = 0.764601 (* 1 = 0.764601 loss)
I1210 16:20:03.884657 15772 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1210 16:20:09.531324 15772 solver.cpp:218] Iteration 57100 (17.7121 iter/s, 5.64587s/100 iters), loss = 0.878352
I1210 16:20:09.531324 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:20:09.531324 15772 solver.cpp:237]     Train net output #1: loss = 0.878352 (* 1 = 0.878352 loss)
I1210 16:20:09.531324 15772 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1210 16:20:15.162636 15772 solver.cpp:218] Iteration 57200 (17.7579 iter/s, 5.6313s/100 iters), loss = 0.787969
I1210 16:20:15.162636 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:20:15.162636 15772 solver.cpp:237]     Train net output #1: loss = 0.787969 (* 1 = 0.787969 loss)
I1210 16:20:15.162636 15772 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1210 16:20:20.812080 15772 solver.cpp:218] Iteration 57300 (17.7012 iter/s, 5.64933s/100 iters), loss = 0.838615
I1210 16:20:20.813081 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:20:20.813081 15772 solver.cpp:237]     Train net output #1: loss = 0.838615 (* 1 = 0.838615 loss)
I1210 16:20:20.813081 15772 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1210 16:20:26.450024 15772 solver.cpp:218] Iteration 57400 (17.7399 iter/s, 5.63702s/100 iters), loss = 0.927938
I1210 16:20:26.450525 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:20:26.450525 15772 solver.cpp:237]     Train net output #1: loss = 0.927938 (* 1 = 0.927938 loss)
I1210 16:20:26.450525 15772 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1210 16:20:31.811043 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:20:32.032054 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_57500.caffemodel
I1210 16:20:32.047557 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_57500.solverstate
I1210 16:20:32.076063 15772 solver.cpp:330] Iteration 57500, Testing net (#0)
I1210 16:20:32.076063 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:20:33.446137 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:20:33.499140 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6165
I1210 16:20:33.499140 15772 solver.cpp:397]     Test net output #1: loss = 1.3604 (* 1 = 1.3604 loss)
I1210 16:20:33.553647 15772 solver.cpp:218] Iteration 57500 (14.0788 iter/s, 7.10288s/100 iters), loss = 0.798301
I1210 16:20:33.553647 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:20:33.553647 15772 solver.cpp:237]     Train net output #1: loss = 0.798301 (* 1 = 0.798301 loss)
I1210 16:20:33.553647 15772 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1210 16:20:39.192625 15772 solver.cpp:218] Iteration 57600 (17.7357 iter/s, 5.63834s/100 iters), loss = 0.839192
I1210 16:20:39.192625 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:20:39.192625 15772 solver.cpp:237]     Train net output #1: loss = 0.839192 (* 1 = 0.839192 loss)
I1210 16:20:39.192625 15772 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1210 16:20:44.824551 15772 solver.cpp:218] Iteration 57700 (17.756 iter/s, 5.63191s/100 iters), loss = 0.698951
I1210 16:20:44.824551 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:20:44.824551 15772 solver.cpp:237]     Train net output #1: loss = 0.698951 (* 1 = 0.698951 loss)
I1210 16:20:44.824551 15772 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1210 16:20:50.470237 15772 solver.cpp:218] Iteration 57800 (17.7145 iter/s, 5.64509s/100 iters), loss = 0.781503
I1210 16:20:50.470237 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:20:50.470237 15772 solver.cpp:237]     Train net output #1: loss = 0.781503 (* 1 = 0.781503 loss)
I1210 16:20:50.470237 15772 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1210 16:20:56.119660 15772 solver.cpp:218] Iteration 57900 (17.7023 iter/s, 5.64897s/100 iters), loss = 0.927517
I1210 16:20:56.119660 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:20:56.119660 15772 solver.cpp:237]     Train net output #1: loss = 0.927517 (* 1 = 0.927517 loss)
I1210 16:20:56.119660 15772 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1210 16:21:01.483162 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:21:01.703188 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_58000.caffemodel
I1210 16:21:01.719188 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_58000.solverstate
I1210 16:21:01.724189 15772 solver.cpp:330] Iteration 58000, Testing net (#0)
I1210 16:21:01.724189 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:21:03.096663 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:21:03.150666 15772 solver.cpp:397]     Test net output #0: accuracy = 0.619
I1210 16:21:03.150666 15772 solver.cpp:397]     Test net output #1: loss = 1.37082 (* 1 = 1.37082 loss)
I1210 16:21:03.202666 15772 solver.cpp:218] Iteration 58000 (14.1185 iter/s, 7.08293s/100 iters), loss = 0.744307
I1210 16:21:03.202666 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:21:03.202666 15772 solver.cpp:237]     Train net output #1: loss = 0.744307 (* 1 = 0.744307 loss)
I1210 16:21:03.202666 15772 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1210 16:21:08.842133 15772 solver.cpp:218] Iteration 58100 (17.7345 iter/s, 5.63871s/100 iters), loss = 0.688707
I1210 16:21:08.842133 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:21:08.842133 15772 solver.cpp:237]     Train net output #1: loss = 0.688707 (* 1 = 0.688707 loss)
I1210 16:21:08.842133 15772 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1210 16:21:14.475272 15772 solver.cpp:218] Iteration 58200 (17.7519 iter/s, 5.6332s/100 iters), loss = 0.808327
I1210 16:21:14.475272 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:21:14.475272 15772 solver.cpp:237]     Train net output #1: loss = 0.808327 (* 1 = 0.808327 loss)
I1210 16:21:14.475272 15772 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1210 16:21:20.114233 15772 solver.cpp:218] Iteration 58300 (17.7377 iter/s, 5.63771s/100 iters), loss = 0.840189
I1210 16:21:20.114233 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:21:20.114233 15772 solver.cpp:237]     Train net output #1: loss = 0.840189 (* 1 = 0.840189 loss)
I1210 16:21:20.114233 15772 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1210 16:21:25.755100 15772 solver.cpp:218] Iteration 58400 (17.7282 iter/s, 5.64074s/100 iters), loss = 0.933418
I1210 16:21:25.755604 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:21:25.755604 15772 solver.cpp:237]     Train net output #1: loss = 0.933418 (* 1 = 0.933418 loss)
I1210 16:21:25.755604 15772 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1210 16:21:31.110133 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:21:31.332717 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_58500.caffemodel
I1210 16:21:31.347707 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_58500.solverstate
I1210 16:21:31.352228 15772 solver.cpp:330] Iteration 58500, Testing net (#0)
I1210 16:21:31.352711 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:21:32.724136 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:21:32.777175 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6225
I1210 16:21:32.777175 15772 solver.cpp:397]     Test net output #1: loss = 1.36689 (* 1 = 1.36689 loss)
I1210 16:21:32.831178 15772 solver.cpp:218] Iteration 58500 (14.1333 iter/s, 7.07547s/100 iters), loss = 0.675428
I1210 16:21:32.831178 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:21:32.831178 15772 solver.cpp:237]     Train net output #1: loss = 0.675428 (* 1 = 0.675428 loss)
I1210 16:21:32.831178 15772 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1210 16:21:38.470510 15772 solver.cpp:218] Iteration 58600 (17.7341 iter/s, 5.63886s/100 iters), loss = 0.794955
I1210 16:21:38.470510 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:21:38.470510 15772 solver.cpp:237]     Train net output #1: loss = 0.794955 (* 1 = 0.794955 loss)
I1210 16:21:38.470510 15772 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1210 16:21:44.108081 15772 solver.cpp:218] Iteration 58700 (17.7406 iter/s, 5.63679s/100 iters), loss = 0.619162
I1210 16:21:44.108081 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:21:44.108081 15772 solver.cpp:237]     Train net output #1: loss = 0.619162 (* 1 = 0.619162 loss)
I1210 16:21:44.108081 15772 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1210 16:21:49.754853 15772 solver.cpp:218] Iteration 58800 (17.7078 iter/s, 5.64722s/100 iters), loss = 0.938456
I1210 16:21:49.754853 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:21:49.755852 15772 solver.cpp:237]     Train net output #1: loss = 0.938456 (* 1 = 0.938456 loss)
I1210 16:21:49.755852 15772 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1210 16:21:55.396821 15772 solver.cpp:218] Iteration 58900 (17.7277 iter/s, 5.64088s/100 iters), loss = 0.916696
I1210 16:21:55.396821 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:21:55.396821 15772 solver.cpp:237]     Train net output #1: loss = 0.916696 (* 1 = 0.916696 loss)
I1210 16:21:55.396821 15772 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1210 16:22:00.757318 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:22:00.978421 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_59000.caffemodel
I1210 16:22:00.995414 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_59000.solverstate
I1210 16:22:00.999416 15772 solver.cpp:330] Iteration 59000, Testing net (#0)
I1210 16:22:00.999416 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:22:02.370479 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:22:02.424003 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6092
I1210 16:22:02.424003 15772 solver.cpp:397]     Test net output #1: loss = 1.43061 (* 1 = 1.43061 loss)
I1210 16:22:02.477010 15772 solver.cpp:218] Iteration 59000 (14.1248 iter/s, 7.07975s/100 iters), loss = 0.676166
I1210 16:22:02.477010 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:22:02.477010 15772 solver.cpp:237]     Train net output #1: loss = 0.676166 (* 1 = 0.676166 loss)
I1210 16:22:02.477010 15772 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1210 16:22:08.121537 15772 solver.cpp:218] Iteration 59100 (17.7168 iter/s, 5.64436s/100 iters), loss = 0.893413
I1210 16:22:08.121537 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:22:08.121537 15772 solver.cpp:237]     Train net output #1: loss = 0.893413 (* 1 = 0.893413 loss)
I1210 16:22:08.121537 15772 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1210 16:22:13.768945 15772 solver.cpp:218] Iteration 59200 (17.7097 iter/s, 5.64664s/100 iters), loss = 0.722546
I1210 16:22:13.768945 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:22:13.768945 15772 solver.cpp:237]     Train net output #1: loss = 0.722546 (* 1 = 0.722546 loss)
I1210 16:22:13.768945 15772 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1210 16:22:19.417340 15772 solver.cpp:218] Iteration 59300 (17.7061 iter/s, 5.64777s/100 iters), loss = 0.8105
I1210 16:22:19.417340 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:22:19.417340 15772 solver.cpp:237]     Train net output #1: loss = 0.8105 (* 1 = 0.8105 loss)
I1210 16:22:19.417340 15772 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1210 16:22:25.047772 15772 solver.cpp:218] Iteration 59400 (17.7617 iter/s, 5.63008s/100 iters), loss = 0.861682
I1210 16:22:25.047772 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 16:22:25.047772 15772 solver.cpp:237]     Train net output #1: loss = 0.861682 (* 1 = 0.861682 loss)
I1210 16:22:25.047772 15772 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1210 16:22:30.405153 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:22:30.627163 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_59500.caffemodel
I1210 16:22:30.641165 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_59500.solverstate
I1210 16:22:30.646163 15772 solver.cpp:330] Iteration 59500, Testing net (#0)
I1210 16:22:30.646163 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:22:32.018270 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:22:32.072784 15772 solver.cpp:397]     Test net output #0: accuracy = 0.607
I1210 16:22:32.072784 15772 solver.cpp:397]     Test net output #1: loss = 1.44067 (* 1 = 1.44067 loss)
I1210 16:22:32.127279 15772 solver.cpp:218] Iteration 59500 (14.1262 iter/s, 7.07904s/100 iters), loss = 0.734212
I1210 16:22:32.127279 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:22:32.127279 15772 solver.cpp:237]     Train net output #1: loss = 0.734212 (* 1 = 0.734212 loss)
I1210 16:22:32.127279 15772 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1210 16:22:37.763782 15772 solver.cpp:218] Iteration 59600 (17.7435 iter/s, 5.63587s/100 iters), loss = 0.886475
I1210 16:22:37.763782 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:22:37.763782 15772 solver.cpp:237]     Train net output #1: loss = 0.886475 (* 1 = 0.886475 loss)
I1210 16:22:37.763782 15772 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1210 16:22:43.401203 15772 solver.cpp:218] Iteration 59700 (17.7385 iter/s, 5.63744s/100 iters), loss = 0.63622
I1210 16:22:43.401203 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:22:43.401203 15772 solver.cpp:237]     Train net output #1: loss = 0.63622 (* 1 = 0.63622 loss)
I1210 16:22:43.401203 15772 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1210 16:22:49.043611 15772 solver.cpp:218] Iteration 59800 (17.7251 iter/s, 5.64172s/100 iters), loss = 0.924494
I1210 16:22:49.043611 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:22:49.043611 15772 solver.cpp:237]     Train net output #1: loss = 0.924494 (* 1 = 0.924494 loss)
I1210 16:22:49.043611 15772 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1210 16:22:54.689049 15772 solver.cpp:218] Iteration 59900 (17.7156 iter/s, 5.64475s/100 iters), loss = 0.930263
I1210 16:22:54.689049 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:22:54.689049 15772 solver.cpp:237]     Train net output #1: loss = 0.930263 (* 1 = 0.930263 loss)
I1210 16:22:54.689049 15772 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1210 16:23:00.057526 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:23:00.279556 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_60000.caffemodel
I1210 16:23:00.293552 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_60000.solverstate
I1210 16:23:00.298066 15772 solver.cpp:330] Iteration 60000, Testing net (#0)
I1210 16:23:00.298066 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:23:01.670694 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:23:01.723701 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6227
I1210 16:23:01.723701 15772 solver.cpp:397]     Test net output #1: loss = 1.39305 (* 1 = 1.39305 loss)
I1210 16:23:01.777701 15772 solver.cpp:218] Iteration 60000 (14.1077 iter/s, 7.08832s/100 iters), loss = 0.684411
I1210 16:23:01.777701 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:23:01.777701 15772 solver.cpp:237]     Train net output #1: loss = 0.684411 (* 1 = 0.684411 loss)
I1210 16:23:01.777701 15772 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1210 16:23:07.439183 15772 solver.cpp:218] Iteration 60100 (17.6628 iter/s, 5.66161s/100 iters), loss = 0.83995
I1210 16:23:07.439183 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:23:07.439183 15772 solver.cpp:237]     Train net output #1: loss = 0.83995 (* 1 = 0.83995 loss)
I1210 16:23:07.439183 15772 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1210 16:23:13.081638 15772 solver.cpp:218] Iteration 60200 (17.7244 iter/s, 5.64193s/100 iters), loss = 0.707982
I1210 16:23:13.081638 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:23:13.081638 15772 solver.cpp:237]     Train net output #1: loss = 0.707982 (* 1 = 0.707982 loss)
I1210 16:23:13.081638 15772 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1210 16:23:18.733074 15772 solver.cpp:218] Iteration 60300 (17.6957 iter/s, 5.65108s/100 iters), loss = 0.890164
I1210 16:23:18.734076 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:23:18.734076 15772 solver.cpp:237]     Train net output #1: loss = 0.890164 (* 1 = 0.890164 loss)
I1210 16:23:18.734076 15772 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1210 16:23:24.384615 15772 solver.cpp:218] Iteration 60400 (17.6963 iter/s, 5.6509s/100 iters), loss = 0.821
I1210 16:23:24.385617 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:23:24.385617 15772 solver.cpp:237]     Train net output #1: loss = 0.821 (* 1 = 0.821 loss)
I1210 16:23:24.385617 15772 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1210 16:23:29.764111 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:23:29.987138 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_60500.caffemodel
I1210 16:23:30.001641 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_60500.solverstate
I1210 16:23:30.006142 15772 solver.cpp:330] Iteration 60500, Testing net (#0)
I1210 16:23:30.006644 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:23:31.380290 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:23:31.434298 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6203
I1210 16:23:31.434298 15772 solver.cpp:397]     Test net output #1: loss = 1.38205 (* 1 = 1.38205 loss)
I1210 16:23:31.488297 15772 solver.cpp:218] Iteration 60500 (14.08 iter/s, 7.10225s/100 iters), loss = 0.701636
I1210 16:23:31.488297 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:23:31.488297 15772 solver.cpp:237]     Train net output #1: loss = 0.701636 (* 1 = 0.701636 loss)
I1210 16:23:31.488297 15772 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1210 16:23:37.140727 15772 solver.cpp:218] Iteration 60600 (17.6928 iter/s, 5.65202s/100 iters), loss = 0.811147
I1210 16:23:37.140727 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:23:37.140727 15772 solver.cpp:237]     Train net output #1: loss = 0.811147 (* 1 = 0.811147 loss)
I1210 16:23:37.140727 15772 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1210 16:23:42.785185 15772 solver.cpp:218] Iteration 60700 (17.7165 iter/s, 5.64447s/100 iters), loss = 0.694719
I1210 16:23:42.785185 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:23:42.785185 15772 solver.cpp:237]     Train net output #1: loss = 0.694719 (* 1 = 0.694719 loss)
I1210 16:23:42.785185 15772 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1210 16:23:48.441725 15772 solver.cpp:218] Iteration 60800 (17.6804 iter/s, 5.65599s/100 iters), loss = 0.903262
I1210 16:23:48.441725 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:23:48.441725 15772 solver.cpp:237]     Train net output #1: loss = 0.903262 (* 1 = 0.903262 loss)
I1210 16:23:48.441725 15772 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1210 16:23:54.087194 15772 solver.cpp:218] Iteration 60900 (17.7141 iter/s, 5.64523s/100 iters), loss = 0.87827
I1210 16:23:54.087194 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:23:54.087194 15772 solver.cpp:237]     Train net output #1: loss = 0.87827 (* 1 = 0.87827 loss)
I1210 16:23:54.087194 15772 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1210 16:23:59.457677 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:23:59.680688 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_61000.caffemodel
I1210 16:23:59.696689 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_61000.solverstate
I1210 16:23:59.700690 15772 solver.cpp:330] Iteration 61000, Testing net (#0)
I1210 16:23:59.700690 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:24:01.072823 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:24:01.126829 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6088
I1210 16:24:01.126829 15772 solver.cpp:397]     Test net output #1: loss = 1.44663 (* 1 = 1.44663 loss)
I1210 16:24:01.179831 15772 solver.cpp:218] Iteration 61000 (14.1005 iter/s, 7.09196s/100 iters), loss = 0.728729
I1210 16:24:01.179831 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:24:01.179831 15772 solver.cpp:237]     Train net output #1: loss = 0.728729 (* 1 = 0.728729 loss)
I1210 16:24:01.179831 15772 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1210 16:24:06.832326 15772 solver.cpp:218] Iteration 61100 (17.6943 iter/s, 5.65153s/100 iters), loss = 0.782178
I1210 16:24:06.832326 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:24:06.832326 15772 solver.cpp:237]     Train net output #1: loss = 0.782178 (* 1 = 0.782178 loss)
I1210 16:24:06.832326 15772 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1210 16:24:12.486840 15772 solver.cpp:218] Iteration 61200 (17.6858 iter/s, 5.65424s/100 iters), loss = 0.752701
I1210 16:24:12.486840 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:24:12.486840 15772 solver.cpp:237]     Train net output #1: loss = 0.752701 (* 1 = 0.752701 loss)
I1210 16:24:12.486840 15772 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1210 16:24:18.147372 15772 solver.cpp:218] Iteration 61300 (17.6682 iter/s, 5.65988s/100 iters), loss = 0.908785
I1210 16:24:18.147372 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:24:18.147372 15772 solver.cpp:237]     Train net output #1: loss = 0.908785 (* 1 = 0.908785 loss)
I1210 16:24:18.147372 15772 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1210 16:24:23.799762 15772 solver.cpp:218] Iteration 61400 (17.6902 iter/s, 5.65284s/100 iters), loss = 0.950955
I1210 16:24:23.800762 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:24:23.800762 15772 solver.cpp:237]     Train net output #1: loss = 0.950955 (* 1 = 0.950955 loss)
I1210 16:24:23.800762 15772 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1210 16:24:29.167517 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:24:29.388602 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_61500.caffemodel
I1210 16:24:29.402618 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_61500.solverstate
I1210 16:24:29.407618 15772 solver.cpp:330] Iteration 61500, Testing net (#0)
I1210 16:24:29.407618 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:24:30.777937 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:24:30.831957 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6006
I1210 16:24:30.831957 15772 solver.cpp:397]     Test net output #1: loss = 1.48442 (* 1 = 1.48442 loss)
I1210 16:24:30.884974 15772 solver.cpp:218] Iteration 61500 (14.1166 iter/s, 7.08384s/100 iters), loss = 0.719578
I1210 16:24:30.884974 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:24:30.884974 15772 solver.cpp:237]     Train net output #1: loss = 0.719578 (* 1 = 0.719578 loss)
I1210 16:24:30.884974 15772 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1210 16:24:36.515547 15772 solver.cpp:218] Iteration 61600 (17.7595 iter/s, 5.63078s/100 iters), loss = 0.917979
I1210 16:24:36.515547 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:24:36.515547 15772 solver.cpp:237]     Train net output #1: loss = 0.917979 (* 1 = 0.917979 loss)
I1210 16:24:36.515547 15772 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1210 16:24:42.155500 15772 solver.cpp:218] Iteration 61700 (17.7341 iter/s, 5.63884s/100 iters), loss = 0.708085
I1210 16:24:42.155500 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:24:42.155500 15772 solver.cpp:237]     Train net output #1: loss = 0.708085 (* 1 = 0.708085 loss)
I1210 16:24:42.155500 15772 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1210 16:24:47.796283 15772 solver.cpp:218] Iteration 61800 (17.7291 iter/s, 5.64045s/100 iters), loss = 0.781986
I1210 16:24:47.796283 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:24:47.796283 15772 solver.cpp:237]     Train net output #1: loss = 0.781986 (* 1 = 0.781986 loss)
I1210 16:24:47.796283 15772 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1210 16:24:53.436779 15772 solver.cpp:218] Iteration 61900 (17.7299 iter/s, 5.6402s/100 iters), loss = 1.01248
I1210 16:24:53.436779 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 16:24:53.436779 15772 solver.cpp:237]     Train net output #1: loss = 1.01248 (* 1 = 1.01248 loss)
I1210 16:24:53.436779 15772 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1210 16:24:58.799191 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:24:59.019208 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_62000.caffemodel
I1210 16:24:59.037210 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_62000.solverstate
I1210 16:24:59.060216 15772 solver.cpp:330] Iteration 62000, Testing net (#0)
I1210 16:24:59.060216 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:25:00.431301 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:25:00.484304 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6053
I1210 16:25:00.484304 15772 solver.cpp:397]     Test net output #1: loss = 1.4877 (* 1 = 1.4877 loss)
I1210 16:25:00.538810 15772 solver.cpp:218] Iteration 62000 (14.0821 iter/s, 7.10124s/100 iters), loss = 0.694038
I1210 16:25:00.538810 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:25:00.538810 15772 solver.cpp:237]     Train net output #1: loss = 0.694038 (* 1 = 0.694038 loss)
I1210 16:25:00.538810 15772 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1210 16:25:06.186728 15772 solver.cpp:218] Iteration 62100 (17.7055 iter/s, 5.64796s/100 iters), loss = 0.804298
I1210 16:25:06.186728 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:25:06.186728 15772 solver.cpp:237]     Train net output #1: loss = 0.804298 (* 1 = 0.804298 loss)
I1210 16:25:06.186728 15772 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1210 16:25:11.827145 15772 solver.cpp:218] Iteration 62200 (17.7304 iter/s, 5.64003s/100 iters), loss = 0.779913
I1210 16:25:11.827145 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:25:11.827145 15772 solver.cpp:237]     Train net output #1: loss = 0.779913 (* 1 = 0.779913 loss)
I1210 16:25:11.827145 15772 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1210 16:25:17.466008 15772 solver.cpp:218] Iteration 62300 (17.7366 iter/s, 5.63807s/100 iters), loss = 0.795388
I1210 16:25:17.466008 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:25:17.466008 15772 solver.cpp:237]     Train net output #1: loss = 0.795388 (* 1 = 0.795388 loss)
I1210 16:25:17.466008 15772 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1210 16:25:23.104224 15772 solver.cpp:218] Iteration 62400 (17.7379 iter/s, 5.63763s/100 iters), loss = 1.00005
I1210 16:25:23.104224 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:25:23.104224 15772 solver.cpp:237]     Train net output #1: loss = 1.00005 (* 1 = 1.00005 loss)
I1210 16:25:23.104224 15772 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1210 16:25:28.465256 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:25:28.685266 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_62500.caffemodel
I1210 16:25:28.703266 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_62500.solverstate
I1210 16:25:28.707267 15772 solver.cpp:330] Iteration 62500, Testing net (#0)
I1210 16:25:28.707267 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:25:30.078385 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:25:30.132391 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5863
I1210 16:25:30.132391 15772 solver.cpp:397]     Test net output #1: loss = 1.56586 (* 1 = 1.56586 loss)
I1210 16:25:30.185390 15772 solver.cpp:218] Iteration 62500 (14.1217 iter/s, 7.08131s/100 iters), loss = 0.657583
I1210 16:25:30.185390 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:25:30.185390 15772 solver.cpp:237]     Train net output #1: loss = 0.657583 (* 1 = 0.657583 loss)
I1210 16:25:30.185390 15772 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1210 16:25:35.822782 15772 solver.cpp:218] Iteration 62600 (17.7393 iter/s, 5.6372s/100 iters), loss = 0.784847
I1210 16:25:35.822782 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:25:35.822782 15772 solver.cpp:237]     Train net output #1: loss = 0.784847 (* 1 = 0.784847 loss)
I1210 16:25:35.822782 15772 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1210 16:25:41.469187 15772 solver.cpp:218] Iteration 62700 (17.7117 iter/s, 5.64598s/100 iters), loss = 0.703369
I1210 16:25:41.469187 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:25:41.469187 15772 solver.cpp:237]     Train net output #1: loss = 0.703369 (* 1 = 0.703369 loss)
I1210 16:25:41.469187 15772 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1210 16:25:47.110622 15772 solver.cpp:218] Iteration 62800 (17.7269 iter/s, 5.64114s/100 iters), loss = 0.96706
I1210 16:25:47.111624 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:25:47.111624 15772 solver.cpp:237]     Train net output #1: loss = 0.96706 (* 1 = 0.96706 loss)
I1210 16:25:47.111624 15772 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1210 16:25:52.754607 15772 solver.cpp:218] Iteration 62900 (17.7219 iter/s, 5.64273s/100 iters), loss = 0.93808
I1210 16:25:52.754607 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:25:52.754607 15772 solver.cpp:237]     Train net output #1: loss = 0.93808 (* 1 = 0.93808 loss)
I1210 16:25:52.754607 15772 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1210 16:25:58.125602 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:25:58.345234 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_63000.caffemodel
I1210 16:25:58.363240 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_63000.solverstate
I1210 16:25:58.392271 15772 solver.cpp:330] Iteration 63000, Testing net (#0)
I1210 16:25:58.392271 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:25:59.761057 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:25:59.814066 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5947
I1210 16:25:59.814066 15772 solver.cpp:397]     Test net output #1: loss = 1.5422 (* 1 = 1.5422 loss)
I1210 16:25:59.868090 15772 solver.cpp:218] Iteration 63000 (14.0579 iter/s, 7.11342s/100 iters), loss = 0.643535
I1210 16:25:59.868090 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:25:59.868090 15772 solver.cpp:237]     Train net output #1: loss = 0.643535 (* 1 = 0.643535 loss)
I1210 16:25:59.868090 15772 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1210 16:26:05.499581 15772 solver.cpp:218] Iteration 63100 (17.76 iter/s, 5.63064s/100 iters), loss = 0.911886
I1210 16:26:05.499581 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:26:05.499581 15772 solver.cpp:237]     Train net output #1: loss = 0.911886 (* 1 = 0.911886 loss)
I1210 16:26:05.499581 15772 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1210 16:26:11.135977 15772 solver.cpp:218] Iteration 63200 (17.7419 iter/s, 5.63637s/100 iters), loss = 0.738265
I1210 16:26:11.135977 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:26:11.135977 15772 solver.cpp:237]     Train net output #1: loss = 0.738265 (* 1 = 0.738265 loss)
I1210 16:26:11.135977 15772 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1210 16:26:16.773386 15772 solver.cpp:218] Iteration 63300 (17.7403 iter/s, 5.63687s/100 iters), loss = 0.913156
I1210 16:26:16.773386 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 16:26:16.773386 15772 solver.cpp:237]     Train net output #1: loss = 0.913156 (* 1 = 0.913156 loss)
I1210 16:26:16.773386 15772 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1210 16:26:22.410764 15772 solver.cpp:218] Iteration 63400 (17.74 iter/s, 5.63698s/100 iters), loss = 0.892497
I1210 16:26:22.410764 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:26:22.410764 15772 solver.cpp:237]     Train net output #1: loss = 0.892497 (* 1 = 0.892497 loss)
I1210 16:26:22.410764 15772 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1210 16:26:27.783216 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:26:28.004240 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_63500.caffemodel
I1210 16:26:28.020251 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_63500.solverstate
I1210 16:26:28.028250 15772 solver.cpp:330] Iteration 63500, Testing net (#0)
I1210 16:26:28.028250 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:26:29.399350 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:26:29.452350 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6002
I1210 16:26:29.452350 15772 solver.cpp:397]     Test net output #1: loss = 1.51212 (* 1 = 1.51212 loss)
I1210 16:26:29.506853 15772 solver.cpp:218] Iteration 63500 (14.0943 iter/s, 7.09509s/100 iters), loss = 0.656077
I1210 16:26:29.506853 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:26:29.506853 15772 solver.cpp:237]     Train net output #1: loss = 0.656077 (* 1 = 0.656077 loss)
I1210 16:26:29.507364 15772 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1210 16:26:35.151830 15772 solver.cpp:218] Iteration 63600 (17.7152 iter/s, 5.64487s/100 iters), loss = 0.839072
I1210 16:26:35.151830 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 16:26:35.151830 15772 solver.cpp:237]     Train net output #1: loss = 0.839072 (* 1 = 0.839072 loss)
I1210 16:26:35.151830 15772 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1210 16:26:40.795784 15772 solver.cpp:218] Iteration 63700 (17.721 iter/s, 5.64303s/100 iters), loss = 0.699894
I1210 16:26:40.795784 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:26:40.796285 15772 solver.cpp:237]     Train net output #1: loss = 0.699894 (* 1 = 0.699894 loss)
I1210 16:26:40.796285 15772 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1210 16:26:46.441723 15772 solver.cpp:218] Iteration 63800 (17.7126 iter/s, 5.6457s/100 iters), loss = 0.917389
I1210 16:26:46.441723 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:26:46.441723 15772 solver.cpp:237]     Train net output #1: loss = 0.917389 (* 1 = 0.917389 loss)
I1210 16:26:46.441723 15772 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1210 16:26:52.088179 15772 solver.cpp:218] Iteration 63900 (17.711 iter/s, 5.64622s/100 iters), loss = 0.868377
I1210 16:26:52.088179 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:26:52.088179 15772 solver.cpp:237]     Train net output #1: loss = 0.868377 (* 1 = 0.868377 loss)
I1210 16:26:52.088179 15772 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1210 16:26:57.458600 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:26:57.677610 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_64000.caffemodel
I1210 16:26:57.693611 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_64000.solverstate
I1210 16:26:57.742631 15772 solver.cpp:330] Iteration 64000, Testing net (#0)
I1210 16:26:57.742631 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:26:59.113726 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:26:59.166719 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5715
I1210 16:26:59.167721 15772 solver.cpp:397]     Test net output #1: loss = 1.63992 (* 1 = 1.63992 loss)
I1210 16:26:59.222726 15772 solver.cpp:218] Iteration 64000 (14.0186 iter/s, 7.13336s/100 iters), loss = 0.597079
I1210 16:26:59.222726 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:26:59.222726 15772 solver.cpp:237]     Train net output #1: loss = 0.597079 (* 1 = 0.597079 loss)
I1210 16:26:59.222726 15772 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1210 16:27:04.870142 15772 solver.cpp:218] Iteration 64100 (17.7087 iter/s, 5.64693s/100 iters), loss = 0.864807
I1210 16:27:04.870142 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:27:04.870142 15772 solver.cpp:237]     Train net output #1: loss = 0.864807 (* 1 = 0.864807 loss)
I1210 16:27:04.870142 15772 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1210 16:27:10.516603 15772 solver.cpp:218] Iteration 64200 (17.7111 iter/s, 5.64617s/100 iters), loss = 0.664581
I1210 16:27:10.516603 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:27:10.516603 15772 solver.cpp:237]     Train net output #1: loss = 0.664581 (* 1 = 0.664581 loss)
I1210 16:27:10.516603 15772 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1210 16:27:16.176043 15772 solver.cpp:218] Iteration 64300 (17.6712 iter/s, 5.65891s/100 iters), loss = 0.829971
I1210 16:27:16.176043 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:27:16.176043 15772 solver.cpp:237]     Train net output #1: loss = 0.829971 (* 1 = 0.829971 loss)
I1210 16:27:16.176043 15772 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1210 16:27:21.832458 15772 solver.cpp:218] Iteration 64400 (17.6805 iter/s, 5.65596s/100 iters), loss = 0.947259
I1210 16:27:21.832458 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:27:21.832458 15772 solver.cpp:237]     Train net output #1: loss = 0.947259 (* 1 = 0.947259 loss)
I1210 16:27:21.832458 15772 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1210 16:27:27.211185 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:27:27.435199 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_64500.caffemodel
I1210 16:27:27.448199 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_64500.solverstate
I1210 16:27:27.453199 15772 solver.cpp:330] Iteration 64500, Testing net (#0)
I1210 16:27:27.453199 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:27:28.824338 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:27:28.879338 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5758
I1210 16:27:28.879338 15772 solver.cpp:397]     Test net output #1: loss = 1.6529 (* 1 = 1.6529 loss)
I1210 16:27:28.933344 15772 solver.cpp:218] Iteration 64500 (14.0835 iter/s, 7.10049s/100 iters), loss = 0.680578
I1210 16:27:28.933344 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:27:28.933344 15772 solver.cpp:237]     Train net output #1: loss = 0.680578 (* 1 = 0.680578 loss)
I1210 16:27:28.933344 15772 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1210 16:27:34.568784 15772 solver.cpp:218] Iteration 64600 (17.7475 iter/s, 5.6346s/100 iters), loss = 0.735599
I1210 16:27:34.568784 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:27:34.568784 15772 solver.cpp:237]     Train net output #1: loss = 0.735599 (* 1 = 0.735599 loss)
I1210 16:27:34.568784 15772 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1210 16:27:40.202673 15772 solver.cpp:218] Iteration 64700 (17.7512 iter/s, 5.63343s/100 iters), loss = 0.608819
I1210 16:27:40.202673 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:27:40.202673 15772 solver.cpp:237]     Train net output #1: loss = 0.608819 (* 1 = 0.608819 loss)
I1210 16:27:40.202673 15772 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1210 16:27:45.830581 15772 solver.cpp:218] Iteration 64800 (17.7675 iter/s, 5.62827s/100 iters), loss = 0.858479
I1210 16:27:45.830581 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:27:45.830581 15772 solver.cpp:237]     Train net output #1: loss = 0.858479 (* 1 = 0.858479 loss)
I1210 16:27:45.830581 15772 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1210 16:27:51.466081 15772 solver.cpp:218] Iteration 64900 (17.7479 iter/s, 5.63448s/100 iters), loss = 0.859574
I1210 16:27:51.466081 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:27:51.466081 15772 solver.cpp:237]     Train net output #1: loss = 0.859574 (* 1 = 0.859574 loss)
I1210 16:27:51.466081 15772 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1210 16:27:56.821490 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:27:57.042527 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_65000.caffemodel
I1210 16:27:57.061527 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_65000.solverstate
I1210 16:27:57.083526 15772 solver.cpp:330] Iteration 65000, Testing net (#0)
I1210 16:27:57.083526 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:27:58.451632 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:27:58.505136 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5862
I1210 16:27:58.505136 15772 solver.cpp:397]     Test net output #1: loss = 1.57199 (* 1 = 1.57199 loss)
I1210 16:27:58.558643 15772 solver.cpp:218] Iteration 65000 (14.0996 iter/s, 7.0924s/100 iters), loss = 0.591972
I1210 16:27:58.558643 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:27:58.558643 15772 solver.cpp:237]     Train net output #1: loss = 0.591972 (* 1 = 0.591972 loss)
I1210 16:27:58.558643 15772 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1210 16:28:04.218085 15772 solver.cpp:218] Iteration 65100 (17.6729 iter/s, 5.65839s/100 iters), loss = 0.795677
I1210 16:28:04.218085 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:28:04.218085 15772 solver.cpp:237]     Train net output #1: loss = 0.795677 (* 1 = 0.795677 loss)
I1210 16:28:04.218085 15772 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1210 16:28:09.875567 15772 solver.cpp:218] Iteration 65200 (17.677 iter/s, 5.65707s/100 iters), loss = 0.637447
I1210 16:28:09.875567 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:28:09.875567 15772 solver.cpp:237]     Train net output #1: loss = 0.637447 (* 1 = 0.637447 loss)
I1210 16:28:09.875567 15772 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1210 16:28:15.531954 15772 solver.cpp:218] Iteration 65300 (17.6798 iter/s, 5.65616s/100 iters), loss = 0.829791
I1210 16:28:15.531954 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:28:15.531954 15772 solver.cpp:237]     Train net output #1: loss = 0.829791 (* 1 = 0.829791 loss)
I1210 16:28:15.531954 15772 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1210 16:28:21.185403 15772 solver.cpp:218] Iteration 65400 (17.6887 iter/s, 5.65334s/100 iters), loss = 0.910351
I1210 16:28:21.185403 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:28:21.186403 15772 solver.cpp:237]     Train net output #1: loss = 0.910351 (* 1 = 0.910351 loss)
I1210 16:28:21.186403 15772 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1210 16:28:26.556785 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:28:26.779794 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_65500.caffemodel
I1210 16:28:26.796793 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_65500.solverstate
I1210 16:28:26.801795 15772 solver.cpp:330] Iteration 65500, Testing net (#0)
I1210 16:28:26.801795 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:28:28.169898 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:28:28.223908 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5908
I1210 16:28:28.223908 15772 solver.cpp:397]     Test net output #1: loss = 1.54114 (* 1 = 1.54114 loss)
I1210 16:28:28.278900 15772 solver.cpp:218] Iteration 65500 (14.0986 iter/s, 7.09288s/100 iters), loss = 0.707874
I1210 16:28:28.278900 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:28:28.278900 15772 solver.cpp:237]     Train net output #1: loss = 0.707874 (* 1 = 0.707874 loss)
I1210 16:28:28.278900 15772 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1210 16:28:33.921320 15772 solver.cpp:218] Iteration 65600 (17.725 iter/s, 5.64174s/100 iters), loss = 0.824865
I1210 16:28:33.921320 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:28:33.921320 15772 solver.cpp:237]     Train net output #1: loss = 0.824865 (* 1 = 0.824865 loss)
I1210 16:28:33.921320 15772 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1210 16:28:39.573794 15772 solver.cpp:218] Iteration 65700 (17.6926 iter/s, 5.65209s/100 iters), loss = 0.769533
I1210 16:28:39.573794 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:28:39.573794 15772 solver.cpp:237]     Train net output #1: loss = 0.769533 (* 1 = 0.769533 loss)
I1210 16:28:39.573794 15772 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1210 16:28:45.223359 15772 solver.cpp:218] Iteration 65800 (17.7034 iter/s, 5.64864s/100 iters), loss = 0.902297
I1210 16:28:45.223359 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:28:45.223359 15772 solver.cpp:237]     Train net output #1: loss = 0.902297 (* 1 = 0.902297 loss)
I1210 16:28:45.223359 15772 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1210 16:28:50.873648 15772 solver.cpp:218] Iteration 65900 (17.6995 iter/s, 5.64988s/100 iters), loss = 0.934131
I1210 16:28:50.873648 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:28:50.873648 15772 solver.cpp:237]     Train net output #1: loss = 0.934131 (* 1 = 0.934131 loss)
I1210 16:28:50.873648 15772 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1210 16:28:56.239903 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:28:56.461926 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_66000.caffemodel
I1210 16:28:56.477926 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_66000.solverstate
I1210 16:28:56.509929 15772 solver.cpp:330] Iteration 66000, Testing net (#0)
I1210 16:28:56.509929 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:28:57.879068 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:28:57.934077 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6157
I1210 16:28:57.934077 15772 solver.cpp:397]     Test net output #1: loss = 1.40896 (* 1 = 1.40896 loss)
I1210 16:28:57.987076 15772 solver.cpp:218] Iteration 66000 (14.0576 iter/s, 7.11359s/100 iters), loss = 0.720633
I1210 16:28:57.988076 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:28:57.988076 15772 solver.cpp:237]     Train net output #1: loss = 0.720633 (* 1 = 0.720633 loss)
I1210 16:28:57.988076 15772 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1210 16:29:03.627488 15772 solver.cpp:218] Iteration 66100 (17.7322 iter/s, 5.63945s/100 iters), loss = 0.751421
I1210 16:29:03.627488 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:29:03.627488 15772 solver.cpp:237]     Train net output #1: loss = 0.751421 (* 1 = 0.751421 loss)
I1210 16:29:03.627488 15772 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1210 16:29:09.268942 15772 solver.cpp:218] Iteration 66200 (17.7266 iter/s, 5.64124s/100 iters), loss = 0.73842
I1210 16:29:09.268942 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:29:09.268942 15772 solver.cpp:237]     Train net output #1: loss = 0.73842 (* 1 = 0.73842 loss)
I1210 16:29:09.268942 15772 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1210 16:29:14.902812 15772 solver.cpp:218] Iteration 66300 (17.7513 iter/s, 5.63339s/100 iters), loss = 0.900009
I1210 16:29:14.902812 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:29:14.902812 15772 solver.cpp:237]     Train net output #1: loss = 0.900009 (* 1 = 0.900009 loss)
I1210 16:29:14.902812 15772 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1210 16:29:20.550652 15772 solver.cpp:218] Iteration 66400 (17.7077 iter/s, 5.64727s/100 iters), loss = 1.02343
I1210 16:29:20.550652 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:29:20.550652 15772 solver.cpp:237]     Train net output #1: loss = 1.02343 (* 1 = 1.02343 loss)
I1210 16:29:20.550652 15772 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1210 16:29:25.911315 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:29:26.133371 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_66500.caffemodel
I1210 16:29:26.147370 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_66500.solverstate
I1210 16:29:26.152374 15772 solver.cpp:330] Iteration 66500, Testing net (#0)
I1210 16:29:26.153374 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:29:27.526458 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:29:27.580461 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6006
I1210 16:29:27.580461 15772 solver.cpp:397]     Test net output #1: loss = 1.48584 (* 1 = 1.48584 loss)
I1210 16:29:27.634469 15772 solver.cpp:218] Iteration 66500 (14.117 iter/s, 7.08365s/100 iters), loss = 0.795819
I1210 16:29:27.634469 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:29:27.634469 15772 solver.cpp:237]     Train net output #1: loss = 0.795819 (* 1 = 0.795819 loss)
I1210 16:29:27.634469 15772 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1210 16:29:33.276881 15772 solver.cpp:218] Iteration 66600 (17.7243 iter/s, 5.64197s/100 iters), loss = 0.761932
I1210 16:29:33.276881 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:29:33.276881 15772 solver.cpp:237]     Train net output #1: loss = 0.761932 (* 1 = 0.761932 loss)
I1210 16:29:33.276881 15772 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1210 16:29:38.918922 15772 solver.cpp:218] Iteration 66700 (17.727 iter/s, 5.64111s/100 iters), loss = 0.758366
I1210 16:29:38.918922 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:29:38.918922 15772 solver.cpp:237]     Train net output #1: loss = 0.758366 (* 1 = 0.758366 loss)
I1210 16:29:38.918922 15772 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1210 16:29:44.566515 15772 solver.cpp:218] Iteration 66800 (17.7065 iter/s, 5.64765s/100 iters), loss = 1.0322
I1210 16:29:44.566515 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 16:29:44.566515 15772 solver.cpp:237]     Train net output #1: loss = 1.0322 (* 1 = 1.0322 loss)
I1210 16:29:44.566515 15772 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1210 16:29:50.204413 15772 solver.cpp:218] Iteration 66900 (17.738 iter/s, 5.63763s/100 iters), loss = 0.894873
I1210 16:29:50.204413 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:29:50.204413 15772 solver.cpp:237]     Train net output #1: loss = 0.894873 (* 1 = 0.894873 loss)
I1210 16:29:50.204413 15772 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1210 16:29:55.559815 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:29:55.781828 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_67000.caffemodel
I1210 16:29:55.795828 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_67000.solverstate
I1210 16:29:55.826345 15772 solver.cpp:330] Iteration 67000, Testing net (#0)
I1210 16:29:55.826345 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:29:57.195945 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:29:57.249953 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5722
I1210 16:29:57.250953 15772 solver.cpp:397]     Test net output #1: loss = 1.61346 (* 1 = 1.61346 loss)
I1210 16:29:57.304952 15772 solver.cpp:218] Iteration 67000 (14.0857 iter/s, 7.09938s/100 iters), loss = 0.6227
I1210 16:29:57.304952 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:29:57.304952 15772 solver.cpp:237]     Train net output #1: loss = 0.6227 (* 1 = 0.6227 loss)
I1210 16:29:57.304952 15772 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1210 16:30:02.965876 15772 solver.cpp:218] Iteration 67100 (17.6649 iter/s, 5.66095s/100 iters), loss = 0.849843
I1210 16:30:02.965876 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:30:02.965876 15772 solver.cpp:237]     Train net output #1: loss = 0.849843 (* 1 = 0.849843 loss)
I1210 16:30:02.965876 15772 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1210 16:30:08.601368 15772 solver.cpp:218] Iteration 67200 (17.7483 iter/s, 5.63435s/100 iters), loss = 0.624872
I1210 16:30:08.601368 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:30:08.601368 15772 solver.cpp:237]     Train net output #1: loss = 0.624872 (* 1 = 0.624872 loss)
I1210 16:30:08.601368 15772 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1210 16:30:14.241786 15772 solver.cpp:218] Iteration 67300 (17.7295 iter/s, 5.64031s/100 iters), loss = 0.866053
I1210 16:30:14.241786 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:30:14.241786 15772 solver.cpp:237]     Train net output #1: loss = 0.866053 (* 1 = 0.866053 loss)
I1210 16:30:14.241786 15772 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1210 16:30:19.886709 15772 solver.cpp:218] Iteration 67400 (17.7174 iter/s, 5.64416s/100 iters), loss = 0.918808
I1210 16:30:19.886709 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:30:19.886709 15772 solver.cpp:237]     Train net output #1: loss = 0.918808 (* 1 = 0.918808 loss)
I1210 16:30:19.886709 15772 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1210 16:30:25.256640 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:30:25.478673 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_67500.caffemodel
I1210 16:30:25.493677 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_67500.solverstate
I1210 16:30:25.498682 15772 solver.cpp:330] Iteration 67500, Testing net (#0)
I1210 16:30:25.498682 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:30:26.865806 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:30:26.920814 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5686
I1210 16:30:26.920814 15772 solver.cpp:397]     Test net output #1: loss = 1.66405 (* 1 = 1.66405 loss)
I1210 16:30:26.974812 15772 solver.cpp:218] Iteration 67500 (14.1087 iter/s, 7.0878s/100 iters), loss = 0.651991
I1210 16:30:26.974812 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:30:26.974812 15772 solver.cpp:237]     Train net output #1: loss = 0.651991 (* 1 = 0.651991 loss)
I1210 16:30:26.974812 15772 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1210 16:30:32.625282 15772 solver.cpp:218] Iteration 67600 (17.698 iter/s, 5.65035s/100 iters), loss = 0.761113
I1210 16:30:32.625282 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:30:32.625282 15772 solver.cpp:237]     Train net output #1: loss = 0.761113 (* 1 = 0.761113 loss)
I1210 16:30:32.625282 15772 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1210 16:30:38.271059 15772 solver.cpp:218] Iteration 67700 (17.7131 iter/s, 5.64553s/100 iters), loss = 0.712156
I1210 16:30:38.271059 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:30:38.271059 15772 solver.cpp:237]     Train net output #1: loss = 0.712156 (* 1 = 0.712156 loss)
I1210 16:30:38.271059 15772 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1210 16:30:43.908361 15772 solver.cpp:218] Iteration 67800 (17.7397 iter/s, 5.63709s/100 iters), loss = 0.904778
I1210 16:30:43.908361 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:30:43.908361 15772 solver.cpp:237]     Train net output #1: loss = 0.904778 (* 1 = 0.904778 loss)
I1210 16:30:43.908361 15772 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1210 16:30:49.544536 15772 solver.cpp:218] Iteration 67900 (17.7454 iter/s, 5.63527s/100 iters), loss = 0.90983
I1210 16:30:49.544536 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 16:30:49.544536 15772 solver.cpp:237]     Train net output #1: loss = 0.90983 (* 1 = 0.90983 loss)
I1210 16:30:49.544536 15772 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1210 16:30:54.903687 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:30:55.126221 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_68000.caffemodel
I1210 16:30:55.142220 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_68000.solverstate
I1210 16:30:55.146220 15772 solver.cpp:330] Iteration 68000, Testing net (#0)
I1210 16:30:55.146220 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:30:56.512620 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:30:56.566620 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5859
I1210 16:30:56.566620 15772 solver.cpp:397]     Test net output #1: loss = 1.57436 (* 1 = 1.57436 loss)
I1210 16:30:56.620673 15772 solver.cpp:218] Iteration 68000 (14.1325 iter/s, 7.07587s/100 iters), loss = 0.703719
I1210 16:30:56.620673 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:30:56.620673 15772 solver.cpp:237]     Train net output #1: loss = 0.703719 (* 1 = 0.703719 loss)
I1210 16:30:56.620673 15772 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1210 16:31:02.263314 15772 solver.cpp:218] Iteration 68100 (17.7246 iter/s, 5.64189s/100 iters), loss = 0.822202
I1210 16:31:02.263314 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:31:02.263314 15772 solver.cpp:237]     Train net output #1: loss = 0.822202 (* 1 = 0.822202 loss)
I1210 16:31:02.263314 15772 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1210 16:31:07.910244 15772 solver.cpp:218] Iteration 68200 (17.7107 iter/s, 5.6463s/100 iters), loss = 0.644362
I1210 16:31:07.910244 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:31:07.910244 15772 solver.cpp:237]     Train net output #1: loss = 0.644362 (* 1 = 0.644362 loss)
I1210 16:31:07.910244 15772 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1210 16:31:13.543983 15772 solver.cpp:218] Iteration 68300 (17.7496 iter/s, 5.63392s/100 iters), loss = 0.84363
I1210 16:31:13.543983 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:31:13.543983 15772 solver.cpp:237]     Train net output #1: loss = 0.84363 (* 1 = 0.84363 loss)
I1210 16:31:13.543983 15772 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1210 16:31:19.196460 15772 solver.cpp:218] Iteration 68400 (17.6937 iter/s, 5.65172s/100 iters), loss = 0.897757
I1210 16:31:19.196460 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:31:19.196460 15772 solver.cpp:237]     Train net output #1: loss = 0.897757 (* 1 = 0.897757 loss)
I1210 16:31:19.196460 15772 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1210 16:31:24.561902 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:31:24.784797 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_68500.caffemodel
I1210 16:31:24.799288 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_68500.solverstate
I1210 16:31:24.804288 15772 solver.cpp:330] Iteration 68500, Testing net (#0)
I1210 16:31:24.804288 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:31:26.172257 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:31:26.226897 15772 solver.cpp:397]     Test net output #0: accuracy = 0.583
I1210 16:31:26.226897 15772 solver.cpp:397]     Test net output #1: loss = 1.59371 (* 1 = 1.59371 loss)
I1210 16:31:26.281908 15772 solver.cpp:218] Iteration 68500 (14.1146 iter/s, 7.08485s/100 iters), loss = 0.698278
I1210 16:31:26.281908 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:31:26.281908 15772 solver.cpp:237]     Train net output #1: loss = 0.698278 (* 1 = 0.698278 loss)
I1210 16:31:26.281908 15772 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1210 16:31:31.926950 15772 solver.cpp:218] Iteration 68600 (17.7173 iter/s, 5.6442s/100 iters), loss = 0.724334
I1210 16:31:31.926950 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:31:31.926950 15772 solver.cpp:237]     Train net output #1: loss = 0.724334 (* 1 = 0.724334 loss)
I1210 16:31:31.926950 15772 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1210 16:31:37.565837 15772 solver.cpp:218] Iteration 68700 (17.735 iter/s, 5.63856s/100 iters), loss = 0.66687
I1210 16:31:37.565837 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:31:37.565837 15772 solver.cpp:237]     Train net output #1: loss = 0.66687 (* 1 = 0.66687 loss)
I1210 16:31:37.565837 15772 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1210 16:31:43.212303 15772 solver.cpp:218] Iteration 68800 (17.7111 iter/s, 5.64618s/100 iters), loss = 0.845039
I1210 16:31:43.212303 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:31:43.212303 15772 solver.cpp:237]     Train net output #1: loss = 0.845039 (* 1 = 0.845039 loss)
I1210 16:31:43.212303 15772 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1210 16:31:48.853011 15772 solver.cpp:218] Iteration 68900 (17.7294 iter/s, 5.64035s/100 iters), loss = 0.878315
I1210 16:31:48.853011 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:31:48.853011 15772 solver.cpp:237]     Train net output #1: loss = 0.878315 (* 1 = 0.878315 loss)
I1210 16:31:48.853011 15772 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1210 16:31:54.225474 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:31:54.445497 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_69000.caffemodel
I1210 16:31:54.460495 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_69000.solverstate
I1210 16:31:54.465497 15772 solver.cpp:330] Iteration 69000, Testing net (#0)
I1210 16:31:54.465497 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:31:55.835641 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:31:55.889642 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5678
I1210 16:31:55.889642 15772 solver.cpp:397]     Test net output #1: loss = 1.68474 (* 1 = 1.68474 loss)
I1210 16:31:55.943645 15772 solver.cpp:218] Iteration 69000 (14.1049 iter/s, 7.08975s/100 iters), loss = 0.642204
I1210 16:31:55.943645 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:31:55.943645 15772 solver.cpp:237]     Train net output #1: loss = 0.642204 (* 1 = 0.642204 loss)
I1210 16:31:55.943645 15772 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1210 16:32:01.574087 15772 solver.cpp:218] Iteration 69100 (17.7614 iter/s, 5.63017s/100 iters), loss = 0.827386
I1210 16:32:01.574087 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:32:01.574087 15772 solver.cpp:237]     Train net output #1: loss = 0.827386 (* 1 = 0.827386 loss)
I1210 16:32:01.574087 15772 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1210 16:32:07.210376 15772 solver.cpp:218] Iteration 69200 (17.7415 iter/s, 5.63651s/100 iters), loss = 0.668131
I1210 16:32:07.210376 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:32:07.210376 15772 solver.cpp:237]     Train net output #1: loss = 0.668131 (* 1 = 0.668131 loss)
I1210 16:32:07.210376 15772 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1210 16:32:12.847832 15772 solver.cpp:218] Iteration 69300 (17.7421 iter/s, 5.6363s/100 iters), loss = 0.765208
I1210 16:32:12.847832 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:32:12.847832 15772 solver.cpp:237]     Train net output #1: loss = 0.765208 (* 1 = 0.765208 loss)
I1210 16:32:12.847832 15772 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1210 16:32:18.486266 15772 solver.cpp:218] Iteration 69400 (17.7348 iter/s, 5.63862s/100 iters), loss = 0.879193
I1210 16:32:18.486266 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:32:18.486266 15772 solver.cpp:237]     Train net output #1: loss = 0.879193 (* 1 = 0.879193 loss)
I1210 16:32:18.486266 15772 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1210 16:32:23.843705 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:32:24.067719 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_69500.caffemodel
I1210 16:32:24.081719 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_69500.solverstate
I1210 16:32:24.108718 15772 solver.cpp:330] Iteration 69500, Testing net (#0)
I1210 16:32:24.108718 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:32:25.477805 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:32:25.531810 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5963
I1210 16:32:25.531810 15772 solver.cpp:397]     Test net output #1: loss = 1.54867 (* 1 = 1.54867 loss)
I1210 16:32:25.586808 15772 solver.cpp:218] Iteration 69500 (14.0852 iter/s, 7.09967s/100 iters), loss = 0.724107
I1210 16:32:25.586808 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:32:25.586808 15772 solver.cpp:237]     Train net output #1: loss = 0.724107 (* 1 = 0.724107 loss)
I1210 16:32:25.586808 15772 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1210 16:32:31.227304 15772 solver.cpp:218] Iteration 69600 (17.7306 iter/s, 5.63997s/100 iters), loss = 0.896922
I1210 16:32:31.227304 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:32:31.227304 15772 solver.cpp:237]     Train net output #1: loss = 0.896922 (* 1 = 0.896922 loss)
I1210 16:32:31.227304 15772 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1210 16:32:36.853891 15772 solver.cpp:218] Iteration 69700 (17.7721 iter/s, 5.62679s/100 iters), loss = 0.711535
I1210 16:32:36.854892 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:32:36.854892 15772 solver.cpp:237]     Train net output #1: loss = 0.711535 (* 1 = 0.711535 loss)
I1210 16:32:36.854892 15772 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1210 16:32:42.495281 15772 solver.cpp:218] Iteration 69800 (17.7282 iter/s, 5.64073s/100 iters), loss = 0.783012
I1210 16:32:42.495281 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:32:42.495281 15772 solver.cpp:237]     Train net output #1: loss = 0.783012 (* 1 = 0.783012 loss)
I1210 16:32:42.495281 15772 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1210 16:32:48.135782 15772 solver.cpp:218] Iteration 69900 (17.7323 iter/s, 5.63944s/100 iters), loss = 0.937522
I1210 16:32:48.135782 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:32:48.135782 15772 solver.cpp:237]     Train net output #1: loss = 0.937522 (* 1 = 0.937522 loss)
I1210 16:32:48.135782 15772 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1210 16:32:53.509202 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:32:53.731731 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_70000.caffemodel
I1210 16:32:53.746237 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_70000.solverstate
I1210 16:32:53.750236 15772 solver.cpp:330] Iteration 70000, Testing net (#0)
I1210 16:32:53.750236 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:32:55.122825 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:32:55.176339 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5595
I1210 16:32:55.176339 15772 solver.cpp:397]     Test net output #1: loss = 1.76395 (* 1 = 1.76395 loss)
I1210 16:32:55.232331 15772 solver.cpp:218] Iteration 70000 (14.0918 iter/s, 7.09633s/100 iters), loss = 0.629317
I1210 16:32:55.232331 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:32:55.232331 15772 solver.cpp:237]     Train net output #1: loss = 0.629317 (* 1 = 0.629317 loss)
I1210 16:32:55.232331 15772 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1210 16:33:00.884786 15772 solver.cpp:218] Iteration 70100 (17.6912 iter/s, 5.65253s/100 iters), loss = 0.785119
I1210 16:33:00.884786 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:33:00.884786 15772 solver.cpp:237]     Train net output #1: loss = 0.785119 (* 1 = 0.785119 loss)
I1210 16:33:00.885787 15772 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1210 16:33:06.535266 15772 solver.cpp:218] Iteration 70200 (17.7022 iter/s, 5.64903s/100 iters), loss = 0.735559
I1210 16:33:06.535266 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:33:06.535266 15772 solver.cpp:237]     Train net output #1: loss = 0.735559 (* 1 = 0.735559 loss)
I1210 16:33:06.535266 15772 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1210 16:33:12.188710 15772 solver.cpp:218] Iteration 70300 (17.6871 iter/s, 5.65385s/100 iters), loss = 0.775395
I1210 16:33:12.188710 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:33:12.188710 15772 solver.cpp:237]     Train net output #1: loss = 0.775395 (* 1 = 0.775395 loss)
I1210 16:33:12.188710 15772 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1210 16:33:17.843109 15772 solver.cpp:218] Iteration 70400 (17.6873 iter/s, 5.65377s/100 iters), loss = 0.765261
I1210 16:33:17.843109 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:33:17.843109 15772 solver.cpp:237]     Train net output #1: loss = 0.765261 (* 1 = 0.765261 loss)
I1210 16:33:17.843109 15772 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1210 16:33:23.219662 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:33:23.440690 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_70500.caffemodel
I1210 16:33:23.454690 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_70500.solverstate
I1210 16:33:23.483688 15772 solver.cpp:330] Iteration 70500, Testing net (#0)
I1210 16:33:23.483688 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:33:24.853818 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:33:24.908818 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5999
I1210 16:33:24.908818 15772 solver.cpp:397]     Test net output #1: loss = 1.47668 (* 1 = 1.47668 loss)
I1210 16:33:24.962821 15772 solver.cpp:218] Iteration 70500 (14.0467 iter/s, 7.11911s/100 iters), loss = 0.595407
I1210 16:33:24.962821 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:33:24.962821 15772 solver.cpp:237]     Train net output #1: loss = 0.595407 (* 1 = 0.595407 loss)
I1210 16:33:24.962821 15772 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1210 16:33:30.618415 15772 solver.cpp:218] Iteration 70600 (17.6829 iter/s, 5.65519s/100 iters), loss = 0.776465
I1210 16:33:30.618415 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:33:30.618415 15772 solver.cpp:237]     Train net output #1: loss = 0.776465 (* 1 = 0.776465 loss)
I1210 16:33:30.618415 15772 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1210 16:33:36.269910 15772 solver.cpp:218] Iteration 70700 (17.6969 iter/s, 5.65071s/100 iters), loss = 0.642393
I1210 16:33:36.269910 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:33:36.269910 15772 solver.cpp:237]     Train net output #1: loss = 0.642393 (* 1 = 0.642393 loss)
I1210 16:33:36.269910 15772 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1210 16:33:41.909394 15772 solver.cpp:218] Iteration 70800 (17.7337 iter/s, 5.63898s/100 iters), loss = 0.848513
I1210 16:33:41.909394 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:33:41.909394 15772 solver.cpp:237]     Train net output #1: loss = 0.848513 (* 1 = 0.848513 loss)
I1210 16:33:41.909394 15772 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1210 16:33:47.557873 15772 solver.cpp:218] Iteration 70900 (17.703 iter/s, 5.64875s/100 iters), loss = 0.919358
I1210 16:33:47.557873 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:33:47.557873 15772 solver.cpp:237]     Train net output #1: loss = 0.919358 (* 1 = 0.919358 loss)
I1210 16:33:47.557873 15772 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1210 16:33:52.927289 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:33:53.149317 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_71000.caffemodel
I1210 16:33:53.163316 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_71000.solverstate
I1210 16:33:53.168318 15772 solver.cpp:330] Iteration 71000, Testing net (#0)
I1210 16:33:53.168318 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:33:54.540426 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:33:54.595427 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5828
I1210 16:33:54.595427 15772 solver.cpp:397]     Test net output #1: loss = 1.56554 (* 1 = 1.56554 loss)
I1210 16:33:54.648430 15772 solver.cpp:218] Iteration 71000 (14.1053 iter/s, 7.08952s/100 iters), loss = 0.539726
I1210 16:33:54.648430 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:33:54.648430 15772 solver.cpp:237]     Train net output #1: loss = 0.539726 (* 1 = 0.539726 loss)
I1210 16:33:54.648430 15772 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1210 16:34:00.304103 15772 solver.cpp:218] Iteration 71100 (17.6823 iter/s, 5.65537s/100 iters), loss = 0.765197
I1210 16:34:00.304103 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:34:00.304103 15772 solver.cpp:237]     Train net output #1: loss = 0.765197 (* 1 = 0.765197 loss)
I1210 16:34:00.304103 15772 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1210 16:34:05.953641 15772 solver.cpp:218] Iteration 71200 (17.703 iter/s, 5.64876s/100 iters), loss = 0.647865
I1210 16:34:05.953641 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:34:05.953641 15772 solver.cpp:237]     Train net output #1: loss = 0.647865 (* 1 = 0.647865 loss)
I1210 16:34:05.953641 15772 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1210 16:34:11.605068 15772 solver.cpp:218] Iteration 71300 (17.6944 iter/s, 5.65149s/100 iters), loss = 0.764126
I1210 16:34:11.605068 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:34:11.605068 15772 solver.cpp:237]     Train net output #1: loss = 0.764126 (* 1 = 0.764126 loss)
I1210 16:34:11.605068 15772 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1210 16:34:17.253487 15772 solver.cpp:218] Iteration 71400 (17.7061 iter/s, 5.64776s/100 iters), loss = 0.799877
I1210 16:34:17.253487 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:34:17.253487 15772 solver.cpp:237]     Train net output #1: loss = 0.799877 (* 1 = 0.799877 loss)
I1210 16:34:17.253487 15772 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1210 16:34:22.625459 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:34:22.849714 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_71500.caffemodel
I1210 16:34:22.864711 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_71500.solverstate
I1210 16:34:22.869712 15772 solver.cpp:330] Iteration 71500, Testing net (#0)
I1210 16:34:22.869712 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:34:24.246496 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:34:24.300500 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5737
I1210 16:34:24.300500 15772 solver.cpp:397]     Test net output #1: loss = 1.61815 (* 1 = 1.61815 loss)
I1210 16:34:24.353371 15772 solver.cpp:218] Iteration 71500 (14.0853 iter/s, 7.09959s/100 iters), loss = 0.608294
I1210 16:34:24.353371 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:34:24.353371 15772 solver.cpp:237]     Train net output #1: loss = 0.608294 (* 1 = 0.608294 loss)
I1210 16:34:24.353371 15772 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1210 16:34:29.993293 15772 solver.cpp:218] Iteration 71600 (17.7337 iter/s, 5.63898s/100 iters), loss = 0.739683
I1210 16:34:29.993293 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:34:29.993293 15772 solver.cpp:237]     Train net output #1: loss = 0.739683 (* 1 = 0.739683 loss)
I1210 16:34:29.993293 15772 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1210 16:34:35.624732 15772 solver.cpp:218] Iteration 71700 (17.7596 iter/s, 5.63077s/100 iters), loss = 0.610494
I1210 16:34:35.624732 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:34:35.624732 15772 solver.cpp:237]     Train net output #1: loss = 0.610494 (* 1 = 0.610494 loss)
I1210 16:34:35.624732 15772 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1210 16:34:41.256727 15772 solver.cpp:218] Iteration 71800 (17.7543 iter/s, 5.63244s/100 iters), loss = 0.891696
I1210 16:34:41.256727 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:34:41.257728 15772 solver.cpp:237]     Train net output #1: loss = 0.891696 (* 1 = 0.891696 loss)
I1210 16:34:41.257728 15772 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1210 16:34:46.895644 15772 solver.cpp:218] Iteration 71900 (17.7374 iter/s, 5.6378s/100 iters), loss = 0.816903
I1210 16:34:46.895644 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:34:46.895644 15772 solver.cpp:237]     Train net output #1: loss = 0.816903 (* 1 = 0.816903 loss)
I1210 16:34:46.895644 15772 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1210 16:34:52.248550 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:34:52.472560 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_72000.caffemodel
I1210 16:34:52.486560 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_72000.solverstate
I1210 16:34:52.491564 15772 solver.cpp:330] Iteration 72000, Testing net (#0)
I1210 16:34:52.491564 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:34:53.864720 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:34:53.919731 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5814
I1210 16:34:53.919731 15772 solver.cpp:397]     Test net output #1: loss = 1.60439 (* 1 = 1.60439 loss)
I1210 16:34:53.973729 15772 solver.cpp:218] Iteration 72000 (14.1283 iter/s, 7.07801s/100 iters), loss = 0.68254
I1210 16:34:53.973729 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:34:53.973729 15772 solver.cpp:237]     Train net output #1: loss = 0.68254 (* 1 = 0.68254 loss)
I1210 16:34:53.973729 15772 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1210 16:34:59.620267 15772 solver.cpp:218] Iteration 72100 (17.7115 iter/s, 5.64604s/100 iters), loss = 0.770965
I1210 16:34:59.620267 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:34:59.620267 15772 solver.cpp:237]     Train net output #1: loss = 0.770965 (* 1 = 0.770965 loss)
I1210 16:34:59.620267 15772 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1210 16:35:05.272699 15772 solver.cpp:218] Iteration 72200 (17.694 iter/s, 5.65164s/100 iters), loss = 0.606823
I1210 16:35:05.272699 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:35:05.272699 15772 solver.cpp:237]     Train net output #1: loss = 0.606822 (* 1 = 0.606822 loss)
I1210 16:35:05.272699 15772 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1210 16:35:10.918119 15772 solver.cpp:218] Iteration 72300 (17.7143 iter/s, 5.64514s/100 iters), loss = 0.903661
I1210 16:35:10.918119 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 16:35:10.918119 15772 solver.cpp:237]     Train net output #1: loss = 0.90366 (* 1 = 0.90366 loss)
I1210 16:35:10.918119 15772 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1210 16:35:16.562572 15772 solver.cpp:218] Iteration 72400 (17.7181 iter/s, 5.64395s/100 iters), loss = 0.98518
I1210 16:35:16.562572 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:35:16.562572 15772 solver.cpp:237]     Train net output #1: loss = 0.98518 (* 1 = 0.98518 loss)
I1210 16:35:16.562572 15772 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1210 16:35:21.925194 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:35:22.149215 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_72500.caffemodel
I1210 16:35:22.163216 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_72500.solverstate
I1210 16:35:22.192216 15772 solver.cpp:330] Iteration 72500, Testing net (#0)
I1210 16:35:22.192216 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:35:23.564402 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:35:23.620412 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5794
I1210 16:35:23.620412 15772 solver.cpp:397]     Test net output #1: loss = 1.66436 (* 1 = 1.66436 loss)
I1210 16:35:23.673416 15772 solver.cpp:218] Iteration 72500 (14.0638 iter/s, 7.11043s/100 iters), loss = 0.524366
I1210 16:35:23.673416 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:35:23.673416 15772 solver.cpp:237]     Train net output #1: loss = 0.524366 (* 1 = 0.524366 loss)
I1210 16:35:23.673416 15772 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1210 16:35:29.322919 15772 solver.cpp:218] Iteration 72600 (17.7035 iter/s, 5.64861s/100 iters), loss = 0.766685
I1210 16:35:29.322919 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:35:29.322919 15772 solver.cpp:237]     Train net output #1: loss = 0.766684 (* 1 = 0.766684 loss)
I1210 16:35:29.322919 15772 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1210 16:35:34.976409 15772 solver.cpp:218] Iteration 72700 (17.688 iter/s, 5.65354s/100 iters), loss = 0.66911
I1210 16:35:34.976409 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:35:34.976409 15772 solver.cpp:237]     Train net output #1: loss = 0.66911 (* 1 = 0.66911 loss)
I1210 16:35:34.976409 15772 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1210 16:35:40.620877 15772 solver.cpp:218] Iteration 72800 (17.7164 iter/s, 5.64448s/100 iters), loss = 0.829084
I1210 16:35:40.621876 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:35:40.621876 15772 solver.cpp:237]     Train net output #1: loss = 0.829084 (* 1 = 0.829084 loss)
I1210 16:35:40.621876 15772 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1210 16:35:46.277340 15772 solver.cpp:218] Iteration 72900 (17.683 iter/s, 5.65515s/100 iters), loss = 0.916197
I1210 16:35:46.277340 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:35:46.277340 15772 solver.cpp:237]     Train net output #1: loss = 0.916197 (* 1 = 0.916197 loss)
I1210 16:35:46.277340 15772 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1210 16:35:51.645725 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:35:51.867738 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_73000.caffemodel
I1210 16:35:51.881737 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_73000.solverstate
I1210 16:35:51.886739 15772 solver.cpp:330] Iteration 73000, Testing net (#0)
I1210 16:35:51.886739 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:35:53.257987 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:35:53.311990 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5869
I1210 16:35:53.311990 15772 solver.cpp:397]     Test net output #1: loss = 1.59824 (* 1 = 1.59824 loss)
I1210 16:35:53.366009 15772 solver.cpp:218] Iteration 73000 (14.1074 iter/s, 7.08848s/100 iters), loss = 0.74512
I1210 16:35:53.366009 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:35:53.366009 15772 solver.cpp:237]     Train net output #1: loss = 0.74512 (* 1 = 0.74512 loss)
I1210 16:35:53.366009 15772 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1210 16:35:59.020702 15772 solver.cpp:218] Iteration 73100 (17.6859 iter/s, 5.65421s/100 iters), loss = 0.709125
I1210 16:35:59.020702 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:35:59.020702 15772 solver.cpp:237]     Train net output #1: loss = 0.709125 (* 1 = 0.709125 loss)
I1210 16:35:59.020702 15772 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1210 16:36:04.671123 15772 solver.cpp:218] Iteration 73200 (17.6991 iter/s, 5.65002s/100 iters), loss = 0.61169
I1210 16:36:04.671123 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:36:04.671123 15772 solver.cpp:237]     Train net output #1: loss = 0.61169 (* 1 = 0.61169 loss)
I1210 16:36:04.671123 15772 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1210 16:36:10.323632 15772 solver.cpp:218] Iteration 73300 (17.6943 iter/s, 5.65153s/100 iters), loss = 0.810218
I1210 16:36:10.323632 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:36:10.323632 15772 solver.cpp:237]     Train net output #1: loss = 0.810218 (* 1 = 0.810218 loss)
I1210 16:36:10.323632 15772 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1210 16:36:15.975131 15772 solver.cpp:218] Iteration 73400 (17.6963 iter/s, 5.65088s/100 iters), loss = 0.850115
I1210 16:36:15.975131 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:36:15.975131 15772 solver.cpp:237]     Train net output #1: loss = 0.850115 (* 1 = 0.850115 loss)
I1210 16:36:15.975131 15772 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1210 16:36:21.348589 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:36:21.572598 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_73500.caffemodel
I1210 16:36:21.585599 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_73500.solverstate
I1210 16:36:21.590598 15772 solver.cpp:330] Iteration 73500, Testing net (#0)
I1210 16:36:21.590598 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:36:22.962748 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:36:23.015746 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5824
I1210 16:36:23.015746 15772 solver.cpp:397]     Test net output #1: loss = 1.64199 (* 1 = 1.64199 loss)
I1210 16:36:23.069746 15772 solver.cpp:218] Iteration 73500 (14.0967 iter/s, 7.09384s/100 iters), loss = 0.643078
I1210 16:36:23.069746 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:36:23.069746 15772 solver.cpp:237]     Train net output #1: loss = 0.643078 (* 1 = 0.643078 loss)
I1210 16:36:23.069746 15772 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1210 16:36:28.716511 15772 solver.cpp:218] Iteration 73600 (17.7105 iter/s, 5.64637s/100 iters), loss = 0.778392
I1210 16:36:28.716511 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:36:28.716511 15772 solver.cpp:237]     Train net output #1: loss = 0.778392 (* 1 = 0.778392 loss)
I1210 16:36:28.716511 15772 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1210 16:36:34.350823 15772 solver.cpp:218] Iteration 73700 (17.7487 iter/s, 5.63422s/100 iters), loss = 0.607028
I1210 16:36:34.350823 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:36:34.350823 15772 solver.cpp:237]     Train net output #1: loss = 0.607028 (* 1 = 0.607028 loss)
I1210 16:36:34.350823 15772 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1210 16:36:39.991603 15772 solver.cpp:218] Iteration 73800 (17.7307 iter/s, 5.63993s/100 iters), loss = 0.824292
I1210 16:36:39.991603 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:36:39.991603 15772 solver.cpp:237]     Train net output #1: loss = 0.824292 (* 1 = 0.824292 loss)
I1210 16:36:39.991603 15772 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1210 16:36:45.634562 15772 solver.cpp:218] Iteration 73900 (17.7227 iter/s, 5.64248s/100 iters), loss = 0.777061
I1210 16:36:45.634562 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:36:45.634562 15772 solver.cpp:237]     Train net output #1: loss = 0.777061 (* 1 = 0.777061 loss)
I1210 16:36:45.634562 15772 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1210 16:36:50.993983 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:36:51.217519 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_74000.caffemodel
I1210 16:36:51.233022 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_74000.solverstate
I1210 16:36:51.238023 15772 solver.cpp:330] Iteration 74000, Testing net (#0)
I1210 16:36:51.238023 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:36:52.610150 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:36:52.662951 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5805
I1210 16:36:52.662951 15772 solver.cpp:397]     Test net output #1: loss = 1.612 (* 1 = 1.612 loss)
I1210 16:36:52.716975 15772 solver.cpp:218] Iteration 74000 (14.1202 iter/s, 7.08205s/100 iters), loss = 0.668026
I1210 16:36:52.716975 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:36:52.716975 15772 solver.cpp:237]     Train net output #1: loss = 0.668026 (* 1 = 0.668026 loss)
I1210 16:36:52.716975 15772 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1210 16:36:58.351956 15772 solver.cpp:218] Iteration 74100 (17.7482 iter/s, 5.63436s/100 iters), loss = 0.879207
I1210 16:36:58.351956 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:36:58.351956 15772 solver.cpp:237]     Train net output #1: loss = 0.879207 (* 1 = 0.879207 loss)
I1210 16:36:58.351956 15772 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1210 16:37:03.991763 15772 solver.cpp:218] Iteration 74200 (17.7309 iter/s, 5.63986s/100 iters), loss = 0.691472
I1210 16:37:03.991763 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:37:03.991763 15772 solver.cpp:237]     Train net output #1: loss = 0.691472 (* 1 = 0.691472 loss)
I1210 16:37:03.991763 15772 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1210 16:37:09.632900 15772 solver.cpp:218] Iteration 74300 (17.73 iter/s, 5.64016s/100 iters), loss = 0.853747
I1210 16:37:09.632900 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:37:09.632900 15772 solver.cpp:237]     Train net output #1: loss = 0.853747 (* 1 = 0.853747 loss)
I1210 16:37:09.632900 15772 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1210 16:37:15.282919 15772 solver.cpp:218] Iteration 74400 (17.7006 iter/s, 5.64952s/100 iters), loss = 0.951976
I1210 16:37:15.282919 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:37:15.282919 15772 solver.cpp:237]     Train net output #1: loss = 0.951976 (* 1 = 0.951976 loss)
I1210 16:37:15.282919 15772 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1210 16:37:20.651373 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:37:20.873396 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_74500.caffemodel
I1210 16:37:20.888396 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_74500.solverstate
I1210 16:37:20.893396 15772 solver.cpp:330] Iteration 74500, Testing net (#0)
I1210 16:37:20.893396 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:37:22.264564 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:37:22.318564 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5767
I1210 16:37:22.318564 15772 solver.cpp:397]     Test net output #1: loss = 1.65255 (* 1 = 1.65255 loss)
I1210 16:37:22.372582 15772 solver.cpp:218] Iteration 74500 (14.1056 iter/s, 7.08939s/100 iters), loss = 0.720932
I1210 16:37:22.372582 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:37:22.372582 15772 solver.cpp:237]     Train net output #1: loss = 0.720932 (* 1 = 0.720932 loss)
I1210 16:37:22.372582 15772 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1210 16:37:28.007015 15772 solver.cpp:218] Iteration 74600 (17.7501 iter/s, 5.63379s/100 iters), loss = 0.693126
I1210 16:37:28.007015 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:37:28.007015 15772 solver.cpp:237]     Train net output #1: loss = 0.693126 (* 1 = 0.693126 loss)
I1210 16:37:28.007015 15772 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1210 16:37:33.649554 15772 solver.cpp:218] Iteration 74700 (17.723 iter/s, 5.64239s/100 iters), loss = 0.66509
I1210 16:37:33.649554 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:37:33.649554 15772 solver.cpp:237]     Train net output #1: loss = 0.66509 (* 1 = 0.66509 loss)
I1210 16:37:33.649554 15772 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1210 16:37:39.290334 15772 solver.cpp:218] Iteration 74800 (17.7291 iter/s, 5.64045s/100 iters), loss = 0.844201
I1210 16:37:39.290334 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:37:39.290334 15772 solver.cpp:237]     Train net output #1: loss = 0.844201 (* 1 = 0.844201 loss)
I1210 16:37:39.290334 15772 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1210 16:37:44.927868 15772 solver.cpp:218] Iteration 74900 (17.7406 iter/s, 5.63678s/100 iters), loss = 0.869937
I1210 16:37:44.927868 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:37:44.927868 15772 solver.cpp:237]     Train net output #1: loss = 0.869937 (* 1 = 0.869937 loss)
I1210 16:37:44.927868 15772 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1210 16:37:50.294271 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:37:50.516281 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_75000.caffemodel
I1210 16:37:50.530282 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_75000.solverstate
I1210 16:37:50.535286 15772 solver.cpp:330] Iteration 75000, Testing net (#0)
I1210 16:37:50.535286 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:37:51.905442 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:37:51.959451 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5845
I1210 16:37:51.959451 15772 solver.cpp:397]     Test net output #1: loss = 1.61346 (* 1 = 1.61346 loss)
I1210 16:37:52.013447 15772 solver.cpp:218] Iteration 75000 (14.1128 iter/s, 7.08578s/100 iters), loss = 0.724437
I1210 16:37:52.014448 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:37:52.014448 15772 solver.cpp:237]     Train net output #1: loss = 0.724437 (* 1 = 0.724437 loss)
I1210 16:37:52.014448 15772 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1210 16:37:57.646962 15772 solver.cpp:218] Iteration 75100 (17.7537 iter/s, 5.63264s/100 iters), loss = 0.60214
I1210 16:37:57.647462 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:37:57.647462 15772 solver.cpp:237]     Train net output #1: loss = 0.60214 (* 1 = 0.60214 loss)
I1210 16:37:57.647462 15772 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1210 16:38:03.293387 15772 solver.cpp:218] Iteration 75200 (17.7108 iter/s, 5.64628s/100 iters), loss = 0.591544
I1210 16:38:03.293387 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:38:03.293387 15772 solver.cpp:237]     Train net output #1: loss = 0.591544 (* 1 = 0.591544 loss)
I1210 16:38:03.293387 15772 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1210 16:38:08.924831 15772 solver.cpp:218] Iteration 75300 (17.7583 iter/s, 5.63116s/100 iters), loss = 0.823
I1210 16:38:08.925832 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:38:08.925832 15772 solver.cpp:237]     Train net output #1: loss = 0.823 (* 1 = 0.823 loss)
I1210 16:38:08.925832 15772 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1210 16:38:14.566231 15772 solver.cpp:218] Iteration 75400 (17.7291 iter/s, 5.64045s/100 iters), loss = 0.75941
I1210 16:38:14.566231 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:38:14.566231 15772 solver.cpp:237]     Train net output #1: loss = 0.75941 (* 1 = 0.75941 loss)
I1210 16:38:14.566231 15772 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1210 16:38:19.922616 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:38:20.143635 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_75500.caffemodel
I1210 16:38:20.157639 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_75500.solverstate
I1210 16:38:20.161639 15772 solver.cpp:330] Iteration 75500, Testing net (#0)
I1210 16:38:20.162641 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:38:21.532752 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:38:21.586756 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5824
I1210 16:38:21.586756 15772 solver.cpp:397]     Test net output #1: loss = 1.66314 (* 1 = 1.66314 loss)
I1210 16:38:21.640758 15772 solver.cpp:218] Iteration 75500 (14.1368 iter/s, 7.07372s/100 iters), loss = 0.590857
I1210 16:38:21.640758 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:38:21.640758 15772 solver.cpp:237]     Train net output #1: loss = 0.590857 (* 1 = 0.590857 loss)
I1210 16:38:21.640758 15772 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1210 16:38:27.282157 15772 solver.cpp:218] Iteration 75600 (17.7265 iter/s, 5.64128s/100 iters), loss = 0.904262
I1210 16:38:27.282157 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:38:27.282157 15772 solver.cpp:237]     Train net output #1: loss = 0.904262 (* 1 = 0.904262 loss)
I1210 16:38:27.282157 15772 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1210 16:38:32.931649 15772 solver.cpp:218] Iteration 75700 (17.7026 iter/s, 5.64889s/100 iters), loss = 0.526148
I1210 16:38:32.931649 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:38:32.931649 15772 solver.cpp:237]     Train net output #1: loss = 0.526148 (* 1 = 0.526148 loss)
I1210 16:38:32.931649 15772 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1210 16:38:38.572077 15772 solver.cpp:218] Iteration 75800 (17.7301 iter/s, 5.64013s/100 iters), loss = 0.853803
I1210 16:38:38.572077 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:38:38.572077 15772 solver.cpp:237]     Train net output #1: loss = 0.853803 (* 1 = 0.853803 loss)
I1210 16:38:38.572077 15772 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1210 16:38:44.217604 15772 solver.cpp:218] Iteration 75900 (17.7139 iter/s, 5.6453s/100 iters), loss = 0.871007
I1210 16:38:44.217604 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:38:44.217604 15772 solver.cpp:237]     Train net output #1: loss = 0.871007 (* 1 = 0.871007 loss)
I1210 16:38:44.217604 15772 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1210 16:38:49.576052 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:38:49.798064 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_76000.caffemodel
I1210 16:38:49.813064 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_76000.solverstate
I1210 16:38:49.818064 15772 solver.cpp:330] Iteration 76000, Testing net (#0)
I1210 16:38:49.818064 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:38:51.186187 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:38:51.239708 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5705
I1210 16:38:51.239708 15772 solver.cpp:397]     Test net output #1: loss = 1.7037 (* 1 = 1.7037 loss)
I1210 16:38:51.294210 15772 solver.cpp:218] Iteration 76000 (14.1316 iter/s, 7.07633s/100 iters), loss = 0.765794
I1210 16:38:51.295212 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:38:51.295212 15772 solver.cpp:237]     Train net output #1: loss = 0.765794 (* 1 = 0.765794 loss)
I1210 16:38:51.295212 15772 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1210 16:38:56.929641 15772 solver.cpp:218] Iteration 76100 (17.7468 iter/s, 5.63483s/100 iters), loss = 0.893637
I1210 16:38:56.929641 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:38:56.929641 15772 solver.cpp:237]     Train net output #1: loss = 0.893637 (* 1 = 0.893637 loss)
I1210 16:38:56.929641 15772 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1210 16:39:02.572091 15772 solver.cpp:218] Iteration 76200 (17.7235 iter/s, 5.64221s/100 iters), loss = 0.596786
I1210 16:39:02.573091 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:39:02.573091 15772 solver.cpp:237]     Train net output #1: loss = 0.596786 (* 1 = 0.596786 loss)
I1210 16:39:02.573091 15772 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1210 16:39:08.206593 15772 solver.cpp:218] Iteration 76300 (17.7512 iter/s, 5.63344s/100 iters), loss = 0.946378
I1210 16:39:08.206593 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:39:08.206593 15772 solver.cpp:237]     Train net output #1: loss = 0.946377 (* 1 = 0.946377 loss)
I1210 16:39:08.206593 15772 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1210 16:39:13.842001 15772 solver.cpp:218] Iteration 76400 (17.7471 iter/s, 5.63471s/100 iters), loss = 0.791728
I1210 16:39:13.842001 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:39:13.842001 15772 solver.cpp:237]     Train net output #1: loss = 0.791728 (* 1 = 0.791728 loss)
I1210 16:39:13.842001 15772 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1210 16:39:19.206420 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:39:19.428431 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_76500.caffemodel
I1210 16:39:19.443434 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_76500.solverstate
I1210 16:39:19.447934 15772 solver.cpp:330] Iteration 76500, Testing net (#0)
I1210 16:39:19.447934 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:39:20.814524 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:39:20.868535 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5456
I1210 16:39:20.868535 15772 solver.cpp:397]     Test net output #1: loss = 1.86985 (* 1 = 1.86985 loss)
I1210 16:39:20.921533 15772 solver.cpp:218] Iteration 76500 (14.126 iter/s, 7.07913s/100 iters), loss = 0.705616
I1210 16:39:20.921533 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:39:20.921533 15772 solver.cpp:237]     Train net output #1: loss = 0.705616 (* 1 = 0.705616 loss)
I1210 16:39:20.921533 15772 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1210 16:39:26.545984 15772 solver.cpp:218] Iteration 76600 (17.7808 iter/s, 5.62406s/100 iters), loss = 0.73187
I1210 16:39:26.545984 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:39:26.545984 15772 solver.cpp:237]     Train net output #1: loss = 0.73187 (* 1 = 0.73187 loss)
I1210 16:39:26.545984 15772 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1210 16:39:32.167431 15772 solver.cpp:218] Iteration 76700 (17.7904 iter/s, 5.62102s/100 iters), loss = 0.614622
I1210 16:39:32.167431 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:39:32.167431 15772 solver.cpp:237]     Train net output #1: loss = 0.614622 (* 1 = 0.614622 loss)
I1210 16:39:32.167431 15772 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1210 16:39:37.806104 15772 solver.cpp:218] Iteration 76800 (17.7341 iter/s, 5.63886s/100 iters), loss = 0.809496
I1210 16:39:37.806104 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:39:37.806104 15772 solver.cpp:237]     Train net output #1: loss = 0.809496 (* 1 = 0.809496 loss)
I1210 16:39:37.806104 15772 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1210 16:39:43.438048 15772 solver.cpp:218] Iteration 76900 (17.7584 iter/s, 5.63114s/100 iters), loss = 0.814265
I1210 16:39:43.438048 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:39:43.438048 15772 solver.cpp:237]     Train net output #1: loss = 0.814265 (* 1 = 0.814265 loss)
I1210 16:39:43.438048 15772 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1210 16:39:48.798842 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:39:49.021867 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_77000.caffemodel
I1210 16:39:49.037853 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_77000.solverstate
I1210 16:39:49.067878 15772 solver.cpp:330] Iteration 77000, Testing net (#0)
I1210 16:39:49.067878 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:39:50.439975 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:39:50.492995 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5693
I1210 16:39:50.492995 15772 solver.cpp:397]     Test net output #1: loss = 1.63247 (* 1 = 1.63247 loss)
I1210 16:39:50.545989 15772 solver.cpp:218] Iteration 77000 (14.0691 iter/s, 7.10776s/100 iters), loss = 0.610493
I1210 16:39:50.545989 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:39:50.545989 15772 solver.cpp:237]     Train net output #1: loss = 0.610492 (* 1 = 0.610492 loss)
I1210 16:39:50.545989 15772 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1210 16:39:56.192409 15772 solver.cpp:218] Iteration 77100 (17.7134 iter/s, 5.64545s/100 iters), loss = 0.779218
I1210 16:39:56.192409 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:39:56.192409 15772 solver.cpp:237]     Train net output #1: loss = 0.779218 (* 1 = 0.779218 loss)
I1210 16:39:56.192409 15772 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1210 16:40:01.843991 15772 solver.cpp:218] Iteration 77200 (17.6943 iter/s, 5.65154s/100 iters), loss = 0.659806
I1210 16:40:01.843991 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:40:01.843991 15772 solver.cpp:237]     Train net output #1: loss = 0.659806 (* 1 = 0.659806 loss)
I1210 16:40:01.843991 15772 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1210 16:40:07.481930 15772 solver.cpp:218] Iteration 77300 (17.7402 iter/s, 5.63691s/100 iters), loss = 0.822333
I1210 16:40:07.481930 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:40:07.481930 15772 solver.cpp:237]     Train net output #1: loss = 0.822333 (* 1 = 0.822333 loss)
I1210 16:40:07.481930 15772 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1210 16:40:13.121822 15772 solver.cpp:218] Iteration 77400 (17.7309 iter/s, 5.63986s/100 iters), loss = 0.824256
I1210 16:40:13.121822 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:40:13.121822 15772 solver.cpp:237]     Train net output #1: loss = 0.824256 (* 1 = 0.824256 loss)
I1210 16:40:13.121822 15772 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1210 16:40:18.496752 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:40:18.717263 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_77500.caffemodel
I1210 16:40:18.732264 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_77500.solverstate
I1210 16:40:18.784766 15772 solver.cpp:330] Iteration 77500, Testing net (#0)
I1210 16:40:18.784766 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:40:20.157398 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:40:20.211405 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5686
I1210 16:40:20.211405 15772 solver.cpp:397]     Test net output #1: loss = 1.66626 (* 1 = 1.66626 loss)
I1210 16:40:20.264405 15772 solver.cpp:218] Iteration 77500 (14.0005 iter/s, 7.14261s/100 iters), loss = 0.685546
I1210 16:40:20.265404 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:40:20.265404 15772 solver.cpp:237]     Train net output #1: loss = 0.685546 (* 1 = 0.685546 loss)
I1210 16:40:20.265404 15772 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1210 16:40:25.910830 15772 solver.cpp:218] Iteration 77600 (17.7144 iter/s, 5.64513s/100 iters), loss = 0.733501
I1210 16:40:25.910830 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:40:25.910830 15772 solver.cpp:237]     Train net output #1: loss = 0.733501 (* 1 = 0.733501 loss)
I1210 16:40:25.910830 15772 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1210 16:40:31.545214 15772 solver.cpp:218] Iteration 77700 (17.7488 iter/s, 5.63418s/100 iters), loss = 0.677382
I1210 16:40:31.545214 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:40:31.545214 15772 solver.cpp:237]     Train net output #1: loss = 0.677382 (* 1 = 0.677382 loss)
I1210 16:40:31.545214 15772 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1210 16:40:37.181650 15772 solver.cpp:218] Iteration 77800 (17.7423 iter/s, 5.63626s/100 iters), loss = 0.884849
I1210 16:40:37.181650 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 16:40:37.181650 15772 solver.cpp:237]     Train net output #1: loss = 0.884849 (* 1 = 0.884849 loss)
I1210 16:40:37.181650 15772 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1210 16:40:42.826120 15772 solver.cpp:218] Iteration 77900 (17.7204 iter/s, 5.64321s/100 iters), loss = 0.873068
I1210 16:40:42.826120 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:40:42.826120 15772 solver.cpp:237]     Train net output #1: loss = 0.873068 (* 1 = 0.873068 loss)
I1210 16:40:42.826120 15772 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1210 16:40:48.187598 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:40:48.409612 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_78000.caffemodel
I1210 16:40:48.423612 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_78000.solverstate
I1210 16:40:48.450611 15772 solver.cpp:330] Iteration 78000, Testing net (#0)
I1210 16:40:48.450611 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:40:49.823696 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:40:49.876696 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5853
I1210 16:40:49.876696 15772 solver.cpp:397]     Test net output #1: loss = 1.61002 (* 1 = 1.61002 loss)
I1210 16:40:49.930709 15772 solver.cpp:218] Iteration 78000 (14.0748 iter/s, 7.1049s/100 iters), loss = 0.641817
I1210 16:40:49.930709 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:40:49.930709 15772 solver.cpp:237]     Train net output #1: loss = 0.641817 (* 1 = 0.641817 loss)
I1210 16:40:49.930709 15772 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1210 16:40:55.581079 15772 solver.cpp:218] Iteration 78100 (17.7015 iter/s, 5.64923s/100 iters), loss = 0.89059
I1210 16:40:55.581079 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:40:55.581079 15772 solver.cpp:237]     Train net output #1: loss = 0.89059 (* 1 = 0.89059 loss)
I1210 16:40:55.581079 15772 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1210 16:41:01.235525 15772 solver.cpp:218] Iteration 78200 (17.686 iter/s, 5.65419s/100 iters), loss = 0.607971
I1210 16:41:01.235525 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:41:01.235525 15772 solver.cpp:237]     Train net output #1: loss = 0.607971 (* 1 = 0.607971 loss)
I1210 16:41:01.235525 15772 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1210 16:41:06.882930 15772 solver.cpp:218] Iteration 78300 (17.7099 iter/s, 5.64657s/100 iters), loss = 0.800598
I1210 16:41:06.882930 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:41:06.882930 15772 solver.cpp:237]     Train net output #1: loss = 0.800597 (* 1 = 0.800597 loss)
I1210 16:41:06.882930 15772 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1210 16:41:12.537358 15772 solver.cpp:218] Iteration 78400 (17.6848 iter/s, 5.65456s/100 iters), loss = 0.93696
I1210 16:41:12.537358 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 16:41:12.537358 15772 solver.cpp:237]     Train net output #1: loss = 0.93696 (* 1 = 0.93696 loss)
I1210 16:41:12.537358 15772 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1210 16:41:17.906787 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:41:18.130797 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_78500.caffemodel
I1210 16:41:18.144798 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_78500.solverstate
I1210 16:41:18.149796 15772 solver.cpp:330] Iteration 78500, Testing net (#0)
I1210 16:41:18.149796 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:41:19.518892 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:41:19.572921 15772 solver.cpp:397]     Test net output #0: accuracy = 0.585
I1210 16:41:19.572921 15772 solver.cpp:397]     Test net output #1: loss = 1.61881 (* 1 = 1.61881 loss)
I1210 16:41:19.625895 15772 solver.cpp:218] Iteration 78500 (14.1087 iter/s, 7.08782s/100 iters), loss = 0.643601
I1210 16:41:19.625895 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:41:19.625895 15772 solver.cpp:237]     Train net output #1: loss = 0.643601 (* 1 = 0.643601 loss)
I1210 16:41:19.625895 15772 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1210 16:41:25.270319 15772 solver.cpp:218] Iteration 78600 (17.7178 iter/s, 5.64403s/100 iters), loss = 0.732874
I1210 16:41:25.270319 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:41:25.270319 15772 solver.cpp:237]     Train net output #1: loss = 0.732874 (* 1 = 0.732874 loss)
I1210 16:41:25.270319 15772 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1210 16:41:30.909807 15772 solver.cpp:218] Iteration 78700 (17.7322 iter/s, 5.63947s/100 iters), loss = 0.570362
I1210 16:41:30.909807 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:41:30.909807 15772 solver.cpp:237]     Train net output #1: loss = 0.570361 (* 1 = 0.570361 loss)
I1210 16:41:30.909807 15772 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1210 16:41:36.548162 15772 solver.cpp:218] Iteration 78800 (17.7376 iter/s, 5.63775s/100 iters), loss = 0.939604
I1210 16:41:36.548162 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:41:36.548162 15772 solver.cpp:237]     Train net output #1: loss = 0.939604 (* 1 = 0.939604 loss)
I1210 16:41:36.548162 15772 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1210 16:41:42.200557 15772 solver.cpp:218] Iteration 78900 (17.6949 iter/s, 5.65135s/100 iters), loss = 0.790854
I1210 16:41:42.200557 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:41:42.200557 15772 solver.cpp:237]     Train net output #1: loss = 0.790854 (* 1 = 0.790854 loss)
I1210 16:41:42.200557 15772 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1210 16:41:47.567924 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:41:47.789454 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_79000.caffemodel
I1210 16:41:47.804453 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_79000.solverstate
I1210 16:41:47.808959 15772 solver.cpp:330] Iteration 79000, Testing net (#0)
I1210 16:41:47.808959 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:41:49.184134 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:41:49.238139 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5924
I1210 16:41:49.238139 15772 solver.cpp:397]     Test net output #1: loss = 1.57079 (* 1 = 1.57079 loss)
I1210 16:41:49.292644 15772 solver.cpp:218] Iteration 79000 (14.1012 iter/s, 7.09159s/100 iters), loss = 0.618893
I1210 16:41:49.292644 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:41:49.292644 15772 solver.cpp:237]     Train net output #1: loss = 0.618893 (* 1 = 0.618893 loss)
I1210 16:41:49.292644 15772 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1210 16:41:54.935853 15772 solver.cpp:218] Iteration 79100 (17.7206 iter/s, 5.64316s/100 iters), loss = 0.67963
I1210 16:41:54.935853 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:41:54.935853 15772 solver.cpp:237]     Train net output #1: loss = 0.67963 (* 1 = 0.67963 loss)
I1210 16:41:54.935853 15772 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1210 16:42:00.572274 15772 solver.cpp:218] Iteration 79200 (17.7435 iter/s, 5.63587s/100 iters), loss = 0.584807
I1210 16:42:00.572274 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:42:00.572274 15772 solver.cpp:237]     Train net output #1: loss = 0.584806 (* 1 = 0.584806 loss)
I1210 16:42:00.572274 15772 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1210 16:42:06.209703 15772 solver.cpp:218] Iteration 79300 (17.7391 iter/s, 5.63727s/100 iters), loss = 0.890582
I1210 16:42:06.209703 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:42:06.209703 15772 solver.cpp:237]     Train net output #1: loss = 0.890582 (* 1 = 0.890582 loss)
I1210 16:42:06.209703 15772 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1210 16:42:11.847105 15772 solver.cpp:218] Iteration 79400 (17.7395 iter/s, 5.63715s/100 iters), loss = 0.862416
I1210 16:42:11.847105 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:42:11.847105 15772 solver.cpp:237]     Train net output #1: loss = 0.862416 (* 1 = 0.862416 loss)
I1210 16:42:11.847105 15772 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1210 16:42:17.223852 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:42:17.445868 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_79500.caffemodel
I1210 16:42:17.459868 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_79500.solverstate
I1210 16:42:17.463868 15772 solver.cpp:330] Iteration 79500, Testing net (#0)
I1210 16:42:17.464869 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:42:18.834077 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:42:18.888077 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5912
I1210 16:42:18.888077 15772 solver.cpp:397]     Test net output #1: loss = 1.61366 (* 1 = 1.61366 loss)
I1210 16:42:18.941083 15772 solver.cpp:218] Iteration 79500 (14.0973 iter/s, 7.09357s/100 iters), loss = 0.643778
I1210 16:42:18.941083 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:42:18.941083 15772 solver.cpp:237]     Train net output #1: loss = 0.643778 (* 1 = 0.643778 loss)
I1210 16:42:18.941083 15772 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1210 16:42:24.597510 15772 solver.cpp:218] Iteration 79600 (17.6824 iter/s, 5.65533s/100 iters), loss = 0.874987
I1210 16:42:24.597510 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:42:24.597510 15772 solver.cpp:237]     Train net output #1: loss = 0.874987 (* 1 = 0.874987 loss)
I1210 16:42:24.597510 15772 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1210 16:42:30.241534 15772 solver.cpp:218] Iteration 79700 (17.7183 iter/s, 5.64388s/100 iters), loss = 0.745761
I1210 16:42:30.241534 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:42:30.241534 15772 solver.cpp:237]     Train net output #1: loss = 0.745761 (* 1 = 0.745761 loss)
I1210 16:42:30.241534 15772 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1210 16:42:35.888886 15772 solver.cpp:218] Iteration 79800 (17.7088 iter/s, 5.64691s/100 iters), loss = 0.847472
I1210 16:42:35.888886 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:42:35.888886 15772 solver.cpp:237]     Train net output #1: loss = 0.847472 (* 1 = 0.847472 loss)
I1210 16:42:35.888886 15772 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1210 16:42:41.544193 15772 solver.cpp:218] Iteration 79900 (17.6847 iter/s, 5.65462s/100 iters), loss = 0.727793
I1210 16:42:41.544193 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:42:41.544193 15772 solver.cpp:237]     Train net output #1: loss = 0.727793 (* 1 = 0.727793 loss)
I1210 16:42:41.544193 15772 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1210 16:42:46.910171 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:42:47.133126 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_80000.caffemodel
I1210 16:42:47.148123 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_80000.solverstate
I1210 16:42:47.153132 15772 solver.cpp:330] Iteration 80000, Testing net (#0)
I1210 16:42:47.153132 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:42:48.521994 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:42:48.574993 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5947
I1210 16:42:48.574993 15772 solver.cpp:397]     Test net output #1: loss = 1.56228 (* 1 = 1.56228 loss)
I1210 16:42:48.629017 15772 solver.cpp:218] Iteration 80000 (14.1147 iter/s, 7.08482s/100 iters), loss = 0.650923
I1210 16:42:48.629017 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:42:48.629017 15772 solver.cpp:237]     Train net output #1: loss = 0.650923 (* 1 = 0.650923 loss)
I1210 16:42:48.629017 15772 sgd_solver.cpp:105] Iteration 80000, lr = 0.01
I1210 16:42:54.277740 15772 solver.cpp:218] Iteration 80100 (17.7056 iter/s, 5.64795s/100 iters), loss = 0.714193
I1210 16:42:54.277740 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:42:54.277740 15772 solver.cpp:237]     Train net output #1: loss = 0.714193 (* 1 = 0.714193 loss)
I1210 16:42:54.277740 15772 sgd_solver.cpp:105] Iteration 80100, lr = 0.01
I1210 16:42:59.914603 15772 solver.cpp:218] Iteration 80200 (17.7427 iter/s, 5.63612s/100 iters), loss = 0.690835
I1210 16:42:59.914603 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:42:59.914603 15772 solver.cpp:237]     Train net output #1: loss = 0.690835 (* 1 = 0.690835 loss)
I1210 16:42:59.914603 15772 sgd_solver.cpp:105] Iteration 80200, lr = 0.01
I1210 16:43:05.554376 15772 solver.cpp:218] Iteration 80300 (17.7298 iter/s, 5.64022s/100 iters), loss = 0.706757
I1210 16:43:05.555377 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:43:05.555377 15772 solver.cpp:237]     Train net output #1: loss = 0.706757 (* 1 = 0.706757 loss)
I1210 16:43:05.555377 15772 sgd_solver.cpp:105] Iteration 80300, lr = 0.01
I1210 16:43:11.198395 15772 solver.cpp:218] Iteration 80400 (17.7218 iter/s, 5.64277s/100 iters), loss = 0.715897
I1210 16:43:11.198395 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:43:11.198395 15772 solver.cpp:237]     Train net output #1: loss = 0.715897 (* 1 = 0.715897 loss)
I1210 16:43:11.198395 15772 sgd_solver.cpp:105] Iteration 80400, lr = 0.01
I1210 16:43:16.562445 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:43:16.787457 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_80500.caffemodel
I1210 16:43:16.801457 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_80500.solverstate
I1210 16:43:16.806458 15772 solver.cpp:330] Iteration 80500, Testing net (#0)
I1210 16:43:16.806458 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:43:18.179630 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:43:18.233635 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5729
I1210 16:43:18.234135 15772 solver.cpp:397]     Test net output #1: loss = 1.65296 (* 1 = 1.65296 loss)
I1210 16:43:18.286638 15772 solver.cpp:218] Iteration 80500 (14.1073 iter/s, 7.08852s/100 iters), loss = 0.592452
I1210 16:43:18.287638 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:43:18.287638 15772 solver.cpp:237]     Train net output #1: loss = 0.592452 (* 1 = 0.592452 loss)
I1210 16:43:18.287638 15772 sgd_solver.cpp:105] Iteration 80500, lr = 0.01
I1210 16:43:23.935585 15772 solver.cpp:218] Iteration 80600 (17.7055 iter/s, 5.64795s/100 iters), loss = 0.890887
I1210 16:43:23.935585 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:43:23.935585 15772 solver.cpp:237]     Train net output #1: loss = 0.890887 (* 1 = 0.890887 loss)
I1210 16:43:23.935585 15772 sgd_solver.cpp:105] Iteration 80600, lr = 0.01
I1210 16:43:29.583577 15772 solver.cpp:218] Iteration 80700 (17.7058 iter/s, 5.64786s/100 iters), loss = 0.735909
I1210 16:43:29.583577 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:43:29.583577 15772 solver.cpp:237]     Train net output #1: loss = 0.735909 (* 1 = 0.735909 loss)
I1210 16:43:29.583577 15772 sgd_solver.cpp:105] Iteration 80700, lr = 0.01
I1210 16:43:35.231076 15772 solver.cpp:218] Iteration 80800 (17.7095 iter/s, 5.64669s/100 iters), loss = 0.742268
I1210 16:43:35.231076 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:43:35.231076 15772 solver.cpp:237]     Train net output #1: loss = 0.742268 (* 1 = 0.742268 loss)
I1210 16:43:35.231076 15772 sgd_solver.cpp:105] Iteration 80800, lr = 0.01
I1210 16:43:40.872547 15772 solver.cpp:218] Iteration 80900 (17.7264 iter/s, 5.6413s/100 iters), loss = 0.858795
I1210 16:43:40.872547 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:43:40.872547 15772 solver.cpp:237]     Train net output #1: loss = 0.858795 (* 1 = 0.858795 loss)
I1210 16:43:40.872547 15772 sgd_solver.cpp:105] Iteration 80900, lr = 0.01
I1210 16:43:46.244040 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:43:46.465050 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_81000.caffemodel
I1210 16:43:46.481050 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_81000.solverstate
I1210 16:43:46.486049 15772 solver.cpp:330] Iteration 81000, Testing net (#0)
I1210 16:43:46.486049 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:43:47.855149 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:43:47.909147 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5864
I1210 16:43:47.909147 15772 solver.cpp:397]     Test net output #1: loss = 1.66408 (* 1 = 1.66408 loss)
I1210 16:43:47.962157 15772 solver.cpp:218] Iteration 81000 (14.1061 iter/s, 7.08913s/100 iters), loss = 0.673978
I1210 16:43:47.962157 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:43:47.962157 15772 solver.cpp:237]     Train net output #1: loss = 0.673978 (* 1 = 0.673978 loss)
I1210 16:43:47.962157 15772 sgd_solver.cpp:105] Iteration 81000, lr = 0.01
I1210 16:43:53.614635 15772 solver.cpp:218] Iteration 81100 (17.6922 iter/s, 5.65221s/100 iters), loss = 0.706065
I1210 16:43:53.614635 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:43:53.614635 15772 solver.cpp:237]     Train net output #1: loss = 0.706065 (* 1 = 0.706065 loss)
I1210 16:43:53.614635 15772 sgd_solver.cpp:105] Iteration 81100, lr = 0.01
I1210 16:43:59.263047 15772 solver.cpp:218] Iteration 81200 (17.7068 iter/s, 5.64756s/100 iters), loss = 0.591795
I1210 16:43:59.263047 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:43:59.263047 15772 solver.cpp:237]     Train net output #1: loss = 0.591795 (* 1 = 0.591795 loss)
I1210 16:43:59.263047 15772 sgd_solver.cpp:105] Iteration 81200, lr = 0.01
I1210 16:44:04.914486 15772 solver.cpp:218] Iteration 81300 (17.6961 iter/s, 5.65095s/100 iters), loss = 0.828864
I1210 16:44:04.914486 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:44:04.914486 15772 solver.cpp:237]     Train net output #1: loss = 0.828863 (* 1 = 0.828863 loss)
I1210 16:44:04.914486 15772 sgd_solver.cpp:105] Iteration 81300, lr = 0.01
I1210 16:44:10.556960 15772 solver.cpp:218] Iteration 81400 (17.7237 iter/s, 5.64218s/100 iters), loss = 0.85158
I1210 16:44:10.556960 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:44:10.556960 15772 solver.cpp:237]     Train net output #1: loss = 0.85158 (* 1 = 0.85158 loss)
I1210 16:44:10.556960 15772 sgd_solver.cpp:105] Iteration 81400, lr = 0.01
I1210 16:44:15.931385 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:44:16.152411 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_81500.caffemodel
I1210 16:44:16.168412 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_81500.solverstate
I1210 16:44:16.173413 15772 solver.cpp:330] Iteration 81500, Testing net (#0)
I1210 16:44:16.173413 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:44:17.544502 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:44:17.597499 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5517
I1210 16:44:17.598501 15772 solver.cpp:397]     Test net output #1: loss = 1.89247 (* 1 = 1.89247 loss)
I1210 16:44:17.651505 15772 solver.cpp:218] Iteration 81500 (14.0957 iter/s, 7.09434s/100 iters), loss = 0.547085
I1210 16:44:17.651505 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 16:44:17.651505 15772 solver.cpp:237]     Train net output #1: loss = 0.547085 (* 1 = 0.547085 loss)
I1210 16:44:17.651505 15772 sgd_solver.cpp:105] Iteration 81500, lr = 0.01
I1210 16:44:23.296984 15772 solver.cpp:218] Iteration 81600 (17.7147 iter/s, 5.64503s/100 iters), loss = 0.63616
I1210 16:44:23.296984 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:44:23.296984 15772 solver.cpp:237]     Train net output #1: loss = 0.63616 (* 1 = 0.63616 loss)
I1210 16:44:23.296984 15772 sgd_solver.cpp:105] Iteration 81600, lr = 0.01
I1210 16:44:28.932415 15772 solver.cpp:218] Iteration 81700 (17.7487 iter/s, 5.63421s/100 iters), loss = 0.579243
I1210 16:44:28.932415 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:44:28.932415 15772 solver.cpp:237]     Train net output #1: loss = 0.579243 (* 1 = 0.579243 loss)
I1210 16:44:28.932415 15772 sgd_solver.cpp:105] Iteration 81700, lr = 0.01
I1210 16:44:34.571825 15772 solver.cpp:218] Iteration 81800 (17.7309 iter/s, 5.63987s/100 iters), loss = 0.872381
I1210 16:44:34.571825 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 16:44:34.572826 15772 solver.cpp:237]     Train net output #1: loss = 0.872381 (* 1 = 0.872381 loss)
I1210 16:44:34.572826 15772 sgd_solver.cpp:105] Iteration 81800, lr = 0.01
I1210 16:44:40.199236 15772 solver.cpp:218] Iteration 81900 (17.7732 iter/s, 5.62645s/100 iters), loss = 0.757939
I1210 16:44:40.199236 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:44:40.199738 15772 solver.cpp:237]     Train net output #1: loss = 0.757939 (* 1 = 0.757939 loss)
I1210 16:44:40.199738 15772 sgd_solver.cpp:105] Iteration 81900, lr = 0.01
I1210 16:44:45.548221 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:44:45.770234 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_82000.caffemodel
I1210 16:44:45.784235 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_82000.solverstate
I1210 16:44:45.853256 15772 solver.cpp:330] Iteration 82000, Testing net (#0)
I1210 16:44:45.853256 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:44:47.222357 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:44:47.276355 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5786
I1210 16:44:47.276355 15772 solver.cpp:397]     Test net output #1: loss = 1.67776 (* 1 = 1.67776 loss)
I1210 16:44:47.329357 15772 solver.cpp:218] Iteration 82000 (14.0268 iter/s, 7.12922s/100 iters), loss = 0.600593
I1210 16:44:47.329357 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:44:47.329357 15772 solver.cpp:237]     Train net output #1: loss = 0.600593 (* 1 = 0.600593 loss)
I1210 16:44:47.329357 15772 sgd_solver.cpp:105] Iteration 82000, lr = 0.01
I1210 16:44:52.954890 15772 solver.cpp:218] Iteration 82100 (17.7757 iter/s, 5.62565s/100 iters), loss = 0.755452
I1210 16:44:52.954890 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:44:52.954890 15772 solver.cpp:237]     Train net output #1: loss = 0.755452 (* 1 = 0.755452 loss)
I1210 16:44:52.954890 15772 sgd_solver.cpp:105] Iteration 82100, lr = 0.01
I1210 16:44:58.581308 15772 solver.cpp:218] Iteration 82200 (17.7738 iter/s, 5.62627s/100 iters), loss = 0.70876
I1210 16:44:58.581308 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:44:58.581308 15772 solver.cpp:237]     Train net output #1: loss = 0.70876 (* 1 = 0.70876 loss)
I1210 16:44:58.581308 15772 sgd_solver.cpp:105] Iteration 82200, lr = 0.01
I1210 16:45:04.212752 15772 solver.cpp:218] Iteration 82300 (17.7588 iter/s, 5.63102s/100 iters), loss = 0.747553
I1210 16:45:04.213753 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:45:04.213753 15772 solver.cpp:237]     Train net output #1: loss = 0.747553 (* 1 = 0.747553 loss)
I1210 16:45:04.213753 15772 sgd_solver.cpp:105] Iteration 82300, lr = 0.01
I1210 16:45:09.843745 15772 solver.cpp:218] Iteration 82400 (17.762 iter/s, 5.63s/100 iters), loss = 0.906404
I1210 16:45:09.843745 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:45:09.843745 15772 solver.cpp:237]     Train net output #1: loss = 0.906404 (* 1 = 0.906404 loss)
I1210 16:45:09.843745 15772 sgd_solver.cpp:105] Iteration 82400, lr = 0.01
I1210 16:45:15.190549 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:45:15.412070 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_82500.caffemodel
I1210 16:45:15.427573 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_82500.solverstate
I1210 16:45:15.431574 15772 solver.cpp:330] Iteration 82500, Testing net (#0)
I1210 16:45:15.431574 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:45:16.800263 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:45:16.853770 15772 solver.cpp:397]     Test net output #0: accuracy = 0.581
I1210 16:45:16.853770 15772 solver.cpp:397]     Test net output #1: loss = 1.60923 (* 1 = 1.60923 loss)
I1210 16:45:16.906770 15772 solver.cpp:218] Iteration 82500 (14.1594 iter/s, 7.06243s/100 iters), loss = 0.735748
I1210 16:45:16.907270 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:45:16.907270 15772 solver.cpp:237]     Train net output #1: loss = 0.735748 (* 1 = 0.735748 loss)
I1210 16:45:16.907270 15772 sgd_solver.cpp:105] Iteration 82500, lr = 0.01
I1210 16:45:22.536270 15772 solver.cpp:218] Iteration 82600 (17.7657 iter/s, 5.62884s/100 iters), loss = 0.712735
I1210 16:45:22.536270 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:45:22.536270 15772 solver.cpp:237]     Train net output #1: loss = 0.712735 (* 1 = 0.712735 loss)
I1210 16:45:22.536270 15772 sgd_solver.cpp:105] Iteration 82600, lr = 0.01
I1210 16:45:28.158939 15772 solver.cpp:218] Iteration 82700 (17.7857 iter/s, 5.62249s/100 iters), loss = 0.770069
I1210 16:45:28.158939 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:45:28.158939 15772 solver.cpp:237]     Train net output #1: loss = 0.770069 (* 1 = 0.770069 loss)
I1210 16:45:28.158939 15772 sgd_solver.cpp:105] Iteration 82700, lr = 0.01
I1210 16:45:33.791981 15772 solver.cpp:218] Iteration 82800 (17.7529 iter/s, 5.63287s/100 iters), loss = 0.822138
I1210 16:45:33.791981 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:45:33.791981 15772 solver.cpp:237]     Train net output #1: loss = 0.822138 (* 1 = 0.822138 loss)
I1210 16:45:33.791981 15772 sgd_solver.cpp:105] Iteration 82800, lr = 0.01
I1210 16:45:39.426607 15772 solver.cpp:218] Iteration 82900 (17.7492 iter/s, 5.63406s/100 iters), loss = 0.886992
I1210 16:45:39.426607 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:45:39.426607 15772 solver.cpp:237]     Train net output #1: loss = 0.886992 (* 1 = 0.886992 loss)
I1210 16:45:39.426607 15772 sgd_solver.cpp:105] Iteration 82900, lr = 0.01
I1210 16:45:44.778000 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:45:45.000010 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_83000.caffemodel
I1210 16:45:45.014014 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_83000.solverstate
I1210 16:45:45.035025 15772 solver.cpp:330] Iteration 83000, Testing net (#0)
I1210 16:45:45.036026 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:45:46.401131 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:45:46.456135 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5852
I1210 16:45:46.456135 15772 solver.cpp:397]     Test net output #1: loss = 1.61601 (* 1 = 1.61601 loss)
I1210 16:45:46.510138 15772 solver.cpp:218] Iteration 83000 (14.119 iter/s, 7.08265s/100 iters), loss = 0.642825
I1210 16:45:46.510138 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:45:46.510138 15772 solver.cpp:237]     Train net output #1: loss = 0.642825 (* 1 = 0.642825 loss)
I1210 16:45:46.510138 15772 sgd_solver.cpp:105] Iteration 83000, lr = 0.01
I1210 16:45:52.151618 15772 solver.cpp:218] Iteration 83100 (17.7268 iter/s, 5.64116s/100 iters), loss = 0.85352
I1210 16:45:52.151618 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:45:52.151618 15772 solver.cpp:237]     Train net output #1: loss = 0.85352 (* 1 = 0.85352 loss)
I1210 16:45:52.151618 15772 sgd_solver.cpp:105] Iteration 83100, lr = 0.01
I1210 16:45:57.794020 15772 solver.cpp:218] Iteration 83200 (17.7235 iter/s, 5.64222s/100 iters), loss = 0.716197
I1210 16:45:57.794020 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:45:57.794020 15772 solver.cpp:237]     Train net output #1: loss = 0.716197 (* 1 = 0.716197 loss)
I1210 16:45:57.794020 15772 sgd_solver.cpp:105] Iteration 83200, lr = 0.01
I1210 16:46:03.437484 15772 solver.cpp:218] Iteration 83300 (17.7221 iter/s, 5.64267s/100 iters), loss = 0.841732
I1210 16:46:03.437484 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:46:03.437484 15772 solver.cpp:237]     Train net output #1: loss = 0.841732 (* 1 = 0.841732 loss)
I1210 16:46:03.437484 15772 sgd_solver.cpp:105] Iteration 83300, lr = 0.01
I1210 16:46:09.066987 15772 solver.cpp:218] Iteration 83400 (17.7654 iter/s, 5.62891s/100 iters), loss = 1.10462
I1210 16:46:09.066987 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 16:46:09.066987 15772 solver.cpp:237]     Train net output #1: loss = 1.10462 (* 1 = 1.10462 loss)
I1210 16:46:09.066987 15772 sgd_solver.cpp:105] Iteration 83400, lr = 0.01
I1210 16:46:14.432438 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:46:14.654450 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_83500.caffemodel
I1210 16:46:14.668450 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_83500.solverstate
I1210 16:46:14.672451 15772 solver.cpp:330] Iteration 83500, Testing net (#0)
I1210 16:46:14.673451 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:46:16.040608 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:46:16.094609 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5975
I1210 16:46:16.094609 15772 solver.cpp:397]     Test net output #1: loss = 1.54703 (* 1 = 1.54703 loss)
I1210 16:46:16.149616 15772 solver.cpp:218] Iteration 83500 (14.1194 iter/s, 7.08243s/100 iters), loss = 0.658105
I1210 16:46:16.149616 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:46:16.149616 15772 solver.cpp:237]     Train net output #1: loss = 0.658105 (* 1 = 0.658105 loss)
I1210 16:46:16.149616 15772 sgd_solver.cpp:105] Iteration 83500, lr = 0.01
I1210 16:46:21.785064 15772 solver.cpp:218] Iteration 83600 (17.7476 iter/s, 5.63456s/100 iters), loss = 0.770453
I1210 16:46:21.785064 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:46:21.785064 15772 solver.cpp:237]     Train net output #1: loss = 0.770453 (* 1 = 0.770453 loss)
I1210 16:46:21.785064 15772 sgd_solver.cpp:105] Iteration 83600, lr = 0.01
I1210 16:46:27.408078 15772 solver.cpp:218] Iteration 83700 (17.7841 iter/s, 5.62301s/100 iters), loss = 0.707748
I1210 16:46:27.408579 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:46:27.408579 15772 solver.cpp:237]     Train net output #1: loss = 0.707748 (* 1 = 0.707748 loss)
I1210 16:46:27.408579 15772 sgd_solver.cpp:105] Iteration 83700, lr = 0.01
I1210 16:46:33.043061 15772 solver.cpp:218] Iteration 83800 (17.7488 iter/s, 5.6342s/100 iters), loss = 0.851018
I1210 16:46:33.043061 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:46:33.043061 15772 solver.cpp:237]     Train net output #1: loss = 0.851018 (* 1 = 0.851018 loss)
I1210 16:46:33.043061 15772 sgd_solver.cpp:105] Iteration 83800, lr = 0.01
I1210 16:46:38.668473 15772 solver.cpp:218] Iteration 83900 (17.777 iter/s, 5.62524s/100 iters), loss = 0.797839
I1210 16:46:38.668473 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:46:38.668473 15772 solver.cpp:237]     Train net output #1: loss = 0.797839 (* 1 = 0.797839 loss)
I1210 16:46:38.668473 15772 sgd_solver.cpp:105] Iteration 83900, lr = 0.01
I1210 16:46:44.030869 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:46:44.249893 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_84000.caffemodel
I1210 16:46:44.264894 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_84000.solverstate
I1210 16:46:44.292892 15772 solver.cpp:330] Iteration 84000, Testing net (#0)
I1210 16:46:44.292892 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:46:45.661067 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:46:45.715065 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5889
I1210 16:46:45.715065 15772 solver.cpp:397]     Test net output #1: loss = 1.56231 (* 1 = 1.56231 loss)
I1210 16:46:45.768065 15772 solver.cpp:218] Iteration 84000 (14.0863 iter/s, 7.09911s/100 iters), loss = 0.602341
I1210 16:46:45.768065 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:46:45.768065 15772 solver.cpp:237]     Train net output #1: loss = 0.602341 (* 1 = 0.602341 loss)
I1210 16:46:45.768065 15772 sgd_solver.cpp:105] Iteration 84000, lr = 0.01
I1210 16:46:51.391547 15772 solver.cpp:218] Iteration 84100 (17.7853 iter/s, 5.62263s/100 iters), loss = 0.743348
I1210 16:46:51.391547 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:46:51.391547 15772 solver.cpp:237]     Train net output #1: loss = 0.743348 (* 1 = 0.743348 loss)
I1210 16:46:51.391547 15772 sgd_solver.cpp:105] Iteration 84100, lr = 0.01
I1210 16:46:57.023025 15772 solver.cpp:218] Iteration 84200 (17.7587 iter/s, 5.63104s/100 iters), loss = 0.551892
I1210 16:46:57.023025 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:46:57.023025 15772 solver.cpp:237]     Train net output #1: loss = 0.551892 (* 1 = 0.551892 loss)
I1210 16:46:57.023025 15772 sgd_solver.cpp:105] Iteration 84200, lr = 0.01
I1210 16:47:02.651470 15772 solver.cpp:218] Iteration 84300 (17.7659 iter/s, 5.62876s/100 iters), loss = 0.873782
I1210 16:47:02.651470 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:47:02.651470 15772 solver.cpp:237]     Train net output #1: loss = 0.873782 (* 1 = 0.873782 loss)
I1210 16:47:02.651470 15772 sgd_solver.cpp:105] Iteration 84300, lr = 0.01
I1210 16:47:08.267060 15772 solver.cpp:218] Iteration 84400 (17.8101 iter/s, 5.61478s/100 iters), loss = 0.798851
I1210 16:47:08.267060 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:47:08.267060 15772 solver.cpp:237]     Train net output #1: loss = 0.798851 (* 1 = 0.798851 loss)
I1210 16:47:08.267060 15772 sgd_solver.cpp:105] Iteration 84400, lr = 0.01
I1210 16:47:13.616454 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:47:13.838480 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_84500.caffemodel
I1210 16:47:13.852479 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_84500.solverstate
I1210 16:47:13.857481 15772 solver.cpp:330] Iteration 84500, Testing net (#0)
I1210 16:47:13.857481 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:47:15.227118 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:47:15.279619 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5853
I1210 16:47:15.279619 15772 solver.cpp:397]     Test net output #1: loss = 1.64692 (* 1 = 1.64692 loss)
I1210 16:47:15.332623 15772 solver.cpp:218] Iteration 84500 (14.1537 iter/s, 7.06531s/100 iters), loss = 0.599486
I1210 16:47:15.332623 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:47:15.332623 15772 solver.cpp:237]     Train net output #1: loss = 0.599486 (* 1 = 0.599486 loss)
I1210 16:47:15.332623 15772 sgd_solver.cpp:105] Iteration 84500, lr = 0.01
I1210 16:47:20.959038 15772 solver.cpp:218] Iteration 84600 (17.7751 iter/s, 5.62585s/100 iters), loss = 0.744075
I1210 16:47:20.959038 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:47:20.959038 15772 solver.cpp:237]     Train net output #1: loss = 0.744075 (* 1 = 0.744075 loss)
I1210 16:47:20.959038 15772 sgd_solver.cpp:105] Iteration 84600, lr = 0.01
I1210 16:47:26.599474 15772 solver.cpp:218] Iteration 84700 (17.7309 iter/s, 5.63988s/100 iters), loss = 0.667231
I1210 16:47:26.599474 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:47:26.599474 15772 solver.cpp:237]     Train net output #1: loss = 0.667231 (* 1 = 0.667231 loss)
I1210 16:47:26.599474 15772 sgd_solver.cpp:105] Iteration 84700, lr = 0.01
I1210 16:47:32.243881 15772 solver.cpp:218] Iteration 84800 (17.7175 iter/s, 5.64412s/100 iters), loss = 0.853733
I1210 16:47:32.243881 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:47:32.243881 15772 solver.cpp:237]     Train net output #1: loss = 0.853733 (* 1 = 0.853733 loss)
I1210 16:47:32.243881 15772 sgd_solver.cpp:105] Iteration 84800, lr = 0.01
I1210 16:47:37.882375 15772 solver.cpp:218] Iteration 84900 (17.7369 iter/s, 5.63795s/100 iters), loss = 0.747538
I1210 16:47:37.882375 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:47:37.882375 15772 solver.cpp:237]     Train net output #1: loss = 0.747538 (* 1 = 0.747538 loss)
I1210 16:47:37.882375 15772 sgd_solver.cpp:105] Iteration 84900, lr = 0.01
I1210 16:47:43.241864 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:47:43.463881 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_85000.caffemodel
I1210 16:47:43.478881 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_85000.solverstate
I1210 16:47:43.492882 15772 solver.cpp:330] Iteration 85000, Testing net (#0)
I1210 16:47:43.492882 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:47:44.862028 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:47:44.917533 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5923
I1210 16:47:44.917533 15772 solver.cpp:397]     Test net output #1: loss = 1.55732 (* 1 = 1.55732 loss)
I1210 16:47:44.970036 15772 solver.cpp:218] Iteration 85000 (14.1094 iter/s, 7.08749s/100 iters), loss = 0.659155
I1210 16:47:44.970036 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:47:44.970036 15772 solver.cpp:237]     Train net output #1: loss = 0.659155 (* 1 = 0.659155 loss)
I1210 16:47:44.970036 15772 sgd_solver.cpp:105] Iteration 85000, lr = 0.01
I1210 16:47:50.609467 15772 solver.cpp:218] Iteration 85100 (17.7351 iter/s, 5.63855s/100 iters), loss = 0.765432
I1210 16:47:50.609467 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:47:50.609467 15772 solver.cpp:237]     Train net output #1: loss = 0.765431 (* 1 = 0.765431 loss)
I1210 16:47:50.609467 15772 sgd_solver.cpp:105] Iteration 85100, lr = 0.01
I1210 16:47:56.253947 15772 solver.cpp:218] Iteration 85200 (17.7155 iter/s, 5.64477s/100 iters), loss = 0.582095
I1210 16:47:56.254947 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:47:56.254947 15772 solver.cpp:237]     Train net output #1: loss = 0.582095 (* 1 = 0.582095 loss)
I1210 16:47:56.254947 15772 sgd_solver.cpp:105] Iteration 85200, lr = 0.01
I1210 16:48:01.894331 15772 solver.cpp:218] Iteration 85300 (17.7307 iter/s, 5.63992s/100 iters), loss = 0.718934
I1210 16:48:01.895332 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:48:01.895332 15772 solver.cpp:237]     Train net output #1: loss = 0.718934 (* 1 = 0.718934 loss)
I1210 16:48:01.895332 15772 sgd_solver.cpp:105] Iteration 85300, lr = 0.01
I1210 16:48:07.590956 15772 solver.cpp:218] Iteration 85400 (17.5564 iter/s, 5.69594s/100 iters), loss = 0.855136
I1210 16:48:07.590956 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:48:07.590956 15772 solver.cpp:237]     Train net output #1: loss = 0.855136 (* 1 = 0.855136 loss)
I1210 16:48:07.590956 15772 sgd_solver.cpp:105] Iteration 85400, lr = 0.01
I1210 16:48:12.970389 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:48:13.201417 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_85500.caffemodel
I1210 16:48:13.217422 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_85500.solverstate
I1210 16:48:13.222421 15772 solver.cpp:330] Iteration 85500, Testing net (#0)
I1210 16:48:13.222421 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:48:14.592533 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:48:14.646553 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5799
I1210 16:48:14.646553 15772 solver.cpp:397]     Test net output #1: loss = 1.59935 (* 1 = 1.59935 loss)
I1210 16:48:14.699539 15772 solver.cpp:218] Iteration 85500 (14.0694 iter/s, 7.10765s/100 iters), loss = 0.580688
I1210 16:48:14.699539 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:48:14.699539 15772 solver.cpp:237]     Train net output #1: loss = 0.580688 (* 1 = 0.580688 loss)
I1210 16:48:14.699539 15772 sgd_solver.cpp:105] Iteration 85500, lr = 0.01
I1210 16:48:20.403141 15772 solver.cpp:218] Iteration 85600 (17.5344 iter/s, 5.70307s/100 iters), loss = 0.800865
I1210 16:48:20.403141 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:48:20.403141 15772 solver.cpp:237]     Train net output #1: loss = 0.800865 (* 1 = 0.800865 loss)
I1210 16:48:20.403141 15772 sgd_solver.cpp:105] Iteration 85600, lr = 0.01
I1210 16:48:26.056648 15772 solver.cpp:218] Iteration 85700 (17.6876 iter/s, 5.65369s/100 iters), loss = 0.527626
I1210 16:48:26.056648 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:48:26.056648 15772 solver.cpp:237]     Train net output #1: loss = 0.527626 (* 1 = 0.527626 loss)
I1210 16:48:26.056648 15772 sgd_solver.cpp:105] Iteration 85700, lr = 0.01
I1210 16:48:31.698302 15772 solver.cpp:218] Iteration 85800 (17.7281 iter/s, 5.64077s/100 iters), loss = 0.814265
I1210 16:48:31.698807 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:48:31.698807 15772 solver.cpp:237]     Train net output #1: loss = 0.814265 (* 1 = 0.814265 loss)
I1210 16:48:31.698807 15772 sgd_solver.cpp:105] Iteration 85800, lr = 0.01
I1210 16:48:37.403643 15772 solver.cpp:218] Iteration 85900 (17.5298 iter/s, 5.70456s/100 iters), loss = 0.814326
I1210 16:48:37.403643 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:48:37.403643 15772 solver.cpp:237]     Train net output #1: loss = 0.814326 (* 1 = 0.814326 loss)
I1210 16:48:37.403643 15772 sgd_solver.cpp:105] Iteration 85900, lr = 0.01
I1210 16:48:42.855275 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:48:43.084327 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_86000.caffemodel
I1210 16:48:43.100348 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_86000.solverstate
I1210 16:48:43.127387 15772 solver.cpp:330] Iteration 86000, Testing net (#0)
I1210 16:48:43.127387 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:48:44.538097 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:48:44.594101 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5908
I1210 16:48:44.594101 15772 solver.cpp:397]     Test net output #1: loss = 1.63891 (* 1 = 1.63891 loss)
I1210 16:48:44.650118 15772 solver.cpp:218] Iteration 86000 (13.8 iter/s, 7.24636s/100 iters), loss = 0.536349
I1210 16:48:44.650118 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:48:44.650118 15772 solver.cpp:237]     Train net output #1: loss = 0.536349 (* 1 = 0.536349 loss)
I1210 16:48:44.650118 15772 sgd_solver.cpp:105] Iteration 86000, lr = 0.01
I1210 16:48:50.378367 15772 solver.cpp:218] Iteration 86100 (17.458 iter/s, 5.72804s/100 iters), loss = 0.697266
I1210 16:48:50.378367 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:48:50.378367 15772 solver.cpp:237]     Train net output #1: loss = 0.697266 (* 1 = 0.697266 loss)
I1210 16:48:50.379367 15772 sgd_solver.cpp:105] Iteration 86100, lr = 0.01
I1210 16:48:56.088027 15772 solver.cpp:218] Iteration 86200 (17.5178 iter/s, 5.70847s/100 iters), loss = 0.711036
I1210 16:48:56.088027 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:48:56.088027 15772 solver.cpp:237]     Train net output #1: loss = 0.711036 (* 1 = 0.711036 loss)
I1210 16:48:56.088027 15772 sgd_solver.cpp:105] Iteration 86200, lr = 0.01
I1210 16:49:01.852761 15772 solver.cpp:218] Iteration 86300 (17.3472 iter/s, 5.76463s/100 iters), loss = 0.861506
I1210 16:49:01.852761 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:49:01.852761 15772 solver.cpp:237]     Train net output #1: loss = 0.861506 (* 1 = 0.861506 loss)
I1210 16:49:01.852761 15772 sgd_solver.cpp:105] Iteration 86300, lr = 0.01
I1210 16:49:07.609405 15772 solver.cpp:218] Iteration 86400 (17.3733 iter/s, 5.75595s/100 iters), loss = 0.968438
I1210 16:49:07.609405 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 16:49:07.609405 15772 solver.cpp:237]     Train net output #1: loss = 0.968438 (* 1 = 0.968438 loss)
I1210 16:49:07.609405 15772 sgd_solver.cpp:105] Iteration 86400, lr = 0.01
I1210 16:49:13.179438 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:49:13.402458 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_86500.caffemodel
I1210 16:49:13.416465 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_86500.solverstate
I1210 16:49:13.421465 15772 solver.cpp:330] Iteration 86500, Testing net (#0)
I1210 16:49:13.421465 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:49:14.796648 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:49:14.851660 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6083
I1210 16:49:14.851660 15772 solver.cpp:397]     Test net output #1: loss = 1.49935 (* 1 = 1.49935 loss)
I1210 16:49:14.905659 15772 solver.cpp:218] Iteration 86500 (13.7068 iter/s, 7.29567s/100 iters), loss = 0.548215
I1210 16:49:14.905659 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 16:49:14.905659 15772 solver.cpp:237]     Train net output #1: loss = 0.548215 (* 1 = 0.548215 loss)
I1210 16:49:14.905659 15772 sgd_solver.cpp:105] Iteration 86500, lr = 0.01
I1210 16:49:20.576306 15772 solver.cpp:218] Iteration 86600 (17.6358 iter/s, 5.67027s/100 iters), loss = 0.652318
I1210 16:49:20.576306 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:49:20.576306 15772 solver.cpp:237]     Train net output #1: loss = 0.652318 (* 1 = 0.652318 loss)
I1210 16:49:20.576306 15772 sgd_solver.cpp:105] Iteration 86600, lr = 0.01
I1210 16:49:26.229851 15772 solver.cpp:218] Iteration 86700 (17.6877 iter/s, 5.65365s/100 iters), loss = 0.608621
I1210 16:49:26.229851 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:49:26.230852 15772 solver.cpp:237]     Train net output #1: loss = 0.608621 (* 1 = 0.608621 loss)
I1210 16:49:26.230852 15772 sgd_solver.cpp:105] Iteration 86700, lr = 0.01
I1210 16:49:32.006469 15772 solver.cpp:218] Iteration 86800 (17.3134 iter/s, 5.77588s/100 iters), loss = 0.72271
I1210 16:49:32.006469 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:49:32.006469 15772 solver.cpp:237]     Train net output #1: loss = 0.72271 (* 1 = 0.72271 loss)
I1210 16:49:32.006469 15772 sgd_solver.cpp:105] Iteration 86800, lr = 0.01
I1210 16:49:37.668395 15772 solver.cpp:218] Iteration 86900 (17.6644 iter/s, 5.6611s/100 iters), loss = 0.814759
I1210 16:49:37.668395 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:49:37.668395 15772 solver.cpp:237]     Train net output #1: loss = 0.814758 (* 1 = 0.814758 loss)
I1210 16:49:37.668395 15772 sgd_solver.cpp:105] Iteration 86900, lr = 0.01
I1210 16:49:43.120165 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:49:43.340173 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_87000.caffemodel
I1210 16:49:43.354172 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_87000.solverstate
I1210 16:49:43.385206 15772 solver.cpp:330] Iteration 87000, Testing net (#0)
I1210 16:49:43.385206 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:49:44.752317 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:49:44.806325 15772 solver.cpp:397]     Test net output #0: accuracy = 0.598
I1210 16:49:44.806325 15772 solver.cpp:397]     Test net output #1: loss = 1.52614 (* 1 = 1.52614 loss)
I1210 16:49:44.859324 15772 solver.cpp:218] Iteration 87000 (13.9062 iter/s, 7.19102s/100 iters), loss = 0.640883
I1210 16:49:44.860327 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:49:44.860327 15772 solver.cpp:237]     Train net output #1: loss = 0.640883 (* 1 = 0.640883 loss)
I1210 16:49:44.860327 15772 sgd_solver.cpp:105] Iteration 87000, lr = 0.01
I1210 16:49:50.498785 15772 solver.cpp:218] Iteration 87100 (17.7364 iter/s, 5.63813s/100 iters), loss = 0.838785
I1210 16:49:50.498785 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:49:50.498785 15772 solver.cpp:237]     Train net output #1: loss = 0.838785 (* 1 = 0.838785 loss)
I1210 16:49:50.498785 15772 sgd_solver.cpp:105] Iteration 87100, lr = 0.01
I1210 16:49:56.133266 15772 solver.cpp:218] Iteration 87200 (17.7466 iter/s, 5.63488s/100 iters), loss = 0.594679
I1210 16:49:56.133266 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:49:56.134268 15772 solver.cpp:237]     Train net output #1: loss = 0.594679 (* 1 = 0.594679 loss)
I1210 16:49:56.134268 15772 sgd_solver.cpp:105] Iteration 87200, lr = 0.01
I1210 16:50:01.849797 15772 solver.cpp:218] Iteration 87300 (17.4951 iter/s, 5.71588s/100 iters), loss = 0.79373
I1210 16:50:01.849797 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:50:01.849797 15772 solver.cpp:237]     Train net output #1: loss = 0.79373 (* 1 = 0.79373 loss)
I1210 16:50:01.849797 15772 sgd_solver.cpp:105] Iteration 87300, lr = 0.01
I1210 16:50:07.520618 15772 solver.cpp:218] Iteration 87400 (17.6362 iter/s, 5.67015s/100 iters), loss = 0.812905
I1210 16:50:07.520618 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:50:07.520618 15772 solver.cpp:237]     Train net output #1: loss = 0.812905 (* 1 = 0.812905 loss)
I1210 16:50:07.520618 15772 sgd_solver.cpp:105] Iteration 87400, lr = 0.01
I1210 16:50:12.927337 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:50:13.151353 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_87500.caffemodel
I1210 16:50:13.166858 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_87500.solverstate
I1210 16:50:13.171360 15772 solver.cpp:330] Iteration 87500, Testing net (#0)
I1210 16:50:13.171360 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:50:14.555477 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:50:14.610473 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5703
I1210 16:50:14.610473 15772 solver.cpp:397]     Test net output #1: loss = 1.70371 (* 1 = 1.70371 loss)
I1210 16:50:14.663471 15772 solver.cpp:218] Iteration 87500 (14.0003 iter/s, 7.14269s/100 iters), loss = 0.650393
I1210 16:50:14.664472 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:50:14.664472 15772 solver.cpp:237]     Train net output #1: loss = 0.650393 (* 1 = 0.650393 loss)
I1210 16:50:14.664472 15772 sgd_solver.cpp:105] Iteration 87500, lr = 0.01
I1210 16:50:20.329969 15772 solver.cpp:218] Iteration 87600 (17.6497 iter/s, 5.66581s/100 iters), loss = 0.587327
I1210 16:50:20.329969 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:50:20.329969 15772 solver.cpp:237]     Train net output #1: loss = 0.587327 (* 1 = 0.587327 loss)
I1210 16:50:20.329969 15772 sgd_solver.cpp:105] Iteration 87600, lr = 0.01
I1210 16:50:25.982424 15772 solver.cpp:218] Iteration 87700 (17.6952 iter/s, 5.65126s/100 iters), loss = 0.509519
I1210 16:50:25.982424 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:50:25.982424 15772 solver.cpp:237]     Train net output #1: loss = 0.509519 (* 1 = 0.509519 loss)
I1210 16:50:25.982424 15772 sgd_solver.cpp:105] Iteration 87700, lr = 0.01
I1210 16:50:31.641885 15772 solver.cpp:218] Iteration 87800 (17.6701 iter/s, 5.65929s/100 iters), loss = 0.744454
I1210 16:50:31.641885 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:50:31.641885 15772 solver.cpp:237]     Train net output #1: loss = 0.744454 (* 1 = 0.744454 loss)
I1210 16:50:31.641885 15772 sgd_solver.cpp:105] Iteration 87800, lr = 0.01
I1210 16:50:37.287319 15772 solver.cpp:218] Iteration 87900 (17.7152 iter/s, 5.64486s/100 iters), loss = 0.716128
I1210 16:50:37.287319 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:50:37.287319 15772 solver.cpp:237]     Train net output #1: loss = 0.716127 (* 1 = 0.716127 loss)
I1210 16:50:37.287319 15772 sgd_solver.cpp:105] Iteration 87900, lr = 0.01
I1210 16:50:42.720701 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:50:42.945714 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_88000.caffemodel
I1210 16:50:42.960716 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_88000.solverstate
I1210 16:50:42.984737 15772 solver.cpp:330] Iteration 88000, Testing net (#0)
I1210 16:50:42.985736 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:50:44.377838 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:50:44.431838 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5678
I1210 16:50:44.431838 15772 solver.cpp:397]     Test net output #1: loss = 1.69878 (* 1 = 1.69878 loss)
I1210 16:50:44.486845 15772 solver.cpp:218] Iteration 88000 (13.8898 iter/s, 7.19954s/100 iters), loss = 0.670997
I1210 16:50:44.486845 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:50:44.486845 15772 solver.cpp:237]     Train net output #1: loss = 0.670997 (* 1 = 0.670997 loss)
I1210 16:50:44.486845 15772 sgd_solver.cpp:105] Iteration 88000, lr = 0.01
I1210 16:50:50.180258 15772 solver.cpp:218] Iteration 88100 (17.5669 iter/s, 5.69253s/100 iters), loss = 0.664096
I1210 16:50:50.180258 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:50:50.180258 15772 solver.cpp:237]     Train net output #1: loss = 0.664096 (* 1 = 0.664096 loss)
I1210 16:50:50.180258 15772 sgd_solver.cpp:105] Iteration 88100, lr = 0.01
I1210 16:50:55.842664 15772 solver.cpp:218] Iteration 88200 (17.6607 iter/s, 5.66229s/100 iters), loss = 0.510951
I1210 16:50:55.842664 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:50:55.842664 15772 solver.cpp:237]     Train net output #1: loss = 0.510951 (* 1 = 0.510951 loss)
I1210 16:50:55.842664 15772 sgd_solver.cpp:105] Iteration 88200, lr = 0.01
I1210 16:51:01.581584 15772 solver.cpp:218] Iteration 88300 (17.427 iter/s, 5.73822s/100 iters), loss = 0.853314
I1210 16:51:01.581584 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:51:01.582085 15772 solver.cpp:237]     Train net output #1: loss = 0.853314 (* 1 = 0.853314 loss)
I1210 16:51:01.582085 15772 sgd_solver.cpp:105] Iteration 88300, lr = 0.01
I1210 16:51:07.256587 15772 solver.cpp:218] Iteration 88400 (17.6219 iter/s, 5.67477s/100 iters), loss = 0.839366
I1210 16:51:07.256587 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:51:07.256587 15772 solver.cpp:237]     Train net output #1: loss = 0.839366 (* 1 = 0.839366 loss)
I1210 16:51:07.256587 15772 sgd_solver.cpp:105] Iteration 88400, lr = 0.01
I1210 16:51:12.629034 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:51:12.850046 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_88500.caffemodel
I1210 16:51:12.864047 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_88500.solverstate
I1210 16:51:12.885051 15772 solver.cpp:330] Iteration 88500, Testing net (#0)
I1210 16:51:12.885051 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:51:14.260196 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:51:14.313205 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6152
I1210 16:51:14.313205 15772 solver.cpp:397]     Test net output #1: loss = 1.49961 (* 1 = 1.49961 loss)
I1210 16:51:14.366204 15772 solver.cpp:218] Iteration 88500 (14.0663 iter/s, 7.10918s/100 iters), loss = 0.675117
I1210 16:51:14.366204 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:51:14.366204 15772 solver.cpp:237]     Train net output #1: loss = 0.675117 (* 1 = 0.675117 loss)
I1210 16:51:14.366204 15772 sgd_solver.cpp:105] Iteration 88500, lr = 0.01
I1210 16:51:20.020686 15772 solver.cpp:218] Iteration 88600 (17.6882 iter/s, 5.65348s/100 iters), loss = 0.607752
I1210 16:51:20.020686 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:51:20.020686 15772 solver.cpp:237]     Train net output #1: loss = 0.607752 (* 1 = 0.607752 loss)
I1210 16:51:20.020686 15772 sgd_solver.cpp:105] Iteration 88600, lr = 0.01
I1210 16:51:25.651156 15772 solver.cpp:218] Iteration 88700 (17.7605 iter/s, 5.63046s/100 iters), loss = 0.520173
I1210 16:51:25.651156 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:51:25.651156 15772 solver.cpp:237]     Train net output #1: loss = 0.520173 (* 1 = 0.520173 loss)
I1210 16:51:25.651156 15772 sgd_solver.cpp:105] Iteration 88700, lr = 0.01
I1210 16:51:31.302964 15772 solver.cpp:218] Iteration 88800 (17.6954 iter/s, 5.65119s/100 iters), loss = 0.809219
I1210 16:51:31.302964 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:51:31.302964 15772 solver.cpp:237]     Train net output #1: loss = 0.809219 (* 1 = 0.809219 loss)
I1210 16:51:31.302964 15772 sgd_solver.cpp:105] Iteration 88800, lr = 0.01
I1210 16:51:36.954394 15772 solver.cpp:218] Iteration 88900 (17.6963 iter/s, 5.6509s/100 iters), loss = 0.661513
I1210 16:51:36.954394 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:51:36.954394 15772 solver.cpp:237]     Train net output #1: loss = 0.661513 (* 1 = 0.661513 loss)
I1210 16:51:36.954394 15772 sgd_solver.cpp:105] Iteration 88900, lr = 0.01
I1210 16:51:42.334844 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:51:42.554855 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_89000.caffemodel
I1210 16:51:42.571856 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_89000.solverstate
I1210 16:51:42.576362 15772 solver.cpp:330] Iteration 89000, Testing net (#0)
I1210 16:51:42.576863 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:51:43.955968 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:51:44.008972 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6183
I1210 16:51:44.008972 15772 solver.cpp:397]     Test net output #1: loss = 1.45079 (* 1 = 1.45079 loss)
I1210 16:51:44.062975 15772 solver.cpp:218] Iteration 89000 (14.0678 iter/s, 7.10842s/100 iters), loss = 0.664835
I1210 16:51:44.062975 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:51:44.062975 15772 solver.cpp:237]     Train net output #1: loss = 0.664834 (* 1 = 0.664834 loss)
I1210 16:51:44.062975 15772 sgd_solver.cpp:105] Iteration 89000, lr = 0.01
I1210 16:51:49.792421 15772 solver.cpp:218] Iteration 89100 (17.4558 iter/s, 5.72877s/100 iters), loss = 0.786161
I1210 16:51:49.792421 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:51:49.792421 15772 solver.cpp:237]     Train net output #1: loss = 0.786161 (* 1 = 0.786161 loss)
I1210 16:51:49.792421 15772 sgd_solver.cpp:105] Iteration 89100, lr = 0.01
I1210 16:51:55.504185 15772 solver.cpp:218] Iteration 89200 (17.5095 iter/s, 5.71118s/100 iters), loss = 0.634043
I1210 16:51:55.504185 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:51:55.504185 15772 solver.cpp:237]     Train net output #1: loss = 0.634043 (* 1 = 0.634043 loss)
I1210 16:51:55.504185 15772 sgd_solver.cpp:105] Iteration 89200, lr = 0.01
I1210 16:52:01.179698 15772 solver.cpp:218] Iteration 89300 (17.6214 iter/s, 5.67492s/100 iters), loss = 0.778842
I1210 16:52:01.179698 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:52:01.180199 15772 solver.cpp:237]     Train net output #1: loss = 0.778842 (* 1 = 0.778842 loss)
I1210 16:52:01.180199 15772 sgd_solver.cpp:105] Iteration 89300, lr = 0.01
I1210 16:52:06.847198 15772 solver.cpp:218] Iteration 89400 (17.6463 iter/s, 5.66692s/100 iters), loss = 0.915158
I1210 16:52:06.847198 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:52:06.847198 15772 solver.cpp:237]     Train net output #1: loss = 0.915158 (* 1 = 0.915158 loss)
I1210 16:52:06.847198 15772 sgd_solver.cpp:105] Iteration 89400, lr = 0.01
I1210 16:52:12.233664 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:52:12.456676 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_89500.caffemodel
I1210 16:52:12.471674 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_89500.solverstate
I1210 16:52:12.501706 15772 solver.cpp:330] Iteration 89500, Testing net (#0)
I1210 16:52:12.501706 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:52:13.876837 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:52:13.930841 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5933
I1210 16:52:13.930841 15772 solver.cpp:397]     Test net output #1: loss = 1.62513 (* 1 = 1.62513 loss)
I1210 16:52:13.984349 15772 solver.cpp:218] Iteration 89500 (14.0123 iter/s, 7.1366s/100 iters), loss = 0.590379
I1210 16:52:13.984349 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:52:13.984349 15772 solver.cpp:237]     Train net output #1: loss = 0.590379 (* 1 = 0.590379 loss)
I1210 16:52:13.984349 15772 sgd_solver.cpp:105] Iteration 89500, lr = 0.01
I1210 16:52:19.636286 15772 solver.cpp:218] Iteration 89600 (17.6947 iter/s, 5.65139s/100 iters), loss = 0.535805
I1210 16:52:19.636286 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:52:19.636286 15772 solver.cpp:237]     Train net output #1: loss = 0.535805 (* 1 = 0.535805 loss)
I1210 16:52:19.636286 15772 sgd_solver.cpp:105] Iteration 89600, lr = 0.01
I1210 16:52:25.287008 15772 solver.cpp:218] Iteration 89700 (17.698 iter/s, 5.65036s/100 iters), loss = 0.59479
I1210 16:52:25.287008 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:52:25.287008 15772 solver.cpp:237]     Train net output #1: loss = 0.594789 (* 1 = 0.594789 loss)
I1210 16:52:25.287008 15772 sgd_solver.cpp:105] Iteration 89700, lr = 0.01
I1210 16:52:30.943390 15772 solver.cpp:218] Iteration 89800 (17.6805 iter/s, 5.65596s/100 iters), loss = 0.931557
I1210 16:52:30.943390 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:52:30.943390 15772 solver.cpp:237]     Train net output #1: loss = 0.931557 (* 1 = 0.931557 loss)
I1210 16:52:30.943390 15772 sgd_solver.cpp:105] Iteration 89800, lr = 0.01
I1210 16:52:36.689862 15772 solver.cpp:218] Iteration 89900 (17.4029 iter/s, 5.74616s/100 iters), loss = 0.750879
I1210 16:52:36.690353 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:52:36.690353 15772 solver.cpp:237]     Train net output #1: loss = 0.750879 (* 1 = 0.750879 loss)
I1210 16:52:36.690353 15772 sgd_solver.cpp:105] Iteration 89900, lr = 0.01
I1210 16:52:42.128324 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:52:42.358518 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90000.caffemodel
I1210 16:52:42.373518 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90000.solverstate
I1210 16:52:42.378518 15772 solver.cpp:330] Iteration 90000, Testing net (#0)
I1210 16:52:42.378518 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:52:43.757858 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:52:43.811774 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5732
I1210 16:52:43.811774 15772 solver.cpp:397]     Test net output #1: loss = 1.65759 (* 1 = 1.65759 loss)
I1210 16:52:43.864789 15772 solver.cpp:218] Iteration 90000 (13.9377 iter/s, 7.1748s/100 iters), loss = 0.600026
I1210 16:52:43.864789 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:52:43.864789 15772 solver.cpp:237]     Train net output #1: loss = 0.600026 (* 1 = 0.600026 loss)
I1210 16:52:43.864789 15772 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1210 16:52:49.505712 15772 solver.cpp:218] Iteration 90100 (17.7301 iter/s, 5.64012s/100 iters), loss = 0.787467
I1210 16:52:49.506211 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:52:49.506211 15772 solver.cpp:237]     Train net output #1: loss = 0.787467 (* 1 = 0.787467 loss)
I1210 16:52:49.506211 15772 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1210 16:52:55.146293 15772 solver.cpp:218] Iteration 90200 (17.7301 iter/s, 5.64012s/100 iters), loss = 0.525961
I1210 16:52:55.146293 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:52:55.146293 15772 solver.cpp:237]     Train net output #1: loss = 0.525961 (* 1 = 0.525961 loss)
I1210 16:52:55.146293 15772 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1210 16:53:00.780871 15772 solver.cpp:218] Iteration 90300 (17.7494 iter/s, 5.63398s/100 iters), loss = 0.772026
I1210 16:53:00.780871 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 16:53:00.780871 15772 solver.cpp:237]     Train net output #1: loss = 0.772026 (* 1 = 0.772026 loss)
I1210 16:53:00.780871 15772 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1210 16:53:06.421291 15772 solver.cpp:218] Iteration 90400 (17.729 iter/s, 5.64047s/100 iters), loss = 0.794478
I1210 16:53:06.421291 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:53:06.421291 15772 solver.cpp:237]     Train net output #1: loss = 0.794478 (* 1 = 0.794478 loss)
I1210 16:53:06.421291 15772 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1210 16:53:11.844523 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:53:12.072551 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90500.caffemodel
I1210 16:53:12.087550 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90500.solverstate
I1210 16:53:12.118566 15772 solver.cpp:330] Iteration 90500, Testing net (#0)
I1210 16:53:12.118566 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:53:13.520985 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:53:13.574986 15772 solver.cpp:397]     Test net output #0: accuracy = 0.556
I1210 16:53:13.574986 15772 solver.cpp:397]     Test net output #1: loss = 1.80057 (* 1 = 1.80057 loss)
I1210 16:53:13.628007 15772 solver.cpp:218] Iteration 90500 (13.8773 iter/s, 7.20603s/100 iters), loss = 0.560771
I1210 16:53:13.628007 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:53:13.628007 15772 solver.cpp:237]     Train net output #1: loss = 0.56077 (* 1 = 0.56077 loss)
I1210 16:53:13.628007 15772 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1210 16:53:19.284797 15772 solver.cpp:218] Iteration 90600 (17.6791 iter/s, 5.65641s/100 iters), loss = 0.775828
I1210 16:53:19.284797 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:53:19.284797 15772 solver.cpp:237]     Train net output #1: loss = 0.775828 (* 1 = 0.775828 loss)
I1210 16:53:19.284797 15772 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1210 16:53:24.932742 15772 solver.cpp:218] Iteration 90700 (17.7086 iter/s, 5.64697s/100 iters), loss = 0.645944
I1210 16:53:24.932742 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:53:24.932742 15772 solver.cpp:237]     Train net output #1: loss = 0.645944 (* 1 = 0.645944 loss)
I1210 16:53:24.932742 15772 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1210 16:53:30.574651 15772 solver.cpp:218] Iteration 90800 (17.7259 iter/s, 5.64145s/100 iters), loss = 0.744127
I1210 16:53:30.574651 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:53:30.574651 15772 solver.cpp:237]     Train net output #1: loss = 0.744127 (* 1 = 0.744127 loss)
I1210 16:53:30.574651 15772 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1210 16:53:36.209498 15772 solver.cpp:218] Iteration 90900 (17.7479 iter/s, 5.63446s/100 iters), loss = 0.922806
I1210 16:53:36.210000 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 16:53:36.210000 15772 solver.cpp:237]     Train net output #1: loss = 0.922805 (* 1 = 0.922805 loss)
I1210 16:53:36.210000 15772 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1210 16:53:41.575316 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:53:41.796839 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91000.caffemodel
I1210 16:53:41.812839 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91000.solverstate
I1210 16:53:41.816839 15772 solver.cpp:330] Iteration 91000, Testing net (#0)
I1210 16:53:41.816839 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:53:43.185515 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:53:43.238653 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5864
I1210 16:53:43.238653 15772 solver.cpp:397]     Test net output #1: loss = 1.6191 (* 1 = 1.6191 loss)
I1210 16:53:43.294157 15772 solver.cpp:218] Iteration 91000 (14.1166 iter/s, 7.08385s/100 iters), loss = 0.623765
I1210 16:53:43.294157 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:53:43.294157 15772 solver.cpp:237]     Train net output #1: loss = 0.623765 (* 1 = 0.623765 loss)
I1210 16:53:43.294157 15772 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1210 16:53:48.929774 15772 solver.cpp:218] Iteration 91100 (17.7454 iter/s, 5.63525s/100 iters), loss = 0.634924
I1210 16:53:48.929774 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:53:48.929774 15772 solver.cpp:237]     Train net output #1: loss = 0.634924 (* 1 = 0.634924 loss)
I1210 16:53:48.929774 15772 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1210 16:53:54.579545 15772 solver.cpp:218] Iteration 91200 (17.7027 iter/s, 5.64887s/100 iters), loss = 0.647351
I1210 16:53:54.579545 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:53:54.579545 15772 solver.cpp:237]     Train net output #1: loss = 0.64735 (* 1 = 0.64735 loss)
I1210 16:53:54.579545 15772 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1210 16:54:00.235270 15772 solver.cpp:218] Iteration 91300 (17.6811 iter/s, 5.65577s/100 iters), loss = 0.71699
I1210 16:54:00.235270 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:54:00.235270 15772 solver.cpp:237]     Train net output #1: loss = 0.71699 (* 1 = 0.71699 loss)
I1210 16:54:00.235270 15772 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1210 16:54:05.868583 15772 solver.cpp:218] Iteration 91400 (17.7548 iter/s, 5.63228s/100 iters), loss = 0.86769
I1210 16:54:05.868583 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:54:05.868583 15772 solver.cpp:237]     Train net output #1: loss = 0.86769 (* 1 = 0.86769 loss)
I1210 16:54:05.868583 15772 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1210 16:54:11.271814 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:54:11.495340 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91500.caffemodel
I1210 16:54:11.526340 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91500.solverstate
I1210 16:54:11.531340 15772 solver.cpp:330] Iteration 91500, Testing net (#0)
I1210 16:54:11.531340 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:54:12.916447 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:54:12.970448 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5794
I1210 16:54:12.970448 15772 solver.cpp:397]     Test net output #1: loss = 1.67326 (* 1 = 1.67326 loss)
I1210 16:54:13.024459 15772 solver.cpp:218] Iteration 91500 (13.9752 iter/s, 7.15553s/100 iters), loss = 0.608169
I1210 16:54:13.024459 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:54:13.024459 15772 solver.cpp:237]     Train net output #1: loss = 0.608169 (* 1 = 0.608169 loss)
I1210 16:54:13.024459 15772 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1210 16:54:18.693809 15772 solver.cpp:218] Iteration 91600 (17.6388 iter/s, 5.66931s/100 iters), loss = 0.80588
I1210 16:54:18.693809 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:54:18.693809 15772 solver.cpp:237]     Train net output #1: loss = 0.80588 (* 1 = 0.80588 loss)
I1210 16:54:18.693809 15772 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1210 16:54:24.335364 15772 solver.cpp:218] Iteration 91700 (17.7284 iter/s, 5.64067s/100 iters), loss = 0.562573
I1210 16:54:24.335364 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:54:24.335364 15772 solver.cpp:237]     Train net output #1: loss = 0.562573 (* 1 = 0.562573 loss)
I1210 16:54:24.335364 15772 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1210 16:54:29.960407 15772 solver.cpp:218] Iteration 91800 (17.78 iter/s, 5.62429s/100 iters), loss = 0.681283
I1210 16:54:29.960407 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:54:29.960407 15772 solver.cpp:237]     Train net output #1: loss = 0.681283 (* 1 = 0.681283 loss)
I1210 16:54:29.960407 15772 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1210 16:54:35.587868 15772 solver.cpp:218] Iteration 91900 (17.7703 iter/s, 5.62735s/100 iters), loss = 0.789706
I1210 16:54:35.587868 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:54:35.588369 15772 solver.cpp:237]     Train net output #1: loss = 0.789706 (* 1 = 0.789706 loss)
I1210 16:54:35.588369 15772 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1210 16:54:40.937320 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:54:41.159332 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92000.caffemodel
I1210 16:54:41.172333 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92000.solverstate
I1210 16:54:41.177846 15772 solver.cpp:330] Iteration 92000, Testing net (#0)
I1210 16:54:41.177846 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:54:42.546470 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:54:42.601480 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5656
I1210 16:54:42.601480 15772 solver.cpp:397]     Test net output #1: loss = 1.75187 (* 1 = 1.75187 loss)
I1210 16:54:42.655480 15772 solver.cpp:218] Iteration 92000 (14.1508 iter/s, 7.06673s/100 iters), loss = 0.543427
I1210 16:54:42.655480 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:54:42.655480 15772 solver.cpp:237]     Train net output #1: loss = 0.543427 (* 1 = 0.543427 loss)
I1210 16:54:42.655480 15772 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1210 16:54:48.289382 15772 solver.cpp:218] Iteration 92100 (17.7495 iter/s, 5.63395s/100 iters), loss = 0.748624
I1210 16:54:48.289882 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:54:48.289882 15772 solver.cpp:237]     Train net output #1: loss = 0.748624 (* 1 = 0.748624 loss)
I1210 16:54:48.289882 15772 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1210 16:54:53.924332 15772 solver.cpp:218] Iteration 92200 (17.7471 iter/s, 5.63472s/100 iters), loss = 0.664742
I1210 16:54:53.924332 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:54:53.924332 15772 solver.cpp:237]     Train net output #1: loss = 0.664742 (* 1 = 0.664742 loss)
I1210 16:54:53.924332 15772 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1210 16:54:59.552651 15772 solver.cpp:218] Iteration 92300 (17.7681 iter/s, 5.62807s/100 iters), loss = 0.722742
I1210 16:54:59.552651 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:54:59.552651 15772 solver.cpp:237]     Train net output #1: loss = 0.722742 (* 1 = 0.722742 loss)
I1210 16:54:59.552651 15772 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1210 16:55:05.186513 15772 solver.cpp:218] Iteration 92400 (17.7525 iter/s, 5.633s/100 iters), loss = 0.831063
I1210 16:55:05.187014 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 16:55:05.187014 15772 solver.cpp:237]     Train net output #1: loss = 0.831063 (* 1 = 0.831063 loss)
I1210 16:55:05.187014 15772 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1210 16:55:10.533905 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:55:10.755920 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92500.caffemodel
I1210 16:55:10.799940 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92500.solverstate
I1210 16:55:10.803939 15772 solver.cpp:330] Iteration 92500, Testing net (#0)
I1210 16:55:10.804941 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:55:12.171016 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:55:12.226023 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5774
I1210 16:55:12.226023 15772 solver.cpp:397]     Test net output #1: loss = 1.65213 (* 1 = 1.65213 loss)
I1210 16:55:12.280021 15772 solver.cpp:218] Iteration 92500 (14.0992 iter/s, 7.0926s/100 iters), loss = 0.589251
I1210 16:55:12.280021 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:55:12.280021 15772 solver.cpp:237]     Train net output #1: loss = 0.589251 (* 1 = 0.589251 loss)
I1210 16:55:12.280021 15772 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1210 16:55:17.924474 15772 solver.cpp:218] Iteration 92600 (17.7171 iter/s, 5.64425s/100 iters), loss = 0.719635
I1210 16:55:17.924474 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:55:17.924474 15772 solver.cpp:237]     Train net output #1: loss = 0.719634 (* 1 = 0.719634 loss)
I1210 16:55:17.924474 15772 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1210 16:55:23.569926 15772 solver.cpp:218] Iteration 92700 (17.7144 iter/s, 5.64514s/100 iters), loss = 0.719215
I1210 16:55:23.569926 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:55:23.569926 15772 solver.cpp:237]     Train net output #1: loss = 0.719215 (* 1 = 0.719215 loss)
I1210 16:55:23.569926 15772 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1210 16:55:29.212725 15772 solver.cpp:218] Iteration 92800 (17.723 iter/s, 5.64239s/100 iters), loss = 0.863381
I1210 16:55:29.212725 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:55:29.212725 15772 solver.cpp:237]     Train net output #1: loss = 0.863381 (* 1 = 0.863381 loss)
I1210 16:55:29.212725 15772 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1210 16:55:34.850145 15772 solver.cpp:218] Iteration 92900 (17.7399 iter/s, 5.637s/100 iters), loss = 0.853935
I1210 16:55:34.850145 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:55:34.850145 15772 solver.cpp:237]     Train net output #1: loss = 0.853935 (* 1 = 0.853935 loss)
I1210 16:55:34.850145 15772 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1210 16:55:40.205586 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:55:40.427609 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93000.caffemodel
I1210 16:55:40.441609 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93000.solverstate
I1210 16:55:40.446610 15772 solver.cpp:330] Iteration 93000, Testing net (#0)
I1210 16:55:40.446610 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:55:41.810720 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:55:41.864719 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5795
I1210 16:55:41.864719 15772 solver.cpp:397]     Test net output #1: loss = 1.6586 (* 1 = 1.6586 loss)
I1210 16:55:41.920727 15772 solver.cpp:218] Iteration 93000 (14.1449 iter/s, 7.06966s/100 iters), loss = 0.571584
I1210 16:55:41.920727 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:55:41.920727 15772 solver.cpp:237]     Train net output #1: loss = 0.571584 (* 1 = 0.571584 loss)
I1210 16:55:41.920727 15772 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1210 16:55:47.553128 15772 solver.cpp:218] Iteration 93100 (17.7548 iter/s, 5.63229s/100 iters), loss = 0.581463
I1210 16:55:47.553128 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:55:47.553128 15772 solver.cpp:237]     Train net output #1: loss = 0.581463 (* 1 = 0.581463 loss)
I1210 16:55:47.553128 15772 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1210 16:55:53.190563 15772 solver.cpp:218] Iteration 93200 (17.7401 iter/s, 5.63695s/100 iters), loss = 0.520447
I1210 16:55:53.190563 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:55:53.190563 15772 solver.cpp:237]     Train net output #1: loss = 0.520447 (* 1 = 0.520447 loss)
I1210 16:55:53.190563 15772 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1210 16:55:58.829960 15772 solver.cpp:218] Iteration 93300 (17.7348 iter/s, 5.63863s/100 iters), loss = 0.955253
I1210 16:55:58.829960 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 16:55:58.829960 15772 solver.cpp:237]     Train net output #1: loss = 0.955253 (* 1 = 0.955253 loss)
I1210 16:55:58.829960 15772 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1210 16:56:04.473362 15772 solver.cpp:218] Iteration 93400 (17.7199 iter/s, 5.64336s/100 iters), loss = 0.89337
I1210 16:56:04.473362 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 16:56:04.473362 15772 solver.cpp:237]     Train net output #1: loss = 0.89337 (* 1 = 0.89337 loss)
I1210 16:56:04.473362 15772 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1210 16:56:09.839793 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:56:10.062805 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93500.caffemodel
I1210 16:56:10.101332 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93500.solverstate
I1210 16:56:10.105831 15772 solver.cpp:330] Iteration 93500, Testing net (#0)
I1210 16:56:10.105831 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:56:11.470944 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:56:11.523948 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6055
I1210 16:56:11.524950 15772 solver.cpp:397]     Test net output #1: loss = 1.51066 (* 1 = 1.51066 loss)
I1210 16:56:11.578948 15772 solver.cpp:218] Iteration 93500 (14.0738 iter/s, 7.10541s/100 iters), loss = 0.517545
I1210 16:56:11.578948 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 16:56:11.578948 15772 solver.cpp:237]     Train net output #1: loss = 0.517544 (* 1 = 0.517544 loss)
I1210 16:56:11.578948 15772 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1210 16:56:17.193327 15772 solver.cpp:218] Iteration 93600 (17.8144 iter/s, 5.61343s/100 iters), loss = 0.701851
I1210 16:56:17.193327 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 16:56:17.193327 15772 solver.cpp:237]     Train net output #1: loss = 0.701851 (* 1 = 0.701851 loss)
I1210 16:56:17.193327 15772 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1210 16:56:22.811745 15772 solver.cpp:218] Iteration 93700 (17.7996 iter/s, 5.6181s/100 iters), loss = 0.589951
I1210 16:56:22.811745 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:56:22.811745 15772 solver.cpp:237]     Train net output #1: loss = 0.589951 (* 1 = 0.589951 loss)
I1210 16:56:22.811745 15772 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1210 16:56:28.440143 15772 solver.cpp:218] Iteration 93800 (17.7686 iter/s, 5.62789s/100 iters), loss = 0.753948
I1210 16:56:28.440143 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:56:28.440143 15772 solver.cpp:237]     Train net output #1: loss = 0.753948 (* 1 = 0.753948 loss)
I1210 16:56:28.440143 15772 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1210 16:56:34.069595 15772 solver.cpp:218] Iteration 93900 (17.766 iter/s, 5.62872s/100 iters), loss = 0.759504
I1210 16:56:34.069595 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 16:56:34.069595 15772 solver.cpp:237]     Train net output #1: loss = 0.759504 (* 1 = 0.759504 loss)
I1210 16:56:34.069595 15772 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1210 16:56:39.416059 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:56:39.637071 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94000.caffemodel
I1210 16:56:39.655071 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94000.solverstate
I1210 16:56:39.661072 15772 solver.cpp:330] Iteration 94000, Testing net (#0)
I1210 16:56:39.661072 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:56:41.035501 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:56:41.090503 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5605
I1210 16:56:41.090503 15772 solver.cpp:397]     Test net output #1: loss = 1.78211 (* 1 = 1.78211 loss)
I1210 16:56:41.143504 15772 solver.cpp:218] Iteration 94000 (14.1368 iter/s, 7.07375s/100 iters), loss = 0.615981
I1210 16:56:41.143504 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:56:41.143504 15772 solver.cpp:237]     Train net output #1: loss = 0.615981 (* 1 = 0.615981 loss)
I1210 16:56:41.143504 15772 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1210 16:56:46.794960 15772 solver.cpp:218] Iteration 94100 (17.6972 iter/s, 5.6506s/100 iters), loss = 0.689096
I1210 16:56:46.794960 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 16:56:46.794960 15772 solver.cpp:237]     Train net output #1: loss = 0.689095 (* 1 = 0.689095 loss)
I1210 16:56:46.794960 15772 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1210 16:56:52.450382 15772 solver.cpp:218] Iteration 94200 (17.6813 iter/s, 5.6557s/100 iters), loss = 0.51674
I1210 16:56:52.450382 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:56:52.450382 15772 solver.cpp:237]     Train net output #1: loss = 0.51674 (* 1 = 0.51674 loss)
I1210 16:56:52.450382 15772 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1210 16:56:58.105257 15772 solver.cpp:218] Iteration 94300 (17.6876 iter/s, 5.65368s/100 iters), loss = 0.88814
I1210 16:56:58.105257 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 16:56:58.105257 15772 solver.cpp:237]     Train net output #1: loss = 0.888139 (* 1 = 0.888139 loss)
I1210 16:56:58.105257 15772 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1210 16:57:03.756187 15772 solver.cpp:218] Iteration 94400 (17.6946 iter/s, 5.65145s/100 iters), loss = 0.75948
I1210 16:57:03.757189 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 16:57:03.757189 15772 solver.cpp:237]     Train net output #1: loss = 0.75948 (* 1 = 0.75948 loss)
I1210 16:57:03.757189 15772 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1210 16:57:09.124758 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:57:09.349782 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94500.caffemodel
I1210 16:57:09.384781 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94500.solverstate
I1210 16:57:09.389782 15772 solver.cpp:330] Iteration 94500, Testing net (#0)
I1210 16:57:09.389782 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:57:10.758882 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:57:10.812887 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5383
I1210 16:57:10.812887 15772 solver.cpp:397]     Test net output #1: loss = 1.88178 (* 1 = 1.88178 loss)
I1210 16:57:10.865886 15772 solver.cpp:218] Iteration 94500 (14.0672 iter/s, 7.10871s/100 iters), loss = 0.605976
I1210 16:57:10.865886 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:57:10.865886 15772 solver.cpp:237]     Train net output #1: loss = 0.605976 (* 1 = 0.605976 loss)
I1210 16:57:10.865886 15772 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1210 16:57:16.503316 15772 solver.cpp:218] Iteration 94600 (17.7405 iter/s, 5.63683s/100 iters), loss = 0.684424
I1210 16:57:16.503808 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:57:16.503808 15772 solver.cpp:237]     Train net output #1: loss = 0.684424 (* 1 = 0.684424 loss)
I1210 16:57:16.503808 15772 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1210 16:57:22.131794 15772 solver.cpp:218] Iteration 94700 (17.7668 iter/s, 5.62846s/100 iters), loss = 0.527465
I1210 16:57:22.131794 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:57:22.131794 15772 solver.cpp:237]     Train net output #1: loss = 0.527465 (* 1 = 0.527465 loss)
I1210 16:57:22.131794 15772 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1210 16:57:27.767252 15772 solver.cpp:218] Iteration 94800 (17.7479 iter/s, 5.63446s/100 iters), loss = 0.840579
I1210 16:57:27.767252 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 16:57:27.767252 15772 solver.cpp:237]     Train net output #1: loss = 0.840579 (* 1 = 0.840579 loss)
I1210 16:57:27.767252 15772 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1210 16:57:33.406416 15772 solver.cpp:218] Iteration 94900 (17.7346 iter/s, 5.63871s/100 iters), loss = 0.794983
I1210 16:57:33.406416 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 16:57:33.406416 15772 solver.cpp:237]     Train net output #1: loss = 0.794983 (* 1 = 0.794983 loss)
I1210 16:57:33.406416 15772 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1210 16:57:38.759686 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:57:38.982734 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95000.caffemodel
I1210 16:57:38.996240 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95000.solverstate
I1210 16:57:39.001240 15772 solver.cpp:330] Iteration 95000, Testing net (#0)
I1210 16:57:39.001240 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:57:40.373818 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:57:40.427822 15772 solver.cpp:397]     Test net output #0: accuracy = 0.5817
I1210 16:57:40.427822 15772 solver.cpp:397]     Test net output #1: loss = 1.6364 (* 1 = 1.6364 loss)
I1210 16:57:40.480823 15772 solver.cpp:218] Iteration 95000 (14.1351 iter/s, 7.07456s/100 iters), loss = 0.559089
I1210 16:57:40.481822 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:57:40.481822 15772 solver.cpp:237]     Train net output #1: loss = 0.559089 (* 1 = 0.559089 loss)
I1210 16:57:40.481822 15772 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1210 16:57:40.481822 15772 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1210 16:57:46.121251 15772 solver.cpp:218] Iteration 95100 (17.731 iter/s, 5.63985s/100 iters), loss = 0.67625
I1210 16:57:46.121251 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 16:57:46.121251 15772 solver.cpp:237]     Train net output #1: loss = 0.676249 (* 1 = 0.676249 loss)
I1210 16:57:46.121251 15772 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1210 16:57:51.753659 15772 solver.cpp:218] Iteration 95200 (17.756 iter/s, 5.6319s/100 iters), loss = 0.461041
I1210 16:57:51.753659 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:57:51.753659 15772 solver.cpp:237]     Train net output #1: loss = 0.461041 (* 1 = 0.461041 loss)
I1210 16:57:51.753659 15772 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1210 16:57:57.389044 15772 solver.cpp:218] Iteration 95300 (17.7466 iter/s, 5.63488s/100 iters), loss = 0.691961
I1210 16:57:57.389044 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 16:57:57.389044 15772 solver.cpp:237]     Train net output #1: loss = 0.691961 (* 1 = 0.691961 loss)
I1210 16:57:57.389044 15772 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1210 16:58:03.029395 15772 solver.cpp:218] Iteration 95400 (17.7315 iter/s, 5.63967s/100 iters), loss = 0.586515
I1210 16:58:03.029395 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:58:03.029395 15772 solver.cpp:237]     Train net output #1: loss = 0.586515 (* 1 = 0.586515 loss)
I1210 16:58:03.029395 15772 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1210 16:58:08.394757 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:58:08.615780 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95500.caffemodel
I1210 16:58:08.641780 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95500.solverstate
I1210 16:58:08.653781 15772 solver.cpp:330] Iteration 95500, Testing net (#0)
I1210 16:58:08.653781 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:58:10.022884 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:58:10.075876 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6799
I1210 16:58:10.075876 15772 solver.cpp:397]     Test net output #1: loss = 1.1775 (* 1 = 1.1775 loss)
I1210 16:58:10.128882 15772 solver.cpp:218] Iteration 95500 (14.0859 iter/s, 7.09932s/100 iters), loss = 0.480427
I1210 16:58:10.128882 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 16:58:10.128882 15772 solver.cpp:237]     Train net output #1: loss = 0.480427 (* 1 = 0.480427 loss)
I1210 16:58:10.128882 15772 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1210 16:58:15.771304 15772 solver.cpp:218] Iteration 95600 (17.7242 iter/s, 5.64201s/100 iters), loss = 0.55939
I1210 16:58:15.771304 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:58:15.771304 15772 solver.cpp:237]     Train net output #1: loss = 0.55939 (* 1 = 0.55939 loss)
I1210 16:58:15.771304 15772 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1210 16:58:21.409260 15772 solver.cpp:218] Iteration 95700 (17.74 iter/s, 5.63698s/100 iters), loss = 0.378586
I1210 16:58:21.409260 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:58:21.409260 15772 solver.cpp:237]     Train net output #1: loss = 0.378586 (* 1 = 0.378586 loss)
I1210 16:58:21.409260 15772 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1210 16:58:27.053352 15772 solver.cpp:218] Iteration 95800 (17.7172 iter/s, 5.64424s/100 iters), loss = 0.614618
I1210 16:58:27.054354 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:58:27.054354 15772 solver.cpp:237]     Train net output #1: loss = 0.614618 (* 1 = 0.614618 loss)
I1210 16:58:27.054354 15772 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1210 16:58:32.695319 15772 solver.cpp:218] Iteration 95900 (17.7263 iter/s, 5.64134s/100 iters), loss = 0.531813
I1210 16:58:32.695319 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 16:58:32.696319 15772 solver.cpp:237]     Train net output #1: loss = 0.531813 (* 1 = 0.531813 loss)
I1210 16:58:32.696319 15772 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1210 16:58:38.063694 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:58:38.286705 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96000.caffemodel
I1210 16:58:38.302709 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96000.solverstate
I1210 16:58:38.307709 15772 solver.cpp:330] Iteration 96000, Testing net (#0)
I1210 16:58:38.307709 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:58:39.678836 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:58:39.732837 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6819
I1210 16:58:39.732837 15772 solver.cpp:397]     Test net output #1: loss = 1.16477 (* 1 = 1.16477 loss)
I1210 16:58:39.786837 15772 solver.cpp:218] Iteration 96000 (14.1042 iter/s, 7.09011s/100 iters), loss = 0.404429
I1210 16:58:39.786837 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 16:58:39.786837 15772 solver.cpp:237]     Train net output #1: loss = 0.404429 (* 1 = 0.404429 loss)
I1210 16:58:39.786837 15772 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1210 16:58:45.418527 15772 solver.cpp:218] Iteration 96100 (17.7583 iter/s, 5.63118s/100 iters), loss = 0.499978
I1210 16:58:45.418527 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 16:58:45.418527 15772 solver.cpp:237]     Train net output #1: loss = 0.499978 (* 1 = 0.499978 loss)
I1210 16:58:45.418527 15772 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1210 16:58:51.062968 15772 solver.cpp:218] Iteration 96200 (17.7181 iter/s, 5.64394s/100 iters), loss = 0.377279
I1210 16:58:51.062968 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 16:58:51.062968 15772 solver.cpp:237]     Train net output #1: loss = 0.377278 (* 1 = 0.377278 loss)
I1210 16:58:51.062968 15772 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1210 16:58:56.718433 15772 solver.cpp:218] Iteration 96300 (17.6827 iter/s, 5.65526s/100 iters), loss = 0.581212
I1210 16:58:56.718433 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 16:58:56.718433 15772 solver.cpp:237]     Train net output #1: loss = 0.581212 (* 1 = 0.581212 loss)
I1210 16:58:56.718433 15772 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1210 16:59:02.352269 15772 solver.cpp:218] Iteration 96400 (17.7506 iter/s, 5.6336s/100 iters), loss = 0.462206
I1210 16:59:02.352269 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 16:59:02.352269 15772 solver.cpp:237]     Train net output #1: loss = 0.462206 (* 1 = 0.462206 loss)
I1210 16:59:02.352269 15772 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1210 16:59:07.700060 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:59:07.920358 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96500.caffemodel
I1210 16:59:07.960360 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96500.solverstate
I1210 16:59:07.964373 15772 solver.cpp:330] Iteration 96500, Testing net (#0)
I1210 16:59:07.964373 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:59:09.339864 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:59:09.392860 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6827
I1210 16:59:09.392860 15772 solver.cpp:397]     Test net output #1: loss = 1.16914 (* 1 = 1.16914 loss)
I1210 16:59:09.446902 15772 solver.cpp:218] Iteration 96500 (14.0957 iter/s, 7.09436s/100 iters), loss = 0.379658
I1210 16:59:09.446902 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 16:59:09.446902 15772 solver.cpp:237]     Train net output #1: loss = 0.379658 (* 1 = 0.379658 loss)
I1210 16:59:09.446902 15772 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1210 16:59:15.076982 15772 solver.cpp:218] Iteration 96600 (17.7648 iter/s, 5.62912s/100 iters), loss = 0.468869
I1210 16:59:15.076982 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 16:59:15.076982 15772 solver.cpp:237]     Train net output #1: loss = 0.468869 (* 1 = 0.468869 loss)
I1210 16:59:15.076982 15772 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1210 16:59:20.711536 15772 solver.cpp:218] Iteration 96700 (17.7476 iter/s, 5.63455s/100 iters), loss = 0.355982
I1210 16:59:20.711536 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:59:20.711536 15772 solver.cpp:237]     Train net output #1: loss = 0.355981 (* 1 = 0.355981 loss)
I1210 16:59:20.711536 15772 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1210 16:59:26.348248 15772 solver.cpp:218] Iteration 96800 (17.741 iter/s, 5.63667s/100 iters), loss = 0.526445
I1210 16:59:26.348248 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 16:59:26.349249 15772 solver.cpp:237]     Train net output #1: loss = 0.526445 (* 1 = 0.526445 loss)
I1210 16:59:26.349249 15772 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1210 16:59:31.967628 15772 solver.cpp:218] Iteration 96900 (17.7969 iter/s, 5.61897s/100 iters), loss = 0.449752
I1210 16:59:31.968627 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:59:31.968627 15772 solver.cpp:237]     Train net output #1: loss = 0.449751 (* 1 = 0.449751 loss)
I1210 16:59:31.968627 15772 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1210 16:59:37.330981 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:59:37.552008 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97000.caffemodel
I1210 16:59:37.593008 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97000.solverstate
I1210 16:59:37.598013 15772 solver.cpp:330] Iteration 97000, Testing net (#0)
I1210 16:59:37.598513 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 16:59:38.967239 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 16:59:39.022256 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6818
I1210 16:59:39.022256 15772 solver.cpp:397]     Test net output #1: loss = 1.17533 (* 1 = 1.17533 loss)
I1210 16:59:39.076251 15772 solver.cpp:218] Iteration 97000 (14.0693 iter/s, 7.10766s/100 iters), loss = 0.376792
I1210 16:59:39.076251 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 16:59:39.076251 15772 solver.cpp:237]     Train net output #1: loss = 0.376792 (* 1 = 0.376792 loss)
I1210 16:59:39.076251 15772 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1210 16:59:44.717687 15772 solver.cpp:218] Iteration 97100 (17.7288 iter/s, 5.64054s/100 iters), loss = 0.492213
I1210 16:59:44.717687 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 16:59:44.717687 15772 solver.cpp:237]     Train net output #1: loss = 0.492212 (* 1 = 0.492212 loss)
I1210 16:59:44.717687 15772 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1210 16:59:50.364465 15772 solver.cpp:218] Iteration 97200 (17.708 iter/s, 5.64716s/100 iters), loss = 0.358404
I1210 16:59:50.365466 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 16:59:50.365466 15772 solver.cpp:237]     Train net output #1: loss = 0.358404 (* 1 = 0.358404 loss)
I1210 16:59:50.365466 15772 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1210 16:59:56.011896 15772 solver.cpp:218] Iteration 97300 (17.7103 iter/s, 5.64644s/100 iters), loss = 0.612887
I1210 16:59:56.011896 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 16:59:56.011896 15772 solver.cpp:237]     Train net output #1: loss = 0.612887 (* 1 = 0.612887 loss)
I1210 16:59:56.011896 15772 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1210 17:00:01.680327 15772 solver.cpp:218] Iteration 97400 (17.642 iter/s, 5.66829s/100 iters), loss = 0.428116
I1210 17:00:01.680327 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:00:01.680327 15772 solver.cpp:237]     Train net output #1: loss = 0.428116 (* 1 = 0.428116 loss)
I1210 17:00:01.680327 15772 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1210 17:00:07.051827 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:00:07.272837 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97500.caffemodel
I1210 17:00:07.286836 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97500.solverstate
I1210 17:00:07.291837 15772 solver.cpp:330] Iteration 97500, Testing net (#0)
I1210 17:00:07.291837 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:00:08.661926 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:00:08.716934 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6848
I1210 17:00:08.716934 15772 solver.cpp:397]     Test net output #1: loss = 1.16666 (* 1 = 1.16666 loss)
I1210 17:00:08.769932 15772 solver.cpp:218] Iteration 97500 (14.1061 iter/s, 7.08913s/100 iters), loss = 0.376988
I1210 17:00:08.769932 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:00:08.769932 15772 solver.cpp:237]     Train net output #1: loss = 0.376987 (* 1 = 0.376987 loss)
I1210 17:00:08.769932 15772 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1210 17:00:14.416354 15772 solver.cpp:218] Iteration 97600 (17.7116 iter/s, 5.64602s/100 iters), loss = 0.368875
I1210 17:00:14.416354 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:00:14.417356 15772 solver.cpp:237]     Train net output #1: loss = 0.368874 (* 1 = 0.368874 loss)
I1210 17:00:14.417356 15772 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1210 17:00:20.061856 15772 solver.cpp:218] Iteration 97700 (17.7152 iter/s, 5.64486s/100 iters), loss = 0.42981
I1210 17:00:20.061856 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:00:20.061856 15772 solver.cpp:237]     Train net output #1: loss = 0.42981 (* 1 = 0.42981 loss)
I1210 17:00:20.061856 15772 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1210 17:00:25.704892 15772 solver.cpp:218] Iteration 97800 (17.7234 iter/s, 5.64226s/100 iters), loss = 0.508042
I1210 17:00:25.705392 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:00:25.705392 15772 solver.cpp:237]     Train net output #1: loss = 0.508042 (* 1 = 0.508042 loss)
I1210 17:00:25.705392 15772 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1210 17:00:31.349683 15772 solver.cpp:218] Iteration 97900 (17.7171 iter/s, 5.64427s/100 iters), loss = 0.517826
I1210 17:00:31.349683 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 17:00:31.349683 15772 solver.cpp:237]     Train net output #1: loss = 0.517825 (* 1 = 0.517825 loss)
I1210 17:00:31.349683 15772 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1210 17:00:36.708531 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:00:36.929592 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98000.caffemodel
I1210 17:00:36.958590 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98000.solverstate
I1210 17:00:36.962589 15772 solver.cpp:330] Iteration 98000, Testing net (#0)
I1210 17:00:36.962589 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:00:38.330201 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:00:38.384711 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6828
I1210 17:00:38.384711 15772 solver.cpp:397]     Test net output #1: loss = 1.17343 (* 1 = 1.17343 loss)
I1210 17:00:38.437222 15772 solver.cpp:218] Iteration 98000 (14.1097 iter/s, 7.08731s/100 iters), loss = 0.368652
I1210 17:00:38.437222 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:00:38.437222 15772 solver.cpp:237]     Train net output #1: loss = 0.368652 (* 1 = 0.368652 loss)
I1210 17:00:38.437222 15772 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1210 17:00:44.082671 15772 solver.cpp:218] Iteration 98100 (17.7165 iter/s, 5.64446s/100 iters), loss = 0.456362
I1210 17:00:44.082671 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:00:44.082671 15772 solver.cpp:237]     Train net output #1: loss = 0.456361 (* 1 = 0.456361 loss)
I1210 17:00:44.082671 15772 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1210 17:00:49.734246 15772 solver.cpp:218] Iteration 98200 (17.694 iter/s, 5.65164s/100 iters), loss = 0.419582
I1210 17:00:49.734246 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:00:49.734246 15772 solver.cpp:237]     Train net output #1: loss = 0.419582 (* 1 = 0.419582 loss)
I1210 17:00:49.734246 15772 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1210 17:00:55.378161 15772 solver.cpp:218] Iteration 98300 (17.7205 iter/s, 5.64318s/100 iters), loss = 0.525952
I1210 17:00:55.378161 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:00:55.378161 15772 solver.cpp:237]     Train net output #1: loss = 0.525952 (* 1 = 0.525952 loss)
I1210 17:00:55.378161 15772 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1210 17:01:01.033679 15772 solver.cpp:218] Iteration 98400 (17.6832 iter/s, 5.6551s/100 iters), loss = 0.455944
I1210 17:01:01.033679 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:01:01.033679 15772 solver.cpp:237]     Train net output #1: loss = 0.455944 (* 1 = 0.455944 loss)
I1210 17:01:01.033679 15772 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1210 17:01:06.408200 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:01:06.631216 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98500.caffemodel
I1210 17:01:06.645215 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98500.solverstate
I1210 17:01:06.650216 15772 solver.cpp:330] Iteration 98500, Testing net (#0)
I1210 17:01:06.650216 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:01:08.022368 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:01:08.075361 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6848
I1210 17:01:08.075361 15772 solver.cpp:397]     Test net output #1: loss = 1.17663 (* 1 = 1.17663 loss)
I1210 17:01:08.129369 15772 solver.cpp:218] Iteration 98500 (14.0935 iter/s, 7.09545s/100 iters), loss = 0.28096
I1210 17:01:08.129369 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:01:08.129369 15772 solver.cpp:237]     Train net output #1: loss = 0.28096 (* 1 = 0.28096 loss)
I1210 17:01:08.129369 15772 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1210 17:01:13.755718 15772 solver.cpp:218] Iteration 98600 (17.7749 iter/s, 5.62591s/100 iters), loss = 0.49452
I1210 17:01:13.755718 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:01:13.755718 15772 solver.cpp:237]     Train net output #1: loss = 0.49452 (* 1 = 0.49452 loss)
I1210 17:01:13.755718 15772 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1210 17:01:19.387639 15772 solver.cpp:218] Iteration 98700 (17.7579 iter/s, 5.6313s/100 iters), loss = 0.372814
I1210 17:01:19.388139 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:01:19.388139 15772 solver.cpp:237]     Train net output #1: loss = 0.372814 (* 1 = 0.372814 loss)
I1210 17:01:19.388139 15772 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1210 17:01:25.016547 15772 solver.cpp:218] Iteration 98800 (17.7672 iter/s, 5.62835s/100 iters), loss = 0.469223
I1210 17:01:25.016547 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 17:01:25.016547 15772 solver.cpp:237]     Train net output #1: loss = 0.469223 (* 1 = 0.469223 loss)
I1210 17:01:25.016547 15772 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1210 17:01:30.651015 15772 solver.cpp:218] Iteration 98900 (17.7487 iter/s, 5.63423s/100 iters), loss = 0.452224
I1210 17:01:30.651015 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:01:30.651015 15772 solver.cpp:237]     Train net output #1: loss = 0.452224 (* 1 = 0.452224 loss)
I1210 17:01:30.651015 15772 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1210 17:01:35.991969 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:01:36.213721 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99000.caffemodel
I1210 17:01:36.249722 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99000.solverstate
I1210 17:01:36.254722 15772 solver.cpp:330] Iteration 99000, Testing net (#0)
I1210 17:01:36.254722 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:01:37.622720 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:01:37.676719 15772 solver.cpp:397]     Test net output #0: accuracy = 0.685
I1210 17:01:37.676719 15772 solver.cpp:397]     Test net output #1: loss = 1.17984 (* 1 = 1.17984 loss)
I1210 17:01:37.731739 15772 solver.cpp:218] Iteration 99000 (14.125 iter/s, 7.07966s/100 iters), loss = 0.317302
I1210 17:01:37.731739 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:01:37.731739 15772 solver.cpp:237]     Train net output #1: loss = 0.317302 (* 1 = 0.317302 loss)
I1210 17:01:37.731739 15772 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1210 17:01:43.373582 15772 solver.cpp:218] Iteration 99100 (17.7261 iter/s, 5.64139s/100 iters), loss = 0.481041
I1210 17:01:43.373582 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:01:43.373582 15772 solver.cpp:237]     Train net output #1: loss = 0.481041 (* 1 = 0.481041 loss)
I1210 17:01:43.373582 15772 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1210 17:01:49.016083 15772 solver.cpp:218] Iteration 99200 (17.7235 iter/s, 5.64222s/100 iters), loss = 0.28681
I1210 17:01:49.016083 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:01:49.016083 15772 solver.cpp:237]     Train net output #1: loss = 0.286809 (* 1 = 0.286809 loss)
I1210 17:01:49.016083 15772 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1210 17:01:54.670198 15772 solver.cpp:218] Iteration 99300 (17.6874 iter/s, 5.65374s/100 iters), loss = 0.469228
I1210 17:01:54.670198 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 17:01:54.670198 15772 solver.cpp:237]     Train net output #1: loss = 0.469227 (* 1 = 0.469227 loss)
I1210 17:01:54.670198 15772 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1210 17:02:00.317667 15772 solver.cpp:218] Iteration 99400 (17.7065 iter/s, 5.64763s/100 iters), loss = 0.458551
I1210 17:02:00.318668 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:02:00.318668 15772 solver.cpp:237]     Train net output #1: loss = 0.458551 (* 1 = 0.458551 loss)
I1210 17:02:00.318668 15772 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1210 17:02:05.692582 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:02:05.916096 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99500.caffemodel
I1210 17:02:05.933095 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99500.solverstate
I1210 17:02:05.960096 15772 solver.cpp:330] Iteration 99500, Testing net (#0)
I1210 17:02:05.960096 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:02:07.330687 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:02:07.385685 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6868
I1210 17:02:07.385685 15772 solver.cpp:397]     Test net output #1: loss = 1.17811 (* 1 = 1.17811 loss)
I1210 17:02:07.438694 15772 solver.cpp:218] Iteration 99500 (14.0439 iter/s, 7.12054s/100 iters), loss = 0.408247
I1210 17:02:07.439693 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:02:07.439693 15772 solver.cpp:237]     Train net output #1: loss = 0.408247 (* 1 = 0.408247 loss)
I1210 17:02:07.439693 15772 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1210 17:02:13.081303 15772 solver.cpp:218] Iteration 99600 (17.7248 iter/s, 5.64182s/100 iters), loss = 0.460894
I1210 17:02:13.081303 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:02:13.081303 15772 solver.cpp:237]     Train net output #1: loss = 0.460893 (* 1 = 0.460893 loss)
I1210 17:02:13.081303 15772 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1210 17:02:18.712740 15772 solver.cpp:218] Iteration 99700 (17.7599 iter/s, 5.63067s/100 iters), loss = 0.32572
I1210 17:02:18.712740 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:02:18.712740 15772 solver.cpp:237]     Train net output #1: loss = 0.32572 (* 1 = 0.32572 loss)
I1210 17:02:18.712740 15772 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1210 17:02:24.359318 15772 solver.cpp:218] Iteration 99800 (17.7106 iter/s, 5.64634s/100 iters), loss = 0.44233
I1210 17:02:24.359318 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 17:02:24.359318 15772 solver.cpp:237]     Train net output #1: loss = 0.442329 (* 1 = 0.442329 loss)
I1210 17:02:24.359318 15772 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1210 17:02:30.009923 15772 solver.cpp:218] Iteration 99900 (17.6983 iter/s, 5.65028s/100 iters), loss = 0.484435
I1210 17:02:30.009923 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:02:30.009923 15772 solver.cpp:237]     Train net output #1: loss = 0.484435 (* 1 = 0.484435 loss)
I1210 17:02:30.009923 15772 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1210 17:02:35.370367 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:02:35.591883 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100000.caffemodel
I1210 17:02:35.607386 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100000.solverstate
I1210 17:02:35.611400 15772 solver.cpp:330] Iteration 100000, Testing net (#0)
I1210 17:02:35.611400 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:02:36.979488 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:02:37.035495 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6838
I1210 17:02:37.035495 15772 solver.cpp:397]     Test net output #1: loss = 1.18395 (* 1 = 1.18395 loss)
I1210 17:02:37.089494 15772 solver.cpp:218] Iteration 100000 (14.1256 iter/s, 7.07936s/100 iters), loss = 0.300901
I1210 17:02:37.089494 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:02:37.089494 15772 solver.cpp:237]     Train net output #1: loss = 0.3009 (* 1 = 0.3009 loss)
I1210 17:02:37.089494 15772 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1210 17:02:42.724887 15772 solver.cpp:218] Iteration 100100 (17.7482 iter/s, 5.63436s/100 iters), loss = 0.481229
I1210 17:02:42.724887 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:02:42.724887 15772 solver.cpp:237]     Train net output #1: loss = 0.481228 (* 1 = 0.481228 loss)
I1210 17:02:42.724887 15772 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1210 17:02:48.367326 15772 solver.cpp:218] Iteration 100200 (17.7239 iter/s, 5.64212s/100 iters), loss = 0.365798
I1210 17:02:48.367326 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:02:48.367326 15772 solver.cpp:237]     Train net output #1: loss = 0.365798 (* 1 = 0.365798 loss)
I1210 17:02:48.367326 15772 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1210 17:02:53.998241 15772 solver.cpp:218] Iteration 100300 (17.7616 iter/s, 5.63011s/100 iters), loss = 0.566445
I1210 17:02:53.998241 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 17:02:53.998241 15772 solver.cpp:237]     Train net output #1: loss = 0.566445 (* 1 = 0.566445 loss)
I1210 17:02:53.998241 15772 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1210 17:02:59.638164 15772 solver.cpp:218] Iteration 100400 (17.7311 iter/s, 5.63981s/100 iters), loss = 0.486106
I1210 17:02:59.638164 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 17:02:59.638164 15772 solver.cpp:237]     Train net output #1: loss = 0.486106 (* 1 = 0.486106 loss)
I1210 17:02:59.638164 15772 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1210 17:03:05.003068 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:03:05.224582 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100500.caffemodel
I1210 17:03:05.238584 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100500.solverstate
I1210 17:03:05.268584 15772 solver.cpp:330] Iteration 100500, Testing net (#0)
I1210 17:03:05.268584 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:03:06.637732 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:03:06.691732 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6867
I1210 17:03:06.691732 15772 solver.cpp:397]     Test net output #1: loss = 1.18415 (* 1 = 1.18415 loss)
I1210 17:03:06.746742 15772 solver.cpp:218] Iteration 100500 (14.0673 iter/s, 7.10869s/100 iters), loss = 0.302314
I1210 17:03:06.746742 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:03:06.747741 15772 solver.cpp:237]     Train net output #1: loss = 0.302314 (* 1 = 0.302314 loss)
I1210 17:03:06.747741 15772 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1210 17:03:12.389004 15772 solver.cpp:218] Iteration 100600 (17.7268 iter/s, 5.64117s/100 iters), loss = 0.476765
I1210 17:03:12.389004 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:03:12.389004 15772 solver.cpp:237]     Train net output #1: loss = 0.476765 (* 1 = 0.476765 loss)
I1210 17:03:12.389004 15772 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1210 17:03:18.035445 15772 solver.cpp:218] Iteration 100700 (17.7106 iter/s, 5.64634s/100 iters), loss = 0.302656
I1210 17:03:18.035445 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:03:18.035445 15772 solver.cpp:237]     Train net output #1: loss = 0.302656 (* 1 = 0.302656 loss)
I1210 17:03:18.035445 15772 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1210 17:03:23.681902 15772 solver.cpp:218] Iteration 100800 (17.7106 iter/s, 5.64634s/100 iters), loss = 0.468209
I1210 17:03:23.682912 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 17:03:23.682912 15772 solver.cpp:237]     Train net output #1: loss = 0.468209 (* 1 = 0.468209 loss)
I1210 17:03:23.682912 15772 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1210 17:03:29.332741 15772 solver.cpp:218] Iteration 100900 (17.7005 iter/s, 5.64956s/100 iters), loss = 0.406379
I1210 17:03:29.332741 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:03:29.332741 15772 solver.cpp:237]     Train net output #1: loss = 0.406378 (* 1 = 0.406378 loss)
I1210 17:03:29.332741 15772 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1210 17:03:34.693287 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:03:34.916329 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101000.caffemodel
I1210 17:03:34.931329 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101000.solverstate
I1210 17:03:34.960330 15772 solver.cpp:330] Iteration 101000, Testing net (#0)
I1210 17:03:34.960330 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:03:36.329419 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:03:36.384418 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6843
I1210 17:03:36.384418 15772 solver.cpp:397]     Test net output #1: loss = 1.18441 (* 1 = 1.18441 loss)
I1210 17:03:36.438161 15772 solver.cpp:218] Iteration 101000 (14.0752 iter/s, 7.10469s/100 iters), loss = 0.320609
I1210 17:03:36.438161 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:03:36.438161 15772 solver.cpp:237]     Train net output #1: loss = 0.320609 (* 1 = 0.320609 loss)
I1210 17:03:36.438161 15772 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1210 17:03:42.078092 15772 solver.cpp:218] Iteration 101100 (17.7316 iter/s, 5.63966s/100 iters), loss = 0.476159
I1210 17:03:42.078092 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:03:42.078092 15772 solver.cpp:237]     Train net output #1: loss = 0.476159 (* 1 = 0.476159 loss)
I1210 17:03:42.078092 15772 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1210 17:03:47.714604 15772 solver.cpp:218] Iteration 101200 (17.7413 iter/s, 5.63655s/100 iters), loss = 0.340427
I1210 17:03:47.714604 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:03:47.714604 15772 solver.cpp:237]     Train net output #1: loss = 0.340427 (* 1 = 0.340427 loss)
I1210 17:03:47.714604 15772 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1210 17:03:53.355063 15772 solver.cpp:218] Iteration 101300 (17.7317 iter/s, 5.63962s/100 iters), loss = 0.453112
I1210 17:03:53.355063 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:03:53.355063 15772 solver.cpp:237]     Train net output #1: loss = 0.453112 (* 1 = 0.453112 loss)
I1210 17:03:53.355063 15772 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1210 17:03:58.983589 15772 solver.cpp:218] Iteration 101400 (17.766 iter/s, 5.62872s/100 iters), loss = 0.439117
I1210 17:03:58.983589 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:03:58.983589 15772 solver.cpp:237]     Train net output #1: loss = 0.439116 (* 1 = 0.439116 loss)
I1210 17:03:58.983589 15772 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1210 17:04:04.340528 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:04:04.561549 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101500.caffemodel
I1210 17:04:04.575542 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101500.solverstate
I1210 17:04:04.602047 15772 solver.cpp:330] Iteration 101500, Testing net (#0)
I1210 17:04:04.602047 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:04:05.969741 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:04:06.023762 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6833
I1210 17:04:06.024763 15772 solver.cpp:397]     Test net output #1: loss = 1.20117 (* 1 = 1.20117 loss)
I1210 17:04:06.079756 15772 solver.cpp:218] Iteration 101500 (14.0929 iter/s, 7.09575s/100 iters), loss = 0.332489
I1210 17:04:06.080756 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:04:06.080756 15772 solver.cpp:237]     Train net output #1: loss = 0.332489 (* 1 = 0.332489 loss)
I1210 17:04:06.080756 15772 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1210 17:04:11.722263 15772 solver.cpp:218] Iteration 101600 (17.7272 iter/s, 5.64106s/100 iters), loss = 0.444872
I1210 17:04:11.722263 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:04:11.722263 15772 solver.cpp:237]     Train net output #1: loss = 0.444872 (* 1 = 0.444872 loss)
I1210 17:04:11.722263 15772 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1210 17:04:17.370764 15772 solver.cpp:218] Iteration 101700 (17.7026 iter/s, 5.64888s/100 iters), loss = 0.396788
I1210 17:04:17.370764 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:04:17.370764 15772 solver.cpp:237]     Train net output #1: loss = 0.396788 (* 1 = 0.396788 loss)
I1210 17:04:17.370764 15772 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1210 17:04:23.009315 15772 solver.cpp:218] Iteration 101800 (17.7393 iter/s, 5.6372s/100 iters), loss = 0.423359
I1210 17:04:23.009315 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:04:23.009315 15772 solver.cpp:237]     Train net output #1: loss = 0.423358 (* 1 = 0.423358 loss)
I1210 17:04:23.009315 15772 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1210 17:04:28.652801 15772 solver.cpp:218] Iteration 101900 (17.7206 iter/s, 5.64316s/100 iters), loss = 0.454878
I1210 17:04:28.652801 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:04:28.652801 15772 solver.cpp:237]     Train net output #1: loss = 0.454878 (* 1 = 0.454878 loss)
I1210 17:04:28.652801 15772 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1210 17:04:34.016206 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:04:34.238226 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102000.caffemodel
I1210 17:04:34.252226 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102000.solverstate
I1210 17:04:34.257228 15772 solver.cpp:330] Iteration 102000, Testing net (#0)
I1210 17:04:34.257228 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:04:35.625339 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:04:35.679337 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6889
I1210 17:04:35.679337 15772 solver.cpp:397]     Test net output #1: loss = 1.18835 (* 1 = 1.18835 loss)
I1210 17:04:35.735343 15772 solver.cpp:218] Iteration 102000 (14.1191 iter/s, 7.08258s/100 iters), loss = 0.358414
I1210 17:04:35.735343 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:04:35.735343 15772 solver.cpp:237]     Train net output #1: loss = 0.358413 (* 1 = 0.358413 loss)
I1210 17:04:35.735343 15772 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1210 17:04:41.377096 15772 solver.cpp:218] Iteration 102100 (17.7274 iter/s, 5.64099s/100 iters), loss = 0.466373
I1210 17:04:41.377096 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:04:41.377096 15772 solver.cpp:237]     Train net output #1: loss = 0.466373 (* 1 = 0.466373 loss)
I1210 17:04:41.377096 15772 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1210 17:04:47.028506 15772 solver.cpp:218] Iteration 102200 (17.6961 iter/s, 5.65096s/100 iters), loss = 0.352325
I1210 17:04:47.028506 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:04:47.028506 15772 solver.cpp:237]     Train net output #1: loss = 0.352325 (* 1 = 0.352325 loss)
I1210 17:04:47.028506 15772 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1210 17:04:52.668982 15772 solver.cpp:218] Iteration 102300 (17.7306 iter/s, 5.63997s/100 iters), loss = 0.479806
I1210 17:04:52.668982 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 17:04:52.668982 15772 solver.cpp:237]     Train net output #1: loss = 0.479806 (* 1 = 0.479806 loss)
I1210 17:04:52.668982 15772 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1210 17:04:58.306540 15772 solver.cpp:218] Iteration 102400 (17.7408 iter/s, 5.63673s/100 iters), loss = 0.450125
I1210 17:04:58.306540 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:04:58.306540 15772 solver.cpp:237]     Train net output #1: loss = 0.450125 (* 1 = 0.450125 loss)
I1210 17:04:58.306540 15772 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1210 17:05:03.671967 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:05:03.892977 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102500.caffemodel
I1210 17:05:03.909482 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102500.solverstate
I1210 17:05:03.935010 15772 solver.cpp:330] Iteration 102500, Testing net (#0)
I1210 17:05:03.935010 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:05:05.306149 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:05:05.359146 15772 solver.cpp:397]     Test net output #0: accuracy = 0.687
I1210 17:05:05.359146 15772 solver.cpp:397]     Test net output #1: loss = 1.19527 (* 1 = 1.19527 loss)
I1210 17:05:05.413660 15772 solver.cpp:218] Iteration 102500 (14.0707 iter/s, 7.10698s/100 iters), loss = 0.310306
I1210 17:05:05.414151 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:05:05.414151 15772 solver.cpp:237]     Train net output #1: loss = 0.310306 (* 1 = 0.310306 loss)
I1210 17:05:05.414151 15772 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1210 17:05:11.061627 15772 solver.cpp:218] Iteration 102600 (17.707 iter/s, 5.64749s/100 iters), loss = 0.467455
I1210 17:05:11.061627 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:05:11.061627 15772 solver.cpp:237]     Train net output #1: loss = 0.467455 (* 1 = 0.467455 loss)
I1210 17:05:11.061627 15772 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1210 17:05:16.714056 15772 solver.cpp:218] Iteration 102700 (17.6941 iter/s, 5.65161s/100 iters), loss = 0.384221
I1210 17:05:16.714056 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:05:16.714056 15772 solver.cpp:237]     Train net output #1: loss = 0.384221 (* 1 = 0.384221 loss)
I1210 17:05:16.714056 15772 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1210 17:05:22.366442 15772 solver.cpp:218] Iteration 102800 (17.6931 iter/s, 5.65192s/100 iters), loss = 0.443852
I1210 17:05:22.366442 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:05:22.366442 15772 solver.cpp:237]     Train net output #1: loss = 0.443852 (* 1 = 0.443852 loss)
I1210 17:05:22.366442 15772 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1210 17:05:28.014885 15772 solver.cpp:218] Iteration 102900 (17.7044 iter/s, 5.64831s/100 iters), loss = 0.463001
I1210 17:05:28.015385 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 17:05:28.015385 15772 solver.cpp:237]     Train net output #1: loss = 0.463001 (* 1 = 0.463001 loss)
I1210 17:05:28.015385 15772 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1210 17:05:33.394273 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:05:33.615788 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103000.caffemodel
I1210 17:05:33.631294 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103000.solverstate
I1210 17:05:33.635293 15772 solver.cpp:330] Iteration 103000, Testing net (#0)
I1210 17:05:33.636294 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:05:35.010946 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:05:35.066453 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6828
I1210 17:05:35.066453 15772 solver.cpp:397]     Test net output #1: loss = 1.19994 (* 1 = 1.19994 loss)
I1210 17:05:35.120457 15772 solver.cpp:218] Iteration 103000 (14.0752 iter/s, 7.1047s/100 iters), loss = 0.270293
I1210 17:05:35.120457 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:05:35.120457 15772 solver.cpp:237]     Train net output #1: loss = 0.270293 (* 1 = 0.270293 loss)
I1210 17:05:35.120457 15772 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1210 17:05:40.773978 15772 solver.cpp:218] Iteration 103100 (17.6887 iter/s, 5.65334s/100 iters), loss = 0.395381
I1210 17:05:40.773978 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:05:40.773978 15772 solver.cpp:237]     Train net output #1: loss = 0.395381 (* 1 = 0.395381 loss)
I1210 17:05:40.773978 15772 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1210 17:05:46.426226 15772 solver.cpp:218] Iteration 103200 (17.6936 iter/s, 5.65178s/100 iters), loss = 0.386004
I1210 17:05:46.426226 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:05:46.426226 15772 solver.cpp:237]     Train net output #1: loss = 0.386004 (* 1 = 0.386004 loss)
I1210 17:05:46.426226 15772 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1210 17:05:52.080132 15772 solver.cpp:218] Iteration 103300 (17.6888 iter/s, 5.6533s/100 iters), loss = 0.450848
I1210 17:05:52.080132 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 17:05:52.080132 15772 solver.cpp:237]     Train net output #1: loss = 0.450848 (* 1 = 0.450848 loss)
I1210 17:05:52.080132 15772 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1210 17:05:57.730573 15772 solver.cpp:218] Iteration 103400 (17.6982 iter/s, 5.65028s/100 iters), loss = 0.488261
I1210 17:05:57.730573 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:05:57.730573 15772 solver.cpp:237]     Train net output #1: loss = 0.488261 (* 1 = 0.488261 loss)
I1210 17:05:57.730573 15772 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1210 17:06:03.106010 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:06:03.328040 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103500.caffemodel
I1210 17:06:03.343042 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103500.solverstate
I1210 17:06:03.369043 15772 solver.cpp:330] Iteration 103500, Testing net (#0)
I1210 17:06:03.369043 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:06:04.739207 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:06:04.792204 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6814
I1210 17:06:04.792204 15772 solver.cpp:397]     Test net output #1: loss = 1.21094 (* 1 = 1.21094 loss)
I1210 17:06:04.846210 15772 solver.cpp:218] Iteration 103500 (14.0556 iter/s, 7.1146s/100 iters), loss = 0.212681
I1210 17:06:04.846210 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:06:04.846210 15772 solver.cpp:237]     Train net output #1: loss = 0.21268 (* 1 = 0.21268 loss)
I1210 17:06:04.846210 15772 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1210 17:06:10.473601 15772 solver.cpp:218] Iteration 103600 (17.7703 iter/s, 5.62737s/100 iters), loss = 0.424751
I1210 17:06:10.473601 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:06:10.473601 15772 solver.cpp:237]     Train net output #1: loss = 0.42475 (* 1 = 0.42475 loss)
I1210 17:06:10.473601 15772 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1210 17:06:16.100072 15772 solver.cpp:218] Iteration 103700 (17.7758 iter/s, 5.62562s/100 iters), loss = 0.299501
I1210 17:06:16.100072 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:06:16.100072 15772 solver.cpp:237]     Train net output #1: loss = 0.299501 (* 1 = 0.299501 loss)
I1210 17:06:16.100072 15772 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1210 17:06:21.724468 15772 solver.cpp:218] Iteration 103800 (17.7802 iter/s, 5.62423s/100 iters), loss = 0.37965
I1210 17:06:21.724468 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:06:21.724468 15772 solver.cpp:237]     Train net output #1: loss = 0.379649 (* 1 = 0.379649 loss)
I1210 17:06:21.724468 15772 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1210 17:06:27.349145 15772 solver.cpp:218] Iteration 103900 (17.7808 iter/s, 5.62403s/100 iters), loss = 0.448089
I1210 17:06:27.349145 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:06:27.349145 15772 solver.cpp:237]     Train net output #1: loss = 0.448089 (* 1 = 0.448089 loss)
I1210 17:06:27.349145 15772 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1210 17:06:32.696535 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:06:32.918048 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104000.caffemodel
I1210 17:06:32.931553 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104000.solverstate
I1210 17:06:32.936553 15772 solver.cpp:330] Iteration 104000, Testing net (#0)
I1210 17:06:32.936553 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:06:34.307660 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:06:34.359668 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6822
I1210 17:06:34.359668 15772 solver.cpp:397]     Test net output #1: loss = 1.20088 (* 1 = 1.20088 loss)
I1210 17:06:34.415171 15772 solver.cpp:218] Iteration 104000 (14.1524 iter/s, 7.06592s/100 iters), loss = 0.25406
I1210 17:06:34.415673 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:06:34.415673 15772 solver.cpp:237]     Train net output #1: loss = 0.25406 (* 1 = 0.25406 loss)
I1210 17:06:34.415673 15772 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1210 17:06:40.060075 15772 solver.cpp:218] Iteration 104100 (17.7153 iter/s, 5.64485s/100 iters), loss = 0.38353
I1210 17:06:40.060075 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:06:40.060075 15772 solver.cpp:237]     Train net output #1: loss = 0.38353 (* 1 = 0.38353 loss)
I1210 17:06:40.061077 15772 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1210 17:06:45.704495 15772 solver.cpp:218] Iteration 104200 (17.7208 iter/s, 5.64308s/100 iters), loss = 0.264907
I1210 17:06:45.704495 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:06:45.704495 15772 solver.cpp:237]     Train net output #1: loss = 0.264907 (* 1 = 0.264907 loss)
I1210 17:06:45.704495 15772 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1210 17:06:51.351892 15772 solver.cpp:218] Iteration 104300 (17.7072 iter/s, 5.64741s/100 iters), loss = 0.405146
I1210 17:06:51.351892 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:06:51.351892 15772 solver.cpp:237]     Train net output #1: loss = 0.405146 (* 1 = 0.405146 loss)
I1210 17:06:51.351892 15772 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1210 17:06:56.996373 15772 solver.cpp:218] Iteration 104400 (17.7189 iter/s, 5.6437s/100 iters), loss = 0.379906
I1210 17:06:56.996373 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:06:56.996373 15772 solver.cpp:237]     Train net output #1: loss = 0.379906 (* 1 = 0.379906 loss)
I1210 17:06:56.996373 15772 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1210 17:07:02.368767 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:07:02.589787 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104500.caffemodel
I1210 17:07:02.603787 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104500.solverstate
I1210 17:07:02.634806 15772 solver.cpp:330] Iteration 104500, Testing net (#0)
I1210 17:07:02.634806 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:07:04.002933 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:07:04.056951 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6825
I1210 17:07:04.056951 15772 solver.cpp:397]     Test net output #1: loss = 1.20492 (* 1 = 1.20492 loss)
I1210 17:07:04.112939 15772 solver.cpp:218] Iteration 104500 (14.0526 iter/s, 7.11611s/100 iters), loss = 0.287749
I1210 17:07:04.112939 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:07:04.112939 15772 solver.cpp:237]     Train net output #1: loss = 0.287748 (* 1 = 0.287748 loss)
I1210 17:07:04.112939 15772 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1210 17:07:09.755450 15772 solver.cpp:218] Iteration 104600 (17.7224 iter/s, 5.64257s/100 iters), loss = 0.36297
I1210 17:07:09.755450 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:07:09.755450 15772 solver.cpp:237]     Train net output #1: loss = 0.36297 (* 1 = 0.36297 loss)
I1210 17:07:09.755450 15772 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1210 17:07:15.388923 15772 solver.cpp:218] Iteration 104700 (17.7541 iter/s, 5.63251s/100 iters), loss = 0.315137
I1210 17:07:15.388923 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:07:15.388923 15772 solver.cpp:237]     Train net output #1: loss = 0.315136 (* 1 = 0.315136 loss)
I1210 17:07:15.388923 15772 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1210 17:07:21.026927 15772 solver.cpp:218] Iteration 104800 (17.7386 iter/s, 5.63743s/100 iters), loss = 0.374553
I1210 17:07:21.026927 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:07:21.026927 15772 solver.cpp:237]     Train net output #1: loss = 0.374553 (* 1 = 0.374553 loss)
I1210 17:07:21.026927 15772 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1210 17:07:26.659909 15772 solver.cpp:218] Iteration 104900 (17.7524 iter/s, 5.63305s/100 iters), loss = 0.362141
I1210 17:07:26.659909 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:07:26.659909 15772 solver.cpp:237]     Train net output #1: loss = 0.362141 (* 1 = 0.362141 loss)
I1210 17:07:26.659909 15772 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1210 17:07:32.026857 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:07:32.249634 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105000.caffemodel
I1210 17:07:32.264633 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105000.solverstate
I1210 17:07:32.269635 15772 solver.cpp:330] Iteration 105000, Testing net (#0)
I1210 17:07:32.269635 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:07:33.637786 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:07:33.690783 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6824
I1210 17:07:33.690783 15772 solver.cpp:397]     Test net output #1: loss = 1.21088 (* 1 = 1.21088 loss)
I1210 17:07:33.746788 15772 solver.cpp:218] Iteration 105000 (14.1116 iter/s, 7.08639s/100 iters), loss = 0.234834
I1210 17:07:33.746788 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:07:33.746788 15772 solver.cpp:237]     Train net output #1: loss = 0.234834 (* 1 = 0.234834 loss)
I1210 17:07:33.746788 15772 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1210 17:07:39.388408 15772 solver.cpp:218] Iteration 105100 (17.728 iter/s, 5.6408s/100 iters), loss = 0.344114
I1210 17:07:39.388408 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:07:39.388408 15772 solver.cpp:237]     Train net output #1: loss = 0.344114 (* 1 = 0.344114 loss)
I1210 17:07:39.388408 15772 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1210 17:07:45.017518 15772 solver.cpp:218] Iteration 105200 (17.765 iter/s, 5.62905s/100 iters), loss = 0.246515
I1210 17:07:45.017518 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:07:45.017518 15772 solver.cpp:237]     Train net output #1: loss = 0.246515 (* 1 = 0.246515 loss)
I1210 17:07:45.017518 15772 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1210 17:07:50.663338 15772 solver.cpp:218] Iteration 105300 (17.7138 iter/s, 5.64532s/100 iters), loss = 0.429999
I1210 17:07:50.663338 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:07:50.663338 15772 solver.cpp:237]     Train net output #1: loss = 0.429999 (* 1 = 0.429999 loss)
I1210 17:07:50.663338 15772 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1210 17:07:56.309047 15772 solver.cpp:218] Iteration 105400 (17.716 iter/s, 5.64463s/100 iters), loss = 0.380123
I1210 17:07:56.309047 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:07:56.309047 15772 solver.cpp:237]     Train net output #1: loss = 0.380123 (* 1 = 0.380123 loss)
I1210 17:07:56.309047 15772 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1210 17:08:01.667464 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:08:01.888473 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105500.caffemodel
I1210 17:08:01.902473 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105500.solverstate
I1210 17:08:01.934988 15772 solver.cpp:330] Iteration 105500, Testing net (#0)
I1210 17:08:01.935488 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:08:03.305582 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:08:03.358587 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6848
I1210 17:08:03.358587 15772 solver.cpp:397]     Test net output #1: loss = 1.21343 (* 1 = 1.21343 loss)
I1210 17:08:03.414585 15772 solver.cpp:218] Iteration 105500 (14.0746 iter/s, 7.10499s/100 iters), loss = 0.334424
I1210 17:08:03.414585 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:08:03.414585 15772 solver.cpp:237]     Train net output #1: loss = 0.334423 (* 1 = 0.334423 loss)
I1210 17:08:03.414585 15772 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1210 17:08:09.056975 15772 solver.cpp:218] Iteration 105600 (17.7223 iter/s, 5.6426s/100 iters), loss = 0.411639
I1210 17:08:09.056975 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 17:08:09.056975 15772 solver.cpp:237]     Train net output #1: loss = 0.411639 (* 1 = 0.411639 loss)
I1210 17:08:09.056975 15772 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1210 17:08:14.706418 15772 solver.cpp:218] Iteration 105700 (17.7016 iter/s, 5.64921s/100 iters), loss = 0.314448
I1210 17:08:14.707417 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:08:14.707417 15772 solver.cpp:237]     Train net output #1: loss = 0.314447 (* 1 = 0.314447 loss)
I1210 17:08:14.707417 15772 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1210 17:08:20.341549 15772 solver.cpp:218] Iteration 105800 (17.7491 iter/s, 5.6341s/100 iters), loss = 0.410225
I1210 17:08:20.341549 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:08:20.342049 15772 solver.cpp:237]     Train net output #1: loss = 0.410225 (* 1 = 0.410225 loss)
I1210 17:08:20.342049 15772 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1210 17:08:25.981945 15772 solver.cpp:218] Iteration 105900 (17.7307 iter/s, 5.63995s/100 iters), loss = 0.357713
I1210 17:08:25.981945 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:08:25.981945 15772 solver.cpp:237]     Train net output #1: loss = 0.357713 (* 1 = 0.357713 loss)
I1210 17:08:25.981945 15772 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1210 17:08:31.340929 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:08:31.564442 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106000.caffemodel
I1210 17:08:31.579442 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106000.solverstate
I1210 17:08:31.584444 15772 solver.cpp:330] Iteration 106000, Testing net (#0)
I1210 17:08:31.584444 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:08:32.952519 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:08:33.005517 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6822
I1210 17:08:33.005517 15772 solver.cpp:397]     Test net output #1: loss = 1.21124 (* 1 = 1.21124 loss)
I1210 17:08:33.062528 15772 solver.cpp:218] Iteration 106000 (14.125 iter/s, 7.07965s/100 iters), loss = 0.265357
I1210 17:08:33.062528 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:08:33.062528 15772 solver.cpp:237]     Train net output #1: loss = 0.265357 (* 1 = 0.265357 loss)
I1210 17:08:33.062528 15772 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1210 17:08:38.694943 15772 solver.cpp:218] Iteration 106100 (17.7529 iter/s, 5.63289s/100 iters), loss = 0.429772
I1210 17:08:38.695943 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 17:08:38.695943 15772 solver.cpp:237]     Train net output #1: loss = 0.429771 (* 1 = 0.429771 loss)
I1210 17:08:38.695943 15772 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1210 17:08:44.320662 15772 solver.cpp:218] Iteration 106200 (17.7775 iter/s, 5.62509s/100 iters), loss = 0.308464
I1210 17:08:44.320662 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:08:44.320662 15772 solver.cpp:237]     Train net output #1: loss = 0.308464 (* 1 = 0.308464 loss)
I1210 17:08:44.320662 15772 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1210 17:08:49.965087 15772 solver.cpp:218] Iteration 106300 (17.7179 iter/s, 5.644s/100 iters), loss = 0.33774
I1210 17:08:49.965087 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:08:49.965087 15772 solver.cpp:237]     Train net output #1: loss = 0.33774 (* 1 = 0.33774 loss)
I1210 17:08:49.965087 15772 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1210 17:08:55.600520 15772 solver.cpp:218] Iteration 106400 (17.7456 iter/s, 5.6352s/100 iters), loss = 0.470009
I1210 17:08:55.600520 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 17:08:55.600520 15772 solver.cpp:237]     Train net output #1: loss = 0.470009 (* 1 = 0.470009 loss)
I1210 17:08:55.600520 15772 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1210 17:09:00.951946 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:09:01.174960 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106500.caffemodel
I1210 17:09:01.189960 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106500.solverstate
I1210 17:09:01.218961 15772 solver.cpp:330] Iteration 106500, Testing net (#0)
I1210 17:09:01.218961 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:09:02.589090 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:09:02.642093 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6797
I1210 17:09:02.642093 15772 solver.cpp:397]     Test net output #1: loss = 1.21849 (* 1 = 1.21849 loss)
I1210 17:09:02.696105 15772 solver.cpp:218] Iteration 106500 (14.0957 iter/s, 7.09436s/100 iters), loss = 0.292289
I1210 17:09:02.696105 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:09:02.696105 15772 solver.cpp:237]     Train net output #1: loss = 0.292288 (* 1 = 0.292288 loss)
I1210 17:09:02.696105 15772 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1210 17:09:08.329517 15772 solver.cpp:218] Iteration 106600 (17.7507 iter/s, 5.63358s/100 iters), loss = 0.447829
I1210 17:09:08.329517 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:09:08.329517 15772 solver.cpp:237]     Train net output #1: loss = 0.447829 (* 1 = 0.447829 loss)
I1210 17:09:08.329517 15772 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1210 17:09:13.964936 15772 solver.cpp:218] Iteration 106700 (17.7473 iter/s, 5.63465s/100 iters), loss = 0.277552
I1210 17:09:13.964936 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:09:13.964936 15772 solver.cpp:237]     Train net output #1: loss = 0.277551 (* 1 = 0.277551 loss)
I1210 17:09:13.964936 15772 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1210 17:09:19.607379 15772 solver.cpp:218] Iteration 106800 (17.7253 iter/s, 5.64164s/100 iters), loss = 0.42949
I1210 17:09:19.607379 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:09:19.607379 15772 solver.cpp:237]     Train net output #1: loss = 0.42949 (* 1 = 0.42949 loss)
I1210 17:09:19.607379 15772 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1210 17:09:25.251345 15772 solver.cpp:218] Iteration 106900 (17.7188 iter/s, 5.64373s/100 iters), loss = 0.415302
I1210 17:09:25.251345 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:09:25.251345 15772 solver.cpp:237]     Train net output #1: loss = 0.415302 (* 1 = 0.415302 loss)
I1210 17:09:25.251345 15772 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1210 17:09:30.604132 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:09:30.826392 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107000.caffemodel
I1210 17:09:30.844895 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107000.solverstate
I1210 17:09:30.849395 15772 solver.cpp:330] Iteration 107000, Testing net (#0)
I1210 17:09:30.849895 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:09:32.221796 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:09:32.274819 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6851
I1210 17:09:32.274819 15772 solver.cpp:397]     Test net output #1: loss = 1.21688 (* 1 = 1.21688 loss)
I1210 17:09:32.328831 15772 solver.cpp:218] Iteration 107000 (14.1293 iter/s, 7.07751s/100 iters), loss = 0.30337
I1210 17:09:32.328831 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:09:32.328831 15772 solver.cpp:237]     Train net output #1: loss = 0.30337 (* 1 = 0.30337 loss)
I1210 17:09:32.328831 15772 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1210 17:09:37.963660 15772 solver.cpp:218] Iteration 107100 (17.7495 iter/s, 5.63395s/100 iters), loss = 0.458162
I1210 17:09:37.963660 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:09:37.963660 15772 solver.cpp:237]     Train net output #1: loss = 0.458162 (* 1 = 0.458162 loss)
I1210 17:09:37.963660 15772 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1210 17:09:43.594571 15772 solver.cpp:218] Iteration 107200 (17.7596 iter/s, 5.63076s/100 iters), loss = 0.291278
I1210 17:09:43.594571 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:09:43.594571 15772 solver.cpp:237]     Train net output #1: loss = 0.291277 (* 1 = 0.291277 loss)
I1210 17:09:43.594571 15772 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1210 17:09:49.240823 15772 solver.cpp:218] Iteration 107300 (17.7131 iter/s, 5.64555s/100 iters), loss = 0.405992
I1210 17:09:49.240823 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 17:09:49.240823 15772 solver.cpp:237]     Train net output #1: loss = 0.405991 (* 1 = 0.405991 loss)
I1210 17:09:49.240823 15772 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1210 17:09:54.879259 15772 solver.cpp:218] Iteration 107400 (17.7366 iter/s, 5.63804s/100 iters), loss = 0.38348
I1210 17:09:54.879259 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:09:54.879259 15772 solver.cpp:237]     Train net output #1: loss = 0.38348 (* 1 = 0.38348 loss)
I1210 17:09:54.879259 15772 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1210 17:10:00.248725 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:10:00.471755 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107500.caffemodel
I1210 17:10:00.486754 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107500.solverstate
I1210 17:10:00.527755 15772 solver.cpp:330] Iteration 107500, Testing net (#0)
I1210 17:10:00.527755 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:10:01.917938 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:10:01.969949 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6852
I1210 17:10:01.970947 15772 solver.cpp:397]     Test net output #1: loss = 1.21166 (* 1 = 1.21166 loss)
I1210 17:10:02.024951 15772 solver.cpp:218] Iteration 107500 (13.9955 iter/s, 7.14513s/100 iters), loss = 0.349661
I1210 17:10:02.024951 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:10:02.024951 15772 solver.cpp:237]     Train net output #1: loss = 0.349661 (* 1 = 0.349661 loss)
I1210 17:10:02.024951 15772 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1210 17:10:07.665467 15772 solver.cpp:218] Iteration 107600 (17.7314 iter/s, 5.63972s/100 iters), loss = 0.371379
I1210 17:10:07.665467 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:10:07.665467 15772 solver.cpp:237]     Train net output #1: loss = 0.371379 (* 1 = 0.371379 loss)
I1210 17:10:07.665467 15772 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1210 17:10:13.302876 15772 solver.cpp:218] Iteration 107700 (17.7392 iter/s, 5.63724s/100 iters), loss = 0.305176
I1210 17:10:13.302876 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:10:13.302876 15772 solver.cpp:237]     Train net output #1: loss = 0.305176 (* 1 = 0.305176 loss)
I1210 17:10:13.302876 15772 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1210 17:10:18.938251 15772 solver.cpp:218] Iteration 107800 (17.7454 iter/s, 5.63527s/100 iters), loss = 0.36236
I1210 17:10:18.938251 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:10:18.938251 15772 solver.cpp:237]     Train net output #1: loss = 0.362359 (* 1 = 0.362359 loss)
I1210 17:10:18.938251 15772 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1210 17:10:24.577646 15772 solver.cpp:218] Iteration 107900 (17.734 iter/s, 5.63888s/100 iters), loss = 0.431358
I1210 17:10:24.577646 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:10:24.577646 15772 solver.cpp:237]     Train net output #1: loss = 0.431358 (* 1 = 0.431358 loss)
I1210 17:10:24.577646 15772 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1210 17:10:29.947127 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:10:30.169142 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108000.caffemodel
I1210 17:10:30.183142 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108000.solverstate
I1210 17:10:30.189143 15772 solver.cpp:330] Iteration 108000, Testing net (#0)
I1210 17:10:30.190145 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:10:31.561254 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:10:31.615257 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6833
I1210 17:10:31.615257 15772 solver.cpp:397]     Test net output #1: loss = 1.22295 (* 1 = 1.22295 loss)
I1210 17:10:31.668260 15772 solver.cpp:218] Iteration 108000 (14.1051 iter/s, 7.08962s/100 iters), loss = 0.285221
I1210 17:10:31.668260 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:10:31.668260 15772 solver.cpp:237]     Train net output #1: loss = 0.285221 (* 1 = 0.285221 loss)
I1210 17:10:31.668260 15772 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1210 17:10:37.322690 15772 solver.cpp:218] Iteration 108100 (17.6875 iter/s, 5.65371s/100 iters), loss = 0.373519
I1210 17:10:37.322690 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:10:37.322690 15772 solver.cpp:237]     Train net output #1: loss = 0.373519 (* 1 = 0.373519 loss)
I1210 17:10:37.322690 15772 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1210 17:10:42.976095 15772 solver.cpp:218] Iteration 108200 (17.6883 iter/s, 5.65347s/100 iters), loss = 0.285594
I1210 17:10:42.976095 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:10:42.976095 15772 solver.cpp:237]     Train net output #1: loss = 0.285594 (* 1 = 0.285594 loss)
I1210 17:10:42.976095 15772 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1210 17:10:48.624572 15772 solver.cpp:218] Iteration 108300 (17.7066 iter/s, 5.64761s/100 iters), loss = 0.307054
I1210 17:10:48.624572 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:10:48.624572 15772 solver.cpp:237]     Train net output #1: loss = 0.307054 (* 1 = 0.307054 loss)
I1210 17:10:48.624572 15772 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1210 17:10:54.259343 15772 solver.cpp:218] Iteration 108400 (17.7485 iter/s, 5.63429s/100 iters), loss = 0.399294
I1210 17:10:54.259343 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:10:54.259343 15772 solver.cpp:237]     Train net output #1: loss = 0.399293 (* 1 = 0.399293 loss)
I1210 17:10:54.259343 15772 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1210 17:10:59.633289 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:10:59.856410 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108500.caffemodel
I1210 17:10:59.870414 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108500.solverstate
I1210 17:10:59.901957 15772 solver.cpp:330] Iteration 108500, Testing net (#0)
I1210 17:10:59.901957 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:11:01.270689 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:11:01.323957 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6801
I1210 17:11:01.323957 15772 solver.cpp:397]     Test net output #1: loss = 1.21905 (* 1 = 1.21905 loss)
I1210 17:11:01.378219 15772 solver.cpp:218] Iteration 108500 (14.0469 iter/s, 7.119s/100 iters), loss = 0.286499
I1210 17:11:01.378219 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:11:01.378219 15772 solver.cpp:237]     Train net output #1: loss = 0.286499 (* 1 = 0.286499 loss)
I1210 17:11:01.378219 15772 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1210 17:11:07.014183 15772 solver.cpp:218] Iteration 108600 (17.7454 iter/s, 5.63525s/100 iters), loss = 0.396531
I1210 17:11:07.014183 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:11:07.014183 15772 solver.cpp:237]     Train net output #1: loss = 0.39653 (* 1 = 0.39653 loss)
I1210 17:11:07.014183 15772 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1210 17:11:12.659634 15772 solver.cpp:218] Iteration 108700 (17.7165 iter/s, 5.64447s/100 iters), loss = 0.259974
I1210 17:11:12.659634 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:11:12.659634 15772 solver.cpp:237]     Train net output #1: loss = 0.259974 (* 1 = 0.259974 loss)
I1210 17:11:12.659634 15772 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1210 17:11:18.310083 15772 solver.cpp:218] Iteration 108800 (17.6972 iter/s, 5.65061s/100 iters), loss = 0.350912
I1210 17:11:18.310083 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:11:18.310083 15772 solver.cpp:237]     Train net output #1: loss = 0.350912 (* 1 = 0.350912 loss)
I1210 17:11:18.310083 15772 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1210 17:11:23.956506 15772 solver.cpp:218] Iteration 108900 (17.713 iter/s, 5.64556s/100 iters), loss = 0.387718
I1210 17:11:23.956506 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:11:23.956506 15772 solver.cpp:237]     Train net output #1: loss = 0.387718 (* 1 = 0.387718 loss)
I1210 17:11:23.956506 15772 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1210 17:11:29.321964 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:11:29.544973 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109000.caffemodel
I1210 17:11:29.558974 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109000.solverstate
I1210 17:11:29.563477 15772 solver.cpp:330] Iteration 109000, Testing net (#0)
I1210 17:11:29.563977 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:11:30.931092 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:11:30.985123 15772 solver.cpp:397]     Test net output #0: accuracy = 0.682
I1210 17:11:30.985123 15772 solver.cpp:397]     Test net output #1: loss = 1.22636 (* 1 = 1.22636 loss)
I1210 17:11:31.038123 15772 solver.cpp:218] Iteration 109000 (14.1207 iter/s, 7.0818s/100 iters), loss = 0.250283
I1210 17:11:31.038123 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:11:31.039124 15772 solver.cpp:237]     Train net output #1: loss = 0.250283 (* 1 = 0.250283 loss)
I1210 17:11:31.039124 15772 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1210 17:11:36.672029 15772 solver.cpp:218] Iteration 109100 (17.7533 iter/s, 5.63277s/100 iters), loss = 0.416631
I1210 17:11:36.672529 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:11:36.672529 15772 solver.cpp:237]     Train net output #1: loss = 0.416631 (* 1 = 0.416631 loss)
I1210 17:11:36.672529 15772 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1210 17:11:42.308945 15772 solver.cpp:218] Iteration 109200 (17.7429 iter/s, 5.63605s/100 iters), loss = 0.331905
I1210 17:11:42.308945 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:11:42.308945 15772 solver.cpp:237]     Train net output #1: loss = 0.331904 (* 1 = 0.331904 loss)
I1210 17:11:42.308945 15772 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1210 17:11:47.953349 15772 solver.cpp:218] Iteration 109300 (17.7163 iter/s, 5.6445s/100 iters), loss = 0.349502
I1210 17:11:47.953349 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:11:47.953349 15772 solver.cpp:237]     Train net output #1: loss = 0.349502 (* 1 = 0.349502 loss)
I1210 17:11:47.953349 15772 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1210 17:11:53.585808 15772 solver.cpp:218] Iteration 109400 (17.7543 iter/s, 5.63243s/100 iters), loss = 0.377925
I1210 17:11:53.586804 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:11:53.586804 15772 solver.cpp:237]     Train net output #1: loss = 0.377925 (* 1 = 0.377925 loss)
I1210 17:11:53.586804 15772 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1210 17:11:58.937989 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:11:59.159049 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109500.caffemodel
I1210 17:11:59.175070 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109500.solverstate
I1210 17:11:59.202093 15772 solver.cpp:330] Iteration 109500, Testing net (#0)
I1210 17:11:59.202093 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:12:00.570626 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:12:00.623646 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6823
I1210 17:12:00.623646 15772 solver.cpp:397]     Test net output #1: loss = 1.22627 (* 1 = 1.22627 loss)
I1210 17:12:00.677156 15772 solver.cpp:218] Iteration 109500 (14.104 iter/s, 7.0902s/100 iters), loss = 0.288116
I1210 17:12:00.677156 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:12:00.677156 15772 solver.cpp:237]     Train net output #1: loss = 0.288116 (* 1 = 0.288116 loss)
I1210 17:12:00.677156 15772 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1210 17:12:06.314314 15772 solver.cpp:218] Iteration 109600 (17.7412 iter/s, 5.63658s/100 iters), loss = 0.3775
I1210 17:12:06.314314 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:12:06.314314 15772 solver.cpp:237]     Train net output #1: loss = 0.3775 (* 1 = 0.3775 loss)
I1210 17:12:06.314314 15772 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1210 17:12:11.952193 15772 solver.cpp:218] Iteration 109700 (17.7388 iter/s, 5.63737s/100 iters), loss = 0.358092
I1210 17:12:11.952193 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:12:11.952193 15772 solver.cpp:237]     Train net output #1: loss = 0.358091 (* 1 = 0.358091 loss)
I1210 17:12:11.952193 15772 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1210 17:12:17.597587 15772 solver.cpp:218] Iteration 109800 (17.7125 iter/s, 5.64574s/100 iters), loss = 0.339518
I1210 17:12:17.597587 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:12:17.597587 15772 solver.cpp:237]     Train net output #1: loss = 0.339518 (* 1 = 0.339518 loss)
I1210 17:12:17.597587 15772 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1210 17:12:23.240783 15772 solver.cpp:218] Iteration 109900 (17.7237 iter/s, 5.64216s/100 iters), loss = 0.364945
I1210 17:12:23.240783 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:12:23.240783 15772 solver.cpp:237]     Train net output #1: loss = 0.364945 (* 1 = 0.364945 loss)
I1210 17:12:23.240783 15772 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1210 17:12:28.600198 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:12:28.821208 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110000.caffemodel
I1210 17:12:28.836210 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110000.solverstate
I1210 17:12:28.869208 15772 solver.cpp:330] Iteration 110000, Testing net (#0)
I1210 17:12:28.869208 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:12:30.239291 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:12:30.293300 15772 solver.cpp:397]     Test net output #0: accuracy = 0.682
I1210 17:12:30.293300 15772 solver.cpp:397]     Test net output #1: loss = 1.23203 (* 1 = 1.23203 loss)
I1210 17:12:30.346295 15772 solver.cpp:218] Iteration 110000 (14.0742 iter/s, 7.10519s/100 iters), loss = 0.266582
I1210 17:12:30.346295 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:12:30.346295 15772 solver.cpp:237]     Train net output #1: loss = 0.266582 (* 1 = 0.266582 loss)
I1210 17:12:30.346295 15772 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1210 17:12:35.980751 15772 solver.cpp:218] Iteration 110100 (17.7497 iter/s, 5.6339s/100 iters), loss = 0.374178
I1210 17:12:35.980751 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:12:35.980751 15772 solver.cpp:237]     Train net output #1: loss = 0.374177 (* 1 = 0.374177 loss)
I1210 17:12:35.980751 15772 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1210 17:12:41.620420 15772 solver.cpp:218] Iteration 110200 (17.7309 iter/s, 5.63987s/100 iters), loss = 0.27753
I1210 17:12:41.620420 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:12:41.621421 15772 solver.cpp:237]     Train net output #1: loss = 0.27753 (* 1 = 0.27753 loss)
I1210 17:12:41.621421 15772 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1210 17:12:47.251802 15772 solver.cpp:218] Iteration 110300 (17.7604 iter/s, 5.6305s/100 iters), loss = 0.307884
I1210 17:12:47.251802 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:12:47.251802 15772 solver.cpp:237]     Train net output #1: loss = 0.307884 (* 1 = 0.307884 loss)
I1210 17:12:47.251802 15772 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1210 17:12:52.878239 15772 solver.cpp:218] Iteration 110400 (17.7762 iter/s, 5.62551s/100 iters), loss = 0.33325
I1210 17:12:52.878239 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:12:52.878239 15772 solver.cpp:237]     Train net output #1: loss = 0.333249 (* 1 = 0.333249 loss)
I1210 17:12:52.878239 15772 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1210 17:12:58.221691 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:12:58.443706 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110500.caffemodel
I1210 17:12:58.458705 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110500.solverstate
I1210 17:12:58.485219 15772 solver.cpp:330] Iteration 110500, Testing net (#0)
I1210 17:12:58.485718 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:12:59.853832 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:12:59.907835 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6782
I1210 17:12:59.907835 15772 solver.cpp:397]     Test net output #1: loss = 1.23635 (* 1 = 1.23635 loss)
I1210 17:12:59.960834 15772 solver.cpp:218] Iteration 110500 (14.1182 iter/s, 7.08304s/100 iters), loss = 0.283895
I1210 17:12:59.961835 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:12:59.961835 15772 solver.cpp:237]     Train net output #1: loss = 0.283895 (* 1 = 0.283895 loss)
I1210 17:12:59.961835 15772 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1210 17:13:05.593232 15772 solver.cpp:218] Iteration 110600 (17.7572 iter/s, 5.6315s/100 iters), loss = 0.347565
I1210 17:13:05.593232 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:13:05.593232 15772 solver.cpp:237]     Train net output #1: loss = 0.347565 (* 1 = 0.347565 loss)
I1210 17:13:05.593232 15772 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1210 17:13:11.220662 15772 solver.cpp:218] Iteration 110700 (17.773 iter/s, 5.62652s/100 iters), loss = 0.259098
I1210 17:13:11.220662 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:13:11.220662 15772 solver.cpp:237]     Train net output #1: loss = 0.259098 (* 1 = 0.259098 loss)
I1210 17:13:11.220662 15772 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1210 17:13:16.849692 15772 solver.cpp:218] Iteration 110800 (17.765 iter/s, 5.62905s/100 iters), loss = 0.49539
I1210 17:13:16.849692 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 17:13:16.849692 15772 solver.cpp:237]     Train net output #1: loss = 0.49539 (* 1 = 0.49539 loss)
I1210 17:13:16.849692 15772 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1210 17:13:22.483459 15772 solver.cpp:218] Iteration 110900 (17.7532 iter/s, 5.63278s/100 iters), loss = 0.36629
I1210 17:13:22.483459 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:13:22.483459 15772 solver.cpp:237]     Train net output #1: loss = 0.366289 (* 1 = 0.366289 loss)
I1210 17:13:22.483459 15772 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1210 17:13:27.864938 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:13:28.089519 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111000.caffemodel
I1210 17:13:28.104009 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111000.solverstate
I1210 17:13:28.108009 15772 solver.cpp:330] Iteration 111000, Testing net (#0)
I1210 17:13:28.108009 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:13:29.484238 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:13:29.537398 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6791
I1210 17:13:29.537398 15772 solver.cpp:397]     Test net output #1: loss = 1.23872 (* 1 = 1.23872 loss)
I1210 17:13:29.590893 15772 solver.cpp:218] Iteration 111000 (14.0704 iter/s, 7.10714s/100 iters), loss = 0.250112
I1210 17:13:29.590893 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:13:29.590893 15772 solver.cpp:237]     Train net output #1: loss = 0.250111 (* 1 = 0.250111 loss)
I1210 17:13:29.590893 15772 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1210 17:13:35.222877 15772 solver.cpp:218] Iteration 111100 (17.7572 iter/s, 5.63152s/100 iters), loss = 0.387242
I1210 17:13:35.222877 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:13:35.222877 15772 solver.cpp:237]     Train net output #1: loss = 0.387242 (* 1 = 0.387242 loss)
I1210 17:13:35.222877 15772 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1210 17:13:40.847669 15772 solver.cpp:218] Iteration 111200 (17.7803 iter/s, 5.62421s/100 iters), loss = 0.298054
I1210 17:13:40.847669 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:13:40.847669 15772 solver.cpp:237]     Train net output #1: loss = 0.298053 (* 1 = 0.298053 loss)
I1210 17:13:40.847669 15772 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1210 17:13:46.484663 15772 solver.cpp:218] Iteration 111300 (17.7412 iter/s, 5.63661s/100 iters), loss = 0.363471
I1210 17:13:46.484663 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:13:46.484663 15772 solver.cpp:237]     Train net output #1: loss = 0.36347 (* 1 = 0.36347 loss)
I1210 17:13:46.484663 15772 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1210 17:13:52.109122 15772 solver.cpp:218] Iteration 111400 (17.7817 iter/s, 5.62377s/100 iters), loss = 0.352012
I1210 17:13:52.109122 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:13:52.109122 15772 solver.cpp:237]     Train net output #1: loss = 0.352011 (* 1 = 0.352011 loss)
I1210 17:13:52.109122 15772 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1210 17:13:57.467869 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:13:57.688889 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111500.caffemodel
I1210 17:13:57.703893 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111500.solverstate
I1210 17:13:57.735894 15772 solver.cpp:330] Iteration 111500, Testing net (#0)
I1210 17:13:57.735894 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:13:59.105971 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:13:59.158969 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6796
I1210 17:13:59.158969 15772 solver.cpp:397]     Test net output #1: loss = 1.23546 (* 1 = 1.23546 loss)
I1210 17:13:59.211975 15772 solver.cpp:218] Iteration 111500 (14.0784 iter/s, 7.10308s/100 iters), loss = 0.186075
I1210 17:13:59.211975 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:13:59.211975 15772 solver.cpp:237]     Train net output #1: loss = 0.186075 (* 1 = 0.186075 loss)
I1210 17:13:59.211975 15772 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1210 17:14:04.838387 15772 solver.cpp:218] Iteration 111600 (17.775 iter/s, 5.62589s/100 iters), loss = 0.375806
I1210 17:14:04.838387 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:14:04.838387 15772 solver.cpp:237]     Train net output #1: loss = 0.375806 (* 1 = 0.375806 loss)
I1210 17:14:04.838387 15772 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1210 17:14:10.473814 15772 solver.cpp:218] Iteration 111700 (17.7476 iter/s, 5.63455s/100 iters), loss = 0.312937
I1210 17:14:10.473814 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:14:10.473814 15772 solver.cpp:237]     Train net output #1: loss = 0.312937 (* 1 = 0.312937 loss)
I1210 17:14:10.473814 15772 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1210 17:14:16.106259 15772 solver.cpp:218] Iteration 111800 (17.7546 iter/s, 5.63235s/100 iters), loss = 0.313103
I1210 17:14:16.106259 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:14:16.106259 15772 solver.cpp:237]     Train net output #1: loss = 0.313102 (* 1 = 0.313102 loss)
I1210 17:14:16.106259 15772 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1210 17:14:21.738680 15772 solver.cpp:218] Iteration 111900 (17.7565 iter/s, 5.63174s/100 iters), loss = 0.44664
I1210 17:14:21.738680 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 17:14:21.738680 15772 solver.cpp:237]     Train net output #1: loss = 0.446639 (* 1 = 0.446639 loss)
I1210 17:14:21.738680 15772 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1210 17:14:27.093080 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:14:27.315101 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112000.caffemodel
I1210 17:14:27.328101 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112000.solverstate
I1210 17:14:27.333101 15772 solver.cpp:330] Iteration 112000, Testing net (#0)
I1210 17:14:27.333101 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:14:28.704224 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:14:28.758224 15772 solver.cpp:397]     Test net output #0: accuracy = 0.678
I1210 17:14:28.758224 15772 solver.cpp:397]     Test net output #1: loss = 1.25378 (* 1 = 1.25378 loss)
I1210 17:14:28.813232 15772 solver.cpp:218] Iteration 112000 (14.1357 iter/s, 7.07431s/100 iters), loss = 0.264411
I1210 17:14:28.813232 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:14:28.813232 15772 solver.cpp:237]     Train net output #1: loss = 0.264411 (* 1 = 0.264411 loss)
I1210 17:14:28.813232 15772 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1210 17:14:34.450698 15772 solver.cpp:218] Iteration 112100 (17.7394 iter/s, 5.63716s/100 iters), loss = 0.38291
I1210 17:14:34.450698 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:14:34.450698 15772 solver.cpp:237]     Train net output #1: loss = 0.382909 (* 1 = 0.382909 loss)
I1210 17:14:34.450698 15772 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1210 17:14:40.081161 15772 solver.cpp:218] Iteration 112200 (17.7646 iter/s, 5.62917s/100 iters), loss = 0.306614
I1210 17:14:40.081161 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:14:40.081161 15772 solver.cpp:237]     Train net output #1: loss = 0.306614 (* 1 = 0.306614 loss)
I1210 17:14:40.081161 15772 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1210 17:14:45.706579 15772 solver.cpp:218] Iteration 112300 (17.7754 iter/s, 5.62575s/100 iters), loss = 0.292553
I1210 17:14:45.706579 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:14:45.706579 15772 solver.cpp:237]     Train net output #1: loss = 0.292552 (* 1 = 0.292552 loss)
I1210 17:14:45.706579 15772 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1210 17:14:51.332145 15772 solver.cpp:218] Iteration 112400 (17.7793 iter/s, 5.62451s/100 iters), loss = 0.318
I1210 17:14:51.332145 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:14:51.332145 15772 solver.cpp:237]     Train net output #1: loss = 0.318 (* 1 = 0.318 loss)
I1210 17:14:51.332145 15772 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1210 17:14:56.685585 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:14:56.907610 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112500.caffemodel
I1210 17:14:56.921610 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112500.solverstate
I1210 17:14:56.951611 15772 solver.cpp:330] Iteration 112500, Testing net (#0)
I1210 17:14:56.951611 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:14:58.318727 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:14:58.371726 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6811
I1210 17:14:58.371726 15772 solver.cpp:397]     Test net output #1: loss = 1.25055 (* 1 = 1.25055 loss)
I1210 17:14:58.424732 15772 solver.cpp:218] Iteration 112500 (14.0998 iter/s, 7.0923s/100 iters), loss = 0.31512
I1210 17:14:58.424732 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:14:58.424732 15772 solver.cpp:237]     Train net output #1: loss = 0.31512 (* 1 = 0.31512 loss)
I1210 17:14:58.424732 15772 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1210 17:15:04.040122 15772 solver.cpp:218] Iteration 112600 (17.8108 iter/s, 5.61458s/100 iters), loss = 0.346607
I1210 17:15:04.040122 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:15:04.040122 15772 solver.cpp:237]     Train net output #1: loss = 0.346607 (* 1 = 0.346607 loss)
I1210 17:15:04.040122 15772 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1210 17:15:09.659757 15772 solver.cpp:218] Iteration 112700 (17.7965 iter/s, 5.61909s/100 iters), loss = 0.34941
I1210 17:15:09.659757 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:15:09.659757 15772 solver.cpp:237]     Train net output #1: loss = 0.34941 (* 1 = 0.34941 loss)
I1210 17:15:09.659757 15772 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1210 17:15:15.288172 15772 solver.cpp:218] Iteration 112800 (17.7663 iter/s, 5.62865s/100 iters), loss = 0.355961
I1210 17:15:15.288172 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:15:15.288172 15772 solver.cpp:237]     Train net output #1: loss = 0.355961 (* 1 = 0.355961 loss)
I1210 17:15:15.288172 15772 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1210 17:15:20.908579 15772 solver.cpp:218] Iteration 112900 (17.7951 iter/s, 5.61951s/100 iters), loss = 0.418375
I1210 17:15:20.908579 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:15:20.908579 15772 solver.cpp:237]     Train net output #1: loss = 0.418375 (* 1 = 0.418375 loss)
I1210 17:15:20.908579 15772 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1210 17:15:26.248982 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:15:26.469990 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_113000.caffemodel
I1210 17:15:26.485991 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_113000.solverstate
I1210 17:15:26.489990 15772 solver.cpp:330] Iteration 113000, Testing net (#0)
I1210 17:15:26.489990 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:15:27.858086 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:15:27.913092 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6792
I1210 17:15:27.913092 15772 solver.cpp:397]     Test net output #1: loss = 1.25565 (* 1 = 1.25565 loss)
I1210 17:15:27.966091 15772 solver.cpp:218] Iteration 113000 (14.169 iter/s, 7.05766s/100 iters), loss = 0.300933
I1210 17:15:27.966091 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:15:27.966091 15772 solver.cpp:237]     Train net output #1: loss = 0.300933 (* 1 = 0.300933 loss)
I1210 17:15:27.966091 15772 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1210 17:15:33.599763 15772 solver.cpp:218] Iteration 113100 (17.7532 iter/s, 5.63279s/100 iters), loss = 0.348687
I1210 17:15:33.599763 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:15:33.599763 15772 solver.cpp:237]     Train net output #1: loss = 0.348687 (* 1 = 0.348687 loss)
I1210 17:15:33.599763 15772 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1210 17:15:39.230190 15772 solver.cpp:218] Iteration 113200 (17.7616 iter/s, 5.63012s/100 iters), loss = 0.350813
I1210 17:15:39.230190 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:15:39.230190 15772 solver.cpp:237]     Train net output #1: loss = 0.350812 (* 1 = 0.350812 loss)
I1210 17:15:39.230190 15772 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1210 17:15:44.869753 15772 solver.cpp:218] Iteration 113300 (17.7343 iter/s, 5.63879s/100 iters), loss = 0.371788
I1210 17:15:44.869753 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:15:44.869753 15772 solver.cpp:237]     Train net output #1: loss = 0.371788 (* 1 = 0.371788 loss)
I1210 17:15:44.869753 15772 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1210 17:15:50.495774 15772 solver.cpp:218] Iteration 113400 (17.7737 iter/s, 5.6263s/100 iters), loss = 0.295437
I1210 17:15:50.495774 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:15:50.495774 15772 solver.cpp:237]     Train net output #1: loss = 0.295436 (* 1 = 0.295436 loss)
I1210 17:15:50.495774 15772 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1210 17:15:55.850388 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:15:56.071384 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_113500.caffemodel
I1210 17:15:56.092384 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_113500.solverstate
I1210 17:15:56.096395 15772 solver.cpp:330] Iteration 113500, Testing net (#0)
I1210 17:15:56.096395 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:15:57.461083 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:15:57.514591 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6815
I1210 17:15:57.514591 15772 solver.cpp:397]     Test net output #1: loss = 1.23688 (* 1 = 1.23688 loss)
I1210 17:15:57.569105 15772 solver.cpp:218] Iteration 113500 (14.1394 iter/s, 7.07242s/100 iters), loss = 0.246318
I1210 17:15:57.569105 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:15:57.569105 15772 solver.cpp:237]     Train net output #1: loss = 0.246318 (* 1 = 0.246318 loss)
I1210 17:15:57.569105 15772 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1210 17:16:03.196591 15772 solver.cpp:218] Iteration 113600 (17.7699 iter/s, 5.62748s/100 iters), loss = 0.342953
I1210 17:16:03.196591 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:16:03.196591 15772 solver.cpp:237]     Train net output #1: loss = 0.342953 (* 1 = 0.342953 loss)
I1210 17:16:03.196591 15772 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1210 17:16:08.812191 15772 solver.cpp:218] Iteration 113700 (17.8117 iter/s, 5.6143s/100 iters), loss = 0.271251
I1210 17:16:08.812191 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:16:08.812191 15772 solver.cpp:237]     Train net output #1: loss = 0.271251 (* 1 = 0.271251 loss)
I1210 17:16:08.812191 15772 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1210 17:16:14.436583 15772 solver.cpp:218] Iteration 113800 (17.7803 iter/s, 5.6242s/100 iters), loss = 0.26689
I1210 17:16:14.436583 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 17:16:14.436583 15772 solver.cpp:237]     Train net output #1: loss = 0.26689 (* 1 = 0.26689 loss)
I1210 17:16:14.436583 15772 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1210 17:16:20.056987 15772 solver.cpp:218] Iteration 113900 (17.7915 iter/s, 5.62065s/100 iters), loss = 0.309252
I1210 17:16:20.057986 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:16:20.057986 15772 solver.cpp:237]     Train net output #1: loss = 0.309252 (* 1 = 0.309252 loss)
I1210 17:16:20.057986 15772 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1210 17:16:25.419968 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:16:25.639483 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_114000.caffemodel
I1210 17:16:25.653483 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_114000.solverstate
I1210 17:16:25.658484 15772 solver.cpp:330] Iteration 114000, Testing net (#0)
I1210 17:16:25.658484 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:16:27.028127 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:16:27.081630 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6776
I1210 17:16:27.081630 15772 solver.cpp:397]     Test net output #1: loss = 1.24872 (* 1 = 1.24872 loss)
I1210 17:16:27.134634 15772 solver.cpp:218] Iteration 114000 (14.1312 iter/s, 7.07653s/100 iters), loss = 0.231489
I1210 17:16:27.134634 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:16:27.134634 15772 solver.cpp:237]     Train net output #1: loss = 0.231489 (* 1 = 0.231489 loss)
I1210 17:16:27.134634 15772 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1210 17:16:32.752970 15772 solver.cpp:218] Iteration 114100 (17.8013 iter/s, 5.61758s/100 iters), loss = 0.258568
I1210 17:16:32.752970 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:16:32.752970 15772 solver.cpp:237]     Train net output #1: loss = 0.258567 (* 1 = 0.258567 loss)
I1210 17:16:32.752970 15772 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1210 17:16:38.370380 15772 solver.cpp:218] Iteration 114200 (17.8015 iter/s, 5.61749s/100 iters), loss = 0.373421
I1210 17:16:38.370380 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:16:38.370380 15772 solver.cpp:237]     Train net output #1: loss = 0.373421 (* 1 = 0.373421 loss)
I1210 17:16:38.370380 15772 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1210 17:16:43.985739 15772 solver.cpp:218] Iteration 114300 (17.811 iter/s, 5.6145s/100 iters), loss = 0.31956
I1210 17:16:43.985739 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:16:43.985739 15772 solver.cpp:237]     Train net output #1: loss = 0.31956 (* 1 = 0.31956 loss)
I1210 17:16:43.985739 15772 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1210 17:16:49.608156 15772 solver.cpp:218] Iteration 114400 (17.7866 iter/s, 5.62221s/100 iters), loss = 0.372152
I1210 17:16:49.608156 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:16:49.608156 15772 solver.cpp:237]     Train net output #1: loss = 0.372151 (* 1 = 0.372151 loss)
I1210 17:16:49.608156 15772 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1210 17:16:54.956593 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:16:55.176607 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_114500.caffemodel
I1210 17:16:55.218118 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_114500.solverstate
I1210 17:16:55.223110 15772 solver.cpp:330] Iteration 114500, Testing net (#0)
I1210 17:16:55.223110 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:16:56.589697 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:16:56.643707 15772 solver.cpp:397]     Test net output #0: accuracy = 0.678
I1210 17:16:56.643707 15772 solver.cpp:397]     Test net output #1: loss = 1.25686 (* 1 = 1.25686 loss)
I1210 17:16:56.695706 15772 solver.cpp:218] Iteration 114500 (14.1093 iter/s, 7.08751s/100 iters), loss = 0.25691
I1210 17:16:56.696707 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:16:56.696707 15772 solver.cpp:237]     Train net output #1: loss = 0.256909 (* 1 = 0.256909 loss)
I1210 17:16:56.696707 15772 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1210 17:17:02.323699 15772 solver.cpp:218] Iteration 114600 (17.7723 iter/s, 5.62674s/100 iters), loss = 0.363611
I1210 17:17:02.323699 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:17:02.323699 15772 solver.cpp:237]     Train net output #1: loss = 0.363611 (* 1 = 0.363611 loss)
I1210 17:17:02.323699 15772 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1210 17:17:07.963673 15772 solver.cpp:218] Iteration 114700 (17.7327 iter/s, 5.6393s/100 iters), loss = 0.298645
I1210 17:17:07.963673 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:17:07.963673 15772 solver.cpp:237]     Train net output #1: loss = 0.298645 (* 1 = 0.298645 loss)
I1210 17:17:07.963673 15772 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1210 17:17:13.589121 15772 solver.cpp:218] Iteration 114800 (17.7775 iter/s, 5.62508s/100 iters), loss = 0.29769
I1210 17:17:13.589121 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:17:13.589121 15772 solver.cpp:237]     Train net output #1: loss = 0.29769 (* 1 = 0.29769 loss)
I1210 17:17:13.589121 15772 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1210 17:17:19.215603 15772 solver.cpp:218] Iteration 114900 (17.7727 iter/s, 5.62661s/100 iters), loss = 0.265506
I1210 17:17:19.215603 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:17:19.215603 15772 solver.cpp:237]     Train net output #1: loss = 0.265505 (* 1 = 0.265505 loss)
I1210 17:17:19.215603 15772 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1210 17:17:24.573184 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:17:24.796191 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_115000.caffemodel
I1210 17:17:24.812191 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_115000.solverstate
I1210 17:17:24.816191 15772 solver.cpp:330] Iteration 115000, Testing net (#0)
I1210 17:17:24.816191 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:17:26.188355 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:17:26.241361 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6796
I1210 17:17:26.241361 15772 solver.cpp:397]     Test net output #1: loss = 1.24906 (* 1 = 1.24906 loss)
I1210 17:17:26.296360 15772 solver.cpp:218] Iteration 115000 (14.1245 iter/s, 7.07988s/100 iters), loss = 0.238538
I1210 17:17:26.296360 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:17:26.296360 15772 solver.cpp:237]     Train net output #1: loss = 0.238538 (* 1 = 0.238538 loss)
I1210 17:17:26.296360 15772 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1210 17:17:31.916860 15772 solver.cpp:218] Iteration 115100 (17.7937 iter/s, 5.61997s/100 iters), loss = 0.36159
I1210 17:17:31.916860 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:17:31.916860 15772 solver.cpp:237]     Train net output #1: loss = 0.36159 (* 1 = 0.36159 loss)
I1210 17:17:31.916860 15772 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1210 17:17:37.540864 15772 solver.cpp:218] Iteration 115200 (17.7834 iter/s, 5.62321s/100 iters), loss = 0.259349
I1210 17:17:37.540864 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:17:37.540864 15772 solver.cpp:237]     Train net output #1: loss = 0.259349 (* 1 = 0.259349 loss)
I1210 17:17:37.540864 15772 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1210 17:17:43.172412 15772 solver.cpp:218] Iteration 115300 (17.756 iter/s, 5.63191s/100 iters), loss = 0.347902
I1210 17:17:43.172412 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:17:43.172412 15772 solver.cpp:237]     Train net output #1: loss = 0.347901 (* 1 = 0.347901 loss)
I1210 17:17:43.172412 15772 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1210 17:17:48.796031 15772 solver.cpp:218] Iteration 115400 (17.7859 iter/s, 5.62242s/100 iters), loss = 0.400075
I1210 17:17:48.796031 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:17:48.796031 15772 solver.cpp:237]     Train net output #1: loss = 0.400074 (* 1 = 0.400074 loss)
I1210 17:17:48.796031 15772 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1210 17:17:54.164098 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:17:54.384201 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_115500.caffemodel
I1210 17:17:54.426204 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_115500.solverstate
I1210 17:17:54.430729 15772 solver.cpp:330] Iteration 115500, Testing net (#0)
I1210 17:17:54.430729 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:17:55.799976 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:17:55.853587 15772 solver.cpp:397]     Test net output #0: accuracy = 0.683
I1210 17:17:55.853587 15772 solver.cpp:397]     Test net output #1: loss = 1.24163 (* 1 = 1.24163 loss)
I1210 17:17:55.907567 15772 solver.cpp:218] Iteration 115500 (14.0613 iter/s, 7.11174s/100 iters), loss = 0.247905
I1210 17:17:55.907567 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:17:55.907567 15772 solver.cpp:237]     Train net output #1: loss = 0.247905 (* 1 = 0.247905 loss)
I1210 17:17:55.907567 15772 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1210 17:18:01.535693 15772 solver.cpp:218] Iteration 115600 (17.7705 iter/s, 5.62731s/100 iters), loss = 0.35901
I1210 17:18:01.536198 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:18:01.536198 15772 solver.cpp:237]     Train net output #1: loss = 0.359009 (* 1 = 0.359009 loss)
I1210 17:18:01.536198 15772 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1210 17:18:07.166055 15772 solver.cpp:218] Iteration 115700 (17.7622 iter/s, 5.62994s/100 iters), loss = 0.281679
I1210 17:18:07.166055 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:18:07.166055 15772 solver.cpp:237]     Train net output #1: loss = 0.281678 (* 1 = 0.281678 loss)
I1210 17:18:07.166055 15772 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1210 17:18:12.798472 15772 solver.cpp:218] Iteration 115800 (17.7573 iter/s, 5.6315s/100 iters), loss = 0.388895
I1210 17:18:12.798472 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:18:12.798472 15772 solver.cpp:237]     Train net output #1: loss = 0.388895 (* 1 = 0.388895 loss)
I1210 17:18:12.798472 15772 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1210 17:18:18.431910 15772 solver.cpp:218] Iteration 115900 (17.7514 iter/s, 5.63336s/100 iters), loss = 0.287551
I1210 17:18:18.431910 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:18:18.431910 15772 solver.cpp:237]     Train net output #1: loss = 0.287551 (* 1 = 0.287551 loss)
I1210 17:18:18.431910 15772 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1210 17:18:23.787295 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:18:24.010305 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_116000.caffemodel
I1210 17:18:24.027310 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_116000.solverstate
I1210 17:18:24.033305 15772 solver.cpp:330] Iteration 116000, Testing net (#0)
I1210 17:18:24.033305 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:18:25.404425 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:18:25.458431 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6822
I1210 17:18:25.458431 15772 solver.cpp:397]     Test net output #1: loss = 1.25514 (* 1 = 1.25514 loss)
I1210 17:18:25.512429 15772 solver.cpp:218] Iteration 116000 (14.1247 iter/s, 7.07982s/100 iters), loss = 0.28936
I1210 17:18:25.512429 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:18:25.512429 15772 solver.cpp:237]     Train net output #1: loss = 0.28936 (* 1 = 0.28936 loss)
I1210 17:18:25.512429 15772 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1210 17:18:31.161875 15772 solver.cpp:218] Iteration 116100 (17.7016 iter/s, 5.64921s/100 iters), loss = 0.342445
I1210 17:18:31.161875 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:18:31.161875 15772 solver.cpp:237]     Train net output #1: loss = 0.342445 (* 1 = 0.342445 loss)
I1210 17:18:31.161875 15772 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1210 17:18:36.810282 15772 solver.cpp:218] Iteration 116200 (17.7062 iter/s, 5.64774s/100 iters), loss = 0.27886
I1210 17:18:36.810282 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:18:36.810282 15772 solver.cpp:237]     Train net output #1: loss = 0.27886 (* 1 = 0.27886 loss)
I1210 17:18:36.810282 15772 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1210 17:18:42.460775 15772 solver.cpp:218] Iteration 116300 (17.699 iter/s, 5.65002s/100 iters), loss = 0.333235
I1210 17:18:42.460775 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:18:42.460775 15772 solver.cpp:237]     Train net output #1: loss = 0.333235 (* 1 = 0.333235 loss)
I1210 17:18:42.460775 15772 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1210 17:18:48.114200 15772 solver.cpp:218] Iteration 116400 (17.6883 iter/s, 5.65345s/100 iters), loss = 0.290539
I1210 17:18:48.114200 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:18:48.114200 15772 solver.cpp:237]     Train net output #1: loss = 0.290539 (* 1 = 0.290539 loss)
I1210 17:18:48.114200 15772 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1210 17:18:53.484603 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:18:53.706619 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_116500.caffemodel
I1210 17:18:53.750634 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_116500.solverstate
I1210 17:18:53.754637 15772 solver.cpp:330] Iteration 116500, Testing net (#0)
I1210 17:18:53.754637 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:18:55.125768 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:18:55.177776 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6807
I1210 17:18:55.177776 15772 solver.cpp:397]     Test net output #1: loss = 1.25701 (* 1 = 1.25701 loss)
I1210 17:18:55.230777 15772 solver.cpp:218] Iteration 116500 (14.0523 iter/s, 7.11629s/100 iters), loss = 0.250495
I1210 17:18:55.230777 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:18:55.230777 15772 solver.cpp:237]     Train net output #1: loss = 0.250495 (* 1 = 0.250495 loss)
I1210 17:18:55.230777 15772 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1210 17:19:00.872269 15772 solver.cpp:218] Iteration 116600 (17.7282 iter/s, 5.64073s/100 iters), loss = 0.392848
I1210 17:19:00.872269 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:19:00.872269 15772 solver.cpp:237]     Train net output #1: loss = 0.392848 (* 1 = 0.392848 loss)
I1210 17:19:00.872269 15772 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1210 17:19:06.516736 15772 solver.cpp:218] Iteration 116700 (17.7188 iter/s, 5.64372s/100 iters), loss = 0.288433
I1210 17:19:06.516736 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:19:06.516736 15772 solver.cpp:237]     Train net output #1: loss = 0.288432 (* 1 = 0.288432 loss)
I1210 17:19:06.516736 15772 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1210 17:19:12.148267 15772 solver.cpp:218] Iteration 116800 (17.7585 iter/s, 5.6311s/100 iters), loss = 0.299805
I1210 17:19:12.148267 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:19:12.148267 15772 solver.cpp:237]     Train net output #1: loss = 0.299804 (* 1 = 0.299804 loss)
I1210 17:19:12.148267 15772 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1210 17:19:17.776692 15772 solver.cpp:218] Iteration 116900 (17.7664 iter/s, 5.6286s/100 iters), loss = 0.402262
I1210 17:19:17.776692 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:19:17.776692 15772 solver.cpp:237]     Train net output #1: loss = 0.402261 (* 1 = 0.402261 loss)
I1210 17:19:17.776692 15772 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1210 17:19:23.142622 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:19:23.364151 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_117000.caffemodel
I1210 17:19:23.401139 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_117000.solverstate
I1210 17:19:23.407141 15772 solver.cpp:330] Iteration 117000, Testing net (#0)
I1210 17:19:23.407141 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:19:24.775218 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:19:24.829217 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6791
I1210 17:19:24.829217 15772 solver.cpp:397]     Test net output #1: loss = 1.26957 (* 1 = 1.26957 loss)
I1210 17:19:24.883220 15772 solver.cpp:218] Iteration 117000 (14.0735 iter/s, 7.10556s/100 iters), loss = 0.16571
I1210 17:19:24.883220 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 17:19:24.883220 15772 solver.cpp:237]     Train net output #1: loss = 0.16571 (* 1 = 0.16571 loss)
I1210 17:19:24.883220 15772 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1210 17:19:30.516654 15772 solver.cpp:218] Iteration 117100 (17.7508 iter/s, 5.63355s/100 iters), loss = 0.384552
I1210 17:19:30.516654 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:19:30.516654 15772 solver.cpp:237]     Train net output #1: loss = 0.384552 (* 1 = 0.384552 loss)
I1210 17:19:30.516654 15772 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1210 17:19:36.155023 15772 solver.cpp:218] Iteration 117200 (17.7392 iter/s, 5.63722s/100 iters), loss = 0.260187
I1210 17:19:36.155023 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:19:36.155023 15772 solver.cpp:237]     Train net output #1: loss = 0.260187 (* 1 = 0.260187 loss)
I1210 17:19:36.155023 15772 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1210 17:19:41.784538 15772 solver.cpp:218] Iteration 117300 (17.7645 iter/s, 5.62921s/100 iters), loss = 0.302353
I1210 17:19:41.784538 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:19:41.784538 15772 solver.cpp:237]     Train net output #1: loss = 0.302352 (* 1 = 0.302352 loss)
I1210 17:19:41.784538 15772 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1210 17:19:47.423115 15772 solver.cpp:218] Iteration 117400 (17.7371 iter/s, 5.6379s/100 iters), loss = 0.364711
I1210 17:19:47.423115 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:19:47.423115 15772 solver.cpp:237]     Train net output #1: loss = 0.364711 (* 1 = 0.364711 loss)
I1210 17:19:47.423115 15772 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1210 17:19:52.766552 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:19:52.987762 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_117500.caffemodel
I1210 17:19:53.002272 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_117500.solverstate
I1210 17:19:53.006778 15772 solver.cpp:330] Iteration 117500, Testing net (#0)
I1210 17:19:53.006778 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:19:54.378298 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:19:54.431354 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6784
I1210 17:19:54.432358 15772 solver.cpp:397]     Test net output #1: loss = 1.26094 (* 1 = 1.26094 loss)
I1210 17:19:54.485342 15772 solver.cpp:218] Iteration 117500 (14.1593 iter/s, 7.06247s/100 iters), loss = 0.268384
I1210 17:19:54.485342 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:19:54.485342 15772 solver.cpp:237]     Train net output #1: loss = 0.268384 (* 1 = 0.268384 loss)
I1210 17:19:54.485342 15772 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1210 17:20:00.120662 15772 solver.cpp:218] Iteration 117600 (17.7461 iter/s, 5.63505s/100 iters), loss = 0.369023
I1210 17:20:00.120662 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:20:00.121660 15772 solver.cpp:237]     Train net output #1: loss = 0.369023 (* 1 = 0.369023 loss)
I1210 17:20:00.121660 15772 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1210 17:20:05.764178 15772 solver.cpp:218] Iteration 117700 (17.7212 iter/s, 5.64297s/100 iters), loss = 0.291302
I1210 17:20:05.764178 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:20:05.764178 15772 solver.cpp:237]     Train net output #1: loss = 0.291301 (* 1 = 0.291301 loss)
I1210 17:20:05.764178 15772 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1210 17:20:11.408218 15772 solver.cpp:218] Iteration 117800 (17.7216 iter/s, 5.64282s/100 iters), loss = 0.351755
I1210 17:20:11.408218 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:20:11.408218 15772 solver.cpp:237]     Train net output #1: loss = 0.351754 (* 1 = 0.351754 loss)
I1210 17:20:11.408218 15772 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1210 17:20:17.041544 15772 solver.cpp:218] Iteration 117900 (17.7534 iter/s, 5.63273s/100 iters), loss = 0.265509
I1210 17:20:17.041544 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:20:17.041544 15772 solver.cpp:237]     Train net output #1: loss = 0.265509 (* 1 = 0.265509 loss)
I1210 17:20:17.041544 15772 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1210 17:20:22.402843 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:20:22.623359 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_118000.caffemodel
I1210 17:20:22.637877 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_118000.solverstate
I1210 17:20:22.668876 15772 solver.cpp:330] Iteration 118000, Testing net (#0)
I1210 17:20:22.668876 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:20:24.038962 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:20:24.092947 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6823
I1210 17:20:24.092947 15772 solver.cpp:397]     Test net output #1: loss = 1.26424 (* 1 = 1.26424 loss)
I1210 17:20:24.145972 15772 solver.cpp:218] Iteration 118000 (14.0757 iter/s, 7.10444s/100 iters), loss = 0.206977
I1210 17:20:24.145972 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:20:24.145972 15772 solver.cpp:237]     Train net output #1: loss = 0.206977 (* 1 = 0.206977 loss)
I1210 17:20:24.145972 15772 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1210 17:20:29.795182 15772 solver.cpp:218] Iteration 118100 (17.7045 iter/s, 5.64828s/100 iters), loss = 0.334348
I1210 17:20:29.795182 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:20:29.795182 15772 solver.cpp:237]     Train net output #1: loss = 0.334348 (* 1 = 0.334348 loss)
I1210 17:20:29.795182 15772 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1210 17:20:35.434715 15772 solver.cpp:218] Iteration 118200 (17.7309 iter/s, 5.63987s/100 iters), loss = 0.366189
I1210 17:20:35.434715 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:20:35.434715 15772 solver.cpp:237]     Train net output #1: loss = 0.366188 (* 1 = 0.366188 loss)
I1210 17:20:35.435717 15772 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1210 17:20:41.080124 15772 solver.cpp:218] Iteration 118300 (17.7151 iter/s, 5.6449s/100 iters), loss = 0.34076
I1210 17:20:41.080124 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:20:41.080124 15772 solver.cpp:237]     Train net output #1: loss = 0.340759 (* 1 = 0.340759 loss)
I1210 17:20:41.080124 15772 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1210 17:20:46.716591 15772 solver.cpp:218] Iteration 118400 (17.7448 iter/s, 5.63546s/100 iters), loss = 0.36284
I1210 17:20:46.716591 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:20:46.716591 15772 solver.cpp:237]     Train net output #1: loss = 0.362839 (* 1 = 0.362839 loss)
I1210 17:20:46.716591 15772 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1210 17:20:52.084097 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:20:52.306125 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_118500.caffemodel
I1210 17:20:52.322130 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_118500.solverstate
I1210 17:20:52.327131 15772 solver.cpp:330] Iteration 118500, Testing net (#0)
I1210 17:20:52.327131 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:20:53.697223 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:20:53.750226 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6784
I1210 17:20:53.750226 15772 solver.cpp:397]     Test net output #1: loss = 1.26683 (* 1 = 1.26683 loss)
I1210 17:20:53.804229 15772 solver.cpp:218] Iteration 118500 (14.1092 iter/s, 7.08756s/100 iters), loss = 0.195084
I1210 17:20:53.804229 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 17:20:53.804229 15772 solver.cpp:237]     Train net output #1: loss = 0.195084 (* 1 = 0.195084 loss)
I1210 17:20:53.804229 15772 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1210 17:20:59.439170 15772 solver.cpp:218] Iteration 118600 (17.7478 iter/s, 5.6345s/100 iters), loss = 0.388265
I1210 17:20:59.439170 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:20:59.439170 15772 solver.cpp:237]     Train net output #1: loss = 0.388265 (* 1 = 0.388265 loss)
I1210 17:20:59.440171 15772 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1210 17:21:05.072512 15772 solver.cpp:218] Iteration 118700 (17.7558 iter/s, 5.63198s/100 iters), loss = 0.253818
I1210 17:21:05.072512 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:21:05.072512 15772 solver.cpp:237]     Train net output #1: loss = 0.253818 (* 1 = 0.253818 loss)
I1210 17:21:05.072512 15772 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1210 17:21:10.704223 15772 solver.cpp:218] Iteration 118800 (17.7559 iter/s, 5.63192s/100 iters), loss = 0.362448
I1210 17:21:10.704223 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 17:21:10.704223 15772 solver.cpp:237]     Train net output #1: loss = 0.362448 (* 1 = 0.362448 loss)
I1210 17:21:10.704223 15772 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1210 17:21:16.336432 15772 solver.cpp:218] Iteration 118900 (17.7584 iter/s, 5.63114s/100 iters), loss = 0.303861
I1210 17:21:16.336432 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:21:16.336432 15772 solver.cpp:237]     Train net output #1: loss = 0.303861 (* 1 = 0.303861 loss)
I1210 17:21:16.336432 15772 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1210 17:21:21.692658 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:21:21.916779 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_119000.caffemodel
I1210 17:21:21.930778 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_119000.solverstate
I1210 17:21:21.960376 15772 solver.cpp:330] Iteration 119000, Testing net (#0)
I1210 17:21:21.960376 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:21:23.329506 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:21:23.383519 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6812
I1210 17:21:23.383519 15772 solver.cpp:397]     Test net output #1: loss = 1.2698 (* 1 = 1.2698 loss)
I1210 17:21:23.436517 15772 solver.cpp:218] Iteration 119000 (14.0848 iter/s, 7.09986s/100 iters), loss = 0.241042
I1210 17:21:23.436517 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:21:23.436517 15772 solver.cpp:237]     Train net output #1: loss = 0.241042 (* 1 = 0.241042 loss)
I1210 17:21:23.436517 15772 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1210 17:21:29.058389 15772 solver.cpp:218] Iteration 119100 (17.7883 iter/s, 5.62169s/100 iters), loss = 0.349792
I1210 17:21:29.058389 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:21:29.058389 15772 solver.cpp:237]     Train net output #1: loss = 0.349792 (* 1 = 0.349792 loss)
I1210 17:21:29.058389 15772 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1210 17:21:34.692934 15772 solver.cpp:218] Iteration 119200 (17.7493 iter/s, 5.63404s/100 iters), loss = 0.249839
I1210 17:21:34.692934 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:21:34.692934 15772 solver.cpp:237]     Train net output #1: loss = 0.249838 (* 1 = 0.249838 loss)
I1210 17:21:34.692934 15772 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1210 17:21:40.323359 15772 solver.cpp:218] Iteration 119300 (17.7636 iter/s, 5.62948s/100 iters), loss = 0.248723
I1210 17:21:40.323359 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:21:40.323359 15772 solver.cpp:237]     Train net output #1: loss = 0.248723 (* 1 = 0.248723 loss)
I1210 17:21:40.323359 15772 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1210 17:21:45.964633 15772 solver.cpp:218] Iteration 119400 (17.7275 iter/s, 5.64094s/100 iters), loss = 0.35938
I1210 17:21:45.964633 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:21:45.964633 15772 solver.cpp:237]     Train net output #1: loss = 0.35938 (* 1 = 0.35938 loss)
I1210 17:21:45.964633 15772 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1210 17:21:51.322216 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:21:51.543229 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_119500.caffemodel
I1210 17:21:51.557234 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_119500.solverstate
I1210 17:21:51.562234 15772 solver.cpp:330] Iteration 119500, Testing net (#0)
I1210 17:21:51.562234 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:21:52.933378 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:21:52.988394 15772 solver.cpp:397]     Test net output #0: accuracy = 0.676
I1210 17:21:52.988394 15772 solver.cpp:397]     Test net output #1: loss = 1.2852 (* 1 = 1.2852 loss)
I1210 17:21:53.041394 15772 solver.cpp:218] Iteration 119500 (14.1315 iter/s, 7.07638s/100 iters), loss = 0.262184
I1210 17:21:53.041394 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:21:53.041394 15772 solver.cpp:237]     Train net output #1: loss = 0.262183 (* 1 = 0.262183 loss)
I1210 17:21:53.041394 15772 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1210 17:21:58.696828 15772 solver.cpp:218] Iteration 119600 (17.6823 iter/s, 5.65536s/100 iters), loss = 0.387341
I1210 17:21:58.697829 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:21:58.697829 15772 solver.cpp:237]     Train net output #1: loss = 0.387341 (* 1 = 0.387341 loss)
I1210 17:21:58.697829 15772 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1210 17:22:04.353246 15772 solver.cpp:218] Iteration 119700 (17.6832 iter/s, 5.65507s/100 iters), loss = 0.282147
I1210 17:22:04.353246 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:22:04.353246 15772 solver.cpp:237]     Train net output #1: loss = 0.282147 (* 1 = 0.282147 loss)
I1210 17:22:04.353246 15772 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1210 17:22:10.006309 15772 solver.cpp:218] Iteration 119800 (17.6911 iter/s, 5.65257s/100 iters), loss = 0.280109
I1210 17:22:10.006309 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:22:10.006309 15772 solver.cpp:237]     Train net output #1: loss = 0.280109 (* 1 = 0.280109 loss)
I1210 17:22:10.006309 15772 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1210 17:22:15.663053 15772 solver.cpp:218] Iteration 119900 (17.6788 iter/s, 5.65648s/100 iters), loss = 0.26798
I1210 17:22:15.663053 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:22:15.663053 15772 solver.cpp:237]     Train net output #1: loss = 0.26798 (* 1 = 0.26798 loss)
I1210 17:22:15.663053 15772 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1210 17:22:21.038460 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:22:21.262475 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_120000.caffemodel
I1210 17:22:21.275482 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_120000.solverstate
I1210 17:22:21.302482 15772 solver.cpp:330] Iteration 120000, Testing net (#0)
I1210 17:22:21.302482 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:22:22.671592 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:22:22.725592 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6775
I1210 17:22:22.725592 15772 solver.cpp:397]     Test net output #1: loss = 1.27734 (* 1 = 1.27734 loss)
I1210 17:22:22.778622 15772 solver.cpp:218] Iteration 120000 (14.0539 iter/s, 7.11548s/100 iters), loss = 0.269128
I1210 17:22:22.778622 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:22:22.778622 15772 solver.cpp:237]     Train net output #1: loss = 0.269128 (* 1 = 0.269128 loss)
I1210 17:22:22.778622 15772 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1210 17:22:28.420017 15772 solver.cpp:218] Iteration 120100 (17.7283 iter/s, 5.6407s/100 iters), loss = 0.391176
I1210 17:22:28.420017 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:22:28.420017 15772 solver.cpp:237]     Train net output #1: loss = 0.391176 (* 1 = 0.391176 loss)
I1210 17:22:28.420017 15772 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1210 17:22:34.054527 15772 solver.cpp:218] Iteration 120200 (17.7501 iter/s, 5.63376s/100 iters), loss = 0.295753
I1210 17:22:34.054527 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:22:34.054527 15772 solver.cpp:237]     Train net output #1: loss = 0.295753 (* 1 = 0.295753 loss)
I1210 17:22:34.054527 15772 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1210 17:22:39.697993 15772 solver.cpp:218] Iteration 120300 (17.7197 iter/s, 5.64344s/100 iters), loss = 0.287417
I1210 17:22:39.697993 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:22:39.697993 15772 solver.cpp:237]     Train net output #1: loss = 0.287417 (* 1 = 0.287417 loss)
I1210 17:22:39.697993 15772 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1210 17:22:45.334563 15772 solver.cpp:218] Iteration 120400 (17.7419 iter/s, 5.63637s/100 iters), loss = 0.316711
I1210 17:22:45.334563 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:22:45.334563 15772 solver.cpp:237]     Train net output #1: loss = 0.31671 (* 1 = 0.31671 loss)
I1210 17:22:45.334563 15772 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1210 17:22:50.694927 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:22:50.916939 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_120500.caffemodel
I1210 17:22:50.930938 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_120500.solverstate
I1210 17:22:50.934938 15772 solver.cpp:330] Iteration 120500, Testing net (#0)
I1210 17:22:50.935940 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:22:52.307031 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:22:52.361029 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6765
I1210 17:22:52.361029 15772 solver.cpp:397]     Test net output #1: loss = 1.29743 (* 1 = 1.29743 loss)
I1210 17:22:52.415040 15772 solver.cpp:218] Iteration 120500 (14.1256 iter/s, 7.07935s/100 iters), loss = 0.2399
I1210 17:22:52.415040 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:22:52.415040 15772 solver.cpp:237]     Train net output #1: loss = 0.2399 (* 1 = 0.2399 loss)
I1210 17:22:52.415040 15772 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1210 17:22:58.055464 15772 solver.cpp:218] Iteration 120600 (17.73 iter/s, 5.64016s/100 iters), loss = 0.325485
I1210 17:22:58.055968 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:22:58.055968 15772 solver.cpp:237]     Train net output #1: loss = 0.325485 (* 1 = 0.325485 loss)
I1210 17:22:58.055968 15772 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1210 17:23:03.700670 15772 solver.cpp:218] Iteration 120700 (17.7169 iter/s, 5.64431s/100 iters), loss = 0.27044
I1210 17:23:03.700670 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 17:23:03.700670 15772 solver.cpp:237]     Train net output #1: loss = 0.27044 (* 1 = 0.27044 loss)
I1210 17:23:03.700670 15772 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1210 17:23:09.330572 15772 solver.cpp:218] Iteration 120800 (17.7622 iter/s, 5.62992s/100 iters), loss = 0.290874
I1210 17:23:09.330572 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:23:09.330572 15772 solver.cpp:237]     Train net output #1: loss = 0.290874 (* 1 = 0.290874 loss)
I1210 17:23:09.330572 15772 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1210 17:23:14.967803 15772 solver.cpp:218] Iteration 120900 (17.7411 iter/s, 5.63662s/100 iters), loss = 0.315944
I1210 17:23:14.967803 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:23:14.968304 15772 solver.cpp:237]     Train net output #1: loss = 0.315944 (* 1 = 0.315944 loss)
I1210 17:23:14.968304 15772 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1210 17:23:20.332677 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:23:20.554329 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_121000.caffemodel
I1210 17:23:20.569335 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_121000.solverstate
I1210 17:23:20.573835 15772 solver.cpp:330] Iteration 121000, Testing net (#0)
I1210 17:23:20.573835 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:23:21.941671 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:23:21.995061 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6776
I1210 17:23:21.995061 15772 solver.cpp:397]     Test net output #1: loss = 1.29987 (* 1 = 1.29987 loss)
I1210 17:23:22.049062 15772 solver.cpp:218] Iteration 121000 (14.1231 iter/s, 7.0806s/100 iters), loss = 0.247236
I1210 17:23:22.049062 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 17:23:22.049062 15772 solver.cpp:237]     Train net output #1: loss = 0.247236 (* 1 = 0.247236 loss)
I1210 17:23:22.049062 15772 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1210 17:23:27.685454 15772 solver.cpp:218] Iteration 121100 (17.7431 iter/s, 5.63599s/100 iters), loss = 0.289209
I1210 17:23:27.685454 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:23:27.685454 15772 solver.cpp:237]     Train net output #1: loss = 0.289209 (* 1 = 0.289209 loss)
I1210 17:23:27.685454 15772 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1210 17:23:33.338759 15772 solver.cpp:218] Iteration 121200 (17.689 iter/s, 5.65324s/100 iters), loss = 0.27219
I1210 17:23:33.338759 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:23:33.338759 15772 solver.cpp:237]     Train net output #1: loss = 0.27219 (* 1 = 0.27219 loss)
I1210 17:23:33.338759 15772 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1210 17:23:38.980237 15772 solver.cpp:218] Iteration 121300 (17.729 iter/s, 5.64049s/100 iters), loss = 0.299136
I1210 17:23:38.980237 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 17:23:38.980237 15772 solver.cpp:237]     Train net output #1: loss = 0.299136 (* 1 = 0.299136 loss)
I1210 17:23:38.980237 15772 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1210 17:23:44.629683 15772 solver.cpp:218] Iteration 121400 (17.7014 iter/s, 5.64929s/100 iters), loss = 0.359586
I1210 17:23:44.629683 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:23:44.629683 15772 solver.cpp:237]     Train net output #1: loss = 0.359585 (* 1 = 0.359585 loss)
I1210 17:23:44.629683 15772 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1210 17:23:49.999145 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:23:50.222160 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_121500.caffemodel
I1210 17:23:50.237161 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_121500.solverstate
I1210 17:23:50.243161 15772 solver.cpp:330] Iteration 121500, Testing net (#0)
I1210 17:23:50.243161 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:23:51.614292 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:23:51.668292 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6775
I1210 17:23:51.668292 15772 solver.cpp:397]     Test net output #1: loss = 1.27135 (* 1 = 1.27135 loss)
I1210 17:23:51.722299 15772 solver.cpp:218] Iteration 121500 (14.0998 iter/s, 7.09229s/100 iters), loss = 0.297184
I1210 17:23:51.722299 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:23:51.722299 15772 solver.cpp:237]     Train net output #1: loss = 0.297184 (* 1 = 0.297184 loss)
I1210 17:23:51.722299 15772 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1210 17:23:57.366797 15772 solver.cpp:218] Iteration 121600 (17.7161 iter/s, 5.64458s/100 iters), loss = 0.34044
I1210 17:23:57.367799 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:23:57.367799 15772 solver.cpp:237]     Train net output #1: loss = 0.34044 (* 1 = 0.34044 loss)
I1210 17:23:57.367799 15772 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1210 17:24:03.017187 15772 solver.cpp:218] Iteration 121700 (17.7006 iter/s, 5.64952s/100 iters), loss = 0.254151
I1210 17:24:03.017187 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 17:24:03.017187 15772 solver.cpp:237]     Train net output #1: loss = 0.25415 (* 1 = 0.25415 loss)
I1210 17:24:03.017187 15772 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1210 17:24:08.658622 15772 solver.cpp:218] Iteration 121800 (17.7273 iter/s, 5.64103s/100 iters), loss = 0.252677
I1210 17:24:08.658622 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:24:08.658622 15772 solver.cpp:237]     Train net output #1: loss = 0.252677 (* 1 = 0.252677 loss)
I1210 17:24:08.658622 15772 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1210 17:24:14.302108 15772 solver.cpp:218] Iteration 121900 (17.7222 iter/s, 5.64264s/100 iters), loss = 0.352857
I1210 17:24:14.302108 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:24:14.302108 15772 solver.cpp:237]     Train net output #1: loss = 0.352856 (* 1 = 0.352856 loss)
I1210 17:24:14.302108 15772 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1210 17:24:19.660821 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:24:19.882287 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_122000.caffemodel
I1210 17:24:19.897836 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_122000.solverstate
I1210 17:24:19.902832 15772 solver.cpp:330] Iteration 122000, Testing net (#0)
I1210 17:24:19.902832 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:24:21.273061 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:24:21.326638 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6763
I1210 17:24:21.326638 15772 solver.cpp:397]     Test net output #1: loss = 1.29492 (* 1 = 1.29492 loss)
I1210 17:24:21.380647 15772 solver.cpp:218] Iteration 122000 (14.1284 iter/s, 7.07793s/100 iters), loss = 0.282332
I1210 17:24:21.380647 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:24:21.380647 15772 solver.cpp:237]     Train net output #1: loss = 0.282332 (* 1 = 0.282332 loss)
I1210 17:24:21.380647 15772 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1210 17:24:27.021931 15772 solver.cpp:218] Iteration 122100 (17.7273 iter/s, 5.64102s/100 iters), loss = 0.324626
I1210 17:24:27.021931 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:24:27.021931 15772 solver.cpp:237]     Train net output #1: loss = 0.324626 (* 1 = 0.324626 loss)
I1210 17:24:27.021931 15772 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1210 17:24:32.665623 15772 solver.cpp:218] Iteration 122200 (17.7202 iter/s, 5.64328s/100 iters), loss = 0.294732
I1210 17:24:32.665623 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:24:32.665623 15772 solver.cpp:237]     Train net output #1: loss = 0.294732 (* 1 = 0.294732 loss)
I1210 17:24:32.665623 15772 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1210 17:24:38.318068 15772 solver.cpp:218] Iteration 122300 (17.6918 iter/s, 5.65234s/100 iters), loss = 0.317697
I1210 17:24:38.318068 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:24:38.318068 15772 solver.cpp:237]     Train net output #1: loss = 0.317697 (* 1 = 0.317697 loss)
I1210 17:24:38.318068 15772 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1210 17:24:43.966481 15772 solver.cpp:218] Iteration 122400 (17.7059 iter/s, 5.64782s/100 iters), loss = 0.330774
I1210 17:24:43.966481 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:24:43.966481 15772 solver.cpp:237]     Train net output #1: loss = 0.330773 (* 1 = 0.330773 loss)
I1210 17:24:43.966481 15772 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1210 17:24:49.330866 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:24:49.552881 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_122500.caffemodel
I1210 17:24:49.567880 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_122500.solverstate
I1210 17:24:49.576880 15772 solver.cpp:330] Iteration 122500, Testing net (#0)
I1210 17:24:49.576880 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:24:50.948617 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:24:51.002120 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6813
I1210 17:24:51.002120 15772 solver.cpp:397]     Test net output #1: loss = 1.27805 (* 1 = 1.27805 loss)
I1210 17:24:51.056124 15772 solver.cpp:218] Iteration 122500 (14.1073 iter/s, 7.08852s/100 iters), loss = 0.230396
I1210 17:24:51.056124 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 17:24:51.056124 15772 solver.cpp:237]     Train net output #1: loss = 0.230396 (* 1 = 0.230396 loss)
I1210 17:24:51.056124 15772 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1210 17:24:56.718511 15772 solver.cpp:218] Iteration 122600 (17.6591 iter/s, 5.66279s/100 iters), loss = 0.319595
I1210 17:24:56.719511 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:24:56.719511 15772 solver.cpp:237]     Train net output #1: loss = 0.319594 (* 1 = 0.319594 loss)
I1210 17:24:56.719511 15772 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1210 17:25:02.376011 15772 solver.cpp:218] Iteration 122700 (17.6777 iter/s, 5.65683s/100 iters), loss = 0.306843
I1210 17:25:02.376011 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:25:02.376011 15772 solver.cpp:237]     Train net output #1: loss = 0.306842 (* 1 = 0.306842 loss)
I1210 17:25:02.376011 15772 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1210 17:25:08.026638 15772 solver.cpp:218] Iteration 122800 (17.6984 iter/s, 5.65022s/100 iters), loss = 0.296803
I1210 17:25:08.026638 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:25:08.027635 15772 solver.cpp:237]     Train net output #1: loss = 0.296803 (* 1 = 0.296803 loss)
I1210 17:25:08.027635 15772 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1210 17:25:13.676034 15772 solver.cpp:218] Iteration 122900 (17.7028 iter/s, 5.64882s/100 iters), loss = 0.311034
I1210 17:25:13.676034 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:25:13.676034 15772 solver.cpp:237]     Train net output #1: loss = 0.311033 (* 1 = 0.311033 loss)
I1210 17:25:13.676034 15772 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1210 17:25:19.048395 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:25:19.271411 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_123000.caffemodel
I1210 17:25:19.286412 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_123000.solverstate
I1210 17:25:19.290411 15772 solver.cpp:330] Iteration 123000, Testing net (#0)
I1210 17:25:19.290411 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:25:20.663527 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:25:20.716528 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6767
I1210 17:25:20.716528 15772 solver.cpp:397]     Test net output #1: loss = 1.29528 (* 1 = 1.29528 loss)
I1210 17:25:20.769532 15772 solver.cpp:218] Iteration 123000 (14.0991 iter/s, 7.09264s/100 iters), loss = 0.188465
I1210 17:25:20.769532 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 17:25:20.769532 15772 solver.cpp:237]     Train net output #1: loss = 0.188465 (* 1 = 0.188465 loss)
I1210 17:25:20.769532 15772 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1210 17:25:26.412377 15772 solver.cpp:218] Iteration 123100 (17.7218 iter/s, 5.64277s/100 iters), loss = 0.333246
I1210 17:25:26.412377 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:25:26.412377 15772 solver.cpp:237]     Train net output #1: loss = 0.333245 (* 1 = 0.333245 loss)
I1210 17:25:26.412377 15772 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1210 17:25:32.047353 15772 solver.cpp:218] Iteration 123200 (17.7491 iter/s, 5.6341s/100 iters), loss = 0.26801
I1210 17:25:32.047353 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:25:32.047353 15772 solver.cpp:237]     Train net output #1: loss = 0.268009 (* 1 = 0.268009 loss)
I1210 17:25:32.047353 15772 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1210 17:25:37.689354 15772 solver.cpp:218] Iteration 123300 (17.7258 iter/s, 5.64148s/100 iters), loss = 0.275645
I1210 17:25:37.689354 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:25:37.689354 15772 solver.cpp:237]     Train net output #1: loss = 0.275645 (* 1 = 0.275645 loss)
I1210 17:25:37.689354 15772 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1210 17:25:43.333928 15772 solver.cpp:218] Iteration 123400 (17.7183 iter/s, 5.64388s/100 iters), loss = 0.397463
I1210 17:25:43.333928 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 17:25:43.333928 15772 solver.cpp:237]     Train net output #1: loss = 0.397462 (* 1 = 0.397462 loss)
I1210 17:25:43.333928 15772 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1210 17:25:48.701380 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:25:48.924403 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_123500.caffemodel
I1210 17:25:48.940407 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_123500.solverstate
I1210 17:25:48.968423 15772 solver.cpp:330] Iteration 123500, Testing net (#0)
I1210 17:25:48.968423 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:25:50.339565 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:25:50.393573 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6797
I1210 17:25:50.393573 15772 solver.cpp:397]     Test net output #1: loss = 1.29547 (* 1 = 1.29547 loss)
I1210 17:25:50.446574 15772 solver.cpp:218] Iteration 123500 (14.0597 iter/s, 7.11253s/100 iters), loss = 0.254806
I1210 17:25:50.446574 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:25:50.446574 15772 solver.cpp:237]     Train net output #1: loss = 0.254806 (* 1 = 0.254806 loss)
I1210 17:25:50.447075 15772 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1210 17:25:56.085034 15772 solver.cpp:218] Iteration 123600 (17.7361 iter/s, 5.63822s/100 iters), loss = 0.321557
I1210 17:25:56.085034 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:25:56.085034 15772 solver.cpp:237]     Train net output #1: loss = 0.321557 (* 1 = 0.321557 loss)
I1210 17:25:56.085034 15772 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1210 17:26:01.729511 15772 solver.cpp:218] Iteration 123700 (17.7183 iter/s, 5.64388s/100 iters), loss = 0.243046
I1210 17:26:01.729511 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:26:01.729511 15772 solver.cpp:237]     Train net output #1: loss = 0.243046 (* 1 = 0.243046 loss)
I1210 17:26:01.729511 15772 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1210 17:26:07.371537 15772 solver.cpp:218] Iteration 123800 (17.7265 iter/s, 5.64127s/100 iters), loss = 0.354873
I1210 17:26:07.371537 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:26:07.371537 15772 solver.cpp:237]     Train net output #1: loss = 0.354872 (* 1 = 0.354872 loss)
I1210 17:26:07.371537 15772 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1210 17:26:13.001698 15772 solver.cpp:218] Iteration 123900 (17.7632 iter/s, 5.62962s/100 iters), loss = 0.322787
I1210 17:26:13.001698 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:26:13.001698 15772 solver.cpp:237]     Train net output #1: loss = 0.322787 (* 1 = 0.322787 loss)
I1210 17:26:13.001698 15772 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1210 17:26:18.362998 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:26:18.586081 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_124000.caffemodel
I1210 17:26:18.600075 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_124000.solverstate
I1210 17:26:18.605080 15772 solver.cpp:330] Iteration 124000, Testing net (#0)
I1210 17:26:18.605080 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:26:19.976575 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:26:20.030575 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6744
I1210 17:26:20.030575 15772 solver.cpp:397]     Test net output #1: loss = 1.298 (* 1 = 1.298 loss)
I1210 17:26:20.083564 15772 solver.cpp:218] Iteration 124000 (14.1211 iter/s, 7.0816s/100 iters), loss = 0.240593
I1210 17:26:20.083564 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:26:20.083564 15772 solver.cpp:237]     Train net output #1: loss = 0.240592 (* 1 = 0.240592 loss)
I1210 17:26:20.083564 15772 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1210 17:26:25.712262 15772 solver.cpp:218] Iteration 124100 (17.7687 iter/s, 5.62788s/100 iters), loss = 0.285785
I1210 17:26:25.712262 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:26:25.712262 15772 solver.cpp:237]     Train net output #1: loss = 0.285785 (* 1 = 0.285785 loss)
I1210 17:26:25.712262 15772 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1210 17:26:31.332701 15772 solver.cpp:218] Iteration 124200 (17.7922 iter/s, 5.62046s/100 iters), loss = 0.220604
I1210 17:26:31.332701 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:26:31.332701 15772 solver.cpp:237]     Train net output #1: loss = 0.220603 (* 1 = 0.220603 loss)
I1210 17:26:31.332701 15772 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1210 17:26:36.965621 15772 solver.cpp:218] Iteration 124300 (17.7543 iter/s, 5.63243s/100 iters), loss = 0.311697
I1210 17:26:36.965621 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:26:36.966123 15772 solver.cpp:237]     Train net output #1: loss = 0.311697 (* 1 = 0.311697 loss)
I1210 17:26:36.966123 15772 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1210 17:26:42.600606 15772 solver.cpp:218] Iteration 124400 (17.7488 iter/s, 5.63418s/100 iters), loss = 0.334263
I1210 17:26:42.600606 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:26:42.600606 15772 solver.cpp:237]     Train net output #1: loss = 0.334263 (* 1 = 0.334263 loss)
I1210 17:26:42.600606 15772 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1210 17:26:47.957983 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:26:48.179000 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_124500.caffemodel
I1210 17:26:48.194002 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_124500.solverstate
I1210 17:26:48.228000 15772 solver.cpp:330] Iteration 124500, Testing net (#0)
I1210 17:26:48.228000 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:26:49.597128 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:26:49.651129 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6715
I1210 17:26:49.651129 15772 solver.cpp:397]     Test net output #1: loss = 1.31432 (* 1 = 1.31432 loss)
I1210 17:26:49.703137 15772 solver.cpp:218] Iteration 124500 (14.0796 iter/s, 7.1025s/100 iters), loss = 0.215168
I1210 17:26:49.703137 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 17:26:49.703137 15772 solver.cpp:237]     Train net output #1: loss = 0.215168 (* 1 = 0.215168 loss)
I1210 17:26:49.703137 15772 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1210 17:26:55.361425 15772 solver.cpp:218] Iteration 124600 (17.6754 iter/s, 5.65757s/100 iters), loss = 0.285112
I1210 17:26:55.361425 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:26:55.361425 15772 solver.cpp:237]     Train net output #1: loss = 0.285112 (* 1 = 0.285112 loss)
I1210 17:26:55.361425 15772 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1210 17:27:01.021867 15772 solver.cpp:218] Iteration 124700 (17.6674 iter/s, 5.66016s/100 iters), loss = 0.267766
I1210 17:27:01.021867 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:27:01.021867 15772 solver.cpp:237]     Train net output #1: loss = 0.267766 (* 1 = 0.267766 loss)
I1210 17:27:01.021867 15772 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1210 17:27:06.675343 15772 solver.cpp:218] Iteration 124800 (17.6913 iter/s, 5.65251s/100 iters), loss = 0.303131
I1210 17:27:06.675343 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:27:06.675343 15772 solver.cpp:237]     Train net output #1: loss = 0.303131 (* 1 = 0.303131 loss)
I1210 17:27:06.675343 15772 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1210 17:27:12.320791 15772 solver.cpp:218] Iteration 124900 (17.7156 iter/s, 5.64476s/100 iters), loss = 0.279794
I1210 17:27:12.320791 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:27:12.320791 15772 solver.cpp:237]     Train net output #1: loss = 0.279794 (* 1 = 0.279794 loss)
I1210 17:27:12.320791 15772 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1210 17:27:17.688246 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:27:17.913277 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_125000.caffemodel
I1210 17:27:17.928277 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_125000.solverstate
I1210 17:27:17.933277 15772 solver.cpp:330] Iteration 125000, Testing net (#0)
I1210 17:27:17.933277 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:27:19.308408 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:27:19.361908 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6756
I1210 17:27:19.361908 15772 solver.cpp:397]     Test net output #1: loss = 1.28578 (* 1 = 1.28578 loss)
I1210 17:27:19.415410 15772 solver.cpp:218] Iteration 125000 (14.0959 iter/s, 7.09428s/100 iters), loss = 0.168277
I1210 17:27:19.415410 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1210 17:27:19.415410 15772 solver.cpp:237]     Train net output #1: loss = 0.168277 (* 1 = 0.168277 loss)
I1210 17:27:19.415410 15772 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1210 17:27:25.051784 15772 solver.cpp:218] Iteration 125100 (17.7445 iter/s, 5.63555s/100 iters), loss = 0.280407
I1210 17:27:25.051784 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:27:25.051784 15772 solver.cpp:237]     Train net output #1: loss = 0.280407 (* 1 = 0.280407 loss)
I1210 17:27:25.051784 15772 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1210 17:27:30.696154 15772 solver.cpp:218] Iteration 125200 (17.7164 iter/s, 5.64447s/100 iters), loss = 0.216769
I1210 17:27:30.696154 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 17:27:30.696154 15772 solver.cpp:237]     Train net output #1: loss = 0.216769 (* 1 = 0.216769 loss)
I1210 17:27:30.696154 15772 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1210 17:27:36.340567 15772 solver.cpp:218] Iteration 125300 (17.7194 iter/s, 5.64354s/100 iters), loss = 0.259214
I1210 17:27:36.340567 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:27:36.340567 15772 solver.cpp:237]     Train net output #1: loss = 0.259214 (* 1 = 0.259214 loss)
I1210 17:27:36.340567 15772 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1210 17:27:41.979971 15772 solver.cpp:218] Iteration 125400 (17.7311 iter/s, 5.63981s/100 iters), loss = 0.353295
I1210 17:27:41.980971 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:27:41.980971 15772 solver.cpp:237]     Train net output #1: loss = 0.353295 (* 1 = 0.353295 loss)
I1210 17:27:41.980971 15772 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1210 17:27:47.346354 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:27:47.567865 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_125500.caffemodel
I1210 17:27:47.583369 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_125500.solverstate
I1210 17:27:47.610371 15772 solver.cpp:330] Iteration 125500, Testing net (#0)
I1210 17:27:47.610371 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:27:48.981508 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:27:49.036509 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6728
I1210 17:27:49.036509 15772 solver.cpp:397]     Test net output #1: loss = 1.30686 (* 1 = 1.30686 loss)
I1210 17:27:49.089516 15772 solver.cpp:218] Iteration 125500 (14.0675 iter/s, 7.1086s/100 iters), loss = 0.240544
I1210 17:27:49.089516 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:27:49.089516 15772 solver.cpp:237]     Train net output #1: loss = 0.240544 (* 1 = 0.240544 loss)
I1210 17:27:49.089516 15772 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1210 17:27:54.720021 15772 solver.cpp:218] Iteration 125600 (17.7634 iter/s, 5.62957s/100 iters), loss = 0.301968
I1210 17:27:54.720021 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:27:54.720021 15772 solver.cpp:237]     Train net output #1: loss = 0.301968 (* 1 = 0.301968 loss)
I1210 17:27:54.720021 15772 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1210 17:28:00.357223 15772 solver.cpp:218] Iteration 125700 (17.7404 iter/s, 5.63684s/100 iters), loss = 0.229499
I1210 17:28:00.357223 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 17:28:00.357223 15772 solver.cpp:237]     Train net output #1: loss = 0.229498 (* 1 = 0.229498 loss)
I1210 17:28:00.357223 15772 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1210 17:28:05.997117 15772 solver.cpp:218] Iteration 125800 (17.7323 iter/s, 5.63941s/100 iters), loss = 0.281153
I1210 17:28:05.997117 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:28:05.997117 15772 solver.cpp:237]     Train net output #1: loss = 0.281153 (* 1 = 0.281153 loss)
I1210 17:28:05.997117 15772 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1210 17:28:11.637552 15772 solver.cpp:218] Iteration 125900 (17.7289 iter/s, 5.6405s/100 iters), loss = 0.311347
I1210 17:28:11.637552 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:28:11.637552 15772 solver.cpp:237]     Train net output #1: loss = 0.311347 (* 1 = 0.311347 loss)
I1210 17:28:11.637552 15772 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1210 17:28:17.000972 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:28:17.223996 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_126000.caffemodel
I1210 17:28:17.238996 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_126000.solverstate
I1210 17:28:17.269013 15772 solver.cpp:330] Iteration 126000, Testing net (#0)
I1210 17:28:17.269013 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:28:18.642163 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:28:18.695189 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6776
I1210 17:28:18.695189 15772 solver.cpp:397]     Test net output #1: loss = 1.28964 (* 1 = 1.28964 loss)
I1210 17:28:18.749173 15772 solver.cpp:218] Iteration 126000 (14.0619 iter/s, 7.11142s/100 iters), loss = 0.179143
I1210 17:28:18.749173 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:28:18.750174 15772 solver.cpp:237]     Train net output #1: loss = 0.179143 (* 1 = 0.179143 loss)
I1210 17:28:18.750174 15772 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1210 17:28:24.399797 15772 solver.cpp:218] Iteration 126100 (17.7012 iter/s, 5.64933s/100 iters), loss = 0.339208
I1210 17:28:24.399797 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:28:24.399797 15772 solver.cpp:237]     Train net output #1: loss = 0.339208 (* 1 = 0.339208 loss)
I1210 17:28:24.399797 15772 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1210 17:28:30.050204 15772 solver.cpp:218] Iteration 126200 (17.6988 iter/s, 5.65011s/100 iters), loss = 0.256917
I1210 17:28:30.050204 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:28:30.050204 15772 solver.cpp:237]     Train net output #1: loss = 0.256917 (* 1 = 0.256917 loss)
I1210 17:28:30.050204 15772 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1210 17:28:35.709637 15772 solver.cpp:218] Iteration 126300 (17.6706 iter/s, 5.6591s/100 iters), loss = 0.357307
I1210 17:28:35.709637 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:28:35.709637 15772 solver.cpp:237]     Train net output #1: loss = 0.357307 (* 1 = 0.357307 loss)
I1210 17:28:35.709637 15772 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1210 17:28:41.362084 15772 solver.cpp:218] Iteration 126400 (17.6931 iter/s, 5.65191s/100 iters), loss = 0.29972
I1210 17:28:41.362084 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:28:41.362584 15772 solver.cpp:237]     Train net output #1: loss = 0.29972 (* 1 = 0.29972 loss)
I1210 17:28:41.362584 15772 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1210 17:28:46.738569 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:28:46.961596 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_126500.caffemodel
I1210 17:28:46.977602 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_126500.solverstate
I1210 17:28:46.982609 15772 solver.cpp:330] Iteration 126500, Testing net (#0)
I1210 17:28:46.982609 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:28:48.354701 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:28:48.407706 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6754
I1210 17:28:48.407706 15772 solver.cpp:397]     Test net output #1: loss = 1.31066 (* 1 = 1.31066 loss)
I1210 17:28:48.460706 15772 solver.cpp:218] Iteration 126500 (14.0874 iter/s, 7.09856s/100 iters), loss = 0.25739
I1210 17:28:48.460706 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:28:48.460706 15772 solver.cpp:237]     Train net output #1: loss = 0.25739 (* 1 = 0.25739 loss)
I1210 17:28:48.460706 15772 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1210 17:28:54.111176 15772 solver.cpp:218] Iteration 126600 (17.6995 iter/s, 5.64987s/100 iters), loss = 0.302781
I1210 17:28:54.111176 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:28:54.111176 15772 solver.cpp:237]     Train net output #1: loss = 0.302781 (* 1 = 0.302781 loss)
I1210 17:28:54.111176 15772 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1210 17:28:59.756122 15772 solver.cpp:218] Iteration 126700 (17.7185 iter/s, 5.64382s/100 iters), loss = 0.27105
I1210 17:28:59.756122 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:28:59.756122 15772 solver.cpp:237]     Train net output #1: loss = 0.27105 (* 1 = 0.27105 loss)
I1210 17:28:59.756122 15772 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1210 17:29:05.400084 15772 solver.cpp:218] Iteration 126800 (17.7188 iter/s, 5.64373s/100 iters), loss = 0.294174
I1210 17:29:05.400084 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:29:05.400084 15772 solver.cpp:237]     Train net output #1: loss = 0.294174 (* 1 = 0.294174 loss)
I1210 17:29:05.400084 15772 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1210 17:29:11.041579 15772 solver.cpp:218] Iteration 126900 (17.7265 iter/s, 5.64127s/100 iters), loss = 0.32076
I1210 17:29:11.041579 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:29:11.041579 15772 solver.cpp:237]     Train net output #1: loss = 0.32076 (* 1 = 0.32076 loss)
I1210 17:29:11.041579 15772 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1210 17:29:16.420992 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:29:16.643002 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_127000.caffemodel
I1210 17:29:16.684046 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_127000.solverstate
I1210 17:29:16.688045 15772 solver.cpp:330] Iteration 127000, Testing net (#0)
I1210 17:29:16.688045 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:29:18.060148 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:29:18.112152 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6743
I1210 17:29:18.112152 15772 solver.cpp:397]     Test net output #1: loss = 1.29876 (* 1 = 1.29876 loss)
I1210 17:29:18.165161 15772 solver.cpp:218] Iteration 127000 (14.0397 iter/s, 7.12268s/100 iters), loss = 0.250067
I1210 17:29:18.165161 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:29:18.165161 15772 solver.cpp:237]     Train net output #1: loss = 0.250067 (* 1 = 0.250067 loss)
I1210 17:29:18.165161 15772 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1210 17:29:23.798784 15772 solver.cpp:218] Iteration 127100 (17.7519 iter/s, 5.6332s/100 iters), loss = 0.292354
I1210 17:29:23.798784 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:29:23.798784 15772 solver.cpp:237]     Train net output #1: loss = 0.292354 (* 1 = 0.292354 loss)
I1210 17:29:23.798784 15772 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1210 17:29:29.430212 15772 solver.cpp:218] Iteration 127200 (17.7571 iter/s, 5.63154s/100 iters), loss = 0.248699
I1210 17:29:29.430212 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:29:29.430212 15772 solver.cpp:237]     Train net output #1: loss = 0.248699 (* 1 = 0.248699 loss)
I1210 17:29:29.430212 15772 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1210 17:29:35.080839 15772 solver.cpp:218] Iteration 127300 (17.6997 iter/s, 5.64983s/100 iters), loss = 0.285107
I1210 17:29:35.080839 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:29:35.080839 15772 solver.cpp:237]     Train net output #1: loss = 0.285107 (* 1 = 0.285107 loss)
I1210 17:29:35.080839 15772 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1210 17:29:40.716262 15772 solver.cpp:218] Iteration 127400 (17.7461 iter/s, 5.63505s/100 iters), loss = 0.353456
I1210 17:29:40.716262 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:29:40.716262 15772 solver.cpp:237]     Train net output #1: loss = 0.353456 (* 1 = 0.353456 loss)
I1210 17:29:40.716262 15772 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1210 17:29:46.084748 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:29:46.306764 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_127500.caffemodel
I1210 17:29:46.349763 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_127500.solverstate
I1210 17:29:46.355764 15772 solver.cpp:330] Iteration 127500, Testing net (#0)
I1210 17:29:46.355764 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:29:47.729913 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:29:47.782920 15772 solver.cpp:397]     Test net output #0: accuracy = 0.677
I1210 17:29:47.782920 15772 solver.cpp:397]     Test net output #1: loss = 1.30586 (* 1 = 1.30586 loss)
I1210 17:29:47.835922 15772 solver.cpp:218] Iteration 127500 (14.0463 iter/s, 7.1193s/100 iters), loss = 0.208385
I1210 17:29:47.835922 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 17:29:47.835922 15772 solver.cpp:237]     Train net output #1: loss = 0.208385 (* 1 = 0.208385 loss)
I1210 17:29:47.835922 15772 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1210 17:29:53.483475 15772 solver.cpp:218] Iteration 127600 (17.7078 iter/s, 5.64722s/100 iters), loss = 0.397957
I1210 17:29:53.483475 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:29:53.483475 15772 solver.cpp:237]     Train net output #1: loss = 0.397957 (* 1 = 0.397957 loss)
I1210 17:29:53.483475 15772 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1210 17:29:59.123013 15772 solver.cpp:218] Iteration 127700 (17.7356 iter/s, 5.63838s/100 iters), loss = 0.275104
I1210 17:29:59.123013 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:29:59.123013 15772 solver.cpp:237]     Train net output #1: loss = 0.275104 (* 1 = 0.275104 loss)
I1210 17:29:59.123013 15772 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1210 17:30:04.786890 15772 solver.cpp:218] Iteration 127800 (17.6555 iter/s, 5.66396s/100 iters), loss = 0.297959
I1210 17:30:04.786890 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:30:04.786890 15772 solver.cpp:237]     Train net output #1: loss = 0.297959 (* 1 = 0.297959 loss)
I1210 17:30:04.786890 15772 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1210 17:30:10.417522 15772 solver.cpp:218] Iteration 127900 (17.7629 iter/s, 5.62971s/100 iters), loss = 0.325916
I1210 17:30:10.417522 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:30:10.417522 15772 solver.cpp:237]     Train net output #1: loss = 0.325916 (* 1 = 0.325916 loss)
I1210 17:30:10.417522 15772 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1210 17:30:15.772995 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:30:15.995009 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_128000.caffemodel
I1210 17:30:16.010010 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_128000.solverstate
I1210 17:30:16.014009 15772 solver.cpp:330] Iteration 128000, Testing net (#0)
I1210 17:30:16.014009 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:30:17.382115 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:30:17.435113 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6775
I1210 17:30:17.436115 15772 solver.cpp:397]     Test net output #1: loss = 1.30362 (* 1 = 1.30362 loss)
I1210 17:30:17.488121 15772 solver.cpp:218] Iteration 128000 (14.1424 iter/s, 7.07093s/100 iters), loss = 0.222081
I1210 17:30:17.488121 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 17:30:17.489121 15772 solver.cpp:237]     Train net output #1: loss = 0.222081 (* 1 = 0.222081 loss)
I1210 17:30:17.489121 15772 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1210 17:30:23.131811 15772 solver.cpp:218] Iteration 128100 (17.7225 iter/s, 5.64254s/100 iters), loss = 0.300787
I1210 17:30:23.131811 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 17:30:23.131811 15772 solver.cpp:237]     Train net output #1: loss = 0.300787 (* 1 = 0.300787 loss)
I1210 17:30:23.131811 15772 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1210 17:30:28.762691 15772 solver.cpp:218] Iteration 128200 (17.7598 iter/s, 5.6307s/100 iters), loss = 0.354127
I1210 17:30:28.763191 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:30:28.763191 15772 solver.cpp:237]     Train net output #1: loss = 0.354127 (* 1 = 0.354127 loss)
I1210 17:30:28.763191 15772 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1210 17:30:34.402613 15772 solver.cpp:218] Iteration 128300 (17.7334 iter/s, 5.63908s/100 iters), loss = 0.249672
I1210 17:30:34.402613 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:30:34.402613 15772 solver.cpp:237]     Train net output #1: loss = 0.249672 (* 1 = 0.249672 loss)
I1210 17:30:34.402613 15772 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1210 17:30:40.034181 15772 solver.cpp:218] Iteration 128400 (17.7578 iter/s, 5.63134s/100 iters), loss = 0.354153
I1210 17:30:40.034181 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:30:40.034181 15772 solver.cpp:237]     Train net output #1: loss = 0.354153 (* 1 = 0.354153 loss)
I1210 17:30:40.034181 15772 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1210 17:30:45.395690 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:30:45.618705 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_128500.caffemodel
I1210 17:30:45.659703 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_128500.solverstate
I1210 17:30:45.664206 15772 solver.cpp:330] Iteration 128500, Testing net (#0)
I1210 17:30:45.664206 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:30:47.034832 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:30:47.087846 15772 solver.cpp:397]     Test net output #0: accuracy = 0.677
I1210 17:30:47.087846 15772 solver.cpp:397]     Test net output #1: loss = 1.30448 (* 1 = 1.30448 loss)
I1210 17:30:47.140838 15772 solver.cpp:218] Iteration 128500 (14.0715 iter/s, 7.10655s/100 iters), loss = 0.278854
I1210 17:30:47.140838 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:30:47.140838 15772 solver.cpp:237]     Train net output #1: loss = 0.278853 (* 1 = 0.278853 loss)
I1210 17:30:47.140838 15772 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1210 17:30:52.773268 15772 solver.cpp:218] Iteration 128600 (17.7578 iter/s, 5.63133s/100 iters), loss = 0.328258
I1210 17:30:52.773268 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:30:52.773268 15772 solver.cpp:237]     Train net output #1: loss = 0.328258 (* 1 = 0.328258 loss)
I1210 17:30:52.773268 15772 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1210 17:30:58.396950 15772 solver.cpp:218] Iteration 128700 (17.7838 iter/s, 5.62309s/100 iters), loss = 0.251207
I1210 17:30:58.396950 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:30:58.396950 15772 solver.cpp:237]     Train net output #1: loss = 0.251206 (* 1 = 0.251206 loss)
I1210 17:30:58.396950 15772 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1210 17:31:04.053267 15772 solver.cpp:218] Iteration 128800 (17.6807 iter/s, 5.65587s/100 iters), loss = 0.276322
I1210 17:31:04.053267 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 17:31:04.053267 15772 solver.cpp:237]     Train net output #1: loss = 0.276322 (* 1 = 0.276322 loss)
I1210 17:31:04.053267 15772 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1210 17:31:09.715219 15772 solver.cpp:218] Iteration 128900 (17.6617 iter/s, 5.66196s/100 iters), loss = 0.313809
I1210 17:31:09.715219 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:31:09.715219 15772 solver.cpp:237]     Train net output #1: loss = 0.313808 (* 1 = 0.313808 loss)
I1210 17:31:09.715219 15772 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1210 17:31:15.063100 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:31:15.284318 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_129000.caffemodel
I1210 17:31:15.299823 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_129000.solverstate
I1210 17:31:15.304327 15772 solver.cpp:330] Iteration 129000, Testing net (#0)
I1210 17:31:15.304327 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:31:16.668072 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:31:16.721837 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6713
I1210 17:31:16.721837 15772 solver.cpp:397]     Test net output #1: loss = 1.31869 (* 1 = 1.31869 loss)
I1210 17:31:16.773835 15772 solver.cpp:218] Iteration 129000 (14.1675 iter/s, 7.05843s/100 iters), loss = 0.171338
I1210 17:31:16.773835 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:31:16.773835 15772 solver.cpp:237]     Train net output #1: loss = 0.171338 (* 1 = 0.171338 loss)
I1210 17:31:16.773835 15772 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1210 17:31:22.392684 15772 solver.cpp:218] Iteration 129100 (17.8004 iter/s, 5.61786s/100 iters), loss = 0.318835
I1210 17:31:22.392684 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 17:31:22.392684 15772 solver.cpp:237]     Train net output #1: loss = 0.318835 (* 1 = 0.318835 loss)
I1210 17:31:22.392684 15772 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1210 17:31:28.006331 15772 solver.cpp:218] Iteration 129200 (17.816 iter/s, 5.61294s/100 iters), loss = 0.251975
I1210 17:31:28.006331 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:31:28.006331 15772 solver.cpp:237]     Train net output #1: loss = 0.251975 (* 1 = 0.251975 loss)
I1210 17:31:28.006331 15772 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1210 17:31:33.620929 15772 solver.cpp:218] Iteration 129300 (17.8124 iter/s, 5.61406s/100 iters), loss = 0.340925
I1210 17:31:33.620929 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:31:33.620929 15772 solver.cpp:237]     Train net output #1: loss = 0.340925 (* 1 = 0.340925 loss)
I1210 17:31:33.620929 15772 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1210 17:31:39.234647 15772 solver.cpp:218] Iteration 129400 (17.8132 iter/s, 5.61382s/100 iters), loss = 0.331131
I1210 17:31:39.234647 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:31:39.234647 15772 solver.cpp:237]     Train net output #1: loss = 0.331131 (* 1 = 0.331131 loss)
I1210 17:31:39.234647 15772 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1210 17:31:44.571238 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:31:44.792248 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_129500.caffemodel
I1210 17:31:44.834265 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_129500.solverstate
I1210 17:31:44.839267 15772 solver.cpp:330] Iteration 129500, Testing net (#0)
I1210 17:31:44.839267 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:31:46.207362 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:31:46.261366 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6716
I1210 17:31:46.261366 15772 solver.cpp:397]     Test net output #1: loss = 1.32676 (* 1 = 1.32676 loss)
I1210 17:31:46.317369 15772 solver.cpp:218] Iteration 129500 (14.1208 iter/s, 7.08173s/100 iters), loss = 0.247251
I1210 17:31:46.317369 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:31:46.317369 15772 solver.cpp:237]     Train net output #1: loss = 0.247251 (* 1 = 0.247251 loss)
I1210 17:31:46.317369 15772 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1210 17:31:51.962550 15772 solver.cpp:218] Iteration 129600 (17.7153 iter/s, 5.64483s/100 iters), loss = 0.256959
I1210 17:31:51.962550 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:31:51.962550 15772 solver.cpp:237]     Train net output #1: loss = 0.256959 (* 1 = 0.256959 loss)
I1210 17:31:51.962550 15772 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1210 17:31:57.598353 15772 solver.cpp:218] Iteration 129700 (17.7456 iter/s, 5.63519s/100 iters), loss = 0.261588
I1210 17:31:57.598353 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:31:57.598353 15772 solver.cpp:237]     Train net output #1: loss = 0.261588 (* 1 = 0.261588 loss)
I1210 17:31:57.598353 15772 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1210 17:32:03.237850 15772 solver.cpp:218] Iteration 129800 (17.7334 iter/s, 5.63909s/100 iters), loss = 0.310092
I1210 17:32:03.237850 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:32:03.237850 15772 solver.cpp:237]     Train net output #1: loss = 0.310092 (* 1 = 0.310092 loss)
I1210 17:32:03.237850 15772 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1210 17:32:08.879304 15772 solver.cpp:218] Iteration 129900 (17.7263 iter/s, 5.64133s/100 iters), loss = 0.282702
I1210 17:32:08.879304 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 17:32:08.879304 15772 solver.cpp:237]     Train net output #1: loss = 0.282702 (* 1 = 0.282702 loss)
I1210 17:32:08.879304 15772 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1210 17:32:14.238252 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:32:14.459321 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_130000.caffemodel
I1210 17:32:14.478329 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_130000.solverstate
I1210 17:32:14.483330 15772 solver.cpp:330] Iteration 130000, Testing net (#0)
I1210 17:32:14.483330 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:32:15.850107 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:32:15.903118 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6779
I1210 17:32:15.903118 15772 solver.cpp:397]     Test net output #1: loss = 1.30019 (* 1 = 1.30019 loss)
I1210 17:32:15.958137 15772 solver.cpp:218] Iteration 130000 (14.1284 iter/s, 7.07795s/100 iters), loss = 0.213895
I1210 17:32:15.958137 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 17:32:15.958137 15772 solver.cpp:237]     Train net output #1: loss = 0.213895 (* 1 = 0.213895 loss)
I1210 17:32:15.958137 15772 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1210 17:32:21.584475 15772 solver.cpp:218] Iteration 130100 (17.7739 iter/s, 5.62622s/100 iters), loss = 0.282844
I1210 17:32:21.584475 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 17:32:21.584475 15772 solver.cpp:237]     Train net output #1: loss = 0.282844 (* 1 = 0.282844 loss)
I1210 17:32:21.584475 15772 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1210 17:32:27.213194 15772 solver.cpp:218] Iteration 130200 (17.7687 iter/s, 5.62787s/100 iters), loss = 0.222199
I1210 17:32:27.213194 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 17:32:27.213194 15772 solver.cpp:237]     Train net output #1: loss = 0.222199 (* 1 = 0.222199 loss)
I1210 17:32:27.213194 15772 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1210 17:32:32.835974 15772 solver.cpp:218] Iteration 130300 (17.7857 iter/s, 5.62249s/100 iters), loss = 0.250153
I1210 17:32:32.835974 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 17:32:32.835974 15772 solver.cpp:237]     Train net output #1: loss = 0.250153 (* 1 = 0.250153 loss)
I1210 17:32:32.835974 15772 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1210 17:32:38.471443 15772 solver.cpp:218] Iteration 130400 (17.7455 iter/s, 5.63522s/100 iters), loss = 0.305503
I1210 17:32:38.471443 15772 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 17:32:38.471443 15772 solver.cpp:237]     Train net output #1: loss = 0.305503 (* 1 = 0.305503 loss)
I1210 17:32:38.471443 15772 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1210 17:32:43.827406 18600 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:32:44.047436 15772 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_130500.caffemodel
I1210 17:32:44.082919 15772 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_130500.solverstate
I1210 17:32:44.087919 15772 solver.cpp:330] Iteration 130500, Testing net (#0)
I1210 17:32:44.087919 15772 net.cpp:676] Ignoring source layer accuracy_training
I1210 17:32:45.452538 10416 data_layer.cpp:73] Restarting data prefetching from start.
I1210 17:32:45.506543 15772 solver.cpp:397]     Test net output #0: accuracy = 0.6772
I1210 17:32:45.506543 15772 solver.cpp:397]     Test net output #1: loss = 1.29938 (* 1 = 1.29938 loss)
I1210 17:32:45.559