
G:\Caffe\examples\cifar100>REM go to the caffe root 

G:\Caffe\examples\cifar100>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar100/fcifar100_full_relu_solver_bn.prototxt --snapshot=examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90000.solverstate 
I1210 14:03:09.375563  4700 caffe.cpp:219] Using GPUs 0
I1210 14:03:09.568312  4700 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1210 14:03:09.867370  4700 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 14:03:09.882966  4700 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1210 14:03:09.883966  4700 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 14:03:09.884968  4700 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 14:03:09.884968  4700 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1210 14:03:09.884968  4700 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1210 14:03:09.884968  4700 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_v2_360k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "newconv_added1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "newconv_added1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "newconv_added1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "added_new_conv2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "added_new_conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "added_new_conv2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1210 14:03:09.891966  4700 layer_factory.cpp:58] Creating layer cifar
I1210 14:03:09.897980  4700 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1210 14:03:09.897980  4700 net.cpp:84] Creating Layer cifar
I1210 14:03:09.897980  4700 net.cpp:380] cifar -> data
I1210 14:03:09.897980  4700 net.cpp:380] cifar -> label
I1210 14:03:09.898967  4700 data_layer.cpp:45] output data size: 100,3,32,32
I1210 14:03:09.903967  4700 net.cpp:122] Setting up cifar
I1210 14:03:09.903967  4700 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1210 14:03:09.903967  4700 net.cpp:129] Top shape: 100 (100)
I1210 14:03:09.903967  4700 net.cpp:137] Memory required for data: 1229200
I1210 14:03:09.903967  4700 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1210 14:03:09.904969  4700 net.cpp:84] Creating Layer label_cifar_1_split
I1210 14:03:09.904969  4700 net.cpp:406] label_cifar_1_split <- label
I1210 14:03:09.904969  4700 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1210 14:03:09.904969  4700 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1210 14:03:09.904969  4700 net.cpp:122] Setting up label_cifar_1_split
I1210 14:03:09.904969  4700 net.cpp:129] Top shape: 100 (100)
I1210 14:03:09.904969  4700 net.cpp:129] Top shape: 100 (100)
I1210 14:03:09.904969  4700 net.cpp:137] Memory required for data: 1230000
I1210 14:03:09.904969  4700 layer_factory.cpp:58] Creating layer conv1
I1210 14:03:09.904969  4700 net.cpp:84] Creating Layer conv1
I1210 14:03:09.904969  4700 net.cpp:406] conv1 <- data
I1210 14:03:09.904969  4700 net.cpp:380] conv1 -> conv1
I1210 14:03:09.904969 16984 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 14:03:10.157694  4700 net.cpp:122] Setting up conv1
I1210 14:03:10.157694  4700 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 14:03:10.157694  4700 net.cpp:137] Memory required for data: 13518000
I1210 14:03:10.158195  4700 layer_factory.cpp:58] Creating layer bn1
I1210 14:03:10.158195  4700 net.cpp:84] Creating Layer bn1
I1210 14:03:10.158195  4700 net.cpp:406] bn1 <- conv1
I1210 14:03:10.158195  4700 net.cpp:367] bn1 -> conv1 (in-place)
I1210 14:03:10.158195  4700 net.cpp:122] Setting up bn1
I1210 14:03:10.158195  4700 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 14:03:10.158195  4700 net.cpp:137] Memory required for data: 25806000
I1210 14:03:10.158195  4700 layer_factory.cpp:58] Creating layer scale1
I1210 14:03:10.158195  4700 net.cpp:84] Creating Layer scale1
I1210 14:03:10.158195  4700 net.cpp:406] scale1 <- conv1
I1210 14:03:10.158195  4700 net.cpp:367] scale1 -> conv1 (in-place)
I1210 14:03:10.158195  4700 layer_factory.cpp:58] Creating layer scale1
I1210 14:03:10.158195  4700 net.cpp:122] Setting up scale1
I1210 14:03:10.158195  4700 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 14:03:10.158195  4700 net.cpp:137] Memory required for data: 38094000
I1210 14:03:10.158195  4700 layer_factory.cpp:58] Creating layer relu1
I1210 14:03:10.158695  4700 net.cpp:84] Creating Layer relu1
I1210 14:03:10.158695  4700 net.cpp:406] relu1 <- conv1
I1210 14:03:10.158695  4700 net.cpp:367] relu1 -> conv1 (in-place)
I1210 14:03:10.158695  4700 net.cpp:122] Setting up relu1
I1210 14:03:10.158695  4700 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 14:03:10.158695  4700 net.cpp:137] Memory required for data: 50382000
I1210 14:03:10.158695  4700 layer_factory.cpp:58] Creating layer conv1_0
I1210 14:03:10.158695  4700 net.cpp:84] Creating Layer conv1_0
I1210 14:03:10.158695  4700 net.cpp:406] conv1_0 <- conv1
I1210 14:03:10.158695  4700 net.cpp:380] conv1_0 -> conv1_0
I1210 14:03:10.160696  4700 net.cpp:122] Setting up conv1_0
I1210 14:03:10.160696  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.160696  4700 net.cpp:137] Memory required for data: 66766000
I1210 14:03:10.160696  4700 layer_factory.cpp:58] Creating layer bn1_0
I1210 14:03:10.160696  4700 net.cpp:84] Creating Layer bn1_0
I1210 14:03:10.160696  4700 net.cpp:406] bn1_0 <- conv1_0
I1210 14:03:10.160696  4700 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1210 14:03:10.160696  4700 net.cpp:122] Setting up bn1_0
I1210 14:03:10.160696  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.160696  4700 net.cpp:137] Memory required for data: 83150000
I1210 14:03:10.160696  4700 layer_factory.cpp:58] Creating layer scale1_0
I1210 14:03:10.160696  4700 net.cpp:84] Creating Layer scale1_0
I1210 14:03:10.160696  4700 net.cpp:406] scale1_0 <- conv1_0
I1210 14:03:10.160696  4700 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1210 14:03:10.161195  4700 layer_factory.cpp:58] Creating layer scale1_0
I1210 14:03:10.161195  4700 net.cpp:122] Setting up scale1_0
I1210 14:03:10.161195  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.161195  4700 net.cpp:137] Memory required for data: 99534000
I1210 14:03:10.161195  4700 layer_factory.cpp:58] Creating layer relu1_0
I1210 14:03:10.161195  4700 net.cpp:84] Creating Layer relu1_0
I1210 14:03:10.161195  4700 net.cpp:406] relu1_0 <- conv1_0
I1210 14:03:10.161195  4700 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1210 14:03:10.161195  4700 net.cpp:122] Setting up relu1_0
I1210 14:03:10.161195  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.161195  4700 net.cpp:137] Memory required for data: 115918000
I1210 14:03:10.161195  4700 layer_factory.cpp:58] Creating layer conv2
I1210 14:03:10.161195  4700 net.cpp:84] Creating Layer conv2
I1210 14:03:10.161195  4700 net.cpp:406] conv2 <- conv1_0
I1210 14:03:10.161195  4700 net.cpp:380] conv2 -> conv2
I1210 14:03:10.162694  4700 net.cpp:122] Setting up conv2
I1210 14:03:10.162694  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.162694  4700 net.cpp:137] Memory required for data: 132302000
I1210 14:03:10.162694  4700 layer_factory.cpp:58] Creating layer bn2
I1210 14:03:10.162694  4700 net.cpp:84] Creating Layer bn2
I1210 14:03:10.162694  4700 net.cpp:406] bn2 <- conv2
I1210 14:03:10.162694  4700 net.cpp:367] bn2 -> conv2 (in-place)
I1210 14:03:10.162694  4700 net.cpp:122] Setting up bn2
I1210 14:03:10.162694  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.162694  4700 net.cpp:137] Memory required for data: 148686000
I1210 14:03:10.162694  4700 layer_factory.cpp:58] Creating layer scale2
I1210 14:03:10.162694  4700 net.cpp:84] Creating Layer scale2
I1210 14:03:10.162694  4700 net.cpp:406] scale2 <- conv2
I1210 14:03:10.162694  4700 net.cpp:367] scale2 -> conv2 (in-place)
I1210 14:03:10.162694  4700 layer_factory.cpp:58] Creating layer scale2
I1210 14:03:10.162694  4700 net.cpp:122] Setting up scale2
I1210 14:03:10.162694  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.162694  4700 net.cpp:137] Memory required for data: 165070000
I1210 14:03:10.163195  4700 layer_factory.cpp:58] Creating layer relu2
I1210 14:03:10.163195  4700 net.cpp:84] Creating Layer relu2
I1210 14:03:10.163195  4700 net.cpp:406] relu2 <- conv2
I1210 14:03:10.163195  4700 net.cpp:367] relu2 -> conv2 (in-place)
I1210 14:03:10.163195  4700 net.cpp:122] Setting up relu2
I1210 14:03:10.163195  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.163195  4700 net.cpp:137] Memory required for data: 181454000
I1210 14:03:10.163195  4700 layer_factory.cpp:58] Creating layer conv2_1
I1210 14:03:10.163195  4700 net.cpp:84] Creating Layer conv2_1
I1210 14:03:10.163195  4700 net.cpp:406] conv2_1 <- conv2
I1210 14:03:10.163195  4700 net.cpp:380] conv2_1 -> conv2_1
I1210 14:03:10.164695  4700 net.cpp:122] Setting up conv2_1
I1210 14:03:10.164695  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.164695  4700 net.cpp:137] Memory required for data: 197838000
I1210 14:03:10.164695  4700 layer_factory.cpp:58] Creating layer bn2_1
I1210 14:03:10.164695  4700 net.cpp:84] Creating Layer bn2_1
I1210 14:03:10.164695  4700 net.cpp:406] bn2_1 <- conv2_1
I1210 14:03:10.164695  4700 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1210 14:03:10.164695  4700 net.cpp:122] Setting up bn2_1
I1210 14:03:10.164695  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.165195  4700 net.cpp:137] Memory required for data: 214222000
I1210 14:03:10.165195  4700 layer_factory.cpp:58] Creating layer scale2_1
I1210 14:03:10.165195  4700 net.cpp:84] Creating Layer scale2_1
I1210 14:03:10.165195  4700 net.cpp:406] scale2_1 <- conv2_1
I1210 14:03:10.165195  4700 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1210 14:03:10.165195  4700 layer_factory.cpp:58] Creating layer scale2_1
I1210 14:03:10.165195  4700 net.cpp:122] Setting up scale2_1
I1210 14:03:10.165195  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.165195  4700 net.cpp:137] Memory required for data: 230606000
I1210 14:03:10.165195  4700 layer_factory.cpp:58] Creating layer relu2_1
I1210 14:03:10.165195  4700 net.cpp:84] Creating Layer relu2_1
I1210 14:03:10.165195  4700 net.cpp:406] relu2_1 <- conv2_1
I1210 14:03:10.165195  4700 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1210 14:03:10.165695  4700 net.cpp:122] Setting up relu2_1
I1210 14:03:10.165695  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.165695  4700 net.cpp:137] Memory required for data: 246990000
I1210 14:03:10.165695  4700 layer_factory.cpp:58] Creating layer conv2_2
I1210 14:03:10.165695  4700 net.cpp:84] Creating Layer conv2_2
I1210 14:03:10.165695  4700 net.cpp:406] conv2_2 <- conv2_1
I1210 14:03:10.165695  4700 net.cpp:380] conv2_2 -> conv2_2
I1210 14:03:10.167196  4700 net.cpp:122] Setting up conv2_2
I1210 14:03:10.167196  4700 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 14:03:10.167196  4700 net.cpp:137] Memory required for data: 267470000
I1210 14:03:10.167196  4700 layer_factory.cpp:58] Creating layer bn2_2
I1210 14:03:10.167196  4700 net.cpp:84] Creating Layer bn2_2
I1210 14:03:10.167196  4700 net.cpp:406] bn2_2 <- conv2_2
I1210 14:03:10.167196  4700 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1210 14:03:10.167697  4700 net.cpp:122] Setting up bn2_2
I1210 14:03:10.167697  4700 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 14:03:10.167697  4700 net.cpp:137] Memory required for data: 287950000
I1210 14:03:10.167697  4700 layer_factory.cpp:58] Creating layer scale2_2
I1210 14:03:10.167697  4700 net.cpp:84] Creating Layer scale2_2
I1210 14:03:10.167697  4700 net.cpp:406] scale2_2 <- conv2_2
I1210 14:03:10.167697  4700 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1210 14:03:10.167697  4700 layer_factory.cpp:58] Creating layer scale2_2
I1210 14:03:10.167697  4700 net.cpp:122] Setting up scale2_2
I1210 14:03:10.167697  4700 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 14:03:10.167697  4700 net.cpp:137] Memory required for data: 308430000
I1210 14:03:10.167697  4700 layer_factory.cpp:58] Creating layer relu2_2
I1210 14:03:10.167697  4700 net.cpp:84] Creating Layer relu2_2
I1210 14:03:10.167697  4700 net.cpp:406] relu2_2 <- conv2_2
I1210 14:03:10.167697  4700 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1210 14:03:10.168200  4700 net.cpp:122] Setting up relu2_2
I1210 14:03:10.168200  4700 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 14:03:10.168200  4700 net.cpp:137] Memory required for data: 328910000
I1210 14:03:10.168200  4700 layer_factory.cpp:58] Creating layer newconv_added1
I1210 14:03:10.168200  4700 net.cpp:84] Creating Layer newconv_added1
I1210 14:03:10.168200  4700 net.cpp:406] newconv_added1 <- conv2_2
I1210 14:03:10.168200  4700 net.cpp:380] newconv_added1 -> newconv_added1
I1210 14:03:10.169194  4700 net.cpp:122] Setting up newconv_added1
I1210 14:03:10.169194  4700 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 14:03:10.169194  4700 net.cpp:137] Memory required for data: 349390000
I1210 14:03:10.169194  4700 layer_factory.cpp:58] Creating layer pool2_1
I1210 14:03:10.169194  4700 net.cpp:84] Creating Layer pool2_1
I1210 14:03:10.169194  4700 net.cpp:406] pool2_1 <- newconv_added1
I1210 14:03:10.169194  4700 net.cpp:380] pool2_1 -> pool2_1
I1210 14:03:10.169694  4700 net.cpp:122] Setting up pool2_1
I1210 14:03:10.169694  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.169694  4700 net.cpp:137] Memory required for data: 354510000
I1210 14:03:10.169694  4700 layer_factory.cpp:58] Creating layer conv3
I1210 14:03:10.169694  4700 net.cpp:84] Creating Layer conv3
I1210 14:03:10.169694  4700 net.cpp:406] conv3 <- pool2_1
I1210 14:03:10.169694  4700 net.cpp:380] conv3 -> conv3
I1210 14:03:10.171197  4700 net.cpp:122] Setting up conv3
I1210 14:03:10.171197  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.171197  4700 net.cpp:137] Memory required for data: 359630000
I1210 14:03:10.171197  4700 layer_factory.cpp:58] Creating layer bn3
I1210 14:03:10.171197  4700 net.cpp:84] Creating Layer bn3
I1210 14:03:10.171197  4700 net.cpp:406] bn3 <- conv3
I1210 14:03:10.171197  4700 net.cpp:367] bn3 -> conv3 (in-place)
I1210 14:03:10.171197  4700 net.cpp:122] Setting up bn3
I1210 14:03:10.171197  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.171197  4700 net.cpp:137] Memory required for data: 364750000
I1210 14:03:10.171197  4700 layer_factory.cpp:58] Creating layer scale3
I1210 14:03:10.171197  4700 net.cpp:84] Creating Layer scale3
I1210 14:03:10.171197  4700 net.cpp:406] scale3 <- conv3
I1210 14:03:10.171197  4700 net.cpp:367] scale3 -> conv3 (in-place)
I1210 14:03:10.171197  4700 layer_factory.cpp:58] Creating layer scale3
I1210 14:03:10.171197  4700 net.cpp:122] Setting up scale3
I1210 14:03:10.171197  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.171197  4700 net.cpp:137] Memory required for data: 369870000
I1210 14:03:10.171197  4700 layer_factory.cpp:58] Creating layer relu3
I1210 14:03:10.171197  4700 net.cpp:84] Creating Layer relu3
I1210 14:03:10.171197  4700 net.cpp:406] relu3 <- conv3
I1210 14:03:10.171197  4700 net.cpp:367] relu3 -> conv3 (in-place)
I1210 14:03:10.172374  4700 net.cpp:122] Setting up relu3
I1210 14:03:10.172374  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.172374  4700 net.cpp:137] Memory required for data: 374990000
I1210 14:03:10.172374  4700 layer_factory.cpp:58] Creating layer conv3_1
I1210 14:03:10.172374  4700 net.cpp:84] Creating Layer conv3_1
I1210 14:03:10.172374  4700 net.cpp:406] conv3_1 <- conv3
I1210 14:03:10.172374  4700 net.cpp:380] conv3_1 -> conv3_1
I1210 14:03:10.173377  4700 net.cpp:122] Setting up conv3_1
I1210 14:03:10.173377  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.173377  4700 net.cpp:137] Memory required for data: 380110000
I1210 14:03:10.173377  4700 layer_factory.cpp:58] Creating layer bn3_1
I1210 14:03:10.173377  4700 net.cpp:84] Creating Layer bn3_1
I1210 14:03:10.173377  4700 net.cpp:406] bn3_1 <- conv3_1
I1210 14:03:10.173377  4700 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1210 14:03:10.173377  4700 net.cpp:122] Setting up bn3_1
I1210 14:03:10.173377  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.173377  4700 net.cpp:137] Memory required for data: 385230000
I1210 14:03:10.173377  4700 layer_factory.cpp:58] Creating layer scale3_1
I1210 14:03:10.173377  4700 net.cpp:84] Creating Layer scale3_1
I1210 14:03:10.173377  4700 net.cpp:406] scale3_1 <- conv3_1
I1210 14:03:10.173377  4700 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1210 14:03:10.173377  4700 layer_factory.cpp:58] Creating layer scale3_1
I1210 14:03:10.173377  4700 net.cpp:122] Setting up scale3_1
I1210 14:03:10.173377  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.173377  4700 net.cpp:137] Memory required for data: 390350000
I1210 14:03:10.173377  4700 layer_factory.cpp:58] Creating layer relu3_1
I1210 14:03:10.173377  4700 net.cpp:84] Creating Layer relu3_1
I1210 14:03:10.173377  4700 net.cpp:406] relu3_1 <- conv3_1
I1210 14:03:10.173377  4700 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1210 14:03:10.174374  4700 net.cpp:122] Setting up relu3_1
I1210 14:03:10.174374  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.174374  4700 net.cpp:137] Memory required for data: 395470000
I1210 14:03:10.174374  4700 layer_factory.cpp:58] Creating layer conv4
I1210 14:03:10.174374  4700 net.cpp:84] Creating Layer conv4
I1210 14:03:10.174374  4700 net.cpp:406] conv4 <- conv3_1
I1210 14:03:10.174374  4700 net.cpp:380] conv4 -> conv4
I1210 14:03:10.175377  4700 net.cpp:122] Setting up conv4
I1210 14:03:10.175377  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.175377  4700 net.cpp:137] Memory required for data: 400590000
I1210 14:03:10.175377  4700 layer_factory.cpp:58] Creating layer bn4
I1210 14:03:10.175377  4700 net.cpp:84] Creating Layer bn4
I1210 14:03:10.175377  4700 net.cpp:406] bn4 <- conv4
I1210 14:03:10.175377  4700 net.cpp:367] bn4 -> conv4 (in-place)
I1210 14:03:10.176378  4700 net.cpp:122] Setting up bn4
I1210 14:03:10.176378  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.176378  4700 net.cpp:137] Memory required for data: 405710000
I1210 14:03:10.176378  4700 layer_factory.cpp:58] Creating layer scale4
I1210 14:03:10.176378  4700 net.cpp:84] Creating Layer scale4
I1210 14:03:10.176378  4700 net.cpp:406] scale4 <- conv4
I1210 14:03:10.176378  4700 net.cpp:367] scale4 -> conv4 (in-place)
I1210 14:03:10.176378  4700 layer_factory.cpp:58] Creating layer scale4
I1210 14:03:10.176378  4700 net.cpp:122] Setting up scale4
I1210 14:03:10.176378  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.176378  4700 net.cpp:137] Memory required for data: 410830000
I1210 14:03:10.176378  4700 layer_factory.cpp:58] Creating layer relu4
I1210 14:03:10.176378  4700 net.cpp:84] Creating Layer relu4
I1210 14:03:10.176378  4700 net.cpp:406] relu4 <- conv4
I1210 14:03:10.176378  4700 net.cpp:367] relu4 -> conv4 (in-place)
I1210 14:03:10.176378  4700 net.cpp:122] Setting up relu4
I1210 14:03:10.176378  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.176378  4700 net.cpp:137] Memory required for data: 415950000
I1210 14:03:10.176378  4700 layer_factory.cpp:58] Creating layer conv4_1
I1210 14:03:10.176378  4700 net.cpp:84] Creating Layer conv4_1
I1210 14:03:10.176378  4700 net.cpp:406] conv4_1 <- conv4
I1210 14:03:10.176378  4700 net.cpp:380] conv4_1 -> conv4_1
I1210 14:03:10.178376  4700 net.cpp:122] Setting up conv4_1
I1210 14:03:10.178376  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.178376  4700 net.cpp:137] Memory required for data: 421070000
I1210 14:03:10.178376  4700 layer_factory.cpp:58] Creating layer bn4_1
I1210 14:03:10.178376  4700 net.cpp:84] Creating Layer bn4_1
I1210 14:03:10.178376  4700 net.cpp:406] bn4_1 <- conv4_1
I1210 14:03:10.178376  4700 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1210 14:03:10.178376  4700 net.cpp:122] Setting up bn4_1
I1210 14:03:10.178376  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.178376  4700 net.cpp:137] Memory required for data: 426190000
I1210 14:03:10.178376  4700 layer_factory.cpp:58] Creating layer scale4_1
I1210 14:03:10.178376  4700 net.cpp:84] Creating Layer scale4_1
I1210 14:03:10.178376  4700 net.cpp:406] scale4_1 <- conv4_1
I1210 14:03:10.178376  4700 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1210 14:03:10.178376  4700 layer_factory.cpp:58] Creating layer scale4_1
I1210 14:03:10.178376  4700 net.cpp:122] Setting up scale4_1
I1210 14:03:10.178376  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.178376  4700 net.cpp:137] Memory required for data: 431310000
I1210 14:03:10.179378  4700 layer_factory.cpp:58] Creating layer relu4_1
I1210 14:03:10.179378  4700 net.cpp:84] Creating Layer relu4_1
I1210 14:03:10.179378  4700 net.cpp:406] relu4_1 <- conv4_1
I1210 14:03:10.179378  4700 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1210 14:03:10.179378  4700 net.cpp:122] Setting up relu4_1
I1210 14:03:10.179378  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.179378  4700 net.cpp:137] Memory required for data: 436430000
I1210 14:03:10.179378  4700 layer_factory.cpp:58] Creating layer conv4_2
I1210 14:03:10.179378  4700 net.cpp:84] Creating Layer conv4_2
I1210 14:03:10.179378  4700 net.cpp:406] conv4_2 <- conv4_1
I1210 14:03:10.179378  4700 net.cpp:380] conv4_2 -> conv4_2
I1210 14:03:10.180372  4700 net.cpp:122] Setting up conv4_2
I1210 14:03:10.180372  4700 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 14:03:10.180372  4700 net.cpp:137] Memory required for data: 442369200
I1210 14:03:10.180372  4700 layer_factory.cpp:58] Creating layer bn4_2
I1210 14:03:10.180372  4700 net.cpp:84] Creating Layer bn4_2
I1210 14:03:10.180372  4700 net.cpp:406] bn4_2 <- conv4_2
I1210 14:03:10.180372  4700 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1210 14:03:10.180372  4700 net.cpp:122] Setting up bn4_2
I1210 14:03:10.180372  4700 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 14:03:10.180372  4700 net.cpp:137] Memory required for data: 448308400
I1210 14:03:10.180372  4700 layer_factory.cpp:58] Creating layer scale4_2
I1210 14:03:10.180372  4700 net.cpp:84] Creating Layer scale4_2
I1210 14:03:10.180372  4700 net.cpp:406] scale4_2 <- conv4_2
I1210 14:03:10.180372  4700 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1210 14:03:10.180372  4700 layer_factory.cpp:58] Creating layer scale4_2
I1210 14:03:10.180372  4700 net.cpp:122] Setting up scale4_2
I1210 14:03:10.181376  4700 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 14:03:10.181376  4700 net.cpp:137] Memory required for data: 454247600
I1210 14:03:10.181376  4700 layer_factory.cpp:58] Creating layer relu4_2
I1210 14:03:10.181376  4700 net.cpp:84] Creating Layer relu4_2
I1210 14:03:10.181376  4700 net.cpp:406] relu4_2 <- conv4_2
I1210 14:03:10.181376  4700 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1210 14:03:10.181376  4700 net.cpp:122] Setting up relu4_2
I1210 14:03:10.181376  4700 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 14:03:10.181376  4700 net.cpp:137] Memory required for data: 460186800
I1210 14:03:10.181376  4700 layer_factory.cpp:58] Creating layer added_new_conv2
I1210 14:03:10.181376  4700 net.cpp:84] Creating Layer added_new_conv2
I1210 14:03:10.181376  4700 net.cpp:406] added_new_conv2 <- conv4_2
I1210 14:03:10.181376  4700 net.cpp:380] added_new_conv2 -> added_new_conv2
I1210 14:03:10.183393  4700 net.cpp:122] Setting up added_new_conv2
I1210 14:03:10.183393  4700 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 14:03:10.183393  4700 net.cpp:137] Memory required for data: 466126000
I1210 14:03:10.183393  4700 layer_factory.cpp:58] Creating layer pool4_2
I1210 14:03:10.183393  4700 net.cpp:84] Creating Layer pool4_2
I1210 14:03:10.183393  4700 net.cpp:406] pool4_2 <- added_new_conv2
I1210 14:03:10.183393  4700 net.cpp:380] pool4_2 -> pool4_2
I1210 14:03:10.183393  4700 net.cpp:122] Setting up pool4_2
I1210 14:03:10.183393  4700 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 14:03:10.183393  4700 net.cpp:137] Memory required for data: 467610800
I1210 14:03:10.183393  4700 layer_factory.cpp:58] Creating layer conv4_0
I1210 14:03:10.183393  4700 net.cpp:84] Creating Layer conv4_0
I1210 14:03:10.183393  4700 net.cpp:406] conv4_0 <- pool4_2
I1210 14:03:10.183393  4700 net.cpp:380] conv4_0 -> conv4_0
I1210 14:03:10.184376  4700 net.cpp:122] Setting up conv4_0
I1210 14:03:10.184376  4700 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 14:03:10.184376  4700 net.cpp:137] Memory required for data: 469095600
I1210 14:03:10.184376  4700 layer_factory.cpp:58] Creating layer bn4_0
I1210 14:03:10.184376  4700 net.cpp:84] Creating Layer bn4_0
I1210 14:03:10.184376  4700 net.cpp:406] bn4_0 <- conv4_0
I1210 14:03:10.184376  4700 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1210 14:03:10.185387  4700 net.cpp:122] Setting up bn4_0
I1210 14:03:10.185387  4700 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 14:03:10.185387  4700 net.cpp:137] Memory required for data: 470580400
I1210 14:03:10.185387  4700 layer_factory.cpp:58] Creating layer scale4_0
I1210 14:03:10.185387  4700 net.cpp:84] Creating Layer scale4_0
I1210 14:03:10.185387  4700 net.cpp:406] scale4_0 <- conv4_0
I1210 14:03:10.185387  4700 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1210 14:03:10.185387  4700 layer_factory.cpp:58] Creating layer scale4_0
I1210 14:03:10.185387  4700 net.cpp:122] Setting up scale4_0
I1210 14:03:10.185387  4700 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 14:03:10.185387  4700 net.cpp:137] Memory required for data: 472065200
I1210 14:03:10.185387  4700 layer_factory.cpp:58] Creating layer relu4_0
I1210 14:03:10.185387  4700 net.cpp:84] Creating Layer relu4_0
I1210 14:03:10.185387  4700 net.cpp:406] relu4_0 <- conv4_0
I1210 14:03:10.185387  4700 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1210 14:03:10.185387  4700 net.cpp:122] Setting up relu4_0
I1210 14:03:10.185387  4700 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 14:03:10.185387  4700 net.cpp:137] Memory required for data: 473550000
I1210 14:03:10.185387  4700 layer_factory.cpp:58] Creating layer conv11
I1210 14:03:10.185387  4700 net.cpp:84] Creating Layer conv11
I1210 14:03:10.185387  4700 net.cpp:406] conv11 <- conv4_0
I1210 14:03:10.185387  4700 net.cpp:380] conv11 -> conv11
I1210 14:03:10.187376  4700 net.cpp:122] Setting up conv11
I1210 14:03:10.187376  4700 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 14:03:10.187376  4700 net.cpp:137] Memory required for data: 475342000
I1210 14:03:10.187376  4700 layer_factory.cpp:58] Creating layer bn_conv11
I1210 14:03:10.187376  4700 net.cpp:84] Creating Layer bn_conv11
I1210 14:03:10.187376  4700 net.cpp:406] bn_conv11 <- conv11
I1210 14:03:10.187376  4700 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1210 14:03:10.187376  4700 net.cpp:122] Setting up bn_conv11
I1210 14:03:10.187376  4700 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 14:03:10.187376  4700 net.cpp:137] Memory required for data: 477134000
I1210 14:03:10.187376  4700 layer_factory.cpp:58] Creating layer scale_conv11
I1210 14:03:10.187376  4700 net.cpp:84] Creating Layer scale_conv11
I1210 14:03:10.187376  4700 net.cpp:406] scale_conv11 <- conv11
I1210 14:03:10.187376  4700 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1210 14:03:10.187376  4700 layer_factory.cpp:58] Creating layer scale_conv11
I1210 14:03:10.187376  4700 net.cpp:122] Setting up scale_conv11
I1210 14:03:10.187376  4700 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 14:03:10.187376  4700 net.cpp:137] Memory required for data: 478926000
I1210 14:03:10.187376  4700 layer_factory.cpp:58] Creating layer relu_conv11
I1210 14:03:10.187376  4700 net.cpp:84] Creating Layer relu_conv11
I1210 14:03:10.187376  4700 net.cpp:406] relu_conv11 <- conv11
I1210 14:03:10.187376  4700 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1210 14:03:10.188376  4700 net.cpp:122] Setting up relu_conv11
I1210 14:03:10.188376  4700 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 14:03:10.188376  4700 net.cpp:137] Memory required for data: 480718000
I1210 14:03:10.188376  4700 layer_factory.cpp:58] Creating layer conv12
I1210 14:03:10.188376  4700 net.cpp:84] Creating Layer conv12
I1210 14:03:10.188376  4700 net.cpp:406] conv12 <- conv11
I1210 14:03:10.188376  4700 net.cpp:380] conv12 -> conv12
I1210 14:03:10.189376  4700 net.cpp:122] Setting up conv12
I1210 14:03:10.189376  4700 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 14:03:10.189376  4700 net.cpp:137] Memory required for data: 483022000
I1210 14:03:10.189376  4700 layer_factory.cpp:58] Creating layer bn_conv12
I1210 14:03:10.189376  4700 net.cpp:84] Creating Layer bn_conv12
I1210 14:03:10.189376  4700 net.cpp:406] bn_conv12 <- conv12
I1210 14:03:10.189376  4700 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1210 14:03:10.190376  4700 net.cpp:122] Setting up bn_conv12
I1210 14:03:10.190376  4700 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 14:03:10.190376  4700 net.cpp:137] Memory required for data: 485326000
I1210 14:03:10.190376  4700 layer_factory.cpp:58] Creating layer scale_conv12
I1210 14:03:10.190376  4700 net.cpp:84] Creating Layer scale_conv12
I1210 14:03:10.190376  4700 net.cpp:406] scale_conv12 <- conv12
I1210 14:03:10.190376  4700 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1210 14:03:10.190376  4700 layer_factory.cpp:58] Creating layer scale_conv12
I1210 14:03:10.190376  4700 net.cpp:122] Setting up scale_conv12
I1210 14:03:10.190376  4700 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 14:03:10.190376  4700 net.cpp:137] Memory required for data: 487630000
I1210 14:03:10.190376  4700 layer_factory.cpp:58] Creating layer relu_conv12
I1210 14:03:10.190376  4700 net.cpp:84] Creating Layer relu_conv12
I1210 14:03:10.190376  4700 net.cpp:406] relu_conv12 <- conv12
I1210 14:03:10.190376  4700 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1210 14:03:10.190376  4700 net.cpp:122] Setting up relu_conv12
I1210 14:03:10.190376  4700 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 14:03:10.190376  4700 net.cpp:137] Memory required for data: 489934000
I1210 14:03:10.190376  4700 layer_factory.cpp:58] Creating layer poolcp6
I1210 14:03:10.190376  4700 net.cpp:84] Creating Layer poolcp6
I1210 14:03:10.190376  4700 net.cpp:406] poolcp6 <- conv12
I1210 14:03:10.190376  4700 net.cpp:380] poolcp6 -> poolcp6
I1210 14:03:10.191373  4700 net.cpp:122] Setting up poolcp6
I1210 14:03:10.191373  4700 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1210 14:03:10.191373  4700 net.cpp:137] Memory required for data: 489970000
I1210 14:03:10.191373  4700 layer_factory.cpp:58] Creating layer ip1
I1210 14:03:10.191373  4700 net.cpp:84] Creating Layer ip1
I1210 14:03:10.191373  4700 net.cpp:406] ip1 <- poolcp6
I1210 14:03:10.191373  4700 net.cpp:380] ip1 -> ip1
I1210 14:03:10.191373  4700 net.cpp:122] Setting up ip1
I1210 14:03:10.191373  4700 net.cpp:129] Top shape: 100 100 (10000)
I1210 14:03:10.191373  4700 net.cpp:137] Memory required for data: 490010000
I1210 14:03:10.191373  4700 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1210 14:03:10.191373  4700 net.cpp:84] Creating Layer ip1_ip1_0_split
I1210 14:03:10.191373  4700 net.cpp:406] ip1_ip1_0_split <- ip1
I1210 14:03:10.191373  4700 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1210 14:03:10.191373  4700 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1210 14:03:10.191373  4700 net.cpp:122] Setting up ip1_ip1_0_split
I1210 14:03:10.191373  4700 net.cpp:129] Top shape: 100 100 (10000)
I1210 14:03:10.191373  4700 net.cpp:129] Top shape: 100 100 (10000)
I1210 14:03:10.191373  4700 net.cpp:137] Memory required for data: 490090000
I1210 14:03:10.191373  4700 layer_factory.cpp:58] Creating layer accuracy_training
I1210 14:03:10.191373  4700 net.cpp:84] Creating Layer accuracy_training
I1210 14:03:10.191373  4700 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1210 14:03:10.191373  4700 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1210 14:03:10.191373  4700 net.cpp:380] accuracy_training -> accuracy_training
I1210 14:03:10.191373  4700 net.cpp:122] Setting up accuracy_training
I1210 14:03:10.191373  4700 net.cpp:129] Top shape: (1)
I1210 14:03:10.191373  4700 net.cpp:137] Memory required for data: 490090004
I1210 14:03:10.191373  4700 layer_factory.cpp:58] Creating layer loss
I1210 14:03:10.191373  4700 net.cpp:84] Creating Layer loss
I1210 14:03:10.191373  4700 net.cpp:406] loss <- ip1_ip1_0_split_1
I1210 14:03:10.191373  4700 net.cpp:406] loss <- label_cifar_1_split_1
I1210 14:03:10.191373  4700 net.cpp:380] loss -> loss
I1210 14:03:10.191373  4700 layer_factory.cpp:58] Creating layer loss
I1210 14:03:10.192376  4700 net.cpp:122] Setting up loss
I1210 14:03:10.192376  4700 net.cpp:129] Top shape: (1)
I1210 14:03:10.192376  4700 net.cpp:132]     with loss weight 1
I1210 14:03:10.192376  4700 net.cpp:137] Memory required for data: 490090008
I1210 14:03:10.192376  4700 net.cpp:198] loss needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:200] accuracy_training does not need backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] ip1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] poolcp6 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu_conv12 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale_conv12 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn_conv12 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv12 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu_conv11 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale_conv11 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn_conv11 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv11 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu4_0 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale4_0 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn4_0 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv4_0 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] pool4_2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] added_new_conv2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu4_2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale4_2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn4_2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv4_2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu4_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale4_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn4_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv4_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu4 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale4 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn4 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv4 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu3_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale3_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn3_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv3_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu3 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale3 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn3 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv3 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] pool2_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] newconv_added1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu2_2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale2_2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn2_2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv2_2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu2_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale2_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn2_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv2_1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv2 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu1_0 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale1_0 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn1_0 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv1_0 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] relu1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] scale1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] bn1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:198] conv1 needs backward computation.
I1210 14:03:10.192376  4700 net.cpp:200] label_cifar_1_split does not need backward computation.
I1210 14:03:10.192376  4700 net.cpp:200] cifar does not need backward computation.
I1210 14:03:10.192376  4700 net.cpp:242] This network produces output accuracy_training
I1210 14:03:10.192376  4700 net.cpp:242] This network produces output loss
I1210 14:03:10.192376  4700 net.cpp:255] Network initialization done.
I1210 14:03:10.193377  4700 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 14:03:10.193377  4700 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 14:03:10.193377  4700 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1210 14:03:10.193377  4700 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1210 14:03:10.194386  4700 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_v2_360k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "newconv_added1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "newconv_added1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "newconv_added1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "added_new_conv2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "added_new_conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "added_new_conv2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1210 14:03:10.194386  4700 layer_factory.cpp:58] Creating layer cifar
I1210 14:03:10.197374  4700 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1210 14:03:10.197374  4700 net.cpp:84] Creating Layer cifar
I1210 14:03:10.197374  4700 net.cpp:380] cifar -> data
I1210 14:03:10.197374  4700 net.cpp:380] cifar -> label
I1210 14:03:10.197374  4700 data_layer.cpp:45] output data size: 100,3,32,32
I1210 14:03:10.203377  4700 net.cpp:122] Setting up cifar
I1210 14:03:10.203377  4700 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1210 14:03:10.203377  4700 net.cpp:129] Top shape: 100 (100)
I1210 14:03:10.203377  4700 net.cpp:137] Memory required for data: 1229200
I1210 14:03:10.203377  4700 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1210 14:03:10.203377  4700 net.cpp:84] Creating Layer label_cifar_1_split
I1210 14:03:10.203377  4700 net.cpp:406] label_cifar_1_split <- label
I1210 14:03:10.203377  4700 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1210 14:03:10.203377  4700 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1210 14:03:10.203377  4700 net.cpp:122] Setting up label_cifar_1_split
I1210 14:03:10.203377  4700 net.cpp:129] Top shape: 100 (100)
I1210 14:03:10.203377  4700 net.cpp:129] Top shape: 100 (100)
I1210 14:03:10.203377  4700 net.cpp:137] Memory required for data: 1230000
I1210 14:03:10.203377  4700 layer_factory.cpp:58] Creating layer conv1
I1210 14:03:10.203377  4700 net.cpp:84] Creating Layer conv1
I1210 14:03:10.203377  4700 net.cpp:406] conv1 <- data
I1210 14:03:10.203377  4700 net.cpp:380] conv1 -> conv1
I1210 14:03:10.205376  5200 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 14:03:10.205376  4700 net.cpp:122] Setting up conv1
I1210 14:03:10.205376  4700 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 14:03:10.205376  4700 net.cpp:137] Memory required for data: 13518000
I1210 14:03:10.205376  4700 layer_factory.cpp:58] Creating layer bn1
I1210 14:03:10.205376  4700 net.cpp:84] Creating Layer bn1
I1210 14:03:10.205376  4700 net.cpp:406] bn1 <- conv1
I1210 14:03:10.205376  4700 net.cpp:367] bn1 -> conv1 (in-place)
I1210 14:03:10.206387  4700 net.cpp:122] Setting up bn1
I1210 14:03:10.206387  4700 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 14:03:10.206387  4700 net.cpp:137] Memory required for data: 25806000
I1210 14:03:10.206387  4700 layer_factory.cpp:58] Creating layer scale1
I1210 14:03:10.206387  4700 net.cpp:84] Creating Layer scale1
I1210 14:03:10.206387  4700 net.cpp:406] scale1 <- conv1
I1210 14:03:10.206387  4700 net.cpp:367] scale1 -> conv1 (in-place)
I1210 14:03:10.206387  4700 layer_factory.cpp:58] Creating layer scale1
I1210 14:03:10.206387  4700 net.cpp:122] Setting up scale1
I1210 14:03:10.206387  4700 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 14:03:10.206387  4700 net.cpp:137] Memory required for data: 38094000
I1210 14:03:10.206387  4700 layer_factory.cpp:58] Creating layer relu1
I1210 14:03:10.206387  4700 net.cpp:84] Creating Layer relu1
I1210 14:03:10.206387  4700 net.cpp:406] relu1 <- conv1
I1210 14:03:10.206387  4700 net.cpp:367] relu1 -> conv1 (in-place)
I1210 14:03:10.206387  4700 net.cpp:122] Setting up relu1
I1210 14:03:10.206387  4700 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1210 14:03:10.206387  4700 net.cpp:137] Memory required for data: 50382000
I1210 14:03:10.206387  4700 layer_factory.cpp:58] Creating layer conv1_0
I1210 14:03:10.206387  4700 net.cpp:84] Creating Layer conv1_0
I1210 14:03:10.206387  4700 net.cpp:406] conv1_0 <- conv1
I1210 14:03:10.206387  4700 net.cpp:380] conv1_0 -> conv1_0
I1210 14:03:10.208375  4700 net.cpp:122] Setting up conv1_0
I1210 14:03:10.208375  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.208375  4700 net.cpp:137] Memory required for data: 66766000
I1210 14:03:10.208375  4700 layer_factory.cpp:58] Creating layer bn1_0
I1210 14:03:10.208375  4700 net.cpp:84] Creating Layer bn1_0
I1210 14:03:10.208375  4700 net.cpp:406] bn1_0 <- conv1_0
I1210 14:03:10.208375  4700 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1210 14:03:10.208375  4700 net.cpp:122] Setting up bn1_0
I1210 14:03:10.208375  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.208375  4700 net.cpp:137] Memory required for data: 83150000
I1210 14:03:10.208375  4700 layer_factory.cpp:58] Creating layer scale1_0
I1210 14:03:10.208375  4700 net.cpp:84] Creating Layer scale1_0
I1210 14:03:10.208375  4700 net.cpp:406] scale1_0 <- conv1_0
I1210 14:03:10.208375  4700 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1210 14:03:10.208375  4700 layer_factory.cpp:58] Creating layer scale1_0
I1210 14:03:10.209374  4700 net.cpp:122] Setting up scale1_0
I1210 14:03:10.209374  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.209374  4700 net.cpp:137] Memory required for data: 99534000
I1210 14:03:10.209374  4700 layer_factory.cpp:58] Creating layer relu1_0
I1210 14:03:10.209374  4700 net.cpp:84] Creating Layer relu1_0
I1210 14:03:10.209374  4700 net.cpp:406] relu1_0 <- conv1_0
I1210 14:03:10.209374  4700 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1210 14:03:10.209374  4700 net.cpp:122] Setting up relu1_0
I1210 14:03:10.209374  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.209374  4700 net.cpp:137] Memory required for data: 115918000
I1210 14:03:10.209374  4700 layer_factory.cpp:58] Creating layer conv2
I1210 14:03:10.209374  4700 net.cpp:84] Creating Layer conv2
I1210 14:03:10.209374  4700 net.cpp:406] conv2 <- conv1_0
I1210 14:03:10.209374  4700 net.cpp:380] conv2 -> conv2
I1210 14:03:10.211376  4700 net.cpp:122] Setting up conv2
I1210 14:03:10.211376  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.211376  4700 net.cpp:137] Memory required for data: 132302000
I1210 14:03:10.211376  4700 layer_factory.cpp:58] Creating layer bn2
I1210 14:03:10.211376  4700 net.cpp:84] Creating Layer bn2
I1210 14:03:10.211376  4700 net.cpp:406] bn2 <- conv2
I1210 14:03:10.211376  4700 net.cpp:367] bn2 -> conv2 (in-place)
I1210 14:03:10.211376  4700 net.cpp:122] Setting up bn2
I1210 14:03:10.211376  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.211376  4700 net.cpp:137] Memory required for data: 148686000
I1210 14:03:10.211376  4700 layer_factory.cpp:58] Creating layer scale2
I1210 14:03:10.211376  4700 net.cpp:84] Creating Layer scale2
I1210 14:03:10.211376  4700 net.cpp:406] scale2 <- conv2
I1210 14:03:10.211376  4700 net.cpp:367] scale2 -> conv2 (in-place)
I1210 14:03:10.211376  4700 layer_factory.cpp:58] Creating layer scale2
I1210 14:03:10.211376  4700 net.cpp:122] Setting up scale2
I1210 14:03:10.211376  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.211376  4700 net.cpp:137] Memory required for data: 165070000
I1210 14:03:10.211376  4700 layer_factory.cpp:58] Creating layer relu2
I1210 14:03:10.211376  4700 net.cpp:84] Creating Layer relu2
I1210 14:03:10.211376  4700 net.cpp:406] relu2 <- conv2
I1210 14:03:10.211376  4700 net.cpp:367] relu2 -> conv2 (in-place)
I1210 14:03:10.212376  4700 net.cpp:122] Setting up relu2
I1210 14:03:10.212376  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.212376  4700 net.cpp:137] Memory required for data: 181454000
I1210 14:03:10.212376  4700 layer_factory.cpp:58] Creating layer conv2_1
I1210 14:03:10.212376  4700 net.cpp:84] Creating Layer conv2_1
I1210 14:03:10.212376  4700 net.cpp:406] conv2_1 <- conv2
I1210 14:03:10.212376  4700 net.cpp:380] conv2_1 -> conv2_1
I1210 14:03:10.214392  4700 net.cpp:122] Setting up conv2_1
I1210 14:03:10.214392  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.214392  4700 net.cpp:137] Memory required for data: 197838000
I1210 14:03:10.214392  4700 layer_factory.cpp:58] Creating layer bn2_1
I1210 14:03:10.214392  4700 net.cpp:84] Creating Layer bn2_1
I1210 14:03:10.214392  4700 net.cpp:406] bn2_1 <- conv2_1
I1210 14:03:10.214392  4700 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1210 14:03:10.214392  4700 net.cpp:122] Setting up bn2_1
I1210 14:03:10.214392  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.214392  4700 net.cpp:137] Memory required for data: 214222000
I1210 14:03:10.214392  4700 layer_factory.cpp:58] Creating layer scale2_1
I1210 14:03:10.214392  4700 net.cpp:84] Creating Layer scale2_1
I1210 14:03:10.214392  4700 net.cpp:406] scale2_1 <- conv2_1
I1210 14:03:10.214392  4700 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1210 14:03:10.214392  4700 layer_factory.cpp:58] Creating layer scale2_1
I1210 14:03:10.214392  4700 net.cpp:122] Setting up scale2_1
I1210 14:03:10.214392  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.214392  4700 net.cpp:137] Memory required for data: 230606000
I1210 14:03:10.214392  4700 layer_factory.cpp:58] Creating layer relu2_1
I1210 14:03:10.214392  4700 net.cpp:84] Creating Layer relu2_1
I1210 14:03:10.214392  4700 net.cpp:406] relu2_1 <- conv2_1
I1210 14:03:10.214392  4700 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1210 14:03:10.215391  4700 net.cpp:122] Setting up relu2_1
I1210 14:03:10.215391  4700 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1210 14:03:10.215391  4700 net.cpp:137] Memory required for data: 246990000
I1210 14:03:10.215391  4700 layer_factory.cpp:58] Creating layer conv2_2
I1210 14:03:10.215391  4700 net.cpp:84] Creating Layer conv2_2
I1210 14:03:10.215391  4700 net.cpp:406] conv2_2 <- conv2_1
I1210 14:03:10.215391  4700 net.cpp:380] conv2_2 -> conv2_2
I1210 14:03:10.217387  4700 net.cpp:122] Setting up conv2_2
I1210 14:03:10.217387  4700 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 14:03:10.217387  4700 net.cpp:137] Memory required for data: 267470000
I1210 14:03:10.217387  4700 layer_factory.cpp:58] Creating layer bn2_2
I1210 14:03:10.217387  4700 net.cpp:84] Creating Layer bn2_2
I1210 14:03:10.217387  4700 net.cpp:406] bn2_2 <- conv2_2
I1210 14:03:10.217387  4700 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1210 14:03:10.217387  4700 net.cpp:122] Setting up bn2_2
I1210 14:03:10.217387  4700 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 14:03:10.217387  4700 net.cpp:137] Memory required for data: 287950000
I1210 14:03:10.217387  4700 layer_factory.cpp:58] Creating layer scale2_2
I1210 14:03:10.217387  4700 net.cpp:84] Creating Layer scale2_2
I1210 14:03:10.217387  4700 net.cpp:406] scale2_2 <- conv2_2
I1210 14:03:10.217387  4700 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1210 14:03:10.217387  4700 layer_factory.cpp:58] Creating layer scale2_2
I1210 14:03:10.217387  4700 net.cpp:122] Setting up scale2_2
I1210 14:03:10.217387  4700 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 14:03:10.217387  4700 net.cpp:137] Memory required for data: 308430000
I1210 14:03:10.217387  4700 layer_factory.cpp:58] Creating layer relu2_2
I1210 14:03:10.217387  4700 net.cpp:84] Creating Layer relu2_2
I1210 14:03:10.217387  4700 net.cpp:406] relu2_2 <- conv2_2
I1210 14:03:10.217387  4700 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1210 14:03:10.218384  4700 net.cpp:122] Setting up relu2_2
I1210 14:03:10.218384  4700 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 14:03:10.218384  4700 net.cpp:137] Memory required for data: 328910000
I1210 14:03:10.218384  4700 layer_factory.cpp:58] Creating layer newconv_added1
I1210 14:03:10.218384  4700 net.cpp:84] Creating Layer newconv_added1
I1210 14:03:10.218384  4700 net.cpp:406] newconv_added1 <- conv2_2
I1210 14:03:10.218384  4700 net.cpp:380] newconv_added1 -> newconv_added1
I1210 14:03:10.219383  4700 net.cpp:122] Setting up newconv_added1
I1210 14:03:10.219383  4700 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1210 14:03:10.219383  4700 net.cpp:137] Memory required for data: 349390000
I1210 14:03:10.219383  4700 layer_factory.cpp:58] Creating layer pool2_1
I1210 14:03:10.219383  4700 net.cpp:84] Creating Layer pool2_1
I1210 14:03:10.219383  4700 net.cpp:406] pool2_1 <- newconv_added1
I1210 14:03:10.219383  4700 net.cpp:380] pool2_1 -> pool2_1
I1210 14:03:10.219383  4700 net.cpp:122] Setting up pool2_1
I1210 14:03:10.219383  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.219383  4700 net.cpp:137] Memory required for data: 354510000
I1210 14:03:10.219383  4700 layer_factory.cpp:58] Creating layer conv3
I1210 14:03:10.219383  4700 net.cpp:84] Creating Layer conv3
I1210 14:03:10.219383  4700 net.cpp:406] conv3 <- pool2_1
I1210 14:03:10.219383  4700 net.cpp:380] conv3 -> conv3
I1210 14:03:10.221374  4700 net.cpp:122] Setting up conv3
I1210 14:03:10.221374  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.221374  4700 net.cpp:137] Memory required for data: 359630000
I1210 14:03:10.221374  4700 layer_factory.cpp:58] Creating layer bn3
I1210 14:03:10.221374  4700 net.cpp:84] Creating Layer bn3
I1210 14:03:10.221374  4700 net.cpp:406] bn3 <- conv3
I1210 14:03:10.221374  4700 net.cpp:367] bn3 -> conv3 (in-place)
I1210 14:03:10.221374  4700 net.cpp:122] Setting up bn3
I1210 14:03:10.221374  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.221374  4700 net.cpp:137] Memory required for data: 364750000
I1210 14:03:10.221374  4700 layer_factory.cpp:58] Creating layer scale3
I1210 14:03:10.221374  4700 net.cpp:84] Creating Layer scale3
I1210 14:03:10.221374  4700 net.cpp:406] scale3 <- conv3
I1210 14:03:10.221374  4700 net.cpp:367] scale3 -> conv3 (in-place)
I1210 14:03:10.221374  4700 layer_factory.cpp:58] Creating layer scale3
I1210 14:03:10.221374  4700 net.cpp:122] Setting up scale3
I1210 14:03:10.221374  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.221374  4700 net.cpp:137] Memory required for data: 369870000
I1210 14:03:10.221374  4700 layer_factory.cpp:58] Creating layer relu3
I1210 14:03:10.221374  4700 net.cpp:84] Creating Layer relu3
I1210 14:03:10.221374  4700 net.cpp:406] relu3 <- conv3
I1210 14:03:10.221374  4700 net.cpp:367] relu3 -> conv3 (in-place)
I1210 14:03:10.221374  4700 net.cpp:122] Setting up relu3
I1210 14:03:10.221374  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.221374  4700 net.cpp:137] Memory required for data: 374990000
I1210 14:03:10.221374  4700 layer_factory.cpp:58] Creating layer conv3_1
I1210 14:03:10.222373  4700 net.cpp:84] Creating Layer conv3_1
I1210 14:03:10.222373  4700 net.cpp:406] conv3_1 <- conv3
I1210 14:03:10.222373  4700 net.cpp:380] conv3_1 -> conv3_1
I1210 14:03:10.223372  4700 net.cpp:122] Setting up conv3_1
I1210 14:03:10.223372  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.223372  4700 net.cpp:137] Memory required for data: 380110000
I1210 14:03:10.223372  4700 layer_factory.cpp:58] Creating layer bn3_1
I1210 14:03:10.223372  4700 net.cpp:84] Creating Layer bn3_1
I1210 14:03:10.223372  4700 net.cpp:406] bn3_1 <- conv3_1
I1210 14:03:10.223372  4700 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1210 14:03:10.223372  4700 net.cpp:122] Setting up bn3_1
I1210 14:03:10.223372  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.223372  4700 net.cpp:137] Memory required for data: 385230000
I1210 14:03:10.223372  4700 layer_factory.cpp:58] Creating layer scale3_1
I1210 14:03:10.223372  4700 net.cpp:84] Creating Layer scale3_1
I1210 14:03:10.223372  4700 net.cpp:406] scale3_1 <- conv3_1
I1210 14:03:10.223372  4700 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1210 14:03:10.223372  4700 layer_factory.cpp:58] Creating layer scale3_1
I1210 14:03:10.223372  4700 net.cpp:122] Setting up scale3_1
I1210 14:03:10.223372  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.223372  4700 net.cpp:137] Memory required for data: 390350000
I1210 14:03:10.223372  4700 layer_factory.cpp:58] Creating layer relu3_1
I1210 14:03:10.223372  4700 net.cpp:84] Creating Layer relu3_1
I1210 14:03:10.223372  4700 net.cpp:406] relu3_1 <- conv3_1
I1210 14:03:10.223372  4700 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1210 14:03:10.224371  4700 net.cpp:122] Setting up relu3_1
I1210 14:03:10.224371  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.224371  4700 net.cpp:137] Memory required for data: 395470000
I1210 14:03:10.224371  4700 layer_factory.cpp:58] Creating layer conv4
I1210 14:03:10.224371  4700 net.cpp:84] Creating Layer conv4
I1210 14:03:10.224371  4700 net.cpp:406] conv4 <- conv3_1
I1210 14:03:10.224371  4700 net.cpp:380] conv4 -> conv4
I1210 14:03:10.225373  4700 net.cpp:122] Setting up conv4
I1210 14:03:10.225373  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.225373  4700 net.cpp:137] Memory required for data: 400590000
I1210 14:03:10.225373  4700 layer_factory.cpp:58] Creating layer bn4
I1210 14:03:10.225373  4700 net.cpp:84] Creating Layer bn4
I1210 14:03:10.225373  4700 net.cpp:406] bn4 <- conv4
I1210 14:03:10.225373  4700 net.cpp:367] bn4 -> conv4 (in-place)
I1210 14:03:10.226373  4700 net.cpp:122] Setting up bn4
I1210 14:03:10.226373  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.226373  4700 net.cpp:137] Memory required for data: 405710000
I1210 14:03:10.226373  4700 layer_factory.cpp:58] Creating layer scale4
I1210 14:03:10.226373  4700 net.cpp:84] Creating Layer scale4
I1210 14:03:10.226373  4700 net.cpp:406] scale4 <- conv4
I1210 14:03:10.226373  4700 net.cpp:367] scale4 -> conv4 (in-place)
I1210 14:03:10.226373  4700 layer_factory.cpp:58] Creating layer scale4
I1210 14:03:10.226373  4700 net.cpp:122] Setting up scale4
I1210 14:03:10.226373  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.226373  4700 net.cpp:137] Memory required for data: 410830000
I1210 14:03:10.226373  4700 layer_factory.cpp:58] Creating layer relu4
I1210 14:03:10.226373  4700 net.cpp:84] Creating Layer relu4
I1210 14:03:10.226373  4700 net.cpp:406] relu4 <- conv4
I1210 14:03:10.226373  4700 net.cpp:367] relu4 -> conv4 (in-place)
I1210 14:03:10.226373  4700 net.cpp:122] Setting up relu4
I1210 14:03:10.226373  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.226373  4700 net.cpp:137] Memory required for data: 415950000
I1210 14:03:10.226373  4700 layer_factory.cpp:58] Creating layer conv4_1
I1210 14:03:10.226373  4700 net.cpp:84] Creating Layer conv4_1
I1210 14:03:10.226373  4700 net.cpp:406] conv4_1 <- conv4
I1210 14:03:10.226373  4700 net.cpp:380] conv4_1 -> conv4_1
I1210 14:03:10.227372  4700 net.cpp:122] Setting up conv4_1
I1210 14:03:10.227372  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.227372  4700 net.cpp:137] Memory required for data: 421070000
I1210 14:03:10.227372  4700 layer_factory.cpp:58] Creating layer bn4_1
I1210 14:03:10.227372  4700 net.cpp:84] Creating Layer bn4_1
I1210 14:03:10.227372  4700 net.cpp:406] bn4_1 <- conv4_1
I1210 14:03:10.227372  4700 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1210 14:03:10.228373  4700 net.cpp:122] Setting up bn4_1
I1210 14:03:10.228373  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.228373  4700 net.cpp:137] Memory required for data: 426190000
I1210 14:03:10.228373  4700 layer_factory.cpp:58] Creating layer scale4_1
I1210 14:03:10.228373  4700 net.cpp:84] Creating Layer scale4_1
I1210 14:03:10.228373  4700 net.cpp:406] scale4_1 <- conv4_1
I1210 14:03:10.228373  4700 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1210 14:03:10.228373  4700 layer_factory.cpp:58] Creating layer scale4_1
I1210 14:03:10.228373  4700 net.cpp:122] Setting up scale4_1
I1210 14:03:10.228373  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.228373  4700 net.cpp:137] Memory required for data: 431310000
I1210 14:03:10.228373  4700 layer_factory.cpp:58] Creating layer relu4_1
I1210 14:03:10.228373  4700 net.cpp:84] Creating Layer relu4_1
I1210 14:03:10.228373  4700 net.cpp:406] relu4_1 <- conv4_1
I1210 14:03:10.228373  4700 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1210 14:03:10.228373  4700 net.cpp:122] Setting up relu4_1
I1210 14:03:10.228373  4700 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1210 14:03:10.228373  4700 net.cpp:137] Memory required for data: 436430000
I1210 14:03:10.229373  4700 layer_factory.cpp:58] Creating layer conv4_2
I1210 14:03:10.229373  4700 net.cpp:84] Creating Layer conv4_2
I1210 14:03:10.229373  4700 net.cpp:406] conv4_2 <- conv4_1
I1210 14:03:10.229373  4700 net.cpp:380] conv4_2 -> conv4_2
I1210 14:03:10.230372  4700 net.cpp:122] Setting up conv4_2
I1210 14:03:10.230372  4700 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 14:03:10.230372  4700 net.cpp:137] Memory required for data: 442369200
I1210 14:03:10.230372  4700 layer_factory.cpp:58] Creating layer bn4_2
I1210 14:03:10.230372  4700 net.cpp:84] Creating Layer bn4_2
I1210 14:03:10.230372  4700 net.cpp:406] bn4_2 <- conv4_2
I1210 14:03:10.230372  4700 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1210 14:03:10.230372  4700 net.cpp:122] Setting up bn4_2
I1210 14:03:10.230372  4700 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 14:03:10.230372  4700 net.cpp:137] Memory required for data: 448308400
I1210 14:03:10.230372  4700 layer_factory.cpp:58] Creating layer scale4_2
I1210 14:03:10.231374  4700 net.cpp:84] Creating Layer scale4_2
I1210 14:03:10.231374  4700 net.cpp:406] scale4_2 <- conv4_2
I1210 14:03:10.231374  4700 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1210 14:03:10.231374  4700 layer_factory.cpp:58] Creating layer scale4_2
I1210 14:03:10.231374  4700 net.cpp:122] Setting up scale4_2
I1210 14:03:10.231374  4700 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 14:03:10.231374  4700 net.cpp:137] Memory required for data: 454247600
I1210 14:03:10.231374  4700 layer_factory.cpp:58] Creating layer relu4_2
I1210 14:03:10.231374  4700 net.cpp:84] Creating Layer relu4_2
I1210 14:03:10.231374  4700 net.cpp:406] relu4_2 <- conv4_2
I1210 14:03:10.231374  4700 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1210 14:03:10.231374  4700 net.cpp:122] Setting up relu4_2
I1210 14:03:10.231374  4700 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 14:03:10.231374  4700 net.cpp:137] Memory required for data: 460186800
I1210 14:03:10.231374  4700 layer_factory.cpp:58] Creating layer added_new_conv2
I1210 14:03:10.231374  4700 net.cpp:84] Creating Layer added_new_conv2
I1210 14:03:10.231374  4700 net.cpp:406] added_new_conv2 <- conv4_2
I1210 14:03:10.231374  4700 net.cpp:380] added_new_conv2 -> added_new_conv2
I1210 14:03:10.232373  4700 net.cpp:122] Setting up added_new_conv2
I1210 14:03:10.232373  4700 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1210 14:03:10.232373  4700 net.cpp:137] Memory required for data: 466126000
I1210 14:03:10.232373  4700 layer_factory.cpp:58] Creating layer pool4_2
I1210 14:03:10.232373  4700 net.cpp:84] Creating Layer pool4_2
I1210 14:03:10.232373  4700 net.cpp:406] pool4_2 <- added_new_conv2
I1210 14:03:10.232373  4700 net.cpp:380] pool4_2 -> pool4_2
I1210 14:03:10.232373  4700 net.cpp:122] Setting up pool4_2
I1210 14:03:10.232373  4700 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 14:03:10.232373  4700 net.cpp:137] Memory required for data: 467610800
I1210 14:03:10.232373  4700 layer_factory.cpp:58] Creating layer conv4_0
I1210 14:03:10.232373  4700 net.cpp:84] Creating Layer conv4_0
I1210 14:03:10.232373  4700 net.cpp:406] conv4_0 <- pool4_2
I1210 14:03:10.232373  4700 net.cpp:380] conv4_0 -> conv4_0
I1210 14:03:10.234374  4700 net.cpp:122] Setting up conv4_0
I1210 14:03:10.234374  4700 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 14:03:10.234374  4700 net.cpp:137] Memory required for data: 469095600
I1210 14:03:10.234374  4700 layer_factory.cpp:58] Creating layer bn4_0
I1210 14:03:10.234374  4700 net.cpp:84] Creating Layer bn4_0
I1210 14:03:10.234374  4700 net.cpp:406] bn4_0 <- conv4_0
I1210 14:03:10.234374  4700 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1210 14:03:10.235373  4700 net.cpp:122] Setting up bn4_0
I1210 14:03:10.235373  4700 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 14:03:10.235373  4700 net.cpp:137] Memory required for data: 470580400
I1210 14:03:10.235373  4700 layer_factory.cpp:58] Creating layer scale4_0
I1210 14:03:10.235373  4700 net.cpp:84] Creating Layer scale4_0
I1210 14:03:10.235373  4700 net.cpp:406] scale4_0 <- conv4_0
I1210 14:03:10.235373  4700 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1210 14:03:10.235373  4700 layer_factory.cpp:58] Creating layer scale4_0
I1210 14:03:10.235373  4700 net.cpp:122] Setting up scale4_0
I1210 14:03:10.235373  4700 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 14:03:10.235373  4700 net.cpp:137] Memory required for data: 472065200
I1210 14:03:10.235373  4700 layer_factory.cpp:58] Creating layer relu4_0
I1210 14:03:10.235373  4700 net.cpp:84] Creating Layer relu4_0
I1210 14:03:10.235373  4700 net.cpp:406] relu4_0 <- conv4_0
I1210 14:03:10.235373  4700 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1210 14:03:10.235373  4700 net.cpp:122] Setting up relu4_0
I1210 14:03:10.235373  4700 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1210 14:03:10.235373  4700 net.cpp:137] Memory required for data: 473550000
I1210 14:03:10.235373  4700 layer_factory.cpp:58] Creating layer conv11
I1210 14:03:10.235373  4700 net.cpp:84] Creating Layer conv11
I1210 14:03:10.235373  4700 net.cpp:406] conv11 <- conv4_0
I1210 14:03:10.235373  4700 net.cpp:380] conv11 -> conv11
I1210 14:03:10.236372  4700 net.cpp:122] Setting up conv11
I1210 14:03:10.237373  4700 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 14:03:10.237373  4700 net.cpp:137] Memory required for data: 475342000
I1210 14:03:10.237373  4700 layer_factory.cpp:58] Creating layer bn_conv11
I1210 14:03:10.237373  4700 net.cpp:84] Creating Layer bn_conv11
I1210 14:03:10.237373  4700 net.cpp:406] bn_conv11 <- conv11
I1210 14:03:10.237373  4700 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1210 14:03:10.237373  4700 net.cpp:122] Setting up bn_conv11
I1210 14:03:10.237373  4700 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 14:03:10.237373  4700 net.cpp:137] Memory required for data: 477134000
I1210 14:03:10.237373  4700 layer_factory.cpp:58] Creating layer scale_conv11
I1210 14:03:10.237373  4700 net.cpp:84] Creating Layer scale_conv11
I1210 14:03:10.237373  4700 net.cpp:406] scale_conv11 <- conv11
I1210 14:03:10.237373  4700 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1210 14:03:10.237373  4700 layer_factory.cpp:58] Creating layer scale_conv11
I1210 14:03:10.237373  4700 net.cpp:122] Setting up scale_conv11
I1210 14:03:10.237373  4700 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 14:03:10.237373  4700 net.cpp:137] Memory required for data: 478926000
I1210 14:03:10.237373  4700 layer_factory.cpp:58] Creating layer relu_conv11
I1210 14:03:10.237373  4700 net.cpp:84] Creating Layer relu_conv11
I1210 14:03:10.237373  4700 net.cpp:406] relu_conv11 <- conv11
I1210 14:03:10.237373  4700 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1210 14:03:10.237373  4700 net.cpp:122] Setting up relu_conv11
I1210 14:03:10.237373  4700 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1210 14:03:10.237373  4700 net.cpp:137] Memory required for data: 480718000
I1210 14:03:10.237373  4700 layer_factory.cpp:58] Creating layer conv12
I1210 14:03:10.237373  4700 net.cpp:84] Creating Layer conv12
I1210 14:03:10.237373  4700 net.cpp:406] conv12 <- conv11
I1210 14:03:10.237373  4700 net.cpp:380] conv12 -> conv12
I1210 14:03:10.239372  4700 net.cpp:122] Setting up conv12
I1210 14:03:10.239372  4700 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 14:03:10.239372  4700 net.cpp:137] Memory required for data: 483022000
I1210 14:03:10.239372  4700 layer_factory.cpp:58] Creating layer bn_conv12
I1210 14:03:10.239372  4700 net.cpp:84] Creating Layer bn_conv12
I1210 14:03:10.239372  4700 net.cpp:406] bn_conv12 <- conv12
I1210 14:03:10.239372  4700 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1210 14:03:10.239372  4700 net.cpp:122] Setting up bn_conv12
I1210 14:03:10.239372  4700 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 14:03:10.239372  4700 net.cpp:137] Memory required for data: 485326000
I1210 14:03:10.239372  4700 layer_factory.cpp:58] Creating layer scale_conv12
I1210 14:03:10.239372  4700 net.cpp:84] Creating Layer scale_conv12
I1210 14:03:10.239372  4700 net.cpp:406] scale_conv12 <- conv12
I1210 14:03:10.239372  4700 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1210 14:03:10.239372  4700 layer_factory.cpp:58] Creating layer scale_conv12
I1210 14:03:10.239372  4700 net.cpp:122] Setting up scale_conv12
I1210 14:03:10.239372  4700 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 14:03:10.239372  4700 net.cpp:137] Memory required for data: 487630000
I1210 14:03:10.239372  4700 layer_factory.cpp:58] Creating layer relu_conv12
I1210 14:03:10.239372  4700 net.cpp:84] Creating Layer relu_conv12
I1210 14:03:10.239372  4700 net.cpp:406] relu_conv12 <- conv12
I1210 14:03:10.239372  4700 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1210 14:03:10.240372  4700 net.cpp:122] Setting up relu_conv12
I1210 14:03:10.240372  4700 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1210 14:03:10.240372  4700 net.cpp:137] Memory required for data: 489934000
I1210 14:03:10.240372  4700 layer_factory.cpp:58] Creating layer poolcp6
I1210 14:03:10.240372  4700 net.cpp:84] Creating Layer poolcp6
I1210 14:03:10.240372  4700 net.cpp:406] poolcp6 <- conv12
I1210 14:03:10.240372  4700 net.cpp:380] poolcp6 -> poolcp6
I1210 14:03:10.240372  4700 net.cpp:122] Setting up poolcp6
I1210 14:03:10.240372  4700 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1210 14:03:10.240372  4700 net.cpp:137] Memory required for data: 489970000
I1210 14:03:10.240372  4700 layer_factory.cpp:58] Creating layer ip1
I1210 14:03:10.240372  4700 net.cpp:84] Creating Layer ip1
I1210 14:03:10.240372  4700 net.cpp:406] ip1 <- poolcp6
I1210 14:03:10.240372  4700 net.cpp:380] ip1 -> ip1
I1210 14:03:10.240372  4700 net.cpp:122] Setting up ip1
I1210 14:03:10.240372  4700 net.cpp:129] Top shape: 100 100 (10000)
I1210 14:03:10.240372  4700 net.cpp:137] Memory required for data: 490010000
I1210 14:03:10.240372  4700 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1210 14:03:10.240372  4700 net.cpp:84] Creating Layer ip1_ip1_0_split
I1210 14:03:10.240372  4700 net.cpp:406] ip1_ip1_0_split <- ip1
I1210 14:03:10.240372  4700 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1210 14:03:10.240372  4700 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1210 14:03:10.240372  4700 net.cpp:122] Setting up ip1_ip1_0_split
I1210 14:03:10.240372  4700 net.cpp:129] Top shape: 100 100 (10000)
I1210 14:03:10.240372  4700 net.cpp:129] Top shape: 100 100 (10000)
I1210 14:03:10.240372  4700 net.cpp:137] Memory required for data: 490090000
I1210 14:03:10.240372  4700 layer_factory.cpp:58] Creating layer accuracy
I1210 14:03:10.240372  4700 net.cpp:84] Creating Layer accuracy
I1210 14:03:10.240372  4700 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1210 14:03:10.240372  4700 net.cpp:406] accuracy <- label_cifar_1_split_0
I1210 14:03:10.240372  4700 net.cpp:380] accuracy -> accuracy
I1210 14:03:10.240372  4700 net.cpp:122] Setting up accuracy
I1210 14:03:10.240372  4700 net.cpp:129] Top shape: (1)
I1210 14:03:10.240372  4700 net.cpp:137] Memory required for data: 490090004
I1210 14:03:10.240372  4700 layer_factory.cpp:58] Creating layer loss
I1210 14:03:10.240372  4700 net.cpp:84] Creating Layer loss
I1210 14:03:10.240372  4700 net.cpp:406] loss <- ip1_ip1_0_split_1
I1210 14:03:10.240372  4700 net.cpp:406] loss <- label_cifar_1_split_1
I1210 14:03:10.240372  4700 net.cpp:380] loss -> loss
I1210 14:03:10.240372  4700 layer_factory.cpp:58] Creating layer loss
I1210 14:03:10.241372  4700 net.cpp:122] Setting up loss
I1210 14:03:10.241372  4700 net.cpp:129] Top shape: (1)
I1210 14:03:10.241372  4700 net.cpp:132]     with loss weight 1
I1210 14:03:10.241372  4700 net.cpp:137] Memory required for data: 490090008
I1210 14:03:10.241372  4700 net.cpp:198] loss needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:200] accuracy does not need backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] ip1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] poolcp6 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu_conv12 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale_conv12 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn_conv12 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv12 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu_conv11 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale_conv11 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn_conv11 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv11 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu4_0 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale4_0 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn4_0 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv4_0 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] pool4_2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] added_new_conv2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu4_2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale4_2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn4_2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv4_2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu4_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale4_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn4_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv4_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu4 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale4 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn4 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv4 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu3_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale3_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn3_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv3_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu3 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale3 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn3 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv3 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] pool2_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] newconv_added1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu2_2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale2_2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn2_2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv2_2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu2_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale2_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn2_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv2_1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv2 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu1_0 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale1_0 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn1_0 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv1_0 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] relu1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] scale1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] bn1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:198] conv1 needs backward computation.
I1210 14:03:10.241372  4700 net.cpp:200] label_cifar_1_split does not need backward computation.
I1210 14:03:10.241372  4700 net.cpp:200] cifar does not need backward computation.
I1210 14:03:10.241372  4700 net.cpp:242] This network produces output accuracy
I1210 14:03:10.241372  4700 net.cpp:242] This network produces output loss
I1210 14:03:10.241372  4700 net.cpp:255] Network initialization done.
I1210 14:03:10.241372  4700 solver.cpp:56] Solver scaffolding done.
I1210 14:03:10.246376  4700 caffe.cpp:243] Resuming from examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90000.solverstate
I1210 14:03:10.250373  4700 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90000.caffemodel
I1210 14:03:10.250373  4700 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 14:03:10.250373  4700 sgd_solver.cpp:318] SGDSolver: restoring history
I1210 14:03:10.254386  4700 caffe.cpp:249] Starting Optimization
I1210 14:03:10.254386  4700 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_v2_360k
I1210 14:03:10.254386  4700 solver.cpp:273] Learning Rate Policy: multistep
I1210 14:03:10.256892  4700 solver.cpp:330] Iteration 90000, Testing net (#0)
I1210 14:03:10.258893  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:03:11.684623  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:03:11.737637  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5871
I1210 14:03:11.737637  4700 solver.cpp:397]     Test net output #1: loss = 1.66452 (* 1 = 1.66452 loss)
I1210 14:03:11.841653  4700 solver.cpp:218] Iteration 90000 (56749.2 iter/s, 1.58592s/100 iters), loss = 0.686856
I1210 14:03:11.841653  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 14:03:11.841653  4700 solver.cpp:237]     Train net output #1: loss = 0.686856 (* 1 = 0.686856 loss)
I1210 14:03:11.841653  4700 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1210 14:03:17.503244  4700 solver.cpp:218] Iteration 90100 (17.6634 iter/s, 5.66143s/100 iters), loss = 0.658448
I1210 14:03:17.503244  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 14:03:17.503244  4700 solver.cpp:237]     Train net output #1: loss = 0.658448 (* 1 = 0.658448 loss)
I1210 14:03:17.503244  4700 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1210 14:03:23.138195  4700 solver.cpp:218] Iteration 90200 (17.7465 iter/s, 5.6349s/100 iters), loss = 0.612428
I1210 14:03:23.138195  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 14:03:23.138195  4700 solver.cpp:237]     Train net output #1: loss = 0.612428 (* 1 = 0.612428 loss)
I1210 14:03:23.138195  4700 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1210 14:03:28.768723  4700 solver.cpp:218] Iteration 90300 (17.7623 iter/s, 5.62991s/100 iters), loss = 0.805623
I1210 14:03:28.769224  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 14:03:28.769224  4700 solver.cpp:237]     Train net output #1: loss = 0.805623 (* 1 = 0.805623 loss)
I1210 14:03:28.769224  4700 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1210 14:03:34.413710  4700 solver.cpp:218] Iteration 90400 (17.7162 iter/s, 5.64454s/100 iters), loss = 0.817319
I1210 14:03:34.413710  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 14:03:34.413710  4700 solver.cpp:237]     Train net output #1: loss = 0.817319 (* 1 = 0.817319 loss)
I1210 14:03:34.413710  4700 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1210 14:03:39.780094 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:03:40.001121  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90500.caffemodel
I1210 14:03:40.018121  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_90500.solverstate
I1210 14:03:40.026129  4700 solver.cpp:330] Iteration 90500, Testing net (#0)
I1210 14:03:40.026129  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:03:41.389264  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:03:41.442770  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5548
I1210 14:03:41.442770  4700 solver.cpp:397]     Test net output #1: loss = 1.78273 (* 1 = 1.78273 loss)
I1210 14:03:41.498268  4700 solver.cpp:218] Iteration 90500 (14.1171 iter/s, 7.08361s/100 iters), loss = 0.616382
I1210 14:03:41.498268  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 14:03:41.498268  4700 solver.cpp:237]     Train net output #1: loss = 0.616382 (* 1 = 0.616382 loss)
I1210 14:03:41.498268  4700 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1210 14:03:47.124605  4700 solver.cpp:218] Iteration 90600 (17.7732 iter/s, 5.62644s/100 iters), loss = 0.626211
I1210 14:03:47.124605  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 14:03:47.124605  4700 solver.cpp:237]     Train net output #1: loss = 0.626211 (* 1 = 0.626211 loss)
I1210 14:03:47.124605  4700 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1210 14:03:52.787770  4700 solver.cpp:218] Iteration 90700 (17.6604 iter/s, 5.6624s/100 iters), loss = 0.522833
I1210 14:03:52.787770  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:03:52.787770  4700 solver.cpp:237]     Train net output #1: loss = 0.522833 (* 1 = 0.522833 loss)
I1210 14:03:52.787770  4700 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1210 14:03:58.479235  4700 solver.cpp:218] Iteration 90800 (17.5715 iter/s, 5.69102s/100 iters), loss = 0.796103
I1210 14:03:58.479235  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 14:03:58.479235  4700 solver.cpp:237]     Train net output #1: loss = 0.796103 (* 1 = 0.796103 loss)
I1210 14:03:58.479235  4700 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1210 14:04:04.172247  4700 solver.cpp:218] Iteration 90900 (17.5663 iter/s, 5.69273s/100 iters), loss = 0.92618
I1210 14:04:04.172747  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 14:04:04.172747  4700 solver.cpp:237]     Train net output #1: loss = 0.92618 (* 1 = 0.92618 loss)
I1210 14:04:04.172747  4700 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1210 14:04:09.698246 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:04:09.922276  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91000.caffemodel
I1210 14:04:09.937275  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91000.solverstate
I1210 14:04:09.942276  4700 solver.cpp:330] Iteration 91000, Testing net (#0)
I1210 14:04:09.942276  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:04:11.316401  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:04:11.369400  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5904
I1210 14:04:11.369400  4700 solver.cpp:397]     Test net output #1: loss = 1.60031 (* 1 = 1.60031 loss)
I1210 14:04:11.424410  4700 solver.cpp:218] Iteration 91000 (13.7894 iter/s, 7.25193s/100 iters), loss = 0.493231
I1210 14:04:11.424410  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:04:11.424410  4700 solver.cpp:237]     Train net output #1: loss = 0.493231 (* 1 = 0.493231 loss)
I1210 14:04:11.424410  4700 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1210 14:04:17.070811  4700 solver.cpp:218] Iteration 91100 (17.7114 iter/s, 5.6461s/100 iters), loss = 0.680159
I1210 14:04:17.070811  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 14:04:17.070811  4700 solver.cpp:237]     Train net output #1: loss = 0.680159 (* 1 = 0.680159 loss)
I1210 14:04:17.070811  4700 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1210 14:04:22.772243  4700 solver.cpp:218] Iteration 91200 (17.5436 iter/s, 5.70009s/100 iters), loss = 0.516844
I1210 14:04:22.772243  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:04:22.772243  4700 solver.cpp:237]     Train net output #1: loss = 0.516844 (* 1 = 0.516844 loss)
I1210 14:04:22.772243  4700 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1210 14:04:28.501705  4700 solver.cpp:218] Iteration 91300 (17.4552 iter/s, 5.72895s/100 iters), loss = 0.690256
I1210 14:04:28.501705  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 14:04:28.501705  4700 solver.cpp:237]     Train net output #1: loss = 0.690256 (* 1 = 0.690256 loss)
I1210 14:04:28.501705  4700 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1210 14:04:34.289583  4700 solver.cpp:218] Iteration 91400 (17.2771 iter/s, 5.78801s/100 iters), loss = 0.838834
I1210 14:04:34.289583  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 14:04:34.289583  4700 solver.cpp:237]     Train net output #1: loss = 0.838834 (* 1 = 0.838834 loss)
I1210 14:04:34.289583  4700 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1210 14:04:39.743326 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:04:39.968343  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91500.caffemodel
I1210 14:04:39.983343  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_91500.solverstate
I1210 14:04:39.988343  4700 solver.cpp:330] Iteration 91500, Testing net (#0)
I1210 14:04:39.988343  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:04:41.357456  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:04:41.411459  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5902
I1210 14:04:41.411459  4700 solver.cpp:397]     Test net output #1: loss = 1.58257 (* 1 = 1.58257 loss)
I1210 14:04:41.466464  4700 solver.cpp:218] Iteration 91500 (13.9357 iter/s, 7.17581s/100 iters), loss = 0.703956
I1210 14:04:41.466464  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 14:04:41.466464  4700 solver.cpp:237]     Train net output #1: loss = 0.703956 (* 1 = 0.703956 loss)
I1210 14:04:41.466464  4700 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1210 14:04:47.114996  4700 solver.cpp:218] Iteration 91600 (17.704 iter/s, 5.64843s/100 iters), loss = 0.735954
I1210 14:04:47.114996  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 14:04:47.114996  4700 solver.cpp:237]     Train net output #1: loss = 0.735954 (* 1 = 0.735954 loss)
I1210 14:04:47.114996  4700 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1210 14:04:52.739413  4700 solver.cpp:218] Iteration 91700 (17.7816 iter/s, 5.6238s/100 iters), loss = 0.548383
I1210 14:04:52.739413  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:04:52.739413  4700 solver.cpp:237]     Train net output #1: loss = 0.548383 (* 1 = 0.548383 loss)
I1210 14:04:52.739413  4700 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1210 14:04:58.357903  4700 solver.cpp:218] Iteration 91800 (17.8001 iter/s, 5.61795s/100 iters), loss = 0.747017
I1210 14:04:58.357903  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 14:04:58.357903  4700 solver.cpp:237]     Train net output #1: loss = 0.747017 (* 1 = 0.747017 loss)
I1210 14:04:58.357903  4700 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1210 14:05:03.982281  4700 solver.cpp:218] Iteration 91900 (17.7809 iter/s, 5.62403s/100 iters), loss = 0.772177
I1210 14:05:03.982281  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 14:05:03.982281  4700 solver.cpp:237]     Train net output #1: loss = 0.772177 (* 1 = 0.772177 loss)
I1210 14:05:03.982281  4700 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1210 14:05:09.333717 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:05:09.557751  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92000.caffemodel
I1210 14:05:09.573750  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92000.solverstate
I1210 14:05:09.578752  4700 solver.cpp:330] Iteration 92000, Testing net (#0)
I1210 14:05:09.578752  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:05:10.945854  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:05:11.001859  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5833
I1210 14:05:11.001859  4700 solver.cpp:397]     Test net output #1: loss = 1.5912 (* 1 = 1.5912 loss)
I1210 14:05:11.055861  4700 solver.cpp:218] Iteration 92000 (14.1371 iter/s, 7.07356s/100 iters), loss = 0.611394
I1210 14:05:11.056862  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:05:11.056862  4700 solver.cpp:237]     Train net output #1: loss = 0.611394 (* 1 = 0.611394 loss)
I1210 14:05:11.056862  4700 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1210 14:05:16.713326  4700 solver.cpp:218] Iteration 92100 (17.6793 iter/s, 5.65632s/100 iters), loss = 0.80694
I1210 14:05:16.713326  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 14:05:16.713326  4700 solver.cpp:237]     Train net output #1: loss = 0.80694 (* 1 = 0.80694 loss)
I1210 14:05:16.713326  4700 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1210 14:05:22.362761  4700 solver.cpp:218] Iteration 92200 (17.7021 iter/s, 5.64903s/100 iters), loss = 0.60981
I1210 14:05:22.362761  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 14:05:22.362761  4700 solver.cpp:237]     Train net output #1: loss = 0.60981 (* 1 = 0.60981 loss)
I1210 14:05:22.362761  4700 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1210 14:05:28.004134  4700 solver.cpp:218] Iteration 92300 (17.7273 iter/s, 5.64103s/100 iters), loss = 0.838023
I1210 14:05:28.004134  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 14:05:28.004134  4700 solver.cpp:237]     Train net output #1: loss = 0.838023 (* 1 = 0.838023 loss)
I1210 14:05:28.004134  4700 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1210 14:05:33.656620  4700 solver.cpp:218] Iteration 92400 (17.692 iter/s, 5.65226s/100 iters), loss = 0.73271
I1210 14:05:33.656620  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 14:05:33.656620  4700 solver.cpp:237]     Train net output #1: loss = 0.73271 (* 1 = 0.73271 loss)
I1210 14:05:33.656620  4700 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1210 14:05:39.019992 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:05:39.240998  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92500.caffemodel
I1210 14:05:39.255996  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_92500.solverstate
I1210 14:05:39.260998  4700 solver.cpp:330] Iteration 92500, Testing net (#0)
I1210 14:05:39.260998  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:05:40.627138  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:05:40.681136  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5886
I1210 14:05:40.681136  4700 solver.cpp:397]     Test net output #1: loss = 1.58839 (* 1 = 1.58839 loss)
I1210 14:05:40.735141  4700 solver.cpp:218] Iteration 92500 (14.1286 iter/s, 7.07786s/100 iters), loss = 0.678725
I1210 14:05:40.735141  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:05:40.735141  4700 solver.cpp:237]     Train net output #1: loss = 0.678725 (* 1 = 0.678725 loss)
I1210 14:05:40.735141  4700 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1210 14:05:46.385567  4700 solver.cpp:218] Iteration 92600 (17.6988 iter/s, 5.65011s/100 iters), loss = 0.863016
I1210 14:05:46.385567  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 14:05:46.385567  4700 solver.cpp:237]     Train net output #1: loss = 0.863016 (* 1 = 0.863016 loss)
I1210 14:05:46.385567  4700 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1210 14:05:52.048027  4700 solver.cpp:218] Iteration 92700 (17.6609 iter/s, 5.66222s/100 iters), loss = 0.631929
I1210 14:05:52.048027  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 14:05:52.048027  4700 solver.cpp:237]     Train net output #1: loss = 0.631929 (* 1 = 0.631929 loss)
I1210 14:05:52.048027  4700 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1210 14:05:57.702438  4700 solver.cpp:218] Iteration 92800 (17.6888 iter/s, 5.6533s/100 iters), loss = 0.848595
I1210 14:05:57.702438  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 14:05:57.702438  4700 solver.cpp:237]     Train net output #1: loss = 0.848595 (* 1 = 0.848595 loss)
I1210 14:05:57.702438  4700 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1210 14:06:03.358842  4700 solver.cpp:218] Iteration 92900 (17.6793 iter/s, 5.65632s/100 iters), loss = 0.745005
I1210 14:06:03.358842  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 14:06:03.358842  4700 solver.cpp:237]     Train net output #1: loss = 0.745005 (* 1 = 0.745005 loss)
I1210 14:06:03.358842  4700 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1210 14:06:08.731272 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:06:08.953285  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93000.caffemodel
I1210 14:06:08.967286  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93000.solverstate
I1210 14:06:08.972285  4700 solver.cpp:330] Iteration 93000, Testing net (#0)
I1210 14:06:08.972285  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:06:10.341405  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:06:10.394412  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5741
I1210 14:06:10.394412  4700 solver.cpp:397]     Test net output #1: loss = 1.73465 (* 1 = 1.73465 loss)
I1210 14:06:10.448410  4700 solver.cpp:218] Iteration 93000 (14.1051 iter/s, 7.08962s/100 iters), loss = 0.694914
I1210 14:06:10.448410  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 14:06:10.448410  4700 solver.cpp:237]     Train net output #1: loss = 0.694914 (* 1 = 0.694914 loss)
I1210 14:06:10.448410  4700 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1210 14:06:16.091836  4700 solver.cpp:218] Iteration 93100 (17.7214 iter/s, 5.64289s/100 iters), loss = 0.769033
I1210 14:06:16.091836  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 14:06:16.091836  4700 solver.cpp:237]     Train net output #1: loss = 0.769033 (* 1 = 0.769033 loss)
I1210 14:06:16.091836  4700 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1210 14:06:21.742272  4700 solver.cpp:218] Iteration 93200 (17.6992 iter/s, 5.64996s/100 iters), loss = 0.525267
I1210 14:06:21.742272  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:06:21.742272  4700 solver.cpp:237]     Train net output #1: loss = 0.525267 (* 1 = 0.525267 loss)
I1210 14:06:21.742272  4700 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1210 14:06:27.391747  4700 solver.cpp:218] Iteration 93300 (17.703 iter/s, 5.64876s/100 iters), loss = 0.814072
I1210 14:06:27.391747  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 14:06:27.391747  4700 solver.cpp:237]     Train net output #1: loss = 0.814072 (* 1 = 0.814072 loss)
I1210 14:06:27.391747  4700 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1210 14:06:33.038188  4700 solver.cpp:218] Iteration 93400 (17.712 iter/s, 5.64589s/100 iters), loss = 0.795317
I1210 14:06:33.038188  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 14:06:33.038188  4700 solver.cpp:237]     Train net output #1: loss = 0.795317 (* 1 = 0.795317 loss)
I1210 14:06:33.038188  4700 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1210 14:06:38.423558 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:06:38.646567  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93500.caffemodel
I1210 14:06:38.661568  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_93500.solverstate
I1210 14:06:38.666568  4700 solver.cpp:330] Iteration 93500, Testing net (#0)
I1210 14:06:38.666568  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:06:40.036761  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:06:40.090759  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5919
I1210 14:06:40.090759  4700 solver.cpp:397]     Test net output #1: loss = 1.54188 (* 1 = 1.54188 loss)
I1210 14:06:40.144745  4700 solver.cpp:218] Iteration 93500 (14.0717 iter/s, 7.10644s/100 iters), loss = 0.599164
I1210 14:06:40.144745  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:06:40.144745  4700 solver.cpp:237]     Train net output #1: loss = 0.599164 (* 1 = 0.599164 loss)
I1210 14:06:40.144745  4700 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1210 14:06:45.792372  4700 solver.cpp:218] Iteration 93600 (17.7097 iter/s, 5.64663s/100 iters), loss = 0.708216
I1210 14:06:45.792372  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 14:06:45.792372  4700 solver.cpp:237]     Train net output #1: loss = 0.708216 (* 1 = 0.708216 loss)
I1210 14:06:45.792372  4700 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1210 14:06:51.439975  4700 solver.cpp:218] Iteration 93700 (17.7073 iter/s, 5.6474s/100 iters), loss = 0.569028
I1210 14:06:51.439975  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:06:51.439975  4700 solver.cpp:237]     Train net output #1: loss = 0.569028 (* 1 = 0.569028 loss)
I1210 14:06:51.439975  4700 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1210 14:06:57.098990  4700 solver.cpp:218] Iteration 93800 (17.6715 iter/s, 5.65882s/100 iters), loss = 0.846213
I1210 14:06:57.098990  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 14:06:57.098990  4700 solver.cpp:237]     Train net output #1: loss = 0.846213 (* 1 = 0.846213 loss)
I1210 14:06:57.098990  4700 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1210 14:07:02.752840  4700 solver.cpp:218] Iteration 93900 (17.6896 iter/s, 5.65303s/100 iters), loss = 0.897031
I1210 14:07:02.752840  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 14:07:02.752840  4700 solver.cpp:237]     Train net output #1: loss = 0.897031 (* 1 = 0.897031 loss)
I1210 14:07:02.752840  4700 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1210 14:07:08.131183 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:07:08.352212  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94000.caffemodel
I1210 14:07:08.367203  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94000.solverstate
I1210 14:07:08.372213  4700 solver.cpp:330] Iteration 94000, Testing net (#0)
I1210 14:07:08.372213  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:07:09.743024  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:07:09.797024  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5967
I1210 14:07:09.797024  4700 solver.cpp:397]     Test net output #1: loss = 1.54673 (* 1 = 1.54673 loss)
I1210 14:07:09.850536  4700 solver.cpp:218] Iteration 94000 (14.0904 iter/s, 7.09705s/100 iters), loss = 0.593608
I1210 14:07:09.850536  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:07:09.850536  4700 solver.cpp:237]     Train net output #1: loss = 0.593608 (* 1 = 0.593608 loss)
I1210 14:07:09.850536  4700 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1210 14:07:15.506809  4700 solver.cpp:218] Iteration 94100 (17.6808 iter/s, 5.65584s/100 iters), loss = 0.710518
I1210 14:07:15.506809  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 14:07:15.506809  4700 solver.cpp:237]     Train net output #1: loss = 0.710518 (* 1 = 0.710518 loss)
I1210 14:07:15.506809  4700 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1210 14:07:21.154594  4700 solver.cpp:218] Iteration 94200 (17.7058 iter/s, 5.64785s/100 iters), loss = 0.448537
I1210 14:07:21.154594  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:07:21.154594  4700 solver.cpp:237]     Train net output #1: loss = 0.448537 (* 1 = 0.448537 loss)
I1210 14:07:21.154594  4700 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1210 14:07:26.802006  4700 solver.cpp:218] Iteration 94300 (17.7099 iter/s, 5.64657s/100 iters), loss = 0.813995
I1210 14:07:26.802006  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 14:07:26.802006  4700 solver.cpp:237]     Train net output #1: loss = 0.813995 (* 1 = 0.813995 loss)
I1210 14:07:26.802006  4700 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1210 14:07:32.445415  4700 solver.cpp:218] Iteration 94400 (17.7215 iter/s, 5.64285s/100 iters), loss = 0.906427
I1210 14:07:32.445415  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 14:07:32.445415  4700 solver.cpp:237]     Train net output #1: loss = 0.906427 (* 1 = 0.906427 loss)
I1210 14:07:32.445415  4700 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1210 14:07:37.819284 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:07:38.039796  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94500.caffemodel
I1210 14:07:38.056802  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_94500.solverstate
I1210 14:07:38.062795  4700 solver.cpp:330] Iteration 94500, Testing net (#0)
I1210 14:07:38.062795  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:07:39.429394  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:07:39.482897  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5986
I1210 14:07:39.482897  4700 solver.cpp:397]     Test net output #1: loss = 1.54847 (* 1 = 1.54847 loss)
I1210 14:07:39.536900  4700 solver.cpp:218] Iteration 94500 (14.1029 iter/s, 7.09075s/100 iters), loss = 0.694521
I1210 14:07:39.536900  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 14:07:39.536900  4700 solver.cpp:237]     Train net output #1: loss = 0.694521 (* 1 = 0.694521 loss)
I1210 14:07:39.536900  4700 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1210 14:07:45.171401  4700 solver.cpp:218] Iteration 94600 (17.7487 iter/s, 5.63421s/100 iters), loss = 0.661805
I1210 14:07:45.171401  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 14:07:45.171401  4700 solver.cpp:237]     Train net output #1: loss = 0.661805 (* 1 = 0.661805 loss)
I1210 14:07:45.171401  4700 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1210 14:07:50.812914  4700 solver.cpp:218] Iteration 94700 (17.7282 iter/s, 5.64073s/100 iters), loss = 0.5851
I1210 14:07:50.812914  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 14:07:50.812914  4700 solver.cpp:237]     Train net output #1: loss = 0.5851 (* 1 = 0.5851 loss)
I1210 14:07:50.812914  4700 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1210 14:07:56.451349  4700 solver.cpp:218] Iteration 94800 (17.7346 iter/s, 5.63868s/100 iters), loss = 0.773482
I1210 14:07:56.451349  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 14:07:56.451349  4700 solver.cpp:237]     Train net output #1: loss = 0.773482 (* 1 = 0.773482 loss)
I1210 14:07:56.451349  4700 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1210 14:08:02.083811  4700 solver.cpp:218] Iteration 94900 (17.7578 iter/s, 5.63134s/100 iters), loss = 0.809857
I1210 14:08:02.083811  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 14:08:02.083811  4700 solver.cpp:237]     Train net output #1: loss = 0.809857 (* 1 = 0.809857 loss)
I1210 14:08:02.083811  4700 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1210 14:08:07.450281 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:08:07.670291  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95000.caffemodel
I1210 14:08:07.684291  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95000.solverstate
I1210 14:08:07.689291  4700 solver.cpp:330] Iteration 95000, Testing net (#0)
I1210 14:08:07.689291  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:08:09.058549  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:08:09.112548  4700 solver.cpp:397]     Test net output #0: accuracy = 0.5774
I1210 14:08:09.112548  4700 solver.cpp:397]     Test net output #1: loss = 1.67469 (* 1 = 1.67469 loss)
I1210 14:08:09.166558  4700 solver.cpp:218] Iteration 95000 (14.1183 iter/s, 7.08302s/100 iters), loss = 0.629534
I1210 14:08:09.166558  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 14:08:09.166558  4700 solver.cpp:237]     Train net output #1: loss = 0.629534 (* 1 = 0.629534 loss)
I1210 14:08:09.166558  4700 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1210 14:08:09.166558  4700 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1210 14:08:14.822536  4700 solver.cpp:218] Iteration 95100 (17.683 iter/s, 5.65514s/100 iters), loss = 0.631889
I1210 14:08:14.822536  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:08:14.822536  4700 solver.cpp:237]     Train net output #1: loss = 0.631889 (* 1 = 0.631889 loss)
I1210 14:08:14.822536  4700 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1210 14:08:20.469552  4700 solver.cpp:218] Iteration 95200 (17.7083 iter/s, 5.64706s/100 iters), loss = 0.441123
I1210 14:08:20.469552  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:08:20.469552  4700 solver.cpp:237]     Train net output #1: loss = 0.441123 (* 1 = 0.441123 loss)
I1210 14:08:20.469552  4700 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1210 14:08:26.130012  4700 solver.cpp:218] Iteration 95300 (17.6693 iter/s, 5.65953s/100 iters), loss = 0.69342
I1210 14:08:26.130012  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:08:26.130512  4700 solver.cpp:237]     Train net output #1: loss = 0.69342 (* 1 = 0.69342 loss)
I1210 14:08:26.130512  4700 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1210 14:08:31.783452  4700 solver.cpp:218] Iteration 95400 (17.6886 iter/s, 5.65335s/100 iters), loss = 0.506687
I1210 14:08:31.783452  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:08:31.783452  4700 solver.cpp:237]     Train net output #1: loss = 0.506687 (* 1 = 0.506687 loss)
I1210 14:08:31.783452  4700 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1210 14:08:37.158875 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:08:37.379886  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95500.caffemodel
I1210 14:08:37.394886  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_95500.solverstate
I1210 14:08:37.400887  4700 solver.cpp:330] Iteration 95500, Testing net (#0)
I1210 14:08:37.400887  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:08:38.768036  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:08:38.822041  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6763
I1210 14:08:38.822041  4700 solver.cpp:397]     Test net output #1: loss = 1.17417 (* 1 = 1.17417 loss)
I1210 14:08:38.875044  4700 solver.cpp:218] Iteration 95500 (14.1019 iter/s, 7.09125s/100 iters), loss = 0.522954
I1210 14:08:38.876044  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:08:38.876044  4700 solver.cpp:237]     Train net output #1: loss = 0.522954 (* 1 = 0.522954 loss)
I1210 14:08:38.876044  4700 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1210 14:08:44.507484  4700 solver.cpp:218] Iteration 95600 (17.7562 iter/s, 5.63184s/100 iters), loss = 0.548972
I1210 14:08:44.507484  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:08:44.507484  4700 solver.cpp:237]     Train net output #1: loss = 0.548972 (* 1 = 0.548972 loss)
I1210 14:08:44.507484  4700 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1210 14:08:50.143916  4700 solver.cpp:218] Iteration 95700 (17.7433 iter/s, 5.63593s/100 iters), loss = 0.410831
I1210 14:08:50.143916  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:08:50.143916  4700 solver.cpp:237]     Train net output #1: loss = 0.410831 (* 1 = 0.410831 loss)
I1210 14:08:50.143916  4700 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1210 14:08:55.784371  4700 solver.cpp:218] Iteration 95800 (17.7317 iter/s, 5.63963s/100 iters), loss = 0.566944
I1210 14:08:55.784371  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:08:55.784371  4700 solver.cpp:237]     Train net output #1: loss = 0.566944 (* 1 = 0.566944 loss)
I1210 14:08:55.784371  4700 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1210 14:09:01.416807  4700 solver.cpp:218] Iteration 95900 (17.7544 iter/s, 5.63242s/100 iters), loss = 0.566051
I1210 14:09:01.416807  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:09:01.416807  4700 solver.cpp:237]     Train net output #1: loss = 0.566051 (* 1 = 0.566051 loss)
I1210 14:09:01.416807  4700 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1210 14:09:06.768210 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:09:06.990226  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96000.caffemodel
I1210 14:09:07.004226  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96000.solverstate
I1210 14:09:07.010227  4700 solver.cpp:330] Iteration 96000, Testing net (#0)
I1210 14:09:07.010227  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:09:08.379369  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:09:08.432873  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6783
I1210 14:09:08.432873  4700 solver.cpp:397]     Test net output #1: loss = 1.17076 (* 1 = 1.17076 loss)
I1210 14:09:08.486374  4700 solver.cpp:218] Iteration 96000 (14.1459 iter/s, 7.06917s/100 iters), loss = 0.517787
I1210 14:09:08.486374  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:09:08.486374  4700 solver.cpp:237]     Train net output #1: loss = 0.517787 (* 1 = 0.517787 loss)
I1210 14:09:08.486374  4700 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1210 14:09:14.137173  4700 solver.cpp:218] Iteration 96100 (17.6991 iter/s, 5.64999s/100 iters), loss = 0.531294
I1210 14:09:14.137673  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 14:09:14.137673  4700 solver.cpp:237]     Train net output #1: loss = 0.531294 (* 1 = 0.531294 loss)
I1210 14:09:14.137673  4700 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1210 14:09:19.794945  4700 solver.cpp:218] Iteration 96200 (17.6777 iter/s, 5.65683s/100 iters), loss = 0.357058
I1210 14:09:19.794945  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:09:19.794945  4700 solver.cpp:237]     Train net output #1: loss = 0.357058 (* 1 = 0.357058 loss)
I1210 14:09:19.794945  4700 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1210 14:09:25.448601  4700 solver.cpp:218] Iteration 96300 (17.6878 iter/s, 5.65363s/100 iters), loss = 0.51928
I1210 14:09:25.448601  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 14:09:25.448601  4700 solver.cpp:237]     Train net output #1: loss = 0.51928 (* 1 = 0.51928 loss)
I1210 14:09:25.448601  4700 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1210 14:09:31.094873  4700 solver.cpp:218] Iteration 96400 (17.7119 iter/s, 5.64592s/100 iters), loss = 0.511277
I1210 14:09:31.094873  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 14:09:31.094873  4700 solver.cpp:237]     Train net output #1: loss = 0.511277 (* 1 = 0.511277 loss)
I1210 14:09:31.094873  4700 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1210 14:09:36.466177 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:09:36.689270  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96500.caffemodel
I1210 14:09:36.704252  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_96500.solverstate
I1210 14:09:36.709265  4700 solver.cpp:330] Iteration 96500, Testing net (#0)
I1210 14:09:36.709265  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:09:38.081629  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:09:38.135639  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6814
I1210 14:09:38.135639  4700 solver.cpp:397]     Test net output #1: loss = 1.17263 (* 1 = 1.17263 loss)
I1210 14:09:38.188683  4700 solver.cpp:218] Iteration 96500 (14.0971 iter/s, 7.09365s/100 iters), loss = 0.474404
I1210 14:09:38.188683  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:09:38.188683  4700 solver.cpp:237]     Train net output #1: loss = 0.474404 (* 1 = 0.474404 loss)
I1210 14:09:38.188683  4700 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1210 14:09:43.833298  4700 solver.cpp:218] Iteration 96600 (17.7171 iter/s, 5.64428s/100 iters), loss = 0.495984
I1210 14:09:43.834298  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 14:09:43.834298  4700 solver.cpp:237]     Train net output #1: loss = 0.495984 (* 1 = 0.495984 loss)
I1210 14:09:43.834298  4700 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1210 14:09:49.494709  4700 solver.cpp:218] Iteration 96700 (17.6675 iter/s, 5.66011s/100 iters), loss = 0.332323
I1210 14:09:49.494709  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:09:49.494709  4700 solver.cpp:237]     Train net output #1: loss = 0.332323 (* 1 = 0.332323 loss)
I1210 14:09:49.494709  4700 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1210 14:09:55.148313  4700 solver.cpp:218] Iteration 96800 (17.6886 iter/s, 5.65335s/100 iters), loss = 0.483056
I1210 14:09:55.148313  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:09:55.148313  4700 solver.cpp:237]     Train net output #1: loss = 0.483056 (* 1 = 0.483056 loss)
I1210 14:09:55.148313  4700 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1210 14:10:00.808751  4700 solver.cpp:218] Iteration 96900 (17.6678 iter/s, 5.66001s/100 iters), loss = 0.582
I1210 14:10:00.808751  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:10:00.808751  4700 solver.cpp:237]     Train net output #1: loss = 0.582 (* 1 = 0.582 loss)
I1210 14:10:00.808751  4700 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1210 14:10:06.200616 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:10:06.422631  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97000.caffemodel
I1210 14:10:06.436630  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97000.solverstate
I1210 14:10:06.441630  4700 solver.cpp:330] Iteration 97000, Testing net (#0)
I1210 14:10:06.441630  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:10:07.808748  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:10:07.862751  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6808
I1210 14:10:07.862751  4700 solver.cpp:397]     Test net output #1: loss = 1.17342 (* 1 = 1.17342 loss)
I1210 14:10:07.918759  4700 solver.cpp:218] Iteration 97000 (14.066 iter/s, 7.10934s/100 iters), loss = 0.438634
I1210 14:10:07.918759  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:10:07.918759  4700 solver.cpp:237]     Train net output #1: loss = 0.438634 (* 1 = 0.438634 loss)
I1210 14:10:07.918759  4700 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1210 14:10:13.561457  4700 solver.cpp:218] Iteration 97100 (17.7247 iter/s, 5.64185s/100 iters), loss = 0.608592
I1210 14:10:13.561457  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 14:10:13.561457  4700 solver.cpp:237]     Train net output #1: loss = 0.608592 (* 1 = 0.608592 loss)
I1210 14:10:13.561457  4700 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1210 14:10:19.202872  4700 solver.cpp:218] Iteration 97200 (17.726 iter/s, 5.64142s/100 iters), loss = 0.329066
I1210 14:10:19.203372  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:10:19.203372  4700 solver.cpp:237]     Train net output #1: loss = 0.329066 (* 1 = 0.329066 loss)
I1210 14:10:19.203372  4700 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1210 14:10:24.844377  4700 solver.cpp:218] Iteration 97300 (17.7285 iter/s, 5.64062s/100 iters), loss = 0.483942
I1210 14:10:24.844377  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:10:24.844377  4700 solver.cpp:237]     Train net output #1: loss = 0.483942 (* 1 = 0.483942 loss)
I1210 14:10:24.844377  4700 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1210 14:10:30.481819  4700 solver.cpp:218] Iteration 97400 (17.7373 iter/s, 5.63785s/100 iters), loss = 0.518114
I1210 14:10:30.481819  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 14:10:30.481819  4700 solver.cpp:237]     Train net output #1: loss = 0.518114 (* 1 = 0.518114 loss)
I1210 14:10:30.481819  4700 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1210 14:10:35.845226 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:10:36.068239  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97500.caffemodel
I1210 14:10:36.084239  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_97500.solverstate
I1210 14:10:36.089238  4700 solver.cpp:330] Iteration 97500, Testing net (#0)
I1210 14:10:36.089238  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:10:37.456360  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:10:37.510376  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6809
I1210 14:10:37.510376  4700 solver.cpp:397]     Test net output #1: loss = 1.17867 (* 1 = 1.17867 loss)
I1210 14:10:37.564385  4700 solver.cpp:218] Iteration 97500 (14.121 iter/s, 7.08163s/100 iters), loss = 0.561959
I1210 14:10:37.564385  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:10:37.564385  4700 solver.cpp:237]     Train net output #1: loss = 0.561959 (* 1 = 0.561959 loss)
I1210 14:10:37.564385  4700 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1210 14:10:43.214787  4700 solver.cpp:218] Iteration 97600 (17.7004 iter/s, 5.6496s/100 iters), loss = 0.491995
I1210 14:10:43.214787  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 14:10:43.214787  4700 solver.cpp:237]     Train net output #1: loss = 0.491995 (* 1 = 0.491995 loss)
I1210 14:10:43.214787  4700 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1210 14:10:48.859223  4700 solver.cpp:218] Iteration 97700 (17.7153 iter/s, 5.64483s/100 iters), loss = 0.358413
I1210 14:10:48.859223  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:10:48.860224  4700 solver.cpp:237]     Train net output #1: loss = 0.358413 (* 1 = 0.358413 loss)
I1210 14:10:48.860224  4700 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1210 14:10:54.504655  4700 solver.cpp:218] Iteration 97800 (17.7162 iter/s, 5.64454s/100 iters), loss = 0.490111
I1210 14:10:54.505156  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:10:54.505156  4700 solver.cpp:237]     Train net output #1: loss = 0.490111 (* 1 = 0.490111 loss)
I1210 14:10:54.505156  4700 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1210 14:11:00.146050  4700 solver.cpp:218] Iteration 97900 (17.7274 iter/s, 5.64099s/100 iters), loss = 0.515345
I1210 14:11:00.146050  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:11:00.146050  4700 solver.cpp:237]     Train net output #1: loss = 0.515345 (* 1 = 0.515345 loss)
I1210 14:11:00.146050  4700 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1210 14:11:05.509457 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:11:05.732470  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98000.caffemodel
I1210 14:11:05.746469  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98000.solverstate
I1210 14:11:05.751469  4700 solver.cpp:330] Iteration 98000, Testing net (#0)
I1210 14:11:05.751469  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:11:07.120581  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:11:07.175081  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6853
I1210 14:11:07.175081  4700 solver.cpp:397]     Test net output #1: loss = 1.16956 (* 1 = 1.16956 loss)
I1210 14:11:07.230588  4700 solver.cpp:218] Iteration 98000 (14.1166 iter/s, 7.08387s/100 iters), loss = 0.425453
I1210 14:11:07.230588  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:11:07.230588  4700 solver.cpp:237]     Train net output #1: loss = 0.425453 (* 1 = 0.425453 loss)
I1210 14:11:07.230588  4700 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1210 14:11:12.881744  4700 solver.cpp:218] Iteration 98100 (17.697 iter/s, 5.65069s/100 iters), loss = 0.409758
I1210 14:11:12.881744  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:11:12.881744  4700 solver.cpp:237]     Train net output #1: loss = 0.409758 (* 1 = 0.409758 loss)
I1210 14:11:12.881744  4700 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1210 14:11:18.531692  4700 solver.cpp:218] Iteration 98200 (17.6991 iter/s, 5.64999s/100 iters), loss = 0.305097
I1210 14:11:18.531692  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:11:18.531692  4700 solver.cpp:237]     Train net output #1: loss = 0.305097 (* 1 = 0.305097 loss)
I1210 14:11:18.531692  4700 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1210 14:11:24.179592  4700 solver.cpp:218] Iteration 98300 (17.7095 iter/s, 5.64669s/100 iters), loss = 0.529937
I1210 14:11:24.179592  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:11:24.179592  4700 solver.cpp:237]     Train net output #1: loss = 0.529937 (* 1 = 0.529937 loss)
I1210 14:11:24.179592  4700 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1210 14:11:29.825587  4700 solver.cpp:218] Iteration 98400 (17.7107 iter/s, 5.6463s/100 iters), loss = 0.537929
I1210 14:11:29.825587  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:11:29.826587  4700 solver.cpp:237]     Train net output #1: loss = 0.537929 (* 1 = 0.537929 loss)
I1210 14:11:29.826587  4700 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1210 14:11:35.203042 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:11:35.425067  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98500.caffemodel
I1210 14:11:35.440066  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_98500.solverstate
I1210 14:11:35.444068  4700 solver.cpp:330] Iteration 98500, Testing net (#0)
I1210 14:11:35.445068  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:11:36.812228  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:11:36.865226  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6823
I1210 14:11:36.866228  4700 solver.cpp:397]     Test net output #1: loss = 1.17412 (* 1 = 1.17412 loss)
I1210 14:11:36.922235  4700 solver.cpp:218] Iteration 98500 (14.0933 iter/s, 7.09557s/100 iters), loss = 0.39885
I1210 14:11:36.922235  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:11:36.922235  4700 solver.cpp:237]     Train net output #1: loss = 0.39885 (* 1 = 0.39885 loss)
I1210 14:11:36.922235  4700 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1210 14:11:42.581727  4700 solver.cpp:218] Iteration 98600 (17.6707 iter/s, 5.65908s/100 iters), loss = 0.478098
I1210 14:11:42.581727  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:11:42.581727  4700 solver.cpp:237]     Train net output #1: loss = 0.478098 (* 1 = 0.478098 loss)
I1210 14:11:42.581727  4700 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1210 14:11:48.237848  4700 solver.cpp:218] Iteration 98700 (17.6807 iter/s, 5.65587s/100 iters), loss = 0.396917
I1210 14:11:48.237848  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:11:48.237848  4700 solver.cpp:237]     Train net output #1: loss = 0.396917 (* 1 = 0.396917 loss)
I1210 14:11:48.237848  4700 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1210 14:11:53.905949  4700 solver.cpp:218] Iteration 98800 (17.6449 iter/s, 5.66736s/100 iters), loss = 0.512717
I1210 14:11:53.905949  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:11:53.905949  4700 solver.cpp:237]     Train net output #1: loss = 0.512717 (* 1 = 0.512717 loss)
I1210 14:11:53.905949  4700 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1210 14:11:59.558470  4700 solver.cpp:218] Iteration 98900 (17.6912 iter/s, 5.65251s/100 iters), loss = 0.540999
I1210 14:11:59.558470  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 14:11:59.558470  4700 solver.cpp:237]     Train net output #1: loss = 0.540999 (* 1 = 0.540999 loss)
I1210 14:11:59.558470  4700 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1210 14:12:04.935225 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:12:05.157375  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99000.caffemodel
I1210 14:12:05.172377  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99000.solverstate
I1210 14:12:05.177389  4700 solver.cpp:330] Iteration 99000, Testing net (#0)
I1210 14:12:05.177389  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:12:06.539057  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:12:06.594566  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6824
I1210 14:12:06.594566  4700 solver.cpp:397]     Test net output #1: loss = 1.18148 (* 1 = 1.18148 loss)
I1210 14:12:06.648094  4700 solver.cpp:218] Iteration 99000 (14.1056 iter/s, 7.0894s/100 iters), loss = 0.465444
I1210 14:12:06.648094  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:12:06.648094  4700 solver.cpp:237]     Train net output #1: loss = 0.465444 (* 1 = 0.465444 loss)
I1210 14:12:06.648094  4700 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1210 14:12:12.293143  4700 solver.cpp:218] Iteration 99100 (17.7185 iter/s, 5.64383s/100 iters), loss = 0.412438
I1210 14:12:12.293143  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:12:12.293143  4700 solver.cpp:237]     Train net output #1: loss = 0.412438 (* 1 = 0.412438 loss)
I1210 14:12:12.293143  4700 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1210 14:12:17.948082  4700 solver.cpp:218] Iteration 99200 (17.6848 iter/s, 5.65457s/100 iters), loss = 0.327734
I1210 14:12:17.948082  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:12:17.948082  4700 solver.cpp:237]     Train net output #1: loss = 0.327734 (* 1 = 0.327734 loss)
I1210 14:12:17.948082  4700 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1210 14:12:23.587301  4700 solver.cpp:218] Iteration 99300 (17.7348 iter/s, 5.63863s/100 iters), loss = 0.451638
I1210 14:12:23.587301  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:12:23.587301  4700 solver.cpp:237]     Train net output #1: loss = 0.451638 (* 1 = 0.451638 loss)
I1210 14:12:23.587301  4700 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1210 14:12:29.228246  4700 solver.cpp:218] Iteration 99400 (17.7277 iter/s, 5.64088s/100 iters), loss = 0.50667
I1210 14:12:29.228246  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:12:29.228246  4700 solver.cpp:237]     Train net output #1: loss = 0.50667 (* 1 = 0.50667 loss)
I1210 14:12:29.228246  4700 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1210 14:12:34.590625 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:12:34.811146  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99500.caffemodel
I1210 14:12:34.826148  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_99500.solverstate
I1210 14:12:34.831147  4700 solver.cpp:330] Iteration 99500, Testing net (#0)
I1210 14:12:34.831147  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:12:36.198828  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:12:36.254330  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6869
I1210 14:12:36.254330  4700 solver.cpp:397]     Test net output #1: loss = 1.17891 (* 1 = 1.17891 loss)
I1210 14:12:36.307339  4700 solver.cpp:218] Iteration 99500 (14.1265 iter/s, 7.07891s/100 iters), loss = 0.333838
I1210 14:12:36.307339  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:12:36.307339  4700 solver.cpp:237]     Train net output #1: loss = 0.333838 (* 1 = 0.333838 loss)
I1210 14:12:36.307339  4700 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1210 14:12:41.947032  4700 solver.cpp:218] Iteration 99600 (17.7341 iter/s, 5.63886s/100 iters), loss = 0.466651
I1210 14:12:41.947032  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:12:41.947032  4700 solver.cpp:237]     Train net output #1: loss = 0.466651 (* 1 = 0.466651 loss)
I1210 14:12:41.947032  4700 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1210 14:12:47.585994  4700 solver.cpp:218] Iteration 99700 (17.7354 iter/s, 5.63844s/100 iters), loss = 0.367002
I1210 14:12:47.585994  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:12:47.585994  4700 solver.cpp:237]     Train net output #1: loss = 0.367002 (* 1 = 0.367002 loss)
I1210 14:12:47.585994  4700 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1210 14:12:53.219079  4700 solver.cpp:218] Iteration 99800 (17.7534 iter/s, 5.63273s/100 iters), loss = 0.445314
I1210 14:12:53.219079  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:12:53.219079  4700 solver.cpp:237]     Train net output #1: loss = 0.445314 (* 1 = 0.445314 loss)
I1210 14:12:53.219079  4700 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1210 14:12:58.856113  4700 solver.cpp:218] Iteration 99900 (17.7407 iter/s, 5.63676s/100 iters), loss = 0.46199
I1210 14:12:58.856113  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:12:58.856113  4700 solver.cpp:237]     Train net output #1: loss = 0.46199 (* 1 = 0.46199 loss)
I1210 14:12:58.856113  4700 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1210 14:13:04.203652 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:13:04.425405  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100000.caffemodel
I1210 14:13:04.439405  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100000.solverstate
I1210 14:13:04.444404  4700 solver.cpp:330] Iteration 100000, Testing net (#0)
I1210 14:13:04.444404  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:13:05.810308  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:13:05.863839  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6792
I1210 14:13:05.863839  4700 solver.cpp:397]     Test net output #1: loss = 1.19834 (* 1 = 1.19834 loss)
I1210 14:13:05.918857  4700 solver.cpp:218] Iteration 100000 (14.1591 iter/s, 7.06258s/100 iters), loss = 0.373381
I1210 14:13:05.919874  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:13:05.919874  4700 solver.cpp:237]     Train net output #1: loss = 0.373381 (* 1 = 0.373381 loss)
I1210 14:13:05.919874  4700 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1210 14:13:11.571434  4700 solver.cpp:218] Iteration 100100 (17.694 iter/s, 5.65165s/100 iters), loss = 0.469273
I1210 14:13:11.571434  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:13:11.571434  4700 solver.cpp:237]     Train net output #1: loss = 0.469273 (* 1 = 0.469273 loss)
I1210 14:13:11.571434  4700 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1210 14:13:17.220558  4700 solver.cpp:218] Iteration 100200 (17.7031 iter/s, 5.64873s/100 iters), loss = 0.320305
I1210 14:13:17.220558  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:13:17.220558  4700 solver.cpp:237]     Train net output #1: loss = 0.320305 (* 1 = 0.320305 loss)
I1210 14:13:17.220558  4700 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1210 14:13:22.879659  4700 solver.cpp:218] Iteration 100300 (17.6725 iter/s, 5.65852s/100 iters), loss = 0.468643
I1210 14:13:22.879659  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:13:22.879659  4700 solver.cpp:237]     Train net output #1: loss = 0.468643 (* 1 = 0.468643 loss)
I1210 14:13:22.879659  4700 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1210 14:13:28.530305  4700 solver.cpp:218] Iteration 100400 (17.6976 iter/s, 5.65048s/100 iters), loss = 0.496445
I1210 14:13:28.530305  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:13:28.530305  4700 solver.cpp:237]     Train net output #1: loss = 0.496445 (* 1 = 0.496445 loss)
I1210 14:13:28.530305  4700 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1210 14:13:33.905009 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:13:34.128043  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100500.caffemodel
I1210 14:13:34.143043  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_100500.solverstate
I1210 14:13:34.148043  4700 solver.cpp:330] Iteration 100500, Testing net (#0)
I1210 14:13:34.148043  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:13:35.513207  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:13:35.568209  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6806
I1210 14:13:35.568209  4700 solver.cpp:397]     Test net output #1: loss = 1.1942 (* 1 = 1.1942 loss)
I1210 14:13:35.621214  4700 solver.cpp:218] Iteration 100500 (14.1045 iter/s, 7.08993s/100 iters), loss = 0.322368
I1210 14:13:35.621214  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:13:35.621716  4700 solver.cpp:237]     Train net output #1: loss = 0.322368 (* 1 = 0.322368 loss)
I1210 14:13:35.621716  4700 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1210 14:13:41.252125  4700 solver.cpp:218] Iteration 100600 (17.7607 iter/s, 5.63041s/100 iters), loss = 0.512613
I1210 14:13:41.252125  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:13:41.252125  4700 solver.cpp:237]     Train net output #1: loss = 0.512613 (* 1 = 0.512613 loss)
I1210 14:13:41.252125  4700 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1210 14:13:46.895015  4700 solver.cpp:218] Iteration 100700 (17.7209 iter/s, 5.64304s/100 iters), loss = 0.262577
I1210 14:13:46.895015  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:13:46.896015  4700 solver.cpp:237]     Train net output #1: loss = 0.262577 (* 1 = 0.262577 loss)
I1210 14:13:46.896015  4700 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1210 14:13:52.528007  4700 solver.cpp:218] Iteration 100800 (17.7565 iter/s, 5.63174s/100 iters), loss = 0.448558
I1210 14:13:52.528007  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:13:52.528007  4700 solver.cpp:237]     Train net output #1: loss = 0.448558 (* 1 = 0.448558 loss)
I1210 14:13:52.528007  4700 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1210 14:13:58.164562  4700 solver.cpp:218] Iteration 100900 (17.7426 iter/s, 5.63615s/100 iters), loss = 0.444388
I1210 14:13:58.164562  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:13:58.164562  4700 solver.cpp:237]     Train net output #1: loss = 0.444388 (* 1 = 0.444388 loss)
I1210 14:13:58.164562  4700 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1210 14:14:03.516963 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:14:03.738986  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101000.caffemodel
I1210 14:14:03.753984  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101000.solverstate
I1210 14:14:03.758985  4700 solver.cpp:330] Iteration 101000, Testing net (#0)
I1210 14:14:03.758985  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:14:05.128159  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:14:05.182170  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6828
I1210 14:14:05.182170  4700 solver.cpp:397]     Test net output #1: loss = 1.18713 (* 1 = 1.18713 loss)
I1210 14:14:05.237167  4700 solver.cpp:218] Iteration 101000 (14.1399 iter/s, 7.07219s/100 iters), loss = 0.419689
I1210 14:14:05.237167  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:14:05.237167  4700 solver.cpp:237]     Train net output #1: loss = 0.419689 (* 1 = 0.419689 loss)
I1210 14:14:05.237167  4700 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1210 14:14:10.895609  4700 solver.cpp:218] Iteration 101100 (17.6745 iter/s, 5.65786s/100 iters), loss = 0.526321
I1210 14:14:10.895609  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:14:10.895609  4700 solver.cpp:237]     Train net output #1: loss = 0.526321 (* 1 = 0.526321 loss)
I1210 14:14:10.895609  4700 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1210 14:14:16.554061  4700 solver.cpp:218] Iteration 101200 (17.6742 iter/s, 5.65796s/100 iters), loss = 0.304373
I1210 14:14:16.554061  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:14:16.554061  4700 solver.cpp:237]     Train net output #1: loss = 0.304373 (* 1 = 0.304373 loss)
I1210 14:14:16.554061  4700 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1210 14:14:22.208490  4700 solver.cpp:218] Iteration 101300 (17.6865 iter/s, 5.65402s/100 iters), loss = 0.433212
I1210 14:14:22.208490  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:14:22.208490  4700 solver.cpp:237]     Train net output #1: loss = 0.433212 (* 1 = 0.433212 loss)
I1210 14:14:22.208490  4700 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1210 14:14:27.853365  4700 solver.cpp:218] Iteration 101400 (17.7159 iter/s, 5.64466s/100 iters), loss = 0.466466
I1210 14:14:27.853365  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:14:27.853365  4700 solver.cpp:237]     Train net output #1: loss = 0.466466 (* 1 = 0.466466 loss)
I1210 14:14:27.853365  4700 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1210 14:14:33.238016 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:14:33.460029  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101500.caffemodel
I1210 14:14:33.475533  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_101500.solverstate
I1210 14:14:33.480533  4700 solver.cpp:330] Iteration 101500, Testing net (#0)
I1210 14:14:33.480533  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:14:34.848168  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:14:34.902166  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6815
I1210 14:14:34.902667  4700 solver.cpp:397]     Test net output #1: loss = 1.18697 (* 1 = 1.18697 loss)
I1210 14:14:34.956182  4700 solver.cpp:218] Iteration 101500 (14.0805 iter/s, 7.10204s/100 iters), loss = 0.333697
I1210 14:14:34.956182  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:14:34.956182  4700 solver.cpp:237]     Train net output #1: loss = 0.333697 (* 1 = 0.333697 loss)
I1210 14:14:34.956182  4700 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1210 14:14:40.608760  4700 solver.cpp:218] Iteration 101600 (17.6931 iter/s, 5.65192s/100 iters), loss = 0.381889
I1210 14:14:40.608760  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:14:40.608760  4700 solver.cpp:237]     Train net output #1: loss = 0.381889 (* 1 = 0.381889 loss)
I1210 14:14:40.608760  4700 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1210 14:14:46.258332  4700 solver.cpp:218] Iteration 101700 (17.7001 iter/s, 5.64968s/100 iters), loss = 0.331049
I1210 14:14:46.258332  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:14:46.258332  4700 solver.cpp:237]     Train net output #1: loss = 0.331049 (* 1 = 0.331049 loss)
I1210 14:14:46.258332  4700 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1210 14:14:51.899381  4700 solver.cpp:218] Iteration 101800 (17.7279 iter/s, 5.64084s/100 iters), loss = 0.384119
I1210 14:14:51.899381  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:14:51.899381  4700 solver.cpp:237]     Train net output #1: loss = 0.384119 (* 1 = 0.384119 loss)
I1210 14:14:51.899381  4700 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1210 14:14:57.543421  4700 solver.cpp:218] Iteration 101900 (17.7205 iter/s, 5.64318s/100 iters), loss = 0.444489
I1210 14:14:57.543421  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:14:57.543421  4700 solver.cpp:237]     Train net output #1: loss = 0.444489 (* 1 = 0.444489 loss)
I1210 14:14:57.543421  4700 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1210 14:15:02.896622 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:15:03.120303  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102000.caffemodel
I1210 14:15:03.135668  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102000.solverstate
I1210 14:15:03.140668  4700 solver.cpp:330] Iteration 102000, Testing net (#0)
I1210 14:15:03.140668  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:15:04.506420  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:15:04.561218  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6815
I1210 14:15:04.561218  4700 solver.cpp:397]     Test net output #1: loss = 1.19887 (* 1 = 1.19887 loss)
I1210 14:15:04.614233  4700 solver.cpp:218] Iteration 102000 (14.1437 iter/s, 7.07031s/100 iters), loss = 0.386006
I1210 14:15:04.614233  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:15:04.614233  4700 solver.cpp:237]     Train net output #1: loss = 0.386006 (* 1 = 0.386006 loss)
I1210 14:15:04.614233  4700 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1210 14:15:10.251857  4700 solver.cpp:218] Iteration 102100 (17.7389 iter/s, 5.63734s/100 iters), loss = 0.438239
I1210 14:15:10.251857  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:15:10.251857  4700 solver.cpp:237]     Train net output #1: loss = 0.438239 (* 1 = 0.438239 loss)
I1210 14:15:10.251857  4700 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1210 14:15:15.894448  4700 solver.cpp:218] Iteration 102200 (17.7228 iter/s, 5.64246s/100 iters), loss = 0.287233
I1210 14:15:15.894448  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:15:15.894448  4700 solver.cpp:237]     Train net output #1: loss = 0.287233 (* 1 = 0.287233 loss)
I1210 14:15:15.894448  4700 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1210 14:15:21.536033  4700 solver.cpp:218] Iteration 102300 (17.7278 iter/s, 5.64085s/100 iters), loss = 0.377036
I1210 14:15:21.536033  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:15:21.536538  4700 solver.cpp:237]     Train net output #1: loss = 0.377036 (* 1 = 0.377036 loss)
I1210 14:15:21.536538  4700 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1210 14:15:27.172994  4700 solver.cpp:218] Iteration 102400 (17.7404 iter/s, 5.63684s/100 iters), loss = 0.480089
I1210 14:15:27.172994  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:15:27.172994  4700 solver.cpp:237]     Train net output #1: loss = 0.480089 (* 1 = 0.480089 loss)
I1210 14:15:27.172994  4700 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1210 14:15:32.539979 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:15:32.762492  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102500.caffemodel
I1210 14:15:32.776491  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_102500.solverstate
I1210 14:15:32.781492  4700 solver.cpp:330] Iteration 102500, Testing net (#0)
I1210 14:15:32.781492  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:15:34.147584  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:15:34.202585  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6822
I1210 14:15:34.202585  4700 solver.cpp:397]     Test net output #1: loss = 1.19552 (* 1 = 1.19552 loss)
I1210 14:15:34.255592  4700 solver.cpp:218] Iteration 102500 (14.1204 iter/s, 7.08198s/100 iters), loss = 0.27934
I1210 14:15:34.255592  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:15:34.255592  4700 solver.cpp:237]     Train net output #1: loss = 0.27934 (* 1 = 0.27934 loss)
I1210 14:15:34.255592  4700 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1210 14:15:39.901089  4700 solver.cpp:218] Iteration 102600 (17.715 iter/s, 5.64494s/100 iters), loss = 0.42678
I1210 14:15:39.901089  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:15:39.901089  4700 solver.cpp:237]     Train net output #1: loss = 0.42678 (* 1 = 0.42678 loss)
I1210 14:15:39.901089  4700 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1210 14:15:45.542557  4700 solver.cpp:218] Iteration 102700 (17.7285 iter/s, 5.64063s/100 iters), loss = 0.282329
I1210 14:15:45.542557  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:15:45.542557  4700 solver.cpp:237]     Train net output #1: loss = 0.282329 (* 1 = 0.282329 loss)
I1210 14:15:45.542557  4700 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1210 14:15:51.194015  4700 solver.cpp:218] Iteration 102800 (17.695 iter/s, 5.65131s/100 iters), loss = 0.39345
I1210 14:15:51.194015  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:15:51.194015  4700 solver.cpp:237]     Train net output #1: loss = 0.39345 (* 1 = 0.39345 loss)
I1210 14:15:51.194015  4700 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1210 14:15:56.841401  4700 solver.cpp:218] Iteration 102900 (17.7087 iter/s, 5.64695s/100 iters), loss = 0.487342
I1210 14:15:56.841401  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:15:56.841401  4700 solver.cpp:237]     Train net output #1: loss = 0.487342 (* 1 = 0.487342 loss)
I1210 14:15:56.841401  4700 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1210 14:16:02.214844 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:16:02.436369  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103000.caffemodel
I1210 14:16:02.450878  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103000.solverstate
I1210 14:16:02.455873  4700 solver.cpp:330] Iteration 103000, Testing net (#0)
I1210 14:16:02.455873  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:16:03.822010  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:16:03.878029  4700 solver.cpp:397]     Test net output #0: accuracy = 0.682
I1210 14:16:03.878029  4700 solver.cpp:397]     Test net output #1: loss = 1.1972 (* 1 = 1.1972 loss)
I1210 14:16:03.931540  4700 solver.cpp:218] Iteration 103000 (14.1052 iter/s, 7.08956s/100 iters), loss = 0.382767
I1210 14:16:03.931540  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:16:03.931540  4700 solver.cpp:237]     Train net output #1: loss = 0.382767 (* 1 = 0.382767 loss)
I1210 14:16:03.931540  4700 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1210 14:16:09.572484  4700 solver.cpp:218] Iteration 103100 (17.7266 iter/s, 5.64124s/100 iters), loss = 0.450979
I1210 14:16:09.573483  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:16:09.573483  4700 solver.cpp:237]     Train net output #1: loss = 0.450979 (* 1 = 0.450979 loss)
I1210 14:16:09.573483  4700 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1210 14:16:15.213045  4700 solver.cpp:218] Iteration 103200 (17.7321 iter/s, 5.63948s/100 iters), loss = 0.311428
I1210 14:16:15.213045  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:16:15.213045  4700 solver.cpp:237]     Train net output #1: loss = 0.311428 (* 1 = 0.311428 loss)
I1210 14:16:15.213045  4700 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1210 14:16:20.861548  4700 solver.cpp:218] Iteration 103300 (17.7041 iter/s, 5.64842s/100 iters), loss = 0.489541
I1210 14:16:20.861548  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:16:20.861548  4700 solver.cpp:237]     Train net output #1: loss = 0.489541 (* 1 = 0.489541 loss)
I1210 14:16:20.861548  4700 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1210 14:16:26.504031  4700 solver.cpp:218] Iteration 103400 (17.7252 iter/s, 5.6417s/100 iters), loss = 0.478914
I1210 14:16:26.504031  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:16:26.504031  4700 solver.cpp:237]     Train net output #1: loss = 0.478914 (* 1 = 0.478914 loss)
I1210 14:16:26.504031  4700 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1210 14:16:31.872460 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:16:32.094496  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103500.caffemodel
I1210 14:16:32.109496  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_103500.solverstate
I1210 14:16:32.114496  4700 solver.cpp:330] Iteration 103500, Testing net (#0)
I1210 14:16:32.114496  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:16:33.479578  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:16:33.535080  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6843
I1210 14:16:33.535080  4700 solver.cpp:397]     Test net output #1: loss = 1.20076 (* 1 = 1.20076 loss)
I1210 14:16:33.587582  4700 solver.cpp:218] Iteration 103500 (14.1171 iter/s, 7.0836s/100 iters), loss = 0.388612
I1210 14:16:33.587582  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:16:33.587582  4700 solver.cpp:237]     Train net output #1: loss = 0.388612 (* 1 = 0.388612 loss)
I1210 14:16:33.587582  4700 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1210 14:16:39.252985  4700 solver.cpp:218] Iteration 103600 (17.6546 iter/s, 5.66423s/100 iters), loss = 0.352744
I1210 14:16:39.252985  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:16:39.252985  4700 solver.cpp:237]     Train net output #1: loss = 0.352744 (* 1 = 0.352744 loss)
I1210 14:16:39.252985  4700 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1210 14:16:44.913431  4700 solver.cpp:218] Iteration 103700 (17.6664 iter/s, 5.66046s/100 iters), loss = 0.279525
I1210 14:16:44.913431  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:16:44.913431  4700 solver.cpp:237]     Train net output #1: loss = 0.279525 (* 1 = 0.279525 loss)
I1210 14:16:44.913431  4700 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1210 14:16:50.573006  4700 solver.cpp:218] Iteration 103800 (17.6733 iter/s, 5.65827s/100 iters), loss = 0.406319
I1210 14:16:50.573006  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:16:50.573006  4700 solver.cpp:237]     Train net output #1: loss = 0.406319 (* 1 = 0.406319 loss)
I1210 14:16:50.573006  4700 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1210 14:16:56.241008  4700 solver.cpp:218] Iteration 103900 (17.6428 iter/s, 5.66805s/100 iters), loss = 0.479288
I1210 14:16:56.241508  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:16:56.241508  4700 solver.cpp:237]     Train net output #1: loss = 0.479288 (* 1 = 0.479288 loss)
I1210 14:16:56.241508  4700 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1210 14:17:01.629938 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:17:01.853953  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104000.caffemodel
I1210 14:17:01.867954  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104000.solverstate
I1210 14:17:01.872953  4700 solver.cpp:330] Iteration 104000, Testing net (#0)
I1210 14:17:01.872953  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:17:03.242566  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:17:03.296069  4700 solver.cpp:397]     Test net output #0: accuracy = 0.683
I1210 14:17:03.296069  4700 solver.cpp:397]     Test net output #1: loss = 1.21152 (* 1 = 1.21152 loss)
I1210 14:17:03.349071  4700 solver.cpp:218] Iteration 104000 (14.0699 iter/s, 7.10735s/100 iters), loss = 0.395368
I1210 14:17:03.349071  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:17:03.349071  4700 solver.cpp:237]     Train net output #1: loss = 0.395368 (* 1 = 0.395368 loss)
I1210 14:17:03.349071  4700 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1210 14:17:08.997514  4700 solver.cpp:218] Iteration 104100 (17.7043 iter/s, 5.64834s/100 iters), loss = 0.401086
I1210 14:17:08.997514  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:17:08.997514  4700 solver.cpp:237]     Train net output #1: loss = 0.401086 (* 1 = 0.401086 loss)
I1210 14:17:08.997514  4700 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1210 14:17:14.639583  4700 solver.cpp:218] Iteration 104200 (17.7257 iter/s, 5.64154s/100 iters), loss = 0.296593
I1210 14:17:14.640084  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:17:14.640084  4700 solver.cpp:237]     Train net output #1: loss = 0.296593 (* 1 = 0.296593 loss)
I1210 14:17:14.640084  4700 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1210 14:17:20.287295  4700 solver.cpp:218] Iteration 104300 (17.7078 iter/s, 5.64723s/100 iters), loss = 0.377614
I1210 14:17:20.287295  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:17:20.287295  4700 solver.cpp:237]     Train net output #1: loss = 0.377614 (* 1 = 0.377614 loss)
I1210 14:17:20.287295  4700 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1210 14:17:25.928663  4700 solver.cpp:218] Iteration 104400 (17.7272 iter/s, 5.64104s/100 iters), loss = 0.457306
I1210 14:17:25.928663  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:17:25.928663  4700 solver.cpp:237]     Train net output #1: loss = 0.457306 (* 1 = 0.457306 loss)
I1210 14:17:25.928663  4700 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1210 14:17:31.307268 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:17:31.527983  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104500.caffemodel
I1210 14:17:31.542980  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_104500.solverstate
I1210 14:17:31.548496  4700 solver.cpp:330] Iteration 104500, Testing net (#0)
I1210 14:17:31.548496  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:17:32.915452  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:17:32.968473  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6789
I1210 14:17:32.968473  4700 solver.cpp:397]     Test net output #1: loss = 1.21252 (* 1 = 1.21252 loss)
I1210 14:17:33.022464  4700 solver.cpp:218] Iteration 104500 (14.097 iter/s, 7.0937s/100 iters), loss = 0.352419
I1210 14:17:33.022464  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:17:33.022464  4700 solver.cpp:237]     Train net output #1: loss = 0.352419 (* 1 = 0.352419 loss)
I1210 14:17:33.023466  4700 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1210 14:17:38.662277  4700 solver.cpp:218] Iteration 104600 (17.7347 iter/s, 5.63865s/100 iters), loss = 0.372958
I1210 14:17:38.662277  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:17:38.662277  4700 solver.cpp:237]     Train net output #1: loss = 0.372958 (* 1 = 0.372958 loss)
I1210 14:17:38.662277  4700 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1210 14:17:44.302419  4700 solver.cpp:218] Iteration 104700 (17.7291 iter/s, 5.64045s/100 iters), loss = 0.293252
I1210 14:17:44.303418  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:17:44.303418  4700 solver.cpp:237]     Train net output #1: loss = 0.293252 (* 1 = 0.293252 loss)
I1210 14:17:44.303418  4700 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1210 14:17:49.945893  4700 solver.cpp:218] Iteration 104800 (17.7214 iter/s, 5.6429s/100 iters), loss = 0.412199
I1210 14:17:49.945893  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:17:49.945893  4700 solver.cpp:237]     Train net output #1: loss = 0.412199 (* 1 = 0.412199 loss)
I1210 14:17:49.945893  4700 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1210 14:17:55.596349  4700 solver.cpp:218] Iteration 104900 (17.7013 iter/s, 5.64929s/100 iters), loss = 0.422684
I1210 14:17:55.596349  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:17:55.596349  4700 solver.cpp:237]     Train net output #1: loss = 0.422684 (* 1 = 0.422684 loss)
I1210 14:17:55.596349  4700 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1210 14:18:00.971770 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:18:01.192781  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105000.caffemodel
I1210 14:18:01.207782  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105000.solverstate
I1210 14:18:01.212781  4700 solver.cpp:330] Iteration 105000, Testing net (#0)
I1210 14:18:01.212781  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:18:02.581897  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:18:02.634896  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6783
I1210 14:18:02.634896  4700 solver.cpp:397]     Test net output #1: loss = 1.22975 (* 1 = 1.22975 loss)
I1210 14:18:02.688902  4700 solver.cpp:218] Iteration 105000 (14.1005 iter/s, 7.09196s/100 iters), loss = 0.318618
I1210 14:18:02.688902  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:18:02.688902  4700 solver.cpp:237]     Train net output #1: loss = 0.318618 (* 1 = 0.318618 loss)
I1210 14:18:02.688902  4700 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1210 14:18:08.342953  4700 solver.cpp:218] Iteration 105100 (17.686 iter/s, 5.65418s/100 iters), loss = 0.301058
I1210 14:18:08.342953  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:18:08.342953  4700 solver.cpp:237]     Train net output #1: loss = 0.301058 (* 1 = 0.301058 loss)
I1210 14:18:08.342953  4700 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1210 14:18:14.010402  4700 solver.cpp:218] Iteration 105200 (17.6449 iter/s, 5.66735s/100 iters), loss = 0.237943
I1210 14:18:14.011404  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:18:14.011404  4700 solver.cpp:237]     Train net output #1: loss = 0.237943 (* 1 = 0.237943 loss)
I1210 14:18:14.011404  4700 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1210 14:18:19.669890  4700 solver.cpp:218] Iteration 105300 (17.6734 iter/s, 5.65823s/100 iters), loss = 0.391233
I1210 14:18:19.669890  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:18:19.669890  4700 solver.cpp:237]     Train net output #1: loss = 0.391233 (* 1 = 0.391233 loss)
I1210 14:18:19.669890  4700 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1210 14:18:25.324344  4700 solver.cpp:218] Iteration 105400 (17.6845 iter/s, 5.65468s/100 iters), loss = 0.394142
I1210 14:18:25.324344  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:18:25.324344  4700 solver.cpp:237]     Train net output #1: loss = 0.394142 (* 1 = 0.394142 loss)
I1210 14:18:25.324344  4700 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1210 14:18:30.701756 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:18:30.923779  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105500.caffemodel
I1210 14:18:30.938778  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_105500.solverstate
I1210 14:18:30.943778  4700 solver.cpp:330] Iteration 105500, Testing net (#0)
I1210 14:18:30.943778  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:18:32.313184  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:18:32.366231  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6775
I1210 14:18:32.366231  4700 solver.cpp:397]     Test net output #1: loss = 1.22854 (* 1 = 1.22854 loss)
I1210 14:18:32.420219  4700 solver.cpp:218] Iteration 105500 (14.095 iter/s, 7.09473s/100 iters), loss = 0.395632
I1210 14:18:32.420219  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:18:32.420219  4700 solver.cpp:237]     Train net output #1: loss = 0.395632 (* 1 = 0.395632 loss)
I1210 14:18:32.420219  4700 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1210 14:18:38.049645  4700 solver.cpp:218] Iteration 105600 (17.7657 iter/s, 5.62881s/100 iters), loss = 0.37414
I1210 14:18:38.049645  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:18:38.049645  4700 solver.cpp:237]     Train net output #1: loss = 0.37414 (* 1 = 0.37414 loss)
I1210 14:18:38.049645  4700 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1210 14:18:43.675065  4700 solver.cpp:218] Iteration 105700 (17.7776 iter/s, 5.62504s/100 iters), loss = 0.263429
I1210 14:18:43.675065  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:18:43.675065  4700 solver.cpp:237]     Train net output #1: loss = 0.263429 (* 1 = 0.263429 loss)
I1210 14:18:43.675065  4700 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1210 14:18:49.304978  4700 solver.cpp:218] Iteration 105800 (17.7629 iter/s, 5.62972s/100 iters), loss = 0.397457
I1210 14:18:49.304978  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:18:49.304978  4700 solver.cpp:237]     Train net output #1: loss = 0.397457 (* 1 = 0.397457 loss)
I1210 14:18:49.304978  4700 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1210 14:18:54.936360  4700 solver.cpp:218] Iteration 105900 (17.7597 iter/s, 5.63073s/100 iters), loss = 0.471839
I1210 14:18:54.936360  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:18:54.936360  4700 solver.cpp:237]     Train net output #1: loss = 0.471839 (* 1 = 0.471839 loss)
I1210 14:18:54.936360  4700 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1210 14:19:00.305856 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:19:00.526870  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106000.caffemodel
I1210 14:19:00.541870  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106000.solverstate
I1210 14:19:00.546871  4700 solver.cpp:330] Iteration 106000, Testing net (#0)
I1210 14:19:00.546871  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:19:01.912976  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:19:01.967478  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6803
I1210 14:19:01.967478  4700 solver.cpp:397]     Test net output #1: loss = 1.21767 (* 1 = 1.21767 loss)
I1210 14:19:02.020985  4700 solver.cpp:218] Iteration 106000 (14.116 iter/s, 7.08415s/100 iters), loss = 0.346018
I1210 14:19:02.020985  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:19:02.020985  4700 solver.cpp:237]     Train net output #1: loss = 0.346018 (* 1 = 0.346018 loss)
I1210 14:19:02.020985  4700 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1210 14:19:07.677898  4700 solver.cpp:218] Iteration 106100 (17.6798 iter/s, 5.65618s/100 iters), loss = 0.410594
I1210 14:19:07.677898  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:19:07.677898  4700 solver.cpp:237]     Train net output #1: loss = 0.410594 (* 1 = 0.410594 loss)
I1210 14:19:07.677898  4700 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1210 14:19:13.331856  4700 solver.cpp:218] Iteration 106200 (17.686 iter/s, 5.65419s/100 iters), loss = 0.255608
I1210 14:19:13.331856  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:19:13.331856  4700 solver.cpp:237]     Train net output #1: loss = 0.255608 (* 1 = 0.255608 loss)
I1210 14:19:13.331856  4700 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1210 14:19:18.984302  4700 solver.cpp:218] Iteration 106300 (17.6945 iter/s, 5.65148s/100 iters), loss = 0.342943
I1210 14:19:18.984302  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:19:18.984302  4700 solver.cpp:237]     Train net output #1: loss = 0.342943 (* 1 = 0.342943 loss)
I1210 14:19:18.984302  4700 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1210 14:19:24.630831  4700 solver.cpp:218] Iteration 106400 (17.7097 iter/s, 5.64663s/100 iters), loss = 0.525712
I1210 14:19:24.630831  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:19:24.630831  4700 solver.cpp:237]     Train net output #1: loss = 0.525712 (* 1 = 0.525712 loss)
I1210 14:19:24.630831  4700 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1210 14:19:29.998586 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:19:30.219101  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106500.caffemodel
I1210 14:19:30.235105  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_106500.solverstate
I1210 14:19:30.240103  4700 solver.cpp:330] Iteration 106500, Testing net (#0)
I1210 14:19:30.240103  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:19:31.607923  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:19:31.660938  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6795
I1210 14:19:31.660938  4700 solver.cpp:397]     Test net output #1: loss = 1.22367 (* 1 = 1.22367 loss)
I1210 14:19:31.714558  4700 solver.cpp:218] Iteration 106500 (14.1182 iter/s, 7.08303s/100 iters), loss = 0.384015
I1210 14:19:31.714558  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:19:31.714558  4700 solver.cpp:237]     Train net output #1: loss = 0.384015 (* 1 = 0.384015 loss)
I1210 14:19:31.714558  4700 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1210 14:19:37.363021  4700 solver.cpp:218] Iteration 106600 (17.7068 iter/s, 5.64753s/100 iters), loss = 0.408775
I1210 14:19:37.363021  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:19:37.363021  4700 solver.cpp:237]     Train net output #1: loss = 0.408775 (* 1 = 0.408775 loss)
I1210 14:19:37.363021  4700 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1210 14:19:43.000583  4700 solver.cpp:218] Iteration 106700 (17.7385 iter/s, 5.63746s/100 iters), loss = 0.266389
I1210 14:19:43.000583  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:19:43.000583  4700 solver.cpp:237]     Train net output #1: loss = 0.266389 (* 1 = 0.266389 loss)
I1210 14:19:43.000583  4700 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1210 14:19:48.648803  4700 solver.cpp:218] Iteration 106800 (17.7074 iter/s, 5.64737s/100 iters), loss = 0.421341
I1210 14:19:48.648803  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:19:48.648803  4700 solver.cpp:237]     Train net output #1: loss = 0.421341 (* 1 = 0.421341 loss)
I1210 14:19:48.648803  4700 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1210 14:19:54.295027  4700 solver.cpp:218] Iteration 106900 (17.7114 iter/s, 5.64609s/100 iters), loss = 0.519287
I1210 14:19:54.295027  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:19:54.295527  4700 solver.cpp:237]     Train net output #1: loss = 0.519287 (* 1 = 0.519287 loss)
I1210 14:19:54.295527  4700 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1210 14:19:59.670538 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:19:59.893736  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107000.caffemodel
I1210 14:19:59.914242  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107000.solverstate
I1210 14:19:59.920241  4700 solver.cpp:330] Iteration 107000, Testing net (#0)
I1210 14:19:59.920241  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:20:01.308089  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:20:01.361068  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6807
I1210 14:20:01.361068  4700 solver.cpp:397]     Test net output #1: loss = 1.21748 (* 1 = 1.21748 loss)
I1210 14:20:01.417084  4700 solver.cpp:218] Iteration 107000 (14.0411 iter/s, 7.12193s/100 iters), loss = 0.353941
I1210 14:20:01.417084  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:20:01.417084  4700 solver.cpp:237]     Train net output #1: loss = 0.353941 (* 1 = 0.353941 loss)
I1210 14:20:01.417084  4700 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1210 14:20:07.056571  4700 solver.cpp:218] Iteration 107100 (17.7331 iter/s, 5.63918s/100 iters), loss = 0.427092
I1210 14:20:07.057555  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:20:07.057555  4700 solver.cpp:237]     Train net output #1: loss = 0.427092 (* 1 = 0.427092 loss)
I1210 14:20:07.057555  4700 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1210 14:20:12.690703  4700 solver.cpp:218] Iteration 107200 (17.7519 iter/s, 5.63319s/100 iters), loss = 0.253824
I1210 14:20:12.691202  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 14:20:12.691202  4700 solver.cpp:237]     Train net output #1: loss = 0.253824 (* 1 = 0.253824 loss)
I1210 14:20:12.691202  4700 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1210 14:20:18.328205  4700 solver.cpp:218] Iteration 107300 (17.7397 iter/s, 5.63708s/100 iters), loss = 0.37135
I1210 14:20:18.328205  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:20:18.328205  4700 solver.cpp:237]     Train net output #1: loss = 0.37135 (* 1 = 0.37135 loss)
I1210 14:20:18.328205  4700 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1210 14:20:23.963727  4700 solver.cpp:218] Iteration 107400 (17.7458 iter/s, 5.63514s/100 iters), loss = 0.400768
I1210 14:20:23.963727  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:20:23.963727  4700 solver.cpp:237]     Train net output #1: loss = 0.400768 (* 1 = 0.400768 loss)
I1210 14:20:23.963727  4700 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1210 14:20:29.332268 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:20:29.553282  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107500.caffemodel
I1210 14:20:29.568282  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_107500.solverstate
I1210 14:20:29.574282  4700 solver.cpp:330] Iteration 107500, Testing net (#0)
I1210 14:20:29.574282  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:20:30.942386  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:20:30.996392  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6778
I1210 14:20:30.996392  4700 solver.cpp:397]     Test net output #1: loss = 1.22544 (* 1 = 1.22544 loss)
I1210 14:20:31.051407  4700 solver.cpp:218] Iteration 107500 (14.1111 iter/s, 7.08664s/100 iters), loss = 0.347447
I1210 14:20:31.051407  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:20:31.051407  4700 solver.cpp:237]     Train net output #1: loss = 0.347447 (* 1 = 0.347447 loss)
I1210 14:20:31.051407  4700 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1210 14:20:36.685328  4700 solver.cpp:218] Iteration 107600 (17.7512 iter/s, 5.63342s/100 iters), loss = 0.401153
I1210 14:20:36.685328  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:20:36.685328  4700 solver.cpp:237]     Train net output #1: loss = 0.401153 (* 1 = 0.401153 loss)
I1210 14:20:36.685328  4700 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1210 14:20:42.327344  4700 solver.cpp:218] Iteration 107700 (17.7254 iter/s, 5.64162s/100 iters), loss = 0.24915
I1210 14:20:42.327344  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:20:42.327344  4700 solver.cpp:237]     Train net output #1: loss = 0.24915 (* 1 = 0.24915 loss)
I1210 14:20:42.327344  4700 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1210 14:20:47.954777  4700 solver.cpp:218] Iteration 107800 (17.7719 iter/s, 5.62688s/100 iters), loss = 0.343067
I1210 14:20:47.954777  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:20:47.954777  4700 solver.cpp:237]     Train net output #1: loss = 0.343067 (* 1 = 0.343067 loss)
I1210 14:20:47.954777  4700 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1210 14:20:53.583180  4700 solver.cpp:218] Iteration 107900 (17.769 iter/s, 5.62779s/100 iters), loss = 0.402271
I1210 14:20:53.583180  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:20:53.583180  4700 solver.cpp:237]     Train net output #1: loss = 0.402271 (* 1 = 0.402271 loss)
I1210 14:20:53.583180  4700 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1210 14:20:58.944679 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:20:59.165693  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108000.caffemodel
I1210 14:20:59.181692  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108000.solverstate
I1210 14:20:59.186692  4700 solver.cpp:330] Iteration 108000, Testing net (#0)
I1210 14:20:59.186692  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:21:00.554797  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:21:00.608300  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6799
I1210 14:21:00.608800  4700 solver.cpp:397]     Test net output #1: loss = 1.22913 (* 1 = 1.22913 loss)
I1210 14:21:00.662803  4700 solver.cpp:218] Iteration 108000 (14.1249 iter/s, 7.0797s/100 iters), loss = 0.277354
I1210 14:21:00.662803  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:21:00.662803  4700 solver.cpp:237]     Train net output #1: loss = 0.277354 (* 1 = 0.277354 loss)
I1210 14:21:00.662803  4700 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1210 14:21:06.314251  4700 solver.cpp:218] Iteration 108100 (17.698 iter/s, 5.65034s/100 iters), loss = 0.410651
I1210 14:21:06.314251  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:21:06.314251  4700 solver.cpp:237]     Train net output #1: loss = 0.410651 (* 1 = 0.410651 loss)
I1210 14:21:06.314251  4700 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1210 14:21:11.962710  4700 solver.cpp:218] Iteration 108200 (17.7036 iter/s, 5.64858s/100 iters), loss = 0.268263
I1210 14:21:11.962710  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:21:11.962710  4700 solver.cpp:237]     Train net output #1: loss = 0.268263 (* 1 = 0.268263 loss)
I1210 14:21:11.962710  4700 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1210 14:21:17.622114  4700 solver.cpp:218] Iteration 108300 (17.6713 iter/s, 5.65889s/100 iters), loss = 0.491842
I1210 14:21:17.622114  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:21:17.622114  4700 solver.cpp:237]     Train net output #1: loss = 0.491842 (* 1 = 0.491842 loss)
I1210 14:21:17.622114  4700 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1210 14:21:23.268579  4700 solver.cpp:218] Iteration 108400 (17.7127 iter/s, 5.64568s/100 iters), loss = 0.463426
I1210 14:21:23.268579  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 14:21:23.268579  4700 solver.cpp:237]     Train net output #1: loss = 0.463426 (* 1 = 0.463426 loss)
I1210 14:21:23.268579  4700 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1210 14:21:28.641005 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:21:28.864018  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108500.caffemodel
I1210 14:21:28.878017  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_108500.solverstate
I1210 14:21:28.883018  4700 solver.cpp:330] Iteration 108500, Testing net (#0)
I1210 14:21:28.883018  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:21:30.252161  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:21:30.306164  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6813
I1210 14:21:30.306164  4700 solver.cpp:397]     Test net output #1: loss = 1.23597 (* 1 = 1.23597 loss)
I1210 14:21:30.360172  4700 solver.cpp:218] Iteration 108500 (14.1012 iter/s, 7.09161s/100 iters), loss = 0.359714
I1210 14:21:30.360172  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:21:30.360172  4700 solver.cpp:237]     Train net output #1: loss = 0.359714 (* 1 = 0.359714 loss)
I1210 14:21:30.360172  4700 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1210 14:21:36.026613  4700 solver.cpp:218] Iteration 108600 (17.6503 iter/s, 5.66562s/100 iters), loss = 0.373297
I1210 14:21:36.026613  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:21:36.026613  4700 solver.cpp:237]     Train net output #1: loss = 0.373297 (* 1 = 0.373297 loss)
I1210 14:21:36.026613  4700 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1210 14:21:41.692000  4700 solver.cpp:218] Iteration 108700 (17.6511 iter/s, 5.66538s/100 iters), loss = 0.285124
I1210 14:21:41.693001  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:21:41.693001  4700 solver.cpp:237]     Train net output #1: loss = 0.285124 (* 1 = 0.285124 loss)
I1210 14:21:41.693001  4700 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1210 14:21:47.350426  4700 solver.cpp:218] Iteration 108800 (17.6744 iter/s, 5.65792s/100 iters), loss = 0.377413
I1210 14:21:47.350426  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:21:47.350426  4700 solver.cpp:237]     Train net output #1: loss = 0.377413 (* 1 = 0.377413 loss)
I1210 14:21:47.351428  4700 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1210 14:21:53.019870  4700 solver.cpp:218] Iteration 108900 (17.6423 iter/s, 5.6682s/100 iters), loss = 0.511154
I1210 14:21:53.019870  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:21:53.019870  4700 solver.cpp:237]     Train net output #1: loss = 0.511154 (* 1 = 0.511154 loss)
I1210 14:21:53.019870  4700 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1210 14:21:58.400308 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:21:58.622321  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109000.caffemodel
I1210 14:21:58.637321  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109000.solverstate
I1210 14:21:58.642321  4700 solver.cpp:330] Iteration 109000, Testing net (#0)
I1210 14:21:58.642321  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:22:00.011463  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:22:00.066473  4700 solver.cpp:397]     Test net output #0: accuracy = 0.678
I1210 14:22:00.066473  4700 solver.cpp:397]     Test net output #1: loss = 1.22981 (* 1 = 1.22981 loss)
I1210 14:22:00.120472  4700 solver.cpp:218] Iteration 109000 (14.0837 iter/s, 7.1004s/100 iters), loss = 0.257068
I1210 14:22:00.120472  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:22:00.120472  4700 solver.cpp:237]     Train net output #1: loss = 0.257068 (* 1 = 0.257068 loss)
I1210 14:22:00.120472  4700 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1210 14:22:05.763967  4700 solver.cpp:218] Iteration 109100 (17.7209 iter/s, 5.64306s/100 iters), loss = 0.386445
I1210 14:22:05.763967  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:22:05.763967  4700 solver.cpp:237]     Train net output #1: loss = 0.386445 (* 1 = 0.386445 loss)
I1210 14:22:05.763967  4700 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1210 14:22:11.411962  4700 solver.cpp:218] Iteration 109200 (17.708 iter/s, 5.64715s/100 iters), loss = 0.237458
I1210 14:22:11.411962  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:22:11.411962  4700 solver.cpp:237]     Train net output #1: loss = 0.237458 (* 1 = 0.237458 loss)
I1210 14:22:11.411962  4700 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1210 14:22:17.058908  4700 solver.cpp:218] Iteration 109300 (17.7093 iter/s, 5.64676s/100 iters), loss = 0.375755
I1210 14:22:17.058908  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:22:17.058908  4700 solver.cpp:237]     Train net output #1: loss = 0.375755 (* 1 = 0.375755 loss)
I1210 14:22:17.058908  4700 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1210 14:22:22.703362  4700 solver.cpp:218] Iteration 109400 (17.7186 iter/s, 5.64378s/100 iters), loss = 0.474347
I1210 14:22:22.703362  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 14:22:22.703362  4700 solver.cpp:237]     Train net output #1: loss = 0.474347 (* 1 = 0.474347 loss)
I1210 14:22:22.703362  4700 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1210 14:22:28.068802 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:22:28.290822  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109500.caffemodel
I1210 14:22:28.304826  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_109500.solverstate
I1210 14:22:28.309828  4700 solver.cpp:330] Iteration 109500, Testing net (#0)
I1210 14:22:28.309828  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:22:29.677922  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:22:29.732929  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6814
I1210 14:22:29.732929  4700 solver.cpp:397]     Test net output #1: loss = 1.23997 (* 1 = 1.23997 loss)
I1210 14:22:29.786927  4700 solver.cpp:218] Iteration 109500 (14.1173 iter/s, 7.08351s/100 iters), loss = 0.321873
I1210 14:22:29.786927  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:22:29.786927  4700 solver.cpp:237]     Train net output #1: loss = 0.321873 (* 1 = 0.321873 loss)
I1210 14:22:29.786927  4700 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1210 14:22:35.429339  4700 solver.cpp:218] Iteration 109600 (17.7246 iter/s, 5.64188s/100 iters), loss = 0.40197
I1210 14:22:35.429339  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:22:35.429339  4700 solver.cpp:237]     Train net output #1: loss = 0.40197 (* 1 = 0.40197 loss)
I1210 14:22:35.429339  4700 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1210 14:22:41.073724  4700 solver.cpp:218] Iteration 109700 (17.7185 iter/s, 5.64382s/100 iters), loss = 0.256632
I1210 14:22:41.073724  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:22:41.073724  4700 solver.cpp:237]     Train net output #1: loss = 0.256632 (* 1 = 0.256632 loss)
I1210 14:22:41.073724  4700 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1210 14:22:46.720158  4700 solver.cpp:218] Iteration 109800 (17.7132 iter/s, 5.64551s/100 iters), loss = 0.412035
I1210 14:22:46.720158  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:22:46.720158  4700 solver.cpp:237]     Train net output #1: loss = 0.412035 (* 1 = 0.412035 loss)
I1210 14:22:46.720158  4700 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1210 14:22:52.366565  4700 solver.cpp:218] Iteration 109900 (17.7114 iter/s, 5.64608s/100 iters), loss = 0.388823
I1210 14:22:52.366565  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:22:52.366565  4700 solver.cpp:237]     Train net output #1: loss = 0.388823 (* 1 = 0.388823 loss)
I1210 14:22:52.366565  4700 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1210 14:22:57.733937 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:22:57.954954  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110000.caffemodel
I1210 14:22:57.969954  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110000.solverstate
I1210 14:22:57.974954  4700 solver.cpp:330] Iteration 110000, Testing net (#0)
I1210 14:22:57.974954  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:22:59.343137  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:22:59.398138  4700 solver.cpp:397]     Test net output #0: accuracy = 0.679
I1210 14:22:59.398138  4700 solver.cpp:397]     Test net output #1: loss = 1.23506 (* 1 = 1.23506 loss)
I1210 14:22:59.452157  4700 solver.cpp:218] Iteration 110000 (14.1132 iter/s, 7.08558s/100 iters), loss = 0.315163
I1210 14:22:59.452157  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:22:59.452157  4700 solver.cpp:237]     Train net output #1: loss = 0.315163 (* 1 = 0.315163 loss)
I1210 14:22:59.452157  4700 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1210 14:23:05.107065  4700 solver.cpp:218] Iteration 110100 (17.6869 iter/s, 5.65389s/100 iters), loss = 0.388445
I1210 14:23:05.107065  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:23:05.107065  4700 solver.cpp:237]     Train net output #1: loss = 0.388445 (* 1 = 0.388445 loss)
I1210 14:23:05.107065  4700 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1210 14:23:10.763988  4700 solver.cpp:218] Iteration 110200 (17.6802 iter/s, 5.65605s/100 iters), loss = 0.252098
I1210 14:23:10.763988  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:23:10.763988  4700 solver.cpp:237]     Train net output #1: loss = 0.252098 (* 1 = 0.252098 loss)
I1210 14:23:10.763988  4700 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1210 14:23:16.416965  4700 solver.cpp:218] Iteration 110300 (17.6911 iter/s, 5.65255s/100 iters), loss = 0.335162
I1210 14:23:16.416965  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:23:16.416965  4700 solver.cpp:237]     Train net output #1: loss = 0.335162 (* 1 = 0.335162 loss)
I1210 14:23:16.416965  4700 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1210 14:23:22.078873  4700 solver.cpp:218] Iteration 110400 (17.6621 iter/s, 5.66185s/100 iters), loss = 0.459393
I1210 14:23:22.078873  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:23:22.078873  4700 solver.cpp:237]     Train net output #1: loss = 0.459393 (* 1 = 0.459393 loss)
I1210 14:23:22.078873  4700 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1210 14:23:27.456336 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:23:27.679347  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110500.caffemodel
I1210 14:23:27.694346  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_110500.solverstate
I1210 14:23:27.699347  4700 solver.cpp:330] Iteration 110500, Testing net (#0)
I1210 14:23:27.699347  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:23:29.068454  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:23:29.121457  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6754
I1210 14:23:29.121457  4700 solver.cpp:397]     Test net output #1: loss = 1.25638 (* 1 = 1.25638 loss)
I1210 14:23:29.175457  4700 solver.cpp:218] Iteration 110500 (14.0925 iter/s, 7.09597s/100 iters), loss = 0.288845
I1210 14:23:29.175457  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:23:29.175457  4700 solver.cpp:237]     Train net output #1: loss = 0.288845 (* 1 = 0.288845 loss)
I1210 14:23:29.175457  4700 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1210 14:23:34.811935  4700 solver.cpp:218] Iteration 110600 (17.7424 iter/s, 5.63621s/100 iters), loss = 0.408386
I1210 14:23:34.812429  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:23:34.812429  4700 solver.cpp:237]     Train net output #1: loss = 0.408386 (* 1 = 0.408386 loss)
I1210 14:23:34.812429  4700 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1210 14:23:40.453400  4700 solver.cpp:218] Iteration 110700 (17.7279 iter/s, 5.64084s/100 iters), loss = 0.209492
I1210 14:23:40.453400  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 14:23:40.453400  4700 solver.cpp:237]     Train net output #1: loss = 0.209492 (* 1 = 0.209492 loss)
I1210 14:23:40.453400  4700 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1210 14:23:46.089893  4700 solver.cpp:218] Iteration 110800 (17.7432 iter/s, 5.63595s/100 iters), loss = 0.380447
I1210 14:23:46.089893  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:23:46.089893  4700 solver.cpp:237]     Train net output #1: loss = 0.380447 (* 1 = 0.380447 loss)
I1210 14:23:46.089893  4700 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1210 14:23:51.717295  4700 solver.cpp:218] Iteration 110900 (17.7702 iter/s, 5.62739s/100 iters), loss = 0.455354
I1210 14:23:51.717295  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:23:51.717295  4700 solver.cpp:237]     Train net output #1: loss = 0.455354 (* 1 = 0.455354 loss)
I1210 14:23:51.717295  4700 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1210 14:23:57.073700 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:23:57.292711  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111000.caffemodel
I1210 14:23:57.306710  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111000.solverstate
I1210 14:23:57.311712  4700 solver.cpp:330] Iteration 111000, Testing net (#0)
I1210 14:23:57.311712  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:23:58.678840  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:23:58.732839  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6738
I1210 14:23:58.732839  4700 solver.cpp:397]     Test net output #1: loss = 1.25814 (* 1 = 1.25814 loss)
I1210 14:23:58.787848  4700 solver.cpp:218] Iteration 111000 (14.1456 iter/s, 7.06934s/100 iters), loss = 0.380513
I1210 14:23:58.787848  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:23:58.787848  4700 solver.cpp:237]     Train net output #1: loss = 0.380513 (* 1 = 0.380513 loss)
I1210 14:23:58.787848  4700 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1210 14:24:04.440246  4700 solver.cpp:218] Iteration 111100 (17.6902 iter/s, 5.65285s/100 iters), loss = 0.374322
I1210 14:24:04.441247  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:24:04.441247  4700 solver.cpp:237]     Train net output #1: loss = 0.374322 (* 1 = 0.374322 loss)
I1210 14:24:04.441247  4700 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1210 14:24:10.080704  4700 solver.cpp:218] Iteration 111200 (17.7325 iter/s, 5.63936s/100 iters), loss = 0.226118
I1210 14:24:10.080704  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:24:10.080704  4700 solver.cpp:237]     Train net output #1: loss = 0.226118 (* 1 = 0.226118 loss)
I1210 14:24:10.080704  4700 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1210 14:24:15.743113  4700 solver.cpp:218] Iteration 111300 (17.6625 iter/s, 5.66171s/100 iters), loss = 0.376997
I1210 14:24:15.743113  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:24:15.743113  4700 solver.cpp:237]     Train net output #1: loss = 0.376997 (* 1 = 0.376997 loss)
I1210 14:24:15.743113  4700 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1210 14:24:21.410058  4700 solver.cpp:218] Iteration 111400 (17.6486 iter/s, 5.66618s/100 iters), loss = 0.432489
I1210 14:24:21.410058  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:24:21.410058  4700 solver.cpp:237]     Train net output #1: loss = 0.432489 (* 1 = 0.432489 loss)
I1210 14:24:21.410058  4700 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1210 14:24:26.785950 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:24:27.007467  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111500.caffemodel
I1210 14:24:27.023979  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_111500.solverstate
I1210 14:24:27.028972  4700 solver.cpp:330] Iteration 111500, Testing net (#0)
I1210 14:24:27.028972  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:24:28.399117  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:24:28.454136  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6763
I1210 14:24:28.454136  4700 solver.cpp:397]     Test net output #1: loss = 1.25016 (* 1 = 1.25016 loss)
I1210 14:24:28.507643  4700 solver.cpp:218] Iteration 111500 (14.0904 iter/s, 7.09704s/100 iters), loss = 0.291646
I1210 14:24:28.507643  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:24:28.507643  4700 solver.cpp:237]     Train net output #1: loss = 0.291646 (* 1 = 0.291646 loss)
I1210 14:24:28.507643  4700 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1210 14:24:34.163539  4700 solver.cpp:218] Iteration 111600 (17.6815 iter/s, 5.65562s/100 iters), loss = 0.305882
I1210 14:24:34.163539  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:24:34.163539  4700 solver.cpp:237]     Train net output #1: loss = 0.305882 (* 1 = 0.305882 loss)
I1210 14:24:34.163539  4700 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1210 14:24:39.812723  4700 solver.cpp:218] Iteration 111700 (17.7025 iter/s, 5.64891s/100 iters), loss = 0.201227
I1210 14:24:39.812723  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 14:24:39.812723  4700 solver.cpp:237]     Train net output #1: loss = 0.201227 (* 1 = 0.201227 loss)
I1210 14:24:39.812723  4700 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1210 14:24:45.455307  4700 solver.cpp:218] Iteration 111800 (17.7229 iter/s, 5.64241s/100 iters), loss = 0.372953
I1210 14:24:45.455307  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:24:45.455307  4700 solver.cpp:237]     Train net output #1: loss = 0.372953 (* 1 = 0.372953 loss)
I1210 14:24:45.455307  4700 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1210 14:24:51.095738  4700 solver.cpp:218] Iteration 111900 (17.732 iter/s, 5.63953s/100 iters), loss = 0.344338
I1210 14:24:51.095738  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:24:51.095738  4700 solver.cpp:237]     Train net output #1: loss = 0.344337 (* 1 = 0.344337 loss)
I1210 14:24:51.095738  4700 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1210 14:24:56.459575 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:24:56.682587  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112000.caffemodel
I1210 14:24:56.697587  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112000.solverstate
I1210 14:24:56.702587  4700 solver.cpp:330] Iteration 112000, Testing net (#0)
I1210 14:24:56.702587  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:24:58.073704  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:24:58.127195  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6734
I1210 14:24:58.127696  4700 solver.cpp:397]     Test net output #1: loss = 1.25355 (* 1 = 1.25355 loss)
I1210 14:24:58.180698  4700 solver.cpp:218] Iteration 112000 (14.1146 iter/s, 7.08489s/100 iters), loss = 0.247106
I1210 14:24:58.180698  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:24:58.180698  4700 solver.cpp:237]     Train net output #1: loss = 0.247106 (* 1 = 0.247106 loss)
I1210 14:24:58.180698  4700 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1210 14:25:03.822965  4700 solver.cpp:218] Iteration 112100 (17.7258 iter/s, 5.64151s/100 iters), loss = 0.32333
I1210 14:25:03.822965  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:25:03.822965  4700 solver.cpp:237]     Train net output #1: loss = 0.32333 (* 1 = 0.32333 loss)
I1210 14:25:03.822965  4700 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1210 14:25:09.470904  4700 solver.cpp:218] Iteration 112200 (17.7048 iter/s, 5.64818s/100 iters), loss = 0.229299
I1210 14:25:09.470904  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:25:09.470904  4700 solver.cpp:237]     Train net output #1: loss = 0.229298 (* 1 = 0.229298 loss)
I1210 14:25:09.470904  4700 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1210 14:25:15.122340  4700 solver.cpp:218] Iteration 112300 (17.6976 iter/s, 5.65047s/100 iters), loss = 0.247388
I1210 14:25:15.122853  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:25:15.122853  4700 solver.cpp:237]     Train net output #1: loss = 0.247388 (* 1 = 0.247388 loss)
I1210 14:25:15.122853  4700 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1210 14:25:20.769212  4700 solver.cpp:218] Iteration 112400 (17.7117 iter/s, 5.64599s/100 iters), loss = 0.417983
I1210 14:25:20.769212  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:25:20.769212  4700 solver.cpp:237]     Train net output #1: loss = 0.417983 (* 1 = 0.417983 loss)
I1210 14:25:20.769212  4700 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1210 14:25:26.140142 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:25:26.362162  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112500.caffemodel
I1210 14:25:26.377167  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_112500.solverstate
I1210 14:25:26.382167  4700 solver.cpp:330] Iteration 112500, Testing net (#0)
I1210 14:25:26.382167  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:25:27.750322  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:25:27.804327  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6741
I1210 14:25:27.804327  4700 solver.cpp:397]     Test net output #1: loss = 1.25851 (* 1 = 1.25851 loss)
I1210 14:25:27.857858  4700 solver.cpp:218] Iteration 112500 (14.1079 iter/s, 7.08823s/100 iters), loss = 0.363605
I1210 14:25:27.857858  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:25:27.857858  4700 solver.cpp:237]     Train net output #1: loss = 0.363605 (* 1 = 0.363605 loss)
I1210 14:25:27.857858  4700 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1210 14:25:33.499805  4700 solver.cpp:218] Iteration 112600 (17.7251 iter/s, 5.64171s/100 iters), loss = 0.367673
I1210 14:25:33.499805  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:25:33.499805  4700 solver.cpp:237]     Train net output #1: loss = 0.367673 (* 1 = 0.367673 loss)
I1210 14:25:33.499805  4700 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1210 14:25:39.140245  4700 solver.cpp:218] Iteration 112700 (17.7312 iter/s, 5.63977s/100 iters), loss = 0.336137
I1210 14:25:39.140245  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:25:39.140245  4700 solver.cpp:237]     Train net output #1: loss = 0.336137 (* 1 = 0.336137 loss)
I1210 14:25:39.140245  4700 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1210 14:25:44.775034  4700 solver.cpp:218] Iteration 112800 (17.748 iter/s, 5.63443s/100 iters), loss = 0.326129
I1210 14:25:44.775034  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:25:44.775034  4700 solver.cpp:237]     Train net output #1: loss = 0.326129 (* 1 = 0.326129 loss)
I1210 14:25:44.775034  4700 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1210 14:25:50.414345  4700 solver.cpp:218] Iteration 112900 (17.7322 iter/s, 5.63944s/100 iters), loss = 0.423785
I1210 14:25:50.414345  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:25:50.414345  4700 solver.cpp:237]     Train net output #1: loss = 0.423785 (* 1 = 0.423785 loss)
I1210 14:25:50.414345  4700 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1210 14:25:55.777042 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:25:55.999588  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_113000.caffemodel
I1210 14:25:56.014588  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_113000.solverstate
I1210 14:25:56.020591  4700 solver.cpp:330] Iteration 113000, Testing net (#0)
I1210 14:25:56.020591  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:25:57.387039  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:25:57.441038  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6757
I1210 14:25:57.441038  4700 solver.cpp:397]     Test net output #1: loss = 1.25877 (* 1 = 1.25877 loss)
I1210 14:25:57.494570  4700 solver.cpp:218] Iteration 113000 (14.1244 iter/s, 7.07995s/100 iters), loss = 0.221374
I1210 14:25:57.495560  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 14:25:57.495560  4700 solver.cpp:237]     Train net output #1: loss = 0.221374 (* 1 = 0.221374 loss)
I1210 14:25:57.495560  4700 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1210 14:26:03.141742  4700 solver.cpp:218] Iteration 113100 (17.7119 iter/s, 5.64591s/100 iters), loss = 0.336337
I1210 14:26:03.141742  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:26:03.141742  4700 solver.cpp:237]     Train net output #1: loss = 0.336337 (* 1 = 0.336337 loss)
I1210 14:26:03.141742  4700 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1210 14:26:08.788163  4700 solver.cpp:218] Iteration 113200 (17.71 iter/s, 5.64654s/100 iters), loss = 0.237029
I1210 14:26:08.788163  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:26:08.788163  4700 solver.cpp:237]     Train net output #1: loss = 0.237029 (* 1 = 0.237029 loss)
I1210 14:26:08.788163  4700 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1210 14:26:14.447599  4700 solver.cpp:218] Iteration 113300 (17.6725 iter/s, 5.65852s/100 iters), loss = 0.366702
I1210 14:26:14.447599  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:26:14.447599  4700 solver.cpp:237]     Train net output #1: loss = 0.366702 (* 1 = 0.366702 loss)
I1210 14:26:14.447599  4700 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1210 14:26:20.091701  4700 solver.cpp:218] Iteration 113400 (17.719 iter/s, 5.64366s/100 iters), loss = 0.409221
I1210 14:26:20.091701  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:26:20.091701  4700 solver.cpp:237]     Train net output #1: loss = 0.409221 (* 1 = 0.409221 loss)
I1210 14:26:20.091701  4700 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1210 14:26:25.457104 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:26:25.680889  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_113500.caffemodel
I1210 14:26:25.695436  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_113500.solverstate
I1210 14:26:25.700435  4700 solver.cpp:330] Iteration 113500, Testing net (#0)
I1210 14:26:25.700435  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:26:27.068102  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:26:27.121289  4700 solver.cpp:397]     Test net output #0: accuracy = 0.675
I1210 14:26:27.121289  4700 solver.cpp:397]     Test net output #1: loss = 1.26474 (* 1 = 1.26474 loss)
I1210 14:26:27.175297  4700 solver.cpp:218] Iteration 113500 (14.1183 iter/s, 7.08302s/100 iters), loss = 0.32544
I1210 14:26:27.175297  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:26:27.175297  4700 solver.cpp:237]     Train net output #1: loss = 0.32544 (* 1 = 0.32544 loss)
I1210 14:26:27.175297  4700 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1210 14:26:32.835420  4700 solver.cpp:218] Iteration 113600 (17.6681 iter/s, 5.6599s/100 iters), loss = 0.304937
I1210 14:26:32.835420  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:26:32.835420  4700 solver.cpp:237]     Train net output #1: loss = 0.304937 (* 1 = 0.304937 loss)
I1210 14:26:32.835420  4700 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1210 14:26:38.500466  4700 solver.cpp:218] Iteration 113700 (17.652 iter/s, 5.66509s/100 iters), loss = 0.265113
I1210 14:26:38.500466  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:26:38.500466  4700 solver.cpp:237]     Train net output #1: loss = 0.265113 (* 1 = 0.265113 loss)
I1210 14:26:38.500466  4700 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1210 14:26:44.163875  4700 solver.cpp:218] Iteration 113800 (17.6602 iter/s, 5.66245s/100 iters), loss = 0.347702
I1210 14:26:44.163875  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:26:44.163875  4700 solver.cpp:237]     Train net output #1: loss = 0.347702 (* 1 = 0.347702 loss)
I1210 14:26:44.163875  4700 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1210 14:26:49.838346  4700 solver.cpp:218] Iteration 113900 (17.6245 iter/s, 5.67391s/100 iters), loss = 0.400448
I1210 14:26:49.838346  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:26:49.838346  4700 solver.cpp:237]     Train net output #1: loss = 0.400448 (* 1 = 0.400448 loss)
I1210 14:26:49.838346  4700 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1210 14:26:55.228739 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:26:55.451762  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_114000.caffemodel
I1210 14:26:55.466761  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_114000.solverstate
I1210 14:26:55.470762  4700 solver.cpp:330] Iteration 114000, Testing net (#0)
I1210 14:26:55.470762  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:26:56.836953  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:26:56.890456  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6795
I1210 14:26:56.890456  4700 solver.cpp:397]     Test net output #1: loss = 1.242 (* 1 = 1.242 loss)
I1210 14:26:56.943956  4700 solver.cpp:218] Iteration 114000 (14.0736 iter/s, 7.10549s/100 iters), loss = 0.268211
I1210 14:26:56.943956  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:26:56.943956  4700 solver.cpp:237]     Train net output #1: loss = 0.268211 (* 1 = 0.268211 loss)
I1210 14:26:56.943956  4700 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1210 14:27:02.587851  4700 solver.cpp:218] Iteration 114100 (17.7208 iter/s, 5.64308s/100 iters), loss = 0.325103
I1210 14:27:02.587851  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:27:02.587851  4700 solver.cpp:237]     Train net output #1: loss = 0.325103 (* 1 = 0.325103 loss)
I1210 14:27:02.587851  4700 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1210 14:27:08.237789  4700 solver.cpp:218] Iteration 114200 (17.7007 iter/s, 5.64951s/100 iters), loss = 0.270759
I1210 14:27:08.237789  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:27:08.237789  4700 solver.cpp:237]     Train net output #1: loss = 0.270759 (* 1 = 0.270759 loss)
I1210 14:27:08.237789  4700 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1210 14:27:13.883146  4700 solver.cpp:218] Iteration 114300 (17.7146 iter/s, 5.64505s/100 iters), loss = 0.387524
I1210 14:27:13.883146  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:27:13.883146  4700 solver.cpp:237]     Train net output #1: loss = 0.387524 (* 1 = 0.387524 loss)
I1210 14:27:13.883146  4700 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1210 14:27:19.526599  4700 solver.cpp:218] Iteration 114400 (17.7199 iter/s, 5.64336s/100 iters), loss = 0.398261
I1210 14:27:19.526599  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:27:19.526599  4700 solver.cpp:237]     Train net output #1: loss = 0.398261 (* 1 = 0.398261 loss)
I1210 14:27:19.526599  4700 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1210 14:27:24.899919 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:27:25.122944  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_114500.caffemodel
I1210 14:27:25.137943  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_114500.solverstate
I1210 14:27:25.142944  4700 solver.cpp:330] Iteration 114500, Testing net (#0)
I1210 14:27:25.142944  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:27:26.511085  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:27:26.564083  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6765
I1210 14:27:26.564083  4700 solver.cpp:397]     Test net output #1: loss = 1.26409 (* 1 = 1.26409 loss)
I1210 14:27:26.618089  4700 solver.cpp:218] Iteration 114500 (14.1019 iter/s, 7.09122s/100 iters), loss = 0.298494
I1210 14:27:26.619091  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:27:26.619091  4700 solver.cpp:237]     Train net output #1: loss = 0.298494 (* 1 = 0.298494 loss)
I1210 14:27:26.619091  4700 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1210 14:27:32.270592  4700 solver.cpp:218] Iteration 114600 (17.6934 iter/s, 5.65182s/100 iters), loss = 0.4326
I1210 14:27:32.270592  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:27:32.270592  4700 solver.cpp:237]     Train net output #1: loss = 0.4326 (* 1 = 0.4326 loss)
I1210 14:27:32.270592  4700 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1210 14:27:37.918066  4700 solver.cpp:218] Iteration 114700 (17.7092 iter/s, 5.64679s/100 iters), loss = 0.226873
I1210 14:27:37.918066  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:27:37.918066  4700 solver.cpp:237]     Train net output #1: loss = 0.226873 (* 1 = 0.226873 loss)
I1210 14:27:37.918066  4700 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1210 14:27:43.567518  4700 solver.cpp:218] Iteration 114800 (17.7013 iter/s, 5.6493s/100 iters), loss = 0.290274
I1210 14:27:43.567518  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:27:43.567518  4700 solver.cpp:237]     Train net output #1: loss = 0.290274 (* 1 = 0.290274 loss)
I1210 14:27:43.567518  4700 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1210 14:27:49.217913  4700 solver.cpp:218] Iteration 114900 (17.6999 iter/s, 5.64976s/100 iters), loss = 0.360351
I1210 14:27:49.217913  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:27:49.217913  4700 solver.cpp:237]     Train net output #1: loss = 0.360351 (* 1 = 0.360351 loss)
I1210 14:27:49.217913  4700 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1210 14:27:54.585290 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:27:54.809306  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_115000.caffemodel
I1210 14:27:54.828307  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_115000.solverstate
I1210 14:27:54.833308  4700 solver.cpp:330] Iteration 115000, Testing net (#0)
I1210 14:27:54.833308  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:27:56.200435  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:27:56.254459  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6755
I1210 14:27:56.254459  4700 solver.cpp:397]     Test net output #1: loss = 1.26104 (* 1 = 1.26104 loss)
I1210 14:27:56.309458  4700 solver.cpp:218] Iteration 115000 (14.1019 iter/s, 7.09122s/100 iters), loss = 0.299922
I1210 14:27:56.309458  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:27:56.309458  4700 solver.cpp:237]     Train net output #1: loss = 0.299922 (* 1 = 0.299922 loss)
I1210 14:27:56.309458  4700 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1210 14:28:01.963871  4700 solver.cpp:218] Iteration 115100 (17.6889 iter/s, 5.65326s/100 iters), loss = 0.3349
I1210 14:28:01.963871  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:28:01.963871  4700 solver.cpp:237]     Train net output #1: loss = 0.3349 (* 1 = 0.3349 loss)
I1210 14:28:01.963871  4700 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1210 14:28:07.614342  4700 solver.cpp:218] Iteration 115200 (17.6964 iter/s, 5.65088s/100 iters), loss = 0.230067
I1210 14:28:07.614342  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:28:07.614342  4700 solver.cpp:237]     Train net output #1: loss = 0.230067 (* 1 = 0.230067 loss)
I1210 14:28:07.614342  4700 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1210 14:28:13.266741  4700 solver.cpp:218] Iteration 115300 (17.6955 iter/s, 5.65116s/100 iters), loss = 0.323395
I1210 14:28:13.266741  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:28:13.266741  4700 solver.cpp:237]     Train net output #1: loss = 0.323395 (* 1 = 0.323395 loss)
I1210 14:28:13.266741  4700 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1210 14:28:18.914139  4700 solver.cpp:218] Iteration 115400 (17.7086 iter/s, 5.64699s/100 iters), loss = 0.33552
I1210 14:28:18.914139  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:28:18.914139  4700 solver.cpp:237]     Train net output #1: loss = 0.33552 (* 1 = 0.33552 loss)
I1210 14:28:18.914139  4700 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1210 14:28:24.289589 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:28:24.513605  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_115500.caffemodel
I1210 14:28:24.528606  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_115500.solverstate
I1210 14:28:24.533607  4700 solver.cpp:330] Iteration 115500, Testing net (#0)
I1210 14:28:24.533607  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:28:25.901728  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:28:25.955731  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6745
I1210 14:28:25.955731  4700 solver.cpp:397]     Test net output #1: loss = 1.27948 (* 1 = 1.27948 loss)
I1210 14:28:26.010733  4700 solver.cpp:218] Iteration 115500 (14.0916 iter/s, 7.09645s/100 iters), loss = 0.349565
I1210 14:28:26.010733  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:28:26.010733  4700 solver.cpp:237]     Train net output #1: loss = 0.349565 (* 1 = 0.349565 loss)
I1210 14:28:26.010733  4700 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1210 14:28:31.653172  4700 solver.cpp:218] Iteration 115600 (17.7256 iter/s, 5.64155s/100 iters), loss = 0.290314
I1210 14:28:31.653172  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:28:31.653172  4700 solver.cpp:237]     Train net output #1: loss = 0.290314 (* 1 = 0.290314 loss)
I1210 14:28:31.653172  4700 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1210 14:28:37.297624  4700 solver.cpp:218] Iteration 115700 (17.7167 iter/s, 5.6444s/100 iters), loss = 0.248591
I1210 14:28:37.297624  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:28:37.298125  4700 solver.cpp:237]     Train net output #1: loss = 0.248591 (* 1 = 0.248591 loss)
I1210 14:28:37.298125  4700 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1210 14:28:42.935088  4700 solver.cpp:218] Iteration 115800 (17.7388 iter/s, 5.63734s/100 iters), loss = 0.291364
I1210 14:28:42.935088  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:28:42.935088  4700 solver.cpp:237]     Train net output #1: loss = 0.291364 (* 1 = 0.291364 loss)
I1210 14:28:42.935088  4700 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1210 14:28:48.588582  4700 solver.cpp:218] Iteration 115900 (17.6913 iter/s, 5.65249s/100 iters), loss = 0.399007
I1210 14:28:48.588582  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:28:48.588582  4700 solver.cpp:237]     Train net output #1: loss = 0.399007 (* 1 = 0.399007 loss)
I1210 14:28:48.588582  4700 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1210 14:28:53.951984 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:28:54.174996  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_116000.caffemodel
I1210 14:28:54.189996  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_116000.solverstate
I1210 14:28:54.195509  4700 solver.cpp:330] Iteration 116000, Testing net (#0)
I1210 14:28:54.195509  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:28:55.562152  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:28:55.615154  4700 solver.cpp:397]     Test net output #0: accuracy = 0.677
I1210 14:28:55.616156  4700 solver.cpp:397]     Test net output #1: loss = 1.2597 (* 1 = 1.2597 loss)
I1210 14:28:55.671154  4700 solver.cpp:218] Iteration 116000 (14.1198 iter/s, 7.08225s/100 iters), loss = 0.26313
I1210 14:28:55.671154  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:28:55.671154  4700 solver.cpp:237]     Train net output #1: loss = 0.26313 (* 1 = 0.26313 loss)
I1210 14:28:55.671154  4700 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1210 14:29:01.327618  4700 solver.cpp:218] Iteration 116100 (17.6787 iter/s, 5.65652s/100 iters), loss = 0.402567
I1210 14:29:01.328616  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:29:01.328616  4700 solver.cpp:237]     Train net output #1: loss = 0.402567 (* 1 = 0.402567 loss)
I1210 14:29:01.328616  4700 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1210 14:29:06.983001  4700 solver.cpp:218] Iteration 116200 (17.6854 iter/s, 5.65439s/100 iters), loss = 0.226047
I1210 14:29:06.983001  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:29:06.983001  4700 solver.cpp:237]     Train net output #1: loss = 0.226047 (* 1 = 0.226047 loss)
I1210 14:29:06.983001  4700 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1210 14:29:12.626791  4700 solver.cpp:218] Iteration 116300 (17.7199 iter/s, 5.64339s/100 iters), loss = 0.355945
I1210 14:29:12.626791  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:29:12.626791  4700 solver.cpp:237]     Train net output #1: loss = 0.355945 (* 1 = 0.355945 loss)
I1210 14:29:12.626791  4700 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1210 14:29:18.286180  4700 solver.cpp:218] Iteration 116400 (17.6717 iter/s, 5.65877s/100 iters), loss = 0.441968
I1210 14:29:18.286180  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:29:18.286180  4700 solver.cpp:237]     Train net output #1: loss = 0.441968 (* 1 = 0.441968 loss)
I1210 14:29:18.286180  4700 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1210 14:29:23.667572 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:29:23.891582  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_116500.caffemodel
I1210 14:29:23.906086  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_116500.solverstate
I1210 14:29:23.910586  4700 solver.cpp:330] Iteration 116500, Testing net (#0)
I1210 14:29:23.910586  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:29:25.280673  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:29:25.335681  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6764
I1210 14:29:25.335681  4700 solver.cpp:397]     Test net output #1: loss = 1.25617 (* 1 = 1.25617 loss)
I1210 14:29:25.389696  4700 solver.cpp:218] Iteration 116500 (14.0789 iter/s, 7.10283s/100 iters), loss = 0.229419
I1210 14:29:25.389696  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:29:25.389696  4700 solver.cpp:237]     Train net output #1: loss = 0.229419 (* 1 = 0.229419 loss)
I1210 14:29:25.389696  4700 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1210 14:29:31.040235  4700 solver.cpp:218] Iteration 116600 (17.6966 iter/s, 5.65082s/100 iters), loss = 0.354688
I1210 14:29:31.040235  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:29:31.040235  4700 solver.cpp:237]     Train net output #1: loss = 0.354688 (* 1 = 0.354688 loss)
I1210 14:29:31.040235  4700 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1210 14:29:36.697659  4700 solver.cpp:218] Iteration 116700 (17.6783 iter/s, 5.65664s/100 iters), loss = 0.269981
I1210 14:29:36.697659  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:29:36.697659  4700 solver.cpp:237]     Train net output #1: loss = 0.269981 (* 1 = 0.269981 loss)
I1210 14:29:36.697659  4700 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1210 14:29:42.350100  4700 solver.cpp:218] Iteration 116800 (17.6945 iter/s, 5.65146s/100 iters), loss = 0.365732
I1210 14:29:42.350100  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:29:42.350100  4700 solver.cpp:237]     Train net output #1: loss = 0.365732 (* 1 = 0.365732 loss)
I1210 14:29:42.350100  4700 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1210 14:29:48.008512  4700 solver.cpp:218] Iteration 116900 (17.6741 iter/s, 5.658s/100 iters), loss = 0.354107
I1210 14:29:48.008512  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:29:48.008512  4700 solver.cpp:237]     Train net output #1: loss = 0.354107 (* 1 = 0.354107 loss)
I1210 14:29:48.008512  4700 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1210 14:29:53.383968 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:29:53.604490  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_117000.caffemodel
I1210 14:29:53.618989  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_117000.solverstate
I1210 14:29:53.623994  4700 solver.cpp:330] Iteration 117000, Testing net (#0)
I1210 14:29:53.623994  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:29:54.992121  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:29:55.046135  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6752
I1210 14:29:55.046135  4700 solver.cpp:397]     Test net output #1: loss = 1.27731 (* 1 = 1.27731 loss)
I1210 14:29:55.100150  4700 solver.cpp:218] Iteration 117000 (14.1004 iter/s, 7.09199s/100 iters), loss = 0.305793
I1210 14:29:55.100150  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:29:55.100150  4700 solver.cpp:237]     Train net output #1: loss = 0.305793 (* 1 = 0.305793 loss)
I1210 14:29:55.100150  4700 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1210 14:30:00.762678  4700 solver.cpp:218] Iteration 117100 (17.6633 iter/s, 5.66144s/100 iters), loss = 0.312178
I1210 14:30:00.762678  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:30:00.762678  4700 solver.cpp:237]     Train net output #1: loss = 0.312178 (* 1 = 0.312178 loss)
I1210 14:30:00.762678  4700 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1210 14:30:06.419957  4700 solver.cpp:218] Iteration 117200 (17.6783 iter/s, 5.65665s/100 iters), loss = 0.270656
I1210 14:30:06.419957  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:30:06.419957  4700 solver.cpp:237]     Train net output #1: loss = 0.270656 (* 1 = 0.270656 loss)
I1210 14:30:06.419957  4700 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1210 14:30:12.060945  4700 solver.cpp:218] Iteration 117300 (17.7283 iter/s, 5.64068s/100 iters), loss = 0.406162
I1210 14:30:12.060945  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:30:12.060945  4700 solver.cpp:237]     Train net output #1: loss = 0.406162 (* 1 = 0.406162 loss)
I1210 14:30:12.060945  4700 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1210 14:30:17.706914  4700 solver.cpp:218] Iteration 117400 (17.7138 iter/s, 5.64532s/100 iters), loss = 0.348011
I1210 14:30:17.706914  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:30:17.706914  4700 solver.cpp:237]     Train net output #1: loss = 0.34801 (* 1 = 0.34801 loss)
I1210 14:30:17.706914  4700 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1210 14:30:23.075865 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:30:23.297885  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_117500.caffemodel
I1210 14:30:23.312387  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_117500.solverstate
I1210 14:30:23.317389  4700 solver.cpp:330] Iteration 117500, Testing net (#0)
I1210 14:30:23.317389  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:30:24.686998  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:30:24.740002  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6728
I1210 14:30:24.740002  4700 solver.cpp:397]     Test net output #1: loss = 1.27817 (* 1 = 1.27817 loss)
I1210 14:30:24.794003  4700 solver.cpp:218] Iteration 117500 (14.1099 iter/s, 7.08724s/100 iters), loss = 0.307878
I1210 14:30:24.795002  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:30:24.795002  4700 solver.cpp:237]     Train net output #1: loss = 0.307878 (* 1 = 0.307878 loss)
I1210 14:30:24.795002  4700 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1210 14:30:30.430470  4700 solver.cpp:218] Iteration 117600 (17.7436 iter/s, 5.63584s/100 iters), loss = 0.362412
I1210 14:30:30.430470  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:30:30.430470  4700 solver.cpp:237]     Train net output #1: loss = 0.362412 (* 1 = 0.362412 loss)
I1210 14:30:30.430470  4700 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1210 14:30:36.064890  4700 solver.cpp:218] Iteration 117700 (17.752 iter/s, 5.63317s/100 iters), loss = 0.210917
I1210 14:30:36.064890  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:30:36.064890  4700 solver.cpp:237]     Train net output #1: loss = 0.210917 (* 1 = 0.210917 loss)
I1210 14:30:36.064890  4700 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1210 14:30:41.696333  4700 solver.cpp:218] Iteration 117800 (17.7577 iter/s, 5.63137s/100 iters), loss = 0.364761
I1210 14:30:41.696333  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:30:41.696333  4700 solver.cpp:237]     Train net output #1: loss = 0.364761 (* 1 = 0.364761 loss)
I1210 14:30:41.696333  4700 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1210 14:30:47.333891  4700 solver.cpp:218] Iteration 117900 (17.7411 iter/s, 5.63662s/100 iters), loss = 0.423241
I1210 14:30:47.333891  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:30:47.333891  4700 solver.cpp:237]     Train net output #1: loss = 0.423241 (* 1 = 0.423241 loss)
I1210 14:30:47.333891  4700 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1210 14:30:52.690263 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:30:52.913777  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_118000.caffemodel
I1210 14:30:52.927279  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_118000.solverstate
I1210 14:30:52.932281  4700 solver.cpp:330] Iteration 118000, Testing net (#0)
I1210 14:30:52.933280  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:30:54.304369  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:30:54.357373  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6743
I1210 14:30:54.357373  4700 solver.cpp:397]     Test net output #1: loss = 1.28043 (* 1 = 1.28043 loss)
I1210 14:30:54.411375  4700 solver.cpp:218] Iteration 118000 (14.1296 iter/s, 7.07734s/100 iters), loss = 0.232194
I1210 14:30:54.411375  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:30:54.411375  4700 solver.cpp:237]     Train net output #1: loss = 0.232194 (* 1 = 0.232194 loss)
I1210 14:30:54.411375  4700 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1210 14:31:00.075834  4700 solver.cpp:218] Iteration 118100 (17.6542 iter/s, 5.66439s/100 iters), loss = 0.313709
I1210 14:31:00.075834  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:31:00.075834  4700 solver.cpp:237]     Train net output #1: loss = 0.313709 (* 1 = 0.313709 loss)
I1210 14:31:00.075834  4700 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1210 14:31:05.726300  4700 solver.cpp:218] Iteration 118200 (17.7016 iter/s, 5.6492s/100 iters), loss = 0.276812
I1210 14:31:05.726300  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:31:05.726300  4700 solver.cpp:237]     Train net output #1: loss = 0.276812 (* 1 = 0.276812 loss)
I1210 14:31:05.726300  4700 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1210 14:31:11.381687  4700 solver.cpp:218] Iteration 118300 (17.6822 iter/s, 5.65539s/100 iters), loss = 0.317038
I1210 14:31:11.381687  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:31:11.381687  4700 solver.cpp:237]     Train net output #1: loss = 0.317038 (* 1 = 0.317038 loss)
I1210 14:31:11.381687  4700 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1210 14:31:17.037170  4700 solver.cpp:218] Iteration 118400 (17.6824 iter/s, 5.65534s/100 iters), loss = 0.366197
I1210 14:31:17.037170  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:31:17.037170  4700 solver.cpp:237]     Train net output #1: loss = 0.366197 (* 1 = 0.366197 loss)
I1210 14:31:17.037170  4700 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1210 14:31:22.412598 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:31:22.634613  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_118500.caffemodel
I1210 14:31:22.648613  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_118500.solverstate
I1210 14:31:22.653614  4700 solver.cpp:330] Iteration 118500, Testing net (#0)
I1210 14:31:22.653614  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:31:24.024430  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:31:24.076931  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6737
I1210 14:31:24.076931  4700 solver.cpp:397]     Test net output #1: loss = 1.28718 (* 1 = 1.28718 loss)
I1210 14:31:24.130937  4700 solver.cpp:218] Iteration 118500 (14.0988 iter/s, 7.0928s/100 iters), loss = 0.28212
I1210 14:31:24.130937  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:31:24.130937  4700 solver.cpp:237]     Train net output #1: loss = 0.28212 (* 1 = 0.28212 loss)
I1210 14:31:24.130937  4700 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1210 14:31:29.798354  4700 solver.cpp:218] Iteration 118600 (17.6457 iter/s, 5.66711s/100 iters), loss = 0.368675
I1210 14:31:29.798354  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:31:29.798354  4700 solver.cpp:237]     Train net output #1: loss = 0.368675 (* 1 = 0.368675 loss)
I1210 14:31:29.798354  4700 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1210 14:31:35.467800  4700 solver.cpp:218] Iteration 118700 (17.6405 iter/s, 5.66876s/100 iters), loss = 0.311148
I1210 14:31:35.467800  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:31:35.467800  4700 solver.cpp:237]     Train net output #1: loss = 0.311148 (* 1 = 0.311148 loss)
I1210 14:31:35.467800  4700 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1210 14:31:41.137430  4700 solver.cpp:218] Iteration 118800 (17.6387 iter/s, 5.66937s/100 iters), loss = 0.317823
I1210 14:31:41.137430  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:31:41.137430  4700 solver.cpp:237]     Train net output #1: loss = 0.317823 (* 1 = 0.317823 loss)
I1210 14:31:41.137430  4700 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1210 14:31:46.794450  4700 solver.cpp:218] Iteration 118900 (17.6804 iter/s, 5.65597s/100 iters), loss = 0.321588
I1210 14:31:46.794450  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:31:46.794450  4700 solver.cpp:237]     Train net output #1: loss = 0.321588 (* 1 = 0.321588 loss)
I1210 14:31:46.794450  4700 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1210 14:31:52.178179 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:31:52.399719  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_119000.caffemodel
I1210 14:31:52.415719  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_119000.solverstate
I1210 14:31:52.420228  4700 solver.cpp:330] Iteration 119000, Testing net (#0)
I1210 14:31:52.420228  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:31:53.786270  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:31:53.839095  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6739
I1210 14:31:53.839095  4700 solver.cpp:397]     Test net output #1: loss = 1.28513 (* 1 = 1.28513 loss)
I1210 14:31:53.894078  4700 solver.cpp:218] Iteration 119000 (14.0857 iter/s, 7.09942s/100 iters), loss = 0.306
I1210 14:31:53.894078  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:31:53.894078  4700 solver.cpp:237]     Train net output #1: loss = 0.306 (* 1 = 0.306 loss)
I1210 14:31:53.894078  4700 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1210 14:31:59.538828  4700 solver.cpp:218] Iteration 119100 (17.7178 iter/s, 5.64405s/100 iters), loss = 0.298569
I1210 14:31:59.538828  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:31:59.538828  4700 solver.cpp:237]     Train net output #1: loss = 0.298569 (* 1 = 0.298569 loss)
I1210 14:31:59.538828  4700 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1210 14:32:05.177610  4700 solver.cpp:218] Iteration 119200 (17.7346 iter/s, 5.6387s/100 iters), loss = 0.265992
I1210 14:32:05.177610  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:32:05.177610  4700 solver.cpp:237]     Train net output #1: loss = 0.265992 (* 1 = 0.265992 loss)
I1210 14:32:05.177610  4700 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1210 14:32:10.818617  4700 solver.cpp:218] Iteration 119300 (17.7297 iter/s, 5.64027s/100 iters), loss = 0.342297
I1210 14:32:10.818617  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:32:10.818617  4700 solver.cpp:237]     Train net output #1: loss = 0.342297 (* 1 = 0.342297 loss)
I1210 14:32:10.818617  4700 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1210 14:32:16.459117  4700 solver.cpp:218] Iteration 119400 (17.7314 iter/s, 5.63973s/100 iters), loss = 0.385291
I1210 14:32:16.459117  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:32:16.459117  4700 solver.cpp:237]     Train net output #1: loss = 0.385291 (* 1 = 0.385291 loss)
I1210 14:32:16.459117  4700 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1210 14:32:21.833850 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:32:22.056884  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_119500.caffemodel
I1210 14:32:22.072883  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_119500.solverstate
I1210 14:32:22.077883  4700 solver.cpp:330] Iteration 119500, Testing net (#0)
I1210 14:32:22.077883  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:32:23.443831  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:32:23.497336  4700 solver.cpp:397]     Test net output #0: accuracy = 0.675
I1210 14:32:23.497336  4700 solver.cpp:397]     Test net output #1: loss = 1.29572 (* 1 = 1.29572 loss)
I1210 14:32:23.553340  4700 solver.cpp:218] Iteration 119500 (14.0959 iter/s, 7.09424s/100 iters), loss = 0.338653
I1210 14:32:23.553340  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:32:23.553340  4700 solver.cpp:237]     Train net output #1: loss = 0.338653 (* 1 = 0.338653 loss)
I1210 14:32:23.553340  4700 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1210 14:32:29.213413  4700 solver.cpp:218] Iteration 119600 (17.6698 iter/s, 5.65939s/100 iters), loss = 0.297103
I1210 14:32:29.213413  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:32:29.213413  4700 solver.cpp:237]     Train net output #1: loss = 0.297103 (* 1 = 0.297103 loss)
I1210 14:32:29.213413  4700 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1210 14:32:34.854364  4700 solver.cpp:218] Iteration 119700 (17.7288 iter/s, 5.64053s/100 iters), loss = 0.234172
I1210 14:32:34.854364  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:32:34.854364  4700 solver.cpp:237]     Train net output #1: loss = 0.234172 (* 1 = 0.234172 loss)
I1210 14:32:34.854364  4700 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1210 14:32:40.499747  4700 solver.cpp:218] Iteration 119800 (17.7137 iter/s, 5.64536s/100 iters), loss = 0.40274
I1210 14:32:40.499747  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:32:40.499747  4700 solver.cpp:237]     Train net output #1: loss = 0.402739 (* 1 = 0.402739 loss)
I1210 14:32:40.499747  4700 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1210 14:32:46.158231  4700 solver.cpp:218] Iteration 119900 (17.6759 iter/s, 5.65741s/100 iters), loss = 0.351961
I1210 14:32:46.158231  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:32:46.158231  4700 solver.cpp:237]     Train net output #1: loss = 0.351961 (* 1 = 0.351961 loss)
I1210 14:32:46.158231  4700 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1210 14:32:51.541676 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:32:51.765696  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_120000.caffemodel
I1210 14:32:51.779695  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_120000.solverstate
I1210 14:32:51.784696  4700 solver.cpp:330] Iteration 120000, Testing net (#0)
I1210 14:32:51.784696  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:32:53.152324  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:32:53.206826  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6711
I1210 14:32:53.206826  4700 solver.cpp:397]     Test net output #1: loss = 1.29421 (* 1 = 1.29421 loss)
I1210 14:32:53.260833  4700 solver.cpp:218] Iteration 120000 (14.0791 iter/s, 7.10272s/100 iters), loss = 0.224161
I1210 14:32:53.260833  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:32:53.260833  4700 solver.cpp:237]     Train net output #1: loss = 0.224161 (* 1 = 0.224161 loss)
I1210 14:32:53.260833  4700 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1210 14:32:58.907291  4700 solver.cpp:218] Iteration 120100 (17.7123 iter/s, 5.64578s/100 iters), loss = 0.319228
I1210 14:32:58.907291  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:32:58.907291  4700 solver.cpp:237]     Train net output #1: loss = 0.319228 (* 1 = 0.319228 loss)
I1210 14:32:58.907291  4700 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1210 14:33:04.559710  4700 solver.cpp:218] Iteration 120200 (17.6924 iter/s, 5.65214s/100 iters), loss = 0.219661
I1210 14:33:04.559710  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 14:33:04.559710  4700 solver.cpp:237]     Train net output #1: loss = 0.219661 (* 1 = 0.219661 loss)
I1210 14:33:04.559710  4700 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1210 14:33:10.205153  4700 solver.cpp:218] Iteration 120300 (17.7148 iter/s, 5.645s/100 iters), loss = 0.323681
I1210 14:33:10.205153  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:33:10.205153  4700 solver.cpp:237]     Train net output #1: loss = 0.323681 (* 1 = 0.323681 loss)
I1210 14:33:10.205153  4700 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1210 14:33:15.854701  4700 solver.cpp:218] Iteration 120400 (17.7034 iter/s, 5.64864s/100 iters), loss = 0.391086
I1210 14:33:15.854701  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:33:15.854701  4700 solver.cpp:237]     Train net output #1: loss = 0.391086 (* 1 = 0.391086 loss)
I1210 14:33:15.854701  4700 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1210 14:33:21.229106 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:33:21.450124  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_120500.caffemodel
I1210 14:33:21.465126  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_120500.solverstate
I1210 14:33:21.470127  4700 solver.cpp:330] Iteration 120500, Testing net (#0)
I1210 14:33:21.470127  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:33:22.837205  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:33:22.892210  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6713
I1210 14:33:22.892210  4700 solver.cpp:397]     Test net output #1: loss = 1.2798 (* 1 = 1.2798 loss)
I1210 14:33:22.946244  4700 solver.cpp:218] Iteration 120500 (14.1022 iter/s, 7.0911s/100 iters), loss = 0.253732
I1210 14:33:22.946244  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:33:22.946244  4700 solver.cpp:237]     Train net output #1: loss = 0.253732 (* 1 = 0.253732 loss)
I1210 14:33:22.946244  4700 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1210 14:33:28.587699  4700 solver.cpp:218] Iteration 120600 (17.726 iter/s, 5.64144s/100 iters), loss = 0.352936
I1210 14:33:28.587699  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:33:28.587699  4700 solver.cpp:237]     Train net output #1: loss = 0.352936 (* 1 = 0.352936 loss)
I1210 14:33:28.587699  4700 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1210 14:33:34.228806  4700 solver.cpp:218] Iteration 120700 (17.7292 iter/s, 5.64041s/100 iters), loss = 0.204201
I1210 14:33:34.228806  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:33:34.228806  4700 solver.cpp:237]     Train net output #1: loss = 0.204201 (* 1 = 0.204201 loss)
I1210 14:33:34.228806  4700 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1210 14:33:39.863910  4700 solver.cpp:218] Iteration 120800 (17.7481 iter/s, 5.63441s/100 iters), loss = 0.342598
I1210 14:33:39.863910  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:33:39.863910  4700 solver.cpp:237]     Train net output #1: loss = 0.342598 (* 1 = 0.342598 loss)
I1210 14:33:39.863910  4700 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1210 14:33:45.505007  4700 solver.cpp:218] Iteration 120900 (17.727 iter/s, 5.64111s/100 iters), loss = 0.356286
I1210 14:33:45.505007  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 14:33:45.505007  4700 solver.cpp:237]     Train net output #1: loss = 0.356286 (* 1 = 0.356286 loss)
I1210 14:33:45.505007  4700 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1210 14:33:50.868440 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:33:51.091451  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_121000.caffemodel
I1210 14:33:51.107452  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_121000.solverstate
I1210 14:33:51.112452  4700 solver.cpp:330] Iteration 121000, Testing net (#0)
I1210 14:33:51.112452  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:33:52.481587  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:33:52.536587  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6727
I1210 14:33:52.536587  4700 solver.cpp:397]     Test net output #1: loss = 1.28069 (* 1 = 1.28069 loss)
I1210 14:33:52.590591  4700 solver.cpp:218] Iteration 121000 (14.1154 iter/s, 7.08444s/100 iters), loss = 0.286892
I1210 14:33:52.590591  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:33:52.590591  4700 solver.cpp:237]     Train net output #1: loss = 0.286892 (* 1 = 0.286892 loss)
I1210 14:33:52.590591  4700 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1210 14:33:58.248976  4700 solver.cpp:218] Iteration 121100 (17.6716 iter/s, 5.65879s/100 iters), loss = 0.323076
I1210 14:33:58.248976  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:33:58.248976  4700 solver.cpp:237]     Train net output #1: loss = 0.323076 (* 1 = 0.323076 loss)
I1210 14:33:58.248976  4700 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1210 14:34:03.910512  4700 solver.cpp:218] Iteration 121200 (17.6673 iter/s, 5.66016s/100 iters), loss = 0.270551
I1210 14:34:03.910512  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:34:03.910512  4700 solver.cpp:237]     Train net output #1: loss = 0.270551 (* 1 = 0.270551 loss)
I1210 14:34:03.910512  4700 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1210 14:34:09.571949  4700 solver.cpp:218] Iteration 121300 (17.6642 iter/s, 5.66116s/100 iters), loss = 0.326034
I1210 14:34:09.571949  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:34:09.571949  4700 solver.cpp:237]     Train net output #1: loss = 0.326034 (* 1 = 0.326034 loss)
I1210 14:34:09.571949  4700 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1210 14:34:15.234385  4700 solver.cpp:218] Iteration 121400 (17.6608 iter/s, 5.66225s/100 iters), loss = 0.349338
I1210 14:34:15.234385  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:34:15.234385  4700 solver.cpp:237]     Train net output #1: loss = 0.349337 (* 1 = 0.349337 loss)
I1210 14:34:15.234385  4700 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1210 14:34:20.615806 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:34:20.837832  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_121500.caffemodel
I1210 14:34:20.852833  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_121500.solverstate
I1210 14:34:20.857837  4700 solver.cpp:330] Iteration 121500, Testing net (#0)
I1210 14:34:20.857837  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:34:22.227947  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:34:22.280956  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6719
I1210 14:34:22.280956  4700 solver.cpp:397]     Test net output #1: loss = 1.29948 (* 1 = 1.29948 loss)
I1210 14:34:22.335957  4700 solver.cpp:218] Iteration 121500 (14.0835 iter/s, 7.10053s/100 iters), loss = 0.306805
I1210 14:34:22.335957  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:34:22.335957  4700 solver.cpp:237]     Train net output #1: loss = 0.306805 (* 1 = 0.306805 loss)
I1210 14:34:22.335957  4700 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1210 14:34:27.985229  4700 solver.cpp:218] Iteration 121600 (17.7015 iter/s, 5.64924s/100 iters), loss = 0.314151
I1210 14:34:27.985229  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:34:27.985229  4700 solver.cpp:237]     Train net output #1: loss = 0.314151 (* 1 = 0.314151 loss)
I1210 14:34:27.985229  4700 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1210 14:34:33.629765  4700 solver.cpp:218] Iteration 121700 (17.7164 iter/s, 5.64447s/100 iters), loss = 0.218878
I1210 14:34:33.629765  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:34:33.629765  4700 solver.cpp:237]     Train net output #1: loss = 0.218878 (* 1 = 0.218878 loss)
I1210 14:34:33.629765  4700 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1210 14:34:39.275519  4700 solver.cpp:218] Iteration 121800 (17.7156 iter/s, 5.64476s/100 iters), loss = 0.288266
I1210 14:34:39.275519  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:34:39.275519  4700 solver.cpp:237]     Train net output #1: loss = 0.288266 (* 1 = 0.288266 loss)
I1210 14:34:39.275519  4700 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1210 14:34:44.927130  4700 solver.cpp:218] Iteration 121900 (17.6954 iter/s, 5.65118s/100 iters), loss = 0.357679
I1210 14:34:44.927130  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:34:44.927130  4700 solver.cpp:237]     Train net output #1: loss = 0.357679 (* 1 = 0.357679 loss)
I1210 14:34:44.927130  4700 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1210 14:34:50.309587 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:34:50.532598  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_122000.caffemodel
I1210 14:34:50.546617  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_122000.solverstate
I1210 14:34:50.550613  4700 solver.cpp:330] Iteration 122000, Testing net (#0)
I1210 14:34:50.550613  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:34:51.920074  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:34:51.974576  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6751
I1210 14:34:51.974576  4700 solver.cpp:397]     Test net output #1: loss = 1.29038 (* 1 = 1.29038 loss)
I1210 14:34:52.028090  4700 solver.cpp:218] Iteration 122000 (14.0831 iter/s, 7.10072s/100 iters), loss = 0.160122
I1210 14:34:52.028090  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1210 14:34:52.028090  4700 solver.cpp:237]     Train net output #1: loss = 0.160122 (* 1 = 0.160122 loss)
I1210 14:34:52.028090  4700 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1210 14:34:57.678946  4700 solver.cpp:218] Iteration 122100 (17.6996 iter/s, 5.64986s/100 iters), loss = 0.288853
I1210 14:34:57.678946  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:34:57.678946  4700 solver.cpp:237]     Train net output #1: loss = 0.288853 (* 1 = 0.288853 loss)
I1210 14:34:57.678946  4700 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1210 14:35:03.328858  4700 solver.cpp:218] Iteration 122200 (17.6987 iter/s, 5.65012s/100 iters), loss = 0.2099
I1210 14:35:03.328858  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 14:35:03.328858  4700 solver.cpp:237]     Train net output #1: loss = 0.2099 (* 1 = 0.2099 loss)
I1210 14:35:03.328858  4700 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1210 14:35:08.971304  4700 solver.cpp:218] Iteration 122300 (17.726 iter/s, 5.64143s/100 iters), loss = 0.353769
I1210 14:35:08.971304  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:35:08.971304  4700 solver.cpp:237]     Train net output #1: loss = 0.353769 (* 1 = 0.353769 loss)
I1210 14:35:08.971304  4700 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1210 14:35:14.614681  4700 solver.cpp:218] Iteration 122400 (17.7188 iter/s, 5.64373s/100 iters), loss = 0.398201
I1210 14:35:14.615681  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:35:14.615681  4700 solver.cpp:237]     Train net output #1: loss = 0.398201 (* 1 = 0.398201 loss)
I1210 14:35:14.615681  4700 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1210 14:35:19.983182 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:35:20.205191  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_122500.caffemodel
I1210 14:35:20.221192  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_122500.solverstate
I1210 14:35:20.226193  4700 solver.cpp:330] Iteration 122500, Testing net (#0)
I1210 14:35:20.226193  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:35:21.598294  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:35:21.651298  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6727
I1210 14:35:21.651298  4700 solver.cpp:397]     Test net output #1: loss = 1.28115 (* 1 = 1.28115 loss)
I1210 14:35:21.704305  4700 solver.cpp:218] Iteration 122500 (14.107 iter/s, 7.0887s/100 iters), loss = 0.296163
I1210 14:35:21.704305  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:35:21.704305  4700 solver.cpp:237]     Train net output #1: loss = 0.296163 (* 1 = 0.296163 loss)
I1210 14:35:21.704305  4700 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1210 14:35:27.339843  4700 solver.cpp:218] Iteration 122600 (17.7459 iter/s, 5.6351s/100 iters), loss = 0.373428
I1210 14:35:27.339843  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:35:27.339843  4700 solver.cpp:237]     Train net output #1: loss = 0.373428 (* 1 = 0.373428 loss)
I1210 14:35:27.339843  4700 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1210 14:35:32.971750  4700 solver.cpp:218] Iteration 122700 (17.758 iter/s, 5.63125s/100 iters), loss = 0.249454
I1210 14:35:32.971750  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:35:32.971750  4700 solver.cpp:237]     Train net output #1: loss = 0.249453 (* 1 = 0.249453 loss)
I1210 14:35:32.971750  4700 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1210 14:35:38.611706  4700 solver.cpp:218] Iteration 122800 (17.7317 iter/s, 5.63962s/100 iters), loss = 0.309269
I1210 14:35:38.611706  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:35:38.611706  4700 solver.cpp:237]     Train net output #1: loss = 0.309269 (* 1 = 0.309269 loss)
I1210 14:35:38.611706  4700 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1210 14:35:44.254138  4700 solver.cpp:218] Iteration 122900 (17.723 iter/s, 5.64239s/100 iters), loss = 0.355666
I1210 14:35:44.255138  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:35:44.255138  4700 solver.cpp:237]     Train net output #1: loss = 0.355666 (* 1 = 0.355666 loss)
I1210 14:35:44.255138  4700 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1210 14:35:49.616538 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:35:49.838562  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_123000.caffemodel
I1210 14:35:49.853561  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_123000.solverstate
I1210 14:35:49.858562  4700 solver.cpp:330] Iteration 123000, Testing net (#0)
I1210 14:35:49.858562  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:35:51.227695  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:35:51.281700  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6729
I1210 14:35:51.281700  4700 solver.cpp:397]     Test net output #1: loss = 1.29704 (* 1 = 1.29704 loss)
I1210 14:35:51.334703  4700 solver.cpp:218] Iteration 123000 (14.1258 iter/s, 7.07926s/100 iters), loss = 0.268305
I1210 14:35:51.334703  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:35:51.334703  4700 solver.cpp:237]     Train net output #1: loss = 0.268305 (* 1 = 0.268305 loss)
I1210 14:35:51.334703  4700 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1210 14:35:56.980125  4700 solver.cpp:218] Iteration 123100 (17.7153 iter/s, 5.64485s/100 iters), loss = 0.282418
I1210 14:35:56.980125  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:35:56.980125  4700 solver.cpp:237]     Train net output #1: loss = 0.282418 (* 1 = 0.282418 loss)
I1210 14:35:56.980125  4700 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1210 14:36:02.629597  4700 solver.cpp:218] Iteration 123200 (17.7018 iter/s, 5.64914s/100 iters), loss = 0.259775
I1210 14:36:02.629597  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:36:02.629597  4700 solver.cpp:237]     Train net output #1: loss = 0.259775 (* 1 = 0.259775 loss)
I1210 14:36:02.629597  4700 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1210 14:36:08.279496  4700 solver.cpp:218] Iteration 123300 (17.7008 iter/s, 5.64946s/100 iters), loss = 0.339458
I1210 14:36:08.279496  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:36:08.279496  4700 solver.cpp:237]     Train net output #1: loss = 0.339458 (* 1 = 0.339458 loss)
I1210 14:36:08.279496  4700 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1210 14:36:13.937767  4700 solver.cpp:218] Iteration 123400 (17.6731 iter/s, 5.65833s/100 iters), loss = 0.367003
I1210 14:36:13.937767  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:36:13.937767  4700 solver.cpp:237]     Train net output #1: loss = 0.367003 (* 1 = 0.367003 loss)
I1210 14:36:13.937767  4700 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1210 14:36:19.312320 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:36:19.535337  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_123500.caffemodel
I1210 14:36:19.549337  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_123500.solverstate
I1210 14:36:19.554337  4700 solver.cpp:330] Iteration 123500, Testing net (#0)
I1210 14:36:19.554337  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:36:20.922521  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:36:20.976523  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6733
I1210 14:36:20.976523  4700 solver.cpp:397]     Test net output #1: loss = 1.29429 (* 1 = 1.29429 loss)
I1210 14:36:21.029525  4700 solver.cpp:218] Iteration 123500 (14.102 iter/s, 7.09121s/100 iters), loss = 0.301764
I1210 14:36:21.029525  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:36:21.029525  4700 solver.cpp:237]     Train net output #1: loss = 0.301764 (* 1 = 0.301764 loss)
I1210 14:36:21.029525  4700 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1210 14:36:26.692997  4700 solver.cpp:218] Iteration 123600 (17.6605 iter/s, 5.66235s/100 iters), loss = 0.306763
I1210 14:36:26.692997  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:36:26.692997  4700 solver.cpp:237]     Train net output #1: loss = 0.306763 (* 1 = 0.306763 loss)
I1210 14:36:26.692997  4700 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1210 14:36:32.363476  4700 solver.cpp:218] Iteration 123700 (17.6372 iter/s, 5.66982s/100 iters), loss = 0.218198
I1210 14:36:32.363476  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:36:32.363476  4700 solver.cpp:237]     Train net output #1: loss = 0.218198 (* 1 = 0.218198 loss)
I1210 14:36:32.363476  4700 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1210 14:36:38.027230  4700 solver.cpp:218] Iteration 123800 (17.656 iter/s, 5.66381s/100 iters), loss = 0.261733
I1210 14:36:38.027230  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:36:38.027230  4700 solver.cpp:237]     Train net output #1: loss = 0.261733 (* 1 = 0.261733 loss)
I1210 14:36:38.027230  4700 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1210 14:36:43.690661  4700 solver.cpp:218] Iteration 123900 (17.6602 iter/s, 5.66246s/100 iters), loss = 0.345815
I1210 14:36:43.690661  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:36:43.690661  4700 solver.cpp:237]     Train net output #1: loss = 0.345815 (* 1 = 0.345815 loss)
I1210 14:36:43.690661  4700 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1210 14:36:49.075623 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:36:49.296146  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_124000.caffemodel
I1210 14:36:49.312146  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_124000.solverstate
I1210 14:36:49.317147  4700 solver.cpp:330] Iteration 124000, Testing net (#0)
I1210 14:36:49.317147  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:36:50.687793  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:36:50.740296  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6707
I1210 14:36:50.740296  4700 solver.cpp:397]     Test net output #1: loss = 1.3093 (* 1 = 1.3093 loss)
I1210 14:36:50.795312  4700 solver.cpp:218] Iteration 124000 (14.0759 iter/s, 7.10436s/100 iters), loss = 0.203327
I1210 14:36:50.795312  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:36:50.795312  4700 solver.cpp:237]     Train net output #1: loss = 0.203327 (* 1 = 0.203327 loss)
I1210 14:36:50.795312  4700 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1210 14:36:56.436695  4700 solver.cpp:218] Iteration 124100 (17.7273 iter/s, 5.64103s/100 iters), loss = 0.295923
I1210 14:36:56.436695  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:36:56.436695  4700 solver.cpp:237]     Train net output #1: loss = 0.295923 (* 1 = 0.295923 loss)
I1210 14:36:56.436695  4700 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1210 14:37:02.083094  4700 solver.cpp:218] Iteration 124200 (17.7124 iter/s, 5.64577s/100 iters), loss = 0.187448
I1210 14:37:02.083094  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 14:37:02.083094  4700 solver.cpp:237]     Train net output #1: loss = 0.187448 (* 1 = 0.187448 loss)
I1210 14:37:02.083595  4700 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1210 14:37:07.720520  4700 solver.cpp:218] Iteration 124300 (17.7382 iter/s, 5.63754s/100 iters), loss = 0.289754
I1210 14:37:07.721520  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:37:07.721520  4700 solver.cpp:237]     Train net output #1: loss = 0.289754 (* 1 = 0.289754 loss)
I1210 14:37:07.721520  4700 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1210 14:37:13.362952  4700 solver.cpp:218] Iteration 124400 (17.7247 iter/s, 5.64186s/100 iters), loss = 0.372157
I1210 14:37:13.362952  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:37:13.362952  4700 solver.cpp:237]     Train net output #1: loss = 0.372157 (* 1 = 0.372157 loss)
I1210 14:37:13.362952  4700 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1210 14:37:18.736304 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:37:18.959317  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_124500.caffemodel
I1210 14:37:18.979820  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_124500.solverstate
I1210 14:37:18.984820  4700 solver.cpp:330] Iteration 124500, Testing net (#0)
I1210 14:37:18.984820  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:37:20.351500  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:37:20.404531  4700 solver.cpp:397]     Test net output #0: accuracy = 0.675
I1210 14:37:20.404531  4700 solver.cpp:397]     Test net output #1: loss = 1.29615 (* 1 = 1.29615 loss)
I1210 14:37:20.457510  4700 solver.cpp:218] Iteration 124500 (14.0963 iter/s, 7.09404s/100 iters), loss = 0.284099
I1210 14:37:20.457510  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:37:20.457510  4700 solver.cpp:237]     Train net output #1: loss = 0.284099 (* 1 = 0.284099 loss)
I1210 14:37:20.457510  4700 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1210 14:37:26.100033  4700 solver.cpp:218] Iteration 124600 (17.7262 iter/s, 5.64136s/100 iters), loss = 0.261751
I1210 14:37:26.100033  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:37:26.100033  4700 solver.cpp:237]     Train net output #1: loss = 0.26175 (* 1 = 0.26175 loss)
I1210 14:37:26.100033  4700 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1210 14:37:31.747737  4700 solver.cpp:218] Iteration 124700 (17.7076 iter/s, 5.64729s/100 iters), loss = 0.243851
I1210 14:37:31.747737  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:37:31.747737  4700 solver.cpp:237]     Train net output #1: loss = 0.243851 (* 1 = 0.243851 loss)
I1210 14:37:31.747737  4700 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1210 14:37:37.397117  4700 solver.cpp:218] Iteration 124800 (17.7009 iter/s, 5.64943s/100 iters), loss = 0.338976
I1210 14:37:37.397117  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:37:37.397117  4700 solver.cpp:237]     Train net output #1: loss = 0.338976 (* 1 = 0.338976 loss)
I1210 14:37:37.397117  4700 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1210 14:37:43.047570  4700 solver.cpp:218] Iteration 124900 (17.7012 iter/s, 5.64933s/100 iters), loss = 0.373908
I1210 14:37:43.047570  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 14:37:43.047570  4700 solver.cpp:237]     Train net output #1: loss = 0.373908 (* 1 = 0.373908 loss)
I1210 14:37:43.047570  4700 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1210 14:37:48.412923 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:37:48.635933  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_125000.caffemodel
I1210 14:37:48.649933  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_125000.solverstate
I1210 14:37:48.653934  4700 solver.cpp:330] Iteration 125000, Testing net (#0)
I1210 14:37:48.653934  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:37:50.023099  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:37:50.076092  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6742
I1210 14:37:50.076092  4700 solver.cpp:397]     Test net output #1: loss = 1.30745 (* 1 = 1.30745 loss)
I1210 14:37:50.129096  4700 solver.cpp:218] Iteration 125000 (14.1208 iter/s, 7.08173s/100 iters), loss = 0.250196
I1210 14:37:50.129096  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:37:50.129096  4700 solver.cpp:237]     Train net output #1: loss = 0.250196 (* 1 = 0.250196 loss)
I1210 14:37:50.129096  4700 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1210 14:37:55.787997  4700 solver.cpp:218] Iteration 125100 (17.6756 iter/s, 5.65751s/100 iters), loss = 0.267641
I1210 14:37:55.787997  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:37:55.787997  4700 solver.cpp:237]     Train net output #1: loss = 0.267641 (* 1 = 0.267641 loss)
I1210 14:37:55.787997  4700 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1210 14:38:01.442922  4700 solver.cpp:218] Iteration 125200 (17.6825 iter/s, 5.65531s/100 iters), loss = 0.193952
I1210 14:38:01.442922  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 14:38:01.442922  4700 solver.cpp:237]     Train net output #1: loss = 0.193952 (* 1 = 0.193952 loss)
I1210 14:38:01.442922  4700 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1210 14:38:07.103386  4700 solver.cpp:218] Iteration 125300 (17.6673 iter/s, 5.66016s/100 iters), loss = 0.331037
I1210 14:38:07.104385  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:38:07.104385  4700 solver.cpp:237]     Train net output #1: loss = 0.331037 (* 1 = 0.331037 loss)
I1210 14:38:07.104385  4700 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1210 14:38:12.766805  4700 solver.cpp:218] Iteration 125400 (17.6594 iter/s, 5.6627s/100 iters), loss = 0.305164
I1210 14:38:12.766805  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:38:12.766805  4700 solver.cpp:237]     Train net output #1: loss = 0.305164 (* 1 = 0.305164 loss)
I1210 14:38:12.766805  4700 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1210 14:38:18.152209 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:38:18.374219  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_125500.caffemodel
I1210 14:38:18.388722  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_125500.solverstate
I1210 14:38:18.393223  4700 solver.cpp:330] Iteration 125500, Testing net (#0)
I1210 14:38:18.393223  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:38:19.764297  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:38:19.820304  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6749
I1210 14:38:19.820304  4700 solver.cpp:397]     Test net output #1: loss = 1.29938 (* 1 = 1.29938 loss)
I1210 14:38:19.874305  4700 solver.cpp:218] Iteration 125500 (14.0713 iter/s, 7.10667s/100 iters), loss = 0.253615
I1210 14:38:19.874305  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:38:19.874305  4700 solver.cpp:237]     Train net output #1: loss = 0.253615 (* 1 = 0.253615 loss)
I1210 14:38:19.874305  4700 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1210 14:38:25.510668  4700 solver.cpp:218] Iteration 125600 (17.7424 iter/s, 5.63623s/100 iters), loss = 0.285559
I1210 14:38:25.510668  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:38:25.510668  4700 solver.cpp:237]     Train net output #1: loss = 0.285559 (* 1 = 0.285559 loss)
I1210 14:38:25.510668  4700 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1210 14:38:31.158013  4700 solver.cpp:218] Iteration 125700 (17.7107 iter/s, 5.6463s/100 iters), loss = 0.214187
I1210 14:38:31.158013  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:38:31.158013  4700 solver.cpp:237]     Train net output #1: loss = 0.214187 (* 1 = 0.214187 loss)
I1210 14:38:31.158013  4700 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1210 14:38:36.795440  4700 solver.cpp:218] Iteration 125800 (17.739 iter/s, 5.6373s/100 iters), loss = 0.315059
I1210 14:38:36.795440  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:38:36.795440  4700 solver.cpp:237]     Train net output #1: loss = 0.315059 (* 1 = 0.315059 loss)
I1210 14:38:36.795440  4700 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1210 14:38:42.434224  4700 solver.cpp:218] Iteration 125900 (17.7364 iter/s, 5.63813s/100 iters), loss = 0.344437
I1210 14:38:42.434224  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:38:42.434224  4700 solver.cpp:237]     Train net output #1: loss = 0.344437 (* 1 = 0.344437 loss)
I1210 14:38:42.434224  4700 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1210 14:38:47.791087 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:38:48.015105  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_126000.caffemodel
I1210 14:38:48.033103  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_126000.solverstate
I1210 14:38:48.038103  4700 solver.cpp:330] Iteration 126000, Testing net (#0)
I1210 14:38:48.038103  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:38:49.406206  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:38:49.460206  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6738
I1210 14:38:49.460206  4700 solver.cpp:397]     Test net output #1: loss = 1.30232 (* 1 = 1.30232 loss)
I1210 14:38:49.515213  4700 solver.cpp:218] Iteration 126000 (14.1229 iter/s, 7.08072s/100 iters), loss = 0.242485
I1210 14:38:49.515213  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:38:49.515213  4700 solver.cpp:237]     Train net output #1: loss = 0.242485 (* 1 = 0.242485 loss)
I1210 14:38:49.515213  4700 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1210 14:38:55.164680  4700 solver.cpp:218] Iteration 126100 (17.7006 iter/s, 5.64952s/100 iters), loss = 0.346958
I1210 14:38:55.164680  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 14:38:55.164680  4700 solver.cpp:237]     Train net output #1: loss = 0.346958 (* 1 = 0.346958 loss)
I1210 14:38:55.164680  4700 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1210 14:39:00.815089  4700 solver.cpp:218] Iteration 126200 (17.7013 iter/s, 5.64932s/100 iters), loss = 0.257614
I1210 14:39:00.815089  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:39:00.815089  4700 solver.cpp:237]     Train net output #1: loss = 0.257614 (* 1 = 0.257614 loss)
I1210 14:39:00.815089  4700 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1210 14:39:06.468523  4700 solver.cpp:218] Iteration 126300 (17.6887 iter/s, 5.65331s/100 iters), loss = 0.258732
I1210 14:39:06.468523  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:39:06.468523  4700 solver.cpp:237]     Train net output #1: loss = 0.258732 (* 1 = 0.258732 loss)
I1210 14:39:06.468523  4700 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1210 14:39:12.132951  4700 solver.cpp:218] Iteration 126400 (17.656 iter/s, 5.66381s/100 iters), loss = 0.393875
I1210 14:39:12.132951  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:39:12.132951  4700 solver.cpp:237]     Train net output #1: loss = 0.393875 (* 1 = 0.393875 loss)
I1210 14:39:12.132951  4700 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1210 14:39:17.513345 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:39:17.736357  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_126500.caffemodel
I1210 14:39:17.750357  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_126500.solverstate
I1210 14:39:17.755357  4700 solver.cpp:330] Iteration 126500, Testing net (#0)
I1210 14:39:17.755357  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:39:19.122483  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:39:19.177481  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6684
I1210 14:39:19.177481  4700 solver.cpp:397]     Test net output #1: loss = 1.31293 (* 1 = 1.31293 loss)
I1210 14:39:19.230487  4700 solver.cpp:218] Iteration 126500 (14.0898 iter/s, 7.09733s/100 iters), loss = 0.268137
I1210 14:39:19.230487  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:39:19.230487  4700 solver.cpp:237]     Train net output #1: loss = 0.268137 (* 1 = 0.268137 loss)
I1210 14:39:19.230487  4700 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1210 14:39:24.870884  4700 solver.cpp:218] Iteration 126600 (17.7322 iter/s, 5.63947s/100 iters), loss = 0.344065
I1210 14:39:24.870884  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:39:24.870884  4700 solver.cpp:237]     Train net output #1: loss = 0.344065 (* 1 = 0.344065 loss)
I1210 14:39:24.870884  4700 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1210 14:39:30.513294  4700 solver.cpp:218] Iteration 126700 (17.7243 iter/s, 5.64196s/100 iters), loss = 0.20214
I1210 14:39:30.513294  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 14:39:30.513294  4700 solver.cpp:237]     Train net output #1: loss = 0.20214 (* 1 = 0.20214 loss)
I1210 14:39:30.513294  4700 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1210 14:39:36.157742  4700 solver.cpp:218] Iteration 126800 (17.7171 iter/s, 5.64428s/100 iters), loss = 0.25054
I1210 14:39:36.157742  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:39:36.157742  4700 solver.cpp:237]     Train net output #1: loss = 0.25054 (* 1 = 0.25054 loss)
I1210 14:39:36.157742  4700 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1210 14:39:41.797159  4700 solver.cpp:218] Iteration 126900 (17.7331 iter/s, 5.63916s/100 iters), loss = 0.318113
I1210 14:39:41.797159  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:39:41.797159  4700 solver.cpp:237]     Train net output #1: loss = 0.318113 (* 1 = 0.318113 loss)
I1210 14:39:41.797159  4700 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1210 14:39:47.159626 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:39:47.381638  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_127000.caffemodel
I1210 14:39:47.395640  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_127000.solverstate
I1210 14:39:47.400640  4700 solver.cpp:330] Iteration 127000, Testing net (#0)
I1210 14:39:47.400640  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:39:48.766767  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:39:48.819766  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6714
I1210 14:39:48.819766  4700 solver.cpp:397]     Test net output #1: loss = 1.31 (* 1 = 1.31 loss)
I1210 14:39:48.875772  4700 solver.cpp:218] Iteration 127000 (14.129 iter/s, 7.07763s/100 iters), loss = 0.272938
I1210 14:39:48.875772  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:39:48.875772  4700 solver.cpp:237]     Train net output #1: loss = 0.272938 (* 1 = 0.272938 loss)
I1210 14:39:48.875772  4700 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1210 14:39:54.526232  4700 solver.cpp:218] Iteration 127100 (17.6983 iter/s, 5.65025s/100 iters), loss = 0.293692
I1210 14:39:54.526232  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:39:54.526232  4700 solver.cpp:237]     Train net output #1: loss = 0.293692 (* 1 = 0.293692 loss)
I1210 14:39:54.526232  4700 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1210 14:40:00.169719  4700 solver.cpp:218] Iteration 127200 (17.7206 iter/s, 5.64315s/100 iters), loss = 0.245355
I1210 14:40:00.169719  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:40:00.169719  4700 solver.cpp:237]     Train net output #1: loss = 0.245355 (* 1 = 0.245355 loss)
I1210 14:40:00.169719  4700 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1210 14:40:05.833535  4700 solver.cpp:218] Iteration 127300 (17.6563 iter/s, 5.66369s/100 iters), loss = 0.32486
I1210 14:40:05.834537  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:40:05.834537  4700 solver.cpp:237]     Train net output #1: loss = 0.32486 (* 1 = 0.32486 loss)
I1210 14:40:05.834537  4700 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1210 14:40:11.486243  4700 solver.cpp:218] Iteration 127400 (17.6929 iter/s, 5.652s/100 iters), loss = 0.304729
I1210 14:40:11.486243  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:40:11.486243  4700 solver.cpp:237]     Train net output #1: loss = 0.304729 (* 1 = 0.304729 loss)
I1210 14:40:11.486243  4700 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1210 14:40:16.853273 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:40:17.075318  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_127500.caffemodel
I1210 14:40:17.090320  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_127500.solverstate
I1210 14:40:17.095331  4700 solver.cpp:330] Iteration 127500, Testing net (#0)
I1210 14:40:17.095331  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:40:18.462484  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:40:18.517990  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6703
I1210 14:40:18.517990  4700 solver.cpp:397]     Test net output #1: loss = 1.32748 (* 1 = 1.32748 loss)
I1210 14:40:18.572011  4700 solver.cpp:218] Iteration 127500 (14.1146 iter/s, 7.08484s/100 iters), loss = 0.264852
I1210 14:40:18.572011  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:40:18.572011  4700 solver.cpp:237]     Train net output #1: loss = 0.264852 (* 1 = 0.264852 loss)
I1210 14:40:18.572011  4700 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1210 14:40:24.213979  4700 solver.cpp:218] Iteration 127600 (17.726 iter/s, 5.64142s/100 iters), loss = 0.274742
I1210 14:40:24.213979  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:40:24.213979  4700 solver.cpp:237]     Train net output #1: loss = 0.274742 (* 1 = 0.274742 loss)
I1210 14:40:24.213979  4700 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1210 14:40:29.854948  4700 solver.cpp:218] Iteration 127700 (17.729 iter/s, 5.64047s/100 iters), loss = 0.236361
I1210 14:40:29.854948  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:40:29.854948  4700 solver.cpp:237]     Train net output #1: loss = 0.236361 (* 1 = 0.236361 loss)
I1210 14:40:29.854948  4700 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1210 14:40:35.506609  4700 solver.cpp:218] Iteration 127800 (17.6942 iter/s, 5.65156s/100 iters), loss = 0.263882
I1210 14:40:35.506609  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:40:35.506609  4700 solver.cpp:237]     Train net output #1: loss = 0.263882 (* 1 = 0.263882 loss)
I1210 14:40:35.506609  4700 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1210 14:40:41.153312  4700 solver.cpp:218] Iteration 127900 (17.7124 iter/s, 5.64575s/100 iters), loss = 0.344489
I1210 14:40:41.153312  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:40:41.153312  4700 solver.cpp:237]     Train net output #1: loss = 0.344489 (* 1 = 0.344489 loss)
I1210 14:40:41.153312  4700 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1210 14:40:46.520761 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:40:46.743772  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_128000.caffemodel
I1210 14:40:46.758774  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_128000.solverstate
I1210 14:40:46.763278  4700 solver.cpp:330] Iteration 128000, Testing net (#0)
I1210 14:40:46.763278  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:40:48.129904  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:40:48.185915  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6682
I1210 14:40:48.185915  4700 solver.cpp:397]     Test net output #1: loss = 1.32654 (* 1 = 1.32654 loss)
I1210 14:40:48.239914  4700 solver.cpp:218] Iteration 128000 (14.1122 iter/s, 7.08606s/100 iters), loss = 0.275506
I1210 14:40:48.239914  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:40:48.239914  4700 solver.cpp:237]     Train net output #1: loss = 0.275506 (* 1 = 0.275506 loss)
I1210 14:40:48.239914  4700 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1210 14:40:53.879343  4700 solver.cpp:218] Iteration 128100 (17.7314 iter/s, 5.63972s/100 iters), loss = 0.324047
I1210 14:40:53.879343  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:40:53.879343  4700 solver.cpp:237]     Train net output #1: loss = 0.324047 (* 1 = 0.324047 loss)
I1210 14:40:53.879343  4700 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1210 14:40:59.516860  4700 solver.cpp:218] Iteration 128200 (17.742 iter/s, 5.63635s/100 iters), loss = 0.195312
I1210 14:40:59.516860  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:40:59.516860  4700 solver.cpp:237]     Train net output #1: loss = 0.195312 (* 1 = 0.195312 loss)
I1210 14:40:59.516860  4700 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1210 14:41:05.161252  4700 solver.cpp:218] Iteration 128300 (17.717 iter/s, 5.64431s/100 iters), loss = 0.314171
I1210 14:41:05.161252  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:41:05.161753  4700 solver.cpp:237]     Train net output #1: loss = 0.314171 (* 1 = 0.314171 loss)
I1210 14:41:05.161753  4700 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1210 14:41:10.810700  4700 solver.cpp:218] Iteration 128400 (17.7018 iter/s, 5.64916s/100 iters), loss = 0.400311
I1210 14:41:10.810700  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 14:41:10.810700  4700 solver.cpp:237]     Train net output #1: loss = 0.400311 (* 1 = 0.400311 loss)
I1210 14:41:10.810700  4700 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1210 14:41:16.185115 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:41:16.408126  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_128500.caffemodel
I1210 14:41:16.423125  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_128500.solverstate
I1210 14:41:16.428128  4700 solver.cpp:330] Iteration 128500, Testing net (#0)
I1210 14:41:16.428128  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:41:17.796242  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:41:17.852238  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6722
I1210 14:41:17.852238  4700 solver.cpp:397]     Test net output #1: loss = 1.32243 (* 1 = 1.32243 loss)
I1210 14:41:17.906240  4700 solver.cpp:218] Iteration 128500 (14.0952 iter/s, 7.09464s/100 iters), loss = 0.297147
I1210 14:41:17.906240  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:41:17.906240  4700 solver.cpp:237]     Train net output #1: loss = 0.297147 (* 1 = 0.297147 loss)
I1210 14:41:17.906240  4700 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1210 14:41:23.557688  4700 solver.cpp:218] Iteration 128600 (17.6939 iter/s, 5.65167s/100 iters), loss = 0.345308
I1210 14:41:23.557688  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:41:23.557688  4700 solver.cpp:237]     Train net output #1: loss = 0.345308 (* 1 = 0.345308 loss)
I1210 14:41:23.557688  4700 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1210 14:41:29.214154  4700 solver.cpp:218] Iteration 128700 (17.6822 iter/s, 5.6554s/100 iters), loss = 0.218986
I1210 14:41:29.214154  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:41:29.214154  4700 solver.cpp:237]     Train net output #1: loss = 0.218986 (* 1 = 0.218986 loss)
I1210 14:41:29.214154  4700 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1210 14:41:34.858615  4700 solver.cpp:218] Iteration 128800 (17.7183 iter/s, 5.64388s/100 iters), loss = 0.317056
I1210 14:41:34.858615  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:41:34.858615  4700 solver.cpp:237]     Train net output #1: loss = 0.317056 (* 1 = 0.317056 loss)
I1210 14:41:34.858615  4700 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1210 14:41:40.511049  4700 solver.cpp:218] Iteration 128900 (17.6917 iter/s, 5.65236s/100 iters), loss = 0.426614
I1210 14:41:40.511049  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:41:40.511049  4700 solver.cpp:237]     Train net output #1: loss = 0.426614 (* 1 = 0.426614 loss)
I1210 14:41:40.511049  4700 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1210 14:41:45.880450 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:41:46.104465  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_129000.caffemodel
I1210 14:41:46.118465  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_129000.solverstate
I1210 14:41:46.123466  4700 solver.cpp:330] Iteration 129000, Testing net (#0)
I1210 14:41:46.123466  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:41:47.493592  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:41:47.547593  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6705
I1210 14:41:47.547593  4700 solver.cpp:397]     Test net output #1: loss = 1.33096 (* 1 = 1.33096 loss)
I1210 14:41:47.600594  4700 solver.cpp:218] Iteration 129000 (14.1053 iter/s, 7.08953s/100 iters), loss = 0.233387
I1210 14:41:47.600594  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:41:47.600594  4700 solver.cpp:237]     Train net output #1: loss = 0.233387 (* 1 = 0.233387 loss)
I1210 14:41:47.601594  4700 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1210 14:41:53.269084  4700 solver.cpp:218] Iteration 129100 (17.6456 iter/s, 5.66715s/100 iters), loss = 0.285941
I1210 14:41:53.269084  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:41:53.269084  4700 solver.cpp:237]     Train net output #1: loss = 0.285941 (* 1 = 0.285941 loss)
I1210 14:41:53.269084  4700 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1210 14:41:58.925469  4700 solver.cpp:218] Iteration 129200 (17.6804 iter/s, 5.65598s/100 iters), loss = 0.207748
I1210 14:41:58.925469  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:41:58.925469  4700 solver.cpp:237]     Train net output #1: loss = 0.207748 (* 1 = 0.207748 loss)
I1210 14:41:58.925469  4700 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1210 14:42:04.584919  4700 solver.cpp:218] Iteration 129300 (17.6702 iter/s, 5.65924s/100 iters), loss = 0.298671
I1210 14:42:04.584919  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:42:04.584919  4700 solver.cpp:237]     Train net output #1: loss = 0.298671 (* 1 = 0.298671 loss)
I1210 14:42:04.584919  4700 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1210 14:42:10.251402  4700 solver.cpp:218] Iteration 129400 (17.6485 iter/s, 5.66621s/100 iters), loss = 0.357428
I1210 14:42:10.251402  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:42:10.251402  4700 solver.cpp:237]     Train net output #1: loss = 0.357428 (* 1 = 0.357428 loss)
I1210 14:42:10.251402  4700 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1210 14:42:15.639780 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:42:15.861793  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_129500.caffemodel
I1210 14:42:15.876296  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_129500.solverstate
I1210 14:42:15.881297  4700 solver.cpp:330] Iteration 129500, Testing net (#0)
I1210 14:42:15.881297  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:42:17.248946  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:42:17.302951  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6715
I1210 14:42:17.302951  4700 solver.cpp:397]     Test net output #1: loss = 1.32071 (* 1 = 1.32071 loss)
I1210 14:42:17.355950  4700 solver.cpp:218] Iteration 129500 (14.0758 iter/s, 7.10441s/100 iters), loss = 0.23273
I1210 14:42:17.355950  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:42:17.355950  4700 solver.cpp:237]     Train net output #1: loss = 0.23273 (* 1 = 0.23273 loss)
I1210 14:42:17.355950  4700 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1210 14:42:23.007405  4700 solver.cpp:218] Iteration 129600 (17.6958 iter/s, 5.65107s/100 iters), loss = 0.277959
I1210 14:42:23.007405  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:42:23.007405  4700 solver.cpp:237]     Train net output #1: loss = 0.277959 (* 1 = 0.277959 loss)
I1210 14:42:23.007405  4700 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1210 14:42:28.659855  4700 solver.cpp:218] Iteration 129700 (17.6948 iter/s, 5.65137s/100 iters), loss = 0.2035
I1210 14:42:28.659855  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 14:42:28.659855  4700 solver.cpp:237]     Train net output #1: loss = 0.2035 (* 1 = 0.2035 loss)
I1210 14:42:28.659855  4700 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1210 14:42:34.306313  4700 solver.cpp:218] Iteration 129800 (17.7114 iter/s, 5.64608s/100 iters), loss = 0.314618
I1210 14:42:34.306313  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:42:34.306313  4700 solver.cpp:237]     Train net output #1: loss = 0.314618 (* 1 = 0.314618 loss)
I1210 14:42:34.306313  4700 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1210 14:42:39.956717  4700 solver.cpp:218] Iteration 129900 (17.6975 iter/s, 5.65052s/100 iters), loss = 0.362341
I1210 14:42:39.956717  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:42:39.957717  4700 solver.cpp:237]     Train net output #1: loss = 0.362341 (* 1 = 0.362341 loss)
I1210 14:42:39.957717  4700 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1210 14:42:45.327118 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:42:45.548130  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_130000.caffemodel
I1210 14:42:45.562131  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_130000.solverstate
I1210 14:42:45.567131  4700 solver.cpp:330] Iteration 130000, Testing net (#0)
I1210 14:42:45.567131  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:42:46.936254  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:42:46.989259  4700 solver.cpp:397]     Test net output #0: accuracy = 0.67
I1210 14:42:46.989259  4700 solver.cpp:397]     Test net output #1: loss = 1.31834 (* 1 = 1.31834 loss)
I1210 14:42:47.043258  4700 solver.cpp:218] Iteration 130000 (14.1138 iter/s, 7.08526s/100 iters), loss = 0.240468
I1210 14:42:47.043258  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:42:47.043258  4700 solver.cpp:237]     Train net output #1: loss = 0.240468 (* 1 = 0.240468 loss)
I1210 14:42:47.043258  4700 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1210 14:42:52.684165  4700 solver.cpp:218] Iteration 130100 (17.7298 iter/s, 5.64023s/100 iters), loss = 0.31963
I1210 14:42:52.684165  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:42:52.684165  4700 solver.cpp:237]     Train net output #1: loss = 0.31963 (* 1 = 0.31963 loss)
I1210 14:42:52.684165  4700 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1210 14:42:58.326140  4700 solver.cpp:218] Iteration 130200 (17.7247 iter/s, 5.64185s/100 iters), loss = 0.197494
I1210 14:42:58.326140  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 14:42:58.326140  4700 solver.cpp:237]     Train net output #1: loss = 0.197494 (* 1 = 0.197494 loss)
I1210 14:42:58.326140  4700 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1210 14:43:03.970043  4700 solver.cpp:218] Iteration 130300 (17.7207 iter/s, 5.64312s/100 iters), loss = 0.324666
I1210 14:43:03.970043  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 14:43:03.970043  4700 solver.cpp:237]     Train net output #1: loss = 0.324666 (* 1 = 0.324666 loss)
I1210 14:43:03.970043  4700 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1210 14:43:09.614930  4700 solver.cpp:218] Iteration 130400 (17.7143 iter/s, 5.64514s/100 iters), loss = 0.418402
I1210 14:43:09.614930  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 14:43:09.614930  4700 solver.cpp:237]     Train net output #1: loss = 0.418402 (* 1 = 0.418402 loss)
I1210 14:43:09.614930  4700 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1210 14:43:14.973120 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:43:15.195343  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_130500.caffemodel
I1210 14:43:15.210345  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_130500.solverstate
I1210 14:43:15.215348  4700 solver.cpp:330] Iteration 130500, Testing net (#0)
I1210 14:43:15.215348  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:43:16.582131  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:43:16.634646  4700 solver.cpp:397]     Test net output #0: accuracy = 0.667
I1210 14:43:16.635634  4700 solver.cpp:397]     Test net output #1: loss = 1.32174 (* 1 = 1.32174 loss)
I1210 14:43:16.689347  4700 solver.cpp:218] Iteration 130500 (14.1379 iter/s, 7.0732s/100 iters), loss = 0.244031
I1210 14:43:16.689347  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 14:43:16.689347  4700 solver.cpp:237]     Train net output #1: loss = 0.244031 (* 1 = 0.244031 loss)
I1210 14:43:16.689347  4700 sgd_solver.cpp:105] Iteration 130500, lr = 0.001
I1210 14:43:22.332895  4700 solver.cpp:218] Iteration 130600 (17.7198 iter/s, 5.6434s/100 iters), loss = 0.319321
I1210 14:43:22.332895  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:43:22.332895  4700 solver.cpp:237]     Train net output #1: loss = 0.319321 (* 1 = 0.319321 loss)
I1210 14:43:22.332895  4700 sgd_solver.cpp:105] Iteration 130600, lr = 0.001
I1210 14:43:27.962258  4700 solver.cpp:218] Iteration 130700 (17.7639 iter/s, 5.62941s/100 iters), loss = 0.205562
I1210 14:43:27.962258  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:43:27.962258  4700 solver.cpp:237]     Train net output #1: loss = 0.205562 (* 1 = 0.205562 loss)
I1210 14:43:27.962258  4700 sgd_solver.cpp:105] Iteration 130700, lr = 0.001
I1210 14:43:33.578992  4700 solver.cpp:218] Iteration 130800 (17.8067 iter/s, 5.61586s/100 iters), loss = 0.258697
I1210 14:43:33.578992  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 14:43:33.578992  4700 solver.cpp:237]     Train net output #1: loss = 0.258697 (* 1 = 0.258697 loss)
I1210 14:43:33.578992  4700 sgd_solver.cpp:105] Iteration 130800, lr = 0.001
I1210 14:43:39.214792  4700 solver.cpp:218] Iteration 130900 (17.7462 iter/s, 5.635s/100 iters), loss = 0.333637
I1210 14:43:39.214792  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:43:39.214792  4700 solver.cpp:237]     Train net output #1: loss = 0.333637 (* 1 = 0.333637 loss)
I1210 14:43:39.214792  4700 sgd_solver.cpp:105] Iteration 130900, lr = 0.001
I1210 14:43:44.577162 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:43:44.799187  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_131000.caffemodel
I1210 14:43:44.814189  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_131000.solverstate
I1210 14:43:44.819190  4700 solver.cpp:330] Iteration 131000, Testing net (#0)
I1210 14:43:44.819190  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:43:46.188012  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:43:46.240514  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6692
I1210 14:43:46.240514  4700 solver.cpp:397]     Test net output #1: loss = 1.32802 (* 1 = 1.32802 loss)
I1210 14:43:46.294545  4700 solver.cpp:218] Iteration 131000 (14.1253 iter/s, 7.07952s/100 iters), loss = 0.334259
I1210 14:43:46.294545  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 14:43:46.294545  4700 solver.cpp:237]     Train net output #1: loss = 0.334259 (* 1 = 0.334259 loss)
I1210 14:43:46.294545  4700 sgd_solver.cpp:105] Iteration 131000, lr = 0.001
I1210 14:43:51.943001  4700 solver.cpp:218] Iteration 131100 (17.7052 iter/s, 5.64806s/100 iters), loss = 0.317909
I1210 14:43:51.943001  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 14:43:51.943001  4700 solver.cpp:237]     Train net output #1: loss = 0.317909 (* 1 = 0.317909 loss)
I1210 14:43:51.943001  4700 sgd_solver.cpp:105] Iteration 131100, lr = 0.001
I1210 14:43:57.595463  4700 solver.cpp:218] Iteration 131200 (17.694 iter/s, 5.65163s/100 iters), loss = 0.247014
I1210 14:43:57.595463  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:43:57.595463  4700 solver.cpp:237]     Train net output #1: loss = 0.247014 (* 1 = 0.247014 loss)
I1210 14:43:57.595463  4700 sgd_solver.cpp:105] Iteration 131200, lr = 0.001
I1210 14:44:03.241946  4700 solver.cpp:218] Iteration 131300 (17.7101 iter/s, 5.64649s/100 iters), loss = 0.306222
I1210 14:44:03.241946  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 14:44:03.241946  4700 solver.cpp:237]     Train net output #1: loss = 0.306222 (* 1 = 0.306222 loss)
I1210 14:44:03.241946  4700 sgd_solver.cpp:105] Iteration 131300, lr = 0.001
I1210 14:44:08.889302  4700 solver.cpp:218] Iteration 131400 (17.7092 iter/s, 5.6468s/100 iters), loss = 0.33608
I1210 14:44:08.889302  4700 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 14:44:08.889302  4700 solver.cpp:237]     Train net output #1: loss = 0.33608 (* 1 = 0.33608 loss)
I1210 14:44:08.889302  4700 sgd_solver.cpp:105] Iteration 131400, lr = 0.001
I1210 14:44:14.270309 16984 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:44:14.491822  4700 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_131500.caffemodel
I1210 14:44:14.505821  4700 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_iter_131500.solverstate
I1210 14:44:14.510821  4700 solver.cpp:330] Iteration 131500, Testing net (#0)
I1210 14:44:14.510821  4700 net.cpp:676] Ignoring source layer accuracy_training
I1210 14:44:15.879904  5200 data_layer.cpp:73] Restarting data prefetching from start.
I1210 14:44:15.933902  4700 solver.cpp:397]     Test net output #0: accuracy = 0.6705
I1210 14:44:15.933902  4700 solver.cpp:397]     Test net output #1: loss = 1.3196 (* 1 = 1.3196 loss)
I1210 14:44:15.987907  4700 solver.cpp:218] Iteration 131500 (14.0883 iter/s, 7.09807s/100 iters), loss = 0.